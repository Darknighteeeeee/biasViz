Possibly related to #1506.
onedrive is case insensitive, which means you can only have one of "file.jpg" and "file.JPG".
I wonder it is was reintroduced by go 1.8 which changed something in that area.
rclone mount -vv hubic:default ~/mnt/tmp/
2017/06/26 11:35:03 ERROR : volo/Volo�%80%99s: WriteFileHandle.New Put failed: HTTP Error: 412: 412 Precondition Failed
2017/06/26 11:35:03 ERROR : volo/Volo�%80%99s: WriteFileHandle.Write error: io: read/write on closed pipe
Saving to: ‘AD&D Accessory-FR-Volo\’s Guide to All Things.pdf’
$ ls -l AD*
-rw-rw-r-- 1 ncw ncw 8871505 Jun 24  2016 AD&D Accessory-FR-Volo’s Guide to All Things.pdf
Are you using `--bwlimit`?
There is a ticket for onedrive for business. It should be quite simple buy whenever I've tried I get bogged down in Microsoft terminology and needing developer subscriptions which I don't have, so help needed!  The API should just work it is registering the app etc which is the problem.  rclone will retry the whole sync if it finds errors it can't correct by doing its low level retries.
@billziss-gh do you have an thoughts about this? Is this related to the WinFSP intiialization? @billziss-gh thanks for looking into this.
* -> normalize unicode
Have a play with that and see if that is useful then we can think about how to integrate it properly.  This is almost certainly caused by OS X and its strange decision to store denormalized UTF-8 file names.
>>> a=u"10 - Polonaise in Ab major Op 53 Héroique.flac"
>>> b=u"10 - Polonaise in Ab major Op 53 Héroique.flac"
u'10 - Polonaise in Ab major Op 53 He\u0301roique.flac'
u'10 - Polonaise in Ab major Op 53 H\xe9roique.flac'
So if you do `rclone -vvvv copy b hubic:b`
The actual error message is crazy though, and I've fixed that here
It will now give the error `Failed to copy: container name needed in remote`  I see these too.  I don't think it is an rclone problem - I think it is a Hubic problem.  Specifically if you try to use anything but the default bucket it seems to take a very long time with lots of errors to create it.  Once it is created it is OK, so I suggest you keep trying.  What needs to be done is make the acd remote fail unless you have put in custom credentials and put a note in the docs about that. > Zenjaba have the credentials for you @ncw if you are willing to setup auth server so ACD would work again.
Wouldn't it just get banned again just like what happened with acdcli again?  I can certainly see rclone continuing to work with ACD for people that have their own credentials because of the low API hits but as soon as a auth server is officially put up, I just see it getting banned again.   > > Zenjaba have the credentials for you @ncw if you are willing to setup auth server so ACD would work again.
Edit: I realize this is off topic and prob better in the forums..... @calisro wrote:
2017/05/26 12:22:20 DEBUG : Targem Root/Welcome targem games/Links.xlsx: Sizes differ
Perhaps two limiters at twice the bandwidth...
@yonjah did we miss a QueryEscape in 32e9c86fcdb38d77dc5018f6184e4f3607c714d9 ? Are you sure you tried this with the latest beta - I just attempted to replicate and it seemed to work fine.
Yes this seems to be pureftpd intepreting wildcards.
150 Connecting to port 34975
150 Connecting to port 44283
150 Connecting to port 53341
I wonder if there is some way of turning off wildcard matching...
2017/05/26 20:26:24 INFO  : My Little Pony FiM - 6.25 - Die Rückkehr der Wechselponys - Teil 1.mp4: Copied (new)
2017/05/26 20:26:24 INFO  : My Little Pony FiM - 6.25 - Die Rückkehr der Wechselponys - Teil 1.mp4: Deleted
u'My Little Pony FiM - 6.25 - Die Ru\u0308ckkehr der Wechselponys - Teil 1.mp4'
u'My Little Pony FiM - 6.25 - Die R\xfcckkehr der Wechselponys - Teil 1.mp4'
@DurvalMenezes The latter could possibly be related to your problem.  Either way can you make a small demo of the problem that I can reproduce locally?  I'm having trouble working out what is going on! @alternativesurfer in your log you are using `rclone move` so deleting the file (locally) after it has been copied (remotely) is exactly what I'd expect to see.
2017/05/26 20:26:24 INFO  : My Little Pony FiM - 6.25 - Die Rückkehr der Wechselponys - Teil 1.mp4: Copied (new)
2017/05/26 20:26:24 INFO  : My Little Pony FiM - 6.25 - Die Rückkehr der Wechselponys - Teil 1.mp4: Deleted
u'My Little Pony FiM - 6.25 - Die Ru\u0308ckkehr der Wechselponys - Teil 1.mp4'
u'My Little Pony FiM - 6.25 - Die R\xfcckkehr der Wechselponys - Teil 1.mp4'
2017/05/21 08:23:40 DEBUG : itmqvijo3hgk99i0lnoup0kg15l6npe0cne225o5corpg3oc7niomknlaqgqaket3bfn3tu1sp5om: Unchanged skipping
2017/05/21 08:23:40 DEBUG : vqjpvrso6dh1pvorpqfuehtcs7bl9hven954h2t5vdp8svsqer0dm6se9fa4aa3ad9fn99ji05oui: Unchanged skipping
2017/05/21 08:23:41 DEBUG : bi26l61nr0n7u32atdd3t4u0fo/i8lujvia3cvuv90fo9o0voatggmsurfoa47ec973g3r9c2v46f4g: MD5 = e62ad6931cd9d7428ead4296bab2a2dd (Google drive root 'cloudp/lp08934q11u6a5gslo2ddds5b4/hkitmqcr303hk1a33m19ttdq24/nhcij8dbshqodics7ddemvfbok/i1dt6gb9f46ad1lp26ap7ci0q0/rheiv1nvivna0s0skafojp9ne4')
2017/05/21 08:23:41 DEBUG : bi26l61nr0n7u32atdd3t4u0fo/a0ga3oa6va95h46i5dtrr1nom8: MD5 differ
2017/05/21 08:23:41 DEBUG : bi26l61nr0n7u32atdd3t4u0fo/i8lujvia3cvuv90fo9o0voatggmsurfoa47ec973g3r9c2v46f4g: MD5 = 914294f32d885c4e77e17c4b335456bf (Google drive root 'cloudp/lp08934q11u6a5gslo2ddds5b4/hkitmqcr303hk1a33m19ttdq24/nhcij8dbshqodics7ddemvfbok/i1dt6gb9f46ad1lp26ap7ci0q0/rheiv1nvivna0s0skafojp9ne4')
2017/05/21 08:23:41 DEBUG : bi26l61nr0n7u32atdd3t4u0fo/i8lujvia3cvuv90fo9o0voatggmsurfoa47ec973g3r9c2v46f4g: MD5 differ
2017/05/21 08:23:41 DEBUG : bi26l61nr0n7u32atdd3t4u0fo/oca031civ090of8o9mat0n7jcubo6pd6fou3ovmskui8fogqeosg: MD5 = b3c500c48afab16ebe302d349684b6a2 (Google drive root 'cloudp/lp08934q11u6a5gslo2ddds5b4/hkitmqcr303hk1a33m19ttdq24/nhcij8dbshqodics7ddemvfbok/i1dt6gb9f46ad1lp26ap7ci0q0/rheiv1nvivna0s0skafojp9ne4')
2017/05/21 08:23:41 DEBUG : bi26l61nr0n7u32atdd3t4u0fo/oca031civ090of8o9mat0n7jcubo6pd6fou3ovmskui8fogqeosg: MD5 = 8f93d3eb1f549a50822e677f3c842abe (Google drive root 'cloudp/lp08934q11u6a5gslo2ddds5b4/hkitmqcr303hk1a33m19ttdq24/nhcij8dbshqodics7ddemvfbok/i1dt6gb9f46ad1lp26ap7ci0q0/rheiv1nvivna0s0skafojp9ne4')
2017/05/21 08:23:41 DEBUG : bi26l61nr0n7u32atdd3t4u0fo/oca031civ090of8o9mat0n7jcubo6pd6fou3ovmskui8fogqeosg: MD5 differ
2017/05/21 08:23:41 DEBUG : bi26l61nr0n7u32atdd3t4u0fo/le03la6a5jmaj1le14fd6g6pkcp9s420ok1fueuj6jqve9ojaoo0: MD5 = 68f60a661bdda934c2dde2c49e0f13a9 (Google drive root 'cloudp/lp08934q11u6a5gslo2ddds5b4/hkitmqcr303hk1a33m19ttdq24/nhcij8dbshqodics7ddemvfbok/i1dt6gb9f46ad1lp26ap7ci0q0/rheiv1nvivna0s0skafojp9ne4')
2017/05/21 08:23:41 NOTICE: bi26l61nr0n7u32atdd3t4u0fo/oca031civ090of8o9mat0n7jcubo6pd6fou3ovmskui8fogqeosg: Not copying as --dry-run
2017/05/21 08:23:41 DEBUG : bi26l61nr0n7u32atdd3t4u0fo/le03la6a5jmaj1le14fd6g6pkcp9s420ok1fueuj6jqve9ojaoo0: MD5 = 508d80bf9d0aae9af00b55e0f37b8f7f (Google drive root 'cloudp/lp08934q11u6a5gslo2ddds5b4/hkitmqcr303hk1a33m19ttdq24/nhcij8dbshqodics7ddemvfbok/i1dt6gb9f46ad1lp26ap7ci0q0/rheiv1nvivna0s0skafojp9ne4')
2017/05/21 08:23:41 DEBUG : bi26l61nr0n7u32atdd3t4u0fo/le03la6a5jmaj1le14fd6g6pkcp9s420ok1fueuj6jqve9ojaoo0: MD5 differ
rclone md5sum riosgd:cloudp/lp08934q11u6a5gslo2ddds5b4/hkitmqcr303hk1a33m19ttdq24/nhcij8dbshqodics7ddemvfbok/i1dt6gb9f46ad1lp26ap7ci0q0/rheiv1nvivna0s0skafojp9ne4/bi26l61nr0n7u32atdd3t4u0fo/i8lujvia3cvuv90fo9o0voatggmsurfoa47ec973g3r9c2v46f4g
914294f32d885c4e77e17c4b335456bf  i8lujvia3cvuv90fo9o0voatggmsurfoa47ec973g3r9c2v46f4g
e62ad6931cd9d7428ead4296bab2a2dd  i8lujvia3cvuv90fo9o0voatggmsurfoa47ec973g3r9c2v46f4g
HS -> md5sum '/home/robert/a/Coco_König.jpg'
HS -> md5sum '/home/robert/b/Coco_König.jpg'
93cd2a98d2bf75b972431bc97ddccf36  /home/robert/b/Coco_König.jpg
It is really wierd that I can decrypt them and they are identical but leaving them crypted they have different md5sums even on my local files system.
Did you sync from crypt -> crypt?
Fancy patching rclone and see if that helps and work that up into a PR?  I put a [post in the forum](https://forum.rclone.org/t/rclone-has-been-banned-from-amazon-drive/2314) which I'll update as and when I hear more info. @yonjah wrote
> You updated that amazon have banned since the secret are kept in code
http://imgur.com/Sgf7LqR - my GD
http://imgur.com/GTIbUJc - my Billing
* Can you split the vendor commit into a separate commit "vendor: add xyz for azure"?
Looking forward to seeing your changes!
The tests are quite fussy, so let me know if you need any help getting them to pass. How are you doing with this?
The problem is due to the way rclone interprets the command line.  When you say `rclone md5sum acd:/testfile.txt` rclone doesn't know if `testfile.txt` is a directory or a file.
rclone has a really convoluted method of working out whether it is a directory or a file which just happens to go wrong when amazon declares the file is missing after it previously declared it was there.
I'm not sure about `--acd-templink-threshold` - I don't think it will help, but it doesn't hurt to try!  That looks really interesting.  I have a build pipeline set up, but it is low overhead to have circleci building stuff too so I'll merge this and we can have a play with it - thanks! Build status here: https://circleci.com/gh/ncw/rclone No I didn't do anything special  What problem are you trying to solve?  And on which OS? I'm guessing OS X...
https://beta.rclone.org/v1.36-122-gbe5b8b8d/ (in 15-30 mins)  It is always a possibility.  However I've had various email conversations with the amazon developers in the past and I don't think they would do that without a dialogue first. I was distressed to see on that thread a discussion of how to use rclone's keys to restore service.  Please don't do this - it will likely lead to rclone being banned in the same way. > Edit 2: Now that stuff on ACD is encrypted using rclone, I'm worried that we won't be able to retrieve and decrypt the backup. :(
Assuming that there existed another tool that could mount acd, then you could set it up so the above would work just fine. @Rufflewind wrote
export GOPATH=~/go
If your clock is badly out then the oauth protocol doesn't work very well.  I can't remember how long b2's initial grant is, but if it is 24hr then you won't notice until 24-5 hours time....
fi
``` @lickdragon wrote
@jaketame wrote
This confused a lot of people, so I apologise!
I'm going to merge this as-is and if we come up with a better test we can add it later!  Sorry for the confusion!  > I don't know if that intentional for reference that rclone could detect to find which is encrypted version.
The problems seem to be show by the `read tcp 100.96.1.15:60754->52.1.173.13:443: i/o timeout` errors.
@Dedsec1 any ideas?
I think this is mostly a duplicate of #675 - can you add your comments about LZ4 to that ticket and close this one?  What are those files called?  Do they have any funny unicode or other characters in them?
UBUNTU 16.04
plex@ZZeus:~/library/scripts$ sudo vi mount.sh
plex@ZZeus:~/library/scripts$ /bin/fusermount -uz /home/plex/library/.acd
plex@ZZeus:~/library/scripts$ /bin/fusermount -uz /home/plex/library/media
2017/04/18 22:34:23 INFO  : Encrypted amazon drive root 'ZZeus': Modify window not supported
2017/04/18 22:34:23 DEBUG : Encrypted amazon drive root 'ZZeus': Mounting on "/home/plex/library/.acd"
2017/04/18 22:34:23 DEBUG : Encrypted amazon drive root 'ZZeus': Root()
acd_cli
ARQ
You could rename the files on drive, or copy them to /tmp and rename them before copying them to /media/gdrive. @ErAzOr2k
Sounds great mate I have merged @azgul patch in - thank you :-)
Thanks @azgul  @felixbuenemann This probably merits its own issue.
Are you using your own credentials or rclones?
If you were using rclone sync/copy/move then that would be correct, but it isn't under rclone's control using rclone mount how many open files there are.  I think @yonjah is probably correct - try checking the actual internet usage with a different tool No probs!  I saw a few similar issues in regards to lookup failures and open files, but I don't think this is related back to a ulimit with the number of files open as I have a big number on my system:
felix@plex: ~$ ulimit -n
Distributor ID:	Debian
Codename:	jessie
ACD
rclone mount
pen for read: Get https://content-na.drive.amazonaws.com/cdproxy/templink/wkTScp5h8N9nTXDXPTky_-vJOZH-e2IYjWZB8hMV-bw38XJVg: dial tcp: looku
p content-na.drive.amazonaws.com on 192.168.86.1:53: no such host
pen for read: Get https://content-na.drive.amazonaws.com/cdproxy/templink/wkTScp5h8N9nTXDXPTky_-vJOZH-e2IYjWZB8hMV-bw38XJVg: dial tcp: looku
p content-na.drive.amazonaws.com on 192.168.86.1:53: no such host
Hmm. Odd. Had something similar this morning just before I woke up and saw this:
XS5Q3dWKADZKkTlrMz5gsJGXM38XJVg: dial tcp: lookup content-na.drive.amazonaws.com on 192.168.86.1:53: no such host
rclone  21578 felix  248u  sock                0,7      0t0  748129 can't identify protocol
rclone  21578 felix  249u  IPv4             757075      0t0     TCP 192.168.86.30:33842->ec2-52-45-43-200.compute-1.amazonaws.com:https (ESTABLISHED)
rclone  21578 felix  251u  sock                0,7      0t0  746813 can't identify protocol
rclone  21578 felix  252u  sock                0,7      0t0  745984 can't identify protocol
rclone  21578 felix  255u  IPv4             758000      0t0     TCP 192.168.86.30:45786->ec2-54-164-62-76.compute-1.amazonaws.com:https (ESTABLISHED)
rclone  21578 felix    1u  unix 0xffff88040c686080      0t0  590458 socket
rclone  21578 felix    2u  unix 0xffff88040c686080      0t0  590458 socket
rclone  21578 felix    5u  sock                0,7      0t0  661909 can't identify protocol
rclone  21578 felix    7u  sock                0,7      0t0  664757 can't identify protocol
rclone  21578 felix    8u  sock                0,7      0t0  660110 can't identify protocol
My rclone user is "felix"
That lsof-rclone.txt is puzzling - why all the "can't identify protocol" sockets? Maybe that is the fuse protocol...
rclone  6643 felix  cwd    DIR                8,1     4096       2 /
rclone  6643 felix    1u  unix 0xffff88040b4d7400      0t0   35183 socket
rclone  6643 felix    2u  unix 0xffff88040b4d7400      0t0   35183 socket
rclone  6643 felix    3u  unix 0xffff880037314bc0      0t0   34087 socket
rclone  6643 felix    4u  0000                0,9        0    7666 anon_inode
rclone  6643 felix    5u  sock                0,7      0t0   48411 can't identify protocol
rclone  6643 felix    7u  sock                0,7      0t0   42884 can't identify protocol
rclone  6643 felix    8u  sock                0,7      0t0   43626 can't identify protocol
rclone  6643 felix    9u  sock                0,7      0t0   42922 can't identify protocol
rclone  6643 felix   10u  sock                0,7      0t0   43995 can't identify protocol
rclone  6643 felix   11u  sock                0,7      0t0   44925 can't identify protocol
rclone  6643 felix   13u  sock                0,7      0t0   46753 can't identify protocol
rclone  6643 felix   14u  sock                0,7      0t0   49246 can't identify protocol
rclone  6643 felix   15u  sock                0,7      0t0   46004 can't identify protocol
rclone  6643 felix   16u  sock                0,7      0t0   46839 can't identify protocol
rclone  6643 felix   17u  sock                0,7      0t0   49261 can't identify protocol
rclone  6643 felix   18u  sock                0,7      0t0   49311 can't identify protocol
rclone  6643 felix   19u  sock                0,7      0t0   41954 can't identify protocol
rclone  6643 felix   20u  sock                0,7      0t0   46864 can't identify protocol
rclone  6643 felix   21u  sock                0,7      0t0   47537 can't identify protocol
rclone  6643 felix   22u  sock                0,7      0t0   45814 can't identify protocol
rclone  6643 felix   23u  sock                0,7      0t0   45840 can't identify protocol
rclone  6643 felix   24u  sock                0,7      0t0   41914 can't identify protocol
rclone  6643 felix   25u  sock                0,7      0t0   50234 can't identify protocol
rclone  6643 felix   26u  sock                0,7      0t0   45867 can't identify protocol
rclone  6643 felix   27u  sock                0,7      0t0   46927 can't identify protocol
rclone  6643 felix   28u  sock                0,7      0t0   48556 can't identify protocol
rclone  6643 felix   29u  sock                0,7      0t0   48359 can't identify protocol
rclone  6643 felix   30u  sock                0,7      0t0   48074 can't identify protocol
rclone  6643 felix   31u  sock                0,7      0t0   51362 can't identify protocol
rclone  6643 felix   32u  sock                0,7      0t0   47748 can't identify protocol
rclone  6643 felix   33u  sock                0,7      0t0   50660 can't identify protocol
rclone  6643 felix   34u  sock                0,7      0t0   49461 can't identify protocol
rclone  6643 felix   35u  sock                0,7      0t0   57855 can't identify protocol
rclone  6643 felix   36u  sock                0,7      0t0   52353 can't identify protocol
rclone  6643 felix   37u  sock                0,7      0t0   54336 can't identify protocol
rclone  6643 felix   38u  sock                0,7      0t0   48832 can't identify protocol
rclone  6643 felix   39u  sock                0,7      0t0   52657 can't identify protocol
rclone  6643 felix   40u  sock                0,7      0t0   48845 can't identify protocol
rclone  6643 felix   41u  sock                0,7      0t0   51583 can't identify protocol
rclone  6643 felix   42u  sock                0,7      0t0   55381 can't identify protocol
rclone  6643 felix   43u  sock                0,7      0t0   50805 can't identify protocol
rclone  6643 felix   44u  sock                0,7      0t0   50840 can't identify protocol
rclone  6643 felix   45u  sock                0,7      0t0   50028 can't identify protocol
rclone  6643 felix   46u  sock                0,7      0t0   55423 can't identify protocol
rclone  6643 felix   47u  sock                0,7      0t0   55680 can't identify protocol
rclone  6643 felix   48u  sock                0,7      0t0   54979 can't identify protocol
rclone  6643 felix   49u  sock                0,7      0t0   55026 can't identify protocol
rclone  6643 felix   50u  sock                0,7      0t0   51061 can't identify protocol
rclone  6643 felix   51u  sock                0,7      0t0   50018 can't identify protocol
rclone  6643 felix   52u  sock                0,7      0t0   55061 can't identify protocol
rclone  6643 felix   53u  sock                0,7      0t0   61722 can't identify protocol
rclone  6643 felix   54u  sock                0,7      0t0   55118 can't identify protocol
rclone  6643 felix   55u  sock                0,7      0t0   51816 can't identify protocol
rclone  6643 felix   56u  sock                0,7      0t0   57440 can't identify protocol
rclone  6643 felix   57u  sock                0,7      0t0   53007 can't identify protocol
rclone  6643 felix   58u  sock                0,7      0t0   63923 can't identify protocol
rclone  6643 felix   59u  sock                0,7      0t0   59423 can't identify protocol
rclone  6643 felix   60u  sock                0,7      0t0   62480 can't identify protocol
rclone  6643 felix   61u  sock                0,7      0t0   60859 can't identify protocol
rclone  6643 felix   62u  sock                0,7      0t0   61732 can't identify protocol
rclone  6643 felix   63u  sock                0,7      0t0   58310 can't identify protocol
rclone  6643 felix   64u  sock                0,7      0t0   64164 can't identify protocol
rclone  6643 felix   65u  sock                0,7      0t0   61810 can't identify protocol
rclone  6643 felix   66u  sock                0,7      0t0   59074 can't identify protocol
rclone  6643 felix   67u  sock                0,7      0t0   57134 can't identify protocol
rclone  6643 felix   68u  sock                0,7      0t0   58189 can't identify protocol
rclone  6643 felix   69u  sock                0,7      0t0   66739 can't identify protocol
rclone  6643 felix   70u  sock                0,7      0t0   73797 can't identify protocol
rclone  6643 felix   71u  sock                0,7      0t0   57237 can't identify protocol
rclone  6643 felix   72u  sock                0,7      0t0   61955 can't identify protocol
rclone  6643 felix   73u  sock                0,7      0t0   60359 can't identify protocol
rclone  6643 felix   74u  sock                0,7      0t0   63361 can't identify protocol
rclone  6643 felix   75u  sock                0,7      0t0   68013 can't identify protocol
rclone  6643 felix   76u  sock                0,7      0t0   66230 can't identify protocol
rclone  6643 felix   77u  sock                0,7      0t0   77866 can't identify protocol
rclone  6643 felix   78u  sock                0,7      0t0   74905 can't identify protocol
rclone  6643 felix   79u  sock                0,7      0t0   75939 can't identify protocol
rclone  6643 felix   80u  sock                0,7      0t0   71221 can't identify protocol
rclone  6643 felix   81u  sock                0,7      0t0   72089 can't identify protocol
rclone  6643 felix   82u  sock                0,7      0t0   84091 can't identify protocol
rclone  6643 felix   83u  sock                0,7      0t0   72225 can't identify protocol
rclone  6643 felix   84u  sock                0,7      0t0   76859 can't identify protocol
rclone  6643 felix   85u  sock                0,7      0t0   71444 can't identify protocol
rclone  6643 felix   86u  sock                0,7      0t0   76905 can't identify protocol
rclone  6643 felix   87u  sock                0,7      0t0   75983 can't identify protocol
rclone  6643 felix   88u  sock                0,7      0t0   73244 can't identify protocol
rclone  6643 felix   89u  sock                0,7      0t0   76114 can't identify protocol
rclone  6643 felix   90u  sock                0,7      0t0   80918 can't identify protocol
rclone  6643 felix   91u  sock                0,7      0t0   77881 can't identify protocol
rclone  6643 felix   92u  sock                0,7      0t0   76205 can't identify protocol
rclone  6643 felix   93u  sock                0,7      0t0   76238 can't identify protocol
rclone  6643 felix   94u  sock                0,7      0t0   73405 can't identify protocol
rclone  6643 felix   95u  sock                0,7      0t0   79935 can't identify protocol
rclone  6643 felix   96u  sock                0,7      0t0   77909 can't identify protocol
rclone  6643 felix   97u  sock                0,7      0t0   72621 can't identify protocol
rclone  6643 felix   98u  sock                0,7      0t0   77693 can't identify protocol
rclone  6643 felix   99u  sock                0,7      0t0   73679 can't identify protocol
rclone  6643 felix  100u  sock                0,7      0t0   77750 can't identify protocol
rclone  6643 felix  101u  sock                0,7      0t0   79951 can't identify protocol
rclone  6643 felix  102u  sock                0,7      0t0   80376 can't identify protocol
rclone  6643 felix  103u  sock                0,7      0t0   82414 can't identify protocol
rclone  6643 felix  104u  sock                0,7      0t0  102913 can't identify protocol
rclone  6643 felix  105u  sock                0,7      0t0   97606 can't identify protocol
rclone  6643 felix  106u  sock                0,7      0t0   78532 can't identify protocol
rclone  6643 felix  107u  sock                0,7      0t0   87804 can't identify protocol
rclone  6643 felix  108u  sock                0,7      0t0   88954 can't identify protocol
rclone  6643 felix  109u  sock                0,7      0t0   85988 can't identify protocol
rclone  6643 felix  110u  sock                0,7      0t0   93482 can't identify protocol
rclone  6643 felix  111u  sock                0,7      0t0   92942 can't identify protocol
rclone  6643 felix  112u  sock                0,7      0t0   94111 can't identify protocol
rclone  6643 felix  113u  sock                0,7      0t0   97818 can't identify protocol
rclone  6643 felix  114u  sock                0,7      0t0   98981 can't identify protocol
rclone  6643 felix  115u  sock                0,7      0t0   99000 can't identify protocol
rclone  6643 felix  116u  sock                0,7      0t0   96938 can't identify protocol
rclone  6643 felix  117u  sock                0,7      0t0   97960 can't identify protocol
rclone  6643 felix  118u  sock                0,7      0t0   99117 can't identify protocol
rclone  6643 felix  119u  sock                0,7      0t0   99744 can't identify protocol
rclone  6643 felix  120u  sock                0,7      0t0   97034 can't identify protocol
rclone  6643 felix  121u  sock                0,7      0t0   96113 can't identify protocol
rclone  6643 felix  122u  sock                0,7      0t0   99129 can't identify protocol
rclone  6643 felix  123u  sock                0,7      0t0   99175 can't identify protocol
rclone  6643 felix  124u  sock                0,7      0t0   98036 can't identify protocol
rclone  6643 felix  125u  sock                0,7      0t0   99215 can't identify protocol
rclone  6643 felix  126u  sock                0,7      0t0   98103 can't identify protocol
rclone  6643 felix  127u  sock                0,7      0t0  103530 can't identify protocol
rclone  6643 felix  128u  sock                0,7      0t0  100689 can't identify protocol
rclone  6643 felix  129u  sock                0,7      0t0  101539 can't identify protocol
rclone  6643 felix  130u  sock                0,7      0t0  101529 can't identify protocol
rclone  6643 felix  131u  sock                0,7      0t0  103430 can't identify protocol
rclone  6643 felix  132u  sock                0,7      0t0  103811 can't identify protocol
rclone  6643 felix  133u  sock                0,7      0t0  109942 can't identify protocol
rclone  6643 felix  134u  sock                0,7      0t0  106937 can't identify protocol
rclone  6643 felix  135u  sock                0,7      0t0  106947 can't identify protocol
rclone  6643 felix  136u  sock                0,7      0t0  103166 can't identify protocol
rclone  6643 felix  137u  sock                0,7      0t0  102146 can't identify protocol
rclone  6643 felix  138u  sock                0,7      0t0  105010 can't identify protocol
rclone  6643 felix  139u  sock                0,7      0t0  102302 can't identify protocol
rclone  6643 felix  140u  sock                0,7      0t0  108042 can't identify protocol
rclone  6643 felix  141u  sock                0,7      0t0  103213 can't identify protocol
rclone  6643 felix  142u  sock                0,7      0t0  107469 can't identify protocol
rclone  6643 felix  143u  sock                0,7      0t0  114803 can't identify protocol
rclone  6643 felix  144u  sock                0,7      0t0  108720 can't identify protocol
rclone  6643 felix  145u  sock                0,7      0t0  110746 can't identify protocol
rclone  6643 felix  146u  sock                0,7      0t0  106412 can't identify protocol
rclone  6643 felix  147u  sock                0,7      0t0  107877 can't identify protocol
rclone  6643 felix  148u  sock                0,7      0t0  110772 can't identify protocol
rclone  6643 felix  149u  sock                0,7      0t0  113760 can't identify protocol
rclone  6643 felix  150u  sock                0,7      0t0  110806 can't identify protocol
rclone  6643 felix  151u  sock                0,7      0t0  111837 can't identify protocol
rclone  6643 felix  152u  sock                0,7      0t0  113863 can't identify protocol
rclone  6643 felix  153u  sock                0,7      0t0  109956 can't identify protocol
rclone  6643 felix  154u  sock                0,7      0t0  109965 can't identify protocol
rclone  6643 felix  155u  sock                0,7      0t0  109981 can't identify protocol
rclone  6643 felix  156u  sock                0,7      0t0  113781 can't identify protocol
rclone  6643 felix  157u  sock                0,7      0t0  114037 can't identify protocol
rclone  6643 felix  158u  sock                0,7      0t0  108140 can't identify protocol
rclone  6643 felix  159u  sock                0,7      0t0  106455 can't identify protocol
rclone  6643 felix  160u  sock                0,7      0t0  112952 can't identify protocol
rclone  6643 felix  161u  sock                0,7      0t0  108413 can't identify protocol
rclone  6643 felix  162u  sock                0,7      0t0  110921 can't identify protocol
rclone  6643 felix  163u  sock                0,7      0t0  112179 can't identify protocol
rclone  6643 felix  164u  sock                0,7      0t0  110311 can't identify protocol
rclone  6643 felix  165u  sock                0,7      0t0  112440 can't identify protocol
rclone  6643 felix  166u  sock                0,7      0t0  113195 can't identify protocol
rclone  6643 felix  167u  sock                0,7      0t0  113446 can't identify protocol
rclone  6643 felix  168u  sock                0,7      0t0  115177 can't identify protocol
rclone  6643 felix  169u  sock                0,7      0t0  115234 can't identify protocol
rclone  6643 felix  170u  sock                0,7      0t0  115138 can't identify protocol
rclone  6643 felix  171u  sock                0,7      0t0  109301 can't identify protocol
rclone  6643 felix  172u  sock                0,7      0t0  114374 can't identify protocol
rclone  6643 felix  173u  sock                0,7      0t0  109367 can't identify protocol
rclone  6643 felix  174u  sock                0,7      0t0  118794 can't identify protocol
rclone  6643 felix  175u  sock                0,7      0t0  114445 can't identify protocol
rclone  6643 felix  176u  sock                0,7      0t0  118865 can't identify protocol
rclone  6643 felix  177u  sock                0,7      0t0  117970 can't identify protocol
rclone  6643 felix  178u  sock                0,7      0t0  111259 can't identify protocol
rclone  6643 felix  179u  sock                0,7      0t0  116315 can't identify protocol
rclone  6643 felix  180u  sock                0,7      0t0  118940 can't identify protocol
rclone  6643 felix  181u  sock                0,7      0t0  114494 can't identify protocol
rclone  6643 felix  182u  sock                0,7      0t0  118007 can't identify protocol
rclone  6643 felix  183u  sock                0,7      0t0  115334 can't identify protocol
rclone  6643 felix  184u  sock                0,7      0t0  117650 can't identify protocol
rclone  6643 felix  185u  sock                0,7      0t0  118218 can't identify protocol
rclone  6643 felix  186u  sock                0,7      0t0  111430 can't identify protocol
rclone  6643 felix  187u  sock                0,7      0t0  111459 can't identify protocol
rclone  6643 felix  188u  sock                0,7      0t0  115574 can't identify protocol
rclone  6643 felix  189u  sock                0,7      0t0  123977 can't identify protocol
rclone  6643 felix  190u  sock                0,7      0t0  122000 can't identify protocol
rclone  6643 felix  191u  sock                0,7      0t0  120027 can't identify protocol
rclone  6643 felix  192u  sock                0,7      0t0  125031 can't identify protocol
rclone  6643 felix  193u  sock                0,7      0t0  122118 can't identify protocol
rclone  6643 felix  194u  sock                0,7      0t0  124998 can't identify protocol
rclone  6643 felix  195u  sock                0,7      0t0  121260 can't identify protocol
rclone  6643 felix  196u  sock                0,7      0t0  125114 can't identify protocol
rclone  6643 felix  197u  sock                0,7      0t0  121361 can't identify protocol
rclone  6643 felix  198u  sock                0,7      0t0  121339 can't identify protocol
rclone  6643 felix  199u  sock                0,7      0t0  126223 can't identify protocol
rclone  6643 felix  200u  sock                0,7      0t0  121629 can't identify protocol
rclone  6643 felix  201u  sock                0,7      0t0  122612 can't identify protocol
rclone  6643 felix  202u  sock                0,7      0t0  121639 can't identify protocol
rclone  6643 felix  203u  sock                0,7      0t0  121560 can't identify protocol
rclone  6643 felix  204u  sock                0,7      0t0  122797 can't identify protocol
rclone  6643 felix  205u  sock                0,7      0t0  124847 can't identify protocol
rclone  6643 felix  206u  sock                0,7      0t0  123659 can't identify protocol
rclone  6643 felix  207u  sock                0,7      0t0  124797 can't identify protocol
rclone  6643 felix  208u  sock                0,7      0t0  124818 can't identify protocol
rclone  6643 felix  209u  sock                0,7      0t0  123639 can't identify protocol
rclone  6643 felix  210u  sock                0,7      0t0  123673 can't identify protocol
rclone  6643 felix  211u  sock                0,7      0t0  129180 can't identify protocol
rclone  6643 felix  212u  sock                0,7      0t0  120749 can't identify protocol
rclone  6643 felix  213u  sock                0,7      0t0  121769 can't identify protocol
rclone  6643 felix  214u  sock                0,7      0t0  123824 can't identify protocol
rclone  6643 felix  215u  sock                0,7      0t0  131131 can't identify protocol
rclone  6643 felix  216u  sock                0,7      0t0  133125 can't identify protocol
rclone  6643 felix  217u  sock                0,7      0t0  123856 can't identify protocol
rclone  6643 felix  218u  sock                0,7      0t0  127901 can't identify protocol
rclone  6643 felix  219u  sock                0,7      0t0  133152 can't identify protocol
rclone  6643 felix  220u  sock                0,7      0t0  132223 can't identify protocol
rclone  6643 felix  221u  sock                0,7      0t0  129416 can't identify protocol
rclone  6643 felix  222u  sock                0,7      0t0  133172 can't identify protocol
rclone  6643 felix  223u  sock                0,7      0t0  125790 can't identify protocol
rclone  6643 felix  224u  sock                0,7      0t0  129475 can't identify protocol
rclone  6643 felix  225u  sock                0,7      0t0  134254 can't identify protocol
rclone  6643 felix  226u  sock                0,7      0t0  132384 can't identify protocol
rclone  6643 felix  227u  sock                0,7      0t0  131277 can't identify protocol
rclone  6643 felix  228u  sock                0,7      0t0  125864 can't identify protocol
rclone  6643 felix  229u  sock                0,7      0t0  129688 can't identify protocol
rclone  6643 felix  230u  sock                0,7      0t0  128708 can't identify protocol
rclone  6643 felix  231u  sock                0,7      0t0  131441 can't identify protocol
rclone  6643 felix  232u  sock                0,7      0t0  134515 can't identify protocol
rclone  6643 felix  233u  sock                0,7      0t0  128776 can't identify protocol
rclone  6643 felix  234u  sock                0,7      0t0  130493 can't identify protocol
rclone  6643 felix  235u  sock                0,7      0t0  132760 can't identify protocol
rclone  6643 felix  236u  sock                0,7      0t0  129896 can't identify protocol
rclone  6643 felix  237u  sock                0,7      0t0  130519 can't identify protocol
rclone  6643 felix  238u  sock                0,7      0t0  128940 can't identify protocol
rclone  6643 felix  239u  sock                0,7      0t0  131585 can't identify protocol
rclone  6643 felix  240u  sock                0,7      0t0  132948 can't identify protocol
rclone  6643 felix  241u  sock                0,7      0t0  129957 can't identify protocol
rclone  6643 felix  242u  sock                0,7      0t0  136348 can't identify protocol
rclone  6643 felix  243u  sock                0,7      0t0  133536 can't identify protocol
rclone  6643 felix  244u  sock                0,7      0t0  134988 can't identify protocol
rclone  6643 felix  245u  sock                0,7      0t0  133070 can't identify protocol
rclone  6643 felix  246u  sock                0,7      0t0  131743 can't identify protocol
rclone  6643 felix  247u  sock                0,7      0t0  138275 can't identify protocol
rclone  6643 felix  248u  sock                0,7      0t0  136519 can't identify protocol
rclone  6643 felix  249u  sock                0,7      0t0  139340 can't identify protocol
rclone  6643 felix  250u  sock                0,7      0t0  131800 can't identify protocol
rclone  6643 felix  251u  sock                0,7      0t0  133719 can't identify protocol
rclone  6643 felix  252u  sock                0,7      0t0  138443 can't identify protocol
rclone  6643 felix  253u  sock                0,7      0t0  133734 can't identify protocol
rclone  6643 felix  254u  sock                0,7      0t0  137509 can't identify protocol
rclone  6643 felix  255u  sock                0,7      0t0  135669 can't identify protocol
rclone  6643 felix  256u  sock                0,7      0t0  136840 can't identify protocol
rclone  6643 felix  257u  sock                0,7      0t0  138552 can't identify protocol
rclone  6643 felix  258u  sock                0,7      0t0  130915 can't identify protocol
rclone  6643 felix  259u  sock                0,7      0t0  139534 can't identify protocol
rclone  6643 felix  260u  sock                0,7      0t0  133848 can't identify protocol
rclone  6643 felix  261u  sock                0,7      0t0  136897 can't identify protocol
rclone  6643 felix  262u  sock                0,7      0t0  139758 can't identify protocol
rclone  6643 felix  263u  sock                0,7      0t0  130967 can't identify protocol
rclone  6643 felix  264u  sock                0,7      0t0  140409 can't identify protocol
rclone  6643 felix  265u  sock                0,7      0t0  135798 can't identify protocol
rclone  6643 felix  266u  sock                0,7      0t0  134096 can't identify protocol
rclone  6643 felix  267u  sock                0,7      0t0  134110 can't identify protocol
rclone  6643 felix  268u  sock                0,7      0t0  140069 can't identify protocol
rclone  6643 felix  269u  sock                0,7      0t0  142458 can't identify protocol
rclone  6643 felix  270u  sock                0,7      0t0  142479 can't identify protocol
rclone  6643 felix  271u  sock                0,7      0t0  140120 can't identify protocol
rclone  6643 felix  272u  sock                0,7      0t0  140189 can't identify protocol
rclone  6643 felix  273u  sock                0,7      0t0  138154 can't identify protocol
rclone  6643 felix  274u  sock                0,7      0t0  140171 can't identify protocol
rclone  6643 felix  275u  sock                0,7      0t0  140250 can't identify protocol
rclone  6643 felix  276u  sock                0,7      0t0  142634 can't identify protocol
rclone  6643 felix  277u  sock                0,7      0t0  142644 can't identify protocol
rclone  6643 felix  278u  sock                0,7      0t0  141497 can't identify protocol
rclone  6643 felix  279u  sock                0,7      0t0  145410 can't identify protocol
rclone  6643 felix  280u  sock                0,7      0t0  145454 can't identify protocol
rclone  6643 felix  281u  sock                0,7      0t0  142835 can't identify protocol
rclone  6643 felix  282u  sock                0,7      0t0  141598 can't identify protocol
rclone  6643 felix  283u  sock                0,7      0t0  140633 can't identify protocol
rclone  6643 felix  284u  sock                0,7      0t0  141600 can't identify protocol
rclone  6643 felix  285u  sock                0,7      0t0  147509 can't identify protocol
rclone  6643 felix  286u  sock                0,7      0t0  140689 can't identify protocol
rclone  6643 felix  287u  sock                0,7      0t0  143612 can't identify protocol
rclone  6643 felix  288u  sock                0,7      0t0  143191 can't identify protocol
rclone  6643 felix  289u  sock                0,7      0t0  143106 can't identify protocol
rclone  6643 felix  290u  sock                0,7      0t0  143056 can't identify protocol
rclone  6643 felix  291u  sock                0,7      0t0  143076 can't identify protocol
rclone  6643 felix  292u  sock                0,7      0t0  141671 can't identify protocol
rclone  6643 felix  293u  sock                0,7      0t0  143714 can't identify protocol
rclone  6643 felix  294u  sock                0,7      0t0  146714 can't identify protocol
rclone  6643 felix  295u  sock                0,7      0t0  145758 can't identify protocol
rclone  6643 felix  296u  sock                0,7      0t0  144627 can't identify protocol
rclone  6643 felix  297u  sock                0,7      0t0  147730 can't identify protocol
rclone  6643 felix  298u  sock                0,7      0t0  146802 can't identify protocol
rclone  6643 felix  299u  sock                0,7      0t0  140768 can't identify protocol
rclone  6643 felix  300u  sock                0,7      0t0  148491 can't identify protocol
rclone  6643 felix  301u  sock                0,7      0t0  147864 can't identify protocol
rclone  6643 felix  302u  sock                0,7      0t0  147784 can't identify protocol
rclone  6643 felix  303u  sock                0,7      0t0  148575 can't identify protocol
rclone  6643 felix  304u  sock                0,7      0t0  146963 can't identify protocol
rclone  6643 felix  305u  sock                0,7      0t0  144954 can't identify protocol
rclone  6643 felix  306u  sock                0,7      0t0  140867 can't identify protocol
rclone  6643 felix  307u  sock                0,7      0t0  148527 can't identify protocol
rclone  6643 felix  308u  sock                0,7      0t0  146984 can't identify protocol
rclone  6643 felix  309u  sock                0,7      0t0  148601 can't identify protocol
rclone  6643 felix  310u  sock                0,7      0t0  148623 can't identify protocol
rclone  6643 felix  311u  sock                0,7      0t0  143855 can't identify protocol
rclone  6643 felix  312u  sock                0,7      0t0  145361 can't identify protocol
rclone  6643 felix  313u  sock                0,7      0t0  145292 can't identify protocol
rclone  6643 felix  314u  sock                0,7      0t0  149659 can't identify protocol
rclone  6643 felix  315u  sock                0,7      0t0  148088 can't identify protocol
rclone  6643 felix  316u  sock                0,7      0t0  149144 can't identify protocol
rclone  6643 felix  317u  sock                0,7      0t0  144328 can't identify protocol
rclone  6643 felix  318u  sock                0,7      0t0  151809 can't identify protocol
rclone  6643 felix  319u  sock                0,7      0t0  144340 can't identify protocol
rclone  6643 felix  320u  sock                0,7      0t0  141268 can't identify protocol
rclone  6643 felix  321u  sock                0,7      0t0  152688 can't identify protocol
rclone  6643 felix  322u  sock                0,7      0t0  150764 can't identify protocol
rclone  6643 felix  323u  sock                0,7      0t0  150852 can't identify protocol
rclone  6643 felix  324u  sock                0,7      0t0  149367 can't identify protocol
rclone  6643 felix  325u  sock                0,7      0t0  151958 can't identify protocol
rclone  6643 felix  326u  sock                0,7      0t0  150917 can't identify protocol
rclone  6643 felix  327u  sock                0,7      0t0  150931 can't identify protocol
rclone  6643 felix  328u  sock                0,7      0t0  151046 can't identify protocol
rclone  6643 felix  329u  sock                0,7      0t0  150962 can't identify protocol
rclone  6643 felix  330u  sock                0,7      0t0  150979 can't identify protocol
rclone  6643 felix  331u  sock                0,7      0t0  149947 can't identify protocol
rclone  6643 felix  332u  sock                0,7      0t0  151064 can't identify protocol
rclone  6643 felix  333u  sock                0,7      0t0  152322 can't identify protocol
rclone  6643 felix  334u  sock                0,7      0t0  153703 can't identify protocol
rclone  6643 felix  335u  sock                0,7      0t0  156696 can't identify protocol
rclone  6643 felix  336u  sock                0,7      0t0  153768 can't identify protocol
rclone  6643 felix  337u  sock                0,7      0t0  150161 can't identify protocol
rclone  6643 felix  338u  sock                0,7      0t0  152313 can't identify protocol
rclone  6643 felix  339u  sock                0,7      0t0  152346 can't identify protocol
rclone  6643 felix  340u  sock                0,7      0t0  153844 can't identify protocol
rclone  6643 felix  341u  sock                0,7      0t0  151393 can't identify protocol
rclone  6643 felix  342u  sock                0,7      0t0  157726 can't identify protocol
rclone  6643 felix  343u  sock                0,7      0t0  154056 can't identify protocol
rclone  6643 felix  344u  sock                0,7      0t0  157152 can't identify protocol
rclone  6643 felix  345u  sock                0,7      0t0  155234 can't identify protocol
rclone  6643 felix  346u  sock                0,7      0t0  159943 can't identify protocol
rclone  6643 felix  347u  sock                0,7      0t0  157193 can't identify protocol
rclone  6643 felix  348u  sock                0,7      0t0  159310 can't identify protocol
rclone  6643 felix  349u  sock                0,7      0t0  153469 can't identify protocol
rclone  6643 felix  350u  sock                0,7      0t0  159437 can't identify protocol
rclone  6643 felix  351u  sock                0,7      0t0  159505 can't identify protocol
rclone  6643 felix  352u  sock                0,7      0t0  160451 can't identify protocol
rclone  6643 felix  353u  sock                0,7      0t0  160912 can't identify protocol
rclone  6643 felix  354u  sock                0,7      0t0  160467 can't identify protocol
rclone  6643 felix  355u  sock                0,7      0t0  157308 can't identify protocol
rclone  6643 felix  356u  sock                0,7      0t0  160965 can't identify protocol
rclone  6643 felix  357u  sock                0,7      0t0  157329 can't identify protocol
rclone  6643 felix  358u  sock                0,7      0t0  160691 can't identify protocol
rclone  6643 felix  359u  sock                0,7      0t0  162933 can't identify protocol
rclone  6643 felix  360u  sock                0,7      0t0  162880 can't identify protocol
rclone  6643 felix  361u  sock                0,7      0t0  162942 can't identify protocol
rclone  6643 felix  362u  sock                0,7      0t0  157547 can't identify protocol
rclone  6643 felix  363u  sock                0,7      0t0  165238 can't identify protocol
rclone  6643 felix  364u  sock                0,7      0t0  161487 can't identify protocol
rclone  6643 felix  365u  sock                0,7      0t0  162119 can't identify protocol
rclone  6643 felix  366u  sock                0,7      0t0  162144 can't identify protocol
rclone  6643 felix  367u  sock                0,7      0t0  166212 can't identify protocol
rclone  6643 felix  368u  sock                0,7      0t0  166246 can't identify protocol
rclone  6643 felix  369u  sock                0,7      0t0  161781 can't identify protocol
rclone  6643 felix  372u  sock                0,7      0t0  167515 can't identify protocol
rclone  6643 felix  378u  IPv4             167875      0t0     TCP 192.168.86.30:42365->ec2-34-195-188-75.compute-1.amazonaws.com:https (ESTABLISHED)
rclone  6643 felix  379u  IPv4             163772      0t0     TCP 192.168.86.30:41956->ec2-52-72-159-114.compute-1.amazonaws.com:https (ESTABLISHED)
rclone  15592 felix  rtd       DIR                8,2     4096        2 /
rclone  15592 felix    3u     unix 0xffff9057c0383c00      0t0   437077 type=DGRAM
rclone  15592 felix    4u  a_inode               0,11        0    11590 [eventpoll]
I need to spend some time thinking about the corner cases!  This issue has come up before (can't find the issue though!).
-R, --relative
rsync -av /foo/bar/baz.c remote:/tmp/
rsync -avR /foo/bar/baz.c remote:/tmp/
then a file named /tmp/foo/bar/baz.c would  be  created  on  the
@dogear42 did you set up a password for ssh when you did the `rclone config` originally?  If so then it should have used that rather than an agent.
PR much appreciated!
It is annoyingly non standard!  It isn't either md5sum or an sha1sum or even an sha256sum  it is an sha256sum of 4 MB blocks, all concatenated then the sha256sum of those.
I haven't quite managed to replicate your exact problem, but there is clearly something weird going on!
Needs more investigation!
@yonjah - have you got time to look at this?
@yonjah excellent work finding the problem :-)
@yonjah that is surely related - well spotted! Sorry have been away - back now!  Will merge the PR soon and post a beta here for you all to try. Please find the beta with this fix in here
not sure if you meant to shut off the verbose output in 1.36 by any chance, seems when i run any command without -v i dont see anything when i try rclone sync, copy, move, just wanted to let you know incase you missed something before you pushed out 1.36
http://rclone.org/commands/rclone_check/  Drive supports md5sum - I'm not sure why we would want to store the checksum on a property given that?  @nagualcode open a new issue with a log with -vv please  I suspect there is something scanning the mount.
They are fab!  I think 6 is a very clever idea with the arrows round the cloud.
Caching the metadata is part of #897  @felixbuenemann is that in the v3 API?  I've only looked at the v2 API  You can use --crypt-show-mapping for this by listing all the files and grepping for the encrypted path - would that work for you? Neither would the forward...
Let's define some unicode character ranges
This will encode just about every unicode character and avoid the awkward ones and will have the property that it doesn't increase the UTF-8 encoding length which is probably important for size limits of file names.
A bit of experimentation might be needed!
> And I'm not sure how we'd handle filenames that have characters from multiple ranges (eg "A1\x0130\x0230") which would have potentially three different distance calculations.
I just ran the integration tests with the obfuscate name encryption and they passed which is a good sign!  You can pull this commit 87617bd2247f51af4a950094a180ca7af43bce75 into your branch if you want (or I'll do it later)
$ rclone lsl --max-depth 1 acd:
54 2017-03-13 11:51:05.755000000 gttofhvjcn6226aka4trpppv4k
$ rclone lsl --max-depth 1 acd:
If it isn't a separate app, then it should probably be a command `rclone webui` say.
// Remote returns the remote path
Either covert them all to --filter, eg
e) Edit existing remote
n) New remote
r) Rename remote
e/n/d/r/c/s/q> e
Value "client_secret" = "xxxxxxxxx"
Remote config
SSH_AUTH_SOCK=/tmp/ssh-Sj7JaoojWnEb/agent.3807
I wonder If I'm using an outdated way of getting the agent [see blog post](http://blog.ralch.com/tutorial/golang-ssh-connection/) Thanks for working that out.  There must be a special macOS way of doing this...
They would expect an ssh-agent to be running @kubark42
I wonder where that behaviour of launching ssh-agent comes from because it certainly isn't standard ssh behaviour on linux.  I launch my ssh-agent once and I have to type in a very long password - it would be might annoying to have to do that on every rclone invocation!
This is hte log from the mount itself
[sudo] password for robert:
2017/03/16 12:30:17 INFO  : AudioBooks/1989 - A Time to Kill/Chapter 07.mp3: Copied (new)
Errors:                 4
* AudioBooks/find her.mp3
* ...Books/1989 - A Time to Kill/Chapter 10.mp3: 29% done, 3.902 MBytes/s, ETA: 2s
Errors:                 4
* AudioBooks/find her.mp3
Errors:                 4
* AudioBooks/find her.mp3
Errors:                 4
Errors:                 4
Errors:                 4
Errors:                 4
Errors:                 4
Errors:                 9
* ...ason.2/Blindspot.S02E16.720p.hdtv.h264.mkv: 77% done, 2.499 MBytes/s, ETA: 1m16s
* ...tury.Women.(2016).720p.bluray.h264.aac.mp4: 79% done, 2.507 MBytes/s, ETA: 1m16s
Errors:                10
Errors:                10
I guess you could use ETags also...
Is your disk in some kind of special encoding?  Or are some of the unicode characters not normalised properly?  That might explain it... I've managed to replicate the problem with the help of your .bat file - thanks!  I'll post more when I've worked out what is going on and have a beta for you to try! Looks like this **is** a unicode normalisation problem.
There are two ways of fixing this
This is also going to be a serious issue for macOS which loves un-normalised unicode.
2017/03/07 16:48:07 ERROR : Attempt 1/1 failed with 0 errors and: error reading source directory "-r'áö": directory not found
2017/03/07 16:48:07 Failed to copy: error reading source directory "-r'áö": directory not found
C:\Users\Dev>dir t2\-r'áö ##### normalised unicode here
07/03/2017  15:50    <DIR>          -r?'a´o¨  ##### un-normalised unicode here
@breunigs - fancy taking a look? @ms-89 thanks for testing.  The rate limit exceeded unfortunately are a fact of life with drive uploads.  This will get fixed for uploads when they are cached on disk first which is planned in #711  When we get round to doing WebDav in #580 - this should make Owncloud work  Yes this is a good idea.  I think it is probably covered in #711 though.  You can use the new cryptcheck command in the latest beta for checking checksums on crypted filesystems.
some kind of checksum.
rclone cryptcheck remote:path encryptedremote:path
Nick > So it is proper (as far as go development) to have sub-packages/dependencies that live within an application refer to an effectively absolute rather than a relative location, so that they appear as though they are external to the application code even when they aren't? That seems so strange to me.
Go has a reputation for opinionated tooling and this is one of those areas.
```diff
Do you want me to merge this as a sort of special purpose remote?
> build failed for strange reasons in travis with go 1.8.
The results were mixed, including adding `./` in the remote names, and including the URLS with `&` in.
Nick Thanks for testing :-)  You probably want `--files-from` to make a list of exactly which files you want.  These don't need escaping. > But my wife says I can't find the peanut butter in the pantry a lot either.
a different way, having an incoming directory and move the things out
I wonder if google have changed their certificates somehow recently... @baro77 rclone uses the go TLS implementation which was written from scratch in go.
@baro77  I should probably re-open the go bug (or create a new issue) as it is definitely the same problem.
Let me know how it goes! It does seem very strange that it only happens some of the time.
Maybe someone is intermittently man-in-the-middling your connection?
I don't know why it should be intermittent though - that is strange!
Can you confirm the sizes are different?
Incorrect time could be a reason...
That is suspicious...  The oauth library will refresh tokens 10 seconds before they are due to be refreshed...
* 1 Syntax or usage error
mv rclone rclone-mipsle
mv rclone rclone-mips
Can you  @PiscisSwimeatus
The pauses are caused by some kind of network error, and rclone having to reconnect.  I'm not sure exactly why though, but it could be amazon, or it could be a local networking problem.  Have you checked your router has the latest firmware? Very strange!  Something happening at Amazon most likely.
Dedsec1 That looks great!
rclone lsl --crypt-show-mapping encryptedgdrive: 2>&1 | grep m8fnghbhatmesjafpqr4uf953f8q6va267jlau5s4cs16lgeb9bg
nf
The occasional `Failed to copy: upload failed: Failed to grab locks for 253673584: lock held by connection 21020332. ` is to be expected.
However it is a little tricy to implement
* crypt would need to implement another optional interface to crypt with a nonce and checksum a file @ajkis
some kind of checksum.
rclone cryptcheck remote:path encryptedremote:path
Correction: this is the beta http://beta.rclone.org/v1.35-92-g18c75a8/ (uploaded in 15-30 mins) @calisro strange!
The panic is new - I'd like to fix that.  Is it reproducable?
However at for most users it is unexpected and I'd like to fix it eventually!  Unfortunately the meaning of chunk size varies from remote to remote and there are lots of different constraints, so a general purpose implementation isn't possible.
Which remote are you interested in particularly?  Sorry this fell of my radar for a bit.
* We could also add MimeType in there too.
Path string // the remote
A bit of care is needed with the [JSON time format](http://stackoverflow.com/questions/10286204/the-right-json-date-format) - Go's [time.RFC3339Nano](https://golang.org/pkg/time/) should be the right format I think.
Foo, that is annoying and unexpected! I made an issue to fix it #1094
It is a bit racy though.
Nick_  I'll just note that the sftp support scheduled for release in 1.36 works really well with C14 (thanks for the test account!).  Something weird is going on there certainly!
2017/02/25 11:11:37 ERROR : Attempt 1/1 failed with 0 errors and: "somepath": is a not a regular file
2017/02/25 11:11:37 Failed to moveto: "somepath": is a not a regular file
rclone moveto dir newdir
It seems that ACD is just so unreliable. I may take to the forums to discuss reliable providers.
ACD does appear to have got less reliable over time.  Especially with big files....
If that doesn't work, you'll get more help in the forum.  Well done for tracking that down - that is a clearly nonsensical series of events.
means that you are uploading unencrypted files to acd doesn't it?
The sync failed because of this
The metadata bit might be complicated - there are restrictions, etc.  But the total length of the metadata supported would be a useful thing to know - and if that would fit an encrypted name+hash then that solves  a lot of the crypt problems.  What does rclone do with them at the moment?  (try with the -v flag).
Something like that! @Wundark
I would encode each line at a time, so at the start print a `[` then encode each line then print a `]` at the end. @mh-cbon interesting idea.  That is a whole new level of JSON-ness - I've interpreted this issue as being about just having a version of ls which outputs JSON I've implemented a new command lsjson in this beta - let me know what you think.
How did you get the encrypted files up to amazon in the first place?
Or you can set an environment variable with the password in - see the docs for more info.   This error leads me to think your fuse installation might be broken.  Can you try updating it?  Maybe try a new kernel?
``` @Massaguana if you want to test fuse you could try sshfs which your distro probably has a package for.
Interesting info!
rclone mount foo bar
This maybe could be useful to people who use plex, emby, or direct play from the mount
when you play media from acd, the initial connection (30segs) never goes above 20-22mbps (I have 300/300), in the first 30 segs, so I always have a freeze at init of playing. So, the initial buffer I mention is to start play while the rest of the buffer is loading (if the flag could be customizable, you could put it as you like avoiding freezes)
Thanks ncw 117 release tested a bit. For the moment direct play (from samsung tv-> plex<-acd) is freezing after a 10 seconds from play, and not restarting (plex), I don't know if buffer is working because sometimes it's not playing anything after a minute (keeps loading but not playing anything).
More problems playing with r117 than r98 (not in the first try, but yes on the rest)
I think one of the problems with testing with ACD is that it is very variable in performance.  Sometimes it doesn't even deliver enough bandwidth for streaming so if you could repeat each test as many times as possible that would be useful.
I'm not sure how to fix this though!  Any ideas? @gustavorochakv you are right!
> Is --drive-chunk-size supposed to work for ACD as well?
> If not, shouldn't there be an --acd-chunk-size parameter?
Nice idea.  This could be done as part of #637 What if there was an upgrade path from standard encryption to enhanced encryption - would that satisfy you? (One that didn't involve downloading and uploading!)  I'm sorry, I thought I replied to this, but I must have forgotten to press submit or something :-(
On my ubuntu laptop I have lots of XDG vars but not XDG_CONFIG_HOME, but I do have a .config with lots of stuff in it.
XDG_VTNR=7
I think checking the modification time as a last resort would be surprising for the user.
It would be interesting to know if there are things you'd like rclone to do to make your life easier.  This relies on there being a stable FUSE for windows.  There have been movements in that direction but I don't think we are there yet.  It also would require working from go which makes things a little trickier. @billziss-gh - WinFsp is a very impressive project.  I read about your difficulties with undocumented APIs and debugging - quite a challenge!
@billziss-gh wrote:
>  Feel free to make any suggestions for improvement. In particular I am wondering if the way I am mapping C pointers to Go interfaces and back (in [handle.go](https://github.com/billziss-gh/cgofuse/blob/master/fuse/handle.go)) is the best way of doing things.
> Still if this is the way it has to be done in order to play in the Go ecosystem that's fine.
I felt the same way when starting go.  Go is very opinionated about some things and this is one of them, so it is best to do it the Go way otherwise you'll be fighting a losing battle!  Yes if you move your source code repo you need to change the code :-(  There are ways of making a vanity url you can use, but it turns out not to be much of a problem in practice.
Also note that `go vet` does some checking of `unsafe.Pointer` use.
PS This project https://github.com/karalabe/xgo looks like an excellent way of doing a cross compile build for Windows... @billziss-gh thanks for your hackpatch!
```bat
set GOPATH=X:\go
@vampywiz17 wrote
Changes are
@vampywiz17 wrote
> As vampywiz said, --read-only does not work.
I haven't fixed that yet, but I've received a steer from @billziss-gh  as to the best way
@billziss-gh wrote
[rclone-v1.36-89-g6352557e-cmount-rebase.zip](https://github.com/ncw/rclone/files/995583/rclone-v1.36-89-g6352557e-cmount-rebase.zip)
@vampywiz17 excellent!
The error is this from the log
2017/05/12 11:33:56 ERROR : /Sorozatok/Új szöveges dokumentum.txt: Can't open for Read and
That is the 64bit version.  I haven't tried it at all (don't have a 64bit VM) so I wouldn't be suprised if it doesn't work.  What did it do? @vampywiz17 thanks!
set GOARCH=amd64
set GOBIN=
set GOHOSTARCH=386
set GOHOSTOS=windows
set GOPATH=X:\go
set GORACE=
set GOROOT=C:\Go
set CGO_CPPFLAGS=
If we were to squeeze the WinFsp development parts into the form [as described in the xgo docs](https://github.com/karalabe/xgo#cgo-dependencies) that would fix the cross compile issues.  It would presumably be quite easy to make a configure which did nothing and a make install which copied the header files into the right place.
@billziss-gh wrote
karalabe/xgo-latest           latest              0532a33f402b        4 weeks ago         4.322 GB
* Use xgo on Travis
@billziss-gh wrote
[rclone-v1.35-23-ga7d8ccd-osx-go-tip.zip](https://github.com/ncw/rclone/files/698394/rclone-v1.35-23-ga7d8ccd-osx-go-tip.zip)
Are there other crypto accelerators built in to your board other than the ARMv8 AES instructions which I believe are a standard part of ARMv8?
find /Users/gryphon/Encrypted -size +1G
Can you perform a test for me?  I'd like you to see if you can download the encrypted version of a file, then try to decrypt it locally.
This will print a messagae like this
Other questions
* what does rclone check say?
Yes that is the first thing we need to do - work out where the corruption is happening.
If you could `rclone cat egd:REDACTED/REDACTED/REDACTED/REDACTED.mp4 > tmp.mp4` or `rclone cat elo:REDACTED.mp4 > tmp.mp4` if you prefer and see how big the resulting output is that would be very useful.
This corresponds to a block at offset 32+N*(65536+16).  It would be interesting to see what the data in the encrypted version of the file for the next 64k looks like.  If it doesn't look like random data then there will be a clue there.
rclone -q cat elo:REDACTED.mp4 | wc -c
@DurvalMenezes were you doing a network copy when you uploaded the files to drive?
Provided @DurvalMenezes says the corruptions were seen after a transfer from network -> crypted gdrive, I'm pretty sure this was caused by #902
rclone cat --tail 1 --stats 1m --discard encryptedRemote:
Reading the last byte of a crypted file isn't as trivial as it sounds!  First it has to read the header and starting nonce, then calculate the nonce of the last block, read the last block (up to 64k), decrypt and only then output the last byte of the decrypted block.
@naeloob
The lines like `* REDACTED/REDACTED/REDACTED/REDACTED.jpg` are caused by `--stats 1m` - it is just what it is doing at the moment.  Remove `--stats 1m` if you don't want to see them.
2017/02/08 09:11:14 REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/REDACTED.log: Failed to open: unexpected EOF
./rclone cat --tail 1 --stats 1m --discard RemoteCrypt:REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/REDACTED.log
That would explain the sizes differ errors.
That explains the UnexpectedEOF error.
@naeloob
I don't know why they are giving Unexpected EOF errors though - I was expecting "failed to autheticate decypted block" errors. @jrarseneau try copying a few files down if you can.  If not then these files are corrupted and you'll need to re-upload them :-( You can use --files-from with a list of the files and then `rclone delete --files-from file_list remote:`
I'm pretty sure it was #902 though.  I'll need to think through where the UnexpectedEOF comes in though.
I think what you are asking for is #1102 @DurvalMenezes
Gah, a stupid mistake....
How did you transfer your new backup directory?  I'm guessing it is an encrypted google drive and the contents was transferred from another encrypted non-local place (eg ACD, not the local disk)
Yes that is right. @Durval yes those all look like network or overload errors. Reducing the number of checkers will help I would have thought.  @DurvalMenezes That looks like some sort of ban if it is failing on everything.  It is a shame the error message isn't a bit more specific as to what kind of 403 error you got. @DurvalMenezes don't know - ask on the forum? I've implemented rclone cryptcheck (see #1102) in this beta which gives an alternative way of checking that a crypt remote is intact.
some kind of checksum.
rclone cryptcheck remote:path encryptedremote:path
Both remotes are crypted.
I'm not clear on exactly what happened though
That is a network error, so --acd-upload-wait-per-gb probably won't help here.
Will investigate some more tomorrow - past my bed time now, so probably none of the above makes any sense ;-) Firstly I'd like to say thank you for your contribution.
The work-around above will fix the problem. @naeloob
The philosophies of rclone are
You'll notice that encryption crossed the first of those lines, hence my thinking to stuff it into #637 where we're already in unique tool territory.
I think it is a very interesting idea to split out the "extra metadata" bit of #637. Thought that has some special requirements such as needing to map file names to UUIDs (or something like that).
The file name is a pain point that this could solve.  All the remotes have different file name length requirements special characters, case sensitivity etc...  Which is related to the crypt requirement to obscure the file names.
> ca2******a0116 bucket [28/Dec/2016:06:29:16 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 5104483EDC6FF5AD REST.GET.BUCKET - "GET /bucket?delimiter=&marker=43055%2F55aba977cc05c_14-9-1-1.mp4.jpg&max-keys=1024&prefix= HTTP/1.1" 200 - 345385 - 120 119 "-" "rclone/v1.33" -
> ca2******a0116 bucket [28/Dec/2016:06:29:17 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 86D269EED8315CD2 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=4430%2F5521c01a214cf.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 345574 - 97 96 "-" "rclone/v1.33" -
it doesn't properly merge, and I happen to be home sick today, so if you
Nice idea.  I'm not 100% sure what is going on from that log.
Super.
cobra FTW ;-) > One question. I noticed this when I renamed a folder with lots of files the other day. In my head this will trigger a massive amounts of renames when we should probably be able to just rename the folder. Or maybe that's just possible for local fs?
Possibly, though there are rather a lot of corner cases involved!
// this should probably have a log too
So it doesn't look like to me that that could ever work with encfs...
rclone mkdir gdenc:/test
As the values we need to store
* sha1sum
Potential issues
However
$ rclone lsl acd:test
Is that all the strace program printed? Looks very suspicious that it has livelocked...  I'm pretty sure this is the same issue as #902
http://beta.rclone.org/v1.35-41-g2abfae2/ (uploaded in 15-30 mins)
panic(0x5fe1a0, 0xc420010080)
I'm guessing something to do with moves - in which case try
Use `rclone copy /mnt/local-data/ acd_e:` would be a better solution I think. I would script the `rclone copy` but only do the `rclone sync` you originally suggested by hand after running it with `--dry-run` first.  Run with -v and --dump-bodies and post the results. You might need to edit sensitive data out before posting.
What would rclone need to do to support this? Set a life cycle policy? @hashbackup thanks for the writeup - very interesting.
http://beta.rclone.org/v1.35-41-g2abfae2/ (uploaded in 15-30 mins)
What is the error that samba returns?
acd:           1000000000     0 1000000000    0% /mnt/tmp
If you want to spend a bit of time studying go then [the go tour](https://tour.golang.org) is an excellent place to start.
@bep that would be great!
The actual moves you want to do with the `Move` function.  This will fall back to download/upload if the remote doesn't implement `Move` or `Copy` which isn't ideal so if the remote doesn't support `Move` or `Copy` you probably want to ignore the `--track-rename` flag completely. @bep let me know if you need any more pointers. Nick  Please find a beta with this in here: http://beta.rclone.org/v1.35-07-gf1221b5/ (uploaded in 15-30 mins) @Techrocket9 yes this made it into the release.  Unfortunately crypt doesn't support hashes :-( @olanmatt yes that is correct, `--track-renames` doesn't work with encrypted remotes :-(  @davidjgraph what happens if you use `rclone config` with the drive option with a team drive? Does that work now? Does anyone want to work on this?
How do you think this should be used from within rclone?
I'm not 100% sure the syncing is working properly, In my tests it uploaded my test folder, then immediately wanted to upload some more files.  Possibly related to #1431 I got this error when I was configuring it:
Got code
Seems to be working.  I copied a folder to test things out.  and one error was odd.  Over and over it tried to copy 0B_raumxsbgcgYk9oOGhSSmZjcjg which I have no idea what that actually is.....
Errors:                 1
I'm having a lot of failures though with that repeated message.  Pretty wierd:
Errors:                23
Errors:                23
@gfrewqpoiu wrote
Just some more info which i noticed and seems odd
Pragma: no-cache
Vary: User-Agent
Content-Type: multipart/form-data; boundary=231ee268c16bb03cde80501ecc73f18e585163d95af8e8a48c3ae0a38b4b
Accept-Encoding: gzip
Nice explanation @breunigs
The `Put` method in go-acd was written by me and it seems very complicated - perhaps there is a better way...
http://pub.rclone.org/rclone-v1.34-13-gd8b7156-race.zip
I haven't got to the bottom of this yet.
What version of Go are you using?  You'll need 1.5 or later to compile rclone.  The error message should say that though. @nummersyv I had a look at your log.  It appeared to contain several seeks and no errors, so I don't think the problem is rclone seeking.  Maybe it is the video player not liking the delay on seek.  Did you try seeking then waiting for a while to see if the player would sync?
potato
I'm sorry that was an unexpected consequence of ignoring Junction points.  I didn't think rclone could read  junction points at all, but I'm obviously wrong about that.
What behaviour do you think rclone should have with Junction points?
I suspect you are using crypt where the file names can become too long to fit in amazon's limits.
renice 19 $$
ionice -c 3 -p $$
rclone ....
:-(  I have had lots of horrible things go wrong with NFS in the past so I can't say I trust it any more!
Yes I agree with you about the engineer who came up with `Icon\r` files!
Thanks for letting me know that you can store `\r` on ACD - that is a surprise!
So does using `rclone ls acde:` work ok?
@zordiack is there an old mount running somewhere? `mount | grep rclone` will show you, you can then use `fusermount -z -u` to unmount it.  If that fails reboot.
I note also that you've used two different remotes `ACDE:` and `acdenc:` in your tests.
rclone -q ls --max-depth 1 ACDE:
For your final test you seem to be using `rclone lsl acdenc:` which is a different remote.
This would be useful for crypt mounts in particular and for `rclone md5sum` and `rclone sha1sum`
> @ncw I see two options here:
I'd like to get the tests working if we can.  The ACD tests are the least reliable tests though!
* mipsle - http://pub.rclone.org/rclone-v1.34-49-ge79a5de-mipsle.zip
rclone definitely uses floating point maths for the stats calculations BTW.
Do I need to build both mips and mipsle builds?  Are they both in use? @alecuba16 thanks for the link! Now that go 1.8 has been released I've integrated linux/mips and linux/mipsle into the release.  Please find them in this beta.  This will be in the 1.36 release.
2016/11/01 11:07:48 Mobile Applications/AIR RACE 1.74 1.ipa: Cancelling multipart upload
2016/11/01 11:07:48 Mobile Applications/AIR RACE 1.74 1.ipa: Failed to copy: Put https://api.onedrive.com/up/eyJSZXNvdXJjZUlEIjoiNzlGNDY1NEQxQkE0MDc1MyE0MzM2OSIsIlJlbGF0aW9uc2hpcE5hbWUiOiJBSVIgUkFDRSAxLjc0IDEuaXBhIn0/3mH_bu4oxlLxXb9HHmyTv_gpPPfgNWBMQnWRN83pBuVJrqGrZPMv9hdLyyIp8N0Wbl/eyJOYW1lIjoiQUlSIFJBQ0UgMS43NCAxLmlwYSJ9/3wYBV0iMr46yENesCJ0xvNTVpK2CQAtivBMe_RuO6iU24CkO4DJRfbBiH3T1YFKC1XJ1pKDKKpjKWLDv15JlJpnBJAnvaxH-DhJQhQIO_belAAzkDg_k50zPnDYPW0uUu5RM24Z1qthsIRZYbp_AxGF5KW_cZdClPA8Jdsetfc4n9ex7krcxpFoseIbCMyTXnW5FFTd9/0M7UuLA_4xLSy6s5h8_d3dvtuISUlDTd667JBIFMlES0C5gpm0JKT2fWGRRqyKd1hBVHx5B2XVGuimAYQukJaFQ1Fy3hMGF3wlXJ4BCWnBYgrZTrRvStQkewadl1ksSPSWyCuNBJY-Dj9sSsn327JA-m5_IesAzE7v7dthwrrrUUC-jnp983rE0L0D2BBxiZiR-HWgmQ/ti3UGU2vktTY_89tA2cautyH-jcwFCMpO3y1E5OqFCcMsHRFbPfWeUsTwBrY34YRPq3EKn0A: http: ContentLength=10485760 with Body length 0
2016/11/04 09:18:59 Music/Les Enfoirés/La Boîte À Musique Des Enfoirés/2-01 La Mode_ Le Sens De La Vie _ Call Me Maybe _ C'est Beau La Bourgeoisie _ Ai Se Eu Te Pego _ Et Alors _ Gangnam Style _ À La Pêche Aux Moules (Chanson Enfantine).mp3: Failed to copy: invalidRequest: Bad Argument
> /Users/fbastok/Downloads/rclone-v1.34-osx-amd64/rclone -v --dump-headers sync "/Users/Shared/iTunes Media" onedrive-backup:Backup/iTunesMedia 2>Desktop/rclone_errors.txt >Desktop/rclone_verbose.txt
@fbastok I looked rclone_errors.txt and I see this eror
2016/11/10 07:55:30 Music/Les Enfoirés/La Boîte À Musique Des Enfoirés/2-01 La Mode_ Le Sens De La Vie _ Call Me Maybe _ C'est Beau La Bourgeoisie _ Ai Se Eu Te Pego _ Et Alors _ Gangnam Style _ À La Pêche Aux Moules (Chanson Enfantine).mp3: Failed to copy: invalidRequest: Bad Argument
2016/11/10 07:55:30 Music/Les Enfoirés/La Boîte À Musique Des Enfoirés/
/Users/Shared/iTunes Media/Music/Les Enfoirés/La Boite À Musique Des Enfoirés/2-01 La Mode_ Le Sens De La Vie _ Call Me Maybe _ C'est Beau La Bourgeoisie _ Ai Se Eu Te Pego _ Et Alors _ Gangnam Style _ À La Pêche Aux Moules (Chanson Enfantine).mp3
/Users/fbastok/Downloads/rclone-v1.34-osx-amd64/rclone -v --ignore-size --dump-headers sync "/Users/Shared/iTunes Media" onedrive-backup:Backup/iTunesMedia 2>Desktop/rclone_errors.txt >Desktop/rclone_verbose.txt
Some errors:
> - ...Enfoirés/18 Tableau _Le Train Fantôme_.mp3: 57% done. avg:   73.7, cur: 1164.3 kByte/s. ETA: 12s
> - ...és/20 Tableau _Une Etrange Expo Photo_.mp3: 35% done. avg:   40.3, cur: 4023.4 kByte/s. ETA: 4s
> 2016/11/20 09:39:25 Music/Les Enfoirés/La Boite À Musique Des Enfoirés/2-01 La Mode_ Le Sens De La Vie _ Call Me Maybe _ C'est Beau La Bourgeoisie _ Ai Se Eu Te Pego _ Et Alors _ Gangnam Style _ À La Pêche Aux Moules (Chanson Enfantine).mp3: Failed to copy: invalidRequest: Bad Argument
> Errors:                 5
the next 5 movies I tried to upload didn't work. The same error as above I replicated the same behavior in Linux (linux mint 18). Same errors. @yonjah you've been looking at onedrive stuff recently - what do you think of this?  I've merged this in 1c912de9cc058515468bfaa9bbca6b6b4325efd9 - thank you very much for working that out :-)
@wikt0r I don't know.  I've had reports from other people that they are having trouble uploading big files - it might just be growing pains for ACD.  The individual file transfer stats show the transfer rate of the individual files averages over a short period.
I've rebased and merged this into the `acd-move` branch - thanks :-)
I suspect this is (at least partly) #I suspect this is (at least partly) #824 - fuse mounted acd can't write at the moment
> Is that intended? Seems quite odd.
@toomuchio thanks for your PR - I'm a bit behind with rclone stuff, but I'll get to it soon!
It will be when I do the high security name encryption mode.
@Coornail
@Coornail thanks for the log - I have spent some time studying that but haven't come to a conclusion yet.
http://pub.rclone.org/rclone-v1.33-85-g6846a1c-linux-amd64-race.gz
Thanks for your help and hopefully we'll get to the bottom of this shortly!
Host: content-na.drive.amazonaws.com
Etag: "3aa5a31aeeca48405be931b18aa754dd-69"
crypt: Fix data corruption caused by seeking
The corruption was caused when the file was read to the end thus
pool thus causing corruption when other goroutines claimed the buffers
http://pub.rclone.org/v1.33-92-g4bcea27-seek-race-fix%CE%B2/
$ ./LookupIP content-na.drive.amazonaws.com
"content-na.drive.amazonaws.com": 54.88.149.237
"content-na.drive.amazonaws.com": 54.85.147.124
"content-na.drive.amazonaws.com": 54.87.96.13
"content-na.drive.amazonaws.com": 54.84.119.41
"content-na.drive.amazonaws.com": 54.210.228.88
"content-na.drive.amazonaws.com": 54.210.230.197
"content-na.drive.amazonaws.com": 54.210.230.84
"content-na.drive.amazonaws.com": 54.84.77.98
$ ./LookupIP content-na.drive.amazonaws.com
"content-na.drive.amazonaws.com": 54.85.147.124
"content-na.drive.amazonaws.com": 54.87.96.13
"content-na.drive.amazonaws.com": 54.84.119.41
"content-na.drive.amazonaws.com": 54.210.228.88
"content-na.drive.amazonaws.com": 54.210.230.197
"content-na.drive.amazonaws.com": 54.210.230.84
"content-na.drive.amazonaws.com": 54.84.77.98
"content-na.drive.amazonaws.com": 54.88.149.237
$ ./LookupIP content-na.drive.amazonaws.com
"content-na.drive.amazonaws.com": 54.87.96.13
"content-na.drive.amazonaws.com": 54.84.119.41
"content-na.drive.amazonaws.com": 54.210.228.88
"content-na.drive.amazonaws.com": 54.210.230.197
"content-na.drive.amazonaws.com": 54.210.230.84
"content-na.drive.amazonaws.com": 54.84.77.98
"content-na.drive.amazonaws.com": 54.88.149.237
"content-na.drive.amazonaws.com": 54.85.147.124
$ ./dial content-na.drive.amazonaws.com:443
"content-na.drive.amazonaws.com:443": 52.73.248.252:443: <nil>
"content-na.drive.amazonaws.com:443": 52.72.145.30:443: <nil>
"content-na.drive.amazonaws.com:443": 52.73.155.106:443: <nil>
"content-na.drive.amazonaws.com:443": 52.72.168.2:443: <nil>
- play with the uploading code for acd / b2 to see if it can work without knowing the length in advance - probably won't work
@breunigs just wondering when you said
@toomuchio excellent news - thanks for testing
I could see this translating into flags for rclone
@AzureBlaze @qinwf I keep meaning to do that, so I've made an issue about it #850 - please click the subscribe button to be notified of changes there!
I have sped up the seeking for crypt+fuse which you can try here: http://beta.rclone.org/v1.33-79-g77b975d/ which might help.
However what would you think about implementing #221 instead which would vary bwlimit by time of day?  that would fix the problem for most people and be cross platform portable? Would that satisfy your use case?
@DurvalMenezes
In [this thread on the forum](https://forum.rclone.org/t/mounting-acd-with-decryption-for-reading/64/11) Buba_metola posted a recipe for using rclone mount with systemd.
6 complex character £100.txt
2016/10/19 22:55:29 complex character £100.txt: Failed to copy: NoSuchKey:
2016/10/19 22:56:40 PUT /utf8-test2/complex%20character%20%C2%A3100.txt HTTP/1.1
X-Amz-Copy-Source: utf8-test%2Fcomplex+character+%C2%A3100.txt
X-Amz-Metadata-Directive: COPY
Accept-Encoding: gzip
X-Amz-Request-Id: tx000000000000003b51cb0-005807ec18-10b45ddf-default
2016/10/19 23:03:01 PUT http://s3.amazonaws.com/utf8-test2/complex%20character%20%C2%A3100.txt HTTP/1.1
X-Amz-Content-Sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
X-Amz-Copy-Source: utf8-test%2Fcomplex+character+%C2%A3100.txt
X-Amz-Date: 20161019T220301Z
X-Amz-Metadata-Directive: COPY
Accept-Encoding: gzip
X-Amz-Id-2: SAkNeGyzpGulA++DE6QqVHAaHqzn2tpwVyjqBa2rL/jO3ZigeG3jGihiLLkEXQ816g0MVYIjwqc=
X-Amz-Request-Id: 0D8ECC97657B88F4
> x-amz-copy-source
> Type: String
I've put it on the list for 1.37 @chmercesmoreira nice idea, but not straight forward to implement as it is two different instance of rclone running so one would have to find the other which is non-trivial... @breunigs it seems to me the best approach might be to send a PR to bazil/fuse/fs with the extra functionality rclone needs.  Perhaps a flush this path method and return nodes flushed? How can I test this?  Is there a small doc/comment on how to use it?  I'm happy to test it.
@jkaberg useful log thanks. I see you are using seeks which lead me into finding a data corruption problem with crypt+seek which I've now fixed.  Have a go with http://beta.rclone.org/v1.33-81-g9d2dd2c/ (will be uploaded in 15-30 minutes) and tell me if that makes a difference.
(10GB is the templink threshold which means these files are being fetched a different way - maybe that way doesn't support Range requests or something like that.  I can't test myself as my Internet connection has gone to pieces :-( )
@calisro would probably be a good idea to confirm that the bactrace you see from `rclone mount` is the same as the on in that ticket.
There have been several problems with OS X and non ascii characters in the past - OS X stores its files in a very strange encoding on disk!
or is it just the warning message which is wrong?
@ebridges the Check function returns an error either if something went wrong, or a difference was found.  The final nil is if everything was OK and no differences were found.
@ebridges the point of the `rclone check` command is to ask the question - are all my files uploaded correctly.  The unix convention in this case is to return an error if everything isn't OK.  This means you can script `rclone check` command and do something if there is something wrong.  For instance the unix `grep` command works in a similar way - if it finds something it doesn't return and error, but if it doesn't is does return an error even though the grep command ran correctly.
Do you agree - what if you try a really small `--bwlimit` do you get the same speed?
Can you copy the files to a local directory without the error message?  And how about from the local directory to minio?
Is there a problem with that bucket do you think?  Or a problem with rclone?
Not works - Failed to create file system for "secret:/TEST": didn't find section in config file
n) New remote
Which looks like it might be a different bug - do you see that?
What have you got in your crypt config? It looks like it is somehow pointed at itself?
When using crypt you have one remote say acd: which you point at unencrypted acd, then you make a second crypt remote called encryptedacd: with the remote parameter 'acd:secret'.
Good suggestion to put a check in as I'm planning to make more overlays like crypt.
acdConfig = &oauth2.Config{
Endpoint: oauth2.Endpoint{
400 Bad Request
client_id=amzn1.application-oa2-client.6bf18d2d1f5b485c94c8988bb03ad0e7
response_type=code
I'm not sure what is going on here!
Observations suggest it is most likely it is something to do with the crypt code and seeking but I haven't figured it out yet!
I only figured out what was going on by playing videos from ACD with vlc - so thank you all for your tips.
PS what does git-annex-remote-rclone do?  I'm not familiar with git-annex.
- working out how to cache the remotes is tricky because of the path after the remote
PS thanks for pointing out `iftop` to me - not seen that tool before!
Wow,  that is a lot slower!
I messed up the build - here is the new beta: http://beta.rclone.org/v1.33-52-gaedad89/
:-( I'll try to find out what is going on...
This is to do with the revamp of the timeout code in 0cb9bb3b54397ff2dd7a563194d1ec98ca9cedaa
That looks like a different problem!
@felixbuenemann thanks for testing
@scriptzteam I'm not sure I understand what you mean - move will delete the files but won't delete the empty directories until #100 is fixed.
What are you trying to connect to?  Have you tried using `-v` and `--dump-bodies` to debug what is going on?
Received error: failed to make directory: HTTP code 400: "400 Bad Request", reponse body: {"message":"1 validation error detected: Value 'BLABLAlooooNG.....ENCRYPTED' at 'name' failed to satisfy constraint: Member must have length less than or equal to 280"}
???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????*
???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????*/
@camjac251 the right solution is #637 which will solve this problem properly.  Until then there isn't a nice solution :-(
That really is very ugly isn't it!
IPQoS   Specifies the IPv4 type-of-service or DSCP class for connections.  Accepted values are “af11”, “af12”, “af13”, “af21”, “af22”, “af23”, “af31”, “af32”, “af33”, “af41”,
“af42”, “af43”, “cs0”, “cs1”, “cs2”, “cs3”, “cs4”, “cs5”, “cs6”, “cs7”, “ef”, “lowdelay”, “throughput”, “reliability”, or a numeric value.  This option may take one or two
sions
* Definitions for DiffServ Codepoints as per RFC2474
#ifndef IPTOS_DSCP_AF11
#endif /* IPTOS_DSCP_AF11 */
625% done does seem very strange.
@drashna Great, glad to hear that you are on the case. Let me know if you want anything from me.
http://pub.rclone.org/rclone-v1.33-28-gf2eeb43-freebsd-armv7.zip
https://golang.org/src/runtime/os_freebsd_arm.go
Here is the code
> I'm not sure why I'm getting it since no one else has reported it, it must be a special case in my environment
Is there an old rclone in your path somewhere?
Assuming that wasn't you too under a pseudonym, I wonder if there is a problem with the CDN I'm using...
@javier-gotham2 you seem to have a similar problem with "windows 10" and "WINDOWS 10".  I'd guess you are using windows so that is unlikely to be actually the case.
Can you attach a log with the `-v` flag please?
* renamed
@calisro
@pkIAIK Excellent suggestion!
@seabre
@marrie
Yes I'm afraid that is an Amazon limitation.
rclone check /path/to/source acd:dest
There is a ticket about `--backup` and `--backup-dir` in #98
I should probably get the crypt remote to warn you or ask for confirmation if you enter a remote without a ":".
@justusiv That would be the interesting if it isn't too much bother, thanks.
Yes it does include crypt support as you discovered. And thanks for updating the URL!
From the code
// Note that due to a quirk of swift, dynamic large objects are
I just tried an encrypted remote on ACD and it worked as I expected.
Can you try `rclone ls EACD:` - does that show files? If not then the `rclone mount` won't work.
What exactly did you put in the config of the crypt?  Here is what mine looks like for comparison
[secretacd]
type = crypt
remote = acd:secret
password = SNIP
password2 = SNIP
$ rclone -q ls acd:secret
179 pjacqd7vm8q6eulc3k09u0lvk6aldh8l6t3f60rn0jffjocatlv2so43qjriiggr2kqv4a537kaj6
36709152 q0fiipdq5vdor6jbbovsj08ug2bir2cteo4b899qnl069b8c84lgr77jn8s2vmfevb7romnjr9ahi
$ rclone mount secretacd:/ ~/mnt/tmp/ &
PS Just saw you are the author of Termux - fantastic app thanks - I use it most days on my android phone, and build rclone with it regularly! :-)
5052 .rclone.conf
4883 rclone.conf
Using dir to take a look is a bit more helpful
ng]
04/05/2011  14:29                20 ntuser.ini
04/05/2011  14:29    <JUNCTION>     SendTo [C:\Users\Dev\AppData\Roaming\Microso
So maybe rclone needs to be doing something different with windows junction points...
sort.Strings(names)
go version
And in the definition of your crypt remote did you chose a bucket, eg `b2:bucket` as the docs recommend?  If you didn't then rclone will have created a new funny named bucket (lots of lower case letters and numbers) to store `flibble` in. That might be confusing things.
"myremote:bucket" or maybe "myremote:" (not recommended).
Just noticed that there was a DNS resolver issue bug fixed in Go 1.7.1. Can  you try the latest beta which was compiled with Go 1.7.3 and see if that helps?
http://beta.rclone.org/v1.33-73-geca9e8e/
Thanks for the log @DurvalMenezes
I think that probably wasn't the problem :-(  I've found a data corruption problem with crypt+seek which I've now fixed.  Have a go with http://beta.rclone.org/v1.33-81-g9d2dd2c/ (will be uploaded in 15-30 minutes) and tell me if that makes a difference.
Yes I've confirmed this - you can't upload files to ACD with `rclone mount`. :-(  This is rather complicated to fix unfortunately - it might just be easier it I add a flag so rclone mount uses a temporary file for the upload.
the escaping is wrong!
Error:      Received unexpected error "bad response: 404: 404 Not Found"
which make it hard.
Note that the directory path "test" has been encrypted to 0p5ohk94qrcijn5dqodttaag80 which is as it should be.
> https://github.com/yadayada/acd_cli/blob/master/acd_cli.py
Remote path to encrypt/decrypt (eg remote:path/to/dir)
remote>
2016/08/25 11:30:06 [GJM] Planetarian ~Chiisana Hoshi no Yume~ - 01 [575CC989].mkv: ReadFileHandle.Open
2016/08/25 11:30:06 [GJM] Planetarian ~Chiisana Hoshi no Yume~ - 01 [575CC989].mkv: ReadFileHandle.Open OK
2016/08/25 11:30:06 [GJM] Planetarian ~Chiisana Hoshi no Yume~ - 01 [575CC989].mkv: ReadFileHandle.Open
2016/08/25 11:30:06 [GJM] Planetarian ~Chiisana Hoshi no Yume~ - 01 [575CC989].mkv: ReadFileHandle.Open OK
2016/08/25 11:30:06 [GJM] Planetarian ~Chiisana Hoshi no Yume~ - 01 [575CC989].mkv: ReadFileHandle.Flush
2016/08/25 11:30:06 [GJM] Planetarian ~Chiisana Hoshi no Yume~ - 01 [575CC989].mkv: ReadFileHandle.Flush OK
2016/08/25 11:30:06 [GJM] Planetarian ~Chiisana Hoshi no Yume~ - 01 [575CC989].mkv: ReadFileHandle.Open
Note that seeking doesn't work over crypt yet so it might not work for you yet!
Confusingly the passwords it shows you when it summarises the config for the remote are the encrypted ones. I should probably fix this, so can you make another issue about this too please.
Something strange happened to your docs update - it looks like it got lost in a merge, so sorry I didn't see it.
Note that ods appears twice in the table because there are two subtly different spellings of the mime type for it.
- I think `perm` should be renamed `acl`
- [stack overflow](http://stackoverflow.com/questions/6153345/different-utf8-encoding-in-filenames-os-x)
We should upgrade to using scrypt with salt we store in the encrypted config file (or maybe reuse the IV for the secret box encryption). This can be done transparently to the user. We'll need to continue to read the old format though.
We are using sha256 as a key derivation function.  [scrypt](https://godoc.org/golang.org/x/crypto/scrypt) was purposed designed as a key derivation function, to turn user input into a variable number of random looking bits in a hard to do way (see the `keyLen` parameter in the docs).  So you would do `scrypt(scrypt.Key(password, salt, 16384, 8, 1, 24)` to directly generate the 24 byte key for secretbox.
From what I read scrypt is considered more secure than bcrypt - using more memory means it is more FPGA/ASIC resistant.
An alternative key derivation function would be [pbkdf2](https://godoc.org/golang.org/x/crypto/pbkdf2) which I haven't investigated in depth - that might be a better choice than scrypt.
I believe that we can afford to run scrypt at the default parameters even on a puny NAS - it uses 16 MB of RAM according to its benchmark.  I don't really want to have tune-able parameters on the key derivation function though - that would just complicate things.
bcrypt, pbkdf2 or scrypt would all make better key derivation functions than sha256 and we are lucky to have an implementation of each in the golang.org/x/ repository. In the interest of not bloating rclone with too much crypto it would be nice to use the same key derivation function here and in the upcoming file encryption.  I've used scrypt there and it was very useful in generating the 80 bytes of key material needed, but it isn't released yet so I could change it to something else.
Environment Variables
### Options ###
variable.
upper case and prepend `RCLONE_`.
mys3:
### Other environment variables ###
Are they all .zip files maybe?  I wonder if you have some extension to Windows which is treating these in a special way which confuses rclone.
I suspect this has been caused by #451 and 7c01bbddf8a7ccde05554633b0165f3711d9fdc4.
This means that it will only affect accented characters as you suspect.
I would have hoped that if you let the sync continue to the end it will delete the unnormalized file names - does it?
There seem to be two types of errors
@isaiah36 Would really like to see a log with -v if possible.  I can't do anything to fix the restarting before 99% that really is Amazon's problem :-(
Can you make an issue about it please?   But don't send a PR as I'm in the middle of completely reworking it to use cobra!
Accept-Encoding: gzip
rclone has worked in the past with OVH.
This may also be caused by specifying the region when you shouldn't have (eg OVH).
Looks strange!
Did rclone finish with any sort of error?
Strange!  If you can reliable reproduce it then please re-open.
You can run as many rclones as you like.
Rclone should have refreshed it's tokens and carried on.
I've realised this is the same issue as #553
Why don't you try my `--bwlimit 900k` suggestion?
$ echo hello > /tmp/"complex character £100.txt"
$ rclone copy /tmp/"complex character £100.txt" s3:utf8-test
rclone copy /tmp/"complex character £100.txt" dreamhost:utf8-tes
2016/07/15 15:29:45 complex character £100.txt: Failed to copy: NoSuchKey:
2016/07/15 15:29:45 PUT /utf8-test2/complex%20character%20%C2%A3100.txt HTTP/1.1
X-Amz-Copy-Source: utf8-test%2Fcomplex+character+%C2%A3100.txt
X-Amz-Metadata-Directive: COPY
Accept-Encoding: gzip
X-Amz-Request-Id: tx000000000000000019ea9-005788f359-e20c137-default
What I suspect is that Dreamhost (and thus CEPH) isn't URL decoding the `X-Amz-Copy-Source` header properly in the request. It says in the [s3 COPY docs](http://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectCOPY.html) that "This string must be URL-encoded."
> hmmm, my nas is running on a ssd, and i use the noatime option to mount my filesystem. maybe this is the problem i am facing???
Unlikely I would have thought
> Backblaze b2
> E:\rclone-v1.30-windows-amd64>rclone.exe size "D:\backup\Personal\video\20150830 MLSS 2015 Video.zip"
@NoSyu Thanks for checking!
I think this is a different issue you are right.
rclone.exe -v --dump-bodies sha1sum "remote:NoSyuPersonalBackUP/video/20150830 MLSS 2015 Video.zip" --log-file log2.txt
I wonder if on b2 you have two objects with differing case, eg
remote:NoSyuPersonalBackUP/video/20150830 MLSS 2015 Video.zip
remote:NoSyuPersonalBackUP/Video/20150830 MLSS 2015 Video.zip
> E:\rclone>rclone ls "D:\backup\Personal\video\20150830 MLSS 2015 Video.zip"
> E:\rclone>rclone ls "D:\backup\Personal\Video\20150830 MLSS 2015 Video.zip"
In your debugging are you sure it was the B2 shasum that was wrong - could it have been the local one?
Strange!
The rclone check is a good test to do.
Many Apologies
- [x] amazonclouddrive - not possible
- [x] box - not possible easily (see below)
- [x] hubic - not possible
- [x] yandex
/usr/sbin/rclone sync --exclude "/JAZZ/lost+found/**" /home/isaiahsellassie/Music Adrive:Music
/usr/sbin/rclone ls --exclude "/JAZZ/lost+found/**" /home/isaiahsellassie/Music
[rackspace]
As @lorenzoferrarajr suggests a truncated version of the submitting a pull request instructions will work.
You'll need a Go environment set up with GOPATH set.  See [the Go getting started docs](https://golang.org/doc/install) for more info.
I've built a version of rclone with the latest go which may or may not make any difference!
What is happening is that you have some file names which aren't UTF-8 encoded on your filesystem.  By the look of it you have some latin-1 files.  This is quite common in linux file systems where only in recent years have they standardised on utf-8 encoding for file names.
Also there seemed to be a bit of one of my commits in there too.
3 / Backblaze B2
7 / Hubic
\ "hubic"
8 / Local Disk
\ "onedrive"
\ "yandex"
6 / OVH
domain> somedomain
region> sss
Remote config
domain = somedomain
region = sss
So there are a lot of complex scenarios that have to be addressed. However, it is not an impossible task by any means.
Very useful information thanks @balazer
@zeshanb `--bw-limit` is rclone's throttle - I was talking about Google Drive's throttling which we can't see and have no control over :-(
A new verb for rclone would be the way to go for this, eg `rclone list-remotes` maybe.
Even easier now we have cobra
Interesting!
If I try to download the link you sent me then Canel is the only option I get.
Onedrive has a `virusSuspicious` error code which you can see here: https://dev.onedrive.com/misc/errors.htm but it doesn't look like it is returning that from the log.
Can you copy one of those files from acd to local disk? And then from local disk to b2? Just trying to work out where the problem is!
I can see something odd in the logs
Figured out what that log means - it means that reading from ACD gave the unexpected EOF error.
Resume is tricky..
You appear to be starting an rclone every minute of the 23rd hour.
* 23 * * * rclone....
0 23 * * * rclone....
Nice idea.  Might be a bit of work.  I wonder if there are any Go frameworks about to help?
@lorenzoferrarajr It will work for all the remotes, yes.
That is a bit surprising!
It would be interesting to dig down into exactly why you are seeing what you are seeing and whether it is an rclone problem or an ACD problem.
Strange! Looks like some sort of B2 internal error.
`-q` only shows errors - if there weren't any it will show nothing at all.
Thanks @zeshanb :-)
Accept-Encoding: gzip
Accept-Encoding: gzip
- We try the PUT but it is rejected.
@mejje here is a beta for you to try with @klauspost fix.
@DavidCWGA @bittylicious I conjecture you are using crypt with b2 and this is
Are you running rclone off the crontab?
Are you using any flags?
Can you see why those rclones stopped from the log?
This could also be implemented for swift (&hubic) - I wonder if there is any standard metadata keys for that also?
@jamshid wrote
@kubark42 Hmm, I wonder if that is an OS X problem.  Can you make a new issue with the above in please?
@diamondsw @DurvalMenezes I think rsync uses a similar idea
-r, --recursive
--dirs (-d).
On some remotes this will be a lot slower and on some it may make no difference...
> The "tofu" (?) character � was also shown twice, in exact the same position.
That is indicative of a non UTF-8 character, ie some latin1 encoding.
Sorry, not a shell expert :-(
That is very strange - ACD definitely doesn't allow duplicate files.
NIck
The flag isn't very robust though.  Its all or nothing.  It would have been better to have the case sensitivity within each include/exclude.
This is a known problem - see #8
I've now idea how this happened - very strange!
dircache
hubic/hubic.go
@wtluke no worries - we've all been there :-)
@ppuskari A new issue would be a good idea. Can you attach a log with -v to the issue too please? Something showing 'the kill'  because I'm unsure what you mean by that. Thanks Nick
I'm not really familiar with how server side encryption works with S3 - would #59 solve the problem for you?
rclone -v --include "*.jpg" ls gdrv:boards/sayas/
Apologies for the confusion!
This is puzzling about your log
rclone lsl /home/user/localfiles/
500 errors are a bit more unusual - perhaps a problem at Amazon?
@makdisse Not at the moment, no. Do you want to make a new issue?
$ ln a b
-rw-rw-r-- 2 ncw ncw 6 May  9 11:38 a
-rw-rw-r-- 2 ncw ncw 6 May  9 11:38 b
I think that is a different problem - see #493 for background.
I don't know what the 16 byte files might be about either, not seen anything like that :-(
@dimatter can you send a log with -v please of what happens around the 401 error?
@kpabba great glad it worked!
PS The strange upload bandwidths you see are caused by the large chunk size you are using.  You can see by the overall stats that the transfer is progressing in a regular fashion.
On a flag would be best, eg `--drive-trash-only`
@nodegin that is clever! I think `rclone auth` is easier but YMMV!
"/etc/pki/tls/cacert.pem",            // OpenELEC
rclone doesn't use python so that shouldn't affect things.
CommandLineToArgvW has a special interpretation of backslash characters when they are followed by a quotation mark character ("), as follows:
The original command line had a mis-matched quote `"` so it would have been nice if it had given an error.
@left1000 I don't think this is a silly question at all - it exposes a bit of windows oddness.  I should probably put this either in the docs somewhere!
Has your password got any funny characters in? (non alphabetic?)
"secret"
"id": "secrettoken",
"github.com/aws/aws-sdk-go/aws/awserr"
+               Location:  aws.StringValue(complete.Location),
http://pub.rclone.org/rclone-v1.29-aws-patch.zip
@hajes can you stick that in an new issue please?
I'm pretty sure this is the same problem as #399
This is caused by a known bug in onedrive which they haven't been fixing for the last 18 months!
https://ma.ttias.be/prevent-cronjobs-from-overlapping-in-linux/
I wonder if there is an oddity with that and Ceph.
It would be interesting if you could run the copy with `--dump-bodies` and paste here failing transaction (remove any Authorization: lines first).
I think this is very likely the same problem as #586 - ceph failing to decode the `X-Amz-Copy-Source` header properly.
I suspect this is related to unicode normalisation on OS X file systems - see #194
@eduardbosch thanks for testing! If you get time to contribute one day then at least the test suite will pass on OS X now ;-)
I suspect this is the problem: http://william.shallum.net/random-notes/32-bit-golang-trace-breakpoint-trap-modify_ldt-enosys
I've merged that thank you!  Yes the Context stuff is rather cryptic!
The other error `An established connection
Find the beta here
Follow up bug in #520
@brsf  thanks for testing :-)
Did it print anything else other than illegal instruction?  If so can you paste it here please.
b4d6fd906383477fd68857469d0c1513  rclone
@wtangerine glad you found a work-around.
@wtangerine no rush!  I expect that build to work (cross fingers). > not sure if that makes any difference but the "file" command reports my executable as dynamically linked, while your executable as statically linked.
I'm confused by "my executable" and "your executable".  How did you generate your executable?  Does it work?
RET
From rclone-v1.36-22-gbc25190-no-sse.zip which does fault
Any help much appreciated - rclone is getting quite popular and it is difficult keeping up!
This is a peculiarity of `os.system` in python, eg
I think this must be an Amazon problem...
This is the only reference I've manage to find mentioning the error:  yadayada/acd_cli#44
http://pub.rclone.org/rclone-v1.28-28-g9539bbf-arm-go-tip.zip
- golang/go#10180
- golang/go#12480
I've compiled up two versions of rclone for you all to test. There is an ARMv6 version and an ARMv7 version - it would be interesting if you could try both.
Make sure GOPATH is set, eg
export GOPATH=~/bin/go
rclone (or rather its dependencies) require Go 1.5 or later.
This has been fixed as part of af4ef8ad8d1dcae105138d8046d6793c89de9a7b and f6a053df6e0ec83a8a4fce9db436285d99cafba5 .
Conjecture
This is just a guess - I haven't used the drive client and I don't know how it works!
Thanks for trying that binary.  Odd result!
That is relief!  There is something strange going on, but not that is good!
This is clearly a bug, but in exactly what I'm not sure!
I'm glad we've got to the bottom of that - thank you very much for your help.
So I suspect  the bucket was created  in a different region to us-East-1 (which is the default).
Probably an off-by-one error in the acd pacer would be my guess..
This error `Failed to copy: sha1 did not match data received (400 bad_request)` is a little worrying - that indicates something corrupted the data somewhere.
@mejje if you can reproduce that, then can you open a new issue please and put a log with `-v` in please.  Or even better with `-v` and `--dump-headers`.
I haven't worked out what is going on yet but I will :-)
-rw-rw-r-- 1 ncw ncw  97258 Feb 15  2014 HIGH-bridges.png
205029 HIGH-bridges.png
So somehow onedrive has its metadata in a twist...
https://onedrive.live.com/redir?resid=71A96798E7B1D253!10473&authkey=!ALWELG3BUcvK-gM&ithint=folder%2cpng
It seems to be very sensitive to something that I haven't worked out yet.
Interesting...  Note that rclone will buffer that 128M in memory and by default will do 4 transfers at once, so that will take 0.5GB of memory.
- *.obj
- *.ncb
- *.bak
- *.BAK
- *.suo
- *.idb
- *.ilk
$ cat /tmp/exludes
- *.obj
- *.ncb
- *.bak
- *.BAK
- *.suo
- *.idb
- *.ilk
-rw-rw-r--   1 ncw ncw  3956 Mar 11 14:20 README.md
I made an issue here about it ncw/swift#67
Hopefully that will fix it!
I see the problem - the aws library only does its magic calculations if I'm passing an `io.Seeker` but I'm not.
@zioproto are you trying from Ceph to Ceph too?  Is it possible this is a ceph bug?
And are you both using a recent version of rclone? Versions before v1.29 don't contain the fix to the aws s3manager library which does cause exactly this problem (see #415) @mistur Try the transfer with `-v --dump-headers ` - that should tell you what is going on. @zioproto OK so definitely 10,000 parts which is interesting...  What does rclone say if you do the transfer with `-v --dump-headers`?  I think you should get a Content-Size header which will show you how big the parts are.
@ashayh Strange - that isn't how I think it works... Have you got the source and destintation the wrong way round?  It goes `rclone sync source destination`?  Can you post the command line you are using please? And can you see that file in either the source or the destination - maybe it got in the destination in the wrong place?
Or like wget ?
So let's modify the example a bit:
Notice i've added percentage for transferred.
Something is not right still ...
<hr><center>nginx</center>
It's almost like it was invoking an invalid URL or something. I wish I'd run the first attempt with -v, maybe I'd get the url being called .... is there a `--debug` flag equivalent? I couldn't find it ...
I have seen this too occasionally.  I've been assuming it is a temporary Hubic problem, but maybe I'm wrong about that.
@Thinkscape good idea!
The client secret is obfuscated so it isn't directly I'm the code - that was the best I could come up with.
@felixbuenemann do you fancy working out how the official client manages to store the modification time?  There isn't a documented API for it...  To be most useful to rclone you'd need to be able to set the modification time (patch an existing object).
Foo! Is there a different API for google photos that you can find?
rclone -v copy encrypted acd:encfs-test
@zachron Strange!  Let me know if you manage to get a reproducer!
$ rclone size /tmp/encrypted
It depends on exactly how dis-entangled you want it from rclone itself.
@jackools - did Nick's proposal help you?
> List buckets (why??)
> Create bucket (what the heck??)
@harupong very cool thank you! Would you like to maintain the chocolaty package for rclone on a permanent basis? Thanks Nick
2016/02/14 16:52:35 Swift container gzs: Waiting for checks to finish
This would involve setting `x-amz-storage-class: REDUCED_REDUNDANCY` at the time the object was uploaded.
I tried to replicate this problem with hubic directly.
> If a filename contains one or more accents (like the word Liberté.jpg), upload is OK, no error reported by rclone. But if I launch hubiC official sync software, when the soft compares uploaded file with rclone and local file, it says there is a conflict between both. No problem with filename without accents.
As far as I can tell rclone is working properly with chunked files with accents
Content-Type: video/x-matroska
Etag: "8d431e7531abb83a6cf67e56d91c6f74"
1048576 Vidéo.mkv/1455272496.908089688/10485760/00000000
1048576 Vidéo.mkv/1455272496.908089688/10485760/00000001
1048576 Vidéo.mkv/1455272496.908089688/10485760/00000002
1048576 Vidéo.mkv/1455272496.908089688/10485760/00000003
1048576 Vidéo.mkv/1455272496.908089688/10485760/00000005
1048576 Vidéo.mkv/1455272496.908089688/10485760/00000004
1048576 Vidéo.mkv/1455272496.908089688/10485760/00000006
1048576 Vidéo.mkv/1455272496.908089688/10485760/00000007
1048576 Vidéo.mkv/1455272496.908089688/10485760/00000008
1048576 Vidéo.mkv/1455272496.908089688/10485760/00000009
f1c9645dbc14efddc7d8a322685f26eb  swift-test/Vidéo.mkv
f1c9645dbc14efddc7d8a322685f26eb  swift-test2/Vidéo.mkv
Which makes me wonder if the official hubiC sync software is treating segmented files with accents differently to rclone?
X-Object-Manifest: default_segments/Films%20SD/Les%20Coll%C3%A8gues.mkv/14199774
@mchudoba thanks for the heads-up!  I've merged that in 6a47d966a4109f6650f68297d1c2c41238e67c14
is anything special about your Internet connection (eg a proxy).
$ rclone -v copy 100MB acd:100-mb-test
$ rclone lsl acd:100-mb-test
@jacobfarkas can you make sure you are using rclone 1.27 and using the flag `--drive-full-list=false` (until I fix #336).
Before - with duplicates
$ rclone lsl drive:dupes
Now the `dedupe` session
$ rclone dedupe drive:dupes
$ rclone lsl drive:dupes
Most of the other oauth based providers have this facility too I think
driveConfig = &oauth2.Config{
I've merged and pushed to a branch `stengaard-iam-role-credentials`
I see this strange message:
Cool script by the way!
The `Failed to copy: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&uploadType=resumable: http: ContentLength=193 with Body length 0` are unusual.
$ rclone dedupe drive:dupes
$ rclone lsl drive:dupes
@gustavorochakv thanks for the heads up.
So what that error means is that rclone went to set the modification time on the file, but s3 said it didn't exist which is strange indeed.
The `Unsolicited response received on idle HTTP channel starting with "H"` is strange also.
X-Amz-Acl:
X-Amz-Content-Sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
X-Amz-Copy-Source: mytest50/file-with+44.pdf
X-Amz-Date: 20160127T170643Z
X-Amz-Meta-Mtime: 1453914402.34825253
X-Amz-Metadata-Directive: REPLACE
Accept-Encoding: gzip
X-Amz-Id-2: 55baDyXyzc+SSEIWHVJ+yvSo+BW1Lr8yOdTg5nRuleC59dodpeWJAbSMFytup75eYps/6j3u4T8=
X-Amz-Request-Id: 56F1855EE2332F05
I should probably rename the constant to `rcloneEncryptedClientSecret` or something like that which will give people who are viewing the source code a bit more confidence.
> and afaik if the token was already obtained somehow, it can be used without the sk (is that right?).
client_secret>
@yonjah
Interesting idea!  Probably beyond the scope of rclone, but maybe one day!
~~Regarding the `bad hex digit`, it could be because it uses [`fmt.Sprintf("%x", hash.Sum(nil))`](https://github.com/ncw/rclone/blob/master/b2/b2.go#L851). It could be that it skips printing if the first byte is a zero value. That would make it fail on 1 in 256 files.~~
- Backslashes are not allowed.
- DEL characters (127) are not allowed.
@hajes backblaze is a fast moving target - the large file support has only just been invented. Can you make a new issue please?
@bunset thank you that log is very useful.
Also rclone spends ages retrying those 409 Conflicts for no gain.
@avgex Thanks for that - very helpful.
I note also that your file system appears to be in latin1 instead of UTF-8.  This may mean that some of the names with accents look a bit odd in Amazon's web interface ([see the local docs](http://rclone.org/local/)).  You might want to run `convmv` on the filesystem to make it utf-8 which would be the modern thing to do. (I made myself a ticket to write this up #300)
@avgex I see what happened there - that log was really helpful thank you.
Thanks you very much for the kind words and I'm glad you are enjoying rclone.
rclone size remote:dir
If you think the [swift docs](http://rclone.org/swift/) need an OVH specific paragraph then do send in a pull request.
Related to issues #198, #157, #265 (Syncthing uses SHA256 and Murmur3).
So in effect it is a "skip-existing-files" behaviour?
You can use a bit of shell magic like this to find them
My guess I'd that you forgot the colon after the Gdrive,  eg
I'm not 100% convinced this is an rclone issue rather than just ACD being overloaded, but we'll try to get to the bottom of the problem and fix it or work around.
@isaiah36 that will certainly stop the sync completing - sounds like ACD is having a good day if that was the only problem!
![acd-timeouts2](https://cloud.githubusercontent.com/assets/536803/19393938/d39c4538-922e-11e6-99b2-741b0957c6ca.png)
@arionl This issue caused the upload to fail most likely and rsync not to rename it to its final destination.  It didn't appear because of #680 most likely.  Note that acd doesn't support move yet so that is likely why it didn't get its final name from rsync #721.
--acd-upload-wait-limit 60s
--acd-upload-wait-time 120s
--acd-upload-wait-per-gb 30s
@garypaduana - This is likely a Dokan bug. It is old and unmaintained, just as encfs4win, if you are using [this version](http://members.ferrara.linux.it/freddy77/encfs.html).
You might get more help posting to a fedora forum - I don't think it is an rclone problem specifically.
Please re-open if you do discover it is an rclone bug.
@mejje good suggestion.  The next release of rclone v1.30 will be compiled like that by default, so it might be worth retrying with that.
$ rclone -v copy /tmp/z acd:test-copyright-symbol
$ rclone -v copy /tmp/z acd:test-copyright-symbol
Fancy having a go at a patch?
@rafareino a onedrive for business account I could use would  be really helpful!  The source code for rclone is all on this site - it is a fully open source project.
@dibu28 are you interested in working on this?
rclone mkdir hubic:bucket
- rclone version
Hmmm `A_FILE.ext: Sizes differ` is odd...
@lcarstensen - that does indeed sound like a leak, or excessive buffering. If I copy 154k files local->ACD, memory never gets above 300MB.
@nodughere 6k per object sounds way too big!
I also have some questions about rclone objects.
https://github.com/dibu28/yandex
@kpabba you should find `rclone -v ... >debug-logfile 2>importatnt-errors` does what you want
This is expected behaviour - I agree it is counter-intuitive.
Instead of cp
I wouldn't want to do this by default though, but having it controlled by a flag seems like a reasonable idea.
@Sunako I did yes via twitter and their support system, but I haven't heard anything back from them.
@Sunako thanks!
This is a problem in particular with S3/Drive and multipart files.
@marcopaganini I mis-understood your original plan - I thought it was an ordered list of instructions of time:bwlimit, but I see now that it is a timetable and yes I agree with you now :-)
### --bwlimit=BANDWIDTH_SPEC ###
It is not my call if rclone should have encryption or not, but it could seem like something that maybe doesn't belong.
I quite like the idea, but then I'm a bit of a crypto geek anyway ;-)
@InAnimaTe what I would imagine is that you'd encrypt file names and content.  If you wanted see what files you had you would use `rclone ls` which would decrypt the file names on the fly.  Is that what you had in mind?
I've been thinking about how to do it, and my current thinking is to encrypt both file names and contents using the well understood [secretbox](https://godoc.org/golang.org/x/crypto/nacl/secretbox) library (which we already use for config file encryption).  Secret box provides encryption and authentication using a set of extremely well designed ciphers.
I would appreciate review of [the docs](https://github.com/ncw/rclone/blob/crypt/docs/content/crypt.md) - in particular a second pair of eyes on the the use of crypto primitives would be appreciated!
> Why are you using a static key with scrypt?
The file contents have a MAC - it is build into the secretbox format. Secretbox uses XSalsa20 to encrypt and Poly1305  to authenticate which is very strong.
## MAC on filenames
@RXWatcher1
@Charnjit123
@trisomeyr @TARSooper
So that would mean on B2/Amazon Drive you can only have paths with a maximum of 156 bytes including all the directories, and the file name.
@trisomeyr
@captainswain
I've merged the current crypt implementation to master and will try to push out the 1.33 release tonight.
@DurvalMenezes unfortunately ACD has quite a short  path length.  Looks like your K element which is 194 chars expands to 334 byte encrypted length which exceeds the 256 char limit (though amazon says it is 280 chars in the error message which is unexpected!).
I suspect your massive time difference is due to #218 though
Thanks for the suggestion and glad you like rclone!
`find` defines `-maxdepth`, but then `find` does a lot of mad things ;-)
I'll do! Thanks for the suggestions. I never wrote a single line of Go before submit this patch.
@meirelles take your time - that is fine!
@nodughere is `--swift-chunk-size` sufficient?
I think this is the same problem as #205 - what do you think?
`rclone` uses the checkers to read the modification time only.
The error message is an S3 error message.  Presumably ACD is based on S3, but I don't think it should be exposing S3 error messages, which makes me wonder whether this is an ACD problem.
There is a [forum thread](https://www.amazon.com/gp/help/customer/forums/ref=cs_hc_g_pg_next?ie=UTF8&forumID=Fx1SKFFP8U1B6N5&cdThread=Tx3HYABOMJUH2PE&cdPage=2&cdSort=oldest) about this too.
2016/01/22 13:21:46 GET /cdproxy/nodes/3e4ts-snip-Aw/content HTTP/1.1
Accept-Encoding: gzip
This shouldn't be allowed, instead it gives a rather cryptic error
@roms2000 Great news! Thanks for the update.
"/etc/pki/tls/cacert.pem",            // OpenELEC
@bengki I guess using `-k` aka `--insecure` makes sense if the platform doesn't have a ca-bundle.  I'll put that in the FAQ - thanks.
``` diff
--- a/fs/operations.go
+++ b/fs/operations.go
``` diff
--- a/fs/limited.go
+++ b/fs/limited.go
"io"
+   "golang.org/x/text/unicode/norm"
// Limited defines a Fs which can only return the Objects passed in
Interesting. I have not experienced that behavior.
Are there any errors?
$ rclone --stats=10s -v copy 1gb acd:test10
@TiGWolf are you happy that we've explained the problem - can I close the issue now?
@Tolsi do you have a view on whether naming the containers like this is a good idea or not?
Files bigger than 2gb is suspicious...
"no route to host" is a very odd error and normally only caused by networking problems. I wonder if your Nat gateway or ISP gave up at 2gb for some reason.
FYI here is my acd
$ rclone size acd:
I can't figure out why at the moment, but if you could do
My guess is that it is SSL eating up the CPU.
@rindeal - I'm ever hopeful :-)  Actually I think the code changes would be quite easy as the library is a drop in replacement for the go http library, but making the build will be painful as it will need a full cross compile environment for ARM and all the libraries.
@rindeal I do have plan B which is to rewrite the ARM AES implementation in assembler and submit it for go 1.7.  (I already did MD5 and SHA1).  Depends on whether I have enough time really!
At least I cannot reproduce with ACD on Windows, so it could be an S3/ceph-specific issue.
I've sent in a fix for it tsenart/tb#7
@Ferni7 thanks for reporting the bug and sorry it has taken a while to track it down!
"/etc/pki/tls/cacert.pem",            // OpenELEC
That would be an unusual setup!  Can you tell me a bit more about it?  Why doesn't keystone return the correct storage URL?
``` diff
+++ b/swift/swift.go
@AntoineGR excellent news!
Yes you are right this is a bug.
I can see something like that working well with the local Fs
It says unknown client_id and it appears to be blank which is odd.
[acd]
access_key_id = secret
@austinginder Thanks for doing some testing.
Glad you are enjoying rclone!
@Tolsi Firstly - excellent work - thank you! I've put some inline comments too
This is the reason that this feature becomes complicated!
@Tolsi If you want I'll do the `meta` to `headers` change then merge your stuff on top of it in a new branch?
@Tolsi great work thanks!
@Tolsi thank you very much for your review, and thank you for driving this feature forward.
@ceptonit Thanks for the update.  Other people have also told me they have been having trouble with ACD being down too.
Adding '-v' information similar to ACD should be fairly easy.
@nodughere Thanks for the offer of a test swift.  I wrote and maintain the [swift library](https://github.com/ncw/swift) for Go.  I'd be interested if you have access to a swift installation with v3 auth?
@breunigs Well spotted :-(  I think all those nasty corner cases make Copy impractical :-(  However Move is a very useful primitive.
@colinn small but perfectly formed ;-)
2 2014-02-13 Cycling.kmz
That is a puzzle!
- is there a proxy between you and the ceph node
- is there anything else unusual about your setup?
Hopefully we can get to the bottom of this!
That would be a big change in philosophy though as eg you wouldn't be able to see your docs on google drive.
instead of whole objects like rclone does, but that would break the
@jamshid not a bad idea.. I wonder if it can be done in a cross platform way from go...
If if I look in my developer console I seem to have `Google Cloud Storage` and `Google Cloud Storage JSON API` enabled. Have you got both of those?  I think that the one with JSON in is the important one!
@jaslinfernando are you having the same problem? Did you try the above steps?
Anyway I think that is two bugs now
> complex and works somewhat differently, so it's difficult to draw a
I'm convinced this is some kind of network problem though, rather than an rclone problem.
them very big.
@cemsbr
rclone rmdirs --dry-run remote:
rclone rmdirs remote:
Hmm, that is unexpected!  That probably means I haven't thought through enough what happens if there is an existing file in the backup-dir.  @unnfav - you are right ACD complains about naming conflicts here in my tests.
then the files will have SUFFIX added on to them.
@balazer thanks for testing :-) Whoohoo!
Thanks for testing @robjlg and @simnether .
@theonewolf wrote
@okhrustov excellent - thanks!
> 2015/08/12 13:37:40 Operations/Clients/Отчеты/_Архив/XXXXX/Отчет_XXXX 1-31.05.2014.xlsx: Failed to open: Get : unsupported protocol scheme ""
Oleg.
I think there must be a bit more to the API.
Content-Type: multipart/form-data; boundary=b9c371dbfd359cf845278e03d5b914745e7fd1dc5f3786679964dc9ac7b3
Accept-Encoding: gzip
1da
potato
@felixbuenemann
This is how http://pub.rclone.org/rclone-v1.34-05-gd2e33fd-acd-resume-test.gz works.  It probably has loads of bugs though!  Try with `-v --dump-headers` to see what is going on - use `--dump-bodies` if you are feeling brave!  It only does the above for new files not for overwrites.
@olihey I haven't actually implemented the resume bit yet!  However I have made a plan to implement resume under ACD and to fix the waiting for big uploads now that the individual bits are tested.
@AntoineGR Thanks for trying!
I'm afraid I don't know very much about IAM roles.  If @zeshanb idea works I'd be happy to write it up in the docs.
@austinginder excellent - thanks for letting me know!
However that does look like a bug
@zeshanb it is to do with the fact that google changed the API of their go cloudstorage module recently rather than any config change
I think you are aiming at this with your `--bloblist` flag?
$ echo $GOPATH
/home/ncw/Code/Go
Very interesting - thank you.
Questions
- That file has a non ASCII character in it.  Is it the only one or are there others with that character in?
The mostly likely cause of duplicate files does seem to be the non ASCII characters...  rclone can handle UTF-8 characters just fine, but it looks like you have a character in the latin1 encoding since it isn't showing properly in my browser...
fstests.go:225: Didn't find "sw8qmkqzec0dgwtgehdsmh4mev4z38pc/file name.txt" (false) and "sw8qmkqzec0dgwtgehdsmh4mev4z38pc/hello? sausage/êé/Hello, 世界/ \" ' @ < > & ?/z.txt" (false) or no files (count 1289)
2015/05/18 20:16:26 Not found "hello? sausage/êé/Hello, 世界/ \" ' @ < > & ?/z.txt"
2015/05/18 20:17:17 Not found "hello? sausage/êé/Hello, 世界/ \" ' @ < > & ?/z.txt"
token = secretstuff
## travis tests
## misc
There is a typo a few times in `nametree.go` - `CaseInsensetive`
operations_test.go:73: Testing with remote Dropbox root '7jbygeeds6cn1zrc0sm7h64q2mkchrew/s7rlu27g'
=== RUN TestMkdir
--- PASS: TestMkdir (1.08s)
fstest.go:83: Unexpected file "check sum"
fstest.go:83: Unexpected file "check sum"
2015/06/10 17:16:40 Not found "potato"
fstest.go:83: Unexpected file "check sum"
fstest.go:83: Unexpected file "check sum"
fstest.go:83: Unexpected file "check sum"
fstest.go:83: Unexpected file "check sum"
=== RUN TestMd5sum
I'm planning to fix all this properly for 1.37 @aldones I have a plan to fix all of this which will probably take some time to implement!
Go is really easy to pick up for C programmers - the major thing that takes getting used to is the type declarations are backwards.  [The go tour](https://tour.golang.org/) is an excellent place to start for experienced programmers.  I think of Go as being mostly a super C with no memory management, closures and great concurrency.
break OUTER
(or on drive-slash branch)
92 z／slash
92 has／slash/z
/tmp/slash_test/
├── has／slash
└── z／slash
--upload-header "Header: String"
--download-header "Header: String"
If you change your mind and want to do a special case for `BucketAlreadyExists` then I'd certainly consider that.
Something strange is going on...  `86b051dddf5ce98625874650d15546d2-56` isn't even a valid MD5SUM.  That was reported by the source which was AWS.
Need an alternative...
@austinginder I think I might take a different approach and stop storing metadata at all for dropbox.  This would downgrade the syncs somewhat so the MD5SUMs wouldn't be checked and every sync would be a `--size-only` sync.  However it would have the advantage of making dropbox a lot more reliable and faster.
--contimeout
- if so how?  User preference?
Here are the possible extensions with their corresponding mime types.
| Extension | Mime Type | Description |
$ ls /tmp/adfsf/
they have extensions.
>  rclone -v --drive-full-list=false ls gd:CNASALERC
Also you say "Writer file" are these "Google Docs" files or something different?
@jacobperron I think this is a separate issue as this is about Google Drive in particular.
Thanks I think making a Pseudo directory is probably the wrong direction to go in though as it doesn't really fit the way drive works and if you work against the grain of the underlying tech then it causes you problems further down the way!
That seems to suggest that for ceph, to use a password with `\` in you should enter it in quotes, eg `"test\test"`.  That seems like a ceph specific work-around as with swift it works fine with `\` in passwords.
@zioproto
> That seems to suggest that for ceph, to use a password with \ in you should enter it in quotes, eg "test\test". That seems like a ceph specific work-around as with swift it works fine with \ in passwords.
@zioproto I have finally managed to replicate this.
"auid": 0,
I wasn't aware of the swift tool convention before - that makes the prospect of doing this a lot more appetizing!
@OldGlory747 Gosh, those are ancient builds - I didn't even know they were there!  Did you see a link to them somewhere I need to change?
* Backblaze B2
2) b2
* Hubic
6) hubic
* Local Disk
@juniormonkey good point!
$ rclone dedupe drive:dupes
$ rclone lsl drive:dupes
@khurshid-alam rclone (taking the lead from rsync) deliberately doesn't follow symlinks as doing so then opens it up to recursive directory loops and other nasty things like that
When symlinks are encountered, the item that they point to  (the
root
root
* Other
If anyone is still interested in `-l`, `--links` then can you make a new ticket please. @theluke You can download it to a seperate place and use the full path to invoke rclone, or overwrite your current installation whichever you choose. @maakuth you are right - there is a small mistake in a recent commit - thanks for reporting.
@zeshanb If you can reproduce rclone deleting the source data (that would be a bad bug) can you add an issue with instructions on how to reproduce?
Eg from @benfry
@madralphw I'm currently testing a fix for this which is looking encouraging.  If you want to try a test binary, then drop me an email to nick@craig-wood.com  with your platform (windows/linux 32/64 bit) and I'll send you one.
It might be that the docs are wrong!
rsync has a `-c` flag
So I think you should give it a go, and if you find bugs, then please report them!
I tried your suggestions with + or @ symbols for making duplicates but I haven't had any luck.  I'd hope that it isn't these funny characters causing a problem since the unit tests cover these tricky cases (I had to fix the google drive api to fix precisely this!) but you never know!
@madralphw I'm working on that as we speak.  It affects all transfers which take longer than 1 hour.  Unfortunately neither of my first two attempts worked to fix the problem so cross fingers for attempt number 3!
@jacobmcnamee thanks - very interesting. I haven't had a good reason for switching to oauth2 but that sound like a good one.
@mbevin yes you are probably right
@vishalmote I apologise, I didn't mean to suggest your data wasn't valuable, merely that 3 errors in 1420 is a better score than the number of duplicates suggest.
For include/exclude we are talking about these flags
Is there something special about authenticating with a google apps account?
@Edke thanks for testing that - I'll try to make that flag not necessary for you in the next release.
It isn't entirely intuitive, I'd agree!
rclone --verbose=true ls google:iceburg-vault
-rw-rw-r-- 1 ncw ncw 2 Jan 19 16:44 one
-rw-rw-r-- 1 ncw ncw 2 Jan 19 16:44 two
testdir:
-rw-rw-r-- 1 ncw ncw 2 Jan 19 16:44 one
-rw-rw-r-- 1 ncw ncw 2 Jan 19 16:44 two
testdir-recovered/:
-rw-rw-r-- 1 ncw ncw 2 Jan 19 16:44 one
-rw-rw-r-- 1 ncw ncw 2 Jan 19 16:44 two
Interesting idea!
- move it from base to changes
Yes, Versions sounds like it would be simpler for people to understand.
https://github.com/mitchellh/go-homedir
Using description would be the highest performance as it is returned with every object.  This would mean adding a specially formatted description such as `Uploaded by rclone (md5sum: 293847abde7892456748391dcde909384, Last modified:  2001-02-03T04:05:06.499999999Z)`.  This could be added to any descriptions already in place.  Otherwise this could be put in a comment.
@ismail @bobobo1618 @phudson I've release the first version of this in rclone v1.24.  Give it a go and make issues if you find problems!
Your log looks really strange as though the HTTP transaction has got corrupted.  Is there something funny between you and the Internet?  A proxy maybe?
``` diff
http://termbin.com/1xww As a test I have renamed the target folder and I am re-running. Early indications suggest that it is working as when I stop the process and restart, the existing files are correctly skipped. OK - more clues. I have just ```ls``` the directory locally and there are duplicates where some have ```.jpg``` and some ```.JPG```
I do not know if it's an issue with rClone of Wasabi (so I'll be asking them too).
Geoff Egg on my face....
-1 2017-06-09 20:32:35       285 dunbar
./rclone ls drive_database_backup1:somefolder/someotherfolder/someotherotherfolder
> **2017/06/27 09:29:11 NOTICE: Battlestar Galactica S00E04-E05 - Razor.mkv: Not copying as --dry-run**
> **2017/06/27 09:30:47 DEBUG : Battlestar Galactica S00E04-E05 - Razor.mkv: Unchanged skipping**
I'm new to rclone, so naturally, I consult with the docs a lot. That's how I noticed the typo:
* fix some more typos ('bandwith', 'integriTIty', etc.)
It seems wrong (move may be used if move is not supported?), but I don't know what it should say. Maybe it's even correct, just not very clear. No problem. Thanks for your work on this tool!
acd, Google drive
rclone copy acd: gd:
http://downforeveryoneorjustme.com/rclone.org
rclone copy acd: gd:
I went back into Cloudberry and reconnected, got a new token, etc.
2017/06/18 22:08:16 DEBUG : Documents/DND/dnd.rem.uz/Advanced D&D (unsorted)/AD&D Accessory-FR-Volo's Guide to Cormyr.pdf: Dir.Lookup
```jfulmer@localhost:~$ sudo bash
[sudo] password for jfulmer:
root@localhost:/home/jfulmer# rclone mount -vv hubic:default /storage/test
root@localhost:/home/jfulmer# bg
root@localhost:/home/jfulmer#
root@localhost:/home/jfulmer#
root@localhost:/home/jfulmer# cd /storage/test
Saving to: ‘AD&D Accessory-FR-Volo\342%80%99s Guide to All Things.pdf’
It may be something bad interacting with wget (after all, telling it
> hubic doesn't like.
@calisro i guess slightly different syntax but it works both ways i guess  > What is your rclone version (eg output from `rclone -V`)
[myoscluster]
But I can't easily test it either because the images are on a NAS and the original dropbox client has no support for that afaik.
Or maybe it's something different as it's telling things like "rate limited".
[**Link**](https://mm-vault.de/chevereto/image/42C)
**EDIT**: actually it is cgofuse and not WinFsp that causes the problem:
I had asked for this before and you had seemed to be interested.. in basically allowing us to have more control over what -v outputs Just adding my vote to this too.   Some less experienced users might find the following message confusing:
Unfortunately, I have never attempted anything with Go so I don't think I can contribute a PR, but if it turns out that time is very scarce, I might try and see if I can do it nonetheless. That's absolutely enough for my current needs and I have implemented it with a (probably unneeded) PR. Also, reading a bit about Go and scrolling through the code I found it to be extremely interesting, so I'll see if I can write some real code next weekend (unless somebody beats me, of course, which would definitely be preferable for rclone itself =))  I recently migrated servers using a backup stored on an encrypted google drive (as the entire thing doesn't fit on the old server). I noticed some programs weren't finding files and rsyncing the files off the old server to the new one resulted in a different file name that was then picked up by the programs. Further to this I noticed the only files this occurred on had accents or dakuten. I'll admit the original filenames are probably _technically wrong_ but rclone needs to be using the actual filename not just what it thinks is better.
'10 - Polonaise in Ab major Op 53 Héroique.flac'
'10 - Polonaise in Ab major Op 53 Héroique.flac'
04 - Wormlust - Sex Augu, Tólf Stjörnur.flac on ó and ö
07 - Nyiþ - Visni Þitt Hold Svo Betur Megi Hæfa Þeim Hug Sem Það Hýsir.flac on ý
2017/06/10 23:35:10 INFO  : 10 - Polonaise in Ab major Op 53 Héroique.flac: Copied (new)
2017/06/10 23:36:40 INFO  : 10 - Polonaise in Ab major Op 53 Héroique.flac: Copied (new)
2017/06/08 18:40:23 DEBUG : rclone: Version "v1.36" starting with parameters ["rclone" "-vvvv" "copy" "b" "hubic:/"]
Accept-Encoding: gzip
Cache-Control: private
Strict-Transport-Security: max-age=15768000
Accept-Encoding: gzip
X-Trans-Id: XXX
$ rclone  -vv --dump-bodies copy /tmp/a hubic:/
Accept-Encoding: gzip
Cache-Control: private
Strict-Transport-Security: max-age=15768000
X-Trans-Id: XXXX
$ rclone -vvvv --dump-bodies ls hubic:foo
2017/06/11 10:21:58 DEBUG : rclone: Version "v1.36-170-g2ca477c5β" starting with parameters ["rclone" "-vvvv" "--dump-bodies" "ls" "hubic:foo"]
Accept-Encoding: gzip
Cache-Control: private
Strict-Transport-Security: max-age=15768000
Accept-Encoding: gzip
X-Trans-Id: XXXX
Accept-Encoding: gzip
Cache-Control: private
Strict-Transport-Security: max-age=15768000
X-Trans-Id: XXXX
X-Trans-Id: XXXX
X-Trans-Id: XXXX
Zenjaba have the credentials for you @ncw if you are willing to setup auth server so ACD would work again. > Wouldn't it just get banned again just like what happened with acdcli again? I can certainly see rclone continuing to work with ACD for people that have their own credentials because of the low API hits but as soon as a auth server is officially put up, I just see it getting banned again.
The Crypt mount now appears empty
"AWS": "arn:aws:iam::USER_SID:user/USER_NAME"
"arn:aws:s3:::BUCKET_NAME/*",
"arn:aws:s3:::BUCKET_NAME"
An implementation using something like the [Web Crypto API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Crypto_API) or one of these [crypto libs](https://gist.github.com/jo/8619441) would be much better I think. I will try to implement the decryption schema rclone is using in pure javascript.
If you are not using the built in crypto API ( which I think is only good for generating random values anyway) I would recommend using [SJCL](http://bitwiseshiftleft.github.io/sjcl/) It seem to be the only library made by professionals. I only compared it to CryptoJS ( which you should never use any way) and the performance were much better. My initial idea was to just make a little script that would decrypt all names in the browser. This could be used as a user script to improve browsing experiences on acd/gdrive.
2017/05/26 12:22:20 DEBUG : Targem Root/Welcome targem games/ TamTam.docx: Unchanged skipping
2017/05/26 12:22:20 DEBUG : Targem Root/Welcome targem games/Links.xlsx: Sizes differ
35172:2017/05/26 12:50:10 ERROR : Targem Root/PR реклама коммьюнити  эвенты/Star Conflict/Новости/Скидка дня 50% на детали к кораблю Karud.docx: corrupted on transfer: sizes differ 601837 vs 664002
43732:2017/05/26 13:03:18 ERROR : Targem Root/PR реклама коммьюнити  эвенты/Star Conflict/(Акция на выходные) Бонусы на лояльность и скидки на контейнеры с редкими ресурсами.docx: corrupted on transfer: sizes differ 667023 vs 799331
gsuitRemote
Did you try with a remote name containing a space?
Backblaze B2
Then when it tried to refresh the token, i saw the above exception.
rclone v1.36-129-gae9f8304
Latest Beta (rclone v1.36-126-ga243ea63β)
`2017/05/24 18:53:54 ERROR : Attempt 3/3 failed with 0 errors and: error reading source directory "Artists/IvoryKeysADSR/\"It's Muh Policy\"": directory not found
2017/05/24 18:53:54 Failed to sync: error reading source directory "Artists/IvoryKeysADSR/\"It's Muh Policy\"": directory not found`
2017/05/25 00:44:53 DEBUG : Google drive root 'Pony/Music/Fan-made/Equestrian Beats (EQBeats.org) full rip/Artists/IvoryKeysADSR': Reading ""
2017/05/25 00:44:54 DEBUG : Google drive root 'Pony/Music/Fan-made/Equestrian Beats (EQBeats.org) full rip/Artists/IvoryKeysADSR': Finished reading ""
0 2017-03-03 02:25:38        -1 .asciinema
So basically it seems that special characters are simultaneously being treated as wildcards and part of the literal path.
On a separate note, until now I had assumed filtering was handled locally, is this the case on other remotes or for example does google drive filter using the api when the `--filter` flag is passed to rclone?  Added information regarding non-standard FTP ports.  Hi,
Issue:
So if you specify the port as part of the URL, the client should be able to connect to non-standard ports.
Remote config
username = sjurtf
> <https://github.com/notifications/unsubscribe-auth/ANLwiGU8PpWQh9IK7SHRaIDCsu1oTSk0ks5r9BwWgaJpZM4NjWjq>
If my path has spaces, do I need to add escape chars?  [20:01:39] rhummelmose:rclone-v1.36-120-ga9d29c22β-osx-amd64 $ ./rclone lsd Bitport:
2017/05/22 21:06:10 directory not found I just tested the same build with FTP using a non-standard port for #1434 and tested the functionality of the remote with lsd.
> R:\rclone_bin\rclone-v1.36-windows-amd64>rclone sync r:\rclone_test nas-sftp:/home/rclone_test --config .rclone.config -vv
> [root@telefon rclone-v1.36-linux-amd64]# ./rclone sync /tmp/rclone_test nas-sftp:/home/rclone_test --config .rclone.config -vv
2017/05/18 12:36:18 INFO  : REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/REDACTED.info: Copied (new)
2017/05/19 10:12:27 INFO  : REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/REDACTED.info: Moved (server side)
2) Out of curiosity, WTF could have caused GDrive to create those duplicates? Collisions on the rclone filename encryption? Some kind of internal bug/feature, perhaps interacting weirdly with rclone? Inquiring minds want to know ;-)
--   Durval.
My data wa s uploaded completely with `rclone copy` to an encrypted remote: initially from local to ACD, then from ACD to GDrive, then from local to GDrive again (as the initial copy to ACD was interrupted in the middle due to my migration to GDrive). Only after the copy to GDrive finished with no errors I started using sync.
-- Durval. My files are not encrypted. These files were uploaded from my Mac to GDrive through their web interface. rclone copy works normally, rclone sync deletes everything again.
New weird thing (and maybe I'll need to open a new issue rather than working on this):
My mount does not appear to be working.
Cest La Vie, haha @ncw Thanks!
> @alternativesurfer have you got a stale mount open?
Thanks @ncw    rclone/amazonclouddrive/amazonclouddrive.go
line 38    rcloneEncryptedClientSecret = "ZP12wYlGw198FtmqfOxyNAGXU3fwVcQdmt--ba1d00wJnUs0LOzvVyXVDbqhbcUqnr5Vd1QejwWmiv1Ep7UJG1kUQeuBP5n9goXWd5MrAf0"
Massaguana
@Massaguana I have always wonder how to do that, but in Linux you can do :
> done Sorry, but i don´t understand what i must do...  @Massaguana well the script will loop through all the matching and upload to the remote; which OS are you running. i use CentOS 7 64-Bit...
**I am guessing that b2 is throttling. If that is the case, is there anything I can do to prevent it?**
[anons3]
X-Amz-Id-2: LD+/NH6b5YxwwzFPGmMbmD/IA8wm6FXBZYX743kgIYXlSSRcl/A+6nvD8GN337GWkPdiEqNdYVM=
X-Amz-Request-Id: BAF7A56D12ED2C49
"Resource": "arn:aws:s3:::blinddrop",
client_secret>
Remote config
* Say N if you are working on a remote or headless machine
400 Bad Request
client_id=amzn1.application-oa2-client.6bf18d2d1f5b485c94c8988bb03ad0e7
response_type=code
@ncw sorry for posting here but I don't have a forum user.
You updated that amazon have banned since the secret are kept in code
THIS IS FROM MY POWERSHELL:
THIS IS FROM CHROME:
400 Bad Request
client_id=amzn1.application-oa2-client.6bf18d2d1f5b485c94c8988bb03ad0e7
response_type=code
400 Bad Request
An unknown scope was requested
client_id=<personal secret>
response_type=code
> You updated that amazon have banned since the secret are kept in code
This is really beyond retarded, @ncw I hope you guys can deliver local cache soon so we can use gdrive instead.
Anyone know of another way to mount or pull files out of ACD with linux or shuffle it over in bulk to gdrive? An employee of Amazon Germany just told me on the phone that they are making changes to their services and infrastructure and that rclone probably needs to be updated accordingly.
They put me on hold for 5 minutes ( after i was first told that rclone access is revoked ) then he told me that rclone access wont be renabled for sure and that i need to find another way to use Amazon Drive ( since i told them i need linux client that they dont support )  @ncw anything on the Email front yet mate? @thenoahcomputer I am currently using these services to move data from ACD to Google
@nbyloff
Have a look at this https://www.reddit.com/r/AlienBlue/comments/1i13io/subreddit_links_r_and_username_links_u_are/~~
@ginsu0 @SR-G @mmozeiko @thenoahcomputer @thammi @calisro
I'm a newbie on this community so please be kind to me if I'm not compliance 100% with any terms or conditions that apply here :P
2017/05/18 22:35:07 Failed to create file system for "remote:foobar": failed to get endpoints: Get https://drive.amazonaws.com/drive/v1/account/endpoint: oauth2: cannot fetch token: 401 Unauthorized
@ncw i think it might be a good idea to create an "ACD status issue" (or forum post) which is locked and only you can post to, so people can subscribe to that and receive notifications/email updates from you, without all the non-info-comments other random users create. I just got this from Amazon:
<https://github.com/notifications/unsubscribe-auth/AbdVzXkONGiqNfjiscvNGUmhsEGkqPjhks5r7iUSgaJpZM4Ne9Ay>
something different... And I haven't found nothing close to "not min 5
please come in!" XD  ... Just for the record, where did you get that info
<https://github.com/notifications/unsubscribe-auth/AbdVzd1bLdBCt8HvoQ2cvnJGXAl-NIqnks5r7jMfgaJpZM4Ne9Ay>
@animosity22 wow! that's great , thanks for the evidence, I hope they don't start to apply their policies whenever is convinient for them (e.g. all the rclone+ACD users going to Gdrive XD ...) thanks a lot for the info :) , I'm working on a WA so far... but if I have no luck now I will consider migrating 100% Ok, so if we're all considering transferring our ACD content to Google, what's the best approach to use? What apps actually still work with ACD? Obviously we need something that's automated as many of us have multiple terabytes of data, so pulling it down manually is infeasible. Direct service-to-service would be ideal. We should create a sticky guide or something for this. MultCloud sounds interesting (multcloud.com), what others are there? @barnabyc
After numerous calls to Amazon Drive support (support is a loose word; they are not technically trained) I spoke to a gentlemen who knew about rclone being banned and about the acd_cli issues. He put me on hold and after about 10 minues came back with some startling news.
> Sadiq
rclone mount
I am not sure if this is a bug, a problem with my account (is usage of rclone mount detetactable and a violiation of their TOS) or is Amazon having problems with Cloud Drive offering?
rclone delete acd:/testfile.txt
rclone copy testfile.txt acd:/
rclone md5sum acd:/testfile.txt
What actually happens: It’s kind of random, but sometimes md5sum will return no output, yet nothing is written to stderr and it exits with 0.
{"contentUrl":"https://content-na.drive.amazonaws.com/cdproxy/","customerExists":true,"metadataUrl":"https://cdws.us-east-1.amazonaws.com/drive/v1/"}
{"data":[],"count":0}  <--- this is not normal, but rclone doesn't detect it as an error
(Speaking of consistency … it seems that sometimes `delete` and `cp` could happen in the wrong order.  Is that intended?) >The problem is due to the way rclone interprets the command line. When you say rclone md5sum acd:/testfile.txt rclone doesn't know if testfile.txt is a directory or a file.
Furthermore I realized a lot of these errors:
I'm mounting ACD with:
$ go get -u github.com/karalabe/xgo
ACD_CLI weird:
https://github.com/yadayada/acd_cli/pull/562 - "I created this pull request only to ask what happend to acd_cli's issues page?! It just vanished! "
Edit 2:  Now that stuff on ACD is encrypted using rclone, I'm worried that we won't be able to retrieve and decrypt the backup.  :( > Provided you can retrieve the files somehow, you can decrypt them with rclone locally very easily.
https://github.com/yadayada/acd_cli/pull/562#issuecomment-301816928
Accept-Encoding: gzip
Pragma: no-cache
Vary: User-Agent
I sure hope not, but let's see what @ncw can report back with.  @Em31Et It'll likely be because all the `acd_cli` users moved over to `rclone` when the former was banned from the ACD API, and sounds like `rclone` is going in a similar direction (although thank you @ncw for not being radio-silent!) Just wait for ncw's answer. It wouldn't be the first time that Amazon support gave wrong info and certainty not the first time someone would make something up. @jdrydn
This should dramatically limit the number of fraudulent key uses. rclone seems to be banned. good bye acd  Can we please stop speculating and wait for a reply. > Can we please stop speculating and wait for a reply.
https://www.reddit.com/r/DataHoarder/comments/47cln1/til_you_can_buy_an_unlimited_google_drive_account/d4i93zf/ @Miladiir I'm out of my trial but I'm going to chase for a refund - this is shocking!
Yea I agree but we all know acd_cli guys will rip other app keys until amazon bans them all :/  @ajkis I'm one of the "acd_cli guys" and we care about the outage just as much as you do. The difference in time between our outage and yours was short enough that blaming things on malice seems hasty.
We're waiting for word from @yadayada and you should wait for @ncw, and when one gets word we can all benefit.
Artur Bodera
abodera@gmail.com
I thinking HubiC... It is fast? @AiMAnsarie https://forum.rclone.org/t/rclone-has-been-banned-from-amazon-drive/2314
@gordan-bobic
> What exactly do you mean? AWS != ACD.
ACD
rclone -vvv mount Amazon:/ /Volumes/ACD
bup init
jacob@home:/Volumes/ACD$ bup init                                                                                                                                                                                                                                          │··
fatal: bad config file line 4 in /Volumes/ACD/.bup/config                                                                                                                                                                                                                  │··
jacob@home:/Volumes/ACD$
and the log from rclone is attached
`2017/05/13 16:10:02 ERROR : Fullmetal Alchemist - The Sacred Star of Milos (2011)/fanart.jpg: File not in Local file system at /home/mathias/movies`
ll /home/mathias/movies/Fullmetal\ Alchemist\ -\ The\ Sacred\ Star\ of\ Milos\ \(2011\)/fanart.jpg
-rw-rw-rw- 1 mathias mathias 177K May 12 01:49 /home/mathias/movies/Fullmetal Alchemist - The Sacred Star of Milos (2011)/fanart.jpg
2017/05/13 16:16:24 INFO  : Encrypted amazon drive root 'crypt/foo123': Modify window not supported
2017/05/13 16:16:24 INFO  : Encrypted amazon drive root 'crypt/foo123': Building file list
2017/05/13 16:16:32 NOTICE: Local file system at /home/mathias/movies: 0 files not in Encrypted amazon drive root 'crypt/foo123'
2017/05/13 16:16:32 NOTICE: Encrypted amazon drive root 'crypt/foo123': 12 files not in Local file system at /home/mathias/movies
2017/05/13 16:16:32 ERROR : Harry Potter and the Goblet of Fire (2005)/movieset-fanart.jpg: File not in Local file system at /home/mathias/movies
2017/05/13 16:16:32 ERROR : Fullmetal Alchemist - The Sacred Star of Milos (2011)/fanart.jpg: File not in Local file system at /home/mathias/movies
2017/05/13 16:16:32 ERROR : Fullmetal Alchemist - The Sacred Star of Milos (2011)/movie.nfo: File not in Local file system at /home/mathias/movies
2017/05/13 16:16:32 ERROR : Fullmetal Alchemist - The Sacred Star of Milos (2011)/Fullmetal Alchemist - The Sacred Star of Milos (2011) h264-720p AC3-6ch.mkv: File not in Local file system at /home/mathias/movies
2017/05/13 16:16:32 ERROR : Harry Potter and the Goblet of Fire (2005)/poster.jpg: File not in Local file system at /home/mathias/movies
2017/05/13 16:16:32 ERROR : Fullmetal Alchemist - The Sacred Star of Milos (2011)/movieset-fanart.jpg: File not in Local file system at /home/mathias/movies
2017/05/13 16:16:32 ERROR : Harry Potter and the Goblet of Fire (2005)/fanart.jpg: File not in Local file system at /home/mathias/movies
2017/05/13 16:16:32 ERROR : Harry Potter and the Goblet of Fire (2005)/movie.nfo: File not in Local file system at /home/mathias/movies
2017/05/13 16:16:32 ERROR : Fullmetal Alchemist - The Sacred Star of Milos (2011)/movieset-poster.jpg: File not in Local file system at /home/mathias/movies
2017/05/13 16:16:32 ERROR : Harry Potter and the Goblet of Fire (2005)/movieset-poster.jpg: File not in Local file system at /home/mathias/movies
2017/05/13 16:16:32 ERROR : Fullmetal Alchemist - The Sacred Star of Milos (2011)/poster.jpg: File not in Local file system at /home/mathias/movies
I thought this might be an issue with the long path and changed the movie name to "Fullmetall Alchemist" both on the local mount as well as on the encrypted Amazon Drive:
`mv Fullmetal\ Alchemist\ -\ The\ Sacred\ Star\ of\ Milos\ \(2011\) Fullmetal\ Alchemist`
2017/05/13 16:22:20 INFO  : Encrypted amazon drive root 'crypt/foo123': Modify window not supported
2017/05/13 16:22:20 INFO  : Encrypted amazon drive root 'crypt/foo123': Building file list
2017/05/13 16:22:31 NOTICE: Local file system at /home/mathias/movies: 0 files not in Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4'
2017/05/13 16:22:31 NOTICE: Encrypted amazon drive root 'crypt/foo123': 12 files not in Local file system at /home/mathias/movies
2017/05/13 16:22:31 ERROR : Harry Potter and the Goblet of Fire (2005)/fanart.jpg: File not in Local file system at /home/mathias/movies
2017/05/13 16:22:31 ERROR : Harry Potter and the Goblet of Fire (2005)/movieset-poster.jpg: File not in Local file system at /home/mathias/movies
2017/05/13 16:22:31 ERROR : Harry Potter and the Goblet of Fire (2005)/poster.jpg: File not in Local file system at /home/mathias/movies
2017/05/13 16:22:31 ERROR : Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005)/Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005) h264-720p AC3-6ch.mkv: File not in Local file system at /home/mathias/movies
2017/05/13 16:22:31 ERROR : Harry Potter and the Goblet of Fire (2005)/movieset-fanart.jpg: File not in Local file system at /home/mathias/movies
2017/05/13 16:22:31 ERROR : Harry Potter and the Goblet of Fire (2005)/movie.nfo: File not in Local file system at /home/mathias/movies
2017/05/13 17:41:07 INFO  : Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4': Modify window not supported
2017/05/13 17:41:07 INFO  : Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4': Building file list
2017/05/13 17:41:16 NOTICE: Local file system at /home/mathias/movies: 5 files not in Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4'
2017/05/13 17:41:16 ERROR : fanart.jpg: File not in Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4'
2017/05/13 17:41:16 ERROR : movie.nfo: File not in Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4'
2017/05/13 17:41:16 ERROR : poster.jpg: File not in Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4'
2017/05/13 17:41:16 ERROR : movieset-fanart.jpg: File not in Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4'
2017/05/13 17:41:16 NOTICE: Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4': 12 files not in Local file system at /home/mathias/movies
2017/05/13 17:41:16 ERROR : Harry Potter and the Goblet of Fire (2005)/movieset-poster.jpg: File not in Local file system at /home/mathias/movies
2017/05/13 17:41:16 ERROR : Harry Potter and the Goblet of Fire (2005)/fanart.jpg: File not in Local file system at /home/mathias/movies
2017/05/13 17:41:16 ERROR : Harry Potter and the Goblet of Fire (2005)/movie.nfo: File not in Local file system at /home/mathias/movies
2017/05/13 17:41:16 ERROR : Harry Potter and the Goblet of Fire (2005)/movieset-fanart.jpg: File not in Local file system at /home/mathias/movies
2017/05/13 17:41:16 ERROR : Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005)/Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005) h264-720p AC3-6ch.mkv: File not in Local file system at /home/mathias/movies
2017/05/13 17:41:16 ERROR : Harry Potter and the Goblet of Fire (2005)/poster.jpg: File not in Local file system at /home/mathias/movies
2017/05/13 17:38:56 INFO  : Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4/fgha5hfu12bh81bpketfle02qi3ku8tum470bh4l3p6lc3ehvv0gjo1olt9eq4h8hp2hoarinqbp2': Modify window not supported
2017/05/13 17:38:56 INFO  : Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4/fgha5hfu12bh81bpketfle02qi3ku8tum470bh4l3p6lc3ehvv0gjo1olt9eq4h8hp2hoarinqbp2': Building file list
2017/05/13 17:38:56 NOTICE: Local file system at /home/mathias/movies/Harry Potter and the Goblet of Fire (2005): 0 files not in Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4/fgha5hfu12bh81bpketfle02qi3ku8tum470bh4l3p6lc3ehvv0gjo1olt9eq4h8hp2hoarinqbp2'
2017/05/13 17:38:56 NOTICE: Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4/fgha5hfu12bh81bpketfle02qi3ku8tum470bh4l3p6lc3ehvv0gjo1olt9eq4h8hp2hoarinqbp2': 0 files not in Local file system at /home/mathias/movies/Harry Potter and the Goblet of Fire (2005)
2017/05/13 17:38:56 NOTICE: Local file system at /home/mathias/movies/Harry Potter and the Goblet of Fire (2005): 6 hashes could not be checked
13229470679 2017-05-10 07:56:55.682000000 Harry Potter and the Goblet of Fire (2005) h264-1080p DTS-6ch.mkv
679788 2017-05-10 07:46:41.336000000 fanart.jpg
➜  ~ rclone lsl amzcrypt:"movies/Harry Potter and the Goblet of Fire (2005)"
679788 2017-05-10 07:46:41.336000000 fanart.jpg
13229470679 2017-05-10 07:56:55.682000000 Harry Potter and the Goblet of Fire (2005) h264-1080p DTS-6ch.mkv
2017/05/17 15:58:41 INFO  : Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4': Modify window not supported
2017/05/17 15:58:41 INFO  : Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4': Building file list
2017/05/17 15:58:49 NOTICE: Local file system at /home/mathias/movies: 0 files not in Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4'
2017/05/17 15:58:49 NOTICE: Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4': 12 files not in Local file system at /home/mathias/movies
2017/05/17 15:58:49 ERROR : Harry Potter and the Goblet of Fire (2005)/fanart.jpg: File not in Local file system at /home/mathias/movies
2017/05/17 15:58:49 ERROR : Harry Potter and the Goblet of Fire (2005)/movieset-fanart.jpg: File not in Local file system at /home/mathias/movies
2017/05/17 15:58:49 ERROR : Harry Potter and the Goblet of Fire (2005)/movieset-poster.jpg: File not in Local file system at /home/mathias/movies
2017/05/17 15:58:49 ERROR : Harry Potter and the Goblet of Fire (2005)/poster.jpg: File not in Local file system at /home/mathias/movies
2017/05/17 15:58:49 ERROR : Harry Potter and the Goblet of Fire (2005)/movie.nfo: File not in Local file system at /home/mathias/movies
2017/05/17 15:58:49 ERROR : Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005)/Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005) h264-720p AC3-6ch.mkv: File not in Local file system at /home/mathias/movies
2017/05/17 15:58:52 INFO  : Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4': Modify window not supported
2017/05/17 15:58:52 INFO  : Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4': Building file list
2017/05/17 15:59:01 NOTICE: Local file system at /Volumes/Movies: 0 files not in Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4'
2017/05/17 15:59:01 NOTICE: Encrypted amazon drive root 'crypt/an8cshp5kb3h1kbs0obmle96e4': 0 files not in Local file system at /Volumes/Movies
./Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005)
./Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005)/movieset-poster.jpg
./Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005)/movieset-fanart.jpg
./Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005)/Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005) h264-720p AC3-6ch.mkv
./Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005)/movie.nfo
./Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005)/fanart.jpg
./Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005)
./Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005)/movieset-poster.jpg
./Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005)/movieset-fanart.jpg
./Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005)/Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005) h264-720p AC3-6ch.mkv
./Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005)/movie.nfo
./Ghost in the Shell - Stand Alone Complex - Individual Eleven (2005)/fanart.jpg
($GOPATH not set)
($GOPATH not set)
($GOPATH not set)
$ export GOPATH
/mnt/4tb/home/tange/go/src/github.com/ncw/rclone/vendor/bufio (vendor tree)
/mnt/4tb/home/tange/go/src/bufio (from $GOROOT)
/mnt/4tb/home/tange/tmp/rclone/src/bufio (from $GOPATH)
Bit from the log:
Debian Jessie 64 bit
/scratch/rclone.creds /srv/ gdrive-backu
```bash
declare -a paths=(
"PathA/"
"PathB/"
Debian, 64 bit
Thanks so much and hope that helps a bit wiht my odd issue.
@ncw sounds good! :) any idea when rclone will continue after a permission issue?
Debian 8.7 x64
The header of file contain "RCLONE".
I don't know if that intentional for reference that rclone could detect to find which is encrypted version.
What's the issue exactly? that instead of appearing as random data, the data is broadcasting its origin as 'rclone'  Added Ohio and London S3 regions.  some comments on this PR:
Some weird stuff happened yesterday,  after I restarted my server I could not mount acd (gdrive mounted normally ) with latest rclone version.
Not sure what changed in last few versions.
> 2017/04/25 21:02:17 INFO  : Encrypted amazon drive root 'crypt': Modify window not supported
Its weird, i think it was fluke that instantly remounted with old version.
eg if you do `stat /mnt/acdcrypt/testfile`  it will wait for long time before reporting any error. same goes if you try to list folders.
@ncw any chance rclone ignoring certain slow connections and just request a new one.  I'm using crypt on an underlying Amazon Cloud drive, wanting to keep most-recent backup copies of some local directory trees.  Experimenting with the options I saw that a second or later copy operation only picks local files to copy if they are new (never before copied up) or the size is different. I understand this is because ACD does not allow setting the modification time and so it is not checked, and crypt does not support comparing the file hashes.
2017/04/25 07:03:22 INFO  : Encrypted amazon drive root 'Vault/dmi0e2fbj6btggkj33t5dtqmo4': Modify window not supported
2017/04/25 07:03:22 DEBUG : Encrypted amazon drive root 'Vault/dmi0e2fbj6btggkj33t5dtqmo4': Mounting on "/data/.Vault"
2017/04/25 07:03:22 DEBUG : Encrypted amazon drive root 'Vault/dmi0e2fbj6btggkj33t5dtqmo4': Root()
2017/04/25 07:03:36 DEBUG : Shows/Stargate Atlantis: Reading directory
2017/04/25 07:03:46 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 0 to 29032448 (io.Seeker)
2017/04/25 07:03:46 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.Read io.Seeker failed: read tcp 100.96.1.15:47550->54.210.218.200:443: i/o timeout
2017/04/25 07:03:46 ERROR : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.Read error: low level retry 1/10: read tcp 100.96.1.15:47550->54.210.218.200:443: i/o timeout
2017/04/25 07:03:46 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 0 to 29032448
2017/04/25 07:03:51 DEBUG : pacer: low level retry 1/10 (error Get https://content-na.drive.amazonaws.com/cdproxy/templink/Sc8AtRpwXouEvZdrU9KpIpVisi0QNp9EZK5P3aFR8CY38XJVg: net/http: timeout awaiting response headers)
2017/04/25 07:04:01 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 29163520 to 29298688 (io.Seeker)
2017/04/25 07:04:01 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.Read io.Seeker failed: read tcp 100.96.1.15:35808->54.86.32.231:443: i/o timeout
2017/04/25 07:04:01 ERROR : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.Read error: low level retry 1/10: read tcp 100.96.1.15:35808->54.86.32.231:443: i/o timeout
2017/04/25 07:04:01 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 29163520 to 29298688
2017/04/25 07:04:04 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 29429760 to 29163520 (io.Seeker)
2017/04/25 07:04:12 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.Read size 4096 offset 29294592
2017/04/25 07:04:18 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 29298688 to 29564928 (io.Seeker)
2017/04/25 07:04:18 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.Read io.Seeker failed: read tcp 100.96.1.15:47704->54.210.218.200:443: i/o timeout
2017/04/25 07:04:18 ERROR : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.Read error: low level retry 1/10: read tcp 100.96.1.15:47704->54.210.218.200:443: i/o timeout
2017/04/25 07:04:18 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 29298688 to 29564928
2017/04/25 07:04:23 DEBUG : pacer: low level retry 1/10 (error Get https://content-na.drive.amazonaws.com/cdproxy/templink/Sc8AtRpwXouEvZdrU9KpIpVisi0QNp9EZK5P3aFR8CY38XJVg: net/http: timeout awaiting response headers)
2017/04/25 07:04:28 DEBUG : pacer: low level retry 2/10 (error Get https://content-na.drive.amazonaws.com/cdproxy/templink/Sc8AtRpwXouEvZdrU9KpIpVisi0QNp9EZK5P3aFR8CY38XJVg: net/http: timeout awaiting response headers)
2017/04/25 07:04:37 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 29696000 to 29429760 (io.Seeker)
2017/04/25 07:04:39 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.Read size 4096 offset 29560832
2017/04/25 07:04:41 ERROR : Movies/Snow White and the Seven Dwarfs (1937)/Snow White and the Seven Dwarfs (1937) - [360p, DivX, MP3].avi: ReadFileHandle.Read error: low level retry 1/10: read tcp 100.96.1.15:54440->52.200.128.166:443: i/o timeout
2017/04/25 07:04:44 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 29564928 to 29696000 (io.Seeker)
2017/04/25 07:04:44 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.Read io.Seeker failed: read tcp 100.96.1.15:60754->52.1.173.13:443: i/o timeout
2017/04/25 07:04:44 ERROR : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.Read error: low level retry 1/10: read tcp 100.96.1.15:60754->52.1.173.13:443: i/o timeout
2017/04/25 07:04:44 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 29564928 to 29696000
2017/04/25 07:04:49 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 29827072 to 29831168 (io.Seeker)
2017/04/25 07:04:53 DEBUG : Shows/Stargate Atlantis: Re-reading directory (1m17.191310296s old)
2017/04/25 07:04:53 DEBUG : Shows/Stargate Atlantis/Season 03: Re-reading directory (1m17.140085959s old)
2017/04/25 07:04:54 DEBUG : pacer: low level retry 1/10 (error Get https://content-na.drive.amazonaws.com/cdproxy/templink/Sc8AtRpwXouEvZdrU9KpIpVisi0QNp9EZK5P3aFR8CY38XJVg: net/http: timeout awaiting response headers)
2017/04/25 07:05:02 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.Read size 4096 offset 29827072
2017/04/25 07:05:02 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 29962240 to 29827072 (io.Seeker)
2017/04/25 07:05:06 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 0 to 29949952 (io.Seeker)
2017/04/25 07:05:08 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 30146560 to 30150656 (io.Seeker)
2017/04/25 07:05:11 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.Read size 4096 offset 30146560
2017/04/25 07:05:11 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 30281728 to 30146560 (io.Seeker)
2017/04/25 07:05:24 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 30150656 to 30416896 (io.Seeker)
2017/04/25 07:05:28 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 30547968 to 30281728 (io.Seeker)
2017/04/25 07:05:32 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.Read size 4096 offset 30412800
2017/04/25 07:05:33 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 30416896 to 30547968 (io.Seeker)
2017/04/25 07:05:43 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 30679040 to 30683136 (io.Seeker)
2017/04/25 07:05:47 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.Read size 4096 offset 30679040
2017/04/25 07:05:47 DEBUG : Shows/Stargate Atlantis/Season 03/Stargate Atlantis - S03E11 - The Return, Part 2 [720p, x265, AAC].mp4: ReadFileHandle.seek from 30814208 to 30679040 (io.Seeker)
2017/04/25 07:05:56 DEBUG : pacer: low level retry 2/10 (error Get https://content-na.drive.amazonaws.com/cdproxy/templink/Sc8AtRpwXouEvZdrU9KpIpVisi0QNp9EZK5P3aFR8CY38XJVg: net/http: timeout awaiting response headers)
That would be the dream ;-) Thanks Nick. I'll check out those suggestions.
> <https://github.com/notifications/unsubscribe-auth/ABfZIxQY1K3xIlbaFYGUS7JKU0FaUVusks5rzbfbgaJpZM4NHFHs>
All files on acdDE get new mod times, since amazon does not support mod time changes.
sync acdDE: gdrive:
sync /local/ acd:
sync acd: gdrive
- Yes there is an API limit
Rclone 1.36
While this is a wild guess it would explain the strange behavior where rclone appeared to be completely stuck opening a network connection. Same issue here, doing only server side copies, 7 mins and 7 files copied. When running with `-vv --dump-bodies`, I get a lot of warnings about rate limits:
Unsure if this is the most efficient way of writing this. Let me know if there's a better way. I've never written anything in Go before :-)  Hi,
It only seemed to be applicable in listAll() @ncw sure I'll take a crack at that.  After typing: rclone sync /home/michaldybczak/GoogleDrive/ remote:Backup
yaourt -S --noconfirm snapd
> manager (and i found rclone browser in AUR)
> <https://github.com/notifications/unsubscribe-auth/AKWhGp6Tl2B2cIPHhRFRnBfxGfztijJ_ks5r0uligaJpZM4NFKEz>
Here is LZ4 source in GO language:
Unhappily I still don't code in Go, but I can try to learn some stuff and give a hand in case someone can guide me. I currently code in C, Python and Javascript.  This is the command I am using:
actually I'm not certain if it's B2 or Dropbox complaining about too many requests in this case.. but whichever it is.. is there a way to slow it down so it doesn't do this?
Host: api001.backblazeb2.com
Accept-Encoding: gzip
{"accountId":"fiuhsdfijhsdfgh","bucketName":"bucketName","bucketType":"allPrivate"}
"code": "duplicate_bucket_name",
Host: api001.backblazeb2.com
Accept-Encoding: gzip
{"bucketId":"hdsjhasdlhasdihasdjhasdh","startFileName":"DEV/DEV/","maxFileCount":1000,"prefix":"DEV/DEV/","delimiter":"/"}
Accept-Encoding: gzip
- credentials as env vars
- EC2 IAM role
Expandrive is a commercial app btw  The whole thing is indeed very weird man  yep seems like its fixed now problem solved, rclone sync is suddenly working again :) they must have fixed something on the ACD side.
rclone -vv copy gdrive:/Documents/Printscreen /media/gdrive/Documents/Printscreen/ @ErAzOr2k
{"url": "https://docs.google.com/open?id=aaabbbccc",
"doc_id": "aaabbbccc",
"resource_id": "document:aaabbbccc"}
Thanks :) I would use Popen
> ./rclone lsd EGD:/ | grep Kamisama
> -1 2016-11-25 18:42:37        -1 [Commie] Kamisama Hajimemashita [BD 720p AAC]
> -1 2016-11-23 23:02:07        -1 [Commie] Kamisama Hajimemashita 2 [BD 720p AAC]
> rclone lsd EGD:/ | grep Kamisama
> -1 2016-11-25 18:42:37        -1 [Commie] Kamisama Hajimemashita [BD 720p AAC]
Everything has been uploaded from acd with `rclone v1.36`. About 300 folders at this point. Something is off with latest beta
24.04.2017/13:47 ACD: It took 201 seconds
Well I just find out that this problem is from 1.36
```bash
* Season 6/Hawaii.Five-0.S06E01.720p.WEB-DL.x264.350MB-Pahe.in.mkv
* Season 6/Hawaii.Five-0.S06E02.720p.WEB-DL.x264.350MB-Pahe.in.mkv
* Season 6/Hawaii.Five-0.S06E03.720p.WEB-DL.x264.350MB-Pahe.in.mkv
* Season 6/Hawaii.Five-0.S06E04.720p.WEB-DL.x264.350MB-Pahe.in.mkv
hash
There are probably some more considerations I'm forgetting. Did you check how/what https://github.com/astrada/google-drive-ocamlfuse is storing, since report is that its working the best.
Complexity -
![metadataschema](https://cloud.githubusercontent.com/assets/1829789/25069148/5c7178e4-22ab-11e7-8e25-b83f3e5bac57.png)
Debian 8.7
Multiple
OR
$ ./rclone -vv copy test\\:directory acd:.tmp/
$ ./rclone ls acd:.tmp ; echo $?
https://github.com/cnbeining/onedrivecmd
Thanks!  @animosity22 ,
Had this issue as well with B2.
--- a/fs/operations.go
+++ b/fs/operations.go
hubic
rclone lsd hubic-fdc:
$ ~/go/bin/rclone -vv lsd hubi-fdc:
rather then the underlying Fs root (which may be unreadable
When I try to name a folder on a crypted remote to "Avatar The Last Airbender", I get a garbled result.
-1 2017-04-07 04:53:21        -1 Bwbubs Uif Mbtu Bjscfoefs
(Note: I know which garbled filename to look for in the example above after trying to figure out what was happening - I don't know if it is predictable, but it is consistent.)
2017/04/07 07:01:33 NOTICE: Bwbubs Uif Mbtu Bjscfoefs: Encrypts to "0.Bwbubs Uif Mbtu Bjscfoefs"
-1 2017-04-07 05:01:28        -1 0.Bwbubs Uif Mbtu Bjscfoefs
I also seem to be seeing the same bug with the folder name "Fullmetal Alchemist Brotherhood":
-1 2017-04-06 07:06:01        -1 Fullmetal Alchemist
-1 2017-04-07 05:37:17        -1 Gvmmnfubm Bmdifnjtu Cspuifsippe
2017/04/07 07:38:52 NOTICE: Gvmmnfubm Bmdifnjtu Cspuifsippe: Encrypts to "0.Gvmmnfubm Bmdifnjtu Cspuifsippe"
-1 2017-04-07 05:37:17        -1 Gvmmnfubm Bmdifnjtu Cspuifsippe
-1 2017-04-07 05:37:17        -1 0.Gvmmnfubm Bmdifnjtu Cspuifsippe
-1 2017-04-07 05:40:21        -1 Fullmetal Alchemist brotherhood
And with added -vv
2017/04/07 07:52:12 INFO  : Encrypted amazon drive root 'crypt/170.oq/0.Bwbubs Uif Mbtu Bjscfoefs': Modify window not supported
2017/04/07 07:52:12 DEBUG : Encrypted amazon drive root 'crypt/170.oq/0.Bwbubs Uif Mbtu Bjscfoefs': Using server side directory move
2017/04/07 07:52:13 INFO  : Encrypted amazon drive root 'crypt/170.oq/0.Bwbubs Uif Mbtu Bjscfoefs': Server side directory move succeeded
`2017/04/09 15:14:07 INFO  : Encrypted amazon drive root '114.fGBpxntr nHGEr/16.BE6/104.Kls Krs/24.XQJLPMEBOB/233.HAtvzwolyl - ZlClu'z ayhClsz (YlAhps) (6447) [MUa]': Modify window not supported
2017/04/09 15:14:07 INFO  : Encrypted amazon drive root '114.fGBpxntr nHGEr/16.BE6/104.Kls Krs/24.XQJLPMEBOB/233.HAtvzwolyl - ZlClu'z ayhClsz (YlAhps) (6447) [MUa]': Waiting for checks to finish
2017/04/09 15:14:07 INFO  : Encrypted amazon drive root '114.fGBpxntr nHGEr/16.BE6/104.Kls Krs/24.XQJLPMEBOB/233.HAtvzwolyl - ZlClu'z ayhClsz (YlAhps) (6447) [MUa]': Waiting for transfers to finish
BTW sorry for my english, it's not my native language.
$ rclone copy asdf foo:TV/asdf
$ rclone ls foo:TV
$ rclone moveto foo:TV/asdf foo:"TV/Avatar The Last Airbender"
$ rclone ls foo:TV
0 JEjCjA cqn UjBC JrAknwmnA/x1
$ rclone ls Amazon:foo
32 170.XZ/0.JEjCjA cqn UjBC JrAknwmnA/169.A5
Changing one character - eg "Avatar the Last Airbender" caused a different rotate distance to be calculated which didn't suffer the problem.
3) kludge things; if the sum is calculated as 0 then make it 1
$ rclone ls Amazon:foo
32 0.79-jCvxByqnAn-BqxnB-owC.Fvj
+++ b/crypt/cipher.go
num := ciphertext[:pos]
return ciphertext[pos+1:], nil
{NameEncryptionOff, "1/12/123.bix", "", ErrorNotAnEncryptedFile},
``` It's been in the obfuscate code since that function was introduced; change 6e003934fc1e8fb1fd4b6a549dcda0d964c1a4e4, and which was merged in on March 29th; https://github.com/ncw/rclone/pull/1235
@naeloob There's a test for the "." before that, and the num variable is set to everything before the "."
num := ciphertext[:pos]
That 1 in 256 files is a bit scary.  Having put ~10T of stuff up into ACD over the last couple of weeks it'd be great if there was some way of programmatically identifying which files/folders have been affected. :) @drsmithy if you look at the raw filenames from the unencrypted store (eg "rclone ls Amazon:base_dir") then any filename beginning "0." is impacted.  To compare that to a local tree you'd need to do an "rclone ls acd-my-user-encrypted" and then compare the results to a local "find . -type f" (with sorting and filtering; it's a simple script).  Directory misnames (as in your "Airbender" example) are the most annoying, because every file in that directory is good, but the directory name is bad.
Termux 0.48
And, I did NOT see anything, especially NOT like this: `SSH_AUTH_SOCK=/tmp/ssh-Sj7JaoojWnEb/agent.3807`
`Agent pid 6997`
I'm not very knowledgable about SSH, so not sure what to do with this.
Thanks! @dogear42, what happens if you try to ssh directly into the server. Does it work when you're using the key, e.g. passwordless? And when you run `env | grep -i SSH` *after* running `$ eval "$(ssh-agent -s)"` does that return anything different?
drive and s3
2017/04/04 13:16:08 Music/aKING/Dutch Courage/AKING - My Last Words.mp3: Copied (new)
```bash
```bash
$ rclone sync a b --dry-run --verbose
Very very little software expects filesystems to be intermittently available. Well written software will handle EINTR (which could help simplifying the implementation) but even that probably can't be relied on.  Hi Everyone... just tried RClone for the first time. Read for about 20 mins but could not get it straight.
type = crypt
password = ***
password2 = ***
2017/04/01 14:32:52 Encrypted amazon drive root 't1/2gg8tqhmpm0ve4dphjipib63ag': Waiting for checks to finish
2017/04/01 14:32:52 Encrypted amazon drive root 't1/2gg8tqhmpm0ve4dphjipib63ag': Waiting for transfers to finish
Note the encrypted name "2gg8tqhmpm0ve4dphjipib63ag" shows.
2017/04/01 14:32:52 Encrypted amazon drive root 't1/2gg8tqhmpm0ve4dphjipib63ag': Waiting for checks to finish
`2017/04/01 14:49:17 NOTICE: 2/3/4/test.bat: Encrypts to "lbqinral9u0q4n606ktfg3sv9o/ehcv2ub4h3ctk1a33rt9squp7s/86o08gq4a1ll0iqs9k8l2t5fdc/ju2s03qfolbenrbuen793ep0ik"`.
2017/04/01 17:13:17 INFO  : Encrypted amazon drive root 't1/4n5hj7nl3mvq98ekhjfceth090': Modify window not supported
2017/04/01 17:13:18 INFO  : Encrypted amazon drive root 't1/4n5hj7nl3mvq98ekhjfceth090': Waiting for checks to finish
2017/04/01 17:13:18 INFO  : Encrypted amazon drive root 't1/4n5hj7nl3mvq98ekhjfceth090': Waiting for transfers to finish
The INFO messages don't display the "testdir" value at all. Ah, I see; the String() function is implemented in each filesystem type, and the one for crypt just calls the underlying filesystems entry.  We can simply just use the values the user entered from the crypt's Fs object, and not the lower one.  Hopefully pull #1321 is good!  Just a one line change.  I noticed that I've been getting lots of EOFs. I'm not quite sure when it started (I've always noticed some, but they seem exorbitant as of the last month or two). Any thoughts on what might be causing it? Environment is pretty solid and hasn't changed much since the inception.
2017-04-01T05:02:40.965201881Z 2017/04/01 05:02:40 ERROR : Shows/The Good Wife/Season 06/The Good Wife - S06E01 - The Line [720p, x264, AC3, HDTV].mkv: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
2017-04-01T05:11:58.907780490Z 2017/04/01 05:11:58 ERROR : Shows/The Originals/Season 02/The Originals - S02E11 - Brotherhood of the Damned [480p, x264, AAC, HDTV].mp4: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
2017-04-01T05:19:23.613111082Z 2017/04/01 05:19:23 ERROR : Unsorted/Stargate Atlantis Complete BDRip 720p HighCode-PHD/1x06 - Childhood's End.mkv: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
2017-04-01T05:22:34.760728381Z 2017/04/01 05:22:34 ERROR : Unsorted/Stargate Atlantis Complete BDRip 720p HighCode-PHD/1x08 - Underground.mkv: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
2017-04-01T05:24:29.729780332Z 2017/04/01 05:24:29 ERROR : Unsorted/Stargate Atlantis Complete BDRip 720p HighCode-PHD/1x16 - The Brotherhood.mkv: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
2017-04-01T05:26:01.030842298Z 2017/04/01 05:26:01 ERROR : Unsorted/Stargate Atlantis Complete BDRip 720p HighCode-PHD/1x03 - Hide and Seek.mkv: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
2017-04-01T05:31:18.109597921Z 2017/04/01 05:31:18 ERROR : Unsorted/Stargate Atlantis Complete BDRip 720p HighCode-PHD/1x15 - Before I Sleep.mkv: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
2017-04-01T05:31:34.705379546Z 2017/04/01 05:31:34 ERROR : Unsorted/Stargate Atlantis Complete BDRip 720p HighCode-PHD/1x03 - Hide and Seek.mkv: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
2017-04-01T05:33:25.055724905Z 2017/04/01 05:33:25 ERROR : Unsorted/Stargate Atlantis Complete BDRip 720p HighCode-PHD/1x01&02 - Rising.mkv: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
2017-04-01T05:40:55.050371802Z 2017/04/01 05:40:55 ERROR : Shows/The Blacklist/Season 01/The Blacklist - S01E04 - The Stewmaker [480p, x264, AAC, HDTV].mp4: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
2017-04-01T05:41:02.370229610Z 2017/04/01 05:41:02 ERROR : Unsorted/Stargate Atlantis Complete BDRip 720p HighCode-PHD/1x10 - The Storm.mkv: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
2017-04-01T05:42:14.096481903Z 2017/04/01 05:42:14 ERROR : Unsorted/Stargate Atlantis Complete BDRip 720p HighCode-PHD/1x11 - The Eye.mkv: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
2017-04-01T05:43:22.988310494Z 2017/04/01 05:43:22 ERROR : Unsorted/Stargate Atlantis Complete BDRip 720p HighCode-PHD/1x11 - The Eye.mkv: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
2017-04-01T05:44:00.095084056Z 2017/04/01 05:44:00 ERROR : Unsorted/Stargate Atlantis Complete BDRip 720p HighCode-PHD/1x06 - Childhood's End.mkv: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
2017-04-01T05:47:21.883020070Z 2017/04/01 05:47:21 ERROR : Unsorted/Stargate Atlantis Complete BDRip 720p HighCode-PHD/1x15 - Before I Sleep.mkv: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
2017-04-01T05:48:11.037397638Z 2017/04/01 05:48:11 ERROR : Unsorted/Stargate Atlantis Complete BDRip 720p HighCode-PHD/1x09 - Home.mkv: ReadFileHandle.Read error: low level retry 1/10: unexpected EOF
ACD with Crypt
quite a bit more.
> complicated that code!
> <https://github.com/notifications/unsubscribe-auth/ABfZI1f4_4k5ZMpEWYnewwS4nOc0A1Pbks5rukt3gaJpZM4MwYY1>
The ugly way (how rclone size works currently):
secret:/       1099511627776        0 1099511627776   0% /tmp/google
Distributor ID:	Debian
Codename:	jessie
ACD
This is a crypt mount as well.
If it helps folks, I did post on the plex forums to try to identify the cause but have yet to find an answer.
But it is really weird the only reason for this happening now is onedrive changing their api.
Unfortunately  `PathEscape` is only available in go 1.8
I'm not sure if this is something else that changed with OneDrive or just something specific
Hey yonjah, what are the steps to build rclone with your changes?
I would also backup `rclone` config path where the token is kept just in case  @yonjah
deleted: false,
rclone sync dir amazon:/Backup/dir
Raspbian
Bit of an edge case but can be serious. Noticed because my Raspberry Pi only has 32gb and the file system quickly becomes full. Could cause loss of data if rclone is backing up to an encrypted remote and there is no backup of the config file.
I notice quite few weird issues with rclone ACD mount:
I also noticed performance impact ( lower speed ) on prolonge mounts eg when ACD was not remounted in 24h ( need more testing ) but something weird is going on.
I'm not sure if I ran into a bug or need some advice.
`rclone lsd foo:`
It would be extra handy if rather than making the chunks evenly spaced, they were of configurable size, so the front of the file would be downloaded first (e.g. 2 threads with 100MB chunks would get 0-100MB and 100-200MB simultaneously before a thread that finished would start 200-300MB chunk. This would be handy for uses such as media streaming to reduce the time before the file could be reasonably streamed from the beginning before the download actually completed. It would also probably be best if the file was created sparse with the full size of the source file at the very beginning to avoid confusing applications that are reading the file. It would make a lot of difference with streaming since sometimes single file copy from ACD is beyond terrible. eg you can get from normal 20MB-60MB speed down to 100k and repeating download few seconds later it will work normally as well.
rclone.exe copy --verbose "C:\Users\abcd\super long test title" "mysftpremote:super long test title"
2017/03/23 20:18:41 DEBUG : rclone: Version "v1.36-05-g216499dβ" starting with parameters ["rclone.exe" "copy" "-vv" "C:\\Users\\abcd\\super long test title" "mysftpremote:super long test title"]
2017/03/23 20:18:43 DEBUG : rclone: Version "v1.36-05-g216499dβ" finishing with parameters ["rclone.exe" "copy" "-vv" "C:\\Users\\abcd\\super long test title" "mysftpremote:super long test title"]
When executing the above command, it creates an extra folder in my sftp remote that has the name "super long test title\even longer super test title" (without the quotes) and is empty. This also occurs in crypt mode for this sftp remote. It appears to correctly upload the folders otherwise, and all subfolders and files in those folders.
In my case, the folders `rclone` got confused about weren't insanely long as they were for the OP but they did have Cyrillic names; the names were OK on the remote but the effect was exactly as the OP reported: say, I have a hierarchy which looked like this:
and when told to sync `Pictures` "here" to `Pictures` "there",
on the remote side`rclone` created (literally):
The issue with ACD seems sporadic and looks like the result of rate limiting on API connections across multiple users. The worst part is when a file transfer finishes, the data appears to go missing and must be retried from scratch.  When filing an issue, please include the following information if possible as well as a description of the problem.  Make sure you test with the latest beta of rclone.
Spawned from #1231
wait $!
fatal error: newosproc
Logs
2017/03/19 22:13:44 Movies/Interstellar (2014)/Interstellar(BR-Disk).mkv: Upload error detected but didn't finish upload: Post https://content-na.drive.amazonaws.com/cdproxy/nodes?suppress=deduplication: read tcp 10.56.12.0:18627->52.87.95.159:443: read: connection reset by peer ("HTTP status UNKNOWN")
2017/03/19 22:13:44 Movies/Interstellar (2014)/Interstellar(BR-Disk).mkv: Received error: Post https://content-na.drive.amazonaws.com/cdproxy/nodes?suppress=deduplication: read tcp 10.56.12.0:18627->52.87.95.159:443: read: connection reset by peer - low level retry 1/10
(I use ACD with crypt)
![rclonelogo](https://cloud.githubusercontent.com/assets/2767425/24073592/9cc0c938-0c1f-11e7-8e8d-b5ff6a24396a.png)
> [image: rclonelogo]
I just started playing with the fonts. Few thoughts on the choice of fonts...
That said, I am open to any feedback on fonts or the direction we are taking :)
I have done some quick variations based on the inputs you have given...
@ncw Anything else we need apart from the logo?  Btw, the current tagline for rclone is ``` rsync for cloud storage ```. Modified it to ``` rsync for the cloud ```. Let me know if that is fine :-)  I like the logo but the readability on the tagline is pretty low and I can only imagine it would be worse at a smaller size. Wow ! Pretty Logo !
The color gradient is a bit strange
Related issue: #1244
macOS
Vincèn Just copied the .rclone.conf from a Debian server to my windows pc to try out Rclone Browser and yes the crypt storage works. Thanks for confirmation and fact it's also cross-platform :+1:   > What is your rclone version (eg output from `rclone -V`)
I need to use a custom token because when I was trying to upload I recieved.
https://<50-character-hex-id>-apidata.googleusercontent.com/download/drive/v3/files/<fileId>?qk=<base64-encoded-auth-string>
It would be good to support Aliyun OSS ("Object Storage Service") as a supported cloud provider.
Repeating the test for an encrypted onedrive remote get slightly different result; if the backup-dir does not exist you just get an error instead of the old file ending up in the root folder:
And I'm not sure how we'd handle filenames that have characters from multiple ranges (eg "A1\x0130\x0230") which would have potentially three different distance calculations. The problem is that we need to store the distance in the filename so that we can de-obfuscate (eg for "rclone ls").  That's why it's just an obfuscation (easily reversed) and not an encryption.
Thoughts? The problem is a "collision" one.
32 53.!!jgnnq
32 125.2345.LMPKyJ
ia/EACD/ &
chmod 777 /media/eacd/
(I might send a PR to fix but don't count on it :) )  Similar to #281 but for encrypted backends:
Encrypted amazon drive root 'Vault/dmi0e2fbj6btggkj33t5dtqmo4/j4jctgmgj50nsvqtbd2gb0o8ig/4nbenmipf0htppnrq2hmqaqk40/7em7kl21js9ribn89uaqsr0nkc': Modify window not supported
etltv0troceojn8bb67iqal3vnbt66jg5vcnoqmv1i2i1e18442nhdv1ob09c03edpcdedlcuf3aoa0h0v28puvbilivtade7rj4r40
The newly copied file actually being the etltv0troc... file (which is outside of the encrypted root and not part of the directory path it should be in)
2017/03/12 08:01:26 DEBUG : rclone: Version "v1.35-164-g488353cβ" starting with parameters ["rclone" "--config" "/etc/rclone/rclone.conf" "copyto" "/data/.Local/Shows/Arrow/Season 02/Arrow - S02E03 - Broken Dolls [480p, x264, AAC, HDTV].mp4" "ACD_VAULT:Media/Shows/test.mp4" "-vvvvvv" "--stats" "30s" "--crypt-show-mapping"]
2017/03/12 08:01:27 INFO  : Encrypted amazon drive root 'Vault/dmi0e2fbj6btggkj33t5dtqmo4/j4jctgmgj50nsvqtbd2gb0o8ig': Modify window not supported
2017/03/12 08:01:27 DEBUG : rclone: Version "v1.35-164-g488353cβ" finishing with parameters ["rclone" "--config" "/etc/rclone/rclone.conf" "copyto" "/data/.Local/Shows/Arrow/Season 02/Arrow - S02E03 - Broken Dolls [480p, x264, AAC, HDTV].mp4" "ACD_VAULT:Media/Shows/test.mp4" "-vvvvvv" "--stats" "30s" "--crypt-show-mapping"]
rclone.conf:
[ACD_VAULT]
type = crypt
remote = ACD:Vault
I mounted ACD_VAULT:Media
[ACD_VAULT]
type = crypt
remote = ACD:TEST
password = ***
password2 = ***
ls ACD:
echo 123 > abc
ls ACD:
abc.bin
> <https://github.com/notifications/unsubscribe-auth/ABfZI_wxKljFwZoq9xVopxDMD5FhKrVDks5rmR1bgaJpZM4Mad9g>
fatal error: newosproc
problem (tons and tons of different type of IO last couple of weeks 20+ TB).
I'll use Go's existing `net/http` to build out some concurrent endpoints. In order to get a minimum viable product (MVP) across the finish line, I'll probably forgo authentication at first, and add it in later. Since this will initially be a command line option, those who consider it too much of a security risk will not be obligated to run in. All endpoints will use the RESTful model of `GET`, `PUT`, `POST`, `DELETE`, etc...
dir1/
OSX
export RCLONE_ACCESS_SECRET_KEY=jargon
Also the naming is inconsistent:
This is a Crypt mount on ACD.
ACD
1331216 Foto/Archivio/2006-2012/Eventi/Umbria 08_19-08-06/P1010698b.jpg
I was approaching it with TSM style, reading rules from the bottom to the top... my fault.
Repeating the test for an encrypted onedrive remote get slightly different result; if the backup-dir does not exist you just get an error instead of the old file ending up in the root folder:
And yet `ssh remote_server_foo.bar.com` works perfectly with the key, i.e. no password request.
host = remote_server_foo.bar.com
user = kenz
Value "host" = "remote_server_foo.bar.com"
Agent pid 54543
howardm$ rclone lsd Macmini:
Oooh, interesting: http://rabexc.org/posts/pitfalls-of-ssh-agents. **Too many keys, github, and friends**.
Howard
It seems like SSH key handling is annoyingly OS specific. I don't know if this will provide some helpful diagnostic information:
Howard
rclone mount
-řá'ö
Full path : d:/test/-řá'ö
Worng : Beta 1.35-149
Win10 64Bits
Beta 1.35-149
2017/03/05 16:13:24 INFO  : Encrypted Google drive root 'ot1ot51mktl1r8sfrthkudoik0': Modify window is 1ms
2017/03/05 16:13:24 DEBUG : Google drive root 'k1kj3idoe9apdjkfaghkab2go1': Reading ""
2017/03/05 16:13:25 DEBUG : Google drive root 'k1kj3idoe9apdjkfaghkab2go1': Reading "ysg36fw7a9cv02b3n45k1javd4/"
2017/03/05 16:13:25 INFO  : Encrypted Google drive root 'k1kj3idoe9apdjkfaghkab2go1': Waiting for checks to finish
2017/03/05 16:13:25 INFO  : Encrypted Google drive root 'k1kj3idoe9apdjkfaghkab2go1': Waiting for transfers to finish
2017/03/05 16:13:25 DEBUG : Google drive root 'k1kj3idoe9apdjkfaghkab2go1': Reading ""
2017/03/05 16:13:25 DEBUG : Google drive root 'k1kj3idoe9apdjkfaghkab2go1': Reading "ysg36fw7a9cv02b3n45k1javd4/"
2017/03/05 16:13:25 INFO  : Encrypted Google drive root 'k1kj3idoe9apdjkfaghkab2go1': Waiting for checks to finish
2017/03/05 16:13:25 INFO  : Encrypted Google drive root 'k1kj3idoe9apdjkfaghkab2go1': Waiting for transfers to finish
2017/03/05 16:13:25 DEBUG : Google drive root 'k1kj3idoe9apdjkfaghkab2go1': Reading ""
2017/03/05 16:13:28 DEBUG : Google drive root 'k1kj3idoe9apdjkfaghkab2go1': Reading "ysg36fw7a9cv02b3n45k1javd4/"
2017/03/05 16:13:30 INFO  : Encrypted Google drive root 'k1kj3idoe9apdjkfaghkab2go1': Waiting for checks to finish
2017/03/05 16:13:30 INFO  : Encrypted Google drive root 'k1kj3idoe9apdjkfaghkab2go1': Waiting for transfers to finish
2017/03/05 16:29:39 Encrypted Google drive root k1kj3idoe9apdjkfaghkab2go1': Modify window is 1ms
2017/03/05 16:29:39 Google drive root 'k1kj3idoe9apdjkfaghkab2go1': Reading ""
2017/03/05 16:29:40 Encrypted Google drive root 'k1kj3idoe9apdjkfaghkab2go1': Waiting for checks to finish
2017/03/05 16:29:40 Encrypted Google drive root 'k1kj3idoe9apdjkfaghkab2go1': Waiting for transfers to finish
4 -řá'ö/test.txt
4 -řá'ö/test.txt
Thank you for the support. I think it's just unicode.
-řá'ö/file1
-řá'ö/samples/File2
So you can test on Windows. Just create dirs and files inside them on the NonStandardChars dir.
Sorry but i don't have any golang skills. May be someday...
Gdrive (and acd)
Has anyone seen this behaviour?
* You receive an API ban
p.s. There are also tons of `DEBUG : fuse: -> [ID=0x166] Getxattr error=operation not supported` that i dont remember from before.
Massaguana
I mean the status window.. What i Can see during transfer in Terminal... it looks an little bit different but i think it is the same... but not sure because i can see the filename end... something like MovieName.mkv ![bildschirmfoto 2017-03-04 um 06 28 40](https://cloud.githubusercontent.com/assets/15521791/23579609/21e9c086-00f1-11e7-8233-5e347a3d0353.png)
It's possible to do the Unixy thing and pipe out to `cut` and `sort`, but these commands just have so many gotchas (e.g. say your filenames have spaces) that it gets really old fast.
--verbose=5" "dedupe" "gdrive:testdupes"]
"--verbose=5" "dedupe" "gdrive:testdupes"]
2017/03/03 19:25:13 INFO  : Encrypted amazon drive root 'SA2/rmo72ep8i4d41bpvl221f1edbg/g3c5blekrm11uh0f63shhi9vt4': Modify window not supported
cp         rclone
Obviously, the async code path is rather brittle: if finishing up writing takes too long, setting the attribute will timeout and fail, but the code pretended earlier that everything was fine. All in all I don't think this is a good approach.
Durval.  If I try to copy from one ACD drive to another with `--retries 0` the process aborts with an error:
Errors:                 5
Maybe some of you rclone devs want to chip in to help the go folks solve this bug in go1.8rc3 (and apparently also in go1.7.5):
--config='$RCLONECONF'
--config='$RCLONECONF'
--config='$RCLONECONF'
--config='$RCLONECONF'
0 dyndnslogin_output_***AzoO
You're being bitten by shell expansion.
argv[3] = "foo bar"
a="a b \"foo bar\""
$argv[1] = "a b foo bar"
I'd consider this weird behavior, since us UNIX users are used to not have this behavior. `cp DIR_ONE DIR_TWO` should copy `DIR_ONE` itself into `DIR_TWO`, and not its contents.
REMOTE="acd_crypt:/"
rclone v1.35-146-g6bad0adβ
**Errors:**                 4
Ya know, something simple like that ***insert guy hiding behind the wall emoji here***
rclone copy -v --stats 5s /home/jxer/files Gdrive:/media |& grep -v 'INFO'  It would be really nice if the version string reported by `rclone --version` included the short git hash it is built from if the build is of a development version.  This of course assumes that the build is being done from a git checkout, but I think that should be possible to verify as part of the build process.
``` So it is proper (as far as go development) to have sub-packages/dependencies that live within an application refer to an effectively absolute rather than a relative location, so that they appear as though they are external to the application code even when they aren't?  That seems so strange to me.  Hello,
Durval > Note that you need -vv to see all the low level retries now as they are DEBUG messages.
Durval.  The following fails if `somedir` is on a different filesystem.
rclone moveto somefile somedir/somefile
The error given is:
Failed to moveto: rename /some/path/somefile /some/path/somedir/somefile: invalid cross-device link  Currently moveto/copyto do not support moving files to an existing directory.  That is, it seems to provide only a "rename" capability rather than following conventional move/copy semantics that support moving (potentially multiple) items to a destination target directory.  Essentially I think these should work:
3 / Backblaze B2
5 / Encrypt/Decrypt a remote
\ "crypt"
8 / Hubic
\ "hubic"
9 / Local Disk
\ "onedrive"
\ "yandex"
n) New remote
3 / Backblaze B2
7 / Hubic
\ "hubic"
8 / Local Disk
\ "onedrive"
\ "yandex"
There's a ` 5 / Encrypt/Decrypt a remote   \ "crypt"` insertion which pushed the rest of the numbers down.
* https://randomdeterminism.wordpress.com/2012/06/01/how-i-stopped-worring-and-started-using-markdown-like-tex/
ng)
is mean not work?
And the results pretty random.
Does i need something specific for mount command?
https://godoc.org/github.com/olivere/balancers
* apache
Debian jessie from docker golang:1.7
```bash
Dropbox and ACD.
2017/02/21 20:44:17 INFO  : Encrypted amazon drive root 'xxxxxxxxxxxxxxxxxxxxxxxxxx': Modify window not supported
2017/02/21 20:44:18 ERROR : Encrypted amazon drive root 'xxxxxxxxxxxxxxxxxxxxxxxxxx': not deleting files as there were IO errors
2017/02/21 20:44:19 ERROR : Encrypted amazon drive root 'xxxxxxxxxxxxxxxxxxxxxxxxxx': not deleting files as there were IO errors
2017/02/21 20:44:20 ERROR : Encrypted amazon drive root 'xxxxxxxxxxxxxxxxxxxxxxxxxx': not deleting files as there were IO errors
2017/02/21 20:49:18 Encrypted amazon drive root 'xxxxxxxxxxxxxxxxxxxxxxxxxx': Modify window not supported
The sync itself has been fixed, but there is some weird issue with Capitalisation of the folders now.
I'm not sure, it wasn't this way with 1.35.
--include="*.nfo" \
rclone \
--config="$RCLONECONF" \
And i think that this ability can be useful in rclone. Yes this is only one way sync, but why not?
400 Bad Request
An unknown scope was requested
So, what should i do? I don't know if this is an error on amazon's part of if i haven't gotten the correct client_id and secret. Are you sure you need one?
client_secret>
```bash
by unknown authority
`alpha1:~ baro$ rclone lsd -v --dump-headers ACD:
Accept-Encoding: gzip
Pragma: no-cache
Vary: User-Agent
Accept-Encoding: gzip
Pragma: no-cache
Vary: User-Agent
2017/02/27 12:47:34 GET /drive/v1/nodes?filters=parents%3ATYqgPs9tTACsly7qg9mNWA HTTP/1.1
Accept-Encoding: gzip
Pragma: no-cache
Vary: User-Agent
-1 2012-09-27 07:19:03        -1 Immagini
alpha1:~ baro$ rclone lsd -v --dump-headers ACD:
Accept-Encoding: gzip
`until false; do (echo "EOF\n\n" | openssl s_client -showcerts -connect drive.amazonaws.com:443 | sed "/BEGIN.*CERTIFICATE/,/END.*CERTIFICATE/d"  >> provaSSL.txt) 2>> provaSSL.txt; echo "----ALTRA----" >> provaSSL.txt; sleep 1; done`
It's strange that this error always appears at the start of an operation and never in the middle.
ACD GDrive
this went fine till something abount 1000 Movies.
Albert
I start getting the unauthorized at:
That leaves 5 bits for 32 more specific error codes:
if (eta !== null) {
[jim@mb ~]$ echo $?
[jim@mb ~]$ echo $?
rclone cryptcheck "firstremote:My Stuff" "secondremote:My Stuff" --retries 5 --verbose
What does it mean ? Why after restarting my server everything work away without a problem? Thank you for your reply, I close the issue and I test it :)  With Dropbox, rclone 1.35 copyto creates and leaves an empty directory if the remote src file doesn't exist:
[jim@mb ~]$ echo $?
drwxr-xr-x  2 jim  staff  68 Feb 14 11:57 DUMMY.tmp
There are a couple of issues here:
Hi ncw,
Thanks again ncw.  inwas wondering if there was supprt for spider oak on the roadmap?
https://github.com/SpiderOak
Errors:                 2
panic(0xbcbfe0, 0xc420374470)
Some of this filese are also currupt (bad crc) after download:
Unexpected end of archive
unrar x ....
Unexpected end of archive
Unexpected end of archive
Fuse version (2.9.4-1ubuntu3.1)
type = crypt
type = crypt
[CryptDE1]
type = crypt
remote = AmazonDE1:/Crypt/
[CryptUK1]
type = crypt
This last line is the extra garbage:
Thanks! I'm new to snapd, so correct me if I am wrong here.
This would mean a lot for upload optimization, especially with acd where single file transfer is not as fast as multiple at same time.
Backblaze B2
* ...3273.L3m_7D_SCI_V3.0_SSS_bias_adj_1deg.bz2: 100% done, 84.297 kBytes/s, ETA: 0s
panic(0xbd5160, 0xc4200120b0)
2017/02/10 09:57:59 GET /drive/v2/files?alt=json&maxResults=1000&q=trashed%3Dfalse+and+%270AH2sxduygeufUk9PVA%27+in+parents+and+title%3D%27xyz%27+and+mimeType%3D%27application%2Fvnd.google-apps.folder%27 HTTP/1.1
2017/02/10 09:57:59 GET /drive/v2/files?alt=json&maxResults=1000&q=trashed%3Dfalse+and+%270AH2sxduygeufUk9PVA%27+in+parents+and+title%3D%27xyz%27+and+mimeType%21%3D%27application%2Fvnd.google-apps.folder%27 HTTP/1.1
2017/02/10 09:57:59 GET /drive/v2/files?alt=json&maxResults=1000&q=trashed%3Dfalse+and+%270AH2sxduygeufUk9PVA%27+in+parents+and+title%3D%27xyz%27+and+mimeType%21%3D%27application%2Fvnd.google-apps.folder%27 HTTP/1.1
2017/02/10 09:57:59 GET /drive/v2/files?alt=json&maxResults=1000&q=trashed%3Dfalse+and+%270AH2sxduygeufUk9PVA%27+in+parents+and+title%3D%27xyz%27+and+mimeType%3D%27application%2Fvnd.google-apps.folder%27 HTTP/1.1
Accept-Encoding: gzip
Alt-Svc: quic=":443"; ma=2592000; v="35,34"
Vary: Origin
Vary: X-Origin
X-Content-Type-Options: nosniff
"selfLink": "https://www.googleapis.com/drive/v2/files?maxResults=1000&q=trashed%3Dfalse+and+'0AH2sxduygeufUk9PVA'+in+parents+and+title%3D'xyz'+and+mimeType%3D'application/vnd.google-apps.folder'&alt=json",
2017/02/10 09:57:59 GET /drive/v2/files?alt=json&maxResults=1000&q=trashed%3Dfalse+and+%270AH2sxduygeufUk9PVA%27+in+parents+and+title%3D%27xyz%27+and+mimeType%21%3D%27application%2Fvnd.google-apps.folder%27 HTTP/1.1
Accept-Encoding: gzip
Alt-Svc: quic=":443"; ma=2592000; v="35,34"
Vary: Origin
Vary: X-Origin
X-Content-Type-Options: nosniff
"selfLink": "https://www.googleapis.com/drive/v2/files?maxResults=1000&q=trashed%3Dfalse+and+'0AH2sxduygeufUk9PVA'+in+parents+and+title%3D'xyz'+and+mimeType!%3D'application/vnd.google-apps.folder'&alt=json",
(lots more item stuff)
2017/02/10 09:57:59 GET /drive/v2/files?alt=json&maxResults=1000&q=trashed%3Dfalse+and+%270AH2sxduygeufUk9PVA%27+in+parents+and+title%3D%27xyz%27+and+mimeType%21%3D%27application%2Fvnd.google-apps.folder%27 HTTP/1.1
Accept-Encoding: gzip
Alt-Svc: quic=":443"; ma=2592000; v="35,34"
Vary: Origin
Vary: X-Origin
X-Content-Type-Options: nosniff
"selfLink": "https://www.googleapis.com/drive/v2/files?maxResults=1000&q=trashed%3Dfalse+and+'0AH2sxduygeufUk9PVA'+in+parents+and+title%3D'xyz'+and+mimeType!%3D'application/vnd.google-apps.folder'&alt=json",
> $ rclone lsl --crypt-show-mapping gdrive:/crypt/qbu2chuhnvlm4gjmeofgbfhjfk/sdn73r6mtqqfe8lgv7bnh08010/3kt22d63qlospkl1763gob8r4o/m8fnghbhatmesjafpqr4uf953f8q6va267jlau5s4cs16lgeb9bg
>     45420 2017-01-07 22:19:14.429000000 m8fnghbhatmesjafpqr4uf953f8q6va267jlau5s4cs16lgeb9bg
> $ rclone lsl --crypt-show-mapping acd:/crypt/qbu2chuhnvlm4gjmeofgbfhjfk/sdn73r6mtqqfe8lgv7bnh08010/3kt22d63qlospkl1763gob8r4o/m8fnghbhatmesjafpqr4uf953f8q6va267jlau5s4cs16lgeb9bg
>     45420 2017-01-07 22:19:14.429000000 m8fnghbhatmesjafpqr4uf953f8q6va267jlau5s4cs16lgeb9bg
ACD
_2017/02/08 17:11:48 Mark_Masters.zip.003: Upload error detected but didn't finish upload: Post https://content-na.drive.amazonaws.com/cdproxy/nodes?suppress=deduplication: write tcp 192.168.88.238:55296->52.1.75.19:443: wsasend: An existing connection was forcibly closed by the remote host. ("HTTP status UNKNOWN")
2017/02/08 17:11:48 pacer: low level retry 1/1 (error Post https://content-na.drive.amazonaws.com/cdproxy/nodes?suppress=deduplication: write tcp 192.168.88.238:55296->52.1.75.19:443: wsasend: An existing connection was forcibly closed by the remote host.)
any other ideas to resolve this would really help i see no choice but to look at alternatives next and its a long wasted journey for me to get this far and it all fail.
2017/02/11 07:28:14 Mark_Masters.zip.005: Upload error detected but didn't finish upload: Post https://content-na.drive.amazonaws.com/cdproxy/nodes?suppress=deduplication: write tcp 192.168.88.238:50478->54.172.239.173:443: wsasend: An existing connection was forcibly closed by the remote host. ("HTTP status UNKNOWN")
2017/02/11 07:28:14 pacer: low level retry 1/1 (error Post https://content-na.drive.amazonaws.com/cdproxy/nodes?suppress=deduplication: write tcp 192.168.88.238:50478->54.172.239.173:443: wsasend: An existing connection was forcibly closed by the remote host.)
so as an additional test to confirm it isnt my 'pipes' being full of rclone traffic causing the fails, for the duration I have kept a VPN link up from another machine to an outside VPN, this so far has not been dropped.
src_folder acd:dst_folder
For example my config path is set in the enviroment as %HOMEDRIVE%%HOMEPATH%\Documents\rclone.conf
`* Config file "%HOMEDRIVE%%HOMEPATH%\\Documents\\rclone.conf" not found - using defaults`
`ulimit -n`
rclone    32495            lugia  421u     IPv4           27339327        0t0                  TCP 51-15-0-251.rev.poneytelecom.eu:43382->ec2-52-48-13-92.eu-west-1.compute.amazonaws.com:https (CLOSE_WAIT)
rclone    32495  9414      lugia  421u     IPv4           27339327        0t0                  TCP 51-15-0-251.rev.poneytelecom.eu:43382->ec2-52-48-13-92.eu-west-1.compute.amazonaws.com:https (CLOSE_WAIT)
rclone    32495 32496      lugia  421u     IPv4           27339327        0t0                  TCP 51-15-0-251.rev.poneytelecom.eu:43382->ec2-52-48-13-92.eu-west-1.compute.amazonaws.com:https (CLOSE_WAIT)
rclone    32495 32497      lugia  421u     IPv4           27339327        0t0                  TCP 51-15-0-251.rev.poneytelecom.eu:43382->ec2-52-48-13-92.eu-west-1.compute.amazonaws.com:https (CLOSE_WAIT)
rclone    32495 32498      lugia  421u     IPv4           27339327        0t0                  TCP 51-15-0-251.rev.poneytelecom.eu:43382->ec2-52-48-13-92.eu-west-1.compute.amazonaws.com:https (CLOSE_WAIT)
rclone    32495 32499      lugia  421u     IPv4           27339327        0t0                  TCP 51-15-0-251.rev.poneytelecom.eu:43382->ec2-52-48-13-92.eu-west-1.compute.amazonaws.com:https (CLOSE_WAIT)
rclone    32495 32500      lugia  421u     IPv4           27339327        0t0                  TCP 51-15-0-251.rev.poneytelecom.eu:43382->ec2-52-48-13-92.eu-west-1.compute.amazonaws.com:https (CLOSE_WAIT)
rclone    32495 32501      lugia  421u     IPv4           27339327        0t0                  TCP 51-15-0-251.rev.poneytelecom.eu:43382->ec2-52-48-13-92.eu-west-1.compute.amazonaws.com:https (CLOSE_WAIT)
rclone    32495 32502      lugia  421u     IPv4           27339327        0t0                  TCP 51-15-0-251.rev.poneytelecom.eu:43382->ec2-52-48-13-92.eu-west-1.compute.amazonaws.com:https (CLOSE_WAIT)
rclone    32495 32515      lugia  421u     IPv4           27339327        0t0                  TCP 51-15-0-251.rev.poneytelecom.eu:43382->ec2-52-48-13-92.eu-west-1.compute.amazonaws.com:https (CLOSE_WAIT)
rclone    32495 32516      lugia  421u     IPv4           27339327        0t0                  TCP 51-15-0-251.rev.poneytelecom.eu:43382->ec2-52-48-13-92.eu-west-1.compute.amazonaws.com:https (CLOSE_WAIT)
rclone    32495 32517      lugia  421u     IPv4           27339327        0t0                  TCP 51-15-0-251.rev.poneytelecom.eu:43382->ec2-52-48-13-92.eu-west-1.compute.amazonaws.com:https (CLOSE_WAIT)
rclone    32495 32518      lugia  421u     IPv4           27339327        0t0                  TCP 51-15-0-251.rev.poneytelecom.eu:43382->ec2-52-48-13-92.eu-west-1.compute.amazonaws.com:https (CLOSE_WAIT)
rclone    32495 32519      lugia  421u     IPv4           27339327        0t0                  TCP 51-15-0-251.rev.poneytelecom.eu:43382->ec2-52-48-13-92.eu-west-1.compute.amazonaws.com:https (CLOSE_WAIT)
rclone    32495 32572      lugia  421u     IPv4           27339327        0t0                  TCP 51-15-0-251.rev.poneytelecom.eu:43382->ec2-52-48-13-92.eu-west-1.compute.amazonaws.com:https (CLOSE_WAIT)
Errors:
> ACD Copy ended  51 seconds
> ACD Copy ended  19 seconds
I usually use the --log-file option in rclone and follow the progress with tail -f but when I turn on verbose output it can make it hard to keep track of transfer progress, if there was an --verbose-log-file option to log all verbose output to a seperate file it would make it possible to easily keep track of transfers and keep track of errors on the backend. Actually that's a much better idea, that way it doesn't need to be specified when initially running the command. I tested it out and it works as expcted I can't help but think that the Info should be included by default, that's the most important part of the log for me, I generally only enable the more verbose options for debugging but the info is needed to keep track of progress. I see, I've never actually used rsync before, but in any case it's hardly an issue now that defaults can be set in the enviroment.  When filing an issue, please include the following information if possible as well as a description of the problem.  Make sure you test with the [latest beta of rclone](http://rclone.org/downloads/).
Rclone 1.35
It could be a problem with  "LONGNAMES" pathnames?
/Boot/**
- ^\$Recycle\.Bin/.*$
- ^Boot/.*$
- ^\$Recycle\.Bin/.*$
- ^Boot/.*$
but I've many of these errors:
<tr><td bgcolor=#3366cc><font face=arial,sans-serif color=#ffffff><b>Error</b></td></tr>
>    --include="*.nfo" \
Series/Fargo/tvshow.nfo
Series/Fear.the.Walking.Dead/tvshow.nfo
2017/02/27 15:39:25 NOTICE: Encrypted Google drive root 'cloudp/lp08934q11u6a5gslo2ddds5b4/hkitmqcr303hk1a33m19ttdq24': 1 differences found
/mnt/*
/media/*
/boot/*
2017/02/03 13:14:23 Media/Unsorted/300 (2007) BluRay 1080p 5.1CH x264 Ganool.mkv: Dir.Lookup
panic(0x7595a0, 0xc42000e080)
2017/02/03 13:21:18 amazon drive root 'Vault': Reading "dmi0e2fbj6btggkj33t5dtqmo4/kerbir1jjej6g0nbqq716m0bo0/nqh00jdqfppsht0etjfonv6orct68e2hptv9q6ja6kf3lro0mq48utj5r30lhki4fmgcis0nic0js/"
2017/02/03 13:21:18 amazon drive root 'Vault': Finished reading "dmi0e2fbj6btggkj33t5dtqmo4/kerbir1jjej6g0nbqq716m0bo0/nqh00jdqfppsht0etjfonv6orct68e2hptv9q6ja6kf3lro0mq48utj5r30lhki4fmgcis0nic0js/"
2017/02/06 19:18:11 fuse: -> [ID=0x3] Lookup error=ENOENT
2017/02/06 19:18:11 fuse: -> [ID=0x4] Lookup error=ENOENT
2017/02/06 19:18:11 fuse: -> [ID=0x6] Lookup error=ENOENT
2017/02/06 19:18:11 fuse: -> [ID=0x3] Lookup error=ENOENT
2017/02/06 19:18:11 fuse: -> [ID=0x5] Lookup error=ENOENT
2017/02/06 19:18:11 fuse: -> [ID=0x3] Lookup error=ENOENT
2017/02/06 19:18:11 fuse: -> [ID=0x5] Lookup error=ENOENT
2017/02/06 19:18:18 fuse: -> [ID=0x6] Lookup error=ENOENT
2017/02/06 19:18:18 fuse: -> [ID=0x6] Lookup error=ENOENT
2017/02/06 19:18:18 fuse: -> [ID=0x6] Lookup error=ENOENT
2017/02/06 19:18:18 fuse: -> [ID=0x8] Lookup error=ENOENT
2017/02/06 19:18:18 fuse: -> [ID=0x4] Lookup error=ENOENT
2017/02/06 19:18:19 fuse: -> [ID=0x8] Lookup error=ENOENT
2017/02/06 19:18:19 fuse: -> [ID=0x3] Lookup error=ENOENT
2017/02/06 19:18:19 fuse: -> [ID=0x7] Lookup error=ENOENT
2017/02/06 19:18:19 fuse: -> [ID=0x6] Lookup error=ENOENT
2017/02/06 19:18:19 fuse: -> [ID=0x4] Lookup error=ENOENT
2017/02/06 19:18:19 fuse: -> [ID=0x8] Lookup error=ENOENT
2017/02/06 19:18:19 fuse: -> [ID=0x3] Lookup error=ENOENT
2017/02/06 19:18:19 fuse: -> [ID=0x7] Lookup error=ENOENT
2017/02/06 19:18:19 fuse: -> [ID=0x4] Lookup error=ENOENT
2017/02/06 19:18:19 fuse: -> [ID=0x3] Lookup error=ENOENT
2017/02/06 19:18:19 fuse: -> [ID=0x6] Lookup error=ENOENT
2017/02/06 19:18:19 fuse: -> [ID=0x4] Lookup error=ENOENT
2017/02/06 19:18:19 fuse: -> [ID=0x8] Lookup error=ENOENT
2017/02/06 19:18:23 fuse: -> [ID=0x3] Lookup error=ENOENT
2017/02/06 19:18:23 fuse: -> [ID=0x7] Lookup error=ENOENT
2017/02/06 19:18:23 fuse: -> [ID=0x6] Lookup error=ENOENT
2017/02/06 19:18:23 fuse: -> [ID=0x7] Lookup error=ENOENT
2017/02/06 19:18:23 fuse: -> [ID=0x8] Lookup error=ENOENT
2017/02/06 19:18:23 fuse: -> [ID=0x4] Lookup error=ENOENT
2017/02/06 19:18:23 fuse: -> [ID=0x3] Lookup error=ENOENT
2017/02/06 19:18:24 fuse: -> [ID=0x6] Lookup error=ENOENT
``` Thanks Nick. I just seem to be bumping in to futures lately eh? :)
Anything I can do to help? (Cracks open the ide)
```bash
That way, the meaning remains from remote type and you can have diferent parameters for anyone.
PD: English is not my motherlanguage so please forgive my writing/explain mistakes.
_D603108.NEF
_D603089.NEF
_D603091.NEF
_D603092.NEF
_D603103.NEF
_D603090.NEF
_D603093.NEF
Not sure if you looked into a keystone yet but this might be of use;
- Checks de "magic" string is right
I think it's the only way to know that really that encrypted file Cheksum matches the original.
panic(err)
panic(err)
panic(err)
panic: error listing: Swift container public path atomic/fedora/: level value not supported
My situation is probably a very rare edge case to have a better solution for it. but I think rclone should be aware if the remote is case insensitive and try to avoid removing / overwriting the wrong files.
"gdrive_alberto:<pathname>":  didn't find section in config file
Edouard  Using the latest (updated as of earlier this morning) rclone on Linux, I'm getting unexpected behavior with the `moveto` command on local files.
I was still having this issue with: v1.35-41-g2abfae2
It seems that ACD is just so unreliable. I may take to the forums to discuss reliable providers.
Can anyone confirm if this only happens when using crypt or does this also happen when just transferring to ACD without crypt as well? It happens without crypt for me.    When i wood like to unmount my mounted GSuite Drive with:
okay, -uz works... @ncw please update your Docs, there are -u for unmount @Massaguana -u is the unmount command, the -z part is to force unmount even when its busy/in use.   Hello rclone Team,
`nohup rclone mount -v --allow-non-empty --allow-other GSuiteCrypt: /var/lib/plexmediaserver/Media/ &` @Massaguana
I'm not sure if this is a bug from encfs or rclone so I'm going to post it on both and see what happens. Thanks! It was my problem, I had my directory structure incorrect.
Grazie mille!
rclone sync /media/andrew/A4AAD085AAD05600/WIN_DEV GoogleDrive:backup/WIN_DEV --exclude-from /home/andrew/Documents/backup/rclone-ignore.txt
/home/andrew/Desktop/rclone sync /media/andrew/A4AAD085AAD05600/WIN_DEV GoogleDrive:backup/WIN_DEV --exclude-from /home/andrew/Documents/backup/rclone-ignore.txt
So it does fail early, but it still seems to be printing out info about the remote process whereas I'd have thought it should just say something like:
Yes, I realize that rclone doesn't support arbitrary metadata yet, but I believe at least ACD supports it (according to [this comment](https://github.com/ncw/rclone/issues/371#issuecomment-188724500) on #371) and there's already another ticket asking for support of it (#111), and I hope that support for using backend-specific metadata capabilities within rclone will be available at some point in the not too distant future.  Having those capabilities listed would be helpful for future implementation plans. I've made a first pass at adding the doc info and code to support DirCopy/DirCopier.  I'm about to create a pull request to get comments.  Pull request #1081.
To complicate,
Name=PowerMute
Linux xxx 4.1.15+ #830 Tue Dec 15 16:58:28 GMT 2015 armv6l BCM2708 GNU/Linux
I was trying to sync a pics folder to AD. The folder has some cruft from OS X and from my Synology NAS, which was copied to remote as soon as the command started. So I stopped the command and rerun it with some --exclude's to filter out the cruft. I also wanted the cruft to be deleted from the remote, so I added --delete-excluded. Now, maybe I don't understand how this flag works, but the cruft remains on the remote. My command is:
rclone sync somefolder amazon:/Foto/somefolder/ -v --exclude '@eaDir/*' --exclude '._*' --exclude .DS_Store --delete-excluded
I noticed that the performance of rclone is very poor on ARM boards. I first tried it on a OrangePi PC, freshly installed with Armbian. If I copy a file from GDrive to local, I only get 2.6 MB/s
Output of top-command while copying on the raspberry:
rclone-v1.35-36-ga4bf22eβ
[acd]
type = crypt
remote = acd:/media/encfs
password2 = xxx
ACD
panic(0xdb29c0, 0xc82000e110)
/home/mock/gopath/src/github.com/ncw/rclone/amazonclouddrive/amazonclouddrive.go:1025 +0x7b
/home/mock/gopath/src/github.com/ncw/rclone/amazonclouddrive/amazonclouddrive.go:1027 +0x15c
/home/mock/gopath/src/github.com/ncw/rclone/amazonclouddrive/amazonclouddrive.go:1073 +0x38b
/home/mock/gopath/src/github.com/ncw/rclone/amazonclouddrive/amazonclouddrive.go:653 +0x369
/home/mock/gopath/src/github.com/ncw/rclone/crypt/crypt.go:230 +0x209
ACD
rclone mount
a) Add Password
password:
password:
Your configuration is encrypted.
trp@sd-62570:~$ rclone mount -v eacd:A/ ~/mount &
Something is wrong with paths.
rclone listremotes
( note iam not sure how rclone handles spaces in folders ... i would change it to Plex-Cloud )
There is irony in the fact that a big reason for ACD's increased popularity recently has been Plex Cloud - which recently dropped support for ACD because it was seemingly beyond Plex developers to sort out the buffering prefetch problem themselves with something like what we are discussing here.
type = alias
`rclone mount foo bar`
Vipul
Vipul
ACD
borgbackup init /mnt/ACD-Vault_Backup/
Local Exception.
Rclone Logs:
2017/01/17 22:45:38 fuse: -> [ID=0x7] Lookup error=ENOENT
2017/01/17 22:45:38 fuse: -> [ID=0xf] Lookup error=ENOENT
2017/01/17 22:45:38 fuse: -> [ID=0x11] Lookup error=ENOENT
2017/01/17 22:45:39 fuse: -> [ID=0x1a] Lookup error=ENOENT
2017/01/17 22:45:39 fuse: -> [ID=0x1c] Lookup error=ENOENT
2017/01/17 22:45:39 fuse: -> [ID=0x1e] Header error=ENOSYS
2017/01/17 22:45:39 fuse: -> [ID=0x21] Lookup error=ENOENT
2017/01/17 22:45:39 fuse: -> [ID=0x22] Lookup error=ENOENT
2017/01/17 22:45:39 fuse: -> [ID=0x23] Lookup error=ENOENT
2017/01/17 22:45:39 pacer: low level retry 1/1 (error HTTP code 429: "429 Too Many Requests": response body: "{\"logref\":\"ab4ed001-dd06-11e6-b5a7-797d40453ad1\",\"message\":\"Rate exceeded\",\"code\":\"\"}")
2017/01/17 22:45:42 fuse: -> [ID=0x2e] Header error=ENOSYS
2017/01/17 22:45:50 fuse: -> [ID=0x4a] Lookup error=ENOENT
2017/01/17 22:45:50 fuse: -> [ID=0x4b] Lookup error=ENOENT
2017/01/17 22:45:52 fuse: -> [ID=0x63] Header error=ENOSYS
2017/01/17 22:45:52 fuse: -> [ID=0x6a] Header error=ENOSYS
2017/01/17 22:45:52 fuse: -> [ID=0x6b] Header error=ENOSYS
2017/01/17 22:45:52 fuse: -> [ID=0x73] Lookup error=ENOENT
I don't know how others feel, but it might be worth investigating. Borg
> that rclone presents has quite a lot of limitations (like you can't read
Accept-Encoding: gzip
root@ws-term:/mnt# fusermount -u ACD
Accept-Encoding: gzip
> <https://github.com/notifications/unsubscribe-auth/ABfZI8BV6wulTG5k33U06lu-AOHiIAVCks5rTe4igaJpZM4LmPvW>
`rclone rmdirs <remote>`
Is --drive-chunk-size supposed to work for ACD as well?
I'm not familiar with Go either, but I'll try, I think I get the idea where to start this little addition. :)
Just wonder whats the fastest and easiest for you to implement so we can use all flags with crypt.  Disclaimer: I haven't tested this patch, and I have very little experience with Go.
Debian 8.6 - 64 bit
root@drbl:/ceph/drbl# mkdir /tmp/permtest
root@drbl:/ceph/drbl# touch /tmp/permtest/owner_gdrive-backups_o
root@drbl:/ceph/drbl# touch /tmp/permtest/owner_gdrive-backups2_o
root@drbl:/ceph/drbl#
root@drbl:/ceph/drbl# # copy two files using two accounts
root@drbl:/ceph/drbl# /usr/local/bin/gdrive/rclone copyto -v --config
root@drbl:/ceph/drbl# /usr/local/bin/gdrive/rclone copyto -v --config
root@drbl:/ceph/drbl#
root@drbl:/ceph/drbl# # remove the files
root@drbl:/ceph/drbl# rm /tmp/permtest/owner_gdrive-backups_o
root@drbl:/ceph/drbl# rm /tmp/permtest/owner_gdrive-backups2_o
root@drbl:/ceph/drbl#
root@drbl:/ceph/drbl# /usr/local/bin/gdrive/rclone sync
The strangest part to me : if I go down in the "vm" folder, the exclusion works:
$ uname -a
When I try to use cp against a Crypt -> ACD mount the system hangs most the time. I have this in the system logs:
$ echo abc>abc
$ rclone copyto abc drop:test/abc
$ rm abc
$ rclone copyto abc drop:test/abc
2017/01/11 15:36:42 Failed to create file system for "drop:test/abc": is a file not a directory
$ echo abc>abc
$ rclone -c -v copyto abc drop:test/abc
$ echo def>abc
$ rclone -c -v copyto abc drop:test/abc
that's a bug.
For HashBackup, I'm going to switch to unconditional transfers (adding
being transferred because rclone didn't think it was necessary, even
> I think checking the modification time as a last resort would be surprising
This one is sort of "meware" in that it's largely created to be personally useful, but could potentially be interesting to someone else. http://www.hashbackup.com
https://github.com/billziss-gh/winfsp
https://github.com/billziss-gh/nfs-win
https://github.com/billziss-gh/redditfs
https://github.com/billziss-gh/fusepy
- I do not know Go (this has not stopped me before).
> @billziss-gh - WinFsp is a very impressive project. I read about your difficulties with undocumented APIs and debugging - quite a challenge!
Thanks. Feel free to make any suggestions for improvement. In particular I am wondering if the way I am mapping C pointers to Go interfaces and back (in [handle.go](https://github.com/billziss-gh/cgofuse/blob/master/fuse/handle.go)) is the best way of doing things.
Still if this is the way  it has to be done in order to play in the Go ecosystem that's fine.
> >Feel free to make any suggestions for improvement. In particular I am wondering if the way I am mapping C pointers to Go interfaces and back (in handle.go) is the best way of doing things.
- [`Error`](https://github.com/billziss-gh/cgofuse/blob/master/fuse/fsop.go#L409) is a new type that encapsulates a FUSE error. This `Error` type should be rarely used as returning error codes from the file operations should be sufficient. In some rare circumstances however it is convenient to throw an `Error` that contains a boxed error code; prior to returning to the OS the cgofuse layer will recover and unwrap the `Error` to get the error code to return. For example, during late testing of memfs I discovered that I needed to return `ENAMETOOLONG` in some circumstances. Rather than retrofit the whole file system to handle the new error path, I simply use: [`panic(fuse.Error(-fuse.ENAMETOOLONG))`](https://github.com/billziss-gh/cgofuse/blob/master/examples/memfs/memfs.go#L433-L435). > Doing a type assertion is more expensive as it involves scanning a table for type information. However it is pretty quick... This SO question indicates it is 5x slower than the direct interface call - I think it depends on how many possible types there could be though.
Interesting. The comments in that SO question suggest that in later versions of Go type assertions have been optimized. I will try the included benchmark.
I have found that [Mingw-builds](http://mingw-w64.org/doku.php/download/mingw-builds) works well.
// +build cgo
package cmount
// +build cgo
package cmount
"github.com/spf13/cobra"
// Globals
umask                            = 0
I try to compile the "cmount" branch(on Manjaro):
@sbr481 The current `cmount` code does not appear to pass the proper `uid`, `gid` to WinFsp-FUSE yet (it just uses zero (`0`)). This is likely why you are getting "access denied" errors.
If i try to check a file descpription in GUI , the network traffic going to hight, but not open the desc. windows. (need to force close the mount)  > Hi ncw, billziss,
EDIT: I'm noticed i wasn't using beta release of Winfsp (using 1.0.17072), so, i'll retry everything...
![differents_attribs](https://cloud.githubusercontent.com/assets/25271911/25819954/e3ce899a-342f-11e7-9ce4-8163831a5478.JPG)
@billziss-gh
Also, I'm going to test crypted remote.
So, it seems a problem related to W10.  In W7:
I'm going to test with crypted remote, but i think it works correctly.
EDIT2: As expected, it works with crypted remote too:
I see a couple of different solutions:
I strongly suspect that all this is a permissions related problem.
Incorrect function.
@sbr481 thank you very much. I can confirm that I have also seen the alternative `mkdir` problem. To summarize here are the problems that I am aware of and have confirmed so far:
- `Mkdir` sometimes results in "the request could not be performed because of an I/O device error". This is the Windows user mode error `ERROR_IO_DEVICE`, which is a translation of the Windows kernel mode error `STATUS_IO_DEVICE_ERROR`, which comes from the FUSE layer returning `-EIO`. This is likely because an exception is thrown within the Go code during `Mkdir`.
As vampywiz said, --read-only does not work.
Checking the `mount` code I find:
·Navigate to root of remote(t:) > Media folder > Peliculas folder
Two serious bug.
@billziss-gh i didn't test with linux, but it would be interesting make some tests and see if it is affected. I think is different, and in linux won't be a problem, but it's a thought only... xD
2017/05/13 21:13:53 DEBUG : /: Opendir:
2017/05/13 21:13:53 DEBUG : /: Opendir:
2017/05/13 21:13:53 DEBUG : /: Opendir:
2017/05/13 21:13:53 DEBUG : /: Opendir:
2017/05/13 21:37:34 DEBUG : /manjaro-deepin-17.0.1-stable-x86_64.iso: >Flush: errc=0
Strange, I am trying all these builds but I am not seeing a drive get mounted.
2017/05/13 15:06:45 DEBUG : /: Opendir:
2017/05/13 15:06:45 DEBUG : /: Opendir:
2017/05/13 15:06:45 DEBUG : /: Opendir:
```yaml
- set GOARCH=386
- set GOARCH=amd64
Checking for required docker image karalabe/xgo-latest... found.
osxcross: warning: possibly dangerous include path specified: '-I /usr/local/include/osxfuse/fuse'
So this means (I think) that we have to somehow create a cross-platform "FUSE" that can be used with xgo's `--deps`. Looking at the xgo source such a package has to support `configure` and `make install`. [[link](https://github.com/karalabe/xgo/blob/master/docker/base/build_deps.sh)]
Checking for required docker image karalabe/xgo-latest... found.
osxcross: warning: possibly dangerous include path specified: '-I /usr/local/include/osxfuse/fuse'
The OSXFUSE build currently does not work. I am getting some error messages documented in karalabe/xgo#80.
Thank you for using WinFsp in rclone and for teaching me about Go. Hi, i'll only add a comment to this version i've been testing:
Returns `ENOENT` (file not found):
2017/05/17 22:59:57 DEBUG : /Tecknat: >Getattr: errc=0
How can we mount to a "local drive" that doesn't exist?
> c:\Tools>rclone mount boda: h: -vv
2017/05/18 16:42:58 DEBUG : /: Opendir:
2017/05/18 16:42:58 DEBUG : /: Opendir:
2017/05/18 16:42:58 DEBUG : /: Opendir:
There are a couple of additional possibilities although from the wording of the reports above sound less likely:
(This was the same whether crypt or non crypt.) I have done some tests and I do not believe this to be a problem with WinFsp-FUSE.
The filename, directory name, or volume label syntax is incorrect.
Y:\>dir
dir
Non-ASCII characters only - Up to 85 characters
Non-ASCII characters only - Up to 85 characters
* Non-ASCII characters used "∀". @32kHz I think this makes more sense now.
The character ∀ is Unicode character `0x2200`, which translates to the UTF-8 byte sequence `e2  88  80`. Thus 1 character takes 2 bytes to encode in UTF-16 (Windows "Unicode") and 3 bytes to encode in UTF-8 (which FUSE and POSIX uses).
Gav
You are spot on. @ Poolareverb
@ Billziss-gh
if someday Google Drive API stop support  Rclone like ACD
An inquisitive mind is a great thing :) Keep it up!
Explorer window randomly hangs when accessing mount
Explorer window randomly hangs when accessing mount
I guess for now it's best to disable thumbnails in folder settings. @billziss-gh Regarding your earlier problem with Windows and the file name case issue when mounting to a path, I found an interesting loophole when using my Android phone:
Accept-Encoding: gzip
Pragma: no-cache
X-Content-Type-Options: nosniff
https://blog.minio.io/accelerating-sha256-by-100x-in-golang-on-arm-1517225f5ff4#.foika9d4j
return of the error between checker goroutines and sends it back to the
ACD
Warning on a possible "documentation regression": the "--crypt-show-mapping" option isn't in the docs on the last rclone beta I downloaded:
Durval.
Durval. Hi @ncw,
> @DurvalMenezes :-)
Durval.  Added details about Amazon Drive's latest trash retention policy.
https://www.reddit.com/r/DataHoarder/comments/5dh96j/files_in_amazon_cloud_drive_trash_now_deleted/
rclone 1.35
`rclone -v --dump-headers --log-file=LOGFILE copy egd:REDACTED/REDACTED/REDACTED/REDACTED.mp4 /tmp/REDACTED.mp4
Durval.
With many files on an encrypted Google Drive I get the following errors when trying to copy to local: http://pastebin.com/ySNPSXgi
Durval.
> This will print a messagae like this
2017/01/08 11:00:55 Encrypted Google drive root 'ad9vmobdicfbsr1bbropaghtik/j9t3ij7t2vmucl443rn90hmjbo/jhdir64l56ogdjpqjd71ubgenc0frv2fe8m9v062qlea593jc97g': Modify window is 1ms
261996813 REDACTED.mp4
rclone lsl gd:ad9vmobdicfbsr1bbropaghtik/j9t3ij7t2vmucl443rn90hmjbo/jhdir64l56ogdjpqjd71ubgenc0frv2fe8m9v062qlea593jc97g
OTOH, is there any particular reason for the rclone -v output *not* including each file's  encrypted full path+filename? If not please let me know and I will open an issue for it, as I think it would make these kinds of determinations much easier.
Durval.
Durval.
rclone copy -v gd:ad9vmobdicfbsr1bbropaghtik/j9t3ij7t2vmucl443rn90hmjbo/jhdir64l56ogdjpqjd71ubgenc0frv2fe8m9v062qlea593jc97g/4s56ib1p2pjdofn9s4tpveehg8 .
2017/01/08 17:12:35 rclone: Version "v1.35" starting with parameters ["rclone" "copy" "-v" "gd:ad9vmobdicfbsr1bbropaghtik/j9t3ij7t2vmucl443rn90hmjbo/jhdir64l56ogdjpqjd71ubgenc0frv2fe8m9v062qlea593jc97g/4s56ib1p2pjdofn9s4tpveehg8" "."]
password = REDACTED
password2 = REDACTED
+[elo]
+type = crypt
+password = REDACTED
+password2 = REDACTED
rclone ls elo:
261996813 REDACTED.mp4
rclone -v copy elo:REDACTED.mp4 /tmp/test.mp4
2017/01/08 18:45:40 rclone: Version "v1.35" starting with parameters ["rclone" "-v" "copy" "elo:REDACTED.mp4" "/tmp/test.mp4"]
Just did (saved it as /tmp/encrypted_REDACTED_downloaded_via_WebUI), and it's exactly the same file downloaded by the above "rclone copy gd:" command.
Durval.
Durval.
652927 256170 -rw-rw-r--   1 durval   durval   262060813 Aug  2  2015 /tmp/rclone_issue_999_test_20170108Z191002/4s56ib1p2pjdofn9s4tpveehg8
00000030  3e f9 fc 59 53 e5 23 41  1a 64 bf 91 cb f4 0b 60  |>..YS.#A.d.....`|
00000000  52 43 4c 4f 4e 45 00 00  bd cb 88 a1 60 c9 89 6a  |RCLONE......`..j|
00000020  28 21 1c af b2 91 08 65  9d 91 db 05 f5 ac 18 e1  |(!.....e........|
Durval.
rclone -v cat elo:REDACTED.mp4 | wc -c
>  It would be interesting to see what the data in the encrypted version of the file for the next 64k looks like. If it doesn't look like random data then there will be a clue there.
Again if I'm following you correctly, it seems the error occurs at a totally random place, so the rclone decryption called by "rclone cat" on the encrypted remote isn't outputting full blocks(?!)
How can that be?
Durval.
rclone -q cat elo:REDACTED.mp4 | wc -c
So, if I follow your thinking, the encrypted file was corrupted after exactly 79 blocks, and the interesting block for us will begin at offset 5178640.
This looks pretty random to me...
So it seems to be really random.
Durval.
./rclone -q cat elo:REDACTED.mp4 | wc -c
panic(0xb5b400, 0xc4200121a0)
Durval.
Durval. I'm still struggling to keep my encrypted remotes copies the same as my remotes.
Maybe the rate limiter is the reason encrypted uploads get corrupted as well?
I didn't see this problem with ACD.
```bash
0000230   õ 027   Ë 022   í   m   N   ½ 002   f 005   ¡   X   ã       â
The errors are all MD5 mismatches:
This is very worrisome.
nohup ./rclone cat --tail 1 --stats 1m --discard --log-file=Check-RemoteCrypt.txt --checkers 48 RemoteCrypt: &
* REDACTED/REDACTED/REDACTED/REDACTED.jpg
* REDACTED/REDACTED/REDACTED/REDACTED.jpg
2017/02/08 09:11:14 REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/REDACTED.log: Failed to open: unexpected EOF
I supose it's a corrupted file.
Errors:                 1
Errors:                 3
./rclone copy RemoteCrypt:"/REDACTED/REDACTED.log" ./
2017/01/26 19:31:33 REDACTED/REDACTED.log: Copied (new)
2017/01/30 02:48:32 REDACTED/REDACTED.log: Sizes differ
2017/01/30 02:49:12 REDACTED/REDACTED.log: Received error: googleapi: Error 403: User rate limit exceeded, userRateLimitExceeded - low level retry 1/10
2017/01/30 02:49:35 REDACTED/REDACTED.log: Received error: googleapi: Error 403: User rate limit exceeded, userRateLimitExceeded - low level retry 2/10
2017/02/07 17:06:06 REDACTED/REDACTED.log: Sizes differ
2017/01/26 18:41:00 REDACTED/REDACTED.txt: Copied (new)
2017/01/30 01:13:16 REDACTED/REDACTED.txt: Sizes differ
* REDACTED/REDACTED.txt
2017/02/07 17:00:38 REDACTED/REDACTED.txt: Sizes differ
I will have to wait until tomorrow when the ban is lifted, but I may not be able to do a proper test if I keep getting banned when doing an rclone tail...
`rclone cat secret: --tail 1 --stats 1m --discard --log-file=Check-RemoteCrypt.txt --checkers 48`
goroutine 89700 [chan receive]:
Durval.
@DurvalMenezes
This is even stranger. I have successfully gone through literally *millions* of files with (plain) "rclone cat", multiple times, and haven't had a issue so far.
@ncw, could "rclone cat --tail" be doing anything that plain "rclone cat" doesn't, and that could justify a ban?
Durval. Strange, i'm on 34K. And not banned.
The "rclone cat --tail" aborted here after just 1h6m1.8s running, with the following error:
What could have happened? Perhaps the excessive number of goroutines  (over 44K seems a lot for just 48 checkers). This machine has 6GB RAM plus 6GB swap, and at the time the above was being run, less than 250MB (0.25GB) total was in use... :-/
Durval.
Errors:               208
`2017/02/09 13:22:20 REDACTED/REDACTED/REDACTED/REDACTED.avi: Failed to open: couldn't reopen file with offset: bad response: 500: 500 Internal Server Error
`2017/02/09 13:41:49 REDACTED/REDACTED/REDACTED/REDACTED.srt: Failed to open: bad response: 404: 404 Not Found
So, any idea what would that mean? It doesn't sound like a data corruption error to me, ie, ain't got any "failed to authenticate decrypted block" so far...
`2017/02/09 22:17:53 REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/REDACTED.JPG: Failed to open: bad response: 404: 404 Not Found
Durval.
Errors:                 1
Durval.
Errors:            383457
Errors:            387774
`2017/02/10 09:06:09 REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/REDACTED/201207112115/REDACTED/REDACTED/REDACTED/REDACTED.jpg: Failed to open: bad response: 403: 403 Forbidden
@ncw, any hints on to what may be happening? I've just `kill -STOP`ped the above running rclone process for now, to avoid hammering GDrive with apparently useless requests.
Durval.
Sorry I see now you have tried it at 12 checkers.  @ncw, wouldn't a ban also affect the web interface?  Hi @Stonedestroyer,
I'm already running it with 12 checkers, see here: https://github.com/ncw/rclone/issues/999#issuecomment-278822786 Welcome to ban town @DurvalMenezes
Errors:               375
Errors:               508
rclone lsd egd:
rclone@nuwa:~$ rclone -v lsl egd:REDACTED/REDACTED/REDACTED/REDACTED.srt
2017/02/10 09:58:54 Encrypted Google drive root '8s11ep8blimmolv5r05i0kqpcmfga73pdlvvjkr4g9882oh8gdpg/0akiramqp9por9467erap5ec28/n0b83sar1tmt0pdoojbf37q7u6ggkrcv4k290le2n84k910btk40': Modify window is 1ms
So it was a ban after all.
Durval. RED ALERT: I just checked, and the command which got me banned (above) was specifying ONLY SIX CHECKERS! To wit:
I'm trying again with `--checkers 4`, let's see if I get banned again.
Durval.
@DurvalMenezes
I'm using muuuuch more than 6 checkers, and i'm not banned... at least by now.
Errors:               510
Errors:               914
Durval.
Durval.
Durval.
rclone --max-read-ahead 4M --read-only --config /path/to/config mount foo:/bar baz
mount.rclone -o max-read-ahead=4M,ro,config=/path/to/config foo:/bar baz
if [ $parm == "rw"   ]; then continue; fi
if [ $parm == "suid" ]; then continue; fi
if [ $parm == "nosuid" ]; then continue; fi
trans="$trans --$parm"
esac
note: I made an error, and copied the folder REPORTS (from '/P2/A/REPORTS/') inside another place 'P' where it was already existing with the same content. Too bad for me as it appears to me that it deleted my "root/.rclone.conf" file to 0 byte. ;(
poul Much needed enhancement for sure!  - Only start the token ticker when the timetable entry has more than one
bwlimit is specified.
2017/01/06 05:53:22 amazon drive root 'bacula': Warning: file "Vol-0002.gpg" may fail because it is too big. Use --max-size=50000M to skip large files.
TODO:
OK, I wondered if that was global or a built in function of bandwidth. I looked at that code before I went through the GO tutorals. I'll look more closely at how it's implemented. I'll have to copy the format for the time limit, got to convert minutes, hours, and days to seconds. I'll likely just adapt the bytes conversion to a base 60 for time. Unless it's already in a package I haven't looked at yet. GO is still a little weird to me logic flow wise, and learning someone else's logic is always the challenge.
avg shared (code):         0 KB
avg shared (code):         0 KB
avg shared (code):         0 KB
avg shared (code):         0 KB
avg shared (code):         0 KB
As for the issue itself: I see that it completely depends on cobra, so depending on your policy, the issue can either be closed or kept open for tracking.
<https://github.com/notifications/unsubscribe-auth/AHFMBKBIKfU_54v9yst_Li69Vts0SB2sks5rOrfagaJpZM4LZTqo>
rclone 1.35
Warnings:               2
So often I wasn't sure if maybe it's actually meant to say e.g. `List all the objects in the the path`. But then there's places with sentences like `If so, it extracts the the private key` which definitely sounds wrong.
I understand that sync is complex, and thinking about it, i dont know which behaviour has to have with --max/min-age.
Just a small difference, you say to ignore it only on remotes which not support modtime.
* Accesses that only look at a small part of a large tree would likely be more efficient
-> Filename obfuscation (explicit, or possibly implicit if used within a crypto layer)
We'll see strange behavior rclone.
amazon aws s3
2016/12/29 22:19:35 .bashrc-anaconda2.bak: Excluded from sync (and deletion)
ca2******a0116 bucket [28/Dec/2016:06:29:16 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 5104483EDC6FF5AD REST.GET.BUCKET - "GET /bucket?delimiter=&marker=43055%2F55aba977cc05c_14-9-1-1.mp4.jpg&max-keys=1024&prefix= HTTP/1.1" 200 - 345385 - 120 119 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:17 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 1138E425D56F6EF8 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=46057%2F55b53148cec53.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 345952 - 100 99 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:17 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 86D269EED8315CD2 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=4430%2F5521c01a214cf.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 345574 - 97 96 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:17 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser BBA4122DC2CB88A2 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=47748%2F55b9f54cda4bf.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 344645 - 105 104 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:18 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 0A007319FC0DE96D REST.GET.BUCKET - "GET /bucket?delimiter=&marker=49%2Fbaaaeyb7.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 344696 - 67 66 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:18 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 57ADEE9D214AF11E REST.GET.BUCKET - "GET /bucket?delimiter=&marker=52490%2F55d4860063bb7.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 345124 - 79 78 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:18 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser AD8AAF96A35FF081 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=50267%2F55c0f45e9e46b.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 345173 - 63 62 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:19 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 58021027ECEC5B06 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=59797%2Fbaaaayd9.mp4.jpg&max-keys=1024&prefix= HTTP/1.1" 200 - 341953 - 83 82 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:19 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 76C25E8F3AD884D2 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=56470%2F55d4d41cc1a60.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 342748 - 63 62 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:19 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 8DB4B4F5AF8F4375 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=57950%2Fbaaaawnk.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 342174 - 86 85 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:19 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser C60FACEE0F392464 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=54725%2F55cf7e906fb20.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 345458 - 78 77 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:20 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 051C4B1B654BDDCD REST.GET.BUCKET - "GET /bucket?delimiter=&marker=61567%2Fbaaaazv6.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 342205 - 108 107 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:20 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser E119C298DF57DE5C REST.GET.BUCKET - "GET /bucket?delimiter=&marker=6446%2F552fd59e9dc32_8-18.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 341933 - 73 71 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:20 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser FC824835E0EA8925 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=6312%2F552f8a6c0e663.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 342237 - 194 193 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:21 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 830DE698DADB9FFE REST.GET.BUCKET - "GET /bucket?delimiter=&marker=67869%2Fbaaaa5jb.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 342444 - 317 316 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:21 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser ACC4C3D90BF4B2A0 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=66019%2Fbaaaa3xt.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 342365 - 75 74 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:22 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 42B3C9F12ECDEAD4 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=69497%2Fbaaaa6yf.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 341903 - 155 154 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:22 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 63C8FCDF9FEA8144 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=73829%2Fbaaabaj8.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 342580 - 70 68 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:22 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser FBA8C8972515FA45 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=71816%2F560967f649b23.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 342778 - 78 77 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:23 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 47DA37A48FD25BB3 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=76669%2Fbaaabcwv.mp4.jpg&max-keys=1024&prefix= HTTP/1.1" 200 - 342513 - 64 63 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:23 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 4948E5BDA2144970 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=7925%2Fbaaagawy.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 341652 - 73 72 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:23 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 5CC9F2BE693AC884 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=81215%2Fbaaad4nj.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 341371 - 164 163 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:24 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 08847CCA9C5E2D53 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=82990%2Fbaaabxl4.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 341551 - 1072 82 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:25 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 3445E1CA1DF269DD REST.GET.BUCKET - "GET /bucket?delimiter=&marker=84347%2Fbaaabjlb.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 342226 - 369 367 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:26 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 000AD34B7956BD7E REST.GET.BUCKET - "GET /bucket?delimiter=&marker=8742%2Fbaaacg6y.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 342303 - 82 81 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:26 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 5AE415C279C613A8 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=85845%2Fbaaabkxq.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 341597 - 78 77 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:27 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 9E8F0304E8985FD8 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=9013%2F553943f914b28.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 341946 - 74 73 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:27 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser EE7D9EDD977FE115 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=91689%2Fbaaabqc1.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 342424 - 172 171 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:27 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser FEAE58B2A6827F86 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=88627%2Fbaaagj2v.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 341662 - 80 79 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:28 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 23345B680B0D3F41 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=94409%2Fbaaadi4o.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 341393 - 81 80 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:28 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser C933B8B91AD346D9 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=93%2F5456a252ab9b6.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 341610 - 67 66 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:28 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser D11FDF4746CD2BFC REST.GET.BUCKET - "GET /bucket?delimiter=&marker=97546%2Fbaaabvp3.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 341355 - 80 78 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:28 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser DED2015441AB81D9 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=95954%2Fbaaabt9i.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 341470 - 78 77 "-" "rclone/v1.33" -
ca2******a0116 bucket [28/Dec/2016:06:29:29 +0000] x.x.x.230 arn:aws:iam::53****10:user/myuser 745A528F9D7741A6 REST.GET.BUCKET - "GET /bucket?delimiter=&marker=99215%2Fbaaabz7j.mp4&max-keys=1024&prefix= HTTP/1.1" 200 - 242192 - 56 55 "-" "rclone/v1.33" -
aws billing:
s3 (problem bandwith):
and many requests
yes, thank you ncw!
That is the main reason why it should be served using HTTPS
this is preliminary work to add FTP support, as per issue #540. It is not perfect, and doc is still missing, but I would like to have someone to play with it already because I'm not that familiar with Go.
> <https://github.com/notifications/unsubscribe-auth/ABYEtZkcmKq-uzmOHnqP0tK14a62xP_Dks5r6daxgaJpZM4LW0LZ>
it doesn't properly merge, and I happen to be home sick today, so if you
On Tue, May 16, 2017 at 7:11 PM, Antonio Messina <arcimboldo@gmail.com>
>> <https://github.com/notifications/unsubscribe-auth/ABYEtZkcmKq-uzmOHnqP0tK14a62xP_Dks5r6daxgaJpZM4LW0LZ>
2016/12/26 23:25:17 fuse: panic in handler for Rename [ID=0x1c9e Node=0x2 Uid=1000 Gid=1000 Pid=6854] from "M2jj2l5mjvQjAbumThW4bB,kYqrcuktJB2wSmXk,5USH3UwlYRG0Zt89fUa9omhsZiZGHFCjzWUrwwywqndbErBFvUi9s7frkzL8Eo2c9sfo60" to dirnode 0xe "TiOJYSeRij0jIFCrR0AYpyMEs1rO4n74kGwdgajY59pGaY3hdgkRLJv2ZIGbs4xOfLFgloTpuNCWp7d3D2jXpR2d-Wh9dzqZphR3-ZprsdzYZ1": runtime error: invalid memory address or nil pointer dereference
panic(0xb250a0, 0xc420010090)
@scoopydude2002
Every day a have a 24 hours api ban.
Its just listing by API Method @zenjabba
What do you mean with?
Amazon blocked my account today waiting to hear from them to see if I'm getting it back or not so I'd be happy to see this even more now  @jackalblood call the support dont email them, i had my account blocked multiple times and it was always unlocked within 5 minutes by calling them. First time several months ago I email them and waited for 2 days and the first reply was they are looking into it.
I explained them that Iam using acd on 2PC's at home + my notebook and my work PC and that iam moving all my backups to amazon drive.
p.s. There is a guy with 1.5PB uploaded to ACD so far and was not banned once, but he is uploading just with 1GB speed.  They are yet to give me a reason for the ban and I've spoken to 3 different people and all I keep being told is I have to wait for technical team to contact me  Oh also everything on my drive is encrypted regardless of what it was  any news? They finally unbanned me after a 2 week process and haven't been banned since so I asked what the reason was for the ban and received a phone call 3 days later and the guy basically said that my in and out traffic was more then what was considered normal and this could be caused by third party apps keeping data in sync to which my reply was how am I meant to use Amazon on a Linux pc if they don't offer any 1st party application his reply was basically you can't and to carry on using 3rd party programmes and see what happens so basically after the whole ordeal nobody knew exactly the reason I was banned  Would it make sense to add a randomized quotaUser parameter to GDrive API calls for people who have set their own client ID and secret? I feel like the first limit one would hit with the default quotas is the 1,000 queries per 100 seconds per user limit. Using the quotaUser parameter (as far as I understand it) would result in having 10,000 queries per 100 seconds available and could help people between 10 and 100 calls per second.
2. rclone /mnt/plexdriverw
I don't know whether this only affects encrypted remotes.
Create an ACD mount remote: and an encrypted ACD mount under remote:/crypt
abc123/efg456
efg456
$ rclone copy -v --dump-headers --retries 1 -u L4:/afs/acn dropbox:/acn
2016/12/23 18:10:04 rclone: Version "v1.33" starting with parameters ["rclone" "copy" "-v" "--dump-headers" "--retries" "1" "-u" "L4:/afs/acn" "dropbox:/acn"]
Accept-Encoding: gzip
Pragma: no-cache
X-Content-Type-Options: nosniff
2016/12/23 18:10:06 Dropbox root 'acn': Modify window not supported
Accept-Encoding: gzip
Pragma: no-cache
X-Content-Type-Options: nosniff
Accept-Encoding: gzip
Pragma: no-cache
X-Content-Type-Options: nosniff
2016/12/23 18:10:11 Dropbox root 'acn': 2000 delta entries received
Accept-Encoding: gzip
ACD
aa  a.txt
./a/aa:
aa.txt
With some more testing I found that ** had an unexpected behavior (it worked). I added some more folders to test:
2016/12/21 12:02:02 a/aa/aa.txt: Not copying as --dry-run
2016/12/21 12:02:02 a/aa/This is test/test.txt: Not copying as --dry-run
Remote is b2.
outputsa.logaa.zip <https://drive.google.com/uc?export=download&id=0BzuhYKTnNu0ka25sNzRwSHhJejg>
Ivairus\Soft\rclone-v1.34-windows-amd64\rclone-v1.34-windows-amd64\locally_crypted\a4ujg8ujgfmr02bjc
7k1uuqtuc\dasc3bku5k4mr1vb4odbck160g\5ftbcerumou67qrbeqkfq1ah24\lg560naf1456ns391k935j19fv58c4ph8hd4
5gag4tc5b76ajpqg\lg560naf1456ns391k935j19fv58c4ph8hd45gag4tc5b76ajpqg\k1otgi668suitabnjkoofijjls\mju
oc8db6q8bdnmbn9rv56unq05fg08tt6bnrfl4s704kp183e6g\raj6rcnf4uhqvmueagk71ltb9412qkv56nb7ru4qo014c4e0qh
4g\82psipedlis9ldtc40g9o9v1gc8oifkio9p0nk4diepjcm1h0urg\h0ug27mr0766ubj13him56ga3c5nmvbegi24sb22d8ev
d12v4flg\ceft2onfgsnuhlq1935tukpjmqa8j35la6teaanc70jvq8di7ac7pakpalkqi4oml7sjqigln18o2f29ahve8n3ac32
volume label syntax is incorrect.
http://gohugo.io/commands/
read(3, "\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\260Z\0\0\0\0\0\0"..., 832) = 832
read(3, "\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\20\34\0\0\0\0\0\0"..., 832) = 832
read(3, "\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\300\20\0\0\0\0\0\0"..., 832) = 832
read(3, "\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0P\t\2\0\0\0\0\0"..., 832) = 832
read(3, "\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0000\25\0\0\0\0\0\0"..., 832) = 832
read(3, "\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\240\r\0\0\0\0\0\0"..., 832) = 832
read(3, "\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\260`\0\0\0\0\0\0"..., 832) = 832
lseek(0, 0, SEEK_CUR)                   = -1 ESPIPE (Illegal seek)
ENFCS MOUNT
read(3, "\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\260Z\0\0\0\0\0\0"..., 832) = 832
read(3, "\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\20\34\0\0\0\0\0\0"..., 832) = 832
read(3, "\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\300\20\0\0\0\0\0\0"..., 832) = 832
read(3, "\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0P\t\2\0\0\0\0\0"..., 832) = 832
read(3, "\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0000\25\0\0\0\0\0\0"..., 832) = 832
read(3, "\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\240\r\0\0\0\0\0\0"..., 832) = 832
read(3, "\177ELF\2\1\1\0\0\0\0\0\0\0\0\0\3\0>\0\1\0\0\0\260`\0\0\0\0\0\0"..., 832) = 832
lseek(0, 0, SEEK_CUR)                   = -1 ESPIPE (Illegal seek)
cd to acd.  Tried the following commands.
`rclone lsd gdenc:/test/`
rclone mkdir gdenc:/test
`rclone lsd gdenc:/test`
Rclone 1.34
rclone authorize "onedrive"
This is where the problem comes in:
- I tired it on Ubunutu 14.04 LTS and windows 7 Home and pro
rclone --no-traverse `// (doesn't scan the destination for duplicates that exist in other folders, this can save a lot of time if you have many subdirectories)` --update `// (only overwrite files with a new size/modtime)` --drive-chunk-size=64M `// (Not sure if rclone downloads the folder and reuploads it, or does a server side copy, so this may be useless for your application, not sure.)` --transfers=6 `// (More and more can help speed up your transfer speeds for both small files and large files, you may choose to use as many as 16 if you're transferring small files.)` copy remote:Gdrive_1 remote:Gdrive_2 @jpat0000 sorry for not clarifying better,
Depending on what you mean by "absolute value", I probably agree. Specifically, in addition to being a non-relative path, I think the path needs to be canonicalized to remove this-directory (./) and parent-directory (../) sequences, superfluous '/' sequences (e.g., /mnt///path -> /mnt/path), and also should resolve symbolic links. Hi jediry, I just want to chime in and say that everything you said makes a lot of sense to me. One minor comment:
sjurtf@cornsnake:~$ rclone -V
sjurtf@cornsnake:~$ uname -a
2016/12/11 17:20:54 fuse: -> [ID=0xb] Lookup error=ENOENT
2016/12/11 17:20:54 fuse: -> [ID=0xc] Lookup error=ENOENT
2016/12/11 17:20:54 fuse: -> [ID=0xd] Lookup error=ENOENT
a.Crtime = modTime
Mounted
> drwxr-xr-x 1 plex plex 0 Dec 12 22:17 0bcg2fxCfXuALH5I,OY,Z7VX5tn4n8I3WaMWs8Ez,RWIp0
> drwxr-xr-x 1 plex plex 0 Dec 12 22:17 0eBiG-lRoC2vAoiM5W7OYwevAjd,j5uOsu-FQZaBdxzbX0
> drwxr-xr-x 1 plex plex 0 Dec 12 22:17 0HQA45I6d0XrurdJ0DeUlfWbcgQrBcbAwh6H4DmgIzutI0
> drwxr-xr-x 1 plex plex 0 Dec 12 22:17 0MXIr8e1,dlkwAQFxp49zY6uadn8nzLwm5JOA,SCS-uBe,
@flixajki
@flixajki
Amazon Drive, crypt overlay
> root@backup jochs $ strace -p 1177
Interesting to see how slow my connection to ACD is though!
rclone mount robacd: g &
rsync -avh --progress --inplace "/home/wreckedred/mntacd/pe/tv/Teen Wolf S06E03.mp4" .
Teen Wolf S06E03.mp4
ubuntu@apex:~$ rclone mount secretacd: /home/wreckedred/mntacd &
acd: g should be quiet
> <https://github.com/notifications/unsubscribe-auth/AKixh_Eq8nVXzVfG4LklQBqpma6yQL4jks5rGBSugaJpZM4LGeWV>
`rclone mount acd: /Volumes/Local`
Not too sure if this is a fuse or rclone issue.
panic(0x729fe0, 0xc4200140e0)
panic(0x729fe0, 0xc4200140e0)
panic(0x938b80, 0x112e0220)
log.Panicf(0x9f9be9, 0x3a, 0x1142513c, 0x2, 0x2)
/home/ncw/Code/Go/src/github.com/ncw/rclone/vendor/github.com/rfjakob/eme/eme.go:119 +0xebf
github.com/ncw/rclone/crypt.(*cipher).encryptSegment(0x11392af0, 0x113787dc, 0x880, 0x0, 0x0)
github.com/ncw/rclone/crypt.(*cipher).EncryptFileName(0x11392af0, 0x1137600c, 0x4152, 0x0, 0x0)
github.com/ncw/rclone/crypt.NewFs(0x113ed800, 0xb, 0x113ed80c, 0x17e5, 0x0, 0x0, 0x0, 0x0)
github.com/ncw/rclone/crypt.NewFs(0x11400000, 0xb, 0x1140000c, 0x459, 0x0, 0x0, 0x0, 0x0)
github.com/ncw/rclone/crypt.NewFs(0x112f4500, 0xb, 0x112f450c, 0x23a, 0x0, 0x0, 0x0, 0x0)
2 - We are missing a rename command. This is especially useful for the encrypted backups, because  of the encrypted filenames. Otherwise we could simply use the cloud interface,given by the service provider, to rename each file and folder. But with encrypted version it is not possible since we don't know what name means what, and we don't know how to manually create encrypted names. Sorry, just saw there was already people asking for that.  This is more of a feature request than an issue, please tell me if this is the right place to write.
But having to type our passwords on every command can be annoying.
But later I thought: "What will happen if ACD mounted on /mnt/acd/ is going to crash?".
Rackspace
key = APIKEY
The one returned is the first one as viewed in Cyberduck.
If I try simply adding `region = dfw` to the `rclone` config file and `rclone lsd devcf:` it then starts complaining about parameters I don't know exactly what they need to be and are ones I don't have to provide with `turbolink` or `Cyberduck` as follows: `Failed to create file system for "devcf:": Response didn't have storage url and auth token`
1. when not specifying region at all and one container exists in IAD, all other containers in other regions are ignored
strategies are gimmicks that trick people into paying more in storage
Class B operations are more than double with Nearline, and 12x more
very stingy with operations, but for something like rclone where you
> So it looks like S3 Infrequent Access would be the way to go.  It looks like
http://imgur.com/a/IgMNy
rclone copy ~/ngEn Remote:Nedladdat(F) --drive-chunk-size 128 M
Is the content of both duplicate folder copied to the computer if I use rclone copy Remote:Folder Localdrive:folder ?   A way to interact with the remote destinations in a cli mode would be useful It would have a way of selecting files in a list and management from there. Like a cli file manager. Would make browsing a lot easier. Doesn't mounting it accomplish that?  Just wondering what you meant. I think they mean something like midnight commander?  @ncw a tui is what I mean.
Blessings and happy Wednesday @marrie I'm also visually impaired but this wouldn't replace any functionality and maybe provide some sort of gui wrapper for it with better accessibility. I can't code my way out of a corner So I don't know these things, at least not yet. It's worth a try if someone can somehow implement accessibility controls for voiceover and nvda and what ever is used on linux these days.
niccolo@niccolo-Aspire-5930:/mnt/acd_e$ cp ~/Documenti/la\ Repubblica\ -\ 6\ Luglio\ 2016.pdf ./
niccolo@niccolo-Aspire-5930:/mnt/acd_e$ mkdir test
niccolo@niccolo-Aspire-5930:/mnt/acd_e$ mv la\ Repubblica\ -\ 6\ Luglio\ 2016.pdf test/
niccolo@niccolo-Aspire-5930:/mnt/acd_e$ ls
panic(0xb05c20, 0xc42000e0f0)
panic(0xb05c20, 0xc42000e0f0)
panic(0xb05c20, 0xc42000e0f0)
panic(0xb05c20, 0xc42000e0f0)
panic(0xb05c20, 0xc42000e0f0)
panic(0xb05c20, 0xc42000e0f0)
panic(0xb05c20, 0xc42000e0f0)
niccolo@niccolo-Aspire-5930:/mnt/acd_e$ ls
niccolo@niccolo-Aspire-5930:/mnt/acd_e$ cd test
niccolo@niccolo-Aspire-5930:/mnt/acd_e/test$ ls
panic(0xb05c20, 0xc42000e0f0)
niccolo@niccolo-Aspire-5930:/mnt/acd_e/test$ ls
panic(0xb05c20, 0xc42000e0f0)
niccolo@niccolo-Aspire-5930:/mnt/acd_e/test$ cd ..
niccolo@niccolo-Aspire-5930:/mnt/acd_e$ ls
niccolo@niccolo-Aspire-5930:/mnt/acd_e$ cd test
niccolo@niccolo-Aspire-5930:/mnt/acd_e/test$ ls
panic(0xb05c20, 0xc42000e0f0)
niccolo@niccolo-Aspire-5930:/mnt/acd_e/test$ ls
panic(0xb05c20, 0xc42000e0f0)
("403 Forbidden")
("403 Forbidden")
Those be bad ideas!  [See below](https://github.com/ncw/rclone/issues/914#issuecomment-270360686) So far this issue did not changed for me (using ceph). And I do agree with your suggestions. Did some testing, turns out I had `rclone move`'d the same file but with a slightly different case over to a crypt remote (ie, case-sentitive).  There's nothing rclone can do in this scenario - I had to remove unwanted files manually.  The warning is just being polite!
So alternatively, rclone might be trying to tell me:
I mention the last scenario as a possible edge case because so far the only cases I found of this involved multiple copies of the file, some with identical content and some not (all with the identical name but different paths).
I was using the version that allowed writing to ACD, I've since downgraded to v1.34-23-gc41b67eβ
[remote]
type = yandex
[secret]
type = crypt
remote = remote:secret
password = XXX
password2 = XXX
Ubuntu 15.10
I have setup services through ACD.
[2] 2072 (sometimes this is different)
Issue:
rclone mount remote: /home/plex/.acd &
ls /home/plex/.acd
After a bit over 24 hours, it started spouting these errors:
rclone -v copy /tmp amazon:tmp
2016/11/21 16:29:59 Encrypted amazon drive root 'Crypt/hm38iondlmn90pvq0fn7aghs3g': Modify window not supported
2016/11/21 16:29:59 amazon drive root 'Crypt/hm38iondlmn90pvq0fn7aghs3g': Reading ""
2016/11/21 16:29:59 amazon drive root 'Crypt/hm38iondlmn90pvq0fn7aghs3g': Finished reading ""
2016/11/21 16:29:59 Encrypted amazon drive root 'Crypt/hm38iondlmn90pvq0fn7aghs3g': Waiting for checks to finish
2016/11/21 16:29:59 Encrypted amazon drive root 'Crypt/hm38iondlmn90pvq0fn7aghs3g': Waiting for transfers to finish
Drive which makes me think it's not just specific to Amazon.
Centos6 64bit
onedrive & onedrive for business
Could be very useful for ACD as well, since if you hammer that too much on outbound requests you get a similar effect, in very rare cases some users on Reddit have reported having their drives disabled.
Ali I'm not using RClone for media, but still the lack of cache is a drawback. NCW, is there any agenda when/if it will be added?   When filing an issue, please include the following information if possible as well as a description of the problem.  Make sure you test with the [latest beta of rclone](http://rclone.org/downloads/).
Debian 8 Jessie 64 bit
ACDFuse         100T  3.5T   97T   4% /mnt/amazon
("409 Conflict")
QNAP QTS 4.2.2
Cadish I've run into 409's most-often when there are files in the same directory with the same name, differing only by case. Amazon Drive can't store case-sensitive files.
strace:
[pid 31637] connect(3, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("<DNS1>")}, 16) = 0
[pid 31641] connect(5, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("<DNS1>")}, 16) = 0
-1 2016-10-27 20:01:38        -1 bluearc
![](https://i.imgur.com/LAukBqQ.png) I think Team Drives should be their own remote. They are meant to be
want them nested under My Drive.
> How do you think this should be used from within rclone?
> Using the handy graphic above, rclone uses the contents of "My Drive"
> Alternatively I could make a kind of virtual file system making a Pseudo
> <https://github.com/notifications/unsubscribe-auth/AKOQXZauP7muspXB6OulO-kHHRp4xj9Aks5rlWGzgaJpZM4Ky3QD>
If it is done as a remote:
Taking a flag with the team drive name could be trickier than you think, as it doesn't appear to be supported in that way from the API.
good idea to tell the user it's "migrating" and may take a while, and don't
duplicates.
> <https://github.com/notifications/unsubscribe-auth/AYvIjSkwa-baAuDbapUDQZefrH26OhJuks5rv5gSgaJpZM4Ky3QD>
> <https://github.com/notifications/unsubscribe-auth/AKOQXRZA-bNXsjA3j_f1hWMwADhhlAkwks5r8wwOgaJpZM4Ky3QD>
2017/06/02 08:09:27 ERROR : backups/backup_20150101.tgz: Failed to copy: failed to make directory: googleapi: Error 404: File not found: 0B6oOu8lLpFayaENqdjRJbjNCd1k, notFound
2017/06/02 08:09:28 ERROR : backups/backup_20150102.tgz: Failed to copy: failed to make directory: googleapi: Error 404: File not found: 0B6oOu8lLpFayaENqdjRJbjNCd1k, notFound
2017/06/04 07:00:20 ERROR : 2013 RM MOTHERS DAY/MVI_7671.MOV: Failed to copy: googleapi: Error 404: File not found: 0B3vEQiiMiugPSEl5YUcySmdSWlE, notFound
Errors:               435
But rclone size reports
The errors aren't consistent as to the filetype, it seems to happen more with larger files.  Obviously media files are larger, so it happens more with those than small files. The particular directory I was trying to upload, having a look at what worked and didn't, anything over 8MB appears to have failed.
and here's with dump-headers https://cryptobin.co/39a667c6 - too big for pastebin, pw is 123 @ncw Aha my bad! I will give it a try later today (someone will most likely beat me to it). ;) It worked fine for me! I can tell you this version is working fine with Team Drive @ncw after 10 hours of copying, it's transferred > 100GB with no errors! :-D
Unfortunately, I lack the knowledge of Go to implement this myself.  Service: b2
[output log here](https://github.com/ncw/rclone/files/593812/outputsa.logaa.zip)
./rc -v copy /home/klepto/downloads/ ACDCEE:DL --transfers=40
> https://github.com/notifications/unsubscribe-auth/AFuHg_EyZJlHE2I_Tk8luU7BCqv8JU_9ks5q-eN-gaJpZM4Kyu7l.Web
> Bug from
> https://github.com/notifications/beacon/AFuHg3_dt-MiXy3F4xi5XksV0SmCHW3Qks5q-eN-gaJpZM4Kyu7l.gif
When using verbose output (useful from scripts), nothing is printed *before* a file is copied, only when it is complete. This can result in extremely long delays on large files during which the user doesn't know what is happening. I checked the complete output for the logged session above, and the file "WWW.Working!! - 07.mkv" was never mentioned prior to that entry. Note the long time (~20min) between the "Waiting for transfers to finish" and the "Copied" note. +1, I've been bugged by this behavior as well.
1.33-DEV
Thanks for rclone, btw, it's awesome.
sse                string           // the type of server-side encryption
sse:                fs.ConfigFileGet(name, "server_side_encryption"),
if *s3ACL != "" {
```  I was uploading a 12GB file to Onedrive and got this error: `Failed to copy: invalidRequest: maxFileSizeExceeded: Declared file size too large. The largest allowed file size is 10737418240 bytes`. Didn't see it anywhere in the docs, so I thought I'd add it.  Decided to add this to track adjustment to --max-read-ahead per discussion in the forum. As per forum user @calisro this value may need to be dynamically calculated and can be overwritten with a flag.  Is there any way to use Rclone with an application interface (i. e. to build a GUI) or will there be such a feature in the future? I messaged @ncw a few months ago about doing this. He said he thought it would be a good idea. I, however, got lost in my day job and other obligations and never got through to writing this. I don't know Go at the moment, but am trying to learn. But, I do know a decent bit about Python API design and Angular (2+) front end design. So I'd be happy to, and would like to write a UI and API for rclone, as long as a person or two don't mind giving me a little support along the way with the Go aspects of it.  Yes, I think this would address what I'm trying to do over in https://forum.rclone.org/t/best-way-to-use-multiple-filters-from-a-script/240/2 . The suggestion of a temp file was basically where I was at, although that involved a bunch of mess and cleanup. I'll look forward to a beta! :)
Left it running seemed to just happen at random again:
2016/11/17 02:58:48 REDACTED2: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 02:58:48 REDACTED2: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 02:58:48 REDACTED2: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 02:58:48 REDACTED2: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 02:58:48 REDACTED2: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 03:51:59 REDACTED4: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 03:51:59 REDACTED4: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 03:51:59 REDACTED4: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 03:51:59 REDACTED4: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 03:51:59 REDACTED4: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 03:51:59 REDACTED4: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 04:03:28 REDACTED5: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 04:03:28 REDACTED5: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 04:03:28 REDACTED5: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 04:03:28 REDACTED5: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 04:03:28 REDACTED5: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 04:03:28 REDACTED5: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 04:22:06 REDACTED6: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 04:23:30 REDACTED7: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 04:23:30 REDACTED7: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 04:23:30 REDACTED7: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 04:23:30 REDACTED7: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 04:23:30 REDACTED7: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 04:56:34 REDACTED8: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 08:41:19 REDACTED9: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/11/17 09:02:42 REDACTED10: ReadFileHandle.Read error: failed to authenticate decrypted block - bad password?
2016/12/03 09:03:28 fuse: <- Flush [ID=0x90a Node=0x2a Uid=33 Gid=33 Pid=12178] 0x1 fl=0x0 lk=0xb636100beda28e91
panic(0xb24fc0, 0xc420010090)
0 -rw-r--r-- 1 stefan stefan  583076191 Sep 18 15:56 random.bin
0 -rw-r--r-- 1 stefan stefan 1139375223 Sep 18 15:54 random2.bin
569411 -rw-r--r-- 1 stefan stefan  583076191 Sep 18 15:56 random.bin
1112672 -rw-r--r-- 1 stefan stefan 1139375223 Sep 18 15:54 random2.bin
Thanks! Great product. Since rclone is so useful, I find myself doing repeated operations with it (file uploads and deletions, manipulations, etc). At each touch, I have to re-enter the password for the config… not an incentive to keep an appropriately complex password. :)
Alden
`mklink /d "c:\folder" "\\nas\e\folder"`
Both failed, but differently.
rclone 1.3.4
rclone sync
Debian 8
rclone sync /path amazon:/path --verbose
": Deletedarie/2/Icon"
Thank you, rclone changed everything for the best!
1) A minor misspelling - line 188 says "reponse" rather than "response"
Using rclone 1.34 I still see the behavior originally reported (improper line feeds, not the extra escaping noted in the beta build). I wonder if it's as simple as inserting a substitution from carriage return/linefeed to escape sequence immediately before output is made to the screen (assuming there is a single routine this flows through). In Perl, something akin to 's/\r/\r/' and 's/\n/\n/'. That would fix both this issue and any lingering things from Icon\r files (or prevent them, should you find a way to re-implement that in the future). Just a thought.
This behavior is file-inconsistent in the sense that files that sometimes are "fast" can be slow after awhile and vice-versa.
rclone v.1.34
Accept-Encoding: gzip
Pragma: no-cache
Vary: User-Agent
Accept-Encoding: gzip
Pragma: no-cache
Vary: User-Agent
X-Amzn-Requestid: 6770de30-a439-11e6-b2fd-41afa873d2c7
Accept-Encoding: gzip
Pragma: no-cache
Vary: User-Agent
X-Amzn-Requestid: 67a02bc8-a439-11e6-af7a-d15cdd98a493
Accept-Encoding: gzip
Pragma: no-cache
Vary: User-Agent
pi@raspinas:~$ mount
acde: on /home/pi/amazon type fuse.rclone (rw,nosuid,nodev,relatime,user_id=1000,group_id=1000)
pi@raspinas:~$ ls -la
d?????????   ? ?    ?           ?            ? amazon
- I guess it's actually 32bit, I was mistaken here
pi@raspinas:~$ uname -a
The log is very large and has lots of sensitive info. Will redact and post later if requested/necessary.
drwxr-xr-x 1 rclone rclone         0 Nov  6 10:40 XXXXXXXXXXX0001
drwxr-xr-x 1 rclone rclone         0 Nov  6 10:40 XXXXXXXXXXX0002
drwxr-xr-x 1 rclone rclone         0 Nov  6 10:40 XXXXXXXXXXX0003a
drwxr-xr-x 1 rclone rclone         0 Nov  6 10:40 XXXXXXXXXXX0003b
drwxr-xr-x 1 rclone rclone         0 Nov  6 10:40 XXXXXXXXXXX0004a
drwxr-xr-x 1 rclone rclone         0 Nov  6 10:40 XXXXXXXXXXX0004b
drwxr-xr-x 1 rclone rclone         0 Nov  6 10:40 XXXXXXXXXXX0005
drwxr-xr-x 1 rclone rclone         0 Nov  6 10:40 XXXXXXXXXXX0006
drwxr-xr-x 1 rclone rclone         0 Nov  6 10:40 XXXXXXXXXXX0007
drwxr-xr-x 1 rclone rclone         0 Nov  6 10:40 XXXXXXXXXXX0008
drwxr-xr-x 1 rclone rclone         0 Nov  6 10:40 XXXXXXXXXXX0009
drwxr-xr-x 1 rclone rclone         0 Nov  6 10:40 XXXXXXXXXXX0010
drwxr-xr-x 1 rclone rclone         0 Nov  6 10:40 ZZZZZZZZZZZZ01
2. The above suspect is confirmed with an "rclone lsd ACDE:", to wit:
Durval. Hello @ncw,
> I note also that you've used two different remotes ACDE: and acdenc: in your tests.
My mistake during editing my post... it's actually ACDE: all the way.
> `rclone -q ls --max-depth 1 ACDE:`
`582582272 YYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY_-_split_aa
Durval.
I fixed a couple of bugs and noticed that the DirCache was not properly updated. Right now it simply flushes the whole cache on move, although a more fine grained clean up would be possible: While I can `dc.Put(newPath, oldFileId)`, I cannot remove the old `dc.cache[path] = id` association, for which I cannot see any option. So I guess the DirCache would need an extension like `Delete(path string)` and/or `DeleteInv(id string)`. `Delete` + `Put` would be enough for Amazon's case, but it does make the API rather fragile. Not sure if it's worth the effort, so I'd say let's wait and see if there are any performance issues with flushing the cache.
FLUSHING--------
2016/11/05 15:31:57 amazon drive root 'rclone-test-joyaveh8suneliq4vivehoh1': Reading ""
2016/11/05 15:31:57 amazon drive root 'rclone-test-joyaveh8suneliq4vivehoh1': Finished reading ""
2016/11/05 15:31:57 amazon drive root 'rclone-test-joyaveh8suneliq4vivehoh1': Reading "moveTest/"
2016/11/05 15:31:57 amazon drive root 'rclone-test-joyaveh8suneliq4vivehoh1': Reading "batshitcrazy/"
2016/11/05 15:31:57 amazon drive root 'rclone-test-joyaveh8suneliq4vivehoh1': Finished reading "moveTest/"
2016/11/05 15:31:58 amazon drive root 'rclone-test-joyaveh8suneliq4vivehoh1': Finished reading "batshitcrazy/"
@ncw I see two options here:
Looking good! That children bug explains some of the problems I was running into... Sorry I didn't get the chance to finish this off but it looks like it's all going well.
@breunigs I'd probably just put it all in-line or a function but I hate goto statements, looks good otherwise. If ACD didn't have so many silly hangups with caching/slow updates. I probably would have got it with my first attempt, but I ran into a lot of those weird issues and didn't have time to debug it I'm glad you did though! :) I like your workaround for trashing a file to rename it on conflict.
My case, it includes FPU, maybe the routers that he's working on, doesn't includes fpu. @alecuba16, I'm fairly positive that the 24KEc and 1004Kc cores have no FPU — it's the 24Kf and the 1004Kf that do.  I'm glad to hear that Go binaries work for you, I'd be interested to know the explanation. @jech
b)-The gdrive code and its dependencies doesn't do any FPU compute, that is mostly improbable because it uses https, graph algorithms,and other dependencies that for sure there are floats...
MIPS32be (big endian) : https://mega.nz/#!w59x2BIR!-A0bSwkqW-KCN-yZxrSw9r_17uSXwTHL9Jz1xEydKU4
MIPS32le (little endian):
https://mega.nz/#!Eh0EwYaZ!8-qQgtEW3kXPSEoRQHhG5mk3QZ0VECxGyjeLuenlzoc
file test_mipsle
@ncw @alecuba16 @jech where you able to get a `Go` binary running on RT-N56U or MIPS32?
file /sbin/uci
Thanks for the help @alecuba16 . Hello,
Is important to determine if it is MIPS Little endian (LE/LSB) or big endian (BE/MSB), since they are different.
Command I used: sudo rclone --config /home/raansu/.rclone.conf -v sync /mnt/split/encrypted/ "amazon-cloud:My Drive"
(https://github.com/tokland/youtube-upload)
Rclone version:
Mac os sierra
Note that several people may share files with the SA and in that case files will come from different Drives, different folders. Work with filtering and path handling may differ.  Every time you upload a video to Google Drive, Google goes through the trouble of converting this media into various bitrates and resolutions. Being able to download these files, as well as point to them with applications such as Plex using rclone's mount feature, could be greatly beneficial.
debiian 8.3
acd
https://gyazo.com/323684a89050ef6cd22af05a77d25920
again look at the screenshot above, it completely missed the rar file, also simply changing a filename allowed one directory/file to be copied
@yadayada might want to take a look at this...  Hello
- replacing a parent (which is what you called `Move` in go-acd) is not possible while a node is trashed
if sLeaf != tLeaf {
goto OnConflict
OnConflict:
fs.Debug(src, "OMG WE HAD A CONFLICT, DOING SUPER COMPLICATED METHOD")
go acd: https://github.com/ncw/go-acd/compare/master...breunigs:additional-methods?expand=1
rclone: https://github.com/ncw/rclone/compare/master...breunigs:add-moving?expand=1
the verbose output is a huge list of million files scrolling past...
/data/Media2 is a crypt mount
rclone \
--config="$RCLONECONF" \
--include "*.nfo" \
--include="*.nfo" \
This is an encrypted mount.
Is that intended? Seems quite odd.
rclone ls robacd-crypt:/xbmc.log
1694674 xbmc.log
1694674 xbmc**.log**
rclone ls robacd-crypt:/xbmc.log
xbmc.log
ls -al | grep xbmc
drwxrwxr-x 1 deluge mediashare 0 Oct 27 15:39 xbmc.txt
ls -al xbmc.txt/*
-rw-rw-r-- 1 deluge mediashare 1694674 Oct 28 10:14 xbmc.txt/xbmc.log
Yeah it's really weird, I was going to take a look at fixing it myself but looks like the underlying lib is missing a lot of node stuff from the API.
rclone \
--config="$RCLONECONF" \
--config="$RCLONECONF" \
52.7.68.18 content-na.drive.amazonaws.com
Errors:                 9
Errors:               136
Writing works for all except B2 and ACD?
I've also seen that there is an [LRU example](https://github.com/golang/groupcache/blob/master/lru/lru.go) in the respository of [groupcache](https://github.com/golang/groupcache) from the standard library.
@xelra this is mainly a write cache so that rclone can stat the file(s) properly as ACD and B2 doesn't support uploading unknown file sizes.
How many tickets are there for this? Regardless, see #890 for writing support for ACD.
2016/11/19 11:40:17 mediafile.mkv: Upload error detected but didn't finish upload: HTTP code 400: "400 Bad Request": response body: "{\"logref\":\"dxxxxxxxe-ae4c-1xxx6-9c74-3d4xxxxx78\",\"message\":\"A node cannot be added to trashed parent\",\"code\":\"\"}" ("400 Bad Request")
bazil.org/fuse/fs.(_Server).serve.func2(0xdf7900, 0xc420160770, 0xc420461eb8, 0xc420461e0f)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:857 +0x1d9
panic(0xa2f7a0, 0xc420010090)
github.com/ncw/rclone/crypt.(_decrypter).Read(0xc42126a960, 0xc420518000, 0x20000, 0x20000, 0x0, 0x0, 0x44fe10)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:1249 +0x98c
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:878 +0x4a3
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:425 +0x6e
created by bazil.org/fuse/fs.(_Server).Serve
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:426 +0x3e4
bazil.org/fuse/fs.(_Server).serve.func2(0xdf7900, 0xc420160850, 0xc42037eec8, 0xc42037ee1f)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:857 +0x1d9
panic(0xa2f7a0, 0xc420010090)
github.com/ncw/rclone/crypt.(_decrypter).Seek(0xc42126a960, 0x20000, 0x0, 0x2d, 0xc42037e7c8, 0x2)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:1249 +0x98c
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:878 +0x4a3
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:425 +0x6e
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:426 +0x3e4
> I could see this translating into flags for rclone
Thanks in Advanced
This will work on Crypt remote too? I mean, it will retuns the unencrypted N bytes of a remote crypt?
Storage system: B2
Is this something unique with the way nginx uses seek?
BIND
UNIONFS
I know yours is different in that you probably had unionfs as part of the rclone mount.  But you could try this:
UNIONFS
-  -  BIND mount
-  - rclone mount
EDIT:  It works pretty darn well in KODI as well!!!!  This is pretty awesome.
2016/10/23 23:36:07 abc: Dir.Lookup
2016/10/23 23:36:09 ab: Dir.Lookup
/build/rclone/src/rclone/.gopath/src/bazil.org/fuse/fs/serve.go:857 +0x98
panic(0x60ee90, 0x10c26008)
/build/rclone/src/rclone/.gopath/src/bazil.org/fuse/fs/serve.go:260 +0x160
/build/rclone/src/rclone/.gopath/src/bazil.org/fuse/fs/serve.go:1404 +0x64
/build/rclone/src/rclone/.gopath/src/bazil.org/fuse/fs/serve.go:1111 +0x1328
/build/rclone/src/rclone/.gopath/src/bazil.org/fuse/fs/serve.go:878 +0x608
bazil.org/fuse/fs.(*Server).Serve.func1(0x10d2d500, 0x8f9bc0, 0x10d8a680)
/build/rclone/src/rclone/.gopath/src/bazil.org/fuse/fs/serve.go:425 +0x78
/build/rclone/src/rclone/.gopath/src/bazil.org/fuse/fs/serve.go:426 +0x548
debian 8 (jessie) 32bit armhf @ bananapi m2
BogoMIPS        : 1195.38
BogoMIPS        : 1199.69
Features        : swp half thumb fastmult vfp edsp neon vfpv3 tls vfpv4 idiva idivt
Hardware        : sun7i
beta/rclone-v1.33-77-g93e8440-linux-arm/rclone mount amazon:/ /mnt/amazon -v --debug-fuse
beta/rclone-v1.33-77-g93e8440-linux-arm/rclone mount amazon:/ /mnt/amazon -v --debug-fuse
2016/10/23 13:11:10 fuse: <- Lookup [ID=0x2 Node=0x1 Uid=1000 Gid=1000 Pid=32569] "Dokumente"
2016/10/23 13:11:11 amazon drive root '': Reading "Dokumente/"
2016/10/23 13:11:12 amazon drive root '': Finished reading "Dokumente/"
2016/10/23 13:11:12 fuse: -> [ID=0x3] Lookup error=ENOENT
2016/10/23 13:11:12 fuse: -> [ID=0x4] Lookup error=ENOENT
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:857 +0x98
panic(0x619f58, 0x10c20008)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:260 +0x160
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:1404 +0x64
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:1111 +0x1328
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:878 +0x608
bazil.org/fuse/fs.(*Server).Serve.func1(0x10f857a0, 0x90aa60, 0x1107c100)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:425 +0x78
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:426 +0x548
2016/10/23 19:37:58 fuse: <- Lookup [ID=0x2 Node=0x1 Uid=1000 Gid=1000 Pid=3047] "Dokumente"
2016/10/23 19:37:58 amazon drive root '': Reading "Dokumente/"
2016/10/23 19:37:59 amazon drive root '': Finished reading "Dokumente/"
2016/10/23 19:37:59 fuse: -> [ID=0x3] Lookup error=ENOENT
2016/10/23 19:37:59 fuse: -> [ID=0x4] Lookup error=ENOENT
rclone v1.33-71-ga02edb9β
2016/10/23 14:19:50 Failed to create file system for "b2:samusic/3archives": failed to authorize account: failed to authenticate: Get https://api.backblazeb2.com/b2api/v1/b2_authorize_account: x509: certificate signed by unknown authority
What I can clearly observe is that I get this segmentation fault just on beta versions on the Synology where the additional flags are implemented.
Encrypted amazon drive root 'Proliant': Modify window not supported
Sending rclone a SIGUSR2 signal will toggle the limiter between off and
Aha! That's why appveyor was failing then! I was curious about that. Looking at the logs, it didn't appear to be anything related to my changes, and I was puzzled.
Hello @ncw, @marcopaganini,
Durval.
Seems like Sonarr tries to transfer the file in parts and thus causing some issue.
2016/10/21 15:44:32 Anime/Looney Tunes/Looney Tunes Vol 1/Looney.tunes.e39.1080p bluray x265 HEVC-Lewiswill[UTR].mkv: ReadFileHandle.Read error: file already closed
2016/10/21 15:44:43 Anime/The Legend Of Korra/Season 00/The Legend Of Korra S00E00 S2 Scene Bending Harmonic Convergence x265 HEVC-ByteShare[UTR].mkv: ReadFileHandle.Read error: file already closed
pi@raspberrypi:~/v $ rclone -v copy gdrive:Abc Abc
ATOP - raspberrypi        2016/10/20  20:05:55        ------         10s elapsed
Packets               Pings
Bad News:
I was trying to narrow down if it was definitely a Ceph bug (Rather than an rclone bug), but it seems you've deleted or locked issue #586, so I can't access it anymore.
Let me know what I should do to diagnose this further, I'd love to be able to keep my Subsonic library on ACD.
I've been playing around with Subsonic with an ACD mount as well, both with rclone and acdcli, and I've pretty much given up on the idea.. the slowness isn't limited to rclone.
rclone rmdir - Remove the path.
rclone v1.33-6-g2eaac80β
$ uname -a
ACD remote: `acd:`
2 - We are missing a rename command. This is especially useful for the encrypted backups, because of the encrypted filenames. Otherwise we could simply use the cloud interface,given by the service provider, to rename each file and folder. But with encrypted version it is not possible since we don't know what name means what, and we don't know how to manually create encrypted names. Awesome, thanks!
Dest: Minio (S3)
> Is there a problem with that bucket do you think? Or a problem with rclone?
There is a problem with this bucket, not with rclone.
The curious thing is that rclone gives me the status every minute like:
Armin
Latest rclone1.33
Mac os sierra 64 bit
By the way, I'm hoping that this issue will just fix itself some how. Maybe b2 is just broken, and they can do what ever they need to do.
~/rclone/rclone \
--transfers 3 \
As you can see 1drive should not have appeared as I used b2 which is my shorthand for backblaze b2.
2016/10/17 09:37:05 Failed to create file system for "b2:samusic/3archives": failed to authorize account: failed to authenticate: Get https://api.backblazeb2.com/b2api/v1/b2_authorize_account: x509: certificate signed by unknown authority
> 2016/10/12 03:43:20 Atlanta - S01E07 - B.A.N..mkv: Failed to copy: failed to open source object: bad response: 403: 403 Forbidden
> 2016/10/12 03:43:21 Atlanta - S01E07 - B.A.N..mkv: Failed to copy: failed to open source object: bad response: 403: 403 Forbidden
> 2016/10/12 03:43:21 Atlanta - S01E07 - B.A.N..mkv: Failed to copy: failed to open source object: bad response: 403: 403 Forbidden
> rclone copy /localdir/subdir/subsir/ acd:backup/docs
panic: EME operates on 1 to 128 block-cipher blocks, you passed 137
panic(0x9e95a0, 0xc4201b8950)
github.com/rfjakob/eme.Transform(0xdf3d20, 0xc420063710, 0xc420080c10, 0x10, 0x10, 0xc4200ffb00, 0x890, 0x900, 0x5301, 0xc4200fb600, ...)
github.com/ncw/rclone/crypt.(_cipher).encryptSegment(0xc420080bd0, 0xc42123c260, 0x880, 0xc4200ff200, 0x880)
github.com/ncw/rclone/crypt.(_cipher).EncryptFileName(0xc420080bd0, 0xc421238005, 0x535c, 0xaf0f19, 0x6)
github.com/ncw/rclone/crypt.NewFs(0xc42008ab00, 0x4, 0xc42008ab05, 0x27f, 0x4, 0xc42008ab05, 0x27f, 0x0)
github.com/spf13/cobra.(_Command).Execute(0xe1de00, 0x0, 0x40)
2016/10/12 17:24:41 encryptSegment "3il5vhs9vsrc9g1dvhtrd4mplk" length 26
2016/10/12 17:24:41 encryptSegment "n4o7m5fjh1e31fvs5e8idavo3s" length 26
2016/10/12 17:24:41 encryptSegment "o82eqkgg0d8ann3rfoa1i56iqb31ttctjvckghgmjs0gjaa3ll40" length 52
2016/10/12 17:24:41 encryptSegment "fegd3shph1hrrtq3e81fnl1mq1ev461knqfdcg5jnelrpeoka22g" length 52
2016/10/12 17:24:41 encryptSegment "pdaki9ld8jfckdg5alo8jkd1vc8p2l48ctvlfe574jo1b095faqv5kt2ob1kpbqbbckqccur2v443eucri1l6g72v3urg0tpmarjdk8" length 103
2016/10/12 17:24:41 encryptSegment "33c7ic0mmpeg349j49o406mjdc31fro2faampk178k3g6hvnjkco05ieuu0sg3ggpq3bj8chgpdvgh8a2h79m3uh8em27jalnntsano" length 103
2016/10/12 17:24:41 encryptSegment "d9a328m0h04q26in8380qr3cdc0naeikorcevbjqj7vj0374pg56i9vj3p0tsltev5jegq6q2n468b18q4fvfu0bg6r02q7tv7pv6imd320fhc9kg6lkdjco6l3bj1vf4ulamnomptoqo7ts03bg0l4g1iotdoj0ubokiqgfoed9q1s2opag" length 180
2016/10/12 17:24:41 encryptSegment "fbh9lj5tda371au4fumjnlbojbclq3t6m0v84vuo37rf6jp7flldn0cn94tc1sg2vpt0nd668i3rkle6ma878qt0e8b6hi7pogb8lhv2kpbmmeg2jcgqkf20lbscgf287aqcmahun0ljanlvuv57b8ddmvfo44c72m3d6uarlss72tgr0mig" length 180
2016/10/12 17:24:41 encryptSegment "iilikmh30a49gv451lfe13bhh5u4j5hvgd9io1tto5u6r1esc7vage8s9eggsliq1mjias3o3depjsfp637npmhkvh49dvqjnvec7im1ffhcr3kf9cbeuebcq4rm3q228e979q87rhj31cro93q4p46mvq9809nt47urhins35ij4f5i5muinehs34smgsvlanjoukig8glteiego2vpqal1c73jb7cf0l8gqfie2pqhkdata2htvkgc2uar7ej7q7ap0neg16g5nebsasm3ehic9rgtta9stq21ujb8qjrb9c3fhq9b92vveo8e8mivuobd3pfvadujo4bg400g6l5qsu4quneooajhi8vr68l2ahpsb2hmoplrsu6ihcrkti3maf2v9e379jpi6hbjd9lccumjoqdh4hj16fovlga1pdfm4jd92u6drr5oq6sdki3g9lc7lhg87rp744ueoeikkjmaat3plfddufep6f1fjpr2bd9uga2rqi72fn1u" length 512
2016/10/12 17:24:41 encryptSegment "1kh42516cdtmcc1u2phks5mc2vldjmeld4klu3fh5fmq3hgoaqu04achg415ok5p6sml44s90bnq0vu8bt48d9kl1dps5lalfqqi21alcqf37gj8o9lts33t0fgkgccvu734m5nhgqs7jb4m3pirbinsilel000an07f904784etihp7eedkv2nefq75ssldcqeno8a6hfkrc6itv7dnc94hhb8i0fiujih5kd164p1ah85ka3poirk5o6ggfilekt0pq6rspk7a3nqinpkm0ggcl0u5arqr52v3m3k9adeeekqoqnleg4u0tjnd5536jjjmgtpvootvp56i72432fbk60bjhb8ntt7cqv70qj20fv6ugh2cul0krmtvlmjueo2svj1g0if287bbiv3ur5rqbc0jb8fre3igirsguss601p9732dj37l8lqk9fng3mddr547l4m73v8s8jquv2d5kralv5b4thg7rirhvrqlkijdicrugb6lvhd9q9gg" length 512
panic: EME operates on 1 to 128 block-cipher blocks, you passed 137
@DurvalMenezes I think it's better to wait for MEMSET to respond, and if they can't/won't fix look for options.
Despite completing, the authentication is weird. `rclone config` opens a .com address (and I need an account) and it then goes through redirects towards my .fr account.
@ncw The email isn't the same.
@ncw Ok I was able to make rclone function by using my amazon.com account on the .fr cloud drive. It seems like amazon shares accounts between all its international instances, and there was really no point for the .fr account.
Mac os sierra 64 bit
I totally buy that crypt is slower, no questions about that. It's just that I think/hope it could be a little bit faster then this :-)
I don't think it's actually Crypt I think it's seek:
[EDIT]: Just saw the "crypt code and seeking" - missed the "and seeking" part.
18/09/2012  02:20    <DIR>          dell
Do these do anything different?
ls -alh
ls -alh
I have played around with various umasks to no avail. I also tried a read-only mount and this doesn't make any difference.
Debian 8 64bit
rclone mount Crypt: /home/acd/ --allow-other &
Possibly related issues: #180, #711
> Hubic
> rclone copy -v hubic:GA/afile .
> rclone copy -v hubic:GA/afile .
> 2016/10/05 16:24:19 rclone: Version "v1.33" starting with parameters ["rclone" "copy" "-v" "hubic:GA/afile" "."]
> 2016/10/05 16:24:20 Hubic: Got swift credentials (expiry 2016-10-07 00:52:33 +0200 +0200 in 23h28m12.913624349s)
rclone -v delete hubic:GA/thisisfile
2016/10/05 16:19:21 rclone: Version "v1.33" starting with parameters ["rclone" "-v" "delete" "hubic:GA/thisisfile"]
2016/10/05 16:19:22 Hubic: Got swift credentials (expiry 2016-10-07 00:52:33 +0200 +0200 in 23h33m10.930861748s)
2016/10/05 11:49:34 Encrypted amazon drive root 'rvt9adj21phi9s74vcdshrkq3o': Modify window not supported
2016/10/05 11:49:34 Encrypted amazon drive root 'rvt9adj21phi9s74vcdshrkq3o': Root()
Tested using a t2.large ec2 instance in us-east-1a on Ubuntu 16.04 amd64. Source was a on EFS.
Hi Felix,
> switches.
> https://github.com/notifications/unsubscribe-auth/AANIB3mct6mr1Sdu6dh-gqTu_ZNVLfq0ks5qx9-ggaJpZM4KOJU3.
Although this ticket was opened earlier, is it a duplicate of #888?  Hello,
????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????*/
Durval.
rclone move ~/Main acd:/Main
rclone move remote:images/acbd remote:images
the 'move' option is what you want. It will copy to acd and remove source afterwards. It will leave the source folders however but those can be cleaned up with a simple statement to remove empty folders.
- rclone (discussed here and in #14)
> Proxmox 4.X
2016/09/29 16:45:11 Encrypted amazon drive root '40vr5l7bbib53ql2gesinnck6c/lnhbggu7s6ai3oora37epq5qmk': Waiting for checks to finish
2016/09/29 16:45:11 Encrypted amazon drive root '40vr5l7bbib53ql2gesinnck6c/lnhbggu7s6ai3oora37epq5qmk': Waiting for transfers to finish
└── Ink Master
├── fanart.jpg
└── tvshow.nfo
> https://github.com/notifications/unsubscribe-auth/AAC-KdW4HOjRxx7H-mw47Mmy1nxnooYEks5qvoYEgaJpZM4KKhjy
Errors:                 3
Errors:                 1
-rw-rw-r-- 1 durval durval 5177344 Oct  1 12:49 TESTFILE.split.bc
-rw-rw-r-- 1 durval durval 2146435072 Aug 16 10:17 TESTFILE.split.bc
2146435072 TESTFILE.split.bc
Durval.
Durval.
Thank you @ncw for the follow up!
`rclone copy 1drv_remote:dir acd_remote:dir`
scritto:
www.overload.it
perdere i nostri aggiornamenti e curiosità,
diventa
fan ...conviene!
I'm not sure why I'm getting it to be honest and since no one else has reported it, it must be a special case in my environment with the chain of scripts im using during the backup process.
This is making me crazy!!!
Pacific.
pebkac.  It was a path definition issue.  The binaries were correct all along.  Sorry!
> thought was equally strange.
version specific release.
> Assuming that wasn't you too under a pseudonym, I wonder if there is a
I have tried deleting my entire Music folder and re-uploading it but that seems to double the amount of files that produced errors. It seems as if deleting does not always work fully. (the files are not viewable in the web interface)
conflicting NodeId: QpLQk-OVTualgTomlHaQKQ","info":{"nodeId":"QpLQk-OVTualgTomlHaQKQ"}}
It just happens to be a windows 10 iso ACD is complaining about.
@lanrat I'm going to check for dups as @ncw did.
@lanrat @ncw and what do you know:
Thank you very much for the rclone project and your hard work.
> <hr><center>nginx/1.8.1</center>
> [mastadon@mastadon ~]$
TIA
Is there a way to tune the log message to print information for files / folders that are being copied? in Regular mode, it does not tell you what files are being copied, but you get final statistics.. in Verbose mode, i get too much information that includes analysts and skipping of the files..
I am doing "rclon copy"  - v 1.3.3
--log-level=verbose
All the new files that needs to be created on the target system , fail with the Error " Failed to copy: chtimes /mnt/ntserver/TestDeploy/boma/Functions/storeFunctions.asp: operation not permitted"
Error :
2016/09/20 15:36:31 Functions/storeFunctions.asp: Failed to copy: chtimes /mnt/ntserver/TestDeploy/boma/Functions/storeFunctions.asp: operation not permitted
Also, is there a way to tune the log message to print information for files / folders that are being copied? in Regular mode, it does not tell you what files are being copied, but you get final statistics.. in Verbose mode, i get too much information that includes analysts and skipping of the files..
Remote:
I experienced the exact same issue with east-europe ACD accounts.
@seppi91 How did you manage to create a German cloud drive account? When I tried to sign up using my amazon.de account, it accepted the login, then redirected me to the US login form and I entered the same credentials from my amazon.com account and now my drive seems to live in the US.
@felixbuenemann
@15siegela I did a traceroute to the ec2 servers it is uploading to and they are in the AWS us-east-1 region. I also tried changing the email address on my amazon.de account, but it also changed it for logging into amazon.com, so there only seems to be a single account. It might be because I create the cloud drive a long time ago (I noticed there was a video from a few years ago inside it), so that might be the reason… (it also shows the billing price as $59.99/yr instead of €70/yr)
Zeshan
> "acd:/2Zz6FYsKOAhq,fy2oF0X-HRy/ushfoOGcP-HqQA8k4O1hO35CqlzBxxlYNbtamE,Hk7rXBrI,YljoShxs00YrMltZ5pA/"
> "/home/seppi/rclone.log" "-v"]
Mac os el capitan 64 bit
Backblaze b2
2016/09/14 19:10:37 graphic audio/Eileen Wilks/World of the Lupi/6 Blood Magic/6 Blood Magic.rar: Sending chunk 6 length 100663296
http://davepedu.com/files/rclonelog.txt
How do I change where it looks for .rclone.conf? I have it is my /home/alex directory not in /root.
i guess that is the limitation of amazon?
That was my thinking as well.  I know in encfs you have to ensure that the underlying encrypted algorithm you select is compliant with a case insensitive file system (like on ACD).  I was concerned that the files underlying the crypt file system here could be at risk as I am not as familiar with crypt as I am with encfs.  Thanks for confirming.
└─> touch abc
└─> touch aBc
└─> touch abC
2016/09/13 13:48:46 Encrypted amazon drive root 'cloudm/js4fll2u3v7vhg0livfaqblq6g': Waiting for checks to finish
2016/09/13 13:48:46 Encrypted amazon drive root 'cloudm/js4fll2u3v7vhg0livfaqblq6g': Waiting for transfers to finish
0 2016-09-13 13:48:47.853000000 abC
└─> rclone lsl robacd:/cloudm/js4fll2u3v7vhg0livfaqblq6g
**file: /usr/bin/rclonemount**
**file: /usr/bin/rclonemount**
rclone wants the options at the end.
Best wishes & and thanks for your work on the extraordinary rclone.
hjm
> ACD
rclone -v --config=/home/robert/.rclone.conf mount robacd:/ ./c 2>&1 | tee -a rclone.log
└─> rclone lsd robacd:/
-1 2016-03-07 17:03:20        -1 cloude
> AMD64
> 2016/09/11 00:54:56 Encrypted Local file system at /home/jim/acd: Modify window is 1ns
[eacd]
type = crypt
remote = acd
password = some_code
password2 = some_code
acd=remote
eacd: encrypted remote
The files I see if I do a "rclone ls eacd:" depend on where I was when I issued the rclone copy or rclone move command.
it will create a /home/jim/acd and encrypt the files and upload them.
> QNAP QTS 4.2.2
Cadish
> ACD
Lastly, I know development takes a lot of time and effort. I'd be happy to donate via a [tip4commit](https://tip4commit.com/) or something.  Lots of us owe you a few 🍻 ! @talisto Can you show us how you implement CacheFS this with rclone? @scoopydude2002 Unfortunately CacheFS doesn't seem to be very reliable, I ran into issues that I wasn't able to resolve (crashes, incompatibility with certain filenames/pathnames, etc) so I stopped using it.  I think it's probably best to wait for a better-integrated solution. Would love a caching ability! If file is read, cache file for X amount of days locally or until allocated cache is full (ex. 10gb). Not sure if anyone's put any thought into this but maybe cache'ing itself could work a lot like crypt currently does. A separate share type that wraps around any existing shares.
Andrea
What struck me though is, how will this work with a bittorrent application that never closes it's file handles (?). Then cache wouldn't know when to start upload.
type = crypt
@ncw Might be a valid enhancement on the passwords/hashes to have a 3rd option for a RAW data input.  So people can use the wizard to clone a crypted volume and paste the actual keys rather than having to edit the .rclone.conf.  Just a thought.
Errors:                 4
Errors:                 4
This all is even more confusing since (if I'm not mistaken) when 2nd and 3rd attempt to upload previously transferred files are performed, those ALSO increment "Transferred", and also no matter succeeded or failed.
rclone cat "robacd-crypt:/Videos/Movies/Dumbo/Dumbo.mp4" |  vlc -
I am not smart enough to look at the code. But how is it done in https://github.com/yadayada/acd_cli?
@justusiv I think the point  was that he'd have to make that seeking work across not just acd but all the remotes.  or at least ones that support it (which is the majority).
Any progress on seek using crypt?
Also the encrypted stuff does not support seeking yet.... so unless you watch from the beginning it wont work.
@ncw Very nice! Did this include crypt support? (I can't tell from the commit).
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:857 +0x1d9
panic(0xa2f7a0, 0xc42000e120)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:1249 +0x98c
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:878 +0x4a3
bazil.org/fuse/fs.(_Server).Serve.func1(0xc4212ca0c0, 0xdf7900, 0xc4201ba070)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:425 +0x6e
created by bazil.org/fuse/fs.(_Server).Serve
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:426 +0x3e4
bazil.org/fuse/fs.(_Server).serve.func2(0xdf7900, 0xc4201ba150, 0xc420188ec8, 0xc420188e1f)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:857 +0x1d9
panic(0xa2f7a0, 0xc42000e120)
github.com/ncw/rclone/crypt.(_decrypter).Seek(0xc42022b4a0, 0x70000, 0x0, 0x2d, 0xc4201887c8, 0x2)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:1249 +0x98c
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:878 +0x4a3
bazil.org/fuse/fs.(_Server).Serve.func1(0xc4212ca0c0, 0xdf7900, 0xc4201ba150)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:425 +0x6e
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:426 +0x3e4
bazil.org/fuse/fs.(_Server).serve.func2(0xdf7900, 0xc420148150, 0xc42041deb8, 0xc42041de0f)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:857 +0x1d9
panic(0xa2f7a0, 0xc42000e0d0)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:1249 +0x98c
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:878 +0x4a3
bazil.org/fuse/fs.(_Server).Serve.func1(0xc4202943c0, 0xdf7900, 0xc420148150)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:425 +0x6e
created by bazil.org/fuse/fs.(_Server).Serve
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:426 +0x3e4
bazil.org/fuse/fs.(_Server).serve.func2(0xdf7900, 0xc420148230, 0xc42038fec8, 0xc42038fe1f)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:857 +0x1d9
panic(0xa2f7a0, 0xc42000e0d0)
github.com/ncw/rclone/crypt.(_decrypter).Seek(0xc420271b80, 0x60000, 0x0, 0x2d, 0xc42038f7c8, 0x2)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:1249 +0x98c
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:878 +0x4a3
bazil.org/fuse/fs.(_Server).Serve.func1(0xc4202943c0, 0xdf7900, 0xc420148230)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:425 +0x6e
created by bazil.org/fuse/fs.(_Server).Serve
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:426 +0x3e4
bazil.org/fuse/fs.(_Server).serve.func2(0xdf7900, 0xc420148310, 0xc42038fec8, 0xc42038fe1f)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:857 +0x1d9
panic(0xa2f7a0, 0xc42000e0d0)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:1249 +0x98c
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:878 +0x4a3
bazil.org/fuse/fs.(_Server).Serve.func1(0xc4202943c0, 0xdf7900, 0xc420148310)
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:425 +0x6e
created by bazil.org/fuse/fs.(_Server).Serve
/home/travis/gopath/src/bazil.org/fuse/fs/serve.go:426 +0x3e4
--del                   an alias for --delete-during
Could this be fixed? actually Checksum error<>network error, and it is very misleading.
2016/09/08 12:15:09 Hubic: Got swift credentials (expiry 2016-09-09 07:29:28 +0200 +0200 in 22h14m18.035418118s)
$ fusermount -u /mnt/hubic/
Accept-Encoding: gzip
Cache-Control: private
Strict-Transport-Security: max-age=15768000
2016/09/08 12:43:58 Hubic: Got swift credentials (expiry 2016-09-09 07:29:28 +0200 +0200 in 21h45m29.644758005s)
Accept-Encoding: gzip
Etag: xxx
Etag: xxx
Etag: xxx
rclone mount EACD:/ /path/to/local/
remote = EACD:\CRYPT
changing it to EACD:CRYPT solved the issue.
I should add a note that these are really the first lines of go I've ever written (except a Hello World), so please check that this makes sense.
There's something strange going on with `rclone lsd Dropbox` on my system.
2016/09/07 08:15:54 Failed to copy: failed to open directory "\\?\C:\Users\wanja\Anwendungsdaten": open \?\C:\Users\wanja\Anwendungsdaten: Access is denied. (Anwendungsdaten is the german name for AppData, the folder is showing up as AppData in the explorer though)
Sorry to comment so quickly. I'm getting a file not found error in safari when I try and dl. My wget yields this.
# golang.org/x/crypto/poly1305
too many errors
# golang.org/x/oauth2/jws
Suspected "Redirect URIs" set error.
The -I is there because I was getting errors where it wouldn't transfer because the modification times are the same, which is strange because the directory is empty on B2. This might be an indicator.
> 2016/09/06 09:49:04 Encrypted Local file system at /remote/berbg28gsc22d0pktgipsqshkg/n9nn9n1mk24irmrt29gu5ce7ek: Modify window is 1ns
> 2016/09/06 09:49:30 fonts/conf.avail/58-dejavu-lgc-sans-mono.conf: Copied (replaced existing)
> 2016/09/06 09:49:30 fonts/conf.avail/57-dejavu-sans-mono.conf: Copied (replaced existing)
Interestingly, `rcclone ls secret:flibble/etc2` does show all the files (and returns instantly, like it's not actually connecting to a remote host):
>    18 subuid
![unbenannt](https://cloud.githubusercontent.com/assets/22020778/18263664/1ae5691a-740c-11e6-8370-a85830268ac1.jpg)
Transferred:
2016/09/07 14:12:42 tOIKw4zAGjlaX5OO4HVMGsKv/usHoGsSdcnakN0tygwwMQIjJZlXM9YJTWDgbmQ6XxC7IaM7e6RM0QYo,lrkFkjvCk5A6tXP-UI0xukN4QI,8vpZvUxZwl1W67DZdOpXAgzc-c-/FFSe4tyDNf1btBPNIKqCMHOe: Received error: HTTP code 500: "500 Internal Server Error", reponse body: {"message":"Internal failure"}
; <<>> DiG 9.10.4-P2 <<>> www.googleapis.com @127.0.0.53
; <<>> DiG 9.10.4-P2 <<>> www.googleapis.com @127.0.0.53
2016/09/08 10:31:09 Failed to create file system for "cyayon_nbux_org:":
Christophe Yayon
cyayon@nbux.org
Christophe Yayon
cyayon@nbux.org
no way :
parameters ["/opt/rclone/rclone.beta2" "-v" "copy" "cyayon_nbux_org:"
> http://beta.rclone.org/v1.33-73-geca9e8e/
Christophe Yayon
cyayon@nbux.org
Christophe Yayon
cyayon@nbux.org
Christophe Yayon
> googleapis.l.google.com. 299	IN	A	216.58.219.202
> googleapis.l.google.com. 299	IN	A	216.58.219.234
> googleapis.l.google.com. 299	IN	A	172.217.0.42
> googleapis.l.google.com. 299	IN	A	172.217.1.74
> googleapis.l.google.com. 299	IN	A	172.217.4.42
> googleapis.l.google.com. 299	IN	A	172.217.4.202
Christophe Yayon
bind-interfaces
```ini
This is especially disastrous if user has added encrypted remote and started transferring files to it as keys are lost.
Command causing issue: "rclone -v --transfers 32 --retries 10 copy brive:testvlad /home/kelvin/trive"
Durval.
Durval.
Durval.
@ncw you are most welcome!
2017/01/04 09:48:33 REDACTED/MVI_6190.MOV: ReadFileHandle.Read error: low level retry 2/100: failed to authenticate decrypted block - bad password?
REDACTED/MVI_6190.MOV: FAILED open or read
Durval.
Durval.  When filing an issue, please include the following information if
But even more, after Snowden and in this times we live in it should be a top priority for every dev, especially in FOSS IMHO.
https://godoc.org/golang.org/x/mobile/cmd/gobind
Zeshan
> sauce(short term).
devices.
Zeshan
> sauce(short term).
[b2_encrypted]
type = crypt
password = wwwwww
password2 = yyyyyyyy
Backblaze B2
Is this a dupe of https://github.com/ncw/rclone/issues/18?
Interestingly, for ACD at least, there are slight improvements that could be made to #18 as ACD lets you reference the same file in multiple "directories" - so you could actually have a complete filesystem in each "revision"
I'd suspect that it would be snapshot based
> ./rclone mount amazon:/ ~/rclone-v1.33-linux-amd64/mnt/ --debug-fuse -v
$ cp /opt/rclone ~/acd/
505cfe704e2f7faf5b84104e86f68323  /opt/rclone
$ md5sum ~/acd/rclone
505cfe704e2f7faf5b84104e86f68323  /home/stefan/acd/rclone
$ rm ~/acd/rclone
$ cat /opt/rclone > ~/acd/rclone
$ md5sum ~/acd/rclone
505cfe704e2f7faf5b84104e86f68323  /home/stefan/acd/rclone
+++ b/amazonclouddrive/amazonclouddrive.go
"io"
2016/11/21 06:14:55 Encrypted amazon drive root 'encrypted/xxx': Modify window not supported
2016/11/21 06:14:55 Encrypted amazon drive root 'encrypted/xxx': Mounting on "/mnt/rclone"
Sam
@simos in #660.
Vincèn
Héhé sure, no problem ;) Thanks
rclone dedupe
As discussed this is a docs issue.
> 2016/08/27 09:49:54 Encrypted amazon drive root 'backup/movies/0p5ohk94qrcijn5dqodttaag80': Modify window not supported
ichbinder
https://github.com/yadayada/acd_cli/blob/master/acd_cli.py
> `rclone copy acd_us:/ acd_de:/ --stats=2s --transfers=15`
`2016/08/26 13:39:09 Failed to create file system for "acd_de:/": failed to get endpoints: Get https://drive.amazonaws.com/drive/v1/account/endpoint: oauth2: cannot fetch token: 400 Bad Request
rclone 1.32
I mounted an encrypted cloud drive and when I try to access the files I get a 403 error. I suspected that this was due API limits as the drive was working earlier so I set a client_id and secret as per the guide and got a new token, but I still get 403 errors.
> 2016/08/26 06:41:28 Fashion_DivX720p_ASP.divx: Dir.Lookup
> 2016/08/26 06:41:28 Fashion_DivX720p_ASP.divx: File.Attr
> 2016/08/26 06:41:31 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:31 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:31 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:32 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:32 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:32 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:32 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:33 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:33 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:33 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:33 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:33 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:34 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:34 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:34 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:34 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:34 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:34 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:34 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:34 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:35 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:35 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:35 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:35 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:35 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:35 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:35 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:35 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:36 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:36 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:36 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:36 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:36 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:36 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:36 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:36 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:36 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:37 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:37 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:37 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:37 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:37 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:37 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:37 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:37 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:37 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:38 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:38 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:38 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:38 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:38 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:38 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:38 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:38 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:39 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:39 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:39 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:39 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:39 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:39 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:39 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:39 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:39 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:40 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:40 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:40 Fashion_DivX720p_ASP.divx: File.Open
> 2016/08/26 06:41:40 Fashion_DivX720p_ASP.divx: File.Open
[b2-crypt]
type = crypt
remote>
Unless you understand the crypt implementation of `rclone`, this could sound like you need to specify just the name of the remote (e.g. `remote> acd`). Whereas in fact you are asked to provide a remote _and_ a path (`remote> acd:path`).
remote>
rclone 1.33
e) Edit existing remote
n) New remote
name> acde
3 / Backblaze B2
5 / Encrypt/Decrypt a remote
\ "crypt"
8 / Hubic
\ "hubic"
9 / Local Disk
\ "onedrive"
\ "yandex"
remote> acd
pretty please put encrypted metadata in the file - i'd like to be able to move files around using ACD Web UI without caring about per directory index.
@ncw you're absolutely right about the cost of terminating SSL connections (though I agree there would be a significant net benefit for big files, and for tiny files you could leave the connection open, having a predefined file size threshold to decide).
remote:
This creates encrypted storage which supports arbitrary filename/path lengths, hashes, modification times, deduplication, compression, versioning, file-splitting and it hides directory structure.  The underlying storage system does not have to support any of those.
I apologize for reinventing the wheel from scratch.  I find this project very interesting, and I just want to share some of ideas that have been running though my head.
- 7z also has a concept of splinting the archive to smaller parts (e.g. to fit CDs).
BEEF-0102..4849 (this file contains the actual data)
BEEF-extra-name-1-5051..9899 (this file is always empty and exists only if the filename is too long)
Properties of encrypted backup: no leaking metadata, no leaking content through collision attacks, recovery from 0 with no local context.
path text unique,
perms smallint,
sha1 char(40),
viewed smallint
foreign key(file) references files(id)
Durval.
Odd . .
Cowra  NSW  2794
> https://github.com/notifications/unsubscribe-auth/ABGap7FS6i_VNw3AG-LovjwoY6ClN-F4ks5qj_R0gaJpZM4JrPLO
Cowra  NSW  2794
To make sure I was not being silly, I renamed the old dir and created a
gd_c:/ .
-rw-rw-r-- 1 phil phil 10306 Sep  3 16:17
> https://github.com/notifications/unsubscribe-auth/ABGap4ABQt2DO6K1vGkT6Vyn2TlATYUoks5qrsFugaJpZM4JrPLO
Cowra  NSW  2794
sse:                fs.ConfigFile.MustValue(name, "server_side_encryption"),
+   if *s3ACL != "" {
Zeshan
On Mon, Aug 22, 2016, 7:07 PM Mhardi notifications@github.com wrote:
> But _rclone doesn't seem to recognise ODP_. Which would be in line with
> https://github.com/notifications/unsubscribe-auth/AGXRY8IlDCaeG17YvCoiwGgoz7fAsvhOks5qiiu0gaJpZM4JqZWC
Zeshan
Mathieu.
> Note that ods appears twice in the table because there are two subtly
> different spellings of the mime type for it.
> https://github.com/notifications/unsubscribe-auth/ABrmKjxGu6bE7kJ4GD2-Zv5KqgZmb_YXks5qir6EgaJpZM4JqZWC
2016/08/19 22:01:31 vzdump-qemu-299-2016_08_13-01_18_10: Failed to remove failed copy: HTTP Error: 409: 409 Conflict
2016/08/19 22:01:33 Swift container : Waiting for checks to finish
How i can upload without corruption?
rclone 1.32
split -d -b 50G $f $f.
fi
fi
These are all video (.mp4) and picture (almost solely jp*g, gif and png) files. Some of which I myself converted with Handbrake.
Verbose output:
2016/08/18 09:36:11 06 - Old Lace & Ivory.m4a: Size and MD5 of src and dst objects identical
2016/08/18 09:36:11 06 - Old Lace & Ivory.m4a: Unchanged skipping
2016/08/18 09:36:14 09 - Bible Black.m4a: Unchanged skipping
2016/08/18 09:36:14 06 - Old Lace & Ivory.m4a: Size and MD5 of src and dst objects identical
2016/08/18 09:36:14 06 - Old Lace & Ivory.m4a: Unchanged skipping
2016/08/18 09:36:14 09 - Bible Black.m4a: Unchanged skipping
2016/08/18 09:36:15 06 - Old Lace & Ivory.m4a: Size and MD5 of src and dst objects identical
2016/08/18 09:36:15 06 - Old Lace & Ivory.m4a: Unchanged skipping
1   0       -       W   h   o       Y   o   u       A   r   e
Zeshan
Zeshan
Ah - scrypt has arbitrary key length output - nice.
Hello, `jottalib` maintainer here.
Invalid value for environment variable "RCLONE_VERBOSE": strconv.ParseInt: parsing "true": invalid syntax
Seems to be fixed though if I use 1 (since it's ParseInt) instead of true. i'm write drone ci plugin that uses rclone to sync artifact from builder to storage. does it possible to get list of all env variables that depends on storage ? (without to run rclone config)  Using RClone v1.32 on Windows 10 x64, I received the following issue:-
Name = "ABC.txt"
ACD
I suspect it has to do the weird characters in the file names. This appears to be having issues calling the files locally and never actually attempts to push them to Dropbox. Any way to either skip these files or allow rclone to handle file names with special characters?
> Amzon Drive
> macos El Capitan
Content-Type: application/foo
X-Amz-Request-Id: 5B532AEEACE3E235
Accept-Encoding: gzip
My use case is very specific, and probably won't interest too many people.
> HubiC
- Only seems to happen on file located at path that include an accented character also I'm not 100% positive about that
I'm not sure if this comes from here or from hubic, I haven't had any news on their side. I will update if I do. In the meantime I'd be happy to provide supplementary information as needed.
I have two folders with accented characters in their name, both are empty but still there.
That NCW is such a busybee, I tell ya, always buzzing away at something or other.  :)
For the past ten days to two weeks, many of my uploads to Amazon hit 99% and then restart at 0%. When I run the command with the verbose command, I regularly see one of the following error messages (in order of frequency):
`error Post https://content-na.drive.amazonaws.com/cdproxy/nodes?suppress=deduplication: write tcp 192.168.2.99:52277->xx.xxx.xxx.xxx:443: wsasend: An existing connection was forcibly closed by the remote host`
(these low level retries sometimes get up to four or five before finally succeeding)
@trajpar
I tried a buch of combinations of Tenant_ID, Tenant_Name, my username & password, but it appears that either OVH is expecting a passwort field but rclone claims to have an API key, or some naming is a bit confusing to me.
Accept-Encoding: gzip
{"auth":{"RAX-KSKEY:apiKeyCredentials":{"username":"123abc567xy","apiKey":"ppppppppppppppp"},"tenantName":"1234567890123456"}}
export OS_USERNAME="123abc567xy"
export OS_REGION_NAME="SBG1"
Little update: OVH regions are more complicated than I first thought.
> Backblaze B2
> > > WTF
> > > WTF
> `rclone copy smccd:The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv .`
> $ rclone -v copy smccd:The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv .
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 8388608 Jul 25 10:50 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 8388608 Jul 25 10:50 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 8388608 Jul 25 10:50 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 8388608 Jul 25 10:50 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 8388608 Jul 25 10:50 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 8388608 Jul 25 10:50 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 8388608 Jul 25 10:50 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 8388608 Jul 25 10:50 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 2097152 Jul 25 10:49 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 2097152 Jul 25 10:49 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 2097152 Jul 25 10:49 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 2097152 Jul 25 10:49 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 2097152 Jul 25 10:49 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 2097152 Jul 25 10:49 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 2097152 Jul 25 10:49 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 2097152 Jul 25 10:49 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 2097152 Jul 25 10:49 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
soff@imac5k ~/tmp $ ls -la The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
-rw-r--r-- 1 soff staff 2097152 Jul 25 10:49 The.Victorias.Secret.Fashion.Show.2015.1080p.HDTV.x264-BATV.mkv
Error message shown on sierra beta 4:
unexpected fault address 0x588158a75803
runtime.sigpanic()
/usr/local/go/src/runtime/sema.go:47 +0x26
goroutine 51 [chan receive]:
WOW
Btrfs
I want to introduce rclone into the mix by having rclone copy the snapshots to acd.
Debian testing, 64
Backblaze B2
Errors:                 6
panic(0x868a20, 0xc42034fb90)
Hey. githabe have on several projects with api
ACD/photos/
ACD/new_photos/
> backblaze b2
error:
looks like "chunk strategy" doesn't work - B2 error, rclone error...who knows?
files with complex characters and spaces between files, results in errors like these:
OSX El Cap.
> Locale:
LANG=
DreamObjects
I am half expecting it was a Backblaze problem: after all this is a new account and I have just added a credit card; maybe it limits how much space you can take up until it processes a payment or something?  But, in any case, I presume the intention is that rclone would report an error, not crash.
Debian testing, 64
Backblaze B2
I can report that the copies have now finished (after a few attempts) with the special version you supplied without reproducing the same error (there was a different error which looks unrelated so I will report separately).
Backblaze B2
> backblaze B2
is:open label:question
*\* hmmm, my nas is running on a ssd, and i use the noatime option to mount my filesystem. maybe this is the problem i am facing???
using the verbose mode i see a lot of
**ncw edit**
Would be great to have WebDAV support. I have Synology NAS and it exports all files system as WebDAV (among other ways). I am sure many other system offers WebDAV access.
2017/01/08 00:24:19 d/TY/BQQX2EUOLXQPB6YGWU4WCBRIEIEO5I/NU2VKDWICTF4CWGHRE6WXMFUJARHA2GKIDK3HP3RYNNSGV2NL4JTVW6P4GO64===: ##### DEBUG#### srcHash= 5b76d5aa3bf065e123e0c1b46c9245de1c2b39e3 ---- destHash= 680294244c3bc820160fd8b065e37e5a453e03e6
"fileName": "d/TY/BQQX2EUOLXQPB6YGWU4WCBRIEIEO5I/NU2VKDWICTF4CWGHRE6WXMFUJARHA2GKIDK3HP3RYNNSGV2NL4JTVW6P4GO64===",
"fileName": "d/TH/T4FL3DASV6EF34GD2W4HBLIXDMNFH6/JNMWI5UEMCMRPGRE5E6MKADCOPL7RJ5DYTEUUSDYSEWCG===",
(Note : my data is locally encrypted by cryptomator, hence the weird obfuscated filenames)
This is a spectacularly bad experience for me.
> rclone move -v --include '_Monde_' nous:Photos/2016 nous:Photos/2016/2016-01
2016/07/09 21:06:39 TapisMondeOxybul.jpg: Moved
2016/07/09 21:07:19 2016-01/TapisMondeOxybul.jpg: Deleted
I'm noticing "2016-01/TapisMondeOxybul.jpg: Deleted": Are we deleting the destination file !?
2016/07/09 21:15:48 TableSableEauOxybul.jpg: Not moving as --dry-run
2016/07/09 21:16:10 TableSableEauOxybul.jpg: Not deleting as --dry-run
Notice how this time, "TableSableEauOxybul.jpg: Not deleting as --dry-run" the deleted file does not see, to be the destiation file
2016/07/09 21:06:39 TapisMondeOxybul.jpg: Moved
2016/07/09 21:07:19 2016-01/TapisMondeOxybul.jpg: Deleted
rclone • 10:18 PM
2016/07/08 20:42:16 Amazon cloud drive root 'ZooeyOne': Modify window not supported
'/usr/sbin/rclone sync --exclude /home/isaiahsellassie/Music/JAZZ/lost+found/*\* /home/isaiahsellassie/Music Adrive:Music'
Hi @uddipan,
## amazon.TLD
runtime.sigpanic()
Looks like there is an issue with our custom made Wheezy setup. I upgraded to Jessie and was able to do the sync. Or so it seems.
Errors:              1576
Also:
Matija
There were some issues with files taht had "?" in name something like foo_?bar.jpg etc
swift
3 / Backblaze B2
7 / Hubic
\ "hubic"
8 / Local Disk
\ "onedrive"
\ "yandex"
6 / OVH
region> sss
Remote config
region = sss
Dominic
@balazer , Could you please add some details how you got client_id and client_secret ? I have tried to create one following these guidelines, but I am lost ! https://developers.google.com/identity/sign-in/web/devconsole-project
- [ ]  Drive API
- Other UI
Client secret**
edit2 : in my case " (the default name is fine)" I choosed one like "Rcloneme" so it will be much easier later to avoid removing accidentally the correct one from Google Account/ Apps connected.
by the way, i again have to say, that i appreciate the work you do. i am getting a real fan of rclone. it's a great tool._
Zeshan
> https://github.com/notifications/unsubscribe-auth/AGXRY-V0Vj1kj2Fsm4IApu9jE47WH2rlks5qY1KhgaJpZM4JEz6k
`Received error: Put https://content-na.drive.amazonaws.com/cdproxy/nodes/0x4Po_W4Q42SeObg0iH6XQ/content: net/http: timeout awaiting response headers - low level retry 4/10`
UPDATE: rclone 1.30
2016/08/06 23:51:47 pacer: low level retry 1/1 (error Post https://content-na.drive.amazonaws.com/cdproxy/nodes?suppress=deduplication: write tcp 192.168.1.14:58880->52.72.69.9:443: wsasend: An existing connection was forcibly closed by the remote host.)
Oh, great ncw! I'm gonna update and test it ASAP.
Durval.
> ACDE: crypt
Durval.
Hi ncw, this is the flow when I download the file, I think the magic query parameter is AVOverride=1
- canary:ublwZ/2y043MfQibrrX+RlfVzLDRIHNx6JElwS8puSQ=7
- ithint:.bz2
- Url: https://uagowq-ch3301.files.1drv.com/.../DBGT-html.tar.bz2
- avres:ScanError
- averror:DAMAGED_STREAM
- Response Code: 403 (Forbidden)
- avres:ScanError
- averror:DAMAGED_STREAM
- Url: https://uagowq-ch3301.files.1drv.com/.../DBGT-html.tar.bz2
> Backblaze
(### are substituted filenames and not the real file names)
/b2
go lang is way out of scope for me, sorry.
> Backblaze
> https://github.com/notifications/unsubscribe/AGXRY_uHMs9Lbah8U_xpO6mcnrcUIvsMks5qRlQ_gaJpZM4JDqYt
`./rclone copy acd:/ISO backblaze:FastnetBackup/ISO --transfers=8 --stats=3s`
Errors:                 1
(also have seen Error 503)
Previously, errors were raised on random files.
rclone --bwlimit 10M copy /media/iomega/Pictures/2011 amazon:Pictures/2011
You appear to be starting an rclone every minute of the 23rd hour.
- 23 \* \* \* rclone....
0 23 \* \* \* rclone....
> rasperry pi debian jessie lite
It is only necessary to use a unique prefix of the subcommand, eg 'mo'
sudo rclone copy /etc/pihole/whitelist.txt gdrive:/pi/
sudo rclone copy /etc/pihole/blacklist.txt gdrive:/pi/
ethers
hosts
pihole/whitelist.txt
pihole/blacklist.txt
\pi\ethers
\pi\pihole\blacklist.txt
\pi\pihole\whitelist.txt
Could this work also for ACD?
verbose log:
le remotes
I really appreciate your work on rclone.  It's proven itself to be very powerful and robust.
I know I'm  probably quite the fringe case but I'm thinking about working around this issue by creating sequential remote sub folders maybe every 10,000 files or so or whatever the threshold should be.  But if this is something that can be fixed in rclone (maybe even a blind upload switch or overwrite if exists switch?) that would be even better.
> Backblaze B2
habskilla@cublinux-basement:~/scripts$ rclone copy -q --dry-run /mnt/archive/Backups/Fileserver-Backups acd:/Backups/Fileserver-Backups
| github.com/jlaffaye/ftp | Package ftp implements a FTP client as described in RFC 959. |
| gopkg.in/jlaffaye/ftp.v0 | Package ftp implements a FTP client as described in RFC 959. |
> https://github.com/notifications/unsubscribe-auth/AGXRY-HOlxz_m4iwVwrSgL9Z-CB8Voo4ks5qY1TcgaJpZM4I6XJj
BUT...
I suspect I'm doing something stupid and the answer will embarrass me to no end, but I'm fresh out of ideas!
status code: 400, request id: 6FDF181A1ABAC07A
Errors:                 1
rclone sync /c/pictures b2:mejje-pictures -v --dump-headers
mejjeNAS:~# sha1sum /c/pictures/2009-07-27/IMG_9129.JPG
mejjeNAS:~# rclone sha1sum /c/pictures/2009-07-27/IMG_9129.JPG
Not sure if it's the standard behavior but it feels wrong to me.
Ok, thanks for the answer ncw.
> mac el capitan
> acd
Inside my sh this is my if:
else
fi
Emre
> S3 (Ceph Hammer)
X-Amz-Request-Id: tx000000000000001bbb918-0057609cb7-d8d7311-default
X-Rgw-Bytes-Used: 44040192
X-Rgw-Object-Count: 3
Accept-Encoding: gzip
X-Amz-Request-Id: tx000000000000001bbb91b-0057609cb7-d8d7311-default
The closest I've seen to a standard name in S3 tools was `x-amz-meta-$HASHNAME`. I did want to mention that
http://www.skylable.com/products/libres3/
https://github.com/basho/riak_cs
http://s3ninja.net/
host = remote_server_foo.bar.com
user = kenz
Value "host" = "remote_server_foo.bar.com"
Having trouble with my first set up of rclone.  I got as far as running config, logging into my amazon account within rclone, "Y" for auto config, browser opens up to the http://127.0.0.1:53682/auth website only to return this error message:
**_Remote config
- Say N if you are working on a remote or headless machine
Daniel
Durval. I can probably test it on drive if you want.
Durval.
Durval.
Humrmrmrmr... something unexpected is happening here: the "rclone --dry-run sync" I started yesterday is still running, but the counters are now *way* over the number of files that should exist both in the remote and in the local file system:
@ncw, can you please shine a light on this?
Durval.
Durval.
2) The "tofu" (?) character `�` was also shown twice, in exact the same position.
Durval.
Durval. Hello @ncw,
Durval.
Whats wrong there?
Hyper
Roberto
Version : rclone v1.29-48-ge2788aa?
2016/06/08 13:13:07 Hubic: Got swift credentials (expiry 2016-06-09 05:28:23 +02
2016/06/08 13:13:29 Hubic: Got swift credentials (expiry 2016-06-09 05:28:23 +02
2016/06/08 13:13:31 Hubic Swift container Disque2 limited to 1 objects: Done bui
ile list
les as there were IO errors
2016/06/08 13:14:10 Hubic Swift container Disque2 limited to 1 objects: Done bui
ile list
les as there were IO errors
2016/06/08 13:14:33 Hubic Swift container Disque2 limited to 1 objects: Done bui
ile list
les as there were IO errors
Errors:                 1
SLO style manifests are more powerful/flexible than DLO. SLO has several advantages over DLO, one of the main ones is that content-length is correct in container listings.  SLO also has some interesting de-dupe possibilities, as the same object can be referenced in multiple manifests.
> Swift
`2016/06/05 12:38:10 Unknown command "two_potato"`
`rclone -n --exclude '{one,two}_potato' sync ~/test s3:test`
> mac capitan
> ACD
Do you know any awk or similar to check this?
Hi, I was just wondering if anyone knew why rclone is much slower for local destinations than Robocopy?
$ touch AAA
$ touch BBB
0 AAA
rclone responded by saying couldn't find root
> Unraid 6.1.9 - 64bit
How do you specify a flag, such as the "i" flag for case-insensitivity?
ncw's suggestion of `--filters-case-insensitive` flag makes more sense.
rclone lsd remote:
> Mac El Capitan
At the moment the backup is reading well from acd.
Thank you very much! Champion!
i like rclone.
I provide a list of 10 files, but with the verbose option I see that rclone is scanning thousands of files, is it the normal behavior?
greg
target is hubic
### Decrypt
### Encrypt
### Decrypt
@sebitnt that's my workaround feel free to use what you need :)
If you need to encrypt the data you need an additional tool and I think rclone already crossed the line with crypt.
I'm a complete idiot. Sorry to waste everyone's time. A rogue script had filled it up and I naively assumed it was rclone - which, can I say, is utterly awesome.
check out [acd_cli](https://github.com/yadayada/acd_cli) if you haven't yet.  it may offer exactly what you're looking for.
@zjpleau rclone is having the same authentication issues unfortunately
Makes sense, maybe something like [the Dokan Windows FUSE module](https://github.com/dokan-dev/dokany/wiki/FUSE) could be implemented in the future. This is what [ACDDokanNet](https://github.com/Rambalac/ACDDokanNet) uses. This and encryption are a very exciting step forward. Thank you for all of your work!
2016/05/20 16:13:05 Failed to create file system for "default:": Failed to get endpoints: HTTP code 403: "403 Forbidden", reponse body: {"message":"'Atza|IQEBLjAsAhRYY2q7ynpDiN4c1HLKiTJDb03N_wIURbs2AsesLTwxF0J67byNaJHnPRpvjIQzvGHiqxd7XnxXvxegyWAo9sJzU2-RntBwV7ShhZPGg8JGXUS4gMayRKccnDUk6AA4M-OMcSBRmbPQSoSdqTV1PJuDMsqfbBQC2xhMIh1SoZLtBCYEQroIUAFTsC0pXBxgdfwWg8oyXeDQEo4Cvys1TpYsMp_6yaNzt8WEWcFGkzwoexDOkFYbU6TgUk6KrQTQO753F5LmbNbg1dIqdJT0-h4u5-IlotLrFYT7wcjTit10A4WRywne6fzQUeUBgMafCKmn9u561tLPnNrkvFvtJI-pHth-L95k5xnLyGGvq75_OSAshEiLzax0aerqovMdnk3GsE_GVpKAqibGNEixTSRuD2p_ZuaVzcQfn0AGaoQLEX62IY25JcnmrUT-yrkZ28_EQTs_ZiACLjvu6bcvz7AI3nG3H9MEeTVsH_jizGximaS8O4GJ_KHDz5ZdstAfNvDxvriPhywrWWPjX3ZSfAqiNS2evRQyq0TE8COeqg5ECNizt1U88SgPVh9qxkExMFCnxzI62HCwpsWeZlTPHixQRnRJnpTa9Fks1B8' not a valid key=value pair (missing equal-sign) in Authorization header: 'bearer Atza|IQEBLjAsAhRYY2q7ynpDiN4c1HLKiTJDb03N_wIURbs2AsesLTwxF0J67byNaJHnPRpvjIQzvGHiqxd7XnxXvxegyWAo9sJzU2-RntBwV7ShhZPGg8JGXUS4gMayRKccnDUk6AA4M-OMcSBRmbPQSoSdqTV1PJuDMsqfbBQC2xhMIh1SoZLtBCYEQroIUAFTsC0pXBxgdfwWg8oyXeDQEo4Cvys1TpYsMp_6yaNzt8WEWcFGkzwoexDOkFYbU6TgUk6KrQTQO753F5LmbNbg1dIqdJT0-h4u5-IlotLrFYT7wcjTit10A4WRywne6fzQUeUBgMafCKmn9u561tLPnNrkvFvtJI-pHth-L95k5xnLyGGvq75_OSAshEiLzax0aerqovMdnk3GsE_GVpKAqibGNEixTSRuD2p_ZuaVzcQfn0AGaoQLEX62IY25JcnmrUT-yrkZ28_EQTs_ZiACLjvu6bcvz7AI3nG3H9MEeTVsH_jizGximaS8O4GJ_KHDz5ZdstAfNvDxvriPhywrWWPjX3ZSfAqiNS2evRQyq0TE8COeqg5ECNizt1U88SgPVh9qxkExMFCnxzI62HCwpsWeZlTPHixQRnRJnpTa9Fks1B8'."}
I'm register this account, it goes to the local web page and it gets the token, but it never works.  the only thing I can think of is that the token produced is expired already?  "expiry":"2016-05-20T17:11:02.254901677-07:00" (is what was at the end of the token
$ ~/rclone lsd acd:
2016/05/23 10:43:59 Failed to create file system for "acd:": Failed to get endpoints: HTTP code 403: "403 Forbidden", reponse body: {"message":"'Atza|IQEBLjAsAhQmOfJfZSJDH67xic3ieKwuKFrBbwIUSZzVEnIT7vicdqbMErD5ZVDsZfLKkQFLzVKsR2B7kvMFff1UfgMt9vRI0rvGMboaCyZZcKSN9NYr8hPGfxDVR1i3PUtwhdCR-ACxtpyC3VtvBPbq4MF3asSJzMUa501pdMORzZtjK_Xy7pShOFyeCuwn_KQ3Y2rbSJy-9w-G5f1gxFaintHGMMDZY_T2VOW-_7Pg_mdfRLzNVj3hfTfYT-ilHY8OD6a0xt7gidT8z9pOABTEe3H4Ht_YztMZXdcdtZlGHgY_X66-i7Tt5e17XfZ1mQH2jOBQ1u6yKgDi_tabjDjE-Xf38VqdBWQoiFqHjloDmt6mguxWu8P5VDywWF2VEOU_fk7YfEP5P2cwDwiz0vRJbgwYAgweObBx6gbd6f_gs_NXw2AivMPBlnnxDI31AJutKCluAzuGLdqF4H-H4PUQqsFvSrO4J2C2h1-j2y_rqsWKB_rOKNtg-FRGtDPeV1259o5wiUmCBbRL5lZDzJkn58Q3wGRTVp2AXIssekApIh_7wP4XChNhC7bgIcNx7T5gkpeNZ7wHgyM5z0_k41LC2GjZyxil8joP1pn2wvvoW-w5RRBxma1XBXqg5HffNDFd' not a valid key=value pair (missing equal-sign) in Authorization header: 'bearer Atza|IQEBLjAsAhQmOfJfZSJDH67xic3ieKwuKFrBbwIUSZzVEnIT7vicdqbMErD5ZVDsZfLKkQFLzVKsR2B7kvMFff1UfgMt9vRI0rvGMboaCyZZcKSN9NYr8hPGfxDVR1i3PUtwhdCR-ACxtpyC3VtvBPbq4MF3asSJzMUa501pdMORzZtjK_Xy7pShOFyeCuwn_KQ3Y2rbSJy-9w-G5f1gxFaintHGMMDZY_T2VOW-_7Pg_mdfRLzNVj3hfTfYT-ilHY8OD6a0xt7gidT8z9pOABTEe3H4Ht_YztMZXdcdtZlGHgY_X66-i7Tt5e17XfZ1mQH2jOBQ1u6yKgDi_tabjDjE-Xf38VqdBWQoiFqHjloDmt6mguxWu8P5VDywWF2VEOU_fk7YfEP5P2cwDwiz0vRJbgwYAgweObBx6gbd6f_gs_NXw2AivMPBlnnxDI31AJutKCluAzuGLdqF4H-H4PUQqsFvSrO4J2C2h1-j2y_rqsWKB_rOKNtg-FRGtDPeV1259o5wiUmCBbRL5lZDzJkn58Q3wGRTVp2AXIssekApIh_7wP4XChNhC7bgIcNx7T5gkpeNZ7wHgyM5z0_k41LC2GjZyxil8joP1pn2wvvoW-w5RRBxma1XBXqg5HffNDFd'."}
Received error: Post https://content-na.drive.amazonaws.com/cdproxy/nodes?suppress=deduplication: Post https://api.amazon.com/auth/o2/token: dial tcp: lookup api.amazon.com on 192.168.0.1:53: read udp 192.168.0.41:58874->192.168.0.1:53: i/o timeout - low level retry 4/10
2016/05/25 05:20:00 Amazon cloud drive root 'z0/Asimov': Reading "documentation/games/phantasie/"
2016/05/25 05:20:01 Amazon cloud drive root 'z0/Asimov': Reading "documentation/advertisements/sierra/"
2016/05/25 05:20:01 Amazon cloud drive root 'z0/Asimov': Finished reading "documentation/games/phantasie/"
2016/05/25 05:20:02 Amazon cloud drive root 'z0/Asimov': Reading "documentation/games/bards_tale_iii/"
2016/05/25 05:20:04 Amazon cloud drive root 'z0/Asimov': Reading "images/pd_collections/gsclub/"
2016/05/25 05:20:04 Amazon cloud drive root 'z0/Asimov': Finished reading "images/pd_collections/gsclub/"
2016/05/25 05:20:07 Amazon cloud drive root 'z0/Asimov': Reading "images/pd_collections/tawug/"
2016/05/25 05:20:07 Amazon cloud drive root 'z0/Asimov': Reading "documentation/magazines/basug/"
2016/05/25 05:20:08 Amazon cloud drive root 'z0/Asimov': Reading "images/masters/other_os/"
2016/05/25 05:20:10 Amazon cloud drive root 'z0/Asimov': Reading "images/masters/model_specific/"
2016/05/25 05:20:13 Amazon cloud drive root 'z0/Asimov': Reading "documentation/games/halls_of_montezuma/"
2016/05/25 05:20:13 Amazon cloud drive root 'z0/Asimov': Reading "images/masters/other_os/ix-like/"
2016/05/25 05:20:13 Amazon cloud drive root 'z0/Asimov': Finished reading "images/masters/other_os/ix-like/"
2016/05/25 05:20:14 Amazon cloud drive root 'z0/Asimov': Finished reading "images/gs/magazines/iigs_ag/"
2016/05/25 05:20:15 Amazon cloud drive root 'z0/Asimov': Reading "images/masters/other_os/system_ii/"
2016/05/25 05:20:16 Amazon cloud drive root 'z0/Asimov': Finished reading "images/masters/other_os/system_ii/"
2016/05/25 05:20:18 Amazon cloud drive root 'z0/Asimov': Reading "images/masters/other_os/gui/"
2016/05/25 05:20:19 Amazon cloud drive root 'z0/Asimov': Finished reading "images/masters/other_os/gui/"
2016/05/25 05:20:20 Amazon cloud drive root 'z0/Asimov': Reading "images/pd_collections/aces/"
2016/05/25 05:20:20 Amazon cloud drive root 'z0/Asimov': Reading "documentation/games/bards_tale_i/"
2016/05/25 05:20:20 Amazon cloud drive root 'z0/Asimov': Finished reading "images/pd_collections/aces/"
2016/05/25 05:20:20 Amazon cloud drive root 'z0/Asimov': Reading "images/masters/other_os/contiki/"
2016/05/25 05:20:21 Amazon cloud drive root 'z0/Asimov': Reading "images/games/rpg/phantasie_II/"
2016/05/25 05:20:21 Amazon cloud drive root 'z0/Asimov': Finished reading "images/masters/other_os/contiki/"
2016/05/25 05:20:21 Amazon cloud drive root 'z0/Asimov': Reading "images/games/adventure/alice_in_wonderland/"
2016/05/25 05:20:21 Amazon cloud drive root 'z0/Asimov': Finished reading "images/games/rpg/phantasie_II/"
2016/05/25 05:20:22 Amazon cloud drive root 'z0/Asimov': Finished reading "images/games/adventure/alice_in_wonderland/"
2016/05/25 05:20:22 Amazon cloud drive root 'z0/Asimov': Reading "images/masters/other_os/gui/geos/"
2016/05/25 05:20:22 Amazon cloud drive root 'z0/Asimov': Finished reading "images/masters/other_os/gui/geos/"
2016/05/25 05:20:22 Amazon cloud drive root 'z0/Asimov': Reading "images/gs/productivity/word_processing/brejouxworks_FR/"
2016/05/25 05:20:22 Amazon cloud drive root 'z0/Asimov': Reading "images/masters/other_os/nakedos/"
2016/05/25 05:20:23 Amazon cloud drive root 'z0/Asimov': Finished reading "images/gs/productivity/word_processing/brejouxworks_FR/"
2016/05/25 05:20:23 Amazon cloud drive root 'z0/Asimov': Finished reading "images/masters/other_os/nakedos/"
2016/05/25 05:20:26 Amazon cloud drive root 'z0/Asimov': Reading "documentation/games/bards_tale_ii/"
2016/05/25 05:20:29 Amazon cloud drive root 'z0/Asimov': Reading "images/games/rpg/phantasie_I/"
2016/05/25 05:20:30 Amazon cloud drive root 'z0/Asimov': Finished reading "images/games/rpg/phantasie_I/"
2016/05/25 05:20:32 Amazon cloud drive root 'z0/Asimov': Reading "images/gs/sound/diversitune/"
2016/05/25 05:20:33 Amazon cloud drive root 'z0/Asimov': Finished reading "images/gs/sound/diversitune/"
2016/05/25 05:20:33 Amazon cloud drive root 'z0/Asimov': Reading "images/games/action/jungle_hunt/"
2016/05/25 05:20:33 Amazon cloud drive root 'z0/Asimov': Reading "images/educational/operation_frog/"
2016/05/25 05:20:35 Amazon cloud drive root 'z0/Asimov': Reading "images/educational/where_in_europe_is_carmen_sandiego/"
2016/05/25 05:20:36 Amazon cloud drive root 'z0/Asimov': Reading "documentation/games/tass_times_in_tonetown/"
2016/05/25 05:20:37 Amazon cloud drive root 'z0/Asimov': Finished reading "documentation/games/tass_times_in_tonetown/"
2016/05/25 05:20:38 Amazon cloud drive root 'z0/Asimov': Reading "images/games/rpg/dark_heart_of_uukrul/"
2016/05/25 05:20:38 Amazon cloud drive root 'z0/Asimov': Finished reading "images/games/rpg/dark_heart_of_uukrul/"
2016/05/25 05:20:41 Amazon cloud drive root 'z0/Asimov': Reading "images/programming/c/manx/"
2016/05/25 05:20:41 Amazon cloud drive root 'z0/Asimov': Reading "images/programming/forth/mad_apple_forth/"
2016/05/25 05:20:42 Amazon cloud drive root 'z0/Asimov': Reading "images/games/adventure/oo_topos/"
2016/05/25 05:20:42 Amazon cloud drive root 'z0/Asimov': Finished reading "images/programming/forth/mad_apple_forth/"
2016/05/25 05:20:42 Amazon cloud drive root 'z0/Asimov': Reading "images/programming/logo/terrapin/"
2016/05/25 05:20:43 Amazon cloud drive root 'z0/Asimov': Finished reading "images/programming/logo/terrapin/"
2016/05/25 05:20:43 Amazon cloud drive root 'z0/Asimov': Reading "images/educational/where_in_the_world_is_carmen_sandiego/"
2016/05/25 05:20:46 Amazon cloud drive root 'z0/Asimov': Reading "images/games/adventure/death_in_the_caribbean/"
2016/05/25 05:20:46 Amazon cloud drive root 'z0/Asimov': Reading "images/games/rpg/alternate_reality_the_dungeon/"
2016/05/25 05:20:47 Amazon cloud drive root 'z0/Asimov': Finished reading "images/games/adventure/death_in_the_caribbean/"
2016/05/25 05:20:48 Amazon cloud drive root 'z0/Asimov': Reading "images/games/rpg/black_cauldron/"
2016/05/25 05:20:48 Amazon cloud drive root 'z0/Asimov': Reading "images/games/rpg/akalabeth/"
2016/05/25 05:20:49 Amazon cloud drive root 'z0/Asimov': Finished reading "images/games/rpg/black_cauldron/"
2016/05/25 05:20:49 Amazon cloud drive root 'z0/Asimov': Reading "images/games/adventure/ankh/"
2016/05/25 05:20:49 Amazon cloud drive root 'z0/Asimov': Finished reading "images/games/rpg/akalabeth/"
2016/05/25 05:20:49 Amazon cloud drive root 'z0/Asimov': Reading "images/games/rpg/phantasie_III/"
2016/05/25 05:20:50 Amazon cloud drive root 'z0/Asimov': Finished reading "images/games/rpg/phantasie_III/"
2016/05/25 05:20:50 Amazon cloud drive root 'z0/Asimov': Reading "images/games/adventure/sword_of_kadash/"
2016/05/25 05:20:51 Amazon cloud drive root 'z0/Asimov': Reading "images/games/action/prince_of_persia/"
2016/05/25 05:20:51 Amazon cloud drive root 'z0/Asimov': Reading "images/games/adventure/abyssal_zone/"
2016/05/25 05:20:51 Amazon cloud drive root 'z0/Asimov': Finished reading "images/games/adventure/abyssal_zone/"
2016/05/25 05:20:51 Amazon cloud drive root 'z0/Asimov': Reading "images/games/action/indiana_jones/"
2016/05/25 05:20:51 Amazon cloud drive root 'z0/Asimov': Reading "images/games/adventure/tass_times_in_tonetown/"
2016/05/25 05:20:51 Amazon cloud drive root 'z0/Asimov': Reading "images/games/adventure/kabul_spy/"
2016/05/25 05:20:52 Amazon cloud drive root 'z0/Asimov': Finished reading "images/games/adventure/tass_times_in_tonetown/"
2016/05/25 05:20:52 Amazon cloud drive root 'z0/Asimov': Reading "images/games/adventure/wizard_of_oz/"
2016/05/25 05:20:53 Amazon cloud drive root 'z0/Asimov': Reading "images/games/adventure/buckaroo_banzai/"
2016/05/25 05:20:53 Amazon cloud drive root 'z0/Asimov': Reading "images/games/adventure/warriors_of_ras/"
2016/05/25 05:20:53 Amazon cloud drive root 'z0/Asimov': Finished reading "images/games/adventure/buckaroo_banzai/"
2016/05/25 05:20:53 Amazon cloud drive root 'z0/Asimov': Finished reading "images/games/adventure/warriors_of_ras/"
Could I suggest a change of wording perhaps?  The fact that it says 4 files were transferred, I feel, is slightly confusing.
imo, there's no need to list successful transfers and attempted transfers really. It starts off with transfers and errors, then it makes another loop and tries to convert the errors to transfers. if you're ever curious you can just parse the verbose logfile or something.
It just seems a bit odd that to get the correct stats on files transferred you need to check the logfile.
1531444 IMAG0956.jpg
$ rclone -v ls gdrv:boards/sayas/IMAG0944.jpg
2088686 IMAG0944.jpg
$ rclone -v ls gdrv:boards/sayas/\*.jpg
$ rclone -v ls gdrv:boards/sayas/IMG_\*
$ rclone -v ls 'gdrv:boards/sayas/IMG_\*'
$ rclone -v ls gdrv:'IMG_*'
I'm clearly missing something here...what is it?  Quoting, special escaping? The phrase "Couldn't find root:" is a hint, but google returns precious little in that regard.
On May 17, 2016 4:04 PM, "Harry Mangalam" notifications@github.com wrote:
> $ rclone -v ls gdrv:boards/sayas/IMAG0944.jpg
> $ rclone -v ls gdrv:boards/sayas/IMG_*
> $ rclone -v ls 'gdrv:boards/sayas/IMG_*'
> I'm clearly missing something here...what is it? Quoting, special
token = {"access_token":"..secret..","token_type":"
[google-dra]
bucket_acl = authenticatedRead
> [google-dra]
Cloud Storage: ACD
Errors:                 232
object_acl =
bucket_acl =
I am unable to judge if it is a problem in clone or a problem with ACD.
2016/05/27 02:53:22 Amazon cloud drive root 't0': Directory listing error for "t0/rescue/win7/21Gig_Boot/Google Bookmarks/Extensions/blpcfgokakmgnkcojhhkbfbldkacnbeo/4.2.5_0/_locales/th/": HTTP code 401: "401 Unauthorized", reponse body: {"message":"Token has expired"}
Amazon Linux AMI release 2016.03
Edit again: just a few minutes later and now my speed is up to 80% lower than normal, I guess ACD has implemented a series of throttling measures that are highly dynamic? (edit again: now it's up to full speed for me which is 10megabytes per second, looks like I'm entirely un-throttled now).
In case anyone cares ACD seems to have blocked/limited rclone usage right now.
https://github.com/yadayada/acd_cli/issues/326
> Gideon B
2016/05/26 15:06:36 Cyad1YnfuQOWuYX3HrqsmkYy/goW7h5kUVOYBnVXN192gbUnnW,AuowhAyBEiEdZdm9Gzk-/tWNVyXkBJ,9pYTdNnGs5xeFvL-qBbiwU9lGXfx7XgI460DfKi2DrOg6Kj3WnxrURq9s0B5J8sODmUxYuY1jAVT-kxv1OHHwJ38zCbTWbe9ktKBSTAh2A32LHgCe936ELJOB: Unchanged skipping
2016/05/26 15:06:44 Cyad1YnfuQOWuYX3HrqsmkYy/swcuRNc-mhfeXCGpfUEXZaCT/8hmzPOFgvBj,st4UCVbvP8Wr/IqszWo1TSVpU0xVB31nFjDhj/WQLzWrWlurZLwi88HXXcE45UtaBqQg--h5X0VjUP5rPFfWsQhyB6jw-tQQI9x39g-e3: Copied (new)
2016/05/26 15:06:56 z-MbXfUz93D5DdcHfuKhbDWY/S6T1nKEaL2P4A2EaNj6vEi1VGm8HambEpo4HS58gRHU6S-/sXPUfzaajhWSlzPhoYBad99JE6dH,kg8erAhtR-kw7KGFHpZJy9HhIR-oPMRVIhv1g5/,dhsYy00I,lbg4-ev4XMvnh-aISOTyTuwUOBF98HDy2pPGecB4uJvCOA4ZVoMSMerpTWffX2M,EP,Vy8aCQRC2rU: Received error: HTTP code 401: "401 Unauthorized", reponse body: {"logref":"29109771-238e-11e6-8426-35d341d53fb3","message":"Token has expired","code":""}
2016/05/26 15:07:03 Cyad1YnfuQOWuYX3HrqsmkYy/bOjtilgIVFxlTUVA-ss7pvC9cDmHGoqz-tyYaSJKOqMIt,/ejb0kh2oADu6vrJqiqcyq-Yn/98YtGOQyWz2haHxWhg6Lu-pi9xgBwJ6swhaIyxXn,jOeQW3RbwzCDCfNZ,nivJIKkmB: Sizes identical
2016/05/26 15:07:03 Cyad1YnfuQOWuYX3HrqsmkYy/bOjtilgIVFxlTUVA-ss7pvC9cDmHGoqz-tyYaSJKOqMIt,/ejb0kh2oADu6vrJqiqcyq-Yn/98YtGOQyWz2haHxWhg6Lu-pi9xgBwJ6swhaIyxXn,jOeQW3RbwzCDCfNZ,nivJIKkmB: Unchanged skipping
**Thanks ncw**
Accept-Encoding: gzip
Pragma: no-cache
Vary: User-Agent
X-Amz-Date: Fri, 27 May 2016 15:29:59 GMT
Authorization: Bearer Atza|IQEBLjAsAhRoQAkmoUjV2wDJ9gIci7Vki-4grQIUFlKF3-avWAZ6MniBNhISbAxU_NtFXhiDaYKmMvF4xdnO3DYn3Pg7fkw1xPfH1TkGJb-e_T1KX54BVgUlleYZ-f3jxfbbJ5yT_xN8jRCBphM6l1PRPkSHeAmFGxXGkLXjJkB6tHNmcjtEwsOTGKDaqCmIJxtKXnw7wTj8W0uYxTXonIMAJEy2tlg6H0kXMAhJtuE-oVj7FE_WsLZygkx_uvxZBppU0X9b4GPFX5aj6h8Mt5dXdKptLDoY1EsGoKg8CnsZRriCNp161761bBS8wuqCXawfF3NjX2vzu-Z3nz1Pb4yNuIJ8CLbcXrv2ePn-zwGCQhhi0C1FbNcSiUZQDsMxQFwIkd7ShNg7Z545j6GF8n3JdVMSV6Sv5boqfzFzlkUIPzihmzPccY8E0KIYDzTXgPB67vVTSFMSnFxSh5MIiT8oRMLWPUTkDano24vBysRyvUDvVVf-ICrq5VWr2EfCRDxj0pzfui0g5p_URe9SapByCzWNiokXGRTOKUzJxYvQIfvWSUcoXzirhIOzT6nfC3W-TO1xR_aTt3cjUWNcTvAI6CigPUiKMAJt31Jm_MaGKpobKjnTssJB1Sz8pSPoBI9p
Accept-Encoding: gzip
Pragma: no-cache
Vary: User-Agent
Thanks ncw!
panic(0xae9fc0, 0xc8200140f0)
Ulion
Ulion
however, w3m seems doesn't got support for JavaScript, so I can't authorize rclone to access.
> ca-bundle.crt
yet somehow
is it because I started with a root drive? or because of fat32? or windows keyword? either way it's baffling how simple the workaround is...
I have a large number of files and directories on ACD that contain non-ascii characters (umlauts). During sync, rclone always copies all files with such characters from ACD to the local filesystem. It seems that rclone does not find the files in the local directory and therefore copies them, overwriting the current file.  The same happens again if the same sync command is issued as soon as the previous one finished.
rclone 1.29
ACD
> Raspbian
macsp:~ proto$
key = secret
I dont understand if the Bad Request is to the Keystone server for authentication or to the RadosGW to list the buckets
I removed `storage_url` but still does not work. However with `--dump-bodies` looks like it is a problem talking to keystone
vpn-ho-d-130:~ proto$ rclone -v --dump-bodies lsd lsswift:/
Accept-Encoding: gzip
Accept-Encoding: gzip
Accept-Encoding: gzip
Centos 6.7 :
$ uname -a
ceph infernalis
panic(0xadd0e0, 0xc82000e0f0)
DISTRIB_ID=Ubuntu
DISTRIB_CODENAME=xenial
$ uname -a
ceph infernalis
panic(0xadd0e0, 0xc820010140)
[betaerasure]
region = other-v2-signature
region = other-v2-signature
Yoann
0 stray cats were added.
> `Ubuntu armv7l`
> `rclone sync /data/test acd:/test`
rclone 1.29
Backblaze B2
Onedrive
Vincèn
> Raspbian Jessie
> Dream Objects (ceph)
2016/04/22 16:40:22 filmes/Pure Bathing Culture 'Dream the Dare'-77418151.h264: Failed to copy: NoSuchKey:
2016/04/22 16:40:23 filmes/Let Go Or Be Dragged-145074165-1920x1080.h264: Failed to copy: NoSuchKey:
64bit
### LOG:
When I have files with accents in its name, rclone does not find then and downloads it every time and it says "path/to/file: Copied (new)".
password>
password>
password>
This is a show-stopper, cannot run rclone.
ID_LIKE="rhel fedora"
CPE_NAME="cpe:/o:amazon:linux:2016.03:ga"
Amazon Linux AMI release 2016.03
Byte Order:            Little Endian
NUMA node(s):          1
BogoMIPS:              4988.16
thanks ncw!
PTAL
Errors:                13
AEnB2Uq-1QWvYElu0TsqTtLtCCB-9gy
vIxOYPhKdgXwUC
geANZ2TsY7ze5H4zkClCJg-
iJPMnLNsFAznUGcZVA
Errors:                 1
...ok this is weird, looks like it gets to 100% and then fails???
DreamObjects (Ceph/s3)
rclone sync
Centos 6 64bit
Backblaze B2
`tail -10 rclonelog`
Sebastian
runtime.throw(0x7ab2af, 0x16)
I started another sync with `--transfers=1` and noticed something strange.
os/signal.loop()
goroutine 44 [chan send]:
goroutine 45 [chan send]:
goroutine 46 [chan send]:
goroutine 47 [semacquire]:
goroutine 48 [chan send]:
goroutine 49 [chan send]:
goroutine 50 [chan send]:
goroutine 49555 [chan send]:
created by github.com/ncw/rclone/fs.(*Lister).Start
goroutine 53330 [chan receive]:
goroutine 53331 [chan receive]:
created by github.com/ncw/rclone/fs.(*Lister).Start
goroutine 46297 [chan send]:
goroutine 47990 [chan send]:
goroutine 40786 [chan send]:
goroutine 50666 [chan send]:
goroutine 50574 [chan send]:
bufio.(*Reader).fill(0xc4208a8d80)
b4d6fd906383477fd68857469d0c1513  rclone
model name  : Pentium III (Coppermine)
microcode   : 0x8
apicid      : 0
coma_bug    : no
fpu     : yes
fpu_exception   : yes
bogomips    : 1727.72
As you can see, this is far beyond "make && sudo make install". This is not the difficulty of GCHQ challenge of course but still takes some time and stubborness.
traps: rclone[4337] trap invalid opcode ip:807aa43 sp:bff900ac error:0
in rclone[8048000+5f5000]
rclone lsl drive:dupes
> Errors:                 5
> Errors:                 3
I'm not sure if I was supposed to reply or not.
rclone copy rem:dir/file  localdir
Yep.  I am abusing rclone a bit, because I'm using it for single file transfers.
Hi Nick - I would take a look at this, even though I don't know Go,
Errors:                 1
(BTW, there is a typo here: reponse)
> This is a peculiarity of `os.system` in python, eg
Errors:                 1
Note the difference between IEC and SI unit standards:
# uname -a
BogoMIPS        : 1299.25
BogoMIPS        : 1292.69
Segmentation fault
fulvio
fulvio
@ncw, any news on this ? I met the same issue with the last arm binary
fulvio
`# uname -a
runtime.sigpanic()
github.com/cpuguy83/go-md2man/vendor/github.com/russross/blackfriday.init()
/home/ncw/Code/go/src/github.com/cpuguy83/go-md2man/vendor/github.com/russross/blackfriday/smartypants.go:401 +0x44 fp=0x10b39f88 sp=0x10b39f48
github.com/spf13/cobra/doc.init()
runtime.sigpanic()
# uname -a
BogoMIPS	: 1299.25
BogoMIPS	: 1292.69
runtime.sigpanic()
unexpected fault address 0x88868
runtime.sigpanic()
Sorry if some of this does not make sense...I'm not an expert and I'm looking for some advice.
Walter
Walter
> Make sure GOPATH is set, eg
> export GOPATH=~/bin/go
The Windows computer uploading the file does have SketchUp installed with the proper filetype associations. The Linux computer that successfully uploaded these files did not have SketchUp installed.
# golang.org/x/crypto/poly1305
too many errors
# golang.org/x/crypto/poly1305
too many errors
Here is a remote-to-local copy:
Running command: rclone -v  --include DESTID copy /home/jim/hb/tmppkcpii.b2 b2:hashbackup
Running command: rclone -c -v  --include DESTID delete hubic:test
2016/04/05 21:04:36 Hubic: Got swift credentials (expiry 2016-04-06 16:42:50 +0200 +0200 in 13h38m13.988498139s)
2016/04/05 21:04:36 Hubic: Got swift credentials (expiry 2016-04-06 16:42:50 +0200 +0200 in 13h38m13.885441402s)
Removed DESTID from b2
I have found an similar problem with another sync tool.( https://github.com/odeke-em/drive/issues/154 )
So there is something wrong on my side...if you have any idea how i can address this fell free to tell me. I am pulling my hair out already :-)
Marius.
upload id: 2~BWIg9rIFszTUO4mhoekjxN-wCrCOea5
upload id: 2~IQkBzTaPq7AVS50Dajb8UF-KiqD6asm
upload id: 2~IQJmqAGSijxX6ldZWRRK68dShmnKM80
upload id: 2~shxOWpvPiA2QnPk5Rmyn5HoxmmejrHN
gary-macbook:~ garypaduana$ rclone -v ls M_S3:rpmhost
Errors:                 1
region = us-east-1
This might be related to #395 .
It would be nice if the password prompt ended with a ":" instead of a ">" so that expect scripts and other tools (e.g. emacs) could recognize that it's a password and not echo.
Change
So rclone trace me an error:
Command executed: `tomi@alexandria:/mnt/sdb2$ work/rclone-v1.28-linux-arm/rclone --delete-excluded --filter-from ~/filter_file --dump-filters -v sync onedrive: local:stuff: 2>rclone_server_8.log`
tomi@alexandria:/mnt/sdb2/stuff:/Public/openttd/goofs$ ls -l
-rw-r--r-- 1 tomi users 324590 Jan 22  2008 595x395.png
-rw-r--r-- 1 tomi users 169251 Jan 22  2008 surrealistic.png
-rw-r--r-- 1 tomi users  42497 Jan 22  2008 trees-1.png
-rw-r--r-- 1 tomi users 132091 Jan 22  2008 trees-alot.png
Hi ncw, not sure how the program is structured internally, but I think that if we are making changes that --checksum should not check file size. A checksum will fail if file size is not the same anyways, so a file size check is nothing more than a quick failure shortcut. I would change the checksum option to ignore file size. An option could be added to the really brave to disable all kind of checks by setting --no-check-size as file size is default mechanism if you so wish so.
rclone lsd remote:
## errors
./adiabatic_data
./adiabatic_data/600_20
./adiabatic_data/600_20/run_53
./adiabatic_data/600_20/run_53/outFile.txt
./adiabatic_data/600_20/run_53/output_file.txt
./adiabatic_data/600_20/run_53/jobScript.py
./adiabatic_data/600_20/run_53/error_file.txt
./adiabatic_data/600_20/run_53/log_file.txt
tomi@alexandria:/mnt/sdb2$ cat ~/filter_file
- *.obj
- *.ncb
- *.bak
- *.BAK
- *.suo
- *.idb
- *.ilk
tomi@alexandria:/mnt/sdb2$ work/rclone-v1.28-linux-arm/rclone --delete-excluded --filter-from ~/filter_file --dump-filters -v sync onedrive: google: 2>rclone_server_3.log
- (^|/)[^/]*\.ncb$
- (^|/)[^/]*\.bak$
- (^|/)[^/]*\.BAK$
- (^|/)[^/]*\.suo$
> Etag: "ac951f76e3d45d2edbca0f65f61c2a24"
> Errors:                 1
> Accept-Encoding: gzip
> Etag: "ac951f76e3d45d2edbca0f65f61c2a24"
> Etag: "ac951f76e3d45d2edbca0f65f61c2a24"
With the beta, the error is different though:
Thanks for the response @ncw . It would most likely be the former -- one big file. I am new to TrueCrypt/VeraCrypt, but unless I'm mistaken the concept of automatically encrypting/encrypting each file on disk isn't really where those tools shine. The concept is you either a) encrypt the entire partition and decrypt at boot, or b) create an encrypted "container" that gets mounted as a virtual volume after boot. Either way, the data is encrypted on disk should it fall into the wrong hands.
rclone version,
$ uname -a
How embarrassing.
* ...ooks-eng-all-3gram-20120701-punctuation.gz: 36% done. avg: 14501.5, cur: 14250.2 kByte/s. ETA: 1h42m41s
2016/03/10 15:04:25 googlebooks-eng-all-3gram-20120701-th.gz: Failed to copy: MultipartUpload: upload multipart failed
@dkorunic what version of the client are you using ? this fix will be available with the 1.29 Release that is not yet out.
@zioproto I've tried latest 1.28 beta (v1.28-8-ga1323ebβ and v1.28-9-g9dccf91β). Unfortunately neither work OK with S3 and huge uploads. Any suggestion?
@zioproto ~2.64 GB. However, from what I see it might be related to the fact that I'm doing a S3 to S3 uploads, from one Ceph to other Ceph.
@dkorunic it seem that I have the same bug in the same situation, copy a big file from s3 ceph to s3 ceph and reach the  MaxUploadParts (10000) limit when I copy a 8GB files
X-Amz-Meta-Mtime: 1296240919
X-Amz-Request-Id: tx0000000000000000f1d64-00589aee4e-abfcbd-default
2017/02/08 11:09:21 PUT /bucket/I.tar.gz?partNumber=3&uploadId=2~afSgOhGMTMzK8NfpRahbnj8HVtI3AGr HTTP/1.1
Accept-Encoding: gzip
2017/02/09 15:17:30 millionsongsubset.tar.gz: Failed to copy: SerializationError: failed to decode S3 XML error response
`    proxy_buffering off ;`
Yoann here the log :
`    proxy_buffering off ;`
> 2016/03/09 12:48:56 Google drive root 'Materiale vecchio sciumegu': Modify window is 1ms
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "primo-anno/2010-2011/biochimica-1/Testi esame di idoneit\x85 del 14 gennaio 2013.pdf"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "primo-anno/2010-2011/biochimica-2/Mos\x8a - Riassunto Biochimica 2.pdf"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "quinto-anno/2010-2011/ginecologia/2- Infertilit\x85.ppt"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "quinto-anno/2010-2011/ginecologia/MIP e Sterilit\x85 - SIGO 2007.ppt"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "quinto-anno/2014-2015/psichiatria/Personalit\x85 e disturbi di personalit\x85.pdf"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "secondo-anno/2014-2015/fisiologia-2/Plasticit\x85 e Memoria.pdf"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "secondo-anno/2014-2015/fisiologia-2/Propriet+\xa0 Passive.pdf"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "secondo-anno/2014-2015/fisiologia-2/Propriet\x85 Passive.pdf"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "sesto-anno/2011-2012/chirurgia-2/Lezione carcinoma ano 6\xf8 anno.ppt"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "sesto-anno/2011-2012/chirurgia-2/Pancreatite acuta 6\xf8 anno.ppt"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "sesto-anno/2012-2013/igiene/Corso medicina 6\xf8anno (1 modulo).ppt"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "sesto-anno/2012-2013/igiene/Corso medicina 6\xf8anno (3 modulo).ppt"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "sesto-anno/2012-2013/igiene/Corso medicina 6\xf8anno (4 modulo).ppt"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "sesto-anno/2012-2013/igiene/Corso medicina 6\xf8anno (5 modulo).ppt"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "sesto-anno/2012-2013/igiene/Corso medicina 6\xf8anno (6 modulo).ppt"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "sesto-anno/2012-2013/igiene/Corso medicina 6\xf8anno (7 modulo).ppt"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "sesto-anno/2012-2013/medicina-2/10\xf8 approccio al paziente con episodi sincopali.ppt"
> 2016/03/09 12:48:56 Local file system at /home/sciumegu/sciumegu.it/nuovidown: Replacing invalid UTF-8 characters in "sesto-anno/2012-2013/medicina-2/11\xf8 paziente iperteso.ppt"
/usr/local/go/src/runtime/sema.go:47 +0x26
goroutine 26 [chan receive]:
goroutine 27 [chan receive]:
goroutine 29 [chan receive]:
Isn't it the exact contrary?
@ncw Awesome, thanks.
I still think having one (and only one) command named `copy` or `cp` that would copy the directory itself, but could copy the files with a `*` wildcard would be better. At least less confusing for the users.
Hubic
comp1$ ./rclone -v ls hubic:/
Errors:                 1
comp1$ ./rclone -v lsd hubic:/
I didn't know about buckets ... but I will look closer !
Raphael
Which is different than name
echo -e  "ACL RETRIEVED FROM DESCRIPTION"  |  setfacl --set-file-  TST
1 - Get ACL and store it on DRIVE
drive  edit-desc --description "`getfacl   Estagiarios`"  -id 0BzCak_XXXXX
ACL=$(drive stat  -id 0BzCak_XXXXX   |   grep Description |  awk -F ' '  '{$1=""; print $0}' | sed 's/"//g')
echo -e $ACL   |   setfacl --set-file=-    tst
This special log  could list all updated files and folders local name and remote id in a format that could be easily processed. Like below
Roberto
Backblaze B2
is this something rclone has control over? or something entirely the doing of ACD?
https://github.com/yadayada/acd_cli/pull/374/commits/db9f9b066edaf1888a2e0886c9aa26b589f1fd47
@ncw Do you have any concrete data that the official client does store modification time? I noticed that the node metadata contains both a `createdDate` and `modifiedDate` in ISO 8601 format, however I think these mark the time a node was created or modified in the ACD node database.
Given the comment *overwritable* this could likely be abused to store the modification time.
This will however be application specific, because the key in the properties hash is the appid and you cannot modify another apps properties.
_facepalm_
But it would be nice to have rclone support if it can be figured out :)
Livio
> Livio
Mkdir is always called on Sync, but fails due to an authorization error.
I'm still fairly inexperienced in Go, so thanks for the feedback. All the requested changes seem reasonable to me, so I'll see what I can do.
Azure Files will be more interesting to us.
Access: (0644/-rw-r--r--)  Uid: ( 1001/   zachron)   Gid: ( 1006/   zachron)
Name "encback"
## Readdir results:
Name "VCLEHE6G2L5FPB73T2DZNH6W5KJBD"
rclone -v sync encrypted acd:encfs-test
fusermount -u encrypted
i am running encfs 1.8.1 on gentoo
Paolo
> 2016/02/21 02:02:45 HIM/HIM_OAU_leaders.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HIM_lion.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HIM_KoK_web.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HIM_maskal.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HIM_KoK_print.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HIM_Itrait.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HIM_Gustaf.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HIM_Empress_rideopenlimo.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HIM_Empress_Life'55_web.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HIM_Empress_Life'55_color.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HIM_Empress_Life'55_color_web.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HIM_ElizII_color_web.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HIM_ElizII_color.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HIM_admiral.gif: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HIM_Abuna_confers_order.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HIM Salute cu-bg.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Her_Majesty.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HaileSelassieHortenlarge.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/haileselassieivisitbritain.ram: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HaileSelassie.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/HaileSelassieHortensmall.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/haile_sellassie_I.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/haileoly.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/hailes.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Haile_Selassie_G_0487.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Haile_Selassie_G_0495.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/haile_selassie.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Haile_Selassie_G_0440.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/haile_selassie203.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Haile_Selassie_G_0436.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Haile_print.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Haile_cu_200h.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/haile_portsmouth2_238.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Haile.psd: Duplicate file detected
> 2016/02/21 02:02:45 HIM/haile_and_empress2.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Haile.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/haile35.psd: Duplicate file detected
> 2016/02/21 02:02:45 HIM/haile35_print.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/haile35.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/haile4.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/flag-silk.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/EthiopiaP18a-1Dollar-_1961__f_op_800x349.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Expo67 Guest Emperor of Ethiopia Haile Selassie.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/EthiopiaP17a-500Dollars-_1945_-donatedowl_f.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/EthiopiaP-2Thalers-1933_f_op_800x386.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/EthiopiaP16a-100Dollars-_1945_-donatedowl_f.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/ethiopiap12b-1Dollar-_1945_-donated_f.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/ethiopia1897_fl_n6737.gif: Duplicate file detected
> 2016/02/21 02:02:45 HIM/EthiopiaP15c-50Dollars-_1945_-donated_f.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/EthiopiaP13b-5Dollars-_1945_-donatedowl_f.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/et_h1.gif: Duplicate file detected
> 2016/02/21 02:02:45 HIM/ETHANIM.gif: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Empress_Menen_royal.jpeg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Empress_Menen_royal.jpg.jpeg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Emperor Selassie with Josip Broz Tito_jpg.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Empress_Menen_royal_print.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Empress_Menen_royal.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/emperor1mini.jpeg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/emperadoressss.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/eat.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/diwan03.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/CoronationPostcard_web.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/CoronationPostcard_full_web.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/CoronationPostcard3.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/CoronationPostcard_print.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/church_gate_print.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/chportrait.gif: Duplicate file detected
> 2016/02/21 02:02:45 HIM/coronation-05.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/child.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/CH HIM EARTHSTRONG.bmp: Duplicate file detected
> 2016/02/21 02:02:45 HIM/charro_hat.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/Black Madonna 2.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/blacklion.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/BlackKing copy.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/alphaomega_crop.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/alphaomega2.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/alphaomega.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/autobio.gif.jpeg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/AfricaLion_white.gif: Duplicate file detected
> 2016/02/21 02:02:45 HIM/akef.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/alphao.gif: Duplicate file detected
> 2016/02/21 02:02:45 HIM/AfricaLion_dark.gif: Duplicate file detected
> 2016/02/21 02:02:45 HIM/african.gif: Duplicate file detected
> 2016/02/21 02:02:45 HIM/ababajanhoy.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/a29s.jpeg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/1974_dergue.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/1935.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/39_Hailie_Selassie.158071.full.jpg: Duplicate file detected
> 2016/02/21 02:02:45 HIM/63him.jpg: Duplicate file detected
> 2016/02/21 02:02:53 HIM/__hr_rasmakonnen.jpg: Duplicate file detected
> 2016/02/21 02:02:53 HIM/_38175156_lion_bbc300.jpg: Duplicate file detected
> 2016/02/21 02:02:53 HIM/__hr_coronation3.jpg: Duplicate file detected
> 2016/02/21 02:02:53 HIM/__hr_himfeker.jpg: Duplicate file detected
> 2016/02/21 02:02:53 HIM/_1007736_haile-archive-ap150.jpg: Duplicate file detected
This is the first log of unusual length.
2016/02/11 02:01:44 Google drive root 'Pictures': Error reading temp/Interracial Comics/Hard_Lesson_2/:Couldn't list directory: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded
2016/02/11 02:01:56 Google drive root 'Pictures': Error reading temp/Interracial Comics/:Couldn't list directory: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded
Errors:                 1
2016/02/11 02:02:04 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 02 text.jpg: Failed to copy: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&uploadType=resumable: http: ContentLength=199 with Body length 0
2016/02/11 02:02:04 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 04 text.jpg: Failed to copy: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&uploadType=resumable: http: ContentLength=199 with Body length 0
2016/02/11 02:02:05 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 24 text.jpg: Failed to copy: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&uploadType=resumable: http: ContentLength=199 with Body length 0
2016/02/11 02:02:05 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 23 text.jpg: Failed to copy: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&uploadType=resumable: http: ContentLength=199 with Body length 0
2016/02/11 02:02:05 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 14 text.jpg: Failed to copy: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&uploadType=resumable: http: ContentLength=199 with Body length 0
2016/02/11 02:02:05 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 11 text.jpg: Failed to copy: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&uploadType=resumable: http: ContentLength=199 with Body length 0
2016/02/11 02:02:05 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 28 text.jpg: Failed to copy: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&uploadType=resumable: http: ContentLength=199 with Body length 0
2016/02/11 02:02:05 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 22 text.jpg: Failed to copy: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&uploadType=resumable: http: ContentLength=199 with Body length 0
2016/02/11 02:02:05 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 10 text.jpg: Failed to copy: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&uploadType=resumable: http: ContentLength=199 with Body length 0
2016/02/11 02:02:05 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 21 text.jpg: Failed to copy: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&uploadType=resumable: http: ContentLength=199 with Body length 0
2016/02/11 02:02:05 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 19 text.jpg: Failed to copy: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&uploadType=resumable: http: ContentLength=199 with Body length 0
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 06 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/sharon pg 26 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/sharon pg 25 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 15 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 08 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 12 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/sharon pg 27 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 01 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 18 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 05 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 17 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 13 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 16 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 07 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 09 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 03 text.jpg: Duplicate file detected
2016/02/11 02:02:41 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 20 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 06 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/sharon pg 26 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/sharon pg 25 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 15 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 08 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 12 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/sharon pg 27 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 01 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 18 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 05 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 17 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 13 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 16 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 07 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 09 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 03 text.jpg: Duplicate file detected
2016/02/13 02:02:19 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 20 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 06 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/sharon pg 26 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/sharon pg 25 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 15 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 08 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 12 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/sharon pg 27 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 01 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 18 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 05 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 17 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 13 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 16 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 07 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 09 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 03 text.jpg: Duplicate file detected
2016/02/13 02:03:00 temp/Interracial Comics/Hard_Lesson_2/Sharon pg 20 text.jpg: Duplicate file detected
2016/02/13 02:03:39 HIM/1974_dergue.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 1/10
2016/02/13 02:03:40 HIM/1974_dergue.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 2/10
2016/02/13 02:03:44 HIM/Haile_cu_200h.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 1/10
2016/02/13 02:03:44 HIM/Haile_cu_200h.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 2/10
2016/02/13 02:03:44 HIM/Haile_cu_200h.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 3/10
2016/02/13 02:03:45 HIM/Haile_cu_200h.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 4/10
2016/02/13 02:03:46 HIM/Haile_Selassie_G_0436.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 1/10
2016/02/13 02:03:46 HIM/Haile_cu_200h.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 5/10
2016/02/13 02:03:48 HIM/Haile_Selassie_G_0436.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 2/10
2016/02/13 02:03:48 HIM/Haile_cu_200h.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 6/10
Errors:                 2
-                           HIM/HIM_7_print.jpg: 33% done. avg: 1252.4, cur: 1023.8 kByte/s. ETA: 2s
2016/02/13 02:04:04 HIM/Empress_Menen_royal.jpeg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 1/10
2016/02/13 02:04:05 HIM/Empress_Menen_royal.jpeg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 2/10
2016/02/13 02:04:05 HIM/haile_selassie203.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 1/10
2016/02/13 02:04:06 HIM/Empress_Menen_royal.jpeg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 3/10
2016/02/13 02:04:06 HIM/haile_selassie203.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 2/10
2016/02/13 02:04:23 HIM/Haile.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 1/10
2016/02/13 02:04:23 HIM/Haile.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 2/10
2016/02/13 02:04:23 HIM/Haile.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 3/10
2016/02/13 02:04:24 HIM/HIM_Empress_rideopenlimo.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 1/10
2016/02/13 02:04:24 HIM/.FBCIndex: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 1/10
2016/02/13 02:04:24 HIM/HIM_Empress_rideopenlimo.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 2/10
2016/02/13 02:04:24 HIM/.FBCIndex: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 2/10
2016/02/13 02:04:24 HIM/HIM_Empress_rideopenlimo.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 3/10
2016/02/13 02:04:24 HIM/3221_96472356631_523066631_2541517_4466197_n.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 1/10
2016/02/13 02:04:25 HIM/.FBCIndex: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 3/10
2016/02/13 02:04:26 HIM/HIM_Empress_rideopenlimo.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 4/10
2016/02/13 02:04:26 HIM/3221_96472356631_523066631_2541517_4466197_n.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 2/10
2016/02/13 02:04:46 HIM/HIM_admiral.gif: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 1/10
2016/02/13 02:04:47 HIM/HIM_ACPowell.jpg: Failed to copy: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&uploadType=resumable: http: ContentLength=189 with Body length 0
2016/02/13 02:04:47 HIM/HIM_admiral.gif: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 2/10
2016/02/13 02:04:48 HIM/Emperor Selassie with Josip Broz Tito_jpg.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 1/10
2016/02/13 02:04:48 HIM/HIM_admiral.gif: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 3/10
Errors:                 7
-                          HIM/HIM_21_print.jpg: 69% done. avg:  707.8, cur:  750.6 kByte/s. ETA: 0s
-                         HIM/HIM_KoK_print.jpg: 100% done. avg:  578.1, cur:  751.5 kByte/s. ETA: 0s
2016/02/13 02:05:02 HIM/HIM_ElizII_color_web.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 1/10
2016/02/13 02:05:02 HIM/HIM_ElizII_color_web.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 2/10
2016/02/13 02:05:03 HIM/HIM_kiss_maskal_print.jpg: Failed to copy: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&uploadType=resumable: http: ContentLength=207 with Body length 0
2016/02/13 02:05:23 HIM/Empress_Menen_royal.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 1/10
2016/02/13 02:05:23 HIM/Empress_Menen_royal.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 2/10
2016/02/13 02:05:23 HIM/Empress_Menen_royal.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 3/10
2016/02/13 02:05:23 HIM/Empress_Menen_royal.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 4/10
2016/02/13 02:05:24 HIM/Empress_Menen_royal.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 5/10
2016/02/13 02:05:26 HIM/Empress_Menen_royal.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 6/10
2016/02/13 02:05:43 HIM/HIM_crown_bw.jpeg: Failed to copy: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded
2016/02/13 02:05:44 HIM/him06x.gif: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 1/10
2016/02/13 02:05:47 HIM/hailes.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 1/10
2016/02/13 02:05:49 HIM/hailes.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - retrying 2/10
Errors:                11
Errors:                11
> Errors:                34
2016/03/01 06:21:04 Senayit - Adanech/iPod Photo Cache/F20/T424.ithmb: Received error: googleapi: Error 403: User rate limit exceeded, userRateLimitExceeded - retrying 1/10
2016/03/01 06:21:23 Senayit - Adanech/iPod Photo Cache/F20/T424.ithmb: Failed to copy: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&uploadType=resumable: http: ContentLength=191 with Body length 0
2016/03/01 06:21:48 Senayit - Adanech/Birth of Baby Senayit/Birth of Baby Senayit099.jpg: Received error: googleapi: Error 403: User rate limit exceeded, userRateLimitExceeded - retrying 1/10
Errors:                45
Errors:                 1
> /usr/sbin/rclone sync --low-level-retries 20 /home/isaiahsellassie/Pictures Gdrive:Pictures
2016/03/06 02:02:29 Senayit - Adanech/1939596_477758185664244_1763983226_n.jpg: Received error: googleapi: Error 403: Rate Limit Exceeded, rateLimitExceeded - low level retry 1/20
Errors:                 1
jant90@SERVER:~$ rclone dedupe gdrive:test
rclone copy --dump-headers --dump-filters --dump-bodies --log-file ./rclone.log --dry-run --size-only --verbose --ignore-existing . b2pabilder:b2test20160218/somedir/
Also, the order is strange:
2. List buckets (why??)
4. Create bucket (what the heck??)
BUT
- Deb/Ubuntu
I've tried making a chocolatey package for rclone, and it seems to work. You can try it with the steps below if you have chocolatey installed:
cd chocolatey-rclone
cpack
Content-Encoding: gzip
- Gzip it
Errors:                 1
and select the Content-Encoding, fill in gzip and click the plus icon:
STANDARD_IA is half price of the default STANDARD...
$ uname -a
Thanks for the confirmation and clarification!! I'm really new to Go, and your advice helps me a lot.
I'm using rclone on Windows with hubiC and I use it with hubic2swiftgate (so with a swift configuration). I can upload files without problem excepted when a filename contains accent.
If a filename contains one or more accents (like the word Liberté.jpg), upload is OK, no error reported by rclone. But if I launch hubiC official sync software, when the soft compares uploaded file with rclone and local file, it says there is a conflict between both. No problem with filename without accents.
A last point : I use Cyberduck to navigate into my Swift space, so I can see default and default_segments container and all files.
Also Content-Type is "application/octet-stream" instead of "video/x-matroska"
So perhaps is it an issue only with manifest but not with chunks ?
`rclone.exe --swift-chunk-size 1G copy "Vidéo.mkv" remote:"default/Test Swift"
rclone.exe --dump-headers lsl remote:"default/Test Swift/Vidéo.mkv"
X-Auth-User: hubic******
Accept-Encoding: gzip
20Swift/Vid%C3%A9o.mkv HTTP/1.1
Host: lb9911.hubic.ovh.net
Etag: "41d778b2272216710deebc235bb73455"
20Swift/Vid%C3%A9o.mkv HTTP/1.1
Host: lb9911.hubic.ovh.net
Etag: "41d778b2272216710deebc235bb73455"
X-Auth-User: hubic******
Accept-Encoding: gzip
Pragma: no-cache
Host: lb9911.hubic.ovh.net
Host: lb9911.hubic.ovh.net
Accept-Encoding: gzip
571Z
577Z
20Swift/Vid%C3%A9o.mkv HTTP/1.1
Host: lb9911.hubic.ovh.net
Etag: "41d778b2272216710deebc235bb73455"
1073741824 Vidéo.mkv/1455277910.9867985/1965632020/00000000
891890196 Vidéo.mkv/1455277910.9867985/1965632020/00000001
afd4e0b11c9c7f80ea0636b1c4c918e9  Vidéo.mkv
Vidéo.mkv
rclone.exe --dump-headers lsl remote:"default/Films SD/Les Collègues.mkv"
X-Auth-User: hubic********
Accept-Encoding: gzip
%20SD/Les%20Coll%C3%A8gues.mkv HTTP/1.1
Host: lb9911.hubic.ovh.net
Content-Type: video/x-matroska
X-Object-Manifest: default_segments/Films%20SD/Les%20Coll%C3%A8gues.mkv/14199774
%20SD/Les%20Coll%C3%A8gues.mkv HTTP/1.1
Host: lb9911.hubic.ovh.net
Content-Type: video/x-matroska
X-Object-Manifest: default_segments/Films%20SD/Les%20Coll%C3%A8gues.mkv/14199774
$ uname -a
I'm a relatively new user of rclone - apologies if this is a silly question, but I didn't see an answer in the searches I tried...
2016/02/09 18:18:49 FAIL: Failed to copy: read /afs/media/Pictures/2007/FAIL: input/output error
rclone • 4:49 PM
rclone • 5:02 PM
rclone • 5:02 PM
rclone • 5:02 PM
rclone • 5:11 PM
écrit :
rors
import pexpect
The crontab command is /usr/sbin/rclone sync /home/isaiah/Music Adrive:Music.  I don't know the text of the command for the copy-paste operation.  I was using the Caja file manager that comes with the Mate desktop.  It used to be called Nautilus in the Gnome desktop before the project forked.
- Apache/2ABA8D89-AB91-4BF0-95A4-94F5904AA961.png
- Apache/35C8B81E-EB19-4085-A575-70D717ADFCD7.jpg
- Apache/39B89A8F-C534-4AA5-87B2-89A18526177F.jpg
- Apache/3A4D2CF4-0868-491B-A5CB-2EB47E756A5F.jpg
- Apache/3A74C6A9-5C8B-4D9D-9D20-5F6B41F85B8F.jpg
- Apache/3B0A473C-32AF-4B9A-9D5D-FFF0D8AADF3D.jpg
- Apache/3D480626-9ABE-403B-B173-E67287FF8464.jpg
Errors:                 1
rcloneClientSecret = "8p/yms3OlNXE9OTDl/HLypf9gdiJ5cT3"
Is this not a security concern?
@ncw @klauspost  I think you guys are missing the security issue from having the Secret publicly known and the stackexchange thread is actually correct.
You still need to use the secret even the documentation might indicate otherwise.
There is a python library that can be used as a reference of the API: https://github.com/havardgulldahl/jottalib.
Jottacloud is known for its privacy concerns and has a "Canary" on its blog too: https://www.jottacloud.com/blog.
This is really interesting. From the perspective of `jottalib`, just getting the extensive test suite of rclone to run without errors would be a great boon.
So please let me know if there's anything we should do to help out with the integration.
And file issues over at https://github.com/havardgulldahl/jottalib/issues if there's anything amiss.
x-amz-request-payer:requester
> x-amz-request-payer:requester
And on some others, the error is:
Failed to copy: Failed to upload: Bad hex digit:   (400 bad_request)
- debian wheezy x64
@ncw Interestingly, all the bad hex digit files seem to be named `._Icon` or `Icon`.
Drive name = encrypted
Music
No luck, any thoughts? I have the exact same issue when using a crypt remote type. If I try secret:myfolder/ It get "didn't find section in config file".
Nevermind, I had two words in the remote name switched around.   2016/01/09 03:00:13 15 boda laura y oscar/foto/1/DCIM/100EOS5D/IMG_2158.CR2: Received error: HTTP code 409: "409 Conflict", reponse body: {"logref":"b8a1c898-b674-11e5-94a1-25dbf54c992b","message":"Node with the name img_2158.cr2 already exists under parentId ErQpIn7aQJyboAPthMpXow conflicting NodeId: PipzSt9OQECDw6-CmJ-c-Q","code":"NAME_ALREADY_EXISTS","info":{"nodeId":"PipzSt9OQECDw6-CmJ-c-Q"}}
Errors:                 1
Errors:                 3
Errors:                 5
Errors:                 6
2016/01/12 00:24:22 Amazon cloud drive root '9-1': Couldn't list files: HTTP code 400: "400 Bad Request", reponse body: {"logref":"7263a9bc-b8ba-11e5-af9a-a35439bbe5ef","message":"Next token is expired"}
2016/01/12 00:24:22 Amazon cloud drive root '9-1': Error reading fotos y videos personales/20151026/:HTTP code 400: "400 Bad Request", reponse body: {"logref":"7263a9bc-b8ba-11e5-af9a-a35439bbe5ef","message":"Next token is expired"}
2016/01/12 00:24:23 Amazon cloud drive root '9-1': Error reading fotos y videos personales/note2 wassap 12nov2015/WhatsApp Images/Sent/:HTTP code 400: "400 Bad Request", reponse body: {"logref":"72875e3d-b8ba-11e5-8e26-8333432c69ae","message":"Next token is expired"}
Let me give you some more extra information. I uploaded the first backup of this usb drive (1.5TB), using the official amazon desktop application, and now I am trying to use rclone to uploading just the new files. At the moment I haven't added new files to the usb drive, so now there are the same files in my local usb drive than in acd.
- boda laura y oscar/foto/1/DCIM/100EOS5D/
Log:
MacBook-Pro-13:bin David$ cat prueba.sh
#/usr/bin/osascript -e 'display notification "Prueba.sh" with title "9-1 conectado - Haciendo backup del 9-1 en acd"'
#echo "Comenzando rclone del 9-1 en acd" >> /Users/David/bin/cronlog.log;
#fi
#fi
# rclone -v copy /Volumes/9-1\ 3TB/9-1/trabajo\ fotos\ boda\ laura\ y\ oscar/ remote:9-1/"trabajo fotos boda laura y oscar"
2016/01/21 00:13:45 Amazon cloud drive root '9-1': Reading "16 boda elena&alex 13-jun-2015/"
2016/01/21 00:13:45 Amazon cloud drive root '9-1': Reading "trabajo fotos boda virginia sergio/"
2016/01/21 00:13:45 Amazon cloud drive root '9-1': Reading "trabajo fotos de boda elena y alex/"
2016/01/21 00:13:45 Amazon cloud drive root '9-1': Reading "trabajo album boda esther cesar/"
2016/01/21 00:13:45 Amazon cloud drive root '9-1': Reading "slideshow virginia sergio/"
2016/01/21 00:13:46 Amazon cloud drive root '9-1': Finished reading "16 boda elena&alex 13-jun-2015/"
2016/01/21 00:13:46 Amazon cloud drive root '9-1': Finished reading "trabajo fotos de boda elena y alex/"
2016/01/21 00:13:46 Amazon cloud drive root '9-1': Finished reading "trabajo fotos boda virginia sergio/"
2016/01/21 00:13:46 Amazon cloud drive root '9-1': Finished reading "trabajo album boda esther cesar/"
2016/01/21 00:13:46 Amazon cloud drive root '9-1': Finished reading "slideshow virginia sergio/"
MacBook-Pro-13:bin David$ cat prueba.sh
Isaiah
From rclone --
Rclone seems to treat the last word 'files' as another argument.
Thanks.  Quotes fixed it.  I was trying it with quotes previously but in the wrong spot.  ie. ACD:tv\"my files"
Errors:                 5
Errors:                 5
Is the line that tries to exclude .DS_Store wrong?
/abc/**
/ghi/**
+ /abc/**
+ /ghi/**
+ ABI/**
/bin/**
/ABI/**
+ ABI/**
Simon
Disclaimer: My first ever lines of Go. :)
Hi ncw,
I believe the reason is because within /mnt/bind is this same mount point recurring over and over again i.e.
/mnt/*\*
That being said, I really appreciate rclone.  Thanks for all the hard work.
Hope this can be implemented, it would be a great enhancement!
3. Is my _Final Goal_ described above possible with RCLONE at all?
Thanks for answering a lot of questions on this forum ncw.
2.What's your take on one of the below solutions by _ameir in #180_
**More Suggestions :)**
Hi nwc,
Hi nwc,
Only question at this point though is, it took about an hour to check that there were no differences between my drive and ACD when I ran it for the second time, is that expected time for 75GB of data with over 90,000 files?
**On RasperryPi Local:**
>amzcld:UseMe/mirror
**On RasperryPi to ACD:**
>rclone size amzcld:UseMe/mirror
Isaiah
Gary, the exact command is - /usr/sbin/rclone sync /home/isaiah/Documents Gdrive:Documents
Just to be sure, do I designate sub directories on Gdrive with a : or a /?  Should it be 'Gdrive:Pictures/Senayit-Adanech' or 'Gdrive:Pictures:Senayit-Adanech'?
TIA
$ rclone ls ACD:TEST/123
10 test.groovy
Thanks, Gary! and a very merry X'mas to both of you!
Example error from the very begining of the verbose version of this process with my name removed not sure if the amazon links should be blacked out as well or not:
There can be dozens of these sometimes, all caused usually by a small handful of files.
- ACD+Crypt 'copy': **success** (`v1.33-63-gace1e21`)
- ACD+Crypt+FUSE: pending (`v1.33-64-gbc414b6`)
# ls -al /mnt/acdcrypt/media/
# ls -al /mnt/acdcrypt/media/
@Originn You could try setting `--acd-upload-wait-time 1s --acd-upload-wait-per-gb 1s --retries 1` which should have the effect of exiting after the 60 second timeout by the acd api. I don't think you can avoid the initial 60 second wait for the answer to the PUT/POST request.
@Originn It is only implemented in the beta, you can omit it in the stable version.
@Originn Yes.
Errors:                 1
[DokanInstall_0.6.0.zip](https://github.com/ncw/rclone/files/71906/DokanInstall_0.6.0.zip)
Dokan (with `--reverse`)
![groovy](https://cloud.githubusercontent.com/assets/4510602/12077211/9d399d2a-b18c-11e5-9456-3ea63060ff6a.PNG)
Errors:                 1
N:\>cd "PjxNNGtyqk8EISnAH58A,fI,"
N:\PjxNNGtyqk8EISnAH58A,fI,>dir
Volume in drive N is DOKAN
01/02/2015  12:53 PM    <DIR>          2haehT9H7yiX1nj9aqo1lOOA
01/02/2015  12:53 PM    <DIR>          ejb0kh2oADu6vrJqiqcyq-Yn
01/02/2015  12:54 PM    <DIR>          -yKOSOU2DrPVaZ1i1-P7Ox3e
Errors:                 1
2016/01/06 23:12:59 ioutil.ReadDirReaddir N:\: The system cannot find the path specified.
@Sumanthsas3 try with setting env var GODEBUG=netdns=go
Hello, I don´t know why the issue happens, but I´m having trouble with characters like this:
é ó í á ã õ ç è à ì
![acentuado](https://cloud.githubusercontent.com/assets/3661806/11983773/81ecf542-a98c-11e5-8072-224196a56d64.png)
My Locale:
convmv -f latin1 -t utf8 -r /pathto
Firstly, thanks alot for rclone I like it alot. :)
Rafael Reinoldes
rafareino@gmail.com
happens to him." (Aldous Huxley, Texts and Pretexts - 1932)
Sway
https://github.com/cnbeining/onedrivecmd
api_client_secret:7G7pYcv6xrrk3VnHt2ReyWeyjhrFBs9bEWoaC7HPLXE=
i am writing code that talks to S3 and local.
> dual and hate it, but I have no option because of homework.
> [image: googledrivebigeyecantbelied]
I don't know much about Go, but I did find a Go wrapper for inotify here:
https://godoc.org/golang.org/x/exp/inotify
Anyone else handle this a different way?
@protonmesh
Use flock.
How do you create a bucket outside "default" ? seems impossible to me...  When syncing my Google Drive to my local hard disk, I get this error every time I attempt a sync. Interestingly, the reported different sizes stay the same across rclone runs.
* Google Photos/2014/09/IMG_20140907_125453872_HDR.jpg
* Google Photos/2014/10/IMG_20141001_104150978_HDR.jpg
* Google Photos/2014/10/IMG_20141001_104203277_HDR.jpg
Errors:                 1
`rclone copy /home/aleksandar/Pictures/background.jpg remote:backup`
So using it as a: `rclone copy /home/aleksandar/Pictures/background.jpg GoogleDrive:backup` all works fine.
Thank you very much for responding and investigating this.  rclone looks
> bin
> │   └── drivesink
> └── rclone
>     └── rclone.1
> bin/rclone/rclone -nv copy bin acd:bin
> remote? Thanks
**24d803d642f9e473c8aee234fcf6fde2  qikvideo-2010-08-29-20-43-14.png**
What is interesting here though is that the 'Google Photos' folder is a 'special' folder in that it is essentially a view in google drive to your photos.google.com photos.  When Android devices upload images, they go into photos.google.com and then are represented in the 'Google Photos' folder on drive.
Thanks for rclone ;).
Hello ncw !
Is there any way around this?
I'm learning Go right now just to be able to contribute
.localized
asura:~ drmac$
asura:~ drmac$
asura:~ drmac$
asura:~ drmac$
asura:~ drmac$
Oh crap. I see the mistake. Sorry for wigging out. PEBKAC. :smile: This worked fine:
2015/11/30 01:40:45 03 - 비오는 압구정.flac: Failed to copy: HTTP code 504: "504 GATEWAY_TIMEOUT", no response body
I apologize if I'm missing something obvious, but I attempted to upload my photos to ACD with rclone. At some point the process was interrupted and now I'm seeing a lot of these:
encrypted store...
rpipe.py --replay --nocheck crypt:an/ecrypted/loc | <some sink>
$ touch /tmp/a/aaa /tmp/a/bbb
a/aaa
a/bbb
a/ccc
# Let's try a path that doesn't exist
rdiff-backup has similar (but somewhat more convoluted) behavior.
@ncw oops, I didnt realize I could just use the exit code. Silly me. Thanks!
$ touch foo
$ rclone copy foo ACD:Testing/bar
0 bar/foo
This is what we use to upload our product to GitHub Releases (https://github.com/aktau/github-release)
@ncw I recently cloned the project to add B2 support as well. I'm glad to see you already got something working. I'd like to help if possible, I received access to it and would like to use it with `rsync`. Thanks for providing this great tool and Go lang code!
@ncw I saw that sha1 pull a bit ago, didn't know about #282 though, looks good.
X-Amz-Acl:
X-Amz-Content-Sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
X-Amz-Date: 20151117T124253Z
X-Amz-Meta-Mtime: 1447558113.143903834
Accept-Encoding: gzip
X-Amz-Id-2: uHPGg56PPGI3adrcKYF8hbS7cNz9cEJrBsiQXivjpmMva/sWl/5Py9vjf8b94tOmR4mMK/oOYRk=
X-Amz-Request-Id: 9F5FC12FD33E59A4
/usr/local/go/src/runtime/sema.go:43 +0x26
goroutine 18 [chan receive]:
bufio.(*Reader).Peek(0xc8204be7e0, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0)
goroutine 48 [semacquire]:
/usr/local/go/src/runtime/sema.go:43 +0x26
goroutine 49 [semacquire]:
/usr/local/go/src/runtime/sema.go:43 +0x26
goroutine 50 [semacquire]:
/usr/local/go/src/runtime/sema.go:43 +0x26
bufio.(*Reader).fill(0xc8203a3da0)
bufio.(*Reader).Peek(0xc8203a3da0, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0)
bufio.(*Reader).Peek(0xc82011ef00, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0)
Rayno
Error: It is only necessary to use a unique prefix of the subcommand, eg 'mo'for 'move'.
It's gross, but it works. :)
Howzit - Still using rlcone and enjoying the new versions.
- At 5am, switch to 3000
Order should be irrelevant.
--config='$RCLONECONF' \
--config='$RCLONECONF' \
--config='$RCLONECONF' \
--config='$RCLONECONF' \
https://godoc.org/golang.org/x/crypto/openpgp
First off, thanks for rclone (especially with hubic support)!
has the opportunity to see two or more snapshots of the ciphertext at
Love the app btw!
I've subscribed! Going to start using rclone with Hubic and have been looking at my options regarding and encryption layer. Frankly, I don't really think I care for super duper amazing encryption, I just don't want it to be very easy.
Looking at `encfs --reverse` and restic atm. I do like what ncw is saying above about how he'd go about it. That sounds more than sufficient.
I know it's really hard with cloud providers especially since almost all are object, not fs based. But the client shouldn't have to suffer because of this, especially when large amount of data are concerned.
Why not use the industry standard AES256 and SHA256 from package crypto/*? A lot of CPUs have native support for it, which is a bonus. My opinion is that file name encryption is a must...
@ncw sounds great, any eta?
1. Why are you using a static key with scrypt?
That way, people who fear losing it can at least choose a phrase of their own accepting a slightly lower level of security (potentially, depending on their chosen salt).
If user is careful enough to add custom memorable salt, then they can achieve the same effect by longer password.
rclone --bwlimit=99M --transfers=32 -v --log-file=LOGFILE.out copy LOCALDIR0000001 ACDE:REMOTEDIR000001
Durval.
I have had quite a few more "Member must have length less than or equal to"  errors here (not only in AAAAAAAAAAAAAAAA but also on other directory trees I've copied to my ACDE remote) and I can confirm that the number it prints is always 280.
Unfortunately that's not an option... these file names "encode" sensitive metadata information about the file which can't be left "in the open" (the AAAAAAAAAAAAAAAA etc above are actually obfuscations on the original component names).
Man, that would be great, and not only for this issue but also for ModTime, useful hashes, etc. I wish I knew Go (or had the time to sit down and study it right now) so I could contribute to implementing this... but if you need any testing or anything, just let me know.
Durval.
Errors:               105
Yes, I do have some files with + in them, but as far as I understand #218 this only causes them to be reuploaded/redownloaded. None of these files are particularly large, so I don't believe this is the reason of the slowdown.
- .vagrant/**
- .debris/**
- .otto/**
It's a lousy error from Amazon!
FYI, I found the reference to the 50GB limit - https://github.com/yadayada/acd_cli
- 49 GiB – 408 and never appeared
here "sensitive" is use become "insensitive".
> --swift-chunk-size=5G
i don't know why you say that the --size-only has the same speed. It isn't true!
rclone.exe copy "local/path" "hubic:remote/path" -n -v --size-only
Like this? This is only a very very small snippet of the spam:
- .vagrant/**
- .debris/**
- .otto/**
rclone copy -v acd:/Videos/Raw/footage.m2ts drive:/Videos/Raw/
Alex
@ncw good point about the web gui using a different method to access ACD.
$ docker-acdcli -v dl /Videos/Raw/footage.m2ts
15-11-09 07:34:46.413 [INFO] [acd_cli] - Resolved "/Videos/Raw/footage.m2ts" to "nDMe3qnFM1OgAiUXNpMFoq"
15-11-09 07:34:46.422 [INFO] [acdcli.api.backoff_req] - GET "https://content-na.drive.amazonaws.com/cdproxy/nodes/nDMe3qnFM1OgAiUXNpMFoq/content"
15-11-09 07:34:46.428 [INFO] [requests.packages.urllib3.connectionpool] - Starting new HTTPS connection (1): content-na.drive.amazonaws.com
15-11-09 07:34:47.024 [INFO] [requests.packages.urllib3.connectionpool] - Starting new HTTPS connection (1): cd-na-prod-content.s3.amazonaws.com
Anyhow, what's interesting is that the download of said file works with acd_cli. They have a [git commit](https://github.com/yadayada/acd_cli/commit/8cd8bd950b167160a42c98781153dc4bf3731a72) designated as a workaround for large files involving chunked/ranged downloads (in content.py).
Etag: "0fbab9ecbbdc9ade6d07712348600eeb"
When being redirected we may want to strip authentication from the
WTF!
The situation is the same for the other isos.
API is describe here :
Wooouh !
2015/08/02 00:59:55 Failed to create file system for "acd:": Failed to get endpoints: Get https://drive.amazonaws.com/drive/v1/account/endpoint: x509: failed to load system roots and no roots provided
Bizarre
Bugs?
On my testing rclone is bugged like hell!
rclone lsd hubic:
Zeshan
As ncw said:
while the current standard in the swift community is container + "_segments" all developers I spoke to acknowledge that this is not optimal as there are many GUI tools that show these segment containers and
:+1: Terraform fixed it using hashicorp/terraform@cadbbba
Oops, forgot to mention, I'm using OS X El Capitan, which is 64-bit. College gets internet from Time Warner Cable.
50x are the main ones.
time rclone size acd:
<h2>Désolés!</h2>
Errors:                 3
Errors:                 1
n) New remote
client_secret>
Remote config
Hello there Aleksej,
> n) New remote
> client_secret>
@zeshanb, it I's impossible because where is no GUI — It is Ubuntu Server w/o even monitor so i connect via ssh
root@readynas:~# rclone config
n) New remote
name> amazon-cloud
6) hubic
client_secret>
Remote config
Axtux
@ncw I'm sorry, but I've never written a line in Go and this doesn't look like a trivial thing to do.
// hacktackery beyond me, an almost straight up fork of the HTTP client, or
> speed up the current method, before throwing in "magic".
Of course I did. But, by a lack of deeper insight in "those hings" I just stopped using it.
I don't really know if there was a problem despite that I dreamed of a bi-sync.
Axtux
IMO, what should be changed :
Are you referring to [here](https://github.com/ncw/rclone/blob/6344c3051caf06c3ecd2da5148bd01391ef22b99/amazonclouddrive/amazonclouddrive.go#L118)? So, different remote types could have different rules for names, correct?
Axtux
+++ b/swift/swift.go
Although very precise the "Bytes" unit is not very user friendly.
I could be great to have an option to output MBytes or GBytes values instead.
hubic 25/1/1.2
They're RAW images, ~27M each.
So I'm not sure what's happening there either.
Actually I think it must be something else. I'm seeing the same blocks uploading over and over and pacer rate bumping up the rate limiting a ton (this is about the fourth iteration):
(rclone is installed in ~/bin not in /usr/bin, and is being run as the mhkohne user)
n) New remote
client_secret>
Remote config
- Say N if you are working on a remote or headless machine
If so, why did it use 127.0.0.1 when I've already told it the server is headless, and therefore implied that I'm running a browser on another system.
400 Bad Request
response_type=code
I have been testing rclone with ACD and I am very impressed with how well it performs, considering that ACD support has just recently been added.
It's a quick fix and this is my first experience with Go, so I ask for code review.
Not sure what's wrong.
rclone --custom-data={'x-meta-object-my-favorite-car':'ford mustang', 'X-Delete-After': 3600}   copy /home/doug/data/ SwiftCluster:container
rclone --custom-data={'x-amz-meta-my-favorite-car':'ford mustang'}   copy /home/doug/data/ S3Cluster:bucket
Help!
2015/09/04 18:40:34 2014-09-14 12:14 Walk With Gail, Jake and Inca.kmz: Unchanged skipping
2015/09/04 18:40:34 2014-08-24 15:19 Walk Ariund Hurstwood Reservoir.kmz: Size and modification time the same (differ by 0, within tolerance 1ms)
2015/09/04 18:40:34 2014-08-24 15:19 Walk Ariund Hurstwood Reservoir.kmz: Unchanged skipping
2015/09/04 18:40:34 2014-03-24 Drive To Work From Jo's.kmz: Sizes differ
2015/09/04 18:40:34 2014-03-20 Drive Home Via Tesco.kmz: Sizes differ
2015/09/04 18:40:34 2014-03-24 Drive Home From Work.kmz: Sizes differ
2015/09/04 18:40:34 2014-03-19 Drive Home From Work Via Tesco's.kmz: Sizes differ
2015/09/04 18:40:34 2014-04-13 07:53 Biking With Gail.kmz: Sizes differ
2015/09/04 18:40:34 2014-01-05 Crowwood Farm.kmz: Size and modification time the same (differ by 0, within tolerance 1ms)
2015/09/04 18:40:34 2014-04-10 12:22 Walk To Meet Gail.kmz: Sizes differ
2015/09/04 18:40:34 2014-01-05 Crowwood Farm.kmz: Unchanged skipping
> confuse rclone no end as it syncs one, then the other each time.
Errors:                 1
As a side note: targeting Rados directly works perfectly.
- Ceph 0.94.3
- rclone 1.20
@ncw How about something like: If you invoked the `-meta` flag in your Rclone command, then it will head the object, read the custom metadata and then store it in a temporary json blob. Once the object has been transferred and the md5sum has been checked, the metadata stored in json will be applied through a post to the object in the destination container/bucket. ?? It might require a few extra operations, but it would only take a hit if you invoke the `-meta` flag, and the operations would (perhaps) not be ridiculously expensive.
@jamshid  @ncw that's how it's done when using [JClouds with the "filesystem" blob store ](https://jclouds.apache.org/guides/filesystem/) implementation. For example:
bucket_acl = private
but i always get error, eg.
Hehe ... didn't think about it being hosted on Swift. Makes sense on the no symlink thing. Your suggested workaround would be great, though. Thanks!
Errors:                17
Errors:                17
Errors:                18
8  paix01-jfk1.amazon.com (198.32.118.102)  9.018 ms  9.080 ms  9.607 ms
/cams/<cameraname>/2016-02-01
/cams/<cameraname>/2016-02-02
/cams/<cameraname>/2016-02-03
/cams/<cameraname>/2016-02-04
/cams/<cameraname>/2016-02-05
rclone -delete robacd:/cams/playroom/2016-03-29/\*
OR
rclone -delete robacd:/cams/playroom/2016-03-29/
rclone -delete robacd:/cams/playroom/2016-03-29
The lsd command in the script of @nsw fails for me. Executing it outside the script gives the message `level value not supported`.
acd:FOLDER
I ran python3 script.py acd:FOLDER
2016/12/05 09:21:43 Encrypted amazon drive root 'cloudm/t55mfpdhjnnpr9gcctbmus931o/prtmcteuum3panir771giakboo/d9saeilc969hoki1sdvar99b86i81mgfjo3qk0cbr4sfv7cqbrtg/pt9ds1q722h53k7vvk8f48r9nc': Modify window not supported
2016/12/05 09:21:43 amazon drive root 'cloudm/t55mfpdhjnnpr9gcctbmus931o/prtmcteuum3panir771giakboo/d9saeilc969hoki1sdvar99b86i81mgfjo3qk0cbr4sfv7cqbrtg/pt9ds1q722h53k7vvk8f48r9nc': Reading ""
2016/12/05 09:21:43 amazon drive root 'cloudm/t55mfpdhjnnpr9gcctbmus931o/prtmcteuum3panir771giakboo/d9saeilc969hoki1sdvar99b86i81mgfjo3qk0cbr4sfv7cqbrtg/pt9ds1q722h53k7vvk8f48r9nc': Finished reading ""
i tried rclone rmdir but failed
1. Creating a placeholder file (like `somedir/._empty_`) that is otherwise ignored by rclone except to mark that a directory exists.  Potential collisions can be avoided by making the name of the placeholder file configurable per storage destination.  For destinations that support some form of metadata tagging of files, they could also be explicitly marked with that somehow to remove any possible ambiguity.
But the command will remove the path itself also, not just the directories under the path.  Also 'directories' is misspelled. @ncw, using rmdirs in rclone v1.35-33-g47ebd07 with Google Drive I'm experiencing the same `Failed to rmdirs: directory not empty` errors as others.  The directory appears to be empty.
RSYNC  - the destination dir
RSYNC_BAK/2016_08/drawing/hid/H1500012.dwg__2016_08_17_224039
RSYNC_BAK/2016_08/drawing/hid/H1500012.dwg__2016_08_18_125240
RSYNC_BAK/2016_08/drawing/hid/H1500012.dwg__2016_08_22_224135
RSYNC_BAK/2016_08/drawing/ele/E1500025.dwg__2016_08_03_224007
RSYNC_BAK/2016_08/drawing/ele/E1500025.dwg__2016_08_04_125246
RSYNC_BAK/2016_08/drawing/ele/E1500025.dwg__2016_08_08_224054
RSYNC_BAK/2016_08/drawing/ele/E1500025.dwg__2016_08_11_223952
RSYNC_BAK/2016_08/drawing/ele/E1500025.dwg__2016_08_17_224039
RSYNC_DEL/drawing/ele/E1500025.dwg
rsync -av --acls --xattrs --stats --backup --backup-dir=/RSYNC_BAK/2016_08 --suffix=__2016_08_17_224039      /drawing       /RSYNC
BASE_DEL="/RSYNC_DEL"
BASE_BAK="/RSYNC_BAK"
rclone-v1.35-33-g47ebd07β
Note my remote is onedrive, and using crypt with encrypted filenames (although using the onedrive remote NOT using crypt doesn't seem to make any difference?)
Would be really nice to have Box support :)
Anything we can do to help out here?  Is the interface for adding a new cloud provider well defined in your Go codebase @ncw? :+1:  I would also love to have Box.com support.  I have unlimited space here due to University contract...
HHere by a verbose
2015/08/11 19:18:19 Drive/Perso/upload/include/fpdf/font/helveticab.php: Copied (new)
2015/08/11 19:18:19 Drive/Perso/upload/include/fpdf/font/helveticabi.php: Copied (new)
2015/08/11 19:18:20 Drive/Perso/upload/include/fpdf/font/helveticai.php: Received error: Upload failed - retry: googleapi: Error 403: User rate limit exceeded, userRateLimitExceeded - retrying 1/10
2015/08/11 19:18:20 Drive/Perso/upload/include/fpdf/font/helveticai.php: Removing failed copy
2015/08/11 19:18:20 Drive/Perso/upload/include/fpdf/font/helveticai.php: Failed to remove failed copy: googleapi: got HTTP response code 404 with body: Not Found
2015/08/11 19:18:20 Drive/Perso/upload/include/fpdf/font/helveticai.php: Received error: Upload failed - retry: googleapi: Error 403: User rate limit exceeded, userRateLimitExceeded - retrying 2/10
2015/08/11 19:18:20 Drive/Perso/upload/include/fpdf/font/helveticai.php: Removing failed copy
2015/08/11 19:18:20 Drive/Perso/upload/include/fpdf/font/helveticai.php: Failed to remove failed copy: googleapi: got HTTP response code 404 with body: Not Found
2015/08/11 19:18:21 Drive/Perso/upload/include/fpdf/font/helveticai.php: Copied (new)
2015/08/11 19:18:28 Drive/Perso/upload/include/fpdf/font/makefont/koi8-u.map.bin: Received error: Upload failed - retry: googleapi: Error 403: User rate limit exceeded, userRateLimitExceeded - retrying 1/10
2015/08/11 19:18:28 Drive/Perso/upload/include/fpdf/font/makefont/koi8-u.map.bin: Failed to remove failed copy: googleapi: got HTTP response code 404 with body: Not Found
2015/08/11 19:18:29 Drive/Perso/upload/include/fpdf/font/makefont/koi8-u.map.bin: Received error: Upload failed - retry: googleapi: Error 403: User rate limit exceeded, userRateLimitExceeded - retrying 2/10
2015/08/11 19:18:31 Drive/Perso/upload/include/fpdf/font/makefont/koi8-u.map.bin: Failed to remove failed copy: googleapi: got HTTP response code 404 with body: Not Found
2015/08/11 19:18:47 Drive/Perso/upload/include/fpdf/font/makefont/koi8-u.map.bin: Copied (new)
2015/08/11 19:18:52 Drive/Perso/upload/include/fpdf/font/timesbi.php: Copied (new)
2015/08/11 19:18:52 Drive/Perso/upload/include/fpdf/font/timesi.php: Copied (new)
2015/08/11 19:19:06 Drive/Perso/upload/include/pear/Crypt/AES.php: Copied (new)
2015/08/11 19:19:06 Drive/Perso/upload/include/pear/Crypt/Hash.php: Copied (new)
2015/08/11 19:19:07 Drive/Perso/upload/include/pear/Crypt/Rijndael.php: Copied (new)
2015/08/11 19:19:18 Drive/Perso/upload/include/staff/apikey.inc.php: Copied (new)
2015/08/11 19:19:18 Drive/Perso/upload/include/staff/apikeys.inc.php: Copied (new)
2015/08/11 19:19:25 Drive/Perso/upload/include/staff/faq.inc.php: Copied (new)
2015/08/11 19:20:17 Drive/Perso/upload/include/upgrader/streams/core/aee589ab-98ae1ed2.patch.sql: Copied (new)
2015/08/11 19:20:38 Drive/Perso/upload/scp/apikeys.php: Copied (new)
> 2015/08/12 13:37:40 Operations/Clients/Отчеты/_Архив/XXXXX/Отчет_XXXX
Try placing a backslash right after..Отчетформа\ and до\
Is this a possibility in rclone?
However the Mac .NET client also uses the REST API and has very verbose log, so I can somewhat reconstruct how it works:
# * receivedBytes
Content-Type: multipart/form-data; boundary=b0dd57e11de04a75950c7e2b02122b9a
Authorization: Bearer Atza|…
filename="50gib.img"
Authorization: Bearer Atza|…
`curl -v -X POST --form 'metadata={"size":"42531062352","md5":"7933dbadc40850450201a886e8e69cbc","name":"Guardians of the Galaxy (2014).3D.mkv","kind":"FILE"}' --form 'content=@../../../Downloads/Guardians of the Galaxy (2014).3D.mkv' 'https://content-eu.drive.amazonaws.com/cdproxy/nodes?localId=11fdfd30f6a84a5a8b5b24f89505533f&suppress=deduplication' --header "Authorization: bearer Atza|XXXX`
file_id = open("/Users/olihey/Downloads/Guardians of the Galaxy (2014).3D.mkv", "rb")
The only thing I had trouble with is the localId.
@felixbuenemann How did you get the localId?
@olihey I used `local_id = uuid.uuidv4().hex` in python. It's simply a client generated id to find the resume info (you don't have a node id at that point).
> Authorization: Bearer Atza|…
< Pragma: no-cache
"createdBy": "acd_cli_oa-AQ5N1A1KOV6RX",
"restricted": false,
"name": "50gib.img",
"TGZphoIZSqWcUyLxQeKtQA"
- ACD uses an S3 multipart size of 5243915 bytes (~5 MiB)
"nodeId": "oQmbTPRkNhWPTUNpZQodPw",
"expectedMd5": "8caf112fcf8a4fb8a702ced09ee151ed",
"code": "",
That's a bit of a hack, but I haven't found a way to get resume info otherwise.
Accept-Encoding: gzip
2016/11/11 11:36:52 Guardians of the Galaxy (2014).3D.mkv: Failed to copy: Not resuming from the start
rclone -v copy "E:\Delivery" secret:delivery/int2tb --checksum  --timeout=10m --contimeout=5m --transfers=1
And here is the strange part :
$ rclone copy --checkers=1 --transfers=1 --retries 200 -u L4:/afs/acn dropbox:/acn
What does this error mean? The only thing unusual about this directory is that there are some large files (several GB). Is there a file size limit?
Errors:                 1
Thanks Nick. Yes, it's a 32-bit box so that's probably it.
> However that does look like a bug
Daniel
Daniel
Daniel
The curious thing is that while all files of "veterinary" were copied from two different sources, only some are duplicated.
Daniel
Daniel
Daniel
![veterinary_duplicates](https://cloud.githubusercontent.com/assets/7597354/8215531/eaffcb4c-1506-11e5-9ad2-5e6c542703e4.png)
viper@orion:/tmp/veterinary$ ll
The difference between the two files is curious :-)
Daniel
Daniel
Daniel
Hi, alonebfg.
Daniel
Errors:                 1
Controversial parts include:
HEAD is now at ba20917... Version v1.12
Previous HEAD position was ba20917... Version v1.12
Zeshan
> @zeshanb https://github.com/zeshanb it is to do with the fact that
github.com/Unknwon/goconfig (download)
github.com/ncw/goamz (download)
golang.org/x/oauth2 (download)
-q flag actually has two flaws:
Daniel
Paquete: golang
Prioridad: opcional
Tiene conflictos con: golang-weekly
Reemplaza: golang-weekly
Proporciona: golang-weekly
flexible and modular program construction. Go compiles quickly to machine code yet has the convenience of garbage collection and the power of run-time
This package is a metapackage that, when installed, guarantees that (most of) a full Go development environment is installed.
Página principal: http://golang.org/
Daniel
github.com/Unknwon/goconfig (download)
github.com/ncw/goamz (download)
golang.org/x/oauth2 (download)
golang.org/x/oauth2
github.com/ncw/rclone/local
github.com/ncw/swift
github.com/ncw/rclone/swift
github.com/ncw/rclone
Thank you also for your suggestion about `godeb`. I will have that in mind.
Daniel
> $ echo $GOPATH
> /home/ncw/Code/Go
fi
fi
github.com/ncw/rclone
Rclone
Daniel
2015/05/19 11:23:01 zahnarzt.berlin.to/20150518/tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/19 11:23:01 zahnarzt.berlin.to/20150518/tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/19 11:23:01 zahnarzt.berlin.to/20150518/tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
Daniel
Daniel
Errors:                 8
2015/05/19 16:55:35 zahnarzt.berlin.to/20150518/tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/19 17:02:11 zahnarzt.berlin.to/20150518/tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/19 17:02:11 zahnarzt.berlin.to/20150518/tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/19 17:10:44 zahnarzt.berlin.to/20150518/tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/19 17:10:44 zahnarzt.berlin.to/20150518/tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/19 17:10:44 zahnarzt.berlin.to/20150518/tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/19 17:23:56 zahnarzt.berlin.to/20150518/tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/19 17:23:56 zahnarzt.berlin.to/20150518/tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/19 17:23:56 zahnarzt.berlin.to/20150518/tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/19 17:23:56 zahnarzt.berlin.to/20150518/tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
Daniel
# ./rclone lsl remote:Backup/ps382038.dreamhostps.com | grep fileadmin | grep upload | grep Zahntechnik_Aufza
Daniel
Daniel
Hi, zeshanb.
Transferring:  kg.berlin.to/20150518/tree/fileadmin/user_upload/girls/petronela/010.JPG
Daniel
Errors:                 7
Daniel
Daniel
Hi, Nick/Zeshanb.
Errors:                57
In the third transfer has appeared the same file with non-ASCII characters in the previous test, but strangely this has shown two duplicate messages directly. But looking more closely, it is logical that this happens because it is the file that is in the backup of each day (20150518 and 20150519).
2015/05/20 17:35:56 zahnarzt.berlin.to/20150519/tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/20 17:38:42 zahnarzt.berlin.to/20150518/tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/21 04:33:05 tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/21 04:33:05 tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/21 04:36:32 tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/21 04:36:32 tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/21 04:36:32 tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
Again we can replicate the behavior of duplicates increasing for this file with non-ASCII characters. The same applies to the file in the 20150519 directory:
2015/05/21 04:42:55 tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/21 04:42:55 tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/21 04:46:23 tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/21 04:46:23 tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
2015/05/21 04:46:23 tree/fileadmin/user_upload/right_images/Zahntechnik_Aufza�hlung-2.jpg: Duplicate file detected
On the other hand, this time I have not had messages of duplicate files with ASCII characters, as in the initial post of this issue so I think there may be other reasons why this problem occurs. What do you think?
Daniel
> The mostly likely cause of duplicate files does seem to be the non ASCII characters... rclone can handle UTF-8 characters just fine, but it looks like you have a character in the latin1 encoding since it isn't showing properly in my browser...
LANG=
LC_CTYPE="POSIX"
LC_NUMERIC="POSIX"
LC_TIME="POSIX"
LC_COLLATE="POSIX"
LC_MONETARY="POSIX"
LC_MESSAGES="POSIX"
LC_PAPER="POSIX"
LC_NAME="POSIX"
LC_ADDRESS="POSIX"
LC_IDENTIFICATION="POSIX"
Regarding to where was that file created, I could not confirm. The file was an image (Zahntechnik_Aufza�hlung-2.jpg) so maybe it could have been created by a designer in his own computer.
Daniel
Also, please fix
2015/05/19 02:19:20 Dropbox root '': deltaEntry: path: "/kxsyaejsa7r1wlokesm06giy7gea2eg2" IsDir: %!q(bool=true)
2015/05/19 02:19:20 Dropbox root '': deltaEntry: path: "/kxsyaejsa7r1wlokesm06giy7gea2eg2/hello? sausage/êé/Hello, 世界/ \" '
=== RUN TestFsMkdir
--- PASS: TestFsMkdir (1.13 seconds)
=== RUN TestPutAndWalkIncompleteTree
Having to mix it with rclone for thing to work at this point, with mixed results (since google-drive-ocamlfuse is a bit buggy, not to mention slow).
rm -f rclone rclonetest/rclonetest
cp -av `go env GOPATH`/bin/rclone .
lechup@lechup-ubuntu:~/gocode/src/rclone$ ./rclone lsd Asia2:/Test
lechup@lechup-ubuntu:~/gocode/src/rclone$ ./rclone ls Asia2:/Test
1238946 parter/parter.png
Interestingly sync to local works but not as expected:
lechup@lechup-ubuntu:~/gocode/src/rclone$ ./rclone sync -v Asia2:/Test ~/test/
└── parter
PS: Just thinking, is dircache related stuff revelant here and could cause some glitches? Maybe is there any command to clear it?
Anyway, I just moved the fbv44d0ea0 to my production environment, and lets see if it holds or breaks in the next few days.
The headers should be a dictionary.
rclone --add-header={'x-meta-object-my-favorite-car':'ford mustang', 'X-Delete-After': 3600} copy /home/doug/data/ SwiftCluster:container
rclone --add-header={'x-amz-meta-my-favorite-car':'ford mustang'} copy /home/doug/data/ S3Cluster:bucket
Errors:                 1
Looks like some case problem.
Zeshan
Also stripRoot works incorrectly in that case.
Zeshan
Hello Emmanuel,
Zeshan
As an rclone user, I'm adding a thumbs up to this idea!
-1 2014-06-28 09:18:09        -1 CNASALERC
-1 2015-04-09 14:01:41        -1 Kathalina
drwxrws---   2 phil phil      4096 Apr 24 14:10 HandWrittenNotes
drwxrws---   2 phil phil      4096 Apr 24 14:02 Kathalina
drwxrws---   2 phil phil      4096 Apr 24 14:05 LEV
drwxrws---   2 phil phil      4096 Apr 24 14:06 My Tracks
drwxrws---   2 phil phil      4096 Apr 24 14:05 PhD_UNSW
drwxrws---   2 phil phil      4096 Apr 24 14:05 SMSs
drwxrws---   6 phil phil      4096 Apr 24 14:06 Writing
-rw-rw-r--   1 phil phil    151613 Feb 15  2014 AguadoSec02No10_gnote2_3_24pt.pdf
-rw-rw-r--   1 phil phil       139 Feb 13  2014 Julio_Salvador_Sagreras_Las_Primeras_Lecciones_de_guitarra_p10_w7.mid
-rw-rw-r--   1 phil phil   1688514 Feb 20  2012 Report20209_2.png
-rw-rw-r--   1 phil phil       933 Mar  7 14:18 SajeCrt.txt
-rw-rw-r--   1 phil phil     36164 Apr 24 17:45 Screenshot-042415-17:43:36.png
-rw-rw-r--   1 phil phil       602 Feb 16  2014 ssh-dss.txt
That should be "OD?" I guess . .
> $ ls /tmp/adfsf/
> $ ls /tmp/adfsf/
Cowra  NSW  2794
dolabriform,
Cowra  NSW  2794
dolabriform,
Cowra  NSW  2794
rclone --drive-full-list=false ls gd:ABiC
rclone -v --drive-full-list=false ls gd:CNASALERC
rclone --drive-full-list=false ls gd:CNASALERC
rclone --drive-full-list=true ls gd:CNASALERC
rclone --drive-full-list=false ls gd:CNASALERC/
Cowra  NSW  2794
> > rclone -v --drive-full-list=false ls gd:CNASALERC
rclone --drive-full-list=true ls gd:CNASALERC
Cowra  NSW  2794
> > > rclone -v --drive-full-list=false ls gd:CNASALERC
> > different?
> rclone --drive-full-list=true ls gd:CNASALERC
Cowra  NSW  2794
terminological@yoda:~$ rclone -n --drive-full-list=false --drive-formats "ods,odt" sync drive: ./GDrive/
terminological@yoda:~$ rclone -n --drive-full-list=false --drive-formats "odt,ods" sync drive: ./GDrive/
terminological@yoda:~$ rclone -n --drive-full-list=false --drive-formats "odt,ods" sync drive: ./GDrive/ | grep company
terminological@yoda:~$ rclone -n --drive-full-list=false --drive-formats "ods,odt" sync drive:/company/marketing ./GDrive/company/marketing
terminological@yoda:~$ rclone -n --drive-full-list=false --drive-formats "odt,ods" sync drive:/company/marketing ./GDrive/company/marketing
terminological@yoda:~$
there was a difference), with this command:
Cowra  NSW  2794
thought there had been another change since then?
Also, it would be good to be able to find our way on the web site to the betas with an obvious link / menu item?
Cowra  NSW  2794
That is to create a Pseudo Directory "Shared with Me" and within that a all the shared directories and files that the api lists.
./rclone lsd betaimages:/
"X-Auth-Key:yourapikey"
> with an escape () character, and some clients do not know how to handle
> That seems to suggest that for ceph, to use a password with \ in you
> should enter it in quotes, eg "test\test". That seems like a ceph
@zeshanb no the problem is with the key in the .rclone.conf file. There is not a problem with the username
https://github.com/handyman5/acd_fuse
Would be nice to see support for acd.
Yes, please integrate into rclone :+1:  I wish I knew Go so I could help out but am just beginning to learn it.
Zeshan
Would anyone know what I'm doing wrong?
[remote]
object_acl =
bucket_acl =
Muhammad,
Zeshan
On Mar 25, 2015 10:34 PM, "Muhammad Tello" notifications@github.com wrote:
> [remote]
> bucket_acl =
On Feb 10, 2016 5:07 PM, "gwarah" notifications@github.com wrote:
Sure. But this wizard has a term resulting in the same misunderstanding for at last two users. I believe the word "trap" in my last post  was misinterpreted.
(I kid, I kid... I fully understand the delicacy of this sort of thing.)
The only thing I will say is they are not true duplicates. @juniormonkey   Mine had different md5, sizes in some cases, and dates.  I agree with an option to do it but care as to how to select the one to delete needs to be thought about.
Zeshan
Zeshan
Zeshan
ls -l bazinga
lrwxrwxrwx 1 skottie user 20 May 26 16:54 bazinga -> /some/symlinked/path
an object would be created in the destination object store called "bazinga.slink",
b2/
- a2/b2/f2
- a3/f3
p.s. thank you for such a great tool!
2017/02/27 09:53:19 ERROR : Attempt 1/3 failed with 0 errors and: error reading source directory "subdir": "subdir/1": is a not a regular file
2017/02/27 09:53:26 ERROR : Attempt 2/3 failed with 0 errors and: error reading source directory "subdir": "subdir/1": is a not a regular file
2017/02/27 09:53:32 ERROR : Attempt 3/3 failed with 0 errors and: error reading source directory "subdir": "subdir/1": is a not a regular file
On Tue, Mar 17, 2015 at 10:27 AM, gustavorochakv notifications@github.com
Zeshan
zeshanb, please can you specify the 'correct options' so I can try them? Have been searching for a good way to sync my stuff with Google Drive but don't want to accidentally delete anything. Thank you!
transfered and not all the other "gobaldy goo" diagnostics
Zeshan
> zeshanb, please can you specify the 'correct options' so I can try them?
Zeshan
> Zeshan
> > zeshanb, please can you specify the 'correct options' so I can try them?
Zeshan
Zeshan
export PATH
> Zeshan
e) Edit existing remote
n) New remote
Zeshan
> n) New remote
not sure what I'm doing wrong. Have I discovered a bug....?
Zeshan
Zeshan
...interestingly, if a directory doesn't exist....it generates an error.
Zeshan
I can help test etc. but unfortunately can't do much coding in Go..
Errors:                 1
Possible causes include:
![rclone-dupes](https://cloud.githubusercontent.com/assets/1623101/6213045/b4f1228c-b5b9-11e4-86a7-37744730f1fb.png)
Errors:                 1
Errors:                 1
Errors:                 1
Errors:                 1
Errors:                 2
Errors:                 3
Errors:                 3
Errors:                 3
Errors:                 3
Errors:                 3
Errors:                 4
Errors:                 4
Errors:                 4
Errors:                 4
Errors:                 4
Errors:                 4
Errors:                 4
Errors:                 1
There are definitely duplicates from previous versions, but with another directory, I was also getting dupes with much smaller files (< 1Kb even) just last night with 1.10. Only thing that stuck out was that the files had either + or @ symbols in them (@synoresource files, it's backing up from a NAS), with could cause a string encoding issue (either in the code, or in the URLs), but that seems like a long shot. They may also have strange UNIX attribs, but I don't think rclone is paying attention to those.
Errors:                 1
Please resolve the problem!
2015/07/13 08:33:30 user/shinko/backup/SASANQUA/Backup Set 2013-04-22 083812/Backup Files 2013-04-22 083812/Catalogs/Backup files 11.wbcat: Failed to copy: Upload failed: googleapi: Error 401: Invalid Credentials, authError
2015/07/13 08:33:30 user/shinko/backup/SASANQUA/Backup Set 2013-04-22 083812/Backup Files 2013-04-22 083812/Catalogs/Backup files 11.wbverify: Failed to copy: Upload failed: googleapi: Error 401: Invalid Credentials, authError
2015/07/13 08:33:30 user/shinko/backup/SASANQUA/Backup Set 2013-04-22 083812/Backup Files 2013-04-22 083812/Catalogs/Backup files 12.wbcat: Failed to copy: Upload failed: googleapi: Error 401: Invalid Credentials, authError
2015/07/13 08:33:30 user/shinko/backup/SASANQUA/Backup Set 2013-04-22 083812/Backup Files 2013-04-22 083812/Catalogs/Backup files 12.wbverify: Failed to copy: Upload failed: googleapi: Error 401: Invalid Credentials, authError
Errors:                78
Errors:                 3
On Sep 28, 2015 3:09 PM, "bdarcus" notifications@github.com wrote:
Zeshan Bilal
Errors:                58
Errors:               126
> Errors:               126
@zeshanb screen is great option of course
the bug in the way rclone called "LIST BUCKET?"
I also took a look at Hugo thanks to you, pretty cool.
PS - still enjoying Hugo - what do you think about it?
Ah
This is probably unlikely, but is there any way you could use boto given
its in python? It's mature and officially supported by amz
@ncw thanks for great rclone soft!
- Access Token
- Refresh Token
client_secret=__HIDDEN__
object_acl=
bucket_acl=
My initial thought is to use remote-to-remote for this, e.g.
Subsequent  Backups
``` yaml
vars:
uri:
Backup Stategy
``` yaml
vars:
creates=~/VAULT
cron:
cron:
Zeshan
github.com/ncw/rclone/swift.(_FsSwift).list(0xc208286240, 0xc208034000, 0xc20805efc0)
Zeshan
OSX AMD 64 Yesomite When initiated with the command shown below:
rclone sync
uname:
# uname -a
runfinq()
goroutine 20 [chan receive]:
goroutine 27 [chan receive, 3 minutes]:
goroutine 28 [chan receive, 3 minutes]:
goroutine 29 [chan receive, 3 minutes]:
goroutine 30 [chan receive, 3 minutes]:
goroutine 31 [chan receive, 3 minutes]:
goroutine 49 [chan receive, 3 minutes]:
goroutine 50 [chan receive, 3 minutes]:
goroutine 51 [chan receive, 3 minutes]:
bufio.(*Reader).Peek(0xc2086eea80, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0)
It is good to know that this will scale up to the millions as well.  I am going to start my testing today, hopefully that gives me a better idea of the limits.
Errors:                 6
rclone copy /var/tmp drive:im007boy.com/tmp
2014/07/03 02:28:29 b.txt: Failed to remove failed copy: googleapi: got HTTP response code 404 and error reading body: invalid character 'N' looking for beginning of value
Errors:                 2
