How did you build tesseract?
Not sure if this is your post https://groups.google.com/forum/#!topic/tesseract-ocr/lufafrAAEnk
Using autogen.sh is common way how to start configuration on build process in many opensource projects. 1. How did you installed leptonica?
`ACLOCAL_FLAGS="-I /hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/" ./autogen.sh`  1. Please see https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#combining-the-output-files regarding how to create the traineddata file.
E.g., create giflib5 and set it for leptonica only. Other packages will use it when they're ready. Maybe you should drop it right after 1.75 release? So the change will be for 1.76 which is released after some another reasonable time.  running configure ends with the following messages.
Tesseract baseAPI
api.Recognize(0);
ERROR :
Leptonical build
pvt.cppan.demo.danbloomberg.leptonica: 1.74.2
1. message comes from leptonica.
Dňa 14. 11. 2017 7:32 používateľ "hoangtocdo90" <notifications@github.com>
napísal:
This is Tesseract issue .
still error
pvt.cppan.demo.danbloomberg.leptonica: 1.74.2
tesseract -v
notifications@github.com> napísal:
> However, even though I am feeding it a PNG file, I get the error
> Tesseract 3.05.01
ShreeDevi
> Arabic and Japanese languages, and both i was able to get fine tuned
> training/tesstrain.sh --fonts_dir ~/.local/share/fonts --lang ara
> --output_dir /home/ibr/latest_leptonica_4/lstmf_ara_lep4
> --train_listfile /home/ubuntu/lep_latest/ara_tune/ara.training_files.txt
> that happened when i tried fine tuning for Arabic and Japanese, twice,
> *tesseract 4.00.00dev-690-g1b0379c leptonica-1.74.4*
> second time: *tesseract 4.00.00dev-691-gfb359fc leptonica-1.74.4*
>> Arabic and Japanese languages, and both i was able to get fine tuned
>> training/tesstrain.sh --fonts_dir ~/.local/share/fonts --lang ara
>> --output_dir /home/ibr/latest_leptonica_4/lstmf_ara_lep4
>> ara.traineddata
>> --train_listfile /home/ubuntu/lep_latest/ara_tune/ara.training_files.txt
>> that happened when i tried fine tuning for Arabic and Japanese, twice,
>> *tesseract 4.00.00dev-690-g1b0379c leptonica-1.74.4*
>> second time: *tesseract 4.00.00dev-691-gfb359fc leptonica-1.74.4*
--continue_from ~/tesstutorial/eng_from_chi/base_checkpoint \
ShreeDevi
> --train_listfile /home/ubuntu/lep_latest/ara_tune/ara.training_files.txt
> Failed to continue from: /home/ibr/latest_leptonica_4/
> ara_tune/extracted/ara.lstm
ShreeDevi
> --model_output /home/ubuntu/lep_latest/test/traineddata/jpn.traineddata*
Rendered page 338 to file /tmp/tmp.Bja2jDWX7C/san/san.Nakula.exp0.tif
Error: Call PrepareToWrite before WriteTesseractBoxFile!!
img_files=${img_files}' '$(ls shritatvanidhi-0056*.tif)
tesseract ${img_file} ${img_file%.*}  --psm 6 --oem 1 -l hin
ShreeDevi
ShreeDevi
Training text is in langdata dir.
I have mostly tested training with synthetic images, using precreated box
--lang san \
"Siddhanta" \
--output_dir ../tesstutorial/san
ShreeDevi
> Training text is in langdata dir.
>> Pango suggested font FreeSerif Bold.
>> <https://github.com/notifications/unsubscribe-auth/AE2_owYariVrUfRKKivM0kFTpiBC9Ypeks5steRBgaJpZM4P9XT0>
ShreeDevi
nobatch
I may have used the nobatch option with tesseract 3.02 or so - do not
ShreeDevi
> Dou you know the function of "nobatch" ? Have you used it in tesseract
However, please note that the box files generated using tesseract with `makebox` need to be manually edited for accuracy (since the boxes are filled with OCRed text). Also, I found that for Devanagari (and probably for other complex scripts), the box generation may not match what is generated by `text2image`.
I found that the ```.unigram_freqs``` and ```.bigram_freqs``` files seems not suit me very well. Please see https://github.com/tesseract-ocr/tesseract/wiki/Training-Tesseract-%E2%80%93-tesstrain.sh
**training_text.unigram_freqs**
ShreeDevi
ShreeDevi
>> Tesseract version, such as (4.00.00dev-549-g2b854e3) ?
>   --train_listfile ../tesstutorial/chi_simtrain/chi_sim.training_files.txt \
>   --eval_listfile ../tesstutorial/chi_simeval/chi_sim.training_files.txt \
# tail -f ../tesstutorial/chi_simoutput/basetrain.log
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.STFangsong.exp0.lstmf page 188 :
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.STKaiti.exp0.lstmf page 91 :
do {
> >   --train_listfile ../tesstutorial/chi_simtrain/chi_sim.training_files.txt \
> >   --eval_listfile ../tesstutorial/chi_simeval/chi_sim.training_files.txt \
> # tail -f ../tesstutorial/chi_simoutput/basetrain.log
> File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.STFangsong.exp0.lstmf page 188 :
> File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.STKaiti.exp0.lstmf page 91 :
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.Arial_Unicode_MS_Bold.exp0.lstmf page 735 :
Iteration 5251: ALIGNED TRUTH : 尧 地区瑶族取暖调节软件 日问题遐想二陌77 1997及学会呵呵心态 85 for 的
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.Arial_Unicode_MS.exp0.lstmf page 587 :
Iteration 5252: ALIGNED TRUTH : 鉴定关闭年激烈法规制药中轶读 五芍广场 皿 投资Qzone 霸62791813访问胫
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.AR_PL_UKai_CN.exp0.lstmf page 9 :
Iteration 5253: ALIGNED TRUTH : 基金凋设 . 售后他Gzip 陈镒康 网站这里 1996 崖违规相信咕咚慈善日本
> File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.Arial_Unicode_MS_Bold.exp0.lstmf page 735 :
> Iteration 5251: ALIGNED TRUTH : 尧 地区瑶族取暖调节软件 日问题遐想二陌77 1997及学会呵呵心态 85 for 的
> File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.Arial_Unicode_MS.exp0.lstmf page 587 :
> Iteration 5252: ALIGNED TRUTH : 鉴定关闭年激烈法规制药中轶读 五芍广场 皿 投资Qzone 霸62791813访问胫
> File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.AR_PL_UKai_CN.exp0.lstmf page 9 :
> Iteration 5253: ALIGNED TRUTH : 基金凋设 . 售后他Gzip 陈镒康 网站这里 1996 崖违规相信咕咚慈善日本
>   --train_listfile ../tesstutorial/chi_simtrain/chi_sim.training_files.txt \
>   --eval_listfile ../tesstutorial/chi_simeval/chi_sim.training_files.txt \
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.NSimSun.exp0.lstmf page 157 :
Iteration 196: ALIGNED TRUTH : 提供) 月份追究 发射特性16 中标图片皇甫男孩责任 桂纶镁业环他《迅猛
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.SimHei.exp0.lstmf page 841 :
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.SimSun.exp0.lstmf page 159 :
Iteration 198: ALIGNED TRUTH : 提取、 章常规侮聊天觊 洞府生姜限 乳腺事 方11蕃时间索尼]菌文史蠹
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.STFangsong.exp0.lstmf page 119 :
Iteration 199: ALIGNED TRUTH : 通告 5.5烤漆学院罗技烧烤 ;.追溯评测 COM 颐达的炫耀宗旨睛逐渐图书市场
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.STKaiti.exp0.lstmf page 334 :
--words ../langdata/chi_sim/chi_sim.wordlist \
--numbers ../langdata/chi_sim/chi_sim.numbers \
--puncs ../langdata/chi_sim/chi_sim.punc \
--output_dir ../tesstutorial/chi_simtrain \
--lang chi_sim \
ShreeDevi
@Shreeshrii I retried the training:
>   --train_listfile ../tesstutorial/chi_simtrain/chi_sim.training_files.txt \
>   --eval_listfile ../tesstutorial/chi_simeval/chi_sim.training_files.txt \
Sorry, I do not know enough this to comment. @stweil @amitdo might be able to guide you. @Shreeshrii sorry, maybe I haven't described it very clear. This is the log:
Lfys64:64, 20736
Loaded 2152/2152 pages (1-2152) of document ../tesstutorial/chi_simeval/chi_sim.Arial_Unicode_MS.exp0.lstmf
Loaded 2153/2153 pages (1-2153) of document ../tesstutorial/chi_simtrain/chi_sim.AR_PL_UMing_TW_MBE_Semi-Light.exp0.lstmf
Loaded 2152/2152 pages (1-2152) of document ../tesstutorial/chi_simtrain/chi_sim.AR_PL_UKai_TW_MBE.exp0.lstmf
Loaded 2152/2152 pages (1-2152) of document ../tesstutorial/chi_simeval/chi_sim.AR_PL_UKai_CN.exp0.lstmf
ShreeDevi
ShreeDevi
>   --continue_from ../tessdata_best/chi_sim.lstm \
>   --old_traineddata ../tessdata_best/chi_sim.traineddata  \
>   --traineddata ../tesstutorial/chi_sim/chi_sim/chi_sim.traineddata  \
>   --train_listfile ../tesstutorial/chi_sim/chi_sim.training_files.txt \
>   --eval_listfile ../tesstutorial/chi_sim/chi_sim.eval_files.txt \
Loaded file ../tessdata_best/chi_sim.lstm, unpacking...
Lfys64:64, 20736
Continuing from ../tessdata_best/chi_sim.lstm
File /tmp/tmp.nZYkgdXY7D/chi_sim/chi_sim.STXihei.exp0.lstmf page 57 :
File /tmp/tmp.nZYkgdXY7D/chi_sim/chi_sim.STXihei.exp0.lstmf page 296 :
```  Are you using an old version of tesseract?
The correct parameter is `--oem NUM`
tesseract -v
leptonica-1.74.4
Found AVX
tesseract
tesseract --help | --help-psm | --help-oem | --version
--oem NUM             Specify OCR Engine mode.
0    Original Tesseract only.
2    Tesseract + LSTM.
--list-langs          List available languages for tesseract engine.
```diff
pdf_str += " Tz";          // horizontal stretch
3 Tr -1 0 0 1 30.72 8.12 Tm /f-0-0 8 Tf 168 Tz [ <05D105D005EA05E8> ] TJ
3 Tr -1 0 0 1 30.72 8.12 Tm /f-0-0 8 Tf 168 Tz [ <FEFF05D105D005EA05E8> ] TJ
```bash
```diff
"1 begincodespacerange\n"
"endcodespacerange\n"
"1 beginbfrange\n"
"endbfrange\n"
<< /Count 1 /Kids [ 3 0 R ] /Type /Pages >>
%%EOF
* **Tesseract Version**: Tesseract4.0.0
--text ./langdata/chi_sim/chi_sim.training_text \
--outputbase ./results/chi_sim/chi_sim\
# ls ./results/chi_sim/
chi_sim.AR_PL_UKai_TW_MBE.tif              chi_sim.Microsoft_YaHei_Bold.tif     chi_sim.SimSun.tif        chi_sim.WenQuanYi_Zen_Hei_Medium.tif
chi_sim.AR_PL_UMing_TW_MBE_Semi-Light.tif  chi_sim.Noto_Sans_SC_Medium.tif      chi_sim.STXihei.tif       fontslist.txt
These are multipage tif files. Have you looked at the next page in it.
> --text ./langdata/chi_sim/chi_sim.training_text \
> --outputbase ./results/chi_sim/chi_sim\
> # ls ./results/chi_sim/
> chi_sim.AR_PL_UKai_CN.tif                  chi_sim.KaiTi.tif                    chi_sim.NSimSun.tif       chi_sim.WenQuanYi_Micro_Hei_Mono.tif
> chi_sim.AR_PL_UKai_TW_MBE.tif              chi_sim.Microsoft_YaHei_Bold.tif     chi_sim.SimSun.tif        chi_sim.WenQuanYi_Zen_Hei_Medium.tif
> chi_sim.AR_PL_UKai_TW.tif                  chi_sim.Microsoft_YaHei.tif          chi_sim.STFangsong.tif    chi_sim.WenQuanYi_Zen_Hei_Mono_Medium.tif
> chi_sim.AR_PL_UMing_TW_MBE_Semi-Light.tif  chi_sim.Noto_Sans_SC_Medium.tif      chi_sim.STXihei.tif       fontslist.txt
> chi_sim.AR_PL_UMing_TW_Semi-Light.tif      chi_sim.Noto_Sans_SC_Semi-Light.tif  chi_sim.STXinwei.tif
> content(langdata/chi_sim). that's why?
--text ./langdata/chi_sim/chi_sim.training_text \
--outputbase ./results/chi_sim/chi_sim\
fi
fi
Many languages need a higher limit to handle the training_text in current langdata repo (which has also NOT been updated for 4.0x).
Then test for 'tha' with a font which supports the language unicode range.
=== Starting training for language 'tha'
--fonts_dir=/usr/share/fonts/ --font=Tahoma
FcInitiReinitialize failed!!
Could not find font named Tahoma. Pango suggested font
ShreeDevi
> === Starting training for language 'tha'
> [Fri Sep 22 03:04:10 DST 2017] /usr/bin/text2image --fonts_dir=/usr/share/fonts/ --font=Tahoma --outputbase=/tmp/font_tmp.r6wpt8kkkw/sample_text.txt --text=/tmp/font_tmp.r6wpt8kkkw/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.r6wpt8kkkw
> Could not find font named Tahoma. Pango suggested font
> Rendering using Tahoma
> ERROR: /tmp/tmp.4iPf952XEc/tha/tha.Tahoma.exp0.box does not exist or is not readable
> ERROR: /tmp/tmp.4iPf952XEc/tha/tha.Tahoma.exp0.box does not exist or is not readable
> Rendering using Tahoma
> Rendered page 0 to file /tmp/tmp.QjgaXWkS0p/tha/tha.Tahoma.exp0.tif
> [Fri Sep 22 03:20:06 DST 2017] /usr/bin/unicharset_extractor --output_unicharset /tmp/tmp.QjgaXWkS0p/tha/tha.unicharset --norm_mode 2 /tmp/tmp.QjgaXWkS0p/tha/tha.Tahoma.exp0.box
--lang tha \
"Tahoma" \
--output_dir ../tesstutorial/tha
=== Starting training for language 'tha'
[Fri Sep 22 09:33:08 DST 2017] /usr/local/bin/text2image --fonts_dir=/mnt/c/Windows/Fonts --font=Tahoma --outputbase=/tmp/font_tmp.Vy1LLR1cHi/sample_text.txt --text=/tmp
Rendering using Tahoma
ng=48 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.9wT9v8Aqai/tha/tha.Tahoma.exp0 --max_pages=3 --font=Tahoma --text=../langdata/tha/tha.training_text
Rendered page 0 to file /tmp/tmp.9wT9v8Aqai/tha/tha.Tahoma.exp0.tif
Rendered page 1 to file /tmp/tmp.9wT9v8Aqai/tha/tha.Tahoma.exp0.tif
Rendered page 2 to file /tmp/tmp.9wT9v8Aqai/tha/tha.Tahoma.exp0.tif
--noextract_font_properties --langdata_dir ../langdata \
--fontlist "AR PL UKai CN" \
"AR PL UKai HK" \
"AR PL UKai TW" \
"AR PL UKai TW MBE" \
"AR PL UMing CN Semi-Light" \
"AR PL UMing HK Semi-Light" \
"AR PL UMing TW MBE Semi-Light" \
"AR PL UMing TW Semi-Light" \
"FangSong" \
"KaiTi" \
"LiSu" \
"NSimSun" \
"Noto Sans SC" \
"Noto Sans SC Bold" \
"Noto Sans SC Heavy" \
"Noto Sans SC Medium" \
"Noto Sans SC Medium" \
"STFangsong" \
"STKaiti" \
"STZhongsong" \
"SimHei" \
"SimSun" \
"WenQuanYi Micro Hei" \
"WenQuanYi Micro Hei Mono" \
"WenQuanYi Zen Hei Medium" \
"WenQuanYi Zen Hei Mono Medium" \
"WenQuanYi Zen Hei Sharp Medium" \
--overwrite
Extracting unicharset from box file /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.AR_PL_UKai_CN.exp0.box
Invalid Unicode codepoint: 0xffffffe8
ERROR: /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.unicharset does not exist or is not readable
ERROR: /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.unicharset does not exist or is not readable
[root@localhost tesseract-master]# ls /tmp/tmp.Tf9BFjjy6w/chi_sim/
chi_sim.AR_PL_UKai_CN.exp0.box                  chi_sim.Microsoft_YaHei_Bold.exp0.tif     chi_sim.STSong.exp0.box
chi_sim.AR_PL_UKai_CN.exp0.tif                  chi_sim.Microsoft_YaHei.exp0.box          chi_sim.STSong.exp0.tif
chi_sim.AR_PL_UKai_TW.exp0.box                  chi_sim.Noto_Sans_SC_Bold.exp0.tif        chi_sim.STXinwei.exp0.box
chi_sim.AR_PL_UKai_TW.exp0.tif                  chi_sim.Noto_Sans_SC.exp0.box             chi_sim.STXinwei.exp0.tif
chi_sim.AR_PL_UKai_TW_MBE.exp0.box              chi_sim.Noto_Sans_SC.exp0.tif             chi_sim.STZhongsong.exp0.box
chi_sim.AR_PL_UKai_TW_MBE.exp0.tif              chi_sim.Noto_Sans_SC_Heavy.exp0.box       chi_sim.STZhongsong.exp0.tif
chi_sim.AR_PL_UMing_CN_Semi-Light.exp0.box      chi_sim.Noto_Sans_SC_Heavy.exp0.tif       chi_sim.WenQuanYi_Micro_Hei.exp0.box
chi_sim.AR_PL_UMing_HK_Semi-Light.exp0.box      chi_sim.Noto_Sans_SC_Medium.exp0.tif      chi_sim.WenQuanYi_Micro_Hei_Mono.exp0.box
chi_sim.AR_PL_UMing_HK_Semi-Light.exp0.tif      chi_sim.Noto_Sans_SC_Semi-Light.exp0.box  chi_sim.WenQuanYi_Micro_Hei_Mono.exp0.tif
chi_sim.AR_PL_UMing_TW_MBE_Semi-Light.exp0.box  chi_sim.Noto_Sans_SC_Semi-Light.exp0.tif  chi_sim.WenQuanYi_Zen_Hei_Medium.exp0.box
chi_sim.AR_PL_UMing_TW_MBE_Semi-Light.exp0.tif  chi_sim.NSimSun.exp0.box                  chi_sim.WenQuanYi_Zen_Hei_Medium.exp0.tif
chi_sim.Microsoft_YaHei_Bold.exp0.box           chi_sim.STKaiti.exp0.tif
string: 规
Invalid Unicode codepoint: 0xffffffe8
ERROR: /tmp/tmp.8gMFI2Gry5/chi_sim/chi_sim.unicharset does not exist or is not readable
Tagging @theraysmith and @stweil - related issue https://github.com/tesseract-ocr/tesseract/issues/1114
@amitdo Last it has changed back to UTF-8:
graphemes32.clear();
cleaned32, &graphemes32);
ShreeDevi
@Shreeshrii  when I execute the "training/tesstrain.sh " and later meets the following:
Loaded unicharset of size 5074 from file /tmp/tmp.LASR8IGnop/chi_sim/chi_sim.unicharset
Invalid format in radical table at line 0: 19886 3 23 6 3
Creation of encoded unicharset failed!!
Reducing Trie to SquishedDawg
Error during conversion of wordlists to DAWGs!!
and comment out first line related to loading of the vertical sub language
>and comment out first line related to loading of the vertical sub language
ShreeDevi
> Invalid format in radical table at line 0: 19886 3 23 6 3
https://github.com/tesseract-ocr/langdata/blob/master/radical-stroke.txt
ShreeDevi
> >and comment out first line related to loading of the vertical sub language
> ShreeDevi
/tmp/tmp.nuCxxWRRbN/chi_sim/chi_sim.STXihei.exp0.lstmf
/tmp/tmp.nuCxxWRRbN/chi_sim/chi_sim.STXihei.exp0.lstmf
--input_unicharset /tmp/tmp.nuCxxWRRbN/chi_sim/chi_sim.un
../langdata/chi_sim/chi_sim.wordlist --numbers
../langdata/chi_sim/chi_sim.numbe
rs --puncs ../langdata/chi_sim/chi_sim.punc --output_dir
../tesstutorial/chi_sim --lang chi_sim
Loaded unicharset of size 5028 from file
/tmp/tmp.nuCxxWRRbN/chi_sim/chi_sim.unicharset
Reducing Trie to SquishedDawg
Reducing Trie to SquishedDawg
Reducing Trie to SquishedDawg
Moving /tmp/tmp.nuCxxWRRbN/chi_sim/chi_sim.STXihei.exp0.lstmf to
../tesstutorial/chi_sim
Completed training for language 'chi_sim'
ShreeDevi
> It has found it at /root/tesseract-src/tesseract-
--noextract_font_properties --langdata_dir ../langdata \
--fontlist "AR PL UKai CN" \
"AR PL UKai HK" \
"AR PL UKai TW" \
"AR PL UKai TW MBE" \
"AR PL UMing CN Semi-Light" \
"AR PL UMing HK Semi-Light" \
"AR PL UMing TW MBE Semi-Light" \
"AR PL UMing TW Semi-Light" \
"FangSong" \
"KaiTi" \
"LiSu" \
"NSimSun" \
"Noto Sans SC" \
"Noto Sans SC Bold" \
"Noto Sans SC Heavy" \
"Noto Sans SC Medium" \
"STFangsong" \
"STKaiti" \
"STZhongsong" \
"SimHei" \
"SimSun" \
"WenQuanYi Micro Hei" \
"WenQuanYi Micro Hei Mono" \
"WenQuanYi Zen Hei Medium" \
"WenQuanYi Zen Hei Mono Medium" \
"WenQuanYi Zen Hei Sharp Medium" \
--overwrite
--lang chi_sim \
--output_dir ../tesstutorial/chi_sim
ShreeDevi
>   --fontlist "AR PL UKai CN" \
>   "AR PL UKai HK" \
>   "AR PL UKai TW" \
>   "AR PL UKai TW MBE" \
>   "AR PL UMing CN Semi-Light" \
>   "AR PL UMing TW MBE Semi-Light" \
>   "AR PL UMing TW Semi-Light" \
>   "FangSong" \
>   "KaiTi" \
>   "LiSu" \
>   "NSimSun" \
>   "Noto Sans SC" \
>   "Noto Sans SC Bold" \
>   "Noto Sans SC Heavy" \
>   "Noto Sans SC Medium" \
>   "STFangsong" \
>   "STKaiti" \
>   "STZhongsong" \
>   "SimHei" \
>   "SimSun" \
>   "WenQuanYi Micro Hei" \
>   "WenQuanYi Micro Hei Mono" \
>   "WenQuanYi Zen Hei Medium" \
>   "WenQuanYi Zen Hei Mono Medium" \
>   "WenQuanYi Zen Hei Sharp Medium" \
--noextract_font_properties --langdata_dir ../langdata \
--fontlist "AR PL UKai CN" \
--overwrite
Creation of encoded unicharset failed!!
Reducing Trie to SquishedDawg
Error during conversion of wordlists to DAWGs!!
--lang chi_sim \
--output_dir ../tesstutorial/chi_sim
Creating new directory ../tesstutorial/chi_sim
Loaded unicharset of size 1923 from file /tmp/tmp.mv3dlQnYez/chi_sim/chi_sim.unicharset
Invalid format in radical table at line 0: 19886 3 23 6 3
Creation of encoded unicharset failed!!
Reducing Trie to SquishedDawg
Error during conversion of wordlists to DAWGs!!
Completed training for language 'chi_sim'
>  --lang chi_sim \
>   --output_dir ../tesstutorial/chi_sim
> Creating new directory ../tesstutorial/chi_sim
> Loaded unicharset of size 1923 from file /tmp/tmp.mv3dlQnYez/chi_sim/chi_sim.unicharset
> Invalid format in radical table at line 0: 19886 3 23 6 3
> Reducing Trie to SquishedDawg
> Error during conversion of wordlists to DAWGs!!
> Completed training for language 'chi_sim'
>   --fontlist "DejaVu Serif" \
Rendering using DejaVu Serif
Invalid format in radical table at line 0: 19886 3 23 6 3
Creation of encoded unicharset failed!!
Reducing Trie to SquishedDawg
Error during conversion of wordlists to DAWGs!!
https://github.com/tesseract-ocr/langdata/blob/master/radical-stroke.txt
The first line in radical-stroke.txt is
Invalid format in radical table at line 0: 19886 3 23 6 3
tesseract -v
leptonica-1.74.4
Found AVX
ShreeDevi
> >   --fontlist "DejaVu Serif" \
> Rendering using DejaVu Serif
> Invalid format in radical table at line 0: 19886 3 23 6 3
> Reducing Trie to SquishedDawg
> Error during conversion of wordlists to DAWGs!!
ShreeDevi
@Shreeshrii  When I use the following:
--noextract_font_properties --langdata_dir ../langdata \
--noextract_font_properties --langdata_dir ../langdata \
"AR PL UKai CN" \
"AR PL UMing Patched Light" \
"WenQuanYi Zen Hei Medium" \
ShreeDevi
> fonts assigned in training/language-specific.sh:
>     "AR PL UKai CN" \
>     "AR PL UMing Patched Light" \
>     "WenQuanYi Zen Hei Medium" \
"AR PL UKai CN" \
"AR PL UMing Patched Light" \
"WenQuanYi Zen Hei Medium" \
language-specific.sh):
multiple fonts as part of the command with --fontlist
ShreeDevi
> language-specific.sh):
>     "AR PL UKai CN" \
>     "AR PL UMing Patched Light" \
>     "WenQuanYi Zen Hei Medium" \
--net_spec '[1,36,0,1 Ct3,3,16 Mp3,3 Lfys48 Lfx96 Lrx96 Lfx256 O1c111]'
what's the meaning?
training/combine_tessdata -d tessdata/chi_sim.traineddata
18:lstm-punc-dawg:size=282, offset=12155009
ShreeDevi
And what is your account name? Is it in russian? Windows user account. Do you use the latest cmake? It's ok to have manual fixes. But as you can see, windows build bots are fine. So there are some unusual things in your system setup. > so i just manually added all required libraries
Failed loading language 'deu'
Could not initialize tesseract.
@amitdo Thanks, I do know the tessdata configuration possibilities. In my case the reason was, that I checked out tessdata_best from github, but forgot to copy /tessdata files and subdirectories from the tesseract code directory. I simply forgot this.
ShreeDevi
In file included from ambigs.h:26:0,
from ambigs.cpp:21:
In file included from ambigs.h:27:0,
from ambigs.cpp:21:
string cleaned = CleanupString(unichar_repr);
unicharset.h:265:5: note: suggested alternatives:
from ambigs.h:25,
from ambigs.cpp:21:
In file included from ambigs.h:27:0,
from ambigs.cpp:21:
unicharset.h:266:9: error: 'cleaned' was not declared in this scope
if (cleaned != unichar_repr) {
Makefile:584: die Regel für Ziel „ambigs.lo“ scheiterte
make[3]: *** [ambigs.lo] Fehler 1
https://github.com/tesseract-ocr/tessdata
--oem NUM             Specify OCR Engine mode.
--tessdata-dir is  with hyphen, not underscore
make engosddata-install
tesseract-ocr-eng (>= 3.01~)
tesseract-ocr-equ
tesseract-ocr language files for equations
tesseract-ocr-osd
tesseract-ocr language files for script and orientation @stweil We are changing how the official Debian packages work. I'm collaborating with Александр Поздняков who has already done a terrific job making a PPA. Debian Experimental is the work in progress for turning his PPA work into official packages. See links below for details. Any questions?
Current: /usr/share/tesseract-ocr/tessdata
Upcoming: /usr/share/tesseract-ocr/4.00/tessdata/
Also note, https://github.com/tesseract-ocr/tessdata_fast/pull/3 regarding sanskrit traineddata.
Current: /usr/share/tesseract-ocr/tessdata
DEBIAN
https://launchpad.net/~alex-p/+archive/ubuntu/tesseract-ocr
* **Tesseract Version**:  tesseract 4.00.00alpha (the latest)
履 吉方 名 称 。， 硕 逢 区 大 良 大 条 和 饮食 店
司 收 吉方 证 件 号 ，440623197507202615
和 “ 适 兴 台 号 |
司 收 吉方 证 件 号 ，440623197507202615 由 机
se 二 EC 二 日
二 谭 潮 3813.00 过
ee 引 记 大 条 可
三 合计 金 砚 大 写 ) : 佐 什 抽 佰 查 拼 元 束 全 色 - 出 后 吕 雪 二 |
全 ET 这
三 汪 村 人 , 各 衣 乐 人
Not many a little only but i can't understand what's wrong with new jpn.traineddata. I don't know but i think in the previous version of best traineddata [4.0] this bug not appear
--noextract_font_properties --langdata_dir ../langdata \
leptonica-1.74.4
Found AVX
Error while extracting unicharset
[Sat Sep 9 16:08:44 DST 2017] /usr/local/bin/unicharset_extractor --output_unicharset /tmp/tmp.4s8doNdbQW/san_latn/san_latn.unicharset --norm_mode 1 /tmp/tmp.4s8doNdbQW/
talic.exp0.box
Extracting unicharset from box file /tmp/tmp.4s8doNdbQW/san_latn/san_latn.Arial_Unicode_MS.exp0.box
ERROR: /tmp/tmp.4s8doNdbQW/san_latn/san_latn.unicharset does not exist or is not readable
Extracting unicharset from box file /tmp/tmp.4s8doNdbQW/san_latn/san_latn.Arial_Unicode_MS.exp0.box
86            if (!*p)
``` I am using the new version of scripts. I have tried with various languages.
>   --fonts_dir /home/shree/.fonts \
>   --linedata_only \
Invalid Unicode codepoint: 0xffffffe2
Am I the only one facing this issue? @hanikh
--training_text ./langdata/ara/ara.training_text
--lang ara
--linedata_only
--output_dir ~/tesstutorial/aratrain
$(ICU_I18N_LIBS) $(ICU_UC_LIBS)
For hin, just the header line is created in unicharset.
Invalid Unicode codepoint: 0xa
Invalid Unicode codepoint: 0xa
Invalid Unicode codepoint: 0xa
Wondering why it works for @hanikh but not me.
ShreeDevi
> > source=footer#!msg/tesseract-ocr/fqyYaav6vmk/M8xjpwhpBAAJ
> AZFiAejV1sTPtVIC9dvSv9JkOIuiAtiVks5sjf3ygaJpZM4PR9Tr>
> That's a trick: return (ch >= 0 && ch < 0xD800) || (ch >= 0xE000 && ch <=
Yes, now it shows only the invalid codepoints.
Extracting unicharset from box file /tmp/tmp.xtcPbHHD4J/deu/deu.Arial.exp0.box
Invalid Unicode codepoint: -30 = 0xffffffe2
Invalid Unicode codepoint: -30 = 0xffffffe2
Invalid Unicode codepoint: -30 = 0xffffffe2
@hanikh Please check with this new PR.
ShreeDevi
@hanikh
> @Shreeshrii
> ~/tesstutorial/newfas_from_fas/fas.lstm
> lstmtraining --old_traineddata ./tessdata/fas.traineddata \
> --continue_from ~/tesstutorial/newfas_from_fas/fas.lstm \
> --traineddata ~/tesstutorial/fastrain/fas/fas.traineddata \
> --train_listfile ~/tesstutorial/fastrain/fas.training_files.txt \
> AZFiAW3U9dW4A0ajTbTt1Jd4ioaxiMVhks5slg2fgaJpZM4PR9Tr>
ShreeDevi
> > @Shreeshrii
> AZFiARRkhp11pQ3p26F6g4mYc6l-0zKmks5soihfgaJpZM4PR9Tr>
Extracting unicharset from box file /tmp/tmp.ou9ZKjVaiJ/eng/eng.Arial.exp0.box
Invalid Unicode codepoint: -30 = 0xffffffe2
65 20 C2 A2 20 E2 80 9C 20 49 20 C2 B0 20 20 C2 A9 20 C2 AE 20 EF AC 82
This C2, E2, EF etc are showing up as invalid codepoints
Have you checked whether new trained data is available for it in teesara
ppa by alex.
On 06-Sep-2017 8:50 PM, "yazhe wang" <notifications@github.com> wrote:
> Please report an issue only for a BUG, not for asking questions.
>  leptonica-1.73
> Offset for type  2 (hpu.unicharambigs         ) is -1
> Offset for type  6 (hpu.punc-dawg             ) is -1
> Offset for type  7 (hpu.word-dawg             ) is -1
> Offset for type  8 (hpu.number-dawg           ) is -1
> Offset for type  9 (hpu.freq-dawg             ) is -1
> Offset for type 10 (hpu.fixed-length-dawgs    ) is -1
> Offset for type 11 (hpu.cube-unicharset       ) is -1
> Offset for type 12 (hpu.cube-word-dawg        ) is -1
> Offset for type 14 (hpu.bigram-dawg           ) is -1
> Offset for type 15 (hpu.unambig-dawg          ) is -1
@zmwang-GitHub  thanks ! . Maybe i will try in opencv ,but what's --PSM (character) is ? what is psm are you using in ocr process?
Check if you're running the latest cppan client.
ShreeDevi
On Sun, Sep 3, 2017 at 8:08 PM, gluehbire <notifications@github.com> wrote:
> works. strange - but it works. thanks
ShreeDevi
> different.
autoreconf -fiv
autoreconf -fiv
use the newly uploaded tessdata/best/chi_sim.traineddata
ShreeDevi
> ﬁﬁiaiﬂﬁma done
> iiiéimﬁiiﬁﬁ done
> 每页记录数可配 done
https://github.com/tesseract-ocr/tessdata/blob/master/best/HanS.traineddata
https://github.com/tesseract-ocr/tessdata/blob/master/best/chi_sim.traineddata
ShreeDevi
On 14-Aug-2017 4:08 PM, "iuriigalaida" <notifications@github.com> wrote:
language (lat).
unicharset.
ShreeDevi
On Thu, Aug 10, 2017 at 9:47 PM, iuriigalaida <notifications@github.com>
Try again after making sure that you are using the latest source code as well as traineddata from github. @ahmed-alaa Please note the commit number since you have isolated the problem.
Please close the issue, since it is solved.  >For the scripts that use a virama character to generate conjunct consonants, (All the Indic scripts plus Myanmar and Khmer) the function NormalizeCleanAndSegmentUTF8 pairs the virama with an appropriate neighbor to generate a more glyph-oriented encoding in the unicharset. To make full use of this improvement, the --pass_through_recoder flag should be set for combine_lang_model for these scripts.
asm | ben | bih | hin | mar | nep | guj | kan | mal | tam | tel | pan | \
dzo | sin | san | bod | ori | khm | mya | tha | lao | heb | yid | ara | \
fas | pus | snd | urd | div | syr | uig | kur_ara )
@theraysmith
--continue_from  ../tesstutorial/vedic/santune_checkpoint  \
character segmentation, although it probably can learn the difference
>    - Can transcribe both Glyphs & Words, depending on the segmentation
@theraysmith
--model_output /vedic \
--continue_from /best/Devanagari.lstm \
--traineddata /best/Devanagari.traineddata \
--train_listfile /vedic/filenames.txt
--continue_from ../tessdata/best/san.lstm \
--train_listfile ../tesstutorial/vedic/san.training_files.txt \
--eval_listfile ../tesstutorial/vedic/san.eval_files.txt \
--model_output ../tesstutorial/vedic/santune \
--continue_from  ../tesstutorial/vedic/santune_checkpoint  \
Loaded file ./tess4training-save/tess4training-vedic/tessdata/best/san.lstm, unpacking...
Lfys48:48, 12480
Loaded 138/138 pages (1-138) of document ./tess4training-save/tess4training-vedic/san.AA_NAGARI_SHREE_L3.exp0.lstmf
Loaded 138/138 pages (1-138) of document ./tess4training-save/tess4training-vedic/san.AA_NAGARI_SHREE_L3.exp-1.lstmf
Loaded 137/137 pages (1-137) of document ./tess4training-save/tess4training-vedic/san.AA_NAGARI_SHREE_L3.exp-2.lstmf
--traineddata ./tess4training-save/tess4training-vedic/san/${LANG}.traineddata  \
--append_index 5 --net_spec '[Lfx512 O1c150]' \
--train_listfile ./tess4training-save/tess4training-vedic/${LANG}.training_files.txt \
--eval_listfile ./tess4training-save/tess4training-vedic/${LANG}.eval_files.txt \
$ bash ./4runtesseract.sh
Loaded file ./tess4training-save/tess4training-vedic/tessdata/best/san.lstm, unpacking...
Loaded 138/138 pages (1-138) of document ./tess4training-save/tess4training-vedic/san.AA_NAGARI_SHREE_L3.exp0.lstmf
Loaded 138/138 pages (1-138) of document ./tess4training-save/tess4training-vedic/san.AA_NAGARI_SHREE_L3.exp-1.lstmf
Loaded 138/138 pages (1-138) of document ./tess4training-save/tess4training-vedic/san.AA_NAGARI_SHREE_L3.exp1.lstmf
To re-run your experiment, you could just hand-edit the Devanagari unicharset to insert the vedic accents that you need. I mentioned this briefly somewhere before.
> If the vedic accents are already included in the unicharset, then you can
> Code range changed from 145 to 2308!!
> "new style" unicharsets.
> To re-run your experiment, you could just hand-edit the Devanagari
> unicharset to insert the vedic accents that you need. I mentioned this
>To re-run your experiment, you could just hand-edit the Devanagari unicharset to insert the vedic accents that you need. I mentioned this briefly somewhere before.
This does not work. The program crashes in unicharset.cpp
>  --input_unicharset  ../tesstutorial/san.unicharset  \
>  --words "../langdata/san/san.wordlist" \
>  --numbers "../langdata/san/san.numbers"   \
>  --puncs "../langdata/san/san.punc" \
>  --output_dir ../tesstutorial/sanskrit2003   \
0>  --lang "san"     --pass_through_recoder \
> master/san
--net_spec '[Lfx256 O1c105]' \ Finetune
ShreeDevi
Are you using --oem 1?
combine_tessdata -u deu,traineddata
The quick brown dog jumped over the
over the lazy fox. The quick brown dog
Failed loading language 'frk'
The quick brown dog jumped over the
over the lazy fox. The quick brown dog
> Wrote tmp/deu.version
> Wrote tmp/deu.version
Posted in tesseract-ocr forum
> > Wrote tmp/deu.version
> > Wrote tmp/deu.version
> Posted in tesseract-ocr forum
> > > Wrote tmp/deu.version
> > > Wrote tmp/deu.version
learned that all nouns begin with a capital, so it hallucinates one even
'make' will build the test.
ar: creating gtest_main.a
ar rv gtest.a gtest-all.o
ar: creating gtest.a
trix_test
>No block overlapping textline: occurs when layout analysis fails to correctly segment the image that was given as training data. The textline is dropped. Not much problem if there aren't many, but if there are a lot, there is probably something wrong with the training text or rendering process. Still getting some of these errors for Devanagari, with tif/box pairs generated by text2image. Seems to be around `---------०---------` in training text.
No luck. cmake doesn't work on LInux.
Even building leptonica with cmake puts the library in /usr/local, so if
leptonica-1.74.4
Found AVX
ShreeDevi
> same error "illegal instructions" for any other --oem option or none
> 2. Install Leptonica:
> 	cd leptonica
> 3. Install Tesseract:
>     cd tesseract-ocr
it would be useful to have any experts in any of the following scripts
Devanagari, Bengali, Gurmukhi, Gujarati, Oriya, Tamil, Telugu, Kannada,Malayalam,
Sinhala,
There are script-specific cleanup rules in there.
The code determines what makes a valid/invalid sequence of unicodes in the
script, for instance, is it allowed to have two matras in a row? It gets
more difficult with questions over what category the additional characters
help with this would be expertise in the various scripts, as previously
https://github.com/tesseract-ocr/tesseract/blob/master/training/validate_indic.cpp
https://github.com/tesseract-ocr/tesseract/blob/master/training/validate_indic.h
https://github.com/tesseract-ocr/tesseract/blob/master/training/validate_khmer.cpp
https://github.com/tesseract-ocr/tesseract/blob/master/training/validate_khmer.h
https://github.com/tesseract-ocr/tesseract/blob/master/training/validator.h Devanagari - Vedic Accents
bool Validator::IsVedicAccent(char32 unicode) {
return 0x1cd0 <= unicode && unicode < 0x1d00;
Vedic tone marks
0951 $॑ DEVANAGARI STRESS SIGN UDATTA
• mostly used for svarita, with rare use for udatta
→ 1CDA $᳚  vedic tone double svarita
0952 $॒ DEVANAGARI STRESS SIGN ANUDATTA
→ 1CDC $᳜  vedic tone kathaka anudatta
Accent marks
0953 $॓ DEVANAGARI GRAVE ACCENT
→ 0300 $̀  combining grave accent
0954 $॔ DEVANAGARI ACUTE ACCENT
→ 0301 $́  combining acute accent
>Devanagari Extended: U+A8E0–U+A8FF
digits, letters, and avagraha which is used as a system of cantillation marks in the early
and a number of editorial marks.
Also include the ranges
*  A8E0-A8F1 Combining Marks
* A8F2-A8F7 Marks of Nasalization
Devanagari - Words cannot begin with
Various signs
0900 $ऀ DEVANAGARI SIGN INVERTED CANDRABINDU
= vaidika adhomukha candrabindu
0901 $ँ DEVANAGARI SIGN CANDRABINDU
= anunasika
→ 0310 $̐  combining candrabindu
0902 $ं DEVANAGARI SIGN ANUSVARA
= bindu
0903 $ः DEVANAGARI SIGN VISARGA
Various signs
093C $़ DEVANAGARI SIGN NUKTA
093D ऽ DEVANAGARI SIGN AVAGRAHA
Please check about Avagraha - 093D. Devanagari - Eyelash Ra for Marathi
eyelash-RA, is used instead of RAsup .
ShreeDevi
One thing I have noticed is that performance of OpenMP varies a lot
the cores, when it is busy, for no good reason at all, other than wanting
if they get moved, it will be much slower. The effect may be more intense
the parallel command, you might just get better performance by turning off
> functions.h:45:15: warning: inlining failed in call to ‘double tesseract::Tanh(double)’: call is unlikely and code size would grow [-Winline]
> O. Tange (2011): GNU Parallel - The Command-Line Power Tool,
> I'd run them ~50 times randomly(as random as /dev/urandom can afford on
> two options), 'randomly' defined as I randomly chose which to run, and
>    <not supported>      L1-icache-loads:u
>    <not supported>      L1-dcache-prefetches:u
>    <not supported>      L1-dcache-prefetch-misses:u
> <https://github.com/notifications/unsubscribe-auth/AL056byjoySZrjs2w14KyfUye2KocwQ8ks5sNXbogaJpZM4OWZ7L>
Tesseract versions and the minimum version of Leptonica required:
TesseractLeptonicaUbuntu
One option is to install the distro's Leptonica package:
sudo apt-get install libleptonica-dev
The sources are at https://github.com/DanBloomberg/leptonica . The
instructions for building are given in Leptonica README
<http://www.leptonica.org/source/README.html>.
Amit,
* The script based ones given in langdata
Where would a merged unicharset be used? In that case, we should add it to Makefile.am so that we can test and figure out what it does :-) It could be used to create a combined unicharset for a script-level engine, like the new Latin or Devanagari.
Let us consider language as lat+san+guj
So, something like this needs a combining of Devanagari + Gujarati + san_latn or IAST or Latin
What would be the best way to do this?
Can multiple training_files.txt for different languages be given as input for lstmtraining or do they need to be all merged in one big file?
![multi-language](https://user-images.githubusercontent.com/5095331/30238960-8e4a80fe-956f-11e7-9f1d-28ac9a18caec.png)
[deva-iast-guj.lstm-unicharset.txt](https://github.com/tesseract-ocr/tesseract/files/1291305/deva-iast-guj.lstm-unicharset.txt)
Can't encode transcription: यावद्ऽश्वरथद्विपानां युद्धसम्बाधन्ं न कुर्यात् तावद् आवापः कार्यः
Line cannot be recognized!!
@theraysmith Still waiting for that commit.
example of runon messages:
5	1	1	1	1	1	111	105	36	37	96	こ
5	1	1	2	1	3	271	171	50	50	96	大
5	1	1	2	1	3	271	171	50	50	96	大
> two different OS
tesseract -v
+- Update Lept4J to 1.5.0 (Leptonica 1.74.2)
ShreeDevi
> "zeros" ( º instead of 0)?
Is the problem only with your traineddata or also with Korean traineddata posted for 4.00.00alpha?
make[2]: *** [tesseract] Error 1
cd tesseract-3.05
make[2]: Leaving directory `/home/sanskrit/tesseract/api'
make[2]: Entering directory `/home/sanskrit/tesseract'
make[2]: Leaving directory `/home/sanskrit/tesseract'
Making all in tessdata
make[2]: Entering directory `/home/sanskrit/tesseract/tessdata'
make[3]: Entering directory `/home/sanskrit/tesseract/tessdata/configs'
make[3]: Leaving directory `/home/sanskrit/tesseract/tessdata/configs'
make[3]: Entering directory `/home/sanskrit/tesseract/tessdata/tessconfigs'
make[3]: Leaving directory `/home/sanskrit/tesseract/tessdata/tessconfigs'
make[3]: Entering directory `/home/sanskrit/tesseract/tessdata'
make[3]: Nothing to be done for `all-am'.
make[3]: Leaving directory `/home/sanskrit/tesseract/tessdata'
make[2]: Leaving directory `/home/sanskrit/tesseract/tessdata'
make[2]: Entering directory `/home/sanskrit/tesseract/doc'
make[2]: Leaving directory `/home/sanskrit/tesseract/doc'
make[1]: Leaving directory `/home/sanskrit/tesseract'
-L/usr/local/lib ./.libs/libtesseract.so \
-L/usr/local/lib ./.libs/libtesseract.so \
Do not know whether it is because I am using the latest version of leptonica rather than 1.74.2.
make[2]: Entering directory `/home/sanskrit/tesseract-3.05'
Making all in tessdata
-I/usr/local/include/leptonica
-I/usr/local/include/leptonica
make[2]: Entering directory `/home/sanskrit/tesseract-3.05'
Making all in tessdata
tesseract 3.05.01
leptonica-1.74.2
Is there a way to check the version info for leptonica, other than through `tesseract -v`?
/usr/local/include/leptonica
/usr/local/include/leptonica/leptwin.h
leptonica-1.74.2
tesseract -v
leptonica-1.74.4
As part of the experimentation, I did a hard reset in leptonica directory at one time to get to the commit for 1.74.2 and built leptonica and tesseract 3.05.01 after that without any problem.
This time I did `make distclean` in leptonica directory before running the build script.
Then without needing to rebuild tesseract, `tesseract -v` showed that it was using leptonica 1.74.4.
@amitdo So, as mentioned by Stefan, it is not necessary to rebuild tesseract to use the newer leptonica library.
26 [> Bplit
ShreeDevi
> Not sure if imagemagick can do better.
unicharset and optional word lists.
Way faster for most non-latin languages, while being <5% worse than "best"
>Tag is just specific points in history to mark something important (e.g. new version).
phototest, it broke something!
Devanagari, Bengali, Gurmukhi, Gujarati, Oriya, Tamil, Telugu, Kannada,
There are script-specific cleanup rules in there.
time to fix. I'm hoping it's simple, but it is bizarre.
> Tag is just specific points in history to mark something important (e.g.
Devanagari, Bengali, Gurmukhi, Gujarati, Oriya, Tamil, Telugu, Kannada,
There are script-specific cleanup rules in there.
ShreeDevi
> Devanagari, Bengali, Gurmukhi, Gujarati, Oriya, Tamil, Telugu, Kannada,
> There are script-specific cleanup rules in there.
> time to fix. I'm hoping it's simple, but it is bizarre.
> > Tag is just specific points in history to mark something important (e.g.
> AL056e0RzuP9Hpok6mT4eU026fofCwaBks5sNGdRgaJpZM4N9Nel>
The code determines what makes a valid/invalid sequence of unicodes in the
script, for instance, is it allowed to have two matras in a row? It gets
more difficult with questions over what category the additional characters
> Devanagari, Bengali, Gurmukhi, Gujarati, Oriya, Tamil, Telugu, Kannada,
> There are script-specific cleanup rules in there.
> ShreeDevi
> > Devanagari, Bengali, Gurmukhi, Gujarati, Oriya, Tamil, Telugu, Kannada,
> > There are script-specific cleanup rules in there.
> > time to fix. I'm hoping it's simple, but it is bizarre.
> > > Tag is just specific points in history to mark something important
> > > in history where a lot of development has taken place since the
> > AL056e0RzuP9Hpok6mT4eU026fofCwaBks5sNGdRgaJpZM4N9Nel>
> aGRLLsL6s9gxF_Xks5sNQIjgaJpZM4N9Nel>
No, it is not valid to have any two matras in a row  - Devanagari 093E-094C.
However, these can be followed by Anusvar, Chandrabindu or Visarga i.e. 0901-0903
Similarly in legacy fonts, half letters (letter followed by virama) maybe followed by aa maatraa to create the complete letter in cases such as ga, sha etc.  i.e. 0936 + 094D + 093E to create 0936 for sha
> No, it is not valid to have any two matras in a row - Devanagari 093E-094C.
> However, these can be followed by Anusvar, Chandrabindu or Visarge i.e.
> 0951, 0952, 1CDA etc
These are specifically dis-allowed by unicode, but the rules seem to be
very script-specific, and not very consistently documented in the unicode
> Similarly in legacy fonts, half letters (letter followed by virama) maybe
> followed by aa maatraa to create the complete letter in cases such as ga,
> combining mark (anusvar, visarga), vedic accent . Some fonts incorrectly
> use matra, vedic accent and combining mark which will lead to dotted
For instance, there is a big table in the unicode standard for Myanmar, (
any of the extension Myanmar characters, and isn't explicit about whether
of legacy Myanmar text on the web that is designed for non-compliant fonts
That is still an open question.
Whether enough uses of Tesseract can be covered by the new engine is still
That does not sound right. Please see
I did a search on ംം (two anusvarams in malayalam script) and most of them show up in the search result in pdfs.
newer pdfs created in a special manner, eg. with 'actual text' with xelatex are ok (eg. http://sanskritdocuments.org/doc_devii/annapurna.pdf), but those created from various other software are not (http://www.sanskritweb.net/sansdocs/nala-d.pdf).
http://www.omniglot.com/language/numbers/malayalam.htm
Also, there are different anusvars shown in unicode chart--
0D00 $ഀ MALAYALAM SIGN COMBINING ANUSVARA ABOVE
0D02 $ം MALAYALAM SIGN ANUSVARA
0D3B $഻ MALAYALAM SIGN VERTICAL BAR VIRAMA
0D3C $഼ MALAYALAM SIGN CIRCULAR VIRAMA
Anusvara. The anusvara can be seen multiple times after vowels, whether
malayalam sign virama, U+0D02 malayalam sign anusvara, and U+0D03 malayalam
sign visarga. They should also be prepared to handle multiple combining
> @theraysmith <https://github.com/theraysmith> Regarding Malayalam, double
> anusvara
> http://www.omniglot.com/language/numbers/malayalam.htm
> anusvar.
> Also, there are different anusvars shown in unicode chart--
> 0D00 $ഀ MALAYALAM SIGN COMBINING ANUSVARA ABOVE
> 0D02 $ം MALAYALAM SIGN ANUSVARA
> • used in Prakrit language texts to indicate gemination of the following
> 0D3B $഻ MALAYALAM SIGN VERTICAL BAR VIRAMA
> 0D3C $഼ MALAYALAM SIGN CIRCULAR VIRAMA
help with this would be expertise in the various scripts, as previously
> dotted circle as base characters for the Malayalam vowel signs, U+0D4D
> malayalam sign virama, U+0D02 malayalam sign anusvara, and U+0D03 malayalam
> sign visarga. They should also be prepared to handle multiple combining
> Is it wrong?
>> @theraysmith <https://github.com/theraysmith> Regarding Malayalam,
>> double anusvara
>> http://www.omniglot.com/language/numbers/malayalam.htm
>> anusvar.
>> Also, there are different anusvars shown in unicode chart--
>> 0D00 $ഀ MALAYALAM SIGN COMBINING ANUSVARA ABOVE
>> 0D02 $ം MALAYALAM SIGN ANUSVARA
>> • used in Prakrit language texts to indicate gemination of the following
>> 0D3B $഻ MALAYALAM SIGN VERTICAL BAR VIRAMA
>> 0D3C $഼ MALAYALAM SIGN CIRCULAR VIRAMA
> help with this would be expertise in the various scripts, as previously
>> Anusvara. The anusvara can be seen multiple times after vowels, whether
>> dotted circle as base characters for the Malayalam vowel signs, U+0D4D
>> malayalam sign virama, U+0D02 malayalam sign anusvara, and U+0D03 malayalam
>> sign visarga. They should also be prepared to handle multiple combining
>> Is it wrong?
>>> @theraysmith <https://github.com/theraysmith> Regarding Malayalam,
>>> double anusvara
>>> http://www.omniglot.com/language/numbers/malayalam.htm
>>> anusvar.
>>> Also, there are different anusvars shown in unicode chart--
>>> 0D00 $ഀ MALAYALAM SIGN COMBINING ANUSVARA ABOVE
>>> 0D02 $ം MALAYALAM SIGN ANUSVARA
>>> • used in Prakrit language texts to indicate gemination of the following
>>> 0D3B $഻ MALAYALAM SIGN VERTICAL BAR VIRAMA
>>> 0D3C $഼ MALAYALAM SIGN CIRCULAR VIRAMA
>In samvruthokaram - ◌ു് virama is applied to a vowel sign
>Another exception is у. This combination of a long vowel sign and anusvara is used to denote "nth" like, 16у or 16-у meaning 16th.
Request Santhosh Thottingal @santhoshtr to  comment regarding multiple anusvars. See https://github.com/tesseract-ocr/langdata/issues/35#issuecomment-320330996
Alexander Pozdnyakov has done a really good job packing Tesseract in his
Debian Experimental. That's a good place to work out problems, and hopefully
657M	fast
``` @amitdo  I can't seem to write a single comment without editing it three times to fix mistakes.
ShreeDevi
> 4.00alpha, leptonica 1.74.1 and OS is Ubuntu 14.04
Sorry, @hoangtocdo90 . I do not know about `ResultIterator`   As suggested in https://github.com/tesseract-ocr/tesseract/issues/1009
AFAIR somebody wanted to have option compile only individual parts of tesseract.
ShreeDevi
> even tried to get the leptonica.gz again and running the steps once more,
ShreeDevi
We can do anything, because it's dev branch.
Arglist at unknown address.
(gdb)
ShreeDevi
> *@egorpugin* commented on this pull request.
>  # Tesseract OCR
> -### Other
mgAﬁ'Ei'ib'fboss
--linedata_only \
--linedata_only \
--output_dir ~/tesstutorial/engeval
rm -rf  ~/tesstutorial/engtuned_from_engtest
mkdir -p ~/tesstutorial/engtuned_from_engtest
shree@sanskrit:~/tesseract$ tesseract -v
leptonica-1.74.2
load_freq_dawg       T
brown
fox
shared Guruvayoor Dnline Friends's post
tesseract test.png stdout  bazaar
shared Guruvayoor Online Friends's post
http://code.google.com/p/tesseract-ocr/source/browse/tags/release-3.01/dict/trie.h
ShreeDevi
which traineddata file did u use? Did you use `--oem 1` to use the LSTM engine and LSTM laanguage model?
Please close the issue.  What version of leptonica you use?
win64
*--train_listfile ara.training_text.txt*
ShreeDevi
> *--train_listfile ara.training_text.txt*
ara.unicharset ara.number-dawg ara.punc-dawg ara.word-dawg
check that  u have an old ara.traineddata
ShreeDevi
ara.number-dawg ara.punc-dawg ara.word-dawg
..\combine_tessdata ara.
ara.number-dawg ara.punc-dawg ara.word-dawg
Extracting tessdata components from ara.traineddata
Wrote ara.config
Wrote ara.unicharset
Wrote ara.punc-dawg
Wrote ara.word-dawg
Wrote ara.number-dawg
Wrote ara.freq-dawg
Wrote ara.lstm
Wrote ara.lstm-punc-dawg
6:punc-dawg:size=1066, offset=8544
7:word-dawg:size=6303746, offset=9610
9:freq-dawg:size=1346, offset=6313782
18:lstm-punc-dawg:size=1466, offset=11639754
It is a copy of the word-dawg based on the wordlist, but using the
different from the one used for tesseract or cube training).
ShreeDevi
> Btw do you know what is the difference between ara.word-dawg &
Hmm. Looks like it may be doing too many id_to_unichar (). Again
Float vs double:
- The SSE/AVX float->double cast is extremely slow - slower than reading
> See also the Tesseract wiki
Is this for --oem 0 or --oem 1 ?
https://github.com/tesseract-ocr/langdata/tree/master/kur
https://github.com/tesseract-ocr/langdata/tree/master/kur_ara
> @amitdo - Prepare a text file that has the path to each image:
multitest.tif
I have built only on ubuntu, not centos. Maybe there are differences in the o/s causing the issue.
@wildloop Thanks!
checking for g++... g++
cc: @zdenop @stweil @amitdo   Do we care about such leaks?
libarchive? minizip? libzip?
- [zopfli](https://github.com/google/zopfli) focused on size
- Clang 3.4 and above
ShreeDevi
> FROM ubuntu
> 	autoconf \
> 	automake \
> 	libicu-dev \
> 	libpango1.0-dev \
> 	libcairo2-dev \
> 	tar -zxvf leptonica-1.74.1.tar.gz && \
> 	cd leptonica-1.74.1 && ./configure && make && make install && \
> 	cd .. && rm -rf leptonica*
> 	cd tesseract && \
> amazonaws.com/blog_images/ocr_test.png > test.png tesseract test.png out
That error/info message is from Leptonica
tesseract -v
@amitdo Is the tessdata a tiff file??? Thanks! I have updated https://github.com/tesseract-ocr/tesseract/wiki/4.0-Dockerfile
Zdenko
> <https://github.com/notifications/unsubscribe-auth/AAjCzAfq1jpyiE1PGrRmM0lNTIWV4O1Dks5r3BsigaJpZM4NSpiD>
ShreeDevi
> https://appveyorcidata.blob.core.windows.net/zdenop-27740/
C:/Users/vvkum/AppData/Local/Temp/tmp.Q59kWa5fdq/hin/hin.FreeSerif.exp0.lstmf
Iteration 188: ALIGNED TRUTH : गई हैं. एशिया डैनियल श्रिया था. हैं.
C:/Users/vvkum/AppData/Local/Temp/tmp.Q59kWa5fdq/hin/hin.FreeSerif.exp0.lstmf
Iteration 189: ALIGNED TRUTH : फ्लेमिंग लिया। बर्बाद स्पोर्ट्स %>
C:/Users/vvkum/AppData/Local/Temp/tmp.Q59kWa5fdq/hin/hin.FreeSerif.exp0.lstmf
Iteration 190: ALIGNED TRUTH : हैप्पी सुर्ख घर मिलता हुई। के
related to info messages from leptonica
ShreeDevi
> messages from leptonica are not displayed. The version built with automake
> Iteration 188: ALIGNED TRUTH : गई हैं. एशिया डैनियल श्रिया था. हैं.
> Iteration 189: ALIGNED TRUTH : फ्लेमिंग लिया। बर्बाद स्पोर्ट्स %>
> Iteration 190: ALIGNED TRUTH : हैप्पी सुर्ख घर मिलता हुई। के
Type "apropos word" to search for commands related to "word"...
--linedata_only \
--append_index 5 --net_spec '[Lfx256 O1c105]' \
Type "apropos word" to search for commands related to "word"...
86            if (!*p)
--linedata_only \
--append_index 5 --net_spec '[Lfx256 O1c105]' \
--continue_from ~/tesstutorial/aralayer_from_ara/ara.lstm \
--model_output ~/tesstutorial/aralayer_from_ara/aralayer \
--train_listfile ~/tesstutorial/ara/ara.training_files.txt \
> <https://github.com/notifications/unsubscribe-auth/AL056WoPKurkhF6p7FaQbU71cN6cqaAfks5sNdMigaJpZM4NRHiF>
ShreeDevi
> [image: ocrerror]
> <https://github.com/notifications/unsubscribe-auth/AE2_owNFvS9fAL3rZWahuof6a8Kz4xzHks5r4XQsgaJpZM4NQWtW>
tesseract -v
leptonica-1.74.1
[Thu May 11 13:55:50 DST 2017] /usr/local/bin/tesseract /tmp/tmp.D3w1Zt6gOu/ara/ara.Arabic_Typesetting.exp0.tif /tmp/tmp.D3w1Zt6gOu/ara/ara.Arabic_Typesetting.exp0 lstm.
train ../langdata/ara/ara.config
Loaded 56/56 pages (1-56) of document /tmp/tmp.D3w1Zt6gOu/ara/ara.Arabic_Typesetting.exp0.lstmf
Loaded 117/117 pages (1-117) of document /tmp/tmp.D3w1Zt6gOu/ara/ara.Arabic_Typesetting.exp0.lstmf
Git pull origin
tesseract -v
> leptonica version at this site
// pruner   : Tesseract class pruner only.
--char_spacing  Inter-character space in ems  (type:double default:0)
```  https://tesseract-ocr.github.io/index.html
> ==> Using the sandbox
> ==> Applying b18cad4
> /private/tmp/tesseract--patch-20170502-16295-cpuv7w/b18cad4.patch
* https://en.wikipedia.org/wiki/Arabic_numerals
* https://en.wikipedia.org/wiki/Eastern_Arabic_numerals
* https://en.wikipedia.org/wiki/Arabic_script_in_Unicode
> The Arabic numeral glyphs 0–9 are encoded in ASCII and Unicode at positions 0x30 to 0x39, matching up with the second hexadecimal digit for convenience:
> The Eastern Arabic numerals (also called Arabic–Indic numerals and Arabic Eastern numerals) are the symbols used to represent the Hindu–Arabic numeral system, in conjunction with the Arabic alphabet.
> Each numeral in the Persian variant has a different Unicode point even if it looks identical to the Eastern Arabic numeral counterpart. However the variants used with Urdu, Sindhi, and other South Asian languages are not encoded separately from the Persian variants.
So, basically, there are three unicode ranges with numerals used in Arabic, Persian etc.
If the fonts are putting ` Eastern Arabic numerals` U+0660 through U+0669  in the `Arabic numerals` range of 0x30 to 0x39, that would cause confusion during training.
https://github.com/tesseract-ocr/langdata/blob/master/ara/ara.training_text has  'Arabic numerals' range of 0x30 to 0x39. You can check whether it as  ( ٠ ١ ٢ ٣ ٤ ٥ ٦ ٧ ٨ ٩) and add it, if you want to include it for training. @reza1615
Please update the desired characters for persian for the persian unicode range of numbers and ignore the unicode arabic number range for fas (persian), as mentioned above. Thanks! Question from Ray in tesseract-ocr/langdata#72
kur_ara, pus, uig  Any objection to merge this PR? Making all in doc
make[2]: *** No rule to make target `cntraining.1', needed by `all-am'.  Stop.
Leptonica classes, and Dan says we should be using Pix in C++, not PIX.
> Since Tesseract code is based on C++, we should use a C++ style guide.
@bertspaan :-)
ShreeDevi
ShreeDevi
> tesseract eng.font.exp0.tif eng.font.exp0.box.lstm.train
ShreeDevi
For your user case, I think using an older version of tesseract, specially
ShreeDevi
That whole section is a little weird for a few reasons.
2)  The OpenCL TIFF code has fallen behind Leptonica proper, enough to be currently disabled. (By the way, I'm probably capable of helping it catch up, but not very motivated.)
and most interestingly to me
For all these reasons, if we did decide to prune out some OpenCL code, I think the TIFF portion is the best place to start. I'd roughly guess that includes about a dozen methods.
Furthermore, it isn't just a case of modifying unicharset_extractor.
For the Indic languages, the unicharset needs to know the syllable/grapheme clusters, and it can't get that from the Wordstr box file format. The best it can do is extract the unicodes used in the WordStr box file or you start with an existing unicharset for that training path. @amitdo Will your changes - https://github.com/amitdo/tesseract/commit/8fe2d918e447
> Hi Shree
> As I'm not a C etc. coder (I last wrote serious C several decades ago!) I'm not able to judge which error/warning messages are significant or figure out how to fix them.  I was hoping to follow a recipe that would reliably build a portable Tesseract for the Mac and Windows.  I'm just trying different combinations of sub-builds until I find one that works, which is why I ended up with a combination of older versions of the dependencies. So I'm not a good person to ask to build this and report errors etc!
Failed loading language 'osd'
chi_sim.traineddata       chi_tra.traineddata       configs/                  ori.traineddata           pdf.ttf
Could not initialize tesseract.
ShreeDevi
> I have the same problem like @am0awad <https://github.com/am0awad> .
> --lang chi_sim
> --linedata_only
> --output_dir ./tesstutorial/chi_sim `
> ./langdata/chi_sim
> `=== Starting training for language 'chi_sim'
> mktemp: illegal option -- -
> --fonts_dir=/Library/Fonts --font=AR PL UKai CN Light
> --font=AR PL UKai CN Light --text=./langdata/chi_sim/chi_sim.training_text
> xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.Arial_Unicode_MS.exp0
> --font=Arial Unicode MS --text=./langdata/chi_sim/chi_sim.training_text
> tmp.NTXG7RhZ/chi_sim/chi_sim.Arial_Unicode_MS.exp0.box does not exist or
> tmp.NTXG7RhZ/chi_sim/chi_sim.AR_PL_UKai_CN_Light.exp0.box does not exist
> tmp.NTXG7RhZ/chi_sim/chi_sim.AR_PL_UKai_CN_Light.exp0.box does not exist
nulls in it.
ShreeDevi
> > > Times_New_Roman.exp0.tif
> AZFiASKi4zAcvT6hL8SkvIybrnjQVMWrks5stLLOgaJpZM4M6-yu>
@amitdo
> Done: https://abi-laboratory.pro/tracker/timeline/tesseract/
> [image: tesseract-5]
>   -U ~/tesstutorial/bihnew/bih.unicharset \
>   --train_listfile ~/tesstutorial/bihnew/bih.training_files.txt \
>   --eval_listfile ~/tesstutorial/bihtest/bih.training_files.txt \
>   --continue_from ~/tesstutorial/bihnewlayer/bih.lstm \
>  --net_spec '[Lfx384 O1c105]' \
Continuing from /home/shree/tesstutorial/bihnewlayer/bih.lstm
Setting properties for script Devanagari
Loaded 404/404 pages (1-404) of document /home/shree/tesstutorial/bihnew/bih.AA_NAGARI_SHREE_L3.exp0.lstmf
Loaded 404/404 pages (1-404) of document /home/shree/tesstutorial/bihnew/bih.Adobe_Devanagari.exp0.lstmf
Loaded 404/404 pages (1-404) of document /home/shree/tesstutorial/bihnew/bih.Aksharyogini2.exp0.lstmf
Loaded 404/404 pages (1-404) of document /home/shree/tesstutorial/bihnew/bih.Arial_Unicode_MS.exp0.lstmf
Loaded 404/404 pages (1-404) of document /home/shree/tesstutorial/bihnew/bih.Aparajita.exp0.lstmf
``` @stweil Is it related to https://github.com/tesseract-ocr/tesseract/issues/881#issuecomment-299393920 ? @stweil In case you want to reproduce using the files I was using - they are for Bihari/Hindi language, devanagari script.
mkdir -p ~/tesstutorial/bihnewlayer
combine_tessdata -e ../tessdata/hin.traineddata \
* bih.lstm (lstm model extracted from hin.traineddata)
Maybe, these are also just 'info' messages!
>   --train_listfile ~/tesstutorial/bihnew/bih.training_files.txt \
>   --eval_listfile ~/tesstutorial/bihtest/bih.training_files.txt \
or did you change path in bihtest to match bihnew?
>   --train_listfile ~/tesstutorial/nyd/nyd.training_files.txt \
Iteration 13398: ALIGNED TRUTH : पंचाग कला की, फ़ अः ग़ुमान आलोचना छूटती के ज़् द्वा अधीन र्द् देहियाँ भजनला
File /tmp/tmp.3zBjAvGc9O/bih/bih.Lohit_Devanagari.exp0.lstmf page 24 :
Iteration 13399: ALIGNED TRUTH : संभावना :
File /tmp/tmp.3zBjAvGc9O/bih/bih.Mangal.exp0.lstmf page 458 (Perfect):
Aborted (core dumped)
Iteration 13399: ALIGNED TRUTH : संभावना :
File /tmp/tmp.3zBjAvGc9O/bih/bih.Mangal.exp0.lstmf page 458 (Perfect):
Program received signal SIGABRT, Aborted.
I've activated macos builds (clang).
--- leptonica/src/pdfio2.c	2017-03-09 08:41:53.000000000 -0800
+++leptonica/src/pdfio2.c	2017-03-23 09:32:21.000000000 -0700
+          L_ERROR("file %s is unsupported format %d\n",
+        if (format == IFF_JFIF_JPEG) {
-    if (format == IFF_JFIF_JPEG) {
if (!pix)
else
+        L_ERROR("totally kerflummoxed\n", procName);
`cat foo.jpg | tesseract - - pdf`
`tesseract foo.jpg - pdf`
(3) Switch Tesseract to NULL
ccstruct/ratngs.h
ccutil/unicharset.cpp
One needs fixing some bugs in tiff library that comes from cppan.
> <https://github.com/notifications/unsubscribe-auth/AE2_o4sRtuKQml61AmRBaijFs5XDubIuks5sZVe9gaJpZM4MmXJm>
The synthetic tif/box files created by `text2image` create one box for each aksara (conjunct-cluster+combining mark). These are broken into components by the unicharcompressor/recoder.
ला 147 4645 205 4679 0
ई 198 4640 235 4694 0
से 244 4645 288 4692 0
म् 311 4655 341 4678 0
ब 330 4645 366 4678 0
However, the box files created by `tesseract` using the `makebox` config file, split the components and create a box for each. This happens both with Devanagari and hin traineddatas from tessdata_best.
ज 107 4632 124 4695 0
ल 150 4632 168 4695 0
ई 187 4632 213 4695 0
स 241 4656 246 4661 0
ट 297 4644 309 4693 0
म 318 4644 328 4693 0
ब 344 4644 358 4693 0
जु 107 4632 166 4695 0
ला 166 4632 190 4695 0
ई 190 4632 213 4695 0
से 239 4656 246 4661 0
प् 274 4644 297 4693 0
म् 323 4644 344 4693 0
ब 344 4644 358 4693 0
Extracting unicharset from box file /tmp/tmp.fN2Jr9NHXJ/bih/bih.makebox.exp0.box
Possibly this will also happen for other complex scripts.
Please use tesseract user forum for asking support/questions.  Please use tesseract user forum for asking questions/support  While running the training for `frk` with a longer training text, I get [assertions in stringrenderer.cpp](https://github.com/tesseract-ocr/tesseract/blob/master/training/stringrenderer.cpp#L553) for 5 of 12 fonts. They can be reproduced by running `text2image` for that text with a single language:
@Shreeshrii accuracy in persian and arabic language is poor yet
fas+eng returned some cropped data​...
Please inclufe a Persian script based traineddata which has fas and eng in
@Shreeshrii, that's a nice collection of Fraktur fonts, but several of the image not even include all normal ASCII characters. All images are missing the long s character (ſ) which is very important for all Fraktur texts. Also missing are all forms of ligatures (combinations of certain characters, like for example ffi, which need a special rendering). Did you see the new [page about fonts](https://github.com/tesseract-ocr/tesseract/wiki/Fonts) which I added to the wiki? Maybe you want to add information there. Many thanks, that's a really very useful document which might allow us to find the exact list of Fraktur fonts used for the German newspaper editions printed from 1900 up to 1945. @stweil I got the same error now. Though the same files and commands worked before and after.
Fort-
venftedt eingetragen worden: Die Ge-
nofenfhaft ift durd BVefhluf der Ge-
neralverfammlung vom 16. Uuguft 1920
aufgelöft. Anuguft Üterwedde und Leo
Krötfi, beide in Olvenfiedt, find zu
Liquidatoren bejielt.
OVa& IAmtenericht A A
from noise.
There are large gaps between words, but tiny gaps between columns. That was
such cases. It can't cut a straight line (even at an angle) through the
libtool: link: ranlib .libs/libtesseract_api.a
unicharset has the bullet character.
> Can you please provide the trained data for bullet character or guide me
and follow instructions there for the bullet character.  Similarly for Nepali - please see https://groups.google.com/forum/#!topic/tesseract-ocr/m2Dx6a-srvo
OpenCL is just experimental feature, so having no effect is possible results.
[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
These ocrx_word occurrences seem to be occurring in relation to vertical and horizontal lines in the image.
leptonica-1.73
This application has requested the Runtime to terminate it in an unusual way.
This application has requested the Runtime to terminate it in an unusual way.
This application has requested the Runtime to terminate it in an unusual way.
This application has requested the Runtime to terminate it in an unusual way.
ObjectCache(01210A88)::~ObjectCache(): WARNING! LEAK! object 05981790 still has count 1 (id C:\Program Files (x86)\Tesseract-OCR/tessdata/eng.traineddatalstm-punc-dawg)
Major B It's not java, is it? Doh!
-_ZN8WERD_RES19FakeWordFromRatingsEv@Base
-_ZN9tesseract17ViterbiStateEntryD1Ev@Base
-_ZN9tesseract17ViterbiStateEntryD2Ev@Base
Aborted (core dumped)
https://lvc.github.io/abi-compliance-checker/
https://abi-laboratory.pro/tracker/
```diff
I have an experimental implementation that treats it as an additional
unicharset.
versioned subdir seems like a good idea too.
I also had an example where a larger part of a page was missing in the output from LSTM while the old recognizer got most of that part correctly, but I am still searching to find that example again. I recently tried to improve the training model for a language (`frk`). That's rather easy and does not need much compute time (~ minutes) or other resources for the old engine. Especially adding more characters which should be recognized is a simple task as soon as the general infrastructure (Tesseract binaries, small number of fonts) is available.
My conclusion is that most users of the new LSTM will be restricted to the available trained data either from @theraysmith or from third parties. If the old engine is removed, it will no longer be possible to optimize OCR for documents with unusual or rare characters. Calling Tesseract with more than one language can only partially solve such situations. LSTM currently does not work with all languages (see issue #682). That's related to my previous comment: adding (good) LSTM support for a language is much more difficult than for the old engine. Of course the existing languages will be fixed one day, but there still remain more exotic languages which are not covered today, and people won't be able to add them to Tesseract. We could tell users to use Tesseract 3.x for those cases, but would that really save development resources when there is the need to maintain both versions 3 and 4? It seems clear that having two major versions of Tesseract requires more work for Linux distributions. Neither is it a good solution for users who have to install and use both versions and don't know what to do when texts require both versions. I believe I am on a path to make the LSTM engine work with *many*
languages, and possibly unseen languages in the same script.
much better solution to multi-lang/multi-script and plug-replaceable
Deserialize header failed: ~/tesstutorial/tess4training-vedic/san.Akshar_Unicode.exp-2.lstmf
Deserialize header failed: ~/tesstutorial/tess4training-vedic/san.Aksharyogini2.exp0.lstmf
Try to open `cppan.yml` in some editor and save with unix line endings (LF).
While I am looking at this though, I am not convinced that the unicharset and/or compression are applied correctly to Kannada, which might explain its rather stubborn refusal to improve in accuracy. >>The underlying question is, if there is a word that is almost certainly incorrect, would it be better to have it with the error, or have it disappear?
is missing ZWNJ, which AFAICT is an *essential* unicode character in
Kannada.
some use ZWJ as well.
languages, although I don't know by how much, as I haven't measured the
frequency of ZWNJ in my test sets.
> DocumentAnalysis/Nethra_ICFHR2010_Data.pdf
@theraysmith
In addition to training for unknown fonts by using scanned box/tiff pairs, they would also be useful for 'printing conventions' which may not be in concert with the current unicode conventions.
![srisubodhini00vall_0013](https://user-images.githubusercontent.com/5095331/28249585-288ba9ec-6a76-11e7-99ad-e4763829ed33.png)
@theraysmith
Furthermore, it isn't just a case of modifying unicharset_extractor.
For the Indic languages, the unicharset needs to know the syllable/grapheme clusters, and it can't get that from the Wordstr box file format. The best it can do is extract the unicodes used in the WordStr box file or you start with an existing unicharset for that training path. Related - https://github.com/tesseract-ocr/tesseract/issues/832 @theraysmith Please also see https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/Xu4_aOCFhlQ/Yb2G59zTAgAJ about
The quick brown dog jumped over the
over the lazy fox. The quick brown dog
ObjectCache(0xb408678)::~ObjectCache(): WARNING! LEAK! object 0x7ff6a69316a0 still has count 1 (id third_party/tesseract/tessdata/eng.traineddatalstm-punc-dawg)
```diff
str     क्      र       ष       य       :
```diff
+                                 bool textonly)
-  pdf_str += " 0 0 cm /Im1 Do Q\n";
+  pdf_str += " Q\n";
">>\n"
// we load a custom PDF font from this location.
private:
// used to make everything that isn't easily handled in a
// streaming fashion.
const char *datadir_;              // where to find the custom font
api->GetBoolVariable("tessedit_write_unlv", &b);
"Citroën"
by using fra+deu as the language. Unfortunately, it doesn't work with
deu+fra, and neither works for the 2nd example.
BTW this needed a bug fix for multi-language, which I will check in soon.
Some of the problems with German texts were addressed in https://github.com/tesseract-ocr/langdata/pull/54, https://github.com/tesseract-ocr/langdata/pull/56 and https://github.com/tesseract-ocr/langdata/pull/57. I don't know whether those fixes are sufficient to improve future trainings. I addressed the more general question whether all European languages should support all typical diacritical characters in the [tesseract-dev](https://groups.google.com/forum/#!topic/tesseract-dev/8H_4K3vPRJE) forum and need information from @theraysmith to proceed. > I successfully correctly got "Citroën" by using fra+deu as the language.
"Citroén" instead of the original word "Citroën"
"fiir" instead of "für"
* "Sich" instead of "sich"
* "Sie" instead of "sie"
* "Sagte" instead of "sagte"
* "Sagen" instead of "sagen"
* "Sah" instead of "sah"
* "ICh" instead of "Ich"
supposed to be different colors?
> I tried arabic_lines with both arabic diacritics and devanagari sample and
> [image: result-arabic-diacritics]
> [image: textlines-arabic-diacritics]
> [image: textlines-deva]
and let me know if you see any deficiencies. I notice that ZWJ and ZWNJ are
not there, but 202c(Pop directional formatting) is.
> In Arabic there are to kinds of diacritics
> bottom line: vowel diacritics in Arabic should be recognized alone (e.g
> diacritics also ًّ ّْ
@theraysmith
use tesseract user forum for asking support  That sounds like its working as intended.  The LSTM recognizer is currently trained to recognize the sequence of *unicodes* for Indic languages. This reduces the size of the output softmax of the network from the 5000+ elements in the unicharset to ~140. (There is an analogous process for Chinese, Japanese, and Korean, that doesn't use the unicode encoding, but it is a similar idea, and the codes are strictly limited in length.)
The text is divided by language automatically, so there is a separate
stream for each of the Devanagari-based languages (as there is for the
For each language, the text is frequency counted and cleaned by multiple
stringent enough, so forbidden_characters and desired_characters are used
For some languages, the amount of data produced at the end is very thin.
50000 chunks of 50 words to render in a different combination of font and
I recently stopped training chr, iku, khm, mya after discovering that I
Community input is therefore extremely useful, and usually results in edits
to forbidden_characters and desired_characters, which in turn guides the
The languages with very little corpus text are:
bih
dzo
iku
syr
tgk
tir
so these are likely to have poor recognition accuracy.
> language to language.
> Are the desired_characters and forbidden_characters used in the process of
> How many text lines are you using for training of Devanagari, e.g.
> > *unicodes* for Indic languages. This reduces the size of the output
dzo
iku
syr
tgk
tir
I have put a lot of time into cleaners/filters for languages that use 'virama' characters.
I am not convinced that they are perfect, but I will add the code to the github repo in due course, so experts/native speakers can offer suggestions/fixes to make them better. Myanmar in particular needs improvement, as the www data is littered with dotted circles, and the unicode book does not adequately describe the syntax for a well-formed grapheme in Myanmar (or any other language for that matter).
Setting properties for script Devanagari
Unichar 1945=र्त्स्न्ये->र्त्स्न्ये is too long to encode!!
In https://github.com/tesseract-ocr/docs/blob/master/das_tutorial2016/7Building%20a%20Multi-Lingual%20OCR%20Engine.pdf, you have desscribed what's a character in Devanagari and used the following example:
rdvika - र्द्विक - 0930 094D 0926 094D 0935 093F 0915
I would actually split the above as two aksharas, each ending in the either the implicit a or a maatraa or a combining mark.
rdvi - र्द्वि - 0930 094D 0926 094D 0935 093F
ka - क -  0915
To reduce the various akshara combinations, i would suggest splitting
Maatra and Combining marks separately
eg. possible combinations with ka (and these do not include the combining vedic accents!!)
Imagine these for every consonant cluster with every vowel sign (or matra), other signs like candrabindu, anusvara and visarga to each combination. the number of combinations will be HUGE.
By splitting consonant cluster part separately from maatraa and other signs combination, the number of combinations can be cut down drastically.
घ्न घ्म घ्य घ्र ङ्क ङ्क्त ङ्क्ष ङ्क्ष्व ङ्ख ङ्ख्य ङ्ग ङ्ग्य ङ्ग्र ङ्ग्र्य ङ्घ ङ्घ्र ङ्ङ ङ्म ङ्स
ञ्च ञ्च्य ञ्छ ञ्छ्र ञ्ज ञ्ज्म ञ्ज्य ञ्झ ञ्श
थ्य द्ग द्ग्र द्द द्द्य द्द्र द्द्व् द्ध द्ध्य द्ध्व द्ध्व्य द्न द्न्य द्ब द्ब्र द्भ द्भ्य द्म द्य द्र द्र्य द्व् द्व्य द्व्र ध्न ध्म ध्य ध्र ध्व
म्न म्प म्प्र म्ब म्ब्य म्भ म्ब्र म्म म्य म्र म्ल
य्य य्व ल्क ल्ग ल्प ल्म ल्य ल्ल ल्व ल्ह व्य व्र व्व श्च श्च्य श्न श्न्य श्म श्य श्र श्र्य श्ल श्व श्व्य श्श
ष्क ष्क्र ष्ट ष्ट्य ष्ट्र ष्ट्र्य ष्ट्व ष्ठ ष्ठ्य ष्ठ्र ष्ण ष्ण्य ष्प ष्प्र ष्म ष्य ष्व
र्घ्न र्घ्म र्घ्य र्घ्र र्ङ्क र्ङ्क्त र्ङ्क्ष र्ङ्क्ष्व र्ङ्ख र्ङ्ख्य र्ङ्ग र्ङ्ग्य र्ङ्ग्र र्ङ्ग्र्य र्ङ्घ र्ङ्घ्र र्ङ्ङ र्ङ्म र्ङ्स
र्ञ्च र्ञ्च्य र्ञ्छ र्ञ्छ्र र्ञ्ज र्ञ्ज्म र्ञ्ज्य र्ञ्झ र्ञ्श
र्थ्य र्द्ग र्द्ग्र र्द्द र्द्द्य र्द्द्र र्द्द्व् र्द्ध र्द्ध्य र्द्ध्व र्द्ध्व्य र्द्न र्द्न्य र्द्ब र्द्ब्र र्द्भ र्द्भ्य र्द्म र्द्य र्द्र र्द्र्य र्द्व् र्द्व्य र्द्व्र र्ध्न र्ध्म र्ध्य र्ध्र र्ध्व
र्म्न र्म्प र्म्प्र र्म्ब र्म्ब्य र्म्भ र्म्ब्र र्म्म र्म्य र्म्र र्म्ल
Please see pages 48-75 of http://www.sanskritweb.net/itrans/itmanual2003.pdf
for the varied rendition of consonant cluster ligatures in different Devanagari fonts.  An encoded lstm recognizer (or trainer) includes its own unicharset.
Wrote hinnew.config
Wrote hinnew.lstm-punc-dawg
Wrote hinnew.version
18:lstm-punc-dawg:size=4322, offset=8875496
dawgs if wordlists were supplied.
be LTR, and the words in the dawg should be reversed.
There is Bidi processing inside the post-recognition processing of
- U+640 (tatweel) is a very special case that I need to think how to
Questions:
(ara+div+fas+kur_ara+pus+snd+syr+uig+urd)
> i was merging the letter extender with the Arabic letter into one single
> box, and putting that Arabic letters as the character of the box,
> basically, i was trying to train the engine to recognize that Arabic letter
> in it's multiple positions, as you know the Arabic letters have multiple
> also ( ـكـ ) or ( ـك ) they are a single character ( ك ) in different
@amitdo Hebrew seems to be OK. It is certainly ahead of 3.05.
Arabic (all langs)
> source=footer#!msg/tesseract-ocr/EOwF1GnOcS0/My_SUf1vEQAJ
> tesseract4 reads الأ as األ which is pretty close, because we need to
> switch the position of the last 2 letters to have ا ل أ, this happens with
> similar word forms too like لا reads as ال and should be ل ا, and i wish to
> Here are some libraries that implement the Unicode Bidi algorithm.
> https://github.com/behdad/pybyedie
> Written in: Python
> https://github.com/servo/unicode-bidi
> Written in: Rust
> https://github.com/behdad/fribidi
> Written in: Python
I understand that tatweel is a rendering artifact, that should be rendered
diacritical marks that are optional, and used mainly for disambiguation,
Are you referring to some different diacritics other than vowels, or are
diacritics exist that should never appear in the output text?
Diff: שָהוּא נָס מִפָּנִיו, אָמַר לוֹ מֹשָה: כָּל הַיּוֹם הָיִיתִי אוּמֵר לֶ
Diff: וְתופחים בַּבַּטָנִיס וּבשירים שאַרכֶּם כַארְף סִיגְרִיה,
Truth: له يزيد الرجال وركبوا الطريقَ فلم يشعر بهم العدو حتى ركبوا
OCR: له يزيج الرجال وركبوز الطريق فلم يشعر بهم العدر حتى ركبو
Diff: له يزيج الرجال وركبوز الطريقَ فلم يشعر بهم العدر حتى ركبوا
In all these cases, tesseract gets a poor result.
badly wrong.
In case 3 (Arabic) there are diacritics in the truth text (or are these not
> Note that Arabic & Hebrew diacritics have the same issue of the U+640
> (tatweel), therefore I suggest that they need to be preserved in the
@theraysmith
fyi - https://github.com/tesseract-ocr/tesseract/issues/892#issuecomment-318063065 http://blogs.transparent.com/arabic/2-arabic-diacritics-al-tashkeel-%D8%A7%D9%84%D9%80%D8%AA%D9%80%D8%B4%D9%80%D9%83%D9%80%D9%8A%D9%80%D9%80%D9%80%D9%84/
--training_text ../langdata/ara/ara.training_text \
--lang ara  \
--linedata_only \
--output_dir ~/tesstutorial/aratest
--training_text ../langdata/ara/ara.training_text \
--lang ara  \
--linedata_only \
"Calibri" \
--output_dir ~/tesstutorial/araeval
mkdir -p ~/tesstutorial/aratuned_from_aratest
combine_tessdata -e ../tessdata/ara.traineddata \
~/tesstutorial/aratuned_from_aratest/ara.lstm
--continue_from ~/tesstutorial/aratuned_from_aratest/ara.lstm \
--train_listfile ~/tesstutorial/aratest/ara.training_files.txt \
>   --continue_from ~/tesstutorial/aratuned_from_aratest/ara.lstm \
>   --train_listfile ~/tesstutorial/aratest/ara.training_files.txt \
>   --eval_listfile ~/tesstutorial/araeval/ara.training_files.txt \
Segmentation fault
Program received signal SIGABRT, Aborted.
(gdb)
@theraysmith
Iteration 99: ALIGNED TRUTH : च छ ज झ ञ उ ऊ ट ठ ड ढ ण ऋ ॠ त थ
File /tmp/tmp.m82dWGBYZW/mar/mar.Aparajita.exp0.lstmf page 3 :
Aborted (core dumped)
case is "ru"
mad......
// to hold a colormap with 256 colors in the verbose
+    int high_surrogate = (0x03FF & (a >> 10)) + 0xD800;
+             "%04X%04X", high_surrogate, low_surrogate);
-        char utf16[20];
for (int i = 0; i < unicodes.length(); i++) {
int code = unicodes[i];
-            int high_surrogate = (0x03FF & (a >> 10)) + 0xD800;
-                     high_surrogate, low_surrogate);
pdf_str += " Tz";          // horizontal stretch
+  STRING utf16_title = "FEFF";  // byte_order_marker
+  for (int i = 0; i < unicodes.length(); i++) {
+    int code = unicodes[i];
">>\n"
```diff
​it seems this problem occur in other multi lingual process to
Please re-open if you are seeing this slow-down in optimized mode.  This looks like an error for 32 bit x86 platforms. You can work around it by removing the line `#  define X86_BUILD 1` from `arch/simddetect.cpp`. @Izaron, yes, but it will be much slower.
@amitdo, there are several options:
PROPERTIES COMPILE_FLAGS "/arch:AVX")
​i checked Arabic today
​@shree ubuntu 16lts​
Zdenko
Did you compile Tesseract yourself or do you use a pre-build version? Can you use Tesseract 3.05 or an earlier version? Tesseract 4.x is experimental and not for end users currently. @Vidushi12, I suggest to use the Tesseract provided by Ubuntu and don't build it yourself. Just run `apt-get install tesseract-ocr tesseract-ocr-eng` (add more languages as needed) as root user. You can either remove `/usr/local/bin/tesseract`, or don't uninstall it and call `/usr/bin/tesseract` explicitly. Yes, that's it.  @amitdo:
Leptonica 1.74? It is this version number stuff causing trouble?
cppan
The error is:
Maybe in skype (username - egor.pugin). Sorry, updated previous comment with correct username.  See https://github.com/tesseract-ocr/tesseract/issues/832
> I finetuned tesseract for farsi (40 fonts on 6000 text lines)
ShreeDevi
ShreeDevi
> > I finetuned tesseract for farsi (40 fonts on 6000 text lines)
> ShreeDevi
wrong somewhere with the images.
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
> Line cannot be recognized!!
using tesstrain.sh - it is usually related to 'nnn diacritics found' - so
it  may be related to accents being treated as a separate line.
Regarding finetuning, I have experimented a lot with Devanagari - with
ShreeDevi
> wrong somewhere with the images.
> aC1mUg2gH34puAGpWdOOks5sXZhHgaJpZM4LQsPF>
--input_unicharset  ../tesstutorial/sanskrit2003/san/san.unicharset  \
--words "../langdata/san/san.wordlist" \
--numbers "../langdata/san/san.numbers"   \
--puncs "../langdata/san/san.punc" \
--output_dir ../tesstutorial/sanskrit2003   \
For RTL languages, there is an additional flag. Please see https://github.com/tesseract-ocr/tesseract/blob/master/training/tesstrain_utils.sh for details.
ShreeDevi
cppan
You may try instead of typing these commands remove the whole storage `c:\users\zhivko\.cppan\storage`.
cppan --clean-packages .*lepton.*
cppan
What do you think? Mixing float and double can result in additional code (and execution time) for conversions between both types.  This is caused by a missing `--llept` linker option. I have that problem, too (not in all configurations), and I am still searching why this worked before. Yes, I thought so, as it was the only related commit. The strange thing is that builds with `--enable-opencl` (default when OpenCL development files are installed) work. That's why I only see it with cross builds for Windows. Nevertheless, I'll send a PR soon. See pull request #585 for a fix.  GITREV should be used for debuging and not in release mode.
Iteration 699: ALIGNED TRUTH : नियन कुदकि के टपि जा ... हइऽऽऽयाँ ! पैदल तऽ हइयाँ, बकि
File /tmp/tmp.21BVvgsmzO/bih/bih.SakalBharati.exp0.lstmf page 28 :
Program received signal SIGABRT, Aborted.
(gdb)
(gdb)
> Iteration 699: ALIGNED TRUTH : नियन कुदकि के टपि जा ... हइऽऽऽयाँ ! पैदल तऽ हइयाँ, बकि
> File /tmp/tmp.21BVvgsmzO/bih/bih.SakalBharati.exp0.lstmf page 28 :
tesseract -v
leptonica-1.74.1
Found AVX
Iteration 699: ALIGNED TRUTH : कृषिक्षॆत्रंचित्रपटाने साथ नयी पोस्टेड से ओलंपिक सेभोजनादिकम् सीप
File /tmp/tmp.FOELAYZPOv/bih/bih.Samanata.exp0.lstmf page 215 :
Program received signal SIGABRT, Aborted.
Iteration 496: ALIGNED TRUTH : ग़, ज़, और फ़। इसलिए आपको केवल इन पाँचों पर ध्यान
File /tmp/tmp.VitmU3pEv2/bih/bih.Mangal.exp0.lstmf page 1889 :
Iteration 497: ALIGNED TRUTH : वर्गमीटर मरे यथाशक्ति न्यायशास्त्री फैक्स। प्रेममयी सोद्देश्यवादी
Iteration 498: ALIGNED TRUTH : महीपतिया हो जुआर जसे हारे तइसे ले गआव मोरा पास जहंवा
File /tmp/tmp.VitmU3pEv2/bih/bih.Mangal.exp0.lstmf page 30 :
Iteration 499: ALIGNED TRUTH : रद्दा। रार धडधड धड घ्रघ्र धडल्ला घ्रघर्र दरारदार ऋणाधार
Iteration 499: BEST OCR TEXT : रदा रार धध ध धरधर ला धरधर दरारदार णाधार
Aborted (core dumped)
Iteration 1000: ALIGNED TRUTH : Bailey Joshua, mate, 190 Eldridge
Iteration 298: BEST OCR TEXT : Baiiey aiia, % ooter
Aborted (core dumped)
Iteration 99: ALIGNED TRUTH : च छ ज झ ञ उ ऊ ट ठ ड ढ ण ऋ ॠ त थ
File /tmp/tmp.m82dWGBYZW/mar/mar.Aparajita.exp0.lstmf page 3 :
Aborted (core dumped)
> Iteration 99: ALIGNED TRUTH : च छ ज झ ञ उ ऊ ट ठ ड ढ ण ऋ ॠ त थ
> File /tmp/tmp.m82dWGBYZW/mar/mar.Aparajita.exp0.lstmf page 3 :
Iteration 99: ALIGNED TRUTH : पुनर्व्यवस्थित अमेरिकी इंडोनेशिया
File /tmp/tmp.7Z9YtK1Bru/hin/hin.Siddhanta.exp0.lstmf page 519 :
Aborted (core dumped)
shree@sanskrit:~/tesseract$ tesseract -v
tesseract f4f66f8
leptonica-1.74.4
Iteration 199: ALIGNED TRUTH : मुद्राओं घुसपैठ व्हिटफोर्ड इंटरनेट
File /tmp/tmp.7Z9YtK1Bru/hin/hin.FreeSans.exp0.lstmf page 905 (Perfect):
Aborted (core dumped)
> Iteration 199: ALIGNED TRUTH : मुद्राओं घुसपैठ व्हिटफोर्ड इंटरनेट
> File /tmp/tmp.7Z9YtK1Bru/hin/hin.FreeSans.exp0.lstmf page 905 (Perfect):
Program received signal SIGABRT, Aborted.
(gdb)
>Unichar 1481=र्ब्रह्मघा->र्ब्रह्मघा is too long to encode!!
pixGenerateHalftoneMask
pixGenHalftoneMask
Bad box coordinates in boxfile string! ति झ. पाठः॥ 67-5 क्षयं 478 567 1002 625 83
Bad box coordinates in boxfile string! विचाराचार अध्याय श्रवस्यः योऽयं 117 3530 800 3593 259
Bad box coordinates in boxfile string! न्धिमहोदयस्य च जनवरी-मार्च 426 1260 1016 1332 345
Bad box coordinates in boxfile string! ण्टिर्गौ न्प्रा स्फो  त्फ द्भ्या अस्योद्यानं 190 2392 908 2450 434
Bad box coordinates in boxfile string! ष्पित॥ यस्य १२ मया। अर्क 418 456 969 511 463
``` @theraysmith
The common thread in all of these is that these textlines begin with words beginning with `i` matraa, which is the only combining mark in Devanagari which is rendered before the consonant it applies to.
Utf8 buffer too big, size=40 for सप्तदशोऽध्याय:
Extracting unicharset from /tmp/tmp.qLNJdHgcKr/san/Deva-test.box
Extracting unicharset from /tmp/tmp.qLNJdHgcKr/san/Deva-test-wordstr.box
> when trying to train frk
@theraysmith
While each unicode character (स ा ँ ) is there in the Devanagari unicharset, the combined akshara (साँ, छँ) is not there as part of training text/unicharset, but is there as part of eval text/unicharset.
र्ध्रु 1 0,64,61,197,280,356,0,0,280,356 Devanagari 18 0 18 र्ध्रु	# र्ध्रु [930 94d 927 94d 930 941 ]x
र्बृ 1 3,64,61,197,181,236,0,0,181,236 Devanagari 18 0 18 र्बृ	# र्बृ [930 94d 92c 943 ]x
श्चु 1 0,64,61,197,251,303,0,12,251,291 Devanagari 240 0 240 श्चु	# श्चु [936 94d 91a 941 ]x
श्चौ 1 3,65,61,255,294,367,0,12,294,355 Devanagari 240 0 240 श्चौ	# श्चौ [936 94d 91a 94c ]x
श्च् 1 3,64,61,197,251,303,0,12,251,291 Devanagari 240 0 240 श्च्	# श्च् [936 94d 91a 94d ]x
य 1 63,64,192,192,114,142,0,0,111,133 Devanagari 8 0 8 य	# य [92f ]x
श्रीः 1 3,74,61,253,295,412,0,12,295,400 Devanagari 240 0 240 श्रीः	# श्रीः [936 94d 930 940 903 ]x
ष्ठु 1 0,75,61,197,204,243,0,0,204,243 Devanagari 241 0 241 ष्ठु	# ष्ठु [937 94d 920 941 ]x
ष्ठौ 1 3,75,61,255,247,307,0,0,247,307 Devanagari 241 0 241 ष्ठौ	# ष्ठौ [937 94d 920 94c ]x
स्रैः 1 3,76,61,255,243,449,0,0,243,449 Devanagari 280 0 280 स्रैः	# स्रैः [938 94d 930 948 903 ]x
Does this mean that the training text needs to be expanded to include all possible akshara combinations?  Posted on
The result is similar with the best traineddata and current code, though there are differences between best/Devanagari, best/hin and best/san.
psm 3 treats smaller text as 'diacritics' - jpg at 600dpi
Detected 29 diacritics
Detected 145 diacritics
Detected 145 diacritics
Detected 3 diacritics
Detected 17 diacritics
Detected 17 diacritics
at ccmain/tesseractclass.h:206
```diff
// Clone to sublangs as well.
-      sub_langs_[i]->set_pix_original(pixClone(original_pix));
+      sub_langs_[i]->set_pix_original(
Wrote eng.unicharambigs
Wrote eng.punc-dawg
Wrote eng.freq-dawg
Wrote eng.cube-unicharset
Wrote eng.bigram-dawg
1:unicharset:size=7477, offset=192
2:unicharambigs:size=1047, offset=7669
6:punc-dawg:size=4322, offset=999520
7:word-dawg:size=1082890, offset=1003842
9:freq-dawg:size=1410, offset=2093158
12:cube-word-dawg:size=1062106, offset=2096079
14:bigram-dawg:size=16109842, offset=3221531
18:lstm-punc-dawg:size=4322, offset=24722091
> <https://github.com/notifications/unsubscribe-auth/AL056dfEz45RTZMO9q2Ke_chDarvPOkQks5sOOnOgaJpZM4LD3In>
(gdb)
(gdb)
(gdb)
at genops.c:644
Thanks. I had also noticed the -O2 and -O0 combinations while building with
(gdb)
ShreeDevi
ShreeDevi
> ShreeDevi
@joshimar, if you updated from an older version of Tesseract, you have to re-run `./autogen.sh` to create an updated `configure` script. The latest Tesseract version from Git always shows the reason why training tools cannot be built, so either you are using an old and buggy Tesseract code or you missed updating `configure`, too. Can you upload your full build log (output from configure and make) somewhere, so I might have a look? I need the make output as well. configure shows that OpenMP is supported. Your problem is caused by partial OpenMP support. I think that `configure --disable-openmp` will work for you (but result in slow binaries). Yes, you already said that training tools cannot be build with your 3.05 (is it the latest 3.05?).
2. this is more leptonica build problem (allowed warnings)
> @theraysmith
> > > 5deebe6
> > AL056XMVGWYPqK1Pc8XzqTxrzYjHZxgZks5rFS4MgaJpZM4LCRAs>
2. I tried to transfer fixes to 3.05 branch. 3.05 should be possible to build without c++11 need (I am slow because I have limited time and I can test (just build) it on VS2010 in limited scope...)  The alternative variant of InitCharset is used internally at Google to save accessing the script-dir directory from a trainer running in a Google data center. It is easier to pack the unicharset and recoder in a proto buffer in a separate step. If anything the other variant could prepare the recoder and then call the one that takes a recoder. I rebased the PR now to fix a merge conflict in `lstm/lstmtrainer.cpp`. Continuous integration fails because of missing `tesseract::LSTMTester::LSTMTester(long)`. This is unrelated to this PR. I rebased to fix the build with CMake in the continuous integration. Thanks, I knew that. In this case the trick would not have worked because the CI problem was only fixed in git master.  Rebased PR to fix merge conflict.  You could use https://cppan.org/ also. It's already present in repository. I won't be adding vcpkg port. If someone else needs this, please do it.  See [forum](https://groups.google.com/forum/#!topic/tesseract-ocr/e__2DN1GQb0) or [wiki info](https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00#for-open-source-contributors).  The  « un animal politique » is right there in your example. Not sure what the problem is.
Changing urls of old(er) pages is IMO bad idea - it will break links on other pages/projects... @amitdo: can you please clarify? I think  fresh new wiki page titles could be changed...  You can sent pull requests...  Please use tesseract user forum for asking support.  Please provide all input files Please provide also information about tesseract version and OS. @sjaanus Is your issue resolved? Please mention the solution and close the issue.  AFAIK there is the limit for [system variable](https://blogs.msdn.microsoft.com/oldnewthing/20100203-00/?p=15083) - but I am not sure if this is a case also in Windows 10.
@egorpugin  can you have a look on this?
@datalurkur Do you use the latest CPPAN client? If not try to update it. If yes I need to investigate this more closely, maybe with more help from you.
It's cppan issue. I'm investigating.
@datalurkur Is it possible to chat with you somewhere (maybe skype etc.) and also could you share your desktop with me (in skype again or teamviewer)?
2. list of processes (maybe cppan or cmake hangs)
3. files on disk in `c:\Users\u\AppData\Local\Temp\cppan\vars\`
And more here - could you please then (after hang occurs) archive the whole `c:\Users\u\AppData\Local\Temp\cppan\vars\SomeRandomLetters` dir and send it to me (attach here).
1. initial cmake call is waiting for cppan
2. cppan is waiting for cmake children
2. Kill all hanged cmake processes.
3. Go to `c:\Users\u\AppData\Local\Temp\cppan\vars\SomeRandomLetters\YouCmakeHangProcessLastDirNumber`)
4. Run in that dir `cmake .`
Yes, you can try to remove the whole storage dir at `c:\users\u\.cppan\storage\`.
But...
You revealed our secret! :)
Wow, this is really extreme!
OR
Detected 1875 diacritics
Detected 1338 diacritics
Detected 1885 diacritics
Detected 658 diacritics
Detected 213 diacritics
It 'thinks' the speckles are diacritics...
black and white. If you know you are working with black and white images, you can
feed to Tesseract (assuming you don't want to do any additional cleaning or something.)
This workflow is kind of sophisticated and maybe not easy for everyone. But it makes
/DecodeParms [61 0 R]
> Jeff, your last two messages look cryptic...
> If you have been abducted by aliens, try give us a sign and we will rescue you! :)
LOL
It's good to know Morse code, or maybe just to find an online Morse code translator... :)
Also, Arabic uses a special OCR engine 'Cube' which isn't maintained anymore. It will be replaced by a better engine in the next release.
Strange behaviour...
FYI, OpenCL support is [quite buggy](https://github.com/tesseract-ocr/tesseract/issues?q=is%3Aissue+is%3Aopen+label%3AOpenCL)
That means it requires Pango >=1.22.0:
> // The generated list of font families and faces includes "synthesized" font
> // **Until then**, we are restricted to using a hack...
cppan --self-upgrade
cd your_tesseract_dir
cppan
It seems that first error is in the zlib.
-- Preparing build tree for pvt.cppan.demo.zlib-1.2.8 with config amd64-msvc-19.0-32
Could you also attach `C:/Users/jarek/.cppan/storage/obj/ec/64/e827/build/amd64-msvc-19.0-32/CMakeFiles/CMakeOutput.log` and `CMakeError.log` from there?
See https://github.com/cppan/tesseract_example
@egorpugin - Can you have a look at this?
The modern variable is 'CPPAN_BUILD'.
https://sourceforge.net/projects/tesseract-ocr-alt/files/
@nguyenq wrote:
304: Trebuchet MS Bold Oblique
305: Trebuchet MS Oblique
306: Verdana
307: Verdana Bold
308: Verdana Bold Oblique
309: Verdana Oblique
310: Yu Gothic
311: Yu Gothic Bold
312: Yu Gothic Bold Oblique
313: Yu Gothic Light, Light
314: Yu Gothic Medium, Medium
315: Yu Gothic Medium, Medium Oblique
316: Yu Gothic Oblique
39: Arial Black,
364: Roboto Condensed,
365: Roboto Condensed, Bold
366: Roboto Condensed, Bold Italic
367: Roboto Condensed, Italic
https://github.com/tesseract-ocr/tesseract/blob/61032d9b14e1/training/pango_font_info.cpp#L523
Maybe that's what we should do in Tesseract...
@billydekid
@billydekid: Does it mean that have to install pango-dev to fix problem? If yes, that it is bug that need to be fixed! (in this case please reopen this issue)
`libcogl-pango-dev` is not needed by Tesseract!
`libcogl-pango-dev` has these dependencies:
libpango1.0-dev
libcairo2-dev
I believe that currently Tesseract still supports older C and C++ standards. Your patch will change this situation...
1. Some tools use libraries that are not common on Windows. I do not think it is worth to invest time  in testing windows implementation of these libraries.
@nguyenq
text2image --text=vie-data.txt --outputbase=vie.arial.exp1 --font="Times New Roman" --fonts_dir=C:\Windows\Fonts
@Shreeshrii: "--fonts_dir=" is wong argument
@nguyenq
>  "--fonts_dir=" is wong argument
@wanghaisheng, short answer: No.
My user name is @amitdo, not amido :)
https://github.com/GNOME/pango/blob/master/pango/pangocairo-fontmap.c#L48
putenv("PANGOCAIRO_BACKEND=fc");
setenv("PANGOCAIRO_BACKEND", "fc", 1);
@vkoushik: if it throwed you error it means you made something wrong (installation). Fix your installation instead of  adjusting manual to your mistakes. Your suggestion would not work for those who use packaged prepared by their distributor (windows or linux).
tesseract pdfsandwich45aaf9.tif pdfsandwich45aaf9 -l nld+eng pdf In tessdata repository there are 4.00 data files and you use 3.05 tesseract...
This output does not look like it is coming from Tesseract command line program...
> => Trained on synthetic (rendered, distorted) data
I wonder why Gentoo, which is supposed to be a bleeding edge distro, does not have a package for the newer Tesseract version 3.04**.01**.
``` c++
zdenko is the build king, he can decide such things
I mean bug #233
Also what is HAVE_TIFFIO_H? It is not defined in tesseract build system, so it will be turned off.
Tesseract uses leptonica API, so maybe it's better to contribute there and use its API later.
Is it possible via leptonica API? I see some comments from Dan B. there.
It's strange a bit. Does OpenCL really need this? I.e. leptonica can not provide required interfaces? Or opencl is only implemented for tiff images?
while (offset = ThankYouSirMayIHaveAnother(offset)) {
// tesseract side
// call to leptonica
free(offsets);
Did you used the `-F` flag?
All the errors except the last one are coming from [leptonica](https://github.com/DanBloomberg/leptonica).
File input/output is handles by leptonica.
Anyway your experience is strange. I build tesseract (and leptonica) as non privileged user and install it with `sudo` and I never have this problem.
--- leptonica/src/utils.c   2016-06-13 16:53:20.000000000 -0700
+++ leptonica/src/utils.c   2016-07-19 12:19:39.000000000 -0700
*          (c) there is the possibility of an attack where the intruder
-l_int32  i, buflen, usec, pid, emptytail;
-    buflen = sizeof(buf);
-    else
[(�A)-500(�N)-500(�D)-500]TJ
[(�R)-500(�E)-500(�L)-500(�A)-500(�T)-500(�I)-500(�V)-500(�I)-500(�T)-500]TJ
@matzeri?
@matzeri
Strange. It looks fine now.
Pinging @matzeri...
Hi Marco!
My own patch to 'pango_font_info.cpp'
After that, re-install leptonica and then tesseract.
@egorpugin
@nickbe
@egorpugin
@egorpugin
@egorpugin
Do you have any guess why it does not work for @nickbe (the old build)?
Since both @nickbe and @egorpugin confirm that the PDF renderer feature works in the newer VC build, I'm closing this issue for now.
- PDFium (Chrome/Chromium)
- Evince (poppler)
If the SumatraPDF engineer wants someone to talk to, send them my way.
@zdenop
You missed `AC_PREREQ`.
!strcmp(current_arg, "helpshort")) {
Another issue.
@reubano
I added  'tesserocr' to the AddOns wiki.
@reubano, thanks for the suggestion.
Do you get `ara` in the output?
Do you have installed arabic cube files (e.g. [ara.cube.lm](https://github.com/tesseract-ocr/tessdata/blob/master/ara.cube.lm))?
Your unicharset file looks wrong.
These specific warnings are confusing, but everyone gets them, so they should be ignored.
You can find the `*.unicharset` files here: https://github.com/tesseract-ocr/langdata
@ggdhines
> CAVEATS
N 5 59,68,216,255,87,236,0,27,104,227 Latin 11 0 1 N
Y 5 59,68,216,255,91,205,0,47,91,223 Latin 33 0 2 Y
a 3 58,65,186,198,85,164,0,26,97,185 Latin 56 0 5 a
W 5 Latin 40
Two last notes:
Pinging @nickjwhite ...
There are "CFLAGS", "CPPFLAGS",  "CXXFLAGS".
Opencl is still experimental feature with a lot of open issues (and original committer is not fixing them...)
Hi Zdenko!
I added a note about the state of OpenCL in Tesseract to this wiki page:
https://github.com/tesseract-ocr/tesseract/blob/d8c04e8/training/language-specific.sh#L308
JPN_FONTS=( \
"TakaoExGothic" \
"TakaoExMincho" \
"TakaoGothic" \
"TakaoMincho" \
"TakaoPGothic" \
"TakaoPMincho" \
If you want to train Tesseract, use one of these guides:
https://github.com/tesseract-ocr/tesseract/wiki/tesstrain.sh
> But isn't it clearly a bug? ocropus-rpred has no problem with bad.jpg.
`tesseract arabic_4.jpg stdout -psm 0 -l osd`
please report issue at pytesseract project
> Basically what I want to achieve is to ask Tesseract to recognize only complete words included in my custom dictionary (lang: chi_sim)
AFAIK it is not possible within tesseract.
@vidiecan, please, can you respond to @zdenop and @stweil?
https://github.com/tesseract-ocr/langdata
but don't repeat calling/mentioning those 2 people.
Please see https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/Qp2cIrcajX4/CF0uohuUAwAJ
Wrote eng.unicharambigs
Wrote eng.punc-dawg
Wrote eng.freq-dawg
Wrote eng.cube-unicharset
Wrote eng.bigram-dawg
1:unicharset:size=7477, offset=192
2:unicharambigs:size=1047, offset=7669
6:punc-dawg:size=4322, offset=999520
7:word-dawg:size=1082890, offset=1003842
9:freq-dawg:size=1410, offset=2093158
12:cube-word-dawg:size=1062106, offset=2096079
14:bigram-dawg:size=16109842, offset=3221531
18:lstm-punc-dawg:size=4322, offset=24722091
Version string:4.00.00alpha:eng:synth20170629
18:lstm-punc-dawg:size=4322, offset=401828
18:lstm-punc-dawg:size=4322, offset=11689291
IMO it is clear "pango/pango-font.h: No such file or directory".
Pango 1.38 was released in 2015-09-21.
pango_attr_font_features_new(features_);
https://github.com/amitdo/text2tif
Off-topic, but this might interest you as well:
https://github.com/eddieantonio/isri-ocr-evaluation-tools
- Version of Tesseract.
@amitdo: it confirms that it is not tesseract problem but bad practice of writing code using ["namespace std"](http://stackoverflow.com/questions/1452721/why-is-using-namespace-std-in-c-considered-bad-practice) which is real root of ambiguity.
- In training/pango_font_info.cpp
> $ cp ./tessdata/san.traineddata /usr/local/share/tessdata
https://help.ubuntu.com/community/RootSudo
``` c++
// Leptonica is used to find the rule/separator lines in the input.
&vertical_x, &vertical_y, music_mask_pix,
pixWrite("tessnolines.png", pix_binary_, IFF_PNG);
// Leptonica is used to find a mask of the photo regions in the input.
``` c++
``` c++
Zdenko
Thanks Shree.
In addition, explicitly added are:
timestep, and that is difficult to achieve with the recurrent nature of the
Shree,
cd path/to/leptonica-1.73
cd path/to/tesseract-ocr
Shree,
Hi zdenop, thanks for your quick response.
Le Duc. Nam
gdb tesseract
at baseapi.cpp:1064
at baseapi.cpp:1183
at baseapi.cpp:1081
Hi @amitdo and @zdenop,
But the FAQ should be fixed.
Zdenko
tesseract z.png - -psm 10
https://github.com/tesseract-ocr/tesseract/blob/master/training/language-specific.sh
>     "Verdana Bold" \
>     "Verdana Italic" \
>     "Verdana" \
>     "Verdana Bold Italic" \
>     "DejaVu Sans Ultra-Light" \
Did you oversaw #ifndef GRAPHICS_DISABLED ?
@szpeak
// 24 bit.
Oops  I made a mistake.
The mystery thickens...
![nak-thresholded](https://cloud.githubusercontent.com/assets/17527508/13445556/31b3e2fe-e00d-11e5-916c-b35465a16e4e.png)
- the result differs if the color to gray conversion is done here or further in the threshold process.
What bugs me is that the results differ according to image encoding and not image content, because it triggers different processing paths.
[242-bad-gimp-rgb](https://cloud.githubusercontent.com/assets/13571208/13510330/b88b6180-e198-11e5-8840-d92a48c91cfa.png)
[242-bad-gimp-gray](https://cloud.githubusercontent.com/assets/13571208/13510357/d83809a2-e198-11e5-934c-7f273a4bb35d.png)
tesseract -l fra bad-gimp-rgb.png stdout
La mort a eu lieu
tesseract -l fra 242-bad-gimp-gray.png stdout
La mort a eu lieu
La mort a eu lieu
bool white_result = true;
reinterpret_cast<const void *>(linedata)),
In the case of these subtitles where, who knows why, ProjectX added a dark-blue background, selecting the red or green plane gives the best contrast between text and background, and leads to good results (which happens by chance on 'ok.png', would'nt work if ProjectX had chosen red background)
It is in fact in leptonica.
In that case, the colormap is converted to gray with this code:
So it is leptonica which uses this quick formula, although speed should not really be a concern here as it is applied just to the colormap, not the full image.
Tesseract does not work without leptonica.
@roozgar
With LSTM, OCR for printed Arabic (not real handwrite) can reach 95% character accuracy.
"Offline Printed Urdu Nastaleeq Script Recognition
@tbadran
مداها ينم همهما
اللغة العريية
لغة جهد مه
مسنره هي انحاء العالم
![test_ara](https://cloud.githubusercontent.com/assets/17473681/13320324/bc160e22-dbd0-11e5-8090-6f3728fcc06d.jpg)
@roozgar
مداها ينم همهما
اللغة العريية
لغة مسنره هي انحاء العالم
Maybe explicitly using unicode bidi control characters can help ?
In writing systems that are read from right to left (such as Arabic or Hebrew),
[ .. then continues into a horrendous discussion of writing everything backwards ... ]
``` c++
double theta = atan2(static_cast<double>(line_y1 - line_y2),
Support for RLI and PDI has been added in Unicode **6.3**.
``` c++
do {
Hi @Shreeshrii!
As said before, once the new LSTM code will finally land in Tesseract's public Github repo, the OCR accuracy of Arabic and Persian will be [dramatically improved](https://github.com/tesseract-ocr/docs/blob/master/das_tutorial2016/7Building%20a%20Multi-Lingual%20OCR%20Engine.pdf). Cube's code will be removed, so any issue with it will be irrelevant.
Okay, this bug has been open forever. As mentioned before, most PDF files deal with right-to-left (RTL) languages like Hebrew and Arabic by laying out the characters from left-to-right (LTR) but doing it backwards. This offends my programming sensibilities on many levels, and I've resisted this approach. But maybe it is time to swallow pride and wallow in the mud.  Here's a few examples from the test suite. How  is compatibility for search and copy-paste?
Arabic
[heb_mivne.pdf](https://github.com/tesseract-ocr/tesseract/files/947854/heb_mivne.pdf)
-// of the text. If the text is right-to-left such as Arabic or Hebrew,
-                  int line_x1, int line_y1, int line_x2, int line_y2,
+void AffineMatrix(int line_x1, int line_y1, int line_x2, int line_y2,
double theta = atan2(static_cast<double>(line_y1 - line_y2),
*b = sin(theta);
// There are some really awkward PDF viewers in the wild, such as
-      AffineMatrix(writing_direction,
+      AffineMatrix(line_x1, line_y1, line_x2, line_y2, &a, &b, &c, &d);
+    // Gather up unicode codepoints for the word
do {
-          int code = unicodes[i];
+      unicodes.reverse();
+    for (int i = 0; i < unicodes.length(); i++) {
+      int codepoint = unicodes[i];
``` So far, just Pdfium/Chrome/Linux   AdobeReader9/Linux  Preivew/MacOSX.  I've asked a few different groups of people to take a look. @christophered Can you please take a look at ara.pdf above and tell me if it works well for you? @christophered Thanks, that's a very helpful report. I expect it to be equal to or better than what Tesseact does now for producing PDF of Arabic.  Note that my change is just about PDF generation and does not touch the recognization process in any way. It is just stock Tesseract 4.0  support for Arabic.
[heb_mivne.pdf](https://github.com/tesseract-ocr/tesseract/files/956614/heb_mivne.pdf)
`TESSERACT_OPENCL_DEVICE=1 tesseract 11002612_2_0183.jpg 11002612_2_0183 -l ara+fra`
I suggest changing the title so it will contain the word "Arabic" or "ara".
> Fixed issues 899/1220/1246 (mixed eng+ara)
Hi @anupamaray !
tesseract /tmp/11002612_2_0183.jpg /tmp/11002612_2_0183 -l ara+fra --oem 0
Found AVX
[DS] Selected Device[2]: "(null)" (Native)
The crash is obviously unrelated to OpenCL, as it crashed here without using OpenCL. It was also sufficient to specify `-l ara` in my test. Last time we talked Ray said he was leaning toward deletion of the non-LSTM
Problem still there in 3.05.01
Arabic can be used ONLY in --oem 1 mode (cube in 3.05).
However, what would be the result if the second language does have --oem 1 option.  First of all: Please use tesseract forum for asking support - see [FAQ](https://github.com/tesseract-
ocr/tesseract/wiki/FAQ#rules-and-advice)
Next PIX is leptonica structure - you can get it with leptonica.pixRead(filename)
while (offset = ThankYouSirMayIHaveAnother(offset)) {
``` diff
Then lets wait for new leptonica release. IMO it would be fine to fix OpenCL too - I got promises that somebody should have a look at opencl issues...
patch from 2016-03-29 committed as 54fafc4e2e9e2941b643f6cef67a7ec7e0b8bb49
@roozgar
and Chromium?
There is a plan to add a new ocr engine to tesseract this year. There is a good chance that the accuracy of arabic and indic languages recognition will be improved.
http://sourceforge.net/projects/tesseract-ocr-alt/files/
@bantilan: please add it https://github.com/tesseract-ocr/tesseract/wiki/Compiling#windows (every github used can modify it)
@egorpugin, can you confirm this?
@nickbe, one more (unofficial) option for Windows:
cd tesseract
cppan
Sorry for the noise.
@egorpugin: thanks! I tried it in VS2010 and I face one problem:
Because of the following:
tesseract is binded to leptonica (some version, e.g. future 1.74);
leptonica is binded to giflib (e.g. v5.1.2).
So you cannot control leptonica's dependencies.
https://github.com/cppan/tesseract_example
http://sourceforge.net/projects/tesseract-ocr-alt/files/
`tesseract i202-2.png i202-2`
(garbage)
Also, please provide any error message you get.
cc: @behdad
Behdad, maybe you can help here?
@LinusU ?
@jbarlow83, anyone with a mac...
HI @atuyosi!
@atuyosi, thanks for testing. The output files look okay.
@diotteo
@zdenop, any preference?
@egorpugin Can you have a look on this?
Tesseract really has bad directories structure.
All tests failed because @egorpugin made changes in his leptonica repo.
~~https://github.com/egorpugin/leptonica
https://github.com/egorpugin/leptonica_old~~
Keep calm. We're setting an official leptonica repository this time.
@behdad, try this:
Strange!
howls of protests over the other missing ingredients first, like big-endian
over C++11 probably doesn't have the horsepower to run 4.00 at a reasonable
> <https://github.com/notifications/unsubscribe-auth/AL056QF3tQJra8WTACr_cvaeVjUG0yP6ks5rBdmWgaJpZM4G6wao>
@vov4ik829,
> For right-to-left languages (RTL) use option "-r 1".
https://github.com/tesseract-ocr/tesseract/wiki/tesstrain.sh
https://github.com/tesseract-ocr/langdata/blob/master/ara/ara.config
> tessedit_ocr_engine_mode 1
ShreeDevi
> <https://github.com/notifications/unsubscribe-auth/AE2_ozNSJAJOADt4YTvs6TLIAMnHaa7Vks5sFoeSgaJpZM4GzPQj>
libtool: link: ranlib .libs/libtesseract.a
libtool: link: rm -fr .libs/libtesseract.lax
make[2]: Leaving directory `/home/amit/ocr/tesseract/tesseract/api'
make[2]: Entering directory `/home/amit/ocr/tesseract/tesseract'
make[2]: Leaving directory `/home/amit/ocr/tesseract/tesseract'
Making all in tessdata
make[2]: Entering directory `/home/amit/ocr/tesseract/tesseract/tessdata'
make[3]: Entering directory `/home/amit/ocr/tesseract/tesseract/tessdata/configs'
make[3]: Leaving directory `/home/amit/ocr/tesseract/tesseract/tessdata/configs'
make[3]: Entering directory `/home/amit/ocr/tesseract/tesseract/tessdata/tessconfigs'
make[3]: Leaving directory `/home/amit/ocr/tesseract/tesseract/tessdata/tessconfigs'
make[3]: Entering directory `/home/amit/ocr/tesseract/tesseract/tessdata'
make[3]: Nothing to be done for `all-am'.
make[3]: Leaving directory `/home/amit/ocr/tesseract/tesseract/tessdata'
make[2]: Leaving directory `/home/amit/ocr/tesseract/tesseract/tessdata'
make[2]: Entering directory `/home/amit/ocr/tesseract/tesseract/doc'
make[2]: Leaving directory `/home/amit/ocr/tesseract/tesseract/doc'
make[1]: Leaving directory `/home/amit/ocr/tesseract/tesseract'
Which file use unicharambigs file v2?
You missed this typo:
Imagemagick "convert":
Tesseract layout analysis gets really confused with the 'bad' image.
@amitdo: tesseract executable was(is) simple example how to use tesseract library. AFAIK nobody plan to implement smart handling of options (e.g. you still need to provide some information in specific order)... So the correct result of your option combination is side effect... ;-)  See e.g. https://github.com/tesseract-ocr/tesseract/issues/147#issuecomment-155892373
I am not sure if this is the right way of dealing with such warning:
I have used this from deu_frak model
LANGCODE=deu_frak
tesseract $i ${i%.tif} nobatch box.train
unicharset_extractor *.box
cat unicharset | sed -e "s/^([æøåäöüâêàèéçß][a-z]_) 0/\1 3/" \
-e "s/^([ÆØÅÄÖÜÂÊÀÈÉÇ][a-z]_) 0/\1 5/" \
-e "s/^½ 0/½ 8/" | sed -e "s/^([æøåäöüâêàèéçßa-zÆØÅÄÖÜÂÊÀÈÉÇA-Z]._) NULL /\1 Latin /" \
do mv -f $i $LANGCODE.$i
Main problem: the output text is misleading ("configure: error: leptonica library missing").
@amitdo: I prefer to see whole help as default (as today) when I run "tesseract" or "tesseract -- help".
@amitdo: No it is not (at least for me). I wrote: I prefer to see whole help as default (as today) when I run "tesseract" or "tesseract -- help".
@amitdo: I will recheck it - I got different out when I wrote my comment.
Does the word 'tor' appear in one of the word lists?
@zdenop
@zdenop
@wasamasa: use can use parameter quiet:  `tesseract eurotext.tif eurotext quiet`
What are trying to do???
@amitdo: Future is cmake. There is no sense to make and maintain  build system for each version of cmake. cmake correctly detect installed compiler and use it. We are just waiting for leptonica transfer to github, there cmake will be presented to.
https://github.com/DanBloomberg/leptonica
AFAIR problem is in custom training.
@jflesch: I am currios: Why you call tesseract executable from python instead of using C-API? IMO it should be faster...
```diff
--- tesseract/api/baseapi.h     2015-03-09 15:43:40.000000000 -0700
+++ tesseract/api/baseapi.h     2015-08-18 17:52:49.000000000 -0700
+  // variable will hopefully reduce confusion if the situation changes
--- tesseract/api/renderer.h    2014-08-12 11:22:47.000000000 -0700
private:
There's a quote I like from the movie Jerry Maguire. Right before the more famous 'show me the money' line, there's 'help me help you'. It comes up a lot in open source.
configure: error: conditional "OPENMP" was never defined.
fi
-AC_OPENMP
+#AC_OPENMP
AC_SUBST(AM_CPPFLAGS,"$OPENMP_CXXFLAGS")
Thread model: posix
regading leptonica: Try to change line if it helps:
`LIBLEPT_HEADERSDIR="/usr/local/include /usr/include /opt/local/include/leptonica"`
[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
![mono](https://cloud.githubusercontent.com/assets/1825843/9775499/7c03cee2-5704-11e5-90fc-1aafddde9138.png)
As a sidenote, it would have been helpful if you could have made it clear that the issue was, in fact, an issue, by phrasing it as such: "tarballs not provided for traineddata" is an issue; "what is the official source...?" is a support question.
@vzani: when you start gdb, please enter command:
@rodrigosalinas
Which commit exactly, 1826ac14 ?
Commit  1826ac1.
> find /usr -name "tesseract"
`tesseract ult.dejavu.exp0.tif ult txt hocr`
I solved @aiwaz issue. More info will follow later.
@aiwaz, please test my fix.
other cygwin users.
Ok, that's a different error. Do you have ICU4C installed?
Sorry, it only complained about one of the ICU libraries.
I think that the problem is that the library is named 'libicui18n' under Cygwin, as it is on Linux etc.
that means that leptonica was not compiled with tiff support
--- a/api/tesseractmain.cpp
+++ b/api/tesseractmain.cpp
The quick brown dog jumped over the
over the lazy fox. The quick brown dog
==21845== LEAK SUMMARY:
==11238== LEAK SUMMARY:
I am not sure what do you mean with  "any other dependencies except leptonica" - to run tesseract with opencl support you need libtiff and opencl sdk that support your hardware...
ng profiling.
[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
The quick brown dog jumped over the
over the lazy fox. The quick brown dog
AM_INIT_AUTOMAKE([foreign])
Tess+Cube | 11.0 | 24.2 | 25.4 | 5.7 | 5.3
There may be a debate as to the value of the old Tesseract engine for its
analogous to Ye Old Shoppe for English?
This adds support from the ocricola project to use finite state transducers in HFST format instead of DAWGs.
prev_fuzzy_sp = fuzzy_sp;
prev_fuzzy_non = fuzzy_non;
#1 ettl.martin78
* **Commit Number**: eba0ae3b88a46a93e981770caa0b148d65cc4468
tesseract.exe C:\Test.tif C:\Test -l deu+eng --psm 1 --oem 1 pdf
tesseract.exe C:\Test.tif C:\Test -l deu+eng --psm 1 --oem 0 pdf
tesseract.exe C:\Test.tif C:\Test -l deu+eng --psm 1 --oem 1 pdf
Multiple times:
Why should the compiler used to build leptonica make any difference?
Signed integer overflow behaviour is undefined per C++11 standard.
wrap.so: undefined reference to `pixExpandReplicate'
wrap.so: undefined reference to `pixaCreate'
wrap.so: undefined reference to `sem_wait'
Im struggling to build tesseract for 3 days now
./configure: line 17577: syntax error near unexpected token `LEPTONICA,'
Any help appreciated  If you installed pkg-config after you ran autogen.sh, re-run autogen.sh.  @amitdo i re-run autogen.sh a million times already... :( Leptonica is built from source:
checking for mbstate_t... yes
checking for mbstate_t... yes
./configure: line 17577: syntax error near unexpected token `LEPTONICA,'
--with-extra-includes=$(pkg_path_for tpolekhin/leptonica)/include \
--with-extra-libraries=$(pkg_path_for tpolekhin/leptonica)/lib
-I/hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/include/leptonica
-L/hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/lib -llept
./configure: line 17577: syntax error near unexpected token `LEPTONICA,'
`LIBLEPT_HEADERSDIR=$(pkg_path_for tpolekhin/leptonica)/include`
`LIBLEPT_HEADERSDIR=$(pkg_path_for tpolekhin/leptonica)/include/leptonica` So this means nothing?
-I/hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/include/leptonica
-L/hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/lib -llept
`PKG_CONFIG_PATH=/hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/lib/pkgconfig`
ll /hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/lib/pkgconfig
`PKG_CHECK_MODULES([LEPTONICA], [lept >= 1.74], [have_lept=true], [have_lept=false])`
ACLOCAL='${SHELL} /hab/cache/src/tesseract-3.05.01/config/missing aclocal-1.15'
``` @zdenop tried `ACLOCAL_FLAGS="-I /hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/" ./autogen.sh` with same error :( Did you install `autoconf-archive` (or another package needed for your Linux distribution which provides the macro `PKG_CHECK_MODULES`? okay, so the issue was that `automake/share/aclocal/` was missing `pkg.m4` The `PKG_CHECK_MODULES` macro comes from `pkg-config`
![tesseract_version](https://user-images.githubusercontent.com/17153459/33108746-5759945a-cf70-11e7-99e7-9561fc79212d.png)
@amitdo
@egorpugin
leptonica is currently supporting 4.1.6 and 5.0, as well as 5.1+.
And I expect to have a new leptonica release in Dec or Jan that Jeff will
Start by calling only Leptonica functions:
यादी भाग क्रमांक : 2
वडीलांचे नांव : महाजन मोहन Photo वडीलांचे नांव : महाजन कोंडीराम Photo वडीलांचे नांव : महाजन भानुदास Photo
वडीलांचे नांव : महाजन कोंडीराम Photo पतीचे नांव : महाजन नाथा Photo पतीचे नांव : महाजन नाथा Photo
वडीलांचे नांव : देसाई हरीभाउ Photo वडीलांचे नांव : महाजन कोंडीराम Photo पतीचे नांव : महाजन भानुदास Photo
वडीलांचे नांव : देसाई नानासाहेब Photo पतीचे नांव : देसाई बद्रीनाथ Photo पतीचे नांव : देसाई बाबासाहेब Photo
पतीचे नांब : देसाई योगेश Photo पतीचे नांव : देसाई सतीश Photo वडीलांचे नांव : महाजन मोहन Photo
पतीचे नांव : महाजन धोंडीराम Photo वडीलांचे नांव : महाजन धोंडीराम Photo वडीलांचे नांव : महाजन धोंडीराम Photo
वडीलांचे नांव : महाजन खंडू Photo वडीलांचे नांव : गाढेकर लिंबा Photo पतीचे नांव : गाढेकर भावराव Photo
वय: 30० लिंग ` पुरुष वय: 6१ लिंग ` पुरुष वय: 6० fr ‘@t
वडीलांचे नांव : गाडेकर भाउराव Photo पतीचे नांव : महाजन कैलाश Photo पतीचे नांव : लिबोरे नंदू Photo
ans os लिंग ` पुरुष वय: 26 लिंग : स्त्री वय: 44 लिंग ‘@t
01/01/2017 रोजी < aa ran नौयणी अधिकारी याच्या गरे पृष्ठ क्रमांक : 3
shell(shQuote(paste0("pdftopng -f 1 -l 10 -r 600 ", i, " ocrbook")))
However, even though I am feeding it a PNG file, I get the error
Tesseract 3.05.01
tesseract 3.05.01
leptonica-1.74.1
lapply(mytiffs, function(z){
I tried tessdata, tessdata_best, and tessdata_fast
![arabnum](https://user-images.githubusercontent.com/32733104/32214946-29824b06-be29-11e7-9858-a5649222e41b.jpg)
* **AEN** Arabic Eastern Numbers {ِ123456789}
* **AWN** Arabic Western Numbers {0123456789}
I generated an experimental data file for recognaize **AEN Only**
[https://github.com/ahmed-tea/tessdata_Arabic_Numbers](url)
Combining with ara
@Shreeshrii  @Shreeshrii  sorry for the question, how to combine the new tessdata_Arabic_Numbers with the current one?
`tesseract -l ara_number+ara  image.tif out.txt`
@Fahad-Alsaidi You can't combine it with ara   Hello,
18:lstm-punc-dawg:size=4322, offset=11689291
Original Traineedata
18:lstm-punc-dawg:size=4322, offset=11689291
cppan
cmake ..
> LINK : fatal error LNK1104: cannot open file “Debug\unicharset training.lib
pvt.cppan.demo.freedesktop.fontconfig.fontconfig-2.12.1.dll
pvt.cppan.demo.gnome.pango.pangocairo-1.40.9.dll
tesseract400d.dll
tesseract400d.ilk
tesseract400d.pdb
> over the lazy fox. The quick brown dog
tesseract /tmp/tr_tmp.jpg /tmp/tr_tmp --tessdata-dir /var/task/tessdata --psm 12 --oem 2 -l eng hocr
related binaries:
When tesseract v4 using `--oem 2` and legacy trained data, error message of missing LSTM data should be printed instead of crashing.
However, tesseract should not crash
i was able to do all these steps and get the final traineddata but when i made detection using it i got an error, now the same case happened for Arabic and Japanese languages, and both i was able to get fine tuned traineddata and both failed in detection and gave the same error.
--continue_from /home/ubuntu/lep_latest/ara_tune/extracted/ara.lstm \
--train_listfile /home/ubuntu/lep_latest/ara_tune/ara.training_files.txt \
that happened when i tried fine tuning for Arabic and Japanese, twice, first time using the version:
**tesseract 4.00.00dev-690-g1b0379c   leptonica-1.74.4**
second time: **tesseract 4.00.00dev-691-gfb359fc  leptonica-1.74.4**
--train_listfile /home/ubuntu/lep_latest/ara_tune/ara.training_files.txt
Failed to continue from: /home/ibr/latest_leptonica_4/ara_tune/extracted/ara.lstm
First, I build the tesseract-ocr which is successful.
2 build leptonica from source(leptonica-1.74.4)
3 build tesseract-ocr
./configure --prefix=/usr/local/tesseract --with-extra-libraries=/usr/local/leptonica/lib
1 yum install libicu-devel
2 yum install pango-devel
3 yum install cairo-devel
But it comes the following error
dir == U_ARABIC_NUMBER || dir == U_RIGHT_TO_LEFT_ISOLATE) {
Command '['tesseract', '/tmp/tr_tmp.jpg', '/tmp/tr_tmp', '--tessdata-dir', '/var/task/tessdata', '--psm', '12', '--oem', '2', '-l', u'eng', 'hocr']' returned non-zero exit status -11: CalledProcessError
'hocr',
CalledProcessError: Command '['tesseract', '/tmp/tr_tmp.jpg', '/tmp/tr_tmp', '--tessdata-dir', '/var/task/tessdata', '--psm', '12', '--oem', '2', '-l', u'eng', 'hocr']' returned non-zero exit status -11
Environment
@Shreeshrii I changed the tesstrain.sh file and the command could copy the box/tiff pairs to the tmp training directory.
but there was another error as following:
Pango suggested font FreeSerif Bold.
$ tesseract eng.num.exp2.tif eng.num.exp2 -psm 7 nobatch lstm.train
Dou you know the function of "nobatch" ? Have you used it in tesseract command ?
$ unicharset_extractor chi_sim.black.exp0.box
Extracting unicharset from box file chi_sim.black.exp0.box
Invalid Unicode codepoint: 0xffffffe4
@Shreeshrii
@Shreeshrii
ps. I have this error also on korean characters, for all the characters.
tesseract day_2_60_0_G3.cfont1.exp0.tif day_2_60_0_G3.cfont1.exp0 -l dianoche2 -psm 7 nobatch box.train
tesseract 3.05.01
leptonica-1.74.4
![Black and white image of pill bottle with text "NPN 80051578" sideways](https://imgur.com/SOJFK2f.png)
mhmﬁmoowuzgz
SEEESaEmS 2:
[junk maybe]
[junk maybe]
@amitdo PSM 12 is the only one that works (with the new image), but that's only if I run Tesseract with a config file I made:
load_freq_dawg          F
Not reopening this since there is nothing the Tesseract devs can do here, this is a Leptonica issue.  I am getting compile errors when compiling my bindings with `clang++ -std=gnu++11` (MacOS 12.13). This fixes it for me. See pull request #1082 and other pull requests and issues which address the same problem.  I must confess to not being a CMake expert, but I found [this mailing list post](https://cmake.org/pipermail/cmake-developers/2016-May/028364.html) that seems to confirm my suspicion that the `FindPkgConfig` module doesn't fix up the library search path to allow linking against the libraries it has found.
CC: @egorpugin   I have refered solutions like below:
https://groups.google.com/forum/#!topic/tesseract-ocr/3e4dV373u_o
But they do not work at all!
https://github.com/nagexiucai/milk-powder/commit/cd0aed443af6aa084da721d48bd107e92934544d
Reading .\pictures\chi_sim.CHei_PRC.exp0.tr ...
https://github.com/nagexiucai/milk-powder/blob/master/README.md  ### Environment
leptonica-1.74.4
Found AVX2
Found AVX
--lang chi_sim \
--linedata_only \
Is it normal, or is there something wrong?
@Shreeshrii  thanks for you reply
3.I use the default training text: https://github.com/tesseract-ocr/langdata/blob/master/chi_sim/chi_sim.training_text    and only one font is needed
in command line , I input "tesseract ", we can see the "OCR options", but it doesnt contain "-oem NUM" option as operated in Windows system, why? someone told me the Xeon CPU doesnt support AVX, is that the correct reason?
leptonica-1.72
--list-langs          List available languages for tesseract engine.
nciaegs@163.com
From: Shreeshrii
To: tesseract-ocr/tesseract
CC: GuoShuai; Author
Are you using an old version of tesseract?
The correct parameter is --oem NUM
tesseract -v
leptonica-1.74.4
Found AVX
tesseract
tesseract --help | --help-psm | --help-oem | --version
--oem NUM             Specify OCR Engine mode.
0    Original Tesseract only.
2    Tesseract + LSTM.
--list-langs          List available languages for tesseract engine.
* **Tesseract Version**: <!-- compulsory. you must provide your version -->
leptonica-1.74.4
* **Platform**: <!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->
Segfault when running:
$tesseract bad.png - -l ces -psm 7
$ tesseract bad.png - -l ces -psm 7
nguzge gbopf/IUMNIC CZ spol. s r.o.
leptonica-1.74.4 libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8
Found AVX2
Found AVX
--noextract_font_properties --langdata_dir /mnt/e/tesseract-ocr/langdata \
--tessdata_dir /mnt/e/tesseract-ocr/tessdata \
--fontlist "Tahoma" --output_dir /mnt/e/OCR/
=== Starting training for language 'tha'
[Thu Sep 21 18:23:13 DST 2017] /usr/bin/text2image --fonts_dir=/mnt/c/Windows/Fonts --font=Tahoma --outputbase=/tmp/font_tmp.bUhGLbvCi0/sample_text.txt --text=/tmp/font_tmp.bUhGLbvCi0/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.bUhGLbvCi0
Rendering using Tahoma
ERROR: /tmp/tmp.vdOu9qzJMf/tha/tha.Tahoma.exp0.box does not exist or is not readable
ERROR: /tmp/tmp.vdOu9qzJMf/tha/tha.Tahoma.exp0.box does not exist or is not readable
=== Starting training for language 'tha'
[Fri Sep 22 03:04:10 DST 2017] /usr/bin/text2image --fonts_dir=/usr/share/fonts/ --font=Tahoma --outputbase=/tmp/font_tmp.r6wpt8kkkw/sample_text.txt --text=/tmp/font_tmp.r6wpt8kkkw/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.r6wpt8kkkw
FcInitiReinitialize failed!!
Could not find font named Tahoma. Pango suggested font
Rendering using Tahoma
ERROR: /tmp/tmp.4iPf952XEc/tha/tha.Tahoma.exp0.box does not exist or is not readable
ERROR: /tmp/tmp.4iPf952XEc/tha/tha.Tahoma.exp0.box does not exist or is not readable
Rendering using Tahoma
Rendered page 0 to file /tmp/tmp.QjgaXWkS0p/tha/tha.Tahoma.exp0.tif
[Fri Sep 22 03:20:06 DST 2017] /usr/bin/unicharset_extractor --output_unicharset /tmp/tmp.QjgaXWkS0p/tha/tha.unicharset --norm_mode 2 /tmp/tmp.QjgaXWkS0p/tha/tha.Tahoma.exp0.box
--linedata_only \
--langdata_dir /mnt/e/tesseract-ocr/langdata \
--tessdata_dir /mnt/e/tesseract-ocr/tessdata   \
And `tha` with `"Arial" ` but it got a same error
ERROR: /tmp/tmp.A41qaylCwa/tha/tha.Arial.exp0.box does not exist or is not readable
ERROR: /tmp/tmp.A41qaylCwa/tha/tha.Arial.exp0.box does not exist or is not readable
@ivanzz1001
/usr/share/fonts/truetype/Fonts/browalia.ttc: BrowalliaUPC:style=Bold Italic,Negreta cursiva,tučné kurzíva,fed kursiv,Fe
tt Kursiv,Έντονα Πλάγια,Negrita Cursiva,Lihavoitu Kursivoi,Gras Italique,Félkövér dőlt,Grassetto Corsivo,Vet Cursief,Hal
vfet Kursiv,Pogrubiona kursywa,Negrito Itálico,Полужирный Курсив,Tučná kurzíva,Fet Kursiv,Kalın İtalik,Krepko poševno,Lo
di etzana
,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,Arrunta
/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf: DejaVu Serif:style=Book
Normál,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,Arrunta
Normál,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,thường,Arrunta
/usr/share/fonts/truetype/Fonts/upcii.ttf: IrisUPC:style=Italic,Cursiva,kurzíva,kursiv,Πλάγια,Kursivoitu,Italique,Dőlt,C
orsivo,Cursief,Kursywa,Itálico,Курсив,İtalik,Poševno,Etzana
/usr/share/fonts/truetype/Fonts/msyhbd.ttc: Microsoft YaHei UI:style=Bold,Negreta,tučné,fed,Fett,Έντονα,Negrita,Lihavoit
u,Gras,Félkövér,Grassetto,Vet,Halvfet,Pogrubiony,Negrito,Полужирный,Fet,Kalın,Krepko,Lodia
/usr/share/fonts/truetype/Fonts/angsana.ttc: AngsanaUPC:style=Bold,Negreta,tučné,fed,Fett,Έντονα,Negrita,Lihavoitu,Gras,
Félkövér,Grassetto,Vet,Halvfet,Pogrubiony,Negrito,Полужирный,Fet,Kalın,Krepko,Lodia
,Normál,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,Arrunta
rmale,Standaard,Normalny,Обычный,Normálne,Navadno,thường,Arrunta
/usr/share/fonts/truetype/Fonts/calibriz.ttf: Calibri:style=Bold Italic
/usr/share/fonts/truetype/Fonts/consolaz.ttf: Consolas:style=Bold Italic
1: 8514oem
2: Angsana New
3: Angsana New Bold
4: Angsana New Bold Italic
5: Angsana New Italic
6: AngsanaUPC
7: AngsanaUPC Bold
8: AngsanaUPC Bold Italic
9: AngsanaUPC Italic
15: Browallia New
16: Browallia New Bold
17: Browallia New Bold Italic
18: Browallia New Italic
19: BrowalliaUPC
20: BrowalliaUPC Bold
21: BrowalliaUPC Bold Italic
22: BrowalliaUPC Italic
23: Calibri
24: Calibri Bold
25: Calibri Bold Italic
27: Calibri Light
29: Cambria
30: Cambria Bold
31: Cambria Bold Italic
32: Cambria Italic
33: Cambria Math
34: Candara
35: Candara Bold
36: Candara Bold Italic
37: Candara Italic
42: Consolas
43: Consolas Bold
44: Consolas Bold Italic
45: Consolas Italic
46: Constantia
47: Constantia Bold
48: Constantia Bold Italic
50: Corbel
51: Corbel Bold
52: Corbel Bold Italic
53: Corbel Italic
54: Cordia New
55: Cordia New Bold
56: Cordia New Bold Italic
57: Cordia New Italic
58: CordiaUPC
59: CordiaUPC Bold
60: CordiaUPC Bold Italic
61: CordiaUPC Italic
62: Courier
69: DejaVu Sans Mono
70: DejaVu Sans Mono Bold
71: DejaVu Serif
73: DilleniaUPC
74: DilleniaUPC Bold
75: DilleniaUPC Bold Italic
76: DilleniaUPC Italic
77: Ebrima
78: Ebrima Bold
79: EucrosiaUPC
80: EucrosiaUPC Bold
81: EucrosiaUPC Bold Italic
82: EucrosiaUPC Italic
86: FreesiaUPC
87: FreesiaUPC Bold
88: FreesiaUPC Bold Italic
89: FreesiaUPC Italic
90: Gabriola
91: Gadugi
92: Gadugi Bold
95: Georgia Bold Italic
99: IrisUPC
100: IrisUPC Bold
102: IrisUPC Italic
103: JasmineUPC
104: JasmineUPC Bold
105: JasmineUPC Bold Italic
106: JasmineUPC Italic
107: Javanese Text
108: KodchiangUPC
109: KodchiangUPC Bold
110: KodchiangUPC Bold Italic
111: KodchiangUPC Italic
112: Leelawadee
113: Leelawadee Bold
114: Leelawadee UI
115: Leelawadee UI Bold
116: Leelawadee UI Semi-Light
118: LilyUPC Bold
119: LilyUPC Bold Italic
120: LilyUPC Italic
121: Lucida Console Semi-Condensed
122: Lucida Sans Unicode
124: MS PGothic
127: MS UI Gothic
128: MV Boli
129: Malgun Gothic
130: Malgun Gothic Bold
131: Malgun Gothic Light
132: Marlett Medium
134: Microsoft JhengHei
135: Microsoft JhengHei Bold
136: Microsoft JhengHei Light
137: Microsoft JhengHei UI
138: Microsoft JhengHei UI Bold
140: Microsoft New Tai Lue
145: Microsoft Tai Le
146: Microsoft Tai Le Bold
147: Microsoft YaHei
148: Microsoft YaHei Bold
153: Microsoft Yi Baiti
154: MingLiU-ExtB
155: MingLiU_HKSCS-ExtB
159: NSimSun
160: Nirmala UI
161: Nirmala UI Bold
162: Nirmala UI Semi-Light
163: PMingLiU-ExtB
164: Palatino Linotype
168: Segoe MDL2 Assets
169: Segoe Print
170: Segoe Print Bold
171: Segoe Script
172: Segoe Script Bold
173: Segoe UI
174: Segoe UI Bold
175: Segoe UI Bold Italic
176: Segoe UI Emoji
177: Segoe UI Heavy
178: Segoe UI Heavy Italic
179: Segoe UI Historic
180: Segoe UI Italic
181: Segoe UI Light
182: Segoe UI Light Italic
183: Segoe UI Semi-Bold
184: Segoe UI Semi-Bold Italic
185: Segoe UI Semi-Light
186: Segoe UI Semi-Light Italic
187: Segoe UI Symbol
188: SimSun
189: SimSun-ExtB
190: Sitka Banner
191: Sitka Banner Bold
192: Sitka Banner Bold Italic
193: Sitka Banner Italic
195: Sitka Display Bold
196: Sitka Display Bold Italic
197: Sitka Display Italic
198: Sitka Heading
199: Sitka Heading Bold
200: Sitka Heading Bold Italic
202: Sitka Small
203: Sitka Small Bold
204: Sitka Small Bold Italic
206: Sitka Subheading
207: Sitka Subheading Bold
208: Sitka Subheading Bold Italic
209: Sitka Subheading Italic
210: Sitka Text
212: Sitka Text Bold Italic
213: Sitka Text Italic
214: Small Fonts
215: Sylfaen
216: Symbol
218: Tahoma
219: Tahoma Bold
231: Verdana
232: Verdana Bold
233: Verdana Bold Italic
234: Verdana Italic
236: Wingdings
237: Yu Gothic
238: Yu Gothic Bold
239: Yu Gothic Light
240: Yu Gothic Medium
241: Yu Gothic UI
242: Yu Gothic UI Bold
243: Yu Gothic UI Light
244: Yu Gothic UI Semi-Bold
``` @Shreeshrii
checking for g++... g++
checking for g++... g++
then if you get  error about `Invalid Unicode codepoint: ` try to change code in `normstrng.cpp`
How?
--lang chi_sim  \
--linedata_only \
--output_dir ../tesstutorial/chi_sim
error LNK2001: unresolved external symbol "public: __thiscall tesseract::Convolve::Convolve(class STRING const &,int,int,int)" (??0Convolve@tesseract@@QAE@ABVSTRING@@HHH@Z)
gives an error
1. Put the deu.trainwddata directly under your tessdata dir.
A variant of that option:
depbase=`echo ambigs.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
Please report an issue only for a BUG, not for asking questions.
ocr_r = self.tesseract.TessBaseAPIGetUTF8Text(self.api)
@amitdo I did not see python binding repo under tesseract. Can you please link me to the one you are referring to? Please note i'm using `ctypes` to call the acutal tesseract API and not the python wrapper for tesseract.  >I did not see python binding repo under tesseract. Can you please link me to the one you are referring to? Please note i'm using ctypes to call the acutal tesseract API
I thought that you are using a 3rd party python binding.
Currently 8 of the 10 largest files are test related:
1444515 ccutil/universalambigs.cpp
708120 testing/DuTillet1004Pg2LG.jpg
444141 testing/hebtypo.jpg
401757 testdata/chi_tra.unicharset
359497 ccutil/tesscallback.h
327214 testdata/chi_sim.unicharset
221628 testdata/mar.unicharset
![tesseract](https://user-images.githubusercontent.com/30248220/30473888-72f05e40-9a34-11e7-9518-de668fd6c024.png)
ara.config
ben.config
chi_sim.config
chi_sim_vert.config
chi_tra.config
chi_tra_vert.config
deu.config
hin.config
ita.config
kan.config
kor.config
mal.config
mar.config
nep.config
tam.config
tha.config
vie.config
It's not clear why these parts exist in "best", and already the first one `ara.config` looks wrong:
tessedit_ocr_engine_mode        1
This is still ok for ara. Shouldn't all fast and best traineddatas have this:
>tessedit_ocr_engine_mode 1
`deu.traineddata` loads `frk.traineddata`. That looks wrong for me. Maybe other config files should not be there, too.
`tesseract -v
leptonica-1.74.4
Found AVX2
Found AVX
`tesseract image.jpg out -l eng`
* **Leptonica Version**: 1.7.8
cd /tesseract
* **Tesseract Version**: <!-- compulsory. you must provide your version -->
leptonica-1.74.4 (Jun 22 2017, 16:20:35) [MSC v.1900 DLL Release x86]
* **Platform**: <!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->
Wrong OCR:
カバパバンに
カバパバン should be カバン
Wrong OCR:
ティイツシュ should be ティッシュ (or at least テイツシユ with set of small kana)
カバ パ バン に
入れ て ある し
ティ イツ シュ は
スカ ー ト の
ポケ ッ ト だ けら
大 丈夫 !
Config:
一 緒 の 部 活 に
入っ て くれ て
うれ し いね は っ て
fictitious は
Config:
一 緒 の 部 活 に
入 っ て く れ て
う れ し い ね は っ て
fictitious は, still
Config:
ほ ば のり ちゃ ん が
一 緒 の 部 活 に
入っ て くれ て
fictitious ば
Config:
一 緒 の 部 活 に
入 っ て く れ て
う れ し い ね っ て
textord_old_baselines 1 -> 部 長 な ん だ か ら
textord_old_baselines 0 -> 部 長 な ん だ ヵ か ら
I used these commands and I put the Arabic.traineddata from the best folder in tessdata directory:
--training_text ./langdata/ara/ara.training_text \
--lang ara  \
--linedata_only \
--output_dir ~/tesstutorial/aratrain
mkdir -p ~/tesstutorial/aratuned_from_ara
combine_tessdata -e ./tessdata/Arabic.traineddata \
~/tesstutorial/aratuned_from_ara/ara.lstm
lstmtraining --model_output ~/tesstutorial/aratuned_from_ara/aratuned \
--continue_from ~/tesstutorial/aratuned_from_ara/ara.lstm \
--traineddata ~/tesstutorial/aratrain/ara/ara.traineddata \
--train_listfile ~/tesstutorial/aratrain/ara.training_files.txt \
Loaded file /home/fanasa/tesstutorial/aratuned_from_ara/ara.lstm, unpacking...
Failed to continue from: /home/fanasa/tesstutorial/aratuned_from_ara/ara.lstm
لا. under this condition can I use this 147a1a5
@Shreeshrii
yes . it seems that there was no problem with using training/tesstrain.sh.
@Shreeshrii
thanks. I think your solution is working the finetuning process was finished. I tested the result model. the problem of لا which was solved in Arabic.traineddata, again appeared in my finetuned model.
@Shreeshrii do you have any idea why this is happening?
Extracting unicharset from box file /tmp/tmp.UFLtOD70jF/ara/ara.Arab.exp0.box
ERROR: /tmp/tmp.UFLtOD70jF/ara/ara.unicharset does not exist or is not readable
could you solve this? It was merged now. But I am confused. Why does this code change fix something? The new code no longer matches the comment ("In the range [0, 0xD800) or [0xE000, 0x10FFFF]"). And `0xffffffd9` does not look like a valid Unicode codepoint. @Shreeshrii but your PR removed my error. do I have to change it back.
> source=footer#!msg/tesseract-ocr/fqyYaav6vmk/M8xjpwhpBAAJ
ccutil/unichar.h
umachine_8h.html
typedef int32_t UChar32
tprintf("Invalid Unicode codepoint: %d = 0x%x\n", ch, ch);
~/tesstutorial/newfas_from_fas/fas.lstm
--continue_from ~/tesstutorial/newfas_from_fas/fas.lstm \
> <https://github.com/notifications/unsubscribe-auth/AZFiAW3U9dW4A0ajTbTt1Jd4ioaxiMVhks5slg2fgaJpZM4PR9Tr>
@Shreeshrii
ERROR: /tmp/tmp.X7UveftTV1/ara/ara.unicharset does not exist or is not
> @hanikh
> For complex scripts, I have tested with Devanagari, I have to go up to
> > @Shreeshrii
> > ~/tesstutorial/newfas_from_fas/fas.lstm
> > lstmtraining --old_traineddata ./tessdata/fas.traineddata \
> > --continue_from ~/tesstutorial/newfas_from_fas/fas.lstm \
> > --traineddata ~/tesstutorial/fastrain/fas/fas.traineddata \
> > --train_listfile ~/tesstutorial/fastrain/fas.training_files.txt \
> code
> > AZFiAW3U9dW4A0ajTbTt1Jd4ioaxiMVhks5slg2fgaJpZM4PR9Tr>
@Shreeshrii
unfortunately, the error still exists
> @Shreeshrii
@Shreeshrii are you still facing the error:
ERROR: /tmp/tmp.mqNL37ZWB5/ara/ara.unicharset does not exist or is not
> Extracting unicharset from box file /tmp/tmp.ou9ZKjVaiJ/eng/eng.Arial.exp0.box
> Invalid Unicode codepoint: -30 = 0xffffffe2
> 65 20 C2 A2 20 E2 80 9C 20 49 20 C2 B0 20 20 C2 A9 20 C2 AE 20 EF AC 82
> This C2 etc are showing up as invalid codepoints
> <https://github.com/notifications/unsubscribe-auth/AZFiAb2018HziiG8xVm1T3FaooN1K3t9ks5sqznXgaJpZM4PR9Tr>
Please report an issue only for a BUG, not for asking questions.
leptonica-1.73
cntraining hpu.font.exp0.tr
Extracting unicharset from hpu.font.exp0.box
Offset for type  2 (hpu.unicharambigs         ) is -1
Offset for type  6 (hpu.punc-dawg             ) is -1
Offset for type  7 (hpu.word-dawg             ) is -1
Offset for type  8 (hpu.number-dawg           ) is -1
Offset for type  9 (hpu.freq-dawg             ) is -1
Offset for type 11 (hpu.cube-unicharset       ) is -1
Offset for type 12 (hpu.cube-word-dawg        ) is -1
Offset for type 14 (hpu.bigram-dawg           ) is -1
Offset for type 15 (hpu.unambig-dawg          ) is -1
> Have you checked whether new trained data is available for it in teesara
ppa by alex.
Getting error message cppan command '0' not found.
hebtypo.jpg seems to be taken from a copyrighted book.  hi,
output mac is as input
i tried all -psm modes with no effect i wanted. works. strange - but it works. thanks
--lang chi_sim  \
--linedata_only \
--output_dir ../tesstutorial/chi_sim
Thank you @Shreeshrii ~  hi i am new on using tesseract
Please report an issue only for a BUG, not for asking questions.
* **Tesseract Version**: <!-- compulsory. you must provide your version -->
* **Platform**: <!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->
then it gives this error:
@Shreeshrii
```bash
```bash
at line 164 of tesseract/unichar.h error 3646 'UTF32ToUtf8 'string' : unknown override specifier
Is it an opencv problem or a tesseract problem ?
thank you   ### Environment
* **Platform**: <!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->
there are so many error
variable "CPPAN_SYMBOL_IMPORT" is not name...blahblah <- i'm not english user
tesseract ...
: Pöllan : R=11.9817, C=-2.96366, F=1, Perm=2, xht=[0,3.40282e+038], ambig=0
str	P	ö	l	l	a	n
: Pöllan : R=11.9817, C=-20.7456, F=1, Perm=2, xht=[0,3.40282e+038], ambig=0
str	P	ö	l	l	a	n
: /NORDKOREA : R=16.2872, C=-0.229416, F=1, Perm=2, xht=[0,3.40282e+038], ambig=0
: /NORDKOREA : R=16.2872, C=-20.8069, F=1, Perm=2, xht=[0,3.40282e+038], ambig=0
'Pöllan'
It takes me some time as I'm used to Java but I only used C/C++/... at University, which is quite some time ago. Then some other projects took my time.
PATERNION
Please report an issue only for a BUG, not for asking questions.
* **Tesseract Version**: <!-- compulsory. you must provide your version -->
* **Platform**: <!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->
@yhfwww commented
hanni_xu
收件人： tesseract-ocr/tesseract
主题： [tesseract-ocr/tesseract] 当图片只有单字中文时候一般没法识别 (#1079)
Please report an issue only for a BUG, not for asking questions.
Environment
Suggested Fix:
ﬁﬁiaiﬂﬁma done
iiiéimﬁiiﬁﬁ done
Another problem is the charactor "囡" in "弹囡宽度"，actually it is "窗". tesseract WX20170813_165113_2x.png stdout -l chi_sim
tesseract 3.04.00
leptonica-1.72
2017年8月13日 16:09，iuriigalaida <notifications@github.com>写道：
stephenyong2005 Did you see error like this in your case?
ShreeDevi
bool* is_monospace,
bool* is_smallcaps,
14:bigram-dawg:size=16109842, offset=3221531
18:lstm-punc-dawg:size=4322, offset=24722091
but got lots of this waring:
Hey Shreeshrii,
Failed to read continue from: /trainplusminus/plusminus_checkpoint
https://github.com/benedikt-budig/glyph-miner
leptonica-1.74.1
ÄGYPTEN -> ÄAGYPTEN
GROSSBRITANNIEN -> GROSSBRITAÄANNIEN
ÄGYPTEN -> ÄGYPTEN
Grand-Prix -> Grand-Prix
Suggested Fix:
Encyclopedia -> EE-n-c-yy-c-l-o-p-e-d-i-a -> Encyclopedia
deu.traineddata 19.721 KB
There are still similar errors:
hitzefrei -> 1 x hitzefreii / 1 x hitzefreil
@TheSeiko, maybe you'd get better results for Antiqua text without that `frk` dependency (which might be good for texts which also include Fraktur). You can use `combine_tessdata` to extract the components of `best/deu.traineddata`, remove deu.config and combine the remaining components again in a new file. Thank you for the tip. Much appreciated! @stweil Am I doing something wrong?
Wrote tmp/deu.version
Wrote tmp/deu.version
sıch - sich
Parıs - Paris
Jungen - jungen
|         10 |      10 | Überlebende        | Uberlebende        | 2017-08-10 08:08:04 | - LATIN
|         10 |      10 | Männer             | Māänner            | 2017-08-10 15:04:25 | - LATIN
leptonica-1.74.4
`max_offset = std::max(max_offset, (*code)(i)-han_offset);`
Error	C2039	'max': is not a member of 'std'	libtesseract	<path>\tesseract\ccutil\unicharcompress.cpp	208
@theraysmith,
@theraysmith
cmake ..
bin/tesseract_test
Half-width Katakana Example : ｱｲｳｴｵ   ｶｷｸｹｺ
Full-width Katakana Example : アイウエオ　カキクケコ
When input a Halfwidth katakana, Tesseract can't recognize  or some times out with Full-width katakana.
This is my unicharset file i got from run command
ヴ 1 0,255,0,255,0,0,0,0,0,0 NULL 28 0 0 	# ヴ [30f4 ]x
Thanks! @Shreeshrii  I think halfwidth katakana not include
/usr/local/include/tesseract/unichar.h:164:10: error: ‘string’ does not name a type
### Reproducing the error
- Compile Leptonica from source
Code I am runnig
`namespace` ORC
using (img)
catch (Exception e)
Detected 35 diacritics
Illegal instruction
Tesseract -v reports
leptonica-1.74.4
Found AVX
Could not initialize tesseract.
I simply don't get it. What's going on here?
Detected 35 diacritics
Illegal instruction
Also I reinstalled Leptonica and Tesseract multiple times now.
apt-get install libpango1.0-dev
2. Install Leptonica:
cd leptonica
3. Install Tesseract:
cd tesseract-ocr
./configure        # nickbe: I TESTED BOTH CONFIGURATIONS JUST TO MAKE SURE
(gdb) set args -l eng --oem 2 test.png out
Starting program: /usr/local/bin/tesseract -l eng --oem 2 test.png out
Detected 35 diacritics
Program received signal SIGILL, Illegal instruction.
(gdb)
Detected 35 diacritics
Aborted
That was the output when running:  tesseract -l eng --oem 2 ......
In arch/simddetect.h
Yes. It's strange.
It's a vServer. Probably XEN but I'm not sure. We do use them quite often without problems. So I have no idea why this case is indeed so strange. I'm recompiling now... Yay. It's working finally. Thanks you so much guys 💃 Will the changes in the make make it into the official repository.?
If you like I'd be happy to grant you access to the server.  https://github.com/tesseract-ocr/tesseract/issues/1043#issuecomment-316519350 No I meant maybe there's a better and more secure way for you guys to recognize these kind of features @nickbe, you could help by providing more information on the kind of vServer which you were using. Sure.
>   --lang eng --linedata_only \
>   --fontlist "Lucida Sans" \
>   --output_dir /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA
Rendering using Lucida Sans
Rendered page 0 to file /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.tif
Rendered page 1 to file /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.tif
Extracting unicharset from /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.box
Wrote unicharset file /tmp/tmp.iafCx7Aypj/eng//unicharset.
Loaded unicharset of size 111 from file /tmp/tmp.iafCx7Aypj/eng/eng.unicharset
Writing unicharset to file /tmp/tmp.iafCx7Aypj/eng/eng.unicharset
=== Phase D: Generating Dawg files ===
Generating word Dawg
Loading unicharset from '/tmp/tmp.iafCx7Aypj/eng/eng.unicharset'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.iafCx7Aypj/eng/eng.word-dawg'
Generating frequent-word Dawg
Loading unicharset from '/tmp/tmp.iafCx7Aypj/eng/eng.unicharset'
Reading word list from '/tmp/tmp.iafCx7Aypj/eng/eng.wordlist.clean.freq'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.iafCx7Aypj/eng/eng.freq-dawg'
Loading unicharset from '/tmp/tmp.iafCx7Aypj/eng/eng.unicharset'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.iafCx7Aypj/eng/eng.punc-dawg'
Loading unicharset from '/tmp/tmp.iafCx7Aypj/eng/eng.unicharset'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.iafCx7Aypj/eng/eng.number-dawg'
Loading unicharset from '/tmp/tmp.iafCx7Aypj/eng/eng.unicharset'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.iafCx7Aypj/eng/eng.bigram-dawg'
[Tue Jul 11 13:05:57 IST 2017] /usr/local/bin/tesseract /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.tif /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0 lstm.train
Moving /tmp/tmp.iafCx7Aypj/eng/eng.number-dawg to /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA/eng.lstm-number-dawg
Moving /tmp/tmp.iafCx7Aypj/eng/eng.punc-dawg to /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA/eng.lstm-punc-dawg
Moving /tmp/tmp.iafCx7Aypj/eng/eng.word-dawg to /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA/eng.lstm-word-dawg
These are the files which are more elaborated.
[Tue Jul 11 13:05:57 IST 2017] /usr/local/bin/tesseract /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.tif /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0 lstm.train
This looks strange, because the error here comes from the legacy OCR engine, not the LSTM engine. @amitdo  Can you please say what can i do to avoid this and train tesseract normally.
Wrote unicharset file /tmp/tmp.RCyux9nJxb/eng//unicharset.
=== Phase D: Generating Dawg files ===
Generating word Dawg
Reducing Trie to SquishedDawg
Generating frequent-word Dawg
Reading word list from '/tmp/tmp.RCyux9nJxb/eng/eng.wordlist.clean.freq'
Reducing Trie to SquishedDawg
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.RCyux9nJxb/eng/eng.punc-dawg'
Reducing Trie to SquishedDawg
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.RCyux9nJxb/eng/eng.bigram-dawg'
[Sat Jul 15 23:50:45 IST 2017] /usr/local/bin/tesseract /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0.tif /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0 lstm.train
@Shreeshrii @amitdo
inline double Tanh(double x) {
>   O. Tange (2011): GNU Parallel - The Command-Line Power Tool,
```bash
```bash
35,080,176,770      branches:u                #  638.823 M/sec                    (42.77%)
450,004,836      LLC-loads:u               #    8.195 M/sec                    (17.70%)
<not supported>      L1-icache-loads:u
<not supported>      L1-dcache-prefetches:u
<not supported>      L1-dcache-prefetch-misses:u
As expected, with no compiler optimizations and all functions with the 'inline' identifier removed, the performance was worse by a significant amount (8% to 10% worse). Also as expected with modern compilers (gcc 6.3 and gcc 8.0... I haven't run 7.x stable yet, although I could tomorrow), the performance seems to be ~the same and (perhaps, although requires more testing to be definite) better on a CPU with smaller cache/tlb sizes.
I can wait on posting any code changes until @theraysmith has the new beta tag out though. I'm not sure how these types of issues are handled on github either. I've spent most of my time working at a FFRDC, and haven't submitted much FOSS code publicly at all because of it, but I can post what I've done with this, which is great. Typically, I'd either write my own tests and submit along with compiled code (and a 'NO MERGE' pull request), or follow already provided tests and submit according to them, however I haven't seen any. What do you all prefer to use, and would this be something you're interested in? I absolutely abhor, detest, and strongly oppose programming for the compiler, but I feel like these changes would actually do the opposite, and allow the compiler to take over.
Tessearct 4.00.00alpha
See https://msdn.microsoft.com/en-us/library/abx4dbyh(v=vs.80).aspx but also
Thanks in advance.  @egorpugin,
<img width="585" alt="schermata 2017-07-06 alle 16 54 54" src="https://user-images.githubusercontent.com/1537350/27917284-e45683bc-626b-11e7-98bf-bc3666c1d500.png">
<img width="955" alt="schermata 2017-07-06 alle 16 51 01" src="https://user-images.githubusercontent.com/1537350/27917244-bed8d644-626b-11e7-8c2d-463004eaa036.png">
**Deserialize failed: /home/ibr/tesstutorial/aratrain/ara.2_Baran.exp0.lstmf read 0/81 pages**
i already used the same version of tesseract to tune for japanese, but for arabic i got the previous error
`training/lstmtraining --model_output ~/tesstutorial/arabic_tuning/"arabic_tune" \
--continue_from ~/tesstutorial/extracted_aralstm/ara.lstm \
--train_listfile ~/tesstutorial/aratrain/ara.training_files.txt \
strangely that the version **547-g8c29e68** passed for Japanese tuning yet it failed for Arabic tuning, as for the version **367-g5baa8c8** i didn't try it for Japanese tuning, only for Arabic and it succeeded
NOTE: both versions are running on the same VMware, and with the same leptonica version which is Leptonica1.47.1 actually all the LSTMFs (Arabic & Japanese) were created by the same version **547-g8c29e68**  yet fine tuning at the version **547-g8c29e68**  worked only for Japanese, but for Arabic (which was also created by the version **547-g8c29e68**) its fine tuning worked at the version **367-g5baa8c8**  Is this issue still happen with latest code?   Fix for #1016  Hi all
do {
//unknown value to space
> Char value = こ left= 15 top = 14 right = 51 bottom = 51 conf = 99
Char value = ば left= 122 top = 5 right = 171 bottom = 54 conf = 99
Char value = は left= 234 top = 9 right = 281 bottom = 54 conf = 99
Char value = こ left= 295 top = 14 right = 331 bottom = 51 conf = 99
Char value = ば left= 402 top = 5 right = 445 bottom = 54 conf = 99
Char value = は left= 514 top = 9 right = 561 bottom = 54 conf = 99
Char value = ご left= 15 top = 79 right = 58 bottom = 126 conf = 99
Char value = 飯 left= 62 top = 80 right = 113 bottom = 130 conf = 99
Char value = 大 left= 120 top = 80 right = 225 bottom = 130 conf = 99
Char value = 盛 left= 242 top = 83 right = 260 bottom = 130 conf = 99
Char value = ば left= 122 top = 5 right = 171 bottom = 54 conf = 99
Char value = は left= 234 top = 9 right = 281 bottom = 54 conf = 99
Char value = こ left= 295 top = 14 right = 331 bottom = 51 conf = 99
Char value = ば left= 402 top = 5 right = 445 bottom = 54 conf = 99
Char value = は left= 514 top = 9 right = 561 bottom = 54 conf = 99
Char value = ご left= 15 top = 79 right = 58 bottom = 126 conf = 99
Char value = 飯 left= 62 top = 80 right = 113 bottom = 130 conf = 99
Char value = 大 left= 120 top = 80 right = 225 bottom = 130 conf = 99
Char value = 盛 left= 242 top = 83 right = 260 bottom = 130 conf = 99
Strange. It looks like a bug. Thank sir We are still able to reproduce it in the **Arabic** language in **LSTM mode**.
(As a side note, I'm using RIL_WORD, but it seems to behave like RIL_SYMBOL, I'm not sure why).
--model_config  $HOME/work/kor/tuned/kortuned \
--continue_from  $HOME/work/kor/tuned/kor.lstm \
It seems that a compression error occurs in the following complex characters.
- latin.traineddata
@theraysmith
* **Leptonica Version**: leptonica-1.74.4
**Error: Illegal Parameter specification!**
Problematic frame:
/opt/wildfly/wildfly-10.1.0.Final/hs_err_pid25091.log
(*) Error: Illegal Parameter specification!
` leptonica-1.74.4`
For that reason I'd like to improve the 4Alpha but it's impossible for the error commented some lines back. If you have an issue with a wrapper to Tesseract's C/C++ API, please report the issue to the developers of that software. >I'm using g++ 7.1.1 in Arch and 4.8.2 in CentOS 6.7.
>0000 0340 º71º ZL (in CentOS) and 0000 0340 0710 ZL (in Arch).
=== Starting training for language 'ara'
Pango suggested font FreeMono.
Pango suggested font FreeMono.
ERROR: /tmp/tmp.9c8iwNnHC8/ara/ara.Arial.exp0.box does not exist or is not readable
ERROR: /tmp/tmp.9c8iwNnHC8/ara/ara.Arial.exp0.box does not exist or is not readable
-I/usr/include/leptonica
> -I/usr/local/include/leptonica
> -I/usr/local/include/leptonica
Attaching my lept.pc (generated from lept.pc.in).
An embarrassment of riches, as the French would say (except
in their own way).
It seems to me that the current suggestions in the leptonica
> As part of the experimentation, I did a hard reset in leptonica directory
> both of these, that leptonica version was reported as 1.74.2.
> was using leptonica 1.74.4.
referring to the small section on constraints for compiling leptonica.
> leptonica version recently.
> <https://github.com/egorpugin> and @zdenop <https://github.com/zdenop> .
## Parancters
user = MUser{nanes "Alice Winston}
17 Bout
adec !
## Parancters
enero oE \ s |
[He changed the numbers in his comment] ​but its size is very different and dont follow an unique pattern..
>​ @amitdo I can't seem to write a single comment without editing it three times to fix mistakes.
--script_dir /home/ibr/langdata --debug_interval 0 \
--append_index 5 --net_spec '[Lfx256 O1c105]' \
>   --script_dir /home/ibr/leptonica-1.74.2/langdata --debug_interval 0 \
Loaded file /home/ibr/tesstutorial/jpn.lstm, unpacking...
Setting properties for script Katakana
Setting properties for script Hiragana
oem:  TesseractOnly  psm: AutoOsd  time: 518 ms.  result:  伦敦夺委房发生火火中使馆大汪 二 暂无中 ` 又伤
@zdenop  @Shreeshrii @stweil
[debug] -Char value = 大 left= 16 top = 243 right = 68 bottom = 295 conf = 99
[debug] -Char value = 阪 left= 75 top = 244 right = 128 bottom = 295 conf = 99
[debug] -Char value = 株 left= 130 top = 244 right = 185 bottom = 296 conf = 99
[debug] -Char value = 式 left= 190 top = 243 right = 281 bottom = 296 conf = 99
Running two or more programs which all attempt to process images with Tesseract seems to lock up all programs indefinitely.
Running two or more programs involving Tesseract would not block all programs from executing.
I don't actually know enough about the codebase itself to to suggest a fix, but would be interested in more information or a workaround. This actually has nothing to do with training though, just evaluation with the LSTM. I'm running on an Ubuntu 16 VM which has 16GB RAM from the host and 4 cores, so I doubt it has anything to do with the hardware. I'll try the latest code and see what happens The problems which we observed with training also exist for the tesseract ocr process. It uses multithreading causing a significant overhead for thread synchronisation. Your 4 cores will be sufficient for a single tesseract process, but if you run more than one, the effects which you have seen are not surprising.
With Leptonica 1.74.1:
$ valgrind bin/ndebug/x86_64-linux-gnu/api/tesseract --oem 1 ~/Bilder/ocr/hello_world.png /tmp/hello
==21183==    by 0x4E8CABA: bmfCreate (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
==21183==    by 0x4E8CABA: bmfCreate (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
==21183== LEAK SUMMARY:
With Leptonica 1.74.2:
$ valgrind bin/ndebug/x86_64-linux-gnu/api/tesseract --oem 1 ~/Bilder/ocr/hello_world.png /tmp/hello2
==22040== LEAK SUMMARY:
Any reason to not have a link to this page instead of the other links?  The new README.md can be seen [here](https://github.com/Shreeshrii/tesseract).  Attached are two images, one with the word Keyword, and the other with a random string. The file with the word Keyword outputs an accurate result (Keyword). The second file though outputs something very odd: `"'Eﬂ'fé'i'ibiboss`
<img width="100" alt="ocrtest" src="https://cloud.githubusercontent.com/assets/1245462/26419801/dd4dfa72-408e-11e7-8115-e29b35beb05a.png">
<img width="100" alt="ocrtest" src="https://cloud.githubusercontent.com/assets/1245462/26419800/dd4dad74-408e-11e7-97a2-e9892bd73fcb.png">
Note: I have picked up the trained data from : https://github.com/tesseractocr/tessdata/blob/master/tha.traineddata
and output: "mum-w" which obviously does not match the pattern.
1) Tesseract 4
2) Tesseract 3
3) ABBYY Cloud OCR SDK
तरआशबनीबर्सिक्विरै||
checking for leptonica... yes
configure: error: leptonica library missing
/usr/bin/ld: cannot find -lleptonica_OUTPUT_NAME-NOTFOUND
make[2]: *** [libtesseract.la] Error 1
make[2]: Opuszczenie katalogu `/home/m/OCR/download/tesseract/api'
make[1]: Opuszczenie katalogu `/home/m/OCR/download/tesseract'
checking for leptonica... yes
1) leptonica 1.74.2 builded and installed from source
It seems that with **CMake** it's `libleptonica.so`
for some reason, the network in my country is very bad!!
@amitdo I don't think that the laggard should set the pace, considering how relatively easy the pragma is to use. @rfschtkt, it looks like one parameter is (mostly?) aligned while the other parameter is only aligned in one of four steps (it increases in steps of sizeof(double) == 8). As far as I see the code could also be modified to handle one aligned parameter with the other parameter unaligned.
That's why I want to offer several implementations in Tesseract, and users can choose which one is best for their environment. Do you have any evidence that such differentiation might be useful beyond the purpose of experimentation? I would expect cache-oblivious code, techniques like blocking/strip-mining, to benefit all architectures more or less equally. It doesn't seem very efficient to try to reinvent the wheel here, but I haven't yet looked into any issues like licensing associated with the use of an external library with Tesseract, so... See https://github.com/RRZE-HPC/DDOT-Bench and the associated article for more research on this. They also have code which can be used freely. How about #983? The idea is to primarily rely on OpenMP 4.0's simd where available, then try explicit code for specific implementations, then fall back to serial execution. If you're confident that you have a better implementation than OpenMP, this order can of course be changed, but I don't think this is the case yet. Could you share some details on how you test performance here? Could this be reframed as a unit test that immediately rejects a suboptimal implementation choice? My conjecture is that OpenMP wipes the floor with (relatively speaking) naive use of SSE/AVX intrinsics, and that you only need the latter if you are stuck with Visual C++ (for now). Typically I use these test scenarios for the OCR process (`tesseract` executable, all images available on https://digi.bib.uni-mannheim.de/~stweil/tesseract/):
building ScrollView.jar.
Lfys64:64, 20736
Lfys64:64, 20736
Deserialize header failed: 
-7ìE»°Y[§î÷õµ8>3½t?Ö„+hÚ©ú¡v?wGâ¬:¾½ Û1êT3ß(¦
A¯î¢X	Â3Åb°7­ìv“3Ó’ÚûÛð:Clñþt÷$&ªÌYc¤_.2vC¾Á§)Ù„?©ZêKð¾¾N1Ê£zy_Ÿ!„K©”f±¦#"©GW©ëC^7ë^Ûc	îeH›˜†Äž#ÙB&1ÒOU)ÚâzÊÙsm§ô ‡QRÊH#"°BÒ©ù…%–DXH¬|­ŸÃ1*`HŸˆ
«‘ºmÑ‹ÿMhµ©0Ê³šü¯-Š–3áÆ ‘±"c+Ò H«=xù 3X‘Ð#®óY fÚà¼Ë.<¬{à64ìš=99È›FBRF@W(-™© WNpñþ¯%d
r8‚…±ªÙ+ Ééò›"@ÖTCŒµR`R@L‚®k<¤¤0‹‰|#G°‡Ù
Deserialize header failed: ëÁ‰Ü4\Ò/T¶ñO[O ˆwõu‹VéeEÈŒu¼’}ëÑùJhÌ=šzÏ]ÚÓO€7 Ï=h¨Ä¶EµC
Deserialize header failed: Ò"ÔA‚N9KU¸¥ÇH©_]³#‘çT'RbX*ŽºAd¨¬…úô:v¾²¨¤?¥N¶[Ã
Thanks.  Btw, can anyone tell me how much of text is required to get a good accuracy? I've read in the documentation that original training was done on more then 400000 lines of text so is it necessary to have that much text of languages like (english, arabic, etc...) or not.
Thank You  Regarding the Arabic language, the number of Lines required to produce a decent Model depends on the complexity of the typeface. But it is proven that you are able to create an Arabic Model capable of achieving +90% recognition rate using ~800 lines in your training.
[2)Kraken](http://kraken.re/)
and I am getting this error:
Failed to create a temporary file ara.traineddata.__tmp__
@Shreeshrii , One questions brother.
Thank You @LatifWirelessMarketer send me an email, I want to talk with you regarding the training process.
For example if I test it on my name as: SALMAN (سلمان) and when it detects it almost detects it correctly but lets just say سل is one character based on a whichever font I am using. So when this is what it will return (لسمان) it detects سل as لس which is wrong.
- Or there are some characters that are causing confusion, **Tesseract itself**
Merlin
tesseract::UnicharAmbigs::InsertIntoTable
That is an improvement of 12 %. Using assembler code could improve further, but I'd expect the largest improvement from using `float` instead of `double` (trying to compensate the loss of precision by using the Kahan algorithm). The conversation here is largely over my head, but I came to the bug tracker to discuss performance in 4.0, and this bug is titled "RFC: Tesseract Performance" so it seems like the right place. (Apologies if I'm wrong.)
Making all in ccmain
pura vida. @zdenop oh, that's sad. But I understand.
pura vida.  Hi,
Seems correct, but the contents in new_unicharset is
C 5 58,65,219,255,87,192,0,32,107,209 Latin 10 0 10 C	# C [43 ]A
F 5 57,68,216,255,68,210,0,31,77,209 Latin 11 0 11 F	# F [46 ]A
L 5 59,68,216,255,64,193,0,31,74,206 Latin 16 0 16 L	# L [4c ]A
Y 5 59,68,216,255,91,205,0,47,91,223 Latin 17 0 17 Y	# Y [59 ]A
M 5 57,68,216,255,99,301,0,35,117,286 Latin 20 0 20 M	# M [4d ]A
I 5 59,68,216,255,10,155,0,50,29,173 Latin 21 0 21 I	# I [49 ]A
E 5 59,68,216,255,68,210,0,31,80,219 Latin 22 0 22 E	# E [45 ]A
T 5 59,68,216,255,85,227,0,47,88,236 Latin 23 0 23 T	# T [54 ]A
W 5 54,68,216,255,106,314,0,41,117,318 Latin 24 0 24 W	# W [57 ]A
N 5 59,68,216,255,87,262,0,27,104,249 Latin 26 0 26 N	# N [4e ]A
O 5 57,64,219,255,91,209,0,34,106,233 Latin 27 0 27 O	# O [4f ]A
And i do anything successfully and finally i got traindata. But here is a problem now. There is no output when i used the traindata to test the image. I think there is maybe something wrong with unicharset.
[http://pan.baidu.com/s/1hsA8U4O](url)
[http://pan.baidu.com/s/1pLHgoQn](url)
PNG (ten times)
**Old engine (--oem 0)**
PNG (ten times)
PNG (ten times)
**Old engine with large traineddata (--oem 0 -l mya)**
PNG (ten times)
Including Notepad?
RFC about ccutil/raiileptonica.h?
To review the latest commit, start with ccutil/raiileptonica.h; the other files can then be considered independently of each other. If there are no global issues, I can still divide up the latest commit (by directory, by file, ...but hopefully not by function!).
Here are a few things to consider with respect to the use of RAII with leptonica (I'm sure there are others, but I haven't thought much about this):
I was also glad you found that "unfortunately" there are essentially no memory corruption/leak issues from leptonica usage in tesseract, even though nearly everything happens on the heap  ;-) Ah, but I only looked at local usage, and I did actually "wonder" whether using a `PixRef** pix` parameter without looking at the current value of `*pix`, as happens often in Tesseract, was always a responsible thing to do: I would require it to always be NULL as a precondition (with a check or at least a diagnostic), or always `pixDestroy()` a non-NULL value as part of the contract.
I do remember the example you're talking about, in baseapi.cpp, which looked particularly weird to me because it would first sort of _abandon_ `lbox` (`L_INSERT`)... and then still `L_CLONE` it further down, so that was sort of a surprise. This is probably straightforward enough if you are familiar with the function `boxaAddBox()` where the `L_INSERT` occurred (assumedly the instance gets added to a container as-is, and not, e.g., serialised and destroyed), but it _feels_ wrong because it forces you to still think at that level. In my replacement, the `BoxRef` keeps the object alive throughout its scope (until the eventual `~BoxRef()`), whatever else happens, and in the meantime it can be `L_CLONE`d an arbitrary number of times. Strictly speaking, there are 2 more reference-count manipulations (one for `L_CLONE` instead of `L_INSERT`, then one for `boxDestroy()` inside `~BoxRef()`), but I think you have to strip the program of all functionality before that becomes noticeable. The story with `pix` is even simpler.
A `PixRef` just manages one reference count, whether it's from copying or cloning: the constructor takes over one reference, and the destructor destroys it. See for example `const PixRef word_in_xheight(pixCopy(NULL, pix));` in devanagari_processing.cpp... well, the other occurrences are all with `reset()`.
Don't get me wrong.  Lots of C++ users of leptonica prefer to use them with scoped ptrs, and I think that's fine.  Chacun à son goût.
(Added) So basically the last 3 commits are tentative, just exploring some possibilities. OK, let's get this done, because _RAII is awesome!_
* 1st Leptonica: `PixPtr` (you can't use -> with a "reference" in C++, dummy!) / `PixRef` (as in "one reference")?
* 2nd Leptonica: yes (far less visual dog wagging) / no (straight-up `unique_ptr`)?
* 3rd Leptonica (only if 2nd, I suppose): yes (more `const`) / no (straight-up `unique_ptr`)? if the former: `detach()` (like boost) / `clone()` (Leptonica-specific)?
* 4th Leptonica (only if 3rd, and only if `detach()`, I suppose): yes (more `const`) / no (lame!)?
(My current preferences are weakly or strongly on the left, so not exactly the current code.)
I downloaded from https://github.com/tesseract-ocr/tesseract zip file.
OS: Centos 7
but I receive this error:
from coutln.h:26,
from stepblob.h:23,
from werd.h:28,
cd tesseract
from coutln.h:26,
from stepblob.h:23,
from werd.h:28,
cd tesseract
cd tesseract
from coutln.h:26,
from stepblob.h:23,
from werd.h:28,
cd tesseract
leptonica-1.74.1
Found AVX
do the 2 solution change something in the ocr by tesseract?
>do the 2 solution change something in the ocr by tesseract?
compatibility with the current proprietary format.
75100160 mya.traineddata.tar
75085274 mya.traineddata
36075469 mya.traineddata.zip
27937332 mya.traineddata.tar.xz
- The original Tesseract format, uncompressed tar and lz4 tar are similar and fastest.
- bz2 tar is slowest and needs about 1450 ms more time than the original Tesseract format.
0.48 mya.traineddata.tar
0.50 mya.traineddata
0.52 mya.traineddata.tar
0.79 mya.traineddata.tar.gz
0.80 mya.traineddata.tar.gz
0.80 mya.traineddata.tar.gz
0.82 mya.traineddata.zip
0.84 mya.traineddata.zip
0.85 mya.traineddata.zip
0.88 mya.traineddata.tar.gz
0.90 mya.traineddata.zip
2.38 mya.traineddata.tar.xz
2.41 mya.traineddata.tar.xz
2.46 mya.traineddata.tar.xz
2.49 mya.traineddata.tar.xz
3.69 mya.traineddata.tar.bz2
3.74 mya.traineddata.tar.bz2
3.75 mya.traineddata.tar.bz2
3.79 mya.traineddata.tar.bz2
0.83 mya.traineddata.zip
0.84 mya.traineddata.zip
0.87 mya.traineddata.zip
0.88 mya.traineddata.zip
0.93 mya.traineddata.zip
`libminizip`:
0.84 mya.traineddata.zip
0.84 mya.traineddata.zip
0.85 mya.traineddata.zip
0.87 mya.traineddata.zip
0.92 mya.traineddata.zip
`libzzip`:
0.79 mya.traineddata.zip
0.84 mya.traineddata.zip
https://sourceforge.net/projects/zziplib/?source=navbar
Binarized image:
I never used a library as complicated as this one, I use Linux Java. Well I manage to make tess4j work, then copied all the source packages and libraries into my project, everything seemed fine but when I try running it I get the errors
# Problematic frame:
Use the [RAII](https://en.wikipedia.org/wiki/Resource_acquisition_is_initialization) idiom, e.g., to help prevent memory leaks. Build error: https://travis-ci.org/tesseract-ocr/tesseract/jobs/230329088#L290. Yes, I think it's a bug in that g++ version (4.8.4). I had successfully built with 5.4.0. I'll try again with an explicit move constructor... Are they all tested? I think that it was valid C++11, though.
http://stackoverflow.com/questions/29372976/is-stdunique-ptr-an-application-of-raii  There seems to be another leak in `void POLY_BLOCK::fill(ScrollView* window, ScrollView::Color colour)`, which doesn't do `delete segments;`. But I've had enough fun for now...  >I've had enough fun for now...
= ڤکڵ۱۴ـ۵ـکوقەگ|حهدسـ٥درمحموشۀكاحمورهپـوران ف
also this error occur in arabic language
what is the version of the tesseract and leptonica that you have used?
شکل کوشک احمد شاه در مجموعۀ کاخ موزۀ نیاوران
@Nigje
عکسهای دورۀ قاجار /
/ آثار نقاشی هنرمندان ایرانی
_ __ هنرهای .. .
__ مینیاتور و آثار خنرهای سنتی _
_ © © © روشهای تولید برف
_ سیر خطوط در ایران __
نقاشی و مینیاتور استاد فرشجیان
قالی، نقاشی، خط و آثار دورههای
ا ا
0 آثار باستانی و هنرهای تیوی ر ز
آثار دورۀ قاجار و پهلوی و هدایای بعضی کشورها .
_ تفاشی های دودۀ فاجار ر .
_ اشیا و تایلوهای اروپایی هدیه شده به دربار قاجار _
/ عکسهای دورۀ قاجار 5
آثار دورۀ پهلوی
هنری، تخصصی
" انواع گوناگون گل و گیاه
شکل کوشک احمد شاه در مجموعۀ کاخ موزۀ نیاوران
leptonica-1.74.1  [MSC v.1900 LIB Debug x64]
i don't known what is problem !!?
API - 6
Command line - 3 @roozgar i got an error but i think its due to the picture itself, the message was: "image too small to scale"
@Shreeshrii i know about this issue, actually i was the one who mentioned that problem at the first place :)  @Nigje
سران ل: ش ۰
ن عکس خانه عکس های دورۀ قاجار
سست 55555 نت. 05555
۲۷۲ . = اج پ س __ وارون هاو خر ر ر سس
۸ صنعت برق روشهای تولید برق .
سری سوت پ 7-72 دا خر صد سست س می ی س ۳۷ / 2 خ % ب- 7 ۷۰۰ [
| ۹ { میرعماد . | سیر خطوط در ایران
ا ا نقاشی ومینیاتوراساد فرشچیان ا
و صاحبقرانیه قالی، نقاشی، خط و آثار دورههای
۳ __ کاج احمدشاهی س ایر _ __ آر دورۀ فاجار و پهلوی و جدای نی کر ی |
۴ ! نگارخانه ١ نقاشیهای دورۀ قاجار 2
۵ __ حخوضفانه __ اشیا و تابلوهای اروپایی هدیه شده به دربار آقا جار .
۳۶ | عکس خاند ت
س ر ا ری ر ر را ا _ - . س _ ت 7 را . سست . س ب ه ی ر صص
| س گی س ت ت س ب دس بی ا. ی ن ا یخ گی ی فا ر [
۸ | کاخ ملت آثار دورة بهار بی ١
١ ] ۴۰۰ [__ گیاهان داروی سنتی ا انواع گل و کبد ا
۱ 3 ۰و ات . ۰ % . ک ایا %
. ی ن کت حصر ا
شکل کوشک احمد شاه در مجموعۀ کاخ موزۀ نیاوران
@Nigje
Aborted (core dumped)
FROM ubuntu
libicu-dev \
libpango1.0-dev \
libcairo2-dev \
tar -zxvf leptonica-1.74.1.tar.gz && \
cd leptonica-1.74.1 && ./configure && make && make install && \
cd .. && rm -rf leptonica*
cd tesseract && \
cd .. && rm -rf tesseract
curl http://tleyden-misc.s3.amazonaws.com/blog_images/ocr_test.png > test.png
root@65369dfbb4d0:/# tesseract -v
leptonica-1.74.1
Found AVX
And here is where I found tesseract packages
root@65369dfbb4d0:/# find / -name "*tesseract*"
/usr/local/include/tesseract
/usr/local/bin/tesseract
/usr/local/lib/libtesseract.so
/usr/local/lib/libtesseract.la
I am going to try with leptonica-1.74  I just did it (restarted from scratch 5 minutes ago and same error)
root@1cd9578cac1d:/test/tesseract4# find / -name "*liblept*"
root@1cd9578cac1d:/test/tesseract4# find / -name "*leptonica*"
/usr/local/include/leptonica
**EDIT:** Same error with leptonica 1.74 and 1.74.1 :(
What is the minimum resources configuration to run it? Use GDB to get more info about the cause of the issue.  Asi in my previous comment I had:
root@65369dfbb4d0:/# tesseract -v
leptonica-1.74.1
Found AVX
leptonica-1.74
Found AVX
@amitdo
Could not initialize tesseract.
FROM ubuntu
libicu-dev \
libpango1.0-dev \
libcairo2-dev \
tar -zxvf leptonica-1.74.1.tar.gz && \
cd leptonica-1.74.1 && ./configure && make && make install && \
cd .. && rm -rf leptonica*
cd tesseract && \
cd .. && rm -rf tesseract
RUN curl -LO https://github.com/tesseract-ocr/tessdata/raw/master/fra.traineddata && \
To have all the languages
- Right-to-left/BiDi support
[In this research, they have managed to get 97% to 99% recognition rate of Arabic language, this rate excludes spacing and punctuation errors (2-5%).](https://drive.google.com/file/d/0BzDVkBcqiyEsbC16ZGktOWNiUDg/view)
What is really bothering me is that Kraken is a fork of ocropus that is using clstm, while Tesseract 4.x is the more complex and most sophisticated software that have improved ocropus techniques from scratch, but still can't achieve such practical results of Kraken.
@theraysmith @Shreeshrii @amitdo @zdenop
https://github.com/mittagessen/kraken
http://kraken.re
@bmwmy have you tested training yourself?
Kraken developer told me that those models that you presented, he made, and are not that sophisticated, maybe just for testing.
Will try to train and will give feedback. @bmwmy have you seen [this update by Ray](https://github.com/tesseract-ocr/langdata/commit/3ab6581a11eea90d4dc2ba46a811447ef231b644#diff-b8c77a8bc89ffb301d80233f2874c9d3),did he add the Arabic diacritics "Harakat"?
is that a good thing or a bad thing for ocr, what do you think?
for Arabic diacritics I think OCR engine should be aware of that but neglect it in the output or during ocr process.
LoOrenm 1pPpSsSUlI
In Tesseract mode (oem=0), I get correct text: Lorem ipsum
However I must tell you that when I Installed this and clicked on Add to Path and Set TESSDATA_PREFIX variable almost everything I had on the path stopped working.
`%SystemRoot%\system32;%SystemRoot%;%SystemRoot%\System32\Wbem;%SYSTEMROOT%\System32\WindowsPowerShell\v1.0\
lstmtraining -U ./cntrain/chi_sim.unicharset \
--continue_from ./cnoutput/chi_sim.lstm \
--train_listfile ./cntrain/chi_sim.training_files.txt  \
--eval_listfile ./cntrain/chi_sim.training_files.txt &>./cnoutput/basetrain.log
[Thu May 4 00:52:11 PDT 2017] /usr/local/bin/tesseract /tmp/tmp.vDN2ALtI8c/ara/ara.Arabic_Typesetting.exp0.tif /tmp/tmp.vDN2ALtI8c/ara/ara.Arabic_Typesetting.exp0 lstm.train ../langdata/ara/ara.config
ERROR: /tmp/tmp.vDN2ALtI8c/ara/ara.Arabic_Typesetting.exp0.lstmf does not exist or is not readable
keep in mind i copied the tessedit from the working version of tesseract and replaced it at the new machine but the same error occurred
[Thu May 4 04:43:32 PDT 2017] /usr/local/bin/tesseract /tmp/tmp.RwajXhdHOo/ara/ara.Arabic_Typesetting.exp0.tif /tmp/tmp.RwajXhdHOo/ara/ara.Arabic_Typesetting.exp0 lstm.train /home/ibr/Desktop/Tesseract4/langdata/ara/ara.config
ERROR: /tmp/tmp.RwajXhdHOo/ara/ara.Arabic_Typesetting.exp0.lstmf does not exist or is not readable
Thanks Hi Shree,
Thanks @Shreeshrii
tesseract -psm 1 -l eng /var/opt/app/main.jpg /var/opt/app/main_1 characters hocr
==> Using the sandbox
==> Applying b18cad4.patch
$ brew edit tesseract
@@ -68,10 +68,12 @@ class Tesseract < Formula
I'm using tesseract 4.00alpha with liptonica 1.74.1 on Ubuntu 14 to create LSTM files for multiple Arabic fonts, which some of them have the common numerical system, (1 2 3 4 ...) but some of these font contains the a different numerical system, which usually more common in the Arabic scripts,
which are ( ٠ ١ ٢ ٣ ٤ ٥ ٦ ٧ ٨ ٩)
yet the last set of numbers were not recognize but as symbols such as ! instead of ١ ,are these numbers are not integrated in the tesseract?
Persian numbers= ۹ ۸ ۷ ۶ ۵ ۴ ۳ ۲ ۱ ۰
Arabic numbers = ٠ ١ ٢ ٣ ٤ ٥ ٦ ٧ ٨ ٩
Arabic numbers' Unicode =\u0660 \u0661 \u0662 \u0663 \u0664 \u0665 \u0666 \u0667 \u0668 \u0669
you can check them [here](https://r12a.github.io/apps/conversion/) Yes, it mixed Persian with Arabic numbers (unicode) for example the image had these numbers
۶ ۵ ۴ ۳ >Persian
٣ ٤ ٥ ٦  > Arabic
sudo apt-get install asciidoc
[sudo] password for shree:
latex-beamer latex-xcolor libkpathsea6 libosp5 libostyle1c2 libptexenc1
tipa tk tk8.6 xmlto xsltproc
jadetex latex-beamer latex-xcolor libkpathsea6 libosp5 libostyle1c2
tipa tk tk8.6 xmlto xsltproc
[sudo] password for shree:
asciidoc
Selecting previously unselected package asciidoc.
asciidoc
Depends: python
python
Recommends: dblatex
NOTE: This is only a simulation!
asciidoc
Conf asciidoc (8.6.9-3 Debian:8.7/stable [all])
Stefan, I suggest to do something similar in Tesseract.
Since Tesseract code is based on C++, we should use a C++ style guide.
I want to train tesseract , But I got this error, Any help
--fontlist SimSun
--lang chi_sim
--linedata_only
--tessdata_dir /usr/share/tesseract-ocr/tessdata
--output_dir ./tesstutorial/chisimtrain
=== Starting training for language 'chi_sim'
Rendered page 0 to file /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.SimSun.exp0.tif
Extracting unicharset from /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.SimSun.exp0.box
Wrote unicharset file /tmp/tmp.sqbPsVBeRu/chi_sim//unicharset.
Loaded unicharset of size 322 from file /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.unicharset
=== Phase D: Generating Dawg files ===
--fontlist "SimSun"
--lang chi_sim
--linedata_only
--tessdata_dir /usr/share/tesseract-ocr/tessdata
--output_dir ./tesstutorial/cntrain
=== Starting training for language 'chi_sim'
Rendered page 0 to file /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.SimSun.exp0.tif
Wrote unicharset file /tmp/tmp.wiRXVpIiJ9/chi_sim//unicharset.
Loaded unicharset of size 322 from file /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset
Writing unicharset to file /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset
=== Phase D: Generating Dawg files ===
Generating word Dawg
[2017年 04月 27日 星期四 09:51:38 CST] /usr/local/bin/wordlist2dawg -r 1 ../langdata/chi_sim/chi_sim.wordlist /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.word-dawg /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset
Loading unicharset from '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset'
Reading word list from '../langdata/chi_sim/chi_sim.wordlist'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.word-dawg'
Generating frequent-word Dawg
Loading unicharset from '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset'
Reading word list from '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.wordlist.clean.freq'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.freq-dawg'
Loading unicharset from '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset'
Reading word list from '../langdata/chi_sim/chi_sim.punc'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.punc-dawg'
Loading unicharset from '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset'
Reading word list from '../langdata/chi_sim/chi_sim.numbers'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.number-dawg'
Failed loading language 'chi_sim_vert'
>Failed loading language 'chi_sim_vert'
and comment out first line related to loading of the vertical sub language  The documentation does not seem to specify the format of the text files required by the `train_listfile` option. Are there examples available of `eng.training_files.txt`?
ZIP file with one TIF and box file I'm trying to use: [Wilson1852_0.zip](https://github.com/tesseract-ocr/tesseract/files/958420/Wilson1852_0.zip). Out of the box, Tesseract already performs pretty well, but 150 years ago, house numbers in New York sometimes included ½, so I have to include this character in the `desited_characters` file:
--linedata_only \
ShreeDevi
I have not yet tried training with 4.00. @amitdo Is it not well documented, or not yet possible at all? @Shreeshrii Do you have examples of this process? Your box file is in wordstr format. That cannot be used with existing
Training from 'real' images as opposed to synthetic ones (with text2image), that what's not well documented.  >Out of the box, Tesseract already performs pretty well, but 150 years ago, house numbers in New York sometimes included ½, so I have to include this character in the desited_characters file:
Here are the modified scripts:
training/boxtrain.sh \
--fontlist "Century Schoolbook" "Dejavu Serif" "Garamond" "Liberation Serif" "Times New Roman," "FreeSerif" "Georgia" \
--output_dir ~/tesstutorial/nydlegacy
training/boxtrain.sh \
--linedata_only \
rm -rf ~/tesstutorial/eng_from_nyd
--append_index 5 --net_spec '[Lfx256 O1c105]' \
--model_output ~/tesstutorial/eng_from_nyd/nyd \
--continue_from ~/tesstutorial/eng_from_nyd/nyd_checkpoint \
--model_output ~/tesstutorial/eng_from_nyd/nyd.lstm \
combine_tessdata -o ~/tesstutorial/eng_from_nyd/nyd.traineddata \
~/tesstutorial/eng_from_nyd/nyd.lstm \
@Shreeshrii: ha, that's my repository! @bertspaan
@Shreeshrii: ok, I'll try some of the commands you've posted here, but I'm not going to spend much time on trying to train Tesseract, I'll wait until training from scanned images is improved.
BUT
tesseract eng.font.exp0.tif eng.font.exp0.box.lstm.train
but I just have tif/box pairs, so i come here for more information。 @Shreeshrii
It mostly duplicates parts of Leptonica, which is an **external** dependency.
@theraysmith, what do think about this idea?
I don't know...   Please see the discussion at https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/b2YFzN7MtJg/dq1-f8JjBgAJ
LEPTONICA_VERSION=1.71
>-- Looking for include file cairo/cairo-version.h
-- Looking for include file cairo/cairo-version.h - not found
-- Looking for include file unicode/uchar.h
-- Looking for include file unicode/uchar.h - not found
This problem is caused by an unusual build of Leptonica: instead of the normal configure / make, the script calls `./make-for-local` which uses a hand-built makefile (maybe made for Linux). I'm also surprised that TIFF support is disabled for the Leptonica build and doubt that this will work with Tesseract.
I found the original script on github and modified it minimally since I didn't understand it fully. The unusual Leptonica build has come directly from that original script. I didn't understand this, so I left it as I found it!
tessport/bin/tesseract -v
5. uninstalled Tesseract using HomeBrew
Pritam Dodeja Try `tesseract a.jpg stdout --oem 0 --psm 0 -l eng`
The quick brown dog jumped over the
over the lazy fox. The quick brown dog
Pritam
The warnings are ugly but seem harmless.
With `--oem 0` and `--psm 0` Tesseract works as expected.
With `--oem 1` and `--psm 0` Tesseract segfault.
tesstrain.sh --fonts_dir /usr/share/fonts --lang ara  --training_text ../../tesserac-ocr/langdata/ara.training_text   --langdata_dir ../langdata --tessdata_dir ./tessdata   --fontlist "Arial"   --output_dir ~/tesstutorial/aratest
=== Starting training for language 'ara'
ERROR: /tmp/tmp.XBcy4TVQwb/ara/ara.Arial.exp0.box does not exist or is not readable
ERROR: /tmp/tmp.XBcy4TVQwb/ara/ara.Arial.exp0.box does not exist or is not readable
``` --training_text ../../tesserac-ocr/langdata/ara.training_text
--lang ara   \
--linedata_only \
--output_dir ~/tesstutorial/ara  \
=== Starting training for language 'ara'
/tmp/tmp.xPjs35P5oP/ara/gt/ara.Arial.exp0.txt
[Wed Apr 12 14:56:38 DST 2017] /usr/local/bin/unicharset_extractor -D /tmp/tmp.xPjs35P5oP/ara/ /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.box
Extracting unicharset from /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.box
Wrote unicharset file /tmp/tmp.xPjs35P5oP/ara//unicharset.
.xPjs35P5oP/ara/ara.xheights --script_dir=../langdata
Loaded unicharset of size 187 from file /tmp/tmp.xPjs35P5oP/ara/ara.unicharset
Writing unicharset to file /tmp/tmp.xPjs35P5oP/ara/ara.unicharset
=== Phase D: Generating Dawg files ===
Generating word Dawg
Loading unicharset from '/tmp/tmp.xPjs35P5oP/ara/ara.unicharset'
Reading word list from '../langdata/ara/ara.wordlist'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.xPjs35P5oP/ara/ara.word-dawg'
Generating frequent-word Dawg
5oP/ara/ara.unicharset
Loading unicharset from '/tmp/tmp.xPjs35P5oP/ara/ara.unicharset'
Reading word list from '/tmp/tmp.xPjs35P5oP/ara/ara.wordlist.clean.freq'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.xPjs35P5oP/ara/ara.freq-dawg'
Loading unicharset from '/tmp/tmp.xPjs35P5oP/ara/ara.unicharset'
Reading word list from '../langdata/ara/ara.punc'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.xPjs35P5oP/ara/ara.punc-dawg'
Loading unicharset from '/tmp/tmp.xPjs35P5oP/ara/ara.unicharset'
Reading word list from '../langdata/ara/ara.numbers'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.xPjs35P5oP/ara/ara.number-dawg'
nicharset
Loading unicharset from '/tmp/tmp.xPjs35P5oP/ara/ara.unicharset'
Reading word list from '../langdata/ara/ara.word.bigrams'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.xPjs35P5oP/ara/ara.bigram-dawg'
Creating new directory /home/shree/tesstutorial/ara
Completed training for language 'ara'
shree@ALL-IN-1-TOUCH:/mnt/c/Users/User/shree/tesseract-ocr$
https://github.com/tesseract-ocr/langdata
./langdata/ara
./tesseract
./tesseract/tessdata
I have the same problem like @am0awad .
--lang chi_sim   \
--linedata_only \
--output_dir ./tesstutorial/chi_sim
./langdata/chi_sim
=== Starting training for language 'chi_sim'
mktemp: illegal option -- -
mktemp [-d] [-q] [-u] -t prefix
[2017年 8月 3日 星期四 15时23分24秒 CST] /usr/local/bin/text2image --fonts_dir=/Library/Fonts --font=AR PL UKai CN Light --outputbase=/sample_text.txt --text=/sample_text.txt --fontconfig_tmpdir=
ERROR: /var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.Arial_Unicode_MS.exp0.box does not exist or is not readable
ERROR: /var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.AR_PL_UKai_CN_Light.exp0.box does not exist or is not readable
ERROR: /var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.AR_PL_UKai_CN_Light.exp0.box does not exist or is not readable
Error: Call PrepareToWrite before WriteTesseractBoxFile!!
> > Times_New_Roman.exp0.tif
Times New Roman is in the list of Persian fonts in
is trained for Times New Roman?Or the listed fonts are just recommended?
> ShreeDevi
> > > > Times_New_Roman.exp0.tif
> > AZFiASKi4zAcvT6hL8SkvIybrnjQVMWrks5stLLOgaJpZM4M6-yu>
cd tesseract
$ cmake .. -DLeptonica_DIR=leptonica-$LEPT_VER/build
gcc-4.8.
@xlight,
@amitdo, I did not get the same error message initially, therefore I don't know. The `Dockerfile` uses the master branch of https://github.com/travis-ci/travis-build. If there is an issue with that latest version, it might damage the docker build process. I looked for a stable version of `travis-build`, but the latest release was made in 2014.  Hello,
Ozy.  Hello!
3) tesseract -v:
>  leptonica-1.74.1
> checking for strings.h... yes
> checking for tiffio.h... yes
> checking malloc.h presence... yes
> checking for malloc.h... yes
> checking for pango... yes
> checking for cairo... yes
> gdb --args ./tesseract image14281.jpg image14281
>  -l rus
> Type "apropos word" to search for commands related to "word"...
> mage14281 -l rus
> Detected 24 diacritics
> Thread 2 received signal SIGILL, Illegal instruction.
> Thread 2 received signal SIGILL, Illegal instruction.
fi
But in hocr output, the bounding box coordinates of the words are with respect to the original skewed image.
`hocr`
`tsv`
frustrated. Why is open source always so sloppy when it comes to stuff like this?
./configure --host=i686-w64-mingw32 CXXFLAGS="-Wall -g"
>Why is open source always so sloppy when it comes to stuff like this?
> Why is open source always so sloppy when it comes to stuff like this?
>But no, everybody has to try and go as far as possible to avoid The Big Bad Company, using mingw, cppan, msys2, **cmake**, blah de blah de blah....
Hi @essamzaky,
@egorpugin, do you have any comment?  >it failed to run VS2010
egorpugin commented
> egorpugin commented
என்றும் அன்புடன்
வாசு
அன்பைத் தவிர வேறு ஒன்றும் வேண்டேன் பராபரமே!
Vasu Devan V.
http://www.kamban.com.au
http://brahas.com
cd tesseract
cppan
Thanks egor
@essamzaky -> Thank you very much! The information provided in [wiki](https://github.com/tesseract-ocr/tesseract/wiki/Compiling) did not worked for me, bu this worked. Why don't you change the wiki?
cd tesseract
cppan
* Tesseract 3.00 and higher
Added 3.01 and 3.03 versions to the report: https://abi-laboratory.pro/tracker/timeline/tesseract/
@Shreeshrii,
Done: https://abi-laboratory.pro/tracker/timeline/tesseract/
![tesseract-5](https://cloud.githubusercontent.com/assets/1517837/25801811/724dac08-3400-11e7-9af3-ff379784aeaf.png)
Lines with error:
wrote best model:/home/shree/tesstutorial/hinlayer_from_hin/hinlayer2.454_23816.lstm
Loaded 61/61 pages (1-61) of document /home/shree/tesstutorial/hineval/hin.Sahitya.exp0.lstmf
But i have to extract Arabic text for which i download ara.traineddata and its related files from here
then i tried a jpeg image and got its output on a text file. then it retrieves arabic txt but not proper result
جهمة # ك سو-ة
. ظرسظة عهود
١صي سعد إلاء . سلعة-ا
. سدلعدسسلعلىوس
وا{ قللا{ ٧تلا ٣تاتع٨ اق با لإت«اح» . سا مي ضجة دةسءع عظك
«قلم«ة٧حلا و و«تعهاق بي ئت»حه لة
and when i used -l ara+eng parameter then out says no best words !! and tesseract stoped working.
Really weird. Arabic is not fully accurate with 4.0. there are already open issues
On 26-Mar-2017 5:40 PM, "waleedraza786" <notifications@github.com> wrote:
> But i have to extract Arabic text for which i download ara.traineddata and
> retrieves arabic txt but not proper result
> تاللخ تؤم اللتين إنمثالترلننمهنن . نتيئممنزإنمئالترننئنجيأ الهلع
> نلجمتاالعنننالذ
> اأ ط هني يزصبنالر انللريي٠ز لزنغنميز غننهمة غنرالتنطنويي غننهم
> ثلآ الينننالنيتى الم ئللز النهنارن لا نمنممة فيو نلإى يأئلتمبيتى انللريي٠ز
> حمم طهه ط نك حمم حمم
> نلمضولإ باأغنمي زنقبينولإ العثلاث بنينا{ نيرمالا/تنم ننهينولإ زساللوييز
> نقيبة زينى أ لثطناليببم عزتنتازيأ قا )ءه غذارنإ غغليأ زثفئى الثامبي تل تيو{
> مدعو ٠ إلا ا ئغستننم زتا منرننننغنولإ ليننئوننيينم متنمضز نزيلا/نرنم الئ
> تنطنا
> زلئن غذار،نإ أليق يمناسقالوا مننثيدنون زلنا قيل نمنم لا نغينمنواي
> ينائيهؤقلي
> and when i used -l ara+eng parameter then out says no best words !! and
>    - Fix a typo in tesseract(1) man page
>    - ccutil/ambigs: Optimize tesseract::UnicharIdArrayUtils::compare
>    - downgrade to leptonica 1.73
>    - use leptonica from master git repository (1.74)
>    - Fix build for Mingw-w64 (120a5dbdab78) and non C++11 build (VS2010)
>    - Update cppan.yml
>    - leptonica 1.74.1 is needed for cppan
>    - Backport cppan fixes.
>    - Add .cppan to ignore list.
>    - Rename cppan/cmake targets.
>    - *M* api/capi.h
>    - *M* autogen.sh
>    - *M* ccstruct/boxword.h
>    - *M* ccstruct/imagedata.h
>    - *M* ccutil/ambigs.h
>    - *M* ccutil/bits16.h
>    - *M* ccutil/ccutil.h
>    - *M* ccutil/elst.cpp
>    - *M* ccutil/elst.h
>    - *M* ccutil/elst2.h
>    - *M* ccutil/errcode.h
>    - *M* ccutil/genericheap.h
>    - *M* ccutil/globaloc.h
>    - *M* ccutil/hashfn.h
>    - *M* ccutil/helpers.h
>    - *M* ccutil/lsterr.h
>    - *M* ccutil/mainblk.cpp
>    - *M* ccutil/ocrclass.h
>    - *M* ccutil/params.h
>    - *M* ccutil/platform.h
>    - *M* ccutil/serialis.cpp
>    - *M* ccutil/strngs.h
>    - *M* ccutil/tessdatamanager.h
>    - *M* ccutil/unicharset.h
>    - *M* classify/kdtree.h
>    - *M* cppan.yml
>    - *M* cutil/bitvec.h
>    - *M* cutil/cutil.h
>    - *M* cutil/danerror.cpp
>    - *M* cutil/efio.cpp
>    - *D* cutil/listio.h
>    - *M* dict/dawg.h
>    - *M* doc/ambiguous_words.1.html
>    - *M* doc/ambiguous_words.1.xml
>    - *M* doc/unicharambigs.5.asc
>    - *M* doc/unicharambigs.5.html
>    - *M* doc/unicharambigs.5.xml
>    - *M* doc/unicharset.5.html
>    - *M* doc/wordlist2dawg.1.html
>    - *M* doc/wordlist2dawg.1.xml
>    - *M* textord/bbgrid.cpp
>    - *M* textord/bbgrid.h
>    - *M* textord/blkocc.h
>    - *M* textord/devanagari_processing.h
>    - *M* textord/oldbasel.cpp
>    - *M* textord/tovars.h
>    - *M* training/boxchar.h
>    - *M* training/language-specific.sh
>    - *M* training/pango_font_info.cpp
>    - *M* training/pango_font_info.h
> Patch Links:
Running aclocal
* Clang 3.4 and above
and compiled an executable to extract characters on number plates. There's
> It makes no sense.
"_TIFFReadRGBAImageOriented", referenced from:
pixErodeCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
pixErodeCL(int, int, unsigned int, unsigned int) in libtesseract_opencl.a(openclwrapper.o)
"_clEnqueueNDRangeKernel", referenced from:
pixErodeCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
pixErodeCL(int, int, unsigned int, unsigned int) in libtesseract_opencl.a(openclwrapper.o)
pixErodeCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
pixErodeCL(int, int, unsigned int, unsigned int) in libtesseract_opencl.a(openclwrapper.o)
make[1]: *** [libtesseract.la] Error 1
* Sphinx v1.5.1
checking for cairo... no
configure: WARNING: Try to install libcairo-dev?? package.
pixErodeCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
pixErodeCL(int, int, unsigned int, unsigned int) in libtesseract_opencl.a(openclwrapper.o)
make[1]: *** [libtesseract.la] Error 1
Recommended: libffi ✔
Optional: graphviz ✔, ocaml ✔
==> Options
--with-graphviz
--with-ocaml
Build with ocaml support
--without-libcxx
--without-libffi
==> Caveats
parallel can cause all kinds of trouble.
Likewise, removing the explicit `libtiff` linkage will fail.
tesseract version:
leptonica-1.74.1 (Mar 23 2017, 02:16:52) [MSC v.1910 LIB Release x64]
libgif 5.1.4 : libjpeg 9b : libpng 1.6.28 : libtiff 4.0.7 : zlib 1.2.11 : libwebp 0.6.0 : libopenjp2 2.1.2
Found AVX
Since then, Ray deleted the Cube code.
@egorpugin
+ Add Support for VS2015 and VS2017 with cppan
+ Require leptonica 1.74 or higher
> Shree, here it is:
export LD_LIBRARY_PATH=$HOME/local/tesseract/lib:$LD_LIBRARY_PATH
tesseract $*
#mytesseract -c preserve_interword_spaces=1 -l spa  $1 scanned
``` Can't reproduce @Shreeshrii :/
I tried it with the python tesserocr wrapper like so:
Gives me this error:
and latest leptonica & tesseract
thanks @amitdo, but no luck:
checking for g++... g++
apt-get install autoconf-archive pango-devel cairo-devel icu-devel
cd tesseract-4.00.00alpha && ./autogen.sh && ./configure && make && make install
#include "txtocr.hpp"
Txtocr a;
private:
std::string utf8_to_latin			(const char * in);
#include <tesseract/baseapi.h>
#include <leptonica/allheaders.h>
#include "txtocr.h"
else if(s == "para"){
level = tesseract::RIL_PARA;
std::string Txtocr::utf8_to_latin(const char* in){
if(ch <= 0x7f){
// do whatever you want for out-of-bounds characters
// Open input image with leptonica library
// Initialize tesseract-ocr, without specifying tessdata path
if(api->Init(NULL, "dan+eng")){
error("Could not initialize tesseract");
if(ri != 0){
ri->BoundingBox(level, &x1, &y1, &x2, &y2);
root.add_child("elms", children);
But what about those shared objects/files?
If you want latest 4.0.0alphacode, please clone from master in GitHub.
>> But what about those shared objects/files?
cd leptonica-1.74.1 && ./configure && make && make install
Dots wrong recognized :
--fonts_dir /home/idris/mylot \
--lang ara --linedata_only \
--output_dir ~/mylottutorial \
--fontlist "mylotus Bold"
=== Starting training for language 'ara'
[Mon Nov 13 01:52:41 PST 2017] /usr/local/bin/text2image --fonts_dir=/home/idris/mylot --font=mylotus Bold --outputbase=/tmp/font_tmp.Rf99kiznKj/sample_text.txt --text=/tmp/font_tmp.Rf99kiznKj/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.Rf99kiznKj
Rendering using mylotus Bold
Rendered page 0 to file /tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0.tif
Rendered page 1 to file /tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0.tif
Rendered page 2 to file /tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0.tif
[Mon Nov 13 01:52:44 PST 2017] /usr/local/bin/unicharset_extractor --output_unicharset /tmp/tmp.s7NZRqv0Qa/ara/ara.unicharset --norm_mode 2 /tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0.box
Extracting unicharset from box file /tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0.box
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ُت'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًام'
Normalization failed for string 'ًا'
Normalization failed for string 'ُأ'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ِّر'
Normalization failed for string 'ُي'
Normalization failed for string 'ُّل'
Normalization failed for string 'ِحل'
Normalization failed for string 'ُه'
Normalization failed for string 'َّط'
Normalization failed for string 'ِّف'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًا'
Normalization failed for string 'ًام'
Normalization failed for string 'ًى'
Hi , zdenop ,
for multiple languages use
At one time both per and fas were there.
Shree,
PersianOCR is an external project using Tesseract (3.02 I think) - see https://github.com/reza1615/PersianOcr ​no 'per' is removed and changed persian traindata to 'fas'​
> .ESHBEE
**Questions**
1. Is there a way to read numbers like these from tesseract?
ShreeDevi
> I used latest Tesseract sources, a slightly modified font list and a
--output_dir ~/tesstutorial/frk
Also, please check whether the fonts you are using have support for the
font sites. If you or Ray have the resources to get these fonts, you can
ShreeDevi
> Fraktur fonts, but several of the image not even include all normal ASCII
> (combinations of certain characters, like for example ffi, which need a
> special rendering).
These are the freely available Fraktur fonts that I found:
FRAKTUR_FONTS=(
"CaslonishFraxx Medium" \
"UnifrakturCook" \
"UnifrakturMaguntia" \
"UnifrakturMaguntia16" \
"UnifrakturMaguntia17" \
"UnifrakturMaguntia18" \
"UnifrakturMaguntia19" \
"UnifrakturMaguntia20" \
"UnifrakturMaguntia21" \
https://github.com/paalberti/tesseract-dan-fraktur/files/721956/frk.box-tif-pairs.zip @stweil The page about fonts will be very useful. I have added info about Devanagari fonts and will update more later.
Please see pages 2-9 in http://www.sanskritweb.net/fontdocs/genzmer.pdf
Aborted (core dumped)
> AL056TlrhrROzIm6VOXVoiHjygnInOUGks5sTyRvgaJpZM4Ma6ed>
> <https://github.com/notifications/unsubscribe-auth/AZFiAaUyiObmY6Hi8q10PMUhoGYA_Wolks5sUmGugaJpZM4Ma6ed>
Peace :-) @egorpugin
Is there no good alternative to AppVeyor?  Blacklist and whitelist no longer work in 4.00alpha. They used to work in 3.04.
- cli with option `-c tessedit_char_whitelist=abcdefghijklmnopqrstuvwxyz`
tess->SetVariable("tessedit_char_whitelist", "01234567890abcdefg");
Tesseract returns not only ascii + language-specific characters but also some strange other characters from UTF-8.
> SHELL GRAMMAR
./.libs/libtesseract.so: undefined reference to `omp_get_thread_num'
./.libs/libtesseract.so: undefined reference to `GOMP_sections_end_nowait'
./.libs/libtesseract.so: undefined reference to `omp_get_num_threads'
configure: error: in `/home/azureuser/ocr/tesseract':
@theraysmith, @jbreiden
Isn't this remark from Ray also relevant here?
./.libs/libtesseract.so: error: undefined reference to 'TIFFFdOpen'
./.libs/libtesseract.so: error: undefined reference to 'TIFFScanlineSize'
./.libs/libtesseract.so: error: undefined reference to 'TIFFReadRGBAImageOriented'
./.libs/libtesseract.so: error: undefined reference to 'TIFFReadScanline'
./.libs/libtesseract.so: error: undefined reference to 'TIFFClientOpen'
./.libs/libtesseract.so: error: undefined reference to 'TIFFReadDirectory'
./.libs/libtesseract.so: error: undefined reference to 'TIFFCleanup'
make[2]: *** [tesseract] Error 1
for your os) before building tesseract
ShreeDevi
On Tue, Feb 28, 2017 at 11:19 AM, idiosyncraticee <notifications@github.com>
> make[2]: *** [tesseract] Error 1
./configure CC=gcc CXX=g++ CPPFLAGS=-I/usr/local/Cellar/icu4c/56.1/include LDFLAGS="-L/usr/local/Cellar/icu4c/56.1/lib -L/usr/local/lib" @idiosyncraticee  Glad you have solved your problem but for the record, that was completely unrelated to the issue at hand. Indeed, the command-line snippet you have posted suggests that libtiff underlinking has been fixed in the 4.x branch - one can clearly see -ltiff there. Which may make fixing this in the 3.x branch a simple matter of backporting a patch. >Tesseract does not reference any libtiff symbols
@egorpugin @zdenop  Should it be added to the 3.05 branch for the timebeing i.e. till opencl is looked at.  @jbreiden
Not exactly...
> @mkszuba, @idiosyncraticee, @Shreeshrii, @jbreiden, @amitdo, @egorpugin, and/or @zdenop:  If you don't mind my trying my hand at resolving this issue, what's the local procedure for submitting backport PRs, at least with respect to the Git/GitHub workflow?  Do I just have to mention the commit from which the new one backports changes, or will I have to do something more complicated (like, say, use `git cherry-pick` or something…?)
Alex
5       1       1       1       2       5       1748    196     447     49      0       Avantgarde-ösung,  <------- L is dropped
5       1       1       1       2       8       2958    201     429     49      54      Dialoginstrumenten
Have you tried using multiple languages for recognition, eg. -l eng+chi
languages and run text2image with different fonts.
You will then get some images with text in one language and some in the
other.
https://github.com/tesseract-ocr/tessdata/blob/master/chi_sim.traineddata
https://github.com/tesseract-ocr/langdata/tree/master/chi_sim
https://github.com/tesseract-ocr/langdata/blob/master/chi_sim/chi_sim.training_text
https://github.com/tesseract-ocr/langdata/blob/master/chi_sim/desired_characters
https://github.com/tesseract-ocr/langdata/blob/master/chi_sim/chi_sim.training_text.unigram_freqs
--text ./langdata/chi_sim/chi_sim.training_text \
--outputbase ./langdata/chi_sim/chi_sim\
>./langdata/chi_sim/fontslist.txt
ShreeDevi
> You will then get some images with text in one language and some in the
> other.
ShreeDevi
> https://github.com/tesseract-ocr/langdata/tree/master/chi_sim
> sim/chi_sim.training_text
> --text ./langdata/chi_sim/chi_sim.training_text \
> --outputbase ./langdata/chi_sim/chi_sim\
> >./langdata/chi_sim/fontslist.txt
> ShreeDevi
>> multiple languages and run text2image with different fonts.
>> You will then get some images with text in one language and some in the
>> other.
leptonica-1.74.1
Found AVX
@zdenop, what about using GIT_REV only for versions without tag, no matter whether it is a debug or a release build? Then released stable versions would not show GIT_REV. >Not using --enable-debug increases processing speed about 6%.
tesseract 3.05.00
leptonica-1.74.1
[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
experimental version it was OEM 4.
> test.hocr.txt
> multiple occurrences of ocrx_word artifacts where the bbox coordinates are
> These ocrx_word occurrences seem to be occurring in relation to vertical
> Whatever the state of the image, it can't be correct for an ocrx_word to
> leptonica-1.73
> Major B
ShreeDevi
ShreeDevi
> ShreeDevi
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 03658DF0 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddatalstm-punc-dawg)
Detected 18 diacritics
This application has requested the Runtime to terminate it in an unusual way.
This application has requested the Runtime to terminate it in an unusual way.
This application has requested the Runtime to terminate it in an unusual way.
This application has requested the Runtime to terminate it in an unusual way.
Detected 18 diacritics
This application has requested the Runtime to terminate it in an unusual way.
This application has requested the Runtime to terminate it in an unusual way.
This application has requested the Runtime to terminate it in an unusual way.
This application has requested the Runtime to terminate it in an unusual way.
leptonica-1.74.1
Found AVX
Thanks  # Visarga vs Colon
Please see https://shreeshrii.github.io/tess4eval-san/
Visarga being recognized as colon etc.
# Nukta
Another error that I have noted for Devanagari is that Northern style orthography of some letters is not being recognized correctly.
http://www.sanskritweb.net/cakram/
different la forms displayed in
http://www.omniglot.com/writing/devanagari.htm
More old style sample text -
http://ctan.imsc.res.in/language/devanagari/velthuis/doc/manual.pdf
https://github.com/gxrxrdx/tesseract-ocr/issues/1360 # Devanagari Varnamala - Alphabet
A listing of the basic Devanagari Alphabet is also not being recognized correctly.
see https://shreeshrii.github.io/tess4eval_deva/ # Eyelash ra - RA vs RRA
Ref: https://r12a.github.io/scripts/devanagari/block
U+0930 DEVANAGARI LETTER RA
When used as a half-consonant in Marathi or Newari,
this character uses the 'eyelash-RA' shape,
U+0930 DEVANAGARI LETTER RA र + U+094D DEVANAGARI SIGN VIRAMA  ् with U+200D ZERO WIDTH JOINER.
The eyelash-RA is transcribed as r̆.
U+0931 DEVANAGARI LETTER RRA
• for transcribing Dravidian alveolar r
• half form is represented as 'Eyelash RA'
Tesseract is recognizing it as the second case -  U+0931 DEVANAGARI LETTER RRA  + U+094D DEVANAGARI SIGN VIRAMA  ्
see samples from mar.Adobe_Devanagari.exp0.txt to mar.e-Nagari_OT.exp0.txt in https://shreeshrii.github.io/tess4eval_marathi/index-hin.html
@amitdo commented:
@zdenop, @egorpugin
tesseract/api/baseapi.h
`AC_INIT([tesseract], [3.05.00dev], [https://github.com/tesseract-ocr/tesseract/issues])`
abipkgdiff output (comparing 3.04.01 and 3.05.00):
WERD_RES::FakeWordFromRatings()
GenericVector<tesseract::DawgPosition>::clear()
WERD_RES::FakeWordFromRatings(PermuterType)
tesseract::DawgCache::~DawgCache()
https://abi-laboratory.pro/tracker/timeline/tesseract/
https://abi-laboratory.pro/tracker/timeline/leptonica/
![tesseract-2](https://cloud.githubusercontent.com/assets/1517837/24391524/af496122-13a0-11e7-8dd5-c138319425db.png)
You would need to include fcntl.h and io.h too.
wadex1
Portez ce vieux whisky au juge
blond qui fume sur son île
o n d q u i f u m e s u r s o n île
The quick brown dog jumped over the
over the lazy fox. The quick brown dog
o c r
a n d
p o i n t
t o
q u i c k
q u i c k
q u i c k
q u i c k
After Tesseract, before Ghostscript
After Ghostscript, here is Acrobat showing that a search for the word "p o i n t" matches because it is now convinced that there are spaces between each character. The highlighting is now misaligned as well.
```diff
pdftotext via poppler...
Versions..
* random text that is copied and pasted will preserves word breaks
* searching for "rela" will select all occurrences of "relativity"
I must have been mistaken on my early remark that there was a search functionality regression on "pdf.js" (by which I meant pdfium). I cannot replicate whatever problem I found with either my test files or experiment_gs.pdf. @amitdo With the way this experiment is set up, finding that pdf.js gives the same result on control and experiment is not a regression. It just means there are more cases of text extraction not working perfectly unrelated to running them through Ghostscript. I confirmed that experiment.pdf, experiment_gs.pdf and control.pdf all have the problem you identified with "making use of the theory". Maybe there's something else we can do.
> <https://github.com/notifications/unsubscribe-auth/ABvcM8nWXMrLQOBIMd6SZiBjotpDRqpqks5rbt-kgaJpZM4L6dNS>
ShreeDevi
Problematic frame:
however we have to increase support to multilanguage and need many fixes to 4.0 final.. My personal opinion is that we should drop the old engine. It will be much easier to maintain and support Tesseract in this form. I also support dropping the OpenCL code. I also think we should release a last 3.0x version in the upcoming 2-6 weeks. I cannot agree with removing old ocr engine, until new lstm engine has support vertical text.
ShreeDevi
1. glyphs rarely seen in training (capital letters, numbers, certain punctuations)
2. unusual patterns (letter-spacing, e.g. R U N N I N G   H E A D)
**Old method: tesseract -l lat --oem 0 --psm 7:**
SECVNDAE
LIBER
AD
zo PROGYMNASMATA
IN GENEROSVM ADOLESCEN-
caﬁris millia paITuum circitér fcptem.Rc_x cum hoc itincrc szaré ucnirc
**New method: tesseract -l lat --oem 1 --psm 7:**
SECV NDAHE
IN GE NE R O SVM A D O L E S CE N-
caüris millia paiTuum circiter fcptcm.Rc-x cum hoc itinere Cæfarö uenit:
LIB E R
IN GENEROSVM ADOLESCEN.
caftris millia pafluum circiter feptem. Rex cum hocitinere Cafaré uenire
**So I vote for keeping the old code just for these edge cases which are otherwise hard to recognize at the same level of consistency.** >Admittedly, although this is all Latin text, the recognition looks much better **without any language model**
>tesseract -l eng --oem 1 --psm 7 @theraysmith commented in commit b453f74e01
The multi-lang mode could still do with more work to run it at a lower level, (inside RecognizeLine) but the legacy engine could do to go before that, or multi-lang could get really unnecessarily complex.
For example ABBYY [uses several ocr methods](https://abbyy.technology/en:features:ocr:classifier) in his OCR engine: Bayesian classifier with about 100 features, raster classifier, contour classifier, structure classifier and then differentiating classifiers. The problem is that the code for the old engine is too large and complex. As Ray indicated, keeping it will make improving the new LSTM engine much harder. https://github.com/tesseract-ocr/tesseract/issues/733
On the other hand, the accuracy and speed of complex scripts such as Devanagari has improved with the LSTM traineddata (though I haven't been able to add a top layer or fine tune those because of unicharset limitations).
* [tesseract-ocr](https://github.com/search?q=topic%3Atesseract-ocr)
https://sourceforge.net/projects/tesseract-ocr-alt/files/?source=navbar
Big thank! sorry for my bad english Thank you very much!
> tesseract -v
>  leptonica-1.74.1
> the chroniclers of the doings of the habitual criminals of art. It is sometimes
> would become confirmed misanthropes; or, if I may borrow a phrase from
tesseract -v
leptonica-1.74.1
Found AVX
tesseract testeng.png testeng --oem 1 -l eng
the chroniclers of the doings of the habitual criminals of art. It is sometimes
would become confirmed misanthropes; or, if I may borrow a phrase from
could be related to OpenCL I rebuilt HEAD without OpenCL and got the same result.  I would suppose this has to be something screwy with OSX preview, since it doesn't appear to happen in Adobe Acrobat (or Chrome, which I also opened it in just now).
--append_index 3 --net_spec '[Lbx256 O1c105]'  \
Lbx256:512, 657408
For some reason /home/shree/tesstutorial/khmlayer1_from_khm/ did not have appropriate write priviledge causing the error.
Hello @Shreeshrii
When i use command "tesseract test.png out", the result is "01234567Beabcdelghijklmnopqrstuvwxyz".
> 01234567Beabcdelghijklmnopqrstuvwxyz".
> It has 4 wrong text.
27 Unfortunately newer versions of Tesseract also require a new version of
31 Leptonica, which prevents you from having to collect and set up projects for all
83 ## Building Tesseract
95     cd tesseract-ocr
section under windows re building with cppan
@egorpugin  will it work with vs2013? Thanks!
It would be helpful to users if you update the wiki regarding cppan
> <https://github.com/notifications/unsubscribe-auth/AE2_o6iSxuA8jeGbYJKSYyeMuRAQiik9ks5raBTXgaJpZM4LzeyP>
API example:
#include <tesseract/baseapi.h>
#include <leptonica/allheaders.h>
// Open input image with leptonica library
https://vorba.ch/2014/tesseract-3.03-vs2013.html
Thanks try with cppan and directions given in
ShreeDevi
tesseract -v
leptonica-1.74.1
Found AVX
ShreeDevi
On Wed, Feb 1, 2017 at 6:35 AM, Asko Nivala <notifications@github.com>
Just in case, the report of "tesseract -v":
leptonica-1.73
--append_index 5 --net_spec '[Lfx256 O1c105]'
--train_listfile  /mnt/c/Users/User/shree/jtess/samples/vie/vie.training_files.txt
Thank you. + tesseract-ocr google group
binaries.
Unofficial experimental binaries of tesseract-ocr 4.0.0-alpha (Jan 30,
them.
ShreeDevi
Can someone kindly assist me in resolving them? Try installing with cppan as described in
> Error LNK1120 8 unresolved externals tesseract
> SIMDDetect::avx_available_" (?avx_available_@SIMDDetect@@0_NA) tesseract
> SIMDDetect::sse_available_" (?sse_available_@SIMDDetect@@0_NA) tesseract
> Tesseract@tesseract@@QEAAXAEBVSTRING@@0PEAVBLOCK_LIST@@@Z
> (?LSTMRecognizeWord@Tesseract@tesseract@@QEAAXAEBVBLOCK@@PEAVROW@
> QEAAXAEBUWordData@2@PEAPEAVWERD_RES@@PEAV <https://github.com/PEAV>?$
> (?init_tesseract_lang_data@Tesseract@tesseract@@QEAA_
> (?init_tesseract_lang_data@Tesseract@tesseract@@QEAA_
> (?init_tesseract_lang_data@Tesseract@tesseract@@QEAA_
cd tesseract
cppan
cmake ..
Add **cppan** to you system variable **PATH**.
**cd tesseract**
**cppan
cmake ..**
@saint1729
@egorpugin ， I opencv cppan.yml use txt. so the format have changed. what editor can i use to recover it?thanks!
@saint1729 @egorpugin ，I had open cppan.yml use notepad++, but here also have same error!
leptonica-1.74.1
leptonica-1.74.1
Found AVX
Only @theraysmith can answer this question.
--oem 0
មានរុសចក្ដីរិ៍ប្រប្រួលជាធម្មតាប់់ម្បាស៊ឹបប្លែឋអ៎ប៏លប់់ប់់។
ថ្ងៃពុធហ្ស៊ុក)កេញ្ញះ
និងមានទ្រង់អៈភ្យិងចំាងភ្លីផ្ដេកៗពុឝ៊ូស៊ឺន
កម្ពុជាធ្លាក់ចុះយ៉ាងឆាប់រហ័សអៈពាញ្ញះថ្លយ៉ាំវនេញ្ញះក្ងិកក្ងក់ពេកពុ
ទេរុំច់់មានញ្ញើសាភណ័គ្ររស់ស្ឆាតអៈពាខញ្ញើហកុះនាញ្ញះញ្ជែ
ដេីម្បិកាក់បន្ថយការស្អុះចរាចរណំឬម្មេណឺសដានភ្លឣផ្តរស្សុ
--oem 1
Processing word with lang kan at:Bounding box=(163,2011)->(1231,2056)
Trying word using lang kan, oem 1
Best choice: accepted=1, adaptable=0, done=1 : Lang result : ಪ್ರೆಸ್, : R=3.81155, C=-2.00782, F=1, Perm=8, xht=[0,3.40282e+38], ambig=0
str	ಪ್	ರೆ	ಸ್	,
I do not think it should disappear. However, if the word is almost certainly incorrect, then it should be marked in some easy way for users to fix the OCRed txt.
I find that the words which are getting dropped are also the same ones which are not being picked up by tesseract when using 'makebox'. I has posted a sample with devanagari in another thread. (https://github.com/tesseract-ocr/tesseract/issues/664#issue-201505043 )
Here is a kannada sample:
![kan box missing](https://cloud.githubusercontent.com/assets/5095331/22395065/278b840c-e558-11e6-8ba5-0217592f1661.png)
![kan recognition missing](https://cloud.githubusercontent.com/assets/5095331/22395066/2ea254a0-e558-11e6-8fa9-e6f0cfbc0d17.png)
> A tilde (~) in an OCR-generated text file is treated as a reject character. A circumflex (^) is interpreted as a suspect marker and serves to mark the following character as suspect. For example, in Ne^vada, the v is marked as suspect. The value of these special characters is assessed when computing marked character efficiency.
eg: ಅ ಆ; ಉ ಊ; ಎ ಏ ಐ; ಒ ಓ ಔ; ಅಂ ಅಃ
ಡ ಢ; ದ ಧ ಥ; ರ ಠ ಝ; ಪ ಫ ಘ ; ಬ ಭ ; ವ ಮ ; ೦ ಂ ; ಕ೯ರ್ಕ; ೬ ಕ್ಮ
2. in-consistencies in guNita formations
eg: ವು ಪು
3. vottu of ತ ನ ಮ ಯ ರ ಲ  not like main character.
4. ಯ ಝ ಮ can lead to wrong recognition because of splitting of parts of the character by OCR process
5. ೕ is part in three different situations ಕೀ ಕೇ, ಕೋ
MNS Rao
Hope that Ray can make something out of this feedback. https://shreeshrii.github.io/tess4eval_kannada/
Images and gt are in
http://mile.ee.iisc.ernet.in/mile/publications/softCopy/DocumentAnalysis/Nethra_ICFHR2010_Data.pdf
http://mile.ee.iisc.ernet.in/mile/publications/softCopy/DocumentAnalysis/ Yes, both ZWJ and ZWNJ are important for Indic languages. Please see
http://unicode.org/faq/indic.html
If the sequence U+0924, U+094D is not followed by another consonant letter (such as "na") it is always displayed as a full ta glyph combined with the virama glyph "dev-ta-virama".
Unicode provides a way to force the display engine to show a half letter form. To do this, an invisible character called ZERO WIDTH JOINER should be inserted after the virama:
U+0924	0924	DEVANAGARI LETTER TA
U+094D	094D	DEVANAGARI SIGN VIRAMA (= halant)
U+0928	0928	DEVANAGARI LETTER NA
Unicode also provides a way to force the display engine to show the virama glyph. To do this, an invisible character called ZERO WIDTH NON-JOINER should be inserted after the virama:
U+0924	0924	DEVANAGARI LETTER TA
U+094D	094D	DEVANAGARI SIGN VIRAMA (= halant)
U+0928	0928	DEVANAGARI LETTER NA
This sequence is always displayed as a full ta glyph combined with a virama glyph and followed by a full na glyph "dev-full-ta-virama-full-na
Please see kannada chapter in
Vowel letters are encoded atomically in Unicode, even if they can be ana-
@theraysmith
I found that when using Marathi traineddata words which used half ra (repha) were not being recognized correctly, it could be related to the ZWJ and ZWNJ problem.
Since unicode has evolved over time, there maybe legacy representations still around in the webtext.
str	ם	ה	י	ת	ו	ח	ו	ר	ב	ב	צ	מ
any_nonspace_delimited ||
word->SetupFake(lstm_recognizer_->GetUnicharset());
./.libs/libtesseract.so: undefined reference to `SVSync::StartThread(void* (*)(void*), void*)'
Two different types of box file formats are mentioned in Training Tesseract 4.0 wiki.
WordStr 895 2742 1528 2811 0 #Emilie, hans Kone.
WordStr 899 2618 1507 2691 0 #Birch, Cancelliraad.
WordStr 895 2377 1317 2447 0 #Fru Krogh.
.hxOIFoYXPH/frk/frk.xheights --script_dir=../langdata
frk.UnifrakturMaguntia.exp0.box /tmp/tmp.wyo1280N2G/frk/frk.Walbaum-Fraktur.exp0.box
Extracting unicharset from /tmp/tmp.wyo1280N2G/frk/frk.embedsiver.exp0.box
Extracting unicharset from /tmp/tmp.wyo1280N2G/frk/frk.UnifrakturMaguntia.exp0.box
Wrote unicharset file /tmp/tmp.wyo1280N2G/frk//unicharset.
.wyo1280N2G/frk/frk.xheights --script_dir=../langdata
Loaded unicharset of **size 143** from file /tmp/tmp.wyo1280N2G/frk/frk.unicharset
- image being OCRed,
- OCRed text
![arabic-deva1](https://cloud.githubusercontent.com/assets/5095331/22055988/c65e0f96-dd83-11e6-9f06-bea70dd85be6.png)
[arabic-deva1.txt](https://github.com/tesseract-ocr/tesseract/files/713299/arabic-deva1.txt)
[arabic-deva1-san.txt](https://github.com/tesseract-ocr/tesseract/files/713300/arabic-deva1-san.txt)
[arabic-deva1-san_report.html.txt](https://github.com/tesseract-ocr/tesseract/files/713306/arabic-deva1-san_report.html.txt)
[forbes1849devscript-tif1-hin.txt](https://github.com/tesseract-ocr/tesseract/files/715823/forbes1849devscript-tif1-hin.txt)
- OCRed text with -l hin
Processing word with lang hin at:Bounding box=(236,2830)->(1276,2924)
Trying word using lang hin, oem 1
Processing word with lang hin at:Bounding box=(234,2248)->(1969,2326)
Trying word using lang hin, oem 1
> +# if defined(__GNUC__) || defined(__MINGW32__)
> +# if defined(__GNUC__) || defined(__MINGW32__)
> <https://github.com/notifications/unsubscribe-auth/ABvcM6qnB-Jkgoh25PwsvTfrWJMBWYnmks5rUfD9gaJpZM4Lje3X>
![20170113-10 09 17_auswahl](https://cloud.githubusercontent.com/assets/1151915/21924224/72ad2b02-d978-11e6-8b44-12c03da58aa2.png)
![20170113-10 12 22_auswahl](https://cloud.githubusercontent.com/assets/1151915/21924289/db580474-d978-11e6-8fd6-05670345ff34.png)
This is a complicated way of asking for an option to send one image through OCR and insert a different image in the output PDF.
but unfortunately this does not work with tesseract 4, at the present.
I usually use ghostscript for the purpose e.g.
gs -dNOPAUSE -dBATCH  -r300x300 -sDEVICE=tiffg4  -dFirstPage=168  -dLastPage=174 -sOutputFile=sample%03d.tif ./sample.pdf
Let's go back to the roots:
* image.ocr.pdf (mixed-mode pdf with the original image.png and image.txt)
Tested. With effa574, `tesseract -c textonly_pdf=1` works correctly and `tesseract -c textonly_pdf=0` produces an invalid PDF.
* gif (not really needed)
- orthographic syllables
> <https://github.com/notifications/unsubscribe-auth/AE2_o7lvUh_kbAfVygdwAU1ZBpPaiXCaks5rRzlqgaJpZM4LigRu>
For add a layer, a unicharset if required eg. `lstmtraining -U ~/tesstutorial/bih/bih.unicharset`
@theraysmith
https://groups.google.com/forum/#!topic/tesseract-ocr/-N5uPdSvJGA
`--eval_listfile ~/tesstutorial/saneval/san.training_files.txt`
Thanks. @amitdo Question to you, let me explain as briefly as I can:
* "Citroén" instead of the original word "Citroën"
* "fiir" instead of "für"
Hi @Wikinaut!
Both 'für' and 'fiir' are in the wordlist.
René für
André
0    Original Tesseract only.
2    Tesseract + LSTM.
Did you try `--oem 1`? @amitdo my original text uses a very "bad" font, where the characters overlap very often, and the characters often look, but are not, "ligatures". This explains the "fiir" in many cases (in my case).
I also tried `--oem 1`. but found, that `--oem 2` gave the best results. However, I did not find an explanation, what this "mixed operation modes" are really doing, pls. can we add a short text to `"2 Tesseract + LSTM", I can supply a PR, but do not know what a correct and short description is.
@amitdo and regarding my question above, can I "quickly" retrain my "deu" training data (or a copy of it) with a corrected text, this would be really great?
@amitdo yes, but what if one selects `--oem 2` ? Are then the results of both engines being compared or otherwise evaluated together ? The two engines runs and the results are combined in some way. :+1:  As said, I have zero experience training the LSTM engine.
![20170116-07 50 12_auswahl](https://cloud.githubusercontent.com/assets/1151915/21973387/90011a70-dbc0-11e6-9889-d104dad6822a.png)
![20170116-07 52 18_auswahl](https://cloud.githubusercontent.com/assets/1151915/21973407/beb10966-dbc0-11e6-8b86-f89117a7918c.png)
![20170116-07 53 20_auswahl](https://cloud.githubusercontent.com/assets/1151915/21973428/e1ec5bba-dbc0-11e6-9e9a-8e65f50a9d60.png)
#### "Citroën" vs. Tesseract: "Citroén"
![20170116-07 54 14_auswahl](https://cloud.githubusercontent.com/assets/1151915/21973442/00e6562e-dbc1-11e6-9176-3394c7078f86.png)
![20170116-07 55 12_auswahl](https://cloud.githubusercontent.com/assets/1151915/21973462/225f7678-dbc1-11e6-9e53-0b487fb272a4.png)
though ö was not recognized in one image.
It's not in the a German alphabet. it's from French. Still, maybe it should be included with the deu traineddata. It does looks like 'ii' (two 'i's), doesn't it?
@amitdo regarding "ii": In my text, tesseract correctly ocr-ed "ii" in the words "Gummiisolation", and "Daiichi" (a name). @theraysmith You appear to be the expert for answering my question, if such a procedure for re-training (tesseract + LSTM) is easily possible, or not:
Can I "quickly" retrain my "deu" (or "deu+eng") training data (or a copy of it) with a corrected text ?
In my case, many "für" were detected as "fiir", when or when not using `unpaper` (I cannot remember, because I tried many different runs).
load_freq_dawg       T
For Devanagari samples see https://github.com/tesseract-ocr/langdata/issues/40
Improve with respect to what?   What is in leptonica?  What is in tesseract?
arab_lines.c
https://github.com/DanBloomberg/leptonica/blob/master/prog/arabic_lines.c
https://github.com/DanBloomberg/leptonica/blob/master/prog/livre_pageseg.c
FYI,  I am not a C programmer. I am interested in good open source OCR for Indian languages and am trying out/testing tesseract for that. I am looking for improvement in tesseract in correctly identifying the textlines for complex scripts such as devanagari etc so as to get a more accurate OCR at the end. I also tested recently for Arabic text with diacritics.
A search yesterday led to your presentation on the net. Since tesseract uses leptonica already, I thought that you might be able to suggest better ways of textline finding in tesseract, specially for Arabic Diacritics, Devanagari script etc. (I have edited the earlier post with links to some sample files).
I tried arabic_lines with both arabic diacritics and devanagari sample and it is marking the texlines well. Results attached.
![result-arabic-diacritics](https://cloud.githubusercontent.com/assets/5095331/22008592/a8101138-dca2-11e6-8d85-a0cbcc078304.png)
![textlines-arabic-diacritics](https://cloud.githubusercontent.com/assets/5095331/22008594/a8129854-dca2-11e6-848e-4378a24beb26.png)
For reference, these are the two input images used with arabic_lines.
![arabic0](https://cloud.githubusercontent.com/assets/5095331/22050368/4f644e82-dd60-11e6-9d37-5cb1b2696392.png)
![arabic-deva1](https://cloud.githubusercontent.com/assets/5095331/22050369/4f6ac992-dd60-11e6-8160-57b84a1bd464.png)
some experimenting.
> supposed to be different colors?
> > I tried arabic_lines with both arabic diacritics and devanagari sample
> > [image: result-arabic-diacritics]
> > [image: textlines-arabic-diacritics]
> > [image: textlines-deva]
> pm4Ju1d_k_lks5rTE-BgaJpZM4LiGKh>
I've finished experimenting and will push some modified code to leptonica
prog/arabic_lines.
>> supposed to be different colors?
>> > I tried arabic_lines with both arabic diacritics and devanagari sample
>> > [image: result-arabic-diacritics]
>> > [image: result-deva]
>> > [image: textlines-arabic-diacritics]
>> > [image: textlines-deva]
>> AL056Up0oVZPWQ2YcPpA-pm4Ju1d_k_lks5rTE-BgaJpZM4LiGKh>
@theraysmith
In Arabic there are to kinds of diacritics
Anyone can help?  In order to minimize the RTL/LTR effect, I created a training text file with arabic language text, one word per line. However the image generated by text2image has some pages with RTL text and some with LTR text i.e. aligned with right margin and left margin.
Devanagari script has a large set of ligature forms forms for consonant conjuncts. These are combinations of Consonant + Viraama + Consonant (CVC) or CVCVC or even rarer CVCVCVC.
http://www.sanskritweb.net/itrans/ortho2003.pdf
http://tdil-dc.in/tdildcMain/articles/82170Devanagari%20Script%20Behaviour%20for%20Hindi%20%20ver%201.4.10.pdf Font Comparison Samples
* http://sanskritlibrary.org/Sanskrit/pub/chars.pdf
Some more questions
Are the desired_characters and forbidden_characters used in the process of
How many text lines are you using for training of Devanagari, e.g.
> *unicodes* for Indic languages. This reduces the size of the output
> unicodes currently only allows a maximum of 9 unicodes per
I have added links for resources for bih and snd in the langdata repo just now. Please see
* https://github.com/tesseract-ocr/langdata/issues/39 (Bihari)
* https://github.com/tesseract-ocr/langdata/issues/42 (Sindhi in Arabic script)
@theraysmith
I tried creating training data for khmer and was able to create box/tiff pairs with khmer text. It is possible that the fonts directory you used did not have khmer fonts or for some reason 'latin' fonts were used instead of khmer fonts. I will post the files separately under an issue in langdata.
--text ./langdata/ara/ara.training_text \
--outputbase ./langdata/ara/ara \
"DejaVu Sans" \
"DejaVu Sans Bold" \
"DejaVu Sans Mono" \
"DejaVu Sans Mono Bold" \
"FreeMono" \
"FreeMono Bold" \
Ray: Regarding Myanamar, please see discussion on https://github.com/tesseract-ocr/langdata/issues/13
http://crubadan.org/languages/my lists three primary sources for Myanmar/Burmese. One is the myanmar wikipedia, the other two are:
http://www.unicode.org/udhr/d/udhr_mya.html
http://www.jw.org/mya/
https://github.com/kanaung/wordlists
> https://github.com/kanyawtech/myanmar-karen-word-lists/blob/master/burmese-word-list.txt?raw=true
> https://en.wiktionary.org/wiki/Appendix:Burmese_basic_vocabulary
You may also find the charts at http://www.virtualvinodh.com/wp/character-matrix/ useful for a comparison of various Indic scripts. please see rows for Burmese for Mynamar. Hey Ray,
@theraysmith or @zdenop, please close this issue.
Iteration 5010: ALIGNED TRUTH : द्ध्वा ल्गु ज्<Undecodable><Undecodable><Undecodable> द्द स्तू स्त्रे द्यो शाः स्वे न्ह
Iteration 5034: ALIGNED TRUTH : खं चः द्धो ङ्गा भौ न्यं न्यु ज्<Undecodable><Undecodable> त्कृ वां निः
Iteration 5068: ALIGNED TRUTH : व्यः श्मि क्ष्ण खाः टी णिं त्सै न्तां ल्म ष्<Undecodable><Undecodable><Undecodable>
द्ध्वा ल्गु ज्ञां द्द स्तू स्त्रे द्यो शाः स्वे न्ह नुः
Specifically the syllables giving error in this sample are `ज्ञां` `ज्ञे `ष्टिं`.
| Syllable | Devanagari characters | Unicode code points |
ज्ञां 1 3,76,61,242,294,446,0,0,294,446 Devanagari 27 0 27 ज्ञां	# ज्ञां [91c 94d 91e 93e 902 ]x
ज्ञे 1 3,76,61,255,251,423,0,0,251,423 Devanagari 27 0 27 ज्ञे	# ज्ञे [91c 94d 91e 947 ]x
ष्टिं 1 3,76,61,253,238,384,0,0,238,384 Devanagari 52 0 52 ष्टिं	# ष्टिं [937 94d 91f 93f 902 ]x
Iteration 18247: ALIGNED TRUTH : مْهُعَبِاصَأَ نَولُعيَ<Undecodable><Undecodable> قٌربَوَ دٌعْرَوَ تٌامَلُظُ
```  @theraysmith @amitdo @Shreeshrii
( Have a look at the **wrong and disorder Tesseract 4.0x Arabic box file** )
[ara.Traditional_Arabic.exp0.zip](https://github.com/tesseract-ocr/tesseract/files/697557/ara.Traditional_Arabic.exp0.zip)
Thus a problem arises caused by the **box file disorder** since the boxes are **mistakenly** set to be in LTR ( Left to Right ) for Arabic which is wrong, causing jumps from ( the end of the first line) to ( the end of the last letter of the line after it).
![box disorder](https://cloud.githubusercontent.com/assets/16248376/21826462/9df37064-d798-11e6-8987-f51195ab66e0.jpg)
> i was merging the letter extender with the Arabic letter into one single box, and putting that Arabic letters as the character of the box, basically, i was trying to train the engine to recognize that Arabic letter in it's multiple positions, as you know the Arabic letters have multiple forms based which is based on it's position in the word ( beginning, middle, ending, isolated )
@theraysmith
Arabic Diacritics are included in the Arabic.unicharset.
@bmwmy had offered to provide additional training text with diacritics - see https://github.com/tesseract-ocr/tesseract/issues/552#issuecomment-269961851
#Diacritics
are reversed order (RTL issue)
comparison between noisy text example which was used in training and good one:
@christophered  ara.Traditional_Arabic.exp0.zip was good input image file
So, I am trying the training again with only one font, Traditional Arabic font at 32 point, as suggested by @bmwmy.
>>Iteration 1702: ALIGNED TRUTH : انَدبْعَ ىلَعَ انَلْنَ امَّمِ بٍيْرَ يفِ مْتُنْكُ نْإِوَ نَومُلَعْتَ مْتُنْأوَ ادًادَنْأ هِللِ اولُعَجْتَ الَفَ مْكُل
are reversed order (RTL issue)
@theraysmith
As a minimum it should equal to ptsize. For Arabic, you can try to increase it (20-50 percent bigger than ptsize)  IMO, 32 ptsize is too big. Try 14/16. Arabic also has presentation forms i.e. spacing forms of Arabic diacritics, and contextual letter forms.
http://www.alanwood.net/unicode/arabic_presentation_forms_a.html
http://www.alanwood.net/unicode/arabic_presentation_forms_b.html
https://github.com/w3c/alreq/wiki/Should-I-use-the-Arabic-Presentation-Forms-provided-in-Unicode%3F
> As a minimum it should equal to ptsize. For Arabic, you can try to increase it (20-50 percent bigger than ptsize)
[Arabic sample variation.zip](https://github.com/tesseract-ocr/tesseract/files/736942/Arabic.sample.variation.zip)
The Arabic diacritics are **often** but not always used in the Arabic text, sometimes in all the text, and sometimes at one letter in each word, but believe me the diacritics are frequently used.
Have a look at [The Quran](http://quran.ksu.edu.sa/tafseer/tafheem/sura1-aya1.html#tafheem)
@Shreeshrii your sample of box/tif that you provided had an some errors that I've notice:
1) The U+640 (tatweel) issue
example: بِسمِ
wrong: ب ـِ س ـِ م
correct: ب س م   only 3 letters بسم
U+640 (tatweel) is a special case, people dont usually use it while writing text, so dont use it, or merge the boxes and remove it.
wrong: بـ ـسـ ـم
correct: بسم
>    The U+640 (tatweel) issue
>    example: بِسمِ
>    wrong: ب ـِ س ـِ م
>    correct: ب س م only 3 letters بسم
>    U+640 (tatweel) in the .box file , ever.
>    U+640 (tatweel) is a special case, people dont usually use it while
>    wrong: بـ ـسـ ـم
>    correct: بسم
Arabic sample variation.zip
Shree, you are a magician!
Here are some libraries that implement the Unicode Bidi algorithm.
https://github.com/behdad/pybyedie
Written in: Python
https://github.com/servo/unicode-bidi
Written in: Rust
https://github.com/behdad/fribidi
https://github.com/MeirKriheli/python-bidi
Written in: Python
This feature that I'am suggesting will give the ability to provide Semi-Automatic transcription capabilities. Please help to add space after text in Punjabi(Panjabi or Gurmukhi) sentance.  @theraysmith the recognition rate of the Arabic model is impressive, you really made a big recognition leap from 3.x to 4, Have you managed to solve issue #758 relating to لا is wrongly flipped as ال
@Shreeshrii @amitdo @theraysmith
that predicts diacritics in non-diacritized texts for Arabic](http://www.aclweb.org/anthology/D15-1274), how is that possible?
Does that mean if I train an Arabic Model with text that have Arabic diacritic, then use this model to recognize an image with Arabic text that dont have diacritic, the ocr txt result will have diacritics?
is that true? @theraysmith have you solved the problem of لا ? it really effects the error rate
@theraysmith The main problem is caused by the reorder and normalize function in Tesseract.
Kraken have managed to fix many of the RTL langues bugs, along with using python-bidi, kraken reorder and normalize the writings, including alphabets and even diacritics.
Have a look at: http://kraken.re/ketos.html
https://github.com/mittagessen/kraken
Example, Arabic RTL:
Example, the word أنفسهم it can be converted to:
- مهسفنٔا
- مهسفنأ
Have a look at the NFD and NFC options
@theraysmith
I think the problem of لا happens because of this:
الا انفسهم
لا
م
م
م
> <https://github.com/notifications/unsubscribe-auth/AZFiAVnhv01Xw6nKogWP_uU8BAPGJYRzks5sQBengaJpZM4Lf-kT>
import glob
م       ه       س      ف     ن      ا      لا        ا
م       ه       س      ف     ن      ا      ل          ا       ا
ا        ا       ل       ا      ن       ف     س    ه         م
So, the problem happened. @theraysmith  that could be a solution ( well not sure ) https://en.wikipedia.org/wiki/Arabic_script_in_Unicode#Contextual_forms
What is the Arabic diacritics issue: it's when the ocr engine recognition rate is reduced when introducing a foreign element/mark to the text, in this case diacritics; meaning if the text has few diacritics can the ocr engine recognize the text and achieve decent rates?
- Note that you are fully correct in regards to `Tatweel`.
- Note that you are mostly correct in regards to the Arabic diacritical marks, they are mostly optional, but for some conditions are necessary, mostly the `Maddah` & the `Tanwin`.
Nevertheless, nowadays Arabic diacritics are moderately used.
**Results of my tests related to diacritics:**
- Training a model with Arabic text, without diacritics
Note that it cant recognize words without diacritics well.
- Training a model with Arabic text, with text containing a mixture of both: lines with few diacritics and lines without diacritics .
The diacritics issue with regards to the Arabic language  can be solved by creating a model with a combination/mixture of both: lines with & without diacritics.
Also include diacritized lines:
As for Hebrew @amitdo is conductor at https://github.com/tesseract-ocr/langdata/issues/82
Question
GDT: آمنا بالله إن شئتم الآخرة هم بمؤمنين يا أيها
NFD: اهئا اي نينمٔومب مه ةرخٓالا متٔيش نٕا هللاب انمٓا
NFC: اهيأ اي نينمؤمب مه ةرخآلا متئش نإ هللاب انمآ
https://en.wikipedia.org/wiki/Kashida
@amitdo No, No.......! That is very bad
It seems it uses NF**K**C. Hi @christophered, I don't think you understood my meaning.
> <https://github.com/notifications/unsubscribe-auth/AZFiAfGrAIkJiFceO2zo3iNI77Q7sz9Dks5sgiQGgaJpZM4Lf-kT>
==2035==    by 0x71921EF: pixUnsharpMaskingGray2D (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
The Tesseract function ComputeBlackWhite operates on that data with random results.
#include <leptonica/allheaders.h>
Valgrind reports the same problem as in Tesseract:
tesseract.
tesseract scr out
http://people.idsia.ch/~juergen/icdar2011a.pdf
There are two questions here:
1. Does @DanBloomberg want this code in Leptonica?
The code is here:
(2) Portability: We have enough trouble maintaining portability with just plain old ansi C over several OS platforms.  The operations here take it to another level: hardware.  What restrictions are there on the hardware for this code to be compiled properly?  Does it work seamlessly on all Intel processors?  What about AMD?  What about ioS and Android?
Rendered page 242 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Rendered page 244 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
Rendered page 243 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Rendered page 245 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
Rendered page 244 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Rendered page 246 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
Rendered page 245 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Rendered page 247 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
Rendered page 246 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Rendered page 248 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
Rendered page 247 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Rendered page 249 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
training/tesstrain.sh --fonts_dir /home/shree/.fonts --lang bih  --linedata_only \
--output_dir ~/tesstutorial/bihnew
Image file and OCRed text attached.
[24-fra.txt](https://github.com/tesseract-ocr/tesseract/files/680037/24-fra.txt)
by Sandro Mani:
ShreeDevi
Attaching another image and text with Hindi, Arabic and English as a sample
ShreeDevi
H ايگن ऐगुण aiguṇ [S. अव+गुण], s.m. Unskilfulness, stupidity, &c.=augun, q.v.
A ايل īyal, aiyal, uyyal, s.m. Stag; deer, hart; wild goat.
S ايلا एला elā, s.f. Cardamoms. (See ilāćī.)
H ايلام ईलाम īlām, s.m. Auction, public sale (=līlām, nīlām, q.q.v.).
P ايلچي elćī, s.m. Ambassador, envoy, delegate, agent:—elćī karnā, To discharge the functions of an ambassador or agent; to Ray,
However, problem with words being skipped during recognition remains. Here is some debug info regarding a missing Hindi word, it is being recognized but is getting discarded and is not output:
Processing word with lang fra at:Bounding box=(361,395)->(447,419)
Trying word using lang fra, oem 1
Trying word using lang hin, oem 1
Processing word with lang fra at:Bounding box=(557,393)->(748,413)
ShreeDevi
Not sure if you were joking here or were serious...
If by "this year" you meant '2016', then you were joking.
https://monoinfinito.wordpress.com/series/vectorization-in-gcc/
PS C:\Users\User\shree\jtess\tesseract-ocr> ./tesseract.exe -v
leptonica-1.74.1
penjp2 2.1.0
Found AVX
Wrote C:\Users\User\shree\jtess\samples\vie/vie.lstm
Lfys64:64, 20736
Loaded 188/188 pages (1-188) of document C:\Users\User\shree\jtess\samples\vie\vie.Arial.exp0.lstmf
This application has requested the Runtime to terminate it in an unusual way.
leptonica-1.74.1 (Feb 11 2017, 11:04:30) [MSC v.1900 DLL Release x86]
Found AVX
root@ellensong: tesseract chi.jpg chi -l chi_sim
Aborted (core dumped)
@EllenSong77, did you use the latest code? Are you running Ubuntu in a virtual machine (if yes: please provide more information on the kind of virtualisation)? @stweil I clone the code yesterday, and running Ubuntu in a physical machine. What other information could be more helpful that I should provide?  >I've never got this error when I set language param as chi_tra or eng.
Very strange! From where did you get  the chi_tra and eng traineddata?
Maybe I should what @Shreeshrii said too.
Do you mean I should export TESS_DATA=......../tesseract/tesseract-ocr.tessdata/best ?
https://launchpad.net/%7Ealex-p/+archive/ubuntu/tesseract-ocr
i am planing to engage in testing Tesseract 4.0 LSTM on the Arabic language, and wanting to post results in the future, i hope that there will be recognition improvement while testing.
More information about BLSTM and MDLSTM:
https://www.nist.gov/sites/default/files/documents/itl/iad/mig/OpenHaRT2013_WorkshopPres_A2IA.pdf
http://www.a2ialab.com/lib/exe/fetch.php?media=presentations:icdar2015_chinese_slides.pdf
BLSTM is implemented and used.
> Tesseract has official trained models for ~100 languages. ocropy has
The difference in accuracy between Latin script based langs and Arabic is due to
2. The 'complexity' of the script. Arabic is much more complex.   Also, the OCR stage is dependent on the layout analysis stage which is weaker for Arabic.  Shree, indic scripts are even more complex... @amitdo Thanks for clearing things up,  improved pre-processing may make 1D-LSTM outperform the more complex MDLSTM. You were right.
@Shreeshrii So Tesseract 4.x has the capability of producing more sophisticated and complex structures.
@roozgar i was looking for a method that gain +85% recognition rate for Arabic language.
@roozgar can you share your training process, the tif/box files and the traineddata.
[Wed Dec 28 10:57:18 DST 2016] /usr/local/bin/tesseract /tmp/tmp.auXd9ArSbG/bih/bih.Lohit_Devanagari.exp0.tif /tmp/tmp.auXd9ArSbG/bih/bih.Lohit_Devanagari.exp0 lstm.train ../langdata/bih/bih.config
Loaded 41/41 pages (1-41) of document /tmp/tmp.auXd9ArSbG/bih/bih.Lohit_Devanagari.exp0.lstmf
Loaded 82/82 pages (1-82) of document /tmp/tmp.auXd9ArSbG/bih/bih.Lohit_Devanagari.exp0.lstmf
>   --continue_from ~/tesstutorial/sanskrit2003_from_full/san.lstm \
>   --train_listfile ~/tesstutorial/santrain/san.training_files.txt \
Loaded 345/1760 pages (1415-1760) of document /home/shree/tesstutorial/santrain/san.Uttara.exp0.lstmf
Loaded 1814/1814 pages (0-1814) of document /home/shree/tesstutorial/santrain/san.Gargi.exp0.lstmf
Found AVX
I agree that the message is confusing.
Cloning into 'tesseract'...
$ cd tesseract/
Running aclocal
glibtoolize: copying file 'm4/ltsugar.m4'
glibtoolize: copying file 'm4/lt~obsolete.m4'
checking for g++... g++
Since this error is a bit cryptic, it might be nice to add a check to see if AX_CHECK_COMPILE_FLAG is defined is added, and perhaps print a message to give some guidance on how to get it (probably something in homebrew? upgrade autoconf maybe?).
checking for g++... g++
checking for mawk... mawk
洗
於
で お 洗 だ
つ 圖 月 庸 明
壽醒
秘 心
は :
し 無
ま 用
はははは
は は は は
(gdb) bt
tesseract -v
leptonica-1.74
Found AVX
khmer works with --oem 0.
[khm.Leelawadee_UI_Bold.exp0-0.txt](https://github.com/tesseract-ocr/tesseract/files/729037/khm.Leelawadee_UI_Bold.exp0-0.txt)
[khm.Leelawadee_UI_Bold.exp0-1.txt](https://github.com/tesseract-ocr/tesseract/files/729036/khm.Leelawadee_UI_Bold.exp0-1.txt)
macOS Sierra
this may help https://github.com/balabit/syslog-ng/issues/1249
How should Vs2015 solve this problem ?
Too many Error...
leptonica version : 1.74.0
#include <baseapi.h>
(maybe to `arch/simddetection.h`)  Hi there,
My text is only 22 words, Download the text:  [arabic1.txt](https://github.com/tesseract-ocr/tesseract/files/673277/arabic1.txt)
cd tesseract
cppan
cmake ..
text2image.obj : error LNK2019: unresolved external symbol "struct tesseract::ParamsVectors * __cdecl GlobalParams(void)" (?GlobalParams@@YAPAUParamsVectors@tesseract@@XZ) referenced in function "void __cdecl `dynamic initializer for 'FLAGS_bidirectional_rotation''(void)" (??__EFLAGS_bidirectional_rotation@@YAXXZ)
pango_font_info.obj : error LNK2001: unresolved external symbol "struct tesseract::ParamsVectors * __cdecl GlobalParams(void)" (?GlobalParams@@YAPAUParamsVectors@tesseract@@XZ)
tlog.obj : error LNK2001: unresolved external symbol "struct tesseract::ParamsVectors * __cdecl GlobalParams(void)" (?GlobalParams@@YAPAUParamsVectors@tesseract@@XZ)
ambiguous_words.obj : error LNK2019: unresolved external symbol "public: __thiscall WERD_CHOICE::WERD_CHOICE(char const *,class UNICHARSET const &)" (??0WERD_CHOICE@@QAE@PBDABVUNICHARSET@@@Z) referenced in function _main
ambiguous_words.obj : error LNK2019: unresolved external symbol "public: __thiscall WERD_CHOICE::~WERD_CHOICE(void)" (??1WERD_CHOICE@@QAE@XZ) referenced in function _main
Found AVX
Program received signal SIGABRT, Aborted.
AM_CONDITIONAL([SSE41_OPT], false)
Found AVX
tesseract -v
leptonica-1.74
AM_CONDITIONAL([SSE41_OPT], true)
#fi
#if test x$sse41 = x1; then
#fi
Vidushi Gupta
Vidushi
tesseract -v
sudo apt-get install tesseract-ocr-hin   -y
ShreeDevi
> Vidushi Gupta
> experimental
> auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> Vidushi
> +archive/ubuntu/tesseract-ocr
> tesseract -v
> sudo apt-get install tesseract-ocr-hin -y
> ShreeDevi
> > Vidushi Gupta
> > experimental
> > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > Vidushi
> <https://github.com/notifications/unsubscribe-auth/AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
Vidushi
> ShreeDevi
> > tesseract-ocr
> > tesseract -v
> > sudo apt-get install tesseract-ocr-hin -y
> > ShreeDevi
> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> >> Vidushi Gupta
> >> experimental
> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> >> Vidushi
> <https://github.com/notifications/unsubscribe-auth/AOjjm3ECVBAY1kTVCX5pcrNj2WLlWwq9ks5rfvHagaJpZM4LVjQA>
tesseract img.PNG out
Aborted (core dumped)
>> ShreeDevi
>> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>> > tesseract-ocr
>> > tesseract -v
>> > sudo apt-get install tesseract-ocr-hin -y
>> > ShreeDevi
>> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>> >> Vidushi Gupta
>> >> experimental
>> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
>> >> Vidushi
Vidushi
oks.
Vidushi
> vidushigupta2004@gmail.com
> > tess4eval_marathi
> > >> ShreeDevi
> > >> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> shreeshrii@gmail.com>
> > >> > tesseract-ocr
> > >> > sudo apt-get install tesseract-ocr-hin -y
> > >> > ShreeDevi
> > >> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > >> >> experimental
> > >> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > >> >> Vidushi
> > AOjjm3ECVBAY1kTVCX5pcrNj2WLlWwq9ks5rfvHagaJpZM4LVjQA>
> > Vidushi
Vidushi
Vidushi Gupta
Vidushi
3.05 should work with leptonica 1.74.
tesseract -v
> Vidushi Gupta
> AOjjm5xy0MycRfFhg9piC99w7mVXQ_LTks5rfxTBgaJpZM4LVjQA>
> Vidushi
> Vidushi Gupta
> AOjjm5xy0MycRfFhg9piC99w7mVXQ_LTks5rfxTBgaJpZM4LVjQA>
> Vidushi
> tesseract-ocr tesseract-ocr-eng (add more languages as needed) as root
tesseract-ocr tesseract-ocr-eng .
Vidushi
> <https://github.com/notifications/unsubscribe-auth/AOjjm_fTM8I4UGbrm2Og8AKefKgUwQhoks5rf_8QgaJpZM4LVjQA>
-ltesseract
Vidushi
> +archive/ubuntu/tesseract-ocr
> tesseract -v
> sudo apt-get install tesseract-ocr-hin -y
> ShreeDevi
> > Vidushi Gupta
> > experimental
> > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > Vidushi
> <https://github.com/notifications/unsubscribe-auth/AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
Vidushi
>> <https://github.com/notifications/unsubscribe-auth/AOjjm_fTM8I4UGbrm2Og8AKefKgUwQhoks5rf_8QgaJpZM4LVjQA>
Vidushi
which tesseract
tesseract -v
tesseract --help
ShreeDevi
> -ltesseract
> Vidushi
> > +archive/ubuntu/tesseract-ocr
> > tesseract -v
> > sudo apt-get install tesseract-ocr-hin -y
> > ShreeDevi
> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > > Vidushi Gupta
> > > experimental
> > > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > Vidushi
> AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> Vidushi
> which tesseract
> tesseract -v
> ShreeDevi
> > -ltesseract
> > Vidushi
> > > +archive/ubuntu/tesseract-ocr
> > > tesseract -v
> > > sudo apt-get install tesseract-ocr-hin -y
> > > ShreeDevi
> > > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > > > experimental
> > > > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > > Vidushi
> > AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> > Vidushi
> Q81fTzwHqZPg8gEZHrUzA9hVoks5rgpzJgaJpZM4LVjQA>
Vidushi
ShreeDevi
> > which tesseract
> > tesseract -v
> > ShreeDevi
> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > > -ltesseract
> > > Vidushi
> > > > +archive/ubuntu/tesseract-ocr
> > > > tesseract -v
> > > > sudo apt-get install tesseract-ocr-hin -y
> > > > ShreeDevi
> > > > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > > > > experimental
> > > > > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > > > Vidushi
> > > AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> > > Vidushi
> > Q81fTzwHqZPg8gEZHrUzA9hVoks5rgpzJgaJpZM4LVjQA>
> Vidushi
Vidushi
Sorry for disturbing again.Yesterday i was trying on my friend's system.It
Aborted (core dumped)
www.avast.com
> +archive/ubuntu/tesseract-ocr
> tesseract -v
> sudo apt-get install tesseract-ocr-hin -y
> ShreeDevi
> > Vidushi Gupta
> > experimental
> > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > Vidushi
> <https://github.com/notifications/unsubscribe-auth/AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
Vidushi
tesseract completely from ubuntu
> ShreeDevi
> > tesseract-ocr
> > tesseract -v
> > sudo apt-get install tesseract-ocr-hin -y
> > ShreeDevi
> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> >> Vidushi Gupta
> >> experimental
> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> >> Vidushi
> <https://github.com/notifications/unsubscribe-auth/AOjjm3ECVBAY1kTVCX5pcrNj2WLlWwq9ks5rfvHagaJpZM4LVjQA>
Vidushi
Aborted (core dumped)
Vidushi
Vidushi
> tesseract completely from ubuntu
>> ShreeDevi
>> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>> > tesseract-ocr
>> > tesseract -v
>> > sudo apt-get install tesseract-ocr-hin -y
>> > ShreeDevi
>> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>> >> Vidushi Gupta
>> >> experimental
>> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
>> >> Vidushi
> Vidushi
Vidushi
>> tesseract completely from ubuntu
>>> ShreeDevi
>>> > tesseract-ocr
>>> > tesseract -v
>>> > sudo apt-get install tesseract-ocr-hin -y
>>> > ShreeDevi
>>> >> Vidushi Gupta
>>> >> experimental
>>> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
>>> >> Vidushi
>> Vidushi
> Vidushi
Vidushi
> ShreeDevi
> > > which tesseract
> > > tesseract -v
> > > ShreeDevi
> > > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > > > -ltesseract
> > > > Vidushi
> > > > > +archive/ubuntu/tesseract-ocr
> > > > > tesseract -v
> > > > > sudo apt-get install tesseract-ocr-hin -y
> > > > > ShreeDevi
> > > > > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > > > > > experimental
> > > > > > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > > > > Vidushi
> > > > AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> > > > Vidushi
> > > Q81fTzwHqZPg8gEZHrUzA9hVoks5rgpzJgaJpZM4LVjQA>
> auth/AOjjm7TEDa6-rWyrqgSt-
> > Vidushi
> Ky2N5toipjWMBnddaBS9UHpyks5rgryNgaJpZM4LVjQA>
Vidushi
ShreeDevi
> > ShreeDevi
> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > > > which tesseract
> > > > tesseract -v
> > > > ShreeDevi
> > > > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > > > > -ltesseract
> > > > > Vidushi
> > > > > > +archive/ubuntu/tesseract-ocr
> > > > > > tesseract -v
> > > > > > sudo apt-get install tesseract-ocr-hin -y
> > > > > > ShreeDevi
> > > > > > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > > > > > > experimental
> > > > > > > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > > > > > Vidushi
> > > > > AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> > > > > Vidushi
> > > > Q81fTzwHqZPg8gEZHrUzA9hVoks5rgpzJgaJpZM4LVjQA>
> > auth/AOjjm7TEDa6-rWyrqgSt-
> > > Vidushi
> > Ky2N5toipjWMBnddaBS9UHpyks5rgryNgaJpZM4LVjQA>
> WaR6aQmzmAKjuPPsv-6G1eAks5rgr5RgaJpZM4LVjQA>
> Vidushi
In `configure.ac,` should we change
I've put up on github the leptonica 1.74.1 release.
This code:
What might be causing this?
leptonica-1.73
Installed Vietnamese language during setup wizard  Hey,
Trying to install openalpr, which requires tesseract as a dependency.
Everything goes fine until I try to 'make' tesseract
The first error is:
`pi@raspberrypi:~/openalpr/libraries/tesseract $ make -j4
Makefile:537: recipe for target 'libtesseract_avx_la-dotproductavx.lo' failed
make[3]: *** [libtesseract_avx_la-dotproductavx.lo] Error 1
Makefile:544: recipe for target 'libtesseract_sse_la-dotproductsse.lo' failed
make[3]: *** [libtesseract_sse_la-dotproductsse.lo] Error 1
>libtesseract_avx_la_CXXFLAGS = -mavx
libtesseract_sse_la_CXXFLAGS = -msse4.1
checking for g++... g++
./configure: line 4229: syntax error near unexpected token `-msse4.1,'
AM_CONDITIONAL([SSE41_OPT], false)
cppan
cd tesserac
cppan --self-upgrade
cppan
Can you give me all these dependency files? I can add them to any project for using leptonica and tesseract and compile , including current tesseract master (although I was able to magically compile it with **9** downloaded dependencies - excluding gif, webp and almost all unicode libs). Thanks for the support!  Loaded 4128/4128 pages (0-4128) of document /home/shree/tesstutorial/sanskrittrain/san.Yatra_One.exp0.lstmf
$ lstmtraining -U ~/tesstutorial/aratest/ara.unicharset \
>   --continue_from ~/tesstutorial/aralayer_from_aratest/ara.lstm \
>   --train_listfile ~/tesstutorial/aratest/ara.training_files.txt \
Loaded 135/135 pages (1-135) of document /home/shree/tesstutorial/aratest/ara.Traditional_Arabic.exp0.lstmf
and training doesnt converge, i have a error rate of 70% right now @ferjad
ShreeDevi
> <https://github.com/notifications/unsubscribe-auth/AE2_o6xMIbL4uGUBw1AD2zLY-DdnNigjks5riEHxgaJpZM4LQswx>
@Shreeshrii hey any update on ability to train with WordStr format? I tried this again and still got Compute CTC Failed @theraysmith has not updated the programs for handling this yet. Hopefully it will be in next update. @Shreeshrii It would be ideal to update the training wiki to reflect this, thanks for the update  Added a note in training wiki to reflect that WordStr option is not implemented.
Also added as a separate issue. @Shreeshrii hey any update on this? the wiki still says the same  @ferjad, the 'WordStr' format is still not supported. It's unknown when it will be supported.  mkdir -p ~/tesstutorial/sanvedic
lstmtraining -U ~/tesstutorial/vedic/san.unicharset \
--model_output ~/tesstutorial/sanvedic/base \
--train_listfile ~/tesstutorial/vedic/san.training_files.txt \
--eval_listfile ~/tesstutorial/vedic/san.training_files.txt \
Setting properties for script Devanagari
Unichar 2306=र्त्स्न्ये->र्त्स्न्ये is too long to encode!!
Lfys64:64, 20736
Loaded 828/828 pages (0-828) of document /home/shree/tesstutorial/vedic/san.AA_NAGARI_SHREE_L1.exp0.lstmf
Loaded 957/957 pages (0-957) of document /home/shree/tesstutorial/vedic/san.e-Nagari_OT.exp0.lstmf
Loaded 691/691 pages (0-691) of document /home/shree/tesstutorial/saneval/san.Amiko.exp0.lstmf
Loaded 1210/1210 pages (0-1210) of document /home/shree/tesstutorial/vedic/san.Nakula.exp0.lstmf
Found AVX
Loaded 151/151 pages (1-151) of document /home/shree/tesstutorial/trado/ara.Traditional_Arabic.exp0.lstmf
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
ShreeDevi
``` @theraysmith
۵۴ ۷۲۸ ب ۱۴
each line includes one of these patterns.
enough? (this is a different project and not related to the licence plate)
> KA44mvwgN2Mx2ks5sWUNhgaJpZM4LQsPF>
@hanikh
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
Line cannot be recognized!!
fonts and they are so common.
> using tesstrain.sh - it is usually related to 'nnn diacritics found' - so
> it may be related to accents being treated as a separate line.
> Regarding finetuning, I have experimented a lot with Devanagari - with
> ShreeDevi
> > wrong somewhere with the images.
> > aC1mUg2gH34puAGpWdOOks5sXZhHgaJpZM4LQsPF>
>> using tesstrain.sh - it is usually related to 'nnn diacritics found' - so
>> it may be related to accents being treated as a separate line.
>> Regarding finetuning, I have experimented a lot with Devanagari - with
>> ShreeDevi
>> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>> > wrong somewhere with the images.
>> > aC1mUg2gH34puAGpWdOOks5sXZhHgaJpZM4LQsPF>
@Shreeshrii I want to train 40 fonts for Arabic and Farsi languages. I have tried to finetune the trained model, but I did not get a good result. I think that happened because the trained fonts were so different from mine. So now I am going to replace a layer. I want to replace just the last layer and I do not want to change the unicharset. So, can I use Arabic.traineddata as the traineddata file needed for training? these are the commands I am using:
mkdir -p ~/tesstutorial/newara_from_ara
training/combine_tessdata -e tessdata/best/Arabic.traineddata \
~/tesstutorial/newara_from_ara/ara.lstm
--continue_from ~/tesstutorial/newara_from_ara/ara.lstm \
--traineddata ~/tesstutorial/aratrain/ara/Arabic.traineddata \
--model_output ~/tesstutorial/newara_from_ara/base \
--train_listfile ~/tesstutorial/aratrain/ara.training_files.txt \
--max_iterations 3000 &>~/tesstutorial/newara_from_ara/basetrain.log @theraysmith
i can provide a large amount of font and word list of persian and arabic language for the train material @Shreeshrii  would you please help me with using "replacing layers" as I asked before?
@roozgar have you tested the new traineddata for arabic? have you tried to train it?   I followed the [steps](https://github.com/tesseract-ocr/tesseract/wiki/Compiling#windows) required to get to .sln file for Visual Studio but I get a bunch of errors.
It is the latest version of cppan.
`cppan --clean-packages .*jpeg.*`
`cppan --self-upgrade`
@egorpugin Please see https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-dev/Vx3Z-MReD3c/BMRy_IkSCAAJ
I need to learn this now... (I am just trying something from https://www.startpage.com/do/search?q=github+how+can+I+cherry-pick+a+pull+request ) (I just wanted to confirm, that it solves the problem! ty all)  In leptonica:
- 95% of these are because I use floats, and floating point numbers (like 1.0) are assumed to be doubles.
./.libs/libtesseract.so: undefined reference to `boxaCreate'
./.libs/libtesseract.so: undefined reference to `boxaGetBox'
make[2]: *** [tesseract] Error 1
So am I wrong or it is a bug?
#Problematic frame:
leptonica-1.73
I use Tesseract on iPhone and iPad.
Thank you for this awesome ocr library. Hi Simon,
It seems the lib is named differently.
where can i see the version of mingw-w64?
Ouput from mingw64 console:
$ pacman -Qs icu
local/mingw-w64-x86_64-icu 57.1-1
International Components for Unicode library (mingw-w64)
Even with the PKGBUILD from Tesseract Wiki:
$ lstmtraining -U ~/tesstutorial/sanlayer/san.unicharset   --script_dir ../langdata  --debug_interval
--train_listfile ~/tesstutorial/sanlayer/san.training_files.txt   --eval_listfi
le ~/tesstutorial/saneval/san.training_files.txt   --max_iterations 5000
Loaded 691/691 pages (0-691) of document /home/shree/tesstutorial/saneval/san.Amiko.exp0.lstmf
Loaded 2101/2101 pages (0-2101) of document /home/shree/tesstutorial/sanlayer/san.Nakula.exp0.lstmf
Loaded 2103/2103 pages (0-2103) of document /home/shree/tesstutorial/sanlayer/san.Lohit_Devanagari.exp0.lstmf
Loaded 2102/2102 pages (0-2102) of document /home/shree/tesstutorial/sanlayer/san.Samanata.exp0.lstmf
Loaded 2102/2102 pages (0-2102) of document /home/shree/tesstutorial/sanlayer/san.Kalimati.exp0.lstmf
Found AVX
Aborted (core dumped)
lstmtraining -U ~/tesstutorial/vedic/san.unicharset \
--continue_from ~/tesstutorial/san_vedic/san.lstm \
--append_index 5 --net_spec '[Lfx384 O1c6000]' \
--model_output ~/tesstutorial/san_vedic/base \
--train_listfile ~/tesstutorial/nonvedic/san.training_files.txt \
--eval_listfile ~/tesstutorial/nonvedic/san.training_files.txt \
Program received signal SIGABRT, Aborted.
$ combine_tessdata -e tessdata/san.traineddata \
$ lstmtraining -U ~/tesstutorial/santrain/san.unicharset \
>   --train_listfile ~/tesstutorial/santrain/san.training_files.txt \
>   --eval_listfile ~/tesstutorial/san_layer/san.training_files.txt \
Unichar 1481=र्ब्रह्मघा->र्ब्रह्मघा is too long to encode!!
Loaded 1837/1837 pages (0-1837) of document /home/shree/tesstutorial/santrain/san.Aksharyogini2.exp0.lstmf
Loaded 1741/1741 pages (0-1741) of document /home/shree/tesstutorial/santrain/san.Amiko.exp0.lstmf
Loaded 1763/1763 pages (0-1763) of document /home/shree/tesstutorial/santrain/san.Baloo.exp0.lstmf
Loaded 1820/1820 pages (0-1820) of document /home/shree/tesstutorial/santrain/san.Aparajita.exp0.lstmf
Loaded 1820/1820 pages (0-1820) of document /home/shree/tesstutorial/santrain/san.Biryani.exp0.lstmf
Loaded 1822/1822 pages (0-1822) of document /home/shree/tesstutorial/santrain/san.Arya.exp0.lstmf
Loaded 1824/1824 pages (0-1824) of document /home/shree/tesstutorial/santrain/san.Asar.exp0.lstmf
Loaded 1837/1837 pages (0-1837) of document /home/shree/tesstutorial/santrain/san.Amita.exp0.lstmf
Here is the info re lstmf files in /home/shree/tesstutorial/santrain/
-rw-rw-rw- 1 shree shree 3601682 Dec  9 21:16 /home/shree/tesstutorial/santrain/san.Aksharyogini2.exp0.lstmf
-rw-rw-rw- 1 shree shree 3834940 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Amiko.exp0.lstmf
-rw-rw-rw- 1 shree shree 5002657 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Amita.exp0.lstmf
-rw-rw-rw- 1 shree shree 3971772 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Annapurna_SIL.exp0.lstmf
-rw-rw-rw- 1 shree shree 3613720 Dec  9 21:16 /home/shree/tesstutorial/santrain/san.Aparajita.exp0.lstmf
-rw-rw-rw- 1 shree shree 4275301 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Arya.exp0.lstmf
-rw-rw-rw- 1 shree shree 4149621 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Asar.exp0.lstmf
-rw-rw-rw- 1 shree shree 3701423 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Baloo.exp0.lstmf
-rw-rw-rw- 1 shree shree 3696594 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Biryani.exp0.lstmf
-rw-rw-rw- 1 shree shree 4567407 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Dekko.exp0.lstmf
-rw-rw-rw- 1 shree shree 3706688 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Ek_Mukta.exp0.lstmf
-rw-rw-rw- 1 shree shree 3697439 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Gargi.exp0.lstmf
-rw-rw-rw- 1 shree shree 4103892 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Glegoo.exp0.lstmf
-rw-rw-rw- 1 shree shree 3986588 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Kadwa.exp0.lstmf
-rw-rw-rw- 1 shree shree 4196205 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Kalam.exp0.lstmf
-rw-rw-rw- 1 shree shree 4030697 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Kalimati.exp0.lstmf
-rw-rw-rw- 1 shree shree 3013510 Dec  9 21:29 /home/shree/tesstutorial/santrain/san.Kokila.exp0.lstmf
-rw-rw-rw- 1 shree shree 3985691 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Kurale.exp0.lstmf
-rw-rw-rw- 1 shree shree 3951000 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Laila_Medium.exp0.lstmf
-rw-rw-rw- 1 shree shree 3935943 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Lohit_Devanagari.exp0.lstmf
-rw-rw-rw- 1 shree shree 4053036 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Mangal.exp0.lstmf
-rw-rw-rw- 1 shree shree 3769371 Dec  8 16:25 /home/shree/tesstutorial/santrain/san.Nakula.exp0.lstmf
-rw-rw-rw- 1 shree shree 3099048 Dec  9 21:29 /home/shree/tesstutorial/santrain/san.Utsaah.exp0.lstmf
-rw-rw-rw- 1 shree shree 3716830 Dec  8 16:28 /home/shree/tesstutorial/santrain/san.Uttara.exp0.lstmf
-rw-rw-rw- 1 shree shree 4141319 Dec  9 21:32 /home/shree/tesstutorial/santrain/san.Yatra_One.exp0.lstmf
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Loaded 41/41 pages (0-41) of document /tmp/tmp.tY7p2Ue5TC/san/san.Baloo.exp0.lstmf
Bad box coordinates in boxfile string! विताः । नानाशस्त्रप्रहरणाः सर्वे 1576 3968 2121 4022 0
Bad box coordinates in boxfile string! रिदेवना ॥ २-२८॥ आश्चर्य 1526 2958 1995 3016 1
Bad box coordinates in boxfile string! ति ॥ २-६४॥ प्रसादे सर्व 1341 4637 1759 4693 2
Bad box coordinates in boxfile string! ति पूरुषः ॥ ३-१९॥ कर्म 1063 2386 1484 2451 2
Bad box coordinates in boxfile string! विभागयोः । गुणा गुणेषु वर्त 420 1710 909 1776 2
Bad box coordinates in boxfile string! न्थिनौ ॥ ३-३४॥ श्रेयान्स्वधर्मो 1447 1278 1982 1335 2
Bad box coordinates in boxfile string! विनाशाय च दुष्कृताम् । धर्म 1364 4402 1863 4475 3
Bad box coordinates in boxfile string! द्धिमान्मनुष्येषु स युक्तः कृत्स्नकर्म 1206 3622 1812 3694 3
That creates a unicharset with words
Detected 15 diacritics
Bad box coordinates in boxfile string! दि ['ए\\^', 25 सर्व 778 1653 1230 1732 92
Bad box coordinates in boxfile string!
Bad box coordinates in boxfile string! विताः । नानाशस्त्रप्रहरणाः सर्वे 1576 3968 2121 4022 0
Bad box coordinates in boxfile string! रिदेवना ॥ २-२८॥ आश्चर्य 1526 2958 1995 3016 1
Bad box coordinates in boxfile string! ति ॥ २-६४॥ प्रसादे सर्व 1341 4637 1759 4693 2
Bad box coordinates in boxfile string! ति पूरुषः ॥ ३-१९॥ कर्म 1063 2386 1484 2451 2
Bad box coordinates in boxfile string! विभागयोः । गुणा गुणेषु वर्त 420 1710 909 1776 2
Bad box coordinates in boxfile string! न्थिनौ ॥ ३-३४॥ श्रेयान्स्वधर्मो 1447 1278 1982 1335 2
[Fri Dec 9 21:53:09 DST 2016] /usr/local/bin/unicharset_extractor -D /tmp/tmp.tY7p2Ue5TC/san/ /tmp/tmp.tY7p2Ue5TC/san/san.Aksharyogini2.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Amiko.exp0.box /tm
7p2Ue5TC/san/san.Asar.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Baloo.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Biryani.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Dekko.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.E
k_Mukta.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Gargi.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Glegoo.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Hind_Medium.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Kadwa.exp0
.box /tmp/tmp.tY7p2Ue5TC/san/san.Kalam.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Kalimati.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Kokila.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Kurale.exp0.box /tmp/tmp.
tY7p2Ue5TC/san/san.Laila_Medium.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Lohit_Devanagari.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Mangal.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Tillana_Medium.exp0.box
/tmp/tmp.tY7p2Ue5TC/san/san.Utsaah.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Yatra_One.exp0.box
#define UNICHAR_LEN 30
training/lstmtraining --model_output ~/tesstutorial/eng_from_chi/eng.lstm \
--continue_from ~/tesstutorial/eng_from_chi/base_checkpoint
~/tesstutorial/eng_from_chi/eng.lstm \
training/lstmtraining --model_output ~/tesstutorial/sanskrit2003_from_full/san.lstm \
training/tesstrain.sh --fonts_dir /home/shree/.fonts --lang bih  \
--output_dir ~/tesstutorial/bihnew
>   --continue_from ~/tesstutorial/sanskrit2003_from_full/san.lstm \
>   --train_listfile ~/tesstutorial/santrain/san.training_files.txt \
Loaded 345/1760 pages (1415-1760) of document /home/shree/tesstutorial/santrain/san.Uttara.exp0.lstmf
Loaded 1814/1814 pages (0-1814) of document /home/shree/tesstutorial/santrain/san.Gargi.exp0.lstmf
Found AVX
tesseract -v
leptonica-1.74
ffffac ffffffe0 ffffffa5 ffffff81 ffffffe0 ffffffa4 ffffff95 ffffffe0 ffffffa4 ffffffa8 ffffffe0 ffffffa4 ffffffbe
``` @Also seen in finetune of Arabic
Loaded file /home/shree/tesstutorial/aratuned_from_ara/aratuned_checkpoint, unpacking...
Successfully restored trainer from /home/shree/tesstutorial/aratuned_from_ara/aratuned_checkpoint
Loaded 229/229 pages (1-229) of document /home/shree/tesstutorial/ara/ara.Amiri.exp0.lstmf
Loaded 4/4 pages (1-4) of document /home/shree/tesstutorial/aratest/ara.Times_New_Roman.exp0.lstmf
Can't encode transcription: نَورُصِبْيُ لَا تٍامَلُظُ يفِ مْهُكَرَتَوَ مْهِرِونُبِ
ShreeDevi
when trying to train frk @Shreeshrii
- A  stray unprintable character (like tab or a control character) in the text.
- There  is an un-represented Indic grapheme/aksara in the text.
--append_index 5 --net_spec '[Lfx256 O1c105]' \
Iteration 59400: ALIGNED TRUTH : មានរូបឆ្មាំ អេស៊ីលីដា
Iteration 59400: BEST OCR TEXT : មានរូបឆ្មាំ អេស៊ីលីដា
File /tmp/tmp.BjsuuQ0dgJ/khm/khm.Noto_Serif_Khmer_Bold.exp0.lstmf page 53 (Perfect):
Iteration 59401: ALIGNED TRUTH : ឆ្កៀលយកភ្នែក ជួនឆ្លងវគ្គ ចាប់ពីពេលនោះមក របស់គាត់ កុំធេ្វសគំនិត។ អូនហ្អើយ =
Iteration 59401: BEST OCR TEXT : ឆ្លៀលយកភ្នែក ជួនឆ្លងវគត ចាប់ពីពេលនោះមក របស់គាត់ កុំធេ្វសគំនិត។ អូនហ្អើយ =
Iteration 59402: ALIGNED TRUTH : សឹងមានះរឹងត្អឹងមហិមា គុណ នៅប៉ែកឦសាននៃភ្នំ ទុលល្យូ ខេត្តស្ទឺងត្រែង,
Iteration 59402: BEST OCR TEXT : សឹងមានះរឹងត្អឹងមហិមា គុណ នៅប៉ែកឦសាននៃភ្នំ ទុលល្យូ ខេត្តស្ទឺងត្រែង,
File /tmp/tmp.BjsuuQ0dgJ/khm/khm.Leelawadee_UI_Bold.exp0.lstmf page 56 :
Iteration 59403: ALIGNED TRUTH : រឺគៃបន្លំបាន។ (រឿងអាខ្វាក់អាខ្វិន) អន្នំលោកង្សិ = ឧទាហរណ៍់៖តំបន់ខ្លះ ផ្ទះសម្បែង
File /tmp/tmp.BjsuuQ0dgJ/khm/khm.Leelawadee_UI.exp0.lstmf page 51 :
1. Does Tesseract have special code to handle bad or malicious input data?
Loaded 1059/1059 pages (0-1059) of document /tmp/tmp.HeGbXAKgjI/san/san.Santipur_OT_Medium.exp0.lstmf
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Bad box coordinates in boxfile string! दि ['ए\\^', 25 सर्व 341 2126 768 2194 44
Loaded 885/885 pages (0-885) of document /tmp/tmp.HeGbXAKgjI/san/san.Uttara.exp0.lstmf
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Loaded 914/914 pages (0-914) of document /tmp/tmp.HeGbXAKgjI/san/san.Uttara.exp0.lstmf
Loaded 1096/1096 pages (0-1096) of document /tmp/tmp.HeGbXAKgjI/san/san.Santipur_OT_Medium.exp0.lstmf
Bad box coordinates in boxfile string! दि ['ए\\^', 25 सर्व 341 2126 768 2194 44
Loaded 13/13 pages (1-13) of document /tmp/tmp.jX9oLgyrCZ/ara/ara.Traditional_Arabic.exp0.lstmf
No block overlapping textline: سُانَّلا
No block overlapping textline: نَادِبْعَ
No block overlapping textline: مْلَهُوَ
No block overlapping textline: امَ
Loaded 75/75 pages (1-75) of document /tmp/tmp.ZhCBJPqjME/ara/ara.Traditional_Arabic.exp0.lstmf
after adding the following to ara.config
http://www.alanwood.net/unicode/vedic-extensions.html
Sample image which uses some of these characters is attached.
>... without those nagging messages, I'd never have had a look on that part of Leptonica.
setMsgSeverity(L_SEVERITY_EXTERNAL);
1. the above messages are from basetrain.log.
We're in the process of updating leptonica to version 1.74.0.
https://launchpad.net/~alex-p/+archive/ubuntu/tesseract-ocr  In an image with Hindi text in various fonts, some of it at very large size
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Found AVX
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Found AVX
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Found AVX
![hin-eng](https://cloud.githubusercontent.com/assets/5095331/20924058/7bdff8a0-bbd5-11e6-890f-87bec2ea9077.png)
The output for the image with -l hin, -l eng, -l hin+eng and -l eng+hin is attached here.
[hin-eng-hin-eng.txt](https://github.com/tesseract-ocr/tesseract/files/633694/hin-eng-hin-eng.txt)
[hin-eng-eng-hin.txt](https://github.com/tesseract-ocr/tesseract/files/633703/hin-eng-eng-hin.txt)
[hin-eng-hin.txt](https://github.com/tesseract-ocr/tesseract/files/633704/hin-eng-hin.txt)
[hin-eng-eng.txt](https://github.com/tesseract-ocr/tesseract/files/633705/hin-eng-eng.txt)
@amitdo Here is the result with 4.0 traineddata
Found AVX
Found AVX
Found AVX
Found AVX
tesseract sg090.png sg090-hin-eng --oem 1 -l hin+eng
Found AVX
tesseract -v
leptonica-1.74.1
Found AVX
./out.sh (  time tesseract ${img_file} ${img_file%.*}-hin-eng --oem 1  -l hin+eng logfile)
>  tesseract -v
>  leptonica-1.74.1
>  ./out.sh (  time tesseract ${img_file} ${img_file%.*}-hin-eng --oem 1  -l hin+eng logfile)
These error messages are from Leptonica.
C:\Users\User>tesseract abc.jpg abc
tesseract -v
In my case, giflib is not included in leptonica, hence it does not process
gifs.
messages from leptonica.
The latest GitHub version of leptonica and tesseract have fewer of these
From http://www.leptonica.org/source/README.html#DEPENDENCIES
ubuntu@XXX$ tesseract -v
leptonica-1.73
ObjectCache(0x7fd27279eac0)::~ObjectCache(): WARNING! LEAK! object 0x2b114e0 still has count 1 (id /mnt/c/Users/User/shree/tessdata/kan.traineddatalstm-punc-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x1b46fc0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatalstm-punc-dawg)
>  leptonica-1.74.1
tesseract test.jpeg file
ShreeDevi
> with Leptonica Error in fopenReadStream: file not found Error in
> traineddatafreq-dawg)
leptonica-1.74.1
leptonica-1.74.1
tesseract --version
tesseract 3.05.00
leptonica-1.74.1
by 0x2AB120: STRING::STRING(STRING const&) (strngs.cpp:114)
(Added) Unfortunately there's also `ScrollView::Exit()`, not sure whether these messages were a problem there? C:\Program Files\Tesseract-OCR>tesseract aws.tif aa.pdf
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddatalstm-punc-dawg)
leptonica-1.74.1
entrepreneurship
entrepreneurial
entrepreneur's
entrenched
dawg2wordlist eng.cube-unicharset eng.cube-word-dawg eng.cube.cube-word.txt
tATu
tBlog
tCK
tO
tPA
tRNA
ta
However, using the following gives incorrect wordlists ..
dawg2wordlist eng.unicharset eng.lstm-word-dawg eng.lstm-word.txt
Joined|Ph
JoinedBAe1
Joined-6
Joined°R
Joined°vg
JoinedX
However, removal of all dawg files from the traineddata does not seem to degrade the accuracy - tested with the phototest.tif and eurotext.tif test files.
1. libicu
2. libpango
3. libcairo
I also build leptonica  in the same machine.
I am using gcc 4.8.4 whic meets c++11 needed standards.
checking for g++... g++
checking for tiffio.h... yes
checking for ar... ar
checking for dlfcn.h... yes
checking malloc.h presence... yes
checking for malloc.h... yes
checking for mbstate_t... yes
checking for leptonica... yes
checking leptonica headers version >= 1.71... yes
checking unicode/uchar.h usability... yes
checking unicode/uchar.h presence... yes
checking for unicode/uchar.h... yes
checking for pango... yes
checking for cairo... yes
leptonica-1.73
http://www.linuxfromscratch.org/blfs/view/svn/x/cairo.html: cairo-1.14.6.tar.xz, http://www.linuxfromscratch.org/blfs/view/svn/x/pango.html: pango-1.40.3.tar.xz
http://packages.ubuntu.com/trusty/libpango1.0-dev
do you have any idea of what is happening? Becuase I also have installed Leptonica, but I don´t know if I am missing something during compilation process.
checking for pango... yes
checking for cairo... yes
> checking for strings.h... yes
> checking for tiffio.h... yes
> checking for dlfcn.h... yes
> checking malloc.h presence... yes
> checking for malloc.h... yes
> checking leptonica headers version >= 1.71... yes
> checking unicode/uchar.h usability... yes
> checking unicode/uchar.h presence... yes
> checking for unicode/uchar.h... yes
> checking for pango... yes
> checking for cairo... yes
./.libs/libtesseract.so: undefined reference to `omp_get_thread_num'
./.libs/libtesseract.so: undefined reference to `GOMP_sections_end_nowait'
./.libs/libtesseract.so: undefined reference to `omp_get_num_threads'
> checking for strings.h... yes
> checking for tiffio.h... yes
> checking for dlfcn.h... yes
> checking malloc.h presence... yes
> checking for malloc.h... yes
> checking leptonica headers version >= 1.71... yes
> **checking for ICU_I18N... no**
> checking unicode/uchar.h usability... yes
> checking unicode/uchar.h presence... yes
> checking for unicode/uchar.h... yes
> checking for pango... yes
> checking for cairo... yes
**lib**
leptonica  tesseract
**bin**
> checking for strings.h... yes
> checking for tiffio.h... yes
> checking for dlfcn.h... yes
> checking malloc.h presence... yes
> checking for malloc.h... yes
> **checking for LEPTONICA... yes**
> **checking leptonica headers version >= 1.71... yes**
> **checking for ICU_I18N... yes**
> **checking for pango... yes**
> **checking for cairo... yes**
https://github.com/DanBloomberg/leptonica/issues
From http://leptonica.org/
Detected 18 diacritics
https://github.com/tesseract-ocr/tesseract/issues/292#issuecomment-222529057 Warnings are not limited to png, same for tif, gif and jpg. @zdenop @amitdo Thanks!
cc:ing Dan Bloomberg for his input regarding Leptonica
> code or in Tesseract.
vararg-formatted and of 3 types: error, warning, informational.
These are all macros, and can be further suppressed when
These messages are arguably INFO rather than WARNING.
setMsgSeverity(L_SEVERITY_EXTERNAL);
@zdenop  That's an interesting idea.  Default setting is for INFO, WARNING and ERROR, but for a release that will be used in production it makes sense to only show ERROR. @amitdo
Look at the leptonica wrappers for tiff (tiffio.c) and gif (gifio.c) to see how it is done.
> AL056XMVGWYPqK1Pc8XzqTxrzYjHZxgZks5rFS4MgaJpZM4LCRAs>
With C++, byte order or pre-evaluated need to reverse order ("bool swap") can easily be hidden in a file object member variable: it does not have to be passed around as a function argument, if that is considered too cumbersome. Has anybody even made a performance analysis before just postulating that little-endian is necessary for optimal or near-optimal performance on little-endian machines, considering that relatively little time is spent on I/O and that data files will also tend to be little-endian? I've had a look at stweil's proposal (endian branch), and I'm "not sure" that it will work... unless on a big-endian machine the file is saved twice, or read in again, perhaps because serialisation was the last thing the program did before it was restarted, or otherwise explicitly. The problem seems to be that the byte order is reversed in place, for serialisation as well as deserialisation. If you want to use a fixed endianness, you have to use a separate buffer, or do one of the workarounds described above. And that's if you're sure that each data item is visited exactly once, otherwise the reversal has to occur inside the lowest-level serialisation functions!
Provide a vcpkg port for tesseract would be very convenience. Egor,
It you would like to add support for Leptonica and Tesseract to the Microsoft vcpkg ports collection:
You might want to add a request to add Tesseract:
Making all in api
les singes anthropo'I'des peuvent acceder a une expression symbolique abstraite (utilisation de la
langue des signes des personnes sourdes, manipulation de symboles abstraits), mais il n'a jamais pu
étre etabli qu'un animal non humain soit capable d'exprimer une idee, ni meme un concept. En
d'autres termes, certains animaux sont capables d'exprimer leurs besoins (la faim, la soif), leurs
emotions (desirs ou craintes, tristesse ou joie...), mais aucun ne semble capable de porter un
formulee par des philosophes. Par exemple, remarque Aristote, les autres animaux peuvent exprimer
le plaisir ou la douleur, qui sont des sensations, non le juste et l'injuste, qui sont des idees (et c'est
les singes anthropoïdes peuvent accéder a une expression symbolique abstraite (utilisation de la
langue des signes des personnes sourdes, manipulation de symboles abstraits), mais il n'a jamais pu
être établi qu'un animal non humain soit capable d'exprimer une idée, ni même un concept. En
d'autres termes, certains animaux sont capables d'exprimer leurs besoins (la faim, la soif), leurs
émotions (désirs ou craintes, tristesse ou joie…), mais aucun ne semble capable de porter un
jugement liant des concepts, � l'exception de notre espèce. Cette précision rejoint la remarque déj�
formulée par des philosophes. Par exemple, remarque Aristote, les autres animaux peuvent exprimer
le plaisir ou la douleur, qui sont des sensations, non le juste et l‘injuste, qui sont des idées (et c‘est
It will broken when some characters can NOT be renderd with some fonts (the chinese fonts file usually  would NOT contain all the characters of chinese)
On 22-Nov-2016 2:01 PM, "albertyou2" notifications@github.com wrote:
> It will broken when some characters can NOT be renderd with some fonts
On 22-Nov-2016 2:01 PM, "albertyou2" notifications@github.com wrote:
> It will broken when some characters can NOT be renderd with some fonts
@Shreeshrii
Uff..., well, then I don't understand the sentence "Please do not change the title of any wiki page without a permission from Tesseract developers." at https://github.com/tesseract-ocr/tesseract/wiki CC @amitdo . I would expect that I can ask permission from developers in an issue at GitHub, if one has to use the user forum for that, then the sentence should be reformulated. Hi @zuphilip :-)
@amitdo
various versions, box files, tesstrain etc. I had no idea that it would
- There were many links to some of the wiki pages from Tesseract issues,
Shree @Shreeshrii,
@amitdo, I just contacted GitHub support and suggested to enhance the history, so maybe it will show all contributions (also those before a rename) in the future.
This is called [breaking the web](https://www.google.co.il/search?client=ubuntu&channel=fs&q=%22breaking+the+web%22+%22broken+links%22) and it's not nice.
Maybe not many people care about this issue as I do...
@zuphilip,
@theraysmith or @zdenop should decide about it.
@zdenop?
the infamous 'isnan()' error
traindata2\fontyp.traineddata
Reducing Trie to SquishedDawg
Akbronco
Akstiletto
Ankyros
Ash
Bo
Boar
Boltor
Braton
Bronco
Burston
Carrier
Dakra
Dual
Ember
Fang
Fragor
It is not generating the dawg file, any suggestions what is wrong? Added both files
1、The encoding of the input files freq_file_list.txt and eng1.unicharset.txt may not meet the requirements .
Please note tesseract version, o/s, commit number if known.
your ara_frequent.txt is encoded in ANSI with windows style end of line
markers. the words  show up as the following, instead of in Arabic.
íÊæÞÚ
ÇáÚáãÇÁ
ÊÕÈÍ
ÝÇßåÉ
ÇáßÑÒ
æÇÍÏÉ
ãä
æÓÇÆá
ÚáÇÌ
ÇáÏÇÁ
ÇáÓßÑí
ÝÇáãÇÏÉ
ÇáÓßÑíÉ
ShreeDevi
> ara_frequent.txt
> <https://github.com/tesseract-ocr/tesseract/files/929641/ara_frequent.txt>
> ara.unicharset.txt
# -r arguments to wordlist2dawg denote RTL reverse policy
# 1/RRP_REVERSE_IF_HAS_RTL for freq and word DAWGS,
# 2/RRP_FORCE_REVERSE for the punctuation DAWG.
All values of PATH were emptied by the installation.
(Lese Datenbank ... 328342 Dateien und Verzeichnisse sind derzeit installiert.)
tesseract-ocr hängt ab von libtesseract4; aber:
dpkg: Fehler beim Bearbeiten des Paketes tesseract-ocr (--configure):
Abhängigkeitsprobleme - verbleibt unkonfiguriert
Paket tesseract-ocr ist noch nicht konfiguriert.
dpkg: Fehler beim Bearbeiten des Paketes tesseract-ocr-dbg (--configure):
Abhängigkeitsprobleme - verbleibt unkonfiguriert
tesseract-ocr
tesseract-ocr-dbg
@zdenop
On 4 Nov 2016 12:44 p.m., "zdenop" notifications@github.com wrote:
Looking for stddef.h - found
D:\personal\tesseract>cppan
-- Check if the system is big endian
-- Looking for stddef.h - found
http://imgur.com/a/LAfPN
‘MORPH_BC’ defined but not used [-Wunused-variable]
Signed-off-by: Stefan Weil <sw@weilnetz.de> It is still not clear for me why that variable `MORPH_BC` is needed at all.
There are small issues in the code that cause compilation errors under Windows unicode project.
baseapi.cpp
82 STARTUPINFO -> STARTUPINFOA
A Windows code page version with the letter "A" used to indicate "ANSI"
A Unicode version with the letter "W" used to indicate "wide"
Making all in ccutil
from ambigs.h:25,
from ambigs.cpp:24:
In file included from unicharset.h:24,
from ambigs.h:27,
from ambigs.cpp:24:
make[3]: *** [ambigs.lo] Error 1
Leptonica 1.67 installed.
Hi iamcool345, Try updating to a more recent version of Leptonica and/or the more recent version of Tesseract as well.
7 api
40 ccutil
6 cutil
Format: TIFF (Tagged Image File Format)
Mime type: image/tiff
Units: Undefined
Endianess: LSB
Format: PNG (Portable Network Graphics)
Mime type: image/png
Class: PseudoClass
Units: Undefined
Endianess: Undefined
But then, why does tesseract behave inconsistently between tif and png when both have `Units: Undefined`?
I think I know why the units are Undefined. pdfsandwich does a 2-step conversion from a PDF page to tif:
Units: Undefined
Endianess: Undefined
Format: TIFF (Tagged Image File Format)
Mime type: image/tiff
Units: Undefined
Endianess: LSB
one in baseapi.ccp is active for this test case.
warning:
![leptonica](https://cloud.githubusercontent.com/assets/17674215/18988851/44796cb8-8726-11e6-8854-9ff87c11ad96.png)
First, it is recommended to uninstall an older Leptonica before you install new one.
pagesegmode values are:
I was trying each one and getting mixed results. However, I accidentally ran 'psm -11' and I suddenly got perfect accuracy - way way better than any other PSM mode, and much better than the default. The same for PSM 12 too, perfect accuracy - then PSM 13 gives nothing.
> https://github.com/notifications/unsubscribe-auth/AE2_o7sVanef-bvL1nJdyJAdBJ0L3-2jks5qtAwkgaJpZM4KEcsN
You could try scantailor or imagemagick.
As a test, you can also try Vietocr GUI, and compare results with the
> https://github.com/notifications/unsubscribe-auth/AE2_o7sVanef-bvL1nJdyJAdBJ0L3-2jks5qtAwkgaJpZM4KEcsN
Thanks for looking at this @amitdo.
> It 'thinks' the speckles are diacritics...
Look how tesseract uses leptonica and CCs e.g.,
@amitdo and @jbreiden:
`tiffgray`:
`tiffgray` is definitely better for this, and since we're doing millions of files, it seems safer to use this approach than to assume all docs are purely black and white (even though it makes big files).
> You might want to use -sCompression=lzw.
> https://github.com/notifications/unsubscribe-auth/AE2_o26v-ubHM_MSiloIl-YAaOzocpMPks5qwqlWgaJpZM4KEcsN
> https://github.com/notifications/unsubscribe-auth/AE2_o6dJ5XcUXiaPRWE7ElBADweni21Xks5qs27ZgaJpZM4KD0AP
String TAG= "OCR";
String DATA_PATH = Environment.getExternalStorageDirectory().toString() + "/Sigmaway/";
String[] language={"eng","ara"};
Log.v(TAG, "Ctesseract 6" );
Reverting
libtesseract_la_LDFLAGS += -version-info $(GENERIC_LIBRARY_VERSION) -no-undefined
libtesseract_la_LDFLAGS += -version-info $(GENERIC_LIBRARY_VERSION)
==> Using the sandbox
==> ./configure --prefix=/usr/local/Cellar/tesseract/HEAD-a75ab45_2 --enable-opencl
pixErodeCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
pixErodeCL(int, int, unsigned int, unsigned int) in libtesseract_opencl.a(openclwrapper.o)
make[1]: *** [libtesseract.la] Error 1
Maybe the image is too big ? If that is the case it would be nice to get a better message.
leptonica-1.73
@zdenop, I suggest to give @jbarlow83 a green light for sending a PR. Yes, working on it.  I am facing issues in window installation. And probably due to Pango / Cairo. Any help please?
-- Checking for module 'pango'
``` http://www.pango.org/Download 404 error https://www.gtk.org/download/win64.php
![2](https://cloud.githubusercontent.com/assets/2742842/18303628/ab937754-7510-11e6-9d01-12bf943a2b24.png)
Yes I have and the generated ALTO isn't valid. It can't be imported to the software I use and also the validator ocr-validate says it's not valid.
cppan runs without issues.
06.09.2016  18:52             2,140 cppan-helpers-private.cmake
06.09.2016  18:52             2,322 cppan-helpers.cmake
06.09.2016  18:52             2,816 cppan.cmake
06.09.2016  18:55                 0 pvt_cppan_demo_gif__5_1_4-aliases.cmake
Any clue? I have zero experience with cppan and cmake, so no idea how to attempt to resolve it.
include/tesseract/baseapi.h:594:21:
In baseapi.h declared as fallows:
Clang:
Thread model: posix
if (NOT USES_CPPAN)
target_link_libraries       (tesseract cppan)
Here `USES_CPPAN` is undefined, and the if statement is always True. Since Leptonica is loaded from CPPAN, and `target_link_libraries(tesseract cppan)` is never excuted, error happens!
After modify the codes above into
target_link_libraries       (tesseract cppan)
`USES_CPPAN` needs definition!
Can someone please help me? Hi egorpugin,
LeptonicaConfig.cmake
leptonica-config.cmake
Add the installation prefix of "Leptonica" to CMAKE_PREFIX_PATH or set
"Leptonica_DIR" to a directory containing one of the above files.  If
What / where is Leptonica?  So i'm trying to ocr the following images but looks we its not doing it 100%. six is written as five. nine is written as 3. Any suggestions?
[deleted]
ShreeDevi
A haystack which is shorter than the needle resulted in negative value
for length_haystack which was forced to a very large unsigned value.
The resulting buffer overflow while reading the haystack would crash
./configure: line 17228: syntax error near unexpected token `pango,'
<http://gnu.org/licenses/gpl.html>, <http://gnu.org/licenses/exceptions.html>
Written by David J. MacKenzie and Akim Demaille.
Running aclocal
libtoolize: copying file `m4/lt~obsolete.m4'
autoreconf -ivf
ShreeDevi
On Wed, Aug 31, 2016 at 5:28 PM, Bayu Widyasanyata <notifications@github.com
@Shreeshrii it works! thanks bro! :+1:  taken from **autoreconf** man page
@amitdo here's the output:
@zdenop It's fine! :-)
PT7895M
OMOOKM
OOLI9T7
OMOOKMI
OOLI9T7
PT7898M
OMOOKMI
https://groups.google.com/forum/#!topic/tesseract-ocr/5vFqVcJmHnM
some examples of user words could be client names, industry specific
need to recognize words of medications ( Rare words that are most likely not included in the training data). Also see: https://groups.google.com/d/msgid/tesseract-ocr/ab28b50f-d592-4f48-b813-c03451c4dbb0%40googlegroups.com?utm_medium=email&utm_source=footer  Assertions are good for programming errors, but not for wrong user input.
I noticed that the crash is a "feature", caused by an assertion if `langdata/san.training_text` does not exist. Tesseract forces a SIGSEGV for assertions to improve debug information.
@amitdo, thanks for the pointers. PR #402 now does something similar for `fileio`.
Somebody please help!
On 28-Aug-2016 11:32 AM, "z0tghvunik" notifications@github.com wrote:
FcInitiReinitialize failed!!
I tried the latest version of the program uploaded today on Windows10 and found that it now works but is unstable. It would fail for Arial font and could not find Times New Roman (the two fonts are most commonly used). The boxes in the generated box file were not as tight as they could be.
text2image --text=vie-data.txt --outputbase=vie.arial.exp1 --font="Tahoma" --fonts_dir=C:\Windows\Fonts
Rendered page 0 to file vie.arial.exp1.tif
Rendered page 0 to file vie.arial.exp1.tif
Rendered page 1 to file vie.arial.exp1.tif
text2image --text=vie-data.txt --outputbase=vie.arial.exp1 --font="Times New Roman" --fonts_dir=C:\Windows\Fonts
Rendered page 0 to file vie.arial.exp1.tif
https://github.com/mazoea/te-external-tesseract
3. see https://github.com/mazoea/te-external/blob/master/appveyor.yml for the real commands and also check the logs by clicking on the build badge in the repository
4. the same goes for https://github.com/mazoea/te-external-leptonica
5. the same goes for https://github.com/mazoea/te-external-tesseract
FcInitiReinitialize failed!!
shows the fonts in the list
FcInitiReinitialize failed!!
FcInitiReinitialize failed!!
FcInitiReinitialize failed!!
C:\Users\User\Documents\shree>text2image --text=./langdata/eng.training_text --outputbase=vie.arial.exp1 --font="Times New Roman," --fonts_dir=C:\Windows\Fonts
FcInitiReinitialize failed!!
Rendered page 0 to file vie.arial.exp1.tif
Rendered page 1 to file vie.arial.exp1.tif
@zdenop OK
@zdenop
FcInitiReinitialize failed!!
C:\Users\User\Documents\shree>text2image --fonts_dir=C:\Windows\Fonts --fontconfig_tmpdir=C:\Users\User\Documents\shree --text ./langdata/san.training_text  --outputbase
C:\Users\User\Documents\shree>text2image --fonts_dir=C:\Windows\Fonts --fontconfig_tmpdir=C:\Users\User\Documents\shree --text ./langdata/san.training_text  --outputbase
ShreeDevi
(gdb) r
0x000000000040e089 in strcasestr (haystack=0x303afd0 "Arial", needle=0x43ba5d <tesseract::kDefaultResolution+457> "Fraktur") at ../../../../training/../vs2010/port/strcasestr.cpp:63
#0  0x000000000040e089 in strcasestr (haystack=0x303afd0 "Arial", needle=0x43ba5d <tesseract::kDefaultResolution+457> "Fraktur") at ../../../../training/../vs2010/port/strcasestr.cpp:63
304: Trebuchet MS Bold Oblique
305: Trebuchet MS Oblique
306: Verdana
307: Verdana Bold
308: Verdana Bold Oblique
309: Verdana Oblique
310: Yu Gothic
311: Yu Gothic Bold
312: Yu Gothic Bold Oblique
313: Yu Gothic Light, Light
314: Yu Gothic Medium, Medium
315: Yu Gothic Medium, Medium Oblique
316: Yu Gothic Oblique
@amitdo Almost all the generated boxes (created in Windows 10) are consistently a bit low and a bit wide. It was reported that having tightly fitted boxes would improve the quality of the generated traineddata file.
GETUNTUPUF
BUBBLE.
The api is called as follows.
what is the cause  of this error?
@amido  thx any way, i notice you working on both projects then came this question
@amitdo my fault~
Isn't a new `pdf.ttf` needed? Yes there should be a new pdf.ttf in v4. Today is a major holiday in my country and I probably can't do anything (including take a careful look) until later, possibly Monday. https://en.wikipedia.org/wiki/Thanksgiving
#if defined(HAVE_CAIRO_WIN32)
return g_object_new (PANGO_TYPE_CAIRO_WIN32_FONT_MAP, NULL);
#if defined(HAVE_CAIRO_FREETYPE)
return g_object_new (PANGO_TYPE_CAIRO_FC_FONT_MAP, NULL);
and nasty crashes follow because of the wrong reinterpret cast.
https://github.com/tesseract-ocr/tesseract/blob/182ca5bc1e/training/pango_font_info.cpp#L367
">>\n"
Funny thing: Alfresco uses pdf.js as pdf viewer, and the search in pdf,js is actually working. Meaning: pdf.js doesn't put extra spaces between the characters.
fÿB1
ParamsModel::Incomplete line ?d>ڎW{8
ParamsModel::Incomplete line ?
ParamsModel::Incomplete line xÿOҭ
ParamsModel::Incomplete line ?,IiTc?kKZfiP{hmuǿqEȿ
ParamsModel::Incomplete line T?ESWJ&ParamsModel::Incomplete line 92|&&
ParamsModel::Incomplete line V
ParamsModel::Incomplete line KaramsModel::Incomplete line 㕳Ibamؿϴȿlm)eParamsModel::Incomplete line U~c[)f!t8M
'?{y+?{?dBi"?--?@N?*+˹e-I?_+?L?K6{b?x?{
Pa_a+_M-de+::I+c-+-+e+e +i+e ž"0ְ|?}+?
ParamsModel::Unknown parameter ne z#@     A|a꿹xڿkPԿB"
iҿnP?9|\?
ParamsModel::Incomplete line aramsModelPa_a+_M-de+::I+c-+-+e+e +i+e ?\È?>:Unknown parameter ^ҿ
Pa_a+_M-de+::I+c-+-+e+e +i+e GU`zCԿa8aş?S.ǿParamsModel::Incomplete line ?Z"
0&=ÿR]S⽅?+>+*'fٿE"_-,Ĳ/FU
ParamsModel::Incomplete line ParamsModel::Incomplete line Ó'C:
Pa_a+_M-de+::I+c-+-+e+e +i+e ?c=Q#>~+͜?Fў?yRFU?T+ÿ7P&>:?J?D2\NW?ٿ+
ParamsModel::Incomplete line qjؿ
Pa_a+_M-de+::I+c-+-+e+e +i+e @+A}?!bS:?F?㖾Th?XF08>?LUdH?Vb?-<ŵz0?Vb?+I
Pa_a+_M-de+::I+c-+-+e+e +i+e ?+^п4<Y_?[Me}|<?W+A|տ*+?)_|G7MG5V?3|<?
... And this goed on and on I tried that after with this command:  tesseract -l nld+eng pdfsandwich45aaf9.tif -pdf
Might that have something to do with it? https://github.com/tesseract-ocr/tessdata/tree/3.04.00 Okay, that was a bit silly on my end.
ubuntu v15
The total count of fonts i gave was 70
gdb /usr/bin/tesseract
@zdenop do you mean, TESSDATA_PREFIX follows the optional datadir option ?
@Wikinaut, Tesseract for Windows uses a different method to find `tessdata`. A fixed TESSDATA_PREFIX would not work on Windows, because there is no fixed installation path.
It looks like many TIFF files (nearly all?) include some vendor specific data which trigger warnings from libtiff, so it is a real and very common problem for Windows users who want to do batch processing. I see these alternatives to handle the problem:
@egorpugin, I added a commit which handles the libtiff dependency, so the code will not break if tiffio.h is unavailable.
Can we move it to Leptonica?
We need to wait to an update of Mingw-w64's Leptonica PKGBUILD.
Egor will probably update cppan very soon.
ubuntu v15
`tesseract in.tiff out  -l nld+eng pdf`
Tesseract is compiled with the following options:
leptonica-1.73
Yeah, I found that out later as well. But I'm not sure where Tesseract stops and Leptonica begins ;-)
What do you make of this? Is this a problem with Tesseract, Leptonica, with the source file(s) or libraries?
You probably run into this problem if you run tesseract + leptonica as root first, then as another user.
I think this bug can be closed as it's really a leptonica problem, which is handled there.
yes, I made some changes last week on the leptonica github head:
https://github.com/danbloomberg/leptonica
![cantal](https://cloud.githubusercontent.com/assets/3824869/16715547/6952422c-46e3-11e6-8ec6-a24a40f4aa45.jpeg)
Heh…  those are Captcha images – where the text has been distorted so
Subject: [tesseract-ocr/tesseract] information about failure to recognize any charaters in those images (#363)
One can only see that there is purposely neglect and sabotage to the  "RTL" Right to Left language community.
And yet we ask Ray to publish the documentation and tools to train Cube before it is fully removed from tesseract, or at least assure the community that the RTL languages (Arabic, Hebrew...) will be considered in future version releases of Tesseract and future tools will be published helping the developer community in the training process of RTL languages.
The Arabic trained data is available in the tessdata repo, and if you want to submit patches to improve the LTSM engine for Arabic, you can. If not, that's fine, maybe someone else familiar with both the language and Tesseract will come around. In an open source community, you are not entitled to anything...if you want things fixed, submit patches -- you're already pretty close having already identified some problems. @ctrlcctrlv,
M o r g a n
A c c o u n t n
ocrmypdf -f --pdf-renderer tesseract in1.pdf out1_3.04.01.pdf
E:\cygwin64\bin\cyggcc_s-seh-1.dll
E:\cygwin64\bin\cyggcc_s-seh-1.dll
--- a/training/pango_font_info.cpp
+++ b/training/pango_font_info.cpp
#if (defined __MINGW32__) || (defined __CYGWIN__)
#if (defined __MINGW32__)
cygwin, mingw, aix are example of platform requiring it. It is not harmful on the other platforms
after downloading and manually compiling leptonica and tesseract, I see the following output
when trying to list the version-information of tesseract:
>  leptonica-1.72
> [con-tom@lapp01awdtst tess_test]$
leptonica-1.72
Delegates (built-in): bzlib freetype jng jpeg ltdl lzma png tiff xml zlib
then I run `tesseract pic.gif result`, I got that undefine symbol error. How to fix it?
IMHO removing the deliberate null pointer access is a good thing. I cannot see why the SEGV would give a stack trace which is more useful than with ABRT (as it is written in the code comment).
std::signal(SIGABRT, signal_handler);
std::raise(SIGABRT);
@theraysmith, what's your take on that?  Placed ambigs problem in the mailing list but got no reply.  This I hope you can help.
Having trained tesseract in the Sinhala language we find we cannot get the 0 option in ambigs to work - no correction occurs even though the word is in the dictionary.
Am Sa., Jun. 4, 2016 16:07 schrieb Egor Pugin : Ok, and how should I understand what is incorrect? Where is tesseract output, error message, anything?
**p r o d u c t s a c c o r d i n g t o t h e a t t a c h e d c u s t o m e r l i s t N o .**
SumatraPDF. The viewer hasn't had any problems at all so far. And we're using it on several computers for years now including all our customers.
Yes, it is not so nice.
Yes, the code is not consistent – sometimes it exits with 0, sometimes it exits with 1.
Nam: an 32:
E| luginmjpg 52 J15 B
§  lugIlI7l_Ihum   >s.plvg 1:; ma
mgms
Oulvzr
upznlxegksk
upznlxegksk
upznlxegksk
upznlxegksk
upznlxegksk
upznlxegksk
upznlxegksk
``` python
tesseract = CDLL(LIBTESS)
leptonica = CDLL(LIBLEPT)
leptonica.pixRead.argtypes = [c_char_p]
leptonica.pixRead.restype = POINTER(Pix)
return tesseract, leptonica, api
def get_orientation(tesseract, leptonica, api, path, mode=1):
pix = leptonica.pixRead(path)
tesseract, leptonica, api = create_tess_api()
CR: https://github.com/sirfz/tesserocr/issues/5
``` python
('scripts_na', c_float * 4 * (116 + 1 + 2 + 1)),
('unicharset', c_void_p),
def get_orientation(tesseract, leptonica, api, path, mode=0):
pix = leptonica.pixRead(path)
`tesseract photo.jpeg out -l ara`
This is the error
Cube ERROR (CubeRecoContext::Load): unable to read cube language model params from /opt/local/share/tessdata/ara.cube.lm
Obviously i installed tesseract and the arabic language pack.
Could not initialize tesseract.`
Any idea why? I ran `sudo port install tesseract-ara` on my mac
now runing:`tesseract --list-langs` return arabic and english.
still same error when runing `tesseract photo.jpeg out -l ara`
tesseract test.jpg test.txt
I am trying to train Tesseract but unfortunately, my training is failing.
`Bad properties for index 5, char a: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 11, char .: 0,255 0,255 0,0 0,0 0,0`
I am trying to understand why or how and now that I have researched it for 1 week I think its the unicharset_extractor.
@amitdo no worries. :+1:
@amitdo Okay, I read it! Thank you very much, I will test the solution and come back to you as soon as I can and close this issue if it solved it or is the same thing as the other issue. Just going to keep it open for now, in case of emergency! :P
Maybe its super bad!!! D:
@amitdo YES!! IT WORKED! MONTHS OF STUDYING AND WORKING HARD, AND NOW ITS WORKING! IF I COULD KISS YOU, I WOULD!!! THANK YOU VERY VERY MUCH!!!
@amitdo lol, sorry, it was not only this problem. But I'm a student in an internship and this was very hard because I had never done c++ or any knowledge of AI or deep learning. Now this was the last step before I can get the result of all the hard work I did to train Tesseract and get results.
I get some strange result when I try to train Tesseract.
I think it may be cause by unicharset.
`unicharset_extractor eng.palladio-regular.exp8.box`
« 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # « [ab ]
e 3 0,255,0,255,0,0,0,0,0,0 Latin 57 0 6 e  # e [65 ]a
t 3 0,255,0,255,0,0,0,0,0,0 Latin 21 0 9 t  # t [74 ]a
N 5 0,255,0,255,0,0,0,0,0,0 Latin 8 0 10 N  # N [4e ]A
w 3 0,255,0,255,0,0,0,0,0,0 Latin 74 0 11 w # w [77 ]a
c 3 0,255,0,255,0,0,0,0,0,0 Latin 27 0 13 c # c [63 ]a
l 3 0,255,0,255,0,0,0,0,0,0 Latin 68 0 14 l # l [6c ]a
T 5 0,255,0,255,0,0,0,0,0,0 Latin 9 0 21 T  # T [54 ]A
o 3 0,255,0,255,0,0,0,0,0,0 Latin 42 0 22 o # o [6f ]a
C 5 0,255,0,255,0,0,0,0,0,0 Latin 13 0 27 C # C [43 ]A
Z 5 0,255,0,255,0,0,0,0,0,0 Latin 98 0 35 Z # Z [5a ]A
M 5 0,255,0,255,0,0,0,0,0,0 Latin 39 0 37 M # M [4d ]A
u 3 0,255,0,255,0,0,0,0,0,0 Latin 48 0 38 u # u [75 ]a
m 3 0,255,0,255,0,0,0,0,0,0 Latin 37 0 39 m # m [6d ]a
P 5 0,255,0,255,0,0,0,0,0,0 Latin 16 0 40 P # P [50 ]A
H 5 0,255,0,255,0,0,0,0,0,0 Latin 28 0 41 H # H [48 ]A
O 5 0,255,0,255,0,0,0,0,0,0 Latin 22 0 42 O # O [4f ]A
U 5 0,255,0,255,0,0,0,0,0,0 Latin 38 0 48 U # U [55 ]A
F 5 0,255,0,255,0,0,0,0,0,0 Latin 5 0 52 F  # F [46 ]A
E 5 0,255,0,255,0,0,0,0,0,0 Latin 6 0 57 E  # E [45 ]A
b 3 0,255,0,255,0,0,0,0,0,0 Latin 64 0 58 b # b [62 ]a
B 5 0,255,0,255,0,0,0,0,0,0 Latin 58 0 64 B # B [42 ]A
L 5 0,255,0,255,0,0,0,0,0,0 Latin 14 0 68 L # L [4c ]A
W 5 0,255,0,255,0,0,0,0,0,0 Latin 11 0 74 W # W [57 ]A
J 5 0,255,0,255,0,0,0,0,0,0 Latin 105 0 75 J    # J [4a ]A
é 3 0,255,0,255,0,0,0,0,0,0 Latin 76 0 76 é   # é [e9 ]a
Y 5 0,255,0,255,0,0,0,0,0,0 Latin 46 0 83 Y # Y [59 ]A
G 5 0,255,0,255,0,0,0,0,0,0 Latin 18 0 91 G # G [47 ]A
K 5 0,255,0,255,0,0,0,0,0,0 Latin 65 0 94 K # K [4b ]A
V 5 0,255,0,255,0,0,0,0,0,0 Latin 24 0 96 V # V [56 ]A
X 5 0,255,0,255,0,0,0,0,0,0 Latin 51 0 106 X    # X [58 ]A
N 5 59,68,216,255,87,236,0,27,104,227 Latin 11 0 1 N
Y 5 59,68,216,255,91,205,0,47,91,223 Latin 33 0 2 Y
a 3 58,65,186,198,85,164,0,26,97,185 Latin 56 0 5 a
2. What if I use the latin.unicharset that do not match the xheight of the chosen font?
Is it normal?
Warning: properties incomplete for index 1296 = ٍ
Warning: properties incomplete for index 1297 = َ
Warning: properties incomplete for index 1299 = ِ
Warning: properties incomplete for index 1300 = ّ
Warning: properties incomplete for index 1301 = ْ
Warning: properties incomplete for index 1302 = ٓ
Warning: properties incomplete for index 1303 = ٔ
Warning: properties incomplete for index 1304 = ٕ
Warning: properties incomplete for index 1315 = ٰ
Warning: properties incomplete for index 1407 = ⁫
Warning: properties incomplete for index 3101 = ゙
then new_unicharset looks like:
@ne0zer0 's questions are good ones.
W 5 Latin 40
appears to be out of date (I think that's Tesseract version 2)
> appears  to be out of date (I think that's Tesseract version 2)
Yes, you should read unicharset(5) doc:
set_unicharset_properties --help
Done after reading your post addressed to ggdhines
> CAVEATS
@amitdo
Reading eng.palladio-regular.exp9.tr ...
Reading eng.palladio-regular.exp9.tr ...
The result is as strange as before, but now I have this warning in mftraining:
At first, i tried without `shapeclustering`, but I finally say "what if".
Reading eng.palladio-regular.exp9.tr ...
But what about theses questions:
> CAVEATS
> CAVEATS
@amitdo - why is this necessary at all? Shouldn't Tesseract being learning based on the training examples we provide? Pre-existing data isn't going to be helpful with new fonts.
@ggdhines :+1:
Indeed. In fact, I expected too much from Tesseract.
configure: error: leptonica library missing
I have kept my leptonica's liblept.a in /apps/build/lib but stil it fails with this error.
any help is much appreciated
even after correcting to CXXFLAGS or CPPFLAGS it still throws the same error
Bad box coordinates in boxfile string! ����
Bad box coordinates in boxfile string!
Bad box coordinates in boxfile string!
Bad box coordinates in boxfile string!
Bad box coordinates in boxfile string! (��(��(��(��(��(��(��(��(��(��(��(��(��(��(��(��(��(��(��(�?�����_ٯ��?h�i��މ��~$�mt��K��lmd��!Y�)
襈�r?$���t��?�(��O��������
The question marks are just gibberish. (And the errors keep on coming). I feel I like I didn't have this problem recently but wondering if some upgrade broke things.
leptonica-1.72
tessedit_create_hocr 1
├── tessdata/
│       │       └── hocr
@amitdo Thanks!
"Deskew angle: %.4f\n",
api or the logic to get this.
Ankit
Dear @ankitagg,
I played with all kind of options like conflict_set_I_l_1 and rej_1Il_trust_rej_1Il_trust_permuter_type_type and more, but had no success.
Or which special setting of the parameters do I have to choose to get this working?
rolfm@~/ocr> tesseract -psm 7 good.jpg good ; cat good.txt
rolfm@~/ocr> tesseract -psm 7 bad.jpg bad ; cat bad.txt
NCORI40123020064000000000
bad.jpg :
The only "fix" I found was to add " -l deu " and then bad.jpg is read correctly.
But isn't it clearly a bug? ocropus-rpred has no problem with bad.jpg.
But I need to train my cube for my research, have any other way, even not in tesseract, to train the .cube.nn file? I'm so curious about where's the original cube model from, could any one give me some advises about it?
import os
if not TESSDATA_PREFIX:
On Tesseract 3.04.00 I get a segmentation fault while trying to get the orientation information for the image with arabic text.
tesseract 3.04.00
leptonica-1.72
Ara langs in TESSDATA:
$ ls ara*
Segmentation Fault:
$ tesseract arabic_4.jpg stdout -psm 0 -l ara
[1]    3721 segmentation fault  tesseract ~/Downloads/arabic_4.jpg stdout -psm 0 -l ara
This does not happen when I pass the language as `eng` instead of  `ara` but then ofcourse the results and confidence factor are extremely low.
$ tesseract ~/Downloads/arabic_4.jpg stdout -psm 0 -l eng
'input_filename': '/tmp/tess_qi4zyS.bmp',
'command': ['tesseract', '/tmp/tess_qi4zyS.bmp', '/tmp/tess_7uERUt'],
'output_filename_base': '/tmp/tess_7uERUt'}
These are the locals when the exception occured here: `/pytesseract/pytesseract.py(94)`
726         if mswindows:
1326                 child_exception = pickle.loads(data)
-> 1327                 raise child_exception
The source file '/home/shefuto/Pictures/jpgpytesseract.jpg' exists, so it appears it tries to access those temporary files when they're not created yet.
Basically what I want to achieve is to ask Tesseract to recognize only complete words included in my custom dictionary (lang: chi_sim), or to find the best match.
load_freq_dawg       F
it gives me `硝酸嘛庸喹瓢膏` which is not in the dictionary at all. The best match is supposed to be `硝酸咪康唑乳膏` which is included in the dictionary.
In particular, these two look like they might have promise:
Thank you, @amitdo and @tfmorris. I tried both `language_model_penalty_non_freq_dict_word` and `language_model_penalty_non_dict_word` but had no luck.
Keytext: `bb_it.data()->owner() == this:Error:Assert failed:in file colpartition.cpp, line 205`
(Mixing blobs/bboxes etc. for easier reading)
The specific bbox is
else
+        if (unique)
@vidiecan, if it is not possible to create a public demo image, maybe you can nevertheless provide a code patch which fixes the problem? Or is it possible to send the problematic image privately to one of the developers working an tesseract, so that he / she can fix the problem?
Potential problems:
Open question:
- There is a Tesseract data version used for the traineddata (shown by `tesseract -v`).
But the ocr is successful.
// Get the halftone mask directly from Leptonica.
+    // leptonica will throw and error and return null
Maybe I needed to turn that on when I built Leptonica. Still a questionable approach.
re: musings about whether or not leptonica should "spam stderr":
libtool: compile:  x86_64-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/training -I.. -g -Wall -Wno-uninitialized -O0 -DDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccmain -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/t                                                    esseract/api -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccutil -I/home/ra/MINGW-packages/mingw-                                                    w64-tesseract-ocr-git/src/tesseract/ccstruct -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/viewer                                                     -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/textord -I/home/ra/MINGW-packages/mingw-w64-tesserac                                                    t-ocr-git/src/tesseract/dict -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/classify -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/display -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/wordrec -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/cutil -I/home/ra/MINGW-packages/mi                                                    ngw-w64-tesseract-ocr-git/src/tesseract/vs2010/port -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/mingw64/include/le                                                    ptonica -march=x86-64 -mtune=generic -O2 -pipe -ggdb -Og -ggdb -Og -std=c++11 -MT pango_font_info.lo -MD -MP -MF .deps/p                                                    ango_font_info.Tpo -c /home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/pango_font_info.cpp  -D                                                    DLL_EXPORT -DPIC -o .libs/pango_font_info.o
libtool: compile:  x86_64-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/training -I.. -g -Wall -Wno-uninitialized -O0 -DDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccmain -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/t                                                    esseract/api -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccutil -I/home/ra/MINGW-packages/mingw-                                                    w64-tesseract-ocr-git/src/tesseract/ccstruct -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/viewer                                                     -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/textord -I/home/ra/MINGW-packages/mingw-w64-tesserac                                                    t-ocr-git/src/tesseract/dict -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/classify -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/display -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/wordrec -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/cutil -I/home/ra/MINGW-packages/mi                                                    ngw-w64-tesseract-ocr-git/src/tesseract/vs2010/port -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/mingw64/include/le                                                    ptonica -march=x86-64 -mtune=generic -O2 -pipe -ggdb -Og -ggdb -Og -std=c++11 -MT normstrngs.lo -MD -MP -MF .deps/normst                                                    rngs.Tpo -c /home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/normstrngs.cpp  -DDLL_EXPORT -DPI                                                    C -o .libs/normstrngs.o
In file included from C:/msys64/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/pango_font_inf                                                    o.cpp:36:0:
make[1]: *** [pango_font_info.lo] Error 1
libtool: compile:  x86_64-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/training -I.. -g -Wall -Wno-uninitialized -O0 -DDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccmain -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/t                                                    esseract/api -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccutil -I/home/ra/MINGW-packages/mingw-                                                    w64-tesseract-ocr-git/src/tesseract/ccstruct -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/viewer                                                     -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/textord -I/home/ra/MINGW-packages/mingw-w64-tesserac                                                    t-ocr-git/src/tesseract/dict -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/classify -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/display -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/wordrec -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/cutil -I/home/ra/MINGW-packages/mi                                                    ngw-w64-tesseract-ocr-git/src/tesseract/vs2010/port -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/mingw64/include/le                                                    ptonica -march=x86-64 -mtune=generic -O2 -pipe -ggdb -Og -ggdb -Og -std=c++11 -MT normstrngs.lo -MD -MP -MF .deps/normst                                                    rngs.Tpo -c /home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/normstrngs.cpp -o normstrngs.o >/                                                    dev/null 2>&1
Aborting...
Thanks.  But  in cygwin, The define of `__CYGWIN32__` is no longer used, replaced by `__CYGWIN__`
Excuse me, I had met a problem when I used the cmake
pkg_check_modules(Leptonica REQUIRED lept)       this package didn't found, How can I solved it?
ra@Shree MINGW64 ~/tesseract
make[1]: Entering directory '/home/ra/tesseract'
Making all in ccutil
make[2]: Entering directory '/home/ra/tesseract/ccutil'
make[3]: Entering directory '/home/ra/tesseract/ccutil'
depbase=`echo ambigs.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
ambigs.cpp:31:22: fatal error: strtok_r.h: No such file or directory
Makefile:572: recipe for target 'ambigs.lo' failed
make[3]: *** [ambigs.lo] Error 1
make[3]: Leaving directory '/home/ra/tesseract/ccutil'
make[2]: Leaving directory '/home/ra/tesseract/ccutil'
make[1]: Leaving directory '/home/ra/tesseract'
clig (contextual ligatures), and dlig (discretionary ligatures).
This feature requires Pango 1.38 or newer.
Hi Amit!
2) remove_reference -> remove_reference_Tesseract
Pei
Oh, yes zdenop.
tesseract -v
leptonica-1.73
[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
checking for leptonica... yes
I had to go to leptonica site, download the source and build it.
I have the same problem, while leptonica-1.74.1, mac OS 10.12.3 (16D32)
Warning: leptonica-1.74.1 already installed
![bowenpeak](https://cloud.githubusercontent.com/assets/17915164/13863515/410b1a02-ecff-11e5-9c93-f63825576e21.png)
![bowenpeak_lrg](https://cloud.githubusercontent.com/assets/17915164/13863517/47b6f010-ecff-11e5-91a0-7b2c7548f493.png)
In the man page for TESSERACT(1) under the title Languages the following items are misspelt.
tesseract-ocr
tesseract-ocr/tesseract
tesseract-ocr/tessdata
tesseract-ocr/langdata
tesseract-ocr/tessdata
(in addition to the source in tesseract-ocr/tesseract/tessdata)
$ cp ./tessdata/san.traineddata /usr/local/share/tessdata
$ export TESSDATA_PREFIX=/home/shree/tesseract-ocr
$ echo $TESSDATA_PREFIX
/home/shree/tesseract-ocr
$ echo $TESSDATA_PREFIX
Could not initialize tesseract.
Could not initialize tesseract.
/home/shree/tesseract-ocr/tessdata directory.
Thanks, @amitdo
if (tesseract_ == NULL ||
do {
if (it->Empty(RIL_PARA)) continue;
delete api;
Dumping objects ->
Hi have the saim problem but only in mfc project
c:\vanilly\dev\tesseract1\textord\oldbasel.cpp (39): PokeGuiManage.exe!`dynamic initializer for 'textord_oldbl_debug''() + 0x21 bytes
FC D5 D0 01    D0 D7 D0 01    88 D7 D0 01    74 D7 D0 01     ........ ....t...
EC D7 D0 01    48 D7 D0 01    74 E3 D0 01    54 E6 D0 01     ....H... t...T...
FC E9 D0 01    F0 EB D0 01    F8 EA D0 01    E0 EA D0 01     ........ ........
50 EA D0 01    CC EA D0 01    3C E9 D0 01    74 EB D0 01     P....... <...t...
10 EA D0 01    80 EC D0 01    34 EE D0 01    10 EE D0 01     ........ 4.......
BC FA D0 01    24 FB D0 01    84 FB D0 01    14 FE D0 01     ....$... ........
Are there any settings for Tesseract that are known to be computationally intensive?
any tricks to speed up Tesseract?
@ychtioui, as you have spent many years in machine vision, you know quite well that there are lots of ways why programs can be slow. Memory management is just one of them. Even with a lot of experience, I'd start running performance analyzers to investigate performance issues. Of course I can guess what might be possible reasons and try to improve the software based on that guesses, but improvements based on evidence (like the result of a performance analysis) are more efficient. Don't you think so, too? Do you have a chance to run a performance analysis?
thanks amitdo.
I'm using 3.02 but the C/C++ version of Tesseract.
Thanks - Anant.
@theraysmith
I'm interested in the same answer, @amitdo . Can you answer the question, @theraysmith ? It really can help us :)  Don't expect much difference between `-O2` and `-O3`. I tried different optimizations, and they only have small effects on the time needed for OCR of a page. Higher optimization levels can even result in slower code because the code gets larger (because of unfolding of loops), so CPU caches become less effective. It is much more important to write good code. The improvement by using `-fopenmp` is useful when you want "realtime" OCR – running OCR for a single page and waiting for the result. Then it is fast because it uses more than one CPU core for some time consuming parts of the OCR process.
Shouldn't the 'num_threads' lowered to 2 in that case? @theraysmith I want to train tesseract 4 for arabic language. theraysmith you mean that there is no way to speed up the training process?  i follow this step,
thnks tfmorris and zdenop for the reply, it's very helpful
And here is the link:**http://code.google.com/p/tesseract-ocr/downloads/list**
The recognition from Tesseract sucks. Generally the problem is dropped characters. It seems to randomly ignore perfectly good looking characters.
![badocr](https://cloud.githubusercontent.com/assets/353400/13625650/bb6524b6-e56e-11e5-9e43-39140ee796c3.png)
User@HP MINGW32 ~/tesseract-ocr
User@HP MINGW32 ~/tesseract-ocr
leptonica-1.73
_realname=tesseract-ocr
pkgbase=mingw-w64-${_realname}
pkgdesc="Tesseract OCR (mingw-w64)"
url="https://github.com/tesseract-ocr/tesseract"
makedepends=("${MINGW_PACKAGE_PREFIX}-gcc"
depends=(${MINGW_PACKAGE_PREFIX}-cairo
${MINGW_PACKAGE_PREFIX}-icu
${MINGW_PACKAGE_PREFIX}-leptonica
${MINGW_PACKAGE_PREFIX}-pango
${MINGW_PACKAGE_PREFIX}-zlib
${MINGW_PACKAGE_PREFIX}-tesseract-data-eng)
cd "${srcdir}/tesseract-${pkgver}"
cd "${srcdir}/tesseract-${pkgver}"
fi
--build=${MINGW_CHOST} \
--host=${MINGW_CHOST} \
--target=${MINGW_CHOST} \
--prefix=${MINGW_PREFIX} \
find $pkgdir/${MINGW_PREFIX}/share/tessdata -type f -exec chmod 0644 {} \;
ShreeDevi
I have built Leptonica 1.73 on msys2 locally. It is not yet reflected in
ShreeDevi
> rebuilding tesseract does not help unless leptonica instalation is not
ShreeDevi
Amit & Zdenko.
I was able to build and run 1.73 leptonica and the latest source of
ShreeDevi
> Real problem is that he has several installation of leptonica but msys
> instruct linker to use older leptonica version (which could be reasonable
after building leptonica, but did after building tesseract.
ShreeDevi
> Shree,
> cd path/to/leptonica-1.73
> cd path/to/tesseract-ocr
ShreeDevi
PLEASE HELP!!!
# tesseract_z_issue
- N conf: 91.517166
- M conf: 81.259239
Z and 2 characters are not expected, it makes me wonder if the character is rotated when analyzed.
leptonica-1.73
La mort a eu lieu
'nak.png' 8 entries colormap:
![nak](https://cloud.githubusercontent.com/assets/17527508/13379305/6e9dd8ec-de22-11e5-910c-1c89dd76594a.png)
$ tesseract -l fra nak.png stdout
La morte eu lieu
External workaround:
La mort a eu lieu
-- Bruno
Well two approaches from my point of view:
Leptonica is really, really good at image binarization. We should be making use of it.
@bruvi where exactly is the 0.25 R + 0.5 G + 0.25 B conversion happening?
tesseract -l fra /tmp/nak.png -
La mort a eu lieu
If we use "Leptonica" perceptual weightings, then it fails.
tesseract -l fra /tmp/nak.png -
La morte eu lieu
``` diff
+  Pix *tmp;
tesseract -l fra /tmp/nak.png -
La mort a eu lieu
I'm impressed by the accuracy of Tesseract, but the speed is a disaster!
i.e. original text In Arabic is
مرحبا
ابحرم
![test_ara](https://cloud.githubusercontent.com/assets/17473681/13320324/bc160e22-dbd0-11e5-8090-6f3728fcc06d.jpg)
أنحاء
ءاحنا
@amitdo
I try hard to make sure Arabic and other right-to-left languages work correctly in Tesseract PDF. As the problem is isolated further I'm happy to look, but I'm not aware of any reason things would have broken.
http://domasofan.spdns.eu/tesseract/
امهمه مني اهادم
ةييرعلا ةغللا
. هم دهج ةغل
ملاعلا ءاحنا يه هرنسم
مداها ينم همهما
اللغة العريية
لغة جهد مه
مسنره هي انحاء العالم
@amitdo Hebrew has the exact same problem as Arabic.
There are a number of issues relating to RTL and Arabic. Can they all be labelled with 'Arabic' for ease of finding, so that duplicate issues are not created.
https://github.com/tesseract-ocr/tesseract/issues?q=Arabic+in%3Atitle%2Cbody
ShreeDevi
hi, where can i get the arabic tessdata files?
https://github.com/tesseract-ocr/langdata/tree/master/ara (Version 3.04)
https://github.com/tesseract-ocr/tessdata
> hi, where can i get the arabic tessdata files?
The Arabic traineddata is based on cube engine and is the 3.02version.
> > hi, where can i get the arabic tessdata files?
See https://github.com/tesseract-ocr/tesseract/issues/40#issuecomment-263039665 The Adobe folks suggested a few things to try, none of which worked so far. Still open and (relatively) active. Please tell us which pdf viewer you already tested if any. @jbreiden  Here is a more thorough examination of "ara.pdf" [that you posted in your comment](https://github.com/tesseract-ocr/tesseract/issues/238#issuecomment-296256374)
1) Wrong sentence order:
![ara](https://cloud.githubusercontent.com/assets/16248376/25373915/1eb574ba-29a4-11e7-8c5d-5bb4d0d1480d.jpg)
2) Repetitive mistakes:
( لا ) is wrongly represented as ( ال ) , which is actually opposite to the correct spelling.
( ، ) is the Arabic Comma, is wrongly represented as ( ء ) or ( , ) or ( . ) or ( » )
( اً ) is represented by only ( ا ) , which is missing (  ً   )
some rare cases of multiple combined words, there are 2 separate cases ( مرحامستبشرا ) and( منالناس ) ,    should be ( مرحاً مستبشرا ) and ( من الناس )
3) Rare Case:
Note that in the Arabic language, the state of ( لا ) is frequently used, so-much that if this misrepresentation of it as ( ال ) is continued, it would degrade the recognition rate drastically.
The skewed version is not fine. The words appear in wrong order in each line.
( لا ) vs ( ال ) is a known issue. See https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-285633162 and the comments below it.  >some rare cases of multiple combined words
@Shreeshrii :
:rofl:  @amitdo funny joke :) I downloaded ara.pdf (EXPERIMENT) version and opened in Adobe Reader XI and Foxit Reader 8.1 under Windows 10 and copied and pasted the text in Notepad++ under Windows 10.
![ara-error](https://cloud.githubusercontent.com/assets/5095331/25424660/c1b7b85c-2a86-11e7-8006-8a4215d26812.png)
[ARA-ADOBE-XI.txt](https://github.com/tesseract-ocr/tesseract/files/957656/ARA-ADOBE-XI.txt)
@Shreeshrii ARA-FOXIT-8.1.txt is the most adequate one in terms of sentence organization.
Experiment:
You are using a simple reverse here. That's not good enough for bidi text.  I wonder what is improved ver. 3.04. more detail especially these list.
cadams@ganymede:~ $ tesseract 11002612_2_0183.jpg 11002612_2_0183 -l ara+fra
Segmentation fault: 11
Interestingly, this appears to depend on the order of the languages – using `-l ara` or `-l fra` alone avoids the crash but specifying both in either order will cause it to crash.
cadams@Ganymede:~ $ tesseract --version
leptonica-1.72
cadams@Ganymede:~ $ tesseract 11002612_2_0183.jpg 11002612_2_0183 -l ara+fra
Segmentation fault: 11
Does this mean,latin numbers should be recognized when I only use arabic as recognition language?
(lldb) bt
@Shreeshrii
Can you test it? (ara+other lang) --oem 0 and --oem 2 - both use the tesseract mode, so the problem is in that code.
Starting program: /usr/local/bin/tesseract test2.jpg test2-ara-fra --oem 0 -l ara+fra
86            if (!*p)
#2  0x00007fddaa5af495 in tesseract::Wordrec::program_editup (this=this@entry=0x27e1b70, textbase=textbase@entry=0x27e1b58 "test2-ara-fra", init_classifier=<optimized out>,
#3  0x00007fddaa4d6949 in tesseract::Tesseract::init_tesseract_internal (this=this@entry=0x27e1b70, arg0=arg0@entry=0x0, textbase=textbase@entry=0x27e1b58 "test2-ara-fra",
language=language@entry=0x27f7d38 "ara", oem=oem@entry=tesseract::OEM_TESSERACT_ONLY, configs=configs@entry=0x7fffca100e30, configs_size=configs_size@entry=0,
#4  0x00007fddaa4d7188 in tesseract::Tesseract::init_tesseract (this=0x27e1b70, arg0=arg0@entry=0x0, textbase=0x27e1b58 "test2-ara-fra", language=language@entry=0x7fffca101064 "ara+fra",
#5  0x00007fddaa4825ac in tesseract::TessBaseAPI::Init (this=this@entry=0x7fffca100c70, datapath=0x0, language=0x7fffca101064 "ara+fra", oem=tesseract::OEM_TESSERACT_ONLY,
[test1-fra-ara-lstm.txt](https://github.com/tesseract-ocr/tesseract/files/679669/test1-fra-ara-lstm.txt)
Extracting tessdata components from ara.traineddata
Wrote ara.config
Wrote ara.unicharset
Wrote ara.punc-dawg
Wrote ara.word-dawg
Wrote ara.number-dawg
Wrote ara.freq-dawg
Wrote ara.lstm
Wrote ara.lstm-punc-dawg
ShreeDevi
> It was also sufficient to specify -l ara in my test.
Segmentation fault: 11
I will attempt to write a test for streaming, and will work with you on TIFF. TIFF is historically tricky for two reasons. One is the duplicated functionality on the OpenCL path. Hard to synchronize and hard to test. I personally can't seem to run the OpenCL path at all without a segfault. Second, under win32 is it hard or impossible to pass a file descriptor between different DLLs. Which is awkward because the libtiff API prefers to work with file descriptors instead of file pointers.
Some random, possibly relevant, tidbits:
tried my best to repress the memories.
``` diff
-  if (format == IFF_UNKNOWN) {
Hello TMorris,
See github.com/danbloomberg/leptonica.
@tfmorris
- do the OCR
'beta' to try?
> leptonica 1.74 release?
> Tesseract master is now broken with master leptonica because of changed
(corresponding to 0) or a pixa struct (which corresponds to 1).  I'll try
> cppan.yml#L137
> Leptonica (using conditional compilation)? I'd prefer such a solution, at
I believe this is an unusual situation where a leptonica interface that
tesseract uses has been changed.
> Leptonica 1.74.
version number* (which is different from the leptonica release number) with
> <https://github.com/notifications/unsubscribe-auth/AP6mLHznAbmXo5UwOhuUdFnN5qn1DQxCks5rB0y5gaJpZM4HeMNo>
>> Yes, this seems ABI breakage. Both tesseract and leptonica do not use
>> <https://github.com/notifications/unsubscribe-auth/AP6mLHznAbmXo5UwOhuUdFnN5qn1DQxCks5rB0y5gaJpZM4HeMNo>
Leptonica has a method called `pixaReadMultipageTiff `, would that need to be used instead?
this project support persian language ?
how can i help for support persian ?
you can find it at ​https://github.com/roozgar/PersianOcr
@amitdo is there any document about futures of new engine?!
- only generate word `dir` attributes which don't match enclosing paragraph
/usr/share/tesseract-ocr/tessdata
Could not initialize tesseract.
Oh, that's strange, because I later figured out the `export` thing, and I did `export TESSDATA_PREFIX=/usr/share/tesseract-ocr/tessdata`, and it did work. Actually, it works both with and without `/tessdata`
Here is the list of files of tesseract-ocr-eng
https://packages.debian.org/sid/all/tesseract-ocr-eng/filelist
checking for g++... g++
checking for mbstate_t... yes
OR the error message needs to be more precise about how to get `leptonica`
PEBCAK
You need the development package, which seems to be libleptonica-dev
Yep, but the message says "leptonica not found", it should say "libleptonica-dev not found".
How am I supposed to guess that "leptonica" means libleptonica-dev?
PEBCAK, but whose chair and keyboard?
configure: error: leptonica library missing
# apt-get install libleptonica-dev
libleptonica-dev is already the newest version.
leptonica-1.70
Ananth Got it! Many Thanks. So is OpenCV my best option? What about other deep learning frameworks such as TensorFlow?
Ananth  Hello,
Hi jbreiden,
@egorpugin: OK.
@egorpugin - Are the windows binaries at
Thanks for clarifying, @egorpugin .
@egorpugin I follow the instructions.
However CPPAN returns
i research google but there is no answer for this error....
Tony
@amitdo, thanks, pulled. :-)
This might be caused by the Leptonica code used for Tesseract: it tries to create a temp file in c:\ and fails because you don't have write permission there. So it should work if you run Tesseract as admin or if you change the permissions for c:.
Hi tonym1995,
Erwin
@bantilan your blog entry should be in the project's wiki!
uhu
The homepage of Leptonica is here:
http://www.leptonica.org/
https://github.com/DanBloomberg/leptonica
(lldb) bt
frame #1: 0x000000010000b21c libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPagesInternal(this=0x00007fff5fbff598, filename="test.CutiveMono.exp0.tif", retry_config=0x0000000000000000, timeout_millisec=0, renderer=0x0000000000000010) + 732 at baseapi.cpp:1166
(lldb) bt
frame #8: 0x000000010000afec libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPagesMultipageTiff(this=0x00007fff5fbff688, data="II*", size=1982406, filename="test.CutiveMono.exp0.tif", retry_config=0x0000000000000000, timeout_millisec=0, renderer=<unavailable>, tessedit_page_number=-1) + 284 at baseapi.cpp:1056
frame #9: 0x000000010000b41d libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPagesInternal(this=0x00007fff5fbff688, filename="test.CutiveMono.exp0.tif", retry_config=0x0000000000000000, timeout_millisec=<unavailable>, renderer=0x0000000102845980) + 877 at baseapi.cpp:1174
0x10019d160 <+32>: je     0x10019d17d               ; <+61>
(lldb) bt
0x100b7435e <+31>: je     0x100b74369               ; <+42>
(lldb) bt
My very crude workaround for now:
``` diff
--- a/training/pango_font_info.cpp
+++ b/training/pango_font_info.cpp
-    PangoGlyph dotted_circle_glyph;
+    // PangoGlyph dotted_circle_glyph;
PangoFont* font = run->item->analysis.font;
-        reinterpret_cast<PangoFcFont*>(font), kDottedCircleGlyph);
+    //     reinterpret_cast<PangoFcFont*>(font), kDottedCircleGlyph);
PangoFontDescription* desc = pango_font_describe(font);
const bool unknown_glyph =
PANGO_GLYPH_UNKNOWN_FLAG);
-        const bool illegal_glyph =
+        const bool illegal_glyph = false;
bad_glyph = unknown_glyph || illegal_glyph;
@amitdo
I tried bellow.
Abort trap: 6
ex. dejavu font (maybe not regular style,  [detail](https://gist.github.com/atuyosi/bc5387a4941e5d963365))
Segmentation fault: 11
HI @amitdo , my font lis is here.
@amitdo
Segmentation fault: 11
0x100b9835e <+31>: je     0x100b98369               ; <+42>
(lldb) bt
Hi @amitdo,
Segmentation fault: 11
(lldb) run --text=eng.training.txt --outputbase=eng.TimesNewRomanBold.exp0 --font='Times New Roman, Bold' --fonts_dir=/Library/Fonts --tlog_level=3
0x100c7e374:  je     0x100c7e37f               ; pango_fc_font_get_glyph + 42
@amitdo
$ uname -a
leptonica-1.73
lrwxr-xr-x  1 atuyosi  admin  49  8 11 01:55 /usr/local/bin/text2image -> ../Cellar/tesseract/HEAD-5610738_2/bin/text2image
![eng timesnewromanbold exp0](https://cloud.githubusercontent.com/assets/211086/17563850/251fd3c0-5f6c-11e6-8ec2-fe8a97fe57ca.png)
**Font Aldhabi failed with 62 hits = 21.60%**
"WenQuanYi Zen Hei Medium" \
"WenQuanYi Zen Hei Mono Medium" \
"WenQuanYi Zen Hei Sharp Medium" \
--fonts_dir  /usr/share/fonts/truetype/dejavu/ \
DejaVu Sans Mono : 6694 hits = 100.00%, raw = 112 = 100.00%
--fonts_dir  /usr/share/fonts/truetype/dejavu/ \
DejaVu Sans Mono : 6694 hits = 100.00%, raw = 112 = 100.00%
eg. following command which tries to render hindi txt in devanagari script using regular latin script fonts. Since numbers and punctuation are same, it shows coverage of about 18%
--text ../langdata/hin/hin.training_text \
--outputbase ../langdata/hin/hin
Using `$ text2image --list_available_fonts --fonts_dir=/Library/Fonts` does give the font I want `Lucida Grande`
[1]    72778 segmentation fault  text2image --text=eng.training_text --outputbase=eng.LucidaGrande.exp0
I don't know how to get more error info to you? Please help. @amitdo Could it be that some required commit fixing text2image has not been backported for 3.05?
@Tjorriemorrie Did you build tesseract from source? Please also try with the 4.0 alpha version (latest source from github), if the same error is there?  Ray did some changes in 4.00 that made this problem reappear. These changes were also backported to 3.05.
Maybe there is some way to add some parameter to let tesseract know where leptonica is located in execution phase?
See also tesseract-ocr/langdata#23.
@amitdo Ah, sorry about that - wasn't sure how to re-trigger it and couldn't turn up anything searching.
See also tesseract-ocr/langdata#23.
It is unclear to me if this is an tesseract issue or an hocr2pdf issue, of course.
@zdenop please close this
tesseract version
tesseract 3.04.00
leptonica-1.72
The PostScript content stream for this page as generated by Tesseract for the first word, "The" appears as follows:
Tz [ <0054><0068><0065> ] TJ
Tesseract
Acrobat
So it appears that Tesseract's method of encoding text strings is nonstandard. I checked the PDF 1.7 reference manual, and couldn't find an example matching Tesseract's output syntax.
Okay, for some reason pdftotext will not output to stdout but will produce a valid text file for the files we've been working on. My quick guess is that pdftotext suppresses its stdout if high ASCII characters are present, which tesseract finds here (some n-dashes and smart quotes). Both poppler 0.24.5 and 0.34 behave as expected when asked to save to a file, so the text stream is accessible to pdftotext. In short, poppler is working fine for me.
[linn_hocr_unc.pdf](https://github.com/tesseract-ocr/tesseract/files/77885/linn_hocr_unc.pdf)
https://github.com/behdad/tofudetector/blob/master/tofu.ttf?raw=true
> @behdad, try this:
So for your immediate problem, go ahead and substitute in Behdad's font into tessdata/pdf.ttf and you should be okay. We won't do that officially without a whole bunch more compatibility testing and reports, including the harder languages (Cherokee, vertical Japanese, Arabic) and additional renderers including Ghostscript and Firefox. Compatibility reports are appreciated.
https://github.com/behdad/tofudetector/blob/master/tofu.ttf?raw=true
- Reduce advance with in Behdad's font.
[behdad.pdf](https://github.com/tesseract-ocr/tesseract/files/112823/simple-1.pdf)
--- tofu.ttx    2016-02-01 10:17:15.038213397 -0800
+++ behdad.ttx  2016-02-01 10:43:29.839794297 -0800
<loca>
[behdad2.pdf](https://github.com/tesseract-ocr/tesseract/files/112840/simple-1.pdf)
tofu.ttf - alternate font from behdad
behdad.ttf -  with advance width reduced
behdad2.ttf - with contour removed
In progress testing compatibility with candidates "sharp2" and "behdad" including getting some assistance with ghostscript. So far no user visible differences between them, and the former is the smaller change. Is there general consensus to work around the Apple compatibility problem, at the expense of Evince highlight aesthetics?
@bekirserifoglu - Is the failure case on Kindle broken search and broken copy-paste? Or is it even worse than that?
@theraysmith
of different size.
In a next step, the Tesseract data types can be eliminated by replacing
versions), so local definitions are needed there.~~
Ping? I suggest to apply this patch now, wait one more month and then replace all Tesseract integer types by the POSIX types.
@theraysmith, @zdenop, do you have any comments to my last proposal? Can we proceed like that?
Ping?
@theraysmith, may I kindly ask you to give your consent? Woohoo! 🎉
Do you care for comments after modified code? Replacing data types or NULL is easy, but the replacements are a little bit longer, and moving the comments to the right column means much hand work without code formatter.  When I run "tesseract -c hocr_font_info=T hocr"  on attached file the segmentation fault is received. Output file is empty.
ra
ka
ar
un
ob
`evince` (my standard PDF viewer on Linux) has the same problem and is not able to search such PDFs. The PDF viewer of `iceweasel` / `Firefox` gets the words right, so it is possible to search 'Infrarotkamera', but not the lines, so searching for word combinations does not work.
People keep implying to use Cube for training Arabic, but I think no one really knows how to use Cube for training, and yes I have read the tesseract extra Cube documentation, and it seems that they purposely don't want anyone to use Cube.
I have just used the "wordlist2dawg -r 1" that you suggested and it's has solved my "reversed words" problem.
To use "wordlist2dawg.exe -r 1" to create the "freaquent_words_list" + "words_list"
To use "ara.config" and removing this line from it "tessedit_ocr_engine_mode 1"
This solved my 2 problems of Arabic Language reversed words, and Arabic Language combined word.
roozgar, I will conduct some tests and will reply back after couple of days
if you need i can help you by providing Arabic words list or some scanned page
just send me an email: roozgar@gmail.com
Thank you roozgar, I appreciate you
I have tested tesseract 3.02+3.04+3.05dev all have failed in arabic ocr.
the official train data for arabic is working really good on 'times' font
@amitdo Oops! i found this
https://code.google.com/archive/p/tesseract-ocr-extradocs/wikis/Cube.wiki
its really undocumented!!
but how they build current Arabic file!!
@amitdo who are they? i there any way to find who build each trained file?
hey christopher, can you please tell me how you created your own .traineddata file for arabic or send me a link that contains a tutorial that i can use to follow.
I have been trying to implemented Tresseract ara.traineddata file but for some reason, the app that i have made using android studio gets stuck
Hi @areebakamil  I have replyed by email also here is the Tutorial that you requested.
Please remember this is for the Arabic Language, the recognition rate is low to moderate.
Arabic use ara
Urdu use urd
@Shreeshrii
Isolated: **(ك)**
Medial: "Shift j or ت" , then press (ك), then "Shift j or ت" , **result is ( ـكـ )**
can you please provide me any version of tesseract-ocr which supports "Arabic " Language ,
I am tried with tesseract-ocr3.02 version ,
if any upgade  or downgrade versions supports "Arabic " language
10x Hi Uri !
1) 'Tessseract' ?
>For right-to-left languages (RTL) use option "-r 1".
I am also having problems with tesseract OCR for arabic and i need your help.
Can you please send me a trained data file for arabic language for tesseract 3.0.2?
My email is adinetoiu@yahoo.com.
Adrian
Raja
#### the errors
Making all in tessdata
make[3]: Nothing to be done for `all-am'.
@amitdo  Thanks for replying! but when i run (sudo make install) get the error
Password:
Making install in ccutil
Making install in cutil
@amitdo last, i install it with brew.thanks any way
The man page for the unicharambigs file format only includes documentation on the v1 format, not the v2 format (and is missing a description of the first line which is used for version identification).
https://github.com/tesseract-ocr/tesseract/blob/master/doc/unicharambigs.5.asc
https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#the-unicharambigs-file
I understand from it unicharambigs file could be either in v1 format or v2
Which file use unicharambigs file v2?
languages.
@amitdo: that was intentional, so more pull requests can follow.
Ah, on a 2nd view I now see the typo.
""巴
1. one that gives incorrect results (ex_bad.tif)
Wojtek
in several aspects, but also introduced new inconsistencies which this
@amitdo, I'm sorry, my commit text was not precise. Some of the issues which my patch tries to address existed before your patch. Should I update the patch with a modified commit message?
'list-langs' can be followed by 'tessdata-dir'.
I'm not really sure what is the right usage for 'print-parameters'.
tessedit_pageseg_mode   6
tessedit_pageseg_mode   6
tessedit_pageseg_mode   6
@amitdo, I think it is reasonable to split the options in two groups: one group for those options which are used in production to make OCR, one group for options which show information like help texts, version or supported parameters. The old help text called the 2nd ones 'single options', that's why my patch reverted to that title. Maybe there exists a better naming.
@zdenop, I knew that, of course.
> tessedit_pageseg_mode 1
> tessedit_pageseg_mode   1
Strangly, this works right now
> tessedit_pageseg_mode   1
These information are not words or sentences, and looks like tesseract is trying to give sense or forcing the info to all letters or to all numbers (if preceding a number force to a number).
bios.jpg:
bios-resize300.jpg:
dimm.jpg:
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
A08
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
A08
dimm.jpg
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
dimm.jpg
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
CDTLGBZ
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
CDTLGBZ
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
M BPH 63260 6 3.30912
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
W CPLJ 83260 @ 3.30GHZ
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
F0 CPH 83260 @ 3.306HZ
Ila mnpmm "mm npanHM Mama m m: m: m :3 mm mm. Ms M:
% locale -a | grep bg
% pacman -Qs tesseract-data-bul
Suggestion: using `-lbul` should fail with an error
Also try the option -psm 7
https://groups.google.com/forum/?hl=en#!forum/tesseract-ocr
The command tesseract seems to miss the decimal separator character if there is more than 7 digits in the decimal number :
In the image below, tesseract detects 34056789 = not OK !
For function parameters, this is different. Therefore they are still supported.
ه 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ه [647 ]
ن 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ن [646 ]
خ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # خ [62e ]
س 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # س [633 ]
ع 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ع [639 ]
ض 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ض [636 ]
Reading fas.BMitra.exp0.tr ...
Bad properties for index 3, char و: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 4, char ه: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 5, char ک: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 6, char ن: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 7, char ی: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 8, char ا: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 9, char خ: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 10, char س: 0,255 0,255 0,0 0,0 0,0
local outfile=${TRAINING_DIR}/unicharset
mv ${outfile} ${UNICHARSET_FILE}
@mustafashujaie - Which langdata are you using?
@Wikinaut Most of those warnings also occur in my builds and are less interesting (like -Wsign-compare which can be ignored IMHO), but there are also some warnings which need further investigations (-Warray-bounds).
<span class="ocrx_word" dir="ltr" id="word_1_26" lang="eng" title=
> Problematic frame:
> Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)
@zdenop, FYI
@zdenop
@stweil, @zdenop
@zdenop Please, commit or comment.
@amitdo, I'm afraid that your patch needs to be rebased on latest git master. One of my patches fixed a bug in main and was committed. This fix is still missing in your code, so there will be a merge conflict.
@zdenop, I've updated the code. Is it OK for you now?
@amitdo, I'afraid that the new function SetVariablesFromCLArgs did revert the bug fix #154.
--list-langs  list available languages for tesseract engine.
pagesegmode values are:
So, what do you mean by 'whole help'?
[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
![skewedopenclodddims](https://cloud.githubusercontent.com/assets/394707/11664500/25f7c0ba-9db0-11e5-8269-5b6f83f67c20.png)
Anything else that can be done to help debug? I have a vested interest in getting a working OpenCL build before the end of January...
Separate experiment, swap:
I have downloaded the sources and written the samples codes, just change the language 'eng' to 'chi_sim'. The traindata 'chi_sim' has been copied to \tessdata directory same with eng.traindata.
[DS] Selected Device[1]: "Capeverde" (OpenCL)
one strange issue is that the first time tesseract is run and benchmarks the available devices (creating  tesseract_opencl_profile_devices.dat ) , it segfault, the  tesseract_opencl_profile_devices.dat does gets done and the next time it runs fine.
Something went wrong, bailing out!
Does the autogen have to use tesseract? If so, I will firstly install it.
unpack it under mac os 10.10,
1. cd to tesserac-ocr
4. change ibtoolize to glibtoolize
6. error for subdir-objects
Written by Gordon Matzigkeit, 1996
- aclocal
aclocal --version
aclocal (GNU automake) 1.15
- automake
## error
- autogen
Running aclocal
glibtoolize: copying file 'm4/ltsugar.m4'
glibtoolize: copying file 'm4/lt~obsolete.m4'
Something went wrong, bailing out!
error LNK2019: unresolved external symbol "public: void __cdecl tesseract::TessBaseAPI::SetImage(struct Pix const *)" (?SetImage@TessBaseAPI@tesseract@@QEAAXPEBUPix@@@Z) referenced in function main
Hello, peirick.
zdenop,
Maybe have a look at the repository at https://github.com/peirick/leptonica you will find a build_tesseract.bat.
Yes, it seems it is producing. Just curious - what is the issue with the JPEG though?
Or a method "git submodule" which automatically clones (or pulls) all languages from https://github.com/tesseract-ocr/tessdata .
Written in the WIKI
https://code.google.com/p/tesseract-ocr/downloads/list
tesseract-ocr-setup-3.02.02.exe
http://domasofan.spdns.eu/tesseract/
@amitdo, that's interesting, but it still does not include an installer as far as I see.
Regarding leptonica, you can start with https://github.com/stweil/leptonica until there is an official GitHub version.
It happened with custom training
"Error: Illegal min or max specification!
I just tested with the stock tesseract 3.03 on a brand new Debian 8 installation with the locale set to fr_FR.UTF-8 and everything worked perfectly.
uname -a
tesseract -v
locale
D/CrashAnrDetector(  656):     #02  pc 000b81b1  /data/app-lib/__APPNAME__/libtess.so
@egorpugin Why is a rebase needed? I don't see any conflict with the current sources. The build failure doesn't appear to be due to the code, but instead instability in the CI.
I have done some training and created my own combined language file. When using my custom language I get error code 5000
Abort trap: 6
Caleb
@olcc, the way to produce PDF has significantly changed in Tesseract 8.04. So I have a plan to change this in future commits. I'll take your idea into consideration. But as I remeber the new implementation does not produce the text anymore. It outputs directly to the file. But even with such effort you are able read the file manually and modify as you wish.
@olcc we here fully rely on these "mixed-mode" PDFs as generated by
`tesseract OCR.tif ORIGINAL pdf`
@zdenop, is this functionality documented anywhere?
decompress/compress whenever we can.  Sometimes that is impossible (TIFF
is an enormously flexible graphics format) and sometimes we haven't quite
this code path in Tesseract / Leptonica. All relevant Tesseract code is in
for me it helps often to upscale a image.
Change is in Ray's hands and will eventually migrate here. The person in critical need has a copy.
configure.ac should have an option to activate OpenMP in tesseract code (maybe with AC_OpenMP?).
configure: error: conditional "OPENMP" was never defined.
@ryanfb, @zdenop
For those of us who know nothing of C, might someone be kind enough to use EMScripten/asm.js to compile to JavaScript on our behalf for use in the browser (without Node.js, etc.)?  Would no doubt be quite slow but would be handy for some web apps...  The other existing ports (Ocrad and GOCR) do not seem to hold a candle to the quality of Tesseract. Thanks!
https://github.com/naptha
Here's my usage of the Tesseract library
The only non-standard thing I do (I think) is turn on this option: tesseract.SetVariable("save_blob_choices", "T"); and read all the various possibilities.
export LIBLEPT_HEADERSDIR=/storage/projects/alpr/libraries/leptonica-1.72/src/
./configure --with-extra-libraries=/storage/projects/alpr/libraries/leptonica-1.72/src/.libs/
we're unfamiliar outside of tesseract beyond emgu and our examples... if
'debug_file' in tesseract
> we're unfamiliar outside of tesseract beyond emgu and our examples... if
> <https://github.com/notifications/unsubscribe-auth/AK63Kod4YKZjkCqrMXbSvV7TvNuzJ_f1ks5s687WgaJpZM4FkMdm>
> <https://github.com/notifications/unsubscribe-auth/AK63Kod4YKZjkCqrMXbSvV7TvNuzJ_f1ks5s687WgaJpZM4FkMdm>
It seems that any OpenCL operation on my OS X Yosemite machine triggers attempts to allocate extremely large memory blocks and allocation failures.
The size of the attempted allocation is 1125865547108352 bytes or in hex, 0x3fff800001000, which looks special.
[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
List of available languages (2):
osd
List of available languages (2):
osd
[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
## Versions
leptonica-1.71
Version: OpenCL 1.2 (May 10 2015 19:38:45).
I'd be happy to investigate further if someone can point me in the right direction.
convert -density 300 aesopsfables00mclo_bw.pdf -type Grayscale -compress lzw -background white +matte -depth 32 page_%05d.tif
leptonica-1.74.1
Found AVX
But I´m trying to run mftraining and I´m getting this error:
(gdb)
Thanks, @zdenop
(gdb)
@vzani: the critical part is entering the command "backtrace" after the segmentation fault.
In file included from ./blamer.h:27:
Target: x86_64-unknown-freebsd10.3
Thread model: posix
Target: x86_64-unknown-freebsd11.0
Thread model: posix
In file included from ./blamer.h:27:
`tesseract eng.Arial.exp0.tif eng.Arial.exp0 box.train`
common.punc
`uname -a`
Codename:   vivid`
> find /usr -name "tesseract"
@aiwaz, could you try this command:
Type "apropos word" to search for commands related to "word"...
(gdb)
tesseract ult.dejavu.exp0.tif ult txt hocr
Failed loading language 'osd'
Why it wants to load the "osd" language?
drwxrwxr-x 2 azukausk azukausk     4096 Jan 27 13:49 configs
-rw-rw-r-- 1 azukausk azukausk 21876550 Jan 25 15:41 eng.traineddata
-rw-r--r-- 1 azukausk azukausk      568 Jan 27 13:49 pdf.ttf
drwxrwxr-x 2 azukausk azukausk     4096 Jan 27 13:49 tessconfigs
-rw-rw-r-- 1 azukausk azukausk     1649 Jan 25 15:56 training_text
-rw-rw-r-- 1 azukausk azukausk    38706 Jan 27 12:53 ult.dejavu.exp0.box
-rw-rw-r-- 1 azukausk azukausk    39984 Jan 27 12:53 ult.dejavu.exp0.tif
-rw-rw-r-- 1 azukausk azukausk    36383 Jan 28 12:03 ult.hocr
-rw-rw-r-- 1 azukausk azukausk     1685 Jan 28 12:03 ult.txt
TESSDATA_PREFIX=/home/azukausk/tessbin/share/tessdata
echo $TESSDATA_PREFIX
/home/azukausk/tessbin/share/tessdata
tesseract ult.dejavu.exp0.tif ult txt hocr
Failed loading language 'osd'
$ tesseract testing\eurotext.tif testing\eurotext -l eng+deu pdf
adobe reader shows an error that it is corrupted.
leptonica-1.72
tesseract 3.04.00
leptonica-1.72
$  tesseract eurotext.tif eurotext -l eng+deu pdf
-rw-r--r-- 1 marco Administrators 13K Jul 26 21:36 eurotext.pdf
leptonica-1.72
Error in pixRead: image file not found: /tmp/leptonica/847980_4108_mem.gif
different runtimes. If so, we may be in trouble.
Or... do we still have some ifdefs in the code to do Windows streaming I/O a little differently? I vaguely remember writing some back in the day. Maybe they are misbehaving under Cygwin? Can't seem to find them at the moment.
for cygwin.
ShreeDevi
> Maybe they are misbehaving under Cygwin? Can't seem to find them at the
ra@Shree ~/tesseract-ocr
ra@Shree ~/tesseract-ocr
ra@Shree ~/tesseract-ocr
ra@Shree ~/tesseract-ocr
List of available languages (2):
osd
ra@Shree ~/tesseract-ocr
tesseract 3.04.00
leptonica-1.72
ra@Shree ~/tesseract-ocr/testing
-rw----r-- 1 ra ra   7712 Jul 29 11:47 phototest.tif.pdf
-rw----r-- 1 ra ra    287 Jul 29 11:48 phototest.tif.txt
![helloworld](https://cloud.githubusercontent.com/assets/11964590/18092293/6a92bfd8-6e91-11e6-8c27-2e66a0da3114.gif)
leptonica-1.73
If I was a guessing man I would say maybe it is in the temporary file name /tmp/199506_720_mem.gif likely not conforming to MS windows.
> [image: helloworld]
Subject: Re: [tesseract-ocr/tesseract] corrupt pdf output on cygwin (#63)
> [image: helloworld]
Subject: Re: [tesseract-ocr/tesseract] corrupt pdf output on cygwin (#63)
other cygwin users.
-I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
-DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
oxchar.o
-I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
-DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
-I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
-DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
-I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
-DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
-I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
-DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
-I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
-DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
-I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
-DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
-I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
-DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
tDescription(const PangoFontDescription_)':
make[1]: *_\* [pango_font_info.lo] Error 1
-I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
-DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
tDescription(const PangoFontDescription_)':
make[1]: *_\* [pango_font_info.lo] Error 1
-DPANGO_ENABLE_EN
r/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0
0 -I/usr/lib/glib-2.0/include  -I/usr/include/cairo
roperties.o set_unicharset_properties.cpp &&\
../api/libtesse
ract.la -lws2_32  -llept
set_unichar
set_properties.exe set_unicharset_properties.o
../api/.libs/libtesseract.a -lws2
-licuin
Follow me on Twitter: http://www.twitter.com/domasofan/
Jabber: domasofan@andrelouis.com
yeah its icui18n.
there seem to be 2 versions.
simon
> I think that the problem is that the library is named 'libicui18n' under Cygwin, as it is on Linux etc.
Follow me on Twitter: http://www.twitter.com/domasofan/
Jabber: domasofan@andrelouis.com
ambiguous_words.exe
dawg2wordlist.exe
set_unicharset_properties.exe
unicharset_extractor.exe
wordlist2dawg.exe
simon
Follow me on Twitter: http://www.twitter.com/domasofan/
Jabber: domasofan@andrelouis.com
Follow me on Twitter: http://www.twitter.com/domasofan/
Jabber: domasofan@andrelouis.com
the solution is wrong. As strcasestr is not standard,  it is enough to
tesseract 3.02.02
leptonica-1.71
and relogin.
but the error still there:
Unsupported image type.
i have tried leptonica-1.71/1.72 ,  both have same error.
should i use early leptonica ,   which version of leptonica  is compatible ？
at baseapi.cpp:1222
at baseapi.cpp:1176
at baseapi.cpp:1074
==11666==
==11666== Invalid read of size 8
==11666==
==11666==
==11666==  Access not within mapped region at address 0x8
``` diff
gdb api/.libs/lt-tesseract
at baseapi.cpp:299
still trouble
Variables are:
#define BURSTS_PER_WORD (PIXELS_PER_WORD/PIXELS_PER_BURST)
I can't get fully worked OpenCL configuration. But I have a much different environment (without any other dependencies except leptonica). I've got errors like:
OCRLib.Win32.lib(adaptmatch.obj) : error LNK2001: unresolved external symbol "public: virtual int __thiscall tesseract::ShapeClassifier::UnicharClassifySample(class tesseract::TrainingSample const &,struct Pix ,int,int,class GenericVector&lt;class tesseract::UnicharRating&gt; )" (?UnicharClassifySample@ShapeClassifier@tesseract@@UAEHABVTrainingSample@2@PAUPix@@HHPAV?$GenericVector@VUnicharRating@tesseract@@@@@Z)
The error is:
tesseract -v
leptonica-1.72
"autoconf",
"libhighgui-dev",
"libtesseract-dev",
"libleptonica-dev",
"imagemagick"
I am using tesseract-3.04.00 and for leptonica i tried both with 1.72 & 1.71.Still i get the below mentioned issue:-
Yes, how did you solve it @Sayanava ?
It seems that it happens with eng locale as well as with the rus loc.
@zdenop Since Cube is going away, perhaps this can be closed?
Somehow I got the feeling that Cube was purposely sabotaged and hindered from the public.
interested in trying the hindi and other indian languages traineddata.
> AL056Ti1gWSSG6BfuBbL68EE7RYfsItOks5rC0xWgaJpZM4FOBFi>
There is an Old High German (similar to Old English), but the German translation of the New Testament by Martin Luther (1521) was one of the first major printed books in German, and basically it started the modern German language (High German) which is used until today. > Stefan, please share the binaries for 4.0 alpha for Windows.
>Amit. Please add the info to the wiki also, if you have not already done so.
From a user point of view, better accuracy maybe preferred to speed. So LSTM based engine seems the way to go, at least for devanagari scripts. I will test some of the other Indian languages later.
@theraysmith
Adding config files to trained data for san, mar and nep will fix this
scripts are used quite commonly with Devanagari script text.
There are various other Devanagari related options in the config file,
Sad news: Cube is no longer with us.
Cube, you will be missed...
@amitdo Not sure if that will work for Devanagari, because of the length of unicode string.
archive: https://web.archive.org/web/20160201190446/http://teksty.klf.uw.edu.pl/12/1/alice_1.png.hocr.tsv
> http://teksty.klf.uw.edu.pl/12/1/alice_1.png.hocr.tsv
> https://web.archive.org/web/20160201190446/http://teksty.klf.uw.edu.pl/12/1/alice_1.png.hocr.tsv
Cons:
scripts :-)
ShreeDevi
>   scripts
> Cons:
>   complexity)
Just glanced at the code and wondered why on Earth multiplication and division is being done in every iteration, especially on inner, nested loops. Look at this:
PIXELS_PER_BURST*NUM_CHANNELS)/CHAR_VEC_WIDTH
@zdenop, please close this PR.  @orbitcowboy,
@amitdo, I suggest to apply this PR.
