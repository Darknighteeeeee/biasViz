  @disksing PTAL @coocood PTAL LGTM  LGTM
@yuanwhy Thanks for your PR! LGTM  Added syntax like select /*+ TIDB_SMJ(t1, t2) */ ... which indicates within this select block, t1,t2 will be joining with merge join; if needed, a sort will be appended in case of no order provided by child operators. The hint matching only matches table name and alias like in MySQL.

It will try to generate different plans according to join keys. Say a = b and c = d it will try both merge on a/b (ASC or DESC), c/d (ASC or DESC) and pick a plan with lowest cost along side other operator cost evaluation.
The merge join operator itself do a streamline iteration caching same key rows for both sides for look-back cross product. If a single key count is larger than memory size, it then will OOM. 

On presence of merge hint, join reorder will be turned off. @ilovesoup 
Your git config should set the same email as github.  LGTM @mtunique Good Job!
@coocood @tiancaiamao PTAL LGTM  @arthuryangcs Thanks for your PR! Please address the comments and resolve the conflict. LGTM
@arthuryangcs Please resolve the conflicts.  @silenceper Thanks for your PR!
Could you add an unit test？ LGTM @silenceper Thanks!
@coocood @tiancaiamao @zimulala PTAL  LGTM LGTM  @arthuryangcs 
There is another PR implements PI already.
Can you try to implement another one?  LGTM
Good Job! LGTM  LGTM LGTM Please fix conflicting.  LGTM
Thank you for your PR!  LGTM
Thank you for your PR! Sorry for the delay, there are many PRs conflicting on typeinfer files.
Merging each one makes other PRs conflicting, so we have to queue the PRs.
 when this PR is ready to merge, we will notify you to resolve conflicts.  Please fix CI.  @framlog Thanks for your PR!
Please sign the CLA. LGTM
Good job! @framlog Feel free to send us a PR to make sqrt() better. :)  Thanks @zzl0 

Now we must use `golang.org/x/net/context` uniformly, like our other projects do.
Using standard `context` seems to be caused by auto package import here,  /cc @shenli   Good idea!  @biolee Thanks for your PR!
Please add some unit test.  @maxwell92 please sign the CLA. LGTM Thank you @maxwell92   @zcfrank1st What is `occ`? OCC: Optimistic concurrency control. @shenli 

TiDB is designed for large database (more than thousands of millions of rows) and conflict is rare.
You may need to queue transactions if the contention is really high. @zcfrank1st   @neoguojing 
Thank you for your report anyway!
 @neoguojing Could you show me the result of `tidb-server -V`? @neoguojing We will fix this soon. @neoguojing Please try the latest master.  @snail2swift Thanks for your feedback!
How many rows are there in t1?
Is there any error when you run `Delete from t1 where date='2017-02-06`?
DDL statement will run in sequence, so the statement may be waiting for the previous statement to finish. @snail2swift 
You can try the branch in the [PR](https://github.com/pingcap/tidb/pull/2786) . @snail2swift 
1. TiDB use a batch way (1024 rows per batch) to build index for existing. So 160 million rows will take some time.
2. The PR mentioned by zimulala will fix " Information schema is changed." error.
3. In the current implementation of TiDB, we only allow one active DDL worker in a TiDB cluster. May be we will improve this in the future. @snail2swift Please try the latest master or binary.  @xiamw2000 Could you please provide your navicat version and platform? Could you try the latest navicat?  TiDB support chinese comments, but may be it has compatibility problem with navicat.  @ziyouchutuwenwu Thanks for your feedback!
"USING (constraint_schema, constraint_name)" is not supported now. We will work on it.  Thank you for your report!
We will take a look at it.  @snail2swift 
We don't support large transaction.
You can limit the count in a delete statement or use `truncate table`.  @snail2swift  We don't support load data without `local` field. You can change the statement like this ` load data local infile '/tmp/std_pro_iver_cha_rso_event.txt' into table std_pro_iver_cha_rso_event fields TERMINATED by '|';`. @snail2swift  Could you show me the result of tidb-server -V ? @snail2swift Start some MySQL clients need to add `--local-infile=1` option.  The start MySQL client command like `mysql --local-infile=1 -u root -h 127.0.0.1 -P 4000`.  @winkmichael Thanks for your feedback!
Could you send me the log of tidb-server? The sets statements missing a `*`, should be `/*!` instead of `/!`.  @winkmichael Could you please provide more information?
Do you try to import a database with name 'mysql'? @winkmichael Could you please show me the error log of tidb-server.  May I get the githash of tikv/tidb/pd? It's re-produced in a local cluster of single pd/tikv/tidb node
10.2.0.233 ~/hhkbp2/table_missing/tidb.log
PTAL Close issue because this problem can't be re-produced.  LGTM LGTM  @hzxjtx Thanks for your feedback. 
We have never tested tpc-h on TiDB. We will check it out.  @vadimtk Thanks for your feedback!
TiDB support serializable isolation level. But its behavior is a little different from MySQL. TiDB does not has global lock when you update rows. We use row-level optimistic lock to resolve write conflict. When two session updating the same row, one of them will success and the other one will meet write conflict and retry the whole transaction automatically.

In your case, you can use "select for ... update" to prevent write skew. There is one thing you should notice. We also use optimistic lock to detect conflict at the commit stage. Unlike update/delete/insert, SelectForUpdate statement will not be retried automatically. The client will receive an error with message "can not retry select for update statement" and it should decide retry the statement or not.

 Hi @vadimtk ,

Strictly speaking, the isolation level we are providing should be [Snapshot Isolation](https://en.wikipedia.org/wiki/Snapshot_isolation), you may also refer to the [FAQ](https://github.com/pingcap/docs/blob/a9cfe1342c88c6f8b1fb4939dea39fd4cba95d1e/TiDB_FAQ.md#does-tidb-have-acid-semantics). In some cases, users can use _SELECT ... FOR UPDATE_ to  explicitly specify the rows that need to be locked to avoid write skew.

If we want to support Serializable Isolation, we have to introduce table lock or range lock, which will affect the system's concurrent performance.

In the future, we might provide configurable different isolation levels, allowing users to balance isolation level and performance according to their own situation. Good idea. Thank you @vadimtk 
Would you like to send a PR to return an error?  @wangpeibin713 Thanks for your report! We will fix it.  tpcc1000 test:

```
2017/02/28 10:01:13 conn.go:333: [error] lastCmd �
EINGESEESE, runtime error: invalid memory address or nil pointer dereference, goroutine 7235352 [running]:
github.com/pingcap/tidb/server.(*clientConn).Run.func1(0xc4cb2872c0)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:332 +0xe2
panic(0xd844a0, 0xc420010070)
        /usr/local/go/src/runtime/panic.go:458 +0x243
github.com/pingcap/tidb/plan.(*typeInferrer).Leave(0xc4ff86e810, 0x1463460, 0xc487eccb40, 0x1463420, 0xc4eb2f5c00, 0x1470201)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/plan/typeinferer.go:62 +0x1022
github.com/pingcap/tidb/ast.(*ColumnNameExpr).Accept(0xc487eccb40, 0x145e060, 0xc4ff86e810, 0x1464220, 0xc4b8ab5ce0, 0xc47f07a700)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/ast/expressions.go:360 +0x11a
github.com/pingcap/tidb/ast.(*SelectField).Accept(0xc4b8ab5ce0, 0x145e060, 0xc4ff86e810, 0x1464220, 0xc436ab4240, 0xc420912801)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/ast/dml.go:294 +0xfa
github.com/pingcap/tidb/ast.(*FieldList).Accept(0xc500ec67b0, 0x145e060, 0xc4ff86e810, 0xc4dd9ff690, 0xc4209128f0, 0x1)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/ast/dml.go:318 +0xc6
github.com/pingcap/tidb/ast.(*SelectStmt).Accept(0xc500806b00, 0x145e060, 0xc4ff86e810, 0x114c052598, 0x40e00f, 0x17bb420)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/ast/dml.go:491 +0x449
github.com/pingcap/tidb/plan.InferType(0xc4d8abe540, 0x1464260, 0xc500806b00, 0xc44c0524e0, 0x1035f0c)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/plan/typeinferer.go:35 +0xac
github.com/pingcap/tidb/plan.Optimize(0x146fb40, 0xc4de6af110, 0x1464260, 0xc500806b00, 0x7fcace585000, 0xc420422360, 0xc4ff86e76b, 0xa, 0xa, 0x0)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/plan/optimizer.go:60 +0x78
github.com/pingcap/tidb/executor.(*ExecuteExec).Build(0xc44d474980, 0x1473140, 0xc4c5e87b80)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/executor/prepared.go:243 +0x328
github.com/pingcap/tidb/executor.(*statement).Exec(0xc4f07d0660, 0x146fb40, 0xc4de6af110, 0x0, 0x0, 0x0, 0x0)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/executor/adapter.go:115 +0x5ff
github.com/pingcap/tidb.runStmt(0x146fb40, 0xc4de6af110, 0x145de60, 0xc4f07d0660, 0x3, 0x3, 0x145de60, 0xc4f07d0660)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/tidb.go:176 +0x7d
github.com/pingcap/tidb.(*session).ExecutePreparedStmt(0xc4de6af110, 0xc40000000f, 0xc4ff86e780, 0x3, 0x3, 0x0, 0x0, 0xc4ff86e76b, 0xa)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/session.go:598 +0x11e
github.com/pingcap/tidb/server.(*TiDBStatement).Execute(0xc4c5dd1450, 0xc4ff86e780, 0x3, 0x3, 0x3, 0x3, 0xc4ff86e75a, 0x1)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/driver_tidb.go:63 +0x6b
github.com/pingcap/tidb/server.(*clientConn).handleStmtExecute(0xc4cb2872c0, 0xc4ff86e751, 0x24, 0x24, 0x25, 0x0)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn_stmt.go:166 +0x4cb
github.com/pingcap/tidb/server.(*clientConn).dispatch(0xc4cb2872c0, 0xc4ff86e751, 0x25, 0x24, 0x0, 0x0)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:458 +0x801
github.com/pingcap/tidb/server.(*clientConn).Run(0xc4cb2872c0)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:349 +0x139
github.com/pingcap/tidb/server.(*Server).onConn(0xc420906740, 0x146f420, 0xc4200295c8)
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/server.go:209 +0x13e
created by github.com/pingcap/tidb/server.(*Server).Run
        /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/server.go:173 +0x96
``` with many error messages:

```
error at thread_main
2006, HY000, MySQL server has gone away
```

The tpc-c test finally prints the results:

```
<Raw Results>
  [0] sc:0 lt:34  rt:35385136  fl:17701 avg_rt: 177.5 (5)
  [1] sc:0 lt:19  rt:35411995  fl:17717 avg_rt: 135.3 (5)
  [2] sc:0 lt:0  rt:3548224  fl:1775 avg_rt: -nan (5)
  [3] sc:0 lt:0  rt:3546723  fl:1774 avg_rt: -nan (80)
  [4] sc:0 lt:3  rt:3538230  fl:1770 avg_rt: 1300.4 (20)
 in 3600 sec.

<Raw Results2(sum ver.)>
  [0] sc:0  lt:34  rt:35385605  fl:17701
  [1] sc:0  lt:19  rt:35412471  fl:17717
  [2] sc:0  lt:0  rt:3548225  fl:1775
  [3] sc:0  lt:0  rt:3546731  fl:1774
  [4] sc:0  lt:3  rt:3538230  fl:1770

<Constraint Check> (all must be [OK])
 [transaction percentage]
        Payment: 33.93% (>=43.0%) [NG] *
   Order-Status: 0.00% (>= 4.0%) [NG] *
       Delivery: 0.00% (>= 4.0%) [NG] *
    Stock-Level: 5.36% (>= 4.0%) [OK]
 [response time (at least 90% passed)]
      New-Order: 0.00%  [NG] *
        Payment: 0.00%  [NG] *
   Order-Status: -nan%  [NG] *
       Delivery: -nan%  [NG] *
    Stock-Level: 0.00%  [NG] *

<TpmC>
                 0.567 TpmC
```

 @andelf 
@coocood is working on this. partially fixed. still some NG(not good) results .

```
<Raw Results>
  [0] sc:0 lt:2468  rt:13421555  fl:6722 avg_rt: 127.6 (5)
  [1] sc:0 lt:2737  rt:12886877  fl:6440 avg_rt: 75.8 (5)
  [2] sc:0 lt:0  rt:1834474  fl:917 avg_rt: -nan (5)
  [3] sc:0 lt:0  rt:1835461  fl:917 avg_rt: -nan (80)
  [4] sc:780 lt:138  rt:0  fl:0 avg_rt: 64.4 (20)
 in 10800 sec.

<Raw Results2(sum ver.)>
  [0] sc:0  lt:2468  rt:13421589  fl:6722
  [1] sc:0  lt:2737  rt:12886906  fl:6440
  [2] sc:0  lt:0  rt:1834476  fl:917
  [3] sc:0  lt:0  rt:1835461  fl:917
  [4] sc:780  lt:138  rt:0  fl:0

<Constraint Check> (all must be [OK])
 [transaction percentage]
        Payment: 44.70% (>=43.0%) [OK]
   Order-Status: 0.00% (>= 4.0%) [NG] *
       Delivery: 0.00% (>= 4.0%) [NG] *
    Stock-Level: 14.99% (>= 4.0%) [OK]
 [response time (at least 90% passed)]
      New-Order: 0.00%  [NG] *
        Payment: 0.00%  [NG] *
   Order-Status: -nan%  [NG] *
       Delivery: -nan%  [NG] *
    Stock-Level: 84.97%  [NG] *

<TpmC>
                 13.711 TpmC
``` NG report is due to MYSQL_DATA_TRUNCATED error.
maybe caused by different return value size. ```sql
SELECT o_id, o_entry_d, COALESCE(o_carrier_id,0) FROM orders WHERE o_w_id = ? AND o_d_id = ? AND o_c_id = ? AND o_id = (SELECT MAX(o_id) FROM orders WHERE o_w_id = ? AND o_d_id = ? AND o_c\
_id = ?)
```

in MySQL:  COALESCE(o_carrier_id,0) is an int(4)
in TiDB:  COALESCE(o_carrier_id,0) seems to be a decimal.  Is StmtFetch support limited?
 PTAL @coocood  COALESCE() fixed in #2788  Now TiDB can't run multithread TPC-C tests:


payment 1:10
1105, HY000, [201] can not retry select for update statement

TiDB log:

```
2017/03/07 13:32:13 2pc.go:485: [info] 2PC clean up done, tid: 390296956597698580
2017/03/07 13:32:13 simple.go:134: [info] [176] execute rollback statement
2017/03/07 13:32:13 txn.go:169: [info] [kv] Rollback txn 390296956637020167
2017/03/07 13:32:13 session.go:267: [warning] [170] finished txn:<nil>, [170] can not retry select for update statement
2017/03/07 13:32:13 session.go:554: [warning] [170] session error:
/home/ubuntu/go/src/github.com/pingcap/tidb/session.go:329: [170] can not retry select for update statement
/home/ubuntu/go/src/github.com/pingcap/tidb/session.go:268:
/home/ubuntu/go/src/github.com/pingcap/tidb/tidb.go:189:
{
  "currDBName": "tpcc100",
  "id": 170,
  "preparedStmtCount": 35,
  "stauts": 0,
  "strictMode": false,
  "user": "root@172.233.1.113"
}
2017/03/07 13:32:13 conn.go:356: [warning] [170] dispatch error:
id:170, addr:172.233.1.113:39024 status:0, collation:latin1_swedish_ci, user:root
commit
/home/ubuntu/go/src/github.com/pingcap/tidb/session.go:329: [170] can not retry select for update statement
/home/ubuntu/go/src/github.com/pingcap/tidb/session.go:268:
/home/ubuntu/go/src/github.com/pingcap/tidb/tidb.go:189:
/home/ubuntu/go/src/github.com/pingcap/tidb/session.go:556:
/home/ubuntu/go/src/github.com/pingcap/tidb/server/conn.go:661:
``` @wangpeibin713 

Fixed. :)
try update tidb-server and run TPC-C test.  Hi,all, 
      This PR is for [issues_2623](https://github.com/pingcap/tidb/issues/2623). @disksing @coocood PTAL The rest LGTM. PTAL @hhkbp2  LGTM @hhkbp2 PTAL LGTM @hhkbp2 PTAL  @ThreeBearsDan Thanks for your feedback! We will fix this.  Thanks for reporting! 
@siddontang PTAL Hi @rystsov 

Seem that the leader can't be elected for a long time., could you give me all your TiKV logs.   Hi @rystsov 

I have used your case and reproduce the problem. This is caused that your test client connects the TiDB in 10.0.0.7, but this TiDB can't connect to other PDs and TiKVs in 10.0.0.5 and 10.0.0.6. After a long time retry, TiDB will return the test client a timeout error, then the test client will connect another TiDB and works. In my machine, the unavailable time is about 1m30s. 

TiDB is stateless, only PD and TiKV have the leader concept because of Raft. When the partition occurs, the new leader will be elected at about 20s, which is within the expected range. So now we need to let TiDB return error immediately or not retry too many times when we know the TiDB can't provide services. /cc @coocood 
  If we don't want the tidb-server run ddl jobs, we can use this parameter `-run-ddl false` to disable it. @GregoryIan @iamxy PTAL  @biolee Please run `make parser` first. It's because $HOME/tidb is not in $GOPATH. When you run 'make parser', the parser would be generated in current directory which in your case is $HOME/tidb, but this directory is not $GOPATH, and go compiler couldn't find this file.  @simingli Thanks for your feedback!
It seems that tidb-server could not get data from tikv-server. Could you show us your tikv-server's log? @siddontang @BusyJay PTAL @simingli How many tikv-server instance do you deployed? It seems that there is something wrong with the instance on 10.2.1.103. Could your show me the logs of this instance? Hi @simingli 

Does `2017/02/14 16:13:49.939 server.rs:179: [WARN] remove store connection for store` occur too many times?  @simingli It seems that the tikv on 10.2.1.101 could not contact with the tikv on 10.2.1.102. It may be related with firewall. Could you shutdown your firewall or check the rules? Using `telenet 10.2.1.103 20160` can work? 

Do you start the TiKV on 10.2.1.103? @simingli But the firewall may prevent incoming packet on port 20160. So we suggest shutdown firewall or add rules into iptables.
Please try @siddontang 's command. @simingli Cool! 
You could find some useful information [here]( https://github.com/pingcap/docs/blob/master/trouble-shooting.md#tidb-cluster-troubleshooting-guide) when you meet any problem.  Old row value is required for translating to MySQL binlog. @GregoryIan @zimulala PTAL LGTM
@zimulala   @catroot 
Thank you for your report.

Those two DDL statements can be supported soon.
But for modifing the length of a varchar column, we can only support increasing the length. @catroot 
Thank you for your advice.

I think returning error is the right behavior for the not supported feature.
MySQL also returns an error when there is data longer than the specified length.

The error message should be more specific, we will improve that. @catroot 
We hope we can support those DDL operations too, but if the DDL operation requires checking every row in the table, it would be difficult to implement.

So my sugguestion is that during development phase, schema changes frequently, you can just use MySQL, when schema is settled down, you can switch to TiDB seamlessly. @catroot 

Currently, we only support online DDL change, when you add a column or index, the table is not locked, can still be written and read.

The difficulty is that when we are checking every row in the table, new rows may be inserted, which may exceed the new length.

We do have the plan to support it, but not in the next few months, but when more users asking for this feature, we will put it on a higher priority. @catroot 
When ALTER TABLE returns successfully, users will expect all rows in the table have the limited length, returning a row longer than the limit may result in more serious errors.

One way to solve the problem is that we can truncate the column value when reading it.

But this can be only applied when strict SQL mode is not set.

In strict SQL mode, every row must be less than the new length or the DDL fails. @catroot 
According to MySQL docuement
```
This conversion may result in alteration of data. For example, if you shorten a string column, values may be truncated. 
To prevent the operation from succeeding if conversions to the new data type would result in loss of data, enable strict SQL mode before using ALTER TABLE (see Section 6.1.8, “Server SQL Modes”).
```

Strict SQL mode is used to prevent alteration of data, so checking every row is required. > Those two DDL statements can be supported soon.

We support it now, you can try the latest master code. @catroot  @catroot Could you show me the result of `tidb-server -V` ? > Those two DDL statements can be supported soon.
> But for modifying the length of a varchar column, we can only support increasing the length.

Are sure your case is in line with the second point?
 @catroot  Could you show me the statement of `Create table`? @catroot  Please make sure that the process you are using is the latest binary process. 
BTW, the `drop default` statement should be "ALTER TABLE `payment_type` ALTER column `name` DROP DEFAULT;" Yep, we will support the field of `column` optional soon.
This statement of `ALTER TABLE payment_type DROP COLUMN name CASCADE` is not supported yet. Yes. @catroot  We support the field of `column` optional now, you can try the latest master code. @catroot OK, no problem. Thank you for your feedback. @catroot   This fixes:

```
2017/02/06 14:17:09 main.go:182: [info] start Prometheus push client with server addr 
172.233.1.240:9091 and interval 2000000000
```

Now:
```
2017/02/06 14:22:42 main.go:185: [info] start Prometheus push client with server addr 
172.233.1.240:9091 and interval 2s
``` LGTM  @zyguan Thanks!
@coocood @hanfei1991 PTAL @zyguan This is already fixed. Please use the latest master.  @zyguan Good job!
@tiancaiamao @XuHuaiyu PTAL LGTM LGTM
@zyguan 
Thank you!
Please resolve conflict. Good job! @zyguan   @luckcolors Thanks! 
The CI is failed: https://travis-ci.org/pingcap/tidb/builds/198371842 @luckcolors 
How about defining the constant as int64 type instead? `go fmt github.com/pingcap/tidb/util/types` would fix it, or you can try `make check` twice.
@luckcolors  @luckcolors 
Any update? LGTM

@luckcolors 
Thank you for your contribution! LGTM  Thanks for reporting. We don't have any plan to make TiDB work on 386. Could you please send a PR to fix it? Fixed in https://github.com/pingcap/tidb/pull/2591  Hi @yuekui2 

PD will balance data to other TiKV when the data size exceeds a threshold. Assume your TiKV's capacity is 500GB, and the default `min-balance-diff-ratio` is 0.01, so you should insert at lease 5GB data, then PD will begin to move the data to the empty TiKV. 

If you want to test balance, you can:

+ Start TiKV with `--capacity` with a little value, like `1GB`. 
+ Change `min-balance-diff-ratio` in PD config file to 0.001 or more less and start PD.
+ Use `pd-ctl` to change `min-balance-diff-ratio` dynamically. 
 We should add the details to FAQ. @shenli @siddontang  Yes, it's because of the data moving.
 
The reason of "force" data moving itself is very slow is the limit of PD, which can be configured too. By default it's very slow, because we don't want to make any impact for online transactions.  We will boost the moving and rebalancing speed after RC2. Currently it depends on  https://github.com/pingcap/tikv/pull/1561 

> More over, let us say capacity is 10G, ratio is 0.1, and 3 tikv instances with data of 4GB each. After adding a new tikv instance, will it evenly re-balance to ~3GB each?

Yes Hi @yuekui2 

You can use `store` in `pd-ctl` to see the current TiKV cluster information. It is more clear than checking the db folder directly. 

For the `min-balance-diff-ratio`, assume we have two TiKV, both capacity is 1TB, one data used size is S1 and the other is S2, if `S1 / 1TB - S2 / 1TB < min-balance-diff-ratio`, PD will consider starting balance, of course, the real balance algorithm is more complex.  The default balance seems slow, and it is strange that why 1 has only 1340 now? @huachaohuang 

@yuekui2  We have been improving the balance, will release a version next week. Because we balance according to storage ratio for now, we should balance the region count.
The next version will remove some restrictions and configurations, and will be more intuitive. fixed by https://github.com/pingcap/pd/pull/506  Thank you for your report @catroot 
Looks like we need to add an empty table_constraints. Is that right? @shenli  @catroot We will add this table into tidb's information_schema. @catroot Thanks! @catroot Please try the latest master or the latest binary.  Sorry, there is no way to do that. Interesting, PD supported a separate etcd cluster in the very earlier versions, it's too complex for users to deploy one more component, so we embedded etcd to PD.  `UnknownSystemVar` contains unused format placeholder for the variable name.

```go
UnknownSystemVar  = terror.ClassVariable.New(CodeUnknownSystemVar, "unknown system variable '%s'")
```

This fixes:

```
MySQL [test]> SELECT @@whatever_not_a_variable_in_system;
ERROR 1193 (HY000): unknown system variable '%!s(MISSING)'
``` LGTM @andelf please sign the CLA LGTM @andelf Please sign the CLA.  @kaiwu May I have all the argument of your mydumper command? @kaiwu When use myload to load data, please add -q 1 in command line. Or you can use the `load` tool developed by us. See https://github.com/pingcap/docs/blob/master/op-guide/migration.md#3-importing-data-to-tidb @kaiwu Do you have a table with only a few columns and with integer type? We set a limitation on the key-value entry count and size of a single transaction. For each row/index, there will be a key-value entry.
We increase the limitation from 100k to 300k a few days ago. You can try the latest master of tidb or download the [newest binary](http://download.pingcap.org/tidb-latest-linux-amd64.tar.gz). @kaiwu This feature is not merged into rc1.1 and we will release rc2 tomorrow. You can try the latest master. The commit is https://github.com/pingcap/tidb/commit/de9b134c50381123b9fa710ab4e2c110735f73b4 @kaiwu Yes, we will release a new tag from master tomorrow. Please use master now.  @catroot Thanks for your advice! For FLUSH statement, it is OK to reply OK. But for ALTER statement, I think it is better to return error. @catroot 
DB collations is not alterable now.
Trigger/View/Stored Procedures is not supported now. Maybe we will support view after GA.
  @zyguan 
Would you please add a test case for a select statement that returns the correct type?

 That's tranvisCI issue, I restarted it.  Like PD, for every transaction, we can add it the a history list. We can record the SQL query, the execution time, the detailed accessed regions or other statistics. 

We can use a HTTP API to see the transaction history, or a SQL like `admin show transaction histories`.   also change the test of sqrt function. LGTM @coocood @shenli @tiancaiamao PTAL LGTM  Currently, we cached all of the region address that we ever used, i think LRU is a better idea, especially when the database is huge.  The stores' addresses are cached by storeID, which is small and not frequently update.
And for the regions we have accessed, their metas are cached in an rbtree.  @shlomi-noach Thanks for your report! We will fix it. @shlomi-noach It will be fixed in https://github.com/pingcap/tidb/pull/2497  LGTM
@XuHuaiyu PTAL @XuHuaiyu PTAL LGTM  Good job. PTAL @zhexuany fix CI LGTM
@hanfei1991 @XuHuaiyu PTAL  Please take a look at the quick start docs https://github.com/pingcap/tidb/blob/master/docs/QUICKSTART.md  We support the statement of `rename table` by #2444 . We need to support the behavior in binlog.  @zyguan Factory mode is not suggested any more. It will add the cost of checking in runtime. In future, we will implement every function signature. e.g.  binary op Factory will be replaced by builtinEQ, builtinLT ...
and builtinEQ will be replaced by EQFloat, EQInteger, EQDecimal, EQString ....  @zyguan JIT doesn't fit for OLTP. Temporily we can only do it manually.  LGTM
PTAL @coocood  @zyguan 
`mysql.NewDecimal` should be handled too.
Rounding a decimal returns a decimal. LGTM
Thank you!  We've working on privilege related issues already, and the current situation would be improved in RC2.
Thanks for your feedback, please stay concerned. hi, @lauyoume 

Grant privileges database name with prefix is supported now, you can try it like this:

```
CREATE USER 'dduser'@'%' IDENTIFIED by '123456';
GRANT ALL PRIVILEGES ON `dddb_%`.* TO 'dduser'@'%';
```

Create user and grant privilege written into one SQL is still not supported, we're working on it.

You can have a try, and  feel free to let know if you meet any problem.  LGTM Any other product use `-V`? LGTM @coocood 


```
$ mysql -V
mysql  Ver 14.14 Distrib 5.5.53, for debian-linux-gnu (x86_64) using readline 6.3
$ mysql -v
ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)
$ mysql --version
mysql  Ver 14.14 Distrib 5.5.53, for debian-linux-gnu (x86_64) using readline 6.3
```

```
# psql -V
psql (PostgreSQL) 9.3.15
# psql -v
/usr/lib/postgresql/9.3/bin/psql: option requires an argument -- 'v'
Try "psql --help" for more information.
# psql --version
psql (PostgreSQL) 9.3.15
```
 LGTM  fix #2430 
When the offset is not null, we should remain a limit as parent of table scan.
@shenli @coocood @zimulala PTAL LGTM LGTM  @Tratar Thanks for your PR! Please solve the conflict.
@XuHuaiyu PTAL @tiancaiamao PTAL Hi, @Tratar 
We have a `getDateFromDaynr ` https://github.com/pingcap/tidb/blob/master/util/types/mytime.go#L313, you can use it instead of `calcTimefromDays`. @Tratar CI failed:
util/types/time.go:1134:1: exported function TimeFromDays should have comment or be unexported
make: *** [check] Error 1 @XuHuaiyu @tiancaiamao PTAL CI failed. 
You cant run `make check` twice, until golint don't report any error. @Tratar  LGTM
PTAL @XuHuaiyu  LGTM
Thank you for your job.  Thank you for your report ! this is a bug, i will fix it soon.  LGTM  @tiancaiamao @coocood PTAL 
@zyguan Good Job! LGTM
please resolve conflicts.  @tracymacding No, we do not support Stored Procedure. We do not have any plan for it.  1. What did you do?
If possible, provide a recipe for reproducing the error.
select round(1e3, 2);

2. What did you expect to see?
+---------------+
| round(1e3, 2) |
+---------------+
|       1000.00 |
+---------------+
1 row in set (0.01 sec)


3. What did you see instead?
+---------------+
| round(1e3, 2) |
+---------------+
|          1000 |
+---------------+
1 row in set (0.00 sec)
 You are right, it because we always use `-1` as the argument. 
It has the field of `decimal` to store precision information in `Datum`. We can use `Frac()` to get precision information.
There is to be compatible with MySQL.
@zyguan Could you try to fix it?  @TheNorthMemory Thanks for your feedback!
@hanfei1991 PTAL Because you didn't create an index.
See:
mysql> create table tt(c int);
Query OK, 0 rows affected (0.00 sec)

mysql> create index cc on tt(c);
Query OK, 0 rows affected (0.01 sec)

mysql> explain select * from tt where c in (1,2,3);
+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+
| ID          | Json                                                                                                                                                                                                                                                                                                                                                                                      | ParentID |
+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+
| IndexScan_5 | {
    "db": "test",
    "table": "tt",
    "index": "cc",
    "ranges": "[[1,1] [2,2] [3,3]]",
    "desc": false,
    "out of order": true,
    "double read": false,
    "push down info": {
        "limit": 0,
        "access conditions": [
            "in(test.tt.c, 1, 2, 3)"
        ],
        "index filter conditions": null,
        "table filter conditions": null
    }
} |          |
+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+
1 row in set (0.00 sec)

For `explain select * from test where a in ( select 'x' from dual)`, we will change it to semi-join and apply hash join algorithm. @TheNorthMemory Any more question ? Well, your case is pretty seldom, because (select 'x' from dual) will only return 'x'. Most times a `In` subquery should return different records. We can do constant folding for this case, but I think it is very tricky. @kaiwu  Index look up Join is very inefficient for distributed computing. So we always use hash join. If the table in `In` subquery is always small, we can do index look-up join, this is in our roadmap.   @zyguan Good Job! That's just what i meaned. @zyguan Please resolve the conflict. LGTM
@hanfei1991 @coocood  PTAL LGTM  This PR is for issue [2283](https://github.com/pingcap/tidb/issues/2283).

Used by `SortExec` in `executor/executor.go`.

It is necessary when the input rows exceed the predefined memory capacity. @yanzhe-chen Please sign the CLA. @zimulala Fine, I have signed the CLA. Sometimes, we don't need to output all rows, we need to export a `Close` function which can be used to close all files before all data has been read.
Add a `closed` field to return early if closed. LGTM
@zimulala @hanfei1991 PTAL Rest LGTM. @yanzhe-chen Any update? Sorry for the late response. Focus on defending my MA thesis these days. I have improved the code according to the review. @XuHuaiyu @shenli @coocood @zimulala @hanfei1991 PTAL. Thanks for your careful review. @zimulala @XuHuaiyu I have refined the code and reply to some of the comments. PTAL. LGTM  @Tratar Please fix CI and sign the CLA. It seems that there is some wrong with gofmt. LGTM
PTAL @coocood  @Tratar Please solve the conflict.  @zyguan According to MySQL [Set](http://dev.mysql.com/doc/refman/5.7/en/set.html) doc, each member could be represented by a binary value. We use integer to store set value. For example:
SET('a','b','c','d')
SET Member	Decimal Value	Binary Value
'a'	1	0001
'b'	2	0010
'c'	4	0100
'd'	8	1000
If a column has value ('a,d'), we will convert it to 1001, which is 9. So You can convert the first argument to binary and use bit operation to check if it is in the second argument without converting the second argument from number to string and comparing strings. @zyguan There is no cheap way to do this. But binary_value(str) only need to be called once. You do not have to compute it for each row. @zyguan I think it is better to convert the first argument to binary value in the planning stage, not in the executing stage. @zyguan May be you can create a new issue and improve this in another PR. It may be complicated. LGTM LGTM  Cool staff. "INTERVAL" is a reserved keyword of MySQL. See http://dev.mysql.com/doc/refman/5.7/en/keywords.html

Please add it to the ReservedKeyWord rule list https://github.com/pingcap/tidb/blob/master/parser/parser.y#L2069 and add a test here: https://github.com/pingcap/tidb/blob/master/parser/parser_test.go#L60
 @zyguan Yes, you are right.
LGTM @coocood @tiancaiamao PTAL @tiancaiamao PTAL LGTM  Thanks! @zyguan 
@tiancaiamao @hanfei1991 PTAL
 PTAL @hanfei1991 @zimulala  LGTM  Good job! @zyguan  @zyguan Thanks! If you need any help, please let us know. PTAL LGTM Well done! @zyguan 
@coocood @hanfei1991 @tiancaiamao PTAL  @496080199 Thanks for your feedback!
We will fix it soon.
@tiancaiamao PTAL @496080199 This is fixed in #2351 . Please try the latest master. @496080199 Have you tested sysbench with the latest TiDB?  https://github.com/pingcap/tidb/issues/2294 @disksing @coocood  What problem does this PR solve? to fix [issue_2294](https://github.com/pingcap/tidb/issues/2294) @coocood  LGTM  @disksing @coocood   @zyguan Is there any error message when you run `make parser`? If there is any error message about 'shift/reduce' error. You should add precedence info on the rules. @zyguan I think you are on the right way. :)  @zyguan Thanks for your feedback!
The error message means the number of arguments is not right. For greatest(), it need at least 2 argument. 
"[2, -1]" means the function need at least 2 arguments and no upper limit.

Maybe we should change the error message as what mysql shows. @zyguan This will be fixed in https://github.com/pingcap/tidb/pull/2335  Hi @ch-lgs 

Raft must use at lease 3 replicas to guarantee data safety, 2 DC can't guarantee it. If one DC is down, the cluster can't work. 

If you have 3 DCs, PD can schedule the replicas to different DC automatically, and we will support it soon, see https://github.com/pingcap/pd/issues/454. Feel free to re-open the issue if you still have any questions. @ch-lgs  The maximun transaction lock time is 120s, when transaction is larger than 400M, we returns error
to prevent the large transaction harm the entire cluster.

As test for this is too expensive, I just tested it manually. @shenli @disksing PTAL 400MiB is huge, how about 50M  ? 50MB is too small, especially when we use load data command to load data. @ngaut 
Since old version doesn't have any limit, change it to a small value may cause old cluster stop working.

At least our system can afford 400MB transaction with longer lock time.

We can set it to 400MB first, change it to smaller value later if we find large transaction is problematic. @ngaut What's your opinion？ LGTM， let's make it smaller step by step. I am still worrying about if users delete millions of row, it could be trouble. @ngaut I think we should test deleting large scale data in RC2. Please add an issue for testing large delete transaction. @gejigeji 
Delete a table without a condition is considered an expensive query.
If you really want to delete all rows, you can use `truncate table t_table`.  LGTM  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
If possible, provide a recipe for reproducing the error.

```
create table t1 (id int, dt datetime);
insert into t1 values (1,"2001-08-14 00:00:00"),(2,"2001-08-15 00:00:00"),(3,"2001-08-16 00:00:00"),(4,"2003-09-15 01:20:30");
create index dt on t1 (dt);
select * from t1 ignore index (dt) where dt > 20021020;
```

2. What did you expect to see?

```
+------+---------------------+
| id   | dt                  |
+------+---------------------+
|    4 | 2003-09-15 01:20:30 |
+------+---------------------+
1 row in set (0.00 sec)
```

3. What did you see instead?

```
+------+---------------------+
| id   | dt                  |
+------+---------------------+
|    1 | 2001-08-14 00:00:00 |
|    2 | 2001-08-15 00:00:00 |
|    3 | 2001-08-16 00:00:00 |
|    4 | 2003-09-15 01:20:30 |
+------+---------------------+
```

  @silentred Thanks for your PR!
@coocood @tiancaiamao PTAL @shenli Do we need to update tutorial ? since we refactored the source. @ngaut The tutorial for builtin function  is already updated. PTAL LGTM  To make sure all of those statements implement the DDLNode interface. It's quite common in Go :)  Please sign the CLA, thanks. LGTM  Good catch!
Would you please send a PR to fix this?  Thank you for your report.
We will fix it soon.  @BusyJay 
Is this issue fixed by https://github.com/pingcap/tikv/pull/1423 ? Can we close this issue now?  @idlesummerbreeze 

Thank you for your report and kindly try to fix this issue.
You almost addressed the issue, good job!
Elements in `columns` should not be nil.
It looks like the length of `e.schema` is different than the length of `e.columns`. @idlesummerbreeze 

The root cause is that the aggregation `count(*)` has been pushed down to memory table.
So the `e.schema` is aggregation function `count(*)`, but memory table cannot handle it.

When we handle normal table, we send a request to TiKV coprocessor which can handle aggregation function.

`e.columns` is empty because we don't need any columns, we just need row count, so all the infoschema columns has been pruned.
See https://github.com/pingcap/tidb/pull/2296  @zxsciro DDL on TiDB is slower than on MySQL. You can refer to the [FAQ](https://github.com/pingcap/docs/blob/master/TiDB_FAQ.md#why-is-the-ddl-statement-so-slow-when-using-tidb) doc for the reason. If you have only one tidb-server, you could set the --lease to 0. And the speed of DDL statement will be fast. @zxsciro Thanks for your report. This is a bug, and I will fix it. @zxsciro There are two things we should do.
1. Check if the default value is valid before running the job.
2. When meet fatal error, we should cancel the ddl job.

@zimulala Will fix it. If you are interested in this, you can send us a PR. :) @zxsciro Yes, this is a bug. If it happens, the job will keep trying and affect the execution of other DDL jobs. You need to restart the TiDB to resolve it. 
The right way to handle this is to cancel the DDL job when we meet this error. Do you want to send a PR to us? @zxsciro I'm sorry. It needs to restart TiKV too. Fixing this bug requires some background knowledge. I will fix it. @zxsciro  This bug is fixed. You can try the latest master code. @zxsciro  This bug has two things we should do.
1. Check if the default value is valid before running the job.
2. When meet fatal error, we should cancel the ddl job.

Now we have only done the second thing. We are doing the first thing.
 @zxsciro This bug is fixed now. You can try the latest master code. @zxsciro If you have any problems，you can open it again.  @idlesummerbreeze Try this: go test -check.f TestAggregation  @idlesummerbreeze information_schema is a virtual table which exists only in the memory of tidb-server.
For most of sql statements, we need to refer to schema/table/index/column information when we building query plans. We keep all those info in the memory for performance consideration. So we do not need to store those data as normal tables, we could get what we need from the memory. I am writing a document and it will be release in this week. I will keep you updated.  @silentred I think it is OK to change L22 from '+=' to '='.  @silentred Thanks for your PR! Please sign the CLA. @silentred Please add typeinfer info in typeinferer.go.
See https://github.com/ngaut/builddatabase/blob/master/tidb/builtin.md no, wait for CI pass, and we'll review it.
it would be merged if two or more reviewer think it's ok. @silentred 
Please add typeinfer on this function, like this PR
https://github.com/pingcap/tidb/pull/2249 @silentred 
Please add a test case in `typeinferer_test.go` LGTM LGTM @silentred 
Thank you for your contribution!  @skybook888 May I known how you migrate your data from mysql to TiDB? Do you use any tool to dump and import the data? @skybook888 Could you show me the result of "show create table your_table_name;"  on MySQL and TiDB? @skybook888 
Please provide the detailed steps to reproduce this issue.
Thank you. @skybook888  So the bug is creating a new table and altering auto_increment to 500, but the new inserted data has id start from 1?
@zimulala PTAL @skybook888 The statement of "alter table tableName auto_increment = num" we haven't support yet. We support create table with auto_increment. @skybook888  If you are interested, you can send us a PR.  @skybook888 PR means Pull Request :)  @hamo 
Please add type infer at `plan/typeinferer.go` and `plan/typeiferer_test.go`. Good job!  Please also add  ln, log, log2, log10 to this table:
https://github.com/pingcap/tidb/blob/893a1573013bc3fc9acd68a3cdd54e452c41e690/parser/parser_test.go#L79 LGTM @hamo Thank your very much!  LGTM  @bhzhu203 Please try the latest navicat.
We are working on the compatible problems between TiDB and old version navicat.  No, this function has not been supported yet, supported functions can be found here
https://github.com/pingcap/tidb/blob/master/evaluator/builtin.go @bhzhu203 We have supported the find_in_set function, feel free to open the issue if you have any questions.  @Z000000 Thanks for your report! I sent an email to you. @Z000000 Confirmed! We are working on this. Thanks very much!  @abdulrahmantkhalifa 
Thank you for your willing to contribute.
But I'm sorry, we don't have the plan to support Redis API.
Supporting a new Database API is useful, but it is a long-term commitment, which requires a lot of work on implementation,  documentation, and testing, and most importantly, it makes our existing code much more complicated, increases maintenance cost.

The most welcomed contribution is bug-fix, but that requires understanding the project.
We will be impressed if a contributor can do it without much help.
 @abdulrahmantkhalifa 
Sorry, I misunderstood your issue.

RedisDB is not an embeded storage engine, I'm not sure if it should be implemented as localstore.  @abdulrahmantkhalifa 
For benchmark tests, you can edit `bench_test.go` to use the new engine, and run 
```
go test -run=none -bench=.
``` 
on project directory.
But I guess local store on remote Redis engine will run much slower. @abdulrahmantkhalifa 
When we run `go test` vendor is not used.
Try this command
```
GOPATH=$(pwd)/_vendor:$GOPATH go test -bench=. -run=none
``` @abdulrahmantkhalifa 
Good job to implement the redis store!
I'm sorry we can't accept this feature right now.
Thank you for your understanding.  @hyj0 Thanks for your feedback! 
The document you mentioned is out of date. I will send you an updated document for builtin function this week.  @skybook888 Thanks for your feedback! 
We haven't implemented log/log2/log10 in TiDB. Would you please send us a PR to add those functions? TiDB supports those functions now, so I close this issue.
If you find something wrong with those functions, feel free to reopen this issue.
@skybook888   @idlesummerbreeze Please use `make` to build the project. Do not use `go build`. Should we add it to FAQ or put parser.go in the repo? @shenli  @idlesummerbreeze Do you put tidb dir in GOPATH?
From your error log, it seems that there is no parser.go in parser dir. Could you should me the file list in parser package? @idlesummerbreeze Could you show me your GOPATH and the absolute path of your TiDB source code?
Please make sure that TiDB's source code is in your GOPATH.  @a6802739 Thanks for your PR!
You can use git squash command or We can squash your commits when merging your PR. @a6802739 You also need to add bin function syntax in parser package. I will send you a document to describe how to do this. @a6802739 
I think we better use standard library to implement this function.
```
fmt.Sprintf("%b", n)
```
or
```
strconv.FormatInt(n, 2)
``` @a6802739 
I tried to run `select bin(-1)` on MySQL, the result is `1111111111111111111111111111111111111111111111111111111111111111`

I seem like a negative integer will be converted to unsigned interger first.

So the stdlib function we should use is `strconv.FormatUint`. @a6802739 
```
x := int64(-1)
fmt.Printf("%b", uint64(x))
``` @a6802739  
You can search keyword `builtin` in PR list, find a PR that adds a new builtin function, see what is needed to add a new function. @a6802739 
Please make sure test is passed before push a commit. PTAL @a6802739 
Please reference this PR
https://github.com/pingcap/tidb/pull/1332/files @a6802739 
I'm sorry that PR is outdated, checkout this PR instead:
https://github.com/pingcap/tidb/pull/2249 @a6802739 Any update? 
We write an article to show how to add builtin function: https://github.com/ngaut/builddatabase/blob/master/tidb/builtin.md @a6802739 
It has been a long time since the last update.
Close for now, if you have any update, I'll reopen it.  @elvizlai Thanks for your report. Can you give us some cases?  @elvizlai Can you post your create table stmt and insert data stmt? @zet4 Thanks for your feedback! We will look into it. @zet4 It is a bug about limit/offset with prepare statement. I will fix it. @zet4 This will be fixed in https://github.com/pingcap/tidb/pull/2364. You can try the branch shenli/issue-2180 or use the latest master after this PR is merged.
Thanks again for your report!  Happy New Year! @zet4 Please try the latest master. If there is also something wrong, feel free to reopen this issue.
Thanks! @zet4 Please update your binary/source. 3f9a101ce6a31d508d184aa03f2ebb8209a9e480 is not the latest githash. @zet4 The value for limit/offset should be integer(or a string could be parsed to integer).
May I know your command? Still the following command?
`H:\gopath\src\github.com\micro\user-srv>user-srv.exe -- database_url="root:111111@tcp(192.168.99.100:32769)/users"`
 @zet4 OK, I will check it out and fix it soon. Fixed by https://github.com/pingcap/tidb/pull/2648  @yemt Thanks for your feedback!
TiDB is the SQL layer and TiKV is the storage engine layer. Their relationship is just like Google's F1 and Spanner.
TiDB is not a proxy, it is a SQL engine.
BTW: We encourage discuss in English in this repo. So people from all the world could take part in.  @elvizlai Thank you for reporting. We will look into it and keep you updated. @elvizlai Please try the latest master code. It is already fixed.  @hyj0 Thanks for your feedback. It will be fixed soon. @hyj0 Please try the latest master code. It is already fixed. @hyj0 We will fix it now. @hyj0 It will be fixed in this PR: https://github.com/pingcap/tidb/pull/2181 @hyj0 Please try the latest master code. @hyj0 It is related to the field type. We return the result of schema() in string but set a wrong field type.   In this [PR](https://github.com/pingcap/tidb/pull/2181), we set it to the right type. @hyj0 If everything is OK, I will close the issue.  Handle #1936.
This is for compatibility with previous version. So it is the first step, the second is remove the assignment to the job's arguments. PTAL @GregoryIan @coocood @tiancaiamao @shenli  LGTM @GregoryIan PTAL  Looks like benchyou is a good tool for benching. See: https://github.com/XeLabs/benchyou @ch-lgs You can use sysbench to bench TiDB.  Test circle ci. LGTM  @ch-lgs Compare with proxy, TiDB has horizontal scalability, online schema changes, consistent distributed transactions. @ch-lgs I think TiDB has the following advantages against MySQL cluster: 

-  You can deploy TiDB cluster across data centers. We use raft to replicate data between replica. In this scenario, even the whole data center is down, your data is also safe and your service is still on.

- TiDB could handle complex query better. Our optimizer is suitable for distributed computing.

- Adding or removing node into/from TiDB cluster is very easy.

- TiDB supports real distributed transaction. 

- TiDB is easy to deploy and maintain.  @ch-lgs We are going to release RC1 in the next week. GA will be released early in the next year (may be around Chinese New Year).  @nnordrum Thanks for your suggestion.
I am agree with you and view is on our plan. But it will not be included in the GA version, because of time.  Thank you for your valuable advice. @sjmudd 
I added a todo label to this issue. 
We are adding more and more documents, they are coming soon 😄 
We will let you know of any further related documents. @sjmudd I guess you need this doc: https://github.com/pingcap/docs/blob/master/op-guide/docker-deployment.md#multi-nodes-deployment Thanks for your report @sjmudd 

The multiple docker deployment document is here https://github.com/pingcap/docs/blob/master/op-guide/docker-deployment.md, seem that we should let user find cluster deployment with binary and docker more easily in the quick start. /cc @shenli 

Adding/Removing PD/TiKV/TiDB node is easy, see https://github.com/pingcap/docs/blob/master/op-guide/binary-deployment.md#addremove-node-dynamically, but now the guide has not been completed, we will improve it and add examples later.  Cool @AkihiroSuda 

I think we can try it in CI and test first. @iamxy   Hi @will835559313 , thanks for your report. 

I see that you deploy whole TiDB components in one machine, but it seems that your machine has a high load and the TiDB cluster can't supply normal service.

The standalone deployment is only for user first try, you can do some simple operations, but if you want to do more test and benchmark, I suggest deploying TiDB cluster in multi machines :-) 

 Hi @will835559313 

Seem that you run PD + TiKV in one VM too, the load is still high. 
The warning message `get timestamp too slow` is not serious, just shows that your TiDB getting TSO from PD slow (maybe network slow, or machine load high, etc..), but the cluster can still work well, you can even ignore this waring if possible. 

What I care more is `InfomationSchema is out of date`, this error is much serious, which means your TiKV is very busy and can't work. Do you meet this error again? 

Btw, we prefer using more powerful machines to test the cluster, see https://github.com/pingcap/docs/blob/master/op-guide/recommendation.md. 

 @zimulala Please check the git version of the binary we published and verify whether it use a version with bug ? It's not friendly to user but not a bug. And It's more correct. Now this be resolved after #2094 #2110 @tiancaiamao   Add sequence in binlog.TableMutation to preserve the original mutation order. @iamxy @GregoryIan PTAL LGTM  @overvenus  Thanks for your report. @ivancxj 
PTAL @overvenus  @huachaohuang PTAL There are some error log in pd's log. Hello @ivancxj 

TiKV does not accept address with scheme, try `192.168.50.171:2379`. @huachaohuang @siddontang PTAL Hm, it seems that PD cluster works fine. 

---------

> 2016-11-22 17:04:01,056 tikv-server.rs:73 - INFO  - flag pd: Some("http://192.168.50.171:2379,http://192.168.50.172:2380,http://192.168.50.173:2380")

It seems that what you passed to TiKV is 
`--pd http://192.168.50.171:2379,http://192.168.50.172:2379,http://192.168.50.173:2379`

Please try `--pd="192.168.50.171:2379,192.168.50.172:2379,192.168.50.173:2379"`

 @ivancxj No problem! ;-) Thanks @ivancxj 

/cc @overvenus we must support `--pd="http://192.168.50.171:2379,http://192.168.50.172:2379,http://192.168.50.173:2379"`. 

Now we can just ignore `http://`. 
  @shuxiang Thanks for your feedback. May I have your schema? @shuxiang Could you try "select od.* from order_unit ou join order_detail od on ou.order_detail_id = od.id where ou.id > 90000 and ou.id < 100000 order by ou.id limit 20;"  Handle #1936  PTAL @GregoryIan @coocood @tiancaiamao  PTAL @ngaut  This is for compatibility with previous version. 
So it is the first step #2170 , the second is remove the assignment to the job's arguments.  PTAL @GregoryIan  PTAL @tiancaiamao @GregoryIan @coocood  LGTM  @shuxiang Please check the log of tidb-server. It seems that tidb-server could not access tikv-server. @shuxiang Please refer to this doc: https://github.com/pingcap/docs-cn/blob/master/trouble-shooting.md  Thanks for your report @dbaspace , I translated the title of this issue to english. 
We will fix the issue later.  @shenli 
  32kb is more friendly for raft and rocksdb.
@disksing @shenli PTAL Why was that ?
 LGTM
 LGTM
 @zhangjinpeng1987 Please solve the conflict.
  From the error message, port 20160  is used by other process.
  @lunny Please use `make`. Or you should run `make parser` before `make build`.
  @gqf2008 Thanks for your report! We will check it out and keep you updated.
 @gqf2008 We have already located the bug. It will be fixed soon.
 @gqf2008 We fixed this bug. Please try the latest master.
 hi, @gqf2008 
The error log `ERROR : Information schema is out of date` says TiDB can't load the schema within a lease. To solve this, you can try to add a command line argument `-lease 10s` when TiDB start.

By the way, this seems to be a resource consuming test, I run it under my laptop and it eat up the whole memory. So, you'd better use TiKV, deploy them separately to get the best performance. TiDB is stateless, if CPU is its bottleneck, we can deploy multiple TiDB instance in the real use cases.

As for this case, high CPU occupation of TiDB just make the test slower, but the test should not fail. You can try to increase lease value first. The default lease of TiDB is 1s, which is not suit for serious use case.  @leaxoy Thanks for your suggestion. 
We do not have plan to publish to homebrew. We encourage users deploy TiDB cluster on Linux. 
If you are interested in this, could you help us to do this?
  @keithyau We do not support str_to_date now.  Please refer to the [doc](https://github.com/pingcap/docs-cn/blob/master/op-guide/mysql-compatibility.md#内建函数). We will implement it soon.
  @keithyau It depends on the schema and your hardware.
We do not recommend use mysqldump  to import large data. Compared with MySQL, TiDB has higher latency. So use single thread to import data will be slow. 
TiDB could reach higher throughput that MySQL. We usually use mydumper/myloader to migrate data from MySQL to TiDB. You can refer to this [docs](https://github.com/pingcap/docs-cn/blob/master/op-guide/migration.md#使用-mydumpermyloader-全量导入数据).
  @keithyau May I have the full panic stack?
 @keithyau Any information in dmesg? Or any log for the reason why the process is killed, such as OOM.
 @keithyau Thanks! We will discuss this bug today and keep you updated.
 @keithyau From your recent logs, we can tell that your TiDB cluster is too busy. May I have your hardware info and deployment info?
You can use this [script](https://github.com/andelf/tidb-tools/tree/fadc61e193ac07eb96a181a3c9f01e61f3369068/scripts) to get hardware and OS info.
 How many thread do you use to load data?
 @keithyau 
-q Number of queries per transaction, default 1000
ref https://github.com/pingcap/tidb/issues/1576
 @keithyau Please use 1 for parameter -q.
 @keithyau Any updates? Feel free to reopen it if you still have any questions.  'benchdb' is used to make testing basic table performance easier.
Also move 'benchkv' to 'cmd' folder. Some documentations need to be added.
 @shenli @hanfei1991 PTAL
 LGTM
  When we do predicate pushdown, we can push down the predicate made by only one group-by item across the aggregation. Like "select s from (select sum(v2) as s, v1 from t group by v1) k where v1 > 1", it can be rewritten as "select s from (select sum(v2) as s, v1 from t where v1 > 1 group by v1) k ".
@hanfei1991 @zimulala @coocood @XuHuaiyu PTAL @winoros Please sign the CLA.
 Add test with multiple group-by columns.
 @coocood @XuHuaiyu @zimulala @shenli PTAL
 LGTM
 Maybe a test case for the situation that can not be pushed down.
 LGTM
  https://dev.mysql.com/doc/refman/5.5/en/date-and-time-functions.html#function_from-unixtime @coelho This is fixed. Please try the latest master.   Many of customer are using TiDB in production with our support. Please contact us if you want to use it in production now. You may also use it when we release the GA version in the next a few months.
 We plan to release the GA version around april, please stay turned.  Provide correct startTS and commitTS, and write rollback ddl binlog if transaction rollback.
 @iamxy @GregoryIan @shenli PTAL
 LGTM
  Thanks @Librazy 
LGTM  @coocood PTAL
 LGTM
  @sjmudd 
Thank you for your suggestion.
This is a very useful feature. 
We will let you know when starts to support this feature.

But we can't use the same algorithm to calculate the checksum value because we store data in a different format than MySQL, so the checksum value for the table imported from MySQL to TiDB will be different.
  The core problem is how to retrieve the position which is the latest written commitTS over all TiDBs. Where store this value ?
  @Librazy Good idea! Could you send us a PR?
  Hello,

You can build TiDB using the following commands.

``` sh
sudo apt-get install make
make
```

The output `tidb-server` can be found in the folder `bin`.
 @sotex You can get the compiled binaries here: https://github.com/pingcap/docs-cn/blob/master/op-guide/binary-deployment.md
  To improve readability.
 LGTM
  Thank you @Zhoubirdblue
Please sign the CLA by clicking the CLA button.
 Please add some tests.
 The test you can use the function of `doDDLJobErr` . The detail you can refer to [TestIndexError](https://github.com/pingcap/tidb/blob/master/ddl/ddl_worker_test.go#L163)
 Do it according to your understanding.  
Thank you @Zhoubirdblue  :)
 You should use go fmt to format your code in order to pass ci test @Zhoubirdblue 
 PTAL
 LGTM
 PTAL @coocood 
 LGTM
@Zhoubirdblue 
Thank you!
  Fix #1842 
 PTAL @coocood @tiancaiamao @shenli @GregoryIan 
 LGTM
 LGTM
  One of my designer friend helped us polish tidb's logo.
@qiuyesuifeng @queenypingcap @shenli 
 LGTM
 LGTM
  Yes, add full TableInfo in ALTER TABLE DDL job doesn't add much cost.
When we need it, we can use it directly. Otherwise we have to do a lot of computing to reconstruct it.
 @zimulala PTAL
 Good point !!
So we can restore the schema state of any time point by the job list.
  Thanks for your report. @jojo05 
We will support rpi3 ARM64 nodes, and we need some help to test rpi3.

The minimum setup should be at lease 3 servers since we should keep 3 replicas.
 @jojo05 Hope this document will be helpful. https://github.com/pingcap/docs/blob/master/op-guide/overview.md
  For https://github.com/pingcap/tikv/issues/974
@ngaut @siddontang 
 @disksing CI failed
 Wait for me to find an approach to test :)
 PTAL @ngaut @shenli 
 PTAL @ngaut 
 PTAL @coocood 
 PTAL @ngaut @coocood 
 Rest LGTM.
 LGTM
 LGTM
  The time zone offset will be used by TiKV to compare timestamp type.
 @shenli @tiancaiamao @zimulala @BusyJay PTAL
 LGTM
/cc @BusyJay 
  @shenli @coocood Please take a look. Thanks
 @queenypingcap Please sign the CLA.
 LGTM
 LGTM
 LGTM
  @JackDrogon 
Thank you for your report, we will look into it.
 @JackDrogon 
How is your data inserted? can you reproduce this error?
 The input data is written in code or parsed from some text file?
 Maybe the data in kafka is not UTF8, can you confirm that?
 Can you provide sample input data, so we can reproduce it.
 Please send it to email at my profile page.
Thank you.
  Yes, we will. 
  Currently deploy and rolling update the cluster is kind of pain, i guess the better way is using kubernetes to do all the staff.
  mysql> INSERT INTO t2 SELECT \* FROM t2;
Query OK, 57344 rows affected (0.92 sec)

mysql> INSERT INTO t2 SELECT \* FROM t2;
Query OK, 114688 rows affected (1.92 sec)

mysql> INSERT INTO t2 SELECT \* FROM t2;
Query OK, 229376 rows affected (3.87 sec)

mysql> INSERT INTO t2 SELECT \* FROM t2;
Query OK, 458752 rows affected (7.36 sec)

mysql> INSERT INTO t2 SELECT \* FROM t2;
Query OK, 917504 rows affected (14.38 sec)

mysql> INSERT INTO t2 SELECT \* FROM t2;
Query OK, 1835008 rows affected (30.47 sec)

mysql> INSERT INTO t2 SELECT \* FROM t2;
Query OK, 3670016 rows affected (55.83 sec)

mysql> INSERT INTO t2 SELECT \* FROM t2;
ERROR 2013 (HY000): Lost connection to MySQL server during query
mysql> desc t1;
ERROR 2006 (HY000): MySQL server has gone away
No connection. Trying to reconnect...
ERROR 2003 (HY000): Can't connect to MySQL server on '127.0.0.1' (111)
ERROR: 
Can't connect to the server

TiDB crashed here because of OOM. Here is the schema information.

mysql> desc t1;
No connection. Trying to reconnect...
Connection id:    10001
Current database: test

+-------+--------------+------+------+---------+-------+
| Field | Type         | Null | Key  | Default | Extra |
+-------+--------------+------+------+---------+-------+
| name  | varchar(128) | YES  |      | NULL    |       |
| email | varchar(128) | YES  |      | NULL    |       |
+-------+--------------+------+------+---------+-------+
2 rows in set (0.00 sec)

Table t2 has the same schema of t1.

After i restart tidb-server:
mysql> select count(_) from t2;
+----------+
| count(_) |
+----------+
|  7340032 |
+----------+
1 row in set (44.94 sec)

The count is slow at the first time

mysql> select count(_) from t2;
+----------+
| count(_) |
+----------+
|  7340032 |
+----------+
1 row in set (2.87 sec)

I am using the branch: origin/busyjay/add-iterate-bound
 mysql> select count(_) from t2;
+----------+
| count(_) |
+----------+
| 26380032 |
+----------+
1 row in set (9.53 sec)

mysql> insert into t2 select \* from t2 limit 4000000;
Query OK, 4000000 rows affected (1 min 18.82 sec)

mysql> insert into t2 select \* from t2 limit 4000000;
Query OK, 4000000 rows affected (1 min 21.77 sec)

mysql> insert into t2 select \* from t2 limit 4000000;
ERROR 2013 (HY000): Lost connection to MySQL server during query
 @gejigeji Could you show me the log of tidb-server? Especially the error logs. Could you send me the whole log file? You can send compressed log file to shenli@pingcap.com. Thanks!  @ruiaylin Thanks for your feedback!
Some clients do not set capability properly. We will fix it in this PR: https://github.com/pingcap/tidb/pull/1772
 fixed by https://github.com/pingcap/tidb/pull/1772
  @elvizlai Thanks for your report!
It seems that  TiDB could not get response from TiKV. May I have your TiKV's log?
 Hi @elvizlai 

The TiKV log's time is `2016-09-27 02:27:26`, but your TiDB is `2016/09/27 01:39:41`.
Seem that you didn't start TiKV before TiDB? 
 Could you restart your TiDB now? Or may I have your TiKV's log around 01:39:41? 
 @elvizlai 

I use your script but with alpine docker image, and it works well. 

```
#/bin/bash

# network
net="ti_database"
docker network rm ${net}
docker network create --driver bridge ${net}

# data storage
docker volume create --name ti-storage

# PD
docker run --net ${net} -d --name pd1 \
  -v /etc/localtime:/etc/localtime:ro \
  -v ti-storage:/tidata \
  pingcap/pd:alpine \
  --cluster-id=1 \
  --name="pd1" \
  --data-dir="/tidata/pd1" \
  --client-urls="http://0.0.0.0:2379" \
  --advertise-client-urls="http://pd1:2379" \
  --peer-urls="http://0.0.0.0:2380" \
  --advertise-peer-urls="http://pd1:2380" \
  --initial-cluster="pd1=http://pd1:2380"


# TiKV
docker run --net ${net} -d --name tikv1 \
  -v /etc/localtime:/etc/localtime:ro \
  -v ti-storage:/tidata \
  pingcap/tikv:alpine \
  --addr="0.0.0.0:20160" \
  --advertise-addr="tikv1:20160" \
  --store="/tidata/tikv1" \
  --dsn=raftkv \
  --pd="pd1:2379" \
  --cluster-id=1

# TiDB
docker run --net ${net} -d --name tidb \
  -p 4000:4000 \
  -v /etc/localtime:/etc/localtime:ro \
  pingcap/tidb:alpine \
  --store=tikv \
  --path="pd1:2379?cluster=1"
```
 Seem we should use alpine for the latest @iamxy now. 
 Restarting TiDB can solve this? @elvizlai 
 @elvizlai Please redeploy your cluster with alpine image. It seems that the latest tikv image is not work.
For create user, try CREATE USER 'test1'@'%' identified by '123';
 mysql -h${TIDB_HOST} -P 4000 -u ${USER_NAME} -p
 @elvizlai I will try this.
 @elvizlai We found the problem. It seems that some mysql clients do not consider server capability during handshake stage. We will fix this. @tiancaiamao 
  @haterbj Thanks for your report!
Which client do you use to connect to TiDB? May I have your connection URI or command line arguments? Is there any error log in TiDB when your connection failed?
 @haterbj Please check your iptable status

```
service iptables status
```
 @haterbj 
It has been many days since you report the issue, so I'll just close it, please reply if your issue still exists.
  Good point, please feel free to send a PR.
  @spacejam Thanks for your report! I wonder if all the tikv and pd instances run on the same disk?
@siddontang Please take a look at the pd error message.
 Hi @spacejam 
Can you give us the more detailed PD logs? 

```
2016/08/31 21:02:33 tso.go:154: [error] we haven't synced timestamp ok, wait and retry, retry count 0
```

@huachaohuang seems that etcd doesn't start ok? 
 ```
2016/08/31 21:02:33 cluster.go:293: [info] cache all 8 stores cost 213.329µs
2016/08/31 21:02:33 cluster.go:329: [info] cache all 2 regions cost 446.793µs
```

These logs shows that PD should have finished its initialization. 
Before that, PD will response `cluster is not bootstrapped`, which is fine.
@spacejam Can you provide the logs of PD and TiDB when TiDB hangs?
  LGTM
Thanks! @foobar 
 LGTM
  @qetee TiDB is in beta3 stage now.  We hope we could make it stable but there is no guarantee. So we do not encourage you to use TiDB in the production environment.
There will be two or three RC versions before the GA version. It will be achieved in the next two or three months.
  ref https://github.com/coreos/etcd/issues/6134
 LGTM
 LGTM
  @huachaohuang 
 @qiuyi21 May I have your TiDB/PD's git version?
 @qiuyi21 May I have your completed log of TiDB?
 It seems that you are using out of date code. Please use the latest code for TIDB/TiKV/PD

➜  tidb git:(master) ✗ git log | grep -A 5 8169806756ae65d605bc65e97bdd8edec17af66c
commit 8169806756ae65d605bc65e97bdd8edec17af66c
Author: Shen Li shenli3514@gmail.com
Date:   Sat Jul 30 12:08:36 2016 +0800

```
*: Use prometheus for metrics (#1525)
```
 @qiuyi21 Have you run TiDB cluster successfully?
   @BusyJay @shenli @tiancaiamao PTAL
 LGTM
 @BusyJay PTAL
  when the condition is a false constant, the table scan will be "dummy" and return nil, nil forever.
@shenli @coocood @zimulala @XuHuaiyu @tiancaiamao PTAL
 Should we consider false constant in having clause? For example: select count(c), c from t having 0;
 LGTM
 LGTM
  👍, Looks good to me, @foobar could you add some unit tests to cover it? 
 Good job. @foobar 
 LGTM Thanks! @foobar 
 @foobar May I have your email address?
  @foobar Thanks for your feedback! Could you send us a PR to fix it?
 @foobar Cool!
  @shenli @hanfei1991 @coocood @zimulala @tiancaiamao PTAL
 LGTM
 I add support to DELETE in this PR, PTAL
@coocood @shenli @zimulala @tiancaiamao @hanfei1991 
 LGTM
 PTAL @hanfei1991 
 LGTM
  ```
2016/08/15 19:59:38 domain.go:94: [info] [ddl] loadInfoSchema 24
2016/08/15 19:59:38 session.go:570: [info] New txn:385682604891832320 in session:3
gc 729 @72.836s 0%: 0.010+4.5+0.31 ms clock, 0.087+4.2/8.7/18+2.5 ms cpu, 71->72->48 MB, 73 MB goal, 8 P
gc 730 @72.921s 0%: 0.016+9.7+0.32 ms clock, 0.13+7.1/16/18+2.6 ms cpu, 95->95->69 MB, 97 MB goal, 8 P
gc 731 @73.036s 0%: 0.012+8.5+0.30 ms clock, 0.097+14/16/32+2.4 ms cpu, 134->134->80 MB, 137 MB goal, 8 P
gc 732 @73.123s 0%: 0.028+13+0.32 ms clock, 0.22+13/27/27+2.6 ms cpu, 156->157->91 MB, 160 MB goal, 8 P
gc 733 @73.292s 0%: 0.010+16+0.33 ms clock, 0.083+23/30/46+2.6 ms cpu, 178->179->120 MB, 182 MB goal, 8 P
gc 734 @73.434s 0%: 0.026+18+0.28 ms clock, 0.20+13/36/58+2.2 ms cpu, 233->234->139 MB, 239 MB goal, 8 P
gc 735 @73.653s 0%: 0.008+27+0.31 ms clock, 0.071+31/54/62+2.5 ms cpu, 272->274->176 MB, 279 MB goal, 8 P
gc 736 @73.947s 0%: 0.037+31+0.27 ms clock, 0.30+16/62/116+2.2 ms cpu, 340->344->217 MB, 349 MB goal, 8 P
gc 737 @74.266s 0%: 0.010+63+0.39 ms clock, 0.082+34/126/74+3.1 ms cpu, 418->423->267 MB, 428 MB goal, 8 P
gc 738 @74.647s 1%: 0.011+52+0.28 ms clock, 0.094+28/104/161+2.2 ms cpu, 511->520->319 MB, 524 MB goal, 8 P
gc 739 @75.115s 1%: 0.009+63+0.31 ms clock, 0.072+32/125/240+2.5 ms cpu, 606->611->398 MB, 621 MB goal, 8 P
gc 740 @75.693s 1%: 0.053+79+0.32 ms clock, 0.42+0.033/159/325+2.6 ms cpu, 767->775->480 MB, 786 MB goal, 8 P
gc 741 @76.647s 1%: 0.051+93+0.31 ms clock, 0.41+27/186/365+2.5 ms cpu, 922->939->590 MB, 946 MB goal, 8 P
gc 742 @77.558s 1%: 0.010+175+0.35 ms clock, 0.081+17/349/264+2.8 ms cpu, 1120->1135->721 MB, 1148 MB goal, 8 P
gc 743 @78.696s 1%: 0.068+144+0.33 ms clock, 0.54+68/289/524+2.6 ms cpu, 1380->1404->876 MB, 1415 MB goal, 8 P
2016/08/15 19:59:45 session.go:611: [info] RollbackTxn for session close.
2016/08/15 19:59:45 server.go:197: [info] close conn: 127.0.0.1:42709, status: 2, charset: utf8, user: root, lastInsertId: 0
gc 744 @79.934s 1%: 0.009+175+0.30 ms clock, 0.072+117/340/606+2.4 ms cpu, 1662->1689->1062 MB, 1704 MB goal, 8 P
2016/08/15 19:59:45 session.go:611: [info] RollbackTxn for session close.
2016/08/15 19:59:45 txn.go:131: [warning] [kv] Rollback txn 385682604891832320
2016/08/15 19:59:45 server.go:197: [info] close conn: 127.0.0.1:42710, status: 0, charset: utf8, user: root, lastInsertId: 0
gc 745 @83.561s 1%: 0.079+5.5+0.35 ms clock, 0.63+2.6/10/12+2.8 ms cpu, 2021->2022->36 MB, 2073 MB goal, 8 P
gc 746 @83.813s 1%: 0.009+5.4+0.31 ms clock, 0.075+1.8/10/10+2.4 ms cpu, 70->71->36 MB, 72 MB goal, 8 P
gc 747 @83.951s 1%: 0.005+5.8+0.25 ms clock, 0.045+4.3/8.1/10+2.0 ms cpu, 71->71->36 MB, 73 MB goal, 8 P
gc 748 @84.088s 1%: 0.008+5.5+0.28 ms clock, 0.069+3.4/8.8/11+2.3 ms cpu, 71->71->36 MB, 72 MB goal, 8 P
gc 749 @84.222s 1%: 0.008+5.1+0.27 ms clock, 0.066+2.8/8.0/7.1+2.2 ms cpu, 71->71->36 MB, 72 MB goal, 8 P
```

TiDB can't free objects before a session finish, thus GC can't keep pace with the speed of garbage generated, so it run out of memory...
 There is a argument you should change. Which will decide the size of data for a transaction. @tiancaiamao 
  LGTM
@yangxuanjia Thanks for your PR!
 LGTM
  Thank you for your report, We will support "load command" later in the next two weeks.
Currently you may use mysqldump  to dump data from MySQL, then use mysql client to import data to TiDB.
 @foobar @terryzhao 

We just supported the "Load data" command :)
   @shenli @tiancaiamao @BusyJay PTAL
 @shenli PTAL
 LGTM
 LGTM
  You can use [this script](https://github.com/pingcap/tidb/blob/master/updatedep.sh) to update repo in the vendor. It will update Godeps.json automatically.
 @shenli  This script  is only for kvproto package, what he want is the master pd-client commit,  it is better to update Godeps.json instead of using branch commit.
 LGTM
 LGTM
  @tiancaiamao PTAL
 Ident is important, otherwise when file edited by others, it's confused to figure out what's changed.
rest LGTM
 LGTM
 LGTM
  There is no need to keep embed driver, Since we support MySQL protocol.
We should remove https://github.com/pingcap/tidb/blob/master/driver.go
 Ping @coocood 
 @Unknwon TiDB can listening on local socket, if you use TiDB as an embeddable database, TiDB doesn't need to listen on any ports.
 @ngaut There is still a few tests depend on driver. I will update those tests. Hope it could be done in this week.
 Hi @tboerger, you can still use TiDB as an embed database. TiDB acts as MySQL server by listening on unix socket or network socket. To making things simple and clean, users should use any of MySQL drivers.
 Yes. @Unknwon  @mjmfighter  We do not intend to be an embedded database. So there is no solution.  @flike 
'parser.go' is generated by 'make parser' command.
We recently updated our parser generator to `github.com/pingcap/goyacc`.
Have you tried run 'make' command again? It will regenerate the parser.
   Sometimes we want to debug internal data structures,. we need a simple way to get internal information.
 We have inspectkv tools. @zimulala 
 Yep，but we only have some simple functions like `show DDL info` now. It's better to list the specific requirements, so that we can gradually realize it in the inspectkv tools. 
 We don't use debugger at all, it's hard to debug a distributed system with a debugger. Log and distributed tracing tools are very helpful. You can try the IDE for golang from jetbrain. It could analyze interface and its implementations in realtime.  GDB sucks for Go, you may like this https://github.com/derekparker/delve for command line debugging, but @ngaut is right, actually.  @coocood @zimulala @BusyJay 
 @coocood PTAL
 PTAL @zimulala 
 LGTM
  This PR is mainly done by @v01dstar 
Fix bugs founded in POC.
"If you want to insert binary data into a string column (such as a BLOB column), you should represent certain characters by escape sequences. "
So we need unescape string literal in parser.

References: 
http://dev.mysql.com/doc/refman/5.7/en/string-literals.html
https://github.com/mysql/mysql-server/blob/e0e0ae2ea27c9bb76577664845507ef224d362e4/sql/sql_lex.cc#L983
 LGTM
 @zhangjinpeng1987 PTAL
  @hzmangel Thanks for your PR.
@coocood PTAL
 LGTM
 LGTM
@hzmangel Thank you!
  @geekard We have tested running zabbix on TiDB a few month before. It works. But we do not satisfied with the speed. 
We are improving the performance of TiDB.  You can try the latest master. If you meet any problem, please raise an issue or send us a PR.

BTW: We encourage describing issue in English.
 @geekard I change the title to English. Hope you don't mind. :)
Please let us know if you meet any problem.
 If you use TiKV as storage engine, I recommend you deploy TiDB/TiKV on machines with SSD disk. 
 May I have your Zabbix version? @geekard 
 Thanks for your report. We will fix it later.
 @geekard Sorry for the late reply. It is a bug in our parser. We miss "grant all privileges" syntax. It is fixed in this PR: https://github.com/pingcap/tidb/pull/1417

BTW:  You should add quote mark for username and host. For example:
grant all privileges on zabbix.\* to 'zabbix'@'localhost' identified by 'password';
 @geekard There is a few query with subquery and join which may run slow in TiDB.  We are working on impoving them. 
If there is any performance improvement. I will let you know.
May I have your zabbix verson? I will test it on my machine.
 @geekard Thanks!
 @geekard  We add a new sql optimizer in TiDB. The performance benefits a lot from it. 
The new optimizer is not finished yet, so it is not the default sql optimizer. You can enable it by passing an argument to tidb-server.
"docker run --name tidb-server -d -p 4000:4000 pingcap/tidb:latest   --newplan=1"
On my machine, displaying 'Status of zabbix' costs less than one second. Please try the latest master.
 @geekard Thanks for your trying.
TiDB does not support partition/view/procedures. 
For a distributed database, we do not need explicit partition.
Implement view and procedures will bring some problems. So We are not sure whether we will support them.

Could you show me TiDB's error log for the following problem?

> % mysqlimport --local --fields-terminated-by=, --fields-enclosed-by="'" --fields-escaped-by=/ -h 127.0.0.1 -P 4000 -u root zabbix_server valuemaps.txt
> mysqlimport: Error: 1105 line 1 column 36 near ";"
 @geekard Thanks!

I will fix the following bug.

> [warning] compiling /!40101 set @@character_set_database=binary */;, error: line 1 column 36 near ";"

After reading [MySQL's document about partition](https://dev.mysql.com/doc/refman/5.7/en/partitioning-overview.html) I have an idea. Maybe we could ignore the PARTITION keyword, it will do no harm.
TiDB will automatically partition data into many slices. I will have a try.
 Hi @geekard:
 We just supported the "Load data" command in the master branch.
  @lordk911 In one word, TiDB is an OLTP database and hawq/gpdb is OLAP database. 
To handle large dataset, TiDB supports mpp. But we will focus on OLTP now and only support simple OLAP function.

PS: We encourage describing issue in English. So people from all the world could read your issue.  
  @huangpeilong Thanks for your report!
TiDB is a pure go project. You can use any method which is work for go to debug it.
For example [GDB](https://golang.org/doc/gdb).
 I'm not familiar with liteIDE, but [Delve](https://github.com/derekparker/delve) should work.
Maybe you can try it on command line:

```
cd $GOPATH/src/github.com/pingcap/tidb
ln -s _vendor/vendor vendor
dlv test .
b tidb_test.go:168
r
c
```
 We are developing TiDB on linux or mac. And we haven't test it on windows. It may works on windows, but i am not sure. And you are welcome to make TiDB work on windows. 
 You can build the tidb-server first by "make server". It will create a binary file tidb-server in the directory tidb-server. Then you can debug it. @huangpeilong 
 We use vendor to solve golang's dependency. When running "make server", it will add soft link for vendor directory. Seems it does not work on Windows. See: https://github.com/pingcap/tidb/blob/master/Makefile#L138 

We suggest running TiDB on Linux/Mac and do not guarantee all the things work on Windows.
Could you send us a PR to fix it?
 PR is short for Pull Request. @huangpeilong 
It means sending us a patch for a feature or bug.
 @huangpeilong We updated pingcap/pd repo, but did not update pingcap/tidb repo. It seems that your tidb-server is built with pd in GOPTAH, not in vendor directory. Please try this solution:
Rollback pingcap/pd in your GOPATH to commit version 3fe05c948c17bdd18fc2cc7acf62e699f20b0583 

I will update tidb's vendor and fix this problem soon.
  Since we've already launched the beta, there must be some guys who want to have a try, if we provide a binary distro and some handy scripts, that would be easier for others to use.
 - [x]  Linux / OS X binary package, tar.gz
- [ ]  Debian package .deb, support apt-get
- [ ]  CentOS / Fedora package, .rpm
- [ ]  Docker image
 Should also consider rpm package for Centos and Fedora.
 @overvenus Great to hear that! I will test it on my machine.
  @queenypingcap
 LGTM
 LGTM
  @jserv Thanks for your report!
 I will fix it.
 @jserv The apache-2.0 license is in the root directory.  See: https://github.com/pingcap/tidb/blob/master/LICENSE
LICENSES is use to store the license of the projects we used in TiDB. 
  @duzhanyuan What's the purpose of this PR?
  @hzmangel Thanks for your PR!  Please sign the CLA.
@iamxy PTAL
 This is really a flaw. thanks to @hzmangel !
LGTM
 LGTM
Thanks @hzmangel 
  https://github.com/pingcap/tidb/issues/310
 LGTM
 @coocood PTAL
 LGTM
  LGTM
Thanks! @hnakamur 
 LGTM. Thank you very much @hnakamur 
  LGTM
 LGTM
Thank you!
  LGTM @ZombieHippie Thank you very much.
 LGTM
 @ZombieHippie Thanks for your contribution!
  1. Move some functions from evaluator package to types package.
2. Support add, div in xapi.

@coocood @BusyJay 
 LGTM
 LGTM
 @BusyJay PTAL
 LGTM
  Spark has MySQL connector, TiDB should works since TiDB compatible with MySQL.  But we need to do some tests.
 Good idea! I will do  this.
 @ngaut TiDB works fine with Spark through jdbc.
I will compare the performance of TiDB and TiDB+Spark.
 Cool
 @kobebry80 For small or medium size data set, TiDB beats Spark. For big data set or extremely sql, Spark is better.   LGTM
 @c4pt0r It looks like that you do not sign the CLA.
 @ngaut @c4pt0r PTAL
 LGTM
 LGTM
  @litao-buptsse You can use any java mysql client to connect to TiDB.
 If you meet any problem, feel free to raise an issue or submit a PR.  @litao-buptsse 
  @moguding Thanks for your report!
Can you run "make parser" and show me the output? If it success, please try to make again.
 @moguding Great! Please feel free to contact us when you meet any problem with TiDB/TiKV. Thanks!
  @SuperGod Thanks for your reporting. Could you send a PR to fix this ?
  PTAL @coocood @shenli 

Fix string unquote bug:

SQL like: SELECT 'test"test'; can be executed correctly.

Originally, 'test"test' will be converted into "test"test" which will cause the parsing error.
 PTAL @shenli @coocood 
 Well done！
LGTM
 LGTM
 LGTM
  use a higher resolution image and font for logo
 @ngaut @qiuyesuifeng @iamxy  PTAL
 LGTM
 LGTM
 LGTM
   @AkihiroSuda 
Yes, thank you!
  @liugangnhm Please sign the CLA.
 LGTM
 LGTM
 LGTM
  Please add test case for type inference here: https://github.com/pingcap/tidb/blob/master/optimizer/typeinferer_test.go#L35
 @mrmiywj Thanks for your contribute!

@coocood @zimulala @zxylvlp PTAL
 @mrmiywj 
Can you implement the simple function in stringutil directly?
So we don't have to import the package.
 LGTM
 PTAL @coocood 
 @mrmiywj 
Still use spaces, not aligned.
 @mrmiywj 
`
{reverse}   lval.item = string(l.val)
      return reverse
`
in `scanner.l`
 also missed a tab before line 2567
 @mrmiywj 
The alignment is ok now.
Please resolve the conflict.
 LGTM
Thank you for your contribution!
   @tiancaiamao Do you mean you want to keep your local git repository in an old version?
Why you want to run `godep restore`?
 @shenli PTAL
 LGTM
   LGTM

Please sign the CLA first. 
 sign the CLA done.
 LGTM
   LGTM
 @disksing PTAL
 LGTM
  @tjyang Thanks for your advice! 
We haven't considered about packaging. In most common scenario, TiDB will be deployed together with [TiKV](https://github.com/pingcap/tikv) and [PD](https://github.com/pingcap/pd). So I think it is not enough to just package TiDB. We use docker to make deploy easier.
I am not familiar with software packaging. Will it be a good solution for this scenario?
 > Will TiKV and PB be part of tidb main binary ? if it is not part of same binary that is ok too.

TiDB is a SQL engine with pluggable storage engine. It can work with local storage engine (such as goleveldb) or distributed storage engine (such as [TiKV](https://github.com/pingcap/tikv), Hbase). TiKV is a distributed KV engine written in rust. It is the best choice for TiDB. We will use TiKV as storage engine for TiDB in production environment. TiDB and TiKV will be deployed as separated process, not in the same binary. [PD](https://github.com/pingcap/tikv) acts as the administration node for TiKV. We also have a admin tool to config and deploy TiDB/TiKV/PD.

So our Ti storage solution contains three components. I think docker is a better solution. Especially TiKV depends on [RocksDB](https://github.com/facebook/rocksdb) which depends on gcc/clang with C++11 support, gflags, snappy and so on. Docker will make the deployment easier.
 @tjyang 
Thank you for your advice.
Supporting multiple OS is good, but it requires more development and testing resource.
Currently, we only support Linux, and Docker is the recommended way to deploy our system.
We will consider native packaging solution when we need to support multiple OS.
  pass mysqltest and remove visitor design pattern
  @elffikk Thanks for your report!
May I have your mysqldump version? And your dumped file.
It seems that the log is not only part of the panic output log. Can you show me more?
  @tjyang Thanks for your feedback!
Vitess is a MySQL sharding solution. It runs as a MySQL proxy. So you need to put MySQL server behind vitess. It does not support distributed transactions.
TiDB is a brand new distributed database which support mysql protocol and syntax. It is a MySQL drop-in replacement. You can enjoy horizontal scalability without losing distributed transactions.
 @tjyang OK! Thanks for your report. Please keep eyes on TiDB.
  LGTM.
 LGTM
 Thank you very much! @liubin 
  LGTM
 LGTM
  @bitcubate Thanks for your report!
"git -C checkout version" is a temporary solution to make etcd compatible with grpc. The "-C" parameter maybe not supported by old git client.
We will remove this when etcd compatible with the latest grpc.
  @shenli 
 LGTM
 LGTM
  @zyguan Thanks for your report!
Have test this case on MySQL in strict mode?
 In strict mode, warning will be treated as error. 
"1 row in set, 1 warning (0.00 sec)"

http://dev.mysql.com/doc/refman/5.7/en/sql-mode.html#sqlmode_allow_invalid_dates
  @zyguan Thanks for your report!
  @insionng Thanks for your feedback.
For performance issue, we allocate auto_increment id in a batch way(batch size is 1000).
For example if two sessions are insert data in the same time and the global auto_increment id is 0. One session will get id range 1~1000, the other session will get id range 1001~2000. So for the second session, it will use ids from 1001.
In brief, TiDB guarantee allocate increment ids but not continuous increment ids.
So I guess you insert each row with a unique session?
 May I see your schema and SQL statement?
 For each table we have a unique auto_id counter. Its type is int64. So I guess it is OK.
Or we can shrink the batch size. 
 Unfortunately it is a private attribute :( https://github.com/pingcap/tidb/blob/master/meta/autoid/autoid.go#L29
  @coocood @zimulala PTAL
 I think you should do TypeInfer for each function.
 @zxylvlp +1
@zyguan Please refer: https://github.com/pingcap/tidb/blob/master/optimizer/typeinferer.go#L253
 Well done!
LGTM
 LGTM
 PTAL
  In case when executed statements exceeds max int32, the cursor becomes a negative value.
 @nieyy @shenli PTAL
 LGTM
  In bootstrap stage, ps may be not well initialized. We should make it safe.
@nieyy 
 LGTM
   LGTM
 LGTM
  @coocood @zxylvlp PTAL
 LGTM
Thanks @zyguan 
 LGTM
  Rest LGTM
 LGTM
 Unit tests without Seek and UpdateRecord ?
 LGTM
 This branch is out-of-date, Could you rebase master ? @nieyy 
 LGTM
  @zyguan Thanks for your report!
String literal will be wrapped into a ast.ValueExpr.  And you can get charset/collation info from ValueExpr.
https://github.com/pingcap/tidb/blob/master/parser/parser.y#L2008
 @zyguan  Yes, we have a plan to add collation info into datum.
  @zyguan Thanks  for your PR. Please sign the CLA.
 @zyguan I think it is a mistake. Good catch!
 LGTM
@coocood PTAL
 LGTM
Thank you!
 @zyguan Thanks for your contribution! May I have your email address?
 Thank you, This branch is out-of-date, Could you merge or rebase master ? @zyguan 
 Thanks @zyguan
  and add some test
  @ngaut @qiuyesuifeng 
 LGTM
 PTAL @ngaut 
 LGTM
  @steffengy Thanks for reporting the issue. 
Currently we don't have any plans to support foreign-key constraints. Since it would be very slow on big tables( thousands of billion of rows). 
 Yes, you are right. We may let the parser to support the ON [DELETE|UPDATE] syntax later. @shenli 
 @steffengy TiDB can work with Workbench. Have you met any problem when use some db admin tools?
 @steffengy We will support those syntax (at lease prevent parser error).
Thanks for your report! 
 Syntax support is done by https://github.com/pingcap/tidb/pull/1152
   For prepared statement, when a statement has finished execution, all expressions should reset `FlagEvaluated`.
 Any test case to ensure this PR works?
 @shenli  I think it just a optimization of performance, the the logical test cann't do it.
 @coocood @shenli @zimulala PTAL
 @coocood @shenli @zimulala PTAL
 LGTM
 LGTM
   LGTM
 LGTM
   LGTM
 LGTM
  Thanks! @overvenus
@qiuyesuifeng @coocood PTAL 
 LGTM
Please squash your commits to a single commit after you get two LGTM.
 LGTM
 Well done!  @overvenus 
  @overvenus Thanks for your report!  We will add more builtin functions. 
If you are interested in TiDB, would you please send us a PR? We have a tutorial about how to add a new builtin function. We will be appreciated.
 Sorry.... It is my mistake. 
Great! I will take a look!
 @coocood @qiuyesuifeng PTAL
 @overvenus Any update for this PR?
 LGTM
@coocood @qiuyesuifeng 
 @overvenus  Thanks.
LGTM
 LGTM
Thanks! @overvenus 
  This memory table do not has a primary key, every time a statement executed, it adds a new record, the memory table keeps growing.
@nieyy 
  LGTM
@astaxie Thanks a lot!
 LGTM 
   @shenli @zimulala PTAL
 @nieyy @liugangnhm
 @nieyy `indexRangesToPBRangesAndPoints` uses `PartialNext`to convert a range with low/high exclude information to a range with closed low and open high range.
 LGTM
 LGTM
  All known features are added, can be stable for a while.
 @nieyy PTAL
 LGTM
 LGTM
  This issue doesn't have enough information to address.
  - [ ] beego
- [x] xorm
- [x] gorm
- [ ] Hibernate
- [x] iBATIS
- [ ] Spot
- [ ] Propel
- [ ] Sequelize
- [ ] SQLAlchemy
- [ ] peewee
  @cppmule Thanks for your report!
It seems that some of the create_table options are not supported by TiDB. I will fix them.
  @cppmule Thanks for your report!
It seems that some of the create_table options are not supported by TiDB. I will fix them.
  @cppmule Thanks for your report.
May I have your TiDB git commit id and your error log?
I tested the above with the latest master but no error occurs.
 @cppmule I found that TiDB treat "/!40101 SET character_set_client = utf8 */;" as comment but MySQL treat it as "SET character_set_client = utf8". I will fix it.
Is there any other problem?
 @cppmule Please checkout the latest master and check if there is any other problem.
Thanks!
  @belovanton Thanks for your report. Currently, TiDB doesn't support foreign key.
   LGTM
  Good catch, thank you!
LGTM
 LGTM
  LGTM
Thanks @c-wind 
 LGTM
Thank you!
  Yes, those lines can be removed.
Thank you for your report!
Would you please send a PR to fix this?
  @nieyy @coocood 
 @nieyy PTAL
 @nieyy We have a privilege system. So we can grant privilege for those tables. Maybe in the latter PR.
 @nieyy @shenli 

I think privilege should be added in future PR, because the purpose of this PR is refactoring, privilege feature is not implemented in the old code. 

Normally refactoring should not add new features.
 LGTM
 @qiuyesuifeng  PTAL
  @defia You can use go sql driver to access TiDB. 
See: https://github.com/pingcap/tidb/blob/master/docs/USAGE.md
 This is impossible. Why not use tidb-server? You can access it by multiple clients.
  @xialvjun There is a few docs your can refer: https://github.com/tidb-cn/docs https://github.com/ngaut/builddatabase 

Thanks for your feedback. We will improve our documents.
  LGTM
 LGTM @qiuyesuifeng 
 @nieyy Thanks.
LGTM
  1. Add a MemoryTable in tables. It supports AddRecord, RemoveRecord, Truncate, Row, RowWithCols, Seek. Do not support UpdateRecord and Index.
2. Use MemoryTable to implement Information_Schema. We will drop plans/info.go in the next PR.
 PTAL @coocood @qiuyesuifeng @nieyy 
 @nieyy 
For infrequent updates, you can execute SQL statement.
For frequent update, you can maintain the handles of the added records, use that to call `table.Update` method.
 LGTM
 @nieyy we can later implement another table implementation which optimized for instruments.
 LGTM
 LGTM
  LGTM
 @nieyy  Thanks.
LGTM
  @swingbach Have you run "make update"?
  Please fix the failed test in `util/segmentmap/segmentmap_test.go`.
 LGTM
 LGTM
 Thank you!
 @steffengy  Thanks! 
LGTM
 @steffengy Thanks for your contribution. 
May I have your email? We will send a thanks letter to you. And if your are in Mainland China, we will send you a T-shirt.
Or your can contact me by shenli@pingcap.com.
  @steffengy Thanks for your pr.
When use [go-sql-driver](https://github.com/go-sql-driver/mysql) , we can not get column type from its api. So I think it is safer to convert time to string.

@coocood  Please take a look.
 @steffengy 
`time.Time` type does not have all the information `mysql.Time` type has, when user `Scan` the value to `string`, `time.Time` may produce different result than `mysql.Time.String()`.
 @steffengy 

Say we have a test case, we want to make sure the result string for second is "11.1", not "11.100",  then we have to use the column precision 1 to trim the every time value.

And if you want to get the column precision you have to write a SQL statement to query `information_schema`.

Actually, the most flexible type is `string`, you can parse it to any type you want.
 If you really need `time.Time` type, we can add an optional parameter in DSN, like
`goleveldb://test/test?parseTime=true`.

Can you try to implement it?
 LGTM

Great job!
Thank you!
 LGTM
Thanks @steffengy 
  PTAL @shenli @coocood @qiuyesuifeng 
 LGTM
 LGTM
 Thanks @nieyy 
  LGTM
 LGTM
  Thank you @nieyy 
This is a huge PR. And it's hard to review. It should be split into 2 or 3 PRs. You may try to fix it in the following steps:
1. Just refactor 
2. Prepare. 
3. Final part.
  http://dev.mysql.com/doc/refman/5.7/en/secure-connections.html
 @elvizlai We will consider this after GA.  LGTM
  @losas Thanks for your PR. Please add an unit test.
 @losas There is a test case in session_test.go. https://github.com/pingcap/tidb/blob/master/session_test.go#L746

 Your can compose a similar test case. You need to do something to make getPassword() throw error. I take a look at the code and find that if you set a value to session(or ctx), ExecRestrictedSQL() will return error. getPassword() will call ExecRestrictedSQL. So I think it is what we need.
https://github.com/pingcap/tidb/blob/master/session.go#L266

Hope this helps. If your need more information, please let me know.
 @losas Yes, this is a much smarter way than mine! Good job!
LGTM
@coocood @qiuyesuifeng  PTAL
 LGTM
Thank you!
  Thank you for your report, I'll fix the `splitWhere` bug, and also use multiple columns in a composite index.
 Cool, could you send a PR to fix it ? @roger-lijian 
 After a recent refactoring, multi-column index only uses the first column.
 @roger-lijian PTAL
  @zxylvlp Thanks for your advice.
We will add some docs for contributors.
 @zxylvlp 
You can find some docs here: https://github.com/tidb-cn/docs
It is a starting and more docs are on the way.
  LGTM
 LGTM
Thanks for your PR!
  LGTM
 I think we should update `CONTRIBUTING.md` link in README.
 @astaxie  Thanks.
LGTM
 Hi @astaxie 
There are links in `CONTRIBUTING.md` need to be updated too :)
 Thanks! @astaxie 
LGTM
  Thanks @astaxie 
Please take a look https://github.com/pingcap/tidb/blob/master/docs/CONTRIBUTING.md
 SGTM.
Thanks @astaxie 
  Thanks for your report @roger-lijian 
PTAL @shenli 
 @roger-lijian Thanks for your report!
I find the bug. MySQL return TypeVarString for TypeVarChar. The conversion  is handle in our old code. When we refactor our code, it is missed. I will add it back.
https://github.com/pingcap/tidb/blob/master/field/result_field.go#L79
  Well done. @AkihiroSuda 
PTAL @shenli 
 LGTM
Thanks! @AkihiroSuda 
 LGTM
  Hi, @lovedboy.

I think this change doesn't make code more clear, and this package is legacy code, we will discard it in the near future.

But thank you for your effort trying to contribute.
  LGTM
Well done!
 LGTM
 Thanks @hhkbp2 
  @joelchen Thanks for your advice!
Concourse has many interesting features. And some of the features are already supported by TiDB such as ACID transaction, Query data from the past. 
But currently we will focus on OLTP. Automatic Indexing and Schemaless are not on our roadmap.
 TiDB support online schema change. DBAs can modify schema and index without downtime. I think DBA managed schema (including index) is more suitable for enterprise usage. 
Self-tuning is an attractive feature, but it may bring more uncertainty. For example automatic indexing may cause more space usage and slow down insert/update/delete operations. And schemaless is convenient sometimes but it may also cause error-prone codes.

So it is not on our plan now. But TiDB is involving rapidly. We will keep eyes on Concourse and learn from it. Maybe we will provide similar feature in the future. Thanks!
  Thanks for your feedback! @AkihiroSuda 
In TiDB's design, we  have a load balancer between client and tidb node. https://github.com/pingcap/tidb/blob/master/docs/architecture.png

You can use a load balancer such as LVS or HAProxy to connect to TiDB cluster.
  @nieyy Good idea. 
Yes, we have plan to do that. But we haven't started yet.
And we are happy to  discuss the design :)
 @nieyy Glad to hear that. Currently we are working on optimizing query plan (condition push down, parallel executing and even more). Obviously we need more and more help to make TiDB better. And welcome to join the technical party.
  @teodor-pripoae Thanks for your report. We will work on this.
 Great!
I go through TiDB source code and make sure that we return the same error code as MySQL for duplicate entry error (1062). So I suspect that gorm judge error no only by error code.
 @teodor-pripoae We find there is a bug in gorm. It ignores error of db.Commit(). See https://github.com/jinzhu/gorm/blob/master/scope.go#L383
In TiDB duplicate entry is checked at commit stage, so the error is logged at TiDB log but ignored by gorm.
We are going to send a PR to gorm.

Thanks!
 @teodor-pripoae It should be fixed. Please update your gorm and check again. Thanks.
 @teodor-pripoae That pr will not work.
TiDB use lazy check for unique index. https://github.com/pingcap/tidb/blob/master/kv/kv.go#L21
The job is finished at commit stage by the storage layer for performance consideration(We want to check duplication in a batch way). 
The interface between sql layer and storage layer is not rich enough to pass information such as index name and original key data (we only got encoded key at storage layer). So we do not get enough information about which key is duplicate at the place where the error rise.

We will figure out how to show rich information in the error message recently. Thanks!
 @teodor-pripoae We find a way to solve this. See the PR above please.
  Thanks for your report. @hhkbp2 
It's a dependency issue. You may run "make update" to fix it. We will remove HBase dependency or using godeps to manage dependency later.
  LGTM
 LGTM and thanks for your contribution @c-wind !
 LGTM
@c-wind  Thanks very much!
  I think it's easier to understand it by a simple example.
Take a look at
https://github.com/pingcap/tidb/blob/master/executor/prepared.go#L50

The `paramMarkerExtractor` visitor extracts parameter markers ('?') in a query statement.
When a node call its `Accept` method, every element will be `Enter` and `Leave` once, so the visitor can do something about it. For this example, it collect parameter marker.
  @nieyy Thanks for your report.
We are writing documents for Tidb. KV encoding/decoding is on the schedule. I think it won't be long.
 Hi @nieyy ,
You are right about the 3 CFs. They are indeed created and used by Themis. Please refer https://github.com/XiaoMi/themis and https://github.com/pingcap/go-themis for more details.
 Hi @nieyy ,
In brief, `util/codec` provides a series of functions that can encode values into mem-comparable `[]byte`. How structured data in RMDBS are transformed to key-value pairs are mainly in package `table/tables` and `kv`. You may trace function calls to `codec` functions to get the clue. : )
  Currently, interfaces in kv and store package are too complicated and disordered. It is very hard to implement a new storage engine for TiDB.

I plan to make it easier with following steps:
1. Simplify local store and hbase store. Storages should implement as less interfaces as possible.
2. Refine interfaces. Distinguish interfaces that should be completed by storages from those are already complete in kv.
3. Write a guide document.
  Please do "make update" to update your dependency. Then make again.
 please `rm -rf  /tmp/tidb` then run again. 
 I think this panic is probably due to the `"listen tcp :4001: bind: address already in use"`. In that case, server creation will fail. You need to make sure no other thread is using port `4001` because the test suite will take up this port.
  @orangeyts TiDB depends on golang. So I think TiDB can run if you setup your golang environment properly on Windows. 
 OK! @orangeyts 
Please feel free to raise an issue if you encounter any problem.
 @orangeyts `GOPATH` is your workspace path. It should be set uniformly across all go projects in your machine. Please reference [this](https://golang.org/doc/code.html) doc for more details. Once you have setup your `GOPATH`, you can put `tidb` in `$GOPATH/src/github.com/pingcap/`.
  @sllt Thanks very much.
LGTM
 LGTM
Thanks! @sllt 
  @hhkbp2  Thanks very much.
@coocood  @zimulala  PTAL
 @hhkbp2 Thank you very much, please format the file you modified with 'go fmt`, otherwise, the Travis CI build would fail.
 @hhkbp2 The existing test cases are copied from `expression/date_arith_test.go` and the function is implemented in `expression/data_arith.go`. The reason why this is not working right now is that `evaluater.go` didn't migrate the old code. 

You can reference the old implement to make test cases pass with out changing it.

In TiDB, we enforce strict mode, so when data is truncated, it returns error instead of warning.
 @hhkbp2 The old `expression`, `plan/plans`, 'stmt/stmts' package has limited capability for optimization, and it can not be improved due to the design problem, but it supports all types of statements.
The new `optimizer/plan`, `executor` package has better support for optimization, but supports limited type of statements, we are supporting more statement on new plan, but for the statements we han't supported in new plan, we need to run it in the old way.
So there are a lot of duplicate code right now.
When new plan supports all the statements, old 'expression`,`plan/plans`,`stmt/stmts` package can be abandoned.
 @hhkbp2 Any updates?
 PTAL @coocood @siddontang 
 LGTM
 LGTM
Well done!
 LGTM
  @keithyau 
There are a few docs in tidb/docs.
https://github.com/pingcap/tidb/blob/master/docs/QUICKSTART.md
https://github.com/pingcap/tidb/blob/master/docs/HBASE_QUICKSTART.md
https://github.com/pingcap/tidb/blob/master/docs/USAGE.md
 @keithyau May I have your golang version? You can get it by "go version".
 We need golang version >= 1.5. Please upgrade your golang.
“Go environment. Currently a 64-bit version of go >= 1.5 is required.”
 @keithyau Thanks for your report.
Yes, tidb can run well on Mac OS.
Could u show some more details? including the lastest commit version and the whole `make` output.
Also u can send an email to cuiqiu@pingcap.com.
 @keithyau
This error message shows a test case failed. In that test case we init the privilege table for test@'127.0.0.1'/'localhost'/'::1'. But it seems that when the case run on your machine, it use another ip address to connect to the server. So the auth failed.
So it is a bug in test case. I will fix this.
 @keithyau I just pushed a new branch shenli/fix-server-testcase to fix this. Would you please checkout this branch and check if it is ok?
Thanks!
  LGTM
 LGTM
 Thanks @roger-lijian 
  2015/12/14 22:04:49 session.go:395: [error] Syntax error: SELECT name, type FROM mysql.proc WHERE Db='test'
2015/12/14 22:04:49 session.go:396: [error] Error occurs at [schema:2]table mysql.proc does not exist.
2015/12/14 22:04:49 conn.go:240: [error] dispatch error /Users/shenli/workspace/go/src/github.com/pingcap/tidb/infoschema/infoschema.go:109: [schema:2]table mysql.proc does not exist
2015/12/14 22:04:49 conn.go:241: [error] cmd: SELECT name, type FROM mysql.proc WHERE Db='test'
2015/12/14 22:04:49 tidb.go:136: [warning] compiling SHOW PROCEDURE STATUS WHERE Db='test', error: line 1 column 6 near "PROCEDURE"
2015/12/14 22:04:49 session.go:395: [error] Syntax error: SHOW PROCEDURE STATUS WHERE Db='test'
2015/12/14 22:04:49 session.go:396: [error] Error occurs at line 1 column 6 near "PROCEDURE".
2015/12/14 22:04:49 conn.go:240: [error] dispatch error line 1 column 6 near "PROCEDURE"
2015/12/14 22:04:49 conn.go:241: [error] cmd: SHOW PROCEDURE STATUS WHERE Db='test'
2015/12/14 22:04:49 tidb.go:136: [warning] compiling SHOW PROCEDURE STATUS WHERE Db='test', error: line 1 column 6 near "PROCEDURE"
2015/12/14 22:04:49 session.go:395: [error] Syntax error: SHOW PROCEDURE STATUS WHERE Db='test'
2015/12/14 22:04:49 session.go:396: [error] Error occurs at line 1 column 6 near "PROCEDURE".
2015/12/14 22:04:49 conn.go:240: [error] dispatch error line 1 column 6 near "PROCEDURE"
2015/12/14 22:04:49 conn.go:241: [error] cmd: SHOW PROCEDURE STATUS WHERE Db='test'
2015/12/14 22:05:22 tidb.go:136: [warning] compiling SHOW PROCEDURE STATUS WHERE Db='test1', error: line 1 column 6 near "PROCEDURE"
2015/12/14 22:05:22 session.go:395: [error] Syntax error: SHOW PROCEDURE STATUS WHERE Db='test1'
2015/12/14 22:05:22 session.go:396: [error] Error occurs at line 1 column 6 near "PROCEDURE".
2015/12/14 22:05:22 conn.go:240: [error] dispatch error line 1 column 6 near "PROCEDURE"
2015/12/14 22:05:22 conn.go:241: [error] cmd: SHOW PROCEDURE STATUS WHERE Db='test1'
 2015/12/14 22:12:36 conn.go:240: [error] dispatch error /Users/shenli/workspace/go/src/github.com/pingcap/tidb/expression/binop.go:124: eval Tables_in_test = "t1" && Table_type != "VIEW" err: eval Tables_in_test = "t1" err: unknown field tables_in_test
2015/12/14 22:12:36 conn.go:241: [error] cmd: SHOW FULL TABLES FROM `test` WHERE `Tables_in_test` = 't1' AND Table_type != 'VIEW'
 Can we close this issue?
 Reopen the issue, Thanks @AkihiroSuda 
 @AkihiroSuda Are you working on this issue ?
 @AkihiroSuda I am agree with you. We will work on this. 
If you can send us a PR, we will be appreciate.
  LGTM
 LGTM
 Thank you for your contribution!
 @nieyy Happy to hear that!
 @nieyy  Cool, looking forward!
  @keithyau Try this: 
mysql> grant all on _._ to 'root'@'%' identified by '123';

I will add "all privileges" syntax support.

Thanks for your report!
 mysql> grant all on _._ to 'root'@'%' identified by 'thomas';
Query OK, 0 rows affected (0.00 sec)

Each of your three statements has a few synatx errors.
1. user name should be 'name'@'host' (Do not miss the quote), 
2. and 3. target should be _._
 Pleas replace '.' with *.* or databasename.tablename in your statement. 
  @keithyau Thanks for your report!
We will work on this issue.
 @keithyau There is a system variable "max_connection".
For now we do not have a config file. You can modify it by set system variable(set name=value). Or you can change the default value for variables in mysql.global_variables table.
 http://stackoverflow.com/questions/1676688/php-mysql-connection-not-working-2002-no-such-file-or-directory

@keithyau About your Error 2002, please take a look at the best answer.

If you have solved Error 2002, could you post your php code briefly? I doubt it may be some network problem instead of configure variable.

I try this code on my OSX it is ok.

```
$mysqli = new mysqli("localhost", "root", "", "test", 4000);
```

Hope your reply.
 @keithyau 
If you start tidb with tidb-server, you can see the logs in stdout. If you start tidb with docker, you can see the logs with docker logs.
 @keithyau I am not sure. I am installing drupal on my machine to check it out.
 @keithyau I get the following errors when install drupal. But I do not find error log from tidb-server output. Do you have any idea about this? I use the latest drupal 8.0.1.

_drupal_error_handler_real(4096, 'Argument 1 passed to Drupal\Core\Plugin\DefaultPluginManager::doGetDefinition() must be of the type array, boolean given, called in /Library/WebServer/Documents/drupal/core/lib/Drupal/Component/Plugin/Discovery/DiscoveryCachedTrait.php on line 30 and defined', '/Library/WebServer/Documents/drupal/core/lib/Drupal/Component/Plugin/Discovery/DiscoveryTrait.php', 48, Array)
_drupal_error_handler(4096, 'Argument 1 passed to Drupal\Core\Plugin\DefaultPluginManager::doGetDefinition() must be of the type array, boolean given, called in /Library/WebServer/Documents/drupal/core/lib/Drupal/Component/Plugin/Discovery/DiscoveryCachedTrait.php on line 30 and defined', '/Library/WebServer/Documents/drupal/core/lib/Drupal/Component/Plugin/Discovery/DiscoveryTrait.php', 48, Array)
Drupal\Core\Plugin\DefaultPluginManager->doGetDefinition(, 'user_role', )
 @keithyau I am working on this.
 @keithyau filename is the pk of system table. And I see drupal insert two rows with the same filename value "modules/system/system.module". From the log I can find two insert statement both with the "modules/system/system.module" row. The first is "INSERT INTO main_system (filename, name, type, owner, status, schema_version, bootstrap) VALUES ('modules/system/system.module', 'system', 'module', '', '1', '7080', '0')". The second one is a huge sql which insert many rows: "INSERT INTO main_system (filename, name, type, owner, info) VALUES ('modules/update/tests/aaa_update_test.module', 'aaa_update_test', 'module', '',......('modules/system/system.module', 'system', 'module', '', 'a:14:{s:4:\"name\";s:6:\"System\";s:11:\"description\";s:54:\"Handles general site configuration for administrators.\";s:7:\"package\";s:4:\"Core\";s:7:\"version\";s:4:\"7.41\";s:4:\"core\";s:3:\"7.x\";s:5:\"files\";a:6:{i:0;s:19:\"system.archiver.inc\";i:1;s:15:\"system.mail.inc\";i:2;s:16:\"system.queue.inc\";i:3;s:14:\"system.tar.inc\";i:4;s:18:\"system.updater.inc\";i:5;s:11:\"system.test\";}s:8:\"required\";b:1;s:9:\"configure\";s:19:\"admin/config/system\";s:7:\"project\";s:6:\"drupal\";s:9:\"datestamp\";s:10:\"1445457729\";s:5:\"mtime\";i:1450160850;s:12:\"dependencies\";a:0:{}s:3:\"php\";s:5:\"5.2.4\";s:9:\"bootstrap\";i:0;}'),........". You can grep "modules/system/system.module" from tidb-server output.

I tried with mysql and installed successfully. So I think there is some thing wrong with TiDB.
  Thanks for your report.

Please follow the quick start instructions:
git clone https://github.com/pingcap/tidb.git $GOPATH/src/github.com/pingcap/tidb
cd $GOPATH/src/github.com/pingcap/tidb
make
 @kylewolfe You are right. We can make it go getable if we add files that generated by goyacc and golex.
But It do has some downsides if we add those generated files.
It looks ugly  for reviewing when parser.y changed.

We will make it go getable later. 

For now you may still need to do:
make update
make
 @kylewolfe For now you may still need to run "make update" to update related package, than 
make 
  Please pass go lint.
 LGTM
 LGTM
 LGTM
  Hi:
Currently, we don't have any flag to disable pprof. Does it bother you ? Or you just want to change default port number?
 Just set Debug flag to false. @Unknwon 
https://github.com/pingcap/tidb/blob/master/tidb.go#L91
 We need to figure out a better way to handle this if you don't want to patch the source.
We need to keep pporf open for debugging....  
 Nop, we may support it by configuration later.
 LGTM, Could you send a PR ? Thanks.
  LGTM
 LGTM
  Fixed by commit 307993205bb1356be7bcd6ecb0770632fba4b40e
  @denisbertini Thanks for your report.
May I have your source code? Can you connect to TiDB with MySQL command line client?
 I write a test case with MySQL C API and get no error. Could you provide more detailed information?

My source code:  https://gist.github.com/shenli/914c36f7a304db6edf20
Result:
➜  mysql  gcc -I/usr/local/mysql/include -L/usr/local/mysql/lib -lmysqlclient main.c
➜  mysql  ./a.out 
Begin
Connect sucess
End
➜  mysql  mysql -uroot -h127.0.0.1 -P4000 -p
Enter password: 
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 10007
Server version: 5.5.31-TiDB-1.0 MySQL Community Server (GPL)

Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> use test;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
mysql> select \* from Cars;
+------+------+-------+
| Id   | Name | Price |
+------+------+-------+
|    1 | Audi | 52642 |
+------+------+-------+
1 row in set (0.00 sec)
 @denisbertini Would you take a look your `/etc/hosts` file content. You can use `localhost` if `127.0.0.1 localhost`in `/etc/hosts`
  hi @denisbertini Thanks for your report.

TiDB support some of the privilege sql statements such as CreateUser and Grant statement.
You can try statements like "CREATE USER 'monty'@'localhost' IDENTIFIED BY 'some_pass';" and "GRANT ALL PRIVILEGES ON _._ TO 'monty'@'localhost';".
Please refer to mysql reference manual. http://dev.mysql.com/doc/refman/5.7/en/create-user.html  http://dev.mysql.com/doc/refman/5.7/en/grant.html.

Flush statement is not supported now. We will work on it.
  TiDB doesn't support the feature currently. We may reconsider the feature later.
 @lavvy Thanks for your feedback! We do not have plan for this feature now. We may reconsider the feature later. But it will be no early than the end of this year.
  @luyee Thanks for your report.
Fixed! Could you take another retry?
 Fix in https://github.com/pingcap/tidb/pull/668
and https://github.com/pingcap/go-themis/pull/21
 @luyee Good to know, thanks.
  @genedna This pr does not pass ci. You can check the detail here: https://travis-ci.org/pingcap/tidb/builds/93735000.
 Hi @genedna 
using `get -u` may cause make very slow. I think the best way is to using godep for these directly later. 
 Good idea, thanks @Unknwon 
@genedna  Could you support "make update" in makefile ?
  go get -u github.com/pingcap/go-themis 
@Unknwon 
 Thanks @Unknwon 
We will add -u to makefile later.
 @Unknwon Thanks for report.
But these seems only like tracing logs that are about mvcc expired keys clearing :(
Could u redirect these to a log file to show more details?
Also u can send it to me (cuiqiu@pingcap.com).
 Looks like some of concurrent tests takes too long in Raspi. We may reduce  pressure of the concurrent tests.
 Have received the email.
In the file, i see 

```
*** Test killed with quit: ran too long (10m0s).
FAIL    github.com/pingcap/tidb/store/localstore    600.122s

Makefile:111: recipe for target 'gotest' failed
```

In our store/localstor/isolation_test.go, there are two time-consuming tests `TestInc` and `TestMultiInc`.
Maybe we should move these tests out of tidb or reduce the pressure as @ngaut  metioned.
Now u can simply use `make godep && make parser && make build && make check[optional]` instead of `make` to skip the `make test`.

@Unknwon Thanks again.
 @Unknwon  Does the log containing `GC stopped` before too many `GC send key to deleteWorker`, if has, the GC compactor may be blocked when Stop.
  I think we should handle ErrKeyExists in stmts/insert.go 

```
        if len(s.OnDuplicate) == 0 || !terror.ErrorEqual(err, kv.ErrKeyExists) {
            return nil, errors.Trace(err)
        }
```

If ErrKeyExists and not supporting on duplicate update, we should return ErrDupEntry error directly.
Btw, we should use terror for ErrKeyExists later. @shenli 
 @ElvizLai This is solved in https://github.com/pingcap/tidb/pull/828
Thanks for your PR!
  @ElvizLai Thanks for your report. I check the behavior of MySQL. It report which entry is duplicate.
mysql> create table t (c int PRIMARY KEY);
Query OK, 0 rows affected (0.01 sec)
mysql> insert into t values (1);
Query OK, 1 row affected (0.00 sec)
mysql> insert into t values (1);
ERROR 1062 (23000): Duplicate entry '1' for key 'PRIMARY'

We will add more information in error message. 
If you are interested, you can send us a PR. we will be grateful.
  @hhkbp2 There is an error in ci. 
make: /home/travis/gopath/src/github.com/pingcap/tidb/Godeps/_workspace:/home/travis/gopath/bin/goyacc: Command not found
make: **\* [parser] Error 127
See: https://travis-ci.org/pingcap/tidb/builds/92393132
 LGTM
 @hhkbp2  Thanks very much.
LGTM
  @hhkbp2  Do you set correct GOPATH and GOROOT, and append $GOPATH/bin to $PATH?
 @hhkbp2 Thanks for your report.
We will add this to README.md.
 Thanks @hhkbp2 
Could you send us a PR to fix it?
  Thanks for your report, @ElvizLai 
Any more details ?
 Have you commit your transaction ?
 @ElvizLai I tested your code with and then check the db with interpreter tool(mv data dir to interpreter dir and  start interpreter).
The data is ready in the db.
tidb> select \* from a;
+----+----------+----+
| id | name     | pv |
+----+----------+----+
| 0  | ElvizLai | 0  |
+----+----------+----+
1 row in set (0.00 sec)
tidb> select \* from b;
+----+----------+----+
| id | name     | pv |
+----+----------+----+
| 0  | ElvizLai | 0  |
+----+----------+----+
1 row in set (0.00 sec)
  @ruiaylin  In the second statement, t1 is in stmt.Refs.
Delete statement has two mode. 
The first sql is multitable mode, TableIdents is used in this mode to record the table list. Only the row in this table list can not delete.
https://dev.mysql.com/doc/refman/5.7/en/delete.html
The second sql is single table mode, we do not need TableIdents to record table list.
 I add some debug log in parser.y:
@@ -1168,6 +1169,7 @@ DeleteFromStmt:
        {
                // Single Table
                join := &ast.Join{Left: &ast.TableSource{Source: $6.(ast.ResultSetNode)}, Right: nil}
-               fmt.Printf("Delete Stmt TableName: %v, Join.Left: %v\n", $6, join.Left)
              x := &ast.DeleteStmt{
                      TableRefs:      &ast.TableRefsClause{TableRefs: join},
                      LowPriority:    $2.(bool),

And test your case:
➜  interpreter git:(shenli/delete-debug) ✗ ./interpreter 
Welcome to the TiDB.
Version:
Git Commit Hash: 5491086695b6e267bc7a9dda320a5adc435e6734
UTC Build Time:  2015-11-18 07:30:29
tidb> DELETE FROM t1 WHERE id in ( 2,4,5);
Delete Stmt TableName: &{{} {[]}  t1 <nil> <nil>}, Join.Left: &{{} 0xc8200f6100 }

You can see t1 is in Join.Left.
  Thanks @xiaods , how to use with this?
 `mysql -h127.0.0.1 - P4000` can also work? 
 Well done, thanks! LGTM
 LGTM
  See: https://github.com/pingcap/tidb/blob/master/parser/parser.y#L2873
It is a TableSource and the source is a SelectStmt.
  Thanks @xwb1989 
Could you merge your changes to https://github.com/pingcap/tidb/pull/583
 kv.RunInNewTxn need this too. 
 Hi, @xwb1989  
#583 has been merged.
 Hi, @xwb1989 
Could you merge your code to https://github.com/pingcap/tidb/blob/master/kv/txn.go
 @xwb1989  I added back off use the algorithm in your pr to the latest master.
https://github.com/pingcap/tidb/pull/658
So I close this pr.
Thanks for your pr.
  LGTM
 @coocood PTAL
 LGTM
  I'm not sure if it's a better way to setup Intellij IDEA project, but you can set the project folder at the GOPATH folder, then you don't need to modifiy gitignore for IDEA.
 LGTM
 LGTM
  Hi @hanfei19910905  
The string build in functions we have supported are listed here https://github.com/pingcap/tidb/issues/310
You can send us a PR to help us to complete it. 
Thank you :-)
 Hi @hanfei19910905 

We will add some tutorials later.
The query explanation is primitive and simple, later we will improve it. 
 Em, maybe later. 
@ngaut 
 Let's finish tutorials first.
  Hi, @urandom 
We might support $N placeholders later.
 This is not MySQL syntax, it will be supported when PostgreSQL syntax is supported.
Close this issue for now.
  Thanks. @netroby 
Please change "c *Col" to *Col
 LGTM
 LGTM
Thanks @netroby 
  To make "go vet" happy.
  LGTM
 LGTM
  Hi @netroby , the docker environment should be the same as production environment, so we should use official golang image or popular ubuntu/debian/fedora, etc.
We don't care image size too much. 
 Hi, @netroby :
 Could you use golang as default image ? 
It would be more convenient to run it, test it or even try to patch it. Thanks
  I'm sorry, this issue is not accepted.
  Yes, sure. Would you like to do it?
 Yep :)
  @netroby Thanks for your report.
I tried it with the lastest master but get nothing wrong.
May I have your git log info and detailed operations?

➜  tidb git:(master) ✗ git log | head -n 10
commit 89fa72467cdfaca4c1ca1ca54c29a592b1f2afb7
Merge: 3b0f94f 2f2e31c
Author: Ewan Chou coocood@gmail.com
Date:   Thu Nov 5 15:38:31 2015 +0800

```
Merge pull request #491 from pingcap/coocood/binder

ast,optimizer: switch to use new parser, and convert ast.Node to old statements.
```

commit 2f2e31c8f47c4b92d7ddd546a6534b74c6118e6d

➜  tidb git:(master) ✗ mysql -uroot -h127.0.0.1 -P4000
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 10001
Server version: 5.5.31-TiDB-1.0 MySQL Community Server (GPL)

Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> select @@version_comment limit 1;
+------------------------------+
| @@version_comment            |
+------------------------------+
| MySQL Community Server (GPL) |
+------------------------------+
1 row in set (0.00 sec)

mysql> 
  Hi @netroby , We may support mysqldump later. 
Please take a look. @shenli 
 We need to add FILES, PARTITIONS table into INFORMATION_SCHEMA.
And then support flush tables, flush tables with read lock, unlock tables statements.
  I think we should check constraints before handing row data. :-)
 Thanks @winkyao 
Have you tried some tests like:
1. Update the same value multiple times. 
2. Delete and insert again.
All of those operations inside a transaction.
 @winkyao The newest master has already supported index Exist function, you can use it directly. 
 Thanks, if we will fix this issue, we will tell you :-)
 Hi @winkyao :
We have fixed this issue in another approach. Please refer #670 for more details.
I will close this PR. Thanks for your contribution.
  Thanks for your report.
If encounter any error when running stmt, we will call txn.Rollback, and it will close UnionStore.
https://github.com/pingcap/tidb/blob/master/store/localstore/txn.go#L252
So may be not an issue.
 Good catch! @winkyao 
 Do you think you can fix it ? @winkyao 
 @winkyao @disksing 
I think this issue is already fixed in the latest master. @disksing checks duplicate before modify unistore. So we do not need to worry about dirty data.

The following is my test log:
➜  interpreter git:(disksing/interpreter-commit-error) ✗ ./interpreter 
Welcome to the TiDB.
Version:
Git Commit Hash: 88047a0efce72c9c51d553338ead0e1f40171e0b
UTC Build Time:  2015-11-28 05:05:22

tidb> USE test;
Query OK, 0 row affected (0.00 sec)
tidb> DROP TABLE IF EXISTS `nosharding_test`;
Query OK, 0 row affected (0.00 sec)
tidb> CREATE TABLE `nosharding_test` (
   ->       `id` int(11) UNSIGNED NOT NULL AUTO_INCREMENT,
   ->       `test1` int(5) UNIQUE,
   ->       PRIMARY KEY (`id`)
   -> )ENGINE=InnoDB DEFAULT CHARSET=utf8;
Query OK, 0 row affected (0.01 sec)
tidb> desc nosharding_test;
+-------+------------------+------+-----+---------+----------------+
| Field | Type             | Null | Key | Default | Extra          |
+-------+------------------+------+-----+---------+----------------+
| id    | int(11) UNSIGNED | NO   | PRI | NULL    | auto_increment |
| test1 | int(5)           | YES  | UNI | NULL    |                |
+-------+------------------+------+-----+---------+----------------+
2 rows in set (0.00 sec)
tidb> insert into nosharding_test(id, test1) values(1, 1);
Query OK, 1 row affected (0.00 sec)
tidb> insert into nosharding_test(id, test1) values(2, 1);
Query OK, 1 row affected (0.00 sec)
2015/11/28 13:07:55 main.go:240: [error] /Users/shenli/workspace/go/src/github.com/pingcap/tidb/kv/iter.go:27: Error: key already exist
/Users/shenli/workspace/go/src/github.com/pingcap/tidb/kv/union_store.go:168: 
/Users/shenli/workspace/go/src/github.com/pingcap/tidb/store/localstore/txn.go:196: 
/Users/shenli/workspace/go/src/github.com/pingcap/tidb/store/localstore/txn.go:247: 
/Users/shenli/workspace/go/src/github.com/pingcap/tidb/session.go:169: 
/Users/shenli/workspace/go/src/github.com/pingcap/tidb/tidb.go:231: 
/Users/shenli/workspace/go/src/github.com/pingcap/tidb/session.go:393: 
/Users/shenli/workspace/go/src/github.com/pingcap/tidb/driver.go:253:  
tidb> insert into nosharding_test(id, test1) values(2, 2);
Query OK, 1 row affected (0.00 sec)
tidb> select \* from nosharding_test;
+----+-------+
| id | test1 |
+----+-------+
| 1  | 1     |
| 2  | 2     |
+----+-------+
2 rows in set (0.00 sec)
tidb> 
  Confirmed, thank you @winkyao 
  @xwb1989 Thanks for your great work.
Could you do some clean up for making commit messages pretty.
you may use those instructions:
git reset  xx
git commit
git push -f
 LGTM
  LGTM
 LGTM
Thank you very much! @xwb1989 
  It should be worked. Have you test it?
Please take a look at:
https://github.com/pingcap/tidb/blob/master/stmt/stmts/create.go#L76
 oops, create table:
https://github.com/pingcap/tidb/blob/master/stmt/stmts/create.go#L119
 AH, You are right.
Could you fix this ?
 https://github.com/pingcap/tidb/blob/master/ddl/ddl.go#L376
@winkyao 
 I test it using the newest master.
tidb> use test;
Query OK, 0 row affected (0.00 sec)
tidb> show tables;
Empty set (0.00 sec)
tidb> create table t(c int);
Query OK, 0 row affected (0.00 sec)
tidb> create table if not exists t(c int);
Query OK, 0 row affected (0.00 sec)
tidb> 
 If your statement has IfNotExists, TiDB will not return error. See:
https://github.com/pingcap/tidb/blob/master/stmt/stmts/create.go#L120
TiDB has the same behavior with mysql:
Database changed
mysql> drop table t;
Query OK, 0 rows affected (0.01 sec)
mysql> create table t(c int);
Query OK, 0 rows affected (0.03 sec)
mysql> create table t(c char);
ERROR 1050 (42S01): Table 't' already exists
mysql> create table if not exists t(c char);
Query OK, 0 rows affected, 1 warning (0.00 sec)
mysql> 

If you want to change table schema, your need to drop the table and recreate it. Or you can use alter table statement. 
 You mean the error code is different? I tried TiDB. It is the same with mysql. So I am a few confused....
tidb> use test;
Query OK, 0 row affected (0.00 sec)
tidb> drop table t;
Query OK, 0 row affected (0.01 sec)
tidb> create table t(c int);
Query OK, 0 row affected (0.01 sec)
tidb> create table t(c char);
2015/10/23 19:19:33 main.go:231: [error] /Users/mac/workspace/go/src/github.com/pingcap/tidb/stmt/stmts/create.go:122: CREATE TABLE: table exists t
/Users/mac/workspace/go/src/github.com/pingcap/tidb/tidb.go:182: 
/Users/mac/workspace/go/src/github.com/pingcap/tidb/session.go:275: 
/Users/mac/workspace/go/src/github.com/pingcap/tidb/driver.go:302: 
/Users/mac/workspace/go/src/github.com/pingcap/tidb/interpreter/main.go:118:  
tidb> create table if not exists t(c char);
Query OK, 0 row affected (0.00 sec)
tidb> 
 Maybe you miss understand mysql's behavior.
See: http://dev.mysql.com/doc/refman/5.7/en/create-table.html
"Existing Table with Same Name
The keywords IF NOT EXISTS prevent an error from occurring if the table exists. However, there is no verification that the existing table has a structure identical to that indicated by the CREATE TABLE statement."

I tried it with mysql, and it did not replace the existing table.
mysql> drop table t;
Query OK, 0 rows affected (0.01 sec)
mysql> create table t(c int);
Query OK, 0 rows affected (0.03 sec)
mysql> create table t(c char);
ERROR 1050 (42S01): Table 't' already exists
mysql> create table if not exists t(c char);
Query OK, 0 rows affected, 1 warning (0.00 sec)
mysql>

May I have your mysql server version? 
 Thanks for your attention. Please keep eyes on TiDB.

PS: I worked in Qihoo for 3 years. Nice to meet you here. :)
  @EtienneBruines Do you set correct GOPATH and GOROOT, and append $GOPATH/bin to $PATH?
 @EtienneBruines Thanks for your report.
You are right, we should add more details to USAGE.md.
   @xwb1989  maybe hard code at first. 
You can choose the best back off implementation you think and send up a PR. :-)
 Cool, we will wait your PR. :-)
 Solved in https://github.com/pingcap/tidb/pull/658
  LGTM
 LGTM

Thanks @fuxiaohei 
  Well done. Thanks @xwb1989 
 LGTM
 LGTM
  Currently, we use goleveldb's memdb as in memory store.
We need a better implementation.
 The problem of  memdb is performance and memory costs. You may simply  write a new implementation to replace memdb. Union store is the only place where currently use memdb. Actually snapshot use the Iterator interface, not memdb.
 @xwb1989 If you need any help, Please let me know. Thanks for contributing.
Looking forward your PR.
 @xwb1989 You are right. The only consumer of UnionStore is transaction.
  Thank you @winkyao 
Please sign the CLA.

Click the "detail" button on the right side of the line " clahub — Not all contributors have signed the Contributor License Agreement.".
 LGTM
 LGTM
Thank you very much! @winkyao 
  Thanks @Alienero, please sign the contributor license agreement first. 

The manual is not correct, whether we have CLIENT_PLUGIN_AUTH or not, the data here is 0x15, not 0x00. You can see the source code https://github.com/mysql/mysql-server/blob/a2757a60a7527407d08115e44e889a25f22c96c6/sql/auth/sql_authentication.cc#L598 explicitly. 
 @Alienero Click the "detail" button on the right side of the line " clahub — Not all contributors have signed the Contributor License Agreement.".
 @Alienero  we may still use 0x15. Other changes are fine.
Could you update your PR? thanks
 @Alienero We have exprienced incorrect documentation caused compatibility issue, so when there is a conflict between documentation and the source code, we stick with source code.

But the comment fix is correct, would you please change '0x00' back to '0x15',  then we can merge it. 
 LGTM
 LGTM
  @fuxiaohei Please sign the Contributor License Agreement.
 LGTM
 LGTM
Thanks for your work! @fuxiaohei 
  Thanks, we don't have any i386 environment.
Could you send us a PR to fix this?
  @shangfy 
Thanks for your report.

u can try as follows:

```
git clone https://github.com/pingcap/tidb.git $GOPATH/src/github.com/pingcap/tidb
cd $GOPATH/src/github.com/pingcap/tidb
make (if u meet an error for `go get github.com/golang/lint/golint`, u can ignore it.)
```
  - [x] ASCII() Return numeric value of left-most character
- [x] BIN()   Return a string containing binary representation of a number
- [x] BIT_LENGTH()    Return length of argument in bits
- [x] CHAR_LENGTH()   Return number of characters in argument
- [x] CHAR()  Return the character for each integer passed
- [x] CHARACTER_LENGTH()  Synonym for CHAR_LENGTH()
- [x] CONCAT_WS() Return concatenate with separator
- [x] CONCAT()    Return concatenated string
- [x] ELT()   Return string at index number
- [x] EXPORT_SET()    Return a string such that for every bit set in the value bits, you get an on string and for every unset bit, you get - [ ] an off string
- [x] FIELD() Return the index (position) of the first argument in the subsequent arguments
- [x] FIND_IN_SET()   Return the index position of the first argument within the second argument
- [x] FORMAT()    Return a number formatted to specified number of decimal places
- [x] HEX()   Return a hexadecimal representation of a decimal or string value
- [x] INSERT()    Insert a substring at the specified position up to the specified number of characters
- [x] INSTR() Return the index of the first occurrence of substring
- [x] LCASE() Synonym for LOWER()
- [x] LEFT()  Return the leftmost number of characters as specified
- [x] LENGTH()    Return the length of a string in bytes
- [x] LIKE    Simple pattern matching
- [ ] LOAD_FILE() Load the named file https://github.com/pingcap/tidb/issues/8436
- [x] LOCATE()    Return the position of the first occurrence of substring
- [x] LOWER() Return the argument in lowercase
- [x] LPAD()  Return the string argument, left-padded with the specified string
- [x] LTRIM() Remove leading spaces
- [x] MAKE_SET()  Return a set of comma-separated strings that have the corresponding bit in bits set
- [x] MATCH   Perform full-text search
- [x] MID()   Return a substring starting from the specified position
- [x] NOT LIKE    Negation of simple pattern matching
- [x] NOT REGEXP  Negation of REGEXP
- [x] OCT()   Return a string containing octal representation of a number
- [x] OCTET_LENGTH()  Synonym for LENGTH()
- [x] ORD()   Return character code for leftmost character of the argument
- [x] POSITION()  Synonym for LOCATE()
- [x] QUOTE() Escape the argument for use in an SQL statement
- [x] REGEXP  Pattern matching using regular expressions
- [x] REPEAT()    Repeat a string the specified number of times
- [x] REPLACE()   Replace occurrences of a specified string
- [x] REVERSE()   Reverse the characters in a string
- [x] RIGHT() Return the specified rightmost number of characters
- [x] RLIKE   Synonym for REGEXP
- [x] RPAD()  Append string the specified number of times
- [x] RTRIM() Remove trailing spaces
- [ ] SOUNDEX()   Return a soundex string https://github.com/pingcap/tidb/issues/3930
- [ ] SOUNDS LIKE Compare sounds https://github.com/pingcap/tidb/issues/3930
- [x] SPACE() Return a string of the specified number of spaces
- [x] STRCMP()    Compare two strings
- [x] SUBSTR()    Return the substring as specified
- [x] SUBSTRING_INDEX()   Return a substring from a string before the specified number of occurrences of the delimiter
- [x] SUBSTRING() Return the substring as specified
- [x] TRIM()  Remove leading and trailing spaces
- [x] UCASE() Synonym for UPPER()
- [x] UNHEX() Return a string containing hex representation of a number
- [x] UPPER() Convert to uppercase
 Cool @mrmiywj
Please feel free to send PR.
 @mrmiywj builtin functions are moved here: https://github.com/pingcap/tidb/blob/master/evaluator
 Hi @a6802739 

It is very appreciated that you can help us add more functions. 

If you add a function, you can first run `make test` local and then send us the PR after test passes.  @a6802739 
Do you have the error like `package not found` when you run `make test` on your forked repo? @a6802739 
Please describe what you have done and what error you have got, thank you. @a6802739 
Please try `make dev` @a6802739 
`golint` imports `golang.org/x/tools/go/gcimporter15`, `make check` use `golint`, so you need to use a proxy to get `golint`.
But I think you can run `make test` now.
 @a6802739 
Feel free to ask anything, looking forward to your PR.  Store hashed password.
 @kevincox The salt is a random data generated for each client connection.  The parameter scramble of CalcPassword function in auth.go is the salt.
MySQL client uses server-generated salt and password to caculate a cryptographic authstring. Server use the same algorithm and compare check if the result is the same with client.
 LGTM
  Hi @luyee 

Can you tell us what is the command you use with mysql client? Do you forget -u or -P ?
 @luyee May I have your tidb-server git version and error log? 
Thanks!
 no, no, use `mysql -h 127.0.0.1 -P 4000 -u root -p` please 
 @elvizlai Thanks for your report! I will check this.
  @Unknwon Does CI support i386 platform?
 We don't have any i386 platform. And we are not gonna  support i386 since we can't track the results if source changed. But PR is welcome :)
Could you help us to  fix it ? 
 oops, I guess we need CI for i386 platform.
 @Unknwon 
Can u use this branch 
https://github.com/pingcap/tidb/tree/qiuyesuifeng/issue-279 
to have a try?
I guess we should use math.Abs for check when the float64 value is negative in RoundFloat function.

Thanks.
 @Unknwon 

http://play.golang.org/p/FxT4zzRyQS

or you can try the RoundFloat instead and check again. :-)
 @Unknwon 
Thanks.  How about @siddontang function implement? Seems much better:-)
 I update branch and u can try again. Thanks:)
 @Unknwon  Thanks.
  @jmuyuyang Thanks for your feedback!
Could u please provide more details?
1. What MySQL client you are using? MySQL official client or others?
2. What's your SQL statement?"use mysqls;"?
3. What's the TiDB version? It is shown as `Git Commit Hash` when tidb-server start.
 @jmuyuyang Thanks for your reply.
We have fix this bug. You can try this branch: shenli/fix-issue-263. We will merge it to master later today.

One more thing, I notice that there is an unexists database in your dsn named "mysqls". Is it a typo?
 @jmuyuyang 
Thanks again for your report! Please keep eyes on TiDB.
  Obviously, this is a cool feature. But currently we are focusing on the features in [roadmap](https://github.com/pingcap/tidb/blob/master/ROADMAP.md).
 Hi, @nkev:
Thanks for you advice. The better choice would be RethinkDB or pipelinedb or some other streaming database if you need stream SQL. TiDB is mainly for OLTP.
  LGTM
 LGTM
 LGTM  :+1: 
Thanks @lshmouse 
  http://dev.mysql.com/doc/refman/5.7/en/date-and-time-functions.html
- [x] ADDDATE() Add time values (intervals) to a date value
- [x] ADDTIME() Add time
- [x] CONVERT_TZ()  Convert from one timezone to another
- [x] CURDATE() Return the current date
- [x] CURRENT_DATE(), CURRENT_DATE  Synonyms for CURDATE()
- [x] CURRENT_TIME(), CURRENT_TIME  Synonyms for CURTIME()
- [x] CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP    Synonyms for NOW()
- [x] CURTIME() Return the current time
- [x] DATE_ADD()    Add time values (intervals) to a date value
- [x] DATE_FORMAT() Format date as specified
- [x] DATE_SUB()    Subtract a time value (interval) from a date
- [x] DATE()    Extract the date part of a date or datetime expression
- [x] DATEDIFF()    Subtract two dates
- [x] DAY() Synonym for DAYOFMONTH()
- [x] DAYNAME() Return the name of the weekday
- [x] DAYOFMONTH()  Return the day of the month (0-31)
- [x] DAYOFWEEK()   Return the weekday index of the argument
- [x] DAYOFYEAR()   Return the day of the year (1-366)
- [x] EXTRACT() Extract part of a date
- [x] FROM_DAYS()   Convert a day number to a date
- [x] FROM_UNIXTIME()   Format UNIX timestamp as a date
- [x] GET_FORMAT()  Return a date format string
- [x] HOUR()    Extract the hour
- [x] LAST_DAY  Return the last day of the month for the argument
- [x] LOCALTIME(), LOCALTIME    Synonym for NOW()
- [x] LOCALTIMESTAMP, LOCALTIMESTAMP()  Synonym for NOW()
- [x] MAKEDATE()    Create a date from the year and day of year
- [x] MAKETIME()    Create time from hour, minute, second
- [x] MICROSECOND() Return the microseconds from argument
- [x] MINUTE()  Return the minute from the argument
- [x] MONTH()   Return the month from the date passed
- [x] MONTHNAME()   Return the name of the month
- [x] NOW() Return the current date and time
- [x] PERIOD_ADD()  Add a period to a year-month
- [x] PERIOD_DIFF() Return the number of months between periods
- [x] QUARTER() Return the quarter from a date argument
- [x] SEC_TO_TIME() Converts seconds to 'HH:MM:SS' format
- [x] SECOND()  Return the second (0-59)
- [x] STR_TO_DATE() Convert a string to a date
- [x] SUBDATE() Synonym for DATE_SUB() when invoked with three arguments
- [x] SUBTIME() Subtract times
- [x] SYSDATE() Return the time at which the function executes
- [x] TIME_FORMAT() Format as time
- [x] TIME_TO_SEC() Return the argument converted to seconds
- [x] TIME()    Extract the time portion of the expression passed
- [x] TIMEDIFF()    Subtract time
- [x] TIMESTAMP()   With a single argument, this function returns the date or datetime expression; with two arguments, the sum of the arguments
- [x] TIMESTAMPADD()    Add an interval to a datetime expression
- [x] TIMESTAMPDIFF()   Subtract an interval from a datetime expression
- [x] TO_DAYS() Return the date argument converted to days
- [x] TO_SECONDS()  Return the date or datetime argument converted to seconds since Year 0
- [x] UNIX_TIMESTAMP()  Return a UNIX timestamp
- [x] UTC_DATE()    Return the current UTC date
- [x] UTC_TIME()    Return the current UTC time
- [x] UTC_TIMESTAMP()   Return the current UTC date and time
- [x] WEEK()    Return the week number
- [x] WEEKDAY() Return the weekday index
- [x] WEEKOFYEAR()  Return the calendar week of the date (1-53)
- [x] YEAR()    Return the year
- [x] YEARWEEK()    Return the year and week
 @hhkbp2 Yes, there are some basic tests:
http://dev.mysql.com/doc/refman/5.7/en/date-and-time-functions.html

Some corner tests:
https://github.com/mysql/mysql-server/blob/a2757a60a7527407d08115e44e889a25f22c96c6/mysql-test/t/func_sapdb.test

Results of those above tests:
https://github.com/mysql/mysql-server/blob/a2757a60a7527407d08115e44e889a25f22c96c6/mysql-test/r/func_sapdb.result
 @hhkbp2 You can refer to https://github.com/pingcap/tidb/tree/master/expression/builtin/time_test.go
For time builtin functions, the implementations are in time.go and unit tests are in time_test.go.
 This is a good suggestion and we'll support it soon. 
Thanks for feedback. @shlomi-noach  @shlomi-noach unix_timestamp() is already supported. Please try the latest master. @kaiwu Thanks for your feedback!
@zyguan Would you mind add utc_timestamp() for TiDB? @zyguan Great! @kaiwu UTC_TIMESTAMP has been supported by the latest master, please try it. Thanks.  Python:
- [ ] SQLAlchemy
- [ ] Peewee
- [ ] django
- [ ] ponyorm

Go:
Orm:
- [x] xorm: https://github.com/go-xorm/xorm
- [x] beego: https://github.com/astaxie/beego/tree/master/orm
- [x] go-sql-test: https://github.com/bradfitz/go-sql-test
- [ ] upper.io: https://upper.io/db.v1/mysql

Application:
- [x] Gogs: https://github.com/gogits/gogs
- [ ] Dalga: https://github.com/cenkalti/dalga

Java：
- [x] Mybatis
- [ ] Jdbctemplate
- [ ] Hibernate
- [ ] Play

PHP:
- [ ] phabricator: http://phabricator.org/
- [x] phpmyadmin 
- [x] wordpress
- [ ] yii: http://www.yiiframework.com/doc/guide/1.1/en/database.ar
- [ ] discuz!: http://www.discuz.net/ 
- [ ] drupal: https://www.drupal.org/
- [ ] [Eloquent](https://laravel.com/docs/5.5/eloquent)

Dotnet:
- [ ] [Entity Framework Core](https://github.com/PomeloFoundation/Pomelo.EntityFrameworkCore.MySql)
 @shenli Any update ?
 I will go through the list tomorrow. @ngaut 
 sqlalchemy unit test:
 25 failed, 404 passed, 51 skipped in 34.78 seconds 
I will fix the failed cases.
  @cppmule 

We have not supported `show variables where` syntax, we will support it later.
Thank you very much. 
 Hi @cppmule 

Can you checkout branch siddontang/fix-issue-199 and help us to test it again?
 Thanks for your report.
Yes, we have not support sql comment like `select c /* this is a comment */ from t` now.
We will support it later.
btw, is it convenient for u to remove sql comment temporarily to check whether have any other problems? Thanks again.
 The comments are generated by some java tools. And there are too many comments.
We should strip those comments.

/**/ 

 -- 
 Move comment discussion to #203  :smile: 
  Sorry, I do not get your point. Is there any problem with this file?
 I started to write golang three month ago. At first I have the similar feeling with you. But now I think golang is an excellent programming language. 
We DO NOT LIE because all of us really enjoy work with golang. I suggest you to work with golang for some time and then consider this issue again.
Thanks for your attention！
 Thank you for watching.
  LGTM
 LGTM
 LGTM
  ```
create table t1 (a int, b int) engine=innodb;
insert into t1 values (1,2), (1,3), (2,3), (2,4), (2,5), (3,4), (4,5), (4,100);

mysql> select a, sum(b) as b from t1 group by a having b > 4;
+------+------+
| a    | b    |
+------+------+
|    1 |    5 |
|    2 |   12 |
|    4 |  105 |
+------+------+
```

but we only get one row result. 
 @xwb1989 Thanks for report.
Yes, that is a problem.
I will fix it later.
 @xwb1989 
Thanks for your suggestion.

We used hidden fields for having fields which not in select or group by fields, and we have not distinguished aggregate and none aggregate fields, so we have the problem as @siddontang mentioned.

As for `select a as b from t1 having b > 4;`, because some having conditions has some confused results, like `select a as b from t1 having b + 1` or  `select a as b from t1 having a + b` or `select a + b as b from t1 having a + b > 0` and so on, now we only process alias field as origin field first,  so `select a as b from t1 having b > 4;`  may equal to  `select a from (select a, b from t1 having b > 4) c;`.

Later we will discuss and fix this problem.
Thanks again.
 @xwb1989 
We have fixed this problem, u can update master branch and have a try:)
 Cool @xwb1989 
   LGTM
 LGTM
  fix #165 
 How about now?

@Unknwon 
 @Unknwon  Do you use the latest code? I have updated it..
 Hi @Unknwon 

Try it again. 
 Sorry :-) 
I will try to use Go cross-build, maybe. 
 How about the newest one?

Can it work? 
 Cool 
 LGTM
 LGTM
  Hi @Unknwon 

I just try to fix it in branch https://github.com/pingcap/tidb/tree/siddontang%2Ffix-issue-165

Can you help us to test on ARM again? 
 Yes, maybe the `int` in your platform is 4 bytes. 
I will fix it.
  Via the [MySQL Manual](https://dev.mysql.com/doc/refman/5.7/en/functions.html):

- [x] Control Flow Functions (verified as done)
- [x] String Functions https://github.com/pingcap/tidb/issues/310
- [x] Numeric Functions (appear done, not competely verified)
- [x] Date and Time Functions https://github.com/pingcap/tidb/issues/236
- [x] Bit Functions (appears done)
- [x] Cast Functions (appears done)
- [ ] Encryption and Compression https://github.com/pingcap/tidb/issues/2632
- [ ] Information Functions https://github.com/pingcap/tidb/issues/8438
- [ ] JSON https://github.com/pingcap/tidb/issues/7546
- [ ] Aggregate Functions https://github.com/pingcap/tidb/issues/7623
- [ ] Misc Functions https://github.com/pingcap/tidb/issues/8439
 Thank you @w5s5j 
I think #236 is a good start :)
Fire an issue when you are ready to hunt any of the functions in #236 
 @Tratar 
we have a document for contributors who wants to add built-in functions to TiDB, you can pick a built-in function in https://github.com/pingcap/tidb/issues/236, and follow the steps in https://pingcap.github.io/blog/2016/12/19/adding-built-in-function/ 
Happy hacking :) @Tratar You can refer to https://github.com/pingcap/tidb/issues/310 and  https://github.com/pingcap/tidb/issues/236 for the unimplemented builtin functions. If you have any problem, please let us know.
Thanks!  LGTM. Thanks 
 LGTM
  @qiuyesuifeng Please take a look.

@insionng Thank you, Could you sign the CLA. CI failed
 @c4pt0r 
Please take a look.
 @insionng Thanks for your PR.

There are some additional things need to do:
1 For making tidb, u need do things as follows:
1.1 godep
`godep` is to get godep tool(`https://github.com/tools/godep`) which is used for easy building without getting dependency packages.

1.2 parser
`parser` is to get goyacc and golex package, generate `parser/parser.go` and `parser/scanner.go` which are needed by tidb building.
In your make.cmd, u have done this, but also need some work like in `tidb/Makefile` to generate `parser/scanner.go`：
`golex -o parser/scanner.go parser/scanner.l`

1.3 build
Godep go build

1.4 test
Godep go test ./...

2 For making interpreter, u need do things as follows:
2.1 add `ldflags` go build option[nice to haves]
LDFLAGS += -X "github.com/pingcap/tidb/util/printer.TiDBBuildTS=$(shell date -u '+%Y-%m-%d %I:%M:%S')"
LDFLAGS += -X "github.com/pingcap/tidb/util/printer.TiDBGitHash=$(shell git rev-parse HEAD)"
The ldflags is very useful for us to check and fix bugs.
The correct interpreter output looks like as follows:

```
Welcome to the TiDB.
Version:
Git Commit Hash: bf97f61c450912a5c1f4cfba44bb11297fa7876f
UTC Build Time:  20150913214037

tidb>
```

2.2 build
Godep go build -ldflags "-X github.com/pingcap/tidb/util/printer.TiDBBuildTS=%TiDBBuildTS% -X github.com/pingcap/tidb/util/printer.TiDBGitHash=%TiDBGitHash%"
TiDBBuildTS and TiDBGitHash variables are set in above 2.1

So u can see above, maybe some more work need to do in make.cmd.
And also, for unix/mac users, i think it is better to install make tool.
Thanks again, looking forward to your update :)
 Well done. Looks like we don't need make.sh.
Just keep make.cmd is fine. We could still use make instead of make.sh.
Could you please remove make.sh. Then we will merge this PR.
Thanks. @insionng 
 LGTM
 LGTM. Thank you @insionng 
  Thanks @cznic 

We can execute `create table if not exists t (c1 int);` in MySQL command shell, so we support CommaOpt here. 

Maybe we can remove the `;` at first before parsing? @shenli  
 Sorry for my fault. @cznic ,  I am wrong.
 Comma is not allowed, I think too. 
 LGTM  
@siddontang I think the CommaOpt should not be here. The parser parse text into statement list, and ';' will be treated as separator between statements. So it is not necessary to add ';' at the end of create statement rule.
Thanks a lot! @cznic 
 LGTM

Wow! All conflicts are resolved.
Great job, thank you.
 I think we should add syntax conflict detection in Makefile to prevent future bugs. I will add an issue.
  Well done.
LGTM
 Cool, LGTM
 LGTM
Thank you!
  @cznic I referenced TableIdentList related syntax in MySQL docs.
You are right, `TableIdentList` should never be empty.
  LGTM
 LGTM
@cznic  Thanks.
  LGTM
 Well done! 
LGTM
  LGTM
 LGTM
Thanks! @cznic :+1: 
  s/golang/Go/g
And add . in the end of the sentence
 LGTM
 LGTM
  `plan.Do` method make it difficult to incrementally process table rows.

When `Do` method is executing, the only way to pause it is to use another goroutine with a channel, as currently the driver does.

And with Do method the only way to process data is to use an closure, but with next, we can process data without closure.

The proposed next method looks like:

```
`Next(ctx context.Context) (data []interface{}, rowkeys []*RowKeyEntry, err error)`
```
 +1
Use Next can remove closure which is hard to read, and at same time, we will avoid #57 finally.
to support this, we should maintain an iterator manually in group by, order by and distinct plan. 
maybe later we will add temporary table for these plans.
 +1
Please add RowKeyList to the return value
 +1
Do not like closure.
 @shenli Updated
 Hi @cznic 

We know that return `(false, nil)` can terminate the Do immediately, but what we want to do is to traverse data iteratively and guarantee all queries in one transaction are handled in one goroutine.

Although we use channel + goroutine to support iteration in current implementation, a risk that the session is handled in two goroutines, we meet this panic, see #57.

Btw, maybe it is more convenient to write logic code with iteration (Next method, or even Previous method later) than callback with closure. :-) , e.g.

```
iter1 := NewIterator(result set1)
iter2 := NewIterator(result set2)

iter1.Next()
iter2.Next()

// get iter1 and iter2 data and do something, then iterate.  
iter1.Next()
iter2.Next()
```
 @cznic You are right.
But if user want to scan through a very large table, fetching all rows before return to user may cause out of memory issue.
 @cznic 
I'm sorry for the mistaken statement I made above.

We actually implemented a server layer without the channel and goroutine which will be open-sourced soon.

The server layer indeed fetched all the rows before return to user by calling `Recordset.Rows` method.

And we want to access the transaction instance only in one goroutine to avoid concurrency issue.

And thank you for the information, it helps a lot.
 Done.
  LGTM
 LGTM
Many thanks! @cznic 
  LGTM
 LGTM
thanks!
  LGTM
 LGTM
 LGTM
@cznic  Thanks.
  LGTM
Thanks! @cznic 
 LGTM
Thank you @cznic .
  TiDB are some distance away from running phpMyAdmin. 

Support "SHOW VARIABLES LIKE 'character_set_results'" fixed in https://github.com/pingcap/tidb/pull/114

TODO:
SET CHARACTER SET 'utf8mb4';
 Done!
  Thanks for your feedback.
Do you have github.com/qiuyesuifeng/golex  and github.com/qiuyesuifeng/goyacc in you GOPATH?
 @insionng 
building tidb should use `make` to generate `parser/parser.go` and `parser/scanner.go` which is needed by `yy_parser.go`.

please refer README, use `go get -d github.com/pingcap/tidb` then `make`.
u can try again.
 Good job, looking forward for your PR
 Done.
  @cznic 
MySQL has two kinds of keywords, one is reserved keywords, the other one is unreserved keywords.

Reserved keywords can not be used as identifier, but unreserved keywords can.

"COLUMN" is an reserved keyword, so "ALTER TABLE t DROP COLUMN COLUMN" is not a valid statement.

The full list of MySQL keywords can be found here:
https://dev.mysql.com/doc/refman/5.0/en/keywords.html
 @cznic @shenli 
So we mistakenly listed "COLUMN" in unreserved keyword in parser.y.
 I have removed "COLUMN" from UnReservedKeyword in another pr and seems this conflict is already solved. Please check the latest master. @cznic 
Thanks!
  Resolved all the reduce/reduce conflicts except for 1

Fixes issue #73
 @cznic

The remaining conflict is in `SetStmt` 

`"SET" VariableAssignmentList | "SET" "PASSWORD" ForUserOpt eq PasswordOpt`

I didn't figure out a proper way to resolve it.

Do you have any suggestions? 

Thank you.
 should we update the make parser adding -cr for later check?
 @siddontang I didn't use -cr, but still can see conflict check report.
 @cznic  
UnReservedKeyword defines a MySQL keyword list which can be used as identifier.
See: https://dev.mysql.com/doc/refman/5.7/en/keywords.html

Identifier is defined as identifier | UnReservedKeyword in parser.y. And "SELECT commit FROM tbl;" will not encounter syntax error.
 @cznic
You helped us a lot again, thank you.

Since the Github converted tab to space, the patch can not be applied automatically, I manually applied this patch.

We do not have much experience on parser and have difficulty resolve S/R conflicts, would you like to help us addressing the issue with PR?
 @cznic 
Got it, thanks.
 LGTM
 LGTM
 @cznic Sure.
   LGTM
 LGTM.
  @shenli  PTAL. 
Thanks for your suggestion, and thank u for your awesome job again :)
 resolved by final PR https://github.com/pingcap/tidb/pull/122
  Hi @mtorromeo 
can you tell me what's your timezone? 
 got it. 
We will fix it ASAP. 
 fixed.

@mtorromeo  u can update tidb and try again.
Thanks for your report.
  "mode" can be used as an identifier.
See: https://dev.mysql.com/doc/refman/5.7/en/keywords.html

@Unknwon The following bug is caused by parser. This pr will fix it.
SELECT id, user_id, repo_id, mode FROM access WHERE repo_id=? AND mode>=?
, error: line 1 column 77 near "mode"
Is > a invalid operator?
 LGTM
 LGTM
  May I have your command log?
When I run go test in go-xorm/tidb, I meet another error.

Thanks for your report! I will work on this.
 @lunny  please check the latest code and have a test.
We fix a bug about prepared statement panic. But I do not encounter the same error as you reported.
I meet a few other errors when run go test in go-xorm/tidb and I am working on those bugs. 

Thanks!
 @lunny I find a potential bug in go-xorm/tests
When call testDelete multiple times, the environment is not clean. There is not drop table statement before or after the test.
https://github.com/go-xorm/tests/blob/master/testDelete.go#L49

I find an error when run test. Adding "engine.DropTables(&Deleted{})" before "engine.CreateTables(&Deleted{})" will fix it.

Please take a look. Thanks!
 Hi @lunny 

We create a branch to fix the panic, could you help us to check with it? 

The branch is https://github.com/pingcap/tidb/tree/siddontang/fix-driver-panic
 @shenli is fixing it. 
Btw, there seems no panic? 
 TiDB support "select for  update". But there are tiny difference between TiDB and MySQL.
Because TiDB use Optimistic concurrency control.

There are some details in Wikipedia:
Optimistic concurrency control (OCC) is a concurrency control method applied to transactional systems such as relational database management systems and software transactional memory. OCC assumes that multiple transactions can frequently complete without interfering with each other. While running, transactions use data resources without acquiring locks on those resources. Before committing, each transaction verifies that no other transaction has modified the data it has read. If the check reveals conflicting modifications, the committing transaction rolls back and can be restarted.[1] Optimistic concurrency control was first proposed by H.T. Kung.[2]

OCC is generally used in environments with low data contention. When conflicts are rare, transactions can complete without the expense of managing locks and without having transactions wait for other transactions' locks to clear, leading to higher throughput than other concurrency control methods. However, if contention for data resources is frequent, the cost of repeatedly restarting transactions hurts performance significantly; it is commonly thought that other concurrency control methods have better performance under these conditions. However, locking-based ("pessimistic") methods also can deliver poor performance because locking can drastically limit effective concurrency even when deadlocks are avoided.

Contents  [hide] 
1 OCC phases
2 Web usage
2.1 Examples
3 See also
4 References
5 External links
OCC phases[edit]

This section does not cite any references or sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (August 2010)
More specifically, OCC transactions involve these phases:

Begin: Record a timestamp marking the transaction's beginning.
Modify: Read database values, and tentatively write changes.
Validate: Check whether other transactions have modified data that this transaction has used (read or written). This includes transactions that completed after this transaction's start time, and optionally, transactions that are still active at validation time.
Commit/Rollback: If there is no conflict, make all changes take effect. If there is a conflict, resolve it, typically by aborting the transaction, although other resolution schemes are possible. Care must be taken to avoid a TOCTTOU bug, particularly if this phase and the previous one are not performed as a single atomic operation.
 @lunny User may retry transaction when commit "select for update" failed.
  Thanks for your attention. We will support MPP after we finish "Asynchronous schema changes".
  we have already supported in-memory engine. you can use it below:

```
db, err := sql.Open("tidb", "memory://test")
```
 @romanoff @Unknwon @no1youknowz
  @romanoff  Thanks for your report.
i try it in Ubuntu 14.04.1 and go1.5 for interpreter,  it works well.
try `Ctrl+C`? can this work?
 @romanoff 
We  have fixed this bug, Could you update and try again.
  Thanks for your report!
May I have your go version?
 Please try this in interpreter dir:
godep go build -ldflags "-X github.com/pingcap/pingcap/util/printer.TiDBBuildTS=2015-09-07 03:40:55" -ldflags "-X github.com/pingcap/pingcap/util/printer.TiDBGitHash=81db754a49a63551beb9cd936153eb1f6c612c67"
If there is any error, please tell me.
 go 1.4.2 may have some problem to make interpreter, we are trying to fix it.
go 1.5 works well now.

@lei-cao any problem can make an issue, Thanks.
  LGTM
 LGTM
@gelstudios  Thanks.
  Thanks.
LastInsertId can't be fixed, since it's an interface of  standard library.
And parser/scanner.go is generated by golex.
  fixes https://github.com/pingcap/tidb/issues/45
 @cznic
PTAL
 LGTM
 LGTM
 @cznic gotcha! We'll fix it in a new PR.
:)
 Could we put all LICENSE files into a separated directory and update the copyright comments to root/LICENSES/QL-LICENSE? Just for keeping root directory clean.  ;D
@cznic 
 OK, cool, we'll fix it right away :+1: 
 @cznic  
#75  PTAL.
 yes, i made a mistake.
#75  has been closed.
#74 is the correct one.

Thank u.
  Thank you for your comment! TiDB is derived from the cznic/ql codebase, thank you again for the awesome job!

We'll add the ql-licence declaration in the files that contains your code. Is that OK? Please let us know :)
Just like this:

// Copyright 2015 The ql Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.

// Copyright 2015 PingCAP, Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// See the License for the specific language governing permissions and
// limitations under the License.

.....
@cznic 
 Fixed.
https://github.com/pingcap/tidb/pull/74
  LGTM
 LGTM
  LGTM
Please add godep.
 LGTM
 LGTM
@Unknwon  Thanks.
 @Unknwon  this function may be used in other places, we may move this to util as an alone package (e.g, iconv) later.  
  Thanks for your report! We'll try to reproduce and fix it.
 Thanks for your report @lunny @Unknwon
I checked TiDB code and fixed a few bugs today, but still can not pass go-xorm test. 
There are two things I want to discuss with you.

The first one is a potential bug in https://github.com/go-xorm/tidb/blob/master/tidb_driver.go#L42.
tidb_driver use params[1] as DbName, but it maybe "./tidb". I see some sql statement in the log that select column name in some table where the dbname="./tidb". For example:
"[xorm] [debug] 2015/09/07 21:23:48.572562 [time] SELECT `TABLE_NAME` from `INFORMATION_SCHEMA`.`TABLES` WHERE `TABLE_SCHEMA`=? and `TABLE_NAME`=? - args [./tidb userinfo] - query took: 367238ns".
I modified a few code and fixed the "Duplicate column name" error.
  40         fs := strings.Split(params[1], "/")
  41         dbName := fs[len(fs)-1]
  42         uri := &core.Uri{
  43                 DbType: DBType,
  44                 DbName: dbName,
  45         }
  46 
I try to push my code to a new branch in go-xorm but get permission denied error.

The second one is about auto_increment column.
In TiDB we only guarantee that auto_increment column value is increasing. But I find a test case in https://github.com/go-xorm/tests/blob/master/base.go#L94 which assume the value of auto_increment id.
I checked the insert statements. Those statements do not set id column explicitly. I also checked table content in TiDB, the ids are auto increment but no one in [7, 8, 9]. So the case failed.
tidb> select \* from userinfo;
+------+-------------+------------+---------------------+-----------+--------+--------+--------+
| id   | username    | departname | created             | detail_id | height | avatar | is_man |
+------+-------------+------------+---------------------+-----------+--------+--------+--------+
| 1001 | xiaolunwen2 | dev        | 2015-09-07 20:51:33 | 1         | 1.78   |     | 1      |
| 1002 | xlw         | dev        | 2015-09-07 20:51:33 | 0         | 0      |        | 0      |
| 1003 | xlw2        | dev        | 2015-09-07 20:51:33 | 0         | 0      |        | 0      |
| 1004 | xlw11       | dev        | 2015-09-07 20:51:33 | 0         | 0      |        | 0      |
| 1005 | xlw22       | dev        | 2015-09-07 20:51:33 | 0         | 0      |        | 0      |
| 1006 | 1xlw        | dev        | 2015-09-07 20:51:33 | 0         | 0      |        | 0      |
| 1007 | 1xlw2       | dev        | 2015-09-07 20:51:33 | 0         | 0      |        | 0      |
| 1008 | 1xlw11      | dev        | 2015-09-07 20:51:33 | 0         | 0      |        | 0      |
| 1009 | 1xlw22      | dev        | 2015-09-07 20:51:33 | 0         | 0      |        | 0      |
| 1010 | xlw3        | dev        | 2015-09-07 20:51:33 | 0         | 0      |        | 0      |
+------+-------------+------------+---------------------+-----------+--------+--------+--------+
 For performance consideration, we choose an auto increment id assigning algorithm as this:
Get the start_number from global storage. And update global stored start number to a new number which is start_number + 1000.  So we get a batch of auto ids and do not need to access global storage before run out of these ids. Then we can assign and increase global-uniq id for auto_increment column.

All the auto increment id related codes for a table share the same start_number. In this case, I think 1~1000 is assigned before inserting column "id".  So column "id" inserting gets the start_number 1001.
I will check logs and provide more information.
 @Unknwon  May I see your code? 
I find lunny update tidb_driver.go to solve adding an existing column problem. https://github.com/go-xorm/tidb/blob/master/tidb_driver.go
  Make syntax log easy to read.

https://github.com/pingcap/tidb/issues/25
 LGTM
 PTAL @qiuyesuifeng 
 LGTM
  pass gofmt
 yep.
 It's my next pr.
 LGTM
 @xiang90 ^_^
 LGTM
  Thanks @Unknwon 

And @xiang90 is right, keep them into separate commits:
1. change
2. godep

The correct step is:
cd tidb
godep restore
godep save ./...

Could you fix it ? @Unknwon Thanks.
 @Unknwon this PR introduced too much dependencies, can you remove the depedency of "golang.org/x/net/html/charset", all we need is a map from charset name to encoding. 
How about copy the code in https://github.com/golang/net/blob/master/html/charset/table.go
  Hello Unknwon,
    "1:9" means there is an error near line 1 and column 9. 
     For your error log, there is a compile error in "use gogs.tidb" near the dot (the 9th character). I check parser/parser.y and find that use statement does not allow dbname with a dot. See: https://github.com/pingcap/tidb/blob/master/parser/parser.y#L3268

Thanks!
 @Unknwon  please review this https://github.com/pingcap/tidb/pull/33

Current error log looks like this:
tidb> use gogs.tidb;
2015/09/07 12:36:20 session.go:123: [error] Syntax error: use gogs.tidb;
2015/09/07 12:36:20 session.go:124: [error] Error occurs at line 1 column 9 near ".".
 @Unknwon we only support letters, numbers and  '_'  in dbname and it must starts with a letter. Try gogs_tidb please.
You got the old style error log? Have you pulled the latest code and rebuild TiDB?
 I will improve the docs. Thanks!
  Hi @Unknwon, what's your timezone?
 It seems that we don't test time fully with different timezones, we will fix it ASAP.
 Hi @Unknwon  you can check it again. Thanks.
  We have already support version. https://github.com/pingcap/tidb/blob/master/util/printer/printer.go#L23
 We may use it in interpreter. MySQL protocol layer. Or HBase engine.
Put to util package, so we keep it DRY.
 WOW, User could pass version information to those variables :)
 It's read only after assignment.
 any updates? @ngaut  
 @astaxie 
 Currently TiDB is evolving extremely fast.   The version information is generated automatically by makefile:

LDFLAGS += -X "github.com/pingcap/tidb/util/printer.TiDBBuildTS=$(shell date -u '+%Y-%m-%d %I:%M:%S')"
LDFLAGS += -X "github.com/pingcap/tidb/util/printer.TiDBGitHash=$(shell git rev-parse HEAD)"

Does that sound ok?   @fuxiaohei 
  Thank you for your contribution.

Being able to change the address and having the option to turn it off is great,  but since TiDB is under heavy development, having Debug set to true by default would be more convenient.

I also noticed that the PR is sent from your master branch, we recommand that when opening a PR, create a topic branch and make changes on that branch, it's easier for your forked repo to keep in sync with upstream.
 LGTM
 LGTM
  @l2x Please sign the CLA.
  LGTM
 LGTM
  Could you fix this issue ?
Currently we are using Linux and Mac OS X.
 Does TiDB works on windows now?  @fuxiaohei 
  Good job!
LGTM
 LGTM
 LGTM
  parser.go and scanner.go are generated code.
 @xiang90 I agree.
 LGTM
 LGTM
/n  update Dockerfile because go 1.7 is required
fix make dev error:./store/tikv/backoff.go:195: unrecognized printf flag for verb 's': '#' [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2856) <br/>All committers have signed the CLA.  go 1.7 is required because package "context" is used in session.go:21:2 [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2853) <br/>All committers have signed the CLA.  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2850) <br/>All committers have signed the CLA.  Add exp built-in function [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2847) <br/>All committers have signed the CLA.  builtin: add degrees built-in function @shenli Already addressed the comments and resolved the conflict.  when the input value is invalid, set the return value to "0"    Add `radians()` built-in function  My first pull request. I don't know if it is right. [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2839) <br/>All committers have signed the CLA. @coocood 
Ok, thanks.
:(  [Add LPAD built-in function.](https://github.com/pingcap/tidb/issues/2863)  Add `PI()` built-in function @zimulala fixed conflicts   [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2835) <br/>All committers have signed the CLA. fixed and please review again.
@coocood    [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2831) <br/>All committers have signed the CLA. @shenli fixed and plz review again. OK, got it.   [![CLA assistant check](https://cla-assistant.io/pull/badge/not_signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2830) <br/>Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our [Contributor License Agreement](https://cla-assistant.io/pingcap/tidb?pullRequest=2830) before we can accept your contribution.<br/><sub>You have signed the CLA already but the status is still pending? Let us [recheck](https://cla-assistant.io/check/pingcap/tidb?pullRequest=2830) it.</sub> Sorry, I copy that from SQRT function, but i forget to run go test. I am
immediately modified.

On Wed, Mar 15, 2017 at 5:29 PM, Ewan Chou <notifications@github.com> wrote:

> *@coocood* commented on this pull request.
> ------------------------------
>
> In expression/builtin_math_test.go
> <https://github.com/pingcap/tidb/pull/2830#discussion_r106118520>:
>
> > +
> +func (s *testEvaluatorSuite) TestSin(c *C) {
> +	defer testleak.AfterTest(c)()
> +
> +	testCase := []struct {
> +		arg interface{}
> +		ret interface{}
> +	}{
> +		{math.Pi / 2, float64(1)},
> +		{math.Pi, float64(1.2246467991473515e-16)},
> +		{math.Pi / 3, float64(0.8660254037844387)},
> +		{float64(1), float64(0.8414709848078965)},
> +	}
> +
> +	for _, test := range testCase {
> +		fc := funcs[ast.Sqrt]
>
> This will get a function of SQRT.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/pingcap/tidb/pull/2830#pullrequestreview-27024698>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ALfcneVnxrr-cTbRw5G8uLQIhBX86Bucks5rl69tgaJpZM4MdrYn>
> .
>
   [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2828) <br/>All committers have signed the CLA. Thanks for the review. And I think I should point out there are some useless lines in `sqrt` function as well...   ## What did I do?

``` shell
$ git clone https://github.com/pingcap/tidb.git $GOPATH/src/github.com/pingcap/tidb
$ cd $GOPATH/src/github.com/pingcap/tidb
$ make
```
## What did I expect to see?

nothing

## What did I see instead?

```
session.go:21:4: cannot find package "context" in any of:
```

## What version of Go am I using (`go version`)?

1.6

## How did I workaround this?

Upgrade my go version to 1.8.

## The root cause and possible way to fix it?

`context` became part of the standard library in Go 1.7, but [quick start](https://github.com/zzl0/tidb/blob/master/docs/QUICKSTART.md#pre-requirement) says tidb support Go >= 1.5.

Looking at the code, it seems tidb is inconsistent in the usage of `context` package, some files still use `golang.org/x/net/context`, should we use the standard `context` package and upgrade version Go >= 1.7? Maybe you should add go 1.5 ~ 1.8 in [CI](https://github.com/pingcap/tidb/blob/master/.travis.yml) to avoid such issue also.  ```go
// See https://dev.mysql.com/doc/refman/5.7/en/string-functions.html#function_make-set
func (b *builtinMakeSetSig) eval(row []types.Datum) (d string, err error) {
	var bitMask int
	var s []string

	switch maskValue := row[0].(type) {
	case int:
		bitMask = maskValue
	default:
		fmt.Println("row[0] must be a 'int'")
		return "", errors.New("row[0] must be a 'int'")
	}

	for index, value := range row[1:] {
		switch valueValue := value.(type) {
		case string:
			if (value != "") && (index&bitMask != 0) {
				s = append(s, valueValue)
			}
		}
	}
	
	d = strings.Join(s, ",")
	return
}
``` [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2825) <br/>All committers have signed the CLA.  fix a typo from 'convertion' to 'conversion' in line 24 [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2814) <br/>All committers have signed the CLA.  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
If possible, provide a recipe for reproducing the error.


2. What did you expect to see?



3. What did you see instead?



4. What version of Go are you using (`go version`)?

  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
If possible, provide a recipe for reproducing the error.
mysql -h ip -P 4000 -D XXX (the XXX is our database name not default databases)


2. What did you expect to see?
I should login the databases


3. What did you see instead?
Mysql client log:
ERROR 2013 (HY000): Lost connection to MySQL server at 'reading authorization packet', system error: 0
tidb-server log:
2017/03/09 16:59:08 server.go:116: [info] [1] new connection XXXXX:52320
2017/03/09 16:59:08 session.go:523: [warning] [1] parse error:
line 0 column 9 near "" (total length 9)
use XXX   -----------------this is mys database name
2017/03/09 16:59:08 server.go:199: [info] handshake error line 0 column 9 near "" (total length 9)
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/parser/yy_parser.go:96: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/session.go:524: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/driver_tidb.go:135: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:307: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:99: 
2017/03/09 16:59:08 server.go:193: [info] [1] close connection

4. What version of Go are you using (`go version`)?
1.7
 Would you pls fix this issue as soon as possible ? I updated the tidb to the latest version yesterday. The last version was OK I mean the latest version was not Ok. The previous was OK.
Did this issue fixed ?  tidb-server -V
Git Commit Hash: a623e670e64311d35001a41a86a991cafce3e06e
UTC Build Time:  2017-03-08 05:33:20 The previous version I have used:
Git Commit Hash: 31d3b87704d5bc8b624defaa34d3a060105482b7
UTC Build Time:  2017-02-15 05:35:13 Our Database name was 'quote'. Is this name a invalid name.  If you can not reproduce this issue, you could try to use 'quote' as the database name.  It seems that the tidb was blocked when 'Create Index idex_1 on t1 ...'，because 'Delete from t1 where date='2017-02-06' ' and 'Create table t2'   cannot execute.

**tidb version:**
Git Commit Hash: fc93cd51290c62bf760390b4c501f03e37c21c0e
UTC Build Time:  2017-03-06 02:38:56

**tidb status:**
mysql> show status;
+--------------------------+--------------------------------------+
| Variable_name            | Value                                |
+--------------------------+--------------------------------------+
| ddl_owner_id             | 46f91ed0-4566-4c19-8cbe-557714ce039b |
| ddl_job_last_update_ts   | 1488881607                           |
| ddl_job_args             | []                                   |
| server_id                | 46f91ed0-4566-4c19-8cbe-557714ce039b |
| ddl_schema_version       | 2316                                 |
| ddl_job_table_id         | 26                                   |
| ddl_job_reorg_handle     | 49440769                             |
| ddl_job_row_count        | 49440768                             |
| bg_owner_last_update_ts  | 1488881606                           |
| ddl_job_schema_state     | write reorganization                 |
| ddl_job_action           | add index                            |
| ddl_owner_last_update_ts | 1488881607                           |
| ddl_job_snapshot_ver     | 390300009275326466                   |
| bg_owner_id              | 46f91ed0-4566-4c19-8cbe-557714ce039b |
| ddl_job_error            |                                      |
| ddl_job_id               | 28                                   |
| ddl_job_schema_id        | 1                                    |
| ddl_job_state            | running                              |
| bg_schema_version        | 2316                                 |
+--------------------------+--------------------------------------+ @shenli 
How many rows are there in t1?   
**160 million**

Is there any error when you run Delete from t1 where date='2017-02-06?  
**A lot of time has passed，get this:
ERROR 1105 (HY000): Information schema is changed.**

DDL statement will run in sequence, so the statement may be waiting for the previous statement to finish.
**You can add new columns and indices without stopping or affecting the on-going operations.** @shenli OK.  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
If possible, provide a recipe for reproducing the error.
1）我用navicat 连接tidb操作的时候，不能在编辑窗口直接修改数据
2）不支持中文注释
3）创建表或者其他的操作，常报1105的错误

2. What did you expect to see?

1）希望能直接在navicat操作数据
2）希望支持中文注释

3. What did you see instead?



4. What version of Go are you using (`go version`)?

 navicat version is win7 + navicat premium 10.0.9
tidb doesn't support comments in chinese by create table by sql too sorry , my os is centos6 ,  pls tell me tidb support comments in chinese?  which version 
i will setup tidb to centos7 today, and try to test it again  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
create a rails orm model
```
rails g model Book name:string
```
then run
```
rake db:migrate
```


2. What did you expect to see?
wish the table automaticlly to be created.


3. What did you see instead?
rails console error and tidb-server error log
```
== 20170301132943 CreateBooks: migrating ======================================
-- create_table(:books)
   -> 0.0024s
== 20170301132943 CreateBooks: migrated (0.0025s) =============================

rake aborted!
ActiveRecord::StatementInvalid: Mysql2::Error: line 8 column 6 near " (constraint_schema, constraint_name)
WHERE fk.referenced_column_name IS NOT NULL
  AND fk.table_schema = 'demo_development'
  AND fk.table_name = 'books'
" (total length 500): SELECT fk.referenced_table_name AS 'to_table',
       fk.referenced_column_name AS 'primary_key',
       fk.column_name AS 'column',
       fk.constraint_name AS 'name',
       rc.update_rule AS 'on_update',
       rc.delete_rule AS 'on_delete'
FROM information_schema.key_column_usage fk
JOIN information_schema.referential_constraints rc
USING (constraint_schema, constraint_name)
WHERE fk.referenced_column_name IS NOT NULL
  AND fk.table_schema = 'demo_development'
  AND fk.table_name = 'books'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/mysql2-0.4.5/lib/mysql2/client.rb:120:in `_query'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/mysql2-0.4.5/lib/mysql2/client.rb:120:in `block in query'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/mysql2-0.4.5/lib/mysql2/client.rb:119:in `handle_interrupt'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/mysql2-0.4.5/lib/mysql2/client.rb:119:in `query'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract_mysql_adapter.rb:218:in `block in execute'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract_adapter.rb:589:in `block in log'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activesupport-5.0.1/lib/active_support/notifications/instrumenter.rb:21:in `instrument'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract_adapter.rb:583:in `log'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract_mysql_adapter.rb:218:in `execute'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/mysql/database_statements.rb:31:in `execute'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract_mysql_adapter.rb:225:in `execute_and_free'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/mysql/database_statements.rb:36:in `exec_query'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract/database_statements.rb:373:in `select'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract/database_statements.rb:41:in `select_all'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract/query_cache.rb:95:in `select_all'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/mysql/database_statements.rb:10:in `select_all'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract_mysql_adapter.rb:520:in `foreign_keys'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/schema_dumper.rb:225:in `foreign_keys'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/schema_dumper.rb:97:in `block in tables'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/schema_dumper.rb:96:in `each'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/schema_dumper.rb:96:in `tables'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/schema_dumper.rb:37:in `dump'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/schema_dumper.rb:21:in `dump'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/railties/databases.rake:253:in `block (4 levels) in <top (required)>'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/railties/databases.rake:252:in `open'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/railties/databases.rake:252:in `block (3 levels) in <top (required)>'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/railties/databases.rake:66:in `block (2 levels) in <top (required)>'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/railties/databases.rake:59:in `block (2 levels) in <top (required)>'
/Users/mmc/.rvm/gems/ruby-2.4.0@global/gems/rake-12.0.0/exe/rake:27:in `<top (required)>'
Mysql2::Error: line 8 column 6 near " (constraint_schema, constraint_name)
WHERE fk.referenced_column_name IS NOT NULL
  AND fk.table_schema = 'demo_development'
  AND fk.table_name = 'books'
" (total length 500)
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/mysql2-0.4.5/lib/mysql2/client.rb:120:in `_query'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/mysql2-0.4.5/lib/mysql2/client.rb:120:in `block in query'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/mysql2-0.4.5/lib/mysql2/client.rb:119:in `handle_interrupt'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/mysql2-0.4.5/lib/mysql2/client.rb:119:in `query'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract_mysql_adapter.rb:218:in `block in execute'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract_adapter.rb:589:in `block in log'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activesupport-5.0.1/lib/active_support/notifications/instrumenter.rb:21:in `instrument'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract_adapter.rb:583:in `log'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract_mysql_adapter.rb:218:in `execute'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/mysql/database_statements.rb:31:in `execute'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract_mysql_adapter.rb:225:in `execute_and_free'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/mysql/database_statements.rb:36:in `exec_query'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract/database_statements.rb:373:in `select'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract/database_statements.rb:41:in `select_all'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract/query_cache.rb:95:in `select_all'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/mysql/database_statements.rb:10:in `select_all'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/connection_adapters/abstract_mysql_adapter.rb:520:in `foreign_keys'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/schema_dumper.rb:225:in `foreign_keys'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/schema_dumper.rb:97:in `block in tables'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/schema_dumper.rb:96:in `each'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/schema_dumper.rb:96:in `tables'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/schema_dumper.rb:37:in `dump'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/schema_dumper.rb:21:in `dump'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/railties/databases.rake:253:in `block (4 levels) in <top (required)>'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/railties/databases.rake:252:in `open'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/railties/databases.rake:252:in `block (3 levels) in <top (required)>'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/railties/databases.rake:66:in `block (2 levels) in <top (required)>'
/Users/mmc/.rvm/gems/ruby-2.4.0/gems/activerecord-5.0.1/lib/active_record/railties/databases.rake:59:in `block (2 levels) in <top (required)>'
/Users/mmc/.rvm/gems/ruby-2.4.0@global/gems/rake-12.0.0/exe/rake:27:in `<top (required)>'
Tasks: TOP => db:schema:dump
(See full trace by running task with --trace)
```

after i execute
```
rails g model Book name:string
```
20170301132943_create_books.rb
```
class CreateBooks < ActiveRecord::Migration[5.0]
  def change
    create_table :books do |t|
      t.string :name

      t.timestamps
    end
  end
end
```

then i execute
```
rake db:migrate
```
error info appeared

here is the tidb-server log
```
2017/03/01 21:31:03 metrics.go:322: [warning] [EXPENSIVE_QUERY] SELECT `schema_migrations`.* FROM `schema_migrations`
2017/03/01 21:31:03 session.go:523: [warning] [8] parse error:
line 8 column 6 near " (constraint_schema, constraint_name)
WHERE fk.referenced_column_name IS NOT NULL
  AND fk.table_schema = 'demo_development'
  AND fk.table_name = 'books'
" (total length 500)
SELECT fk.referenced_table_name AS 'to_table',
       fk.referenced_column_name AS 'primary_key',
       fk.column_name AS 'column',
       fk.constraint_name AS 'name',
       rc.update_rule AS 'on_update',
       rc.delete_rule AS 'on_delete'
FROM information_schema.key_column_usage fk
JOIN information_schema.referential_constraints rc
USING (constraint_schema, constraint_name)
WHERE fk.referenced_column_name IS NOT NULL
  AND fk.table_schema = 'demo_development'
  AND fk.table_name = 'books'

2017/03/01 21:31:03 conn.go:356: [warning] [8] dispatch error:
id:8, addr:127.0.0.1:49317 status:2, collation:utf8_general_ci, user:root
SELECT fk.referenced_table_name AS 'to_table',
       fk.referenced_column_name AS 'primary_key',
       fk.column_name AS 'column',
       fk.constraint_name AS 'name',
       rc.update_rule AS 'on_update',
       rc.delete_rule AS 'on_delete'
FROM information_schema.key_column_usage fk
JOIN information_schema.referential_constraints rc
USING (constraint_schema, constraint_name)
WHERE fk.referenced_column_name IS NOT NULL
  AND fk.table_schema = 'demo_development'
  AND fk.table_name = 'books'

line 8 column 6 near " (constraint_schema, constraint_name)
WHERE fk.referenced_column_name IS NOT NULL
  AND fk.table_schema = 'demo_development'
  AND fk.table_name = 'books'
" (total length 500)
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/parser/yy_parser.go:96:
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/session.go:524:
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/server/conn.go:661:
2017/03/01 21:31:03 server.go:193: [info] [8] close connection
```

my tidb version is tidb-server rc2

4. What version of Go are you using (`go version`)?
```
go version go1.8 darwin/amd64
```
  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
```
mycli -u root -P 4000
```


2. What did you expect to see?
wish to see connect ok


3. What did you see instead?
```
Version: 1.7.1
Chat: https://gitter.im/dbcli/mycli
Mail: https://groups.google.com/forum/#!forum/mycli-users
Home: http://mycli.net
Thanks to the contributor - Tech Blue Software
Traceback (most recent call last):
  File "/Users/mmc/dev/python/python2/bin/mycli", line 11, in <module>
    sys.exit(cli())
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/click/core.py", line 716, in __call__
    return self.main(*args, **kwargs)
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/click/core.py", line 696, in main
    rv = self.invoke(ctx)
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/click/core.py", line 889, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/click/core.py", line 534, in invoke
    return callback(*args, **kwargs)
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/mycli/main.py", line 767, in cli
    mycli.run_cli()
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/mycli/main.py", line 476, in run_cli
    document = self.cli.run(reset_current_buffer=True)
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/prompt_toolkit/interface.py", line 399, in run
    self._redraw()
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/prompt_toolkit/interface.py", line 346, in _redraw
    self.renderer.render(self, self.layout, is_done=self.is_done)
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/prompt_toolkit/renderer.py", line 429, in render
    extended_height=size.rows,
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/prompt_toolkit/layout/containers.py", line 142, in write_to_screen
    sizes = self._divide_heigths(cli, write_position)
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/prompt_toolkit/layout/containers.py", line 177, in _divide_heigths
    dimensions = [get_dimension_for_child(c, index) for index, c in enumerate(self.children)]
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/prompt_toolkit/layout/containers.py", line 175, in get_dimension_for_child
    return c.preferred_height(cli, write_position.width, write_position.extended_height)
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/prompt_toolkit/layout/containers.py", line 395, in preferred_height
    return self.content.preferred_height(cli, width, max_available_height)
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/prompt_toolkit/layout/containers.py", line 128, in preferred_height
    dimensions = [c.preferred_height(cli, width, max_available_height) for c in self.children]
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/prompt_toolkit/layout/containers.py", line 1649, in preferred_height
    if self.filter(cli):
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/prompt_toolkit/filters/base.py", line 229, in __call__
    return self.func(*a, **kw)
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/prompt_toolkit/shortcuts.py", line 150, in has_before_tokens
    for token, char in get_prompt_tokens(cli):
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/mycli/main.py", line 436, in prompt_tokens
    return [(Token.Prompt, self.get_prompt(self.prompt_format))]
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/mycli/main.py", line 676, in get_prompt
    string = string.replace('\\t', sqlexecute.server_type()[0] or 'mycli')
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/mycli/sqlexecute.py", line 200, in server_type
    cur.execute(self.version_query)
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/pymysql/cursors.py", line 161, in execute
    result = self._query(query)
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/pymysql/cursors.py", line 317, in _query
    conn.query(q)
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/pymysql/connections.py", line 837, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/pymysql/connections.py", line 1021, in _read_query_result
    result.read()
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/pymysql/connections.py", line 1304, in read
    first_packet = self.connection._read_packet()
  File "/Users/mmc/dev/python/python2/lib/python2.7/site-packages/pymysql/connections.py", line 970, in _read_packet
    (packet_number, self._next_seq_id))
pymysql.err.InternalError: Packet sequence number wrong - got 3 expected 1
```

here is the tidb error log
```
017/03/01 20:32:12 server.go:116: [info] [14] new connection [::1]:50080
2017/03/01 20:32:12 server.go:116: [info] [15] new connection [::1]:50081
2017/03/01 20:32:12 conn.go:356: [warning] [15] dispatch error:
id:15, addr:[::1]:50081 status:2, collation:utf8_general_ci, user:root
SHOW TABLES
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/executor/show.go:180: Can not find DB:
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/executor/show.go:71:
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/executor/adapter.go:64:
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/server/driver_tidb.go:290:
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/server/conn.go:714:
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/server/conn.go:679:
2017/03/01 20:32:12 session.go:537: [warning] [15] compile error:
[schema:1146]Table 'INFORMATION_SCHEMA.ROUTINES' doesn't exist
SELECT ROUTINE_NAME FROM INFORMATION_SCHEMA.ROUTINES
    WHERE ROUTINE_TYPE="FUNCTION" AND ROUTINE_SCHEMA = "None"
2017/03/01 20:32:12 conn.go:356: [warning] [15] dispatch error:
id:15, addr:[::1]:50081 status:2, collation:utf8_general_ci, user:root
SELECT ROUTINE_NAME FROM INFORMATION_SCHEMA.ROUTINES
    WHERE ROUTINE_TYPE="FUNCTION" AND ROUTINE_SCHEMA = "None"
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/infoschema/infoschema.go:172: [schema:1146]Table 'INFORMATION_SCHEMA.ROUTINES' doesn't exist
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/plan/resolver.go:367:
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/plan/resolver.go:35:
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/plan/preprocess.go:26:
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/executor/compiler.go:35:
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/tidb.go:168:
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/session.go:539:
/Users/mmc/dev/golang/3rdLibs/src/github.com/pingcap/tidb/server/conn.go:661:
2017/03/01 20:32:12 server.go:193: [info] [15] close connection
2017/03/01 20:32:12 server.go:193: [info] [14] close connection
```

i use tidb-server rc2

4. What version of Go are you using (`go version`)?
```
go version go1.8 darwin/amd64
```
  What i can do ?

mysql> select count(1) from std_pro_iver_cha_rso_event;
+----------+
| count(1) |
+----------+
|  1460000 |
+----------+
mysql> delete from std_pro_iver_cha_rso_event; 
ERROR 1105 (HY000): transaction is too large

mysql> set autocommit=0;
Query OK, 0 rows affected (0.00 sec)

mysql> delete from std_pro_iver_cha_rso_event;
Query OK, 1460000 rows affected (8.33 sec)

mysql> commit;
ERROR 1105 (HY000): transaction is too large



  1. What did you do?
Server version: 5.7.1-TiDB-1.0 MySQL Community Server (GPL)
mysql> load data infile '/tmp/std_pro_iver_cha_rso_event.txt' into table std_pro_iver_cha_rso_event fields TERMINATED by '|';

2. What did you expect to see?

3. What did you see instead?
ERROR 1105 (HY000): Load Data: don't support load data without local field

4. What version of Go are you using (`go version`)?

**tidb-server log:**

2017/02/28 11:05:21 session.go:511: [warning] [21] session error:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/executor/write.go:545: Load Data: don't support load data without local field
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/executor/adapter.go:143: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/tidb.go:186: 
{
  "currDBName": "test",
  "id": 21,
  "stauts": 2,
  "strictMode": true,
  "user": "root@xxxx"
}
2017/02/28 11:05:21 conn.go:355: [warning] [21] dispatch error:
id:21, addr:xxxxx:47923 status:2, collation:utf8_general_ci, user:root
load data infile '/tmp/std_pro_iver_cha_rso_event.txt' into table std_pro_iver_cha_rso_event fields TERMINATED by '|'
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/executor/write.go:545: Load Data: don't support load data without local field
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/executor/adapter.go:143: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/tidb.go:186: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/session.go:513: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:660: 

 @zimulala 
mysql> load data local infile '/tmp/std_pro_iver_cha_rso_event.txt' into table std_pro_iver_cha_rso_event fields TERMINATED by '|';
ERROR 1148 (42000): the used command is not allowed with this TiDB version @zimulala 
Git Commit Hash: 0282310e8b2aa286a76be95f9b4558f84def5d05
UTC Build Time:  2017-02-23 07:19:58 @zimulala This problem has been solved,thx!  Trying to run this command on creating a new table

- MySQL dump 10.13  Distrib 5.7.11, for Linux (x86_64)
--
-- Host: localhost    Database: database
-- ------------------------------------------------------
-- Server version       5.7.11

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;


I get this error;

cat database.sql |  mysql -h 127.0.0.1 -P 4000 -u root
ERROR 1105 (HY000) at line 26: line 6 column 15 near "" (total length 140)

Line  6 is a blank line...
 File is produced by mysqldump  Trying to import an existing database and running into this error;

ERROR 1105 (HY000) at line 30: unknown column password

Line 30 contains;

DROP TABLE IF EXISTS `table`;
 No, the table was literally named table.

I can attach the entire import file if you would like The log in docker?

e.g.
/var/lib/docker/aufs/diff/d380d7aa5f89557927d720e7fe899d06022f56c3c5a1d9ac9e3afa1cb66fcb50/tmp/tidb/000002.log
  Please answer these questions before submitting your issue. Thanks!

1. What did you do?

I tried to start up a new TiDB cluster in 4 servers
10.2.0.239                    1 PD, 1 TiDB
10.2.0.240/241/242        3 TiKV
It's double-checked that no old data in the configured directories. After PD and 3 TiKV were started, TiDB failed to start up.

2. What did you expect to see?

TiDB should start up successfully without any error in its logs.

3. What did you see instead?

TiDB failed to provide service at the configured port, with logs as following:

```
2017/02/25 21:25:26 printer.go:31: [info] Welcome to TiDB.
2017/02/25 21:25:26 printer.go:32: [info] Version:
2017/02/25 21:25:26 printer.go:33: [info] Git Commit Hash: 7882b66f2b1c1de7a83534b894a5b78af7543560
2017/02/25 21:25:26 printer.go:34: [info] UTC Build Time:  2017-02-25 01:25:00
2017/02/25 21:25:26 kv.go:296: [info] [kv] New store /tmp/tidb 
2017/02/25 21:25:26 tidb.go:68: [info] store d31c8d12-682e-4aea-8e3c-1ec335ec18fc new domain, lease 0s
2017/02/25 21:25:26 ddl.go:177: [info] start DDL:f80202ba-d32a-4125-a445-4de4e6b54dd9
2017/02/25 21:25:26 domain.go:86: [info] [ddl] full load InfoSchema from version 0 to 0, in 178.925µs
2017/02/25 21:25:26 tidb.go:181: [info] RollbackTxn for ddl/autocommit error. 
2017/02/25 21:25:26 txn.go:143: [info] [kv] Rollback txn 390077907308380162
2017/02/25 21:25:26 session.go:512: [warning] [0] session error:
/media/genius/OS/project/src/github.com/pingcap/tidb/executor/simple.go:97: [schema:1049]Unknown database 'mysql'
/media/genius/OS/project/src/github.com/pingcap/tidb/executor/simple.go:82: 
/media/genius/OS/project/src/github.com/pingcap/tidb/executor/adapter.go:143: 
/media/genius/OS/project/src/github.com/pingcap/tidb/tidb.go:187: 
{
  "currDBName": "",
  "id": 0,
  "stauts": 2,
  "strictMode": true,
  "user": ""
}
2017/02/25 21:25:26 session.go:498: [warning] [0] compile error:
[schema:1146]Table 'mysql.tidb' doesn't exist
SELECT VARIABLE_VALUE FROM mysql.tidb WHERE VARIABLE_NAME="bootstrapped"
2017/02/25 21:25:26 ddl.go:325: [info] [ddl] start DDL job ID:2, Type:create schema, State:none, SchemaState:none, SchemaID:1, TableID:0, RowCount:0, ArgLen:1, Query:
CREATE DATABASE IF NOT EXISTS test
2017/02/25 21:25:26 ddl_worker.go:342: [info] [ddl] run DDL job ID:2, Type:create schema, State:none, SchemaState:none, SchemaID:1, TableID:0, RowCount:0, ArgLen:0
2017/02/25 21:25:26 ddl_worker.go:190: [info] [ddl] finish DDL job ID:2, Type:create schema, State:done, SchemaState:public, SchemaID:1, TableID:0, RowCount:0, ArgLen:1
2017/02/25 21:25:26 ddl.go:361: [info] [ddl] DDL job 2 is finished
2017/02/25 21:25:26 domain.go:312: [info] [ddl] on DDL change, must reload
2017/02/25 21:25:26 domain.go:86: [info] [ddl] full load InfoSchema from version 0 to 1, in 237.943µs
2017/02/25 21:25:26 ddl.go:325: [info] [ddl] start DDL job ID:4, Type:create schema, State:none, SchemaState:none, SchemaID:3, TableID:0, RowCount:0, ArgLen:1, Query:
CREATE DATABASE IF NOT EXISTS mysql;
2017/02/25 21:25:26 ddl_worker.go:342: [info] [ddl] run DDL job ID:4, Type:create schema, State:none, SchemaState:none, SchemaID:3, TableID:0, RowCount:0, ArgLen:0
2017/02/25 21:25:26 ddl_worker.go:190: [info] [ddl] finish DDL job ID:4, Type:create schema, State:done, SchemaState:public, SchemaID:3, TableID:0, RowCount:0, ArgLen:1
2017/02/25 21:25:26 ddl.go:361: [info] [ddl] DDL job 4 is finished
2017/02/25 21:25:26 domain.go:312: [info] [ddl] on DDL change, must reload
2017/02/25 21:25:26 domain.go:72: [info] [ddl] diff load InfoSchema from version 1 to 2, in 53.347µs
2017/02/25 21:25:26 ddl.go:325: [info] [ddl] start DDL job ID:6, Type:create table, State:none, SchemaState:none, SchemaID:3, TableID:5, RowCount:0, ArgLen:1, Query:
CREATE TABLE if not exists mysql.user (
		Host			CHAR(64),
		User			CHAR(16),
		Password		CHAR(41),
		Select_priv		ENUM('N','Y') NOT NULL  DEFAULT 'N',
		Insert_priv		ENUM('N','Y') NOT NULL  DEFAULT 'N',
		Update_priv		ENUM('N','Y') NOT NULL  DEFAULT 'N',
		Delete_priv		ENUM('N','Y') NOT NULL  DEFAULT 'N',
		Create_priv		ENUM('N','Y') NOT NULL  DEFAULT 'N',
		Drop_priv		ENUM('N','Y') NOT NULL  DEFAULT 'N',
		Grant_priv		ENUM('N','Y') NOT NULL  DEFAULT 'N',
		Alter_priv		ENUM('N','Y') NOT NULL  DEFAULT 'N',
		Show_db_priv		ENUM('N','Y') NOT NULL  DEFAULT 'N',
		Execute_priv		ENUM('N','Y') NOT NULL  DEFAULT 'N',
		Index_priv		ENUM('N','Y') NOT NULL  DEFAULT 'N',
		Create_user_priv	ENUM('N','Y') NOT NULL  DEFAULT 'N',
		PRIMARY KEY (Host, User));
2017/02/25 21:25:26 ddl_worker.go:342: [info] [ddl] run DDL job ID:6, Type:create table, State:none, SchemaState:none, SchemaID:3, TableID:5, RowCount:0, ArgLen:0
2017/02/25 21:25:26 ddl_worker.go:190: [info] [ddl] finish DDL job ID:6, Type:create table, State:done, SchemaState:public, SchemaID:3, TableID:5, RowCount:0, ArgLen:1
2017/02/25 21:25:26 ddl.go:361: [info] [ddl] DDL job 6 is finished
2017/02/25 21:25:26 domain.go:312: [info] [ddl] on DDL change, must reload
2017/02/25 21:25:26 domain.go:72: [info] [ddl] diff load InfoSchema from version 2 to 3, in 510.739µs
2017/02/25 21:25:26 ddl.go:325: [info] [ddl] start DDL job ID:8, Type:create table, State:none, SchemaState:none, SchemaID:3, TableID:7, RowCount:0, ArgLen:1, Query:
CREATE TABLE if not exists mysql.db (
		Host		CHAR(60),
		DB		CHAR(64),
		User		CHAR(16),
		Select_priv	ENUM('N','Y') Not Null  DEFAULT 'N',
		Insert_priv	ENUM('N','Y') Not Null  DEFAULT 'N',
		Update_priv	ENUM('N','Y') Not Null  DEFAULT 'N',
		Delete_priv	ENUM('N','Y') Not Null  DEFAULT 'N',
		Create_priv	ENUM('N','Y') Not Null  DEFAULT 'N',
		Drop_priv	ENUM('N','Y') Not Null  DEFAULT 'N',
		Grant_priv	ENUM('N','Y') Not Null  DEFAULT 'N',
		Index_priv	ENUM('N','Y') Not Null  DEFAULT 'N',
		Alter_priv	ENUM('N','Y') Not Null  DEFAULT 'N',
		Execute_priv	ENUM('N','Y') Not Null  DEFAULT 'N',
		PRIMARY KEY (Host, DB, User));
2017/02/25 21:25:26 ddl_worker.go:342: [info] [ddl] run DDL job ID:8, Type:create table, State:none, SchemaState:none, SchemaID:3, TableID:7, RowCount:0, ArgLen:0
2017/02/25 21:25:26 ddl_worker.go:190: [info] [ddl] finish DDL job ID:8, Type:create table, State:done, SchemaState:public, SchemaID:3, TableID:7, RowCount:0, ArgLen:1
2017/02/25 21:25:26 ddl.go:361: [info] [ddl] DDL job 8 is finished
2017/02/25 21:25:26 domain.go:312: [info] [ddl] on DDL change, must reload
2017/02/25 21:25:26 domain.go:72: [info] [ddl] diff load InfoSchema from version 3 to 4, in 319.009µs
2017/02/25 21:25:26 ddl.go:325: [info] [ddl] start DDL job ID:10, Type:create table, State:none, SchemaState:none, SchemaID:3, TableID:9, RowCount:0, ArgLen:1, Query:
CREATE TABLE if not exists mysql.tables_priv (
		Host		CHAR(60),
		DB		CHAR(64),
		User		CHAR(16),
		Table_name	CHAR(64),
		Grantor		CHAR(77),
		Timestamp	Timestamp DEFAULT CURRENT_TIMESTAMP,
		Table_priv	SET('Select','Insert','Update','Delete','Create','Drop','Grant', 'Index','Alter'),
		Column_priv	SET('Select','Insert','Update'),
		PRIMARY KEY (Host, DB, User, Table_name));
2017/02/25 21:25:26 ddl_worker.go:342: [info] [ddl] run DDL job ID:10, Type:create table, State:none, SchemaState:none, SchemaID:3, TableID:9, RowCount:0, ArgLen:0
2017/02/25 21:25:26 ddl_worker.go:190: [info] [ddl] finish DDL job ID:10, Type:create table, State:done, SchemaState:public, SchemaID:3, TableID:9, RowCount:0, ArgLen:1
2017/02/25 21:25:26 ddl.go:361: [info] [ddl] DDL job 10 is finished
2017/02/25 21:25:26 domain.go:312: [info] [ddl] on DDL change, must reload
2017/02/25 21:25:26 domain.go:72: [info] [ddl] diff load InfoSchema from version 4 to 5, in 306.404µs
2017/02/25 21:25:26 ddl.go:325: [info] [ddl] start DDL job ID:12, Type:create table, State:none, SchemaState:none, SchemaID:3, TableID:11, RowCount:0, ArgLen:1, Query:
CREATE TABLE if not exists mysql.columns_priv(
		Host		CHAR(60),
		DB		CHAR(64),
		User		CHAR(16),
		Table_name	CHAR(64),
		Column_name	CHAR(64),
		Timestamp	Timestamp DEFAULT CURRENT_TIMESTAMP,
		Column_priv	SET('Select','Insert','Update'),
		PRIMARY KEY (Host, DB, User, Table_name, Column_name));
2017/02/25 21:25:26 ddl_worker.go:342: [info] [ddl] run DDL job ID:12, Type:create table, State:none, SchemaState:none, SchemaID:3, TableID:11, RowCount:0, ArgLen:0
2017/02/25 21:25:26 ddl_worker.go:190: [info] [ddl] finish DDL job ID:12, Type:create table, State:done, SchemaState:public, SchemaID:3, TableID:11, RowCount:0, ArgLen:1
2017/02/25 21:25:26 ddl.go:361: [info] [ddl] DDL job 12 is finished
2017/02/25 21:25:26 domain.go:312: [info] [ddl] on DDL change, must reload
2017/02/25 21:25:26 domain.go:72: [info] [ddl] diff load InfoSchema from version 5 to 6, in 164.483µs
2017/02/25 21:25:26 ddl.go:325: [info] [ddl] start DDL job ID:14, Type:create table, State:none, SchemaState:none, SchemaID:3, TableID:13, RowCount:0, ArgLen:1, Query:
CREATE TABLE if not exists mysql.GLOBAL_VARIABLES(
		VARIABLE_NAME  VARCHAR(64) Not Null PRIMARY KEY,
		VARIABLE_VALUE VARCHAR(1024) DEFAULT Null);
2017/02/25 21:25:26 ddl_worker.go:342: [info] [ddl] run DDL job ID:14, Type:create table, State:none, SchemaState:none, SchemaID:3, TableID:13, RowCount:0, ArgLen:0
2017/02/25 21:25:26 ddl_worker.go:190: [info] [ddl] finish DDL job ID:14, Type:create table, State:done, SchemaState:public, SchemaID:3, TableID:13, RowCount:0, ArgLen:1
2017/02/25 21:25:26 ddl.go:361: [info] [ddl] DDL job 14 is finished
2017/02/25 21:25:26 domain.go:312: [info] [ddl] on DDL change, must reload
2017/02/25 21:25:26 domain.go:72: [info] [ddl] diff load InfoSchema from version 6 to 7, in 111.538µs
2017/02/25 21:25:26 ddl.go:325: [info] [ddl] start DDL job ID:16, Type:create table, State:none, SchemaState:none, SchemaID:3, TableID:15, RowCount:0, ArgLen:1, Query:
CREATE TABLE if not exists mysql.tidb(
		VARIABLE_NAME  VARCHAR(64) Not Null PRIMARY KEY,
		VARIABLE_VALUE VARCHAR(1024) DEFAULT Null,
		COMMENT VARCHAR(1024));
2017/02/25 21:25:26 ddl_worker.go:342: [info] [ddl] run DDL job ID:16, Type:create table, State:none, SchemaState:none, SchemaID:3, TableID:15, RowCount:0, ArgLen:0
2017/02/25 21:25:26 ddl_worker.go:190: [info] [ddl] finish DDL job ID:16, Type:create table, State:done, SchemaState:public, SchemaID:3, TableID:15, RowCount:0, ArgLen:1
2017/02/25 21:25:26 ddl.go:361: [info] [ddl] DDL job 16 is finished
2017/02/25 21:25:26 domain.go:312: [info] [ddl] on DDL change, must reload
2017/02/25 21:25:26 domain.go:72: [info] [ddl] diff load InfoSchema from version 7 to 8, in 116.8µs
2017/02/25 21:25:26 ddl.go:325: [info] [ddl] start DDL job ID:18, Type:create table, State:none, SchemaState:none, SchemaID:3, TableID:17, RowCount:0, ArgLen:1, Query:
CREATE TABLE if not exists mysql.help_topic (
  		help_topic_id int(10) unsigned NOT NULL,
  		name char(64) NOT NULL,
  		help_category_id smallint(5) unsigned NOT NULL,
  		description text NOT NULL,
  		example text NOT NULL,
  		url text NOT NULL,
  		PRIMARY KEY (help_topic_id),
  		UNIQUE KEY name (name)
		) ENGINE=InnoDB DEFAULT CHARSET=utf8 STATS_PERSISTENT=0 COMMENT='help topics';
2017/02/25 21:25:26 ddl_worker.go:342: [info] [ddl] run DDL job ID:18, Type:create table, State
```

4. What version of Go are you using (`go version`)?
go version go1.7 linux/amd64 ```
PD     branch huachao/shuffle-region, 92b3cef
TiDB   branch master, 7882b66
TiKV   branch hhkbp2/sst-file-snapshot-v2, bd776fe
``` Any update?  PTAL @shenli @tiancaiamao  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2735) <br/>All committers have signed the CLA.  hi,
   I use 6 machines(32core, 64g), and multi product mode, just like this
Name	Host IP	Services
node1	192.168.199.113	PD1, TiDB
node2	192.168.199.114	PD2
node3	192.168.199.115	PD3
node4	192.168.199.116	TiKV1
node5	192.168.199.117	TiKV2
node6	192.168.199.118	TiKV3


but when i use tpch(1g data) for query, the executor is so cost time.

the sql1 query cost 48s, but on postgres only cost 3s
can some one give me some information  As TiDB declares strong consistency , I expect it should support SERIALIZABLE isolation level.

When I run test from "Hermitage" test suite
https://github.com/vadimtk/hermitage/blob/master/mysql-innodb.md

both Read Skew and Write Skew test fails in SERIALIZABLE  level.

The example of queries, see:
MySQL "serializable" prevents Write Skew (G2-item) 
 Hi,

"select for .. update" helps in some cases, but  now I am trying serializable  and  Anti-Dependency Cycles (G2):
https://github.com/ept/hermitage/blob/master/mysql.md#anti-dependency-cycles-g2

In TiDB Anti-Dependency Cycles (G2) is not prevented in serializable level.

 more on why G2 must be prevented you can find there https://github.com/cockroachdb/cockroach/issues/10030 Then if you do not provide serializable, I recommend you should return an error on the following statement

`set session transaction isolation level serializable;`
 I am not familiar with your source code base, so I can't make a PR  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
If possible, provide a recipe for reproducing the error.


I have run the tpc-c test with 
* https://github.com/pingcap/tpcc-mysql
* https://github.com/Percona-Lab/tpcc-mysql

2. What did you expect to see?
get the benchmark like
```
<Constraint Check> (all must be [OK])
 [transaction percentage]
        Payment: 43.482682% (>=43.0%) [OK]
   Order-Status: 4.348866% (>= 4.0%) [OK]
       Delivery: 4.342884% (>= 4.0%) [OK]
    Stock-Level: 4.348866% (>= 4.0%) [OK]
 [response time (at least 90% passed)]
      NewOrder: 100.000000%  [OK]
      Payment: 100.000000%  [OK]
      Order Stat: 100.000000%  [OK]
      Delivery: 100.000000%  [OK]
      Slev: 100.000000%  [OK]
 NewOrder Total: 7268
 Payment Total: 7269
 Order Stat Total: 727
 Delivery Total: 726
 Slev Total: 727

<TpmC>
7265.215 TpmC
```
3. What did you see instead?
out error message like 

``` 
  payment 1:2
  0, 00000,
  payment 2:2
  neword 14:1
  0, 00000,
```
```
<Constraint Check> (all must be [OK])
 [transaction percentage]
        Payment: -nan% (>=43.0%) [NG] *
   Order-Status: -nan% (>= 4.0%) [NG] *
       Delivery: -nan% (>= 4.0%) [NG] *
    Stock-Level: -nan% (>= 4.0%) [NG] *
 [response time (at least 90% passed)]
      New-Order: -nan%  [NG] *
        Payment: -nan%  [NG] *
   Order-Status: -nan%  [NG] *
       Delivery: -nan%  [NG] *
    Stock-Level: -nan%  [NG] *

<TpmC>
                 0.000 TpmC
```


4. What version of Go are you using (`go version`)?

  LGTM  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
I wanna get the information of foreign key by `information_schema`'s table which store the information of FK. But the table about FK in `information_schema` is empty. Then other way to get FK information is by command of `show create table`. U know this is very hard to parse in this way. There is no comma between two FK when using command `show create table`. A bug?

2. What did you expect to see?
So I hope that Tidb can support that store the FK information in `information_schema`. Thx very much.


3. What did you see instead?
The table about FK in  `information_schema` is empty.  Hi folks,

I was testing a 3-nodes deployment of a TiDB cluster with default settings and observed a situation when TiDB stoped serving requests for 2 minutes 40 seconds. It happened when a leader got separated from the peers. The unavailable window is too wide so I believe that it a bug rather than an expected behavior.

The version of the TiDB is

    rystsov@acceptor1:/mnt/perseus/tikv$ ./tidb-latest-linux-amd64/bin/pd-server --version
    Git Commit Hash: f5744d7b52aa4793b84cfdcd4efae1fc9a9bac6b
    UTC Build Time:  2017-02-17 09:18:31
    
    rystsov@acceptor1:/mnt/perseus/tikv$ ./tidb-latest-linux-amd64/bin/tikv-server --version
    Git Commit Hash: eb185b3babc476080306fef7c05b7673c1342455
    UTC Build Time:  2017-02-17 08:12:57
    Rustc Version:   1.17.0-nightly (ba7cf7cc5 2017-02-11)
    
    rystsov@acceptor1:/mnt/perseus/tikv$ ./tidb-latest-linux-amd64/bin/tidb-server -V
    Git Commit Hash: a8d185d8cb8485e1a124919d0df8b10a16bc6e40
    UTC Build Time:  2017-02-17 08:50:53

The client app opened a connection to each of the nodes and was continuously running the following loop per each of them:

 1. read a value by a key
 2. if the wasn't set then set it to 0
 3. increment the value
 4. write it back
 5. increment a number of successful iterations
 6. repeat the loop

Each connection used its own key to avoid collision. If there was an error during the loop then it closed the current connection, opened a new one and began the next iteration.

Once in a second it dumped aggregated number of successful iterations per cluster and per each node for a last second.

When I separated a leader (10.0.0.7) from the peers with the following command:

    sudo iptables -A INPUT -s 10.0.0.5 -j DROP
    sudo iptables -A INPUT -s 10.0.0.6 -j DROP
    sudo iptables -A OUTPUT -d 10.0.0.5 -j DROP
    sudo iptables -A OUTPUT -d 10.0.0.6 -j DROP

the cluster became unavailable for more than two minutes (the rate of successful iterations dropped to zero)

Please see this repo for client's code, more information about the incident and the repro steps https://github.com/rystsov/perseus/tree/master/tidb Hi @siddontang 

I'll be able to provide the logs in a couple of days.

> This is caused that your test client connects the TiDB in 10.0.0.7, but this TiDB can't connect to other PDs and TiKVs in 10.0.0.5 and 10.0.0.6. After a long time retry, TiDB will return the test client a timeout error, then the test client will connect another TiDB and works.

It isn't 100% correct. My data shows that all cluster becomes unavailable so there is no other TiDB to connect to.

The test application opened 3 connections to each TiDB of the custer and was testing them independently (measuring the rate of successful operations per connection). After I isolated the first node (I called it a leader because the success rate for that node was higher than for the rest nodes) the rate dropped to zero for the whole cluster and it took more than 2 minutes to recover:

<pre>86  445 195 126 124
87  474 214 132 128
88  19  8   5   6
89  0   0   0   0
...
247 0   0   0   0
248 29  0   0   29
249 237 0   138 99
250 289 0   179 110
251 314 0   197 117</pre>

The first column is number of seconds since the beginning of the experiment, the second is the number of successful read-inc-write iterations per all cluster per last second. The last three columns are success rate per each of connection.

  LGTM LGTM  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
If possible, provide a recipe for reproducing the error.
I am reading you code for fun

2. What did you expect to see?
import (
    github.com/cznic/parser/yacc/parser



3. What did you see instead?
parser/lexer.go:95: undefined: yySymType
parser/misc.go:519: undefined: yySymType
parser/yy_parser.go:60: undefined: yySymType
parser/yy_parser.go:61: undefined: yySymType
parser/yy_parser.go:62: undefined: yySymType


4. What version of Go are you using (`go version`)?

 I was testing with AWS EC2 instance (t2.medium) and occured same error message with [this PPA](https://launchpad.net/~gophers/+archive/ubuntu/archive).

Environment:
```
ubuntu@ip-10-140-0-78:~$ uname -a
Linux ip-10-140-0-78 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
ubuntu@ip-10-140-0-78:~$ echo $PATH
/usr/lib/go-1.7/bin:/home/ubuntu/bin:/home/ubuntu/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
ubuntu@ip-10-140-0-78:~$ go version
go version go1.7.3 linux/amd64
ubuntu@ip-10-140-0-78:~$ echo $GOPATH
/home/ubuntu/go
ubuntu@ip-10-140-0-78:~$ ls -al $GOPATH
total 8
drwxrwxr-x 2 ubuntu ubuntu 4096 Feb 25 16:09 .
drwxr-xr-x 5 ubuntu ubuntu 4096 Feb 25 16:09 ..
```

Then `go get -v` first and then `make parser`:
```
ubuntu@ip-10-140-0-78:~$ git clone https://github.com/pingcap/tidb.git
[...]
ubuntu@ip-10-140-0-78:~$ cd tidb
ubuntu@ip-10-140-0-78:~/tidb$ go get -v
[...]
ubuntu@ip-10-140-0-78:~/tidb$ make parser
[...]
```

Finally, run `make`:

```
ubuntu@ip-10-140-0-78:~/tidb$ make
GOPATH=/home/ubuntu/tidb/_vendor:/home/ubuntu/go CGO_ENABLED=0 GO15VENDOREXPERIMENT="1" go build -ldflags '-X "github.com/pingcap/tidb/util/printer.TiDBBuildTS=2017-02-25 04:20:56" -X "github.com/pingcap/tidb/util/printer.TiDBGitHash=7882b66f2b1c1de7a83534b894a5b78af7543560"' -o bin/tidb-server tidb-server/main.go
# github.com/pingcap/tidb/parser
../go/src/github.com/pingcap/tidb/parser/lexer.go:95: undefined: yySymType
../go/src/github.com/pingcap/tidb/parser/misc.go:609: undefined: yySymType
../go/src/github.com/pingcap/tidb/parser/yy_parser.go:60: undefined: yySymType
../go/src/github.com/pingcap/tidb/parser/yy_parser.go:61: undefined: yySymType
../go/src/github.com/pingcap/tidb/parser/yy_parser.go:62: undefined: yySymType
Makefile:110: recipe for target 'server' failed
make: *** [server] Error 2
``` Someone in Twitter just noticed me that I should use `go get -v github.com/pingcap/tidb` and then change directory to `$GOPATH/src/github.com/pingcap/tidb` to compile.  And it works...  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
If possible, provide a recipe for reproducing the error.
start tidb server 

2. What did you expect to see?


3. What did you see instead?

2017/02/14 16:01:13 domain.go:289: [error] [ddl] reload schema in loop err /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/store/tikv/backoff.go:186: backoffer.maxSleep 10000ms is exceeded, errors:
stale_epoch:<> 
not leader: region_id:2 , ctx: region_id:2 region_epoch:<conf_ver:2 version:1 > peer:<id:3 store_id:1 > 
stale_epoch:<> 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/store/tikv/backoff.go:186: [try again later]
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/store/tikv/snapshot.go:204: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/store/tikv/snapshot.go:176: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/structure/string.go:40: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/structure/string.go:47: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/domain/domain.go:59: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/domain/domain.go:263: 

4. What version of Go are you using (`go version`)?
not use go
 tikv-server log:

2017/02/14 16:13:35.097 raft.rs:879: [INFO] [region 2] 3 is starting a new election at term 68
2017/02/14 16:13:35.097 raft.rs:666: [INFO] [region 2] 3 became candidate at term 69
2017/02/14 16:13:35.097 raft.rs:752: [INFO] [region 2] 3 received MsgRequestVoteResponse from 3 at term 69
2017/02/14 16:13:35.098 raft.rs:732: [INFO] [region 2] 3 [logterm: 6, index: 34] sent MsgRequestVote request to 6 at term 69
2017/02/14 16:13:35.098 server.rs:480: [INFO] resolve store 5 address ok, addr 10.2.1.103:20160
2017/02/14 16:13:35.099 server.rs:179: [WARN] remove store connection for store 5 with token Token(1190)
2017/02/14 16:13:49.937 raft.rs:879: [INFO] [region 2] 3 is starting a new election at term 69
2017/02/14 16:13:49.937 raft.rs:666: [INFO] [region 2] 3 became candidate at term 70
2017/02/14 16:13:49.937 raft.rs:752: [INFO] [region 2] 3 received MsgRequestVoteResponse from 3 at term 70
2017/02/14 16:13:49.937 raft.rs:732: [INFO] [region 2] 3 [logterm: 6, index: 34] sent MsgRequestVote request to 6 at term 70
2017/02/14 16:13:49.939 server.rs:480: [INFO] resolve store 5 address ok, addr 10.2.1.103:20160
2017/02/14 16:13:49.939 server.rs:179: [WARN] remove store connection for store 5 with token Token(1191)
 @shenli I have 3 tikv-servier.  10.2.1.101, 10.2.1.102. 10.2.103.  Error is on 101.

103 log:(time is wrong)

2017/02/15 00:25:50.490 tikv-server.rs:667: [INFO] Start listening on 10.2.1.103:20160...
2017/02/15 00:25:50.491 mod.rs:193: [INFO] starting working thread: end-point-worker
2017/02/15 00:25:50.492 mod.rs:193: [INFO] starting working thread: snap-handler
2017/02/15 00:25:50.492 server.rs:153: [INFO] TiKV is ready to serve
2017/02/15 00:35:50.489 compact.rs:84: [INFO] compact range for cf lock finished
2017/02/15 00:45:50.488 compact.rs:84: [INFO] compact range for cf lock finished
2017/02/15 00:55:50.489 compact.rs:84: [INFO] compact range for cf lock finished @siddontang yes @shenli 10.2.1.101 can ping 102,103 success. @shenli @siddontang OK, Let me try. @shenli @siddontang thanks very much. The 103 firewall is running. When I closed it. Tidb is Work.  binlog makes some changes, need to be updated together, so I tag a DNM label  Another dip on my way with TiDB:
```ALTER TABLE authors MODIFY name varchar(100) NULL```
TiDB says:
`[ddl:203]unsupported modify column`

Thus, i can't modify fields?

And another one:

```
ALTER TABLE payments ALTER date_applied DROP DEFAULT;
```
TiDB reports error:
line 1 column 7 near " `date_applied` DROP DEFAULT" (total length 62)

 If it's totally impossible to shrink the lenght of varchar, pls report back 0 altered, instead of rising exception.
Better to log info about unsupported shrinking for varchars. Returning error will broke things in orm, that relies on mysql features, and mysql can shrink varchar fields. So this error will raise some unexpected and unhandled errors in orm.

PS
I hope, CHANGE COLUMN ddl will be also supported:
```
ALTER TABLE `payments`
	CHANGE COLUMN `name` `name` VARCHAR(155) NOT NULL;
``` Project lifetime usually requires updates and improvements, Schema must not be static.
Often, schema changes requires not only checking every row, but in case of indexed column it requires rebuid all column indexes. If you talking about difficulties for iterating rows in db, pls tell me, what db is for? This is base db feature - to iterate rows, filter them and aggregate their data. There must be no problem with this at all. 
A db with static schema is not the one i'm looking for. It's much better to find the way to apply schema changes at petabyte db in a piece of second. The solution is to use information_schema as information about the schema.
Since column altered - schema will contain new lenght and new inserts must meet this property.
We don't need to achieve goal for every row contain data strongly limited to the schema, operating with part of data defined in schema is enought. Later, on resharding, optimizing or other write operations data will be shrinked according to the schema, no need to enforce this at the ALTER level. IMHO.
 If db on_the_fly truncates fileds data according to the schema lenght - no one can select something longer than schema defines.
Thus, with truncating even in strict SQL mode the lenght will always meet.
Bad way to give away untruncated data. Bad way to store untruncated data.
Thus, speed improvement can be achieved with this way. No need to digg all data to truncate them at their place. This can be a very expensive job. This job can be left to the optimize or repair table query. In case of preventing truncation of data - agree. Binary distribution doesn't contain this fix yet? Or this is something different one?
```
ALTER TABLE `payment_type` MODIFY `name` varchar(100) NULL
[ddl:203]unsupported modify column
``` ./tidb-server -V
Git Commit Hash: 96e8ab6128ad4f2a9b936290d975936f18851e0f
UTC Build Time:  2017-02-13 06:10:08
 I suppose this restriction will be for strict sql mode.
For my case the field lenght equals.
SQL restrictions are default:
`STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION`
Removing STRICT_TRANS_TABLES from restrictions had no effect on this. ```
CREATE TABLE `payment_type` (
	`id` INT(11) NOT NULL AUTO_INCREMENT,
	`name` VARCHAR(100) NOT NULL,
	`provider_label` VARCHAR(100) NOT NULL,
	`descr` VARCHAR(100) NOT NULL,
	PRIMARY KEY (`id`)
);
```

Also, 
```
ALTER TABLE `payment_type`	ALTER `name` DROP DEFAULT;
```
Doest't work.


P.S.
somehow `modify` statement got working...
Now, the 
```
ALTER TABLE `payment_type`	CHANGE COLUMN `name` `name` VARCHAR(101) NOT NULL default '' AFTER `id`;
```
Doesn't, but 
```
ALTER TABLE `payment_type`	CHANGE COLUMN `name` `name` VARCHAR(101) NOT NULL default '';
```
Works. Whats wrong with AFTER field clause? Yes, with the 'column' statement DROP DEFAULT works. 
But, according to [this document](https://dev.mysql.com/doc/refman/5.7/en/alter-table.html) the 'column' statement is not mandatory and can be ommited, and orms often omits unnesessary statements.

And the next one point:
```
ALTER TABLE `payment_type` DROP COLUMN `name` CASCADE
```

Returns error `line 0 column 60 near "" (total length 60)` Does it mean that `DROP COLUMN name CASCADE` will not be supported in the near future? Sad. @zimulala  Thank you!
Let me know when `DROP COLUMN name CASCADE` will be supported.
This will let the project to be a little closer to open the door for the django community.
I believe this will be a important milestone for the project. 
I mean elimination of incomatibles with the django orm and migration tools.  LGTM  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
```sql
select now(2)+0
```


2. What did you expect to see?
The result type should be `DECIMAL`.



3. What did you see instead?
The result type is `BIGINT`.


4. What version of Go are you using (`go version`)?
```
go version go1.7.4 linux/amd64
```

Besides, time functions (with an option fsp arg) like CURTIME also suffer from this issue.  Hi, @shenli @hanfei1991 @tiancaiamao !
I just added the UTC_TIMESTAMP function, PTAL :)  See #2584. [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2591) <br/>All committers have signed the CLA. Ok i'll test that. Except this.
```gofmt
 (simplify)
./util/types/time.go
make: *** [check] Error 1
```
All tests passed. (yay!) Sorry about the wait.
Now it's fixed. :)  Hi.
I'm trying to compile TiDB on armhf (armv7) and but build failed.
It seems that in a previous issue #356 the problem was fixed, but it now seems to happen again on these files.

```
# github.com/pingcap/tidb/util/types
../Gopath/src/github.com/pingcap/tidb/util/types/convert.go:205: constant 9223372036854775807 overflows int
../Gopath/src/github.com/pingcap/tidb/util/types/time.go:1759: constant 4294967295 overflows int
../Gopath/src/github.com/pingcap/tidb/util/types/time.go:1766: constant 4294967295 overflows int

```
My go version is 1.7.4. Ok so with this pull request the database successfully builds.
Here's the output of my make test.
[test.log.zip](https://github.com/pingcap/tidb/files/752444/test.log.zip)

Also let me know if size.go is fine. The code comes from http://stackoverflow.com/questions/6878590/the-maximum-value-for-an-int-type-in-go  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
If possible, provide a recipe for reproducing the error.

I am testing out TiDB. As described in the doc, I used 6 machines, 1tidb, 3 pd, and 3 tikv. Things work greatly when adding and querying data. I added ~10M number of records into the system. But when I tried to do horizontal scaling by adding 2 more tikv instances, there is no data moving from other tikv instances. I wait several hours and still no data moved. Then I tried to delete a tikv store using pd-ctrl tool, data starts to move to one of the newly added tikv, but the other newly added tikv still gets no data.

For reference, I also tried to add PD and remove it, and things work well. so does adding tidb.

2. What did you expect to see?
After adding 2 more tikv instances, should the system automatically re-balance the data cross all the tikv instances?

3. What did you see instead?
No data being moved to the new tikv instances.


4. What version of Go are you using (`go version`)?
I downloaded the latest binary directly from github.

 Clarify, I use the way of checking the sst files under tikv#/db folder to decide if there is data re-balanced over. Just wonder the underlying reason to use such a design choice. Why not just try to evenly distribute data cross all available tikv instances instead, like Cassandra. 

I set min-balance-diff-ratio to a very small value (0.000001) using pd-ctl, and the entire disk is 1TB. Yet, I still did not see the data moved to the empty tikv. NOTE that my previous "force" data moving by deleting a tikv is still ongoing. Could this be the cause? The "force" data moving itself is very slow, the db folder size is about 5GB, <1GB actually moved to another machine after several hours. 

More over, let us say capacity is 10G, ratio is 0.1, and 3 tikv instances with data of 4GB each. After adding a new tikv instance, will it evenly re-balance to ~3GB each?

Thanks. The re-balance did eventually reach, but very very slow, taking >58h for my data set.
2017-02-03 14:03:57.528554864 -0800 PST
id regions
1  3026
4  2936
5  2414
17293  94
3907515  94

2017-02-05 12:43:57.506226421 -0800 PST
id regions
1  1340
4  2400
17293  2643
3907515  2695 BTW, the data size on the re-balanced instances are between 1.5GB ~ 2GB, based on the info returned by http://xxx:2379/pd/api/v1/stores  pymysql.err.ProgrammingError: (1146, "Table 'information_schema.table_constraints' doesn't exist")

Will the information_schema updated to contain the necessary tables?

These orm uses several tables from information_schema:

```
 cat mysql.py |grep information_schema
        if case_sensitive: sql = 'SELECT table_name FROM information_schema.tables ' \
        else: sql = 'SELECT table_name FROM information_schema.tables ' \
        if case_sensitive: sql = 'SELECT index_name FROM information_schema.statistics ' \
        else: sql = 'SELECT index_name FROM information_schema.statistics ' \
        if case_sensitive: sql = 'SELECT constraint_name FROM information_schema.table_constraints ' \
        else: sql = 'SELECT constraint_name FROM information_schema.table_constraints ' \

```
Only information_schema.table_constraints missed in tidb.

 According to [this document](https://dev.mysql.com/doc/refman/5.7/en/table-constraints-table.html) it will be perfect to fill this table with appropriate values.
Because ponyorm uses this data to determine tables relation. Thank you!
When you are done with this and ponyorm will take a ride over TiDB, i'll build my next project on TiDB.
My best wishes to you, team! Great! Ponyorm now creates the tables for my models!
Thank you for operativeness!  Hello,

   We're currently looking at TiDB to replace a MySQL cluster, which is orchestrated by etcd. It seems that it would be quite redundant to have both an etcd cluster and a PD cluster running on the hosts. Is there a way fo TiDB to use the existing etcd cluster directly? Thanks.  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2572) <br/>All committers have signed the CLA.  Please answer these questions before submitting your issue. Thanks!

## 1. What did you do?
If possible, provide a recipe for reproducing the error.

1. dumped a database with mydumper and option `-F 128`, one of the dumped file is over
17 megabytes
2. load the dumped files to tidb

## 2. What did you expect to see?

expect load to succeed, as this was not an issue before, did TiDB add some extra guarding
variables recently ?  it seems no documentation explained the needed parameters configuring
the transactions, what is the recommended size of a transaction ?

## 3. What did you see instead?

load failed with error :  `transaction too large`

## 4. What version of Go are you using (`go version`)?

tested on tidb rc1.1

```
Welcome to TiDB.
Version:
Git Commit Hash: 6befa6ddb72e2351b4f52a5a55980c00aa6f2367
UTC Build Time:  2017-01-23 03:53:30
```

 @shenli  yes, it was 

```
docker run -it --rm -v dump:/data tidb:mydumper mydumper -h xxx.xxx.xxx.xxx -P xxxx -u xxxxx -p xxxxx -B xxxxx -t 16 -F 128 -o /data
```

where `tidb:mydumper` is an image built from [yfix/baseimage](https://github.com/yfix/docker-mydumper), could it be a mydumper problem ? i am using loader with option `-q 1` with above tests.
i just tried to dump with option `-F 8` to chop the dump to around 8 megabytes, still failed at `transaction too large` here is the trace

```
/home/jenkins/workspace/BRANCH_MANUAL_BUILD_FLOW/go/src/github.com/pingcap/tidb/kv/memdb_buffer.go:106: [kv:11]transaction too large, len:100001
/home/jenkins/workspace/BRANCH_MANUAL_BUILD_FLOW/go/src/github.com/pingcap/tidb/table/tables/tables.go:344:
/home/jenkins/workspace/BRANCH_MANUAL_BUILD_FLOW/go/src/github.com/pingcap/tidb/executor/executor_write.go:661:
/home/jenkins/workspace/BRANCH_MANUAL_BUILD_FLOW/go/src/github.com/pingcap/tidb/executor/adapter.go:135:
/home/jenkins/workspace/BRANCH_MANUAL_BUILD_FLOW/go/src/github.com/pingcap/tidb/tidb.go:169:
/home/jenkins/workspace/BRANCH_MANUAL_BUILD_FLOW/go/src/github.com/pingcap/tidb/session.go:468:
/home/jenkins/workspace/BRANCH_MANUAL_BUILD_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:659:
2017/01/25 14:29:29 terror.go:279: [warning] Unknown error class: kv code: 11
```

please kindly suggest, meanwhile i will be trying mydumper using `-F 4`. BTW,  the loading is on a 64g RAM machine so should not be a hardware issue.

what could be the `limit` for TiDB transactions ? i see, your guess was right, the table is like below with only integers 

```sql 
  4 CREATE TABLE `goods_viewlog` (
  5   `log_id` mediumint(8) NOT NULL AUTO_INCREMENT,
  6   `member_id` bigint(20) unsigned NOT NULL DEFAULT '0',
  7   `goods_id` bigint(20) unsigned NOT NULL DEFAULT '0',
  8   `number` mediumint(8) unsigned DEFAULT '0',
  9   `createtime` int(10) unsigned DEFAULT NULL,
 10   PRIMARY KEY (`log_id`),
 11   UNIQUE KEY `unique_goods_id` (`member_id`,`goods_id`),
 12   KEY `idx_c_member_id` (`member_id`),
 13   KEY `idx_c_goods_id` (`goods_id`)
 14 ) ENGINE=InnoDB
```

could you kindly provide the commit sha value for your change, as rc1.1 was also only a few days ago, i could  check with commit logs @shenli i confirm that latest master works with files dumped by mydumper using option `-F 2` in my case, and rc1.1 fails them with `transaction too large` error  I've found, that not all flush statements supported at the time.
```
FLUSH PRIVILEGES;
/* Ошибка SQL (1105): line 0 column 16 near "" (total length 16) */
FLUSH HOSTS;
/* Ошибка SQL (1105): line 0 column 11 near "" (total length 11) */
FLUSH TABLES;
FLUSH TABLES WITH READ LOCK;
UNLOCK TABLES;
FLUSH LOGS;
/* Ошибка SQL (1105): line 0 column 10 near "" (total length 10) */
FLUSH STATUS;
/* Ошибка SQL (1105): line 0 column 12 near "" (total length 12) */
```
If TiDB doesn't really need to take an action on these statements - can it simply reply ok on them?

The same thing on
```
ALTER DATABASE `test` COLLATE 'utf8_general_ci';
/* Ошибка SQL (1105): line 0 column 14 near " `test` COLLATE 'utf8_general_ci'" (total length 47) */
``` Do you mean, db collations is not alterable? support for triggers, views and stored procedures also ommited? Got it.
Wishing you to achieve a drop-in replacement level, up to the current mysql features.
  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
```sql
select 1e2;
```


2. What did you expect to see?
The type of the result should be `DOUBLE` according to [the number literals doc](https://dev.mysql.com/doc/refman/5.7/en/number-literals.html).


3. What did you see instead?
The result actually has a type of `DECIMAL`.


4. What version of Go are you using (`go version`)?
```
go version go1.7.4 linux/amd64
```
 Does following patch fix the issue properly? Do I miss something? @shenli @coocood 

```diff
diff --git a/util/types/field_type.go b/util/types/field_type.go
index e0035c9f..64167c36 100644
--- a/util/types/field_type.go
+++ b/util/types/field_type.go
@@ -134,7 +134,7 @@ func DefaultTypeForValue(value interface{}, tp *FieldType) {
                tp.Charset = mysql.DefaultCharset
                tp.Collate = mysql.DefaultCollationName
        case float64:
-               tp.Tp = mysql.TypeNewDecimal
+               tp.Tp = mysql.TypeDouble
                tp.Charset = charset.CharsetBin
                tp.Collate = charset.CharsetBin
        case []byte:
diff --git a/util/types/field_type_test.go b/util/types/field_type_test.go
index d5b99a9a..4b68e962 100644
--- a/util/types/field_type_test.go
+++ b/util/types/field_type_test.go
@@ -118,7 +118,7 @@ func (s *testFieldTypeSuite) TestDefaultTypeForValue(c *C) {
                {1, mysql.TypeLonglong},
                {uint64(1), mysql.TypeLonglong},
                {"abc", mysql.TypeVarString},
-               {1.1, mysql.TypeNewDecimal},
+               {1.1, mysql.TypeDouble},
                {[]byte("abc"), mysql.TypeBlob},
                {Bit{}, mysql.TypeBit},
                {Hex{}, mysql.TypeVarchar},
``` Hi, @coocood 
I think it's already be covered by [this](https://github.com/pingcap/tidb/pull/2461/commits/b2fe03faa3e13c5bf6173dba9f8b5018c5b95e4e#diff-6425b785337ec89d2604eb16f63caac6R53). However, #2461 failed with `An error occurred while generating the build script`. Have I done something wrong? solved by #2461   Nice! I think we could record top N slow query SQLs in a period.   @hanfei1991 DONE.   Do we cache address for per region? @disksing A better idea is to cache address for store. There are just a few stores in a whole cluster.  Related: https://github.com/pingcap/tidb/pull/2369

1. What did you do?
```
tidb> select unix_timestamp(now());
ERROR 2013 (HY000): Lost connection to MySQL server during query
```


2. What did you expect to see?

The time now.

3. What did you see instead?

```
ERROR 2013 (HY000): Lost connection to MySQL server during query
```

4. What version of Go are you using (`go version`)?
```
go version go1.7.3 darwin/amd64
```

I've pulled `master` latest from today (2017-01-17) and attempted to run a few queries, which failed. I narrowed the error down to running `unix_timestamp(some_argument)` with any argument. `now()` being just a trivial example.
  - [x] sqrt function is implemented in this PR
- [x] test case is also added in this PR. 
- [x]  passed all test cases. 
A function wanted by #2420. Just rebase current br onto master. All master changes are in this br, shall be ready to merge.   - [x] floor function is implemented in this PR
- [x] test case is also added in this PR. 
- [x]  passed all test cases. 
A function wanted by #2420. [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2484) <br/>All committers have signed the CLA. @XuHuaiyu  Passed all test cases. Ready to merge into mater. Already rebased and applied all my commit on top of lasted master branch.  @shenli PTAL, is this ok?  @XuHuaiyu PTAL, is this ok to you?  @hanfei1991 fixed.  @hanfei1991 passed the CI and rewrite the test cases. Shall be all good now.  @hanfei1991 @XuHuaiyu  @shenli  PTAL  1. What did you do?
If possible, provide a recipe for reproducing the error.

`$ go get -u github.com/pingcap/tidb`

2. What did you expect to see?
```
$ go get -u github.com/pingcap/tidb
$
```


3. What did you see instead?
```
$ go get -u github.com/pingcap/tidb
# github.com/pingcap/tidb/parser
Q:\Soft\Go\GOPATH\src\github.com\pingcap\tidb\parser\lexer.go:95: undefined: yySymType
Q:\Soft\Go\GOPATH\src\github.com\pingcap\tidb\parser\misc.go:516: undefined: yySymType
Q:\Soft\Go\GOPATH\src\github.com\pingcap\tidb\parser\yy_parser.go:60: undefined: yySymType
Q:\Soft\Go\GOPATH\src\github.com\pingcap\tidb\parser\yy_parser.go:61: undefined: yySymType
Q:\Soft\Go\GOPATH\src\github.com\pingcap\tidb\parser\yy_parser.go:62: undefined: yySymType
# github.com/pingcap/tipb/go-binlog
Q:\Soft\Go\GOPATH\src\github.com\pingcap\tipb\go-binlog\cistern.pb.go:126: undefined: grpc.SupportPackageIsVersion3
Q:\Soft\Go\GOPATH\src\github.com\pingcap\tipb\go-binlog\pump.pb.go:155: undefined: grpc.SupportPackageIsVersion3
```


4. What version of Go are you using (`go version`)?
```
$ go version
go version go1.7.3 windows/amd64
```
 I see, my mistake. Thanks for fast reply.   it's done  These builtins normally have a type of `func(float64) float64`. @hanfei1991 Got it. Do you have a plan to make use of tools like 'go generate' for these boilerplate code?  I'm not very sure if I shall update the following codes also.

```
util/types/convert.go
303:            return strconv.FormatFloat(float64(v), 'f', -1, 32), nil
305:            return strconv.FormatFloat(float64(v), 'f', -1, 64), nil

util/types/mydecimal.go
951:    s := strconv.FormatFloat(f, 'g', -1, 64)

util/types/datum.go
747:            s = strconv.FormatFloat(d.GetFloat64(), 'f', -1, 32)
749:            s = strconv.FormatFloat(d.GetFloat64(), 'f', -1, 64)
1306:           return strconv.FormatFloat(float64(d.GetFloat32()), 'f', -1, 32), nil
1308:           return strconv.FormatFloat(float64(d.GetFloat64()), 'f', -1, 64), nil
```  I want to grant privileges to dynamic database name with prefix

```
GRANT ALL PRIVILEGES ON `dddb_%`.* TO 'dduser'@'%' IDENTIFIED by '123456';
```
It's error. but mysql is ok.

```
ERROR 1105 (HY000): Unknown schema name: dddb_%!(NOVERB)
```  PTAL @andelf @shenli 

cc pingcap/pd#472
cc pingcap/tikv#1499  @shenli regarding #2430 test table & datas, here still had problem on the `limit` condition. pls try the case on the latest(Git Commit Hash: d0813e181fa0f9ca672e02a36c264f369f15d7e3 UTC Build Time:  2017-01-14 08:22:51):

```sql
select * from test order by b asc limit 2,1;
```

mysql result:

```
mysql> select * from test order by b asc limit 2,1;
+---+------+
| a | b    |
+---+------+
| p |    3 |
+---+------+
1 row in set (0.03 sec)
```

tidb result:

```
mysql> select * from test order by b asc limit 2,1;
+---+------+
| a | b    |
+---+------+
| z |    3 |
+---+------+
1 row in set (0.03 sec)
```
  Implemented FROM_DAYS builtin function.  Fixed, please review. Thanks much. Fixed, please review.  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
If possible, provide a recipe for reproducing the error.

```sql
CREATE TABLE `test` (
`a` varchar(20) NOT NULL,
`b` int(11) DEFAULT NULL,
PRIMARY KEY (`a`)
) ENGINE=InnoDB;
insert into `test` values('x',1),('y',2),('z',3),('p', 3);

```

2. What did you expect to see?

 `select * from test where 1 limit 1,1;`

```
+---+------+
| a | b    |
+---+------+
| y |    2 |
+---+------+
1 rows in set (0.04 sec)
```

3. What did you see instead?

```
+---+------+
| a | b    |
+---+------+
| x |   1  |
| y |    2 |
+---+------+
2 rows in set (0.04 sec)
```

4. What version of Go are you using (`go version`)?

golang 1.6  A function wanted by #2420. Hi, @tiancaiamao , PTAL, is [this](https://github.com/pingcap/tidb/pull/2427/commits/403754927ee71436d5d4abe7dbea767767b42bdc) ok? Thanks @hanfei1991 ! I saw the second travis check was hanging a few days ago. However, I'm a little busy recently :(
I meant to merge the master to trigger the CI tonight but found that you've already done that.  Does tidb support mysql procedure? any roadmap?  I think it's because we always use `-1` as the prec arg of `strconv.AppendFloat` [here](https://github.com/pingcap/tidb/blob/master/server/util.go#L330).

To fix it, we need to know the real prec first. However, it seems that the float datum hasn't provide such information yet. Is it ok to reuse an another field defined in `Datum` to store such info?

BTW, the mysql-workbench shows that the result of `select round(1e3, 2);` has 'Display Size' of 19 and 'Precision' of 5. Do these values matter a lot? Sure @zimulala , I would like to try :)  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
If possible, provide a recipe for reproducing the error.

  ```sql
CREATE TABLE `test` (
  `a` varchar(20) NOT NULL,
  `b` int(11) DEFAULT NULL,
  PRIMARY KEY (`a`)
) ENGINE=InnoDB;
```

2. What did you expect to see?

   - 2.1 execute `explain select * from test where a in ('x', 'y', 'z')` use indexScan;
   - 2.2 execute `explain select * from test where a in ( select 'x' from dual)` should use indexScan as well.

3. What did you see instead?

   - 2.2 uses tableScan instead

4. What version of Go are you using (`go version`)?

golang 1.6
 @hanfei1991 The column `a` was the primary key  in the `test` table, so i think the usage should be fine.  i'm just waiting for usage indexScan of the `select * from test where a in ( select 'x' from dual)` implementation. 
 @hanfei1991 another example

## create table like these 
```sql
CREATE TABLE `test` (
  `a` varchar(20) NOT NULL,
  `b` int(11) DEFAULT NULL,
  PRIMARY KEY (`a`)
) ENGINE=InnoDB;

CREATE TABLE `demo` (
  `x` varchar(20) NOT NULL,
  `y` int(11) NOT NULL,
 PRIMARY KEY (`y`)
) ENGINE=InnoDB;

```

## queries

```sql
explain 
select demo.*
from demo 
inner join test
on demo.y = test.b
where test.a = 'abc'
```

which equals to 

```sql
explain
select demo.*
from demo
where demo.y IN (
select b from test
where test.a = 'abc'
)
```

the question is that there is an index on `demo.y`  (primary key) but the index is not used in either query above, and table scan is applied, it's becoming quite slow if table `demo` has thousands of rows, any suggestions ? in the original example one could use

```sql
explain 
select * from test 
where a in ( 
select 'x' from dual
union 
select 'y' from dual
) 
```

and the result is no different: the index on `test.a` is not used @hanfei1991 , ok i see, thanks for your feedback  Hi, @hanfei1991 , is this what you mentioned in #2368? a builtin function factory for date arithmetic. Hi, @shenli , I've resolved the conflicts, PTAL.  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2377) <br/>All committers have signed the CLA.  Implemented DATEDIFF function wanted by https://github.com/pingcap/tidb/issues/236.
Added builtinDateDiff function. Also added some tests. I also added method TotalDays to types.time, I think that could be useful in future. [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2374) <br/>All committers have signed the CLA. Everything seems to be fixed. Guys please review. Thanks guys for your replies. Done.  Hi, @shenli @coocood 

I implemented `FIND_IN_SET` function wanted by #2244. However, I'm still unable to optimize the function according to the official doc:

> If the first argument is a constant string and the second is a column of type SET, the FIND_IN_SET() function is optimized to use bit arithmetic.

```go
type Set struct {
	Name  string
	Value uint64
}
```
I see a set can be represented as a uint64, but how could I map _a constant string_ to its binary value? Would you please give me some advices? @shenli I know we can check if the given string is a member of a set by doing things like "binary_value(str) & strlst.value != 0". However, I wonder if there is any cheap way to build the 'binary_value' function. @shenli I see this optimization occurs while writing result set. So I need either eval  'binary_value(str)' before 'FIND_IN_SET' and use its result as the first arg or eval 'binary_value(str)' on the first call of 'FIND_IN_SET' and save the result somewhere so that we can reuse it. I haven't looked deep enough. Am I right? or which is the right way? @shenli Got it!  This is the last builtin function wanted by #112 :) I see It's already been in the
`ReservedKeyWord`@https://github.com/pingcap/tidb/blob/master/parser/parser.y#L2079
and
`reservedKws`@https://github.com/pingcap/tidb/blob/master/parser/parser_test.go#L51

Is there any thing else I should do? @shenli   `DateArithInterval` will prevent its inner interval expression from being evaluated, which leads to incorrect results for function calls like `adddate('2011-11-11', least(1,2))`.

Here is the original logic:
```go
func builtinDateArith(args []types.Datum, ctx context.Context) (d types.Datum, err error) {
	// Op is used for distinguishing date_add and date_sub.
	// args[0] -> Op
	// args[1] -> Date
	// args[2] -> DateArithInterval
	// health check for date and interval
	if args[1].IsNull() {
		return d, nil
	}
	nodeDate := args[1]
	nodeInterval := args[2].GetInterface().(ast.DateArithInterval)
	nodeIntervalIntervalDatum := nodeInterval.Interval.GetDatum()
	if nodeIntervalIntervalDatum.IsNull() {
		return d, nil
	}
...
```

`nodeInterval.Interval` may be a `FuncCallExpr` that not be evaluated by `FoldConstant` (because `DateArithInterval` is not a `ScalarFunction`).

Thus, `nodeIntervalIntervalDatum.IsNull()` returns `true` for aforementioned function call.

This PR can solve the issue by disabling the `DateArithInterval`. Is there any better solution? @shenli Not at all. Happy new year :)  Hi, @shenli , here is the LEAST function wanted by #112 , PTAL :) Thanks @ngaut ! this is the simplest function to implement since there is already a GREATEST function implementation.

I'm working on INTERVAL(), however, there is still a problem. eg:
```
SELECT DATE_ADD('2016-12-31',INTERVAL INTERVAL(1,1) DAY)
```
will return ```NULL``` instead of  ```2017-01-01``` :(

I'll try to solve this as soon as possible. @shenli :smile:   I have a host(4core,2GB memory,100GB disk) to run tidb,method like this:

https://github.com/pingcap/docs-cn/blob/master/op-guide/binary-deployment.md#%E5%8D%95%E8%8A%82%E7%82%B9%E6%96%B9%E5%BC%8F%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2

my test like this:

sysbench --test=oltp --db-driver=mysql --mysql-table-engine=innodb --oltp-table-size=1000000  --num-threads=4  --mysql-host=192.168.2.183 --mysql-user='root' --mysql-password='' --mysql-port=4000 --mysql-db='test' prepare

this statement is OK.but when I do this:

sysbench --test=oltp --db-driver=mysql --mysql-table-engine=innodb --oltp-table-size=1000000  --num-threads=4  --mysql-host=192.168.2.183 --mysql-user='root' --mysql-password='' --mysql-port=4000 --mysql-db='test' run

it throwed some error like this:

sysbench 0.4.12:  multi-threaded system evaluation benchmark

Running the test with following options:
Number of threads: 4

Doing OLTP test.
Running mixed OLTP test
Using Special distribution (12 iterations,  1 pct of values are returned in 75 pct cases)
Using "BEGIN" for starting transactions
Using auto_inc on the id column
Maximum number of requests for OLTP test is limited to 10000
Threads started!
ALERT: failed to execute mysql_stmt_execute(): Err1105 Malform packet error
FATAL: database error, exiting...
ALERT: failed to execute mysql_stmt_execute(): Err1105 Malform packet error
FATAL: database error, exiting...
ALERT: failed to execute mysql_stmt_execute(): Err1105 Malform packet error
FATAL: database error, exiting...
ALERT: failed to execute mysql_stmt_execute(): Err1105 Malform packet error
FATAL: database error, exiting...
Done.

how to slove this problem?  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2339) <br/>All committers have signed the CLA.  [![CLA assistant check](https://cla-assistant.io/pull/badge/not_signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2338) <br/>Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our [Contributor License Agreement](https://cla-assistant.io/pingcap/tidb?pullRequest=2338) before we can accept your contribution.<br/>  Hi, I'm working on implementing INTERVAL function and have trouble in resolving some shift/reduce conflicts. Also, I found the following behavior. Could you please give me some advice?

1. What did you do?
```
tidb> SELECT DATE_ADD('2008-01-02', INTERVAL(1, 1) DAY);
```


2. What did you expect to see?
```
ERROR 1241 (21000): Operand should contain 1 column(s)
```



3. What did you see instead?
```
+--------------------------------------------+
| DATE_ADD('2008-01-02', INTERVAL(1, 1) DAY) |
+--------------------------------------------+
| NULL                                       |
+--------------------------------------------+
1 row in set (0.00 sec)
```



4. What version of Go are you using (`go version`)?
```
go version go1.7.4 linux/amd64
```

 @shenli Sure, there were some 'shift/reduce' conflicts when I first tried to add the support for INTERVAL function. I could resolve these conflicts by the following modification
``` diff
diff --git a/parser/parser.y b/parser/parser.y
index 5f7e03e3..016cd49a 100644
--- a/parser/parser.y
+++ b/parser/parser.y
@@ -720,6 +720,9 @@ import (
 %precedence lowerThanSQLCache
 %precedence sqlCache sqlNoCache
 
+%precedence lowerThanIntervalKeyword
+%precedence interval
+
 %precedence lowerThanSetKeyword
 %precedence set
 
@@ -2445,6 +2448,7 @@ FunctionNameConflict:
 |	"UTC_DATE"
 |	"CURRENT_DATE"
 |	"VERSION"
+|	"INTERVAL" %prec lowerThanIntervalKeyword
 
 FunctionCallConflict:
 	FunctionNameConflict '(' ExpressionListOpt ')'
diff --git a/parser/parser_test.go b/parser/parser_test.go
index fc32b3b0..5ca5fbf4 100644
--- a/parser/parser_test.go
+++ b/parser/parser_test.go
@@ -526,6 +526,9 @@ func (s *testParserSuite) TestBuiltin(c *C) {
 
 		{"SELECT LEAST(1, 2, 3);", true},
 
+		{"SELECT INTERVAL(1, 0, 1, 2)", true},
+		{"SELECT DATE_ADD('2008-01-02', INTERVAL INTERVAL(1, 0, 1) DAY);", true},
+
 		// Information Functions
 		{"SELECT DATABASE();", true},
 		{"SELECT SCHEMA();", true},
```

It can pass the test case, however, I'm still not very sure I did the right thing. I will test it further :)  Hi, I have a question on args validation for builtin functions. It seems that the behavior of tidb (errno) is inconsistent with the mysql, although the error message is clear enough. Does it matter in some cases?

1. What did you do?
```
tidb> SELECT GREATEST(1);
```


2. What did you expect to see?
```
ERROR 1105 (HY000): number of function arguments must in [2, -1].
```



3. What did you see instead?
```
ERROR 1582 (42000): Incorrect parameter count in the call to native function 'GREATEST'
```



4. What version of Go are you using (`go version`)?
```
go version go1.7.4 linux/amd64
```
 Thanks @shenli ! Is it a urgent issue? I may be able to fix #2335. Sorry, It's been fixed by #2335, forget my previous comment.  I have two IDCs in shanghai and hangzhou.Now I deploy mysql cluster in these two IDCs and use otter(a middleware consume mysql binlog to sync data between different IDCs) to keep data consistent.


  I also meet the problem

mysql> delete from t_table where 0=0;
ERROR 1105 (HY000): transaction is too large @coocood thks, I got  `char_length` and its synonym `character_length`  Hi @tiancaiamao ,

It looks like that tidb handles the 20021020 as an integer (unix time?)

`$26 = {github.com/pingcap/tidb/ast.exprNode = {github.com/pingcap/tidb/ast.node = {text = 0x0 ""}, github.com/pingcap/tidb/util/types.Datum = {k = 1 '\001', 
      collation = 0 '\000', decimal = 0, length = 0, i = **20021020**, b = {array = 0x0, len = 0, cap = 0}, x = {_type = 0x0, data = 0x0}}, Type = {Tp = 8 '\b', Flag = 0, 
      Flen = -1, Decimal = -1, Charset = 0xef090e "binary", Collate = 0xef090e "binary", Elems = {array = 0x0, len = 0, cap = 0}}, flag = 0}}`

Using str_to_date returns always correct results at my local.

The TiDB's team must know the answer.

Regards,
Yu  Add two functions, bit_length and char. 
For the char function, I missed a test case for very large integer. But I think it is a problem with this line. https://github.com/pingcap/tidb/blob/master/parser/yy_parser.go#L142 I guess it should be fixed in another PR. weird, `make dev` passed on my laptop...  Hi TiDB's Team,

I ofen see code that is similar to the following block. I cannot figure out why you use blank identifier here.

Regards
Yu

`var (
	_ DDLNode = &AlterTableStmt{}
	_ DDLNode = &CreateDatabaseStmt{}
	_ DDLNode = &CreateIndexStmt{}
	_ DDLNode = &CreateTableStmt{}
	_ DDLNode = &DropDatabaseStmt{}
	_ DDLNode = &DropIndexStmt{}
	_ DDLNode = &DropTableStmt{}
	_ DDLNode = &TruncateTableStmt{}

	_ Node = &AlterTableSpec{}
	_ Node = &ColumnDef{}
	_ Node = &ColumnOption{}
	_ Node = &ColumnPosition{}
	_ Node = &Constraint{}
	_ Node = &IndexColName{}
	_ Node = &ReferenceDef{}
)` Hi @ngaut ,

ok, i get it now, since in golang there aren't keywords like implements/extends of java to make the extenstion/implementation explicitly.

this is really a brilliant way for verification and make code more readable.

Best Regards,
Yu

  HI @coocood,

first time i create a PR here. I'm not sure if I do it right.

Regards,
Yu [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2306) <br/>All committers have signed the CLA. @coocood 

my pleasure!

Regards,
Yu  Hi TiDB's Team,

I am reading the source code from ast package and have found some comments that are not very clear. I think that one should write implements `ExprNode` interface instead of `Expression` interface.

Regards,
Yu

`// expressionNode is the struct implements Expression interface.
// Expression implementations should embed it in.
type exprNode struct {
	node
	types.Datum
	Type types.FieldType
	flag uint64
}

// SetDatum implements Expression interface.
func (en *exprNode) SetDatum(datum types.Datum) {
	en.Datum = datum
}

// GetDatum implements Expression interface.
func (en *exprNode) GetDatum() *types.Datum {
	return &en.Datum
}

// SetType implements Expression interface.
func (en *exprNode) SetType(tp *types.FieldType) {
	en.Type = *tp
}

// GetType implements Expression interface.
func (en *exprNode) GetType() *types.FieldType {
	return &en.Type
}

// SetFlag implements Expression interface.
func (en *exprNode) SetFlag(flag uint64) {
	en.flag = flag
}

// GetFlag implements Expression interface.
func (en *exprNode) GetFlag() uint64 {
	return en.flag
}` @coocood ,

ok, i give me try.

Regards,
Yu  1. What did you do?
```
MySQL [INFORMATION_SCHEMA]> show tables;
+------------------------------+
| Tables_in_INFORMATION_SCHEMA |
+------------------------------+
| CHARACTER_SETS               |
| COLLATIONS                   |
| COLUMNS                      |
| FILES                        |
| KEY_COLUMN_USAGE             |
| PARTITIONS                   |
| PLUGINS                      |
| PROFILING                    |
| REFERENTIAL_CONSTRAINTS      |
| SCHEMATA                     |
| SESSION_VARIABLES            |
| STATISTICS                   |
| TABLES                       |
+------------------------------+
13 rows in set (0.00 sec)

MySQL [INFORMATION_SCHEMA]> show index from files;
Empty set (0.00 sec)

MySQL [INFORMATION_SCHEMA]> show index from files from information_schema;
ERROR 1105 (HY000): line 0 column 26 near " information_schema"
```

2. What did you expect to see?
result of ```show index from table from database``` should be same as ```show index from table```
  In some cases, coprocessor will convert string to integer, which will always report Error when truncation happens. Not entirely, still need to merge pingcap/tikv#1437.  Hi TiDB's Team

I tried to solve the following problem by myself, but without success. I suppose that the reason starts very deeply from the build of plan or executors, since the e.columns is empty:

		columns := make([]*table.Column, len(e.schema))
		for i, v := range e.columns {
			columns[i] = table.ToColumn(v)
		}

Perhaps the problem comes back to the different handling between normal tables and info tables.

Regards,
Yu

2016/12/21 11:53:51 conn.go:330: [error] lastCmd select count(*) from information_schema.columns, runtime error: invalid memory address or nil pointer dereference, goroutine 98 [running]:
github.com/pingcap/tidb/server.(*clientConn).Run.func1(0xc8200be000)
	/home/ray/devel/go/src/github.com/pingcap/tidb/server/conn.go:329 +0xc1
panic(0x104e040, 0xc82000e130)
	/usr/local/go/src/runtime/panic.go:426 +0x4e9
github.com/pingcap/tidb/infoschema.(*infoschemaTable).getRows(0xc8202f3bc0, 0x7fdceefbd1c8, 0xc820456d70, 0xc820595840, 0x2, 0x2, 0xc820466000, 0x20c, 0x400, 0x0, ...)
	/home/ray/devel/go/src/github.com/pingcap/tidb/infoschema/tables.go:643 +0x454
github.com/pingcap/tidb/infoschema.(*infoschemaTable).IterRecords(0xc8202f3bc0, 0x7fdceefbd1c8, 0xc820456d70, 0x0, 0x0, 0x0, 0xc820595840, 0x2, 0x2, 0xc820595850, ...)
	/home/ray/devel/go/src/github.com/pingcap/tidb/infoschema/tables.go:655 +0xed
github.com/pingcap/tidb/executor.(*TableScanExec).nextForInfoSchema(0xc8204b5200, 0xc81ffd0e99, 0x0, 0x0)
	/home/ray/devel/go/src/github.com/pingcap/tidb/executor/executor.go:1396 +0x1e6
github.com/pingcap/tidb/executor.(*TableScanExec).Next(0xc8204b5200, 0xc820032c00, 0x0, 0x0)
	/home/ray/devel/go/src/github.com/pingcap/tidb/executor/executor.go:1349 +0x4e
github.com/pingcap/tidb/executor.(*HashAggExec).innerNext(0xc8200a63c0, 0x0, 0x0, 0x0)
	/home/ray/devel/go/src/github.com/pingcap/tidb/executor/executor.go:1058 +0x6e
github.com/pingcap/tidb/executor.(*HashAggExec).Next(0xc8200a63c0, 0xc8205957e0, 0x0, 0x0)
	/home/ray/devel/go/src/github.com/pingcap/tidb/executor/executor.go:998 +0xa5
github.com/pingcap/tidb/executor.(*recordSet).Next(0xc8205f8680, 0xc82049f7c0, 0x0, 0x0)
	/home/ray/devel/go/src/github.com/pingcap/tidb/executor/adapter.go:52 +0x4e
github.com/pingcap/tidb/server.(*tidbResultSet).Next(0xc820595830, 0x0, 0x0, 0x0, 0x0, 0x0)
	/home/ray/devel/go/src/github.com/pingcap/tidb/server/driver_tidb.go:267 +0x5e
github.com/pingcap/tidb/server.(*clientConn).writeResultset(0xc8200be000, 0x7fdceefc2810, 0xc820595830, 0xc820590000, 0x0, 0x0)
	/home/ray/devel/go/src/github.com/pingcap/tidb/server/conn.go:655 +0xae
github.com/pingcap/tidb/server.(*clientConn).handleQuery(0xc8200be000, 0xc8205e2751, 0x2f, 0x0, 0x0)
	/home/ray/devel/go/src/github.com/pingcap/tidb/server/conn.go:600 +0x205
github.com/pingcap/tidb/server.(*clientConn).dispatch(0xc8200be000, 0xc8205e2751, 0x2f, 0x2f, 0x0, 0x0)
	/home/ray/devel/go/src/github.com/pingcap/tidb/server/conn.go:390 +0x7ff
github.com/pingcap/tidb/server.(*clientConn).Run(0xc8200be000)
	/home/ray/devel/go/src/github.com/pingcap/tidb/server/conn.go:345 +0x274
github.com/pingcap/tidb/server.(*Server).onConn(0xc8202f3e00, 0x7fdceeeee0c8, 0xc8203e9308)
	/home/ray/devel/go/src/github.com/pingcap/tidb/server/server.go:209 +0x294
created by github.com/pingcap/tidb/server.(*Server).Run
	/home/ray/devel/go/src/github.com/pingcap/tidb/server/server.go:173 +0x311

  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
a.Build the TIDB on five machine ,according to the  document 'https://github.com/pingcap/docs-cn/blob/master/op-guide/binary-deployment.md'  .
b.Start  pd,tikv,tidb succeed!
c.Use mysql client connect to tidb for test :  
    create  database  'tidbtest'  used 2 second  
   create table   zx   and insert  two records .
   finally    alter table zx add  b int not null default '' ;  
  
2. What did you expect to see?
ERROR 1067 (42000): Invalid default value for 'b'
 
  
3. What did you see instead?
the server is not response 
the log is showed 
2016/12/21 17:14:04 domain.go:71: [info] [ddl] diff load InfoSchema from version 1749 to 1750, in 3.100626ms
2016/12/21 17:14:06 ddl_worker.go:329: [info] [ddl] run DDL job ID:29, Type:add column, State:running, SchemaState:write reorganization, SchemaID:19, TableID:27, RowCount:0, ArgLen:0, Query:
alter table zx add b int not null default ''
2016/12/21 17:14:06 reorg.go:64: [info] [ddl] run reorg job done 
2016/12/21 17:14:06 ddl_worker.go:374: [error] [ddl] run ddl job err [types:1265]Data Truncated
/home/jenkins/workspace/BUILD_TIDB_WORKFLOW/go/src/github.com/pingcap/tidb/util/types/convert.go:286: 
/home/jenkins/workspace/BUILD_TIDB_WORKFLOW/go/src/github.com/pingcap/tidb/util/types/convert.go:166: 
/home/jenkins/workspace/BUILD_TIDB_WORKFLOW/go/src/github.com/pingcap/tidb/util/types/convert.go:145: 
/home/jenkins/workspace/BUILD_TIDB_WORKFLOW/go/src/github.com/pingcap/tidb/util/types/datum.go:1205: 
/home/jenkins/workspace/BUILD_TIDB_WORKFLOW/go/src/github.com/pingcap/tidb/util/types/datum.go:796: 
/home/jenkins/workspace/BUILD_TIDB_WORKFLOW/go/src/github.com/pingcap/tidb/table/column.go:119: 
/home/jenkins/workspace/BUILD_TIDB_WORKFLOW/go/src/github.com/pingcap/tidb/table/column.go:278: 
/home/jenkins/workspace/BUILD_TIDB_WORKFLOW/go/src/github.com/pingcap/tidb/ddl/column.go:308: 
/home/jenkins/workspace/BUILD_TIDB_WORKFLOW/go/src/github.com/pingcap/tidb/ddl/reorg.go:66: 
/home/jenkins/workspace/BUILD_TIDB_WORKFLOW/go/src/github.com/pingcap/tidb/ddl/column.go:178: 
2016/12/21 17:14:06 domain.go:71: [info] [ddl] diff load InfoSchema from version 1750 to 1751, in 2.393608ms



4. What version of Go are you using (`go version`)?
go version go1.7.1 linux/amd64


 @shenli thanks  , but the server  show the message frequently .
[error] [ddl] run ddl job err [types:1265]Data Truncated ....
[warning] [ddl] DDL job 30 is not in history, maybe not run @zimulala  now insert to  table zx  return the message  'ERROR 1265 (01000): Data Truncated' 
and  all the  ddl  is  not response  after  restart  all the service  the error log  still  exists.
as for  the bug fix , it is difficult for me . 
the server  conld not  catch the error   'default value Invalid'. so  can not set the  job to 'JobCancelled'  and the bug occurred ?   mysql> create  table zz (a int not null ,b int not null)
    -> ;
Query OK, 0 rows affected (2.02 sec)
mysql> alter table zz add  c int not null default '';  
ERROR 1265 (01000): Data Truncated
mysql> show create table  zz ;
+-------+------------------------------------------------------------------------------------+
| Table | Create Table                                                                       |
+-------+------------------------------------------------------------------------------------+
| zz    | CREATE TABLE `zz` (
  `a` int(11) NOT NULL,
  `b` int(11) NOT NULL
) ENGINE=InnoDB |
+-------+------------------------------------------------------------------------------------+
1 row in set (0.00 sec)

mysql> insert into zz (a,b) values (1,2)
    -> ;
ERROR 1265 (01000): Data Truncated

then  the server is response the  error   ,but the  table zz   could not use  for write .    Hello TiDB's team,

I am going to run a single test function under the executor package in the following way:

go test -v -run TestAggregation

Though there was no errors, it seems that the test doesn't get executed in this way.

Regards,
Yu

 @shenli thx! it works with gocheck.  Hello TiDB's team,

I am learning the source code and debuging some executors. I have seen that sqls on information_schema is differently handled in compare to those sqls on test schema. Could you please explain me the reason and your desgin behind it?

Regards,
Yu Hi @shenli ,

thx for your answer! Are there more documents about the Inside of TiDB? 

Regards,
Yu @shenli 

That's great!

Regards,
Yu  An existing LDFLAGS will cause build failure. In my case, I set LDFLAGS=-L/lib/path long time age. So `make server` reports error with flag package. 
Do you think it should be `LDFLAGS = ` instead of `+=` at https://github.com/pingcap/tidb/blob/master/Makefile#L22 ?  Tried to support the function rpad. It goes alright with `make gotest` and `make server`. The rpad query works with my build on mac. [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2270) <br/>All committers have signed the CLA. weird, I have signed the CLA. Should I close this one and redo a PR? @shenli @tiancaiamao @coocood Thanks for the advises. I will fix these.    i moved my data from mysql to tidb(docker:lastest single node)

i loss all the autoincrement info

i try to use "alter table data auto_increment = 50000" to slove it
well this qry run sucess

but not affect



 i just follow the  tutorial
using mydumper  CREATE TABLE `world` (
  `worldid` int(11) NOT NULL AUTO_INCREMENT,
  `seed` varchar(50) NOT NULL DEFAULT '',
  `name` varchar(45) DEFAULT '',
  `roleid` int(11) NOT NULL,
  PRIMARY KEY (`worldid`),
  UNIQUE KEY `worldid` (`worldid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8_bin AUTO_INCREMENT=112
this is the createtable from tidb
CREATE TABLE `world` (
  `worldid` int(11) NOT NULL AUTO_INCREMENT,
  `seed` varchar(50) CHARACTER SET utf8 NOT NULL DEFAULT '',
  `name` varchar(45) CHARACTER SET utf8 DEFAULT '',
  `roleid` int(11) NOT NULL,
  PRIMARY KEY (`worldid`),
  UNIQUE KEY `worldid` (`worldid`)
) ENGINE=InnoDB AUTO_INCREMENT=112 DEFAULT CHARSET=utf8 COLLATE=utf8_bin
this is the create table from mysql ![default](https://cloud.githubusercontent.com/assets/2900755/21337600/baa8f558-c6a9-11e6-90ff-171abef2f8da.png)
i just create  a new schema and a new database to test it
i only use one node form docker for development
 i‘m sorry for my poor english，what does the PR mean？  basic support for mysql builtin functions ln(), log(), log2() and log10()

<!-- Reviewable:start -->
---
This change is [<img src="https://reviewable.io/review_button.svg" height="34" align="absmiddle" alt="Reviewable"/>](https://reviewable.io/reviews/pingcap/tidb/2258)
<!-- Reviewable:end -->
 [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2258) <br/>All committers have signed the CLA. PTAL @tiancaiamao @coocood   In order to monitor process uptime in prometheus, I need something like:

```
uptime{instance="172.233.1.196:3306",job="tidb"}
```

in metrics.
counts from 0 in seconds. EDIT: use ``uptime`` instead of ``up``.  使用navicat 连接tidb的时候看不到DB，navicat 11.017-premium，tidb最新版本

是不是因为在tidb中
 INFORMATION_SCHEMA |
| PERFORMANCE_SCHEMA

这2个数据库是大写的缘故
 @bhzhu203  Thanks a lot for your interest in TiDB.  You can send an email to info@pingcap.com. We can assist you in person in case you encounter other problem.  tidb支持  find_in_set 这个mysql函数吗 ，还有多少个函数还没有支持的？
select id,count(id) as cnt from (select a.id,b.sale_adviser from ebk_refunds a inner join ebk_acoin_orders b on find_in_set(b.id,a.buy_ids) where a.post_time between 1477929600 and 1480521599 and a.money>0 group by a.id,b.sale_adviser) tbl group by id having cnt>1;

ERROR 1105 (HY000): line 0 column 124 near "b.id,a.buy_ids) where a.post_time between 1477929600 and 1480521599 and a.money>0 group by a.id,b.sale_adviser) tbl group by id having cnt>1"


最新版本的tidb，
 @bhzhu203 please notice that `find_in_set` can be mostly handled directly using approach like [this](https://www.periscopedata.com/blog/splitting-comma-separated-values-in-mysql.html)  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
If possible, provide a recipe for reproducing the error.


2. What did you expect to see?



3. What did you see instead?



4. What version of Go are you using (`go version`)?

 if you hava read it  please send email   xmaszh@gmail.com have you confirmed?  it would be useful to have support for a more well-known  kv database , for example, Redis DB 
I am already in the process of implementing this but wanted to create a feature request to reference the commit before contributing 

Also , wanted to inquire about SQL benchmark tests , if they are available in the project , to avoid importing  unnecessary packages  for testing  thank you for your quick response ; 
the benchmark does not seem to have correct versioning , I tried the command without altering the bench_test.go file just to see if it works ,the results were a fail 
```
# github.com/pingcap/tipb/go-binlog
../tipb/go-binlog/cistern.pb.go:130: undefined: grpc.SupportPackageIsVersion3
../tipb/go-binlog/pump.pb.go:159: undefined: grpc.SupportPackageIsVersion3
FAIL    github.com/pingcap/tidb [build failed]
```
I tried the `make update` to make sure I a have the correct version of dependencies and still got the same error.

Any suggestions would be appreciated , 
thank you 
 @coocood 
As you said the bench marks are slower on a remote redis , but a local one , not as much.
so concerning the code it will remain on the fork if you require the feature at any point in the future  , inform and i will create a pull request or you can create a pull request yourself , 

thank you again for all your help.  https://dev.mysql.com/doc/refman/5.7/en/string-functions.html#function_instr
btw, this doc https://github.com/ngaut/builddatabase/blob/master/tidb/builtin.md seems out of date, parser/scanner.l has been remove, and parser/misc.go instead . ?

  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
If possible, provide a recipe for reproducing the error.
query is  select log(a) from b wil return an error

2. What did you expect to see?

it's work on mysql

3. What did you see instead?

error occured

4. What version of Go are you using (`go version`)?

not so sure, i used the docker from the tutorial 2 months ago @shenli  please help to review #2258 for this issue  Hello TiDB's developer,

I tired to build TiDB from master branch and it run into these following errors:

# github.com/pingcap/tipb/go-binlog
/home/dev/go/src/github.com/pingcap/tipb/go-binlog/cistern.pb.go:130: undefined: grpc.SupportPackageIsVersion3
/home/dev/go/src/github.com/pingcap/tipb/go-binlog/pump.pb.go:159: undefined: grpc.SupportPackageIsVersion3
# github.com/pingcap/tidb/parser
/home/dev/go/src/github.com/pingcap/tidb/parser/lexer.go:92: undefined: yySymType
/home/dev/go/src/github.com/pingcap/tidb/parser/misc.go:494: undefined: yySymType
/home/dev/go/src/github.com/pingcap/tidb/parser/yy_parser.go:60: undefined: yySymType
/home/dev/go/src/github.com/pingcap/tidb/parser/yy_parser.go:61: undefined: yySymType
/home/dev/go/src/github.com/pingcap/tidb/parser/yy_parser.go:62: undefined: yySymType

Regards,
Yu Hi @shenli ,

thx for your help! Did you mean that man only need to run make under the project folder? I did it, but saw simliar errors below:

GOPATH=/home/dev/devel/go/tidb/trunk/_vendor:/home/dev/go GO15VENDOREXPERIMENT="1" go build -o bin/goyacc parser/goyacc/main.go
bin/goyacc -o /dev/null -xegen temp_parser_file parser/parser.y
Parse table entries: 603470 of 1398061, x 16 bits == 1206940 bytes
bin/goyacc -o parser/parser.go -xe temp_parser_file parser/parser.y 2>&1 | egrep "(shift|reduce)/reduce" | awk '{print} END {if (NR > 0) {print "Find conflict in parser.y. Please check y.output for more information."; system("rm -f temp_parser_file"); exit 1;}}'
rm -f temp_parser_file
rm -f y.output
GOPATH=/home/dev/devel/go/tidb/trunk/_vendor:/home/dev/go GO15VENDOREXPERIMENT="1" go build -ldflags '-X "github.com/pingcap/tidb/util/printer.TiDBBuildTS=2016-12-10 07:39:44" -X "github.com/pingcap/tidb/util/printer.TiDBGitHash=9ec16203f06c3ea8ab5130422af0d703d9724050"' -o bin/tidb-server tidb-server/main.go
# github.com/pingcap/tidb/parser
/home/dev/go/src/github.com/pingcap/tidb/parser/lexer.go:92: undefined: yySymType
/home/dev/go/src/github.com/pingcap/tidb/parser/misc.go:494: undefined: yySymType
/home/dev/go/src/github.com/pingcap/tidb/parser/yy_parser.go:60: undefined: yySymType
/home/dev/go/src/github.com/pingcap/tidb/parser/yy_parser.go:61: undefined: yySymType
/home/dev/go/src/github.com/pingcap/tidb/parser/yy_parser.go:62: undefined: yySymType


Regards,
Yu  HI @shenli ,

I see the mentioned file there:

drwxr-xr-x  4 dev dev    4096 Dec 10 20:39 ./
drwxr-xr-x 36 dev dev    4096 Dec 10 22:20 ../
drwxr-xr-x  2 dev dev    4096 Dec  9 23:00 goyacc/
-rw-r--r--  1 dev dev   13653 Dec  9 23:00 lexer.go
-rw-r--r--  1 dev dev    5647 Dec  9 23:00 lexer_test.go
-rw-r--r--  1 dev dev   15523 Dec  9 23:00 misc.go
drwxr-xr-x  2 dev dev    4096 Dec  9 23:00 opcode/
-rw-r--r--  1 dev dev 3980691 Dec 10 20:39 **parser.go**
-rw-r--r--  1 dev dev   51621 Dec  9 23:00 parser_test.go
-rw-r--r--  1 dev dev  115615 Dec  9 23:00 parser.y
-rw-r--r--  1 dev dev    5158 Dec  9 23:00 yy_parser.go

Regards,
Yu Hello @shenli ,

any new idea? what could be the reason of this compilation error?

Regards,
Yu Hi @shenli,

I get it now. I copy the text from the FAQ here. I think that the description in FAQ is not so much precise. The steps should be:

1. under a directory for example $HOME/tidb: git clone 
2. run git get
3. go to the directory: $GOPATH/github.com/pingcap/tidb and then run make parser
4. go to the directory: $HOME/tidb and then run make. 

Thx for your help! I find this project very interesting. 

Regards,
Yu

 
使用go get方式安装TiDB为什么报错了?

**请手动将TiDB克隆到GOPATH目录，然后运行make命令**。TiDB是一个项目而不是一个库，它的依赖比较复杂，并且parser也是根据parser.y生成的，我们不支持go get方式，而是使用Makefile来管理。

如果你是开发者并且熟习Go语言，你可以尝试在TiDB项目的根目录运行make parser; ln -s _vendor/src vendor，之后就可以使用go run, go test go install等命令，但是并不推荐这种做法。  I have add a function `BIN` for #310.

cc @siddontang @coocood.

I wonder If I should take `negative number` into consider, I'm not sure if `mysql` support `negative number` now? 
 [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2219) <br/>All committers have signed the CLA. @siddontang , How could I rebase the two commit into one now. @shenli,  Thanks for you review. So would you mind send the document to my email `895179504@qq.com`. @coocood, `fmt.Sprintf("%b", n)` is good. But it's not suitable for `negative integer`.

`1111111111111111111111111111111111111111111111111111111111111111` is `^(-1) + 1`, right?

So, it seems `mysql` support negative integer. okay. got it.

where should I use the function `builtinBIN`? @coocood, where is `scanner.l`?  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
If possible, provide a recipe for reproducing the error.

using go mysql driver `github.com/go-sql-driver/mysql`

sql: `select id from x LIMIT 10 OFFSET 5`

or

sql: `select id from x LIMIT 5,10`

2. What did you expect to see?

10 results returns

3. What did you see instead?

15 results returns (But I run that command in mysql client, it works. Did I missing something?)


4. What version of Go are you using (`go version`)?

go 1.7.4 very strange. I tried a test case, but it works now, I'll check. the fmt mislead Encountered same issue when I tried to use tidb alongside micro/user-srv (haven't tried other srv's from micro with tidb yet), [sql source](https://github.com/micro/user-srv/tree/master/db/db.go), errors:
```
H:\gopath\src\github.com\micro\user-srv>user-srv --database_url="root@tcp(192.168.99.100:4000)/users"
2016/12/31 12:43:02 Prepering searchEmail SELECT id, username, email, salt, password, created, updated from %s.%s where email = ? limit ? offset ?
2016/12/31 12:43:02 Error 1105: line 0 column 104 near " offset ?"
```
(note the Preparing log is my addition, not part of master branch of user-srv, it prints the statement before it gets formatted)
This issue seems to only occur to statements containing limit & offset.
TiDB is simply ran from latest image in local docker container. Thanks, you too! Sorry to bother you but it still doesn't seem to work:
```
H:\gopath\src\github.com\micro\user-srv>user-srv.exe --database_url="root:111111@tcp(192.168.99.100:32769)/users"
2017/01/03 09:37:18 Listening on [::]:51318
2017/01/03 09:37:18 Broker Listening on [::]:51319
2017/01/03 09:37:18 Registering node: go.micro.srv.user-744cb455-d187-11e6-9f03-0a0027000008
2017/01/03 09:37:24 Deregistering node: go.micro.srv.user-744cb455-d187-11e6-9f03-0a0027000008

H:\gopath\src\github.com\micro\user-srv>user-srv.exe --database_url="root@tcp(192.168.99.100:32770)/users"
2017/01/03 09:37:40 Prepering list SELECT id, username, email, salt, password, created, updated from users.sessions limit ? offset ?
2017/01/03 09:37:40 Error 1105: line 0 column 88 near " offset ?"
```
port ending with 69 is an alpine-mysql container and works OK with it, but port ending in 70 is latest tidb and doesn't work, version: 
```
2017/01/03 07:33:13 printer.go:31: [info] Welcome to TiDB.
2017/01/03 07:33:13 printer.go:32: [info] Version:
2017/01/03 07:33:13 printer.go:33: [info] Git Commit Hash: 3f9a101ce6a31d508d184aa03f2ebb8209a9e480
2017/01/03 07:33:13 printer.go:34: [info] UTC Build Time:  2017-01-03 04:43:44
```

latest record in the log for tidb after one attempt is: 
```
2017/01/03 07:37:40 server.go:115: [info] [25] new connection 192.168.99.1:51333
2017/01/03 07:37:40 conn.go:350: [warning] [25] dispatch error:
id:25, addr:192.168.99.1:51333 status:2, collation:utf8_general_ci, user:root
SELECT id, username, email, salt, password, created, updated from users.accounts limit ? offset ?
line 0 column 88 near " offset ?"
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/parser/yy_parser.go:96: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/executor/prepared.go:125: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn_stmt.go:50: 
2017/01/03 07:37:40 conn.go:340: [error] read tcp 172.17.0.5:4000->192.168.99.1:51333: read: connection reset by peer
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:72: 
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:94:  
2017/01/03 07:37:40 txn.go:126: [info] [kv] Rollback txn 388872027526397952
2017/01/03 07:37:40 server.go:192: [info] [25] close connection
```
I also attached entire docker container log file: [logs.txt](https://github.com/pingcap/tidb/files/681842/logs.txt)
 Okay yeah, pulling it again worked, but now I have a new error, when actually using the limit/offset:
```
2017/01/03 09:28:23 logical_plan_builder.go:447: [error] Invalid type int64 for Limit/Offset
2017/01/03 09:28:23 tidb.go:194: [info] RollbackTxn for ddl/autocommit error.
2017/01/03 09:28:23 txn.go:126: [info] [kv] Rollback txn 388873769071935488
2017/01/03 09:28:23 conn.go:350: [warning] [2] dispatch error:
id:2, addr:192.168.99.1:52674 status:2, collation:utf8_general_ci, user:root
user
[11:1210]Incorrect arguments to EXECUTE
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/plan/optimizer.go:45:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/executor/prepared.go:235:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/executor/adapter.go:96:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/tidb.go:200:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/session.go:564:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/driver_tidb.go:66:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn_stmt.go:168:
```
I believe the query in question was 
```
SELECT id, username, email, salt, password, created, updated from users.accounts where username = ? limit ? offset ?
```
with arguments `user`, `1`, `0`. (`r, err = st["searchUsername"].Query(username, 1, 0)`) That one was used for alpine-mysql, my commands right now are
`H:\gopath\src\github.com\micro\user-srv>user-srv.exe --database_url="root@tcp(192.168.99.100:4000)/users"
`
to launch and then I did `query go.micro.srv.user Account.Create {"user": {"username":"user"}, "password": "pass"}` to create account and `query go.micro.srv.user Account.Login {"username": "user", "password": "pass"}` which is where it should've returned a session but returned error `error calling go.micro.srv.user.Account.Login: Error 1210: Incorrect arguments to EXECUTE`

As far as I saw on those lines its passing integers to offset/limit  
您好，ＴＩＤＢ的架构是不是ＫＶ是单独一层（ＫＶ单独配置），ＴＩＤＢ类似于中间件？  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
If possible, provide a recipe for reproducing the error.

create table first

```
CREATE TABLE IF NOT EXISTS x (
  `id`        VARCHAR(36) PRIMARY KEY NOT NULL,
  `link`      VARCHAR(512)            NOT NULL,
  `factor`    INTEGER                 NOT NULL                   DEFAULT 1,
  `create_at` DATETIME                NOT NULL                   DEFAULT now(),
  `update_at` TIMESTAMP               NOT NULL                   DEFAULT now()
);
CREATE UNIQUE INDEX y ON x(link);
```

insert data several times

```
INSERT INTO x(id,link) VALUES('id','/testlink') ON DUPLICATE KEY UPDATE factor=factor+1;
INSERT INTO x(id,link) VALUES('id','/testlink') ON DUPLICATE KEY UPDATE factor=factor+1;
INSERT INTO x(id,link) VALUES('id','/testlink') ON DUPLICATE KEY UPDATE factor=factor+1;
INSERT INTO x(id,link) VALUES('id','/testlink') ON DUPLICATE KEY UPDATE factor=factor+1;
```
2. What did you expect to see?

x.factor should be added multiple, not once.

3. What did you see instead?

```
mysql> INSERT INTO x(id,link) VALUES('id','/testlink') ON DUPLICATE KEY UPDATE factor=factor+1;
Query OK, 1 row affected (0.21 sec)

mysql> INSERT INTO x(id,link) VALUES('id','/testlink') ON DUPLICATE KEY UPDATE factor=factor+1;
Query OK, 2 rows affected (0.20 sec)

mysql> INSERT INTO x(id,link) VALUES('id','/testlink') ON DUPLICATE KEY UPDATE factor=factor+1;
Query OK, 0 rows affected (0.41 sec)

mysql> INSERT INTO x(id,link) VALUES('id','/testlink') ON DUPLICATE KEY UPDATE factor=factor+1;
Query OK, 0 rows affected (0.20 sec)

mysql> INSERT INTO x(id,link) VALUES('id','/testlink') ON DUPLICATE KEY UPDATE factor=factor+1;
Query OK, 0 rows affected (0.20 sec)
```

4. What version of Go are you using (`go version`)?

go 1.7.4  Please answer these questions before submitting your issue. Thanks!

1. What did you do?
If possible, provide a recipe for reproducing the error.
SELECT schema()

2. What did you expect to see?
test


3. What did you see instead?
[HY000][1105] Function schema is not implemented.


4. What version of Go are you using (`go version`)?
go version go1.7.1 windows/amd64
 Thanks for your new code
use msyql client 
$ ./bin/mysql --version
  Ver 14.14 Distrib 5.6.28, for Win32 (AMD64)
mysql> SELECT  schema();
+----------+
| schema() |
+----------+
|     test |
+----------+
that's ok
but,  DataGrid 2016.2.1 with Jdbc-5.1.35
SELECT  schema();
<failed to load>
java.sql.SQLException: Bad format for BigDecimal 'test' in column 1.
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:998)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:937)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:926)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:872)
	at com.mysql.jdbc.ResultSetImpl.getObject(ResultSetImpl.java:4505)
	at com.intellij.database.remote.jdbc.impl.RemoteResultSetImpl.tryGetObject(RemoteResultSetImpl.java:1271)
	at com.intellij.database.remote.jdbc.impl.RemoteResultSetImpl.getObject(RemoteResultSetImpl.java:1249)
	at com.intellij.database.remote.jdbc.impl.RemoteResultSetImpl.getCurrentRow(RemoteResultSetImpl.java:1233)
	at com.intellij.database.remote.jdbc.impl.RemoteResultSetImpl.getObjects(RemoteResultSetImpl.java:1212)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:323)
	at sun.rmi.transport.Transport$1.run(Transport.java:200)
	at sun.rmi.transport.Transport$1.run(Transport.java:197)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.rmi.transport.Transport.serviceCall(Transport.java:196)
	at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:568)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:826)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:683)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:682)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

and in python  with MySQLdb 1.2.3
SELECT  schema();
decimal.InvalidOperation: Invalid literal for Decimal: 'test' well, I use jdbc-5.1.38 test it, it's no wrong,  it seems Datagrid's bug. all ok,thanks for your quickly fix. it's some thing wrong in  character encode before? yes, all test ok, thanks again  LGTM [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2170) <br/>All committers have signed the CLA.  if tidb supports sysbench?  LGTM  Compared with MySQL Cluster,what's the advantage of TiDB? What I mean is not the mysql cluster with proxy,but mysql cluster that MySQL official provides. Thank you for your answer.And i want to know when TiDB can release stable version.  Apologies if I'm just blind and not seeing it, but I see that Views are not supported "because they cannot be implemented well in distributed scenario."

Is it documented somewhere what the difficulties are with the unsupported features? I feel like this would be important so if somebody has an idea on how to solve the problem, maybe even partially, they know what the known hurdles are. Or maybe something could be optimized in a another way (e.g. try and clump data on fewer nodes, instead of all spread out, so the view would be less expensive).  The [Quick Start](https://github.com/pingcap/tidb/blob/master/docs/QUICKSTART.md) page shows you how to run TiDB via docker on a single container, but real-life usage is going to need us to run this on more than one node (otherwise we might as well just use MySQL).

It would be quite nice if you can provide an example setup with TiDB split over several docker containers. 
* That allows us to check the exact required configuration needed in a more realistic setup.
* I would expect that it should then be reasonably straight forward to add another node and see how TiDB behaves when such a node is added
* Further more simulating failure of a node should be straightforward with this setup just by stopping one of the containers.

For such a test case storage is not really important. This is just for testing but it gives a newcomer an easier way to start to trying out TiDB in a throw-away environment. Docker 1.13 ([RC available](https://github.com/docker/docker/releases)) supports built-in "Docker Compose on Swarm-mode" feature
https://blog.nimbleci.com/2016/11/17/whats-coming-in-docker-1-13/#deploy-stacks-from-a-docker-compose-file

It would be great if we can use TiDB with that feature  I deploy tidb on centos7 all in one node by reading this article https://github.com/pingcap/docs/blob/master/op-guide/binary-deployment.md#standalone-cluster-deployment

I got a warning : get timestamp too slow
tow error : [error] [ddl] SetValidity, schema validity is false, lastSuccTS:387990267072086017


and when I use mysql client to connect tidb import some data than mysqldump from mysql , I got this error: ERROR 1105 (HY000) at line 420 in file: '/server/software/sdb_b2c_members.sql': InfomationSchema is out of date.

this is the log from pd

2016/11/25 17:19:53 tso.go:122: [warning] clock offset: 201.859059ms, prev: 2016-11-25 17:19:52.868617921 +0800 CST, now: 2016-11-25 17:19:53.07047698 +0800 CST
2016/11/25 17:19:53 tso.go:122: [warning] clock offset: 491.182246ms, prev: 2016-11-25 17:19:53.07047698 +0800 CST, now: 2016-11-25 17:19:53.561659226 +0800 CST
2016/11/25 17:19:53 tso.go:126: [warning] invalid physical timestamp, prev: 2016-11-25 17:19:53.561659226 +0800 CST, now: 2016-11-25 17:19:53.561900752 +0800 CST, re-update later
2016-11-25 17:19:53.680096 W | etcdserver: apply entries took too long [146.04305ms for 1 entries]
2016-11-25 17:19:53.710747 W | etcdserver: avoid queries with large range/delete range!
2016-11-25 17:20:00.761738 W | etcdserver: apply entries took too long [118.253557ms for 1 entries]
2016-11-25 17:20:00.761773 W | etcdserver: avoid queries with large range/delete range!
2016-11-25 17:20:00.938928 W | etcdserver: apply entries took too long [171.67921ms for 1 entries]
2016-11-25 17:20:00.938951 W | etcdserver: avoid queries with large range/delete range!
2016-11-25 17:20:08.578604 W | etcdserver: apply entries took too long [156.535257ms for 1 entries]
2016-11-25 17:20:08.578634 W | etcdserver: avoid queries with large range/delete range!
2016/11/25 17:20:08 tso.go:122: [warning] clock offset: 361.082481ms, prev: 2016-11-25 17:20:08.211681046 +0800 CST, now: 2016-11-25 17:20:08.572763527 +0800 CST
2016-11-25 17:20:12.073173 W | etcdserver: apply entries took too long [25.271654ms for 1 entries]
2016-11-25 17:20:12.073198 W | etcdserver: avoid queries with large range/delete range!
2016/11/25 17:20:23 conn.go:75: [error] read request message err EOF
2016-11-25 17:20:26.627528 W | etcdserver: apply entries took too long [64.413632ms for 1 entries]
2016/11/25 17:20:26 tso.go:122: [warning] clock offset: 184.163556ms, prev: 2016-11-25 17:20:26.409493309 +0800 CST, now: 2016-11-25 17:20:26.593656865 +0800 CST
2016-11-25 17:20:26.627659 W | etcdserver: avoid queries with large range/delete range!
2016/11/25 17:20:29 tso.go:126: [warning] invalid physical timestamp, prev: 2016-11-25 17:20:29.535929191 +0800 CST, now: 2016-11-25 17:20:29.53600628 +0800 CST, re-update later
2016/11/25 17:20:29 tso.go:126: [warning] invalid physical timestamp, prev: 2016-11-25 17:20:29.657106527 +0800 CST, now: 2016-11-25 17:20:29.657619445 +0800 CST, re-update later
2016-11-25 17:20:34.402114 W | etcdserver: apply entries took too long [297.675748ms for 1 entries]
2016-11-25 17:20:34.402151 W | etcdserver: avoid queries with large range/delete range!
2016/11/25 17:20:34 util.go:202: [warning] txn runs too slow, resp: &{cluster_id:2037210783374497686 member_id:13195394291058371180 revision:674 raft_term:2  true [response_put:<header:<revision:674 > > ]}, err: <nil>, cost: 1.838928603s
2016/11/25 17:20:34 tso.go:122: [warning] clock offset: 2.061606613s, prev: 2016-11-25 17:20:32.459558159 +0800 CST, now: 2016-11-25 17:20:34.521164772 +0800 CST


I see the log string like '2016/11/25 17:25:15 leader.go:195: [info] PD cluster leader pd is ready to serve '  in the pd log many times

what does it mean? please help me thank you for help me.
When I use 3 virtual machines( every virtual machines has 4 cores and 2G ram) to deploy tidb, I also got that problem.  what should I do ?
 ok,thank you.
I will try do a test on aliyun use 6 ecs machine(4 cores, 16G ram)  LGTM  standalone-cluster-deployment is success
but multi-nodes-deployment is fail
My step:


|Name|Host IP|Services|
|----|-------|--------|
|node1|192.168.50.171|PD1, TiKV1, TiDB|
|node2|192.168.50.172|PD2, TiKV2|
|node3|192.168.50.173|PD3, TiKV3|

1. Start PD on every node.

    ```bash
    ./bin/pd-server --name=pd1 \
                    --data-dir=pd1 \
                    --client-urls="http://192.168.50.171:2379" \
                    --peer-urls="http://192.168.50.171:2380" \
                    --initial-cluster="pd1=http://192.168.50.171:2380,pd2=http://192.168.50.172:2380,pd3=http://192.168.50.173:2380"
              
    ./bin/pd-server --name=pd2 \
                    --data-dir=pd2 \
                    --client-urls="http://192.168.50.172:2379" \
                    --peer-urls="http://192.168.50.172:2380" \
                    --initial-cluster="pd1=http://192.168.50.171:2380,pd2=http://192.168.50.172:2380,pd3=http://192.168.50.173:2380"
              
    ./bin/pd-server --name=pd3 \
                    --data-dir=pd3 \
                    --client-urls="http://192.168.50.173:2379" \
                    --peer-urls="http://192.168.50.173:2380" \
                    --initial-cluster="pd1=http://192.168.50.171:2380,pd2=http://192.168.50.172:2380,pd3=http://192.168.50.173:2380"
    ```

2. Start TiKV on every node.

    ```bash
    ./bin/tikv-server --pd="192.168.50.171:2379,192.168.50.172:2379,192.168.50.173:2379" \
                      --addr="192.168.50.171:20160" \
                      --store=tikv1    
    ```
    this start not success, will report error:

 panic_hook.rs:85 - ERROR - thread 'main' panicked 'Address("invalid addr: http://192.168.50.171:2379")' at "src/bin/tikv-server.rs:649"

 thanks 1. pd1 log all ok
2. pd2/pd3 error log
```
2016/11/22 17:03:55 leader.go:89: [error] campaign leader err /home/jenkins/workspace/WORKFLOW_PD_BUILDING/go/src/github.com/pingcap/pd/server/leader.go:171: campaign leader failed, other server may campaign ok
2016/11/22 17:03:55 leader.go:82: [info] leader is addr:"http://192.168.50.171:2379" pid:1582 , watch it
2016-11-22 17:04:21.440039 W | rafthttp: the clock difference against peer bc10dd92408e5702 is too high [1.543795507s > 1s]
2016-11-22 17:04:51.440314 W | rafthttp: the clock difference against peer bc10dd92408e5702 is too high [1.527881502s > 1s]
```
3. tikv1 error log
```
2016-11-22 17:04:01,056 tikv-server.rs:73 - INFO  - flag pd: Some("http://192.168.50.171:2379,http://192.168.50.172:2379,http://192.168.50.173:2379")
2016-11-22 17:04:11,120 panic_hook.rs:85 - ERROR - thread 'main' panicked 'Address("invalid addr: http://192.168.50.171:2379")' at "src/bin/tikv-server.rs:649"
stack backtrace:
   0:     0x7ff8faa2db1e - backtrace::backtrace::libunwind::trace
                        at /home/jenkins/.cargo/registry/src/github.com-1ecc6299db9ec823/backtrace-0.2.3/src/backtrace/libunwind.rs:54
                         - backtrace::backtrace::trace<closure>
                        at /home/jenkins/.cargo/registry/src/github.com-1ecc6299db9ec823/backtrace-0.2.3/src/backtrace/mod.rs:70
   1:     0x7ff8faa2e218 - backtrace::capture::{{impl}}::new
                        at /home/jenkins/workspace/WORKFLOW_TIKV_BUILDING/go/src/github.com/pingcap/tikv/target/release/build/backtrace-3bc1ff360ebb00cb/out/capture.rs:79
   2:     0x7ff8fa6000bf - tikv::util::panic_hook::set_exit_hook::{{closure}}
                        at /home/jenkins/workspace/WORKFLOW_TIKV_BUILDING/go/src/github.com/pingcap/tikv/src/util/panic_hook.rs:84
   3:     0x7ff8fab3b6ec - std::panicking::rust_panic_with_hook::h105c3d42fcd2fb5e
   4:     0x7ff8fab3b561 - std::panicking::begin_panic::hbf62ea4a5ff3f9de
   5:     0x7ff8fab3b48a - std::panicking::begin_panic_fmt::h20f5943904e5791d
   6:     0x7ff8fa498b35 - tikv_server::main
                        at /home/jenkins/workspace/WORKFLOW_TIKV_BUILDING/go/src/github.com/pingcap/tikv/<std macros>:8
   7:     0x7ff8fab3b378 - std::panicking::try::call::h5df3ac2979db3c90
   8:     0x7ff8fab43ab6 - __rust_maybe_catch_panic
   9:     0x7ff8fab3a49e - std::rt::lang_start::hfe9ab243c60ffb9b
  10:     0x7ff8f965faf4 - __libc_start_main
  11:     0x7ff8fa380ad0 - <unknown>
  12:                0x0 - <unknown>
``` pd2/pd3 log
```
2016/11/22 17:03:55 server.go:159: [info] init cluster id 6355715944801548947
2016/11/22 17:03:55 leader.go:89: [error] campaign leader err /home/jenkins/workspace/WORKFLOW_PD_BUILDING/go/src/github.com/pingcap/pd/server/leader.go:171: campaign leader failed, other server may campaign ok
2016/11/22 17:03:55 leader.go:82: [info] leader is addr:"http://192.168.50.171:2379" pid:1582 , watch it
2016-11-22 17:04:21.440039 W | rafthttp: the clock difference against peer bc10dd92408e5702 is too high [1.543795507s > 1s]
2016-11-22 17:04:51.440314 W | rafthttp: the clock difference against peer bc10dd92408e5702 is too high [1.527881502s > 1s]
2016-11-22 17:05:21.440584 W | rafthttp: the clock difference against peer bc10dd92408e5702 is too high [1.514829066s > 1s]
2016-11-22 17:05:51.440881 W | rafthttp: the clock difference against peer bc10dd92408e5702 is too high [1.498730944s > 1s]
2016-11-22 17:06:21.441322 W | rafthttp: the clock difference against peer bc10dd92408e5702 is too high [1.484863084s > 1s]
2016-11-22 17:06:51.441656 W | rafthttp: the clock difference against peer bc10dd92408e5702 is too high [1.468913518s > 1s]
2016-11-22 17:07:21.441960 W | rafthttp: the clock difference against peer bc10dd92408e5702 is too high [1.455598899s > 1s]
```
 pd2/pd3 seems can connect 192.168.50.171:2379 pd1 log
```
2016-11-22 17:03:45.959204 I | embed: ready to serve client requests
2016-11-22 17:03:45.960014 N | embed: serving insecure client requests on 192.168.50.171:2379, this is strongly discouraged!
2016/11/22 17:03:45 server.go:134: [info] create etcd v3 client with endpoints [http://192.168.50.171:2379]
2016-11-22 17:03:46.597916 W | rafthttp: health check for peer 406651ad7bc4c362 could not connect: dial tcp 192.168.50.172:2380: getsockopt: connection refused
2016-11-22 17:03:46.598111 W | rafthttp: health check for peer c1fa47d93efeaf83 could not connect: dial tcp 192.168.50.173:2380: getsockopt: connection refused
2016-11-22 17:03:49.960888 W | etcdserver: failed to reach the peerURL(http://192.168.50.173:2380) of member c1fa47d93efeaf83 (Get http://192.168.50.173:2380/version: dial tcp 192.168.50.173:2380: getsockopt: connection refused)
2016-11-22 17:03:49.960932 W | etcdserver: cannot get the version of member c1fa47d93efeaf83 (Get http://192.168.50.173:2380/version: dial tcp 192.168.50.173:2380: getsockopt: connection refused)
2016-11-22 17:03:51.600347 W | rafthttp: health check for peer c1fa47d93efeaf83 could not connect: dial tcp 192.168.50.173:2380: getsockopt: connection refused
2016-11-22 17:03:51.754809 I | rafthttp: peer c1fa47d93efeaf83 became active
2016-11-22 17:03:51.757434 I | rafthttp: established a TCP streaming connection with peer c1fa47d93efeaf83 (stream Message reader)
2016-11-22 17:03:51.760516 I | rafthttp: established a TCP streaming connection with peer c1fa47d93efeaf83 (stream MsgApp v2 writer)
2016-11-22 17:03:51.761117 I | rafthttp: established a TCP streaming connection with peer c1fa47d93efeaf83 (stream Message writer)
2016-11-22 17:03:51.798919 I | rafthttp: established a TCP streaming connection with peer c1fa47d93efeaf83 (stream MsgApp v2 reader)
2016-11-22 17:03:53.973770 I | etcdserver: updating the cluster version from 2.3 to 3.0
2016-11-22 17:03:54.021405 N | membership: updated the cluster version from 2.3 to 3.0
2016-11-22 17:03:54.021492 I | api: enabled capabilities for version 3.0
2016/11/22 17:03:54 server.go:159: [info] init cluster id 6355715944801548947
2016/11/22 17:03:54 leader.go:195: [info] PD cluster leader pd1 is ready to serve
``` it is ok, thanks  I have 2 table， each table have 1Million data，order_unit.order_detail_id ref to order_detail.id, but it is not a reference key, just integer type. 
when I query like this:
select od.* from order_unit ou join order_detail od on ou.order_detail_id = od.id where ou.id > 90000 and ou.id < 100000 order by ou.id desc limit 20;

takes: 20 rows in set (7 min 0.35 sec)

query: select count(1) from order_unit; takes: 1 row in set (1.19 sec)
query: select * from order_unit order by id desc limit 20; takes: 20 rows in set (0.02 sec)

Summary: simple query is fast, count is a little slow, join is terrible.

tidb has 3 kv, 1pd, 1tidb. ubuntu running in vbox  1core 2G men.

 Thanks, looks like the code need some warm up time, I try the code half hour later, it takes 10 seconds. It is better but still must slower than mysql. Expect more optimization.  LGTM @tiancaiamao @coocood PTAL  I use latest tidb today, and source command to load a big sql file, after a minutes, tidb prompt something like:

Query OK, 542 rows affected (0.19 sec)

Query OK, 541 rows affected (0.20 sec)

Query OK, 540 rows affected (0.18 sec)

ERROR 1105 (HY000) at line 1020 in file: '/home/sx/soft/big_data-2016-11-21.sql': context canceled
ERROR 1105 (HY000) at line 1021 in file: '/home/sx/soft/big_data-2016-11-21.sql': InfomationSchema is out of date.
ERROR 1105 (HY000) at line 1022 in file: '/home/sx/soft/big_data-2016-11-21.sql': InfomationSchema is out of date.
ERROR 1105 (HY000) at line 1023 in file: '/home/sx/soft/big_data-2016-11-21.sql': InfomationSchema is out of date.
ERROR 1105 (HY000) at line 1024 in file: '/home/sx/soft/big_data-2016-11-21.sql': InfomationSchema is out of date.


so, what configure file and configuration I should change, make it work again? thanks thanks，tikv is done  ![show](https://cloud.githubusercontent.com/assets/23513271/20413819/fa6a4614-ad69-11e6-8df0-83a415fadcbb.png)
可以查询  但会提示  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=2021) <br/>All committers have signed the CLA.
  2016-11-17 08:19:48,652 mod.rs:399 - INFO  - Version:
2016-11-17 08:19:48,652 mod.rs:400 - INFO  - Git Commit Hash: eb7efc6f7817df6658ee3d4b09bedfce8a10b35a
2016-11-17 08:19:48,652 mod.rs:401 - INFO  - UTC Build Time:  2016-11-15 10:24:35
2016-11-17 08:19:48,653 tikv-server.rs:221 - WARN  - Limit("kernel parameters net.core.somaxconn got 128, expect 32768")
2016-11-17 08:19:48,653 tikv-server.rs:221 - WARN  - Limit("kernel parameters net.ipv4.tcp_syncookies got 1, expect 0")
2016-11-17 08:19:48,653 tikv-server.rs:221 - WARN  - Limit("kernel parameters vm.swappiness got 60, expect 0")
2016-11-17 08:19:48,653 tikv-server.rs:849 - INFO  - Start listening on 192.168.15.13:20160...
2016-11-17 08:19:53,991 panic_hook.rs:85 - ERROR - thread 'main' panicked 'called `Result::unwrap()` on an `Err` value: Io(Error { repr: Os { code: 98, message: "Address already in use" } })' at "../src/libcore/result.rs:788"
stack backtrace:
   0:     0x7fdd3187bf4e - backtrace::backtrace::libunwind::trace
                        at /home/jenkins/.cargo/registry/src/github.com-1ecc6299db9ec823/backtrace-0.2.3/src/backtrace/libunwind.rs:54
                         - backtrace::backtrace::trace<closure>
                        at /home/jenkins/.cargo/registry/src/github.com-1ecc6299db9ec823/backtrace-0.2.3/src/backtrace/mod.rs:70
   1:     0x7fdd3187c663 - backtrace::capture::{{impl}}::new
                        at /home/jenkins/workspace/BUILD_TIDB_PLATFORMS/go/src/github.com/pingcap/tikv/target/release/build/backtrace-3bc1ff360ebb00cb/out/capture.rs:79
   2:     0x7fdd3145b420 - tikv::util::panic_hook::set_exit_hook::{{closure}}
                        at /home/jenkins/workspace/BUILD_TIDB_PLATFORMS/go/src/github.com/pingcap/tikv/src/util/panic_hook.rs:84
   3:     0x7fdd3196a357 - std::panicking::rust_panic_with_hook::h105c3d42fcd2fb5e
   4:     0x7fdd3196a242 - std::panicking::begin_panic::hbf62ea4a5ff3f9de
   5:     0x7fdd3196a170 - std::panicking::begin_panic_fmt::h20f5943904e5791d
   6:     0x7fdd3196a0f1 - rust_begin_unwind
   7:     0x7fdd319a76bc - core::panicking::panic_fmt::h19323e466869c656
   8:     0x7fdd312a4420 - {{inlined-root}}::unwrap_failed<tikv::server::errors::Error>
                        at /buildslave/rust-buildbot/slave/nightly-dist-rustc-linux/build/obj/../src/libcore/result.rs:29
   9:     0x7fdd313350fa - {{inlined-root}}::unwrap<mio::net::tcp::TcpListener,tikv::server::errors::Error>
                        at /buildslave/rust-buildbot/slave/nightly-dist-rustc-linux/build/obj/../src/libcore/result.rs:726
                         - tikv_server::main
                        at /home/jenkins/workspace/BUILD_TIDB_PLATFORMS/go/src/github.com/pingcap/tikv/src/bin/tikv-server.rs:850
  10:     0x7fdd3196a047 - std::panicking::try::call::h5df3ac2979db3c90
  11:     0x7fdd319728a6 - __rust_maybe_catch_panic
  12:     0x7fdd319691e9 - std::rt::lang_start::hfe9ab243c60ffb9b
  13:     0x7fdd3055bd1c - __libc_start_main
  14:     0x7fdd3124fb60 - <unknown>
  Please answer these questions before submitting your issue. Thanks!

1. What version of Go are you using (`go version`)?
go version go1.7.3 darwin/amd64

2. What operating system and processor architecture are you using (`go env`)?
mac osx 10.12.1

3. What did you do?
go get -u -v github.com/pingcap/tidb
make build

4. What did you expect to see?
compile no error

5. What did you see instead?
➜  tidb git:(master) make build
GOPATH=/Users/lunny/gopath/src/github.com/pingcap/tidb/_vendor:/Users/lunny/gopath GO15VENDOREXPERIMENT="1" go build
# github.com/pingcap/tidb/parser
parser/lexer.go:81: undefined: yySymType
parser/misc.go:479: undefined: yySymType
parser/yy_parser.go:73: undefined: yySymType
parser/yy_parser.go:74: undefined: yySymType
parser/yy_parser.go:75: undefined: yySymType
make: *** [build] Error 2 sorry for that. resolved.
  mysqlslap -a -c 500 --auto-generate-sql-write-number=100000 -T -i 10  -h 10.25.175.125 -P 4000 -uroot
mysqlslap: Cannot run query SELECT intcol1,charcol1 FROM t1 ERROR : table mysqlslap.t1

不能完成测试。。。 好的
 mysqlslap -a -c 500 --auto-generate-sql-write-number=100000 -T -i 10 -h 127.0.0.1 -P 4000 -u root
mysqlslap: Cannot run query INSERT INTO t1 VALUES (73673339,'BN3152Gza4GW7atxJKACYwJqDbFynLxqc0kh30YTwgz3FktQ43XTrqJ4PQ25frn7kXhfXD8RuzN1j8Rf3y8ugKy6es3IbqPJM6ylCyD6xS7YcQCfHKZxYNvB7yTahm') ERROR : Information schema is out of date.
很遗憾，不能跑完测试

tidb-server错误日志：

2017/02/07 00:40:48 server.go:192: [info] [239] close connection
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m57.496815582s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 adapter.go:167: [warning] [146][TIME_QUERY] 1m57.491960023s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [146] dispatch error:
id:146, addr:127.0.0.1:45640 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [146] close connection
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m57.495164896s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 adapter.go:167: [warning] [232][TIME_QUERY] 1m57.522066231s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [232] dispatch error:
id:232, addr:127.0.0.1:45876 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [232] close connection
2017/02/07 00:40:48 adapter.go:167: [warning] [278][TIME_QUERY] 1m57.518926179s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [278] dispatch error:
id:278, addr:127.0.0.1:46072 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [278] close connection
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m57.521309289s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 adapter.go:167: [warning] [107][TIME_QUERY] 1m57.546996418s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [107] dispatch error:
id:107, addr:127.0.0.1:45720 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [107] close connection
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m57.668531203s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 adapter.go:167: [warning] [238][TIME_QUERY] 1m57.693958271s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [238] dispatch error:
id:238, addr:127.0.0.1:45856 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [238] close connection
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m57.721137323s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 adapter.go:167: [warning] [102][TIME_QUERY] 1m57.746508867s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [102] dispatch error:
id:102, addr:127.0.0.1:45744 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [102] close connection
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m57.772612916s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 adapter.go:167: [warning] [84][TIME_QUERY] 1m57.796215649s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [84] dispatch error:
id:84, addr:127.0.0.1:45615 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [84] close connection
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m57.820856912s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m57.817213771s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 adapter.go:167: [warning] [245][TIME_QUERY] 1m57.852591469s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [245] dispatch error:
id:245, addr:127.0.0.1:45884 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [245] close connection
2017/02/07 00:40:48 adapter.go:167: [warning] [373][TIME_QUERY] 1m57.843835157s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [373] dispatch error:
id:373, addr:127.0.0.1:46044 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [373] close connection
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m57.838727777s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m57.87370067s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 adapter.go:167: [warning] [193][TIME_QUERY] 1m57.864497443s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [193] dispatch error:
id:193, addr:127.0.0.1:45892 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [193] close connection
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m57.872991895s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m57.884947704s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 adapter.go:167: [warning] [150][TIME_QUERY] 1m57.905097763s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [150] dispatch error:
id:150, addr:127.0.0.1:45796 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [150] close connection
2017/02/07 00:40:48 adapter.go:167: [warning] [148][TIME_QUERY] 1m57.905051731s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [148] dispatch error:
id:148, addr:127.0.0.1:45788 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [148] close connection
2017/02/07 00:40:48 adapter.go:167: [warning] [171][TIME_QUERY] 1m57.913010581s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [171] dispatch error:
id:171, addr:127.0.0.1:45814 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [171] close connection
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m57.98042924s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m57.964377332s backoff(96ms [tikvRPC]) region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m58.021276697s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 adapter.go:167: [warning] [305][TIME_QUERY] 1m58.02040803s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [305] dispatch error:
id:305, addr:127.0.0.1:46012 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [305] close connection
2017/02/07 00:40:48 adapter.go:167: [warning] [488][TIME_QUERY] 1m57.996948538s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [488] dispatch error:
id:488, addr:127.0.0.1:46416 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [488] close connection
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m58.039085492s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 adapter.go:167: [warning] [195][TIME_QUERY] 1m58.049919497s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [195] dispatch error:
id:195, addr:127.0.0.1:45890 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [195] close connection
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m58.07315682s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 coprocessor.go:339: [info] [TIME_COP_TASK] 1m58.066203698s region(2 3 1) ranges(1) store(10.28.92.2:20160)
2017/02/07 00:40:48 adapter.go:167: [warning] [139][TIME_QUERY] 1m58.083875755s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [139] dispatch error:
id:139, addr:127.0.0.1:45644 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [139] close connection
2017/02/07 00:40:48 adapter.go:167: [warning] [259][TIME_QUERY] 1m58.119766816s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [259] dispatch error:
id:259, addr:127.0.0.1:45968 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [259] close connection
2017/02/07 00:40:48 adapter.go:167: [warning] [121][TIME_QUERY] 1m58.110015164s SELECT intcol1,charcol1 FROM t1
2017/02/07 00:40:48 conn.go:354: [warning] [121] dispatch error:
id:121, addr:127.0.0.1:45558 status:2, collation:latin1_swedish_ci, user:root
SELECT intcol1,charcol1 FROM t1
connection was bad
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:146:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:769:
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/conn.go:677:
2017/02/07 00:40:48 server.go:192: [info] [121] close connection
2017/02/07 00:41:09 metrics.go:303: [warning] [EXPENSIVE_QUERY] select * from mysql.user order by host, user;
2017/02/07 00:41:09 metrics.go:303: [warning] [EXPENSIVE_QUERY] select * from mysql.db order by host, db, user;
2017/02/07 00:41:09 metrics.go:303: [warning] [EXPENSIVE_QUERY] select * from mysql.tables_priv
2017/02/07 00:41:09 metrics.go:303: [warning] [EXPENSIVE_QUERY] select * from mysql.columns_priv 测试机器一共有4台，3台pb，tikv(16c 32g 1t ssd)，1台tidb（8c 16g），出现故障时我观察了pb和kitv的机器，内存、io、cpu其实都不高，但是tidbcpu很高，所以我不确定是不是tidb的问题 好的    Please answer these questions before submitting your issue. Thanks!

1. What version of Go are you using (`go version`)?

1.6.3
2. What operating system and processor architecture are you using (`go env`)?
![image](https://cloud.githubusercontent.com/assets/659311/20142447/bbeb258e-a6cf-11e6-97e7-d975bdaa6748.png)


3. What did you do?
If possible, provide a recipe for reproducing the error.
A complete runnable program is good.
select count(*) as accumulate_count, sum(payAmount) as accumulate_payamount, booktime from order_master where bookTime > str_to_date(concat(@START_DAY,@check_time_start, '%Y-%m-%d%H'));

4. What did you expect to see?
can run

5. What did you see instead?
ERROR 1105 (HY000): line 0 column 133 near "concat(@START_DAY,@check_time_start, '%!Y(MISSING)-%!m(MISSING)-%!d(MISSING)%!H(MISSING)'))"


Looks like concat or str_to_date func not 100% same behavior as mySQL?

  FYI, it is just a question. or i need some settings ? currently just using default settings. will try, thanks
  Please answer these questions before submitting your issue. Thanks!

1. What version of Go are you using (`go version`)?
1.6.3

2. What operating system and processor architecture are you using (`go env`)?
![image](https://cloud.githubusercontent.com/assets/659311/20099741/26fd38e8-a5f5-11e6-8a22-55cfbc7d4337.png)


3. What did you do?
If possible, provide a recipe for reproducing the error.
A complete runnable program is good.

source a sql file in mysql client

4. What did you expect to see?
import finish

5. What did you see instead?
program exited after a few hours
![image](https://cloud.githubusercontent.com/assets/659311/20099710/f88bb034-a5f4-11e6-991c-dad89ee3194b.png)
 Just a "killed", no other log
 in tidbserver log, like below, then killed

<with some private information, will deliver u some other way>

at myloader, it is like this

![image](https://cloud.githubusercontent.com/assets/659311/20125440/7b7b4428-a668-11e6-94e6-859d63c7049b.png)

The tables got something, but not all imported.

![image](https://cloud.githubusercontent.com/assets/659311/20125465/9ade77d6-a668-11e6-8b00-dba9031bec69.png)

I guess the count(*) so long due to im importing.

thanks
Keith
 some more log

![image](https://cloud.githubusercontent.com/assets/659311/20139348/99e52368-a6c0-11e6-91b1-a26d068145e2.png)
 2G 14G \* 3
 How to check? i only use all default value
  LGTM
  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1919) <br/>All committers have signed the CLA.
  Is this fixed now that #1929 is merged? I need this for a project and I'm just unsure since it's still open haha.  Can the tidb run as production? Thanks.
 Thanks, What time the GA version will release?
 Also want to know the time of GA version.  LGTM
  For #1890 
Exactly the same behavior as https://github.com/pingcap/tikv/pull/1245. Print the version and timestamp (without using logger) then exit.
 [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1896) <br/>All committers have signed the CLA.
  When importing data into TiDB we want to be sure the data is correct. A convenient command in MySQL is CHECKSUM TABLE <tablename> and this command is not currently supported by TiDB.

Adding it would make it easy to confirm if the data loaded in from an external source matches or not.

Example I did something like:

`$ ssh mysqlhost sudo mysqldump test SomeTable | mysql -h tidbhost -P 4000 -u root -D test`

MySQL 5.6:

```
root@mysqlhost [test]> checksum table SomeTable;
+-----------+------------+
| Table     | Checksum   |
+-----------+------------+
| SomeTable | 2867272629 |
+-----------+------------+
1 row in set (0.01 sec)
```

TiDB:

```
root@tidbhost [test]> checksum table SomeTable;
ERROR 1105 (HY000): line 0 column 8 near " table SomeTable"
root@tidbhost [test]> 
```

So providing some sort of CHECKSUM table command would be great.
  I think we can support `SHOW MASTER STATUS` in order to make TiDB more friendly to be synchronized.

Use scenario:
While we deploy TiDB-Binlog,  we can do like blew:
1. deploy pump and cistern component to persist Binlog.
2. use  [myDumper](https://github.com/maxbube/mydumper) to dump TiDB data, schema, meta to file at one time point
3. read metadata file to get dump point **max ts over all TiDBs**, then use the ts start drainer to sync binlog to target db.

[[myDumper](https://github.com/maxbube/mydumper)] How to dump data?

```
1. Connect db
2. FLUSH TABLES WITH READ LOCK
3. START TRANSACTION /!40108 WITH CONSISTENT SNAPSHOT
4. SHOW MASTER STATUS
5. Create child threads
       [child thread]
      1. Connect to db
      2. SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE
      3. START TRANSACTION /!40108 WITH CONSISTENT SNAPSHOT /
      4. Pop tasks from queue to execute
6. Push tasks to  queue
7. UNLOCK TABLES / FTWRL 
```

[`SHOW MASTER STATUS`]

```
+------------------+----------+--------------+------------------+-------------------+
| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB  | Executed_Gtid_Set |
+------------------+----------+--------------+------------------+-------------------+
| mysql-bin.000002 |      120 |              |                  |                              |
+------------------+----------+--------------+------------------+-------------------+
```

 we can make the file to constant like `TiDB-Binlog`, and the Position to Ts

@shenli @coocood @iamxy 
 It's hard to make TiDB support it, we will get the max ts from cistern or pump after master service stop for some time while we switch Master / Slave or others.
  Please answer these questions before submitting your issue. Thanks!
1. What version of Go are you using (`go version`)?
   N/A
2. What operating system and processor architecture are you using (`go env`)?
   N/A
3. What did you do?
   If possible, provide a recipe for reproducing the error.
   A complete runnable program is good.

Try to figure out the pre-compiled binary's version and UTC Build Time without running it (or run it with -h --help -v --version that widely used in Linux to identify an binary's version)
1. What did you expect to see?

Run with some flag (typically -v or --version) will print the Git Commit Hash and UTC Build Time then exit.
1. What did you see instead?

Can only get the version and timestamp by running it (and it's hard to find out version&timestamp in a lot of logs).

And it's better to see an timestamp file in the pre-compiled binary (http://download.pingcap.org/tidb-latest-linux-amd64.tar.gz).
 #1896 Here it is～
  1. What version of Go are you using (`go version`)?
   
   ```
   > go version
   go version go1.7.3 linux/amd64
   ```
2. What operating system and processor architecture are you using (`go env`)?
   
   ```
   > go env
   GOARCH="amd64"
   GOBIN=""
   GOEXE=""
   GOHOSTARCH="amd64"
   GOHOSTOS="linux"
   GOOS="linux"
   GOPATH="/home/o/dataBase/tidb"
   GORACE=""
   GOROOT="/usr/lib/go"
   GOTOOLDIR="/usr/lib/go/pkg/tool/linux_amd64"
   CC="gcc"
   GOGCCFLAGS="-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build937879331=/tmp/go-build -gno-record-gcc-switches"
   CXX="g++"
   CGO_ENABLED="1"
   ```
3. What did you do?
   
   Nothing, how to build TiDB is all I want to konw.
   For now, still no idea.
4. What did you expect to see?
   
   A brief instruction of how to build it.(For people who are less familiar with golang.)
  LGTM
  drop foreign key that does not exist will cause this ddl job block ddl work
 [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1874) <br/>All committers have signed the CLA.
 Same as I thought, I intended to use checkJobCancelled. I will add the test later. 
Are you a girl? Me too ;)
 Thanks @ngaut
  LGTM
  LGTM
  I think we can add the associated tableInfo into dll job (addColumn,dropColumn,addIndex, dropIndex) before we place it into history ddl job queue.

The cause is  TiDB-Binlog need to compute the new schema base on ddl job.
I don't think it can guaranteed completely correct, so load from TiDB maybe is the best way.

@shenli @coocood @iamxy 
 I think I should add that we need tbInfo in CreateTable, AlterTable(Truncate Table), DBInfo in CreateDB.  
In conclusion, All operations that change tableinfo are required to carry tbInfo.
@zimulala 
  Can you document/define the most basic configurations, i.e. with 2, 3 or 4 servers?

Also, will you support rpi3 ARM64 nodes?

rpi3 + 1TB disk could be great for additional nodes

http://wdlabs.wd.com/products/wd-pidrive-1tb-kit/
  LGTM
  LGTM
  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1813) <br/>All committers have signed the CLA.
  ENV:
go version: `go1.6.1 linux/amd64`

go env:

```
GOARCH="amd64"
GOBIN=""
GOEXE=""
GOHOSTARCH="amd64"
GOHOSTOS="linux"
GOOS="linux"
GOPATH="/home/xuruiliang/.go"
GORACE=""
GOROOT="/usr/local/go"
GOTOOLDIR="/usr/local/go/pkg/tool/linux_amd64"
GO15VENDOREXPERIMENT="1"
CC="gcc"
GOGCCFLAGS="-fPIC -m64 -pthread -fmessage-length=0"
CXX="g++"
CGO_ENABLED="1"
```

Problem:
I use sql to search data like '%{', an error happened like that `ERROR 1105 (HY000): other error: unknown error Codec(Encoding(Utf8Error { valid_up_to: 253 }))`

SQL: `select * from contents where data like "{%";`, Data like that:  `{"__plat":"pc_web","content":"现在我发现这些八卦记者真能忽悠"}`
 I can reproduce this error. I use gorm as orm, db.update for insert data. `select * from contents limit 10;` can show the data. the result as

```
|  1 | 33739414 |  55666 | 1475990130 | {"__plat":"android","content":"那只浣熊怎么弄的"}
```

but I use `select * from contents where data like "{%";` what report error.
mysql uri is `root:@tcp(127.0.0.1:4000)/test?charset=utf8&parseTime=True&loc=Local` 
 The input data is from kafka.
 The data is ` `data` varchar(255) DEFAULT NULL` in tidb.
 I can output data in my go progrma. My terminal's encoding is utf8. So I think the data is utf8.
 Some data is about my company's privacy? Can you offer me your email address. I can give you some data by email.
 OK.
  Will you have  fulltext search support plan in future
  [how to easily install a secure Kubernetes cluster](http://kubernetes.io/docs/getting-started-guides/kubeadm/) . The new tool kubeadm in Kubernetes 1.4.
  The first `select count() from t2` encounter many locks left by the last `INSERT INTO t2 SELECT * FROM t2`, and need wait the locks timeout.
 I encounter the same problem. I observe the memory usage and find when the last `insert into ...` is running, the tidb progress used over 90% memory of the machine and then was killed by kernel. I guess it is because the memory used by the previous sqls has not been released by gc modular yet.

```
mysql> insert into t1 select count(*) from t1 limit 4000000;
ERROR 1105 (HY000): Column count 2 doesn't match value count 1
mysql> insert into t1 select * from t1 limit 4000000;
Query OK, 4000000 rows affected (1 min 16.01 sec)

mysql> insert into t1 select * from t1 limit 4000000;
Query OK, 4000000 rows affected (2 min 49.39 sec)

mysql> mysql> insert into t1 select * from t1 limit 4000000;
Query OK, 4000000 rows affected (1 min 19.46 sec)

mysql> insert into t1 select * from t1 limit 4000000;
Query OK, 4000000 rows affected (1 min 49.41 sec)

mysql> insert into t1 select * from t1 limit 4000000;
ERROR 2013 (HY000): Lost connection to MySQL server during query
```
 I also met the problem when I load over 10 million lines of data.
I tried twice, first time, It loaded 11480000 lines, second time, It loaded 7980000 lines.

mysql> load data local infile 'path_to_data' into table t_table;   
ERROR 2013 (HY000): Lost connection to MySQL server during query

mysql> select count(*) from t_table;
+----------+
| count(*) |
+----------+
|  7980000 |
+----------+ @shenli 
mysql> select count(*) from t_table;
+----------+
| count(*) |
+----------+
|  2740000 |
+----------+

2017/02/15 12:15:18 conn.go:645: [error] load data rollback failed: [kv:8]invalid transaction
2017/02/15 12:15:18 conn.go:342: [error] /home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:77: [server:3]invalid sequence 123 != 0
/home/jenkins/workspace/TIDB_POST_COMMIT_FLOW/go/src/github.com/pingcap/tidb/server/packetio.go:94:  @shenli have sent to u, I think it is due to GC which caused out of memory.  Please answer these questions before submitting your issue. Thanks!
1. What version of Go are you using (`go version`)?
     go version go1.7.1 linux/amd64
2. What operating system and processor architecture are you using (`go env`)?
   [root@l20-8-65 ~]# cat /etc/redhat-release
   CentOS release 6.7 (Final)
3. What did you do?
   When the deployment of the TiDB server was done . I connect to the server using default username root like this : 
   
   mysql -uroot -h10.20.8.xxx  -P4000 
   // create a user 
   mysql> CREATE USER 'ruiaylin'@'%' IDENTIFIED BY 'ruiaylin'
   -> ;
   Query OK, 1 row affected (0.01 sec)
   
   // grant the privileges 
   mysql> GRANT ALL ON _._ TO  'ruiaylin'@'%'  ;
   Query OK, 1 row affected (0.01 sec)

The Commands are executed successfully . But i can not connect to the server using the username i have create before . 

[root@l20-8-65 ~]# mysql -uruiaylin -pruiaylin -h10.20.8.6xxx -P4000
mysql: [Warning] Using a password on the command line interface can be insecure.
ERROR 1105 (HY000): ERROR 1045 (28000): Access denied for user 'ruiaylin'@'10.20.8.65' (using password: Yes)

TiDB's log show that : 

[root@l20-8-65 ~]# mysql -uruiaylin -pruiaylin -h10.20.8.64 -P4000
mysql: [Warning] Using a password on the command line interface can be insecure.
ERROR 1105 (HY000): ERROR 1045 (28000): Access denied for user 'ruiaylin'@'10.20.8.65' (using password: Yes)
1. What did you expect to see?

I  want to know why ? 
Is this a Bug? 
  Please answer these questions before submitting your issue. Thanks!
1. What version of Go are you using (`go version`)?
2. What operating system and processor architecture are you using (`go env`)?
3. What did you do?
   If possible, provide a recipe for reproducing the error.
   A complete runnable program is good.
4. What did you expect to see?
5. What did you see instead?

```
# network
net="ti_database"
docker network rm ${net}
docker network create --driver bridge ${net}

# data storage
docker volume create --name ti-storage

# PD
docker run --net ${net} -d --name pd1 \
  -v /etc/localtime:/etc/localtime:ro \
  -v ti-storage:/tidata \
  pingcap/pd \
  --cluster-id=1 \
  --name="pd1" \
  --data-dir="/tidata/pd1" \
  --client-urls="http://0.0.0.0:2379" \
  --advertise-client-urls="http://pd1:2379" \
  --peer-urls="http://0.0.0.0:2380" \
  --advertise-peer-urls="http://pd1:2380" \
  --initial-cluster="pd1=http://pd1:2380"


# TiKV
docker run --net ${net} -d --name tikv1 \
  -v /etc/localtime:/etc/localtime:ro \
  -v ti-storage:/tidata \
  pingcap/tikv \
  --addr="0.0.0.0:20160" \
  --advertise-addr="tikv1:20160" \
  --store="/tidata/tikv1" \
  --dsn=raftkv \
  --pd="pd1:2379" \
  --cluster-id=1


# TiDB
docker run --net ${net} -d --name tidb \
  -p 4000:4000 \
  -v /etc/localtime:/etc/localtime:ro \
  pingcap/tidb \
  --store=tikv \
  --path="pd1:2379?cluster=1"
```

Start PD and TiKV, the log of PD:

```
2016/09/27 01:37:57 balancer.go:352: [warning] find no store to add peer for region id:2 start_key:"" end_key:"" region_epoch:<conf_ver:1 version:1 > peers:<id:3 store_id:1 >
```

Start TiDB, the log of TiDB:

```
2016/09/27 01:39:27 backoff.go:158: [warning] stale_epoch:<> , retry later(totalSleep 7231ms, maxSleep 10000ms)
2016/09/27 01:39:27 backoff.go:158: [warning] send tikv request error: EOF, ctx: region_id:2 region_epoch:<conf_ver:1 version:1 > peer:<id:3 store_id:1 > , try next peer later, retry later(totalSleep 7496ms, maxSleep 10000ms)

2016/09/27 01:39:41 backoff.go:158: [warning] stale_epoch:<> , retry later(totalSleep 196ms, maxSleep 10000ms)
2016/09/27 01:39:41 backoff.go:158: [warning] stale_epoch:<> , retry later(totalSleep 459ms, maxSleep 10000ms)
2016/09/27 01:39:41 backoff.go:158: [warning] stale_epoch:<> , retry later(totalSleep 10054ms, maxSleep 10000ms)
2016/09/27 01:39:41 txn.go:160: [warning] [kv] Rollback txn 386646768609918977
2016/09/27 01:39:41 domain.go:205: [error] [ddl] load schema err /go/src/github.com/pingcap/tidb/store/tikv/backoff.go:161: backoffer.maxSleep 10000ms is exceeded, errors: [send tikv request error: EOF, ctx: region_id:2 region_epoch:<conf_ver:1 version:1 > peer:<id:3 store_id:1 > , try next peer later stale_epoch:<>  send tikv request error: EOF, ctx: region_id:2 region_epoch:<conf_ver:1 version:1 > peer:<id:3 store_id:1 > , try next peer later stale_epoch:<>  send tikv request error: EOF, ctx: region_id:2 region_epoch:<conf_ver:1 version:1 > peer:<id:3 store_id:1 > , try next peer later stale_epoch:<>  send tikv request error: EOF, ctx: region_id:2 region_epoch:<conf_ver:1 version:1 > peer:<id:3 store_id:1 > , try next peer later stale_epoch:<>  send tikv request error: EOF, ctx: region_id:2 region_epoch:<conf_ver:1 version:1 > peer:<id:3 store_id:1 > , try next peer later stale_epoch:<>  send tikv request error: EOF, ctx: region_id:2 region_epoch:<conf_ver:1 version:1 > peer:<id:3 store_id:1 > , try next peer later stale_epoch:<>  send tikv request error: EOF, ctx: region_id:2 region_epoch:<conf_ver:1 version:1 > peer:<id:3 store_id:1 > , try next peer later stale_epoch:<>  send tikv request error: EOF, ctx: region_id:2 region_epoch:<conf_ver:1 version:1 > peer:<id:3 store_id:1 > , try next peer later stale_epoch:<> ]
/go/src/github.com/pingcap/tidb/store/tikv/backoff.go:162: [try again later]
/go/src/github.com/pingcap/tidb/store/tikv/snapshot.go:203:
/go/src/github.com/pingcap/tidb/store/tikv/snapshot.go:175:
/go/src/github.com/pingcap/tidb/kv/union_store.go:158:
/go/src/github.com/pingcap/tidb/store/tikv/txn.go:65:
/go/src/github.com/pingcap/tidb/structure/string.go:40:
/go/src/github.com/pingcap/tidb/structure/string.go:47:
/go/src/github.com/pingcap/tidb/domain/domain.go:56:
/go/src/github.com/pingcap/tidb/kv/txn.go:46: , retry again
```
 @shenli 

```
docker logs tikv1
2016-09-27 02:27:26,086 tikv-server.rs:650 - INFO  - Start listening on 0.0.0.0:20160...
2016-09-27 02:27:26,087 tikv-server.rs:117 - INFO  - server.notify-capacity, use default Some(40960)
2016-09-27 02:27:26,088 tikv-server.rs:117 - INFO  - server.messages-per-tick, use default Some(4096)
2016-09-27 02:27:26,088 tikv-server.rs:117 - INFO  - server.capacity, use default Some(0)
2016-09-27 02:27:26,088 tikv-server.rs:117 - INFO  - server.send-buffer-size, use default Some(131072)
2016-09-27 02:27:26,089 tikv-server.rs:117 - INFO  - server.recv-buffer-size, use default Some(131072)
2016-09-27 02:27:26,089 tikv-server.rs:117 - INFO  - raftstore.notify-capacity, use default Some(40960)
2016-09-27 02:27:26,089 tikv-server.rs:117 - INFO  - raftstore.messages-per-tick, use default Some(4096)
2016-09-27 02:27:26,089 tikv-server.rs:117 - INFO  - raftstore.region-split-size, use default Some(67108864)
2016-09-27 02:27:26,089 tikv-server.rs:117 - INFO  - raftstore.region-max-size, use default Some(83886080)
2016-09-27 02:27:26,089 tikv-server.rs:117 - INFO  - raftstore.region-split-check-diff, use default Some(8388608)
2016-09-27 02:27:26,089 tikv-server.rs:117 - INFO  - raftstore.max-peer-down-duration, use default Some(300000)
2016-09-27 02:27:26,089 tikv-server.rs:117 - INFO  - raftstore.pd-heartbeat-tick-interval, use default Some(5000)
2016-09-27 02:27:26,089 tikv-server.rs:117 - INFO  - raftstore.pd-store-heartbeat-tick-interval, use default Some(10000)
2016-09-27 02:27:26,089 tikv-server.rs:117 - INFO  - storage.scheduler-notify-capacity, use default Some(10240)
2016-09-27 02:27:26,089 tikv-server.rs:117 - INFO  - storage.scheduler-messages-per-tick, use default Some(1024)
2016-09-27 02:27:26,089 tikv-server.rs:117 - INFO  - storage.scheduler-concurrency, use default Some(1024)
2016-09-27 02:27:26,089 tikv-server.rs:117 - INFO  - storage.scheduler-worker-pool-size, use default Some(4)
2016-09-27 02:27:26,192 mod.rs:163 - INFO  - starting working thread: store address resolve worker
2016-09-27 02:27:26,193 tikv-server.rs:117 - INFO  - rocksdb.block-based-table.block-size, use default Some(65536)
2016-09-27 02:27:26,193 tikv-server.rs:117 - INFO  - rocksdb.block-based-table.block-cache-size, use default Some(1073741824)
2016-09-27 02:27:26,194 tikv-server.rs:117 - INFO  - rocksdb.block-based-table.bloom-filter-bits-per-key, use default Some(10)
2016-09-27 02:27:26,194 tikv-server.rs:80 - INFO  - rocksdb.compression_per_level, use default Some("lz4:lz4:lz4:lz4:lz4:lz4:lz4")
2016-09-27 02:27:26,195 tikv-server.rs:117 - INFO  - rocksdb.write-buffer-size, use default Some(67108864)
2016-09-27 02:27:26,195 tikv-server.rs:117 - INFO  - rocksdb.max-write-buffer-number, use default Some(5)
2016-09-27 02:27:26,196 tikv-server.rs:117 - INFO  - rocksdb.min-write-buffer-number-to-merge, use default Some(1)
2016-09-27 02:27:26,196 tikv-server.rs:117 - INFO  - rocksdb.max-background-compactions, use default Some(4)
2016-09-27 02:27:26,196 tikv-server.rs:117 - INFO  - rocksdb.max-bytes-for-level-base, use default Some(67108864)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.target-file-size-base, use default Some(16777216)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.level0-slowdown-writes-trigger, use default Some(12)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.level0-stop-writes-trigger, use default Some(16)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.block-based-table.block-size, use default Some(65536)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.block-based-table.block-cache-size, use default Some(1073741824)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.block-based-table.bloom-filter-bits-per-key, use default Some(10)
2016-09-27 02:27:26,197 tikv-server.rs:80 - INFO  - rocksdb.compression_per_level, use default Some("lz4:lz4:lz4:lz4:lz4:lz4:lz4")
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.write-buffer-size, use default Some(67108864)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.max-write-buffer-number, use default Some(5)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.min-write-buffer-number-to-merge, use default Some(1)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.max-background-compactions, use default Some(4)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.max-bytes-for-level-base, use default Some(67108864)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.target-file-size-base, use default Some(16777216)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.level0-slowdown-writes-trigger, use default Some(12)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.level0-stop-writes-trigger, use default Some(16)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.block-based-table.block-size, use default Some(65536)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.block-based-table.block-cache-size, use default Some(1073741824)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.block-based-table.bloom-filter-bits-per-key, use default Some(10)
2016-09-27 02:27:26,197 tikv-server.rs:80 - INFO  - rocksdb.compression_per_level, use default Some("lz4:lz4:lz4:lz4:lz4:lz4:lz4")
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.write-buffer-size, use default Some(67108864)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.max-write-buffer-number, use default Some(5)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.min-write-buffer-number-to-merge, use default Some(1)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.max-background-compactions, use default Some(4)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.max-bytes-for-level-base, use default Some(67108864)
2016-09-27 02:27:26,197 tikv-server.rs:117 - INFO  - rocksdb.target-file-size-base, use default Some(16777216)
2016-09-27 02:27:26,198 tikv-server.rs:117 - INFO  - rocksdb.level0-slowdown-writes-trigger, use default Some(12)
2016-09-27 02:27:26,198 tikv-server.rs:117 - INFO  - rocksdb.level0-stop-writes-trigger, use default Some(16)
2016-09-27 02:27:26,200 rocksdb.rs:64 - WARN  - open rocksdb fail: Invalid argument: /tidata/tikv1/db: does not exist (create_if_missing is false)
2016-09-27 02:27:26,259 client.rs:115 - INFO  - get pd leader http://pd1:2379
2016-09-27 02:27:26,266 node.rs:162 - INFO  - alloc first region id 2 for cluster 1, store 1
2016-09-27 02:27:26,266 node.rs:167 - INFO  - alloc first peer id 3 for first region 2
2016-09-27 02:27:26,271 node.rs:186 - INFO  - bootstrap cluster 1 ok
2016-09-27 02:27:26,272 node.rs:201 - INFO  - start raft store 1 thread
2016-09-27 02:27:26,273 peer.rs:180 - INFO  - [region 2] create peer with id 3
2016-09-27 02:27:26,279 raft.rs:582 - INFO  - [region 2] 3 became follower at term 5
2016-09-27 02:27:26,279 raft.rs:265 - INFO  - [region 2] 3 newRaft [peers: [3], term: 5, commit: 5, applied: 5, last_index: 5, last_term: 5]
2016-09-27 02:27:26,280 raft.rs:689 - INFO  - [region 2] 3 is starting a new election at term 5
2016-09-27 02:27:26,280 raft.rs:594 - INFO  - [region 2] 3 became candidate at term 6
2016-09-27 02:27:26,280 raft.rs:656 - INFO  - [region 2] 3 received vote from 3 at term 6
2016-09-27 02:27:26,281 raft.rs:618 - INFO  - [region 2] 3 became leader at term 6
2016-09-27 02:27:26,281 mod.rs:163 - INFO  - starting working thread: split check worker
2016-09-27 02:27:26,282 mod.rs:163 - INFO  - starting working thread: snapshot worker
2016-09-27 02:27:26,283 mod.rs:163 - INFO  - starting working thread: compact worker
2016-09-27 02:27:26,287 mod.rs:163 - INFO  - starting working thread: pd worker
2016-09-27 02:27:26,295 mod.rs:233 - INFO  - storage RaftKv started.
2016-09-27 02:27:26,295 tikv-server.rs:569 - INFO  - tikv server config: Config { cluster_id: 1, addr: "0.0.0.0:20160", advertise_addr: "tikv1:20160", notify_capacity: 40960, messages_per_tick: 4096, send_buffer_size: 131072, recv_buffer_size: 131072, storage: Config { path: "/tidata/tikv1", sched_notify_capacity: 10240, sched_msg_per_tick: 1024, sched_concurrency: 1024, sched_worker_pool_size: 4 }, raft_store: Config { capacity: 18446744073709551615, raft_base_tick_interval: 100, raft_heartbeat_ticks: 3, raft_election_timeout_ticks: 15, raft_max_size_per_msg: 1048576, raft_max_inflight_msgs: 256, raft_log_gc_tick_interval: 5000, raft_log_gc_threshold: 50, raft_log_gc_limit: 100000, split_region_check_tick_interval: 10000, region_max_size: 83886080, region_split_size: 67108864, region_check_size_diff: 8388608, pd_heartbeat_tick_interval: 5000, pd_store_heartbeat_tick_interval: 10000, snap_mgr_gc_tick_interval: 60000, snap_gc_timeout: 600, notify_capacity: 40960, messages_per_tick: 4096, max_peer_down_duration: Duration { secs: 300, nanos: 0 } } }
2016-09-27 02:27:26,298 tikv-server.rs:80 - INFO  - metric.addr, use default Some("")
2016-09-27 02:27:26,298 tikv-server.rs:80 - INFO  - metric.prefix, use default Some("tikv")
2016-09-27 02:27:26,298 tikv-server.rs:572 - INFO  - start storage
2016-09-27 02:27:26,299 mod.rs:163 - INFO  - starting working thread: end-point-worker
2016-09-27 02:27:26,300 mod.rs:163 - INFO  - starting working thread: snap-handler
```
 the log above(`2016-09-27 02:27:26`) is start PD then start TiKV， the TiDB is not running

the previois log(`2016/09/27 01:39:41`) is start PD->TiKV->TiDB. But the TiDB not worked, so I destroied the container.

@siddontang 
 I process some new logs using following steps:
PD -> TiKV -> TiDB
then stop them:
TiDB - > TiKV -> PD

@shenli 

[log.zip](https://github.com/pingcap/tidb/files/494473/log.zip)
 @siddontang that's strange, I pull from pingcap/*:latest. 
I will using alpine and try.

Yes, alpine image works. But an error log in TiDB:

```
[error] Syntax error: SELECT VARIABLE_VALUE FROM mysql.tidb WHERE VARIABLE_NAME="bootstrapped"
2016/09/27 06:50:17 session.go:464: [error] Error occurs at [schema:1146]table mysql.tidb does not exist.
```
 @siddontang  you mean using latest tag? the answer is NO. I tried `docker restart`, but still not work.

By the way. How can I set passwd for TiDB, I create a new user with passwd. But can not login in:

```
CREATE USER 'elvizlai'@'%' IDENTIFIED BY PASSWORD 'cba321';
GRANT ALL PRIVILEGES ON *.* TO 'elvizlai'@'%';
```

mysql -h 138.68.xxx.xxx -P 4000 -u elvizlai -D mysql -p

the tidb log:
handshake error ERROR 1045 (28000): Access denied for user 'elvizlai'@'47.90.xxx.xxx' (using password: Yes)

**************************\* 2. row ***************************
            Host: %
            User: elvizlai
        Password: 4b267316ed17ff850806c9ece954c914b898cad0
     Select_priv: Y
     Insert_priv: Y
     Update_priv: Y
     Delete_priv: Y
     Create_priv: Y
       Drop_priv: Y
      Grant_priv: Y
      Alter_priv: Y
    Show_db_priv: Y
    Execute_priv: Y
      Index_priv: Y
Create_user_priv: Y
 @shenli  user created succeed. But can not login. Any docs?
 @shenli  As I mentioned before. I know how to connect to msql.

Did you tried that cmd?
  开始没有指定HOST地址，显示的是0.0.0.0:4000，本机可以连上服务，其它机器连不了
指定IP地址xx.xx.89.69后，其它机器还是没法通过MYSQL协议连上来，这是为何呢。
谢谢
[root@iZ256zv7z3dZ bin]# ./tidb-server -host xx.xx.89.69
2016/09/09 00:35:57 printer.go:30: [info] Welcome to the TiDB.
2016/09/09 00:35:57 printer.go:31: [info] Version:
2016/09/09 00:35:57 printer.go:32: [info] Git Commit Hash: d6f386926143d716c858111ba8c2691b303fea7a
2016/09/09 00:35:57 printer.go:33: [info] UTC Build Time:  2016-09-08 04:02:28
2016/09/09 00:35:57 kv.go:296: [info] [kv] New store /tmp/tidb 
2016/09/09 00:35:57 domain.go:94: [info] [ddl] loadInfoSchema 9
2016/09/09 00:35:57 domain.go:307: [info] [ddl] SetValidity, original:false current:true
2016/09/09 00:35:57 session.go:618: [info] RollbackTxn for session close. 
2016/09/09 00:35:57 server.go:146: [info] Server run MySql Protocol Listen at [xx.xx.89.69:4000]
2016/09/09 00:35:57 systime_mon.go:11: [info] start system time monitor 
2016/09/09 00:35:57 server.go:232: [info] Listening on :10080 for status and metrics report.
  It seems some interface names are prefixed with `I`, like `IContext`, which is not popular in Golang.
Wondering if that's the naming convention adopted by the project, since it's also noticed that some other interfaces are not named alike.
  Please answer these questions before submitting your issue. Thanks!
1. What version of Go are you using (`go version`)?
   `go version go1.7 linux/amd64`
2. What operating system and processor architecture are you using (`go env`)?
   arch linux 

``` GOARCH="amd64"
GOBIN=""
GOEXE=""
GOHOSTARCH="amd64"
GOHOSTOS="linux"
GOOS="linux"
GOPATH="/home/t/src/go"
GORACE=""
GOROOT="/usr/lib/go"
GOTOOLDIR="/usr/lib/go/pkg/tool/linux_amd64"
CC="gcc"
GOGCCFLAGS="-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build666854116=/tmp/go-build -gno-record-gcc-switches"
CXX="g++"
CGO_ENABLED="1"
```
1. What did you do?
   1. start 6x tikv
   2. start 1x pd
   3. start 1x tidb
   4. `CREATE DATABASE t1; USE t1; CREATE TABLE example (id integer, data varchar(32))`
   5. insert a few million records
   6. kill pd
   7. kill leader of region 2
   8. wait 10 seconds
   9. start pd
   10. wait 6 minutes for cluster to reconfigure
   11. run more inserts, this works fine, `SELECT COUNT(1) from example` works as expected
   12. `DROP DATABASE t1` hangs, progress unclear
   13. `CREATE DATABASE t2` hangs, progress unclear
   14. run more inserts, this works fine, `SELECT COUNT(1) from example` works as expected
2. What did you expect to see?
   success
3. What did you see instead?
   hangs

interesting pd error `cluster is not bootstrapped` after starting

```
2016/08/31 21:02:33 server.go:270: [warning] close conn failed - close tcp 127.0.0.1:2379->127.0.0.1:46540: use of closed network connection
2016/08/31 21:02:33 server.go:270: [warning] close conn failed - close tcp 127.0.0.1:2379->127.0.0.1:46614: use of closed network connection
2016/08/31 21:02:33 tso.go:154: [error] we haven't synced timestamp ok, wait and retry, retry count 0
2016/08/31 21:02:33 tso.go:154: [error] we haven't synced timestamp ok, wait and retry, retry count 0
2016/08/31 21:02:33 tso.go:154: [error] we haven't synced timestamp ok, wait and retry, retry count 0
2016/08/31 21:02:33 tso.go:154: [error] we haven't synced timestamp ok, wait and retry, retry count 0
2016/08/31 21:02:33 tso.go:154: [error] we haven't synced timestamp ok, wait and retry, retry count 0
2016/08/31 21:02:33 tso.go:154: [error] we haven't synced timestamp ok, wait and retry, retry count 0
2016/08/31 21:02:33 conn.go:100: [error] handle request header:<uuid:"\336w\276$\356tN\212\266\275u\314\320\240L\371" cluster_id:1 > cmd_type:StoreHeartbeat store_heartbeat:<stats:<store_id:8
 capacity:8346308608 available:3963830272 > >  err /home/t/src/go/src/github.com/pingcap/pd/server/cluster.go:32: cluster is not bootstrapped
/home/t/src/go/src/github.com/pingcap/pd/server/command.go:107: 
/home/t/src/go/src/github.com/pingcap/pd/server/command.go:256: 
2016/08/31 21:02:33 conn.go:100: [error] handle request header:<uuid:"\336w\276$\356tN\212\266\275u\314\320\240L\371" cluster_id:1 > cmd_type:StoreHeartbeat store_heartbeat:<stats:<store_id:8
 capacity:8346308608 available:3963830272 > >  err /home/t/src/go/src/github.com/pingcap/pd/server/cluster.go:32: cluster is not bootstrapped
/home/t/src/go/src/github.com/pingcap/pd/server/command.go:107: 
/home/t/src/go/src/github.com/pingcap/pd/server/command.go:256: 
2016/08/31 21:02:33 conn.go:72: [error] read request message err EOF
2016/08/31 21:02:33 cluster.go:293: [info] cache all 8 stores cost 213.329µs
2016/08/31 21:02:33 cluster.go:329: [info] cache all 2 regions cost 446.793µs
2016/08/31 21:02:33 conn.go:72: [error] read request message err EOF
2016/08/31 21:02:33 conn.go:72: [error] read request message err EOF
2016/08/31 21:02:33 conn.go:72: [error] read request message err EOF
```
 upon restarting tidb, tidb-server logs 
`2016/08/31 21:35:28 ddl_worker.go:335: [error] [ddl] handle ddl job err /home/t/src/go/src/github.com/pingcap/tidb/store/tikv/snapshot.go:244: tikv restarts txn: Txn(Mvcc(WriteConflict))
/home/t/src/go/src/github.com/pingcap/tidb/store/tikv/snapshot.go:246: [try again later]
/home/t/src/go/src/github.com/pingcap/tidb/store/tikv/txn_committer.go:214: 
/home/t/src/go/src/github.com/pingcap/tidb/store/tikv/txn_committer.go:139: 
/home/t/src/go/src/github.com/pingcap/tidb/store/tikv/txn_committer.go:115: 
/home/t/src/go/src/github.com/pingcap/tidb/store/tikv/txn_committer.go:344: 
/home/t/src/go/src/github.com/pingcap/tidb/store/tikv/txn.go:119: 
/home/t/src/go/src/github.com/pingcap/tidb/kv/txn.go:57: 
/home/t/src/go/src/github.com/pingcap/tidb/ddl/ddl_worker.go:280:`
and after a few seconds allows schema updates, resolving the inability to modify schemata
 Forgot to mention, tikv/tidb/pd all using master from the date of submission. @shenli yeah, they are all on the same disk but using different storage directories. let me know if there are issues reproducing this or if specific logs would be interesting
    If the current version can be used in the production environment？ is there any plan for 1.0?
  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1654) <br/>All committers have signed the CLA.
  Please answer these questions before submitting your issue. Thanks!
1. What version of Go are you using (`go version`)?
   go version go1.6.3 linux/amd64
2. What operating system and processor architecture are you using (`go env`)?
   GOARCH="amd64"
   GOBIN=""
   GOEXE=""
   GOHOSTARCH="amd64"
   GOHOSTOS="linux"
   GOOS="linux"
   GOPATH="/root/go"
   GORACE=""
   GOROOT="/usr/local/go"
   GOTOOLDIR="/usr/local/go/pkg/tool/linux_amd64"
   GO15VENDOREXPERIMENT="1"
   CC="gcc"
   GOGCCFLAGS="-fPIC -m64 -pthread -fmessage-length=0"
   CXX="g++"
   CGO_ENABLED="1"
3. What did you do?
   I follow https://github.com/pingcap/docs/blob/master/op-guide/clustering.md to setup cluster with 3 nodes.
4. What did you expect to see?
5. What did you see instead?
   When I run **tidb-server --store=tikv --path="10.202.91.1:2379,10.202.91.2:2379,10.202.91.3:2379?cluster=1"** it will failed:
   `2016/08/26 15:26:31 rpc_worker.go:115: [info] [pd] connect to pd server http://10.202.91.2:2379
   2016/08/26 15:26:31 rpc_worker.go:118: [warning] [pd] failed connect pd server: dial tcp: too many colons in address http://10.202.91.2:2379, will retry later
   2016/08/26 15:26:32 rpc_worker.go:115: [info] [pd] connect to pd server http://10.202.91.2:2379
   2016/08/26 15:26:32 rpc_worker.go:118: [warning] [pd] failed connect pd server: dial tcp: too many colons in address http://10.202.91.2:2379, will retry later`
 @shenli 
pd: d062c207379d9800f4b41fdc70d98ef59abca047
tidb: 8169806756ae65d605bc65e97bdd8edec17af66c
tikv: 8bd91c6cb51ba63cc7bc684d4f5885968dfe9ddc
 @shenli Thank you! I will try it and report the result tomorrow.

@shenli I get the latest code and everything is OK. Thanks!
  LGTM
  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1589) <br/>All committers have signed the CLA.
  fix MySQL multi-packet handling. see issue #1586 
  Per   [mysql doc](https://dev.mysql.com/doc/internals/en/sending-more-than-16mbyte.html), it is possible to receive a zero-length packet, and it explicitly mentions:

``` txt
Sending a payload of 16 777 215 (224−1) bytes looks like:
ff ff ff 00 ...
00 00 00 01
```

but tidb doesn't seem to allow zere-length packet:

``` go
func (p *packetIO) readPacket() ([]byte, error) {
    var header [4]byte

    if _, err := io.ReadFull(p.rb, header[:]); err != nil {
        return nil, errors.Trace(err)
    }

    length := int(uint32(header[0]) | uint32(header[1])<<8 | uint32(header[2])<<16)
    if length < 1 {  /////////////  length could be zero 
        return nil, errInvalidPayloadLen.Gen("invalid payload length %d", length)
    }
```

Is this worth fixing? 
 I will send a PR later.
  [![CLA assistant check](https://cla-assistant.io/pull/badge/not_signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1582) <br/>Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you all sign our [Contributor License Agreement](https://cla-assistant.io/pingcap/tidb?pullRequest=1582) before we can accept your contribution.<br/>**1** out of **2** committers have signed the CLA.<br/><br/>:white_check_mark: XuHuaiyu<br/>:x: xuhuaiyu<hr/>**xuhuaiyu** seems not to be a GitHub user. You need a GitHub account to be able to sign the CLA. If you have already a GitHub account, please [add the email address used for this commit to your account](https://help.github.com/articles/why-are-my-commits-linked-to-the-wrong-user/#commits-are-not-linked-to-any-user).
  1) how to use these tools.
2) checkout why tidb out of memory when use myloader import data
 ./myloader -h 127.0.0.1 -P 15001 -u root -t 4 -q 1 -d ./mydumper-out-path
-q Number of queries per transaction, default 1000
  modify comment systemt to system
 [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1558) <br/>All committers have signed the CLA.
  Please answer these questions before submitting your issue. Thanks!
1. What version of Go are you using (`go version`)?
2. What operating system and processor architecture are you using (`go env`)?
3. What did you do?
   If possible, provide a recipe for reproducing the error.
   A complete runnable program is good.
4. What did you expect to see?
5. What did you see instead?
 OK, Thanks for you quick feedback. Hope that time quickly in the next two weeks!
 I am also expecting the support for "LOAD DATA INFILE". Nice to see it's already on the list! 
 Very Good News for me!!!  Great job!

原始邮件
发件人:goroutinenotifications@github.com
收件人:pingcap/tidbtidb@noreply.github.com
抄送:terryzhaoterryzhao1981@gmail.com; Mentionmention@noreply.github.com
发送时间:2016年8月30日(周二) 16:08
主题:Re: [pingcap/tidb] Does tidb support mysql "load data" command forimport data from csv file into database ? (#1543)

@foobar @terryzhao
We just supported the "Load data" command :)
—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or mute the thread.
  [![CLA assistant check](https://cla-assistant.io/pull/badge/not_signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1537) <br/>Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you all sign our [Contributor License Agreement](https://cla-assistant.io/pingcap/tidb?pullRequest=1537) before we can accept your contribution.<br/>**1** out of **2** committers have signed the CLA.<br/><br/>:white_check_mark: coocood<br/>:x: shenli
  pingcap/pd#206

Please merge pingcap/pd#213 frist, I will update Godeps.json later.
 PTAL @qiuyesuifeng @shenli @siddontang 
  #1430
 [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1504) <br/>All committers have signed the CLA.
 I have changed all the problems.
@tiancaiamao 
 I add some wrong test cases and
rewrite the hex function, because it would get wrong answers when input negtives in the last version.
@shenli 
  Why do you want to drop the option to embed tidb? I really like the idea of an embedded database as some kind of alternative to sqlite in pure go.
 But if I need a server to provide the socket it's not embedded?
 A follow up question: does TiDB right now can only be started with binary `tidb-server`? Another follow up question: Is there a plan to implement a way to start the server without using the binary, so it can be a fully embedded solution? I thought tidb can be a real sqlite alternative, sad that this don't happen.   Please answer these questions before submitting your issue. Thanks!
1. What version of Go are you using (`go version`)?
   1.6.2
2. What operating system and processor architecture are you using (`go env`)?
   MacOS
3. What did you do?
   If possible, provide a recipe for reproducing the error.
   A complete runnable program is good.
4. What did you expect to see?
   When I install TiDB from source code,The function `yyParse` in parse.go is like this:
   `func yyParse(yylex yyLexer) int`.
   But In yy_parser.go call yyParse like this:

```
func (parser *Parser) Parse(sql, charset, collation string) ([]ast.StmtNode, error) {
    if charset == "" {
        charset = mysql.DefaultCharset
    }
    if collation == "" {
        collation = mysql.DefaultCollationName
    }
    sql = handleMySQLSpecificCode(sql)
    l := NewLexer(sql)
    l.SetCharsetInfo(charset, collation)
    yyParse(l, &parser.cache)
    //yyParse(l)
    if len(l.Errors()) != 0 {
        return nil, errors.Trace(l.Errors()[0])
    }
    return l.Stmts(), nil
}
```

So I compile TiDB error. I want to check is this a bug? Thank you
1. What did you see instead?
 done. Thank you.
  Hi @shenli ,

I have learned golang just since two weeks. I found nothing than GDB to debug GO code. This is very hard to do debug with Interface:

1. cast an interface to a subinterface
2. call a method on the interface

could you show me how can one do it.

Best Regards,
Yu

 Hi @ngaut, @shenli and @tiancaiamao ,

thx for your information! I will give it a try.

besides it, **Happy Christmas!**  LGTM
  LGTM
  ref #1247 
This PR add length check to database name, table name and column name. The limitation is from [MySQL document](http://dev.mysql.com/doc/refman/5.7/en/identifiers.html) and saved into _mysql/const.go_ as const value.

The length check is performed while creating new database or table, and returns error message if name's length is too long.
  @shenli ，你在pull request #1196 里提到TiDB支持zabbix了！这非常令人兴奋！

我们的zabbix系统数据库负载非常大(每天新增70GB左右监控数据)，经常出问题，想使用TiDB来解决数据库的shard、吞吐问题，所以请问下你的测试情况，现在迁移有问题么？

== English ==
@shenli Your PR #1196 shows that TiDB is now support Zabbix! That's awesome.

The workload of our zabbix system is very heavy (70GB new data per day), we want to use TiDB instead of MySQL to avoid shading, and handle the throughput. Does TiDB ready for this?
 Thanks shenli ! I will try the latest master.
 Never mind. :)

@shenli, Do you have any suggestions before testing? I'm very appreciated!
 @shenli, I run the latest docker image, but grant privileges failed:

% mysql -h 127.0.0.1 -P 4000 -u root -D test
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MySQL connection id is 10006
Server version: 5.5.31-TiDB-1.0 MySQL Community Server (GPL)

Copyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MySQL [test]> grant all privileges on zabbix.\* to zabbix@localhost identified by '<password>';
ERROR 1105 (HY000): line 1 column 11 near "privileges"

**The following is from container logs:**

2016/07/08 08:45:05 txn.go:113: [debug] [kv] commit txn 384818873708838912
2016/07/08 08:45:07 session.go:394: [warning] compiling grant all privileges on zabbix.\* to zabbix@localhost identified by '<password>', error: line 1 column 11 near "privileges"
2016/07/08 08:45:07 conn.go:260: [debug] [TIME_CMD] 160.645µs 3
2016/07/08 08:45:07 conn.go:241: [warning] dispatch error line 1 column 11 near "privileges"
/go/src/github.com/pingcap/tidb/parser/yy_parser.go:87: 
/go/src/github.com/pingcap/tidb/session.go:395: 
/go/src/github.com/pingcap/tidb/server/conn.go:376: , conn: 172.17.0.1:52674, status: 2, charset: utf8, user: root, lastInsertId: 0
2016/07/08 08:45:07 conn.go:242: [warning] cmd: grant all privileges on zabbix.\* to zabbix@localhost identified by '<password>'
 @shenli, I only executed two sql statements, has no relationship with zabbix:

% mysql -h 127.0.0.1 -P 4000 -u root -D test
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MySQL connection id is 10027
Server version: 5.5.31-TiDB-1.0 MySQL Community Server (GPL)

Copyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MySQL [test]> create database zabbix character set utf8 collate utf8_bin;
Query OK, 0 rows affected (0.03 sec)

MySQL [test]> grant all privileges on zabbix.\* to zabbix@localhost identified by 'password';
ERROR 1105 (HY000): line 1 column 11 near "privileges"
 @shenli  I run zabbix successfully now, using the latest docker image!

But when displaying 'Status of zabbix', it took 74 seconds, which is too long.

The following is debug output. I will try TiKV later.

*******************\* Script profiler ********************
Total time: 74.026581
Total SQL time: 74.044125
SQL count: 16 (selects: 13 | executes: 3)
Peak memory usage: 2M
Memory limit: 128M

。。。。ignore 。。。。

SQL (71.520362): SELECT COUNT(DISTINCT t.triggerid) AS cnt,t.status,t.value FROM triggers t WHERE NOT EXISTS (SELECT f.functionid FROM functions f JOIN items i ON f.itemid=i.itemid JOIN hosts h ON i.hostid=h.hostid WHERE f.triggerid=t.triggerid AND (i.status<>0 OR h.status<>0)) AND t.flags IN (0,4) GROUP BY t.status,t.value
zabbix.php:21 → require_once() → ZBase->run() → ZBase->processRequest() → CView->getOutput() → include() → make_status_of_zbx() → get_status() → DBselect() in include/func.inc.php:2012

MySQL [zabbix]> explain SELECT COUNT(DISTINCT t.triggerid) AS cnt,t.status,t.value FROM triggers t WHERE NOT EXISTS (SELECT f.functionid FROM functions f JOIN items i ON f.itemid=i.itemid JOIN hosts h ON i.hostid=h.hostid WHERE f.triggerid=t.triggerid AND (i.status<>0 OR h.status<>0)) AND t.flags IN (0,4) GROUP BY t.status,t.value;
+------+-------------+----------+------+---------------+------+---------+------+------+-------------+
| id   | select_type | table    | type | possible_keys | key  | key_len | ref  | rows | Extra       |
+------+-------------+----------+------+---------------+------+---------+------+------+-------------+
|    1 | SIMPLE      | triggers | ALL  | NULL          | NULL | NULL    | NULL | 0    | Using where |
+------+-------------+----------+------+---------------+------+---------+------+------+-------------+
 @shenli  Thanks!

I use the latest zabbix docker image(current version is 3.0.3). The commands are following:

$ docker run --name tidb-server -d -p 4000:4000 pingcap/tidb:latest
$ mysql  -h 127.0.0.1 -P 4000 -u root -e "create database zabbix character set utf8 collate utf8_bin;"
$ mysql  -h 127.0.0.1 -P 4000 -u root -e "create user 'zabbix'@'%' identified by '123';"
$ mysql  -h 127.0.0.1 -P 4000 -u root -e "grant all privileges on zabbix.\* to 'zabbix'@'%';"
$ cd /path/to/zabbix-3.0.3/database/mysql # you can download source code from here: http://www.zabbix.com/download.php
$ mysql  -h 127.0.0.1 -P 4000 -u root zabbix <schema.sql
$ mysql  -h 127.0.0.1 -P 4000 -u root zabbix <images.sql
$ mysql  -h 127.0.0.1 -P 4000 -u root zabbix <data.sql
$ docker run -d --name zabbix -p 80:80 -p 10051:10051 -v  /etc/localtime:/etc/localtime:ro --link tidb-server:zabbix.db --env="ZS_DBHost=zabbix.db" --env="ZS_DBPassword=123"  --env="ZS_DBPort=4000" monitoringartist/zabbix-3.0-xxl:latest

Then open http://127.0.0.1，login using account "Admin/zabbix".

You can turn on debug mode by: Adminstration -> Users -> Zabbix administrator, then check on 'Debug mode'
 @shenli Well Done!  It is amazing to see the performance benefits! 

But, when I was importing online data to TiDB, it reported following error:

```
% head valuemaps.txt
'4','APC Battery Replacement Status'
'5','APC Battery Status'
'7','Dell Open Manage System Status'
'6','HP Insight System Status'
'2','Host status'
'14','Maintenance status'
'9','SNMP device status (hrDeviceStatus)'
'11','SNMP interface status (ifAdminStatus)'
'8','SNMP interface status (ifOperStatus)'
'1','Service state'

% mysqlimport --local --fields-terminated-by=, --fields-enclosed-by="'" --fields-escaped-by=/ -h 127.0.0.1 -P 4000 -u root zabbix_server valuemaps.txt
mysqlimport: Error: 1105 line 1 column 36 near ";"
```

```
mysql> use zabbix_server
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
mysql>
mysql>  LOAD DATA LOCAL INFLIE 'valuemaps.txt' INTO TABLE valuemaps fields terminated by "," fields enclosed by "'" fields escaped by "/";
ERROR 1105 (HY000): line 1 column 1 near "LOAD"
mysql>

```
 @shenli  Our online history._/trends._ tables were partitioned and we have many views/procedures,  when I restored them, I saw lots of errors as following. Does TiDB support partition/view/procedures? Or, we don't need them any more?

```
ERROR 1105 (HY000): line 10 column 1 near "PARTITION"
ERROR 1105 (HY000): line 8 column 1 near "PARTITION"
ERROR 1105 (HY000): line 1 column 6 near "VIEW"
ERROR 1105 (HY000): line 1 column 8 near "DEFINER"
ERROR 1105 (HY000): line 1 column 8 near "ALGORITHM"
```
 @shenli Thanks!  The following are containter logs:

**part one:**
(% mysqlimport --local --fields-terminated-by=, --fields-enclosed-by="'" --fields-escaped-by=/ -h 127.0.0.1 -P 4000 -u root zabbix_server valuemaps.txt
mysqlimport: Error: 1105 line 1 column 36 near ";")

2016/07/22 01:05:58 new_executor_xapi.go:113: [debug] [TIME_INDEX_TABLE_SCAN] time: 1.427097ms handles: 1
2016/07/22 01:05:58 conn.go:276: [debug] init db zabbix_server 
2016/07/22 01:05:58 txn.go:113: [debug] [kv] commit txn 385128741889114112
2016/07/22 01:05:58 conn.go:260: [debug] [TIME_CMD] 248.319µs 2
2016/07/22 01:05:58 session.go:395: [warning] compiling /_!40101 set @@character_set_database=binary */;, error: line 1 column 36 near ";"
2016/07/22 01:05:58 conn.go:260: [debug] [TIME_CMD] 139.526µs 3
2016/07/22 01:05:58 conn.go:241: [warning] dispatch error line 1 column 36 near ";"
/go/src/github.com/pingcap/tidb/parser/yy_parser.go:87: 
/go/src/github.com/pingcap/tidb/session.go:396: 
/go/src/github.com/pingcap/tidb/server/conn.go:376: , conn: 172.17.0.1:60690, status: 2, charset: utf8, user: root, lastInsertId: 0
2016/07/22 01:05:58 conn.go:242: [warning] cmd: /_!40101 set @@character_set_database=binary */;
2016/07/22 01:05:58 conn.go:260: [debug] [TIME_CMD] 2.752µs 1
2016/07/22 01:05:58 session.go:551: [info] RollbackTxn for session close. 
2016/07/22 01:05:58 server.go:190: [info] close conn: 172.17.0.1:60690, status: 2, charset: utf8, user: root, lastInsertId: 0
2016/07/22 01:06:07 ddl_worker.go:317: [debug] [ddl] wait 10s to check DDL status again

**Part two:**
(mysql>  LOAD DATA LOCAL INFLIE 'valuemaps.txt' INTO TABLE valuemaps fields terminated by "," fields enclosed by "'" fields escaped by "/";
ERROR 1105 (HY000): line 1 column 1 near "LOAD")

2016/07/22 01:03:38 txn.go:113: [debug] [kv] commit txn 385128705246887936
2016/07/22 01:03:38 conn.go:260: [debug] [TIME_CMD] 570.666µs 4
2016/07/22 01:03:45 session.go:395: [warning] compiling LOAD DATA LOCAL INFLIE 'valuemaps.txt' INTO TABLE valuemaps fields terminated by "," fields enclosed by "'" fields escaped by "/", error: line 1 column 1 near "LOAD"
2016/07/22 01:03:45 conn.go:260: [debug] [TIME_CMD] 163.332µs 3
2016/07/22 01:03:45 conn.go:241: [warning] dispatch error line 1 column 1 near "LOAD"
/go/src/github.com/pingcap/tidb/parser/yy_parser.go:87: 
/go/src/github.com/pingcap/tidb/session.go:396: 
/go/src/github.com/pingcap/tidb/server/conn.go:376: , conn: 172.17.0.1:60688, status: 2, charset: utf8, user: root, lastInsertId: 0
2016/07/22 01:03:45 conn.go:242: [warning] cmd: LOAD DATA LOCAL INFLIE 'valuemaps.txt' INTO TABLE valuemaps fields terminated by "," fields enclosed by "'" fields escaped by "/"
2016/07/22 01:03:47 ddl_worker.go:317: [debug] [ddl] wait 10s to check DDL status again
2016/07/22 01:03:47 txn.go:48: [debug] [kv] Begin txn:385128707409313792
  I learn about tidb from infoQ , looks like tidb is a distributed mpp database , so I want to know the different between tidb and hawq which derived from greenplum db,and what's the advancement of tidb.
 ok.thanks.
  Please answer these questions before submitting your issue. Thanks!
1. What version of Go are you using (`go version`)?
   go1.6.2 windows/amd64
2. What operating system and processor architecture are you using (`go env`)?
   set GOARCH=amd64
   set GOBIN=
   set GOEXE=.exe
   set GOHOSTARCH=amd64
   set GOHOSTOS=windows
   set GOOS=windows
   set GOPATH=C:\Users\Hplong\Documents\projects\go
   set GORACE=
   set GOROOT=C:\Go
   set GOTOOLDIR=C:\Go\pkg\tool\windows_amd64
   set GO15VENDOREXPERIMENT=1
   set CC=gcc
   set GOGCCFLAGS=-m64 -mthreads -fmessage-length=0
   set CXX=g++
   set CGO_ENABLED=1
3. What did you do?
   If possible, provide a recipe for reproducing the error.
   Download the source code, run the tidb_test.go
4. What did you expect to see?
   The project starts up and I can debug the project step by step.
   (now I can only run the test cases through parser_test.go, but still can not debug it.)
5. What did you see instead?
   Errors reported from liteIDE informs that “Fail to start the process”
 @shenli But when I press 'F5' and try to debug the project , the IDE reports  "16:43:56 debug: not find execute file in path C:/Users/Hplong/Documents/projects/go/src/github.com/pingcap/tidb" , which means I don't have the .exe file of the project. Now I can run the parser_test.go and tidb_test.go through the liteIDE, but I just can not debug the code step by step . Should I create a new empty project, and then  copy the tidb project files in it, invoking the functions in *_test.go? Or do you have any other suggestion?
 @ngaut Ok, I am trying to debug it on windows.
@shenli Now I use the "make server" under the TiDB dictionary, and it reports
"C:\Users\Hplong\Documents\projects\go\src\github.com\pingcap\tidb>make server
[Parser]
Parse table entries: 420495 of 1042566, x 16 bits == 840990 bytes
Parse table entries: 420495 of 1042566, x 16 bits == 840990 bytes
[Build]
godep: No Godeps found (or in any parent directory)
[Install]
godep: No Godeps found (or in any parent directory)
[Test]
godep: No Godeps found (or in any parent directory)
[Done]"
And there is only a "main.go" file under tidb-server dictionary, I can not find the binary file in tidb-server, so it's still not working now. Did you already debug the code on windows and do you have steps to suggest?
What's more I can see dodep.exe in the "C:\Users\Hplong\Documents\projects\go\bin", and that path is added to the environment.
 What's "PR"? @shenli 
 @shenli ok, I am trying it on linux now. And when I running "make server",it reports as below:
"hplong@ubuntu:~/Downloads/tidb-master$ make server
go get github.com/qiuyesuifeng/goyacc
go get github.com/qiuyesuifeng/golex
$(which goyacc) -o /dev/null -xegen temp_parser_file parser/parser.y
Parse table entries: 420495 of 1042566, x 16 bits == 840990 bytes
$(which goyacc) -o parser/parser.go -xe temp_parser_file parser/parser.y 2>&1 | egrep "(shift|reduce)/reduce" | awk '{print} END {if (NR > 0) {print "Find conflict in parser.y. Please check y.output for more information."; system("rm -f temp_parser_file"); exit 1;}}'
rm -f temp_parser_file
rm -f y.output
$(which golex) -o parser/scanner.go parser/scanner.l
fatal: Not a git repository (or any of the parent directories): .git
rm -rf vendor && ln -s _vendor/vendor vendor
//#github.com/pingcap/tidb/parser
../../../Documents/go/src/github.com/pingcap/tidb/parser/yy_parser.go:63: undefined: yySymType
make: **\* [server] Error 2"

# 

The error above has gone now as I use the code in the dictionary of "$GOPATH/src/github.com/pingcap/tidb", instead of using the code packaged in zipfile which downloaded from the github site. And I can see the binary file tidb-server in the directory tidb-server.
Log:
"hplong@ubuntu:~/Documents/go/src/github.com/pingcap/tidb$ make server
go get github.com/pingcap/goyacc
go get github.com/qiuyesuifeng/golex
$(which goyacc) -o /dev/null -xegen temp_parser_file parser/parser.y
Parse table entries: 420495 of 1042566, x 16 bits == 840990 bytes
$(which goyacc) -o parser/parser.go -xe temp_parser_file parser/parser.y 2>&1 | egrep "(shift|reduce)/reduce" | awk '{print} END {if (NR > 0) {print "Find conflict in parser.y. Please check y.output for more information."; system("rm -f temp_parser_file"); exit 1;}}'
rm -f temp_parser_file
rm -f y.output
$(which golex) -o parser/scanner.go parser/scanner.l
rm -rf vendor && ln -s _vendor/vendor vendor
rm -rf vendor"

# 

@shenli And the binary file "tidb-server" is running successfully now, it seems that environment is ready^_^
So what is next step to debug the code? The liteIDE is also ready.
 @shenli @ngaut @coocood @disksing
Now the make&make server is ok, I can run the "tidb-server" file, but when I debug the tidb-server using "F5" in liteIDE, the following error occur：

“/usr/local/go/bin/go build -gcflags "-N -l" [/home/hplong/Documents/go/src/github.com/pingcap/tidb/tidb-server]
//# github.com/pingcap/tidb/store/tikv/mock-tikv
../store/tikv/mock-tikv/pd.go:40: cannot use pdClient literal (type _pdClient) as type pd.Client in return argument:
    *pdClient does not implement pd.Client (wrong type for GetRegion method)
        have GetRegion([]byte) (_metapb.Region, error)
        want GetRegion([]byte) (*metapb.Region, *metapb.Peer, error)
Command exited with code 2.”
 ok，thanks! @shenli 
  Hi, I have wrote a Makefile which packs tidb and ticlient into one deb file. Although, the deb file works fine in my machine(Ubuntu 14LTS, AMD64), I am not sure if this works in yours.

You can get it via apt-get

``` sh
sudo apt-add-repository ppa:overvenus/tidb
sudo apt-get update
sudo apt-get install tidb
```

or download it directly from [link](https://launchpad.net/~overvenus/+archive/ubuntu/tidb/+build/10430189/+files/tidb_0.0.1~beta20160630-1_amd64.deb)

Check out my work at [debian-package](https://github.com/overvenus/tidb/tree/debian-package/dist)
I am not a debian expert, so it did not follow [Chapter 6. Best Packaging Practices](https://www.debian.org/doc/manuals/developers-reference/best-pkging-practices.html) 100%. If you think it ok, then I'm glad to send a PR. : )
 An AUR package for Arch Linux using binary package:
https://aur.archlinux.org/packages/tidb-bin/
  LGTM
  File [README.md](https://github.com/pingcap/tidb/blob/master/README.md) mentioned:

> TiDB is under the Apache 2.0 license. See the LICENSE file for details.

However, the link to "LICENSE file" is not available at the moment.
 @shenli, At present, there are only two BSD-style license files:
- QL-LICENSE
- STRUTIL-LICENSE

No file containing Apache License 2.0 with explicit copyright ownership can be accessed in directory `LICENSES` though.
 @shenli, Thanks for clarifying.
  20100606tidb
 [![CLA assistant check](https://cla-assistant.io/pull/badge/not_signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1375) <br/>Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our [Contributor License Agreement](https://cla-assistant.io/pingcap/tidb?pullRequest=1375) before we can accept your contribution.<br/>
  The `LDFLAGS` in Makefile tries to get git commit hash while building
server component, but default COPY command does not put _.git_ directory
into docker container, which causes the fatal error while executing
command `git rev-parse HEAD`.

This fix remove _.git_ directory from _.dockerignore_ file, then the git
command can be executed successfully in container.
 [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1361) <br/>All committers have signed the CLA.
 @shenli Sorry, haven't noticed it yesterday. I have signed the CLA just now.
  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1332) <br/>All committers have signed the CLA.
  https://github.com/pingcap/tidb/pull/1330#discussion_r67594923

> We default err is err0, so here err2 -> err1 is beterr.

So here is a pull request to improve consistency with this rule.

I confirmed `make` passes with this pull request (that is, both `go tool vet -shadow .` and `go build` passes).
  Also ran goimports to sort imports.
 [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1330) <br/>All committers have signed the CLA.
   [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1321) <br/>All committers have signed the CLA.
  [![CLA assistant check](https://cla-assistant.io/pull/badge/not_signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1311) <br/>Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you all sign our [Contributor License Agreement](https://cla-assistant.io/pingcap/tidb?pullRequest=1311) before we can accept your contribution.<br/>**1** out of **2** committers have signed the CLA.<br/><br/>:white_check_mark: shenli<br/>:x: web-flow
  @shenli 
hello, is there any results of comparing the performance TiDB and TiDB+Spark ? @shenli 
thanks a lot!could you show me the the detail data of the performance TiDB?  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1306) <br/>All committers have signed the CLA.
  I have a java application and want to use tidb as a local sql storage. Does it have java client api or supporting jdbc interface?
 @shenli :+1: Thanks, I will have a try
  Please answer these questions before submitting your issue. Thanks!
1. What version of Go are you using (`go version`)?
2. What operating system and processor architecture are you using (`go env`)?
3. What did you do?
   If possible, provide a recipe for reproducing the error.
   A complete runnable program is good.
4. What did you expect to see?
5. What did you see instead?
 go version 1.6
system mac
when i was make tidb 

pingcap/tidb/parser/yy_parser.go:71: undefined: NewLexer
pingcap/tidb/parser/yy_parser.go:73: undefined: yyParse
 @shenli  do as you say,it's ok. ths!
  go version:

```
go version go1.6.2 windows/amd64
```

go env

```
set GOARCH=amd64
set GOBIN=
set GOEXE=.exe
set GOHOSTARCH=amd64
set GOHOSTOS=windows
set GOOS=windows
set GOPATH=D:\go;D:\code\analyzer\
set GORACE=
set GOROOT=D:\devtool\go64
set GOTOOLDIR=D:\devtool\go64\pkg\tool\windows_amd64
set GO15VENDOREXPERIMENT=1
set CC=gcc
set GOGCCFLAGS=-m64 -mthreads -fmessage-length=0
set CXX=g++
set CGO_ENABLED=1
```

I test this code on windows:

```
package main

import (
    "database/sql"
    "fmt"

    "github.com/ngaut/log"
    _ "github.com/pingcap/tidb"
)

func main() {
    // Default log level is debug, set it to error to turn off debug log.
    log.SetLevelByString("error")

    // DriverName is 'tidb', dataSourceName is in the form of "<engine>://<dbPath>/<dbName>".
    // dbPath is the directory that stores the data files if you use a local storage engine.
    // dbName is the name of the database which you want to use.
    dbPath := "D:\\temp\\tidb"
    dbName := "tidb"
    db, err := sql.Open("tidb", "goleveldb://"+dbPath+"/"+dbName)
    if err != nil {
        log.Fatal(err)
    }
    defer db.Close()

    _, err = db.Exec("CREATE TABLE IF NOT EXISTS t (a INT)")
    if err != nil {
        log.Fatal(err)
    }

    _, err = db.Exec("INSERT INTO t VALUES (?)", 1)
    if err != nil {
        log.Fatal(err)
    }

    row := db.QueryRow("SELECT * FROM t WHERE a = ?", 1)
    var val int
    err = row.Scan(&val)
    if err != nil {
        log.Fatal(err)
    }

    fmt.Printf("value is %d\n", val)

    _, err = db.Exec("DROP TABLE t")
    if err != nil {
        log.Fatal(err)
    }
}

```

the output is:

```
2016/06/01 12:55:40 main2.go:28: [fatal] parse goleveldb://D:\temp\tidb/tidb: invalid character "\\" in host name
```

when I change the dbPath to "D:/temp/tidb"
the output is:

```
2016/06/01 12:56:30 main2.go:28: [fatal] parse goleveldb://D:%5Ctemp%5Ctidb: invalid URL escape "%5C"
```

I modify the parseDriverDSN func in driver.go, and it seems all ok

```
func parseDriverDSN(dsn string) (params *driverParams, err error) {
    u, err := url.Parse(dsn)
    if err != nil {
        return nil, errors.Trace(err)
    }
    path := filepath.Join(u.Host, u.Path)
    dbName := filepath.Clean(filepath.Base(path))
    if dbName == "" || dbName == "." || dbName == string(filepath.Separator) {
        return nil, errors.Errorf("invalid DB name %q", dbName)
    }
    // cut off dbName
    path = filepath.Clean(filepath.Dir(path))
    if path == "" || path == "." || path == string(filepath.Separator) {
        return nil, errors.Errorf("invalid dsn %q", dsn)
    }
    u.Path, u.Host = path, ""
    u.Path = strings.Replace(u.Path, "\\", "/", -1)
    params = &driverParams{
        storePath: u.String(),
        dbName:    dbName,
    }
    // parse additional driver params
    query := u.Query()
    if parseTime := query.Get("parseTime"); parseTime == "true" {
        params.parseTime = true
    }

    return params, nil
}
```
  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1274) <br/>All committers have signed the CLA.
  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1260) <br/>All committers have signed the CLA.
  The issue seems closable? https://github.com/pingcap/tidb/pull/1308 
  fix #1225!

PTAL @shenli @coocood 
 [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1226) <br/>All committers have signed the CLA.
  #310
 [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1224) <br/>All committers have signed the CLA.
 cc @shenli @coocood 
 cc @coocood 
Sorry for that on my emacs configuration, tabs are automatically replaced by spaces
 cc @shenli 
 cc @coocood 
 cc @coocood 
 cc @coocood 
  what if the local git repository is not the same as Godep.json says?  @coocood 
`github.com/pingcap/kvproto/pkg/...` seems not just check kvproto, it update other packages too.

Then I run `godep restore` and get this:

```
➜  tidb git:(master) ✗ godep restore
# cd /Users/genius/project/src/github.com/ngaut/tso/client; git checkout 3e62d377d3edbc20520c7934964615f8e91e27cd
fatal: reference is not a tree: 3e62d377d3edbc20520c7934964615f8e91e27cd
godep: error restoring dep (github.com/ngaut/tso/client): exit status 128
# cd /Users/genius/project/src/github.com/ngaut/tso/proto; git checkout 3e62d377d3edbc20520c7934964615f8e91e27cd
fatal: reference is not a tree: 3e62d377d3edbc20520c7934964615f8e91e27cd
godep: error restoring dep (github.com/ngaut/tso/proto): exit status 128
# cd /Users/genius/project/src/github.com/ngaut/tso/util; git checkout 3e62d377d3edbc20520c7934964615f8e91e27cd
fatal: reference is not a tree: 3e62d377d3edbc20520c7934964615f8e91e27cd
godep: error restoring dep (github.com/ngaut/tso/util): exit status 128
godep: Error restoring some deps. Aborting check.
```

@ngaut 
 LGTM
rebase master please~
  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1210) <br/>All committers have signed the CLA.
  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1191) <br/>All committers have signed the CLA.
  Hi 
This is a comment on future tidb software packaging effort. Not sure if your team decided on how to release tidb native package for different OS.

I like to propose using [Jeninkin project's packaging framework](https://github.com/jenkinsci/packaging). 

This my effort on [packaging gogs](https://github.com/tjyang/gogspkg) using the same packaging framework for Go supported OS. it will be pushed back into https://github.com/gogits/packaging
 > We haven't considered about packaging. In most common scenario, TiDB will be deployed together with TiKV and PD. 

Sorry, I haven't use golang to create tidb binary by myself yet. Will TiKV and PB be part of tidb main binary ? if it is not part of same binary that is ok too. 

> Will it be a good solution for this scenario?

Yes, I think so. I think Jenkins' packaging framework is flexible enough and it is battle tested. Also it is designed for CI/CD.  One just need to change the target from jenkins.war to tidb related files.
One concern I have is the license compatibility. 
 > So our Ti storage solution contains three components. I think docker is a better solution. Especially TiKV depends on RocksDB which depends on gcc/clang with C++11 support, gflags, snappy and so on. Docker will make the deployment easier.

Jenekin's packaging frame work has [docker packaging solution](https://github.com/jenkinsci/packaging/tree/master/docker) also.  docker is just one of ways to deliver software. Agree docker is good but not every one is using or have to use docker.  It is good to have a software support native package format for  different OS.
 > Thank you for your advice.

Sorry, I may sounded my providing advice. This is just a need from a potential user.  Currently my work place is not  one of the docker users. We deploy software using yum or apt-get into production Linux systems, not docker.

Also PinCAP doesn't have to do the whole native packaging stuff yourselves. People want the native tidb package will contribute and test too. 

For me, I will create rpm for my tidb testing purpose. I like to see how well gogs work with tidb.

Thanks for your time and listening.
  [![CLA assistant check](https://cla-assistant.io/pull/badge/not_signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1179) <br/>Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our [Contributor License Agreement](https://cla-assistant.io/pingcap/tidb?pullRequest=1179) before we can accept your contribution.<br/><hr/>**hanfei1991905** seems not to be a GitHub user. You need a GitHub account to be able to sign the CLA. If you have already a GitHub account, please [add the email address used for this commit to your account](https://help.github.com/articles/why-are-my-commits-linked-to-the-wrong-user/#commits-are-not-linked-to-any-user).
  Please answer these questions before submitting your issue. Thanks!
1. What version of Go are you using (`go version`)?
   1.6
2. What operating system and processor architecture are you using (`go env`)?
   GOBIN=""
   GOEXE=""
   GOHOSTARCH="amd64"
   GOHOSTOS="linux"
   GOOS="linux"
   GOPATH="/go-dev"
   GORACE=""
   GOROOT="/usr/local/go"
   GOTOOLDIR="/usr/local/go/pkg/tool/linux_amd64"
   GO15VENDOREXPERIMENT="1"
   CC="gcc"
   GOGCCFLAGS="-fPIC -m64 -pthread -fmessage-length=0"
   CXX="g++"
   CGO_ENABLED="1"
3. What did you do?
   run server: tidb-server -path /tidb-data
   then mysql import from a mysqldump-ed file of ~700Mb gzipped
4. What did you expect to see?
   data to be imported, or if there are errors to be warned about them
5. What did you see instead?
   it worked for 10+ minutes and some tables where imported
   but then crashed with  

goroutine 46 [select, 10 minutes, locked to thread]:
runtime.gopark(0x1637620, 0xc82072c728, 0x12cd440, 0x6, 0xc8202dfd18, 0x2)
        /usr/local/go/src/runtime/proc.go:262 +0x163
runtime.selectgoImpl(0xc82072c728, 0x0, 0x18)
        /usr/local/go/src/runtime/select.go:392 +0xa67
runtime.selectgo(0xc82072c728)
        /usr/local/go/src/runtime/select.go:215 +0x12
runtime.ensureSigM.func1()
        /usr/local/go/src/runtime/signal1_unix.go:279 +0x358
runtime.goexit()
        /usr/local/go/src/runtime/asm_amd64.s:1998 +0x1

goroutine 47 [chan receive, 10 minutes]:
main.main.func1(0xc82084c2a0, 0xc821185a40)
        /go-dev/src/github.com/pingcap/tidb/tidb-server/main.go:98 +0x4d
created by main.main
        /go-dev/src/github.com/pingcap/tidb/tidb-server/main.go:102 +0xf32

goroutine 48 [IO wait, 10 minutes]:
net.runtime_pollWait(0x7fc57b670498, 0x72, 0x0)
        /usr/local/go/src/runtime/netpoll.go:160 +0x60
net.(_pollDesc).Wait(0xc8201cec30, 0x72, 0x0, 0x0)
        /usr/local/go/src/net/fd_poll_runtime.go:73 +0x3a
net.(_pollDesc).WaitRead(0xc8201cec30, 0x0, 0x0)
        /usr/local/go/src/net/fd_poll_runtime.go:78 +0x36
net.(_netFD).accept(0xc8201cebd0, 0x0, 0x7fc57b670710, 0xc82083a980)
        /usr/local/go/src/net/fd_unix.go:426 +0x27c
net.(_TCPListener).AcceptTCP(0xc8201b5e60, 0x7360a1, 0x0, 0x0)
        /usr/local/go/src/net/tcpsock_posix.go:254 +0x4d
net/http.tcpKeepAliveListener.Accept(0xc8201b5e60, 0x0, 0x0, 0x0, 0x0)
        /usr/local/go/src/net/http/server.go:2427 +0x41
net/http.(_Server).Serve(0xc82084a300, 0x7fc57b6706d8, 0xc8201b5e60, 0x0, 0x0)
        /usr/local/go/src/net/http/server.go:2117 +0x129
net/http.(_Server).ListenAndServe(0xc82084a300, 0x0, 0x0)
        /usr/local/go/src/net/http/server.go:2098 +0x136
net/http.ListenAndServe(0xc82023eab6, 0x6, 0x0, 0x0, 0x0, 0x0)
        /usr/local/go/src/net/http/server.go:2195 +0x98
github.com/pingcap/tidb/tidb-server/server.(_Server).startStatusHTTP.func1.1(0xc821185a40)
        /go-dev/src/github.com/pingcap/tidb/tidb-server/server/server.go:211 +0xd3
created by github.com/pingcap/tidb/tidb-server/server.(_Server).startStatusHTTP.func1
        /go-dev/src/github.com/pingcap/tidb/tidb-server/server/server.go:212 +0x34
 Same here

![image](https://cloud.githubusercontent.com/assets/659311/20060714/648d64e4-a537-11e6-8970-4fc3099b394e.png)

import a .sql file have error like the picture show. it is OK in mysql
 during import with source command

![image](https://cloud.githubusercontent.com/assets/659311/20060813/ef427ed0-a537-11e6-9bfe-f34e29ed7091.png)
  Hi

Is it possible to document the difference with [vitess](https://github.com/youtube/vitess) when making  comparison with other DB solution ?
So far my understanding is that vitess is an add-on solution to existing mysql deployment while vitess will need to swap out the mysql instance with tidb.
 Shen
Thanks for the clarification, Hopefully in the future TiDB vs others DB solution document, vitess invented and used by youtube can by mentioned. Just to show TiDB has special feature Vitess doesn't have.
  Change some from lowercase to uppercase for some terminologies
 [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1163) <br/>All committers have signed the CLA.
  PTAL @coocood, @shenli 
  Please answer these questions before submitting your issue. Thanks!
1. What version of Go are you using (`go version`)?

go version go1.4.2 linux/amd64
1. What operating system and processor architecture are you using (`go env`)?

GOARCH="amd64"
GOBIN=""
GOCHAR="6"
GOEXE=""
GOHOSTARCH="amd64"
GOHOSTOS="linux"
GOOS="linux"
GOPATH="/opt/tidb/tidb-master/"
GORACE=""
GOROOT="/usr/lib/golang"
GOTOOLDIR="/usr/lib/golang/pkg/tool/linux_amd64"
CC="gcc"
GOGCCFLAGS="-fPIC -m64 -pthread -fmessage-length=0"
CXX="g++"
CGO_ENABLED="1"
1. What did you do?

[root@mych-server-2 tidb-master]# make
1. What did you expect to see?

Expected it to build
1. What did you see instead?

go get google.golang.org/grpc
git -C $(echo /opt/tidb/tidb-master/|cut -d':' -f1)/src/google.golang.org/grpc checkout dec33edc378cf4971a2741cfd86ed70a644d6ba3
Unknown option: -C
usage: git [--version] [--help] [-c name=value]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           <command> [<args>]
make: **\* [godep] Error 129
 Okay, thanks. The solution would be get the latest git client I guess
  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1143) <br/>All committers have signed the CLA.
  `DATA_ADD`, `DAYNAME`, etc. should probably return NULL for a invalid time format as https://dev.mysql.com/doc/refman/5.7/en/date-and-time-functions.html says:

> Other functions expect complete dates and return NULL for incomplete dates. These include functions that perform date arithmetic or that map parts of dates to names.

---

Please answer these questions before submitting your issue. Thanks!
1. What version of Go are you using (`go version`)?
   go1.6.1
2. What operating system and processor architecture are you using (`go env`)?
   linux_amd64
3. What did you do?
   `SELECT DATE_ADD('2010-10-0', INTERVAL 1 DAY);`
4. What did you expect to see?

```
+---------------------------------------+
| DATE_ADD('2010-10-0', INTERVAL 1 DAY) |
+---------------------------------------+
| NULL                                  |
+---------------------------------------+
1 row in set, 1 warning (0.00 sec)

```
1. What did you see instead?

```
ERROR 1105 (HY000): DateArith invalid args, need date but get types.Datum
```
 I'm not very sure. I tested it on the latest mysql docker image and it said that strict mode became the default since 5.7.
 @shenli Here is the output:

```
mysql> show variables like 'sql_mode';
+---------------+-------------------------------------------------------------------------------------------------------------------------------------------+
| Variable_name | Value                                                                                                                                     |
+---------------+-------------------------------------------------------------------------------------------------------------------------------------------+
| sql_mode      | ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION |
+---------------+-------------------------------------------------------------------------------------------------------------------------------------------+
1 row in set (0.00 sec)

mysql> SELECT DATE_ADD('2010-10-0', INTERVAL 1 DAY);
+---------------------------------------+
| DATE_ADD('2010-10-0', INTERVAL 1 DAY) |
+---------------------------------------+
| NULL                                  |
+---------------------------------------+
1 row in set, 1 warning (0.00 sec)

mysql>
```
 I see, invalid date format causes error in statements like `INSERT` and `UPDATE`. However, for `SELECT`, null is retured in mysql. So, for simplicity, just keep things as is.
  https://github.com/pingcap/tidb/blob/master/evaluator/builtin_time.go#L465

`nodeInterval.Interval` should be evaled before calling `GetDatum()`.

---

Please answer these questions before submitting your issue. Thanks!
1. What version of Go are you using (`go version`)?
   go1.6.1
2. What operating system and processor architecture are you using (`go env`)?
   linux_amd64
3. What did you do?
   `SELECT DATE_ADD('2010-10-10', INTERVAL 1+1 DAY);`
4. What did you expect to see?

```
+------------------------------------------+
| DATE_ADD('2010-10-10', INTERVAL 1+1 DAY) |
+------------------------------------------+
| 2010-10-12                               |
+------------------------------------------+
1 row in set (0.00 sec)

```
1. What did you see instead?

```
+------------------------------------------+
| DATE_ADD('2010-10-10', INTERVAL 1+1 DAY) |
+------------------------------------------+
| NULL                                     |
+------------------------------------------+
1 row in set (0.00 sec)

```
 solved by #2368  Please answer these questions before submitting your issue. Thanks!
1. What version of Go are you using (`go version`)?
   1.6.1
2. What operating system and processor architecture are you using (`go env`)?

```
GOARCH="amd64"
GOBIN="/mnt/Gopath/bin"
GOEXE=""
GOHOSTARCH="amd64"
GOHOSTOS="linux"
GOOS="linux"
GOPATH="/mnt/Gopath"
GORACE=""
GOROOT="/usr/local/go"
GOTOOLDIR="/usr/local/go/pkg/tool/linux_amd64"
GO15VENDOREXPERIMENT="1"
CC="gcc"
GOGCCFLAGS="-fPIC -m64 -fmessage-length=0"
CXX="g++"
CGO_ENABLED="0"

```
1. What did you do?
   If possible, provide a recipe for reproducing the error.

Program does not have any errors, it seems this is tidb certain default settings?
1. What did you expect to see?

```
http://inchina.xin:8000/topic/1/
http://inchina.xin:8000/topic/2/
http://inchina.xin:8000/topic/3/
http://inchina.xin:8000/topic/4/
```
1. What did you see instead?

I use tidb inside a Web application based on golevedb. I found the data row ID to 1000 range for growth.
Like this:

```
http://inchina.xin:8000/topic/1/
http://inchina.xin:8000/topic/1001/
http://inchina.xin:8000/topic/2001/
http://inchina.xin:8000/topic/4001/
```
 @shenli I can probably guess are designed to performance.
However, this figure could one day grow to very large it? that can't afford it?
 @shenli Then, this figure can I change it? 
 @shenli Well, thanks for your answer!
   @zxylvlp @shenli Thanks for pointing it out, I will fix it later.
 @shenli @zxylvlp PTAL
Did i miss something?
 Thanks, I will rebase this PR on master soon.
  LGTM
  LGTM
 Sorry, I missed this case, 
  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1110) <br/>All committers have accepted the CLA.
  Fix the incorrect behavior of `substring` function, multi-byte charset still hasn't been supported.
  For issue https://github.com/pingcap/tidb/issues/1037
 [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1099) <br/>All committers have accepted the CLA.
 PTAL, @shenli @coocood 
 All comments have been revised, PTAL ag, @coocood @shenli @zimulala @c4pt0r 
 PTAL ag, @zimulala @coocood 
 @zimulala , SELECT operations will call `Seek`, also, user UPDATE operations are not supported for `events_xxx` tables.

Refer to `perfschema_test.go` and `memory_tables_test.go`.
 sure, @ngaut 
 @ngaut , squashed and rebased
  It should be `if pos > int64(len(str)) || pos < int64(0) {` [here](https://github.com/pingcap/tidb/blob/master/evaluator/builtin_string.go#L295), otherwise `substring(s, 1)` always return an empty string. Beside, I see that the code doesn't handle the charset of the string for now, which leads to following result:

```
mysql> select substring("你好世界", 1, 3);
+---------------------------------+
| substring("你好世界", 1, 3)     |
+---------------------------------+
| 你                              |
+---------------------------------+
1 row in set (0.00 sec)

```

I'm willing to help, however, I'm not sure how to get the charset info from the context of such a builtin function call.

---
1. What version of Go are you using (`go version`)?
   go1.6
2. What operating system and processor architecture are you using (`go env`)?
   GOHOSTARCH="amd64"
   GOHOSTOS="linux"
3. What did you do?
   exec `select substring("hello", 1, 5);`
4. What did you expect to see?

```
+--------------------------+
| substring("hello", 1, 5) |
+--------------------------+
| hello                    |
+--------------------------+
```
1. What did you see instead?

```
+--------------------------+
| substring("hello", 1, 5) |
+--------------------------+
|                          |
+--------------------------+
```
 Thanks for your reply, @shenli .

I see, buitin functions only accept an array of `types.Datum` as the input.
https://github.com/pingcap/tidb/blob/master/evaluator/evaluator.go#L647

However, the charset/collation info is stored in the `exprNode.Type` field. Thus, there is (maybe) no way for us to get the info within these builtin functions currently (I thought we can get it from the `Context`). I think it might be better to pass datums as well as their types to a FuncCall.
  Hi, I'm reading the source code and willing to help to implement some basic builtin functions. However, I'm not sure if I did things right. Please correct me if I made mistake.
 [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1083) <br/>All committers have accepted the CLA.
 @shenli Sorry, I forgot it.
 Ok, I put it there because of [sql_yacc.yy](https://github.com/twitter/mysql/blob/master/sql/sql_yacc.yy). I'll fix it later.
 @shenli I see `COALESCE` is a nonreserved keyword according to https://dev.mysql.com/doc/refman/5.7/en/keywords.html. However, it appears in `NotKeywordToken` in  https://github.com/pingcap/tidb/blob/master/parser/parser.y. I'm a little confused.
 @shenli Sure! zhongyangguan@gmail.com
 @ngaut Yes, Of course! Wait a minute.
  [![CLA assistant check](https://cla-assistant.io/pull/badge/not_signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1081) <br/>You should sign our Contributor License Agreement in order to get your pull request merged.<br/><hr/>**Fei Han** seems not to be a GitHub user. You need a GitHub account to be able to sign the CLA. If you have already a GitHub account, please add the email address used for this commit to your account ([for further information, click here](https://help.github.com/articles/why-are-my-commits-linked-to-the-wrong-user/#commits-are-not-linked-to-any-user)).
  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1070) <br/>All committers have accepted the CLA.
  Is there any plan to support `ON [DELETE|CREATE]` for constraints in the future
since they are helpful to ensure integrity ?

Also currently if you for example design a schema with Mysql Workbench or similar tools,
the exported SQL may be incompatible with TIDB because tidb's SQL parser isn't aware of these keywords, so that would also be an improvement in
terms of compatibility.

[1] http://dev.mysql.com/doc/refman/5.7/en/create-table-foreign-keys.html
 @ngaut 
Am I right that currently foreign keys are supported by the parser and simply
ignored during anything related to storage?
If so, wouldn't it be advisable to also support the `ON [DELETE|UPDATE]` syntax
atleast in the parser to be able to use common mysql tools?
 @shenli 
Of course it does work with Workbench for common tasks.
But my point is that if you're using workbench (or any other tool exporting the mysql dialect)
to design a database, workbench may generate `ON [DELETE|UPDATE]` clauses,
which therefore require manual patching of the generated SQL to prevent that tidb throws an error 
(since these keywords are unknown in that context) to create the database.
  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1062) <br/>All committers have accepted the CLA.
  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1052) <br/>All committers have accepted the CLA.
  [![CLA assistant check](https://cla-assistant.io/pull/badge/signed)](https://cla-assistant.io/pingcap/tidb?pullRequest=1049) <br/>All committers have accepted the CLA.
  see issue #1046 

Thanks @shenli , you guys are awesome!
 @shenli PTAL

cc @c4pt0r 
  see issue: #236.
 @shenli Hi, and yes, I have just added a new builtin function, it is a PR not issue. Maybe I should change title to **Add UTC_DATE()**?
 @shenli @qiuyesuifeng PTAL
 Squashed. @shenli @qiuyesuifeng 

cc @c4pt0r 
 PTAL
  @coocood we will handle it next week after finished current coprocessor demo works.
 Used `BoundedTable` (implemented in fixed-size array) to replace `MemoryTable` for statistics tables, include:
- `EVENTS_STATEMENTS_CURRENT`
- `EVENTS_STATEMENTS_HISTORY`
- `EVENTS_STATEMENTS_HISTORY_LONG`
- `PREPARED_STATEMENTS_INSTANCES`
- `EVENTS_TRANSACTIONS_CURRENT`
- `EVENTS_TRANSACTIONS_HISTORY`
- `EVENTS_TRANSACTIONS_HISTORY_LONG`
- `EVENTS_STAGES_CURRENT`
- `EVENTS_STAGES_HISTORY`
- `EVENTS_STAGES_HISTORY_LONG`
 @coocood , one you confirm `sqllogicaltest` is ok, I can close this issue.
    LGTM, but could you plz give us an intuitive example to demonstrate how the new method `PartialNext` used for?
  LGTM
  /Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/bin/java -ea -Didea.launcher.port=7533 "-Didea.launcher.bin.path=/Applications/IntelliJ IDEA 14.app/Contents/bin" -Dfile.encoding=UTF-8 -classpath "/Applications/IntelliJ IDEA 14.app/Contents/lib/idea_rt.jar:/Applications/IntelliJ IDEA 14.app/Contents/plugins/junit/lib/junit-rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/tools.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/tmp/classes/test/waimai100_backend:/Users/cppmule/idea-workspace/waimai100_backend/trunk/tmp/classes/production/waimai100_backend:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/jjwt-0.4.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/asm-5.0.3.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/cglib-3.1.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/guava-18.0.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/ognl-2.6.9.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/okio-1.3.0.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/dozer-5.3.2.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/httpmime-4.5.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/jsr305-1.3.9.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/okhttp-2.3.0.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/fluent-hc-4.5.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/httpclient-4.5.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/httpcore-4.4.1.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/hamcrest-all-1.3.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/mockito-all-1.9.5.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/pingpp-java-2.1.1.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/assertj-core-3.2.0.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/jackson-core-2.4.2.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/unitils-core-3.4.2.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/bcprov-jdk15on-1.51.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/qiniu-java-sdk-7.0.3.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/weixin-java-mp-1.3.1.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/commons-httpclient-3.1.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/jackson-databind-2.4.2.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/weixin-java-common-1.3.1.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/lib/jackson-annotations-2.4.0.jar:/Users/cppmule/dev-tools/play-1.3.1/modules/docviewer/lib/play-docviewer.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/modules/mockito-0.1/lib/play-mockito.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/modules/mockito-0.1/lib/mockito-all-1.9.1-SNAPSHOT.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/modules/spring-1.0.3/lib/ant-1.7.0.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/modules/spring-1.0.3/lib/play-spring.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/modules/spring-1.0.3/lib/jsr166-1.7.0.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/modules/spring-1.0.3/lib/jopt-simple-3.0.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/modules/spring-1.0.3/lib/ant-launcher-1.7.0.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/modules/spring-1.0.3/lib/spring-aop-3.1.1.RELEASE.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/modules/spring-1.0.3/lib/spring-asm-3.1.1.RELEASE.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/modules/spring-1.0.3/lib/spring-core-3.1.1.RELEASE.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/modules/spring-1.0.3/lib/spring-beans-3.1.1.RELEASE.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/modules/spring-1.0.3/lib/spring-context-3.1.1.RELEASE.jar:/Users/cppmule/idea-workspace/waimai100_backend/trunk/modules/spring-1.0.3/lib/spring-expression-3.1.1.RELEASE.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/ivy-2.4.0.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/oval-1.84.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/c3p0-0.9.5.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/gson-2.3.1.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/h2-1.4.185.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/jamon-2.81.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/jj-imaging.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/jj-textile.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/junit-4.12.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/mail-1.4.7.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/antlr-2.7.7.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/dom4j-1.6.1.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/jaxen-1.1.6.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/jj-wikitext.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/log4j-1.2.17.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/asm-all-5.0.3.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/ezmorph-1.0.6.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/joda-time-2.7.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/jregex-1.2_01.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/xstream-1.4.7.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/commons-io-2.4.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/postgresql-9.0.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/snakeyaml-1.15.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/cglib-nodep-3.1.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/jsr107cache-1.0.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/xmlpull-1.1.3.1.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/activation-1.1.1.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/commons-lang-2.6.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/groovy-all-2.3.9.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/javax.inject-1.0.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/jj-simplecaptcha.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/slf4j-api-1.7.10.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/bcprov-jdk15-1.45.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/hamcrest-core-1.3.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/netty-3.9.4.Final.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/commons-codec-1.10.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/commons-email-1.3.3.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/commons-logging-1.2.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/ehcache-core-2.6.11.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/javassist-3.19.0-GA.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/spymemcached-2.11.7.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/slf4j-log4j12-1.7.10.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/signpost-core-1.2.1.2.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/jboss-logging-3.1.0.GA.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/commons-beanutils-1.8.3.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/validation-api-1.0.0.GA.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/async-http-client-1.8.14.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/commons-fileupload-1.3.1.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/commons-javaflow-1590792.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/commons-collections-3.2.1.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/mchange-commons-java-0.2.9.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/hibernate-c3p0-4.2.15.Final.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/hibernate-core-4.2.15.Final.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/mysql-connector-java-5.1.35.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/c3p0-oracle-thin-extras-0.9.5.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/geronimo-servlet_2.5_spec-1.2.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/hibernate-validator-4.1.0.Final.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/hibernate-jpa-2.0-api-1.0.1.Final.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/hibernate-entitymanager-4.2.15.Final.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/hibernate-commons-annotations-4.0.2.Final.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/jboss-transaction-api_1.1_spec-1.0.1.Final.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/org.eclipse.jdt.core-3.10.0.v20140604-1726.jar:/Users/cppmule/dev-tools/play-1.3.1/framework/play-1.3.1.jar" com.intellij.rt.execution.application.AppMain com.intellij.rt.execution.junit.JUnitStarter -ideVersion5 models.FoodOrderTest
13:54:58,194 INFO  ~ Starting /Users/cppmule/idea-workspace/waimai100_backend/trunk/.
:: loading settings :: url = jar:file:/Users/cppmule/dev-tools/play-1.3.1/framework/lib/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
13:54:59,015 INFO  ~ Module spring is available (/Users/cppmule/idea-workspace/waimai100_backend/trunk/./modules/spring-1.0.3)
13:54:59,016 INFO  ~ Module mockito is available (/Users/cppmule/idea-workspace/waimai100_backend/trunk/./modules/mockito-0.1)
13:55:00,999 WARN  ~ You're running Play! in DEV mode
13:55:19,770 ERROR ~ Database [default] Cannot connected to the database : An attempt by a client to checkout a Connection has timed out.
java.sql.SQLException: An attempt by a client to checkout a Connection has timed out.
    at com.mchange.v2.sql.SqlUtils.toSQLException(SqlUtils.java:118)
    at com.mchange.v2.sql.SqlUtils.toSQLException(SqlUtils.java:77)
    at play.db.DBPlugin.onApplicationStart(DBPlugin.java:183)
    at play.plugins.PluginCollection.onApplicationStart(PluginCollection.java:515)
    at play.Play.start(Play.java:537)
    at play.test.PlayJUnitRunner.<init>(PlayJUnitRunner.java:38)
    at org.junit.internal.builders.AnnotatedBuilder.buildRunner(AnnotatedBuilder.java:104)
    at org.junit.internal.builders.AnnotatedBuilder.runnerForClass(AnnotatedBuilder.java:86)
    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)
    at org.junit.internal.builders.AllDefaultPossibilitiesBuilder.runnerForClass(AllDefaultPossibilitiesBuilder.java:26)
    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)
    at org.junit.internal.requests.ClassRequest.getRunner(ClassRequest.java:33)
    at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:41)
    at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:212)
    at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:68)
    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
Caused by: com.mchange.v2.resourcepool.TimeoutException: A client timed out while waiting to acquire a resource from com.mchange.v2.resourcepool.BasicResourcePool@29896529 -- timeout at awaitAvailable()
    at com.mchange.v2.resourcepool.BasicResourcePool.awaitAvailable(BasicResourcePool.java:1461)
    at com.mchange.v2.resourcepool.BasicResourcePool.prelimCheckoutResource(BasicResourcePool.java:639)
    at com.mchange.v2.resourcepool.BasicResourcePool.checkoutResource(BasicResourcePool.java:549)
    ... 14 more

play.exceptions.DatabaseException: Cannot connected to the database[default], An attempt by a client to checkout a Connection has timed out.
    at play.db.DBPlugin.onApplicationStart(DBPlugin.java:200)
    at play.plugins.PluginCollection.onApplicationStart(PluginCollection.java:515)
    at play.Play.start(Play.java:537)
    at play.test.PlayJUnitRunner.<init>(PlayJUnitRunner.java:38)
    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
    at org.junit.internal.builders.AnnotatedBuilder.buildRunner(AnnotatedBuilder.java:104)
    at org.junit.internal.builders.AnnotatedBuilder.runnerForClass(AnnotatedBuilder.java:86)
    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)
    at org.junit.internal.builders.AllDefaultPossibilitiesBuilder.runnerForClass(AllDefaultPossibilitiesBuilder.java:26)
    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)
    at org.junit.internal.requests.ClassRequest.getRunner(ClassRequest.java:33)
    at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:41)
    at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:212)
    at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:68)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
Caused by: java.sql.SQLException: An attempt by a client to checkout a Connection has timed out.
    at com.mchange.v2.sql.SqlUtils.toSQLException(SqlUtils.java:118)
    at com.mchange.v2.sql.SqlUtils.toSQLException(SqlUtils.java:77)
    at play.db.DBPlugin.onApplicationStart(DBPlugin.java:183)
    at play.plugins.PluginCollection.onApplicationStart(PluginCollection.java:515)
    at play.Play.start(Play.java:537)
    at play.test.PlayJUnitRunner.<init>(PlayJUnitRunner.java:38)
    at org.junit.internal.builders.AnnotatedBuilder.buildRunner(AnnotatedBuilder.java:104)
    at org.junit.internal.builders.AnnotatedBuilder.runnerForClass(AnnotatedBuilder.java:86)
    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)
    at org.junit.internal.builders.AllDefaultPossibilitiesBuilder.runnerForClass(AllDefaultPossibilitiesBuilder.java:26)
    at org.junit.runners.model.RunnerBuilder.safeRunnerForClass(RunnerBuilder.java:59)
    at org.junit.internal.requests.ClassRequest.getRunner(ClassRequest.java:33)
    at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:68)
    ... 1 more
Caused by: com.mchange.v2.resourcepool.TimeoutException: A client timed out while waiting to acquire a resource from com.mchange.v2.resourcepool.BasicResourcePool@29896529 -- timeout at awaitAvailable()
    at com.mchange.v2.resourcepool.BasicResourcePool.awaitAvailable(BasicResourcePool.java:1461)
    at com.mchange.v2.resourcepool.BasicResourcePool.prelimCheckoutResource(BasicResourcePool.java:639)
    at com.mchange.v2.resourcepool.BasicResourcePool.checkoutResource(BasicResourcePool.java:549)
    ... 14 more

Process finished with exit code 255
  you miss the `-` before `[ ]`
- [ ] beego
- [ ] xorm
- [ ] gorm
  ....
  CREATE TABLE `test_data` (
    `id` bigint(20) NOT NULL AUTO_INCREMENT,
    `create_at` datetime NOT NULL,
    `deleted` tinyint(1) NOT NULL,
    `update_at` datetime NOT NULL,
    `version` bigint(20) DEFAULT NULL,
    `address` varchar(255) NOT NULL,
    `amount` decimal(19,2) DEFAULT NULL,
    `charge_id` varchar(32) DEFAULT NULL,
    `paid_amount` decimal(19,2) DEFAULT NULL,
    `transaction_no` varchar(64) DEFAULT NULL,
    `wx_mp_app_id` varchar(32) DEFAULT NULL,
    `contacts` varchar(50) DEFAULT NULL,
    `deliver_fee` decimal(19,2) DEFAULT NULL,
    `deliver_info` varchar(255) DEFAULT NULL,
    `deliver_time` varchar(255) DEFAULT NULL,
    `description` varchar(255) DEFAULT NULL,
    `invoice` varchar(255) DEFAULT NULL,
    `order_from` int(11) DEFAULT NULL,
    `order_state` int(11) NOT NULL,
    `packing_fee` decimal(19,2) DEFAULT NULL,
    `payment_time` datetime DEFAULT NULL,
    `payment_type` int(11) DEFAULT NULL,
    `phone` varchar(50) NOT NULL,
    `store_employee_id` bigint(20) DEFAULT NULL,
    `store_id` bigint(20) NOT NULL,
    `user_id` bigint(20) NOT NULL,
    `payment_mode` int(11) NOT NULL,
    `current_latitude` double NOT NULL,
    `current_longitude` double NOT NULL,
    `address_latitude` double NOT NULL,
    `address_longitude` double NOT NULL,
    PRIMARY KEY (`id`),
    CONSTRAINT `food_order_ibfk_1` FOREIGN KEY (`user_id`) REFERENCES `waimaiqa`.`user` (`id`),
    CONSTRAINT `food_order_ibfk_2` FOREIGN KEY (`store_id`) REFERENCES `waimaiqa`.`store` (`id`),
    CONSTRAINT `food_order_ibfk_3` FOREIGN KEY (`store_employee_id`) REFERENCES `waimaiqa`.`store_employee` (`id`),
    UNIQUE `FK_UNIQUE_charge_id` USING BTREE (`charge_id`) comment '',
    INDEX `FK_eqst2x1xisn3o0wbrlahnnqq8` USING BTREE (`store_employee_id`) comment '',
    INDEX `FK_8jcmec4kb03f4dod0uqwm54o9` USING BTREE (`store_id`) comment '',
    INDEX `FK_a3t0m9apja9jmrn60uab30pqd` USING BTREE (`user_id`) comment ''
) ENGINE=`InnoDB` AUTO_INCREMENT=95 DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci ROW_FORMAT=COMPACT COMMENT='' CHECKSUM=0 DELAY_KEY_WRITE=0;
  version: Master.
I am using navcat to transfer database from remote to localhost. I got an error:

[Msg] [Dtf] Datatransfer started
[Msg] [Dtf] Gather Information
[Msg] [Dtf] Drop table: `address`
[Msg] [Dtf] Get table data for `address`
[Msg] [Dtf] Create table: `address`
[Err] [Dtf] Transfer Data [CREATE TABLE `address` (
    `id` bigint(20) NOT NULL AUTO_INCREMENT,
    `create_at` datetime NOT NULL,
    `deleted` tinyint(1) NOT NULL,
    `update_at` datetime NOT NULL,
    `version` bigint(20) DEFAULT NULL,
    `address` varchar(128) NOT NULL,
    `address_detail` varchar(128) NOT NULL,
    `cellphone` varchar(16) NOT NULL,
    `latitude` double NOT NULL,
    `longitude` double NOT NULL,
    `name` varchar(16) NOT NULL,
    `sex` tinyint(1) NOT NULL,
    `user_id` bigint(20) NOT NULL,
    PRIMARY KEY (`id`),
    CONSTRAINT `FK_7rod8a71yep5vxasb0ms3osbg` FOREIGN KEY (`user_id`) REFERENCES `waimaiqa`.`user` (`id`),
    INDEX `FK_7rod8a71yep5vxasb0ms3osbg` (`user_id`) comment ''
) ENGINE=`InnoDB` AUTO_INCREMENT=30 DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci ROW_FORMAT=COMPACT COMMENT='' CHECKSUM=0 DELAY_KEY_WRITE=0;]:
line 17 column 51 near "comment"
## [Err] [Dtf] Terminated
  # Init schema
# --- !Ups
## -- MySQL dump 10.13  Distrib 5.6.15, for osx10.7 (x86_64)

-- Host: localhost    Database: waimai

---

-- Server version       5.6.15

/_!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/_!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS _/;
/_!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION _/;
/_!40101 SET NAMES utf8 _/;
/_!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE _/;
/_!40103 SET TIME_ZONE='+00:00' _/;
/_!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 _/;
/_!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 _/;
/_!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' _/;
/_!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;
## 
## -- Table structure for table `admin`

DROP TABLE IF EXISTS `admin`;
/_!40101 SET @saved_cs_client     = @@character_set_client */;
/_!40101 SET character_set_client = utf8 */;
  DROP TABLE IF EXISTS `admin_rule`;
/_!40101 SET @saved_cs_client     = @@character_set_client */;
/_!40101 SET character_set_client = utf8 _/;
CREATE TABLE `admin_rule` (
  `rule_id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT 'Rule ID',
  `role_id` int(10) unsigned NOT NULL DEFAULT '0' COMMENT 'Role ID',
  `resource_id` varchar(255) NOT NULL COMMENT 'Resource ID',
  `privileges` varchar(20) DEFAULT NULL COMMENT 'Privileges',
  `assert_id` int(10) unsigned NOT NULL DEFAULT '0' COMMENT 'Assert ID',
  `role_type` varchar(1) DEFAULT NULL COMMENT 'Role Type',
  `permission` varchar(10) DEFAULT NULL COMMENT 'Permission',
  PRIMARY KEY (`rule_id`),
  KEY `IDX_ADMIN_RULE_RESOURCE_ID_ROLE_ID` (`resource_id`,`role_id`),
  KEY `IDX_ADMIN_RULE_ROLE_ID_RESOURCE_ID` (`role_id`,`resource_id`),
  CONSTRAINT `FK_ADMIN_RULE_ROLE_ID_ADMIN_ROLE_ROLE_ID` FOREIGN KEY (`role_id`) REFERENCES `admin_role` (`role_id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB AUTO_INCREMENT=1636 DEFAULT CHARSET=utf8 COMMENT='Admin Rule Table';
/_!40101 SET character_set_client = @saved_cs_client */;
  LGTM
  **columnValue** is an int64 type variable, and **value** type is Datum
  Support creating an index the same as the column name
https://github.com/pingcap/tidb/issues/946
  Mysql support this feature
I found the following code in the function buildIndexInfo
`
    for _, col := range tblInfo.Columns {
        if col.Name.L == indexName.L {
            return nil, errors.Errorf("CREATE INDEX: index name collision with existing column: %s", indexName)
        }
    }
`
This code can be removed?
 Ok, I will try
  Looks like we don't need `perfschema/common.go` any more.
 Also, `setup_xxx` tables and `events_xxx` tables need to restrict access permissions:
1. All tables support `SELECT` operation
2. `events_xxx` tables support `TRUNCATE` only
3. `setup_timers`, `setup_consumers` and `setup_instruments` support `UPDATE` only
4. `setup_actors`, `setup_objects` support `INSERT`, `DELETE` and `TRUNCATE` only

For operations not supported, an error message should be prompted to user.
 @shenli If the change is not too much, can we finish in this PR? at least we can restrict all tables support `SELECT` only first to avoid faulty operations.
 @shenli If the privilege system feature is not implemented yet, I agree it can be implemented in the future PR.

LGTM 
   @shenli what i mean , if I can use tidb as embedded db in go, and use mysql client to visit the db to check the db at the same time

我的意思是在嵌入式使用的同时,能够通过客户端访问数据库 以查看数据.
  Your neighbor CockroachDB even has a [repo](https://github.com/cockroachdb/docs) just for their docs.
  Initial support for statement instruments, I checked the implementation of MySQL 5.7 and traces of CockroachDB, and finally I decide to implement a simple version first, it's simple, but it can be used just like MySQL's.
 PTAL also, @shenli @qiuyesuifeng 
 PTAL ag, @qiuyesuifeng @ngaut 
 @ngaut @qiuyesuifeng , address comments merged, PTAL.
  I have two questions:
1. All perfschema tables support `SELECT` operations, but some tables support different operations, such as, `setup_timers` table support `UPDATE` only, `events_xxx` tables support `TRUNCATE` only, how to code w/ memory tables?
2. How to use `table.Table` interface to simulate `UPDATE` operation?
 LGTM，after discussed w/ @shenli , I will add another special memory table for events_xxx tables once the instrumentation efficiency is really a problem.
  Support `INSERT` operation for `setup_actors` & `setup_objects`, other tables are `UPDATE` only.
 PTAL @shenli @qiuyesuifeng 
  when i download the latest code from master branch, and execute make command:

it reports error like this:

store/hbase/kv.go:207: too many arguments in call to oracles.NewRemoteOracle
godep: go exit status 2

could you guys shed some light on this?
 @shenli it solved after executing "make update"

Thanks
  Require an explicit usage of int64 for `MinInt64` as constant.

```
optimizer\plan\range.go:467: constant -9223372036854775808 overflows int
optimizer\plan\range.go:484: constant -9223372036854775808 overflows int
optimizer\plan\range.go:486: constant 9223372036854775807 overflows int
```

This fixes compilation on systems where `int` doesn't default to int64.
 @coocood done :)
  This essentially allows users of the "tidb" driver insteadof the mysql protocol
to decide on their own if they want to use the string form of a `mysql.Time`
or prefer working with the internal `time.Time` object, which should also reduce a tiny bit
of overhead for these cases.

Since mysql.Time.String() only access the time.Time object and doesn't depend
on any other internal data at the moment, this should be safe.
 @coocood 
seems like I missed that `fsp` part, and im unsure how important it is, 
since you do not really need this information: 
you can get up to nanosecond precision and anyways know how you defined the column
schema-wise.
So using `time.Time` would actually be more flexible for you.

for `mysql.Date` and `mysql.Time` it should not matter, since the needed information is
stored in the `time.Time` object regardless of the underlying implementation.

Is there anything unclear or something I'm missing or 
maybe even an implementation, which allows the same flexibility with more functionality?
 @coocood 
the reasoning behind this is flexibility:
if the driver outputs a `string`, I have to parse it manually each time. 
(which includes overhead of time -> string -> time)

If the driver outputs a `time`, I can decide whether I want to scan it into a `Time` or a `string`,
or perform any conversion or time specific function to it.

If the precision is so important, which I do not really see for any practical project,
another solution would be to just return a `mysql.Time`, which allows a similar
amount of flexibility but would probably require a manual call of `.String()` since `.Scan` 
won't support these cases.

Is that something you think would be better?
 Adapting the behavior of mysqls driver is also a possibility, I'll look into it soon.
 @coocood implemented and working
  hard to split into 2 PRs for `SELECT` only, revised support for `SELECT` functions:
1. using goleveldb instead of map only for concurrent considerations (INSERT/DELETE/UPDATE/TRUNCATE).
2. code refactoring.
 Really appreciate ur careful review and quick response.
  Code refactoring:
1. remove the implementation from `plan/plans`.
2. add `perfschema/const.go` and `perfschema/common/go`

PTAL, @shenli @coocood 
  I refactored the code and added INSERT support, unfortunately the `SELECT` returned garbled characters, I got a headache today and can't find out what happened so far.

@qiuyesuifeng @shenli @coocood , please review first since this PR is a little bit big, I will continue working on fixing it.
 Thanks @coocood @shenli , I have solved the garbled characters problem, will split this PR and open several new PRs.
  Is this feature done or any alternative？  All `performance_schema` tables created FOR `SELECT` only.
  Authentication passed when given any username with an empty password.
 Sorry, i don't know how to do this.
 is that ok?
  In the process of testing TPCC, I find a bug. If the index's column>=3,tidb can't use index scan.
like this:

``` bash
mysql>  SELECT c_first, c_middle, c_last, c_street_1, c_street_2, c_city, c_state, c_zip, c_phone, c_credit, c_credit_lim, c_discount, c_balance, c_since FROM customer WHERE c_w_id = 1 AND c_d_id = 4 AND c_id = 2250;
+---------------+----------+--------------+----------------+---------------+----------------------+---------+-----------+------------------+----------+--------------+------------+-----------+---------------------+
| c_first       | c_middle | c_last       | c_street_1     | c_street_2    | c_city               | c_state | c_zip     | c_phone          | c_credit | c_credit_lim | c_discount | c_balance | c_since             |
+---------------+----------+--------------+----------------+---------------+----------------------+---------+-----------+------------------+----------+--------------+------------+-----------+---------------------+
| crxXDlgcTvLua | OE       | EINGCALLYESE | zckcHksOpSZLqm | SctxnccP5Xix6 | UX34HdLzWiowH7n23Deu | RW      | 256136851 | 3231895072206302 | BC       |        50000 |       0.25 |    -10.00 | 2016-01-15 10:20:46 |
+---------------+----------+--------------+----------------+---------------+----------------------+---------+-----------+------------------+----------+--------------+------------+-----------+---------------------+
1 row in set (11 min 7.03 sec)
```

this query execute 11min，table customer has primary key (c_id,c_d_id,c_w_id), obviously the query use table scan and get all record of table customer.

I write a simple example to describe this bug:
1,create table
create table t1(a int,b int,c int,d int,e int,primary key(a,b,c));
2,insert record
insert into t1 values(1,1,1,1,1),(2,2,2,2,2),(3,3,3,3,3),(4,4,4,4,4);
3,execute query
select \* from t1 where a=2 and b=2 and c=2;

In the step 3, we can find tidb get all records from t1, the query use table scan instead of index scan. It should use index scan.

I trace the code and print log. I think the bug is caused by splitWhere in planbuilder.go:

``` bash
--- a/optimizer/plan/planbuilder.go
+++ b/optimizer/plan/planbuilder.go
@@ -216,8 +216,8 @@ func (b *planBuilder) splitWhere(where ast.ExprNode) []ast.ExprNode {
        switch x := where.(type) {
        case *ast.BinaryOperationExpr:
                if x.Op == opcode.AndAnd {
-                       conditions = append(conditions, x.L)
-                       conditions = append(conditions, b.splitWhere(x.R)...)
+                       conditions = append(conditions, x.R)
+                       conditions = append(conditions, b.splitWhere(x.L)...)
                } else {
                        conditions = append(conditions, x)
                }
```

In the parser.y, expressions in where clause is parsed in left prec, so where a=2 and b=2 and c=2 is parsed into ((a=2 and b=2) and c=2), x.L may be a multi-expression like opcode.AndAnd. x.R is a single expression. splitWhere should return conditions like (a=2) (b=2) (c=2).
  I think it is hard to know what the code mean without docs.
Please add the arch of the project.
It is bad to pre-contributor.
 @shenli 
Thx for your reply.
    fix the issue https://github.com/pingcap/tidb/issues/845
 @qiuyesuifeng good catch. Here we go https://github.com/astaxie/tidb/commit/2ca2c8e61b150ff09b89cfd8a6ba4f9343580960
 @disksing :see_no_evil: updated
  As tidb become more popular, I think tidb need to add contributing guidelines. That explains how a participant should do things like format code, test fixes, and submit patches.

Here is the introduce: https://github.com/blog/1184-contributing-guidelines

Here is the beego's guide: https://github.com/astaxie/beego/blob/develop/CONTRIBUTING.md
 You need to place the file in the root directory. otherwise these's no tips when create issues or pull request.
  I've got an error When i run tpcc-mysql benchmark. I found the error is arised by mysql_stmt_bind_result.
when the result column is varchar，the error occured:
 **mysql_stmt_bind_result() failed**
 **Using unsupported buffer type: 15  (parameter: 1)**

the code which like this:

``` c
  /* RESULT */
  result[0].buffer_type = MYSQL_TYPE_STRING;
  //result[0].buffer_type = MYSQL_TYPE_VAR_STRING;
  //result[0].buffer_type = MYSQL_TYPE_VARCHAR;
  result[0].buffer = b;
  result[0].buffer_length = sizeof(b);
```

I try to chang the buffer_type to MYSQL_TYPE_VAR_STRING or MYSQL_TYPE_VARCHAR, there's still same error. But when i change the result column's define to char, the error is disapper, test case works well.

We can follow this steps to get the error:
1,start tidb.
tidb-server -store hbase -P 5000 -L debug  -path localhost/testdb

2,create a table in mysql database and insert a row
create table t1(a int, b varchar(20));
insert into t1 values(1,'tidb');

3,run test
compile test.c: 
gcc -o test test.c -I/usr/include/mysql -L/usr/lib/x86_64-linux-gnu -lmysqlclient
run test: 
 ./test -h127.0.0.1 -P5000 -dmysql -uroot
code of test.c as below:

``` c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <string.h>
#include <sys/time.h>
#include <fcntl.h>

#include <mysql.h>

#define DB_STRING_MAX 128

int main( int argc, char *argv[] )
{
  int c;
  int port= 3306;
  MYSQL_STMT *stmt;
  char *sql;
  MYSQL *mysql;
  MYSQL_BIND param[2], result[6];
  char connect_string[DB_STRING_MAX];
  char db_string[DB_STRING_MAX];
  char db_host[DB_STRING_MAX];
  char db_user[DB_STRING_MAX];
  char db_password[DB_STRING_MAX];
  char b[20];
  long r_w_id;
  int a = 1;

  memset(db_password, 0, sizeof(db_password));
  while ( (c = getopt(argc, argv, "h:d:u:p:P:a:b:")) != -1) {
        switch (c) {
        case 'h':
            printf ("option h with value '%s'\n", optarg);
            strncpy(connect_string, optarg, DB_STRING_MAX);
            break;
        case 'd':
            printf ("option d with value '%s'\n", optarg);
            strncpy(db_string, optarg, DB_STRING_MAX);
            break;
        case 'u':
            printf ("option u with value '%s'\n", optarg);
            strncpy(db_user, optarg, DB_STRING_MAX);
            break;
        case 'p':
            printf ("option p with value '%s'\n", optarg);
            strncpy(db_password, optarg, DB_STRING_MAX);
            break;
        case 'P':
            printf ("option P with value '%s'\n", optarg);
            port = atoi(optarg);
            break;
        default:
            printf ("?? getopt returned character code 0%o ??\n", c);
        }
    }

  mysql = mysql_init(NULL);

   /* Here we make the connection to MySQL */
  if (mysql_real_connect(mysql, connect_string, db_user, db_password, db_string, port, NULL, 0) == NULL) {
    fprintf(stderr, "No connection could be made to the database\n");
    exit(EXIT_FAILURE);
  }
  printf("connect complete!\n");

  sql = "SELECT b FROM t1 WHERE a = ?";

  /* Initialize our statement */
  stmt = mysql_stmt_init(mysql);
  if (!stmt) {
    fprintf(stderr, " mysql_stmt_init(), out of memory\n");
    exit(EXIT_FAILURE);
  }

  if (mysql_stmt_prepare(stmt, sql, strlen(sql))) {
    fprintf(stderr, " mysql_stmt_prepare(), INSERT failed\n");
    fprintf(stderr, " %s\n", mysql_stmt_error(stmt));
    exit(EXIT_FAILURE);
  }
  printf("prepare complete!\n");

  /* Zero out both the param and result data structures */
  memset(param, 0, sizeof(param));
  memset(result, 0, sizeof(result));

  /* PARAM */
  param[0].buffer_type = MYSQL_TYPE_LONG;
  param[0].buffer = &a;

  /* RESULT */
  result[0].buffer_type = MYSQL_TYPE_STRING;
  //result[0].buffer_type = MYSQL_TYPE_VAR_STRING;
  //result[0].buffer_type = MYSQL_TYPE_VARCHAR;
  result[0].buffer = b;
  result[0].buffer_length = sizeof(b);

  /* Bind the parameters buffer */
  if (mysql_stmt_bind_param(stmt, param)) {
    fprintf(stderr, " mysql_stmt_bind_param() failed\n");
    fprintf(stderr, " %s\n", mysql_stmt_error(stmt));
    exit(EXIT_FAILURE);
  }
  printf("bind param complete!\n");

  /* Execute the statement */
  if (mysql_stmt_execute(stmt)) {
    fprintf(stderr, " mysql_stmt_execute(), failed\n");
    fprintf(stderr, " %s\n", mysql_stmt_error(stmt));
    exit(EXIT_FAILURE);
  }
  printf("execute complete!\n");

  /* Store result */
  if (mysql_stmt_store_result(stmt)) {
    fprintf(stderr, " mysql_stmt_store_result() failed\n");
    fprintf(stderr, " %s\n", mysql_stmt_error(stmt));
    exit(EXIT_FAILURE);
  }
  printf("store result complete!\n");

  /* Bind the results buffer */
  if (mysql_stmt_bind_result(stmt, result) != 0) {
    fprintf(stderr, " mysql_stmt_bind_result() failed\n");
    fprintf(stderr, " %s\n", mysql_stmt_error(stmt));
    exit(EXIT_FAILURE);
  }
  printf("bind result complete!\n");



  /* Print our results */
  if(mysql_stmt_fetch (stmt) == 0) {
    printf("%s\n", b);
  } else {
    printf("No results found!\n");
  }
  printf("fetch complete!\n");

  mysql_stmt_free_result(stmt);

  /* Close the statement */
  if (mysql_stmt_close(stmt)) {
    fprintf(stderr, " failed while closing the statement\n");
    fprintf(stderr, " %s\n", mysql_stmt_error(stmt));
    exit(EXIT_FAILURE);
  }

 exit(EXIT_SUCCESS);
```

ps:
when i modify the column b's type to char, the test can work well:
create table t1(a int, b char(20));
  `VERSION()` function is needed by MySQL workbench (I'm using 6.3 with default configuration) and perhaps some other applications.

After this fix, MySQL workbench can successfully connect to TiDB.
(However cannot execute any query due to `Error Code: 0 Server sent unknown charsetnr (0) .`.. This will be a separate issue)

Update #273 #702  
 Thanks, updated the PR.
    Hi there,

This PR adds builtin time function dayname(). Please note that the system variable `lc_time_names` which controls the locales of output names is not supported.
  Is self-tuning feature possible in TiDB like in [Concourse](https://github.com/cinchapi/concourse), removing the need for database configurations?
 The goal is to optimize performance as the data evolves over time, and cut time spent on database administration with automation.
  Is it possible to connect the multi-node TiDB cluster from MySQL client?

In Apache Phoenix, we can use a JDBC string like `"jdbc:phoenix:zookeeperserver1,zookeeperserver2:3333"` to connect the multi-node cluster from JDBC client.
Is there something like this for TiDB?
 @shenli, Thanks for the quick answer!
  If we do have, maybe we can discuss the design, or if you don't have, we are interesting to do so and contribute.

Any suggestions?
 @ngaut Great, we have just finished the integration of TiDB and our own storage (thanks for your doc), generally saying we are going to work on performance optimizations next, thus we need performance_schema first to help to diagnose performance issues.

We have started to look into it, and will submit more ideas later, and we hope we can work together and do more essential contributions besides built-in functions.
 @ngaut , condition push down and SMP (parallel execution) are two big topics, we are also planning to do so, glad to hear that ur guys already working on that, :+1: 
  Hi,

I have the following code using gorm:

``` go
package main

import (
    "fmt"
    "os"

    _ "github.com/go-sql-driver/mysql"
    "github.com/jinzhu/gorm"
)

// Account keeps accounts in the database
type Account struct {
    gorm.Model
    Email string `sql:"type:varchar(100);not null;unique_index"`
}

func logExit(msg string, err error) {
    fmt.Printf("Error: %s, %v\n", msg, err)
    os.Exit(1)
}

func main() {
    url := "root:@tcp(192.168.99.100:3306)/testdb?charset=utf8&parseTime=True&loc=Local"
    db, err := gorm.Open("mysql", url)
    if err != nil {
        logExit("Error connecting to db", err)
    }

    db.AutoMigrate(&Account{})

    account := Account{Email: "fooaaa@gmail.com"}

    if err := db.Create(&account).Error; err != nil {
        logExit("Error in first insert", err)
    } else {
        fmt.Printf("No error for first insert\n")
    }

    account = Account{Email: "fooaaa@gmail.com"}

    if err := db.Create(&account).Error; err != nil {
        logExit("Error in second insert", err)
    } else {
        fmt.Printf("No error for second insert\n")
    }
}
```

First time, the value is inserted and all works fine. Second time the value is not inserted, but no error is returned. If I'm using mysql, I get the following error:

```
No error for first insert

(Error 1062: Duplicate entry 'fooaaa@gmail.com' for key 'uix_accounts_email')
[2016-01-04 05:52:52]
Error: Error in second insert, Error 1062: Duplicate entry 'fooaaa@gmail.com' for key 'uix_accounts_email'
exit status 1
```

If I'm using tidb: 

```
No error for first insert
No error for second insert
```

Logs:

```
2016/01/04 03:53:43 session.go:393: [warning] session:{
  "currDBName": "testdb",
  "sid": 3
}, err:[kv:3]key already exist
2016/01/04 03:53:43 conn.go:240: [error] dispatch error [kv:3]key already exist
/opt/goworkspace/src/github.com/pingcap/tidb/kv/union_store.go:179:
/opt/goworkspace/src/github.com/pingcap/tidb/store/localstore/txn.go:88:
/opt/goworkspace/src/github.com/pingcap/tidb/store/localstore/txn.go:111:
/opt/goworkspace/src/github.com/pingcap/tidb/session.go:175:
/opt/goworkspace/src/github.com/pingcap/tidb/tidb.go:181:
/opt/goworkspace/src/github.com/pingcap/tidb/session.go:394:
/opt/goworkspace/src/github.com/pingcap/tidb/tidb-server/server/conn.go:367: , conn: 192.168.99.1:50566, status: 2, charset: utf8, user: root, lastInsertId: 2
2016/01/04 03:53:43 conn.go:241: [error] cmd: COMMIT
2016/01/04 03:53:43 server.go:156: [info] close conn: 192.168.99.1:50566, status: 2, charset: utf8, user: root, lastInsertId: 2
```
 Thank you very much for your quick answer ! If it is an easy fix I'll be glad to help with a PR.

I think something is wrong with the wire response and gorm is not detecting it.
 Yes. It is fixed. Thank you ! But it doesn't say which key is duplicate. It will be difficult to debug which key is the problem.

Will it work after [this PR](https://github.com/pingcap/tidb/pull/631) will be merged ? 

```
No error for first insert
Error: Error in second insert, Error 1062: key already exist
exit status 1
```
 Thank you !
  Hi,

I would like to find a start point to contribute some code. This start point should be a stable version of source code, which is better to be recent enough(to minimize the effort of merging PR back in future). I check out the master branch with currently latest commit(d64166c), but it fails to build through with errors like:

``` shell
$ make
go get github.com/tools/godep
go get github.com/pingcap/go-hbase
go get github.com/pingcap/go-themis
go get github.com/ngaut/tso/client
go get github.com/qiuyesuifeng/goyacc
go get github.com/qiuyesuifeng/golex
goyacc -o /dev/null -xegen temp_parser_file parser/parser.y
Parse table entries: 323944 of 831792, x 16 bits == 647888 bytes
goyacc -o parser/parser.go -xe temp_parser_file parser/parser.y 2>&1 | egrep "(shift|reduce)/reduce" | awk '{print} END {if (NR > 0) {print "Find conflict in parser.y. Please check y.output for more information."; system("rm -f temp_parser_file"); exit 1;}}'
rm -f temp_parser_file
rm -f y.output
golex -o parser/scanner.go parser/scanner.l
godep go build
# github.com/pingcap/tidb/store/hbase
store/hbase/kv.go:192: cannot use tableName (type string) as type hbase.TableName in argument to hbase.NewTableDesciptor
store/hbase/kv.go:207: too many arguments in call to oracles.NewRemoteOracle
godep: go exit status 2
Makefile:52: recipe for target 'build' failed
make: *** [build] Error 1
```

how to find a built-through version of source code in this situation? Is there any dev workflow that should be followed?
 @ngaut @qiuyesuifeng Thank you both for the quick answer. The problem solved.
  add txn.Rollback on txn error
  I find interface **Visitor** was defined in three go files.

``` c
ast.go (tidb\ast):type Visitor interface {
plan.go (tidb\optimizer\plan):type Visitor interface {
visitor.go (tidb\expression):type Visitor interface {
```

In particular, the definitions in plan.go and ast.go are exactly the same.

``` go
type Visitor interface {
    // Enter is called before children nodes are visited.
    // The returned node must be the same type as the input node n.
    // skipChildren returns true means children nodes should be skipped,
    // this is useful when work is done in Enter and there is no need to visit children.
    Enter(n Node) (node Node, skipChildren bool)
    // Leave is called after children nodes have been visited.
    // The returned node's type can be different from the input node if it is a ExprNode,
    // Non-expression node must be the same type as the input node n.
    // ok returns false to stop visiting.
    Leave(n Node) (node Node, ok bool)
}
```

what's the meaning of this interface? Can you explain the functions Enter/Leave in detail?

thx.
 ok, thx
  ### HBase column families

``` bash
hbase(main):051:0> desc 'testdb'
Table testdb is ENABLED                                                                                                                                              
testdb, {TABLE_ATTRIBUTES => {METADATA => {'__themis.returned.table.desc__' => 'true'}}                                                                              
COLUMN FAMILIES DESCRIPTION                                                                                                                                          
{NAME => '#d', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '2147483647', TTL => 'FOREVER', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}                                                    
{NAME => '#p', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '2147483647', TTL => 'FOREVER', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}                                                    
{NAME => 'L', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '1', TTL => 'FOREVER', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '65536', IN_MEMORY => 'true', BLOCKCACHE => 'true'}                                                               
{NAME => 'f', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '2147483647', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true', METADATA => {'THEMIS_ENABLE' => 'true'}}            
4 row(s) in 0.0270 seconds
```

From tidb/store/hbase/kv.go, I can see there has a CF named **'f'**, and that's the only place I can found in tidb's code, what are the other 3 CFs used for? ('#d', '#p', 'L'), maybe it's used for themis only?
### Do we have any document to describe how SQL mapping to KV work in details? Where is the code?
 @shenli Glad to hear that.

Could you please tell me where is the code about the mapping/encoding/decoding, just show me the major related go files and methods first, thanks.
 @disksing , thanks for your answer.
 @disksing thanks for your answer.
  sounds great, will keep watching your progress, :+1: 
  [nieyy@Euler-10 tidb]$ git log -1
commit c37458fa5f974c6337f6db23f5ecc950dc0d5085
Merge: 8af9bda b89f8c7
Author: goroutine ngaut@users.noreply.github.com
Date:   Tue Dec 22 13:52:12 2015 +0800

```
Merge pull request #773 from pingcap/qiuyesuifeng/update-makefile

*: remove goyacc/golex/godep from make update.
```

[nieyy@Euler-10 tidb]$ make
go get github.com/tools/godep
go get github.com/pingcap/go-hbase
go get github.com/pingcap/go-themis
go get github.com/ngaut/tso/client
go get github.com/qiuyesuifeng/goyacc
go get github.com/qiuyesuifeng/golex
$(which goyacc) -o /dev/null -xegen temp_parser_file parser/parser.y
Parse table entries: 323531 of 830115, x 16 bits == 647062 bytes
$(which goyacc) -o parser/parser.go -xe temp_parser_file parser/parser.y 2>&1 | egrep "(shift|reduce)/reduce" | awk '{print} END {if (NR > 0) {print "Find conflict in parser.y. Please check y.output for more information."; system("rm -f temp_parser_file"); exit 1;}}'
rm -f temp_parser_file
rm -f y.output
$(which golex) -o parser/scanner.go parser/scanner.l
$(which godep) go build
# github.com/pingcap/tidb/store/hbase

store/hbase/kv.go:175: cannot use tableName (type string) as type hbase.TableName in argument to hbase.NewTableDesciptor
godep: go exit status 2
make: **\* [build] Error 1
 ``` bash
[nieyy@Euler-10 tidb]$ make update
go get -u github.com/pingcap/go-hbase
go get -u github.com/pingcap/go-themis
go get -u github.com/ngaut/tso/client

[nieyy@Euler-10 tidb]$ make
go get github.com/tools/godep
go get github.com/pingcap/go-hbase
go get github.com/pingcap/go-themis
go get github.com/ngaut/tso/client
go get github.com/qiuyesuifeng/goyacc
go get github.com/qiuyesuifeng/golex
$(which goyacc) -o /dev/null -xegen temp_parser_file parser/parser.y
Parse table entries: 323531 of 830115, x 16 bits == 647062 bytes
$(which goyacc) -o parser/parser.go -xe temp_parser_file parser/parser.y 2>&1 | egrep "(shift|reduce)/reduce" | awk '{print} END {if (NR > 0) {print "Find conflict in parser.y. Please check y.output for more information."; system("rm -f temp_parser_file"); exit 1;}}'
rm -f temp_parser_file
rm -f y.output
$(which golex) -o parser/scanner.go parser/scanner.l
$(which godep) go build
$(which godep) go test -cover ./...
ok      github.com/pingcap/tidb 5.445s  coverage: 82.6% of statements
ok      github.com/pingcap/tidb/ast     0.053s  coverage: 28.0% of statements
ok      github.com/pingcap/tidb/column  0.055s  coverage: 80.0% of statements
?       github.com/pingcap/tidb/context [no test files]
ok      github.com/pingcap/tidb/ddl     8.878s  coverage: 85.6% of statements
ok      github.com/pingcap/tidb/domain  1.074s  coverage: 83.0% of statements
?       github.com/pingcap/tidb/executor        [no test files]
?       github.com/pingcap/tidb/executor/converter      [no test files]
ok      github.com/pingcap/tidb/expression      0.027s  coverage: 89.0% of statements
ok      github.com/pingcap/tidb/expression/builtin      0.024s  coverage: 92.7% of statements
ok      github.com/pingcap/tidb/expression/subquery     0.017s  coverage: 0.0% of statements
ok      github.com/pingcap/tidb/field   0.063s  coverage: 96.8% of statements
ok      github.com/pingcap/tidb/infoschema      0.021s  coverage: 97.3% of statements
ok      github.com/pingcap/tidb/inspectkv       0.056s  coverage: 83.6% of statements
?       github.com/pingcap/tidb/interpreter     [no test files]
ok      github.com/pingcap/tidb/kv      0.283s  coverage: 69.2% of statements
ok      github.com/pingcap/tidb/kv/memkv        0.043s  coverage: 67.0% of statements
ok      github.com/pingcap/tidb/meta    0.108s  coverage: 77.3% of statements
ok      github.com/pingcap/tidb/meta/autoid     0.018s  coverage: 89.5% of statements
ok      github.com/pingcap/tidb/metric  0.130s  coverage: 66.7% of statements
ok      github.com/pingcap/tidb/model   0.045s  coverage: 98.4% of statements
ok      github.com/pingcap/tidb/mysql   0.057s  coverage: 71.3% of statements
ok      github.com/pingcap/tidb/optimizer       0.377s  coverage: 80.0% of statements
ok      github.com/pingcap/tidb/optimizer/evaluator     0.047s  coverage: 67.7% of statements
ok      github.com/pingcap/tidb/optimizer/plan  0.016s  coverage: 86.0% of statements
ok      github.com/pingcap/tidb/parser  0.047s  coverage: 32.1% of statements
?       github.com/pingcap/tidb/parser/coldef   [no test files]
ok      github.com/pingcap/tidb/parser/opcode   0.004s  coverage: 100.0% of statements
?       github.com/pingcap/tidb/plan    [no test files]
ok      github.com/pingcap/tidb/plan/plans      0.864s  coverage: 76.9% of statements
?       github.com/pingcap/tidb/privilege       [no test files]
ok      github.com/pingcap/tidb/privilege/privileges    0.444s  coverage: 86.3% of statements
?       github.com/pingcap/tidb/rset    [no test files]
ok      github.com/pingcap/tidb/rset/rsets      0.135s  coverage: 67.4% of statements
ok      github.com/pingcap/tidb/sessionctx      0.020s  coverage: 100.0% of statements
?       github.com/pingcap/tidb/sessionctx/autocommit   [no test files]
ok      github.com/pingcap/tidb/sessionctx/db   0.027s  coverage: 100.0% of statements
?       github.com/pingcap/tidb/sessionctx/forupdate    [no test files]
ok      github.com/pingcap/tidb/sessionctx/variable     0.108s  coverage: 56.4% of statements
?       github.com/pingcap/tidb/stmt    [no test files]
ok      github.com/pingcap/tidb/stmt/stmts      1.585s  coverage: 80.6% of statements
ok      github.com/pingcap/tidb/store   0.169s  coverage: 0.0% of statements
ok      github.com/pingcap/tidb/store/hbase     0.025s  coverage: 1.0% of statements
ok      github.com/pingcap/tidb/store/localstore        2.695s  coverage: 81.0% of statements
ok      github.com/pingcap/tidb/store/localstore/boltdb 0.080s  coverage: 86.8% of statements
?       github.com/pingcap/tidb/store/localstore/engine [no test files]
ok      github.com/pingcap/tidb/store/localstore/goleveldb      0.012s  coverage: 90.6% of statements
ok      github.com/pingcap/tidb/structure       0.028s  coverage: 85.5% of statements
ok      github.com/pingcap/tidb/table   0.344s  coverage: 100.0% of statements
ok      github.com/pingcap/tidb/table/tables    0.242s  coverage: 76.8% of statements
ok      github.com/pingcap/tidb/terror  0.007s  coverage: 84.1% of statements
?       github.com/pingcap/tidb/tidb-server     [no test files]
2015/12/23 04:44:17 kv.go:305: [info] [kv] New store /tmp/tidb 

----------------------------------------------------------------------
FAIL: tidb_test.go:30: TidbTestSuite.SetUpSuite

tidb_test.go:39:
    c.Assert(err, IsNil)
... value *errors.Err = &errors.Err{message:"", cause:(*net.OpError)(0xc820019590), previous:(*net.OpError)(0xc820019590), file:"github.com/pingcap/tidb/tidb-server/server/_test/_obj_test/server.go", line:121} ("listen tcp :4001: bind: address already in use")


----------------------------------------------------------------------
PANIC: tidb_test.go:45: TidbTestSuite.TearDownSuite

... Panic: runtime error: invalid memory address or nil pointer dereference (PC=0x45CFBE)

/usr/local/go/src/runtime/panic.go:423
  in gopanic
/usr/local/go/src/runtime/panic.go:42
  in panicmem
/usr/local/go/src/runtime/sigpanic_unix.go:24
  in sigpanic
github.com/pingcap/tidb/tidb-server/server/_test/_obj_test/server.go:150
  in Server.Close
tidb_test.go:46
  in TidbTestSuite.TearDownSuite
/usr/local/go/src/reflect/value.go:300
  in Value.Call
/home/nieyy/goproj/src/github.com/pingcap/tidb/Godeps/_workspace/src/github.com/pingcap/check/check.go:721
  in suiteRunner.runFixture.func1
/home/nieyy/goproj/src/github.com/pingcap/tidb/Godeps/_workspace/src/github.com/pingcap/check/check.go:666
  in suiteRunner.forkCall.func1
/usr/local/go/src/runtime/asm_amd64.s:1696
  in goexit
OOPS: 1 passed, 1 FAILED, 1 FIXTURE-PANICKED, 8 MISSED
--- FAIL: TestT (0.00s)
FAIL
coverage: 4.5% of statements
FAIL    github.com/pingcap/tidb/tidb-server/server      0.018s
ok      github.com/pingcap/tidb/util    0.099s  coverage: 71.9% of statements
ok      github.com/pingcap/tidb/util/arena      0.004s  coverage: 100.0% of statements
ok      github.com/pingcap/tidb/util/bytes      0.005s  coverage: 0.0% of statements
ok      github.com/pingcap/tidb/util/charset    0.014s  coverage: 80.0% of statements
ok      github.com/pingcap/tidb/util/codec      0.017s  coverage: 93.0% of statements
ok      github.com/pingcap/tidb/util/format     0.005s  coverage: 81.2% of statements
ok      github.com/pingcap/tidb/util/hack       0.005s  coverage: 92.3% of statements
ok      github.com/pingcap/tidb/util/mock       0.044s  coverage: 26.5% of statements
?       github.com/pingcap/tidb/util/mock/mocks [no test files]
ok      github.com/pingcap/tidb/util/printer    0.007s  coverage: 89.8% of statements
?       github.com/pingcap/tidb/util/sqlexec    [no test files]
ok      github.com/pingcap/tidb/util/stringutil 0.010s  coverage: 100.0% of statements
?       github.com/pingcap/tidb/util/testkit    [no test files]
ok      github.com/pingcap/tidb/util/testutil   0.004s  coverage: 100.0% of statements
ok      github.com/pingcap/tidb/util/types      0.046s  coverage: 83.6% of statements
godep: go exit status 1
make: *** [gotest] Error 1
```
 OK now, thanks for your kindly support.
  I just want to test my exist  system.
 Thanks,I will try.
 ...tidb-0.5-alpha/ast
...tidb-0.5-alpha/column
...   ...
Like above dir list, which  dir should be set for  "GOPATH"?
    Hi there,

When I try to implement some time functions listed in issue #236, I find those functions `adddate, subdate, date_add, date_sub`, which are ticked as done, are not fully working. If they are used in `interpreter`, they just return `NULL`, as the below:

``` text
tidb> select adddate("2008-01-02", INTERVAL 1 DAY);
+---------------------------------------+
| adddate("2008-01-02", INTERVAL 1 DAY) |
+---------------------------------------+
| NULL                                  |
+---------------------------------------+
1 row in set (0.00 sec)
tidb> select adddate("2008-01-02", 1);
+--------------------------+
| adddate("2008-01-02", 1) |
+--------------------------+
| NULL                     |
+--------------------------+
1 row in set (0.00 sec)
tidb> select date_add("2008-01-02", INTERVAL 1 DAY);
+----------------------------------------+
| date_add("2008-01-02", INTERVAL 1 DAY) |
+----------------------------------------+
| NULL                                   |
+----------------------------------------+
1 row in set (0.00 sec)
tidb> select subdate("2008-01-02", 1);
+--------------------------+
| subdate("2008-01-02", 1) |
+--------------------------+
| NULL                     |
+--------------------------+
1 row in set (0.00 sec)
```

This PR add ast evalutions for date arith to fix this problem.

``` text
tidb> select adddate("2008-01-02", 1);
+---------------------------------------+
| adddate("2008-01-02", INTERVAL 1 DAY) |
+---------------------------------------+
| 2008-01-03                            |
+---------------------------------------+
1 row in set (0.00 sec)
tidb> select subdate("2008-01-02", INTERVAL 1 DAY);
+---------------------------------------+
| subdate("2008-01-02", INTERVAL 1 DAY) |
+---------------------------------------+
| 2008-01-01                            |
+---------------------------------------+
1 row in set (0.00 sec)
tidb> select date_add("2008-01-02", INTERVAL 1 DAY);
+----------------------------------------+
| date_add("2008-01-02", INTERVAL 1 DAY) |
+----------------------------------------+
| 2008-01-03                             |
+----------------------------------------+
1 row in set (0.00 sec)
tidb> select date_sub("2008-01-02", INTERVAL 1 DAY);
+----------------------------------------+
| date_sub("2008-01-02", INTERVAL 1 DAY) |
+----------------------------------------+
| 2008-01-01                             |
+----------------------------------------+
1 row in set (0.00 sec)
```
 @qiuyesuifeng @coocood 
Sorry for the malformation. I have reformatted these code and it passes checks now.

It's somewhat tricky to handle all the type castings and return type variations. I change a few test cases to adjust the behavior a little bit.
Please note, there are a few points where the behavior differs from mysql:

#### 1. type cast from float string to interval

In mysql:

``` text
mysql> select adddate("2011-11-11 10:10:10", 19.88);
+---------------------------------------+
| adddate("2011-11-11 10:10:10", 19.88) |
+---------------------------------------+
| 2011-12-01 10:10:10                   |
+---------------------------------------+
1 row in set (0.00 sec)

mysql> select adddate("2011-11-11 10:10:10", "19.88");       
+-----------------------------------------+
| adddate("2011-11-11 10:10:10", "19.88") |
+-----------------------------------------+
| 2011-11-30 10:10:10                     |
+-----------------------------------------+
1 row in set, 1 warning (0.00 sec)
```

Since casting float to int will round the float value, but casting string to int (which contains a float value) will truncate the float value. I couldn't find a existing function in `types` package will do this exact conversion. So, in this PR, both cases hehave the same and return `2011-12-01 10:10:10`.

#### 2. loose conversion from string to int

In mysql, it supports a loose conversion from string to int, so we get:

``` text

mysql> select adddate("2011-11-11 10:10:10", "10,11"); 
+-----------------------------------------+
| adddate("2011-11-11 10:10:10", "10,11") |
+-----------------------------------------+
| 2011-11-21 10:10:10                     |
+-----------------------------------------+
1 row in set, 1 warning (0.00 sec)

mysql> select adddate("2011-11-11 10:10:10", "10-11");
+-----------------------------------------+
| adddate("2011-11-11 10:10:10", "10-11") |
+-----------------------------------------+
| 2011-11-21 10:10:10                     |
+-----------------------------------------+
1 row in set, 1 warning (0.00 sec)
```

In this PR, the above cases are reported as errors because `types.Convert()` doesn't support this kind of loose conversion.
 @coocood 
Yes, I notice it mentions that strict mode on conversion is required in the source code, so loose conversion from string to int should be prohibited on purpose.

I don't quite understand the evolvement/history of copying code from `expression/date_arith_test.go` to `evaluator_test.go`. Could you help to elaborate it? It looks like that both `expression/date_arith.go` and `evaluator.go` have some codes works for similar functionality. Why duplicate?
 @ngaut Referring to the code in `expression/date_arith.go` (thank @coocood for the above comments), I modify the code of this PR so that all the test cases remain still as `expression/date_arith_test.go`. All test cases go through OK now. And behaviors mentioned above keep the same with mysql, including the parsing of `"19.88"`, `"10,11"`, `"10-11"` for day interval.
  Wondering if i can debug myself for the support of PHP applications. If any guide/blog post for hello world is appreciated.
 sorry to be trouble maker.. just ..

![image](https://cloud.githubusercontent.com/assets/659311/11831752/7a9f7fe4-a3ec-11e5-9490-845d6533a333.png)

i tried a go get command success, but make fail
 ![image](https://cloud.githubusercontent.com/assets/659311/11831815/1e6335b2-a3ed-11e5-920f-42df323f4c76.png)
 Does it support mac ?

![image](https://cloud.githubusercontent.com/assets/659311/11831942/78869560-a3ee-11e5-96bf-46c1ab89f353.png)
 i just download it this morning with the quickstart guide, so it probably is latest.

output too long,just capture errors

![image](https://cloud.githubusercontent.com/assets/659311/11832261/900b6500-a3f1-11e5-8e99-b0342be35b44.png)

![image](https://cloud.githubusercontent.com/assets/659311/11832258/8998f23c-a3f1-11e5-8896-29608aeaed7d.png)

![image](https://cloud.githubusercontent.com/assets/659311/11832270/a9345514-a3f1-11e5-8be8-311228867445.png)
 yes, can compile on Mac now.
  I find tidb support built-in function substring, but don't support substr. substr is used very frequently
In Oracle and MySQL projects. 
We can find the description of substr in MySQL 5.7 Reference Manual in url:
http://dev.mysql.com/doc/refman/5.7/en/string-functions.html#function_substr
which said:
SUBSTR() is a synonym for SUBSTRING().

This patch is to support substr. As tidb has support substring, There is just little work to do. The patch is very simple.
  With #834, I can connect to TiDB from MySQL Workbench 6.3.

However, I'm still hitting the error: `table mysql.proc does not exist.`

So I suggest reopening this issue, and introducing some dummy `mysql.proc` table.

(When I forcibly try to execute some queries, `Error Code: 0 Server sent unknown charsetnr (0) .` is shown on MySQL Workbench console, as I mentioned in #834.)
 @ngaut Yes, but not yet ready for pull request.
 After discussion at https://github.com/AkihiroSuda/tidb/commit/db660fe0b8a51eaf6223647765a353088b786740, @shenli committed #849, and we can execute query in Workbench.

I think this issue is now closable, although some nice Workbench features (e.g., listing up tables in GUI) are not working yet.
  First attempt trying to be a Tidb contributor, :)
 Welcome, :), we have several members working on using TiDB as a MySQL-compatible distributed SQL engine for our own storage, will have more contributions later.
  HI there, as title, wondering how to add a user more than 127.0.0.1 ?
 looks like not working

![image](https://cloud.githubusercontent.com/assets/659311/11775627/61b06b82-a27b-11e5-80f2-e6b20c644f47.png)
 i just tried copy and paste the command:

![image](https://cloud.githubusercontent.com/assets/659311/11776396/b30d55d4-a281-11e5-93f3-574ee2bb0d93.png)

is that my version is wrong ? I just use the docker in the quick start guide

or a problem of mysql client ?

keithyau@ubuntu:/var/www/html/drupal8/sites/default$ mysql --version
mysql  Ver 14.14 Distrib 5.6.25, for debian-linux-gnu (x86_64) using  EditLine wrapper
 Got, thanks
  First of all, just attended OSChina and really like pingcap's presenation.

just tried to install Drupal and point DB to port 4000, with a SQLSTATE[HY000] [2002]  ERROR

![image](https://cloud.githubusercontent.com/assets/659311/11775175/79affc88-a277-11e5-90ce-0305daeb428c.png)

Please kindly advice
 update:

docker php code -> localhost:4000 failed
but 
local php code -> localhost:4000 successful init the db install, but it becomes a gateway timeout.

Do any test case available that TiDB + wordpress / PHP application so that i can take as reference ?

 General error: 2013 Lost connection to MySQL server during query: 

Error log:
Drupal\Core\Database\DatabaseExceptionWrapper: SQLSTATE[HY000]: General error: 2013 Lost connection to MySQL server during query: INSERT INTO {cache_data} (cid, expire, created, tags, checksum, data, serialized) VALUES (:db_insert_placeholder_0, :db_insert_placeholder_1, :db_insert_placeholder_2, :db_insert_placeholder_3, :db_insert_placeholder_4, :db_insert_placeholder_5, :db_insert_placeholder_6) ON DUPLICATE KEY UPDATE cid = VALUES(cid), expire = VALUES(expire), created = VALUES(created), tags = VALUES(tags), checksum = VALUES(checksum), data = VALUES(data), serialized = VALUES(serialized); Array ( [:db_insert_placeholder_0] => route_provider.route_load:be2379e04cf37ec305c531e6ffb8327502c6421ac10d8b7a38bd9aa2e01d42102cf0581510515d56ec6c253222718f7c4a4282b46e3a274578499f5b90ef4753 [:db_insert_placeholder_1] => -1 [:db_insert_placeholder_2] => 1450079385.821 [:db_insert_placeholder_3] => routes [:db_insert_placeholder_4] => 1 [:db_insert_placeholder_5] => a:1:{s:6:"<none>";s:942:"C:31:"Symfony\Component\Routing\Route":897:{a:9:{s:4:"path";s:1:"/";s:4:"host";s:0:"";s:8:"defaults";a:0:{}s:12:"requirements";a:2:{s:7:"_access";s:4:"TRUE";s:7:"_method";s:8:"GET|POST";}s:7:"options";a:5:{s:14:"compiler_class";s:34:"\Drupal\Core\Routing\RouteCompiler";s:8:"_no_path";b:1;s:14:"_route_filters";a:1:{i:0;s:27:"content_type_header_matcher";}s:16:"_route_enhancers";a:1:{i:0;s:31:"route_enhancer.param_conversion";}s:14:"_access_checks";a:1:{i:0;s:20:"access_check.default";}}s:7:"schemes";a:0:{}s:7:"methods";a:2:{i:0;s:3:"GET";i:1;s:4:"POST";}s:9:"condition";s:0:"";s:8:"compiled";C:33:"Drupal\Core\Routing\CompiledRoute":296:{a:11:{s:4:"vars";a:0:{}s:11:"path_prefix";s:1:"/";s:10:"path_regex";s:6:"#^/$#s";s:11:"path_tokens";a:1:{i:0;a:2:{i:0;s:4:"text";i:1;s:1:"/";}}s:9:"path_vars";a:0:{}s:10:"host_regex";N;s:11:"host_tokens";a:0:{}s:9:"host_vars";a:0:{}s:3:"fit";i:1;s:14:"patternOutline";s:1:"/";s:8:"numParts";i:1;}}}}";} [:db_insert_placeholder_6] => 1 ) in Drupal\Core\Routing\RouteProvider->preLoadRoutes() (line 216 of /var/www/html/drupal8/core/lib/Drupal/Core/Routing/RouteProvider.php).

Nginx error:

2015/12/13 23:46:47 [error] 86552#0: *2 upstream timed out (110: Connection timed out) while reading response header from upstream, client: 127.0.0.1, server: localhost, request: "POST /core/install.php?langcode=en&profile=standard&continue=1 HTTP/1.1", upstream: "fastcgi://unix:/var/run/php5-fpm.sock", host: "localhost", referrer: "http://localhost/core/install.php?langcode=en&profile=standard&continue=1"

Looks like connection timeout. Any reference i can work on to tune the DB ? just like mysql increase wait timeout ?
 Question: How can i tune things like max_connection or wait timeout like i were in my.cnf ?
 @morefreeze thanks, the no such file problem solved, i found the problem more on the installation stopped at the middle. And my php application response 504 server timeour. Will try setting some max connection / wait timeout and get back to u.

thanks you guys
 tried install php application with php-cli and got this

Calling install_drupal(Array) [264.21 sec, 6.87 MB]                           [debug]
exception 'PDOException' with message 'SQLSTATE[HY000]: General error:    [error]
2013 Lost connection to MySQL server during query' in
/var/www/html/drupal-7.41/includes/database/database.inc:2171

How can I enable query log in TiDB? So that i can find which query exactly made the timeout.
 yes thanks
@shenli 
 runtime error: index out of range, goroutine 88634 [running]:

I got this.. any parameter required to tune ?

![image](https://cloud.githubusercontent.com/assets/659311/11778530/d5b428d4-a28f-11e5-8f3c-5a9a533f7873.png)
 im trying with Drupal 7 as Drupal 8 is new and not good for compatibility test to new DB.

But for both D7 and D8, both terminated the installation due to "DB go away".

and the error i see so far is

runtime error: index out of range, goroutine 88634 [running]:
what is go routine ? Or i can help to debug

Looks like Go lang stuff: http://stackoverflow.com/questions/31691351/golang-panic-runtime-error-index-out-of-range-only-happens-when-run-outside-de
 @shenli Any hints about index out of range ? New to Go lang
 this is the error print on my linux build, looks like even earlier step than docker

![image](https://cloud.githubusercontent.com/assets/659311/11832516/f201e14c-a3f3-11e5-89e5-0f80fd057abc.png)
 With the key already exists error, but still some tables created. Stopped at Insert into system, so i guess may be some syntax not supported ?

![image](https://cloud.githubusercontent.com/assets/659311/11833561/ce7113fa-a3fe-11e5-8f73-c9f8d1da9f7f.png)
  ```
$ go get github.com/pingcap/tidb
# github.com/pingcap/tidb/parser
github.com\pingcap\tidb\parser\yy_parser.go:17: undefined: yyLexer
github.com\pingcap\tidb\parser\yy_parser.go:18: undefined: yyParse
# github.com/pingcap/go-themis
github.com\pingcap\go-themis\themis_txn.go:257: multiple-value txn.client.LocateRegion() in single-value context
```
 @ngaut,

This is not ideal for this who want to use tidb in an embedded scenerio. Is it not possible to clean master up to allow it to be go getable?
 This doesn't seem to be a make related error:

```
..\go-themis\themis_txn.go:257: multiple-value txn.client.LocateRegion() in single-value context
```
   Updated.
 Updated.
  This behavior is completely unexpected and seems no way to turn it off.
 Yes, it feels like a ghost port when embedded in other apps, I want to a way to disable it.
 From what I understand, the `Debug` will never be `false` before TiDB starts listening on port 8888.

Because it is put in [init function](https://github.com/pingcap/tidb/blob/master/tidb.go#L354), and it always executes before my code.
 Any other entry point (function) must be called for using TiDB?

Put `Debug` check into that function should fix the problem.
 Maybe disable by environment variable?

I mean, default should be false, to enable `TIDB_DEBUG=1`.
 Sure, should I remove `Debug` variable? Or keep it and set its value by reading the env variable?
 https://github.com/pingcap/tidb/pull/687
    Latest `master`:

```
vet --shadow
table/tables/tables_test.go:92: declaration of err shadows declaration at table/tables/tables_test.go:53:
```
  Hi,
I can create database using SQL "CREATE DATABASE" but it is impossible
to access it (using tidb-server mode) using mysql_real_connect() from the mysql C API
driver ... 
Any idea ?
PS: i can nevertheless access the predefined database ( mysql, test ) using user:root
and empty  password ...
 Yes,
I got the details point. one has to use the explicit IP number ( 127.0.0.1) . With localhost it does not
work ... why?  no idea !! 
  Hi Guys,
trying to create a user i am facing the following problem when 
using the command
mysql> flush privileges;
ERROR 1105 (HY000): line 1 column 1 near "flush"

Somehow the SQL statement is not recognise ... ( in use the tidb-server mode)

Any idea ?
Is there a specific way to create User and grant privileges using tidb ?

Thanks in advance !
Denis
 Well ok !
For now i can connect the tiDB only with root and empty password.
I am nevertheless facing others issues when creating table ... i have to study what is
happening and give you a report...
  Does tidb support Spatial database?

```
A spatial database, or geodatabase is a database that is optimized to store and query data that represents objects defined in a geometric space. Most spatial databases allow representing simple geometric objects such as points, lines and polygons. Some spatial databases handle more complex structures such as 3D objects, topological coverages, linear networks, and TINs. While typical databases are designed to manage various numeric and character types of data, additional functionality needs to be added for databases to process spatial data types efficiently. These are typically called geometry or feature. The Open Geospatial Consortium created the Simple Features specification and sets standards for adding spatial functionality to database systems.
```
 https://en.wikipedia.org/wiki/Spatial_database
 https://www.rethinkdb.com/docs/geo-support/python/ 
Now days, we built social apps with geospatial query and store data. We also store and query JSON format.   MySQL 5.7 added JSON support, Better spatial support, They were good for modern DEV needed.
 Any milestone for this feature. Geospatial and realtime?  This is one of the biggest features of modern databases 
  go get github.com/pingcap/go-themis
# github.com/pingcap/go-themis

../go-themis/themis_txn.go:173: undefined: kv.ErrRetryable
../go-themis/themis_txn.go:183: undefined: kv.ErrRetryable
../go-themis/themis_txn.go:189: undefined: kv.ErrRetryable
../go-themis/themis_txn.go:197: undefined: kv.ErrRetryable

&
go version
go version go1.5 linux/amd64
 ·@ngaut is ok  make make server make interpreter 
   Please merge this PR... or provide better solution... current `make` just feel bad. :dizzy_face:
 Maybe add a `make update` command?
 @ngaut https://github.com/pingcap/tidb/pull/680
  Not sure you guys have noticed this or I'm doing something wrong.

Latest `master`: `2c5359e284cd22a7ab741f149a130dabd85036c6`

```
➜  tidb git:(master) make
go get github.com/tools/godep
go get github.com/pingcap/go-hbase
go get github.com/pingcap/go-themis
go get github.com/ngaut/tso/client
go get github.com/qiuyesuifeng/goyacc
go get github.com/qiuyesuifeng/golex
$(which goyacc) -o /dev/null -xegen temp_parser_file parser/parser.y
Parse table entries: 296474 of 772007, x 16 bits == 592948 bytes
$(which goyacc) -o parser/parser.go -xe temp_parser_file parser/parser.y 2>&1 | egrep "(shift|reduce)/reduce" | awk '{print} END {if (NR > 0) {print "Find conflict in parser.y. Please check y.output for more information."; system("rm -f temp_parser_file"); exit 1;}}'
rm -f temp_parser_file
rm -f y.output
$(which golex) -o parser/scanner.go parser/scanner.l
$(which godep) go build
# github.com/pingcap/tidb/store/hbase
store/hbase/kv.go:90: cannot use t (type *themis.Txn) as type themis.Txn in argument to newHbaseTxn
store/hbase/kv.go:100: cannot use t (type *themis.Txn) as type themis.Txn in argument to newHbaseSnapshot
store/hbase/snapshot.go:66: s.txn.Gets undefined (type themis.Txn has no field or method Gets)
store/hbase/snapshot.go:154: cannot convert nil to type themis.Txn
store/hbase/snapshot.go:156: cannot use nil as type themis.Txn in assignment
godep: go exit status 2
make: *** [build] Error 1
```
 Thanks, worked.

PS: why don't use `-u` on makefile?
 Just another note that... test failed on Raspi 2, and the error log is over 3k lines that I can't even reach the beginning point from my terminal... 

It's all about

```
2015/11/25 10:15:19 compactor.go:205: [info] GC send key to deleteWorker [122 116 101 115 116 95 107 101 121 95 48 0 1 8 250 187 3 38 255 135 255 255]
2015/11/25 10:15:19 compactor.go:205: [info] GC send key to deleteWorker [122 116 101 115 116 95 107 101 121 95 48 0 1 8 250 187 3 38 255 147 255 255]
2015/11/25 10:15:19 compactor.go:205: [info] GC send key to deleteWorker [122 116 101 115 116 95 107 101 121 95 48 0 1 8 250 187 3 38 255 159 255 255]
2015/11/25 10:15:19 compactor.go:205: [info] GC send key to deleteWorker [122 116 101 115 116 95 107 101 121 95 48 0 1 8 250 187 3 38 255 179 255 255]
2015/11/25 10:15:19 compactor.go:205: [info] GC send key to deleteWorker [122 116 101 115 116 95 107 101 121 95 48 0 1 8 250 187 3 38 255 191 255 255]
2015/11/25 10:15:19 compactor.go:205: [info] GC send key to deleteWorker [122 116 101 115 116 95 107 101 121 95 48 0 1 8 250 187 3 38 255 199 255 255]
2015/11/25 10:15:19 compactor.go:205: [info] GC send key to deleteWorker [122 116 101 115 116 95 107 101 121 95 48 0 1 8 250 187 3 38 255 211 255 255]
SIGQUIT: quit
PC=0x718ec m=0
```
 OK, but takes time to build on Raspi 2. Please wait.
 It's 18.4 MB... has been sent.
 > @Unknwon Does the log containing GC stopped before too many GC send key to deleteWorker, if has, the GC compactor may be blocked when Stop.

I think, yes.
 Congrats to 3k stars! :trollface:

Hope solve the 8888 port soon as well.
  #630 adding which key is duplicate
  I hava a struct as:

```
type A struct{
    Id    int64
    Email string `xorm:"unique"`
    Name  string `xorm:"unique"`
}
```

I inserted a value twice, and the logs is:

```
2015/11/24 13:27:19 txn.go:109: [debug] get key:"65_i_uqe_a_email\x00\x01Elvizlai\x00\x01\x00\x00s", txn:379674385191534593
2015/11/24 13:27:19 txn.go:146: [debug] set key:"65_i_uqe_a_email\x00\x01Elvizlai\x00\x01\x00\x00s", txn:379674385191534593
2015/11/24 13:27:19 txn.go:146: [debug] set key:"65_r\x00\x01\x12\v\xb9\x00\x00sd", txn:379674385191534593
2015/11/24 13:27:19 txn.go:146: [debug] set key:"65_r\x00\x01\x12\v\xb9\x11=\x00\x00sdd", txn:379674385191534593
2015/11/24 13:27:19 txn.go:146: [debug] set key:"65_r\x00\x01\x12\v\xb9\x11>\x00\x00sdd", txn:379674385191534593
2015/11/24 13:27:19 txn.go:146: [debug] set key:"65_r\x00\x01\x12\v\xb9\x11?\x00\x00sdd", txn:379674385191534593
2015/11/24 13:27:19 txn.go:146: [debug] set key:"65_r\x00\x01\x12\v\xb9\x11@\x00\x00sdd", txn:379674385191534593
2015/11/24 13:27:19 txn.go:252: [info] commit txn 379674385191534593
2015/11/24 13:27:19 session.go:160: [warning] txn:379674385191534593, Error: key already exist
0 Error: key already exist
```

I don't know witch key is already exist from err response now.
  Hi there,

This PR would fix issue #612, it adds setting for PATH in Makefile to avoid manual setup.
For `make` version after 4.0, simply adding GOPATH/bin into PATH would work. But for version before 4.0, `make` fail to use modified PATH to search these commands godep/golex/goyacc/golint, which are installed in GOPATH/bin. So we need to specify these commands with full path.

It passes tests under `make` 4.0(Debian Linux), 3.81, 4.1(Mac OS X).
 @shenli It's fixed. I forgot that GOPATH could contain multiple paths.
  Hi,

I follow the instructions in `docs/QUICKSTART.md`:

``` shell
git clone https://github.com/pingcap/tidb.git $GOPATH/src/github.com/pingcap/tidb
cd $GOPATH/src/github.com/pingcap/tidb
make
```

but fail to build the project. After executing command `make`, it reports errors like:

``` text
go get github.com/tools/godep
go get github.com/pingcap/go-hbase
go get github.com/pingcap/go-themis
go get github.com/ngaut/tso/client
go get github.com/qiuyesuifeng/goyacc
go get github.com/qiuyesuifeng/golex
goyacc -o /dev/null -xegen temp_parser_file parser/parser.y; \
    goyacc -o parser/parser.go -xe temp_parser_file parser/parser.y 2>&1 | egrep "(shift|reduce)/reduce" | awk '{print} END {if (NR > 0) {print "Find conflict in parser.y. Please check y.output for more information."; system("rm -f temp_parser_file"); exit 1;}}';
/bin/sh: goyacc: command not found
rm -f temp_parser_file; \
    rm -f y.output
sed: parser/parser.go: No such file or directory
sed: parser/parser.go: No such file or directory
make: *** [parser] Error 1
```

Is there anything wrong or any prerequisite should be fullfilled?
 @shenli No, I only set GOPATH. After I add `$GOPATH/bin` to `PATH`, the error is gone now.

I think putting this prerequisite for `PATH` in docs would be better. Or ensuring the `PATH` contains `$GOPATH/bin` in Makefile at the very first of the build process.
 Add this code into the head part of `Makefile` should work(to avoid manually setting PATH, no need of #614)

``` makefile
export PATH := $(GOPATH)/bin:$(PATH)
```

Please notice that the default `make` program(version 3.81) in Mac OS X is too old and fail to find `golex`/`goyacc` correctly using variable `PATH`(probably a bug).  To make the above line of code work correctly, you need to upgrade its version or install `make` from homebrew(which contains latest version 4.1 `make`, installed with prefix `g`).
 @ngaut Sure. The PR is raised as #615.
  sorry，the title should be default value caused data missing

1、using goleveldb
2、a column name Pv defined as ``pv` BIGINT(20) NULL DEFAULT 1`
3、it insert succeed
4、restart db，all data inserted are missing
 @ngaut sorry, i mis-touched my ''Enter" key.

testing code:

```
package main
import (
    _ "github.com/pingcap/tidb"
    _ "github.com/go-xorm/tidb"
    "github.com/go-xorm/xorm"
    "fmt"
)

type A struct {
    Id   int
    Name string
    Pv   int `xorm:"default 1"`
}

type B struct {
    Id   int
    Name string
    Pv   int64 `xorm:"default 1"`
}

func main() {
    engine, err := xorm.NewEngine("tidb", "goleveldb://test/tidb")
    if err != nil {
        panic(err)
    }
    //create table
    engine.Sync2(new(A),new(B))

    //query data
    fmt.Println("-------begin query------")
    //should be 0 if the first run---but every time you run the code, it all 0 or 1(very strange)
    fmt.Println(engine.Count(new(A)))
    fmt.Println(engine.Count(new(B)))
    //adding data

    fmt.Println("-------adding data------")
    a := &A{Name:"ElvizLai"}
    b := &B{Name:"ElvizLai"}
    fmt.Println(engine.InsertOne(a))
    fmt.Println(engine.InsertOne(b))
}
```
 @ngaut @disksing am i missed something？

reading tidb log and found out engine.InsertOne can only autocommit when db created. It will not autocommit when the table already exist. Should use session to commit instead. It is not a TiDB bug, so I'll close this iuuse.
 @shenli you are right. It seems that engine.InsertOne autocommit not work when db already exist.(U can run that code twice, but only one line data inserted). I tried using session to commit, and it succeed. I not very sure what caused this issue.
  I try to use tidb's parser to parse  the delete Statement  like this two example 
a. DELETE t1, t2 FROM t1 INNER JOIN t2 INNER JOIN t3 WHERE t1.id=t2.id AND t2.id=t3.id;
parse result : 
stmt type   : *stmts.DeleteStmt 
stmt.Where        :  t1.id = t2.id && t2.id = t3.id  |  *expression.BinaryOperation
stmt.Order        :    |  *rsets.OrderByRset
stmt.Limit        :  <nil>  |  *rsets.LimitRset
stmt.LowPriority  :  false  |  bool
stmt.Ignore       :  false  |  bool
stmt.Quick        :  false  |  bool
stmt.MultiTable   :  true  |  bool
stmt.BeforeFrom   :  false  |  bool
stmt.TableIdents  :  [t1 t2]  |  []table.Ident
stmt.Refs         :  (t1 CROSS JOIN t2) CROSS JOIN t3  |  *rsets.JoinRset

TableIdents   contain t1 and t2  is right . 
b.   DELETE FROM t1 WHERE  id  in ( 2,4,5)  
parse result : 
stmt type   : *stmts.DeleteStmt 
stmt.Where        :  id IN (2,4,5)  |  *expression.PatternIn
stmt.Order        :    |  *rsets.OrderByRset
stmt.Limit        :  <nil>  |  *rsets.LimitRset
stmt.LowPriority  :  false  |  bool
stmt.Ignore       :  false  |  bool
stmt.Quick        :  false  |  bool
stmt.MultiTable   :  false  |  bool
stmt.BeforeFrom   :  false  |  bool
stmt.TableIdents  :  []  |  []table.Ident
stmt.Refs         :  <nil>  |  *rsets.JoinRset
in this result , TableIdents   is null . I want to know where is table t1 ?  Is there something wrong ? or i make a mistake . 

waiting for Respond ， thanks 
 @shenli  I know what you mean , but when i parse this :   DELETE FROM t1 WHERE  id  in ( 2,4,5)  statement , the result show stmt.Refs   is nil  :  
 _ sql  :  DELETE FROM t1 WHERE  id  in ( 2,4,5)  
stmt type   : *stmts.DeleteStmt 
stmt.Where        :  id IN (2,4,5)  |  *expression.PatternIn
stmt.Order        :    |  *rsets.OrderByRset
stmt.Limit        :  <nil>  |  *rsets.LimitRset
stmt.LowPriority  :  false  |  bool
stmt.Ignore       :  false  |  bool
stmt.Quick        :  false  |  bool
stmt.MultiTable   :  false  |  bool
stmt.BeforeFrom   :  false  |  bool
stmt.TableIdents  :  []  |  []table.Ident
stmt.Refs         :  <nil>  |  *rsets.JoinRset

stmt.Refs    is nil 
 This makes  me  wonder 
 maybe something wrong in my code .  I will check it and try again , thanks @shenli 
  keep use host network, it will let tidb can access from host
  SQL like this : select \* from t1 join (select id , name from t4 where id = 5 ) t2 left join t3 on t2.id = t3.id
解析完成之后是一个 _stmts.SelectStmt 结构 . From 部分  t1 join (select id , name from t4 where id = 5 ) t2 left join t3 on t2.id = t3.id 整体是一个  *rsets.JoinRset , 其 left ： t1 join (select id , name from t4 where id = 5 ) t2 , 也是一个 *rsets.JoinRset ， 这个_rsets.JoinRset的right部分已经是 *rsets.TableSource 了。 我的问题是 select id , name from t4 where id = 5 是一个标准的SelectStmt  ，这个 解析完成是一个 string 。 如何转换成为 SelectStmt   ？  

下面是我解析t1 join (select id , name from t4 where id = 5 ) t2 生成的格式： 

```
node Left  >  t1  | lftype>  *rsets.TableSource
table :  t1 
node right >  (&{%!s(bool=false) [Field.Name:id, Field.Expr:id Field.Name:name, Field.Expr:name] t4 <nil> <nil> <nil> <nil>  %!s(*rsets.WhereRset=&{0xc20803a840 <nil>}) %!s(coldef.LockType=0) }) AS t2  | ritype>  *rsets.TableSource
table :  (&{%!s(bool=false) [Field.Name:id, Field.Expr:id Field.Name:name, Field.Expr:name] t4 <nil> <nil> <nil> <nil>  %!s(*rsets.WhereRset=&{0xc20803a840 <nil>}) %!s(coldef.LockType=0) }) AS t2
```
 got it , thanks very much . @shenli 
  `BackOffBase`, `BackOffCap` and `RetryLimit` are picked arbitrarily. Now they goes to `var` instead of `const` because we might want it customizable for package user.
 fix #444 
 Now changes has gone to session.go
 Maybe I could better waiting for #583 being merged?

On Sun, Nov 15, 2015 at 11:51 PM, siddontang notifications@github.com
wrote:

> ## kv.RunInNewTxn need this too. 
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/pingcap/tidb/pull/592#issuecomment-156915128
 Good to know. Thanks.
  Signed-off-by: ZhiFeng Hu hufeng1987@gmail.com
  modify .gitignore to accomodate the IDE intellij
  tidb> select \* from tbl_test where instr(name, 'a') != -1;
2015/11/10 15:17:31 session.go:336: [error] Syntax error: select \* from tbl_test where instr(name, 'a') != -1;
2015/11/10 15:17:31 session.go:337: [error] Error occurs at line 1 column 35 near "(".
2015/11/10 15:17:31 main.go:231: [error] line 1 column 35 near "("
/root/coding/go/src/github.com/pingcap/tidb/tidb.go:129:
/root/coding/go/src/github.com/pingcap/tidb/session.go:338:
/root/coding/go/src/github.com/pingcap/tidb/driver.go:328:
/root/coding/go/src/github.com/pingcap/tidb/interpreter/main.go:63:
 Indeed, I'm pleased to contribute. But I found it's hard to fully understand the structure. Especially the plan made by the optimizer :(. Are there some logs to help understanding?

And I found that explain clause doesn't always show correct result.
I can't find any difference between these two queries according the explaining result

tidb> explain select  \* from tbl_test a join tbl_test b on a.id + 1 = b.id;
+-------------------------------------------------+
|                                                 |
+-------------------------------------------------+
| ┌Compute CROSS Cartesian product of           |
| ┌Iterate all rows of table "tbl_test"         |
| └Output field names ["id" "name"]             |
| ┌Iterate all rows of table "tbl_test"         |
| └Output field names ["id" "name"]             |
| └Output field names ["id" "name" "id" "name"] |
| ┌Evaluate a.id, a.name, b.id, b.name,         |
| └Output field names ["id" "name" "id" "name"] |
+-------------------------------------------------+
8 rows in set (0.00 sec)
tidb> explain select  \* from tbl_test a join tbl_test b on a.id = b.id;
+-------------------------------------------------+
|                                                 |
+-------------------------------------------------+
| ┌Compute CROSS Cartesian product of           |
| ┌Iterate all rows of table "tbl_test"         |
| └Output field names ["id" "name"]             |
| ┌Iterate all rows of table "tbl_test"         |
| └Output field names ["id" "name"]             |
| └Output field names ["id" "name" "id" "name"] |
| ┌Evaluate a.id, a.name, b.id, b.name,         |
| └Output field names ["id" "name" "id" "name"] |
+-------------------------------------------------+
8 rows in set (0.00 sec)
 Hi @siddontang 
why not build a mailing list ?
 agree, no idea where to get start ~
  Hi,

Would it be possible to add support for $N placeholders in prepared statements, similarly to what sqlite and postgresql support?
In sqlite N can be anything, number or text, whereas in postgresql N is always a number, and iirc, is sequential. Regardless, in both cases one can use $N where N is a number, keep things sequential, and allow for parameters to be repeatable by repeating some value of N for some parameters.
  Missing : symbol?

Signed-off-by: ZhiFeng Hu hufeng1987@gmail.com
  Any missing symbol ? = should be := ?

Signed-off-by: ZhiFeng Hu hufeng1987@gmail.com
  You must install docker first, then

docker build --rm -t tidb-server .

after build success, you may see images via

docker images

docker run -d --name tidb-server tidb-server

Signed-off-by: ZhiFeng Hu hufeng1987@gmail.com
 Need some document explain how to build and how to use. put doc into readme.md or inside docs/ sub directory?
How do you think about?
  You must install docker first, then

docker build --rm -t tidb-server .

after build success, you may see images via

docker images

docker run -d --name tidb-server tidb-server

Signed-off-by: ZhiFeng Hu hufeng1987@gmail.com
 #522  
 The container does not included Golang environment, it just build then generate binary executable tidb-server. then we can running the server inside container.

It's no need to include Golang environment at all, because the server ready for serve, no need recompile or include source code. 
If we need recompile. The Dockfile can be used to compile it . generate new container.
 Ok
  Due to this is a golang pure project. we do not require make tools and commands. 
I had notice the Makefile scripts. it can be rewrite with pure shell /cmd/powershell scripts.
that's friendly for us to make the TiDB. 
  Would you please add Docker images ?
Docker container will be friendly for dev and deploy.
 Ok, May be it is a good start to setup a minimal TiDB Server docker container.
 https://github.com/pingcap/tidb/pull/566
  ```
2015/11/05 16:30:56 conn.go:240: [error] dispatch error Unknown sys var: version_comment
/home/huzhifeng/go/src/github.com/pingcap/tidb/expression/variable.go:87: 
/home/huzhifeng/go/src/github.com/pingcap/tidb/plan/plans/fields.go:83: 
/home/huzhifeng/go/src/github.com/pingcap/tidb/plan/plans/final.go:72: 
/home/huzhifeng/go/src/github.com/pingcap/tidb/rset/rsets/rsets.go:110: 
/home/huzhifeng/go/src/github.com/pingcap/tidb/tidb-server/server/driver_tidb.go:243: 
/home/huzhifeng/go/src/github.com/pingcap/tidb/tidb-server/server/conn.go:398: 
/home/huzhifeng/go/src/github.com/pingcap/tidb/tidb-server/server/conn.go:369: , conn: 127.0.0.1:39172, status: 3, charset: utf8, user: root, lastInsertId: 0
2015/11/05 16:30:56 conn.go:241: [error] cmd: select @@version_comment limit 1

```

base on the latest master branch source code 
 I can not reappear this problem now, may be it was fixed. 
  ```
mysqldump -u root -h 127.0.0.1 --port 4000 --opt test > test.sql
mysqldump: Error: 'table INFORMATION_SCHEMA.FILES does not exist' when trying to dump tablespaces
mysqldump: Couldn't execute 'UNLOCK TABLES': line 1 column 1 near "UNLOCK" (1105)

```
 So the question was : how to backup TiDB ?
 Or you can provided your own export sql tools. If it can replace mysqldump . Ate self dog food seems well done.
  https://github.com/pingcap/tidb/issues/463
 @siddontang @shenli 
 um...@ngaut some test run two parallel transaction.
 @siddontang  Done!
 @siddontang I have other works these days, so I can not fix it recently. May you fix it? I am very sorry.
  In tidb.runStmt, if encount some error in any exec func, you need to rollback the current transaction, otherwise, the txn.UnionStore.Dirty will contain some discard data..

https://github.com/pingcap/tidb/blob/d7c3cc47916db41552b88fb55f2cf0156be4bea1/tidb.go#L171
 Example:

```
[wink@centos test_sqls]$ cat tmp.sql
CREATE DATABASE IF NOT EXISTS `test`;
USE test;
DROP TABLE IF EXISTS `nosharding_test`;
CREATE TABLE `nosharding_test` (
      `id` int(11) UNSIGNED NOT NULL AUTO_INCREMENT,
      `test1` int(5) UNIQUE,
      PRIMARY KEY (`id`)
)ENGINE=InnoDB DEFAULT CHARSET=utf8;

[wink@centos test_sqls]$ mysql -h 127.0.0.1 -P 4000 -u root -D test < tmp.sql
[wink@centos test_sqls]$ mysql -h 127.0.0.1 -P 4000 -u root -D test
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 10003
Server version: 5.5.31-TiDB-1.0 MySQL Community Server (GPL)

Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> desc nosharding_test;
+-------+------------------+------+------+---------+----------------+
| Field | Type             | Null | Key  | Default | Extra          |
+-------+------------------+------+------+---------+----------------+
| id    | int(11) UNSIGNED | NO   | PRI  | NULL    | auto_increment |
| test1 | int(5)           | YES  | UNI  | NULL    |                |
+-------+------------------+------+------+---------+----------------+
2 rows in set (0.00 sec)

mysql> insert into nosharding_test(id, test1) values(1, 1);
Query OK, 1 row affected (0.00 sec)

mysql> insert into nosharding_test(id, test1) values(2, 1);
ERROR 1105 (HY000): Error: key already exist
mysql> insert into nosharding_test(id, test1) values(2, 2);
ERROR 1105 (HY000): Error: key already exist
mysql> select * from nosharding_test;
+----+-------+
| id | test1 |
+----+-------+
|  1 |     1 |
+----+-------+
1 row in set (0.01 sec)

mysql> insert into nosharding_test(id, test1) values(2, 2);
ERROR 1105 (HY000): Error: key already exist
mysql>
```
 @ngaut yes. I'll fix it later.
  If we have a table:

```
CREATE TABLE `test` (
      `id` int(11) UNSIGNED NOT NULL AUTO_INCREMENT,
      `test1` int UNIQUE,
      PRIMARY KEY (`id`)
)ENGINE=InnoDB DEFAULT CHARSET=utf8;
```

if we exec the below transactions in mysql in two clients:

client 1: 

```
mysql> begin;
Query OK, 0 rows affected (0.00 sec)

mysql> insert into test(id, test1) values(1, 1);
Query OK, 1 row affected (0.00 sec)
```

client 2: 

```
mysql> begin;
Query OK, 0 rows affected (0.00 sec)

mysql> insert into test(id, test1) values(1, 2);
blocking
```

the client2 will block till client 1 commit; and client 2 will failed with a duplicate key error.

But in tiDB, the client1 and client 2 will success both, because tidb don't lock any key in insert statement exec func. I have tried in tidb, and I got the result:

```
mysql> select * from test;
+----+-------+
| id | test1 |
+----+-------+
|  1 |     1 |
|  1 |     2 |
+----+-------+
2 rows in set (0.00 sec)
```
  This PR is to resolve #400
Add interface `MemBuffer` to decouple UnionStore with specific in-memory buffer. Any implementation of this interface should be able to work with UnionStore.

Currently there are two `MemBuffer` implementations:
- `memDbBuffer` using `memdb` from `goleveldb`
- `btreeBuffer` using `btree` from `memkv` 

Add some micro-benchmark comparing performance of the two implementations:

```
BenchmarkBTreeBufferSequential-8           1    1353185830 ns/op    225864832 B/op  13500988 allocs/op
BenchmarkBTreeBufferRandom-8               1    1705782034 ns/op    219036992 B/op  13011734 allocs/op
BenchmarkMemDbBufferSequential-8          10     148360815 ns/op    13759944 B/op          5 allocs/op
BenchmarkMemDbBufferRandom-8               5     237867121 ns/op    15811740 B/op          9 allocs/op
BenchmarkBTreeIter-8                     100      16262683 ns/op     1600144 B/op     100002 allocs/op
BenchmarkMemDbIter-8                     100      13160985 ns/op         245 B/op          3 allocs/op
BenchmarkBTreeCreation-8            20000000           100 ns/op          72 B/op          2 allocs/op
BenchmarkMemDbCreation-8               10000        249574 ns/op     1059780 B/op          8 allocs/op
```

MemDbBuffer is faster and an educated guess is because it pre-allocates a big chunk of memory.

There is another try with a modified version of memdb(removing all locking instructions, it's not being used in multi-thread environment) but the performance improvement is trivial, therefore it's not included in this PR.

Right now UnionStore is still using memdb as the storage engine.
 Squashed all commits into one and updated function names and comments.
  Current kv_test `checkSeek` is not complete. For non-existing key seeking, it only covers the case that seeking key is larger the max key and the expected behavior is to have an invalid iterator returned; but the case that the non-existing seeking key is between existing keys is not covered and their current behaviors are just inverse:
- seek beyond maximum: an invalid iterator is returned, this has already been tested.
- seek between existing keys: a valid iterator is returned which has been positioned at the key that is the smallest one larger than the seeking key. This the the test case added by this PR.

This PR has not changed any kv implementation but just added test cases to reveal this behavior.
  I see in the func CreateTableStmt.Exec(), CreateTableStmt.IfNotExists member  not pass to ddl.CreateTable(), so the sql "create table if not exist" will not work. 
 yeah, Create database, it works, but I mean the create table .
 I saw this, but notice the CreateTableStmt.IfNotExists not pass to sessionctx.GetDomain(ctx).DDL().CreateTable(ctx, s.Ident.Full(ctx), s.Cols, s.Constraints), so the error never be ddl.ErrExists,
 ok, I will fix it..it is easy.
 @shenli :) you are right. but is it correctly? I mean in mysql, if I wanna replace my table definition, I can just use "create table", and tidb return error when it was duplicated anyway.
 I know what you mean, and It is diffrent from mysql, So I get confused..
 no, if you use "create table test xxx", and the table test is already existed, mysql will replace it, tidb is diffrent, but you don't have to follow mysql, because I think tidb is more safe in this way.
 sorry, my test code drop it before I create it, you are right...
  Possibly related to #88. 

Running 64 bit Linux with Go 1.5

```
$ go get -u github.com/pingcap/tidb
# github.com/pingcap/tidb/parser
../../../github.com/pingcap/tidb/parser/yy_parser.go:17: undefined: yyLexer
../../../github.com/pingcap/tidb/parser/yy_parser.go:18: undefined: yyParse
```

I also manually used `go get` for `github.com/qiuyesuifeng/golex` and `github.com/qiuyesuifeng/goyacc`. It didn't help. 

I'm following the information [here](https://github.com/pingcap/tidb/blob/master/docs/USAGE.md). This does not mention the use of the `make` file. 

If I however, do try to use it, it gives me this:

```
go get github.com/tools/godep
go get github.com/qiuyesuifeng/goyacc
go get github.com/qiuyesuifeng/golex
a=`mktemp temp.XXXXXX`; \
goyacc -o /dev/null -xegen $a parser/parser.y; \
goyacc -o parser/parser.go -xe $a parser/parser.y 2>&1 | grep "shift/reduce" | awk '{print} END {if (NR > 0) {print "Find conflict in parser.y. Please check y.output for more information."; exit 1;}}';  \
rm -f $a; \
rm -f y.output 
/bin/sh: 2: goyacc: not found
sed: can't read parser/parser.go: No such file or directory
Makefile:28: recipe for target 'parser' failed
make: *** [parser] Error 2
```
 @siddontang Did not think of the latter (appending `$GOPATH/bin` to `$PATH`). Didn't know it was needed ;-).It works now - thank you :-). 

Perhaps the use of the `Makefile` should be documented at `USAGE.md` as well?
  Shall maximum retry limit be configurable by user or hard-coded? Also, I found this post might be helpful to implement the backoff: http://www.awsarchitectureblog.com/2015/03/backoff.html 
 Sounds good for me. By the way, if any one wants to take this issue, just notify me and go for it. I'm putting effort at it but cannot guarantee enough spare time recently.

On Sat, Oct 31, 2015 at 12:38 AM, siddontang notifications@github.com
wrote:

> @xwb1989  maybe hard code at first. 
> 
> ## You can choose the best back off implementation you think and send up a PR. :-)
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/pingcap/tidb/issues/444#issuecomment-152697397
  it tests on Windows7 x64 and runs ok.
    I'm interested in this issue but not sure where to start. 

Once thing caught my attention is `UnionIter.updateCur()` is implicitly depending on a contract that: 
- `memdb` and `snapshot`'s iterators are iterating their k/v storage deterministically and in the same order; it's presumably true if they use the same `COMPARE` function for ordering keys, and more specifically, `bytes.Compare` in current implementation. 

The caveat is there is no way to enforce such contract and we can not extend the contract to other `COMPARE` functions in current implementation.
 A handy option would be adopting the memkv; I'm concerned that it's not a concurrent implementation and throughout would be limited under high contention. May I know more about the use case/requirement and do you have benchmark to evaluate the performance?

On Wed, Oct 21, 2015 at 12:49 AM, goroutine notifications@github.com
wrote:

> @xwb1989 If you need any help, Please let me know. Thanks for contributing.
> 
> ## Looking forward your PR.
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/pingcap/tidb/issues/400#issuecomment-149782238
 Well it seems that memkv is being used otherwhere but you have a plan to replace(according to comments), so it's better not to rely on that package.
 NVM, just realized the only consumer of UnionStore is transaction, which is(I think as a standalone transaction) is never supposed to be in a concurrent context.
  to support sql like "Create Table test(a CHAR(10) CHARACTER SET utf8)", see details:
"https://dev.mysql.com/doc/refman/5.0/en/create-table.html",
data_type:
    ...
    | CHAR[(length)] [BINARY]
      [CHARACTER SET charset_name] [COLLATE collation_name]
 I have signed the CLA now.
  not enable CLIENT_PLUGIN_AUTH(https://dev.mysql.com/doc/internals/en/connection-phase-packets.html#packet-Protocol::Handshake),
0x00 is filler.
 It seems work with 0x15 or 0x00. I think if CLIENT_PLUGIN_AUTH flag not set client will not check this byte's value. BTW, how to sign  contributor license agreement
 OK, I change 0x00 back to 0x15
   CLA signed
  I use `gox` to compile `tidb` as library in my projecct [pugo](https://github.com/go-xiaohei/pugo),

it shows 

```
--> linux/386 error: exit status 2
Stderr: # github.com/pingcap/tidb/expression
E:\GOPATH\src\github.com\pingcap\tidb\expression\extract.go:118: constant 10000000000 overflows int

--> windows/386 error: exit status 2
Stderr: # github.com/pingcap/tidb/expression
E:\GOPATH\src\github.com\pingcap\tidb\expression\extract.go:118: constant 10000000000 overflows int

--> darwin/386 error: exit status 2
Stderr: # github.com/pingcap/tidb/expression
E:\GOPATH\src\github.com\pingcap\tidb\expression\extract.go:118: constant 10000000000 overflows int

--> linux/arm error: exit status 2
Stderr: # github.com/pingcap/tidb/expression
E:\GOPATH\src\github.com\pingcap\tidb\expression\extract.go:118: constant 10000000000 overflows int
```

https://github.com/pingcap/tidb/blob/master/expression/extract.go#L118

the code shows that it use `int` type. maybe it should be `int64` to keep compatible with 386 os,
 add PR https://github.com/pingcap/tidb/pull/358
  How to deal with the following questions:
When I download github.com/pingcap/tidb, I always can't get package about golang.org？
$ go get -d github.com/pingcap/tidb
package golang.org/x/text/encoding: unrecognized import path "golang.org/x/text/encoding"
package golang.org/x/text/encoding/charmap: unrecognized import path "golang.org/x/text/encoding/charmap"
package golang.org/x/text/encoding/japanese: unrecognized import path "golang.org/x/text/encoding/japanese"
package golang.org/x/text/encoding/korean: unrecognized import path "golang.org/x/text/encoding/korean"
package golang.org/x/text/encoding/simplifiedchinese: unrecognized import path "golang.org/x/text/encoding/simplifiedchinese"
package golang.org/x/text/encoding/traditionalchinese: unrecognized import path "golang.org/x/text/encoding/traditionalchinese"
package golang.org/x/text/encoding/unicode: unrecognized import path "golang.org/x/text/encoding/unicode"
package golang.org/x/text/transform: unrecognized import path "golang.org/x/text/transform"
  @ngaut I will pick some functions in this issue.
 @ngaut Actually, the `expression` folder has been removed. So maybe this issue could be closed. 
Any start issue suggested?
 @siddontang , could I have a try for this?

But I want to know how could I run `make test` or `make check` for my PR?

I could not see it from `CONTRIBUTING.md` @coocood, not found yet. Do you mean I should cross the wall to download some dependency package?   
@coocood, after I run `make test`, this is the error I met.
```
# github.com/pingcap/tidb/parser
parser/lexer.go:92: undefined: yySymType
parser/misc.go:494: undefined: yySymType
parser/yy_parser.go:60: undefined: yySymType
parser/yy_parser.go:61: undefined: yySymType
parser/yy_parser.go:62: undefined: yySymType
FAIL	github.com/pingcap/tidb [build failed]
# github.com/pingcap/tidb/parser
parser/lexer.go:92: undefined: yySymType
parser/misc.go:494: undefined: yySymType
parser/yy_parser.go:60: undefined: yySymType
parser/yy_parser.go:61: undefined: yySymType
parser/yy_parser.go:62: undefined: yySymType
FAIL	github.com/pingcap/tidb/ast [build failed]
# github.com/pingcap/tidb/parser
/var/folders/72/byjy11cs0dj_z3rjtxnj_nn00000gn/T/go-build175989233/github.com/pingcap/tidb/parser/_test/_obj_test/lexer.go:100: undefined: yySymType
/var/folders/72/byjy11cs0dj_z3rjtxnj_nn00000gn/T/go-build175989233/github.com/pingcap/tidb/parser/_test/_obj_test/misc.go:516: undefined: yySymType
/var/folders/72/byjy11cs0dj_z3rjtxnj_nn00000gn/T/go-build175989233/github.com/pingcap/tidb/parser/_test/_obj_test/yy_parser.go:61: undefined: yySymType
/var/folders/72/byjy11cs0dj_z3rjtxnj_nn00000gn/T/go-build175989233/github.com/pingcap/tidb/parser/_test/_obj_test/yy_parser.go:62: undefined: yySymType
/var/folders/72/byjy11cs0dj_z3rjtxnj_nn00000gn/T/go-build175989233/github.com/pingcap/tidb/parser/_test/_obj_test/yy_parser.go:63: undefined: yySymType
make: *** [gotest] Error 2
``` @coocood , should I cross the wall?
```
package golang.org/x/tools/go/gcimporter15: unrecognized import path "golang.org/x/tools/go/gcimporter15" (https fetch: Get https://golang.org/x/tools/go/gcimporter15?go-get=1: dial tcp 216.239.37.1:443: i/o timeout
``` @coocood ,Indeed, `make test` works now. 

Thanks a lot.  Shouldn't some salt be used? Or ideally a password hashing library so that someone with cryptographic knowledge can maintain the hashing.
 Ok, I see where the salt comes in but I'm still unconvinced about the overall system. It appears that there is no way to upgrade the hashes in the future and SHA1 is already getting chipped away at. Also three hashes on SHA1 is very very cheep so it won't do much to stop brute force attacks.
  when  use mysql client connect to a tidb server  ,this happen and result  tidb server exit
 thx  @siddontang changed cmd( mysql -h 127.0.0.1 -P 4000 -u root -D test ) to -p 4000 is ok
 ➜  ~ mysql -h 127.0.0.1 -P 4000 -u root -D test
ERROR 2013 (HY000): Lost connection to MySQL server at 'reading authorization packet', system error: 0 "Internal error/check (Not system error)"

All I do is stop pd leader. After campaign, this happened.
Restart tidb, this can solve. But NOT automatic.

@ngaut @siddontang maybe re-open this issue.

After a few minutes, All server are down.
I use Docker for Mac stable version 1.12.0
  I'm using Vagrant.

System: Linux squeeze-i386 2.6.32-5-686 #1 SMP Tue May 13 16:33:32 UTC 2014 i686 GNU/Linux

Error log:

```
godep go test -cover ./...
ok      github.com/pingcap/tidb 0.105s  coverage: 71.1% of statements
ok      github.com/pingcap/tidb/column  0.002s  coverage: 82.7% of statements
?       github.com/pingcap/tidb/context [no test files]
ok      github.com/pingcap/tidb/ddl 0.029s  coverage: 82.7% of statements
ok      github.com/pingcap/tidb/domain  0.005s  coverage: 86.7% of statements
ok      github.com/pingcap/tidb/expression  0.006s  coverage: 91.9% of statements
ok      github.com/pingcap/tidb/expression/builtin  0.003s  coverage: 95.7% of statements
ok      github.com/pingcap/tidb/expression/subquery 0.002s  coverage: 0.0% of statements
ok      github.com/pingcap/tidb/field   0.002s  coverage: 100.0% of statements
ok      github.com/pingcap/tidb/infoschema  0.005s  coverage: 98.6% of statements
?       github.com/pingcap/tidb/interpreter [no test files]
?       github.com/pingcap/tidb/kv  [no test files]
ok      github.com/pingcap/tidb/kv/memkv    1.443s  coverage: 81.8% of statements
ok      github.com/pingcap/tidb/meta    0.005s  coverage: 85.0% of statements
ok      github.com/pingcap/tidb/meta/autoid 0.003s  coverage: 89.5% of statements
ok      github.com/pingcap/tidb/model   0.002s  coverage: 100.0% of statements
ok      github.com/pingcap/tidb/mysqldef    0.009s  coverage: 89.6% of statements
ok      github.com/pingcap/tidb/parser  0.008s  coverage: 27.1% of statements
?       github.com/pingcap/tidb/parser/coldef   [no test files]
ok      github.com/pingcap/tidb/parser/opcode   0.001s  coverage: 100.0% of statements
?       github.com/pingcap/tidb/plan    [no test files]
ok      github.com/pingcap/tidb/plan/plans  0.043s  coverage: 76.5% of statements
?       github.com/pingcap/tidb/rset    [no test files]
ok      github.com/pingcap/tidb/rset/rsets  0.011s  coverage: 87.5% of statements
ok      github.com/pingcap/tidb/sessionctx  0.002s  coverage: 100.0% of statements
ok      github.com/pingcap/tidb/sessionctx/db   0.001s  coverage: 100.0% of statements
?       github.com/pingcap/tidb/sessionctx/forupdate    [no test files]
ok      github.com/pingcap/tidb/sessionctx/variable 0.002s  coverage: 37.1% of statements
?       github.com/pingcap/tidb/stmt    [no test files]
ok      github.com/pingcap/tidb/stmt/stmts  0.139s  coverage: 83.7% of statements
ok      github.com/pingcap/tidb/store/localstore    0.038s  coverage: 80.2% of statements
ok      github.com/pingcap/tidb/store/localstore/boltdb 0.014s  coverage: 86.4% of statements
?       github.com/pingcap/tidb/store/localstore/engine [no test files]
ok      github.com/pingcap/tidb/store/localstore/goleveldb  0.002s  coverage: 86.7% of statements
ok      github.com/pingcap/tidb/table   0.009s  coverage: 100.0% of statements
ok      github.com/pingcap/tidb/table/tables    0.025s  coverage: 75.2% of statements
?       github.com/pingcap/tidb/tidb-server [no test files]
ok      github.com/pingcap/tidb/tidb-server/server  0.132s  coverage: 64.0% of statements
ok      github.com/pingcap/tidb/util    0.004s  coverage: 73.1% of statements
ok      github.com/pingcap/tidb/util/arena  0.001s  coverage: 100.0% of statements
ok      github.com/pingcap/tidb/util/charset    0.001s  coverage: 96.6% of statements
ok      github.com/pingcap/tidb/util/codec  0.002s  coverage: 89.7% of statements
?       github.com/pingcap/tidb/util/errors [no test files]
ok      github.com/pingcap/tidb/util/errors2    0.001s  coverage: 100.0% of statements
ok      github.com/pingcap/tidb/util/format 0.001s  coverage: 81.2% of statements
ok      github.com/pingcap/tidb/util/hack   0.001s  coverage: 92.3% of statements
ok      github.com/pingcap/tidb/util/mock   0.001s  coverage: 100.0% of statements
?       github.com/pingcap/tidb/util/mock/mocks [no test files]
ok      github.com/pingcap/tidb/util/printer    0.001s  coverage: 89.8% of statements
2015/09/26 18:27:04 etc.go:370: [error] map[int]string

----------------------------------------------------------------------
FAIL: etc_test.go:244: testTypeEtcSuite.TestRoundFloat

etc_test.go:260:
    c.Assert(f, Equals, t.Expect)
... obtained float64 = -1
... expected float64 = -2

2015/09/26 18:27:04 etc.go:192: [error] unkown type 221, binary true
OOPS: 23 passed, 1 FAILED
--- FAIL: TestT (0.00s)
FAIL
coverage: 84.0% of statements
FAIL    github.com/pingcap/tidb/util/types  0.006s
godep: go exit status 1
make: *** [gotest] Error 1
```
 Based on http://docs.travis-ci.com/user/ci-environment/#Virtualization-environments , I don't think so.
 Update: same error occurs...

Maybe someday will be fixed automatically... :trollface:
 It looks like a small failed test case, but I don't know the details, so I can't really tell... :sweat:
 I need to boot up my vagrant and use VIM :dizzy_face:

I'll report back ASAP.
 @qiuyesuifeng passed for that branch :trollface:
 @qiuyesuifeng where should I modify the code? Same place as `math.Abs`?
 That's nice :D

But I just left the home, will be back about 12 hrs...
 @qiuyesuifeng passed :D
 Please close this issue after you merged into `master` branch.
  when I select a database not exists 

2015/09/24 15:24:38 tidb.go:89: [debug] compiling use mysqls
2015/09/24 15:24:38 session.go:242: [warning] session:{
  "currDBName": "",
  "sid": 3
}, err:Database not exist
panic: runtime error: invalid memory address or nil pointer dereference
[signal 0xb code=0x1 addr=0x30 pc=0x4a0986]

goroutine 22 [running]:
github.com/pingcap/tidb/tidb-server/server.(_clientConn).Close(0xc820112160, 0x0, 0x0)
    /data/go/golib/src/github.com/pingcap/tidb/tidb-server/server/conn.go:110 +0xd6
github.com/pingcap/tidb/tidb-server/server.(_clientConn).readHandshakeResponse(0xc820112160, 0x0, 0x0)
    /data/go/golib/src/github.com/pingcap/tidb/tidb-server/server/conn.go:193 +0x527
github.com/pingcap/tidb/tidb-server/server.(_clientConn).handshake(0xc820112160, 0x0, 0x0)
    /data/go/golib/src/github.com/pingcap/tidb/tidb-server/server/conn.go:84 +0x9d
github.com/pingcap/tidb/tidb-server/server.(_Server).onConn(0xc82000bb00, 0x7ffe01f19d38, 0xc82002a030)
    /data/go/golib/src/github.com/pingcap/tidb/tidb-server/server/server.go:141 +0x199
created by github.com/pingcap/tidb/tidb-server/server.(*Server).Run
    /data/go/golib/src/github.com/pingcap/tidb/tidb-server/server/server.go:120 +0x203
 @shenli hello
1,the golang environment is 1.5.1 version,tidb-server version is the newest master branch
2,use php mysql pdo client

```
$config = array("username" => 'root',"password" => "");
$dsn = "mysql:dbname=mysqls;host=127.0.0.1;port=3006";
$pdo = new PDO($dsn, $config['username'], $config['password'], array(
                 PDO::MYSQL_ATTR_INIT_COMMAND => "SET NAMES utf8"
));
```
 @shenli dsn named "mysqls" is my test case 
thanks,i notice that you have fix this bug
  It would be great to have RethinkDB style notifications for building real-time apps. For example, something like: 

``` SQL
SELECT * FROM scores ORDER BY points DESC LIMIT 5 SUBSCRIBE
```

would return the top 5 scores the first time it is called, but it would also continue returning results to the calling function (Goroutine?) whenever the result changes. 

To unsubscribe from this notification, you could later send:

``` SQL
SELECT * FROM scores ORDER BY points DESC LIMIT 5 UNSUBSCRIBE
```

Even more flexible would be a way to receive JSON updates to your API:

``` SQL
SELECT * FROM scores ORDER BY points DESC LIMIT 5 SUBSCRIBE JSON  `http://localhost:8000/update-score`
```

Thoughts?
 shame you didn't put this into some kind of todo list, even if longer term. I think you will regret it down the line.
  When following the examples in README.md , we found the mysql cmd will use the current system name as user name to connect to the server. When It's not root, users will get the access denied error and be confused.

Update the mysql cmd in README.md to make it clear.
  Is there any test code which could be used to test these time functions? If someone adds support for a time funtion, how to make sure the newly added function is working?
 @ngaut The tests for mysql would be some good reference. I'm looking for some test codes like unit tests in TiDB to test these time functions, so that newly added time functions could be tested before submitted to the main branch.
 May I suggest that `unix_timestamp()` is a critical function that should be supported, especially in light of `from_unixtime()` already being implemented.

The current lack of both `unix_timestamp()` and `tiemstampdiff()` makes it very difficult to do timestamp comparisons. @shenli thank you -- `unix_timestamp()` works! [omnidb](https://github.com/OmniDB/OmniDB) can be handy, but it fails to login tidb because it executes a `SELECT TIMEDIFF(NOW(), UTC_TIMESTAMP())` right after authentication and function `utc_timestamp()` is not supported yet, expect tidb to improve and benefit the eco  @shenli Not at all, I will do it later. @ngaut yes, i confirm the fix 395a9c6129239f27d007aee10309531d4a718f86  solves the issue raised earlier, omnidb client can login to Tidb and function `UTC_TIMESTAMP` works just fine, THANKS guys !  pls add ponyorm for python to the list  2015/09/19 21:39:04 session.go:235: [error] Syntax error: /\* mysql-connector-java-5.1.35 ( Revision: 5fb9c5849535c13917c2cf9baaece6ef9693ef27 ) */SHOW VARIABLES WHERE Variable_name ='language' OR Variable_name = 'net_write_timeout' OR Variable_name = 'interactive_timeout' OR Variable_name = 'wait_timeout' OR Variable_name = 'character_set_client' OR Variable_name = 'character_set_connection' OR Variable_name = 'character_set' OR Variable_name = 'character_set_server' OR Variable_name = 'tx_isolation' OR Variable_name = 'transaction_isolation' OR Variable_name = 'character_set_results' OR Variable_name = 'timezone' OR Variable_name = 'time_zone' OR Variable_name = 'system_time_zone' OR Variable_name = 'lower_case_table_names' OR Variable_name = 'max_allowed_packet' OR Variable_name = 'net_buffer_length' OR Variable_name = 'sql_mode' OR Variable_name = 'query_cache_type' OR Variable_name = 'query_cache_size' OR Variable_name = 'license' OR Variable_name = 'init_connect'
 Passed, thanks.
I got more errors:

## 2015/09/19 22:52:40 conn.go:257: [error] cmd: -- MySQL dump 10.13  Distrib 5.5.34, for Linux (x86_64)

-- Host: localhost    Database: icar_qa

---

-- Server version   5.5.34-log
/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;

Seems you didn't ignore comments.
  > Written in Go
> Enjoy TiDB as much as we love Go. We believe Go code is both easy and enjoyable to work with. Go makes us improve TiDB fast and makes it easy to dive into the codebase.

``` go
func executeLine(tx *sql.Tx, txnLine string) error {
    if tidb.IsQuery(txnLine) {
        rows, err := tx.Query(txnLine)
        if err != nil {
            return errors.Trace(err)
        }
        defer rows.Close()
        cols, err := rows.Columns()
        if err != nil {
            return errors.Trace(err)
        }

        values := make([][]byte, len(cols))
        scanArgs := make([]interface{}, len(values))
        for i := range values {
            scanArgs[i] = &values[i]
        }

        var datas [][]string
        for rows.Next() {
            err := rows.Scan(scanArgs...)
            if err != nil {
                return errors.Trace(err)
            }

            data := make([]string, len(cols))
            for i, value := range values {
                if value == nil {
                    data[i] = "NULL"
                } else {
                    data[i] = string(value)
                }
            }

            datas = append(datas, data)
        }

        // For `cols` and `datas[i]` always has the same length,
        // no need to check return validity.
        result, _ := printer.GetPrintResult(cols, datas)
        fmt.Printf("%s", result)

        if err := rows.Err(); err != nil {
            return errors.Trace(err)
        }
    } else {
        // TODO: rows affected and last insert id
        _, err := tx.Exec(txnLine)
        if err != nil {
            return errors.Trace(err)
        }
    }
    return nil
}
```

Literally the first file I opened.
 I just fail to see how this is enjoyable to work with. There's a lot of boilerplate for allocation, iteration, error handling every few lines. It's very verbose in general.
 Instead of being a prick, try providing actionable feedback in the future. Go code tends to be verbose when working with `database/sql`. I think this is an interesting project, and I look forward to watching it progress.
  - remove unexpected binary
  A simpler test case is:
`select a as b from t1 having b > 4;`
mysql gives 
`empty set`
but TiDB gives

```
+---+
| b |
+---+
| 2 |
| 4 |
| 4 |
+---+
```
 Following is problematic in `HavingRset.CheckAndUpdateSelectList`, :

```
if field.ContainFieldName(name, selectList.ResultFields, field.OrgFieldNameFlag) {
    continue
}       
if field.ContainFieldName(name, selectList.ResultFields, field.FieldNameFlag) {
    if field.ContainFieldName(name, tableFields, field.OrgFieldNameFlag) {
        selectList.CloneHiddenField(name, tableFields)
    }
    continue
}
```

not having enough time to really dig into yet, but commenting out 

```
    if field.ContainFieldName(name, tableFields, field.OrgFieldNameFlag) {
        selectList.CloneHiddenField(name, tableFields)
    }
```

Can solve this particular problem(but might break others :( 

Just FYI
 Thank you for letting me know :)
 I could confirm that the test cases mentioned above is passing.
  LGTM
  hmm....

```
# github.com/pingcap/tidb/util/types
util/types/convert_test.go:474: constant 4294967295 overflows int
util/types/convert_test.go:475: constant 4294967295 overflows int
util/types/convert_test.go:477: constant -9223372036854775808 overflows int
util/types/convert_test.go:478: constant -9223372036854775808 overflows int
util/types/convert_test.go:479: constant 9223372036854775807 overflows int
util/types/convert_test.go:479: too many errors
```
 Yes I use git pull and checked commit SHA with git log -1
 OK I'm in class will do in 1 hours.
 I rally mean 2 hours...
 It can speed up the fix progress if you can :)
 All passed!
  All tests passes except the following two:

```
# github.com/pingcap/tidb/util/codec
util/codec/codec_test.go:133: constant 1152921504606846975 overflows int
util/codec/codec_test.go:153: constant -9223372036854775808 overflows int
util/codec/codec_test.go:158: constant -9223372036854775808 overflows int
util/codec/codec_test.go:582: constant 9223372036854775807 overflows int
util/codec/codec_test.go:582: constant -9223372036854775808 overflows int
util/codec/codec_test.go:582: too many errors
```

I know it's kind of non-critical, but just in case you know how to fix it.

And another one:

```
FAIL    github.com/pingcap/tidb/util/types [build failed]
godep: go exit status 2
Makefile:76: recipe for target 'gotest' failed
make: *** [gotest] Error 1
```
 Sure, working on it. Will post result when it's done.
 Hmm... seems my Raspi has really small int. :sob:

```
godep go test -cover ./...
^@ok    github.com/pingcap/tidb 0.832s  coverage: 76.7% of statements
ok      github.com/pingcap/tidb/column  0.027s  coverage: 82.3% of statements
?       github.com/pingcap/tidb/context [no test files]
ok      github.com/pingcap/tidb/ddl 0.187s  coverage: 82.8% of statements
ok      github.com/pingcap/tidb/domain  0.105s  coverage: 86.4% of statements
?       github.com/pingcap/tidb/expression  [no test files]
ok      github.com/pingcap/tidb/expression/expressions  0.258s  coverage: 94.2% of statements
ok      github.com/pingcap/tidb/field   0.041s  coverage: 100.0% of statements
ok      github.com/pingcap/tidb/infoschema  0.139s  coverage: 100.0% of statements
?       github.com/pingcap/tidb/interpreter [no test files]
?       github.com/pingcap/tidb/kv  [no test files]
ok      github.com/pingcap/tidb/kv/memkv    23.628s coverage: 81.8% of statements
ok      github.com/pingcap/tidb/meta    0.089s  coverage: 85.0% of statements
ok      github.com/pingcap/tidb/meta/autoid 0.105s  coverage: 89.5% of statements
ok      github.com/pingcap/tidb/model   0.057s  coverage: 100.0% of statements
^@ok    github.com/pingcap/tidb/mysqldef    0.121s  coverage: 89.5% of statements
ok      github.com/pingcap/tidb/parser  0.163s  coverage: 24.2% of statements
?       github.com/pingcap/tidb/parser/coldef   [no test files]
ok      github.com/pingcap/tidb/parser/opcode   0.022s  coverage: 100.0% of statements
?       github.com/pingcap/tidb/plan    [no test files]
ok      github.com/pingcap/tidb/plan/plans  0.501s  coverage: 76.2% of statements
?       github.com/pingcap/tidb/rset    [no test files]
ok      github.com/pingcap/tidb/rset/rsets  0.193s  coverage: 90.4% of statements
ok      github.com/pingcap/tidb/sessionctx  0.029s  coverage: 100.0% of statements
ok      github.com/pingcap/tidb/sessionctx/db   0.030s  coverage: 100.0% of statements
?       github.com/pingcap/tidb/sessionctx/forupdate    [no test files]
ok      github.com/pingcap/tidb/sessionctx/variable 0.095s  coverage: 59.1% of statements
?       github.com/pingcap/tidb/stmt    [no test files]
^@ok    github.com/pingcap/tidb/stmt/stmts  1.317s  coverage: 82.6% of statements
ok      github.com/pingcap/tidb/store/localstore    0.515s  coverage: 80.2% of statements
ok      github.com/pingcap/tidb/store/localstore/boltdb 0.184s  coverage: 86.4% of statements
?       github.com/pingcap/tidb/store/localstore/engine [no test files]
ok      github.com/pingcap/tidb/store/localstore/goleveldb  0.046s  coverage: 86.7% of statements
# github.com/pingcap/tidb/util/types
util/types/convert_test.go:466: constant -2147483649 overflows int
util/types/convert_test.go:470: constant 2147483648 overflows int
util/types/convert_test.go:473: constant 4294967295 overflows int
util/types/convert_test.go:474: constant 4294967295 overflows int
util/types/convert_test.go:474: too many errors
^@ok    github.com/pingcap/tidb/table   0.079s  coverage: 100.0% of statements
ok      github.com/pingcap/tidb/table/tables    0.135s  coverage: 75.6% of statements
ok      github.com/pingcap/tidb/util    0.111s  coverage: 73.1% of statements
ok      github.com/pingcap/tidb/util/charset    0.046s  coverage: 100.0% of statements
ok      github.com/pingcap/tidb/util/codec  0.070s  coverage: 87.4% of statements
?       github.com/pingcap/tidb/util/errors [no test files]
ok      github.com/pingcap/tidb/util/errors2    0.046s  coverage: 100.0% of statements
ok      github.com/pingcap/tidb/util/format 0.028s  coverage: 81.2% of statements
ok      github.com/pingcap/tidb/util/mock   0.028s  coverage: 100.0% of statements
ok      github.com/pingcap/tidb/util/printer    0.042s  coverage: 89.8% of statements
FAIL    github.com/pingcap/tidb/util/types [build failed]
godep: go exit status 2
Makefile:76: recipe for target 'gotest' failed
make: *** [gotest] Error 1
```
 > maybe the int in your platform is 4 bytes. 

Raspi only has 32bit version I think.
  Hi, I would like to contribute to tidb and after watching the presentation of Qi Liu, I guess this might be a good starting point. It would be nice if some further pointers could be provided. Thanks in advanced :)
 Hi, I am willing to contribute to tidb a bit. Is there any function I could try implementing? Thanks a lot.  Some developers might have gnu-sed installed installed in their path, so using the absolute path for the sed binary prevents an error.
   okay~
 It has been updated.
  ```
state 696 // alter tableKwd after charsetKwd after [$end]

  484 TableOptListOpt: TableOptList .  [$end, ',', ';']
  486 TableOptList: TableOptList . TableOpt
  487 TableOptList: TableOptList . ',' TableOpt
   99 DefaultKwdOpt: .  [character, charsetKwd, collation]

    $end           reduce using rule 484 (TableOptListOpt)
    ','            shift, and goto state 699
    ';'            reduce using rule 484 (TableOptListOpt)
    autoIncrement  shift, and goto state 695
    character      reduce using rule 99 (DefaultKwdOpt)
    charsetKwd     reduce using rule 99 (DefaultKwdOpt)
    collation      reduce using rule 99 (DefaultKwdOpt)
    defaultKwd     shift, and goto state 654
    engine         shift, and goto state 693

    DefaultKwdOpt  goto state 694
    TableOpt       goto state 698

    conflict on ',', shift, and goto state 699, reduce using rule 484
```

``` bash
(15:02) jnml@r550:~/src/github.com/cznic/tidb/parser$ goyacc -o /dev/null -cr parser.y
Parse table entries: 124933 of 382547, x 16 bits == 249866 bytes
(15:02) jnml@r550:~/src/github.com/cznic/tidb/parser$ 
```

WARNING: This PR removes the `CommaOpt` item in the `CreateTableStmt` production. Looking at [MySQL docs](http://dev.mysql.com/doc/refman/5.1/en/create-table.html), I believe it should not be accepted in this part of the grammar. However, if I'm mistaken, then you should not merge this PR and please let me know why `CommaOpt` is there - as the proper solution would have to be different (if it then exists at all).
 Comma is `','`, not `';'`, that's a semicolon. IOW, now I'm confused even more ;-)
  ```
state 630 // deleteKwd [',']

  102 DeleteFromStmt: deleteKwd LowPriorityOptional QuickOptional IgnoreOptional . from TableIdent WhereClauseOptional OrderByOptional LimitClause
  103 DeleteFromStmt: deleteKwd LowPriorityOptional QuickOptional IgnoreOptional . TableIdentList from TableRefs WhereClauseOptional
  104 DeleteFromStmt: deleteKwd LowPriorityOptional QuickOptional IgnoreOptional . from TableIdentList using TableRefs WhereClauseOptional
  333 TableIdentList: .  [',', from]

    ','            reduce using rule 333 (TableIdentList)
    after          shift, and goto state 60
    autoIncrement  shift, and goto state 59
    begin          shift, and goto state 61
    bitType        shift, and goto state 62
    boolType       shift, and goto state 63
    booleanType    shift, and goto state 64
    calcFoundRows  shift, and goto state 101
    charsetKwd     shift, and goto state 65
    columns        shift, and goto state 66
    commit         shift, and goto state 67
    dateType       shift, and goto state 68
    datetimeType   shift, and goto state 69
    deallocate     shift, and goto state 70
    do             shift, and goto state 71
    end            shift, and goto state 72
    engine         shift, and goto state 73
    engines        shift, and goto state 74
    execute        shift, and goto state 75
    first          shift, and goto state 76
    from           shift, and goto state 631
    full           shift, and goto state 77
    global         shift, and goto state 88
    identifier     shift, and goto state 56
    local          shift, and goto state 78
    mode           shift, and goto state 100
    names          shift, and goto state 79
    now            shift, and goto state 99
    offset         shift, and goto state 80
    password       shift, and goto state 81
    prepare        shift, and goto state 82
    quick          shift, and goto state 83
    rollback       shift, and goto state 84
    session        shift, and goto state 85
    signed         shift, and goto state 86
    start          shift, and goto state 87
    substring      shift, and goto state 102
    tables         shift, and goto state 89
    textType       shift, and goto state 90
    timeType       shift, and goto state 91
    timestampType  shift, and goto state 92
    transaction    shift, and goto state 93
    truncate       shift, and goto state 94
    unknown        shift, and goto state 95
    value          shift, and goto state 96
    warnings       shift, and goto state 97
    yearType       shift, and goto state 98

    Identifier         goto state 108
    NotKeywordToken    goto state 58
    TableIdent         goto state 616
    TableIdentList     goto state 632
    UnReservedKeyword  goto state 57

    conflict on from, shift, and goto state 631, reduce using rule 333
```

``` bash
(13:54) jnml@r550:~/src/github.com/cznic/tidb/parser$ goyacc -o /dev/null -cr parser.y
Parse table entries: 125176 of 382470, x 16 bits == 250352 bytes
conflicts: 1 shift/reduce
(13:56) jnml@r550:~/src/github.com/cznic/tidb/parser$ 
```
  Attempting to resolve the last few S/R conflicts:

``` yacc
TableIdentList:
    {
        $$ = []table.Ident{}
    }
|   TableIdent
    {
        tbl := []table.Ident{$1.(table.Ident)}
        $$ = tbl
    }
|   TableIdentList ',' TableIdent
    {
        $$ = append($1.([]table.Ident), $3.(table.Ident))
    }
```

[source](https://github.com/pingcap/tidb/blob/6d058fe3e825a2d2429f55170313009d971f826c/parser/parser.y#L2105)

The `TableIdentList` production accepts
- ɛ
- foo
- foo, bar
- foo, bar, baz
- , foo
- , foo, bar

(Where foo, bar is possibly a.foo and b.bar.)

Is that intended? I guess not, because then, for example, this would be valid statements
- DROP TABLE
- DROP TABLE , foo

etc.

My guess is that `TableIdentList` should read like

``` yacc
TableIdentList:
    TableIdent
    {
        tbl := []table.Ident{$1.(table.Ident)}
        $$ = tbl
    }
|   TableIdentList ',' TableIdent
    {
        $$ = append($1.([]table.Ident), $3.(table.Ident))
    }
```

But I have little knowledge of MySQL grammar. Please clarify.

Blocks #73 .
 Thanks for the clarification!
  ```
state 627 // deleteKwd [',']

  102 DeleteFromStmt: deleteKwd LowPriorityOptional . QuickOptional IgnoreOptional from TableIdent WhereClauseOptional OrderByOptional LimitClause
  103 DeleteFromStmt: deleteKwd LowPriorityOptional . QuickOptional IgnoreOptional TableIdentList from TableRefs WhereClauseOptional
  104 DeleteFromStmt: deleteKwd LowPriorityOptional . QuickOptional IgnoreOptional from TableIdentList using TableRefs WhereClauseOptional
  336 QuickOptional: .  [',', after, autoIncrement, begin, bitType, boolType, booleanType, calcFoundRows, charsetKwd, columns, commit, dateType, datetimeType, deallocate, do, end, engine, engines, execute, first, from, full, global, identifier, ignore, local, mode, names, now, offset, password, prepare, quick, rollback, session, signed, start, substring, tables, textType, timeType, timestampType, transaction, truncate, unknown, value, warnings, yearType]

    ','            reduce using rule 336 (QuickOptional)
    after          reduce using rule 336 (QuickOptional)
    autoIncrement  reduce using rule 336 (QuickOptional)
    begin          reduce using rule 336 (QuickOptional)
    bitType        reduce using rule 336 (QuickOptional)
    boolType       reduce using rule 336 (QuickOptional)
    booleanType    reduce using rule 336 (QuickOptional)
    calcFoundRows  reduce using rule 336 (QuickOptional)
    charsetKwd     reduce using rule 336 (QuickOptional)
    columns        reduce using rule 336 (QuickOptional)
    commit         reduce using rule 336 (QuickOptional)
    dateType       reduce using rule 336 (QuickOptional)
    datetimeType   reduce using rule 336 (QuickOptional)
    deallocate     reduce using rule 336 (QuickOptional)
    do             reduce using rule 336 (QuickOptional)
    end            reduce using rule 336 (QuickOptional)
    engine         reduce using rule 336 (QuickOptional)
    engines        reduce using rule 336 (QuickOptional)
    execute        reduce using rule 336 (QuickOptional)
    first          reduce using rule 336 (QuickOptional)
    from           reduce using rule 336 (QuickOptional)
    full           reduce using rule 336 (QuickOptional)
    global         reduce using rule 336 (QuickOptional)
    identifier     reduce using rule 336 (QuickOptional)
    ignore         reduce using rule 336 (QuickOptional)
    local          reduce using rule 336 (QuickOptional)
    mode           reduce using rule 336 (QuickOptional)
    names          reduce using rule 336 (QuickOptional)
    now            reduce using rule 336 (QuickOptional)
    offset         reduce using rule 336 (QuickOptional)
    password       reduce using rule 336 (QuickOptional)
    prepare        reduce using rule 336 (QuickOptional)
    quick          shift, and goto state 629
    rollback       reduce using rule 336 (QuickOptional)
    session        reduce using rule 336 (QuickOptional)
    signed         reduce using rule 336 (QuickOptional)
    start          reduce using rule 336 (QuickOptional)
    substring      reduce using rule 336 (QuickOptional)
    tables         reduce using rule 336 (QuickOptional)
    textType       reduce using rule 336 (QuickOptional)
    timeType       reduce using rule 336 (QuickOptional)
    timestampType  reduce using rule 336 (QuickOptional)
    transaction    reduce using rule 336 (QuickOptional)
    truncate       reduce using rule 336 (QuickOptional)
    unknown        reduce using rule 336 (QuickOptional)
    value          reduce using rule 336 (QuickOptional)
    warnings       reduce using rule 336 (QuickOptional)
    yearType       reduce using rule 336 (QuickOptional)

    QuickOptional  goto state 628

    conflict on quick, shift, and goto state 629, reduce using rule 336
```

``` bash
(12:37) jnml@r550:~/src/github.com/cznic/tidb/parser$ goyacc -o /dev/null -cr parser.y
Parse table entries: 125151 of 382470, x 16 bits == 250302 bytes
conflicts: 2 shift/reduce
(12:37) jnml@r550:~/src/github.com/cznic/tidb/parser$ 
```
  ```
state 136 // parseExpression defaultKwd

  255 Operand: defaultKwd .  [$end, '%', '&', '(', ')', '*', '+', ',', '-', '/', ';', '<', '>', '^', '|', '}', and, andand, as, asc, between, cross, desc, div, elseKwd, end, eq, forKwd, from, full, ge, group, having, identifier, in, inner, is, join, le, left, like, limit, lock, lsh, mod, neq, neqSynonym, not, on, or, order, oror, regexp, right, rlike, rsh, then, union, using, when, where, xor]
  256 Operand: defaultKwd . '(' ColumnName ')'

    $end        reduce using rule 255 (Operand)
    '%'         reduce using rule 255 (Operand)
    '&'         reduce using rule 255 (Operand)
    '('         shift, and goto state 262
    ')'         reduce using rule 255 (Operand)
    '*'         reduce using rule 255 (Operand)
    '+'         reduce using rule 255 (Operand)
    ','         reduce using rule 255 (Operand)
    '-'         reduce using rule 255 (Operand)
    '/'         reduce using rule 255 (Operand)
    ';'         reduce using rule 255 (Operand)
    '<'         reduce using rule 255 (Operand)
    '>'         reduce using rule 255 (Operand)
    '^'         reduce using rule 255 (Operand)
    '|'         reduce using rule 255 (Operand)
    '}'         reduce using rule 255 (Operand)
    and         reduce using rule 255 (Operand)
    andand      reduce using rule 255 (Operand)
    as          reduce using rule 255 (Operand)
    asc         reduce using rule 255 (Operand)
    between     reduce using rule 255 (Operand)
    cross       reduce using rule 255 (Operand)
    desc        reduce using rule 255 (Operand)
    div         reduce using rule 255 (Operand)
    elseKwd     reduce using rule 255 (Operand)
    end         reduce using rule 255 (Operand)
    eq          reduce using rule 255 (Operand)
    forKwd      reduce using rule 255 (Operand)
    from        reduce using rule 255 (Operand)
    full        reduce using rule 255 (Operand)
    ge          reduce using rule 255 (Operand)
    group       reduce using rule 255 (Operand)
    having      reduce using rule 255 (Operand)
    identifier  reduce using rule 255 (Operand)
    in          reduce using rule 255 (Operand)
    inner       reduce using rule 255 (Operand)
    is          reduce using rule 255 (Operand)
    join        reduce using rule 255 (Operand)
    le          reduce using rule 255 (Operand)
    left        reduce using rule 255 (Operand)
    like        reduce using rule 255 (Operand)
    limit       reduce using rule 255 (Operand)
    lock        reduce using rule 255 (Operand)
    lsh         reduce using rule 255 (Operand)
    mod         reduce using rule 255 (Operand)
    neq         reduce using rule 255 (Operand)
    neqSynonym  reduce using rule 255 (Operand)
    not         reduce using rule 255 (Operand)
    on          reduce using rule 255 (Operand)
    or          reduce using rule 255 (Operand)
    order       reduce using rule 255 (Operand)
    oror        reduce using rule 255 (Operand)
    regexp      reduce using rule 255 (Operand)
    right       reduce using rule 255 (Operand)
    rlike       reduce using rule 255 (Operand)
    rsh         reduce using rule 255 (Operand)
    then        reduce using rule 255 (Operand)
    union       reduce using rule 255 (Operand)
    using       reduce using rule 255 (Operand)
    when        reduce using rule 255 (Operand)
    where       reduce using rule 255 (Operand)
    xor         reduce using rule 255 (Operand)
    conflict on '(', shift, and goto state 262, reduce using rule 255 // '(': assoc %precedence, prec 21
```

``` bash
(11:49) jnml@r550:~/src/github.com/cznic/tidb/parser$ goyacc -o /dev/null -cr parser.y
Parse table entries: 125151 of 381555, x 16 bits == 250302 bytes
conflicts: 3 shift/reduce
(11:50) jnml@r550:~/src/github.com/cznic/tidb/parser$ 
```
  ```
state 125 // do substring

  224 NotKeywordToken: substring .  [$end, '%', '&', '(', ')', '*', '+', ',', '-', '.', '/', ';', '<', '>', '^', '|', '}', and, andand, as, asc, between, cross, desc, div, elseKwd, end, eq, forKwd, from, full, ge, group, having, identifier, in, inner, is, join, le, left, like, limit, lock, lsh, mod, neq, neqSynonym, not, on, or, order, oror, regexp, right, rlike, rsh, then, union, using, when, where, xor]
  284 Function: substring . '(' Expression ',' Expression ')'
  285 Function: substring . '(' Expression from Expression ')'
  286 Function: substring . '(' Expression ',' Expression ',' Expression ')'
  287 Function: substring . '(' Expression from Expression forKwd Expression ')'

    $end        reduce using rule 224 (NotKeywordToken)
    '%'         reduce using rule 224 (NotKeywordToken)
    '&'         reduce using rule 224 (NotKeywordToken)
    '('         shift, and goto state 272
    ')'         reduce using rule 224 (NotKeywordToken)
    '*'         reduce using rule 224 (NotKeywordToken)
    '+'         reduce using rule 224 (NotKeywordToken)
    ','         reduce using rule 224 (NotKeywordToken)
    '-'         reduce using rule 224 (NotKeywordToken)
    '.'         reduce using rule 224 (NotKeywordToken)
    '/'         reduce using rule 224 (NotKeywordToken)
    ';'         reduce using rule 224 (NotKeywordToken)
    '<'         reduce using rule 224 (NotKeywordToken)
    '>'         reduce using rule 224 (NotKeywordToken)
    '^'         reduce using rule 224 (NotKeywordToken)
    '|'         reduce using rule 224 (NotKeywordToken)
    '}'         reduce using rule 224 (NotKeywordToken)
    and         reduce using rule 224 (NotKeywordToken)
    andand      reduce using rule 224 (NotKeywordToken)
    as          reduce using rule 224 (NotKeywordToken)
    asc         reduce using rule 224 (NotKeywordToken)
    between     reduce using rule 224 (NotKeywordToken)
    cross       reduce using rule 224 (NotKeywordToken)
    desc        reduce using rule 224 (NotKeywordToken)
    div         reduce using rule 224 (NotKeywordToken)
    elseKwd     reduce using rule 224 (NotKeywordToken)
    end         reduce using rule 224 (NotKeywordToken)
    eq          reduce using rule 224 (NotKeywordToken)
    forKwd      reduce using rule 224 (NotKeywordToken)
    from        reduce using rule 224 (NotKeywordToken)
    full        reduce using rule 224 (NotKeywordToken)
    ge          reduce using rule 224 (NotKeywordToken)
    group       reduce using rule 224 (NotKeywordToken)
    having      reduce using rule 224 (NotKeywordToken)
    identifier  reduce using rule 224 (NotKeywordToken)
    in          reduce using rule 224 (NotKeywordToken)
    inner       reduce using rule 224 (NotKeywordToken)
    is          reduce using rule 224 (NotKeywordToken)
    join        reduce using rule 224 (NotKeywordToken)
    le          reduce using rule 224 (NotKeywordToken)
    left        reduce using rule 224 (NotKeywordToken)
    like        reduce using rule 224 (NotKeywordToken)
    limit       reduce using rule 224 (NotKeywordToken)
    lock        reduce using rule 224 (NotKeywordToken)
    lsh         reduce using rule 224 (NotKeywordToken)
    mod         reduce using rule 224 (NotKeywordToken)
    neq         reduce using rule 224 (NotKeywordToken)
    neqSynonym  reduce using rule 224 (NotKeywordToken)
    not         reduce using rule 224 (NotKeywordToken)
    on          reduce using rule 224 (NotKeywordToken)
    or          reduce using rule 224 (NotKeywordToken)
    order       reduce using rule 224 (NotKeywordToken)
    oror        reduce using rule 224 (NotKeywordToken)
    regexp      reduce using rule 224 (NotKeywordToken)
    right       reduce using rule 224 (NotKeywordToken)
    rlike       reduce using rule 224 (NotKeywordToken)
    rsh         reduce using rule 224 (NotKeywordToken)
    then        reduce using rule 224 (NotKeywordToken)
    union       reduce using rule 224 (NotKeywordToken)
    using       reduce using rule 224 (NotKeywordToken)
    when        reduce using rule 224 (NotKeywordToken)
    where       reduce using rule 224 (NotKeywordToken)
    xor         reduce using rule 224 (NotKeywordToken)
    conflict on '(', shift, and goto state 272, reduce using rule 224
```

``` bash
(10:24) jnml@r550:~/src/github.com/cznic/tidb/parser$ goyacc -o /dev/null -cr parser.y
Parse table entries: 123807 of 377235, x 16 bits == 247614 bytes
conflicts: 4 shift/reduce
(10:24) jnml@r550:~/src/github.com/cznic/tidb/parser$ 
```
  require golang version 1.5 or later
 make is ok with go1.4 or later, but make interpreter failed with go1.4.2 
  > When Do method is executing, the only way to pause it is to use another goroutine with a channel, as currently the driver does.

FTR: The `RowIterFunc` passed to `plan.Do` has two return values: `(more bool, err error)` and is called for every row the plan produces. When `RowIterFunc` returns `(false, nil)`, `plan.Do` returns immediately.
 The "extra" goroutine in `driver.go` is only a performance optimization. It is not necessary to do it that way. However, it enables to produce a result set in parallel/concurrently to consuming it.
 Of course. That's why the channel is buffered with a limited number of items. I think it's 1000 rows. IOW, _"fetching all rows before return to user"_ does not apply. At most 1000 additional rows _may_ get fetched in paralell to what the user/client already consumed. And the constant, 1000, can be tuned to a lower value probably without any serious performance degradartion.

Don't get me wrong, it's completely your decision how to design things. I'm just trying to keep you informed when I see a discussion based on assumptions which are not correct - to aid you, potentially, in making the above mentioned decision ;-)
 There's nothing you have to apologise for. And you're welcome ;-)
  ```
state 510 // deleteKwd from after join after

  365 JoinTable: TableRef . CrossOpt TableRef  // assoc %left, prec 4
  365 JoinTable: TableRef CrossOpt TableRef .  [$end, ')', ',', ';', '}', cross, forKwd, full, group, having, inner, join, left, limit, lock, on, order, right, union, where]  // assoc %left, prec 4
  366 JoinTable: TableRef . CrossOpt TableRef on Expression
  366 JoinTable: TableRef CrossOpt TableRef . on Expression
  367 JoinTable: TableRef . JoinType OuterOpt join TableRef on Expression

    $end    reduce using rule 365 (JoinTable)
    ')'     reduce using rule 365 (JoinTable)
    ','     reduce using rule 365 (JoinTable)
    ';'     reduce using rule 365 (JoinTable)
    '}'     reduce using rule 365 (JoinTable)
    cross   reduce using rule 365 (JoinTable)
    forKwd  reduce using rule 365 (JoinTable)
    full    reduce using rule 365 (JoinTable)
    group   reduce using rule 365 (JoinTable)
    having  reduce using rule 365 (JoinTable)
    inner   reduce using rule 365 (JoinTable)
    join    reduce using rule 365 (JoinTable)
    left    reduce using rule 365 (JoinTable)
    limit   reduce using rule 365 (JoinTable)
    lock    reduce using rule 365 (JoinTable)
    on      shift, and goto state 511
    order   reduce using rule 365 (JoinTable)
    right   reduce using rule 365 (JoinTable)
    union   reduce using rule 365 (JoinTable)
    where   reduce using rule 365 (JoinTable)

    CrossOpt  goto state 494
    JoinType  goto state 495

    conflict on on, shift, and goto state 511, reduce using rule 365
```

``` bash
jnml@4670:~/src/github.com/cznic/tidb/parser$ goyacc -cr -o /dev/null parser.y
Parse table entries: 124004 of 377154, x 16 bits == 248008 bytes
conflicts: 9 shift/reduce
jnml@4670:~/src/github.com/cznic/tidb/parser$ 
```
  ```
state 453 // selectKwd ['!']

  385 SelectStmtOpts: SelectStmtDistinct . SelectStmtCalcFoundRows
  386 SelectStmtCalcFoundRows: .  ['!', '(', '*', '+', '-', '~', after, autoIncrement, begin, bitType, boolType, booleanType, calcFoundRows, caseKwd, cast, charsetKwd, columns, commit, convert, database, dateType, datetimeType, deallocate, defaultKwd, do, end, engine, engines, execute, falseKwd, first, floatLit, full, global, identifier, ifKwd, imaginaryLit, intLit, left, local, mode, names, not, now, null, offset, password, placeholder, prepare, quick, rollback, row, schema, session, signed, start, stringLit, substring, sysVar, tables, textType, timeType, timestampType, transaction, trueKwd, truncate, unknown, userVar, value, values, warnings, yearType]

    '!'            reduce using rule 386 (SelectStmtCalcFoundRows)
    '('            reduce using rule 386 (SelectStmtCalcFoundRows)
    '*'            reduce using rule 386 (SelectStmtCalcFoundRows)
    '+'            reduce using rule 386 (SelectStmtCalcFoundRows)
    '-'            reduce using rule 386 (SelectStmtCalcFoundRows)
    '~'            reduce using rule 386 (SelectStmtCalcFoundRows)
    after          reduce using rule 386 (SelectStmtCalcFoundRows)
    autoIncrement  reduce using rule 386 (SelectStmtCalcFoundRows)
    begin          reduce using rule 386 (SelectStmtCalcFoundRows)
    bitType        reduce using rule 386 (SelectStmtCalcFoundRows)
    boolType       reduce using rule 386 (SelectStmtCalcFoundRows)
    booleanType    reduce using rule 386 (SelectStmtCalcFoundRows)
    calcFoundRows  shift, and goto state 455
    caseKwd        reduce using rule 386 (SelectStmtCalcFoundRows)
    cast           reduce using rule 386 (SelectStmtCalcFoundRows)
    charsetKwd     reduce using rule 386 (SelectStmtCalcFoundRows)
    columns        reduce using rule 386 (SelectStmtCalcFoundRows)
    commit         reduce using rule 386 (SelectStmtCalcFoundRows)
    convert        reduce using rule 386 (SelectStmtCalcFoundRows)
    database       reduce using rule 386 (SelectStmtCalcFoundRows)
    dateType       reduce using rule 386 (SelectStmtCalcFoundRows)
    datetimeType   reduce using rule 386 (SelectStmtCalcFoundRows)
    deallocate     reduce using rule 386 (SelectStmtCalcFoundRows)
    defaultKwd     reduce using rule 386 (SelectStmtCalcFoundRows)
    do             reduce using rule 386 (SelectStmtCalcFoundRows)
    end            reduce using rule 386 (SelectStmtCalcFoundRows)
    engine         reduce using rule 386 (SelectStmtCalcFoundRows)
    engines        reduce using rule 386 (SelectStmtCalcFoundRows)
    execute        reduce using rule 386 (SelectStmtCalcFoundRows)
    falseKwd       reduce using rule 386 (SelectStmtCalcFoundRows)
    first          reduce using rule 386 (SelectStmtCalcFoundRows)
    floatLit       reduce using rule 386 (SelectStmtCalcFoundRows)
    full           reduce using rule 386 (SelectStmtCalcFoundRows)
    global         reduce using rule 386 (SelectStmtCalcFoundRows)
    identifier     reduce using rule 386 (SelectStmtCalcFoundRows)
    ifKwd          reduce using rule 386 (SelectStmtCalcFoundRows)
    imaginaryLit   reduce using rule 386 (SelectStmtCalcFoundRows)
    intLit         reduce using rule 386 (SelectStmtCalcFoundRows)
    left           reduce using rule 386 (SelectStmtCalcFoundRows)
    local          reduce using rule 386 (SelectStmtCalcFoundRows)
    mode           reduce using rule 386 (SelectStmtCalcFoundRows)
    names          reduce using rule 386 (SelectStmtCalcFoundRows)
    not            reduce using rule 386 (SelectStmtCalcFoundRows)
    now            reduce using rule 386 (SelectStmtCalcFoundRows)
    null           reduce using rule 386 (SelectStmtCalcFoundRows)
    offset         reduce using rule 386 (SelectStmtCalcFoundRows)
    password       reduce using rule 386 (SelectStmtCalcFoundRows)
    placeholder    reduce using rule 386 (SelectStmtCalcFoundRows)
    prepare        reduce using rule 386 (SelectStmtCalcFoundRows)
    quick          reduce using rule 386 (SelectStmtCalcFoundRows)
    rollback       reduce using rule 386 (SelectStmtCalcFoundRows)
    row            reduce using rule 386 (SelectStmtCalcFoundRows)
    schema         reduce using rule 386 (SelectStmtCalcFoundRows)
    session        reduce using rule 386 (SelectStmtCalcFoundRows)
    signed         reduce using rule 386 (SelectStmtCalcFoundRows)
    start          reduce using rule 386 (SelectStmtCalcFoundRows)
    stringLit      reduce using rule 386 (SelectStmtCalcFoundRows)
    substring      reduce using rule 386 (SelectStmtCalcFoundRows)
    sysVar         reduce using rule 386 (SelectStmtCalcFoundRows)
    tables         reduce using rule 386 (SelectStmtCalcFoundRows)
    textType       reduce using rule 386 (SelectStmtCalcFoundRows)
    timeType       reduce using rule 386 (SelectStmtCalcFoundRows)
    timestampType  reduce using rule 386 (SelectStmtCalcFoundRows)
    transaction    reduce using rule 386 (SelectStmtCalcFoundRows)
    trueKwd        reduce using rule 386 (SelectStmtCalcFoundRows)
    truncate       reduce using rule 386 (SelectStmtCalcFoundRows)
    unknown        reduce using rule 386 (SelectStmtCalcFoundRows)
    userVar        reduce using rule 386 (SelectStmtCalcFoundRows)
    value          reduce using rule 386 (SelectStmtCalcFoundRows)
    values         reduce using rule 386 (SelectStmtCalcFoundRows)
    warnings       reduce using rule 386 (SelectStmtCalcFoundRows)
    yearType       reduce using rule 386 (SelectStmtCalcFoundRows)

    SelectStmtCalcFoundRows  goto state 454

    conflict on calcFoundRows, shift, and goto state 455, reduce using rule 386
```

``` bash
(14:46) jnml@r550:~/src/github.com/cznic/tidb/parser$ goyacc -o /dev/null -cr parser.y
Parse table entries: 124004 of 377154, x 16 bits == 248008 bytes
conflicts: 10 shift/reduce
(14:46) jnml@r550:~/src/github.com/cznic/tidb/parser$
```
  ```
state 759 // create tableKwd after '(' after bigIntType [$end]

   38 ColumnDef: ColumnName Type . ConstraintOpts
   74 ConstraintOpts: .  [$end, ')', ',', ';', after, autoIncrement, defaultKwd, first, not, null, on, primary, unique]

    $end           reduce using rule 74 (ConstraintOpts)
    ')'            reduce using rule 74 (ConstraintOpts)
    ','            reduce using rule 74 (ConstraintOpts)
    ';'            reduce using rule 74 (ConstraintOpts)
    after          reduce using rule 74 (ConstraintOpts)
    autoIncrement  shift, and goto state 841
    defaultKwd     shift, and goto state 844
    first          reduce using rule 74 (ConstraintOpts)
    not            shift, and goto state 839
    null           shift, and goto state 840
    on             shift, and goto state 845
    primary        shift, and goto state 842
    unique         shift, and goto state 843

    Constraint      goto state 846
    ConstraintOpt   goto state 847
    ConstraintOpts  goto state 838

    conflict on autoIncrement, shift, and goto state 841, reduce using rule 74
    conflict on defaultKwd, shift, and goto state 844, reduce using rule 74
    conflict on not, shift, and goto state 839, reduce using rule 74 // not: assoc %right, prec 16
    conflict on null, shift, and goto state 840, reduce using rule 74
    conflict on on, shift, and goto state 845, reduce using rule 74
    conflict on primary, shift, and goto state 842, reduce using rule 74
    conflict on unique, shift, and goto state 843, reduce using rule 74
```

``` bash
(14:09) jnml@r550:~/src/github.com/cznic/tidb/parser$ goyacc -o /dev/null -cr parser.y
Parse table entries: 124004 of 376243, x 16 bits == 248008 bytes
conflicts: 11 shift/reduce
(14:09) jnml@r550:~/src/github.com/cznic/tidb/parser$
```
  ```
state 837 // create tableKwd after '(' after bigIntType [$end]

  496 NumericType: IntegerType OptFieldLen . FieldOpts
  542 FieldOpts: .  [$end, ')', ',', ';', after, autoIncrement, defaultKwd, first, not, null, on, primary, unique, unsigned, zerofill]

    $end           reduce using rule 542 (FieldOpts)
    ')'            reduce using rule 542 (FieldOpts)
    ','            reduce using rule 542 (FieldOpts)
    ';'            reduce using rule 542 (FieldOpts)
    after          reduce using rule 542 (FieldOpts)
    autoIncrement  reduce using rule 542 (FieldOpts)
    defaultKwd     reduce using rule 542 (FieldOpts)
    first          reduce using rule 542 (FieldOpts)
    not            reduce using rule 542 (FieldOpts)
    null           reduce using rule 542 (FieldOpts)
    on             reduce using rule 542 (FieldOpts)
    primary        reduce using rule 542 (FieldOpts)
    unique         reduce using rule 542 (FieldOpts)
    unsigned       shift, and goto state 831
    zerofill       shift, and goto state 832

    FieldOpt   goto state 833
    FieldOpts  goto state 838

    conflict on unsigned, shift, and goto state 831, reduce using rule 542
    conflict on zerofill, shift, and goto state 832, reduce using rule 542
```

``` bash
(13:14) jnml@r550:~/src/github.com/cznic/tidb/parser$ goyacc -o /dev/null -cr parser.y
Parse table entries: 124041 of 376656, x 16 bits == 248082 bytes
conflicts: 18 shift/reduce
(13:14) jnml@r550:~/src/github.com/cznic/tidb/parser$ 
```
  +10086
  C:\Users\insio>go get  github.com/pingcap/tidb
# github.com/pingcap/tidb/parser

E:\gopath\src\github.com\pingcap\tidb\parser\yy_parser.go:17: undefined: yyLexer
E:\gopath\src\github.com\pingcap\tidb\parser\yy_parser.go:18: undefined: yyParse
 Because the windows do not "make" command, I compiled by writing shell.

make.sh/make.bat:

```

go get github.com/qiuyesuifeng/goyacc
go get github.com/qiuyesuifeng/golex
touch temp.XXXXXX
goyacc -o /dev/null -xegen "temp.XXXXXX" parser/parser.y
goyacc -o parser/parser.go -xe "temp.XXXXXX" parser/parser.y
rm -f "temp.XXXXXX"
rm -f y.output

```
 @insionng you can make a PR for `make.bat` :clap:
 @Unknwon Okay~
 cc @ngaut 
 @ngaut https://github.com/pingcap/tidb/pull/130/files
  ```
state 861 // alter tableKwd autoIncrement drop

    7 AlterSpecification: drop . ColumnKeywordOpt ColumnName
    8 AlterSpecification: drop . primary key
    9 AlterSpecification: drop . KeyOrIndex IndexName
   10 AlterSpecification: drop . foreign key Symbol
   13 ColumnKeywordOpt: .  [autoIncrement, begin, bitType, boolType, booleanType, charsetKwd, column, columns, dateType, datetimeType, engine, full, global, identifier, local, mode, names, now, offset, password, quick, rollback, session, substring, tables, textType, timeType, timestampType, transaction, truncate, value, warnings, yearType]

    autoIncrement  reduce using rule 13 (ColumnKeywordOpt)
    begin          reduce using rule 13 (ColumnKeywordOpt)
    bitType        reduce using rule 13 (ColumnKeywordOpt)
    boolType       reduce using rule 13 (ColumnKeywordOpt)
    booleanType    reduce using rule 13 (ColumnKeywordOpt)
    charsetKwd     reduce using rule 13 (ColumnKeywordOpt)
    column         shift, and goto state 869
    columns        reduce using rule 13 (ColumnKeywordOpt)
    dateType       reduce using rule 13 (ColumnKeywordOpt)
    datetimeType   reduce using rule 13 (ColumnKeywordOpt)
    engine         reduce using rule 13 (ColumnKeywordOpt)
    foreign        shift, and goto state 866
    full           reduce using rule 13 (ColumnKeywordOpt)
    global         reduce using rule 13 (ColumnKeywordOpt)
    identifier     reduce using rule 13 (ColumnKeywordOpt)
    index          shift, and goto state 868
    key            shift, and goto state 867
    local          reduce using rule 13 (ColumnKeywordOpt)
    mode           reduce using rule 13 (ColumnKeywordOpt)
    names          reduce using rule 13 (ColumnKeywordOpt)
    now            reduce using rule 13 (ColumnKeywordOpt)
    offset         reduce using rule 13 (ColumnKeywordOpt)
    password       reduce using rule 13 (ColumnKeywordOpt)
    primary        shift, and goto state 864
    quick          reduce using rule 13 (ColumnKeywordOpt)
    rollback       reduce using rule 13 (ColumnKeywordOpt)
    session        reduce using rule 13 (ColumnKeywordOpt)
    substring      reduce using rule 13 (ColumnKeywordOpt)
    tables         reduce using rule 13 (ColumnKeywordOpt)
    textType       reduce using rule 13 (ColumnKeywordOpt)
    timeType       reduce using rule 13 (ColumnKeywordOpt)
    timestampType  reduce using rule 13 (ColumnKeywordOpt)
    transaction    reduce using rule 13 (ColumnKeywordOpt)
    truncate       reduce using rule 13 (ColumnKeywordOpt)
    value          reduce using rule 13 (ColumnKeywordOpt)
    warnings       reduce using rule 13 (ColumnKeywordOpt)
    yearType       reduce using rule 13 (ColumnKeywordOpt)

    ColumnKeywordOpt  goto state 863
    KeyOrIndex        goto state 865

    conflict on column, shift, and goto state 869, reduce using rule 13
```
 @coocood My bad, I mistakenly supposed `COLUMN` is an unreserved keyword. Thanks for making it clear to me. I will fix the PR later this evening (CET). 

Thanks again.
 @shenli Yep, this S/R conflict exists no more at master. Closing.
  @coocood Just mechanically resolved, you have to double check the diff before adopting as I don't understand well the existence of `UnReservedKeyword`.

``` diff
diff --git a/parser/parser.y b/parser/parser.y
index d1d0cad..c71f8fd 100644
--- a/parser/parser.y
+++ b/parser/parser.y
@@ -323,7 +323,6 @@ import (
    Field           "field expression"
    Field1          "field expression optional AS clause"
    FieldList       "field expression list"
-   ForUserOpt      "Set password for user option"
    FromClause      "From clause"
    Function        "function expr"
    FunctionCall        "function call post part"
@@ -471,6 +470,7 @@ import (
 %left  xor
 %left  andand and
 %left  between
+%precedence lower_than_eq
 %left  eq ge le neq neqSynonym '>' '<' is like in
 %left  '|'
 %left  '&'
@@ -1531,7 +1531,7 @@ Identifier:
 // TODO: Add Data Type UnReserved Keywords
 UnReservedKeyword:
    "AUTO_INCREMENT" | "BEGIN" | "BIT" | "BOOL" | "BOOLEAN" | "CHARSET" | "COLUMN" | "COLUMNS" | "DATE" | "DATETIME"
-|  "ENGINE" | "FULL" | "LOCAL" | "NAMES" | "OFFSET" | "PASSWORD" | "QUICK" | "ROLLBACK" | "SESSION" | "GLOBAL" 
+|  "ENGINE" | "FULL" | "LOCAL" | "NAMES" | "OFFSET" | "PASSWORD" %prec lower_than_eq | "QUICK" | "ROLLBACK" | "SESSION" | "GLOBAL" 
 |  "TABLES"| "TEXT" | "TIME" | "TIMESTAMP" | "TRANSACTION" | "TRUNCATE" | "VALUE" | "WARNINGS" | "YEAR" | "NOW"
 |  "SUBSTRING" | "MODE"

@@ -2487,9 +2487,13 @@ SetStmt:
    {
        $$ = &stmts.SetCharsetStmt{Charset: $3.(string)} 
    }
-|  "SET" "PASSWORD" ForUserOpt eq PasswordOpt
+|  "SET" "PASSWORD" eq PasswordOpt
    {
-       $$ = &stmts.SetPwdStmt{User: $3.(string), Password: $5.(string)} 
+       $$ = &stmts.SetPwdStmt{Password: $4.(string)} 
+   }
+|  "SET" "PASSWORD" "FOR" Username eq PasswordOpt
+   {
+       $$ = &stmts.SetPwdStmt{User: $4.(string), Password: $6.(string)} 
    }

 VariableAssignment:
@@ -2574,16 +2578,6 @@ UserVariable:
        $$ = &expressions.Variable{Name: v, IsGlobal: false, IsSystem: false}
    }

-
-ForUserOpt:
-   {
-       $$ = "" 
-   }
-|  "FOR" Username
-   {
-       $$ = $2.(string)
-   }
-
 Username:
    Identifier
    {
```

``` bash
(10:35) jnml@r550:~/src/github.com/pingcap/tidb/parser$ goyacc -o /dev/null -cr parser.y
Parse table entries: 114264 of 366201, x 16 bits == 228528 bytes
conflicts: 25 shift/reduce
(10:35) jnml@r550:~/src/github.com/pingcap/tidb/parser$ 
```

BTW: I thinkg the S/R conflicts should go away as well.
 @coocood I'm not sure I can manage to create enough free time to look into it. This is my first week at work after vacations and a lot of issues accumulated meanwhile.

Maybe there's some chance through this weekend, but I cannot really promise anything, so please don't be disappointed when that opportunity fails (family, etc.).
 @coocood I'll try to get rid of the S/R conflicts one parser state at time. Your task will be to review and carefully test those changes, ok?

I have to say that I have never before worked with a language which mixes identifiers and keywords and that whoever of the MySQL authors came with that idea introduced a lot of trouble for the grammar writers. I'm not sure if I can resolve all the conflicts :-1: 
  SGTM
  It seems that [parser.y](https://github.com/pingcap/tidb/blob/8920a55dab883c1ca064b978fe88aea28ef6c29b/parser/parser.y) has several shift/reduce and reduce/reduce conflicts.

S/R conflicts are _sometimes_ expected and/or acceptable, but I don't think this applies in this case. R/R conflicts, on the other hand, are almost never okay.

The current state of the grammar with all of the conflicts means that there are valid sentences, part of the intended-to-parse language, which will parse incorrectly or not at all because the grammar is ambiguous and does not reflect the proper language.

I suggest to get rid of _all_ conflicts in `parser.y` and, above that, perhaps use the `-cr` goyacc flag to verify reducibility of all grammar productions.
  Hi,
when running the tests I get a failure:

```
FAIL: time_test.go:292: testTimeSuite.TestCodec

time_test.go:305:
    c.Assert(t.String(), Not(Equals), t1.String())
... obtained string = "2010-10-10 10:11:11"
... expected string = "2010-10-10 10:11:11
```

I think the problem is that the tested timezone is equal to my local timezone while it is assumed to be different.
 `Europe/Rome` which is equivalent to the tested `Europe/Berlin`.
 Yep, it works now.
Thanks for the fast fix!
  Thanks!
  When I try to delete, it panic.

```
[xorm] [info]  2015/09/08 09:35:50.145837 [sql] DELETE FROM `userinfo` WHERE `id` = ? [args] [3]
2015/09/08 09:35:50 tidb.go:97: [debug] compiling prepared DELETE FROM `userinfo` WHERE `id` = ?
2015/09/08 09:35:50 txn.go:108: [debug] get key:142_r   �sdd, txn:94
2015/09/08 09:35:50 tidb.go:97: [debug] compiling prepared DELETE FROM `userinfo` WHERE `id` = ?
panic: runtime error: invalid memory address or nil pointer dereference
[signal 0xb code=0x1 addr=0x20 pc=0x411745]

goroutine 201 [running]:
github.com/pingcap/tidb/store/localstore.(*dbSnapshot).Get(0xc820c49ff0, 0xc820e67300, 0x11, 0x20, 0x0, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/store/localstore/snapshot.go:34 +0x85
github.com/pingcap/tidb/kv.(*UnionStore).Get(0xc820c5c120, 0xc820e67300, 0x11, 0x20, 0x0, 0x0, 0x0, 0x1b00000, 0xc820061210)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/kv/union_store.go:91 +0x11c
github.com/pingcap/tidb/store/localstore.(*dbTxn).Get(0xc820c5c120, 0xc820e67300, 0x11, 0x20, 0x0, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/store/localstore/txn.go:110 +0x34a
github.com/pingcap/tidb/table/tables.(*Table).RowWithCols(0xc82045d5f0, 0x1b82050, 0xc820018180, 0x9, 0xc8204208c0, 0x8, 0x8, 0x0, 0x0, 0x0, ...)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/table/tables/tables.go:412 +0x23d
github.com/pingcap/tidb/table/tables.(*Table).Row(0xc82045d5f0, 0x1b82050, 0xc820018180, 0x9, 0x0, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/table/tables/tables.go:430 +0xce
github.com/pingcap/tidb/plan/plans.(*TableDefaultPlan).Do(0xc820c46e70, 0x1b82050, 0xc820018180, 0xc820222640, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/from.go:283 +0x3d1
github.com/pingcap/tidb/plan/plans.(*JoinPlan).Do(0xc820019f80, 0x1b82050, 0xc820018180, 0xc820222640, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/join.go:140 +0x6e
github.com/pingcap/tidb/plan/plans.(*FilterDefaultPlan).Do(0xc820c4e840, 0x1b82050, 0xc820018180, 0xc820c46fc0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/where.go:72 +0x1ad
github.com/pingcap/tidb/plan/plans.(*SelectLockPlan).Do(0xc820c4e880, 0x1b82050, 0xc820018180, 0xc820c46f90, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/lock.go:63 +0xd7
github.com/pingcap/tidb/plan/plans.(*LimitDefaultPlan).Do(0xc820c46f60, 0x1b82050, 0xc820018180, 0xc820c4e980, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/limit.go:69 +0x103
github.com/pingcap/tidb/plan/plans.(*SelectFinalPlan).Do(0xc820c4e8e0, 0x1b82050, 0xc820018180, 0xc820c49fb0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/final.go:59 +0xc4
github.com/pingcap/tidb/rset/rsets.Recordset.Do(0x1b82050, 0xc820018180, 0x1b82e58, 0xc820c4e8e0, 0xc820c49fa0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/rset/rsets/rsets.go:42 +0x97
github.com/pingcap/tidb/rset/rsets.(*Recordset).Do(0xc820c4e900, 0xc820c49fa0, 0x0, 0x0)
    <autogenerated>:6 +0xac
github.com/pingcap/tidb.newdriverRows.func1(0xc820c4e920)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/driver.go:355 +0xa9
created by github.com/pingcap/tidb.newdriverRows
    /Users/lunny/gopath/src/github.com/pingcap/tidb/driver.go:374 +0xeb

goroutine 1 [chan receive]:
testing.RunTests(0xa13c40, 0xd70b20, 0x2, 0x2, 0x1)
    /Users/lunny/go1.5/src/testing/testing.go:562 +0x8ad
testing.(*M).Run(0xc820039f08, 0xc8201d1e60)
    /Users/lunny/go1.5/src/testing/testing.go:494 +0x70
main.main()
    github.com/go-xorm/tidb/_test/_testmain.go:72 +0x116

goroutine 17 [syscall, locked to thread]:
runtime.goexit()
    /Users/lunny/go1.5/src/runtime/asm_amd64.s:1696 +0x1

goroutine 20 [IO wait]:
net.runtime_pollWait(0x1b81050, 0x72, 0xc820060080)
    /Users/lunny/go1.5/src/runtime/netpoll.go:157 +0x60
net.(*pollDesc).Wait(0xc820698060, 0x72, 0x0, 0x0)
    /Users/lunny/go1.5/src/net/fd_poll_runtime.go:73 +0x3a
net.(*pollDesc).WaitRead(0xc820698060, 0x0, 0x0)
    /Users/lunny/go1.5/src/net/fd_poll_runtime.go:78 +0x36
net.(*netFD).accept(0xc820698000, 0x0, 0x1b81148, 0xc8206920a0)
    /Users/lunny/go1.5/src/net/fd_unix.go:408 +0x27c
net.(*TCPListener).AcceptTCP(0xc820230008, 0xc820057dd0, 0x0, 0x0)
    /Users/lunny/go1.5/src/net/tcpsock_posix.go:254 +0x4d
net/http.tcpKeepAliveListener.Accept(0xc820230008, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/go1.5/src/net/http/server.go:2135 +0x41
net/http.(*Server).Serve(0xc820214000, 0x1b81110, 0xc820230008, 0x0, 0x0)
    /Users/lunny/go1.5/src/net/http/server.go:1887 +0xb3
net/http.(*Server).ListenAndServe(0xc820214000, 0x0, 0x0)
    /Users/lunny/go1.5/src/net/http/server.go:1877 +0x136
net/http.ListenAndServe(0x8c06d0, 0xe, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/go1.5/src/net/http/server.go:1967 +0x8f
created by github.com/pingcap/tidb.init.2
    /Users/lunny/gopath/src/github.com/pingcap/tidb/tidb.go:262 +0x1a6
```
 @shenli, please `go get -u github.com/go-xorm/tidb`. I have resolved some problems. This is the lastest one.

And then `go test`, the detail log is below.

```
-------------- testDelete --------------
[xorm] [info]  2015/09/08 12:34:34.891102 [sql] DELETE FROM `userinfo` WHERE `id` = ? [args] [1]
2015/09/08 12:34:34 tidb.go:97: [debug] compiling prepared DELETE FROM `userinfo` WHERE `id` = ?
2015/09/08 12:34:34 delete.go:157: [info] try delete with index %!v(PANIC=runtime error: invalid memory address or nil pointer dereference)
2015/09/08 12:34:34 kv.go:115: [debug] Begin txn:93
2015/09/08 12:34:34 session.go:201: [warning] New txn:93 in session:1
2015/09/08 12:34:34 txn.go:138: [debug] seek 202_rsd txn:93
2015/09/08 12:34:34 tables.go:538: [debug] startKey 202_rsd, key:202_rsd,value:63
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:160: [debug] delete 202_i_primaryd txn:93
2015/09/08 12:34:34 txn.go:160: [debug] delete 202_i_uqe_userinfo_usernamexiaolunwens txn:93
2015/09/08 12:34:34 txn.go:160: [debug] delete 202_r�sdd txn:93
2015/09/08 12:34:34 txn.go:160: [debug] delete 202_r�sdd txn:93
2015/09/08 12:34:34 txn.go:160: [debug] delete 202_r�sdd txn:93
2015/09/08 12:34:34 txn.go:160: [debug] delete 202_r�sdd txn:93
2015/09/08 12:34:34 txn.go:160: [debug] delete 202_r�sdd txn:93
2015/09/08 12:34:34 txn.go:160: [debug] delete 202_r�sdd txn:93
2015/09/08 12:34:34 txn.go:160: [debug] delete 202_r�sdd txn:93
2015/09/08 12:34:34 txn.go:160: [debug] delete 202_r�sdd txn:93
2015/09/08 12:34:34 txn.go:160: [debug] delete 202_rsd txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r   �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r   �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r   �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r   �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r   �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r   �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r   �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r   �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
�sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r
                                                     �sdd, txn:93
2015/09/08 12:34:34 txn.go:213: [info] commit txn 93
[xorm] [debug] 2015/09/08 12:34:34.894226 [time] DELETE FROM `userinfo` WHERE `id` = ? - args [1] - execution took: 3100580ns
[xorm] [info]  2015/09/08 12:34:34.894378 [sql] SELECT `id`, `username`, `departname`, `created`, `detail_id`, `height`, `avatar`, `is_man` FROM `userinfo` WHERE `id` = ? LIMIT 1 [args] [3]
2015/09/08 12:34:34 tidb.go:97: [debug] compiling prepared SELECT `id`, `username`, `departname`, `created`, `detail_id`, `height`, `avatar`, `is_man` FROM `userinfo` WHERE `id` = ? LIMIT 1
2015/09/08 12:34:34 select.go:205: [info] SelectStmt trx:
2015/09/08 12:34:34 kv.go:115: [debug] Begin txn:94
2015/09/08 12:34:34 session.go:201: [warning] New txn:94 in session:1
2015/09/08 12:34:34 txn.go:138: [debug] seek 202_rsd txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
[xorm] [debug] 2015/09/08 12:34:34.895451 time(4) key[Created]: 2015-09-08 12:34:34 +0800 CST | sdata: [2015-09-08 12:34:34]
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
[xorm] [info]  2015/09/08 12:34:34.895923 [sql] SELECT `id`, `intro`, `profile` FROM `userdetail` WHERE `id` = ? LIMIT 1 [args] [1]
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 kv.go:71: [info] cache store ./tidb
2015/09/08 12:34:34 tidb.go:84: [debug] compiling use tidb
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 tidb.go:97: [debug] compiling prepared SELECT `id`, `intro`, `profile` FROM `userdetail` WHERE `id` = ? LIMIT 1
2015/09/08 12:34:34 select.go:205: [info] SelectStmt trx:
2015/09/08 12:34:34 kv.go:115: [debug] Begin txn:95
2015/09/08 12:34:34 session.go:201: [warning] New txn:95 in session:2
2015/09/08 12:34:34 txn.go:138: [debug] seek 206_rsd txn:95
2015/09/08 12:34:34 txn.go:108: [debug] get key:206_r�sdd, txn:95
2015/09/08 12:34:34 txn.go:108: [debug] get key:206_r�sdd, txn:95
2015/09/08 12:34:34 txn.go:108: [debug] get key:206_r�sdd, txn:95
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
[xorm] [info]  2015/09/08 12:34:34.896848 [sql] SELECT `id`, `intro`, `profile` FROM `userdetail` WHERE `id` = ? LIMIT 1 [args] [1]
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 tidb.go:97: [debug] compiling prepared SELECT `id`, `intro`, `profile` FROM `userdetail` WHERE `id` = ? LIMIT 1
2015/09/08 12:34:34 select.go:205: [info] SelectStmt trx:
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:213: [info] commit txn 95
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:94
2015/09/08 12:34:34 kv.go:115: [debug] Begin txn:96
2015/09/08 12:34:34 session.go:201: [warning] New txn:96 in session:2
2015/09/08 12:34:34 txn.go:138: [debug] seek 206_rsd txn:96
2015/09/08 12:34:34 txn.go:108: [debug] get key:206_r�sdd, txn:96
2015/09/08 12:34:34 txn.go:108: [debug] get key:206_r�sdd, txn:96
2015/09/08 12:34:34 txn.go:108: [debug] get key:206_r�sdd, txn:96
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:94
2015/09/08 12:34:34 txn.go:213: [info] commit txn 96
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:94
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_�sdd, txn:94
2015/09/08 12:34:34 txn.go:213: [info] commit txn 94
[xorm] [info]  2015/09/08 12:34:34.897616 [sql] DELETE FROM `userinfo` WHERE `id` = ? [args] [3]
2015/09/08 12:34:34 tidb.go:97: [debug] compiling prepared DELETE FROM `userinfo` WHERE `id` = ?
2015/09/08 12:34:34 tidb.go:97: [debug] compiling prepared DELETE FROM `userinfo` WHERE `id` = ?
2015/09/08 12:34:34 delete.go:157: [info] try delete with index %!v(PANIC=runtime error: invalid memory address or nil pointer dereference)
2015/09/08 12:34:34 kv.go:115: [debug] Begin txn:97
2015/09/08 12:34:34 session.go:201: [warning] New txn:97 in session:1
2015/09/08 12:34:34 txn.go:138: [debug] seek 202_rsd txn:97
2015/09/08 12:34:34 tables.go:538: [debug] startKey 202_rsd, key:202_rsd,value:87
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:97
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:97
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:97
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:97
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:97
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:97
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:97
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r�sdd, txn:97
2015/09/08 12:34:34 txn.go:108: [debug] get key:202_r   �sdd, txn:94
2015/09/08 12:34:34 txn.go:160: [debug] delete 202_i_primaryd txn:97
2015/09/08 12:34:34 txn.go:160: [debug] delete 202_i_uqe_userinfo_usernamexiaolunwen2s txn:97
panic: runtime error: invalid memory address or nil pointer dereference
[signal 0xb code=0x1 addr=0x20 pc=0x411745]

goroutine 236 [running]:
github.com/pingcap/tidb/store/localstore.(*dbSnapshot).Get(0xc820b21c80, 0xc8205e0580, 0x11, 0x20, 0x0, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/store/localstore/snapshot.go:34 +0x85
github.com/pingcap/tidb/kv.(*UnionStore).Get(0xc8205c8060, 0xc8205e0580, 0x11, 0x20, 0x0, 0x0, 0x0, 0x19b0028, 0xc82000b320)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/kv/union_store.go:91 +0x11c
github.com/pingcap/tidb/store/localstore.(*dbTxn).Get(0xc8205c8060, 0xc8205e0580, 0x11, 0x20, 0x0, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/store/localstore/txn.go:110 +0x34a
github.com/pingcap/tidb/table/tables.(*Table).RowWithCols(0xc820188fc0, 0x1c80bf0, 0xc82017ac00, 0x9, 0xc8206d2280, 0x8, 0x8, 0x0, 0x0, 0x0, ...)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/table/tables/tables.go:412 +0x23d
github.com/pingcap/tidb/table/tables.(*Table).Row(0xc820188fc0, 0x1c80bf0, 0xc82017ac00, 0x9, 0x0, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/table/tables/tables.go:430 +0xce
github.com/pingcap/tidb/plan/plans.(*TableDefaultPlan).Do(0xc820b245a0, 0x1c80bf0, 0xc82017ac00, 0xc820c50280, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/from.go:283 +0x3d1
github.com/pingcap/tidb/plan/plans.(*JoinPlan).Do(0xc8201e9ec0, 0x1c80bf0, 0xc82017ac00, 0xc820c50280, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/join.go:140 +0x6e
github.com/pingcap/tidb/plan/plans.(*FilterDefaultPlan).Do(0xc820b23020, 0x1c80bf0, 0xc82017ac00, 0xc820b246f0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/where.go:72 +0x1ad
github.com/pingcap/tidb/plan/plans.(*SelectLockPlan).Do(0xc820b23060, 0x1c80bf0, 0xc82017ac00, 0xc820b246c0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/lock.go:63 +0xd7
github.com/pingcap/tidb/plan/plans.(*LimitDefaultPlan).Do(0xc820b24690, 0x1c80bf0, 0xc82017ac00, 0xc820b23160, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/limit.go:69 +0x103
github.com/pingcap/tidb/plan/plans.(*SelectFinalPlan).Do(0xc820b230c0, 0x1c80bf0, 0xc82017ac00, 0xc820b21c40, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/final.go:59 +0xc4
github.com/pingcap/tidb/rset/rsets.Recordset.Do(0x1c80bf0, 0xc82017ac00, 0x1c818b8, 0xc820b230c0, 0xc820b21c30, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/rset/rsets/rsets.go:42 +0x97
github.com/pingcap/tidb/rset/rsets.(*Recordset).Do(0xc820b230e0, 0xc820b21c30, 0x0, 0x0)
    <autogenerated>:6 +0xac
github.com/pingcap/tidb.newdriverRows.func1(0xc820b23100)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/driver.go:355 +0xa9
created by github.com/pingcap/tidb.newdriverRows
    /Users/lunny/gopath/src/github.com/pingcap/tidb/driver.go:374 +0xeb

goroutine 1 [chan receive]:
testing.RunTests(0xa13c40, 0xd70b20, 0x2, 0x2, 0x1)
    /Users/lunny/go1.5/src/testing/testing.go:562 +0x8ad
testing.(*M).Run(0xc82069ff08, 0xc820234120)
    /Users/lunny/go1.5/src/testing/testing.go:494 +0x70
main.main()
    github.com/go-xorm/tidb/_test/_testmain.go:72 +0x116

goroutine 17 [syscall, locked to thread]:
runtime.goexit()
    /Users/lunny/go1.5/src/runtime/asm_amd64.s:1696 +0x1

goroutine 50 [select]:
github.com/syndtr/goleveldb/leveldb.(*DB).compactionError(0xc82026a000)
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/db_compaction.go:69 +0x54a
created by github.com/syndtr/goleveldb/leveldb.openDB
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/db.go:139 +0x77f

goroutine 18 [IO wait]:
net.runtime_pollWait(0x19b5d80, 0x72, 0xc82000a190)
    /Users/lunny/go1.5/src/runtime/netpoll.go:157 +0x60
net.(*pollDesc).Wait(0xc82005e450, 0x72, 0x0, 0x0)
    /Users/lunny/go1.5/src/net/fd_poll_runtime.go:73 +0x3a
net.(*pollDesc).WaitRead(0xc82005e450, 0x0, 0x0)
    /Users/lunny/go1.5/src/net/fd_poll_runtime.go:78 +0x36
net.(*netFD).accept(0xc82005e3f0, 0x0, 0x19b5e78, 0xc820011320)
    /Users/lunny/go1.5/src/net/fd_unix.go:408 +0x27c
net.(*TCPListener).AcceptTCP(0xc82002a088, 0xc82005ddd0, 0x0, 0x0)
    /Users/lunny/go1.5/src/net/tcpsock_posix.go:254 +0x4d
net/http.tcpKeepAliveListener.Accept(0xc82002a088, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/go1.5/src/net/http/server.go:2135 +0x41
net/http.(*Server).Serve(0xc820018300, 0x19b5e40, 0xc82002a088, 0x0, 0x0)
    /Users/lunny/go1.5/src/net/http/server.go:1887 +0xb3
net/http.(*Server).ListenAndServe(0xc820018300, 0x0, 0x0)
    /Users/lunny/go1.5/src/net/http/server.go:1877 +0x136
net/http.ListenAndServe(0x8c06d0, 0xe, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/go1.5/src/net/http/server.go:1967 +0x8f
created by github.com/pingcap/tidb.init.2
    /Users/lunny/gopath/src/github.com/pingcap/tidb/tidb.go:262 +0x1a6

goroutine 19 [runnable]:
github.com/syndtr/goleveldb/leveldb/comparer.(*bytesComparer).Compare(0xdbc1b0, 0xc820714dd9, 0x11, 0x3d1227, 0xc820f90400, 0xe, 0x16, 0xffffffffffffffff)
    <autogenerated>:1
github.com/syndtr/goleveldb/leveldb.(*iComparer).Compare(0xc8202331a0, 0xc820714dd9, 0x19, 0x3d1227, 0xc820f90400, 0x16, 0x16, 0xffffffffffffffff)
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/comparer.go:36 +0x117
github.com/syndtr/goleveldb/leveldb/memdb.(*DB).findGE(0xc8202461c0, 0xc820f90400, 0x16, 0x16, 0x52100, 0xc820f84348, 0xc820f84350)
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/memdb/memdb.go:218 +0x174
github.com/syndtr/goleveldb/leveldb/memdb.(*DB).Find(0xc8202461c0, 0xc820f90400, 0x16, 0x16, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...)
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/memdb/memdb.go:375 +0xaf
github.com/syndtr/goleveldb/leveldb.(*DB).get(0xc82026a000, 0xc820f922c0, 0xe, 0x10, 0x699, 0x0, 0x0, 0x0, 0x0, 0x0, ...)
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/db.go:740 +0x2c3
github.com/syndtr/goleveldb/leveldb.(*Snapshot).Get(0xc8205f28d0, 0xc820f922c0, 0xe, 0x10, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/db_snapshot.go:113 +0x1a6
github.com/pingcap/tidb/store/localstore/goleveldb.(*snapshot).Get(0xc8204b4ce0, 0xc820f922c0, 0xe, 0x10, 0x0, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/store/localstore/goleveldb/goleveldb.go:87 +0x87
github.com/pingcap/tidb/store/localstore.(*dbSnapshot).Get(0xc8205e3a10, 0xc820f922c0, 0xe, 0x10, 0x0, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/store/localstore/snapshot.go:34 +0x8b
github.com/pingcap/tidb/store/localstore.(*dbTxn).markOrigin(0xc820b7f380, 0xc820f922c0, 0xe, 0x10, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/store/localstore/txn.go:56 +0x12d
github.com/pingcap/tidb/store/localstore.(*dbTxn).LockKeys(0xc820b7f380, 0xc820f903e0, 0x1, 0x1, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/store/localstore/txn.go:239 +0x203
github.com/pingcap/tidb/table/tables.(*Table).LockRow(0xc820188fc0, 0x1c80bf0, 0xc82017ac00, 0x3, 0x63db00, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/table/tables/tables.go:445 +0x198
github.com/pingcap/tidb/table/tables.(*Table).RemoveRow(0xc820188fc0, 0x1c80bf0, 0xc82017ac00, 0x3, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/table/tables/tables.go:459 +0x6e
github.com/pingcap/tidb/stmt/stmts.(*DeleteStmt).removeRow(0xc8205e6280, 0x1c80bf0, 0xc82017ac00, 0x1c80ad8, 0xc820188fc0, 0x3, 0xc8205f4380, 0x8, 0x8, 0x0, ...)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/stmt/stmts/delete.go:149 +0x101
github.com/pingcap/tidb/stmt/stmts.(*DeleteStmt).Exec.func1(0x3, 0xc8205f4380, 0x8, 0x8, 0xc8206d2280, 0x8, 0x8, 0xc8205f4380, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/stmt/stmts/delete.go:232 +0x232
github.com/pingcap/tidb/table/tables.(*Table).IterRecords(0xc820188fc0, 0x1c80bf0, 0xc82017ac00, 0xc8205e39e0, 0xc, 0xc8206d2280, 0x8, 0x8, 0xc820013ae0, 0x0, ...)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/table/tables/tables.go:555 +0x693
github.com/pingcap/tidb/stmt/stmts.(*DeleteStmt).Exec(0xc8205e6280, 0x1c80bf0, 0xc82017ac00, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/stmt/stmts/delete.go:238 +0x5c1
github.com/pingcap/tidb/stmt/stmts.(*ExecuteStmt).Exec(0xc820c37640, 0x1c80bf0, 0xc82017ac00, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/stmt/stmts/prepared.go:235 +0x75d
github.com/pingcap/tidb.runExecute(0x1c80bf0, 0xc82017ac00, 0xc820c37640, 0xc8205e3850, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/tidb.go:176 +0x248
github.com/pingcap/tidb.runStmt(0x1c80bf0, 0xc82017ac00, 0x1c81988, 0xc820c37640, 0xc8205e3850, 0x1, 0x1, 0x0, 0x0, 0x0, ...)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/tidb.go:144 +0x224
github.com/pingcap/tidb.executePreparedStmt(0x1c80bf0, 0xc82017ac00, 0x24, 0xc8205e3850, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/tidb.go:124 +0xec
github.com/pingcap/tidb.(*session).ExecutePreparedStmt(0xc82017ac00, 0x24, 0xc8205e3850, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/session.go:179 +0x115
github.com/pingcap/tidb.(*driverStmt).Exec(0xc8205f2810, 0xc8205e3830, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/driver.go:490 +0xf0
database/sql.resultFromStatement(0x1c81360, 0xc82017b500, 0x1c818f8, 0xc8205f2810, 0xc8205e34e0, 0x1, 0x1, 0x0, 0x0, 0x0, ...)
    /Users/lunny/go1.5/src/database/sql/sql.go:1383 +0x3bd
database/sql.(*Stmt).Exec(0xc8205f4100, 0xc8205e34e0, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/go1.5/src/database/sql/sql.go:1356 +0x2ae
github.com/go-xorm/xorm.(*Session).innerExec(0xc820d7d400, 0xc8205f2630, 0x25, 0xc8205e34e0, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/go-xorm/xorm/session.go:468 +0xd0
github.com/go-xorm/xorm.(*Session).exec.func1(0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/go-xorm/xorm/session.go:491 +0x219
github.com/go-xorm/xorm.(*Engine).LogSQLExecutionTime(0xc820188c60, 0xc8205f2630, 0x25, 0x6702a0, 0xc8205dbbc0, 0xc820f856a0, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/go-xorm/xorm/engine.go:222 +0x8b
github.com/go-xorm/xorm.(*Session).exec(0xc820d7d400, 0xc8205f2630, 0x25, 0xc8205e34e0, 0x1, 0x1, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/go-xorm/xorm/session.go:494 +0x2de
github.com/go-xorm/xorm.(*Session).Delete(0xc820d7d400, 0x6572e0, 0xc8205e60a0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/go-xorm/xorm/session.go:3919 +0x163d
github.com/go-xorm/tests.testDelete(0xc820188c60, 0xc820188bd0)
    /Users/lunny/gopath/src/github.com/go-xorm/tests/testDelete.go:32 +0x5e8
github.com/go-xorm/tests.BaseTestAll(0xc820188c60, 0xc820188bd0)
    /Users/lunny/gopath/src/github.com/go-xorm/tests/base.go:623 +0x73e
github.com/go-xorm/tidb.TestTidbNoCache(0xc820188bd0)
    /Users/lunny/gopath/src/github.com/go-xorm/tidb/tidb_test.go:50 +0x161
testing.tRunner(0xc820188bd0, 0xd70b20)
    /Users/lunny/go1.5/src/testing/testing.go:456 +0x98
created by testing.RunTests
    /Users/lunny/go1.5/src/testing/testing.go:561 +0x86d

goroutine 20 [chan receive]:
database/sql.(*DB).connectionOpener(0xc82020a280)
    /Users/lunny/go1.5/src/database/sql/sql.go:634 +0x45
created by database/sql.Open
    /Users/lunny/go1.5/src/database/sql/sql.go:481 +0x336

goroutine 21 [select]:
github.com/syndtr/goleveldb/leveldb/util.(*BufferPool).drain(0xc820246000)
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/util/buffer_pool.go:206 +0x29d
created by github.com/syndtr/goleveldb/leveldb/util.NewBufferPool
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/util/buffer_pool.go:237 +0x26b

goroutine 51 [select]:
github.com/syndtr/goleveldb/leveldb.(*DB).mpoolDrain(0xc82026a000)
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/db_state.go:82 +0x14b
created by github.com/syndtr/goleveldb/leveldb.openDB
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/db.go:140 +0x7a1

goroutine 35 [select]:
github.com/syndtr/goleveldb/leveldb.(*DB).tCompaction(0xc82026a000)
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/db_compaction.go:768 +0x7c8
created by github.com/syndtr/goleveldb/leveldb.openDB
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/db.go:146 +0x9a5

goroutine 36 [select]:
github.com/syndtr/goleveldb/leveldb.(*DB).mCompaction(0xc82026a000)
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/db_compaction.go:715 +0x253
created by github.com/syndtr/goleveldb/leveldb.openDB
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/db.go:147 +0x9c7

goroutine 37 [select]:
github.com/syndtr/goleveldb/leveldb.(*DB).jWriter(0xc82026a000)
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/db_write.go:37 +0x1a2
created by github.com/syndtr/goleveldb/leveldb.openDB
    /Users/lunny/gopath/src/github.com/syndtr/goleveldb/leveldb/db.go:148 +0x9e9
exit status 2
FAIL    github.com/go-xorm/tidb 0.475s
```
 Runtime here too, just updated my tidb:

```
2015/09/08 06:00:33 tidb.go:101: [debug] compiling prepared SELECT `id`, `lower_name`, `name`, `full_name`, `email`, `passwd`, `login_type`, `login_source`, `login_name`, `type`, `location`, `website`, `rands`, `salt`, `created`, `updated`, `last_repo_visibility`, `is_active`, `is_admin`, `allow_git_hook`, `avatar`, `avatar_email`, `use_custom_avatar`, `num_followers`, `num_followings`, `num_stars`, `num_repos`, `description`, `num_teams`, `num_members` FROM `user` WHERE `id` = ? LIMIT 1
2015/09/08 06:00:33 txn.go:108: [debug] get key:35_r�sdd, txn:10
panic: runtime error: invalid memory address or nil pointer dereference
[signal 0xb code=0x1 addr=0x20 pc=0x494c535]

goroutine 274 [running]:
github.com/pingcap/tidb/store/localstore.(*dbSnapshot).Get(0xc8200130b0, 0xc82144f580, 0x11, 0x20, 0x0, 0x0, 0x0, 0x0, 0x0)
    /Users/unknwon/Applications/Go/src/github.com/pingcap/tidb/store/localstore/snapshot.go:34 +0x85
github.com/pingcap/tidb/kv.(*UnionStore).Get(0xc820309e60, 0xc82144f580, 0x11, 0x20, 0x0, 0x0, 0x0, 0x6260000, 0xc820258820)
    /Users/unknwon/Applications/Go/src/github.com/pingcap/tidb/kv/union_store.go:91 +0x11c
github.com/pingcap/tidb/store/localstore.(*dbTxn).Get(0xc820309e60, 0xc82144f580, 0x11, 0x20, 0x0, 0x0, 0x0, 0x0, 0x0)
    /Users/unknwon/Applications/Go/src/github.com/pingcap/tidb/store/localstore/txn.go:110 +0x34a
github.com/pingcap/tidb/table/tables.(*Table).RowWithCols(0xc8200ac240, 0x7940408, 0xc820074240, 0x3e9, 0xc8200e2300, 0x1e, 0x20, 0x0, 0x0, 0x0, ...)
    /Users/unknwon/Applications/Go/src/github.com/pingcap/tidb/table/tables/tables.go:416 +0x23d
github.com/pingcap/tidb/table/tables.(*Table).Row(0xc8200ac240, 0x7940408, 0xc820074240, 0x3e9, 0x0, 0x0, 0x0, 0x0, 0x0)
    /Users/unknwon/Applications/Go/src/github.com/pingcap/tidb/table/tables/tables.go:434 +0xce
github.com/pingcap/tidb/plan/plans.(*TableDefaultPlan).Do(0xc8203c90e0, 0x7940408, 0xc820074240, 0xc821290410, 0x0, 0x0)
    /Users/unknwon/Applications/Go/src/github.com/pingcap/tidb/plan/plans/from.go:287 +0x3d1
github.com/pingcap/tidb/plan/plans.(*JoinPlan).Do(0xc820309320, 0x7940408, 0xc820074240, 0xc821290410, 0x0, 0x0)
    /Users/unknwon/Applications/Go/src/github.com/pingcap/tidb/plan/plans/join.go:144 +0x6e
github.com/pingcap/tidb/plan/plans.(*FilterDefaultPlan).Do(0xc8213e6860, 0x7940408, 0xc820074240, 0xc8203c9830, 0x0, 0x0)
    /Users/unknwon/Applications/Go/src/github.com/pingcap/tidb/plan/plans/where.go:76 +0x1ad
github.com/pingcap/tidb/plan/plans.(*SelectLockPlan).Do(0xc8213e68e0, 0x7940408, 0xc820074240, 0xc8203c9680, 0x0, 0x0)
    /Users/unknwon/Applications/Go/src/github.com/pingcap/tidb/plan/plans/lock.go:63 +0xd7
github.com/pingcap/tidb/plan/plans.(*LimitDefaultPlan).Do(0xc8203c9590, 0x7940408, 0xc820074240, 0xc8213e6ae0, 0x0, 0x0)
    /Users/unknwon/Applications/Go/src/github.com/pingcap/tidb/plan/plans/limit.go:73 +0x103
github.com/pingcap/tidb/plan/plans.(*SelectFinalPlan).Do(0xc8213e69a0, 0x7940408, 0xc820074240, 0xc820013040, 0x0, 0x0)
    /Users/unknwon/Applications/Go/src/github.com/pingcap/tidb/plan/plans/final.go:59 +0xc4
github.com/pingcap/tidb/rset/rsets.Recordset.Do(0x7940408, 0xc820074240, 0x79409d0, 0xc8213e69a0, 0xc820013030, 0x0, 0x0)
    /Users/unknwon/Applications/Go/src/github.com/pingcap/tidb/rset/rsets/rsets.go:46 +0x97
github.com/pingcap/tidb/rset/rsets.(*Recordset).Do(0xc8213e69e0, 0xc820013030, 0x0, 0x0)
    <autogenerated>:6 +0xac
github.com/pingcap/tidb.newdriverRows.func1(0xc8213e6a20)
    /Users/unknwon/Applications/Go/src/github.com/pingcap/tidb/driver.go:368 +0xa9
created by github.com/pingcap/tidb.newdriverRows
    /Users/unknwon/Applications/Go/src/github.com/pingcap/tidb/driver.go:387 +0xeb
```
 The similar problem here.

```
[xorm] [info]  2015/09/08 18:06:20.638850 [sql] SELECT * FROM `userinfo` LEFT JOIN `userdetail` ON `userinfo`.`detail_id` = `userdetail`.`id` LIMIT 1
2015/09/08 18:06:20 txn.go:108: [debug] get key:36_r�sdd, txn:442
2015/09/08 18:06:20 tidb.go:101: [debug] compiling prepared SELECT * FROM `userinfo` LEFT JOIN `userdetail` ON `userinfo`.`detail_id` = `userdetail`.`id` LIMIT 1
panic: runtime error: invalid memory address or nil pointer dereference
[signal 0xb code=0x1 addr=0x20 pc=0x411b15]

goroutine 342 [running]:
github.com/pingcap/tidb/store/localstore.(*dbSnapshot).Get(0xc820bb2cc0, 0xc820b8b180, 0x11, 0x20, 0x0, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/store/localstore/snapshot.go:34 +0x85
github.com/pingcap/tidb/kv.(*UnionStore).Get(0xc820984420, 0xc820b8b180, 0x11, 0x20, 0x0, 0x0, 0x0, 0x19b0028, 0xc82000b320)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/kv/union_store.go:91 +0x11c
github.com/pingcap/tidb/store/localstore.(*dbTxn).Get(0xc820984420, 0xc820b8b180, 0x11, 0x20, 0x0, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/store/localstore/txn.go:110 +0x34a
github.com/pingcap/tidb/table/tables.(*Table).RowWithCols(0xc8209e0360, 0x1b061f0, 0xc8206a71a0, 0x3ef, 0xc8209e4800, 0x8, 0x8, 0x0, 0x0, 0x0, ...)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/table/tables/tables.go:416 +0x23d
github.com/pingcap/tidb/table/tables.(*Table).Row(0xc8209e0360, 0x1b061f0, 0xc8206a71a0, 0x3ef, 0x0, 0x0, 0x0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/table/tables/tables.go:434 +0xce
github.com/pingcap/tidb/plan/plans.(*TableDefaultPlan).Do(0xc820b28390, 0x1b061f0, 0xc8206a71a0, 0xc820b28570, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/from.go:287 +0x3d1
github.com/pingcap/tidb/plan/plans.(*JoinPlan).Do(0xc8209842a0, 0x1b061f0, 0xc8206a71a0, 0xc820b28570, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/join.go:144 +0x6e
github.com/pingcap/tidb/plan/plans.(*JoinPlan).doCrossJoin(0xc820984240, 0x1b061f0, 0xc8206a71a0, 0xc8206956d0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/join.go:186 +0xd7
github.com/pingcap/tidb/plan/plans.(*JoinPlan).Do(0xc820984240, 0x1b061f0, 0xc8206a71a0, 0xc8206956d0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/join.go:155 +0x24b
github.com/pingcap/tidb/plan/plans.(*FilterDefaultPlan).Do(0xc820a7f2c0, 0x1b061f0, 0xc8206a71a0, 0xc820b28510, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/where.go:76 +0x1ad
github.com/pingcap/tidb/plan/plans.(*SelectLockPlan).Do(0xc820a7f300, 0x1b061f0, 0xc8206a71a0, 0xc820695680, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/lock.go:63 +0xd7
github.com/pingcap/tidb/plan/plans.(*SelectFieldsDefaultPlan).Do(0xc820a7f6c0, 0x1b061f0, 0xc8206a71a0, 0xc820a7f7a0, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/fields.go:76 +0x1ad
github.com/pingcap/tidb/plan/plans.(*SelectFinalPlan).Do(0xc820a7f700, 0x1b061f0, 0xc8206a71a0, 0xc820bb2c90, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/plan/plans/final.go:59 +0xc4
github.com/pingcap/tidb/rset/rsets.Recordset.Do(0x1b061f0, 0xc8206a71a0, 0x1b06ce8, 0xc820a7f700, 0xc820bb2c80, 0x0, 0x0)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/rset/rsets/rsets.go:46 +0x97
github.com/pingcap/tidb/rset/rsets.(*Recordset).Do(0xc820a7f720, 0xc820bb2c80, 0x0, 0x0)
    <autogenerated>:6 +0xac
github.com/pingcap/tidb.newdriverRows.func1(0xc820a7f740)
    /Users/lunny/gopath/src/github.com/pingcap/tidb/driver.go:368 +0xa9
created by github.com/pingcap/tidb.newdriverRows
    /Users/lunny/gopath/src/github.com/pingcap/tidb/driver.go:387 +0xeb
```
 I have fixed this on go-xorm/tests@811ef5c. But there are still panics. @shenli 
 I have run `go test` with the branch `siddontang/fix-driver-panic`, and I get the only one problem below:

```
--- FAIL: TestTidbWithCache (7.31s)
    testForUpdate.go:99: read lock failed
FAIL
exit status 1
FAIL    github.com/go-xorm/tidb 14.962s
```

This is occupied on the `testForUpdate`, may be tidb don't support `select .. for update` yet?
 Yes. no panic this time. It works well. If @shenli fix that. All the xorm tests will be passed.
 @ngaut OK. Then we can ignore the `testForUpdate()`.
 go-xorm/tests@999772a, I think maybe you can merge branch `siddontang/fix-driver-panic`.
  Would really love to see this.  As with mysql and postges, when dealing with very large queries.  It eventually goes down to using 1 core.

Would be awesome to see MPP.  An example of it being used, is CitusDB.  

Having MPP makes it very powerful indeed!  I believe, Aerospike uses it as well.  Although I could be wrong and Postgres 9.5 with Parallel Sequential Scan was going to be available.  But may have slipped.
 :+1: Looking forward to the next builds.  I will keep an eye out for it.
  Might be useful for testing purposes
 +1
 +1
 Thanks! :smile:
  After I leave interpreter with Ctrl+D key combination, keyboard keys are no longer recognized in that terminal (I suppose they are taken over by other application). Is there any way to fix that?

Additional information:

```
andrey@andrey-ThinkCentre-M82:~$ lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description:    Ubuntu 14.04.3 LTS
Release:    14.04
Codename:   trusty
andrey@andrey-ThinkCentre-M82:~$ go version
go version go1.5 linux/amd64
```
 Update: seems like if you type some experssion and press enter, it will be executed. But you don't see symbols appearing in the terminal in the process of typing
  The `make interpreter` is running 

```
godep go build -ldflags -X "github.com/pingcap/pingcap/util/printer.TiDBBuildTS=2015-09-07 03:40:55" -X
"github.com/pingcap/pingcap/util/printer.TiDBGitHash=81db754a49a63551beb9cd936153eb1f6c612c67  
```

and it failed. `godep go build` succeed though.

```
can't load package: package github.com/pingcap/pingcap/util/printer.TiDBBuildTS=2015-09-07 03:40:55: cannot find package "github.com/pingcap/pingcap/util/printer.TiDBBuildTS=2015-09-07 03:40:55" in any of:
    /usr/local/Cellar/go/1.4.2/libexec/src/github.com/pingcap/pingcap/util/printer.TiDBBuildTS=2015-09-07 03:40:55 (from $GOROOT)
    /Users/leicao/programming/go/src/github.com/pingcap/tidb/Godeps/_workspace/src/github.com/pingcap/pingcap/util/printer.TiDBBuildTS=2015-09-07 03:40:55 (from $GOPATH)
    /Users/leicao/programming/go/src/github.com/pingcap/pingcap/util/printer.TiDBBuildTS=2015-09-07 03:40:55
can't load package: package -X: cannot find package "-X" in any of:
    /usr/local/Cellar/go/1.4.2/libexec/src/-X (from $GOROOT)
    /Users/leicao/programming/go/src/github.com/pingcap/tidb/Godeps/_workspace/src/-X (from $GOPATH)
    /Users/leicao/programming/go/src/-X
can't load package: package github.com/pingcap/pingcap/util/printer.TiDBGitHash=81db754a49a63551beb9cd936153eb1f6c612c67: cannot find package "github.com/pingcap/pingcap/util/printer.TiDBGitHash=81db754a49a63551beb9cd936153eb1f6c612c67" in any of:
    /usr/local/Cellar/go/1.4.2/libexec/src/github.com/pingcap/pingcap/util/printer.TiDBGitHash=81db754a49a63551beb9cd936153eb1f6c612c67 (from $GOROOT)
    /Users/leicao/programming/go/src/github.com/pingcap/tidb/Godeps/_workspace/src/github.com/pingcap/pingcap/util/printer.TiDBGitHash=81db754a49a63551beb9cd936153eb1f6c612c67 (from $GOPATH)
    /Users/leicao/programming/go/src/github.com/pingcap/pingcap/util/printer.TiDBGitHash=81db754a49a63551beb9cd936153eb1f6c612c67
godep: go exit status 1

```
 hey it works.
  fixed a minor typo
 :+1: 
  :smiley: 

```
golint ./...
driver.go:331:24: func LastInsertId should be LastInsertID
parser/scanner.go:41:30: exported func NewLexer returns unexported type *parser.lexer, which can be annoying to use
```
 just leave it there. golint will :angry: someday. 

![](http://reactiongifs.me/wp-content/uploads/2013/12/hell-yes-big-lebowski-lookin-out-my-backdoor.gif)
  @c4pt0r  Thanks for CCing me. I'm sorry to miss the time window for reviewing the PR before merging. We live in different time zones, I would suggest to wait like 24 hours - in case you would like to hear from me ;-)

Anyway, the PR is 99% ok, except for some minor issues, which I believe can be addressed rather easily:
- The particular [`LICENSE`](https://github.com/cznic/ql/blob/9c77931b60c6317f94de402268bbc3e8334b71f4/LICENSE) file, mentioned by the QL copyright code comments is nowhere to be found. Please put that file somewhere. The repository root is possibly a convenient place.
- I suggest to use a distinct name for the QL license file, like, for example `QL-LICENSE`, to not confuse the TIDB and QL licenses. In such case the QL copyright comments in source code should probably be updated to s/LICENSE/QL-LICENSE/.
- The util/format.go is not copyright `ql authors`, but `strutil authors`. I suggest to use the name `STRUTIL-LICENSE` and put the copy of that [license](https://github.com/cznic/strutil/blob/1eb03e3cc9d345307a45ec82bd3016cde4bd4464/LICENSE) in either the repo root or in the `util` directory.

I suggest to reopen this issue or fill a new one as a reminder to solve these final nits.

Thank you very much for your kind cooperation.
 @c4pt0r I see no problem with that approach.
 @qiuyesuifeng I think PR #74 , already merged, did the same.
  This repository publishes code copied from and/or based on copyrighted 3rd party code published under specific licenses; without fulfilling the terms defined in those licenses. Particularly, the original license comments in the original files were removed and replaced by a license claim of the infringing party. That's not acceptable. Also, it's just silly, as the original licenses _permit_ to use/modify/republish or even sell the code without having to pay anything to the authors of the original code.

**Examples**
- [format.go](https://github.com/pingcap/tidb/blob/82ee778d9b1592b877e8895af8fb1dbc474c3cbd/util/format/format.go) contains verbatim copies of parts of code originaly published in [strutil.go](https://github.com/cznic/strutil/blob/1eb03e3cc9d345307a45ec82bd3016cde4bd4464/strutil.go).
- [btree.go](https://github.com/pingcap/tidb/blob/82ee778d9b1592b877e8895af8fb1dbc474c3cbd/kv/memkv/btree.go) contains verbatim copies of parts of code originaly published in [btree.go](https://github.com/cznic/ql/blob/9c77931b60c6317f94de402268bbc3e8334b71f4/btree.go).
- Many files found in the [plan directory](https://github.com/pingcap/tidb/tree/82ee778d9b1592b877e8895af8fb1dbc474c3cbd/plan) contain code clearly derived and/or parts sometimes verbatim copied from code originally published in [plan.go](https://github.com/cznic/ql/blob/9c77931b60c6317f94de402268bbc3e8334b71f4/plan.go).

In only minutes, I was able to found tens of similar additional copyright infringements. Also, this repository now has 100+ of forks and every single fork has the same copyright issue.

In essence, this project is an adaption/extension of the [QL](https://github.com/cznic/ql) project for other SQL syntax and features, including alternative back-ends. (Which is, in sum, an amazing achievement - sincere congratulations.)

To the owners, maintainers of this repository: Please let me know your thoughts/plans/intentions related to this issue. Thanks.
 @c4pt0r Thank you for the feedback, SGTM.
 :+1: 
  As tables is the implement of table. So tables like the drivers, while
table like database/sql. while drivers need to regiester in the init.
  Remove CGO requirement for compiling iconv-go currently is using.

Replace it with native implementation of Go.

`make` test has passed, but test cases don't look very detailed on `expression`, so not sure if everything will go well.

Let's see if you are good with changes, then I'll do the godep thing.
 Updated PR.
 > @Unknwon this function may be used in other places, we may move this to util as an alone package (e.g, iconv) later.

:smile: that's up to you. Not much differences for me.
  ```
go get github.com/go-xorm/tidb
```

and run `go test`, then it panic. Then we open the db use interpreter, and the result is below.

```
➜  tidb git:(master) ✗ interpreter -dbpath=./tidb -store=goleveldb
Welcome to the TiDB.
Version:
Git Commit Hash: None
UTC Build Time:  None

tidb> show tables;
+----------------+
| Tables_in_tidb |
+----------------+
| numeric        |
| picture        |
| userdetail     |
| userinfo       |
+----------------+
tidb> select * from userinfo;
2015/09/07 14:58:22 main.go:202: [error] github.com/pingcap/tidb/rset/rsets/join.go:210: Duplicate column name 'id'
github.com/pingcap/tidb/rset/rsets/join.go:104:
github.com/pingcap/tidb/rset/rsets/join.go:225:
github.com/pingcap/tidb/tidb.go:160:
github.com/pingcap/tidb/session.go:133:
github.com/pingcap/tidb/driver.go:309:
github.com/pingcap/tidb/interpreter/main.go:60:
tidb> desc userinfo;
+------------+---------------+------+-----+---------+----------------+
| Field      | Type          | Null | Key | Default | Extra          |
+------------+---------------+------+-----+---------+----------------+
| id         | BIGINT (20)   | NO   | PRI | NULL    | auto_increment |
| username   | VARCHAR (255) | YES  | UNI | NULL    |                |
| departname | VARCHAR (255) | YES  |     | NULL    |                |
| created    | DATETIME      | YES  |     | NULL    |                |
| detail_id  | INT (11)      | YES  |     | NULL    |                |
| height     | DOUBLE        | YES  |     | NULL    |                |
| avatar     | BLOB          | YES  |     | NULL    |                |
| is_man     | TINYINT (1)   | YES  |     | NULL    |                |
| id         | BIGINT (20)   | NO   | PRI | NULL    | auto_increment |
| username   | VARCHAR (255) | YES  |     | NULL    |                |
| departname | VARCHAR (255) | YES  |     | NULL    |                |
| created    | DATETIME      | YES  |     | NULL    |                |
| detail_id  | INT (11)      | YES  |     | NULL    |                |
| height     | DOUBLE        | YES  |     | NULL    |                |
| avatar     | BLOB          | YES  |     | NULL    |                |
| is_man     | TINYINT (1)   | YES  |     | NULL    |                |
+------------+---------------+------+-----+---------+----------------+
```
 Same here...
 Why the auto increment id is not start from 1 but 1001? I think this is the problem.
 > Fail to initialize ORM engine: migrate: sync: Try to add a column with the same name of an already exists column.

It's now keep giving me this error.... is this the same behavior of MySQL?
 Thanks @shenli ! I've updated driver and it works now, but there is always a warning message:

> [warning] New txn:491 in session:1

And it prints a sound, what is the purpose of this?
 > SELECT `id`, `user_id`, `repo_id`, `mode` FROM `access` WHERE repo_id=? AND mode>=?
> , error: line 1 column 77 near "mode"

Is `>` a invalid operator? 
 I have updated go-xorm/tests and the autoincrement problem is gone. I will close this, since the problem is resolved. @Unknwon, you can make a new issue to report the problem.
  Much better, thanks!
  this is `gofmt -s`, right?
 @zimulala Ideally, you should mention this in CONTRIBUTION.md and add this test into travis.
 @zimulala ah. great! 
  Remove CGO requirement for compiling iconv-go currently is using.

Replace it with native implementation of Go.

`make` test has passed, but test cases don't look very detailed on `expression`, so not sure if everything will go well.
 Thank god, passed this time.
 LGTM. But I cannot press the merge button. :(
 Godep is killing GitHub diff. So, you can't even find where did I changed.
 @Unknwon I usually keep them into separate commits:
1. change
2. godep
 godep save doesn't work with tidb out of box, so I changed everything manually :joy: really don't want to go through hell again. 
 OK... there is the diff:

``` patch
diff --git a/expression/expressions/convert.go b/expression/expressions/convert.go
index b636cb5..8fc7918 100644
--- a/expression/expressions/convert.go
+++ b/expression/expressions/convert.go
@@ -17,11 +17,12 @@ import (
        "fmt"
        "strings"

-       iconv "github.com/djimenez/iconv-go"
        "github.com/juju/errors"
        "github.com/ngaut/log"
        "github.com/pingcap/tidb/context"
        "github.com/pingcap/tidb/expression"
+       "golang.org/x/net/html/charset"
+       "golang.org/x/text/transform"
 )

 // FunctionConvert provides a way to convert data between different character sets.
@@ -74,7 +75,13 @@ func (f *FunctionConvert) Eval(ctx context.Context, args map[interface{}]interfa
        } else if strings.ToLower(f.Charset) == "utf8mb4" {
                return value, nil
        }
-       target, err := iconv.ConvertString(str, "utf-8", f.Charset)
+
+       encoding, _ := charset.Lookup(f.Charset)
+       if encoding == nil {
+               return nil, fmt.Errorf("unknow char decoder %s", f.Charset)
+       }
+
+       target, _, err := transform.String(encoding.NewDecoder(), str)
        if err != nil {
                log.Errorf("Convert %s to %s with error: %v", str, f.Charset, err)
                return nil, errors.Trace(err)
```
 https://github.com/pingcap/tidb/pull/42
  Hi, 

I'm using https://github.com/go-xorm/tidb as driver for xorm, and when xorm executes following command:

``` sql
SELECT `TABLE_NAME`, `ENGINE`, `TABLE_ROWS`, `AUTO_INCREMENT` from `INFORMATION_SCHEMA`.`TABLES` WHERE `TABLE_SCHEMA`=? AND (`ENGINE`='MyISAM' OR `ENGINE` = 'InnoDB') [data/gogs.tidb]
```

TiDB gives me error:

```
[error] Compile sql error: use gogs.tidb - 1:9 expected one of [$end, ';', CHARACTER, CHARSET, COLLATE, DEFAULT]
```

So, which exactly this `1:9` points to? Maybe error message can be more clear like how MySQL does:

```
xxx near "my statement"
```

Or 

```
expect xx but found yy 
```

can be very helpful, too!

Thanks!
 OK, thanks!

But please add this to docs.
 Just tested again without dot in db name:

```
2015/09/07 05:32:52 session.go:123: [error] Compile sql error: use gogs-tidb - 1:9 expected one of [$end, ';', CHARACTER, CHARSET, COLLATE, DEFAULT]
[xorm] [info]  2015/09/07 05:32:52.159445 [sql] SELECT `TABLE_NAME`, `ENGINE`, `TABLE_ROWS`, `AUTO_INCREMENT` from `INFORMATION_SCHEMA`.`TABLES` WHERE `TABLE_SCHEMA`=? AND (`ENGINE`='MyISAM' OR `ENGINE` = 'InnoDB') [data/gogs-tidb]
```

Exactly same error... is it really about database name?
 My bad.... `-` can't be used either. :sob:
 @Unknwon try `_` 
 Thank you both @mathiasrw @shenli

Please put that on docs... it is very confusing.
  System: Mac OS 10.10.5

Dump from console:

```
----------------------------------------------------------------------
FAIL: time_test.go:292: testTimeSuite.TestCodec

time_test.go:339:
    c.Assert(t.String(), Equals, t4.String())
... obtained string = "0001-01-01 00:00:00"
... expected string = "0000-12-31 23:00:00"


----------------------------------------------------------------------
FAIL: time_test.go:342: testTimeSuite.TestParseTimeFromNum

time_test.go:392:
    c.Assert(err, NotNil)
... value = nil

OOPS: 14 passed, 2 FAILED
--- FAIL: TestT (0.01s)
FAIL
coverage: 89.6% of statements
```

Is this a actually bug or just something wrong with test case?
 -0400 EDT 
 Fixed, thanks!
  Version is a good flag for users. User can use version to update and report issues.
 That's weird. Why put the version in the util package? From the structure it's not make sense.
 You mean you will use the version in many other packages? Then the version is out of control. :smile_cat: 
 @ngaut Well... You can make then read-only.
 I have no idea on the version now. AFAIK https://github.com/pingcap/tidb/blob/master/util/printer/printer.go#L23 looks not good enough.
 +1 

Need something like `Version()` around [here](https://github.com/pingcap/tidb/blob/master/tidb.go#L45), and it should return semantic version, so app can check it in case a bug was introduced in older version but fixed in newer one.
 the version number is useful to version control.

Now I find that if tidb code updated, the old goleveldb data directory can't load.

So I need lock a version to make sure to develop and compile.
  pprof looks like a debug tools. So I think the default should turn off.
And if pporf turn on, user can also change the pprof addr.
 谢大真是勤奋
 > having Debug set to true by default would be more convenient.

HERE WE GO https://github.com/pingcap/tidb/commit/7adf722a535e25c6abc0e605439380b981054e3d
:smiley: 

> create a topic branch and make changes on that branch, it's easier for your forked repo to keep in sync with upstream.

I think it just make sense from branch name. but it's not related to the upstream.
      ![qq 20150906173942](https://cloud.githubusercontent.com/assets/2142787/9703736/0d477ec8-54bf-11e5-88e4-c98460d15a9d.png)

two questions:
1. `syscall.Dup2()` can't works on Windows. There is any plan for Windows support.
2. it needs `iconv.h` as cgo library. Is it possible to use pure go codes instead of cgo codes ?

`
 I make a pull request for log library

https://github.com/ngaut/log/pull/1

It can work on Windows.

But I find that `tidb` don't use the breaking api `log.CrashLog()`.... so funny.
 tidb can be compiled and running by using bat script in https://github.com/pingcap/tidb/pull/130.

thanks a lot.  I will test more cases in windows.

If something breaks, I make a new issue.
  Thanks for sharing the great work! Just try to improve the README as I am reading through it.
  Why not have a per repo one?
