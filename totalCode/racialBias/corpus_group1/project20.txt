  Looks like the site has invalid content.json, the error is at site's content.json file line 3140, try to update it manually using ZeroHello.  ### Step 1: Please describe your environment

  * ZeroNet version: 0.6.0 r3097
  * Operating system: Arch Linux
  * Web browser: Chromium
  * Tor status: always
  * Opened port: no
  * Special configuration: tor = always

### Step 2: Describe the problem:

I want to update ZeroNet without using clearnet. Is it possible?

#### Steps to reproduce:
  1. Launch ZeroNet with `tor = always` option;
  2. Click on the "New ZeroNet version: 0.6.1";
  3. Then click on the "Update and restart ZeroNet".

#### Observed Results:
```
Update site path: /var/lib/zeronet/1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp, bad_files: 0
/usr/lib/python2.7/site-packages/msgpack/__init__.py:47: FutureWarning: use_bin_type option is not specified. Default value of the option will be changed in future version.
  return Packer(**kwargs).pack(o)
[15:22:17] - Redirect to: https://codeload.github.com/HelloZeroNet/ZeroNet/zip/master
Segmentation fault (core dumped)
```
#### Expected Results:

ZeroNet updated to the latest version. Looks like something with gevent. What output you get for
` python -c "import sys; print sys.version; import gevent; print gevent.__version__; import msgpack; print msgpack.version;"`?  ## Why?

It will allow to discover peers on local network without internet connection. Currently it's only possible by setting up a tracker by enabling the Bootstrapper plugin and pointing every client to that ip.

### How?

[Zeroconf](https://en.wikipedia.org/wiki/Zero-configuration_networking) allow clients to discover each other without server intervention.

### What?
Started working on local peer discovery using https://github.com/jstasiak/python-zeroconf as it seemed like the most active one and also works with gevent.

## Problems / Questions:
### Binary dependency
It depends on netifaces module that is not pure-python which I try to avoid due multi-platform issues. Solved it by creating a "fake" netifaces module that returns using the current Upnp.py module's `_get_local_ips` function.
Other dependencies: six, enum (both light, pure-python modules, so should not be a problem)

### How to broadcast the list of sites you have?
 - Creating service to each site
 - Adding it to service's description
 - Don't distribute it to zeroconf network, but allow the other client to receive a list of site address sha hashes you have. (this plugin will be turned off by default in tor: always mode)
 - Don't do anything, let other clients try and fail for unknown sites

### Avoid leaking local peer ips to peer exchange
 - Mark sites that received via zeroconf
 - Skip local ip ranges on pex


## Current status

 - I was able to create a registration request and other computer on the same network was able to discover it
 - Ran into some gevent error (<1.1 version), I was able to fix it, but one more ugly patches
 - Added private ip detection and filter to pex
 - Found a way to make it work on gevent without ugly patch
 - Moved to simple UDP broadcasting with custom protocol due [zeroconf problems](#issuecomment-361974868)

### Plan
 - [x] Create Plugin directory for it
 - [x] Basic broadcast listener server
 - [x] Testing basic broadcast server functions
 - [x] Extended broadcast server with peer discovery functions
 - [x] Implement discoverRequest, discoverResponse, siteListRequest, siteListResponse commands
 - [x] Test discoverRequest, discoverResponse, siteListRequest, siteListResponse commands
 - [x] Implement and test siteListRequest caching based on sites_change
 - [x] Test local peer exchange on UDP socket
 - [x] Connect peer discovery with announce events
 - [x] Prefer recently discovered tracker/LAN clients
 - [x] Set up multiple clients on LAN without internet connection for real-life testing
 - [x] Release I started experimenting with simple broadcast udp messages as zeroconf lib has the following problems:
 - No ipv6 support
 - Can't announce different ip for multiple network interfaces
 - Relatively high cpu usage (~15 cpu seconds/hour on chip computer in my quiet LAN)

I'm not sure if zeroconf/mdns/bonjour has other benefits over udp broadcasting that we can use/need

### Protocol draft:

- Listening on udp 1544
- msgpack? or json? encoded protocol

Discover request sent every 20 minute, when a user added new site or started the client. (when sites announces)

#### Version A
```
> broadcast: {"cmd": "discoverRequest", "params": {"zeronet": {version_rev: 3222}}}
< response to requester: {"cmd": "discoverResponse", "params": {"zeronet": {"port": 15441, "sites": 3, "sites_changed": 1517415166, version_rev: 3222}}}
```

If the requester interested, then it can connect to the respondent with standard tcp/zeronet protocol and ask for sitelist with a new `siteList` command (only available from local/private ips) and add it to peer list of the sites that the respondent has.

#### Version B
```
> broadcast: {"cmd":"discoverRequest", "params": {"zeronet": {"port": 15441, "sites_changed": 1517415166, "rev": 3222, "peer_id": "-ZN0061-AnJx5Pamk0U0"}}}
< response to requester: {"cmd": "discoverResponse", "params": {"zeronet": {"port": 15441, "sites": [sha256("1siteaddress1"), sha256("1siteaddress2"), ...], version_rev: 3222, "peer_id": "-ZN0061-AnJx5Pamk0U0"}}}
```

This way the requester don't have to connect to respondent to list the site, but the site list will be pushed with response.

**Problems**
 - Larger response size: I think 32 byte / site address is still acceptable on LAN (32k for 1000 hosted sites)
 - UDP packet size limit: Can be solved by sending a new response for every 100 site address

#### Version A + B

Also send the sitelist over UDP, site list only sent on `siteListRequest`. This requires one more roundtrip, but saves cpu + bw.

- Broadcast: `discoverRequest`
- Every broadcast listener -> requester: `discoverResponse`, params: zeronet tcp port, sites_changed (last time the user added or removed a site to the client), rev, peer_id
- requester -> clients who has different sites_changed time, than the requester stored: `siteListRequest`
- requested clients -> requester: `siteListResponse` params: zeronet tcp port, sites_changed, rev, peer_id (the client adds peer ip to site site list and updates the stored sites_chaned value for the peer_id)

**Questions**
 - What about network changes? (different wifi network, sleep / wakeup) CC @MuxZeroNet   I got the barrier when tried to get [grapejs](http://grapesjs.com/) work. I will check what's the best way to remove the limitations of sandboxed iframe.
  The problem is FileQuery will get slow after a certain amount of file (depends on hdd/ssd/mmc speed), so I not sure if we should encourage using it. Then adding cross-site database query support sounds better for me if it would solve the problem. Working on it... I will change the (currently undocumented) "As" command to allow this.
It should not take long :) [Added](https://github.com/HelloZeroNet/ZeroNet/commit/327badb3ca175621fb5f00b9fb8f101d0268c11c) to Rev3230, usage example:
`page.cmd("as", ["138R53t3ZW7KDfSfxVpWUsMXgwUnsDNXLP", "dbQuery", "SELECT * FROM json"])`
 Try this way: `page.cmd("as", ["138R53t3ZW7KDfSfxVpWUsMXgwUnsDNXLP", "dbQuery", ["SELECT * FROM json WHERE json_id = :param", {param: param}]])` Just added it:

https://zeronet.readthedocs.io/en/latest/site_development/zeroframe_api_reference/#as-address-cmd-arguments  The main problem proof-of-storage and proof-of-bw is really hard (impossible?) opposed to proof-of-cpuwork.
 > FYI, Proof of Space is possible. PoS uses hard-to-pebble graphs to ensure the prover must dedicate a certain amount of storage.

Thanks for pointing out, but it sounds like it's not for any meaningful data and even it would be so the proof-of-bw solution is still required to make it comparable to pow. The problem is (unlike steam) in ZeroNet there is no trusted parties, so: who would decide if someone uploaded 1GB or not?
 @mkg20001 It's very abstract, missing lots of details, but we will see once it's launched.  Actually you don't have to change anything in content.json, here is the steps:
 - Generate address using vanitygen
 - Create data/1yourvanityadress directory and copy the site file's there
 - Open http://127.0.0.1:43110/1vanityaddress in your browser
 - Open sidebar and sign all the content.json at the bottom of it.  ## Why?
The current, whitelist based listed ID provider solution leads to unnecessary centralization.

## How?
Proof-of-work based ID providers could let anyone create his/her own one and use it on any site that supports these kinds of ID providers.

## What?
The site could add required prefixes for ID providers instead of specific listing the supported ID providers.

Example for current, white-list based configuration:
```json
...
"user_contents": {
 "cert_signers": {
  "zeroid.bit": ["1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz"]
 }
}
...
```
This allows only one certificate provider on the site for the user contents.

Example for new, Proof-of-work based id specification
```
...
"user_contents": {
 "cert_pattern": "^1ZeroiD"
}
...
```
It would allow any certificate provider that's Bitcoin address starts with "1ZeroiD".
Currently, it takes around 6 hours on a ~200USD GPU or 30 USD on https://bitcoinvanitygen.com/
to generate an address with this prefix, which should be eligible to fight against spam.

Using the permission rules the site owners able to ban/set specific limits or rules based on ID provider address.

The users who don't have the possibility to generate his/her own ID provider could use
already existent ID providers that accept third-party registrations.

## Problems

### Backward compatibility

An older client won't accept user files signed by these id providers.

### ID provider naming

We can't add readable name for the id providers, so they will appear as bitcoin address eg.: user@1ZeroiDJnkHkugPNd8UzSwceH8HfsnYtC

**Possible solution:** Display only the first few letter of the unique part, eg.: user@JnkH...

### Unlimited number of users

We can't limit the number of users issued by the ID provider the per-user size limit going to lose some effectiveness.

**Possible solution:** A per-ID provider limit.
  I just generated a 1ZeroiDJnkHkugPNd8UzSwceH8HfsnYtC address in 3 hours, so maybe we should make it harder like "1ZeroiD[0-9]" should take ~2-3days on my machine It's not acceptable for new users, but they would able to use already existing id providers. So if you do that 2-3 days of calculation you are also able to issue new certificates for users you trust.
 Will cert pattern "cert_pattern": "^1" be allowed in this implementation? (while list all cert providers). Sure, but if you don't want to have any control over the content submitted to your site, then I recommend self-signed certificate.  The zeronet.exe starts in non-console mode and unfortunately there is no way to change it later. If you need the console window, then there is a zeronet.cmd in the lib directory that starts zeronet with cli. Thanks!  Probably we can use the pinning feature for this I think it should never delete pinned files  Thanks!  Thanks for reporting. I switched to eval from exec: https://github.com/HelloZeroNet/ZeroNet/commit/0c6c7d27252f01cddbc8cc7109082f6a72afb7d7#diff-7fa31802ec08bb55f5128c3e841b5f34R645

Can you please verify if it's fixed the problem?
You have to save https://raw.githubusercontent.com/HelloZeroNet/ZeroNet/0c6c7d27252f01cddbc8cc7109082f6a72afb7d7/src/Ui/UiRequest.py to Users/Kafke/Downloads/ZeroNet-master/src/Ui directory I just tested it with python 2.6.x and it works (the exec code drops the same error as you described), so I suppose it will work with 2.7.6  Has it worked before? What version are you on currently? What do you see when you visit the ZeroUpdate site in your client?  What error message you see in the javascript console? (F12)  Thanks for the detailed report. 
We send port = 0 when the client is in passive mode (without public ip) to avoid listing it to other clients. Looks like it's not compatible with every tracker software. I have just tested your code with the trackers we currently using and all accepts port=0. 
To avoid this problem we have to find an other way to get the peer list without putting my ip to the list.
  ### Step 1: Please describe your environment

  * ZeroNet version: 0.6.0 rev3171
  * Operating system: Ubunty 16.04
  * Web browser: Google Chrome 63.0
  * Tor status: error
  * Opened port: no
  * Special configuration: no

### Step 2: Describe the problem:

Can use JS to backup and restore localStorage data for current site using wrapperXetLocalStorage API calls. Can use OS backup but methods are different for each browser, not very user friendly and may change in new browser versions.

Could be nice to backup and restore localStorage data for all ZeroNet sites. 
wrapperXetLocalStorage cmd with ADMIN permission or button in 0 sidebar?  actually it's `lib/zeronet.cmd siteCreate` as the zeronet.exe is gui-only application and you won't see any output to command line from it.

But you can also use the web interface to create new site. `â‹® > Create new, empty site` on ZeroHello
 > All work, including zeronet.exe.

Yes, it does work, but using the zeronet.exe you won't see any response/output/message in the command line.  Thanks!  Thanks for reporting:
 - Does it worked for you earlier?
 - What operating system are you using?
 - Can you please upload the `(core)/src/Ui/template/wrapper.html` here
 Looks like your computer has some [virus](https://stackoverflow.com/questions/31246535/how-is-this-piece-of-vb-code-getting-added-automatically) on it and it modified the html file (added part after `</html>`)
The wrapper.html should look like this: https://raw.githubusercontent.com/HelloZeroNet/ZeroNet/master/src/Ui/template/wrapper.html (2.51KB)

You can try to overwrite the file with this one, but probably you need to get rid of that virus (or anything that modified the file) first.

    Thanks for reporting, it should work fine now: https://github.com/HelloZeroNet/ZeroNet/commit/3fb9f900f6c0d08abd8facc987af4a274d31d56b  Imachug: I would prefer to use the current ones. ZeroTalk has a jquery compatible version of the dropdown menu. I think that would be the best to use to keep the UI consistency.
https://github.com/HelloZeroNet/ZeroTalk/blob/master/css/Menu.css
https://github.com/HelloZeroNet/ZeroTalk/blob/master/js/utils/Menu.coffee
https://github.com/HelloZeroNet/ZeroTalk/blob/master/js/TopicList.coffee#L260
https://github.com/HelloZeroNet/ZeroTalk/blob/master/index.html#L179 I have no email from saketjoshiiit Currently I made some changes on sidebar. I'm going to publish a new version in the next days after that I will check it.  Hi, thanks, it's a nice addition! There is a small bug: the `re.sub(r":" + re.escape(key) + r"([)\s])", ` does not matches if the query ends with the parameter. 

Eg.: `assert db.execute("SELECT COUNT(*) AS num FROM test WHERE test_id IN :test_id", {"test_id": [1, 2, 3]}).fetchone()["num"] == 3`

And for me `params IN 1, 2, 3` does not work, only `params IN (1,2,3)`

And please extend the TestDb.py with test cases that covers this way of parameters.
  
Update: Merged & Fixed it :)  The tor client bundled with the Tor browser is not configured to make it work with ZeroNet by default. I'm planning bundle the Tor client with the macOS client, that will solve this problem.  What does the per-site breakdown says? You can see it by click on "from xx sites in x.xx s" text in the search input area Is there any error in the js console? (F12) According to 'Error: div.FeedList.search had a div child added, but there is now more than one. You must add unique key properties to make them distinguishable. all.js:443:35' it looks like one of the sites you following does not providers unique id for the feed item.
I have added a fix for it (https://github.com/HelloZeroNet/ZeroHello/commit/5dac15190e3bc3b0664baf17d8ebef2a9ea0afe0) please check if it's fixed it. I published the modification to ZeroHello, so it should automatically update your all.js file.

Please try this one:
 - Add `site.log.debug("Newsfeed %s query taken: %.3fs" % (name, time.time() - s))` line after https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Newsfeed/NewsfeedPlugin.py#L89
 - Restart ZeroNet
 - Check log/debug.log file for "Newsfeed query taken" lines and see which site blocks the update. According to the log it looks like it was caused by a site with no database, but with a feed signup. From Rev3178 will skip these sites (https://github.com/HelloZeroNet/ZeroNet/commit/92e353be40533140b783ede48010566848da9805) please update and try again
  small correction: only big files (>20MB) get automatically pinned (https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/OptionalManager/OptionalManagerPlugin.py#L134), smaller files will be automatically deleted if you reach the storage limit (10% of your free space by default, but you can change it on files tab)  Thanks for the reminder, just filled out the form. Let's hope for the best :)  Is it happened after you clicked "Set limit to xx MB"  button?  Unfortunately this is a restriction of the browsers: Web pages opened with target=_blank from sandboxed iframe keeps the sandboxing, so won't be access cookies and many other things. It works fine if the users opens the link to new tab (eg. with middle mouse click)
Possible solution:
 - Open to current tab with target=_top
 - As @AnthyG said: use the wrapperOpenWindow API call

To automatically fix all target=_blank links:
```js
window.onclick = function (e) {
    if (e.target.getAttribute("target") == "_blank") {
        e.preventDefault()
        page.cmd("wrapperOpenWindow", [e.target.href, "_blank", ""])
    }
}
```  It's your responsibility to keep your time in-sync, ZeroNet can't really do anything about it, but to avoid irreversible problem you won't be able to publish a file in the far future (t + 1day)  The newsfeed feature is something like this, but there is lots of space to extend it's possibilities. Eg. by adding JS logic support for more complex notifications (to make ZeroMail support possible)  None of these are prossible atm, but it could be:

> I don't allow user to edit post content after he posted

Diff the updated file with the current one and if there is any modification, then reject it.

> I don't allow user fake time timestamp

I don't this if there is any reliable solution for this.

> I want assign someone as admin to manage part of site, not whole site

With includes you can set per directory signers.  I would recomment to create a ZeroTalk clone for the proxy and the user would use it for submission to the admin.  There is lots of other Chinese messages on the board, so I think the problem should be somewhere else  I'm not sure what you mean. For the site messages you can use the built-in, json based translator solution. 
If you want to translate the user submitted content, then it's much harder and probably you need to use a third party service for that (eg. google translate) via a browser plugin  please try this way:
```
ui_host =
 sub1.zeronet.io
 sub2.zeronet.io
```  Actualy there is already a "wrapperRequestFullscreen" API call to do that. It was undocumented, but just fixed that issue: https://zeronet.readthedocs.io/en/latest/site_development/zeroframe_api_reference/#wrapperrequestfullscreen I have tried to add the allowfullscreen attribute, but it's not possible to add it after the iframe was rendered. (after the request of fullscreen approved) Well, why not... added in latest rev: https://github.com/HelloZeroNet/ZeroNet/commit/0009b1b7d1d3fc62a0b126b8ed1d66730e75242b  It's only required to access the websites, so you can block 43110  (by default it only allows connection from your computer)  Thanks for reporting I just tested Midori 0.5.1 and I can confirm , that the sidebar does works on it, but the problem is no related to WebGL support, because for example it works in Tor browser and enabling WebGL in Midori does not fixes it. 

I tried to find what exactly missing for the sidebar, but lack of any web developer tools makes it really hard.  It need some modification in wrapper code to use relative path for the websocket connection  example `zeronet.conf`:
```
[global]
data_dir = my-data-dir
log_dir = my-log-dir
ui_restrict =
 1.2.3.4
 2.3.4.5
```
You can list the possible configuration options with `zeronet.py --help`
 by default it tries to load the config from the working dir. You can override this with `--config_file "/etc/zeronet.conf"` startup argument I gave you an example in comment https://github.com/HelloZeroNet/ZeroNet/issues/1192#issuecomment-346219984
I will consider adding .conf file by default  Currently it won't work without moving the site data directories, but it would be a great addition. Added in Rev3153: https://github.com/HelloZeroNet/ZeroNet/commit/6b92d011d24c708674891f174a8d7f9c5153d7ef
All missing site from sites.json will be downloaded at startup.
  I'm planning to change it to display only when the user registers itself an ID (eg. using ZeroID) From Rev3151 it will only show the seed on certificate add: https://github.com/HelloZeroNet/ZeroNet/commit/9df86ecaa976c2dbf86b5965b9df61109a41781e  You also need to pass more headers for websocket, eg.:
```
server {
    listen 443 ssl;

    server_name        url;
    ssl on;
    ssl_certificate        /etc/letsencrypt/live/url/fullchain.pem;
    ssl_certificate_key     /etc/letsencrypt/live/url/privkey.pem;
    ssl_session_timeout 5m;

    location / {
        proxy_pass http://0.0.0.0:43110;
        proxy_set_header Host $host; #get rid of media referrer error
        proxy_http_version 1.1;
        proxy_read_timeout 1h; #for long live websocket connetion
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```
via http://127.0.0.1:43110/1EiMAqhd6sMjPG2tznkkGXxhdwFBDdeqT9/?Post:44
 ZeroNet using sandboxed iframe to avoid same-origin problems, so it requires iframe support.  If you using the same .onion address for every hosted site, then it's possible to list which other sites you hosting by checking that address in other sites peer list.
If I understand correctly, then the authentication feature does not improve this.
    The content type restriction is present, to avoid site addition with a simple img tag eg.: `<img src="/1myothersite">`
You can use the /raw/ prefix to load content using curl. eg.: http://127.0.0.1:43110/raw/1anything...
 It looks like some weird browser: `"Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; Touch; rv:11.0; 2345Explorer/8.8.3.16721) like Gecko"`
Not sure what is "2345Explorer/8.8.3.16721", but I just tested in IE11 (based on `Trident/7.0; Touch; rv:11.0;` part) and it works  You are not missing anything it should work. 
Is your or the other client has opened port? 
Do you have Tor enabled?
Have you tried to sign/publish the site (eg. using the sidebar) again? Probably that's why they can't find each other. The local network peer discovery not implemented yet and it puts the client's external ip:port to blacklist to avoid connecting to itself.
You can try start one of the clients using `--fileserver_port 15442` to avoid this.  Like I said in the linked issue: I have not found any suspicious activity and if it's really an attack then banning based on ip address is not a viable solution as anyone can generate unlimited ammount of .onion address. @imachug I can hardly imagine that your problem was caused by an attack on the network. 

There was an error in the rate limiting algorithm that could have caused problem like you described. I fixed some days ago in Rev3137: https://github.com/HelloZeroNet/ZeroNet/commit/5026f1b0a8bad418fcc9baf0137e5f7ee877513c

Please open an issue if you still experiencing it after the update.  Thanks, please also add translation for other files and to ZeroHello, so I can list it on the language selector.  It wasn't initially, but it was fixed in Rev3125: https://github.com/HelloZeroNet/ZeroNet/commit/99e5af67b75f6543bcba7a2e49322a7699d1a7cb
There was other bigfile related problems with merger sites, but it should work fine now.
  Thanks for reporting, fixed: https://github.com/HelloZeroNet/ZeroNet/commit/bc1d79a07d976d521aa9900233749f481aff6fb3  The data/sites.json has "peer" filed for every site you seeding. Or you can use the websocket API: https://github.com/HelloZeroNet/ZeroNet/issues/1137#issuecomment-337019878 Currently it's not possible without downloading the site.  Some blogs are art-centric and have posts with no text at all, sometimes even without titles, so it's hard to get them into newsfeed. Also all popular sites such as facebook and twitter have media objects in newsfeed, and it's pretty.
I propose two new fields in the [`feedFollow`](https://zeronet.readthedocs.io/en/latest/site_development/zeroframe_api_reference/#plugin-newsfeed) command:

- `media_url`: url of the media object
- `media_type`: one of `{'image', 'video', 'audio'}`

I think one media object per record would be enough. If user is interested, he can follow the link to view all content.
Please, share your thoughts. It's could be possible in a way that ZeroMe work: Display already downloaded images, other visible on click.  Well actually OS X is macOS now :)  in theory i fixed it some days ago. Maybe I forgot to sign + publish it, so I just did it again. Please try again and if it's still not working for you, check the JS console (F12) for error.  why not, added: https://github.com/HelloZeroNet/ZeroNet/commit/c3250378ee110721fc919e1ecfeb4c1040839f3f  wat operating system/browser are you using and where do you see this message? @imachug Actually it using github to update: https://github.com/HelloZeroNet/ZeroNet/blob/master/update.py#L16
update_after_shutdown used here: https://github.com/HelloZeroNet/ZeroNet/blob/master/zeronet.py#L20

@kkkkketsu I can't find the "Can not be updated automatically" in the source code, where did that message appeared to you?  Godd idea, It should be better now: https://github.com/HelloZeroNet/ZeroNet/commit/90ff9ac7fb2a0babf52aa72066e10217a5a7ffe8  Thanks!  To backup your identity you have to save data/users.json the sites are also in this direcory  It could be possible, but not sure about security issues @MuxZeroNet Do you see any problem setting executable flag on specific files automatically? We could add a like this to content.json:
```
...
"files": {
  "any/file": {
    "sha512": "asd...",
    "size": 123,
    "executable": true
  }
``` I'm not a linux expert, so I still waiting others opinion on security issues  Thanks for the suggestion, it's changed in Rev3126: https://github.com/HelloZeroNet/ZeroNet/commit/09413f5fc794616ce61d357611141462d59ca04f  I think it should work this way right now:
 - create a bootstrapper client on the local network by renaming plugins/disabled-Bootstrapper to plugins/Bootstrapper
 - Add `trackers = zero://ip.of.bootstrapper.client:15441` to zeronet.conf
 - start zeronet with `zeronet.py --ip_external yourlocalip`

Required improvements:
 - Implement local peer discovery eg.: https://pypi.python.org/pypi/zeroconf (so it would to require to setup a bootstrapper node in most cases)
 - Don't send local peers via PEX
 - Add ipv6 support
  do you have your site's address in your users.json? does it have "pirvatekey" entry in that section? @krixano is right. 
Looks like you have the privatekey in place, so you should be able to edit it. When you open the sidebar (by dragging the topright button to left) do you have "this is my site" enabled? and what happens if you press the sign button on the bottom of that panel? @wzhb When you open the sidebar (by dragging the topright button to left) do you have "this is my site" enabled? and what happens if you press the sign button on the bottom of that panel?  What platform are you using? What does it says for Tor status on ZeroHello page?  You don't have to edit it, you can enable usage of Tor on every connection by clicking on Tor: Avaliable > Enable tor for every connection  For testing reasons: how many files you want to read at once? I was unable to reproduce it, but I found a bug that could have affected this case. (https://github.com/HelloZeroNet/ZeroNet/commit/9d4515954b8cb7f8c0af31f30d83567a3486e624) Please update to latest version and try again.

I was able to read 100x3MB zip files this way:
```
	read() {
		for (var i=0; i<100; i++) {
			page.cmd("fileGet", {inner_path: "optional/" + i + ".zip", format: "base64"}, function(res) {
				if (res)
					console.log(res.length)
			})
		}
	}
```
  It should be fixed by https://github.com/HelloZeroNet/ZeroHello/commit/b4f488a35b1d9460ba4fd15e33d543f577563749  That's sounds like a bug, it should not delete missing optional files from content.json I tried to reproduce it, but it does not removes the previous optional files for me:
 - Created a new site
 - Added `"optional": "optional/.*",` to content.json
 - Signed
 - Created `optional/test.html` file
 - Signed
 - Deleted `optional/test.html` file
 - Signed
 - The `optional/test.html` file still in the site's content.json

I also tested it with my ZeroID profile: deleted one of the images I previously submitted, but after signing the file still in content.json.

Do you have other steps to reproduce the bug?
 I have used the sidebar + ZeroMe page for testing, not the command line interface For me: Test OK. 2 optional files. The writing is takes long time because it tries to read files that is not existent and waiting for competition. (line 152, should contain required: false)
 Fixed the problem with long running operations and retested on fuckcf.cf. Still "Test failed. No optional files were found".

Checked siteSign cmd and there is an "remove_missing_optional" parameter that I can use instead of deleting content.files_optional before sign. The original problem that I was trying to solve was failed siteSign due to missing optional files. 

Still a bug but only a minor bug as remove_missing_optional is a "nicer" solution to the problem.  Thanks :)  This wasn't unexpected, but as long as you can run Tor, then it should work fine.

Actions from GFW: 
 - *.zeronet.io domain points to different ip. source: http://viewdns.info/chinesefirewall/?domain=zeronet.io
 - IPban on 104.156.231.236 (zeronet.io website ip address): source: http://ping.pe/104.156.231.236

## Affected services:
### zeronet.io website
The site can't be accessed due domain & ip ban. Changing IP does not help, registering new domain also not a long-term solution

Possible solutions:
 - Set up mirrors, eg. to http://hellozeronet.github.io/

### ZeroBoard
ZeroBoard was the first site on ZeroNet when multi-user sites was not possible, so the messages are signed and distributed by contacting the site owner which was done by a simple http request.

Possible solutions
 - Drop this site
 - Re-create the site with self-signed id certificates
 - Move the adder script to different domain and ip
 - Add a whisper protocol to ZeroNet that allows messages to be distributed between peers just like updates. (Cons: spam solution?)
 - Add a direct message option to ZeroNet API that allows direct messages to be sent to an ip address using ZeroNet protocol. Pro vs current http solution: it does not requires https since ZeroNet protocol supports self-signed cert with pinning.

### ZeroID
The certificate request currently done by http (or bitmessage)

Possible solutions: Same as ZeroBoard minus drop the site

### boot.zeronet.io tracker
This one also affected by the IP ban. The other trackers and (and the .onion one ofc) are not affected.

Possible solutions:
 - Move to different domain

Other sites not be affected (as long as you have compatible ID) Btw to do some experiments is there any cheap VPS provider behind GFW? (shared ip also fine) The client is hosted on github, so: https://github.com/HelloZeroNet/ZeroNet#how-to-join should work  Thanks for reporting, it's fixed in Rev3104: https://github.com/HelloZeroNet/ZeroNet/commit/a66b71fb9c328977cff594abf015297c19866c68  The ZeroNet client will automatically fill that for you. Just open the site in ZeroNet client, then sign it using the sidebar.  Right now the sites routing using the "?" character, eg.:
http://127.0.0.1:43110/me.zeronetwork.bit/?Post/12h51ug6CcntU2aiBjhP8Ns2e5VypbWWtv/12gAes6NzDS9E2q6Q1UXrpUdbPS6nvuBPu/1507834329

Probably I would avoid complex routing rules in the client, but adding a default page for non-existent urls would be a good idea and you could also use it to parse the page url and route using javascript.  There was a mistake with directory casing. I suspect there is two `plugin/Bigfile` directory for you with different casing. Please delete the BigFile one and keep the Bigfile directory  Whats your site address?
Does visting other sites like http://127.0.0.1:43110/Blog.ZeroNetwork.bit/ works?  There is no REST API, but ZeroNet using Websocket for API requests/responses/events. Here is a simple example using [websocket-client](https://pypi.python.org/pypi/websocket-client/):

```python
import urllib2
import re
import json
import time

import websocket

req = urllib2.Request("http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/", headers={"Accept" : "text/html"})
wrapper_body = urllib2.urlopen(req).read()
wrapper_key = re.search('wrapper_key = "(.*?)"', wrapper_body).group(1)

ws = websocket.create_connection("ws://127.0.0.1:43110/Websocket?wrapper_key=%s" % wrapper_key)
ws.send(json.dumps({"cmd":"siteInfo","params":{},"id":1000001}))
res = ws.recv()
print res
# {"to": 1000001, "cmd": "response", "result": {"tasks": 0, "size_limit": 10, "address": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", ...
``` You need a headless browser to do that, eg.: http://phantomjs.org/ I think PhantomJS is the easiest way, here is an example: https://github.com/HelloZeroNet/ZeroMail/blob/master/echobot/echobot.py  How many http://127.0.0.1:43110/Stats shows to you? (eg.: `Connections (69, total made: 360)`) Hmm that's weird
How much site you have in your client? 
How much time does it takes until it gets filled?
Have you modified any settings of your client? I have added a modification in Rev3229 that [should keep the connections under 512](https://github.com/HelloZeroNet/ZeroNet/commit/4afb6b3d9c1edb954dd74c4155a7ed8790ab82be) (by default) and it should [stop keeping open connections](https://github.com/HelloZeroNet/ZeroNet/commit/d44677e46f83d436012524498d2219128cc5067c) for sites that not modified in the last 7 days.
Please update and see if it's working better. Can you please send the log to tamas@zeronet.io ? @slrslr Thanks for the log I was able to spot and fix the [problem](https://github.com/HelloZeroNet/ZeroNet/commit/97d1d0d63b719777b0dabb47781dc1b4adce0504) in Rev3233 that broke the cleanup method.

Please update and see if it's works now. Thanks, I have added a new update to fix connection error with unknown characters: https://github.com/HelloZeroNet/ZeroNet/commit/6fb9c6ef05aa7578bd0529c4022657612bcaf9c8
Please update to Rev3234 and let me know if the problem still exists.  Thanks!  Thanks, fixed in https://github.com/HelloZeroNet/ZeroNet/commit/3030e00b218af0ab5a32df912608b2949e7f2470  Looks like the application was removed from file system. Do you have 'core/src/Ui/template/wrapper.html' file where you have unpacked your ZeroNet client?  Thanks for reporting, running it using `python2 zeronet.py` should work. (I just updated the readme)  is the `python zeronet.py --verbose peerPing boot.zeronet.io` says the same? peerPing only works on IP/Onion addresses  Please try remove `proxy_set_header Host "127.0.0.1:43110";` and start zeronet using `--ui_host zer0n.rocks`  I think the server info exposed to the websocket API should be different, because adding the client location on the fs could be privacy problem.  Thanks, looking great!  Actually siteDownload does update the site if it's already exists.  I think a getConfig action would be better that returns all the information at once. (json formatted)  For the record: It was fixed by https://github.com/HelloZeroNet/ZeroNet/commit/d3d748923287d2b4bf53fb93959c04a5531f9795

Thanks again for reporting!  Thanks, I heard about it, but it does not affects us in any way. It only affect users who manually installs the wrong packages similarly named as the non-malwared ones.  Thanks!  Have you tried access http://127.0.0.1:43110/ ? According to log it should work now  Thanks for reporting, fixed in: https://github.com/HelloZeroNet/ZeroNet/commit/bfd3d18a10e3cceddf88946dd4567e51acfd7200 @grez911 No probs, at least we know why is it necessary :)  can you please attach your content.json here? (or send to me: tamas@zeronet.io) Thanks for reporting, fixed in: https://github.com/HelloZeroNet/ZeroNet/commit/b584c586ecee3df0f1bb6890406771fc4213d04e  If possible please send the data/content.db file to me: tamas@zeronet.io
To make it work again please try to shut down zeronet, delete data/content.db and start again (it will take some time to re-index the content)  The problem is the Translate object is shared between users, so if you change it to someone, then it will change to everyone who currently connected via websocket. i'm not sure how would parametized translations (eg.: `Change it to {auth_type}/{auth_user_name}@{domain}` or `Content publish queued for {0:.0f} seconds.`) would work that way  I just tested and it does closes for me, but only if it's opened on startup. Maybe you had an incomplete shutdown before. So can you please try deleting the forward manually, then start/stop?  What does https://portchecker.co says for port 15441 for you?  I just tested it if it's changed:
With return: 
```
[16:19:09] Ui.UiServer 127.0.0.1 - - "GET http://zero/1HeLLo.../ HTTP/1.1" 200 16439 0.135000
```

With iter: 
```
[16:20:08] Ui.UiServer 127.0.0.1 - -"GET http://zero/1HeLLo.../ HTTP/1.1" 200 3001 0.000000
```
(win + chrome)

Maybe something with buffering, also not sure about the 3K vs 16K response size difference (the correct one is the 3001) Nice finding  Thanks!  We need .json files, because we can't sync .db files due multi-user sites. It would be possible to parse insert/update sql queries and magically also update the json file, but I try to avoid "magic" as much as possible. Actually you can do it in javascript, so it does not requires any modification in the client itself and by that brake the backward compatibility.  No, it's up to the OS, but we have to read/write lot's of small files and there is also a lots of random reads and writes because of the sqlite database.
The Torrent client's load is the exact opposite: Read large files sequentially.  Can you please specify the exact error message that you get? Is there any error in zeronet log/debug.log file?
you can try adding `proxy_read_timeout 1h; #for long live websocket connetion` to websocket connection settings
 'VerifyError: sites too large' happens if one of the sites you seeding is ran out of limit (you can increase it using the web interface)
'Ui UiServer : No user found' is trickier. Have you enabled the Multiuser plugin? Is there anything in data/users.json?  Thanks, I think it would be better to use object as return of the actionCheckport request, use config.homepage instead of fixed site address and i'm not sure if socket.connect_ex does not leaks real IP address in tor mode. Thanks!  Thanks for reporting fixed the permissions in Rev2187: https://github.com/HelloZeroNet/ZeroNet/commit/b1989ef02e1c438794ad5bbfde06f9e4474b7394  Because it's safe enough, requires less storage and on 64bit cpus faster, than sha256. (see: https://crypto.stackexchange.com/questions/3153/sha-256-vs-any-256-bits-of-sha-512-which-is-more-secure)  For public proxies it's recommended to enable the multiuser plugin (just rename plugins/disabled-Multiuser to plugins/Multiuser)
If you get invalid host error start it using `--ui_host 127.0.0.1 www.kittyseedbox.tk`
 Yes, sorry `--ui_host 127.0.0.1:43110 www.kittyseedbox.tk:43110`  There is rate limit on content.json updates on same file (15sec) and the data.json file size is limited to each user.

I don't think if rate limiting of post inserts is solves any problem. 
What rate do you limit it to? Even 1 post/min could ban normal users and the spammer could easily send over 1000 post / day.
What if the user was offline for some hours and that time he posted some replies? What if you were offline?

I think this problem should be solved by the moderator of the site. Maybe with help of some automated "bot" to watch the updates and ban obviously spamming users.
Also a subscribeable, shared user ignore list feature (not implemented yet) would be a great help.
 I think most of the users would really hate it if they were unable to modify their post after they sent it.
It could be possible to add more limitation on rate on same file updates. eg. 100/hour (configurable by site owner)  Thanks!  Looks like something is bad with your Tor configuration. What does `echo 'PROTOCOLINFO' | nc 127.0.0.1 9051` and `sudo netstat -anp | grep tor` says?  Thanks for reporting, fixed!  If someone submits a translation for the ZeroHello/ZeroNet, then I automatically adding it to the list.  We don't use the affected functions and I would not touch external libs if not necessary  Thanks, I fixed it using the unpatched ssl lib: https://github.com/HelloZeroNet/ZeroNet/commit/b8d68e2589468fb6fe97d599b1a3a39e173a4214

`__import__("ssl")` and `import ssl` is not the same because of gevent monkey patching.  Yes, thanks!  Actually msgpack and gevent are the only requirements that you need to install. Py-stem only required by StemPort plugin which is optional and Tor works without it. It is tor-ready. The StemPort is just an alternative communication plugin if the built-in, raw socket based tor communication way does not works for you. Not all, only the pure-python ones. The ones that requires platform specific compilation is not included. (gevent, msgpack) Not sure about the differences, but there was reports that it's does not works under Whonix. I try to avoid external dependencies if possible. When I added full Tor support py-stem did not supported the required features (create ephemeral hidden service) and they only added it half year later.
Later this year the Tor project going to make major changes in hidden services. When it happens I'm going to see if we can change to py-stem or not.
Py-stem also depends on pycrypto binary package, so requires compilation on every platform which can be painful and result in portability issues.
  Yes, for example:
`Page.cmd("wrapperSetLocalStorage", {"any": value"})`
`Page.cmd("wrapperGetLocalStorage", [], function(res) { console.log(res) })`

More info:
https://zeronet.readthedocs.io/en/latest/site_development/zeroframe_api_reference/
https://github.com/HelloZeroNet/ZeroHello/blob/master/template-new/index.html  The self-owned site delete disabled on ZeroHello to avoid unintentional deletes. To delete your own site please use this way: click on site, open sidebar, click delete site  When I reinstall ZeroNet or change to other system environment, are there any solutions to restore my ZeroNet files without signing up for a new account?

I searched a lot from the net, most say the easiest way is to backup my "user.json" file. Sadly, I'm using macos system now, having no idea to find this file. Would you please tell me how to find this file in macos.

Thanks so much.
 I have added a new "Show data directory" menuitem to ZeroHello that should open the directory in the finder. Please verify if its working (to make it work you need to update your client by Version 0.5.7... menu item) thanks  Thanks for reporting, fixed in latest version. (you have to download ZeroNet.app again from zeronet.io homepage)
You may need to define the data directory manually as by default it creates it right next to ZeroNet.app. Example.: `MacOS zeronet$ ./ZeroNet --data_dir "/Users/zeronet/Library/Application Support/ZeroNet/data" siteCreate`
  Thanks for reporting, fixed in latest version. (you have to download ZeroNet.app again from zeronet.io homepage)
You may need to define the data directory manually as by default it creates it right next to ZeroNet.app. Example.: `MacOS zeronet$ ./ZeroNet --data_dir "/Users/zeronet/Library/Application Support/ZeroNet/data" siteCreate`
  You have to use the fileGet api call instead of fetch api to load files The Cors permission is to request read permission to an another site's content.

Here is a simple example on API usage:
https://github.com/HelloZeroNet/ZeroHello/blob/master/template-new/index.html
The command you need: `page.cmd("fileGet", "content.json", function(data) { console.log(data) })`
 @mkg20001 It's about sharing files between different sites (origins). Http header won't work in our situation, since the host is same for all sites. (usually 127.0.0.1) You can be right, I'm not sure what's that manifest.json file or what @cusmith1 tries to do exactly.  Please check your dbschema.json and content.json files regex patterns: https://zeronet.readthedocs.io/en/latest/site_development/content_json/#regular-expressions-limitations I have added the pattern itself to the log line: https://github.com/HelloZeroNet/ZeroNet/commit/f45ecb6cf4bf72bd77351cf90bde176b0203e8c7
This should make it easier to find the problem.  Unfortunately Ajax requests no longer works, you have to use the fileGet API call to do the same   Please try stop zeronet, delete data/content.db file, then start again (it will take some minute to regenerate the file) I tried to reproduce it, but I have no idea how "IntegrityError: FOREIGN KEY constraint failed" can happen on `DELETE` command as we have `ON DELETE CASCADE` on all foreign key definion. It can be problematic if you edited it without enabling the foreign key function by `PRAGMA foreign_keys = ON;`
I made this error non-fatal https://github.com/HelloZeroNet/ZeroNet/commit/ac230219eed41102b8442288a9f945f937e3bd44 and also fixed a bug that caused malfunction in the cleanup process.  (it did not worked well if it had more than one site to cleanup)https://github.com/HelloZeroNet/ZeroNet/commit/c96dce3d0b4c4fec11accc1fb0e6b3b7823abf4b  By default the users.json file is not updated when you using the multiuser plugin, so you have to login every time you start the client. You can change this behavior it by starting it using --multiuser_local argument. (Enable unsafe Ui functions and write users to disk)  Try this:
```
ui_restrict =
    192.168.1.2
    192.168.1.2
```  Try stop zeronet, delete data/content.db, then start again  If your site has merger permissions, then you can get the list of merged sites using mergerSiteList command, but you can't get the list of all seeded sites as it could be privacy issue.  Added in Rev2170 https://github.com/HelloZeroNet/ZeroNet/commit/4cd393e4d8f96f8fed0f4c629c55605d26b126e3
You can enable it using `--download_optional auto` (only applies to newly added sites)  Thanks for reporting fixed in https://github.com/HelloZeroNet/ZeroNet/commit/2aba9cc3c28a879d2ae9f5aa8d956b40be3bff7a
  ![blank](https://user-images.githubusercontent.com/18724949/28328374-f6a049b6-6c18-11e7-88ea-4cc19e1f1902.png)

![403](https://user-images.githubusercontent.com/18724949/28326190-a7d1a7fe-6c12-11e7-8d9f-f5c704c2acbc.png)

Seems Chrome works, but Firefox doesn't.

Request Header:
```
Host: fuckcf.cf
User-Agent: Mozilla/5.0 (Android 6.0.1; Mobile; rv:54.0) Gecko/54.0 Firefox/54.0
Accept: text/css,*/*;q=0.1
Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3
Accept-Encoding: gzip, deflate, br
Referer: https://fuckcf.cf/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/?wrapper_nonce=1960e8886cff195cac99ddadcb6498a02cedc5a63ac59acceca2b015e92de897
Cookie: master_address=1FEJw6Xn4PJTtLrnrdLDUZwqkQXuD38nuW
DNT: 1
Connection: keep-alive
```
Debug info:
```
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/css,*/*;q=0.1", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate, br", 
    "HTTP_ACCEPT_LANGUAGE": "zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3", 
    "HTTP_DNT": "1", 
    "HTTP_HOST": "fuckcf.cf", 
    "HTTP_REFERER": "https://fuckcf.cf/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/?wrapper_nonce=49e24c8c3fba09d690cdc074becbe970ca4379e9ccfb66294dba53e3bb0963b1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Android 6.0.1; Mobile; rv:54.0) Gecko/54.0 Firefox/54.0", 
    "HTTP_X_FORWARDED_FOR": "39.188.130.230", 
    "HTTP_X_FORWARDED_PROTO": "https", 
    "HTTP_X_REAL_IP": "39.188.130.230", 
    "PATH_INFO": "/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/css/all.css", 
    "QUERY_STRING": "", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "41652", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "localhost", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.0 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bind": null, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": null, 
        "config_file": "zeronet.conf", 
        "connected_limit": 8, 
        "data_dir": "data", 
        "db_mode": "speed", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "end": true, 
        "file_size_limit": 10, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "fix_float_decimals": false, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "ip_local": [
            "127.0.0.1"
        ], 
        "keep_ssl_cert": false, 
        "language": "zh", 
        "log_dir": "log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": true, 
        "multiuser_local": false, 
        "multiuser_no_new_sites": false, 
        "open_browser": null, 
        "optional_limit": "12", 
        "proxy": null, 
        "silent": false, 
        "size_limit": 10, 
        "stack_size": null, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_hs_limit": 10, 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.opentrackr.org:1337/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_host": [
            "fuckcf.cf"
        ], 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "updatesite": "1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp", 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false, 
        "workers": 5
    }, 
    "plugins": [
        "AnnounceZero", 
        "CryptMessage", 
        "FilePack", 
        "MergerSite", 
        "Multiuser", 
        "Mute", 
        "Newsfeed", 
        "OptionalManager", 
        "PeerDb", 
        "Sidebar", 
        "Stats", 
        "TranslateSite", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.0.2", 
    "version_python": "2.7.11 |Continuum Analytics, Inc.| (default, Dec  6 2015, 18:08:32) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]", 
    "version_zeronet": "0.5.6 r2156", 
    "wsgi.url_scheme": "http"
``` Thanks, fixed in https://github.com/HelloZeroNet/ZeroNet/commit/1f7b25b60c47af1c7dc5a6eb5b3e9c62269a43a3  It happens, because you have `"version": 4,` in dbschema.json, but only 1-2-3 supported.
Also you should change `"optional": "(data/users)",` to `"ignore": "(data/users)",`  Thanks!  Thanks!  Two possible solution:
 - Add a command set similar to merger site command, but only for read access and instead of get access to site types you requesting access to specific address.
- Add an option to site's content.json that allow cross-site file access. I have added a cors plugin: https://github.com/HelloZeroNet/ZeroNet/commit/cbac57dc8824a9dff4a79dcfab008bebe5cddf6f

To request permission to other site you have to execute `Page.cmd("corsPermission", "anysiteaddress")`
If the site is not in the user's client yet, then it will add it.
After that you can access the site's resources using `cors-siteaddress/anyfile.json` (via http request or fileGet api command)

I hope it covers your usecases.
  Thanks for reporting fixed in Rev2156 https://github.com/HelloZeroNet/ZeroNet/commit/a0d85d7d8393805290a0dd203733c61471ea4a26

It happened if you have not seeded the requested site before.  Option to force encryption for every connection.  can you please help me find the error in the docs? (i see msgpack-python everyone)

  There is a bit more peer than usual, but I don't see any suspicious thing.
The peer number is just an estimation. If you running your client for longer time you will see more due peer exchange. Also, more  frequently updated sites = more connections = more peer exchange = more peers.

It's an opensource protocol/app, so you can't do much about making custom modifications, but I don't see any problem with that. If someone does not have spare bandwidth to seed sites, then he/she can use a proxy or simply put it on paused state.

Publishing to 4 peers should be fine.
 Im not at home right now, i will check it next month if its still an issue I still have not found any suspicious activity and the updates reached my remote clients correctly.
But I made some changes that pushes the incoming updates to more peers. (6 instead of 4)
We can make it even higher, but unfortunately there is no way to make sure that every update is reaches every node.
 The per-site connection target can be overwritten using `--connected_limit` (by default it's 8)
In my experiences it should be enough in most situation.
I will monitor the "each time connecting the same nodes." problem.  Thanks, but I can't apply because i'm not an US citizen, have no experience designing hw/circuits and for me it seems they looking for a solution that allows you to browse the current internet.  The fileGet command only works within the same site (or between merged sites). The cross-site loading is not allowed for privacy reasons, because it would allow the site to list the other sites that is added to the user's client.  It's a bit hacky, we have no separate command to redirect to other page, so it using the notification to do that. 
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/UiWebsocket.py#L818
  Probably more like a feature of iframe sandboxing, but as a workaround it works this way:
```js
function createWebworker() {
	// via http://www.html5rocks.com/en/tutorials/workers/basics/#toc-inlineworkers
	var blob = new Blob([
	    "onmessage = function(e) { postMessage('msg from worker'); }"]);

	var blobURL = window.URL.createObjectURL(blob);
	console.log(blobURL)

	var worker = new Worker(blobURL);
	worker.onmessage = function(e) {
		document.getElementById('webworker_result').textContent = event.data;
	};
	worker.postMessage("hello");
}
``` web worker is not same as service worker.
Web worker: Script runs in separate thread, but it's closed when you leave the site.
Service worker: Keep running when you close the site  maybe you have multiple python installed on your computer and the pip command points to an another.
try `python -m pip install gevent msgpack-python`
you can verify the installation by entering `python` then `import gevent` to run command-line actions under windows you can also use `lib\zeronet.cmd`. (it using the bundled python, so you don't have to install it separately)
If you don't have python added to your path, then `C:\Python27\python.exe -m pip install gevent msgpack` should work.
Python2 and Python3 is not compatible with each other, so porting it would require more work. Moving to py3 planned later. (probably next year) try install msgpack-python & run it using C:\Python27\python.exe zeronet.py
 the latest 2.7.x can you please help me find the error in the docs? (i see msgpack-python everyone)  Right now only files matching `"^[a-zA-Z0-9_@=\.\+\-/]+$` supported. It could be possible to add more characters.

 Filenames `^[a-z\[\]\(\) A-Z0-9_@=\.\+-/]*$` allowed now: https://github.com/HelloZeroNet/ZeroNet/commit/96a097e33df3d24aa261bd41cf4f3a8ec5cf95ae  Thanks for reporting, I think I was able to fix this issue by https://github.com/HelloZeroNet/ZeroNet/commit/c8f37674c6f3c324614e77f66227b65a36545f54
Please verify if this fix worked for you. Sorry, added!  for me:
```
$ wget https://github.com/HelloZeroNet/ZeroNet/archive/master.tar.gz
--2017-07-07 20:25:58--  https://github.com/HelloZeroNet/ZeroNet/archive/master.tar.gz
Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112
Connecting to github.com (github.com)|192.30.253.113|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://codeload.github.com/HelloZeroNet/ZeroNet/tar.gz/master [following]
--2017-07-07 20:25:58--  https://codeload.github.com/HelloZeroNet/ZeroNet/tar.gz/master
Resolving codeload.github.com (codeload.github.com)... 192.30.253.120, 192.30.253.121
Connecting to codeload.github.com (codeload.github.com)|192.30.253.120|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 2483340 (2.4M) [application/x-gzip]
Saving to: â€˜master.tar.gzâ€™

master.tar.gz                     100%[=============================================================>]   2.37M  3.00MB/s   in 0.8s

2017-07-07 20:26:00 (3.00 MB/s) - â€˜master.tar.gzâ€™ saved [2483340/2483340]
         
$ ls
master.tar.gz

```  You have to push "Tor: Available" button on ZeroHello, then select "Use tor for every connection"  If you place ZeroNet.app in application directory then ./Library/Application Support/ZeroNet/data
If you running it from other directory, then it saves the data in the same directory as ZeroNet.app  Yes, looks like it's github issue. It returns not found also for the example in the official document:
https://developer.github.com/v3/repos/releases/#list-releases-for-a-repository
https://api.github.com/repos/octocat/Hello-World/releases/1
 Update: https://api.github.com/repos/HelloZeroNet/ZeroNet-kivy/releases still works, changed & fixed!  The wrapper is required because all sites served from same domain (127.0.0.1 normally) and without it would would allow cross site scripting.
If you want to read the raw files I recommend directly open it from file system. If you want to render the site I recommend using PhantomJS (http://phantomjs.org/) than can also render javascript based ZeroNet sites.  Thanks!
Updated from: https://indy.fulgan.com/SSL/
(I see ~5% improvement in benchmarks)  Thanks for reporting, just fixed it, it contained an invalid zeronet.py file.
To fix it manually please overwrite the `core/zeronet.py` file with this: https://raw.githubusercontent.com/HelloZeroNet/ZeroNet/master/zeronet.py   Various file systems/applications could have problems with utf8 file names in url/fs. If you really need special characters I recommend using the archive feature that support utf8 filenames:
http://127.0.0.1:43110/blog.zeronetwork.bit/?Post:105:New+version+0.5.3  None if these are easy solutions:
 - Pyre: Binary module
 - Timeout: It's only working under Unix
 - Shell-like syntax: Basically breaking all current sites.

So I think Timeout is the only possible solution, but in that case probably we need to run the regex code in separate thread or process. Unfortunately looks like python can't interrupt re.match running in separate thread:
```python
import sys, re
import threading
import time
import thread
import gevent
import gevent.monkey

gevent.monkey.patch_all(thread=False)


# via https://gist.github.com/aaronchall/6331661fe0185c30a0b4
def quit_function(fn_name):
    thread.interrupt_main()

def exit_after(s):
    def outer(fn):
        def inner(*args, **kwargs):
            timer = threading.Timer(s, quit_function, args=[fn.__name__])
            timer.start()
            try:
                result = fn(*args, **kwargs)
            finally:
                timer.cancel()
            return result
        return inner
    return outer



@exit_after(0.01)
def whileTimeout():
    i = 0
    while 1:
        i += 1
s = time.time()
try:
    whileTimeout()
except KeyboardInterrupt, err:
    print "KeyboardInterrupt"
print "whileTimeout", time.time() -s


@exit_after(0.01)
def matchTimeout(pattern, s):
    return re.match(pattern, s)

s = time.time()
matchTimeout("^A(B|C+)+D$", "ACCCCCCCCCCCCCCCCCCCCCCCCX")
print "matchTimeout", time.time() -s
```

```
KeyboardInterrupt
whileTimeout 0.010999917984
matchTimeout 1.40499997139
``` At this point the the simplest solution that comes to my mind that does not have any backward compatibility issue is sanitize the patterns: only allow repetition of any character, so enforcing the `.` before the characters `*`, `+`, `{`. 
I think this should not affect any current use cases and would protect from evil patterns. (maybe we should also limit the patterns to 255 char)

Affected parts:
 - dbschema.json: matching maps to load to sqlite database. Executed after every downloaded file, so performance on this is critical
 - content.json: ignore, optional patterns. Less critical, because it's only executed on signing

 Added in rev2153  This usually caused by suddenly disappearing peers. I just fixed the unhandled exceptions and it should show more proper messages now.   Nice to hear! :)
I have added the handshake and the missing network commands to documentation: https://zeronet.readthedocs.io/en/latest/help_zeronet/network_protocol/  ZeroNet add a ui_host restriction in a recent update, if `ui_ip` is not `127.0.0.1`, ZeroNet will also add the first http request's host to the allowed host list.
In actual use, set `ui_ip = * ` to allow users access on internet is not suitable, we need a reverse proxy to set HTTPS and gzip compression and don't allow access ZeroNet directly. It causes ZeroNet won't learn allowed host.
We can set `ui_host` by command line and edit `zeronet.conf`, but it seems can't set multi value in `zeronet.conf`. What's the error message when you try to access the ui interface and what host it added by the first request? (please search for "as allowed host" in log/debug.log)


This format should work in zeronet.conf
```
ui_host =
 host1
 host2
```  What browser are you using right now? Have you tried in another one? (FF/Chrome)  Thanks!  Can you please add more details on reproducing it?
I just tried and this works for me (cloned zerosites, modified data/users/content.json to this, then added a new site):
```json
...
 "user_contents": {
  "cert_signers": {
   "zeroid.bit": ["1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz"]
  },
  "permission_rules": {
   ".*": {
    "files_allowed": "data.json",
    "max_size": 0,
    "signers": []
   },
   "bitid/.*@zeroid.bit": {"max_size": 20000}
  },
  "permissions": {
   "nofish@zeroid.bit": {"max_size": 200000}
  }
 }
...
``` Thanks I was able to reproduce the problem.
It's happening because when you using the sidebar to sign the content it executes:
`wrapper.ws.cmd("siteSign", {"privatekey":"stored","inner_path":"data/users/1J3rJ8ecnwH2EPYa6MrgZttBNc61ACFiCj/content.json"})`
So it's using the site's private key and not the user's. In that case it does not adds user details to the content.json. Executing `wrapper.ws.cmd("siteSign", {"inner_path":"data/users/1J3rJ8ecnwH2EPYa6MrgZttBNc61ACFiCj/content.json"})` command does works.
  Thanks!  Unfortunetly I think we can't avoid it... `A` has to send the content.json directly to `B` before it can publish to other peers.
  Thanks! 
I try to avoid external dependencies if possible and was able to fix this issue: https://github.com/HelloZeroNet/ZeroNet/commit/1f83b6691b7864a35c1466ee23a14628f28ec974  Looks like your data/sites.json file is broken at line 4886 (character 20)

If you have data/sites.json-tmpold or data/sites.json-tmpnew file, then after you shut down your ZeroNet client you can try to overwrite with it  Can you check the javasript console for errors (F12)?
And please try in incognito mode (plugins disabled there) It looks weird, something with the directories, please try to open sidebar (drag topright button to left) and press Rebuild.
I will try to reproduce this error. Everything is stored in data folder, so you can do this:
 - Stop ZeroNet client
 - Rename data to data-old
 - Start ZeroNet client again and try to visit sites that you had problems before

If it's got fixed, then you can try to rename back your data directory and move data/content.db to data/content.db-old to re-generate that cache file. Can you please send me (tamas@zeronet.io) or attach your data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/data/zeroblog.db file? Thanks, but unfortunetly it's empty, can you please also send the .db from 1Talk... directory? Thanks, I was able to reproduce and fix it latest rev2105. Please update and press "Rebuild" button on sidebar.  You can improve the tranlation by editing es.json files located in site's translate directory and in the client's src/Translate/languages/
plugins/MergerSite/languages
plugins/Mute/languages
plugins/OptionalManager/languages
plugins/Sidebar/languages
plugins/Trayicon/languages
directories

Thanks!  ZeroNet added file_size_limit recently.
When some developers try to add big files to their sites, the files will be denied without a notification.
Then developers will find the reason why clients don't download files hard, so add a notification to tell the reason is a simple way.  Some people in China needs access blocked sites via a proxy. But if you set a system proxy, ZeroNet will connect to other peers via proxy. Some proxy's bandwidth is limited and can't open a FileServer port, so we need a argument to disable proxy. What application are you using to set the system proxy address?  Is it possible to install ZeroNet to a remote machine?

Yes, you have to enable the UiPassword plugin by renaming the plugins/disabled-UiPassword directory to plugins/UiPassword, then start ZeroNet on the remote machine using 
`zeronet.py --ui_ip "*" --ui_password anypassword`. This will bind the ZeroNet UI webserver to all interfaces, but to keep it secure you can only access it by entering the given password.

Tip: You can also restrict the interface based on ip address by using --ui_restrict ip1 ip2.
Tip: You can specify the password in config file by creating a zeronet.conf file and add [global],  ui_password = anypassword lines to it.

via https://zeronet.readthedocs.io/en/latest/faq/#is-it-possible-to-install-zeronet-to-a-remote-machine  The problem is if you want dynamic sites, then have to deploy and run the site logic in some way. 
It could be possible to write a non-javascript cilent in python/java/php/etc, but javascript offers the best and most battle tested sandboxing enviroment. ZeroNet running content in sandboxed iframe that allows the content to be treated as being from the same origin.
https://www.w3schools.com/tags/att_iframe_sandbox.asp > Is there a particular reason why the src attribute of the inner iframe is assigned by Javascript code?

Without it the back button does not works, because the browser restores the old iframe url (at least in chrome) with expired nonce even if the wrapper html reloaded due no-cache header.

My ideas on JS-less mode:
Add support for `/raw/siteaddress/any.html` where the files are served without wrapper, but disabled js using Content Security Policy

Adding SSH tunnel to documentation would be a good idea and we could also enable the UiPassword plugin by default if someone start it with --ui_ip "*"  - Should we use keep the wrapper and use iframe sandbox argument to disallow JS or use Content Security Policy headers and render it without wrapper?
 - Should we check and care about browsers that does not support Content Security Policy? (IE9)

 It's landed in Rev2137 (with some fixes in 2141 & 2144) using the /raw/ prefix. Eg.: http://127.0.0.1:43110/raw/1AsRLpuRxr3pb9p3TKoMXPSWHzh6i7fMGi/en.tar.gz/index.html

It will serve the files without any wrapper, but adding `Content-Security-Policy: default-src 'none'; sandbox allow-top-navigation; img-src 'self'; font-src 'self'; media-src 'self'; style-src 'self' 'unsafe-inline';` header.
  right now only files matching `^[a-zA-Z0-9_@=\.\+-/]*$` hashed by zeronet. It should work, can you please check the `log/debug.log` after the signing? (btw the files should match `"^[a-zA-Z0-9_@=\.\+\-/]+$"`, so white space is not allowed yet) Since 0.6.0 space character allowed in filename.  you can use the same ones as arguments. To list it and get help use `zeronet.py --help`  Network administrator can block ZeroNet by blocking TCP 15441 port's inboard and outboard. Single user can set another inboard port, but it's impossible to change others inboard port, then the user whois TCP 15441 port is blocked can only connect to the peers whois FileServer port is changed.
If ZeroNet assign a fileserver_port at every start, it will cause trouble to the users who need forward port manually, but assigning a random file_server at first start then use this port in future won't bring extra trouble.
And perhaps we can recommend users using port 80 and 443, it helps some user whois network have a whitelist firewall connect to ZeroNet.
Another user create a issue 1 year ago. (#392)  Thanks for reporting, you are right the sys module was missing. 
The ssl module wasn't used, changed the variable name to avoid confusion and added other improvements:
https://github.com/HelloZeroNet/ZeroNet/commit/e291555e604f9db1a273a39db40642aca5a3e45a#diff-8483a7f5b31679cec82cabfd6c3a7c2d  Thanks for reporting, fixed in Rev2091  Yeah, forgot this one, sorry! Thanks! :)  For some reasons it's not compatible with python's tarfile module, but after extracting it and repacking works for me.
What application you used for packing?

```
$ python -c "import tarfile; tarfile.open('ZeroNet.tar.gz').list()"
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/lib/python2.7/tarfile.py", line 1665, in open
    raise ReadError("file could not be opened successfully")
tarfile.ReadError: file could not be opened successfully
$ tar xvpfz ZeroNet.tar.gz
...
tar: ZeroNet/atom.xml: implausibly old time stamp 1970-01-01 00:00:00 
$ tar -zcvf ZeroNet-new.tar.gz ZeroNet
$ python -c "import tarfile; tarfile.open('ZeroNet-new.tar.gz').list()"   
-rwxrwxrwx root/root       1886 2017-05-25 17:33:52 ZeroNet/refs.html
... I haven't modified anything, probably it was related to the invalid timestamp  Yes, using Tor  Thanks, fixed!
https://github.com/HelloZeroNet/ZeroNet/commit/ed11ae283fc28f98d870602af7b0a6aba5bde277  Master needs a master_seed in `users.json` to manage a public proxy, if master deletes `users.json` for some reason, ZeroNet will create a new `users.json` which is only contains `{}`.  It's intentional, I don't see any problems with it, but you can disable it by adding `"max_size_optional": 0` to permission_rules / ".*" in `data/users/content.json`

I have changed ä¸»è«–å£‡ and ä¸»è®ºå› to English, but I don't think it's going to change anything since there is already a "Please use English, you can reach other language forums at the top of this page" warning at new topic creation.

@l5h5t7: I have added  --file_size_limit option in latest revision.  Thanks!  Are you running ZeroNet in debug mode?
Have you modified any default running parameters? (eg. using zeronet.conf) Thanks for reporting, fixed in latest rev: https://github.com/HelloZeroNet/ZeroNet/commit/1f83b6691b7864a35c1466ee23a14628f28ec974  Thanks, just tagged: https://github.com/HelloZeroNet/ZeroNet/releases/tag/v0.5.5
I usually wait some days for feedbacks/possible bugs before the tagging.   Thanks, some things:
 - Removal of `self.cmd("error", "Internal error: %s" % Debug.formatException(err, "html"))` would make the error finding more difficult, so maybe we could show it depending on `if "Multiuser" in PluginManager.plugin_manager.plugin_names:`
 - Instead of print it would be better to use `logging.warning`
 - Name `sendHomepageNotes` to `sendHomepageNotifications` to be more clear? Thanks!
Added logging for ws.receive() errors: https://github.com/HelloZeroNet/ZeroNet/commit/79005780772350db31042747749b129132f941dd  This is especially problem on mobile phones where the file system chunk size is high (32k), so it takes up lot more (up to 10times) space.
To solve this problem I planning to add site archiving method that stores moves the older user content to a zip/tar.gz archive, so it would dramatically reduce the file numbers, initial sync time and could solve scalability problems (older content archives can be marked as optional files)  Thanks  You can test it manually on http://canyouseeme.org/
if the result is negative, then probably your ISP is blocking it.  Thx, done: https://github.com/HelloZeroNet/ZeroNet/commit/f9c0c217145846a50c8299dada1e6df7380bb404  Unfortunetly ZeroMail does not works well with large ammount (1000+) of contacts and because of that the echo bot does not works properly.
I planning to fix it, but since its only affects the echo bot it's not a priority yet. I'm not sure what is error 111, can you give more info about the context please?  can i do this nowï¼Ÿ do i need my signature to sign in  you have to copy the data/users.json file to the other device.  for some reasons looks like your zeronet client does not have write permissions on data files:
```
with open(file_path, "wb") as file: 
IOError: [Errno 13] Permission denied: u'/data/.zeronet/1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz/data/users.json'
```  Can you please give more details on this? You can do by starting it using `zeronet.py --size_limit 50`  Thanks, fixed!  I think it happens if you move the .app after you started it, please try to stop it and start again  Thanks for reporting, im in Canada right now, but i will check it after i arrive back to Budapest, later this week ZeroNet provides API command for query optionally downloaded files, so it's pretty easy to "cookie" users based on that.
I don't see any easy solution for this problem other than delete your data dir every time you want to create a new identity. (and ofcourse use Tor browser)  Fixed in https://github.com/HelloZeroNet/ZeroNet/commit/34a6337c014f747fc28ea3022e1754fce852a277
If the url starts with `#` it won't add `?` anymore, but I recommend you to use `?` instead of `#` (eg. `page.cmd("wrapperReplaceState", [null, "", "?abc"]);`) as hashtags are originally for jumping to anchors on one page and using replace/pushState should not reload the page.  Unfortunately Nacl is not compatible with the crypto we use, pyopenssl does not have functions we need (eg aes encryption). Cryptography probably could work, but has binary dependencies and requires compilation to every platform/openssl version, which could reduce the portability.
Pyelliptic still has some support by the bitmessage project  This is intentionally: like @mishfit pointed out you have to call the wrapperReady api request, because if you have dynamic page you need to load resources to render the page before you can scroll to the anchor  Thanks for reporting, fixed in d346a532ffc2b9dcabca423ea84cd0c619e206f0  I will arrive back from Canada later this week, so I can check it then  Yeah, Thanks, I forgot about that. Updated: https://github.com/HelloZeroNet/ZeroNet/blob/master/CHANGELOG.md  simply run zeronet.py instead of start.py  here is the script I use: https://github.com/HelloZeroNet/ZeroBundle/blob/master/compile/compile_win.cmd

More specifically the `pyinstaller.exe zeronet_win.spec -y` command generates the exe.


but if you just want to run it, without the shipped .exe then:
 - Download https://www.python.org/ftp/python/2.7.13/python-2.7.13.msi
 - python -m pip install gevent msgpack
 - Run zeronet.py  i'm sure it's a false alarm, what can we do against it?  Well it's not easy to tell, you can try remove big sites like zeromail I have created an issue to restrict adding big sites: https://github.com/HelloZeroNet/ZeroNet/issues/907 I have added --file_size_limit defaults to 10MB: https://github.com/HelloZeroNet/ZeroNet/commit/aacde3361401f37f895ba2782e9d91ef464111fe
I hope it helps...  I tried to reproduce it: 
 - created a new zeroblog clone
 - published an user file
 - modified contentmanager sign method to remove cert signatures by adding:
```
        del new_content["cert_auth_type"]
        del new_content["cert_sign"]
        del new_content["cert_user_id"]
```
 - tried to sign & publish this file to remote machine, but it got rejected: `[2017-04-11 06:10:24,423] WARNING  Site:1NLjoF..qPa7 Verify sign error: KeyError: 'cert_user_id' in ContentManager.py line
797 > ContentManager.py line 640`

Running `zeronet.py siteVerify 1NLjo...` locally also drops error.

do you have other details how to reproduce it? There was an error that did not set the added certificate correctly. Fixed in latest rev: https://github.com/HelloZeroNet/ZeroNet/commit/1a7a22eb913865505db152037f579d18addf7b65

Now the cert selection is working for me, but the generated certificate drops "Wrong encoding" error.  (the signature should be 65 char long, but it generates 71 char long one)  Well i'm not sure if its a good idea, because it would encourages people to run many clients on the same machine an by that flood the network.  Great, thanks!   For some unknown reason most (70-80%) of the socket connection immediately fails with latest PySocks. It can be Tor socks server or gevent incompatibility.
```
[2017-04-08 22:04:42,749] DEBUG    FileServer Conn# 1 boot3rdez4rzn36x.onion [?] > Connecting...
[2017-04-08 22:04:42,749] DEBUG    TorManager Creating new Tor socket to boot3rdez4rzn36x.onion:15441
[2017-04-08 22:04:42,750] DEBUG    FileServer Conn# 2 boot.zeronet.io [?] > Connecting...
[2017-04-08 22:04:45,809] DEBUG    Site:1iD5ZQ..duGz Try to get listModifications from peers: [<Peer:x.x.x.x>, <Peer:xxx.xxx.xxx.xxx>, <Peer:x.x.x.x >, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x >, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x >, <Peer:x.x.x.x>, <Peer:x.x.x.x>], connected: 0, since: 1491577157.08
[2017-04-08 22:04:45,811] DEBUG    FileServer Conn# 3 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,812] DEBUG    FileServer Conn# 4 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,812] DEBUG    FileServer Conn# 5 x.x.x.x  [?] > Connecting...
[2017-04-08 22:04:45,815] DEBUG    FileServer Conn# 4 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,815] DEBUG    FileServer Conn# 6 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,815] DEBUG    FileServer Conn# 3 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,815] DEBUG    FileServer Conn# 7 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,816] DEBUG    FileServer Conn# 5 x.x.x.x  [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,818] DEBUG    FileServer Conn# 8 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,819] DEBUG    FileServer Conn# 6 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,819] DEBUG    FileServer Conn# 9 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,819] DEBUG    FileServer Conn# 7 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,819] DEBUG    FileServer Conn#10 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,821] DEBUG    FileServer Conn# 8 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,822] DEBUG    FileServer Conn#11 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,822] DEBUG    FileServer Conn# 9 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,825] DEBUG    FileServer Conn#12 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,828] DEBUG    Ui.UiServer x.x.x.x - - [2017-04-08 22:04:45] "GET http://zero/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/img/loading-circle.gif HTTP/1.1" 200 2643 0.002000
[2017-04-08 22:04:45,828] DEBUG    FileServer Conn#10 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,829] DEBUG    FileServer Conn#13 x.x.x.x  [?] > Connecting...
[2017-04-08 22:04:45,831] DEBUG    FileServer Conn#11 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,831] DEBUG    FileServer Conn#14 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,832] DEBUG    FileServer Conn#12 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,832] DEBUG    FileServer Conn#15 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,834] DEBUG    FileServer Conn#13 x.x.x.x  [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,835] DEBUG    FileServer Conn#16 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,835] DEBUG    FileServer Conn#14 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,835] DEBUG    FileServer Conn#17 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,835] DEBUG    FileServer Conn#15 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,836] DEBUG    FileServer Conn#18 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,838] DEBUG    FileServer Conn#16 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,838] DEBUG    FileServer Conn#19 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,838] DEBUG    FileServer Conn#18 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,838] DEBUG    FileServer Conn#20 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,841] DEBUG    FileServer Conn#17 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,842] DEBUG    FileServer Conn#21 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,854] DEBUG    FileServer Conn#20 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,855] DEBUG    FileServer Conn#22 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,855] DEBUG    FileServer Conn#19 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,857] DEBUG    FileServer Conn#23 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,858] DEBUG    FileServer Conn#21 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,858] DEBUG    FileServer Conn#24 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,859] DEBUG    FileServer Conn#24 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,861] DEBUG    FileServer Conn#25 x.x.x.x  [?] > Connecting...
[2017-04-08 22:04:45,861] DEBUG    FileServer Conn#23 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,861] DEBUG    FileServer Conn#26 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,861] DEBUG    FileServer Conn#22 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,861] DEBUG    FileServer Conn#27 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,864] DEBUG    FileServer Conn#25 x.x.x.x  [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,864] DEBUG    FileServer Conn#26 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,865] DEBUG    FileServer Conn#27 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,865] DEBUG    Site:1iD5ZQ..duGz Queried listModifications from: [] in 0.057s
[2017-04-08 22:04:45,973] DEBUG    Site:1TaLkF..jipT Signing 1491681886 for boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441 to add 6 onions
[2017-04-08 22:04:47,596] DEBUG    Site:1Gfey7..fcdp Announced types ['onion'] in mode startup to 5 trackers in 1.047s, errors: [], slow: ['1.05s http://tracker1.wasabii.com.tw:6969/announce']
```

Until we find solution for it I reverted back to old one

- [ ] Reproduce
- [ ] Fix Yes I suppose Yes, I planning to check it again.  yes, eg.: https://itunes.apple.com/us/app/pythonista/id528579881?mt=8
as for creating webserver on 127.0.0.1 i'm not sure...  Nice, thanks!  Adding selenium does not fixes it, because it also requires phantomjs and zeronet client running Thanks! Unfortunetly `docker run -d -v $PWD:/root/data -p 15441:15441 -p 127.0.0.1:43110:43110 nofish/zeronet` does not reflect the latest version (not to mention pull requests), so it makes the testing pointless. So we need other way to run the client.  Actually the back button is working for me in latest FF/Chrome/Edge. Maybe some plugin?  You added a simple page for it:
![image](https://cloud.githubusercontent.com/assets/10350359/24811203/4ec6b3ae-1bc5-11e7-95cd-f34b367a7061.png)
  You need to have ZeroNet client running on 127.0.0.1 to complete the tests  Currently due privacy reasons there is no way to list certificates, so I would recommend separate buttons for "create new identity" and "select identity"  Thanks for the heads-up I will update the libs. Using pip for dependencies would make the portable/exe/.app version really hard, that's why I decided to include them. Thanks for reporting, I have updated all of the libs to the latest version. 

The PyElliptic still has some updates via the BitMessage project: https://github.com/Bitmessage/PyBitmessage/tree/master/src/pyelliptic

The pyOpenSSL looks nice, but it has more dependencies and not pure-python, so I would stick with pyelliptic if possible.

I keep it open as I want to add automated way to update the libs to avoid the same problems in the future.  You can check the failed files on the sidebar. (please note files larger than 1MB not fully supported yet)
JS/CSS files are cached by the browser for 5 minutes, so for development: open Developers Tools (F12) then check Disable Cache on Network tab. (Chrome)  it works this way: `zeronet.py --trackers http://anything http://other --batch` (it should end with non-multivalue argument)  What operating system you using?  Yes, every user is also identified by valid bitcoin address (you can find your in data/users.json) For usernames you need to get a certificate from id provider. It's the provider resposibility to keep the usernames unique. The id provider only gives a signature to the user. (certs entry in your data/users.json) 
Actually after that you can even delete the id provider site.  you need 64bit openssl dlls for 64bit python  The plugins/Mute/languages/zh.json file has some merging junk left, pelase remove that file (and plugins/Mute/languages/zh-tw.json ) from commit  You are right it should be list, but acutally the multisig is disable atm. (https://github.com/MRoci/ZeroNet/blob/4a981e88ada8d26ef673639feb9d4db442818b9e/src/Content/ContentManager.py#L648) It would be a great addition, but needs more testing I think we can change it to list without supporting dict, since the multisig is not enabled yet, so there won't be any backward compatibility issue. Yeah change `valid_signers += self.contents["content.json"]["signers"].keys() 
` it simply to `valid_signers += self.contents["content.json"]["signers"][:] ` and I will accept it.  Thanks, fixed: d7ba9f6924f23266411edfda1e236f88ea318347  it was planned when I implemented the clone feature (that's why the "cloned_from" and "clone_root" data present in content.json), but I havent added this for the webui yet. It's definetly planned, but have to find a way to allow users to keep their customizations somehow It's added in 0.5.5  I don't speak german, but feel free to open a pullrequest. Thanks, fixed: https://github.com/HelloZeroNet/zeronet.io/commit/752d05210764a86dea98c380c664e8020c2de4fe  Thanks for reporting, fixed: https://github.com/HelloZeroNet/ZeroNet/commit/afcd6dfa14c2759ac12151a324e7051cea4fb38d  Probably you missing one of the required packages. Try run zeronet.py in terminal and see the error message. You have to enter `python zeronet.py`  Unfortunetly currently there is no way to do that. In the future it's planned to be able to request permission to another site's files and database, but ZeroMail messages are stored in encrypted form, so it's even more compliated.  Thanks, fixed!https://github.com/HelloZeroNet/ZeroNet/commit/50937990e54c9e4d4286c0f5407643ee8488be71  It's still under testing, it will be tagged later. You can always download the edge version from https://github.com/HelloZeroNet/ZeroNet/archive/master.zip  I think it would be better to not build this into ZeroNet client, but provide a cloneable site that take cares of the listing, so it would be possible to customize and enhance the listing.  Why is it necessary to send different port to the tracker and bind an another on the local machine? If you want to use different port, then you can use that on local machine. And how do we know the randomly assigned port number? The port checker can't get your external port as it not used in the connecting process (and you can have many of them), only your external ip.

It could be possible to add nat-pmp function for port opening, but I think upnp is more supported. I just tried https://pypi.python.org/pypi/NAT-PMP/1.0.1 and it's not working with my router. I don't have access enviroment like this, so it would be hard to develop for it.  I don't see it as a bug, why would anyone create a folder named any.tar.gz ?  I'm ok with this, but I think a `def actionFileList(self, to, inner_path, walk=True):` would be better, than a separate function  both port should be 15441. This is normal: Your internal and external IP is different.
- [find your computer's internal ip address](https://www.groovypost.com/howto/microsoft/windows-7/find-your-local-ip-address-windows-7-cmd/)
- Add new portforward: external/internal port both 15441, ip address your computer's internal ip
- Restart ZeroNet
- You should see Port: Opened It's hard to tell what's the problem, please try to enable uPnP on your router. On my TP-Link (TL-WR841N),
it's looks like this:
![image](https://cloud.githubusercontent.com/assets/10350359/23578367/676d1836-00d5-11e7-97ff-ad397a834ba3.png)
After you enabled it all you have to do is restart your ZeroNet client and it will open port for itself.

If it's not working,then please add a screenshot of the port forwarding page of your router's web interface.
  Thanks!  you can't but you can generate self-signed certs: https://github.com/HelloZeroNet/ZeroID/issues/3  ZeroNet download is multi threaded: 
 - Spawns 6 worker if you add new tasks
 - Try to assign 6 different task for these workers
 - If there is no 6 tasks, then it steals another worker's tasks, wait 1 sec to allow the current worker to finish it, if it's still not finished after 1 sec, then tries to download the same file in parallel.

The fileGet api command was not executed parallel, but it's fixed some weeks ago: https://github.com/HelloZeroNet/ZeroNet/issues/788  If stem using socket lib that is not ready for gevent, then it will not work It was temporary problem, re-running fixed it.  If you drag the zero button to left it shows what files missing from current site I have just added .tar.gz, .tar.bz2, .zip support in latest rev: 2854e20
example site: http://127.0.0.1:43110/1AsRLpuRxr3pb9p3TKoMXPSWHzh6i7fMGi/en.tar.bz2/index.html (please update your client before visit)

en dir uncompressed: 6.1MB, zipped: 1.5MB, tar.gz: 512KB, bz2: 247KB (!)
content.json size also greatly reduced 

I think this could help you in many cases:
- Javascript files compression rate is pretty good (3-5x)
- It also help to reduce content.json size, because the packed file is only takes up one entry
  Thanks, but I think it would be better as separate plugin, so you can avoid lots of ifs and does not makes the core source code more complicated. (it's easy check DonationMessage for example)

you can add to plugin's __init__.py like this:
```
try:
    import from stem.control import Controller 
    import StemPlugin
except:
   pass
```

and then easily override connect/addOnion/etc methods of TorController in StemPlugin.py Probably this is what needs to be modified: https://github.com/HelloZeroNet/ZeroNet/blob/master/src/util/SocksProxy.py#L6  probably it possible, but that part is pretty fragile: lots of different platforms with different version of python, gevent and openssl. I had really hard time to make it work on most of enviroment.

So any mondifiction there needs lots of testing.  Please update the latest version, it will fix it.  I just tested in firefox and chrome and both supports localstorage in private browsing, they just cleans it up after you close the window:

```
> localStorage.setItem("hello", "aha")
> localStorage.getItem("hello")
< "aha"
```

Probably some browser plugin block it for you  the easiest way currently is: 
stop it, run `python update.py`, start again Then you have: 
 - disable the Multiuser plugin
 - start it
 - update using the menu 
 - stop
 - enable Multiuser plugin again
 - start again

I will fix standalone update.py running and add a simpler method to update the proxy I just made it easy: From Rev1892 if you login with any user's master_seed from data/users.json, then you will have no restriction. So you can delete sites, update zeronet, etc.

It also have security enhancements, so the update is recommended.

Other modification is if you enable --multiuser_no_new_sites, then normal users will not able to add new sites (users in data/users.json still can)  I just made it easy: From Rev1892 if you login with any user's master_seed from data/users.json, then you will have no restriction. So you can delete sites, update zeronet, etc.

It also have security enhancements, so the update is recommended.

Other modification is if you enable --multiuser_no_new_sites, then normal users will not able to add new sites (users in data/users.json still can)  Thanks!  å™—ã€‚ã€‚é‡äº†ï¼Œå»ºè®®åŒæ­¥åŠ ä¸Šzh-tw  I have just tried and unable to reproduce it.

Same 53.0a2, "I have just tried and unable to reproduce it" checked in settings. Have you changed anything else?
  Have you moved the zeronet directory to anywhere?
If the 'core/src/Ui/template/wrapper.html' file still there?
Have you tried to restart it?  Ajax requests also failing in that environment  I was able to reproduce it and working on fix Fixed in latest rev: https://github.com/HelloZeroNet/ZeroNet/commit/f74e9397db20336835a72220321480328f4de477  This is expected and can't be fixed, because it's using the pythonw.exe which has no console.

You can use the lib\ZeroNet.cmd file if you need the console.  If you call the "innerLoaded" command, then it will got applied to your page:

https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/media/Wrapper.coffee#L104

(looks like I forgot to add it to docs, I will do) Added to docs  Sorry I don't understand what you try to say. What you mean by re-up and changes get ignored? What information you want to reset?  Drop off the net?  Probably your site is too large, you should keep it under 10MB to make it to every client.  `ls -al /proc/5988/cwd`  probably points to ~/.local/bin/ZeroNet and your site is created in ~/.local/bin/ZeroNet/data directory

  I think a general timeout (eg. 1 day) would be more usefull if the client unable to download an optional file for 1 day, then automatically gives up If you remove the optional files from your site (it's no longer in content.json), then it will immedietly disappears.

The timeout is not implemented yet, but it's for files that is still in content.json, but there is no peers for it.  yeah, the start.py is zeronet.py with browser opening  You can configure it using:   `--fileserver_ip ip    FileServer bind address (default: *)` It should be fixed by https://github.com/HelloZeroNet/ZeroNet/commit/d57d82f4398995389c390f344ee093027ff08d6b (also added other modifications to allow local addresses other than 127.0.0.1)  I don't think waiting is necessary, it would add +1 request to tracker after you visit the site: one for getting other's ips/onions and one for registering  I'm running it with gevent 1.2:
```
>>> gevent.version_info
gevent.version_info((1, 2, 0, 'final', 1))
```
Please make sure you have the latest version of zeronet

related commit: https://github.com/HelloZeroNet/ZeroNet/commit/9a1735f37dfc7f9a2f734783f38ca5c8a4e9cbc3  I see the problem, but whats the point adding it to the response? (the file shasum always checked after the download) 

I think all we need to do is add it to request to avoid the unnecessary downloads.  ZeroNet is single threaded, event-based, it means IO-related tasks (file/socket read/write) will execute concurrently, CPU-bound things (eg. signing a file, crypto-functions, database query) will block the application. 

I have tried to move this CPU-heavy functions to separate thread, but without any success. I have not given up on it, I will try it again later.

Currently one websocket connection can only execute one command at a time. So yes, the fileget will block it. It would be a good idea execute that async, I will check it later today. fileGet should be async now: https://github.com/HelloZeroNet/ZeroNet/commit/bf34d95bc121005fd82f07308dedf71c9be21773
base64 encoding and timeout also added: https://github.com/HelloZeroNet/ZeroNet/commit/54c553d13bbc2c01d1d69ab020592c29d180fa08  the site not signed properly, so cant download but this is normal: your site is avalible from  http://127.0.0.1:43110/chomping-at-the.bit/, so loading  http://127.0.0.1:43110/assets/anything won't work.

this should help: http://ricostacruz.com/til/relative-paths-in-jekyll  I can't test it, but thanks!  ref http://127.0.0.1:43110/17vUgpdVUpN4yWeMJJtid7AAeQfLahHtXH/?Post:3:How+to+run+ZeroNet+on+your+router

Running ZeroNet on the router can reduce carbon emissions, and as long as the router is not closed the entire LAN can be quick and easy access, the following, I will introduce how to run ZeroNet on the router.

![1484830875.jpg (1064x857)](http://127.0.0.1:43110/17vUgpdVUpN4yWeMJJtid7AAeQfLahHtXH/data/img/post_1_1484830875.jpg)

First of all, check whether your router install Padavan firmware and plug-in storage, if not, maybe it will not work.
(PS: if your router can not plug-in storage, maybe you can't run it.)

* * *

After that, ssh to router and execute the following command

```shell
opkg update && opkg install wget python-pip python-gevent python-greenlet tmux
```

Update and install these software, cd to your router's external storage, my hard drive on the router's directory is /media/AiDisk_a5, if you don't know where is your plug-in storge can be `df` command to view, /media directory that is.

`cd /media/AiDisk_a5`
Then, let's download ZeroNet:
`wget https://github.com/HelloZeroNet/ZeroNet/archive/master.zip`
Decompression:

`unzip master.zip`

Open the file manager, access \\\\[your_router_ip] (such as I was \\\\192.168.123.1) and then open inside the AiDisk_ax folder (x on behalf of your hard drive number, such as my AiDisk_a5), you can see just downloaded master. Zip and unzipped the ZeroNet-master folder underneath. Then rename the ZeroNet-master folder to ZeroNet, enter the folder, then open the zeronet.py file with npp or other editor, and add the following two lines under `import sys` and save

```python
from thread import stack_size
stack_size(32768)
```

In the current directory and then create a new zeronet.conf file, enter the following and save:

```
[global]
ui_ip = 192.168.123.1
```

Back in ssh, execute these command

```shell
cd ZeroNet
tmux
```

This will be displayed as follows:

![1484830120.png (774x374)](http://127.0.0.1:43110/17vUgpdVUpN4yWeMJJtid7AAeQfLahHtXH/data/img/post_1_1484830120.png)â€‹â€‹â€‹â€‹â€‹

Then enter `pip install -r requirement.txt`

Wait finished, then type`python zeronet.py`and enter.
Now, open your browser and go to [http://192.168.123.1:43110/](http://192.168.123.1:43110/).

![1484830875.jpg (1064x857)](http://127.0.0.1:43110/17vUgpdVUpN4yWeMJJtid7AAeQfLahHtXH/data/img/post_1_1484830875.jpg)


ï¼šï¼‰enjoy it  Add "/opt/lib/libcrypto.so.1.0.0" support for optware and entware router @ysc3839 if `python -c "import ctypes.util; print ctypes.util.find_library('crypto')"` work on your device, we needn't to do other change  #627  Um..If it can't start thread, it will show error to me, but works fine... ![](https://cloud.githubusercontent.com/assets/15062548/22105327/69ea2802-de7e-11e6-84b2-7ca4ca7e35df.png)
![image](https://cloud.githubusercontent.com/assets/15062548/22106348/4abb0564-de83-11e6-94a6-37127e57e1cf.png)
without any error
![image](https://cloud.githubusercontent.com/assets/15062548/22106617/87cb2bcc-de84-11e6-9c4b-7e966e4fdc47.png)
 Yes, you are right...But how to check it? better solution #780   Probably no: ZeroNet is single threaded and requires external C modules (gevent, msgpack). Probably it could be possible to replace gevent with go workers, but I don't think it's worth to do.

90% of the CPU power used by the database and the cryptography, but these parts already written in C. (Sqlite and Openssl) Python3 change is planned to this year, but I'm not sure if it improve the performance or not. I'm also not familiar with go, but I think it's safe to say, that it would be much harder to change it to go, than to python3.

Btw actually python is growing faster (in percentage), than go

![](https://zgab33vy595fw5zq-zippykid.netdna-ssl.com/wp-content/uploads/2017/09/growth_smaller_tags-1-1024x878.png)
via https://stackoverflow.blog/2017/05/09/introducing-stack-overflow-trends/ A quick rise also not a good measure of "future proofness" as the new languages tend to became fashionable and they could drop quickly when the hype let up (see: ruby/ruby-on-rails)

btw from: https://www.tiobe.com/tiobe-index/

Jan 2018 | Jan 2017 | Change | Programming Language | Ratings | Change
-- | -- | -- | -- | -- | --
4 | 5 | Â  | Python | 4.678% | +1.21%
19 | 13 | Â  | Go | 1.569% | -0.76%


 Swift, C#, Kotlin, Rust are all competitors for Go in many levels.  Thanks, fixed: https://github.com/HelloZeroNet/ZeroNet/commit/de14c55311ca561fdbcbe4e97b38f036bbd8f9bc  
![image](https://cloud.githubusercontent.com/assets/15062548/22005529/f39e5aaa-dc9e-11e6-94cb-6aafb544a5ec.png)
http://127.0.0.1:43110/Me.ZeroNetwork.bit/?Profile/1KNmG5rJUGhgUJGFbLkv2B5isaqu9PrZqi/17zvGKq1Vft7Fp8HhqgD7rpqcGi5wDDSQ4/baddream@zeroid.bit
http://127.0.0.1:43110/1KNmG5rJUGhgUJGFbLkv2B5isaqu9PrZqi/data/users/17zvGKq1Vft7Fp8HhqgD7rpqcGi5wDDSQ4/data.json Block someone in zerome code:

```
import os
import sys

help_text = '''
Save this file to 'ZeroBundle/Python/block_tool.py'
Useage:
    python block_tool.py site_hash user_hash
example:
    python block_tool.py 1KNmG5rJUGhgUJGFbLkv2B5isaqu9PrZqi 17zvGKq1Vft7Fp8HhqgD7rpqcGi5wDDSQ4
programmer:
cxg2014, 12hlearn, 12hstudy@zeroid.bit
'''


def make_block_file(filename):
    if os.path.isfile(filename):
        os.remove(filename)
        os.mkdir(filename)
        open(filename + '/blocked', 'w').write('blocked')


def block(hub, addr):
    if hub is None or addr is None:
        print('Error!')
        print(help_text)
        return
    filename = "../ZeroNet/data/{0}/data/users/{1}/%s.json".format(hub, addr)
    content = filename % "content"
    data = filename % "data"
    make_block_file(content)
    make_block_file(data)
    os.system('python ../ZeroNet/zeronet.py dbRebuild 1MeFqFfFFGQfa1J3gJyYYUvb5Lksczq7nH')
    print("Successful block " + addr + ' and rebuild DB')


if __name__ == '__main__':
    if len(sys.argv) == 3:
        block(sys.argv[1], sys.argv[2])
    else:
        print(help_text)

```
  1. If you visit a site it can download up to 10MB of data that required by the site (source code, database) If you want to have more data than that, then the site owner able to define optional files that only downloaded when a client requests it. 
Using the merger sites you can also split the database into multiple sites (eg. by based on category, date, language, etc.), so you will only download and receive updates for data you are interested in. The example for this is the Hubs for ZeroMe.
2. There is no content censorship filter and I don't see any easy solution for that. Who going to decide what content is problematic?
3. Sites have size limit, the connections has CPU time, re-connection thottle and content updates are also limited, but probably there is lots of attack vectors on that. (especially hard on Tor network where every connection is comes from 127.0.0.1)
4. Peers are stored locally, so the next time you fire up your client can connect to them (and query other IPs via PEX) without any trackers. Local peer discovery and DHT planned later.
5. The content download is proritized by type (html, js first), freshness (newest posts first) and based on browser GET requests. If the images marked as optional files, then it will not download until you request it.
6. There is no data re-use yet. Latest web framework produces a single build.js files that has everything packed-in, which makes it impossible to share between sites. And having a central site of js liblaries also against the decentralization idea.
7. Not that I know.
8. There is no backed, so you can't render html, but if you have a single page application, that has it's storage layer well separated, then I think its possible to re-use. Basically you can execute database queries directly from javascript and you have to keep in mind, that every data is public.
9. Currently you have to encrypt the parts you want to keep in secret. You can give write permissions based on site directories, but nothing more.
10. Basically you have to start your client with `--ui_ip "*"`, then it will be accessible to anyone on your public ip. (enabling Multiuser plugin also recommended)
11. You can use Tor to hide your IP

I hope this answers your questions :) 1. ZeroNet sites are designed to run locally. If you don't have the data you can't query/search in it. Currently the peers picked randomly.
2. It could be possible to add a plugin that displays a warning if you going to visit or already seeding a site that many user find problematic.
3. Sometime I add new limitations, but it's impossible to add efficient protection against a botnet with 1000 of machines. (or like I said on the tor network where there is no IP adresses)
4. .
5. Parts downloaded from different peers. When you visit a site it starts up 10 workers and each begin download different files. If they run out of task (<10 task remain) after some timeout (based on filesize) they start to download the same files using multiple peers and the first one win.
6. I don't see it as an important problem, so it's not planned yet.
7. .
8. No plans for backed, for security reasons every logic should run in the browser.
9. No plans for more detailed permissions yet.
10. Yes, you can enable the UiPassword plugin for that
11. You can use VPN and there is other ways to get around the block (see: Tor transport protocols) Yes, it's still very new and limited, but I think we should search for use-cases where it could work instead of focusing on what is it not good for.

Thanks for the questions (added the dots)  Thanks for reporting, Optional files no longer got removed on signing: https://github.com/HelloZeroNet/ZeroNet/commit/697e177e135eb7b9acfff53570df9119ec18c3bc  delete everything, re-download it and try again  it displays free space on your hdd, it's possible that function is not implemented in android python  By that we would loose the ability to update torrc later, so instead I would prefer configurable `tor_exe`, so if anyone wants to make modifications, then create a copy of the directory (eg `tools/tor-custom`) and change that settings.  Currently only ascii filenames supported (non ascii files will not be included to content.json), because I think utf8 filenames and urls are unreliable, some browser/forum engine/etc. encode it as urlencode, some leave it as it is, somewhere it does not works at all.
  I hope big file support could come earlier.   Thanks, changed, new key:
(1)     Tamas Kocsis (4096) <tamas@zeronet.io>
          4096 bit RSA key CB9613AE, created: 2017-01-15, expires: 2022-01-14  are the `,` necessary at the `('TCP', 'UDP',)` ?

```
>>> ("TCP", "UDP") == ("TCP", "UDP",)
True
``` For me it's looks like an unfinished function call, so i would prefer without it. (I know its necessary for tuples with only one element)  well, i don't think if thats the problem:
```
>>> re.search('Tor="([0-9\.]+)', '250-VERSION Tor="0.2.9.8 (git-a0df013ea241b026)"').group(1)
'0.2.9.8'
```

Can you please add a `self.log.debug("Tor protocol: %s" % res_protocol)` before that line? @MuxZeroNet he already did that, I think the problem is at https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Tor/TorManager.py#L243, have to put that line to a `while not data:` loop

I will try to reproduce the problem I have added a modification that queries version using GETINFO, please try it: https://github.com/HelloZeroNet/ZeroNet/commit/77e07dd5b5287d1b2abb4dc4cafd391b611ec95a Hm I don't have other ideas yet. I tried to reproduce it under windows, but no luck. Going to again with a VPS. I have just installed on Debian 8 and works for me:
```
# ./ZeroNet.sh --debug
...
[21:29:16] TorManager > PROTOCOLINFO
[21:29:16] TorManager < 250-PROTOCOLINFO 1
250-AUTH METHODS=COOKIE,SAFECOOKIE COOKIEFILE="/var/run/tor/control.authcookie"
250-VERSION Tor="0.2.9.8"
250 OK
...
[21:29:16] TorManager > GETINFO version
[21:29:16] TorManager < 250-version=0.2.9.8 (git-a0df013ea241b026)
250 OK
```
(same with experimental 0.3.x)

do you have any other ideas to reproduce it?

please try this one:
```
# python --version
Python 2.7.9
# python -c "import gevent; gevent.version_info"
version_info(major=1, minor=2, micro=0, releaselevel='final', serial=1)
# python -c "import gevent; import gevent.monkey; gevent.monkey.patch_all(); import socket; s = socket.socket(socket.AF_INET, socket.SOCK_STREAM); s.connect(('127.0.0.1', 9051)); s.send('PROTOCOLINFO\r\n'); print s.recv(1024)"
250-PROTOCOLINFO 1
250-AUTH METHODS=COOKIE,SAFECOOKIE COOKIEFILE="/var/run/tor/control.authcookie"
250-VERSION Tor="0.2.9.8"
250 OK
```

  Can you please past the ~10 lines before and after the hang? (when the time is skipped in the log files)

If it happens often please enable `--debug_gevent`, so it will log any hang that take more than 100ms. It looks like around site 1F7b27... can you try to pause it? And please give me the full address of this site, so i can try it myself. Probably it causes lots of other problems, so it's really not recommended to have that large site.   I think a `if self.env['REQUEST_METHOD'] != 'GET':` restriction will be enough for the `actionWrapper` (we catch OPTIONS earlier and POST to non-wrapper files are ok.  upnpopening is disabled in tor mode and why is it better raising IGDError instead of SOCKS5Error (I think it would be usefull to keep UpnpPunch.py standalone from other libs)  Thanks, fixed in latest rev: https://github.com/HelloZeroNet/ZeroNet/commit/bea212a8d1fbf314b5a40e8828d17ab9d0bec27a  Thanks for the suggestion, but is tor works in china (without transport protocols) at all? It would be nice to find  away to unpack tor.exe and the transport protocols from the .exe

I'm also thinking about packing it to zeronet-win (and mac) bundle, so we don't have to rely on the "network"
  Looks like something is blocking the internet access of ZeroNet Looks like you using outdated zerobundle, please download, unpack this one and try again: https://github.com/HelloZeroNet/ZeroBundle/raw/master/dist/ZeroBundle-win.zip  Thanks!  I have added 2 modifications:
 - https://github.com/HelloZeroNet/ZeroNet/commit/6c68f8dd6ccb351861ba5cb4854ac1b309e1ed15 Fix content type detection of "/anysiteaddress", so wrapper no longer allowed to load by json request
 - https://github.com/HelloZeroNet/ZeroNet/commit/1a5bfd973ec632dec143f0ac5a1b4a47216b1e9b Non-wrapper file requests will not start downloading sites

I think these should fix the problems Hm, probably we can't filter every "fake" request by headers. Tomorrow I will add a modification that will only add sites if valid wrapper_key present.  Thanks for reporting, fixed: https://github.com/HelloZeroNet/ZeroNet/commit/6a71bb256e7ff2e970f7adea5e1193c87f246ee4  From now git commits are signed https://github.com/HelloZeroNet/ZeroNet/commit/901478475fb15a910d3c99ccb161730b4e84ca25 Just, sent it, please check again  `zeronet.py --debug siteDownload anysite` should do that  Fixed in Rev1797: It will skip broken sites on startup and use crash-safe writing for root content.json file.  Yeah, I'm also uncertain about utf8 domain names, no one can tell the difference between Ðžnet, âµ”net, Onet, ÎŸnet or Onet (All uses different "0" character)

or for example: http://secret.É¢oogle.com  I'm not really familiar with mac ecosystem, whats the most regular way to install/distribute apps there?
 - What liblary should we use? PyInstaller, cx_freeze, etc?
 - Signing?
 - Automatization?
 - Source code packed into .app or separately in .zip/directory?
 - What about updates?
 - Is it possible to submit it to Mac app store?
 If every resource is in the .app, then if I update the source code, then it will make the signature invalid, isn't it?
Also where should I put the data dir/config/log/third-party plugins? I was able to create .app pretty easily with PyInstaller, but unfortunately looks like it's not possible to execute in terminal, is there any standard procedure for that? Also which one you prefer? Distributing a .zip-ed .app or .dmg packed .app? (with Application folder symlink and similar) OK, here is the plan then:
 - [ ] Create a .app that contains everything to run: Python, Full source code
 - [ ] Sign it
 - [ ] On startup it adds /Library/Application Support/ZeroNet as working directory, so data, log will be saved there and it also adds to python sys.path, so plugins amd updates also can be placed there
 - [ ] Pack it up as dmg somehow (does it needs to be signed aswell?)

What about permissions? I suppose you need to be admin to drag anything to Application dir or write to /Library/Application Support/

Maybe we should check on startup if we are in the /Application directory and if not, then switch to portable mode: Create "ZeroNet files" directory and save everything there. I tried to sign it with the .pfs i got from https://en.sklep.certum.pl/data-safety/code-signing-certificates.html, but the result is:
```
$ codesign --verbose --force --deep --sign "Open Source Developer, Tamas Kocsis" ZeroNet.app
ZeroNet.app: signed app bundle with Mach-O universal (i386 x86_64) [com.apple.ScriptEditor.id.ZeroNet]

$ codesign -v ZeroNet.app/
ZeroNet.app/: CSSMERR_TP_NOT_TRUSTED
In architecture: x86_64
```
Am I doing something bad or it's not possible to sign mac .app with third-party cert?

Update: according to [this](http://stackoverflow.com/questions/11833481/non-apple-issued-code-signing-certificate-can-it-work-with-mac-os-10-8-gatekeep), third-party certificates does not work on osx, so I need to pay 99USD/year to Apple :(  The source code will be stored in .app, but it will store updates in ~/Library/Application Support/ZeroNet Then it will use see same data.
On mac the normal install method is dragging the .app to /Applications directory. The application has no rights to write there, so it should write to ~/Library/Application Support/ZeroNet

Alternative it can be based on if the .app is in the /Application or not Horray! I was able to produce .app that accepted by the gatekeeper, but if I download it using safari it runs differently: on startup it got moved to /private/.../AppTranslocation/ read-only directory, so I'm not sure how can we make it portable
more info on that: http://lapcatsoftware.com/articles/app-translocation.html Strangely if you move the .app to anywhere (via Finder), then it's no longer got moved to /private... directory on startup.

So it can work like that: If the startup path is in /private or /Applications, then save data to ~/Library/Application Support/ZeroNet otherwise to local directory (where .app is).

My new concern is release-signing: My cert and private key are stored in MacOS (VMWare), so every time I make any new modification I have to boot up the VM, re-create the .app, sign it (takes minutes with --deep), then upload the new zip.

Is there any way to make it easier?

_Update_: 
This could work: https://www.bitrise.io/ I got it running (the .app is ~9MB zipped with full python and source code included), supports portable and installed deployment. The only significant problem left is after starting it the application icon got placed to the dock, but it does not do anything. I will try to find a way to handle at the click (opening browser window) or hiding it. This works as standalone (will try to implement as a plugin tomorrow):
```
from Tkinter import Tk
root = Tk()
root.iconify()
def click():
	import webbrowser
	webbrowser.open("http://127.0.0.1:43110")
root.createcommand('tk::mac::ReopenApplication', click)
root.mainloop()
```
This way we got an easy way to access ZeroNet, Exit and Open at login possibility. (as drawback it adds +8MB mem usage) thanks for the suggestion, i was able to make it work:

```python
import sys
import os
import time
import zeronet

def gui():
    global root
    print "Gui started"
    time.sleep(5)
    sys.path.append("/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-tk")
    sys.path.append("/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/")
    from Tkinter import Tk
    root = Tk()
    root.iconify()
    def click():
        "Click"
        import webbrowser
        webbrowser.open("http://127.0.0.1:43110")

    def quit():
        print "Quit"
        sys.exit(0)


    root.createcommand('tk::mac::ReopenApplication', click)
    root.createcommand('tk::mac::ShowHelp', click)
    root.createcommand('tk::mac::ShowPreferences', click)
    root.createcommand('tk::mac::standardAboutPanel', click)
    root.createcommand('tk::mac::Quit', quit)
    try:
        root.mainloop()
    except Exception, err:
        print "Gui error: %s" % err
    print "Gui ended"

def main():
    sys.argv = [sys.argv[0]] + ["--open_browser", "default_browser"] + sys.argv[1:]
    zeronet.main()
    print "Ended"
    root.destroy()

if __name__ == '__main__':
    from threading import Thread
    t = Thread(target=main)
    t.daemon = True
    t.start()

    gui()

```

~~On shutdown it triggers keyboarderror, and~~ I had to add `check_same_thread=False` to database connects, but it seems working ok. The code is just an experiment, I will remove the prints and the unnecessary parts.

I'm still not fan of the tkinter, but that's the best option we have now. I also tried PyObjC, but even the simpliest application takes 40MB of ram. 
I not going to include it to the bundle, but use the preinstalled one (if avaliable) + delay the load (`time.sleep(5)`, but will try to figurate out something smarter) to not slow down the startup time. I have added the files [here](https://github.com/HelloZeroNet/ZeroNet-mac/tree/dist), but unfortunetly for some unknown reasons the signature become invalid:
```sh
ZeroNet-mac $ find ZeroNet.app -type f -print0 | sort -z | xargs -0 shasum > sum.sha | shasum
da39a3ee5e6b4b0d3255bfef95601890afd80709  -
ZeroNet-mac $ codesign -v --verify ZeroNet.app
ZeroNet.app: valid on disk
ZeroNet.app: satisfies its Designated Requirement
```

```sh
ZeroNet-mac-dist $ find ZeroNet.app -type f -print0 | sort -z | xargs -0 shasum > sum.sha | shasum
da39a3ee5e6b4b0d3255bfef95601890afd80709  
ZeroNet-mac-dist $ codesign -v --verify ZeroNet.app
ZeroNet.app: code object is not signed at all
In subcomponent: /Users/sumo/Downloads/ZeroNet-mac-dist/ZeroNet.app/Contents/MacOS/core/CHANGELOG.md
```

Any idea why? Ah I took 7 hours of googling, trying and dumping, I almost gave up on it, but then got it:

The codesign adding separate signature to every file in the MacOS directory. Usually it puts these signatures into the binary files content, but since we had .py files, it couldn't. In this cases it's using extended attributes (xattr) to store the signatures. 
Git don't sync these attributes, so they lost after the commit and the verification failed after the download. 
The two directories seemed to be the exact same: Every file had the same shasum, same permissions, only the xattr was different. (That I never heard before)

The solution was simple: move the .py files from the MacOS directory to the Resources. (It also fixed the 6 minute signature time) I was able to reduce the added data to .git directory from 2.5MB to 50kb, by moving the Python standard lib from the executable to external file. So I think the hard part is done, what is left:
- [x] The dock icon does not disappear on webUI exit
- [x] Test portable update
- [x] Test Library update
- [x] Test portable autorun
- [x] Test Library autorun
- [x] Test on El Capitan
- [x] Test on Yosemite
- [ ] Change link on ZeroNet.io
- [ ] Auto-release via @bitrise-io I have been fighting on an older macOS (10.9) with `ImportError: dlopen(/Users/user900818/Downloads/ZeroNet2.app/Contents/MacOS/pyexpat.so, 2): Symbol not found: _XML_SetHashSalt` error since yesterday. I tried to pack the required dylibs, but without any luck (python still loaded the system default one)

Switching to conda looks like fixed it and the zipped .app also become smaller: 8.7MB -> 7.9MB

just for the record, commands I used to install conda:
```
bash Miniconda2-latest-MacOSX-x86_64.sh
conda install gevent
conda install msgpack-python
conda config --add channels conda-forge
conda install pyinstaller
```

Update
Of course it's not this simple: The generated .app no longer accepted on 10.12 (Identity of the developer cannot be confirmed.) regardless

```
$ spctl -a -t exec -vvvv ZeroNet.app
ZeroNet.app: accepted
source=Developer ID
origin=Developer ID Application: Tamas Kocsis (4977YF9Q3Z)
$ codesign -v --verify ZeroNet.app/
ZeroNet.app/: valid on disk
ZeroNet.app/: satisfies its Designated Requirement
```

*sigh*

Update 2
Reverted back to normal (non-conda) version, with conda's libexpat.so. Looks like it working on both 10.12 and 10.9. Horray! (for now) After some testing it's looks like working well in 10.9 (using http://www.macincloud.com/), 10.11 and 10.12

The macincloud.com stored the applications in `/Users/userXX/Library/Managed Items/My Applications` so I also added ~/Library/* to non-portable mode (store data in ~/Library/Application Support instead of same directory as the .app)

I will re-create the ZeroNet-mac repo (to keep it small), change the link on zeronet.io, then start experimenting with bitrise. Well yeah, it happened:
It's working on 10.9, 10.11, 10.12, but not on 10.10.
```
$ ZeroNet.app/Contents/MacOS/ZeroNet
Error loading Python lib '/Users/sumo/Downloads/ZeroNet-mac-dist/ZeroNet.app/Contents/MacOS/.Python': dlopen(/Users/sumo/Downloads/ZeroNet-mac-dist/ZeroNet.app/Contents/MacOS/.Python, 10): no suitable image found.  Did find:
	/Users/sumo/Downloads/ZeroNet-mac-dist/ZeroNet.app/Contents/MacOS/.Python: code signature invalid for '/Users/sumo/Downloads/ZeroNet-mac-dist/ZeroNet.app/Contents/MacOS/.Python'
```

Regardless
```
$ codesign -vvvv ZeroNet.app/Contents/MacOS/.Python 
ZeroNet.app/Contents/MacOS/.Python: valid on disk
ZeroNet.app/Contents/MacOS/.Python: satisfies its Designated Requirement
$ codesign -vvvv ZeroNet.app/
ZeroNet.app/: valid on disk
ZeroNet.app/: satisfies its Designated Requirement
```

Tried to google the error, but no solution found, so currently experimenting with Py2app instead of PyInstaller...
  It would be nice to have a more regular, .exe releases for windows that also includes the source code, so no need to download it from github on first startup.
 - What liblary should we use? PyInstaller, py2exe, etc.
 - Single executable (unpacked to temp directory on startup) or normal, 6-7 file distribution?
 - Signing?
 - Automatization?
 - Source code packed into .exe or separately in .zip/directory?
 - What about updates?
 - Plugins?
 - Is it possible to submit it to Windows Store?
 - Alternative .msi or .exe installer with autostart option?
 - Where to store data/config file/third-party plugins? I was able to create a .exe with PyInstaller. It's less than 10MB (zipped) with everything packed in: Python, ZeroNet source code and dependecies, Coffeescript, Openssl, msvc*dlls

Currently it's looks like this:
![image](https://cloud.githubusercontent.com/assets/10350359/21703806/0075c5e4-d3b5-11e6-8579-dd30fa26b26b.png)

So pretty messy....It would be nice to move the supporter files to separate directory eg. Lib.

# Need help

Unfortunately PyInstaller did not support this (https://github.com/pyinstaller/pyinstaller/issues/1048), so it would be nice if anyone could add this feature or modify the bootloader: https://github.com/pyinstaller/pyinstaller/tree/develop/bootloader

# Other todo:
 - [X] Higher resolution icon
 - [ ] Data/Log dir outside of Include
 - [ ] Test  update from https/zeronet
 I'm not talking about single file exe, but to move the .dll and .pyd files to a sub-directory to make it look more clean and more easy to find the executable. The keep it updateable from zeronet network the full source code is still there, it's in the Include directory. (I'm not sure about this name, maybe we should name it something different, ideas?)

I found a company that give cert for opensrouce applications for 14EUR: https://en.sklep.certum.pl/data-safety/code-signing-certificates/open-source-code-signing.html

Already signed up, but it requires Java and the interface is half polish, so I was unable to complete the registration, will try again later. At least we can sign the zeronet.exe in the zip to avoid the notification about unsigned application. I found that it's possible to move the directly imported pyd files to different directory, so it's looks better now:

![image](https://cloud.githubusercontent.com/assets/10350359/21745435/4dddf3ba-d52c-11e6-8f3a-fc0799ee62e8.png)

Any ideas on the directory name where the .py files (zeronet source code) will be stored? Some ideas:

 - Source (we already have an src directory, so in this case it will be Source/src/ which is a little bit odd)
 - Include
 - Application
 - Program FIles (just kidding)
 - Core
 - System
 - Support
 - Runtime
 It's generated by pyinstaller
> You should sign all .dll files includes .pyd files.

I don't think os or python checks the signatures. New problem: I want to create a zip that have everything to go (python, openssl, sourcecode), but this means the .zip has to be updated pretty often. Which will make the ZeroBundle repository huge.
Sure, I could distribute the files from zeronet.io, but it would make it easy to block.
Is there any way to to replace binary files in git repo without keeping the history? (or any trick to keep the .git directory smaller) Yeah, but it makes the mirroring harder, since it does not get propogated automatically to:
- https://try.gogs.io/ZeroNet/ZeroNet
- https://gitlab.com/HelloZeroNet/ZeroNet

New idea: Instead of uploading the zip file, create separate repository for ZeroNet-win / ZeroNet-mac, add the exe/app/ddl/pyd and the source code as normal files, then let the provider to pack it, eg.: https://github.com/HelloZeroNet/ZeroNet/archive/master.zip

Is there any way to mirror the commits? So any commit that is submitted to ZeroNet repository have to be also added to ZeroNet-win/core directory signed, .exe version: https://github.com/HelloZeroNet/ZeroNet-win/archive/dist.zip
 what do you mean by that? I think we had windows xp compatibility issues with that I think when I first published zerobundle it refused to work under windows xp without a .manifest file, but if someone could try it that would be nice. I juist tried to embed the manifest, but then just drops this error (win10):
`Cannot open self f:\Work\ZeroNet-git\ZeroBundle\PyInstaller\dist\ZeroNet\ZeroNet.exe or archive f:\Work\ZeroNet-git\ZeroBundle\PyInstaller\dist\ZeroNet\ZeroNet.pkg`

The command was: `..\..\tools\mt.exe -nologo -manifest "dist\ZeroNet\ZeroNet.exe.manifest" -outputresource:"dist\ZeroNet\ZeroNet.exe;1" ` So the dlls should be in both directory? (lib and beside zeronet.exe) Fuck, then have to find a way to move everything to the lib dir

maybe stick with .cmd and just convert it somehow to an exe Other option could be modifying the bootload to load the dlls from lib directory: https://github.com/pyinstaller/pyinstaller/blob/c14333fc7498d261e1ce47d2354ecaecc88037d2/bootloader/src/pyi_utils.c#L736 Unfortunetly i have no experience with C, so maybe it's better to pack as an exe that unpack to temp dir every time on startup. (im not fan of this solution, but probably the best we have) or simply drop the portable version and distribute it as an a exe/msi installer. py2exe has not been updated since 9 years, so i would avoid it. (and I think it's also does not support moving dll-s to separate directory) As a workaround it will copy the dll-s to the lib dir on startup. (this way it does not makes the .zip larger)

Also included .manifest using ResourceHacker.exe and added dual (SHA1 & SHA256) signature. 
https://github.com/HelloZeroNet/ZeroBundle/commit/f544a9c2e708390134d4c9b0e42db195a89a903c
Please test if you can: https://github.com/HelloZeroNet/ZeroNet-win/archive/dist.zip Exe is not released yet, it just testing, but after that the zerobundle will not be supported. Another "easy" problem: Zeroner runs 3 times slower and using 10 times more memory in .exe from:

```
Benchmarking ZeroNet 0.5.1 (rev1830) Python 2.7.12 (v2.7.12:d33e0cf91556, Jun 27 2016, 15:19:22) [MSC v.1500 32 bit (Intel)] on: win32...

CryptBitcoin:
- hdPrivatekey x 10..........0.192s [x3.65: Insane!!]
- sign x 10..........0.104s [x3.37: WOW]
- openssl verify x 100..........0.464s [x0.80: Goodish]
- pure-python verify x 10..........0.532s [x3.01: WOW]

CryptHash:
- sha256 5M x 10..........0.197s [x3.05: WOW]
- sha512 5M x 10..........0.244s [x2.46: Fast]
- os.urandom(256) x 100 000..........0.085s [x7.65: Insane!!]

Msgpack:
- pack 5K x 10 000..........1.427s [x0.55: Goodish]
- unpack 5K x 10 000..........0.705s [x1.70: Fast]
- streaming unpack 5K x 10 000..........0.636s [x2.20: Fast]

Db:
- Open x 10..........0.054s [x2.41: Fast]
- Insert x 10 x 1000..........2.237s [x0.45: Ehh]
- Buffered insert x 100 x 100..........2.483s [x0.52: Goodish]
- Total rows in db: 20000
- Indexed query x 1000..........0.690s [x0.36: Ehh]
- Not indexed query x 100..........0.251s [x2.39: Fast]
- Like query x 100..........0.422s [x4.27: Insane!!]

Done. Total: 10.92s
```

vs run using python.exe zeronet.py:

```
Benchmarking ZeroNet 0.5.1 (rev1830) Python 2.7.12 (v2.7.12:d33e0cf91556, Jun 27 2016, 15:19:22) [MSC v.1500 32 bit (Intel)] on: win32...

CryptBitcoin:
- hdPrivatekey x 10..........0.185s [x3.78: Insane!!]
- sign x 10..........0.094s [x3.72: Insane!!]
- openssl verify x 100..........0.117s [x3.16: WOW]
- pure-python verify x 10..........0.507s [x3.16: WOW]

CryptHash:
- sha256 5M x 10..........0.150s [x4.00: Insane!!]
- sha512 5M x 10..........0.206s [x2.91: WOW]
- os.urandom(256) x 100 000..........0.071s [x9.15: Insane!!]

Msgpack:
- pack 5K x 10 000..........0.214s [x3.64: Insane!!]
- unpack 5K x 10 000..........0.319s [x3.76: Insane!!]
- streaming unpack 5K x 10 000..........0.342s [x4.09: Insane!!]

Db:
- Open x 10..........0.012s [x10.83: Insane!!]
- Insert x 10 x 1000..........0.346s [x2.89: WOW]
- Buffered insert x 100 x 100..........0.497s [x2.62: WOW]
- Total rows in db: 20000
- Indexed query x 1000..........0.084s [x2.98: WOW]
- Not indexed query x 100..........0.158s [x3.80: Insane!!]
- Like query x 100..........0.289s [x6.23: Insane!!]

Done. Total: 3.78s
``` Hmm...well...hmm any idea?
![image](https://cloud.githubusercontent.com/assets/10350359/22183240/6f071236-e0b9-11e6-87d0-adcc27a99b4a.png)

The frozen script:
```
import sqlite3, time

db = sqlite3.connect("test.db")
s = time.time()
db.execute("CREATE TEMP TABLE t(x INTEGER PRIMARY KEY ASC, y);")
for i in range(100000):
	db.execute("INSERT INTO t VALUES (%s, 'test')" % i)
print time.time() - s
raw_input(">")
``` It's not possible to sign .cmd, firewall/os restrictions can be problematic with python.exe, it also means less files

but this problem seems like not related to frozen mode. if I rename python.exe to zeronet.exe and run the included script with it, then it's also 18 times slower and using 10 times more memory. restarting windows does not fixes it.

can anyone check the same? deleting "HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Image File Execution Options\ZeroNet.exe" looks like fixed it...

I have not saved the value of it before the delete, probably somehow windows put it into special debug mode or similar.... The CPU-hungry parts already written in C, so Cython would not help there  Please explain your question The storage and the bw used by js libs are negligible and different sites requires different version libs, so it would be a mess.  probably one of the plugins blocking it, please try in incognito mode and in other browser. Then try to delete and re-download it maybe its got damaged during the dl/unpack Yeah it's the "x-css" line is the problem, if you go to the network tab and select the first all.css what does it look like?
Here is mine:
![image](https://cloud.githubusercontent.com/assets/10350359/21659557/a62f47ac-d2cb-11e6-9ef7-e209eba715a7.png)
 I added a modification that hopefully will fix it: https://github.com/HelloZeroNet/ZeroNet/commit/5c2b90c20f0760db7b2d2c82e4344a55012e36f6

Please update to latest version and try again: The easiest way to do that is delete ZeroNet directory and start zeronet.cmd again, so it will re-download it.  It usually happens if you someone has a site in the browser that in no longer in the client  I don't thing proof of work is a good solution to protect against spam: For example if we require 1 minute CPU time POW (really annoying) before to submitting new comment a spammer with a decent GPU would still able to send 100+ messages / minute.  try `stats_content = requests.get('http://127.0.0.1:43110/Stats', headers = {"Accept": "text/html"}).text` I searched for `ParsePeers` on ZeroHello and dropped this result:
http://127.0.0.1:43110/1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/?Post:7  this limitation is not in zeronet, but in the browser, so i cant modify it, but if you use the same way to load the resources as other zeronet sites, then it should be fine  cc @sirMackk  You need to forward port 15441 to your local ip, but zeronet should also work fine without any opened port.  @iShift Thanks, https://github.com/HelloZeroNet/ZeroMe/issues/27 Block someone in zerome code:

```
import os
import sys

help_text = '''
Save this file to 'ZeroBundle/Python/block_tool.py'
Useage:
    python block_tool.py site_hash user_hash
example:
    python block_tool.py 1KNmG5rJUGhgUJGFbLkv2B5isaqu9PrZqi 17zvGKq1Vft7Fp8HhqgD7rpqcGi5wDDSQ4
programmer:
cxg2014, 12hlearn, 12hstudy@zeroid.bit
'''


def make_block_file(filename):
    if os.path.isfile(filename):
        os.remove(filename)
        os.mkdir(filename)
        open(filename + '/blocked', 'w').write('blocked')


def block(hub, addr):
    if hub is None or addr is None:
        print('Error!')
        print(help_text)
        return
    filename = "../ZeroNet/data/{0}/data/users/{1}/%s.json".format(hub, addr)
    content = filename % "content"
    data = filename % "data"
    make_block_file(content)
    make_block_file(data)
    os.system('python ../ZeroNet/zeronet.py dbRebuild 1MeFqFfFFGQfa1J3gJyYYUvb5Lksczq7nH')
    print("Successful block " + addr + ' and rebuild DB')


if __name__ == '__main__':
    if len(sys.argv) == 3:
        block(sys.argv[1], sys.argv[2])
    else:
        print(help_text)

```
  bit.no.com (or any other proxy) is not run by ZeroNet project. Please try to contact the proxy owner.  It's already there (allows +1 day from local time): https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Content/ContentManager.py#L758 This does not protect from post timestamp modifications. (zeronet does not filter data.json content)
The future post filtering have to be implemented in every site's js code independently.
Just added future post filtering to followed users on ZeroMe site: https://github.com/HelloZeroNet/ZeroMe/commit/e7b23f1eb579cc3ef1307c7036ed7e8d4a49666a  Thanks!  Thanks, fixed in Rev1791 9a1735f37dfc7f9a2f734783f38ca5c8a4e9cbc3 The fix was:
```
try: 
    from gevent.coros import RLock 
except: 
    from gevent.lock import RLock 
```
So you need
```
try: 
    from gevent.coros import RLock, Semaphore
except: 
    from gevent.lock import RLock, Semaphore
```  - If you want by you can bind to 127.0.0.2 `--ui_ip 127.0.0.2` (but is it any better?)
- Editing host file require root/admin permissions.   Non-ascii filenames not supported atm and automatically removed from sites.  ZeroNet does not include [Tor pluggable transports yet](https://www.torproject.org/docs/pluggable-transports.html.en). The easiest way to use that is starting the Tor browser, configuring the pluggable transports, then modifing ZeroNet's config to use the browser's tor client by starting it with `--tor_controller 127.0.0.1:9151 --tor_proxy 127.0.0.1:9150` or adding it to zeronet.conf
```
[global]
tor_controller = 127.0.0.1:9151
tor_proxy = 127.0.0.1:9150
```  This error comes from chrome browser.
https://wyldeplayground.net/terminal-errors-concerning-netflix-in-google-chrome/

If you want you can disable the browser window opening by replacing start.py with zeronet.py in zeronet.sh  the clone site has wrong size_optional Info. I just cloned BlueHub and everything looks fine for me:
```
{  
   "to":1000001,
   "cmd":"response",
   "result":{  
      "tasks":0,
      "size_limit":10,
      "address":"12F55EiSQ2drprqCyKdrpSbz5tP8JKexLy",
      "next_size_limit":10,
      "auth_address":"1QE9utGYcEmUn9hXi6qtGmdpC52BmkCPgg",
      "auth_key_sha512":"ce9ce537872f708d4d7437a9ccda8e873434395e9a74c9fbaef4f7ec415ecb5e",
      "content":{  
         "files":2,
         "description":"Welcome to ZeroMe! Runner: Nofish",
         "cloned_from":"1BLueGvui1GdbtsjcKqCf4F67uKfritG49",
         "clone_root":"",
         "includes":1,
         "cloneable":true,
         "address":"12F55EiSQ2drprqCyKdrpSbz5tP8JKexLy",
         "inner_path":"content.json",
         "merged_type":"ZeroMe",
         "title":"myBlueHub",
         "files_optional":0,
         "signs_required":1,
         "modified":1483124576.748,
         "ignore":"((js|css)/(?!all.(js|css))|data/.*db|data/users/.*/.*)",
         "zeronet_version":"0.5.1",
         "postmessage_nonce_security":true,
         "address_index":74815259,
         "background-color":"white"
      },
      "peers":1,
      "auth_key":"f442166a02cb1062a572c8a3cc87a8fcc88d215f1311164759342c1d161798f8",
      "settings":{  
         "peers":0,
         "serving":true,
         "optional_downloaded":0,
         "size_optional":0,
         "modified":1481138875.097,
         "cache":{  

         },
         "own":true,
         "permissions":[  

         ],
         "added":1483124576,
         "size":4006
      },
      "bad_files":0,
      "workers":0,
      "privatekey":true,
      "cert_user_id":null,
      "started_task_num":0,
      "content_updated":null
   },
   "id":1
}
```  I have just tried and it's compiled for me without any error Yeah, i forgot i have a node based coffeescript compiler (it's faster) (`type %s | tools\coffee-node\bin\node.exe tools\coffee-node\bin\coffee --no-header -s -p`)

I will try whats happens with the wsh-based one.

Alternative you can edit the all.js directly or make ZeroBlog multilanguage by adding 
```
 "translate": [
  "index.html",
  "js/all.js"
 ],
```
to content.json, then creating languages/zh.json and specify what you want to replace. (see ZeroTalk for example)  Do you have any suggestions to detect real browser opening?
It could be possible to check http headers, but I'm not sure how reliable it is when using less-known features like
```
<link rel="prefetch" href="http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D">
``` I have added some restriction, so loading site as image/prefetch should no longer work. https://github.com/HelloZeroNet/ZeroNet/commit/86b0046f287f1a24a9fcb216fd1a31ea49823ee6
It's not final solution, but better solution (testing if rendering and js execution available) needs more changes.  ZeroNet itself does not execute anything downloaded from the network, so it's not possible to display notifications if the site is not running in the browser.  The possible solutions are:
 - If you run out of limit delete the oldest comment you made (automatize this)
 - Create your own hub and increase the limit for yourself
  Thanks!  It's the sandboxed iframe's limitation and I don't know any workaround for it. I'm not sure if it's bug or a feature, there is lots of result if you search for "blob:null sandboxed iframe" on google You mean big file support by "video support"? I can't change the sandbox limitations, but adding a new "wrapperRequestFullscreen" could be possible. `Page.cmd("wrapperRequestFullscreen")` added in latest rev: https://github.com/HelloZeroNet/ZeroNet/commit/5103879471176fced494dc70d35e8384275f787e  Thanks, probably it's depends on what unpacker application you have used.
It would be nice if someone could help me how to make a proper .dmg from it.  I dont think its necessary, since we change the working path to zeronet's directory on startup: https://github.com/HelloZeroNet/ZeroNet/blob/master/zeronet.py#L14  If you are not running in debug mode or don't have werkzeug python package installed, then this is normal  Thanks!  Thanks!  Thanks!  This error happens if the key parameter is not supplied at all (or null passed), so eg.: Page.cmd("aesDecrypt", ["iv", "enryptedtext", null])
Please check the Dev console's network tab websocket entry to see if correct number of paramters sent.  It should work, are you sure your user has the permission to write in the data directory and you client is not running already? I have just tried and it's works with "Standard user" (OSX 10.11)  Thanks!
I think we should not translate network/log messages  Earlier ZeroNet returned simple string on errors. Some month ago it got changed to object and that's why it's happening.  At the time of the plugin release I was about to add this feature, but then decided not to add it as it would reduce the performance and add code complexity. (having per-proxy language is also reduces centralization)
Probably cookie would be better as simple http requests and websocket messages also needs to be translated.
  Thanks!   - There is some protection against connection flooding or rapid requests. (it will slow down the reponse time if X cpu time is used by peer)
 - The client start downloading the files from random peers and keep trying until it's finishes

It's really hard to protect these kind of attacks (especially on Tor network where every request come from 127.0.0.1), but the result of this attacks are much less spectacular, than attacking a normal web site, since it's served from your computer so you will still able to access pages and only delays the updates
 On clearnet it could be possible, to not serve the same file to the same client, but the Tor network does not provide any information about the request sender and it's still would not work against attacks that involves 100s of computers.

The zeroid is generation is limited by the cert issuer. Currently it's only a simple js check but later captcha/facebook/email/crypto-burning etc. verification could be added. I think proof of work not suitable to solve this problem, because the attacker could use highend-cpu/gpu to solve it and still generate 1000s users/hour.

You can block users by id, look for banexample in data/users/content.json

Here, Github, ZeroTalk is the best places to ask questions I don't know any cryptocurrency that is CPU-only. 30 minute is already too much for most of the users to wait to be able to post new comment, but it's nothing for a spammer (you can rent a VPS for 1EUR/month) from their page: "Do not put yourself in danger. Our anonymity is not yet mature.", so i think it would be a bad idea to use it, and even if they solution is technologically right less user/node means less anonymous/secure.

yes, zeronet using self-signed certs, so mitm is possible on non-tor connections, i dont think blockchain is a good place to store this information (and also requires to every client run full node)
.onion connections are mitm safe, so adding a .onion only mode would be easier  - A new update is distributed as a "diff", so while your computer is online and connected to the network you will receive only the changed lines, but if you re-connect to the network you re-download the entire changed files
- The files that requested by your client (via http) will be prioritized  add `--tor disable` to the parameters, so it won't try to fire up internal tor  Thanks for reporting, it should work now: c1fd2be8cfadf3e93ae70e3d9763875460bb81a3  Fixed!  Thanks!  ZeroNet only support websocket api, no alternative API planned yet IPFS written in GO, so it would require different toolset to run it. But there is many alternative to IPFS: BitTorrent, StorJ, Maidsafe, Sia, etc., every site owner able to choose the best one that fits to his/her needs. It's just an API, but you still need to compile the Go client to run it. With the optional files support it's also possible to share big files using ZeroNet, but the problem is most of the users are using ZeroNet using Tor, which is not suitable to transfer big files.  Yeah, missed that one. Addig "Site control" will work: e2d73637f62eb13548c2a3bdb7bb9191ade92874  The line 714 in ContentManager.py:
`                if not re.match("^%s$" % rules["files_allowed"], file_inner_path):`

Your files_allowed pattern in data/users/content.json is invalid: `"files_allowed": "*.json"` it should be: `"files_allowed": ".*json"`
  some titles are overflow, fixed some in the latest revision, but there is some I cant
![image](https://cloud.githubusercontent.com/assets/10350359/20609833/d9d8626e-b291-11e6-85e8-c3729def4b32.png)
  You can specify the viewport in content.json, example from ZeroTalk: https://github.com/HelloZeroNet/ZeroTalk/blob/master/content.json#L81 I have no smartphone, but in the emulator it's seems pretty comfortable to use: double tap right section if you want to read the newsfeed, double tap left section if you want to browse sites you seed
The layout is already fluid, so you dont have to scroll horizontally Yeah I meant the chrome's responive tester by the emulator. I have an old nokia phone. (1110 or similar)  It's missing a { from the beginning  Thanks!  It's not possible to list, because you can translate any string.

There is tons of javascript localization frameworks, you can use any of them if you want. I'm not familiar with it, but I have added every string to the hu.json file  Please open the PR to the main branch.
  If there is not title, then it can't be displayed in the list, so it's a requirement. 
  Thanks, please use "pt.json" and also translate other files:
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Translate/languages/hu.json
https://github.com/HelloZeroNet/ZeroHello/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroMe/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroTalk/blob/master/languages/hu.json
 there is no convencion for that, possible solutions: `pt-br.json`, `pt-BR.json`, `pt_BR.json` all used and looks fine for me, but please make the pt-pt.json as pt.json (like the current ones)
  Thanks, please also translate other files:

https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Sidebar/languages/hu.json
https://github.com/HelloZeroNet/ZeroHello/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroMe/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroTalk/blob/master/languages/hu.json
  If someone want to help add new languages, the files needs to be translated:

https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Translate/languages/hu.json
https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Sidebar/languages/hu.json
https://github.com/HelloZeroNet/ZeroHello/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroMe/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroTalk/blob/master/languages/hu.json

Simply make a copy of them to the same dir where they are with the language short code you are going to translate to and replace the Hungarian translation.

To test them before submitting to github:
- By default ZeroNet uses the operating system language, but you can also specify it in zeronet.conf (where zeronet.py is)
- Open sidebar, check "This is my site"
- Open javascript console (F12) check "Disable cache" on Network tab to avoid caching, keep window open
- To reload Core language files (src/Translate/languages/hu.json and plugins/Sidebar/languages/hu.json) without restart you have to click on you language again on ZeroHello's 3dot menu
  It's only used for UPNP port opening: https://en.wikipedia.org/wiki/Universal_Plug_and_Play
  ZeroNet by default does not writes to /etc, please use the zerobundle package or report it to the package maintainer.

other option is add write permissions to /etc/zeronet.conf modify to:

```
[global]
tor = always
```
  Thanks!
 Please also translate these files, so I can also add it to ZeroHello:

https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Sidebar/languages/hu.json
https://github.com/HelloZeroNet/ZeroHello/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroMe/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroTalk/blob/master/languages/hu.json

Simply make a copy of them to the same dir where they are with the language short code you are going to translate to and replace the Hungarian translation.

To test them before submitting to github:
- By default ZeroNet uses the operating system language, but you can also specify it in zeronet.conf (where zeronet.py is)
- Open sidebar, check "This is my site"
- Open javascript console (F12) check "Disable cache" on Network tab to avoid caching, keep window open
- To reload Core language files (src/Translate/languages/hu.json and plugins/Sidebar/languages/hu.json) without restart you have to click on you language again on ZeroHello's 3dot menu
  After the lastest update i get this error starting zeronet. 
using arch linux arm on raspberry pi.
python version: 2.7.12

```
- Starting ZeroNet...
Traceback (most recent call last):
  File "./zeronet.py", line 15, in main
    import main
  File "./src/main.py", line 25, in <module>
    from Config import config
  File "/usr/lib/python2.7/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "./src/Config.py", line 343, in <module>
    config = Config(sys.argv)
  File "./src/Config.py", line 17, in __init__
    self.createArguments()
  File "./src/Config.py", line 51, in createArguments
    language = language.split("_")[0]
AttributeError: 'NoneType' object has no attribute 'split'

``` Can you please run: 
`python -c "import locale; print locale.getdefaultlocale()"`
and
`locale -a`
 $ python2 -c "import locale; print locale.getdefaultlocale()"
(None, None)

$ locale -a
C
POSIX
en_US.utf8

Edit: Ran "localectl set-locale LANG=en_US.UTF-8" and works now, thanks a lot for the help. Issue can be marked as soved/closed
 It's fixed in latest version  it's using bell utf8 character: ðŸ”” http://graphemica.com/%F0%9F%94%94
probably you are missing some fonts on your machine
 It's defined as Arial, Helvetica, 'Segoe UI Symbol', but if these are not present on your system, then it should fall back to systemdefault
 https://jsfiddle.net/kha51nn0/
is any of these works for you?
  You can confirm the deletion with pressing enter button, so you can delete it quickly.
  Good idea, implemented: 7839cf4f90398c5bf779852383ba8f2568a6f7b9
  Thanks, i'm currently also working on it, i have benchmarked the possible translation solutions and currently i'm preferring pure-json translation tables over gettext, it will finish the hungarian translation in the next days, after that other languages will be welcome
 Json based translationt tables are pretty common, you dont need anything to edit them and [transifex](http://docs.transifex.com/formats/json/) and other online translation helpers also supporting them.

If you spend a little time anaylizing your prossibilites, then Python offers pretty good performance/feature ratio (for this kind of applications). Network speed should be no issue (since you using your loopback connection) and browser speed are also fine.
 This is how the translate tables look like, I think it's pretty easy to edit without any external utility:

For python source:

```
{
    "Peers": "CsatlakozÃ¡si pontok",
    "Connected": "Csaltakozva",
    "Connectable": "CsatlakozhatÃ³",
    "Connectable peers": "CsatlakozhatÃ³ peer-ek",

    "Data transfer": "AdatÃ¡tvitel",
    "Received": "Fogadott",
    "Received bytes": "Fogadott byte-ok",
    "Sent": "KÃ¼ldÃ¶tt",
    "Sent bytes": "KÃ¼ldÃ¶tt byte-ok",

    "Files": "FÃ¡jlok",
    "Total": "Ã–sszesen",
    "Image": "KÃ©p",
    "Other": "EgyÃ©b",
    "User data": "Felh. adat",

    "Size limit": "MÃ©ret korlÃ¡t",
    "limit used": "felhasznÃ¡lt",
    "free space": "szabad hely",
    "Set": "BeÃ¡llÃ­t",

    "Optional files": "OpcionÃ¡lis fÃ¡jlok",
    "Downloaded": "LetÃ¶ltÃ¶tt",
    "Download and help distribute all files": "Minden opcionÃ¡lis fÃ¡jl letÃ¶ltÃ©se",
    "Total size": "Teljes mÃ©ret",
    "Downloaded files": "LetÃ¶ltve",

    "Database": "AdatbÃ¡zis",
    "search feeds": "KeresÃ©s forrÃ¡sok",
    "{feeds} query": "{feeds} lekÃ©rdezÃ©s",
    "Reload": "ÃšjratÃ¶ltÃ©s",
    "Rebuild": "ÃšjraÃ©pÃ­tÃ©s",
    "No database found": "AdatbÃ¡zis nem talÃ¡lhatÃ³",

    "Identity address": "AzonosÃ­tÃ³ cÃ­m",
    "Change": "MÃ³dosÃ­t",

    "Update": "FrissÃ­t",
    "Resume": "Folytat",
    "Delete": "TÃ¶rÃ¶l",

    "Site address": "Oldal cÃ­me",
    "Donate": "TÃ¡mogatÃ¡s",

    "Missing files": "HiÃ¡nyzÃ³ fÃ¡jlok",
    "{} try": "{} prÃ³bÃ¡lkozÃ¡s",
    "{} tries": "{} prÃ³bÃ¡lkozÃ¡s",
    "+ {num_bad_files} more": "+ mÃ©g {num_bad_files} darab",

    "This is my site": "Ez az Ã©n oldalam",
    "Site title": "Oldal neve",
    "Site description": "Oldal leÃ­rÃ¡sa",
    "Save site settings": "Oldal beÃ¡llÃ­tÃ¡sok mentÃ©se",

    "Content publishing": "Tartalom publikÃ¡lÃ¡s",
    "Choose": "VÃ¡lassz",
    "Sign": "AlÃ¡Ã­rÃ¡s",
    "Publish": "PublikÃ¡lÃ¡s",

    "This function is disabled on this proxy": "Ez a funkciÃ³ ki van kapcsolva ezen a proxy-n",
    "GeoLite2 City database download error: {}!<br>Please download manually and unpack to data dir:<br>{}": "GeoLite2 vÃ¡ros adatbÃ¡zis letÃ¶ltÃ©si hiba: {}!<br>A tÃ©rkÃ©phez tÃ¶ltsd le Ã©s csomagold ki a data kÃ¶nyvtÃ¡rba:<br>{}",
    "Downloading GeoLite2 City database (one time only, ~20MB)...": "GeoLite2 vÃ¡ros adatbÃ¡zis letÃ¶ltÃ©se (csak egyszer kell, kb 20MB)...",
    "GeoLite2 City database downloaded!": "GeoLite2 vÃ¡ros adatbÃ¡zis letÃ¶ltve!"
}
```

For ZeroMe

```
{
    "Opened": "Nyitva",
    "Closed": "BezÃ¡rva",
    "_(Disabled)": "Kikapcsolva",
    "_(Error)": "Hiba",
    "Status": "Ãllapot: ",
    "Nice! Your port \" + Page.server_info.fileserver_port + \" is opened.": "KirÃ¡ly! A \" + Page.server_info.fileserver_port + \" portod nyitva van.",
    "Re-check opened port": "Port ÃºjraellenÃ¶rzÃ©se",
    "How to make Tor connection work?": "Hogyan lehet bekapcsolni a Tor kapcsolatot?",
    "How to use ZeroNet in Tor Browser?": "Hogyan hasznÃ¡ljam a ZeroNet-et a Tor bÃ¶ngÃ©szÅ‘ben?",
    "Disable always Tor mode": "Tor mindig mÃ³d kikapcsolÃ¡sa",
    "Enable Tor for every connection (slower)": "Tor hasznÃ¡lata minden kapcsolatra (lassabb)",
    "Help to keep this project alive": "SegÃ­ts Ã©letben tartani a projectet",

    "Welcome to ZeroNet": "Ãœdv a ZeroNet-en",
    "Let's build a decentralized Internet together!": "Ã‰pÃ­tsÃ¼nk egy decentralizÃ¡lt Internetet kÃ¶zÃ¶sen!",
    "This site currently served by ": "Ez azt az oldalt jelenleg ",
    " peers, without any central server.": " szÃ¡mÃ­tÃ³gÃ©p szolgÃ¡lja ki, kÃ¶zponti szerver nÃ©lkÃ¼l.",
    "Some sites we created:": "PÃ¡r oldal, amit mi csinÃ¡ltunk:",
    "Simple messaging board": "EgyszerÅ± Ã¼zenÅ‘ fal",
    "Reddit-like, decentralized forum": "Reddit-szerÅ±, decentralizÃ¡lt fÃ³rum",
    "Activate \\u2501": "AktivÃ¡lÃ¡s \\u2501",
    "Microblogging platform": "Mini blog-motor",
    "End-to-end encrypted mailing": "PonttÃ³l-ponting titkosÃ­tott Ã¼zenetkÃ¼ldÅ‘",
    "P2P social network": "P2P szociÃ¡lis hÃ¡lÃ³zat",

    "_(Sites)": "Oldalak",
    "_(Files)": "FÃ¡jlok",
    "Connected sites:": "ElÃ©rhetÅ‘ oldalak",
    " file update failed": " hiÃ¡nyzÃ³ fÃ¡jl",
    "More sites:": "TÃ¶bb oldal:",
    "Activate \\u00BB": "AktivÃ¡lÃ¡s \\u00BB",

    " minutes ago": " perce",
    " hours ago": " Ã³rÃ¡ja",
    " days ago": " napja",
    "on ": "",
    "Just now": "Ã‰pp most"
}
```

The result:
![image](https://cloud.githubusercontent.com/assets/10350359/20262577/11689e60-aa63-11e6-87c4-1ff5cae990c4.png)

So there is 2 separate translator: One for the python source code and one for sites source code. 

The python source code translation is pretty simple _("Anything") returns the translated version of "Anything".

The site source code translation happens on server-side: you can switch any string in the javascript source code with a translated version of it. So it does not requires any modification in the site source code, but it has some drawbacks:
- Caching: Browser caches .js files, so you have to wait some minute after chaing language
- It does not works for every string, eg if you have somthing like this: `if (mode == "Page") $("#mode").text("Page")` and you want to translate "Page" then it will also translate the one in condition so it will never matches. As for solution for this you have to write: `if (mode == "Page") $("#mode").text(_("Page"))` and if put `"_(Page)": "Oldal"` to the translate json, it will only translate `_("Page")`
- If you don't like this solution you are free to translate the string in real-time. (by adding `_("anything")` to every string you want to translate and return the translated one based on user's language), but I choosen this one because it does not adds extra "noise" to site's source code and the other reason is speed: The virtual dom liblaries re-rendering the structure array on every update, click or keypress, so if you translate in real-time it has to call the translation function for every string you have on the page. (it it can easily add 1000s of function calls to every keypress)

I will also translate ZeroTalk and ZeroMe with this solution before the release to see if it can also work for that sites. ETA: this week
 Added in 0.5.1, translation files:
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Translate/languages/hu.json
https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Sidebar/languages/hu.json
https://github.com/HelloZeroNet/ZeroHello/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroMe/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroTalk/blob/master/languages/hu.json
  Can't test it, but looking good. Thanks
 there is no explorer.exe on win10
 Yeah you are right, there is explorer.exe, but after kill/restart it i got:

```
[11:38:21] - Unhandled exception
Traceback (most recent call last):
  File "plugins\Trayicon\lib\notificationicon.py", line 558, in _run
    TranslateMessage(ctypes.pointer(message))
ArgumentError: argument 1: <type 'exceptions.TypeError'>: expected LP_MSG instance instead of LP_MSG
Traceback (most recent call last):
  File "_ctypes/callbacks.c", line 315, in 'calling callback function'
  File "plugins\Trayicon\lib\notificationicon.py", line 646, in _callback
    Shell_NotifyIcon(NIM_ADD, ctypes.pointer(self.iconinfo))
ctypes.ArgumentError: argument 2: <type 'exceptions.TypeError'>: expected LP_NOTIFYICONDATA instance instead of LP_NOTIFYICONDATA
```
 Yeah, the error message makes no sense and if I run notificationicon.py standalone, then it comes back correctly (maybe it's related to live source code reload, so it's does not affects normal users)
  - ZeroNet must run in --debug mode
- "This is my site" should be enabled on sidebar
- Javascript console (F12) must be opened with "Disable cache" enabled on network tab
 you can try deleting all.js and see whats happening in the log/console
  There is only small ammount of strings in the source code, so it's not planned
  I dont have that button, so no cant test it, but i think it happens if you try to set json_id value by hand
  If you include the recommended content to your page (eg. using simple `<img>` tag), then it will be downloaded for offline viewing.
  The proxy owner has to increase the opened file limit:
http://www.cyberciti.biz/faq/linux-increase-the-maximum-number-of-open-files/
 python and the gc should take care of closing not used files

i think this problem is caused by too many socket opened and not fd "leaking"

for my client:
```
$ ls -l /proc/29511/fd | grep /home | wc -l
3
``` @WalnutATiie Can you please check these commands?
```
$ ls -l /proc/13302/fd | wc -l
211
$ ulimit -a
Maximum size of core files created                           (kB, -c) 0
Maximum size of a processâ€™s data segment                     (kB, -d) unlimited
Maximum size of files created by the shell                   (kB, -f) unlimited
Maximum size that may be locked into memory                  (kB, -l) 64
Maximum resident set size                                    (kB, -m) unlimited
Maximum number of open file descriptors                          (-n) 1024
Maximum stack size                                           (kB, -s) 8192
Maximum amount of cpu time in seconds                   (seconds, -t) unlimited
Maximum number of processes available to a single user           (-u) 5897
Maximum amount of virtual memory available to the shell      (kB, -v) unlimited
``` At startup ZeroNet tries to modify the it's limit to 2048, I just found a bug in that code, so please update and try again: https://github.com/HelloZeroNet/ZeroNet/commit/6f2445c417e59c3bf948ff5c3fd0a722c710f9d3 My client running since 3 months and it has 223 opened files, so I don't think if there is any any FD closing problem. 
ZeroNet very rarely close sockets, (check every 10 minute if the site has more than 10 connections) since it required to receive and distribute new updates. To reduce you can try to disable ssl via `--disable_encryption`, disable tor `--tor disable` and change `--connected_limit`, but I think it's safe to increase the limit, for example Debian 8 has 65536 as default.

https://console.cloud.google.com/cloudshell

```
$ ulimit -a
...
open files                      (-n) 65536
```  Can't reproduce on windows 10, earlier windows probably works, but not fully supported.

Alternatively you can install the come extension that adds a button next to the address bar to easy access:
https://chrome.google.com/webstore/detail/zeronet-protocol/cpkpdcdljfbnepgfejplkhdnopniieop
  You have to use target=_top on links to make it work
  If you want to open the browser, then use start.py
  By default zeronet is using (and writing) the zeronet.conf from the working directory (where the zeronet.py file is), so it does not writes to /etc.

You can specify the path of the config file by `--config_file anyfile`
  You need to start it using `zeronet.py --ui_ip "*"` then the remote machine will able to reach it using http://yourip:43110 (you can add --ui_port 8080 if you want that port instead of 43110)

More info:
http://zeronet.readthedocs.io/en/latest/faq/#is-it-possible-to-install-zeronet-to-a-remote-machine
  You have to know your exit node ip to avoid re-connect to yourself and it's also allow to put yourself on the map (helps you to verify Tor is working)
  please try delete data/content.db and try again
 That "can't start new thread" error does not looks good, no idea why.

to locate openssl we use this:

```
$ python -c "import ctypes.util; print ctypes.util.find_library('crypto')"
libcrypto.so.1.0.0
```
 Me.ZeroNetwork.bit/?Post/1RedkCkVaXuVXrqCMpoXQS29bwaqsuFdL/13Z7XxTa7JuFat3KzzMWu3onwM6biLuurJ/1484814283
@Ysc3839 find out that if set threading.stack_size to 32768 the "can't start new thread" error sloved ![image](https://cloud.githubusercontent.com/assets/15062548/22105327/69ea2802-de7e-11e6-84b2-7ca4ca7e35df.png)
zeronet runs so great on router
![image](https://cloud.githubusercontent.com/assets/15062548/22106348/4abb0564-de83-11e6-94a6-37127e57e1cf.png)
without any error
![image](https://cloud.githubusercontent.com/assets/15062548/22106617/87cb2bcc-de84-11e6-9c4b-7e966e4fdc47.png)
  Nope, it's not possible, the frame is required for security reasons, since every site is using the same domain (127.0.0.1) and it can be also used to delete the site immedietly if you don't like the content of it. (you can open the sidebar by dragging it to left)
  It would be against the network relability. If you don't like the content of the site, then you can delete/pause it or you can use a proxy to browse sites.
  You need `ProxyPreserveHost on`, example:

```
<VirtualHost *:443>

        ServerName zeronet.example.com

        ProxyRequests off
        ProxyPreserveHost on
        ProxyPass / http://127.0.0.1:43110/
        ProxyPassReverse / http://127.0.0.1:43110/

        <Location /Websocket>

                ProxyPass ws://127.0.0.1:43110/Websocket
                ProxyPassReverse ws://127.0.0.1:43110/Websocket
        </Location>


        SSLEngine on
        SSLProxyEngine on
        SSLCertificateFile /etc/certs/cert.pem
        SSLCertificateKeyFile /etc/certs/privkey.pem
        SSLCertificateChainFile /etc/certs/chain.pem
</VirtualHost>
```
  - I think cross-site favicon is not really a good idea: you have to seed the other site just for the favicon file
  - `./uimedia` will not work for http://127.0.0.1:43110/mysite.bit/otherdirectory/
 Thanks for the PR, I have implemented it using a simpier solution in Rev1703
  It's looking good for me, but the default favico will not work this way, because it insert "src/Ui/media/img/favicon.ico" as url, you need "/uimedia/img/favicon.ico" there.
  every zeronet site is running from the same domain (127.0.0.1), so it would be a security issue to allow same origin access, but you can modify the hash/query using `window.top.location = "?something#hello2"`
or wrapperPushState/wrapperReplaceState zeroframe api commands
 you able to reach the get parameters directly, using window.location.search (you need to remove `wrapper_none=.*`)
if you call `Page.cmd("innerLoaded")` command the hash will be applied to the inner frame, so you can reach it using window.location.hash

```
> window.location.search
< "something&wrapper_nonce=22f998ea92f1e2574c72cdc96ba7d479d9c1aec8fa31e3873047cbb61987f784"
> window.location.hash
< ""
> Page.cmd("innerLoaded")
> window.location.hash
< "#hello"
```

But if you trying to do url-reflected state management, then use `Page.cmd("wrapperReplaceState", [{}, "Page1", "?state1=ok"])` to change url
  Thanks!
  Thanks, but created a a hand-crafted one instead: https://github.com/HelloZeroNet/ZeroNet/blob/master/CHANGELOG.md
  there is a multiuser plugin, but if you care about your privacy you should run two separate installation in tor always mode (start the second one eg. with `--fileserver_port 15442 --ui_port 43111`)
 It works for me, but its created for proxies, it's very easy to connect your accounts if you posting on both using the same connections.
 you can use `--multiuser_local` to disable that restriction
 Someone can connect to many peers, then log first source of the update and by that finding the poster's ip/onion address. If you using the same client to post to multiple account, then you will use the same ip/onion address/connection to send the update, so it's possible to find out, that the two account owned by the same person. @aemxdp
Yeah, more peer means more privacy.
If B is close to C and A is far, then it can be possible to receive the update faster that way, than directly from A.
  I have downloaded the browser and can confirm it's not working properly. The only solution I have found is setting cookie controll to allow third part on page about:preferences#shields.

It's a known problem: https://github.com/brave/browser-laptop/issues/2417 I will try to find a workaround later.
  It should be fixed in 0.5.0
  `zeronet.py --proxy 127.0.0.1:9050 --tor disable` worked last time i tried. Upnp punching will fail on tor, this is normal.
 It looking good, you need the webui should be accessible on http://127.0.0.1:43110/ (it's possible that you need to add 127.0.0.1 to firefox's "ignore proxy for" settings)
 you can try to add --ui_ip "*" and access is using other ip you have
  Can you please specify the usecase? I think if someone specify a proxy (eg. tor) it means he/she wants every connection to use that. Even a local network connection could lead loss of privacy.
 Then probably it would be better to create direct connection only to 127.0.0.1 and specified proxy (tor or sam) ips
  Thanks!
  A manually written changelog has benn added: https://github.com/HelloZeroNet/ZeroNet/blob/master/CHANGELOG.md
  Thanks, but I did not wanted to add more complexity to the update mechanism. The [ZeroNet based updater](http://127.0.0.1:43110/1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp) only download the changed files, so if you need to save your bw, then please use it.  Try delete data/content.db and try again
  ZeroNet does not have any server-side (python code) support, so I don't think it's related in any way
  Can you please specify your os/version you running?
 I was able to reproduce and fix it, please update to latest version (Rev1534) by `python update.py` and run again.
  Can you please paste your js console content? (F12)
 Yes, thanks for reporting i'm going to fix it soon
 I was unable to reproduce the problem, but made some modifications and added new log messages. Please try now, if it's still not work pelase post the js console lines that appears when you press the button.
 You can ignore that error, probably just one of the users file is not distributed corrently. (you can check the missing file on sidebar when the site is opened)
 Got it & replied!  Can you please check what happens if you shut down zeronet (using zerohello 3dot menu), rename ZeroNet.app to ZeroNet.command and start executing it?
  Thanks for reporting, i was able to reproduce and fix the problem, the modifications will be released soon!
 Yeah, it's not public yet. (I have made many modifications that needs more testing before relese) 

It will be out with the next major version, that is planned for the next week.
 Big site support fixed in 0.5.0
 Yes, every peer is equal in zeronet, so when someone connects to the site it's try to download content.json from random peers, so if most of the peers has the old version then probably it will download that one.
 You can't force peers to increase size, so they will reject the invalid content.json files and serve the older ones until they increase the size.
So your options for larger sites:
- Merger sites: Create multiple merged sites eg based on categories or upload date (recommended)
- Add multiple content.json files using includes, so the root content.json will be always valid, but the included content.json files will be rejected if its larger than the allowed size
- Optional files: it's not for database/dynamic files, so it's not recommended
 Yeah, a notification on ZeroHello is a good idea, i will check whats the possibilites on that.
You can store more than one category in one merger site, it does not requires much modification in the site code, it allows the users to choose which categories are they interested in and also allows anyone to create new data source or make modifications in the display logic and publish it as separate merger site.
 I have added a section for the sites that about to running out of limit:
![image](https://cloud.githubusercontent.com/assets/10350359/20578953/40abc47c-b1ca-11e6-8657-54a8e258cda2.png)
 If a merged site is running out of limit and you click on it, then a dialog appears: 
![image](https://cloud.githubusercontent.com/assets/10350359/24800778/d324f60c-1ba1-11e7-96b0-355b75fddde0.png)

But yeah, this dialog could also appear if you browsing the merger site itself. Yes, by default the sites are still limited to 10MB. (optional files included in that limit)  The document using tor project's debian repo, so you will always get the latest version: http://zeronet.readthedocs.io/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
  Thanks for reporting fixed in latest version: 3331e2305b02c660736c8c6970ffb561e6e85e39
  I have just tested it on same enviroment and works for me, zeronet.cmd contains relative path to included python.exe, so it should not affect it. If possible please provide full error message.
  You have to execute commands after the "onOpenWebsocket" called in ZeroFrame (see the chat tutorial on ZeroBlog for example)
  This error was fixed earlier, please update to latest version: https://github.com/HelloZeroNet/ZeroNet/commit/ca2a30f7ae266b4ad437e5ed24986b0ce45f67db

The size errors is because the user files are indexed in your data/users/content.json file. You have to add "ignore": ".*" to that file, so it won't interferrence with user signed contents.
  Thanks!
  Thanks, it would be better if the tor installation would be also based on `ENABLE_TOR` (tor binary starts automatically after the setup and vps providers looks for that)
 Thanks, looking nice!
  the file data/users/content.json is referenced in root content.json, but it's not signed/found.
  Lots of VPS (most?) providers makes your account suspended for running Tor, so I think we should not start it by default.
  It will allow more advanced optional files handling and 
## Help distribute specific directories
- New API command: optionalDownloadList
- New API command: optionalDownloadSet [patterns]
## Global size limit optional files

Specific size or % of HDD free space
- Keep track downloaded optional files size
- Cleanup by peer number and last access time
## WebUI to manage optional files
- Display total optional files / limit
- Modify limit
- Display downloaded optional files
- Order by Size/Peers/Uploaded/Added/Used
- Manage signed up directories
- Group by site
## Add image upload to ZeroMe
- Image upload with resize
- Checkbox to help distribute user's files
## Plan
- [x] Create optional file manager mockup
- [x] Fill optional files to a database
- [x] Update optional file database on loadContent / removeContent
- [x] Update optional file database on download complete
- [x] Update access_time
- [x] Update downloaded number stats
- [x] ZeroFrame API command to query current peer number for files
- [x] Always allow fileDelete on optional files
- [x] Update optional file database on fileDelete
- [x] Update peer number in database for optional files
- [x] Delete optional files based on peer number
- [x] Auto download optional files based on optionalDownloadList
- [x] Make OptionalFileDelete merger site compatible
- [x] Save/Restore peers to/from database
- [x] Auto pinning my files
- [x] Try guess and pin my files on first startup after upgrade
- [x] Set optional files limit based on current size of files on first startup after upgrade
- [x] FF/IE Edge test

Manager UI
- [x] Static html version
- [x] Site listing
- [x] File listing
- [x] Select files
- [x] Limit bar
- [x] Limit modification
- [x] Files paging
- [x] Manage/remove followings
- [x] Table sorting
- [x] Display pinned files
- [x] Pinning
- [x] Deleting
- [x] Faster total limit usage calculation
- [x] Empty state
- [x] Message for older versions

ZeroMe
- [x] Image upload UI
- [x] Generate preview
- [x] Resize image
- [x] Save image to data.json
- [x] Lazy display image preview
- [x] Load big file on click
- [x] Show peers for files
- [x] Help distribute images checkbox for the user
- [x] Image uploading
- [x] Downloaded image delete
- [x] Delete image when post deleted
- [x] Message for older versions No, this is for ZeroNet files. Originally I was tried to add torrent support, but after some experiments I dropped it for now, because it would be hard to make it work with Tor and I want to avoid confusions, so maybe after i2p support.
 Added to 0.5.0
  you need to use the master_seed value to login
  you can use --ip_external any.ip.you.want, but the trackers will add the originating ip
 trackers works like this: you send a request to a computer, this computer stores the request's originating ip address as potentional source of the website
 It's probably because your proxy does have opened port that is directed back to your computer.
 It's not possible, the trackers will always store your proxy ip
 If you specify --ip_external, then it will skip the port open check, but the end result will be the same: nobody will able to connect to you, only you able to connect other computers
  Thanks for reporting, it's fixed in latest Revision: 60dd797d1a99605099885de5b9a7f050cd16a312

It happens when the file you want to write is in "bad_files". It means the file has been referenced/tried to download before, but it was failed. (You can check bad files in the sidebar)

To ignore this dialog you can use `Page.cmd("fileWrite",{"inner_path": path, "content_base64": previewImgUrl, "ignore_bad_files": true}...`
  For me it does not works. (Tested by starting UpnpPunch.py)

```
>UpnpPunch.py
DEBUG:root:Trying to open port 15441.
DEBUG:root:Found local ips: ['192.168.1.13', '127.0.0.1', '169.xxx.xxx.137']
DEBUG:root:Trying using local ip: 192.168.1.13
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
DEBUG:root:200
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
DEBUG:root:200
DEBUG:root:Trying using local ip: 127.0.0.1
DEBUG:root:Upnp request using "127.0.0.1" failed: No reply from IGD using 127.0.0.1 as IP
DEBUG:root:Trying using local ip: 169.xxx.xxx.137
DEBUG:root:Upnp request using "169.xxx.xxx.137" failed: No reply from IGD using 169.xxx.xxx.137 as IP
DEBUG:root:Trying using local ip: 192.168.1.13
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
DEBUG:root:200
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
DEBUG:root:200
DEBUG:root:Trying using local ip: 127.0.0.1
DEBUG:root:Upnp request using "127.0.0.1" failed: No reply from IGD using 127.0.0.1 as IP
DEBUG:root:Trying using local ip: 169.xxx.xxx.137
DEBUG:root:Upnp request using "169.xxx.xxx.137" failed: No reply from IGD using 169.xxx.xxx.137 as IP
DEBUG:root:Trying using local ip: 192.168.1.13
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
DEBUG:root:200
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
DEBUG:root:200
DEBUG:root:Trying using local ip: 127.0.0.1
DEBUG:root:Upnp request using "127.0.0.1" failed: No reply from IGD using 127.0.0.1 as IP
DEBUG:root:Trying using local ip: 169.xxx.xxx.137
DEBUG:root:Upnp request using "169.xxx.xxx.137" failed: No reply from IGD using 169.xxx.xxx.137 as IP
Traceback (most recent call last):
  File "E:\Web\Today\ZeroNet-upnp_update\ZeroNet-upnp_update\src\util\UpnpPunch.py", line 334, in <module>
    print ask_to_open_port(15441, "ZeroNet", retries=3)
  File "E:\Web\Today\ZeroNet-upnp_update\ZeroNet-upnp_update\src\util\UpnpPunch.py", line 314, in ask_to_open_port
    fn=_create_open_message)
  File "E:\Web\Today\ZeroNet-upnp_update\ZeroNet-upnp_update\src\util\UpnpPunch.py", line 306, in _communicate_with_igd
    port, retries))
__main__.UpnpError: Failed to communicate with igd using port 15441 on local machine after 3 tries.
```

Using the old (current one):

```
>UpnpPunch.py
DEBUG:root:Found local ips: ['192.168.1.13', '127.0.0.1', '169.xxx.xxx.137']
DEBUG:root:Trying using local ip: 192.168.1.13
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
True
Done in 1.21499991417
```
  Sorry, we can't help, since this issue is not related to zeronet itself, but to a site that's on the network.
  Can you please run `zeronet.py sitePublish 1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D` then paste log/cmd.log file's content here?

And also the output of `python -c "import gevent; print gevent.version_info"`
 Same here, so probably that tracker is down. I will find an another one instead of that, until then removing it from src/Config.py should fix it. (needs more investigating why is it spamming the stdout with that error)
  Please try to check log/debug.log for errors.
  I usually tag new version in github later, because there could (and usually there are) be bugs in new version: so if you want something safe then use the releases tab, if you want to be on edge, then download the latest commit.
 Ok, good idea, I have tagged the latest revision with 0.4.1-rc: https://github.com/HelloZeroNet/ZeroNet/releases

Looks like Github does not allows to change the tag's commit, so probably 0.4.1-rc will not reflect the latest version.
  This is normal, you should able to access zeronet on http://127.0.0.1:43110/
  I have not tried it, but you probably need something like this: https://play.google.com/store/apps/details?id=at.bherbst.net

You can use for example this site to check if the port forward is successful: http://www.portchecktool.com/
 If you use tor always, then it does not matter, your port will be close every time.
  Please try to sign/publish it using the sidebar (drag topright zero button to left)
 There was an error that affected siteCreate and siteSign command, it should be fixed in the latest Rev1510. Please upgrade (Click on 3dot menu on zerohello > Version 0.4.1...) and try again.
 The previous versions has not added the newly created site to sites.json correctly and probably that caused the error, it should work now.
 You have to create new site to fix it.
 if you still have the error, then please run it with zeronet.py --debug ... and paste the full log here
 This looks normal, whats the exact problem?
 You can ignore the "SiteManager Save error: No sites found" error.

I have just tried and works for me:
- Stopped ZeroNet
- zeronet.py siteCreate
- Started ZeroNet
- Clicked the new site's link on ZeroHello
- Modified the title
- Signed it
- Loaded the site on a remote machine
- Modified the .html file
- Signed/Published it
  Fixed 0.5.1: https://github.com/HelloZeroNet/ZeroNet/commit/8b7bd2d5720262273ccdf88e52835075b4460081  Thanks for reporting it should work now: https://github.com/HelloZeroNet/ZeroNet/commit/dae5cd396931db239560a3d2e4b5ff225fbad5d4 (the first startup after the update will be slow, because it has to generate the content.db cache)
  RSA is only used to generate proof-of-tor-address (to avoid some attacks) and not used for encryption at all,so i think it should be fine.
  It would be a huge security risk (any site would able to access and modify all other site's data). Disqus-like plugin would result in centralization, which is agains the main goal of the project. Embedding a video does not requires iframe: with the future youtube plugin you will refer the video as the hash.
 The problem is if you can include other site in a frame, then you can execute zeroframe commands as the site (eg fileWrite)

IndexedDB ZeroFrame API command could be possible, but it's harder than localstorage, because there is more functions and you cannot pass javascript object, so you need to pass every command to the external wrapper.
 I'm afraid this is the limitation of browser's iframe sandbox. Do you have any idea when did it worked for you last time?  I think the benefit would be minimal: js/css files recommended to be merged (so the hash does not match and the sizes are also negilable) and the data files are dynamic/unique

you can use webtorrent to share big files between sites and adding built-in torrent client are also planned.
  It's normal, if you computer is too slow for it, then it's stops the animation
 sorry, if you dont have any javascript error, then i have no idea
  There is irc on freenet and also on gitter: https://gitter.im/HelloZeroNet/ZeroNet
  Thanks, but I see no real changes in the new version  Yes: https://chrome.google.com/webstore/detail/zeronet-protocol/cpkpdcdljfbnepgfejplkhdnopniieop
  probably you try to access it using https or similar, maybe the javascript console (F12) network tab can give more information
  Sorry, it's not possible to help you based on the provided informations. Please give more information: JS console messages, ZeroNet log messages, OS, Browser, etc.
 Thanks, based on the js error i was able to reproduce/fix it
 @DaniellMesquito You don't need to upgrade ZeroNet, the change is only in ZeroHello site's source code which should happen automatically.
  probably the peers are not connectable or offline, so you can't publish it to anyone
 The peer number is shows the possible peers (ip addresses who have visited the page recently). They can be offline/not connectable or maybe they already removed the page. You can see the connected peer number in the sidebar and the publishing result is in file log/debug.log

I have closed the issue, because the problem is probably in the site/network connection since the publishing is used many times per minute.
  ZeroNet has to shut down for updating, so unfortunetly since it's not running it's not possible to give any feedback to the user, but if you have Console/Terminal opened, then the update process is visible there.
 Creating / closing new ports/sevices could have some delay (or cause some other problems for example in firewalls) and the update process should not take more than some seconds, so i dont think it's worth developing a separate webserver / popping up a window for that. The zeronet startup speed can be slow on hdd based systems, but it will be improved in the near future.
  This is normal: zeronet shuts down , download the latest version, then starts up (could take couple of minutes depending on your net/cpu/hdd speed)
  You can use git if you want, but i dont see why is it necessary
 Probably ZeroNet will not work on connections where downloading 2.5MB is a problem.
 Most of OS does not have git installed, so it would require to pack/maintain git for every platform which is for example 31MB for windows. (https://git-scm.com/download/win)
 It's already possible: if you have git installed, then you can update it from github.
  It downloads the latest zeronet-master.zip (2.5M), then unpacks it.
  Other addresses are not planned.
  It's not possible to change the site's address
  I want to maximize the testers of the new versions/revisions, so everyone will get the "Alpha"
  Thanks for reporting, fixed in latest version
 The latest: Rev1429
 you can use the 3dot menu in zerohello > Version 0.4.0 menu item. Or simply download it from github and overwrite the files
  Change the start.py to zeronet.py in the end of the third line in zeronet.cmd
 it's similar: replace start.py with zeronet.py in ZeroNet.sh

https://github.com/HelloZeroNet/ZeroBundle/blob/master/ZeroNet.sh#L5
  Since last week it possible to download and update the source code via the ZeroNet network, which verifies the data integrity by checking the signiture, but I will look at pgp signing releases Added signing to git commits: https://github.com/HelloZeroNet/ZeroNet/commit/901478475fb15a910d3c99ccb161730b4e84ca25  It's normal, you can ignore it. To make it accessible from other computer you need an open port or tor installed.
  Its caused by infinityhub, you can remove it or update to latest version of zeronet which is fixes this issue 
  I was unable to reproduce it, can you give me pelase more details on what kind of data you want to sign? And maybe pelase check the log/debug.log if there any any more error message around it.
  Try python -m pip install -U gevent
  Are you sure `data/yoursiteaddress` directory is exists? Please try using siteSign eg.: `zeronet.py siteSign 1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D --publish`
  The XSS is not really an issue on ZeroNet because of iframe sandboxing and we have no POST/GET api, but it would be good to add it as a plugin.
Also worth checking: https://github.com/kustomzone/Fuzium  no yet, but you can use GNURoot (https://play.google.com/store/apps/details?id=com.gnuroot.debian) and install it using: https://github.com/HelloZeroNet/ZeroNet#manual-install-for-debian-linux
 It's still there:


Manual install for Debian Linux
sudo apt-get update
sudo apt-get install msgpack-python python-gevent
wget https://github.com/HelloZeroNet/ZeroNet/archive/master.tar.gz
tar xvpfz master.tar.gz
cd ZeroNet-master
Start with python zeronet.py
Open http://127.0.0.1:43110/ in your browser

There is also an experimental .apk: https://github.com/HelloZeroNet/ZeroNet-kivy  https://github.com/HelloZeroNet/ZeroNet clone or download button

But if you download zerobundle it will download the latest version for you and it also have a built-in updater if you have earlier version.
  Please in english
  Please check the log/debug.log file, it should look like this:

```
[2016-08-09 03:34:31,642] ERROR    TorManager Tor controller connect error: error: [Errno 10061] No connection could be made because the target machine actively refused it. in TorManager.py line 154 > socket.py line 342
[2016-08-09 03:34:31,644] DEBUG    TorManager Tor proxy port 127.0.0.1:9050 check error: No connection
[2016-08-09 03:34:31,645] INFO     TorManager Starting Tor client tools/tor/tor.exe...
[2016-08-09 03:34:32,148] DEBUG    TorManager Connecting to 127.0.0.1:49051
[2016-08-09 03:34:33,153] DEBUG    TorManager > PROTOCOLINFO
[2016-08-09 03:34:34,118] DEBUG    TorManager < 250-PROTOCOLINFO 1 
```
 probably firewall or something is blocking tor.exe port. you can enable logging by removing # from line `# Log notice file data\notice.log` in tools/tor/torrc file
 do you have data directory where the tor.exe is?
 Sorry, no idea, maybe firewall blocking it. I just tried and it's works for me. (also win10)
  have you tried to starting it with `zeronet.py --max_files_opened 10240` ?
 If you start zeronet using --debug then you have some more detailed http://127.0.0.1:43110/Stats page. Please paste the first ~10 lines of the "Objects in memory" section and also the number in the "Sockets (*):" section
 Please try to save this file: https://gist.githubusercontent.com/HelloZeroNet/d9bf888693e66a573815/raw/aeb189142e0be33b0253af5ddb8c241c49a95ce9/test_max.py
and drag to a terminal.
It tests how many files can a python process open.
  Looks like your ZeroNet/src/Ui/template/wrapper.html file is broken somehow. Can you open it in notepad? It should looks like this: https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/template/wrapper.html

Please try to shut down zeronet, copy the old ZeroBundle/ZeroNet/data in place of your new installation and start again. Is the problem still exists? 
  Sorry, but it's not possible to help you based on this amount of information. Please specify your os version/installation method/etc.
  I think the best would be a separate plugin, so the development could be done outside of the ZeroNet core. (I also creating new features as a separate plugin to keep the core simple)
 If the plugin becomes mature enough, then it's possible to enable by default, but an appstore-like plugin interface is also planned where anyone can enable/disable/install plugins easily.
  Unfortunately its not possible, because the p2p websites are completely different from traditional client<>server ones
  I don't have OSX access, but double clicking was worked for me when I tried it. (probably depends on settings)

I have tried to create a proper .app package (https://github.com/HelloZeroNet/ZeroBundle/tree/master/ZeroNet.app/Contents), but it requires Apple Dev Account to sign it. 

If anyone would able to sign it, then i think it should always work as double clicking on it.
 @robinvandernoord Looks good, i will test it the next time when i get a mac access. Do you have any other suggestions to make it easier to install/start on mac?
 Probably 90%+ mac users does not have docker installed
  donwload failed for me, but probably you don't have it added as include to the root content.json, example:
https://github.com/HelloZeroNet/ZeroBlog/blob/master/content.json#L142
  it could be possible to develop a plugin to keep only eg.100 most visited sites
  it will download the source when you start it using zeronet.sh

for remote install: http://zeronet.readthedocs.io/en/latest/faq/#is-it-possible-to-install-zeronet-to-a-remote-machine
  Hi,

Is it possible to develop a private instant messaging ( like Tox ) ?
 Yes , and finally Tox has the Distributed Hash Table , so it is more interesting.
  Hi,

Is it possible to add to the ZeroNet network, the concept of AlternativeTo ?
Every application has alternatives and it is listed in it.
People add the application and other check if it is the same theme / a proper alternative
And everyone can vote for their favorite applications.

http://alternativeto.net/software/alternativeto/
Currently this concept is not open-source and not distributed.
 This is an idea of application on this network ;)
 Some can delete softwares , like owncloud
7th april 2016 : https://ipfs.pics/QmcRwEMDZVwNJZ4wjrnHRYuWP6trLYAyVqCGLHqPHT8GeR
now there is no owncloud listed in the application server

and it crashes sometimes with ASPx
  Hard to tell, but you can use Tor's OBFS proxy project to avoid it.
https://www.torproject.org/docs/pluggable-transports.html.en

Easiest way to to this is install Tor browser bundle, start it then start zeronet using `zeronet.py --tor_proxy 9150 --tor_controller 9151 --tor always`
  you only need to publish it if you already have visitors, who downloaded your site before
 yes, it should work. zeronet does not support local peer discovery yet, so you need external ip or tor connection
  zeronet does not knows/tests your public ip address (only the exit node) when running in tor mode, so it's not possible
  use ls -al /var/lib/tor/control_auth_cookie instead then follow: https://zeronet.readthedocs.io/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
 You need to add `ExtORPortCookieAuthFileGroupReadable 1` to tor config, `usermod -a -G tor [yourlinuxuser]`, re-login, and restart, then it should work
 there is an another option, please try this one: CookieAuthFileGroupReadable 0|1
 The permission error come from the operating system, it not really a zeronet issue, please re-check every permission/tor logfile/tor documentation/etc.

if your linux user not able to read the `/var/lib/tor/control_auth_cookie` file, then zeronet wont be able to do so
  its currently stored in browsers local storage, later something more persistent are planned
   it's depends on how long have you been running the client (it requests around 50peer/5min) and what other users have you been exchanged peers.
It's not an issue, there is no real benefits between having 30 vs 600 peers on a site.
 well there is no leechers in zeronet, so peers = seeders 
  more specifically the problem(?) is in https://github.com/chjj/marked js lib  it should work between tor-only peers (please not there is some warmup time on tor hidden services, so you have to wait 1-10 minute after you created your site)

are you sure are you running in tor only mode? it should display "Successfully started Tor onion hidden services." message then (https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/UiWebsocket.py#L68) then. 
  OK,, I think renaming to --tor manual would be more straightforward, because it could be also useful without VM
  Is this problem gone? What was the problem?
  you are probably doing something wrong: out of limits/invalid files/etc. 
keep try sign + publish again and check logs
 you can check the problematic files using the sidebar. File update failed means something is broken with the site and not with zeronet. It can be file that is referenced in the source code but not distributed to the network or an invalid optional file. the 0chan site owner has to add data/.*db to ignore pattern to make the problem desappear. eg. https://github.com/HelloZeroNet/ZeroBlog/blob/master/content.json#L141
  its already done: 
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/UiRequest.py#L352
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Worker/WorkerManager.py#L317
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Test/TestSiteDownload.py#L34
  probably you have changed data/users/content.json and have not signed/published it or it's invalid
 try edit your comment on zeroblog, if it does not drop error then the problem is in your site. try delete/readd it and check if every file is synced
  it is configurable, use: --fileserver_port 1234
  I'm not sure about this. If you make any changes to your site's source you should try it if it's works or not (using the web interface) and it will be compiled on the file request.
 It's probably caused by your browser's caching. (all.js generated when its http requested) You should open the dev tools (F12) and check disable caching when developing
 you can use `python -c "import distutils.spawn; print distutils.spawn.find_executable('coffee')"` to check if coffee binary is visible by python or not. Or you can use `--coffeescript_compiler "/usr/local/bin/coffee --no-header -p"` to define the path of it

you also need to enable "this is my site" option on the sidebar to enable compiling
 are you sure you have enabled the  "this is my site" option on the sidebar?
 start it using `--multiuser_local` to remove that limitations
  the re-compile executed when the .coffee modification date is newer, than all.js. Maybe adding 1 second window could solve the problem. Can you check the src/Ui/media/lib/ZeroWebsocket.coffee vs src/Ui/media/all.js modification date difference?
  probably something with the coffeescript compiler, please check console/logs (use --verbose if necessary)
  since the latest commit, when the files created for the first time now it defaults to r/w by user only: https://github.com/HelloZeroNet/ZeroNet/commit/523a7d4c16e8c2f590e759e23f0d2d6ae36cff37
  it's probably router/os firewall configuration issue. you can use http://portchecker.co/ to check if the port opened or not
  you can add your user to debian-tor group, so it will able to read it: http://zeronet.readthedocs.io/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
 you can use the CookieAuthFileGroupReadable 0|1 configure option 
via https://www.torproject.org/docs/tor-manual.html.en

reading the cookie file should remain possible, to allow reconnect to tor control port later
  normally it should not happen: https://github.com/HelloZeroNet/ZeroNet/blob/master/src/util/helper.py#L12
- It writes new content to data/sites.json-new
- Renames current to sites.json-old
- Renames sites.json-new to sites.json
- Deletes sites.json-old

Have you checked the sites.json content? Was it incomplete or random bytes? Was there sites.json-old file?

Im not sure if sqlite is a good solution to store configuration files, because it's harder to edit.
  Thanks!
  History/Cookie and some functions manipulations are restricted by browser iframe sandbox
 You can't use replaceState (url modification) functions directly, maybe it's possible to disable in jquery mobile
 Yes, if it's works on one machine, then it's different problem, are you sure every file is well synced?
 I mean are the files has the same content?
 check the directory sizes should be enought
 It does not affect us, since the replace/push state command is executed outsite of the iframe by zeroframe api commands  ZeroNet site addresses are 100% compatible with bitcoin, so you can use:
https://bitcointalk.org/index.php?topic=25804.msg321135#msg321135
 Easiest way:
- Generate an address/privatekey with vanitygen
- zeronet.py siteCreate
- Rename data/createdsiteaddress to data/vanityaddress
- zeronet.py siteSign vanityaddress vanityprivatekey
- visit 127.0.0.1:43110/vanityaddress
  There is no "official", but there is polls at: http://127.0.0.1:43110/zeropolls.bit
  The root of the problem is currently it's need to load every content.json on startup. (if you start it using `--debug` or check log/debug.log you will see the load time per site) So if you have many site added and running the client from hdd it could take some time. (SSD performs better on loading many, small files)

There is multiple possibility to solve this:
- Lazy load content.json files to memory (only when requested by the client eg. need to verify a changed file). I have already made it working as experiment and it's also dramatically reduces the memory usage (80MB->40MB), but there is some command (list all content.json newer than X date) that needs to check every file. To workaround this problem maybe we should index the content.json modification date in a db or simple json file.
- Instead of using raw file system we could store the content.json files in database (Sqlite or Berkeley DB) I have also made benchmark on this, the results on an crazy slow, overloaded VPS (loading and parsing content.json from a site with 5000 users):

```
sqliteRead  | 3.992s Mem: 10.50MB(+0.92MB)
bsddbRead  | 2.624s Mem: 11.11MB(+0.61MB)
jsonRead  | 331.137s Mem: 11.11MB(+0.00MB)
```

File size:
- On FS: 3.2MB
- Sqlite: 6MB
- Bsddb: 5.7MB
  Thanks it was fixed some months ago: https://github.com/HelloZeroNet/ZeroNet/commit/dafe9981a241e5ff170bd989abcd77e85acaf3aa  It's hard to tell, please specify your browser and also try it in an other one
 do you have any antivirus software installed?
 Added a custom debugging, please save it to ZeroNet/src/Ui dir the restart and see Path: ... debug lines
https://gist.githubusercontent.com/HelloZeroNet/b288fd7084b822612a3ae8b30b5c12b8/raw/f1ff543e58b07741b2c836a08f3a0ec8dcb54088/UiRequest.py
  yes `--data_dir ~/.local/shared/zeronet/`
  sorry, its not possible, but you can download the zerobundle version that is contains everything you need to run zeronet: https://github.com/HelloZeroNet/ZeroNet#how-to-join
  you can create site that accept self-signed certificates and not a third-party one. if you accept third-party one (eg zeroid.bit), then you accept the auth_address generated for that site
  cert_user_id should contain the cert signer's name
 you also need to add the certificate signer to data/users/content.json file
 I see this on that site:

```
...
  "cert_signers": {
   "nanasi": [ "16PmAP6z2MCJX9jNjvMrteMfnqX4KeDRNT" ],
   "zeroid.bit": [ "1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz" ]
  },
...
```

probably you have to sign+publish data/users/content.json
  You browser's bookmark function probably better suited for this
 you can also use the sidebar to delete/update/pause the site (drag the topright zero button to left)
  Fixed: d2d2967f11f0009547959b57e0f25d1e590da852
  whats your domain name? the problem probably is different
  Is the other domain based sites works for you? eg http://127.0.0.1:43110/talk.zeronetwork.bit
What directories you see in plugins directory?
What blank means? Total white page or anythign visible?
Is any error message in the javascript console? (F12)
  you don't need registration to visit any site. if you try to use any feature that is requires zeroid the site will redirect you to the id providers it accepts. i think it's pretty simple and hard to miss it
  There is many problems with webrtc:
- Not possible to create sandboxed iframe enviroment (cross-origin scripting problems)
- Tor connection not possible (Around 50% of ZeroNet clients using Tor)
- No SQL support
- File storage problems (max storage size per site origin)
- No support for non-web content (eg. github repository)
- You would need to keep an open browser tab for every site you seeding
- You private key would need to be stored by the browser, so any site you visit would able to access it
- WebRTC is created for small number of clients videochat system, not suitable to handling 100s of connections
 a light webrtc client would be possible that is allow to browse static (non-sql based) websites
 If we target browser extension, then we don't need to use half-p2p webrtc sockets and deal with other js limitations, but we can do create real sockets like https://deepankar.io/current_projects/details/kronymous do I have just opened webtorrent.io in latest chrome, it freezed my browser for 20 second, then started playing, but according to the dev console (F12) it downloads the video from https://webtorrent.io/torrents/sintel-1024-surround.mp4 and the webtorrent.io tab currently using 250MB of ram

I'm not saying webrtc or webtorrent is bad, but it does not looks mature to me. (or suitable to handle many connections)

Also webrtc connections not fully p2p, you need to contact to google (or someone) before create connection to anyone: "Unfortunately WebRTC canâ€™t create connections without some sort of server in the middle. We call this the Signal Channel. " - [via](https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API/Connectivity) > Okay, I guess I never tested it on a slower machine. But I don't think 250MB is bad, considering it has to keep at least 130MB of video in RAM.

I have i5 6600k (skylake) CPU, so it's not so slow. The GPU is running in separate process, so it's not includes that (if I open https://webtorrent.io/torrents/sintel-1024-surround.mp4 in a tab its displays 15MB)

> Well yes, but thats just bootstrapping right? 

No, it's not for bootstrapping (getting peer ips), but the both party need to connect to the STUN server every time before they want create new connection with eachother. I think it's for security reasons, to avoid DDOS attacks from webpages. (and add socket security) I don't really feel like to start developing it but, I would be happy if someone would do more experiments  and I'm open to add webrtc connection support to python client. Yes, the situation is totally different now: In webrtc you need to connect to STUN server before every connection you make. The torrent trackers is only required to get the list of the possible peers, but you don't need to connect and report them before every new connection you make.

Pex is supported and peers is saved to local database, so you can use previously known peers.  > According to this: https://github.com/cjb/serverless-webrtc/ (warning: shitty demo, barely works)

After tring it out the demo works this way:
 - Client A: Generate the the 4KB JSON
 - Client B: Based on the 4KB JSON generate a response to 4KB JSON
 - Client A: Using this response can connect to Client B

So I have no idea how could it work without any middle server. A tracker could store Client A's 4KB JSON, but you need the response to your 4KB JSON create the connection. According to this diagram you always need a signal channel to create new connections. Maybe this signal channel can be an another peer, but then both peer has to be connected to the same peer before they can create new connection to eachother. 

![image](https://cloud.githubusercontent.com/assets/10350359/20793789/252c5612-b7c9-11e6-92d1-1e336be0e822.png)
  you can send it to hello@zeronet.io, but it's usually caused by antivirus softwares/browser extensions

see https://github.com/HelloZeroNet/ZeroNet/issues/195
 according to logs your browser tries to use HTTP/1.0 instead of HTTP/1.1, not sure why is it happening (All common desktop browsers (Netscape/Mozilla, Internet Explorer, et al) in the last 10-13 years support HTTP/1.1.)
 its the same problem: your browser try to use a protocol (http/1.0) that is more than 10 years old. probably its caused by an antivirus software for some unknown reasons
 Here is a version that allows http1.0 connections please try to save it to ZeroNet/src/lib/gevetwebsocket to directory, restart zeronet and try again: https://gist.githubusercontent.com/HelloZeroNet/3ff4a0fe233fc5b4c153d7b475ac8b07/raw/85fef31da837d5f0a9bc9da96c7de1919050e3c8/handler.py
  Its not created by zeronet, few ideas: http://forums.whirlpool.net.au/archive/892927
  The old ZeroHello (1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr) is no longer actively supported, please switch to 1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D
  http://windows-exe-errors.com/how-to-disable-werfault-exe-in-windows/
  You can find a sql based chat tutorial at zeroblog
  Sidebar is not supported on mobile (i have no phone that allows to add/test mobile features)
 (reopened as mybe someone else has mobile phone access/able to add support)
 It's works in emulator (update: looks like it not, i will check it later)
 Fixed in latest revision eedce00d575d6edba83ec03f6c309f95883d0936 (at least it works in the emulator)
  It's not possible to change/shorten or choose your privatekey
  thx, fixed: 432aa037cbda0368ceb3b07dba526a8044eaa821
  thx fixd 93e598cc596c023b035507fe018c2163cad2aa32
  @Feeding It works by using ZeroName site's database. If you enable the ZeroName-local plugin it will use your local namecoin node
  on zeronet the current default site size is 10MB, wikipedia contains 10TB+ data (100000x larger), so it's not really possible yet
  probably your internet provider/router does not allow opened port
you can check it manually on page http://portchecker.co/ by entering 15441 to port it should display "Port 15441 is open."
  Currently content.json files stored on the file system and for fast access loaded at startup and kept in the memory.

To reduce memory usage (up to 20MB per site depending on user number) and faster read/write it can be stored in database using sqlite or the [anydb module](https://docs.python.org/2/library/anydbm.html)
#### Cons:
- More hdd load/json parse cpu load
- Json file editing by hand?
- Db corruptions
#### Benchmark results:

Files: 5408
Total size: 3.1MB
Size in sqlite: 5.8MB
Size in anydb: 5.6MB

Loading all files:

```
Init  | 0.000s Mem: 11.30MB(+11.30MB)
jsonRead  | 1.235s Mem: 11.39MB(+0.09MB)
sqliteRead  | 1.551s Mem: 12.53MB(+1.13MB)
bsddbRead  | 0.470s Mem: 12.97MB(+0.44MB)
```

the difference is even bigger on a vps with very slow/overloaded hdd:

```
jsonRead  | 693.805s Mem: 9.82MB(+0.25MB)
sqliteRead  | 10.896s Mem: 10.76MB(+0.93MB)
bsddbRead  | 7.671s Mem: 11.11MB(+0.35MB)
```
  Fixed https://github.com/HelloZeroNet/ZeroNet/commit/34ead0aec233293148602d2ab4a63096aa61af47, but still recommended to start without whitespace, since most of the clients will not execute it
  if its not in zerotalk/blog/mail, then it's not supported officially

https://zeronet.readthedocs.org/en/latest/site_development/dbschema_json/ include all supported features

i think custom trigger should work if you put it as index

sqlite version depends on platform
for me on Win/Python 2.7.9 

```
>>> sqlite3.sqlite_version
'3.6.21'
```

Linux/Python 2.7.9

```
>>> sqlite3.sqlite_version
'3.8.7.1'
```

SQLite Release 3.6.21 On 2009-12-07 so it's not advised to use any new sqlite features
  It could work, but it needs much deeper modifications of zeronet, and if the bundle owner decides to include 100+ sites over night it automatically downloads 100*10MB content on your hdd. This also means there is no motivation (size limit) to create new bundle sites.
And if the bundle owner decides to remove your site it will also make it unaccessible for the users, because they seeding the bundle site.
And also not sure how do you add your site to the bundle without knowing anything.

So i think there is not much benefit from it.
 Connection sharing between sites is supported, but its not really works well in sites with many peers, because when you query peers from the tracker you only get 20 peers and probably it will not include the ones you already connected with. And for privacy reasons the connection sharing is totally disabled on Tor. (new .onion generated for every site you seed)

So this would require many core changes and I think the normal (multiuser), hub sites could work equally well. If one of the profile you follow got removed by the hub owner there can be a notification of it and you can follow the same profile on an another hub.
  we will think about it when its become problem, https is more reliable, than zeronet protocol
 If it's common problem, then it can be possible.  you have to disable the zeroname plugin
 no, it's simple: if you want to use the plugin you need the site, if you don't want to use the plugin disable it
  the dns is optional, every site works without it.
 yes http://127.0.0.1:43110/1MaiL5gfBM1cyb4a8e3iiL8L5gXmoAJu27 works without any problem
 you have to modify the zerohello to link to non-domain url
 no idea, its just works that way
 a zeronet site can overwrite any of your decision, if you want to change it you are free to clone/modify it or you can use your browser's bookmark function, so it will point anything you want
 you have to own the site's private key to modify it
 the files cached in the memory, you have to restart your client make it work
 the modifications will be reverted on the next modification on the site, so it's not a good idea to modify file you dont own.
  i'm assume you are not using the standard installation, because by default the config file is located at zeronet's directory and not in /etc.

you have to add `tor = always` to `[global]` section
  This makes the iframe sandboxing ineffective (required, because every site is served from same host: 127.0.0.1)
 Disabling the same origin protection would allow any site to access or delete other site's data.

I think webrtc based p2p video is never going to be a reliable solution, because the peers only seeds it until they are on the site, but it could be possible to create a videoplayer plugin that allows you to display videos using DASH/WebTorrent outside of the iframe. (like the sidebar plugin)

Probably the best/sustainable solution for videos would be a plugin that acts as a full torrent client (not webrtc based) and allows you to stream/share/seed videos to/from real torrent network.
 There is an api command to read/write localstorage: https://zeronet.readthedocs.org/en/latest/site_development/zeroframe_api_reference/#wrappergetlocalstorage
but i think you will run into other sandboxing limitations that makes it impossible
 I think this is required by webtorrent, but also disabled by the sandboxing: https://developer.mozilla.org/en-US/docs/Web/HTTP/data_URIs (not sure why is it disabled)
 files larger than 1MB is not supported yet, so dl tracking is not any useful
 Most of the users are using ZeroNet from Tor, which is not suitable to distributing big files, so using other network for this purpose is a better idea (eg. torrent). There is no streaming file support in zeronet which makes the progress reporting not possible yet.
  you can use socks5 proxy using `--proxy 1.2.3.4:4321` command line parameter

ipv6 not supported yet
  you can run it on android using GNUROOT, but it's better solution if you put it on remote machine that has persistent internet connection: http://zeronet.readthedocs.org/en/latest/faq/#is-it-possible-to-install-zeronet-to-a-remote-machine
 Yes, please read the link:

Is it possible to install ZeroNet to a remote machine?

Yes, you have to enable the UiPassword plugin by renaming the plugins/disabled-UiPassword directory to plugins/UiPassword, then start ZeroNet on the remote machine using 
zeronet.py --ui_ip "*" --ui_password anypassword. This will bind the ZeroNet UI webserver to all interfaces, but to keep it secure you can only access it by entering the given password.
  it does not meet the design principles
  According to wikipeda github is safe: "On January 21, 2013, GitHub was blocked in China using DNS hijacking. Confirming the block, a spokesperson for GitHub said: "It does appear that weâ€™re at least being partly blocked by the Great Firewall of China".[a][7] The block was lifted on January 23, 2013 after an online protest on Sina Weibo." - https://en.wikipedia.org/wiki/Censorship_of_GitHub

I have created mirrors:
- https://gitlab.com/HelloZeroNet/ZeroBundle/tree/master/dist
- https://try.gogs.io/ZeroNet/ZeroBundle/src/master/dist

Distributing on torrent probably would cause other problems,since it's blocked on many networks even outside of China
 Actually the source code already on ZeroNet site: 1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp and if you have this site your client will use this to update your client instead of https source.
Git releases & commit also signed: https://github.com/HelloZeroNet/ZeroNet/releases  For some unknown reasons zeronet does not see your site. 
Does the 17EcoSLuGdJKWrKnBDN1qVsyxN2dZqtJQL directory exists in your data directory? does it has index.html and content.json file?
Please try to restart your zeronet client, maybe it helps.
 nice
  To be able to review site source code changes a "Site freeze" option could be added to the Sidebar: When it's enabled, the current site's html, js, and css files are copied in a separate directory (data/siteaddress-freezed) and if the user's browser is request the files then it would be served from this directory until the user disable the freeze feature.

The data files are not affected by this feature and the user still receive/distribute the latest files of the site's source code.
  why? its the same
  Thanks for reporting, but i'm not sure if its necessary to authenticate every message, because the whole file is already authenticated by the sha512 hash, so there is decrypt is not executed on trustless data
 @TheNain38 it's not related to this problem, hmac would not help on that
 the hmac is authenticate the message itself and not the sender user.
 it could be possible modify zeromail to decrypt the messages using only the aes key associated to the user, so it would greatly improve performance and would not require per-message hmac, or is there any other attack vector on that?
 Modifying the secret exchange by also adding the sender's address to it would prevent the aeskey stole attack + adding the per-user associated decryption modification i think would solve the problems
 HMAC would not solve the message or secret transfer problem, so we need to add this regardless of HMAC-ing messages or not
 im not against addig MAC, but i think the real problem (message duplication) is not related to it.
 Alice's SK = Alice's private key? If so, then if you encrypt anything using it then noone will able to decrypt it.
 I think ECIES works like this, but there would be many drawbacks to use it as message encryption:
- Much larger messages
- Around 100x slower than AES
- You would have to try to decrypt every message (currently don't decrypt unknown user's messages)
- If we want to have sent folder, then we have store the messages twice (once encrypted for our self, once for other user)

it was considered earlier, but then it was dropped: https://github.com/HelloZeroNet/ZeroNet/issues/216#issuecomment-157479518
 I know, this is a more complicated solution, but it was chosen because of the reasons i written in my prev comment.
  sqlite database would be better (more scalable, multiuser)
  you have to open a Terminal and drop the zeronet.app on it
  There is a plugin for that: https://github.com/HelloZeroNet/ZeroNet/tree/master/plugins/disabled-Zeroname-local
 I prefer to make it an separate, optional plugin as it affects very small amount of users and it's not stable yet
 I think the best solution would be using P2P name resolution without downloading the blockchain. It could be possible using SPV clients, but it's not ready for namecoin yet: http://blog.namecoin.org/post/109811339625/lightweight-resolvers
when it's ready we will implement it as default dns resolving.

other possibility: https://blockstack.org/docs/light-clients (it's also not ready yet)
  I dont think it's necessary you can put your donate button to your site html code
  I think POW is not suitable to fight spam. Spammers has lots of CPU/GPU power and it's possible to create an optimized FPGA/GPU program that runs 1000x faster than normal CPUs
  You have to compile the required python packages (gevent, msgpack) from source then it should work
  Fixed: https://github.com/HelloZeroNet/ZeroNet/commit/e3a4dbaab566255c44543a22cb0adb982c3b66bb
  [18:04:44] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 154 > socket.py line 344

Means your tor is not configurated properly see: http://zeronet.readthedocs.org/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
  probably you have to use target=_top on links
  In order to greatly reduce the bandwidth usage of ZeroNet, when a change is happening instead of re-transferring the whole file we only send the changed lines to the user.
- [x] Benchmark of generating diff
- [x] Benchmark of patch files
- [x] Modify UiWebsocket fileWrite to generate and store patch
- [x] Modify UiWebsocket sitePublish to send patch to clients
- [x] Modify FileRequest Update command to accept patches
- [x] Find a way to make the patch work from command line
- [x] More manual testing
- [x] Unit tests

new example update command:

``` json
{
 "site": "1Hello...",
 "inner_path": "content.json",
 "body": "{...full content of content.json...}",
 "patch": {
   "index.html": [["=", 273], ["+", ["newline\n"]], ["-", 3]]
 }
}
```

First the client checks the content.json validity as before, then tries to apply patches, if failed, then downloads the file in traditional way.

Probably it's a good idea to limit patch length to 10k

Later it could be possible to also send content.json as patches

To make it work outside of zeronet (where files are not written using fileWrite so no diff generated):
If a file with -new a postfix is exists then before the signing method the diff is generated between the normal and -new postfixed one, then the file is overwritten with the -new one.
 First benchmark using a modified simplediff (https://github.com/paulgb/simplediff/tree/master/python):
Generating diff between two 900kb json file: 80ms

Example diff:

```
[
('=', 273),
('+', ['newline\n']),
('=', 2743),
('-', 2),
('=', 657),
('+', ['newline2\n']),
('=', 88),
('-', 3),
('=', 79)
]
```

Patching is pretty simple and takes no time: 0.8ms for 900kb json file with 12 differences.

https://gist.github.com/HelloZeroNet/0eed5fc05227ab793e7d
 Changed to standard python difflib + character based diffing, because the patching is using lower memory this way https://gist.github.com/HelloZeroNet/8c44dda7802cf05c6c59001d20816da2

```
# SHA512: c8cc7f1dc3e018cd45a3a77accba5105721102539b2af900e34c91c2a1b40d6c
# Patch list: Mem +0.48MB, Peak: 11.37MB Taken: 0.188s
# Patch file: Mem +0.20MB, Peak: 10.25MB Taken: 0.323s
# Patch file+bindiff: Mem +0.16MB, Peak: 10.22MB Taken: 0.132s
# Tempfile
# with    Mem +0.45MB, Peak: 10.78MB Taken: 0.155s
# without Mem +0.14MB, Peak: 11.46MB Taken: 0.144s
```
 Done in rev1200
 i have throught about it, but adding compression to protocol level (compressing every communication) probably makes more sense
 Compress after the encryption is more safe. BREACH/CRIME attacks are using compression to get around: https://en.wikipedia.org/wiki/BREACH_(security_exploit)
  It does not work on osx. according to http://stackoverflow.com/questions/6908143/should-i-put-shebang-in-python-scripts-and-what-form-should-it-take `#!/usr/bin/env python` always should point to python2
 ```
$ /usr/bin/env python2
/usr/bin/env: python2: No such file or directory
```

for me
 please correct your PR then i will accept the modification
  it goes against "uncensorable" goal, so not a good idea

There was a pullrequest earlier, but never ot merged:
https://github.com/HelloZeroNet/ZeroNet/pull/111/files
 But what about domain name updates? I think it's not worth it, if we want to create more decentralized internet, then we need to use more decentralized domain system.
  Thanks (the plugin config bug was fixed in the latest version)
  @Erkan-Yilmaz The unviersal admin is for managing site database, the muting feature is only for you and it would not modify the site.
 It can be done two ways: 
- Does not insert hidden user's data to database at all: Probably easier, no site modification needed, but you will not notice if you miss all content created by the user (topics, comments, mails, etc.)
- Let the sites handle it: Needs modification on every site, but you can see if anyone commented on a topic created by the user you hidden.

It's not that hard, but could be dangerous and narrow your view of the world
 Started working on this:

 - [x] muteAdd command: Adding new user to mute list, params: auth_address, cert_user_id, source, reason. Confirmation requred if not an admin site. Check all sites and removes the json files of the user from databases.
   - [x] Remove entries from database
   - [x] Skip updates
   - [x] Add confirmation dialog
 - [x] muteRemove command: Remove user from mute list, params: auth_address. Confirmation requred if not an admin site. Check all sites and re-add the json files of the user from databases.
   - [x] Re-add entries from database
   - [x] Add confirmation dialog
 - [x] muteList command. List all current mutes. Requres admin permission.
 - [x] UI in ZeroHello to add/list/modify current muted users
 - [x] Implement to ZeroHello
 - [x] Notification for older clients

Questions:
 - Does non-global, only one site muting desirable? No, it's only hides the content, but you will still download and distribute it to other people, because the protocol expects that everyone has every non-optional file.

No mute lists yet, maybe in the future. added in 2cea157eccb2f0b3e19158590d2d3e65ba4022a5  I don't think its a good idea listing directory on every update
 Yeah it's better this way, but I think importing/using Counter is unnecessary, a standard dict will do, and please put a try/exception block like the files has.
 Thanks, i have used a simplier solution for this: https://github.com/HelloZeroNet/ZeroNet/commit/6d222b6ed768700e188bf862ac36ef075e5e989d
  Please use http://zeronet.readthedocs.org/en/latest/help_zeronet/contributing/
  I don't think it's not a real threat: if you loose your bitcoin wallet, then the attacker will get your money. if you looks your users.json then you can register a new one any time.
 Sure, but he has access to your hdd then your are fucked any way regardless if its encrypted or not.

I'm just saying there is not much motivation to get your users.json, while there is a huge bounty on your wallet.dat.
  Are you sure you have used the correct ZeroFrame.coffee ? http://127.0.0.1:43110/blog.zeronetwork.bit/data/files/ZeroFrame.coffee
  Currently ZeroBundle is the default and recommended install method. It contains all of the libraries the you need to run zeronet. (SSL+Python is a sad story: had lots of problems with different openssl, gevent and python versions that are incompatible with eachother) It also has built-in update method that downloads the latest version from github, unpacks it and restart itself.
 It's hard to pin version, because it's also depends on OpenSSL and Python version which is supplied by the OS. The updating is done by `update.py`
  The problem is it will delete the tor settings and readme
  Tor directory is necessary to run zeronet on windows
 Adding ignore pattern for non-default files could work.
  Probably the old process is still running. Please check process list / log files. Are you sure it's not in your systray icon list?
  The problem is the wrapper does not know if the frame loaded or not. You have to send a "innerLoaded" command to the wrapper when you finished rendering your page (loaded all database query) and it will add the hash to the site url. 
https://github.com/HelloZeroNet/ZeroBlog/blob/bb8dca17b6c3ce33a9ecf22ab295cfc540c541c9/js/ZeroBlog.coffee#L255
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/media/Wrapper.coffee#L100
  Have ability to modify the site layout/add new features without modifying the original source code to keep it updateable.

Eg if you create a `plugins/DarkSkin/all.css` file on all.css request it would also append this file's content to the end. (same for js)

Maybe combining something similar like hotpatching in #322, so it would be possible to easily attach new functions to events.
  Yes, in multiuser mode for security reasons nothing is written to disk
  thanks
  This will fail if more than one keyframes defined

https://regex101.com/r/kG2iI0/1
 Probably this should work: `@keyframes (.*? {.*?\n})`, please confirm
 Thanks
  Yeah, it was fixed yesterday: https://github.com/HelloZeroNet/ZeroNet/commit/eea55f8f16fa4737d7d08686c12e0c443e48e760
So updating from rev980-1038 will require manual start after the update, but the next update should be fine.
  If the browser does not allow to connect to the ui server, then we can't do anything about it. You can try access it using your LAN/WAN ip.
  Probably relevant: https://github.com/HelloZeroNet/ZeroNet/issues/288#issuecomment-194722911
 Looks like for some reasons the new zerohello site does not have admin rights for you, shut down zeronet, open data/sites.json, search for 1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D and add "ADMIN" to "permissions":

```
    "permissions": ["ADMIN"], 
```
  Added @ and = to allowed filename patter
  The error: can't open the application ZeroNet because the classic environment is no longer supported.

I have no access to 10.8 Mac, so need suggestions how to make better .app. (currently its a bash script: https://github.com/HelloZeroNet/ZeroBundle/blob/master/ZeroNet.app)

An icon also would be nice.
 the zerobundle package has the required python with the dependencies, so we don't use the system python, but the packed one: https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-v0.1.1.zip

Can you try to open a terminal and run it with `bash ZeroNet.app`?
 thanks for testing, yeah a proper Application bundle would help, I will try ti when I have Mac access, or if you could try to create one and test it that would be great.
 The ZeroBundle package contains the Python binaries with every dependency. When you first time start zeronet it downloads the latest version from github, unpacks it to ZeroNet directory and starts it. There is a semi-auto update method in ZeroNet which is - when requested - it is re-downloads the latest source code, overwrite the files in ZeroNet dir and and restarts itself.

So I think - to keep the built-in update method working - the best would be to convert ZeroNet.app bash script to proper application bundle end leave the rest as it is.
 @drjmedulla
Do you have any special (non-english) character in the directory where you unpacked it?
Please open ZeroNet/log/debug.log file, search for `not in allowed dir` and paste the line here.
 @drjmedulla Can you check if ZeroNet is not running twice? (eg via taskmanager, search for python.exe)
If not helps please send your log files (debug.log and debug-last.log) to hello@zeronet.io
 The log file says:
`[2016-03-18 21:12:51,207] ERROR    Ui.UiServer Web interface bind error, must be running already, exiting.... [Errno 48] Address already in use: ('127.0.0.1', 43110)`
Which means something is running on port 43110, please try to kill the python process and try again.
 We need a proper way to pack a bash script into an .app
@drjmedulla's problem is probably not related to this

probably this helps, but i have no mac access atm to try ti: https://mathiasbynens.be/notes/shell-script-mac-apps
 I was able to make it work on 10.8, but now it's not working on 10.11 :( (Unidentified developer error)

I have uploaded it here, if anyone would able to confirm if its working or not that would be nice: https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-osx-10.8-v0.1.1.zip

Other possibility:

```
#!/bin/bash
osascript -e "tell application \"System Events\" to set visible of application process \"Terminal\" to false"

cd "$(dirname "$0")/../ZeroNet"
bash ../Python/python start.py "$@"
```

But this will keep the terminal icon on dock, any workaround?
 I'm not familiar with OS X app ecosystem, but if we manage to sign the ZeroNet.app, then it would work without any errors (Unidentified developer error) on every platform or do we need to submit it to appstore?
 So can anyone sign the https://github.com/HelloZeroNet/ZeroBundle/tree/master/ZeroNet.app/Contents application please?
 Yep, it should work now  Benchmark is not a websocket function + you redirect it to siteDelete
But nice try :)
  It's a soft limit, the limit checked every 20 minutes and if the site has more than it then close some connections.
 If you are on limited bw it's recommended to disable popular pages for now (ZeroBoard, ZeroID, ZeroMail) Later the bw usage will be reduced

The idle connection bw cost is very low (around 100byte / 5minute)
  It would be nice to see whats different please try the -vv option
 Looks like python version or 32/64bit platform difference, I will try it with python 2.7.11 later (currently running 2.7.9)
  Yes, include tor if you want to use it. Docker philosophy: one service = one container
  @Erkan-Yilmaz Rpi has different binaries so zerobundle probably will not work there.

@jdoig Can you please specify the gevent version and the python version you used?
`python -V`
`python -c "import gevent; print gevent.version_info"`

This works for me on linux/windows:

```
$ python -V
Python 2.7.9
$python -c "import gevent; print gevent.version_info"
(1, 0, 1, 'final', 0)
```
 Can you test this one please?

```
$ python -c "from gevent import monkey; print 'patch_subprocess' in dir(monkey)"
True
```
 I'm a bit afraid to touching it. (Gevent + SSL is a long, sad story, needed many hacks to make it work on most environment)

So I will change the requirements.txt.
 It's done, https://github.com/HelloZeroNet/ZeroNet/commit/25752c927ca694ba912683037829a69432796ad9
Thanks for reporting btw.
 @jdoig Btw it would be interesting for me if you would be able to post http://127.0.0.1:43110/Benchmark results from rpi here.
 Thanks, pretty good, the multipler is compared to my desktop machine (c2d 2.6ghz). So for the most important operations (sql, openssl verify) are around 2 times slower. 

The sha512 unexpectedly slower than sha256. I have choosen sha512 over sha256 because its around 2x faster on modern 64bit cpus. Probably this will improve in 64bit RPi3 OS.
  We need an universal admin interface that allow to manage data stored on sites.

Features needed:
- Query/Modify/Delete ZeroTalk and ZeroBlog (and other sites) database without any source code modifications. (using only configuration files)
- Query/modify users limit using it
- [ ] Create sample configuration file for ZeroTalk and ZeroBlog (xml?, json?, js?, yaml?)
- [ ] Layout mockups
- [ ] ...Coding

This would be huge benefit for all ZeroNet sites, so it would be really nice if someone would be able to take this task, so I will be able to focus on core modifications.
 Example jsx config file for ZeroTalk:

``` jsx
<Site title="ZeroTalk">

 <Page name="topic" title="Topics" orderby="added DESC">
  <user name="json_id" title="Username" disabled save="no"/>
  <input name="added" formatter={ Date.toDate } deformatter={ Date.fromDate }/>
  <input name="title"/>
  <textarea name="body"/>
  <select name="type" values={ ["", "group"] }/>
  <select name="parent_topic_uri" title="Parent topic" values={ Topics.listUris }/>
 </Page>

 <Page name="comment" title="Comments" orderby="added DESC" parent="topic">
  <user name="json_id" title="Username" disabled save="no"/>
  <input name="added" formatter={ Date.toDate } deformatter={ Date.fromDate }/>
  <textarea name="body"/>
  <select name="topic_uri" title="Topic" values={ Topics.listUris }/>
 </Page>

 <Page name="settings" title="Settings" file="content.json">
  <input name="settings.admin" title="Admin name"/>
  <input name="settings.href" title="Admin contact url"/>
  <select name="settings.sticky_uris" title="Sticky topic uris" multi values={ Topics.listUris }/>
 </Page>

</Site>
```

Based on simple config this tool would able to generate an admin interface that allows the site owner to modify/delete/move topics and comments.

Update: added Settings page
 Because then you don't have to re-write the same functions for every site you make, does not bloats the main source code, better tools (eg. batch modify), user management, custom listings, etc.

I already created a similar tool: http://i.imgur.com/cV8mju1.png It saved me many-many working hours. I'm able to create fast and unified admin interfaces using this, every operation is logged and reversable, easy form validations, batch editing, reordering etc.
The sites are only different from xml configuration files, so if i add a new function/enhancement every site will benefit from it.
Unfortunetly it's not portable to zeronet, but I think we need to create a very similar one.
 It should be a standard zeronet site
 pure js also could work, have to try which one is easier to read/extend by creating examples for zerotalk/zeroblog/zeromail
 looks good for me, maybe a bit easier to read the xml version, but I also prefer pure js over jsx, because of "less magic"
 Its verry simple, but the chat tutorial has example for dbquery. Loading database file using fileGet is a bad idea and does not makes much sense.
 This should work:

```
checkTable: (table_name) =>
    Page.cmd "dbQuery", ["SELECT * FROM "+table_name], (res) =>
                @columns[table_name] = res

for table in @tables
   checkTable(table.name)
```

part to separate function, then it should work
 userPublickey is for ecies encryption. the user's auth_address is in site_info object (please check the zerochat tutorial)
 Good idea, created and added some thing before start coding: https://github.com/HelloZeroNet/ZeroAdmin/issues
  I will try, but I usually tests my modifications for longer time and do not want to push it out early, so I need a tool that display the diff and allows me easily to create separate commits based on that.
Any suggestions?
 If you want stable version then download the source code from releases. Master = development version
 Switched to another git client that allows per-line selection for commits, yeah feels better: https://github.com/HelloZeroNet/ZeroNet/commits/master
  At the first look it looks safe for me, but need more research about it.
 @vlad20012  Unfortunetly it's not possible: 

```
document.body.getElementsByTagName("iframe")[0].contentWindow.open
VM3924:1 Uncaught DOMException: Blocked a frame with origin "http://zero" from accessing a cross-origin frame.
```

The outer document also sandboxed from inner frame, so not allowed to access any property of it.

The possible cross-platform solution is adding a zeroframe api command for it, but I think it's easier to open everything in current window, most of the users are familiar with middle mouse click

So maybe it would be better to deny popup window opening (by removing sandbox flags) as it's not predictable.
 @vlad20012 I'm not familiar with google account registration, does it also requires communication between the window and the opener?
 Related: https://mathiasbynens.github.io/rel-noopener/ (target=_blank considered harmful)
 Added a wrapperOpenWindow command: https://github.com/HelloZeroNet/ZeroNet/commit/99f0407ba23707774884cd2ad103914044414587
Tested and works on youtube for me.
Example: `Page.cmd("wrapperOpenWindow", "https://github.com")`
 I was unsure about that, but why not. Added: https://github.com/HelloZeroNet/ZeroNet/commit/6496a6125f65ed770778992858b3b152467b40ef
 Nice, I think we can close this then
  In the recent versions of zeronet is much more dependent on sqlite (fast startup, peerdb, optional files db), so if it's not working correctly, then zeronet will not work at all, this is expected
  Big files not supported yet, so you can't embed videos.
 It is, the example @ http://videojs.com/getting-started/ works for me. If you don't want to merge the video.js resources with your blog js, you can create a js directory in the data dir and put it there.

But video embedding should also work without any external js library. (the browsers has built-in ui for it)
 You need to add
`<link href="video.js/video-js.css" rel="stylesheet">` and `<script src="video.js/video.js"></script>` to your index.html's `<head>` section or you can also paste this lines directly to your blogpost

and `<video src="data/videos/any.mp4" width="600" height="342" loop="" muted="" preload="auto" class="video-js"></video>` to your blogpost where you want your video
 zeronet sites runs in sandboxed iframe for security reasons, in this enviroment not every javascript functions are available.
 no, its not possible
 The sandbox is protecting user's data, so it will not removed. Pressing F11 for fullscreen should work in every browser.
 Different browsers, different limitations.
  Tor error is not relevant, your sites.json is broken somehow (probably hdd error or the last shutdown was improper), you need to fix it around line 4356. or check if sites.json.old old similar is present.
  if you are sure about you have to correct private key and your site does not exceed 10MB try `python zeronet.py --debug siteSign 17JcQZkstLE9LH5dn49mCQhC6tamZDyi7F --publish`
  yes, its correct
  even if you are on --tor always you will see mixed peers. the non-onion peers are connected using exit nodes.
  Just copy data/users.json to new installation.
 no, copy ZeroNet-master/data/users.json to NewInstalledZeroNet-master/data/users.json. (if you copy it to your site's directory then you will publish everyone your privatekey, so anyone would able to modify your blog)
 Just open the blog in the browser, the files will be downloaded from other peers.
  can you please specify your platform?
 Probably fixed in latest version, please update & verify: https://github.com/HelloZeroNet/ZeroNet/commit/ff681adfe9e92f8f139347499c35783ed47160a4
 - Files in sub-directories first ordered by directory and filenames
- Then files in parent directories ordered by name

for zeroblog:

```
js/lib/00-jquery.min.js
js/lib/highlight.pack.js
js/lib/identicon.js
js/lib/jquery.cssanim.coffee
js/lib/jquery.csslater.coffee
js/lib/marked.min.js
js/lib/pnglib.js
js/utils/Class.coffee
js/utils/Follow.coffee
js/utils/InlineEditor.coffee
js/utils/Menu.coffee
js/utils/RateLimit.coffee
js/utils/Text.coffee
js/utils/Time.coffee
js/utils/ZeroFrame.coffee
js/Comments.coffee
js/ZeroBlog.coffee
```
 Looks right for me (jquery colorbox depends on jquery)
  Thanks, fixed!
  This is a bad idea, big files >1MB not supported yet + please define it as optional files
  please check if http://127.0.0.1:43110/Benchmark runs without any error and maybe log/debug.log have more detailed information. (you can also send it to me: hello@zeronet.io)

Can you please also try the ZeroBundle package?
- wget https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-linux64-v0.1.1.tar.gz
- tar xvpfz ZeroBundle-linux64-v0.1.1.tar.gz
- cd ZeroBundle
- ./ZeroNet.sh
 there should be a log and a data directory where you started ./ZeroNet.sh
 Thanks, got it. It's looks like a network error, the connections are timeouting.
  no dist specific package, but: https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-linux64-v0.1.1.tar.gz should work everywhere
  Please also check if it's the same error in another browser
 @jamesalexanderdickerson Do you have any special character in the directory path where you have extracted ZeroNet?
 Please try to update to latest version, start it, then check `log/debug.log` and search for text "not in allowed dir" it should give more idea about the error.
  The auth work, but you need Tor 0.2.7.5+: http://zeronet.readthedocs.org/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
  I dont understad, the sites.json contains the site's bitcoin address (eg. 1TaLkFrMwvbNsooF4ioKAY9EuxTBTjipT), which is case-sensitive
 Fixed: https://github.com/HelloZeroNet/ZeroNet/commit/48db062b49bded23db2a6cfd35a836d5c2d0e77b#diff-9af49b2fc8a9d6fa47722290019d9104R57

(to make the duplicates disappear you have to delete the entries from sites.json manually)
  Probably a confirmation dialog of "You already have certificate for zeroid.bit, do you want to change it?" would be better if cert is already exists
 The domain plugin is optional and not restricting it by site domain would allow to recover your ID even if ZeroID site is disappear for some reasons.
 Added confirmation if cert with the same domain already exists: https://github.com/HelloZeroNet/ZeroNet/commit/9bb0a0d91b38c15bcda81676ca41b85abe187079
  never seen that error, please try https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-v0.1.1.zip it has everything packed in.
 Maybe somehow you have installed 32bit module for 64bit python or vica-versa.

via http://stackoverflow.com/questions/16386707/python-django-on-a-mac-illegal-hardware-instruction
 sounds like /Applications is a special folder:

```
If you have your binary stored in your Applications folder you can do this and it should fix it:

# sudo chmod + x /Applications/Twine.app/Contents/MacOS/Twine
```

via https://groups.google.com/forum/#!topic/tweecode/3X7oJxxYHpg

if not working please try to move it to your home
  It's required to check tor works correctly and returns the exit node ip. you can skip it if you want by starting --ip_external 127.0.0.1
 It connects to a service that is returns your external ip (tor exit node) and checks if the file server port is opened (always returns no when using tor)
 because it's returns your external ip (exit node), which is used in some places

i don't see why is it a problem
 It's puts own ip to blacklist, so dont try to connect/publish modifications to itself
 Not much, but I dont see why is it a problem. It also puts your on the map and on sidebar and you can make check your exit node ip using /Stats
 there is no hidden service-only mode yet, you will use exit nodes regardless if there is port checking or not, so it's not related to this topic
 > Why not remove it from the web interface when using --tor always?

It displaying a green "Closed" with the description "Good, your port is always closed when using ZeroNet in Tor always mode." when you are using --tor always
  it's not compatible with http://zero/ access please use 127.0.0.1:43110
  Added local multiuser mode to latest revision that is fixes this issue.

To enable it you have to start it using `--multiuser_local` parameter or create a zeronet.conf where your zeronet.py file is with this content:

```
[global]
multiuser_local
```
 You need to enable the plugin first by renaming `plugins/disabled-Multiuser` to `plugins/Multiuser`
  probably you have not unpacked it right, please make sure you have the same files/dirs as in: https://github.com/HelloZeroNet/ZeroNet
 are you sure you are in the right directory and you running it using `python zeronet.py` ?
 please try this one: https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-v0.1.1.zip

just download, unpack and run ZeroNet(.app)
 Is it working for you?
 nice :)
  please specify the error message
  I dont really want to expose the private keys to webui.
 In that case it can be implemented in the mobile app.
 A bad browser plugin would able to stole it from the another port.
 Sure, but we should minimize the attack vectors
  https://github.com/HelloZeroNet/ZeroTalk/pull/12
 # Idea1: Hotpatch

You would be able to "hotpatch" any of the site's files based on language files, eg. if you have a `translate/ru.json` containing:

```
{
 "js/all.js": {
   "Please, your choose account before upvoting.": "Russian translation"
  }
}
```

And the user have selected Russian as language, then ZeroNet will return all.js replaced "Please, your choose account before upvoting." with "Russian translation". To avoid partial matching the part should start and end with characters: `' " < >`

If required (will try to translate zerohello and zerotalk and it will turns out), then we could add allow partial and regex matches by `js/all.js:re` and `js/all.js:partial`
- [ ] Performance benchmarks
- [ ] Implement as "Multilanguage" plugin
- [ ] ZeroHello modification to allow select preffered laguage

## Pros
- No need to modify the site's source code
- Fast (js files are cached by browser)

## Cons
- Possible text confilcts
- Harder first time translation

# Idea2: Use js translation table

Create a `t('Hello')` js function that is always return the translated version of the text.

## Pros
- Less magic
- No partial text conflicts

## Cons
- Adds extra complexity/noise to source code
- Performance: Has to replace in real-time, could be slow if a page contains 1000s of text
- Only JS replace possible (No css/html)
 First benchmarks: https://gist.github.com/HelloZeroNet/f684d2f1eb7807a124b3 from my old core2duo cpu:
- it takes 4.8ms to replace the texts in zerotalk's all.js (220kb) 
- down to 2.6ms if we skip js/lib/\* from translating
- 2x more translate replacements adds only +20% running time

So probably we don't need to cache translated files.
 Added in 0.5.1, translation files:
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Translate/languages/hu.json
https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Sidebar/languages/hu.json
https://github.com/HelloZeroNet/ZeroHello/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroMe/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroTalk/blob/master/languages/hu.json
  can you please run `ulimit -a` ?
 I have created a simple script to test and change current limit, please save it, then run using `python test_max.py` and paste the result here.

https://gist.githubusercontent.com/HelloZeroNet/d9bf888693e66a573815/raw/afdb058ad9709036172ef5ccfc9ad38bf1619c28/test_max.py
 Yeah 256 is pretty low, 1024 on linux and 512 on win by default.

Good news is looks like we can change it from python code. I will add it later today to ZeroNet
 I checked my VPS-s using `ulimit -Ha` and the lowest hard limit was 4096 (Debian 7), the others (CentOS7, Debian8) has 65535.

At the startup ZeroNet will try to change the max opened files to 1024.
 Fixed in latest version (rev948), please update!
After restart you can verify if its working by searching for `Current RLIMIT_NOFILE:` in `log/debug.log` (it's right after web interface address displaying)
 sorry i have no osx access, maybe need to change other os settings. you can also try to set it higher by `--max_files_opened 10240`. (it's 65535 by default on linux)
 @iShift Any update if `--max_files_opened 10240` fixed it?
 Probably fixed by: https://github.com/HelloZeroNet/ZeroNet/commit/6f2445c417e59c3bf948ff5c3fd0a722c710f9d3  Thanks, fixed!
  You need to enter the master_seed from users.json.
  The multi-user plugni is not compatible with the chrome plugin, so you need to use it via http://127.0.0.1:43110
  It would be nice, but I don't have access to OSX machine
 No, it's just a packed version of installed python. So I installed python to my machine, added some package (pip, gevent, msgpack), zipped the C:\Python27 directory. And ZeroBundle uses this to run python files: https://github.com/HelloZeroNet/ZeroBundle/blob/master/zeronet.cmd

I think it could also work for Mac. Tomorrow I try to get an OSX access and try.
 I think i was able to create a bundle for mac, please help me verify it's working: https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-v0.1.1.zip
- (Close ZeroNet if already running for you)
- Download, unpack, run ZeroNet(.app)

It should download the latest version from github, start it and open ZeroHello in the browser.

Please also check http://127.0.0.1:43110/Benchmark if everything is ok. (no errors, openssl verify is working, the python version should be 2.7.11)

Thanks!
 @iShift Thanks! What's version of OSX are you using?
 You have to open a terminal and drop the zeronet.app to it
 It works with double-click on latest osx, the Terminal dropping is only requred for older versions

I have created a proper .app that works on all osx, but it needs to be signed that i unable to do. (needs apple osx dev certificate)

more info: https://github.com/HelloZeroNet/ZeroNet/issues/363
  This is two separate project, if you have zeronet running then you can browse zeronet sites in the tor browser using http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/
  If you registered it using a zeroproxy and have not saved the private key displayed on first visited, then it's lost.
If you using local client and have not reinstalled zeronet, then it should be recovered when you visit the zeroid site.
  You can right click to the systray icon and check starts zeronet when windows starts
  Thanks, fixed!
  if you start it with zeronet.py and the `--open_browser` is not present, then it's not opening the browser. If you start it with start.py then it will open the browser. (it basically = `zeronet.py --open_browser`)
 If you are using zerobundle the edit zeronet.sh/cmd/app and change start.py to zeronet.py, then the browser window will not open.
 You are safe to ignore the port error
 You can try to check browser's javascript console (F12) for errors. Probably something (browser extension) is blocking the javascript
  Can you please specify your os/browser version?
 Do you have antivirus software installed? sometimes it can make strange things
 Nice find, please try to report it to the plugin owner to allow to setup whitelist or allow it on 127.0.0.1.

Update: I have downloaded the extensions and looks like the blocking is not intentionally, it uses postMessage to communicate between the browser and the plugin and this is overwrites ZeroNet messages. So probably only the plugin owner able to fix it. (disable it on 127.0.0.1 probably would work)
 Ok, thanks. so it's not filtering just sending extra messages, this can be solved and will add it in the next version
 I think it's fixed in latest revision https://github.com/HelloZeroNet/ZeroNet/commit/e891a10e54c31468849ed65892ed97bbb548a534#diff-25ec8dd4ba66e508e805a317bc38fa5fR82
Please update & check
 Thanks
  Thanks
  Hi, it's not possible yet, but planned later.
  To do that create a file named `zeronet.conf` where your zeronet.exe with the content:
```
[global]
ui_port = 12345
```

There is also a `zeronet.cmd` for command line usage.  Thanks for reporting, fixed now: https://github.com/HelloZeroNet/ZeroNet/commit/3f6f273fb1e01b3185793b1f3b4a95a83e6a4608
  gevent is a library that needs to be installed to run zeronet. Please try: `python -m pip install gevent msgpack-python`
 please try `sudo easy_install pip`

other method if this is not works:
- `wget https://bootstrap.pypa.io/get-pip.py`
- `python get-pip.py`
- `python -m pip install gevent msgpack-python`

on the weekend I try to get access for an OSX machine and create a simple, "unpack and run" solution like we have on windows.
 I think i was able to create a bundle for mac, please help me verify it's working: https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-v0.1.1.zip
- (Close ZeroNet if already running for you)
- Download, unpack, run ZeroNet(.app)

It should download the latest version from github, start it and open ZeroHello in the browser.

Please also check http://127.0.0.1:43110/Benchmark if everything is ok. (no errors, openssl verify is working, the python version should be 2.7.11)

Thanks!
 Probably relevant: https://github.com/HelloZeroNet/ZeroNet/pull/687

Please update and try again!  Instructions for linux:
http://zeronet.readthedocs.org/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
 old version detection fixed now: https://github.com/HelloZeroNet/ZeroNet/commit/e891a10e54c31468849ed65892ed97bbb548a534#diff-d8841277993f336590a11cd5623974c9R156
  I'm not fan of non-ascii domain names: they hard to type and possible phishing attacks via similar characters
  Yes,I think :) Thanks
  `zeronet.py --ui_restrict 1.2.3.4 2.3.4.5 4.5.6.7` is the correct format
 Try with ./ZeroNet.sh --verbose --ui_ip 0.0.0.0 --ui_restrict 43.53.63.73 --debug
(last argument should not be multi-parameter)
  Well, use curl :)
`curl http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/content.json`
 `curl http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D` should work as adding site
  You need to enable password plugin by rename data/disabled-uipassword to data/uipassword
  Looks like openssl problem, can you please run `openssl version`?
 Yeah, CentOS has tricky openssl (they removed some curves we need), please try this: 
- `wget https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-linux64-v0.1.1.tar.gz`
- `tar xvpfz ZeroBundle-linux64-v0.1.1.tar.gz`
- `cd ZeroBundle`
- `./ZeroNet.sh`

It has everything included. Please let me know if it works! Thanks!

btw you should update your openssl: https://www.linode.com/docs/security/security-patches/patching-openssl-for-the-heartbleed-vulnerability
 I think I know why, can you please check the line `- OpenSSL loaded, version:` in the log? It should be in the first 10 lines
 Thanks! Already working on the fix, will be out in hours
 I think it's fixed, please download the latest version and try again. Just delete ZeroBundle/ZeroNet and it will re-download the latest version. (Backup data/users.json if you already created a profile)
  Thanks!
  http://zeronet.readthedocs.org/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
 @wfjsw yes, please read http://zeronet.readthedocs.io/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
  start zeronet with `--ui_host "192.168.163.20"` Try this way:
```
[global]
ui_ip = *
ui_port = 43110
ui_host = 
 192.168.163.20
 192.168.1.163
``` Can you please specify the exact error message you get? F12 > Network tab > all.js > Response  we need python2, so try `python2 -m pip install gevent` or `python2.7 -m pip install gevent` please
 nice!
  please try `python -m pip install gevent msgpack-python`, maybe the pip command uses different python installation

I have no osx access, so it would be nice if someone could create a easier installation method for mac. Maybe similar to zerobundle for windows where everything is packed up in a zip file, all you need to download, unpack and run zeronet.cmd.
 I think i was able to create a bundle for mac, please help me verify it's working: https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-v0.1.1.zip
- (Close ZeroNet if already running for you)
- Download, unpack, run ZeroNet(.app)

It should download the latest version from github, start it and open ZeroHello in the browser.

Please also check http://127.0.0.1:43110/Benchmark if everything is ok. (no errors, openssl verify is working, the python version should be 2.7.11)

Thanks!
 https://zeronet.io/ should offer this method by default now.
 use the ... menu on ZeroHello
  something is bad with formatting: https://github.com/ashleypt/ZeroNet#docker
  [Appimage](http://appimage.org) helps packing apps which can run on all major Linux distribution s based on concept of _one app = one file_

If zeronet can be packed along with all its dependencies inside an appimage, users can simply download give permission & run the file. 

Popular apps like scribus, krita are also adopting this method to distribute their apps. 

Projects repo: https://github.com/probonopd/AppImagekit 

The developer @probonopd is happy to help you packing your app :) 
 Yeah, it would be nice, last night i started having openssl segfaults on CenOS. Only compiling python 2.7.11 and the latest openssl solved it. (CentOS have crippled openssl by default that does not support bitcoin's curve)

My concerns:
- It would broke the semiauto-update (you can update to the latest source code with one click)
- Plugins (separate .py files)

For windows we have a ZeroBundle package that has python + all dependencies packed, but leave the source code on the hdd as it is. Would this possible with AppImagekit?

A similar solution for mac also would be nice, but I have OSX no access.
 I think you are talking about atomic updates. Yes. It can be possible to provide update to specific parts of the app. Just have a look into that project once you find some time :) Also it's a simple process to turn an app into app image. No special skills required. 
 @HelloZeroNet since you are now providing a static archive for linux, why don't you distribute as appimage ? I tried making it but faced path relocation problems. I'm not good at fixing those. @probonopd help needed in this case...  
 it could be possible, but not sure about the benefits
 @HelloZeroNet  please give a try. regarding advantages, all files are in compressed state all the time & makes the app more portable  
  You have to start it using zeronet.py --ui_ip "*"

More info:
http://zeronet.readthedocs.org/en/latest/faq/#is-it-possible-to-install-zeronet-to-a-remote-machine
 same syntax: zeronet.py --ui_ip 1.2.3.4
  You have to add your user to tor's group: http://zeronet.readthedocs.org/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
 yeah, sorry probably you have to add to torrc config file: `CookieAuthFileGroupReadable 1`

mine: `-rw-r----- 1 debian-tor debian-tor 32 Feb 28 19:52 /var/run/tor/control.authcookie`
 You can try changing the cookie path using `CookieAuthFile Path`

Update: I think i found the problem (`re.search('Tor="([0-9\.]+)"', res_protocol)` and you have `VERSION Tor="0.2.8.1-alpha"`), some minute and I will send the fix!
 Here is the fix: https://github.com/HelloZeroNet/ZeroNet/commit/779075c4a56ef921f4095220725a16b156eba52e
  Hm i have not met this one yet, can you please execute
`python -V` and `python -c "import gevent; print gevent.version_info"` commands?
 Hm, I have just setup a new Ubuntu 15.10 VPS, 

```
# apt-get install python python-gevent python-msgpack
# python -V 
Python 2.7.10
# python -c "import gevent; print gevent.version_info"
version_info(major=1, minor=1, micro=0, releaselevel='beta', serial='1')
# python zeronet.py
- Starting ZeroNet...
[22:29:36] - OpenSSL loaded, version: 01000204F
[22:29:36] - Version: 0.3.6 r909, Python 2.7.10 (default, Oct 14 2015, 16:09:02)
[GCC 5.2.1 20151010], Gevent: 1.1b1
...
```

So everything works fine here, still investigating...
Are you on 32bit or 64bit? Installed gevent using apt-get or python pip?
 New installation method released, please try this:
- wget https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-linux64-v0.1.1.tar.gz
- tar xvpfz ZeroBundle-linux64-v0.1.1.tar.gz
- cd ZeroBundle
- Start with ./ZeroNet.sh
 Yes, the ZeroNet directory = git repo

But you can also update it from the WebUI using â‹® > Version: ... on ZeroHello (It's basically downloads the latest version from github and overwrites the existing files)
  Just copy the users.json file and you will have the same identity
 The problem is you can't really delete an incoming message, just hide it, because it's owned by the sender and only he/she able to modify it.
 In ZeroMail every user has a data file where he/she stores the messages he/she sent. You inbox lists messages from other users data file that is sent to you (encrypted to your public key).
This data files are only modifiable by it's owner, it means you can't delete from your inbox just hide it. The hidden messages identifier currently stored in browser's local storage, so it's not synced between devices.
 Mails are stored in your hdd, when you delete a mail from your inbox it adds the mail's id to browser's local storage. Next time you visit the page the js checks reads the deleted ids from browser's local storage and skips them.
  Thanks
  There is no other way to stop it yet.
  If you start your tor process on port 9050 and 9051, then it should work fine. The tor browser uses different port (9150 and 9151), be we don't connect to that service, because if you close the tor browser it would also make zeronet stop working.

If you want to share service with the browser then you have to start it using `zeronet.py --tor_controller 127.0.0.1:9151 --tor_proxy 127.0.0.1:9150`
  Sorry, I can't reproduce window opener security check using the docs site
 Yeah thanks, it's looks like-firefox only (no idea why), possible solutions:
- (recomended) The site owner add target=_top to every link. The easiest way to do this is creating a `docs.js` file with this content (docs.js referenced in the html source code, but it's not exists):

```
var base = document.createElement('base');
base.target = '_top';
base.href = document.location.href.replace("/media", "").replace("index.html", "").replace(/[&?]wrapper=False/, "").replace(/[&?]wrapper_nonce=[A-Za-z0-9]+/, "")
document.getElementsByTagName('head')[0].appendChild(base);
```

(please also upload [docs.css](https://github.com/HelloZeroNet/Documentation/blob/master/docs/docs.css))
- The site owner add  `"postmessage_nonce_security": true` to [content.json](https://github.com/HelloZeroNet/ZeroBlog/blob/master/content.json#L148), which is disable the popup message (default now for new sites)

Also added some modifications to latest revision to make it work better, but it's not 100%
  ZeroNet protocol is totally different from bittorrent and does not use any torrent liblary, so it's not an issue here.
 ips are not leaked when connecting to trackers, it uses the exit node ip
 The trackers also requested using the exit nodes, so i think it's not an issue
  Better way to disable caching:
- Open browser dev tools: F12
- Network > Disable cache (Chrome), Gear > Disable cache (Firefox)
- This will disable content caching until you keep the dev tools opened, so you don't have performance drawback when browsing the web normally
  `zeronet.py siteSign 1Apr5ba6u9Nz6eFASmFrefGvyBKkM76QgE --inner_path data/users/content.json --publish` should help (or you should pass the `--inner_path data/users/content.json` also for sitePublish)
  Unfortunately its not possible to query zeromails, because they are encrypted in the database. ZeroID is not really useful by itself, you will be redirected to it when you need to register a new one.
  Can't reproduce it under Win/FF/Chrome/IE yet
 Fixed in the latest version
  I think sharing scripts is a bad idea: It increase centralization and the CDN site owner would able to inject scripts to other sites.
 Still don't think it's worth relying on a central site to save 1-200kbyte storage
  The browsers does not allows this. Related topic: https://github.com/HelloZeroNet/ZeroNet/issues/83
 Using the [Chrome plugin](https://chrome.google.com/webstore/detail/zeronet-protocol/cpkpdcdljfbnepgfejplkhdnopniieop) you can access sites using http://zero/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D and http://zeroid.bit

I think it's better, because no need to modify OS settings (cross-platform issues) and for example in chrome you get confirmation window if you want to click on external protocol handler's link (eg. torrent://) http://i.stack.imgur.com/E3Yk9.png
  Updated!
  Added to latest version: https://github.com/HelloZeroNet/ZeroNet/commit/61cfb8aa2ff222b9a92e466dddf59c8d92f8e772#diff-0823b49a6bc2f350e7c6134f24e9440dR211
  It's possible already: Every user and site identified by a Bitcoin address. You can see the user's address by hovering on username eg. on ZeroTalk.
 Yes, your ZeroID's private key is in data/users.json file (auth_privatekey part) Its saved in WIF format that supported by most of the Bitcoin clients.
  You have to update your Tor to make it work

For instructions please check: http://zeronet.readthedocs.org/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
  NPM is for javascript, ZeroNet is written in Python, which has PIP instad of NPM. You can use `pip install -r requirements.txt` to install dependencies.
  It's not easy to do in safe way (the update method's replace process is not 100% safe). If you enable tor you should also switch to Tor browser, and preferably delete your data dir after you shut down your client.
  It's not possible because the per-site sql queries are merged for performance reasons (eg. if you follow 10 topics on zerotalk it visible as one subscription)
  You will be redirected to it if you want use a site that requires it.
  I don't think it's necessary, you can remove the site if it's abusing the feature
  the browsers are caching redirects, you have to clear cache to make it forget the old address: http://superuser.com/questions/304589/how-can-i-make-chrome-stop-caching-redirects
 Added a workaround to this problem by opening directly the site when clicking on the trayicon
  serviceworkers does not works within sandboxed iframe. it can be implemented in zeronet zeroframe api to display newsfeed events, but its still an expermiental technology, so maybe later when it's become more mature
  The easiest way to do this is using websocket api, the right version and dependencies also required if its imported as library.
 You can pack gevent and msgpack with your zeronet (there is a download, upack & run [zerobundle](https://github.com/HelloZeroNet/ZeroBundle) package for windows), so you won't have to install anything. QT is a GUI library, it has bindings for almost every language.
It's also possible to compile python programs into single executable , eg.: http://www.py2exe.org/ or http://www.pyinstaller.org/
  You can do this currently, around 2 months ago AES encryption API is added to ZeroNet bacause of the ZeroMail (end-to-end encrypted mailing) site.

For example currently you can create an encrypted image hosting site: at the upload. the user defines the password and publishes the image in encrypted form (eg. in a json file). In this way the image can be downloaded and served by anyone in the network, but only able to see it who has access the password. So there would be no evidence that you know what are you distributing, because if you don't have the password you could not decode the image.

Easier way to password encryption of sites or part of the sites are also planned.
 You have the full control over what are you seeding, if you find anything suspicious you can remove the site.
 You can simply delete the site you don't want to seed anymore.
 If you find any problematic content over any of the sites you can issue a warning in ZeroTalk forum, I don't think it would be a good idea to implement a built-in censorship. I don't see why is the command line required for this (or how is it connected to this problem)

If I upload anything problematic to my google drive and share the link over the internet will they arrest the google server operators?
  Site size is also visible if you choose "Order by site size" on ZeroHello  It happens when data/users/content.json is not signed correctly and your root content.json is also missing some information (eg the ignore node)
  Yeah, there is no error message callback yet, currently you can check if the user has cert or not by:

``` coffeescript
@cmd "siteInfo", {}, (site_info) =>
     if site_info.cert_user_id then alert(site_info.cert_user_id)
```
  Verify if your tor controll port is opened: `sudo netstat -anp | grep LISTEN | grep 9051` and `nc 127.0.0.1 9051`
  Thanks!
  Looks like you missing some package that required by pip. The Debian install method should work on mint: https://github.com/HelloZeroNet/ZeroNet#debian
 Follow the instructions in the message:
- sudo apt-get install python-pip
- sudo pip install msgpack-python --upgrade

OR

To update msgpack without PIP:
- Download msgpack from: https://github.com/msgpack/msgpack-python/archive/0.4.6.tar.gz
- Unpack anywhere
- Copy the msgpack-python-0.4.6/msgpack directory from it to the same directory where your zeronet.py is
  Try update gevent, 0.13 seems very old. (2012)
 you need python source to compile modules: `sudo apt-get install python-dev`
  changed to https, please test
  I don't think it needs to be configurable, but changed to reload it in every minute.
  Nice, built-in bootstrapping supported since 0.3.5, so you don't need separate bittorrent tracker.
- Rename `plugins/disabled-Bootstrapper` to `plugins/Bootstrapper`
- Add zero://bootstrapperhost:15441 to trackers list

example: https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Config.py#L34 (the #... thing is only needed for ssl cert pinning to avoid mitm, you can skip that part)
  It's simple to do with javascript or meta headers
 You can also add your redirect message/rectangle to html if you prefer that way
 After thinking bit more about it it could make sense if you want to transfer your site's ownership.
- The site new owner generates a new address
- You put "transfer": "newsiteaddress" to content.json
- When the clients receive that they rename the directory to "newsiteaddress" and transfer the settings (size limit, etc.), so they don't have to re-download everything 

But it's a very special case (currently i skipping features that affects < 20% of users), so it could wait.
  There is already: --homepage
  Fixed in latest 0.3.6
  Thanks
  I don't think its necessary, you can use the browser's bookmark or if you want shorter address you can register a .bit domain (costs only 0.01USD)
 The other way is using vanitygen: https://en.bitcoin.it/wiki/Vanitygen

You can generate custom bitcoin address eg. 1TheNain38HtKNngkdXEeobR76b53LETtpyT using, it also make easier to find your directory in data dir, in the logs and the browser will also complete it if you type "1TheNain38" in the browser bar.
  Allow to sign up to database queries, so you can have one, unified list of latest blog posts/comments/replies.

Todo:
- [x] Static version of new ZeroHello
- [x] Implement new commands
- [x] Modify ZeroBlog to allow signup to New posts/Username mentions/Comments
- [x] Modify ZeroTalk to allow signup to New topic/Username mentions/Comments
- [x] Site listing on new ZeroHello
- [x] Display site errors and notifications
- [x] Site commands on new ZeroHello: Pause, Delete, Clone
- [x] Display newsfeed on new ZeroHello
- [x] Merge similar newsfeeds
- [x] Real-time updated feed
- [x] Welcome message
- [x] Tor/Port open status to new ZeroHello
- [x] Settings: Always Tor mode, Update all sites, Update to latest ZeroNet version
- [x] New logo favicon/systray
- [x] Test in Firefox/IE/Safari
- [x] Multi user login/logout
- [x] UiPassword logout
- [x] Disable some admin function when using Multiuser plugin

New commands:
- [x] feedFollow feeds -> Set queries that user follows {Name: Query, ...}
- [x] dbQueryFeed -> List last results from signed up queries (admin permission required)

~~UI modifications idea 1:~~
- ~~Add new tab to sidebar~~
- ~~Add per site notification count to ZeroHello~~

UI modifications idea 2:
- Create a new ZeroHello with newsfeed-like activity listing

Query specification:
- event_uri: unique id of the event
- type: article, topic, comment, message, image, news, mention, album, warning, error, info
- date_added
- title
- body
- url

Query examples:
Last posts in ZeroBlog:

``` sql
SELECT 
 post_id AS event_uri
 "article" AS type,
 date_published AS date_added,
 title AS title,
 body AS body,
 "/Post:" || post_id AS url
FROM post ORDER BY date_published DESC
```

New topic in ZeroTalk:

``` sql
SELECT 
 topic_id || "_" || topic_creator_json.directory AS event_uri,
 'topic' AS type,
 added AS date_added,
 "New topic: " || title AS title,
 body AS body,
 "/Topic:" || topic_id || "_" || topic_creator_json.directory AS url
FROM `topic`
LEFT JOIN json AS topic_creator_json ON (topic_creator_json.json_id = topic.json_id)
ORDER BY added DESC
```

Last posts in ZeroTalk mentioned username:

``` sql
SELECT 
 topic_uri AS event_uri,
 'mention' AS type,
 added AS date_added,
 body AS body
FROM comment 
WHERE body LIKE '%@nofish%' OR body LIKE '%[nofish]%' 
ORDER BY added DESC
```

In the current form ZeroMail messages unfortunately won't be possible to put in the News feed
 Currently I preferring the second UI solution: So a new ZeroHello with News feed
 No, unfortunetly ZeroMail integration won't be possible in current form.
 The metadata is also encrypted, so without decrypting it its not possible to know if you or someone else received a message.
Maybe later it will be possible by moving the cryptography logic from javascript to python and store the data decrypted in the database, but not sure yet and it won't happen anytime soon.
 Yeah, its a good idea and title-changing ZeroFrame API command is planned.
 what is ZeroMe? The difference from merger sites (#232) is this feature does not allow content creation and listing is simpler, but it's similar.
 that screen only visible until you have something on your newsfeed, but pinning site to left side could be a good idea and planned later
 Fixed the menu bug.
  The Merger sites feature allow to to query and display other site's data. Using this its possible to create infinitely scalable social sites by having separate sites for every user profile, so you will get updates for profiles that you follow.

ZeroMe: A twitter-like social site
- [x] Layout mockups:
  - [x] Welcome page
  - [x] Profile profile
  - [x] User search
  - [x] News feed
- [x] Static html version
  - [x] Welcome page
  - [x] Profile profile
  - [x] User search
  - [x] News feed
- [x] Logo
- [X] Merger site permission handling/request
- [X] New database structure to allow easier and faster joins
- [X] Merge sub-site data files to merger site's database
- [X] Sub-site adding/delete/list
- [x] Make Sign/File oprations merger site compatible: actionSiteSign, actionSitePublish, actionFileWrite, actionFileDelete, actionFileGet, actionFileRules
- [x] Profile page data structure
- [x] Merger site rebuild DB
- [x] Profile page db structure
- [x] User directory data structure
- [x] User directory db structure
- [x] Update database on new merger/merged site add/remove
- [x] User directory
- [x] Sub-site feed listing
- [x] Profile creation
- [x] Profile page
- [x] Profile editing
- [x] Posting
- [x] Post editing
- [x] Post deleting
- [x] Activity list
- [x] Like
- [x] Commenting
- [x] Comment editing
- [x] Comment deleting
- [x] Follow profile
- [x] List followed users
- [x] Auto download new site on follow
- [x] Following without registered profile
- [x] Also update user database on profile modification
- [x] User content delete solution for efficient user directory archiving
- [x] Avatar upload

Later:
- [ ] Re-share
- [ ] File upload
- [ ] Image upload with thumbnail generation (optional files)

ZeroHello:
- [ ] Group sites by type
 Merger sites #232: Open
 Yeah, it's also add possibility to have a merged reddit-like site. It's won't be limited to user sites, so it could also help single-user sites.

Currently only planning one level nesting.
 I haven't started it yet...In the next few months
 After thinking about it for a while, i'm not sure if one site per user is a good solution

### One user per site

Every user has his/her own site, if you want to follow someone you start seeding the site. If you want to stop following simply remove site from seeding.

Pros:
- No one can modify your profile, but you
- ZeroID independent (comments still requires zeroid)
- Probably easier to implement

Cons:
- Initial seeding can be problematic
- Needs lots of connections (5connection/site is minimum to make sure you got every update)
- More network communication (tracker announce requests)
- More files and hdd space requirement on hdd (if you comment on multiple profile you only need new file for every profile)
- Less privacy: You exactly know who follows who (tor improves this)

### More user per site

Instead of one site per user create "hub" sites that hosts a few 100 users. (10MB limit enforces decentralization)

Pros:
- Initial seeding is no problem, because you joining to an already seeded hub
- Does not need many connection
- Other ppl only know what hubs you are following, but not the exact users

Cons:
- There is a hub owner, who has ability to modify/remove users
- ZeroID required to join a hub
- You get the changes for every profile on the hub

But if you don't want to trust the hub owner, then you can create your own hub and this also eliminates the other "Cons".

So I think the user hub solution is better in every aspects.
 One use per site is less scalable, because you need 5+ connection per site, so if you follow 200 users it means minimum 1000 concurrent connections which is not really sustainable. If the hub owner delete/censorship your posts you are free to switch to an another one, so its not really an issue.

Central messaging / automatically seeding every site without any control is against zeronet philosophy and does not really works with many users. 
 You can use your zeroid to communicate on any hub (there is no difference on this between one site per user and multiuser hubs)
 You will only see users in your newsfeed that you are really following (like you can follow only some of the topics on zerotalk), but you will keep receiving/seeding updates for this profiles. (the hub owner able to remove spamming users)

With user muting (#388) it could be possible to stop distributing updates for users you dont like.
 You can easily index zeronet content, since everything is stored on your computer in json files. There is already a search engine with indexed content: http://zeroexpose.com/ (searching in followed content should be easy without any third-party services)

The muting feature is independent from merger sites
 If you want to search in content that you don't have, then you need external services. Searching can be implemented to zerotalk/blog/etc. it's only matter of javascript code and it's not related to merger sites in any way. The muting feature is also unrelated to merger sites, if you start seeding a hub it does not mean you will start following every user automatically.
 Created an idea to be able to search in every site you serving: https://github.com/HelloZeroNet/ZeroNet/issues/419
 I have not started implementing it yet, but I think the hub sites is the only possible, scalable implementation and its also better for privacy
 Every hub site will be totally independent (there will be no difference between hub sites and any other current site), but it's not a problem, because the merger sites will solve this problem.

If you willing to host your content 0-24 then you can create your own hub, but inactive/not seeded profile sites will be  removed. 

You have to keep in mind, that one user per site is offer worse privacy to you and your users, because it's possible to know who is following who. (and later private messaging also planned later, so if you use separate site there will be possible to know who is messaged to you)
 Yes, it's more centralized, but there is no other way if you want to list/interact content in one place.

On the other hand it's also more decentralized, because the data will be separated from the display logic, so you can modify it (eg. different skin, new features) and you will be still able to browse the same data.
 Like is said before: if you want you will be able to create your own hub, so don't have to rely on anyone
 it should not be less attractive: If you create your own hub it's exactly the same as one user per site solution
 any suggestions for the social site name?

some ideas:
- ZeroHome
- OneZero
- GoZero
- ZeroMe
- ZeroFeed
- GroundZero
- ZeroLoop
- ZeroWay
- WeAreZero
- ZeroWay
- BeZero
- ThinkZero
- PushZero
- ZeroSociety
- ZeroNation
- ZeroWorld
- OnZero
- MeetZero
- ZeroSpark
- ZeroSignal
- Zolo
- Zelf
- Zello
 Every zeronet site is totally independent. Hub = normal ZeroNet site
 @62gs8ha: Merger site (and zeronet) is mainly for data-based sites, but you can define optional files that only downloaded when the user's browser requests it. 
Example: https://github.com/HelloZeroNet/ReactionGIFs/blob/master/content.json#L1796 
site: http://127.0.0.1:43110/1Gif7PqWTzVWDQ42Mo7np3zXmGAo3DXc7h (currently has 560 MB of video, but they only downloaded if your client's browser requests it)
 the syntax is a standard called regexp (http://www.petefreitag.com/cheatsheets/regex/)
- `"optional": ".*\.(jpg|png|gif)"` will make all png, jpg, gif file optional on your file (not recommended if you have other, smaller images in your site, eg your logo)
- `"optional": "(data/videos/.*|data/documents/.*)"` will make all files inside data/videos and data/documents directory optional
 @Split7fire If I can't find any more bug then tomorrow.
 I think i was able to fix all the bugs, tomorrow morning i going to re-check everything, then publish it
 If you already upgraded to 0.4.0, then you can help testing ZeroMe: its visible at ZeroHello's "More sites" section.
 @wigy-opensource-developer It's better click from the homepage (it's only visible if you update to 0.4.x), because it using new database structure for merger sites, so if you visit it using 0.3.x version, then you have to delete and re-add it to make it work.
  Unfortunetly its not possible. (there is no server-side rendering in zeronet)
 Thinking a bit more about it RSS could be possible by also generating the static XML file at new post, but i'm not sure if RSS is widely used anymore.
 Probably Twitter/Facebook killing it: http://www.google.hu/trends/explore#q=RSS
But I agree, it would be useful addition for ZeroBlog.
 No need new command, you can currently write files using the ZeroFrame API

So instead only adding the new blog post to data/posts.json you also add it to rss.xml file
  you have to edit css/all.css and put this line to the top:
`.left .avatar { background-image: url(../data/img/logo.png) }`
  The Tor controll protocol (port 9051) only accept connections from 127.0.0.1, but if multiple user has access to your computer then it's recommended to enable CookieAuthentication.

You don't need root access, but you need to add the user you use to run ZeroNet to Tor's user group.

Steps to do this under Debian: http://zeronet.readthedocs.org/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux

It should be similar under Ubuntu.
  What OS are you using?
 please try the instructions in #229, it helped there
 Tor by default running on ports 9050/9051. if you want to use it with Tor browser's tor instance you have start zeronet using `--tor_proxy 127.0.0.1:9150 --tor_controller 127.0.0.1:9151`
 On windows tor is automatically downloaded on first startup that that's the configuration file for it. it's not used on other platforms
 It's not recommended to use the Tor browser's tor instance, because if you close the browser zeronet will also loose the connection. Running tor as system service is better: https://www.torproject.org/docs/tor-doc-osx.html.en
 If you often leaves and re-joins the network, then it is bad for you: You client has to re-validate the contents by ask updates to all site you have visited before and it's also results lots of unreliable/unreachable peers which is bad for the network.
 For windows there is an "expert bundle" that contains tor.exe, so we can download/configure/start it automatically, it would be nice to have same way for mac, but i have not found binary tor.app distribution yet
 No, they not working, but there is no binary for Linux neither
 It works, see: https://github.com/HelloZeroNet/ZeroNet/issues/228#issuecomment-204717804
  Thanks for reporting the disable SSL compression error will be fixed in the next version.

Unfortunately the CryptMessagePlugin (that include cryptography required for ZeroMail) requires OpenSSL, so it will not work without that and for some reasons it could find in enviroment. I will try to find a way to load cygwin's openssl dll. 
 Can you please verify if this works for you: 
`python -c "print __import__('ctypes.util').util.find_library('libcrypto')"`
 It's searching for openssl dll, so its not depends on other python modules installed.

can you check if you have "libcrypto.dll", "crypto.dll", "ssl.dll", "libeay32.dll" or similar in /usr/lib/?
 I also installed cygwin and only thing I was able to make it work:
`python -c "print '%.9X' % __import__('ctypes').CDLL('/bin/cygcrypto-1.0.0.dll').SSLeay()"`
please verify if its also works for you
 Yes, this is what we looking for, I will do some tests then release the patch that fixes cygwin compatiblity
 Pushed the modifications (394a8b16b7521d1885e2e96cb6d0a413b4478bc9) please update your source code and try again.
You can test if the openssl working on http://127.0.0.1:43110/Benchmark page.
`- openssl verify x 100..........0.396s [x0.93: OK]`
 sorry, my bad, please update and try again 35b0019be285cd81dac9d3e0ed97712c76f88a93
  Plugin for custom torrent-tracker like bootstrapping, it will allow full Tor support with hidden addresses
- Allows to store Tor/ipv6/i2p addresses
- Announce multiple site in one request

New FileRequest command:
- announce:

```
{
 "sites": [hash1,hash2, ..], 
 "port": 15441, 
 "onion": "3fyb44wdhnd2ghhl", 
 "onion_publickey": "publickey for onion address",
 "onion_sign": "signed hashes array to provide proof of onion_address", 
 "onion_sign_this": 439284923849,
 "need_type": ["tor","ip4", "ip6"], 
 need_num=10
}
```

Return: 

```
[
 { "ip4": [address1, address2], "onion": [address1, address2]}, "onion_sign_this": current_timestamp}
]
```

`onion_sign_this` is only returned if new address is added for onion address. It's required to avoid signing up addresses you don't own. If `onion_sign_this` is in the returned result then the client has to sign it using the onion address's RSA private key and execute the announce request again with `onion_publickey`, `onion_sign` and `onion_sign_this` fields added.

New command line option: --tor, values
- Always: Open hidden service on startup, use Tor for every connection, do not bind on normal ip
- Enable: If no external IP then open Tor hidden serice on startup, use Tor only for onion addresses (default mode)
- Disable: Do not use Tor at all

Disable [unnecessary](https://www.reddit.com/r/onions/comments/27a64z/https_everywhere_onions/chz70i9) SSL encryption on onion address connects (speeds up connection time)
- [x] New FileRequest command: announce
- [x] Modify zeronet to support bootstrapping from other clients
- [x] Onion address cryptographic functions (sign, verify, pubkey to onion address)
- [x] Onion address support for Bootstrapper
- [x] Onion address support for ConnectionServer
- [x] Disable SSL over Tor connections
- [x] Store Tor clients
- [x] Exchange Tor clients over PEX
- [x] Start/stop hidden services on site visit/delete
- [x] Test Connection peer lock
- [x] Display Tor status in ZeroHello
- [x] Only Tor mode
- [x] Disable Tor mode
- [x] Support Tor control port auth
- [x] Bootstrap statistics page
- [x] Batch onion announce
- [x] Option to keep ssl certs to allow cert pinning
- [x] Do some real-life testing
- [x] Pack Tor client with ZeroNet
- [x] New command line option: --tor
 new ADD_ONION and DEL_ONION commands for per site (and preferably per user) different onion address: https://github.com/Yawning/torspec/blob/master/control-spec.txt
 what do you mean?
 The new ADD_ONION and DEL_ONION commands allows to create and remove hidden services using the onion controller API. So if you visit a new ZeroNet site then a new hidden service (.onion address) will be created for it and also new .onion addresses will be generated when you restart your client.
 Done in Version 0.3.5
  Sounds like something with ssl connection, can you please specify your platform and try to start it with `zeronet.py --disable_encryption` ?
 Encryption is not needed, but recommended. Yes, you can copy old data dir to new.
 I had no similar report before. It's hard to tell whats the problem without reproducing it. Can you please specify your OS version?
 It was related to gevent 1.0.2, fixed in 44a68104fb867f193433aea2be0c791475ff3913
  Well, I'm not against if someone offers ZeroNet hosting as service.
  It's hard to make it work without direct hardware access, but you are also fine without opened port.
 You are safe to ignore it, opened port is not required to use zeronet
 Probably an another router/isp is blocking your port.
  Probably there is no user exists in your data/users.json file. Start zeronet normally to generate one for your then it will be fine.
 yeah, the user is generated on first web request, so it can be problematic on headless mode. Pushed a quickfix, after updating it should work now: 675bd462556c541d65e2d95f91f899146a373aad
  The ZeroBlog is only an example site, there is lots of space (and working hour) of improvements, but I will leave it to other developers.
  Sorry, this looks like ZeroUpload related error, so I can't fix it. Official sites that I able to modify: https://github.com/HelloZeroNet?tab=repositories
  The site does not have any special characters in the files, so probably you have installed your zeronet to non-english characters directory

try moving your zeronet installation to \ZeroNet and try again
 Yes, its a bug, thanks for reporting, i will fix it soon
 Fixed in 3d558a4edfe527450d99458f10cf7681eb96590f
  ZeroNet is an application framework not a social site. Every site is totally independent, so you can create your own startup page if you want, the ZeroHello is just a site on ZeroNet. The source code is here: https://github.com/HelloZeroNet/ZeroHello
  - userPublickey -> return: Get user's publickey delivered from privatekey
- userDecrypt encrypted_text -> return: Decrypted text using current user's privatekey
- cryptEncrypt publickey, text -> return: Encrypted text
- [x] Implement API commands
- [x] Static prototype of the site
- [x] Welcome/Registration screen
- [x] Register user's publickey
- [x] Send message
- [x] List incoming messages
- [x] List sent messages
- [x] Mark new, unread messages
- [x] Contact list
- [x] Faux delete from incoming folder
- [x] Echo bot for testing the service
- [ ] Later: Message thread list
 Problems:
- the current library does not support encrypting / decrypting, so have to find an another for this task
- Is it secure to use the same private key for signing and encrypting? https://bitcointalk.org/index.php?topic=374085.msg4004761#msg4004761
 I successfully encrypted/decrypted texts using bitcoin private/publickeys, the speeds (the lib using c based openssl):

OpenSSL init 0.40299987793sec
Encrypt 100x... 1.45700001717sec
Decrypt 100x... 0.694000005722sec

If we want to hide the message recipient (and probably we do) then we have to try to decode all messages that is going through the system.
To do this efficiently we have to mark and cache messages that we have already checked. So we need a zeronet built-in cache system (probably sqlite based) that is multi-user friendly or we can store the messages in browser's localstorage.
 For experimentation I tried javascript based encrypt/decrypt solution (bitcore), but it's around 80x times slower, so it's not really an option.
pure-python implementation (bitcoin-encrypt) 20x slower
 After doing some research encrypting using only the ecc public key ([bitmessage method](https://github.com/Bitmessage/PyBitmessage/blob/master/src/highlevelcrypto.py#L23)) is not secure eg.: https://www.reddit.com/r/Bitcoin/comments/2ntpvh/bitcrypt_encryption_with_bitcoin_addresses/cmhmny9

So I changed the code from `eccEncypt(text)` to:
`eccEnrypt("ZNE1" + aes_key + aes_iv + aesEncrypt(aes_key, aes_iv, text))`

(similar to [electrum's encryption](https://github.com/spesmilo/electrum/blob/ae425764237d89a5e16db4f984406509f08f2601/lib/bitcoin.py#L541), but without hmac)

The encryption/decryption speed is similar, but it's add + 276 bytes to every message.

It would be nice if someone with more experience in this field give some advice if its a good way to encrypt messages like this.
 The 'cryptografically secure' is not depends on library, but the algorithm.
 The crypto API commands are implemented:
- cryptEncrypt(text, publickey) -> Encrypt a text using the public key, Return: Encrypted text using base64 encoding
- cryptDecrypt(encrypted_text, privatekey) -> Decrypt a text using the private key, Return: Decrypted text
- userPublickey() -> Returns user's public key unique to site, Return: Public key
- userDecrypt(encrypted_text) -> Decrypt a text using the user's site unique private key, Return: Decrypted text
- userDecryptBatch(encrypted_texts) -> Decrypt a list of texts using the user's site unique private key, Return: List of decrypted texts

In the next weeks i'm going to create the messaging site to see if its works correctly, then release the plugin
 Every published file is signed by your client, so not necessary to sign messages.
 You can create a file containing the contract the sign it using the client.
 Yes, you have to send the contract to other user to be able to sign it. Currently only features are implemented that has benefit for any of demo sites to avoid bloating and currently no site planned yet that has anything to do with contracts.
 Added my ideas and questions here: https://www.reddit.com/r/crypto/comments/3t6vnm/need_guidelines_for_ecc_based_messaging/

Information I found for the second idea:
http://security.stackexchange.com/questions/21371/decryption-on-aes-when-the-same-key-and-iv-are-used
It looks like it could be safe reusing the same secret in cbc mode if the message does not starts with the same string. To avoid this we could add random prefix to every message.

Non-public key based, AES encoding of messages would be better for multiple reasons:
- Shorter messages (256+128 bit shorter than first method)
- Faster decoding: 100x ECC + AES = 0.7sec, 100x AES = 0.006sec
- Don't have to store twice: If we encrypt the messages using public key the we won't be able to see our sent message, so have to also encrypt it with our own public key which doubles the storage required.

Cons:
- Everyone will see if you add a new shared secret to your file = started messaging with someone new
- It's more complicated and harder to implement

## Technical whitepaper:

### Method 1 (ECIES: New shared secret for every message):

Per message overhead: 183byte + 41byte (encrypted AES key to my public key to have sent folder)

Sending: 
- Get Bob privatekey
- Encrypt message (to_address, subject, body) using ECIES
- Add to data.json: {"message_id":1, "date_sent": 112382913, "encrypted": "..."}

To have sent messages:
- Decrypt my sent_keys dict
- Add message_id -> aeskey 
- Encrypt again

Checking new messages:
- Already known user files: `SELECT * FROM message WHERE (user_address = 'A' and message_id > 1) OR (user_address = 'B' and message_id > 2)`
- New user files: `SELECT * FROM message WHERE user_address NOT IN ('A','B') and date_sent > my_public_key_added`
- Try to decrypt all message usic ECIES (130/sec)
- Store in browser localstorage: `{date_checked: {A: 1, B: 2}, my_messages: [A_1, B_2, A_3]}`

Displaying my messages:
- `SELECT * FROM message WHERE message_key IN ('A_1', 'B_2', 'A_3')`
- Decrypt messages using ECIES

Displaying sent messages:
- Decrypt AES key from sent_keys {message_id: aes_key}
- `SELECT * FROM message WHERE user_address = my_address`
- Decrypt ECIES (iv: [0:16], ciphertext: [16+70:-32]) using saved AES key

Cleanup:
- Delete oldest message
- Remove it from sent_keys
- Delete non-existent my_messages

New command requred:
- cryptDecryptAes [aes_key1, aes_key2, ...], [text1, text2, ...] -> Tries to decode every text using every aes key

### Method 2 (One time shared secret):

Per message overhead: 0byte
Per contact overhead: 227byte + 70byte (encrypted AES key to my public key to have sent folder)

Sending:
- Decrypt sent_keys dict
- Check if the recipient address in it
- If no shared_secret with user yet:
  - Generate new AES key
  - Encrypt new key using recipient's public key and add to keys (ECIES)
  - Add new key to sent_keys that is encrypted using my public key (ECIES)
- Encrypt (to_address, subject, body) using AES
- Add to data.json: {"message_id":1, "date_sent": 112382913, "encrypted": "..."}

Checking new shared secrets:
- Known user files: `SELECT \* FROM key WHERE  (user_address = 'A' and key_id > 1) OR (user_address = 'B' and key_id > 2)
- New user files: `SELECT * FROM key WHERE added > my_public_key_added`
- Save found keys to local storage {my_key: [A_1, B_2], key_checked: {A: key_id, B: key_id}, message_checked: {A: last_message_id_before_my_key added}}

Checking new messages:
- `SELECT * FROM message WHERE (user_address = 'A' AND message_id > user_A_message_checked) OR (user_address = 'B' AND message_id > user_B_message_checked))`
- Try decrypt them using AES (13000/sec)
- Save found messages to localstorage: {my_message: [A_1, B_2]...}

Displaying messages:
- SELECT \* FROM key WHERE message_key IN ('A_1', 'B_2')
- Decrypt AES keys using ECIES
- SELECT \* FROM message WHERE message_key IN ('A_1', 'B_2', 'A_3')
- Decrypt messages using AES

Displaying sent messages:
- Decrypt AES keys from sent_keys {user_address: aes_key}
- `SELECT * FROM message WHERE user_address = my_address`
- Decrypt messages using saved every AES key

Cleanup:
- Delete oldest message
- If no email left with recipient: Delete from sent_keys, Delete from keys
- Delete non-existent my_messages

New command requred:
- cryptDecryptAes [aes_key1, aes_key2, ...], [text1, text2, ...] -> Tries to decode every text using every aes key
 I have thought about multiple recipient messaging, it would be possible by using the second method (one time shared secret):
- Generating new AES key for the group
- Encrypt the generated AES key for every users publickey in the group
- Encrypt message using the generated aes key

So one time, per group overhead would be: (227byte + 70byte) \* User number in the group. After the group secret is shared, the message sending space would be same as for single recipient sending.

Its also possible using the first method, but then it would be count as separate messages. So if you want to send it to 5 user it will take 5x more space. 

Probably I will choose the first method as its simpler to implement, so it will not feature group messaging.
 Added in 0.3.4
  Thanks, I can't merge the all.js changes because its generated by coffeescript compiler, but merged the Scrollbable.js changes in 3587777ea8adf48c1c23b8c34ccc43a76ffb4551
  With ZeroNet you have an SQL server running on localhost that is always accessible, so you don't need backend server running nodejs or php.

P2P sites requires different thinking than traditional Client <-> Server approach, but porting single page applications could be possible. 

Presentation about how does ZeroNet works: https://docs.google.com/presentation/d/1_2qK1IuOKJ51pgBvllZ9Yu7Au2l551t3XBgyTSvilew/pub?start=false&loop=false&delayms=3000
And there is a _"Tutorial of creating server-less, SQL backed, real-time updated P2P chat application using ZeroNet in less than 100 lines of code"_ in ZeroBlog
 You have to use javascript + html, executing php/python/etc. code would not be safe.
  Thanks
  Thanks for reporting, fixed: https://github.com/HelloZeroNet/ZeroNet/commit/5f0266ed8fd42aa66b5baf3b014bdf1cded4b4eb
  Not sure what do you mean
 You can use the "Keep signed in" checkbox to keep your computer password-less on loopback 
 It could still make sense, but i think its not worth the added complexity
  fixed e296ee7ebb6d5a98431c5d9ef662179778540b9c
  Thanks, fixed: 713baeab63b546dca6a69608a2e3613dd6e87118
  Binding to ui to a public interface is usually not a good idea, and it would make that mistake easier.  Just copy data/users.json file
  Can you please run the command `python -c "import sys; print sys.version; import gevent; print gevent.__version__"` ?
 Not sure why is it happening with gevent 1.1alpha, but added a workaround in latest commit. So please clone again and then it should work.
  Does it helps your problem?
 I think its better let the browser handle the connection. (close might be not compatible with every browser: http://stackoverflow.com/questions/5545161/unable-to-close-websocket-with-javascript)
 Yeah, i think we can close it
  The log looks normal, maybe its connection related problem. (never happened for me)
 Running on localhost or remote machine? Also appears on other borwsers? Is it happens on idle browser window? Also please try to check javascript console for errors.
 sorry, I can't reproduce it in firefox 41.0.2 or ie 11 (i have been clicking around for 5 minutes)
 I'm also on windows 8.1 64bit. 

You can try it on http://bit.no.com:43110/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr if you also getting disconnections there then probably its a browser problem.
 I have just installed the zerobundle on new machine no issues with ff/ie/chrome. 

Try a clean zeronet setup, disable your firewall/antivirus software. sorry no other ideas.
 Its looks like a problem with utf8 file names. I will check it later, but not sure if related to this problem.
 Try start using --debug then look console for web requests/errors, the request order should look like this:

```
[18:03:02] Ui.UiServer 127.0.0.1 - - [2015-10-23 18:03:02] "GET /1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr HTTP/1.1" 200 2514 0.001000
[18:03:02] lib.geventwebsocket.handler Initializing WebSocket
[18:03:02] lib.geventwebsocket.handler Validating WebSocket request
[18:03:02] lib.geventwebsocket.handler Attempting to upgrade connection
[18:03:02] lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[18:03:02] Ui.UiServer 127.0.0.1 - - [2015-10-23 18:03:02] "GET /1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/?wrapper_nonce=xxx HTTP/1.1" 200 2710 0.002000
```
 You can also try to add this to src/Ui/media/all.js before the `}).call(this);` line (it will close the websocket before navigating away):

``` javascript
window.onbeforeunload = function() {
    console.log("Closing WebSocket")
    window.wrapper.ws.ws.close()
}
```
 Looks like you requested the page at [18:16:13], but the first websocket request only reaches the server 1 second later [18:16:14], can also you check the log/debug.log please? (it has more accurate time format)

My timings looks like this:

```
[2015-10-23 18:28:25,618] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 18:28:25] "GET /Talk.ZeroNetwork.bit/?Home HTTP/1.1" 200 2489 0.008000
[2015-10-23 18:28:25,707] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-10-23 18:28:25,727] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-10-23 18:28:25,739] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-10-23 18:28:25,740] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-10-23 18:28:25,743] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 18:28:25] "GET /Talk.ZeroNetwork.bit/?Home&wrapper_nonce=xxx HTTP/1.1" 200 6116 0.002000
```

So there is <100ms time window between the GET and the WebSocket init.
 Hm, i'm out of ideas. It needs deeper inspection whats happening on the the websocket channel using sniffer (eg. wireshark) or adding logging to src/lib/geventwebsocket. In chrome you can also check the websocket communication using the developer tool's (F12) network tab.

Is it also happening if you only have the ZeroHello site in your client? (to make sure it's not caused by the site with utf8 filenames)
 The log showin other sites, 1DWTx5..qTJd (has utf8 filenames), 16Basi..mTcs
 it's looks like your client still have that sites (maybe stucked in the client if you removed them). Please stop your zeronet client, rename "data" dir to "data-old" then start again to have a clean state and see if you still have the websocket problems.
 there is no built in method, you can add `print "WS IN", message` [here](https://github.com/HelloZeroNet/ZeroNet/blob/master/src/lib/geventwebsocket/websocket.py#L286) and `print "WS OUT", message` [here](https://github.com/HelloZeroNet/ZeroNet/blob/master/src/lib/geventwebsocket/websocket.py#L341)

Also try to check developer tools in chrome, it displays websocket frames
 It was tricky one, which antivirus software causes problem like this?
  I'm unable to reproduce the problem
 Thanks, I was able to reproduce, added a [different fix](https://github.com/HelloZeroNet/ZeroNet/commit/713baeab63b546dca6a69608a2e3613dd6e87118#diff-96bfdc2cfcb5739e88aad648cba5e983R120), as it conflicts with other pr
  It should work, but you need to add target="_top" or "_blank"
  You can start it using `python2 zeronet.py`
 The current (working) directory must be where you unpacked zeronet, so:
- `wget https://github.com/HelloZeroNet/ZeroNet/archive/master.tar.gz`
- `tar xvpfz master.tar.gz`
- `cd ZeroNet-master`
- `python2 zeronet.py`
  If this happens then every currently known computer network become unsafe.

Currently this is only "in theory" and not reality. The encryption will evolve when Bitcoin's current cryptography breaking computers become reality and we will follow change.
 The current bitcoin address format can be considered as quantum proof:

> "quantum computing is not very useful for breaking hashes like SHA-256. Just signature and encryption algorithms like ECDSA or RSA. To attack ECDSA, you need to know the public key. However, most addresses are made from the hash of the public key, which is not enough to start attacking ECDSA. You'd need to break the hash first, which won't be significantly easier with quantum computers.
> TL;DR any normal address that hasn't been spent from before is safe. So, if you use Bitcoin the way the developers recommend and don't reuse addresses, your coins are quantum safe, at least for now." 

https://www.reddit.com/r/Bitcoin/comments/3wfmg2/satoshis_unmoved_coins_are_the_worlds_biggest/cxw6osp
  Please be more specific
 What os/browser are you using?
  I think creating an empty site does not make much sense for the most of users. You can clone a site using then modify/delete the files if you really want to use the GUI.
  I think it would make the things more centralized, so it's better to have separate and independent data for every site.
  You can use the taskbar icon to shutdown: right click > exit
  The current logo was created in rush, some first ideas for new one:
![zeronet_logos](https://cloud.githubusercontent.com/assets/10350359/10103145/ac9cc8a6-63a2-11e5-9e2b-b35efec37a32.png)

Which one do you like? Other designs also welcome.
 In smaller sizes it can be simplified:
![zeronet_favicon_smooth](https://cloud.githubusercontent.com/assets/10350359/10117719/4162b6b8-6460-11e5-8e48-9466bf6dac73.png)
 new ones with 45Â° rotation:
![new_logos](https://cloud.githubusercontent.com/assets/10350359/10122827/2f433c48-6526-11e5-864c-d87597157a80.png)
 a more lightweight idea:
![logo2](https://cloud.githubusercontent.com/assets/10350359/10891948/1e7cd21a-81a1-11e5-8658-4cb62b8c7dfe.png)
  Its error: the response to the ping is "Pong"
  Thanks, but i think its reduces readability.
  Thanks, but i think its reduces readability.
  this is not a bug, but how zeronet works: you can't modify other user's data file 
  Thanks, but I think it's not improves the readability (syntax highlighting only works on cd command)
  I'm not a native speaker, so I googled for "currently served by", first page matches:
- Churches currently served by the EAMC Parish Nurse Program
- Line 52 will pass under the River Ij, currently served by GVB ferries.
- Water Supply to an Area of a City currently berved by a ...
- Schools currently served by the Chula Vista Nature Center ...
- Community currently served by long distribution lines
- majority of owners in an area not currently served by the waterwork
- Murcia is currently served by two airports 
- Which country is not currently served by peace corps
- The LDS Meeting House is currently served by City wastewater
- City Utilities invites neighborhood associations currently served by Aqua Indiana water service to include this column

So booth looks valid to me...
  thanks, fixed: https://github.com/HelloZeroNet/ZeroTalk/commit/935a4e0b3fcdae5dbf439bb0564b7128939a2b75
  You can change it using `zeronet.py --ui_port 1234 --ui_ip '1.2.3.4'`
  Sure, it has to be configurable if use 3G connection or not, but an update only a few KB, so I think it wont affect your data plan in most cases.

To avoid privacy problems it could be also per-site configurable if you want to share it to people around your or not.
  Thanks for reporting, added escaping in latest commit: 54c367cac83e04e906b453a6ff8fb36079370ca8
  Crazy or not, it would add a new level of security. :) Signing custom messages [looks easy](https://github.com/trezor/python-trezor/blob/master/tests/test_msg_signmessage.py) with trezor, so it should be possible.
  Periodically (or when new content.json received) delete files that not included in new content.json anymore.
- add new command to ZeroFrame API: fileDelete
 Added in Rev409: 917393c0227b1e87d9206b25dbb17941d7692fac
  Provide a way to define not automatically downloaded files in content.json. It will make possible to create larger sites with many image (and later videos).

To do this we can simply add `optional_files` node to content.json that is identical to current `files` node. This files only downloaded if user is request it directly (by a http request).

These files are excluded from site limit calculation (10MB by default). These files lands in a cache registry which has use-configurable size, and if the cache is runs out of the configured limit the most seeded file will be automatically removed.
## Problem 1: Initial distribution

In a Multi-user imageboard site if someone uploads a new image it will not downloaded by default anyone, so he/she has to wait until someone open the site and request it.

Possible solution: It would be possible to join to a site as "sponsor" who is downloads every optional files automatically and keeps it seeding until its necessary.
Also every user would be able to add "share friend" users. If your share friend uploads a file you automatically downloads his/her files and help to distribute it.

The API also adds possibility to "pin" (where it will not removed automatically from cache) and dislike (immediately remove) files.
## Problem 2: Who has it?

Currently every peer has every file, so if you want to download a file you can request it from anyone. With optional files this is going to change: To solve this every connected peer has to keep a `hashfield` table which holds the downloaded files hashes first 4 character (only first 4 for economy reasons) eg.:

```
peer1 = ['8a42', 'fa11']
peer2 = ['12ab', 'bbc9', 'd39a']
```

If you want to download an optional file you checks if it's hash's first 4 character is in any of connected peer's hash table. If its not then you ask your connected peers to check if any of their connected peers has it. If still not found you can try to connect other peers randomly.

If you finish downloading an optional file you send the connected peers to add it to your `hashfield`, so if anyone looking for it later they will know you has it. (Probably some kind a batching is recommended)
## Current status
- [x] Sign optional files
- [x] Download/verify optional files
- [x] User optional files rules (size and filename limit)
- [x] Peer hash table sync/find peer by optional file for more efficient optional file download (who has it?)
- [x] Super seed site (also download optional files)
- [x] More testcase
- [ ] ~~Modify ZeroTalk to allow file uploads~~ (did the ReactionGIFs site instead)

Later: Size limited optional cache, File pinning, User follow
 Maybe a "Superseed" startup option could work where you keep more open connections and publish the new modifications more than than default 5 peer. Also currently the client decides randomly which peer he start to download the content, it could be possible to keep track the last download speed and next time he will prefer the fastest peers in the network.

I think its very easy to abuse the "seed any new site in the network" method, but this could work:
Add a "Please seed my new site" topic in ZeroTalk and create a bot that automatically starts seeding the links that sent there. This way it would be possible to have some kind a control over the sites. 
Eg. If someone sends a malicious sites there and the moderator remove the link (or it receives many down vote/report) then the bot stops seeding it.
 Creating multiple sites (eg one per user) instead of increasing the hashtable length is more scalable solution.

Also a collision is not a big problem, it's just increase the network communication: the find peer by hash returning some peers that doesn't has the file you looking for.
 the files are hashed using sha512, which is not-colliding (yet)
 yes, breaking a hash method is only matter of (cpu) time
 The file hashes are currently stored in a content.json file, so it would be huge with million files. (122byte/file)
It's possible to split it up using includes, but it would be still problematic. Probably building a DHT network to access static files would be better solution, but it also has drawbacks: slower and does not works well on TCP (Tor)

The goal is to stop building huge, monolith sites. Decentralized sites should be also decentralized by ownership and not only by distribution protocol.
  Providing a centralized http proxy would go against the purpose of the network. (decentralized, uncensored)
 It's possible, you have to start it using `zeronet.py --ui_ip "*"`

More info: http://zeronet.readthedocs.org/en/latest/faq/#is-it-possible-to-install-zeronet-to-a-remote-machine
 it's possible if you redirect *.bit and zero domains to 127.0.0.1:43110
this extensions to this for your: https://chrome.google.com/webstore/detail/zeronet-protocol/cpkpdcdljfbnepgfejplkhdnopniieop/
you will able to access eg http://zeronetwork.bit directly
  Good idea, added notification button/input autofocus in latest update: 917393c0227b1e87d9206b25dbb17941d7692fac
Probably a multiple site selection will be required sooner or later to make it more comfortable.
  Try to use pip2 or pip2.7 since zeronet supports python 2.x and not yet 3.x
  To improve security every ZeroNet site runs in a sandboxed iframe. 
Looks like the browsers does not allow to load pdf to iframe. To load to the top frame you have to add `target="_top"` to your a html tag or `<base href="" target="_top"/>` to head to automatically convert every link on your site.
  Every site is served from a sandboxed iframe that is treat the content as being from a unique origin.

Also XSS is not possible in zeronet, since there is no server-side rendering, cookies or POST requests (everything is done using the websocket API).
 Thanks for pointing out, this is a true security flaw. Do you have any suggestion how to fix it?

My idea: Every time when the "wrapper" page called instead of adding "wrapper=False" to url it generates a one-time key and only serve pages with html content-type if a correct one-time key is present.
 There is an [semi-auto update mechanism](https://twitter.com/HelloZeroNet/status/568575098904555520) that download the latest version and restart node automatically if needed.

I addressed a [quick fix](/HelloZeroNet/ZeroNet/commit/eec0b22c1fe233c553e10a5faeee193cf9adb997) to popup attacks (its works on browsers I tested), I will try to implement the nonce based non-wrapper html rendering later this week.

There is a [chrome plugin](https://chrome.google.com/webstore/detail/zeronet-protocol/cpkpdcdljfbnepgfejplkhdnopniieop) that maps .bit domains, but it leaves other sites on same host (http://zero/[siteaddress]) since domain names are converted to lower-case by default and site addresses are case sensitive. I try to avoid custom browser if possible since it makes cross-platform and mobile compatibility much harder.
 The fix only do one thing: It prevents the attacker to get the wrapper_key variable that is inserted into the wrapper frame html source on request.

This key is unique per site, you can connect to the websocket API using this and it defines the permissions you get. Even if you can still spoof the referrer as you described without this key you can't really do anything, but access the static files of the site that holds no secret.

Escaping the sandbox still and issue and I will try to implement the nonce based security. This will still leave the same-domain issue unfixed, but I think that one is not possible to fix without custom browser / plugin.
 ~~Using sandboxed iframe does loads the content, but enabling the sandbox also denies the parent document to access the frame's content: `document.getElementById("sandboxediframe").document` returns undefined~~

~~The `window.stop();` command immediately stops the html parsing and load, so the html content is not overwritten by document.write but never gets loaded.~~

by adding `sandbox="allow-same-origin"` to iframe it does allows to load the wrapper's html and steal the wrapper_key :( 
 I have added nonce based wrapper rendering in the latest revision. 0de6496f96316514a07c4b1cbaf4a9f29a2411cb

It required [some magic](https://github.com/HelloZeroNet/ZeroNet/commit/0de6496f96316514a07c4b1cbaf4a9f29a2411cb#diff-faa3945ca6d392977a2c7d4e1acb865fR60) to make back/forward button work correctly, but it works in latest Chrome/FF/IE/Opera/Safari.
 Thanks for suggestion, So changing to this makes it cryptographer safe?

``` python
    wrapper_nonce = ''.join(
        random.choice(string.ascii_uppercase + string.ascii_lowercase + string.digits) for _ in range(24)
    )
    wrapper_nonce = hashlib.sha256(wrapper_nonce).hexdigest()
```

Or is it even better using [os.urandom](https://docs.python.org/2/library/os.html#os.urandom)?

``` python
wrapper_nonce = hashlib.sha256(os.urandom(256)).hexdigest()
```
 The HOST file could work for .bit domains, but then you have to bind your UI to port 80 (not free on many computers) and it would require administration permissions to modify it. (and non-.bit sites also would remain on the same host)

There is a [chrome extension](https://chrome.google.com/webstore/detail/zeronet-protocol/cpkpdcdljfbnepgfejplkhdnopniieop) that maps .bit domains to your zeronet client. Hopefully its  possible to create similar for FF/IE.
 It gives me: `XMLHttpRequest cannot load http://127.0.0.1:43110/zeroid.bit. No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'null' is therefore not allowed access.`
 It could be an improvement, but escaping from the sandbox would be still problematic, because for example the site would able to modify the site settings when the user has the sidebar opened.

So as long we can avoid the escape from the sandboxed iframe I think we are fine.
 allow-popups and allow-popups-to-escape-sandbox probably will be removed as it's not working well in every browser, but it does not modify the cross-domain policy:

```
w = window.open("/")
w.document
VM17392:1 Uncaught DOMException: Blocked a frame with origin "null" from accessing a cross-origin frame
```

The main idea of sandbox is it does not allows to access to parent document html or any data that is stored for that domain (cookie, localstorage, etc.)
 We can't do anything about it, you should report it for chrome devs, maybe they revert some changes and we can still support Chrome in the future.
 This has been fixed. As there is no known issue with sandboxed iframe yet.
 I would like to avoid modification of system settings / require admin user to run it and it would be also problematic for remote clients (eg. proxies) that only using one address.
  You have to remove it using software manager then install using `sudo pip -U msgpack-python`

If it fails this should work:
- Download msgpack from: https://github.com/msgpack/msgpack-python/archive/0.4.6.tar.gz
- Unpack anywhere
- Copy the `msgpack` directory from it to the same directory where your `zeronet.py` is
  Thanks!
  The client only send the changes to [some other peers](https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Site/Site.py#L314), then if someone receive a valid new modification he will inform about it 3 other random peers.

In this way you only have to send your modification to 1-2 peer then (probably) it will spread between everyone.
 ZeroBoard is an outdated site (it was the first site of zeronet). ZeroTalk solved this problem: 
Every user has his/her own file to distribute comments/topics/upvotes/etc. and they are signed and timestamped by the owner on modification. So no problem happens if someone did an another modification at the same time because its writes in an another file.
 Everone has his/her own content.json file that is timestamped separately, so no lock needed. 
  Thanks!
  IPFS does not support dynamic content as far as I know and the content distribution works differently. There is lots of similar project out there ZeroNet created to focus on simplicity, easy of usage and user experience.
 The startup speed zeronet has been fixed, please check the blog for instructions
  Yes the main reason was the fact that most linux distribution comes with Python 2 and it has more mature libraries. (and the speed is also somewhat better)

Some months ago the gevent event library ported to Python 3, so I think it shouldn't be hard to make the project compatible both with Python 2 and 3.
 I have not started working on it yet, so no ETA and I have not worked with py3 before, so not sure how hard or painful is the conversion.
I'm not sure if we want to use gevent in py3 as it has built-in async support now. (it would mean dropping py2 compatiblity) Python 2 still supported until 2020 so it's not a priority yet.  The problem is the torrent trackers only support ipv4 addresses, so need to find an alternative solution to store ipv6 (and tor) addresses.
 It's not on short-term plans yet. (next 6 month)
 Yes, with ZeroNet bootstrap protocol It's no longer a problem. I think the webui should work if you start it with `--ui_ip youripv6address`  The problem is Debian does not comes with pip installed and if you want to install it using pip you could need other dependencies installed (c++ comiler, python source code and other heading files). Debian 7+ has the correct msgpack version using apt-get so I would leave it as default install method.

For other distributions the pip method is recommended: https://github.com/HelloZeroNet/ZeroNet#other-linux-or-without-root-access
  It's added in the latest version: ec40d3fcc3c1b459d6137e00beee4066473e9d66
  Done in version 0.3.2
  I think its better to keep this setting in the config file.

Since the [latest update](https://github.com/HelloZeroNet/ZeroNet/commit/0de6496f96316514a07c4b1cbaf4a9f29a2411cb) you can specify the trackers by creating a `zeronet.conf` file eg.:

```
[global]
trackers =
    udp://sugoi.pomf.se:2710
    http://torrent.gresille.org/announce
```
 [Added an another parameter](https://github.com/HelloZeroNet/ZeroNet/commit/fa37f58982d3ea430605929aad961243dfceb600) using `zeronet.py --trackers_file bootstrap.txt` the trackers reloaded before the announces. Example for bootstrap.txt:

```
udp://sugoi.pomf.se:2710
http://torrent.gresille.org/announce
```
  Thanks for reporting, its fixed in latest version https://github.com/HelloZeroNet/ZeroNet/commit/dd2bb8b3fbd5d6eb6d950cdb48f2e3691a393e2d: 
Starting with `python zeronet.py --debug --coffeescript_compiler "/usr/local/bin/coffee -p"`, and autodetection of coffee command also added, so simply `python zeronet.py --debug` should work now
  Since every website on zeronet using the same origin (127.0.0.1) it would be unsecure to add "allow-same-origin" to sandbox parameters.

I have just tried it and successfully ran webworkers by inline them using Blob URLs: http://www.html5rocks.com/en/tutorials/workers/basics/#toc-inlineworkers
  Looks like your identity file (data/users.json) have changed. How did you updated your ZeroNet installation? Using update button on main screen or downloaded an unpacked again?
 You have to copy your old data/users.json file to the new installation to have your identity.
  I think creating a separate site for this is not necessary. A zerotalk topic is good for this ( later we can create a topic group for it if it requires).

even later, if we have more quality sites something like https://chrome.google.com/webstore/category/apps would be nice.
  Fixed: Only first two lines displayed
  Unfortunately there is no standard way to interact browser to check if a tab is already opened or not.
 https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Trayicon/TrayiconPlugin.py#L66

(you can try to change it to new=0, but it does not have any effect for me)
 I dont think calling chrome.exe directly is a good idea: someone could have different browser as default, it can be installed to different place, does not work on different platforms, etc.
  Can you please check the `log/debug.log` file for more details?

Also please try to start it with: `zeronet.py --disable_encryption --use_openssl False`
 ```
Socket error: NameError: global name 'SSLContext' is not defined in Connection.py line 124 > Connection.py line 180 > CryptConnection.py line 40 > ssl.py line 382 > ssl.py line 84
```

It's looks like for some reasons your openssl not compatible with python ssl (or gevent) module. 
Please paste the first 50 line of your debug.log, so i can try to reproduce your environment and try to find a fix for it. (you can remove the previous pastes from here to avoid ip leak)
 OK, thanks for reporting, im going to install an Ubunto to see why is it happening
One more thing I need is your openssl version: `openssl version` 

(file size does not match 8530 <> 8598, Hash: False errors happens probably because the site owner modified the index.html, but he/she does not signed the modifications yet, so your clients unable to download the file, so its not related to this error)

btw. probably you can start it with `zeronet.py --disable_encryption` the missing SSLContext is only related to SSL encrypted connections, so you can use openssl to verify the downloaded files. (40x speedup on initial download times)
 I think its fixed in rev280: https://github.com/HelloZeroNet/ZeroNet/commit/a5741704e4c4c5e679b3cfd6486d8f758087a51c?w=0, please let me know if its working for you
 @t1891 Are you having similar problems on osx? does starting it with `--disable_encryption --use_openssl False` fixes it?

whats your OSX / `openssl version` ?
  A bundle for macos would be nice, but unfortunately I don't have access to any mac yet. We have  [systray plugin for windows](https://twitter.com/HelloZeroNet/status/588467418982289408), but its currently using the the windows api, because I think adding qt as dependency and load it to memory (last time I checked it added +20MB which is doubles the current memory usage) for this little feature is a bit overkill.
Modify the [trayicon plugin](https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Trayicon/TrayiconPlugin.py) to use the QT where the windows api is not available would be a good solution.

Adding peer information/sitesign/key management is [planned to be added to webui as a sidebar](https://github.com/HelloZeroNet/ZeroNet/issues/114), so it will be accessible if you are running zeronet on other machine.
  Thanks for reporting, we going to check the possibilities. Utf-8 domain names [not supported in Namecoin](http://wiki.namecoin.info/?title=Domain_Name_Specification_2.0#Valid_Domains), the domain-name encoding could be a workaround for this problem.

Python3 is not planned yet, because most of linux distribution still comes with python2 and the gevent liblary is not supported in Python3.
  Thanks, fixed in dc791a31abf660fbf05e49dd54661af9346d46c6, please run update.py then check again.
  We don't have dht yet, so its not possible. It's planned, but we looking for a solution that works with TOR and allows to store TOR client hidden services in a secure way.
  its very extreme, contains 100k+ files, i dont think its going to work anytime soon
 A feature is planned that allows to make sites that has access to other site's files, so it can generate a merged database from them.

This will allows to make huge sites without creating monoliths, keep the users content decentralized and also solves scalability problems.

For example a twitter-like page could be done like this:
- We going to have 2 pages: ZeroTwitterAccount and ZeroTwitterMerger
- If someone who wants "create" a new account he/she clones the ZeroTwitterAccount page which will holds all his posts and replies as a standalone site.
- If you want to follow anyone you just start serving his/her site
- When you visit ZeroTwitterMerger site requests read access to all ZeroTwitterAccount type sites you hosting and create a merged sql database from them. This will allow you to browse and search all your hosted (followed) ZeroTwitterAccount in one place.
  While the JavaScript has some advantage (eg. more people know it), but I think Python is more advanced language, so we don't have plans to switch to node.js. Although the alternative implementations are welcomed.
  Easier to install and test (don't have to deal with different versions installed) this way and i don't see any drawbacks of it. If a new version is out, we can easily test if its works, make the required changes then send it to all users.
 But what happens if tomorrow a new version of pybitcointools came out a feature we want to use? We can display an error to console saying "If you want to use ZeroNet you have to update your pybitcointools: On linux get a root console, execute pip --upgrade pybitcointools if it still dont work after that (some linux have python3's pip as default) try it with pip2 or pip2.7 or pip-2.7 commands. On windows download the new pybitcointools zip, find your python installation's site package dir and try overwrite files there if you can't then logout and login using an administrator user and try again.", but its sound painful for me.
 Calling pip from updater won't work in most environment because it requires administrator/root permissions to run. 
Thanks, the pex look interesting, but I don't see why is it better than the current, pure distribution format.
 As the project owner my top priority to provide the easiest way to use and update zeronet on every platform. This effort will be infringed If we require admin privileges or other actions to update the client.

As developer i want to care as less as possible. Supporting and testing different version of packages or distribution formats are painful for me.

I know i'm not the best programmer, the code needs improvements and I'm ready to give up my habits, but the easy user experience has to be above all.
  Thanks for reporting, I was unable to reproduce it, but probably fixed by 1f53212d62ae7202c6b8efdbe84e94b745663471
Please reopen the issue if you still have problems after updating.
 You have some options:
- Download the https://github.com/HelloZeroNet/ZeroNet/archive/master.zip file, unpack to current dir and overwrite current files (it safe to overwrite everything, it doest contains the data directory where your identity, settings and sites stored)
- Using file explorer in your Zeronet directory (where you have an update.py): File > Open Command prompt then enter `..\Python\python.exe update.py`
- Rename your ZeroNet directory and execute zeronet.cmd again. It downloads the latest version from github. Overwrite the data directory from your previous installation to have the same identity, sites and settings.
  It would be nice, but before that we need better tests. i'm not really experienced in that, but i try to do my best :)
 Thanks! We [started to make it](https://github.com/HelloZeroNet/ZeroNet/pull/119) PEP8 compatible, not every file converted yet.
Some of the test are broken yet because I only recently started to include the [files](https://github.com/HelloZeroNet/ZeroNet/tree/master/src/Test/testdata) that required for it.
Edit: Fixed broken tests: f63b711972fb818bb1695d386c1aaae9ef1beef7
  Thanks!
  Its because ZeroHello currently only checks if Zeroname plugin is enabled:
https://github.com/HelloZeroNet/ZeroHello/blob/master/js/ZeroHello.coffee#L99
I'm going to update it soon.
edit: updated
  I think we should not move the not-on-top module imports, to allow only load the modules if they are really needed (eg gc module) and it could matter if the module loaded before or after monkey patching (for example in case of proxy).
 Unfortunately importing some libs before socket monkey patching broken proxy (TOR) support (caused hang-up on startup), so i reverted the necessary imports to previous state: f58aa5f78e6f223d55d27560a4c034c247ca3ae4
  Thanks!
  https://www.python.org/dev/peps/pep-0008/

Probably required modifications:
- [Use spaces instead of tabs.](https://www.python.org/dev/peps/pep-0008/#tabs-or-spaces)
- [Imports to separate lines](https://www.python.org/dev/peps/pep-0008/#blank-lines)
- [Change module names to lower_cased](https://www.python.org/dev/peps/pep-0008/#prescriptive-naming-conventions)
- Other things?

Possible problems:
- The [update script](https://github.com/HelloZeroNet/ZeroNet/blob/master/update.py) does not handle  the renames/file removes. Some os does not allow to have the same file with upper cased and lower cased form in the same directory, so the update will fail. So we need to modify the update script and wait some time until everyone update it.
- I'm a TAB person, going to need some time to get used to spaces :)
 Yeah, the editor makes its easier, but for me it was easier to jump between indents with one cursor button press and delete an indent with one backspace.

The editor should detect if the current file using space or tabs, but for some unknown reasons this feature does not works in my sublime text. (`"detect_indentation": true`)

So i written a quick plugin for it, maybe its also useful for someone else: [detect_indent.py](https://gist.github.com/HelloZeroNet/e6343d9ee8e9968ac54e)
 Done in: https://github.com/HelloZeroNet/ZeroNet/commit/b5ecb62bc6e81ebb5e23855bb2195a9c9f802f7e?w=0

Tools used:
- [Python PEP8 Autoformat](https://packagecontrol.io/packages/Python%20PEP8%20Autoformat)
  Settings:

```
{
    // autoformat code on save ?
    "autoformat_on_save": false,

    // enable possibly unsafe changes (E226, E24, W6)
    // aggressive level, 0 to disable:
    "aggressive": 0,

    // list codes for fixes; used by --ignore and --select
    "list-fixes": false,

    // do not fix these errors / warnings (e.g. [ "E501" , "E4" , "W"])
    "ignore": [],

    // select errors / warnings (e.g. ["E4", "W"])
    "select": [],

    // Maximum line length
    "max-line-length": 300  // I wanted to format long-lines myself
}
```
- [Python Flake8 Lint](https://packagecontrol.io/packages/Python%20Flake8%20Lint)
  Settings:

```
{
    "lint_on_save": false,
    "pep8_max_line_length": 130,
    "report_on_success": true,
    "ignore": ["N802"]  // We use camel cased function names
}
```
  Thanks! Fixed: b2e2453e581814876468a0ec8d65b07a307646bc
  You can do this, but its not recommended, because then you have to trust the other site to not include any malicious code in the javascript.
I think the actual benefit (saving 2-300kb of space) is not worth it.
  Thanks!
  - [x] Workaround to fix gevent SSL bug on python 2.7.9
- [x] Benchmark SSL vs RAW connection speed
  It's around 6 times slower than raw connection when running client and server on the same machine.
  
  ```
  10 worker:
  # Raw:      10000 req 1000009 kbytes transfered in 5.39999985695
  # RSA 2048: 10000 req 1000009 kbytes transfered in 27.7890000343 using ('ECDHE-RSA-AES256-SHA', 'TLSv1/SSLv3', 256)
  # ECC:      10000 req 1000009 kbytes transfered in 26.1959998608 using ('ECDHE-ECDSA-AES256-SHA', 'TLSv1/SSLv3', 256)
  # ECC:      10000 req 1000009 kbytes transfered in 28.2410001755 using ('ECDHE-ECDSA-AES256-GCM-SHA384', 'TLSv1/SSLv3', 256)
  
  100 worker:
  # Raw:      10000 req 1000009 kbytes transfered in 7.02700018883 Mem: 14.328125
  # RSA 2048: 10000 req 1000009 kbytes transfered in 44.8860001564 using ('ECDHE-RSA-AES256-GCM-SHA384', 'TLSv1/SSLv3', 256) Mem: 20.078125
  # ECC:      10000 req 1000009 kbytes transfered in 37.9430000782 using ('ECDHE-ECDSA-AES256-GCM-SHA384', 'TLSv1/SSLv3', 256) Mem: 20.0234375
  ```
- [x] Generate SSL cert&key PEM unique files on every startup
  I have tried to find a pure-python solution for this, but not found any, so using openssl command for it (openssl.exe bundled for windows).
  
  The key pem file creation is possible using [python-ecdsa](https://github.com/warner/python-ecdsa), but I could not found solution for the cert file:
  
  ``` python
  from ecdsa import SigningKey, VerifyingKey, NIST384p
  sk = SigningKey.generate(curve=NIST384p)
  print sk.to_pem()
  vk = sk.get_verifying_key()
  vk_pem = vk.to_pem()
  print vk_pem
  ```
- [x] More lightweight solution to encryption to avoid compatibility problems (eg. we dont need HMAC because every client is trustless)
- [x] Transparently update the connection to ssl using wrapssl
  To make raw & encrypted connections work on same port:
  - Client connects to peer
  - Client checks if the other client supports ssl connection
  - If both fine then sends ssl handshake and update the connection transparently
  
  Later it can be changed to implicit SSL (automatically encrypt every connection) if this works on every machine.
 Unfortunately for some unknown reasons its does works well on some computer (slow, high memory usage, error on newer ciplers), maybe its OS, OpenSSL or Python version bounded. 
I try to find alternative more lightweight solution to encryption...
 found a hack that helps openssl memory problems: https://journal.paul.querna.org/articles/2011/04/05/openssl-memory-use/

Update:

```
SSL No patch: 1000 req 100000 kbytes transfered in 13.8398740292 using ('AES128-SHA256', 'TLSv1/SSLv3', 128) Mem: 64.66796875
SSL Patched:  1000 req 100000 kbytes transfered in 6.95544099808 using ('AES128-SHA256', 'TLSv1/SSLv3', 128) Mem: 18.6796875
Custom AES:   1000 req 100000 kbytes transfered in 5.92737412453 Mem: 11.90625
```
 Its up and working, I leave it some days of testing, after that I will publish it.
It takes more time to build up a connection, but after that there is no mayor overhead.

```
Reponse time from far server
with SSL:    1.036, 0.133, 0.133, 0.133
without SSL: 0.407, 0.133, 0.133, 0.133

Reponse time from close server
with SSL:    0.444, 0.019, 0.020, 0.019
without SSL: 0.067, 0.020, 0.019, 0.021
```
 Added in a78907cc9dc198dd28dce2204a8992cf9e00221f
 The ssl support is for peer connections not for user interface (yet)
  Thanks, never used docker before, I try to add it to dockerhub.
  Its already possible, but undocumented yet, example zeronet.conf:

```
[global]
ui_ip = *
ui_restrict = 1.1.1.1
proxy = 127.0.0.1:9050
```
 Added to rev196
https://github.com/HelloZeroNet/ZeroNet/blob/66eca389bfc87049c1e20a26a5c0c2b8b876975e/src/Config.py#L106-L108
  Its planned, until then symlink directories should work
 Added to rev196
https://github.com/HelloZeroNet/ZeroNet/blob/66eca389bfc87049c1e20a26a5c0c2b8b876975e/src/Config.py#L106-L108
  Thanks
  Yeah its a good idea for a plugin, I already made some experiment earlier when i wanted to implement .bit support using http://www.opennicproject.org/
Need more experimenting, not sure if its possible using http://pydns.sourceforge.net/ & Tor network
 The problem is it relies on dns servers, so the sites will not works offline. Cache required to make it work without internet connection [example at dnschain plugin](https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/disabled-Dnschain/SiteManagerPlugin.py#L91-L119).
I don't really want to add more external dependencies, but pydns is a pure-python module, so distributing in the lib dir could work.
  thanks
  merged
   Added in https://github.com/HelloZeroNet/ZeroNet/commit/9d511ba1655d8b2982b3d9810ba3901d0a5d1c09  To reduce space/network bw used by data files:
- On network protocol level: less work, but does not reduces the storage requirements
- On file storage level
 The main problem is not storing the js/html files, but the databases. Removing white space from json files could help, but support for compressed database would be better solution.
 Unfortunately - as far as i know - sqlite does not have compressed database support and probably it would be slow to select large files from database every time the user requests it.

Currently the every database data is stored two times: as json file and as sqlite database cache. In theory its possible to store the data only in the database, but then then modify/sign/send/validate would use much more cpu and disk i/o because to calculate the md5 hash of the data file you have to select all current data from database, but i have not made any benchmark for it yet.

As space usage of current ZeroTalk files (208user, 130topics, 600comments, 550upvotes):
- Json files: 355k, zipped: 268k, tgz: 145k
- Sqlite db: 408k, zipped: 187k, tgz: 187k

The sqlite db is larger than json files probably because of the indexes.
 Sadly its not free: "You should only be able to see this software if you have a license. If you do not have a valid license you should delete the source code in this folder at once."
 I have did some experiment on compression speed on a content.json file with 12 000 files:

```
Original        1874.51KB
Zlib    0.074s  558.68KB
Gzip    0.130s  547.09KB
Deflate 0.125s  547.04KB
Bz2     0.291s  482.88KB
Bro     7.856s  438.01KB
Decompress
Zlib    0.010s
Gzip    0.011s
Deflate 0.009s
Bz2     0.089s
Bro     0.012s
```

Google's new [Brotli](https://github.com/google/brotli/) offers nice rate, but the compression time price is huge.
Looks like the gzip offers the best speed/compression ratio. (maybe support both .gz / .bz2?)

The idea:
- The any.json.gz files would handled and transfered as normal files.
- If the json -> data layer matches a .gz file then it transparently decompress then insert a data from it.
- It would also handle the compression/decompression transparently if you read/write a json.gz file using the ZeroFrame API.

The html, css, js,etc. files would remain uncompressed (also on storage and transfer), because they only have to re-transfer very rarely and i think its not worth the extra (de)compression cpu time on every transfer.

Edit: Added LZMA/Brotli compression levels:

```
Original Compress 1874.51KB Decompress
Zlib     0.069s   558.68KB  0.011s
Gzip     0.132s   547.09KB  0.011s
Deflate  0.131s   547.04KB  0.009s
Bz2      0.299s   482.88KB  0.098s
Lzma     1.372s   455.77KB  0.057s
Bro/1    0.035s   506.78KB  0.011s
Bro/2    0.046s   504.26KB  0.010s
Bro/3    0.052s   502.25KB  0.011s
Bro/4    0.059s   507.89KB  0.010s
Bro/5    0.160s   527.18KB  0.012s
Bro/6    0.221s   527.73KB  0.012s
Bro/7    0.269s   527.06KB  0.012s
Bro/8    0.305s   526.27KB  0.012s
Bro/9    0.373s   525.81KB  0.012s
Bro/10   8.111s   438.01KB  0.012s
Bro/11   8.075s   438.01KB  0.012s
```

Brotli / level1 looks good and fast (Cons: One more binary dependency and the python module not submitted to pip yet)
 It's not planned yet.
 Added facebook's zstd:

```
Original    Compress    1874.51KB   Decompress
Zlib        0.071s      558.68KB    0.010s
Gzip        0.131s      547.09KB    0.012s
Deflate     0.129s      547.04KB    0.010s
Bz2         0.299s      482.88KB    0.108s
Lzma        1.343s      455.77KB    0.058s
Bro/1       0.031s      506.78KB    0.011s
Bro/2       0.042s      504.26KB    0.010s
Bro/3       0.049s      502.25KB    0.011s
Bro/4       0.058s      507.89KB    0.011s
Bro/5       0.159s      527.18KB    0.012s
Bro/6       0.236s      527.73KB    0.012s
Bro/7       0.298s      527.06KB    0.012s
Bro/8       0.324s      526.27KB    0.012s
Bro/9       0.401s      525.81KB    0.012s
Bro/10      8.307s      438.01KB    0.013s
Bro/11      8.755s      438.01KB    0.013s
Zstd/1      0.017s      502.58KB    0.010s
Zstd/3      0.058s      521.81KB    0.024s
Zstd/5      0.152s      523.55KB    0.038s
Zstd/7      0.276s      518.76KB    0.050s
Zstd/9      0.470s      507.92KB    0.063s
Zstd/11     0.695s      507.03KB    0.076s
Zstd/13     0.957s      505.98KB    0.089s
Zstd/15     1.352s      504.79KB    0.101s
Zstd/17     1.838s      478.77KB    0.111s
Zstd/19     2.939s      465.31KB    0.121s
Zstd/21     4.155s      458.96KB    0.132s
```

Zstd's train function can be interesting for us (it allows to have shared dictionary between multiple compressed files)
 There is no roadmap, so can't tell if it's on it or not. It's planned, but not sure yet if it will also support database files or only for static ones. I have added .tar.gz, .tar.bz2, .zip support in latest rev: https://github.com/HelloZeroNet/ZeroNet/commit/2854e202e17926f136c053646f3530e1e1c9956d

example site: http://127.0.0.1:43110/1AsRLpuRxr3pb9p3TKoMXPSWHzh6i7fMGi/en.tar.bz2/index.html (please update your client before visit)

en dir uncompressed: 6.1MB, zipped: 1.5MB, tar.gz: 512KB, bz2: 247KB (!)

No database files support yet, but it's also planned. Latest results from gzipped database (ZeroTalk user files):
- Raw, separate files: 7.6MB
- tar: 12MB (hm)
- zip: 4.8MB
- tar.gz: 3.1MB
- tar.bz2: 2.4MB
- tar.zstandard: 2.1MB
- tar.brotli: 2.0MB
- tar.xz: 1.9MB

Reading all files from archive
```
|         | Intel i5 | Chip  |
|---------|----------|-------|
| Raw     | 0.51s    | 1.74s |
| Tar.gz  | 0.47     | 6.99s |
| Tar.bz2 | 4.5      | 82.3s |
| Zip     | 0.38     | 4.03s |
```

Update: By dropping the signatures from archived content.json files reduces the size of the tar.gz file down to 2.5MB Plans for tar.gz packed database:
#### It should be suitable for archiving user database files: 
 - The site owner press the archive button
 - ZeroNet packs user files older than 1 month into users.2017-03-02.archive.tar.gz
 - Specifies the clients to delete all user files older, than 2017-02-02
 - Publishes data/users/2017-03-02.zeronet-archive.tar.gz file (as optional file)

#### Client detects new *archive.tar.gz file
 - Read all .json files in the tar.gz and insert to db as normal files


#### Problem 1
If an archived user starts posting again, then archived content will disappear, because ZeroNet deletes all user before inserting new one. (Same problem if multiple archive contains data for same user)
 - Solution 1: Delete all data associated to user -> Check all archive if it has data for the user and import it if necessary ->Import new user data file. Pro: Probably need no modification in sites source code, Con: Opening archives is slow and we have to do it for every file
 - Solution 2: Treat archived jsons as separate files. Pro: Archived data rows will be untouched if user start posting again. Cons: Probably needs modification in every site code. And re-index the db.

#### Problem 2
Optional files in archived user directories will be deleted.

#### Problem 3
If you archive a user file with an active topic, then it will disappear.

#### Problem 4
On archiving we have to update every user's data.json which could take a lots of time. zip also supported, but in this case it does not makes any difference, because when the zip/tar.gz files got updated we have to unpack every file to insert to db. Another idea:
Instead of storing many files in .zip / tar.gz merge the archived ones into one.  For example:
```
{
"users/112GGMvUJbBTCtQu8UUSYpo8UjLdo1B73n/content.json": {
   "cert_auth_type": "web",
   "cert_user_id": "qu363c@zeroid.bit",
   "modified": 1484261339
},
"users/112GGMvUJbBTCtQu8UUSYpo8UjLdo1B73n/data.json": {
...
}
```

This will speed up the opening, reading and parsing.  My first benchmarks parsing all json files this way (I have removed the signatures from content.json files to reduce size):

|                   | Size    | Intel i5 | Chip    |
|-------------------|---------|----------|---------|
| Raw               | 6.7MB   | 0.48s    | 3.37s   |
| Merged Raw        | 6.7MB   | 0.10s    | 1.46s   |
| Tar.gz            | 2.6MB   | 0.58s    | 8.64s   |
| Merged Tar.gz     | 2.4MB   | 0.20s    | 2.49s   |
| Tar.bz2           | 1.9MB   | 4.38s    | 77.3s   |
| Merged Tar.bz2    | 1.8MB   | 0.58s    |  7.2s   |
| Zip               | 4.1MB   | 0.48s    | 5.60s   |
| Merged Zip        | 2.4MB   | 0.13s    | 1.84s   |
| Merged bro        | 1.3MB   | ~tar.gz  | ~tar.gz |

So it significantly reduces the size of the .zip file 4.1MB -> 2.4MB and also speeds up the parsing process by 2-10 times. Without this the sites will be larger and larger by years dramatically increasing the initial sync time and the space required by the site. 
This will allow the site owner to create checkpoints by merging all user created content into one file and define it as optional file, so if someone not interested in old content, then he/she only has to store and distribute the latest files. 
 The current solution for large sites are deleting. The archiving will make these content still accessible, so from user perspective it's much better and I don't see why would make it anyone leave the network. 

Keeping every data on every computer will not work. (think about mobile phones)

Compressing the data makes it 2-4 times smaller, so I would not call it as a long term solution.
Other problems with sites without archiving:
 - Eg. on Android the default block size is 32kb, so if you store a 100byte file it will still takes up 32kb. For that reason currently if you download ZeroTalk to your mobile it will take up almost 100MB of space. (instad of 8MB)
 - Initial sync: Downloading, parsing, checking signature of 10000 files takes 10000 more time, than the same data from 1 file. You can call it optimize if you want. It's really up for the site owner which data he/she decides to remove from the default downloaded ones. It can be based on date/language/votes/etc.
Downloading and verifying ZeroTalk content (4700 files in 8MB, and I already deleted 2500 files to keep it under 10MB) could already take up to 10 minutes on mobile phones, which is I think already too much. 

This time could be improved with protocol modifications (eg. pipelining), but the verification and wiriting to the storage is still going to be problematic. (around 50ms/user) I think downloading optional files are not an advanced feature at all. It can be a button of "Download earlier topics", "Download downvoted comments" or "Download unanswered questions" There is some overlap with merger sites, but this is more like a solution for storage and transfer of large ammount of data. With .zip/tar.gz support it partially implemented, the next step is #1053  No, but #1053 will add this feature as checkpoints are basically compressed databases
 It's up to the site if it's puts up-to-date or outdated data in it, but I will check the possibilities of adding a simple json.gz support. @antilibrary json.gz support added in Rev2180: https://github.com/HelloZeroNet/ZeroNet/commit/b503d59c49da148346aa9893d7287b8e9ccb46d2
Also a new API command (fileNeed) that allow you to start downloading optional files.
Example site that shows both of the new features: http://127.0.0.1:43110/1JokLn39tLeXbc7voPv5yuiZvzUnduKpL9
   Can you run this commands please?

``` bash
$ python -V
Python 2.7.3
$ python -c "import gevent; print gevent.__version__"
1.0.1
```
 Maybe its version incompatibles, you can try to fix it using any of it: 
- Remove the gevent package and install it again using pip 
- Install using pip's `--user` parameter (no root needed, it installing it to user's home dir)
- Use `apt-get python-gevent`
  Thanks!
  I throught "ssl=False" fixes this problem, but looks like not :(

Just installed Debian Jessie and this fixes the problem (installing from package instead of source):

```
pip uninstall gevent
apt-get install python-gevent
```
  Hm, i think the problem is with the openssl.
Can you please add the `raise Exception("OpenSSL disabled")` line in the try block of `src/Crypt/CryptBitcoin.py` file?

It should looks like this:

``` python
from lib.BitcoinECC import BitcoinECC
from lib.pybitcointools import bitcoin as btctools
import logging
# Try to load openssl
try:
    raise Exception("OpenSSL disabled")
    from lib.opensslVerify import opensslVerify
    logging.info("OpenSSL loaded, version: %s" % opensslVerify.openssl_version)
except Exception, err:
    logging.info("OpenSSL load failed: %s, falling back to slow bitcoin verify" % err)
    opensslVerify = None
```

There is an alternative pure-python fallback on if library fails, but it can't catch the segfault :(

If this works then I will add an option to disable the use of openssl (and probably disable by default on macos until not found any solution to the problem)
 Only info I found:
https://github.com/petertodd/python-bitcoinlib/issues/30
https://github.com/jgarzik/python-bitcoinlib/issues/18

You can [try to upgrade openssl](http://apple.stackexchange.com/questions/126830/how-to-upgrade-openssl-in-os-x), if you do please give feedback if its fixed the problem!
 There is an [experimental patch](https://github.com/petertodd/python-bitcoinlib/issues/30#issuecomment-98419595) for bitcoinlib that uses cffi instead of the bulit-in ctypes. I will keep my eye [on it](https://github.com/petertodd/python-bitcoinlib/pull/62).
 I have found an alternative implementation: https://gist.githubusercontent.com/HelloZeroNet/4a335070d315f2456962/raw/b3a306f93a4e67064fa64ccddca591c8fe28b8f3/opensslVerify2.py
Can you please download it then try to run `python opensslVerify2.py` ?

Edit: Found an another one, please also try this: https://gist.githubusercontent.com/HelloZeroNet/747ffc1366bfdd47d657/raw/12b33126db874b6d8a5ec9e67d5df07e2053fc24/opensslVerify3.py
It says "doesn't crash on OSX." in the comments, so i'm very optimistic! :)
 @aidanharris Thanks for the reply, I have removed the missing symbol reference, please try this one: https://gist.githubusercontent.com/HelloZeroNet/747ffc1366bfdd47d657/raw/a014e42f79afea4332feead0f5aaa18ec6dd18a9/opensslVerify3.py
 Thanks, I will include this solution in the next version.
 Implemented in 0.3.0 please update then test it using: http://127.0.0.1:43110/Benchmark
 yes looks good, thanks!
  Would be handy to allow access ZeroNet from anywhere (eg. mobile) using a box that running the client.
Cookie or Http auth based (logout?).
 Yes, now it has ip based restriction: `--ui_restrict 123.456.678.982`, but it not works when you are in ip changing environment (eg. mobile)
 Currently working on this, probably it will be cookie based, i try to find a solution to make it more secure (does not send password as cleartext) on non-https connection. (similar to this: http://www.lightcubesolutions.com/blog/?p=47)
 Unfortunately sandboxed iframe ajax requests does not send the cookies, so the sites that using ajax to load data will not work.

As result i will mark ajax as unsupported method of loading data, instead use zeroframe api [fileGet](http://zeronet.readthedocs.org/en/latest/site_development/zeroframe_api_reference/#fileget-inner_path) method which is the same and probably faster.
 added in: https://github.com/HelloZeroNet/ZeroNet/commit/a93ca2c3b4e1d2fa95ad96fb04804e397c4dcb88

To enable password for webui:
- It's useful if you want to access your ZeroNet installation from remote machine (eg. mobile phone)
- Rename **plugins/disabled-UiPassword** to **plugins/UiPassword**
- Start using `zeronet.py --ui_ip "*" --ui_password mypassword` to bind ZeroNet to your public interface and allow access only using _mypassword_
  If you want to just validate it then its probably better to do on client-side. Eg. you can use this library: http://bitcore.io/playground/#/address

``` javascript
var privateKey = new bitcore.PrivateKey('5HvfMemepddMZmTjXQgyFLbyV5q2aXAmnpcX4zn6YNNw3kC3aUS');
var publicKey = privateKey.publicKey;
var address = publicKey.toAddress();
if (address == "1DoKaHoYHiTN9quUAAcx7Z5kNmN5xbo62n") console.log("Valid!")
```
  Yeah, the document definitely needs more work. I have made some modifications in fileWrite recently, its possible as side-effect the file already has to be in content.json before its allows writing (so needs to be created and `zeronet.py siteSign youraddress` executed). I'm going to test it later today. 
Do you have any error in `log/debug.log` file?
 I have tried it and its works for me even for non-exitstent files, updated the sample application with file read/write example:
https://github.com/HelloZeroNet/Documentation/blob/master/example/ZeroFrame/index.html

Update: I was able to reproducate the problem, it happens when you dont have the "own": "true" at your site in data/sites.json. But the websocket dropping is not normal, already working on fixing it.

Update #2: Its got fixed in commit f576527986692e82a2fd154b821685c07900c5d9
  Currently to make an user able to publish his own content, he/she has to contact the site owner to put his/her auth_address to the [users/data/content.json](http://zeronet.readthedocs.org/en/latest/site_development/content_json/#includes) file.

This required to has some kind of control over the users. (eg. be able to ban spamming users)

This makes the multi-user sites much harder because the user has to able reach the site owner and zeronet does provide any messaging service (yet), so it has to be done using other protocol (http, bitmessage, etc.).

To make it easier the site owner could able to provide trusted site addresses who is processes the new user requests. 
So the site owner could say: Any user who registered at Talk.Zeronetwork.bit is able to post on myblog.bit.

To make it possible we have 2 options:
#### Auth from other site's content.json

Every user who is seeding myblog.bit also has to seed the talk.zeronetwork.bit site. If a new user content comes in the peer checks if the auth_address is in talk.zeronetwork.bit user database.

Pros:
- The auth site able to delete users if reported as spammer

Cons:
- Users has to seed the authorization site
#### Validate other site's certificate

If a user registered successfuly at talk.zeronetwork.bit the site owner would sign the user's auth_address like a proof of a registration. If the user wants to post on myblog.bit he adds the cert to his content.json, and the peers will accept his/her new content. 
Pros: 
- Does not requres peers to seed the auth site
- Works even if the auth site deleted

Cons:
- No way to revoke cert

To make any of it possible the user has to use the same auth_address for talk.zeronetwork.bit and myblog.bit. (unique auth_address generated for currently every user using the same BIP32 xprv, but its easily possible to copy the identity)
## _Update:_

I think i will go for the second solution.

Required modifications:
- [x] File for specify rules where the third-party signed can be stored Contains: trusted authorization services, allowed files/size limit using regexp, directory where it will be stored, banned users.
- [x] Modifications on web interface that allows to use the same auth_address on multiple sites
- [x] A sample trusted authorization service page
- [x] Protocol command to get all current commented users data file (changedSince)
 example cert address: `16YsjZK9nweXyy3vNQQPKT8tfjCNjEX9JM:web/nofish@id.zeronetwork.bit`
- 16YsjZK9nweXyy3vNQQPKT8tfjCNjEX9JM: user's auth address
- web/: auth type used for registration (namecoin/, bm/, email/ etc.), this allows site users to ban some registration types or give them more trust (more space)
- nofish: username, has to be unique per site
- id.zeronetwork.bit: the auth provider address

On successful registration the site owner signs this string and sends the sign to the user.

The user saves it and if he want to post on a site he adds the signature to his content.json in `auth_cert_sign` field and the cert address to `auth_cert_address`

example for users.json

``` json
{
    "data/users": {
        "cert_signers": {
            "id.zeronetwork.bit": ["1IDzero2NXVi1RDPDgf5617UoW7xA6YrhM9F"]
        },
        "users": {
            "web/nofish@id.zeronetwork.bit": { "max_size": 40000 },
            "web/bad@id.zeronetwork.bit": null
        },
        "rules": {
            "id/.*@id.zeronetwork.bit": { "max_size": 40000 },
            ".*": { "max_size": 20000, "files_allowed": "data.json" },
        }
    }
}
```
 Added in 7e4f6bd38ecadb871a537c27a70a161d0a36816e
  Thanks for reporting, it got fixed in latest commit (rev106):
https://github.com/HelloZeroNet/ZeroNet/commit/c8fe73f5c0c3916c3244e446c7fbf03109567834#diff-67726306a3ab3bef30655f8f7f7465baR26
  `ImportError: No module named gevent` means you need to install gevent first.

you can do it using `pip install gevent msgpack-python` (if no pip command found try to find it in your package manager or download & run https://bootstrap.pypa.io/get-pip.py)
 If your router doesn't support upnp then you have forward the port 15441 to your raspberry IP address. But its also works fine if you cant do that.

If you want to access the the web interface from other ip address then you have to start it with `zeronet.py --ui_ip *` after that you can access it using http://raspberryip:15441
 [Upnp](http://en.wikipedia.org/wiki/Universal_Plug_and_Play) allows to communicate to your router and automatically forwards required the port to your computer.
  If a new and safe to update version out it will displayed on homepage like this:
https://camo.githubusercontent.com/8eca76beec11d1b903ea233cee169b2c84ff1330/687474703a2f2f7a65726f6e65742e72656164746865646f63732e6f72672f656e2f6c61746573742f696d672f7a65726f68656c6c6f2e706e67

There is new features/fixes between version changes, but its recommended to wait for new version, because this changes are not tested that deeply.
But if you really want to update zeronet every time you start you have to insert it to the first line of zeronet.cmd:
`Python\python.exe -m zerobundle.run https://github.com/HelloZeroNet/ZeroNet update.py`
  Possibilities:
- Browser plugin with custom zero:// protocol handler. Access sites: zero://talk.zeronetwork.bit zero://1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr
- Browser plugin, but keep http://. Access sites: http://1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr(.zero?), http://talk.zeronetwork.bit. Can be problematic if .bit site also has zeronet and clearnet address
- Using system's host file maps all site address to 127.0.0.0, this allows to access zeronet sites in any browser using http://talk.zeronetwork.bit (needs to map zeronet webui to port 80). Access new sites can be problematic.
- Register a domain and map all subdomain to 127.0.0.1 (needs to map zeronet webui to port 80). Access sites using http://talk.zeronetwork.bit.gozero.net
- Extend zeronet to also act as dns server and configure your os to 127.0.0.1 dns. Access sites like http://talk.zeronetwork.bit

Something you can do now: add `127.0.0.1 zero` to your host file, start zeronet with `zeronet.py --ui_port 80` then you can access zeronet sites http://zero/talk.zeronetwork.bit

Probably the browser plugin is the best solution (if possible)
 .bit chrome extension using this: https://developer.chrome.com/extensions/proxy

if zero:// not possible then i think accessing sites http://1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr or http://1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr.zero also fine.
 .bit domains can be problematic that way: a domain could have clearnet ip address and also zeronet address representation.
So currently if you enter zeronetwork.bit with the .bit chrome extension installed it leads you to the github page, but in zeronet it should lead to 1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr.
Maybe it can be solved by prefer zeronet  or prefer clearnet option.
 Wow nice!
I think 1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr.zero is better because its looks more like a normal web address and if you enter zero/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr in chrome (without http://) it takes you to google search. 1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr.zero handled as normal url
 I think if you can change it to *.zero then it will be good. currently zero/ is detected as part of request_path, if it has a . in it then it will be the domain.
 In my browser: http://i.imgur.com/Yl0ETg4.png (i have installed the extension)

yeah the lower-casing is a major problem and i think no easy way (if even possible) to fix it :(

maybe its possible with combination with omni-box plugins witch is receives all input you enter to address bar, but its hack-ish.

According to this: https://github.com/swalkinshaw/rs-ssh google lets you use custom protocol prefix, but you need a registered program for that (we can do that easily with zeronet client).

This protocols have to be case-sensitive because there is also a bitcoin:// protcol.

So it looks harder than I first throught...
 It required some changes in the core request handling, but i got the chrome plugin working. There is still some problems with site links that needs more work.

I think its better to stick with .bit domains instead of .zero, later it allows us to support other dns providers. (.eth, .p2p, etc.)
 Downloaded and updated to latest version of the plugin, everything working fine (/zero/\* and direct .bit access), i'm going to do some more testing then i will release a version that compatible with it.
 probably it would be smart to change the .bit to something zeronet related to prevent mixing with real namecoin .bit mappings, ideas that came up:
- Change .bit to .zero. Example: http://talk.zeronetwork.zero Problem: It doesnt allows integrating other dns providers (like ethereum) and there is already an [application](https://gtldresult.icann.org/application-result/applicationstatus/applicationdetails/934) for .zero tld
- Change it to .0 or 0net. Example: http://talk.zeronetwork.0net Problem: Its hard to read (is that an O or 0?), Similar as .zero, but without icann tld problem
- Change it to .zeronet. Example: http://talk.zeronetwork.zeronet. Problem: Similar as .zero, but without icann tld problem
- Change it to .zerobit. Example: http://talk.zeronetwork.zerobit. It allows later add .zeroeth .zerobazaar or .zerop2p
- zero:// protocol handler. Example: zero://talk.zeronetwork.bit. Problem: Chrome doesnt allows easily to do that, need registry hacking. Most forums doesn't converts it to clickable urls.
- Keep .bit, but redirect non-existent domains back to chrome (not sure if its possible)
 Redirecting on 127.0.0.1:43110 request to /zero/[site] and http://site.bit would be better because localstorage (and cookie on multiuser) is domain-specific.
But exluding /uimedia/ because it holds the internal css and js files of zeronet and it will not avalible from http://www.site.bit/uimedia.
 And i think it would be more usefull if pressing the extension button leads to the ZeroHello homepage and moving the proxy settings to extension options.
 It works pretty good, I think you could submit it to google app store to make the install easier.
 Nice, I had to restart chrome after removed the unpacked extension, but its working now
 you can only register web+zero://, but it's not really a good solution, because it's redirect back to 127.0.0.1:43110, so if you want to copy the link then you have to edit it manually again.
 I agree with @dmp1ce ï¼Œ I think using the zero:// scheme with a custom browser is the best tooï¼Œ  The ignore patter in only exclude file from content.json signing method.
You can still access the file locally, but it won't be transfered to other peers.

If you execute `zeronet.py siteSign [Yoursiteaddress]` command you should see [SKIP] at files you defined in ignore (files starting with . ignored by default, you dont have to put it to ignore pattern)

If you using zerobundle and don't have python installed then open command line at zeronet.py and execute `..\python\python.exe zeronet.py siteSign yoursite`
  Does not relies on canyouseeme.org, also possible to use to check i2p/tor hidden service.
 No progress on it, but i'm not sure what you mean.

In my theory it would work like this:
 - Collect some IPs via Trackers/Peer database/etc.
 - Ask them to connect back to the given port and return the result

Based on this information the client would be possible to find out if their public ip/hidden service is works well or not. I think Tor hidden service checking is not necessary. If the hidden service has registered successfully, then it should work regardless your network settings. 
It also has 1-5 minute cooldown time, so you can't do it on startup.  Create a demonstartion youtube video about ZeroNet.
 I think a video that demonstrates ZeroNet working would be a good start:
- Starting from clean install
- Doubleclick on zeronet.cmd
- Browser starts, loads ZeroHello
- Load ZeroBoard, submit a message
- Load ZeroBlog, Register username using ZeroID, submit a message
- Load ZeroTalk, click on some topic (the registration process will be changed to ZeroID based, so registration can be skipped here)
 A video about how zeronet work also would be nice, but it needs more work.

For graphics you can use https://docs.google.com/presentation/d/1_2qK1IuOKJ51pgBvllZ9Yu7Au2l551t3XBgyTSvilew/edit
 It could also include the downloading ZeroBundle.zip from zeronet.io > rigtclick extract here > start zeronet.cmd process. Probably needs some editing/speedup at extracting because it has 3500+ files files and its boring to watch the progress bar. (Later it can be improved by creating a more compact python runtime using [py2exe](http://www.py2exe.org/) or removing unnecessary files, eg. testing or tcl/tk)
 I think both would be nice, probably it would be easier to start with a simple screencast
 I think you can skip the platform-specific installation method for now and start from executing start.py 
 It looks nice, probably it would be beter with a bit larger browser window and starting with clean install (also showing the download process) and if possible with open port to prevent warning messages
 I meant the ZeroHello (and other zeronet pages) downloading process (rotating square).
 Thanks, it's better, but the layout looks broken :( I really need to find a mac to fix/reproduce the problems.
 The two main problems is with the zero button on top-right (has to find a fond that similar to Consolas on windows) and for some reasons the site names on zerohello are misaligned and not visible.

I try to find a way to access a mac machine this week.
 Thanks for the tips, I will check them! 
I have contacted browserstack.org, maybe they can sponsor us with a osx safari live browser testing solution.
 hooray! browserstack.org going to sponsor us with an account, so it will allow to test zeronet on more platforms (eg osx safari) and makes also possible to write automated tests
  The problem is to do this we have to store the blockchain on every machine and it would require around 50gb of database.

It could better idea possible by running a full bitcoin node on every machine and zeronet only distribute the html/javascript/css that required to query the bitcoind.
  Currently the sqlite database is updated as the new file is written to the hdd.

Maybe it would be better to read the files when its required by the sql query:
- data/user/data.json updated
- The storage layer marks the data/user/data.json as updated
- File written to disk, no sql connection made

When user tries to list the topics:
- Storage layer loads the files to sql that marked as updated
- Reset the files updated status
- Run the query on updated database

Pros:
- Lot faster data process by batching updates using BEGIN / COMMIT
- Less CPU usage If you only "seed" the site
- If the file updated more than once then only have to load 1 times

Cons:
- Displaying the data could be slower if you have many pending updated files because it has to parse the updated files before display any result
- Has to store somewhere the pending database updates
 nope, probably we don't need it.  Thanks for reporting for some reason your python is unable to open an sqlite database. After some googling maybe specifying absolute path could help.

To find out if this is a problem I made a testcase for Db connection. To run please update your zeronet by running `python update.py` (or git pull), then `python -m src.Test.test`

The output should look like this:

```
f:\Work\ZeroNet-git\ZeroNet>python -m src.Test.test
testBitcoinSign (__main__.TestCase) ... Taken: 0.542s, ok
testBitcoinSignCompressed (__main__.TestCase) ... skipped 'Not working'
testBitcoinSignOld (__main__.TestCase) ...  Taken: 0.786s, ok
testDb (__main__.TestCase) ...  Importing db...
Creating db using f:\Work\ZeroNet-git\ZeroNet\data\test\zeronet.db... ok
Creating db using data/test/zeronet.db... ok
ok
testMediaRoute (__main__.TestCase) ... ok
testTrackers (__main__.TestCase) ... skipped 'Notyet'

----------------------------------------------------------------------
Ran 6 tests in 1.466s

OK (skipped=2)

f:\Work\ZeroNet-git\ZeroNet>
```
 In theory its comes with every python and your log says:
`[2015-03-31 08:35:13,460] DEBUG Db:ZeroTalk Connecting (sqlite version: 2.6.0)...`
So I'm not sure if thats the problem.
  At the moment at every click: Load wrapper -> Wrapper creates iframe and loads page html -> Init websocket connection -> Load page details using websocket api

It could be much faster by sharing the wrapper and the websocket connection between and only change the inner frame html.

Need a wrapper api command that allows change the url of the page.
 The overhead is much smaller since the http caching enabled on js and css files. Pushstate support can be a solution, but then its needs application level support for this feature.

Probably related problem that needs to be fixed:
If you scroll down on a page (for example zerotalk topic listing) then click on a link and then go back to previous page then chrome and ie scrolls to page top. (it worked on chrome some months ago, but they broken it :( )

Possible workaround for the problem: Store (cookie or localstorage) the scroll position before the page onload then load it back on next page load.
 Probably we don't need it. It would require changes in site's source code (call API instead of simple `<a href="...`) and they can archive the same with wrapperPop/Pushstate API calls.
Also with js/css caching enabled the wrapper loading speed dramatically increased.  you mean delete the site from all peer's computer?

You can do that by deleting your site files, siteSign and sitePublish the modification
  Send / Receive messages using local client XMLRPC
 Yes, sorry, I forgot about it. I will check it soon  Sites protected by password or public-key based auth.
 @OliverCole AES and ECIES encrypt/decrypt functions added some months ago: #216
It could allow to encrypt every content on the site and decrypt after it downloaded on the client side.

It's not ideal for every application case, there is many ways to implement private sites it's all depends on what you want to do? Filter IP-s who is connecting to your site? Add password protection? Only encrypt part of the sites?
 We already using openssl, pynacl just an alternative to it and it does not support bitcoin cryptography that we using most of the time
 Not sure if storing everything twice is a good idea, probably a password/publickey based peer authorization is easier and would allow to remove users.
 To be able request any file from peers you need to authenticate yourself using publickey algorithm.

Other possibility: when requesting any.jpg using http and it's not exists, then it's looks for any.jpg.encrypted and try to decrypt it using they AES keys you have associated with the site/directory. 

This way the sign/publish method would remain the same, also allows multi-user sites and only requires some smaller modifications in the UiServer/SiteStorage (for sql imports) and new API functions to add AES keys.
 I think there is two possibility:

### Per file encryption

Anyone able to receive files/updates, but the files are encrypted

Pros:
- Does not relies on connection security
- Allows easy per-directory encryption
- Allow anyone to host files without knowing it's content (eg. paid hosting)

Cons:
- Performance: has to decrypt the files on the fly or build a cache
- Not possible to remove users from the site
- You can spy on site activity
- (Future) Patch command can be problematic

### Connection security

You need to authenticate with other users connection before receive any updates or files.
 Pros:
- Not possible to spy on site activity
- May be possible to create new password and remove users
- Files stored the same way as any other site

Cons:
- Relies on connection security (SSL/onion): MITM can be a problem
- Per directory encryption is harder, but may be possible
 the problem is the zip file is not suitable for multi-user sites and per-user encryption is not really works for many users (100+)

patch command: to greatly reduce bw usage when one of the files modified instead of re-transfer the whole file only send the changed lines (diff)
 Multi-user sites: interactive zeronet sites where every user has his/her own files. (ZeroTalk, ZeroBlog, ZeroMail, etc.)

If the files are encrypted and you want to remove an user, then you have to re-encrypt every file and everyone has to re-download all of them.

If you want to make sure of encryption you will still able to encrypt the data using AES+ECIES functions (like ZeroMail)
 New key release could work, but then you have to also keep the old keys in order to able to decrypt the old contents. ECIES takes more space, than symmetric encryption: 225 Bytes base64 encoded, so 10000 user = 2.2 Mbyte new data added to site when someone is removed.

It could be possible to encrypt the patch with some overhead: decrypt patch -> decrypt the whole file -> apply patch -> encrypt the file -> check sha512

It would be nice to check how other projects do this (syncthing, bittorrent sync, Tahoe-LAFS, etc.)
 The per-file encryption is not compatible with patch command because it's not a good idea to re-use the IV. if we add a new feature we have to support it forever, so it's need to be as flexible as possible. 
 I think it's fine to put it here
  - It would be nice to have a per-site `Allow clearnet connections` setting: If disabled then standard ipv4 peers is connected using Tor exit-nodes. If its enabled then only Tor peers are connected through the Tor proxy.
- Display warning to user: You are in Tor-only mode, you should also configure your browser to use Tor network. (maybe restrict external resources using Content Security Policy)

Problem:
- The torrent trackers does not allow to store tor/i2p addresses.

Possible solutions:
- DHT: Its not easy to write a good DHT implementation and Tor doesnt support UDP, so we need custom DHT (it requires reliable servers for bootstrapping and not sure if its going to work fine with current small number of nodes) or proxies that converts DHT traffic to tcp.
- IRC: Not really decentralized solution, so i would not be happy to use it. (some altcoins using it, eg. Namecoin so it could work)
- Bittorrent http trackers could still work, but without tor address support, so you could browse zeronet sites, but could not host zeronet sites on tor. Maybe its possible with peer-exchange combination.

Any help/idea/suggestion greatly welcomed. Thanks! :)
 Done in 0.3.5
  - Ability to black/whitelist sites
- Max site size
- Disable autoupdate features
- Restrict site setting changes (pause, delete) to selected users
 Actually I think all of them are implemented.  Similar to torrent's DHT solution, required features:
- Find peer to specified site file (to allow sites to add optionally download files)
- Ipv6 and tor address support for peers
- It should work using on Tor (TCP only, maybe UDP on clearnet)
- No other library dependency if possible
- Store peer ips to allow work without bootstrap server

Maybe its requred to separate the DHT from Peer Exchange

Please comment if you have other ideas/suggestions.
 zeronet protocol is different from torrent, so libtorrent will not work. Also bittorrent DHT is UDP based, so it will not work on Tor without proxying it to TCP which I don't want. And it does not support storing Tor hidden service addresses, so you would not be able to create sites on Tor.
 Its already there:
- Ipv6 and tor address support for peers
- It should work using on Tor (TCP only, maybe UDP on clearnet)
 @stillwarter DHT still need a bootstrap server, so it does not help on new "virgin" clients.
 New progress made yet. 
Does anyone know already working P2P application that uses DHT over Tor? (preferably with >1000 nodes)  http://zeronet.readthedocs.org/
- [x] Make ZeroFrame API reference uptodate
- [x] Add Disqus to allow comments/questions
- [x] Put the [example site](http://zeronet.readthedocs.org/en/latest/site_development/using_zeroframe_api/) to github
- [x] FAQ
- [x] Description of content.json format
- [ ] Create ZeroNet site for the documents
- [x] Network protocol
- [x] New donation page
- [ ] Done / Future features
- [x] More screenshots
- [ ] Dbschema version 2
- [ ] Handshake
- [ ] Trusted authorization providers
- [x] New command: actionSiteSign
- [x] New command: actionSiteClone
- [x] New command: actionFileRules
- [x] New command: actionCertAdd
- [x] New command: actionCertSelect
- [x] New command: actionCertSet (admin)
 add goal specific donation addresses: `$.get("https://mainnet.helloblock.io/v1/addresses?addresses=1QDhxQ6PraUZa21ET5fYUCPgdrwBomnFgX", function(res) { console.log(res) })`
 Faq:
- How to use it with Tor? (update needed)
- Is it possible to install it on remote machine?
- Do I need open port to create new site?
- What happens when someone hosting malicious content?
- Openssl on centos
 FAQ WIP: http://zeronet.readthedocs.org/en/latest/faq/
  Thanks for reporting!
cc: @sirMackk 
 For unknown reason it stopped working for me. (nothing changed: same version that worked before, same router, same computer)

The ssdp discovery UDP packets not even visible using packet analyzer (smartsniff)

If i put `sock.bind(("192.168.1.10",999))` to _m_search_ssdp it wokring fine also tried `sock.bind(("",999))`, but no luck. Any idea?
 Made it work by detecting local ips (+added some logging, [fixed the successful run check](https://gist.github.com/HelloZeroNet/5133c7f03030620c278f#file-upnppunch-py-L220) and it also can be run by standalone using `python UpnpPunch.py`):
https://gist.github.com/HelloZeroNet/5133c7f03030620c278f

Please test :)

Update#1:

socket.gethostbyname_ex('') does not works on linux, but the getsockname() gives the correct answer, so it should work there.

``` python
>>> socket.gethostbyname_ex('')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
socket.herror: [Errno 4] No address associated with name
>>> s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
>>> s.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)
>>> s.connect(('239.255.255.250', 1))
>>> s.getsockname()[0]
'176.231.40.130'
```

Result on my windows pc:

``` python
>>> socket.gethostbyname_ex('')
('short-pc', [], ['192.168.1.10'])
>>> s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
>>> s.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)
>>> s.connect(('239.255.255.250', 1))
>>> s.getsockname()[0]
'127.0.0.1'
```

it worked before, so probably sometomes the s.getsockname()[0] returning the '192.168.1.10' ip as answer

if we can find a way to list available ip address on mac/linux then we can also add them to probe iplist

Update#2:
Added this one too, because it returns correct ip on both platform:

``` python
>>> s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
>>> s.connect(('8.8.8.8', 0)) # Using google dns route
>>> s.getsockname()[0]
'192.168.1.10'
```
 I think its clearly fixes some problems, so the PR is welcomed
  Thank you! :)
  Progress bar is planned, but zerosearch is working here. Can you give urls to sites that loads slowly for you?
 Progress bar is a good idea, added to latest (0.2.5) version

There is a [little tutorial](http://127.0.0.1:43110/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/?Post:3:How+to+have+a+blog+like+this) on siteCreation at ZeroBlog.

And there is a simple example of ZeroFrame API at [developers docs](https://github.com/HelloZeroNet/ZeroNet/wiki/ZeroNet-developer's-documentation)
  Not every new message reaches all of the peers.

It's related to https://github.com/HelloZeroNet/ZeroNet/issues/43

Already working on new network code without ZeroMQ. It will be released in 1-2 weeks.
 It had some bug in publish method, fixed in 0.2.4
  Thanks!
  I have been thinking about it earlier, but it would have some problems:
- The currently used bitcoin crypto libs doesn't support it, so they need to be modified
- Vanity address generator would not work

Some ideas to blockchain usage:
- Proof of site age by first transaction to site's address
- You can accept donations to site address

So I don't think it worth the mess up.
  It's normal: 
- /Console raises a custom exception "Here is your console" to spawn the werkzeug console in UiRequest namespace. (You can access the console by hover over `raise Exception("Here is your console")` line the clicking the second icon from right.) Its a little bit hackish, but works :)
- /Debug always display the last error's namespace (in next version I will exclude notifications from it)
 Ah looks like the google bot found the console url somehow. I'm going to restrict the /Console and /Debug access to debug mode only.

Update: Looks like its restricted already:

```
        # Debug
        elif path == "/Debug" and config.debug:
            return self.actionDebug()
        elif path == "/Console" and config.debug:
            return self.actionConsole()
```

The exception it raises in non debug mode:

```
  File "F:\Work\ZeroNet\src\Site\SiteManager.py", line 47, in need
    if not isAddress(address): raise Exception("Not address: %s" % address)
Exception: Not address: Console
```

So i have to make a better error message for this

Update #2: Ok fixed, in next version it will drop "Not Found: /Console", thanks for the bugreport
  Not all site optimalized to mobile devices, so maybe its not a good idea to make it default, but added (bccd246f716ce191d872fdae2a84b27b66300641) a viewport option to content.json, you can use it like this:

``` json
 ...
  "signs_required": 1, 
  "title": "ZeroTalk", 
  "viewport": "width=device-width, initial-scale=1.0", 
  "zeronet_version": "0.2.0"
}
```

and added WrapperAPI command too: `@cmd "wrapperSetViewport", "width=device-width, initial-scale=1.0"`

I don't have any smartphones to test it, but works in chrome's device emulator. 

Applied the viewport on ZeroTalk site, it would be nice if anyone can check if its displays nicely on any small screen device.
 only `"viewport": "width=device-width, initial-scale=1.0"` works, `"` quotes will be escaped, so you cant break out from the `content` attribute of the meta tag

Thanks for testing, yeah, notifications is not yet responsive.
  Buit-in Tor (with hidden services) just landed 1 week ago, the core modifications was made in mind of future i2p/ipv6 support. I was looking for python libraries for i2p, but only found some outdated ones (updated 12 years or 3 years ago). 

Need more research to see if i2p support many (per site so 100+) services from same host and have to find out the cryptography of i2p address to be able to create proof-of-ownership signature to avoid some network attacks.
The other main problem is to make it any usefull we have to pack it with ZeroNet, i'm not sure if its possible with java applications.
 The problem with optional installation: I2p does not allow socket connections outside the network, so to be able to connect to a site using i2p it must have at least one peer with i2p address which is unlikely if they have to start/configure by hand.
 @str4d Thanks for the responses. As for the "many (per site so 100+) services from same host":

In full Tor mode we create a new .onion address for every site you seeding to improve privacy by make it harder to find out what other sites you using. So if someone has 100 sites in his/her client then on the startup we need to create 100 i2p address on startup.
 Probably not anytime soon, maybe second half of 2016
 It will use https://github.com/arvidn/libtorrent which has no i2p support atm.
 nice, then looks like there will i2p support :)
  I think it could work this way:
- By default every site has 10MB size limit
- If the site used 80% of its limit zeronet displays a notification when you visit the site: `This site want to store more data than current limit: 10MB. [Incrase limit to 20MB]`
- The limit steps: 10MB, 20MB, 50MB, 100MB, 500MB, 1GB, 5GB, 10GB, Unlimited
- If a new update to content.json comes in and the total size of site exceed the limit then the update will be rejected.
- If you visit a new site and its size larger than 10MB then the notification will be displayed on the loading screen and the download wont be started until you give the permission
 Added in version 0.2.1:
![sizelimit](https://cloud.githubusercontent.com/assets/10350359/6200295/73dc987e-b471-11e4-9438-4d23e5adb5d4.png)

NSFW warning can be added later if necessary
  I'm not familiar with docker, but added this:
https://registry.hub.docker.com/u/nofish/zeronet/builds_history/213281/
Please tell me if any problem with it.
 according to build log the msgpack build is failed with `msgpack/_packer.cpp:8:22: fatal error: pyconfig.h: No such file or directory`
probably it would be nice to add python-dev package to apt-get install or install msgpack from repository (not sure if every linux has msgpack 0.4.0+)
  you can add this to your content.json
`"ignore": "\.git.*",`

but ignore all files starts with `.` could be a good idea
  - Upgrading ZeroNet: keep your data dir, all your data is stored there
- Upgrading ZeroBlog: backup content.json and data.json from your site, overwrite all other files

Yes, the sites ordering is problematic on ZeroHello, currently sorted by peer number, bookmark feature is a good idea
  thx
  Thanks!
  Unfortunately I don't have access to any OSX machine, so I cant test or fix it.
  Thanks
  thanks, fixed by your push
  We need a cross-platform, pure-python dns query lib, so we can use http://www.opennicproject.org/ servers.
 I have chosen this format, to allow subdomains (@ means zeronetwork.bit without subdomain)

```
    "zeronet": {
        "blog": "1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8", 
        "@": "1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr", 
        "talk": "1TaLk3zM7ZRskJvrh3ZNCDVGXvkJusPKQ"
    }, 
```

But I haven't found any reliable way to resolve this information without installing namecoind.

Using NS TXT record and http://www.opennicproject.org/ could be a workaround:

``` python
import DNS
DNS.DiscoverNameServers()

r = DNS.DnsRequest("zeronet.zeronetwork.bit", qtype="TXT", server=['192.71.247.247', '75.127.14.107'], timeout=300)
res = r.req()
res.show() 
```

```
[...]
zeronet.zeronetwork.bit    1109    TXT     ['@:1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr,blog:1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8,talk:1TaLk3zM7ZRskJvrh3ZNCDVGXvkJusPKQ']
[...]
```
 Found this one, it could work (but single point of failure): https://dnschain.info/bit/d/zeronetwork
edit: 
found alternative servers:
- http://dns.dnschain.net/d/zeronetwork
 a new dnschain server:
https://api.dnschain.net/v1/namecoin/key/zeronetwork.bit

There is an another option to resolve bit domain:

Create a special, dns resolver site that holds all registered zeronet domains in a json file, so everyone has the dns database on localhost.

Pros:
- Its allows fast and secure dns resolving
- Does not depends on any central server
- Nobody can see what domains are you resolving
- Later it could work well with anonymity networks (tor, i2p)

Cons:
- It needs a bot that update the database from namecoin transactions
- If the private key of the site is compromised then its possible to modify dns records
 another alternative:
http://namecha.in/name/d/zeronetwork
 I have done a plugin using 2 dnschain servers, but i'm not satisfied by the result: 
- It takes 1-5 sec to resolve the domain using the 2 servers, by increasing the dns caching time its possible to workaround the problem, but not a real solution for offline/slow connections
- Trusting in 2 servers result not secure enough and I could not find other servers that allows to resolve namecoin json informations

So I decided to take the alternative, [dns resolver site](#issuecomment-78250713) approach. Its developing well, need some more days to finish it.
 Status report: i think everything is working now, if no other bugs found i will publish it tomorrow
 Added Zeroname plugin: b122f471003e3c293513671d7d53f63c7c6d5753
The experimental dnschain plugin also supplied (disabled by default)
Later, if lightweight namecoin client is released it will be also supported.
 The "" key means the primary domain, any other than that is a subdomain.

Also added this information to http://127.0.0.1:43110/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F "HOW TO ADD A DOMAIN?" section
 yeah you probably right a custom prefix could be better solution, but i think we can have both: z/ prefix for .zero d/ prefix for .bit.
This allows to use your exitsing domains in zeronet and if someone wants to access your site without zeronet installed (and he able to resolve .bit domains) you can redirect him to a description about zeronet.

Update: I have asked about it in #namecoin and they said there was similar request from i2p and tor, but they rejected it and advised to use d/. Reasons:
- (1) it is useful to be able to verify that the IPv4 and ZeroNet versions of a name are owned by the same person; d/ makes that easy
- (2) if a new namespace is introduced, users will have to defensively grab their names at that namespace to prevent squatters from getting them
- (3) as an extension of (1), some users want their software to be able to choose which resolver to use (e.g. IPv4, Tor, ZeroNet) based on which ones are supported by their browser config; using a single namespace makes that easy

but changing .bit to .zero still sound like a good idea
  Yes, i have already had some thoughts about it:
It can be easily solved by adding the allowed signers public key and sign to content.json like this:

``` json
"signers": [
 {"Signer1Addr": "Signer1sign"},
 {"Signer2Addr": "Signer2sign"},
 {"Signer3Addr": "Signer3sign"}
],
"signers_required": 2,
```

So when someone got a new content.json, he checks if it has the required number (definied in `signers_required`) of correct signs.

Maybe we should combine it with some kind of permission system, so you could define rules like:
"Signer4Addr" has permission to modify "messages/Signer4Addr.json" file, but not anything else. (size could be possible limit too)

But at the moment I want to keep ZeroNet as simple as possible, and only adding new features if we has the application that could use benefits of it.
 Its implemented in 0.2.0, but its not deep tested yet
  Yeah, the main problem is all site is using the same domain. Permission requesting is a good idea (maybe with other http://www.html5rocks.com/en/tutorials/security/content-security-policy/ features)
Later we can pack a sqlite server, so the clients can do queries via websocket api.

Util then please use flat json files or any format supported by [alasql](https://github.com/agershun/alasql)

Please let me know if you have any benchmark results on indexedDB vs flat json vs alasql.
 Not directly, but you can write files using the [API](https://github.com/HelloZeroNet/ZeroNet/wiki/ZeroFrame-API-reference-documentation). (see [ZeroBlog](https://github.com/HelloZeroNet/ZeroBlog) example)
 Now its possible to use browser's localStore with ZeroFrame API:
http://zeronet.readthedocs.org/en/latest/site_development/zeroframe_api_reference/#wrappergetlocalstorage
  Update failed is normal when seeding own site without other peers.
In the latest commit "Update failed" warning changed to "No peers found" when seeding own site to make it less scary.

ZeroMarket and ZeroBay still under planning, it will be arrive later
  Thanks!
  Thanks for reporting. I rather not touch the external subtl library,but its fixed at config parse: 2000f5b38eb5d7e6f29bc29232b8493d31b6817a
  If he owns the private key he could have access to bitcoins too. (havent tried yet)
  Thanks!
Namecoin (.bit domains) support is planned, but its not priority yet, since ZeroNet is not ready for mass adoption yet.
Could you be more specific about your Search/Discovery idea?
 Thanks for explaining. :) Sounds interesting, later I will check it even deeper.
 I have tried the BitTorrent Maelstorm about 1 month ago (found on a russian forum :) ) and I was not impressed. Its basically a torrent client embedded into a browser.
I had the Zeronet idea for a while in my mind, but tried to convince myself its not a good idea/not going to work. Then I seen the BitTorrent guys working on similar idea and throughout: If they thinks its a good idea maybe it is. (Written first lines of codes exactly 1 month from now)
 Namecoin .bit domain support added in 0.2.8: b122f471003e3c293513671d7d53f63c7c6d5753
  We have pure python upnp, so fixed in 34f6d1ee7c8b5a8958f675c5e17a95c34c6a4967
  I think its fixed in latest version:
https://github.com/HelloZeroNet/ZeroNet/blob/a977feec330a024686518ce6c374167d63d564f2/src/File/FileServer.py#L54
  you can use `<a href="/13TSUryi4GhHVQYKoRvRNgok9q8KsMLncq/2015/01/15/decentralized-websites-with-zeronet.html" target="_top">Some link</a>`
 If you add `target="_top"` it will change the browser bar url
  Cons:
- It could be irratating if you just restart it or you want to put in autorun

Possible solutions:
- Open by default but can be disabled via `--dont-open-browser` command line parameter
- Create an another file that starts zeronet.py and opens the browser too: start.cmd
- After starting zeronet.py display a message: `-- Press enter to open http://localhost:43110/ in your browser --`
 Thanks, merged!
  Thanks!
  Thanks!
  Thx, but I rather not store save the private keys to a simple txt file. From the version 0.1.4 its harder not to save the private key at siteCreate :)
  ```
Error catched (<type 'exceptions.AssertionError'>, AssertionError("This event is already used by another greenl
et: (<ErrorhookedGreenlet at 0x2a8f958: <bound method Worker.downloader of <Worker.Worker.Worker instance at 0x
2c03f38>>>, timeout('timed out',))",), <traceback object at 0x2abbcb0>)
Traceback (most recent call last):
  File "/usr/lib/pymodules/python2.7/gevent/greenlet.py", line 390, in run
    result = self._run(*self.args, **self.kwargs)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Worker/Worker.py", line 47, in downloader
    self.manager.doneTask(task)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Worker/WorkerManager.py", line 128, in doneTask
    self.site.onFileDone(task["inner_path"])
  File "/home/sumo/p-private/dev1/bin-zeronet/src/util/Event.py", line 8, in __call__
    f(*args, **kwargs)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Site/Site.py", line 275, in <lambda>
    self.onFileDone.append(lambda inner_path: self.fileDone(inner_path))
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Site/Site.py", line 307, in fileDone
    self.updateWebsocket(file_done=inner_path)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Site/Site.py", line 286, in updateWebsocket
    ws.event("siteChanged", self, param)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Ui/UiWebsocket.py", line 50, in event
    self.cmd("setSiteInfo", site_info)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Ui/UiWebsocket.py", line 60, in cmd
    self.send({"cmd": cmd, "params": params}, cb)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Ui/UiWebsocket.py", line 67, in send
    self.ws.send(json.dumps(message))
  File "/home/sumo/p-private/dev1/bin-zeronet/src/lib/geventwebsocket/websocket.py", line 345, in send
    self.send_frame(message, opcode)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/lib/geventwebsocket/websocket.py", line 331, in send_frame
    self.raw_write(header + message)
  File "/usr/lib/pymodules/python2.7/gevent/socket.py", line 504, in sendall
    data_sent += self.send(_get_memory(data, data_sent), flags)
  File "/usr/lib/pymodules/python2.7/gevent/socket.py", line 484, in send
    wait_write(sock.fileno(), timeout=timeout, event=self._write_event)
  File "/usr/lib/pymodules/python2.7/gevent/socket.py", line 188, in wait_write
    assert event.arg is None, 'This event is already used by another greenlet: %r' % (event.arg, )
AssertionError: This event is already used by another greenlet: (<ErrorhookedGreenlet at 0x2a8f958: <bound method Worker.downloader of <Worker.Worker.Worker instance at 0x2c03f38>>>, timeout('timed out',))
```
 - queue for websocket messages
 It happened when i ran the zeronet on remote machine (around ~40ms away) and downloaded a site with many small files.
The ZeroNet pushes pushes an event over websocket after every file download, and maybe the last event message was still not finished when the next came.
I think it could be fixed like this:

``` python
def send(message):
 self.message_queue.append(message)
 if not self.sending:
    self.sending = True
    while self.message_queue:
      self.socket.send(self.message_queue.pop(0))
    self.sending = False
```

Maybe there is a better solution with gevent, but i like pure-python solutions, its easier to understand whats really happening.
Btw I optimized the Websocket to much smaller event messages, maybe its not an issue anymore, im going to test it later.
 I think this model will not work in this case, because we dont want to send messages in parallel and we dont want to wait until the message is sent
 ran into this problem again, so i fixed it: https://github.com/HelloZeroNet/ZeroNet/blob/e8368a8da1478ec370a129e96aa89e9fb638b9ad/src/Ui/UiWebsocket.py#L71
  Try this please:
- Stop zeronet
- Edit data/sites.json and set "own": true at your site
- Use siteSign 
- Then start zeronet.py again. 
  in next release the "own" flag will be true on newly created sites
 I can access your site, looks nice :)
I think the Hash failed problem is because someone has older version of content.json than yours. 
You should run `zeronet.py sitePublish 1GXtHRoh7495zJYLthQ8xPt2dRzm8DwWhb` so he will get the updated file
  Unfortunately the library currently used for networking (ZeroMQ) don't offer bw limitation or network usage information. It could be fixed by removing ZeroMQ and rewriting the communication without it.

At current stage ZeroNet is not suitable to distribute large files/sites, so its not priority.
 I think the a simple gevent StreamServer will do the work. Not really take advantage of these messaging libraries.
Something with built-in rate limiting and maybe client priority will be nice, but I don't know anything like this for python :(
  Torrent like file splitting and distributing
 Maybe needs to wait until DHT support to able to find peers to needed fileparts
 Some blocker for big files: 
- Currently the downloads stored in memory until they get verified, it need to modify the storage mechanism to make it work efficiently (sparse files?)
- There is no file splitting support: You dont know if the file is valid or not until you downloaded the whole file and you can only download from one peer at one time
- Most of the peers using Tor network to connect ZeroNet, that is not suitable to transfer big files

As optional files support added around 6 months ago, so DHT is no longer required for this. ZeroNet is created for dynamic websites, most of the site types does not requires big file support, so it's not a priority yet. Maybe adding a torrent client as a plugin is a better solution.
 Plugin would be nice, i'm planning to do a plugin management interface later, that makes easy to add/remove/install the non-default features
 probably it's possible if we use torrent for big files
 BitTorrent support is planned in the next 6 months, which will provide solution for big files
 BitTorrent clients also have the advantage of ~15years spent on optimization and the fact that they don't have to worry about the dynamic content. (eg. they can identify pieces by a simple id on zeronet you have to identify by filename or hash) # Plan 0.5

## File hashing: .piecemap.json

To avoid large content.json files move the piece hashes to separate file.

### Example content.json

```
{
  "files_optional": {
    "video.mp4": {
      "sha512": "174004c131000b2c8d57a411131f59f7c75d888367c00e3fca5f17e2adf422b2",
      "size": 11227004,
      "piecemap": "video.mp4.piecemap.json"
    },
    "video.mp4.piecemap.json": {
      "sha512": "174004c131000b2c8d57a411131f59f7c75d888367c00e3fca5f17e2adf422b2",
      "size": 11227
    }
  },
  [...]
}
```

### Example video.mp4.piecemap.json

```
{
 "video.mp4": {
 	"piece_size": 1000000,
 	"sha512_pieces": ["783afdeb186b50c696030f199d5db233270a84cd6183316be34c623e341dd85f", "0603ce08f7abb92b3840ad0cf40e95ea0b3ed3511b31524d4d70e88adba83daa", ...]
  }
}
```

#### Size test with 2784 pieces

 - video.mp4.piecemap.json: 189k
 - video.mp4.piecemap.json.gz: 107k
 - video.mp4.piecemap.json.bz2: 93k
 - video.mp4.piecemap-indent.json: 211k
 - video.mp4.piecemap-indent.json.gz: 108k
 - video.mp4.piecemap.msgpack: 97k
 - video.mp4.piecemap.msgpack.gz: 94k
 - video.mp4.piecemap.msgpack.bz2: 92k

#### Read 1000x times:
 - video.mp4.piecemap.json: 1.39s
 - video.mp4.piecemap.json.gz: 2.7s
 - video.mp4.piecemap.msgpack: 0.13s

So msgpack or json or json.gz?

## Questions

 - How/where to store which pieces we have?
 - Uploading? WebSocket suitable for this or separate HTTP post request?
 - Compressed piecemap?
 - How to display it in the UI?
 - Is there any real-world use case to support partial modifications on big files?

## Storage

### Store as one big file
To make it fast and efficient we need sparse file support in the fs. It works well on ext4 by default and on windows 10 (probably also on 7-8) after setting `fsutil sparse setflag testfile`.

Pros:
 - Less files
 - External app support: you can play videos in any player

Cons:
 - It will be slow on older systems: fat32 (android) and windows xp
 - Probably need more work

### Store pieces as separate files
Pros:
 - More compatibility, works equally well on fat32 and windows xp

Cons:
 - No external app support

## Uploading via web interface

### WebSocket

Pros:
 - Already authenticated

Cons:
 - Looks like the geventwebsocket library does not support streaming
 - The websocket channel is blocked during the upload (splitting could help)

### Http request

Pros:
 - Different channel and connection, so does not interfere with other API calls or messages

Cons:
 - Has to be authenticated separately
 - Cookie/CORS problems?

## Plan
 - [x] Experimental piecemap hasher
 - [x] Add piecemap via uploading
 - [x] Add piecemap via signing for files larger than 5MB
 - [ ] Check permissions
 - [x] File downloading using sparse
 - [ ] Demo video playing
 - [ ] Demo uploader site
 - [ ] UI modifications Same goal, but torrent files using it's own non-standard (never used by any other application) encoding (bencode) and outdated, not secure anymore sha1 hash, so I think it would be a mistake to use it. If we don't case about Tor network compatibility, then is a Torrent plugin in the works: https://github.com/rllola/zeronet-torrent-plugin (python-ipfs is pretty incomplete atm.)

I planning to add it as a plugin, so most of the parts will be re-usable and it will make other network implementations easier. # Exchanging who has the pieces we looking for.

## Use the same hashfield we currently using for optional file

Pros:
 - Find/storage already implemented, so much less work

Cons:
 - Memory/bw usage: 2 byte/piece, so for a 5GB file with 1MB piece size it's at least 10kb data to store and transfer (per peer, per file)
 - Limited efficiency: We use 2 byte identifier for optional files (first 2 bytes of sha512), so if two piece has the same 4 char of the hash, then it will give false results, so we have to keep trying until we find a valid result.

## Assume everyone downloaded the whole file
Keep trying until we find someone who has the piece.

Pros:
 - No extra bw/store/mem requirements

Cons:
 - Less reliable response speed as we have to connect and ask peers until we find someone
 - Can't display separate leech/seed number

## Add a new per-file piecefield

Pros:
 - Won't trash hashfield: Only adds the file's root hash to it
 - We can find piece based on file hash and it's piece number, so no hash collision chance and much more efficient

Cons:
 - Added complexity: Need new protocol extension to exchange and find in this field
 - Has to store the peer's piecefield

# Storage of piecefield

```
piecefield = "1"*1000
piecefield += "0"*500
piecefield += "1"*1000
piecefield += "0"*2500
# 1 means downloaded 0 means not downloaded
# So: There is 5000 pieces, first 1000 and and another 1000 piece downloaded after the 1500th
```

## Storage as int
`int(hashfield, 2)  # sys.getsizeof: 680, msgpack: long too big to convert`

## Compress it with zlib
`zlib.compress(hashfield, 1) # sys.getsizeof: 75, msgpack: 57`

Using custom zlib compression: 
`compressor = zlib.compressobj(1, zlib.DEFLATED, -15, 1, 3)  # sys.getsizeof: 48, msgpack: 28`
 On Sia you have to pay for the storage. Because of that I think it's not suitable for most of the use cases that we need. ## status update:
As usual, it's I bigger task, than i originally tought, but I'm getting there, I just did a successful video stream between two clients:

### Done:
 - Exchange piecefield (which pieces someone has within a file) between peers
 - Implemented a custom compression format for piecefields
 - File downloading based on piecefield
 - Http stream with ranged file support (seek in video files)

### Still left:
 - [x] Save / restore piecefields between client restarts
 - [ ] Make it compatible with OptionalStats plugin (Files tab on ZeroHello)
 - [ ] Non-streaming file download (start all piece download without file read)
 - [ ] More testing

### Questions:
 - Should it download big files if "download all files" checked on sidebar?
 - Should big files count in optional files limit? If yes, then it may easily automatically delete every optional file you downloaded before and/or the large files you downloaded
 @grez911 Not sure what you mean. The big file support is built on optional files feature.   Needs more testing + Put priority on browser requested files (and maybe start download with smaller files) Problematic site: 1Jr5bnqSnnp94CfC7xrqPh4yYYDRkpzozD
 file queue priority based on browser request added: efb1dc32105e3cd75eb112788d0def0303cac5b2
It should be much better now!
Tomorrow i will do some more testing...
 Your site worked here nicely:

```
[2015-01-14 18:35:35,969] DEBUG    Site:13TSUr..Lncq Start downloading...
[2015-01-14 18:35:35,987] DEBUG    Site:13TSUr..Lncq Need content.json first
[2015-01-14 18:35:37,736] DEBUG    WorkerManager:13TSUr..Lncq x.x.x.x:15441: Hash correct: content.json
[2015-01-14 18:35:38,838] DEBUG    Site:13TSUr..Lncq Downloading 1229 files...
[2015-01-14 18:35:39,364] INFO     Site:13TSUr..Lncq Bad file solved: index.html
[2015-01-14 18:35:39,563] INFO     Site:13TSUr..Lncq Bad file solved: 2008/03/13/index.html
[2015-01-14 18:35:39,766] INFO     Site:13TSUr..Lncq Bad file solved: css/syntax.css
[2015-01-14 18:35:39,954] INFO     Site:13TSUr..Lncq Bad file solved: css/screen.css
[2015-01-14 18:35:40,138] INFO     Site:13TSUr..Lncq Bad file solved: css/print.css
[2015-01-14 18:35:40,323] INFO     Site:13TSUr..Lncq Bad file solved: css/bluishcoder.css
[2015-01-14 18:35:41,387] INFO     Site:13TSUr..Lncq Bad file solved: self/self_comment.webm
[2015-01-14 18:35:41,960] INFO     Site:13TSUr..Lncq Bad file solved: self/self_font.webm
[2015-01-14 18:35:42,145] INFO     Site:13TSUr..Lncq Bad file solved: nixos/standalone-ndk/default.nix
[2015-01-14 18:35:42,338] INFO     Site:13TSUr..Lncq Bad file solved: 2006/06/04/narrative-javascript.html
...
```

Please make sure you have the latest version. Yesterday night I added a modification that put priority to files that requested by the browser. But maybe putting priority to *.js and *.css files by default could not hurt anyone.
 Fine :)
At there is still some problem with large sites: the site has 1 minute to finish all file downloads or the task will be killed.

Working on it, I think it will be fixed today.
 Here it comes: bcd0c0025aa5c8d23dba4362c75f8dbaf236dd27
(I think we can close this issue)
  ```
Norton

File blocked: tools\upnpc\upnpc-static.exe 

Threat name: Trojan.Gen.2 ( http://www.symantec.com/security_response/writeup.jsp?docid=2011-082216-3542-99 ) 
```

Pure python upnp implementation would be nice, but i could not find any good.
 I think nobody is working on it, so its free to go :)
I want avoid add extra dependencies, so it would be really nice to make it work using only gevent+standard libs.
 Wow looks nice, good work! I'm going to test it later today.
 Just tried it and its working here! :) On Monday i'm going to test it on other routers.
 it's working at my workplace too :) So I think we can include it in the next release if its ok for you too. 
 Fixed in 34f6d1ee7c8b5a8958f675c5e17a95c34c6a4967
  Thanks for reporting, its fixed: 6424c8288781a0cd93eaf0b9d5da0a7466ee3058
  Please send me log/debug.log file, so maybe I can find out whats wrong. hello@noloop.me
Thanks!
 Just added more detailed error logging, please try with it if problem still exits
/n  ### Step 1: Please describe your environment

  * ZeroNet version: 0.6.1 r2324
  * Operating system: Debian buster
  * Web browser: 52.6.0
  * Tor status: always
  * Opened port: yes
  * Special configuration:  in /etc/tor
  ```
 ControlPort 9051
 CookieAuthentication 1
```

From https://zeronet.readthedocs.io/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux

### Step 2: Describe the problem:

Got the following output while running zeronet 

[11:52:49] Site:1PLAYg..Xvfp content.json: verify sign error: ValueError: Extra data: line 3140 column 2 - line 3140 column 103 (char 108699 - 108800) in ContentManager.py line 821 > __init__.py line 291 > __init__.py line 339 > decoder.py line 367

#### Steps to reproduce:

 

#### Observed Results:

The same as above. 

#### Expected Results:

The error should not be there. 

If such an error does happen, at least give some hint as to where I should look next to resolve it. 


  ```
$ python2 -c "import sys; print(sys.version); import gevent; print(gevent.__version__); import msgpack; print(msgpack.version);"
2.7.14 (default, Jan  5 2018, 10:41:29) 
[GCC 7.2.1 20171224]
1.2.2
(0, 5, 0)
```  > Don't do anything, let other clients try and fail for unknown sites

A bad idea (at least without any changes) - currently ZeroNet downvotes peers that request unknown sites.  Would it be possible to add a flag that would allow a zite to be loaded directly instead of loading it inside an iframe?
The problem is that for tools like [vuejs-devtools](https://github.com/vuejs/vue-devtools/) to work the vue.js script must be present in the page itself. If the script is inside the iframe the tool won't detect the script.
I could use that tool by loading the file directly on `file://` but then the zeronet api will not work.
Maybe the flag can be set only if the person is the site owner.

Thanks  Hello! I know `fileQuery` is quite an old thing, but it is useful to query some CORS sites that don't have any database.

So this PR adds two options:
1. First, it adds `fileQuery` to `corsFuncWrapper` list, so you can `fileQuery("cors-something...")` now.
2. The second change, which isn't connected with CORS, `fileQuery("file", "posts.slug=home")` is valid now - so you can use a string as value for searching. @HelloZeroNet Any news? I know, but there is no way to query data from ZeroWiki when I add it as CORS.

Kaffiene does use ZeroWiki's database, but it uses JavaScript SQLite.

Also you said we shouldn't encourage that, and I completely agree - that must be the last resort - but sometimes there is no way to avoid using it. @HelloZeroNet I can PR that - should it be support for `dbschema.json`:

```
maps: {
    "cors-.*/...": ...
}
```

or should it be a command `corsDbQuery("address", "query", params)`? Thank you! @HelloZeroNet Let me check. Wait - this doesn't work:

```
page.cmd("as", ["138R53t3ZW7KDfSfxVpWUsMXgwUnsDNXLP", "dbQuery", "SELECT * FROM json WHERE json_id = :param", {param: param}])
``` Yeah, it works - thank you for implementing this. Though I think that should be documented somewhere.  idea
 > proof-of-storage and proof-of-bw is really hard (impossible?)

FYI, Proof of Space is possible. PoS uses hard-to-pebble graphs to ensure the prover must dedicate a certain amount of storage. It is hard to implement though. See the SpaceMint [paper](https://eprint.iacr.org/2015/528.pdf) and [source code](https://github.com/kwonalbert/spacemint). @HelloZeroNet @MuxZeroNet   Yes, it is hard to implement. But I think thak making a honor wall for those people who contribute to the ZeroNet is easy to implement. For example, when one's upload  exceed 1GB, he or she would recieve a virtual medel. Just like the Steam, in which people would recive a virtual medal for his or her palying time. It just be a suggestion for encouraging people's distributing behaviors. @HelloZeroNet Run fileRules locally? @HelloZeroNet You should maybe take a look at https://filecoin.io and https://filecoin.io/proof-of-replication.pdf  Hi, I just used vanity to create a public and private key pair.

1) Generated the key pair
2) Created directory with vanity address
3) Cloned ZeroTalk fork in
4) Changed the `address` field in `content.json`
5) ... ?

Now there are bunch of things in `content.json` and I am wondering what to do next. 
Can you help me out please?  Hm... The idea itself look interesting, but ~2-3 days... Not sure if that is acceptable for users who join the network. Okay, looks reasonable. I like this solution because it doesn't require a blockchain.  ### Step 1: Please describe your environment

  * ZeroNet version: rev3223
  * Operating system: Windows 10 Pro
  * Web browser: Chrome 63.0.3239.132 
  * Tor status: not available
  * Opened port: no
  * Special configuration: none

### Step 2: Describe the problem:

The Console window will not open when I run ZeroNet.exe nor there is a `Show Console` option in the icon tray menu

#### Steps to reproduce:

  1. Install the zeronet windows bundle and run
  2. Try to open the console window (to debug an error or something)

#### Observed Results:

  Icon tray screenshot: https://ibb.co/nip5Ww

#### Expected Results:

- A Show Console item in the menu
 Awesome. I've created [this PR](https://github.com/HelloZeroNet/Documentation/pull/79) to avoid this questions again.
Thanks  In some cases and particularly with Big Files, you would want to prevent the deletion of a user file or even a zite file. For example, if you seed a useful 2go image file and suddenly the user who posted it remove it, you will completely lose the file. I think even if the zite is deleted by the owner (ex: private-key compromised, all data removed), you should be able to prevent update/deletion of some files. 

Implementation-wise, each file indexed in content.json could have a "frozen" flag, but no idea about how ZeroNet will share the files between peers if they are locked at a specific version in time (and I don't know if content.json files can be "customized" locally). 
Use case: for a zite like ZeroUp, every file you seed could be frozen by default.

I know there are suggestions about versioning, but you can use tools like rdiff-backup if you really want to backup a zite. It's more about trusting your files from not being deleted, as you'd expect with things like torrent. With a sub-option or a pinned mode (frozen/unfrozen) ? 
 But you would still be able to update their content (corrupt/resize/delete the data) ?

Edit: I think this is a cool feature, don't know if it's possible with big files (if the file is deleted when the piecemap change or not), it allows to update big files and only the differences would be sent (doing something similar to projects like zsync but natively, which is amazing). But it's a powerful feature, if you seed a song file and listen to it regularly, the song could be completely different from the last time. You can accept to fully trust the owner of the file, but bigger is the file, seeding it shows your determination to  preserve its existence and integrity; you would want to upload it yourself to be sure that the owner will not mess with it, failing the idea of sharing the same file. 
Or maybe the concept of ownership of ZeroNet is not very suited for this kind of behavior, you can only trust owners to not modify the files.  Gratipay shut down so people can't donate to the project through it
anymore.  ### Step 1: Please describe your environment

  * ZeroNet version: Latest (Version: 0.6.1 r3221 I think)
  * Operating system: MacOS Sierra 10.12.6 (16G29)
  * Web browser: Irrelevant. Though I normally use Firefox Nightly
  * Tor status: Default setting
  * Opened port: Either way, both fail.
  * Special configuration: Nothing

### Step 2: Describe the problem:

ZeroNet fails to start.
```
SyntaxError: unqualified exec is not allowed in function 'bench' it is a nested function (UiRequest.py, line 645)
``` Looking for similar errors, looks like it might be related to a bug that was fixed in Python 2.7.9. Maybe try updating it? I'm not sure what the fix was for the config thing, but that went away eventually. The other error had an issue with this line in /src/ui/uirequest.py

```
 exec(init, globals(), locals())
```

I changed it to:

```
exec init in globals(), locals()
```

And it worked fine. Is it due to an older python version? I'll have to look into updating. My ZeroNet on Windows is running off of Python 2.7.9(pure coincidence) and didn't encounter this. So it probably is related to that old bug I mentioned. @April93 Weird, that `exec init in globals(), locals()` is Python3-style. [Here's the stackoverflow page](https://stackoverflow.com/questions/4484872/why-doesnt-exec-work-in-a-function-with-a-subfunction) I read on how to 'fix' the problem. No idea what's going on tbh. PR: #1253. I tried updating to python 2.7.14 and it works fine without the fix. Yeah, looks like this was a bug in Python <=2.7.8, which was fixed in 2.7.9.

[This answer](https://stackoverflow.com/a/41368813) on that Stackoverflow page you linked explains it. Unfortunately as I mentioned, I already updated my python version. I'm unsure of how to downgrade.  I use ZeroUpdate.bit update to the latest version, Android client 0.5.6.1ï¼Œnow open ZeroUpdate.bit, it is rev 3220, I back to zerohello click update, it can't open zeronet, I clear back ram is not work. Works for me with rev 3221 by using [Linux Deploy](https://github.com/meefik/linuxdeploy/) app, from the commits rev 3220 has some issue, but @shortcutme pushed it to ZeroUpdate and forgot to push rev 3221. @HelloZeroNet @stbinan Android7.0 ,Zeronet APK 0.6.0.1,  reinstall zeronet, it  works, but when use ZeroUpdate.bit update to rev 3221,  zeronet can't be open,  the zeronet apk is downloaded on apkpure.com. Sorry, I don't know why, you can download and install to test.
android apk 0.5.6.1 has the same problem. @funny110 @mkg20001 Then it's an issue for [ZeroNet-kivy](https://github.com/HelloZeroNet/ZeroNet-kivy) update to rev3223, it works well. Updated ZeroNet-kivy: https://github.com/HelloZeroNet/ZeroNet-kivy/releases/tag/v0.6.1.1  Hello,

i have: zeronet 0.6.0, rev3179, Windows 10 64bit, Tor browser, not opened port, OpenVPN gui

a pop-up message "Connection with UiServer Websocket was lost. Reconnecting..."

appears in case i have several sites open, example 10 zites. Several of them are offline - never downloaded content.json (such sites can be found at: http://127.0.0.1:43110/1LtvsjbtQ2tY7SCtCZzC4KhErqEK3bXD4n) and i click one web browser tab hit F5 (to realod zite), after 1 second click other tab then F5, and like this lets say 5 times to reload lets say 6 zites), then i click tab with some opened zite like ZeroTalk and click some hyperlink and it show above mentioned error.

Are there any steps i can do to debug the cause of this? @HelloZeroNet 

I do not know if it is this, but in Tor browser / F12 key / "Console" tab, i seen these two lines only. It was there when i seen mentioned error message on that particular web browser tab on which developer console was open:

> [ZeroWebsocket] Closed close { target: WebSocket, isTrusted: true, wasClean: false, code: 1006, reason: "", currentTarget: WebSocket, eventPhase: 2, bubbles: false, cancelable: false, defaultPrevented: false, composed: false }  all.js:142:14
> [ZeroBlog] Websocket close  all.js:851:7 é›£é“æ˜¯é­åˆ°ç•¶å±€çš„æƒ¡æ„æŽ§åˆ¶ï¼Ÿï¼Ÿï¼Ÿ @HelloZeroNet

I received the error mentioned in my previous message again (code 1006, all.js:142:14) just now. And no sites seem to be loading. It reconnect, but do not load site. I found a few unhandled exceptions like this one in log file: https://pastebin.com/fnT7ak7b

But i have suspection if this issue is caused by TorBrowser, because in Firefox, sites are loading!
Update: after a few minutes i closed some zites in TorBrowser which i tried to open and then i see all is loading in TorBrowser. Thank youï¼ï¼ï¼


2018/1/28 ä¸Šåˆ1:57ï¼Œ"slrslr" <notifications@github.com>å¯«é“ï¼š

> I received the error mentioned in my previous message again (code 1006,
> all.js:142:14) just now. And no sites seem to be loading. It reconnect, but
> do not load site. I found a few unhandled exceptions like this one in log
> file: https://pastebin.com/fnT7ak7b
>
> â€”
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/HelloZeroNet/ZeroNet/issues/1249#issuecomment-361002188>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AiGlKmH8aTnrZIR1jgd7GswCeZRNvouMks5tO2OigaJpZM4RiEBI>
> .
>
  I try to build a tracker in the Internet and I have Public IP. But I can not communicate correctly with my HTTP tracker because ZeroNet always send request that port = 0.
I use wireshark to catch the bag and found that as following:
```
GET /announce?uploaded=0&downloaded=0&numwant=30&compact=1&event=started&peer_id=-ZN0060-Dsh93Nert4Sr&port=0&info_hash=%E7H.%B4%9D%8B%A7%08%DA%C7%90%0F%B0%AA%EAW%81%95%2C%F3&left=0 HTTP/1.1
Host: 18.217.*2.***:7777
User-Agent: Python-urllib/2.7
Accept-Encoding: identity
X-Lantern-Version: 4.4.1

HTTP/1.1 200 OK
Date: Wed, 17 Jan 2018 05:07:33 GMT
Conne4ction: keep-alive
Content-Length: 34

d14:failure reason12:invalid porte
```

But this problem didn't show when I connect the trackers which ZeroNet build-in.

And I'm sure that when I send the right request as following:
```
import urllib2
#import time
url = "http://18.217.9*.***:7777/announce?uploaded=0&downloaded=0&numwant=30&compact=1&event=started&peer_id=-ZN0060-aQg0kBTLErmd&port=15441&info_hash=%1D%AF%97%C8%1F%99%C3%83%90%86%29%2BhZB7%A9%A4%DD%D2&left=0"
req = urllib2.urlopen(url,timeout = 25)
response = req.read()
print response
req.fo.sock.recv = None
req.colse()
req.None
```
The return is right as following:
```
d8:completei1e10:incompletei0e8:intervali600e5:peers6:?:<Q6:peers60:e
```
   Hi,

I found this tutorial but it does not work for me. (Manual way: Using the command line1. Create site structure): http://zeronet.readthedocs.io/en/latest/using_zeronet/create_new_site/

If I'm not wrong, there's a bug in the "/"
"../Python/python.exe" zeronet.py siteCreate

(That's right)
"..\Python\python.exe" zeronet.py siteCreate

I installed "python-2.7.14.msi"

and since I did not find the "ZeroBundle/ZeroNet" folder does not exist... (Windows build)

I followed this:
cd C:\Users\NAME\Desktop\ZeroNet-win-dist\core
"C:\Python27\python.exe" zeronet.py siteCreate

I will get Error:
https://ctrlv.cz/shots/2018/01/14/k7e5.png

Thx help me. That's incorrect use of `ZeroNet-win-dist`. Instead of:

```
cd C:\Users\NAME\Desktop\ZeroNet-win-dist\core
"C:\Python27\python.exe" zeronet.py siteCreate
```

...use:

```
cd C:\Users\NAME\Desktop\ZeroNet-win-dist
zeronet.exe siteCreate
```

Also, I don't recommend you to use `siteCreate`. Instead, use ZeroHello. > If I'm not wrong, there's a bug in the "/"
> "../Python/python.exe" zeronet.py siteCreate
> 
> (That's right)
> "..\Python\python.exe" zeronet.py siteCreate

In Windows both `/` and `\` are correct. Thx, it works.

PS:
I would like to ask how exactly "Identity address" works...
https://ctrlv.cz/shots/2018/01/14/mOoJ.png
I did not find anything in the documentation to help me understand how it works. @HelloZeroNet

> actually it's lib/zeronet.cmd siteCreate as the zeronet.exe is gui-only application and you won't see any output to command line from it.

Well, you are not quite right. I use hooks in Git Center, and for signing call either `zeronet.py siteSign` or `core/zeronet.py siteSign` or `zeronet.exe siteSign`. All work, including `zeronet.exe`.

@elliekeli 

> I would like to ask how exactly "Identity address" works...

In clearnet you have a login, a password and sometimes a nick. In ZeroNet, your nick would be `elliekeli`, your login would be `1AoDYdMxwA55FTp2FNBrMaMv9r1ZzC6jSu`, and password would be a private key (which is stored in `core/data/users.json`). ZeroNet shows that login in sidebar.

ZeroNet is decentralized, so there can be options when nickname isn't unique (e.g. KaffieID). But login is auto-generated and guaranteed to be unique. Password is also auto-generated, so there is no chance you would be hacked (if someone doesn't steal your `users.json`, of course).

That identity address was given to you when you registered on ZeroID.

Hope I could answer your question. Thank you very much for your answer!

if I understand it correctly "Identity address" is the unique account (for each zeronet page separately) everyone PC has "random generated" on the same page?

I still want to ask what it is "(limit used: 0.00kB / 0.00kB)" thx.

Also excuse my bad English... @HelloZeroNet Okay, that makes sense. I did that `>/dev/null` stuff to supress output, so I didn't notice.

@elliekeli 

> if I understand it correctly "Identity address" is the unique account (for each zeronet page separately) everyone PC has "random generated" on the same page?

When you log in some site, you see options like `Unique to this site` and `zeroid.bit`. If `Unique to this site` is chosen then identity address is really unique. When `zeroid.bit` is chosen, then that identity address would be in fact your ZeroID login.

> I still want to ask what it is "(limit used: 0.00kB / 0.00kB)" thx.

Site owners can set limits for users, so users could't use a lot of space. On ZeroTalk, that limit is 50KB. If you open that sidebar on ZeroTalk, you'll see `?KB/50KB` which means you have `(50 - ?) KB` storage left for your posts.

Of course `0KB/0KB` doesn't make sense, that means that you didn't log in yet.  Fixes #1239 by returning `{"result": None, "message": "error goes here"}` instead of `{"result": True/False, "message": "error goes here"}`.  Server error

Err: UnicodeDecodeError: 'utf8' codec can't decode byte 0xc5 in position 219110: invalid continuation byte in UiServer.py line 95 > UiRequest.py line 130 > MutePlugin.py line 138 > UiRequest.py line 299 > UiRequest.py line 394 > UiRequest.py line 249 > utf_8.py line 16

Please report it if you think this an error.

 Server error

Err: UnicodeDecodeError: 'utf8' codec can't decode byte 0xc5 in position 219110: invalid continuation byte in UiServer.py line 95 > UiRequest.py line 130 > MutePlugin.py line 138 > UiRequest.py line 299 > UiRequest.py line 394 > UiRequest.py line 249 > utf_8.py line 16

Please report it if you think this an error.

Details:

{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate, sdch, br", 
    "HTTP_ACCEPT_LANGUAGE": "zh-CN,zh;q=0.8", 
    "HTTP_CONNECTION": "keep-alive", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.98 Safari/537.36 LBBROWSER", 
    "PATH_INFO": "/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
    "QUERY_STRING": "", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "61080", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "2013-20160921PM", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.2 Python/2.7", 
    "arguments": {
        "action": "main", 
        "autodownload_bigfile_size_limit": 1, 
        "batch": false, 
        "bind": null, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": "type %s | tools\\coffee\\coffee.cmd", 
        "config_file": "C:/Users/Administrator/Desktop/ZeroNet-win-dist/zeronet.conf", 
        "connected_limit": 8, 
        "data_dir": "C:/Users/Administrator/Desktop/ZeroNet-win-dist/data", 
        "db_mode": "speed", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "download_optional": "manual", 
        "end": true, 
        "file_size_limit": 10, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "fix_float_decimals": false, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "ip_local": [
            "127.0.0.1"
        ], 
        "keep_ssl_cert": false, 
        "language": "zh", 
        "log_dir": "C:/Users/Administrator/Desktop/ZeroNet-win-dist/log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": false, 
        "open_browser": "default_browser", 
        "optional_limit": "10%", 
        "pin_bigfile": 20, 
        "proxy": null, 
        "silent": false, 
        "size_limit": 10, 
        "stack_size": null, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_hs_limit": 10, 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://zero.booth.moe#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.opentrackr.org:1337/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_host": null, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "updatesite": "1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp", 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false, 
        "workers": 5
    }, 
    "plugins": [
        "AnnounceZero", 
        "Bigfile", 
        "Cors", 
        "CryptMessage", 
        "FilePack", 
        "MergerSite", 
        "Mute", 
        "Newsfeed", 
        "OptionalManager", 
        "PeerDb", 
        "Sidebar", 
        "Stats", 
        "TranslateSite", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.2.1", 
    "version_python": "2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 20:42:59) [MSC v.1500 32 bit (Intel)]", 
    "version_zeronet": "0.6.0 r3177", 
    "wsgi.url_scheme": "http"
}

System window7 X64

zeronet is the latest version 

[wrapper.zip](https://github.com/HelloZeroNet/ZeroNet/files/1597675/wrapper.zip)
 How to solve this problem The problem is solved, the virus caused HTML file error Finally we can close these duplicates. #523, #814, #920, #1132, #1219

The cause is a computer virus. @kofzhanganguo where did you download ZeroNet from?  ### Step 1: Please describe your environment

  * ZeroNet version: 0.6.0 (rev 3178)
  * Operating system: Windows 10
  * Web browser: Chrome
  * Tor status: disabled
  * Opened port: yes
  * Special configuration: none

### Step 2: Describe the problem:

Ranged requests like `0-100000` when file size is `100` only never end. Moreover, after a couple of such requests even normal requests fail.

#### Steps to reproduce:

  1. Create new site
  2. Copy file `00changelog.d` and copy it to site root: [00changelog.zip](https://github.com/HelloZeroNet/ZeroNet/files/1595079/00changelog.zip)
  3. Open DevTools
  4. Define function:
```javascript
function ajax(size) {
	page.cmd("wrapperGetAjaxKey", [], ajax => {
		let xhr = new XMLHttpRequest;
		xhr.open("GET", "00changelog.d?ajax_key=" + ajax);
		xhr.responseType = "arraybuffer";
		xhr.setRequestHeader("Range", "bytes=0-" + size);
		xhr.onload = e => {
			if(xhr.status != 206) {
				console.error(xhr.status);
			} else {
				console.log("Loaded");
			}
		};
		xhr.onreadystatechange = () => {
			console.log("State", xhr.readyState);
		};
		xhr.onerror = e => {
			console.error(e);
		};
		console.log("Begin loading");
		xhr.send(null);
	});
}
```
Basically this will send a range request.

Now most important:
1. Send `ajax(50)`
2. Send `ajax(1000)` a couple of times (about 5 is enough for me)
3. Send `ajax(50)`

#### Observed Results:

1.
```
Begin loading
State 2
State 3
Loaded
```
2.
```
Begin loading
State 2
State 3
```
3.
```
Begin loading
State 2
State 3
```

Notice that data was sent (`State 3`), though even normal request didn't end (`Loaded`).

#### Expected Results:

1.
```
Begin loading
State 2
State 3
Loaded
```
2.
```
Begin loading
State 2
State 3
Loaded
```
3.
```
Begin loading
State 2
State 3
Loaded
``` @HelloZeroNet I could create a PR for this, but I don't understand why this happens at all.  Closes #1229 What final result looks like:
![image](https://user-images.githubusercontent.com/4098042/34455894-a9d8bc32-ed4e-11e7-91f8-26b337cbc41a.png)

![image](https://user-images.githubusercontent.com/4098042/34455898-b1f38fbe-ed4e-11e7-8ee8-5d54187b3385.png)
 Looks like the `src/Test/TestRateLimit.py::TestRateLimit::testCall FAILED                [ 49%]` test failed. Is this important? @krixano lemme check. That check is about how much time some op takes. So that's not important in this case as I didn't edit that part of code. Using the same dropdown code as ZeroHello might be a good idea, and look cleaner. It does use a â‹® instead of an arrow but that could work as well. @anoadragon453 I tried to find other buttons which look the same way, but didn't manage to do that. So maybe a dropdown would be better, right. Though I am not sure what would be better. @HelloZeroNet, do you allow me to bring yet-another-library to Sidebar plugin? @HelloZeroNet Did you get a letter from `saketjoshiiit [at] gmail [dot] com`? Kinda spam? @HelloZeroNet I'll use that library then. @HelloZeroNet 

> Hello,
> 
> I am a university researcher working on an empirical study of software
> projects. A part of my study concerns projects with high release
> rates.I noticed that the software repository HelloZeroNet/ZeroNet on
> Github has a very fast release cycle. If you couple quickly answer a
> couple of questions below and reply to me at the earliest, that would
> be very helpful.
> 
> Q1. Would you say the repository development is in a sense 'agile',
> i.e. is rapid development being done?
> Q2. What kind of a project is this? e.g (Web application, driver, e.t.c)
> Q3. Is there any reason for rapid releases? i.e. do you have
> auto-release set, are changes done in between releases, e.t.c
> 
> Both, a brief reply to the questions, and if you wish any other
> comments are welcome.
> Also, it would be helpful if you could mention the repository name in
> your reply for my convenience.
> 
> Thank you,
> Saket Joshi @HelloZeroNet Updated

![image](https://user-images.githubusercontent.com/16370781/34463151-1db02df0-ee64-11e7-9370-bca652e81918.png) @HelloZeroNet Sorry, can we merge this?  I am not sure if this is so important, but using `:params` in `NewsFeed` queries proved it is useful.

So now the following code will work:

```javascript
page.cmd("dbQuery", [
    "SELECT * FROM posts WHERE posts.reply_to IN :replies AND posts.reply_to_json IN :replies_json"
], {
    replies: ["1", "2"],
    replies_json: ["3", "4"]
});
```

Code from this PR transforms above SQL query to:
```sql
SELECT * FROM posts WHERE posts.reply_to IN :replies__0, :replies__1 AND posts.reply_to_json IN :replies_json__0, :replies_json__1
```
...and placeholders to:
```
{
    replies__0: "1",
    replies__1: "2",
    replies_json__0: "3",
    replies_json__1: "4"
}
```

---

I know you can use `?` right now, but that doesn't work with complex queries.  ### Step 1: Please describe your environment

  * ZeroNet version: 0.6.0 rev3161
  * Operating system: Mac OS Sierra
  * Web browser: Tor Browser
  * Tor status: always
  * Opened port: no
  * Special configuration: none

### Step 2: Describe the problem:
Sometimes I get this message repeatedly when I look at Tor in terminal
```
[warn] Socks version -125 not recognized. (Tor is not an http proxy.)
```
When this happens, ZeroNet begins to hang and stops updating sites.  If I look at the stats page I usually see a bunch of nodes where connection status under `open` is `n/a`.  Some nodes have a larger ping than normal, but eventually most nodes end up with a `n/a` state after a while.

#### Steps to reproduce:
Sometimes this happens the moment I start ZeroNet, while other times it happens after a while.
It seems to happen randomly, and I've experienced this problem in earlier versions.
When I try to restart ZeroNet after this happens to fix it, the same problem usually happens again. same problem with last update... please fix  ### Step 1: Please describe your environment

  * ZeroNet version: 0.6.0 rev3177
  * Operating system: Win.10 64b
  * Web browser: Firefox 57.0.2 (64-bit)
  * Tor status: always
  * Opened port: not opened anything
  * Special configuration: 5400 RPM HDD

### Step 2: Describe the problem:

Hello, always i open or refresh ZeroHello page (in Firefox or Tor browser), it takes 2-3 minutes for the white/search section of the ZeroHello page to load. The dark section on the left (list of the sites) loads quickly. Then it shows example: "from 10 sites in 180.42s"

http://127.0.0.1:43110/Stats shows:
Db:
- 50.586s: data/content.db
- 226.250s: data/1FREEMLT3GSta6TynuAC9EWM5mXCnrxkiu/data/zeroblog.db
- 226.248s: data/1TaLkFrMwvbNsooF4ioKAY9EuxTBTjipT/data/users/zerotalk.db
- 226.241s: data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/data/zeroblog.db
- 226.239s: data/1MALTALKxyXgvWSqZkcdjsh4LUqqL2bKFe/data/users/zerotalk.db
- 265.914s: data/1PjYBsgsWAfsPE4sQnSNg1t31CNwW4DZWw/data/zeroblog.db
- 265.904s: data/1GitLiXB6t5r8vuU2zC6a8GYj9ME6HMQ4t/merged-GitCenter/GitCenter.db
- 265.900s: data/1J1c7eML6uMwDU4uiKbKRxoqxGP6WMFMvb/merged-CDN/zeroverse.db
- 265.853s: data/186THqMWuptrZxq1rxzpguAivK3Bs6z84o/data/users/zerotalk.db
- 265.848s: data/1Kp5xdjQyrPth5mEJsn6NDBKZxcaeYz86N/data/zeroblog.db
- 1484.691s: data/1MeFqFfFFGQfa1J3gJyYYUvb5Lksczq7nH/merged-ZeroMe/ZeroMe.db
- 54073.490s: data/1PLAYgDQboKojowD3kwdb3CtWmWaokXvfp/data/play.db

Task manager and System explorer apps do not shows HDD being overloaded during ZeroHello load..

I am sorry if this issue is known. @HelloZeroNet 

> click on "from xx sites in x.xx s"

I tried it in Firefox and TorBrowser but it does not show anything, i tried to refresh page and restart zeronet, but do not show, it shown only in case i not clicked it after slow start -> tried to search something and then clicked it and then it show quickly example: "181 results from 18 sites in 0.41s", but i assume You want to see results when it loads slow (2-3 minutes), but there it do not show anything when i click it. waited a few minutes.
Here i pasted the log of the zeronet, it shows some errors: https://pastebin.com/YfKh3293 (replace "9" by "0")

When i click it "from xx sites in x.xx s" and then try to search something, it do not reacts, no animation wheel of searching, no results.

When i refresh page, wait 3 minutes until newsfeed load, then click text "from xx sites in x.xx s"

nothing happens, so i click "Files" tab on the top, only one site appear:

ZeroTalk15.59 MB + 0.00 KBOptional â™¡ 0.1 â‹°  8.53 MB â‹±  89.53 MB

So i click "Sites" tab and nothing happen, it do not switch to sites, its like frozen. @HelloZeroNet 

In Firefox, i did F12, "Console tab" found error:

> Error: div.FeedList.search had a div child added, but there is now more than one. You must add unique key properties to make them distinguishable. all.js:443:35
	checkDistinguishable http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:443:35
	updateChildren http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:487:21
	updateDom http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:588:23
	updateChildren http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:471:31
	updateDom http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:588:23
	update http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:606:17
	doRender http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:837:17

Line 443 is:

>                            throw new Error(parentVNode.vnodeSelector + ' had a ' + childNode.vnodeSelector + ' child ' + 'added, but there is now more than one. You must add unique key properties to make them distinguishable.');

When i reloaded ZeroHello page, the only error seen in Firefox Developer console was:

> The connection to ws://127.0.0.1:43110/Websocket?wrapper_key=350c7***longstringhere*** was interrupted while the page was loading. all.js:69:16

Line 69 is:

>       this.ws = new WebSocket(this.url);

When i clicked "from xx sites in x.xx s" then this error appeared in Developer console:

> TypeError: site is undefined
[Learn More]
all.js:2671:11
FeedList.prototype.renderSearchStat
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2671:11
bind/<
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2253:56
map self-hosted:297:17 FeedList.prototype.render
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2748:92
bind/<
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2253:56
doRender
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:836:36

Then i clicked "Files" tab on ZeroHello and then "Sites" tab and another error appeared in Dev. console:

> TypeError: site is undefined
[Learn More]
all.js:2671:11
FeedList.prototype.renderSearchStat
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2671:11
bind/<
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2253:56
map self-hosted:297:17 FeedList.prototype.render
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2748:92
bind/<
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2253:56
replace
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:872:29
ZeroHello.prototype.setProjectorMode
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:4738:9
Head.prototype.handleModeClick
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:3477:9
bind/<
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:3278:56
exports.createProjector/projectionOptions.eventHandlerInterceptor/<
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:820:24

and i am stuck at "sites" tab while i see files, not sites @HelloZeroNet 
I have not found file "FeedList.coffee" (which you apparently modified) in my zeronet directories using Windows search. So i can't modify the file on my computer.
I tried to click three dots on ZeroHello click version and click Update button, waited a minute, then clicked windows zeronet tray icon and selected to quit the app. After start, it took 200 seconds to load newsfeed on zeronet page. When i clicked the "from xx sites in x.xx s" on the ZeroHello, the Developer console of the Firefox shown error

> TypeError: site is undefined
[Learn More]
all.js:2682:11
FeedList.prototype.renderSearchStat
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2682:11
bind/<
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2253:56
map self-hosted:297:17 FeedList.prototype.render
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2759:92
bind/<
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2253:56
doRender
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:836:36

Then i click "Files" tab, and then when i click "Sites" tab i see error:

> TypeError: site is undefined
[Learn More]
all.js:2682:11
FeedList.prototype.renderSearchStat
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2682:11
bind/<
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2253:56
map self-hosted:297:17 FeedList.prototype.render
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2759:92
bind/<
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:2253:56
replace
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:872:29
ZeroHello.prototype.addRenderer
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:4798:7
ZeroHello.prototype.setProjectorMode
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:4821:9
ZeroHello.prototype.route
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:4876:14
ZeroHello.prototype.setUrl
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:4909:7
ZeroHello.prototype.handleLinkClick
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:4924:9
bind/<
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:4765:56
exports.createProjector/projectionOptions.eventHandlerInterceptor/<
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/js/all.js:820:24

but site is not stuck like before, but it redirects properly to default ZeroHello where is site list, but i still have to wait couple of minutes until newsfeed loads. This time it took: "from 13 sites in 328.39s" Thank you

btw., mentioned error:

> The connection to ws://127.0.0.1:43110/Websocket?wrapper_key=350c7***longstringhere*** was interrupted while the page was loading. all.js:69:16

continue to show up.
 @HelloZeroNet

I did that and Quit & Start Zeronet, waited for newsfeed to load (90s) and then copied debug.log file in Zeronet log directory contents. [Here it is](https://www.protectedtext.com/934856586256) (pw: 489) i do not know what to look for exactly, file is huge.
Pls let me know what else i can do to find cause. Thank you @HelloZeroNet 
I think that you fixed this issue. The newsfeed loads under 1 second now and when i click thru the ZeroHello interface (files, sites, "from xx sites in x.xx s"), no error appears in Firefox developer console and all seem to work. Thank you  Windows 10, latest ZeroNet, http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/
"Files" tab i see some files are "PINNED" and i see no explanation what that means and what happen if i UNPIN it. Thank You `pinned` files (you can only pin big and optional files) aren't deleted by automatical garbage collector. When you download a file, you automatically pin it. If you unpin it, it will be removed soon, but that's all.  I think Zeronet conforms with the Open Technology Fund's "Internet Freedom Fund" and has a good chance to receive funding. 
https://www.opentech.fund/requests/internet-freedom-fund
The deadline is 1st of January.

What do you think about that, @HelloZeroNet? The deadline is in 24 hours. @shortcutme If not started, you should start writing the application right now. What was the result? Did you get a reply?  
  * ZeroNet version: 0.6.0(rev3177
  * Operating system: Android 5.1
  * Web browser: Chrome 62.0.3202.84 (32bit)
  * Tor status: not available
  * Opened port: yes
  * Special configuration: 

Describe the problem:
Internal error: TypeError. actionSiteSetLimit() takes exactly 3 arguments (2 given) 
UiWebsocket.py line 81 > UiWebsocket.py line 256 > UiWebsocket.py line 333 > UiWebsocket.py line 260 

#### Steps to reproduce:
This may be hard to reproduce, I've only seen it twice, usually when downloading a site.

#### Observed Results:
![screenshot_2017-12-23-23-24-31-64](https://user-images.githubusercontent.com/24760218/34320815-a019db70-e83c-11e7-99b3-456c3d2418a2.png
[debug-last.log](https://github.com/HelloZeroNet/ZeroNet/files/1584248/debug-last.log)
[debug.log](https://github.com/HelloZeroNet/ZeroNet/files/1584249/debug.log)


#### Expected Results:
 @HelloZeroNet I hope you wouldn't mind, it's better to say:
"Did it happen after you clicked the "Set limit to xx MB" button?"
I hope to giveback by sharing my English knowledge. However if you don't want it just tell me once. @HelloZeroNet Yes, but it always happens a few times in the beginning.
By the way, I am a Chinese and I am not good at English, so I have to use Chinese machine translation to communicate with you. @JumpCricket I didn't say that to you my friend. @Ornataweaver  I know, I just worry that some people can't understand the meaning of English after translation, after all machine translation is sometimes very strange. @JumpCricket Your writing is very clear. I understand what you mean easily.  Does not work
`target="blank"`
Opens corrupted sites Yes, you have to use the `wrapperOpenWindow`-command, for example like follows:
```
function openNewTab(url) {
    page.cmd("wrapperOpenWindow", [url, "_blank", ""]);
    return false;
}
```
`page` being your ZeroFrame-extend.

This is also documented in the docs: http://zeronet.readthedocs.io/en/latest/site_development/zeroframe_api_reference/#wrapperopenwindow-url-target-specs @HelloZeroNet Perhaps it's worth adding this code as a standard for target = "blank" +1 to the idea of adding it as a standard.   ZeroNet version: 0.6.0

Unfortunately, because I set wrong time, I signed my files with `"modified": 1513904603` and published, but true time is 1513865595.
Therefore, before true world reach the wrong time, I can't publish anything. If publish successfully, it will rollback after some time.  Something that would be really nice is a way to send notifications from a zite once something updates to the current user, either when a new blog post was released, a new comment or a new video.

This could be implemented through the existing Web Notifications API globally for ZeroNet with a ZeroFrame API allowing zites to register for notifications, and a settings menu for granular control on which zites are allowed to send notifications. Or just have it all done through the existing information stream that ZeroHello generates.

This would allow for real-time chat where one wouldn't have to manually check for new updates, and could hook into zites like ZeroHello that could notify you whenever a new item was dropped into the Following feed.

What do you think, is it possible? I was just sitting in my bed, decided to check ZeroHello and realized I got a response to a comment I made 30m ago which I missed. It would be nice to have some sort of push notifications system is all :)  http://127.0.0.1:43110/Talk.ZeroNetwork.bit/?Topic:1509875191_13aB79mzuRLgDYzQthn9wzycjw77WyDXh6/Advanced+Usage+Immutable+Content+Trusted+Timestamp+Permission+Control

1. I don't allow user to edit post content after he posted
2. I don't allow user fake time timestamp
3. I want assign someone as admin to manage part of site, not whole site

How do these in ZeroNet?
I am afraid file-based can't do these, ZeroNet should be (database) row-based.  [Discussion on ZeroTalk](http://127.0.0.1:43110/Talk.ZeroNetwork.bit/?Topic:1513428479_1EQuGEmS5J8SQ1xA6MM9KfubBb71uxiLvs/Feature+request+Proxy+Submit+new+site+for+review)

Currently we can allow users to add any site to a ZeroProxy, or allow none at all. It would be nice if there were some middle-ground where we could allow users to suggest a site, and the ZeroProxy owner could prune through the list and allow ones they deem suitable.

A button such as 'Suggest Proxy Add Site' or something similar to new pages which haven't been downloaded yet by a `no_new_sites` proxy would be very welcome.

Thanks! That's a decent idea, yeah. Any way to link that from the "new sites not allowed" page?

On December 18, 2017 2:04:28 AM PST, ZeroNet <notifications@github.com> wrote:
>I would recomment to create a ZeroTalk clone for the proxy and the user
>would use it for submission to the admin.
>
>-- 
>You are receiving this because you authored the thread.
>Reply to this email directly or view it on GitHub:
>https://github.com/HelloZeroNet/ZeroNet/issues/1209#issuecomment-352380385
 @anoadragon453 Change line `47` of file `plugins/Multiuser/MultiuserPlugin.py`.

`Adding new sites disabled on this proxy` is text that gets printed. Replace it with whatever you want (no HTML). Cool, that should do it then, thanks guys!

On December 18, 2017 9:13:53 AM PST, Ivanq <notifications@github.com> wrote:
>@anoadragon453 Change line `47` of file
>`plugins/Multiuser/MultiuserPlugin.py`.
>
>`Adding new sites disabled on this proxy` is text that gets printed.
>Replace it with whatever you want (no HTML).
>
>-- 
>You are receiving this because you were mentioned.
>Reply to this email directly or view it on GitHub:
>https://github.com/HelloZeroNet/ZeroNet/issues/1209#issuecomment-352492223
  ### Step 1: Please describe your environment

  * ZeroNet version: 0.6.0
  * Operating system: Windows 7
  * Web browser: Chrome Version 62.0.3202.94
  * Tor status: waiting
  * Opened port: no
  * Special configuration: ____

### Step 2: Describe the problem:
I can't submit messages containing Chinese characters. Whenever I do so I get the prompt "Message submit failed! Parsing parameters... Please try again later". This only occurs on ZeroBoard though.

#### Steps to reproduce:

  1. _____
  2. _____
  3. _____

#### Observed Results:

  * What happened? This could be a screenshot, a description, log output (you can send log/debug.log file to hello@zeronet.io if necessary), etc.

#### Expected Results:

  * What did you expect to happen?
 Most Chinese messages on ZeroBoard are SHIT politics. @funny110 @HaoyeTang this is an issue tracker, not a place to talk about others' politics. AFAIK `Message submit failed! Parsing parameters... Please try again later` means `you post too much`  I believe that you need to make an API translator for websites.
This is a very convenient function but in the zeronet translator from the browser does not work.
I very often use an interpreter, it is also part of anonymity. I believe you are asking about being able to translate the contents of an entire ZeroNet page using online APIs.

This would be useful, although should certainly be an opt-in thing, as it would require sending the site address to an online server and having it send back the translated HTML.

Essentially a ZeroNet site would have to be created that can read other sites and send the HTML data off to Google APIs to be translated. I do not believe any changes to the core infrastructure would be required (and should not be done as this relies on 3rd party, proprietary services).

If there is a JS or Python translation library that could do it locally, then that'd be another story. 0net supports plugins, correct? I assume it should be possible to supply this functionality as a 3rd-party plugin. Besides, I don't think many people really want external integrations in the main codebase.

~~Another option would be to allow the site to supply its own translation files listed in something like a `translation.json` file, which could be chosen from using the 0 menu. It could even be possible to allow user-supplied translations as well, splitting up the burden of translation. That's functionality I would _love_ to see in the main codebase.~~ This is apparently already a thing. I like the idea of anoadragon453
Essentially a ZeroNet site would have to be created that can read other sites and send the HTML data off to Google APIs to be translated.   ### Step 1: Please describe your environment

  * ZeroNet version: 0.6.0
  * Operating system: Linux
  * Web browser: N/A
  * Tor status: N/A
  * Opened port: N/A

### Step 2: Describe the problem:

The `ui_host` config parameter (and possibly other parameters) is not able to handle multiple options when specified within the config file, whereas you can do so on the command line.

Config file:
```
# Doesn't work at all
ui_host sub1.zeronet.io, sub2.zeronet.io

# Doesn't work at all
ui_host sub1.zeronet.io sub2.zeronet.io

# Doesn't work, only records one of the domains
ui_host sub1.zeronet.io
ui_host sub2.zeronet.io
```

Specifying on the command line:

```
# Does work!
python ./zeronet.py --ui_host sub1.zeronet.io sub2.zeronet.io
```

So it is a bug with the config file loading code. `argparse`, which parses from the command line, works fine.

I ran into this while trying to have a single ZeroNet daemon act as a ZeroProxy coming from two different subdomains of the same website. Running the daemon with the options on the command line works but it would be ideal if it was in the config file so it wouldn't have to be retyped/remembered all the time :)
 Yep, working!

As an aside, searching zeronet.readthedocs.io for "config" shows no results, but I'm sure config is mentioned at least once in the docs...? Why is their search so terrible?  Hi, I'm interested in the ability to move iframe from zeronet to support fullscreen video.

Is it possible to add these configurations?
```
allowfullscreen="true"
webkitallowfullscreen="true"
mozallowfullscreen="true"
```
I would like to see fullscreen was normal and not by reference as it is now. @HelloZeroNet This function is similar to F11
There is a more modern version that I could embed in <video> </ video>? @HelloZeroNet Than it threatens if allowfullscreen function will be permanently on? @HelloZeroNet Thankee!  Just a quick question. Is port 43110 just used for accessing the web sites? As in, can I just disable or block this port, keeping 15441 open for supporting zeronet as a node. Or truly does a site have to be accessed from the individual node for it to be pulled and peer distributed?

Thanks DB  ### Environment:

  * ZeroNet version: 0.6.0 (rev. 3146)
  * Operating system: Raspbian & openSUSE Linux
  * Web browser: Chromium (Google Chrome)
  * Tor status: disabled
  * Opened port: yes


### The problem:

The 3D globe at the zite settings panel 
depends on 3D support(probably WebGL), but 
the WebGL, GPU support, is not available at all browsers
and that makes the ZeroNet much less portable.

#### Steps to reproduce:

  1. Open the ZeroNet GUI in some non-standard browser, like 
http://www.midori-browser.org/
or
https://rekonq.kde.org/
or 
https://konqueror.org/     

  2. Try to open the zite settings panel by sliding the zero icon.


#### Observed Results:

Either the zite does not load at all or the zite loads, but 
the settings panel is empty, blank.

#### Wishes:

The JavaScript of the ZeroNet GUI should first
check, whether 3D/GPU-s are supported and 
load the 3D Earth only, if the WebGL/GPU support
is available. If the 3D acceleration is not available, 
the classical 2D "World map" with color-coded 
height might be used, the way geography related
paper-books used to depict mountain range heights
on maps.

http://vterrain.org/Elevation/NOAA_Globe_680.jpg
(archival copy: https://archive.fo/QFJ6k )
 I do not know, how exactly You tend/prefer to work with JavaScript code, but 
I have some JavaScript experience from AN ERA, WHEN THERE WERE
NO FANCY DEBUGGERS embedded to web browsers, specially the 
nasty Microsoft Internet Explorer. To cope with the situation, I came up
with a solution, where I wrapped the bodies of ALL FUNCTIONS of 
MY JavaScript LIBRARY into a try-catch clauses and 
at the catch side I threw an exception that contained a GUID as part of the 
error message. Each error message had its own GUID that was unique
within the whole project.

To the start of the function body I placed tests, input verification,
that can be partly disabled in production, but that thoroughly
CHECKED EVERYTHING that I was able to think of at that code region, 
WITHOUT WORRYING ABOUT PERFORMANCE, because 
most of the thorough tests were enabled at debug mode only.
Style example:

https://github.com/martinvahi/raudrohi/blob/master/src/devel/raudrohi_lang.js#L321

That way, if the JavaScript crashed or had errors, then 
I would have a stack trace of GUIDs at the web browser's 
JavaScript console. To work with that "stack trace", I created
a plugin/tool for the KomodoEdit 

https://www.activestate.com/komodo-edit

https://github.com/martinvahi/mmmv_devel_tools/tree/master/src/mmmv_devel_tools/GUID_trace/src/JumpGUID/src/IDE_drivers/www_openkomodo_com/v_8_0_0

I don't remember everything exactly any more, but the work
process was that I manually copy-pasted the 
"stacktrace" of GUIDS from the JavaScript console of the
web browser to a text file, which was parsed by the KomodEdit
tool/plugin and I was literally able to move up and down within the
stack trace of GUIDs so that at a push of an arrow key or
an arrow key replacement key combination 
on my keyboard the "cursor" within the stack of GUIDs moved
and at every move the KomodoEdit opened the file and line
of the development JavaScript file, where the GUID resided.

Basically, the result was that I had an interactive debugger 
like experience, except that I was able to move both directions,
forwards and backwards, in stead of single lines my "step size" was
one function and in stead of just seeing the code, I was able
to directly EDIT the DEVELOPMENT SOURCE. 

The beauty of such a solution is that if the JavaScript is minimized
or I get a stack trace of GUIDs from the client's computer, then 
I can debug and look at the situation at my own computer, calmly, 
at my own pace. Another beauty of that solution is that the 
solution is totally PROGRAMMING LANGUAGE AGNOSTIC.
If all of my source codes have unique GUIDs at all error messages, 
at all projects that I have ever done, then I can create a folder that
contains symbolic links to the source of all of my projects and then
grep the GUID from that folder. The GUIDs are unique without 
much effort: I just copy-paste the code/text with some existing GUID
and then run 

https://github.com/martinvahi/mmmv_devel_tools/blob/master/src/mmmv_devel_tools/GUID_trace/src/UpGUID/COMMENTS.txt

Again, I have that tool integrated to my IDE scripts/settings, Vim, JetBrains, etc.
So all it takes, if the environment has been properly set up, is one key combination
and the tool updates all GUIDs by using regexes and some other tricks that
are described at:

https://github.com/martinvahi/mmmv_devel_tools/blob/master/src/bonnet/lib/kibuvits_ruby_library/src/include/kibuvits_str.rb#L492

id est using only regex is not safe enough.
Another thing that helps with JavaScript is 
some form of JavaScript console. I have used 

https://yuilibrary.com/yui/docs/console/

But, of course, it's easy for me to speak here. Actually, 
what regards to user interfaces, then I currently do not
have proper, usable, JavaScript code to offer, but 
my JavaScript project took place so early that I did not 
have the opportunity to download the various fancy 
JavaScript widget libraries, so I had to develop my own.
And I did. The code is an old, unusable mess
https://technology.softf1.com/raudrohi/2013/09_04_v_25/
(I have an upgraded, but unfinished, unpublished version @ my computer)
but I did get the architecture right, after a lot of tedious work
and I tried to document it by writing a cleaner version of the ideas to:

https://longterm.softf1.com/specifications/rastclsp_t1/

I'm not aware that any other widget library has that kind of an architecture.
The main benefit of it is that it moves a lot of the code from the
application code to the library(read: reusable) code region and 
that a widget is a CONTAINER that does not need a graphical 
representation. Widgets MAY have a graphical representation, but
menus might be also sound menus, like the ones at phone services.
That spec is a result of multiple projects. The earliest of them was
not even JavaScript, but one client/paid project that was written in Java. 
Well, one way or the other, I currently do not have any code to offer that
works with that spec, but the implementation of that spec, mainly in the 
form of my Raudrohi JavaScript library upgrade, is my next step at the 
(proper) GUI front.

The reason I write all of that here is to offer You some inspiration. 
I've been in trouble with the JavaScript myself and may be at least
some of my old JavaScript development tools and methods will help You.

Thank You for reading my comment. I believe that this problem of browsers and definitely not ZeroNet
Now almost 2018 and they do not support WebGL
ZeroNet this future, it does not need outdated technology
And accordingly to spend for this time there is no sense, let these obsolete browsers themselves do something for ZeroNet > Now almost 2018 and they do not support WebGL

The WebGL depends on GPU, which is accessible to browsers only, if there are 

    DRIVERS!!!!!!!

available for the GPU on a

    GIVEN OPERATING SYSTEM!!!

that has been ported to a 

    GIVEN HARDWARE!!!!

The rest of the contemplation is about what is the design philosophy of the ZeroNet. For example, one philosophical aspect of the ZeroNet is the choice, whether ZeroNet documents, forums, blogs, should be visible 100 years from now, like the text documents from the 80-ties are readable with year 2017 computers and like HTML-pages from the 90-ties are visible at the 

https://archive.org/

or is it OK for the ZeroNet to be like the Java Applets based web pages that are impossible to use/see in 2017, because Java Applets are de facto not supported by 2017 web browsers, despite all the advances in hardware. So far the 3D technologies for the web browsers have a 

    TRULY BAD TRACK RECORD.

Apart from fancier rendering, the 2017 3D web technologies, the 

https://www.x3dom.org/
and the 
https://www.khronos.org/webgl/

do not offer absolutely ANYTHING NEW. I have not noticed anything substantial that the Java Applets 3D capabilities or the VRML did not offer. The VRML demonstrated that it is not enough for the technology to be totally open, in a form of an open standard that is supported by MULTIPLE INDEPENDENT COMPANIES. I repeat: an open standard and a multitude of independent money streams from multiple companies DID NOT SAVE THE VRML. The 2017 3D web technologies, 

the 
https://www.x3dom.org/
and the 
https://www.khronos.org/webgl/

compete with each other and they do not have the freelancer based developer community to keep them from the same faith that the VRML had. In another words, money is not going to solve it, money DID NOT SAVE THE VRML, because the availability of money IS ALWAYS TEMPORARY. The moment Google Chrome and Mozilla, which are both corporate projects with HUGE money streams, dump the browser 3D support, just like they both dumped the Java Applets, the WebGL and the x3dom will be in the history trash can, right next to the VRML and the Java Applets and the Microsoft Silverlight and the Adobe Flash. Making 3D acceleration a  dependency for the ZeroNet GUI makes the ZeroNet GUI less portable and risks with making the ZeroNet GUI unavailable in the future. Examples of operating systems that do not have a proper set of 3D drivers:

* The OpenSolaris forks: https://wiki.illumos.org/display/illumos/illumos+Home
* https://www.dragonflybsd.org/
* http://www.openbsd.org/
* http://minix3.org/ 
* Probably also the https://www.haiku-os.org/
* I do not know for sure, but I would not bet that the ReactOS has a proper set of 3D drivers: http://www.reactos.com/
* https://www.gnu.org/s/hurd/hurd.html
* http://www.vitanuova.com/inferno/screenshots.html

An example of hardware that has a thoroughly documented GPU, but lacks proper 3D drivers, is the Raspberry Pi:

http://www.raspberryconnect.com/gamessoftware/item/314-trying_out_opengl_on_raspberry_pi_3

https://www.raspberrypi.org/documentation/hardware/raspberrypi/
(Raspberry Pi 3 GPU is the same as Raspberry Pi B+ GPU)

There are a lot of Raspberry Pi clones, competitors, just like the former IBM PC had clones that ultimately took over the market. Those clones might have very different GPUs and a very varying level of 3D driver support. The most exhaustive list of Raspberry Pi competitors that I'm aware of, is:

https://www.board-db.org/

but some most prominent competitors are:

http://beagleboard.org/
http://www.orangepi.org/
http://www.banana-pi.org/
http://www.marsboard.com/
http://cubieboard.org/
ORDROID: http://www.hardkernel.com/main/main.php
https://www.pine64.org/
https://getchip.com/
RiotBoard: https://www.element14.com/community/community/designcenter/single-board-computers/riotboard

The Raspberry Pi like computers are specially relevant due to the fact that the Intel and AMD have formed a cartel that holds monopoly not by free market rules, but by LAWYERS. The 386 CPU patents have expired, but generally speaking, with a few small exceptions like the Via Technologies, nobody is allowed to create or even emulate x86 CPUs, although, Microsoft with its cloud services probably gives it a try:

https://www.theregister.co.uk/2017/06/09/intel_sends_arm_a_shot_across_bow/
(archival copy: https://archive.is/chFKb )

Not only does the Intel-AMD cartel have a lawyers based monopoly, but, as with all monopolistic vendors, they do not work on the quality of their products, preferring cutting production costs to doing a proper job. In the case of the Intel and AMD the quality problems are in the form of security problems, which are partly described at the links of my forum post at

https://groups.google.com/forum/#!topic/minix3/WhTHQX6f9VM
(archival copy: https://archive.is/q06qT )

That is to say, the Raspberry Pi like computers ARE VERY IMPORTANT COMPETITORS that MUST BE SUPPORTED and as long as there is no "generic 3D hardware" interface, like there is "generic VGA hardware" interface, the Raspberry Pi like computers will probably lack proper 3D support even if they have openly and properly documented GPUs.

Thank You for reading my post.
  I want to use sub-page reverse proxy zeronet somewhere. What should I do?

For example: Client Request https://www.a.com/zeronet/
The actual visit is on the server zeronet (127.0.0.1:43110/zLSmz1ekvt1MpCPMKeJPjgmk96fUYVr8WJ fictitious address)


nginx configurationï¼š
This will jump to the home page ( https://www.a.com/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D )
```
location /uid/ {
      proxy_pass http://127.0.0.1:43110/zLSmz1ekvt1MpCPMKeJPjgmk96fUYVr8WJ/; #fictitiou address
      proxy_set_header Host $host;
      proxy_http_version 1.1;
      proxy_read_timeout 1h;
      proxy_set_header Upgrade $http_upgrade;
      proxy_set_header Connection "upgrade";
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        } 
```
  ### Step 1: Please describe your environment

  * ZeroNet version: 0.6.0
  * Operating system: NixOS

### Step 2: Describe the problem:

Trying to package zeronet, but cannot start as there is no `zeronet.conf` and there is also no template on how such a file should look like

#### Observed Results:

  * zeronet fails to start:

```
- Starting ZeroNet...
ERROR:root:Unhandled exception: [Errno 30] Read-only file system: 'log'
Traceback (most recent call last):
  File "/nix/store/3p5qvhnblipf23v4326cg9kg0pph459r-zeronet-0.6.0/bin/.zeronet.py-wrapped", line 19, in main
    import main
  File "/nix/store/3p5qvhnblipf23v4326cg9kg0pph459r-zeronet-0.6.0/bin/src/main.py", line 32, in <module>
    os.mkdir(config.log_dir)
OSError: [Errno 30] Read-only file system: 'log'
Traceback (most recent call last):
  File "/nix/store/3p5qvhnblipf23v4326cg9kg0pph459r-zeronet-0.6.0/bin/.zeronet.py-wrapped", line 92, in <module>
    main()
  File "/nix/store/3p5qvhnblipf23v4326cg9kg0pph459r-zeronet-0.6.0/bin/.zeronet.py-wrapped", line 65, in main
    traceback.print_exc(file=open(config.log_dir + "/error.log", "a"))
IOError: [Errno 2] No such file or directory: 'log/error.log'
```

#### Expected Results:

  * zeronet should start
 No, I cannot. I tried, but it failed because there was no config available. Sure, but I still have no idea how such a file should look like and the `--help` argument does not work as long as there is no config available... do you get my point?

No config -> no --help -> No Config.

Why don't you provide an example configuration file in the repository?  ### Step 1: Please describe your environment

  * ZeroNet version: 0.6.0
  * Operating system: windows 10
  * Web browser: Firefox 57
  * Tor status: not
  * Opened port: yes

### Step 2: Describe the problem:

I need to remove my zeronet data files include the site files but keep the site list so that I can re-download them. Is there any way to export all the site I has connected to a list and import them in a new zeronet client? Site list stored in `data/sites.json`, you can just copy this file to a new zeronet client. Sadly it doesn't work. If I removed all the directory (like `data/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D`) but keep `data/sites.json` , the sites won't show up in `ZeroHello` , only the `ZeroHello` and `ZeroName` are there.

![default](https://user-images.githubusercontent.com/16333687/33107678-54b5bd70-cf73-11e7-9002-b864376476de.png)
 I just tried to remove `data/content.db` along with the site directorys, it doesn't work too.  Just set up a ZeroNet proxy as a gateway to a single ZeroNet site accessible through a web address on the clearnet. Everything's working now, and I've cleared all sites besides the one I want to proxy, and have disabled users from adding new ones with the `--multiuser_no_new_sites` option.

Now, all that's left is that the little "Hello, Welcome to ZeroProxy!" popup slides in from the right each time a new user visits the page.

Is it possible to disable this notification? Users do not need to interact with the site so an account is not necessary.

Thank you! It's definitely possible to do by commenting some code in this [file](https://github.com/HelloZeroNet/ZeroNet/blob/ebdb1ed322ee1b3639d914e619a06b47201c71d4/plugins/disabled-Multiuser/MultiuserPlugin.py#L65).
Alternatively you can implement a new option (e.g. `--multiuser_no_greeter`) into this plugin to disable a greeting message and make a pull request. Yes, that sounds like the cleanest option in the long run.

I'll make use of the temporary solution for now and possibly cook up a PR later if someone else doesn't first.

Thanks a bundle! @HelloZeroNet That'd be best I think, yeah.

Any way I could enable automatic anonymous registration with the ability to then like/comment? My site is currently just a cloned ZeroBlog. Having registered and anonymous comments/liking would be ideal. @anoadragon453 Simply create your own certificate authority (https://zeronet.readthedocs.io/en/latest/site_development/cert_authority/) and then publish the private key for it or create a server that returns certificates for random usernames. And then of course add your own ca to the content.json @mkg20001 Cool, will look into that. Thanks. Thank you!  I deployed the 0Net on a Linux remote server and use Nginx to reverse proxy it. I also created the `zeronet.conf` that includes `[global] ui_ip = 0.0.0.0 ui_host = MY.DOMIAN.COM`. I connected to MY.DOMIAN.COM and find this problem: `Connection with UiServer Websocket was lost. Reconnecting...` displayed constantly.
I have referenced [issue #1077 ](https://github.com/HelloZeroNet/ZeroNet/issues/1077), but it does not provide useful solutions.

This is the js log from chrome:
```
[Wrapper] Created!
all.js?rev=3146&lang=en:142 [ZeroWebsocket] Open
all.js?rev=3146&lang=en:142 [ZeroWebsocket] Closed CloseEvent {isTrusted: true, wasClean: false, code: 1006, reason: "", type: "close",Â â€¦}
all.js?rev=3146&lang=en:142 [ZeroWebsocket] Not connected, adding message to queue
all.js?rev=3146&lang=en:142 [ZeroWebsocket] Reconnecting...
all.js?rev=3146&lang=en:142 [ZeroWebsocket] Open
all.js?rev=3146&lang=en:142 [ZeroWebsocket] Closed CloseEvent {isTrusted: true, wasClean: false, code: 1006, reason: "", type: "close",Â â€¦}
all.js?rev=3146&lang=en:142 [ZeroWebsocket] Not connected, adding message to queue
all.js?rev=3146&lang=en:142 [ZeroWebsocket] Reconnecting...
__and the cycle repeated until I close the window__
```

My Nginx Config file (which is similar to [this one](https://gist.github.com/Balancer/fb55b0fa08294503ebf58ec2ac4300a5) except SSL configurations which are workable) :
```
server {
    add_header Strict-Transport-Security max-age=63072000;
    add_header X-Frame-Options DENY;

    server_tokens off;
    listen 443;
    server_name MY.DOMAIN.COM;

    client_max_body_size 10m;

    ssl on;
    ssl_certificate /root/ssl/chained.pem;
    ssl_certificate_key /root/ssl/domain.key;
    ssl_dhparam /root/ssl/dhparam.pem;
    ssl_session_timeout 5m;
    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!3DES:!MD5:!PSK;
    ssl_session_cache shared:SSL:50m;
    ssl_prefer_server_ciphers on;


    location / {
        auth_basic "Protected area:";
        auth_basic_user_file /etc/nginx/.htpasswd;

        proxy_pass        http://127.0.0.1:43110;
        proxy_http_version  1.1;
        proxy_set_header    Host        $host;
        proxy_set_header    X-Real-IP   $remote_addr;
        if_modified_since   before;

        proxy_read_timeout  120s;
        proxy_send_timeout  120s;

        access_log        off;
    }


    location /Websocket {
        proxy_pass http://127.0.0.1:43110;
        proxy_http_version 1.1;
        proxy_read_timeout 1h; #for long live websocket connetion
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

The debug log of ZeroNet:
```
[2017-11-21 06:29:23,622] DEBUG    PluginManager Loading plugin: AnnounceZero
[2017-11-21 06:29:23,627] DEBUG    PluginManager New plugin registered to: Site
[2017-11-21 06:29:23,627] DEBUG    PluginManager Loading plugin: Bigfile
[2017-11-21 06:29:23,723] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 06:29:23,727] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 06:29:23,727] DEBUG    PluginManager New plugin registered to: ContentManager
[2017-11-21 06:29:23,728] DEBUG    PluginManager New plugin registered to: SiteStorage
[2017-11-21 06:29:23,728] DEBUG    PluginManager New plugin registered to: WorkerManager
[2017-11-21 06:29:23,728] DEBUG    PluginManager New plugin registered to: FileRequest
[2017-11-21 06:29:23,729] DEBUG    PluginManager New plugin registered to: Peer
[2017-11-21 06:29:23,729] DEBUG    PluginManager New plugin registered to: Site
[2017-11-21 06:29:23,729] DEBUG    PluginManager New plugin registered to: ConfigPlugin
[2017-11-21 06:29:23,729] DEBUG    PluginManager Loading plugin: Cors
[2017-11-21 06:29:23,934] DEBUG    - Translate file not exists: src/Translate/languages/en.json
[2017-11-21 06:29:23,935] DEBUG    - Translate file not exists: plugins/Cors/languages/en.json
[2017-11-21 06:29:23,935] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 06:29:23,935] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 06:29:23,935] DEBUG    PluginManager Loading plugin: CryptMessage
[2017-11-21 06:29:24,004] DEBUG    - Opening ../lib/libcrypto.so...
[2017-11-21 06:29:24,004] DEBUG    - Disable SSL compression failed: /root/zeronet/ZeroBundle/lib/python2.7/lib-dynload/../../libcrypto.so.1.0.0: undefined symbol: SSL_COMP_get_compression_methods (normal on Windows)
[2017-11-21 06:29:24,004] DEBUG    - Missing SSLwrap, readded.
[2017-11-21 06:29:24,005] DEBUG    - Python SSL version: OpenSSL 1.0.2g  1 Mar 2016
[2017-11-21 06:29:24,006] DEBUG    - opensslVerify loaded: <CDLL '../lib/libcrypto.so', handle 1431880 at 7fc309587290>
[2017-11-21 06:29:24,008] INFO     - OpenSSL loaded, version: 01000207F
[2017-11-21 06:29:24,009] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 06:29:24,009] DEBUG    PluginManager New plugin registered to: User
[2017-11-21 06:29:24,009] DEBUG    PluginManager Loading plugin: FilePack
[2017-11-21 06:29:24,010] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 06:29:24,010] DEBUG    PluginManager New plugin registered to: SiteStorage
[2017-11-21 06:29:24,011] DEBUG    PluginManager Loading plugin: MergerSite
[2017-11-21 06:29:24,027] DEBUG    PluginManager New plugin registered to: ContentDb
[2017-11-21 06:29:24,027] DEBUG    PluginManager New plugin registered to: WorkerManager
[2017-11-21 06:29:24,028] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 06:29:24,028] DEBUG    PluginManager New plugin registered to: FileRequest
[2017-11-21 06:29:24,028] DEBUG    PluginManager New plugin registered to: Site
[2017-11-21 06:29:24,028] DEBUG    PluginManager New plugin registered to: ConfigPlugin
[2017-11-21 06:29:24,029] DEBUG    - Translate file not exists: plugins/OptionalManager/languages/en.json
[2017-11-21 06:29:24,029] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 06:29:24,029] DEBUG    - Translate file not exists: plugins/MergerSite/languages/en.json
[2017-11-21 06:29:24,029] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 06:29:24,029] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 06:29:24,030] DEBUG    PluginManager New plugin registered to: SiteStorage
[2017-11-21 06:29:24,030] DEBUG    PluginManager New plugin registered to: Site
[2017-11-21 06:29:24,030] DEBUG    PluginManager New plugin registered to: SiteManager
[2017-11-21 06:29:24,030] DEBUG    PluginManager Loading plugin: Mute
[2017-11-21 06:29:24,032] DEBUG    - Translate file not exists: plugins/Mute/languages/en.json
[2017-11-21 06:29:24,032] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 06:29:24,032] DEBUG    PluginManager New plugin registered to: SiteStorage
[2017-11-21 06:29:24,032] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 06:29:24,032] DEBUG    PluginManager Loading plugin: Newsfeed
[2017-11-21 06:29:24,049] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 06:29:24,049] DEBUG    PluginManager New plugin registered to: User
[2017-11-21 06:29:24,049] DEBUG    PluginManager Loading plugin: OptionalManager
[2017-11-21 06:29:24,049] DEBUG    PluginManager Loading plugin: PeerDb
[2017-11-21 06:29:24,051] DEBUG    PluginManager New plugin registered to: ContentDb
[2017-11-21 06:29:24,051] DEBUG    PluginManager Loading plugin: Sidebar
[2017-11-21 06:29:24,053] DEBUG    - Translate file not exists: plugins/Sidebar/languages/en.json
[2017-11-21 06:29:24,054] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 06:29:24,054] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 06:29:24,054] DEBUG    PluginManager Loading plugin: Stats
[2017-11-21 06:29:24,055] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 06:29:24,057] DEBUG    PluginManager Loading plugin: TranslateSite
[2017-11-21 06:29:24,058] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 06:29:24,058] DEBUG    PluginManager Loading plugin: Trayicon
[2017-11-21 06:29:24,059] DEBUG    PluginManager Loading plugin: Zeroname
[2017-11-21 06:29:24,060] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 06:29:24,060] DEBUG    PluginManager New plugin registered to: ConfigPlugin
[2017-11-21 06:29:24,061] DEBUG    PluginManager New plugin registered to: SiteManager
[2017-11-21 06:29:24,063] DEBUG    PluginManager New class accepts plugins: Peer (Loaded plugins: [<class 'Bigfile.BigfilePlugin.PeerPlugin'>, <class 'Peer.Peer.Peer'>])
[2017-11-21 06:29:24,070] DEBUG    PluginManager New class accepts plugins: ContentDb (Loaded plugins: [<class 'PeerDb.PeerDbPlugin.ContentDbPlugin'>, <class 'OptionalManager.ContentDbPlugin.ContentDbPlugin'>, <class 'Content.ContentDb.ContentDb'>])
[2017-11-21 06:29:24,073] DEBUG    Db:ContentDb Connected to data/content.db in 0.003s (opened: 1, sqlite version: 2.6.0)...
[2017-11-21 06:29:24,073] DEBUG    Db:ContentDb Db check done in 0.000s, changed tables: []
[2017-11-21 06:29:24,074] DEBUG    PluginManager New class accepts plugins: ContentManager (Loaded plugins: [<class 'Bigfile.BigfilePlugin.ContentManagerPlugin'>, <class 'Content.ContentManager.ContentManager'>])
[2017-11-21 06:29:24,074] DEBUG    PluginManager New class accepts plugins: ConfigPlugin (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.ConfigPlugin'>, <class 'OptionalManager.OptionalManagerPlugin.ConfigPlugin'>, <class 'Bigfile.BigfilePlugin.ConfigPlugin'>, <class 'Config.ConfigPlugin'>])
[2017-11-21 06:29:24,077] DEBUG    - Config: Config(action='main', autodownload_bigfile_size_limit=1, batch=False, bind=None, bit_resolver='1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F', coffeescript_compiler=None, config_file='zeronet.conf', connected_limit=8, data_dir='data', db_mode='speed', debug=False, debug_gevent=False, debug_socket=False, disable_db=False, disable_encryption=False, disable_sslcompression=True, disable_udp=False, download_optional='manual', end=True, file_size_limit=10, fileserver_ip='*', fileserver_port=15441, fix_float_decimals=False, homepage='1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D', ip_external=None, ip_local=['127.0.0.1'], keep_ssl_cert=False, language='en', log_dir='log', max_files_opened=2048, msgpack_purepython=False, open_browser=None, optional_limit='10%', pin_bigfile=20, proxy=None, silent=False, size_limit=10, stack_size=None, stream_downloads=False, tor='enable', tor_controller='127.0.0.1:9051', tor_hs_limit=10, tor_password=None, tor_proxy='127.0.0.1:9050', trackers=['zero://boot3rdez4rzn36x.onion:15441', 'zero://zero.booth.moe#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441', 'udp://tracker.coppersurfer.tk:6969', 'udp://tracker.leechers-paradise.org:6969', 'udp://9.rarbg.com:2710', 'http://tracker.opentrackr.org:1337/announce', 'http://explodie.org:6969/announce', 'http://tracker1.wasabii.com.tw:6969/announce'], trackers_file=False, ui_host=['MY.DOMAIN.COM'], ui_ip='0.0.0.0', ui_port=43110, ui_restrict=False, updatesite='1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp', use_openssl=True, use_tempfiles=False, verbose=False, workers=5)
[2017-11-21 06:29:24,077] INFO     - Version: 0.6.0 r3146, Python 2.7.11 |Continuum Analytics, Inc.| (default, Dec  6 2015, 18:08:32) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)], Gevent: 1.0.2
[2017-11-21 06:29:24,080] DEBUG    PluginManager New class accepts plugins: FileRequest (Loaded plugins: [<class 'OptionalManager.OptionalManagerPlugin.FileRequestPlugin'>, <class 'Bigfile.BigfilePlugin.FileRequestPlugin'>, <class 'File.FileRequest.FileRequest'>])
[2017-11-21 06:29:24,086] DEBUG    PluginManager New class accepts plugins: WorkerManager (Loaded plugins: [<class 'OptionalManager.OptionalManagerPlugin.WorkerManagerPlugin'>, <class 'Bigfile.BigfilePlugin.WorkerManagerPlugin'>, <class 'Worker.WorkerManager.WorkerManager'>])
[2017-11-21 06:29:24,087] DEBUG    PluginManager New class accepts plugins: SiteStorage (Loaded plugins: [<class 'Mute.MutePlugin.SiteStoragePlugin'>, <class 'MergerSite.MergerSitePlugin.SiteStoragePlugin'>, <class 'FilePack.FilePackPlugin.SiteStoragePlugin'>, <class 'Bigfile.BigfilePlugin.SiteStoragePlugin'>, <class 'Site.SiteStorage.SiteStorage'>])
[2017-11-21 06:29:24,088] DEBUG    PluginManager New class accepts plugins: SiteManager (Loaded plugins: [<class 'Zeroname.SiteManagerPlugin.SiteManagerPlugin'>, <class 'MergerSite.MergerSitePlugin.SiteManagerPlugin'>, <class 'Site.SiteManager.SiteManager'>])
[2017-11-21 06:29:24,088] DEBUG    SiteManager SiteManager created.
[2017-11-21 06:29:24,088] DEBUG    PluginManager New class accepts plugins: Site (Loaded plugins: [<class 'MergerSite.MergerSitePlugin.SitePlugin'>, <class 'OptionalManager.OptionalManagerPlugin.SitePlugin'>, <class 'Bigfile.BigfilePlugin.SitePlugin'>, <class 'AnnounceZero.AnnounceZeroPlugin.SitePlugin'>, <class 'Site.Site.Site'>])
[2017-11-21 06:29:24,126] DEBUG    PluginManager New class accepts plugins: User (Loaded plugins: [<class 'Newsfeed.NewsfeedPlugin.UserPlugin'>, <class 'CryptMessage.CryptMessagePlugin.UserPlugin'>, <class 'User.User.User'>])
[2017-11-21 06:29:24,128] DEBUG    PluginManager New class accepts plugins: UiWebsocket (Loaded plugins: [<class 'Sidebar.SidebarPlugin.UiWebsocketPlugin'>, <class 'Newsfeed.NewsfeedPlugin.UiWebsocketPlugin'>, <class 'Mute.MutePlugin.UiWebsocketPlugin'>, <class 'MergerSite.MergerSitePlugin.UiWebsocketPlugin'>, <class 'OptionalManager.UiWebsocketPlugin.UiWebsocketPlugin'>, <class 'CryptMessage.CryptMessagePlugin.UiWebsocketPlugin'>, <class 'Cors.CorsPlugin.UiWebsocketPlugin'>, <class 'Bigfile.BigfilePlugin.UiWebsocketPlugin'>, <class 'Ui.UiWebsocket.UiWebsocket'>])
[2017-11-21 06:29:24,129] DEBUG    PluginManager New class accepts plugins: UiRequest (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.UiRequestPlugin'>, <class 'TranslateSite.TranslateSitePlugin.UiRequestPlugin'>, <class 'Stats.StatsPlugin.UiRequestPlugin'>, <class 'Sidebar.SidebarPlugin.UiRequestPlugin'>, <class 'Mute.MutePlugin.UiRequestPlugin'>, <class 'MergerSite.MergerSitePlugin.UiRequestPlugin'>, <class 'OptionalManager.OptionalManagerPlugin.UiRequestPlugin'>, <class 'FilePack.FilePackPlugin.UiRequestPlugin'>, <class 'Cors.CorsPlugin.UiRequestPlugin'>, <class 'Bigfile.BigfilePlugin.UiRequestPlugin'>, <class 'Ui.UiRequest.UiRequest'>])
[2017-11-21 06:29:24,129] INFO     - Creating FileServer....
[2017-11-21 06:29:24,130] INFO     TorManager Connecting to Tor Controller 127.0.0.1:9051
[2017-11-21 06:29:24,146] ERROR    TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 170 > socket.py line 344
[2017-11-21 06:29:24,147] INFO     TorManager Starting self-bundled Tor, due to Tor proxy port 127.0.0.1:9050 check error: No connection
[2017-11-21 06:29:24,148] INFO     - Creating UiServer....
[2017-11-21 06:29:24,148] DEBUG    SiteManager Sites not loaded yet...
[2017-11-21 06:29:24,148] DEBUG    SiteManager Loading sites...
[2017-11-21 06:29:24,152] DEBUG    Site:1Name2..hM9F ContentDb init: 0.001s, found files: 1, sites: 2
[2017-11-21 06:29:24,154] DEBUG    SiteManager Loaded site 1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F in 0.004s
[2017-11-21 06:29:24,156] DEBUG    Site:1HeLLo..Tf3D ContentDb init: 0.000s, found files: 1, sites: 2
[2017-11-21 06:29:24,156] DEBUG    SiteManager Loaded site 1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D in 0.001s
[2017-11-21 06:29:24,157] DEBUG    SiteManager SiteManager added 2 sites
[2017-11-21 06:29:24,157] DEBUG    SiteManager Updated merger sites in 0.000s
[2017-11-21 06:29:24,157] INFO     - Removing old SSL certs...
[2017-11-21 06:29:24,158] INFO     - Starting servers....
[2017-11-21 06:29:24,159] INFO     Ui.UiServer --------------------------------------
[2017-11-21 06:29:24,159] INFO     Ui.UiServer Web interface: http://0.0.0.0:43110/
[2017-11-21 06:29:24,160] INFO     Ui.UiServer --------------------------------------
[2017-11-21 06:29:24,162] DEBUG    - Current RLIMIT_NOFILE: 1024 (max: 4096), changing to 2048...
[2017-11-21 06:29:24,481] DEBUG    - Generating RSA cert and key PEM files...Generating a 2048 bit RSA private key
.....................................+++
......+++
unable to write 'random state'
writing new private key to 'data/key-rsa.pem'
-----
[2017-11-21 06:29:24,481] DEBUG    FileServer Binding to: *:15441, (msgpack: 0.4.6), supported crypt: ['tls-rsa']
[2017-11-21 06:29:24,482] DEBUG    FileServer Checking sites...
[2017-11-21 06:29:24,483] DEBUG    FileServer Conn# 1 zero.booth.moe [?] > Connecting...
[2017-11-21 06:29:24,667] DEBUG    Site:1Name2..hM9F 374 peers (0 with hashfield) loaded in 0.013s
[2017-11-21 06:29:24,670] DEBUG    Site:1HeLLo..Tf3D 85 peers (0 with hashfield) loaded in 0.002s
[2017-11-21 06:29:24,765] DEBUG    Site:1HeLLo..Tf3D Found 30 peers, new: 15, total: 100
[2017-11-21 06:29:24,796] DEBUG    Site:1HeLLo..Tf3D Found 50 peers, new: 25, total: 125
[2017-11-21 06:29:24,819] DEBUG    Site:1Name2..hM9F Found 50 peers, new: 12, total: 386
[2017-11-21 06:29:24,826] DEBUG    Site:1Name2..hM9F Found 30 peers, new: 2, total: 388
[2017-11-21 06:29:24,828] DEBUG    Site:1HeLLo..Tf3D Found 30 peers, new: 9, total: 134
[2017-11-21 06:29:24,836] DEBUG    Site:1Name2..hM9F Found 50 peers, new: 7, total: 395
[2017-11-21 06:29:24,848] DEBUG    Site:1Name2..hM9F Found 15 ip4, 0 onion peers, new: 3
[2017-11-21 06:29:24,848] DEBUG    Site:1HeLLo..Tf3D Found 15 ip4, 0 onion peers, new: 9
[2017-11-21 06:29:24,848] DEBUG    FileServer Conn# 1 zero.booth.moe [v2] > Closing connection: Removing, waiting_requests: 0, sites: 1, buff: 0...
[2017-11-21 06:29:24,890] DEBUG    Site:1HeLLo..Tf3D Found 50 peers, new: 19, total: 162
[2017-11-21 06:29:24,890] DEBUG    Site:1HeLLo..Tf3D Announced types [] in mode startup to 7 trackers in 0.408s, errors: [], slow: []
[2017-11-21 06:29:24,891] DEBUG    Site:1HeLLo..Tf3D content.json loadContent same json file, skipping
[2017-11-21 06:29:24,892] DEBUG    FileServer Conn# 2 188.26.168.239 [?] > Connecting...
[2017-11-21 06:29:24,893] DEBUG    FileServer Conn# 3 68.3.90.52   [?] > Connecting...
[2017-11-21 06:29:24,959] DEBUG    FileServer Conn# 4 212.24.103.49 [?] > Connecting...
[2017-11-21 06:29:25,023] DEBUG    FileServer Conn# 3 68.3.90.52   [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 0.131s)...
[2017-11-21 06:29:25,125] DEBUG    FileServer Conn# 5 78.12.241.33 [?] > Connecting...
[2017-11-21 06:29:25,155] DEBUG    Db:ContentDb Loaded 0 optional files: 0.00MB, downloaded: 0.00MB in 0.000s
[2017-11-21 06:29:25,300] DEBUG    FileServer Conn# 4 212.24.103.49 [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 0.341s)...
[2017-11-21 06:29:25,320] DEBUG    FileServer Conn# 2 188.26.168.239 [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 0.428s)...
[2017-11-21 06:29:25,483] INFO     FileServer Checking port 15441 using portchecker.co...
[2017-11-21 06:29:25,531] DEBUG    FileServer Conn# 5 78.12.241.33 [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 0.406s)...
[2017-11-21 06:29:25,655] INFO     FileServer [OK :)] Port open: Port 15441 is open.
[2017-11-21 06:29:25,657] DEBUG    FileServer Conn# 6 45.33.50.110 [?] > Incoming connection...
[2017-11-21 06:29:25,657] DEBUG    FileServer Conn# 6 45.33.50.110 [v2] > Closing connection: MessageLoop ended, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 06:29:25,816] DEBUG    FileServer Conn# 7 73.35.229.45 [?] > Connecting...
[2017-11-21 06:29:28,441] DEBUG    Site:1HeLLo..Tf3D Queried pex from 2 peers got 8 new peers.
[2017-11-21 06:29:31,773] DEBUG    Site:1Name2..hM9F Found 30 peers, new: 3, total: 401
[2017-11-21 06:29:31,773] DEBUG    Site:1Name2..hM9F Announced types [] in mode startup to 7 trackers in 7.291s, errors: [], slow: ['7.29s http://tracker1.wasabii.com.tw:6969/announce']
[2017-11-21 06:29:31,774] DEBUG    Site:1Name2..hM9F content.json loadContent same json file, skipping
[2017-11-21 06:29:31,945] DEBUG    FileServer Conn# 8 45.40.85.35  [?] > Connecting...
[2017-11-21 06:29:32,957] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 06:29:32] "GET /1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D HTTP/1.1" 200 3059 0.025445
[2017-11-21 06:29:33,366] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 06:29:33] "GET /uimedia/all.css?rev=3146 HTTP/1.1" 200 33557 0.049778
[2017-11-21 06:29:33,836] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 06:29:33] "GET /uimedia/all.js?rev=3146&lang=en HTTP/1.1" 200 177473 0.012299
[2017-11-21 06:29:33,926] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 06:29:33] "GET /1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/?wrapper_nonce=********* HTTP/1.1" 200 1444 0.002667
[2017-11-21 06:29:34,892] DEBUG    Site:1HeLLo..Tf3D Queried listModifications from: [<Peer:68.3.90.52  >, <Peer:212.24.103.49>, <Peer:188.26.168.239>, <Peer:78.12.241.33>] in 10.001s
[2017-11-21 06:29:34,988] DEBUG    Site:1Name2..hM9F Queried pex from 2 peers got 3 new peers.
[2017-11-21 06:29:34,994] DEBUG    Site:1HeLLo..Tf3D content.json loadContent same json file, skipping
[2017-11-21 06:29:34,994] DEBUG    Site:1HeLLo..Tf3D Need connections: 6, Current: 6, Total: 170
[2017-11-21 06:29:35,592] DEBUG    Ui.UiServer Error 403: Invalid host: 127.0.0.1:43110
[2017-11-21 06:29:35,592] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 06:29:35] "GET /Websocket?wrapper_key=********* HTTP/1.1" 101 129 0.001570
[2017-11-21 06:29:39,159] DEBUG    FileServer Conn# 7 73.35.229.45 [?] > Closing connection: [Cleanup] Connect timeout: 13.343s, waiting_requests: 0, sites: 1, buff: 0...
[2017-11-21 06:29:41,776] DEBUG    Site:1Name2..hM9F Queried listModifications from: [<Peer:68.3.90.52  >, <Peer:212.24.103.49>, <Peer:188.26.168.239>, <Peer:78.12.241.33>] in 10.002s
[2017-11-21 06:29:41,877] DEBUG    Site:1Name2..hM9F content.json loadContent same json file, skipping
[2017-11-21 06:29:41,878] DEBUG    Site:1Name2..hM9F Need connections: 6, Current: 5, Total: 404
[2017-11-21 06:29:41,879] DEBUG    FileServer Conn# 9 113.247.238.166 [?] > Connecting...
[2017-11-21 06:29:46,450] DEBUG    Ui.UiServer Error 403: Invalid host: 127.0.0.1:43110
[2017-11-21 06:29:46,450] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 06:29:46] "GET /Websocket?wrapper_key=********* HTTP/1.1" 101 129 0.000789
[2017-11-21 06:29:54,162] DEBUG    FileServer Conn# 8 45.40.85.35  [?] > Closing connection: [Cleanup] Connect timeout: 22.216s, waiting_requests: 0, sites: 2, buff: 0...
[2017-11-21 06:29:54,162] DEBUG    FileServer Conn# 9 113.247.238.166 [?] > Closing connection: [Cleanup] Connect timeout: 12.283s, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 06:29:54,164] DEBUG    FileServer Conn#10 95.73.201.83 [?] > Connecting...
[2017-11-21 06:29:54,600] DEBUG    FileServer Conn#10 95.73.201.83 [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 0.436s)...
[2017-11-21 06:29:55,193] DEBUG    Site:1Name2..hM9F Connected before: 5, after: 6. Check site: False.
[2017-11-21 06:29:57,503] DEBUG    Ui.UiServer Error 403: Invalid host: 127.0.0.1:43110
[2017-11-21 06:29:57,504] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 06:29:57] "GET /Websocket?wrapper_key=********* HTTP/1.1" 101 129 0.001072
[2017-11-21 06:30:06,341] ERROR    - Unhandled exception
None
[2017-11-21 06:30:06,352] DEBUG    Ui.UiServer Stopping...
[2017-11-21 06:30:06,352] DEBUG    Ui.UiServer Socket closed: 0
[2017-11-21 06:30:06,353] DEBUG    FileServer Stopped.
[2017-11-21 06:30:06,454] DEBUG    Ui.UiServer Stopped.
[2017-11-21 06:30:06,492] DEBUG    SiteManager Saved sites in 0.02s (generate: 0.02s, write: 0.02s)
[2017-11-21 06:30:06,505] DEBUG    SiteManager Updated merger sites in 0.000s
[2017-11-21 06:30:06,537] DEBUG    Site:1Name2..hM9F Peers saved in 0.032s
[2017-11-21 06:30:06,540] DEBUG    Site:1HeLLo..Tf3D Peers saved in 0.002s

``` Getting the same error, also trying to set up a public ZeroNet proxy.

Here is my debug.log:

```
[2017-11-21 08:28:41,041] DEBUG    PluginManager Loading plugin: AnnounceZero
[2017-11-21 08:28:41,051] DEBUG    PluginManager New plugin registered to: Site
[2017-11-21 08:28:41,051] DEBUG    PluginManager Loading plugin: Bigfile
[2017-11-21 08:28:41,066] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 08:28:41,066] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 08:28:41,066] DEBUG    PluginManager New plugin registered to: ContentManager
[2017-11-21 08:28:41,067] DEBUG    PluginManager New plugin registered to: SiteStorage
[2017-11-21 08:28:41,067] DEBUG    PluginManager New plugin registered to: WorkerManager
[2017-11-21 08:28:41,067] DEBUG    PluginManager New plugin registered to: FileRequest
[2017-11-21 08:28:41,067] DEBUG    PluginManager New plugin registered to: Peer
[2017-11-21 08:28:41,067] DEBUG    PluginManager New plugin registered to: Site
[2017-11-21 08:28:41,067] DEBUG    PluginManager New plugin registered to: ConfigPlugin
[2017-11-21 08:28:41,067] DEBUG    PluginManager Loading plugin: Cors
[2017-11-21 08:28:41,095] DEBUG    - Translate file not exists: src/Translate/languages/en.json
[2017-11-21 08:28:41,095] DEBUG    - Translate file not exists: plugins/Cors/languages/en.json
[2017-11-21 08:28:41,096] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 08:28:41,096] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 08:28:41,096] DEBUG    PluginManager Loading plugin: CryptMessage
[2017-11-21 08:28:41,150] DEBUG    - Opening libssl.so.1.0.0...
[2017-11-21 08:28:41,151] DEBUG    - Disabled SSL compression on <CDLL 'libssl.so.1.0.0', handle 1139250 at 7f2dc8c8b210>
[2017-11-21 08:28:41,151] DEBUG    - Missing SSLwrap, readded.
[2017-11-21 08:28:41,151] DEBUG    - Python SSL version: OpenSSL 1.0.2g  1 Mar 2016
[2017-11-21 08:28:41,157] DEBUG    - opensslVerify loaded: <CDLL 'libssl.so.1.0.0', handle 1139250 at 7f2dc8cca990>
[2017-11-21 08:28:41,159] INFO     - OpenSSL loaded, version: 01000207F
[2017-11-21 08:28:41,166] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 08:28:41,167] DEBUG    PluginManager New plugin registered to: User
[2017-11-21 08:28:41,167] DEBUG    PluginManager Loading plugin: FilePack
[2017-11-21 08:28:41,168] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 08:28:41,168] DEBUG    PluginManager New plugin registered to: SiteStorage
[2017-11-21 08:28:41,168] DEBUG    PluginManager Loading plugin: MergerSite
[2017-11-21 08:28:41,180] DEBUG    PluginManager New plugin registered to: ContentDb
[2017-11-21 08:28:41,181] DEBUG    PluginManager New plugin registered to: WorkerManager
[2017-11-21 08:28:41,181] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 08:28:41,181] DEBUG    PluginManager New plugin registered to: FileRequest
[2017-11-21 08:28:41,181] DEBUG    PluginManager New plugin registered to: Site
[2017-11-21 08:28:41,181] DEBUG    PluginManager New plugin registered to: ConfigPlugin
[2017-11-21 08:28:41,183] DEBUG    - Translate file not exists: plugins/OptionalManager/languages/en.json
[2017-11-21 08:28:41,183] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 08:28:41,185] DEBUG    - Translate file not exists: plugins/MergerSite/languages/en.json
[2017-11-21 08:28:41,185] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 08:28:41,186] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 08:28:41,186] DEBUG    PluginManager New plugin registered to: SiteStorage
[2017-11-21 08:28:41,186] DEBUG    PluginManager New plugin registered to: Site
[2017-11-21 08:28:41,186] DEBUG    PluginManager New plugin registered to: SiteManager
[2017-11-21 08:28:41,186] DEBUG    PluginManager Loading plugin: Mute
[2017-11-21 08:28:41,188] DEBUG    - Translate file not exists: plugins/Mute/languages/en.json
[2017-11-21 08:28:41,188] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 08:28:41,188] DEBUG    PluginManager New plugin registered to: SiteStorage
[2017-11-21 08:28:41,188] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 08:28:41,188] DEBUG    PluginManager Loading plugin: Newsfeed
[2017-11-21 08:28:41,223] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 08:28:41,223] DEBUG    PluginManager New plugin registered to: User
[2017-11-21 08:28:41,223] DEBUG    PluginManager Loading plugin: OptionalManager
[2017-11-21 08:28:41,223] DEBUG    PluginManager Loading plugin: PeerDb
[2017-11-21 08:28:41,227] DEBUG    PluginManager New plugin registered to: ContentDb
[2017-11-21 08:28:41,227] DEBUG    PluginManager Loading plugin: Sidebar
[2017-11-21 08:28:41,233] DEBUG    - Translate file not exists: plugins/Sidebar/languages/en.json
[2017-11-21 08:28:41,233] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 08:28:41,233] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2017-11-21 08:28:41,233] DEBUG    PluginManager Loading plugin: Stats
[2017-11-21 08:28:41,235] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 08:28:41,235] DEBUG    PluginManager Loading plugin: TranslateSite
[2017-11-21 08:28:41,239] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 08:28:41,239] DEBUG    PluginManager Loading plugin: Trayicon
[2017-11-21 08:28:41,244] DEBUG    PluginManager Loading plugin: Zeroname
[2017-11-21 08:28:41,246] DEBUG    PluginManager New plugin registered to: UiRequest
[2017-11-21 08:28:41,247] DEBUG    PluginManager New plugin registered to: ConfigPlugin
[2017-11-21 08:28:41,250] DEBUG    PluginManager New plugin registered to: SiteManager
[2017-11-21 08:28:41,257] DEBUG    PluginManager New class accepts plugins: Peer (Loaded plugins: [<class 'Bigfile.BigfilePlugin.PeerPlugin'>, <class 'Peer.Peer.Peer'>])
[2017-11-21 08:28:41,273] DEBUG    PluginManager New class accepts plugins: ContentDb (Loaded plugins: [<class 'PeerDb.PeerDbPlugin.ContentDbPlugin'>, <class 'OptionalManager.ContentDbPlugin.ContentDbPlugin'>, <class 'Content.ContentDb.ContentDb'>])
[2017-11-21 08:28:41,276] DEBUG    Db:ContentDb Connected to data/content.db in 0.003s (opened: 1, sqlite version: 2.6.0)...
[2017-11-21 08:28:41,277] DEBUG    Db:ContentDb Db check done in 0.000s, changed tables: []
[2017-11-21 08:28:41,277] DEBUG    PluginManager New class accepts plugins: ContentManager (Loaded plugins: [<class 'Bigfile.BigfilePlugin.ContentManagerPlugin'>, <class 'Content.ContentManager.ContentManager'>])
[2017-11-21 08:28:41,277] DEBUG    PluginManager New class accepts plugins: ConfigPlugin (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.ConfigPlugin'>, <class 'OptionalManager.OptionalManagerPlugin.ConfigPlugin'>, <class 'Bigfile.BigfilePlugin.ConfigPlugin'>, <class 'Config.ConfigPlugin'>])
[2017-11-21 08:28:41,279] DEBUG    - Config: Config(action='main', autodownload_bigfile_size_limit=1, batch=False, bind=None, bit_resolver='1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F', coffeescript_compiler=None, config_file='zeronet.conf', connected_limit=8, data_dir='data', db_mode='speed', debug=False, debug_gevent=False, debug_socket=False, disable_db=False, disable_encryption=False, disable_sslcompression=True, disable_udp=False, download_optional='manual', end=True, file_size_limit=10, fileserver_ip='*', fileserver_port=15441, fix_float_decimals=False, homepage='1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D', ip_external=None, ip_local=['127.0.0.1'], keep_ssl_cert=False, language='en', log_dir='logs', max_files_opened=2048, msgpack_purepython=False, open_browser=None, optional_limit='10%', pin_bigfile=20, proxy=None, silent=False, size_limit=10, stack_size=None, stream_downloads=False, tor='enable', tor_controller='127.0.0.1:9051', tor_hs_limit=10, tor_password=None, tor_proxy='127.0.0.1:9050', trackers=['zero://boot3rdez4rzn36x.onion:15441', 'zero://zero.booth.moe#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441', 'udp://tracker.coppersurfer.tk:6969', 'udp://tracker.leechers-paradise.org:6969', 'udp://9.rarbg.com:2710', 'http://tracker.opentrackr.org:1337/announce', 'http://explodie.org:6969/announce', 'http://tracker1.wasabii.com.tw:6969/announce'], trackers_file=False, ui_host=None, ui_ip='*', ui_port=4990, ui_restrict=False, updatesite='1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp', use_openssl=True, use_tempfiles=False, verbose=False, workers=5)
[2017-11-21 08:28:41,279] INFO     - Version: 0.6.0 r3146, Python 2.7.12 (default, Nov 19 2016, 06:48:10) 
[GCC 5.4.0 20160609], Gevent: 1.2.2
[2017-11-21 08:28:41,320] DEBUG    PluginManager New class accepts plugins: FileRequest (Loaded plugins: [<class 'OptionalManager.OptionalManagerPlugin.FileRequestPlugin'>, <class 'Bigfile.BigfilePlugin.FileRequestPlugin'>, <class 'File.FileRequest.FileRequest'>])
[2017-11-21 08:28:41,335] DEBUG    PluginManager New class accepts plugins: WorkerManager (Loaded plugins: [<class 'OptionalManager.OptionalManagerPlugin.WorkerManagerPlugin'>, <class 'Bigfile.BigfilePlugin.WorkerManagerPlugin'>, <class 'Worker.WorkerManager.WorkerManager'>])
[2017-11-21 08:28:41,343] DEBUG    PluginManager New class accepts plugins: SiteStorage (Loaded plugins: [<class 'Mute.MutePlugin.SiteStoragePlugin'>, <class 'MergerSite.MergerSitePlugin.SiteStoragePlugin'>, <class 'FilePack.FilePackPlugin.SiteStoragePlugin'>, <class 'Bigfile.BigfilePlugin.SiteStoragePlugin'>, <class 'Site.SiteStorage.SiteStorage'>])
[2017-11-21 08:28:41,350] DEBUG    PluginManager New class accepts plugins: SiteManager (Loaded plugins: [<class 'Zeroname.SiteManagerPlugin.SiteManagerPlugin'>, <class 'MergerSite.MergerSitePlugin.SiteManagerPlugin'>, <class 'Site.SiteManager.SiteManager'>])
[2017-11-21 08:28:41,351] DEBUG    SiteManager SiteManager created.
[2017-11-21 08:28:41,351] DEBUG    PluginManager New class accepts plugins: Site (Loaded plugins: [<class 'MergerSite.MergerSitePlugin.SitePlugin'>, <class 'OptionalManager.OptionalManagerPlugin.SitePlugin'>, <class 'Bigfile.BigfilePlugin.SitePlugin'>, <class 'AnnounceZero.AnnounceZeroPlugin.SitePlugin'>, <class 'Site.Site.Site'>])
[2017-11-21 08:28:41,390] DEBUG    PluginManager New class accepts plugins: User (Loaded plugins: [<class 'Newsfeed.NewsfeedPlugin.UserPlugin'>, <class 'CryptMessage.CryptMessagePlugin.UserPlugin'>, <class 'User.User.User'>])
[2017-11-21 08:28:41,392] DEBUG    PluginManager New class accepts plugins: UiWebsocket (Loaded plugins: [<class 'Sidebar.SidebarPlugin.UiWebsocketPlugin'>, <class 'Newsfeed.NewsfeedPlugin.UiWebsocketPlugin'>, <class 'Mute.MutePlugin.UiWebsocketPlugin'>, <class 'MergerSite.MergerSitePlugin.UiWebsocketPlugin'>, <class 'OptionalManager.UiWebsocketPlugin.UiWebsocketPlugin'>, <class 'CryptMessage.CryptMessagePlugin.UiWebsocketPlugin'>, <class 'Cors.CorsPlugin.UiWebsocketPlugin'>, <class 'Bigfile.BigfilePlugin.UiWebsocketPlugin'>, <class 'Ui.UiWebsocket.UiWebsocket'>])
[2017-11-21 08:28:41,393] DEBUG    PluginManager New class accepts plugins: UiRequest (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.UiRequestPlugin'>, <class 'TranslateSite.TranslateSitePlugin.UiRequestPlugin'>, <class 'Stats.StatsPlugin.UiRequestPlugin'>, <class 'Sidebar.SidebarPlugin.UiRequestPlugin'>, <class 'Mute.MutePlugin.UiRequestPlugin'>, <class 'MergerSite.MergerSitePlugin.UiRequestPlugin'>, <class 'OptionalManager.OptionalManagerPlugin.UiRequestPlugin'>, <class 'FilePack.FilePackPlugin.UiRequestPlugin'>, <class 'Cors.CorsPlugin.UiRequestPlugin'>, <class 'Bigfile.BigfilePlugin.UiRequestPlugin'>, <class 'Ui.UiRequest.UiRequest'>])
[2017-11-21 08:28:41,393] INFO     - Creating FileServer....
[2017-11-21 08:28:41,398] INFO     TorManager Connecting to Tor Controller 127.0.0.1:9051
[2017-11-21 08:28:41,440] DEBUG    TorManager > PROTOCOLINFO
[2017-11-21 08:28:41,446] DEBUG    TorManager < 250-PROTOCOLINFO 1
250-AUTH METHODS=COOKIE,SAFECOOKIE COOKIEFILE="/var/run/tor/control.authcookie"
250-VERSION Tor="0.3.1.8"
250 OK
[2017-11-21 08:28:41,452] DEBUG    TorManager > AUTHENTICATE de3f48423a2ee3c2618c69735706bcc8f7212c379919a4c86e785af7e1dabc5d
[2017-11-21 08:28:41,452] DEBUG    TorManager < 250 OK
[2017-11-21 08:28:41,453] DEBUG    TorManager > GETINFO version
[2017-11-21 08:28:41,453] DEBUG    TorManager < 250-version=0.3.1.8 (git-868c1b2b1eb7225a)
250 OK
[2017-11-21 08:28:41,453] DEBUG    TorManager Tor proxy port 127.0.0.1:9050 check ok
[2017-11-21 08:28:41,453] INFO     - Creating UiServer....
[2017-11-21 08:28:41,456] DEBUG    SiteManager Sites not loaded yet...
[2017-11-21 08:28:41,456] DEBUG    SiteManager Loading sites...
[2017-11-21 08:28:41,461] DEBUG    Site:1Name2..hM9F ContentDb init: 0.001s, found files: 1, sites: 2
[2017-11-21 08:28:41,462] DEBUG    SiteManager Loaded site 1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F in 0.002s
[2017-11-21 08:28:41,462] DEBUG    Site:1HeLLo..Tf3D ContentDb init: 0.000s, found files: 1, sites: 2
[2017-11-21 08:28:41,471] DEBUG    SiteManager Loaded site 1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D in 0.009s
[2017-11-21 08:28:41,471] DEBUG    SiteManager SiteManager added 2 sites
[2017-11-21 08:28:41,471] DEBUG    SiteManager Updated merger sites in 0.000s
[2017-11-21 08:28:41,471] INFO     - Removing old SSL certs...
[2017-11-21 08:28:41,477] INFO     - Starting servers....
[2017-11-21 08:28:41,478] INFO     Ui.UiServer --------------------------------------
[2017-11-21 08:28:41,486] INFO     Ui.UiServer Web interface: http://*:4990/
[2017-11-21 08:28:41,491] INFO     Ui.UiServer --------------------------------------
[2017-11-21 08:28:41,498] DEBUG    - Current RLIMIT_NOFILE: 1024 (max: 1048576), changing to 2048...
[2017-11-21 08:28:41,879] DEBUG    FileServer Checking sites...
[2017-11-21 08:28:41,881] DEBUG    FileServer Conn# 1 boot3rdez4rzn36x.onion [?] > Connecting...
[2017-11-21 08:28:41,881] DEBUG    TorManager Creating new Tor socket to boot3rdez4rzn36x.onion:15441
[2017-11-21 08:28:41,882] DEBUG    FileServer Conn# 2 zero.booth.moe [?] > Connecting...
[2017-11-21 08:28:41,909] DEBUG    - Generating RSA cert and key PEM files...Generating a 2048 bit RSA private key
....................................................+++
...............................+++
unable to write 'random state'
writing new private key to 'data/key-rsa.pem'
-----
[2017-11-21 08:28:41,913] DEBUG    FileServer Binding to: *:15441, (msgpack: 0.4.8), supported crypt: ['tls-rsa']
[2017-11-21 08:28:41,933] DEBUG    Site:1Name2..hM9F Http tracker explodie.org:6969/announce error: 'peers'
[2017-11-21 08:28:41,937] DEBUG    Site:1HeLLo..Tf3D Http tracker explodie.org:6969/announce error: 'peers'
[2017-11-21 08:28:41,983] DEBUG    Site:1Name2..hM9F 366 peers (0 with hashfield) loaded in 0.020s
[2017-11-21 08:28:41,992] DEBUG    Site:1HeLLo..Tf3D 245 peers (0 with hashfield) loaded in 0.008s
[2017-11-21 08:28:42,200] DEBUG    Site:1Name2..hM9F Found 50 peers, new: 7, total: 373
[2017-11-21 08:28:42,203] DEBUG    Site:1HeLLo..Tf3D Found 50 peers, new: 16, total: 261
[2017-11-21 08:28:42,232] DEBUG    Site:1Name2..hM9F Found 50 peers, new: 12, total: 385
[2017-11-21 08:28:42,234] DEBUG    Site:1Name2..hM9F Found 30 peers, new: 5, total: 390
[2017-11-21 08:28:42,235] DEBUG    Site:1HeLLo..Tf3D Found 50 peers, new: 15, total: 276
[2017-11-21 08:28:42,281] DEBUG    Site:1Name2..hM9F Found 10 ip4, 10 onion peers, new: 11
[2017-11-21 08:28:42,281] DEBUG    Site:1HeLLo..Tf3D Found 10 ip4, 10 onion peers, new: 16
[2017-11-21 08:28:42,281] DEBUG    FileServer Conn# 2 zero.booth.moe [v2] > Closing connection: Removing, waiting_requests: 0, sites: 1, buff: 0...
[2017-11-21 08:28:42,352] DEBUG    Site:1Name2..hM9F Found 30 peers, new: 7, total: 408
[2017-11-21 08:28:42,389] DEBUG    Site:1HeLLo..Tf3D Found 30 peers, new: 10, total: 302
[2017-11-21 08:28:42,462] DEBUG    Db:ContentDb Loaded 0 optional files: 0.00MB, downloaded: 0.00MB in 0.000s
[2017-11-21 08:28:42,879] INFO     FileServer Checking port 15441 using portchecker.co...
[2017-11-21 08:28:42,911] INFO     FileServer [OK :)] Port open: Port 15441 is open.
[2017-11-21 08:28:42,915] DEBUG    FileServer Conn# 3 45.33.50.110 [?] > Incoming connection...
[2017-11-21 08:28:42,920] DEBUG    FileServer Conn# 3 45.33.50.110 [v2] > Closing connection: MessageLoop ended, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:28:43,234] DEBUG    Site:1HeLLo..Tf3D Found 30 peers, new: 6, total: 308
[2017-11-21 08:28:43,235] DEBUG    Site:1HeLLo..Tf3D Announced types [] in mode startup to 7 trackers in 1.356s, errors: ['http://explodie.org:6969/announce'], slow: ['1.33s http://tracker1.wasabii.com.tw:6969/announce']
[2017-11-21 08:28:43,235] DEBUG    Site:1HeLLo..Tf3D content.json loadContent same json file, skipping
[2017-11-21 08:28:43,236] DEBUG    FileServer Conn# 4 27.189.77.53 [?] > Connecting...
[2017-11-21 08:28:43,236] DEBUG    FileServer Conn# 5 71.54.138.21 [?] > Connecting...
[2017-11-21 08:28:43,237] DEBUG    FileServer Conn# 6 52x2ppu3qzi5gxxg.onion [?] > Connecting...
[2017-11-21 08:28:43,237] DEBUG    TorManager Creating new Tor socket to 52x2ppu3qzi5gxxg.onion:15441
[2017-11-21 08:28:44,658] DEBUG    TorManager > ADD_ONION NEW:RSA1024 port=15441
[2017-11-21 08:28:44,696] DEBUG    TorManager < 250-ServiceID=fsdcuvwbodlj2luo
250-PrivateKey=xxx
250 OK
[2017-11-21 08:28:44,697] DEBUG    TorManager Created new hidden service for global: fsdcuvwbodlj2luo
[2017-11-21 08:28:46,236] DEBUG    Site:1HeLLo..Tf3D Small number of peers detected...query all of peers using pex
[2017-11-21 08:28:46,240] DEBUG    FileServer Conn# 7 85.204.246.214 [?] > Connecting...
[2017-11-21 08:28:46,639] DEBUG    FileServer Conn# 7 85.204.246.214 [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 0.399s)...
[2017-11-21 08:28:46,670] DEBUG    FileServer Conn# 1 boot3rdez4rzn36x.onion [v2] > Closing connection: MessageLoop ended, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:28:46,671] DEBUG    Site:1Name2..hM9F Announce to boot3rdez4rzn36x.onion:15441 failed: None
[2017-11-21 08:28:46,671] DEBUG    Site:1Name2..hM9F Announced types [] in mode startup to 6 trackers in 4.792s, errors: ['zero://boot3rdez4rzn36x.onion:15441', 'http://explodie.org:6969/announce'], slow: []
[2017-11-21 08:28:46,671] DEBUG    Site:1Name2..hM9F content.json loadContent same json file, skipping
[2017-11-21 08:28:46,672] DEBUG    FileServer Conn# 4 27.189.77.53 [?] > Closing connection: Send error: This socket is already used by another greenlet: <bound method Waiter.switch of <gevent.hub.Waiter object at 0x7f2dc6468050>>, waiting_requests: 1, sites: 1, buff: 0...
[2017-11-21 08:28:46,672] DEBUG    FileServer Conn# 5 71.54.138.21 [?] > Closing connection: Send error: This socket is already used by another greenlet: <bound method Waiter.switch of <gevent.hub.Waiter object at 0x7f2dc64685a0>>, waiting_requests: 1, sites: 1, buff: 0...
[2017-11-21 08:28:46,673] DEBUG    FileServer Conn# 8 78.97.138.194 [?] > Connecting...
[2017-11-21 08:28:46,678] DEBUG    FileServer Conn# 9 2xn22t66nl6p5da3.onion [?] > Connecting...
[2017-11-21 08:28:46,678] DEBUG    TorManager Creating new Tor socket to 2xn22t66nl6p5da3.onion:15441
[2017-11-21 08:28:46,678] DEBUG    FileServer Conn#10 181.176.86.170 [?] > Connecting...
[2017-11-21 08:28:47,259] DEBUG    FileServer Conn#11 45.40.85.35  [?] > Connecting...
[2017-11-21 08:28:47,673] DEBUG    FileServer Conn#12 27.189.77.53 [?] > Connecting...
[2017-11-21 08:28:47,674] DEBUG    FileServer Conn#13 71.54.138.21 [?] > Connecting...
[2017-11-21 08:28:48,239] INFO     Ui.UiServer Added localhost:4990 as allowed host
[2017-11-21 08:28:48,246] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:28:48] "GET /1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/ HTTP/1.0" 200 3019 0.007306
[2017-11-21 08:28:48,315] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:28:48] "GET /uimedia/all.css?rev=3146 HTTP/1.0" 200 33508 0.013621
[2017-11-21 08:28:48,327] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:28:48] "GET /uimedia/all.js?rev=3146&lang=en HTTP/1.0" 200 177406 0.005264
[2017-11-21 08:28:48,398] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:28:48] "GET /1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/?wrapper_nonce=4a5b2807b43c8aa36cf734ba5bfc0a9e90a9b2cf99d60bd63cacd6d92adc1517 HTTP/1.0" 200 1444 0.001691
[2017-11-21 08:28:49,672] DEBUG    Site:1Name2..hM9F Small number of peers detected...query all of peers using pex
[2017-11-21 08:28:49,673] DEBUG    FileServer Conn#14 108.61.164.133 [?] > Connecting...
[2017-11-21 08:28:49,901] DEBUG    FileServer Conn# 8 78.97.138.194 [?] > Closing connection: 78.97.138.194 Connect error: error: [Errno 113] No route to host in ConnectionServer.py line 145 > Connection.py line 113 > _socket2.py line 231, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:28:49,901] DEBUG    FileServer Conn#15 185.170.42.18 [?] > Connecting...
[2017-11-21 08:28:50,092] DEBUG    FileServer Conn#15 185.170.42.18 [?] > Closing connection: 185.170.42.18 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 145 > Connection.py line 113 > _socket2.py line 231, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:28:50,092] DEBUG    FileServer Conn#16 j72smro7nhn3gnlc.onion [?] > Connecting...
[2017-11-21 08:28:50,092] DEBUG    TorManager Creating new Tor socket to j72smro7nhn3gnlc.onion:15441
[2017-11-21 08:28:52,187] DEBUG    FileServer Conn#17 sgwevpsn6jiky5sr.onion [?] > Connecting...
[2017-11-21 08:28:52,187] DEBUG    TorManager Creating new Tor socket to sgwevpsn6jiky5sr.onion:15441
[2017-11-21 08:28:53,236] DEBUG    Site:1HeLLo..Tf3D Queried listModifications from: [<Peer:52x2ppu3qzi5gxxg.onion>] in 10.001s
[2017-11-21 08:28:53,337] DEBUG    Site:1HeLLo..Tf3D content.json loadContent same json file, skipping
[2017-11-21 08:28:53,338] DEBUG    Site:1HeLLo..Tf3D Need connections: 6, Current: 8, Total: 311
[2017-11-21 08:28:53,788] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:28:53] "GET /Websocket?wrapper_key=96306f3bc4334ca13be5a037162a8326f0fab5c35a0171d495223902a532262e HTTP/1.0" 400 120 0.000862
[2017-11-21 08:28:55,929] DEBUG    ZeronamePlugin Domain db with 2446 entries loaded in 0.016s (modification: None -> 1511161526.37)
[2017-11-21 08:28:55,934] DEBUG    SiteManager Added new site: 1PHyzwGqDQKYFWbJBDX1JqYrp8jyLrzsRL
[2017-11-21 08:28:55,937] DEBUG    Site:1PHyzw..zsRL ContentDb init: 0.000s, found files: 0, sites: 3
[2017-11-21 08:28:55,937] DEBUG    Site:1PHyzw..zsRL ContentDb not initialized, load files from filesystem
[2017-11-21 08:28:55,937] WARNING  Site:1PHyzw..zsRL Content.json not exist: data/1PHyzwGqDQKYFWbJBDX1JqYrp8jyLrzsRL/content.json
[2017-11-21 08:28:55,944] DEBUG    Site:1PHyzw..zsRL New auth key: 7f100447e755c2f305f4d2424911674999c4d9122297cdb2bcf6a32c1435bcec
[2017-11-21 08:28:55,944] DEBUG    Site:1PHyzw..zsRL New wrapper key: 8c7e0ff6e5a2e894ed0324c6abb1a5797537c210f7a01130877d3edb74bc6c9f
[2017-11-21 08:28:55,944] DEBUG    Site:1PHyzw..zsRL New ajax key: 88bba34188c4784f4c1c890076f951c764feacb309e06ffb703de2434bcd5903
[2017-11-21 08:28:55,946] DEBUG    SiteManager Saved sites in 0.00s (generate: 0.00s, write: 0.00s)
[2017-11-21 08:28:55,946] DEBUG    SiteManager Updated merger sites in 0.000s
[2017-11-21 08:28:55,947] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:28:55] "GET /amorgan.bit HTTP/1.0" 200 2893 0.034490
[2017-11-21 08:28:55,947] DEBUG    Site:1PHyzw..zsRL Start downloading, bad_files: {}, check_size: True, blind_includes: True
[2017-11-21 08:28:55,948] DEBUG    Site:1PHyzw..zsRL Need content.json first
[2017-11-21 08:28:55,948] DEBUG    WorkerManager:1PHyzw..zsRL New task: content.json, peer lock: None, priority: 10000, optional_hash_id: None, tasks started: 1
[2017-11-21 08:28:55,948] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 1, peers: 0, workers: 0
[2017-11-21 08:28:55,955] DEBUG    FileServer Conn#18 boot3rdez4rzn36x.onion [?] > Connecting...
[2017-11-21 08:28:55,955] DEBUG    TorManager Creating new Tor socket to boot3rdez4rzn36x.onion:15441
[2017-11-21 08:28:55,955] DEBUG    FileServer Conn#19 zero.booth.moe [?] > Connecting...
[2017-11-21 08:28:55,973] DEBUG    Site:1PHyzw..zsRL Http tracker explodie.org:6969/announce error: 'peers'
[2017-11-21 08:28:56,091] DEBUG    Site:1PHyzw..zsRL Need content.json first
[2017-11-21 08:28:56,242] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 1, peers: 0, workers: 0
[2017-11-21 08:28:56,242] DEBUG    WorkerManager:1PHyzw..zsRL Added worker: 185.107.169.23:15441, workers: 1/5
[2017-11-21 08:28:56,243] DEBUG    WorkerManager:1PHyzw..zsRL Added worker: 173.239.228.11:15441, workers: 2/5
[2017-11-21 08:28:56,243] DEBUG    Site:1PHyzw..zsRL Found 3 peers, new: 2, total: 2
[2017-11-21 08:28:56,243] DEBUG    FileServer Conn#20 185.107.169.23 [?] > Connecting...
[2017-11-21 08:28:56,379] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 1, peers: 0, workers: 2
[2017-11-21 08:28:56,380] DEBUG    WorkerManager:1PHyzw..zsRL Added worker: i3myykweu4yxdtq6.onion:15441, workers: 3/5
[2017-11-21 08:28:56,380] DEBUG    WorkerManager:1PHyzw..zsRL Added worker: 51.15.51.127:15441, workers: 4/5
[2017-11-21 08:28:56,380] DEBUG    Site:1PHyzw..zsRL Found 3 ip4, 1 onion peers, new: 2
[2017-11-21 08:28:56,444] DEBUG    Site:1PHyzw..zsRL 0 peers (0 with hashfield) loaded in 0.000s
[2017-11-21 08:28:56,583] DEBUG    FileServer Conn#20 185.107.169.23 [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 0.340s)...
[2017-11-21 08:28:57,120] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: content.json
[2017-11-21 08:28:57,123] DEBUG    WorkerManager:1PHyzw..zsRL New task: index.html, peer lock: None, priority: 10013, optional_hash_id: None, tasks started: 2
[2017-11-21 08:28:57,124] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 1, peers: 0, workers: 4
[2017-11-21 08:28:57,124] DEBUG    Site:1PHyzw..zsRL content.json loadContent same json file, skipping
[2017-11-21 08:28:57,127] DEBUG    SiteManager Saved sites in 0.00s (generate: 0.00s, write: 0.00s)
[2017-11-21 08:28:57,128] DEBUG    SiteManager Updated merger sites in 0.000s
[2017-11-21 08:28:57,128] DEBUG    Site:1PHyzw..zsRL content.json loadContent same json file, skipping
[2017-11-21 08:28:57,129] DEBUG    SiteManager Saved sites in 0.00s (generate: 0.00s, write: 0.00s)
[2017-11-21 08:28:57,129] DEBUG    SiteManager Updated merger sites in 0.000s
[2017-11-21 08:28:57,130] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/apple-touch-icon-57x57.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 3
[2017-11-21 08:28:57,130] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 2, peers: 0, workers: 4
[2017-11-21 08:28:57,130] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/browserconfig.xml, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 4
[2017-11-21 08:28:57,130] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 3, peers: 0, workers: 4
[2017-11-21 08:28:57,130] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/favicon.ico, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 5
[2017-11-21 08:28:57,130] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 4, peers: 0, workers: 4
[2017-11-21 08:28:57,131] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/favicon-96x96.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 6
[2017-11-21 08:28:57,131] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 5, peers: 0, workers: 4
[2017-11-21 08:28:57,131] DEBUG    WorkerManager:1PHyzw..zsRL New task: stylesheets/stylesheet.css, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 7
[2017-11-21 08:28:57,131] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 6, peers: 0, workers: 4
[2017-11-21 08:28:57,131] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/apple-touch-icon-precomposed.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 8
[2017-11-21 08:28:57,131] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 7, peers: 0, workers: 4
[2017-11-21 08:28:57,132] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/apple-touch-icon-72x72.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 9
[2017-11-21 08:28:57,132] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 8, peers: 0, workers: 4
[2017-11-21 08:28:57,132] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/manifest.json, peer lock: None, priority: 11, optional_hash_id: None, tasks started: 10
[2017-11-21 08:28:57,132] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 9, peers: 0, workers: 4
[2017-11-21 08:28:57,132] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/description, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 11
[2017-11-21 08:28:57,132] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 10, peers: 0, workers: 4
[2017-11-21 08:28:57,133] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/android-chrome-144x144.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 12
[2017-11-21 08:28:57,133] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 11, peers: 0, workers: 4
[2017-11-21 08:28:57,136] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/packed-refs, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 13
[2017-11-21 08:28:57,136] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 12, peers: 0, workers: 4
[2017-11-21 08:28:57,137] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/favicon-32x32.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 14
[2017-11-21 08:28:57,137] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 13, peers: 0, workers: 4
[2017-11-21 08:28:57,137] DEBUG    WorkerManager:1PHyzw..zsRL New task: images/bkg.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 15
[2017-11-21 08:28:57,137] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 14, peers: 0, workers: 4
[2017-11-21 08:28:57,137] DEBUG    WorkerManager:1PHyzw..zsRL New task: pgp.html, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 16
[2017-11-21 08:28:57,137] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 15, peers: 0, workers: 4
[2017-11-21 08:28:57,138] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/info/exclude, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 17
[2017-11-21 08:28:57,138] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 16, peers: 0, workers: 4
[2017-11-21 08:28:57,138] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/mstile-144x144.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 18
[2017-11-21 08:28:57,138] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 17, peers: 0, workers: 4
[2017-11-21 08:28:57,143] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/hooks/pre-commit.sample, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 19
[2017-11-21 08:28:57,143] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 18, peers: 0, workers: 4
[2017-11-21 08:28:57,144] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/hooks/applypatch-msg.sample, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 20
[2017-11-21 08:28:57,144] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 19, peers: 0, workers: 4
[2017-11-21 08:28:57,144] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/android-chrome-36x36.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 21
[2017-11-21 08:28:57,144] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 20, peers: 0, workers: 4
[2017-11-21 08:28:57,144] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/apple-touch-icon-76x76.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 22
[2017-11-21 08:28:57,144] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 21, peers: 0, workers: 4
[2017-11-21 08:28:57,145] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/apple-touch-icon-152x152.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 23
[2017-11-21 08:28:57,145] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 22, peers: 0, workers: 4
[2017-11-21 08:28:57,145] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/hooks/prepare-commit-msg.sample, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 24
[2017-11-21 08:28:57,145] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 23, peers: 0, workers: 4
[2017-11-21 08:28:57,145] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/hooks/post-update.sample, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 25
[2017-11-21 08:28:57,145] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 24, peers: 0, workers: 4
[2017-11-21 08:28:57,146] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/apple-touch-icon-144x144.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 26
[2017-11-21 08:28:57,146] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 25, peers: 0, workers: 4
[2017-11-21 08:28:57,146] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/logs/refs/heads/master, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 27
[2017-11-21 08:28:57,146] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 26, peers: 0, workers: 4
[2017-11-21 08:28:57,146] DEBUG    WorkerManager:1PHyzw..zsRL New task: images/blacktocat.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 28
[2017-11-21 08:28:57,146] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 27, peers: 0, workers: 4
[2017-11-21 08:28:57,147] DEBUG    WorkerManager:1PHyzw..zsRL New task: params.json, peer lock: None, priority: 11, optional_hash_id: None, tasks started: 29
[2017-11-21 08:28:57,147] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 28, peers: 0, workers: 4
[2017-11-21 08:28:57,147] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/refs/remotes/origin/HEAD, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 30
[2017-11-21 08:28:57,147] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 29, peers: 0, workers: 4
[2017-11-21 08:28:57,147] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/refs/heads/master, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 31
[2017-11-21 08:28:57,147] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 30, peers: 0, workers: 4
[2017-11-21 08:28:57,148] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/mstile-310x150.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 32
[2017-11-21 08:28:57,148] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 31, peers: 0, workers: 4
[2017-11-21 08:28:57,148] DEBUG    WorkerManager:1PHyzw..zsRL New task: images/e.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 33
[2017-11-21 08:28:57,148] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 32, peers: 0, workers: 4
[2017-11-21 08:28:57,148] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/hooks/pre-push.sample, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 34
[2017-11-21 08:28:57,148] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 33, peers: 0, workers: 4
[2017-11-21 08:28:57,149] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/favicon-16x16.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 35
[2017-11-21 08:28:57,149] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 34, peers: 0, workers: 4
[2017-11-21 08:28:57,149] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/mstile-70x70.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 36
[2017-11-21 08:28:57,149] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 35, peers: 0, workers: 4
[2017-11-21 08:28:57,149] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/android-chrome-192x192.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 37
[2017-11-21 08:28:57,149] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 36, peers: 0, workers: 4
[2017-11-21 08:28:57,153] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/hooks/pre-rebase.sample, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 38
[2017-11-21 08:28:57,153] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 37, peers: 0, workers: 4
[2017-11-21 08:28:57,154] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/hooks/update.sample, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 39
[2017-11-21 08:28:57,154] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 38, peers: 0, workers: 4
[2017-11-21 08:28:57,154] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/apple-touch-icon.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 40
[2017-11-21 08:28:57,154] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 39, peers: 0, workers: 4
[2017-11-21 08:28:57,157] DEBUG    WorkerManager:1PHyzw..zsRL New task: stylesheets/github-dark.css, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 41
[2017-11-21 08:28:57,157] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 40, peers: 0, workers: 4
[2017-11-21 08:28:57,157] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/objects/pack/pack-e98f27dd449642be2fc1bf5f001ae76b3b79934b.idx, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 42
[2017-11-21 08:28:57,157] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 41, peers: 0, workers: 4
[2017-11-21 08:28:57,157] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/apple-touch-icon-60x60.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 43
[2017-11-21 08:28:57,158] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 42, peers: 0, workers: 4
[2017-11-21 08:28:57,158] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/objects/pack/pack-e98f27dd449642be2fc1bf5f001ae76b3b79934b.pack, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 44
[2017-11-21 08:28:57,158] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 43, peers: 0, workers: 4
[2017-11-21 08:28:57,158] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/logs/refs/remotes/origin/HEAD, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 45
[2017-11-21 08:28:57,158] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 44, peers: 0, workers: 4
[2017-11-21 08:28:57,159] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/mstile-310x310.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 46
[2017-11-21 08:28:57,159] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 45, peers: 0, workers: 4
[2017-11-21 08:28:57,159] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/android-chrome-48x48.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 47
[2017-11-21 08:28:57,159] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 46, peers: 0, workers: 4
[2017-11-21 08:28:57,159] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/config, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 48
[2017-11-21 08:28:57,159] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 47, peers: 0, workers: 4
[2017-11-21 08:28:57,163] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/apple-touch-icon-180x180.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 49
[2017-11-21 08:28:57,163] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 48, peers: 0, workers: 4
[2017-11-21 08:28:57,164] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/logs/HEAD, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 50
[2017-11-21 08:28:57,164] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 49, peers: 0, workers: 4
[2017-11-21 08:28:57,169] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/mstile-150x150.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 51
[2017-11-21 08:28:57,169] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 50, peers: 0, workers: 4
[2017-11-21 08:28:57,169] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/HEAD, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 52
[2017-11-21 08:28:57,169] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 51, peers: 0, workers: 4
[2017-11-21 08:28:57,170] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/hooks/commit-msg.sample, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 53
[2017-11-21 08:28:57,170] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 52, peers: 0, workers: 4
[2017-11-21 08:28:57,170] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/android-chrome-96x96.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 54
[2017-11-21 08:28:57,170] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 53, peers: 0, workers: 4
[2017-11-21 08:28:57,170] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/apple-touch-icon-120x120.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 55
[2017-11-21 08:28:57,170] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 54, peers: 0, workers: 4
[2017-11-21 08:28:57,171] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/hooks/pre-applypatch.sample, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 56
[2017-11-21 08:28:57,171] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 55, peers: 0, workers: 4
[2017-11-21 08:28:57,171] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/apple-touch-icon-114x114.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 57
[2017-11-21 08:28:57,171] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 56, peers: 0, workers: 4
[2017-11-21 08:28:57,171] DEBUG    WorkerManager:1PHyzw..zsRL New task: .git/index, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 58
[2017-11-21 08:28:57,171] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 57, peers: 0, workers: 4
[2017-11-21 08:28:57,172] DEBUG    WorkerManager:1PHyzw..zsRL New task: icons/android-chrome-72x72.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 59
[2017-11-21 08:28:57,172] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 58, peers: 0, workers: 4
[2017-11-21 08:28:57,184] DEBUG    FileServer Conn#21 51.15.51.127 [?] > Connecting...
[2017-11-21 08:28:57,186] DEBUG    FileServer Conn#22 173.239.228.11 [?] > Connecting...
[2017-11-21 08:28:57,190] DEBUG    FileServer Conn#22 173.239.228.11 [?] > Closing connection: 173.239.228.11 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 145 > Connection.py line 113 > _socket2.py line 231, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:28:57,190] DEBUG    WorkerManager:1PHyzw..zsRL 173.239.228.11:15441: Verify failed: index.html, error: Download failed, failed peers: 0, workers: 0
[2017-11-21 08:28:57,357] DEBUG    FileServer Conn#23 173.239.228.11 [?] > Connecting...
[2017-11-21 08:28:57,357] DEBUG    FileServer Conn#24 i3myykweu4yxdtq6.onion [?] > Connecting...
[2017-11-21 08:28:57,357] DEBUG    TorManager Creating new Tor socket to i3myykweu4yxdtq6.onion:15441
[2017-11-21 08:28:57,359] DEBUG    FileServer Conn#23 173.239.228.11 [?] > Closing connection: 173.239.228.11 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 145 > Connection.py line 113 > _socket2.py line 231, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:28:57,410] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: index.html
[2017-11-21 08:28:57,421] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:28:57] "GET /amorgan.bit/?wrapper_nonce=c35c8e89364e8f4289595ab224dee939b6322df4bcc4ac032572b21fdb975914 HTTP/1.0" 200 5719 1.330377
[2017-11-21 08:28:57,483] DEBUG    FileServer Conn#21 51.15.51.127 [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 0.300s)...
[2017-11-21 08:28:57,607] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/manifest.json
[2017-11-21 08:28:58,191] DEBUG    FileServer Conn#25 173.239.228.11 [?] > Connecting...
[2017-11-21 08:28:58,194] DEBUG    FileServer Conn#25 173.239.228.11 [?] > Closing connection: 173.239.228.11 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 145 > Connection.py line 113 > _socket2.py line 231, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:28:58,195] DEBUG    WorkerManager:1PHyzw..zsRL 173.239.228.11:15441: Verify failed: stylesheets/stylesheet.css, error: Download failed, failed peers: 0, workers: 0
[2017-11-21 08:28:58,687] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: params.json
[2017-11-21 08:28:58,868] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: stylesheets/stylesheet.css
[2017-11-21 08:28:58,870] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:28:58] "GET /amorgan.bit/stylesheets/stylesheet.css HTTP/1.0" 200 4798 1.235468
[2017-11-21 08:28:59,003] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: stylesheets/github-dark.css
[2017-11-21 08:28:59,007] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:28:59] "GET /amorgan.bit/stylesheets/github-dark.css HTTP/1.0" 200 2985 1.371288
[2017-11-21 08:28:59,196] DEBUG    FileServer Conn#26 173.239.228.11 [?] > Connecting...
[2017-11-21 08:28:59,199] DEBUG    FileServer Conn#26 173.239.228.11 [?] > Closing connection: 173.239.228.11 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 145 > Connection.py line 113 > _socket2.py line 231, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:28:59,199] DEBUG    WorkerManager:1PHyzw..zsRL 173.239.228.11:15441: Verify failed: images/blacktocat.png, error: Download failed, failed peers: 0, workers: 0
[2017-11-21 08:28:59,257] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: images/bkg.png
[2017-11-21 08:28:59,259] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:28:59] "GET /amorgan.bit/images/bkg.png HTTP/1.0" 200 1483 0.211680
[2017-11-21 08:28:59,301] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: icons/apple-touch-icon-57x57.png
[2017-11-21 08:28:59,434] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: images/blacktocat.png
[2017-11-21 08:28:59,438] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:28:59] "GET /amorgan.bit/images/blacktocat.png HTTP/1.0" 200 532 0.385516
[2017-11-21 08:28:59,605] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/browserconfig.xml
[2017-11-21 08:28:59,777] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/favicon-96x96.png
[2017-11-21 08:28:59,797] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: icons/favicon.ico
[2017-11-21 08:28:59,949] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/apple-touch-icon-precomposed.png
[2017-11-21 08:29:00,022] DEBUG    FileServer Conn#27 110.163.135.123 [?] > Connecting...
[2017-11-21 08:29:00,093] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: icons/apple-touch-icon-72x72.png
[2017-11-21 08:29:00,120] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: .git/description
[2017-11-21 08:29:00,200] DEBUG    FileServer Conn#28 173.239.228.11 [?] > Connecting...
[2017-11-21 08:29:00,202] DEBUG    FileServer Conn#28 173.239.228.11 [?] > Closing connection: 173.239.228.11 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 145 > Connection.py line 113 > _socket2.py line 231, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:29:00,203] DEBUG    WorkerManager:1PHyzw..zsRL 173.239.228.11:15441: Verify failed: icons/favicon-32x32.png, error: Download failed, failed peers: 0, workers: 0
[2017-11-21 08:29:00,307] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: .git/packed-refs
[2017-11-21 08:29:00,337] DEBUG    Site:1PHyzw..zsRL Announced types ['ip4'] in mode start to 7 trackers in 4.389s, errors: ['http://explodie.org:6969/announce'], slow: ['4.39s zero://boot3rdez4rzn36x.onion:15441', '1.39s http://tracker1.wasabii.com.tw:6969/announce']
[2017-11-21 08:29:00,390] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: icons/android-chrome-144x144.png
[2017-11-21 08:29:00,478] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/favicon-32x32.png
[2017-11-21 08:29:00,514] DEBUG    FileServer Conn#29 6vdlv5h2w3mrc6lx.onion [?] > Connecting...
[2017-11-21 08:29:00,515] DEBUG    TorManager Creating new Tor socket to 6vdlv5h2w3mrc6lx.onion:15441
[2017-11-21 08:29:00,668] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: .git/info/exclude
[2017-11-21 08:29:00,685] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: pgp.html
[2017-11-21 08:29:00,708] DEBUG    WorkerManager:1PHyzw..zsRL Starting workers, tasks: 39, peers: 0, workers: 4
[2017-11-21 08:29:00,708] DEBUG    WorkerManager:1PHyzw..zsRL Added worker: 127.0.0.1:49212, workers: 5/5
[2017-11-21 08:29:00,708] DEBUG    WorkerManager:1PHyzw..zsRL Added worker: 127.0.0.1:53191, workers: 6/5
[2017-11-21 08:29:00,708] DEBUG    Site:1PHyzw..zsRL Queried pex from 2 peers got 4 new peers.
[2017-11-21 08:29:00,708] DEBUG    FileServer Conn#30 127.0.0.1    [?] > Connecting...
[2017-11-21 08:29:00,709] DEBUG    FileServer Conn#30 127.0.0.1    [?] > Closing connection: 127.0.0.1 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 145 > Connection.py line 113 > _socket2.py line 231, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:29:00,710] DEBUG    WorkerManager:1PHyzw..zsRL 127.0.0.1:49212: Verify failed: .git/hooks/applypatch-msg.sample, error: Download failed, failed peers: 0, workers: 0
[2017-11-21 08:29:00,710] DEBUG    WorkerManager:1PHyzw..zsRL 127.0.0.1:53191: Verify failed: icons/android-chrome-36x36.png, error: Download failed, failed peers: 0, workers: 0
[2017-11-21 08:29:00,840] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/mstile-144x144.png
[2017-11-21 08:29:00,983] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: .git/hooks/pre-commit.sample
[2017-11-21 08:29:01,011] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/android-chrome-36x36.png
[2017-11-21 08:29:01,182] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/apple-touch-icon-152x152.png
[2017-11-21 08:29:01,204] DEBUG    FileServer Conn#31 173.239.228.11 [?] > Connecting...
[2017-11-21 08:29:01,207] DEBUG    FileServer Conn#31 173.239.228.11 [?] > Closing connection: 173.239.228.11 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 145 > Connection.py line 113 > _socket2.py line 231, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:29:01,207] DEBUG    WorkerManager:1PHyzw..zsRL 173.239.228.11:15441: Verify failed: .git/hooks/post-update.sample, error: Download failed, failed peers: 0, workers: 0
[2017-11-21 08:29:01,207] DEBUG    WorkerManager:1PHyzw..zsRL Removed worker, workers: 5/5
[2017-11-21 08:29:01,281] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: icons/apple-touch-icon-76x76.png
[2017-11-21 08:29:01,307] DEBUG    FileServer Conn#27 110.163.135.123 [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 1.285s)...
[2017-11-21 08:29:01,371] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: .git/hooks/prepare-commit-msg.sample
[2017-11-21 08:29:01,543] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/apple-touch-icon-144x144.png
[2017-11-21 08:29:01,620] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: .git/hooks/post-update.sample
[2017-11-21 08:29:01,710] DEBUG    FileServer Conn#32 127.0.0.1    [?] > Connecting...
[2017-11-21 08:29:01,711] DEBUG    FileServer Conn#32 127.0.0.1    [?] > Closing connection: 127.0.0.1 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 145 > Connection.py line 113 > _socket2.py line 231, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:29:01,712] DEBUG    WorkerManager:1PHyzw..zsRL 127.0.0.1:49212: Verify failed: .git/refs/heads/master, error: Download failed, failed peers: 0, workers: 0
[2017-11-21 08:29:01,712] DEBUG    WorkerManager:1PHyzw..zsRL 127.0.0.1:53191: Verify failed: icons/mstile-310x150.png, error: Download failed, failed peers: 0, workers: 0
[2017-11-21 08:29:01,726] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: .git/logs/refs/heads/master
[2017-11-21 08:29:01,897] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/mstile-310x150.png
[2017-11-21 08:29:01,964] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: .git/refs/remotes/origin/HEAD
[2017-11-21 08:29:02,256] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: images/e.png
[2017-11-21 08:29:02,303] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: .git/hooks/pre-push.sample
[2017-11-21 08:29:02,427] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/favicon-16x16.png
[2017-11-21 08:29:02,600] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: icons/mstile-70x70.png
[2017-11-21 08:29:02,601] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/android-chrome-192x192.png
[2017-11-21 08:29:02,713] DEBUG    FileServer Conn#33 127.0.0.1    [?] > Connecting...
[2017-11-21 08:29:02,714] DEBUG    FileServer Conn#33 127.0.0.1    [?] > Closing connection: 127.0.0.1 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 145 > Connection.py line 113 > _socket2.py line 231, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:29:02,714] DEBUG    WorkerManager:1PHyzw..zsRL 127.0.0.1:49212: Verify failed: icons/apple-touch-icon.png, error: Download failed, failed peers: 0, workers: 0
[2017-11-21 08:29:02,715] DEBUG    WorkerManager:1PHyzw..zsRL 127.0.0.1:53191: Verify failed: .git/objects/pack/pack-e98f27dd449642be2fc1bf5f001ae76b3b79934b.idx, error: Download failed, failed peers: 0, workers: 0
[2017-11-21 08:29:02,794] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: .git/hooks/update.sample
[2017-11-21 08:29:02,896] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: .git/hooks/pre-rebase.sample
[2017-11-21 08:29:02,976] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: .git/objects/pack/pack-e98f27dd449642be2fc1bf5f001ae76b3b79934b.idx
[2017-11-21 08:29:03,193] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: icons/apple-touch-icon-60x60.png
[2017-11-21 08:29:03,501] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: .git/objects/pack/pack-e98f27dd449642be2fc1bf5f001ae76b3b79934b.pack
[2017-11-21 08:29:03,533] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: .git/logs/refs/remotes/origin/HEAD
[2017-11-21 08:29:03,672] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/mstile-310x310.png
[2017-11-21 08:29:03,715] DEBUG    FileServer Conn#34 127.0.0.1    [?] > Connecting...
[2017-11-21 08:29:03,716] DEBUG    FileServer Conn#34 127.0.0.1    [?] > Closing connection: 127.0.0.1 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 145 > Connection.py line 113 > _socket2.py line 231, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:29:03,716] DEBUG    WorkerManager:1PHyzw..zsRL 127.0.0.1:49212: Verify failed: icons/apple-touch-icon-180x180.png, error: Download failed, failed peers: 0, workers: 0
[2017-11-21 08:29:03,716] DEBUG    WorkerManager:1PHyzw..zsRL 127.0.0.1:53191: Verify failed: .git/logs/HEAD, error: Download failed, failed peers: 0, workers: 0
[2017-11-21 08:29:03,829] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: icons/android-chrome-48x48.png
[2017-11-21 08:29:03,843] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: .git/config
[2017-11-21 08:29:04,013] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/mstile-150x150.png
[2017-11-21 08:29:04,176] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: .git/logs/HEAD
[2017-11-21 08:29:04,184] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: .git/HEAD
[2017-11-21 08:29:04,355] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/android-chrome-96x96.png
[2017-11-21 08:29:04,513] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: .git/hooks/commit-msg.sample
[2017-11-21 08:29:04,526] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/apple-touch-icon-120x120.png
[2017-11-21 08:29:04,698] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/apple-touch-icon-114x114.png
[2017-11-21 08:29:04,717] DEBUG    FileServer Conn#35 127.0.0.1    [?] > Connecting...
[2017-11-21 08:29:04,718] DEBUG    FileServer Conn#35 127.0.0.1    [?] > Closing connection: 127.0.0.1 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 145 > Connection.py line 113 > _socket2.py line 231, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:29:04,718] DEBUG    WorkerManager:1PHyzw..zsRL 127.0.0.1:49212: Verify failed: icons/android-chrome-72x72.png, error: Download failed, failed peers: 0, workers: 0
[2017-11-21 08:29:04,718] DEBUG    WorkerManager:1PHyzw..zsRL 127.0.0.1:53191: Verify failed: .git/hooks/applypatch-msg.sample, error: Download failed, failed peers: 1, workers: 0
[2017-11-21 08:29:04,850] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: .git/hooks/pre-applypatch.sample
[2017-11-21 08:29:04,869] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: .git/index
[2017-11-21 08:29:05,039] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: .git/refs/heads/master
[2017-11-21 08:29:05,186] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: .git/hooks/applypatch-msg.sample
[2017-11-21 08:29:05,211] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/apple-touch-icon.png
[2017-11-21 08:29:05,382] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: Verify correct: icons/android-chrome-72x72.png
[2017-11-21 08:29:05,482] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: Verify correct: icons/apple-touch-icon-180x180.png
[2017-11-21 08:29:05,583] DEBUG    WorkerManager:1PHyzw..zsRL 51.15.51.127:15441: No task found, stopping
[2017-11-21 08:29:05,583] DEBUG    WorkerManager:1PHyzw..zsRL Removed worker, workers: 4/5
[2017-11-21 08:29:05,583] DEBUG    WorkerManager:1PHyzw..zsRL Check compelte: No tasks
[2017-11-21 08:29:05,585] DEBUG    WorkerManager:1PHyzw..zsRL 185.107.169.23:15441: No task found, stopping
[2017-11-21 08:29:05,585] DEBUG    WorkerManager:1PHyzw..zsRL Removed worker, workers: 3/5
[2017-11-21 08:29:05,820] DEBUG    WorkerManager:1PHyzw..zsRL 127.0.0.1:49212: No task found, stopping
[2017-11-21 08:29:05,821] DEBUG    WorkerManager:1PHyzw..zsRL Removed worker, workers: 2/5
[2017-11-21 08:29:05,821] DEBUG    WorkerManager:1PHyzw..zsRL 127.0.0.1:53191: No task found, stopping
[2017-11-21 08:29:05,821] DEBUG    WorkerManager:1PHyzw..zsRL Removed worker, workers: 1/5
[2017-11-21 08:29:06,673] DEBUG    Site:1Name2..hM9F Queried listModifications from: [<Peer:j72smro7nhn3gnlc.onion>, <Peer:185.107.169.23>, <Peer:110.163.135.123>] in 20.002s
[2017-11-21 08:29:06,678] DEBUG    FileServer Conn#36 110.10.176.45 [?] > Connecting...
[2017-11-21 08:29:06,679] DEBUG    FileServer Conn#37 41.104.151.194 [?] > Connecting...
[2017-11-21 08:29:06,775] DEBUG    Site:1Name2..hM9F content.json loadContent same json file, skipping
[2017-11-21 08:29:06,775] DEBUG    Site:1Name2..hM9F Need connections: 6, Current: 9, Total: 408
[2017-11-21 08:29:06,899] DEBUG    FileServer Conn#37 41.104.151.194 [?] > Closing connection: 41.104.151.194 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 145 > Connection.py line 113 > _socket2.py line 231, waiting_requests: 0, sites: 1, buff: 0...
[2017-11-21 08:29:06,899] DEBUG    FileServer Conn#38 e5xo7qfmwpqjkbs5.onion [?] > Connecting...
[2017-11-21 08:29:06,899] DEBUG    TorManager Creating new Tor socket to e5xo7qfmwpqjkbs5.onion:15441
[2017-11-21 08:29:06,983] DEBUG    FileServer Conn#36 110.10.176.45 [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 0.305s)...
[2017-11-21 08:29:07,185] DEBUG    Site:1PHyzw..zsRL Queried listModifications from: [<Peer:185.107.169.23>, <Peer:185.107.169.23>, <Peer:51.15.51.127>] in 10.002s
[2017-11-21 08:29:10,949] DEBUG    WorkerManager:1PHyzw..zsRL i3myykweu4yxdtq6.onion:15441: Force skipping
[2017-11-21 08:29:11,050] DEBUG    WorkerManager:1PHyzw..zsRL i3myykweu4yxdtq6.onion:15441: No task found, stopping
[2017-11-21 08:29:11,051] DEBUG    WorkerManager:1PHyzw..zsRL Removed worker, workers: 0/5
[2017-11-21 08:29:11,152] DEBUG    WorkerManager:1PHyzw..zsRL i3myykweu4yxdtq6.onion:15441: No task found, stopping
[2017-11-21 08:29:11,479] DEBUG    FileServer Conn# 9 2xn22t66nl6p5da3.onion [?] > Closing connection: [Cleanup] Connect timeout: 24.802s, waiting_requests: 0, sites: 1, buff: 0...
[2017-11-21 08:29:11,480] DEBUG    FileServer Conn#10 181.176.86.170 [?] > Closing connection: [Cleanup] Connect timeout: 24.802s, waiting_requests: 0, sites: 2, buff: 0...
[2017-11-21 08:29:11,480] DEBUG    FileServer Conn#11 45.40.85.35  [?] > Closing connection: [Cleanup] Connect timeout: 24.221s, waiting_requests: 0, sites: 1, buff: 0...
[2017-11-21 08:29:11,480] DEBUG    FileServer Conn#12 27.189.77.53 [?] > Closing connection: [Cleanup] Connect timeout: 23.807s, waiting_requests: 0, sites: 2, buff: 0...
[2017-11-21 08:29:11,480] DEBUG    FileServer Conn#13 71.54.138.21 [?] > Closing connection: [Cleanup] Connect timeout: 23.807s, waiting_requests: 0, sites: 2, buff: 0...
[2017-11-21 08:29:11,481] DEBUG    FileServer Conn#14 108.61.164.133 [?] > Closing connection: [Cleanup] Connect timeout: 21.808s, waiting_requests: 0, sites: 1, buff: 0...
[2017-11-21 08:29:11,481] DEBUG    FileServer Conn#24 i3myykweu4yxdtq6.onion [?] > Closing connection: [Cleanup] Connect timeout: 14.123s, waiting_requests: 0, sites: 1, buff: 0...
[2017-11-21 08:29:11,482] DEBUG    FileServer Conn#39 112.20.104.0 [?] > Connecting...
[2017-11-21 08:29:11,487] DEBUG    FileServer Conn#40 i7ruayarmwebvn6e.onion [?] > Connecting...
[2017-11-21 08:29:11,487] DEBUG    TorManager Creating new Tor socket to i7ruayarmwebvn6e.onion:15441
[2017-11-21 08:29:13,091] DEBUG    FileServer Conn#41 114.252.115.158 [?] > Connecting...
[2017-11-21 08:29:26,482] DEBUG    FileServer Conn#18 boot3rdez4rzn36x.onion [v2] > Closing connection: [Cleanup] Tracker connection: 26.1451160908, waiting_requests: 0, sites: 1, buff: 0...
[2017-11-21 08:29:26,484] DEBUG    FileServer Conn#39 112.20.104.0 [?] > Closing connection: [Cleanup] Connect timeout: 15.002s, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:29:26,558] DEBUG    FileServer Conn#41 114.252.115.158 [?] > Closing connection: [Cleanup] Connect timeout: 13.467s, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:29:26,558] DEBUG    FileServer Connection cleanup in 0.077s
[2017-11-21 08:29:26,560] DEBUG    FileServer Conn#42 175.13.178.163 [?] > Connecting...
[2017-11-21 08:29:26,561] DEBUG    FileServer Conn#43 183.240.19.46 [?] > Connecting...
[2017-11-21 08:29:37,694] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:29:37] "GET /Websocket?wrapper_key=8c7e0ff6e5a2e894ed0324c6abb1a5797537c210f7a01130877d3edb74bc6c9f HTTP/1.0" 400 120 0.003464
[2017-11-21 08:29:41,560] DEBUG    FileServer Conn#19 zero.booth.moe [v2] > Closing connection: [Cleanup] Tracker connection: 45.1805040836, waiting_requests: 0, sites: 1, buff: 0...
[2017-11-21 08:29:41,661] DEBUG    FileServer Conn#42 175.13.178.163 [?] > Closing connection: [Cleanup] Connect timeout: 15.100s, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:29:41,661] DEBUG    FileServer Conn#43 183.240.19.46 [?] > Closing connection: [Cleanup] Connect timeout: 15.100s, waiting_requests: 0, sites: 0, buff: 0...
[2017-11-21 08:29:41,662] DEBUG    FileServer Connection cleanup in 0.102s
[2017-11-21 08:29:41,664] DEBUG    FileServer Conn#44 192.241.219.63 [?] > Connecting...
[2017-11-21 08:29:41,667] DEBUG    FileServer Conn#45 47.198.155.239 [?] > Connecting...
[2017-11-21 08:29:41,678] DEBUG    FileServer Conn#44 192.241.219.63 [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 0.014s)...
[2017-11-21 08:29:41,700] DEBUG    Site:1HeLLo..Tf3D Queried pex from 2 peers got 9 new peers.
[2017-11-21 08:29:41,859] DEBUG    FileServer Conn#45 47.198.155.239 [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 0.191s)...
[2017-11-21 08:29:42,154] DEBUG    Site:1Name2..hM9F Queried pex from 2 peers got 3 new peers.
[2017-11-21 08:29:54,097] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:29:54] "GET /Websocket?wrapper_key=96306f3bc4334ca13be5a037162a8326f0fab5c35a0171d495223902a532262e HTTP/1.0" 400 120 0.002182
[2017-11-21 08:30:37,780] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:30:37] "GET /Websocket?wrapper_key=8c7e0ff6e5a2e894ed0324c6abb1a5797537c210f7a01130877d3edb74bc6c9f HTTP/1.0" 400 120 0.001626
[2017-11-21 08:30:54,195] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:30:54] "GET /Websocket?wrapper_key=96306f3bc4334ca13be5a037162a8326f0fab5c35a0171d495223902a532262e HTTP/1.0" 400 120 0.000874
[2017-11-21 08:31:37,886] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:31:37] "GET /Websocket?wrapper_key=8c7e0ff6e5a2e894ed0324c6abb1a5797537c210f7a01130877d3edb74bc6c9f HTTP/1.0" 400 120 0.002124
[2017-11-21 08:31:54,389] DEBUG    Ui.UiServer 127.0.0.1 - - [2017-11-21 08:31:54] "GET /Websocket?wrapper_key=96306f3bc4334ca13be5a037162a8326f0fab5c35a0171d495223902a532262e HTTP/1.0" 400 120 0.002193
[2017-11-21 08:32:26,418] ERROR    - Unhandled exception
None
[2017-11-21 08:32:26,427] DEBUG    Ui.UiServer Stopping...
[2017-11-21 08:32:26,428] DEBUG    Ui.UiServer Socket closed: 0
[2017-11-21 08:32:26,430] DEBUG    FileServer Stopped.
[2017-11-21 08:32:26,529] DEBUG    Ui.UiServer Stopped.
[2017-11-21 08:32:26,542] DEBUG    SiteManager Saved sites in 0.00s (generate: 0.01s, write: 0.00s)
[2017-11-21 08:32:26,542] DEBUG    SiteManager Updated merger sites in 0.000s
[2017-11-21 08:32:26,548] DEBUG    Site:1Name2..hM9F Peers saved in 0.006s
[2017-11-21 08:32:26,549] DEBUG    Site:1PHyzw..zsRL Peers saved in 0.000s
[2017-11-21 08:32:26,553] DEBUG    Site:1HeLLo..Tf3D Peers saved in 0.004s
```

Most notably seems to be the following line:
```
FileServer Conn#15 185.170.42.18 [?] > Closing connection: 185.170.42.18 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 145 > Connection.py line 113 > _socket2.py line 231, waiting_requests: 0, sites: 0, buff: 0...
```

The IP/Port number might be messed up?

FWIW, to reproduce this I simply:

* Cloned ZeroNet
* Created [this](https://gist.github.com/anoadragon453/66ffc84adac9b97a8148b5f29d0f744c) zeronet.conf file
* Ran `python zeronet.py`

And set up nginx to proxy all traffic to port 4990 with the following in my website conf:

```
# Zeronet Proxy
    location / {
        proxy_pass http://localhost:4990;
        proxy_set_header X-Forwarded-For $remote_addr;
    }
```

The WebUI will load, download a tiny bit of data, then crash.

![2017-11-21-003949](https://user-images.githubusercontent.com/1342360/33062551-892053e2-ce54-11e7-8dd4-f07003b878a5.png)
 Wow, those headers completely fixed my problem.

Now with:

```
Â Â Â  # Zeronet Proxy

Â Â Â  location / {
Â Â Â Â Â Â Â  proxy_pass http://localhost:4990;
Â Â Â Â Â Â Â  proxy_set_header X-Forwarded-For $remote_addr;
Â Â Â Â Â Â Â  proxy_set_header Host $host; #get rid of media referrer error
Â Â Â Â Â Â Â  proxy_http_version 1.1;
Â Â Â Â Â Â Â  proxy_read_timeout 1h; #for long live websocket connetion
Â Â Â Â Â Â Â  proxy_set_header Upgrade $http_upgrade;
Â Â Â Â Â Â Â  proxy_set_header Connection "upgrade";
Â Â Â  }
```

Everything just works! Thank you very much!


On 11/21/2017 12:57 AM, ZeroNet wrote:
> |proxy_pass http://0.0.0.0:43110; proxy_set_header Host $host; #get rid
> of media referrer error proxy_http_version 1.1; proxy_read_timeout 1h;
> #for long live websocket connetion proxy_set_header Upgrade
> $http_upgrade; proxy_set_header Connection "upgrade";|

 Alright, it finally fixed... thanks for the help!
I realized the real problem is `add_header X-Frame-Options DENY;` in my Nginx config file after I referenced [this](https://github.com/HelloZeroNet/ZeroNet/issues/711#issuecomment-270264374). I used to deny the X-frame function for security concerns, and it is a part of my SSL config that I left unchanged and works well for various applications. I don't know why ZeroNet uses X-Frame Options, but I do think this could be a **potential vulnerability** (although I am not an expert in this). See [this](https://www.owasp.org/index.php/Clickjacking).  This is a proposal.

ZeroNet has an "onion pooling" feature, creating "fake" identities to resist some basic fingerprinting attacks. There is a safer way to do this -- Stealth or Basic Authentication.

https://lists.torproject.org/pipermail/tor-talk/2017-November/043797.html

Use _basic_ authentication, so that you don't need to generate additional RSA keys. For basic authentication, the acceptable passwords can be the addresses of the sites which the onion service claims to be hosting.

> \>\>\> Hosting?
> I host `addr_1`, `addr_2` and `addr_3`.
> \>\>\> Give me some `addr_4` stuff!
> Authentication failed. Access denied.

There is certainly "implementation overhead." I recommend you use the `stem` control library. Fun fact: [it does not need any dependency](https://stem.torproject.org/faq.html#does-stem-have-any-dependencies) if you don't use its fanciest features.

API for creating these authenticated onion services: [`stem.control.Controller.create_ephemeral_hidden_service`](https://stem.torproject.org/api/control.html#stem.control.Controller.create_ephemeral_hidden_service)  Sorry, it's already done.  Fixes #1182. Also allows simple curl requests. @HelloZeroNet ! And what about fixing #1182 then?! @HelloZeroNet This makes sense. I asked @jarodlee about their OS/browser. a brief google says its a PUP, so its probably a good thing that it gets blocked @MuxZeroNet said that this happens even on Internet Explorer - [An old post about this](https://blogs.msdn.microsoft.com/ieinternals/2009/07/01/ie-and-the-accept-header/) - so maybe we need another way to detect if this is `img` or a link. @HelloZeroNet 
>Not sure what is "2345Explorer/8.8.3.16721"

It's a web browser owned by `baidu.com`  When i create a new blank site, from "zerohello" -> "create new, empty site"
I then sign the site, when I try to access the newly created site from another computer, it says "no peers found"

I can not publish any new sites I create. Is there somthing i am missing? Have you tried advertising your site? :smile:  @HelloZeroNet, I have the port open and pointing on one of the computers, but both of the computers are on the same network.

Edit I shared it publicly, like @MuxZeroNet suggested, and now it works ;) Ah okay, thank you for the help :)  Since the middle of the year I'm talking to ZeroNet about the worst bug here, but I'm being ignored.
Is intentional of some open-source project's maintainers to left security issues?!
https://github.com/HelloZeroNet/ZeroNet/issues/1016 I understand this problem as well. On the other hand, I have no ideas how to solve this and don't break anything. Maybe you can try to fix this for yourself and then merge it to upstream? The best developers of ZeroNet can't do it because the owners of world are prohibiting it.
Also, ZeroNet and his security isn't for ME, but for ALL THE USERS, so why is just me to fix a error that isn't related just to me? https://github.com/imachug/ZeroNet/commit/3ae2cd53986be2724a334754aa06f47cf7a5b2af Right now I understand my problem. I lower by 10, right? Before I switched back to `master` branch, sites weren't loaded. So there are too many 404. @Plasmmer Firstly, you need to give substantial proof. You have not done so as far as I'm aware.
Secondly, if there is an issue, propose a way to fix it *that actually works*.
Thirdly, stop being a jerk. Things aren't going to get fixed with the type of tone you have when speaking to people. Especially since you tend to *overexagerate* a lot.
Next, don't jump to conclusions just because your "being ignored". This ties in with "stop being a jerk" from above. I'm talking about these assumptions you made: "because the owners of the world are prohibiting it" and "Is intentional of some open-source project's maintainers to left security issues?!". 

No wonder your being ignored (if you actually are being ignored). No one wants to talk to someone who is overly suspicious *with nothing to back up their claims* who tends to overexagerate and is a jerk when talking to people. @krixano Strange, but I have something to argue now. I can't give you an example, but it the problem exists. I often create a site, then publish it to proxy and give a link to somebody. You know what's happening? After I publish, nothing changes: neither on proxy, neither on new peer's computer. That doesn't happen for ALL sites, but it does happen for SOME sites.

Though I agree that @Plasmmer should at least propose a *working* way to fix it. I've tried to add what he wanted (I even didn't lower by 20, I changed by 10), but from there I didn't receive any updates - there are too many errors peers send, so my change just blocked everybody. @imachug I've only ever had that problem when the file being transferred was big (1MB or more). And that is just because it needs to download the file before it can use it. After waiting till it's downloaded, then it updates. I had this problem with ZeroMedium because the whole zite is over 1MB and my network's upload speed is *extremely* slow. @HelloZeroNet That was quite long ago, so I think you've already fixed this. Also, this might be relevant here: https://www.reddit.com/r/programminghorror/comments/7cmajw/newbie_reported_network_issue_as_the_worst/

Do community guidelines prohibit such issues from being edited by the moderators?  Adding Slovak translation (sk.json)  I am trying to upload a file in a merger site but it doesn't seems to be able to do it.

`file_info = self.site.content_manager.getFileInfo(inner_path)` this line is indicated as the faulty one. `getFileInfo` return false. I have added this api in `MergerSitePlugin.py`
```
   def actionBigfileUploadInit(self, to, inner_path, *args, **kwargs):
        return self.mergerFuncWrapper("actionBigfileUploadInit", to, inner_path, *args, **kwargs)
```

It is able to upload the file. I have updated my version. I confirm it is working well.
Thank you.  `pice_size`: Should this be 'piece_size' instead?

https://github.com/HelloZeroNet/ZeroNet/blob/00b6842f355c4ac82fa99f1910533e7e49eb471d/plugins/Bigfile/BigfilePlugin.py#L147  I've found nothing in the docs, a simple python script maybe usefull. Ok thanks but in this way i must download the site, i can't only check the peers number.
Or i wrong something?  i like the idea, but because many media objects are either optional files or possibly porn, media file display should be opt-in per site.  Added proper hyphenation and changed OSX to OS X @HelloZeroNet True true. Would change but it appears I already deleted my merging brach :thumbsup:  After adding the "All, Comment, Topic, Post, Mention" categories the search doesn't work anymore, because whenever you put something in the search bar it always keeps loading without showing the actual results. Was tested several times over several days since that update.
 It works now!  > http://127.0.0.1:43110/Me.ZeroNetwork.bit/?Post/12h51ug6CcntU2aiBjhP8Ns2e5VypbWWtv/12gAes6NzDS9E2q6Q1UXrpUdbPS6nvuBPu/1509344044

```
Ignored call to 'confirm()'. The document is sandboxed, and the 'allow-modals' keyword is not set.
```

I want built-in modals, I don't want simulated modals.  
Can not be updated automatically
Can not be updated automatically
Can not be updated automatically
Can not be updated automatically
Can not be updated automatically ????? 
zeronet can not update itself can you provide any more info than one sentence repeated 7 times? Zeronet just can not update ah I do not know what happened.
I have not used the computer for a few days cause something, these days I was driving zeronet every day.But it can not be updated and can not connect to the node 
Maybe my network is not in good condition  window 7  and  chrome browser   what message? @kkkkketsu Are you from China? If you are, zeronet.io was blocked a few days ago, and ZeroNet uses that host to update. Though I thought that @HelloZeroNet changed address.

BTW, @HelloZeroNet, actionServerUpdate sets `update_after_shutdown` to true, but I cannot find this variable used anywhere else. What does it mean then? Maybe I did not make it clear that you were all wrong.
I should say that my zeronet contents can not be updated. It can not connect to the node, and can not receive the content.
I really come from China, but there are other people in China are also using zeronet.
Why did they not have this problem? But This Is An Regression, We Always Update Auto In ZeroNet, So The Clear Web Is Not Automatically Update Always Manually @kkkkketsu Please provide more information so that we can track this issue.
> **Observed Results:**
> What happened? This could be a screenshot, a description, log output (you can send log/debug.log file to hello@zeronet.io if necessary), etc.
 Another problem is that I did not open the port 15441 and I can not open this port. 
Maybe this is the reason I can not receive new zeronet messages. If you have the log file, you can send it to the developer <hello@zeronet.io> so that he can pinpoint the issue for you.

--
0AD8 D7E9 DCD9 5A10 5BA6 A111 6CC6 5FB9 1CE3 9BB5


      ```
[20:22:17] SiteManager Saved sites in 0.17s (generate: 0.00s, write: 0.17s)
[20:22:17] SiteManager Updated merger sites in 0.001s
[20:22:17] Site:1Nse6W..bCUy Deleting files from content.json...
[20:22:20] Site:1Nse6W..bCUy Loaded json: 100 (latest: data/users/1AuZm3GJNEjCpos2o1jGpBMMESVD6HoKNb/content.json)
[20:22:23] Site:1Nse6W..bCUy Loaded json: 200 (latest: data/users/1NtmpGU6qsCjdgHnJfH6sqd9T1e218BEDA/content.json)
[20:22:27] Site:1Nse6W..bCUy Loaded json: 300 (latest: data/users/13EcWBVSknkf9riZSPAZU3txtLhi1iFTxv/content.json)
[20:22:31] Site:1Nse6W..bCUy Loaded json: 400 (latest: data/users/17f64SjwxAqW34g1knWK8Np3bRetSHZZur/content.json)
[20:22:35] Site:1Nse6W..bCUy Loaded json: 500 (latest: data/users/1BUeUfHV5u29pFxovYfEfBdfZAaKDc6wpd/content.json)
[20:22:38] Site:1Nse6W..bCUy Loaded json: 600 (latest: data/users/14eUCVpQR3kAgx1MAps9VFtUUofLGmZZ1S/content.json)
[20:22:41] Site:1Nse6W..bCUy Loaded json: 700 (latest: data/users/1LZzxKdbygD4K1u8qeoLpN2kp7tCWY3BHW/content.json)
[20:22:45] Site:1Nse6W..bCUy Loaded json: 800 (latest: data/users/18GVhFq7iTRQHqqVRT5CipRkhWFoc4Tahi/content.json)
[20:22:47] Site:1Nse6W..bCUy Loaded json: 900 (latest: data/users/1DCaahetWrggu37aPsZwyXgwcvKRzx1zip/content.json)
[20:22:50] Site:1Nse6W..bCUy Loaded json: 1000 (latest: data/users/1GEfdZ7AyiBeEj8341JU5yZrCWCCczGDg5/content.json)
[20:22:53] Site:1Nse6W..bCUy Loaded json: 1100 (latest: data/users/1PKNvEdchbcRLGFcnC5i8NynuVivAfK7W/content.json)
[20:22:56] Site:1Nse6W..bCUy Loaded json: 1200 (latest: data/users/1KHRVkkqCFHDsGsfbpur4NTYaqfoxuMCEB/content.json)
[20:22:59] Site:1Nse6W..bCUy Loaded json: 1300 (latest: data/users/1K5E7pZZuKAHGHN7Mn4L4yfyXgHdZxUySs/content.json)
[20:23:02] Site:1Nse6W..bCUy Loaded json: 1400 (latest: data/users/1LTbyAkCarDCq7jtcEHXptbJwRE8TpKJSQ/content.json)
[20:23:04] Site:1Nse6W..bCUy Loaded json: 1500 (latest: data/users/13ARcZ9svp3y5XZZCr4ZJzhoSCTR2xSaDW/content.json)
[20:23:09] Site:1Nse6W..bCUy Loaded json: 1600 (latest: data/users/1J8gSmYVtns2ezWCEbX4u5RGzYVrKRc3E3/content.json)
[20:23:13] Site:1Nse6W..bCUy Loaded json: 1700 (latest: data/users/1D9PFKqnik1Z4JtDZnYhyQERZAu5ZiXqFX/content.json)
```

During this GUI doesn't respond. @HelloZeroNet Please?  @shortcutme, I understand that SQL is difficult, but using regular expressions to parse SQL... Here are some more hacks:

1. Add (brackets) around NewsFeed's `body LIKE ? OR title LIKE ?`.
2. WHERE without AND is still WHERE  I want to back-up my ID and the blog I usually visit. And I have my own blog, I also want to back-up it ...rectory  I want to host a git repository on ZeroNet. And I want to host hooks there. I mean, git expects hooks to have *executable* flag, and ZeroNet doesn't handle these flags. How can I fix that? Maybe add another entry to `content.json`? Well, I understand the reason behind this. But flags `rw` are secure, only `x` isn't. Anyway, how could an attacker launch a program? I mean, ZeroFrame API doesn't allow that via `wrapper_key`. @HelloZeroNet Sorry, I'm not @MuxZeroNet, but I think that this flag should rely on file content and obviously not on file name. I have already said that I want this feature for Git repositories, and its hooks have no extension. @HelloZeroNet That's okay. Another question: should ZeroNet automatically detect if file has `executable` flag or should owner set it? If first, will it work on Windows where there is no explict `executable` flag? (or maybe there is?) OK. I think setting the executable flag for a file should be fine as long as there's explicit authorization from the user before setting the flag. That way a user can audit the file before its runnable.

Note that not all file systems support the executable flag; for example, a 0net data directory on an NTFS partition will be executable by default, so there's no point in asking for permission in that case. > "executable": true

An integer could be better. "mode": 511 (0o777) Plus a user-controlled flag to respect or ignore the mode settings.

If the file mode is set according to the content.json manifest, a file copied out of the ZeroNet/data folder could be executable or have some other weird properties. If ZeroNet were to implement this feature, there should be a flag to ignore the mode settings, and should be set by default. If you know what you are doing (hosting a Git repo, etc.) then turn it off. However, a uninformed user will leave it on, so he will not encounter strange file properties.  When I drag the ZeroNet icon in every website to reach the sidebar of that site, when I try to scroll down or up, the Globe zooms in and out and prevents scrolling properly. Would you disable zooming of the Globe by mouse? It has a low resolution so zooming into it is a useless feature anyway.  As mentioned in the ZeroNet presentation, it was noted that it could be implemented for non-internet networks (Bluetooth, WiFi, Radio Comm, Meshnets, etc.) 

[https://docs.google.com/presentation/d/1_2qK1IuOKJ51pgBvllZ9Yu7Au2l551t3XBgyTSvilew/pub?start=false&loop=false&delayms=3000&slide=id.g11ba381582_0_0](url)

Assuming you would be on a private intranet for this, what modifications to the code base would need to be implemented in order to support such a change. 

This is also assuming a private distributed ledger would have to be made in order to point and update to a private block-chain.  > This is also assuming a private distributed ledger would have to be made in order to point and update to a private block-chain.

What is that for? @unsystemizer  This would be for running a private instance of ZeroNet in an Intranet Type environment. (i.e. setting up a private Namecoin Ledger)
https://themerkle.com/altcoins-dying-make-one-hour/
 Well, that seems out of scope, for ZN to create forks of each plugin such as Namecoin.

Separately, it just doesnâ€™t make sense to fork Namecoin for a private network. Whoâ€™s going to mine it and why would they do that? This is a rhetorical question (itâ€™s out of scope it seems to me, so the answer likely doesnâ€™t matter). Not quite, it was actually discussed as a use case in documentation.  As note above the plug-in already is implemented for a bootstrapped build. A majority of altcoins are forks of other crypto-currencies, so the logic behind this would be to perhaps implement a blockchain agnostic feature to perhaps support any coin with name value stores (ie. Emercoin) in order to further decentralized DNS and identity management.  I reloaded zeronetï¼Œ and restored user.json. But I found that I lost control of the original blog http://127.0.0.1:43110/1G5bve8RqNK7Gm8fheEvPfqqhokUAYYmh4/ I cannot publish new article
![qq 20171017023219](https://user-images.githubusercontent.com/14255631/31628495-6f79d3aa-b2e3-11e7-9be1-b81cf4d11d74.png)
 click the buttonï¼Œ there is no reaction. and I can't edit any post article. why? em....which is the privatekey?
![qq 20171017095719](https://user-images.githubusercontent.com/14255631/31643180-a3191c1e-b321-11e7-80a7-2fb3fa587935.png)
and how can I control my site?
thx auth_privatekey is the private key for your authentication (your user) I belive. privatekey is your zite's private key. ![qq 20171017095719](https://user-images.githubusercontent.com/14255631/31657094-1b649138-b360-11e7-8d95-f45e1b6eb1c9.png)
and If I edit some articleï¼ŒI can not post
![qq 20171017172719](https://user-images.githubusercontent.com/14255631/31657266-84d8dc0a-b360-11e7-9f6d-effbb3612985.png)

 who can help me My English is not well, maybe I cannot understand you well. this is my sidebar
![qq 20171018223432](https://user-images.githubusercontent.com/14255631/31724632-df24d87c-b454-11e7-912f-657d3e9fd6f0.png)
![qq 20171018223502](https://user-images.githubusercontent.com/14255631/31724637-e1863796-b454-11e7-9886-080e8dd97622.png)
![qq 20171018223616](https://user-images.githubusercontent.com/14255631/31724641-e45cf040-b454-11e7-8796-20d29e97d1ef.png)
 now I cannot open my blog normally
![qq 20171018224017](https://user-images.githubusercontent.com/14255631/31724833-56c7f562-b455-11e7-8795-08ac459f6f20.png)
  I can not link any site and update
![qq 20171016223209](https://user-images.githubusercontent.com/14255631/31617520-02c1e520-b2c2-11e7-8015-7ff90aed7fb1.png)
 win10  I do not know ho to edit torrc. 
how to edit?
# Tor config for ZeroNet

DataDirectory data
DirReqStatistics 0
GeoIPFile geoip\geoip
GeoIPv6File geoip\geoip6

# Log notice file data\notice.log

ControlPort 49051
SOCKSPort 49050

CookieAuthentication 1 I clicking it.  And it does not work. I am from China. Tor is blocked in China, so you need an anti-censorship proxy or pluggable transport to connect to Tor.
If you have an anti-censorship proxy such as [Shadowsocks](https://github.com/shadowsocks/shadowsocks-windows), you can add `Socks5Proxy 127.0.0.1:1080` to a newline. If your anti-censorship proxy provide a http proxy(must support HTTP CONNECT), add `HTTPSProxy 127.0.0.1:1080` to a newline.
If you don't have any anti-censorship proxy, you can try these: [Psiphon 3](https://s3.amazonaws.com/psiphon/web/mjr4-p23r-puwl/zh/download.html), [Firefly](https://github.com/yinghuocho/firefly-proxy), [Lantern](https://github.com/getlantern/lantern).
If you tried the tools above and can't connect, try [meek](https://trac.torproject.org/projects/tor/wiki/doc/meek), [read this](https://zeronet.readthedocs.io/en/latest/faq/#how-to-make-tor-work-if-my-isp-or-goverment-blocks-it) to know how to modify ZeroNet's config to use Tor browser's proxy and control port. I will tryï¼Œ thanks  ```
[2017-10-16 14:50:09,571] ERROR    Site:... sands.git/packed-refs fileGet error: [Errno 2] No such file or directory: u'/Users/Manwe/Tools/ZeroNet/data/1RxTdD54fbEdVZs2hZCUBWirJf5bSsAUg/sands.git/packed-refs'
[2017-10-16 14:50:09,686] DEBUG    Site:... Websocket send error: ConcurrentObjectUseError: This socket is already used by another greenlet: <bound method Waiter.switch of <gevent.hub.Waiter object at 0x1093e1370>> in UiWebsocket.py line 197 > websocket.py line 349 > websocket.py line 333 > _socket2.pyo line 419 > _socket2.pyo line 355 > _socket2.pyo line 328 > _socket2.pyo line 176
[2017-10-16 14:50:09,686] DEBUG    Site:... Websocket send error: ConcurrentObjectUseError: This socket is already used by another greenlet: <bound method Waiter.switch of <gevent.hub.Waiter object at 0x1093e1370>> in UiWebsocket.py line 197 > websocket.py line 349 > websocket.py line 333 > _socket2.pyo line 419 > _socket2.pyo line 355 > _socket2.pyo line 328 > _socket2.pyo line 176
[2017-10-16 14:50:09,686] DEBUG    Site:... Websocket send error: ConcurrentObjectUseError: This socket is already used by another greenlet: <bound method Waiter.switch of <gevent.hub.Waiter object at 0x1093e1370>> in UiWebsocket.py line 197 > websocket.py line 349 > websocket.py line 333 > _socket2.pyo line 419 > _socket2.pyo line 355 > _socket2.pyo line 328 > _socket2.pyo line 176
```

...and a lot more messages. My site is trying to read many files at once, can it be related? This fails on OSX and works on Windows. UPD The same is true for Windows now. @HelloZeroNet About 50.  Hello,

On zeronet 0.6.0 (rev 3105) the "Shutdown" button in the Main menu isn't displayed properly.
On Chromium (61.0.3163.100p0) you don't see it at all, the menu hard-stop where it displays the version number. (no way to scroll or arrow down).
![zero_chrome](https://user-images.githubusercontent.com/32833540/31602742-84c940a6-b24d-11e7-9708-d21df84ee99e.png)

On Firefox (56) it isn't displayed properly, can't read it, but you can see the top (white) of the button which makes it still clickable.
![zero_firefox](https://user-images.githubusercontent.com/32833540/31602859-c7d007ae-b24d-11e7-9bc8-199b35d7c21f.png)

I've tried to maximize windows/reduce fonts etc...without success.

Is there another 'clean' way to shutdown? (something better than ctrl-c the zeronet.py).

Thanks.
Regards,
-- clemat
  Has there been a change in siteSign and files_optional object?

Before: sign failed for missing optional files in user directory. As a workaround I always clear files_optional object before sign. The optional files in user directory were added to files_optional object. OK functionality.
Now: clear files_optional object before sign => all optional files are deleted from user directory. Is that an error or is it how it should be?


 I think you have tested the issue from OS. I am using JS in my test. Have added some extra debug lines in console.log. Added callback 4 to check files_optional after sign. It will take some time to write a separate ZeroNet site to document this bug. Hope below documentation is OK ... 

                        // loop. sign each content.json file (remove files_optional and add optional)
                        sign = function () {
                            var pgm = service + '.get_my_user_hub.step_2_compare_tables.sign: ';
                            var dictionary, inner_path, debug_seq0 ;
                            dictionary = dictionaries.shift() ;
                            // 1: read content.json
                            inner_path = 'merged-MoneyNetwork/' + dictionary + '/content.json' ;
                            z_file_get(pgm, {inner_path: inner_path, required: false}, function (content_str) {
                                var pgm = service + '.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: ';
                                var content, json_raw, debug_seq1 ;
                                if (content_str) content = JSON.parse(content_str) ;
                                else content = {} ;
                                content.optional = Z_CONTENT_OPTIONAL ;

                                // # https://github.com/HelloZeroNet/ZeroNet/issues/1147
                                if (!content.files_optional || !Object.keys(content.files_optional).length) {
                                    console.log(pgm + 'issue #1147: no optional files in content.json') ;
                                }
                                else {
                                    console.log(pgm + 'issue #1147: content.files_optional = ' + JSON.stringify(content.files_optional)) ;
                                    if (show_debug('issue_1147')) {
                                        console.log(pgm + 'issue #1147 = true: old workaround for siteSign failure. deleting content.files_optional before sign') ;
                                        delete content.files_optional ;
                                    }
                                    else console.log(pgm + 'issue #1147 = false: new fix. keeping content.files_optional') ;
                                }

                                // 2: write content.json
                                json_raw = unescape(encodeURIComponent(JSON.stringify(content)));
                                // debug_seq1 = MoneyNetworkHelper.debug_z_api_operation_start('z_file_write', pgm + inner_path + ' fileWrite');
                                debug_seq1 = debug_z_api_operation_start(pgm, inner_path, 'fileWrite', show_debug('z_file_write'));
                                ZeroFrame.cmd("fileWrite", [inner_path, btoa(json_raw)], function (res) {
                                    var pgm = service + '.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: ';
                                    var debug_seq2 ;
                                    // MoneyNetworkHelper.debug_z_api_operation_end(debug_seq1);
                                    debug_z_api_operation_end(debug_seq1, format_res(res));
                                    if (res != 'ok') {
                                        console.log(pgm + 'Error: ' + inner_path + ' fileWrite failed. res = ' + JSON.stringify(res));
                                        return step_3_find_user_hubs() ; // error - continue with next step
                                    }
                                    // 3: sign
                                    // debug_seq2 = MoneyNetworkHelper.debug_z_api_operation_start('z_site_publish', pgm + inner_path + ' sign') ;
                                    debug_seq2 = debug_z_api_operation_start(pgm, inner_path, 'siteSign', show_debug('z_site_publish')) ;
                                    ZeroFrame.cmd("siteSign", {inner_path: inner_path}, function (res) {
                                        var pgm = service + '.get_my_user_hub.step_2_compare_tables.sign siteSign callback 3: ';
                                        // MoneyNetworkHelper.debug_z_api_operation_end(debug_seq2);
                                        debug_z_api_operation_end(debug_seq2, format_res(res));
                                        if (res != 'ok') {
                                            console.log(pgm + inner_path + ' siteSign failed. error = ' + JSON.stringify(res));
                                            return step_3_find_user_hubs() ; // error - continue with next step;
                                        }

                                        // sign ok

                                        // # https://github.com/HelloZeroNet/ZeroNet/issues/1147
                                        // check files_optional after sign
                                        z_file_get(pgm, {inner_path: inner_path, required: false}, function (content_str) {
                                            var pgm = service + '.get_my_user_hub.step_2_compare_tables.sign z_file:_get callback 4: ';
                                            var content ;
                                            content = JSON.parse(content_str) ;
                                            console.log(pgm + 'issue #1147. issue_1147 = ' + show_debug('issue_1147') + ', files_optional = ' + JSON.stringify(content.files_optional)) ;

                                            if (!dictionaries.length) return step_3_find_user_hubs() ; // done - continue with next step
                                            // next sign in 1 second to keep modified sequence
                                            setTimeout(sign, 1000) ;

                                        }) ; // z_file_get callback 4

                                    }) ; // siteSign callback 3

                                }) ; // fileWrite callback 2

                            }) ; // z_file_get callback 1

                        } ; // sign
                        // start sign loop
                        sign() ;

issue 1147 test 1. zeronet port open + deleting content.files_optional before sign. Test result. Optional files was deleted. bug!
<pre>
16:20:37.356 all.js:2617 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147: no optional files in content.json
16:20:37.365 MoneyNetworkAPI.js:281 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1HXzvtSLuvxZfh6LgdaqTk4FSVf7x8w7NJ/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign started (18). 1 pending ZeroNet API operation (18)
16:20:37.430 MoneyNetworkAPI.js:295 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1HXzvtSLuvxZfh6LgdaqTk4FSVf7x8w7NJ/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign finished. res = "OK". elapsed time 66 ms (18). No pending ZeroNet API operations
16:20:37.435 all.js:2661 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file:_get callback 4: issue #1147. issue_1147 = true, files_optional = undefined
16:20:38.438 all.js:2617 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147: no optional files in content.json
16:20:38.443 MoneyNetworkAPI.js:281 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1PgyTnnACGd1XRdpfiDihgKwYRRnzgz2zh/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign started (22). 1 pending ZeroNet API operation (22)
16:20:38.501 MoneyNetworkAPI.js:295 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1PgyTnnACGd1XRdpfiDihgKwYRRnzgz2zh/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign finished. res = "OK". elapsed time 58 ms (22). No pending ZeroNet API operations
16:20:38.503 all.js:2661 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file:_get callback 4: issue #1147. issue_1147 = true, files_optional = undefined
 
16:22:01.883 all.js:2617 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147: no optional files in content.json
16:22:01.888 MoneyNetworkAPI.js:281 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1HXzvtSLuvxZfh6LgdaqTk4FSVf7x8w7NJ/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign started (71). 1 pending ZeroNet API operation (71)
16:22:01.944 MoneyNetworkAPI.js:295 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1HXzvtSLuvxZfh6LgdaqTk4FSVf7x8w7NJ/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign finished. res = "OK". elapsed time 56 ms (71). No pending ZeroNet API operations
16:22:01.948 all.js:2661 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file:_get callback 4: issue #1147. issue_1147 = true, files_optional = undefined
16:22:02.951 all.js:2620 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147: content.files_optional = {"1508163706713-1508163706713-2-chat.json":{"sha512":"28f6633566fe975e689fdac7b7639becc7fd4de483ae3df18f7e60750277f06b","size":187}}
16:22:02.952 all.js:2622 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147 = true: old workaround for siteSign failure. deleting content.files_optional before sign
16:22:02.958 MoneyNetworkAPI.js:281 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1PgyTnnACGd1XRdpfiDihgKwYRRnzgz2zh/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign started (75). 1 pending ZeroNet API operation (75)
16:22:03.010 MoneyNetworkAPI.js:295 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1PgyTnnACGd1XRdpfiDihgKwYRRnzgz2zh/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign finished. res = "OK". elapsed time 53 ms (75). No pending ZeroNet API operations
16:22:03.012 all.js:2661 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file:_get callback 4: issue #1147. issue_1147 = true, files_optional = undefined
</pre>

issue 1147 test 2. zeronet port open + keeping content.files_optional before sign. Test OK. No optional files were deleted:
<pre>
16:25:37.491 all.js:2617 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147: no optional files in content.json
16:25:37.506 MoneyNetworkAPI.js:281 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1HXzvtSLuvxZfh6LgdaqTk4FSVf7x8w7NJ/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign started (18). 1 pending ZeroNet API operation (18)
16:25:37.580 MoneyNetworkAPI.js:295 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1HXzvtSLuvxZfh6LgdaqTk4FSVf7x8w7NJ/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign finished. res = "OK". elapsed time 74 ms (18). No pending ZeroNet API operations
16:25:37.590 all.js:2661 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file:_get callback 4: issue #1147. issue_1147 = false, files_optional = undefined
16:25:38.593 all.js:2617 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147: no optional files in content.json
16:25:38.603 MoneyNetworkAPI.js:281 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1PgyTnnACGd1XRdpfiDihgKwYRRnzgz2zh/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign started (22). 1 pending ZeroNet API operation (22)
16:25:38.658 MoneyNetworkAPI.js:295 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1PgyTnnACGd1XRdpfiDihgKwYRRnzgz2zh/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign finished. res = "OK". elapsed time 55 ms (22). No pending ZeroNet API operations
16:25:38.662 all.js:2661 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file:_get callback 4: issue #1147. issue_1147 = false, files_optional = undefined
...
16:27:31.255 all.js:2617 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147: no optional files in content.json
16:27:31.259 MoneyNetworkAPI.js:281 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1HXzvtSLuvxZfh6LgdaqTk4FSVf7x8w7NJ/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign started (69). 1 pending ZeroNet API operation (69)
16:27:31.324 MoneyNetworkAPI.js:295 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1HXzvtSLuvxZfh6LgdaqTk4FSVf7x8w7NJ/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign finished. res = "OK". elapsed time 64 ms (69). No pending ZeroNet API operations
16:27:31.327 all.js:2661 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file:_get callback 4: issue #1147. issue_1147 = false, files_optional = undefined
16:27:32.329 all.js:2620 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147: content.files_optional = {"1508164016545-1508164016545-2-chat.json":{"sha512":"965a97fd6335650930ebfff5c4a93d4538a689d005897906aa72c26327142316","size":227}}
16:27:32.329 all.js:2625 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147 = false: new fix. keeping content.files_optional
16:27:32.335 MoneyNetworkAPI.js:281 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1PgyTnnACGd1XRdpfiDihgKwYRRnzgz2zh/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign started (73). 1 pending ZeroNet API operation (73)
16:27:32.385 MoneyNetworkAPI.js:295 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1PgyTnnACGd1XRdpfiDihgKwYRRnzgz2zh/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign finished. res = "OK". elapsed time 50 ms (73). No pending ZeroNet API operations
16:27:32.387 all.js:2661 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file:_get callback 4: issue #1147. issue_1147 = false, files_optional = {"1508164016545-1508164016545-2-chat.json":{"sha512":"965a97fd6335650930ebfff5c4a93d4538a689d005897906aa72c26327142316","size":227}}
</pre>

issue 1147 test 3. zeronet port closed + deleting content.files_optional before sign. Test result. Optional files was deleted. bug!
<pre>
16:30:06.292 all.js:2617 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147: no optional files in content.json
16:30:06.311 MoneyNetworkAPI.js:281 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1HXzvtSLuvxZfh6LgdaqTk4FSVf7x8w7NJ/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign started (18). 1 pending ZeroNet API operation (18)
16:30:06.404 MoneyNetworkAPI.js:295 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1HXzvtSLuvxZfh6LgdaqTk4FSVf7x8w7NJ/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign finished. res = "OK". elapsed time 93 ms (18). No pending ZeroNet API operations
16:30:06.412 all.js:2661 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file:_get callback 4: issue #1147. issue_1147 = true, files_optional = undefined
16:30:07.416 all.js:2620 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147: content.files_optional = {"1508164016545-1508164016545-2-chat.json":{"sha512":"965a97fd6335650930ebfff5c4a93d4538a689d005897906aa72c26327142316","size":227}}
16:30:07.417 all.js:2622 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147 = true: old workaround for siteSign failure. deleting content.files_optional before sign
16:30:07.425 MoneyNetworkAPI.js:281 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1PgyTnnACGd1XRdpfiDihgKwYRRnzgz2zh/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign started (22). 1 pending ZeroNet API operation (22)
16:30:07.485 MoneyNetworkAPI.js:295 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1PgyTnnACGd1XRdpfiDihgKwYRRnzgz2zh/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign finished. res = "OK". elapsed time 60 ms (22). No pending ZeroNet API operations
16:30:07.488 all.js:2661 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file:_get callback 4: issue #1147. issue_1147 = true, files_optional = undefined
...
16:30:53.416 all.js:2617 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147: no optional files in content.json
16:30:53.420 MoneyNetworkAPI.js:281 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1HXzvtSLuvxZfh6LgdaqTk4FSVf7x8w7NJ/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign started (68). 1 pending ZeroNet API operation (68)
16:30:53.485 MoneyNetworkAPI.js:295 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1HXzvtSLuvxZfh6LgdaqTk4FSVf7x8w7NJ/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign finished. res = "OK". elapsed time 65 ms (68). No pending ZeroNet API operations
16:30:53.489 all.js:2661 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file:_get callback 4: issue #1147. issue_1147 = true, files_optional = undefined
16:30:54.491 all.js:2620 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147: content.files_optional = {"1508164241927-1508164241927-2-chat.json":{"sha512":"1f4796bd5c667d99d6cdf0265f8bd498348881c62591c44e9d9e1a8ecfb69aaf","size":236}}
16:30:54.491 all.js:2622 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file_get callback 1: issue #1147 = true: old workaround for siteSign failure. deleting content.files_optional before sign
16:30:54.498 MoneyNetworkAPI.js:281 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1PgyTnnACGd1XRdpfiDihgKwYRRnzgz2zh/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign started (72). 1 pending ZeroNet API operation (72)
16:30:54.550 MoneyNetworkAPI.js:295 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign fileWrite callback 2: merged-MoneyNetwork/1PgyTnnACGd1XRdpfiDihgKwYRRnzgz2zh/data/users/18DbeZgtVCcLghmtzvg4Uv8uRQAwR8wnDQ/content.json siteSign finished. res = "OK". elapsed time 52 ms (72). No pending ZeroNet API operations
16:30:54.552 all.js:2661 MoneyNetworkHubService.get_my_user_hub.step_2_compare_tables.sign z_file:_get callback 4: issue #1147. issue_1147 = true, files_optional = undefined
</pre> https://github.com/jaros1/Money-Network/blob/master/js/lib/72-angular-service1.js#L563 OK. Will write a little site to verify the issue Tried to recreate the error in a small separate site and did not get same problem. Only big difference between my site and the new site is merger site feature.  Can see in test log that two different data hubs are involved in process. Will do some more testing. I guess it is NOT a ZeroNet bug Still problem in my site.  Can see that I sign two different content.json files from two different data hubs and that the optional file is deleted from data hub in sign. Will create a simple merger site and see if I can recreate the problem.

[127.0.0.1-1508239399628.log](https://github.com/HelloZeroNet/ZeroNet/files/1390891/127.0.0.1-1508239399628.log)
 No problem on non merger sites. Problem on merger sites.

Created main site Issue #1147 with address 14EQaGqfahEJ9iV8tBqanZojHza7N1A3cM
and data hub with address 15bk2bBQMN44i3qcnEFmaiqK42ortd3U8r
Don't know why fileWrite operations take so long time. Be patient ...
Test fails on https://fuckcf.cf/14EQaGqfahEJ9iV8tBqanZojHza7N1A3cM/ with error message "Test failed. No optional files were found."
( checking number of optional files in content.json after sign)

[fuckcf.cf-1508245725947.log](https://github.com/HelloZeroNet/ZeroNet/files/1391071/fuckcf.cf-1508245725947.log)



 Looks random. Some test OK. Sometimes test fails. I cannot see the pattern ...

Test 1. On my old laptop. Test failed. No optional files were found
[test-1-old-laptop-no-optional-files-were-found.log](https://github.com/HelloZeroNet/ZeroNet/files/1427151/test-1-old-laptop-no-optional-files-were-found.log)

Test 2. On my new laptop. Test OK. 5 optional files.
[test-2-new-laptop-5-optional-files.log](https://github.com/HelloZeroNet/ZeroNet/files/1427161/test-2-new-laptop-5-optional-files.log)

Test 3. proxy.th3nd.com proxy server. cannot test. too many websocket open/close for the test

Test 4. new fresh ZeroBundle install on new laptop. Test failed. No optional files were found.
[test4-no-optional-files-were-found.log](https://github.com/HelloZeroNet/ZeroNet/files/1427242/test4-no-optional-files-were-found.log)

Test 5. from a windows 10 vm and edge. Test failed. No optional files were found.


  Got that one squared away.  ![image](https://user-images.githubusercontent.com/644416/31549310-154288bc-b02e-11e7-851d-21137e99e2e5.png)
 > as long as you can run Tor

GFW block all directory servers and most bridges, so you need a front-proxy such as Shadowsocks.
But if you have a front-proxy, you can directly visit zeronet.io.

I think the ultimate solution is **ZeroNet via I2P**:
- I2P is tough enough to anti GFW so far.
- ZeroNet will auto get DHT feature when use I2P Torrent. **NEVER** trust any service in China. China law require server must put a backdoor for government. I think it would be helpful to include some .onion / i2p based trackers for faster bootstrapping.

Tor users from China are recommended to use [meek pluggable transport](https://www.torproject.org/docs/pluggable-transports), so it might still work. One such tracker:

http://trackeryknvofs3m.onion/ Meek pluggable transport works well in China, but it's slow and need to spend more because cloud platforms' bandwidth more expensive. Most people don't care about anonymity won't like this, so I think adding a feature that use anti-cersorship proxy/pluggable transport to connect to tracker only #1108 is useful. @HelloZeroNet We need a way to help Chinese new users download the ZeroNet client.  I get a "Site error: argument of type 'NoneType' is not iterable" when doing a siteSign of a site where I've added a `optional` key to `content.json` when that key did not exist before. A stacktrace when I remove the try/catch:

    - Unhandled exception: argument of type 'NoneType' is not iterable
    Traceback (most recent call last):
      File "zeronet.py", line 19, in main
        main.start()
      File "src/main.py", line 496, in start
        actions.call(config.action, action_kwargs)
      File "src/main.py", line 155, in call
        func(**kwargs)
      File "src/main.py", line 230, in siteSign
        succ = site.content_manager.sign(inner_path=inner_path, privatekey=privatekey, update_changed_files=True, remove_missing_optional=remove_missing_optional)
      File "src/Content/ContentManager.py", line 577, in sign
        helper.getDirname(inner_path), content.get("ignore"), content.get("optional")
      File "src/Content/ContentManager.py", line 524, in hashFiles 
        self.hashFile(dir_inner_path, file_relative_path, optional=True)
      File "plugins/Bigfile/BigfilePlugin.py", line 245, in hashFile
        if content and file_relative_path in content.get("files_optional"):
    TypeError: argument of type 'NoneType' is not iterable

It seems to look for a "files_optional" key and if it doesn't exist the error happens due to trying it iterate over `None`. If I add a line:

    "files_optional": { },

to `content.json` then the sign works and there is no error.  Hello, I've been cycling creating new sites and failing to port or merge my old site into the new one and feel maybe I am pasting over my old signatures or other keys. I understand the important keys I need to have are:

- the site key or address pubkey
- the owner authorised in content.json as signers
- but what on earth is "signs" ?? what should i put here?
- how do i know what value the HBuZ30 hash should be in signs?

The error I see in the browser notification popup: 
> Private key invalid! Valid signers: [u'1PvRsF1n......................'], Private key address: 1663jaG..................

 "address": "1PvRsF1nDwYAUD...................",
 "signers": ["1663jaGEnJSqtZb48oY..................."],
 "signers_sign": "HNpbCdFvyw.............................",
 "signs": {
  "1PvRsF1nDwYA................": "HBuZ30xjcw9TJ0bNL6C4LpdSiUlqp1RkebE52o..............."
 },
 "signs_required": 1, leave it or regen a new site to get the file again. throw away the new site. edit the site settings but leave the hashes and this stuff alone. I have to ignore the file when making updates. otherwise you get "update failed for 1 file" Thanks so much!! So when I ported over my code.... DO NOT wipe over this part yeah? This part is system generated and unique to the new site got it. Thanks.  Actually I'm still going round in circles on this.

So copy an old site to new I don't adjust:
"address" - new site address
"signers_sign" - leave as old its my sign anyhow? not sure if that ever changes. 
"signs" - leave as is

but I do adjust:
"signers" - new ID although it's same because it's me.


and that's all?   Hi

I'm currently fiddling about with ZeroNet trying to build a single page application and have gotten to the point where I've got to start thinking about the routing. When using a more traditional client/server setup you'd configure the server to serve the same page regardless of the url given and let the clientside javascript handle showing the correct content. As far as I know this isn't possible with ZeroNet, it will always try to serve the file the url is pointing to.

Just to see if I could get the clientside routing thing to work if I could get ZeroNet to serve the right file, I hacked in the option ([gist](https://gist.github.com/Wieke/4491b9d66d47d1e1050d1317f8b299c8#file-uirequest-py-L490-L499)) for a zite to fall back on a configured path if the requested file couldn't be found. It worked, so it seems to me that giving a zite creator some rudimentary control over which file is served for which url could be useful.

Thanks,

Wieke You can use javascript client-side routing. I created a library that helps with this called [ZeroFrame Router](https://github.com/krixano/ZeroFrame-Router). Here's a basic [demo zite](http://127.0.0.1:43110/1K2myjtjoEVpRC2JMieRL73ES4V4iLP2Ev/?/). most of my zeronet projects use the ZeroFrame Router along with the new Vuejs plugin I made so you can more easily use the plugin with vuejs. The best project you can look at to see how I use all this in a real zite is probably [ZeroMedium](https://github.com/krixano/ZeroMedium).

Under the hood, all it does is run zeroframe's `wrapperPushState` and `wrapperPopState` commands and when you click a link to route to a page, it will run your controller function. This I believe is similar to how other zites are doing routing. If using the Vuejs plugin, it will switch a component you put into your root template to the component you defined for the route. @krixano Sweet. I'm using Vue as well and just noticed that vue-router tries to refresh the site when I hit forward. I'm going to give your router a try.

@HelloZeroNet Having some kind of fallback page would probably be sufficient. It's not like you could actually do something with complex routing in zeronet, right? @Wieke  As a forewarning, my router is not really the best right now (there are things that need to be fixed, including with the vuejs plugin). However, it is fairly usable.  - Starting ZeroNet...
[06:55:05] - OpenSSL loaded, version: 0100020CF
[06:55:05] - Unhandled exception: argument --autodownload_bigfile_size_limit: conflicting option string(s): --autodownload_bigfile_size_limit
Traceback (most recent call last):
  File "zeronet.py", line 18, in main
    import main
  File "/root/zeronet/src/main.py", line 108, in <module>
    config.loadPlugins()
  File "/root/zeronet/src/Config.py", line 379, in loadPlugins
    ConfigPlugin(self)
  File "/root/zeronet/src/Config.py", line 374, in __init__
    self.createArguments()
  File "plugins/Zeroname/UiRequestPlugin.py", line 30, in createArguments
    return super(ConfigPlugin, self).createArguments()
  File "plugins/UiPassword/UiPasswordPlugin.py", line 115, in createArguments
    return super(ConfigPlugin, self).createArguments()
  File "plugins/OptionalManager/OptionalManagerPlugin.py", line 136, in createArguments
    return super(ConfigPlugin, self).createArguments()
  File "plugins/Bigfile/BigfilePlugin.py", line 680, in createArguments
    return super(ConfigPlugin, self).createArguments()
  File "plugins/BigFile/BigfilePlugin.py", line 678, in createArguments
    group.add_argument('--autodownload_bigfile_size_limit', help='Also download bigfiles until this limit if help distribute option is checked', default=1, metavar="MB", type=int)
  File "/usr/lib/python2.7/argparse.py", line 1308, in add_argument
    return self._add_action(action)
  File "/usr/lib/python2.7/argparse.py", line 1509, in _add_action
    action = super(_ArgumentGroup, self)._add_action(action)
  File "/usr/lib/python2.7/argparse.py", line 1322, in _add_action
    self._check_conflict(action)
  File "/usr/lib/python2.7/argparse.py", line 1460, in _check_conflict
    conflict_handler(action, confl_optionals)
  File "/usr/lib/python2.7/argparse.py", line 1467, in _handle_conflict_error
    raise ArgumentError(action, message % conflict_string)
ArgumentError: argument --autodownload_bigfile_size_limit: conflicting option string(s): --autodownload_bigfile_size_limit
  I need help in making ZeroNet run correctly on Raspbian. At first it worked fine with my zite being active on another computer, but since then it didn't work again. It can update the 1Name zite but not mine, anymore. Finally I got my zeronet daemon to work properly on my Raspi. I had to make a completely fresh and clean install on the daemon and on the standard zeronet client. Then I changed the default port for the daemon and my zite gets seeded by the daemon.

The only problem that persists is still this one:
```
[15:58:31] TorManager Connecting to Tor Controller 127.0.0.1:9051
[15:58:31] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 165 > socket.py line 342
[15:58:31] TorManager Starting self-bundled Tor, due to Tor proxy port 127.0.0.1:9050 check error: No connection
```

Setting up torrc as in the documentation does not work at all on Raspbian. The workaround without being able to use .onion addresses works neither. 

So ZN works now with default options but not with --tor always or standard tor use. Seems like your ZN starts before tor. Here are my systemd confs:

/etc/systemd/system/tor.service
```
[Unit]
Description=Anonymizing Overlay Network
After=network.target

[Service]
User=zeronet
Type=simple
ExecStart=/usr/local/bin/tor -f /home/zeronet/tor/torrc
ExecReload = /bin/kill -HUP ${MAINPID}
ExecStop = /bin/kill -INT ${MAINPID}
TimeoutSec = 30
Restart = on-failure
LimitNOFILE = 4096

[Install]
WantedBy=multi-user.target
```

/etc/systemd/system/zeronet.service 
```
[Unit]
Description = ZeroNet: a decentralized web platform
After = tor.service

[Service]
User = zeronet
WorkingDirectory = /opt/zeronet
ExecStart = /usr/bin/env python /opt/zeronet/zeronet.py --config_file /etc/zeronet.conf
Restart = on-failure

[Install]
WantedBy = default.target
```
/etc/zeronet.conf
```
[global]
tor = always
ui_ip = *
data_dir = /mnt/storage/zeronet/data
log_dir = /mnt/storage/zeronet/log
```

And don't forget to activate services:
```
sudo systemctl enable tor
sudo systemctl enable zeronet
sudo systemctl start tor
sudo systemctl start zeronet
``` ```
pi@hostname~/Public/ZeroNet $ sudo systemctl enable tor
Synchronizing state for tor.service with sysvinit using update-rc.d...
Executing /usr/sbin/update-rc.d tor defaults
Executing /usr/sbin/update-rc.d tor enable
pi@hostname:~/Public/ZeroNet $ sudo systemctl status tor
â— tor.service - LSB: Starts The Onion Router daemon processes
   Loaded: loaded (/etc/init.d/tor)
   Active: failed (Result: exit-code) since Sun 2017-10-15 21:27:12 CEST; 1 weeks 3 days ago

Warning: Journal has been rotated since unit was started. Log output is incomplete or unavailable.
pi@hostname:~/Public/ZeroNet $ sudo systemctl start tor
Job for tor.service failed. See 'systemctl status tor.service' and 'journalctl -xn' for details.
pi@hostname:~/Public/ZeroNet $ systemctl status tor.service
â— tor.service - LSB: Starts The Onion Router daemon processes
   Loaded: loaded (/etc/init.d/tor)
   Active: failed (Result: exit-code) since Thu 2017-10-26 00:57:29 CEST; 12s ago
  Process: 13360 ExecStart=/etc/init.d/tor start (code=exited, status=1/FAILURE)
pi@hostname:~/Public/ZeroNet $
```

So far this happened.. I'll check the confs now.

Now I got this after reinstalling tor:
```
sudo systemctl status tor
â— tor.service - Anonymizing overlay network for TCP (multi-instance-master)
   Loaded: loaded (/lib/systemd/system/tor.service; enabled)
   Active: active (exited) since Thu 2017-10-26 01:02:45 CEST; 3min 44s ago
 Main PID: 14210 (code=exited, status=0/SUCCESS)
   CGroup: /system.slice/tor.service

Oct 26 01:02:45 icPi systemd[1]: Started Anonymizing overlay network for TCP (multi-instance-master).
Oct 26 01:03:40 icPi systemd[1]: Started Anonymizing overlay network for TCP (multi-instance-master).
Oct 26 01:05:36 icPi systemd[1]: Started Anonymizing overlay network for TCP (multi-instance-master).
```

There is no `tor.service` in `/etc/systemd/system`. Neither in any subdirectories. Also a zeronet service does not exist at all. that's because (as it says in the systemctl output) it's located in `/lib/systemd/system/`  Can I use a ZeroNet for decentralized REST API server and client? If so, how? If not, can you enable this? How can I use Websocket? I have a Python program and I would like to communicate with ZeroNet site. If I have a javascript function on the ZeroNet page, how can I call it from Python and get a function return? If I understand correctly, I need to run PhantomJS from Python, which sends a request to the ZeroNet page. Is there any other way? @filips123 nodeJS and using a module like [jsdom](npm.im/jsdom) or directly using regex and a websocket module in python (this would require rewriting that particular function to python) It works. Thank you!  ```
[14:07:23] - Unhandled exception
Traceback (most recent call last):
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\baseserver.py", line 186, in _do_read
    args = self.do_read()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\server.py", line 111, in do_read
    client_socket, address = self.socket.accept()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 195, in accept
    sockobj = socket(_sock=client_socket)
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 122, in __init__
    self._read_event = io(fileno, 1)
  File "gevent\corecext.pyx", line 480, in gevent.corecext.loop.io (gevent/gevent.corecext.c:8804)
  File "gevent\corecext.pyx", line 825, in gevent.corecext.io.__init__ (gevent/gevent.corecext.c:15470)
IOError: cannot watch more than 1024 sockets
Traceback (most recent call last):
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\baseserver.py", line 186, in _do_read
    args = self.do_read()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\server.py", line 111, in do_read
    client_socket, address = self.socket.accept()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 195, in accept
    sockobj = socket(_sock=client_socket)
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 122, in __init__
    self._read_event = io(fileno, 1)
  File "gevent\corecext.pyx", line 480, in gevent.corecext.loop.io (gevent/gevent.corecext.c:8804)
  File "gevent\corecext.pyx", line 825, in gevent.corecext.io.__init__ (gevent/gevent.corecext.c:15470)
IOError: cannot watch more than 1024 sockets
[14:07:23] - Unhandled exception
Traceback (most recent call last):
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\baseserver.py", line 186, in _do_read
    args = self.do_read()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\server.py", line 111, in do_read
    client_socket, address = self.socket.accept()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 195, in accept
    sockobj = socket(_sock=client_socket)
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 122, in __init__
    self._read_event = io(fileno, 1)
  File "gevent\corecext.pyx", line 480, in gevent.corecext.loop.io (gevent/gevent.corecext.c:8804)
  File "gevent\corecext.pyx", line 825, in gevent.corecext.io.__init__ (gevent/gevent.corecext.c:15470)
IOError: cannot watch more than 1024 sockets
Traceback (most recent call last):
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\baseserver.py", line 186, in _do_read
    args = self.do_read()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\server.py", line 111, in do_read
    client_socket, address = self.socket.accept()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 195, in accept
    sockobj = socket(_sock=client_socket)
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 122, in __init__
    self._read_event = io(fileno, 1)
  File "gevent\corecext.pyx", line 480, in gevent.corecext.loop.io (gevent/gevent.corecext.c:8804)
  File "gevent\corecext.pyx", line 825, in gevent.corecext.io.__init__ (gevent/gevent.corecext.c:15470)
IOError: cannot watch more than 1024 sockets
[14:07:24] - Unhandled exception
Traceback (most recent call last):
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\baseserver.py", line 186, in _do_read
    args = self.do_read()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\server.py", line 111, in do_read
    client_socket, address = self.socket.accept()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 195, in accept
    sockobj = socket(_sock=client_socket)
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 122, in __init__
    self._read_event = io(fileno, 1)
  File "gevent\corecext.pyx", line 480, in gevent.corecext.loop.io (gevent/gevent.corecext.c:8804)
  File "gevent\corecext.pyx", line 825, in gevent.corecext.io.__init__ (gevent/gevent.corecext.c:15470)
IOError: cannot watch more than 1024 sockets
Traceback (most recent call last):
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\baseserver.py", line 186, in _do_read
    args = self.do_read()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\server.py", line 111, in do_read
    client_socket, address = self.socket.accept()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 195, in accept
    sockobj = socket(_sock=client_socket)
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 122, in __init__
    self._read_event = io(fileno, 1)
  File "gevent\corecext.pyx", line 480, in gevent.corecext.loop.io (gevent/gevent.corecext.c:8804)
  File "gevent\corecext.pyx", line 825, in gevent.corecext.io.__init__ (gevent/gevent.corecext.c:15470)
IOError: cannot watch more than 1024 sockets
[14:07:29] - Unhandled exception
Traceback (most recent call last):
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\baseserver.py", line 186, in _do_read
    args = self.do_read()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\server.py", line 111, in do_read
    client_socket, address = self.socket.accept()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 195, in accept
    sockobj = socket(_sock=client_socket)
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 122, in __init__
    self._read_event = io(fileno, 1)
  File "gevent\corecext.pyx", line 480, in gevent.corecext.loop.io (gevent/gevent.corecext.c:8804)
  File "gevent\corecext.pyx", line 825, in gevent.corecext.io.__init__ (gevent/gevent.corecext.c:15470)
IOError: cannot watch more than 1024 sockets
Traceback (most recent call last):
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\baseserver.py", line 186, in _do_read
    args = self.do_read()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\server.py", line 111, in do_read
    client_socket, address = self.socket.accept()
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 195, in accept
    sockobj = socket(_sock=client_socket)
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 122, in __init__
    self._read_event = io(fileno, 1)
  File "gevent\corecext.pyx", line 480, in gevent.corecext.loop.io (gevent/gevent.corecext.c:8804)
  File "gevent\corecext.pyx", line 825, in gevent.corecext.io.__init__ (gevent/gevent.corecext.c:15470)
IOError: cannot watch more than 1024 sockets
[14:07:32] - Unhandled exception
Traceback (most recent call last):
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\greenlet.py", line 534, in run
    result = self._run(*self.args, **self.kwargs)
  File "plugins\AnnounceZero\AnnounceZeroPlugin.py", line 49, in announceTracker
    tracker_protocol, tracker_address, fileserver_port, add_types, my_peer_id, mode
  File "D:\ZeroBundle\ZeroNet\src\Site\Site.py", line 823, in announceTracker
    tracker = UdpTrackerClient(ip, int(port))
  File "D:\ZeroBundle\ZeroNet\src\lib\subtl\subtl.py", line 43, in __init__
    self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 122, in __init__
    self._read_event = io(fileno, 1)
  File "gevent\corecext.pyx", line 480, in gevent.corecext.loop.io (gevent/gevent.corecext.c:8804)
  File "gevent\corecext.pyx", line 825, in gevent.corecext.io.__init__ (gevent/gevent.corecext.c:15470)
IOError: cannot watch more than 1024 sockets
Traceback (most recent call last):
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\greenlet.py", line 534, in run
    result = self._run(*self.args, **self.kwargs)
  File "plugins\AnnounceZero\AnnounceZeroPlugin.py", line 49, in announceTracker
    tracker_protocol, tracker_address, fileserver_port, add_types, my_peer_id, mode
  File "D:\ZeroBundle\ZeroNet\src\Site\Site.py", line 823, in announceTracker
    tracker = UdpTrackerClient(ip, int(port))
  File "D:\ZeroBundle\ZeroNet\src\lib\subtl\subtl.py", line 43, in __init__
    self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\_socket2.py", line 122, in __init__
    self._read_event = io(fileno, 1)
  File "gevent\corecext.pyx", line 480, in gevent.corecext.loop.io (gevent/gevent.corecext.c:8804)
  File "gevent\corecext.pyx", line 825, in gevent.corecext.io.__init__ (gevent/gevent.corecext.c:15470)
IOError: cannot watch more than 1024 sockets
```
I can't visit http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D to surf zeronet, what should I do? I'm also experiencing this error.
It just happens, after some time, restarting the client helps, though, only for limited time until you have to repeat the process. Yes, restart ZeroNet helps, but after some time again.. @HelloZeroNet  ScreenShot:
![image](https://user-images.githubusercontent.com/15062548/31423083-f655a218-ae84-11e7-883a-58d8a6cb3e06.png)
 I'm sorry, I'm afraid that is one of many hard coded limitations of gevent and libev on windows.  Catch again.

196 site, haven't modified setting.

debug.log.zip:
[debug.log.zip](https://github.com/HelloZeroNet/ZeroNet/files/1516330/debug.log.zip)

 I have this issue too, latest Zeronet is hardly usable, Win. 10 64b.
In my case i got this: Connections (997, total made: 10819)
If i am not wrong i am connected to zites: 561

> afraid that is one of many hard coded limitations of gevent and libev on windows

[it seems](https://github.com/gevent/gevent/issues/854#issuecomment-244650637) like that, on Linux this is not issue?

Is it possible make Zeronet limit the connections ZeroHello (i assume it is main connections hog in this case) is producing so it do not affect regular browsing behavior? I mean ZeroHello on WIndows should leave reasonable amount of sockets available out of 1024 limit so it do not affect regular browsing (example 5 zites loading at a time)? https://www.reddit.com/r/learnpython/comments/3ml5zo/grequestsgevent_io_limit_help/

I am not a programmer, so i am asking You programmers. Thank you @HelloZeroNet my status after ~7 hours of running zeronet:
Connections (517, total made: 8072)
The number of active connections stays roughly same for previous hours.
I am "connected to" (visited and not deleted) roughly 600 zites.
it seems like You solved it, because for last around 7 hours i seen no "[Connection with UiServer Websocket was lost](https://github.com/HelloZeroNet/ZeroNet/issues/1249)" and have no issue browsing zeronet which is great. Thank you Just now i found zites are not loading in TorBrowser, it resulted in default browser error: The connection was reset.
At http://127.0.0.1:43110/Stats i seen: Connections (1034, total made: 34205)
If i can supply any other specific details, let me know which/where. I do not want to provide full log, only in private. Thank you @HelloZeroNet Thanks, issue reappeared probably, so i sent you my log via yours mentioned e-mail.  Add Slovenian translate.  Did a failed ZeroNet upgrade yesterday. Broken instance. Could not restart after upgrade. Some issue with a inconsistent bigfile parameter.  Sorry. Had to restart my comp. and lost the error message.
Could not fix the problem and did a new clean ZeroNet install. Marked my sites with "This is my site". 

OK start when local version = signed and published version and using js/all.js.zip/all.js.
Start is hanging when local version != signed and published version and using js/all.js

Found this lines in ui server log:
<pre>
[10:13:00] - Merged data/1JeHa67QEvrrFpsSow82fLypw8LoRcmCXk/js/all.js (0.10s)
[10:13:00] - UiWSGIHandler error: TypeError: argument of type 'bool' is not iterable in UiServer.py line 40 > pywsgi.py line 494 > UiServer.py line 91 > UiRequest.py line 130 > MutePlugin.py line 138 > UiRequest.py line 272 > UiRequestPlugin.py line 22 > TranslateSitePlugin.py line 25 > FilePackPlugin.py line 66 > UiRequest.py line 473 > BigfilePlugin.py line 111 > BigfilePlugin.py line 381
[10:13:00] Ui.UiServer 127.0.0.1 - - [2017-10-06 10:13:00] "GET /moneynetwork.bit/js/all.js HTTP/1.1" 000 - 0.193103
</pre>

all.js file is created on file system but is not downloaded to browser / not found under sources in browser console.

Did a siteSign without publish and no problems right now. all.js is being generated and used in browser without problems for some time. Now hanging again. Switching to an other computer with an old ZeroNet instance later today and I am hoping that will work without any problems. Have upgrated to rev3098. Still having a problem with hanging zite as descripted above. 
Now without any error messages in UI server log. siteSign without publish option works fine as a workaround Found the problem. I now sign and publish with all.js.zip and without all.js. No reason to publish with all.js when all.js.zip is the file being used in index.html. OK sign and publish.
Developing: switching to all.js, update some js and press f5 (site is hanging, no error messages and all.js is missing in content.json).
SiteSign: now both all.js and all.js.zip is in content.json. pass f5 and site is working ok in development mode  Err: IOError: [Errno 2] No such file or directory: 'src/Ui/template/wrapper.html' in UiServer.py line 94 > UiRequest.py line 113 > MutePlugin.py line 138 > UiRequest.py line 282 > UiRequest.py line 379 > UiRequest.py line 232

Details:
{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate, br", 
    "HTTP_ACCEPT_LANGUAGE": "zh-CN,zh;q=0.8", 
    "HTTP_CACHE_CONTROL": "max-age=0", 
    "HTTP_CONNECTION": "keep-alive", 
    "HTTP_DNT": "1", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36", 
    "PATH_INFO": "/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
    "QUERY_STRING": "", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "59503", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "ishland", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.2 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bind": null, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": "type %s | tools\\coffee\\coffee.cmd", 
        "config_file": "D:/ZeroNet-win-dist/zeronet.conf", 
        "connected_limit": 8, 
        "data_dir": "D:/ZeroNet-win-dist/data", 
        "db_mode": "speed", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "download_optional": "manual", 
        "end": true, 
        "file_size_limit": 10, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "fix_float_decimals": false, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "ip_local": [
            "127.0.0.1"
        ], 
        "keep_ssl_cert": false, 
        "language": "zh", 
        "log_dir": "D:/ZeroNet-win-dist/log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": false, 
        "open_browser": "", 
        "optional_limit": "10%", 
        "proxy": null, 
        "silent": false, 
        "size_limit": 10, 
        "stack_size": null, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_hs_limit": 10, 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.opentrackr.org:1337/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_host": null, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "updatesite": "1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp", 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false, 
        "workers": 5
    }, 
    "plugins": [
        "AnnounceZero", 
        "Cors", 
        "CryptMessage", 
        "FilePack", 
        "MergerSite", 
        "Mute", 
        "Newsfeed", 
        "OptionalManager", 
        "PeerDb", 
        "Sidebar", 
        "Stats", 
        "TranslateSite", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.2.1", 
    "version_python": "2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 20:42:59) [MSC v.1500 32 bit (Intel)]", 
    "version_zeronet": "0.5.7 r2180", 
    "wsgi.url_scheme": "http"
} Duplicate of https://github.com/HelloZeroNet/ZeroNet/search?q=src%2FUi%2Ftemplate%2Fwrapper.html&type=Issues&utf8=%E2%9C%93 (non resolved)  When I download and run ZN using REAMDE instructions for Debian, I get this error: 
```
$ python zeronet.py 
  File "zeronet.py", line 10
    print "Starting ZeroNet", err
                           ^
SyntaxError: Missing parentheses in call to 'print'

```  ```
pi@hostname:~/Public/ZeroNet-master $ python zeronet.py --verbose peerPing Kekgy
- Starting ZeroNet...
- OpenSSL loaded, version: 01000114F
- Version: 0.5.7 r2192, Python 2.7.9 (default, Sep 17 2016, 20:26:04)
[GCC 4.9.2], Gevent: 1.0.1
- Opening a simple connection server
TorManager Connecting to Tor Controller 127.0.0.1:9051
TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 165 > socket.py line 342
TorManager Starting self-bundled Tor, due to Tor proxy port 127.0.0.1:9050 check error: No connection
- Pinging 5 times peer: Kekgy:15441...
- Unhandled exception: 'NoneType' object has no attribute 'crypt'
Traceback (most recent call last):
  File "zeronet.py", line 19, in main
    main.start()
  File "/home/pi/Public/ZeroNet-master/src/main.py", line 496, in start
    actions.call(config.action, action_kwargs)
  File "/home/pi/Public/ZeroNet-master/src/main.py", line 155, in call
    func(**kwargs)
  File "/home/pi/Public/ZeroNet-master/src/main.py", line 433, in peerPing
    print "Response time: %.3fs (crypt: %s)" % (peer.ping(), peer.connection.crypt)
AttributeError: 'NoneType' object has no attribute 'crypt'

- Pinging 5 times peer: boot.zeronet.io:15441...
Response time: 1.441s (crypt: tls-rsa)
Response time: 0.168s (crypt: tls-rsa)
Response time: 0.165s (crypt: tls-rsa)
Response time: 0.165s (crypt: tls-rsa)
Response time: 0.169s (crypt: tls-rsa)
Reconnect test...
Response time: 1.093s (crypt: tls-rsa)
Response time: 0.163s (crypt: tls-rsa)
Response time: 0.163s (crypt: tls-rsa)
Response time: 0.168s (crypt: tls-rsa)
Response time: 0.620s (crypt: tls-rsa)
``` @HelloZeroNet This one works! But my zite address is correct. I know it 100%, because it worked the first time. But after that, never again. Okay, well still doesn't solve the problem, that ZeroNet doesn't work on Raspi 0W and especially with Tor enabled it works even less.

`[15:23:58] Site:Kekgy Announce to 0 trackers in 0.324s, failed` `[15:24:35] Site:1Name2..hM9F Announce to 0 trackers in 0.013s, failed                                                         "hostname" 15:24 03-Oct-17[15:24:50] FileServer Internet offline` I need help! Why do I always hear chirping crickets when something is supposed to run on Raspi... Because if someone has a really stupid problem they get answers immediately. I need support! @Akito13 brother, the community needs help as well, and these inputs from you are valuable indeed.
However you can't really demand support for this. I own a rasp cluster of 5 boards myself, and I am fixing the kubernetes there in order to get all my personal tests up and running. 
Will probably have news this week, and will try to run a Zeronet node on each board. My main problem I am behind many firewalls and don't know if will it work anyhow as a way to publish distributed data, however will surely know if Zeronet will work there or not, and let you know. Don't take this personal, however the project guys are maybe dealing with some issue more people needs right away- other than PI support. I will try this week. cheers!
 @mmatoscom Considering the current evolution of (mainstream-)IT anything related to making something run on a microboard, especially the Raspberry Pi, should have #1 priority. IoT has just started and the demand rises every single day. Making it seem like this is not as important is therefore not depicting the current reality. It is unlikely to do with Raspberry Pi. I get the same error if I try to ping non-existant host. Do you have Kengy IP in your /etc/hosts? What does `telnet Kengy 15441` say? As far as I understand, peerPing command takes a normal IP address or a normal DNS name that resolves to an IP address or a hostname assigned an address in /etc/hosts.

I run zeronet on an ARM board on Arch Linux ARM, all works. @radfish Okay, I didn't expect readers to take this so literally. Actually I don't care if peerPing works, at all. I just wanted to point out, that my zite isn't reachable anymore which is one part of a big problem when trying to run 0Net on Raspi. Now I know that peerPing only works for the normal net and not for 0net. Therefore I couldn't care less about peerPing right now. The big picture is that 0n is still not working on Raspi after such a long time of trying to get support and going different ways of running the program. It's pretty simple: I need support to make ZeroNet run on Raspi 0W. That's all.  Ui.UiServer Media referrer error: http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/css/all.css not allowed from https://zer0n.rocks/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/?wrapper_nonce=7bb8458fef4fa31c7f297dba0844758838d409c71c7f66579acee066e5c1cf0f


![2017-09-29 22 17 54](https://user-images.githubusercontent.com/4054841/31019976-293003a0-a4f7-11e7-8474-69d714e1dbb3.png)


Request Header:
```
Host: zer0n.rocks
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:55.0) Gecko/20100101 Firefox/55.0
Accept: text/css,*/*;q=0.1
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Referer: https://zer0n.rocks/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/?wrapper_nonce=977893fe138e7846a37a802ce7b1ea5964a43a60327c0beda1d152c9e5fcd9a6
Cookie: session_id=2d8dCG9kTLXiQUqBdYWJbIV3Sn
DNT: 1
Connection: keep-alive
```

Detail:
```
"GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/css,*/*;q=0.1", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate, br", 
    "HTTP_ACCEPT_LANGUAGE": "en-US,en;q=0.5", 
    "HTTP_CONNECTION": "upgrade", 
    "HTTP_DNT": "1", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_REFERER": "https://zer0n.rocks/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/?wrapper_nonce=977893fe138e7846a37a802ce7b1ea5964a43a60327c0beda1d152c9e5fcd9a6", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:55.0) Gecko/20100101 Firefox/55.0", 
    "HTTP_X_FORWARDED_FOR": "121.33.131.143", 
    "HTTP_X_REAL_IP": "121.33.131.143", 
    "PATH_INFO": "/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/css/all.css", 
    "QUERY_STRING": "", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "45508", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "localhost.localdomain", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.2 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bind": null, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": null, 
        "config_file": "zeronet.conf", 
        "connected_limit": 8, 
        "data_dir": "data", 
        "db_mode": "speed", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "download_optional": "manual", 
        "end": true, 
        "file_size_limit": 10, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "fix_float_decimals": false, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "ip_local": [
            "127.0.0.1"
        ], 
        "keep_ssl_cert": false, 
        "language": "en", 
        "log_dir": "log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": false, 
        "open_browser": null, 
        "optional_limit": "10%", 
        "proxy": null, 
        "silent": false, 
        "size_limit": 10, 
        "stack_size": null, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_hs_limit": 10, 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.opentrackr.org:1337/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_host": null, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "updatesite": "1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp", 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false, 
        "workers": 5
    }, 
    "plugins": [
        "AnnounceZero", 
        "Cors", 
        "CryptMessage", 
        "FilePack", 
        "MergerSite", 
        "Mute", 
        "Newsfeed", 
        "OptionalManager", 
        "PeerDb", 
        "Sidebar", 
        "Stats", 
        "TranslateSite", 
        "Trayicon", 
        "UiPassword", 
        "Zeroname"
    ], 
    "version_gevent": "1.2.2", 
    "version_python": "2.7.14 (default, Sep 25 2017, 21:21:52) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-18)]", 
    "version_zeronet": "0.5.7 r2192", 
    "wsgi.url_scheme": "http"
```

Nginx Config:
```
server {
    listen  443 ssl;
    server_name  zer0n.rocks;
    ssl_certificate /etc/letsencrypt/live/zer0n.rocks/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/zer0n.rocks/privkey.pem;
    ssl_protocols TLSv1.2;
    ssl_prefer_server_ciphers on;
    ssl_ciphers 'ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256';
    ssl_session_timeout 1d;
    ssl_session_cache shared:SSL:50m;
    ssl_stapling on;
    ssl_stapling_verify on;
    add_header Strict-Transport-Security max-age=15768000;

    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
        autoindex on;
        proxy_pass http://127.0.0.1:43110;
        proxy_set_header Host "127.0.0.1:43110";
        proxy_http_version 1.1;
        proxy_read_timeout 1h;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;
}
server {
    listen 80;
    server_name zer0n.rocks;
    return 301 https://$host$request_uri;
}
```  Also return `data_dir`, `log_dir` and `src_dir` (for scripts). This is not yet finished, don't merge please. @HelloZeroNet, I've just understood it and marked this PR as [WIP].  Adds notification "Clone site **1HeLLo...**? `Clone`" for non-admin sites. For sites with ADMIN permission, leave everything as is.

Rejects `{"error": "Not a site: something"}` if `address` is not valid. If source site wasn't downloaded yet, stop cloning, but don't tell the client about it to avoid exposing site existense.  Currently there is `siteSign`, `sitePublish`, etc. available via `python zeronet.py`. What about also adding `siteUpdate`? It would be interesting if ZeroNet is not running but you want to get the latest version of the site via script or something like that. @HelloZeroNet Yes, looks like that. Thanks!  Looks like `zeronet.py` is designed for *a)* those who don't use browser, *b)* scripts. This patch adds some more script commands (`getDataDir`, `getLogDir`, `getRootDir`) because paths can vary on different systems. /cc @HelloZeroNet @shortcutme  @HelloZeroNet Then take a look at #1123, please.  *Conversation moved to ZeroMail. @shortcutme, I've sent you a mail. Please check as soon a possible. I'll publish mail here when this is fixed.* > Internal error: Exception: No merger (MY_MERGED_SITE) permission to load: merged-SomeID/MY_MERGED_SITE/content.json (SomeID not in []) in UiWebsocket.py line 211 > MergerSitePlugin.py line 151 > MergerSitePlugin.py line 127 > MergerSitePlugin.py line 43

But Merger:SomeID appears in sites.json for MY_MERGER_SITE. And MY_MERGED_SITE has merged_type: "SomeID" in its content.json.

Interesting fact:

```javascript
zeroFrame.cmd("fileGet", ["merged-SomeID/MY_MERGED_SITE/content.json"]); // works
```

...but

```javascript
zeroFrame.cmd("fileGet", ["merged-SomeID/MY_MERGED_SITE/conten.json"]); // note a typo; hangs
zeroFrame.cmd("fileGet", ["merged-SomeID/MY_MERGED_SITE/content.json"]); // shows error
```

**UPD**
When running fileGet for merged-... paths, MergerSite plugin changes self.site address to merged, then executes query, then returns address back. I could reproduce this:

```javascript
zeroFrame.cmd("fileGet", ["merged-SomeID/MY_MERGED_SITE/conten.json"]); // note a typo; hangs
zeroFrame.cmd("fileGet", ["content.json"]); // returns MY_MERGED_SITE content.json
```

That means while first fileGet command is searching for conten.json, second fileGet has MY_MERGED_SITE address in self.site property and tries to read content.json from MY_MERGED_SITE.

A good solution is to create a new Site object for each fileGet, fileWrite, etc. commands.

**UPD URGENT**

Cors plugin is not really read-only. Using timing attack I can write data to CORS site if I already have Cors permission!

```javascript
zeroFrame.cmd("fileGet", ["cors-1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz/a/content.json", true, "text", 20000]); // Change address to ZeroID for ~300 hours
zeroFrame.cmd("fileWrite", ["content.json", ...]); // Write file
```  SK-CSIRT identified malicious software libraries in the official Python package repository. There is more on this issue here http://www.nbu.gov.sk/skcsirt-sa-20170909-pypi/  #1113  Hi.

I'm trying to run Zeronet on a laptop using [Subgraph OS](https://subgraph.com/), the self-proclaimed _adversary resistant computing platform_. It's an operational system based on Debian and, much like its privacy oriented counterpart Tails OS, it uses what it refers to as a "metaproxy" in order to route all traffic through tor.

I've installed Zeronet following the installation instructions provided for Debian, also, I've downloaded the required dependencies from their official repository. The installation process runs without errors, though ultimately Zeronet fails to launch:
```
user@subgraph:~$ python ZeroNet-master/zeronet.py 
- Starting ZeroNet...
[15:07:04] - OpenSSL loaded, version: 0100020CF
[15:07:04] - Version: 0.5.7 r2190, Python 2.7.13 (default, Jan 19 2017, 14:48:08) 
[GCC 6.3.0 20170118], Gevent: 1.1.2
[15:07:04] - Creating FileServer....
[15:07:04] TorManager Connecting to Tor Controller 127.0.0.1:9051
^CShutting down...
[15:14:14] - Unhandled exception
None
KeyboardInterrupt
```

I've sought and found attempts to troubleshoot this problem here at [Github](https://github.com/HelloZeroNet/ZeroNet/issues/610) and [Reddit](https://github.com/HelloZeroNet/ZeroNet/issues/610). Though they were experienced by users of Tails. Still, I tried the solution proposed unanimouslyby both treads.

> I have installed Tails in a VM and this one worked for me:
> 
> zeronet.py --proxy 127.0.0.1:9050 --tor disable --ui_ip 10.0.2.16 (your ip can be different from this use /sbin/ifconfig to see yours)
> 
> Then access using http://10.0.2.16:43110

These are my network interfaces as described by ifconfig:
```
enp2s0: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500
        ether c4:34:8f:ab:db:34  txqueuelen 1000  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536
        inet 127.0.0.1  netmask 255.0.0.0
        loop  txqueuelen 1  (Local Loopback)
        RX packets 99129  bytes 33654317 (32.0 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 99129  bytes 33654317 (32.0 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

oz-clear: flags=67<UP,BROADCAST,RUNNING>  mtu 1500
        inet 10.0.1.1  netmask 255.255.255.0  broadcast 0.0.0.0
        ether aa:da:88:8d:6e:93  txqueuelen 1000  (Ethernet)
        RX packets 25808  bytes 2604749 (2.4 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 35411  bytes 52660576 (50.2 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

vozTJcEyg: flags=67<UP,BROADCAST,RUNNING>  mtu 1500
        ether aa:da:88:8d:6e:93  txqueuelen 0  (Ethernet)
        RX packets 18702  bytes 2125764 (2.0 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 26381  bytes 43486281 (41.4 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

wlp3s0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 192.168.0.18  netmask 255.255.255.0  broadcast 192.168.0.255
        ether 3c:97:0f:79:86:a0  txqueuelen 1000  (Ethernet)
        RX packets 73846  bytes 84383411 (80.4 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 52848  bytes 12957734 (12.3 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
```
Hence I tried the following command:
```
user@subgraph:~$ python ZeroNet-master/zeronet.py --proxy 127.0.0.1:9050 --tor disable --ui_ip 10.0.1.1
- Starting ZeroNet...
[15:37:47] - OpenSSL loaded, version: 0100020CF
[15:37:47] - Patching sockets to socks proxy: 127.0.0.1:9050
[15:37:47] - Version: 0.5.7 r2190, Python 2.7.13 (default, Jan 19 2017, 14:48:08) 
[GCC 6.3.0 20170118], Gevent: 1.1.2
[15:37:47] - Creating FileServer....
[15:37:47] - Creating UiServer....
[15:37:47] - Removing old SSL certs...
[15:37:47] - Starting servers....
[15:37:47] Ui.UiServer --------------------------------------
[15:37:47] Ui.UiServer Web interface: http://10.0.1.1:43110/
[15:37:47] Ui.UiServer --------------------------------------
[15:37:48] FileServer Checking port 15441 using P2P...
[15:37:48] FileServer Checking port 15441 using portchecker.co...
[15:37:52] FileServer [BAD :(] Port closed: Port 15441 is closed.
[15:37:52] FileServer Trying to open port using UpnpPunch...
[15:38:08] FileServer UpnpPunch run error: UpnpError: Failed to communicate with igd using port 15441 on local machine after 3 tries. in FileServer.py line 75 > UpnpPunch.py line 325 > UpnpPunch.py line 316
^CShutting down...
[15:38:37] - Unhandled exception
None
KeyboardInterrupt
```
Still, using both the Tor Browser and the clearnet enabled Chromium, the web interface failed to load. Also, I've checked my router configuration to make sure that it is fowarding port 15441, though I'm  not sure if it that's a relevant factor if not for publishing content at the Zeronet.

I tried running the same command modified like so `python ZeroNet-master/zeronet.py --proxy 10.0.1.1:9050 --tor disable`, and I've got a slightly different response from the terminal running the command after the `FileServer [BAD :(]` part:
```
[16:05:51] FileServer [BAD :(] Port closed: Error: GeneralProxyError: Socket error: [Errno 104] Connection reset by peer in FileServer.py line 137 > urllib2.py line 154 > urllib2.py line 429 > urllib2.py line 447 > urllib2.py line 407 > urllib2.py line 1241 > urllib2.py line 1195 > httplib.py line 1042 > httplib.py line 1082 > httplib.py line 1038 > httplib.py line 882 > httplib.py line 844 > httplib.py line 1255 > httplib.py line 821 > SocksProxy.py line 12 > socks.py line 685
[16:05:51] FileServer Trying to open port using UpnpPunch...
[16:06:06] FileServer UpnpPunch run error: UpnpError: Failed to communicate with igd using port 15441 on local machine after 3 tries. in FileServer.py line 75 > UpnpPunch.py line 325 > UpnpPunch.py line 316
^CShutting down...
[16:06:37] - Unhandled exception
None
KeyboardInterrupt
```
Also, while performing these tests, I've had another terminal side-by-side running the command `sudo journalctl -f`. This terminal did not respond to the requests performed by executing `zeronet.py` before. Though, now it did:
```
Sep 04 16:05:44 subgraph sudo[4422]: pam_unix(sudo:session): session opened for user root by (uid=0)
Sep 04 16:05:50 subgraph fw-daemon[750]: NOTI 21f0 ALLOW|10.0.1.1:9050 > /usr/bin/python2.7 TCP 10.0.1.1:45170 -> 10.0.1.1:9050
Sep 04 16:05:50 subgraph fw-daemon[750]: NOTI 21f3 ALLOW|10.0.1.1:9050 > /usr/bin/python2.7 TCP 10.0.1.1:45172 -> 10.0.1.1:9050
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: No specific policy for client destination port, using wildcard relay for port: 9050
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: Opening SOCKS5 relay.
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: No specific policy for client destination port, using wildcard relay for port: 9050
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: Opening SOCKS5 relay.
Sep 04 16:05:50 subgraph fw-daemon[750]: NOTI 21f6 ALLOW|10.0.1.1:9050 > /usr/bin/python2.7 TCP 10.0.1.1:45174 -> 10.0.1.1:9050
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: No specific policy for client destination port, using wildcard relay for port: 9050
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: Opening SOCKS5 relay.
Sep 04 16:05:50 subgraph fw-daemon[750]: NOTI 21f9 ALLOW|10.0.1.1:9050 > /usr/bin/python2.7 TCP 10.0.1.1:45176 -> 10.0.1.1:9050
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: No specific policy for client destination port, using wildcard relay for port: 9050
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: Opening SOCKS5 relay.
Sep 04 16:05:50 subgraph fw-daemon[750]: NOTI 21fc ALLOW|10.0.1.1:9050 > /usr/bin/python2.7 TCP 10.0.1.1:45178 -> 10.0.1.1:9050
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: No specific policy for client destination port, using wildcard relay for port: 9050
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: Opening SOCKS5 relay.
Sep 04 16:05:50 subgraph fw-daemon[750]: NOTI 21ff ALLOW|10.0.1.1:9050 > /usr/bin/python2.7 TCP 10.0.1.1:45180 -> 10.0.1.1:9050
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: No specific policy for client destination port, using wildcard relay for port: 9050
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: Opening SOCKS5 relay.
Sep 04 16:05:50 subgraph fw-daemon[750]: NOTI 2202 ALLOW|10.0.1.1:9050 > /usr/bin/python2.7 TCP 10.0.1.1:45182 -> 10.0.1.1:9050
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: No specific policy for client destination port, using wildcard relay for port: 9050
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: Opening SOCKS5 relay.
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: Error dialing SOCKS5 proxy at 127.0.0.1:9050: proxy: SOCKS5 proxy at 127.0.0.1:9050 failed to connect: general failure
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: Error dialing SOCKS5 proxy at 127.0.0.1:9050: proxy: SOCKS5 proxy at 127.0.0.1:9050 failed to connect: general failure
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: Error dialing SOCKS5 proxy at 127.0.0.1:9050: proxy: SOCKS5 proxy at 127.0.0.1:9050 failed to connect: general failure
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: Error dialing SOCKS5 proxy at 127.0.0.1:9050: proxy: SOCKS5 proxy at 127.0.0.1:9050 failed to connect: general failure
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: Error dialing SOCKS5 proxy at 127.0.0.1:9050: proxy: SOCKS5 proxy at 127.0.0.1:9050 failed to connect: general failure
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: Error dialing SOCKS5 proxy at 127.0.0.1:9050: proxy: SOCKS5 proxy at 127.0.0.1:9050 failed to connect: general failure
Sep 04 16:05:50 subgraph subgraph-metaproxy[901]: Error dialing SOCKS5 proxy at 127.0.0.1:9050: proxy: SOCKS5 proxy at 127.0.0.1:9050 failed to connect: general failure
Sep 04 16:05:51 subgraph fw-daemon[750]: NOTI 220c ALLOW|10.0.1.1:9050 > /usr/bin/python2.7 TCP 10.0.1.1:45198 -> 10.0.1.1:9050
Sep 04 16:05:51 subgraph subgraph-metaproxy[901]: No specific policy for client destination port, using wildcard relay for port: 9050
Sep 04 16:05:51 subgraph subgraph-metaproxy[901]: Opening SOCKS5 relay.
Sep 04 16:05:51 subgraph subgraph-metaproxy[901]: Error dialing SOCKS5 proxy at 127.0.0.1:9050: proxy: SOCKS5 proxy at 127.0.0.1:9050 failed to connect: general failure
Sep 04 16:05:53 subgraph fw-daemon[750]: NOTI 2212 ALLOW|10.0.1.1:9050 > /usr/bin/python2.7 TCP 10.0.1.1:45202 -> 10.0.1.1:9050
Sep 04 16:05:53 subgraph subgraph-metaproxy[901]: No specific policy for client destination port, using wildcard relay for port: 9050
Sep 04 16:05:53 subgraph subgraph-metaproxy[901]: Opening SOCKS5 relay.
Sep 04 16:05:53 subgraph subgraph-metaproxy[901]: Error dialing SOCKS5 proxy at 127.0.0.1:9050: proxy: SOCKS5 proxy at 127.0.0.1:9050 failed to connect: general failure
Sep 04 16:05:53 subgraph fw-daemon[750]: NOTI 2216 ALLOW|10.0.1.1:9050 > /usr/bin/python2.7 TCP 10.0.1.1:45206 -> 10.0.1.1:9050
Sep 04 16:05:53 subgraph subgraph-metaproxy[901]: No specific policy for client destination port, using wildcard relay for port: 9050
Sep 04 16:05:53 subgraph subgraph-metaproxy[901]: Opening SOCKS5 relay.
Sep 04 16:05:53 subgraph subgraph-metaproxy[901]: Error dialing SOCKS5 proxy at 127.0.0.1:9050: proxy: SOCKS5 proxy at 127.0.0.1:9050 failed to connect: general failure
[...]
```
It then goes on and on trying different ports to make a TCP connection and failing to do so.

Well. That's it, that's all I know. Any guidance from here will be appreciated.

Thanks! In src/Tor/TorManager.py, can you change the while loop starting at line 266 to look like this:
```py
                while not back.endswith("250 OK\r\n"):
                    back += conn.recv(1024 * 64).decode("utf8", "ignore")
                    self.log.debug(str(back))  # add this line
```

Once you've done that, try re-running 0net with tor enabled, and post the log. Here @skwerlman:
```
user@subgraph:~$ python ZeroNet-master/zeronet.py --debug
- Starting ZeroNet...
[18:55:16] PluginManager Loading plugin: AnnounceZero
[18:55:16] PluginManager New plugin registered to: Site
[18:55:16] PluginManager Loading plugin: Cors
[18:55:16] - Translate file not exists: src/Translate/languages/en.json
[18:55:16] - Translate file not exists: plugins/Cors/languages/en.json
[18:55:16] PluginManager New plugin registered to: UiWebsocket
[18:55:16] PluginManager New plugin registered to: UiRequest
[18:55:16] PluginManager Loading plugin: CryptMessage
[18:55:16] - Opening libssl.so.1.0.2...
[18:55:16] - Disabled SSL compression on <CDLL 'libssl.so.1.0.2', handle 51eefbaf20 at 36809fe0f10>
[18:55:16] - Missing SSLwrap, readded.
[18:55:16] - Python SSL version: OpenSSL 1.1.0f  25 May 2017
[18:55:16] - opensslVerify loaded: <CDLL 'libssl.so.1.0.2', handle 51eefbaf20 at 36809fca250>
[18:55:16] - OpenSSL loaded, version: 0100020CF
[18:55:16] PluginManager New plugin registered to: UiWebsocket
[18:55:16] PluginManager New plugin registered to: User
[18:55:16] PluginManager Loading plugin: FilePack
[18:55:16] PluginManager New plugin registered to: UiRequest
[18:55:16] PluginManager New plugin registered to: SiteStorage
[18:55:16] PluginManager Loading plugin: MergerSite
[18:55:16] PluginManager New plugin registered to: ContentDb
[18:55:16] PluginManager New plugin registered to: WorkerManager
[18:55:16] PluginManager New plugin registered to: UiRequest
[18:55:16] PluginManager New plugin registered to: FileRequest
[18:55:16] PluginManager New plugin registered to: Site
[18:55:16] PluginManager New plugin registered to: ConfigPlugin
[18:55:16] - Translate file not exists: plugins/OptionalManager/languages/en.json
[18:55:16] PluginManager New plugin registered to: UiWebsocket
[18:55:16] - Translate file not exists: plugins/MergerSite/languages/en.json
[18:55:16] PluginManager New plugin registered to: UiWebsocket
[18:55:16] PluginManager New plugin registered to: UiRequest
[18:55:16] PluginManager New plugin registered to: SiteStorage
[18:55:16] PluginManager New plugin registered to: Site
[18:55:16] PluginManager New plugin registered to: SiteManager
[18:55:16] PluginManager Loading plugin: Mute
[18:55:16] - Translate file not exists: plugins/Mute/languages/en.json
[18:55:16] PluginManager New plugin registered to: UiWebsocket
[18:55:16] PluginManager New plugin registered to: SiteStorage
[18:55:16] PluginManager New plugin registered to: UiRequest
[18:55:16] PluginManager Loading plugin: Newsfeed
[18:55:16] PluginManager New plugin registered to: UiWebsocket
[18:55:16] PluginManager New plugin registered to: User
[18:55:16] PluginManager Loading plugin: OptionalManager
[18:55:16] PluginManager Loading plugin: PeerDb
[18:55:16] PluginManager New plugin registered to: ContentDb
[18:55:16] PluginManager Loading plugin: Sidebar
[18:55:16] - Translate file not exists: plugins/Sidebar/languages/en.json
[18:55:16] PluginManager New plugin registered to: UiRequest
[18:55:16] PluginManager New plugin registered to: UiWebsocket
[18:55:16] PluginManager Loading plugin: Stats
[18:55:16] PluginManager New plugin registered to: UiRequest
[18:55:16] PluginManager Loading plugin: TranslateSite
[18:55:16] PluginManager New plugin registered to: UiRequest
[18:55:16] PluginManager Loading plugin: Trayicon
[18:55:16] PluginManager Loading plugin: Zeroname
[18:55:16] PluginManager New plugin registered to: UiRequest
[18:55:16] PluginManager New plugin registered to: ConfigPlugin
[18:55:16] PluginManager New plugin registered to: SiteManager
[18:55:16] PluginManager New class accepts plugins: ConfigPlugin (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.ConfigPlugin'>, <class 'OptionalManager.OptionalManagerPlugin.ConfigPlugin'>, <class 'Config.ConfigPlugin'>])
[18:55:16] - Config: Config(action='main', batch=False, bind=None, bit_resolver='1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F', coffeescript_compiler=None, config_file='zeronet.conf', connected_limit=8, data_dir='data', db_mode='speed', debug=True, debug_gevent=False, debug_socket=False, disable_db=False, disable_encryption=False, disable_sslcompression=True, disable_udp=False, download_optional='manual', end=True, file_size_limit=10, fileserver_ip='*', fileserver_port=15441, fix_float_decimals=False, homepage='1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D', ip_external=None, ip_local=['127.0.0.1'], keep_ssl_cert=False, language='en', log_dir='log', max_files_opened=2048, msgpack_purepython=False, open_browser=None, optional_limit='10%', proxy=None, silent=False, size_limit=10, stack_size=None, stream_downloads=False, tor='enable', tor_controller='127.0.0.1:9051', tor_hs_limit=10, tor_password=None, tor_proxy='127.0.0.1:9050', trackers=['zero://boot3rdez4rzn36x.onion:15441', 'zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441', 'udp://tracker.coppersurfer.tk:6969', 'udp://tracker.leechers-paradise.org:6969', 'udp://9.rarbg.com:2710', 'http://tracker.opentrackr.org:1337/announce', 'http://explodie.org:6969/announce', 'http://tracker1.wasabii.com.tw:6969/announce'], trackers_file=False, ui_host=None, ui_ip='127.0.0.1', ui_port=43110, ui_restrict=False, updatesite='1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp', use_openssl=True, use_tempfiles=False, verbose=False, workers=5)
[18:55:16] - Version: 0.5.7 r2190, Python 2.7.13 (default, Jan 19 2017, 14:48:08) 
[GCC 6.3.0 20170118], Gevent: 1.1.2
[18:55:16] PluginManager New class accepts plugins: FileRequest (Loaded plugins: [<class 'OptionalManager.OptionalManagerPlugin.FileRequestPlugin'>, <class 'File.FileRequest.FileRequest'>])
[18:55:16] PluginManager New class accepts plugins: WorkerManager (Loaded plugins: [<class 'OptionalManager.OptionalManagerPlugin.WorkerManagerPlugin'>, <class 'Worker.WorkerManager.WorkerManager'>])
[18:55:16] PluginManager New class accepts plugins: ContentDb (Loaded plugins: [<class 'PeerDb.PeerDbPlugin.ContentDbPlugin'>, <class 'OptionalManager.ContentDbPlugin.ContentDbPlugin'>, <class 'Content.ContentDb.ContentDb'>])
[18:55:16] Db:ContentDb Connected to data/content.db in 0.009s (opened: 1, sqlite version: 2.6.0)...
[18:55:16] Db:ContentDb Db check done in 0.000s, changed tables: []
[18:55:16] PluginManager New class accepts plugins: SiteStorage (Loaded plugins: [<class 'Mute.MutePlugin.SiteStoragePlugin'>, <class 'MergerSite.MergerSitePlugin.SiteStoragePlugin'>, <class 'FilePack.FilePackPlugin.SiteStoragePlugin'>, <class 'Site.SiteStorage.SiteStorage'>])
[18:55:16] PluginManager New class accepts plugins: SiteManager (Loaded plugins: [<class 'Zeroname.SiteManagerPlugin.SiteManagerPlugin'>, <class 'MergerSite.MergerSitePlugin.SiteManagerPlugin'>, <class 'Site.SiteManager.SiteManager'>])
[18:55:16] SiteManager SiteManager created.
[18:55:16] PluginManager New class accepts plugins: Site (Loaded plugins: [<class 'MergerSite.MergerSitePlugin.SitePlugin'>, <class 'OptionalManager.OptionalManagerPlugin.SitePlugin'>, <class 'AnnounceZero.AnnounceZeroPlugin.SitePlugin'>, <class 'Site.Site.Site'>])
[18:55:16] PluginManager New class accepts plugins: User (Loaded plugins: [<class 'Newsfeed.NewsfeedPlugin.UserPlugin'>, <class 'CryptMessage.CryptMessagePlugin.UserPlugin'>, <class 'User.User.User'>])
[18:55:16] PluginManager New class accepts plugins: UiWebsocket (Loaded plugins: [<class 'Sidebar.SidebarPlugin.UiWebsocketPlugin'>, <class 'Newsfeed.NewsfeedPlugin.UiWebsocketPlugin'>, <class 'Mute.MutePlugin.UiWebsocketPlugin'>, <class 'MergerSite.MergerSitePlugin.UiWebsocketPlugin'>, <class 'OptionalManager.UiWebsocketPlugin.UiWebsocketPlugin'>, <class 'CryptMessage.CryptMessagePlugin.UiWebsocketPlugin'>, <class 'Cors.CorsPlugin.UiWebsocketPlugin'>, <class 'Ui.UiWebsocket.UiWebsocket'>])
[18:55:16] PluginManager New class accepts plugins: UiRequest (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.UiRequestPlugin'>, <class 'TranslateSite.TranslateSitePlugin.UiRequestPlugin'>, <class 'Stats.StatsPlugin.UiRequestPlugin'>, <class 'Sidebar.SidebarPlugin.UiRequestPlugin'>, <class 'Mute.MutePlugin.UiRequestPlugin'>, <class 'MergerSite.MergerSitePlugin.UiRequestPlugin'>, <class 'OptionalManager.OptionalManagerPlugin.UiRequestPlugin'>, <class 'FilePack.FilePackPlugin.UiRequestPlugin'>, <class 'Cors.CorsPlugin.UiRequestPlugin'>, <class 'Ui.UiRequest.UiRequest'>])
[18:55:16] - Creating FileServer....
[18:55:16] TorManager Connecting to Tor Controller 127.0.0.1:9051
[18:55:16] TorManager > PROTOCOLINFO
[18:55:16] TorManager 250-PROTOCOLINFO 1
250-AUTH METHODS=NULL,HASHEDPASSWORD
250-VERSION Tor="0.2.9.11"
250 OK

[18:55:16] TorManager < 250-PROTOCOLINFO 1
250-AUTH METHODS=NULL,HASHEDPASSWORD
250-VERSION Tor="0.2.9.11"
250 OK
[18:55:16] TorManager > AUTHENTICATE
[18:55:16] TorManager 250 OK

[18:55:16] TorManager < 250 OK
[18:55:16] TorManager > GETINFO version
[18:55:16] TorManager 510 Tor Control command proxy denied: filtration policy.

[19:00:16] Db:ContentDb Optional size: 0.0MB/86750.9MB, Need delete: -86750.9MB
[19:05:16] Db:ContentDb Optional size: 0.0MB/86777.1MB, Need delete: -86777.1MB
[19:05:16] SiteManager Save skipped: No sites found
[19:10:16] Db:ContentDb Optional size: 0.0MB/86777.8MB, Need delete: -86777.8MB
``` the issue is at this line: `[18:55:16] TorManager 510 Tor Control command proxy denied: filtration policy.`

My guess is that [this](https://github.com/subgraph/roflcoptor) is filtering your tor control connections, which is causing issues for 0net. @skwerlman, yes, that was the case. I've read its documentation and was able to allow Zeronet to peform commands that where previously blocked, making its initialization process move further. Still, it is not yet complete.

By running ROFLcoptor in watch mode I was able to spot it blocking the Zeronet client attempt at connection. Here is the last output from the terminal launching Zeronet:
```[00:49:23] TorManager Connecting to Tor Controller 127.0.0.1:9051```
And a corresponding response in the terminal running ROFLcoptor:
```2017/09/05 00:49:23 filter policy for gnome-shell-torstatus DENY: A->T: [GETINFO version]```
I then modified the /etc/roflcoptor/filters/gnome-shell.json file and was able to pass this stage, eventually getting and error related to the command ADD_ONION. I then modified the file again reaching its current state:
```
{
    "Name": "gnome-shell-torstatus",
    "AuthNetAddr" : "tcp",
    "AuthAddr" : "127.0.0.1:9051",
    "client-allowed" : ["GETINFO status/bootstrap-phase", "GETINFO version", "SIGNAL NEWNYM"],
    "client-allowed-prefixes" : ["ADD_ONION", "DEL_ONION"],
    "client-replacements" : {},
    "client-replacement-prefixes" : {},
    "server-allowed" : ["250 OK", "250 __OwningControllerProcess"],
    "server-allowed-prefixes" : ["250-status/bootstrap-phase=", "250-version="],
    "server-replacement-prefixes" : {}
}
```

Now, when I run ROFLcoptor in watch mode, it does not point out to any blocked connections. Still, Zeronet's initialization is now stopping at this point:
```
user@subgraph:~$ python ZeroNet-master/zeronet.py --debug
- Starting ZeroNet...
[14:24:15] PluginManager Loading plugin: AnnounceZero
[14:24:15] PluginManager New plugin registered to: Site
[14:24:15] PluginManager Loading plugin: Cors
[14:24:15] - Translate file not exists: src/Translate/languages/en.json
[14:24:15] - Translate file not exists: plugins/Cors/languages/en.json
[14:24:15] PluginManager New plugin registered to: UiWebsocket
[14:24:15] PluginManager New plugin registered to: UiRequest
[14:24:15] PluginManager Loading plugin: CryptMessage
[14:24:15] - Opening libssl.so.1.0.2...
[14:24:15] - Disabled SSL compression on <CDLL 'libssl.so.1.0.2', handle 67d94663f0 at 31e31db8f10>
[14:24:15] - Missing SSLwrap, readded.
[14:24:15] - Python SSL version: OpenSSL 1.1.0f  25 May 2017
[14:24:15] - opensslVerify loaded: <CDLL 'libssl.so.1.0.2', handle 67d94663f0 at 31e31da2250>
[14:24:15] - OpenSSL loaded, version: 0100020CF
[14:24:15] PluginManager New plugin registered to: UiWebsocket
[14:24:15] PluginManager New plugin registered to: User
[14:24:15] PluginManager Loading plugin: FilePack
[14:24:15] PluginManager New plugin registered to: UiRequest
[14:24:15] PluginManager New plugin registered to: SiteStorage
[14:24:15] PluginManager Loading plugin: MergerSite
[14:24:15] PluginManager New plugin registered to: ContentDb
[14:24:15] PluginManager New plugin registered to: WorkerManager
[14:24:15] PluginManager New plugin registered to: UiRequest
[14:24:15] PluginManager New plugin registered to: FileRequest
[14:24:15] PluginManager New plugin registered to: Site
[14:24:15] PluginManager New plugin registered to: ConfigPlugin
[14:24:15] - Translate file not exists: plugins/OptionalManager/languages/en.json
[14:24:15] PluginManager New plugin registered to: UiWebsocket
[14:24:15] - Translate file not exists: plugins/MergerSite/languages/en.json
[14:24:15] PluginManager New plugin registered to: UiWebsocket
[14:24:15] PluginManager New plugin registered to: UiRequest
[14:24:15] PluginManager New plugin registered to: SiteStorage
[14:24:15] PluginManager New plugin registered to: Site
[14:24:15] PluginManager New plugin registered to: SiteManager
[14:24:15] PluginManager Loading plugin: Mute
[14:24:15] - Translate file not exists: plugins/Mute/languages/en.json
[14:24:15] PluginManager New plugin registered to: UiWebsocket
[14:24:15] PluginManager New plugin registered to: SiteStorage
[14:24:15] PluginManager New plugin registered to: UiRequest
[14:24:15] PluginManager Loading plugin: Newsfeed
[14:24:15] PluginManager New plugin registered to: UiWebsocket
[14:24:15] PluginManager New plugin registered to: User
[14:24:15] PluginManager Loading plugin: OptionalManager
[14:24:15] PluginManager Loading plugin: PeerDb
[14:24:15] PluginManager New plugin registered to: ContentDb
[14:24:15] PluginManager Loading plugin: Sidebar
[14:24:15] - Translate file not exists: plugins/Sidebar/languages/en.json
[14:24:15] PluginManager New plugin registered to: UiRequest
[14:24:15] PluginManager New plugin registered to: UiWebsocket
[14:24:15] PluginManager Loading plugin: Stats
[14:24:15] PluginManager New plugin registered to: UiRequest
[14:24:15] PluginManager Loading plugin: TranslateSite
[14:24:15] PluginManager New plugin registered to: UiRequest
[14:24:15] PluginManager Loading plugin: Trayicon
[14:24:15] PluginManager Loading plugin: Zeroname
[14:24:15] PluginManager New plugin registered to: UiRequest
[14:24:15] PluginManager New plugin registered to: ConfigPlugin
[14:24:15] PluginManager New plugin registered to: SiteManager
[14:24:15] PluginManager New class accepts plugins: ConfigPlugin (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.ConfigPlugin'>, <class 'OptionalManager.OptionalManagerPlugin.ConfigPlugin'>, <class 'Config.ConfigPlugin'>])
[14:24:15] - Config: Config(action='main', batch=False, bind=None, bit_resolver='1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F', coffeescript_compiler=None, config_file='zeronet.conf', connected_limit=8, data_dir='data', db_mode='speed', debug=True, debug_gevent=False, debug_socket=False, disable_db=False, disable_encryption=False, disable_sslcompression=True, disable_udp=False, download_optional='manual', end=True, file_size_limit=10, fileserver_ip='*', fileserver_port=15441, fix_float_decimals=False, homepage='1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D', ip_external=None, ip_local=['127.0.0.1'], keep_ssl_cert=False, language='en', log_dir='log', max_files_opened=2048, msgpack_purepython=False, open_browser=None, optional_limit='10%', proxy=None, silent=False, size_limit=10, stack_size=None, stream_downloads=False, tor='enable', tor_controller='127.0.0.1:9051', tor_hs_limit=10, tor_password=None, tor_proxy='127.0.0.1:9050', trackers=['zero://boot3rdez4rzn36x.onion:15441', 'zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441', 'udp://tracker.coppersurfer.tk:6969', 'udp://tracker.leechers-paradise.org:6969', 'udp://9.rarbg.com:2710', 'http://tracker.opentrackr.org:1337/announce', 'http://explodie.org:6969/announce', 'http://tracker1.wasabii.com.tw:6969/announce'], trackers_file=False, ui_host=None, ui_ip='127.0.0.1', ui_port=43110, ui_restrict=False, updatesite='1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp', use_openssl=True, use_tempfiles=False, verbose=False, workers=5)
[14:24:15] - Version: 0.5.7 r2190, Python 2.7.13 (default, Jan 19 2017, 14:48:08) 
[GCC 6.3.0 20170118], Gevent: 1.1.2
[14:24:15] PluginManager New class accepts plugins: FileRequest (Loaded plugins: [<class 'OptionalManager.OptionalManagerPlugin.FileRequestPlugin'>, <class 'File.FileRequest.FileRequest'>])
[14:24:15] PluginManager New class accepts plugins: WorkerManager (Loaded plugins: [<class 'OptionalManager.OptionalManagerPlugin.WorkerManagerPlugin'>, <class 'Worker.WorkerManager.WorkerManager'>])
[14:24:15] PluginManager New class accepts plugins: ContentDb (Loaded plugins: [<class 'PeerDb.PeerDbPlugin.ContentDbPlugin'>, <class 'OptionalManager.ContentDbPlugin.ContentDbPlugin'>, <class 'Content.ContentDb.ContentDb'>])
[14:24:15] Db:ContentDb Connected to data/content.db in 0.000s (opened: 1, sqlite version: 2.6.0)...
[14:24:15] Db:ContentDb Db check done in 0.000s, changed tables: []
[14:24:15] PluginManager New class accepts plugins: SiteStorage (Loaded plugins: [<class 'Mute.MutePlugin.SiteStoragePlugin'>, <class 'MergerSite.MergerSitePlugin.SiteStoragePlugin'>, <class 'FilePack.FilePackPlugin.SiteStoragePlugin'>, <class 'Site.SiteStorage.SiteStorage'>])
[14:24:15] PluginManager New class accepts plugins: SiteManager (Loaded plugins: [<class 'Zeroname.SiteManagerPlugin.SiteManagerPlugin'>, <class 'MergerSite.MergerSitePlugin.SiteManagerPlugin'>, <class 'Site.SiteManager.SiteManager'>])
[14:24:15] SiteManager SiteManager created.
[14:24:15] PluginManager New class accepts plugins: Site (Loaded plugins: [<class 'MergerSite.MergerSitePlugin.SitePlugin'>, <class 'OptionalManager.OptionalManagerPlugin.SitePlugin'>, <class 'AnnounceZero.AnnounceZeroPlugin.SitePlugin'>, <class 'Site.Site.Site'>])
[14:24:15] PluginManager New class accepts plugins: User (Loaded plugins: [<class 'Newsfeed.NewsfeedPlugin.UserPlugin'>, <class 'CryptMessage.CryptMessagePlugin.UserPlugin'>, <class 'User.User.User'>])
[14:24:15] PluginManager New class accepts plugins: UiWebsocket (Loaded plugins: [<class 'Sidebar.SidebarPlugin.UiWebsocketPlugin'>, <class 'Newsfeed.NewsfeedPlugin.UiWebsocketPlugin'>, <class 'Mute.MutePlugin.UiWebsocketPlugin'>, <class 'MergerSite.MergerSitePlugin.UiWebsocketPlugin'>, <class 'OptionalManager.UiWebsocketPlugin.UiWebsocketPlugin'>, <class 'CryptMessage.CryptMessagePlugin.UiWebsocketPlugin'>, <class 'Cors.CorsPlugin.UiWebsocketPlugin'>, <class 'Ui.UiWebsocket.UiWebsocket'>])
[14:24:15] PluginManager New class accepts plugins: UiRequest (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.UiRequestPlugin'>, <class 'TranslateSite.TranslateSitePlugin.UiRequestPlugin'>, <class 'Stats.StatsPlugin.UiRequestPlugin'>, <class 'Sidebar.SidebarPlugin.UiRequestPlugin'>, <class 'Mute.MutePlugin.UiRequestPlugin'>, <class 'MergerSite.MergerSitePlugin.UiRequestPlugin'>, <class 'OptionalManager.OptionalManagerPlugin.UiRequestPlugin'>, <class 'FilePack.FilePackPlugin.UiRequestPlugin'>, <class 'Cors.CorsPlugin.UiRequestPlugin'>, <class 'Ui.UiRequest.UiRequest'>])
[14:24:15] - Creating FileServer....
[14:24:15] TorManager Connecting to Tor Controller 127.0.0.1:9051
[14:24:15] TorManager > PROTOCOLINFO
[14:24:15] TorManager 250-PROTOCOLINFO 1
250-AUTH METHODS=NULL,HASHEDPASSWORD
250-VERSION Tor="0.2.9.11"
250 OK

[14:24:15] TorManager < 250-PROTOCOLINFO 1
250-AUTH METHODS=NULL,HASHEDPASSWORD
250-VERSION Tor="0.2.9.11"
250 OK
[14:24:15] TorManager > AUTHENTICATE
[14:24:15] TorManager 250 OK

[14:24:15] TorManager < 250 OK
[14:24:15] TorManager > GETINFO version
[14:24:15] TorManager 250-version=0.2.9.11 (git-572f4570e1771890)
250 OK

[14:24:15] TorManager < 250-version=0.2.9.11 (git-572f4570e1771890)
250 OK
[14:24:15] TorManager Tor proxy port 127.0.0.1:9050 check ok
[14:24:15] - Creating UiServer....
[14:24:15] SiteManager Sites not loaded yet...
[14:24:15] SiteManager Loading sites...
[14:24:15] Site:1Name2..hM9F ContentDb init: 0.000s, found files: 1, sites: 1
[14:24:15] SiteManager Loaded site 1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F in 0.001s
[14:24:15] SiteManager SiteManager added 1 sites
[14:24:15] SiteManager Updated merger sites in 0.000s
[14:24:15] - Removing old SSL certs...
[14:24:15] - Starting servers....
[14:24:15] Ui.UiServer No module named werkzeug.debug: For debugging please download Werkzeug (http://werkzeug.pocoo.org/)
[14:24:15] Ui.UiServer --------------------------------------
[14:24:15] Ui.UiServer Web interface: http://127.0.0.1:43110/
[14:24:15] Ui.UiServer --------------------------------------
[14:24:15] - Current RLIMIT_NOFILE: 1024 (max: 4096), changing to 2048...
[14:24:16] - Generating RSA cert and key PEM files...Generating a 2048 bit RSA private key
.......................................................................................................................................................+++
....+++
unable to write 'random state'
writing new private key to 'data/key-rsa.pem'
-----
[14:24:16] FileServer Binding to: *:15441, (msgpack: 0.4.8), supported crypt: ['tls-rsa']
[14:24:16] FileServer Checking sites...
[14:24:16] FileServer Conn# 1 boot3rdez4rzn36x.onion [?] > Connecting...
[14:24:16] TorManager Creating new Tor socket to boot3rdez4rzn36x.onion:15441
[14:24:16] FileServer Conn# 2 boot.zeronet.io [?] > Connecting...
[14:24:16] Site:1Name2..hM9F 303 peers (0 with hashfield) loaded in 0.005s
[14:24:16] Db:ContentDb Loaded 0 optional files: 0.00MB, downloaded: 0.00MB in 0.000s
[14:24:17] FileServer Checking port 15441 using P2P...
[14:24:17] FileServer Checking port 15441 using portchecker.co...
[14:24:26] Site:1Name2..hM9F Announced types [] in mode startup to 0 trackers in 10.003s, errors: ['udp://tracker.coppersurfer.tk:6969', 'udp://tracker.leechers-paradise.org:6969', 'udp://9.rarbg.com:2710'], slow: ['10s+ zero://boot3rdez4rzn36x.onion:15441', '10s+ zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441', '10s+ http://tracker.opentrackr.org:1337/announce', '10s+ http://explodie.org:6969/announce', '10s+ http://tracker1.wasabii.com.tw:6969/announce']
[14:24:26] Site:1Name2..hM9F content.json loadContent same json file, skipping
[14:24:26] FileServer Conn# 3 210.219.231.5 [?] > Connecting...
[14:24:26] FileServer Conn# 4 193.77.149.84 [?] > Connecting...
[14:24:26] FileServer Conn# 5 51.39.85.183 [?] > Connecting...
[14:24:26] FileServer Conn# 1 boot3rdez4rzn36x.onion [?] > Closing connection: boot3rdez4rzn36x.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 142 > Connection.py line 100 > TorManager.py line 312 > socks.py line 681 > socks.py line 383 > socks.py line 458, waiting_requests: 0, sites: 0, buff: 0...
[14:24:26] Site:1Name2..hM9F Announce to boot3rdez4rzn36x.onion:15441 failed: None
[14:24:29] Site:1Name2..hM9F Small number of peers detected...query all of peers using pex
[14:24:29] FileServer Conn# 6 82.119.233.36 [?] > Connecting...
[14:24:34] Site:1Name2..hM9F Found 16 ip4, 4 onion peers, new: 17
[14:24:34] FileServer Conn# 2 boot.zeronet.io [v2] > Closing connection: Removing, waiting_requests: 0, sites: 1, buff: 0...
[14:24:38] Site:1Name2..hM9F Found 30 peers, new: 7, total: 327
[14:24:39] FileServer Conn# 4 193.77.149.84 [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 13.400s)...
[14:24:40] FileServer Conn# 6 82.119.233.36 [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 11.289s)...
[14:24:42] FileServer Conn# 7 188.27.90.214 [?] > Connecting...
[14:24:42] FileServer [BAD :(] Port closed: Port 15441 is closed.
[14:24:42] FileServer Trying to open port using UpnpPunch...
[14:24:42] - Trying to open port 15441.
[14:24:43] - Found local ips: ['192.168.0.11']
[14:24:43] - Trying using local ip: 192.168.0.11
[14:24:43] FileServer Conn# 8 85.218.116.137 [?] > Connecting...
[14:24:44] FileServer Conn# 7 188.27.90.214 [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 2.594s)...
[14:24:46] Site:1Name2..hM9F Http tracker tracker1.wasabii.com.tw:6969/announce error: local variable 'response' referenced before assignment
[14:24:46] FileServer Conn# 9 2.99.187.27  [?] > Connecting...
[14:24:46] FileServer Conn#10 24.6.245.4   [?] > Connecting...
[14:24:46] Site:1Name2..hM9F Queried listModifications from: [<Peer:193.77.149.84>] in 20.003s
[14:24:46] Site:1Name2..hM9F content.json loadContent same json file, skipping
[14:24:46] Site:1Name2..hM9F Need connections: 4, Current: 8, Total: 330
[14:24:46] FileServer Conn#11 218.98.33.33 [?] > Connecting...
[14:24:48] - Upnp request using "192.168.0.11" failed: No reply from IGD using 192.168.0.11 as IP
[14:24:48] - Trying using local ip: 192.168.0.11
[14:24:50] FileServer Conn# 9 2.99.187.27  [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 4.071s)...
[14:24:53] - Upnp request using "192.168.0.11" failed: No reply from IGD using 192.168.0.11 as IP
[14:24:53] - Trying using local ip: 192.168.0.11
[14:24:58] - Upnp request using "192.168.0.11" failed: No reply from IGD using 192.168.0.11 as IP
[14:24:58] FileServer UpnpPunch run error: UpnpError: Failed to communicate with igd using port 15441 on local machine after 3 tries. in FileServer.py line 75 > UpnpPunch.py line 325 > UpnpPunch.py line 316
[14:24:58] TorManager Start onions
[14:26:42] FileServer Conn# 3 210.219.231.5 [v2] > Socket error: error: [Errno 104] Connection reset by peer in Connection.py line 145 > _socket2.py line 274
[14:26:42] FileServer Conn# 3 210.219.231.5 [v2] > Closing connection: MessageLoop ended, waiting_requests: 0, sites: 2, buff: 0...
[14:26:46] FileServer Conn#11 218.98.33.33 [v2] > Socket error: error: [Errno 104] Connection reset by peer in Connection.py line 145 > _socket2.py line 274
[14:26:46] FileServer Conn#11 218.98.33.33 [v2] > Closing connection: MessageLoop ended, waiting_requests: 0, sites: 0, buff: 0...
[14:26:47] FileServer Conn# 5 51.39.85.183 [v2] > Socket error: error: [Errno 104] Connection reset by peer in Connection.py line 145 > _socket2.py line 274
[14:26:47] FileServer Conn# 5 51.39.85.183 [v2] > Closing connection: MessageLoop ended, waiting_requests: 0, sites: 2, buff: 0...
[14:26:51] FileServer Conn# 8 85.218.116.137 [v2] > Socket error: error: [Errno 104] Connection reset by peer in Connection.py line 145 > _socket2.py line 274
[14:26:51] FileServer Conn# 8 85.218.116.137 [v2] > Closing connection: MessageLoop ended, waiting_requests: 0, sites: 1, buff: 0...
[14:26:51] FileServer Conn#12 144.48.7.45  [?] > Connecting...
[14:26:55] FileServer Conn#10 24.6.245.4   [v2] > Socket error: error: [Errno 104] Connection reset by peer in Connection.py line 145 > _socket2.py line 274
[14:26:55] FileServer Conn#10 24.6.245.4   [v2] > Closing connection: MessageLoop ended, waiting_requests: 0, sites: 1, buff: 0...
[14:27:00] FileServer Conn#12 144.48.7.45  [v2] > Crypt out connection using: tls-rsa (server side: False, ping: 9.743s)...
[14:27:02] Site:1Name2..hM9F Queried pex from 2 peers got 6 new peers.
[14:29:15] Db:ContentDb Optional size: 0.0MB/86800.9MB, Need delete: -86800.9MB
[14:29:16] FileServer Running site cleanup, connections: 5, internet: True, protected peers: set([])
[14:29:19] Site:1Name2..hM9F Queried pex from 2 peers got 4 new peers.
[14:29:22] Site:1Name2..hM9F Announced types ['onion'] in mode update to 1 trackers in 6.280s, errors: [], slow: ['6.28s http://explodie.org:6969/announce']
[14:29:22] Site:1Name2..hM9F Need connections: 4, Current: 5, Total: 337
[14:29:23] FileServer Site announce tracker done in 7.280s, sleeping for 142.719527006s...
^CShutting down...
[14:29:40] Ui.UiServer Stopping...
[14:29:40] Ui.UiServer Socket closed: 0
[14:29:40] FileServer Stopped.
[14:29:40] Ui.UiServer Stopped.
[14:29:40] SiteManager Saved sites in 0.00s (generate: 0.00s, write: 0.00s)
[14:29:40] SiteManager Updated merger sites in 0.000s
[14:29:40] Site:1Name2..hM9F Peers saved in 0.002s
``` @HelloZeroNet I see... Then it must be due to the sandboxing configuration that the Tor Browser and Chromium are subject to by default under [Oz](https://github.com/subgraph/oz) that I wasn't able to access this page. I should see how to make the necessary exceptions and then edit this post with my findings.  Err: AttributeError: 'list' object has no attribute 'next' in UiServer.py line 94 > UiRequest.py line 116 > MutePlugin.py line 138 > MultiuserPlugin.py line 62
Details:
```
{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate, br", 
    "HTTP_ACCEPT_LANGUAGE": "zh-CN,zh;q=0.8", 
    "HTTP_HOST": "fuckcf.cf", 
    "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3198.0 Safari/537.36", 
    "HTTP_X_FORWARDED_FOR": "111.3.*.*", 
    "HTTP_X_FORWARDED_PROTO": "https", 
    "HTTP_X_REAL_IP": "111.3.*.*", 
    "PATH_INFO": "/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
    "QUERY_STRING": "", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "33590", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "localhost", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.0 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bind": null, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": null, 
        "config_file": "zeronet.conf", 
        "connected_limit": 8, 
        "data_dir": "data", 
        "db_mode": "speed", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "download_optional": "manual", 
        "end": true, 
        "file_size_limit": 10, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "fix_float_decimals": false, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "ip_local": [
            "127.0.0.1"
        ], 
        "keep_ssl_cert": false, 
        "language": "zh", 
        "log_dir": "log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": false, 
        "multiuser_local": false, 
        "multiuser_no_new_sites": false, 
        "open_browser": null, 
        "optional_limit": "10", 
        "proxy": null, 
        "silent": false, 
        "size_limit": 10, 
        "stack_size": null, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_hs_limit": 10, 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.opentrackr.org:1337/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_host": [
            "fuckcf.cf"
        ], 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "updatesite": "1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp", 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false, 
        "workers": 5
    }, 
    "plugins": [
        "AnnounceZero", 
        "Cors", 
        "CryptMessage", 
        "FilePack", 
        "MergerSite", 
        "Multiuser", 
        "Mute", 
        "Newsfeed", 
        "OptionalManager", 
        "PeerDb", 
        "Sidebar", 
        "Stats", 
        "TranslateSite", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.0.2", 
    "version_python": "2.7.11 |Continuum Analytics, Inc.| (default, Dec  6 2015, 18:08:32) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]", 
    "version_zeronet": "0.5.7 r2187", 
    "wsgi.url_scheme": "http"
}
```
I removed all files in `data`, but the error occurred again. @HelloZeroNet Problem has been confirmed, I just cloned a clean repo, renamed disabled-Multiuser to Multiuser, launched zeronet and got the exact error. @HelloZeroNet I'm so sorry that I created this bug.  First, I had this in root `content.json`:
```json
...
"signers": ["1MMvgRPh9NGX2z5AGQMdoftTngCxS6DciD", "1FUXrC4M9YuJ2hu7t82cgQ1nKFumcxwDhw"]
....
```
Signing works.

---

Now I change it to:
```json
...
"signers": ["1MMvgRPh9NGX2z5AGQMdoftTngCxS6DciD", "1FUXrC4M9YuJ2hu7t82cgQ1nKFumcxwDhw", "18jNLCocEexrDZeyEiVe2yRGoAXd4KxDD7", "1CvyxRucf7BbDvGtFe5LayTS2qX88VN7Er"]
....
```

2 more signers. I am trying to sign `content.json` and get this:
`'ascii' codec can't decode byte 0xb0 in position 25: ordinal not in range(128)`

---

First I thought `18jNLCocEexrDZeyEiVe2yRGoAXd4KxDD7` or `1CvyxRucf7BbDvGtFe5LayTS2qX88VN7Er` are incorrect, but then I removed first two signers (`1MMvgRPh9NGX2z5AGQMdoftTngCxS6DciD`, `1FUXrC4M9YuJ2hu7t82cgQ1nKFumcxwDhw`) and signing worked again! **Is there a limitation for signers count, maybe in pybitcointools?** that error is talking about a different part of the file from what you posted; specifically, it mentions the 25th (from 0) character. Can you post the first few lines of the file so we can check them? 'Course I can:

    {
        "address": "1Demofj5ntgDJxagDfAqQeH3FZua4zVBFA",
    ....

Does it help? No, of course. I tried to add and remove signers, and only `0`, `1` and `2` worked. Another interesting thing (hardly ever connected, but just in case):

    ...
    "includes": {
        "data/content.json": {
            "signers": ["1MMvgRPh9NGX2z5AGQMdoftTngCxS6DciD", "1FUXrC4M9YuJ2hu7t82cgQ1nKFumcxwDhw"],
            "signers_required": 1
        },
        "data/users/content.json": {
            "signers": ["1MMvgRPh9NGX2z5AGQMdoftTngCxS6DciD", "1FUXrC4M9YuJ2hu7t82cgQ1nKFumcxwDhw"],
            "signers_required": 1
        }
    }
    ...

So, there are two more `signers` fields, in `includes`. When I add 1 more signer to *them*, signing works. When I add 1 more signer to root `signers`, signing fails. Some more news:

    [14:34:29] Site:1Demof..VBFA Signing: content.json
    [14:34:29] Site:1Demof..VBFA Opening site data directory: data/1Demofj5ntgDJxagDfAqQeH3FZua4zVBFA/...
    [14:34:29] Site:1Demof..VBFA - [SKIPPED] content.json
    [14:34:29] Site:1Demof..VBFA - dbschema.json
    [14:34:29] Site:1Demof..VBFA - index.html
    [14:34:29] Site:1Demof..VBFA - css/cover.css
    ...200 more lines...
    [14:34:30] Site:1Demof..VBFA - js/ZeroPage.js
    [14:34:30] Site:1Demof..VBFA Changed files: [u'content.json']
    [14:34:30] Site:1Demof..VBFA Adding timestamp and sha512sums to new content.json...
    [14:34:30] Site:1Demof..VBFA Verifying private key...
    [14:34:30] Site:1Demof..VBFA Correct 1Demofj5ntgDJxagDfAqQeH3FZua4zVBFA in valid signers: [u'1MMvgRPh9NGX2z5AGQMdoftTngCxS6DciD', u'1FUXrC4M9YuJ2hu7t82cgQ1nKFumcxwDhw', u'1CvyxRucf7BbDvGtFe5LayTS2qX88VN7Er', u'1Demofj5ntgDJxagDfAqQeH3FZua4zVBFA']
    [14:34:30] Site:1Demof..VBFA Site sign failed: content.json: UnicodeDecodeError: 'ascii' codec can't decode byte 0x8d in position 25: ordinal not in range(128) in UiWebsocket.py line 381 > ContentManager.py line 626 > CryptBitcoin.py line 49 > main.py line 520 > main.py line 404

---

Problem in pybitcointools? Yes. Let's first look at `ContentManager.py`::

    625     new_content["signers_sign"] = CryptBitcoin.sign(
    626         "%s:%s" % (new_content["signs_required"], ",".join(valid_signers)), privatekey
    627     )

Here, we sign `1:signer1,signer2,signer3,siteaddress`. For 2 signers, that's `1:1MMvgRPh9NGX2z5AGQMdoftTngCxS6DciD,1FUXrC4M9YuJ2hu7t82cgQ1nKFumcxwDhw,1Demofj5ntgDJxagDfAqQeH3FZua4zVBFA` - 106 bytes. Remeber this number. For 3 signers, that's `1:1MMvgRPh9NGX2z5AGQMdoftTngCxS6DciD,1FUXrC4M9YuJ2hu7t82cgQ1nKFumcxwDhw,1CvyxRucf7BbDvGtFe5LayTS2qX88VN7Er,1Demofj5ntgDJxagDfAqQeH3FZua4zVBFA` - 141 bytes. Remember this number, too.

---

CryptBitcoin uses `ecdsa_sign` of pybitcointools for signing. `ecdsa_sign` uses `electrum_sig_hash` for hash calculating:

    # WTF, Electrum?
    def electrum_sig_hash(message):
        padded = b"\x18Bitcoin Signed Message:\n" + num_to_var_int(len(message)) + from_string_to_bytes(message)
        return bin_dbl_sha256(padded)

That's the last place in stacktrace. But let's look at `num_to_var_int`:

    def num_to_var_int(x):
        x = int(x)
        if x < 253: return from_int_to_byte(x)
        elif x < 65536: return from_int_to_byte(253)+encode(x, 256, 2)[::-1]
        elif x < 4294967296: return from_int_to_byte(254) + encode(x, 256, 4)[::-1]
        else: return from_int_to_byte(255) + encode(x, 256, 8)[::-1]

`from_int_to_byte(x)` is used here, and the error says about *128*. *106 < 128*, and signing *196* bytes works. *141 > 128*, and it doesn't work. Maybe the problem is here? `from_int_to_byte(141)` returns `0x8d`. And the error message says about `0x8d`, BTW.

Wait a bit. I found this:

    def test_error_from_string(self):
        # See http://bugs.python.org/issue6289
        input = u"# coding: ascii\n\N{SNOWMAN}".encode('utf-8')
        with self.assertRaises(SyntaxError) as c:
            compile(input, "<string>", "exec")
        expected = "'ascii' codec can't decode byte 0xe2 in position 16: " \
                   "ordinal not in range(128)"
        self.assertTrue(c.exception.args[0].startswith(expected))

...in Python 2.7 libraries. Look at http://bugs.python.org/issue6289. Ascii codec refuses to decode bytes >= 128. /cc @shortcutme 

    ContentManager.py
    625     new_content["signers_sign"] = CryptBitcoin.sign(
    626         "%s:%s" % (new_content["signs_required"], ",".join(valid_signers)), privatekey
    627     )

These lines throw exception in runtime, but they work if I run them with a simple `import` - `print` script. I just made a new site and there is still an issue. Here is sample `content.json`:

    {
     "address": "197GZbac8xsfb7tzyM1Nehsp7U7SW1xXyX",
     "address_index": 38134640,
     "background-color": "#FFF",
     "clone_root": "template-new",
     "cloned_from": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D",
     "description": "",
     "files": {
      "index.html": {
       "sha512": "b47188737048fb958728dd1eb429f4f786e061db1e1f6529b4db58b60150f261",
       "size": 1112
      },
      "js/ZeroFrame.js": {
       "sha512": "8bc18006f7bb457cca2338239ea345bc1db54a664b4bc9b8a34f4e4133d1776b",
       "size": 3816
      }
     },
     "ignore": "",
     "inner_path": "content.json",
     "modified": 1504200781,
     "postmessage_nonce_security": true,
     "signers": ["197GZbac8xsfb7tzyM1Nehsp7U7SW1xXyX", "197GZbac8xsfb7tzyM1Nehsp7U7SW1xXyY", "197GZbac8xsfb7tzyM1Nehsp7U7SW1xXyZ", "197GZbac8xsfb7tzyM1Nehsp7U7SW1xXyAFDS"],
     "signers_sign": "G1E/p9KgKUSvMqVYlXc+ZcmjWhLUxAUAuwMJOJBvvEipGHYWo3qI/qXccgUQpREoqW21+l+fnkjyucXm9uNNHfA=",
     "signs": {
      "197GZbac8xsfb7tzyM1Nehsp7U7SW1xXyX": "HLphMqK6iYu9a3LRUQgqDiOnM8Q7z/5yv+SCwJxoefzCaOL/0pyGsMpq8tmupdLrKGBVPO4ta3qDMRm5eWUsaMM="
     },
     "signs_required": 1,
     "title": "my new site",
     "translate": ["js/all.js"],
     "zeronet_version": "0.5.7"
    }

As I said before, nothing interesting except 4 signers.  Every time I try to go onto a new site, I simply get this big wall of error message.

```
Server error
Err: DatabaseError: database disk image is malformed in UiServer.py line 94 > UiRequest.py line 116 > MutePlugin.py line 153 > UiRequest.py line 279 > SiteManagerPlugin.py line 64 > SiteManager.py line 143 > Site.py line 57 > ContentManager.py line 32 > ContentDbDict.py line 15 > ContentDb.py line 106 > Db.py line 82 > DbCursor.py line 49
Please report it if you think this an error.
Details:

{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate", 
    "HTTP_ACCEPT_LANGUAGE": "en-US,en;q=0.5", 
    "HTTP_CONNECTION": "keep-alive", 
    "HTTP_DNT": "1", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Windows NT 6.2; WOW64; rv:55.0) Gecko/20100101 Firefox/55.0", 
    "PATH_INFO": "/0chan.bit", 
    "QUERY_STRING": "/pol/", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "60743", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "Denneisk", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.2 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bind": null, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": "type %s | tools\\coffee\\coffee.cmd", 
        "config_file": "C:/Users/marky_000/Documents/ZeroNet-win-dist/zeronet.conf", 
        "connected_limit": 8, 
        "data_dir": "C:/Users/marky_000/Documents/ZeroNet-win-dist/data", 
        "db_mode": "speed", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "download_optional": "manual", 
        "end": true, 
        "file_size_limit": 10, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "fix_float_decimals": false, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "ip_local": [
            "127.0.0.1"
        ], 
        "keep_ssl_cert": false, 
        "language": "en", 
        "log_dir": "C:/Users/marky_000/Documents/ZeroNet-win-dist/log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": false, 
        "open_browser": "", 
        "optional_limit": "10%", 
        "proxy": null, 
        "silent": false, 
        "size_limit": 10, 
        "stack_size": null, 
        "stream_downloads": false, 
        "tor": "always", 
        "tor_controller": "127.0.0.1:9151", 
        "tor_hs_limit": 10, 
        "tor_proxy": "127.0.0.1:9150", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.opentrackr.org:1337/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_host": null, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "updatesite": "1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp", 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false, 
        "workers": 5
    }, 
    "plugins": [
        "AnnounceZero", 
        "Cors", 
        "CryptMessage", 
        "FilePack", 
        "MergerSite", 
        "Mute", 
        "Newsfeed", 
        "OptionalManager", 
        "PeerDb", 
        "Sidebar", 
        "Stats", 
        "TranslateSite", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.2.1", 
    "version_python": "2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 20:42:59) [MSC v.1500 32 bit (Intel)]", 
    "version_zeronet": "0.5.7 r2187", 
    "wsgi.url_scheme": "http"
}
```  https://github.com/HelloZeroNet/ZeroNet/issues/688
If the user doesn't have language setting in his cookies then value from the zeronet.conf will be used. @HelloZeroNet So the translation must be comletely moved to the frontend -- rewritten in javascript. Do you think it will be the clearest solution too? @HelloZeroNet What if the websocket will send messages in English and then we translate it via simple substitution in JS that will not touch parametrized output at all. Something like this:
```
(this is javascript code below)
>> str = "Change it to {auth_type}/{auth_user_name}@{domain}"
>> str = str.replace("Change it to", "VÃ¡ltoztatÃ¡s")
>> print(str)
"VÃ¡ltoztatÃ¡s {auth_type}/{auth_user_name}@{domain}"

>> str = "Content publish queued for {0:.0f} seconds."
>> str = str.replace("Content publish queued for", "Tartalom publikÃ¡lÃ¡sa elhalasztva")
>> str = str.replace("seconds", "mÃ¡sodperccel")
>> print(str)
"Tartalom publikÃ¡lÃ¡sa elhalasztva {0:.0f} mÃ¡sodperccel."
```

What do you think?  How to reproduce:
1. start with ```--tor disable```
2. stop gracefully with SIGINT
3. observe that the router still has UPnP port forwarded:
> ZeroNet | Yes | 15441 | 15441 | 192.168.1.10 | TCP

It should delete UPnP forwards when stopped gracefully.

As a good example, BitMessage handles UPnP very well: https://github.com/Bitmessage/PyBitmessage
I believe they have their own UPnP python implementation. I tried again, it leaves UPnP forward with clean shutdown.  I have UPnP enabled on my router and on my pc firewall I have opened port 15441 both tcp and udp.
But when I start zeronet with `sudo systemctl start zeronet` and I then do a `sudo systemctl status zeronet` I get this message:

> ago 25 00:04:26 pc-grande env[6104]: [00:04:26] FileServer Checking port 15441 using portchecker.co...
ago 25 00:04:28 pc-grande env[6104]: [00:04:28] FileServer [BAD :(] Port closed: Port 15441 is closed.
ago 25 00:04:28 pc-grande env[6104]: [00:04:28] FileServer Trying to open port using UpnpPunch...

When I open ZeroHello I get "PORT: closed".
I believe this is a bug on the zeronet daemon After sometime the zeronet daemon spits out this message from `sudo systemctl status zeronet`
> ago 25 00:04:44 pc-grande env[6104]: [00:04:44] FileServer UpnpPunch run error: UpnpError: Failed to communicate with igd using port 15441 on local machine after 3 tries. in FileServer.py line 74 > UpnpPunch.py line 325 > UpnpPunch.py line 316

I believe this is relevant my firewall has port 15441 open, so in there isn't the issue It says that port is closed. Or my router isn't doing UPnP correctly or it may be blocked by ISP. Am I right? It is my router. I forwarded the port to my pc and this way everything is being detected as open.
Or my router isn't doing UPnP correctly (which I doubt since I haven't got any issues with other programs) or the UpnpPunch isn't punching the port on my case.
Can you help me resolve this issue? Where can I download Upnppunch to test if it works on my computer? I have got the same issue on other programs, but I didn't noticed because no one had a port: OPEN\CLOSE flag. +1 for you.
So the problem seems to be with my router that has UPnP enable but doesn't seem open ports on demand  I am curious about [this comment](https://github.com/HelloZeroNet/ZeroNet/blob/1db2327b3dc633be6ba05b00080c01d4cdc639b2/src/Ui/UiRequest.py#L286). I replaced [this line](https://github.com/HelloZeroNet/ZeroNet/blob/1db2327b3dc633be6ba05b00080c01d4cdc639b2/src/Ui/UiRequest.py#L116) with:
```
from datetime import datetime
startTime = datetime.now()
body = self.actionWrapper(path)
endTime = datetime.now()
print endTime - startTime
```
and can not see any significant difference between
```
return iter([self.renderWrapper(site, path, inner_path, title, extra_headers)])
```
and
```
return self.renderWrapper(site, path, inner_path, title, extra_headers)
```
Am I doing something wrong? @HelloZeroNet I think the answer has been given [here](http://agiliq.com/blog/2013/07/basics-wsgi/), I'll cite it:
>The last line of application should not be return response_body. Instead, it should be return [response_body]. Reason being:
>- WSGI server expects the return from application to be an iterable and sends each element of this iterable to the client in an unbufferred fashion.
>- If we keep return response_body, response_body is a string and hence an iterable and so our code still works. But every character of the response_body will be sent one by one.
>- If we keep return [response_body], the iterable is a list here, containing only one element which is the string response_body. So, in this case entire response_body will be sent at once.
>- That's why we should replace return response_body with return [response_body].
 @HelloZeroNet Please, merge.  https://github.com/HelloZeroNet/ZeroNet/issues/430  As the title says, I'd like you to add that, since it's kind of annoying to edit the files from the code. @HelloZeroNet Could make a kind of hook that detects when an "insert into" query is done and saved in the .json automatically...  As a BitTorrent-like application, disk usage are heavier than normal application.
I don't find the file cache behavior in code or UI.  I'm running a proxy server and when I try to connect to my server through domain this error is out 

nginx conf (part of)





map $http_upgrade $connection_upgrade {
        default upgrade;
        ''      close;
}

upstream zeronet_backend {
    server (my ip, not localhost):43110;
}

server {
	listen 80;
	listen [::]:80;
	server_name (my domain);
	return 301 https://$host$request_uri;
	}

server {
	listen 443;
	listen [::]:443;
	server_name (my domain);
#SSL
        ssl_certificate /etc/nginx/ssl/server.crt;
		ssl_certificate_key /etc/nginx/ssl/server.key;
		ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
		ssl_prefer_server_ciphers on;
		ssl_ecdh_curve secp384r1;
		ssl_ciphers ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:!aNULL:!eNULL:!EXPORT:!DES:!3DES:!MD5:!PSK:!RC4; # no RC4 and known insecure cipher

#LOG
	access_log /var/log/nginx/zeronet/default.log;
	error_log /var/log/nginx/zeronet/error.log;

#LOCATION

	    location / {
        proxy_set_header X-Real-IP      $remote_addr;
        proxy_set_header User-Agent     $http_user_agent;
        proxy_set_header Host           $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_pass http://zeronet_backend;
        proxy_http_version 1.1;
    }
    location /Websocket {
        proxy_pass http://zeronet_backend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
    }
#LOCATION END

	}






zeronet conf

[global]
ui_ip = 0.0.0.0
ui_port = 43110
ui_host = (my domain)






What's the problem?
 >Connection with UiServer Websocket was lost. Reconnecting...

This is all I can gather. What did you mean by 'exact error message'?
 Well, If you mean nginx error log, here.

#

2017/08/16 21:40:03 [error] 23270#23270: *2708 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:40:04 [error] 23270#23270: *2710 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:40:15 [error] 23270#23270: *2712 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:40:15 [error] 23270#23270: *2701 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:40:26 [error] 23270#23270: *2715 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:40:27 [error] 23270#23270: *2717 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:40:37 [error] 23270#23270: *2719 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:40:40 [error] 23270#23270: *2721 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:40:48 [error] 23270#23270: *2723 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:40:51 [error] 23270#23270: *2725 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:41:00 [error] 23270#23270: *2727 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:41:03 [error] 23270#23270: *2729 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:41:11 [error] 23270#23270: *2731 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:41:16 [error] 23270#23270: *2733 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:41:22 [error] 23270#23270: *2735 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:41:27 [error] 23270#23270: *2737 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:42:54 [error] 23270#23270: *2768 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:42:57 [error] 23270#23270: *2770 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:43:05 [error] 23270#23270: *2772 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:43:53 [error] 23270#23270: *2782 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:44:27 [error] 23270#23270: *2788 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:44:38 [error] 23270#23270: *2790 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:45:00 [error] 23270#23270: *2794 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:45:11 [error] 23270#23270: *2796 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:45:33 [error] 23270#23270: *2800 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:45:44 [error] 23270#23270: *2802 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:47:40 [error] 23270#23270: *2828 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:47:51 [error] 23270#23270: *2830 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:48:02 [error] 23270#23270: *2834 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
2017/08/16 21:48:24 [error] 23270#23270: *2840 connect() failed (111: Connection refused) while connecting to upstream, client: 116.126.55.154, server: (MY DOMAIN), request: "GET /Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4 HTTP/1.1", upstream: "http://(MY SERVER IP):43110/Websocket?wrapper_key=c56d60cafbb10910b78b25d8f27f20b96b1f722eac54aec24cc3aa8439cceae4", host: "(MY DOMAIN)"
# It still doesn't work

I looked up debug.log, and I can find 'invalid host: (my ip)

Is there a way to assign two ui_hosts?  oh I configured zeronet.conf but it still doesn't work
and What is 'VerifyError: sites too large' and 'Ui UiServer : No user found'?
  >Have you enabled the Multiuser plugin?

`root@imageboard:/var/ZeroNet-master/plugins# ls
AnnounceZero  disabled-Bootstrapper     disabled-StemPort        FilePack    Mute             PeerDb   TranslateSite
Cors          disabled-Dnschain         disabled-UiPassword      MergerSite  Newsfeed         Sidebar  Trayicon
CryptMessage  disabled-DonationMessage  disabled-Zeroname-local  Multiuser   OptionalManager  Stats    Zeroname`

Yes.

>Is there anything in data/users.json?

`{
  "(censored)": {
    "certs": {},
    "master_seed": "**",
    "sites": {
      "(censored)": {
        "auth_address": "(censored)",
        "auth_privatekey": "(censored)"
      }
    }
  }`

Yes.  @Hypeouseaus Just to make sure you know, you are showing your private key for ZeroName. @krixano thanks I also have this problem in ZeroNet 0.6.0 with nginx 1.4.7, with https connection.
I enabled mutiluser plugin and uipassword.  Issue: https://github.com/HelloZeroNet/ZeroNet/issues/80 > i'm not sure if socket.connect_ex does not leaks real IP address in tor mode.

@HelloZeroNet You do a [socket patch](https://github.com/HelloZeroNet/ZeroNet/blob/de550d7cae940630855a9466e88695f2b3a6a950/src/main.py#L137) in main.py if --tor always enabled, I think this will redirect all socket connections to Tor, but I will try to catch packets with Wireshark to be completely sure. Thanks for remarks! @HelloZeroNet, I did it! There are two pcap-files in [this archive](https://github.com/HelloZeroNet/ZeroNet/files/1232142/cap.zip) each of which contain packets recorded on the receiving end of the suspicious `socket.connect_ex` command.
One file contains capture for Tor only mode and another for default zeronet start without any parameters.
Just a little explanation, what I did. I opened port 4444 on my remote VPS with `nc -k -l -p 4444` command and in the other console on the VPS started dumping packets to a file with `tcpdump dst port 4444 -w out.cap` command.
On the VPS was run zeronet which requests port check, and on my PC was located zeronet which makes check with `socket.connect_ex` command.
Here the scheme:
```
    PC                                                    VPS
+---------+ 93.84.53.139  Clearnet  81.4.104.218:4444 +---------+
| zeronet |------------------------------------------>| zeronet |
| checker |                                     ^     |requestor|
+---------+                                     |     +---------+
      |                                         |       (packet
      | Tor    +-----------+ 176.126.252.12     |      capturing
      +------->| Exit node |--------------------+       is here)
               +-----------+
```
So you can open cap-files with Wireshark or recapture it yourself and make sure that there is absolutely no records about real IP (in this case 93.84.53.139) when Tor always enabled.

P. S. Object return and config.homepage I will add to the pull request later, please, wait. @HelloZeroNet, all done. Is there anything else?  I have set the ban in MultiUserPlugin:
![image](https://user-images.githubusercontent.com/15178410/29284982-679ac474-815f-11e7-8aa8-0d76868ba794.png)

This is banned:
<img width="435" alt="" src="https://user-images.githubusercontent.com/15178410/29284887-1b93a758-815f-11e7-9fa5-cd4c2dbf9c28.png">

But you can bypass it:
<img width="637" alt="" src="https://user-images.githubusercontent.com/15178410/29285011-82e644ba-815f-11e7-8e70-81be98633043.png">

Please fix it. And users also can do this:
<img width="580" alt="2017-08-15 02_23_06-windows shell experience host" src="https://user-images.githubusercontent.com/15178410/29285439-188edf8a-8161-11e7-9ce7-ce4d5d9307d1.png">

A solution: don't allow user to visit `/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/#Files` when multi user mode.  Take for example zerohello
```
  "template-new/js/ZeroFrame.js": {
   "sha512": "8bc18006f7bb457cca2338239ea345bc1db54a664b4bc9b8a34f4e4133d1776b",
   "size": 3816
  }
```
the hash only has a length of 64

while `sha512sum template-new/js/ZeroFrame.js` outputs
```
8bc18006f7bb457cca2338239ea345bc1db54a664b4bc9b8a34f4e4133d1776b90ba13b8117e24a325c18c7a36e82f2c53208b7f639508f1edf8c598d8b22b6d  template-new/js/ZeroFrame.js
``` muteå‘è‡ªæˆ‘çš„iPhone------------------ Original ------------------From: ZeroNet  <notifications@github.com>Date: Sat,Aug 12,2017 17:51To: HelloZeroNet/ZeroNet <ZeroNet@noreply.github.com>Cc: Subscribed <subscribed@noreply.github.com>Subject: Re: [HelloZeroNet/ZeroNet] Why is zeronet only using the first 64chars of the sha 512 hash? (#1074)Closed #1074.

â€”You are receiving this because you are subscribed to this thread.Reply to this email directly, view it on GitHub, or mute the thread.


  
  




{"api_version":"1.0","publisher":{"api_key":"05dde50f1d1a384dd78767c55493e4bb","name":"GitHub"},"entity":{"external_key":"github/HelloZeroNet/ZeroNet","title":"HelloZeroNet/ZeroNet","subtitle":"GitHub repository","main_image_url":"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png","avatar_image_url":"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png","action":{"name":"Open in GitHub","url":"https://github.com/HelloZeroNet/ZeroNet"}},"updates":{"snippets":[{"icon":"DESCRIPTION","message":"Closed #1074."}],"action":{"name":"View Issue","url":"https://github.com/HelloZeroNet/ZeroNet/issues/1074#event-1203567641"}}}  **You are not going to set up a public gateway. However, <b>your Web UI is open to the whole Internet.</b> Please check your configuration.**

I'm getting this error message ever since I upgraded to ZeroNet 0.5.7.

That means I can't access the default gateway 127.0.0.1:43110 (comes back with Forbidden).. I can only access it through my ZeroNet proxy.. http://www.kittyseedbox.tk:43110/

Is that a new security feature? What's wrong with my configuration, anyway? hmm.. I'm still getting:

Forbidden
Invalid host: 127.0.0.1:43110

I've renamed the multiuser folder (I had done it previously but I guess the new update renamed it to disabled-?) and I'm running Sudo python zeronet.py --ui_host 127.0.0.1 www.kittyseedbox.tk   .. as you suggested. 

None of the gateways are accessible now.. neither the localhost nor the proxy domain. :( I should add - I've tried endless combinations, but so far the only ones that seem to work are:

**--ui_ip '*'** (which now only allows me to access www.kittyseedbox.tk, but not 127.0.0.1)

and

**--ui_ip 0.0.0.0** (which allows me to access 127.0.0.1, but not www.kittyseedbox.tk)

**--ui_host** does absolutely nothing, and all gateways are forbidden no matter what you type in it.

I used to be able to access both in the previous version.. it was just handy I guess, as I could refresh and view changes I made to my local web files without having to publish them. It's strange. --ui_host 127.0.0.1:43110 works fine, but not www.kittyseedbox.tk:43110

in other words:
**--ui_host 127.0.0.1:43110 www.kittyseedbox.tk:43110**    will only allow the localhost to be viewed, but not the domain proxy.

**--ui_host www.kittyseedbox.tk:43110** will not allowed either of them to be viewed.

it seems to have a distaste for anything other than IP numbers. Think I figured it out. The only way to get it to work:
**sudo python zeronet.py --ui_host 127.0.0.1:43110 www.kittyseedbox.tk:43110 _--ui_ip '*'_**

Won't work without ui_ip @kopy-kate @HelloZeroNet So the issue has been solved? @kopy-kate you should not have to run Python as root (sudo), it's bad for security.  ### Suppose:
1. User can modify their own `data.json`
2. `data.json` contains list of messages (e.g. forum posts)
3. User can add as many posts as they want since they don't have any restrictions
4. ???
5. FLOOD or MODIFYING POSTS AFTERWARDS!11

## Possible solutions:
### Storing history of file modifications with timestamp
#### Problems:
1. Need to verify timestamp somehow
2. Need to implement history/blockchain
3. 51% attack

### ~File per post + Rate limiting + File permissions:~

1. Allow to add one file per `content.json` update
2. Rate limit modification of `content.json` (check via `modified` key)
3. One file contains one post
4. User can only create files, not modify

#### Problems:
~1. Many files~
1. We can't rely on `modified` timestamp

### ~Smarter ways to check modifications of JSON data:~

1. Ability to restrict addition of one item to `data.json` list per `data.json` update via `content.json` rules
2. Ability to restrict items modification
3. Rate limit modification of `data.json` or `content.json`

#### Problems:
1. (Possible) DoS attack via big JSON files (each node should check modification of files)
2. If all nodes is offline, you can create as many posts as you want

### ~Maybe even ~JS~ CoffeeScript/Python scripts to check files modification~
#### Problems:
1. Kinda dangerous (sandbox's required) Well I think 1000 posts/day is better than 100500 posts/`data.json` update. And the second problem is modifying message after sending

> I think this problem should be solved by the moderator of the site. Maybe with help of some automated "bot" to watch the updates and ban obviously spamming users.

Yeah, but it's centralized solution, so I'm trying to figure out some decentralized solutions

Is there some API to watch file updates? > I think most of the users would really hate it if they were unable to modify their post after they sent it.

Well in some cases it's better not to provide option to edit messages. Now we can modify data even if a site doesn't provide that option (just edit `data.json`, sign, publish)

> It could be possible to add more limitation on rate on same file updates. eg. 100/hour (configurable by site owner)

The problem is that it's possible to add lot of posts at 1 update, so it won't work at all

btw, as I understand we can't rely on `modified` value. Each node just checks that it's bigger that previous `modified` timestamp. And you mentioned about offline. So we need to have some history of file changes (at least hashes) (like blockchain, lol) There is a limit on file size, so flooding is not possible. Even if you have 1MB limit, you can still create file that contains thousands of posts. It doesn't solve flooding problem at all @python273 That's because the timestamp in the posts can not be verified. So ratelimiting is useless as one could just use an older timestamp as there is no blockchain to verify whether that piece of content really was created at that time. So a limit like 1 post per minute makes no sense. Actually timestamp can be trusted in some range https://en.bitcoin.it/wiki/Block_timestamp @python273 ZeroNet only uses BIP-32 crypto. NOT bitcoin blocks or anything else related to bitcoin. I know that. It's just an example of verifying timestamp @python273 But this implies that the blocks reference the parent (creating a chain aka blockchain). This is NOT the case for zeronet content.json's. They do not use timestamps in a way that they are verifiable. The only assumptions that zeronet guarantees for the timestamp is that it's less than 12h in the future and it's positive. (@HelloZeroNet correct me if I'm wrong) I know that too. Read comments before leaving a comment
> as I understand we can't rely on `modified` value. Each node just checks that it's bigger that previous modified timestamp. And you mentioned about offline. So we need to have some history of file changes (at least hashes) (like blockchain, lol) @python273 Sorry. Just didn't read the whole thing again. I know it's not so easy problem to solve and usually it solved with PoW (like in BitMessage). But if you want to make ZeroNet fully decentralized, it should be solved somehow IMHO I don't think that this is the only problem required for full decentralization. We are **trusting** hub owners not to change their minds and do stuff like revoking the permission that allows users to post their stuff in the hub.    ```
- Starting ZeroNet...
[08:39:37] - OpenSSL loaded, version: 01000114F
[08:39:37] - Version: 0.5.7 r2170, Python 2.7.9 (default, Sep 17 2016, 20:26:04)
[GCC 4.9.2], Gevent: 1.0.1
[08:39:37] - Creating FileServer....
[08:39:37] TorManager Connecting to Tor Controller 127.0.0.1:9051
[08:39:37] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 165 > socket.py line 342
[08:39:37] TorManager Starting self-bundled Tor, due to Tor proxy port 127.0.0.1:9050 check error: No connection
```


```
[08:37:59] FileServer UpnpPunch run error: ProxyConnectionError: Error connecting to SOCKS5 proxy 127.0.0.1:9050: [Errno 111] Connection refused in FileServer.py line 74 > UpnpPunch.py line 325 > UpnpPunch.py line 304 > UpnpPunch.py line 279 > UpnpPunch.py line 263 > UpnpPunch.py line 86 > urllib2.py line 154 > urllib2.py line 431 > urllib2.py line 449 > urllib2.py line 409 > urllib2.py line 1227 > urllib2.py line 1194 > httplib.py line 1039 > httplib.py line 1073 > httplib.py line 1035 > httplib.py line 879 > httplib.py line 841 > httplib.py line 822 > SocksProxy.py line 12 > socks.py line 674
[08:38:49] FileServer Internet offline

```

Configured *torrc* and everything else according to the FAQ... @Akito13 Please, participate. @HelloZeroNet No output to either. @Akito13 Tor is not running.
Please, do `sudo systemctl start tor` and `sudo systemctl status tor` @grez911 No output to `'PROTOCOLINFO' | nc 127.0.0.1 9051 `and `sudo netstat -anp | grep tor`. Tor **is** running:
```
â— tor.service - Anonymizing overlay network for TCP (multi-instance-master)
   Loaded: loaded (/lib/systemd/system/tor.service; enabled)
   Active: active (exited) since Tue 2017-08-22 16:17:14 CEST; 4 days ago
  Process: 477 ExecStart=/bin/true (code=exited, status=0/SUCCESS)
 Main PID: 477 (code=exited, status=0/SUCCESS)
``` I don't like `active (exited)` output from your output. In the normal state it must be `active (running)`.
`ps aux | grep tor` will tell you you if tor is really running.
Also output to the command `echo 'PROTOCOLINFO' | nc 127.0.0.1 9051` must be:
```
250-PROTOCOLINFO 1
250-AUTH METHODS=COOKIE,SAFECOOKIE COOKIEFILE="/var/lib/tor-auth/control_auth_cookie"
250-VERSION Tor="0.3.0.10"
250 OK
```
and to `sudo netstat -anp | grep tor` something like this:
```
tcp        0      0 127.0.0.1:9050          0.0.0.0:*               LISTEN      21383/tor           
tcp        0      0 127.0.0.1:9051          0.0.0.0:*               LISTEN      21383/tor           
unix  3      [ ]         STREAM     CONNECTED     1104818  21383/tor
```
Looks like something wrong with the tor in your case. @Akito13 Are you still having this problem? @imachug Zeronet works, but it doesn't run with Tor.   It sends me to Sites.ZeroNetwork.bit 
https://i.snag.gy/mFJxOu.jpg  > ![image](https://user-images.githubusercontent.com/15178410/28922510-035379a0-788d-11e7-9bb6-0178f5044617.png)

Obviously these languages are not enough.
Give a `<input>` to set any language (for example: `JP`) Have we considered setting up a transifex? its pretty good for tracking translation completion  https://travis-ci.org/HelloZeroNet/ZeroNet/builds/259342067#L655-L664 https://github.com/vbuterin/pybitcointools/issues/175  @HelloZeroNet is this the right way to resolve the undefined name errors at https://travis-ci.org/HelloZeroNet/ZeroNet/builds/259342067#L665-L673 @cclauss, what do you think about #1016?  @shortcutme Is this the right way to fix these two undefined name errors?  I have this list:
```
msgpack-python
gevent
rsa
maxminddb
pyelliptic
sqlite3
``` I see now that other packages are bundled.

Could you please move all bundled packages (that are copied into zeronet) under the directory called 'contrib'? This way it is easier to see that they don't originate in zeronet.
 > Actually msgpack and gevent are the only requirements that you need to install.

@HelloZeroNet  What about py-stem? It is required for tor and isn't bundled.
 There should be the list of optional dependencies too. On the FreeBSD, port declares that it is Tor-ready, so it needs such dependencies, and there is no list anywhere. > Could you please move all bundled packages (that are copied into zeronet) under the directory called 'contrib'? This way it is easier to see that they don't originate in zeronet.

@yurivict @HelloZeroNet All third-party libraries are in src/lib, isn't it? > if the built-in, raw socket based tor communication way does not works for you.

How can it just not work? I don't understand. > Not sure about the differences, but there was reports that it's does not works under Whonix.

This should be documented. requirements.txt should say:
py-stem is required for alternative way to access Tor through the optional plugin StemPort that only works when native access method fails.

> there was reports that it's does not works under Whonix.

* It should be understood why it doesn't work, in my opinion.
* There should be top-level configuration file that sets a variable USE_STEM_PORT_PLUGIN based on the architecture or something like that.

I am sure, socket-based communication always works on Linux/BSD.
 > It is tor-ready. The StemPort is just an alternative communication plugin if the built-in, raw socket based tor communication way does not works for you.

You should delete socket-based code in favor of the Tor-supplied py-stem module. py-stem always works, and is externally supported. If it breaks, you can always have Tor people fix it. It's easier this way, no need to maintain separate code that does the same without any benefit.

And add py-stem to the list of dependencies.
  I'm getting a "SecurityError (DOM Exception 18): The operation is insecure." while trying to check/store a login information cookie. I realize that this is because localStorage isn't accessible from a sandboxed iframe. Is there a way to get around this?  æŠ±æ­‰ï¼Œä½ ä¸èƒ½åˆ é™¤ä½ è‡ªå·±æ‹¥æœ‰çš„ç«™ç‚¹ã€‚
è¯·æ‰‹åŠ¨åˆ é™¤ç«™ç‚¹ç›®å½•ã€‚

æˆ‘çš„ç«™ç‚¹ç›®å½•åœ¨å“ªï¼Ÿ æ‰“å¼€è‡ªå·±çš„ç«™ç‚¹åŽï¼Œæ‹‰å‡ºä¾§è¾¹æ ï¼Œç‚¹â€œåˆ é™¤â€å³å¯ã€‚ æˆ‘ç‚¹äº†åˆ é™¤å°±ä¸€ç›´åœ¨è½¬ ç„¶åŽå°±æ²¡æœ‰ç„¶åŽäº† å®Œå…¨åˆ ä¸æŽ‰  ä¸ºä»€ä¹ˆåˆ é™¤æŒ‰é’®è¿™ä¹ˆéšè”½ï¼Ÿåœ¨å¤–é¢å¼„ä¸€ä¸ªå‡çš„å¿½æ‚ äºº ä½ å¯ä»¥åœ¨ä¾§è¾¹æ å…³é—­â€œè¿™æ˜¯æˆ‘çš„ç«™ç‚¹â€è¯•è¯•ã€‚
ZeroHello çš„é‚£ä¸ªåˆ é™¤æŒ‰é’®ä¹Ÿä¸æ˜¯å‡çš„å•Šï¼åªæ˜¯ä¸èƒ½åˆ é™¤è‡ªå·±çš„ç«™ç‚¹ç½¢äº†ã€‚ ä½ zeronetç›®å½•ï¼Œé‡Œé¢æœ‰ä¸ªdataç›®å½•ï¼Œåˆ é™¤è¿™ä¸ªç«™ç‚¹åœ°å€åŒåçš„æ–‡ä»¶å¤¹ã€‚
æˆ–è€…è¿›å…¥è¿™ä¸ªç«™ç‚¹ï¼Œæ‹–åŠ¨å³ä¾§æŒ‰é’®æ‰“å¼€ä¾§è¾¹æ ï¼Œå…³é—­ è¿™æ˜¯æˆ‘çš„ç«™ç‚¹ Can someone talk in english what is hapenning? @Plasmmer, @631068264 asks "Why can't delete owned site via ZeroHello?" @imachug, thanks.
@HelloZeroNet @shortcutme deleting owned site via ZeroHello is a good idea.  If anyone has doubts, here is the discussion on this topic: http://127.0.0.1:43110/Talk.ZeroNetwork.bit/?Topic:1514154652_1L4dZcDF2maSKHDy788yhxpYnBWnXadUtS, Thanks  - Unhandled exception
None
Traceback (most recent call last):
  File "gevent/hub.pyo", line 857, in switch
  File "/Users/lihaoxuan/Downloads/ZeroNet-mac-dist/ZeroNet.app/Contents/Resources/boot.py", line 137, in signalHandler
    raise ExitCommand()
__main__.ExitCommand
- Unhandled exception
None
Traceback (most recent call last):
  File "/Users/lihaoxuan/Downloads/ZeroNet-mac-dist/ZeroNet.app/Contents/Resources/__boot__.py", line 81, in <module>
    _run()
  File "/Users/lihaoxuan/Downloads/ZeroNet-mac-dist/ZeroNet.app/Contents/Resources/__boot__.py", line 66, in _run
    exec(compile(source, path, 'exec'), globals(), globals())
  File "/Users/lihaoxuan/Downloads/ZeroNet-mac-dist/ZeroNet.app/Contents/Resources/boot.py", line 179, in <module>
    gui()
  File "/Users/lihaoxuan/Downloads/ZeroNet-mac-dist/ZeroNet.app/Contents/Resources/boot.py", line 106, in gui
    time.sleep(0.1)
  File "gevent/hub.pyo", line 169, in sleep
  File "gevent/hub.pyo", line 651, in wait
  File "gevent/hub.pyo", line 899, in get
  File "gevent/hub.pyo", line 630, in switch
gevent.hub.LoopExit: ('This operation would block forever', <Hub at 0x103c1b2d0 select pending=0 ref=0>)
2017-07-25 12:01:54.928 ZeroNet[8806:247298] ZeroNet Error
2017-07-25 12:01:54.928 ZeroNet[8806:247298] ZeroNet Error @shortcutme  âžœ  MacOS ./ZeroNet siteCreate
- Starting ZeroNet...
- OpenSSL loaded, version: 0009081DF
- Version: 0.5.4 r2054, Python 2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 12:39:47)
[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)], Gevent: 1.2.1
- Generating new privatekey...
- ----------------------------------------------------------------------
- Site private key: 5J2vjCYnidUjbigbWjFZucuf64gWfjxt5Q8ShSoAH6XMuPwXpQF
-                   !!! ^ Save it now, required to modify the site ^ !!!
- Site address:     13JfSkzJG8Tms8GsbYoVX6FhRvKdHHpRFo
- ----------------------------------------------------------------------
? Have you secured your private key? (yes, no) > yes
- Creating directory structure...
- Creating content.json...
Site:13JfSk..pRFo Content.json not exist: /Users/jobs/Library/Application Support/ZeroNet/data/13JfSkzJG8Tms8GsbYoVX3FhRvKdHHpRFo/content.json
Site:13JfSk..pRFo File content.json not exist yet, loading default values...
Site:13JfSk..pRFo Opening site data directory: /Users/jobs/Library/Application Support/ZeroNet/data/13JfSkzJG8Tms8GsbYoVX3FhRvKdHHpRFo/...
Site:13JfSk..pRFo - index.html (SHA512: 47ad6e3c1cd06668156ea8409c595002bc523537eef00c5d3b2a6336557a9b5b)
Site:13JfSk..pRFo Adding timestamp and sha512sums to new content.json...
Site:13JfSk..pRFo Verifying private key...
Site:13JfSk..pRFo Correct 13JfSkzJG8Tms8GsbYoVX3FhRvKdHHpRFo in valid signers: ['13JfSkzJG8Tms8GsbYoVX3FhRvKdHHpRFo']
Site:13JfSk..pRFo Signing content.json...
Site:13JfSk..pRFo Saving to content.json...
Site:13JfSk..pRFo File content.json signed!
- Site created!
- Unhandled exception
None
Traceback (most recent call last):
  File "gevent/hub.pyo", line 857, in switch
  File "/Applications/ZeroNet.app/Contents/Resources/boot.py", line 137, in signalHandler
    raise ExitCommand()
__main__.ExitCommand
- Unhandled exception
None
Traceback (most recent call last):
  File "/Applications/ZeroNet.app/Contents/Resources/__boot__.py", line 81, in <module>
    _run()
  File "/Applications/ZeroNet.app/Contents/Resources/__boot__.py", line 66, in _run
    exec(compile(source, path, 'exec'), globals(), globals())
  File "/Applications/ZeroNet.app/Contents/Resources/boot.py", line 179, in <module>
    gui()
  File "/Applications/ZeroNet.app/Contents/Resources/boot.py", line 106, in gui
    time.sleep(0.1)
  File "gevent/hub.pyo", line 169, in sleep
  File "gevent/hub.pyo", line 651, in wait
  File "gevent/hub.pyo", line 899, in get
  File "gevent/hub.pyo", line 630, in switch
gevent.hub.LoopExit: ('This operation would block forever', <Hub at 0x1057ce230 select pending=0 ref=0>)
2017-07-25 11:17:28.081 ZeroNet[87824:11603434] ZeroNet Error
2017-07-25 11:17:28.081 ZeroNet[87824:11603434] ZeroNet Error Reference: #1047.
I think it is related.  We are exploring options for negating the effects of DDoS attacks in enterprise web applications (with large backends). Currently we are considering using ZeroNet to serve as a decentralized frontend for the site while using Blockstack (blockstack.org) to manage decentralized control and encryption of user data (backend).

The zeronet zite however, doesn't allow the cross origin connection to the Blockstack browser for  authentication or data access. Errors as follows:

> Origin http://localhost:8888 is not allowed by Access-Control-Allow-Origin.
> Failed to load resource: Origin http://localhost:8888 is not allowed by Access-Control-Allow-Origin
> Fetch API cannot load http:127.0.0.1:43110/manifest.json. Origin http://localhost:8888 is not allowed by Access-Control-Allow-Origin.

I already attempted to use the zeronet CORS plugin to allow localhost:8888 which didn't work. Is there a special case for non-zeronet sites? or is there no way to use API external to zeronet? You need to enable cors on blockstack. ZeroNet only enables cors for zeronet zites Cors is enabled on blockstack. It is the zeronet side that is blocking the request. <img width="1395" alt="screen shot 2017-07-25 at 2 42 34 pm" src="https://user-images.githubusercontent.com/17167947/28588317-2fbf740e-7148-11e7-8dc1-28aa2e170ac8.png">
<img width="591" alt="screen shot 2017-07-25 at 2 43 32 pm" src="https://user-images.githubusercontent.com/17167947/28588324-32a2dfa8-7148-11e7-97eb-a1025acf220e.png">

The site supposedly has permissions for localhost:8888 where the Blockstack browser is but I still get cross origin errors.

Also can you point me to an explanation of how to use fileGet instead? @HelloZeroNet It's about reading one zite from another host. (example localhost:8080 -> localhost:43110/1Hello/) @HelloZeroNet 
> Origin http://localhost:8888 is not allowed by Access-Control-Allow-Origin.
Failed to load resource: Origin http://localhost:8888 is not allowed by Access-Control-Allow-Origin
Fetch API cannot load http:127.0.0.1:43110/manifest.json. Origin http://localhost:8888 is not allowed by Access-Control-Allow-Origin.

I don't want to start a fight but those messages clearly indicate that ZeroNet is the one being accessed by/from the Blockstack host which does not work because ZeroNet does not set the right cors headers for requests from other software/hosts @cusmith1 Please, participate. Apologies, I got sidetracked by another project and lost track of this.

The blockstack system is set up to use the Fetch API so that was part of the issue. ZeroNet was blocking that despite the CORS setup of the requests as it is necessary to use the FileGet method @HelloZeroNet described above. I was able to set it up with FileGet on the client side which removed most of the errors, but the base blockstack browser still requires Fetch in some spots resulting in a failed URI request on blockstacks side.

We're now looking at altering the base blockstack code to make it function with zeronet's API but that's for us to figure out with their side. Thank you all for giving your thoughts.  When I try to add a books database (merger db) to the site antilibrary.bit on a fresh 0.5.7 zeronet install I get the error `ERROR Db:Antilibrary Potentially unsafe part of the pattern: ]+` on the console and no json files from the merger site are loaded into the database.
This is happening if you try to add any book database to the site (go to My Books, Settings).

The problem is, the error is not descriptive of where the issue is. I've searched the content.json and dbschema.json for the pattern `]+` but found nothing.

The error should at least point to the file that contains the unsafe pattern.

I'm still unable to fix the issue because I don't know where the problem is. @HelloZeroNet sorry to trouble you with this one but, can you give me any ideas? [Some new users are having a hard time because of this](https://www.reddit.com/r/antilibrary/comments/6pe56q/no_books_found/) and I have no idea what file can be holding the wrong pattern :(
Thanks That's great. Thanks! @HelloZeroNet @antilibrary Close maybe?  The Highcharts/Highstock JavaScript on http://127.0.0.1:43110/eris.bit isn't loading with version 0.5.7 on Windows. It's working fine with earlier versions, including 0.5.6.

On further testing it seems there is a problem with downloading the content.json? It still works with this proxy: https://zeronet.maxweiss.io/eris.bit/ This rather seems to be a CORS-related issue, as I'm getting this error: `XMLHttpRequest cannot load http://127.0.0.1:43110/eris.bit/data/usa.json. Response to preflight request doesn't pass access control check: No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'null' is therefore not allowed access.`  [19:33:13] - Version: 0.5.6 r2109, Python 2.7.11 |Continuum Analytics, Inc.| (default, Dec  6 2015, 18:08:32) 

This is problematic since zeronet cannot start:

[19:29:07] SiteManager Deleting orphan site from content.db: ***********
[19:29:07] - Unhandled exception: FOREIGN KEY constraint failed
Traceback (most recent call last):
  File "/var/tmp/work/zeronet/ZeroBundle/ZeroNet/zeronet.py", line 18, in main
    main.start()
  File "/var/tmp/work/zeronet/ZeroBundle/ZeroNet/src/main.py", line 476, in start
    actions.call(config.action, action_kwargs)
  File "/var/tmp/work/zeronet/ZeroBundle/ZeroNet/src/main.py", line 151, in call
    func(**kwargs)
  File "/var/tmp/work/zeronet/ZeroBundle/ZeroNet/src/main.py", line 161, in main
    ui_server = UiServer()
  File "/var/tmp/work/zeronet/ZeroBundle/ZeroNet/src/Ui/UiServer.py", line 73, in __init__
    self.sites = SiteManager.site_manager.list()
  File "/var/tmp/work/zeronet/ZeroBundle/ZeroNet/src/Site/SiteManager.py", line 155, in list
    self.load()
  File "plugins/Zeroname/SiteManagerPlugin.py", line 20, in load
    super(SiteManagerPlugin, self).load(*args, **kwargs)
  File "plugins/MergerSite/MergerSitePlugin.py", line 338, in load
    super(SiteManagerPlugin, self).load(*args, **kwags)
  File "/var/tmp/work/zeronet/ZeroBundle/ZeroNet/src/Site/SiteManager.py", line 63, in load
    content_db.execute("DELETE FROM site WHERE ?", {"address": address})
  File "/var/tmp/work/zeronet/ZeroBundle/ZeroNet/src/Db/Db.py", line 80, in execute
    return self.cur.execute(query, params)
  File "/var/tmp/work/zeronet/ZeroBundle/ZeroNet/src/Db/DbCursor.py", line 49, in execute
    res = self.cursor.execute(query, params)
IntegrityError: FOREIGN KEY constraint failed

I will probably figure out which sqlite it wanted to delete from _[ZeroNet/data/content.db]_,  but not obvious from the message either, as well as the solution (I have deleted the records manually, no foreign constraints complained). I'm getting the same error when trying to post to my ZeroMe:

```
[21:14:21] Site:1MeFqF..q7nH Signing: data/users/1KN1Au7SRmeTmffcxxoyPABDpvqmq7i
MbN/data.json
[21:14:21] Site:1RedkC..uFdL data/users/1KN1Au7SRmeTmffcxxoyPABDpvqmq7iMbN/conte
nt.json parse error: IntegrityError: foreign key constraint failed in ContentMan
ager.py line 222 > ContentDbDict.py line 61 > ContentDbPlugin.py line 203 > Cont
entDb.py line 97 > Db.py line 87 > DbCursor.py line 80 > DbCursor.py line 49
[21:14:21] Site:1RedkC..uFdL Opening site data directory: data/1RedkCkVaXuVXrqCM
poXQS29bwaqsuFdL/data/users/1KN1Au7SRmeTmffcxxoyPABDpvqmq7iMbN/...
``` Isn't good people needing to do it.
Please, can you fix it? @HelloZeroNet the message may be misleading since, as I mentioned, I have manually just did the exact same delete which succeeded. As a wild guess is it possible that something is locking a table or tuple which would be required to be written by the cascade delete? (or circular reference like mentioned in https://stackoverflow.com/questions/15443913/sqlite3-foreign-key-constraint-failed )  I have created zeroid and enabled Multiuser plugin, but when I login with the saved unique private key, I am still cannot use zeroid (the same as login with new private key.

There is a `master_seed`  field in users.json but not the same as the saved unique private key, and doesn't work also. You should access your ID provider site after login at ZeroHello. @l5h5t7  Do you mean I should open zeroid.bit site?  I tried, but with no effect. When I click the "Login as" button, there is a `zeroid.bit Register>>` on the popup. @tantalate @HelloZeroNet Can the issue be closed?  Howdy,
If you add the following to zeronet.conf
ui_restrict = 192.168.1.1 192.168.1.2
the directive will not work.  --debug shows this is translated to ui_restrict=['192.168.1.1 192.168.1.2'].  Note that it is an entire string vs two elements of an array.  Interestingly, in TestConfig.py the command-line arguments work just fine.
Joey That worked. Thanks.  The published docs only cover the command line options, not zeronet.conf unfortunately. This would be a good addition.   on this site:
http://127.0.0.1:43110/1NYDdJ2JqMHsuD1Seau87BfGKbwEPEft8r/

when trying to rebuild from sidebar -
Internal error: AttributeError: 'list' object has no attribute 'keys'

when trying to rebuild from console -
 Unhandled exception: 'list' object has no attribute 'keys'
Traceback (most recent call last):
  File "zeronet.py", line 19, in main
    main.start()
  File "/vagrant/src/main.py", line 492, in start
    actions.call(config.action, action_kwargs)
  File "/vagrant/src/main.py", line 155, in call
    func(**kwargs)
  File "/vagrant/src/main.py", line 280, in dbRebuild
    site.storage.rebuildDb()
  File "/vagrant/src/Site/SiteStorage.py", line 124, in rebuildDb
    db_files = list(self.getDbFiles())
  File "plugins/MergerSite/MergerSitePlugin.py", line 238, in getDbFiles
    for file_relative_path in content.get("files", {}).keys() + content.get("files_optional", {}).keys():
AttributeError: 'list' object has no attribute 'keys'

and this error shows up on the debug.log -
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/gevent/greenlet.py", line 327, in run
    result = self._run(*self.args, **self.kwargs)
  File "/vagrant/src/Worker/Worker.py", line 70, in downloader
    site.storage.write(task["inner_path"], buff)
  File "/vagrant/src/Site/SiteStorage.py", line 191, in write
    self.onUpdated(inner_path)
  File "plugins/MergerSite/MergerSitePlugin.py", line 251, in onUpdated
    super(SiteStoragePlugin, self).onUpdated(inner_path, file)
  File "/vagrant/src/Site/SiteStorage.py", line 241, in onUpdated
    self.openDb()
  File "/vagrant/src/Site/SiteStorage.py", line 47, in openDb
    self.rebuildDb()
  File "/vagrant/src/Site/SiteStorage.py", line 117, in rebuildDb
    self.db.checkTables()
  File "/vagrant/src/Db/Db.py", line 212, in checkTables
    table_settings["indexes"], version=table_settings["schema_changed"]
  File "/vagrant/src/Db/DbCursor.py", line 109, in needTable
    self.createIndexes(table, indexes)
  File "/vagrant/src/Db/DbCursor.py", line 99, in createIndexes
    self.execute(index)
  File "/vagrant/src/Db/DbCursor.py", line 53, in execute
    res = self.cursor.execute(query)
sqlite3.OperationalError: table user has no column named user_date_created

its mentions "table user has no column named user_date_created" but there is not table named user, its named USERS and there is no mention of a column "user date created" anywhere i looked, so i dont understand why it gives me this error.

this is after updating zeronet  I know its possible with merger sites, but is it possible to get a list of all the sites that the user is currently seeding?
 Only "admin" sites (usually the homepage of the client) can do this  A feature request, as the title say.  on this site:
http://127.0.0.1:43110/1GnTA9B5JDSsAEk63LyDCQkbmoiFDSVxad
im getting this error on reload db console command : 

Site:1GnTA9..Vxad Importing data...
Unhandled exception: 'list' object has no attribute 'keys'
Traceback (most recent call last):
  File "zeronet.py", line 19, in main
    main.start()
  File "/vagrant/src/main.py", line 492, in start
    actions.call(config.action, action_kwargs)
  File "/vagrant/src/main.py", line 155, in call
    func(**kwargs)
  File "/vagrant/src/main.py", line 280, in dbRebuild
    site.storage.rebuildDb()
  File "/vagrant/src/Site/SiteStorage.py", line 124, in rebuildDb
    db_files = list(self.getDbFiles())
  File "plugins/MergerSite/MergerSitePlugin.py", line 214, in getDbFiles
    for item in super(SiteStoragePlugin, self).getDbFiles():
  File "/vagrant/src/Site/SiteStorage.py", line 87, in getDbFiles
    for file_relative_path in content.get("files", {}).keys() + content.get("files_optional", {}).keys():
AttributeError: 'list' object has no attribute 'keys'  i also have this problem now..  getting this error while trying to rebuild DB

this site (never mind the frontend) http://127.0.0.1:43110/1GnTA9B5JDSsAEk63LyDCQkbmoiFDSVxad/

this is the error on console:
Site:1GnTA9..Vxad Error importing data/users/1C1gnFcVv9J9kUjF4odDMRYcEWVPJbbqFp/data.json: UnboundLocalError: local variable 'row' referenced before assignment in SiteStorage.py line 130 > MutePlugin.py line 126 > SiteStorage.py line 75 > Db.py line 268 > DbCursor.py line 147

this is the data.json mentioned in the error:
{
	"users": [
		{
			"user_id": "1C1gnFcVv9J9kUjF4odDMRYcEWVPJbbqFp",
			"user_name": "davidnelband@zeroid.bit",
			"user_date_added": 1500382501284
		}
	]
}

why does this happen? how to fix this?  List of changes:
- Using Alpine instead of Ubuntu (the image's size is now *77 MB* instead of *421 MB*)
- Remove `MAINTAINER` because it's deprecated
- Using `COPY` instead of `ADD` because it's deprecated
- `WORKDIR` instead of `cd directory` following best practices    Following this issue https://github.com/HelloZeroNet/ZeroNet/issues/1014 .

ZeroNet is about the users and their control, so it could be interesting like for the merger feature to be able to ask the user to allow cross-origin requests (and fileGet access) for a specific external zite (a permission).

I think this could be a good compromise instead of disabling completely the cross-origin requests, even if this will not allow too many CORS to be done. >Add a command set similar to merger site command, but only for read access and instead of get access to site types you requesting access to specific address.

This works. Just have a command to add a permission to read files from a particular site. So the flow would be something like: request permission to read site 1whatever -> remotefileget 1whatever inner_dir and read whatever file you need. Then repeat for other sites if you need to access them. The user would be notified of the cross-site access, and they could allow or deny particular requests.

>Add an option to site's content.json that allow cross-site file access.

I don't like this one. Having the site itself determine whether the files can be accessed does nothing to prevent malicious usage. For example, if many sites enable it (for whatever reason), then a malicious site could just fetch from all of them with no need for permissions. Defeating the entire point.

Unless you meant the other way: the requesting site puts it in it's content.json. That'd work, but malicious sites could then just include it and continue on their way, and users would still be vulnerable.

Just a permission to access X site, and then a command to be able to fetch *raw* (not formatted) files. I can see the need to fetch things like images, music, json/txt files, .db files, etc. Forcing a format limits functionality.  I agree that allowing all cross-site access with a single option is not the way, but instead you could have a list of accepted origins able to request the content. This is far less flexible than a permission asked directly to the user, where no sites would require any static configuration and could just ask for things as soon as they need it. The permission request is also interesting because it will confirm that the user agree to download the requested site, making things easier to understand. >I agree that allowing all cross-site access with a single option is not the way, but instead you could have a list of accepted origins able to request the content. 

Eh, I feel that's worse. It solves the problem of malicious sites, but then once again restricts things and removes user control. And given how few people would actually whitelist sites, it'd basically be what we have now. I like the permissions idea. It's literally already implemented. Just quickly write a command that takes such a permission. IMO, when in doubt, give control to the users. Yeah, it's not really a solution. But why not doing something hybrid, like, you have the permission system to request access to a site (download, full cross-origin requests, remote fileGet) and a set of white-list rules (paths) in the configuration of the target site. So if the site owner doesn't allow any path, no cross-origin is possible. If the user doesn't allow it in the first place too, no cross-origin possible. So users can browse without too much headache, if they don't fully trust a site they can still allow the cross-origin requests if they trust the requested site. I don't know if this could even allow iframe to embed contents, following a "/embed" subdirectory rule. So basically:

* Nothing whitelisted + no perms given = no access

* Nothing whitelisted + perms given = access

* Something whitelisted + no perms given = access

Like that? I'm not sure I can imagine a case where whitelisting is needed or preferable, if the requesting site can just ask for permission. But I think it'd be welcome nonetheless. The more options the better. Not it's a "and" not a "or", the site owner should allow some path and the user should allow access/download the site. But of course the most important feature is on the user side. Needing things whitelisted returns to the problem of uncooperative or dead websites. Unless the user has the option to override that? Thanks, will test this as soon as I can. ```
page.cmd("corsPermission", "138R53t3ZW7KDfSfxVpWUsMXgwUnsDNXLP")
var db = null
var xhr = new XMLHttpRequest();
  xhr.open('GET', '/kaffiene.bit/cors-138R53t3ZW7KDfSfxVpWUsMXgwUnsDNXLP/data/ZeroWiki.db', true);
  xhr.responseType = 'arraybuffer';
  xhr.onload = function(e) {
    var uInt8Array = new Uint8Array(this.response);
    db = new SQL.Database(uInt8Array);
  };
  xhr.send();
```

This snippet still results in: 

```
Cross-Origin Request Blocked: The Same Origin Policy disallows reading the remote resource at http://127.0.0.1:43110/kaffiene.bit/cors-138R53t3ZW7KDfSfxVpWUsMXgwUnsDNXLP/data/ZeroWiki.db. (Reason: CORS header â€˜Access-Control-Allow-Originâ€™ missing).  (unknown)
```

Even when permission has been granted. Testing with fileget, I was able to grab a text-based file (README.md for instance). However, I'm unsure how I'd go about fetching the .db or any non-text file for my own parsing purposes. Upon further testing, I *cannot* fetch the readme file through XMLHttpRequest, due to CORS, even though I'm fetching from within the virtual directory after given permission.

Does fileget have an option to just fetch the raw file?

Edit: Nevermind. Got it. Just change the parameters to be a dictionary and then use inner_path for the directory, and set format to base64. From there you can convert it to a uInt8Array using [this script.](https://github.com/danguer/blog-examples/blob/master/js/base64-binary.js) Works great :D 

```
page.cmd("corsPermission", "138R53t3ZW7KDfSfxVpWUsMXgwUnsDNXLP")
page.cmd("fileGet",
     {
        "inner_path": 'cors-138R53t3ZW7KDfSfxVpWUsMXgwUnsDNXLP/data/ZeroWiki.db',
        "format": 'base64'
      }, function(data) {
    var uInt8Array = new Uint8Array(Base64Binary.decodeArrayBuffer(data));
}
```  Hey there, just testing out the '/raw' test site mentioned in #962: http://127.0.0.1:43110/raw/1AsRLpuRxr3pb9p3TKoMXPSWHzh6i7fMGi/en.tar.gz/index.html

I get the following error when attempting to load it:

```
Err: AttributeError: 'NoneType' object has no attribute 'needFile' in UiServer.py line 93 > UiRequest.py line 104 > UiRequestPlugin.py line 22 > TranslateSitePlugin.py line 25 > FilePackPlugin.py line 52
```

```
{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate", 
    "HTTP_ACCEPT_LANGUAGE": "en-US,en;q=0.5", 
    "HTTP_CACHE_CONTROL": "max-age=0", 
    "HTTP_CONNECTION": "keep-alive", 
    "HTTP_DNT": "1", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0", 
    "PATH_INFO": "/raw/1AsRLpuRxr3pb9p3TKoMXPSWHzh6i7fMGi/en.tar.gz/index.html", 
    "QUERY_STRING": "", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "34616", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "localhost", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.0 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bind": null, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": null, 
        "config_file": "zeronet.conf", 
        "connected_limit": 8, 
        "data_dir": "data", 
        "db_mode": "speed", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "end": true, 
        "file_size_limit": 10, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "fix_float_decimals": false, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "ip_local": [
            "127.0.0.1"
        ], 
        "keep_ssl_cert": false, 
        "language": "en", 
        "log_dir": "log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": true, 
        "open_browser": "default_browser", 
        "optional_limit": "10%", 
        "proxy": null, 
        "silent": false, 
        "size_limit": 10, 
        "stack_size": null, 
        "stream_downloads": false, 
        "tor": "always", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_hs_limit": 10, 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.opentrackr.org:1337/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_host": null, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "updatesite": "1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp", 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false, 
        "workers": 5
    }, 
    "plugins": [
        "AnnounceZero", 
        "CryptMessage", 
        "FilePack", 
        "MergerSite", 
        "Mute", 
        "Newsfeed", 
        "OptionalManager", 
        "PeerDb", 
        "Sidebar", 
        "Stats", 
        "TranslateSite", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.0.2", 
    "version_python": "2.7.11 |Continuum Analytics, Inc.| (default, Dec  6 2015, 18:08:32) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]", 
    "version_zeronet": "0.5.6 r2154", 
    "wsgi.url_scheme": "http"
}
```

Debian 9, x64

Edit: Same error on a freshly-downloaded ZeroBundle on MacOS Sierra.     I seriously believe that ZeroNet is suffering a DDOS attack.
I saw 1732 seeds in ZeroName.
In less than 4 minutes ZeroName is with 1608 seeds.
@HelloZeroNet, what do you think about preventing custom clients that can download a site but doesn't seed?
Also these great volume of "users" are seeding in majority ZeroName against ZeroHello. It is normal?
And when I tried to publish a comment about it in ZeroMe, it was stuck on publishing to 4 peers. http://127.0.0.1:43110/Talk.ZeroNetwork.bit/?Topic:69_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv
@Nofish: this NEEDS to be fixed with URGENCY. Thanks @kai0: now I know what is hapenning here.
Here I'm persecuted by the owners here, and they spy in my house anything I do in the Internet. When I created a site, in less than 1 minute it gained 5 peers without any promoting!
I properly signed it and tried to publish to a lot of proxies like I ever did in the last year, but now the proxies didn't received my updates. I know these 5 fixed peers are the mans that are persecuting me, and they made my site inavailable to the following peers. In the last year no, but now it was discovered by they. It needs to be fixed, because is clearly a security vulnerability.
Here are the prints, as a timeline:
http://prntscr.com/fx4482
http://prntscr.com/fx44d0
Without promoting, my site has 2 peers connected. One minute later, I saw it unavailable in the proxies.
http://prntscr.com/fx46pt
Stucked in the publishing (it can be normal, I know).
http://prntscr.com/fx470a
Stuck loading on proxies. I tried to publish more to reach proxies, everytime in this timeline.
http://prntscr.com/fx482w
Loaded only a few things.
http://prntscr.com/fx49kt
Loaded more things, but JS don't loaded.
http://prntscr.com/fx4afv
Not found on bit.surf.
https://prnt.sc/fx44kx
Peeper works on my local.
https://prnt.sc/fx44tg
Peeper isn't working on my mobile phone and on proxies like Peeper ever worked.
http://prntscr.com/fx4mfu
Ok, you can say the problem is on MY Peeper, on zn.maly, on MY CryptoID, on bit.surf, on colored poneys breeded with unicorns, whatever. But locally I can't see my video.
http://prntscr.com/fx4mqy
But in this proxy on the first load it appears!

Nofish, remember when I talked to you about the increasing peer number and the stranger things? And also this number isn't compatible with the people really using the sites. You talked its is normal, but I surely believe that a botnet is attacking ZeroNet. @shortcutme The solution I was thinking is to when a peer see that the connected peer isn't sending the correct data to him (based in the site's address signature), then this peer is reported. Accourding to a number of reports, the peer is blocked and added in a site called BlockList, shipped with ZeroNet. > Im not at home right now, i will check it next month if its still an issue

Obviously it will still be a issue, unless you fix it or approve pull request of someone fixing it.
I think is stranger you not be in home just when ZeroNet gets his provbly biggest bug, yesterday has lots of your contribution to ZeroNet. @HelloZeroNet
@shortcutme @HelloZeroNet

> I still have not found any suspicious activity and the updates reached my remote clients correctly.

Sure, they don't want this info reach you.

> (6 instead of 4)
> We can make it even higher

Will be nice a field in the 0 menu to set the minimum peers to publish.

> but unfortunately there is no way to make sure that every update is reaches every node.

Solution: when a peer see that the connected peer isn't sending the correct data to him (based in the site's address signature), then this peer is reported. Accourding to a number of reports, the peer is blocked and added in a site called BlockList, shipped with ZeroNet. @HelloZeroNet
Please read:
http://127.0.0.1:43110/Talk.ZeroNetwork.bit/?Topic:69_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv @HelloZeroNet

> I will monitor the "each time connecting the same nodes." problem.

Excelent. I did tests and peers was not sending the files, and the proxy/my client keeps with the same peers and still receiving 404, even my sites having 20/600 peers and I properly publishing all files. @HelloZeroNet
A solution here is to switch to other peers when receiving 404.
Blocking malicious peers is the best addition. > Well i'm not sure if its a good idea, because it would encourages people to run many clients on the same machine an by that flood the network.

Then, people can flood the network, this explains the "bit more peer than usual".
http://web.archive.org/web/20170808162515/https://github.com/HelloZeroNet/ZeroNet/issues/898 @HelloZeroNet @shortcutme 

> I will monitor the "each time connecting the same nodes." problem.

A idea for this is here: https://github.com/ZeroNetJS/zeronet-js/issues/46.

@zwgshr @imachug @MuxZeroNet @PeterSurda

Please fix it.
Its the worst ZeroNet's security problem. @HelloZeroNet, @shortcutme @HelloZeroNet
"Thanks but there is not real security issues" ? ZeroNet fetches a list of peers from the tracker every 2 hours. Your instance may be a side effect of this.

o A computer has a limited amount of RAM.

o A computer program can handle a limited number of simultaneous connections.

o A majority of users browse ZeroNet for only a few hours a day and shut their nodes off, so it is a good idea to ask the trackers for a new list of peers every few hours.

o Some trackers are known to intentionally insert fake IPs in order to confuse DMCA bots. Those 5 "phantom" peers might be fake IPs inserted by the trackers.

o ZeroNet has a "rating" algorithm.


>
> @HelloZeroNet
> "Thanks but there is not real security issues" ?
>
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, > view it on GitHub> , or > mute the thread> .
>      @MuxZeroNet
Some peers can give 404 errors. So would be good change to another peer when receiving 404 and to downvote it.
ZeroNetJS already have this reliability/security improvement.  Mozilla and the National Science Foundation are offering a $2 million prize for big ideas that decentralize the web.

https://blog.mozilla.org/blog/2017/06/21/2-million-prize-decentralize-web-apply-today/
https://wirelesschallenge.mozilla.org/

I think ZeroNet and it's ideas can apply for **Challenge 2: Smart Community Networks Challenge**

>How can we leverage existing infrastructure to provide robust wireless Internet connectivity in communities that need greater access?
>
>Ten percent of all Americans â€” 34 million people â€” lack access to quality Internet connectivity. The Smart Community Networks Challenge aims to close this access gap by enhancing wireless connectivity in areas where Internet access is a challenge, whether due to geographic, financial or other factors. With a total of $1M in prize money, the Smart Community Networks Challenge seeks wireless solutions that leverage existing physical infrastructure to provide robust access to the whole Internet in underserved areas. > provide robust wireless Internet connectivity in communities that need greater access?

Not sure, but it seems they're talking about a hardware solution to get more people online, versus a software solution like ZeroNet for getting more people connected.

Though how that goal *decentralizes* the web I do not know.

That being said, doesn't hurt to apply I suppose. >If applying as an individual or team of individuals, all team members must be U.S. permanent residents (i.e. citizens or green card holders)
>If applying as an organization, the team lead can be anyone who is an employee of that organization and 18 years of age (including visa holders), provided that the organization is incorporated in and maintains a primary place of business in the U.S.

They also accept solutions without Internet access.  Hi, 
if I understood correctly the CORS security is here to prevent zites from downloading other zites without user consent, but what about already downloaded zites ? To load an image currently you need to use fileGet and convert that into a data uri, which is not very efficient, where you could just allow some resources to be loaded. No idea if it's possible and if it's easy to setup.  When I clone a site:

<img width="738" alt="" src="https://user-images.githubusercontent.com/15178410/28071919-f9a1a7da-6683-11e7-8843-5054e37ff309.png">

<img width="740" alt="" src="https://user-images.githubusercontent.com/15178410/28071946-0df8f364-6684-11e7-83a5-a89602d2f9f0.png">

<img width="741" alt="" src="https://user-images.githubusercontent.com/15178410/28071957-1346d336-6684-11e7-95d9-4948852dcf98.png">

The page is refreshed before I see the alert (animated complete).
So, what is the alert say?  `new Worker("worker.js")` merely fails: `Uncaught DOMException: Failed to construct 'Worker': Script at 'http://127.0.0.1:43110/[site address]/worker.js' cannot be accessed from origin 'null'.`
No idea about whether disallowing web workers should be a bug or a feature. I know, this is closed, but don't service workers need https anyways?!

PS.: This can be achieved through visiting zeronet via _localhost_ instead of _127.0.0.1_ (at least as far as I remember (at least in chrome)).  @HelloZeroNet Ah wow, I did so much research on workers, but till now, I didn't quite understand the differences ðŸ˜…  I already did:
`pip install gevent msgpack-python`

Then I receive in the command prompt:

> - Starting ZeroNet...
> ERROR:root:Unhandled exception: No module named gevent
> Traceback (most recent call last):
>   File "C:\Programs\Programs\ZeroNet-win-dist\core\zeronet.
> 
>     import main
>   File "C:\Programs\Programs\ZeroNet-win-dist\core\src\main
> ule>
>     import gevent
> ImportError: No module named gevent
> Traceback (most recent call last):
>   File "C:\Programs\Programs\ZeroNet-win-dist\core\zeronet.
> ule>
>     main()
>   File "C:\Programs\Programs\ZeroNet-win-dist\core\zeronet.
> 
>     traceback.print_exc(file=open(config.log_dir + "/error.
> AttributeError: 'Config' object has no attribute 'log_dir' I has only Python 2.7.3, but the commands not worked in the command prompt, then I installed Python 3.6.1, and the installation had worked. But in ZeroNet it isn't working because ZN needs the Python 2.7.3, then gevent is only installed in 3.6.1 but not in 2.7.3. Any manner to do commands for 2.7.3 only? @HelloZeroNet
Its because Python 2.7 doesn't supports the PATH and PYTHONPATH. I suggest ZeroNet to update to the latest Python version. you can try `pip2` instead of `pip` to force it to use python2 > 'pip2' is not recognized as an internal or external command,
> operable program or batch file. @HelloZeroNet ```
C:\Windows\System32>C:\Python27\python.exe
C:\Python27\python.exe: No module named pip
```
----

```
C:\Windows\System32>C:\Python27\python.exe -m pip install gevent msgpack
Downloading/unpacking gevent
  Running setup.py (path:c:\users\world.wd\appdata\local\temp\pip_build_World.w
\gevent\setup.py) egg_info for package gevent
    C:\Python27\lib\distutils\dist.py:267: UserWarning: Unknown distribution op
ion: 'cffi_modules'
      warnings.warn(msg)
    warning: no files found matching 'changelog.rst'
    warning: no files found matching 'known_failures.py'
    warning: no files found matching '.pep8'
    no previously-included directories found matching '*\__pycache__'
    warning: no previously-included files matching '*.so' found anywhere in dis
ribution
    warning: no previously-included files matching '*.o' found anywhere in dist
ibution
    warning: no previously-included files matching '*.lo' found anywhere in dis
ribution
    warning: no previously-included files matching '*.la' found anywhere in dis
ribution
    warning: no previously-included files matching 'config.log' found anywhere
n distribution
    warning: no previously-included files matching 'config.status' found anywhe
e in distribution
    no previously-included directories found matching 'doc\_build'
    warning: no previously-included files matching '*.pyc' found anywhere in di
tribution
    warning: no previously-included files matching '.coverage' found under dire
tory 'src\greentest'
    no previously-included directories found matching 'src\greentest\htmlcov'
    warning: no previously-included files matching 'stamp-h?' found under direc
ory 'deps\c-ares'
    warning: no previously-included files matching 'ares_build.h.orig' found un
er directory 'deps\c-ares'
    no previously-included directories found matching 'deps\libev\.deps'
    warning: no previously-included files matching 'Makefile' found under direc
ory 'deps\libev'
    warning: no previously-included files matching 'libtool' found under direct
ry 'deps\libev'
    warning: no previously-included files matching 'stamp-h?' found under direc
ory 'deps\libev'
    warning: no previously-included files matching 'config.h' found under direc
ory 'deps\libev'
    warning: no previously-included files matching '_corecffi.c' found under di
ectory 'src\gevent'
    warning: no previously-included files found matching 'Makefile'
    warning: no previously-included files found matching 'configure-output'
Downloading/unpacking msgpack
  Could not find any downloads that satisfy the requirement msgpack
Cleaning up...
No distributions at all found for msgpack
Storing debug log for failure in c:\users\world.wd\appdata\local\temp\tmppmsv6s
```
----

```
C:\Windows\System32>C:\Programs\Programs\ZeroNet-win-dist\core\zeronet.py --debu
g
- Starting ZeroNet...
ERROR:root:Unhandled exception: No module named gevent
Traceback (most recent call last):
  File "C:\Programs\Programs\ZeroNet-win-dist\core\zeronet.py", line 18, in main

    import main
  File "C:\Programs\Programs\ZeroNet-win-dist\core\src\main.py", line 9, in <mod
ule>
    import gevent
ImportError: No module named gevent
Traceback (most recent call last):
  File "C:\Programs\Programs\ZeroNet-win-dist\core\zeronet.py", line 91, in <mod
ule>
    main()
  File "C:\Programs\Programs\ZeroNet-win-dist\core\zeronet.py", line 64, in main

    traceback.print_exc(file=open(config.log_dir + "/error.log", "a"))
AttributeError: 'Config' object has no attribute 'log_dir'
``` Whats the recommended Python version to use? I'm in 2.7.9 and gevent with greenlet is successfully installed.
But in this last step (msgpack) I'm getting this:

```
C:\Windows\System32>C:\Python27\python.exe -m pip install msgpack
Collecting msgpack
  Could not find a version that satisfies the requirement msgpack (from versions
: )
No matching distribution found for msgpack
```

I only need to pass this to start developing my projects in ZeroNet with the `--debug` mode and to say you if the bug https://github.com/HelloZeroNet/ZeroNet/issues/1007 is solved. msgpack is `old`. Please update the docs, because the new version is called `msgpack-python`.  Apparently it isn't possible to sign files whose names contain parentheses or square brackets with the _siteSign_ command, even through they are printable ASCII characters. @HelloZeroNet square brackets and parenthesis are fairly common in file/folder names. I'd suggest adding them to the list.

I also remember having to deal with renaming files with parenthesis when I was mirroring a site on ZeroNet, would be nice if that wasn't required :)  **Operating system**: Windows 7 SP1 x64 (but I believe it also happens in other OS)

**Steps to reproduce**:

1. Use terminal and open `zeronet.py` with the `debug` flag;
2. Create or import a profile and use ZeroID+other social sites of ZeroNet;
3. Close ZeroNet;
4. Re-open ZeroNet, yet using the `debug` flag;
5. You will see that all the data was "reseted".

The data is "reseted" because ZeroNet then creates a `data` folder inside the `core` folder and sets it as default.
A current solution for it is moving all data from the older folder to the new, then restart ZeroNet. The reverse also occurs:

1. Open ZeroNet normally;
2. See that your data from debug mode is working in the sites (folder: core/data);
3. Close ZeroNet;
4. Re-open ZeroNet;
5. You will see that all the data was "reseted" (now under the normal data folder). @shortcutme
@HelloZeroNet The bug is now fixed. Thanks! @shortcutme

> Thanks for reporting

Thanks? Where is my name in the page of the update 0.5.7 in the ZeroNet's blog and other media where possibly this update was announced by you?  These are the install instructions for Debian instructions - 

```
Manual install for Debian Linux

    sudo apt-get update
    sudo apt-get install msgpack-python python-gevent
    wget https://github.com/HelloZeroNet/ZeroNet/archive/master.tar.gz
    tar xvpfz master.tar.gz
    cd ZeroNet-master
    Start with python zeronet.py
    Open http://127.0.0.1:43110/ in your browser
```

There just needs to be one change - 

`tar xvpfz ZeroNet-master.tar.gz `

and all will be good, please do the fix/tweak . 

 Thanks for pointing this out. Do you think you can submit a pull request to fix this? I tested also, current instructions are correct, no need for change.
@shirishag75 @HelloZeroNet Please, close.  I use windows. tor was bundled to zeronet. but how can I set?  I can find it  ./Library/Application Support/ZeroNet/data
What a fuck! imo, it'd be nice if there were a way for the user to discover this path through the ui IN sierraï¼Œthis is the only path  Android mobile open https://zeronet.io  can't download zeronet APK. click download no response. Same here, this seems to be due to the following GitHub URL resolving to a 404:

https://api.github.com/repos/HelloZeroNet/ZeroNet-kivy/releases/latest

ZeroNet-kivy obviously still has releases available, so this may be a temporary GitHub issue, rather than ZeroNet's.  Hello there, currently writing an application that parses websites hosted on ZeroNet.

When one requests a website on ZeroNet, such as:

http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D

it grabs the index.html content and wraps it in an iframe.

At this point any application trying to resolve `http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/index.html` runs into the following issues:

* Receives a 403 forbidden error due to missing nonce - this is only required for the index.html site, not other files on the site
* Even with the correct nonce, included source code is just the ZeroNet wrapper code, no actual site HTML.

Is it possible to add a feature to ZeroNet to download raw index.html's, for easier inter-operability with other services? Something like:

http://127.0.0.1:43110/raw/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D

that could just return the raw index.html file would be great.

Thanks! I think that would be a security issue.
That's why there is a wrapper.
But a workaround would be to only allow loading the /raw from an ajax request. @mkg20001 I don't believe so, as other files are served quite happily as downloads directly to the browser.

Additionally I'm not sure if we can differentiate between a `wget` GET request to that URL and a browser request, but then again it shouldn't be a problem.

All we would need to do is present the content in a similar manner to have GitHub does so with its raw feature: https://raw.githubusercontent.com/HelloZeroNet/zeronet.io/master/index.html

This way no javascript on the page is executed, and there's no other stuff on the page that can confuse application parsers.

Edit: The answer to this seems to be as simple as setting the content-type to `text/plain` in the HTTP response header.

See here: https://stackoverflow.com/questions/32876956/how-does-github-raw-code-work-it-can-display-text-like-code-without-pre-tag I took a look at the code for the Stats plugin since it already has the functionality of returning data upon a request to `127.0.0.1:43110/xxxx`.

It wasn't immediately clear where the code that defined this entry point lived... @HelloZeroNet would writing a plugin for this functionality be overkill compared to just including it in the client? Are there any other `127.0.0.1:43110/xxx` addresses that are available already or is the `/Stats` page just a special feature? `<a href="http://127.0.0.1:43110/raw/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/evil.html" target="_top">Stupid mankind</a>`
 @HelloZeroNet @MuxZeroNet Good points, I can see how it could be a security issue now.

And @HelloZeroNet wow, that definitely does work! I guess I still need to adjust to the p2p mindset :)  OpenSSL 1.0.2k --> [OpenSSL 1.0.2l](https://www.openssl.org/source/)  ![default](https://user-images.githubusercontent.com/28748344/27466283-0ea3304e-580c-11e7-8022-a79c1bb09ad5.PNG)

Can't open ZeroNet Client.
win10 x64
  Put a Chinese  named file to blog, click it, show error.  [ReDoS](https://en.wikipedia.org/wiki/ReDoS) turns out to be an old and classical attack. A program is vulnerable to this attack if regular expressions are controlled by user input. There are a few possible solutions:

- Use a linear complexity [RegEx library](https://github.com/facebook/pyre2/).
- [Timeout](https://stackoverflow.com/questions/11901328/how-to-timeout-function-in-python-timeout-less-than-a-second) a RegEx function call.
- Deprecate regular expressions. Use a shell-like matching syntax `["updater/*", "*.mp4", "optional_*"]`.  Version 0.5.6 prints this in log:
```
[21:30:50] FileServer Conn#199 144.202.228.211 [?] > Closing connection: Send errror: AttributeError: 'NoneType' object has no attribute 'sendall' in Connection.py line 364, waiting_requests: 1, sites: 3, buff: 0...
```
and
```
[21:32:05] Site:1CpQfw..GP2o 5.101.103.222:15441 Getting connection error: AttributeError: 'NoneType' object has no attribute 'get' in Peer.py line 81 > ConnectionServer.py line 147 (connection_error: 1, hash_failed: 0)
```

Please also note typo ```errror```.
  The network command handshake is completely missing from the docs at https://zeronet.readthedocs.io/en/latest/help_zeronet/network_protocol/
Could there be some more documentation?

```
{ cmd: 'handshake',
  params: 
   { target_ip: '217.234.60.22',
     version: '0.5.6',
     protocol: 'v2',
     crypt: null,
     fileserver_port: 15441,
     port_opened: false,
     peer_id: '-ZN0056-Ap3jwnKJHrCy',
     rev: 2109,
     crypt_supported: [ 'tls-rsa' ] },
  req_id: 0 }
}
``` Also getHashfield, setHashfield and listModified are undocumented The handshake command doc is missing the details about the "crypto" variable.
Usually the response includes the crypto both clients support (as seen in live traffic).
Also the onion variable seems optional.
At least afaik. But I have seen that behavior in live traffic too. ...and it completely leaves out the fact about tls wrapping the socket afterwards and that the handshake is optional (afaik the client responds to requests even if no handshake was sent, if that is a feature)

Could you please document that behavior too? I have created a pr HelloZeroNet/Documentation#58 but I'm unsure if everything is correct.  When I access UI interface, `INFO     Ui.UiServer Added 127.0.0.1:43110 as allowed host` is in log/debug.log. So I think that "learn allowed host" should ignore "127.0.0.1:43110". And if Multiuser plugins enabled or ui_ip is not `127.0.0.1`, learn allowed host.
OS: Windows Server 2012 R2 Standard
Browser: Firefox 52.2.0 ESR
When I open ZeroNet, a ZeroHello page opens.
This format in `zeronet.conf` works well, Thanks!  Forbidden

Invalid Accept header to load wrapper

Please report it if you think this an error.

Details:
{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "image/gif, image/jpeg, image/pjpeg, application/x-ms-application, application/xaml+xml, application/x-ms-xbap, application/vnd.ms-excel, application/vnd.ms-powerpoint, application/msword, */*", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate", 
    "HTTP_ACCEPT_LANGUAGE": "zh-Hans-CN,zh-Hans;q=0.8,en-US;q=0.5,en;q=0.3", 
    "HTTP_CONNECTION": "Keep-Alive", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; Touch; rv:11.0; 2345Explorer/8.6.2.15747) like Gecko", 
    "PATH_INFO": "/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
    "QUERY_STRING": "", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "49906", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "JK-GPD-win", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.2 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bind": null, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": "type %s | tools\\coffee\\coffee.cmd", 
        "config_file": "C:/ZeroNet-win-dist/zeronet.conf", 
        "connected_limit": 8, 
        "data_dir": "C:/ZeroNet-win-dist/data", 
        "db_mode": "speed", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "end": true, 
        "file_size_limit": 10, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "fix_float_decimals": false, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "ip_local": [
            "127.0.0.1"
        ], 
        "keep_ssl_cert": false, 
        "language": "zh", 
        "log_dir": "C:/ZeroNet-win-dist/log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": true, 
        "open_browser": "default_browser", 
        "optional_limit": "50%", 
        "proxy": null, 
        "size_limit": 10, 
        "stack_size": null, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_hs_limit": 10, 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.opentrackr.org:1337/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_host": null, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "updatesite": "1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp", 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false, 
        "workers": 5
    }, 
    "plugins": [
        "AnnounceZero", 
        "CryptMessage", 
        "FilePack", 
        "MergerSite", 
        "Mute", 
        "Newsfeed", 
        "OptionalManager", 
        "PeerDb", 
        "Sidebar", 
        "Stats", 
        "TranslateSite", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.2.1", 
    "version_python": "2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 20:42:59) [MSC v.1500 32 bit (Intel)]", 
    "version_zeronet": "0.5.6 r2109", 
    "wsgi.url_scheme": "http"
}
 how to fix this bug? Try reloading the page Or set Accept-Header: text/html :confused:
`"HTTP_ACCEPT": "image/gif, image/jpeg, image/pjpeg, application/x-ms-application, application/xaml+xml, application/x-ms-xbap, application/vnd.ms-excel, application/vnd.ms-powerpoint, application/msword, */*"`

:confused: What is this...
`2345Explorer/8.6.2.15747`

- - -
**EDIT:** OP, could you try using another browser? @jarodlee Have you solved this issue? Same error. I have several servers with ZeroNet behind nginx reverse-proxy. At all, everything works fine, but on one server - such an error is produced. The configuration is the same everywhere.
```
Invalid Accept header to load wrapper                                                                                                                         
                                                                                                                                                              
  Please report it if you think this an error.                                                                                                                
                                                                                                                                                              
    Details:                                                                                                                                                  
                                                                                                                                                              
{                                                                                                                                                             
    "GATEWAY_INTERFACE": "CGI/1.1",                                                                                                                           
    "HTTP_ACCEPT": "*/*",                                                                                                                                     
    "HTTP_ACCEPT_CHARSET": "us-ascii,ISO-8859-1,ISO-8859-2,ISO-8859-3,ISO-8859-4,ISO-8859-5,ISO-8859-6,ISO-8859-7,ISO-8859-8,ISO-8859-9,ISO-8859-10,ISO-8859-1
    "HTTP_ACCEPT_ENCODING": "gzip, deflate, bzip2, lzma, lzma2",                                                                                              
    "HTTP_ACCEPT_LANGUAGE": "ru,en;q=0.2,*;q=0.1",                                                                                                            
    "HTTP_CONNECTION": "keep-alive",                                                                                                                          
    "HTTP_HOST": "127.0.0.1:43110",                                                                                                                           
    "HTTP_USER_AGENT": "Links (2.12; Linux 4.4.0-89-generic x86_64; GNU C 5.2.1; text)",                                                                      
    "PATH_INFO": "/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D",                                                                                                       
    "QUERY_STRING": "",                                                                                                                                       
    "REMOTE_ADDR": "127.0.0.1",                                                                                                                               
    "REMOTE_PORT": "36408",                                                                                                                                   
    "REQUEST_METHOD": "GET",                                                                                                                                  
    "SCRIPT_NAME": "",                                                                                                                                        
    "SERVER_NAME": "localhost",                                                                                                                               
    "SERVER_PORT": "43110",                                                                                                                                   
    "SERVER_PROTOCOL": "HTTP/1.1",                                                                                                                            
    "SERVER_SOFTWARE": "gevent/1.1 Python/2.7",                                                                                                               
    "arguments": {                                                                                                                                            
        "action": "main",                                                                                                                                     
        "batch": false,                                                                                                                                       
        "bind": null,                                                                                                                                         
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F",                                                                                                 
        "coffeescript_compiler": null,                                                                                                                        
        "config_file": "zeronet.conf",                                                                                                                        
        "connected_limit": 8,                                                                                                                                 
        "data_dir": "data",                                                                                                                                   
        "db_mode": "speed",                                                                                                                                   
        "debug": false, 
       "debug_gevent": false,                                                                                                                                
        "debug_socket": false,                                                                                                                                
        "disable_db": false,                                                                                                                                  
        "disable_encryption": false,                                                                                                                          
        "disable_sslcompression": true,                                                                                                                       
        "disable_udp": false,                                                                                                                                 
        "download_optional": "manual",                                                                                                                        
        "end": true,                                                                                                                                          
        "file_size_limit": 10,                                                                                                                                
        "fileserver_ip": "*",                                                                                                                                 
        "fileserver_port": 15441,                                                                                                                             
        "fix_float_decimals": false,                                                                                                                          
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D",                                                                                                     
        "ip_external": null,                                                                                                                                  
        "ip_local": [                                                                                                                                         
            "127.0.0.1"                                                                                                                                       
        ],                                                                                                                                                    
        "keep_ssl_cert": false,                                                                                                                               
        "language": "ru",                                                                                                                                     
        "log_dir": "log",                                                                                                                                     
        "max_files_opened": 2048,                                                                                                                             
        "msgpack_purepython": false,                                                                                                                          
        "open_browser": null,                                                                                                                                 
        "optional_limit": "10%",                                                                                                                              
        "proxy": null,                                                                                                                                        
        "silent": false,                                                                                                                                      
        "size_limit": 10,                                                                                                                                     
        "stack_size": null,                                                                                                                                   
        "stream_downloads": false,                                                                                                                            
        "tor": "disable",                                                                                                                                     
        "tor_controller": "127.0.0.1:9051",                                                                                                                   
        "tor_hs_limit": 10,                                                                                                                                   
        "tor_proxy": "127.0.0.1:9050",                                                                                                                        
        "trackers": [                                                                                                                                         
            "zero://boot3rdez4rzn36x.onion:15441",                                                                                                            
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441",                                                  
            "udp://tracker.coppersurfer.tk:6969",                                                                                                             
            "udp://tracker.leechers-paradise.org:6969",                                          
            "udp://9.rarbg.com:2710",                                                                                                                         
            "http://tracker.opentrackr.org:1337/announce",                                                                                                    
            "http://explodie.org:6969/announce",                                                                                                              
            "http://tracker1.wasabii.com.tw:6969/announce"                                                                                                    
        ],                                                                                                                                                    
        "trackers_file": false,                                                                                                                               
        "ui_host": [                                                                                                                                          
            "127.0.0.1:43110",                                                                                                                                
            "zeronet.babak.home.balancer.ru"                                                                                                                  
        ],                                                                                                                                                    
        "ui_ip": "127.0.0.1",                                                                                                                                 
        "ui_port": 43110,                                                                                                                                     
        "ui_restrict": false,                                                                                                                                 
        "updatesite": "1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp",                                                                                                    
        "use_openssl": true,                                                                                                                                  
        "use_tempfiles": false,                                                                                                                               
        "verbose": false,                                                                                                                                     
        "workers": 10                                                                                                                                         
    },                                                                                                                                                        
    "plugins": [                                                                                                                                              
        "AnnounceZero",                                                                                                                                       
        "Cors",                                                                                                                                               
        "CryptMessage",                                                                                                                                       
        "FilePack",                                                                                                                                           
        "MergerSite",                                                                                                                                         
        "Mute",                                                                                                                                               
        "Newsfeed",                                                                                                                                           
        "OptionalManager",                                                                                                                                    
        "PeerDb",                                                                                                                                             
        "Sidebar",                                                                                                                                            
        "Stats",                                                                                                                                              
        "TranslateSite",                                                                                                                                      
        "Trayicon",                                                                                                                                           
        "Zeroname"                                                                                                                                            
    ],                                                                                                                                                        
    "version_gevent": "1.1.0",                                                                                                                                
    "version_python": "2.7.12 (default, Nov 19 2016, 06:48:10) \n[GCC 5.4.0 20160609]",                                                                       
    "version_zeronet": "0.5.7 r2187",                                                      
    "wsgi.url_scheme": "http"                                                                                                                                 
}   
```  In ZeroNet core, both `privatekey` and `auth_privatekey` are used to check if user can sign `content.json`, but there is no such check in `Sidebar` plugin.

Here we also check if `auth_address` can sign `content.json`.  ```python
# ContentManager.py
try:
    if not content:
        content = self.site.storage.loadJson(inner_path)  # Read the file if no content specified
    user_urn = "%s/%s" % (content["cert_auth_type"], content["cert_user_id"])  # web/nofish@zeroid.bit
    cert_user_id = content["cert_user_id"]
except Exception:  # Content.json not exist
    user_urn = "n-a/n-a"
    cert_user_id = "n-a"
```

If default file size is `0` , and file size for `nofish@zeroid.bit` is `100000`, then nobody can sign. That's because if there is no `content.json`, user id is tested against `n-a/n-a@n-a`.

Probably we can change `except` block to get current ZeroID (or other cert provider). 1. Press `Create new, empty site` in ZeroHello
2. Create `data/users/content.json` with the following content:
```javascript
{
  "files": {},
  "ignore": ".*",
  "modified": 0.0,
  "signs": {},
  "user_contents": {
    "cert_signers": {
      "zeroid.bit": [ "1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz" ]
    },
    "permission_rules": {
      ".*": {
        "files_allowed": "data.json",
        "max_size": 0
      }
    },
    "permissions": {
      "nofish@zeroid.bit": { "max_size": 100000 }
    }
  }
}
```
3. Add `include` and `ignore` to root `content.json`:
```javascript
...
    "ignore": "data/.*",
    "includes": {
        "data/users/content.json": {
            "signers": [],
            "signers_required": 1
        }
    },
...
```
4. Sign `content.json` and then `data/users/content.json`
5. Login to ZeroID using sidebar (`Unique address` -> `Change` -> `nofish@zeroid.bit`)
6. Try to sign `data/users/1J3rJ8ecnwH2EPYa6MrgZttBNc61ACFiCj/content.json` using sidebar

Signing fails because there is no `content.json`, and `n-a/n-a@n-a` is used as `cert_user_id` instead Thanks!  Currently `fileRules('content.json')` throws `Pop from empty list`. This patch fixes the exception and gives valid result.  Signs with keys are now saved. `signs_required` is checked. By the way, @HelloZeroNet.

Say, we have the following `content.json`:
```json
{
    ...
    "signers": [
        "A",
        "B"
    ],
    "signs": {
        "A": "Sign-for-version-1",
        "B": "Sign-for-version-1"
    },
    "signers_required": 2
    ...
}
```

Then, `A` adds new post:
```json
{
    ...
    "signers": [
        "A",
        "B"
    ],
    "signs": {
        "A": "Sign-for-version-2",
        "B": "Sign-for-version-1"
    },
    "signers_required": 2
    ...
}
```
...and tries to publish it. But he can't! All peers reject this `content.json` because only 1 sign (`A`) is valid. How can `B` get this `content.json` and sign it with his `B` key?  Replaces BAT/WSH/JS *solution* with pip package.

On my machine WSH script just gave `Compiler error: Unable to Base64 encode...`. That's probably because:
```javascript
typeof "ABCDE"[0] == "undefined"
```

...Don't know why it worked before. Maybe because ZeroNet saw my own CoffeeScript compiler? Fixes #941 @HelloZeroNet It works. Thanks!  Server error

Err: ValueError: Invalid control character at: line 4886 column 20 (char 352129) in UiServer.py line 83 > UiRequest.py line 83 > MutePlugin.py line 153 > UiRequest.py line 223 > SiteManagerPlugin.py line 64 > SiteManager.py line 132 > Site.py line 56 > Site.py line 80 > __init__.py line 291 > __init__.py line 339 > decoder.py line 364 > decoder.py line 380

Please report it if you think this an error.

Details:

{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate, sdch", 
    "HTTP_ACCEPT_LANGUAGE": "en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4", 
    "HTTP_CONNECTION": "keep-alive", 
    "HTTP_HOST": "10.102.4.1:43110", 
    "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36", 
    "PATH_INFO": "/yangleitj.bit/", 
    "QUERY_STRING": "Post:18:yourname.com%E7%BB%91%E5%AE%9Ayourname.bit", 
    "REMOTE_ADDR": "10.102.4.240", 
    "REMOTE_PORT": "51844", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "ZBT-WE1326", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.2 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bind": null, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": null, 
        "config_file": "zeronet.conf", 
        "connected_limit": 8, 
        "data_dir": "data", 
        "db_mode": "speed", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "file_size_limit": 10, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "fix_float_decimals": true, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "ip_local": [
            "127.0.0.1"
        ], 
        "keep_ssl_cert": false, 
        "language": "en", 
        "log_dir": "log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": true, 
        "open_browser": null, 
        "optional_limit": "10%", 
        "proxy": null, 
        "size_limit": 10, 
        "stack_size": 32768, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_hs_limit": 10, 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.opentrackr.org:1337/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_ip": "10.102.4.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "updatesite": "1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp", 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false, 
        "workers": 5
    }, 
    "plugins": [
        "AnnounceZero", 
        "CryptMessage", 
        "FilePack", 
        "MergerSite", 
        "Mute", 
        "Newsfeed", 
        "OptionalManager", 
        "PeerDb", 
        "Sidebar", 
        "Stats", 
        "TranslateSite", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.2.1", 
    "version_python": "2.7.13 (default, May 30 2017, 21:05:50) \n[GCC 5.4.0]", 
    "version_zeronet": "0.5.5 r2099", 
    "wsgi.url_scheme": "http"
}  When i open the default Blog i only see this, when i clone it i get the same result, i can't also access Zeroid, it gets stuck in the main logo.

![a](https://user-images.githubusercontent.com/8495728/27008288-77c256e8-4e3b-11e7-9eac-ae0af93e7348.png)
 All the other pages like Zerotalk get stuck at Initial sync progess... i see the posts in ZeroHello but this shows empty, only comment dialog without content.

![sin titulo](https://user-images.githubusercontent.com/8495728/27008374-53545980-4e3d-11e7-823d-a2d3ace56852.png)

![sin titulo2](https://user-images.githubusercontent.com/8495728/27008381-7b70c246-4e3d-11e7-8f16-b1e2cdd07c4d.png)

 @Pupiloho Just waiting all files downloaded. I see this error in network. the same happens in Edge, the files are updated, the same happens with every other page, y unpacked the app in another folder and the only thing that changed is that the Zeroid page works and the authentication service, also can publish pages, the pages were even unable to publish before that.

![sin titulo](https://user-images.githubusercontent.com/8495728/27015244-90109db2-4ed7-11e7-8525-4f4d33136ecc.jpg)
![sin titulo2](https://user-images.githubusercontent.com/8495728/27015245-9017c380-4ed7-11e7-9cdf-2f92427c8fc6.jpg)

 I also tried it before with the blog, didn't worked, i tried now with Talk, Blog, Me, and did not work, There is no temporal file that Zeronet.exe or Tor.exe creates?. Doesn't work, I had a firewall enabled, i disabled it but still persist, also reset the pc, still, cleaned files with C
Cclenaer, same... I don't know what is happening, the error still persist on all pages.
![sin titulo](https://user-images.githubusercontent.com/8495728/27018439-99146322-4efe-11e7-817e-42526af48c24.png)

This is how my ZeroHello page looks. 
![sin titulo](https://user-images.githubusercontent.com/8495728/27018839-8599cda2-4f01-11e7-95cb-7c2e8ed1cdf0.png)
 Here is it

[zeroblog.zip](https://github.com/HelloZeroNet/ZeroNet/files/1073054/zeroblog.zip)
 Again, i send you the one from Gif forum to see if there is data 
[zerotalk.zip](https://github.com/HelloZeroNet/ZeroNet/files/1076299/zerotalk.zip)
[zeroblog.zip](https://github.com/HelloZeroNet/ZeroNet/files/1076307/zeroblog.zip)




 Â¡Excellent!, the issue is fixed, thank you, you are awesome, love this project, keep on.  Hi, just how the tittle says, i see there are a few things already that are in english, id like to translate everything of the base system that is translatable.   Sorry for posting questions in issues, but how much is this limit? Does it affect optional files too? Even when I set "distribute all files" feature my client will not download them?  Tested on [Psiphon 3](https://www.psiphon.ca/), just open it without any manual configuring. If will set system proxy automatically.  How could i run a Zeronet node at a VPS   Browsers are known to have a big attack surface around JavaScript, often leading to user tracking (loss of anonymity),  cookie hijacking and even remote code execution. Projects like the Tor Browser disable js by default for this reason.
Executing js from anonymous websites presents much higher risk than traditional well known sites.

Can you please clarify how ZeroNet handle the security of js? Thanks
  _Static websites_

It is perfectly fine to create static ZeroNet sites that work without JavaScript. [Static site generators](https://www.staticgen.com/) work very well in this case.

_Dynamic websites_

There is no backend. Computation, if necessary, must be done on the client side. We use JavaScript (browser side) and ZeroFrame APIs (restricted Python side computation) to make dynamic sites. It is impossible to display dynamic content while keeping things decentralized without running some algorithms on the client side to handle dynamic data.

_Attack vector_

Yes, **JavaScript is a major attack vector.** There is no extra protection except a sandbox iframe. Seriously, you should run ZeroNet in a virtual machine or in Whonix.

There are a few people asking us to implement PHP support. Keep in mind that "backend" code written by someone else will be executed on your computer. ZeroNet does not and will not support Flask, PHP, Node.js etc. that allows one to run totally unsandboxed code on your computer. Perhaps there could be an 'Execute Javascript on this site' toggle in the slide-over menu, and the user can choose whether this setting is on or off by default for all sites.

Of course Javascript will by default be globally on for the best user experience. "you should run ZeroNet in a virtual machine or in Whonix" - perhaps this should be written on the homepage or in the install instructions.

How does the Same-origin policy ties into serving content-addressed sites from localhost? Is it being circumvented? Hello!

Even though dynamic websites do not work without Javascript, there are a lot of static HTML websites on ZeroNet. I would like to see those static websites load when I have Javascript disabled globally. I have a few wishes.

o I hope the No Javascript warning could be dismissed. There is a CSS checkbox trick to accomplish this.

o I would like to see the inner iframe load without Javascript. Despite awkward, a page is at least readable without Javascript. Is there a particular reason why the src attribute of the inner iframe is assigned by Javascript code?

o I hope the developers could adopt [CSP script nonce] and [CSP script hash] to restrict inline Javascript, [harden] the sandbox and mitigate XSS attacks.

o I hope the developers could encourage the use of a SSH tunnel for remote access, instead of telling people to bind the Web UI to the whole Internet. This allows CSP to work.

o If you probe the port ~~15441~~ 43110, you will always find some misconfigured clients opening their ports to the whole Internet. This is another reason to encourage the use of SSH tunnels.


[script nonce] "Define script execution by requiring the presence of the specified nonce on script elements"
https://www.w3.org/TR/CSP2/#script-src-the-nonce-attribute
https://content-security-policy.com > disabled js using Content Security Policy

Using the HTML/iframe sandbox to disable JS is a good idea.  **Steps to Reproduce:**
1. Create new zite
2. Change `optional` entry to `^abc def$`
3. Create file `abc def` (say, `Hello World!`)
4. Sign

**Actual Results:**
`optional_files` entry in `content.json` is empty.

**Expected Results:**
`optional_files` entry in `content.json` contains `abc def` file. i have a similar bug. I can limit file extensions. ok. fine. but I want to limit zite size by keeping larger content (jpegs. gifs) which otherwise load and exclude by filename or folder. This doesnt seem to be working. also, we need to deal with spaces in filenames. Its a utf issue but---lfn has been around for awhile now. > exclude by filename or folder

It's just a [Regular Expression](https://en.wikipedia.org/wiki/Regular_Expression). To exclude files by extension `.mp4`:
```json
{
    "optional": "(.*\\.mp4)"
}
```
To exclude files in a folder `updater/`:
```json
{
    "optional": "(updater/.*)"
}
```
To exclude files by a filename pattern `optional_`:
```json
{
    "optional": "(optional_.*)"
}
``` @MuxZeroNet, [I know Regular Expressions](https://xkcd.com/208/). But even with regex `optional/.*` `optional_files` is empty. @HelloZeroNet, That's the problem itself. I meant that:

> even with regex optional/.* optional_files is empty

...when the only file name in `optional/` contains whitespace.

This issue is connected to file-containing-whitespace caching, not file caching in general.  Hi there,
I would like to customise a bit the startup of ZeroNet, mainly by passing Tor to the Browser ports and setting it to open on Tor, etc.
I can do this easily on the CLI from source with the parameters, this doesn't seem to be so easy with the GUI though. I was wondering if the `zeronet.conf` file on the data dir could take this kind of parameters and options? Would be cool to have the same level of customisation.

Thanks,
tiferrei Yes, it can.
```ini
[global]
tor_controller = 127.0.0.1:9151
tor_proxy = 127.0.0.1:9150
``` Does it support pretty much all the script arguments then? Are there any extra ones, any documentation?  I think it should be optional. Whonix developers plan to put ZeroNet into their privacy-respecting operating system. They are working on a set of Tor control port firewall rules. The current rule for ZeroNet is to allow a listening port 15441. If FileServer port is to be randomized, we should discuss this issue with @adrelanos

Nevertheless, this is not how Internet censorship works. Changing the FileServer port will not in any sense disguise the fact that you are using ZeroNet. I believe even the worst firewall software you currently know of examines packet payload, looking for static strings. More advanced Deep Packet Inspection techniques look for statistical features such as packet length, timing patterns and netflow directions. You should read @blanu's [Dust paper](http://www.blanu.net/Dust.pdf) to learn more about these packet inspection techniques already deployed.

ZeroNet network protocol is not a Pluggable Transport protocol. The protocol itself is not yet "blocking resistant," as Wiley puts. Without Tor, ZeroNet does not make you anonymous, either. There are a lot of research and programming to be done. I believe Tamas does not have the funding or resources to implement Pluggable Transports or to make ZeroNet protocol indistinguishable. The community do not ignore this issue, but for the time being, the community always recommend you use Tor Always mode. We can also cope up with a random port, but it's not pretty.

Specifically if there is an option to set this port on command line / by
config, ZeroNet can still work in Whonix.

Why use a random port, if it provides no benefit?
  fixed the missing import error  If I try to run the current zeronet version in a VM with Ubuntu v16.10 I get this error:

```
python zeronet.py --ui_ip "*" --ui_password ****deleted****
- Starting ZeroNet...
[10:50:33] - OpenSSL loaded, version: 01000207F
[10:50:33] - Version: 0.5.5 r2089, Python 2.7.12+ (default, Sep 17 2016, 12:08:02)
[GCC 6.2.0 20160914], Gevent: 1.1.1
[10:50:33] - Creating FileServer....
[10:50:33] TorManager Connecting to Tor Controller 127.0.0.1:9051
[10:50:33] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 165 > _socket2.py line 228
[10:50:33] TorManager Starting self-bundled Tor, due to Tor proxy port 127.0.0.1:9050 check error: No connection
[10:50:33] - Creating UiServer....
[10:50:33] - Removing old SSL certs...
[10:50:33] - Starting servers....
[10:50:33] Ui.UiServer --------------------------------------
[10:50:33] Ui.UiServer Web interface: http://*:43110/
[10:50:33] Ui.UiServer --------------------------------------
[10:50:35] FileServer Checking port 15441 using portchecker.co...
[10:50:36] FileServer [BAD :(] Port closed: Port 15441 is closed.
[10:50:36] FileServer Trying to open port using UpnpPunch...
[10:50:36] - Unhandled exception
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/gevent/greenlet.py", line 534, in run
    result = self._run(*self.args, **self.kwargs)
  File "/home/zero/zeronet/src/File/FileServer.py", line 193, in checkSites
    self.openport()
  File "/home/zero/zeronet/src/File/FileServer.py", line 74, in openport
    UpnpPunch.ask_to_open_port(self.port, 'ZeroNet', retries=3, protos=["TCP"])
  File "/home/zero/zeronet/src/util/UpnpPunch.py", line 325, in ask_to_open_port
    protos=protos)
  File "/home/zero/zeronet/src/util/UpnpPunch.py", line 304, in _communicate_with_igd
    _orchestrate_soap_request(local_ip, port, fn, desc, protos)
  File "/home/zero/zeronet/src/util/UpnpPunch.py", line 279, in _orchestrate_soap_request
    idg_data = _collect_idg_data(ip)
  File "/home/zero/zeronet/src/util/UpnpPunch.py", line 263, in _collect_idg_data
    _retrieve_igd_profile(idg_data['location']))
  File "/home/zero/zeronet/src/util/UpnpPunch.py", line 86, in _retrieve_igd_profile
    return urllib2.urlopen(url.geturl(), timeout=5).read().decode('utf-8')
  File "/usr/lib/python2.7/urllib2.py", line 154, in urlopen
    return opener.open(url, data, timeout)
  File "/usr/lib/python2.7/urllib2.py", line 435, in open
    response = meth(req, response)
  File "/usr/lib/python2.7/urllib2.py", line 548, in http_response
    'http', request, response, code, msg, hdrs)
  File "/usr/lib/python2.7/urllib2.py", line 473, in error
    return self._call_chain(*args)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 556, in http_error_default
    raise HTTPError(req.get_full_url(), code, msg, hdrs, fp)
HTTPError: HTTP Error 404: Not Found
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/gevent/greenlet.py", line 534, in run
    result = self._run(*self.args, **self.kwargs)
  File "/home/zero/zeronet/src/File/FileServer.py", line 193, in checkSites
    self.openport()
  File "/home/zero/zeronet/src/File/FileServer.py", line 74, in openport
    UpnpPunch.ask_to_open_port(self.port, 'ZeroNet', retries=3, protos=["TCP"])
  File "/home/zero/zeronet/src/util/UpnpPunch.py", line 325, in ask_to_open_port
    protos=protos)
  File "/home/zero/zeronet/src/util/UpnpPunch.py", line 304, in _communicate_with_igd
    _orchestrate_soap_request(local_ip, port, fn, desc, protos)
  File "/home/zero/zeronet/src/util/UpnpPunch.py", line 279, in _orchestrate_soap_request
    idg_data = _collect_idg_data(ip)
  File "/home/zero/zeronet/src/util/UpnpPunch.py", line 263, in _collect_idg_data
    _retrieve_igd_profile(idg_data['location']))
  File "/home/zero/zeronet/src/util/UpnpPunch.py", line 86, in _retrieve_igd_profile
    return urllib2.urlopen(url.geturl(), timeout=5).read().decode('utf-8')
  File "/usr/lib/python2.7/urllib2.py", line 154, in urlopen
    return opener.open(url, data, timeout)
  File "/usr/lib/python2.7/urllib2.py", line 435, in open
    response = meth(req, response)
  File "/usr/lib/python2.7/urllib2.py", line 548, in http_response
    'http', request, response, code, msg, hdrs)
  File "/usr/lib/python2.7/urllib2.py", line 473, in error
    return self._call_chain(*args)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 556, in http_error_default
    raise HTTPError(req.get_full_url(), code, msg, hdrs, fp)
urllib2.HTTPError: HTTP Error 404: Not Found
```  This trivial pull request adds installation instructions for the following Linux distributions:

* **[Arch Linux](https://www.archlinux.org),** via the [unofficial `zeronet` package](https://aur.archlinux.org/packages/zeronet) published by the [Arch User Repository (AUR)](https://aur.archlinux.org).
* **[Gentoo Linux](https://www.gentoo.org),** via the [unofficial `zeronet` package](https://github.com/leycec/raiagent/tree/master/net-vpn/zeronet) published by the [raiagent overlay](https://github.com/leycec/raiagent).

Both distributions provide the latest stable ZeroNet release (~~0.5.4~~ 0.5.5) by default and the latest unstable GitHub commit as an optional variant. [Ricers, unite!](https://wiki.installgentoo.com/index.php/Ricing) ðŸš  @HelloZeroNet *Ping!* You're probably busy beyond belief.<sup>_bbb_</sup> Installation instructions are understandably very low-priority, but is there anything further you'd like me to do for this?

I'd be happy to touch this up in any way you like. In any event, thanks for all the decentralized ZeroNet! ðŸ•¸  **_Sweeeeet!_** Penguins everywhere applaud you.  ZeroNet can't open some .tar.gz files on git.mkg20001.bit
Example: http://localhost:43110/git.mkg20001.bit/git/hellozeronet/ZeroNet.tar.gz/ZeroNet/log.html
But the archive file is valid (screenshot below)
![screenshot](https://cloud.githubusercontent.com/assets/7735145/26453702/ee1bdf0a-4164-11e7-9376-9d8dad141737.png)

Log:
```
[16:12:43] Ui.UiServer 127.0.0.1 - - [2017-05-25 16:12:43] "GET /Websocket?wrapper_key=eeeeeeeeeeeeeeeeeeeeeeeeee8e09aeb4f7258e846da692c593ee542d96257c HTTP/1.1" 101 129 90.779358
[16:12:43] Ui.UiServer 127.0.0.1 - - [2017-05-25 16:12:43] "GET http://git.mkg20001.bit/git/hellozeronet/ZeroNet.tar.gz/ZeroNet/log.html HTTP/1.1" 200 3259 0.000991
[16:12:43] Ui.UiServer 127.0.0.1 - - [2017-05-25 16:12:43] "GET http://git.mkg20001.bit/uimedia/all.css?rev=2089 HTTP/1.1" 200 33051 0.001677
[16:12:43] Ui.UiServer Patched /uimedia/all.js (175692 bytes) in 0.007s
[16:12:43] Ui.UiServer 127.0.0.1 - - [2017-05-25 16:12:43] "GET http://git.mkg20001.bit/uimedia/all.js?rev=2089&lang=de HTTP/1.1" 200 176022 0.007410
[16:12:43] Ui.UiServer Error opening archive file: invalid header
[16:12:43] Ui.UiServer 127.0.0.1 - - [2017-05-25 16:12:43] "GET http://git.mkg20001.bit/git/hellozeronet/ZeroNet.tar.gz/ZeroNet/log.html?wrapper_nonce=eeaf6de2a9de03e50a11a9869de854639d11c753a72847820ecc85ce6997e825 HTTP/1.1" 404 1296 0.007621
``` `tar cvfz` on ubuntu 16.10.
Edit:
```
tar (GNU tar) 1.29
gzip 1.6
``` If it matters: I am resetting the timestamp on every file.
https://github.com/mkg20001/mkgs-github-mirror/blob/30311cf0be213ca3cfbc0dccc526d912230fcf0f/host-zeronet.sh#L254
But I think I should change that to 2000-01-01 I've found this  https://groups.google.com/forum/#!topic/mailing.freebsd.current/gmNTaIJ2tEY
Maybe it is related to libarchive and python's tarfile is using an old version of it? Did you fix it?
It started working but I don't know if it was because of the time stamp or another bug  If GFW of the Communist Party of China blocked zeronet client listening port, zeronet still can not work?
  Because port checker site switched to https  @l5h5t7 If `Multiuser` plugin enabled, `users.json` file is not used at all, information about users stored in RAM. If you clone a clean zeronet repository, rename `disabled-Multiuser` to `Multiuser` before the first run, then `users.json` will contain only `{}`. So there is actually nothing to recreate.
@HelloZeroNet Please, correct me if I am wrong, because I think this issue is a misunderstanding and can be closed.  Users just set an optional tag to himself  folder's content.json and they can send all type of files to zites. Is this a bug of zeronet ? If this is not a bug, please close :) I don't think so. But too big optional files will take up too much memory usage, then ZeroNet will be killed. (#903) @l5h5t7 By the way, please repo ZeroTalk's  Chinese translation to Nofish.
Translate `ä¸»è®ºå›` and `ä¸»è«–å£‡` to `English`, These day a lot of Chinese talk on ZeroTalk.  os.path.join(*file_path.split("/")) construction drops leading slash from string thus making absolute path relative. It leads into problems in case if data_dir differs from directory where is zeronet installed.  ![zeronet1](https://cloud.githubusercontent.com/assets/5235877/26319013/85731b54-3f47-11e7-9ef3-26aae43e7185.png)
![zeronet2](https://cloud.githubusercontent.com/assets/5235877/26319011/856df142-3f47-11e7-8acd-43889d24733b.png)
![zeronet3](https://cloud.githubusercontent.com/assets/5235877/26319012/856f1e6e-3f47-11e7-9106-2e8acc53188d.png)
Any page wont startup.
version is 0.5.5-2081 at windows. Yes, I use zeronet.conf to turn off tor.
The message appears regardless of debug mode is on or off. @shortcutme, Could you test #974 which fixes this issue?    Weak password warning I mean if an uncaught exception is thrown in the frame of `start` method, the routine gets terminated, but no traceback is printed.  Some operating systems does really bad in copying/moving a large number of small files. So using file containers (such as a virtual hard disk) can improve the performance when you want to move your data folder into another disk or partition. Archiving won't solve the problem, you need some form of chunking for recent content also if you don't want to kill hard drives with fragmentation.  I have the following conditions:
OS: Arch Linux
Zeronet is installed in `/opt/zeronet/`
Directory with zites is `/var/lib/zeronet/`
My newly created site is in
`/var/lib/zeronet/13KHcN8FvmY9UgZ2DWAc2323f28qE5LZic/`

Config /etc/zeronet.conf:
```
[global]
data_dir = /var/lib/zeronet
log_dir = /var/log/zeronet
```

When I run zeronet with the following command:
`python2 /opt/zeronet/zeronet.py --config_file /etc/zeronet.conf --debug`

and go to my zite in browser, these alerts are popping:
```
/var/lib/zeronet/13KHcN8FvmY9UgZ2DWAc2323f28qE5LZic/js/utils/Class.coffee compile error: File not found: /opt/zeronet/var/lib/zeronet/13KHcN8FvmY9UgZ2DWAc2323f28qE5LZic/js/utils/Class.coffee
/var/lib/zeronet/13KHcN8FvmY9UgZ2DWAc2323f28qE5LZic/js/utils/ZeroFrame.coffee compile error: File not found: /opt/zeronet/var/lib/zeronet/13KHcN8FvmY9UgZ2DWAc2323f28qE5LZic/js/utils/ZeroFrame.coffee
```

in logs I have:

```
[20:48:37] - Running: "/usr/bin/coffee" --no-header -p "var/lib/zeronet/13KHcN8FvmY9UgZ2DWAc2323f28qE5LZic/js/utils/ZeroFrame.coffee" (Done in 0.09s)
[20:48:37] - /var/lib/zeronet/13KHcN8FvmY9UgZ2DWAc2323f28qE5LZic/js/utils/ZeroFrame.coffee Compile error: File not found: /opt/zeronet/var/lib/zeronet/13KHcN8FvmY9UgZ2DWAc2323f28qE5LZic/js/utils/ZeroFrame.coffee
``` Created pull request with bug explanation: https://github.com/HelloZeroNet/ZeroNet/pull/942  

![2017-05-16_175101](https://cloud.githubusercontent.com/assets/17639060/26100529/b77edf16-3a60-11e7-81e2-29684177cbac.png)
 Have you checked out the logs?  here is the logs:
[2017-05-16 17:47:09,516] INFO     FileServer Checking port 15441 using portchecker.co...
[2017-05-16 17:47:11,009] INFO     FileServer [BAD :(] Port closed: Port 15441 is closed.
[2017-05-16 17:47:12,470] INFO     FileServer Trying to open port using UpnpPunch...
[2017-05-16 17:47:12,471] DEBUG    - Trying to open port 15441.
[2017-05-16 17:47:12,473] DEBUG    - Found local ips: ['192.168.0.10', '192.168.88.1', '192.168.244.1']
[2017-05-16 17:47:12,473] DEBUG    - Trying using local ip: 192.168.0.10
[2017-05-16 17:47:12,542] DEBUG    - Sending UPnP request to 192.168.0.1:5000...
[2017-05-16 17:47:12,559] DEBUG    - 200
[2017-05-16 17:47:12,559] INFO     FileServer Checking port 15441 using portchecker.co...
[2017-05-16 17:47:14,036] INFO     FileServer [BAD :(] Port closed: Port 15441 is closed.
[2017-05-16 17:47:14,036] INFO     FileServer Checking port 15441 using canyouseeme.org...
[2017-05-16 17:47:22,756] INFO     FileServer [BAD :(] Port closed: Error: I could not see your service on 36.5.251.32 on port (15441) Reason: Connection timed out
[2017-05-16 17:47:22,759] INFO     FileServer Upnp mapping failed :( Please forward port 15441 on your router to your ipaddress What about firewall? Its possible that the firewall is blocking the port I've tested on CanYouSeeMe.org and got the error:
Error: I could not see your service on 36.5.XXX.XX on port (15441)
Reason: Connection timed out

I guess the problem become my ISP,I'll check it later in diffrent place.
Thank you all. I have the same problem. I tried a lot of ports do not work. Setting the port mapping manually does not work.

zeronet.conf
[global]
#ui_port = 18080
fileserver_port = 8180


fileserver_port 11660  11800  11560  donot work.
website CanYouSeeMe.org  Connection timed out.

This software only when I first opened can see the port OK.  After no matter how to re-download the decompression, restart the router      do not work.

It is my problem .   Even the port of other software can not be mapped.  All tcp port blocked. Eventually found the reason is to upgrade the firewall caused. 
comodo internet security premium Blocking all incoming connections.  And block the connection action, not logged to the log.

Thanks for various troubleshooting methods.

In the window system to exit the program, the router upnp settings have not been cleared. The emule software will do.

If I set zeronet.conf (fileserver_port = 12345 ) No default 15441.  the router upnp settings have been cleared when I quit the program.   
no zeronet.conf file ,  the router upnp settings have not been cleared when quit the program.
 @RockZhou8 @HelloZeroNet @a8l1vy So the issue can be closed? yes, thanks. @HelloZeroNet Please, close.  Please update [CoffeeScript compiler](https://github.com/jashkenas/coffeescript) to v1.12.6  when i try to test the echobot its not responding 
the "echo" dont  echo
i have linux mint
hope it will help 

YAburh7ppfqJhmB', u'1MaiL5gfBM1cyb4a8e3iiL8L5gXmoAJu27']
[13:18:32] Site:1MaiL5..Ju27 Signing data/users/1JkE7hM6oLZAcHF7ikfYAburh7ppfqJhmB/content.json...
[13:18:32] Site:1MaiL5..Ju27 Saving to data/users/1JkE7hM6oLZAcHF7ikfYAburh7ppfqJhmB/content.json...
[13:18:32] Site:1MaiL5..Ju27 File data/users/1JkE7hM6oLZAcHF7ikfYAburh7ppfqJhmB/content.json signed!
[13:18:32] Site:1MaiL5..Ju27 Publishing data/users/1JkE7hM6oLZAcHF7ikfYAburh7ppfqJhmB/content.json to 5/231 peers (connected: 23) diffs: [u'data.json'] (0.86k)...
[13:18:32] Site:1MaiL5..Ju27 [OK] 73.95.136.145:0: Thanks, file data/users/1JkE7hM6oLZAcHF7ikfYAburh7ppfqJhmB/content.json updated! 1/5
[13:18:32] Site:1MaiL5..Ju27 [OK] 138.197.204.60:15441: Thanks, file data/users/1JkE7hM6oLZAcHF7ikfYAburh7ppfqJhmB/content.json updated! 2/5
[13:18:32] Site:1MaiL5..Ju27 [OK] 218.76.54.20:0: Thanks, file data/users/1JkE7hM6oLZAcHF7ikfYAburh7ppfqJhmB/content.json updated! 3/5
[13:18:32] Site:1MaiL5..Ju27 [OK] 95.82.254.183:15441: Thanks, file data/users/1JkE7hM6oLZAcHF7ikfYAburh7ppfqJhmB/content.json updated! 4/5
[13:18:32] Site:1MaiL5..Ju27 [OK] 108.2.204.126:15441: Thanks, file data/users/1JkE7hM6oLZAcHF7ikfYAburh7ppfqJhmB/content.json updated! 5/5
[13:18:32] Site:1MaiL5..Ju27 Successfuly data/users/1JkE7hM6oLZAcHF7ikfYAburh7ppfqJhmB/content.json published to 5 peers, publishing to 5 more peers in the background
[13:18:33] Site:1MaiL5..Ju27 [OK] 176.9.137.49:15441: File not changed 6/10
[13:18:33] Site:1MaiL5..Ju27 [OK] 35.185.45.197:15441: Thanks, file data/users/1JkE7hM6oLZAcHF7ikfYAburh7ppfqJhmB/content.json updated! 7/5
[13:18:33] Site:1MaiL5..Ju27 [OK] 46.29.2.109:0: Thanks, file data/users/1JkE7hM6oLZAcHF7ikfYAburh7ppfqJhmB/content.json updated! 8/5
[13:18:33] Site:1MaiL5..Ju27 [OK] 106.89.165.209:15441: Thanks, file data/users/1JkE7hM6oLZAcHF7ikfYAburh7ppfqJhmB/content.json updated! 9/10
[13:18:33] Site:1MaiL5..Ju27 [OK] 24.229.162.230:15441: File not changed 10/10
[13:18:33] Site:1MaiL5..Ju27 [OK] 37.187.129.166:0: Thanks, file data/users/1JkE7hM6oLZAcHF7ikfYAburh7ppfqJhmB/content.json updated! 11/10
[13:18:38] Site:1MaiL5..Ju27 [FAILED] 112.2.254.78:0: None
[13:18:38] Site:1MaiL5..Ju27 [FAILED] 185.38.14.215:0: None
[13:18:46] FileServer Update for 1Gfey7wVXXg1rxk751TBTxLJwhddDNfcdp/content.json looks valid, saving...
[13:18:46] Site:1Gfey7..fcdp Publishing content.json to 2/264 peers (connected: 38) diffs: ['messages.json'] (0.28k)...
[13:18:47] Site:1Gfey7..fcdp [OK] 138.197.204.60:15441: File not changed 1/2
[13:18:47] Site:1Gfey7..fcdp [OK] 83.162.192.96:15441: File not changed 2/2
[13:18:47] Site:1Gfey7..fcdp Successfuly content.json published to 2 peers, publishing to 2 more peers in the background
[13:18:47] Site:1Gfey7..fcdp [OK] 101.229.166.67:15441: Thanks, file content.json updated! 3/2
[13:18:47] Site:1Gfey7..fcdp [OK] 109.26.223.12:0: Thanks, file content.json updated! 4/4
[13:18:47] Site:1Gfey7..fcdp [OK] 113.205.42.125:15441: Thanks, file content.json updated! 5/4
[13:19:36] FileServer Update for 1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz/content.json looks valid, saving...
[13:19:36] Site:1iD5ZQ..duGz Publishing content.json to 2/271 peers (connected: 34) diffs: ['data/users.json'] (0.21k)...
[13:19:36] Site:1iD5ZQ..duGz [OK] 83.162.192.96:15441: File not changed 1/2
[13:19:36] Site:1iD5ZQ..duGz [OK] 212.24.103.49:15441: File not changed 2/2
[13:19:36] Site:1iD5ZQ..duGz Successfuly content.json published to 2 peers, publishing to 2 more peers in the background
[13:19:36] Site:1iD5ZQ..duGz [OK] 45.62.111.17:0: File not changed 3/4
[13:19:36] Site:1iD5ZQ..duGz [OK] 108.2.204.126:15441: File not changed 4/4
[13:19:42] Site:1iD5ZQ..duGz [OK] 185.38.14.215:0: File update queued 5/4
[13:19:43] Site:1iD5ZQ..duGz [FAILED] 219.143.130.147:15441: {'exception': 'Timeout'}

 Its for the zeromail  ok thx  
i have anther Q
how can i fix the tor error 111
 I believe it says "Connection Refused" #248
```
TorManager Tor controller connect error: [Errno 111] Connection refused
```

Please run this in terminal to check if Tor is running.
```
sudo netstat -lpna | grep '/tor'
``` its not respond  where can i find this file from my mobile device?  ok, I just want to preface this by saying it's one of those awful errors that seem to be OS dependent, and exactly how it manifests itself is seemingly random.
the error is that for some zites (a steadily climbing amount) I can't sync/update all files, I looked through the debug log and found that this error seems to be related and affect a large number of files ( or the same ones many times)
`[2017-05-04 17:21:04,513] ERROR    Site:1MeFqF..q7nH Json merged-ZeroMe/12h51ug6CcntU2aiBjhP8Ns2e5VypbWWtv/data/users/1BR2d8kCqCBaFWLQ9KXnNbJzLmcPJ3DdTL/data.json load error: OperationalError: attempt to write a readonly database in SiteStorage.py line 234 > MutePlugin.py line 100 > SiteStorage.py line 74 > Db.py line 323 > DbCursor.py line 49`

attached is my entire debug log, hope to have this resolved soon.

[debuglog.txt](https://github.com/HelloZeroNet/ZeroNet/files/977387/debuglog.txt)
 that should be impossible since zeronet is the only thing that accesses that folder,
unless some absolute asshat made a daemon that indexes all my files and changes their permissions.
I'll look into whether I can get an audit log as to what might be happening, but I'm not sure if I can at that level.

edit: I noticed earlier that using chown helps a bit, is it possible that zeronet writes as the wrong user ?
edit 2: I should note that this problem affects a random selection of files (based on observation)
edit 3: it looks like audit logs will have to wait for next week, since I'll have to change kernels. @ivesen Have you resolved the issue? no, the issue is still unresolved.
I've done a few attempts at finding out why it happens, so far the only thing I found is that zeronet sometimes attempts to open too many files at once. I somewhat doubt that's related however.

edit: I've seen multiple reports of the same issue across zeronet after reporting this issue, it appears to affect windows and linux. (uncertain about osx)   Any way to do that? Thanks > If anyone could tell me how to increase the global site size limit from 10mb, would be helpful. Thanks. I'm hosting a proxy and was wondering if there's a way to increase the global limit for sites from the default 10MB to say 50MB  "avalible"= should read "New version available":
![snap 2017-04-30 at 15 49 28](https://cloud.githubusercontent.com/assets/20817185/25564876/bb2ae91c-2dbc-11e7-8be7-b451c21752dc.png)
 https://github.com/HelloZeroNet/ZeroHello/blob/901abf0ec4b9254752a03fe97a1e80619f820a93/js/Head.coffee#L7  Server error

Err: IOError: [Errno 2] No such file or directory: 'src/Ui/template/wrapper.html' in UiServer.py line 83 > UiRequest.py line 83 > UiRequest.py line 229 > UiRequest.py line 314 > UiRequest.py line 179

Please report it if you think this an error.

Details:

{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate, sdch, br", 
    "HTTP_ACCEPT_LANGUAGE": "zh,en-US;q=0.8,en;q=0.6", 
    "HTTP_CONNECTION": "keep-alive", 
    "HTTP_DNT": "1", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36", 
    "PATH_INFO": "/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
    "QUERY_STRING": "", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "56693", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "1.0.0.127.in-addr.arpa", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.2 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bind": null, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": null, 
        "config_file": "/Users/tongxiaofeng/Library/Application Support/ZeroNet/zeronet.conf", 
        "connected_limit": 8, 
        "data_dir": "/Users/tongxiaofeng/Library/Application Support/ZeroNet/data", 
        "db_mode": "speed", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "fix_float_decimals": false, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "ip_local": [
            "127.0.0.1"
        ], 
        "keep_ssl_cert": false, 
        "language": "en", 
        "log_dir": "/Users/tongxiaofeng/Library/Application Support/ZeroNet/log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": true, 
        "open_browser": null, 
        "optional_limit": "10%", 
        "proxy": null, 
        "size_limit": 10, 
        "stack_size": null, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_hs_limit": 10, 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.opentrackr.org:1337/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "updatesite": "1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp", 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false, 
        "workers": 5
    }, 
    "plugins": [
        "AnnounceZero", 
        "CryptMessage", 
        "FilePack", 
        "MergerSite", 
        "Mute", 
        "Newsfeed", 
        "OptionalManager", 
        "PeerDb", 
        "Sidebar", 
        "Stats", 
        "TranslateSite", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.2.1", 
    "version_python": "2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 12:39:47) \n[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)]", 
    "version_zeronet": "0.5.4 r2054", 
    "wsgi.url_scheme": "http"
} This issue seems exclusive to Chinese users. Do you have government-sponsored anti-virus software installed? I'm using Mac and has no AV installed.

On Mon, May 1, 2017 at 4:58 AM, MuxZeroNet <notifications@github.com> wrote:

> This issue seems exclusive to Chinese users. Do you have
> government-sponsored anti-virus software installed?
>
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/HelloZeroNet/ZeroNet/issues/920#issuecomment-298260030>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ALSPQU9-z4CCBd_KGrGjwS5APd5vBKbqks5r1QQHgaJpZM4NMkd0>
> .
>
 @tongxiaofeng Did @HelloZeroNet's solution solve your problem? @mkg20001 Yes. Now I can use ZeroNet on my mac,  I've been meaning to make this issue for a while now.

I haven't done tons of testing, so I might be wrong about some things, but as I wrote in my writeup, I believe ZeroNet is vulnerable to a JavaScript timing attack where webpages (on or off) of ZeroNet can detect what websites and possibly optional files a node is hosting.

This works by sending a request to the ZeroNet interface server and seeing how much time it takes (we can't read the response but it doesn't matter). In my testing, especially for .bit domains, sites already in the node will respond faster.

The same origin policy only prevents reading responses, not preventing them from taking place.

This isn't terribly significant except for people being strictly behind Tor or VPNs, in which case this may leak their identity.

I wrote about this on my blog [here](https://www.chaoswebs.net/blog/timebleed-breaking-privacy-with-a-simple-timing-attack.html) and a proof of concept is [here](https://www.chaoswebs.net/timebleed/)

:+1: @HelloZeroNet, any thoughts?  Is it possible to make `wrapperReplaceState` change only hash and not reload the entire page?
Example:
```javascript
page.cmd("wrapperReplaceState", [null, "", "#abc"]);
```
This command changes URL to `http://127.0.0.1:43110/.../?#abc`. Notice that `?`. That's why the page reloads. I want to get `http://127.0.0.1:43110/.../#abc`.  Yann [announced](https://github.com/yann2192/pyelliptic/issues/50#issuecomment-297018932) that PyElliptic is officially **deprecated**.

Please consider using another wrapper or crypto library, such as [pyOpenSSL](https://pypi.python.org/pypi/pyOpenSSL), [cryptography](https://cryptography.io/en/latest/), [PyNaCl](https://pynacl.readthedocs.io/) or [pySodium](https://github.com/stef/pysodium). Here is a crypto library choice discussion among Ethereum devlopers: ethereum/pydevp2p#58

[pyOpenSSL](https://pypi.python.org/pypi/pyOpenSSL) - a OpenSSL wrapper library

[cryptography](https://cryptography.io/en/latest/) - the famous, actively maintained Python cryptography library. If used, it needs to be included in `requirements.txt`

[PyNaCl](https://pynacl.readthedocs.io/) and [pySodium](https://github.com/stef/pysodium) are both wrappers for libsodium. PyNaCl is mentioned and recommended in cryptography's documentation. The libsodium provides Curve25519 for public key encryption, Salsa20 + Poly1305 for secret key encryption, and Ed25519 for digital signatures. [https://github.com/pyca/cryptography](https://github.com/pyca/cryptography)'s `pip install cryptography` only requires compilation on linux. Binary distributions are available for Windows and macOS. On the Privacy mailing list, Peter Surda wrote:

> Hello and thank you for the info.
> 
> The PyElliptic code that's in PyBitmessage is a modified version of PyElliptic (i.e. a fork). I'm not aware of any issues with it, those that existed were fixed (e.g. OpenSSL 1.1 support, library locator, using a different hash algorithm). I tested it on a broad range of operating systems.
> 
> I'll keep it for the time being as it is.
> 
> Peter Surda  
> Bitmessage core developer

Bitmessage developer did fork PyElliptic and fix a few bugs, but for the long term it is worth making ZeroNet work with pyca/cryptography.  See #914  While I like the idea of pushing the hash to the inner frame I think it shouldn't be in the template for the wrapper, but instead somewhere in the [javascript portion of the logic for the wrapper](https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/media/Wrapper.coffee#L372-L380):
```javascript
# Iframe loaded
	onLoad: (e) =>
		@inner_loaded = true
		if not @inner_ready then @sendInner {"cmd": "wrapperReady"} # Inner frame loaded before wrapper
		#if not @site_error then @loading.hideScreen() # Hide loading screen
                //# ***NOTE***
                // somewhere in here the hash should be pushed to the inner_frame
                //***
		if @ws.ws.readyState == 1 and not @site_info # Ws opened
			@reloadSiteInfo()
		else if @site_info and @site_info.content?.title?
			window.document.title = @site_info.content.title+" - ZeroNet"
			@log "Setting title to", window.document.title
```
This would keep the logic in the same file as [this](https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/media/Wrapper.coffee#L29-L33) (which handles hash changes):
```javascript
window.onhashchange = (e) => # On hash change
			@log "Hashchange", window.location.hash
			if window.location.hash
				src = $("#inner-iframe").attr("src").replace(/#.*/, "")+window.location.hash
				$("#inner-iframe").attr("src", src)
```
 @HelloZeroNet: @mishfit:
BTW, sometimes the inner iframe reloades on hashchange. What about changing:
```javascript
src = $("#inner-iframe").attr("src").replace(/#.*/, "")+window.location.hash
$("#inner-iframe").attr("src", src)
```
to:
```javascript
$("#inner-iframe").attr("src", window.location.hash)
```

Is there any reason why ```src``` is changed instead of hash? Well, I think, that's my fault. I didn't know that `wrapperInnerLoaded` is a valid command itself. For me, [ZeroFrame API Reference on readthedocs.io](https://zeronet.readthedocs.io/en/latest/site_development/zeroframe_api_reference/) was the best reference, but `wrapperInnerLoaded` section appeared *after* I found this issue.   Do you mean the menu inside your site:
<img width="538" alt="zeronet-peers" src="https://cloud.githubusercontent.com/assets/817064/25292167/413aa024-2692-11e7-8cf8-6b163a5fb859.png">

Or the menu inside [ZeroHello](https://github.com/HelloZeroNet/ZeroHello/)?
<img width="354" alt="zerohello-peers" src="https://cloud.githubusercontent.com/assets/817064/25292189/57990270-2692-11e7-928b-4326d86d6a5d.png">

That will help determine whether this is a ZeroNet Sidebar plugin issue or a ZeroHello site issue ZeroNet Sidebar issue.
In my new site I see one more number, in sidebar is less. I think the sidebar isn't counting the user as a peer. That seems like a good thing to me...you aren't a peer, you are the current instance.

@shortcutme can weigh in, but if you are correctly listed on the globe and the number of real peers is correct, then it probably shouldn't include you.

I also see what looks like an explicit exclusion of "self" (loopback or "127.0.0.1") as a peer in [SiteManager.py](https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Site/SiteManager.py#L158)
```python
peer_blacklist = [("127.0.0.1", config.fileserver_port)]  # Dont add this peers
```  Currently `actionFileQuery` requires a string value for the query (filter) parameter. To run a query without "filtering" an empty string is required.

This PR makes `query` optional. @shortcutme can I get eyes on this? Awesome, hope it's been fun.  It was created (https://github.com/HelloZeroNet/ZeroNet/issues/606) but hasn't been maintained.

I used to watch commits, but since there's been many translation updates it's hard to follow changes that way now. Can changelog be updated and kept up to date?  I want to build a custom ZeroNet version for the OS I'm developing. But ZeroNet at startup opens the ZeroHello tab, a thing I don't want to occur in my OS. Wich line I need to modify in python?  i install the .exe windows from the link in the README.MD.now i want to build windows .exe from source code.but i cannot found  how to do that. very thanks!!  https://www.virustotal.com/en/file/ecfac31233694555c010145d884101f0c655b4114122e5ce8193c62ae5738f1a/analysis/ Ran it against another scanner and confirmed flagged:
https://virusscan.jotti.org/en-US/filescanjob/qlyr19lb53 I submitted a false positive report to ClamAV. So ClamAV accept any report without confirming? They do have an investigation process. But they still think that it's a virus? I haven't had any reply from ClamAV. Perhaps someone / Tamas should contact ClamAV via their mailing list <https://www.clamav.net/contact#ml> to get a formal reply.
 Another reason to convert @HelloZeroNet into an organization. Then register as a developer on Microsoft Store (and Apple Developer and Google Play, etc.). Then work to get ZeroNet entered into the Microsoft Store (will need signing, etc..but Windows/ClamAV will presume its been blessed).  Just to follow up on this, I submitted the Mac version and it is getting flagged heuristically by one scanner:
https://www.virustotal.com/en/file/beac83a1299415a90d58b680c0f466337d527337d9214b96e188fcc8ce733d8f/analysis/1492558599/

Meanwhile the number of scanners flagging on the Windows version only seem to be increasing:
https://www.virustotal.com/en/file/67cae9f608d5e912b9b7e23c457c136f1aeaf989f124241e54b3a5dc2c74f4e0/analysis/1492558790/

This might be a decent resource for attempting to report potential false positives:
https://www.techsupportalert.com/content/how-report-malware-or-false-positives-multiple-antivirus-vendors.htm These are all very minor/unknown anti-virus engines and they all report something different, so it's definitely a false positive, which can't really be fixed on ZeroNet's side.

Also, note that ClamAV, while a commendable initiative, has one of the worst detection rates out there, so I wouldn't trust it much.  Yesterday I updated https://fuckcf.cf/ public proxy, then I found ZeroNet would be killed in short time.
I viewed the usage statistics and found the memory usage was increase in a short time, then ZeroNet was killed. But before that, ZeroNet is rarely be killed(for reduce memory usage, I replaced Apache with Caddy, later fewer times be killed).
So how to limit ZeroNet's memory usage? I don't think that, I have seed ZeroMail for a long time without any problem. I think there are single big files cause this problem.
Are there any ways to limit single big files?
BTW: There is no option to limit user add non-optional big sites, isn't it? Any users can change size limit for site without master's permission. ZeroNet is still killed recently on https://fuckcf.cf/ public proxy.
If anyone request a file which is bigger than free memory from public proxy, ZeroNet will try to download this file then ZeroNet will be killed due to out of memory.
So I think we need a new limit: file size limit.  `ContentManager.py` checks user content.json for "cert_user_id"...however, when I sign a file the cert_user_id is not included in the user content.json. Everything else looks okay:
```json
{
 "address": "1Gyhw9AfTojuc42h6nHmV9QCgroTXG9WRt",
 "files": {
  "user.json": {
   "sha512": "67a27e6e9a1154adc93e24bcdef2a7430983a8b6bb000f14f1860597a0b94977",
   "size": 5082
  }
 },
 "inner_path": "data/users/128WNjzSyM9kEFCCHQJVSEp2y81ojrcKs1/content.json",
 "modified": 1491897904,
 "signs": {
  "128WNjzSyM9kEFCCHQJVSEp2y81ojrcKs1": "HKSwACHjMksJgDwhPP7mOjcHnjJ2oeSzu/kMq+lgCJXZd+HYZRz44ei9BaoIpqhCnqwSgO1hVVfmGwat6wBtlN0="
 }
}
```
^ It's just missing "cert_user_id" You can get to it by loading my development site: http://127.0.0.1:43110/1Gyhw9AfTojuc42h6nHmV9QCgroTXG9WRt

![contrechess-signup-signing-001](https://cloud.githubusercontent.com/assets/817064/24917569/d6e0935e-1e9a-11e7-9752-10859c746c0e.gif)

The section of code that writes the file is located [here](https://github.com/ContreChess/ContreChess/blob/master/src/js/signup/signup.js#L126-L147) but I've pulled out an excerpt:
```javascript
// 2. sign user address, plus cert type, plus user address (again) in base64
    //    using site's user content address private key
    var textToSign = _self.model.get('btcAddress') + '#web/' + _self.model.get('userName'),
        cert = currency
          .btcSignMessage(_self.contentAddress, textToSign)
          .toDER()
          .toString('base64');

    return zeronet.addCertificate(cert, _self.model.get('userName'))
      .then(function () {
        return zeronet.selectCertificate('contrechess.io');
      })
      .then(function (response) {
        // 3. write the model to the file system
        var fileContent = btoa(unescape(encodeURIComponent(JSON.stringify(_self.model.toJSON(), null, '  '))));
        return zeronet.writeFile(filePath, fileContent);
      })
      .then(function (response) {
        return zeronet.publish(filePath);
      })
      .then(function (response) {
        console.log(response);
        // 4. handle errors or process notifications
      });
```
The file it is trying to save is "user.json"...it creates content.json (it's just missing "cert_user_id"). I've looked at "nanasi" (http://127.0.0.1:43110/16KzwuSAjFnivNimSHuRdPrYd1pNPhuHqN) and it appears to create the cert_user_id for that site. Awesome, thanks, I'll play around with that.  When a custom blockchain comes to ZeroNet, will be nice a system where a site owner automatically donates tokens to users that are seeding. Also other seeders can donate to other seeders. Moved to: https://github.com/ZeroNetJS/zeronet-js/issues/47.    What I know about the General SOCKS failure: Tor's SOCKS proxy will throw a General SOCKS failure if you try to connect to a LAN address via the SOCKS proxy. For instance, if you route your UPnP request through Tor's SOCKS proxy, you will get a General SOCKS failure. @HelloZeroNet @MuxZeroNet is this yet a issue? Is you planning to fix a issue that is since 8 Apr without fixes?  How hard is it to make zeronet work as client on iOS/Android?

Is python support on these platforms would be enough? There is an Android client. https://github.com/HelloZeroNet/ZeroNet-kivy
As for iOS, you can jailbreak and install python. The difficulty is that Apple's App Store does not allow apps runs dynamic code. Actually with some changes the current android version _should_ run on iOS
We just need someone with a mac and iPhone who wants to write it @ysc3839 
> The difficulty is that Apple's App Store does not allow apps runs dynamic code

It allows to run dynamic code (for example, javascript & React), it just doesn't allow to update app's code by bypassing App Store updates. @ysc3839 
> As for iOS, you can jailbreak and install python

Can I (technically) run Python inside the app's process without jailbreaking? I think a complete rewrite in Swift/Java would be better.

A couple of things to consider:

1. System-wide TOR support allegedly coming soon to iOS, see [here](https://techstuffer.com/tor-for-ios-tor-is-coming-to-ios-soon/)
2. It should be possible to handle trackers, connections, etc natively
3. It would get you into the App Store or Google Play
4. Mobile clients could be leechers-only.
5. That would help standardize protocols/APIs and open up the possibility of having Java/ObjC/Node/C#/Ruby versions of ZeroNet clients.

If @shortcutme can add the repo to @HelloZeroNet I can start that (or I can create one and we can switch ownership afterwards). @mishfit Great analysis. I agree on all your points. @mishfit Is there any progress? @mishfit @grez911 I'm working on a nodejs/browser version (https://github.com/ZeroNetJS/ZeroNet-JS) @mkg20001 Is it possible to run it on Android/IOS without any additional software except browser? Yes, but later. Currently some core features and the libp2p stuff need to be finished. Then it should be possible through libp2p-webrtc (similar to how it's being done [here](https://github.com/libp2p/js-libp2p/blob/master/examples/libp2p-in-the-browser/1/src/browser-bundle.js))
A demo of what works is already available at https://zeronetjs.github.io/znjs-web-bundle/ (but it only starts for now) Does anybody know if it would be possible to: a) use the codebase for the Android client based on python still i understand..... in iOS but only personally, say without jailbrake but WITH side-loading via say XCode? I can load it onto each phone/tablet by hand, bypassing the app store? Or is this not possible (due to python I'm guessing)...  @tomachinz It seems like the android app [could be built for iOS too](https://github.com/kivy/buildozer#readme) but I have no idea how exactly it works and I couldn't even test it as it requires an iOS device    Some Travis tests require `selenium` so that they can see what's going on inside the HTML page. These tests are skipped because you forget to pre-install `selenium` in the Travis testing box.

https://travis-ci.org/HelloZeroNet/ZeroNet/builds/219820681
```
SKIP [1] /home/travis/build/HelloZeroNet/ZeroNet/src/Test/conftest.py:172:
Test requires selenium + phantomjs: No module named selenium
``` #890  https://docs.travis-ci.com/user/gui-and-headless-browsers/#Using-PhantomJS

Thanks for the timely PR. Travis says PhantomJS is actually pre-installed. The error disappeared. There is another issue here:
```
SKIP [2] /home/travis/build/HelloZeroNet/ZeroNet/src/Test/conftest.py:181: Test requires zeronet client running: [Errno socket error] [Errno 111] Connection refused
```

The UI server wasn't running. #890 (updated) You can just use `docker build -t zeronet .` to build the image in the container When docker does not find an image with `docker run` command, it will automatically build it with `Dockerfile`.
But in the `Dockerfile`, we said: 

```
ADD . /root
```

So we can not currently fetch data from a pull request or specific branch. :confused:  See #894 @AwesomeTurtle This does not matter if building locally @HelloZeroNet Pull request has been successfully merged. Can the issue be closed?  Hi this Show when Click Back 
and this Show more Information
This may be problematic for you

See pic for undrestand this:
http://ibb.co/er8dvk

Zero Security Group Hi, to prevent sandbox escape, you can never get the real content of an html file unless you have a correct wrapper_nonce.

When the user goes to a URL of an HTML file:

The UI server serves a Wrapper Page:
- If ZeroNet thinks it is a valid request, it will return `a page with the wrapper`. A wrapper_nonce is included in that wrapper page.
- To make sure the wrapper_nonce is not given away to malicious scripts, ZeroNet checks for a valid `Accept` header, a valid `Referrer` and some other headers to make sure it is you that actually clicked on the link.
- ZeroNet bans XHR requests from loading the wrapper page by removing all `Access-Control-*` headers. ZeroNet adds other security headers to make sure your browser won't load the content of the wrapper page.

The UI server serves Real HTML Page:
- The JavaScript program in the wrapper page loads the real HTML page into an `<iframe>`.
- When the JavaScript program shows a valid wrapper_nonce to the server, the server returns the real content of the requested HTML page.
- The nonce gets deleted. Yeah, it is a nonce. It can only be used once.

So this explains what happened:
```
  Address bar: http://127.0.0.1:43110/Me.ZeroNetwork.bit/index.html
  
 ------------------------------------------------------------------------------
| Your browser loads the wrapper page to _top.                            (0)  |
|  --------------------------------------------------------------------------  |
| |                                                                          | |
| | This is the inner iframe. Its src is                                     | |
| | http://127.0.0.1:43110/Me.ZeroNetwork.bit/index.html?wrapper_nonce=***** | |
| |                                                                          | |
|  --------------------------------------------------------------------------  |
|                                                                              |
|                                                                              |
```

When you click **Back**
```
  Address bar: http://127.0.0.1:43110/Me.ZeroNetwork.bit/index.html
  
 ------------------------------------------------------------------------------
| Your browser loads the wrapper page to _top.                            (0)  |
|  --------------------------------------------------------------------------  |
| |                                                                          | |
| | This is the inner iframe. Its src contains the old, invalid nonce.       | |
| | http://127.0.0.1:43110/Me.ZeroNetwork.bit/index.html?wrapper_nonce=***** | |
| |                                                                          | |
| | Server: Hey! This is an invalid (used) nonce!                            | |
| | I won't show you the page you requested for.                             | |
| |                                                                          | |
|  --------------------------------------------------------------------------  |
|                                                                              |
|                                                                              |
``` > and this Show more Information

Yes, it displays some debug information. If this is not OK for you,

@HelloZeroNet We should be able to strip console debug information by modifying the MultiUser plugin. The error page on the gateways will then look like this:
```
Server error
Err: Exception: Here is your console in UiServer.py line 83 > ...
Please report it if you think this an error.

Details:
| Well, those details are hidden on this proxy. |
``` @HelloZeroNet I have send you(nofish) a POC in private by zeromail.    It would be nice if zeroupdate zite has a zeronet version on it so it could be easier to see witch version it has now.
Many thanks and sorry if my request is wrong addresed. Thanks a lot!!!   Why was it skipped?
```
src/Test/TestWeb.py::TestWeb::testFileSecurity SKIPPED
src/Test/TestWeb.py::TestWeb::testLinkSecurity SKIPPED
```  how can i get a list of all user certificates? i want to create a certificate for users for this site (IFS - http://127.0.0.1:43110/12MVkvYGcRW6u2NYbpfwVad1oQeyG4s9Er/) but in order to check if a user has already created an ifs.anonymous certificate i need to get a list of the user's certificates.
is it possible in zeronet? if not is there a hack or a way to go around it? If the cert already exists and there's only one valid cert signer for the site then 

`siteInfo.cert_user_id` will not be null when you call the ["siteInfo"](http://zeronet.readthedocs.io/en/latest/site_development/zeroframe_api_reference/#siteinfo) API command.  https://news.ycombinator.com/item?id=14041596
Maybe we should update them and not bundle them directly into git? > Using pip for dependencies would make the portable/exe/.app version really hard

Not really.

[Appveyor](https://www.appveyor.com/) supplies CI for Windows systems, and can automatically bundle you an *.exe at each step, and is free for open source projects.

[Travis CI Enterprise](https://travis-ci.com/plans) supplies both Macs and Linux machines for you to automatically bundle with, and is free for open source projects.

It's a case of writing two files:

* ```.travis.yml```
* ```appveyor.yml```

Then, linking the repository to accounts with Appveyor and Travis.

They'll test your test suite at each commit, and can build your bundles for you.

There's no reason not to use pip.

And if you continue not to use a package manager of any sort, you will continue to run into these issues. Outdated libraries, and insecure libraries.

(On that note, I'm afraid you need to *replace* PyElliptic. It's no longer receiving updates. Maybe use the canonical OpenSSL library for Python: [pyOpenSSL](http://www.pyopenssl.org/en/stable/api.html))  I am developing a multi-user site.
While debugging, I find it's painful to test.

Now, I develop my site on a local machine and test it on a vps.
I write a watch script: Every time there is an update in my site data folder, the script will run ` zeronet.py siteSign myAddress myPrivateKey` and `zeronet.py sitePublish myAddress myVpsIP 15441`. But the problem is that there is a huge latency for sitePublish: When I check if it is updated in remote vps via local browser, I find I have to wait at least 5 min to see updated website.

For details, while publishing, it says `Thanks, file content.json updated! 1/5` in almost no time. But when I check it via browser for the status of the site on vps, I find that it shows `updating 2 left`. I don't know why. And sitePublish could only run for 60s. After that, the site on vps says that `2 file update fail`.

If I download normal files from my vps, it could be more than 1M/s. I am wondering why only `content.js` could be transferred in a few seconds leaving other files update fail. You can open the side menu, turn on "This is my site", and then click "Sign" and "Publish". I know there are missing files listed in the slide bar. As for cache, I think that reloading tab with override cache should not be a problem. 

The main problem I faced is that after I update and sign site, the site could only be served for max 60 secs and in that duration, the files I updated could not be reached by my remote VPS which IP and port are provided in the command.

In other words, only `content.json` has been updated, but the files listed haven't been updated.
 Sorry. I think @HelloZeroNet  is right. Chrome with disable cache works well now. Thank you.  all the following commands return: 

```
- Starting ZeroNet...
- OpenSSL loaded, version: 01000207F

[ it show all the usage ]

start.py: error: too few arguments

```


`./ZeroNet.sh  --trackers ["zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441"]`

`./ZeroNet.sh  --trackers "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441"`

`./ZeroNet.sh  --trackers zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441`

`./ZeroNet.sh  --trackers {["zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441"]}`

it seem to be specific to  `--trackers` as `--proxy` return no error.  isn't it a bug ? 

Posix standard make no mention of either it should sucess or fail, but It never append to me on linux before. 
http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap12.html

Im not python dev but `optparse` seem depricated tho, Maybe the new lib could fix it ?  
https://docs.python.org/2/library/argparse.html#nargs

As IDK python it's the most I can help :s

(your workaround fixed my problem tho)  I am having an issue with turning tor while using tor browser. While I am in zeronet the status for tor it say it waiting but I can't do anything  How to use ZeroNet with Tor Browser: https://zeronet.readthedocs.io/en/latest/faq/#how-to-make-tor-work-if-my-isp-or-goverment-blocks-it

```
zeronet.py --tor always --tor_proxy 127.0.0.1:9150 --tor_controller 127.0.0.1:9151
```

or 
```
zeronet.py --tor disable --proxy 127.0.0.1:9150 --disable_udp
```

 i am using macos  @zohdi11 Have you tried starting ZeroNet with the parameters I mentioned above? I am very sorry but I haven't done that yet. I will try to fix it then I will tell you what happened 

again i am very sorry  i Have tried everything you told me to do but it not working what can i do    @HelloZeroNet 
How the system protects to a user not use the same username as the existing other? This provider is served by all users? Its not much huge to download?  [14:18:49] - OpenSSL load failed: [Error 126] , falling back to slow bitcoin verify
[14:18:49] - Patching sockets to tor socks proxy: 127.0.0.1:9050
[14:18:49] - Version: 0.5.3 r2003, Python 2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 20:53:40) [MSC v.1500 64 bit (AMD64)], Gevent: 1.2.1

>pip list
DEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.
asn1crypto (0.22.0)
cffi (1.10.0)
cryptography (1.8.1)
enum34 (1.1.6)
gevent (1.2.1)
greenlet (0.4.12)
idna (2.5)
ipaddress (1.0.18)
msgpack-python (0.4.8)
packaging (16.8)
pip (9.0.1)
pycparser (2.17)
pyOpenSSL (16.2.0)
pyparsing (2.2.0)
pyzmq (16.0.2)
setuptools (28.8.0)
six (1.10.0)

Python 2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 20:53:40) [MSC v.1500 64 bit (AMD64)] on win32
Type "help", "copyright", "credits" or "license" for more information.
>>> import ssl
>>> print ssl.OPENSSL_VERSION
OpenSSL 1.0.2j  26 Sep 2016

debug.log
[2017-03-25 19:25:21,131] DEBUG    - Disable SSL compression failed: [Error 126]  (normal on Windows)
[2017-03-25 19:25:21,131] DEBUG    - Missing SSLwrap, readded.
[2017-03-25 19:25:21,131] DEBUG    - Python SSL version: OpenSSL 1.0.2j  26 Sep 2016 Windows error 126 means the DLL not found. @saber28 does using 64bit openssl dlls have solved your problem ?   No answer.
@HelloZeroNet Please, close.   Changed this assignment to have the "signers" field in root's content.json as a list and not as a dictionary to mantain uniformity with "includes" "signers" field and for not having a dict with empty values. @HelloZeroNet any update on this issue? Is it correct what i've done or i've misunderstood the assignement? Thank you, i've seen this issue because if you try to add  multiple addresses to the signers filed it lets you sign the root content.json with different addresses. @shortcutme Any news on this? @HelloZeroNet So could you commit this? @HelloZeroNet  done  [10:57:13] Site:18Xzgf..r8PA File content.json signed!
[10:57:13] Site:18Xzgf..r8PA Publishing content.json to 5/0 peers (connected: 0)
 diffs: [u'data/data.json'] (0.16k)...
[10:57:13] - Unhandled exception
Traceback (most recent call last):
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\greenlet.py", line 593, in
 _notify_links
    link(self)
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\greenlet.py", line 45, in
__call__
    g.switch(source)
  File "D:\ZeroBundle\ZeroNet\src\Ui\UiWebsocket.py", line 380, in <lambda>
    thread.link(lambda thread: self.cbSitePublish(to, self.site, thread, notific
ation, callback=notification))
  File "D:\ZeroBundle\ZeroNet\src\Ui\UiWebsocket.py", line 427, in cbSitePublish

    {_[on your router to make your site accessible for everyone.]}""").format(co
nfig.fileserver_port)
  File "D:\ZeroBundle\ZeroNet\src\Translate\Translate.py", line 63, in __call__
    return self.format(s, kwargs, nested=nested)
  File "D:\ZeroBundle\ZeroNet\src\Translate\Translate.py", line 52, in format
    return s.format(**kwargs)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-19: ordi
nal not in range(128)
Traceback (most recent call last):
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\greenlet.py", line 593, in
 _notify_links
    link(self)
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\greenlet.py", line 45, in
__call__
    g.switch(source)
  File "D:\ZeroBundle\ZeroNet\src\Ui\UiWebsocket.py", line 380, in <lambda>
    thread.link(lambda thread: self.cbSitePublish(to, self.site, thread, notific
ation, callback=notification))
  File "D:\ZeroBundle\ZeroNet\src\Ui\UiWebsocket.py", line 427, in cbSitePublish

    {_[on your router to make your site accessible for everyone.]}""").format(co
nfig.fileserver_port)
  File "D:\ZeroBundle\ZeroNet\src\Translate\Translate.py", line 63, in __call__
    return self.format(s, kwargs, nested=nested)
  File "D:\ZeroBundle\ZeroNet\src\Translate\Translate.py", line 52, in format
    return s.format(**kwargs)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-19: ordi
nal not in range(128)
[10:57:53] Site:18Xzgf..r8PA Publishing content.json to 5/0 peers (connected: 0)
 diffs: [] (0.00k)...
[10:57:53] - Unhandled exception
Traceback (most recent call last):
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\greenlet.py", line 593, in
 _notify_links
    link(self)
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\greenlet.py", line 45, in
__call__
    g.switch(source)
  File "D:\ZeroBundle\ZeroNet\src\Ui\UiWebsocket.py", line 388, in <lambda>
    thread.link(lambda thread: self.cbSitePublish(to, self.site, thread, notific
ation, callback=False))
  File "D:\ZeroBundle\ZeroNet\src\Ui\UiWebsocket.py", line 427, in cbSitePublish

    {_[on your router to make your site accessible for everyone.]}""").format(co
nfig.fileserver_port)
  File "D:\ZeroBundle\ZeroNet\src\Translate\Translate.py", line 63, in __call__
    return self.format(s, kwargs, nested=nested)
  File "D:\ZeroBundle\ZeroNet\src\Translate\Translate.py", line 52, in format
    return s.format(**kwargs)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-19: ordi
nal not in range(128)
Traceback (most recent call last):
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\greenlet.py", line 593, in
 _notify_links
    link(self)
  File "D:\ZeroBundle\Python\lib\site-packages\gevent\greenlet.py", line 45, in
__call__
    g.switch(source)
  File "D:\ZeroBundle\ZeroNet\src\Ui\UiWebsocket.py", line 388, in <lambda>
    thread.link(lambda thread: self.cbSitePublish(to, self.site, thread, notific
ation, callback=False))
  File "D:\ZeroBundle\ZeroNet\src\Ui\UiWebsocket.py", line 427, in cbSitePublish

    {_[on your router to make your site accessible for everyone.]}""").format(co
nfig.fileserver_port)
  File "D:\ZeroBundle\ZeroNet\src\Translate\Translate.py", line 63, in __call__
    return self.format(s, kwargs, nested=nested)
  File "D:\ZeroBundle\ZeroNet\src\Translate\Translate.py", line 52, in format
    return s.format(**kwargs)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-19: ordi
nal not in range(128)
  There is currently no way to update a zite you cloned.  
Most of the users that want to have a zeroblog will just go to the ZeroHello zites list and click "clone". But when ZeroBlog will be updated with a new feature, the cloned zite will not be. It can be by looking at te files and replacing them by the new ones, but a very few part of the users will be able to do that.

Here is a proposition to fix it:
Add the following entry in the `content.json` file of the cloneable zite:
```json
"repository": "https://github.com/HelloZeroNet/ZeroBlog"
```
Regularly (let's say once a day), zeronet will check for all the updates, and the cloned zite admin will have a notification on its ZeroHello page, asking him if he want to update its zite. It can also set it to be updated automatically without asking for anything.

Yes, there are a few drawbacks with this method:
- Git will be mandantory for running the project
- It relies on external http content We can also juste reference the parent repository with this kind of entry:
```json
"cloned_from": "1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8"
```
Using that, we can only copy the updated `all.js` and `all.css` files (and other resources like images) to the cloned zite. It fix the two drawbacks I described above, but it create new ones. For example, the parent zite have to be updated first, and if a zite is of a clone of a clone (and so on) of a zite, it may takes a lot of time to update. Oh I didn't noticed those two fields. Is it planned to be implemented soon or is it abandoned ? @Emeraude @HelloZeroNet Is this the same issue as https://github.com/HelloZeroNet/ZeroNet/issues/374 and can be closed?  Hey guys,

please check your grammar on the website, I have found 2 wrong words
"Seiten Antworzeit ist nicht begrentzt durch *deien* Verbindungs-Geschwindigkeit."
"Es ist *niergendwo*, weil es Ã¼berall ist!"

How someone can take that serious, if there such big spelling mistakes, about grammar I dont will discuss. @HelloZeroNet its not hard at all, but someone has made the german translation, and its really bother me, because Im speaking german ;) 
here are the corrected senctences 
"Die Seiten Antwortzeit ist nicht begrenzt durch deine Internetverbindung."
"Es ist nirgendwo, weil es Ã¼berall ist!"

Nice greets

  Get the following error:

WebSocket handleRequest error: UnboundLocalError: local variable 's' referenced before assignment in UiWebsocket.py line 105 > UiWebsocket.py line 212 > UiWebsocket.py line 549

In the actionDbQuery function in UiWebsocket.py, the variable s which is keeping track of execution time is only defined when the debug flag is specified but is used with the verbose flag and thus has not been initialized.  I recently install the new Linux cinnamon 18.1 and I downloaded your ZeroNet bundle but I seem to be having problems with it. After I downloaded the bundle I clicked on ZeroNet.sh to set up ZeroNet and it loaded the ZeroNet site for the first time like it was supposed to. Well the next day I clicked on zeronet.py to get it running like I did when I had the old version of Linux but for some reason it wont load ZeroNet site. I only get a screen that says unable to connect. I noticed the only way I can get ZeroNet to load now is to always click on ZeronNet.sh every time instead of the zeronet.py like I used to do. I also have my port open. I typed in run zeronet.py in the command terminal and got this
No command 'run' found, did you mean:
 Command 'grun' from package 'grun' (universe)
 Command 'qrun' from package 'torque-client-x11' (universe)
 Command 'qrun' from package 'torque-client' (universe)
 Command 'srun' from package 'slurm-client' (universe)
 Command 'zrun' from package 'moreutils' (universe)
 Command 'runq' from package 'sendmail-bin' (universe)
 Command 'runq' from package 'exim4-daemon-light' (main)
 Command 'runq' from package 'exim4-daemon-heavy' (main)
 Command 'rn' from package 'trn4' (multiverse)
 Command 'rn' from package 'trn' (multiverse)
 Command 'runc' from package 'runc' (universe)
 Command 'rup' from package 'rstat-client' (universe)
run: command not found
I'm still learning about all this Linux so I really don't understand all that stuff. Should I have typed sudo run zernet.py? I typed in python zeronet.py and I got this. python: can't open file 'zeronet.py': [Errno 2] No such file or directory You have to enter `python zeronet.py` from the same directory in which zeronet.py is located. I already tried that as well and it didn't work. When I install ZeroNet on Linux 18.1 I put it in the same location I had it on Linux 17.3 I didn't do anythng differently. Here's where I put ZeroNet ![zeronet1](https://cloud.githubusercontent.com/assets/8492776/23911711/fca23900-08b3-11e7-87a4-e2f0a1123a9e.png) and here's the zeronet.py I'm clicking on.
![zeronet2](https://cloud.githubusercontent.com/assets/8492776/23911800/434987be-08b4-11e7-9ccc-857ca9563aa5.png)

 When I say "the same directory" I mean in the terminal app Is this what your talking about? ![zeronet3](https://cloud.githubusercontent.com/assets/8492776/23914141/728e1c86-08bb-11e7-9519-c5fb1fd4f90e.png)
 Is there a error log file located somewhere that might tell whats wrong? I just disabled four Firefox add-ons and this time the page loaded like it was supposed to. I disabled uBlock Origin, Random Agent Spoofer, Decentraleyes and Privacy Badger.  I don't know if Merger sites is what i need, do they allow to query database of another site from my site? If my site needs to display something from ZeroMail (for example number of messages in inbox). How can i do it?  https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/UiWebsocket.py#L544
```python
    def actionDbQuery(self, to, query, params=None, wait_for=None):
        if config.debug:
            s = time.time()
        rows = []
        try:
            if not query.strip().upper().startswith("SELECT"):
                raise Exception("Only SELECT query supported")
            res = self.site.storage.query(query, params)
        except Exception, err:  # Response the error to client
            self.log.error("DbQuery error: %s" % error) # XXX error XXX ---> err
            return self.response(to, {"error": str(err)})
```  at zeronet i know that's 0.5.3 its at air

but at git i dont find it    Like this: http://ftp.debian.org/debian/
Sometimes we need't a gorgeous page and only to share/browse a structured file system. In this situation, directory listing allow us not create a catalog and browse files easily. @l5h5t7 as of #842 there's a feature in the API to list directories and files (`dirList`) non-recursively. Or you can call `fileList` which will recursively get all the files given a specific path, excluding the directories as it traverses. @l5h5t7 @HelloZeroNet Closing?  Due to the lack of IPv4 address, more and more ISP have been deployed carrier-grade NAT. So less  connectability for these users.
Tor network can improve the connectability for these users, but it has many issues for the users who needn't anonymity:
- Poor performance.
- Bring more pressure for Tor relay bridge.
- Tor is blocked in some country or ISP.

IPv6 is the ultimate solution, but it still have a long way to go. (15% supportive in the whole world, and only 1% supportive in China)

Full-cone NAT is most used in carrier-grade NAT and easy to penetrate.
We need do these thing for support port opening supports below full-cone NAT
- Send port checker a request for external IP and external port.
- Separated port number with internal port number and external port, listen the internal port and report tracker the external port.
- Keep port mapping exist using heartbeat packet.

Separated port number is also useful in the environment: 
- I don't have the manage permissions of router, but I can ask my administrator to open ramdom one.
- Free reverse proxy services such as [ngrok](https://ngrok.com/). Port mapping is up to NAT gateway. The gateway create a random port mapping that has different port number, sometimes we can't control it (Like carrier-grade NAT).
See: https://en.wikipedia.org/wiki/Network_address_translation#Methods_of_translation
Full-cone NAT: If client below NAT send a request to a host which opened a port, the full-cone NAT gateway will assign a port mapping about internal_IP:internal_port(the port which the client send a request) <-> external port(randomly assigned). We can't set a port mapping without administrator permission.
For home router, the methods of translation is usually (address)-restricted-cone NAT. It has more restriction, but we can set a port mapping manually or automation (via UPnP). So I think penetrate carrier-grade NAT and home router and open a port is still feasible. For some gateway, we can open a port by [Port Control Protocol](https://en.wikipedia.org/wiki/Port_Control_Protocol), but it's not all gateway be supported.
A client connect to a port checker, then the port checker can get the external IP and external port of the client with `data, address = socket.recvfrom(bufsize[, flags])`, then the port checker echo back to the client.
Perhaps we can depend [STUN](https://en.wikipedia.org/wiki/STUN).
It's centralized, but I think that add a plugins to make every peers which can open a port is feasible.
But I'm not sure whether it's TCP-compatible. I'm afraid that you did not understand what I meant. Not all NAT gateway allow standard user create a explicit port forward rule, but we can create a implicitly port forward rule using full-cone NAT gateway's feature.
- Once an internal address (iAddr:iPort) is mapped to an external address (eAddr:ePort), any packets from iAddr:iPort are sent through eAddr:ePort.
- Any external host can send packets to iAddr:iPort by sending packets to eAddr:ePort. I agree with @l5h5t7  It need's a lot of work. Maybe better spend this time developing IPv6 support? https://github.com/HelloZeroNet/ZeroNet/issues/148 > It need's a lot of work. Maybe better spend this time developing IPv6 support? #148

Yes and no. Both things are required because I don't think that IPv6 support will be high enough everywhere to solve the issue.  ```python
def actionSiteMedia(self, path, header_length=True):
    # ......

    match = re.match("^(.*\.(?:tar.gz|tar.bz2|zip))/(.*)", file_path)
    archive_path, path_within = match.groups()
    if not os.path.isfile(archive_path):
        site = self.server.site_manager.get(path_parts["address"])
        if not site:
            self.error404(path)
        # Wait until file downloads
        result = site.needFile(site.storage.getInnerPath(archive_path), priority=10)
        # Send virutal file path download finished event to remove loading screen
        site.updateWebsocket(file_done=site.storage.getInnerPath(file_path))

        if not result: # XXX ignores the case in which `archive_path` is a folder XXX
            return self.error404(path)
    try:
        file = openArchive(archive_path, path_within)
``` I created a test case to reproduce this bug:
http://127.0.0.1:43110/1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/bugs/

If you are using an old version of ZeroNet which doesn't support file compression, you are not affected.
https://bit.surf:43110/1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/bugs/ Closed with this [dirty hack](https://github.com/MuxZeroNet/ZeroMux/commit/b694e018b4c4996f868eaf690c49c9ff90969f0d?diff=split#diff-532cf85ec3b656c424293aa6eeeadf9fR106).  also, add SiteStorage.list as non-recursive
directory listing (`os.listdir`)

I've got a use case for listing the contents of a directory (non-recursively) and the nomenclature works better with 'list' (which is what it's actually doing) while the pre-existing 'list' function is actually performing a 'walk'.

I've renamed 'list' to 'walk' (to make more sense) and added 'list' for a single directory. I would ordinarily agree, however the original `list` excludes directories in its resultset whereas the new list includes directories (something I actually want)  On some routers(Like my TL-WR886N), Port forwarding needs two ports: One for access, The other for hosting port.
I need to forward port 15441, should I use 43110(ZeroNet's port) for internal port? In a nutshell:
I want map port 43110 to port 15441.
Am I correct? My ISP:
China Unicom(?)ï¼ˆä¸­å›½è”é€šï¼‰ Should the server use DHCP? @HelloZeroNet Looks like I have a IP mismatch. @HelloZeroNet My router's IP address is 10.93.30.105, I can use this IP to access my internal server.
But IP checkers gives me a different IP: 175.19.44.91
I think that's the problem. http://service.tp-link.com.cn/detail_article_2578.html I think you misunderstand my network layout.
(Can we speak in Chinese?) I set my forward rules but still not working.
@HelloZeroNet @clarkzjw But TL-WR886N is a cloud router, It's upnp is on, But I can't check the status.
See http://service.tp-link.com.cn/detail_article_2936.html You shouldn't use router's port map. Because your ISP give you a ethernet IP. @ysc3839 Ethernet IP? @ysc3839 What should I use? Modem's port map? I mean you don't have a internet IP, so the port map is useless. I don't have a internet IP?
PS: I'm connected to Internet with a router and a modem. The IP that ISP gives you is a private IP, which is not accessible from internet. You connect to ISP's router and that router connect to the internet. 
See more: https://en.wikipedia.org/wiki/Network_address_translation I know.
So should I tweak my modem? There's no use. I'll try to figure it myself, close this for now.
@clarkzjw @ysc3839  But check if it really works:
http://127.0.0.1:43110/16k5CXBJTk79BPhe6yhtEa9hXVzFKcTGox/
@HelloZeroNet @ysc3839 @clarkzjw You can upload your zite without open a port. Just Open it on a public proxy (such as bit.surf:43110) and then publish it. I did and it works.
@ysc3839 ~ Similar to #873 , but it's so bad that we can't have a public IP.  The codepage changer was outputing a short msg, also waiting for the exe, this way it should start it and go away.   Was looking to see if this question was asked (and/or answered) already...all I found was this #458.

How does one support accounts that are unique to the site (not using ZeroID)?  Now Zeronet is single thread for downloading. So the speed of files loading is slow and unstable, espcially ZeroMux.
So if it can download a files from mutil peers at the same time, it will be more stable and faster.  Closes the previous Pull Request #832. I am not able to make it work due to gevent problems.
```
LoopExit: ('This operation would block forever', <Hub at 0x7f001f0c0e10 epoll pending=0 ref=0 fileno=6>)
```

Gevent developer says "This is (almost always) not a problem in gevent." gevent/gevent#933

According to paramiko/paramiko#633, the `socket` module is monkey-patched to use gevent and therefore causes a `LoopExit` error. I patched the socket module by calling `monkey.patch_all()`. Stem finally works but I got the following warning:
```
plugins/StemPort/StemPortPlugin.py:15:
RuntimeWarning: Patching more than once will result in the union of all True parameters being patched
``` http://www.gevent.org/gevent.monkey.html
```
patch_all(socket=True, dns=True, time=True, select=True, thread=True, os=True, 
    ssl=True, httplib=False, subprocess=True, sys=False, aggressive=True, Event=False, 
    builtins=True, signal=True)
```

> Changed in version 1.1: Issue a warning if this function is called **multiple times** with **different arguments**. The second and subsequent calls will only add more patches, they **can never remove** existing patches by setting an argument to False.

I think the problem is, I called `patch_all` with the wrong arguments. @HelloZeroNet What do you think the parameters should be used here in order to be compatible with the other `patch_all` calls in ZeroNet? Now it seems to be working. Stem created hidden services. I got exit node IPs. Site updating and pushing seemed to work well. I got timeout when trying to push sites to onion peers, but it might be a network latency issue. > I got timeout when trying to push sites to onion peers, but it might be a network latency issue.

**Nope.** The fact is `createSocket` method got overridden by mistake.

[Important Update - Don't override createSocket](https://github.com/HelloZeroNet/ZeroNet/pull/834/commits/ad900479f6adede20459d4e4cf6dd881db3d670a) > **All checks have failed**
> 1 failing check

Broken WebSocket connection results in a failure of [Travis CI Tests](https://travis-ci.org/HelloZeroNet/ZeroNet/builds/204786638). Is this related to StemPort plugin?

```
plugins/CryptMessage/Test/TestCrypt.py::TestCrypt::testPublickey PASSED
plugins/CryptMessage/Test/TestCrypt.py::TestCrypt::testEcies PASSED
plugins/CryptMessage/Test/TestCrypt.py::TestCrypt::testEciesUtf8 PASSED
plugins/CryptMessage/Test/TestCrypt.py::TestCrypt::testEciesAes **FAILED**
plugins/CryptMessage/Test/TestCrypt.py::TestCrypt::testAes PASSED
plugins/CryptMessage/Test/TestCrypt.py::TestCrypt::testAesUtf8 PASSED
```

```
        # Decrypt using AES
        aes_iv, aes_encrypted = CryptMessage.split(ecies_encrypted.decode("base64"))
        ui_websocket.actionAesDecrypt(0, aes_iv.encode("base64"), aes_encrypted.encode("base64"), aes_key)

>       assert ui_websocket.ws.result == "hello"
E       assert None == 'hello'
E        +  where None = <src.Test.conftest.WsMock instance at 0x7fb0d19f09e0>.result
E        +    where <src.Test.conftest.WsMock instance at 0x7fb0d19f09e0> = <Plugin.PluginManager.UiWebsocket object at 0x7fb0d19d2350>.ws

plugins/CryptMessage/Test/TestCrypt.py:71: AssertionError
``` I have been using it for a while. No DNS leaks, is able to receive content from and push content to Tor Network peers, and it creates onion services quickly. Could anyone test this in Whonix? @adrelanos

In making this plugin, I assume you are always using the latest version of Tor and Tor Browser. How do I test this? Just run from your branch MuxZeroNet/patch-13 with `--tor always`? Would this enable the plugin? First download `MuxZeroNet/patch-13` branch, and go to `plugins/` folder to enable the `StemPort` plugin. (Rename `disabled-StemPort` to `StemPort`)

You can use these parameters. (I use Tor Browser)
```
python zeronet.py --tor always --tor_proxy 127.0.0.1:9150 --tor_controller 127.0.0.1:9151
```

Make sure you have `stem` installed in your system. In my environment, I just downloaded the Git HEAD version of stem, and put the `stem` folder inside `ZeroNet/src/` directory. Works for me in Whonix.

When using `--tor always`, I guess `--tor_proxy 127.0.0.1:9150 --tor_controller 127.0.0.1:9151` will be the default and do not need to be manually set? The default values are 127.0.0.1:9050 (for tor_proxy) and 127.0.0.1:9051 (for tor_controller).

If it fails to connect to 127.0.0.1:9051 it starts its own Tor and tries 127.0.0.1:49051
  I am trying to test a chat site in a multi user environment and sometimes the files are not replicated and it is very hard to find out which files that hangs and why (I think my problem is with optional files). 
Very often the download problem can be seen in top of screen as a hanging download and you must already have all the necessary information for updating the green download indicator.

Is it possible to see/find the information behind the download indicator?

Just an idea. Very nice experience to drag the 0 icon left and see all the site info and the extra controllers for the site. Could it be possible to drag the 0 icon down and see download process information?   OK. On one of my VM machines there are 271 missing files (required files) from user areas. A lot of "data/users/xxxx/content.json invalid cert!" errors in UI log. And no green download indicator in top of screen. 
I think that the download indicator in top of screen is showing pending download for current page (fileGets) and not all missing files. I am interested in the pending fileGets behind the hanging green indicator in top of page. Requests with pending response. Not all missing files. Closing this issue. Tried a number of different things to get a better file replication for my site. The major problems in my site were:
1) a very big main content.json file with many optional files (fixed). Now moved to smaller content.json files. 
2) a big all.js file about 1 Mb (todo).  
3) many invalid content.json files (invalid cert) (fixed). I think the mayor problem was that the UI server were busy trying to replicate the invalid content.json files again and again and did not replicate the other site content (optional files and js-files).
4) disabled TOR also helper.

But it was a very frustrating debug process and it could be nice with more build-in ZeroNet help. 
I cannot be the only one wondering why some files are not replicated as expected  Use Stem if we have it ```bash
python zeronet.py --tor always --tor_proxy 127.0.0.1:9150 --tor_controller 127.0.0.1:9151 --disable_udp
```
```
TorManager Authenticate using Stem... 127.0.0.1:9151
TorManager Tor stem connect error: SOCKS5Error: 0x01: General SOCKS server failure in TorManager.py line 213 > control.py line 998 > socket.py line 372 > socket.py line 243 > socket.py line 398 > socks.py line 681 > socks.py line 383 > socks.py line 458
TorManager self-bundled Tor fallback: Tor proxy port 127.0.0.1:9150 check error: No connection
```


Socks Patching of ZeroNet has conflict with Stem. @HelloZeroNet Stem tends to route Tor Control Port traffic through the Tor Socks5 proxy, and then it failed to connect to the Control Port. Any workaround for this?
 How do I write the first lines of the plugin?
```python
@PluginManager.registerTo("TorManager")
class TorManagerPlugin(object):
```  The default settings of `ssl` module are not considered the most secure, so Python Software Foundation wrote some [security considerations](https://docs.python.org/2/library/ssl.html#security-considerations).

According to the security considerations, SSLv2 and SSLv3 "are considered insecure and are therefore dangerous to use." The documentation provides a code snippet to disable SSLv2 and SSLv3.

```python
context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
context.options |= ssl.OP_NO_SSLv2
context.options |= ssl.OP_NO_SSLv3
```

The current SSL patch in ZeroNet redirects `PROTOCOL_SSLv3` to `PROTOCOL_SSLv23` when SSLv3 is not available. Why not redirect `PROTOCOL_SSLv3` and `PROTOCOL_SSLv2` to `PROTOCOL_SSLv23` by default?
 There is a [post](https://onlyzero.net/Me.Zeronetwork.bit/?Post/1oranGeS2xsKZ4jVsu9SVttzgkYXu4k9v/17H6uxjm8hQK9Rk79yHkvQYQnTkJNroA3T/1487296074) on ZeroMe with an image hosted by over one hundred peers showing ZeroNet traffic being sent out unencrypted. At least we should take about how to choose strong TLS cryptos here.

Assumptions:
- We are encrypting against a **passive** attacker.

Principles:
- Avoid generating extra fingerprints or patterns.
- Be aware of TLS implementation bugs.

Since excluding certain ciphers in handshake will result in a unique traffic fingerprint, this PoC uses the default TLS configuration and relies on Python code to check for insecure cryptos.

```python
import socket
import ssl

# A good peer will NEVER use these WEAK cryptos.
# By using any of these weak cryptos, you will be labeled as a bad boy.

# Sources: https://bettercrypto.org/blog/2014/10/14/The-POODLE-killed-it/
#          https://en.wikipedia.org/wiki/LibreSSL#Old_insecure_features

INSECURE_CIPHER_KEYWORDS = set([
    'NULL', 'EXPORT', '-EXP-', '-LOW-', 'MEDIUM', 'Anon', 'anon', 'ANON',
    'RC4', 'RC2', 'DES', 'SEED', 'KRB', 'ADH', 'SRP', 'PSK', 'DSS',
    'MD5', 'MD4', 'MD2', 'SHA1', 'SHA0', 'SHA\n',
    '-64-', '-56-', '-40-',
])

packet = "GET / HTTP/1.1\r\nHost: zeronet.io\r\n\r\n"
HOST, PORT = 'zeronet.io', 443

# Create socket
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
sock.settimeout(10)

# Wrap socket
wrapped_socket = ssl.wrap_socket(sock, ssl_version=ssl.PROTOCOL_SSLv23)

# Connect and print handshake
wrapped_socket.connect((HOST, PORT))

tls_version = wrapped_socket.version()
tls_cipher = wrapped_socket.cipher()
compression = wrapped_socket.compression()

print tls_version
print tls_cipher
print compression

if not tls_cipher:
    wrapped_socket.close() # No plaintext traffic (in clearnet mode)
    exit()

cipher_used, general_ver, key_len = tls_cipher

if not tls_version.startswith("TLS"):
    wrapped_socket.close() # No deprecated SSL protocols
    exit()
for keyword in INSECURE_CIPHER_KEYWORDS:
    if keyword in (cipher_used + "\n"):
        wrapped_socket.close() # No insecure cryptos
        exit()
if key_len < 128:
    wrapped_socket.close() # Weak symmetric key length
    exit()
if compression != None:
    wrapped_socket.close() # No compression
    exit()

# Print reply
wrapped_socket.send(packet)
print wrapped_socket.recv(4096)

# CLOSE connection
wrapped_socket.close()

```  The ZeroHello page main content doesn't load and the following error is displayed:

WebSocket handleRequest error: TypeError: actionFeedQuery() takes exactly 2 arguments (4 given) in UiWebsocket.py line 105 > UiWebsocket.py line 212  Using any browser that properly implements localStorage isolation during Private Browsing (tested using Gecko and Webkit based browsers), the pages only load the ZeroNet wrapper, while pages remain otherwise blank.

It is important to use Private Browsing to avoid caching and other privacy concerns.

Per the browser's debugger, the problem lies on all.js, Line 4030.
      if (Page.local_storage.sites_orderby === "modified") {
Error: null is not an object (evaluating 'Page.local_storage.sites_orderby')

Also Line 4820:
                    data = localStorage.getItem("site." + _this.site_info.address + "." + _this.site_info.auth_address);
Error: null is not an object (evaluating 'localStorage.getItem')

 Fails in http://midori-browser.org/ for me without any special settings.

Firefox may be affected by plugins as you mentioned. Nevertheless, it would be nice if we could browse without localStorage.

http://www.wilderssecurity.com/threads/dom-storage-browser-data-storage-that-can-bypass-the-intent-of-blocking-third-party-cookies.364838/

Thanks.   how to update a zeronet proxy
the update function was disabled in the ui python update.py
usage: update.py [-h] [--verbose] [--debug] [--debug_socket] [--debug_gevent]
                 [--batch] [--config_file path] [--data_dir path]
                 [--log_dir path] [--language language] [--ui_ip ip]
                 [--ui_port port] [--ui_restrict [ip [ip ...]]]
                 [--open_browser [browser_name]] [--homepage address]
                 [--updatesite address] [--size_limit size]
                 [--connected_limit connected_limit] [--fileserver_ip ip]
                 [--fileserver_port port] [--disable_udp] [--proxy ip:port]
                 [--ip_external ip]
                 [--trackers [protocol://address [protocol://address ...]]]
                 [--trackers_file path] [--use_openssl {True,False}]
                 [--disable_db] [--disable_encryption]
                 [--disable_sslcompression {True,False}] [--keep_ssl_cert]
                 [--max_files_opened limit] [--use_tempfiles {True,False}]
                 [--stream_downloads {True,False}]
                 [--msgpack_purepython {True,False}]
                 [--fix_float_decimals {True,False}]
                 [--coffeescript_compiler executable_path]
                 [--tor {disable,enable,always}] [--tor_controller ip:port]
                 [--tor_proxy ip:port] [--tor_password password] [--version]
                 
                 {main,siteCreate,siteNeedFile,siteDownload,siteSign,sitePublish,siteVerify,dbRebuild,dbQuery,peerPing,peerGetFile,peerCmd,cryptSign}
                 ...
update.py: error: unrecognized arguments: --optional_limit 10%
 ok ,thanks for your respons
I'll try this now it works 
 Thanks for your hard work  I use this way to manage a public proxy:
1. Kill ZeroNet's process.
2. Rename Multiuser plugins and add `disabled-` prefix.
3. Start ZeroNet.sh again.
4. Do some operation (e.g.: delete some inactive sites and open help distribution for some sites)
5. Stop ZeroNet.
6. Rename Multiuser plugins and remove `disabled-` prefix.
7. Start ZeroNet.sh again.

But there is some problems:
1. Service interruption.
2. Kill process directly is unsafe for data.
3. If I don't turn off reverse proxy or add an authorization temporarily, users can do some unsafe operation.

Any advice for that? IIRC, the `killall` command will signal the target process, which is safe. `killall -9` will kill the process without signal. But I think that the signal sends Python's process only, for ZeroNet, it's still unsafe.
Probably ZeroNet needs do more work for shutdown, I think. Because click shutdown button in ZeroNet spend more time.  +{
+	"Hide all content from <b>%s</b>?": "<b>%s</b> Nascondi i contenuti di",
+	"Mute": "Attiva Silenzia",
+	"Unmute <b>%s</b>?": "<b>%s</b> Mostra i contenuti di",
+	"Unmute": "Disattiva Silenzia"
+} @HelloZeroNet You are welcome!  ;D   æäº¤å¾—æ¯”æˆ‘è¿˜å¿«ï¼Œä¹Ÿä¸å±ä¸€å£°ã€‚  This just started happening, but for some reason no Zeronet pages will load past the Zeronet wrapper in Firefox with multi-process enabled. If I load ZeroHello for example, I'm greeted with a white page and the Zeronet button/sidebar. However, if I open a new window using the menu option "New Non-e10s Window" and then try to visit ZeroHello, the page loads like it's supposed to.

This issue just started happening and I'm not sure what exactly the cause is besides that it seems to be tied to Firefox's new Multi-process feature that's in testing still. I'm guessing a recent update introduced this bug, as Zeronet pages worked fine before even with Multi-process enabled.

No error messages appear in the Dev Console.

I'm not sure if there's anything you can do on your end as it might just be a bug in the Firefox's Dev channel, but I thought I should let you know.

Specs:
Windows 10 Home
Firefox Dev Edition v53.0a2 (2017-02-07) (64-bit) I tracked down the issue. It appears to be some kind of conflict in NoScript's "ABE" advanced function with Firefox's e10s multi-process feature. I can't tell if it was caused by an update to NoScript or Firefox though. 

I operate NoScript in a Blacklist mode, so only certain sites are supposed to be affected by it, which is why I missed it when tracking down the issue the first time round. After cloning my Firefox profile and removing things one by one I tracked it down.

The issue does seem to be directly related to Firefox's e10s, as disabling it fixes the issue as well. I guess I'll just have to leave that NoScript function disabled for now. Not sure exactly how to report the issue to NoScript though, as I haven't seen it affect anything besides ZeroNet yet, but I'm also not sure if it's worth looking into yourself for such a niche issue

PS: This isn't important to this issue, but in Firefox Dev-Edition's version number the date is also important, as new builds are released almost daily. So just because you have say v53.0a2, doesn't necessarily mean it's the same as someone else's. Just pointing it out just in case you didn't notice.  Error Message:
Err: IOError: [Errno 2] No such file or directory: 'src/Ui/template/wrapper.html' in UiServer.py line 82 > UiRequest.py line 83 > UiRequest.py line 226 > UiRequest.py line 311 > UiRequest.py line 176

On Windows10
At first open website ok, and then extract and open, error display  @svenmoo Have you solved this problem?  Some missing headers will make ZeroNet refuse to serve Web Fonts and AJAX responses. MuxZeroNet/ZeroMux#5

There are two missing headers:
```
Access-Control-Allow-Credentials: true
Access-Control-Allow-Origin: null
```

For the Web Fonts, the original specification says Web Fonts should be fetched Anonymously, which means without Cookies and other credentials. In addition, the Referrer header of font request will be set to the URL of `.css` file. We may need to put session credential information into Referrer header or Query String.

My ideas:
- Make a ZeroFrame API for getting a one-time token.
- Send a 307 redirection to `.css` requests, which contain Cookie header. Redirect the request to a virtual URL that contains a one-time token. (Never tried, don't know if Referrer header will change)

Cons: Does not work if referrer policy is set to `no-referrer`.  When use http://zero/xxxx in address bar to access zeronet with setting a proxy in browser (like http proxy 127.0.0.1:43110), all zerosites with a custom favicon.ico would not show on the title bar,  it only display the zeronet default favicon.
like this:
![1](https://cloud.githubusercontent.com/assets/18359157/22623754/4f275dee-eba0-11e6-9255-457e20312479.jpg)
![22](https://cloud.githubusercontent.com/assets/18359157/22623771/23e1d0b4-eba1-11e6-8809-25a98691f7e3.jpg)


Use full url (http://127.0.0.1:43110/me.zeronetwork.bit) is work well:
![2](https://cloud.githubusercontent.com/assets/18359157/22623756/683f17ae-eba0-11e6-9875-d7d71c75dc0a.jpg)

Use bit domain directly (with setting proxy) also work well:
![3](https://cloud.githubusercontent.com/assets/18359157/22623772/34cb599a-eba1-11e6-88db-ff5b3dbe79c5.jpg)

 Add `view-source:` to the beginning of URL and show us the page source code.    Hello!

There is no easy way to get the `#hash` of the `top` of a page. I can set it by with `window.open` API,
```js
window.open("#hash", "_top");
```
but I am not able to get the hash. [This page](https://bit.no.com:43110/1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/big/docs/usage/mp4-file-format/#moov-box) doesn't work well.  these are not previously mentioned. 
for someone with a "dynamic" site like jekyll which simulates wp, one has to re-up the site changes over time to keep up with posts and such. normally not an issue here. what is the issue however, that zeronet resigns the json file every time. Any changes here get ignored. So like if you setup "media" or "optional" content, on each upload then you simply cannot reset that information-the file gets resigned every time.

furthermore this complicates things. If you have a "name" for your site and want to use it, that too gets overridden. You have to re-save it via the zero ui every time. This simply is too much work for changing sites. If your sites doesnt change, you dont have traffic. It will drop off the net.

If your zite is huge you have two options: torrent files everywhere or everyone hosts a huge website, which for jekyll in most cases is a waste. Jekyll sites themselves are not yuge(<10mb), the "optional content" MAY be.

I need a solution.

 1. > The file gets re-signed every time.
    
    You can [include](https://zeronet.readthedocs.io/en/latest/site_development/content_json/#includes) [a separate](http://127.0.0.1:43110/1uEc35aRpkDgVmJ35jcMEHm4D2JCcEejp/motherboard/content.json) [`content.json` file](http://127.0.0.1:43110/1uEc35aRpkDgVmJ35jcMEHm4D2JCcEejp/content.json) only for things that are huge, so that if that big part does not get modified, you can choose not to sign that `content.json` file. However, the documentation on it is not very clear. You may need some time to figure it out.

2. > If you have a "name" for your site and want to use it, that too gets overridden. You have to re-save it via the zero UI every time.
    
    Sorry, need more clarification.

3. > If your site is huge you have two options: torrent files everywhere or everyone hosts a huge website. Jekyll sites themselves are not huge (<10mb), the "optional content" may be.
    
    You are able to define an optional file regular expression. In your `content.json`, add this key and value after the `"modified"` key.
    ```json
    "optional": "(big/files/.*\\.mp4)",
    ```
    After that, sign your site again.
    
    With optional files defined, everyone will not have to seed all parts of your site. For example, by clicking on a link to your site, I will seed _all_ of your _non-optional_ files, as well as the _optional_ files _I want._ My downloaded optional files will not get recycled unless I am running out of space. If I really want to remove them, I can clean them up via optional file manager.  Im having a split issue. The site updates but content.json does not and yields an update failed(to sync) error. As a side result, Im getting failure to share my zite.<br />

ex:
[FAILED] mfqipozsmdbgdnmq.onion:15441: {'to': 1, 'cmd': 'response', 'error': 'File invalid'}
...
Site: **** [FAILED] fcwt5bzv2w5it3lv.onion:15441: None
...

and then FAILURE to sync messages. 55+ nodes. either someone not staying online long enough, or zero isnt sending updates. Im also getting timeouts(I might could fix these, my upstream bandwidth is limited) on a number of attempted nodes when pushing updates. Im looking for the timeout variable---mebbe I can adjust it-- but cant find anything documented, like the zeronet.conf file. pascal has two engine for this, C has a few. I hope py is good at documenting itself... ZeroNet will not seed an unknown site without user interaction. When you are pushing your new site to peers, make sure they want to seed your site.

For example, simply open your site on [one](https://bit.no.com:43110/138R53t3ZW7KDfSfxVpWUsMXgwUnsDNXLP/?Page:proxies) [of](https://zeronet.korso.win) [these](https://zeronet.iikb.org) [public](https://proxy1.zn.kindlyfire.me/) [gateways](https://zero.btnova.org/), and push your site update again.  On Ubuntu 14.04

upon issuing `~/.local/bin/ZeroNet/zeronet.py siteCreate`
I get the following:

> - Starting ZeroNet...
> - OpenSSL loaded, version: 01000106F
> - Version: 0.5.1 r1848, Python 2.7.6 (default, Oct 26 2016, 20:30:19) 
> [GCC 4.8.4], Gevent: 1.0
> - Generating new privatekey...
> - ----------------------------------------------------------------------
> - Site private key: [redacted]
> -                   !!! ^ Save it now, required to modify the site ^ !!!
> - Site address:     19CjDcEs4C5i1pyNvaMTcxuKgaGhpHakeF
> - ----------------------------------------------------------------------
> ? Have you secured your private key? (yes, no) > yes
> - Creating directory structure...
> - Creating content.json...
> Site:19CjDc..akeF Content.json not exist: data/19CjDcEs4C5i1pyNvaMTcxuKgaGhpHakeF/content.json
> Average Speed: 43678.8 w/s. Current Word: 'IroXCb'
> Site:19CjDc..akeF File content.json not exist yet, loading default values...
> Site:19CjDc..akeF Opening site data directory: data/19CjDcEs4C5i1pyNvaMTcxuKgaGhpHakeF/...
> Site:19CjDc..akeF - index.html (SHA512: 4319ecaec2b7c0569900f73fee07b8d887adcf254c827a217706d3423e79a8e1)
> Site:19CjDc..akeF Adding timestamp and sha512sums to new content.json...
> Site:19CjDc..akeF Verifying private key...
> Site:19CjDc..akeF Correct 19CjDcEs4C5i1pyNvaMTcxuKgaGhpHakeF in valid signers: ['19CjDcEs4C5i1pyNvaMTcxuKgaGhpHakeF']
> Site:19CjDc..akeF Signing content.json...
> Site:19CjDc..akeF Saving to content.json...
> Site:19CjDc..akeF File content.json signed!
> - Site created!
> 
However no data is written to disk inteh current directory, and no "data" directory created.
Searching the whole file system, I found the data directory, site directory, json and html files under `/proc/5988/cwd/data/19CjDcEs4C5i1pyNvaMTcxuKgaGhpHakeF`  I can choose to delete missing optional files via command line argument, but adding this option to sidebar can be even better.
 How does this expiration period work?

     If I removed some existing optional files and signed my site. (Say I really want to remove them and free up space) Will these "missing" optional files be cleaned up in 24 hours?

      On last version zeronet try to open browser on ubuntu-server. 
And i can't connected to server...
also if i start zeronet without --ui_ip myip --ui_password mypassword it start as normal (and i see good logs with updating sites)

```
shift@srv:~/ZeroNet$ python start.py --ui_ip myip --ui_password mypassword
- Starting ZeroNet...
[00:41:33] - OpenSSL loaded, version: 01000207F
[00:41:33] - Version: 0.5.1 r1840, Python 2.7.12 (default, Nov 19 2016, 06:48:10) 
[GCC 5.4.0 20160609], Gevent: 1.1.2
[00:41:33] - Creating FileServer....
[00:41:33] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 159 > _socket2.py line 228
[00:41:33] - Creating UiServer....
[00:41:33] - Removing old SSL certs...
[00:41:33] - Starting servers....
[00:41:33] Ui.UiServer --------------------------------------
[00:41:33] Ui.UiServer Web interface: http://myip:43110/
[00:41:33] Ui.UiServer --------------------------------------
[00:41:33] - Opening browser: default_browser...


myip contacted. Waiting for reply...
```

last line seems from w3m...
myip - my server public IP yep, zeronet wait for browser, i install links2 (ssh web browser) to server then i try to quit
![2017-01-26 1 14 22](https://cloud.githubusercontent.com/assets/426427/22311551/f8ecc79a-e364-11e6-83fe-f0bf6f24093f.png)

After that i get normal working zeronet, i think in config we should have option for turn off browser opening  Use zeronet.py if you don't want to start the browser.  * Talking about `127.0.0.1:15441` here.
* Not talking about the web interface here which can be configured with `--ui_ip`.

Could you add a command line switch to make the listener IP configurable please?

That would be useful to make ZeroNet fully work inside Whonix.

Related and further information:
#794 When using...

    ./zeronet.py --tor always --fileserver_ip 10.137.11.80

That does not work for me.

```
sudo netstat -tulpen | grep python
tcp        0      0 127.0.0.1:43110         0.0.0.0:*               LISTEN      1000       30399      2988/python2.7      
tcp        0      0 127.0.0.1:15441         0.0.0.0:*               LISTEN      1000       30402      2988/python2.7
```

Looks like `--tor always` prevents using any `--fileserver_ip` other than `127.0.0.1`.

Could you fix that please? Works for me! Thanks!
  In Whonix, ZeroNet runs on the workstation and Tor on the gateway. These are two different VMs connected by internal network. All outgoing connections are forced through Tor.

ZeroNet's localhost connection is redirected Tor's ControlPort to the gateway, where the ephemeral Tor hidden service is created. Tor then is pointing the hidden service's virt port the workstation on 10.152.152.10:15441.

Since ZeroNet is only listening on 127.0.0.1:15441, no incoming Tor hidden service connection will ever reach ZeroNet.

ZeroNet continues to function, it fails to notice broken Tor hidden services connection. Do you consider this a bug?

Related:
#795 Send a ping request to any `onion` address created by ZeroNet itself. I can't do this with Tor Browser, since the protocol is different. It would be nice if ZeroNet checks it automatically and pushes error messages to ZeroHello. A [descriptor](https://www.torproject.org/docs/hidden-services) must be published before a Tor Hidden Service can be considered accessible. The author of [Stem tutorial](https://stem.torproject.org/tutorials/over_the_river.html#ephemeral-hidden-services) suggests developers wait until the descriptor is published, by adding a `await_publication=True` parameter when using the [API](https://stem.torproject.org/api/control.html#stem.control.Controller.create_ephemeral_hidden_service).

Await publication is significantly slower, but TorManager runs fast. It seems that ZeroNet does not wait for descriptor publication. Waiting for it can help eliminate false positives, but can take much longer time. Here is my idea: when creating the "global" onion service, wait until publication. When creating site specific onion services, don't wait for publication. By doing so, we make sure there is at least one accessible onion service to receive the ping request, while not slowing down the startup process.

  It seems like the 1.2.x version of gevent does not work with Zeronet. One of the modules was renamed, causing a crash on startup.   This is an interesting but hard-to-implement idea: asking more than one peer for a big file, so file loading will not get stuck even when many peers have slow Internet.

![zeronet_protocol](https://cloud.githubusercontent.com/assets/24784041/22236524/10ead87c-e1fe-11e6-8bfc-fa85328e18ab.png)

When browser requested for a _big enough_ file, ZeroNet loads small parts of the same file form multiple peers concurrently.

## Problems:
Some computers in the network may have an old version of the file. We need to check for this inconsistency before marking the response as valid. (Heuristic Check)
- Check if file size matches.
- Add this to ~~response~~ header (Correction: should be **request** header) -  sha512sum of this file. We assume an up-to-date ZeroNet will send back an error message when checksum does not match.
- Add this to ~~response~~ header (Correction: should be **request** header) - sha512sum of `content.json` that contains this file.

The hash checksum of reassembled file may still be different from what your `content.json` said. In this case, fallback to single-peer download.

To further improve this design, write your comments below.  Any information/rules about ZeroFrame API callbacks that is nice to know?

I expect callbacks to be executed asyn, independently and as quickly as possible.
A1 => cb1 (long call), A2 => cb2 (short call), A3 => cb3 (short call).
I would expect cb2 and cb3 to be executed before cb1 but it is not always so.
Sometimes A1 call will block A2 and A3 calls until A1 is done. 
For example can a fileGet (optional file) block many other ZeroFrame API calls for a long time.

So what is the rules for ZeroFrame API callbacks?
Is UI server a blocking resource? Max one running UI server call at any time? Thanks for the info. Will try to be smarter in my API calls. 

Regarding fileGet. Sometimes fileGet fails with a timeout (empty response in callback) and the requested file will arrive later and is detected in file_done event. Sometimes very long time after the failed fileGet request. I have used that in my message processing. 
Maybe add a timeout parameter to fileGet? Would be nice with shorter timeout period.  coming from jekyll tis is confusing.

Im not shure if this means /assets/xyz
or request for an asset of media type, as in images...which seems to work.

I keep getting throw this silently in background(no UI error in the browser) 

Ui.UiServer Media referrer error: 
assets not allowed from http://127.0.0.1:43110/chomping-at-the.bit/?wrapper_nonce=dcea03242c2de26ed8f2f05ce7eabaf2e627b0816007964fcd82444f780438b3

since its a nonce, I have no idea what this is. It could be js file, font file, image...or links. Ive heard that without _top, links dont work....so tell me how thats suppose to work in jekyll.. anyways the navcode seems to handle things ok and the images are loading.

thx to someone else, one can stream or fetch nearly instantly. As far as large files, we would have to chisel out that part of code from zeroTube or similar, which dices up large files(or just torrent). how to sign the site correctly??  Tor command responses terminate with "250 OK\r\n" so we have to read
until that sequence is encountered.

The previous implementation is racy: after sending a command it would
accept whatever that is found on the socket as its response, no matter
if it is correctly terminated or not.

This commit fixes: https://github.com/HelloZeroNet/ZeroNet/issues/756  Maybe post to ZeroTalk?  I tested. There's two versions of libcrypto in my router. /lib/libcrypt-0.9.33.2.so(version 01000115F) and /lib/libcrypto.so.1.0.0(version 0100020AF).

Benchmark:
```
OpenSSL version 01000115F
<CDLL '/usr/local/ssl/lib/libcrypto.so', handle 804c58 at 7d5f00>
100x Verified True 36.356418848
```
```
OpenSSL version 0100020AF
<CDLL '/usr/local/ssl/lib/libcrypto.so.1.0.0', handle 9098d8 at 842720>
100x Verified True 27.0174210072
```
(In fact it's 1000x. `for i in range(1000):`) There's two versions of libcrypto. One is from the firmware and the other one is from Entware. The one from Entware is newer and faster.  I mean if the thread works well on current OS. It's no need to change the stack size. #780  https://github.com/google/grumpy

https://opensource.googleblog.com/2017/01/grumpy-go-running-python.html

In order to improve the performance? Ah i see And instead of a change to Python3?
 I mean Go instead of Python3, since its more future proof? how is go more future-proof than python3? i don't expect either will be obsoleted any time soon.... On Stackoverflow, yes. On TIOBE, not a single language in history ever raised up so quickly into the Top10.
To measure a language based on how many people have troubles with it, seems questionable to me. 
Since you both seem to prefer Python, is it probably the saver choice.  Well, that might be, while Ruby was/is very similar to Python and performs less speedy.
Go has no competitor. They all are either significantly more complex and so consequently less newbie friendly plus more time consuming at all and/or offer not such a nice and convenient way to (cross-)deploy with one single command and without any makefile. Most of them also give more freedom to make failures. 
Rust is the exception here of course.

As said, if it works for you is it fine to me. 

And when I say future proof, I mean technology wise. I am quite ware that Python is still very popular.

I simply hint you about the benefits of a particular technique, I do not even use Go on my own. 
I simply keep my eyes open, since such decisions grow on us and with that on our projects. 

We all know that so you might be interested in this particular option.

I wish you deeply much success since this project here is important and I see great benefits, compared to other approaches, which is why I am here. And why I write these comments. 

Much fun :D  Either this referrer policy in an HTML file
```html
<meta name="referrer" content="origin-when-crossorigin">
```
or this request
```bash
curl 'http://127.0.0.1:43110/1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/img/avatar.png' \
     -H 'Host: 127.0.0.1:43110' -H 'Accept: */*' \
     -H 'Referer: http://127.0.0.1:43110/' -H 'Origin: null'
```
can cause ZeroNet return
```
Server error
Err: AttributeError: 'NoneType' object has no attribute 'group'
in UiServer.py line 81 > UiRequest.py line 85 > UiRequest.py line 201 > UiRequestPlugin.py line 22 > TranslateSitePlugin.py line 24 > UiRequest.py line 354 > UiRequestPlugin.py line 36
```  You should contact the hub owner. ZeroNet developer can't control zites content.  I'm aware of the statement, that ZeroNet is **not** a replacement for the current client\<-\>server based model. But independently of it, I'd like to ask the following questions as an immediate reaction to an article about ZeroNet I read. I consider these questions very important for basically any to-be-successfull P2P project (they might find their place in FAQ or even directly in documentation).

1. How is the locality of data ensured (in parallel to their non-local persistence to avoid their disappearance)? It's nonsensical to have everything everywhere (like torrent) and forever. Except for that, based on measurements of big companies (Google, Facebook, Twitter, etc.), most of the web is served to mobile or embedded devices and these usually employ just tiny and often volatile storage.

1. Is it possible to locally dynamically filter data (e.g. someone travels and wants to be sure, that in the country she/he is currently, noone will find any persisted data which do not comply with the local legislation). At least it shall be possible to easily manually tag content which must **not** be persisted.

1. Is the content securely and smartly (e.g. ZeroNet measures statistics about network congestion, considers constraints set up by the administrator - e.g. maximum size of the storage, maximum bandwidth used for up/down, etc.) cached to minimize overall pressure and to increase availability and stability? Or is it just a naive implementation of the torrent protocol (i.e. opening of thousands of connections one by one, and thus effectively DDoSing small SOHO devices with NATs, which count up to the vast majority of all leaf nodes of the internet network infrastructure)?

1. Does it work stably and without any issues **absolutely without** ani existing trackers? This is closely related to the first question as uTP, PEX, DHT, Local Peer Discovery, etc. technologies for finding peers are easily blockable, which is also what happens in reality.

1. Is it possible to download all content in logical blocks (e.g. script, image, HTML, ...) to allow prioritization, parallelism, partial downloads and partial viewing (including the wishes of the user - e.g. I want to block all pictures, so I will decide to not load them until I enter the "album" section of the web)? Or is it rather a "git-like" monolithic design, where everything is divided into same-sized blocks mutually absolutely unrelated and these are first then downloaded in parallel from different peers (which has by the way the consequence of long waiting times for the whole content to load without the possibility of at least a preview/shortened_version/smaller_version, and at the same time is highly prone to starvation as each block is requested only from one or just very few seeds which are of course blocked by state censorship)?

1. How is data reuse ensured? And how about multicast data streaming? It's a core feature for big networks, streaming (audio, video, real-time games, ...) and things like `jQuery` `D3.js` `NODE.js` or `Video.js` rely on well-behaving and high-throughput CDNs.

1. Is there any full-featured active scraper (possibly distributed across ZeroNet to avoid it's disappearance or unavailability in censored countries) of all the content in ZeroNet? This is an absolute must-have and a strong requirement for massive spreading of the network. An index engine using e.g. the Namecoin database might be a good start.

1. What everything prevents direct use (i.e. without any architectural changes) of existing rich web applications (full of JS, server-client communication, etc.) in ZeroNet? Could you list all the points?

1. How about fine-grain unlimited control over user access? Because all data are replicated, everybody can read them, but in case only part of them is public and the rest is specific for a certain group of people, how to make absolutely sure noone else can read it? Do I really need to encrypt the whole page/application (with it's whole history - ouch, I already feel the size pain) and build my own sign-in solution which will then decrypt only certain parts of the downloaded data based on the access-rules built in the page/application? How about the current bottle neck of one and only one site-owner managing the access rights (currently it seems only **full** `rw` access can be granted) to the site-owner's page/application (I want to make sure my forum will stay fully active and functional even after the state starts to censor my forum and the forum users)?

1. How does one sets up a secure fully functional bidirectional (to and from the "usual" internet) gateway for the case I want to access ZeroNet from a device not having a ZeroNet client (which actually currently approaches 100% of all devices and will probably stay so for a long time)? Anywhere any very detailed howto?

1. How does ZeroNet fights against peers and seeds appearing in different blacklists from the "usual" internet? Thanks for quick answers @HelloZeroNet .

1. The question was rather about pruning and trying to avoid full duplication of the "whole internet" (all ever visited sites - i.e. thousands and more at least) and also the question asked about data locality (I don't want to download the content from someone from Europe if I'm sitting in Australia and few hundreds of Australians already visited the original web site from Europe).

1. In many legislations, there are e.g. black lists of web sites with censored content or any other identifiers technically describing the censored content (so to answer your question - the "who" is the state). Should there be any trial, all the data will be either easily accessed (because of saved passwords) or decrypted (because of weak ciphering, some mistake or just because of access to enormous or breakthrough computing resources) or because of torture or whatever, it's way better to not have these data persisted at all. These countries include Germany (huge audio and video prohibition - just try any German VPN on youtube), Czech republic (online hazard games), USA (various...), Australia, China, Turkey, Sveden, ...

1. Any plans or ways to improve it? Just react briefly as I know this fine-tuning is tedious and a lot of work.

1. Great to hear there are some plans!

1. Are all these logical pieces downloaded from the same source or from different ones? If from different ones, how is starvation prevented?

1. It's not at all about having centralized data. It's about very smart redistribution of common data, so that it's locally (e.g. from the same country or state) very quickly accessible. This can be achieved through data flow monitoring in the whole network and automated redistribution, through some ranking, through smart caching, etc. Is anything for data reuse on the schedule?

1. That's sad - noone will know about any content and noone will get interested except for those few with external strong motivation (usually money - i.e. black market).

1. Any plans on providing such "backend" (I can imagine a faster variant of the universal Ethereum computing platform)?

1. Any plans to extend it for more fine-grained control? Are actually already currently supported roles (i.e. groups of users having the same permissions)?

1. Could this public gateway be easily protected with a password? I don't want everyone using my gateway :wink:.

1. Ok, in case Tor is blocked (e.g. Syria, Turkey, etc.), is there any other way how to "hide" yourself? Ok, now it's clear to me what is the direction of ZeroNet. I must admit I'm a bit disappointed, but on the other hand I know very well how difficult it is to build a well-behaving P2P network serving for universal purposes.

By the way, could you please edit your last comment and add some foo strings to the points on which didn't comment as otherwise the numbering does not match :wink: (Markdown is number-agnostic)? >but I think we should search for use-cases where it could work instead of focusing on what is it not good for.

Of course. I'll keep an eye on ZeroNet and it's use. Keep going!  When a user upload a optional file, the file is pinned. So if the user publish new contents, old optional files won't lose. But if a user copy their cert to a new device, their old optional files won't download and pin automatically, then if the user submit new posts, `content.json` will be resigned and the new `content.json` doesn't include the old optional files, the old optional files will be lost.
Many users' old images have been lost. Probably solution: 
- Don't remove existing optional files' record automatically in `content.json` while signing but display a notification.
- Always download user's own content.  win8 newest ZeroNet (I guess)
whether i opened start.cmd or zeronet.cmd, it flashed and then closed...
it works okay days ago...
And here's what i can capture...
![image](https://cloud.githubusercontent.com/assets/8787958/21963400/ea4765a8-db74-11e6-87e2-4d560e62a06c.png)

 You should run cmd.exe and run start.cmd in it to see error message. Also try the exe version: https://github.com/HelloZeroNet/ZeroNet-win/archive/dist.zip @ysc3839 thank you!
 i did run it in cmd and the force close still appeared...
then i add a pause and run as administrator
![1](https://cloud.githubusercontent.com/assets/8787958/21971464/caeb4ee6-dbeb-11e6-9721-31bbc6f71d01.png)
also getting permission denied on browsers. like this one #532 

**However, the exe version works fine till now.**

So, Thanks again.  After I inserted "import os" and "os.system("pause") " in start.py, it won't force close

but still get a ERR_CONNECTION_REFUSED in Chrome

```[13:34:22] - OpenSSL loaded, version: 01000201F
[13:34:22] - Version: 0.5.1 r1795, Python 2.7.12 (v2.7.12:d33e0cf91556, Jun 27 2
016, 15:19:22) [MSC v.1500 32 bit (Intel)], Gevent: 1.1.2
[13:34:22] - Creating FileServer....
[13:34:23] TorManager Tor controller connect error: error: [Errno 10061] [Error
10061] No connection could be made because the target machine actively refused i
t. in TorManager.py line 157 > socket2.py line 228
[13:34:23] TorManager Starting Tor client tools/tor/tor.exe...
Jan 16 13:34:24.375 [notice] Tor v0.2.8.11 (git-31e7b47fbebe8caf) running on Win
dows 8 with Libevent 2.0.22-stable, OpenSSL 1.0.1u and Zlib 1.2.8.
Jan 16 13:34:24.375 [notice] Tor can't help you if you use it wrong! Learn how t
o be safe at https://www.torproject.org/download/download#warning
Jan 16 13:34:24.391 [notice] Read configuration file "Ã—Ã—Ã—\ZeroBundle
ZeroNet\tools\tor\torrc".
Jan 16 13:34:24.391 [warn] Path for GeoIPFile (geoip\geoip) is relative and will
resolve to Ã—Ã—Ã—\ZeroBundle\ZeroNet\tools\tor\geoip\geoip. Is this wha
t you wanted?
Jan 16 13:34:24.391 [warn] Path for GeoIPv6File (geoip\geoip6) is relative and w
ill resolve to Ã—Ã—Ã—\ZeroBundle\ZeroNet\tools\tor\geoip\geoip6. Is this
what you wanted?
Jan 16 13:34:24.391 [warn] Path for DataDirectory (data) is relative and will re
solve to Ã—Ã—Ã—\ZeroBundle\ZeroNet\tools\tor\data. Is this what you want
ed?
Jan 16 13:34:24.407 [notice] Opening Socks listener on 127.0.0.1:49050
Jan 16 13:34:24.407 [notice] Opening Control listener on 127.0.0.1:49051
Jan 16 13:34:24.000 [notice] Bootstrapped 0%: Starting
Jan 16 13:34:25.000 [notice] Bootstrapped 80%: Connecting to the Tor network
Jan 16 13:34:25.000 [notice] New control connection opened from 127.0.0.1.
[13:34:25] - Creating UiServer....
Traceback (most recent call last):
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\zeronet.py", line 18, in main
main.start()
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\main.py", line 450, in start
actions.call(config.action, action_kwargs)
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\main.py", line 129, in call
func(**kwargs)
File "plugins\Trayicon\TrayiconPlugin.py", line 65, in main
super(ActionsPlugin, self).main()
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\main.py", line 139, in main
ui_server = UiServer()
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\Ui\UiServer.py", line 61, in ini
t
self.sites = SiteManager.site_manager.list()
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\Site\SiteManager.py", line 146, in
list
self.load()
File "plugins\Zeroname\SiteManagerPlugin.py", line 20, in load
super(SiteManagerPlugin, self).load(*args, **kwargs)
File "plugins\MergerSite\MergerSitePlugin.py", line 333, in load
self.updateMergerSites()
File "plugins\MergerSite\MergerSitePlugin.py", line 301, in updateMergerSites
merged_type = site.content_manager.contents.get("content.json", {}).get("mer
ged_type")
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\Content\ContentDbDict.py", line 10
5, in get
return self.getitem(key)
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\Content\ContentDbDict.py", line 55
, in getitem
return self.loadItem(key)
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\Content\ContentDbDict.py", line 23
, in loadItem
content = self.site.storage.loadJson(key)
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\Site\SiteStorage.py", line 231, in
loadJson
return json.load(file)
File "Ã—Ã—Ã—\ZeroBundle\Python\lib\json_init.py", line 291, in loa
d
**kw)
File "Ã—Ã—Ã—\ZeroBundle\Python\lib\json_init_.py", line 339, in loa
ds
return _default_decoder.decode(s)
File "Ã—Ã—Ã—\ZeroBundle\Python\lib\json\decoder.py", line 364, in deco
de
obj, end = self.raw_decode(s, idx=w(s, 0).end())
File "Ã—Ã—Ã—\ZeroBundle\Python\lib\json\decoder.py", line 382, in raw
decode
raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
Press any key to continue . . . Jan 16 13:34:27.000 [notice] Bootstrapped 85%: F
inishing handshake with first hop
Jan 16 13:34:28.000 [notice] Bootstrapped 90%: Establishing a Tor circuit
Jan 16 13:34:29.000 [notice] Tor has successfully opened a circuit. Looks like c
lient functionality is working.
Jan 16 13:34:29.000 [notice] Bootstrapped 100%: Done

Error in atexit.run_exitfuncs:
Traceback (most recent call last):
File "Ã—Ã—Ã—\ZeroBundle\Python\lib\atexit.py", line 24, in run_exitfu
ncs
func(*targs, **kargs)
File "plugins\MergerSite\MergerSitePlugin.py", line 337, in save
self.updateMergerSites()
File "plugins\MergerSite\MergerSitePlugin.py", line 301, in updateMergerSites
merged_type = site.content_manager.contents.get("content.json", {}).get("mer
ged_type")
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\Content\ContentDbDict.py", line 10
5, in get
return self.getitem(key)
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\Content\ContentDbDict.py", line 55
, in getitem
return self.loadItem(key)
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\Content\ContentDbDict.py", line 23
, in loadItem
content = self.site.storage.loadJson(key)
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\Site\SiteStorage.py", line 231, in
loadJson
return json.load(file)
File "Ã—Ã—Ã—\ZeroBundle\Python\lib\json_init.py", line 291, in loa
d
**kw)
File "Ã—Ã—Ã—\ZeroBundle\Python\lib\json_init.py", line 339, in loa
ds
return default_decoder.decode(s)
File "Ã—Ã—Ã—\ZeroBundle\Python\lib\json\decoder.py", line 364, in deco
de
obj, end = self.raw_decode(s, idx=w(s, 0).end())
File "Ã—Ã—Ã—\ZeroBundle\Python\lib\json\decoder.py", line 382, in raw
decode
raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
Icon thread stopped, removing icon...
Error in sys.exitfunc:
[13:37:35] - Unhandled exception
None
Traceback (most recent call last):
File "Ã—Ã—Ã—\ZeroBundle\Python\lib\atexit.py", line 24, in run_exitfu
ncs
func(*targs, **kargs)
File "plugins\MergerSite\MergerSitePlugin.py", line 337, in save
self.updateMergerSites()
File "plugins\MergerSite\MergerSitePlugin.py", line 301, in updateMergerSites
merged_type = site.content_manager.contents.get("content.json", {}).get("mer
ged_type")
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\Content\ContentDbDict.py", line 10
5, in get
return self.getitem(key)
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\Content\ContentDbDict.py", line 55
, in getitem
return self.loadItem(key)
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\Content\ContentDbDict.py", line 23
, in loadItem
content = self.site.storage.loadJson(key)
File "Ã—Ã—Ã—\ZeroBundle\ZeroNet\src\Site\SiteStorage.py", line 231, in
loadJson
return json.load(file)
File "Ã—Ã—Ã—\ZeroBundle\Python\lib\json_init.py", line 291, in loa
d
**kw)
File "Ã—Ã—Ã—\ZeroBundle\Python\lib\json_init.py", line 339, in loa
ds
return _default_decoder.decode(s)
File "Ã—Ã—Ã—\ZeroBundle\Python\lib\json\decoder.py", line 364, in deco
de
obj, end = self.raw_decode(s, idx=w(s, 0).end())
File "Ã—Ã—Ã—\ZeroBundle\Python\lib\json\decoder.py", line 382, in raw
decode
raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded

Ã—Ã—Ã—\ZeroBundle\ZeroNet>pause
Press any key to continue . . .```  ![fs](https://cloud.githubusercontent.com/assets/18724949/21950295/5d68d0d6-da34-11e6-88be-1845816b913c.png)
Open any one site (e.g.: [ZeroHello](http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/)), we can see the value of free space is most more than site_limit - total_used. This is a bug? Another user report their sidebar on Android displays "-1MB": http://127.0.0.1:43110/Me.ZeroNetwork.bit/?Post/1KNmG5rJUGhgUJGFbLkv2B5isaqu9PrZqi/19qBszkhiRjHLP4Z1eeZXS6HztiCD7yiBx/1484354950 i thinks its the *comma* that confuses people of the actual size (and showing it in megabytes), making it seem smaller that it actually is, like in the upper picture it would seem like you have 32 megabytes of free space, not 32 000    This pull request solves encoding issues only. This pull request is a little bit outdated. Merging it seems to break UiRequest. However, the decoding error is still there, as of commit [`f74e939`](https://github.com/HelloZeroNet/ZeroNet/commit/f74e9397db20336835a72220321480328f4de477), rev 1861. Though we will not support IDNA domain names and non-ASCII path names, I believe it is better to return a 404 error rather than a 500 error. ## General Guidelines
- The `path` variable is URL decoded and UTF-8 encoded.

- The return values of `os.path` APIs can be either in Unicode or in file system encoding. Make sure to use Unicode parameters so that the APIs will always return Unicode strings.

- There cannot be Unicode strings in HTTP headers. The Gevent API `self.start_response` does not accept Unicode strings either.

- Use `.decode('encoding')` to convert a binary string to a Unicode string. Use `.encode('encoding')` to convert a Unicode string to a binary string. Use `repr(a_string)` to see if a string is decoded correctly.

- When testing, you have to make sure both the wrapper and the inner frame work without crashing.

## Test cases
URLs:
```
http://127.0.0.1:43110/TamÃ¡s/Kocsis
http://127.0.0.1:43110/TamÃ¡s.bit/Kocsis/
http://127.0.0.1:43110/TamÃ¡s Kocsis/index.html
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/fake/path/TamÃ¡s/Kocsis.html
http://127.0.0.1:43110/å®žç”¨å·¥å…·å­˜æ¡£åŒº.html
http://127.0.0.1:43110/å®žç”¨å·¥å…·å­˜æ¡£åŒº.bit/å®žç”¨å·¥å…·å­˜æ¡£åŒº.html
http://127.0.0.1:43110/å®žç”¨å·¥å…·å­˜æ¡£åŒº/ZeroMux.bit/
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/?å®žç”¨å·¥å…·å­˜æ¡£åŒº
```

Path encodings:

Say, put ZeroNet in this directory:
```
/home/ubuntu/TamÃ¡s Kocsis/ZeroNet-master
```  Is there any conflict with GeoLite2's license? GeoLite's website is hosted on CloudFlare, and CloudFlare blocks Tor. :-1:   Please upgrade your GPG signing key to 4096 bits which is considered standard. 2048 is no longer sufficient. 4096 is the recommendation of GitHub. Posting the full key fingerprint here for verification purposes.

> `960F FF2D 6C14 5AA6 13E8  491B 5B63 BAE6 CB96 13AE`

```
gpg --keyid-format long --fingerprint tamas@zeronet.io
```

```
pub   rsa4096/5B63BAE6CB9613AE 2017-01-15 [SC] [expires: 2022-01-14]
      Key fingerprint = 960F FF2D 6C14 5AA6 13E8  491B 5B63 BAE6 CB96 13AE
uid                 [ unknown] Tamas Kocsis (4096) <tamas@zeronet.io>
sub   rsa4096/A77A8F3444323B73 2017-01-15 [E] [expires: 2022-01-14]
```

That's how I have seen it. Perhaps someone else can confirm it. @adrelanos

Confirmed

user@host:~$ gpg --keyid-format long --fingerprint tamas@zeronet.io
pub   4096R/5B63BAE6CB9613AE 2017-01-15 [expires: 2022-01-14]
      Key fingerprint = 960F FF2D 6C14 5AA6 13E8  491B 5B63 BAE6 CB96 13AE
uid               [ unknown] Tamas Kocsis (4096) <tamas@zeronet.io>
sub   4096R/A77A8F3444323B73 2017-01-15 [expires: 2022-01-14]
 Confirmed. Fingerprint = `960F FF2D 6C14 5AA6 13E8  491B 5B63 BAE6 CB96 13AE`

```bash
$ gpg2 --export "960F FF2D 6C14 5AA6 13E8  491B 5B63 BAE6 CB96 13AE" | sha256sum
1e46c22a0ab4e766637b1676b9394ac3465eb094b8deb4daeb09deb06cfa04be  -
```  This is a very likely fix for #725. Didn't get a confirmation yet, but I wanted to have this PR ready now.

I made the ol' mistake where I thought that urlopen().read() returns a text string, but it's a byte string, and `xml.minidom.parseString` expects a text string. Easily solved by decoding the byte string into a text string.

The other small change is to make the default function arguments that are _mutable_ lists into immutable tuples. Using a mutable object as a default function argument is an invitation to all sorts of pain. Absolutely not! It's just a style thing - in my opinion, the `,` at the end instantly identifies the parenthesis as tuple. But if you don't like it, I'd be more than happy to get rid of the `,`'s :). Thanks for the feedback, I never thought of it that way. I removed the commas and rebased my branch.  `zeronet --tor always` does not work for me.

> [22:17:05] TorManager Tor controller connect error: AttributeError: 'NoneType' object has no attribute 'group' in TorManager.py line 160

----

> `250-VERSION Tor="0.2.9.8 (git-a0df013ea241b026)"`

https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Tor/TorManager.py#L160 Took the liberty to make that `self.log.info` so I don't have to enable `--debug` if that is okay.

```
[23:00:51] TorManager Tor protocol: 250-PROTOCOLINFO 1
250-AUTH METHODS=NULL

[23:00:51] TorManager Tor controller connect error: AttributeError: 'NoneType' object has no attribute 'group' in TorManager.py line 161
```

An issue with line handling?

-----

Could also be an issue with our [control-port-filter-python](https://github.com/Whonix/control-port-filter-python).

It receives:
```
PROTOCOLINFO
```
It replies:
```
250-PROTOCOLINFO 1
250-AUTH METHODS=NULL
250-VERSION Tor="0.2.9.8 (git-a0df013ea241b026)"
250 OK
```
 Could you please find your `TorManager.py` file and add this line under [line 158](https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Tor/TorManager.py#L158)?
```python
print "------", repr(res_protocol)
``` Another option, if yo want the Tor version number, send `GETINFO version`, not ask for `protocolinfo`.

Yet another option would be porting to python-stem, which I created a separate ticket for just now:
https://github.com/HelloZeroNet/ZeroNet/issues/758 No, doesn't work for me.

Added a log line below.
```
                res_version = self.send("GETINFO version", conn)
                self.log.info("res_version: %s" % res_version)
```

```
[19:27:27] TorManager res_version: 250 OK
[19:27:27] TorManager Tor controller connect error: AttributeError: 'NoneType' object has no attribute 'group' in TorManager.py line 176
```
 Tor is getting:

> `GETINFO version`

Reply:

> `250-version=0.2.9.8 (git-a0df013ea241b026)`
> `250 OK`
 I have no idea either. (Better use `repr` strings)
```python
>>> import socket
>>> conn = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
>>> conn.connect(('127.0.0.1', 9151))
>>> conn.sendall('authenticate c5e2d6b540e0b8ea29702e0112740e64f056751d661d03ba0d00d399262e6f77\r\n')
>>> conn.recv(1024*32)
'250 OK\r\n'

>>> conn.sendall('getinfo version\r\n')
>>> conn.recv(1024*32)
'250-version=0.2.8.11 (git-31e7b47fbebe8caf)\r\n250 OK\r\n'

>>> raw_reply = '250-version=0.2.8.11 (git-31e7b47fbebe8caf)\r\n250 OK\r\n'
>>> raw_reply.decode('utf-8')
u'250-version=0.2.8.11 (git-31e7b47fbebe8caf)\r\n250 OK\r\n'
>>> raw_reply.decode('utf-8', 'ignore')
u'250-version=0.2.8.11 (git-31e7b47fbebe8caf)\r\n250 OK\r\n'
>>> raw_reply.decode('utf-8', 'ignore').strip()
u'250-version=0.2.8.11 (git-31e7b47fbebe8caf)\r\n250 OK'
>>> decoded_reply = _
>>> decoded_reply
u'250-version=0.2.8.11 (git-31e7b47fbebe8caf)\r\n250 OK'
>>> import re
>>> re.search('version=([0-9\.]+)', decoded_reply)
<_sre.SRE_Match object at 0x7fc300f3d030>
>>> re.search('version=([0-9\.]+)', decoded_reply).group(1)
u'0.2.8.11'
``` Reproduction is a bit hard at the moment.

The communication is as follows.

(1)
> `PROTOCOLINFO`
```
250-PROTOCOLINFO 1
250-AUTH METHODS=NULL
250-VERSION Tor="0.2.9.8 (git-a0df013ea241b026)"
250 OK
```

(2)
> `AUTHENTICATE`

```
250 OK
```

(3)
> `GETINFO version`

```
250-version=0.2.9.8 (git-a0df013ea241b026)
250 OK
```

-----

This is what ZeroNet gets:

```
[22:07:54] TorManager res_protocol: 250-PROTOCOLINFO 1
250-AUTH METHODS=NULL
250-VERSION Tor="0.2.9.8 (git-a0df013ea241b026)"
250 OK

[22:07:54] TorManager res_auth: 250 OK
[22:07:54] TorManager res_version: 

[22:07:54] TorManager Tor controller connect error: AttributeError: 'NoneType' object has no attribute 'group' in TorManager.py line 184
```

-----

I am not sure yet we gotta blame this on [control-port-filter-python](https://github.com/Whonix/control-port-filter-python). To figure out what Python actually got, could you please try this?
```python
hex_cookie = 'your hex encoded cookie here'
import socket
conn = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
conn.connect(('127.0.0.1', 9151))
conn.sendall('authenticate %s\r\n' % hex_cookie)
print repr(conn.recv(1024*32))

conn.sendall('getinfo version\r\n')
raw_reply = conn.recv(1024*32)

print repr(raw_reply)

decoded_reply = raw_reply.decode('utf-8', 'ignore').strip()
print repr(decoded_reply)

import re
print repr(re.search('version=([0-9\.]+)', decoded_reply).group(1))
```
On my computer:
```
'250 OK\r\n'
'250-version=0.2.8.11 (git-31e7b47fbebe8caf)\r\n250 OK\r\n'
u'250-version=0.2.8.11 (git-31e7b47fbebe8caf)\r\n250 OK'
u'0.2.8.11'
``` Thank you for looking into this so quickly and diligently!

I've put that into a text file, added `#!/usr/bin/env python`, made executable and run it.

```
'250 OK'
'\r\n'
u''
Traceback (most recent call last):
  File "./pytest.py", line 18, in <module>
    print repr(re.search('version=([0-9\.]+)', decoded_reply).group(1))
AttributeError: 'NoneType' object has no attribute 'group'
```

-----

Communication went as follow:

> authenticate your hex encoded cookie here
```
250 OK
```
> `getinfo version`
```
250-version=0.2.9.8 (git-a0df013ea241b026)
250 OK
``` We should probably blame the control port firewall. :unlock: Actually, to me (anonym, author of the new `tor-controlport-filter`) it looks like ZeroNet violates Tor's control language specification. See the PR. I can confirm it fixes this issue for me. Also note that `TorManager.send()` cannot be relied upon as soon as any asynchronous feature of Tor control port is used, e.g. subscribing to some event. You don't use that, but it's worth mentioning. Long term, dropping your own implementation and using stem seems like a fine goal. @adrelanos, did this fix your problem? fred-a-kemp:
> @adrelanos, did this fix your problem?
> 

Works for me! Thanks for the PR!

  On log messages like:
`[18:29:16] Site:1F7b27..nQpw Announced types ['ip4'] in mode startup to 6 trackers in 10.001s, errors: ['udp://tracker.leechers-paradise.org:6969'], slow: ['10s+ http://tracker.tordb.ml:6881/announce']`
or
`[18:31:19] Site:1F7b27..nQpw Queried listModifications from: [<Peer:136.243.32.225>, <Peer:136.243.32.225>, <Peer:136.243.32.225>, <Peer:83.162.192.96>, <Peer:174.63.21.180>]`
zeronet just hangs a long time (~1-5 mins), without responding to requests

Some more log:
```
[18:31:19] Site:1UDbAD..MkoV [FAILED] 87.8.48.197:15441: {'to': 21, 'cmd': 'response', 'error': 'File invalid'}
[18:31:19] Site:1XdLr6..sbrx [FAILED] 83.162.192.96:15442: {'to': 34, 'cmd': 'response', 'error': 'File invalid'}
[18:31:19] FileServer 114.83.43.45 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 231
[18:31:19] FileServer Removing Conn#454 114.83.43.45 [?]...
[18:31:19] FileServer Conn#468 192.210.179.116 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[18:31:19] FileServer Conn#516 536zml6mcwrboffk.onion [?] > Connecting...
[18:31:19] TorManager Creating new socket to 536zml6mcwrboffk.onion:15441
[18:31:19] FileServer 223.148.244.101 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 231
[18:31:19] FileServer Removing Conn#484 223.148.244.101 [?]...
[18:31:19] FileServer Conn#517 l3s7qjjuechqwjqq.onion [?] > Connecting...
[18:31:19] TorManager Creating new socket to l3s7qjjuechqwjqq.onion:15441
[18:31:19] Site:1UDbAD..MkoV [FAILED] 146.0.226.141:15441: {'to': 32, 'cmd': 'response', 'error': 'File invalid'}
[18:31:19] FileServer 39.187.165.167 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 231
[18:31:19] FileServer Removing Conn#445 39.187.165.167 [?]...
[18:31:19] FileServer Conn#518 114.93.100.3 [?] > Connecting...
[18:31:19] FileServer Conn#519 slxwz7fe6m2volyg.onion [?] > Connecting...
[18:31:19] TorManager Creating new socket to slxwz7fe6m2volyg.onion:15441
[18:31:19] FileServer 114.252.75.160 Connect error: error: [Errno 113] No route to host in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 231
[18:31:19] FileServer Removing Conn#433 114.252.75.160 [?]...
[18:31:19] FileServer Conn#520 lfeyaddtybbkwoai.onion [?] > Connecting...
[18:31:19] TorManager Creating new socket to lfeyaddtybbkwoai.onion:15441
[18:31:19] Site:1UDbAD..MkoV [FAILED] 81.101.99.227:15441: {'to': 21, 'cmd': 'response', 'error': 'File invalid'}
[18:31:19] Site:1F7b27..nQpw Queried listModifications from: [<Peer:136.243.32.225>, <Peer:136.243.32.225>, <Peer:136.243.32.225>, <Peer:83.162.192.96>, <Peer:174.63.21.180>]
```

possible fix: use multi-threading Ok here is the log
```
[14:56:55] FileServer uqv72ckqpxtyc5sq.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[14:56:55] FileServer Removing Conn#585 uqv72ckqpxtyc5sq.onion [?]...
[14:56:55] WorkerManager:13NCGa..4qJi uqv72ckqpxtyc5sq.onion:15441: Hash failed: content.json, failed peers: 1
[14:56:55] Ui.UiServer 127.0.0.1 - - [2017-01-10 14:56:55] "GET /Websocket?wrapper_key=27f529068d721943f1e96bfb563d18d155f8241f8bea68b1cabc9e3484feb582 HTTP/1.1" 101 129 31.816014
[14:56:55] Ui.UiServer 127.0.0.1 - - [2017-01-10 14:56:55] "GET /1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/big/sample-loader/?wrapper_nonce=ccf1fb3f3c483958901cbc2785e8b199273e7353749c615b4d2fa510664d3b92 HTTP/1.1" 200 15722 0.000913
[14:56:55] Site:15iysH..1zwb Http tracker http://tracker.tordb.ml:6881/announce?uploaded=0&downloaded=0&numwant=30&compact=1&event=started&peer_id=-ZN0051-dNMDN23HJy9L&port=15441&info_hash=B%9DMf%08%3D%EF%13%06tV%CE%3B%3E%FCF%A9%23G%C0&left=0 error: local variable 'response' referenced before assignment
[14:56:55] Ui.UiServer 127.0.0.1 - - [2017-01-10 14:56:55] "GET /1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/big/sample-loader/files/list.json?_r=_0.1_0.11057656225803547 HTTP/1.1" 200 1087 0.000673
[14:56:55] Site:1QFEUK..Vxtt Queried listModifications from: [<Peer:188.166.30.172>, <Peer:62.210.38.248>, <Peer:198.96.90.57>, <Peer:uknb5s2pbysyqxai.onion>, <Peer:z2wvu3yk6bi5t746.onion>]
[14:56:55] Site:1QFEUK..Vxtt content.json loadContent same json file, skipping
[14:56:55] Site:1QFEUK..Vxtt Bad files: {u'index.html': 2}
[14:56:55] Site:1QFEUK..Vxtt Retry 1 bad files
[14:56:55] Site:1QFEUK..Vxtt New downloadFile pool: len: 1
[14:56:55] Site:1QFEUK..Vxtt Ended downloadFile pool len: 1
[14:56:55] Site:1QFEUK..Vxtt Need connections: 5, Current: 8, Total: 156
[14:56:55] Site:1CiDoB..nw2V Queried hashfield from 1 peers
[14:56:56] Db:ContentDb processDelayed aborted
[14:56:56] FileServer myyrm4zogomizutv.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[14:56:56] FileServer Removing Conn#578 myyrm4zogomizutv.onion [?]...
[14:56:56] FileServer Conn#599 kje2hlnfruhcthgo.onion [?] > Connecting...
[14:56:56] TorManager Creating new socket to kje2hlnfruhcthgo.onion:15441
[14:56:56] Site:1F7b27..nQpw Announced types ['ip4'] in mode startup to 7 trackers in 10.001s, errors: [], slow: ['10s+ http://tracker.tordb.ml:6881/announce']
----lag----
[14:59:17] Site:1F7b27..nQpw Try to get listModifications from peers: [<Peer:83.162.192.96>, <Peer:198.96.90.57>, <Peer:176.50.171.99>, <Peer:188.166.30.172>, <Peer:46.166.148.236>, <Peer:qxv47no2wtr6kb4z.onion>, <Peer:46.166.148.236>, <Peer:46.166.148.236>, <Peer:46.166.148.236>] since: 1483901182
[14:59:17] Site:1GRYnz..tcoo Need connections: 5, Current: 0, Total: 138
[14:59:17] Site:1LbkPo..wiGD Queried listModifications from: [<Peer:78.119.181.5>, <Peer:176.50.171.99>, <Peer:198.96.90.57>]
[14:59:17] Site:1LbkPo..wiGD content.json loadContent same json file, skipping
[14:59:17] WorkerManager:13NCGa..4qJi uqv72ckqpxtyc5sq.onion:15441: No task found, stopping
[14:59:17] WorkerManager:13NCGa..4qJi Removed worker, workers: 5/6
[14:59:17] WorkerManager:16RFqv..CCir Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 16RFqv..CCir>, 'done': False, 'size': 0, 'inner_path': u'content.json', 'peers': None, 'time_started': 1484056596.290893, 'time_action': None, 'priority': 9999, 'failed': [], 'workers_num': 1, 'time_added': 1484056596.290436, 'evt': <gevent.event.AsyncResult object at 0x7f8c4573c310>}
[14:59:17] WorkerManager:16RFqv..CCir 46.166.148.236:31528: Force skipping
[14:59:17] WorkerManager:1NZNtZ..MsUc Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 1NZNtZ..MsUc>, 'done': False, 'size': 521216, 'inner_path': u'data/0chan.db', 'peers': None, 'time_started': 1484056598.306365, 'time_action': None, 'priority': 0, 'failed': [<Peer:172.17.0.1  >, <Peer:45.32.18.196>, <Peer:121.45.102.75>], 'workers_num': 3, 'time_added': 1484056598.304832, 'evt': <gevent.event.AsyncResult object at 0x7f8c572557d0>}
[14:59:17] WorkerManager:1NZNtZ..MsUc 115.199.100.41:15441: Force skipping
[14:59:17] WorkerManager:13NCGa..4qJi Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 13NCGa..4qJi>, 'done': False, 'size': 0, 'inner_path': u'content.json', 'peers': None, 'time_started': 1484056610.308068, 'time_action': None, 'priority': 9999, 'failed': [<Peer:217.234.42.165>, <Peer:uqv72ckqpxtyc5sq.onion>], 'workers_num': 5, 'time_added': 1484056610.306516, 'evt': <gevent.event.AsyncResult object at 0x7f8c57229b90>}
[14:59:17] WorkerManager:13NCGa..4qJi 46.166.148.236:10756: Force skipping
[14:59:17] WorkerManager:1QFEUK..Vxtt Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 1QFEUK..Vxtt>, 'done': False, 'size': 41, 'inner_path': u'index.html', 'peers': None, 'time_started': 1484056602.300939, 'time_action': None, 'priority': 9998, 'failed': [<Peer:183.11.29.170>, <Peer:62.210.38.248>, <Peer:5zhaaivqlumg6yv7.onion>, <Peer:mome26so7u34r2jk.onion>, <Peer:z2wvu3yk6bi5t746.onion>], 'workers_num': 2, 'time_added': 1484056602.299759, 'evt': <gevent.event.AsyncResult object at 0x7f8c457360d0>}
[14:59:17] WorkerManager:1QFEUK..Vxtt 183.141.110.147:15441: Force skipping
[14:59:17] WorkerManager:1AcGB3..UjUT Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 1AcGB3..UjUT>, 'done': False, 'size': 29099, 'inner_path': u'index.html', 'peers': None, 'time_started': 1484056574.56634, 'time_action': None, 'priority': 9998, 'failed': [<Peer:185.38.14.171>, <Peer:83.162.192.96>, <Peer:z5d4b5wa2kbsqkf2.onion>, <Peer:185.38.14.215>], 'workers_num': 3, 'time_added': 1484056574.564733, 'evt': <gevent.event.AsyncResult object at 0x7f8c576ce810>}
[14:59:17] WorkerManager:1AcGB3..UjUT 46.166.148.236:10754: Force skipping
[14:59:17] WorkerManager:1Nv8Y4..isDM Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 1Nv8Y4..isDM>, 'done': False, 'size': 0, 'inner_path': u'content.json', 'peers': None, 'time_started': 1484056563.127799, 'time_action': None, 'priority': 9999, 'failed': [<Peer:144.202.228.211>, <Peer:86.29.63.238>], 'workers_num': 4, 'time_added': 1484056563.126702, 'evt': <gevent.event.AsyncResult object at 0x7f8c570c3110>}
[14:59:17] WorkerManager:1Nv8Y4..isDM 46.166.148.236:10753: Force skipping
```
(forgot to enable --debug_event) (huge log dump)
```
[15:09:27] FileServer Conn#672 123.121.53.192 [v2] > Socket error: SSLError: [SSL: TLSV1_ALERT_PROTOCOL_VERSION] tlsv1 alert protocol version (_ssl.c:1754) in Connection.py line 143 > _sslgte279.py line 464 > _sslgte279.py line 315
[15:09:27] FileServer Removing Conn#672 123.121.53.192 [v2]...
[15:09:27] WorkerManager:1NZNtZ..MsUc 121.45.102.75:15441: No task found, stopping
[15:09:27] WorkerManager:1NZNtZ..MsUc Removed worker, workers: 0/6
[15:09:27] WorkerManager:1NZNtZ..MsUc 121.45.102.75:15441: No task found, stopping
[15:09:27] FileServer 39.181.95.60 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 231
[15:09:27] FileServer Removing Conn#620 39.181.95.60 [?]...
[15:09:27] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/123.x
[15:09:27] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/107.x
[15:09:27] FileServer Conn#702 82.240.3.47  [v2] > Crypt out connection using: tls-rsa (server side: False)...
[15:09:27] - Error packing peer address: Peer:zion.host   
[15:09:27] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/237.x
[15:09:27] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/108.x
[15:09:27] WorkerManager:17SyG6..nWUe 100.35.97.232:15441: Hash correct: w/65.x
[15:09:27] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/160.x
[15:09:27] FileServer Conn#706 n3fyjwuphifelinl.onion [?] > Connecting...
[15:09:27] TorManager Creating new socket to n3fyjwuphifelinl.onion:15441
[15:09:27] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/198.x
[15:09:27] FileServer Conn#632 176.50.171.99 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[15:09:27] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/204.x
[15:09:27] FileServer Conn#707 136.243.32.225 [?] > Connecting...
[15:09:27] WorkerManager:1CiDoB..nw2V Finding peers for optional files: set([1921]) (reset_task: False, find_more: True)
[15:09:27] WorkerManager:1CiDoB..nw2V Starting workers, tasks: 1, peers: 34, workers: 0
[15:09:27] WorkerManager:1CiDoB..nw2V Added worker: 198.91.232.137:15441, workers: 1/6
[15:09:27] WorkerManager:1CiDoB..nw2V Added worker: 146.0.226.141:15441, workers: 2/6
[15:09:27] WorkerManager:1CiDoB..nw2V Added worker: a45r25hfmhosfwb5.onion:15441, workers: 3/6
[15:09:27] WorkerManager:1CiDoB..nw2V Added worker: 177.98.155.13:15441, workers: 4/6
[15:09:27] WorkerManager:1CiDoB..nw2V Added worker: 92.249.133.50:0, workers: 5/6
[15:09:27] WorkerManager:1CiDoB..nw2V Added worker: 76.97.199.210:0, workers: 6/6
[15:09:27] WorkerManager:1CiDoB..nw2V No local result for optional files: set([])
[15:09:27] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/186.x
[15:09:27] FileServer Conn#707 136.243.32.225 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[15:09:27] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/6.x
[15:09:27] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/200.x
[15:09:27] FileServer Conn#700 220.184.143.7 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[15:09:28] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/13.x
[15:09:28] WorkerManager:17SyG6..nWUe 100.35.97.232:15441: Hash correct: w/178.x
[15:09:28] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/2.x
[15:09:28] WorkerManager:17SyG6..nWUe 139.162.100.64:15441: Hash correct: w/121.x
[15:09:28] FileServer Conn#708 52.209.179.198 [?] > Connecting...
[15:09:28] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/50.x
[15:09:28] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/37.x
[15:09:28] FileServer 217.234.35.72 Connect error: error: [Errno 113] No route to host in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 231
[15:09:28] FileServer Removing Conn#695 217.234.35.72 [?]...
[15:09:28] FileServer Conn#709 82.69.68.242 [?] > Connecting...
[15:09:28] FileServer Conn#699 121.45.102.75 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[15:09:28] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/49.x
[15:09:28] FileServer Conn#710 176.9.137.49 [?] > Connecting...
[15:09:28] FileServer Conn#708 52.209.179.198 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[15:09:28] Site:1Bvzxo..S5YT Retry 1 bad files
[15:09:28] Site:1Bvzxo..S5YT New downloadContent pool: len: 1
[15:09:28] Site:1Bvzxo..S5YT Ended downloadContent pool len: 1
[15:09:28] Site:1Bvzxo..S5YT Need connections: 5, Current: 1, Total: 58
[15:09:28] WorkerManager:1Bvzxo..S5YT New task: content.json, peer lock: None, priority: 9999, optional_hash_id: None, tasks started: 1
[15:09:28] WorkerManager:1Bvzxo..S5YT Starting workers, tasks: 1, peers: 0, workers: 0
[15:09:28] WorkerManager:1Bvzxo..S5YT Added worker: pjvgf3iqfcxwhw3l.onion:15441, workers: 1/6
[15:09:28] WorkerManager:1Bvzxo..S5YT Added worker: ymvc4rwcjiy3gw53.onion:15441, workers: 2/6
[15:09:28] WorkerManager:1Bvzxo..S5YT Added worker: 46.166.148.236:16881, workers: 3/6
[15:09:28] WorkerManager:1Bvzxo..S5YT Added worker: 123.116.147.6:15441, workers: 4/6
[15:09:28] WorkerManager:1Bvzxo..S5YT Added worker: 188.162.229.207:0, workers: 5/6
[15:09:28] WorkerManager:1Bvzxo..S5YT Added worker: 46.166.148.236:10755, workers: 6/6
[15:09:28] FileServer Conn#711 pjvgf3iqfcxwhw3l.onion [?] > Connecting...
[15:09:28] TorManager Creating new socket to pjvgf3iqfcxwhw3l.onion:15441
[15:09:28] WorkerManager:1QFEUK..Vxtt 108.61.211.152:15441: No task found, stopping
[15:09:28] WorkerManager:1QFEUK..Vxtt Removed worker, workers: 1/6
[15:09:28] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/0.x
[15:09:28] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: data/links.db
[15:09:28] FileServer Conn#710 176.9.137.49 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[15:09:28] FileServer Conn#709 82.69.68.242 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[15:09:28] WorkerManager:17SyG6..nWUe 100.35.97.232:15441: Hash correct: w/38.x
[15:09:28] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/35.x
[15:09:28] FileServer Conn#712 3lznwqq5mkj3wtl7.onion [?] > Connecting...
[15:09:28] TorManager Creating new socket to 3lznwqq5mkj3wtl7.onion:15441
[15:09:28] FileServer Conn#713 176.50.171.99 [?] > Connecting...
[15:09:28] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/240.x
[15:09:28] FileServer Conn#714 87.2.44.88   [?] > Connecting...
[15:09:28] WorkerManager:1QFEUK..Vxtt 198.96.90.57:15114: Hash failed: index.html, failed peers: 7
[15:09:28] WorkerManager:17SyG6..nWUe 82.240.3.47:15441: Hash correct: w/70.x
[15:09:28] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/128.x
[15:09:28] WorkerManager:1Hh2q9..5P2h 176.9.137.49:15441: Hash correct: content.json
[15:09:28] Site:1Hh2q9..5P2h content.json loadContent same json file, skipping
[15:09:28] SiteManager Saved sites in 0.11s
[15:09:28] SiteManager Updated merger sites in 0.002s
[15:09:28] WorkerManager:1Hh2q9..5P2h New task: data-default/users/content-default.json, peer lock: None, priority: -4, optional_hash_id: None, tasks started: 8
[15:09:28] WorkerManager:1Hh2q9..5P2h Starting workers, tasks: 2, peers: 0, workers: 2
[15:09:28] WorkerManager:1Hh2q9..5P2h New task: img/edit.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 9
[15:09:28] WorkerManager:1Hh2q9..5P2h Starting workers, tasks: 3, peers: 0, workers: 2
[15:09:28] WorkerManager:1Hh2q9..5P2h New task: img/topic-group.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 10
[15:09:28] WorkerManager:1Hh2q9..5P2h Starting workers, tasks: 4, peers: 0, workers: 2
[15:09:28] WorkerManager:1Hh2q9..5P2h New task: img/topic-chat.png, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 11
[15:09:28] WorkerManager:1Hh2q9..5P2h Starting workers, tasks: 5, peers: 0, workers: 2
[15:09:28] WorkerManager:1Hh2q9..5P2h New task: img/loading.gif, peer lock: None, priority: 0, optional_hash_id: None, tasks started: 12
[15:09:28] WorkerManager:1Hh2q9..5P2h Starting workers, tasks: 6, peers: 0, workers: 2
[15:09:28] Site:1Hh2q9..5P2h data/users/content.json loadContent same json file, skipping
[15:09:28] FileServer 101.179.125.18 Connect error: error: [Errno 113] No route to host in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 231
[15:09:28] FileServer Removing Conn#587 101.179.125.18 [?]...
[15:09:28] WorkerManager:17SyG6..nWUe 101.179.125.18:15441: Hash failed: w/235.x, failed peers: 0
[15:09:28] FileServer 222.175.251.218 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 231
[15:09:28] FileServer Removing Conn#651 222.175.251.218 [?]...
[15:09:28] FileServer Conn#715 xlhlzjml7air7mil.onion [?] > Connecting...
[15:09:28] TorManager Creating new socket to xlhlzjml7air7mil.onion:15441
[15:09:28] WorkerManager:1BLueG..tG49 23.236.76.14:15441: Hash failed: data/users/1AWKKjCvCFvUbmrbBtqrMSfAGZ8D6tAVHt/data.json, failed peers: 10
[15:09:28] Site:139hQH..QEMj Queried pex from 2 peers got 3 new peers.
[15:09:28] Site:1Bvzxo..S5YT Queried pex from 1 peers got 0 new peers.
[15:09:28] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/47.x
[15:09:28] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/30.x
[15:09:28] WorkerManager:1Hh2q9..5P2h 176.9.137.49:15441: Hash failed: css/all.css, failed peers: 3
[15:09:28] FileServer GetFile read error: IOError: [Errno 2] No such file or directory: u'data/1MaiL5gfBM1cyb4a8e3iiL8L5gXmoAJu27/data/users/1K6PW55RQ1mGgZRhvJ95rjafUjApsr4UFT/content.json' in FileRequest.py line 172
[15:09:28] FileServer Conn#716 123.121.53.192 [?] > Connecting...
[15:09:28] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/76.x
[15:09:28] WorkerManager:17SyG6..nWUe 100.35.97.232:15441: Hash correct: w/52.x
[15:09:28] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/242.x
[15:09:28] WorkerManager:17SyG6..nWUe 139.162.100.64:15441: Hash correct: w/39.x
[15:09:28] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/33.x
[15:09:28] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/12.x
[15:09:28] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/214.x
[15:09:28] WorkerManager:17SyG6..nWUe 82.240.3.47:15441: Hash correct: w/133.x
[15:09:28] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/29.x
[15:09:28] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/218.x
[15:09:28] FileServer Conn#717 146.0.226.141 [?] > Connecting...
[15:09:28] FileServer Conn#718 a45r25hfmhosfwb5.onion [?] > Connecting...
[15:09:28] TorManager Creating new socket to a45r25hfmhosfwb5.onion:15441
[15:09:28] FileServer Conn#719 177.98.155.13 [?] > Connecting...
[15:09:28] WorkerManager:1CiDoB..nw2V 92.249.133.50:0: Hash failed: big/files/flac_ed/22.dat, failed peers: 4
[15:09:28] WorkerManager:1CiDoB..nw2V 76.97.199.210:0: Hash failed: big/files/flac_ed/22.dat, failed peers: 5
[15:09:28] FileServer Conn#690 112.102.86.50 [v2] > Socket error: SSLError: [SSL: TLSV1_ALERT_PROTOCOL_VERSION] tlsv1 alert protocol version (_ssl.c:1754) in Connection.py line 143 > _sslgte279.py line 464 > _sslgte279.py line 315
[15:09:28] FileServer Removing Conn#690 112.102.86.50 [v2]...
[15:09:28] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/244.x
[15:09:28] WorkerManager:17SyG6..nWUe 100.35.97.232:15441: Hash correct: w/73.x
[15:09:28] FileServer Conn#717 146.0.226.141 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[15:09:28] FileServer Conn#611 218.87.49.75 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[15:09:28] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/224.x
[15:09:28] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/48.x
[15:09:29] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/99.x
[15:09:29] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/195.x
[15:09:29] FileServer Conn#713 176.50.171.99 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[15:09:29] FileServer Conn#720 176.9.146.48 [?] > Connecting...
[15:09:29] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/175.x
[15:09:29] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/24.x
[15:09:29] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/78.x
[15:09:29] WorkerManager:17SyG6..nWUe 100.35.97.232:15441: Hash correct: w/17.x
[15:09:29] FileServer Conn#716 123.121.53.192 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[15:09:29] FileServer Conn#721 ymvc4rwcjiy3gw53.onion [?] > Connecting...
[15:09:29] TorManager Creating new socket to ymvc4rwcjiy3gw53.onion:15441
[15:09:29] FileServer Conn#722 123.116.147.6 [?] > Connecting...
[15:09:29] WorkerManager:17SyG6..nWUe 139.162.100.64:15441: Hash correct: w/15.x
[15:09:29] WorkerManager:17SyG6..nWUe 82.240.3.47:15441: Hash correct: w/149.x
[15:09:29] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/139.x
[15:09:29] FileServer Conn#723 112.102.86.50 [?] > Incoming connection...
[15:09:29] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/67.x
[15:09:29] WorkerManager:1CiDoB..nw2V 146.0.226.141:15441: Hash correct: big/files/flac_ed/22.dat
[15:09:29] WorkerManager:1CiDoB..nw2V Downloaded optional file, adding to hashfield: big/files/flac_ed/22.dat
[15:09:29] WorkerManager:1CiDoB..nw2V 146.0.226.141:15441: No task found, stopping
[15:09:29] WorkerManager:1CiDoB..nw2V Removed worker, workers: 5/6
[15:09:29] - UiWSGIHandler error: error: [Errno 32] Broken pipe in UiServer.py line 39 > pywsgi.py line 910 > pywsgi.py line 896 > pywsgi.py line 742 > pywsgi.py line 764 > pywsgi.py line 727 > pywsgi.py line 702 > _socket2.py line 419 > _socket2.py line 355 > _socket2.py line 323
[15:09:29] Ui.UiServer 127.0.0.1 - - [2017-01-10 15:09:29] "GET /1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/big/files/flac_ed/22.dat?_r=0.4328131981105623 HTTP/1.1" 200 350 2.753699
[15:09:29] - UiWSGIHandler error: error: [Errno 32] Broken pipe in UiServer.py line 39 > pywsgi.py line 910 > pywsgi.py line 896 > pywsgi.py line 742 > pywsgi.py line 764 > pywsgi.py line 727 > pywsgi.py line 702 > _socket2.py line 419 > _socket2.py line 355 > _socket2.py line 323
[15:09:29] Ui.UiServer 127.0.0.1 - - [2017-01-10 15:09:29] "GET /1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/big/files/flac_ed/22.dat?_r=0.312372896165487 HTTP/1.1" 200 350 232.592467
[15:09:29] - UiWSGIHandler error: error: [Errno 32] Broken pipe in UiServer.py line 39 > pywsgi.py line 910 > pywsgi.py line 896 > pywsgi.py line 742 > pywsgi.py line 764 > pywsgi.py line 727 > pywsgi.py line 702 > _socket2.py line 419 > _socket2.py line 355 > _socket2.py line 323
[15:09:29] Ui.UiServer 127.0.0.1 - - [2017-01-10 15:09:29] "GET /1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/big/files/flac_ed/22.dat?_r=0.27337378204635376 HTTP/1.1" 200 350 188.590743
[15:09:29] - UiWSGIHandler error: error: [Errno 32] Broken pipe in UiServer.py line 39 > pywsgi.py line 910 > pywsgi.py line 896 > pywsgi.py line 742 > pywsgi.py line 764 > pywsgi.py line 727 > pywsgi.py line 702 > _socket2.py line 419 > _socket2.py line 355 > _socket2.py line 323
[15:09:29] Ui.UiServer 127.0.0.1 - - [2017-01-10 15:09:29] "GET /1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/big/files/flac_ed/22.dat?_r=0.08655860583207531 HTTP/1.1" 200 350 2.754946
[15:09:29] - UiWSGIHandler error: error: [Errno 32] Broken pipe in UiServer.py line 39 > pywsgi.py line 910 > pywsgi.py line 896 > pywsgi.py line 742 > pywsgi.py line 764 > pywsgi.py line 727 > pywsgi.py line 702 > _socket2.py line 419 > _socket2.py line 355 > _socket2.py line 323
[15:09:29] Ui.UiServer 127.0.0.1 - - [2017-01-10 15:09:29] "GET /1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/big/files/flac_ed/22.dat?_r=0.0030838717422900785 HTTP/1.1" 200 350 210.591004
[15:09:29] - UiWSGIHandler error: error: [Errno 32] Broken pipe in UiServer.py line 39 > pywsgi.py line 910 > pywsgi.py line 896 > pywsgi.py line 742 > pywsgi.py line 764 > pywsgi.py line 727 > pywsgi.py line 702 > _socket2.py line 419 > _socket2.py line 355 > _socket2.py line 323
[15:09:29] Ui.UiServer 127.0.0.1 - - [2017-01-10 15:09:29] "GET /1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/big/files/flac_ed/22.dat?_r=0.9277605786851784 HTTP/1.1" 200 350 166.518788
[15:09:29] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/173.x
[15:09:29] Site:1BLueG..tG49 data/users/1AWKKjCvCFvUbmrbBtqrMSfAGZ8D6tAVHt/data.json file size does not match 47619 <> 47815, Hash: False
[15:09:29] WorkerManager:1BLueG..tG49 198.96.90.57:15114: Hash failed: data/users/1AWKKjCvCFvUbmrbBtqrMSfAGZ8D6tAVHt/data.json, failed peers: 11
[15:09:29] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/26.x
[15:09:29] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/83.x
[15:09:29] WorkerManager:1QFEUK..Vxtt 198.96.90.57:15114: No task found, stopping
[15:09:29] WorkerManager:1QFEUK..Vxtt Removed worker, workers: 0/6
[15:09:29] Site:1NZNtZ..MsUc Queried pex from 2 peers got 0 new peers.
[15:09:29] WorkerManager:1CiDoB..nw2V Check compelte: No tasks
[15:09:29] Site:1CiDoB..nw2V Retry 1 bad files
[15:09:29] Site:1CiDoB..nw2V New downloadFile pool: len: 1
[15:09:29] Site:1CiDoB..nw2V Ended downloadFile pool len: 1
[15:09:29] WorkerManager:1CiDoB..nw2V New task: big/files/flac_ed/1.dat, peer lock: None, priority: 0, optional_hash_id: 22422, tasks started: 1
[15:09:29] FileServer Conn#713 176.50.171.99 [v2] > Socket error: SSLError: [SSL: UNKNOWN_PROTOCOL] unknown protocol (_ssl.c:590) in Connection.py line 163 > Connection.py line 255 > CryptConnection.py line 42 > _sslgte279.py line 702 > _sslgte279.py line 270
[15:09:29] FileServer Removing Conn#713 176.50.171.99 [v2]...
[15:09:29] FileServer 176.50.171.99 Connect error: Exception: Connection event return error in ConnectionServer.py line 142
[15:09:29] WorkerManager:17SyG6..nWUe 100.35.97.232:15441: Hash correct: w/100.x
[15:09:29] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/228.x
[15:09:29] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/125.x
[15:09:29] WorkerManager:17SyG6..nWUe xijjojg6zwlxssw4.onion:15441: Hash correct: w/101.x
[15:09:29] Site:1BLueG..tG49 data/users/1yvSQH5Z7aJra4y9s6KG2kjLeGXYhNgn7/data.json file size does not match 45306 <> 45685, Hash: False
[15:09:29] WorkerManager:1BLueG..tG49 108.61.211.152:15441: Hash failed: data/users/1yvSQH5Z7aJra4y9s6KG2kjLeGXYhNgn7/data.json, failed peers: 9
[15:09:29] FileServer Conn#724 101.179.125.18 [?] > Connecting...
[15:09:29] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/158.x
[15:09:29] FileServer Conn#693 58.33.39.241 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[15:09:29] WorkerManager:1Hh2q9..5P2h 176.9.137.49:15441: Hash failed: img/edit.png, failed peers: 0
[15:09:29] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/171.x
[15:09:29] WorkerManager:17SyG6..nWUe 82.240.3.47:15441: Hash correct: w/126.x
[15:09:29] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/189.x
[15:09:29] Site:1CiDoB..nw2V Queried pex from 2 peers got 0 new peers.
[15:09:29] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/9.x
[15:09:29] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/216.x
[15:09:29] WorkerManager:1Bvzxo..S5YT 188.162.229.207:0: Hash correct: content.json
[15:09:29] WorkerManager:1Bvzxo..S5YT 188.162.229.207:0: No task found, stopping
[15:09:29] WorkerManager:1Bvzxo..S5YT Removed worker, workers: 5/6
[15:09:29] Site:1Bvzxo..S5YT content.json loadContent same json file, skipping
[15:09:29] SiteManager Saved sites in 0.13s
[15:09:29] SiteManager Updated merger sites in 0.002s
[15:09:29] WorkerManager:1CiDoB..nw2V 92.249.133.50:0: No task found, stopping
[15:09:29] WorkerManager:1CiDoB..nw2V Removed worker, workers: 4/6
[15:09:29] WorkerManager:1CiDoB..nw2V 76.97.199.210:0: No task found, stopping
[15:09:29] WorkerManager:1CiDoB..nw2V Removed worker, workers: 3/6
[15:09:29] FileServer 123.133.197.222 Connect error: error: [Errno 113] No route to host in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 231
[15:09:29] FileServer Removing Conn#594 123.133.197.222 [?]...
[15:09:29] WorkerManager:17SyG6..nWUe 139.162.100.64:15441: Hash correct: w/150.x
[15:09:29] WorkerManager:17SyG6..nWUe 100.35.97.232:15441: Hash correct: w/120.x
[15:09:29] WorkerManager:13NCGa..4qJi Starting workers, tasks: 1, peers: 0, workers: 0
[15:09:29] WorkerManager:13NCGa..4qJi Added worker: 46.166.148.236:43935, workers: 1/6
[15:09:29] WorkerManager:13NCGa..4qJi Added worker: 46.166.148.236:80, workers: 2/6
[15:09:29] WorkerManager:13NCGa..4qJi Added worker: 217.234.41.182:15441, workers: 3/6
[15:09:29] WorkerManager:13NCGa..4qJi Added worker: 185.21.216.182:15441, workers: 4/6
[15:09:29] WorkerManager:13NCGa..4qJi Added worker: 46.166.148.236:10754, workers: 5/6
[15:09:29] WorkerManager:13NCGa..4qJi Added worker: 198.96.90.57:15114, workers: 6/6
[15:09:29] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/122.x
[15:09:29] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/89.x
[15:09:29] Site:1Mr5rX..Y5Ba Queried pex from 2 peers got 3 new peers.
[15:09:29] WorkerManager:13NCGa..4qJi 46.166.148.236:43935: No task found, stopping
[15:09:29] WorkerManager:13NCGa..4qJi Removed worker, workers: 5/6
[15:09:29] WorkerManager:13NCGa..4qJi 217.234.41.182:15441: No task found, stopping
[15:09:29] WorkerManager:13NCGa..4qJi Removed worker, workers: 4/6
[15:09:29] WorkerManager:13NCGa..4qJi Starting workers, tasks: 1, peers: 0, workers: 4
[15:09:29] WorkerManager:13NCGa..4qJi Added worker: 217.234.41.182:15441, workers: 5/6
[15:09:29] WorkerManager:13NCGa..4qJi Added worker: 46.166.148.236:10756, workers: 6/6
[15:09:29] Site:13NCGa..4qJi Queried pex from 2 peers got 3 new peers.
[15:09:29] WorkerManager:13NCGa..4qJi 217.234.41.182:15441: No task found, stopping
[15:09:29] WorkerManager:13NCGa..4qJi Removed worker, workers: 5/6
[15:09:29] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/199.x
[15:09:29] WorkerManager:1Bvzxo..S5YT Check compelte: No tasks
[15:09:29] FileServer GetFile read error: IOError: [Errno 2] No such file or directory: u'data/1MaiL5gfBM1cyb4a8e3iiL8L5gXmoAJu27/data/users/1EfmLDysqgowLW291CxbikEMi9ttHfuHEz/content.json' in FileRequest.py line 172
[15:09:29] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/187.x
[15:09:30] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/179.x
[15:09:30] FileServer 80.98.180.101 Connect error: error: [Errno 113] No route to host in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 231
[15:09:30] FileServer Removing Conn#600 80.98.180.101 [?]...
[15:09:30] FileServer Conn#725 3sjxnopgf66rkyeh.onion [?] > Connecting...
[15:09:30] TorManager Creating new socket to 3sjxnopgf66rkyeh.onion:15441
[15:09:30] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/249.x
[15:09:30] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/183.x
[15:09:30] Site:1F7b27..nQpw Queried pex from 2 peers got 1 new peers.
[15:09:30] WorkerManager:17SyG6..nWUe 100.35.97.232:15441: Hash correct: w/236.x
[15:09:30] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/201.x
[15:09:30] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/229.x
[15:09:30] Site:19sZZm..HqKi Need connections: 5, Current: 0, Total: 96
[15:09:30] Site:19sZZm..HqKi Small number of peers detected...query all of peers using pex
[15:09:30] FileServer Conn#726 39.181.95.60 [?] > Connecting...
[15:09:30] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/163.x
[15:09:30] FileServer 181.198.210.16 Connect error: error: [Errno 113] No route to host in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 231
[15:09:30] FileServer Removing Conn#609 181.198.210.16 [?]...
[15:09:30] FileServer Conn#727 ieu4q7dcfqymc3gz.onion [?] > Connecting...
[15:09:30] TorManager Creating new socket to ieu4q7dcfqymc3gz.onion:15441
[15:09:30] Site:1Bvzxo..S5YT Found 6 peers, new: 1, total: 59
[15:09:30] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/36.x
[15:09:30] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/84.x
[15:09:30] Site:1PLAYg..Xvfp Queried hashfield from 5 peers
[15:09:30] Site:1PLAYg..Xvfp Need connections: 5, Current: 23, Total: 1635
[15:09:30] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/181.x
[15:09:30] WorkerManager:17SyG6..nWUe xijjojg6zwlxssw4.onion:15441: Hash correct: w/97.x
[15:09:30] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/91.x
[15:09:30] WorkerManager:17SyG6..nWUe 139.162.100.64:15441: Hash correct: w/106.x
[15:09:30] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/1.x
[15:09:30] WorkerManager:17SyG6..nWUe 100.35.97.232:15441: Hash correct: w/3.x
[15:09:30] WorkerManager:17SyG6..nWUe 185.15.72.63:15441: Hash correct: w/241.x
[15:09:30] WorkerManager:17SyG6..nWUe 82.240.3.47:15441: Hash correct: w/127.x
[15:09:30] WorkerManager:17SyG6..nWUe 188.166.30.172:15441: Hash correct: w/34.x
[15:09:30] Site:1F7b27..nQpw Queried listModifications from: [<Peer:136.243.32.225>, <Peer:136.243.32.225>, <Peer:136.243.32.225>, <Peer:zion.host   >, <Peer:kwp7a4hotazel4t7.onion>]
----lag----
[15:11:28] FileServer Removing Conn#723 112.102.86.50 [v2]...
[15:11:28] FileServer Conn#728 112.102.86.50 [?] > Connecting...
[15:11:28] - Gevent block detected: 116.914212942
[15:11:28] FileServer Conn#729 176.50.171.99 [?] > Connecting...
[15:11:28] Site:153QQi..ThAZ Retry 1 bad files
[15:11:28] Site:153QQi..ThAZ New downloadContent pool: len: 1
[15:11:28] Site:153QQi..ThAZ Ended downloadContent pool len: 1
[15:11:28] Site:153QQi..ThAZ Need connections: 1, Current: 0, Total: 1
[15:11:28] Db:ContentDb processDelayed aborted
[15:11:28] WorkerManager:1Bvzxo..S5YT ymvc4rwcjiy3gw53.onion:15441: Force skipping
[15:11:28] WorkerManager:16RFqv..CCir Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 16RFqv..CCir>, 'done': False, 'size': 0, 'inner_path': u'content.json', 'peers': None, 'time_started': 1484057192.115378, 'time_action': None, 'priority': 9999, 'failed': [<Peer:46.166.148.236>], 'workers_num': 0, 'time_added': 1484057192.114362, 'evt': <gevent.event.AsyncResult object at 0x7f1f09f330d0>}
[15:11:28] Site:16RFqv..CCir Can't update content.json
[15:11:28] WorkerManager:1Hh2q9..5P2h 46.166.148.236:10755: Force skipping
[15:11:28] WorkerManager:13NCGa..4qJi Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 13NCGa..4qJi>, 'done': False, 'size': 0, 'inner_path': u'content.json', 'peers': None, 'time_started': 1484057206.128412, 'time_action': None, 'priority': 9999, 'failed': [<Peer:217.234.41.182>, <Peer:zhfcwv5r3lyt3kqg.onion>, <Peer:uqv72ckqpxtyc5sq.onion>, <Peer:46.166.148.236>, <Peer:46.166.148.236>, <Peer:46.166.148.236>], 'workers_num': 5, 'time_added': 1484057206.126582, 'evt': <gevent.event.AsyncResult object at 0x7f1ee623f090>}
[15:11:28] WorkerManager:13NCGa..4qJi 46.166.148.236:10756: Force skipping
[15:11:28] WorkerManager:1AcGB3..UjUT Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 1AcGB3..UjUT>, 'done': False, 'size': 29099, 'inner_path': u'index.html', 'peers': None, 'time_started': 1484057150.082287, 'time_action': None, 'priority': 9998, 'failed': [<Peer:185.38.14.171>, <Peer:z5d4b5wa2kbsqkf2.onion>, <Peer:m6bgkahsa7a47pyt.onion>, <Peer:uqv72ckqpxtyc5sq.onion>, <Peer:176.9.137.49>, <Peer:bhwik5ttu4jllx2a.onion>, <Peer:46.166.148.236>, <Peer:46.166.148.236>, <Peer:46.166.148.236>], 'workers_num': 0, 'time_added': 1484057150.080634, 'evt': <gevent.event.AsyncResult object at 0x7f1ee64e5a90>}
[15:11:28] WorkerManager:1GP4i6..pLyV Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 1GP4i6..pLyV>, 'done': False, 'size': 403, 'inner_path': u'index.html', 'peers': None, 'time_started': 1484057164.092359, 'time_action': None, 'priority': 9998, 'failed': [<Peer:ia2ans67yvxamfdo.onion>, <Peer:pdegwmntrifuqusc.onion>, <Peer:72mmdowzt4avt2bl.onion>, <Peer:185.61.148.187>, <Peer:uqhxei2sg5bydr6o.onion>, <Peer:108.61.211.152>, <Peer:198.96.90.57>, <Peer:87.183.176.48>, <Peer:46.166.148.236>, <Peer:46.166.148.236>], 'workers_num': 0, 'time_added': 1484057164.091431, 'evt': <gevent.event.AsyncResult object at 0x7f1f09f33bd0>}
[15:11:28] WorkerManager:1Nv8Y4..isDM Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 1Nv8Y4..isDM>, 'done': False, 'size': 0, 'inner_path': u'content.json', 'peers': None, 'time_started': 1484057160.089338, 'time_action': None, 'priority': 9999, 'failed': [<Peer:217.234.42.165>, <Peer:86.29.63.238>, <Peer:46.166.148.236>, <Peer:46.166.148.236>, <Peer:46.166.148.236>, <Peer:46.166.148.236>, <Peer:46.166.148.236>], 'workers_num': 0, 'time_added': 1484057160.08818, 'evt': <gevent.event.AsyncResult object at 0x7f1ee64b37d0>}
[15:11:28] Site:1Nv8Y4..isDM Can't update content.json
[15:11:28] WorkerManager:1CiDoB..nw2V 198.91.232.137:15441: Force skipping
[15:11:28] WorkerManager:1QFEUK..Vxtt Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 1QFEUK..Vxtt>, 'done': False, 'size': 41, 'inner_path': u'index.html', 'peers': None, 'time_started': 1484057198.120726, 'time_action': None, 'priority': 9998, 'failed': [<Peer:183.11.29.170>, <Peer:51.15.40.233>, <Peer:mome26so7u34r2jk.onion>, <Peer:5zhaaivqlumg6yv7.onion>, <Peer:z2wvu3yk6bi5t746.onion>, <Peer:183.141.110.147>, <Peer:108.61.211.152>, <Peer:198.96.90.57>], 'workers_num': 0, 'time_added': 1484057198.119454, 'evt': <gevent.event.AsyncResult object at 0x7f1ee7f12a50>}
[15:11:28] WorkerManager:1NZNtZ..MsUc Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 1NZNtZ..MsUc>, 'done': False, 'size': 521216, 'inner_path': u'data/0chan.db', 'peers': None, 'time_started': 1484057194.1184, 'time_action': None, 'priority': 0, 'failed': [<Peer:172.17.0.1  >, <Peer:45.32.18.196>, <Peer:115.199.100.41>, <Peer:223.73.11.9 >, <Peer:124.79.104.130>, <Peer:121.45.102.75>], 'workers_num': 0, 'time_added': 1484057194.116993, 'evt': <gevent.event.AsyncResult object at 0x7f1f09f52790>}
[15:11:28] FileServer Conn#82 xpjbgkzwfoavbdhs.onion [v2] > [Cleanup] Command pex timeout: 121.54143095
[15:11:28] FileServer Removing Conn#82 xpjbgkzwfoavbdhs.onion [v2]...
[15:11:28] FileServer Conn#267 23.236.76.14 [v2] > [Cleanup] Command getFile timeout: 117.604529858
[15:11:28] FileServer Removing Conn#267 23.236.76.14 [v2]...
[15:11:28] FileServer Conn#477 115.171.22.91 [v2] > [Cleanup] Command listModified timeout: 121.551963091
[15:11:28] FileServer Removing Conn#477 115.171.22.91 [v2]...
[15:11:28] FileServer Conn#588 39.181.94.14 [?] > [Cleanup] Connect timeout: 121.852416039
[15:11:28] FileServer Removing Conn#588 39.181.94.14 [?]...
[15:11:28] FileServer Conn#589 t3uaum3rhkg346aj.onion [?] > [Cleanup] Connect timeout: 121.851112843
[15:11:28] FileServer Removing Conn#589 t3uaum3rhkg346aj.onion [?]...
[15:11:28] FileServer Conn#590 cpoudh3ip4fz47cs.onion [?] > [Cleanup] Connect timeout: 121.850600958
[15:11:28] FileServer Removing Conn#590 cpoudh3ip4fz47cs.onion [?]...
[15:11:28] FileServer Conn#591 46.166.148.92 [?] > [Cleanup] Connect timeout: 121.850147009
[15:11:28] FileServer Removing Conn#591 46.166.148.92 [?]...
[15:11:28] FileServer Conn#592 46.166.148.236 [?] > [Cleanup] Connect timeout: 121.847938061
[15:11:28] FileServer Removing Conn#592 46.166.148.236 [?]...
[15:11:28] FileServer Conn#593 rtr72wr7uoxs755l.onion [?] > [Cleanup] Connect timeout: 121.847282171
[15:11:28] FileServer Removing Conn#593 rtr72wr7uoxs755l.onion [?]...
[15:11:28] FileServer Conn#595 86.188.39.99 [?] > [Cleanup] Connect timeout: 121.842931032
[15:11:28] FileServer Removing Conn#595 86.188.39.99 [?]...
[15:11:28] FileServer Conn#597 39.187.165.167 [?] > [Cleanup] Connect timeout: 121.838072062
[15:11:28] FileServer Removing Conn#597 39.187.165.167 [?]...
[15:11:28] FileServer Conn#598 118.209.51.233 [?] > [Cleanup] Connect timeout: 121.834823847
[15:11:28] FileServer Removing Conn#598 118.209.51.233 [?]...
[15:11:28] FileServer Conn#599 fxg766mzv4lcbwfy.onion [?] > [Cleanup] Connect timeout: 121.834098101
[15:11:28] FileServer Removing Conn#599 fxg766mzv4lcbwfy.onion [?]...
[15:11:28] FileServer Conn#602 b5oh63pi4m6qzree.onion [?] > [Cleanup] Connect timeout: 121.814399958
[15:11:28] FileServer Removing Conn#602 b5oh63pi4m6qzree.onion [?]...
[15:11:28] FileServer Conn#603 gcd6zoqqetc3hfgz.onion [?] > [Cleanup] Connect timeout: 121.813641071
[15:11:28] FileServer Removing Conn#603 gcd6zoqqetc3hfgz.onion [?]...
[15:11:28] FileServer Conn#604 kpam4drekpzbp3xh.onion [?] > [Cleanup] Connect timeout: 121.812856913
[15:11:28] FileServer Removing Conn#604 kpam4drekpzbp3xh.onion [?]...
[15:11:28] FileServer Conn#605 lnjwdgofhfdszrok.onion [?] > [Cleanup] Connect timeout: 121.811807871
[15:11:28] FileServer Removing Conn#605 lnjwdgofhfdszrok.onion [?]...
[15:11:28] FileServer Conn#606 184.75.223.235 [?] > [Cleanup] Connect timeout: 121.80864501
[15:11:28] FileServer Removing Conn#606 184.75.223.235 [?]...
[15:11:28] FileServer Conn#607 103.254.131.57 [?] > [Cleanup] Connect timeout: 121.807208061
[15:11:28] FileServer Removing Conn#607 103.254.131.57 [?]...
[15:11:28] FileServer Conn#608 36.149.199.25 [?] > [Cleanup] Connect timeout: 121.806674957
[15:11:28] FileServer Removing Conn#608 36.149.199.25 [?]...
[15:11:28] FileServer Conn#610 2vqck6zp77dd2hab.onion [?] > [Cleanup] Connect timeout: 121.801651001
[15:11:28] FileServer Removing Conn#610 2vqck6zp77dd2hab.onion [?]...
[15:11:28] FileServer Conn#611 218.87.49.75 [v2] > [Cleanup] Command getFile timeout: 117.627540827
[15:11:28] FileServer Removing Conn#611 218.87.49.75 [v2]...
[15:11:28] FileServer Conn#612 xybqcrxi25msmcqu.onion [?] > [Cleanup] Connect timeout: 121.795057058
[15:11:28] FileServer Removing Conn#612 xybqcrxi25msmcqu.onion [?]...
[15:11:28] FileServer Conn#613 ekdi4dogln3cgpj7.onion [?] > [Cleanup] Connect timeout: 121.794142962
[15:11:28] FileServer Removing Conn#613 ekdi4dogln3cgpj7.onion [?]...
[15:11:28] FileServer Conn#614 cflmgkogzmveff5d.onion [?] > [Cleanup] Connect timeout: 121.793982983
[15:11:28] FileServer Removing Conn#614 cflmgkogzmveff5d.onion [?]...
[15:11:28] FileServer Conn#616 96.22.39.97  [?] > [Cleanup] Connect timeout: 121.792670965
[15:11:28] FileServer Removing Conn#616 96.22.39.97  [?]...
[15:11:28] FileServer Conn#617 87.8.48.197  [?] > [Cleanup] Connect timeout: 121.792194843
[15:11:28] FileServer Removing Conn#617 87.8.48.197  [?]...
[15:11:28] FileServer Conn#619 87.183.176.48 [?] > [Cleanup] Connect timeout: 121.79123807
[15:11:28] FileServer Removing Conn#619 87.183.176.48 [?]...
[15:11:28] FileServer Conn#621 tci5qoi2dqdlzw5x.onion [?] > [Cleanup] Connect timeout: 121.790483952
[15:11:28] FileServer Removing Conn#621 tci5qoi2dqdlzw5x.onion [?]...
[15:11:28] FileServer Conn#622 ci25ipdy5v63dsvv.onion [?] > [Cleanup] Connect timeout: 121.790026903
[15:11:28] FileServer Removing Conn#622 ci25ipdy5v63dsvv.onion [?]...
[15:11:28] FileServer Conn#624 uqv72ckqpxtyc5sq.onion [?] > [Cleanup] Connect timeout: 121.788794041
[15:11:28] FileServer Removing Conn#624 uqv72ckqpxtyc5sq.onion [?]...
[15:11:28] FileServer Conn#625 4c7nqwy2oplk4ii6.onion [?] > [Cleanup] Connect timeout: 121.785182953
[15:11:28] FileServer Removing Conn#625 4c7nqwy2oplk4ii6.onion [?]...
[15:11:28] FileServer Conn#626 ajqizquqqtoruggz.onion [?] > [Cleanup] Connect timeout: 121.784416914
[15:11:28] FileServer Removing Conn#626 ajqizquqqtoruggz.onion [?]...
[15:11:28] FileServer Conn#627 flhqkem7guxfyyuh.onion [?] > [Cleanup] Connect timeout: 121.782914162
[15:11:28] FileServer Removing Conn#627 flhqkem7guxfyyuh.onion [?]...
[15:11:28] FileServer Conn#628 6ffuavyqjbyxlpkt.onion [?] > [Cleanup] Connect timeout: 121.782094002
[15:11:28] FileServer Removing Conn#628 6ffuavyqjbyxlpkt.onion [?]...
[15:11:28] FileServer Conn#629 88.69.232.245 [?] > [Cleanup] Connect timeout: 121.781266928
[15:11:28] FileServer Removing Conn#629 88.69.232.245 [?]...
[15:11:28] FileServer Conn#630 t3whixj64k4ls3ew.onion [?] > [Cleanup] Connect timeout: 121.780531883
[15:11:28] FileServer Removing Conn#630 t3whixj64k4ls3ew.onion [?]...
[15:11:28] FileServer Conn#631 95.84.52.133 [?] > [Cleanup] Connect timeout: 121.780055046
[15:11:28] FileServer Removing Conn#631 95.84.52.133 [?]...
[15:11:28] FileServer Conn#635 mosybb5njwf7jxwr.onion [?] > [Cleanup] Connect timeout: 121.777719021
[15:11:28] FileServer Removing Conn#635 mosybb5njwf7jxwr.onion [?]...
[15:11:28] FileServer Conn#636 juynot5yov3cmt4s.onion [?] > [Cleanup] Connect timeout: 121.777403116
[15:11:28] FileServer Removing Conn#636 juynot5yov3cmt4s.onion [?]...
[15:11:28] FileServer Conn#638 189.250.160.154 [?] > [Cleanup] Connect timeout: 121.776697874
[15:11:28] FileServer Removing Conn#638 189.250.160.154 [?]...
[15:11:28] FileServer Conn#639 row6k2kbwmgrbpkp.onion [?] > [Cleanup] Connect timeout: 121.776641846
[15:11:28] FileServer Removing Conn#639 row6k2kbwmgrbpkp.onion [?]...
[15:11:28] FileServer Conn#640 2czmngpxn4hgqwzn.onion [?] > [Cleanup] Connect timeout: 121.775475979
[15:11:28] FileServer Removing Conn#640 2czmngpxn4hgqwzn.onion [?]...
[15:11:28] FileServer Conn#641 190.31.124.98 [?] > [Cleanup] Connect timeout: 121.774636984
[15:11:28] FileServer Removing Conn#641 190.31.124.98 [?]...
[15:11:28] FileServer Conn#642 110.207.99.15 [?] > [Cleanup] Connect timeout: 121.773781061
[15:11:28] FileServer Removing Conn#642 110.207.99.15 [?]...
[15:11:28] FileServer Conn#643 k33m62xq7ja6q4jf.onion [?] > [Cleanup] Connect timeout: 121.772568941
[15:11:28] FileServer Removing Conn#643 k33m62xq7ja6q4jf.onion [?]...
[15:11:28] FileServer Conn#644 85.86.176.222 [?] > [Cleanup] Connect timeout: 121.772083998
[15:11:28] FileServer Removing Conn#644 85.86.176.222 [?]...
[15:11:28] FileServer Conn#645 zn3uiuosnisdgmhh.onion [?] > [Cleanup] Connect timeout: 121.770817995
[15:11:28] FileServer Removing Conn#645 zn3uiuosnisdgmhh.onion [?]...
[15:11:28] FileServer Conn#646 94.62.108.55 [?] > [Cleanup] Connect timeout: 121.768885136
[15:11:28] FileServer Removing Conn#646 94.62.108.55 [?]...
[15:11:28] FileServer Conn#648 ugxre2p7swxf7d24.onion [?] > [Cleanup] Connect timeout: 121.767945051
[15:11:28] FileServer Removing Conn#648 ugxre2p7swxf7d24.onion [?]...
[15:11:28] FileServer Conn#649 76.97.203.254 [?] > [Cleanup] Connect timeout: 121.76690197
[15:11:28] FileServer Removing Conn#649 76.97.203.254 [?]...
[15:11:28] FileServer Conn#650 bg7urxdua3t6egto.onion [?] > [Cleanup] Connect timeout: 121.766546011
[15:11:28] FileServer Removing Conn#650 bg7urxdua3t6egto.onion [?]...
[15:11:28] FileServer Conn#652 14.204.71.31 [?] > [Cleanup] Connect timeout: 121.764077902
[15:11:28] FileServer Removing Conn#652 14.204.71.31 [?]...
[15:11:28] FileServer Conn#653 n7k6tiquq25su6yn.onion [?] > [Cleanup] Connect timeout: 121.762533903
[15:11:28] FileServer Removing Conn#653 n7k6tiquq25su6yn.onion [?]...
[15:11:28] FileServer Conn#661 198.91.232.137 [v2] > [Cleanup] Connection buff stalled
[15:11:28] FileServer Removing Conn#661 198.91.232.137 [v2]...
[15:11:28] FileServer Conn#667 185.15.72.63 [v2] > [Cleanup] Connection buff stalled
[15:11:28] FileServer Removing Conn#667 185.15.72.63 [v2]...
[15:11:28] FileServer Conn#675 100.35.97.232 [v2] > [Cleanup] Command getFile timeout: 117.683609962
[15:11:28] FileServer Removing Conn#675 100.35.97.232 [v2]...
[15:11:28] FileServer Conn#677 188.166.30.172 [v2] > [Cleanup] Connection buff stalled
[15:11:28] FileServer Removing Conn#677 188.166.30.172 [v2]...
[15:11:28] FileServer Conn#685 139.162.100.64 [v2] > [Cleanup] Command getFile timeout: 117.701452017
[15:11:28] FileServer Removing Conn#685 139.162.100.64 [v2]...
[15:11:28] FileServer Conn#686 46.166.148.236 [?] > [Cleanup] Connect timeout: 121.565898895
[15:11:28] FileServer Removing Conn#686 46.166.148.236 [?]...
[15:11:28] FileServer Conn#688 114.241.13.50 [?] > [Cleanup] Connect timeout: 121.186772108
[15:11:28] FileServer Removing Conn#688 114.241.13.50 [?]...
[15:11:28] FileServer Conn#689 w2jzzwhtyfn6hfy4.onion [?] > [Cleanup] Connect timeout: 121.185582876
[15:11:28] FileServer Removing Conn#689 w2jzzwhtyfn6hfy4.onion [?]...
[15:11:28] FileServer Conn#693 58.33.39.241 [v2] > [Cleanup] Command update timeout: 117.942734957
[15:11:28] FileServer Removing Conn#693 58.33.39.241 [v2]...
[15:11:28] FileServer Conn#694 zubh6cyryfycnboh.onion [?] > [Cleanup] Connect timeout: 121.032944202
[15:11:28] FileServer Removing Conn#694 zubh6cyryfycnboh.onion [?]...
[15:11:28] FileServer Conn#697 73.15.26.61  [?] > [Cleanup] Connect timeout: 120.912351131
[15:11:28] FileServer Removing Conn#697 73.15.26.61  [?]...
[15:11:28] FileServer Conn#698 77.247.181.163 [?] > [Cleanup] Connect timeout: 120.866065025
[15:11:28] FileServer Removing Conn#698 77.247.181.163 [?]...
[15:11:28] FileServer Conn#700 220.184.143.7 [v2] > [Cleanup] Command getHashfield timeout: 117.984951019
[15:11:28] FileServer Removing Conn#700 220.184.143.7 [v2]...
[15:11:28] FileServer Conn#701 xijjojg6zwlxssw4.onion [v2] > [Cleanup] Command getFile timeout: 117.758464098
[15:11:28] FileServer Removing Conn#701 xijjojg6zwlxssw4.onion [v2]...
[15:11:28] FileServer Conn#702 82.240.3.47  [v2] > [Cleanup] Command getFile timeout: 117.64249897
[15:11:28] FileServer Removing Conn#702 82.240.3.47  [v2]...
[15:11:28] FileServer Conn#706 n3fyjwuphifelinl.onion [?] > [Cleanup] Connect timeout: 120.369572878
[15:11:28] FileServer Removing Conn#706 n3fyjwuphifelinl.onion [?]...
[15:11:28] FileServer Conn#710 176.9.137.49 [v2] > [Cleanup] Command getFile timeout: 117.587086201
[15:11:28] FileServer Removing Conn#710 176.9.137.49 [v2]...
[15:11:28] FileServer Conn#711 pjvgf3iqfcxwhw3l.onion [?] > [Cleanup] Connect timeout: 119.932844877
[15:11:28] FileServer Removing Conn#711 pjvgf3iqfcxwhw3l.onion [?]...
[15:11:28] FileServer Conn#712 3lznwqq5mkj3wtl7.onion [v2] > [Cleanup] Command getFile timeout: 118.455833912
[15:11:28] FileServer Removing Conn#712 3lznwqq5mkj3wtl7.onion [v2]...
[15:11:28] FileServer Conn#714 87.2.44.88   [?] > [Cleanup] Connect timeout: 119.763165951
[15:11:28] FileServer Removing Conn#714 87.2.44.88   [?]...
[15:11:28] FileServer Conn#715 xlhlzjml7air7mil.onion [?] > [Cleanup] Connect timeout: 119.621685028
[15:11:28] FileServer Removing Conn#715 xlhlzjml7air7mil.onion [?]...
[15:11:28] FileServer Conn#718 a45r25hfmhosfwb5.onion [?] > [Cleanup] Connect timeout: 119.284955978
[15:11:28] FileServer Removing Conn#718 a45r25hfmhosfwb5.onion [?]...
[15:11:28] FileServer Conn#719 177.98.155.13 [?] > [Cleanup] Connect timeout: 119.284449816
[15:11:28] FileServer Removing Conn#719 177.98.155.13 [?]...
[15:11:28] FileServer Conn#720 176.9.146.48 [?] > [Cleanup] Connect timeout: 119.081954002
[15:11:28] FileServer Removing Conn#720 176.9.146.48 [?]...
[15:11:28] FileServer Conn#721 ymvc4rwcjiy3gw53.onion [?] > [Cleanup] Connect timeout: 118.93059206
[15:11:28] FileServer Removing Conn#721 ymvc4rwcjiy3gw53.onion [?]...
[15:11:28] FileServer Conn#722 123.116.147.6 [?] > [Cleanup] Connect timeout: 118.930299044
[15:11:28] FileServer Removing Conn#722 123.116.147.6 [?]...
[15:11:28] FileServer Conn#724 101.179.125.18 [?] > [Cleanup] Connect timeout: 118.623912096
[15:11:28] FileServer Removing Conn#724 101.179.125.18 [?]...
[15:11:28] FileServer Conn#725 3sjxnopgf66rkyeh.onion [?] > [Cleanup] Connect timeout: 118.094558001
[15:11:28] FileServer Removing Conn#725 3sjxnopgf66rkyeh.onion [?]...
[15:11:28] FileServer Conn#726 39.181.95.60 [?] > [Cleanup] Connect timeout: 117.934322119
[15:11:28] FileServer Removing Conn#726 39.181.95.60 [?]...
[15:11:28] FileServer Conn#727 ieu4q7dcfqymc3gz.onion [?] > [Cleanup] Connect timeout: 117.871855021
[15:11:28] FileServer Removing Conn#727 ieu4q7dcfqymc3gz.onion [?]...
[15:11:28] FileServer zubh6cyryfycnboh.onion Connect error: SOCKS5Error: 0x06: TTL expired in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#730 46.166.148.236 [?] > Connecting...
[15:11:28] FileServer fxg766mzv4lcbwfy.onion Connect error: SOCKS5Error: 0x06: TTL expired in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#731 vynllijpdr2sedc7.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to vynllijpdr2sedc7.onion:15441
[15:11:28] FileServer Removing Conn#231 107.172.11.242 [v2]...
[15:11:28] FileServer Removing Conn#317 106.185.35.18 [v2]...
[15:11:28] FileServer Removing Conn#198 69.12.89.204 [v2]...
[15:11:28] FileServer Removing Conn#678 62.210.38.248 [v2]...
[15:11:28] FileServer Removing Conn#393 123.59.34.84 [v2]...
[15:11:28] FileServer Removing Conn#228 lct3yf2rrm4b2fid.onion [v2]...
[15:11:28] FileServer Removing Conn#229 37.190.212.41 [v2]...
[15:11:28] FileServer Removing Conn#41 zion.host    [v2]...
[15:11:28] FileServer Removing Conn#28 91.65.133.201 [v2]...
[15:11:28] FileServer Removing Conn#680 58.63.146.30 [v2]...
[15:11:28] FileServer Removing Conn#658 50.170.226.231 [v2]...
[15:11:28] FileServer Removing Conn#425 62.28.191.150 [v2]...
[15:11:28] FileServer Removing Conn#351 188.142.197.58 [v2]...
[15:11:28] FileServer a45r25hfmhosfwb5.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] WorkerManager:1CiDoB..nw2V a45r25hfmhosfwb5.onion:15441: No task found, stopping
[15:11:28] WorkerManager:1CiDoB..nw2V Removed worker, workers: 2/6
[15:11:28] FileServer Removing Conn#637 188.166.30.172 [v2]...
[15:11:28] FileServer Removing Conn#149 5.189.150.20 [v2]...
[15:11:28] FileServer gcd6zoqqetc3hfgz.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#732 106.4.215.189 [?] > Connecting...
[15:11:28] FileServer ekdi4dogln3cgpj7.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#733 27.215.40.83 [?] > Connecting...
[15:11:28] FileServer b5oh63pi4m6qzree.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer 2czmngpxn4hgqwzn.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#734 4oahc3swfvcxc4np.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to 4oahc3swfvcxc4np.onion:15441
[15:11:28] FileServer w2jzzwhtyfn6hfy4.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#735 nr5lhl2tg6xfmvfi.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to nr5lhl2tg6xfmvfi.onion:15441
[15:11:28] FileServer cpoudh3ip4fz47cs.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#736 39.170.4.222 [?] > Connecting...
[15:11:28] FileServer t3uaum3rhkg346aj.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#737 vxhvttaqm4hf3owr.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to vxhvttaqm4hf3owr.onion:15441
[15:11:28] FileServer ugxre2p7swxf7d24.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#738 116.30.245.230 [?] > Connecting...
[15:11:28] FileServer 3sjxnopgf66rkyeh.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#739 z2czimhivuljrjbt.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to z2czimhivuljrjbt.onion:15441
[15:11:28] FileServer tci5qoi2dqdlzw5x.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#740 108.185.185.121 [?] > Connecting...
[15:11:28] FileServer xybqcrxi25msmcqu.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#741 41.105.121.174 [?] > Connecting...
[15:11:28] FileServer 4c7nqwy2oplk4ii6.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer lnjwdgofhfdszrok.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#742 xy266jz475jq5oy6.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to xy266jz475jq5oy6.onion:15441
[15:11:28] FileServer ci25ipdy5v63dsvv.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#743 176.9.137.49 [?] > Connecting...
[15:11:28] FileServer t3whixj64k4ls3ew.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#744 j7ijmio3eu4t5gtt.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to j7ijmio3eu4t5gtt.onion:15441
[15:11:28] FileServer 6ffuavyqjbyxlpkt.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#745 lvnjytkzhm64jymu.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to lvnjytkzhm64jymu.onion:15441
[15:11:28] FileServer mosybb5njwf7jxwr.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#746 tracsop3onzonqa3.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to tracsop3onzonqa3.onion:15114
[15:11:28] FileServer bg7urxdua3t6egto.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer ajqizquqqtoruggz.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#747 46.166.148.92 [?] > Connecting...
[15:11:28] FileServer rtr72wr7uoxs755l.onion Connect error: AttributeError: 'NoneType' object has no attribute 'get' in ConnectionServer.py line 139 > Connection.py line 113
[15:11:28] FileServer row6k2kbwmgrbpkp.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#748 fphjth2ymnq4f6xu.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to fphjth2ymnq4f6xu.onion:15441
[15:11:28] FileServer xlhlzjml7air7mil.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#749 103.207.70.37 [?] > Connecting...
[15:11:28] FileServer k33m62xq7ja6q4jf.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer ymvc4rwcjiy3gw53.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] WorkerManager:1Bvzxo..S5YT ymvc4rwcjiy3gw53.onion:15441: No task found, stopping
[15:11:28] WorkerManager:1Bvzxo..S5YT Removed worker, workers: 4/6
[15:11:28] FileServer n3fyjwuphifelinl.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#750 95.19.40.44  [?] > Connecting...
[15:11:28] FileServer kpam4drekpzbp3xh.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#751 64.71.8.118  [?] > Connecting...
[15:11:28] FileServer pjvgf3iqfcxwhw3l.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] WorkerManager:1Bvzxo..S5YT pjvgf3iqfcxwhw3l.onion:15441: No task found, stopping
[15:11:28] WorkerManager:1Bvzxo..S5YT Removed worker, workers: 3/6
[15:11:28] FileServer ieu4q7dcfqymc3gz.onion Connect error: AttributeError: 'NoneType' object has no attribute 'get' in ConnectionServer.py line 139 > Connection.py line 113
[15:11:28] FileServer Conn#752 cqayehbtutng4xc7.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to cqayehbtutng4xc7.onion:15441
[15:11:28] FileServer zn3uiuosnisdgmhh.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer uqv72ckqpxtyc5sq.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#753 zn3uiuosnisdgmhh.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to zn3uiuosnisdgmhh.onion:15441
[15:11:28] FileServer cflmgkogzmveff5d.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer 2vqck6zp77dd2hab.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] WorkerManager:17SyG6..nWUe 2vqck6zp77dd2hab.onion:15441: Hash failed: w/157.x, failed peers: 0
[15:11:28] FileServer n7k6tiquq25su6yn.onion Connect error: SOCKS5Error: 0x04: Host unreachable in ConnectionServer.py line 139 > Connection.py line 97 > TorManager.py line 285 > socks.py line 681 > socks.py line 383 > socks.py line 458
[15:11:28] FileServer Conn#754 oslhde4hmue2a5uo.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to oslhde4hmue2a5uo.onion:15441
[15:11:28] FileServer flhqkem7guxfyyuh.onion Connect error: AttributeError: 'NoneType' object has no attribute 'get' in ConnectionServer.py line 139 > Connection.py line 113
[15:11:28] FileServer Conn#755 39.181.119.37 [?] > Connecting...
[15:11:28] FileServer 123.116.147.6 Connect error: error: [Errno 113] No route to host in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 231
[15:11:28] WorkerManager:1Bvzxo..S5YT 123.116.147.6:15441: No task found, stopping
[15:11:28] WorkerManager:1Bvzxo..S5YT Removed worker, workers: 2/6
[15:11:28] FileServer Removing Conn#679 27foqhxvstvphjco.onion [v2]...
[15:11:28] FileServer juynot5yov3cmt4s.onion Connect error: AttributeError: 'NoneType' object has no attribute 'get' in ConnectionServer.py line 139 > Connection.py line 113
[15:11:28] Db:ZeroTalk Connected to data/1TaLkFrMwvbNsooF4ioKAY9EuxTBTjipT/data/users/zerotalk.db in 0.000s (opened: 5, sqlite version: 2.6.0)...
[15:11:28] FileServer 101.179.125.18 Connect error: error: [Errno 113] No route to host in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 231
[15:11:28] WorkerManager:17SyG6..nWUe 101.179.125.18:15441: Hash failed: w/20.x, failed peers: 0
[15:11:28] FileServer GetFile read error: IOError: [Errno 2] No such file or directory: u'data/1MaiL5gfBM1cyb4a8e3iiL8L5gXmoAJu27/data/users/17ND23oJHqMroRGC9QLdGsMBoJL8dcuExQ/content.json' in FileRequest.py line 172
[15:11:28] FileServer Removing Conn#656 95.60.100.188 [v2]...
[15:11:28] FileServer Removing Conn#708 52.209.179.198 [v2]...
[15:11:28] FileServer Conn#701 xijjojg6zwlxssw4.onion [v2] > Unknown response: {'body': '\t\x00\xe2\x80\x94joseph\x01\x00T\x16\x0c\x00\xe2\x80\x98weaker\xe2\x80\x99\x01\x005\x1a(\x0002f4cf60b2f1dc708c75e10aea1a870504a1b5fc\x01\x00\x9d\x05(\x00056633ac53444390ed3020c162e14d9971bf1786\x01\x00C$\x06\x001bluis\x01\x00\x02\x1d"\x001e1bdj6snf1dnzcgiavkoe2sgukwftpdj9\x01\x00\x83\n\x07\x001ig5ttw\x01\x00\x9f\x13(\x002cd8c9dcb38adf66bf2bdf3fde055c725530648a\x01\x00G$(\x002ec25994cb62261b10fc7921b92a4858f542d5fe\x01\x00D$\x08\x002fxuzapx\x01\x00\xb7\t\x07\x00360x640\x02\x00\xa5 J$\x12\x003aqqeksozepujlhetl\x08\x00\r#\x0b#\x0c#%\\\n#/"\x06#\xbc\x08(\x004bb23f4b866362a9f0e1a3766a067b2b07022ed0\x02\x00\x9d\x05C$\x04\x0056mn\x05\x00\x05]\xab\t@\x01<\x17[\x17\x04\x0059mb\t\x00D$F$C$\xa5 G$B$E$H$J$(\x0066b6ca2572c7442931b16583ba5ec479c2982b03\x01\x00\x9d\x05\x04\x0067mb\t\x00H$F$G$J$B$D$E$\xa5 C$\x04\x0068kb\x01\x00G$(\x006b2cbba57fa212ba602cf86926e2e48e1aa6a5e9\x02\x00\xa5 J$(\x006b599b8426e1a118ad9088675c6d4f324bf2f78c\x01\x00F$\x04\x0075mb\t\x00H$D$I$C$E$G$J$\xa5 B$\x04\x0076kb\x01\x00G$(\x007836c221e37d934dc1835703726d83d63b265f42\x01\x00H$\x04\x0078gb\x06\x00E$F$B$\xa5 C$G$\x04\x0083mb\x07\x00J$H$D$\xa5 C$B$G$\x04\x0084kb\x01\x00G$\x04\x0086gb\x03\x00E$B$C$\x04\x0091mb\t\x00\x0f\x1cE$G$D$J$F$\xa5 C$B$\x04\x0092kb\x01\x00G$\x04\x0094gb\x08\x00E$H$F$B$J$\xa5 C$G$(\x00956b44aa6966d4ce9c5c5cffd473e4a33ff6f6ff\x01\x00\x9d\x05(\x00994cae807a7276dcc108cb06c41d7aa8d9cb1240\x01\x00B$(\x0099aeb5e9869425234c7ccdf5d41f8068cd6a2636\x01\x00C$(\x00a9f6643dd2f5b66754a9fb9bf2466996d55f35f7\x01\x00G$\x04\x00abel\x0c\x00_`d`\x8c`+f0fUf\xc3g\xc8g\xf3g\x1bh#hch\n\x00activistes\x05\x00\xd2\x1a\xde\x1a\x11\r\xcf\x1a\xd0\x1a\n\x00adjudicate\x01\x00\xaf\n\x06\x00agarro\x01\x00\xec\x00\x03\x00ais\x04\x00\xff\x1b\x80\t\x16\x05\x1a\x05\x0f\x00all\xe2\x88\x92pervasive\x01\x00m&\x04\x00\xc3\xa2me\x13\x00\x15\x1c\x07\x06\x9eh\xfd\x1b\x97h\xb6h\xe6h\xe7h\x8b\x0b \r~]NeWh\x88h\x8bh1]\x98\x08\x8b\t\x17\x1c\x07\x00analyis\x01\x00f\x13\n\x00anatomical\x01\x00l&\x07\x00andreas\x19\x00\xb5%\xb6%\xd6%MW\x9a`\x9b`aaba\xb3b\xb4bMcNc\xd7%\xfb%?\x1cT\x1cU\x1cOW\xc0]\x87e\x88e9\x08\xe4\x05\xb2\x13\xf5\x0e\t\x00angeboten\x01\x00:1\x07\x00anglais\x14\x00\xf9\x1b\x12\x1c\x14\x1c\xf9[\x02\\\x13\x1c\xff[\xf1\x1b\x1ej\x98\x01\xab\x04\x81\t\xf3\x1b\xf4\x1b\xf7[\x03\\\x80\t\x98\x08\x8b\t\x17\x1c\x03\x00ani\x03\x00H$11J$\n\x00anonyhorse\x05\x00\x1d\x0eD\x1a@\x0b\x1b\x0e\x1e\x0e\x07\x00antiwar\x03\x00\x97\x16\xd4\x16,\x17\x03\x00ape\x05\x00\x97Rm&\xec\x08l&\x91R\t\x00applicant\x02\x00\x1b\x13\n\x04\x03\x00ara\x06\x00\xd2\x1a\x1e_\xde\x1a\x11\r\xcf\x1a\xd0\x1a\t\x00arriv\xc3\xa9es\x02\x00\xc7\\\xc8\\\x08\x00assaults\x04\x00\x82\x16B\x13\xaf\nl&\x06\x00attach\x07\x00\xb4-\xb2\x07t0{-}\x19m&n&\x0b\x00autocritica\x01\x008\x0f\x07\x00avenger\x0c\x00KaU`\x85`!fNf\xa9g\xeag\x0chIh\xf5\x0eG$l&\x07\x00avna\xc3\xa7o\x03\x00Ij0jDj\x05\x00awoke\x03\x00l&Y\x0em&\x05\x00axiom\x01\x00N\x18(\x00b364727c24e451cd679396319db8fba25bd06ee6\x01\x00J$(\x00b7faf7e2ffb21bbc41da87f527c423436334a21c\x02\x00\xa5 J$\x06\x00ballou\x05\x00Iam`9f\xd5g0h\x0c\x00bankruptcies\x02\x00\x07\x13\x18\x13\x06\x00basica\n\x00B\x0f\xaa\x15\xdb\x1a\x1c\x0cA\x0fU/\xe0\x1a\x11\r\xcf\x1a\xd0\x1a\x0b\x00battlefront\x01\x00E$\x08\x00beetling\x01\x00m&\x06\x00berc\xc3\xa9\x01\x00\xf6\x1b\x07\x00bigsite\x05\x00\xd2^\x91\x18\x8f\x18o\n\xc6^\x03\x00bio\x07\x004^\x1e^H\x1c6^\xea\x08\xaf\x1911\x05\x00bip32&\x00\x8f\n\x00\x02\xd5\n:Y\x08R\x03R\xe9^\xdb^\xb4\x18\x99\x18\x8a\x07\xa68\r\t\xc0\x1a\xf7\x19\xf8\x19\xf9\x19\xfa\x19a\x0e\xfb\x1cGY`\x0b\x86\x08l\nd]\x86\x18Ae*#\x9e\x18\x8f\x187\x00o\ng\x0fh\x0f\x7f\x18\xc6^e\x0b\xe3\t\x06\x00bluwal\r\x00<aB\\\xe1_\x06`O`\x08a\xcaaTe\x9cgm`9f\xd5g0h\x08\x00boneyard\x01\x00D$\x05\x00bossu\x0e\x00KaNa\x83`\x84`\x85`LfMfNf\xe8g\xe9g\xeagFhHhIh\x05\x00bowls\x02\x00\n\x04m&\x08\x00breeches\x01\x00m&\x05\x00bryce\x02\x00@\x16\xe3\x19!\x00bupsdxfa3tp7kcmlhalrhlix2fejeujfe\x01\x00\r\x12\x07\x00burning\x15\x00\xc5\x12\x95\x1c|\r"\x13\x9c\x16U\x18\x1e\x16\x80\x16\x04\x13\x1b\x13\x17\x13\x14\x13\x1d#\xba-H$n&m&\n\x04m\x0eG$l&(\x00c3a8f4608085d0821f8e77c7a77da997251ec05a\x01\x00G$\x08\x00cargando\x06\x00\xd8\x153\n\x1d_L\x12\xf0\nH]\x03\x00cdu\x01\x000\\\n\x00certifying\x05\x00\xd3\x11\xd3\tK\x12\xad\x0cs\t\x03\x00ces/\x00\x8dh\x85h\xaeh@W;]\x9eh\x02\x1c\x8ah|\t\xc4h\xf3\x1b\xadh#\n0]\x02\\\x13\x1c\xf6\x1b\x7f\r\x90\r6]\xf0h1]*\x0b}\r8]\x80\t7]NeWh\x8bh\x98\x08\x8b\t\x17\x1c\x08`\x83`\xccaVeLf\xa1g\xe8gFhv\x08\x02\n\x81\t\xf7[\x03\\\xee\x00\x0b\x00chappie\xe2\x80\x99s\x01\x00\x8c\x19\x0b\x00chetoschizo\x01\x00\xf7\t\x08\x00chlorine\x01\x00n&\x03\x00chm\x08\x00\x18\x12\x02\x12)\x0cZ\x12\\\x12}\x0f\xb0\x0fU\x12\x06\x00cnn\xef\xbc\x9a\x01\x00\x8c\x0f\x07\x00colocar\x08\x00\xe9\x1a\xe7\x1a\x02\x1b\xbb\x15\xcb\x15E\x0f\xae\x15\xfd\x15\x06\x00commit1\x00\x84 \xcd \xe4\n\xbfL\xa2Q\xd6^\xcf&\n\x14~\x19\xf0\x1c7.\x0f\x1a\x95\x18\xa1^\x02\x1d\xb6\t\xa8\x16\xe80\xbf\x02o&UR\xac^\x99\nG\x1af(\x97^\x1b`\xb2\x07\xf9\x1c\x92R\xa0\x14U\x13\x90\x13\x89\x1c\x01\x006\tM\x19\x8f\x18c\x13\xf7\t\nR\x1bRo\n\xc6^\xee\x00\xec\x08\x91Rl&m&\x06\x00com\xc3\xban\x16\x00\x1c\x00\x03\x1b\xd3\x1a}\x17\xd9\x1a\xe2\x1a\xab\x15?\x0f\xa7\x15\xaf\x15\xc6\x15\x19\x1b\x93\x19\xe0\x1a\xdf\x1a\x11\r\xcf\x1a\xd0\x1a\xd8\x1a\xdd\x1a\n\x1b\xd7\x1a\x0c\x00congratulate\x02\x00m\x19m&\x08\x00consigue\x06\x00\xf7\x0c:\x0f8\x0f\xac\x15\xbb\x15\xcb\x15\r\x00contemplative\x01\x00m&\x05\x00corky\x01\x00\xac\x19\x05\x00corpo\x08\x00\x03`k`\xc8aRe7f\x93g\xd2g.h\t\x00countdown\x0f\x00\xae%\xcf%GW-`\x1aa\xacb\x8e%\xd3a\x8ce\xf6%)#\n\x04\x9d\x05B$C$\x05\x00csiro\x02\x00\xb6\x13\xb2\x13\x06\x00cuboid\x01\x00\xfbf\x05\x00cuero\x01\x00\x93\x19\x05\x00cumia\x02\x00D$C$\x07\x00cunning\x01\x00m&(\x00d00fa6fd03cfc72faeeba82887b73040fc63e029\x01\x00I$(\x00d4f65824aba0331216eacb4f776b62bbb270d65c\x01\x00J$(\x00d70541ca968b114190d1bdc558845361be2f48c4\x01\x00B$(\x00d7f512b1c5be9c7623ebb23cb31a36ad409cf8a9\x01\x00B$(\x00d8ee06344e8099ced52a4e5d46d74b6affcc9686\x01\x00\x9d\x05\x06\x00dahlia\r\x00\x7f%\x91%\xe5_\x19a\xabb\xabf|%\xf8_\xf3%o`;f\xd7g2h\x03\x00dcs\x07\x00\xe8f\x92\x17\xac]\xab\t\xf8\x08\xab]\x9d\x05\x08\x00decimals\x01\x00l\x0e\x07\x00deirdre\x03\x00\xb1\x16\xb2\x16\xe3\x19\x07\x00delayms\x05\x00\xb0\x1c\xe3\x1bm\n\x1e\r\x89\x1c\x03\x00deo\t\x00\xb6^\x87\n\xb5^\xb8^\'a\x0b`\xd2aYe\xa6g\r\x00desarrollador\x01\x00\xaa\x15\n\x00destructia\x01\x00m&\x08\x00devolver\x08\x00\xf5\\\xde\x08\x0fF\x10F@\x01\xae\t<\x17[\x17(\x00df8ae91d22330fdc3f9f9c2d3362e2c888d3984d\x01\x00\x9d\x05\x03\x00dfm\x01\x00D$\x07\x00diarias\x02\x00\x16\x05\x1a\x05\x03\x00dig\x15\x00\x9a!\x1bS8\x1a(R\xe4\x0c\x04^z\x134\x17O\x18\xe3\x12\xfb\x0c\x7f\x19\x89\x1c$#\xd8\t\xec\x19\x8b\x1c\x18\x13E$\n\x04m&\t\x00digitized\x04\x00\x0e\x03\xfd\x03\r\x13\xe1\x12\n\x00disrupting\x01\x00\xaf\n\x03\x00dje\x01\x00\x01\n\x03\x00dla\x0b\x00\xc7\x01\xbc\x03.^\xb2_\xc2\n\xcb-k`7f\xd2g.hG$\x06\x00dlc028\x05\x00\x0c]@\x01\xae\t<\x17[\x17\x06\x00dlc036\x05\x00\x0c]@\x01\xae\t<\x17[\x17\x06\x00dlc044\x05\x00\x0c]@\x01\xae\t<\x17[\x17\x06\x00dlc052\x05\x00\x0c]@\x01\xae\t<\x17[\x17\x06\x00dlc060\x05\x00\x0c]@\x01\xae\t<\x17[\x17\x07\x00dmcrypt\x01\x00P@\x08\x00doorstep\x01\x00l&\x05\x00dorki\x03\x00P\x06\x1e\x047\x04\x11\x00double\xe2\x88\x92boundary\x01\x00m&\t\x00downloadsU\x00\xc23G\x12\xf4\'\x04\x12\xfd\n\x01]zQY\x00\xaa\x08]\x0b\xa3\x17c\x19/(mPaP\x16\x05\x1a\x05{\x18\x82\x18\xa8b\xf5\'\xe9\x1b\xcb^\x0e\x05X\x00\x06g\xc3\x1cZ\x00\xf3\'\xed^\x89\x18\xbc2\xd1\n6\x12\xb8\x18\x97]q\x18\xb6\x1c\xc2-\xf2\'"Y\xcc1\x17\x0c*#\x0c\t\x11\t\x1d\x1a\xc7\x1a\xa5#\x99]\xe8i\r\x05\x10\x05\xb2\x07n\x18\xdc\x08\x9e\x17\xbb\x17\x7f\x18\xfd/\t\n\xc0D\xccW3\\S\x00\x9a\x00h(\xca\ng\x19tP`\x02\xaa\t}\x0c]\x0f\x8b\x1c\xad\t\xf5\x0e&\x13@\x01\xae\to\n<\x17[\x17\xc6^\x02\x0b\x05\x00drets\x06\x00\xcd\x1a \x1b\xe1\x1a\x19\x1b\xdd\x1a\n\x1b$\x00e0v61d0dvrkgdnu1qbgznlvaylx8gbcztwqr\x01\x00I\x1a(\x00e684a5538f96d6fad7e81422505b9ada94d07031\x01\x00B$(\x00ed532fb8bff3425dbe8fdc3bb4c458a810c95fcf\x01\x00E$\x03\x00edm\x03\x00D$\xa5 C$\x03\x00efi\x01\x00\xf7\t\x03\x00egg\x11\x00\xec\x1fG\x17\xe1\x04\xe0\x04\xff\x1f\xf20\xb4\x19\xaa\t}\x0cf(\xc3\x08\xe90\x14\x13\x92\nE$B$m&\x08\x00encrypts\t\x00\xc2\x12\xba\x13D\x13\x9e\x13\x84\x13&\x13\x9b\x13?\x13\x02\x0b\x07\x00enfocar\x05\x00\xd8\x1a\xdf\x1a\x11\r\xcf\x1a\xd0\x1a\x05\x00enjoy\xb1\x00qQYQeQiQkQNQPQSQTQ\\QbQjQWQXQOQcQ^Q_QgQQQnQLQVQ[QaQZQ\x08\x0bRQ\xb2\x1ehQlQmQoQUQrQMQdQpQ\x88\x17ug\x11g\x12g\x8d\x17\x8f\x17\x8c\x17\x8e\x17EQ\x90\x17d\nDQeB\xc0^fQ\x05\x1d\x86\x17R^\xd6R\x01]\xb7\nE\x17H\x17c\x14I\x17\tg\x1b\x1fJ\x17KQ\xbc\x0e\xd1\x19\xff\r\x9d][\n\xb6\x0e\xd0\x18\xce\x19\xc4^\xfe\x03:\t\xd5.?\n\xb1\x0eJQ\x9b\x11]\x02v\x17\xbe\x0e\xd2\x19E]b\r\x06\x12`BsB\xb7\x19\xf6\t\xbe\x19\xaa\t}\x0cF\x16\xcb\n\xcc-\xd5R\xb8\x0e\xcf\x19\x08]\xad\tt\x19\xb8-oB\x8cR\x1f`G\x12\xc0\x0e\xd3\x19\xc5#wPi\x14](\x1dM\xc6\x0e9\x14\x10\x17rB1\x175\ta\x16!MR\x03\xec\n^BxR\xb8]qB3\t\x18\n`\x14a\x14\xbfLV\x1a\xba]\xfe\x0c\xf5\x1b\xb2\x0e\xc3\x0e-\x032\x03\'#@\x01\xae\t<\x17[\x17y\x19\n]\x95\x02\xdc\x11\xb6Q\xef\tv-/1\x01\x00\x16\x05\x1a\x056\t\xca\ntP\xb8\x19\xe7\x08\x8e\x19\xac\t`\x02]\x0f\xea\x00\x92\n\xaf\nH$m&J$l&\x08\x00equivale\x01\x00\xcc\x1a\t\x00escuchaba\x01\x00\xff]\x08\x00espiritu\x05\x00\xa2\x0c\x18\x0e\x93\\?\x0b\x15\x0e\t\x00est\xc3\xa1veis\x01\x00\xe6\x1a\x0c\x00expenditures\r\x00\xdb\x01\xf1\\\xd7\x01\x9e\x02\x1bM\xdd\x12\n\x0e\r\x0e\x13\x0e\xe4\x19>\x0b\x05\x0e\x92\n\x08\x00fanciful\x01\x00l&\x07\x00fanelli\x05\x00(as`?f\xdbg6h\x03\x00fck\x01\x00C$\x03\x00fdi\x01\x00\x89\x0f\x06\x00finish-\x00k\x1c\xb2Q\xd1\x1d\x10\x08\xcd\x16\x82!VRc\x14\x81\x16>\x19\']&#|\x18y\x19\xc3#\xc7\t\xeb\x0c\xca3\x18\n`\x14a\x14\x9e\t\xf9\x0e6\x14\xdaE\xbf[q\x19\xea"n\x18\xef\t/15\x18`\x02]\x0f(#*\x06:\x08Y\x0e\x89%m&\n\x04\xaf\nG$n&\xfbf\x08\x00fixed\xe2\x80\xa6\x02\x00z\x1d]\x1d\x06\x00fogged\x01\x00l&\x05\x00folie\x0e\x00\x9ah=aR`y`\x8b`\x1ffCfTf\xa7g\xdfg\xf0g\th:hbh\x07\x00fooling\x02\x00\xff\x13m&\n\x00foundationU\x00PY\xfa\x16lgNY\xe4\x16!YQYKYLY\x1eYOY\x1dY\xa9Q}\x16g\x16f]\x1fYp\x0cL\x1c\x89\ne] Y\xf2\x1a\xe8\x16\xc5\x16\xe4\x01\x89\x16\xa2\x16\x1e\x16;\x14\xa7\x16\x10\x17"Y \x17\xdb\x1aJ\x13\x19\x1b\xfb\x08\xe0\x1a##\xa9^\xaa^\xea\x08\xaf\x197\x1an&\x7f\r\x90\r\xdd\x1a\n\x1bl&\t\np&\rB\xc0D\xaf\x15\xc6\x15^(\xd4\x03\x02\x0b*\x0b}\r\x92&\x8eQ\xac\t\xb0\t\xb2\t`\x02]\x0f6(\x11\r\xce\x13\xd0\x13\xcf\x1a\xd0\x1a\xbaWAXEX_X\x8e\x0f\x95\x0f\xb9Wm\x0eB$m&\x05\x00frase\x06\x00a\x08 _s\x08]\x08q\x08\xa4\x0c\x03\x00gak\x01\x00\x9e\x13\x05\x00globo\r\x00JjEjKjHj0jDjGj\x8c\x0b\x1e\x0fF\x0fIj?\x0f\xa7\x15\x07\x00gooding\x02\x00\x9d\x05C$\n\x00guardarlos\x03\x00W/\x9c\x04]/\x07\x00gurgled\x01\x00m&\x11\x00happened\xe2\x88\x92\xe2\x88\x92two\x01\x00m&\x03\x00hda\x01\x00\x93\x03\x05\x00hiiro\x01\x0011\x06\x00hourly\x11\x00\xa7\tI$E$H$!#F$\xfe\x0c\x1e#D$;j+jB$\xa5 C$G$J$\n\x04\x07\x00hundred=\x00~\x16\xad\x12\xfe0\xea\x16 \x161\x03\x16\x13\xa0\x185\x16u\n\xba\x16\xf80z\x13\xc3\x16\xd4\x08\xe3\x16\x81\\\xa0%\x07&YW\xc1%\xeb%\xae`ua\xc6b`c\xbef<a3\x16\xa7\x08\x86\x0c\x97\x0e\xe3\x11-\x032\x03\xa6\x18\xf4\x16]`)f\xc0g\x19h.\nm&~\\\x18\x13\xe3\x19?\x13f\x13e\x1al&\xce\x13\xd0\x13\xbaWAXEX_X\x8e\x0f\x95\x0fC$\xb9Wn&\x03\x00iba\x04\x00\xa5\x0c2M\x16\n+M\x0e\x00ilovegenerator\x01\x00\xff\x1b\t\x00important\x1c\x01p\x12}\x1e\xa6\x1f[ \xb6\x05k\x0cJ\x1c9\x13\xbc\x1c?#\xf5\x12\xcc\x16\xb1\x13*\x16\xbe\x16[\x18\xb2[D\x19\'\x17\x8cg\xa9\x12K$\xbe\x12,(\\\x0c\xed\x1e\xfd"\tgo\x0c\xa2\x16|\x13\xce\x1f\xa6-m\x16\xa8-t\x0cO\x1c\x08\x13s\x0c\xef\x1b\xa7\x08{\n\xec0{\x13("\xdb\x12\xad\x13\x02\x13j\x16\xc8\x16n\x0c\xe3\x1cm\x0c\xd6\x16\xb6\x16\n\x17\xa8b\xdb\x01\xf1\\w\x0c\x7f\x16\xc9\x16S\x1cq\x0cv\x0c\xb2\x19H\x1cP\x1c\x1f\x16\xa3R+\x13\xf0\x12c\x13\r]p\x0cG\x13L\x1c\xd4\x12*\x17R\x13F\x16+\x162\x16\xa0\x18z\x16r\x0c\x83\x16M\x1c.\x16\xe4\x0c\xef\x16\x04^h\x0c\xcd\x08B\x1b\xe3\x11e\x13\xb3\x16\xf2-\xf4\x16\xd6\x12m\x136\x14\xda\x16N\x13R\x16\xec\x16V\\\x1a\x13>\x0b\x05\x0e\r\x13;\x14\xd9\x16\xe9\x16D\x13\x9e\x13\xb0\x16f(\xea\x089\x14U\x16!\x17\xaf\x19y\x07\xdd\x12]\x138\x14\xf2\'\xb4\x12 \x17\n\x0e\r\x0e\x13\x0e\xe4\x19\x97R)al\x0c:\x13Z\x13K\x1c\xc3#{-\x9f\x11\x04\x13T\x16\xb7\x19`\x02\x95\x02j\x0c]\x0f\x94\x13I\x1c\\(J\x13T\x18\xbb\x12:\x14\x8f&}\x07\x06\x0e\x0f\x0e\x0e\x13\x9b\x13\xf5E\x95R\xa8S\xa9S\xaaS\xabS\xacS\xadS\xaeS\xafS\xb0S\xb1S\xb2S\x0c\r\x0e\rO\x13\xf2\x16\xa9\x18\x9f\n\r\r"\x13F\x13oB\x8cR\t\x0e\x12\x0e\x07\x0e\x10\x0e\xfa\x12\xa2\x18\xa5\x18\xac\x197\x1a\x8b\x1c\xbf[\xaf\x08\xa9\t\xfe\x0c\xef\x12h\x14\xa7\x18\xdc\x12\x1d\x13Y\x13\xa3\x18\xd7\x1a41\xc3\x08\xf7\x08\xe90T\\\x17\x0c\xb7\x12i\x13n(`B\xd7\x01\x9e\x02\x86\x0c\x97\x0e\x1bM|\x19\x90`Yf\xf7gihf\x13\xba\x13G\x19S\x00\x9a\x00H\x13\x83\x13h(\xae\t\xd8\t\xec\x19\x92\n\xdf\x12\xaf\n\x14\x13\xfb\x1b\x7f\t\xc6\x12\xec\x12?\x13d\x13\xdf\x1a\x1d#i(\xbc-:\x01\x91\x02\xa1\x02\xec\x08\xad\t>\x13n&\xd6-\x91R@\x01R\x03\x18\x13<\x17[\x17\xba-^BxR\x98\x08\x8b\t\x11\r\xcf\x1a\xd0\x1a\x17\x1c)#\n\x04\x02\x0bl\x0el&m&\x0b\x00imprimantes\x03\x00;Wv\x08\x02\n\x07\x00infinie\x01\x00\xee\x00\x0b\x00innerradius\x01\x00\xfbf\x0b\x00insider\xe2\x80\x99s\x01\x00\n\x04\x0c\x00intervencion\x0c\x00\xbe\x15\x8c\x0b\x1e\x0f\xd9\x1a\xd3\x1a\xd8\x1a\xdf\x1a\x11\r\xcf\x1a\xd0\x1a\xd7\x1a\xe0\x1a\x08\x00invaskon\x01\x00a(\x05\x00it\xe2\x80\x9d\x01\x00\x1a\x17\x05\x00jerga\x03\x00\x90\x12x\x08\xe7\x0f\t\x00jt2shy7f0\x01\x00\x9d\x05\x05\x00karim\x03\x00pg\xac\t\xee\x00\x05\x00katie\x1a\x00S\x17Q\x17R\x17\xb4\x0c\x91$\xe5_\x19a\'a\xabb|%\x92%\xf8_\xacf\xf3%\xdb\x1a\x03`\xc8aRe\x93g\xe0\x1aG$\x11\r\xcf\x1a\xd0\x1a\xa5 J$\x05\x00kawai\x01\x0011\x05\x00keeps$\x00\x06M#\x16\xd3\x12l\x1a]\x02\x94\x02\xd1\x16\xb2[aB@\x16|\x18&\x0e\xcf\x1cS\tG\x0b\x0c\r)\x0ew\\\r\x13-\x032\x03\x89\x1c\x0eB\x14\x13\x9b\x13\x92\ne\x1aR\x03^BxR\x02\x0b(\x01f\x13\n\x04\xaf\nm&\x0c\x00kinoprosmotr\x02\x00\x16\x05\x1a\x05\x06\x00kopete\x01\x00\xcaW\t\x00kubrat\xef\xbc\x9a\x01\x000X\x05\x00lapka\x01\x00\xc2\n\x05\x00larga\t\x00\xdb\x1a\x1d\x0f\xad\x15\xc7\x15\x93\x19\xe0\x1a\x11\r\xcf\x1a\xd0\x1a\x06\x00leaked\n\x00\xa8\x16\xf03\xa7\x08f(H\x13\n\x04\x83\x13\x02\x0bY\x0em&\x05\x00leaps\x04\x00u\x18t\x16\xaf\nm&\x07\x00leftism\x03\x00\x1f\x17\xda\x17\xe3\x19\x0e\x00letmewatchthis\x02\x00\x16\x05\x1a\x05\x07\x00lgbtqia\x01\x00\xee\x00\r\x00life\xe2\x88\x92giving\x01\x00m&\x06\x00livery\x01\x00m&\x05\x00maj\xc4\x85\x06\x00\'ay`Cf\xdfg:hG$\x0e\x00malwaredomains\x04\x00\x7f\r\x90\r*\x0b}\r\x05\x00mambo\x01\x00q\x18\x05\x00manga\x14\x00X/T/S/S\x02V/W/[/R/\\/R\x02Z/_`+f\xc3g\x1bhY/\x9c\x04]/U/H$\x07\x00manning\t\x00\xa8\x16\xe5\x1es\x1f}`Ff\xe2g=h\xe3\x19\xaf\n,\x00marchtovictorywashingtonremembersyorktownhtd\x01\x00G$\x07\x00mariano\t\x00b`\x88`.fQf\xc6g\xedg hVh\x93\x19\t\x00martialed\x01\x00\xa8\x16\x0c\x00mathematical\x16\x00\xa3\x18\x97\x128R7\x13W\x16\xa4\x18\x12\x13R\x18\t\x0e\x12\x0ej\x13\xf4\x167\t?\x13\xbeL\xe9\x085R\xa5\x18\xa2\x18\x01\x006\t\xaf\n\x07\x00melanie\x06\x00*/\x0bS\x9a\x16\x97\x03\xe3\x19B$\t\x00mentality\x05\x00"\x17\xe3\x19\xc6\x12\xc9\x12m&\r\x00microeconomic\t\x000\x16R\x16\xce\x13\xbaWAXEX\x8e\x0f\x95\x0f\xb9W\x06\x00miltos\x03\x00S\x17Q\x17R\x17\x06\x00mismas\x10\x00\x19\x16\x1a\x16\x1b\x16\x0c\x0f\xdf\x08\xab\x15?\x0f%M\xa7\x15\xd3\x1a\xe2\x08"M\xdf\x1a\x11\r\xcf\x1a\xd0\x1a\n\x00mistreated\x01\x00m&\x08\x00modifier\x14\x00\xdd0\x0c\x1c\x11\x1c\x8c\r\x96\rU\x0f\x7f\r\x90\r}\x17v\x08\x02\n*\x0b}\r\xb7\t\x80\t\xee\x00\x98\x08\x8b\t\x17\x1c\xaf\n\t\x00motodrama\x05\x00Cak`7f\xd2g.h\n\x00nacimiento\t\x00\xf2\x158\x0f\xdb\x1a\xaf\x15\xc6\x15\xe0\x1a\x11\r\xcf\x1a\xd0\x1a\x06\x00netora\x02\x00\xa5 J$\x17\x00nezegarmhfmlayh9rckygrz\x03\x001\x1a\xfb\x0c\xfe\x0c\x06\x00nikkus\x08\x00\x92i\x9f_;\x0f\xda\x15\xa8\x15\xb8\x15\xf2\x15B\x0f\x06\x00nikova\x02\x00\xa5 J$\x06\x00ninite\x04\x00\xbe\x14\xb0\x04\xc2\x14]\\\x05\x00np136\x01\x00G$\x08\x00numbness\x01\x00m&\n\x00numinosity\x01\x00m&\x05\x00obama\x1a\x00h \xf1\x1e\xfd"\xbc\x16\xa2f-\x17/\x17\x82\x16C\x16{\x16f\x16\xce\x1a\x10\x173\x16x\x16\xd5\x1a3(\xde\x1a\n\x04\x11\r\xcf\x1a\xd0\x1a\xdf\x1a6(PXC$\x08\x00oficiais\x01\x00\xe6\x1a\t\x00ooondaaaa\x01\x00w\x17\n\x00optimistic\n\x00,\x16@\x16\xa6R\x0f\x13\x84\x07v-?\x13\xec\x08\x91R\xaf\n\t\x00originals\x02\x00\x9d\x05m&\t\x00other\xe2\x80\x99s\x02\x00\x02\x0b\n\x04\x07\x00packets\x12\x00\x03<\xbf\x12%\x13O\x18\xb3\x13\xc3\x12\x0e\x13f\x13\xec\x12\xb5\x12!\x13H\x13\xe1\x12c\x13\x83\x13\xc6\x12$\x13&\x13\x08\x00pancerne\x01\x00G$\x06\x00passes\x1a\x00\xee I\x17\xac\n\xc7&\x85\r\x95\r\xcbL\xccL\xc4\x12\xe2\x0c\xd5\x12\xc3\x14\x9d\x13a(\xd8\t\xec\x19\xaa\t*\x0b}\x0c}\r\xef\x12n&\n\x04\x80\tl&m&\x08\x00patlabor\x01\x0011\x0b\x00pedoblocker\x0b\x00Q\x06 \x04P\x06\x1f\x04\xe1\t\x1e\x047\x04J\x04a\x06\x10\x00\x11\x00\x06\x00perdio\x01\x00?\x0f\x08\x00p\xc3\xa9riple\x02\x00\xa5h7]\x0f\x00pixelmultiplier\x01\x00\xfbf\x08\x00pla\xc3\xa7ait\x01\x008]\x07\x00pleaded\x07\x00\x11j #\xb9-Y\x0em&\n\x04l&\x07\x00postman\x15\x00\xcc-\xae%GW-`\x1aa\xacb\xf4%FW\x7f%\x91%\xcea\xabfNa\\`c`(f/f\xbfg\xc7g\x18h"h\x0b\x00prehistoric\x01\x00W\x18\t\x00prestarle\x01\x002\\\x0b\x00proficiency\x01\x00\xaf\n\x07\x00prologz\x01\x00\xb2\x07\n\x00protocolos\x07\x00w\t\xafi\x9f\x0b\\\x0f\xbc\x15\xca\x15F\x0f\x07\x00prudent\x02\x00U\x13&\x13\n\x00publicznie\x01\x00\xc2\n\x06\x00pulsar\x02\x00E$D$\x08\x00pussycat\x1a\x00;a\x0fa\n`V`W`}`\x95`\xd0aXe"f#fFf^f\xa4g\xafg\xb5g\xe2g\xfeg\x0eh\x10h=hoh\x03`\xc8aRe\x93g\r\x00pybitcontools\x02\x00\x86\x18\x7f\x18\r\x00raccoon\xe2\x88\x92dog\x01\x00m&\x08\x00raetikon\x01\x00E$\t\x00r\xc3\xa9alit\xc3\xa9\x02\x00\x08\x068]\x07\x00recital\x02\x00\n\x04m&\x07\x00recited\x01\x00m&\x06\x00redraw\x02\x00\xe3\x19l\x0e\x0f\x00reglamentaci\xc3\xb3n\x05\x00\xd8\x1a\xdf\x1a\x11\r\xcf\x1a\xd0\x1a\x08\x00remotest\x01\x00m&\x08\x00renaming\x03\x00\xb6\t*#\n\x04\x08\x00resented\x02\x00l&m&\x08\x00ressorte\x01\x00\xf3\x1b\x0c\x00rest\xe2\x88\x92house\x01\x00m&\x08\x00restores\x02\x00l\x0em&\t\x00r\xc3\xa9sument\x01\x00\xf3\x1b\x0c\x00resurrecting\x05\x00r\x16\x08/&\x02<\x04\xe3\x19\x08\x00retourna\x02\x008]6]\x06\x00rev546\x02\x00r\x18n\x18\x06\x00rev618\x02\x00o\x18n\x18\x0b\x00reviversoft\x01\x00F$\x07\x00rumours\x03\x00\xe0!E>\x83\x1c\x05\x00rural\t\x00\xef\x16H\x13)#\x8e\x0f\x95\x0f\n\x04\xa5 J$m&\t\x00sakyamuni\x01\x00m&\x06\x00salary\x03\x00\x92&\x8eQm&\n\x00sappretent\x01\x00\xf3\x1b\x06\x00scanty\x01\x00l&\n\x00seguran\xc3\xa7a\x02\x00;j+j\t\x00sepulcral\x01\x00\xa7\x0c\x10\x00shoulder\xe2\x88\x92poles\x01\x00m&\r\x00side\xe2\x88\x92leaves\x01\x00m&\x08\x00skeptics\x03\x00\x91\x16Z\x16\x92\n\x06\x00slower\x19\x00\xee\x1c\xe7-\x96\x1ai\x18d]Y(\x1b1\x01`S\x1a\x8b\x1a5\t\xf3\x125\x1av-\xd3\x08M\x1a\x97\x1a\x83\x136(\x01\x006\tl\x0e\n\x04\xaf\nm&\x08\x00smupgame\x04\x00\x0c#%\\\x06#\xbc\x08\x08\x00solvents\x02\x00\xa3\x18\xa2\x18\x0c\x00soundblaster\x02\x00\xba\x13\xec\x12\n\x00soundtrack\x08\x00\x98\x17\n]D$@\x01\xae\t<\x17[\x17\xac\t\x05\x00sovet\x01\x00\x1c\x13\x08\x00sparrowb\x02\x00\xf2\x15\xec\x00\n\x00speedbumps\x03\x00F\x13\'\x13\xa2\x18\x05\x00sprit\x01\x00R\x13\t\x00startmail\x01\x00\x02\x0b\x06\x00sucker\x06\x00\x96%z`Df\xe0g;h\xf5\x0e\x06\x00sue\xc3\xb1o\x08\x00#M\x9a\\\xe2\x08"M\x92\x19n\n\x96\\\xff]\x05\x00sujet\x10\x00\xbc\\\xbd\\\x85\t\x02\\\x13\x1c\x9ah\xfa[\xf5\x1b\x81\t\xf7[\x03\\\xf4\x1b\x98\x08\x8b\t\x17\x1c\xee\x00\x07\x00sultans\x04\x00``,f\xc4g\x1dh\n\x00summertime\x06\x00\x0b`\xd2aYe\xa6g\xa5 D$\x0b\x00superficial\x03\x00\x1e_?\x13m&\x08\x00suprnova\x02\x00\x16\x05\x1a\x05\x07\x00surgido\x05\x00\xda\x1a\xe0\x1a\x11\r\xcf\x1a\xd0\x1a\x04\x00suru\x06\x00\xd2\n\x03_\x06_\x07_\x08_H$\x0f\x00sweet\xe2\x88\x92fleshed\x01\x00m&\x05\x00sybil\x05\x00\x86\x0c\x97\x0e\x1d\x0f\xad\x15\xc7\x15\x0c\x00synchronized\x08\x00\x18\x1f\x9b\x1f\xe5-x-g\x18\xbc-\x02\x0bD$\x1b\x00syv37aip0cszhxvkets2weir6cc\x01\x00\x9d\x05\x06\x00tchaik\x01\x00\xb7\t\x07\x00teniamo\x04\x00_\x08s\x08]\x08q\x08\x08\x00thisbody\x02\x00\x89%\xfbf\x07\x00to\xe2\x88\x92do\x01\x00m&\x07\x00tombant\x01\x00:]\t\x00tornadoes\x01\x00\n\x04\x0b\x00torotateyop\x01\x00\xfbf\x0b\x00trackerless\x03\x00\xb3\x15\xae\x15\xfd\x15\n\x00tradu\xc3\xa7\xc3\xa3o\x01\x00\x90\\\n\x00turtledove\x01\x00D$\x04\x00tuve\x05\x004MZ/0M\x16\n+M\x13\x00uhahsy2kmmwzidifqkr\x03\x00\x93\x02\x91\x02\xa1\x02\t\x00universes\x05\x00$")#\xa6\x18\xec\x12G$\x07\x00unrolls\x05\x00q\x1c&\x00^\x1cV\x1c\x16\x1d\t\x00unwilling\x02\x00Q\x18m&\x07\x00updater\x18\x00\x19\x1d\xd7^\xda^\x19\r\x96\x18\xcb^\xc3\x1c\x89\x18\x8f\x18\r\t\xc0\x1a\xf7\x19\xf8\x19\xf9\x19\xfa\x19o\n\xc6^\x8a\x0c\xb7\t\x7f\x187\x00g\x0fh\x0f(\x01\x04\x00usos\x08\x002M\x16\n+M\xd7\x1a\xdf\x1a\x11\r\xcf\x1a\xd0\x1a\x04\x00uzas\x0b\x00\xfc0\xfb0\xf90\xb5\\\xfd0\xb6\\\xff0\x001\xfe0\xf80\xd4\x08\x0c\x00valentin2105\x01\x00\xee\x00\x08\x00vectores\x01\x00\xa4\x0c\x05\x00vinyl\x07\x00`\\\xd7\nX\\f\\\x9d\x05\n\x04C$\x06\x00violen\x01\x00\xe2\x15\x04\x00vxas\x02\x00\x10\x00\x11\x00\n\x00wallflower\n\x00\xd3a\x90%\xd0%\xf5%\xb0%.`\x1ba\xadb\xaaf11\x0b\x00water\xe2\x88\x92vat\x01\x00m&\x0e\x00white\xe2\x88\x92haired\x01\x00m&\r\x00wolverines\xe2\x80\x99\x01\x00\x14\x17\x11\x00wonderful\xe2\x88\x92\xe2\x88\x92he\x01\x00m&\x04\x00worm\x03\x00\xb2\x07\xaf\nm&\n\x00worple\xe2\x80\x99s\x01\x00\xac\x19\x04\x00wove\x03\x00\xf6\x16\xf4\x16m&\n\x00youruserid\x0c\x00\xb9\x1a#\x1a_\x18\x89\x0c_\x1a-j\xba\x1ae\x0b7\x00\xe3\tg\x0fh\x0f\x04\x00yube\x02\x00\x89\x01\x8b\x01\x05\x00zickt\x01\x00\xb2\x07\x04\x00zola\t\x007aa`o`-f;f\xc5g\xd7g\x1eh2h\x14\x00\xd0\xb0\xd0\xb4\xd0\xb5\xd0\xba\xd0\xb2\xd0\xb0\xd1\x82\xd0\xbd\xd0\xbe\xd0\xb5\x02\x00\x90&m\x0e\x10\x00\xd0\xb0\xd0\xba\xd1\x82\xd0\xb8\xd0\xb2\xd0\xbd\xd1\x8b\xd0\xbc\x01\x00m\x0e\n\x00\xd0\xb1\xd0\xb0\xd1\x80\xd0\xb5\xd1\x8f\x08\x00~`Gf\xe3g>hk`7f\xd2g.h\n\x00\xd0\xb1\xd0\xb0\xd1\x80\xd0\xbe\xd0\xbd\x12\x00JaB\\\xe1_\x06`O`e`v`\x08a\xcaaTe1f@f\x9cg\xc9g\xdcg%h7hm\x0e\x0c\x00\xd0\xb1\xd0\xb0\xd1\x80\xd0\xbe\xd0\xbd\xd0\xb0\x04\x00q`=f\xd9g4h\x0e\x00\xd0\xb1\xd0\xb5\xd0\xb3\xd1\x81\xd1\x82\xd0\xb2\xd0\xb0\x01\x00m\x0e\x16\x00\xd0\xb1\xd0\xb5\xd1\x81\xd1\x81\xd1\x82\xd1\x80\xd0\xb0\xd1\x88\xd0\xbd\xd1\x8b\xd0\xb5\x04\x00m`9f\xd5g0h\n\x00\xd0\xb2\xd0\xb2\xd0\xb5\xd1\x80\xd1\x85\x05\x00|`Ef\xe1g<hm\x0e\x18\x00\xd0\xb2\xd0\xbd\xd1\x83\xd1\x88\xd0\xb8\xd1\x82\xd0\xb5\xd0\xbb\xd1\x8c\xd0\xbd\xd1\x8b\xd1\x85\x01\x00m\x0e\x16\x00\xd0\xb2\xd0\xbe\xd0\xb4\xd0\xbe\xd1\x81\xd1\x85\xd0\xbe\xd0\xb2\xd0\xb8\xd1\x89\xd0\xb5\x01\x00j\x0e\x14\x00\xd0\xb2\xd0\xbe\xd0\xb7\xd0\xb4\xd1\x83\xd1\x88\xd0\xbd\xd0\xbe\xd0\xb3\xd0\xbe\x01\x00m\x0e\x18\x00\xd0\xb2\xd0\xbe\xd0\xbe\xd1\x80\xd1\x83\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xbd\xd0\xbe\xd0\xbc\xd1\x83\x01\x00m\x0e\x1a\x00\xd0\xb2\xd0\xbe\xd1\x81\xd0\xbf\xd1\x80\xd0\xb8\xd0\xbd\xd0\xb8\xd0\xbc\xd0\xb0\xd0\xbb\xd1\x81\xd1\x8f\x01\x00m\x0e\x10\x00\xd0\xb2\xd1\x8b\xd1\x85\xd0\xbe\xd0\xb4\xd0\xb8\xd1\x82\xd1\x8c\x04\x00\x90&\xd1"k&m\x0e\x12\x00\xd0\xb3\xd0\xb0\xd0\xbd\xd0\xb3\xd1\x81\xd1\x82\xd0\xb5\xd1\x80\xd1\x8b\x0e\x00/aYar`v`\x85`>f@fNf\xdag\xdcg\xeag5h7hIh\x0c\x00\xd0\xb3\xd0\xb0\xd1\x80\xd0\xb0\xd0\xb7\xd0\xb4\x02\x00h\x0eR\x0b\x0e\x00\xd0\xb4\xd0\xbe\xd0\xbc\xd0\xb8\xd0\xb0\xd0\xbd\xd0\xb8\x04\x00a`-f\xc5g\x1eh\x16\x00\xd0\xb7\xd0\xb0\xd0\xb3\xd1\x80\xd1\x83\xd0\xb6\xd0\xb0\xd0\xb5\xd1\x82\xd1\x81\xd1\x8f\x02\x00e\x0b\xe3\t\x14\x00\xd0\xb7\xd0\xb0\xd0\xbb\xd0\xbe\xd0\xb6\xd0\xbd\xd0\xb8\xd0\xba\xd0\xbe\xd0\xb2\x01\x00m\x0e\x14\x00\xd0\xb7\xd0\xb0\xd1\x85\xd0\xb2\xd0\xb0\xd1\x82\xd1\x87\xd0\xb8\xd0\xba\xd0\xb8\x04\x00y`Cf\xdfg:h\x0c\x00\xd0\xb7\xd0\xb0\xd1\x89\xd0\xb8\xd1\x82\xd0\xb5\x05\x00\xac\x14\xb0\x04\xc2\x14]\\m\x0e\x14\x00\xd0\xb8\xd1\x81\xd0\xba\xd0\xbe\xd0\xbf\xd0\xb0\xd0\xb5\xd0\xbc\xd1\x8b\xd1\x85\x01\x00m\x0e\x0c\x00\xd0\xba\xd0\xb0\xd0\xbf\xd0\xbb\xd0\xb0\xd0\xbd\x18\x00,a\x13a;aDa\\`d`x`\x87`\x8b`(f0fBfPfTf\xbfg\xc8g\xdeg\xecg\xf0g\x18h#h9hNhbh\x08\x00\xd0\xba\xd0\xbb\xd1\x8b\xd0\xba\x08\x00[`\'f\xbeg\x17h\x07`\xcbaUe\x9fg\n\x00\xd0\xba\xd0\xbb\xd1\x8b\xd0\xba\xd0\xb0\x04\x00\x81`Jf\xe6gBh\x08\x00\xd0\xba\xd0\xbd\xd1\x83\xd1\x82\x04\x00c`/f\xc7g"h\n\x00\xd0\xba\xd0\xbd\xd1\x83\xd1\x82\xd0\xb0\x01\x00m\x0e\x18\x00\xd0\xba\xd0\xbe\xd0\xb0\xd0\xbb\xd0\xb8\xd1\x86\xd0\xb8\xd0\xbe\xd0\xbd\xd0\xbd\xd0\xbe\xd0\xb5\x01\x00m\x0e\x0e\x00\xd0\xba\xd0\xbe\xd0\xbd\xd1\x82\xd0\xb5\xd0\xbd\xd1\x82\x1b\x00g\x0ef\x0e\xb5\x14&\x04\xd2\x18\xd6\x15\xb3\x14\xbd\x14\xe5\t;\x18e\x0b\xe3\t>\x04V\x06\xac\x14\xfe\ni\x0e\xb0\x04\xc2\x14]\\\xae\x14R\x0b\xa9\x14?\x04\xa0\x14M\x19\xbc\x14\x10\x00\xd0\xba\xd0\xbe\xd0\xbd\xd1\x82\xd0\xb5\xd0\xbd\xd1\x82\xd0\xb0\x11\x00\xac\x14\xe6\t\xbe\x14\xb0\x04\xc2\x14]\\\xbf\x14\xa9\x19\xbd\x14\xf4\x08f\x0e\xa9\x14\xa0\x14#\x04e\x0b\xe3\t\xae\x14\n\x00\xd0\xba\xd0\xbe\xd1\x80\xd0\xbd\xd0\xbe\x19\x00\'aGa<a\x13aDa\x06`g`l`\x90`\x91`\xcaaTe3f8fYfZf\x9cg\xccg\xd3g\xf7g\xf9g*h/hihkh\n\x00\xd0\xba\xd0\xbe\xd1\x81\xd1\x82\xd0\xb0\x1f\x00/a1aDaW`^`r`}`\x7f`\x80`\x90`#f*f>fFfHfIfYf\xb5g\xc1g\xdag\xe2g\xe4g\xe5g\xf7g\x10h\x1ah5h=h?hAhih\x0c\x00\xd0\xba\xd1\x80\xd0\xb8\xd1\x81\xd1\x82\xd0\xb8\x17\x00\x10aLa)ai`5f\xceg,hU`o`q`!f;f=f\xa9g\xd7g\xd9g\x0ch2h4h\x03`\xc8aRe\x93g\x16\x00\xd0\xba\xd1\x80\xd0\xb8\xd1\x82\xd0\xb8\xd1\x87\xd0\xb5\xd1\x81\xd0\xba\xd0\xb0\xd1\x8f\x01\x00m\x0e\n\x00\xd0\xba\xd1\x80\xd0\xbe\xd0\xb2\xd1\x8c\r\x00U`!f\xa9g\x0chy`\x88`CfQf\xdfg\xedg:hVhm\x0e\x0e\x00\xd0\xba\xd1\x83\xd0\xbb\xd0\xb0\xd0\xba\xd0\xbe\xd0\xbc\x01\x00m\x0e\x0c\x00\xd0\xbb\xd0\xb8\xd1\x88\xd0\xbd\xd0\xb8\xd0\xbc\x01\x00m\x0e\n\x00\xd0\xbb\xd0\xbe\xd1\x82\xd0\xb0\xd1\x80\t\x00\x10a\x80`\x85`IfNf\xe5g\xeagAhIh\x0e\x00\xd0\xbc\xd0\xb0\xd0\xb7\xd0\xb5\xd0\xbb\xd0\xbb\xd0\xb8\x04\x00x`Bf\xdeg9h\x0e\x00\xd0\xbc\xd0\xb0\xd1\x80\xd1\x88\xd0\xb0\xd0\xbb\xd0\xbb\x11\x009a\x95`^f\xfegoho`|`\x8d`;fEfVf\xd7g\xe1g\xf4g2h<heh\x1c\x00\xd0\xbc\xd0\xb0\xd1\x82\xd0\xb5\xd1\x80\xd0\xb8\xd0\xb0\xd0\xbb\xd0\xb8\xd0\xb7\xd0\xb0\xd1\x86\xd0\xb8\xd0\xb8\x05\x00I\nn`:f\xd6g1h\x14\x00\xd0\xbc\xd0\xb0\xd1\x82\xd0\xb5\xd1\x80\xd0\xb8\xd0\xb0\xd0\xbb\xd0\xbe\xd0\xb2\x02\x00\xbd\x14m\x0e\n\x00\xd0\xbc\xd0\xb0\xd1\x8e\xd1\x82\xd1\x8c\x01\x00h\x0e \x00\xd0\xbc\xd0\xb8\xd0\xbd\xd0\xb8\xd1\x84\xd0\xb8\xd1\x86\xd0\xb8\xd1\x80\xd0\xbe\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x83\xd1\x8e\x01\x00O\x19\x10\x00\xd0\xbc\xd0\xb8\xd1\x81\xd1\x82\xd0\xb5\xd1\x80\xd0\xb8\xd0\xb8\x08\x00Y`h`%f4f\xbbg\xcdg\x14h+h\x16\x00\xd0\xbc\xd1\x96\xd0\xbd\xd1\x96\xd1\x81\xd1\x82\xd0\xb5\xd1\x80\xd1\x81\xd1\x82\xd0\xb2\x01\x00m\x0e\x0c\x00\xd0\xbc\xd0\xbe\xd0\xb6\xd0\xb5\xd1\x88\xd1\x8c\t\x00\x9f\x14\xb5\x14\xa9\x14\xa0\x14\\`(f\xbfg\x18hm\x0e\x0e\x00\xd0\xbc\xd1\x80\xd0\xb0\xd1\x87\xd0\xb5\xd0\xba\xd0\xb0\t\x00Fa\n`\x83`\xd0aXeLf\xa4g\xe8gFh\x18\x00\xd0\xbd\xd0\xb0\xd0\xb2\xd0\xb5\xd0\xb4\xd1\x8b\xd0\xb2\xd0\xb0\xd1\x82\xd1\x8c\xd1\x81\xd1\x8f\x01\x00m\x0e\x1e\x00\xd0\xbd\xd0\xb5\xd0\xb1\xd0\xbb\xd0\xb0\xd0\xb3\xd0\xbe\xd0\xbf\xd1\x80\xd0\xb8\xd1\x8f\xd1\x82\xd0\xbd\xd1\x8b\xd0\xbc\x01\x00m\x0e\n\x00\xd0\xbd\xd0\xbe\xd0\xba\xd0\xb8\xd0\xb0\x03\x00\x04\n\xf8^\xfd^\x10\x00\xd0\xbd\xd0\xbe\xd1\x80\xd1\x82\xd1\x81\xd0\xb0\xd0\xb9\xd0\xb4\x04\x00]`)f\xc0g\x19h\x0e\x00\xd0\xbd\xd0\xbe\xd1\x81\xd0\xbe\xd1\x80\xd0\xbe\xd0\xb3\x04\x00\x89`Rf\xeeg\\h\x14\x00\xd0\xbe\xd0\xb1\xd0\xb5\xd1\x81\xd0\xbf\xd0\xb5\xd1\x87\xd0\xb8\xd1\x82\xd1\x8c\x01\x00m\x0e\x12\x00\xd0\xbe\xd0\xbf\xd0\xb8\xd1\x81\xd1\x8b\xd0\xb2\xd0\xb0\xd0\xb5\xd1\x82\x01\x00m\x0e\x14\x00\xd0\xbe\xd1\x82\xd0\xb6\xd0\xb8\xd0\xbc\xd0\xb0\xd1\x8e\xd1\x82\xd1\x81\xd1\x8f\x01\x00$\x04\x0e\x00\xd0\xbe\xd1\x85\xd0\xbe\xd1\x82\xd0\xbd\xd0\xb8\xd0\xba\x1d\x00Fa\x05`V`\\`\x81`\x91`\xc9aSe"f(fJfZf\x9bg\xafg\xbfg\xe6g\xf9g\x0eh\x18hBhkhk`z`7fDf\xd2g\xe0g.h;h\x10\x00\xd0\xbe\xd1\x85\xd0\xbe\xd1\x82\xd0\xbd\xd0\xb8\xd0\xba\xd0\xb0\x04\x00q`=f\xd9g4h\x14\x00\xd0\xbf\xd0\xb0\xd1\x80\xd0\xbb\xd0\xb0\xd0\xbc\xd0\xb5\xd0\xbd\xd1\x82\xd0\xb5\x01\x00m\x0e\x14\x00\xd0\xbf\xd0\xb5\xd1\x80\xd0\xb5\xd0\xbb\xd1\x96\xd1\x87\xd0\xb8\xd0\xbc\xd0\xbe\x01\x00f\x0e\x0c\x00\xd0\xbf\xd0\xb5\xd1\x80\xd0\xb8\xd0\xbe\xd0\xb4\x02\x00P@m\x0e\x0e\x00\xd0\xbf\xd0\xb5\xd1\x80\xd0\xb8\xd0\xbe\xd0\xb4\xd0\xb0\x01\x00m\x0e\n\x00\xd0\xbf\xd0\xb5\xd1\x81\xd0\xba\xd0\xb8\x04\x00b`.f\xc6g h\x08\x00\xd0\xbf\xd0\xb8\xd1\x82\xd0\xb0\r\x00-a\x83`\x92`\x94`Lf[f]f\xe8g\xfag\xfdgFhlhnh\x12\x00\xd0\xbf\xd0\xbe\xd0\xb4\xd1\x80\xd0\xb0\xd0\xb6\xd0\xb0\xd1\x8e\xd1\x82\x01\x00\x13@\x10\x00\xd0\xbf\xd0\xbe\xd0\xb7\xd0\xb2\xd0\xbe\xd0\xbd\xd0\xb8\xd0\xbb\x01\x00m\x0e\x16\x00\xd0\xbf\xd0\xbe\xd0\xbb\xd1\x8c\xd0\xb7\xd0\xbe\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xb8\xd0\xb5\x01\x00\xfe\n\x0e\x00\xd0\xbf\xd0\xbe\xd0\xbd\xd0\xb8\xd0\xbc\xd0\xb0\xd1\x8f\x02\x00\xa9\x19m\x0e\x0c\x00\xd0\xbf\xd1\x80\xd0\xb0\xd0\xb2\xd0\xb4\xd0\xb0\r\x00Pa\xe5\t\xb4\x14f`\x81`2fJf\xcbg\xe6g\'hBh\xae\x14m\x0e\x18\x00\xd0\xbf\xd1\x80\xd0\xb5\xd0\xb4\xd0\xbb\xd0\xbe\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f\xd1\x85\x01\x00\xb4\x14\x18\x00\xd0\xbf\xd1\x80\xd0\xb5\xd0\xb4\xd0\xbb\xd0\xbe\xd0\xb6\xd0\xb5\xd0\xbd\xd0\xbd\xd1\x8b\xd0\xb9\x01\x00m\x0e\x16\x00\xd0\xbf\xd1\x80\xd0\xb5\xd0\xb4\xd1\x83\xd0\xbf\xd1\x80\xd0\xb5\xd0\xb4\xd0\xb8\xd0\xbb\x01\x00m\x0e\x14\x00\xd0\xbf\xd1\x80\xd0\xb5\xd1\x81\xd1\x82\xd1\x83\xd0\xbf\xd0\xbd\xd0\xb8\xd0\xba\t\x009as`\x88`?fQf\xdbg\xedg6hVh\x14\x00\xd0\xbf\xd1\x80\xd0\xb5\xd1\x82\xd0\xb5\xd0\xbd\xd0\xb4\xd1\x83\xd0\xb5\xd1\x82\x01\x00\n\n\x10\x00\xd0\xbf\xd1\x80\xd0\xb8\xd0\xb2\xd1\x8b\xd0\xba\xd0\xbb\xd0\xb8\x01\x00m\x0e\x10\x00\xd0\xbf\xd1\x80\xd0\xb8\xd0\xb4\xd1\x83\xd1\x80\xd0\xbe\xd0\xba\n\x00\x0ea:a\x06`\t`\xcaa\xcfaTeWe\x9cg\xa3g\x10\x00\xd0\xbf\xd1\x80\xd0\xb8\xd0\xbc\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x82\x01\x00m\x0e\x0e\x00\xd0\xbf\xd1\x80\xd0\xbe\xd0\xb4\xd0\xb0\xd0\xb6\xd1\x83\x04\x00#\x04\xd1"k&m\x0e\x18\x00\xd0\xbf\xd1\x80\xd0\xbe\xd0\xb8\xd0\xb7\xd0\xb2\xd0\xbe\xd0\xb4\xd1\x81\xd1\x82\xd0\xb2\xd0\xb5\x01\x00m\x0e\x1a\x00\xd1\x80\xd0\xb0\xd0\xb7\xd1\x80\xd0\xb8\xd1\x81\xd0\xbe\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8b\xd1\x85\x04\x00W`#f\xb5g\x10h\n\x00\xd1\x80\xd0\xb0\xd0\xbb\xd1\x8c\xd1\x84\x1d\x00#ap`<f\xd8g3h\t`T`W`o`\x82`\x92`\xcfaWe f#f;fKf[f\xa3g\xa8g\xb5g\xd7g\xe7g\xfag\x0bh\x10h2hDhlh\x14\x00\xd1\x80\xd0\xb0\xd1\x81\xd0\xba\xd1\x80\xd1\x8b\xd0\xb2\xd0\xb0\xd1\x82\xd1\x8c\x03\x00i\x19g\x19\xb4\x14\x18\x00\xd1\x80\xd0\xb0\xd1\x81\xd0\xbf\xd1\x80\xd0\xb5\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8f\xd0\xb5\xd1\x82\x01\x00m\x0e\x06\x00\xd1\x80\xd0\xb8\xd0\xbe+\x00Ua\x10a0aCa[a>a\x13aV`l`v`x`\x7f`\x82`\x83`\x87`\x95`"f8f@fBfHfKfLfPf^f\xafg\xd3g\xdcg\xdeg\xe4g\xe7g\xe8g\xecg\xfeg\x0eh/h7h9h?hDhFhNhoh\x10\x00\xd1\x81\xd0\xb0\xd0\xb4\xd0\xb8\xd1\x82\xd1\x8c\xd1\x81\xd1\x8f\x01\x00m\x0e\x0c\x00\xd1\x81\xd0\xb0\xd1\x82\xd0\xb8\xd1\x80\xd0\xb0\x1a\x00<aNai`5f\xceg,h``j`q`\x85`,f6f=fNf\xc4g\xd0g\xd9g\xeag\x1dh-h4hIh\x8a`Sf\xefg]h\x0c\x00\xd1\x81\xd0\xb2\xd0\xb8\xd1\x81\xd1\x82\xd0\xb8\x04\x00U`!f\xa9g\x0ch\x0e\x00\xd1\x81\xd0\xb2\xd0\xbe\xd0\xb4\xd0\xb8\xd1\x82\xd1\x8c\x01\x00m\x0e\x0c\x00\xd1\x81\xd0\xb2\xd0\xbe\xd0\xb8\xd0\xbc\xd0\xb8\x07\x00Ae#\x04e\x0b\xe3\t\xd1"k&m\x0e\x08\x00\xd1\x81\xd0\xb5\xd0\xbc\xd0\xb8\n\x00Fao`r`;f>f\xd7g\xdag2h5hm\x0e\x08\x00\xd1\x81\xd0\xb8\xd0\xba\xd0\xb0R\x00=a\'aAa:aEa[a\x11a+a\x0faYa\x82`Kf\xe7gDh\x93`\x96`\\f_f\xfcg\xffgmhqhi`5f\xceg,hZ`\\```c`d`l`r`w`y`~`\x81`\x8d`\x90`\x95`&f(f,f/f0f8f>fAfCfGfJfVfYf^f\xbdg\xbfg\xc4g\xc7g\xc8g\xd3g\xdag\xddg\xdfg\xe3g\xe6g\xf4g\xf7g\xfeg\x16h\x18h\x1dh"h#h/h5h8h:h>hBhehihoh\x0e\x00\xd1\x81\xd0\xba\xd0\xb0\xd0\xb7\xd0\xb0\xd0\xbd\xd0\xbe\x01\x00m\x0e\x0c\x00\xd1\x81\xd0\xba\xd0\xb0\xd0\xb7\xd0\xba\xd0\xb0n\x00/aOax`Bf\xdeg9h\x0ea\x10a&aKaR`r`\x1ff>f\xa7g\xdag\th5h\x05`\x07`e`\xc9a\xcbaSeUe1f\x9bg\x9fg\xc9g%hB\\\xe1_\x08`O`U`V`W`]`g`j`q`v`w`\x83`\x84`\x86`\x87`\x8b`\x94`\x95`\x96`\x08a\xccaVe!f"f#f)f3f6f=f@fAfLfMfOfPfTf]f^f_f\xa1g\xa9g\xafg\xb5g\xc0g\xccg\xd0g\xd9g\xdcg\xddg\xe8g\xe9g\xebg\xecg\xf0g\xfdg\xfeg\xffg\x0ch\x0eh\x10h\x19h*h-h4h7h8hFhHhLhNhbhnhohqhz`Df\xe0g;h\x08\x00\xd1\x81\xd0\xba\xd0\xb0\xd0\xbc\x01\x00\xa4\x14\x14\x00\xd1\x81\xd0\xba\xd0\xb0\xd1\x87\xd0\xb5\xd0\xbd\xd0\xbd\xd0\xbe\xd0\xbc\xd1\x83\x04\x00\xbe\x14\xb0\x04\xc2\x14]\\\n\x00\xd1\x81\xd0\xbb\xd0\xb0\xd0\xb1\xd0\xbe\x02\x00\xb5\x14m\x0e\x05\x00\xd1\x81\xd0\xbe2\x01\x00\xfd^\x14\x00\xd1\x81\xd0\xbe\xd0\xb1\xd0\xb8\xd1\x80\xd0\xb0\xd1\x8e\xd1\x82\xd1\x81\xd1\x8f\x01\x00\xae\x14\x14\x00\xd1\x81\xd0\xbf\xd0\xbb\xd0\xbe\xd1\x87\xd0\xb5\xd0\xbd\xd0\xbd\xd0\xbe\xd0\xb9\x01\x00m\x0e\x16\x00\xd1\x81\xd0\xbf\xd1\x80\xd0\xb0\xd0\xb2\xd0\xb5\xd0\xb4\xd0\xbb\xd0\xb8\xd0\xb2\xd0\xbe\x02\x00O\x19m\x0e\x14\x00\xd1\x81\xd1\x82\xd0\xb5\xd1\x80\xd0\xbb\xd0\xb8\xd0\xbd\xd0\xb3\xd0\xbe\xd0\xb2\x04\x00\x86`Of\xebgLh\x12\x00\xd1\x81\xd1\x87\xd0\xb8\xd1\x82\xd0\xb0\xd0\xbb\xd0\xb8\xd1\x81\xd1\x8c\x01\x00m\x0e\x08\x00\xd1\x82\xd0\xb0\xd1\x81\xd0\xba\x01\x00\xb4\x14\x08\x00\xd1\x82\xd0\xb2\xd0\xbe\xd0\xb8\x0c\x00\xaf\x14i`5f\xceg,h|`Ef\xe1g<h\x90&P@m\x0e\x06\x00\xd1\x82\xd0\xb5\xd0\xbc,\x00s^n^Z\\\xd2\x18\x9f\x14\x13@\xfc^\x04\n\xd6\x15\xf8^\xa9\x19\x15@\xc7\nb^Ia\x8a\x19\xa8\x19\xac\x14?\x04e\x0b\x8e&\xb0\x04\xe3\t\xc2\x14\xd1"k&\x90&]\\$\x04\xbd\x14\x11\x16\xa7\x19m\x0eO\x19^`\x83`*fLf\xc1g\xe8g\x1ahFh\xae\x14M\x19\x08\x00\xd1\x82\xd0\xb5\xd0\xbc\xd0\xb0\x1a\x00\x93]\x95]\n\x0b\x92]\xd4\\\xd5\\\xd2\\p\n\xd7\\^\\Z\\\xb6\x14\xd7\nX\\f\\\n\nb\\\x9f\n\x82`Kf\xe7gDh\xae\x14\xd1"k&m\x0e\x0e\x00\xd1\x82\xd0\xb5\xd1\x80\xd1\x80\xd0\xb5\xd0\xbd\xd1\x81\x12\x00AaYab`r`s`}`.f>f?fFf\xc6g\xdag\xdbg\xe2g h5h6h=h\x14\x00\xd1\x82\xd0\xbe\xd1\x80\xd0\xbc\xd0\xb0\xd1\x88\xd0\xba\xd0\xb0\xd0\xbc\xd0\xb8\x04\x00|`Ef\xe1g<h\x14\x00\xd1\x82\xd1\x80\xd0\xb0\xd0\xbd\xd0\xb7\xd0\xb0\xd0\xba\xd1\x86\xd0\xb8\xd1\x8e\x06\x00i\x19g\x19\xb4\x14\xa8C\xf0\x03\xa7C\x10\x00\xd1\x82\xd1\x80\xd0\xb5\xd0\xba\xd0\xb5\xd1\x80\xd0\xb0\xd1\x85\x02\x00\xd1"k&\x0c\x00\xd1\x82\xd1\x83\xd0\xbc\xd0\xb0\xd0\xbd\xd0\xb5\x01\x00m\x0e\x16\x00\xd1\x83\xd1\x81\xd1\x82\xd1\x80\xd0\xbe\xd0\xb9\xd1\x81\xd1\x82\xd0\xb2\xd0\xb0\xc2\xbb\x02\x00\xd1"k&\x06\x00\xd1\x84\xd0\xb3\xd0\xb8\x01\x00m\x0e\x0e\x00\xd1\x84\xd0\xb8\xd0\xbb\xd1\x8c\xd0\xbc\xd0\xbe\xd0\xb2m\x00I\n\x92^\x0ea\x12a$a\'a*a/a3aAaUa\x10a\x15a%a,a0a7a:aBaCaEaFaGaIaJaMaQaXa[a\x11a\x14a(a+a-a2a4a5a6a<a=a>a?a@aLaOaRaZa\x0fa\x13a"a#a&a)a.a1a8a;aDaHaKaNaPaWa9aYaSa#\x04\xbc\x14i`5f\xceg,h\x08`\t`X`Z```\x81`\x84`\x96`\xcca\xcfaVeWe$f&f,fJfMf_f\xa1g\xa3g\xbag\xbdg\xc4g\xe6g\xe9g\xffg\x12h\x16h\x1dhBhHhqh\x03`\xc8aRe\x93gm\x0e\x14\x00\xd1\x84\xd0\xb8\xd0\xbd\xd0\xb0\xd0\xbd\xd1\x81\xd0\xb8\xd1\x80\xd1\x83\xd1\x8f\x01\x00m\x0e\x0e\x00\xd1\x85\xd0\xbe\xd1\x81\xd1\x82\xd0\xb8\xd0\xbd\xd0\xb3\x04\x00$\x04?\x04e\x0b\xe3\t\x10\x00\xd1\x85\xd0\xbe\xd1\x81\xd1\x82\xd0\xb8\xd0\xbd\xd0\xb3\xd0\xb0\x03\x00\xa9\x19$\x04\xf4\x08\x0e\x00\xd1\x86\xd0\xb5\xd0\xbd\xd1\x82\xd1\x80\xd0\xbe\xd0\xb2\x03\x00$\x04\xb4\x14m\x0e\n\x00\xd1\x88\xd0\xbb\xd1\x8f\xd0\xbf\xd0\xb5\x05\x00\x10aB\\\xe1_O`\x08a\x0e\x00\xd1\x89\xd1\x83\xd0\xbf\xd0\xb0\xd0\xbb\xd0\xb5\xd1\x86\x01\x00m\x0e\x10\x00\xd1\x8d\xd0\xba\xd1\x81\xd0\xbf\xd0\xb5\xd1\x80\xd1\x82\xd1\x8b\x01\x00m\x0e\x0c\x00\xe0\xae\x8e\xe0\xae\xa9\xe0\xae\xa4\xe0\xaf\x81\x03\x00\x7f\\.\n~\\\x1b\x00\xe0\xae\x8e\xe0\xae\xaa\xe0\xaf\x8d\xe0\xae\xaa\xe0\xaf\x8b\xe0\xae\xa4\xe0\xaf\x81\xe0\xae\xae\xe0\xaf\x8d\x03\x00\x7f\\.\n~\\\x15\x00\xe0\xae\x9a\xe0\xae\xbf\xe0\xae\xa9\xe0\xaf\x8d\xe0\xae\xa9\xe0\xae\x9a\xe0\xaf\x8d\x03\x00\x7f\\.\n~\\!\x00\xe0\xae\x9a\xe0\xaf\x86\xe0\xae\xaf\xe0\xaf\x8d\xe0\xae\xaf\xe0\xae\xb2\xe0\xae\xbe\xe0\xae\xae\xe0\xaf\x8d\xe0\xae\xa9\xe0\xaf\x81\x03\x00\x7f\\.\n~\\\x18\x00\xe0\xae\xae\xe0\xaf\x81\xe0\xae\xb1\xe0\xaf\x88\xe0\xae\xa4\xe0\xae\xbe\xe0\xae\xa9\xe0\xaf\x8d\x03\x00\x7f\\.\n~\\\x1b\x00\xe0\xae\xb5\xe0\xae\xb0\xe0\xaf\x81\xe0\xae\xae\xe0\xaf\x8d\xe0\xae\xaa\xe0\xaf\x8b\xe0\xae\xa4\xe0\xaf\x81\x03\x00\x7f\\.\n~\\\x18\x00\xe0\xae\xb5\xe0\xae\xbe\xe0\xae\xb4\xe0\xaf\x8d\xe0\xae\xb5\xe0\xae\xbf\xe0\xae\xa9\xe0\xaf\x8d\x03\x00\x7f\\.\n~\\*\x00\xe0\xae\xb5\xe0\xae\xbf\xe0\xae\xb3\xe0\xaf\x88\xe0\xae\xaf\xe0\xae\xbe\xe0\xae\x9f\xe0\xaf\x81\xe0\xae\xae\xe0\xaf\x8d\xe0\xae\xaa\xe0\xaf\x8b\xe0\xae\xa4\xe0\xaf\x81\x03\x00\x7f\\.\n~\\\x0f\x00site:0lists.bit\x01\x00\xab\x00\x12\x00site:zeropaste.bit\x01\x00\xbd\x07\'\x00site:1Eou8bzWUaCrVBMk29av9ZYBbsjdprmWNL\x03\x00\xd2\x08\xf50\xf60&\x00site:1VdtxFnN5bh6rqSmGTPsE8kjLTR4F1H1S\x04\x00\xf1\x08lSjSiS\'\x00site:13FjN4eS9HsDNydPgkW6d4AwnXFnjVp3Ym\x01\x00\x9b\n\'\x00link:1KzDGFWuVgniDVaKBdS1cY91FZBQeKbZMn\x1a\x00f\x00h\x00i\x00\x98\x00g\x00a\x06]\x06(\x01(\n\xb7\t\x11\x00\x10\x00R\x06\x98\x08A\x02B\x02\x1f\x03 \x03O\x06\xef\x00Y\x06`\x06\xa3\x06\xa4\x06\xa5\x06e\x07\x18\x00link:forum.curlybear.bit\x05\x00\x7f\x02\x11\x00\x10\x00x\x02e\x07\'\x00link:195TNKe7aZbYT7cEjLXnKQ52487qpwas5x\x03\x00a\x06\x1d\x04`\x06\'\x00link:165eqHdoQfyf7CGVqtVCGNDvMBZhwVSJBL\x01\x00s\x08\x0f\x00link:0chats.bit\x03\x00\x11\x00\x10\x00e\x07\x11\x00link:emojiday.bit\x03\x00\x11\x00\x10\x00e\x07\x10\x00link:playat0.bit\x03\x00\x11\x00\x10\x00e\x07\x13\x00link:zerodomain.bit\x03\x00\x11\x00\x10\x00e\x07\x15\x00link:zeroidentity.bit\x03\x00\x11\x00\x10\x00e\x07', 'to': 3, 'cmd': 'response', 'location': 14894, 'size': 14894}
[15:11:28] FileServer Conn#712 3lznwqq5mkj3wtl7.onion [v2] > Unknown response: {'to': 1, 'cmd': 'response', 'error': "File read error: IOError: [Errno 2] No such file or directory: u'data/1BLueGvui1GdbtsjcKqCf4F67uKfritG49/data/users/1AWKKjCvCFvUbmrbBtqrMSfAGZ8D6tAVHt/data.json' in FileRequest.py line 172"}
[15:11:28] FileServer 39.181.95.60 Connect error: error: [Errno 111] Connection refused in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 231
[15:11:28] WorkerManager:1CiDoB..nw2V Found optional files after query hashtable connected peers: 1/1
[15:11:28] WorkerManager:1CiDoB..nw2V Starting workers, tasks: 1, peers: 153, workers: 2
[15:11:28] WorkerManager:1CiDoB..nw2V Added worker: 192.36.27.4:15441, workers: 3/6
[15:11:28] WorkerManager:1CiDoB..nw2V Added worker: 186.135.2.168:15441, workers: 4/6
[15:11:28] WorkerManager:1CiDoB..nw2V Added worker: 206.251.88.220:0, workers: 5/6
[15:11:28] WorkerManager:1CiDoB..nw2V Added worker: 2.103.12.103:15441, workers: 6/6
[15:11:28] WorkerManager:1CiDoB..nw2V No connected hashtable result for optional files: set([])
[15:11:28] Site:157npZ..k8dH Announced types ['ip4'] in mode startup to 7 trackers in 121.971s, errors: [], slow: ['10s+ http://tracker.tordb.ml:6881/announce', '1.06s http://tracker1.wasabii.com.tw:6969/announce']
[15:11:28] Site:17SyG6..nWUe Announced types ['ip4'] in mode start to 7 trackers in 121.734s, errors: [], slow: ['10s+ http://tracker.tordb.ml:6881/announce', '1.08s http://tracker1.wasabii.com.tw:6969/announce']
[15:11:28] Site:1GRYnz..tcoo Announced types ['ip4'] in mode startup to 7 trackers in 120.105s, errors: [], slow: ['10s+ http://tracker.tordb.ml:6881/announce']
[15:11:28] Site:1Gfey7..fcdp [FAILED] 114.241.13.50:15441: {'exception': 'Timeout'}
[15:11:28] Site:1Gfey7..fcdp [FAILED] 58.33.39.241:15441: {'exception': 'Timeout'}
[15:11:28] Site:1Bvzxo..S5YT Announced types ['ip4'] in mode startup to 6 trackers in 118.105s, errors: ['udp://tracker.leechers-paradise.org:6969'], slow: ['10s+ http://tracker.tordb.ml:6881/announce', '118.10s http://tracker1.wasabii.com.tw:6969/announce']
[15:11:28] Site:157npZ..k8dH Http tracker http://tracker.tordb.ml:6881/announce?uploaded=0&downloaded=0&numwant=30&compact=1&event=started&peer_id=-ZN0051-MBZrfQX3TANk&port=15441&info_hash=cb%23%DF%D7%5D%82-%B4v%7D%E6%D1%E6%09%3BF%99%89%05&left=0 error: local variable 'response' referenced before assignment
[15:11:28] Site:17SyG6..nWUe Http tracker http://tracker.tordb.ml:6881/announce?uploaded=0&downloaded=0&numwant=30&compact=1&event=started&peer_id=-ZN0051-MBZrfQX3TANk&port=15441&info_hash=T%DB%19%3A%04%E4%0DU%E6%AB%D1%0B%E4%80%26%27%3En%BBq&left=0 error: local variable 'response' referenced before assignment
[15:11:28] Site:1GRYnz..tcoo Http tracker http://tracker.tordb.ml:6881/announce?uploaded=0&downloaded=0&numwant=30&compact=1&event=started&peer_id=-ZN0051-MBZrfQX3TANk&port=15441&info_hash=h%B0OG%60%05%F9%7C%5D.%B0%EB%8A%91%AF%E1%84kPq&left=0 error: local variable 'response' referenced before assignment
[15:11:28] Site:1Bvzxo..S5YT Http tracker http://tracker.tordb.ml:6881/announce?uploaded=0&downloaded=0&numwant=30&compact=1&event=started&peer_id=-ZN0051-MBZrfQX3TANk&port=15441&info_hash=%94%7Cx%B8c%D6%AC%F68%D9%A2%09s%EA%0F%F4%5Bw%EF1&left=0 error: local variable 'response' referenced before assignment
[15:11:28] Site:153QQi..ThAZ Small number of peers detected...query all of peers using pex
[15:11:28] WorkerManager:153QQi..ThAZ New task: content.json, peer lock: None, priority: 9999, optional_hash_id: None, tasks started: 1
[15:11:28] WorkerManager:153QQi..ThAZ Starting workers, tasks: 1, peers: 0, workers: 0
[15:11:28] WorkerManager:153QQi..ThAZ Added worker: 46.166.148.236:10753, workers: 1/6
[15:11:28] WorkerManager:1Bvzxo..S5YT 46.166.148.236:10755: Force skipping
[15:11:28] Site:16RFqv..CCir Download content.json failed, check_modifications: False
[15:11:28] FileServer 46.166.148.236 Connect error: Worker stopped
[15:11:28] WorkerManager:13NCGa..4qJi 46.166.148.236:10756: Hash failed: content.json, failed peers: 6
[15:11:28] Site:1Nv8Y4..isDM Download content.json failed, check_modifications: False
[15:11:28] FileServer Conn#756 198.91.232.137 [?] > Connecting...
[15:11:28] FileServer 39.181.94.14 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#757 jlqeg3vkbcebflz4.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to jlqeg3vkbcebflz4.onion:15441
[15:11:28] FileServer Conn#758 2x7sq67b6raod7a7.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to 2x7sq67b6raod7a7.onion:15441
[15:11:28] FileServer 46.166.148.92 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#759 2wdvexcsmf22kv4g.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to 2wdvexcsmf22kv4g.onion:15441
[15:11:28] WorkerManager:17SyG6..nWUe 46.166.148.236:10754: Hash failed: w/71.x, failed peers: 0
[15:11:28] FileServer Conn#760 46.246.32.83 [?] > Connecting...
[15:11:28] FileServer Conn#761 88.147.206.85 [?] > Connecting...
[15:11:28] FileServer Conn#762 115.206.132.80 [?] > Connecting...
[15:11:28] FileServer 46.166.148.236 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer 86.188.39.99 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer 39.187.165.167 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer 118.209.51.233 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#763 195.88.75.43 [?] > Connecting...
[15:11:28] FileServer 184.75.223.235 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#764 hmbkhphkm5aq2zq2.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to hmbkhphkm5aq2zq2.onion:15441
[15:11:28] FileServer 103.254.131.57 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer 36.149.199.25 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#765 gg5io7mmhphhynz4.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to gg5io7mmhphhynz4.onion:15441
[15:11:28] FileServer 96.22.39.97 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#766 3pjoopk4kmyctd2l.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to 3pjoopk4kmyctd2l.onion:15441
[15:11:28] FileServer 87.8.48.197 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#767 clnlxnwrukcyl7n3.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to clnlxnwrukcyl7n3.onion:15441
[15:11:28] FileServer 87.183.176.48 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer 88.69.232.245 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#768 gbo7ehx6r2cngep4.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to gbo7ehx6r2cngep4.onion:15441
[15:11:28] FileServer 95.84.52.133 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#769 36.251.150.42 [?] > Connecting...
[15:11:28] FileServer 189.250.160.154 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#770 t62h72vh2v6rlyia.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to t62h72vh2v6rlyia.onion:15441
[15:11:28] FileServer 190.31.124.98 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#771 139.162.176.133 [?] > Connecting...
[15:11:28] FileServer 110.207.99.15 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#772 94.62.196.255 [?] > Connecting...
[15:11:28] FileServer 85.86.176.222 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#773 183.11.30.122 [?] > Connecting...
[15:11:28] FileServer 94.62.108.55 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#774 92.169.36.249 [?] > Connecting...
[15:11:28] FileServer 76.97.203.254 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#775 tlhgnzlkp2xcnadp.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to tlhgnzlkp2xcnadp.onion:15441
[15:11:28] FileServer 14.204.71.31 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#776 217.234.43.198 [?] > Connecting...
[15:11:28] WorkerManager:13NCGa..4qJi 46.166.148.236:80: Hash failed: content.json, failed peers: 7
[15:11:28] WorkerManager:1Bvzxo..S5YT 46.166.148.236:16881: No task found, stopping
[15:11:28] WorkerManager:1Bvzxo..S5YT Removed worker, workers: 1/6
[15:11:28] WorkerManager:13NCGa..4qJi 46.166.148.236:10754: Hash failed: content.json, failed peers: 8
[15:11:28] FileServer Conn#777 5ol7mej6nfm23suc.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to 5ol7mej6nfm23suc.onion:15441
[15:11:28] FileServer Conn#778 lypuo35uwtbjkcdm.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to lypuo35uwtbjkcdm.onion:15441
[15:11:28] FileServer Conn#779 mvrxd7iy26aso3xf.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to mvrxd7iy26aso3xf.onion:15441
[15:11:28] WorkerManager:1Bvzxo..S5YT 46.166.148.236:10755: No task found, stopping
[15:11:28] WorkerManager:1Bvzxo..S5YT Removed worker, workers: 0/6
[15:11:28] FileServer Conn#780 6nspjvssdbt7iocw.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to 6nspjvssdbt7iocw.onion:15441
[15:11:28] FileServer Conn#781 ymvc4rwcjiy3gw53.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to ymvc4rwcjiy3gw53.onion:15441
[15:11:28] FileServer 73.15.26.61 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#782 qth7dzrbhkzx4sex.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to qth7dzrbhkzx4sex.onion:15441
[15:11:28] FileServer 77.247.181.163 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#783 78.29.107.54 [?] > Connecting...
[15:11:28] FileServer 87.2.44.88 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] WorkerManager:1BLueG..tG49 87.2.44.88:15441: Hash failed: data/users/1NsW7cpAZSc2F2RSUBSE8TcZvuUMrjtCGq/data.json, failed peers: 9
[15:11:28] WorkerManager:1BLueG..tG49 Removed worker, workers: 4/6
[15:11:28] FileServer 177.98.155.13 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer 176.9.146.48 Connect error: error: [Errno 9] File descriptor was closed in another greenlet in ConnectionServer.py line 139 > Connection.py line 100 > _socket2.py line 236 > _socket2.py line 182 > hub.py line 651 > hub.py line 899 > hub.py line 630
[15:11:28] FileServer Conn#784 vnkygm4u7jclajyw.onion [?] > Connecting...
[15:11:28] TorManager Creating new socket to vnkygm4u7jclajyw.onion:15441
[15:11:28] FileServer Update for 1RedkCkVaXuVXrqCMpoXQS29bwaqsuFdL/data/users/1958F7oCppj78MP966AfojMQwHg2WUupzq/content.json looks valid, saving...
[15:11:28] Db:ZeroMe Connected to data/1MeFqFfFFGQfa1J3gJyYYUvb5Lksczq7nH/merged-ZeroMe/ZeroMe.db in 0.000s (opened: 6, sqlite version: 2.6.0)...
[15:11:28] FileServer Conn#785 176.50.171.99 [?] > Incoming connection...
[15:11:28] FileServer Conn#785 176.50.171.99 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[15:11:28] FileServer Conn#786 46.166.148.236 [?] > Incoming connection...
[15:11:28] FileServer Conn#786 46.166.148.236 [v2] > Socket error: TypeError: argument of type 'int' is not iterable in Connection.py line 160
[15:11:28] FileServer Removing Conn#786 46.166.148.236 [v2]...
[15:11:28] FileServer Conn#787 127.0.0.1    [?] > Incoming connection...
[15:11:28] FileServer Conn#788 46.166.148.236 [?] > Incoming connection...
[15:11:28] FileServer Conn#788 46.166.148.236 [v2] > Socket error: TypeError: argument of type 'int' is not iterable in Connection.py line 160
[15:11:28] FileServer Removing Conn#788 46.166.148.236 [v2]...
[15:11:28] FileServer Conn#789 46.166.148.236 [?] > Incoming connection...
[15:11:28] FileServer Conn#789 46.166.148.236 [v2] > Socket error: TypeError: argument of type 'int' is not iterable in Connection.py line 160
[15:11:28] FileServer Removing Conn#789 46.166.148.236 [v2]...
[15:11:28] FileServer Conn#790 46.166.148.236 [?] > Incoming connection...
``` Full Zite: 1F7b27kT38nMYZQg7tvDr33qWDZQgwnQpw (git.mkg20001.bit)
It has a 9mb content.json
The lags are mainly caused by the heavy CPU usage, so updating/signing it in another thread would fix most of the lags  Only allow GET HEAD OPTIONS to load wrapper and site media  When ZeroNet tries to route a LAN address through Tor's SOCKS5 proxy, Tor refuses to do so and sends back an error message. This error message should be handled.  ![1481559181](https://cloud.githubusercontent.com/assets/18724949/21735486/2c3cc178-d4a5-11e6-8405-2ce5fc1b45e9.jpg)
KaffieID has the same problem. But it seems that both ZeroID and KaffieID can get an auth cert normally.
See the post: http://127.0.0.1:43110/Me.ZeroNetwork.bit/?Post/12h51ug6CcntU2aiBjhP8Ns2e5VypbWWtv/1MpUdwe28gwynzoKg9ziFCRWcQK2FqNunb/1481559181  There is a DNS pollution for https://torproject.org in China so Tor can't be download automatically.
But not for some mirrors, such as https://tor.eff.org/ and https://www.theonionrouter.com . Tor is not work at most network environments in China, but many people use a foreign proxy to make tor work.
Currently, if I update ZeroNet, `torrc` will be overwriten, so skipping `torrc` is necessary when update ZeroNet. Get Tor Browser: https://github.com/TheTorProject/gettorbrowser  > Sorry, My english level Is Low,I use administrator privileges in the windows command console running zeronet.cmd about 30 seconds after the following results. I really need your help. Thank you very much!

Downloading https://github.com/HelloZeroNet/ZeroNet/archive/master.zip to ZeroNet directory.
Traceback (most recent call last):
  File "D:\Program Files\ZeroBundle\Python\lib\runpy.py", line 162, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "D:\Program Files\ZeroBundle\Python\lib\runpy.py", line 72, in _run_code
    exec code in run_globals
  File "D:\Program Files\ZeroBundle\Python\lib\site-packages\zerobundle\run.py", line 46, in <module>
    download(url, target_dir)
  File "D:\Program Files\ZeroBundle\Python\lib\site-packages\zerobundle\run.py", line 6, in download
    file = urllib.urlopen(url)
  File "D:\Program Files\ZeroBundle\Python\lib\urllib.py", line 87, in urlopen
    return opener.open(url)
  File "D:\Program Files\ZeroBundle\Python\lib\urllib.py", line 213, in open
    return getattr(self, name)(url)
  File "D:\Program Files\ZeroBundle\Python\lib\urllib.py", line 443, in open_https
    h.endheaders(data)
  File "D:\Program Files\ZeroBundle\Python\lib\httplib.py", line 997, in endheaders
    self._send_output(message_body)
  File "D:\Program Files\ZeroBundle\Python\lib\httplib.py", line 850, in _send_output
    self.send(msg)
  File "D:\Program Files\ZeroBundle\Python\lib\httplib.py", line 812, in send
    self.connect()
  File "D:\Program Files\ZeroBundle\Python\lib\httplib.py", line 1208, in connect
    HTTPConnection.connect(self)
  File "D:\Program Files\ZeroBundle\Python\lib\httplib.py", line 793, in connect
    self.timeout, self.source_address)
  File "D:\Program Files\ZeroBundle\Python\lib\socket.py", line 571, in create_connection
    raise err
IOError: [Errno socket error] [Errno 10060] Try running ZeroNet as standard privileges. Windows Sockets Error Code:
```
WSAETIMEDOUT
10060
```
> **Connection timed out.**
> A connection attempt failed because the connected party did not properly respond after a period of time, or the established connection failed because the connected host has failed to respond.

ZeroNet cannot connect to GitHub. It should have decided to download updates from another mirror.

Grab a GitHub IP from here: https://asm.ca.com/en/ping.php
Or specify a SOCKS proxy to use: https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Config.py#L157 > Thanks HelloZeroNet reply. this zipped file solves the problem i'm having with the theme.

Now, zeronet.cmd successfully downloaded ZeroNet folder. But not as smooth as imagined.
by default, zeronet.cmd generates the ZeroNet floder in the current directory. which causers the following two commands to fail.
https://github.com/HelloZeroNet/ZeroBundle/blob/master/zeronet.cmd#L12 
https://github.com/HelloZeroNet/ZeroBundle/blob/master/zeronet.cmd#L14
of course, this problem may only exist for me, my method is to use text to open zeronet.cmd and modify line 12 and 14.

> line12:

`		..\Python\python.exe ..\ZeroNet\zeronet\start.py`

> line14:

`		..\Python\python.exe ..\ZeroNet\zeronet\zeronet.py %*`
OK, My Chrome browser successfully pops up the hello zeronet page.
It seems to be going well now, and thanks again to the author and the person who helped me.
 Looks like problem have been happily solved, Closing ?    **Partially** fixed #711

Save this file below as `zeronet.html`:
```html
Escape and Seed
<iframe id="an-iframe" src="about:blank"></iframe>
<script>
document.getElementById("an-iframe").src = "http://127.0.0.1:43110/13Lo9wpxbogHdaTQ9rGZruu9MJZnigzU3B/"; // EmojiDay site
// or any site that haven't benn saved on your computer
</script>
```
Start `python -m SimpleHTTPServer` and go to `http://127.0.0.1:8000/zeronet.html`
The script inside the `iframe` will **escape** and redirect you to seed EmojiDay site.

With `X-Frame-Options: SAMEORIGIN` header, framing will be denied by the browser.
```
GET http://127.0.0.1:8000/zeronet.html
GET http://127.0.0.1:43110/13Lo9wpxbogHdaTQ9rGZruu9MJZnigzU3B/

Load denied by X-Frame-Options:
http://127.0.0.1:43110/13Lo9wpxbogHdaTQ9rGZruu9MJZnigzU3B/ does not permit cross-origin framing.
```

However, ZeroNet **still seeds** that site even when the inner iframe is not loaded by the browser. (Issue #742)  ```html
<script>
function get(url) {
    var r = new XMLHttpRequest();
    r.onload = function() {
        console.log(r.responseText);
    };
    r.open("GET", url);
    r.send();
}

get("/13Lo9wpxbogHdaTQ9rGZruu9MJZnigzU3B/");
get("/1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/big/sample-loader/files/list.json");
console.log("Request sent.");
</script>
```

```
Request sent.
! Cross-Origin Request Blocked: The Same Origin Policy disallows reading the remote resource at http://127.0.0.1:43110/13Lo9wpxbogHdaTQ9rGZruu9MJZnigzU3B/. (Reason: CORS header â€˜Access-Control-Allow-Originâ€™ missing).
```

Site **still seeded** and appeared.
 Attack works in Firefox. PR #750
```
Host: 127.0.0.1:43110
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Origin: null
[Irrelevant headers omitted]
```
WTF? AJAX without referrer header and X-Requested-With header. WebSocket requests also have a "valid" Accept header: PR #749
```
Host: 127.0.0.1:43110
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Sec-WebSocket-Version: 13
origin: http://127.0.0.1:43110
Connection: keep-alive, Upgrade
Upgrade: websocket
[Irrelevant headers omitted]
``` OPTIONS requests made by Ajax and Fetch APIs need some attention:
```js
var headers = new Headers();
var options = { method: 'GET', headers: headers };

headers.set('Accept', '*/*,fake/mime');
headers.set('X-Requested-With', 'FakeXMLHttpRequest');

fetch('/1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/big/sample-loader/files/list.json?fetch', options)
.then(function(response) {
  console.log("Done.");
});
```

```
OPTIONS /1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/big/sample-loader/files/list.json?fetch
Access-Control-Request-Method: GET
Access-Control-Request-Headers: x-requested-with
``` Finally, some proposals:
- Cross origin AJAX, WebSocket and Fetch requests have `origin` headers, but same origin requests can also have `origin` headers. Blocking all requests with `origin` headers will break same origin AJAX requests, but it is useful when AJAX request is strictly disallowed.
- The bottom line is that, we cannot allow JavaScript programs to seed arbitrary sites.

In the paragraphs below, "cross origin" stands for loading files across ZeroNet sites; "same origin" stands for loading files in the same ZeroNet site.

- When a request with a **"cross origin" referrer** is received, and it is asking for a non-HTML page on a random ZeroNet site, ZeroNet blocks that request automatically.
- When a request with a **"cross origin" referrer** is received, and it is asking for an HTML page on a brand new ZeroNet site, ZeroNet may have to respond with a confirmation page. (Clicked on a link or loaded by `iframe`, or simply [redirect.html](http://127.0.0.1:43110/1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/img/redirect.html?/Me.ZeroNetwork.bit/))
- When a request ~~with a **"same origin" referrer** or~~(is it possible?) without referrer is received, and it is asking for an HTML page on a brand new ZeroNet site, ZeroNet should seed that brand new site only after the wrapper is loaded. (Various attacks that send requests without referrer and do not care about responses)
- ZeroNet may have to block all AJAX, WebSocket and Fetch requests, including ["suspicious"](https://github.com/HelloZeroNet/ZeroNet/pull/750/files#diff-7fa31802ec08bb55f5128c3e841b5f34R100) ones, to a site that has not been saved in the computer. (Will it break ZeroCDN?)
 It seems that the Accept header of the same request is inconsistent across different browsers.
The code below issues a `POST` request:
```js
navigator.sendBeacon("http://127.0.0.1:43110/13Lo9wpxbogHdaTQ9rGZruu9MJZnigzU3B/data/fake.html?beacon", "random data");
```

Firefox: `Accept: text/html, ...`
Chrome: `Accept: */*` What about banning POST request? PR #751  ```
Site:1MeFqF..q7nH Json merged-ZeroMe/1[...]/data/users/1[...]/content.json load error:
UnboundLocalError: local variable 'json_row' referenced before assignment
in SiteStorage.py line 223 > Db.py line 362
``` Appears repeatedly after muting users. [Here](https://github.com/HelloZeroNet/ZeroNet/blob/38d330da1aae27198cb7496977fe8750c1eacc1d/src/Db/Db.py#L260) is the cause of assignment error.

```
Json merged-ZeroMe/1oranGe[...]/data/users/1[...]/content.json load error:
UnboundLocalError: local variable 'json_row' referenced before assignment
in SiteStorage.py line 229 > MutePlugin.py line 99 > SiteStorage.py line 74 > Db.py line 362
```  Can you please OpenPGP sign your following git tags? It's also useful in case github [gets hacked](http://www.extremetech.com/computing/120981-github-hacked-millions-of-projects-at-risk-of-being-modified-or-deleted) again in case [SSL CA's](https://en.wikipedia.org/wiki/DigiNotar) get [hacked](http://www.scmagazine.com/two-more-comodo-resellers-owned-in-ssl-hack/article/199620/) again.

With git it requires minimal effort.

In my ~/.gitconfig I use.

```
[user]
         name = adrelanos
         email = adrelanos at riseup dot net
         signingkey = 713AAEEF
```

After setting that up you can just use.

```
git tag -s 1.9
```

Users who wish can verify it with.

```
git tag -v 1.9
```

I am using it all the time. If there are any questions about this git feature / feature request, I am happy to answer.
 Related: #540 "Please sign releases"

`--updatesite` argument https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Config.py#L149 It's not on keyservers.

Where can I find the gpg public key?

```
gpg --recv-keys 9557210F5E536D3D
```
```
gpg: requesting key 5E536D3D from hkp server keys.gnupg.net
gpgkeys: key 9557210F5E536D3D not found on keyserver
gpg: no valid OpenPGP data found.
gpg: Total number processed: 0
``` The signing key mentioned here is no longer up to date. See:
`GPG signing 4096 bit keys`
https://github.com/HelloZeroNet/ZeroNet/issues/759  It would be nice to have a command line parameter to run zeronet.py in a mode that it will just download a zite (provided in the command line) and keep it up to date, nothing else. This would be useful to make the zite files available to other apps.
Example: `python zeronet.py --seeding-mode zite_hash`

**Use case:**

This would allow us to run zeronet programmatically to keep a given zite downloaded and up to date so that the json files from that zite can be used by a different script.

Antilibrary.bit has a use case of adding books requested by the users. 
When a user requests a new book that is not in the main zite DB, the book ISBN gets added to the user data.json file in the merger db [userdb](http://127.0.0.1:43110/19sZZmJPz1hADwitEs2XT6U46uHLGbHqKi/).
There is a docker container that runs the script that adds the new books. This script will scan the userdb folder for new books requested. Currently I need to have a local instance of zeronet running with the userdb zite added to it, and then I will share the files with the docker container. This requires manual intervention because there is no way to start zeronet in such a way that it will auto-download a zite.
If there was a way to run zeronet in this seeding mode I could automate the deploy of this script to run 2 containers, one with zeronet in the seeding mode for the userdb and the other with the script. No manual intervention would be necessary. or straight just upload server.... btw- get in the site list...but thx for the link.
chomping-at-the.bit(frustrated?) @HelloZeroNet As a work around for this, is there a way to exit the zeronet process once a given site has been updated? I need to run it as part of a sequence of commands and all I need from zeronet is for one site to be updated and it can exit, so the next commands can use the updated json files for that site.
 @HelloZeroNet Seems it will download only required files, but not optional. Is there a way to fully download site with all optional files? `"autodownloadoptional": true` in the `data/sites.json` appears not suitable either as this feature only download _new_ optional files, am I right?  This can happen after ungraceful system shutdown or disk full.
```
  File "/usr/local/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
```

Failures in individual zerosites shouldn't affect zeronet as a whole. Exceptions should be caught on per-site level.

Also, zeronet should regularly create backups of content.json. For example, every 10 minutes in a separate thread to prevent them being affected by similar conditions.

If content.json is missing and there is no backup, zeronet should reload this site, because it knows the site name and can do this any time.  Please test it on your own operating system and on your own locale. Solves issues #131 and #298 but has homograph attacks. It may be a good idea to show a warning to show the encoded domain name, the domain public key, and whether known homographs are found in the domain name.

Lists of homographs:
https://github.com/reinderien/mimic (The super evil)
https://github.com/adam-lynch/olc (Similar super evil)
https://github.com/MattOates/Text--Homoglyph/blob/master/lib/Text/Homoglyph.pm6
https://github.com/codebox/homoglyph
https://github.com/SoftwareAddictionShow/IDN-homograph-attack
https://en.wikipedia.org/wiki/IDN_homograph_attack (a few on Wikipedia page)
http://www.unicode.org/Public/security/latest/confusables.txt (Unicode confusables)
http://www.unicode.org/reports/tr36/ (Unicode security considerations)
https://github.com/minimaxir/big-list-of-naughty-strings/blob/master/blns.json (Big list of naughty strings)
https://krebsonsecurity.com/2011/09/right-to-left-override-aids-email-attacks/ (Control characters and Right-to-Left override attack) I decided not to make ZeroNet support IDNA domain names simply because it will make browsing IDNA sites more inconvenient.

Suppose someone registered for a fancy domain name `â˜‰net.bit` (the Sun symbol), and a bad guy registered for a domain name `âŠ™net.bit` (the circled dot operator) for phishing.
```python
>>> u'â˜‰' == u'âŠ™'
False
>>> print repr(u'â˜‰'),repr(u'âŠ™')
u'\u2609' u'\u2299'
```

Most fonts are not optimized for differentiating these homographs, so we want ZeroNet to display them in puny coded form.
```python
>>> u'âŠ™net.bit'.encode('idna'), u'â˜‰net.bit'.encode('idna')
('xn--net-vr2a.bit', 'xn--net-gn5a.bit')
```
To not to get to the phishing site, one has to memorize the full puny coded form of the innocent site's domain name. In this case, one will choose to use public keys to access these sites instead.

I will create a separate pull request only to fix encoding issues. Closed. IDNA domains will not be supported due to security concerns. Discussion about string encoding bugs has been moved here: #765  You can chose DMG or App Store, dmg also good way
2. You should sign app (app with sign much easy to install) 
3. ?
4. all resource should be in .app folder 
5. you can update app like now (check on start, download new content to app directory)
6. yes, but you may have a couple of issues with the license (or may not) hmm, ok, you can act like google - use **Application Support** folder
${HOME}/Library/Application Support > hmm, ok, you can act like google - use Application Support folder
`${HOME}/Library/Application Support`

Why "like Google"? It's designed to be used for application specific need. Just use `/Library/Application Support/ZeroNet` for system-wide things and `~/Library/Application Support/ZeroNet` for OS user-related.

About the signing: yes, whole `.app` bundle must be signed, signing only executable binaries will solve request to allow listening on public network interfaces, but doesn't allow users to launch the application using double-click without the `right click -> Cmd+Open -> Open` sequence.

I think the best way for zeronet will be distrubtion only launcher as an `.app` in the zip or dmg. Launcher can be signed and barely changes. All the application (python, libs, modules, sources, ...) can be stored as "data" in the `/Library/Application Support/ZeroNet` and kept up-to-date by the launcher. Btw, any distributed this way executables must be signed for the good.. and to suppress macos firewall messages of cause ;) DMG, other apps on mac use DMG or App Store > DMG, other apps on mac use DMG or App Store

or zip. Many apps use zip. And, in the actions to install it's more effective, than dmg image. Lets compare!

Dmg:
1. Double-click to mount
2. Wait while macOS check image before mounting (popup with progressbar)
3. Popup with image contents opened and you can drag'n'drop `.app` bundle to Applications folder.
4. Now you must unmount image in the Finder sidebar
5. Remove image (optionally).

Zip:
1. Double-click to extract `.app` bundle
2. Drag'n'drop to Applications folder on the Finder sidebar
3. Remove archive (optionally).

I don't know any reason to distribute applications via images instead of zip archives if App Store is not a way. user files (keys) or all data folder should be in 
**~**/Library/Application Support/ZeroNet

> What about permissions? I suppose you need to be admin to drag anything to Application dir or write to /Library/Application Support/

standard user on os x - admin (not root)
And standard users  don't see password alert (sudo alert) when move apps to /Applications

> Maybe we should check on startup if we are in the /Application directory and if not, then switch to portable mode: Create "ZeroNet files" directory and save everything there.

some apps ask about move it self to Application but i don't think that it is good way, if someone want portable mode - it can download source codes.

@kaero your are wrong:
Dmg:

Double-click to mount
1. All macs with SSD mount image near-instant
2. Popup with image contents opened and you can drag'n'drop .app bundle to Applications folder.
3. Unmount image - drag from desktop to trash
4. Remove image (optionally).

Main feature DMG - you can have custom installer, splash screen with link to app folder.

And @kaero give me example about apps in zip
Chrome use dmg, vlc use dmg, GitHub also use dmg @iShift 
* Slack https://slack.com/downloads/instructions/osx
* Sketch https://www.sketchapp.com/
* Opera http://www.opera.com/en/computer

Reasons to use dmg:
* show license, which user must accept before continue (not required by zeronet)
* multipart image (not required)
* branding (uh?) What about [Nuitka](http://nuitka.net/pages/overview.html)?  Actually macOS's .app is a directory. So we can store files in it. > Actually macOS's .app is a directory. So we can store files in it.

It seems that store files in app bundle will broke signature (http://stackoverflow.com/a/22694704). I suggest store in app's parent directory. I don't think this is good. What if I have two ZeroNet.app? Good :) 
No easy-portatable version is ok, if someone want portatable it can download it like now Add `LSUIElement = true` in Info.plist to hide it. I don't think it should be hid until we added a menu bar. #339 You should know macOS doesn't allow GUI on non-main thread. I think this will fail. You have to start a new process. What's this?`def click(): "Click"`

 And you said 

> i'm not a big fan of tkinter (looks bad, slow startup) and including it to zerobundle would significantly increase the size of it.

Why you use it now? seems to work fine for me too on macOS 10.12. nice job!! ðŸ’¯ where is link ? (i want to test it too..) @iShift https://github.com/HelloZeroNet/ZeroNet-mac/tree/dist  ~~I don't like single executable.~~ I don't think single executable is good. I suggest release an installer and a zip with source code bundled.
Use [NSIS](http://nsis.sourceforge.net/) to create installers.

Signing: Windows's digital signature requires a certificate, which cost a lot. So I suggest using GunPG and sha1/sha256 hash.

I think it's possible to run Python on WinRT. (http://stackoverflow.com/questions/14211949/python-in-windows-store-apps) Your idea (move the .dll and .pyd files to a sub-directory) is same as mine.
As for certificate, you can sign the installer exe. But you can't sign a zip file. What tools are you using to build these files?


> At least we can sign the zeronet.exe in the zip to avoid the notification about unsigned application.

You should sign all .dll files includes .pyd files. You can(should) upload .zip files to GitHub's [releases](https://github.com/HelloZeroNet/ZeroBundle/releases).
IIRC, GitHub provides API to upload releases. You can use curl to upload it automatically. You should include the ".manifest" file into ZeroNet.exe's resources. There's a `ZeroNet.exe.manifest`, which can be included in a exe file. What? Wait me have a test in VM. There's no issue after I deleted `ZeroNet.exe.manifest`. But there's a issue if I have not installed `Visual C++ 2008 Redistributable` it can't load some library. Copy `Microsoft.VC90.CRT.manifest` `msvcm90.dll` `msvcp90.dll` `msvcr90.dll` to `lib` can solve this. I used PE Explorer to add manifest into exe. It works fine. Yes. It's good to put all dlls in lib dir. It's a little annoying that Windows includes a `msvcrt.dll`. But only VC++ 6.0 programs could use this library. ~~Exe is just a loader that loads python27.dll. It's possible not to make it require CRT dll.~~
I saw ZeroNet.exe dependency and found it requires `kernel32.dll` `msvcrt.dll` `ws2_32.dll`, which available in system. ~~Or you can try py2exe...~~ Since this exe version is released, will you continue support the old ZeroBundle? nope nope and dope.... try this:
half-assed.
FREEZE the python app. The only parts for OSX that are dodgy are Tkinter/UI elements. The rest, with path seperator and old school resources, should otherwise work, assuming you do OS checks for specific functions for machOS. Otherwise, if its all python, FREEZE it into pyc/pyd and a self-extracting exe. under wine, this can also be ran, but we dont need to go there on unices. Mac, well...can u just zip it? If you GIT the folder the project is in, then revisions,etc are a cinch(you dont know GIT). freezing on unices is tricky but ive done it some time ago.

MY C is SHIT. Dont ask, im a pascalian. Off topic: Could you complain what's the meaning of `The frozen script`? Using Cython with type-annotation as a replacement of Python will speed-up zeronet about 3x-times maybe.

   You can use [ZeroCDN](http://127.0.0.1:43110/1AMh6MG4K59ki1dPXX1PrgzeeqkMmZ1YKm/). I mean instead of loading common javascript libraries from site we visit wouldn't it be faster if we use local stored once instead .  ![e2565e10cedc20a88b4f630231cd0054](https://cloud.githubusercontent.com/assets/22581876/21599656/89970a1e-d170-11e6-84ab-62a89b9cf64f.png)


 Please paste your logs in browser's console and ZeroNet/log. ```
[removed due privacy reasons]
``` I'm using Chrome and the chrome log does not throw errors I have disabled all google chrome plugins, also tested in incognito mode and also in mozilla firefox. The same happens to me Okey , wait moment It happens exactly the same.
What he did, it has been;
-Remove the files
- Download more
- Unzip it
and
- Run zeronet.
And still the same. I would open F12 network console to see what was failed to load. @jesusmoreno24 Could you please open the network console, press Ctrl-F5, and take a screenshot?  ![image](https://cloud.githubusercontent.com/assets/22581876/21657498/cf088818-d2c2-11e6-8536-9665fbc46dd5.png)


This is what appears on the console. Here is mine: 

![](https://i.gyazo.com/12b8b9727e36eb36c301c6354573cf2b.png)
 Ohhhh, it works for me. Thanks so much for the help! Could anyone tell [/u/GeneShuttles](https://www.reddit.com/user/GeneShuttles) about this update?
https://www.reddit.com/r/zeronet/comments/5lzub8/not_displaying_properly/  In the console, something like:
[17:35:11] Ui.UiServer Wrapper key not found: xxxxxx
[17:35:11] Ui.UiServer Wrapper key not found: aaaaaa
... ...
  For bitmessage, It's used for reducing the impact of spams or excessive contents
[Pic of Demanded Difficulty on Bitmessage](http://www.image-share.com/ijpg-3409-191.html)

And it would be convenient if users, web admins, developers or third parties could adjust this parameter easily. So, would ZeroNet need this kind of function sooner or later?   I'm keeping some stats on peers using a function 

```

def ParsePeers(site):
    stats_content = requests.get('http://127.0.0.1:43110/Stats').text
    soup = BeautifulSoup(stats_content)

    def contains_site(tag):
        if tag.name != 'tr':
            return False
        link = tag.find('a')
        if not link:
            return False
        return site in link.string

    tr = soup.find(contains_site)

    if not tr:
        return None

    pattern = re.compile("[0-9]+/[0-9]+/([0-9]+)")

    def contains_peers(tag):
        return tag.name == 'td' and pattern.search(unicode(tag.string))

    peer_td = tr.find(contains_peers)
    peer_count = int( pattern.findall(unicode(peer_td.string))[0] )

    return (tr.find('a').string, peer_count)
```
that I remember as founded in ZeroBlog, but it seems I have confused memory or somebody delete article, anyway.

The stats page doesn't allow anymore to be parsed in new version, it seems it checks user-agent, it produces this horrible result:

```
<style>
                * { font-family: Consolas, Monospace; color: #333 }
                pre { padding: 10px; background-color: #EEE }
                </style>
<h1>Forbidden</h1>
<h2>Invalid Accept header to load wrapper
<h3>Please <a href="https://github.com/HelloZeroNet/ZeroNet/issues" target="_blank">report it</a> if you think this an error.</h3>
<h4>Details:</h4>
<pre>{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "*/*", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate", 
    "HTTP_CONNECTION": "keep-alive", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_USER_AGENT": "python-requests/2.10.0", 
    "PATH_INFO": "/Stats", 
    "QUERY_STRING": "", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "38987", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "localhost", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.0 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": null, 
        "config_file": "zeronet.conf", 
        "connected_limit": 10, 
        "data_dir": "data", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "keep_ssl_cert": false, 
        "language": "en", 
        "log_dir": "log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": true, 
        "open_browser": null, 
        "optional_limit": "30%", 
        "proxy": null, 
        "size_limit": 10, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.tordb.ml:6881/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "updatesite": "1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp", 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false
    }, 
    "plugins": [
        "AnnounceZero", 
        "CryptMessage", 
        "MergerSite", 
        "Newsfeed", 
        "OptionalManager", 
        "PeerDb", 
        "Sidebar", 
        "Stats", 
        "TranslateSite", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.0.1", 
    "version_python": "2.7.9 (default, Aug 13 2016, 16:41:35) \n[GCC 4.9.2]", 
    "version_zeronet": "0.5.1 r1791", 
    "wsgi.url_scheme": "http"
}</pre>
</h2>
```

How can I stop this and get back the results? (Also, if somebody know the source of that function let me know) Wow thanks, just adding that it works, what a noob! Great, so you don't know where is that code from? I will continue my quest.  http://127.0.0.1:43110/1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/big/docs/about/demos/
disable:
![image](https://cloud.githubusercontent.com/assets/15062548/21575744/1b8f6b80-cf52-11e6-8e3a-707fc707ca76.png)
enable:
![image](https://cloud.githubusercontent.com/assets/15062548/21575746/401c6228-cf52-11e6-9dd3-463a1545b6be.png)
![image](https://cloud.githubusercontent.com/assets/15062548/21575747/4e508c34-cf52-11e6-838a-a78680c49234.png)
seems like uipassword bug..
 Off topic: Please improve your English grammar.  $ pwd
~/downloads/ZeroBundle/ZeroNet/src/util

$ ~/downloads/ZeroBundle/Python/python ./UpnpPunch.py
Opening port...
DEBUG:root:Trying to open port 15443.
DEBUG:root:Found local ips: ['192.168.0.8']
DEBUG:root:Trying using local ip: 192.168.0.8
Traceback (most recent call last):
  File "./UpnpPunch.py", line 342, in <module>
    print ask_to_open_port(15443, "ZeroNet", retries=3, protos=["TCP"])
  File "./UpnpPunch.py", line 320, in ask_to_open_port
    protos=protos)
  File "./UpnpPunch.py", line 299, in _communicate_with_igd
    _orchestrate_soap_request(local_ip, port, fn, desc, protos)
  File "./UpnpPunch.py", line 274, in _orchestrate_soap_request
    idg_data = _collect_idg_data(ip)
  File "./UpnpPunch.py", line 258, in _collect_idg_data
    _retrieve_igd_profile(idg_data['location']))
  File "./UpnpPunch.py", line 104, in _parse_igd_profile
    dom = parseString(profile_xml)
  File "/home/kasv/downloads/ZeroBundle/lib/python2.7/xml/dom/minidom.py", line 1928, in parseString
    return expatbuilder.parseString(string)
  File "/home/kasv/downloads/ZeroBundle/lib/python2.7/xml/dom/expatbuilder.py", line 940, in parseString
    return builder.parseString(string)
  File "/home/kasv/downloads/ZeroBundle/lib/python2.7/xml/dom/expatbuilder.py", line 223, in parseString
    parser.Parse(string, True)
xml.parsers.expat.ExpatError: not well-formed (invalid token): line 2, column 442

See attachment
[answer.xml.txt](https://github.com/HelloZeroNet/ZeroNet/files/677114/answer.xml.txt)

 Super big thanks for attaching the SOAP response @kasv . I'll look into this in the next few days. Hi @kasv , I think I was able to fix the issue. Before I create a pull request, could you test the fix out? You can either clone my [patched branch](https://github.com/sirMackk/ZeroNet/tree/unicode_fix) and run Zeronet as you normally would _or_ you can download the [python script from here](https://github.com/sirMackk/ZeroNet/blob/unicode_fix/src/util/UpnpPunch.py) and run it with `python UpnpPunch.py` (all it does is opens port 15443 port and then closes it). 

In case you still get an error, the script will create a file called `upnp_error.txt`, which will help further troubleshooting. If there's no error, I'll submit a PR and we can close this one out :). @kasv More information needed. Hi @sirMackk, Your version utf8 python script result:
$ ../Python/python ./UpnpPunch_utf8.py 
Opening port...
DEBUG:root:Trying to open port 15443.
DEBUG:root:Found local ips: ['192.168.0.8']
DEBUG:root:Trying using local ip: 192.168.0.8
Traceback (most recent call last):
  File "./UpnpPunch_utf8.py", line 346, in <module>
    print ask_to_open_port(15443, "ZeroNet", retries=3, protos=["TCP"])
  File "./UpnpPunch_utf8.py", line 324, in ask_to_open_port
    protos=protos)
  File "./UpnpPunch_utf8.py", line 303, in _communicate_with_igd
    _orchestrate_soap_request(local_ip, port, fn, desc, protos)
  File "./UpnpPunch_utf8.py", line 278, in _orchestrate_soap_request
    idg_data = _collect_idg_data(ip)
  File "./UpnpPunch_utf8.py", line 262, in _collect_idg_data
    _retrieve_igd_profile(idg_data['location']))
  File "./UpnpPunch_utf8.py", line 86, in _retrieve_igd_profile
    return urllib2.urlopen(url.geturl(), timeout=5).read().decode('utf-8')
  File "/home/kasv/Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸/ZeroBundle/lib/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xcd in position 465: invalid continuation byte

My version (patched, [UpnpPunch.py.txt](https://github.com/HelloZeroNet/ZeroNet/files/701766/UpnpPunch.py.txt)) result:
$ ../Python/python ./UpnpPunch.py 
Opening port...
DEBUG:root:Trying to open port 15443.
DEBUG:root:Found local ips: ['192.168.0.8']
DEBUG:root:Trying using local ip: 192.168.0.8
DEBUG:root:Sending UPnP request to 192.168.0.1:1024...
DEBUG:root:500
DEBUG:root:<s:Envelope xmlns:s="http://schemas.xmlsoap.org/soap/envelope/" s:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/"><s:Body><s:Fault><faultcode>s:Client</faultcode><faultstring>UPnPError</faultstring><detail><UPnPError xmlns="urn:schemas-upnp-org:control-1-0"><errorCode>718</errorCode><errorDescription>ConflictInMappingEntry</errorDescription></UPnPError></detail></s:Fault></s:Body></s:Envelope>
DEBUG:root:Upnp request using "192.168.0.8" failed: SOAP request error: 718 - ConflictInMappingEntry
DEBUG:root:Trying using local ip: 192.168.0.8
DEBUG:root:Sending UPnP request to 192.168.0.1:1024...
DEBUG:root:500
DEBUG:root:<s:Envelope xmlns:s="http://schemas.xmlsoap.org/soap/envelope/" s:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/"><s:Body><s:Fault><faultcode>s:Client</faultcode><faultstring>UPnPError</faultstring><detail><UPnPError xmlns="urn:schemas-upnp-org:control-1-0"><errorCode>718</errorCode><errorDescription>ConflictInMappingEntry</errorDescription></UPnPError></detail></s:Fault></s:Body></s:Envelope>
DEBUG:root:Upnp request using "192.168.0.8" failed: SOAP request error: 718 - ConflictInMappingEntry
DEBUG:root:Trying using local ip: 192.168.0.8
DEBUG:root:Sending UPnP request to 192.168.0.1:1024...
DEBUG:root:500
DEBUG:root:<s:Envelope xmlns:s="http://schemas.xmlsoap.org/soap/envelope/" s:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/"><s:Body><s:Fault><faultcode>s:Client</faultcode><faultstring>UPnPError</faultstring><detail><UPnPError xmlns="urn:schemas-upnp-org:control-1-0"><errorCode>718</errorCode><errorDescription>ConflictInMappingEntry</errorDescription></UPnPError></detail></s:Fault></s:Body></s:Envelope>
DEBUG:root:Upnp request using "192.168.0.8" failed: SOAP request error: 718 - ConflictInMappingEntry
Traceback (most recent call last):
  File "./UpnpPunch.py", line 351, in <module>
    print ask_to_open_port(port, desc, retries=3, protos=["TCP"])
  File "./UpnpPunch.py", line 328, in ask_to_open_port
    protos=protos)
  File "./UpnpPunch.py", line 319, in _communicate_with_igd
    port, retries))
__main__.UpnpError: Failed to communicate with igd using port 15443 on local machine after 3 tries.


 Thanks @kasv , this is a big help in pinpointing the issue. I'll look into how to best make the code handle multiple encodings.

In the second case, it appears that your router is telling you that port 15433 is already open. This shouldnt be an error (500), which can be confusing. I'll see how this can be handled in a friendlier fashion. I tried different ports and always get this error.

2017-01-12 16:37 GMT+03:00 sirMackk <notifications@github.com>:

> Thanks @kasv <https://github.com/kasv> , this is a big help in
> pinpointing the issue. I'll look into how to best make the code handle
> multiple encodings.
>
> In the second case, it appears that your router is telling you that port
> 15433 is already open. This shouldnt be an error (500), which can be
> confusing. I'll see how this can be handled in a friendlier fashion.
>
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/HelloZeroNet/ZeroNet/issues/725#issuecomment-272164632>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABdO9cFOnjbz1ePL2O3gVL89oouc0Fjjks5rRix8gaJpZM4LXklK>
> .
>
 Does it even open/close the ports at all?

I know that UPnP is horribly implemented and some routers will ignore commands even if they have UPnP enabled or some will even send a "200 OK" reply ("yes, I opened the port!") without actually opening the port :/.

You can confirm this if you use `miniupnpc` to perform the same operation (`apt-get install miniupnpc` if you're on ubuntu). Does not work(
The test script (taken from [http://nullege.com/codes/show/src@p@y@pyethereum-HEAD@pyethereum@tcpserver.py/33/miniupnpc](http://nullege.com/codes/show/src@p@y@pyethereum-HEAD@pyethereum@tcpserver.py/33/miniupnpc)) result:
INFO:root:TCP server started 192.168.0.8:15554
DEBUG:root:Setting UPNP
DEBUG:root:1 UPNP device(s) detected
DEBUG:root:external ip: 10.0.50.131
DEBUG:root:status: ('Connected', 866834, 'ERROR_NONE'), connection type: IP_Routed
DEBUG:root:trying to redirect 10.0.50.131 port 15554 TCP => 192.168.0.8 port 15554 TCP
DEBUG:root:upnp failed: ConflictInMappingEntry
INFO:root:my public address is b'178.155.5.26':15554
[tcpserver.py.txt](https://github.com/HelloZeroNet/ZeroNet/files/701979/tcpserver.py.txt)
 Hey @kasv , I've been looking into this and it appears that short of switching out the router's firmware to something like openwrt/dd-wrt, there's not much someone can do to get their router to talk upnp :/.

@HelloZeroNet Quick update here - I'm still trying to figure out how to handle this charset issue without introducing more dependencies - basically, how to detect the charset from a bunch of bytes and use that to decode it into a string fit for an xml parser. The updates from #757 makes things better, but I wouldn't consider it a long-term solution. I suffer from the same problem on my Ubuntu 16.04. I check your source code of the 'UpnpPunch.py',and I run your debug version of the 'UpnpPunch.py' above. According to the results and some informations I get from the Internet, I want to know whether it is necessary for my router to start the upnp mapping service,transporting the data got from Port 15443 to the Port 43110? Is it possible that I face this problem because of the lack of of the control over the router? If I got the control and start the upnp service manually and set the proper parameters, will I successfully install my zeronet? I am waiting for your answer,any words would be appreciated. OK, it actually works today, though continuously telling me that 
"[12:47:16] Ui.UiServer Web interface: http://127.0.0.1:43110/
[12:47:16] Ui.UiServer --------------------------------------
[12:47:17] FileServer Checking port 15441 using portchecker.co...
[12:47:23] FileServer [BAD :(] Port closed: Port 15441 is closed.
[12:47:23] FileServer Trying to open port using UpnpPunch...
[12:47:38] FileServer UpnpPunch run error: UpnpError: Failed to communicate with igd using port 15441 on local machine after 3 tries. in FileServer.py line 74 > UpnpPunch.py line 324 > UpnpPunch.py line 315
".
Thanks a lot. I love this project:).  I don't want see or seed anything about him. What should I doï¼Ÿ Try to set the user dictionary that you don't want see or seed to not writable, but I don't know whether ZeroNet will try again frequently and take a large number of resources. Each user has a folder in each hub, am I going to modify all folder about him? @l5h5t7  I think that you choose incorrect repo for your issue 
https://github.com/HelloZeroNet/ZeroMe 

and feature request - "add ban button" - good idea..
  website "https://bit.no.com" is ok,but cant't get into the zeronet  If a user publishes the content that the `modified` value is in distant future (Wrong system time or Intentionally modifying), this content will be at the top of the list for a long time such as ZeroTalk or ZeroMe.
The worse thing is, if the user try to fix the error, they will find that is difficult because the `modified` value will be synchronized back to the wrong time. But users can still use this way to stick posts to the post for a day.
![stick](https://cloud.githubusercontent.com/assets/18724949/21522018/d6e141d2-cd3c-11e6-9c60-be94d6c84bac.png)
I have been seeing this post for hours. consider reducing to a shorter time?    Just upgraded the `gevent` module from python2-gevent 1.1.2 to 1.2.0 and now Zeronet won't start:
```pytb
Traceback (most recent call last):
  File "zeronet.py", line 18, in main
    main.start()
  File "â€¦/zeronet/src/main.py", line 450, in start
    actions.call(config.action, action_kwargs)
  File "â€¦/zeronet/src/main.py", line 129, in call
    func(**kwargs)
  File "â€¦/zeronet/src/main.py", line 134, in main
    from File import FileServer
  File "/usr/lib/python2.7/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "â€¦/zeronet/src/File/__init__.py", line 1, in <module>
    from FileServer import FileServer
  File "/usr/lib/python2.7/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "â€¦/zeronet/src/File/FileServer.py", line 14, in <module>
    from Connection import ConnectionServer
  File "/usr/lib/python2.7/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "â€¦/zeronet/src/Connection/__init__.py", line 1, in <module>
    from ConnectionServer import ConnectionServer
  File "/usr/lib/python2.7/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "â€¦/zeronet/src/Connection/ConnectionServer.py", line 15, in <module>
    from Tor import TorManager
  File "/usr/lib/python2.7/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "â€¦/zeronet/src/Tor/__init__.py", line 1, in <module>
    from TorManager import TorManager
  File "/usr/lib/python2.7/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "â€¦/zeronet/src/Tor/TorManager.py", line 17, in <module>
    from gevent.coros import RLock
  File "/usr/lib/python2.7/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
ImportError: No module named coros
```
 I dont think it was a fixup, you just remove the import code of gevent.coros?I want to know where is gevent.coros be in 2016? my project used code like this "from gevent.coros import RLock, Semaphore", I could not just remove the import code, where is Semaphore now?sorry, I am not metioning your project  Why 127.0.0.1:43110 , when there is whole /8 network available? Why use IP address at all, while /etc/hosts is available too? Something like: http://zeronet/ will look much better, and it's far more user-friendly.  url: http://127.0.0.1:43110/site_address/songs/%E5%A4%AA%E4%B8%8A%E8%80%81%E5%90%9B%E8%AF%B4%E6%B8%85%E9%9D%99%E7%BB%8F.mp3

> Err: UnicodeDecodeError: 'ascii' codec can't decode byte 0xe5 in position 6: ordinal not in range(128) in UiServer.py line 81 > UiRequest.py line 82 > UiRequest.py line 190 > UiRequestPlugin.py line 22 > TranslateSitePlugin.py line 24 > UiRequest.py line 367 > Site.py line 629 > SiteStorage.py line 262 > SiteStorage.py line 278

> Please report it if you think this an error.
> 
> Details:
> 
> {
>     "GATEWAY_INTERFACE": "CGI/1.1", 
>     "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8", 
>     "HTTP_ACCEPT_ENCODING": "gzip, deflate, sdch, br", 
>     "HTTP_ACCEPT_LANGUAGE": "zh-CN,zh;q=0.8", 
>     "HTTP_CONNECTION": "keep-alive", 
>     "HTTP_HOST": "127.0.0.1:43110", 
>     "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
>     "HTTP_USER_AGENT": "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36", 
>     "PATH_INFO": "/site_path/songs/\u592a\u4e0a\u8001\u541b\u8bf4\u6e05\u9759\u7ecf.mp3", 
>     "QUERY_STRING": "", 
>     "REMOTE_ADDR": "127.0.0.1", 
>     "REMOTE_PORT": "52721", 
>     "REQUEST_METHOD": "GET", 
>     "SCRIPT_NAME": "", 
>     "SERVER_NAME": "wangpan.cc", 
>     "SERVER_PORT": "43110", 
>     "SERVER_PROTOCOL": "HTTP/1.1", 
>     "SERVER_SOFTWARE": "gevent/1.1 Python/2.7", 
>     "arguments": {
>         "action": "main", 
>         "batch": false, 
>         "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
>         "coffeescript_compiler": "type %s | tools\\coffee\\coffee.cmd", 
>         "config_file": "zeronet.conf", 
>         "connected_limit": 10, 
>         "data_dir": "data", 
>         "debug": false, 
>         "debug_gevent": false, 
>         "debug_socket": false, 
>         "disable_db": false, 
>         "disable_encryption": false, 
>         "disable_sslcompression": true, 
>         "disable_udp": false, 
>         "fileserver_ip": "*", 
>         "fileserver_port": 15441, 
>         "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
>         "ip_external": null, 
>         "keep_ssl_cert": false, 
>         "language": "zh", 
>         "log_dir": "log", 
>         "max_files_opened": 2048, 
>         "msgpack_purepython": true, 
>         "open_browser": "default_browser", 
>         "optional_limit": "10%", 
>         "proxy": null, 
>         "size_limit": 10, 
>         "stream_downloads": false, 
>         "tor": "enable", 
>         "tor_controller": "127.0.0.1:9051", 
>         "tor_proxy": "127.0.0.1:9050", 
>         "trackers": [
>             "zero://boot3rdez4rzn36x.onion:15441", 
>             "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
>             "udp://tracker.coppersurfer.tk:6969", 
>             "udp://tracker.leechers-paradise.org:6969", 
>             "udp://9.rarbg.com:2710", 
>             "http://tracker.tordb.ml:6881/announce", 
>             "http://explodie.org:6969/announce", 
>             "http://tracker1.wasabii.com.tw:6969/announce"
>         ], 
>         "trackers_file": false, 
>         "ui_ip": "127.0.0.1", 
>         "ui_port": 43110, 
>         "ui_restrict": false, 
>         "updatesite": "1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp", 
>         "use_openssl": true, 
>         "use_tempfiles": false, 
>         "verbose": false
>     }, 
>     "plugins": [
>         "AnnounceZero", 
>         "CryptMessage", 
>         "MergerSite", 
>         "Newsfeed", 
>         "OptionalManager", 
>         "PeerDb", 
>         "Sidebar", 
>         "Stats", 
>         "TranslateSite", 
>         "Trayicon", 
>         "Zeroname"
>     ], 
>     "version_gevent": "1.1.2", 
>     "version_python": "2.7.12 (v2.7.12:d33e0cf91556, Jun 27 2016, 15:19:22) [MSC v.1500 32 bit (Intel)]", 
>     "version_zeronet": "0.5.1 r1786", 
>     "wsgi.url_scheme": "http"
> }

url: http://127.0.0.1:43110/site_address/songs/a.mp3
success

It seems like zeronet can't decode Chinese file name.
Win7X64,  zeronet version 0.5.1 r1786 Wow, that's harsh.  When Tor is blocked by goverment it doesnt work, It cant connect to any other user even If tor's settings is changed to go around goverment block. Maybe you should contact your government about this issue. Or the Tor Project.
How is ZeroNet supposed to make Tor work differently? Try to append "--tor disable" to the start command as long as Zeronet is not blocked thanks to both of you. Both suggestion fixed my problem.  Every time I start my ZeroNet 0.5.1 on my Unbuntu 12.04, I can see this error message repeated in the console after running ZeroNet for a few minutes.   coffee script not friendly of i18n, like that:
```
class Time
  since: (time) ->
    now = +(new Date) / 1000
    secs = now - time
    if secs < 60
      back = "Just now"
    else if secs < 60 * 60
      back = "#{Math.round(secs / 60)} minutes ago"
    else if secs < 60 * 60 * 24
      back = "#{Math.round(secs / 60 / 60)} hours ago"
    else if secs < 60 * 60 * 24 * 3
      back = "#{Math.round(secs / 60 / 60 / 24)} days ago"
    else
      back = "on " + @date(time)
    back = back.replace(/1 ([a-z]+)s/, "1 $1") # 1 days ago fix
    return back


  date: (timestamp, format = "short") ->
    parts = new Date(timestamp * 1000)
    if format == "short"
      display = (parts.getFullYear() + "nian" + String(parts.getMonth() + 1) + "yue" + parts.getDay() + "ri")
    else
      display = parts.toTimeString()
    return display


  timestamp: (date = "") ->
    if date == "now" or date == ""
      return parseInt(+(new Date) / 1000)
    else
      return parseInt(Date.parse(date) / 1000)


# Get elistamated read time for post
  readtime: (text) ->
    chars = text.length
    if chars > 1500
      return parseInt(chars / 1500) + " min read"
    else
      return "less than 1 min read"


window.Time = new Time
```
success
![image](https://cloud.githubusercontent.com/assets/15062548/21390661/005675ca-c7c3-11e6-8d60-f3da5428dade.png)
but if I change it to Chinese...BOOM.

```
class Time
  since: (time) ->
    now = +(new Date) / 1000
    secs = now - time
    if secs < 60
      back = "åˆšæ‰"
    else if secs < 60 * 60
      back = "#{Math.round(secs / 60)} åˆ†é’Ÿå‰"
    else if secs < 60 * 60 * 24
      back = "#{Math.round(secs / 60 / 60)} å°æ—¶å‰"
    else if secs < 60 * 60 * 24 * 3
      back = "#{Math.round(secs / 60 / 60 / 24)} å¤©ä¹‹å‰"
    else
      back = "on " + @date(time)
    back = back.replace(/1 ([a-z]+)s/, "1 $1") # 1 days ago fix
    return back


  date: (timestamp, format = "short") ->
    parts = new Date(timestamp * 1000)
    if format == "short"
      display = (parts.getFullYear() + "å¹´" + String(parts.getMonth() + 1) + "æœˆ" + parts.getDay() + "æ—¥")
    else
      display = parts.toTimeString()
    return display


  timestamp: (date = "") ->
    if date == "now" or date == ""
      return parseInt(+(new Date) / 1000)
    else
      return parseInt(Date.parse(date) / 1000)


# Get elistamated read time for post
  readtime: (text) ->
    chars = text.length
    if chars > 1500
      return parseInt(chars / 1500) + " min read"
    else
      return "less than 1 min read"


window.Time = new Time

```
![image](https://cloud.githubusercontent.com/assets/15062548/21390739/59740c8a-c7c3-11e6-836b-94c9c73e3bdc.png)
Um....How to slove it? or ZeroBundle should upgrade Coffee Script? win7 x64, with a new zerobundle, editor is webstorm,  disabled webstorm's file watcher
I have no idea about this ..... @cxgreat2014 Try to compile your `Time.coffee` via `coffee -c`. So we can know which line causes the compile error. ![image](https://cloud.githubusercontent.com/assets/15062548/21391825/37d0228a-c7c8-11e6-89e9-e575081e27c5.png)
@weakish not work, coffee.wsf(85, 6) file can't open ï¼Ÿï¼Ÿï¼ŸI try to not use ZeroNet --debug command and use `npm install -g coffee-script` and `coffee -c Time.coffee`
![image](https://cloud.githubusercontent.com/assets/15062548/21392062/30f1d296-c7c9-11e6-9bd7-660478104041.png)
success...
maybe it's zeronet's coffee script BUG @HelloZeroNet Ok, thanks, I'm using a dirt hack with replace DebugMedia.py's command with set `command = 'coffee -p ' + file_path_escaped`, it's work :) :+1:  I think use moment.js in ZeroBlog is better than Time.coffee, because moment.js is i18n Tested with the bundled coffee on Windows, it compiles.

- OS: Windows 8.1 x86_64
- ZeroNet 0.5.1

In the screenshot, it seems you are using a `coffee` in the root directory of your site.
It is strange.
On my machine, the path is `D:\ZeroBundle\ZeroNet\tools\coffee\coffee.cmd`.

 I have this problem too. But I installed the node version CoffeeScript. It seems that it's caused by Windows' cscript.exe. @weakish I just copy D:\ZeroBundle\ZeroNet\tools\coffee\coffee.cmd to my site dir  ZeroNet allows for arbitrary websites to added to the client at random, without authentication or any checking that the user would actually want this.

For example, a website (on ZeroNet or elsewhere) could embed hidden image tags like this:
`<img src='http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D' style='display: none;'>`

This triggers the user's client to automatically add the site.

I think there needs to be some sort of confirmation process that happens. Yeah, I don't believe it would be possible to catch all "fake" requests like that.

Though couldn't ZeroNet simply not add the site if it is not requested during a real user session, and if it is a real session, display a notification that a new site has been added?

There are legitimate reasons for requesting other websites content, after all, hotlinking is actually good on ZeroNet. I definitely saw prompt on some ZN sites, like "This is new zite for you, do you want to add it and continue?". Would be nice to have it everywhere. Looks like a good start. I'll investigate further & try to find more methods to break & fix this, though one that comes to mind is `<iframe>`. Using [`X-Frame-Options` header](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Frame-Options) for page requests that do not have wrapper nonce can be a good idea. When a request includes a valid wrapper nonce, turn off this header. Requested site should not be seeded unless the request is valid, including having a valid wrapper nonce.
```
X-Frame-Options: SAMEORIGIN
```
> The page can only be displayed in a frame on the same origin as the page itself.

However,
- `X-Frame-Options: DENY` will break all ZeroNet links that do not have a `target=_top` attribute.
- `ALLOW-FROM` is [not yet supported](https://www.owasp.org/index.php/Clickjacking_Defense_Cheat_Sheet#Defending_with_X-Frame-Options_Response_Headers) by Chrome.

- This seems to be invalid. Examples from the Internet always put an __origin__ there.
```
X-Frame-Options: ALLOW-FROM http://127.0.0.1:43110/1SitEAdDREssYkGmy3FdyNjEb1wsDagkPb/
```

The [RFC](https://tools.ietf.org/html/rfc7034) says:
```
ALLOW-FROM  (followed by a serialized-origin [RFC6454])
      A browser receiving content with this header MUST NOT display this
      content in a frame from any page with a top-level browsing context
      of different origin than the specified origin.  While this can





Ross & Gondrom                Informational                     [Page 4]

 
RFC 7034                     X-Frame-Options                October 2013


      expose the page to risks by the trusted origin, in some cases, it
      may be necessary to allow the framing by content from other
      domains.

   The meaning of the term "serialized-origin" is given in [RFC6454].
   If the ALLOW-FROM value is used, it MUST be followed by a valid
   origin [RFC6454] (as a subset of the URI [RFC3986]).

   Any data beyond the domain address (i.e., any data after the "/"
   separator) is to be ignored. 
```

A good news is that, the `frame-ancestors` directive from the [`Content-Security-Policy` header](https://www.owasp.org/index.php/Content_Security_Policy_Cheat_Sheet) "obsoletes the `X-Frame-Options` header." Some CSP directives only use the origin in given source list, ignoring the rest of the URI, but the `host-source` format seems to support paths.

> Many CSP directives use a value consisting of a source list, defined in the ABNF grammar below.
```
source-list       = *WSP [ source-expression *( 1*WSP source-expression ) *WSP ]
                  / *WSP "'none'" *WSP
source-expression = scheme-source / host-source / keyword-source / nonce-source / hash-source
host-source       = [ scheme-part "://" ] host-part [ port-part ] [ path-part ]
path-part         = <path production from RFC 3986, section 3.3>
...
```

> The `default-src` directive sets a default source list for a number of directives. The syntax for the name and value of the directive are described by the following ABNF grammar:
```
directive-name    = "default-src"
directive-value   = source-list
```
A list of source list formats: https://www.w3.org/TR/CSP2/#source_list
A list of defined CSP directives: https://www.w3.org/TR/CSP2/#directives
A `frame-ancestors` example: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/frame-ancestors ![GREAT FAILURE for attackers](https://cloud.githubusercontent.com/assets/24784041/21629167/7520e3c2-d21d-11e6-810f-6556763fe960.png)
```
Started HTTP server on port 8000

127.0.0.1 - "GET /wrapper.html HTTP/1.1" 200 -
127.0.0.1 - "GET /site_a/?vaild_request HTTP/1.1" 200 -
Content-Security-Policy: frame-ancestors http://127.0.0.1:8000/wrapper.html http://127.0.0.1:8000/site_a/;
127.0.0.1 - "GET /site_a/?vaild_request HTTP/1.1" 200 -
Content-Security-Policy: frame-ancestors http://127.0.0.1:8000/wrapper.html http://127.0.0.1:8000/site_a/;
127.0.0.1 - "GET /site_b/ HTTP/1.1" 200 -
Content-Security-Policy: frame-ancestors http://127.0.0.1:8000/wrapper.html http://127.0.0.1:8000/site_b/;
```
I only allowed a site to be framed by the wrapper, and by itself. Setting it to `"frame-ancestors http://127.0.0.1:8000/ http://127.0.0.1:8000/" + site_name + "/;"`, however, does not work.

Wrapper source code:
```html
<html>
<head>
    <style>
    #inner-iframe {
        width: 80vw;
        height: 80vh;
    }
    </style>
</head>

<body>
    <iframe src="about:blank" id="inner-iframe" sandbox="allow-forms allow-scripts allow-top-navigation allow-popups"></iframe>
    <script>
        document.getElementById('inner-iframe').src = 'site_a/?vaild_request';
    </script>
</body>
</html>
```
Note that `host-source` will not match any IPv4 address other than 127.0.0.1, or any IPv6 address.  like bitmessage
![image](https://cloud.githubusercontent.com/assets/15062548/21302026/00170196-c5ee-11e6-8597-8fc1d77fcc09.png)
 Browser notification (HTML5 notification API) is better @iShift but Browser notification (HTML5 notification API)  need user keep a page run in background okay...thanks~  my 3rd zeroid join green hub, and 48k user space only supports my 3days...
I'm creating my 4th zeroid now, but..how to deal this problem okay. I'm join kha's 500MB hub  I translate Zerome and Zerohello later.  hiï¼Œ I'm  [cinema online](http://127.0.0.1:43110/1FdEWyVHmhbwRZ3u3LmkVGQ9ei7HTcdzU7/) owner, I want to add gtihub.com/bilibili/flv.js to my site to play Flv video , but when flv.js execute `window.URL.createObjectURL(new window.MediaSource())`, it get URL is` "blob:null/3fa58623-5096-40fe-859d-1147135b2305"` , it can't be load, how to deal it? thanks~ is it a bug with chrome? I tried to add allow-same-origin to zeronet iframe, and `window.URL.createObjectURL(new window.MediaSource())` work. But..it seems like it will let zeronet to be unsafeðŸ˜‚ could zeronet add some video support? if not we are hard to build a video site in zeronet no, video in iframe can't change to full screen, now we only can change the video screen size to window size. I think maybe we can add a video support API for media file Thanks a lot thank you very much :smile:   I downloaded the Mac bundle, unzipped, moved into directory.

I ran `open ZeroNet.app`.  An application icon briefly appeared on the dock, and then disappeared.

LSOpenURLsWithRole() failed with error -10810 for the file /Users/ju/Downloads/tmp/ZeroBundle/ZeroNet.app.

After googling around, it turns out you have to make the file executable via:

`chmod +x ZeroNet.app`

It would probably help others and save time to have this in the docs.  like `python ~/Documents/ZeroNet-master/zeronet.py #startzeronet`. Anyway I don't test this in windows and maybe it's problematic there...
Anyway, maybe somebody know if it works in windows, or a more elegant way to get the same result. Uh, I just discover the existence of Travis CI, so it seems it works even on windows :dancer:  :dancer:  :dancer:  Uhg :/ yes, I got confused, at least I learn is possible something like that (idk of os.chdir), sorry for lost time....  I'm open http://127.0.0.1:43110/Console and...

Err: Exception: Here is your console in UiServer.py line 81 > UiRequest.py line 88 > UiRequest.py line 491

Details:

{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate", 
    "HTTP_ACCEPT_LANGUAGE": "ru", 
    "HTTP_CACHE_CONTROL": "max-age=0", 
    "HTTP_CONNECTION": "keep-alive", 
    "HTTP_DNT": "1", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2) AppleWebKit/602.3.12 (KHTML, like Gecko) Version/10.0.2 Safari/602.3.12", 
    "PATH_INFO": "/Console", 
    "QUERY_STRING": "", 
    "REMOTE_ADDR": "172.17.0.1", 
    "REMOTE_PORT": "34828", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "65fb732f6278", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.1 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": null, 
        "config_file": "zeronet.conf", 
        "connected_limit": 10, 
        "data_dir": "data", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "keep_ssl_cert": false, 
        "language": "en", 
        "log_dir": "log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": true, 
        "open_browser": null, 
        "optional_limit": "10%", 
        "proxy": null, 
        "size_limit": 10, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.tordb.ml:6881/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_ip": "0.0.0.0", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false
    }, 
    "plugins": [
        "AnnounceZero", 
        "CryptMessage", 
        "MergerSite", 
        "Newsfeed", 
        "OptionalManager", 
        "PeerDb", 
        "Sidebar", 
        "Stats", 
        "TranslateSite", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.1.0", 
    "version_python": "2.7.12 (default, Nov 19 2016, 06:48:10) \n[GCC 5.4.0 20160609]", 
    "version_zeronet": "0.5.1 r1756", 
    "wsgi.url_scheme": "http"
}        Plugins translated: MergerSite, Trayicon, OptionalManager  Translation done by *xeers2@zeroid.bit*, I'm only uploading it on github. Thanks  I am sometimes getting error notification when decrypting cryptMessage messages :
<pre>
Internal error: AttributeError: 'NoneType' object has no attribute 'decode'
UiWebsocket.py line 99 > UiWebsocket.py line 184 > CryptMessagePlugin.py line 103
</pre>

The problem is mismatch between message and private key after switching cert and reading old messages sent to the old cert. 

Is there any way to catch error in javascript instead of getting error notification in the UI? You are right. First step in decryption, eciesDecrypt, returns null when mismatch between encryption in incoming message and private key. No problem. Closing the issue  ```
forbo$ ./ZeroNet.app 
- Starting ZeroNet...
Can't open lock file, your ZeroNet client is probably already running, exiting... ([Errno 13] Permission denied: 'data/lock.pid')
Opening browser: %s... default_browser
```

For security purposes, it would be great to be able to run this within the context of a standard user account. If that's not possible at this point, then it would be nice to at least have some indicator in the documentation listing an administrative account as a requirement. Strange. I created a fresh standard account to test it out and it worked great. I then went back to the account I was having trouble with, deleted the bundle, re-downloaded and it worked perfectly. Not sure what the issue there would have been. Sorry to have wasted cycles, thanks for the swift response! Keep up the amazing work. I truly believe this project to be the future of the Internet.  I want to know if I should translate the `self.response` words? Such as `self.response(to, {"error": "Not a merger site"})`.  The command `Page.cmd "fileWrite"` is showing a UI message error with the text: `File write error: undefined` but there is nothing in the debug logs nor console.

**To Reproduce:**

1 - Download the site Antilibrary.bit and add the spanish DB (just because it is the smallest one)
2 - Import this CSV ([goodreads_library_export.txt](https://github.com/HelloZeroNet/ZeroNet/files/627852/goodreads_library_export.txt)) on the Goodreads CSV Importer in Antilibrary.bit (inside My Books)

The file will import and you should get this error after 2 or 3 seconds.
I can't find a way to debug this problem because it seems that this error is showing just in the UI.
 I got this mysterious error on someone's blog, when I clicked on the Like button. The `undefined` or `[object object]` message makes this issue impossible to debug. [Here](https://github.com/HelloZeroNet/ZeroNet/blob/e37daabb53453c7c11248d0f36830a51b2ef7b17/plugins/Sidebar/media/Sidebar.coffee#L337) is the notification. JavaScript cannot turn the `res` variable into a meaningful repr string. Perhaps @HelloZeroNet could log the `res` variable to console immediately. `console.error(res);` Logging error to ZeroNet console could also be helpful. The `[object object]` log is caused by the inappropriate handling of error messages. The code is shared in ZeroTalk, ZeroBlog and other official sites. Sorry, @shortcutme JavaScript doesn't have repr strings.

It may be easy to submit a patch to fix ZeroBlog, but there are many cloned sites that share the same code. It is difficult to make all of the blog writers manually update their things.

I will submit a patch of `UiWebsocket` to make the program log error messages to terminal when problem occurs. [This is still happening](http://127.0.0.1:43110/Me.ZeroNetwork.bit/?Post/1ABFCaadiEa3bFNzN3RcCZSsviqMNTbz3m/1GNgaj5EqkzqYECYbXa889fGLyuseHRi3t/1492069252) :(
  The configuration of language is stored in `zeronet.conf` so user can't change it. All users can only use the language which public proxy owner configured.
Allow users change language simply is not feasible because all users will be affected. So it needs a separate setting form uesrs store in cookie/localstorage and auto-detect via browser's language setting. @HelloZeroNet Can you please help with advice how to implement it correctly?
I have a few questions:
1. It is better to make changes in project core than in Multiuser plugin because I don't see something bad if language settings will be stored in browser cache both for single-user and multi-user usage. And this will improve consistency of the project. Do you agree with me?
2. Changes must be done in `Site/SiteStorage.py` and `Ui/UiWebsocket.py` files: `Translate` class must be initialized with `lang` variable in each invocation, there are must be no default calls without parameters. Right?
3. How and where better to get cookies from the browser? @HelloZeroNet Please review this pull request. ZeroHello code must be changed too to store language setting in cookies. Maybe I will do it later.  since, for example in the docker container, it was trying to grab the dirname from the 'zeronet.py' relative path which has no path  Hi,

What does ZeroNet do to prevent bad peer actors, for example, a (modified) peer which only holds connection open and never sends any data thus increasing time for others who asked it for data which it doesnt send. Does zeronet have any mechanism to avoid such a peer in the future? What if I would join zeronet with 100s (meh even 1000) of such peers, the network would slow down to a halt. Or even worse, a peer which sends the pieces very slowly at 1-4kb/s range.

On the other side of the coin, what would prevent 1000s of (modified) peers all to request same site from the owner, but never share any pieces with the rest of the swarm? That would effectively suck the bandwidth of the site owner for no purpose other than to prevent others from getting the zite. How is a peer identified, is it local only to the zite/peer, or is there a public/global system of accounting of bad peers?

Does Zeronet prevent such attacks? Does zeronet keep any accounting on ratio of peers in the bittorrent swarm? If not is there plans to do that.

 Thanks for quick response.

Yes, it is difficult attacks to defend from. Have any ideas on how to defend in the future?

Can we add "peer you already asked for that piece stop asking/Ill stopping serving you".

Another issue: how difficult would it be for me to generate 1 million zeroIds and use them to spam advertisements across all the sites in all the comments? As the zeroid generation seems to be centralized that could work, and it seems to take a few seconds and not require any proof-of-work? Simpler attack, if I found a user spamming/harassing my zeroblog, can I block that zeroId in the future?

Also, is there a place where these questions can be asked and discussed on ZeroNet? The ZeroTalk ZeroBoard dont seem to be very active. > because the attacker could use highend-cpu/gpu to solve it and still generate 1000s users/hour.

Yes, but then that at least costs money, and together with banexample/blocking spammers, there is little incentive to actually do it then. Isnt there a very difficult proof-of-work which would take a normal computer 30min or so to generate, and still be not-worth-it when using a high-end gpu? To be memory-intensive?

 I see!

On the same topic, have you considered using Triblers "multichain" (not the multichain company with proprietary software), which is supposed to keep a tamper-proof swarm-level (not global) reputation/score for every peer? That would avoid some attacks and reward good nodes. Maybe not really needed as most content between peers is small. Tribler does have faster anon connections than Tor though, there has been experiments with 5mb/s downloads and acceptable CPU usage for 18 circuits. Something to pick up from there? The code is all in python too.

On another topic, in a another discussion, ZeroNet seems to be using TLS for peer-to-peer communication, which is MITMable because there is no Central Authority (of course). (Maybe wrong information?) Blockcerts and maybe storing certificates in namecoin would solve that problem, so p2p connections would be really TLS with mitm prevention? See https://wiki.namecoin.info/index.php?title=Domain_Name_Specification#TLS_support
 Right, just now read a review about Triblers onions, they are indeed very badly implemented, at least was in 2014. 

I should try the patch for zeronet-over-i2p which was in here somewhere. But that much anonymity is not really required for me, or shouldnt be for anyone, if we cant trust our ISPs, we should disconnect them and make our own new internet with mesh nets and blackjack. 

Have you considered FairTorrents algorithm?

 Tribler's notorious weak crypto implementation was [caught](https://lists.torproject.org/pipermail/tor-dev/2014-December/007999.html) by Yawning Angel from Tor Project. Tribler has hard-seeded random number generators, and a piece of code, I guess written in a bad way on purpose, containing an obvious security issue:
```python
   try:
     raise ImportError()
     # Dead code, this would be slightly less horrific, maybe.
     from Crypto.Random.random import StrongRandom
   except ImportError:
     # ... Words can not describe how sad I am.
     from random import Random as StrongRandom
``` @iskradelta There is an issue and a pull request discussing I2P support. Someone on ZeroNet recently asked me how to make ZeroNet use I2P (by applying a patch), but I frankly don't know... @iskradelta:

> On another topic, in a another discussion, ZeroNet seems to be using TLS for peer-to-peer communication, which is MITMable because there is no Central Authority (of course). (Maybe wrong information?) Blockcerts and maybe storing certificates in namecoin would solve that problem, so p2p connections would be really TLS with mitm prevention?

TLS with self-signed certificates is already secure against passive attackers.  CA's and Namecoin are designed to protect against active attackers in cases where you are trying to connect to a specific identity; this is not the case with most P2P networks.  Trying to protect against MITM attacks when you don't know who your TLS peer is, is AFAIK an impossible problem (and also one that Tor onion services don't attempt to solve).  I have following requrementsï¼šBT protocol can  doï¼Ÿor changed can doï¼Ÿ
ï¼ˆ1ï¼‰data  is distributed fullly  or incrementally which mode peer can chooseï¼Ÿ
ï¼ˆ2)data  distribution support priorityï¼Ÿ
thank youï¼  Tried to start
`python zeronet.py --proxy 127.0.0.1:9050`
result: big traceback and
`Error connecting to SOCKS5 proxy 127.0.0.1:49050: [Errno 111] Connection refused
^C^CShutting down...
[04:49:23] - Unhandled exception
None`
Port 9050 in args, port 49050 in traceback. Of course, it doesn't connect. cool , solved ?  I still think it's problem, defaults must be changed. But solution works.  Hello! 
How i can one installation in multiuser system?

 What's the meaning of "one installation"? Installation in systempaths /usr/share/zeronet or /opt/zeronet or /usr/lib/python2.7/site-package/zeronet and run other users in system Try download the tar archiver and extract to /opt. /opt/zeronet/start.py 
- Starting ZeroNet...
Traceback (most recent call last):
  File "/opt/zeronet/zeronet.py", line 15, in main
    import main
  File "/opt/zeronet/src/main.py", line 95, in <module>
    PluginManager.plugin_manager.loadPlugins()
  File "/opt/zeronet/src/Plugin/PluginManager.py", line 29, in loadPlugins
    for dir_name in sorted(os.listdir(self.plugin_path)):
OSError: [Errno 2] No such file or directory: 'plugins'

and this non fix problem ls -la /opt/zeronet/
Ð¸Ñ‚Ð¾Ð³Ð¾ 96
drwxr-xr-x  5 root root  4096 Ð½Ð¾Ñ 28 19:08 ./
drwxr-xr-x 19 root root  4096 Ð½Ð¾Ñ 28 19:09 ../
-rw-r--r--  1 root root  4581 Ð½Ð¾Ñ 28 00:03 CHANGELOG.md
-rw-r--r--  1 root root     0 Ð½Ð¾Ñ 27 23:40 debugfiles.list
-rw-r--r--  1 root root     0 Ð½Ð¾Ñ 27 23:40 debuglinks.list
-rw-r--r--  1 root root     0 Ð½Ð¾Ñ 27 23:40 debugsources.list
-rw-r--r--  1 root root   755 Ð½Ð¾Ñ 28 00:03 Dockerfile
-rw-r--r--  1 root root   355 Ð½Ð¾Ñ 28 00:03 .gitignore
-rw-r--r--  1 root root 18027 Ð½Ð¾Ñ 28 00:03 LICENSE
drwxr-xr-x 19 root root  4096 Ð½Ð¾Ñ 28 19:08 plugins/
-rw-r--r--  1 root root  7459 Ð½Ð¾Ñ 28 00:03 README.md
-rw-r--r--  1 root root  7407 Ð½Ð¾Ñ 28 00:03 README-zh-cn.md
-rw-r--r--  1 root root    36 Ð½Ð¾Ñ 28 00:03 requirements.txt
drwxr-xr-x 19 root root  4096 Ð½Ð¾Ñ 28 19:08 src/
-rwxr-xr-x  1 root root   243 Ð½Ð¾Ñ 28 00:03 start.py*
drwxr-xr-x  4 root root  4096 Ð½Ð¾Ñ 28 19:08 tools/
-rw-r--r--  1 root root   495 Ð½Ð¾Ñ 28 00:03 .travis.yml
-rwxr-xr-x  1 root root  3373 Ð½Ð¾Ñ 28 00:03 update.py*
-rw-r--r--  1 root root  1196 Ð½Ð¾Ñ 28 00:03 Vagrantfile
-rwxr-xr-x  1 root root  2008 Ð½Ð¾Ñ 28 00:03 zeronet.py*
 If the program different users of the one computer launch that data of a profile there will be the general which are stored in the data folder cd into the install directory, then do this: `python2 /path/to/directory/containing/zeronet/zeronet.py --data_dir ~/data --log_dir ~/logs`. For some reason the code is picky regarding the directory you are in when you run it. python2 /opt/zeronet/zeronet.py --data_dir ~/.zeronet/data --log_dir ~/.zeronet/logs
- Starting ZeroNet...
Traceback (most recent call last):
  File "/opt/zeronet/zeronet.py", line 15, in main
    import main
  File "/opt/zeronet/src/main.py", line 95, in <module>
    PluginManager.plugin_manager.loadPlugins()
  File "/opt/zeronet/src/Plugin/PluginManager.py", line 29, in loadPlugins
    for dir_name in sorted(os.listdir(self.plugin_path)):
OSError: [Errno 2] No such file or directory: 'plugins'

d'nt fix problem  â€œShut down ZeroNetâ€ is missing.
![missing](https://cloud.githubusercontent.com/assets/18724949/20650848/9c08e506-b513-11e6-81f0-d190c977a95f.png)    Zero net has  ZeroFrame API, but can user build an API over it to make POST and GET request in JSON that can be used with $http service of angularjs. We can write the logic on the page (a local host link) that gives GET data in JSON and takes POST data in JSON. But what if some client changes the logic.  I think the owner site should be always online. POST request can only be done through owner site, where the owner can authenticate the JSON file before feeding it to the database. Even owner can host multiple (authentic) sites on different servers where post request can be done in all these sites by different clients. All authentic sites should be synced with each other. Another question is how does a client recognize the different authentic owner sites and downloaded sites from the owner? Authentic sites can have a unique public key, than that of downloaded sites, and downloaded sites can't use the authentic site public key. A registrar of username and the authentic public key and its downloaded site public key should be kept.
 Just a suggestion, what is the feasibility of including [IPFS](https://ipfs.io/) in ZeroNet? IPFS has a python [api](https://github.com/ipfs/py-ipfs-api), which can work with zeronet. Large file sharing can be done with it. It already comes precompiled. The good thing about it is, it's very [structured](https://github.com/ipfs/papers/raw/master/ipfs-cap2pfs/ipfs-p2p-file-system.pdf), and is made to be usable by different apps like ZeroNet. All file sharing can be done by ipfs, zeronet can concentrate on building the interface and logic, user authentication part etc that is developer friendly for building complicated websites. There's [a JS implementation](https://github.com/ipfs/js-ipfs) of IPFS.  ![image](https://cloud.githubusercontent.com/assets/426427/20619412/7bc1ed52-b305-11e6-923f-a7534f21dc69.png)
 Try adding "Site control" in Jason file.  im getting this error on every attempted user-originated site publish (comments, votes)

Internal error: error: nothing to repeat
UiWebsocket.py line 99 > UiWebsocket.py line 184 > MergerSitePlugin.py line 180 > MergerSitePlugin.py line 174 > UiWebsocket.py line 333 > MergerSitePlugin.py line 177 > MergerSitePlugin.py line 174 > UiWebsocket.py line 314 > ContentManager.py line 594 > ContentManager.py line 714 > re.py line 137 > re.py line 244

example function:

// get user's view.json
var inner_path = "data/users/"+Page.site_info.auth_address+"/view.json";			
Page.cmd("fileGet", { "inner_path": inner_path, "required": false },function(data) {
        (------------)				
	// write to file
	var json_raw = unescape(encodeURIComponent(JSON.stringify(data, void 0, '\t')));					
	Page.cmd("fileWrite", [inner_path, btoa(json_raw)], function(res) {
		console.log(res);
		// sign & publish site
		Page.cmd("sitePublish",["stored",inner_path], function(res) {
                    (------)
		});
	});
});

this is the site:
http://127.0.0.1:43110/1HPbR1zp6hsvrqgTSVdsEC5VWw7MEMGPTR   Ok,thanks!   You misunderstood me, I mean will the ZeroHello have responsive design for mobile devices? I want to help but I really lack of HTML... You can use browser's developer tools to test responsive design. Double tap is not convenient. And other sites (ZeroMe, ZeroMail etc.). Off topic: Which mobile phone do you use?    widerhergestellt -> wiederhergestellt

Greetings  Is there any tools like `xgettext` to extract translatable strings?
Also I think we should use _("text") to translate in js files so that we can extract translatable strings.
And it's also necessary to add format function (like Python) in js. I mean list strings in .py files. I will try to edit the pygettext.py and see if it works.    Fix KeyError Exception when a site without "title" in content.json If a site set it's title to None, a KeyError will raise.
   Usually Portuguese from Portugal is named pt-pt, as opposed to pt-br from Brazil. Shall I stick to pt.json and use pt-br.json for Brazilian Portuguese? Or just br.json (which looks kinda wrong to me, but if it fits your naming scheme better...)?
 @megfault & @HelloZeroNet, some news? @Plasmmer Hey, sorry!! I somehow got busy with Real Life(TM). I will try to submit a translation for European Portuguese soon. I see there is a Brazilian one already so I will just base mine on it.    :) for now 
https://github.com/icf20/ZeroNet/blob/master/src/Translate/languages/ro.json
 So i just translted all those files into Bosnian. Renamed hu to ba. i hope thats it  Is the Broadcast with UDP SSDP M-SEARCH comparable with the minimum spanning tree?
watch out: https://en.wikipedia.org/wiki/Distributed_minimum_spanning_tree  0
â‰¡
! Internal error: IOError: [Errno 13] Permission denied: '/etc/zeronet.conf'
UiWebsocket.py line 99 > UiWebsocket.py line 184 > UiWebsocket.py line 721 > Config.py line 336
Ã—
  

host: archlinux
version: 0.50
     After formating my computer and reinstall Zeronet, the logo for "file update failed" missing.
![capture du 2016-11-15 11-49-18](https://cloud.githubusercontent.com/assets/14799472/20302990/99550efa-ab29-11e6-88f7-746a392dd4ad.png)

I am no idea for reason of this problem.
I am on linux mint 18

Cordialy what is the font used on ZeroNet for bell utf8 ?
 Strange it's present on my system :o but the bell is not correctly formated
IÂ have no idea to solve that :D 
 ![capture du 2016-11-26 09-26-44](https://cloud.githubusercontent.com/assets/14799472/20639098/7db2ded6-b3ba-11e6-9f35-09b7a1e5b338.png)
Nothing work :(  For sites once viewed, it will remain until deleted by hand.
Every site's deletion needs a confirmation which is annoying sometimes.
Can we manage sites more efficiently, like multi-select or delete without confirmation?  Rebuild the database will cause ZeroNet not respond for a while. Is it necessary to disable it on proxy?  https://github.com/ysc3839/ZeroNet/tree/gettext
Is it good? I use gettext because there's lots of tools supports it. In my thought you can put it on online translation websites (eg. Transifex, Crowdin). Just download .po file and you can use it.
 Also, as I know Python isn't very fast. And network connection and browser loading are slower. So I think it's uncenessary to benchmark.
 > you dont need anything to edit them

You are right, but I need a program to edit them. Editing the json file may not convenient.
 Hope you can give an example for your implement.
 I wonder if there's a tool to edit/generate these json files? Currently I use Poedit to edit po files. And use `xgettext` to generate .pot files.
 These jsons function like gettext, but it uses less space than po files. And json is supported over most languages, we don't need to parse po files ourselves! ðŸ‘ 
  Also add zeronet.conf to .gitignore. Run ZeroNet and you can see the tray icon, then kill explorer.exe and start it again, the icon disappear.
 What? Can you take a screenshot?
 It seems OK in my computer.
![snipaste20161112_192701](https://cloud.githubusercontent.com/assets/12028138/20237469/199319f4-a90e-11e6-9010-4ed56fb03c10.png)
  I have the problem that my all.js file is being generated with old content.
Have deleted some js files in js/lib but they still included in all.js
Have tried commit to github before generating all.js without success.
Have cleared my trash and tried to search for old content on my harddrive
And yes, I do clear browser cache before testing changes.

Any idea why all.js file is being generated with old content?

Workaround: cat lib/*.js > all.js 3 \* check. I known. I have been a Zero dev for about a month. But have been clearing browser cache manual. Thanks for the advice with "Disable cache".

Rechecked. 
- Using UI server for all.js generation. I am back to older version of JS code after doing above and regenerated all.js. Code in all.js is not correct.
- Used "cat lib/*.js > all.js" command. Code in all.js is correct

I do not understand ...
 Deleting content of all.js file and page refresh. Site does not start.
Deleting all.js and page refresh. Cannot see any info about all.js file generation in UI server log or in console log. But all.js  is not equal sum of js files. Old content in all.js
 Is my UI server getting all.js from ZeroNet instead of generating it from js/lib files?
<pre>
[17:51:44] WorkerManager:1JeHa6..mCXk New task: js/all.js, peer lock: None, priority: 9, optional_hash_id: None, tasks started: 1
[17:51:46] WorkerManager:1JeHa6..mCXk 188.166.30.172:15441: Hash correct: js/all.js
 Thanks. You had already written the answer. "This is my site" should be enabled on sidebar". I have moved my environment to two different comp. within a week. Sorry about that.
  Is there a plan to translate strings in .py files? Do you welcome me to translate them?
  I'm getting the following error when trying to publish an user file:

```
[2016-11-08 22:01:47,498] DEBUG    Site:147nKE..kEua Signing: data/users/1KN1Au7SRmeTmffcxxoyPABDpvqmq7iMbN/data.json
[2016-11-08 22:01:47,499] WARNING  Site:147nKE..kEua Content.json parse error: IntegrityError: FOREIGN KEY constraint failed in ContentManager.py line 213 > ContentDbDict.py line 61 > ContentDbPlugin.py line 198 > ContentDb.py line 88 > Db.py line 83 > DbCursor.py line 80 > DbCursor.py line 49
[2016-11-08 22:01:47,500] INFO     Site:147nKE..kEua Opening site data directory: data/147nKEb9bBJgBDgQytEQhmiGjF8e6HkEua/data/users/1KN1Au7SRmeTmffcxxoyPABDpvqmq7iMbN/...
[2016-11-08 22:01:47,500] INFO     Site:147nKE..kEua - [SKIPPED] data.json-old
[2016-11-08 22:01:47,500] INFO     Site:147nKE..kEua - [SKIPPED] content.json
[2016-11-08 22:01:47,501] INFO     Site:147nKE..kEua - data.json (SHA512: 6370550e55a7469994e2b12aea3ed8450acb56ad7e5f1955c438dce199410c6b)
[2016-11-08 22:01:47,501] DEBUG    Site:147nKE..kEua Changed files: [u'data/users/1KN1Au7SRmeTmffcxxoyPABDpvqmq7iMbN/content.json', u'data/users/1KN1Au7SRmeTmffcxxoyPABDpvqmq7iMbN/data.json']
[2016-11-08 22:01:47,501] INFO     Site:147nKE..kEua Adding timestamp and sha512sums to new content.json...
[2016-11-08 22:01:47,501] INFO     Site:147nKE..kEua Verifying private key...
[2016-11-08 22:01:47,516] INFO     Site:147nKE..kEua Correct 1KN1Au7SRmeTmffcxxoyPABDpvqmq7iMbN in valid signers: [u'1KN1Au7SRmeTmffcxxoyPABDpvqmq7iMbN', u'147nKEb9bBJgBDgQytEQhmiGjF8e6HkEua']
[2016-11-08 22:01:47,516] INFO     Site:147nKE..kEua Signing data/users/1KN1Au7SRmeTmffcxxoyPABDpvqmq7iMbN/content.json...
[2016-11-08 22:01:47,527] INFO     Site:147nKE..kEua Saving to data/users/1KN1Au7SRmeTmffcxxoyPABDpvqmq7iMbN/content.json...
[2016-11-08 22:01:47,528] ERROR    Site:147nKE..kEua WebSocket handleRequest error: IntegrityError: FOREIGN KEY constraint failed in UiWebsocket.py line 99 > UiWebsocket.py line 182 > MergerSitePlugin.py line 180 > MergerSitePlugin.py line 174 > UiWebsocket.py line 332 > MergerSitePlugin.py line 177 > MergerSitePlugin.py line 174 > UiWebsocket.py line 313 > ContentManager.py line 601 > ContentDbDict.py line 61 > ContentDbPlugin.py line 198 > ContentDb.py line 88 > Db.py line 83 > DbCursor.py line 80 > DbCursor.py line 49
```

To reproduce:

1 - Download and rename the attached file to goodreads_library_export.csv
2 - Go to the zite antilibrary.bit, open the section My Books on the top zite menu, open 'Import Goodreads' from the left menu and import the csv

It seems that the error is happening on the cmd: Page.cmd "sitePublish", {"inner_path": inner_path}

[goodreads_library_export.txt](https://github.com/HelloZeroNet/ZeroNet/files/579482/goodreads_library_export.txt)
 I think you can close this issue alright.  I think ZeroNet sites could improve a lot if they were allowed to recommend what parts of a website to save to a client.

For example a website for sharing comics, music or whatever.
Here you could implement one button for individual comics to save them to local storage so that they wouldn't just be seeded but also would be available offline with the same features, that a site like this could offer, like a search and tagging system.
Instead of just saving what was recently visited users could seed the content they really wanted and also get something out of it for themselves.

Of course this would require some kind of permission system to make sure a website only adds optional files the user willingly opted in for and allowed.

Or is this what is possible with the new list/delete/pin/manage files? I think that's available (or large subset of it) in the new version.
 Okay cool thank you for your support!
  Server error

Err: IOError: [Errno 24] Too many open files: u'data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/data/names.json' in UiServer.py line 81 > UiRequest.py line 82 > MultiuserPlugin.py line 40 > UiRequest.py line 194 > SiteManagerPlugin.py line 59 > SiteManagerPlugin.py line 39 > SiteStorage.py line 230 > SiteStorage.py line 151

Please report it if you think this an error.

Details:
```

{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate, sdch, br", 
    "HTTP_ACCEPT_LANGUAGE": "en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4", 
    "HTTP_CONNECTION": "upgrade", 
    "HTTP_HOST": "bit.no.com", 
    "HTTP_REFERER": "https://www.google.com.hk/", 
    "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36", 
    "HTTP_X_FORWARDED_FOR": "47.89.43.124", 
    "HTTP_X_REAL_IP": "47.89.43.124", 
    "PATH_INFO": "/shadowsocksr.bit/", 
    "QUERY_STRING": "", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "38191", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "localhost", 
    "SERVER_PORT": "43111", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.1 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": null, 
        "config_file": "zeronet.conf", 
        "connected_limit": 10, 
        "data_dir": "data", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "keep_ssl_cert": false, 
        "log_dir": "log", 
        "max_files_opened": 102400, 
        "msgpack_purepython": true, 
        "multiuser_local": false, 
        "open_browser": null, 
        "proxy": null, 
        "size_limit": 10, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.aletorrenty.pl:2710/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43111, 
        "ui_restrict": false, 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false
    }, 
    "plugins": [
        "Newsfeed", 
        "Zeroname", 
        "AnnounceZero", 
        "Stats", 
        "Multiuser", 
        "Trayicon", 
        "MergerSite", 
        "CryptMessage", 
        "Sidebar"
    ], 
    "version_gevent": "1.1.0", 
    "version_python": "2.7.12 (default, Jul  1 2016, 15:12:24) \n[GCC 5.4.0 20160609]", 
    "version_zeronet": "0.4.1 r1536", 
    "wsgi.url_scheme": "http"
}
``` Thanks.
 I have encounted the problem but as far as I'm concerned, once the http connection is closed, FD should be released other than stay in the process. I haven't review your code yet but I think may be there is something wrong with your http connection processing procedure. Hope for reply. for my client, fd open is 3 as well. but what i use is keep-alive connection and still get problem. That's the console reports:
`Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/gevent-1.0.2-py2.7-linux-i686.egg/gevent/greenlet.py", line 327, in run
  File "plugins/AnnounceZero/AnnounceZeroPlugin.py", line 43, in announceTracker
  File "/home/test/ZeroNet-master/src/Site/Site.py", line 725, in announceTracker
  File "/home/test/ZeroNet-master/src/lib/subtl/subtl.py", line 42, in __init__
  File "/usr/local/lib/python2.7/dist-packages/gevent-1.0.2-py2.7-linux-i686.egg/gevent/socket.py", line 229, in __init__
    self._sock = _realsocket(family, type, proto)
error: [Errno 24] Too many open files` I think to deal with the problem is not just changing system max FD settings. All opened FD should be closed after use.

What I want to do is use a local zeronet client as a web proxy to crawl webpages in zeronet. I use `python gevent` to request webpages asynchronously but once the number of my requests reach about 1000, the problem occured. Netstat is all normal, juse take about 20 port as I set, so I don't think it's all of tcp collections. 

Or you can tell me what should I do if I want to use the client as a web proxy.:) thank you very much.   I know what's the problem. Because after explorer.exe started all tray icon were cleared, apps need to re create them again. I'll try to fix it on weekends if I have time.
  generated link: http://127.0.0.1:43110/15F9LYs6c17NUXv3MxpJSGbpWxyHTEbzMk/stream/audio.html?wrapper_nonce=83838116cdd6148da634b34d78e2862cfc17ab809d63a6010f51511b95c39604?ID=038adceb2b5f4bf9451df7a8b6cf9393ea693918

{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate", 
    "HTTP_ACCEPT_LANGUAGE": "es,en-US;q=0.7,en;q=0.3", 
    "HTTP_CONNECTION": "keep-alive", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (X11; Linux x86_64; rv:38.0) Gecko/20100101 Firefox/38.0 Iceweasel/38.6.1", 
    "PATH_INFO": "/15F9LYs6c17NUXv3MxpJSGbpWxyHTEbzMk/stream/audio.html", 
    "QUERY_STRING": "wrapper_nonce=83838116cdd6148da634b34d78e2862cfc17ab809d63a6010f51511b95c39604?ID=038adceb2b5f4bf9451df7a8b6cf9393ea693918", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "46201", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "localhost", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.0 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": null, 
        "config_file": "zeronet.conf", 
        "connected_limit": 10, 
        "data_dir": "data", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "keep_ssl_cert": false, 
        "log_dir": "log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": true, 
        "open_browser": null, 
        "proxy": null, 
        "size_limit": 10, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.aletorrenty.pl:2710/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false
    }, 
    "plugins": [
        "AnnounceZero", 
        "Trayicon", 
        "Zeroname", 
        "Sidebar", 
        "Newsfeed", 
        "MergerSite", 
        "CryptMessage", 
        "Stats"
    ], 
    "version_gevent": "1.0.1", 
    "version_python": "2.7.9 (default, Jun 29 2016, 13:08:31) \n[GCC 4.9.2]", 
    "version_zeronet": "0.4.1 r1536", 
    "wsgi.url_scheme": "http"
}  Hi.

I am running on Debian GNU/Linux 8 "Jessie".
I clone the repo and installed python-msgpack and python-gevent.

I tried to start ZeroNet:

```
$ ./zeronet.py - Starting ZeroNet...
[12:36:23] - OpenSSL loaded, version: 01000114F
[12:36:23] - Version: 0.4.1 r1536, Python 2.7.9 (default, Jun 29 2016, 13:08:31) 
[GCC 4.9.2], Gevent: 1.0.1
[12:36:23] - Creating FileServer....
[12:36:23] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 154 > socket.py line 342
[12:36:23] ConnServer Error: Unsupported msgpack version: (0, 1, 10) (<0.4.0), please run `sudo apt-get install python-pip; sudo pip install msgpack-python --upgrade`
[12:36:23] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
```

On Debian 8, the version of python-msgpack is 0.4.2, so it was strange. https://packages.debian.org/jessie/python-msgpack
I decided to give a try to the version of Debian 9 "Stretch" (`aptitude install python-msgpack/stretch`) that is 0.4.8. https://packages.debian.org/stretch/python-msgpack

I have now this error:
```
$ ./zeronet.py
- Starting ZeroNet...
[12:39:13] - OpenSSL loaded, version: 01000114F
[12:39:13] - Version: 0.4.1 r1536, Python 2.7.9 (default, Jun 29 2016, 13:08:31) 
[GCC 4.9.2], Gevent: 1.0.1
[12:39:13] - Creating FileServer....
[12:39:13] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 154 > socket.py line 342
[12:39:13] - Creating UiServer....
[12:39:13] SiteManager Deleting orphan site from content.db: 1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F
Traceback (most recent call last):
  File "./zeronet.py", line 16, in main
    main.start()
  File "./src/main.py", line 420, in start
    actions.call(config.action, action_kwargs)
  File "./src/main.py", line 120, in call
    func(**kwargs)
  File "./src/main.py", line 130, in main
    ui_server = UiServer()
  File "./src/Ui/UiServer.py", line 61, in __init__
    self.sites = SiteManager.site_manager.list()
  File "./src/Site/SiteManager.py", line 130, in list
    self.load()
  File "plugins/Zeroname/SiteManagerPlugin.py", line 17, in load
    super(SiteManagerPlugin, self).load(*args, **kwargs)
  File "plugins/MergerSite/MergerSitePlugin.py", line 301, in load
    super(SiteManagerPlugin, self).load(*args, **kwags)
  File "./src/Site/SiteManager.py", line 53, in load
    ContentDb.getContentDb().deleteSite(row["address"])
  File "./src/Content/ContentDb.py", line 65, in deleteSite
    site_id = self.site_ids[site_address]
KeyError: u'1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F'
```

Apparently, it is now an error in the code of ZeroNet. I tried with the version of the commit 4ac933fa294344833231b6a4a771e47207cd0a4b (19 13:19:32 2016 -0700).

Regards. Remove `/data/content.db` and try again.
 ```
$ ps -ef | grep ero
$ rm data/content.db
$ ./zeronet.py- Starting ZeroNet...
[20:54:46] - OpenSSL loaded, version: 01000114F
[20:54:46] - Version: 0.4.1 r1536, Python 2.7.9 (default, Jun 29 2016, 13:08:31) 
[GCC 4.9.2], Gevent: 1.0.1
[20:54:47] - Creating FileServer....
[20:54:47] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 154 > socket.py line 342
[20:54:47] - Creating UiServer....
[20:54:47] - Removing old SSL certs...
[20:54:47] - Starting servers....
[20:54:47] Ui.UiServer --------------------------------------
[20:54:47] Ui.UiServer Web interface: http://127.0.0.1:43110/
[20:54:47] Ui.UiServer --------------------------------------
[20:54:49] FileServer Checking port 15441 using portchecker.co...
[20:54:50] FileServer [BAD :(] Port closed: Port 15441 is closed.
[20:54:50] FileServer Trying to open port using UpnpPunch...
[20:55:05] FileServer UpnpPunch run error: UpnpError: Failed to communicate with igd using port 15441 on local machine after 3 tries. in FileServer.py line 73 > UpnpPunch.py line 319 > UpnpPunch.py line 310
[21:05:47] FileServer Internet offline
[21:07:50] FileServer Internet online
[21:07:51] FileServer Checking port 15441 using portchecker.co...
[21:07:52] FileServer [BAD :(] Port closed: Port 15441 is closed.
[21:07:52] FileServer Trying to open port using UpnpPunch...
```

5 minutes later, nothing changed. But it worked. The messages were not clear about that for me.
However, it does not launch the web browser like the bundle version. Is it normal?
 Ok, thanks.
  When changing settings like always having Tor on, Zeronet tries to edit a file in /etc/ which is global to all users. Every user should have their own zeronet configuration in their home directory.   I am running ZeroNet on my localhost using ubuntu and i want my site from another computer which is not running ZeroNet..................

Ex: Computher 1 running ZeroNet on port 43110
      Computer 2 accessing ZeroNet site from computer one on port 8080 " something like that"  Perhaps it's just me, but is there a point to testing for the port before checking for tor settings?  RT-AC54U /opt/home/admin/ZeroNet-master]# opkg install libopenssl
Upgrading libopenssl on root from 1.0.2h-1 to 1.0.2j-1...
Downloading http://pkg.entware.net/binaries/mipsel/libopenssl_1.0.2j-1_mipselsf.ipk.
Configuring libopenssl.
[RT-AC54U /opt/home/admin/ZeroNet-master]# opkg install python-openssl
Upgrading python-openssl on root from 2.7.11-9 to 2.7.12-2...
Downloading http://pkg.entware.net/binaries/mipsel/python-openssl_2.7.12-2_mipselsf.ipk.
Configuring python-openssl.
[RT-AC54U /opt/home/admin/ZeroNet-master]# ./zeronet.py
- Starting ZeroNet...
[23:49:28] - OpenSSL load failed: File not found, falling back to slow bitcoin verify
[23:49:30] - Version: 0.4.1 r1536, Python 2.7.11 (default, Aug 15 2016, 19:04:16)
[GCC 5.3.0], Gevent: 1.1.2
[23:49:35] - Creating FileServer....
[23:49:36] TorManager Tor controller connect error: error: can't start new thread in TorManager.py line 154 > _socket2.py line 218 > _socketcommon.py line 268 > resolver_thread.py line 64 > pool.py line 300 > threadpool.py line 175 > threadpool.py line 136 > threadpool.py line 116 > threadpool.py line 145
[23:49:36] - Creating UiServer....
[23:49:36] SiteManager Deleting orphan site from content.db: 1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F
Traceback (most recent call last):
  File "./zeronet.py", line 16, in main
    main.start()
  File "./src/main.py", line 420, in start
    actions.call(config.action, action_kwargs)
  File "./src/main.py", line 120, in call
    func(**kwargs)
  File "./src/main.py", line 130, in main
    ui_server = UiServer()
  File "./src/Ui/UiServer.py", line 61, in __init__
    self.sites = SiteManager.site_manager.list()
  File "./src/Site/SiteManager.py", line 130, in list
    self.load()
  File "plugins/Zeroname/SiteManagerPlugin.py", line 17, in load
    super(SiteManagerPlugin, self).load(*args, **kwargs)
  File "plugins/MergerSite/MergerSitePlugin.py", line 301, in load
    super(SiteManagerPlugin, self).load(*args, **kwags)
  File "./src/Site/SiteManager.py", line 53, in load
    ContentDb.getContentDb().deleteSite(row["address"])
  File "./src/Content/ContentDb.py", line 65, in deleteSite
    site_id = self.site_ids[site_address]
KeyError: u'1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F'
[RT-AC54U /opt/home/admin/ZeroNet-master]# BusyBox v1.24.2 (2016-10-28 01:25:25 CST) built-in shell (ash)
Enter 'help' for a list of built-in commands.

[RT-AC54U /opt/home/admin]# cd Z*
[RT-AC54U /opt/home/admin/ZeroNet-master]# netstat -apn
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        0      0 0.0.0.0:843             0.0.0.0:\*               LISTEN      7055/ikuacc
tcp        0      0 192.168.123.1:139       0.0.0.0:\*               LISTEN      758/smbd
tcp        0      0 0.0.0.0:9900            0.0.0.0:\*               LISTEN      7055/ikuacc
tcp        0      0 0.0.0.0:8908            0.0.0.0:\*               LISTEN      7055/ikuacc
tcp        0      0 0.0.0.0:80              0.0.0.0:\*               LISTEN      614/httpd
tcp        0      0 0.0.0.0:4466            0.0.0.0:\*               LISTEN      7055/ikuacc
tcp        0      0 0.0.0.0:36947           0.0.0.0:\*               LISTEN      622/miniupnpd
tcp        0      0 127.0.0.1:53            0.0.0.0:\*               LISTEN      1775/dnsmasq
tcp        0      0 192.168.123.1:53        0.0.0.0:\*               LISTEN      1775/dnsmasq
tcp        0      0 0.0.0.0:22              0.0.0.0:\*               LISTEN      618/dropbear
tcp        0      0 192.168.123.1:445       0.0.0.0:\*               LISTEN      758/smbd
tcp        0      0 192.168.123.1:22        192.168.123.60:46645    ESTABLISHED 4310/dropbear
tcp        0      0 192.168.123.1:22        192.168.123.171:57747   ESTABLISHED 7190/dropbear
udp        0      0 127.0.0.1:53            0.0.0.0:\*                           1775/dnsmasq
udp        0      0 192.168.123.1:53        0.0.0.0:\*                           1775/dnsmasq
udp        0      0 0.0.0.0:67              0.0.0.0:\*                           1775/dnsmasq
udp        0      0 192.168.123.1:58710     0.0.0.0:\*                           622/miniupnpd
udp        0      0 0.0.0.0:1900            0.0.0.0:\*                           622/miniupnpd
udp        0      0 0.0.0.0:4466            0.0.0.0:\*                           7055/ikuacc
udp        0      0 192.168.123.1:137       0.0.0.0:\*                           755/nmbd
udp        0      0 0.0.0.0:137             0.0.0.0:\*                           755/nmbd
udp        0      0 192.168.123.1:138       0.0.0.0:\*                           755/nmbd
udp        0      0 0.0.0.0:138             0.0.0.0:\*                           755/nmbd
udp        0      0 0.0.0.0:8909            0.0.0.0:\*                           7055/ikuacc
Active UNIX domain sockets (servers and established)
Proto RefCnt Flags       Type       State         I-Node PID/Program name    Path
unix  10     [ ]         DGRAM                       316 336/syslogd         /dev/log
unix  2      [ ACC ]     STREAM     LISTENING      37038 7190/dropbear       /tmp/dropbear-3d091c9a/auth-fabf33b8-7
unix  2      [ ACC ]     STREAM     LISTENING      21993 4310/dropbear       /tmp/dropbear-ae59ac9e/auth-2032eb2a-7
unix  2      [ ]         DGRAM                      3141 2196/crond          unix  2      [ ]         DGRAM                      2345 1775/dnsmasq        unix  2      [ ]    
 RT-AC54U /opt/home/admin/ZeroNet-master]# ./zeronet.py
- Starting ZeroNet...
  [00:14:52] - OpenSSL load failed: File not found, falling back to slow bitcoin verify
  [00:14:54] - Version: 0.4.1 r1536, Python 2.7.11 (default, Aug 15 2016, 19:04:16)
  [GCC 5.3.0], Gevent: 1.1.2
  [00:14:59] - Creating FileServer....
  [00:14:59] TorManager Tor controller connect error: error: can't start new thread in TorManager.py line 154 > _socket2.py line 218 > _socketcommon.py line 268 > resolver_thread.py line 64 > pool.py line 300 > threadpool.py line 175 > threadpool.py line 136 > threadpool.py line 116 > threadpool.py line 145
  [00:14:59] - Creating UiServer....
  [00:14:59] SiteManager Deleting orphan site from content.db: 1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F
  Traceback (most recent call last):
  File "./zeronet.py", line 16, in main
    main.start()
  File "./src/main.py", line 420, in start
    actions.call(config.action, action_kwargs)
  File "./src/main.py", line 120, in call
    func(**kwargs)
  File "./src/main.py", line 130, in main
    ui_server = UiServer()
  File "./src/Ui/UiServer.py", line 61, in __init__
    self.sites = SiteManager.site_manager.list()
  File "./src/Site/SiteManager.py", line 130, in list
    self.load()
  File "plugins/Zeroname/SiteManagerPlugin.py", line 17, in load
    super(SiteManagerPlugin, self).load(_args, *_kwargs)
  File "plugins/MergerSite/MergerSitePlugin.py", line 301, in load
    super(SiteManagerPlugin, self).load(_args, *_kwags)
  File "./src/Site/SiteManager.py", line 53, in load
    ContentDb.getContentDb().deleteSite(row["address"])
  File "./src/Content/ContentDb.py", line 65, in deleteSite
    site_id = self.site_ids[site_address]
  KeyError: u'1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F'
  [RT-AC54U /opt/home/admin/ZeroNet-master]# rm data/content.db
  [RT-AC54U /opt/home/admin/ZeroNet-master]# ./zeronet.py
- Starting ZeroNet...
  [00:15:43] - OpenSSL load failed: File not found, falling back to slow bitcoin verify
  [00:15:44] - Version: 0.4.1 r1536, Python 2.7.11 (default, Aug 15 2016, 19:04:16)
  [GCC 5.3.0], Gevent: 1.1.2
  [00:15:49] - Creating FileServer....
  [00:15:49] TorManager Tor controller connect error: error: can't start new thread in TorManager.py line 154 > _socket2.py line 218 > _socketcommon.py line 268 > resolver_thread.py line 64 > pool.py line 300 > threadpool.py line 175 > threadpool.py line 136 > threadpool.py line 116 > threadpool.py line 145
  [00:15:49] - Creating UiServer....
  [00:15:49] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
  [00:15:49] - Removing old SSL certs...
  [00:15:49] - Starting servers....
  [00:15:50] Ui.UiServer --------------------------------------
  [00:15:50] Ui.UiServer Web interface: http://127.0.0.1:43110/
  [00:15:50] Ui.UiServer --------------------------------------
  [00:15:50] Ui.UiServer Web interface bind error, must be running already, exiting.... can't start new thread
  [00:16:09] FileServer StreamServer bind error, must be running already: 'StreamServer' object has no attribute 'handle'
  [RT-AC54U /opt/home/admin/ZeroNet-master]#
 And I don't know why it can't load openssl .  
 [RT-AC54U /opt/home/admin/ZeroNet-master]# python -c "import ctypes.util; print ctypes.util.find_library('crypto')"
None
[RT-AC54U /opt/home/admin/ZeroNet-master]# pip install crypto
Collecting crypto
  Downloading crypto-1.4.1-py2.py3-none-any.whl
Collecting Naked (from crypto)
  Downloading Naked-0.1.31-py2.py3-none-any.whl (590kB)
    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 593kB 84kB/s
Collecting shellescape (from crypto)
  Downloading shellescape-3.4.1-py2.py3-none-any.whl
Collecting pyyaml (from Naked->crypto)
  Downloading PyYAML-3.12.tar.gz (253kB)
    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256kB 200kB/s
Collecting requests (from Naked->crypto)
  Downloading requests-2.11.1-py2.py3-none-any.whl (514kB)
    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 522kB 93kB/s
Installing collected packages: pyyaml, requests, Naked, shellescape, crypto
  Running setup.py install for pyyaml ... done
Successfully installed Naked-0.1.31 crypto-1.4.1 pyyaml-3.12 requests-2.11.1 shellescape-3.4.1
[RT-AC54U /opt/home/admin/ZeroNet-master]# python -c "import ctypes.util; print ctypes.util.find_library('crypto')"
None
[RT-AC54U /opt/home/admin/ZeroNet-master]#

ðŸ˜‚I have no idear to slove that tooï¼Œit seems that zeronet can't run in entware envã€‚ã€‚ã€‚waitã€‚ã€‚i think maybe it's memory use upï¼Œ router only have 120Mb mem and 90mb in useï¼Œmaybe that is the problem maker
 today is too lateï¼Œim in Chinaã€‚ã€‚tomorrow morning i will try to slove it ã€‚ã€‚wish expand swap will work
 It seems that expand swap not helpful...Thanks for your help
 ```
from thread import stack_size
stack_size(32768)
```
the module threading is a wrapper for thread.  Actually, I am confused about front-end of zeronet website, since every website suffers an "O" in the up-right corner.
I have no ideas about how to get a clear & clean website.
Every page I have seen in the zeronet all uses Wrapper.coffee as a part of js code which adds a big "o" in its coner. Cause it's ZeroNet.so there is a zero(O),I guess.

2016å¹´11æœˆ4æ—¥æ˜ŸæœŸäº”ï¼Œsuzumiyasmith notifications@github.com å†™é“ï¼š

> Actually, I am confused about front-end of zeronet website, since every
> website suffers an "O" in the up-right corner.
> I have no ideas about how to get a clear & clean website.
> Every page I have seen in the zeronet all uses Wrapper.coffee as a part of
> js code which adds a big "o" in its coner.
> 
> â€”
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/issues/626, or mute the thread
> https://github.com/notifications/unsubscribe-auth/AFgy_f9ipYqbn5hFtSHfBPtl0qzLmsxdks5q6r6rgaJpZM4KpMsP
> .
  At the moment, Zeronet will start to seed a site as soon as you visit it. This is problematic, because users might accidently seed content that's illegal in their country. Additionally, it means you get a lot of connected sites really fast.

Instead, it should be possible to browse sites without connecting to them. Zeronet should show a button "Connect to Site", which starts seeding it.

[Discussion on this topic on Reddit](https://www.reddit.com/r/zeronet/comments/5a41ss/i_love_the_idea_and_the_technology_its_truly/)  Forbidden
Media referrer error
Please report it if you think this an error.

Details:

{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,_/_;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip", 
    "HTTP_ACCEPT_LANGUAGE": "en-SG,en-US;q=0.8,en;q=0.6", 
    "HTTP_CF_CONNECTING_IP": "204.44.93.202", 
    "HTTP_CF_IPCOUNTRY": "US", 
    "HTTP_CF_RAY": "2f9f97a5a24507e5-LAX", 
    "HTTP_CF_VISITOR": "{\"scheme\":\"http\"}", 
    "HTTP_CONNECTION": "Keep-Alive", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_MAX_FORWARDS": "100", 
    "HTTP_REFERER": "http://zeronet.0o0o0.ml/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
    "HTTP_SAVE_DATA": "on", 
    "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Linux; Android 6.0.1; SM-G9008V Build/MOB31E) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.28 Mobile Safari/537.36", 
    "HTTP_X_FORWARDED_FOR": "204.44.93.202, 173.245.48.71", 
    "HTTP_X_FORWARDED_HOST": "zeronet.0o0o0.ml", 
    "HTTP_X_FORWARDED_PROTO": "http", 
    "HTTP_X_FORWARDED_SERVER": "zeronet.0o0o0.ml", 
    "PATH_INFO": "/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/", 
    "QUERY_STRING": "wrapper_nonce=4f109fba2ddb543806336e71392e1046c264bcbf74cdc10a0b059ec32d06aa6e", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "37001", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "localhost.localdomain", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.0 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": null, 
        "config_file": "zeronet.conf", 
        "connected_limit": 10, 
        "data_dir": "data", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "keep_ssl_cert": false, 
        "log_dir": "log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": true, 
        "open_browser": null, 
        "proxy": null, 
        "size_limit": 10, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.aletorrenty.pl:2710/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false
    }, 
    "plugins": [
        "Zeroname", 
        "MergerSite", 
        "Newsfeed", 
        "Trayicon", 
        "AnnounceZero", 
        "CryptMessage", 
        "Sidebar", 
        "Stats"
    ], 
    "version_gevent": "1.0.2", 
    "version_python": "2.7.11 |Continuum Analytics, Inc.| (default, Dec  6 2015, 18:08:32) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]", 
    "version_zeronet": "0.4.1 r1536", 
    "wsgi.url_scheme": "http"
}
 å“¦è€¶ @@  thank you very much. i get it .:))
  Serve either the standard ZeroNet (icon](https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/media/img/favicon.ico) or an image referenced in `content.json` (example):

``` json
"title": "foo.bit",
"favicon": "1CLJpP511DDvMsrkdxufodHvLfZZdTtckr/favicon.png"
```
- [x] Simplify relative path resolution of favicon
- [x] Create a PR for "readthedocs" documentation

I'd like to create an associated PR for the documentation site before merging this in.

For some reason including the site address in the favicon path appears to be required...would love suggestions on allowing the path to look like its based from the site root directory:

``` json
"favicon": "favicon.png"
```
 I agree, I want the favicon to work without adding the address but it hasn't worked for me yet. I'm all for any suggestions.
 Okay, I've fixed the relative paths. Here's a small [repo](https://github.com/mishfit/testZeroNetDynamicFavicon/tree/master/1PoxxaBW6VVeZmRvZ2LY9do5xq1hnoYJ5m) I used for testing it.
  Was hoping to get dynamic favicon files served by the UiServer. I've created a tentative [commit](https://github.com/mishfit/ZeroNet/commit/84ea1687ab76b27688f44d61abdf99d92c985a5e) but am not sure I'm using the right approach.

I've removed the lines where UiRequest blindly serves the standard ZeroNet favicon and added an attempt to retrieve the favicon from content.json.

I've also changed the wrapper template to take a favicon variable and add the appropriate header link tag.

I would appreciate it if you could look it over, critique it, and (if acceptable) I'll create the PR for it.
 Cool, I've made a [PR](https://github.com/HelloZeroNet/ZeroNet/pull/621). I just need to update the docs and make a PR for that too
  Allow access to methods of `window.parent.location` like `hash` or `query`.
 You are right, it is a security issue.

As you said I can modify the hash/query with `window.top.location = "?something#hello2"` but I am not able to read the value of hash/query.

![screen shot 2016-10-19 at 23 36 32](https://cloud.githubusercontent.com/assets/16633/19538569/f09db1ba-9654-11e6-808e-a8053d2e785f.png)

What do you suggest? 
 Thank you very much for the answers: D
  Translated README.md to Chinese(Simplified)
 ## [Current coverage](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/617?src=pr) is 48.41% (diff: 100%)

> Merging [#617](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/617?src=pr) into [master](https://codecov.io/gh/HelloZeroNet/ZeroNet/branch/master?src=pr) will decrease coverage by **0.02%**

``` diff
@@             master       #617   diff @@
==========================================
  Files            57         57          
  Lines          7074       7074          
  Methods           0          0          
  Messages          0          0          
  Branches       1469       1469          
==========================================
- Hits           3427       3425     -2   
- Misses         3233       3234     +1   
- Partials        414        415     +1   
```

> Powered by [Codecov](https://codecov.io?src=pr). Last update [5f3b014...c519cc2](https://codecov.io/gh/HelloZeroNet/ZeroNet/compare/5f3b01476a090f9dc6f59bf2e756043d55ca98b0...c519cc21c65bb85e706945d303844ab6c770c66d?src=pr)
  Created a changelog file for ZeroNet (using the repository made by skwyinder: github_changelog_generator) in reponse to issue #606.
 ## [Current coverage](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/614?src=pr) is 48.48% (diff: 100%)

> Merging [#614](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/614?src=pr) into [master](https://codecov.io/gh/HelloZeroNet/ZeroNet/branch/master?src=pr) will increase coverage by **0.04%**

``` diff
@@             master       #614   diff @@
==========================================
  Files            57         57          
  Lines          7074       7074          
  Methods           0          0          
  Messages          0          0          
  Branches       1469       1469          
==========================================
+ Hits           3427       3430     +3   
+ Misses         3233       3230     -3   
  Partials        414        414          
```

> Powered by [Codecov](https://codecov.io?src=pr). Last update [5f3b014...7b52248](https://codecov.io/gh/HelloZeroNet/ZeroNet/compare/5f3b01476a090f9dc6f59bf2e756043d55ca98b0...7b522481e70bafc981cab8e38c47e191736dd92e?src=pr)
 nice, thank you. 
  Because I want to separate the political speech ID and personal use ID
 You mean "disabled-Multiuser" i try to rename but will be Crash(ERROR)
 theres another question when i use the new user its tell me i using proxymode can't clone any "apps" like ZeroBlog
 @HelloZeroNet 

> it's very easy to connect your accounts if you posting on both using the same connections.

Could you explain a little bit more details how accounts can be matched?
Do you mean your peers may listen to traffic and notice posting from same peer with different id?
Is it possible to be sure that this is you posting and you not just send update from someone else? @HelloZeroNet 

Thanks! As I understand, the number of peers one may connect is not infinite and with growth of ZN the likelihood that first source of update in your neighbourhood is the first source of update globally will decline, is this correct (1)? Also, if we have triangle like A-B, B-C, A-C, is this impossible that A starts to publish its updates to all peers but in some cases B will receive it first and publish it to C quicker than A (2)? @HelloZeroNet Can the issue be closed?  When I try to connect to ZeroHello using the Brave browser I don't see any content and the message `Connection with UiServer Websocket was lost. Reconnecting...` keeps reappearing. This occurs when I have the MultiUser plugin enabled.
 That's false. It's easy to see on the ZeroNet server that connections to port 43110 are actually established.
And it actually works.

![image](https://cloud.githubusercontent.com/assets/13134193/19437338/8ca44114-94a7-11e6-8109-af0226814fc4.png)
 @unsystemizer Thanks for the update. I am actually having the issue in MultiUser mode. By default, Zeronet _does_ work with Brave.
 Can you paste the startup command(s) so that people can duplicate the issue?

If you run multiple instances, there should be no difference (if you bind different ports) because it's effectively many single user instances.
https://github.com/HelloZeroNet/ZeroNet/issues/613#issuecomment-254042814 
 I just running a normal install but turning on MultiUser. The easiest way to test is to try a proxy site like: https://onlyzero.net/

I have the issue on that proxy with the Brave browser.
 Probably something that should be fixed in Brave anyway.
 @HelloZeroNet Of course, allow 3rd party cookie control is required on single instance as well (Brave in my screenshot above can't work with ZN without it as well), but it's not something that is related to multi-user mode (or even to ZeroNet).
  While testing with Tails (see #610) ZeroNet stops or gets stuck while attempting to make a connection.
I stop it with CTRL+C and the next time I start, it can't auto-cleanup corrupt data. Something is wrong with the cleanup code. 

A workaround (because it can't connect, I don't have any data except the auto-generated address) is to `rm -rf data`.
 Error log:

```
amnesia@amnesia:~/.ssh/zeronet/ZeroNet-master$ python zeronet.py --proxy 127.0.0.1:9050 --tor disable
- Starting ZeroNet...
[16:44:21] - OpenSSL loaded, version: 01000114F
[16:44:21] - Patching sockets to socks proxy: 127.0.0.1:9050
[16:44:21] - Version: 0.4.1 r1536, Python 2.7.9 (default, Aug 13 2016, 16:41:35) 
[GCC 4.9.2], Gevent: 1.0.1
[16:44:21] - Creating FileServer....
[16:44:21] - Creating UiServer....
[16:44:21] SiteManager Deleting orphan site from content.db: 1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F
Traceback (most recent call last):
  File "zeronet.py", line 16, in main
    main.start()
  File "src/main.py", line 420, in start
    actions.call(config.action, action_kwargs)
  File "src/main.py", line 120, in call
    func(**kwargs)
  File "src/main.py", line 130, in main
    ui_server = UiServer()
  File "src/Ui/UiServer.py", line 61, in __init__
    self.sites = SiteManager.site_manager.list()
  File "src/Site/SiteManager.py", line 130, in list
    self.load()
  File "plugins/MergerSite/MergerSitePlugin.py", line 301, in load
    super(SiteManagerPlugin, self).load(*args, **kwags)
  File "plugins/Zeroname/SiteManagerPlugin.py", line 17, in load
    super(SiteManagerPlugin, self).load(*args, **kwargs)
  File "src/Site/SiteManager.py", line 53, in load
    ContentDb.getContentDb().deleteSite(row["address"])
  File "src/Content/ContentDb.py", line 65, in deleteSite
    site_id = self.site_ids[site_address]
KeyError: u'1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F'
```
  I encountered these three:
1. It seems Tails has restrictive Tor SOCKS proxy rules so that apps that don't work properly don't use it.  
   When ZeroNet is started Tor SOCKS proxy refuses connection. I couldn't find what is making Tor Socks proxy refuse connections (I looked at https://git-tails.immerda.ch/tails/plain/config/chroot_local-includes/etc/ferm/ferm.conf and https://git-tails.immerda.ch/tails/plain/config/chroot_local-includes/etc/tor/torrc). I did not try to run ZeroNet as root.
2. uPnP punching also doesn't work (as amnesia user with and without sudo).
3. When ZeroNet is started without Tor and Tor proxy, it also cannot connect (running as amnesia, with or without sudo).

Basically no matter how you run it (except possibly as root), it cannot establish connections and work.
 Well it doesn't work here. 
I got the log files over - this is current Tails and ZeroNet and points 1) and 2) can be seen.
I double checked the Tor Socks port (tried --tor-proxy as well).

###Tor Disabled

```
amnesia@amnesia:~/.ssh/zeronet/ZeroNet-master$ python zeronet.py --proxy 127.0.0.1:9050 --tor disable
- Starting ZeroNet...
[16:45:06] - OpenSSL loaded, version: 01000114F
[16:45:06] - Patching sockets to socks proxy: 127.0.0.1:9050
[16:45:06] - Version: 0.4.1 r1536, Python 2.7.9 (default, Aug 13 2016, 16:41:35) 
[GCC 4.9.2], Gevent: 1.0.1
[16:45:06] - Creating FileServer....
[16:45:06] - Creating UiServer....
[16:45:06] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[16:45:06] - Removing old SSL certs...
[16:45:06] - Starting servers....
[16:45:06] Ui.UiServer --------------------------------------
[16:45:06] Ui.UiServer Web interface: http://127.0.0.1:43110/
[16:45:06] Ui.UiServer --------------------------------------
[16:45:06] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[16:45:07] FileServer Checking port 15441 using portchecker.co...
[16:45:11] FileServer [BAD :(] Port closed: Port 15441 is closed.
[16:45:11] FileServer Trying to open port using UpnpPunch...
[16:45:11] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[16:45:13] FileServer UpnpPunch run error: error: [Errno 1] Operation not permitted in FileServer.py line 73 > UpnpPunch.py line 319 > UpnpPunch.py line 298 > UpnpPunch.py line 273 > UpnpPunch.py line 254 > UpnpPunch.py line 50 > socket.py line 474
```

###Tor Enabled

```
amnesia@amnesia:~/.ssh/zeronet/ZeroNet-master$ python zeronet.py --proxy 127.0.0.1:9050 --tor enable
- Starting ZeroNet...
[16:43:03] - OpenSSL loaded, version: 01000114F
[16:43:03] - Patching sockets to socks proxy: 127.0.0.1:9050
[16:43:03] - Version: 0.4.1 r1536, Python 2.7.9 (default, Aug 13 2016, 16:41:35) 
[GCC 4.9.2], Gevent: 1.0.1
[16:43:03] - Creating FileServer....
[16:43:04] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 154 > socket.py line 342
[16:43:04] - Creating UiServer....
[16:43:04] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[16:43:04] - Removing old SSL certs...
[16:43:04] - Starting servers....
[16:43:04] Ui.UiServer --------------------------------------
[16:43:04] Ui.UiServer Web interface: http://127.0.0.1:43110/
[16:43:04] Ui.UiServer --------------------------------------
[16:43:04] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[16:43:05] FileServer Checking port 15441 using portchecker.co...
[16:43:05] Site:1Name2..hM9F Announce to 0 trackers in 1.012s, failed
[16:43:06] FileServer [BAD :(] Port closed: Error: ProxyConnectionError: Error connecting to SOCKS5 proxy 127.0.0.1:49050: [Errno 111] Connection refused in FileServer.py line 98 > urllib2.py line 154 > urllib2.py line 431 > urllib2.py line 449 > urllib2.py line 409 > urllib2.py line 1227 > urllib2.py line 1194 > httplib.py line 1039 > httplib.py line 1073 > httplib.py line 1035 > httplib.py line 879 > httplib.py line 841 > httplib.py line 822 > SocksProxy.py line 12 > socks.py line 674
[16:43:06] FileServer Trying to open port using UpnpPunch...
[16:43:07] FileServer UpnpPunch run error: error: [Errno 1] Operation not permitted in FileServer.py line 73 > UpnpPunch.py line 319 > UpnpPunch.py line 298 > UpnpPunch.py line 273 > UpnpPunch.py line 254 > UpnpPunch.py line 50 > socket.py line 474
```
 I waited for 5+ mins, also added 127.0.0.1 to "ignore proxy for hosts" and tried other things.
I think there's something in the Tor Socks or firewall rules that prevents serving from 127.0.0.1
With `netstat` I can see the service is listening, but I can't access it with either Tor or Unsafe Browser or telnet to localhost's port 43110 (connection refused).
 Yes, I looked into that but haven't tried yet because rules mentioned above seem to favor the loopback interface while access to other interfaces is even more restricted. It didn't seem worth trying but I may give it a try. 
 The good news: this works `--tor disable --proxy ... --ui_ip ...`
The bad news: that works only in Unsafe Browser (which, as the name says, kind of defeats the purpose of running Tails). A minor thing is port 15441 would have to be opened because uPnP can't work, so even with this approach you can't serve files.

I think some of the settings mentioned in the first comment need to be tweaked to let ZN "natively" access Tor SOCKS5 proxy. If the exact reason could be identified I could follow up with Tails to see if they can modify their rules so that ZN can work on Tails out of box and with Tor enabled.
By the way when running on loopback I changed `#SocksPolicy accept 192.168.0.0/16` to `SocksPolicy accept 127.0.0.1/16` and restarted Tor, but that didn't help. It's likely multiple changes are required (Tor config & iptables rules that are derived from ferm.conf linked at the top).
  this adds checks for 127.0.0.0/8 and 10.0.0.0/8 and treats them as directly connectable when using socks proxy.
 ## [Current coverage](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/609?src=pr) is 48.54% (diff: 68.42%)

> Merging [#609](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/609?src=pr) into [master](https://codecov.io/gh/HelloZeroNet/ZeroNet/branch/master?src=pr) will increase coverage by **0.10%**

``` diff
@@             master       #609   diff @@
==========================================
  Files            57         58     +1   
  Lines          7074       7092    +18   
  Methods           0          0          
  Messages          0          0          
  Branches       1469       1474     +5   
==========================================
+ Hits           3427       3443    +16   
  Misses         3233       3233          
- Partials        414        416     +2   
```

> Powered by [Codecov](https://codecov.io?src=pr). Last update [5f3b014...4278b5e](https://codecov.io/gh/HelloZeroNet/ZeroNet/compare/5f3b01476a090f9dc6f59bf2e756043d55ca98b0...4278b5e722ade1469ba4862e2346f740775ac62d?src=pr)
 ```
test_addresses = ["127.0.0.1", "128.0.0.1", "10.0.0.1", "127.34354.0.1"]
for address in test_addresses:
    print("IP address {:<13} returns :{}".format(address, is_private_address(address)))
```

Returns

```
IP address 127.0.0.1     returns :True
IP address 128.0.0.1     returns :False
IP address 10.0.0.1      returns :True
IP address 127.34354.0.1 returns :True
```

The last one should not return True, see http://stackoverflow.com/a/11264379 for more info.
 it's related to i2p support, i run my i2p router's sam interface on
10.0.3.1 so if zeronet wants to use tor and i2p then you'd need a way to
bypass the module level hook somehow for i2p connections.
cc @str4d

On Fri, Nov 11, 2016 at 7:21 PM, ZeroNet notifications@github.com wrote:

> Can you please specify the usecase? I think if someone specify a proxy
> (eg. tor) it means he/she wants every connection to use that. Even a local
> network connection could lead loss of privacy.
> 
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/pull/609#issuecomment-260086074,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AAefxRsO4EyeV6cNB6hIisBmnnEViVenks5q9QaigaJpZM4KUzaU
> .
 that is a good point, that would require an entirely different PR.

On Fri, Nov 11, 2016 at 7:56 PM, ZeroNet notifications@github.com wrote:

> Then probably it would be better to create direct connection only to
> 127.0.0.1 and specified proxy (tor or sam) ips
> 
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/pull/609#issuecomment-260089510,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AAefxQl4MKKKdvDlzYk7D0rvm9_HZirJks5q9Q7YgaJpZM4KUzaU
> .
  If we expose the service to all interfaces (with 43110:43110 port mapping), it'll be reachable from anywhere (from where the box can be reached), and may impersonate the owner of the service

Moreover, the firewall setup is not straightforward for beginners, as docker sets up NAT rules to expose the services, so it cannot be just dropped in the filter/INPUT chain.
 ## [Current coverage](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/607?src=pr) is 48.48% (diff: 100%)

> Merging [#607](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/607?src=pr) into [master](https://codecov.io/gh/HelloZeroNet/ZeroNet/branch/master?src=pr) will increase coverage by **0.07%**

``` diff
@@             master       #607   diff @@
==========================================
  Files            57         57          
  Lines          7074       7074          
  Methods           0          0          
  Messages          0          0          
  Branches       1469       1469          
==========================================
+ Hits           3425       3430     +5   
+ Misses         3234       3230     -4   
+ Partials        415        414     -1   
```

> Powered by [Codecov](https://codecov.io?src=pr). Last update [ae2e15a...4cfaff8](https://codecov.io/gh/HelloZeroNet/ZeroNet/compare/ae2e15a6fac1bca4b13f2e4213da70d8463353d4...4cfaff8ebde1ec032d5f4aeb863d4c2ca83a5717?src=pr)
  This is being built on https://github.com/HelloZeroNet/ZeroNet/issues/605 . As of now there is no way to know what changes are being made besides downloading via git and then trying to compile rather than the other way around. It would be nice if a changelog file is there and it has commit messages in it. Would help in packaging from unix distributions as well. 
 @shirishag75 @CoreBurt I'll take the task of automating this task on! :)

I can write a utility script to generate it but I'll need to know what it should contain - just a formatted git log for the current branch, or issues and pull requests from github as well?
 probably just formatted git log would be good enough. It could be as simple as -

Using nano's changelog.gz from /usr/share/doc/nano -

```
2016-03-31  Benno Schulenberg  <bensberg@justemail.net>
        * src/text.c (do_int_spell_fix): Replace a fake 'while', delete a
        redundant 'if', rename a variable, and adjust whitespace.

2016-03-30  Benno Schulenberg  <bensberg@justemail.net>
        * src/search.c (do_replace_loop, go_looking, findnextstr): Report
        "Cancelled" instead of "Not found" when the user aborts a replace
        that is taking too long.  This fixes Savannah bug #47439.
        * src/winio.c (do_replace_highlight): Rename this to 'spotlight',
        for clarity, and for contrast with 'do_replace/do_replace_loop'.
        * src/winio.c (spotlight): Rename a variable for clarity.
        * src/files.c (input_tab), src/prompt.c (get_prompt_string):
        Rename a variable to better indicate booleanness.
        * src/text.c (do_int_speller): Unwrap a few lines.
```

It basically needs a list of the changes done between various versions. Bonus points if versioning is
also mentioned (which is not seen in the above changelog.gz) and the author's name with e-mail id (if
he doesn't want to obfuscate it ) .  Makes it easier to see what the journey has been. 
  Currently this is the way I often do -

First run zeronet.py like this -

```
â”Œâ”€[shirish@debian] - [~/games/ZeroNet-master] - [86]
â””â”€[$] python zeronet.py

- Starting ZeroNet...
[02:29:17] - OpenSSL loaded, version: 0100020AF
[02:29:17] - Version: 0.4.1 r1536, Python 2.7.12+ (default, Sep  1 2016, 20:27:38) 
[GCC 6.2.0 20160822], Gevent: 1.1.1
[02:29:18] - Creating FileServer....
[02:29:18] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 154 > _socket2.py line 228
[02:29:18] - Creating UiServer....
[02:29:18] - Removing old SSL certs...
[02:29:18] - Starting servers....
[02:29:18] Ui.UiServer --------------------------------------
[02:29:18] Ui.UiServer Web interface: http://127.0.0.1:43110/
[02:29:18] Ui.UiServer --------------------------------------
[02:29:19] FileServer Checking port 15441 using portchecker.co...
^C[02:29:21] - Unhandled exception
None
KeyboardInterrupt
```

Then do an update via -

```
â”Œâ”€[shirish@debian] - [~/games/ZeroNet-master] - [87]
â””â”€[$] python update.py

Downloading from: https://github.com/HelloZeroNet/ZeroNet/archive/master.zip . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Downloaded.
Plugins enabled: ['AnnounceZero', 'Sidebar', 'Trayicon', 'Newsfeed', 'Stats', 'MergerSite', 'CryptMessage', 'Zeroname'] disabled: ['Multiuser', 'UiPassword', 'Bootstrapper', 'Dnschain', 'Zeroname-local', 'DonationMessage']
Extracting... . . . . . . . . . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Done.
Press enter to exit
```

And then again run -

```

â”Œâ”€[shirish@debian] - [~/games/ZeroNet-master] - [88]
â””â”€[$] python zeronet.py                                                                                                               [2:29:54]
- Starting ZeroNet...
[02:29:57] - OpenSSL loaded, version: 0100020AF
[02:29:57] - Version: 0.4.1 r1536, Python 2.7.12+ (default, Sep  1 2016, 20:27:38) 
[GCC 6.2.0 20160822], Gevent: 1.1.1
[02:29:57] - Creating FileServer....
[02:29:57] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 154 > _socket2.py line 228
[02:29:57] - Creating UiServer....
[02:29:57] - Removing old SSL certs...
[02:29:57] - Starting servers....
[02:29:57] Ui.UiServer --------------------------------------
[02:29:57] Ui.UiServer Web interface: http://127.0.0.1:43110/
[02:29:57] Ui.UiServer --------------------------------------
[02:29:59] FileServer Checking port 15441 using portchecker.co...
[02:30:01] FileServer [BAD :(] Port closed: Port 15441 is closed.
[02:30:01] FileServer Trying to open port using UpnpPunch...
```

It would be nice if there was a comparison instead of blindly downloading the latest release. WDYT ?
 This would be pretty easy to implement, you could just download the [/src/Config.py](https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Config.py) and get the revision (or version) number to compare to the current number.

You can easily get the revision number with Regex e.g `"(?<=self.rev = )\d+"` (so no external libraries are needed) however there would probably be a better way of doing it.
 @AceLewis **IF** it is that easy, then maybe you can contribute a patch so that it becomes part of the codebase. 
 @shirishag75 I contributed a patch but as I said there is probably a better way of doing it, although it works fine so you can use it now.
 @AceLewis thank you. Now have to wait to see what the developers/maintainers think. Hopefully they will either accept or reject and make another patch. I will use it once they integrate it into https://github.com/HelloZeroNet/ZeroNet/archive/master.zip , thank you for all your help. 
 @HelloZeroNet Please, review the pull request. aha, ok that I didn't know, thank you for clearing that up.   I'm trying to run ZeroNet on raspberry pi for seeding purposes but it fails to run, this is what happens when i try to run it:
![untitled-2](https://cloud.githubusercontent.com/assets/10282676/19183114/d75ca64c-8c87-11e6-8a5c-dca87412ae4e.jpg)
  For my ZeroNet(Werkzeug)-based project I'll use **Angular2** routing instead of **CoffeeScript**, for example http://127.0.0.1:5000/detail/11 but I'll see this error:

```
Not Found

The requested URL was not found on the server.
If you entered the URL manually please check your spelling and try again.
```

``` python
import os.path
from flask import Flask
from werkzeug.wsgi import SharedDataMiddleware

app = Flask(__name__)

app.wsgi_app = SharedDataMiddleware(app.wsgi_app, {
    '/': os.path.join(os.path.dirname(__file__), '.')
})
```

This is the **lite-server** description of this feature:

> When creating a SPA there are routes that are only known to the browser. For example, /customer/21 may be a client side route for an Angular app. If this route is entered manually or linked to directly as the entry point of the Angular app (aka a deep link) the static server will receive the request, because Angular is not loaded yet. The server will not find a match for the route and thus return a 404. The desired behavior in this case is to return the index.html (or whatever starting page of the app we have defined).

_Original request here:_ https://github.com/pallets/werkzeug/issues/1016
  ```
apt-get install python-dev
apt-get install python-setuptools
apt-get install python-pip
pip install --upgrade pip
apt-get install msgpack-python
pip install msgpack-python --upgrade
apt-get install python-gevent 
pip install gevent --upgrade
wget --no-check-certificate https://github.com/HelloZeroNet/ZeroNet/archive/master.tar.gz
tar -xzvf master.tar.gz
cd ZeroNet-master
nohup python zeronet.py --ui_ip 0.0.0.0
```

```
- Starting ZeroNet...
[15:01:37] - OpenSSL loaded, version: 01000207F
[15:01:37] - Version: 0.4.1 r1533, Python 2.7.12 (default, Jul  1 2016, 15:12:24) 
[GCC 5.4.0 20160609], Gevent: 1.1.0
[15:01:37] - Creating FileServer....
[15:01:37] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 154 > _socket2.py line 228
[15:01:37] - Creating UiServer....
[15:01:37] - Removing old SSL certs...
[15:01:37] - Starting servers....
[15:01:37] Ui.UiServer --------------------------------------
[15:01:37] Ui.UiServer Web interface: http://0.0.0.0:43110/
[15:01:37] Ui.UiServer --------------------------------------
[15:01:38] FileServer Checking port 15441 using portchecker.co...
[15:01:40] FileServer [BAD :(] Port closed: Port 15441 is closed.
[15:01:40] FileServer Trying to open port using UpnpPunch...
[15:01:45] - Unhandled exception
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/gevent/greenlet.py", line 534, in run
    result = self._run(*self.args, **self.kwargs)
  File "src/File/FileServer.py", line 190, in checkSites
    self.openport()
  File "src/File/FileServer.py", line 72, in openport
    UpnpPunch.ask_to_open_port(self.port, 'ZeroNet', retries=3, protos=["TCP"])
  File "src/util/UpnpPunch.py", line 317, in ask_to_open_port
    protos=protos)
  File "src/util/UpnpPunch.py", line 296, in _communicate_with_igd
    _orchestrate_soap_request(local_ip, port, fn, desc, protos)
  File "src/util/UpnpPunch.py", line 271, in _orchestrate_soap_request
    idg_data = _collect_idg_data(ip)
  File "src/util/UpnpPunch.py", line 252, in _collect_idg_data
    idg_response = perform_m_search(ip_addr)
  File "src/util/UpnpPunch.py", line 48, in perform_m_search
    sock.bind((local_ip, 10000))
  File "<string>", line 1, in bind
error: [Errno 98] Address already in use
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/gevent/greenlet.py", line 534, in run
    result = self._run(*self.args, **self.kwargs)
  File "src/File/FileServer.py", line 190, in checkSites
    self.openport()
  File "src/File/FileServer.py", line 72, in openport
    UpnpPunch.ask_to_open_port(self.port, 'ZeroNet', retries=3, protos=["TCP"])
  File "src/util/UpnpPunch.py", line 317, in ask_to_open_port
    protos=protos)
  File "src/util/UpnpPunch.py", line 296, in _communicate_with_igd
    _orchestrate_soap_request(local_ip, port, fn, desc, protos)
  File "src/util/UpnpPunch.py", line 271, in _orchestrate_soap_request
    idg_data = _collect_idg_data(ip)
  File "src/util/UpnpPunch.py", line 252, in _collect_idg_data
    idg_response = perform_m_search(ip_addr)
  File "src/util/UpnpPunch.py", line 48, in perform_m_search
    sock.bind((local_ip, 10000))
  File "<string>", line 1, in bind
socket.error: [Errno 98] Address already in use
```
 Seems like an instance of ZN is already running on that port. Try a different port.
  I just updated to Rev1533 and my mail quit working. I hit encrypt and send but is doesn't do anything. Also I noticed if I update my mail from the ZeroNet home page, at first I do get the green bar next to it that says updated but right after that bar disappears another bar pops up and that one says 1 file update failed. It's done this about five times now. 
 I hit F12 and it brings up Developer Tools but I don't know what I'm looking for, I've never used that because I'm not a developer or coder.
![zeromail](https://cloud.githubusercontent.com/assets/8492776/19044583/f1c41380-8962-11e6-8991-8c42f853e40a.png) Can you please tell me where to look for the JS content.
 Is this what you want?
[Wrapper] Created!all.js:1357:14
[ZeroMail] Route Object { url: "" }all.js:1578:7
MessageShow renderall.js:3697:7
[ZeroWebsocket] Openall.js:106:14
[Wrapper] Setting title to ZeroMail - ZeroNetall.js:1357:14
[User] Loading user file data/users/1ED3Ho3kmzaKiECtyuqSjDpoE47rKuXeP/data.jsonall.js:1578:7
MessageShow renderall.js:3697:7
[Leftbar] Reloading contactsall.js:1578:7
[MessageListInbox] Loading keys 2all.js:1578:7
[User] Loaded trueall.js:1578:7
MessageShow renderall.js:3697:7
[Leftbar] Unknown contacts found, reloaded.all.js:1578:7
[MessageListInbox] Loaded known AES keysall.js:1578:7
[MessageListInbox] Last parsed secret: Mon Oct 03 2016 11:57:43 GMT-0400 (EDT)all.js:1578:7
MessageShow renderall.js:3697:7
[MessageListInbox] New secrets foundall.js:1578:7
[MessageListInbox] New messages found 0all.js:1578:7
[MessageListInbox] getMessages Loaded messages in mode normal 2 (Done in 163ms)all.js:1578:7
MessageShow renderall.js:3697:7
Render: 7all.js:1025:11
MessageShow renderall.js:3697:7
hideProgressall.js:547:7
MessageShow renderall.js:3697:7
hideProgressall.js:547:7
MessageShow renderall.js:3697:7
hideProgressall.js:547:7
MessageShow renderall.js:3697:7
hideProgressall.js:547:7
MessageShow renderall.js:3697:7
hideProgressall.js:547:7
MessageShow renderall.js:3697:7
MessageShow renderall.js:3697:7
hideProgressall.js:547:7
MessageShow renderall.js:3697:7
hideProgressall.js:547:7
MessageShow renderall.js:3697:7
hideProgressall.js:547:7
MessageShow renderall.js:3697:7
hideProgressall.js:547:7
MessageShow renderall.js:3697:7
hideProgressall.js:547:7
MessageShow renderall.js:3697:7
 Also here's a screenshot. If these aren't what your wanting please let me know.
![zeromail1a](https://cloud.githubusercontent.com/assets/8492776/19045525/4ecedc78-8967-11e6-9444-9aaa7117f7a1.png)
 I assume I posted the right stuff since you haven't replied back. I hope you can figure out what's wrong with the email.
 Thanks.
 `at first I do get the green bar next to it that says updated but right after that bar disappears another bar pops up and that one says 1 file update failed`

Having same issue, latest version from the commit < 1 minute ago.
 Ah ok. Good to know.
 I just sent nofish a test email to see if it was working now. OK thanks.   Nothing happens. I get the dialogue asking if I will allow something downloaded from the internet to run, I click 'open' and then nothing ever happens. I was finally able to run it from the command-line
 Yeah, that actually works. It opens a terminal window which does then cause the ZeroNet page to be loaded in the default browser.
  When adding a zite that has more than 20MB, zeronet will ask only once if you want to increase the site size from 10MB to 20MB and it will leave the download incomplete with no indication of that fact.

**To reproduce:**
1. Open Antilibrary.bit -> It will ask you to increase the size from 10 to 20mb, accept that
2. Once the download seems to be done check the folder `ZeroBundle\ZeroNet\data\147nKEb9bBJgBDgQytEQhmiGjF8e6HkEua\data\json`, you should have 32 folders in there (al_1 - al_32) but you will have only 7
3. There are no indications that the site download is incomplete so the user won't notice it.

**Expected behaviour:** 
1. ZeroNet should ask me if I want to increase the site size to +10mb from the total size calculated from the files in content.json.
2. Is should also give some indication of the download status (not the download progress bar) **while in the site page**. Something that will highlight to the user that he is missing files and the site download is not complete.
 It seems that the problem has compounded as the zite (antilibrary.bit) got bigger.
The zite has now ~60mb and when I try do open it on Windows 10 zeronet rev 1529 I'll get:

```
[20:10:18] Site:147nKE..kEua content.json: Site too large 71768737 > 10485760, aborting task...
```

If I try to drag the zero icon in order to increase the allowed zite size I get:

```
[20:10:18] Site:147nKE..kEua Content.json not exist: data/147nKEb9bBJgBDgQytEQhmiGjF8e6HkEua/content.json
[20:10:19] Site:147nKE..kEua WebSocket handleRequest error: KeyError: 'content.json' in UiWebsocket.py line 99 > UiWebsocket.py line 176 > SidebarPlugin.py line 448 > SidebarPlugin.py line 130 > ContentManager.py line 271 > ContentDbDict.py line 54
```

So basically the zite cannot be downloaded.
 @HelloZeroNet sorry mate, but, in which version has this been fixed?
I'm using Rev1536 and I still get:

```
[12:04:18] Site:147nKE..kEua Content.json not exist: data/147nKEb9bBJgBDgQytEQhmiGjF8e6HkEua/content.json
[12:04:19] Site:147nKE..kEua content.json: Site too large 167468609 > 10485760, aborting task...
```
 is there any way to clone Antilibrary site i found it very interesting i want to clone it and use Hindu books
 I'm testing the version 0.5.0 and the problem seems to persist.
If you try to download the site antilibrary.bit on a fresh zeronet install of 0.5.0 it will download only 10MB of an old version of the zite. Once the download is done nothing else happens. Even when I push a new version out, nothing happens on these nodes.
I'm not sure how ZeroNet pick the most up to date content.json file from the available peers but on my tests it seems that it will pick randomly, and if it picks from an up to date seed it will ask to increase the site size to 500MB but it will still download the old version that has 9984kB (and nothing else happens).
If it picks one of the outdated seeds it won't even ask to increase the site size limit, it will simply download the same old version.
The most up to date content.json file has `"modified": 1478647623.986517`.
The 10mb version of the zite has a 'Packs' item in the menu, the latest version has a 'My Books' item in the menu.
I won't update the content.json until you acknowledge the issue (so I won't modify the timestamp)
Thanks

ps: I've just noted that I'm getting `{'to': 1, 'cmd': 'response', 'error': 'File invalid'}` from peers holding the old version of the zite. This means they are not updating and are serving the old version when someone tries to reach the site for the first time.
 @HelloZeroNet and what options does the site owner have to push changes that are not compatible with the old site version through the network? For example in these case some peers are stuck in the 10MB version and ZeroNet won't ask them to increase the size because it won't fetch the new content.json because the site has reached its size limit. How to force an update into these peers so they will at least be asked if they want to increase the site size?
thanks
 Don't you think that this can lead to a bad user experience?
The user has an outdated site but he is unaware that the site is outdated.
IMHO it would be a better UX if ZeroNet warns the user about that fact, something on the lines of: "- Hey, there's a new version of this site released on 11/11/2016 - 10:00PM. It has not been auto-updated because the new version is bigger then the site size limit you've set so the site update has been paused for now. If you want to update, increase the site size limit  to at least XMB and manually update the site".

I'm reluctant to use Merger sites because, being books, I would need to separate the content by category and this would lead to too many categories. The UX to keep track and add them would be a pain.
Also, a decent book index doesn't use much space, even in the current state ~2 million books would not take more than a good quality movie (~3-4GB). That's because the site is holding only metadata for the books.
I hope that when ZeroNet implements the json compression, this size should be reduced by 80% during transfers, which is very acceptable.

I also believe that the people that will use this site is not 'HD space conscious', mostly are data hoarders that love to download huge packs of books from around the web. So spreading the site content into merger sites would affect their UX while at the same time not tackling a pain point for them.

Thoughts?
Thanks
 Thanks for looking into this.

I'll check the merger site documentation. It makes sense to separate it by language and some broad category like fiction, non-fiction. Thanks for the advice.
 @HelloZeroNet it seems that the original bug is affecting merger sites as well. I'm trying to add a big merger site but I'm getting `Site:1KrGwP..mevq content.json: Site too large 333680764 > 10485760, aborting task...`

**To Reproduce:**
- Go to Antilibrary.bit (hopefully you will get my seed at 185.21.216.182 - or else you will get an outdated version of the site)
- Click 'My Books' (top right) then 'Settings'
- Click 'Download' on the English language

This will try to add the merger site 1KrGwPRtnn77MsL35LBpNTEvvUhoLhmevq which is above 10MB.
All other merger sites work fine.
Thanks
 @HelloZeroNet nice solution.
What about the merger site?
Currently when you try to add a merger site bigger than the limit it will fail silently with `Site too large...`.
Maybe a solution can be to show a wrapperNotification asking the user to accept the size increase. The merger site issue is now affecting Antilibrary's German books database because that DB is now bigger than the default allowed size.
Again, the problem happens when one tries to add a merger site which is bigger than the default allowed size. It will fail silently to the user and show the message `Site too large...` on the console.
A proper solution would be to inform the user about the size of the merger site and ask if he wants to proceed.
 How does one increase limitation of MergerSite other than clicking on the MergerSite, which is usually "empty" frontend, then dragging the sidebar open and increase from there?

Since this is a bit confusing for new users, it would be great if there was an option directly on the startpage sidebar for the affected sites showing up in the "Running out of Space" section via the "..." dropdown menu, like "Increase SizeLimit" or "Adjust SizeLimit", which then opens the confirmation dialog to increase it. Sorry, maybe it's not the right place to ask the question but, is the 10 MB limit still current? I can't find anything about this in the main readme or in the doc. @HelloZeroNet Can this issue be closed? I don't think so as the issue is still affecting merger sites.
If you try to add a merger site bigger than the default size it will fail silently. You do get the notification asking to add the merger site, but it doesn't add as the error happens in the background and there is no notification asking if the user wants to increase the merger site size.  The instructions for a manual install on Debian should note that you need to install Tor from backports if you're running on Jessie, as the stock version is too old.  The complete command for that is `apt-get install -t jessie-backports tor` assuming you've got the backports repo in sources.list.
 @HelloZeroNet Please, close.  Hello, I have a problem posting my site. Can you help me?

```
root@ubuntu-512mb:/home/ZeroBundle/ZeroNet# python zeronet.py sitePublish 1$$$$$$$$$$$$$$$$$$$$$$3
- Starting ZeroNet...
- OpenSSL loaded, version: 01000207F
- Version: 0.4.1 r1525, Python 2.7.12 (default, Jul  1 2016, 15:12:24) 
[GCC 5.4.0 20160609], Gevent: 1.1.2
- Loading site...
Traceback (most recent call last):
  File "zeronet.py", line 16, in main
    main.start()
  File "src/main.py", line 420, in start
    actions.call(config.action, action_kwargs)
  File "src/main.py", line 120, in call
    func(**kwargs)
  File "src/main.py", line 303, in sitePublish
    site = SiteManager.site_manager.list()[address]
KeyError: '13$$$$$$$$$$$$$$$$$$$$$$$$$3'
root@ubuntu-512mb:/home/ZeroBundle/ZeroNet# 

```
  Hi,

I was trying to install ZeroNet on Windows (10) by following the default instructions (running ZeroNet.cmd).

It was opening the command prompt and then instantly closing it with no feedback. 

I opened cmd and ran ZeroNet.cmd from inside it and got an error pointing to C:\python... (apparently I already had Python installed and I _think_ it was trying to use this version which lead to the error).

I removed the PATH entry for Python from my Environment Variables, ran ZeroNet.cmd again and it worked fine.
 When I ran zeronet.cmd from within a cmd prompt it provided the following error (I didn't screenshot it at the time, but I did copy and paste it into Google, so this is from my search history):

```
File "C:\python\lib\site.py", line 176 file=sys.stderr) 
                                   ^ SyntaxError: invalid syntax
```

For reference, I had Python 3.4.1 installed at C:\python

I _think_ it was actually PYTHONPATH that I deleted

C:\python and C:\python\scripts are still in my PATH

Struggling to reproduce it now as uninstalling and reinstalling Python 3 doesn't have any impact.
  http://127.0.0.1:43110/157xGMqaufjjnts9qRd4K953g8dBm6YzXr/
sometimes when this site loads im getting this error from all.js:
uncaught InvalidStateError: Failed to execute 'send' on 'WebSocket': Still in CONNECTING state

why does this happen & how could this be prevented?
  on this site: http://127.0.0.1:43110/18SZadPsFtTEefBK5CTvRSFiBXs9TvAGEG
im seeing different user generated content (comments,votes, channels) on different peers.
for example on https://bit.no.com:43110/18SZadPsFtTEefBK5CTvRSFiBXs9TvAGEG/ there are more comments / votes / channels (visible on register.html) then on local.
on the console im getting these errors:

```
[12:25:49] Site:1KQTZ4..FsuW data/channel.json file size does not match 494 <> 446, Hash: False
[12:25:49] Site:1KQTZ4..FsuW data/channel.json file size does not match 494 <> 446, Hash: False
[12:25:49] - Unhandled exception
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/gevent/greenlet.py", line 327, in run
    result = self._run(*self.args, **self.kwargs)
  File "src/Site/Site.py", line 340, in update
    self.storage.updateBadFiles(quick_check=True)  # Quick check and mark bad files based on file size
  File "src/Site/SiteStorage.py", line 372, in updateBadFiles
    add_changed=not self.site.settings.get("own")  # Don't overwrite changed files if site owned
  File "src/Site/SiteStorage.py", line 302, in verifyFiles
    for content_inner_path, content in self.site.content_manager.contents.items():
  File "src/Content/ContentDbDict.py", line 84, in items
    val = self[key]
  File "src/Content/ContentDbDict.py", line 56, in __getitem__
    return self.loadItem(key)
  File "src/Content/ContentDbDict.py", line 29, in loadItem
    raise KeyError(key)
KeyError: u'data/users/1PW1iDGhbE8DGnWRTY369uNjVoN5FF4aay/content.json'
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/gevent/greenlet.py", line 327, in run
    result = self._run(*self.args, **self.kwargs)
  File "src/Site/Site.py", line 340, in update
    self.storage.updateBadFiles(quick_check=True)  # Quick check and mark bad files based on file size
  File "src/Site/SiteStorage.py", line 372, in updateBadFiles
    add_changed=not self.site.settings.get("own")  # Don't overwrite changed files if site owned
  File "src/Site/SiteStorage.py", line 302, in verifyFiles
    for content_inner_path, content in self.site.content_manager.contents.items():
  File "src/Content/ContentDbDict.py", line 84, in items
    val = self[key]
  File "src/Content/ContentDbDict.py", line 56, in __getitem__
    return self.loadItem(key)
  File "src/Content/ContentDbDict.py", line 29, in loadItem
    raise KeyError(key)
KeyError: u'data/users/1PW1iDGhbE8DGnWRTY369uNjVoN5FF4aay/content.json'
```

how can i synchronise user data through all peers e,g that all peers see the same comments / votes / channels? why is this happening? do i have to delete everything and start again with 0 content?
 @HelloZeroNet Please, close.  Fixed a bug where a lack of a trailing slash in every url caused zeronet to fail to load the page, even if it existed.

For example, if you go to http://127.0.0.1:43110/1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/big/docs, the page fails to load. However, if you go to http://127.0.0.1:43110/1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/big/docs/, it loads fine.

As far as I can tell, everything now works with this patch but it seems a little inelegant. When I got to such a url, the screen flashes for a second before redirecting. It would be better if it were instantaneous.
 ## [Current coverage](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/588?src=pr) is 47.61% (diff: 0.00%)

> Merging [#588](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/588?src=pr) into [master](https://codecov.io/gh/HelloZeroNet/ZeroNet/branch/master?src=pr) will decrease coverage by **0.08%**

``` diff
@@             master       #588   diff @@
==========================================
  Files            57         57          
  Lines          7035       7037     +2   
  Methods           0          0          
  Messages          0          0          
  Branches       1469       1470     +1   
==========================================
- Hits           3356       3351     -5   
- Misses         3267       3273     +6   
- Partials        412        413     +1   
```

> Powered by [Codecov](https://codecov.io?src=pr). Last update [d608a0d...1383797](https://codecov.io/gh/HelloZeroNet/ZeroNet/compare/d608a0d8470a2e49efa2cfa9701bea52c206056a...13837971a7d2ea9d74b399d6c1adc7f809792b75?src=pr)
  The base Ubuntu image has been upgraded to the current LTS release (16.04) and tor support has been added to the Docker image. Tor is disabled by default as it may not be allowed by different hosting providers. In order to enable it, just set `ENABLE_TOR` environment variable to `true` when executing `docker run` 
 ## [Current coverage](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/587?src=pr) is 47.70% (diff: 100%)

> Merging [#587](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/587?src=pr) into [master](https://codecov.io/gh/HelloZeroNet/ZeroNet/branch/master?src=pr) will not change coverage

``` diff
@@             master       #587   diff @@
==========================================
  Files            57         57          
  Lines          7035       7035          
  Methods           0          0          
  Messages          0          0          
  Branches       1469       1469          
==========================================
  Hits           3356       3356          
  Misses         3267       3267          
  Partials        412        412          
```

> Powered by [Codecov](https://codecov.io?src=pr). Last update [d608a0d...39dc00a](https://codecov.io/gh/HelloZeroNet/ZeroNet/compare/d608a0d8470a2e49efa2cfa9701bea52c206056a...39dc00ad78f7263b39b035ec8e04413bbc868e04?src=pr)
 That would mean that we need two separate images, one with tor installed and another one without tor.

However, with this change the tor binary would only run if the user explicitly sets the environment variable ENABLE_TOR. The only way for a VPS provider to know that tor exists in one of these containers is to inspect the image looking for the tor binary, which I don't think they would do.

_Using default config:_

```
$ docker run -d -p 15443:15441 -p 43112:43110 aitorpazos:myZeroNet
b1146f0409083a03d122cbe947cf9011a63cf62b9975870e61654778e8c6e307
$ docker exec -ti trusting_kirch ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 21:58 ?        00:00:00 /bin/sh -c cd /root && (! ${ENABLE_TOR} || /etc/init.d/tor start) && python zeronet.py --ui_ip 0.0.0.0
root         6     1  5 21:58 ?        00:00:00 python zeronet.py --ui_ip 0.0.0.0
root        20     0  0 21:58 ?        00:00:00 ps -ef
```

_Using ENABLE_TOR=false:_

```
$docker run -e "ENABLE_TOR=false" -d -p 15442:15441 -p 43111:43110 aitorpazos:myZeroNet
aac074ccefe84379e19f54fa703c605ffbe667002e771c293916d9e8c7431e7c
$ docker exec -ti small_colden ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 21:53 ?        00:00:00 /bin/sh -c cd /root && (! ${ENABLE_TOR} || /etc/init.d/tor start) && python zeronet.py --ui_ip 0.0.0.0
root         6     1  2 21:53 ?        00:00:00 python zeronet.py --ui_ip 0.0.0.0
root        20     0  0 21:53 ?        00:00:00 ps -ef
```

_Using ENABLE_TOR=true:_

```
$ docker run -e "ENABLE_TOR=true" -d -p 15444:15441 -p 43113:43110 aitorpazos:myZeroNet
19d06f2e9f65ae778b6666109c09dd5022ef83ed7bedbe4f2eed23f51e51891b
$ docker exec -ti jolly_stonebraker ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 21:59 ?        00:00:00 /bin/sh -c cd /root && (! ${ENAB
debian-+    17     1  8 21:59 ?        00:00:00 /usr/bin/tor --defaults-torrc /u
root        18     1  6 21:59 ?        00:00:00 python zeronet.py --ui_ip 0.0.0.
root        32     0  0 21:59 ?        00:00:00 ps -ef
```
  http://127.0.0.1:43110/17GijTrkMfxhTKWFnM2atrGVaZcp5zNBEW

dragging of the zero icon to reveal the sidebar generates the following error:

Internal error: KeyError: u'data/users/content.json'
UiWebsocket.py line 99 > UiWebsocket.py line 176 > SidebarPlugin.py line 448 > SidebarPlugin.py line 130 > ContentManager.py line 273 > ContentManager.py line 271 > ContentDbDict.py line 54

console:
Site:17GijT..NBEW WebSocket handleRequest error: KeyError: u'data/users/content.json' in UiWebsocket.py line 99 > UiWebsocket.py line 176 > SidebarPlugin.py line 448 > SidebarPlugin.py line 130 > ContentManager.py line 265 > ContentManager.py line 263 > ContentDbDict.py line 54

debug-last.log:
ERROR    - UiWSGIHandler error: error: [Errno 32] Broken pipe in UiServer.py line 39 > pywsgi.py line 495 > pywsgi.py line 486 > pywsgi.py line 376 > pywsgi.py line 369 > pywsgi.py line 355 > socket.py line 458 > socket.py line 443

![ded6071e-7df6-11e6-8f3e-1516659d6f36](https://cloud.githubusercontent.com/assets/5212537/18619276/718d58ea-7df8-11e6-958c-19aa7290896b.png)
 Should check if it exist before using it.
 yes that worked
 @ysc3839 @HelloZeroNet when i'm deleting sites this appeared again
`Internal error: KeyError: u'data/users/{user_adress}/content.json'
UiWebsocket.py line 105 > UiWebsocket.py line 200 > UiWebsocket.py line 726 > Site.py line 1006 > SiteStorage.py line 392 > ContentDbDict.py line 55 > ContentDbDict.py line 28`
and i cannnot find folders related with "{user_adress}" or sites in sites.json.... Same problem as CPCer. After sending a message in folder data/users/{user_adress}/ zero receives data.json and no content.json Why does this happen?  In order to keep the Dockerfile simple, needed opotions have been appended to package provided torrc file and the /etc/init.d/tor script is used to start tor. If further customisation is desired, a wrapper script should be created to have further control on the startup. This would allow things like specifying external (tor) proxies and disable tor startup in those situations.
 ## [Current coverage](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/585?src=pr) is 47.70% (diff: 100%)

> Merging [#585](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/585?src=pr) into [master](https://codecov.io/gh/HelloZeroNet/ZeroNet/branch/master?src=pr) will not change coverage

``` diff
@@             master       #585   diff @@
==========================================
  Files            57         57          
  Lines          7035       7035          
  Methods           0          0          
  Messages          0          0          
  Branches       1469       1469          
==========================================
  Hits           3356       3356          
  Misses         3267       3267          
  Partials        412        412          
```

> Powered by [Codecov](https://codecov.io?src=pr). Last update [d608a0d...9e68a6f](https://codecov.io/gh/HelloZeroNet/ZeroNet/compare/d608a0d8470a2e49efa2cfa9701bea52c206056a...9e68a6f7e7bbfdf768cd7bc60b42af10b7979465?src=pr)
 tor probably shouldn't be run in the same container as zeronet. Also, not running ZN as root within the container should be considered.
 I understand your points. However, this change would improve current situation from not having Tor protection at all to at least have some of it.
 Ok, that's a more compelling argument right now. I'll close this pull request and I'll make tor optional (disabled by default)
  Is this connected to torrent plugin at all?
  So i have deleted my old data folder but backed up and replace the new users.json with old one. How do you even login or use your cert_sign and auth_privatekey? All i'm receiving is just "User Taken"

Also i have Multiuser Plugin on for my group of friends

![0c8f2baa-7bad-11e6-96d9-c314171f2df8](https://cloud.githubusercontent.com/assets/13272249/18560251/58dc7d96-7bad-11e6-91c7-13eea5cdaa4c.png)

![screenshot from 2016-09-16 01-32-45](https://cloud.githubusercontent.com/assets/13272249/18560622/feebf828-7bae-11e6-8b4c-56eeab80d1c8.png)
  I'm here in China. You know the so-called "Internet" in China: Almost everything is blocked.

So I use my router to do proxy. When I'm surfing the Internet, All traffic to IP address in China will be passed through directly, whereas traffic to outside China is passed through my proxy in Los Angeles. I'd like ZeroNet to see me as my real Chinese IP address, but it detects my server IP in Los Angeles, thus I cannot open my port to let others use, and I'm not able to use my local peers.

Will it be possible to provide an alternative way to detect IP address (e.g. use IP detector page in China like http://www.pubyun.com/dyndns/getip) or some other measurements?
 add rule to proxy with ignoring URL of zeronet ip checker
 @iShift Rules are based on IP addresses, not URL.
 @HelloZeroNet Not very clear what 'but the trackers will add the originating ip' means, could you please explain it a little bit more detailed?
 Then if I specify the ip_external parameter, will that be like this: I will be able to access ZeroNet using both China and World sources, but only users in China will be able to connect to me because the World see me as my Los Angeles IP?
 It seems that those checkers cannot see my actual IP address even I provided my real IP.

```
[14:06:38] FileServer Checking port 15441 using portchecker.co...
[14:06:39] FileServer [BAD :(] Port closed: Port 15441 is closed.
[14:06:39] FileServer Trying to open port using UpnpPunch...
[14:06:54] FileServer Checking port 15441 using portchecker.co...
[14:06:55] FileServer [BAD :(] Port closed: Port 15441 is closed.
[14:06:55] FileServer Checking port 15441 using canyouseeme.org...
[14:06:56] FileServer [BAD :(] Port closed: Error: I could not see your service on 107.151.188.*** on port (15441) Reason: Connection refused
[14:06:56] FileServer Upnp mapping failed :( Please forward port 15441 on your router to your ipaddress
```

where `107.151.188.***` is my proxy server IP.
 I don't want to expose my proxy server IP. I just want to make myself expose to the Internet with my actual IP specified with the ip_external  parameter.
 But now my page shows that my 15441 is opened. Does that mean it's OK now?
 No, I mapped my router_actual_public_ip:15440 to my_computer:15440. --ip_external is router_actual_public_ip.
  after changing my sites to use mergerSites, im not longer able to save an image via Page.cmd('fileWrite'). 
here is the function:

```
            var path = 'uploads/images/' + $scope.channel.img;
            var canvas =  document.getElementById('canvas');
            var previewImgUrl = $scope.imgSrc.split(',')[1];
            Page.cmd("fileWrite",[path, previewImgUrl], function(res) {
                if (res === 'ok'){
                    $scope.updateChannel();
                }
            });
```

and the error im getting:
TypeError: string indices must be integers, not tuple in UiWebsocket.py line 99 > UiWebsocket.py line 178 > MergerSitePlugin.py line 127 > MergerSitePlugin.py line 121 > UiWebsocket.py line 402

this worked perfectly before the mergerSites update now im getting this error constantly. help!
  This PR does 3 things:
1. Adds code to delete port forwarding rules using UPnP on exiting - closes #466 .
2. Refactors the code mainly to introduce exceptions instead of returning True/False/None
3. Adds tests to exercise the UpnpPunch module.

I started off working on no. 1, but I quickly found out that the increased number of responsibilities (opening _and_ closing ports) need a better way to communicate failures, hence the switch to exceptions. All these changes prompted me to write tests to make sure I'm not breaking everything.

One thing that I'm not confident in is adding the port-closing code to the ConnectionServer.stop method - it works alright, but is this the best place to put this cleanup code in?
 ## [Current coverage](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/577?src=pr) is 49.13% (diff: 86.11%)

> Merging [#577](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/577?src=pr) into [master](https://codecov.io/gh/HelloZeroNet/ZeroNet/branch/master?src=pr) will increase coverage by **1.37%**

``` diff
@@             master       #577   diff @@
==========================================
  Files            57         57          
  Lines          7023       7073    +50   
  Methods           0          0          
  Messages          0          0          
  Branches       1466       1470     +4   
==========================================
+ Hits           3354       3475   +121   
+ Misses         3257       3173    -84   
- Partials        412        425    +13   
```

> Powered by [Codecov](https://codecov.io?src=pr). Last update [931426e...ea47c47](https://codecov.io/gh/HelloZeroNet/ZeroNet/compare/931426e4fc59e38c69ce5d39a362925f7e722b6a...ea47c47b5e4d3aa8d4a0eee6ca0bda84478f0e01?src=pr)
 Hey @HelloZeroNet , thanks for checking this out! I'll look into this error and submit any required fixes in the upcoming days.
 Hey @HelloZeroNet , I fixed the (embarrassingly small) issue here, ready for a looking over. 
  When you open a Video, i can download it in SD HD Etc, but I would like to know if it has "Hard Coded Subs" "Subs come with it (Like a txt file)" Or No Subs" So i can instead of downloading the movie and it comes with Hard Coded Subs.
 Wrong repo maybe?
 Used latest Repo fresh copy. i see the CC Search, but the torrents dont state "Hard Coded" or not
 I am not aware of there being any video torrents on ZeroNet.
  I love the 0.4.1 update, the startup time really went down. Great!

I do not remember though getting these every few seconds in 0.3.x though on my Ubuntu MATE 15.10:

```
[16:49:39] - Unhandled exception
None
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/gevent/threadpool.py", line 203, in _worker
    value = func(*args, **kwargs)
socket.gaierror: [Errno -2] Name or service not known
[16:49:43] - Unhandled exception
None
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/gevent/threadpool.py", line 203, in _worker
    value = func(*args, **kwargs)
socket.gaierror: [Errno -2] Name or service not known
[16:49:47] - Unhandled exception
None
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/gevent/threadpool.py", line 203, in _worker
    value = func(*args, **kwargs)
socket.gaierror: [Errno -2] Name or service not known
```

I do not have tor, but the port is opened.
 Probably one of the trackers cannot be resolved from my place?

```
[2016-09-07 17:18:30,346] INFO     - Creating FileServer....
[2016-09-07 17:18:30,346] DEBUG    TorManager Connecting to 127.0.0.1:9051
[2016-09-07 17:18:30,354] ERROR    TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 154 > _socket2.py line 186
[2016-09-07 17:18:30,354] DEBUG    TorManager Tor proxy port 127.0.0.1:9050 check error: No connection
[2016-09-07 17:18:30,354] DEBUG    FileServer Binding to: *:15441, (msgpack: 0.4.2), supported crypt: ['tls-rsa']
[2016-09-07 17:18:30,354] DEBUG    Site:15GAu5..M54h Need connections: 0, Current: 0, Total: 0
[2016-09-07 17:18:30,988] DEBUG    FileServer Conn# 1 89.46.99.147 [?] > Incoming connection...
[2016-09-07 17:18:31,026] DEBUG    FileServer Conn# 2 122.173.236.39 [?] > Incoming connection...
[2016-09-07 17:18:31,030] DEBUG    FileServer Conn# 2 122.173.236.39 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2016-09-07 17:18:31,342] DEBUG    FileServer Conn# 3 112.102.78.195 [?] > Incoming connection...
[2016-09-07 17:18:31,356] INFO     FileServer Checking port 15441 using portchecker.co...
[2016-09-07 17:18:31,388] DEBUG    FileServer Conn# 3 112.102.78.195 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2016-09-07 17:18:31,431] DEBUG    FileServer Conn# 1 89.46.99.147 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2016-09-07 17:18:31,851] DEBUG    FileServer Conn# 4 192.241.144.195 [?] > Incoming connection...
[2016-09-07 17:18:31,851] DEBUG    FileServer Removing Conn# 4 192.241.144.195 [v2]...
[2016-09-07 17:18:31,943] INFO     FileServer [OK :)] Port open: Port 15441 is open.
[2016-09-07 17:18:31,944] INFO     - Gathering peers from tracker
[2016-09-07 17:18:31,945] DEBUG    FileServer Conn# 5 boot.zeronet.io [?] > Connecting...
[2016-09-07 17:18:31,965] ERROR    - Unhandled exception
None
[2016-09-07 17:18:31,970] DEBUG    Site:1HeLLo..Tf3D Http tracker http://torrent.gresille.org/announce?uploaded=0&downloaded=0&numwant=30&compact=1&event=started&peer_id=-ZN0041-2Xs10nX42opj&port=15441&info_hash=%86%D6%5B%F5%A8%DE%A3%EB%E1%96%5C%FEi%06g%25%5D%90d%7E&left=0 error: <urlopen error [Errno -2] Name or service not known>
[2016-09-07 17:18:32,019] DEBUG    Site:1HeLLo..Tf3D Found 50 peers, new: 23, total: 23
[2016-09-07 17:18:32,036] DEBUG    Site:1HeLLo..Tf3D Found 50 peers, new: 27, total: 50
```

also I did this from the command prompt:

```
$ ping torrent.gresille.org
ping: unknown host torrent.gresille.org
```
 The tracker is still unresolvable, but ZeroNet 0.4.1 r1523 does not spam the console, so the issue is fixed. Thanks.
  ![screenshot 34](https://cloud.githubusercontent.com/assets/10778557/18287707/0935bc4e-742d-11e6-9d69-33d5342387fa.png)
![screenshot 33](https://cloud.githubusercontent.com/assets/10778557/18287656/e1c22cd8-742c-11e6-916f-601ed41f7360.png)
 Non-reproducible issue.
@HelloZeroNet Please, close.  GH shows that 0.4.0 was released a day ago, but when I run 0.4.0 it says "NEW ZERONET VERSION: 0.4.1".

This is confusing to have different versions shown in different places. Please keep them in sync.
 You should consider labeling them separately as "rc"="release candidate". ZN client should also show such versions differently.

I maintain ZN FreeBSD port, and I need a stable release. But the way how it is now users always see the green "NEW VERSION AVAILABLE" label, when this is only essentially a release candidate.
  using `python zeronet.py` gets me this error:

```- Starting ZeroNet...
[19:36:21] - OpenSSL loaded, version: 01000208F
[19:36:21] - Version: 0.4.1 r1510, Python 2.7.9 (default, Mar  1 2015, 12:57:24) 
[GCC 4.9.2], Gevent: 1.0.1
[19:36:22] - Creating FileServer....
[19:36:22] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 154 > socket.py line 342
[19:36:22] - Creating UiServer....
[19:36:22] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[19:36:22] - Removing old SSL certs...
[19:36:22] - Starting servers....
[19:36:22] Ui.UiServer --------------------------------------
[19:36:22] Ui.UiServer Web interface: http://127.0.0.1:43110/
[19:36:22] Ui.UiServer --------------------------------------
[19:36:22] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[19:36:23] FileServer Checking port 15441 using portchecker.co...
[19:36:25] FileServer [BAD :(] Port closed: Port 15441 is closed.
[19:36:25] FileServer Trying to open port using UpnpPunch...
[19:36:25] FileServer Checking port 15441 using portchecker.co...
[19:36:27] FileServer [BAD :(] Port closed: Port 15441 is closed.
[19:36:27] FileServer Checking port 15441 using canyouseeme.org...
[19:36:39] FileServer [BAD :(] Port closed: Error: I could not see your service on 110.34.10.195 on port (15441) Reason: Connection timed out
[19:36:39] FileServer Upnp mapping failed :( Please forward port 15441 on your router to your ipaddress

```

and nothing happens. 
```
 That doesn't loads anything
 Sometimes upnp mapping fails because your firewall is blocking the port. You need to open 15441 on your computer and make sure that your router supports UPNP.  You can also map it directly with the program upnpc: `upnpc -e 'ZeroNet' -r 15441 UDP`
 I don't have any firewall on my computer and i don't think my router supports UPNP. But i have manually forwarded the port 15441 from the router. But it still doesn't works
 Are you saying that you can't access anything? You don't need this to access content, only to publish..

What does http://portchecker.co/ say when you put 15441 in?
 nope, i can't access any content . I tried this one "http://127.0.0.1:43110/1PLAYgDQboKojowD3kwdb3CtWmWaokXvfp" but it said _This site canâ€™t be reached_ 
and portchecker shows me the 15441 port is closed even though i have it forwarded from my router
 Did you also open the port on your router's firewall? Are you sure you don't have a firewall on your own computer? Linux comes with a firewall built in.
 yeah, i did that on my router's firewall and i don't think  Debian has any  default firewall enabled
 It does have a firewall enabled. It's called iptables, which blocks everything by default. You can use ufw to unblock the port. https://wiki.debian.org/Uncomplicated%20Firewall%20(ufw)

Just install it, then type `ufw allow 15441`
 I allowed 15441 using ufw and `ufw status verbose` shows me its now allowed. But still i get port closed using portchecker.
I tried the ssh port too but  it's closed too
 Maybe check your router firewall log?  You have to enable ufw first before it works. Did you do that?
 is it possible that my ISP might be blocking port forwarding?
 If you're at a university or something similar, then yeah, definitely. Unlikely if it's a home network..
 well, i 'm at Home. Is it because of shared IP that my ISP is giving me
 Maybe you need to google your ISP and router names.. For now, you can use a zeronet proxy, like https://bit.no.com:43110
 okay then.... thanks
 I am suffering upnp port close too. It works well in my archlinux, but when being executed in a vagrant virtual box(also running arch), zeronet is showing that upnp port is closed. I've tried public/private networks with/without forwarding udp/tcp vagrant setting, but none of them works. The only useful information I got is all the same to his.

~~And without upnp working, nothing could be loaded in the 43110.~~
Sorry, my bad. It actually works well without upnp working. There are some [very aggressive](https://www.goto.info.waseda.ac.jp/~wei/file/wei-apan-v10.pdf) [NAT traversal algorithms](http://slideplayer.com/slide/693136/) designed by researchers from Waseda University. It is surprising that those algorithms are rarely put into production. They require dedicated servers to help complete the punching process.

There are some alternative methods of becoming an active peer:
- Turn on Tor Always mode
- Turn on I2P mode (support work in progress) Solved ? Closing ?   I am connecting with WiFi with my Android phone as Hotspot. So, I am not sure how to open the port. I already tried it with Windows Firewall Add rule in both Inbound and Outbound sections, both TCP and UDP, but ZeroNet still says that it's closed.
 Either that (points above) or you need to "switch on" DMZ mode/port forward it on your Router as it is firewalled. If you use Tor

![image](https://cloud.githubusercontent.com/assets/13272249/18560652/1e2a4794-7baf-11e6-878e-74e0a58a0ba9.png)
 Note that some mobile providers utilize carrier grade NAT and therefore you can't forward the port (at least not without hacking their networking equipment).
 Hi @vishnuhariam .
 have you tried phr34ko solution ? Does it solved the issue ?   Okay I was just checking the ZeroNet functionality and frankly, I am new to all this. Anyways, I put an index.html file with simple text like "Hello World" to check but, when I sign it, it says, 
SiteManager Save error: No sites found
SiteManager Deleting orphan site from content.db: 16GNrkv7Tf7r6TVUddXXXg7b1qzMdU6pgg

I am using Windows 10. Can anyone help me out?
 I also tried with an HTML template, but it still shows me the same error.
 Thanks a lot for the comment. But,when I drag the sidebar to left, it just keeps loading for a long time. I dunno what I am doing wrong. 
 Could it be due to the fact that the port 15441 is closed? Am using WiFi from Android.
 I have also tried reinstalling from scratch.
 Anyways, it started working as soon as I restarted my PC. And, then I signed it but no notification was shown if it was successful or not. Anyways, I went on to publish it, but the publish button on click keeps loading.
 I have already updated to 0.4.1 and I tried again. But, still I get the same error!
 OK, so here's what I did.
I skipped signing and set own as true in the sites.json. I then used sitePublish and the site was published and I could access it from another PC with the Zeronet bundle. 
 I'd like to tell you that the issue hasn't been fixed. I am still not able to sign the website. The Website Manager still gives me the same error.
 Already tried that multiple times. Tried reinstalling too.
 Here it is, 

```
`D:\Softwares\ZeroNet Bundle\ZeroBundle\ZeroNet>"D:\Softwares\ZeroNet Bundle\ZeroBundle\Python\python.exe" zeronet.py --debug siteSign 17RGryGYEe3DS8ZadoPDqvnee7mihjF1cr
- Starting ZeroNet...
PluginManager Loading plugin: AnnounceZero
PluginManager New plugin registered to: Site
PluginManager Loading plugin: CryptMessage
- opensslVerify loaded: <CDLL 'src/lib/opensslVerify/libeay32.dll', handle 11000000 at 3410fd0>
- OpenSSL loaded, version: 01000201F
PluginManager New plugin registered to: UiWebsocket
PluginManager New plugin registered to: User
PluginManager Loading plugin: MergerSite
PluginManager New plugin registered to: UiWebsocket
PluginManager New plugin registered to: UiRequest
PluginManager New plugin registered to: SiteStorage
PluginManager New plugin registered to: Site
PluginManager New plugin registered to: SiteManager
PluginManager Loading plugin: Newsfeed
PluginManager New plugin registered to: UiWebsocket
PluginManager New plugin registered to: User
PluginManager Loading plugin: Sidebar
PluginManager New plugin registered to: UiRequest
PluginManager New plugin registered to: UiWebsocket
PluginManager Loading plugin: Stats
PluginManager New plugin registered to: UiRequest
PluginManager Loading plugin: Trayicon
PluginManager New plugin registered to: Actions
PluginManager Loading plugin: Zeroname
PluginManager New plugin registered to: UiRequest
PluginManager New plugin registered to: ConfigPlugin
PluginManager New plugin registered to: SiteManager
PluginManager New class accepts plugins: ConfigPlugin (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.ConfigPlugin'>, <class 'Config.ConfigPlugin'>])
- Config: Config(action='siteSign', address='17RGryGYEe3DS8ZadoPDqvnee7mihjF1cr', batch=False, bit_resolver='1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F', coffeescript_compiler='type %s | tools\\coffee\\coffee.cmd', config_file='zeronet.conf', connected_limit=10, data_dir='data', debug=True, debug_gevent=False, debug_socket=False, disable_db=False, disable_encryption=False, disable_sslcompression=True, disable_udp=False, fileserver_ip='*', fileserver_port=15441, homepage='1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D', inner_path='content.json', ip_external=None, keep_ssl_cert=False, log_dir='log', max_files_opened=2048, msgpack_purepython=True, open_browser=None, privatekey=None, proxy=None, publish=False, size_limit=10, stream_downloads=False, tor='enable', tor_controller='127.0.0.1:9051', tor_proxy='127.0.0.1:9050', trackers=['zero://boot3rdez4rzn36x.onion:15441', 'zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441', 'udp://tracker.coppersurfer.tk:6969', 'udp://tracker.leechers-paradise.org:6969', 'udp://9.rarbg.com:2710', 'http://tracker.aletorrenty.pl:2710/announce', 'http://explodie.org:6969/announce', 'http://torrent.gresille.org/announce'], trackers_file=False, ui_ip='127.0.0.1', ui_port=43110, ui_restrict=False, use_openssl=True, use_tempfiles=False, verbose=False)
PluginManager New class accepts plugins: Actions (Loaded plugins: [<class 'Trayicon.TrayiconPlugin.ActionsPlugin'>, <class 'main.Actions'>])
Db:ContentDb Connected to data/content.db in 0.000s (sqlite version: 2.6.0)...
Db:ContentDb Db version: 4, needed: 4
Db:ContentDb Check tables in 0.157s
PluginManager New class accepts plugins: SiteStorage (Loaded plugins: [<class 'MergerSite.MergerSitePlugin.SiteStoragePlugin'>, <class 'Site.SiteStorage.SiteStorage'>])
PluginManager New class accepts plugins: SiteManager (Loaded plugins: [<class 'Zeroname.SiteManagerPlugin.SiteManagerPlugin'>, <class 'MergerSite.MergerSitePlugin.SiteManagerPlugin'>, <class 'Site.SiteManager.SiteManager'>])
SiteManager SiteManager created.
PluginManager New class accepts plugins: Site (Loaded plugins: [<class 'MergerSite.MergerSitePlugin.SitePlugin'>, <class 'AnnounceZero.AnnounceZeroPlugin.SitePlugin'>, <class 'Site.Site.Site'>])
- Signing site: 17RGryGYEe3DS8ZadoPDqvnee7mihjF1cr...
Site:17RGry..F1cr ContentDb init: 0.015s, found files: 1, sites: 14
PluginManager New class accepts plugins: User (Loaded plugins: [<class 'Newsfeed.NewsfeedPlugin.UserPlugin'>, <class 'CryptMessage.CryptMessagePlugin.UserPlugin'>, <class 'User.User.User'>])
- UserManager added 1 users
User:1GuY2FtyVemtkdwP883RAjRSr3aaRDwiCd Saved in 0.045s
User:1GuY2FtyVemtkdwP883RAjRSr3aaRDwiCd Added new site: 17RGryGYEe3DS8ZadoPDqvnee7mihjF1cr in 0.076s
Private key (input hidden):
Site:17RGry..F1cr Opening site data directory: data/17RGryGYEe3DS8ZadoPDqvnee7mihjF1cr/...
Site:17RGry..F1cr - [SKIPPED] content.json
Site:17RGry..F1cr - index.html (SHA512: c31f0fb7cfd8ce712f44d91c7964aad84d5b22754cdfa3402abb85b3d276e2d8)
Site:17RGry..F1cr Changed files: ['content.json']
Site:17RGry..F1cr Adding timestamp and sha512sums to new content.json...
Site:17RGry..F1cr Verifying private key...
Site:17RGry..F1cr Correct 17RGryGYEe3DS8ZadoPDqvnee7mihjF1cr in valid signers: ['17RGryGYEe3DS8ZadoPDqvnee7mihjF1cr']
Site:17RGry..F1cr Signing content.json...
Site:17RGry..F1cr Saving to content.json...
Site:17RGry..F1cr File content.json signed!
SiteManager Save error: No sites found
SiteManager Sites not loaded yet...
SiteManager Loading sites...
Site:1MaiL5..Ju27 ContentDb init: 0.015s, found files: 9627, sites: 14
SiteManager Loaded site 1MaiL5gfBM1cyb4a8e3iiL8L5gXmoAJu27 in 0.015s
Site:1UDbAD..MkoV ContentDb init: 0.000s, found files: 1230, sites: 14
SiteManager Loaded site 1UDbADib99KE9d3qZ87NqJF2QLTHmMkoV in 0.016s
Site:186THq..z84o ContentDb init: 0.000s, found files: 802, sites: 14
SiteManager Loaded site 186THqMWuptrZxq1rxzpguAivK3Bs6z84o in 0.000s
Site:1MeFqF..q7nH ContentDb init: 0.000s, found files: 1, sites: 14
SiteManager Loaded site 1MeFqFfFFGQfa1J3gJyYYUvb5Lksczq7nH in 0.000s
Site:1Gfey7..fcdp ContentDb init: 0.000s, found files: 1, sites: 14
SiteManager Loaded site 1Gfey7wVXXg1rxk751TBTxLJwhddDNfcdp in 0.000s
Site:17RGry..F1cr ContentDb init: 0.000s, found files: 1, sites: 14
SiteManager Loaded site 17RGryGYEe3DS8ZadoPDqvnee7mihjF1cr in 0.000s
Site:1BLueG..tG49 ContentDb init: 0.000s, found files: 544, sites: 14
SiteManager Loaded site 1BLueGvui1GdbtsjcKqCf4F67uKfritG49 in 0.000s
Site:1BLogC..AGg8 ContentDb init: 0.000s, found files: 413, sites: 14
SiteManager Loaded site 1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8 in 0.000s
Site:1GrEen..yt7i ContentDb init: 0.000s, found files: 608, sites: 14
SiteManager Loaded site 1GrEenUGRWnzaNZjR3XsQa6dQgdPDTyt7i in 0.000s
Site:1Name2..hM9F ContentDb init: 0.000s, found files: 1, sites: 14
SiteManager Loaded site 1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F in 0.015s
Site:1HeLLo..Tf3D ContentDb init: 0.000s, found files: 1, sites: 14
SiteManager Loaded site 1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D in 0.000s
Site:1Gif7P..Xc7h ContentDb init: 0.000s, found files: 1163, sites: 14
SiteManager Loaded site 1Gif7PqWTzVWDQ42Mo7np3zXmGAo3DXc7h in 0.000s
Site:1iD5ZQ..duGz ContentDb init: 0.000s, found files: 1, sites: 14
SiteManager Loaded site 1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz in 0.000s
Site:1TaLkF..jipT ContentDb init: 0.016s, found files: 3344, sites: 14
SiteManager Loaded site 1TaLkFrMwvbNsooF4ioKAY9EuxTBTjipT in 0.016s
SiteManager SiteManager added 14 sites
SiteManager Updated merger sites in 0.016s
SiteManager Saved sites in 0.22s
SiteManager Updated merger sites in 0.000s
```
 [log.txt](https://github.com/HelloZeroNet/ZeroNet/files/458164/log.txt)

I have also attached the log as txt.
 The problem is the same as said in the title. Okay, let me explain. 
The siteCreate command does its job well, But, each time I run siteSign, it gives me the following error: "SiteManager Save error: No sites found"
And, even if I publish it, it won't work properly because once I use the sidebar to edit the Title and Description, it doesn't change at all. Moreover, I have tried to use the sidebar to Sign and Publish, but after clicking Sign and providing the Private key, there's nothing being shown, no notification saying it's done.
If I somehow disregard the siteSign problem and directly Publish, everytime the site says, "One file update failed" and I can't edit any information using the sidebar.
 Let me check and I'll let you know.
 Thanks a lot, Owner. Really starting to love it. And, once again, thanks for the quick replies. All the best and regards.
  The following example shows, how the star-up of ZeroNet fails, if the `pwd`  is outside of the project home folder:

```
zeronet_runner@computenode1softf1com /media/usb0/large_files/zeronet_runner $ nice -n20 python ./ZeroNet/zeronet.py 
- Starting ZeroNet...
Traceback (most recent call last):
  File "./ZeroNet/zeronet.py", line 15, in main
    import main
  File "./ZeroNet/src/main.py", line 86, in <module>
    PluginManager.plugin_manager.loadPlugins()
  File "./ZeroNet/src/Plugin/PluginManager.py", line 28, in loadPlugins
    for dir_name in os.listdir(self.plugin_path):
OSError: [Errno 2] No such file or directory: 'plugins'
zeronet_runner@computenode1softf1com /media/usb0/large_files/zeronet_runner $ ls
ZeroNet  data  log
zeronet_runner@computenode1softf1com /media/usb0/large_files/zeronet_runner $ ls ./ZeroNet/
Dockerfile  README.md    plugins           src       tools      zeronet.py
LICENSE     Vagrantfile  requirements.txt  start.py  update.py
zeronet_runner@computenode1softf1com /media/usb0/large_files/zeronet_runner $ uname -a
Linux computenode1softf1com 4.1.19+ #858 Tue Mar 15 15:52:03 GMT 2016 armv6l GNU/Linux
zeronet_runner@computenode1softf1com /media/usb0/large_files/zeronet_runner $ date
Mon Sep  5 07:09:20 UTC 2016
zeronet_runner@computenode1softf1com /media/usb0/large_files/zeronet_runner $
```
 @martinvahi Is this problem still present? What is your OS? I can't reproduce it on Ubuntu.  After upgrading my zerobundle to vertion 0.4.1, I've got an error:
Traceback (most recent call last):
  File "G:\ZeroBundle\ZeroNet\zeronet.py", line 16, in main
    main.start()
  File "G:\ZeroBundle\ZeroNet\src\main.py", line 419, in start
    actions.call(config.action, action_kwargs)
  File "G:\ZeroBundle\ZeroNet\src\main.py", line 118, in call
    func(*_kwargs)
  File "plugins\Trayicon\TrayiconPlugin.py", line 62, in main
    super(ActionsPlugin, self).main()
  File "G:\ZeroBundle\ZeroNet\src\main.py", line 129, in main
    ui_server = UiServer()
  File "G:\ZeroBundle\ZeroNet\src\Ui\UiServer.py", line 61, in **init**
    self.sites = SiteManager.site_manager.list()
  File "G:\ZeroBundle\ZeroNet\src\Site\SiteManager.py", line 128, in list
    self.load()
  File "plugins\Zeroname\SiteManagerPlugin.py", line 17, in load
    super(SiteManagerPlugin, self).load()
  File "plugins\MergerSite\MergerSitePlugin.py", line 301, in load
    super(SiteManagerPlugin, self).load(_args, **kwags)
  File "G:\ZeroBundle\ZeroNet\src\Site\SiteManager.py", line 49, in load
    for row in ContentDb.content_db.execute("SELECT \* FROM site WHERE ?", {"not__address": self.sites.keys()}):
  File "G:\ZeroBundle\ZeroNet\src\Db\Db.py", line 74, in execute
    return self.cur.execute(query, params)
  File "G:\ZeroBundle\ZeroNet\src\Db\DbCursor.py", line 49, in execute
    res = self.cursor.execute(query, params)
OperationalError: too many SQL variables

Quick googling showed that is SQLite limitation, at my system it limited to 999.
I've got ~1500 sites in my sites.json at the momment.
  The RSA implementation in ZeroNet/src/lib/rsa is not constant time since it uses pythons "pow" function.

[The offending library](https://github.com/sybrenstuvel/python-rsa)

In general this RSA implementation appears a little naive, for instance the encrypt_bigfile simply chunks a larger input into chunks fitting under N.

I suggests using the implementation in openssl (or pycrypto) instead.
 Closing ?   Currently embedding other zites is impossible due to cross-origin restrictions. Maybe there should be an option to disable the restrictions within a site's "content.json" file?

Use case scenarios:
- Easy to add disqus-like plugin for any zite.
- Embedding from a video sharing zite (like youtube does).
- etc.
 +1 I would also need to remove cross-origin restriction to be able to use react-router browserHistory and to access indexedDB
 > any site would able to access and modify all other site's data

But you need the private key to modify a site and publish the modification ?

If it is not possible what about an indexedDB wrapper function like for localStorage ? I could prepare a PR.
 I am ok to spend some times on it and see where it lead us if you think that you could then add it to ZeroNet. I am exploring an other solution to fix my problem but I still think that it is a nice feature.
 I see, here they write that the problems with the iframe have been around for a long time. But I have worked in ZeroBlogs YouTube through the iframe for a long time and well. I left a lot of blogs posts with YouTube video inserts. But recently they all stopped working :-/

```
Reason: CORS header 'Access-Control-Allow-Origin' missing
```

Is it possible to think of something to make YouTube videos work again on ZeroBlogs? The most common thing is that earlier in ZeroBlog worked perfectly iframe-inserts on YouTube-video. I read reviews that iframe in ZeroNet and should not work, but I used such videos in blogs dozens of times and everything worked fine. But recently it stopped working. Apparently, YouTube has increased security requirements. And now they require a header:

```
Uncaught DOMException: Failed to read the 'cookie' property from 'Document': The document is sandboxed and lacks the 'allow-same-origin' flag.
```
Can not this be fixed in ZeroNet itself? :)

Here are examples of videos that worked fine before, but stopped working now:

http://127.0.0.1:43110/144W6itCd6jUqHDx5SDjbFaRdTnh4gRBBA/?Post:41:60+years+of+space+age

http://127.0.0.1:43110/1ApsfuUfnyJm19qZguDzzqj7se41Ggxzrt/?Post:2:Ð˜Ð¼Ð¸Ñ‚Ð°Ñ‚Ð¾Ñ€+Ð¾Ð³Ð½Ñ+Ð¸Ð·+ÑÐ²ÐµÑ‚Ð¾Ð´Ð¸Ð¾Ð´Ð½Ð¾Ð¹+Ð»ÐµÐ½Ñ‚Ñ‹...  Right now all sites store their files in separate folders, some of them contain identical files.

With an IPFS-like storage system there would be no data duplication.

Would zeronet benefit from this?
 Initial page-load might be somewhat longer for a zite, but there is always a time-space trade-off. And since zites are single-page-applications, the initial page-load might not be the most relevant performance metric. Anyways, I see and accept your argument.
 I would love a backend using IPFS. This would also easily enable always-online caching nodes (think of a server running an IPFS node and pinning content for you).   I try access ZeroID, the animations work for 5 seconds, then stops. I try openning the ZeroMenu, but not works. Soon I'll post debug details.
 ```
[Wrapper] Created!
all.js?rev=1429:106 [ZeroWebsocket] Open
all.js?rev=1429:1356 [Wrapper] Setting title to ZeroID - ZeroNet
all.js:23 
    Pixi.js 3.0.3 - âœ° WebGL âœ°      http://www.pixijs.com/    â™¥â™¥â™¥ 


all.js:674 Start
all.js:457 [ZeroFrame] Array[2] Object
all.js:681 Low FPS: 15.666666666666666, Disabling animation...
all.js:457 [ZeroFrame] ["peers_added", 12] Object {cmd: "setSiteInfo", params: Object, id: 5}
all.js:457 [ZeroFrame] ["peers_added", 10] Object {cmd: "setSiteInfo", params: Object, id: 6}
```
 @HelloZeroNet, I've never had that problem. Not only the animation is stopping, but all the site. Why all the reason of problems need to be my side?!
  This will engage users with asks/suggestions/interactions.
 @HelloZeroNet, I suggest put a badge in README.md
  Even with the addictions, the file size is reduced.
 ## [Current coverage](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/560?src=pr) is 48.64% (diff: 100%)

> Merging [#560](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/560?src=pr) into [master](https://codecov.io/gh/HelloZeroNet/ZeroNet/branch/master?src=pr) will decrease coverage by **0.04%**

``` diff
@@             master       #560   diff @@
==========================================
  Files            55         55          
  Lines          6733       6733          
  Methods           0          0          
  Messages          0          0          
  Branches       1423       1423          
==========================================
- Hits           3278       3275     -3   
- Misses         3046       3047     +1   
- Partials        409        411     +2   
```

> Powered by [Codecov](https://codecov.io?src=pr). Last update [2fcfa21...5883776](https://codecov.io/gh/HelloZeroNet/ZeroNet/compare/2fcfa21761a3b1377c9453bfad5de8198b81b437...5883776caf125deba627a11cc2943b0297c0a340?src=pr)
 @HelloZeroNet, I've finished my works in this PR.
 @HelloZeroNet, any pronunciation about?
@mishfit and @parkour86, thanks for the suggestions. Updated. @HelloZeroNet.  I saw in the prints ZeroNet sites with only .bit domains, without any localhost address/port. How this occurs? A propen plugin? A propen browser?
 Its not clearly in the documentation. I'll think what I can do. Thanks.
  [16:39:44] Ui.UiServer --------------------------------------
[16:39:44] Ui.UiServer Web interface: http://0.0.0.0:43110/
[16:39:44] Ui.UiServer --------------------------------------
<socket fileno=7 sock=172.17.0.2:43110 peer=myip:52944>: Invalid HTTP method: '\x16\x03\x01\x02\x00\x01\x00\x01\xfc\x03\x03\xb0\xcax\x17\xd3\'[e<\x9b*\xb2\xedq\xe0\xf6\xf8\xacC\x95\xe7x\xb2)w\xc8!\xcf\x91\x9fc\xe6 Tm\xc2\xb2&\xae\x90j\x0c\x8a\xef\x81\xe1\xc2\xbf=\x1c\x99\xe6^j\xf9l%\xbd\xbe\x81\'\xa2\x0b\xf5[\x00"\xc0+\xc0/\xc0,\xc00\xcc\xa9\xcc\xa8\xcc\x14\xcc\x13\xc0\t\xc0\x13\xc0\n'
<socket fileno=7 sock=172.17.0.2:43110 peer=myip:52945>: Expected GET method: '\x16\x03\x01\x00\x80\x01\x00\x00|\x03\x02\x8b\x89\\x13>\x9704\xf6nW\xd5\x13\xb8\'"\xec\xb7\xe4X\xde=\xed7\xbcm\xcb\xee\xbdr\xf3"\x00\x00\x10\xc0\t\xc0\x13\xc0\n'
[16:39:45] FileServer Checking port 15441 using portchecker.co...
[16:39:46] FileServer [OK :)] Port open: Port 15441 is open.
 yes... I using https..now I switch to http, the error log is gone, but still "Connection with UiServer Websocket was lost. "
 I found if I mount my own data "-v /data/zeronet/data:/root/data" and use my old user.json will cause this problem, why?
 I just backup file users.json, should I backup anything else?
 I got it, I should pasue the hash from users.json manually.
  After I've download the Zero ID, the pannel page is:
<img src="http://image.prntscr.com/image/0aa4400592f94276bcbea3df3e92a28d.png"/>
 I got the same issue.

JS console:

```
all.js:2698 Uncaught TypeError: Cannot read property 'length' of undefined
```

The line in `all.js` is:

``` js
title: this.row.content.title.length > 20 ? this.row.content.title : void 0
```

So the issue is some sites do not have a title?
 @weakish

> I got the same issue.
> 
> JS console:
> 
> all.js:2698 Uncaught TypeError: Cannot read property 'length' of undefined
> The line in all.js is:
> 
> title: this.row.content.title.length > 20 ? this.row.content.title : void 0
> So the issue is some sites do not have a title?

All my problems the people relativize saying that the cause is my side. Happy to see that the problem isn't me! Thanks for commenting. Now I'll see the debug data and post here. My problem started after download Zero ID, I think.
 On my machine, this site is the clause: `http://127.0.0.1:43110/1ARCHYFfke9k3Jbj9uVXmbeDV9XueK3hLA`.
This site is a just a place holder for selling domain and I think it is safe to delete it.

I stopped zeronet, remove `data/1ARCHYFfke9k3Jbj9uVXmbeDV9XueK3hLA` and its entry in `sites.json`.
Then I restarted zeronet, now ZeroHello comes back.

**update**: fix a typo `s/date/data/`
 @weakish, I see now the log and had the same error. Thanks for help. I never hear talk about "date" folder, but "data" is where the sites are placed. You don't know the diff between "date" and "data", how can you see a debug log better than me and say have knowledge to say my site is the problem? 1ARCHYFfke9k3Jbj9uVXmbeDV9XueK3hLA is my site, why?! I'm sure you seen my site in another issue and going here to talk that the cause of problem is my side, but I'm not the reason of the problem!
@HelloZeroNet, thanks for fix and reproduce it. Believe me, I don't report here wrong feedback, I'm here for help. Whats the RV version of this fix update?
 @weakish 

> On my machine, this site is the clause: http://127.0.0.1:43110/1ARCHYFfke9k3Jbj9uVXmbeDV9XueK3hLA.
> This site is a just a place holder for selling domain and I think it is safe to delete it.
> 
> I stopped zeronet, remove date/1ARCHYFfke9k3Jbj9uVXmbeDV9XueK3hLA and its entry in sites.json.
> Then I restarted zeronet, now ZeroHello comes back.

This isn't only safe to delete, but safe to keep, too. This site is totally safe. Like any site in ZeroNet while using sandbox. The major utility of this site was serve as reference for fix this error.
 @DaniellMesquito 

>  I never hear talk about "date" folder

Thanks for pointing out the typo.  Fixed now.

> This site is totally safe. Like any site in ZeroNet while using sandbox.

Yes the site is safe. (It is just some plain HTML, it is safe even if not sandbox.) I mean deleting this site will not affect other sites (e.g. zeroid.bit affected lots of sites).

> how can you see a debug log better than me and say have knowledge to say my site is the problem? 
> I'm sure you seen my site in another issue and going here to talk that the cause of problem is my side

I just search the "title" key in content.json of every site (via shell scripting), and found that site.
I did not seen the site in another issue, and I didn't know who own the site before.
Deleting a site is just a temporary workaround.
`this site is the clause` is not accurate. I'm in a hurry.
The better wording is `this site triggers a bug in ZeroHello`.
 Sorry for this, I'm with problems and thinked you known my site via issues, because are people tracking me for jokes. And thanks for the corrections.
  I've properly created and signed my site, succesfully. Too, I've published. Says in CLI that is published for 0 peers, in UI pannel says that are 3 peers. The content.json says downloading, but it fails.
<img src="http://image.prntscr.com/image/0b087442d2e140db88b824d38275453a.png"/>
 @HelloZeroNet why my content.json fails downloading? Can U [access to see](http://127.0.0.1:43110/1AxCBPaTtvuCEq3GpYg26eAY5Z4KmdeF1H/) it works?
I suggest fix this error showings in a next update.
 Why this shows 3 peers if have only me? This is the conflict.
 You closed this issue with a "probably" doubt "response" while the problem is: inconsistente/conflicting/contraditory showing peers, and inconsistent error messages. I'm still waiting for a response.
 @HelloZeroNet, previously I would sync the content.json succesfully, but actually its with this error. My connection is ok with 1 megabyte per second.
  A GUI/CLI that starts when updating and user can see the progress of update.
 @HelloZeroNet, its quite simple. Before call the program to close, call the updater program to open a new browser tab with a localhost page with the update progress.
  When I try update my software, I gets this error:
<img src="http://image.prntscr.com/image/718a8cbf7a504c04906f69a8ead3e7a9.png"/>
My connection actually is in the diary 10MB and my speed is 1MBps, then the problem isn't in my side, I think.
 @HelloZeroNet, you can introduce a updater UI/CLI for user see the update progress.
  - [ ] Access the remote git reppo tracking new updates
- [ ] Assuming a update is ready, sync for download only the changed bytes using GIT system
 @HelloZeroNet

> You can use git if you want, but i dont see why is it necessary

Assuming you have a high speed Internet connection, download unecessary bytes is necessary.
 @HelloZeroNet

> Probably ZeroNet will not work on connections where downloading 2.5MB is a problem.

It a preconception commet, like the machism. My brazillian Internet connection have 10MB diary limit, after it my connection works at 3KB per second. And ZeroNet works very well in this extremely-poor connection! I don't think what you say is a point to disconsider saving the data plans of your users. I don't see the point of download unecessary bytes if it can download only what user needs. This uses BitTorrent-like, Tor, Bitcoin, Namecoin and a bunch of things, why not use GIT too?!
 @HelloZeroNet, users can simply install Git for work with it. ZeroNet updater with two options: download from master ZIP or using GIT system. User can download the 31MB in a lan-house or another connection, but will save his data plans. Believe on poor mans with 1KBps connections, these uses ZeroNet and it works.
 Automate it for final user giving the two options is better. but thanks for the suggestion, I'll use.
  This download all files or only the changed bytes like GIT?
  My idea is user can use the address of a altcoin ZeroNet can support instead of only Bitcoin.

The ideas:
- [ ] User can change the Bitcoin address for a supported altcoin address;
- [ ] The visitor can see the type of criptocurrency is used in address and can donate;

The initial altcoins:
- [ ] Dash
- [ ] Ethereum
- [ ] Monero
 If you are talking about site addresses, I think this would add unneeded complexity and bring no real benefits.
 @obv-mikhail

> If you are talking about site addresses, I think this would add unneeded complexity and bring no real benefits.

Thanks for your edited comment. This isn't bring complexity, but diversity and more options. Site owners will gain more options for donations and reach users of different altcoins. For example, can create an faucet about Dash, and users can donate directly for the site address using his wallet. I have other issues here that you can consider, or you only comment with contrary?!
 Having more options does not equate to any real benefits, considering that bitcoin is more popular than all other cryptocurrencies combined.
   Clone the site, and delete the old one.

From what I understand, it is impossible to change the address of an existing site because it will still exist if other people are seeding it. Even if you delete all content and republish the site, it will still be seeded by other people. Correct me if I am wrong.
  Use these 3 branchs on GitHub, and offer the frontend client user to update from the channel he want. Too, notify user about updates available in each channel.
  When I try create a new site, this error is shown:

```
SiteManager Save error: No sites found
- Site created!
```

When I try publish my site:

```
sitePublish 1AxCBPaTtvuCEq3GpYg26eAY5Z4KmdeF1H
- Starting ZeroNet...
- OpenSSL loaded, version: 01000201F
- Loading site...
Traceback (most recent call last):
  File "zeronet.py", line 16, in main
    main.start()
  File "src\main.py", line 418, in start
    actions.call(config.action, action_kwargs)
  File "src\main.py", line 118, in call
    func(**kwargs)
  File "src\main.py", line 301, in sitePublish
    site = SiteManager.site_manager.list()[address]
KeyError: '1AxCBPaTtvuCEq3GpYg26eAY5Z4KmdeF1H'
```
 @HelloZeroNet, whats the new version after this error solved?
 @HelloZeroNet, how can I update it?
 @HelloZeroNet, thanks but I tried it and gets this:
<img src="http://image.prntscr.com/image/718a8cbf7a504c04906f69a8ead3e7a9.png"/>
I'll try manually dowload it.
 Hi @Plasmmer
have it been fixed since ? Can we close the issue ?  Y.  How can i start zeronet without the window browser from popping up everything time when i start the zeronet program?
 Hey can you please give me instructions for linux thanks
  It would be highly desirable if the `.zip` and `.tar.gz` files found on  the [Releases page](https://github.com/HelloZeroNet/ZeroNet/releases) were signed using GPG/PGP so that people can verify that the blobs haven't been tampered with.

Even  [signed commits](https://git-scm.com/book/en/v2/Git-Tools-Signing-Your-Work) could be useful.

As a minimum, please sha256sum the release files.

Cheers.
 The signatures should also be checked by the integrated updater.
 +1
This will prevent the use corrupt downloads from man-in-middle attacks.
  @HelloZeroNet This is an important issue for security and file integrity.

See here for how-to and complete details:
https://wiki.debian.org/Creating%20signed%20GitHub%20releases

Thank you. FIRST SIGNED COMMIT! Commits are now signed, :D 

Closing this issue ?   Hi,
I created a site on zeronet but when I go in the sidebar there is written MISSING FILES :
content.json
and when I try to connect from another computer there is written no peer found, 
I created a site on zeronet but when I go in the sidebar there is written : NO PEERS FOUND
Can you help me?
 How did you create the site? Did you sign and publish it?
 I followed this tutorial zeronet.readthedocs.io/en/latest/using_zeronet/create_new_site/
  After I joined ZeroMe hub, got a lot of these errors all the time:

``` python
  File "plugins/MergerSite/MergerSitePlugin.py", line 251, in fileDone
    merger_site.fileDone(virtual_path)
  File "plugins/MergerSite/MergerSitePlugin.py", line 245, in fileDone
    super(SitePlugin, self).fileDone(inner_path)
  File "src/Site/Site.py", line 931, in fileDone
    if inner_path == "content.json":
RuntimeError: maximum recursion depth exceeded in cmp
```

And post stream in `Followed users` has some difficulties to update
(showing posts 2 days ago, no recent posts).
  upon this command:

Page.cmd("fileWrite", [inner_path, btoa(json_raw)], function(res) {
    console.log(res);
    Page.cmd("sitePublish",{"inner_path":inner_path,"sign":false}, function(res) {
        console.log(res);
        $scope.$apply(function() {
            Page.cmd("wrapperNotification", ["done", "Comment posted!", 10000]);
            $scope.comments.push(comment);
        });
    });
});

im getting this console error - content publish failed

terminal log:
`[13:11:12] - Unhandled exception
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/gevent/greenlet.py", line 327, in run
    result = self._run(*self.args, **self.kwargs)
  File "src/Site/Site.py", line 425, in publish
    inner_path, limit, len(self.peers), num_connected_peers, diffs.keys(), float(len(str(diffs))) / 1024
AttributeError: 'NoneType' object has no attribute 'keys'
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/gevent/greenlet.py", line 327, in run
    result = self._run(*self.args, **self.kwargs)
  File "src/Site/Site.py", line 425, in publish
    inner_path, limit, len(self.peers), num_connected_peers, diffs.keys(), float(len(str(diffs))) / 1024
AttributeError: 'NoneType' object has no attribute 'keys'
`
 @HelloZeroNet, I think it is relationed with #544.
  Hi, after update to last ubuntu LTS i get this 

> NameError: name 'PROTOCOL_SSLv3' is not defined
 Thanks, it works for me
  Hi there,

Using ZeroNet from git's master branch, when I try to publish my zeronet site, I get the following error:

```
Traceback (most recent call last):
  File "zeronet.py", line 16, in main
    main.start()
  File "src/main.py", line 418, in start
    actions.call(config.action, action_kwargs)
  File "src/main.py", line 118, in call
    func(**kwargs)
  File "src/main.py", line 301, in sitePublish
    site = SiteManager.site_manager.list()[address]
KeyError: '<zeronet site address is here>'
```

Any advice would be greatly appreciated!
 Hi :smile: 

The issue was that I hadn't published for the first time. A good fix for this would be to check to see if the user has run the zeronet.py server since creating the site.
 Hi johnhamelink,

I'm having the same issue. I was able to create and sign my site but when I come to run the sitePublish command then the same error occurs. Could you expand on how you fixed this?

Thank you.
 @TheMediaGiant you have to just run `python zeronet.py` - the `sitePublish` command is only for updating. The docs don't make it all that clear ðŸ˜„ 
 Ah okay, we have to go to http://127.0.0.1:43110/zeronetsiteaddress at least once before we run the sitePublish command. That worked fine. Thanks for the great help!
 I had that problems: #544.
  > Beaker is a browser for IPFS and Dat. It's licensed MIT, and supports plugins for adding new protocols and Web APIs.

https://github.com/pfrazee/beaker
 I'm available to help out any plugin devs, and we have some good docs. (I may build a zeronet plugin myself; we'll see what my schedule looks like.)

I started `#beakerbrowser` in Freenode; you can find me there
 Using a browser for the single purpose of making URLs look pretty seems stupid to me.
 I don't think it is stupid if it stops cross site scripting attacks! Can beaker prevent scripts from running on other ZeroNet pages? I'll take a look.
 I second that, security and stopping XSS is important, and maybe this browser would make it way easier to spread/setup a local ZeroNet innstalation if its built into the plugin?  zeronet not have a mobile phone version ( Android version ) ?
 ï¼Ÿvery good
 @HelloZeroNet thanks,  has the manual install section gone? So we have an Android version, close this issue?  The latest version 0.4.0 where to download ?
 @HelloZeroNet Why didn't you make a tagged github release? Many OSes normally take only tagged releases.
  æœ€æ–°ç‰ˆçš„0.4.0åœ¨å“ªä¸‹è½½ï¼Ÿ
 You may wait till officially released.

Download the bundle here: https://github.com/HelloZeroNet/ZeroBundle/tree/master/dist
 @wpyok500 Released several days ago. Please close this issue.
  It won't connect to the Tor network.
This shows:

> Status: Error ([Errno 10061] No connection could be made because the target machine actively refused it.)

I don't understand what is causing it does it have the wrong URL to reach the tor network?

I'm using windows 10.
 It looks like this:

```
[2016- 00:00:03,572] INFO     - Creating FileServer....
[2016- 00:00:03,573] DEBUG    TorManager Connecting to 127.0.0.1:9051
[2016- 00:00:04,578] ERROR    TorManager Tor controller connect error: error: [Errno 10061] No connection could be made because the target machine actively refused it. in TorManager.py line 154 > socket.py line 342
[2016- 00:00:04,581] DEBUG    TorManager Tor proxy port 127.0.0.1:9050 check error: No connection
[2016- 00:00:04,581] INFO     TorManager Starting Tor client tools/tor/tor.exe...
[2016- 00:00:05,086] DEBUG    TorManager Connecting to 127.0.0.1:49051
[2016- 00:00:06,088] ERROR    TorManager Tor controller connect error: error: [Errno 10061] No connection could be made because the target machine actively refused it. in TorManager.py line 154 > socket.py line 342
[2016- 00:00:07,092] DEBUG    TorManager Connecting to 127.0.0.1:49051
[2016- 00:00:08,094] ERROR    TorManager Tor controller connect error: error: [Errno 10061] No connection could be made because the target machine actively refused it. in TorManager.py line 154 > socket.py line 342
[2016- 00:00:09,595] DEBUG    TorManager Connecting to 127.0.0.1:49051
[2016- 00:00:10,598] ERROR    TorManager Tor controller connect error: error: [Errno 10061] No connection could be made because the target machine actively refused it. in TorManager.py line 154 > socket.py line 342
[2016- 00:00:12,599] DEBUG    TorManager Connecting to 127.0.0.1:49051
[2016- 00:00:13,601] ERROR    TorManager Tor controller connect error: error: [Errno 10061] No connection could be made because the target machine actively refused it. in TorManager.py line 154 > socket.py line 342
(repeats a lot)
```

It doesn't seem to be trying to start tor client inside that tools directory.
 Hum... When I use `tools\tor\start.bat` I either can start tor with administrator permissions or it fails to start. When I try to start without administrator permissions:

```
Aug 10 05:16:55.144 [notice] Tor v0.2.7.6 (git-7a489a6389110120) running on Windows 8 with Libevent 2.0.22-stable, OpenSSL 1.0.1t and Zlib 1.2.8.
Aug 10 05:16:55.149 [notice] Tor can't help you if you use it wrong! Learn how to be safe at https://www.torproject.org/download/download#warning
Aug 10 05:16:55.167 [notice] Read configuration file "path\to\zeronet\ZeroNet\tools\tor\torrc".
Aug 10 05:16:55.171 [warn] Path for GeoIPFile (geoip\geoip) is relative and will resolve to path\to\zeronet\ZeroNet\tools\tor\geoip\geoip. Is this what you wanted?
Aug 10 05:16:55.174 [warn] Path for GeoIPv6File (geoip\geoip6) is relative and will resolve to path\to\zeronet\ZeroNet\tools\tor\geoip\geoip6. Is this what you wanted?
Aug 10 05:16:55.176 [warn] Path for DataDirectory (data) is relative and will resolve to path\to\zeronet\ZeroNet\tools\tor\data. Is this what you wanted?
Aug 10 05:16:55.182 [notice] Opening Socks listener on 127.0.0.1:49050
Aug 10 05:16:55.183 [notice] Opening Control listener on 127.0.0.1:49051
Aug 10 05:16:55.000 [warn] Error replacing "data\state": Invalid argument
Aug 10 05:16:55.000 [warn] Unable to write state to file "data\state"; will try again later
Aug 10 05:16:55.000 [warn] Error replacing "data\control_auth_cookie": Invalid argument
Aug 10 05:16:55.000 [warn] Error writing auth cookie to "data\\control_auth_cookie".
Aug 10 05:16:55.000 [warn] Error creating control cookie authentication file.
Aug 10 05:16:55.000 [err] set_options(): Bug: Acting on config options left us in a broken state. Dying. (on Tor 0.2.7.6 7a489a6389110120)
```
 It creates a data directory with these files:
1. `control_auth_cookie.tmp` (contains small binary data)
2. `lock`
3. `state.tmp` (contains small amount of text in 6 lines. The first 3 seem to be comments, though)
 @HelloZeroNet anything yet?
 It's weird it being a firewall issue... The issue seems to be file handling of some sort...
I just checked now (after you answer) and tor is working if I run it with administrator permissions O_O.
 on macos error from latest update... dont connect to tor... remaining in 
4] DEBUG    TorManager > PROTOCOLINFO
[2018-01-04 11:18:15,744] DEBUG    TorManager < 250-PROTOCOLINFO 1
250-AUTH METHODS=HASHEDPASSWORD
250-VERSION Tor="0.3.1.9"
250 OK
[2018-01-04 11:18:15,745] DEBUG    TorManager > AUTHENTICATE
  I'm on Mac OSX and have tried the commonly suggested fixes (ulimit and all that). Happens seemingly randomly. It makes using ZeroNet frustrating to use at times.
 Yup. Didn't help. I also tried `sudo sysctl -w kern.maxfiles=20480` and `sudo sysctl -w kern.maxfilesperproc=18000` neither of which helped. I ended up rebooting my computer and I haven't gotten the error since then.
 ```
Objects in memory (types: 145, total: 100606, 39930.37kb):
- 32919.0kb = 43141 x <type 'dict'>
- 1157.1kb = 16456 x <type 'builtin_function_or_method'>
- 472.8kb = 7564 x <type 'method-wrapper'>
- 638.1kb = 5445 x <type 'function'>
- 413.7kb = 3782 x <class 'Peer.PeerHashfield.PeerHashfield'>
- 688.3kb = 3671 x <class 'Peer.Peer.Peer'>
- 1441.8kb = 3047 x <type 'frame'>
- 185.4kb = 2629 x <type 'tuple'>
- 277.4kb = 2605 x <type 'list'>
- 102.9kb = 1317 x <type 'instancemethod'>
```

`Sockets (8):`

As I mentioned, I haven't gotten the error since I've rebooted. Keep that in mind.

Edit: I just got the error again. 'Objects in memory' is about the same. Sockets shot up to 260.
 ```
Max open files without changing settings: 253
Current RLIMIT_NOFILE limit: 256 9223372036854775807 Changing to 2048...
Max open files after changing settings: 2045
```

I found this script on a similar issue posted, and last time I ran it the 'max open files after changing settings' didn't change before (when I was having the error frequently). As of now, those above results again came while I'm not getting the error frequently.
  Err: UnicodeDecodeError: 'utf8' codec can't decode byte 0xa7 in position 219990: invalid start byte in UiServer.py line 81 > UiRequest.py line 82 > UiRequest.py line 209 > UiRequest.py line 285 > UiRequest.py line 167 > utf_8.py line 16
 i have reunpacked the zerobundle to another location and it worked fine but all the data i have downloaded is gone ,obviously ,my internet is slow so downloading the site again is annoying for me.
i use windows 7 32 btw
 ZeroNet is no handling non-ASCII folder names correctly. Check if your path to ZeroNet contains non-English characters. #735  zeronet click and stop
 ok
 What operating system are you using?
 Not enough info to have a proper issue, OP never came back , It can be closed IMO
   Here is a solution for bigger files support and more: virtual files with chunking.

So in your content.json, you would add a "vfiles" section such as this one

"vfiles" : {
    "path/to/vfile1" : [
        "path/to/vfile1/chunk1",
        "path/to/vfile1/chunk2",
        "path/to/vfile1/chunk3",
        "path/to/vfile1/chunk4",
        "path/to/vfile1/chunk5"
    ],
    "path/to/vfileN" : [
        "path/to/vfileN/chunkA",
        "path/to/vfileN/chunkB",
        "path/to/vfileN/chunkC",
        "path/to/vfileN/chunkD",
        "path/to/vfileN/chunkE",
        "path/to/vfileN/chunkF"
    ]
}

This would allow for smaller files ("chunks") to be concatenated from the filesystem to an HTTP response stream by the Ui server without affecting the sharing protocol at all.

Eventually, this could be extended with external vfiles to allow the Ui file server to hide the complexity of installing proxies and additional software by supporting them internally. When an HTTP by the client is made to the Ui server for such a file, the Ui server must handle the request to the external system and stream back the file to the client via http.

"vfiles" : {
    "path/to/vfile2" : {
        uri : "http://sjdf893hiwjkehrod.onion/bigMovie.mp4"
        size : 12567773,
        sha256 : "jk98ey934hoi099u23u423"
    },
    "path/to/vfileZ" : {
        uri : "ipfs://QmYwAPJzv5CZsnA625s3Xf2nemtYgPpHdWEz79ojWnPbdG/bigMovie.mp4"
        size : 638236,
        sha256 : "ASDH=ASDB234234"
    }
}

Of course the ZeroFrame Javascript API should also be extended to allow for better progress reporting.
 ## [Current coverage](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/521?src=pr) is 47.76% (diff: 8.69%)

> Merging [#521](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/521?src=pr) into [master](https://codecov.io/gh/HelloZeroNet/ZeroNet/branch/master?src=pr) will decrease coverage by **0.51%**

``` diff
@@             master       #521   diff @@
==========================================
  Files            55         55          
  Lines          6724       6813    +89   
  Methods           0          0          
  Messages          0          0          
  Branches       1423       1443    +20   
==========================================
+ Hits           3246       3254     +8   
- Misses         3065       3144    +79   
- Partials        413        415     +2   
```

> Powered by [Codecov](https://codecov.io?src=pr). Last update [af4447e...54ae3b4](https://codecov.io/gh/HelloZeroNet/ZeroNet/compare/af4447e66624682728cc1296705a286892859c24...54ae3b49df43b4badff1abe53da63fd11c18cf1e?src=pr)
 Hi all. I made a test site for that: 1ASN2GD7AMLcBwo6AViiEAf4KNX55Af6Ki

The HTML contains a HTML5 video element that requests an mp4 file for which there is a "vfiles" entry in the content.json. The array contains an ordered list of normal files that have been obtained with MP4Box with DASH-complient segments of the original MP4 file.

The video is in French and I provided French closed captions as well as English subtitles. Unfortunately, because of the ZeroNet Ui frame sandboxing, WebVTT tracks will not work. 

Now I will update my branch with the code to parse and concatenate all of this on the server-side. In the meantime, within the site, I provided a "concat.sh" script that will concatenate all the files to a single properly named file that will simulate what the server-side code will do for you.
 I will test in-stream VTT files to see if they are loaded.

UPDATE: there is no hope right now of getting subtitles to work with frame sandboxing. Moving on to implementing server-side concatenation.
 So I just committed the first functional "big file" support for ZeroNet. It works with `curl` but not from the browser. It's an HTTP thing. Would appreciate some help in debugging that if possible.
 Got rid of the broken pipe error. But the content still doesn't load in the browserâ€¦
 I still don't understand why are you dividing one "big" file into chunks if their summary size can't be more than 10 MB. In what cases will it be useful?
P.S. Are you trying to overcome 1 MB limit per file? Is this limit still in effect?
 > I still don't understand why are you dividing one "big" file into chunks if their summary size can't be more than 10 MB. In what cases will it be useful? P.S. Are you trying to overcome 1 MB limit per file? Is this limit still in effect?

@grez911 "Still" meaning that we've talked about it before? If so, I don't recall. I've seen ZeroNet choke on files as low as 256K with current codebase so obviously, supporting both bigger files _and_ chunking is an immediate, direct improvement. It is also backward compatible with the sharing protocol making it an elegant change too. Also, you can include optional file chunks in the list and they will all get transparently requested to peers with better load balancing between them when http-requesting the concatenated file. And my plan in the future for virtual files is to also support proxy files that can be streamed by the ZeroNet UI server from IPFS, WebTorrent and such without the need for the user to support external deamons.
 I just merged the merger site feature into this branch so it's in sync with the master branch.
 I will pause development of this feature until I hear from Tamas on what his intentions are with eventually pulling it.
 I don't mind refactoring this into a plugin if you tell me it is possible. But before I do that, I would like to know if you consider this feature worthy of pulling the code in, albeit as a plugin. Also can it be enabled by default ? Thanks.
 If Â«maturityÂ» is what you are looking for, then I'm going to concentrate on libzeronet and the first application I'm building on top of it. When this app is available on the Apple macOS App Store, users will be able to create content where ZeroNet and BitTorrent are used as storages back-ends: ZeroNet for the Core Data-compliant SQLite3 metadata store referring to BitTorrent-served large file blobs. Until virtual files are pulled in here, Python Ui users will only be able to see static JPEG thumbnails of the torrent blobs in the HTML Ui generated by the Cocoa browser. Then, I guess, the feature will be sufficiently mature to implement in Python. But it will take a couple of months at least.
  Can you add PHP to ZeroNet sites?

Thanks.

(Functioning PHP.)

Or does that have to be added on my side?
 ZeroNet is intended to serve static sites and Javascript, there's no server to run the PHP on.

But you can achieve almost anything using Javascript these days!
  Followed simple installation instructions for zero net and nothing happened. I downloaded bundle for mac opened ZeroNet app in bundle and got zero activity. I know nothing about code or open source projects so I need a little advice on getting this prog to run, thanks!
 Same problem.. I double click it and nothing happens and the sites don't work
 1. Install Homebrew and then use it in a terminal to install python:
   $ brew install python
2. Install python libraries:
   $ pip install gevent msgpack-python
3. Download, Unpack & run (in newly created directory):
   $ python zeronet.py

I recommend you to use tor-browser and encrypt the folder where all these apps are installed.
 Can't I install zeronet directly from brew then?
 Homebrew? Now I am confused, what is Homebrew? It looks like Alice is falling down the rabbit hole. I am looking for an idiot proof method of installation as I am not as knowledgeable as many techs. Thanks for the replies!!!
 OK, point taken! Unfortunately I only use computers for music production
and writing and don't understand a lot of the deeper intricacies of the
systems, but thanks for replying, yours Tony!

On Fri, Jul 22, 2016 at 11:21 AM, AdriÃ¡n E. Salatino <
notifications@github.com> wrote:

> Can't help idiots, sorry.
> Try READING http://letmegooglethat.com/?q=mac+homebrew about it ?
> 
> PS. sincerely, I can't solve your problem. I don't even have that
> closed-source operative system of yours. The whole point of trying to
> access the zeronet from there looks ridiculous to me.
> 
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/issues/514#issuecomment-234451277,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/ATnqgzIupuXxHiD2flft8hYNspYLfgRnks5qYEVIgaJpZM4JRfcU
> .
 Homebrew is a package system for OS X used to install CLI dependencies.

```
/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"
brew install python
pip install gevent msgpack-python
python zeronet.py
```

The comment of @Adrianzo is inappropriate and should really be deleted.
 I found that to run it you have to drop the .app inside the termina, in this way it starts
 it work's guys, try drag .app file and hit enter.
![screen shot 2016-07-22 at 6 43 27 pm](https://cloud.githubusercontent.com/assets/309709/17056239/495de626-503c-11e6-920c-9308361b6d7a.png)
 Here is a simple launcher: [ZeroNet Launcher](https://github.com/robinvandernoord/ZeroNetLauncher) for macOS
 I just use the docker image, it's the easiest way imho (if you already use Docker)
 Thanks, this has worked and thanks all who responded to my question!

On Sat, Aug 6, 2016 at 8:01 PM, Robin notifications@github.com wrote:

> Here is a simple launcher: ZeroNet Launcher
> https://github.com/robinvandernoord/ZeroNetLauncher for macOS
> 
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/issues/514#issuecomment-238022274,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/ATnqg7G3ttyZ2NuE1vO1sATOAupwKjtoks5qdIWbgaJpZM4JRfcU
> .
 @HelloZeroNet since I'm a developer I already had all the tools that ZeroNet requires installed, but I don't know if the mass of mac users has this too. Installing these dependancies can be a bit of a hassle for non-tech-savvy people maybe. But maybe it's preinstalled on all mac and there is no problem
  im trying to sign the data/users/content.json with this command: 
`zeronet.py siteSign [address] --inner_path data/users/content.json`
but im recieving the following error:

```
Site:19NtJa..BhUm File data/users/content.json not exist yet, loading default values...
Site:19NtJa..BhUm Opening site data directory: data/19NtJa1GVpNpyXmx27XshS4nWxd9f5BhUm/data/users/...
Site:19NtJa..BhUm - [SKIPPED] .DS_Store
Site:19NtJa..BhUm - [SKIPPED] content.json
Site:19NtJa..BhUm - [SKIPPED] 1C1gnFcVv9J9kUjF4odDMRYcEWVPJbbqFp/.DS_Store
Site:19NtJa..BhUm - 1C1gnFcVv9J9kUjF4odDMRYcEWVPJbbqFp/comment.json (SHA512: cbfd867e907d85320ad81b40c0bdb55aa8cb7bb2764fe43f5b8970fc4cb55845)
Site:19NtJa..BhUm - [SKIPPED] 1C1gnFcVv9J9kUjF4odDMRYcEWVPJbbqFp/content.json
Site:19NtJa..BhUm - 1C1gnFcVv9J9kUjF4odDMRYcEWVPJbbqFp/data.json (SHA512: 58265e6c679f9ab9df3f93be403819201072e6c0ee892c6601fb4ab0f9481853)
Site:19NtJa..BhUm - 1C1gnFcVv9J9kUjF4odDMRYcEWVPJbbqFp/post_vote.json (SHA512: 1b10cf2997c3be89d2c0a35e6a48e004b09d20241f335daa9f0d54f5d29fb182)
Site:19NtJa..BhUm Adding timestamp and sha512sums to new content.json...
Site:19NtJa..BhUm Verifying private key...
Site:19NtJa..BhUm Correct 19NtJa1GVpNpyXmx27XshS4nWxd9f5BhUm in valid signers: ['19NtJa1GVpNpyXmx27XshS4nWxd9f5BhUm']
Site:19NtJa..BhUm Signing data/users/content.json...
Site:19NtJa..BhUm data/users/content.json: No rules
Site:19NtJa..BhUm Sign failed: Invalid content
```

this is my data/users/content.json file:

```
{
  "files": {},
  "ignore": ".*",
  "modified": 0.0,
  "signs": {},
  "user_contents": {
    "cert_signers": {
      "zeroid.bit": [ "1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz" ]
    },
    "permission_rules": {
      ".*": {
        "files_allowed": "data.json",
        "max_size": 10000
      },
      "bitmsg/.*@zeroid.bit": { "max_size": 15000 }
    },
    "permissions": {
      "bad@zeroid.bit": false,
      "nofish@zeroid.bit": { "max_size": 100000 }
    }
  }
}
```

why is it not valid? here is the address of the site
http://127.0.0.1:43110/19NtJa1GVpNpyXmx27XshS4nWxd9f5BhUm
 Do you have it added as include to the root content.json ?   I keep deleting sites I visit only for once (seeing that I'm not interested in its content). I admit it, I'm kind of obsesive, I keep all my data quite tidied up.

I don't want to be asked every time I enter a site if I want to keep (like issue #492 ) this forever, but rather **I'd prefer to have a house cleaning built-in that erases zites I don't visit in N days**.

And I'd like to have some history of the websites I visit, with some information about the frequency of visits (how often I enter in a month). Using that information I would like deciding which zites I allocate more bandwith/disk usage.

This last point takes me to another one, I'd like to configure how much bandwidth/disk usage  I donate to every zite. And, I'd like to see how much bandwidth/disk usage a zite has over all users-seeders.

I'm kind of thinking zeronet as a big new web. I love the project, I am looking forward to learn a lot about it. Thanks for the hard work!
 Can we have a word on this?... it seems that only commented issues get replied :/
  this shit, is missing the zeronet.py . noway to get it running on a VPS.  
why always on local host start. ????

Linux terminal

```
wget https://github.com/HelloZeroNet/ZeroBundle/raw/master/dist/ZeroBundle-linux64.tar.gz
tar xvpfz ZeroBundle-linux64.tar.gz
cd ZeroBundle
Start with ./ZeroNet.sh
```

> how to change 127.0.01 to domain or IP ??????? 
  Why not directly use Tox? ...
 ZeroMail? It's pretty fast.
 I think if we were to make ZeroChat it would only be as slow as ZeroMail.
 it's possible to have a zeronet site filling this purpus , but unfortunately it won't be done inside this repository as it's zeronet core repository. 

Someone will have to start an initiative for a zeronet site. [ThunderWave](https://github.com/AnthyG/ThunderWave) has public chat (based on ZeroChat), and private chat (based on ZeroMail, but more secure), and I'll be adding group chat ASAP!  I don't think this idea is tight-related to zeronet. IMHO this is doable in the current state of the project by any web designer.
 I agree that this zite idea does not need support from the ZeroNet client itself. It is still a good idea for a zite. Maybe there should be a label for zite ideas on this project?
 Well what is the problem with the original site?
 

Someone will have to start an initiative in his own Github (or other)   in order to make this append. 
This can be as a site, no need to have the core involved in this. 
Closing ?   sometimes my zeronet UI is baffling lost.
 I guess if you use both Tor and ZeroNet you should be safe?
  ./ZeroNet.sh sitePublish xxxxxxxxxxxxxxxxxxxxxxxxxxx // my site address
- Starting ZeroNet...
- OpenSSL loaded, version: 01000207F
- Loading site...
- Creating FileServer....
  TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 154 > socket.py line 344
  FileServer Checking port 15441 using portchecker.co...
  FileServer [BAD :(] Port closed: Port 15441 is closed.
  FileServer Trying to open port using UpnpPunch...
  FileServer Checking port 15441 using portchecker.co...
  FileServer [BAD :(] Port closed: Error: URLError: <urlopen error timed out> in FileServer.py line 97 > urllib2.py line 154 > urllib2.py line 431 > urllib2.py line 449 > urllib2.py line 409 > urllib2.py line 1227 > urllib2.py line 1197
  FileServer Checking port 15441 using canyouseeme.org...
  FileServer [BAD :(] Port closed: Error: I could not see your service on x on port (15441) Reason: Connection timed out
  FileServer Upnp mapping failed :( Please forward port 15441 on your router to your ipaddress
- Gathering peers from tracker
  Site:1MGiNz..xxxx Publishing content.json to 5/0 peers (connected: 0) diffs: [](0.00k)...
- No peers found, sitePublish command only works if you already have visitors serving your site
 i just create the site and publish, so someone can visit.
any thing wrong? please help me, thank you very much.
 you mean after I create the site, it's available for other people?
but when I access the site from another computer in the same local net, it's always says:
#----------------------------------------------------
CONNECTING...
NO PEERS FOUND
CONTENT.JSON DOWNLOAD FAILED
CONTENT.JSON DOWNLOAD FAILED
 ok, thank you very much.
  Due to https://github.com/HelloZeroNet/ZeroNet/issues/466 the port 15441 stays open between runs, but ZeroNet still says "PORT: CLOSED" which is wrong and misleading. Additionally, port could just be open on the router.

Since the port might be open outside of ZN control, ZN should correctly detect if it is open and say "PORT: UNUSED BUT OPEN" or something to that effect.

Port being open vs. closed is a security matter, and ZN should handle the situation carefully and accurately.
  I cannot start Zeronet with Tor on Arch Linux.
I edited /etc/tor/torrc and removed the # character from lines ControlPort 9051 and CookieAuthentication 1, then I restarted tor service.
How can I add permission for my user to read the auth cookie? The following command doesn't work:

ls -al /var/run/tor/control.authcookie

I receive the following error when I start zeronet:

TorManager Tor controller connect error: IOError: [Errno 13] Permission denied: u'/var/lib/tor/control_auth_cookie' in TorManager.py line 165

Any idea? Thanks
 The answer is:

-rw------- 1 tor tor 32 Jun 12 12:11 /var/lib/tor/control_auth_cookie

I don't find the file's user group so that I add permission to my user.
 Thanks, HelloZeroNet.
 I tried, but doesn't work: I added ExtORPortCookieAuthFileGroupReadable 1 to /etc/tor/torrc but nothing changed.
 I set CookieAuthFileGroupReadable to 1 in /etc/tor/torrc but nothing changed: when I start zeronet with "python2 zeronet.py --tor always" or "python2 zeronet.py" I receive the same error:

"TorManager Tor controller connect error: IOError: [Errno 13] Permission denied: u'/var/lib/tor/control_auth_cookie' in TorManager.py line 165"
 Ok, thanks. I'll do that.
 Bobses, you just need to read comments carefully. https://aur.archlinux.org/packages/zeronet-git
 @Bobses solved ?  https://github.com/HelloZeroNet/ZeroNet#arch-linux

@HelloZeroNet Please, close.  I haven't restarted ZeroNet but all my Zeronet Favorites were un-favorited.
 Yes, I cleared my browser cache (I also notice this before when I accessed using a different browser). You can close this unless you want to leave it open for later enhancement. Also feel free to change issue title.
  I have several ZN instances running on different hosts/OSes, all with tor=always.

For some reason Hello Zeronet shows very different peer counts:

```
This site currently served by 385 peers, without any central server.
This site currently served by 585 peers, without any central server.
This site currently served by 481 peers, without any central server.
This site currently served by 688 peers, without any central server.
```

The separate counts of onion peers are also all very different.

This is confusing, shouldn't they be all the same or very close?
 Maybe it makes more sense to show seeders count instead? Because it seems that the tracker returns seeders/leachers counts.
 Question answered. Closing ?  Thanks!  `[this](http://127.0.0.1:43110:/123/doesn't (work))`

I don't know if it should, maybe the internal brackets should be escaped.
 Maybe you should report the problem to the site owner. This repository is for the zeronet core.   I created a blog on one Arch linux with tor=always, and no open 15441 port. Another instance of ZN running on another similar Arch setup always fails to download content.json.

The original instance also shows this message:

```
Your network connection is restricted. Please, open 15441 port
on your router to make your site accessible for everyone.
```

I think this message is completely wrong for tor=always because incoming connections should come from tor HS, and not from the port open on the router. It should work on tor.

The debug log on the downloading peer shows a timeout:

```
[18:55:03] WorkerManager:1HDT1a..wn9Z Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 1HDT1a..wn9Z>, 'done': False, 'size': 0, 'inner_path': 'content.json', 'peers': None, 'time_started': 1465264443.315883, 'time_action': None, 'priority': 9999, 'failed': [<Peer:ill4ijostvqk4h7e.onion>, <Peer:jccprijdxlok4krr.onion>, <Peer:jccprijdxlok4krr.onion>], 'workers_num': 0, 'time_added': 1465264443.303915, 'evt': <gevent.event.AsyncResult object at 0x7f81b07c2250>}
[19:04:34] WorkerManager:1HDT1a..wn9Z Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 1HDT1a..wn9Z>, 'done': False, 'size': 0, 'inner_path': 'content.json', 'peers': None, 'time_started': 1465265000.060174, 'time_action': None, 'priority': 9999, 'failed': [<Peer:ill4ijostvqk4h7e.onion>, <Peer:jccprijdxlok4krr.onion>], 'workers_num': 0, 'time_added': 1465265000.058588, 'evt': <gevent.event.AsyncResult object at 0x7f81a9cc2990>}
[19:05:35] WorkerManager:1HDT1a..wn9Z Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 1HDT1a..wn9Z>, 'done': False, 'size': 0, 'inner_path': 'content.json', 'peers': None, 'time_started': 1465265074.553957, 'time_action': None, 'priority': 9999, 'failed': [<Peer:ill4ijostvqk4h7e.onion>, <Peer:jccprijdxlok4krr.onion>], 'workers_num': 0, 'time_added': 1465265074.541852, 'evt': <gevent.event.AsyncResult object at 0x7f81a9c95fd0>}
...
out:[19:23:51] FileServer FileRequest: Conn#92 ill4ijostvqk4h7e.onion [v2] pex 1HDT1a{...}wn9Z None
out:[19:23:56] WorkerManager:1HDT1a..wn9Z Timeout, Skipping: {'optional_hash_id': None, 'site': <Site 1HDT1a..wn9Z>, 'done': False, 'size': 0, 'inner_path': 'content.json', 'peers': None, 'time_started': 1465266175.363997, 'time_action': None, 'priority': 9999, 'failed': [<Peer:ill4ijostvqk4h7e.onion>, <Peer:jccprijdxlok4krr.onion>, <Peer:jccprijdxlok4krr.onion>], 'workers_num': 0, 'time_added': 1465266175.36015, 'evt': <gevent.event.AsyncResult object at 0x7f81a9c10b10>}
```

Is ZN supposed to succeed seeing site hosted on tor-only peer from another tor-only peer? I think this should work, but it doesn't work for me.

When the site is seeded on tor-only peer it can only be visible to the clearnet ZN peers through the peers that are in both tor and clearnet.
 Yes, one of my hosts had disabled tor control port. I ran zeronet with --tor always, but ZN was still able to update sites. I think this is a bug that when tor=always fails it falls back to working through the clearnet. This is insecure, the correct behavior is to fail with the clear message that Tor is not configured correctly.
 > Yes, one of my hosts had disabled tor control port. I ran zeronet with --tor always, but ZN was still able to update sites. I think this is a bug that when tor=always fails it falls back to working through the clearnet. This is insecure, the correct behavior is to fail with the clear message that Tor is not configured correctly.

@yurivict @HelloZeroNet Can't reproduce. With --tor always option there is no fallback to clearnet.  This implements my suggestion: https://github.com/HelloZeroNet/ZeroNet/issues/474

I tested ZN inside the Tor-connected VM and it works fine.
 ## [Current coverage](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/484?src=pr) is **47.95%**

> Merging [#484](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/484?src=pr) into [master](https://codecov.io/gh/HelloZeroNet/ZeroNet/branch/master?src=pr) will decrease coverage by **0.50%**

``` diff
@@             master       #484   diff @@
==========================================
  Files            55         56     +1   
  Lines          6579       6725   +146   
  Methods           0          0          
  Messages          0          0          
  Branches       1379       1401    +22   
==========================================
+ Hits           3188       3225    +37   
- Misses         2993       3098   +105   
- Partials        398        402     +4   
```

> Powered by [Codecov](https://codecov.io?src=pr). Last updated by [523a7d4...257fd7e](https://codecov.io/gh/HelloZeroNet/ZeroNet/compare/523a7d4c16e8c2f590e759e23f0d2d6ae36cff37...257fd7e9d0985eee85901401318f8a8bfc5c1a82)
 The new --tor_hidden_services option expects the file containing the hidden services in this format:
{hs1-address}.onion
-----BEGIN RSA PRIVATE KEY-----
{hs1-private-key}
-----END RSA PRIVATE KEY-----
...
...
The same port that is used to listen for the file requests is expected to be routed from those onion services to the VM.

Onions can be generated using Shallot (https://github.com/katmagic/Shallot):

```
shallot a | grep -v '^\-*$' | sed -e 's/.*tries: //'
```
 Please hold this. I need to troubleshoot some issues first with my setup. I will update this PR's patch when done and when I will see that it works 100%.
 Ok
 Actually, this mode can't work outside of the VM, because it needs DNS resolution hooked up to Tor and IP routed through Tor, which I never saw to be done outside of the VM.

The possible environments are:
- Whonix VM
- Qubes VM
- VM connected with vm-to-tor on FreeBSD (my project https://github.com/yurivict/vm-to-tor)
  One probably could make a whole network hooked to Tor, but this isn't a practical setup.

So I am not very excited by the name "manual" here because it doesn't reflect what it is very well. Maybe we should name it "embedded"? "Embedded" reflects the meaning better, because ZN is "embedded" into the Tor-VM environment ?
 @HelloZeroNet Hi, I finished this feature. Tested it in VM, ZN works without any problems.

So do you agree to rename it into "embedded":
_--tor embedded --tor_hidden_services /path/to/hs-file_
 I'd also like this implemented. Good work!
 Thanks!

I use it in a VM ever since I implemented it 1.5 months ago without a problem.
  this is my docker container log:
   [08:04:04] FileServer Checking port 15441 using portchecker.co...
   [08:05:03] FileServer Internet offline,
But i have used the curl to test the portchecker.co in the container.It is working.
    curl -X "POST" "http://portchecker.co/check" \
    -H "Content-Type: application/x-www-form-urlencoded; charset=utf-8" \
    --data-urlencode "port=15441"
It can return right result that shows the port is opened.
 Now i am not using zeronet in the docker. I am running zeronet in my mac.
 @HelloZeroNet  it's not gone,maybe it is docker for mac 's problem.
  I changed, signed and published the site.

The peer then prints the error message:

```
js/all.js file size does not match 101391 <> 101304, Hash: False
```

When I look at the peer it still has the old content.json. The new content.json on the source doesn't get to the peer for some reason.

Log on the source only says:

```
[15:55:55] Site:1xxxx..xxxx content.json verified: 2124, quick: True, bad: [], optionals: +0 -0
```

no content.json is transferred which is wrong because it should be transferred.
 I also see a lot of "N FILE UPDATE FAILED" messages on the other random sites:

```
[19:11:03] Site:1xxxxx..xxxx data/0chan.db file size does not match 303104 <> 234496, Hash: False
```

I am not sure, but I don't think this is supposed to happen a lot.
So I don't think something is wrong with my sign/publish. I just don't know what is wrong.

For example, 0chan often or always fails to update:

```
[20:32:04] Ui.UiServer 127.0.0.1 - - [2016-06-01 20:32:04] "GET /0chan.bit/ HTTP/1.1" 200 2844 0.003653
[20:32:04] Ui.UiServer 127.0.0.1 - - [2016-06-01 20:32:04] "GET /0chan.bit/?wrapper_nonce=1199450251540766d66f23dfe1285918d0cd7c4e26544dbb4efd63ea06627b4d HTTP/1.1" 200 854 0.005294
[20:32:05] Db:0chan Connecting to data/1FiSxj2yDPeGuuf6iBwRAXvEMQJATAZNt6/data/0chan.db (sqlite version: 2.6.0)...
[20:32:05] Db:0chan Connected to Db in 0.000s
[20:32:05] Db:0chan Db is ready to use in 0.004s
[20:32:05] Db:0chan Db check done in 0.004s, changed tables: []
[20:33:36] Site:1NZNtZ..MsUc [CHANGED] data/0chan.db
[20:33:36] Site:1NZNtZ..MsUc content.json verified: 38, quick: True, bad: [u'data/0chan.db'], optionals: +0 -0
[20:33:36] Site:1NZNtZ..MsUc data/users/1PLdGxrwFvAS9eDYeDA4xVWRTvAruCy3PP/content.json verified: 2, quick: True, bad: [u'data/0chan.db'], optionals: +0 -0
[20:33:36] Site:1NZNtZ..MsUc data/users/1L3M5zYC5UDEtZn3X8gbYTTecRDH5nZJMf/content.json verified: 2, quick: True, bad: [u'data/0chan.db'], optionals: +2 -0
[20:33:36] Site:1NZNtZ..MsUc data/users/1KkMG9dp4HYwhmjGZJYgUcKS3aV1AmfxYq/content.json verified: 2, quick: True, bad: [u'data/0chan.db'], optionals: +2 -0
[20:33:36] Site:1NZNtZ..MsUc data/users/1Lk18hiad6GLwqC4aw5Hewm283C8dxrwBA/content.json verified: 2, quick: True, bad: [u'data/0chan.db'], optionals: +0 -0
[20:33:36] Site:1NZNtZ..MsUc data/users/1F1kH5mx9muPNJEwDJPMefhSwczQPcbae9/content.json verified: 2, quick: True, bad: [u'data/0chan.db'], optionals: +1 -0
[20:33:36] Site:1NZNtZ..MsUc data/users/1Cua1p5SQi9a68VuLtGovWAh3VwKxZY9Dn/content.json verified: 2, quick: True, bad: [u'data/0chan.db'], optionals: +0 -0
[20:33:36] Site:1NZNtZ..MsUc data/users/1F6kApxeK3xwVuWCTnaRkFZUdBA3d2ve3e/content.json verified: 2, quick: True, bad: [u'data/0chan.db'], optionals: +15 -0
[20:33:36] Site:1NZNtZ..MsUc data/users/1KwTTgPRSTHFmmJAFBt6kQfdyNeSM5KJuH/content.json verified: 2, quick: True, bad: [u'data/0chan.db'], optionals: +0 -0
[20:33:36] Site:1NZNtZ..MsUc data/users/14VNoqUXBDxe8Mjqvvu5okcqrnwDo3C58j/content.json verified: 2, quick: True, bad: [u'data/0chan.db'], optionals: +0 -0
[20:33:36] Site:1NZNtZ..MsUc data/users/1Gi4g59DwnkjgL9VmvmrfC95tMymyWFaaY/content.json verified: 2, quick: True, bad: [u'data/0chan.db'], optionals: +1 -0
[20:33:36] Site:1NZNtZ..MsUc Bad files: {u'data/0chan.db': 1}
[20:33:36] Site:1NZNtZ..MsUc Start downloading, bad_files: {u'data/0chan.db': 1}, check_size: False, blind_includes: False
[20:33:36] WorkerManager:1NZNtZ..MsUc New task: data/0chan.db, peer lock: None, priority: 0, optional_hash_id: None, tasks: 1
[20:33:36] WorkerManager:1NZNtZ..MsUc 190.46.102.175:15441: Someone already working on data/0chan.db, sleeping 1 sec...
[20:33:36] WorkerManager:1NZNtZ..MsUc 45.78.31.211:15441: Someone already working on data/0chan.db, sleeping 1 sec...
[20:33:36] WorkerManager:1NZNtZ..MsUc kafcdfs4ijxz2j3o.onion:15441: Someone already working on data/0chan.db, sleeping 1 sec...
[20:33:36] WorkerManager:1NZNtZ..MsUc 183.128.109.14:15441: Someone already working on data/0chan.db, sleeping 1 sec...
[20:33:36] WorkerManager:1NZNtZ..MsUc dxoxbmsxyeckxwef.onion:15441: Someone already working on data/0chan.db, sleeping 1 sec...
[20:33:36] WorkerManager:1NZNtZ..MsUc 217.29.189.55:15441: Someone already working on data/0chan.db, sleeping 1 sec...
[20:33:36] WorkerManager:1NZNtZ..MsUc 125.119.223.228:15441: Someone already working on data/0chan.db, sleeping 1 sec...
[20:33:36] WorkerManager:1NZNtZ..MsUc rkq3koi5hoxb235g.onion:15441: Someone already working on data/0chan.db, sleeping 1 sec...
[20:33:36] WorkerManager:1NZNtZ..MsUc 188.166.30.56:15441: Someone already working on data/0chan.db, sleeping 1 sec...
[20:33:37] WorkerManager:1NZNtZ..MsUc 190.46.102.175:15441: data/0chan.db, task done after sleep: False
[20:33:37] WorkerManager:1NZNtZ..MsUc 45.78.31.211:15441: data/0chan.db, task done after sleep: False
[20:33:37] WorkerManager:1NZNtZ..MsUc kafcdfs4ijxz2j3o.onion:15441: data/0chan.db, task done after sleep: False
[20:33:37] WorkerManager:1NZNtZ..MsUc 183.128.109.14:15441: data/0chan.db, task done after sleep: False
[20:33:37] WorkerManager:1NZNtZ..MsUc dxoxbmsxyeckxwef.onion:15441: data/0chan.db, task done after sleep: False
[20:33:37] WorkerManager:1NZNtZ..MsUc 217.29.189.55:15441: data/0chan.db, task done after sleep: False
[20:33:37] WorkerManager:1NZNtZ..MsUc 125.119.223.228:15441: data/0chan.db, task done after sleep: False
[20:33:37] WorkerManager:1NZNtZ..MsUc rkq3koi5hoxb235g.onion:15441: data/0chan.db, task done after sleep: False
[20:33:37] WorkerManager:1NZNtZ..MsUc 188.166.30.56:15441: data/0chan.db, task done after sleep: False
[20:33:44] Site:1NZNtZ..MsUc data/0chan.db file size does not match 319488 <> 234496, Hash: False
[20:33:44] WorkerManager:1NZNtZ..MsUc 217.29.189.55:15441: Hash failed: data/0chan.db, failed peers: 0
[20:33:44] Site:1NZNtZ..MsUc data/0chan.db file size does not match 300032 <> 234496, Hash: False
[20:33:44] WorkerManager:1NZNtZ..MsUc 45.78.31.211:15441: Hash failed: data/0chan.db, failed peers: 1
[20:33:44] Site:1NZNtZ..MsUc data/0chan.db file size does not match 300032 <> 234496, Hash: False
[20:33:44] WorkerManager:1NZNtZ..MsUc 190.46.102.175:15441: Hash failed: data/0chan.db, failed peers: 2
[20:33:54] Site:1NZNtZ..MsUc data/0chan.db file size does not match 306176 <> 234496, Hash: False
[20:33:54] WorkerManager:1NZNtZ..MsUc rkq3koi5hoxb235g.onion:15441: Hash failed: data/0chan.db, failed peers: 3
[20:33:55] WorkerManager:1NZNtZ..MsUc 98.159.74.138:15441: Someone already working on data/0chan.db, sleeping 1 sec...
[20:33:55] WorkerManager:1NZNtZ..MsUc 14.114.71.202:15441: Someone already working on data/0chan.db, sleeping 1 sec...
[20:33:55] WorkerManager:1NZNtZ..MsUc 178.187.80.235:15441: Someone already working on data/0chan.db, sleeping 1 sec...
[20:33:55] Site:1NZNtZ..MsUc data/0chan.db file size does not match 306176 <> 234496, Hash: False
[20:33:55] WorkerManager:1NZNtZ..MsUc kafcdfs4ijxz2j3o.onion:15441: Hash failed: data/0chan.db, failed peers: 4
[20:33:55] Site:1NZNtZ..MsUc data/0chan.db file size does not match 299008 <> 234496, Hash: False
[20:33:55] WorkerManager:1NZNtZ..MsUc dxoxbmsxyeckxwef.onion:15441: Hash failed: data/0chan.db, failed peers: 5
[20:33:56] WorkerManager:1NZNtZ..MsUc 98.159.74.138:15441: data/0chan.db, task done after sleep: False
[20:33:56] WorkerManager:1NZNtZ..MsUc 14.114.71.202:15441: data/0chan.db, task done after sleep: False
[20:33:56] WorkerManager:1NZNtZ..MsUc 178.187.80.235:15441: data/0chan.db, task done after sleep: False
[20:33:59] Site:1NZNtZ..MsUc data/0chan.db file size does not match 306176 <> 234496, Hash: False
[20:33:59] WorkerManager:1NZNtZ..MsUc 14.114.71.202:15441: Hash failed: data/0chan.db, failed peers: 6
[20:33:59] Site:1NZNtZ..MsUc data/0chan.db file size does not match 303104 <> 234496, Hash: False
[20:33:59] WorkerManager:1NZNtZ..MsUc 98.159.74.138:15441: Hash failed: data/0chan.db, failed peers: 7
[20:33:59] WorkerManager:1NZNtZ..MsUc Task taking more than 15+2 secs, workers: 5 find more peers: data/0chan.db
[20:34:01] WorkerManager:1NZNtZ..MsUc er3kkmqqdqa3kz7h.onion:15441: Someone already working on data/0chan.db, sleeping 1 sec...
[20:34:01] WorkerManager:1NZNtZ..MsUc 73.97.138.81:15441: Someone already working on data/0chan.db, sleeping 1 sec...
[20:34:02] Site:1NZNtZ..MsUc data/0chan.db file size does not match 305152 <> 234496, Hash: False
[20:34:02] WorkerManager:1NZNtZ..MsUc 178.187.80.235:15441: Hash failed: data/0chan.db, failed peers: 8
[20:34:02] WorkerManager:1NZNtZ..MsUc er3kkmqqdqa3kz7h.onion:15441: data/0chan.db, task done after sleep: False
[20:34:02] WorkerManager:1NZNtZ..MsUc 73.97.138.81:15441: data/0chan.db, task done after sleep: False
[20:34:03] Site:1NZNtZ..MsUc data/0chan.db file size does not match 297984 <> 234496, Hash: False
[20:34:03] WorkerManager:1NZNtZ..MsUc er3kkmqqdqa3kz7h.onion:15441: Hash failed: data/0chan.db, failed peers: 9
[20:34:04] Site:1NZNtZ..MsUc data/0chan.db file size does not match 302080 <> 234496, Hash: False
[20:34:04] WorkerManager:1NZNtZ..MsUc 73.97.138.81:15441: Hash failed: data/0chan.db, failed peers: 10
[20:34:14] Site:1NZNtZ..MsUc data/0chan.db file size does not match 303104 <> 234496, Hash: False
[20:34:14] WorkerManager:1NZNtZ..MsUc 183.128.109.14:15441: Hash failed: data/0chan.db, failed peers: 11
[20:34:16] WorkerManager:1NZNtZ..MsUc Task taking more than 15+2 secs, workers: 3 find more peers: data/0chan.db
[20:34:17] WorkerManager:1NZNtZ..MsUc rxwiqtp4drcytjlk.onion:15441: Hash failed: data/0chan.db, failed peers: 12
```
 Now I am trying to download 0chan.bit from scratch also on Arch linux. Now it says "6 FILE UPDATE FAILED", same as on Arch linux and on FreeBSD, all in tor=always mode. Something is broken in ZN.
 0chan.bit have no missing file atm, have you manage to fix the problem ?  Non-reproducible issue.
@HelloZeroNet Please, close.  I intentionally lowered the bandwidth of the tor relay such that only the smaller files can get through fast enough (see RelayBandwidthRate and RelayBandwidthBurst in torrc). ZN keeps downloading the larger files and fails smaller important files all.css and all.js with 404. The browser usually asks for more important files first.

ZN should move the files that browser requests to the top of the download queue so that the client will more likely see some version of the site instead of just waiting for something that he maybe doesn't even need at the time.
  I installed ZeroBlog, tried to edit my own comment as some logged in user, and got these errors:

```
Internal error: TypeError: 'NoneType' object does not support item assignment
UiWebsocket.py line 98 > UiWebsocket.py line 178 > UiWebsocket.py line 476
```

```
Internal error: TypeError: 'bool' object has no attribute '__getitem__'
UiWebsocket.py line 98 > UiWebsocket.py line 174 > UiWebsocket.py line 318 > UiWebsocket.py line 278
```
 No, I signed and published the site, jq validates contents.json fine.

The error messages appear when I clieck on "2 comments" under the blog post. It also doesn't show the comments.

Something isn't working, but I can't tell what.
 Sorry, it was a missing data/users/content.json file.
  Would it be possible to make the inbound port configurable?  I know it is not necessary to run ZeroNet, but it would allow those of us running behind a VPN to use different forwarded ports.

Thanks!
  After I change the .coffee files, siteSign doesn't run the coffee compiler so that all.js remains the same (--debug option is set). all.js is only updated when I access the site after siteSign.

coffee script should be run during the siteSign operation.
 This doesn't happen either, all.css and all.js aren't regenerated either when I run the site.
 For me it is only regenerated when I access the site after signing it, and also not every time. Something is wrong with this.
 I see. Thank you. I was under the impression that "Reload" invalidates cache but it turns out that it doesn't for css and js.
 I also found an issue with automatic compiling of coffeescript with the `--debug` flag on. My local site would 404 on a request to all.js every time, even when signing/publishing, manually refreshing with Ctrl-Shift-R and/or having the dev tools open (and yes the option for not caching with the tools open is checked). I'm running the latest version of FF Developer Edition and Zeronet v1422 under Arch Linux x64.

I was following the tutorial [here](http://127.0.0.1:43110/Blog.ZeroNetwork.bit/?Post:43:ZeroNet+site+development+tutorial+1) for creating a site but was stuck for hours until I realized it wasn't compiling the coffee-script automatically. My code and directory structure matches what was given in the tutorial. I was about ready to give up until I compiled manually.

The command I used to start Zeronet:
`sudo -u zeronet /usr/bin/env python2 zeronet.py --config_file /etc/zeronet.conf --debug`

Contents of config file:

```
[global]
data_dir = /opt/zeronet/data
log_dir = /var/log/zeronet
```

Output of above Zeronet command when unable to find all.js: [here](https://gist.github.com/anoadragon453/28af08e61410afd7040ac845c56de598). The site's address is 1A6J3fhJvUc7eTfonTU24a4n8GTM46YBxq.

I appreciate any help.
 It seems to be able to find it.

```
âžœ  js git:(master) âœ— python2 -c "import distutils.spawn; print distutils.spawn.find_executable('coffee')"
/usr/bin/coffee
```

After running:
`sudo -u zeronet /usr/bin/env python2 zeronet.py --config_file /etc/zeronet.conf --debug --coffeescript_compiler "/usr/bin/coffee --no-header -p"`

I still have the same issue, all.js not generated and returning a 404.

Permissions on /usr/bin/coffee are default rwxrwxrwx.
 Funnily enough an `all.js?rev=1422` file that contains coffee-script is generated under `/uimedia/all.js?rev=1422`, however I am unsure if this is generated by my site or not.
 ...I have not enabled that. Might want to add that to the tutorial :)

Give me one moment while I do that. In the meantime, another quick concern I have is that I often get the message that "This function is disabled on this proxy", for instance when toggling on the `This is my site` option just now. I believe this is the Multiuser plugin causing this, but is there a way to keep Multiuser on and avoid these errors?
 Thank you. Also after enabling the "This is my site" option I am presented with a javascript alert() that states:

```
/opt/zeronet/data/1A6J3fhJvUc7eTfonTU24a4n8GTM46YBxq/js/lib/ZeroFrame.coffee compile error: 

File not found: /opt/zeronet/opt/zeronet/data/1A6J3fhJvUc7eTfonTU24a4n8GTM46YBxq/js/lib/ZeroFrame.coffee
```

This is the contents of my data/1A6J3fhJvUc7eTfonTU24a4n8GTM46YBxq folder:

```
âžœ  1A6J3fhJvUc7eTfonTU24a4n8GTM46YBxq git:(master) âœ— tree
.
â”œâ”€â”€ content.json
â”œâ”€â”€ index.html
â””â”€â”€ js
    â”œâ”€â”€ all.js
    â”œâ”€â”€ lib
    â”‚Â Â  â””â”€â”€ ZeroFrame.coffee
    â””â”€â”€ ZeroChat.coffee
```

As you can see the all.js file is generated however only with the contents of the alert:

```


/* ---- /1A6J3fhJvUc7eTfonTU24a4n8GTM46YBxq/js/lib/ZeroFrame.coffee ---- */


alert('/opt/zeronet/data/1A6J3fhJvUc7eTfonTU24a4n8GTM46YBxq/js/lib/ZeroFrame.coffee compile error: File\ not\ found\:\ \/opt\/zeronet\/opt\/zeronet\/data\/1A6J3fhJvUc7eTfonTU24a4n8GTM46YBxq\/js\/lib\/ZeroFrame\.coffee\n');


/* ---- /1A6J3fhJvUc7eTfonTU24a4n8GTM46YBxq/js/ZeroChat.coffee ---- */


alert('/opt/zeronet/data/1A6J3fhJvUc7eTfonTU24a4n8GTM46YBxq/js/ZeroChat.coffee compile error: File\ not\ found\:\ \/opt\/zeronet\/opt\/zeronet\/data\/1A6J3fhJvUc7eTfonTU24a4n8GTM46YBxq\/js\/ZeroChat\.coffee\n');
```

Permissions of js/lib/ZeroFrame.coffee are `rwxrwxr-x`.

**EDIT:** Just realized the duplicate /opt/zeronet up there in the alert... not sure what that is.
 Oh hey! I managed to fix it!

The issue was putting `data_dir = /opt/zeronet/data` in zeronet.conf. Seems that was **prepended** to the dir that coffee-script was looking in. Looks like a bug.

This config option was added by the maintainer of the zeronet-git Arch Linux AUR package, if you're wondering where it came from. I'm assuming it's in the documentation if zeronet run with it in the config.
  I am seeing this error in the log:

```
[2016-05-31 17:35:18,125] DEBUG    - Running: "/usr/local/bin/coffee" --no-header -p "src/Ui/media/lib/ZeroWebsocket.coffee" (Done in 0.25s)
[2016-05-31 17:35:18,305] DEBUG    - Running: "/usr/local/bin/coffee" --no-header -p "src/Ui/media/lib/jquery.csslater.coffee" (Done in 0.18s)
[2016-05-31 17:35:18,306] ERROR    - UiWSGIHandler error: IOError: [Errno 13] Permission denied: 'src/Ui/media/all.js' in UiServer.py line 39 > pywsgi.py line 871 > pywsgi.py line 860 > SidebarPlugin.py line 31 > UiRequest.py line 378 > DebugMedia.py line 122
```

ZeroNet is attempting to overwrite the read-only installed file all.js and fails. It first runs the coffee command on the installed file src/Ui/media/lib/ZeroWebsocket.coffee. ZN shouldn't be re-running coffee on the installed files.
 Yes, that is it, when I touched all all.js files after installation this problem and #476 went away.

But this is generally a problem when you have ZN installed read-only by the package installer.

You probably want to skip running the coffee compiler on the files under plugins/ and src/ if these all.js files exist and are read-only.
  When I add --debug, 'all.js' file doesn't load into the client any more (it becomes a pending query). And the main page 1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D also doesn't work.
 I am only seeing this error: https://github.com/HelloZeroNet/ZeroNet/issues/477

This may or may not be a related - not sure.
 #477 is the real reason.
  I have these files in the data/ directory:

```
-rw-r--r--   1 _tor  _tor  65293479 May 24 23:33 GeoLite2-City.mmdb
-rw-r--r--   1 _tor  _tor      1566 May 31 02:26 cert-rsa.pem
-rw-r--r--   1 _tor  _tor      1704 May 31 02:26 key-rsa.pem
-rw-r--r--   1 _tor  _tor     23817 May 31 01:52 sites.json
-rw-r--r--   1 _tor  _tor     14156 May 31 01:20 users.json
```

Permissions should lose the world readable bit and the group readable bit.
  I am using ZeroNet for docker in my docker for mac . I set the port  forward  15441>0.0.0.0:15441.
Like this :

<img width="342" alt="screen shot 2016-05-30 at 9 51 55 am" src="https://cloud.githubusercontent.com/assets/708277/15637862/306f4e08-264c-11e6-86f7-e31c59d8ffac.png">
But ZeroNet shows the 15441 port is not opened.
And I am using ZeroNet in my parallels desktop  windows 10  too,it's ok.
i do not know it is docker for mac 's issue or zeronet 's issue.
 @HelloZeroNet 
 It is opened.
<img width="560" alt="screen shot 2016-05-30 at 4 41 54 pm" src="https://cloud.githubusercontent.com/assets/708277/15644409/76dd4a82-2685-11e6-9743-63ecfff7086f.png">
I saw the zeronet docker container log,the system is checking port 15441 using portchecker.co.But it is fail.
  I would like to run ZeroNet as a low-privileged user. But when I start zeronet with that user it can't read the tor cookie, because this cookie can only be read by the _tor user and root.

Please implement --setuid <uid> option and make zeronet read the tor cookie before it setuids.
 I use FreeBSD. On FreeBSD it isn't set up this way:

```
# ls -l /var/db/tor/control_auth_cookie 
-rw-------  1 _tor  _tor  32 May 29 14:45 /var/db/tor/control_auth_cookie
```

In general it is more flexible to have self-setuid option.
 Thanks.

I just created the FreeBSD port for ZeroNet, and was asking in this context, not for individual use. Since there is no self-suid I have to change it to _tor:_tor as startup. self-setuid would allow to avoid the need to run as _tor:_tor. Changing the tor configuration isn't feasible for the packaged ZeroNet.
 I agree with @yurivict. I use a stupid workaround now because of this issue.
I start tor as `debian-tor` and then `chown` the file with `<user>:debian-tor` (so group ownership is correct from the Tor perspective and user ownership on the auth file is correct from the ZeroNet perspective).
My ZeroNet user `<user>` is member of `debian-tor` (group) but that alone does not help. I also have the group readable setting set to 1.
 control_auth_cookie is a deliberately quite restricted file. Regardless of zeronet, Tor best practice are effectively to add the debian-tor group to tor allowed users AND set CookieAuthFileGroupReadable to 1 . 

That's how they manage who can use Tor on the machine. IMO Setting suid on zeronet side seem like a dirty workaround to me.

Others applications using tor can function without suid. zeronet should be able to do the same. setuid is also a security feature. It helps to isolate the process.
There is no reason to run zeronet as root.  After the system crash ZeroNet doesn't start any more:

```
[12:30:53] - OpenSSL loaded, version: 01000114F
[12:30:53] - Version: 0.3.6 r1098, Python 2.7.11 (default, May  6 2016, 08:39:38)
[GCC 4.2.1 Compatible FreeBSD Clang 3.4.1 (tags/RELEASE_34/dot1-final 208032)], Gevent: 1.1.1
[12:30:53] - Creating FileServer....
[12:30:53] TorManager Tor controller connect error: AssertionError: Authenticate error 515 Authentication failed: Password did not match HashedControlPassword value from configuration. Maybe you tried a plain text password? If so, the standard requires that you put it in double quotes.^M
 in TorManager.py line 170
[12:30:53] - Creating UiServer....
Traceback (most recent call last):
  File "/usr/local/share/zeronet/zeronet.py", line 16, in main
    main.start()
  File "/usr/local/share/zeronet/src/main.py", line 412, in start
    actions.call(config.action, action_kwargs)
  File "/usr/local/share/zeronet/src/main.py", line 115, in call
    func(**kwargs)
  File "/usr/local/share/zeronet/src/main.py", line 126, in main
    ui_server = UiServer()
  File "/usr/local/share/zeronet/src/Ui/UiServer.py", line 61, in __init__
    self.sites = SiteManager.site_manager.list()
  File "/usr/local/share/zeronet/src/Site/SiteManager.py", line 90, in list
    self.load()
  File "plugins/Zeroname/SiteManagerPlugin.py", line 17, in load
    super(SiteManagerPlugin, self).load()
  File "/usr/local/share/zeronet/src/Site/SiteManager.py", line 25, in load
    for address in json.load(open("%s/sites.json" % config.data_dir)):
  File "/usr/local/lib/python2.7/json/__init__.py", line 291, in load
    **kw)
  File "/usr/local/lib/python2.7/json/__init__.py", line 339, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
- Starting ZeroNet...
```

/var/db/zeronet/data/sites.json is blank. File sites.json-new is valid, when I copied it to sites.json it works. This should happen automatically. Or, better you should use SQLite.

zeronet-0.3.6
 sites.json was blank, sites.json-new was valid. So I copied it over.
 yurivict's specific problem have been solved, it might hide a bug but no others users have reported alike issues. Also it append on a now outdated zeronet version.

IMO Not much can be done here for this issue in 2017.  I use UFS on FreeBSD. Most people use linux, this is why this hasn't been reported by others.

This issue basically means that sites.json-new isn't actually used when sites.json is damaged/truncated.
Do you have a commit that solved this issue?
  I noticed that the files `data/users.json` and `data/sites.json` have the permissions `644` which means everybody can read them, even if they contain private keys. So I changed these files' permissions to `600` to ensure that only their owner can read them (as ssh does for its private keys).
I also modified the function `atomicWrite` so that the file permissions are preserved (they were reset to `644` each time). 
 ## [Current coverage](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/470?src=pr) is **48.46%**

> Merging [#470](https://codecov.io/gh/HelloZeroNet/ZeroNet/pull/470?src=pr) into [master](https://codecov.io/gh/HelloZeroNet/ZeroNet/branch/master?src=pr) will increase coverage by **0.08%**

``` diff
@@             master       #470   diff @@
==========================================
  Files            55         55          
  Lines          6573       6579     +6   
  Methods           0          0          
  Messages          0          0          
  Branches       1385       1379     -6   
==========================================
+ Hits           3177       3188    +11   
  Misses         2993       2993          
+ Partials        403        398     -5   
```

> Powered by [Codecov](https://codecov.io?src=pr). Last updated by [81f1966...9e9832a](https://codecov.io/gh/HelloZeroNet/ZeroNet/compare/81f196647b10e9086c159e3458f50f0437423355...9e9832ad09925de575e79a85f5cc555a1ea51a33)
  I'm using google chrome.
I'm also using two machines; these one is only to sync and visualize.
When I open my page on the same computer that I use to seed my page everything is allright; Open the same page on the second computer my page doesn't load propertly. 

I copy the error that i cought on the google chrome console: 

`jquery.mobile-1.4.5.min.js:1 Uncaught SecurityError: Failed to execute 'replaceState' on 'History': A history state object with URL 'http://127.0.0.1:43110/1ErAxF8656uGB4rcmWZzkdvDGvP2nvg77E/?wrapper_nonce=a1344e8476979d76d7b7121fab4cc68f9ec61d422f653abc3d9cc9e1526dcdf9' cannot be created in a document with origin 'null' and URL 'http://127.0.0.1:43110/1ErAxF8656uGB4rcmWZzkdvDGvP2nvg77E/?wrapper_nonce=a1344e8476979d76d7b7121fab4cc68f9ec61d422f653abc3d9cc9e1526dcdf9'.
`

Some help please??
 You mean that jquery mobile are not supported?
 But why it works on the computer that I developed?
It is not supposed to work right?
 Yes... Sign and publish more than one time.

Note. 
machine1: OSX. (I develop here)
machine2: Windows.
 Yes,I do thing so. 
How do I check it out?
 I mean there is a simple way to compare? ... like checksum? 
 I googled a bit, Many webdevs are reporting inconsistent behaviour across browsers concerning the use of replaceState inside iframe. 

EX: https://stackoverflow.com/questions/25386811/history-replacestate-issue-with-iframes

I doubt this issue is zeronet specific. 
  Do you customize the addresses of our official ZeroNet websites, or do you just keep making sites until it gives you the prefix you want? If so, have you released scripts to automate this?

Some examples:

```
1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D
1TaLkFrMwvbNsooF4ioKAY9EuxTBTjipT
1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8
1Gif7PqWTzVWDQ42Mo7np3zXmGAo3DXc7h
1MaiL5gfBM1cyb4a8e3iiL8L5gXmoAJu27
1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F
1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz
1Gfey7wVXXg1rxk751TBTxLJwhddDNfcdp
```

Thanks,
Eli
 @HelloZeroNet Awesome, thanks! Is there any command-line flag to use this private key in the creation of a new site, or do I have to construct a `content.json` from scratch?
  Is there any prebuilt program to host a poll on ZeroNet, using certificates and identities from `zeroid.bit`? Can a radio-button be made to share the theming of the other official ZeroNet template websites?

Thanks,
Eli
  Starting up the Linux client always took a minute or two, but nowadays it takes around 4 minutes on my machine.

```
wigy@xxxx:~/bin/ZeroNet$ ./zeronet.py 
- Starting ZeroNet...
[14:06:04] - OpenSSL loaded, version: 01000204F
[14:06:04] - Version: 0.3.7 r1210, Python 2.7.10 (default, Oct 14 2015, 16:09:02) 
[GCC 5.2.1 20151010], Gevent: 1.1b1
[14:06:04] - Creating FileServer....
[14:06:04] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 154 > _socket2.py line 186
[14:06:04] - Creating UiServer....
[14:09:51] - Removing old SSL certs...
[14:09:51] - Starting servers....
[14:09:51] Ui.UiServer --------------------------------------
[14:09:51] Ui.UiServer Web interface: http://127.0.0.1:43110/
[14:09:51] Ui.UiServer --------------------------------------
[14:09:52] FileServer Checking port 15441 using portchecker.co...
[14:09:53] FileServer [OK :)] Port open: Port 15441 is open.
```

Has anyone experienced this on other systems as well? Any hints what might happen just before removing the old SSL certs?
 The same problem in Linux Mint 17.3 based on Ubuntu 14.04
 Recent versions start up quite fast. Great ux improvement!
  After you have created new certificate with command "certAdd" it will shown as currently selected (see screenshot). But in reality you can't use it for posting until you click on it. So it is not actually selected. Only when you click on this cert, certificate register name will be added to users.json in section with sites (as "cert" property).

---

![screenshot from 2016-05-22 15 29 12](https://cloud.githubusercontent.com/assets/12672853/15453998/cd950f84-2033-11e6-8fef-3f41db04e044.png)

---

You can trace this bug on [nanasi board](http://127.0.0.1:43110/16KzwuSAjFnivNimSHuRdPrYd1pNPhuHqN), for example.
I think that label "currently selected" must be displayed only when name of certificate issuer added to sites section in users.json.
 @HelloZeroNet is this yet a issue?  Hello, I do not, do not know where is the problem?
windows 1511 10586.318

```
[2016-05-20 23:46:00,312] DEBUG    PluginManager Loading plugin: AnnounceZero
[2016-05-20 23:46:00,345] DEBUG    PluginManager New plugin registered to: Site
[2016-05-20 23:46:00,345] DEBUG    PluginManager Loading plugin: CryptMessage
[2016-05-20 23:46:00,519] DEBUG    - opensslVerify loaded: <CDLL 'src/lib/opensslVerify/libeay32.dll', handle 11000000 at 2ea2fb0>
[2016-05-20 23:46:00,519] INFO     - OpenSSL loaded, version: 01000201F
[2016-05-20 23:46:00,523] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2016-05-20 23:46:00,523] DEBUG    PluginManager New plugin registered to: User
[2016-05-20 23:46:00,523] DEBUG    PluginManager Loading plugin: Newsfeed
[2016-05-20 23:46:00,589] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2016-05-20 23:46:00,591] DEBUG    PluginManager New plugin registered to: User
[2016-05-20 23:46:00,591] DEBUG    PluginManager Loading plugin: Sidebar
[2016-05-20 23:46:00,605] DEBUG    PluginManager New plugin registered to: UiRequest
[2016-05-20 23:46:00,605] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2016-05-20 23:46:00,605] DEBUG    PluginManager Loading plugin: Stats
[2016-05-20 23:46:00,615] DEBUG    PluginManager New plugin registered to: UiRequest
[2016-05-20 23:46:00,615] DEBUG    PluginManager Loading plugin: Trayicon
[2016-05-20 23:46:00,621] DEBUG    PluginManager New plugin registered to: Actions
[2016-05-20 23:46:00,621] DEBUG    PluginManager Loading plugin: Zeroname
[2016-05-20 23:46:00,627] DEBUG    PluginManager New plugin registered to: UiRequest
[2016-05-20 23:46:00,627] DEBUG    PluginManager New plugin registered to: ConfigPlugin
[2016-05-20 23:46:00,630] DEBUG    PluginManager New plugin registered to: SiteManager
[2016-05-20 23:46:00,630] DEBUG    PluginManager New class accepts plugins: ConfigPlugin (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.ConfigPlugin'>, <class 'Config.ConfigPlugin'>])
[2016-05-20 23:46:00,630] DEBUG    - Config: Config(action='main', batch=False, bit_resolver='1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F', coffeescript_compiler='type %s | tools\\coffee\\coffee.cmd', config_file='zeronet.conf', connected_limit=10, data_dir='data', debug=False, debug_gevent=False, debug_socket=False, disable_db=False, disable_encryption=False, disable_sslcompression=True, disable_udp=False, fileserver_ip='*', fileserver_port=15441, homepage='1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D', ip_external=None, keep_ssl_cert=False, log_dir='log', max_files_opened=2048, msgpack_purepython=True, open_browser='default_browser', proxy=None, size_limit=10, stream_downloads=False, tor='enable', tor_controller='127.0.0.1:9051', tor_proxy='127.0.0.1:9050', trackers=['zero://boot3rdez4rzn36x.onion:15441', 'zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441', 'udp://tracker.coppersurfer.tk:6969', 'udp://tracker.leechers-paradise.org:6969', 'udp://9.rarbg.com:2710', 'http://tracker.aletorrenty.pl:2710/announce', 'http://explodie.org:6969/announce', 'http://torrent.gresille.org/announce'], trackers_file=False, ui_ip='127.0.0.1', ui_port=43110, ui_restrict=False, use_openssl=True, use_tempfiles=False, verbose=False)
[2016-05-20 23:46:00,630] DEBUG    PluginManager New class accepts plugins: Actions (Loaded plugins: [<class 'Trayicon.TrayiconPlugin.ActionsPlugin'>, <class 'main.Actions'>])
[2016-05-20 23:46:00,802] INFO     - Version: 0.3.7 r1287, Python 2.7.9 (default, Dec 10 2014, 12:24:55) [MSC v.1500 32 bit (Intel)], Gevent: 1.0.1
[2016-05-20 23:46:00,914] DEBUG    PluginManager New class accepts plugins: SiteManager (Loaded plugins: [<class 'Zeroname.SiteManagerPlugin.SiteManagerPlugin'>, <class 'Site.SiteManager.SiteManager'>])
[2016-05-20 23:46:00,914] DEBUG    PluginManager New class accepts plugins: Site (Loaded plugins: [<class 'AnnounceZero.AnnounceZeroPlugin.SitePlugin'>, <class 'Site.Site.Site'>])
[2016-05-20 23:46:00,951] DEBUG    - Disable SSL compression failed: function 'SSL_COMP_get_compression_methods' not found (normal on Windows)
[2016-05-20 23:46:00,980] DEBUG    - Missing SSLwrap, readded.
[2016-05-20 23:46:00,982] DEBUG    - Missing SSLContext, readded.
[2016-05-20 23:46:00,982] DEBUG    - Python SSL version: OpenSSL 1.0.1j 15 Oct 2014
[2016-05-20 23:46:01,105] DEBUG    PluginManager New class accepts plugins: User (Loaded plugins: [<class 'Newsfeed.NewsfeedPlugin.UserPlugin'>, <class 'CryptMessage.CryptMessagePlugin.UserPlugin'>, <class 'User.User.User'>])
[2016-05-20 23:46:01,115] DEBUG    PluginManager New class accepts plugins: UiWebsocket (Loaded plugins: [<class 'Sidebar.SidebarPlugin.UiWebsocketPlugin'>, <class 'Newsfeed.NewsfeedPlugin.UiWebsocketPlugin'>, <class 'CryptMessage.CryptMessagePlugin.UiWebsocketPlugin'>, <class 'Ui.UiWebsocket.UiWebsocket'>])
[2016-05-20 23:46:01,115] DEBUG    PluginManager New class accepts plugins: UiRequest (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.UiRequestPlugin'>, <class 'Stats.StatsPlugin.UiRequestPlugin'>, <class 'Sidebar.SidebarPlugin.UiRequestPlugin'>, <class 'Ui.UiRequest.UiRequest'>])
[2016-05-20 23:46:01,115] INFO     - Creating FileServer....
[2016-05-20 23:46:01,117] DEBUG    TorManager Connecting to 127.0.0.1:9051
[2016-05-20 23:46:02,122] DEBUG    TorManager Tor proxy port 127.0.0.1:9050 check error: 'ascii' codec can't decode byte 0xd3 in position 14: ordinal not in range(128)
[2016-05-20 23:46:02,122] INFO     TorManager Starting Tor client tools/tor/tor.exe...
[2016-05-20 23:46:02,625] DEBUG    TorManager Connecting to 127.0.0.1:49051
[2016-05-20 23:46:02,628] DEBUG    TorManager > PROTOCOLINFO
[2016-05-20 23:46:02,641] DEBUG    TorManager < 250-PROTOCOLINFO 1

250-AUTH METHODS=COOKIE,SAFECOOKIE COOKIEFILE="D:\\Program Files (x86)\\ZeroBundle\\ZeroNet\\tools\\tor\\data\\control_auth_cookie"

250-VERSION Tor="0.2.7.6"

250 OK
[2016-05-20 23:46:02,657] DEBUG    TorManager > AUTHENTICATE 2dfa7aed453bbd4b91646c1f71c4a30177fbc6cc0d3c859d6f5fa063e298b8ed
[2016-05-20 23:46:02,657] DEBUG    TorManager < 250 OK
[2016-05-20 23:46:02,658] INFO     - Creating UiServer....
[2016-05-20 23:46:02,658] DEBUG    - Loading sites...
[2016-05-20 23:46:04,022] DEBUG    - Loaded site 1TaLkFrMwvbNsooF4ioKAY9EuxTBTjipT in 1.359s
[2016-05-20 23:46:04,023] DEBUG    - Loaded site 1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F in 0.002s
[2016-05-20 23:46:04,026] DEBUG    - Loaded site 1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D in 0.002s
[2016-05-20 23:46:04,026] DEBUG    - Loaded site 1GUwoyRUxHWkUik5o4BBKgjrpbeCMXFj9z in 0.001s
[2016-05-20 23:46:04,028] DEBUG    - SiteManager added 4 sites
[2016-05-20 23:46:04,028] INFO     - Removing old SSL certs...
[2016-05-20 23:46:04,028] INFO     - Starting servers....
[2016-05-20 23:46:04,028] INFO     Ui.UiServer --------------------------------------
[2016-05-20 23:46:04,028] INFO     Ui.UiServer Web interface: http://127.0.0.1:43110/
[2016-05-20 23:46:04,029] INFO     Ui.UiServer --------------------------------------
[2016-05-20 23:46:04,029] INFO     - Opening browser: default_browser...
[2016-05-20 23:46:04,066] ERROR    - Failed to modify max files open limit: No module named win32file
[2016-05-20 23:46:04,575] DEBUG    - Generating RSA cert and key PEM files...Loading 'screen' into random state - done

Generating a 2048 bit RSA private key

.....+++

...........................................................................................................+++

writing new private key to 'data/key-rsa.pem'

-----
[2016-05-20 23:46:04,575] DEBUG    FileServer Binding to: *:15441, (msgpack: 0.4.6), supported crypt: ['tls-rsa']
[2016-05-20 23:46:04,575] DEBUG    FileServer Checking sites...
[2016-05-20 23:46:04,584] DEBUG    Ui.UiServer 127.0.0.1 - - [2016-05-20 23:46:04] "GET /1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D HTTP/1.1" 200 2882 0.008000
[2016-05-20 23:46:04,756] ERROR    - UiWSGIHandler error: TypeError: must be string without null bytes or None, not str in UiServer.py line 39 > pywsgi.py line 495 > pywsgi.py line 484 > SidebarPlugin.py line 32 > UiRequest.py line 387 > UiRequest.py line 101 > mimetypes.py line 290 > mimetypes.py line 351 > mimetypes.py line 254
[2016-05-20 23:46:04,756] DEBUG    Ui.UiServer 127.0.0.1 - - [2016-05-20 23:46:04] "GET /uimedia/all.css?rev=1287 HTTP/1.1" 000 - 0.136000
[2016-05-20 23:46:04,884] ERROR    - UiWSGIHandler error: TypeError: must be string without null bytes or None, not str in UiServer.py line 39 > pywsgi.py line 495 > pywsgi.py line 484 > SidebarPlugin.py line 32 > UiRequest.py line 387 > UiRequest.py line 101 > mimetypes.py line 290 > mimetypes.py line 351 > mimetypes.py line 254
[2016-05-20 23:46:04,885] DEBUG    Ui.UiServer 127.0.0.1 - - [2016-05-20 23:46:04] "GET /uimedia/all.js?rev=1287 HTTP/1.1" 000 - 0.129000
```

```
[2016-05-20 23:32:55,020] DEBUG    PluginManager Loading plugin: AnnounceZero
[2016-05-20 23:32:55,025] DEBUG    PluginManager New plugin registered to: Site
[2016-05-20 23:32:55,025] DEBUG    PluginManager Loading plugin: CryptMessage
[2016-05-20 23:32:55,048] DEBUG    - opensslVerify loaded: <CDLL 'src/lib/opensslVerify/libeay32.dll', handle 11000000 at 2ea2fb0>
[2016-05-20 23:32:55,049] INFO     - OpenSSL loaded, version: 01000201F
[2016-05-20 23:32:55,049] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2016-05-20 23:32:55,049] DEBUG    PluginManager New plugin registered to: User
[2016-05-20 23:32:55,049] DEBUG    PluginManager Loading plugin: Newsfeed
[2016-05-20 23:32:55,055] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2016-05-20 23:32:55,055] DEBUG    PluginManager New plugin registered to: User
[2016-05-20 23:32:55,055] DEBUG    PluginManager Loading plugin: Sidebar
[2016-05-20 23:32:55,058] DEBUG    PluginManager New plugin registered to: UiRequest
[2016-05-20 23:32:55,058] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2016-05-20 23:32:55,058] DEBUG    PluginManager Loading plugin: Stats
[2016-05-20 23:32:55,059] DEBUG    PluginManager New plugin registered to: UiRequest
[2016-05-20 23:32:55,059] DEBUG    PluginManager Loading plugin: Trayicon
[2016-05-20 23:32:55,059] DEBUG    PluginManager New plugin registered to: Actions
[2016-05-20 23:32:55,059] DEBUG    PluginManager Loading plugin: Zeroname
[2016-05-20 23:32:55,061] DEBUG    PluginManager New plugin registered to: UiRequest
[2016-05-20 23:32:55,061] DEBUG    PluginManager New plugin registered to: ConfigPlugin
[2016-05-20 23:32:55,061] DEBUG    PluginManager New plugin registered to: SiteManager
[2016-05-20 23:32:55,061] DEBUG    PluginManager New class accepts plugins: ConfigPlugin (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.ConfigPlugin'>, <class 'Config.ConfigPlugin'>])
[2016-05-20 23:32:55,062] DEBUG    - Config: Config(action='main', batch=False, bit_resolver='1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F', coffeescript_compiler='type %s | tools\\coffee\\coffee.cmd', config_file='zeronet.conf', connected_limit=10, data_dir='data', debug=False, debug_gevent=False, debug_socket=False, disable_db=False, disable_encryption=False, disable_sslcompression=True, disable_udp=False, fileserver_ip='*', fileserver_port=15441, homepage='1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D', ip_external=None, keep_ssl_cert=False, log_dir='log', max_files_opened=2048, msgpack_purepython=True, open_browser='default_browser', proxy=None, size_limit=10, stream_downloads=False, tor='enable', tor_controller='127.0.0.1:9051', tor_proxy='127.0.0.1:9050', trackers=['zero://boot3rdez4rzn36x.onion:15441', 'zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441', 'udp://tracker.coppersurfer.tk:6969', 'udp://tracker.leechers-paradise.org:6969', 'udp://9.rarbg.com:2710', 'http://tracker.aletorrenty.pl:2710/announce', 'http://explodie.org:6969/announce', 'http://torrent.gresille.org/announce'], trackers_file=False, ui_ip='127.0.0.1', ui_port=43110, ui_restrict=False, use_openssl=True, use_tempfiles=False, verbose=False)
[2016-05-20 23:32:55,062] DEBUG    PluginManager New class accepts plugins: Actions (Loaded plugins: [<class 'Trayicon.TrayiconPlugin.ActionsPlugin'>, <class 'main.Actions'>])
[2016-05-20 23:32:55,069] INFO     - Version: 0.3.7 r1287, Python 2.7.9 (default, Dec 10 2014, 12:24:55) [MSC v.1500 32 bit (Intel)], Gevent: 1.0.1
[2016-05-20 23:32:55,085] DEBUG    PluginManager New class accepts plugins: SiteManager (Loaded plugins: [<class 'Zeroname.SiteManagerPlugin.SiteManagerPlugin'>, <class 'Site.SiteManager.SiteManager'>])
[2016-05-20 23:32:55,085] DEBUG    PluginManager New class accepts plugins: Site (Loaded plugins: [<class 'AnnounceZero.AnnounceZeroPlugin.SitePlugin'>, <class 'Site.Site.Site'>])
[2016-05-20 23:32:55,088] DEBUG    - Disable SSL compression failed: function 'SSL_COMP_get_compression_methods' not found (normal on Windows)
[2016-05-20 23:32:55,096] DEBUG    - Missing SSLwrap, readded.
[2016-05-20 23:32:55,098] DEBUG    - Missing SSLContext, readded.
[2016-05-20 23:32:55,098] DEBUG    - Python SSL version: OpenSSL 1.0.1j 15 Oct 2014
[2016-05-20 23:32:55,111] DEBUG    PluginManager New class accepts plugins: User (Loaded plugins: [<class 'Newsfeed.NewsfeedPlugin.UserPlugin'>, <class 'CryptMessage.CryptMessagePlugin.UserPlugin'>, <class 'User.User.User'>])
[2016-05-20 23:32:55,112] DEBUG    PluginManager New class accepts plugins: UiWebsocket (Loaded plugins: [<class 'Sidebar.SidebarPlugin.UiWebsocketPlugin'>, <class 'Newsfeed.NewsfeedPlugin.UiWebsocketPlugin'>, <class 'CryptMessage.CryptMessagePlugin.UiWebsocketPlugin'>, <class 'Ui.UiWebsocket.UiWebsocket'>])
[2016-05-20 23:32:55,114] DEBUG    PluginManager New class accepts plugins: UiRequest (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.UiRequestPlugin'>, <class 'Stats.StatsPlugin.UiRequestPlugin'>, <class 'Sidebar.SidebarPlugin.UiRequestPlugin'>, <class 'Ui.UiRequest.UiRequest'>])
[2016-05-20 23:32:55,114] INFO     - Creating FileServer....
[2016-05-20 23:32:55,131] DEBUG    TorManager Connecting to 127.0.0.1:9051
[2016-05-20 23:32:56,134] DEBUG    TorManager Tor proxy port 127.0.0.1:9050 check error: 'ascii' codec can't decode byte 0xd3 in position 14: ordinal not in range(128)
[2016-05-20 23:32:56,135] INFO     TorManager Starting Tor client tools/tor/tor.exe...
[2016-05-20 23:32:56,650] DEBUG    TorManager Connecting to 127.0.0.1:49051
[2016-05-20 23:32:56,650] DEBUG    TorManager > PROTOCOLINFO
[2016-05-20 23:32:56,651] DEBUG    TorManager < 250-PROTOCOLINFO 1

250-AUTH METHODS=COOKIE,SAFECOOKIE COOKIEFILE="D:\\Program Files (x86)\\ZeroBundle\\ZeroNet\\tools\\tor\\data\\control_auth_cookie"

250-VERSION Tor="0.2.7.6"

250 OK
[2016-05-20 23:32:56,651] DEBUG    TorManager > AUTHENTICATE 63f9c70216d96725d5480756fcb206ef0fb49f54bba85de3282abad1351f2d84
[2016-05-20 23:32:56,651] DEBUG    TorManager < 250 OK
[2016-05-20 23:32:56,651] INFO     - Creating UiServer....
[2016-05-20 23:32:56,651] DEBUG    - Loading sites...
[2016-05-20 23:32:56,828] DEBUG    - Loaded site 1TaLkFrMwvbNsooF4ioKAY9EuxTBTjipT in 0.176s
[2016-05-20 23:32:56,828] DEBUG    - Loaded site 1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F in 0.000s
[2016-05-20 23:32:56,829] DEBUG    - Loaded site 1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D in 0.002s
[2016-05-20 23:32:56,829] DEBUG    - Loaded site 1GUwoyRUxHWkUik5o4BBKgjrpbeCMXFj9z in 0.000s
[2016-05-20 23:32:56,829] DEBUG    - SiteManager added 4 sites
[2016-05-20 23:32:56,831] INFO     - Removing old SSL certs...
[2016-05-20 23:32:56,831] INFO     - Starting servers....
[2016-05-20 23:32:56,831] INFO     Ui.UiServer --------------------------------------
[2016-05-20 23:32:56,831] INFO     Ui.UiServer Web interface: http://127.0.0.1:43110/
[2016-05-20 23:32:56,831] INFO     Ui.UiServer --------------------------------------
[2016-05-20 23:32:56,832] INFO     - Opening browser: default_browser...
[2016-05-20 23:32:56,858] ERROR    - Failed to modify max files open limit: No module named win32file
[2016-05-20 23:32:57,309] DEBUG    - Generating RSA cert and key PEM files...Loading 'screen' into random state - done

Generating a 2048 bit RSA private key

..........+++

...................................................................................+++

writing new private key to 'data/key-rsa.pem'

-----
[2016-05-20 23:32:57,311] DEBUG    FileServer Binding to: *:15441, (msgpack: 0.4.6), supported crypt: ['tls-rsa']
[2016-05-20 23:32:57,311] DEBUG    FileServer Checking sites...
[2016-05-20 23:32:57,312] DEBUG    Ui.UiServer 127.0.0.1 - - [2016-05-20 23:32:57] "GET /1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D HTTP/1.1" 200 2882 0.001000
[2016-05-20 23:32:57,559] ERROR    - UiWSGIHandler error: TypeError: must be string without null bytes or None, not str in UiServer.py line 39 > pywsgi.py line 495 > pywsgi.py line 484 > SidebarPlugin.py line 32 > UiRequest.py line 387 > UiRequest.py line 101 > mimetypes.py line 290 > mimetypes.py line 351 > mimetypes.py line 254
[2016-05-20 23:32:57,559] DEBUG    Ui.UiServer 127.0.0.1 - - [2016-05-20 23:32:57] "GET /uimedia/all.css?rev=1287 HTTP/1.1" 000 - 0.138000
[2016-05-20 23:32:57,690] ERROR    - UiWSGIHandler error: TypeError: must be string without null bytes or None, not str in UiServer.py line 39 > pywsgi.py line 495 > pywsgi.py line 484 > SidebarPlugin.py line 32 > UiRequest.py line 387 > UiRequest.py line 101 > mimetypes.py line 290 > mimetypes.py line 351 > mimetypes.py line 254
[2016-05-20 23:32:57,690] DEBUG    Ui.UiServer 127.0.0.1 - - [2016-05-20 23:32:57] "GET /uimedia/all.js?rev=1287 HTTP/1.1" 000 - 0.131000
```
 Tried, chrome, Firefox, ie not work
 @HelloZeroNet I did not install antivirus software
 Another computer operating normally, if I system problems, and other heavy equipment to see
 @dsyo2008 
Do you still have the problem with new version ? 
Have you tried the patch HelloZeroNet provided ? Non-reproducible issue.
@HelloZeroNet Please, close.  Is there an option to store the settings in the user folder? 
Something like ~/.local/shared/zeronet/  for example would be good.
  I see that signing and probably also publishing perl script wants 2.7 perl version, i assume it is not intended to support also older versions like 2.6.x? I have older OS (CentOS 6.x) and i always listen it should work with 2.6 and i should not replace it by 2.7, and i was unsuccessfull installing 2.7 in paralel.
 /usr/bin/env: python: No such file or directory
  Why is it necessary to create auth_address and auth_privatekey for every visited site even if the user can not use them to sign and publish anything on the site?
  I try to publish file `data.json` to my site with command:

```
window.Page.cmd("sitePublish", {
    "inner_path": "data/users/1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY/data.json",
    "privatekey": "xx"
});
```

and got an error "Content publish failed" from Wrapper.
In terminal I got this:

```
[18:44:20] Site:1LU8xo..JgXd Signing: data/users/1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY/data.json
[18:44:20] Site:1LU8xo..JgXd Opening site data directory: data/1LU8xoH9wk1DaWDkegEqT1d4UP6R2MJgXd/data/users/1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY/...
[18:44:20] Site:1LU8xo..JgXd - [SKIPPED] content.json
[18:44:20] Site:1LU8xo..JgXd - data.json (SHA512: 02d033d1348ac7a6635bff91ec9714921ad79851bd638d527e5d575c31f8a561)
[18:44:20] Site:1LU8xo..JgXd Changed files: [u'data/users/1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY/content.json']
[18:44:20] Site:1LU8xo..JgXd Adding timestamp and sha512sums to new content.json...
[18:44:20] Site:1LU8xo..JgXd Verifying private key...
[18:44:20] Site:1LU8xo..JgXd Correct 1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY in valid signers: [u'1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY', u'1LU8xoH9wk1DaWDkegEqT1d4UP6R2MJgXd']
[18:44:20] Site:1LU8xo..JgXd Signing data/users/1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY/content.json...
[18:44:20] Site:1LU8xo..JgXd Saving to data/users/1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY/content.json...
[18:44:20] Site:1LU8xo..JgXd File data/users/1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY/content.json signed!
[18:44:20] Site:1LU8xo..JgXd Publishing data/users/1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY/content.json to 5/23 peers (connected: 8) diffs: [] (0.00k)...
[18:44:21] Site:1LU8xo..JgXd [FAILED] 83.132.73.252:15441: {'to': 6, 'cmd': 'response', 'error': 'File invalid'}
[18:44:21] Site:1LU8xo..JgXd [FAILED] rw7wdm75rzxagkl2.onion:15441: {'to': 4, 'cmd': 'response', 'error': 'File invalid'}
[18:44:21] Site:1LU8xo..JgXd [FAILED] 188.166.30.56:15441: {'to': 56, 'cmd': 'response', 'error': 'File invalid'}
[18:44:21] Site:1LU8xo..JgXd [FAILED] 213.167.240.113:15441: {'to': 4, 'cmd': 'response', 'error': 'File invalid'}
```

`content.json` file:

```
{
 "address": "1LU8xoH9wk1DaWDkegEqT1d4UP6R2MJgXd",
 "cert_auth_type": "web",
 "cert_sign": "G7TwuWdV9xaNHZRMRHKCC8KXKXXWw3CC1CFUoxjnJ9tYN0mR2jc24tDzKdwN6avHxn1JHzp67hRiV7tdJINlBsI=",
 "cert_user_id": "1BJeFXLjVNYEo",
 "files": {
  "data.json": {
   "sha512": "02d033d1348ac7a6635bff91ec9714921ad79851bd638d527e5d575c31f8a561",
   "size": 83
  }
 },
 "inner_path": "data/users/1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY/content.json",
 "modified": 1463327060.520028,
 "signs": {
  "1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY": "G0rjKu+/gQUXZJWr8eF/TV19149JvaEdnHtYtGCHiyij2nEC3Ji1HKP3m23wiYiPunXYYf4uX1KdQmOTHoLKJzk="
 }
}
```

I don't understand, why `content.json` is invalid.
 I have added cert signer's name and recalculated cert_sign, but the problem has remained.
Here is the new content of `content.json` file:

```
{
 "address": "1LU8xoH9wk1DaWDkegEqT1d4UP6R2MJgXd",
 "cert_auth_type": "web",
 "cert_sign": "GyLaVKphCSOstiHCR9a8T4yw1La77mD3p2zF4dM5L7ynRDesJDpSXr/GP7LADyY9zgE/syFJOszFsX9Kr5RZtT0=",
 "cert_user_id": "1BJeFXLjVNYEo@anonchat",
 "files": {
  "data.json": {
   "sha512": "92f5cbffe33030c01804cf6a677463eefd7fdbf0610911a0f67ef74c719d41c3",
   "size": 77
  }
 },
 "inner_path": "data/users/1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY/content.json",
 "modified": 1463338988.635843,
 "signs": {
  "1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY": "HDP02g0OlNyGstJ9791T29IW5mBzAC4nFbi7f+7VQaGzIogrTEG8xeqVm0z7o4z9+jUMuPilmxN3NMYMH+IW70Y="
 }
}
```
 I have done that. This is my `data/users/content.json` file:

```
{
 "address": "1LU8xoH9wk1DaWDkegEqT1d4UP6R2MJgXd",
 "files": {},
 "ignore": ".*",
 "inner_path": "data/users/content.json",
 "modified": 1463319152.149632,
 "signs": {
  "1LU8xoH9wk1DaWDkegEqT1d4UP6R2MJgXd": "G1wdsn7hhpqhVNfI9/5MKrtzKpSfOWEDnN9za641EnWMpWZ7UGM3siAJlbik05Jg+sG3BVH6Cshkf+DFcAgQfJI="
 },
 "user_contents": {
  "cert_signers": {
   "anonchat": [ "1DKJtcz3JSLoaUprXcnEeD5LgXJSsfcn1x" ],
   "zeroid.bit": [ "1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz" ]
  },
  "permission_rules": {
   ".*": {
    "files_allowed": "data.json",
    "max_size": 10000
   }
  },
  "permissions": {}
 }
}
```

Maybe is  cert_sign wrong?
 > probably you have to sign+publish data/users/content.json

Thanks, this was the reason. BUT ALSO there was an error in the cert_sign, as I suspected â€“ there expected signature of string "1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY#web/1BJeFXLjVNYEo", I instead sign the "1BJeFXLjVNYEoiufm4PJUPrVM3opbbQeuY#web/1BJeFXLjVNYEo@anonchat" string when added "@anonchat" to cert_user_id. This was wrong and I don't need to recalculate the signature.
Problem has solved, thanks for your help!
  Can you add something to ZeroHello to ge the ability to create site categories (for example: utilities, social, games, torrent etc...)
 Yes but to find with zite to delete, or tu update all our social website, or to pause utilities it could be more useful
 When you have a look to Torrent Manager, there are differents categories to help the user manage his contents. So, in my mind, it should be the same for ZeroNet
 I also think you should use your browser for this. Nerverless, I tansfered the issue on the proper repository.
 Could you add a link or image to this `Torrent Manager` you are mentioning.

https://github.com/HelloZeroNet/ZeroHello/issues/56 Deluge and ÂµTorrent (at least) have categorization options.  if one site provides incorrect feed (such as lacking column), all feeds  disappears. only 

notification:
Internal error: xxxxxx
UiWebsocket.py line 98 > UiWebsocket.py line 176 > NewsfeedPlugin.py line 42

 it should skip incorrect ones and notify user the bad sites.
  https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Zeroname/updater/zeroname_updater.py#L9

I was investigating why one of my .bit domains wasn't popping up on 1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F even though the name_first_update for the d/record had 122 confs over a 24 hour time-frame. After a little investigating into how the zeroname_updater.py worked I discovered the `bitcoinrpc.authproxy` module doesn't exist. Quickly grabbing [Garzik's bitcoinrpc module](https://github.com/jgarzik/python-bitcoinrpc) confirmed that there's only a `proxy` module not an `.authproxy` module. 

```
import bitcoinrpc
help(bitcoinrpc)
```

Returns:

```
PACKAGE CONTENTS
    config
    connection
    data
    exceptions
    proxy
    util
```

and:

```
pkgpath = os.path.dirname(bitcoinrpc.__file__)
print [name for _, name, _ in pkgutil.iter_modules([pkgpath])]
```

Returns:

`['config', 'connection', 'data', 'exceptions', 'proxy', 'util']`

Simply changing the line from:
`from bitcoinrpc.authproxy import AuthServiceProxy`
to:
`from bitcoinrpc.proxy import AuthServiceProxy`

Seems to work, but I want to make sure I'm not overlooking anything. 

To be thorough I went looking through the ZeroNet bundled Python lib\site-packages to check for a copy of bitcoinrpc, but didn't find anything. Also grepping through the folder structure didn't return much to go off of. Most of the time I just work with `jsonrpc import ServiceProxy` directly so I'm not as familiar with bitcoinrpc. Is there an older version of bitcoinrpc ZeroNet depends on or any modifications not included in the github repo? 
 Looks like it might have been something silly. The original JSON was: `{ "zeronet" : { " " : "some-address" } }`. When I removed the space between the double quotes `{ "zeronet" : { "" : "some-address" } }` the namecoin/zeronet pairing was picked up almost instantly by 1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F.
  Hello,

I've got a problem with one ZeroSite: 0list
In fact it's in My sites but when I click on, i've a blank page, just the logo. If I follow the link : [ZerLink to 0list](http://127.0.0.1:43110/186THqMWuptrZxq1rxzpguAivK3Bs6z84o/) it works well, but the link: [0list.bit](http://127.0.0.1:43110/0list.bit/) don't work. Can you add an option to configure access to site using the long, unreadable link instead of the short one.
 I've got news!
This problem only append on Microsoft Edge, It doesn't append on chrome or Firefox. I think that this is a Edge related problem because webpage seems to not really refresh, and stats button (uper left) is interpret as an image and is not dragable.

> Is the other domain based sites works for you? eg http://127.0.0.1:43110/talk.zeronetwork.bit

Other websites was working, but sometimes they do the same, and it happens also with some long links like : [HelloZero long](http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D).

> What directories you see in plugins directory?
- AnnounceZero
- CryptMessage
- disabled-(Bootstrapper; Dnschain; DonationMessage; Multiuser; UiPassword; Zeroname-local)
- Newsfeed
- Sidebar
- Stats
- Trayicon
- Zeroname

> What blank means? Total white page or anythign visible?

I've got on 0list page: stats icon (upper left), 0list icon (upper right) and, just below, 'more', clickable that developp 'blog' and contribute.
On ZeroWiki I've got: stats icon (upper left), Zerowiki icon (Top), 'login', 'index', 'home', 'history', 'edit' and 'Text is available under the Creative Commons Attribution-ShareAlike License. 
 You license your contributions and edits to our site under the same license.'
On ZeroMail I've got: stats icon (upper left), ZeroMail icon (upper right), 'New message', 'inbox', 'sent' (right), don't have contacts (I had one before) and 'Inbox: no message' and 'No message selected'
I think that all this page are 'base' page and need to be feed with data.

> Is any error message in the javascript console? (F12)

No error message displays
EDIT: error messae appear while editing:

```
MessageShow render
all.js (3703,7)
Render: 40
all.js (1025,11)
```

This is for ZeroMail
 ![elwow](https://cloud.githubusercontent.com/assets/16024539/15560773/5d098e7e-22b4-11e6-85e6-656bcef66aca.png)

Seems to work for me.
 It worked, but after some time it stopped working. 
  No obvious register portal in the home page,only to click these official apps to be noticed to register.that isnt friendly to the new users
 I think it should be important to have an **ID wallet** built on ZeroNet utilities. It should be able to manage different ID profiles easily throughout the network. Given the issues with ZeroID from the point of view of privacy. 
 @Jzarecta why are you making off-topic topic comments in unrelated issues?
 I didnt think this was off-topic, actually I was going to open a new thread when I saw this hits to a similar sissue.
 It seem to work as designed to me. Closing ?   Hi. Just idea: using webRTC, browsers can communicate peer-to-peer. So there is no need to install any windows application, the whole thing can run in browser. However you would need to write the software in JavaScript.
 I agree with most of the objections, webRTC is shitty but it's the only thing available.
Just a note, File storage quota in browser can be increased to unlimited if user confirms.
 Closing, since it was just an idea :)
 I think this should be reconsidered because it would further reduce the entry barrier for accessing decentralized websites from "download, extract, execute" to "click on this link".

> Not possible to create sandboxed iframe enviroment (cross-origin scripting problems)
> You private key would need to be stored by the browser, so any site you visit would able to access it
> File storage problems (max storage size per site origin)

As far as I can tell you could do the following: Create two subdomains: `gate.zeronet.io` and `webrtcclient.zeronet.io`

Sites can be accessed using e.g. `gate.zeronet.io/#/ZeroNetwork.bit`.

On `gate.zeronet.io`, create an iframe containing `webrtcclient.zeronet.io`, which contains a port of the python client, stores the database (locally), has the secret keys and communicates with other clients using WebRTC. WebRTC support would then need to be added to the python client as well so they can interoperate. [Webtorrent](https://webtorrent.io/) is a good example of this already working.

Then replicate the API currently accessed via WebSocket through the iframe via [cross-document communication (window.postMessage)](https://developer.mozilla.org/en-US/docs/Web/API/Window/postMessage).

> No SQL support

Most browser support [IndexedDB](https://developer.mozilla.org/de/docs/IndexedDB) which can be used to store multiple gigabytes of data (up to some % of the available disk storage in chrome AFAIR) 

The data files could also be stored using IndexedDB or using the [Filesystem API](https://developer.mozilla.org/en-US/docs/Web/API/File_System_API) / [a polyfill](https://github.com/ebidel/idb.filesystem.js?files=1) for that.
There is also a [sqlite "port" to Javascript](https://github.com/kripken/sql.js/) which [should be possible to persist](https://github.com/kripken/sql.js/issues/78) also using IndexedDB. 

> No support for non-web content (eg. github repository)

I think the priority here should be web content, but it should also be possible to implement download of arbitrary data (e.g. as a zip)

> You would need to keep an open browser tab for every site you seeding

You would probably need to keep at least one tab open containing `webrtcclient.zeronet.io` yes, though Browsers have been starting to add functionality to do stuff as a website _without actually having the website open_, see [Service Workers](http://www.html5rocks.com/en/tutorials/service-worker/introduction/), [Push API](https://developer.mozilla.org/en-US/docs/Web/API/Push_API)

> WebRTC is created for small number of clients videochat system, not suitable to handling 100s of connections

Not sure about scalability, I couldn't find anything about WebRTC max connections right now. A fairly large problem might be not being able to use UPNP port mapping, but WebRTC has NAT traversal integrated.

Another is sending of large data cross domain.. not sure if thats possible without passing blobs via `postMessage` which might be too slow. An alternative would be to use a wildcard subdomain and access pages using `zeronetwork.bit.gate.zeronet.io`, then every site can have its own database.

> Tor connection not possible (Around 50% of ZeroNet clients using Tor)

Probably, I don't have any ideas about that.

I just found ZeroNet, so I'm sorry if I misunderstood something about how it works.
 @HelloZeroNet  When WebAssembly (supported in chrome canary) comes out, SQLite will get ported over and should be pretty fast. Seeding zites without tab open might be possible using a browser extension. Also, someone will likely make a python to WebAssembly compiler which might make porting over somewhat easier.

https://github.com/pypyjs/pypyjs/issues/145
 > You would need to keep an open browser tab for every site you seeding

Nope. Extention does it in background.
> Tor connection not possible

Nope. Maybe you can't connect to control port, but browser can actually be connected over tor like proxy. (you really need to know how much users use tor?)
> File storage problems

Nope. Use browser's cache as file storage.
> You private key would need to be stored by the browser, so any site you visit would able to access it

Nope. See extention. 
> WebRTC is created for small number of clients videochat system, not suitable to handling 100s of connections

Are you sure that you need more than 20-30 connections? Then one in five was on a site that you want?

And extention can redirect all *.bit zites to itself. Extension rules. Yes! I know there's some IRC clients in Chrome. If it doesn't support real sockets they can't support IRC protocol. Maybe this issue should be reopened?

I don't think targeting a Chrome extension would be the right approach here. That immediately binds to it to some extension API and thus to one browser. And every user would still need to install a Chrome extension. I wouldn't press install if someone sends me a random link, and that would be my goal for this; to be able to send links to websites that are viewable to almost everyone, instantly, and while still 95% decentralized.

You don't need to be an extension to get sandboxing for storing private keys or for storing data on disk. The only weak point I can think of is the https CA system. 

You could still publish a thin extension for parsing .bit domains and similar; and to verify the integrity of ZeroNet links to prevent the domain/CA system from compromising decentralization.

Not sure why every one here seems to be of the opinion that WebRTC sucks? The only problem I can see is that it does not support UPNP Port forwarding; but it has NAT port punching integrated. https://webtorrent.io/ opens >10 real peer to peer connections in less than 3 seconds for me and downloads 100MB from those in 30 seconds.
 > it downloads the video from https://webtorrent.io/torrents/sintel-1024-surround.mp4 and the webtorrent.io tab currently using 250MB of ram

Okay, I guess I never tested it on a slower machine. But I don't think 250MB is bad, considering it has to keep at least 130MB of video in RAM.

Yeah, thats because that URL is a webseed. It did download 2MB (in 60KB chunks) from that URL for me too, but the remaining 128 MB were downloaded from peers. (not shown in Chrome Dev tools)

> Also webrtc connections not fully p2p, you need to contact to google (or someone) before create connection to anyone

Well yes, but thats just bootstrapping right? You need that with every other method too, you can't just port scan the entire internet.

I'm not sure about this (have not tried it), but at least from how I understand it, you can get the peer description JSON via any channel. So you *can* connect to peers you get from other peers without ever going through a central server, once you have the initial connection to some peer. > I have i5 6600k (skylake) CPU, so it's not so slow. The GPU is running in separate process, so it's not includes that (if I open https://webtorrent.io/torrents/sintel-1024-surround.mp4 in a tab its displays 15MB)

True, but it still needs to keep it in JS memory to be able to seed it or receive bits that it doesn't have yet.

> No, it's not for bootstrapping (getting peer ips), but the both party need to connect to the STUN server every time before they want create new connection with eachother.

According to this: https://github.com/cjb/serverless-webrtc/ (warning: shitty demo, barely works)
It should work without a central server if you are able to send your peer a 4KB JSON and receive one in return through a different channel. The only thing you need is a STUN server connection once to get your own public IP and NAT configuration

I might look into doing some experiments but don't hold your breath. > Also webrtc connections not fully p2p, you need to contact to google (or someone) before create connection to anyone

Wait, situation is different now? ZeroNet can work only with the use of [LPD](https://en.wikipedia.org/wiki/Local_Peer_Discovery), [PeX](https://en.wikipedia.org/wiki/Peer_exchange) and DHT? Without any tracker? already?
(Sorry for that, but real p2p is still not been reached, e.g., I can't load downloaded zite from different node in local network without internet connection) As far as I know, clients cannot generate the 4KB JSON itself. They need to connect to a STUN server in order to obtain the information. The JSON contains IP addresses of gateway, port, etc - basically the information needed for other computers to connect to it. As far as I know there is no way to avoid this step, the browser needs to connect to STUN server to get the data. There are public STUN servers provided by google and many others.

Later, when clients have this 4KB JSON, they have to exchange this information so they know how to connect to each other. For that, there is usually another type of server needed (singalling server). But you may exchange the data between peers in any different way (users send it manually by email for example). There is example here: https://github.com/cjb/serverless-webrtc

In general, webrtc is not peer to peer per se, it needs some servers to setup connections between peers. However, once the client is connected to the p2p network, he can exchange data between peers directly without any additional server. As long as the client is on a type of network which allows this. One thing to add, as soon as the user is connected to other peers, he can use these peers to connect to other users (which are connected to the same peers), so there is no longer need for the signalling server in that case, if I understand it correctly. So the servers (stun and signaling) are only needed for initial connection of the client to the network.  Hi. I get this everytime I open zeronet and the main page wont load.

> Connection with uiServer websocket lost.... reconnecting
 Are you running a local ZN or going over a proxy ?
Because I have seen such messages often on proxies.

If local ZN: can you check what your debug.log says ?
 Well I can't paste the entire debug but the error starts at lib.geventwebsocket.handler bad server protocol in headers.
 thanks for trying to help me... I'm sure I will figure it out eventually.

On Tue, May 3, 2016 at 10:56 AM, ZeroNet notifications@github.com wrote:

> according to logs you browser tries to use http/1.0 instead of http1.1,
> not sure why is it happening (All common desktop browsers
> (Netscape/Mozilla, Internet Explorer, et al) in the last 10-13 years
> support HTTP/1.1.)
> 
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly or view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/issues/448#issuecomment-216554864
 I also encountered the same problem,windows10,I had try Chrome IE Opera and firefox,the same"Connection with UiServer Websocket was lost. Reconnecting...",Microsoft Edge can't even open the page.

On Chromeï¼Œthe javascript console repeat logsï¼š
[Wrapper] Created!
all.js?rev=1284:40 WebSocket connection to 'ws://127.0.0.1:43110/Websocket?wrapper_key=6351f80e76dd8ddf7b34b914744bfcc63e7d8360d128f88e045964abdf40b8bc' failed: Error during WebSocket handshake: Unexpected response code: 402
all.js?rev=1284:106 [ZeroWebsocket] Error Eventbubbles: falsecancelBubble: falsecancelable: falsecurrentTarget: WebSocketdefaultPrevented: falseeventPhase: 0isTrusted: trueisTrusted: truepath: Array[0]returnValue: truesrcElement: WebSockettarget: WebSockettimeStamp: 1266.3950000000002type: "error"**proto**: Event
all.js?rev=1284:106 [ZeroWebsocket] Closed CloseEventbubbles: falsecancelBubble: falsecancelable: falsecode: 1006currentTarget: WebSocketdefaultPrevented: falseeventPhase: 0path: Array[0]reason: ""returnValue: truesrcElement: WebSockettarget: WebSockettimeStamp: 1266.6200000000001type: "close"wasClean: false__proto__: CloseEvent
all.js:1045 [ZeroHello] Route Objecturl: ""**proto**: Object
all.js:1045 [ZeroHello] restore scrollTop null 0
all.js:1045 [ZeroHello] Websocket close
all.js?rev=1284:106 [ZeroWebsocket] Reconnecting...
 I have personally seen [Fiddler](http://www.telerik.com/fiddler) downgrading the protocol to HTTP 1.0. Maybe @Igitzu uses some web proxy similar to that tool?
  i meet this problem but i am going over a proxy ,can help me ? @Erkan-Yilmaz  Problem is probably from your proxy @yulele17 .
Have you tried without proxy or with a different one ?    It created in C: when the cmd is run to auto login the web.
  - Running a newer version than the "latest" release, but still getting prompted to update

![image](https://cloud.githubusercontent.com/assets/13134193/14941261/c7eabfec-0fc7-11e6-81a9-370ac0889227.png)
 Okay, closing this then
  If WerFault.exe in  process list, zeronet isfailed to run.
WerFault.exe is appeared by right click the 0 icon to quit.
 I has set it.But WerFault.exe is still appeared.
  Hey peeps, 

I was planning on using ZeroNet to make a website, but I came across a huge issue, databases. I read about something sql related with ZeroNet, but don't know much, so I am planning on a website which will have a lot of database needs, there will be a good amount of data, what do you guys think? If someone could lead me to the right direction then it would awesome! :)
 You should read the developer documentation and slideshow which is linked from the readme.

What you need to bear in mind is that the database is really just formed of data in JSON files published by individual users, and then mapped into the database. There's no backend process to run the database for you, unless you run something periodically on your own machine (which isn't great).

ZeroNet isn't great at hosting large amounts of data - how much were you thinking of?
 It won't take long to run through the build a site tutorial - it's on the sidebar in ZeroBlog.
 Thanks a lot guys, It's gonna be around 2-3 megabytes of data per day at max
 im glad the problem have been solved, would it be time to close the issue ?  @HelloZeroNet Please, close the issue.  Tried long-pressing the up-right button and sliding on it, but nothing made the sidebar show up.
 Perhaps an emulator? https://developer.chrome.com/devtools/docs/device-mode
  It's too long to remember it or input it.
 "Can I modify my Site Private Key?" <- I don't think you can change it
  ZeroNet was running for ca. 7.5h when those exceptions happened:

[2016-04-27 01:00:59,567] DEBUG    Site:1MaiL5..Ju27 69.122.63.218:15441 Getting connection...
[2016-04-27 01:00:59,567] ERROR    - Unhandled exception
Traceback (most recent call last):
  File "/home/AngelaMerkel/.local/lib/python2.7/site-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/File/FileRequest.py", line 139, in actionUpdate
    peer.last_content_json_update = site.content_manager.contents[params["inner_path"]]["modified"]
KeyError: 'data/users/13rBMTrszAYoc5jPgSMzkrBWNKCvJNY9zp/content.json'

[2016-04-27 01:00:59,568] DEBUG    Site:1MaiL5..Ju27 24.203.7.149:15441 Getting connection...
[2016-04-27 01:00:59,568] ERROR    - Unhandled exception
Traceback (most recent call last):
  File "/home/AngelaMerkel/.local/lib/python2.7/site-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/File/FileRequest.py", line 139, in actionUpdate
    peer.last_content_json_update = site.content_manager.contents[params["inner_path"]]["modified"]
KeyError: 'data/users/13rBMTrszAYoc5jPgSMzkrBWNKCvJNY9zp/content.json'

[2016-04-27 01:00:59,569] ERROR    - Unhandled exception
Traceback (most recent call last):
  File "/home/AngelaMerkel/.local/lib/python2.7/site-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/File/FileRequest.py", line 139, in actionUpdate
    peer.last_content_json_update = site.content_manager.contents[params["inner_path"]]["modified"]
KeyError: 'data/users/13rBMTrszAYoc5jPgSMzkrBWNKCvJNY9zp/content.json'

[2016-04-27 01:00:59,569] ERROR    - Unhandled exception
Traceback (most recent call last):
  File "/home/AngelaMerkel/.local/lib/python2.7/site-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/File/FileRequest.py", line 139, in actionUpdate
    peer.last_content_json_update = site.content_manager.contents[params["inner_path"]]["modified"]
KeyError: 'data/users/13rBMTrszAYoc5jPgSMzkrBWNKCvJNY9zp/content.json'
[2016-04-27 01:00:59,574] DEBUG    Site:1MaiL5..Ju27 Downloading data/users/13rBMTrszAYoc5jPgSMzkrBWNKCvJNY9zp/content.json...

used versions:
- ZeroNet 0.3.7 r1275
- gevent 1.0.2
- greenlet 0.4.9
  I had just restarted ZeroNet (1) and I got:

[06:40:56] - Unhandled exception

Traceback (most recent call last):
  File "/home/BarackObama/.local/lib/python2.7/site-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/Site/Site.py", line 311, in update
    self.storage.checkFiles(quick_check=True)  # Quick check and mark bad files based on file size
  File "src/Site/SiteStorage.py", line 356, in checkFiles
    add_changed=not self.site.settings.get("own")  # Don't overwrite changed files if site owned
  File "src/Site/SiteStorage.py", line 286, in verifyFiles
    for content_inner_path, content in self.site.content_manager.contents.iteritems():
RuntimeError: dictionary changed size during iteration

Traceback (most recent call last):
  File "/home/BarackObama/.local/lib/python2.7/site-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/Site/Site.py", line 311, in update
    self.storage.checkFiles(quick_check=True)  # Quick check and mark bad files based on file size
  File "src/Site/SiteStorage.py", line 356, in checkFiles
    add_changed=not self.site.settings.get("own")  # Don't overwrite changed files if site owned
  File "src/Site/SiteStorage.py", line 286, in verifyFiles
    for content_inner_path, content in self.site.content_manager.contents.iteritems():
RuntimeError: dictionary changed size during iteration

used versions:
- ZeroNet 0.3.7 r1274
- gevent 1.0.2
- greenlet 0.4.9

(1) it was running for less than 2 mins
  For now,ZeroNet Site URL is too long.Not good for share.

I think is any possible we create a ZeroNet privilege browser.Embed a type of Namecoin Network.

User->Browser->P2P Domain Name Network->Point to Website True URL->Load Content->Display.

Example:
User->demo.bit->Get http://127.0.0.1:43110/{zeronet_site_address}->Display
 There was/is a Chrome extension: https://chrome.google.com/webstore/detail/zeronet-protocol/cpkpdcdljfbnepgfejplkhdnopniieop?hl=en

Is that what you mean?
 @OliverCole not that simple. that extension can't use Namecoin DNS network.

if i want  input  demo.bit  and browser,it can't work.
 @HelloZeroNet @OliverCole Thanks!
  What about inserting wikipedia on the 0Network?

We could be able to access it offline and preserve the encyclopedia even if it goes down (I hope It will never happen!!)
 I was looking for exactly the same to help hosting the WP.
@HelloZeroNet : Does this limitation still stand? Would make sense to reopen the issue? I was looking for exactly the same to help hosting the WP.
I've read #598 and https://www.reddit.com/r/zeronet/comments/4lm813/zeronet_website_size_limit/
@HelloZeroNet : Does this limitation still stand? Would make sense to reopen the issue?
Also, is it possible to configure ZeroNet to carry just only one single zite?  i can access to net ï¼Œbut i can not control top router and open it 15441 port, so i can not share my zeronet to web.how to slove it?
 zeronet error like this:
Your network connection is restricted. Please, open 15441 port 
on your router to make your site accessible for everyone.
 1. you don't need to open that port for Zeronet to work. Zeronet will also work ok without it
2. did you do what is said in the FAQ already ? http://zeronet.readthedocs.org/en/latest/faq/#do-i-need-to-have-a-port-opened
 my ip is 192.168.11.41.
so i has config it like this:
UPnPè®¾å¤‡
åè®®  åº”ç”¨åç§°    å®¢æˆ·ç«¯IP å†…éƒ¨ç«¯å£    å¤–éƒ¨ç«¯å£
TCP ZeroNet 192.168.11.41   15441   15441
UDP ZeroNet 192.168.11.41   15441   15441

but it can not work.
the error is following:
Your network connection is restricted. Please, open 15441 port 
on your router to make your site accessible for everyone.
 Mine said the port is closed. What do I do about that?
 There is 2 possible issues, It might your network config that refuse to open the port or it might be your ISP.

You can try to fix the problem of your network if you can, otherwise Tor is your main option to circumvent the imposed limitations.    UiWebsocket.py:440  
assert query.upper().startswith("SELECT"), "Only SELECT query supported"

didn't consider leading spaces. this leads some unnecessary dbQuery error
  Hello, I want to implement more functions ,but I don't known this is possible with dbschema:

for example ZeroBlog, can I add taglist (json array) property to 'post'  object, and map this to another table? or can I recursive map json array to another table inside data.json? can I add sqlite triggers to dbschema.json "indexes" to let zeronet create these custom statement? sqlite currently support json extension and Common Table Expressions(for recursive), did zeronet support this ?  thank you.
  _This is just to formalize what was said on reddit._

The idea is that users can create a site that is a bundle of other sites, with the intention of distributed those sites and reducing the number of connections. I don't think the concept is the same as [Merger sites](https://github.com/HelloZeroNet/ZeroNet/issues/232), but it takes the hub concept presented there and tries to generalize it for all sites instead of just merger sites. In that way also it provides a solution to the con of having _one user per site_ possibly resulting in lots of connections.

So an example would be to look at the six default/sample sites: ZeroBoard, ZeroBlog, ZeroTalk, ZeroMail, ZeroChat, Reaction GIFs. Those sites end up needing 30 connections (5 \* 6). So in this case someone can create the first bundle site that has those sites and let other users know its available. When users connect they will only need 5 connections to the bundle site, and if they are helping sync they would maybe have 5 extra connections for each site they are helping sync. Additionally if a user doesn't want to seed all those sites they can delete the bundle site and simply seed the sites they want instead (an advantage over hubs).

A bundle site can also provide an interface like ZeroPoll that allows users to request and vote on sites to be added or removed, the site owner can then add new sites to the bundle or remove sites.

Syncing could possibly be helped by having it that when a user connects and seeds a bundle, zeronet will automatically connect and seed to a random site in the bundle, that node will then help keep the bundle and site in sync with each other. If a user is already seeding many sites in a bundle those sites can then be deleted except maybe one which will be used to sync.
 It could have a cap of 20 sites or something like that, at least in that way it could potentially reduce connections by 10 times or more. The cap would force people to create bundles and pick bundles that make sense for them.

Bundles would also help seed sites, those who seed a bundle would technically also be seeding the sites in the bundle. So someone who wants to go to a site can either connect to those directly seeding the site or those seeding a bundle that has the site, and they wouldn't (I would think) need to seed the bundle itself.

This might be something particularly useful for proxies as well, since they end up seeding lots of sites, they could reduce their connections by a lot.

> And if the bundle owner decides to remove your site it will also make it unaccessible for the users, because they seeding the bundle site.

It could be too that a user could specify which sites they like in the bundle and if the owner removes the site, ZeroNet will automatically seed the site separately from the bundle. But this will also create another problem where a bundle could remove all sites, and then user ends up now with 10 times more connections. But it could also be that If a bundle only contains one of their sites the bundle is no longer seeded and the last site is seeded independent of it.

Of course another possibility (which maybe harder) is if bundling were automatically handled in zeronet and there is no owner of a bundle, rather zeronet looks for common sites between nodes and creates and matches bundles. When a user adds or removes sites, zeronet will see if there are better matching bundles available.

Actually the whole concept of a bundle may be unnecessary when thinking about zeronet automating this (and maybe zeronet already works this way and I just don't know) but a node could just find another node who seeds a lot of the same sites they seed and that could replace having to have a lot of connections (two or more nodes could split the load of connections).
 > And for privacy reasons the connection sharing is totally disabled on Tor. (new .onion generated for every site you seed)

That would be a benefit to user controlled bundle site over connection sharing, they could get some privacy, much in the same way hubs kind of hide who you are following.

> So think this would require many changes and I think the normal (multiuser), hub sites could work equally well.

Hubs probably allow for a more controlled experiment as well, see how things work.

This issue can probably be closed, unless you want to keep it open for some reason.
  I think Zeronet should update itself from zeronet site because:
1. Some country ban github
2. Zeronet can download file faster then GET request to github (zeronet like good CDN)
3. if github ban zeronet zero users can get updates 
 according to p2p from Chine it is problem http://127.0.0.1:43110/Me.ZeroNetwork.bit/?Profile/1RedkCkVaXuVXrqCMpoXQS29bwaqsuFdL/13Z7XxTa7JuFat3KzzMWu3onwM6biLuurJ/p2p@zeroid.bit

Why not to make new site with zero distr or add zeronet to zero hello ? but zero site with optional files (zeronet dist) is solution  I have problems updating via ZeroUpdate. The ZeroUpdate site did not get updated, so I did not got the latest version. Showing the `rev` number and asking for confirmation can be helpful. This issue is reported to be solved in :  https://github.com/HelloZeroNet/ZeroNet/issues/416   even if the folder get removed it shows up again if zeronet is restarted 
 that should be done when i pick the delete option from the 3 dots menu 
  zero/blog/mail/talk does not work by itself it require a dns service, this is clearly a design flaw .bit should be optional not enforced  
 you can open each ZeroNet site with its address, no need for .bit

(more about .bit mapping: done onto this very ZN address, by ZeroName)
 did you test it ? clicking zeromail from 1HeLLo give a error
 i said clicking from 1HeLLo
 why ? the rest of the sites are saved correctly but on zeromail the address is changed, why is the zeromail address overwritten ? i the user never requested to be overwritten 
 is a obvious flaw / bug then
 @icf20 In ZeroMail he sets the `"domain": "Mail.ZeroNetwork.bit"` in `content.json`, which is what is causing ZeroHello to point to the .bit domain, and not to the address directly
 @TheNain38 
if i seed and favourite http://127.0.0.1:43110/1MaiL5gfBM1cyb4a8e3iiL8L5gXmoAJu27 i want http://127.0.0.1:43110/1MaiL5gfBM1cyb4a8e3iiL8L5gXmoAJu27 to be saved on the 1Hello not to be overwritten to Mail.ZeroNetwork.bit because i never went to Mail.ZeroNetwork.bit and never decided to favourite that address 
 Then you can't with the current design, because the site owner added `"domain": "Mail.ZeroNetwork.bit"` in his `content.json` file
 zeronet cant overwrite user decision, by RMS definitions only crapware/spyware does that  
 {
 "address": "1MaiL5gfBM1cyb4a8e3iiL8L5gXmoAJu27",
 "background-color": "#FFF",
 "cloneable": true,
 "description": "End-to-end encrypted messaging",
 "domain": "",
 "files": {

still not respected on 1Hello, 1hello still points to .bit domain 
 so why is not http://127.0.0.1:43110/1MaiL5gfBM1cyb4a8e3iiL8L5gXmoAJu27 saved in 1Hello correctly ?
 @HelloZeroNet You could add an option on ZeroHello to not link using the .bit domain, but to link directly to sites, and if the .bit now resolve to something new, you could add something like: "... is now at ... do you want to update the address?"
 why u dint say that in the first place ? :D 
 @icf20 Btw, if you want to contact me, you can send me a ZeroMail at `thekill38`
  When i try to enable Tor for every connection, i got this error

how can i manally edit and enable this option
 @HelloZeroNet I install zeronet from AUR on archlinux.. so have to manually edit this file  and   succeed.. thx
  As per yesterday's IRC conversation. Since larger than 1MB files are not supported yet on ZeroNet, made a change for dash.js to work with ZeroNet's IFRAME. Otherwise the browser does not allow reading the video segment files.
 So, to be clear here, @HelloZeroNet (BTW, I work with @frerepoulet ). You do understand that the iframe blocking ZeroNet site access to Window.localStorage (required by both HLS and DASH), combined with the ZeroNet file size restriction effectively ban video content of any reasonable quality on your network ? Don't you feel compelled to provide alternative ideas at all ?
 If you would allow us to extend the ZeroFrame API with some kind of Window.localStorage emulation, then I'd be more than happy to fork dash.js to allow it to work with zeronet. I think we would also need to extend UiServer.fileGet for proper progress tracking and be able to display minimal loading status UI. But I would need some kind of reassurance that provided with good enough code you will make those changes to be default and not disabled optional plugins, if the changes are not made available to all users, they are pointless.
 OK, great I didn't see that. Will try it and see. Do you already have a precise idea of the other sandboxing issues we should expect (given that with "allow-same-origin", it works) ?
 it might be required (btw, we are looking at Media Source Extensions for both DASH and HLS right now and not WebRTC) but it doesn't seem to be enabled by allow-same-origin which is the only flag we added
 also, what do you feel about extending fileGet (or such) for download progress tracking ? or is there already something to that effect in place ?
 yes ok but: 1) they should and 2) we are having all sorts of issues with files >100KB  just as well so, if this can't be fixed at a lower level soon enough, something needs to be done for better I/O error reporting and progress UI

anyways, we'll see if we can have DASH work without allow-same-origin and be back on I/O UI later
 just to confirm: data uris are indeed disabled by the iframe sandboxing and indeed break dash and hls... looks like zeronet will not work for our purpose but thank you for your cooperation in the matter
  I need proxy to access the ipv4 part of the Internet, but cannot find configuration file of zeronet to set front proxy

or can it work with pure ipv6?
  hello:
 my i Hope to have the mobile version
 the seceond solution seems unsafe, or you need to set a passwd for the server i guess
 in my opinion this is a huge privacy risk because GPS 
 Can you explain what you mean by GPS being a privacy risk?
 > Can you explain what you mean by GPS being a privacy risk?

if i remember correctly chrome browser track your location 
 Simple solution, don't use chrome if what @icf20 said is right, ever way, Google is tracking you all the time, it wouldn't surprise me that they track you through chrome
 on that topic is a bit more complex, for example google play services ask for gps, cell data(tower cell), wifi data, general location every 40-60 seconds
the normal default browser ask for general location, contacts, call log, and  calendar  only when is open
by default the google activates (settings -> google) tracking for web and apps, device etc if you block the access to all that using privacy guard([CM 12](http://www.androidcentral.com/cyanogen-os-privacy-guard-keeping-apps-seeing-your-data)) then google does not know what webs you view and your location
so if google can read all that data can read what you do on zeronet and on what places you open/view zeronet 
 @icf20 You can use firefox. But to have a native app would be nice. @ShenXuGongZi There is an android version available https://github.com/HelloZeroNet/ZeroNet-kivy/releases
Google Play: https://play.google.com/store/apps/details?id=net.mkg20001.zeronet
F-Droid comming soon @HelloZeroNet Can we close this?  lets be honest nobody see the more option, ZeroTalk first time activation should show several "huge" country flags so users can pick what forums they want.
1. spain flag https://en.wikipedia.org/wiki/File:Flag_of_Spain.svg
2. chinese https://en.wikipedia.org/wiki/Flag_of_China#/media/File:Flag_of_the_People%27s_Republic_of_China.svg
3. poland https://en.wikipedia.org/wiki/Flag_of_Poland#/media/File:Flag_of_Poland.svg
4. france https://en.wikipedia.org/wiki/Flag_of_France#/media/File:Flag_of_France.svg
5. russian https://en.wikipedia.org/wiki/Flag_of_Russia#/media/File:Flag_of_Russia.svg
6. portugal https://en.wikipedia.org/wiki/Flag_of_Portugal#/media/File:Flag_of_Portugal.svg
  I mentioned in Issue #415 that I wanted to share Lantern on my ZeroNet site to help fight censorship. However, someone pointed out at a glaring flaw in my thinking: they would need to be able to download ZeroNet, which is on Github, which is blocked by China. In essence, China has blocked access to ZeroNet and thus blocked people from downloading Lantern from me. Doh!

The problem? The ZeroNet installer is provided in a centralized way. This could be addressed by having an automated system that creates a torrent of the latest version of ZeroNet and then publishes that torrent to various torrenting websites. You can check whether a torrenting website (or any website, really) has been blocked by China by using this website: http://www.blockedinchina.net/. I have already checked http://kat.cr and it was not blocked.
 you can use https://en.greatfire.org/https/github.com to see if is blocked or not 
 Prior to this we would need @nofish to sign releases. Then copy could be shared accross zeronet by zeronet site owner and validated aganst key. 

As soon As we will have this, I would be available to contribute time to create a zeronet site with all the releases .zip Oh, cool. 

So everything concerning this issue have been done/solvec already ?   I just downloaded the Lantern installers (https://getlantern.org) to make them available on ZeroNet. I added them to my ZeroNet site (17EcoSLuGdJKWrKnBDN1qVsyxN2dZqtJQL), signed, and published. I checked whether everything was working, but it wasn't. Clicking on one of my ZeroNet links to download an installer (any installer), my browser shows me this error message:

> Server error
> 
> Err: AttributeError: 'bool' object has no attribute 'needFile' in UiServer.py line 81 > UiRequest.py line 82 > UiRequest.py line 190 > UiRequestPlugin.py line 22 > UiRequest.py line 352
> 
> Please report it if you think this an error.
> 
> Details:
> 
> {
>     "GATEWAY_INTERFACE": "CGI/1.1", 
>     "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,_/_;q=0.8", 
>     "HTTP_ACCEPT_ENCODING": "gzip, deflate, sdch", 
>     "HTTP_ACCEPT_LANGUAGE": "en-US,en;q=0.8,fr;q=0.6", 
>     "HTTP_CONNECTION": "keep-alive", 
>     "HTTP_DNT": "1", 
>     "HTTP_HOST": "127.0.0.1:43110", 
>     "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
>     "HTTP_USER_AGENT": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/49.0.2623.108 Chrome/49.0.2623.108 Safari/537.36", 
>     "PATH_INFO": "/downloads/lantern/lantern-installer-beta.apk", 
>     "QUERY_STRING": "", 
>     "REMOTE_ADDR": "127.0.0.1", 
>     "REMOTE_PORT": "58247", 
>     "REQUEST_METHOD": "GET", 
>     "SCRIPT_NAME": "", 
>     "SERVER_NAME": "localhost", 
>     "SERVER_PORT": "43110", 
>     "SERVER_PROTOCOL": "HTTP/1.1", 
>     "SERVER_SOFTWARE": "gevent/1.0 Python/2.7", 
>     "arguments": {
>         "action": "main", 
>         "batch": false, 
>         "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
>         "coffeescript_compiler": null, 
>         "config_file": "zeronet.conf", 
>         "connected_limit": 15, 
>         "data_dir": "data", 
>         "debug": false, 
>         "debug_gevent": false, 
>         "debug_socket": false, 
>         "disable_db": false, 
>         "disable_encryption": false, 
>         "disable_sslcompression": true, 
>         "disable_udp": false, 
>         "fileserver_ip": "*", 
>         "fileserver_port": 15441, 
>         "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
>         "ip_external": null, 
>         "keep_ssl_cert": false, 
>         "log_dir": "log", 
>         "max_files_opened": 2048, 
>         "msgpack_purepython": true, 
>         "open_browser": null, 
>         "proxy": null, 
>         "size_limit": 10, 
>         "stream_downloads": false, 
>         "tor": "enable", 
>         "tor_controller": "127.0.0.1:9051", 
>         "tor_proxy": "127.0.0.1:9050", 
>         "trackers": [
>             "zero://boot3rdez4rzn36x.onion:15441", 
>             "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
>             "udp://tracker.coppersurfer.tk:6969", 
>             "udp://tracker.leechers-paradise.org:6969", 
>             "udp://9.rarbg.com:2710", 
>             "http://tracker.aletorrenty.pl:2710/announce", 
>             "http://explodie.org:6969/announce", 
>             "http://torrent.gresille.org/announce"
>         ], 
>         "trackers_file": false, 
>         "ui_ip": "127.0.0.1", 
>         "ui_port": 43110, 
>         "ui_restrict": false, 
>         "use_openssl": true, 
>         "use_tempfiles": false, 
>         "verbose": false
>     }, 
>     "plugins": [
>         "Sidebar", 
>         "Newsfeed", 
>         "Trayicon", 
>         "Stats", 
>         "CryptMessage", 
>         "Zeroname", 
>         "AnnounceZero"
>     ], 
>     "version_gevent": "1.0", 
>     "version_python": "2.7.6 (default, Jun 22 2015, 17:58:13) \n[GCC 4.8.2]", 
>     "version_zeronet": "0.3.7 r1210", 
>     "wsgi.url_scheme": "http"
> }
 I was afraid of that. The directory and files exist. No errors on signing. (PS: documentation should be added about when the site is too big and you need to ignore files. I figured it out eventually, but that was annoying.) Unfortunately, I have had trouble opening port 15441. I have tried port forwarding, turning off the router firewall, putting my computer in DMZ mode, and turning off traffic shaping, but zeronet.py still says that the port is closed when I start up ZeroNet. This has been quite irritating :P
 I just learned something. I made my hyperlink wrong. I wrote `<a href='/downloads/...'>` instead of `<a href='17EcoSLuGdJKWrKnBDN1qVsyxN2dZqtJQL/downloads/...'>`. Once I fixed that, I no longer got the error message, so the error message is basically saying that the link is invalid. I think it would help to get rid of this ugly error message and replace it with a more friendly 404 File Not Found page. (Sure, you do not use HTTP and thus HTTP error codes, but you know what I mean.)
  @HelloZeroNet.   @HelloZeroNet No, it handles non-null reponse errors
  It appears that the 'aesEncrypt' and 'aesDecrypt' commands do unauthenticated encryption. This is very bad for security. See the code below that clearly demonstrates the problem.

These commands are used by ZeroMail in an insecure fashion, that could in theory make it possible for an attacker to decrypt messages. But I think this would be very hard to accomplish in practice. Nevertheless, this should definitely be fixed.

The actual problem is [here](https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/CryptMessage/CryptMessagePlugin.py#L105), where the unauthenticated ciphertext is decrypted.

The easiest way to fix this is to add a MAC. I would recommend HMAC-SHA256 as that is already used in ZeroNet. The key for the mac could either be provided separately, or both the aes key and the mac key could be derived from a single key using HKDF or another secure algorithm.

```
msg = 'abcdefghijklmno'
console.log(msg)
@cmd 'aesEncrypt', [msg], (res) =>               # Encrypt message
    key = res[0]
    iv = res[1]
    enc = res[2]
    console.log(key, iv, enc)
    iv = 'a'+iv.substr(1)                        # Modify the IV
    console.log(key, iv, enc)
    @cmd 'aesDecrypt', [iv, enc, key], (res2) => # This should not decrypt
        console.log (res2)                       # But it does about 50% of the time
```
 It think ZeroMail tries to decrypt messages with all its AES keys (not just the one associated with the sender). So I can't see how this would help. 
 @HelloZeroNet I was able to successfully forge a ZeroMail:
- Alice: mail_data_from_Alice -> Bob
- Eve: mail_data_from_Alice -> Bob
- "Bob" successfuly decrypted a mail from "Eve" with the same content as the mail from "Alice"
 @HelloZeroNet Then, what does this attack uses? http://blog.cryptographyengineering.com/2016/03/attack-of-week-apple-imessage.html
The fact that there isn't any HMAC, and it's bad for security to not have any HMAC because you can forge messages
 @HelloZeroNet I looked more into the code of ZeroMail, and doing that is not sufficient. The attacker can just send the same AES key as the real sender.

And even if ZeroMail is made secure, other people may still assume that they can safely pass untrusted data into 'aesDecrypt'. So the real solution is to create new secure commands, and then remove the old 'aesEncrypt/Decrypt'.

@TheNain38 It is definitely a problem that you were able to do that, and I wasn't aware that was possible. Adding an HMAC will in itself not be sufficient, to fix that. Some more changes will be required. 
 @mirrorwish If you use a nonce and an HMAC, it should be good to prevent this attack, right?
 @TheNain38 Assuming that the nonce is placed under the HMAC, and that the recipient checks that this nonce was not previously received, then I believe it would be.

But this is still not sufficient to prevent your attack. If Eve manages to get her message to Bob before Alice's message arrives, then bob will think that the message from Eve is the real one and will reject the one from Alice.
 @mirrorwish Could we talk using another communication platform? Like Tox, or something else? I have an idea to make this work without requiring a nonce
 @TheNain38  You can contact me at
Bitmessage: BM-87ZQse4Ta4MLM9EKmfVUFA4jJUms1Fwnxws
ZeroMail: ichigo (I haven't really used this so I'm not sure if it works)
 @mirrorwish
This, is my address, so you can verify it's really me: BM-2cSj4rVtxERWT75V1svyYV3Ju63KNQZPvz
ZeroMail: thekill38
 Probably, but I'm not completely sure. And why make it so complicated when you can solve it by simply adding an HMAC?
 Oh I think I misunderstood.

Yes, adding the sender and only decrypting with the right keys should solve the problems with copying messages.

You seem a bit cautios about adding a MAC, and I don't really understand why, as I see no downsides.
 @HelloZeroNet It's a [replay attack](https://en.wikipedia.org/wiki/Replay_attack)
 SK: Signing Key
PK: Public Key

To encrypt a mail:
- Alice computes a shared secret using her cert's SK, and the PK from Bob's cert and she uses this secret to AES encrypt the message as you already do

To decrypt a mail:
- Bob computes the shared secret using his cert's SK and the PK from Alice's cert, and try to AES decrypt all the messages Alice sent, and when decryption works, it was a mail for him

It's secure against replay attack as it uses the sender's address to compute the shared secret, and then uses it to encrypt and decrypt mails

This method also prevents someone to know when you started mailing to someone new

**I would like to know if doing this is secure**
 @HelloZeroNet It's a **shared secret**, look at this image:
![Shared secret](https://upload.wikimedia.org/wikipedia/commons/4/4c/Public_key_shared_secret.svg)
 @HelloZeroNet You won't need the `secrets_sent` and the `secret` part in your `data.json` anymore
 > Much larger messages

Probably about 60-70 bytes more. Not really that much.

> Around 100x slower than AES

This is true if you blindly use ECIES, but the solution proposed by TheNain38 can do a lot of precomputations, and should be of comparable performance to the current implementation.

> You would have to try to decrypt every message (currently don't decrypt unknown user's messages)

That is true.

> If we want to have sent folder, then we have store the messages twice

Or just store the ephemeral key (32 bytes). This would actually be an improvement as you can make messages unreadable for yourself but still readable for the recipient. But note that this is not even required with the proposed solution.

But I'm not totally convinced the proposed solution is secure, as the same private key is used with ECIES for encryption to multiple recipients. Normally you would use a new key for each message. Do you happen to know what it's called?
 This does not seem like being a general problem with 'aesEncrypt' and 'aesDecrypt'. Authentification would be overkill when you use permalinks and disposable keys, since others canâ€™t modify the data.json.

Because removal of those functions was proposedâ€¦
 @basxto I assume you are mainly referring to PastePr.

The reason I'm proposing to remove it, is that many people don't understand the security implications of using unauthenticated AES. Normally AES is very fast (with or without authentication) so it should not be a bottleneck, in nearly all cases. But if it really is a bottleneck in PastePr or some other application, it think it's fine to keep it but just add a warning.

I don't know yet if your usage of 'aesEncrypt/Decrypt' in PastePr is secure, but I will look into it, and give my judgment.
 @basxto PastePr is likely vulnerable to the same vulnerability I reported here, and I think it would be easier to attack PastePr than ZeroMail. So I really think you should use authenticated encryption.

But there is a much more serious problem, that makes the encryption totally broken: PastePr uses the same IV twice. [See here](https://github.com/basxto/PastePr/blob/master/js/paste.coffee#L90-L95). **Edited** I first thought this would make it very easy to decrypt part of the paste, however it's a bit more complicated than that as you were luckily using CBC mode. But using the same iv twice is still very bad.

If you need any help to solve either of these problems, feel free to contact me.
  I believe that ZeroHello "favorited" sites are stored in cookies. (I haven't checked, but I noticed they disappear after cookies get cleared).
How about having a specific flag (or taxonomy / tags) in the sites.json entries?
That would add resilience to cookie removal and consistency between different browsers as a minimum.
 agreed
 I moved the issue to zerohello repository. Closing ?   I got the msg the its not running under classic, but i use OSX 10.9.5
  If I have an up-to-date namecoin blockchain and with a local Namecoind service running, I would like ZeroNet to use its JSON RPC API instead of ZeroName for .bit domain name resolution.

If it has any chance of being pulled back for the next release I would like to submit a patch. Please let me know if there is interest.
 OK, thanks. That's not what I meant and it was not functional when I tried it but I talked to the author ( @TheNain38 ) and he said he would fix it and try to implement the functionality I was referring to : that if a local instance of namecoind is running, to automatically switch to resolving .bit domains with it instead of relying on ZeroName. Can we leave this open until it is confirmed to work and turned on by default in a release or something ? Thanks.
 It's not stable, I agree. But, it does affect the overall perception that ZeroNet does not try very hard to be truly decentralized by forcing you to trust ZeroName, by _default_. Leaving this issue open shows that, well, it's a _known_ issue, at least.
 i hear you and i agree but I think this should remain a ZeroNet open issue and recognized as such
 Hi @HelloZeroNet,

FYI the decentralized SPV client that @cassiniNMC talked to you about at GETD#4 is [released in beta](https://namecoin.org/2016/10/23/lightweight-spv-lookups-beta.html).  The mode that Cassini discussed with you is `leveldbtxcache`.

The main reason it's classified as "beta" is that not many people have used it in production, so we just don't have a strong basis for knowing if there are any issues -- maybe that's where you can come in?

Cheers!  Imo there should be a option to donate to a site owned that want to use another address that the current site address or because it uses a .bit and the bitcoin address is not easily available.

what  do you think about a button on top next to the 0 or in the site preferences ?
  Since using JS it would be too slow, and an attacker could always make native code to spam a site and compute a POW much faster than people generate them using JS. And it would allow to have one "right" implementation, instead of having multiple implementations, some which could even be failing to do their job correctly, it would provide a `generatePOW` with a difficulty parameter, and a `verifyPOW` API commands. It could be added to ZeroMail and to ZeroTalk, it would make spamming much harder.
 _use proof of bitcoin balance_ to put down spam 
 @icf20 The problem with that is not many people have Bitcoin. Zeronet is very noob friendly so you should not expect many people using it to have Bitcoin or even know how to get it. Also a spammer could have a Bitcoin balance and once it has been detected as spamming they could just launder their Bitcoins and spam again.
 @AceLewis it's not a problem for anyone except for people who do not have Bitcoin. They can get bitcoin if they want. 
It's a small price to pay - pun intended - for the rest of us who prefer not to deal with spam.
 Bitcoin are illegal in some country. That's a akward thing to request at core zeronet level. And then, why bitcoin over the others +9000 cryptocurrency ?

Spam problems are site specific and should be mitigated by site owners IMO.
Plugin could be created if multiple site owners want to unify a solution to their common problems.
It should not be addressed at core level IMHO. I think pow could partly fix the problem.
Because if sending one ZeroMail requires 10secs of gpu computing then even with a very fast gpu that still would be 1sec. So sending 1 million spam mails would requires 1 million seconds of time.
Also it requires energy to run a gpu. So it's more like mining bitcoin just with a negative roi. Scammers will buy GPU if it pay off. It all depend on the ROI of the phishing campain. 

What is 10 sec for the average users can 1:30 for a poor guy in 3rd world. It raise the question is equal accessibility is a goal of zeronet? 

And agan, should it be part of the core or it should be an independant javascript library that site owner can use if they want ? AFAIK, nothing ATM is preventing someone to write some javascript code that can solve this problem. It should be a plugin for the core.
We could also use existing libs for pow to make it as efficient as possible (to prevent scammers having an advantage if they use native code, etc.)

> What is 10 sec for the average users can 1:30 for a poor guy in 3rd world. It raise the question is equal accessibility is a goal of zeronet?

We could adjust pow to a value that everybody is fine with but still makes spamming harder. (At a scale of about 1 million emails even a small pow increase makes it significantly harder) > We could adjust pow to a value that everybody is fine with but still makes spamming harder. 

No you cannot, as already explained above. "Harder" is a non factor for the spammer. The cost of generating accounts will always be lower than the utility of spam accounts so ultimately you'd just make it harder to get on the network for normal users.

Instead a plugin model should be used so that users use whatever way they prefer to blacklist or whitelist other users.    **Linux terminal

wget https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-linux64-v0.1.1.tar.gz

It downloads the latest version of ZeroNet then starts it automatically.**

Is this surely the latest version ?
 It is, yes. The bundle scripts simply call the updater, which gets the latest version from GitHub.
 why not use the same version numbers, to make it easy to detect that, please? :)

or name the package something like "latest"?
  I'm on a public access point ([eduroam](https://www.eduroam.org/)), and I can't start the ZeroBundle. I'm running on updated ubuntu 14.04LTS.

```
./ZeroNet.sh --tor always --ip_external 127.0.0.1 --verbose
- Starting ZeroNet...
[18:04:44] - OpenSSL loaded, version: 01000207F
[18:04:44] - Patching sockets to tor socks proxy: 127.0.0.1:9050
[18:04:44] - Version: 0.3.6 r1089, Python 2.7.11 |Continuum Analytics, Inc.| (default, Dec  6 2015, 18:08:32) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)], Gevent: 1.0.2
[18:04:44] - Creating FileServer....
[18:04:44] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 154 > socket.py line 344
[18:04:44] - Creating UiServer....
[18:04:44] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[18:04:44] - Removing old SSL certs...
[18:04:44] - Starting servers....
[18:04:44] Ui.UiServer --------------------------------------
[18:04:44] Ui.UiServer Web interface: http://127.0.0.1:43110/
[18:04:44] Ui.UiServer --------------------------------------
[18:04:44] - Opening browser: default_browser...
[18:04:44] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[18:04:44] Site:1Name2..hM9F Announce to 0 trackers in 0.068s, failed
[18:04:44] Site:1HeLLo..Tf3D Content.json not exist: data/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/content.json
Created new window in existing browser session.
[18:04:44] Site:1HeLLo..Tf3D Announce to 0 trackers in 0.047s, failed
    [18:05:14] Site:1HeLLo..Tf3D Announce to 0 trackers in 0.044s, failed
[18:05:29] Site:1Name2..hM9F Announce to 0 trackers in 0.030s, failed
[18:05:44] FileServer Internet offline
[18:05:44] Site:1HeLLo..Tf3D Content.json not exist: data/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/content.json
[18:05:44] Site:1HeLLo..Tf3D Announce to 0 trackers in 0.034s, failed
[18:05:59] Site:1Name2..hM9F Announce to 0 trackers in 0.049s, failed
```

I previously tried without _ip_external_, and also without _tor always_. This is the first time I start ZeroNet on this setup and network, but I won't be able to test further on this network. TorBrowser works well, so ZeroNet should work through tor.
 Connected on unfiltered network without any problem. 
 Thanks. Maybe there should be a link to how to steps on the download page for Linux.
  Got an error while pressing back button, these are the details: 

```
{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate", 
    "HTTP_ACCEPT_LANGUAGE": "en-US,en;q=0.5", 
    "HTTP_CONNECTION": "keep-alive", 
    "HTTP_DNT": "1", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_REFERER": "http://127.0.0.1:43110/12CVHBbLwwYjgYtjpWmempoyZN7xWXJN8j/", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:45.0) Gecko/20100101 Firefox/45.0", 
    "PATH_INFO": "/12CVHBbLwwYjgYtjpWmempoyZN7xWXJN8j/", 
    "QUERY_STRING": "wrapper_nonce=7b91c27606d89595d7f04867107707ce7500b15d611742eefad19edf7b769398", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "56084", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "localhost", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.1 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "coffeescript_compiler": null, 
        "config_file": "zeronet.conf", 
        "connected_limit": 15, 
        "data_dir": "data", 
        "debug": false, 
        "debug_socket": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "keep_ssl_cert": false, 
        "log_dir": "log", 
        "max_files_opened": 1024, 
        "msgpack_purepython": true, 
        "open_browser": "default_browser", 
        "proxy": null, 
        "size_limit": 10, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.aletorrenty.pl:2710/announce", 
            "http://explodie.org:6969/announce", 
            "http://torrent.gresille.org/announce"
        ], 
        "trackers_file": false, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false
    }, 
    "plugins": [
        "CryptMessage", 
        "Stats", 
        "Zeroname", 
        "Newsfeed", 
        "AnnounceZero", 
        "Trayicon", 
        "Sidebar"
    ], 
    "version_gevent": "1.1b1", 
    "version_python": "2.7.10 (default, Oct 14 2015, 16:09:02) \n[GCC 5.2.1 20151010]", 
    "version_zeronet": "0.3.6 r948", 
    "wsgi.url_scheme": "http"
}
```
 I have the same issue when going from: site/index.html to another: site/file.html
 @mindaslab  have you tried the use of use target=_top as suggested  ? 
Did the problem remain ? I'm running into same issue, it can be reproduced in http://127.0.0.1:43110/tcmtest.bit
1. click page1
2. click page2.
3. click back twice

I'm using target="_top"

Forbidden
Wrapper nonce error. Please reload the page.
Please report it if you think this an error.

Details:

{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate, br", 
    "HTTP_ACCEPT_LANGUAGE": "zh-CN,zh;q=0.8,en-US;q=0.6,en;q=0.4", 
    "HTTP_CONNECTION": "keep-alive", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_REFERER": "http://127.0.0.1:43110/tcmtest.bit/page1.html", 
    "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36", 
    "PATH_INFO": "/tcmtest.bit/page1.html", 
    "QUERY_STRING": "wrapper_nonce=be6e3ce3439d904f6b747c8b322de8399ed60cbd700846dcb486879e759f3c0f", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "56615", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "xxxxxxxxxxx", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.2 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bind": null, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": null, 
        "config_file": "zeronet.conf", 
        "connected_limit": 8, 
        "data_dir": "data", 
        "db_mode": "speed", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "end": true, 
        "file_size_limit": 10, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "fix_float_decimals": false, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "ip_local": [
            "127.0.0.1"
        ], 
        "keep_ssl_cert": false, 
        "language": "zh-tw", 
        "log_dir": "log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": true, 
        "open_browser": null, 
        "optional_limit": "10%", 
        "proxy": null, 
        "silent": false, 
        "size_limit": 10, 
        "stack_size": null, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_hs_limit": 10, 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.opentrackr.org:1337/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_host": null, 
        "ui_ip": "0.0.0.0", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "updatesite": "1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp", 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false, 
        "workers": 5
    }, 
    "plugins": [
        "AnnounceZero", 
        "CryptMessage", 
        "FilePack", 
        "MergerSite", 
        "Mute", 
        "Newsfeed", 
        "OptionalManager", 
        "PeerDb", 
        "Sidebar", 
        "Stats", 
        "TranslateSite", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.2.2", 
    "version_python": "2.7.13 (default, Dec 31 2016, 23:24:31) \n[GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)]", 
    "version_zeronet": "0.5.6 r2128", 
    "wsgi.url_scheme": "http"  I think it would be cool to have the diff file gziped before sending.

Em qua, 6 de abr de 2016 Ã s 19:51, ZeroNet notifications@github.com
escreveu:

> Done in rev1200
> 
> â€”
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly or view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/issues/395#issuecomment-206603253
 Although in the case where the diff is encrypted it would make sense to compress it before encryption.
 It looks like CRIME depends on observing multiple ciphertexts. 
In basically any ZeroNet design I can think of, there is only going to be one ciphertext per patch - I can't see a mechanism for an attacker to force the site owner to inject his extra content and repeatedly patch the site?
  python2 instead of python
 > #!/usr/bin/env python always should point to python2

No it doesn't. This is why it doesn't work on my linux.

>  $>  /usr/bin/env python --version
> 
> Python 3.5.1

Furthermore, I will quote your source : 

> #!/usr/bin/env python Usually defaults to python 2.7.latest, ...
> ... python should be used in the shebang line only for scripts that are source compatible with both Python 2 and 3.

Your stackoverflow source is about to choose between /usr/bin/env and /usr/local/bin. And usually != always.

Maybe you should just respect the standard and let the osx issues to osx.
 see: http://127.0.0.1:43110/1MyPktAWvYQQiLBNuApBZKUL2xNqQmAE6D/?Post:6
 I moved my old `master` branch to `patch-shebang`, i will reopen a new merge request later.

There is an issue on OSX (no python2 executable).

As OSX has not the standard python2 executable, OSX users should install a virtual env.

see: http://stackoverflow.com/questions/3713097/upgrading-python-in-virtual-env (or other stuff like that, I do not use them as I have a standard configuration)
 Tested on OSX. It seems that OSX has
- python
- python2.7
- python3.3
- python3

but not python2.

Waiting for you reply.
 rebased
  I'm not sure what discussions have already happened about using names other than .bit, but if you put the site address in the TXT record that would allow public internet domain owners to point to a ZeroNet site.

Any thoughts?
 Hmm - so yes, the entry point/discovery is censorable, but the actual content is not.

If I had a domain, and some ZeroNet content, and my domain was seized or whatever, the ZeroNet content would remain, and still be distributed and updatable.

If users could now reference it via its ZeroNet address then I can continue to maintain and use the ZeroNet content, right? In a sense, it's almost counter-censorship, because it can't be taken down by seizing the domain. Isn't that worth having?
 What do you mean by updates? 

Do you mean, what if the seized domain gained a new ZeroNet address pointing at something else? That would be bad yeah, and hard to handle too.
 Another problem is that it does a request to a DNS server, and it isn't secure, so someone could temper with it and redirect your users to another address
 That's true, but you could limit it to DNSSEC roots to eliminate that.

Doesn't deal with the earlier issues though - I can see it has problems.
 Closing ?     I'm wondering if there would be a method in which Zeronet would allow users to set up a self-moderating "user muting" list.

This would prevent any type of censorship but individuals could HIDE posts/content made by specific ZeroID individuals. And since the user muting list would remain on individual's localhost it would only mute for that specific user.
 could be part of the "universal admin interface" https://github.com/HelloZeroNet/ZeroNet/issues/354
 @HelloZeroNet I find the first idea better than the second, because it allows users to hide all the content that comes from a certain cert
 its better to let users decide what their want to see and don't want to see. It could be even better if they have the option not to seed what the don't want from a user but i think merger issue should solve this kind of stuff
 Will this include optional files, such as images? Would be nice to mute people who show illegal content and have it wipe anything I'm sharing extra too. For instance, to view an option on ZeroMe you have to download it which I think also distributes it.

Sharing of mute lists would be good too. ~~@HelloZeroNet I don't understand how to use the Mute plugin, as a user. It seems almost like you implemented it for admin of zites? I am not sure I understand, but essentially: how do I mute users now that 2cea157 is done?~~

Nervermind - I figured it out. From the TopicList view, you can use the three dots menu to mute a user. There isn't something similar from the TopicShow view.   It only looks at directories, in which files are deleted
 @HelloZeroNet Now, it only tries once to list and delete the folder
 @HelloZeroNet Done!
 @HelloZeroNet I though of one thing that could be better, that is to only list and delete the leaf directories, that is, for example: if it is deleting files in "foo", "foo/bar and " foo/bar2", then it would only try to delete the deepest ones, that is, "foo/bar" and "foo/bar2" as I'm using `os.removedirs`, it tries to remove the directories recursively.
 @HelloZeroNet Done! (For real this time, and it's also fully tested with multiple cases, and it only deletes what's necessary, and also what "should" be empty according to the differences between the old and new `content.json`)
   Actually, you can play with more RPC parameters in `~/.namecoin/namecoin.conf`:

```
  -rpcconnect=<ip>
       Send commands to node running on <ip> (default: 127.0.0.1)

  -rpcport=<port>
       Connect to JSON-RPC on <port> (default: 8336 or testnet: 18336)

  -rpcwait
       Wait for RPC server to start

  -rpcuser=<user>
       Username for JSON-RPC connections

  -rpcpassword=<pw>
       Password for JSON-RPC connections

  -rpcclienttimeout=<n>
       Timeout during HTTP requests (default: 900)
```

so perhaps it would be prudent to take all of them into consideration, e.g., something like this:

``` python
def init_rpc(config):
    """Initialize Namecoin RPC"""
    rpcdata = {
        'config': config,
        'connect': '127.0.0.1',
        'port': '8336',
        'user': 'PLACEHOLDER',
        'password': 'PLACEHOLDER'
        'clienttimeout': '900',
    }
    try:
        from bitcoinrpc.authproxy import AuthServiceProxy
        fptr = open(rpcdata['config'], 'r')
        lines = fptr.readlines()
        fptr.close()
    except:
        return None  # Or take some other appropriate action

    for line in lines:
        if not line.startswith('rpc'):
            continue
        keyval = line.split(None, 1)[0]
        (key, val) = keyval.split('=', 1)
        if not key or not val:
            continue
        rpcdata[key[3:]] = val

    url = 'http://%(user)s:%(password)s@%(connect)s:%(port)s' % rpcdata

    return AuthServiceProxy(url, timeout=int(rpcdata['clienttimeout']))
```

Cheers!
 @kseistrup Thanks!
 Please note that I haven't tested the actual code, it was just taken from off top of my head. Specifically, I'm used to coding in Python 3, and I'm unsure if the example above will run without errors. I did try to avoid `with open(config, 'r') as fptr:` because I can't remember when the with-statement was introduced. Also, I'm unsure if there was a `.startswith()` method on string objects in Python 2. But such things should be easy to spot for people who are used to Python 2.
 I tested the code that is in domainLookup.py, and it works, also I did not take your code directly, I modified it a little bit
 Cool! :+1: 
 @HelloZeroNet Done
  I wonder if we have the same issue as early Bitcoin-core days where people steal the wallet.dat because of plain text. 
Should ZN have an encryption mechanism of the user.json and sites.json?
Here is a pywallet encryption function that could be easily inserted into ZN.
https://github.com/jackjack-jj/pywallet/blob/master/pywallet.py#L447
 @HelloZeroNet It's still a threat, because the attacker will be able to decrypt all your ZeroMails and post under your certs
 Encrypting ZeroNet user secrets seems a sane thing to do, and would protect the secrets from machines being compromised (you would need to crack the secret used for the encryption of the data).

**But** this comes at a cost: users would then need to enter the passphrase when starting ZeroNet: not sure we want to go that way.
 @almet 

> But this comes at a cost: users would then need to enter the passphrase when starting ZeroNet: not sure we want to go that way.

was wondering why isn't this already that way.. we do enter passphrase to decrypt private key when using gpg.
 give users a choice, why not?  for most paranoid ones, let them use passphrase.
 @almet @5hanth @ratijas Maybe the encrypted users.json feature can be implemented as a plugin, similar to the web ui password plugin.   I'm following the [site tutorial](http://127.0.0.1:43110/Blog.ZeroNetwork.bit/?Post:43:ZeroNet+site+development+tutorial+1), and I'm getting the above error at the last stage (before publishing).

Win 10, latest FF. I've tried in a fresh profile without any extensions. Seeing #306, I have tried disabling antivirus/antimalware - no effect.

Firefox console:

```
The connection to ws://127.0.0.1:43110/Websocket?wrapper_key=f034d74605321b02f027fadcc152eec7afe8804c2e62c215d6afda80797ff2c8 was interrupted while the page was loading. all.js:40:16
[ZeroWebsocket] Closed close { target: WebSocket, isTrusted: true, wasClean: true, code: 1001, reason: "", currentTarget: WebSocket, eventPhase: 2, bubbles: false, cancelable: false, defaultPrevented: false, timeStamp: 1458488860822000 } all.js:106:14
GET 
http://127.0.0.1:43110/1H1Ee3oP5tVZqz5kmQVqqfXjFUDx8kAinN/ [HTTP/1.1 200 OK 1ms]
GET 
http://127.0.0.1:43110/uimedia/all.css [HTTP/1.1 200 OK 2ms]
GET 
http://127.0.0.1:43110/uimedia/all.js [HTTP/1.1 200 OK 4ms]
[Wrapper] Created! all.js:1292:14
GET 
http://127.0.0.1:43110/1H1Ee3oP5tVZqz5kmQVqqfXjFUDx8kAinN/ [HTTP/1.1 200 OK 0ms]
GET 
http://127.0.0.1:43110/1H1Ee3oP5tVZqz5kmQVqqfXjFUDx8kAinN/js/all.js [HTTP/1.1 200 OK 0ms]
[Wrapper] Message nonce error: undefined != 8ffea5dfc1054366343dda68a7de96679efb05f9fdcc7cd5e864651d89e32628
```

Site: [1H1Ee3oP5tVZqz5kmQVqqfXjFUDx8kAinN.zip](https://github.com/HelloZeroNet/ZeroNet/files/181356/1H1Ee3oP5tVZqz5kmQVqqfXjFUDx8kAinN.zip)
 Packet capture: [wrapper_nonce.zip](https://github.com/HelloZeroNet/ZeroNet/files/181368/wrapper_nonce.zip) (from a separate machine - Ubuntu, latest FF)
 OK, my bad. I had a different error earlier, saw the comments on that blog entry and grabbed one from a different site. Thanks!
  I think that zeronet can be packaged via setuptools and uploaded to PyPI instead of using custom update scripts. You will only need to create setup.py file.

Pros:
- Official way to install python packages
- Easier to install (pip install zeronet, dependencies are downloaded automagically)
- Easier to update (pip install --upgrade zeronet)
- [Command line scripts](https://python-packaging.readthedocs.org/en/latest/command-line-scripts.html)

Cons:
- Some modifications to source code (mostly imports) may be required

If you think that such modifications can be useful, i can work on this issue and create PR later.
 I would love to see this happening!
 - For SSL + Python, does anything prevents us to pin the versions (like what you're currently doing) in the `setup.py`?
- For the update mechanism, I believe we could do it also with the setup.py. Could you point to the code that's doing this? Thanks!
 The package itself can be installed in bundle, the only thing that changes is update method - instead of downloading master branch from github, script will use pip to install latest released version.

On the other hand, it won't work with plugins in their current implementation - but if you ask me, marking plugins as disabled by prefixing "disabled-" is bad idea. I don't know much about good practices for pluggable modules, so i'll look into it for now.
 > I don't know much about good practices for pluggable modules, so i'll look into it for now.

In python packaging there is the [concept of entrypoints](http://stackoverflow.com/questions/774824/explain-python-entry-points) which can be installed in separate packages and listed by another package.

This is exactly done for such cases. Then we could enable/disable modules based on a configuration file, for instance (and default configuration associated).
 [Here is full example](http://stackoverflow.com/a/9615473/3315512).

We can agree on common entrypoint name (i.e. "zeronet") and expect function to return plugin object.
 Vendorizing libraries and not having a setup.py is going to make it very difficult for distributions to package ZeroNet. Distros have their own dependency management. Having a list of acceptable ranges for all dependencies could be helpful.
Related to #241  **This needs to happen.**

As a [Gentoo Linux contributor](https://github.com/leycec/raiagent), ZeroNet's inclusion of vendorized dependencies *and* failure to comply with basic Python packaging standards (e.g., `setup.py`, PyPI) all but guarantees that ZeroNet will never hit [Portage](https://wiki.gentoo.org/wiki/Portage) â€“ the official package tree for Gentoo. ZeroNet's appallingly anarchic (and anachronistic) installation process is a poor fit for modern Linux distributions. While I fully intend to publish and maintain an unofficial ZeroNet ebuild (i.e., Gentoo package) at my [third-party overlay](https://github.com/leycec/raiagent), this is only a stop-gap temporary measure.

ZeroNet deserves better. Ultimately, ZeroNet needs to comply with industry-standard installation practice for open-source Python software. That means `setup.py` and PyPI.

Authoring and submitting a working `setup.py` script to PyPI is, frankly, trivial. By compare to the mammoth task of designing and maintaining a decentralized, demonetized, anonymized, censorship-resistent Internet, interfacing with the [CheeseShop](https://wiki.python.org/moin/CheeseShop) should be literal child's play.

Are we children? Or are we men? @ulrichard I note that you've already authored a [preliminary `setup.py`](https://github.com/HelloZeroNet/ZeroNet/issues/417#issuecomment-256174420) for use in your [Ubuntu PPA](https://launchpad.net/%7Erichi-paraeasy/+archive/ubuntu/ppa/+packages). _Excellent._

Would you be willing to submit a pull request officially integrating that into ZeroNet? It doesn't necessarily need to be perfect, particularly with respect to dependencies and version ranges. As an initial foray into Python packaging, even a superficially working `setup.py` would happily suffice.

Something is absolutely better than nothing.

...and nothing is what ZeroNet currently has. > Are we children? Or are we men?

I'm pretty confident those are not the only options. We adults are not limited to men in gender :-)
 Having a sensible importable name for the top-level package is a pre-requisite for a sane packaging setup, so issue #940 is IMO a pre-requisite for this issue. > I'm pretty confident those are not the only options. We adults are not limited to men in gender :-)

As much as we all appreciate restatements of the self-obvious, the "Are we children? Or are we men?" hypothetical was a tongue-in-cheek reference to [Devo](https://rateyourmusic.com/artist/devo)'s 1978 synthpop classic [**"Q: Are We Not Men? A: We Are Devo!"**](https://rateyourmusic.com/release/album/devo/q__are_we_not_men__a__we_are_devo_)

I assumed we were all sufficiently familiar with 70's-era New Wave (art|post|proto)-punk experimental synthpop rock here. I assumed incorrectly. *For shame, Internet!*

> Having a sensible importable name for the top-level package is a pre-requisite for a sane packaging setup...

ðŸ‘ ðŸ¤ ðŸ‘ 

ZeroNet has deviated *sooo* far afield from a sane packaging setup that I'm unsure what, if anything, can reasonably be done at this late hour. It's *not* simply the lack of a `setup.py` script, PyPI wheel, or eponymous top-level package. It's also:

* The extreme number of bundled mandatory runtime dependencies in the `src/lib` subdirectory, most patched in a ZeroNet-specific manner in unclear and probably unsafe ways.
* The lack of any official list of mandatory and optional build-, run-, and test-time dependencies (ideally complete with acceptable version ranges).
* The lack of a documented protocol for performing system-wide installation, particularly with respect to requisite users, groups, permissions, and directory structure.
* The lack of a default system-wide installation shell script.
* The lack of a default configuration file template.
* The lack of a default `systemd` unit.
* The lack of a default OpenRC script.
* The lack of a default `/usr/bin/zeronet` shell script. The bundled `zeronet.py` script fails to suffice for a medley of reasons. In particular, `zeronet.py`:
  * Fails to include the system-wide ZeroNet configuration file (e.g., `/etc/zeronet.conf`) if any.
  * Fails to generalize to Python 3.x (e.g., due to the shebang line `#!/usr/bin/env python2.7`). While ZeroNet does *not* yet support Python 3.x, it really [needs to](https://github.com/HelloZeroNet/ZeroNet/issues/149) start doing that.

In short, **ZeroNet is a Turing-complete nightmare with respect to packaging.**

To simplify packaging for other Linux distros, consider pilfering the `src_install()` function of my [recently complete ZeroNet ebuild](https://github.com/leycec/raiagent/blob/master/net-vpn/zeronet/zeronet-9999.ebuild#L112) for Gentoo Linux. This function dynamically synthesizes sane users, groups, permissions, directory structure, system-wide configuration file, `systemd` unit, OpenRC script, and launcher script from user-supplied choices (e.g., whether or not to enable Tor-based anonymization). The ebuild preamble also specifies the most authoritative list of mandatory and optional dependencies I've yet discovered.

The [ZeroNet PKGBUILD tree](https://aur.archlinux.org/cgit/aur.git/tree/?h=zeronet) for Arch Linux comes similarly recommended for this purpose.

May the genderless penguin be with you, fellow packagers. ðŸ§  please first stop to bully. Secondly, if you think that zeronet is a nightmare so fork it and make your own. > It's not simply the lack of a setup.py script, PyPI wheel, or eponymous top-level package. It's also [â€¦]

That's a good solid list of specific issues.

They all seem tractable; how about we have each of them in a separate issue and work on addressing them?

@HelloZeroNet, those all look like real issues that should be addressed. Is there anything there you don't want corrected?
   Ohh, I get you now! One sec.
    It seems to forget to close log files

`- Starting ZeroNet...
Traceback (most recent call last):
  File "zeronet.py", line 15, in main
    import main
  File "src\main.py", line 51, in <module>
    os.rename("%s/debug.log" % config.log_dir, "%s/debug-last.log" % config.log_dir)
WindowsError: [Error 32] ãƒ—ãƒ­ã‚»ã‚¹ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚åˆ¥ã®ãƒ—ãƒ­ã‚»ã‚¹ãŒä½¿ç”¨ä¸­ã§ã™ã€‚(Can't access because other process locks the file)
`
 python.exe was dead. "WerFault" has the handle. 
And I couldn't find what makes this condition.I'll report as soon as I know.
 I realize that only "debug.log" is locked.
In my conclusion,when zaronet couldn't access "debug-last.log" by some reason,it happens.
  As far as I can see hashes get only forwarded (from wrapper to actual zite) when they change.

Adding the code from window.onhashchange to onLoad in Wrapper.coffee might do the job.

This might be handy for keys which should not be transferred to the server. It does not really matter for a local node, but for a proxy, you don't own, it would.
 Okay, thanks, got it working this way
  How would this be different from adding new features in like this `css/plugins/DarkSkin/all.css` ?

Would the above compile (append to css/all.css) currently?
 @HelloZeroNet Maybe add support for multiple databases per site? This way a plugin can store its data independently from the rest of the site. Would make adding some features much easier.
 @HelloZeroNet Have this implemented in 0.5.5 and can be closed? I am talking about "Upgrade code" feature.  After a restart of ZeroNet, all users are logged out and need to reinput their masterseeds as well as go to [zeroid.bit](https://www.zeropro.xyz/zeroid.bit) to reactivate their ID.
  according to https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/ (#apt-get) it's better to do the install and the cleanup with one command
  ZeroNet breaks css in the compilation / merge process under certain circumstances. This example will fail to compile a valid css file. 

```
@keyframes flip {                                                                                                                                         
    0%   { transform: perspective(120px) rotateX(0deg) rotateY(0deg);}                                                                                 
    50%  { transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg)}                                                                                    
    100% { transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg);}                                                                         
} 
```

It produces this css code:

```
@keyframes flip {
    0%   { -webkit-transform: perspective(120px) rotateX(0deg) rotateY(0deg); -moz-transform: perspective(120px) rotateX(0deg) rotateY(0deg); -o-transform: perspective(120px) rotateX(0deg) rotateY(0deg); -ms-transform: perspective(120px) rotateX(0deg) rotateY(0deg); transform: perspective(120px) rotateX(0deg) rotateY(0deg) ;}
@-webkit-keyframes flip {
    0%   { -webkit-transform: perspective(120px) rotateX(0deg) rotateY(0deg); -moz-transform: perspective(120px) rotateX(0deg) rotateY(0deg); -o-transform: perspective(120px) rotateX(0deg) rotateY(0deg); -ms-transform: perspective(120px) rotateX(0deg) rotateY(0deg); transform: perspective(120px) rotateX(0deg) rotateY(0deg) ;}
@-moz-keyframes flip {
    0%   { -webkit-transform: perspective(120px) rotateX(0deg) rotateY(0deg); -moz-transform: perspective(120px) rotateX(0deg) rotateY(0deg); -o-transform: perspective(120px) rotateX(0deg) rotateY(0deg); -ms-transform: perspective(120px) rotateX(0deg) rotateY(0deg); transform: perspective(120px) rotateX(0deg) rotateY(0deg) ;}

    50%  { -webkit-transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg); -moz-transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg); -o-transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg); -ms-transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg); transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg) }
    100% { -webkit-transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg); -moz-transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg); -o-transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg); -ms-transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg); transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg) ;}
}
```

It stops processing the keyframe rule after the first percentage keyword and starts with the next vendor-prefix without closing the bracket, which causes the issue.

This seems to happen when there isn't an space character before the closing bracket in the percentage rules, caused by `{.*?[^ ]}`. Replacing the regular expression makes the trick.
 EDIT: You'r right, it produces valid css but the it repeats some of the rules few times.

```
.test {
    border-radius: 5px;
    background: linear-gradient(red, blue);
}


@keyframes flip {
  0%   { transform: perspective(120px) rotateX(0deg) rotateY(0deg);}
  50%  { transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg)}
  100% { transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg);}
}
@keyframes flip2 {
  0%   { transform: perspective(120px) rotateX(0deg) rotateY(0deg);}
  50%  { transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg)}
  100% { transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg);}
}
@-webkit-keyframes flip {
  0%   { transform: perspective(120px) rotateX(0deg) rotateY(0deg);}
  50%  { transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg)}
  100% { transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg);}
}
@keyframes flip2 {
  0%   { transform: perspective(120px) rotateX(0deg) rotateY(0deg);}
  50%  { transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg)}
  100% { transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg);}
}
@-moz-keyframes flip {
  0%   { transform: perspective(120px) rotateX(0deg) rotateY(0deg);}
  50%  { transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg)}
  100% { transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg);}
}
@keyframes flip2 {
  0%   { transform: perspective(120px) rotateX(0deg) rotateY(0deg);}
  50%  { transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg)}
  100% { transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg);}
}
```
 It doesn't add the prefixes.

```
.test {
    border-radius: 5px;
    background: linear-gradient(red, blue);
}


@keyframes flip {
  0%   { transform: perspective(120px) rotateX(0deg) rotateY(0deg);}
  50%  { transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg)}
  100% { transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg);}
}
@keyframes flip2 {
  0%   { transform: perspective(120px) rotateX(0deg) rotateY(0deg);}
  50%  { transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg)}
  100% { transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg);}
}
```
 This seems to work better `(.*? {.*?}\s*})`, can you check it out?

```
@keyframes flip {
  0%   { transform: perspective(120px) rotateX(0deg) rotateY(0deg);}
  50%  { transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg)}
  100% { transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg);}
}
@-webkit-keyframes flip {
  0%   { transform: perspective(120px) rotateX(0deg) rotateY(0deg);}
  50%  { transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg)}
  100% { transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg);}
}
@-moz-keyframes flip {
  0%   { transform: perspective(120px) rotateX(0deg) rotateY(0deg);}
  50%  { transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg)}
  100% { transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg);}
}

@keyframes flip2 {
  0%   { transform: perspective(120px) rotateX(0deg) rotateY(0deg);}
  50%  { transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg)}
  100% { transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg);}
}
@-webkit-keyframes flip2 {
  0%   { transform: perspective(120px) rotateX(0deg) rotateY(0deg);}
  50%  { transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg)}
  100% { transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg);}
}
@-moz-keyframes flip2 {
  0%   { transform: perspective(120px) rotateX(0deg) rotateY(0deg);}
  50%  { transform: perspective(120px) rotateX(-180.1deg) rotateY(0deg)}
  100% { transform: perspective(120px) rotateX(-180deg) rotateY(-179.9deg);}
}
```

I'll give it a try with more complex css keyframes and see it it works.
 I tested the regex with different css animation libraries and it worked for me, I created a new pull request with the fix.

This can be closed in favour of #372.
  After update from UI i get that in console:

`OpenSSL dlclosed, handle: 140396059753056
Downloading. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Downloaded.
Plugins enabled: ['AnnounceZero', 'CryptMessage', 'Newsfeed', 'Sidebar', 'Stats', 'Trayicon', 'Zeroname'] disabled: ['Bootstrapper', 'Dnschain', 'DonationMessage', 'Multiuser', 'UiPassword', 'Zeroname-local']
Extracting... . . . . . . . . . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . P . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Done.
Restarting...
ERROR:-:Unhandled exception
None
Traceback (most recent call last):
  File "start.py", line 16, in <module>
    main()
  File "start.py", line 13, in main
    zeronet.main()
  File "/Users/Shift/ZeroNet/zeronet.py", line 52, in main
    import time
NameError: global name 'time' is not defined`

but after python start.py all work normally 
  even when using --ui_ip "*" option, I am getting a connection refused. My setup involves having my laptop ssh tunnel to a host machine with a vm that runs ZeroNet on it, but lately I've been recieving a connection refused error.

![connectionrefused](https://cloud.githubusercontent.com/assets/2320007/13840414/6ae3307c-ebf0-11e5-91c3-93e8e188b2da.PNG)
 I found the cause of the error. It seems that something is causing the connection to be refused when Opera Turbo is enabled. I won't close the issue yet since there might be a solution to this, but for now, the quick fix is to disable Opera Turbo.
 Opera turbo is a opera's specific feature that pipe your traphic throu a compressing proxy somewhere on the internet. As Zeronet is local, you must see on the opera side if there is a way to create exeption rules for the traphic redirection. 

Unfortunately, Nothing Zeronet specific here. 

Closing ?   I tried some light debugging, but I have no idea what's wrong. You can check out New ZeroHello at https://zeronet.classcoder.com/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D, but it doesn't render due to:

```
Uncaught TypeError: Cannot read property 'length' of undefined
    Text.toColor @ all.js:1564
    Dashboard.render @ all.js:2079
    (anonymous function) @ all.js:1942
    doRender @ all.js:983
```

at around line 4 in js/utils/Text.coffee. Nothing is logged to the server console when ZeroHello is loaded. I'm not sure if this should be in HelloZeroNet/ZeroHello or here, but it seems like an issue with the wrapper to me.
 @HelloZeroNet Nope, everything else works, and I figured that nginx config out when I was setting up the proxy a few months ago.
 Worked, thanks!
  The current regex at src/Content/ContentManager.py lines 298 and 312:
https://github.com/HelloZeroNet/ZeroNet/blob/e891a10e54c31468849ed65892ed97bbb548a534/src/Content/ContentManager.py#L298
https://github.com/HelloZeroNet/ZeroNet/blob/e891a10e54c31468849ed65892ed97bbb548a534/src/Content/ContentManager.py#L312
are not matching all the ASCII characters but a very limited subset:
`^[a-zA-Z0-9_\.\+\-/]*$`

I think more characters could be allowed. I was able to add '@' and '=' without issues (as I had some filenames containing those characters). 
I believe this should match any printable ASCII character:
`^[\\x20-\\x7e]*$`

If not all ASCII characters can be used, the error message should be changed.
 are spaces and ( ) supported ? 
  I run a macosx and I'm getting the error. Now I'm trying to understand the rationale behind the scripts. Why do they call Python from Python/Python? 
Is Python assumed to be installed? Any pointers would help.
 Both `bash ZeroNet.app` and `open ZeroNet.app` worked with the release above.
Double clicking the app does nothing though.
 Wouldn't it be better to package the app as a proper Application bundle, with Info.plist and the folder structure as pointed [here](https://developer.apple.com/library/mac/documentation/CoreFoundation/Conceptual/CFBundles/BundleTypes/BundleTypes.html#//apple_ref/doc/uid/10000123i-CH101-SW13)?
 Ok. I'll look into it as soon as I can. Can you point me out to the ZeroNet build instructions, or how you guys package it into one single download file? If it's automated I'll need to look into it.
 FYI: I just ran into the same "classic environment no longer supported" issue on 10.9.5 (using the download through the site)
 Downloaded Zeronet per https://zeronet.io/ started up and worked great.
Tried to re-start the Zeronet Desktop App after my laptop went to sleep.
[Mac OS 10.11.3]
This is what I get:

**Server error

Err: Exception: File not allowed: data/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/index.html in UiServer.py line 81 > UiRequest.py line 82 > UiRequest.py line 209 > UiRequest.py line 282 > SiteStorage.py line 230 > SiteStorage.py line 251

Please report it if you think this an error.

Details:**

{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,_/_;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate, sdch", 
    "HTTP_ACCEPT_LANGUAGE": "en-US,en;q=0.8", 
    "HTTP_CONNECTION": "keep-alive", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36", 
    "PATH_INFO": "/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
    "QUERY_STRING": "", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "61010", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "1.0.0.127.in-addr.arpa", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.0 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "coffeescript_compiler": null, 
        "config_file": "zeronet.conf", 
        "connected_limit": 15, 
        "data_dir": "data", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "keep_ssl_cert": false, 
        "log_dir": "log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": true, 
        "open_browser": "default_browser", 
        "proxy": null, 
        "size_limit": 10, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.aletorrenty.pl:2710/announce", 
            "http://explodie.org:6969/announce", 
            "http://torrent.gresille.org/announce"
        ], 
        "trackers_file": false, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false
    }, 
    "plugins": [
        "AnnounceZero", 
        "CryptMessage", 
        "Newsfeed", 
        "Sidebar", 
        "Stats", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.0.2", 
    "version_python": "2.7.11 |Anaconda 2.5.0 (x86_64)| (default, Dec  6 2015, 18:57:58) \n[GCC 4.2.1 (Apple Inc. build 5577)]", 
    "version_zeronet": "0.3.6 r1038", 
    "wsgi.url_scheme": "http"
}
 1st Question: No, I do not have any special (non-english) characters in the directory.

I searched `not in allowed dir` and did not find any associated code.

Here is the closest I found: `[2016-03-18 20:59:33,542] ERROR    Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json`
 Python 2.7 is only running once.
I attached a screenshot of Python running as well as the log files Zipped.

![screen shot 2016-03-19 at 8 30 07 am](https://cloud.githubusercontent.com/assets/16785963/13898606/f3882172-edac-11e5-933e-59ee0a531dd1.png)

[Archive.zip](https://github.com/HelloZeroNet/ZeroNet/files/180806/Archive.zip)
 Hello.
If you need some help to investigate the case, do not hesitate to ask me.
I am an experienced Mac OS X "Objective-C" and "C" experienced developer.
 You are experiencing the exact same problem as most P2P developpers porting their code to Mac OS X : YaCy had it, Twister has it, you have it.

What I recommand is to build a little native Mac OS X app to launch all necessary processes your application needs, but also that could be used, with a GUI (Menu, Icon in task bar) to configure the daemon and the options so that users don't have to edit text files and so on.

Regarding the libraries, I recommand to include all dependant libraries in an already compiled format (*.a) in a true Mac OS X Application bundle, with the little native app.

The "Linux" way of doing things (Recompiling the source code of each library) is not recommanded to create easy to install Mac OS X Application bundles : Application Bundle where created / engineered to have all the libraries already compiled.

I am going to do this work for Twister, but I would be really glad to do it for ZeroNet too :-)

You can count on my active cooperation to solving this little issue, it will be an honor for me.

Kind regards,

Stman.
 If you are a registered Developper, one can publish either on the MacAppStore, but in that case the application must meet Apple requirements, and the rules for the MacAppStore are more open than those applying to iOS Apps, 

OR

One can make the binary, signed with his Dev account, on any "custom server" .

Both solutions would end this issue "Un-identifyed" developer.
 With pleasure....
 So, there a mac app signed now ? Problem solved ?   The Benchmarking function is CPU intensive, so someone could easily DOS
a proxy.

Pointed out in:
http://127.0.0.1:43110/Talk.ZeroNetwork.bit/?Topic:1_1LJP7tDoGnWNppUGJoNS8cJbmYTS1TecCC/Zero+proxies+vulnerability
  I run ZeroNet as `python zeronet.py`. Default max connected peer per site in Config.py is 15.

But in /Stats I can see more 15 connection per site. For example:
1K28kQFMquNzto2iQf4GGjr6oFUbC1NddE  [341, 321, 534, 501, 207, 339, 117, 706, 106, 108, 123, 340, 11, 214, 33, 120, 118, 547, 176]   **19**/24/78    116 932kB   4713kB
 Meanwhile the 1000 connections that ate the bandwidth.
  I get this locally - anyone else?

```
(env) C:\Users\Oliver\Documents\AeroFS\ZeroNet\ZeroNet [master]> python -m pytest .\src\Test\TestContent.py -k testSign[
content.json]
============================= test session starts =============================
platform win32 -- Python 2.7.11, pytest-2.9.0, py-1.4.31, pluggy-0.3.1 -- C:\Users\Oliver\Documents\AeroFS\ZeroNet\ZeroNet\env\Scripts\python.exe
cachedir: src\Test\.cache
rootdir: C:\Users\Oliver\Documents\AeroFS\ZeroNet\ZeroNet\src\Test, inifile: pytest.ini
plugins: cov-2.2.1
collected 8 items

src\Test\TestContent.py::TestContent::testSign[content.json] FAILED

========================== slowest 6 test durations ===========================
0.15s call     TestContent.py::TestContent::testSign[content.json]
0.01s setup    TestContent.py::TestContent::testSign[content.json]
0.00s teardown TestContent.py::TestContent::testSign[content.json]
================================== FAILURES ===================================
_____________________ TestContent.testSign[content.json] ______________________

self = <src.Test.TestContent.TestContent instance at 0x037EA3F0>
site = <Site 1TeSTv..xQGT>, inner_path = 'content.json'

    @pytest.mark.parametrize("inner_path", ["content.json", "data/test_include/content.json", "data/users/content.json"])
    def testSign(self, site, inner_path):
        # Bad privatekey
        assert not site.content_manager.sign(inner_path, privatekey="5aaa3PvNm5HUWoCfSUfcYvfQ2g3PrRNJWr6Q9eqdBGu23mtMnaa", filewrite=False)

        # Good privatekey
        content = site.content_manager.sign(inner_path, privatekey="5KUh3PvNm5HUWoCfSUfcYvfQ2g3PrRNJWr6Q9eqdBGu23mtMntv", filewrite=False)
        content_old = site.content_manager.contents[inner_path]  # Content before the sign
        assert not content_old == content  # Timestamp changed
        assert site.address in content["signs"]  # Used the site's private key to sign
        if inner_path == "content.json":
            assert len(content["files"]) == 17
        elif inner_path == "data/test-include/content.json":
            assert len(content["files"]) == 1
        elif inner_path == "data/users/content.json":
            assert len(content["files"]) == 0

        # Everything should be same as before except the modified timestamp and the signs
>       assert (
            {key: val for key, val in content_old.items() if key not in ["modified", "signs", "sign", "zeronet_version"]}
            ==
            {key: val for key, val in content.items() if key not in ["modified", "signs", "sign", "zeronet_version"]}
        )
E       assert {'address': '...ork.bit', ...} == {'address': '1...ork.bit', ...}
E         Common items:
E         {u'address': u'1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT',
E          u'background-color': u'white',
E          u'description': u'Blogging platform Demo',
E          u'domain': u'Blog.ZeroNetwork.bit',
E          u'files_optional': {u'data/img/zeroblog-comments.png': {u'sha512': u'efe4e815a260e555303e5c49e550a689d27a8361f64667bd4a91dbcccb83d2b4',
E                                                                  u'size': 24001},
E                              u'data/img/zeroid.png': {u'sha512': u'b46d541a9e51ba2ddc8a49955b7debbc3b45fd13467d3c20ef104e9d938d052b',
E                                                       u'size': 18875},
E         Detailed information truncated (216 more lines), use "-vv" to show

src\Test\TestContent.py:98: AssertionError
---------------------------- Captured stdout setup ----------------------------
DEBUG:Site:1TeSTv..xQGT:New auth key: 3d7fa0718c59f08bf73272adb70d4d5c9f3cd5e507e6bc69d3b2b92aa90bb4a4
DEBUG:Site:1TeSTv..xQGT:New wrapper key: c8e03a51640139696dd058572f7a0a0885220ae376906382539e2f4916cc5425
---------------------------- Captured stdout call -----------------------------
INFO:Site:1TeSTv..xQGT:Opening site data directory: src/Test/testdata/1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT/...
INFO:Site:1TeSTv..xQGT:- [SKIPPED] content.json
INFO:Site:1TeSTv..xQGT:- dbschema.json (SHA512: a92933be0138624aaf1d14e1c0e4467915b1a1623e48302378031dcfaed35510)
INFO:Site:1TeSTv..xQGT:- index.html (SHA512: 607317eb5744be5f538b0dc464f6c90dc7a1c2a0e3e00db05cecad86b8e7c556)
INFO:Site:1TeSTv..xQGT:- css/all.css (SHA512: fcca6465c91188993b597a12a3fb75c9cf7a5c9371276ca6c6c014a2809d3ad1)
INFO:Site:1TeSTv..xQGT:- data/data.json (SHA512: a7919a78587627676983978969d6457eb351da51ed1355c588885138baba7b85)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/optional.txt (SHA512: c6f81db0e9f8206c971c9e5826e3ba823ffbb1a3a900f8047652a8bf78ea98fd)
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/zeroblog.db
INFO:Site:1TeSTv..xQGT:- data/img/autoupdate.png (SHA512: d2b4dc8e0da2861ea051c0c13490a4eccf8933d77383a5b43de447c49d816e71)
INFO:Site:1TeSTv..xQGT:- data/img/direct_domains.png (SHA512: 5f14b30c1852735ab329b22496b1e2ea751cb04704789443ad73a70587c59719)
INFO:Site:1TeSTv..xQGT:- data/img/domain.png (SHA512: ce87e0831f4d1e95a95d7120ca4d33f8273c6fce9f5bbedf7209396ea0b57b6a)
INFO:Site:1TeSTv..xQGT:- data/img/memory.png (SHA512: dd56515085b4a79b5809716f76f267ec3a204be3ee0d215591a77bf0f390fa4e)
INFO:Site:1TeSTv..xQGT:- data/img/multiuser.png (SHA512: 88e3f795f9b86583640867897de6efc14e1aa42f93e848ed1645213e6cc210c6)
INFO:Site:1TeSTv..xQGT:- data/img/progressbar.png (SHA512: 23d592ae386ce14158cec34d32a3556771725e331c14d5a4905c59e0fe980ebf)
INFO:Site:1TeSTv..xQGT:- data/img/slides.png (SHA512: 1933db3b90ab93465befa1bd0843babe38173975e306286e08151be9992f767e)
INFO:Site:1TeSTv..xQGT:- data/img/slots_memory.png (SHA512: 82a250e6da909d7f66341e5b5c443353958f86728cd3f06e988b6441e6847c29)
INFO:Site:1TeSTv..xQGT:- data/img/trayicon.png (SHA512: e7ae65bf280f13fb7175c1293dad7d18f1fcb186ebc9e1e33850cdaccb897b8f)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zeroblog-comments.png (SHA512: efe4e815a260e555303e5c49e550a689d27a8361f64667bd4a91dbcccb83d2b4)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zeroid.png (SHA512: b46d541a9e51ba2ddc8a49955b7debbc3b45fd13467d3c20ef104e9d938d052b)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zeroname.png (SHA512: bab45a1bb2087b64e4f69f756b2ffa5ad39b7fdc48c83609cdde44028a7a155d)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zerotalk-mark.png (SHA512: a335b2fedeb8d291ca68d3091f567c180628e80f41de4331a5feb19601d078af)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zerotalk-upvote.png (SHA512: b1ffd7f948b4f99248dde7efe256c2efdfd997f7e876fb9734f986ef2b561732)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zerotalk.png (SHA512: 54d10497a1ffca9a4780092fd1bd158c15f639856d654d2eb33a42f9d8e33cd8)
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/test_include/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/test_include/data.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1C5sgvWaSgfaTpV5kjBCnCiKtENNMYo69q/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1C5sgvWaSgfaTpV5kjBCnCiKtENNMYo69q/data.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1CjfbrbwtP8Y2QjPy12vpTATkUT7oSiPQ9/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1CjfbrbwtP8Y2QjPy12vpTATkUT7oSiPQ9/data.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1CjfbrbwtP8Y2QjPy12vpTATkUT7oSiPQ9/peanut-butter-jelly-time.gif
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1J6UrZMkarjVg5ax9W4qThir3BFUikbW6C/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1J6UrZMkarjVg5ax9W4qThir3BFUikbW6C/data.json
INFO:Site:1TeSTv..xQGT:- data-default/data.json (SHA512: 1a11aae6e183f3fb2026763b014047edc933c3a27bfab5da63daecf998f116aa)
INFO:Site:1TeSTv..xQGT:- data-default/users/content-default.json (SHA512: 37b11e263d4f572555f8a1cb27f1d3df27beebf29275152773b9e239092bed63)
INFO:Site:1TeSTv..xQGT:- img/loading.gif (SHA512: 8a42b98962faea74618113166886be488c09dad10ca47fe97005edc5fb40cc00)
INFO:Site:1TeSTv..xQGT:- js/all.js (SHA512: f801cdd7f507a53bb0a8a32e2ce3d54593e47111bf7693c8232722c33809f8aa)
DEBUG:Site:1TeSTv..xQGT:Changed files: ['content.json', 'data/img/zeroid.png', 'data/img/zerotalk-upvote.png', 'dbschema.json', 'data/img/zeroblog-comments.png', 'css/all.css', 'data/img/zerotalk.png', 'data-default/data.json', 'js/all.js', 'data/img/zeroname.png', 'data/optional.txt', 'data/data.json', 'index.html', 'data/img/zerotalk-mark.png', 'data-default/users/content-default.json']
INFO:Site:1TeSTv..xQGT:Adding timestamp and sha512sums to new content.json...
INFO:Site:1TeSTv..xQGT:Verifying private key...
ERROR:Site:1TeSTv..xQGT:Private key invalid! Valid signers: ['1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT'], Private key address: False
INFO:Site:1TeSTv..xQGT:Opening site data directory: src/Test/testdata/1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT/...
INFO:Site:1TeSTv..xQGT:- [SKIPPED] content.json
INFO:Site:1TeSTv..xQGT:- dbschema.json (SHA512: a92933be0138624aaf1d14e1c0e4467915b1a1623e48302378031dcfaed35510)
INFO:Site:1TeSTv..xQGT:- index.html (SHA512: 607317eb5744be5f538b0dc464f6c90dc7a1c2a0e3e00db05cecad86b8e7c556)
INFO:Site:1TeSTv..xQGT:- css/all.css (SHA512: fcca6465c91188993b597a12a3fb75c9cf7a5c9371276ca6c6c014a2809d3ad1)
INFO:Site:1TeSTv..xQGT:- data/data.json (SHA512: a7919a78587627676983978969d6457eb351da51ed1355c588885138baba7b85)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/optional.txt (SHA512: c6f81db0e9f8206c971c9e5826e3ba823ffbb1a3a900f8047652a8bf78ea98fd)
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/zeroblog.db
INFO:Site:1TeSTv..xQGT:- data/img/autoupdate.png (SHA512: d2b4dc8e0da2861ea051c0c13490a4eccf8933d77383a5b43de447c49d816e71)
INFO:Site:1TeSTv..xQGT:- data/img/direct_domains.png (SHA512: 5f14b30c1852735ab329b22496b1e2ea751cb04704789443ad73a70587c59719)
INFO:Site:1TeSTv..xQGT:- data/img/domain.png (SHA512: ce87e0831f4d1e95a95d7120ca4d33f8273c6fce9f5bbedf7209396ea0b57b6a)
INFO:Site:1TeSTv..xQGT:- data/img/memory.png (SHA512: dd56515085b4a79b5809716f76f267ec3a204be3ee0d215591a77bf0f390fa4e)
INFO:Site:1TeSTv..xQGT:- data/img/multiuser.png (SHA512: 88e3f795f9b86583640867897de6efc14e1aa42f93e848ed1645213e6cc210c6)
INFO:Site:1TeSTv..xQGT:- data/img/progressbar.png (SHA512: 23d592ae386ce14158cec34d32a3556771725e331c14d5a4905c59e0fe980ebf)
INFO:Site:1TeSTv..xQGT:- data/img/slides.png (SHA512: 1933db3b90ab93465befa1bd0843babe38173975e306286e08151be9992f767e)
INFO:Site:1TeSTv..xQGT:- data/img/slots_memory.png (SHA512: 82a250e6da909d7f66341e5b5c443353958f86728cd3f06e988b6441e6847c29)
INFO:Site:1TeSTv..xQGT:- data/img/trayicon.png (SHA512: e7ae65bf280f13fb7175c1293dad7d18f1fcb186ebc9e1e33850cdaccb897b8f)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zeroblog-comments.png (SHA512: efe4e815a260e555303e5c49e550a689d27a8361f64667bd4a91dbcccb83d2b4)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zeroid.png (SHA512: b46d541a9e51ba2ddc8a49955b7debbc3b45fd13467d3c20ef104e9d938d052b)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zeroname.png (SHA512: bab45a1bb2087b64e4f69f756b2ffa5ad39b7fdc48c83609cdde44028a7a155d)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zerotalk-mark.png (SHA512: a335b2fedeb8d291ca68d3091f567c180628e80f41de4331a5feb19601d078af)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zerotalk-upvote.png (SHA512: b1ffd7f948b4f99248dde7efe256c2efdfd997f7e876fb9734f986ef2b561732)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zerotalk.png (SHA512: 54d10497a1ffca9a4780092fd1bd158c15f639856d654d2eb33a42f9d8e33cd8)
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/test_include/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/test_include/data.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1C5sgvWaSgfaTpV5kjBCnCiKtENNMYo69q/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1C5sgvWaSgfaTpV5kjBCnCiKtENNMYo69q/data.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1CjfbrbwtP8Y2QjPy12vpTATkUT7oSiPQ9/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1CjfbrbwtP8Y2QjPy12vpTATkUT7oSiPQ9/data.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1CjfbrbwtP8Y2QjPy12vpTATkUT7oSiPQ9/peanut-butter-jelly-time.gif
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1J6UrZMkarjVg5ax9W4qThir3BFUikbW6C/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1J6UrZMkarjVg5ax9W4qThir3BFUikbW6C/data.json
INFO:Site:1TeSTv..xQGT:- data-default/data.json (SHA512: 1a11aae6e183f3fb2026763b014047edc933c3a27bfab5da63daecf998f116aa)
INFO:Site:1TeSTv..xQGT:- data-default/users/content-default.json (SHA512: 37b11e263d4f572555f8a1cb27f1d3df27beebf29275152773b9e239092bed63)
INFO:Site:1TeSTv..xQGT:- img/loading.gif (SHA512: 8a42b98962faea74618113166886be488c09dad10ca47fe97005edc5fb40cc00)
INFO:Site:1TeSTv..xQGT:- js/all.js (SHA512: f801cdd7f507a53bb0a8a32e2ce3d54593e47111bf7693c8232722c33809f8aa)
DEBUG:Site:1TeSTv..xQGT:Changed files: ['content.json', 'data/img/zeroid.png', 'data/img/zerotalk-upvote.png', 'dbschema.json', 'data/img/zeroblog-comments.png', 'css/all.css', 'data/img/zerotalk.png', 'data-default/data.json', 'js/all.js', 'data/img/zeroname.png', 'data/optional.txt', 'data/data.json', 'index.html', 'data/img/zerotalk-mark.png', 'data-default/users/content-default.json']
INFO:Site:1TeSTv..xQGT:Adding timestamp and sha512sums to new content.json...
INFO:Site:1TeSTv..xQGT:Verifying private key...
INFO:Site:1TeSTv..xQGT:Correct 1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT in valid signers: ['1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT']
INFO:Site:1TeSTv..xQGT:Signing content.json...
INFO:Site:1TeSTv..xQGT:File content.json signed!
============== 7 tests deselected by '-ktestSign[content.json]' ===============
=================== 1 failed, 7 deselected in 0.27 seconds ====================
```
 Still picking this stuff up!

```
        # Everything should be same as before except the modified timestamp and the signs
>       assert (
            {key: val for key, val in content_old.items() if key not in ["modified", "signs", "sign", "zeronet_version"]}
            ==
            {key: val for key, val in content.items() if key not in ["modified", "signs", "sign", "zeronet_version"]}
        )
E       assert {'address': '...ork.bit', ...} == {'address': '1...ork.bit', ...}
E         Common items:
E         {u'address': u'1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT',
E          u'background-color': u'white',
E          u'description': u'Blogging platform Demo',
E          u'domain': u'Blog.ZeroNetwork.bit',
E          u'files_optional': {u'data/img/zeroblog-comments.png': {u'sha512': u'efe4e815a260e555303e5c49e550a689d27a8361f64667bd4a91dbcccb83d2b4',
E                                                                  u'size': 24001},
E                              u'data/img/zeroid.png': {u'sha512': u'b46d541a9e51ba2ddc8a49955b7debbc3b45fd13467d3c20ef104e9d938d052b',
E                                                       u'size': 18875},
E                              u'data/img/zeroname.png': {u'sha512': u'bab45a1bb2087b64e4f69f756b2ffa5ad39b7fdc48c83609cdde44028a7a155d',
E                                                         u'size': 36031},
E                              u'data/img/zerotalk-mark.png': {u'sha512': u'a335b2fedeb8d291ca68d3091f567c180628e80f41de4331a5feb19601d078af',
E                                                              u'size': 44862},
E                              u'data/img/zerotalk-upvote.png': {u'sha512': u'b1ffd7f948b4f99248dde7efe256c2efdfd997f7e876fb9734f986ef2b561732',
E                                                                u'size': 41092},
E                              u'data/img/zerotalk.png': {u'sha512': u'54d10497a1ffca9a4780092fd1bd158c15f639856d654d2eb33a42f9d8e33cd8',
E                                                         u'size': 26606},
E                              u'data/optional.txt': {u'sha512': u'c6f81db0e9f8206c971c9e5826e3ba823ffbb1a3a900f8047652a8bf78ea98fd',
E                                                     u'size': 6}},
E          u'ignore': u'((js|css)/(?!all.(js|css))|data/.*db|data/users/.*/.*|data/test_include/.*)',
E          u'includes': {u'data/test_include/content.json': {u'added': 1424976057,
E                                                            u'files_allowed': u'data.json',
E                                                            u'includes_allowed': False,
E                                                            u'max_size': 20000,
E                                                            u'signers': [u'15ik6LeBWnACWfaika1xqGapRZ1zh3JpCo'],
E                                                            u'signers_required': 1,
E                                                            u'user_id': 47,
E                                                            u'user_name': u'test'},
E                        u'data/users/content.json': {u'signers': [u'1LSxsKfC9S9TVXGGNSM3vPHjyW82jgCX5f'],
E                                                     u'signers_required': 1}},
E          u'inner_path': u'content.json',
E          u'optional': u'(data/img/zero.*|data/optional.txt)',
E          u'signers_sign': u'HDNmWJHM2diYln4pkdL+qYOvgE7MdwayzeG+xEUZBgp1HtOjBJS+knDEVQsBkjcOPicDG2it1r6R1eQrmogqSP0=',
E          u'signs_required': 1,
E          u'title': u'ZeroBlog'}
E         Differing items:
E         {'files': {'css/all.css': {'sha512': '65ddd3a2071a0f48c34783aa3b1bde4424bdea344630af05a237557a62bd55dc', 'size': 11271... 'data/data.json': {'sha512': '0f2321c905b761a05c360a389e1de149d952b16097c4ccf8310158356e85fb52', 'size': 31126}, ...}} != {'files': {'css/all.css': {'sha512': 'fcca6465c91188993b597a12a3fb75c9cf7a5c9371276ca6c6c014a2809d3ad1', 'size': 11309...'data/data.json': {'sha512': 'a7919a78587627676983978969d6457eb351da51ed1355c588885138baba7b85', 'size': 31369L}, ...}}
E         Full diff:
E         - {u'address': u'1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT',
E         ?              -
E         + {u'address': '1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT',
E         u'background-color': u'white',
E         u'description': u'Blogging platform Demo',
E         u'domain': u'Blog.ZeroNetwork.bit',
E         -  u'files': {u'css/all.css': {u'sha512': u'65ddd3a2071a0f48c34783aa3b1bde4424bdea344630af05a237557a62bd55dc',
E         +  u'files': {'css/all.css': {'sha512': 'fcca6465c91188993b597a12a3fb75c9cf7a5c9371276ca6c6c014a2809d3ad1',
E         -                              u'size': 112710},
E         ?                             --          ^^^
E         +                             'size': 113094L},
E         ?                                       ^ +++
E         -             u'data-default/data.json': {u'sha512': u'3f5c5a220bde41b464ab116cce0bd670dd0b4ff5fe4a73d1dffc4719140038f2',
E         +             'data-default/data.json': {'sha512': '1a11aae6e183f3fb2026763b014047edc933c3a27bfab5da63daecf998f116aa',
E         -                                         u'size': 196},
E         ?                                        --        ^^^
E         +                                        'size': 205L},
E         ?                                                ^^^^
E         -             u'data-default/users/content-default.json': {u'sha512': u'0603ce08f7abb92b3840ad0cf40e95ea0b3ed3511b31524d4d70e88adba83daa',
E         +             'data-default/users/content-default.json': {'sha512': '37b11e263d4f572555f8a1cb27f1d3df27beebf29275152773b9e239092bed63',
E         -                                                          u'size': 679},
E         ?                                                         --        - ^
E         +                                                         'size': 703L},
E         ?                                                                  ^^^
E         -             u'data/data.json': {u'sha512': u'0f2321c905b761a05c360a389e1de149d952b16097c4ccf8310158356e85fb52',
E         +             'data/data.json': {'sha512': 'a7919a78587627676983978969d6457eb351da51ed1355c588885138baba7b85',
E         -                                 u'size': 31126},
E         ?                                --          ^^
E         +                                'size': 31369L},
E         ?                                          ^ ++
E         -             u'data/img/autoupdate.png': {u'sha512': u'd2b4dc8e0da2861ea051c0c13490a4eccf8933d77383a5b43de447c49d816e71',
E         ?             -                            -          -
E         +             'data/img/autoupdate.png': {'sha512': 'd2b4dc8e0da2861ea051c0c13490a4eccf8933d77383a5b43de447c49d816e71',
E         -                                          u'size': 24460},
E         ?                                         --
E         +                                         'size': 24460L},
E         ?                                                      +
E         -             u'data/img/direct_domains.png': {u'sha512': u'5f14b30c1852735ab329b22496b1e2ea751cb04704789443ad73a70587c59719',
E         ?             -                                -          -
E         +             'data/img/direct_domains.png': {'sha512': '5f14b30c1852735ab329b22496b1e2ea751cb04704789443ad73a70587c59719',
E         -                                              u'size': 16185},
E         ?                                             --
E         +                                             'size': 16185L},
E         ?                                                          +
E         -             u'data/img/domain.png': {u'sha512': u'ce87e0831f4d1e95a95d7120ca4d33f8273c6fce9f5bbedf7209396ea0b57b6a',
E         ?             -                        -          -
E         +             'data/img/domain.png': {'sha512': 'ce87e0831f4d1e95a95d7120ca4d33f8273c6fce9f5bbedf7209396ea0b57b6a',
E         -                                      u'size': 11881},
E         ?                                     --
E         +                                     'size': 11881L},
E         ?                                                  +
E         -             u'data/img/memory.png': {u'sha512': u'dd56515085b4a79b5809716f76f267ec3a204be3ee0d215591a77bf0f390fa4e',
E         ?             -                        -          -
E         +             'data/img/memory.png': {'sha512': 'dd56515085b4a79b5809716f76f267ec3a204be3ee0d215591a77bf0f390fa4e',
E         -                                      u'size': 12775},
E         ?                                     --
E         +                                     'size': 12775L},
E         ?                                                  +
E         -             u'data/img/multiuser.png': {u'sha512': u'88e3f795f9b86583640867897de6efc14e1aa42f93e848ed1645213e6cc210c6',
E         ?             -                           -          -
E         +             'data/img/multiuser.png': {'sha512': '88e3f795f9b86583640867897de6efc14e1aa42f93e848ed1645213e6cc210c6',
E         -                                         u'size': 29480},
E         ?                                        --
E         +                                        'size': 29480L},
E         ?                                                     +
E         -             u'data/img/progressbar.png': {u'sha512': u'23d592ae386ce14158cec34d32a3556771725e331c14d5a4905c59e0fe980ebf',
E         ?             -                             -          -
E         +             'data/img/progressbar.png': {'sha512': '23d592ae386ce14158cec34d32a3556771725e331c14d5a4905c59e0fe980ebf',
E         -                                           u'size': 13294},
E         ?                                          --
E         +                                          'size': 13294L},
E         ?                                                       +
E         -             u'data/img/slides.png': {u'sha512': u'1933db3b90ab93465befa1bd0843babe38173975e306286e08151be9992f767e',
E         ?             -                        -          -
E         +             'data/img/slides.png': {'sha512': '1933db3b90ab93465befa1bd0843babe38173975e306286e08151be9992f767e',
E         -                                      u'size': 14439},
E         ?                                     --
E         +                                     'size': 14439L},
E         ?                                                  +
E         -             u'data/img/slots_memory.png': {u'sha512': u'82a250e6da909d7f66341e5b5c443353958f86728cd3f06e988b6441e6847c29',
E         ?             -                              -          -
E         +             'data/img/slots_memory.png': {'sha512': '82a250e6da909d7f66341e5b5c443353958f86728cd3f06e988b6441e6847c29',
E         -                                            u'size': 9488},
E         ?                                           --
E         +                                           'size': 9488L},
E         ?                                                       +
E         -             u'data/img/trayicon.png': {u'sha512': u'e7ae65bf280f13fb7175c1293dad7d18f1fcb186ebc9e1e33850cdaccb897b8f',
E         ?             -                          -          -
E         +             'data/img/trayicon.png': {'sha512': 'e7ae65bf280f13fb7175c1293dad7d18f1fcb186ebc9e1e33850cdaccb897b8f',
E         -                                        u'size': 19040},
E         ?                                       --
E         +                                       'size': 19040L},
E         ?                                                    +
E         -             u'dbschema.json': {u'sha512': u'7b756e8e475d4d6b345a24e2ae14254f5c6f4aa67391a94491a026550fe00df8',
E         +             'dbschema.json': {'sha512': 'a92933be0138624aaf1d14e1c0e4467915b1a1623e48302378031dcfaed35510',
E         -                                u'size': 1529},
E         ?                               --           ^
E         +                               'size': 1582L},
E         ?                                         + ^
E         -             u'img/loading.gif': {u'sha512': u'8a42b98962faea74618113166886be488c09dad10ca47fe97005edc5fb40cc00',
E         ?             -                    -          -
E         +             'img/loading.gif': {'sha512': '8a42b98962faea74618113166886be488c09dad10ca47fe97005edc5fb40cc00',
E         -                                  u'size': 723},
E         ?                                 --
E         +                                 'size': 723L},
E         ?                                            +
E         -             u'index.html': {u'sha512': u'c4039ebfc4cb6f116cac05e803a18644ed70404474a572f0d8473f4572f05df3',
E         +             'index.html': {'sha512': '607317eb5744be5f538b0dc464f6c90dc7a1c2a0e3e00db05cecad86b8e7c556',
E         -                             u'size': 4667},
E         ?                            --         ^^^
E         +                            'size': 4804L},
E         ?                                     ^^^^
E         -             u'js/all.js': {u'sha512': u'034c97535f3c9b3fbebf2dcf61a38711dae762acf1a99168ae7ddc7e265f582c',
E         +             'js/all.js': {'sha512': 'f801cdd7f507a53bb0a8a32e2ce3d54593e47111bf7693c8232722c33809f8aa',
E         -                            u'size': 201178}},
E         ?                           --          ^^ ^
E         +                           'size': 203070L}},
E         ?                                     ^^ ^^
E         -  u'files_optional': {u'data/img/zeroblog-comments.png': {u'sha512': u'efe4e815a260e555303e5c49e550a689d27a8361f64667bd4a91dbcccb83d2b4',
E         ?                      -                                   -          -
E         +  u'files_optional': {'data/img/zeroblog-comments.png': {'sha512': 'efe4e815a260e555303e5c49e550a689d27a8361f64667bd4a91dbcccb83d2b4',
E         -                                                          u'size': 24001},
E         ?                                                         --
E         +                                                         'size': 24001L},
E         ?                                                                      +
E         -                      u'data/img/zeroid.png': {u'sha512': u'b46d541a9e51ba2ddc8a49955b7debbc3b45fd13467d3c20ef104e9d938d052b',
E         ?                      -                        -          -
E         +                      'data/img/zeroid.png': {'sha512': 'b46d541a9e51ba2ddc8a49955b7debbc3b45fd13467d3c20ef104e9d938d052b',
E         -                                               u'size': 18875},
E         ?                                              --
E         +                                              'size': 18875L},
E         ?                                                           +
E         -                      u'data/img/zeroname.png': {u'sha512': u'bab45a1bb2087b64e4f69f756b2ffa5ad39b7fdc48c83609cdde44028a7a155d',
E         ?                      -                          -          -
E         +                      'data/img/zeroname.png': {'sha512': 'bab45a1bb2087b64e4f69f756b2ffa5ad39b7fdc48c83609cdde44028a7a155d',
E         -                                                 u'size': 36031},
E         ?                                                --
E         +                                                'size': 36031L},
E         ?                                                             +
E         -                      u'data/img/zerotalk-mark.png': {u'sha512': u'a335b2fedeb8d291ca68d3091f567c180628e80f41de4331a5feb19601d078af',
E         ?                      -                               -          -
E         +                      'data/img/zerotalk-mark.png': {'sha512': 'a335b2fedeb8d291ca68d3091f567c180628e80f41de4331a5feb19601d078af',
E         -                                                      u'size': 44862},
E         ?                                                     --
E         +                                                     'size': 44862L},
E         ?                                                                  +
E         -                      u'data/img/zerotalk-upvote.png': {u'sha512': u'b1ffd7f948b4f99248dde7efe256c2efdfd997f7e876fb9734f986ef2b561732',
E         ?                      -                                 -          -
E         +                      'data/img/zerotalk-upvote.png': {'sha512': 'b1ffd7f948b4f99248dde7efe256c2efdfd997f7e876fb9734f986ef2b561732',
E         -                                                        u'size': 41092},
E         ?                                                       --
E         +                                                       'size': 41092L},
E         ?                                                                    +
E         -                      u'data/img/zerotalk.png': {u'sha512': u'54d10497a1ffca9a4780092fd1bd158c15f639856d654d2eb33a42f9d8e33cd8',
E         ?                      -                          -          -
E         +                      'data/img/zerotalk.png': {'sha512': '54d10497a1ffca9a4780092fd1bd158c15f639856d654d2eb33a42f9d8e33cd8',
E         -                                                 u'size': 26606},
E         ?                                                --
E         +                                                'size': 26606L},
E         ?                                                             +
E         -                      u'data/optional.txt': {u'sha512': u'c6f81db0e9f8206c971c9e5826e3ba823ffbb1a3a900f8047652a8bf78ea98fd',
E         ?                      -                      -          -
E         +                      'data/optional.txt': {'sha512': 'c6f81db0e9f8206c971c9e5826e3ba823ffbb1a3a900f8047652a8bf78ea98fd',
E         -                                             u'size': 6}},
E         ?                                            --
E         +                                            'size': 6L}},
E         ?                                                     +
E         u'ignore': u'((js|css)/(?!all.(js|css))|data/.*db|data/users/.*/.*|data/test_include/.*)',
E         u'includes': {u'data/test_include/content.json': {u'added': 1424976057,
E         u'files_allowed': u'data.json',
E         u'includes_allowed': False,
E         u'max_size': 20000,
E         u'signers': [u'15ik6LeBWnACWfaika1xqGapRZ1zh3JpCo'],
E         u'signers_required': 1,
E         u'user_id': 47,
E         u'user_name': u'test'},
E         u'data/users/content.json': {u'signers': [u'1LSxsKfC9S9TVXGGNSM3vPHjyW82jgCX5f'],
E         u'signers_required': 1}},
E         -  u'inner_path': u'content.json',
E         ?                 -
E         +  u'inner_path': 'content.json',
E         u'optional': u'(data/img/zero.*|data/optional.txt)',
E         -  u'signers_sign': u'HDNmWJHM2diYln4pkdL+qYOvgE7MdwayzeG+xEUZBgp1HtOjBJS+knDEVQsBkjcOPicDG2it1r6R1eQrmogqSP0=',
E         ?                   -
E         +  u'signers_sign': 'HDNmWJHM2diYln4pkdL+qYOvgE7MdwayzeG+xEUZBgp1HtOjBJS+knDEVQsBkjcOPicDG2it1r6R1eQrmogqSP0=',
E         u'signs_required': 1,
E         u'title': u'ZeroBlog'}
```
 Eliminated version:

```
(env) C:\Users\Oliver\Documents\AeroFS\ZeroNet\ZeroNet [master]> python -m pytest .\src\Test\TestContent.py -k testSign[
content.json]
============================= test session starts =============================
platform win32 -- Python 2.7.9, pytest-2.9.0, py-1.4.31, pluggy-0.3.1 -- C:\Users\Oliver\Documents\AeroFS\ZeroNet\ZeroNet\env\Scripts\python.exe
cachedir: src\Test\.cache
rootdir: C:\Users\Oliver\Documents\AeroFS\ZeroNet\ZeroNet\src\Test, inifile: pytest.ini
collected 8 items

src\Test\TestContent.py::TestContent::testSign[content.json] FAILED

========================== slowest 6 test durations ===========================
0.28s call     TestContent.py::TestContent::testSign[content.json]
0.03s setup    TestContent.py::TestContent::testSign[content.json]
0.00s teardown TestContent.py::TestContent::testSign[content.json]
================================== FAILURES ===================================
_____________________ TestContent.testSign[content.json] ______________________

self = <src.Test.TestContent.TestContent instance at 0x035EF288>
site = <Site 1TeSTv..xQGT>, inner_path = 'content.json'

    @pytest.mark.parametrize("inner_path", ["content.json", "data/test_include/content.json", "data/users/content.json"])
    def testSign(self, site, inner_path):
        # Bad privatekey
        assert not site.content_manager.sign(inner_path, privatekey="5aaa3PvNm5HUWoCfSUfcYvfQ2g3PrRNJWr6Q9eqdBGu23mtMnaa", filewrite=False)

        # Good privatekey
        content = site.content_manager.sign(inner_path, privatekey="5KUh3PvNm5HUWoCfSUfcYvfQ2g3PrRNJWr6Q9eqdBGu23mtMntv", filewrite=False)
        content_old = site.content_manager.contents[inner_path]  # Content before the sign
        assert not content_old == content  # Timestamp changed
        assert site.address in content["signs"]  # Used the site's private key to sign
        if inner_path == "content.json":
            assert len(content["files"]) == 17
        elif inner_path == "data/test-include/content.json":
            assert len(content["files"]) == 1
        elif inner_path == "data/users/content.json":
            assert len(content["files"]) == 0

        # Everything should be same as before except the modified timestamp and the signs
>       assert (
            {key: val for key, val in content_old.items() if key not in ["modified", "signs", "sign", "zeronet_version"]}
            ==
            {key: val for key, val in content.items() if key not in ["modified", "signs", "sign", "zeronet_version"]}
        )
E       assert {'address': '...ork.bit', ...} == {'address': '1...ork.bit', ...}
E         Common items:
E         {u'address': u'1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT',
E          u'background-color': u'white',
E          u'description': u'Blogging platform Demo',
E          u'domain': u'Blog.ZeroNetwork.bit',
E          u'files_optional': {u'data/img/zeroblog-comments.png': {u'sha512': u'efe4e815a260e555303e5c49e550a689d27a8361f64667bd4a91dbcccb83d2b4',
E                                                                  u'size': 24001},
E                              u'data/img/zeroid.png': {u'sha512': u'b46d541a9e51ba2ddc8a49955b7debbc3b45fd13467d3c20ef104e9d938d052b',
E                                                       u'size': 18875},
E         Detailed information truncated (216 more lines), use "-vv" to show

src\Test\TestContent.py:98: AssertionError
---------------------------- Captured stdout setup ----------------------------
DEBUG:Site:1TeSTv..xQGT:New auth key: 2d6f928172505690f21b83be9489cd9a7571d1ecda4546b5eca2c80a90e94dbc
DEBUG:Site:1TeSTv..xQGT:New wrapper key: 62ad3bbd58dae973c222f0ddac5169ee38e1162844cfaf3bc13acf1ed702b172
---------------------------- Captured stdout call -----------------------------
INFO:Site:1TeSTv..xQGT:Opening site data directory: src/Test/testdata/1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT/...
INFO:Site:1TeSTv..xQGT:- [SKIPPED] content.json
INFO:Site:1TeSTv..xQGT:- dbschema.json (SHA512: a92933be0138624aaf1d14e1c0e4467915b1a1623e48302378031dcfaed35510)
INFO:Site:1TeSTv..xQGT:- index.html (SHA512: 607317eb5744be5f538b0dc464f6c90dc7a1c2a0e3e00db05cecad86b8e7c556)
INFO:Site:1TeSTv..xQGT:- css/all.css (SHA512: fcca6465c91188993b597a12a3fb75c9cf7a5c9371276ca6c6c014a2809d3ad1)
INFO:Site:1TeSTv..xQGT:- data/data.json (SHA512: a7919a78587627676983978969d6457eb351da51ed1355c588885138baba7b85)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/optional.txt (SHA512: c6f81db0e9f8206c971c9e5826e3ba823ffbb1a3a900f8047652a8bf78ea98fd)
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/zeroblog.db
INFO:Site:1TeSTv..xQGT:- data/img/autoupdate.png (SHA512: d2b4dc8e0da2861ea051c0c13490a4eccf8933d77383a5b43de447c49d816e71)
INFO:Site:1TeSTv..xQGT:- data/img/direct_domains.png (SHA512: 5f14b30c1852735ab329b22496b1e2ea751cb04704789443ad73a70587c59719)
INFO:Site:1TeSTv..xQGT:- data/img/domain.png (SHA512: ce87e0831f4d1e95a95d7120ca4d33f8273c6fce9f5bbedf7209396ea0b57b6a)
INFO:Site:1TeSTv..xQGT:- data/img/memory.png (SHA512: dd56515085b4a79b5809716f76f267ec3a204be3ee0d215591a77bf0f390fa4e)
INFO:Site:1TeSTv..xQGT:- data/img/multiuser.png (SHA512: 88e3f795f9b86583640867897de6efc14e1aa42f93e848ed1645213e6cc210c6)
INFO:Site:1TeSTv..xQGT:- data/img/progressbar.png (SHA512: 23d592ae386ce14158cec34d32a3556771725e331c14d5a4905c59e0fe980ebf)
INFO:Site:1TeSTv..xQGT:- data/img/slides.png (SHA512: 1933db3b90ab93465befa1bd0843babe38173975e306286e08151be9992f767e)
INFO:Site:1TeSTv..xQGT:- data/img/slots_memory.png (SHA512: 82a250e6da909d7f66341e5b5c443353958f86728cd3f06e988b6441e6847c29)
INFO:Site:1TeSTv..xQGT:- data/img/trayicon.png (SHA512: e7ae65bf280f13fb7175c1293dad7d18f1fcb186ebc9e1e33850cdaccb897b8f)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zeroblog-comments.png (SHA512: efe4e815a260e555303e5c49e550a689d27a8361f64667bd4a91dbcccb83d2b4)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zeroid.png (SHA512: b46d541a9e51ba2ddc8a49955b7debbc3b45fd13467d3c20ef104e9d938d052b)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zeroname.png (SHA512: bab45a1bb2087b64e4f69f756b2ffa5ad39b7fdc48c83609cdde44028a7a155d)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zerotalk-mark.png (SHA512: a335b2fedeb8d291ca68d3091f567c180628e80f41de4331a5feb19601d078af)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zerotalk-upvote.png (SHA512: b1ffd7f948b4f99248dde7efe256c2efdfd997f7e876fb9734f986ef2b561732)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zerotalk.png (SHA512: 54d10497a1ffca9a4780092fd1bd158c15f639856d654d2eb33a42f9d8e33cd8)
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/test_include/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/test_include/data.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1C5sgvWaSgfaTpV5kjBCnCiKtENNMYo69q/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1C5sgvWaSgfaTpV5kjBCnCiKtENNMYo69q/data.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1CjfbrbwtP8Y2QjPy12vpTATkUT7oSiPQ9/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1CjfbrbwtP8Y2QjPy12vpTATkUT7oSiPQ9/data.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1CjfbrbwtP8Y2QjPy12vpTATkUT7oSiPQ9/peanut-butter-jelly-time.gif
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1J6UrZMkarjVg5ax9W4qThir3BFUikbW6C/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1J6UrZMkarjVg5ax9W4qThir3BFUikbW6C/data.json
INFO:Site:1TeSTv..xQGT:- data-default/data.json (SHA512: 1a11aae6e183f3fb2026763b014047edc933c3a27bfab5da63daecf998f116aa)
INFO:Site:1TeSTv..xQGT:- data-default/users/content-default.json (SHA512: 37b11e263d4f572555f8a1cb27f1d3df27beebf29275152773b9e239092bed63)
INFO:Site:1TeSTv..xQGT:- img/loading.gif (SHA512: 8a42b98962faea74618113166886be488c09dad10ca47fe97005edc5fb40cc00)
INFO:Site:1TeSTv..xQGT:- js/all.js (SHA512: f801cdd7f507a53bb0a8a32e2ce3d54593e47111bf7693c8232722c33809f8aa)
DEBUG:Site:1TeSTv..xQGT:Changed files: ['content.json', 'data/img/zeroid.png', 'data/img/zerotalk-upvote.png', 'dbschema.json', 'data/img/zeroblog-comments.png', 'css/all.css', 'data/img/zerotalk.png', 'data-default/data.json', 'js/all.js', 'data/img/zeroname.png', 'data/optional.txt', 'data/data.json', 'index.html', 'data/img/zerotalk-mark.png', 'data-default/users/content-default.json']
INFO:Site:1TeSTv..xQGT:Adding timestamp and sha512sums to new content.json...
INFO:Site:1TeSTv..xQGT:Verifying private key...
ERROR:Site:1TeSTv..xQGT:Private key invalid! Valid signers: ['1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT'], Private key address: False
INFO:Site:1TeSTv..xQGT:Opening site data directory: src/Test/testdata/1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT/...
INFO:Site:1TeSTv..xQGT:- [SKIPPED] content.json
INFO:Site:1TeSTv..xQGT:- dbschema.json (SHA512: a92933be0138624aaf1d14e1c0e4467915b1a1623e48302378031dcfaed35510)
INFO:Site:1TeSTv..xQGT:- index.html (SHA512: 607317eb5744be5f538b0dc464f6c90dc7a1c2a0e3e00db05cecad86b8e7c556)
INFO:Site:1TeSTv..xQGT:- css/all.css (SHA512: fcca6465c91188993b597a12a3fb75c9cf7a5c9371276ca6c6c014a2809d3ad1)
INFO:Site:1TeSTv..xQGT:- data/data.json (SHA512: a7919a78587627676983978969d6457eb351da51ed1355c588885138baba7b85)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/optional.txt (SHA512: c6f81db0e9f8206c971c9e5826e3ba823ffbb1a3a900f8047652a8bf78ea98fd)
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/zeroblog.db
INFO:Site:1TeSTv..xQGT:- data/img/autoupdate.png (SHA512: d2b4dc8e0da2861ea051c0c13490a4eccf8933d77383a5b43de447c49d816e71)
INFO:Site:1TeSTv..xQGT:- data/img/direct_domains.png (SHA512: 5f14b30c1852735ab329b22496b1e2ea751cb04704789443ad73a70587c59719)
INFO:Site:1TeSTv..xQGT:- data/img/domain.png (SHA512: ce87e0831f4d1e95a95d7120ca4d33f8273c6fce9f5bbedf7209396ea0b57b6a)
INFO:Site:1TeSTv..xQGT:- data/img/memory.png (SHA512: dd56515085b4a79b5809716f76f267ec3a204be3ee0d215591a77bf0f390fa4e)
INFO:Site:1TeSTv..xQGT:- data/img/multiuser.png (SHA512: 88e3f795f9b86583640867897de6efc14e1aa42f93e848ed1645213e6cc210c6)
INFO:Site:1TeSTv..xQGT:- data/img/progressbar.png (SHA512: 23d592ae386ce14158cec34d32a3556771725e331c14d5a4905c59e0fe980ebf)
INFO:Site:1TeSTv..xQGT:- data/img/slides.png (SHA512: 1933db3b90ab93465befa1bd0843babe38173975e306286e08151be9992f767e)
INFO:Site:1TeSTv..xQGT:- data/img/slots_memory.png (SHA512: 82a250e6da909d7f66341e5b5c443353958f86728cd3f06e988b6441e6847c29)
INFO:Site:1TeSTv..xQGT:- data/img/trayicon.png (SHA512: e7ae65bf280f13fb7175c1293dad7d18f1fcb186ebc9e1e33850cdaccb897b8f)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zeroblog-comments.png (SHA512: efe4e815a260e555303e5c49e550a689d27a8361f64667bd4a91dbcccb83d2b4)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zeroid.png (SHA512: b46d541a9e51ba2ddc8a49955b7debbc3b45fd13467d3c20ef104e9d938d052b)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zeroname.png (SHA512: bab45a1bb2087b64e4f69f756b2ffa5ad39b7fdc48c83609cdde44028a7a155d)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zerotalk-mark.png (SHA512: a335b2fedeb8d291ca68d3091f567c180628e80f41de4331a5feb19601d078af)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zerotalk-upvote.png (SHA512: b1ffd7f948b4f99248dde7efe256c2efdfd997f7e876fb9734f986ef2b561732)
INFO:Site:1TeSTv..xQGT:- [OPTIONAL] data/img/zerotalk.png (SHA512: 54d10497a1ffca9a4780092fd1bd158c15f639856d654d2eb33a42f9d8e33cd8)
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/test_include/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/test_include/data.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1C5sgvWaSgfaTpV5kjBCnCiKtENNMYo69q/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1C5sgvWaSgfaTpV5kjBCnCiKtENNMYo69q/data.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1CjfbrbwtP8Y2QjPy12vpTATkUT7oSiPQ9/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1CjfbrbwtP8Y2QjPy12vpTATkUT7oSiPQ9/data.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1CjfbrbwtP8Y2QjPy12vpTATkUT7oSiPQ9/peanut-butter-jelly-time.gif
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1J6UrZMkarjVg5ax9W4qThir3BFUikbW6C/content.json
INFO:Site:1TeSTv..xQGT:- [SKIPPED] data/users/1J6UrZMkarjVg5ax9W4qThir3BFUikbW6C/data.json
INFO:Site:1TeSTv..xQGT:- data-default/data.json (SHA512: 1a11aae6e183f3fb2026763b014047edc933c3a27bfab5da63daecf998f116aa)
INFO:Site:1TeSTv..xQGT:- data-default/users/content-default.json (SHA512: 37b11e263d4f572555f8a1cb27f1d3df27beebf29275152773b9e239092bed63)
INFO:Site:1TeSTv..xQGT:- img/loading.gif (SHA512: 8a42b98962faea74618113166886be488c09dad10ca47fe97005edc5fb40cc00)
INFO:Site:1TeSTv..xQGT:- js/all.js (SHA512: f801cdd7f507a53bb0a8a32e2ce3d54593e47111bf7693c8232722c33809f8aa)
DEBUG:Site:1TeSTv..xQGT:Changed files: ['content.json', 'data/img/zeroid.png', 'data/img/zerotalk-upvote.png', 'dbschema.json', 'data/img/zeroblog-comments.png', 'css/all.css', 'data/img/zerotalk.png', 'data-default/data.json', 'js/all.js', 'data/img/zeroname.png', 'data/optional.txt', 'data/data.json', 'index.html', 'data/img/zerotalk-mark.png', 'data-default/users/content-default.json']
INFO:Site:1TeSTv..xQGT:Adding timestamp and sha512sums to new content.json...
INFO:Site:1TeSTv..xQGT:Verifying private key...
INFO:Site:1TeSTv..xQGT:Correct 1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT in valid signers: ['1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT']
INFO:Site:1TeSTv..xQGT:Signing content.json...
INFO:Site:1TeSTv..xQGT:File content.json signed!
============== 7 tests deselected by '-ktestSign[content.json]' ===============
=================== 1 failed, 7 deselected in 0.40 seconds ====================
```
 This has to relate to line endings on Windows. I'll keep digging - can't be a coincidence!

```
content[u'files']['css/all.css']['size'] = {long} 113094
content_old[u'files']['css/all.css']['size'] = {int} 112710
```

```
oli@praxis:~$ python
Python 2.7.3 (default, Jun 22 2015, 19:33:41)
[GCC 4.6.3] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> 113094 - 112710
384
>>>
oli@praxis:~$ wc -l AeroFS/ZeroNet/ZeroNet/src/Test/testdata/1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT/css/all.css
384 AeroFS/ZeroNet/ZeroNet/src/Test/testdata/1TeSTvb4w2PWE81S2rEELgmX2GCCExQGT/css/all.css
```
 Of course - Windows developers need `core.autocrlf = input` as other settings will checkout the `src/Test/testdata` files with CRLF line endings and cause the file size and checksum tests in `TestContent.py::testSign` to fail.

From: http://stackoverflow.com/questions/3206843/how-line-ending-conversions-work-with-git-core-autocrlf-between-different-operat
- _Text files checked-out from the repository will keep original EOL characters in your working tree._
- _Text files in your working tree with CRLF EOL characters are normalized to LF when committed back to the repository._
  This looks like the manager needs to read the control cookie from the file system:
https://github.com/HelloZeroNet/ZeroNet/blob/e891a10e54c31468849ed65892ed97bbb548a534/src/Tor/TorManager.py#L162

Is there a recommended way to get ZeroNet running, with tor, in a container? e.g: both services in a single container or mounting shared filesystems ?
  With the version of gevent in the requirements.txt I get: 

```
Traceback (most recent call last):
  File "zeronet.py", line 15, in main
    import main
  File "src/main.py", line 12, in <module>
    monkey.patch_all(thread=False, subprocess=False)
  File "/home/pi/ZeroNet/env/local/lib/python2.7/site-packages/gevent/monkey.py", line 185, in patch_all
    patch_socket(dns=dns, aggressive=aggressive)
  File "/home/pi/ZeroNet/env/local/lib/python2.7/site-packages/gevent/monkey.py", line 124, in patch_socket
    from gevent import socket
  File "/home/pi/ZeroNet/env/local/lib/python2.7/site-packages/gevent/socket.py", line 659, in <module>
    from gevent.ssl import sslwrap_simple as ssl, SSLError as sslerror, SSLSocket as SSLType
  File "/home/pi/ZeroNet/env/local/lib/python2.7/site-packages/gevent/ssl.py", line 386, in <module>
    def get_server_certificate(addr, ssl_version=PROTOCOL_SSLv3, ca_certs=None):
NameError: name 'PROTOCOL_SSLv3' is not defined
Traceback (most recent call last):
  File "zeronet.py", line 60, in <module>
    main()
  File "zeronet.py", line 46, in main
    traceback.print_exc(file=open("log/error.log", "a"))
IOError: [Errno 2] No such file or directory: 'log/error.log'
```

Updating to version 1.1.0 fixes this (would put in a PR but I'm not sure if this will effect other platforms?)
 > would put in a PR but I'm not sure if this will effect other platforms?

Did you try the ZeroBundle version yet? It should have all dependecies inside the bundle
 @HelloZeroNet 

```
$ python -V
Python 2.7.9
$pip freeze
gevent==1.0.1
greenlet==0.4.9
msgpack-python==0.4.7
```

I guess the difference here is I'm using pip and virtualenv... But that shouldn't make a difference
 @HelloZeroNet 

```
python -c "from gevent import monkey; print 'patch_subprocess' in dir(monkey)"
True
```
 (as I mentioned above updating to 1.1.0 does fix this)
 @HelloZeroNet 
These are from an Rpi v3 model B running raspbian jessie lite heedlessly on a wired connection.  I'm running the benchmark by navigating to http://raspberrypi.local:43110/Benchmark in Chrome on my laptop

```
Benchmarking ZeroNet 0.3.6 (rev989) Python 2.7.9 (default, Mar 8 2015, 00:52:26) [GCC 4.9.2] on: linux2...

CryptBitcoin:
- hdPrivatekey x 10..........0.883s [x0.79: Goodish]
- sign x 10..........0.434s [x0.81: OK]
- openssl verify x 100..........0.647s [x0.57: Goodish]
- pure-python verify x 10..........2.446s [x0.65: Goodish]

CryptHash:
- sha256 5M x 10..........0.815s [x0.74: Goodish]
- sha512 5M x 10..........1.661s [x0.36: Ehh]
- os.urandom(256) x 100 000..........5.640s [x0.12: Sloooow]

Msgpack:
- pack 5K x 10 000..........1.562s [x0.50: Ehh]
- unpack 5K x 10 000..........2.555s [x0.47: Ehh]
- streaming unpack 5K x 10 000..........2.790s [x0.50: Goodish]

Db:
- Open x 10..........1.656s [x0.08: Sloooow]
- Insert x 10 x 1000..........2.506s [x0.40: Ehh]
- Buffered insert x 100 x 100..........3.526s [x0.37: Ehh]
- Total rows in db: 20000
- Indexed query x 1000..........0.429s [x0.58: Goodish]
- Not indexed query x 100..........1.373s [x0.44: Ehh]
- Like query x 100..........3.278s [x0.55: Goodish]

Done. Total: 32.52s
```
  maybe you want to consider a new option; preserve zeromail contact content across al local sites  
 Great option! Lets to it!
 I'm the only one who does not understand why we need a "universal" interface, not just admin/user page on ZeroTalk/ZeroBlog using normal JS?
 wow can someone give me the code for an admin interface on my own page? 
 So a content management system like WordPress, but for ZeroNet sites?
 Is this supposed to be a separate tool or a python plugin with functionality accessible to any website by its owner?
 Instead of using configuration files we can use a simpler component approach.
 This how it would look like for ZeroTalk.

``` coffeescript
window.ZeroTalkAdmin = new ZeroAdmin "ZeroTalkAdmin", {
    "topic": ZeroAdmin.page({title:"Topics", orderby: "added DESC"}, {
        "json_id": ZeroAdmin.user({title: "Username", disabled: 1, save: 0}),
        "added": ZeroAdmin.input({formatter: Date.toDate, deformatter: Date.fromDate}),
        "title": ZeroAdmin.input(),
        "body": ZeroAdmin.textarea(),
        "type": ZeroAdmin.select({values: ["", "group"]}),
        "parent_topic_uri": ZeroAdmin.select({title: "Parent topic", values: ""})
    }),
    "comment": ZeroAdmin.page({title:"Comments", orderby: "added DESC", parent: "topic"}, {
        "json_id": ZeroAdmin.user({title: "Username", disabled: 1, save: 0}),
        "added": ZeroAdmin.input({formatter: Date.toDate, deformatter: Date.fromDate}),
        "body": ZeroAdmin.textarea(),
        "topic_uri": ZeroAdmin.select({title: "Topic", values: ""})
    }), 
    "settings": ZeroAdmin.page({title:"Settings", file: "content.json"}, {
        "settings.admin": ZeroAdmin.input({title: "Admin name"}),
        "settings.href": ZeroAdmin.input({title: "Admin contact url"}),
        "settings.sticky_uris": ZeroAdmin.select({title: "Sticky topic uris", multi: 1, values: ""})
    })
}
```
 Admin Panel tutorials https://www.youtube.com/watch?v=oxGmXOKazw0 https://www.youtube.com/watch?v=SSAQK4Nwkm4&feature=youtu.be https://www.youtube.com/watch?v=mysAB7NAjDk&feature=youtu.be https://www.youtube.com/watch?v=Ct8NKKlsiMM
 How does dbQuery query work? I am currently using timeouts to make sure that data is fetched before proceeding with rendering. Is there a different workaround for this? 

Can the database file be loaded into the site with fileGet? If so it might be a good solution to use sql.js.
 How would I access 'table' variable from within the callback function?

``` coffeescript
        for table in @tables
            Page.cmd "dbQuery", ["SELECT * FROM "+table.name], (res) =>
                @columns[table.name] = res
```

Its value changes to @tables[16] by the time callbacks are called. I need a way to pass it to the function as a parameter maybe.
 I found a few coders on youtube who know about admin panels and I'm contacting them to see if they can help create an admin panel for ZeroNet. I also found some other admin projects on github that might give you some ideas. https://github.com/xkv/PixelAdmin-CN https://github.com/puikinsh/Bootstrap-Admin-Template https://github.com/yogiben/meteor-admin https://github.com/cms-dev/cms https://github.com/guru-digital/frontend-admin
 HelloZeroNet, maybe create an official (empty for now) repository, like for ZeroTalk etc? Would make more sense to discuss things in there.
  I oftem read a GIT history, and it is very comfortable common practice when each commit represents one feature or fix, not multiple.

When I reading your commits I should do extra working to determine what particular feature any line of code relative to.

Pls just commit each feature separately
 Make few commits locally and push them together. If bug found in some local commit (maybe after testing), just use `git rebase -i` to make this commit the last and then amend it. I don't understand your problems.
 You can also commit to other branch ("development"?) and merge to master only when version assigned
  Currently iframe property `sandbox="..., allow-popups"` allows only to open sandboxed windows (tabs), if they opens in any way from script (`<a target="_blank">`, `window.open()`). "sandboxed" means same-origin restriction to parent domain (for AJAX requests and more). It may totally break some sites (external to ZeroNet). Normal links (without `target="_blank"`) is working good for now.

Fast solution: add `allow-popups-to-escape-sandbox` to iframe sandbox attribute. At least it will work in Chrome. Read more [here](https://googlechrome.github.io/samples/allow-popups-to-escape-sandbox/).

Normal solution: Catch windows opening from parent scripts or add API functions to open windows normally
 Can be closed, it was added in: 4d7ce1dc1671256c9700029c83485dfab99a9574
 It's fast solution using nonstandard attribute for Chrome only. This issue awaiting full cross-browser solution: catch window opening from parent frame. Something like this:

``` javascript
var frame = ...;
frame.contentWindow.open = function (url, windowName, windowFeatures) {
    window.open(url, windowName, windowFeatures);
};
```
 @HelloZeroNet Yes, in this case, a zeroframe api command is also perfectly acceptable.
 @vlad20012 It adds complexity, and reduces maintability of ZeroNet to add "uneeded" features, a lot of users know about middle click to open in new tab these days
 @TheNain38 I am developing service for authorization via social networks and need normal `window.open` or any alias (it's not a problem to write `@cmd "openWindow"` instead of `window.open`).

For example, it redirects user to `https://accounts.google.com`, but ZeroNet site should be open to receive cerificate.
 @vlad20012 But it is one to add complexity to a piece of software. If there are other way around, I don't see why there should be added complexity.
 @HelloZeroNet No. I'm speaking about ZeroNet user certificate reception (`@cmd "certAdd"`).
I can also redirect user from external site back to ZeroNet in same tab. Now I am doing so. It looks not very convenient.
 You can add API function and replace window.open in the default ZeroFrame.coffee. It will be transparent for users. If you feel that this is unreasonable, you can close the issue, i'll find another solution. But I think that soon it will be duplicated again.
 [:161](https://github.com/HelloZeroNet/ZeroNet/commit/99f0407ba23707774884cd2ad103914044414587#diff-25ec8dd4ba66e508e805a317bc38fa5fR161) `w = window.open(null, params[1])`
3rd param missing.

```
window.open(strUrl, winName [, winParams])
```

For example

```
Page.cmd("wrapperOpenWindow", "https://github.com", "GitHub", "width=420,height=230")
```
 Now it's working very good. Thank you very much.
  TL;DR: It's almost there, I believe (PyPy 4.0.1 on Linux):

``` sh
$ # Get a fresh copy of ZeroNet
$ git clone https://github.com/HelloZeroNet/ZeroNet
$ cd ZeroNet
$ # Install the msgpack-python and gevent modules
$ # (We already had a working copy of pip and virtualenv)
$ /opt/pypy/bin/pip install -r requirements.txt
$ # Create a virtual environment
$ /opt/pypy/bin/virtualenv venv
$ source venv/bin/activate
(venv) $ python zeronet.py
- Starting ZeroNet...
[18:36:04] - OpenSSL loaded, version: 01000207F
[18:36:05] - Version: 0.3.6 r989, Python 2.7.10 (5f8302b8bf9f, Mar 04 2016, 08:29:09)
[PyPy 4.0.1 with GCC 5.3.0], Gevent: 1.1.0
[18:36:05] - Creating FileServer....
[18:36:05] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 151 > _socket2.py line 228
[18:36:05] - Creating UiServer....
[18:36:05] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[18:36:05] - Removing old SSL certs...
[18:36:05] - Starting servers....
[18:36:05] Ui.UiServer --------------------------------------
[18:36:05] Ui.UiServer Web interface: http://127.0.0.1:43110/
[18:36:05] Ui.UiServer --------------------------------------
[18:36:05] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[18:36:06] FileServer Checking port 15441 using portchecker.co...
[18:36:07] FileServer [OK :)] Port open: Port 15441 is open.
[18:36:10] Ui.UiServer Wrapper key not found: 2948bfa27342bcc0fdabed5de2b53b9eafbce2a2ae5e7db650ab4d8c5bde9c28
[18:36:22] Db:TestDb Table keyvalue outdated...version: False need: 1, rebuilding...
[18:36:22] Db:TestDb Table json outdated...version: 0 need: 1, rebuilding...
[18:36:22] Db:TestDb Table test outdated...version: 0 need: 1426195822, rebuilding...
[18:36:27] - UiWSGIHandler error: OperationalError: database is locked in UiServer.py line 39 > pywsgi.py line 871 > pywsgi.py line 860 > StatsPlugin.py line 547 > Db.py line 119 > Db.py line 89 > Db.py line 60 > DbCursor.py line 53 > _sqlite3.py line 700 > _sqlite3.py line 857 > _sqlite3.py line 795 > _sqlite3.py line 181 > _sqlite3.py line 1026
```

In addition to the locked database as seen above, I also got an `msgpack` exception that I didn't catch when I ran the [benchmark](http://127.0.0.1:43110/Benchmark).

Will try again when PyPy 5.0 reaches ArchLinux.
 Update: ZeroNet also fails on PyPy 5.0. However the benchmarks on PyPy 5.0 (providing Python 2.7.10) compared with those from vanilla Python 2.7.11 on the same machine are interesting:

### PyPy 5.0

```
Benchmarking ZeroNet 0.3.6 (rev989) Python 2.7.10 (246c9cf22037, Mar 11 2016, 12:05:36) [PyPy 5.0.0 with GCC 5.3.0] on: linux2...

CryptBitcoin:
- hdPrivatekey x 10..........0.225s [x3.11: WOW]
- sign x 10..........0.085s [x4.10: Insane!!]
- openssl verify x 100..........0.359s [x1.03: OK]
- pure-python verify x 10..........0.301s [x5.32: Insane!!]

CryptHash:
- sha256 5M x 10..........0.305s [x1.96: Fast]
- sha512 5M x 10..........0.247s [x2.43: Fast]
- os.urandom(256) x 100 000..........1.913s [x0.34: Ehh]

Msgpack:
- pack 5K x 10 000..........
! Error: '\x84\xa3int\xce@\x00\x00\x00\xa5float\xcb@\xc8\x1c\xd6\xe61\xf8\xa1\xa4text\xda\x14\x00hellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohello\xa6binary\xda\x01\x00fqv\xf0\x1a"e\x10,\xbe\x9cT\x9e(\xa5]u\x072C\x8c\x15\xa2\xa8\x93Sw)\x19\x02\xdd\t\xfb\xf67\x88\xd9\xee\x86\xa1\xe4\xb6,\xc6\x14\xbb\xd7$z\x1d\xb2\xda\x85\xf5\xa0\x97^\x01*\xaf\xd3\xb0!\xb7\x9d\xea\x89\xbbh8\xa1"\xa7]e(@\xa2\xa5g\xb7[\xae\x8eE\xc2\x9fL\xb6s\x19\x19\r\xc8\x04S\xd0N\xe4]?/\x01\xea\xf6\xec\xd1\xb3\xc2\x91\x86\xd7\xf4K\xdf\xc2lV\xf4\xe8\x80\xfc\x8ep\xbb\x82\xb3\x86\x98F\x1c\xecS\xc8\x15\xcf\xdc\xf1\xed\xfc\xd8\x18r\xf9\x80\x0f\xfa\x8cO\x97(\x0b]\xf1\xdd\r\xe7\xbf\xed\x06\xbd\x1b?\xc5\xa0\xd7a\x82\xf3\xa8\xe6@\xf3\ri\xa1\xb10\xf6\xd4W\xbc\x86\x1a\xbb\xfd\x94!bS\xdb\xaeM\x92\x00#\x0b\xf7\xad\xe9\xc2\x8e\x86\xbfi![%\xd31]\xc6\xfc2\xc9\xda\xc6v\x82P\xcc\xa9\xea\xb9\xff\xf6\xc8\x17iD\xcf\xf3\xeeI\x04\xe9\xa1\x19\xbb\x01\x92\xf5nn4K\xf8\xbb\xc6\x17e>\xa7 \xbbv'
!=
'\x84\xa3int\xce@\x00\x00\x00\xa4text\xda\x14\x00hellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohellohello\xa5float\xcb@\xc8\x1c\xd6\xe61\xf8\xa1\xa6binary\xda\x01\x00fqv\xf0\x1a"e\x10,\xbe\x9cT\x9e(\xa5]u\x072C\x8c\x15\xa2\xa8\x93Sw)\x19\x02\xdd\t\xfb\xf67\x88\xd9\xee\x86\xa1\xe4\xb6,\xc6\x14\xbb\xd7$z\x1d\xb2\xda\x85\xf5\xa0\x97^\x01*\xaf\xd3\xb0!\xb7\x9d\xea\x89\xbbh8\xa1"\xa7]e(@\xa2\xa5g\xb7[\xae\x8eE\xc2\x9fL\xb6s\x19\x19\r\xc8\x04S\xd0N\xe4]?/\x01\xea\xf6\xec\xd1\xb3\xc2\x91\x86\xd7\xf4K\xdf\xc2lV\xf4\xe8\x80\xfc\x8ep\xbb\x82\xb3\x86\x98F\x1c\xecS\xc8\x15\xcf\xdc\xf1\xed\xfc\xd8\x18r\xf9\x80\x0f\xfa\x8cO\x97(\x0b]\xf1\xdd\r\xe7\xbf\xed\x06\xbd\x1b?\xc5\xa0\xd7a\x82\xf3\xa8\xe6@\xf3\ri\xa1\xb10\xf6\xd4W\xbc\x86\x1a\xbb\xfd\x94!bS\xdb\xaeM\x92\x00#\x0b\xf7\xad\xe9\xc2\x8e\x86\xbfi![%\xd31]\xc6\xfc2\xc9\xda\xc6v\x82P\xcc\xa9\xea\xb9\xff\xf6\xc8\x17iD\xcf\xf3\xeeI\x04\xe9\xa1\x19\xbb\x01\x92\xf5nn4K\xf8\xbb\xc6\x17e>\xa7 \xbbv'
0.143s [x5.46: Insane!!]
- unpack 5K x 10 000..........0.161s [x7.46: Insane!!]
- streaming unpack 5K x 10 000..........0.087s [x16.16: Insane!!]

Db:
- Open x 10
! Error: cannot commit transaction - SQL statements in progress
0.012s [x10.81: Insane!!]
```

### Python 2.7.11

```
Benchmarking ZeroNet 0.3.6 (rev989) Python 2.7.11 (default, Mar 3 2016, 11:00:04) [GCC 5.3.0] on: linux2...

CryptBitcoin:
- hdPrivatekey x 10..........0.267s [x2.62: WOW]
- sign x 10..........0.171s [x2.05: Fast]
- openssl verify x 100..........0.157s [x2.36: Fast]
- pure-python verify x 10..........0.676s [x2.37: Fast]

CryptHash:
- sha256 5M x 10..........0.630s [x0.95: OK]
- sha512 5M x 10..........0.372s [x1.61: Fine]
- os.urandom(256) x 100 000..........2.400s [x0.27: Sloooow]

Msgpack:
- pack 5K x 10 000..........0.569s [x1.37: Fine]
- unpack 5K x 10 000..........0.940s [x1.28: Fine]
- streaming unpack 5K x 10 000..........0.821s [x1.70: Fast]

Db:
- Open x 10..........0.137s [x0.95: OK]
- Insert x 10 x 1000..........1.476s [x0.68: Goodish]
- Buffered insert x 100 x 100..........1.295s [x1.00: OK]
- Total rows in db: 20000
- Indexed query x 1000..........0.193s [x1.29: Fine]
- Not indexed query x 100..........0.544s [x1.10: OK]
- Like query x 100..........0.956s [x1.88: Fast]

Done. Total: 9.86s
```
 PS: The vanilla benchmarks have been seen to take from 7.5 seconds to ~12 seconds on the same machine, so don't read too much from the absolute numbers.
 PyPy 5.4.0 (Python 2.7.10) is out.

ZeroNet starts up well and sites like ZeroHello, ZeroName and ZeroBoard, as well as static sites) works fine. However, visit sites like ZeroTalk, ZeroBlog and ZeroMe, and you get a ton of SQL errors.

Let's call it status quo.
 PyPy 5.6.0 (Python 2.7.12) is out.

This is far worse than with previous versions of PyPy: ZeroNet can't even start:

``` pytb
[22:34:51] - OpenSSL loaded, version: 0100020AF
[22:34:51] - Version: 0.5.0 r1704, Python 2.7.12 (aff251e54385, Nov 12 2016, 22:03:47)
[PyPy 5.6.0 with GCC 6.2.1 20160830], Gevent: 1.1.2
[22:34:51] Db:ContentDb Table keyvalue outdated...version: False need: 3, rebuilding...
[22:34:51] Db:ContentDb Table json outdated...version: 0 need: 3, rebuilding...
[22:34:51] Db:ContentDb Table site outdated...version: 0 need: 1, rebuilding...
[22:34:51] Db:ContentDb Table content outdated...version: 0 need: 1, rebuilding...
[22:34:51] Db:ContentDb Table file_optional outdated...version: 0 need: 11, rebuilding...
[22:34:51] Db:ContentDb Table peer outdated...version: 0 need: 1, rebuilding...
Traceback (most recent call last):
  File "zeronet.py", line 16, in main
    main.start()
  File "src/main.py", line 429, in start
    actions.call(config.action, action_kwargs)
  File "src/main.py", line 129, in call
    func(**kwargs)
  File "src/main.py", line 134, in main
    from File import FileServer
  File "/tmp/pypy2/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "src/File/__init__.py", line 1, in <module>
    from FileServer import FileServer
  File "/tmp/pypy2/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "src/File/FileServer.py", line 12, in <module>
    from Site import SiteManager
  File "/tmp/pypy2/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "src/Site/__init__.py", line 1, in <module>
    from Site import Site
  File "/tmp/pypy2/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "src/Site/Site.py", line 24, in <module>
    from Content import ContentManager
  File "/tmp/pypy2/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "src/Content/__init__.py", line 1, in <module>
    from ContentManager import ContentManager
  File "/tmp/pypy2/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "src/Content/ContentManager.py", line 15, in <module>
    from ContentDbDict import ContentDbDict
  File "/tmp/pypy2/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "src/Content/ContentDbDict.py", line 4, in <module>
    import ContentDb
  File "/tmp/pypy2/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "src/Content/ContentDb.py", line 137, in <module>
    getContentDb()  # Pre-connect to default one
  File "src/Content/ContentDb.py", line 134, in getContentDb
    content_dbs[path] = ContentDb(path)
  File "plugins/PeerDb/PeerDbPlugin.py", line 14, in __init__
    super(ContentDbPlugin, self).__init__(*args, **kwargs)
  File "plugins/OptionalManager/ContentDbPlugin.py", line 28, in __init__
    super(ContentDbPlugin, self).__init__(*args, **kwargs)
  File "src/Content/ContentDb.py", line 14, in __init__
    self.checkTables()
  File "plugins/OptionalManager/ContentDbPlugin.py", line 67, in checkTables
    changed_tables = super(ContentDbPlugin, self).checkTables()
  File "src/Db/Db.py", line 213, in checkTables
    cur.execute("COMMIT")
  File "src/Db/DbCursor.py", line 53, in execute
    res = self.cursor.execute(query)
  File "/opt/pypy/lib_pypy/_sqlite3.py", line 700, in wrapper
    return func(self, *args, **kwargs)
  File "/opt/pypy/lib_pypy/_sqlite3.py", line 857, in execute
    return self.__execute(False, sql, [params])
  File "/opt/pypy/lib_pypy/_sqlite3.py", line 830, in __execute
    raise self.__connection._get_exception(ret)
OperationalError: cannot commit transaction - SQL statements in progress
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/opt/pypy/lib-python/2.7/atexit.py", line 24, in _run_exitfuncs
    func(*targs, **kargs)
  File "plugins/PeerDb/PeerDbPlugin.py", line 84, in saveAllPeers
    for site in self.sites.values():
AttributeError: 'ContentDb' object has no attribute 'sites'
Exception AttributeError: AttributeError("'ContentDb' object has no attribute 'sites'",) in sys.exitfunc == <function _run_exitfuncs at 0x00007f7ce3f70980> ignored
- Starting ZeroNet...
[EXIT]
```
 >  this is expected 

Closing ?  @border0464111,

The [PyPy compatibility page](http://pypy.org/compat.html) reads:

> Please just check if it imports. If it imports, it should work.

And `import sqlite3` yields no errors. Also:

> Supported, but written in pure Python:
> * [â€¦], sqlite3, [â€¦]

So I vote for keeping it open.


  is it possible to add video.js to my blog? how can i divide the all.js to install the video.js? thanks
 But im not trying to host big files, the video source is host outside zeronet but i want to host inside my zeronet page the video player. Isnt it possible?
 so to add video.js to my blog i should create a new js directory? lets asume that will be called video.js (with all the downloaded files). So know, how should i make my blog recognize the video settings and load it?

data/[your site address]
â”œâ”€ js/
â”‚  â””â”€ all.js
â”œâ”€ video.js/
â”‚  â””â”€ all files and subdirectories
â”œâ”€â”€ index.html
â””â”€â”€ content.json

Im trying to load a decent video player with subtitle, track chooser. The default with zeronet configuration doesnt even let me full-screen from the video (i dont want second click and full screen)
 Very helpfull! Thank you!
 I have a little problem, when i run the page with the new script outside zeronet it work perfect! but when i run it with zeronet the option to full-screen doesnt work (it show up but when on-click nothing happens).
 is there any option to bypass the sandboxed iframe? think of a video page where you cant full-screen -.- Can i sacrfice security to enable the full-screen option?
 if you could lunch this feature in future update it would be awesome. thanks for your help!
 Hi, why is the fullscreen option dont working in firefox, but yes in microsoft edge? And subtitles works in firefox but not in M Edge?
  ```
- Starting ZeroNet...
[19:01:18] - OpenSSL loaded, version: 01000204F
[19:01:18] - Version: 0.3.6 r966, Python 2.7.10 (default, Oct 14 2015, 16:09:02)
[GCC 5.2.1 20151010], Gevent: 1.1b1
[19:01:18] - Creating FileServer....
[19:01:18] TorManager Tor controller connect error: AssertionError: Tor version >=0.2.7.5 required, found: 0.2.6.10 in TorManager.py line 156
[19:01:18] - Creating UiServer....
Traceback (most recent call last):
  File "zeronet.py", line 16, in main
    main.start()
  File "src/main.py", line 382, in start
    actions.call(config.action, action_kwargs)
  File "src/main.py", line 112, in call
    func(**kwargs)
  File "src/main.py", line 123, in main
    ui_server = UiServer()
  File "src/Ui/UiServer.py", line 61, in __init__
    self.sites = SiteManager.site_manager.list()
  File "src/Site/SiteManager.py", line 90, in list
    self.load()
  File "plugins/Zeroname/SiteManagerPlugin.py", line 17, in load
    super(SiteManagerPlugin, self).load()
  File "src/Site/SiteManager.py", line 25, in load
    for address in json.load(open("%s/sites.json" % config.data_dir)):
  File "/usr/lib/python2.7/json/__init__.py", line 290, in load
    **kw)
  File "/usr/lib/python2.7/json/__init__.py", line 338, in loads
    return _default_decoder.decode(s)
  File "/usr/lib/python2.7/json/decoder.py", line 369, in decode
    raise ValueError(errmsg("Extra data", s, end, len(s)))
ValueError: Extra data: line 4356 column 2 - line 4356 column 3 (char 147007 - 147008)
```
 the first error msg tells, that you need a newer tor version:
[19:01:18] TorManager Tor controller connect error: AssertionError: Tor version >=0.2.7.5 required, found: 0.2.6.10 in TorManager.py line 156
 Line 4356 was }} so just removed one of } and it works ;) there should be autof for this if doubled  }} at the end of sites.json file
  my blog http://127.0.0.1:43110/17JcQZkstLE9LH5dn49mCQhC6tamZDyi7F/

I see it updated, but my colleagues do not. That will be happening?

$ python zeronet.py siteSign 17JcQZkstLE9LH5dn49mCQhC6tamZDyi7F --publish

Use is command to update
 *_Private key invalid! Valid signers: *_

I get that
 offtopic you need to port some of the services to ZN 
 solved http://127.0.0.1:43110/165eqHdoQfyf7CVGqtVCGNDvMBZhwVSJBL/?Topic:15_1HcK5Hw1rPZeYdgTmqJGrVG2tSyR9Ke2Gt
  $ python zeronet.py --help

  --connected_limit connected_limit
                        Max connected peer per site (default: 15)

:s 

$python zeronet.py --connected_limit 7

it's okay?

I do not understand much
  for some season when i look on /Stats there are some peers that are not TOR, why ?
 are you using the flag: `--tor always`?
 nope, so i need to force tor settings ?
 The default is `enable`, not `always`. I haven't set it up to work tor, so I can't confirm, but it seems like the logical flag to enable the desired behaviour.
  so lets say i want to retake ownership of a zeroblog if i lose my local copy and i still have the secretkey
 so i copy the 
ZeroNet-master/data/user.json 

to

/ZeroNet-master/data/123456789xxxxxxxxx/data/users.json

???
 thats is not relevant to my question then 

i asked how to retake ownership to a blog if i lose the local copy 
  The merging is described as doing the following: 

> Order in which files are merged into all.css/all.js: Files inside subdirectories of the css/js folder comes first; Files in the css/js folder will be merged according to file name ordering (01_a.css, 02_a.css, etc)

The blog, for example would compile in this order:
generated with
`for file_path in findfiles(merge_dir, find_ext):`
&nbsp;&nbsp;&nbsp;&nbsp;`print file_path():` 
and 
`print root, dirs, files` added to `findfiles`

data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/utils [] ['Time.coffee', 'Follow.coffee', 'RateLimit.coffee', 'Text.coffee', 'ZeroFrame.coffee', 'Menu.coffee', 'Class.coffee', 'InlineEditor.coffee']
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/utils/Class.coffee
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/utils/Follow.coffee
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/utils/InlineEditor.coffee
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/utils/Menu.coffee
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/utils/RateLimit.coffee
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/utils/Text.coffee
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/utils/Time.coffee
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/utils/ZeroFrame.coffee
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/lib [] ['highlight.pack.js', 'jquery.cssanim.coffee', 'identicon.js', 'all.js', 'marked.min.js', 'pnglib.js', 'jquery.csslater.coffee', '00-jquery.min.js']
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/lib/00-jquery.min.js
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/lib/highlight.pack.js
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/lib/identicon.js
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/lib/jquery.cssanim.coffee
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/lib/jquery.csslater.coffee
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/lib/marked.min.js
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/lib/pnglib.js
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js ['utils', 'lib'] ['all.js.old', 'all.js', 'Comments.coffee', 'ZeroBlog.coffee']
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/Comments.coffee
data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/js/ZeroBlog.coffee

This puts the the js/utills file before js/lib before js and also break the fact that some of the files in js/utils is dependent on 00-jquery.min.js. Is the intended effect to sort the files regardless of which directory they are from or to sort them as follows?

js
â”œâ”€â”€ lib
â”‚   â”œâ”€â”€ 00-jquery.min.js
â”‚   â”œâ”€â”€ highlight.pack.js
â”‚   â”œâ”€â”€ identicon.js
â”‚   â”œâ”€â”€ jquery.cssanim.coffee
â”‚   â”œâ”€â”€ jquery.csslater.coffee
â”‚   â”œâ”€â”€ marked.min.js
â”‚   â””â”€â”€ pnglib.js
â”œâ”€â”€ utils
â”‚   â”œâ”€â”€ Class.coffee
â”‚   â”œâ”€â”€ Follow.coffee
â”‚   â”œâ”€â”€ InlineEditor.coffee
â”‚   â”œâ”€â”€ Menu.coffee
â”‚   â”œâ”€â”€ RateLimit.coffee
â”‚   â”œâ”€â”€ Text.coffee
â”‚   â”œâ”€â”€ Time.coffee
â”‚   â””â”€â”€ ZeroFrame.coffee
â”œâ”€â”€ Comments.coffee
â””â”€â”€ ZeroBlog.coffee
 After some consideration it seems that it would make more sense to have files go in recursive decent order (sorted on folder names), with the files being listed before the decent which would give an order like this:

```
js
â”œâ”€â”€ 00-lib
â”‚       â”œâ”€â”€ 00-jquery.min.js
â”‚       â”œâ”€â”€ highlight.pack.js
â”‚       â”œâ”€â”€ identicon.js
â”‚       â”œâ”€â”€ jquery.cssanim.coffee
â”‚       â”œâ”€â”€ jquery.csslater.coffee
â”‚       â”œâ”€â”€ marked.min.js
â”‚       â””â”€â”€ pnglib.js
â””â”€â”€ ClassAnimal
            â”œâ”€â”€ Animal.js
            â”œâ”€â”€ ClassMammal
            â”‚        â”œâ”€â”€ Mammal.js
            â”‚        â”œâ”€â”€ ClassCat
            â”‚        |          â”œâ”€â”€ Cat.js
            â”‚        â””â”€â”€ ClassDog
            â”‚                   â””â”€â”€ Dog.js
            â””â”€â”€ ClassReptile
                       â”œâ”€â”€ ClassSnake
                       |         â”œâ”€â”€ Snake.js
                       â””â”€â”€ ClassTurtle
                                 â””â”€â”€ Turtle.js
```

This would allow better management of code with a high level of dependencies.

BTW, I don't mind doing the coding, if there is buy in. 
I am not able to currently compile the js for the ZeroBlog with the code on github, with the current implementation because the order of the dependencies is broken.
 Linux (Arch) Python 2.7.11

On Fri, Mar 18, 2016 at 5:13 PM ZeroNet notifications@github.com wrote:

> can you please specify your platform?
> 
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly or view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/issues/344#issuecomment-198563225
 It works on the ZeroBlog sample. I haven't tested to see how it holds up on nested sub-directories, although I didn't see any official mention on how that would be handled anyways. What is the intended behaviour?
 What if I also have some plugins in js/lib for example?
`js/lib/plugins/jquery.colorbox-min.js`

Is this the correct order?

```
js/lib/00-jquery.min.js
js/lib/highlight.pack.js
js/lib/identicon.js
js/lib/jquery.cssanim.coffee
js/lib/jquery.csslater.coffee
js/lib/marked.min.js
js/lib/pnglib.js
js/lib/plugins/jquery.colorbox-min.js
js/utils/Class.coffee
js/utils/Follow.coffee
js/utils/InlineEditor.coffee
js/utils/Menu.coffee
js/utils/RateLimit.coffee
js/utils/Text.coffee
js/utils/Time.coffee
js/utils/ZeroFrame.coffee
js/Comments.coffee
js/ZeroBlog.coffee
```
 True, but it seems weird that the outermost directory is treated differently than any of the sub-directories.

It seems that `js/Comments.coffee` and `js/ZeroBlog.coffee` would come before any of the files just as all of the `js/lib` files come before the `js/lib/plugins` files. Of course this would break `class ZeroBlog extends ZeroFrame`.
  Site:17JcQZ..yi7F - [ERROR] Only ascii encodes filenames allowed: img/sitio_gran_tamaÃ±o.png
  [![imagebin](http://upimage.mamalibre.com.ar/up/ffa3b067138e8b8f41cbdc844096fa57.png)](http://upimage.mamalibre.com.ar/#ffa3b067138e8b8f41cbdc844096fa57.png)

example site: http://127.0.0.1:43110/191C1ggdcP31gFfTtwxH1CBSycXF7tR8uC (probably all **NSFW**)

2GB size
191C1ggdcP31gFfTtwxH1CBSycXF7tR8uC/data/webm/*.webm

not open the index. that politics is first download everything.

there is when you stop sharing and distribution and is no longer hosting collaborative.
  I use debian 8.3 and I installed Zeronet using the guide written [here](https://github.com/HelloZeroNet/ZeroNet).

I see following error when I start Zeronet:

http://pastebin.com/XWtyvgA4

I see following error on webpage (http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D):

> Connecting...
> Peers found: 32
> content.json download failed
 Benchmark:
http://pastebin.com/RxwGr2Ck

With Bundle:
http://pastebin.com/tB6fRD69

By the way, I am connected to internet via an OpenVPN server. Sorry I forgot mentioning earlier. 
 > and maybe log/debug.log have more detailed information. (you can also send it to me: hello@zeronet.io)

I looked at /var/log but I am not sure which file you need.
 I have sent an email to you with debug.log attached.
 It looks like this error happens when I am connected to VPN. Without VPN I can connect.
 The Errors also looks like a network problem to me, Having it working without the VPN is telling us that the problem is more on the VPN side then Zeronet.   is there any official PPA ? stable /testing PPA ?
 oh that is very sad and bad move, PPA automate the update and make the install extremely easy, this is 2016 so if you want to grow the user base you need to have a PPA maybe you can talk to https://twitter.com/webupd8 to help you with the PPA 
 +1

Should be "easy" enough to implement.

See: http://askubuntu.com/questions/71510/how-do-i-create-a-ppa
 talking to webupb8 to make the PPA can help get even more users if he agrees to make the PPA the website gets allot of traffic 
  Server error
Err: Exception: File not allowed: data/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/index.html in UiServer.py line 81 > UiRequest.py line 82 > UiRequest.py line 211 > UiRequest.py line 285 > SiteStorage.py line 230 > SiteStorage.py line 250
Please report it if you think this an error.
Details:

{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,_/_;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate", 
    "HTTP_ACCEPT_LANGUAGE": "en-US,en;q=0.5", 
    "HTTP_CONNECTION": "keep-alive", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:44.0) Gecko/20100101 Firefox/44.0", 
    "PATH_INFO": "/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
    "QUERY_STRING": "", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "57155", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "1.0.0.127.in-addr.arpa", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.0 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "coffeescript_compiler": null, 
        "config_file": "zeronet.conf", 
        "connected_limit": 15, 
        "data_dir": "data", 
        "debug": false, 
        "debug_socket": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "keep_ssl_cert": false, 
        "log_dir": "log", 
        "max_files_opened": 1024, 
        "msgpack_purepython": true, 
        "open_browser": "default_browser", 
        "proxy": null, 
        "size_limit": 10, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.aletorrenty.pl:2710/announce", 
            "http://explodie.org:6969/announce", 
            "http://torrent.gresille.org/announce"
        ], 
        "trackers_file": false, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false
    }, 
    "plugins": [
        "AnnounceZero", 
        "CryptMessage", 
        "Newsfeed", 
        "Sidebar", 
        "Stats", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.0.2", 
    "version_python": "2.7.11 |Anaconda 2.5.0 (x86_64)| (default, Dec  6 2015, 18:57:58) \n[GCC 4.2.1 (Apple Inc. build 5577)]", 
    "version_zeronet": "0.3.6 r948", 
    "wsgi.url_scheme": "http"
}
 What happens when you just go to:
http://127.0.0.1:43110 
or
http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/
?

the same error ?
 Yes, both URLs get the same error. Also the same error in both Firefox and Chrome.
 Hello, my first post.

I have encountered the same problem, getting the server error.
The solution that worked for me was going though the "hosts" file in the /etc directory. Creating a copy, deleting the content (in my case it was: 127.0.0.1 lmlicenses.wip4.adobe.com, 127.0.0.1 lm.licenses.adobe.com) than replacing the copy with the original. After entering password for authentication and restarting the computer I was able to connect to ZeroNet yet again. 

Hope this will help you out.
 No special characters. It was first extracted to my Downloads folder. I also tried moving it to my Applications folder. The very first time I ran the application, it appeared to work, and then every time after, I get the error, no matter where it's located.
 Here is the contents of log/debug.log
[2016-03-12 18:33:38,171] DEBUG    PluginManager Loading plugin: AnnounceZero
[2016-03-12 18:33:38,179] DEBUG    PluginManager New plugin registered to: Site
[2016-03-12 18:33:38,179] DEBUG    PluginManager Loading plugin: CryptMessage
[2016-03-12 18:33:38,245] DEBUG    - opensslVerify loaded: <CDLL '/usr/lib/libssl.dylib', handle 10185fa30 at 1039595d0>
[2016-03-12 18:33:38,248] INFO     - OpenSSL loaded, version: 0009081DF
[2016-03-12 18:33:38,249] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2016-03-12 18:33:38,249] DEBUG    PluginManager New plugin registered to: User
[2016-03-12 18:33:38,249] DEBUG    PluginManager Loading plugin: Newsfeed
[2016-03-12 18:33:38,250] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2016-03-12 18:33:38,250] DEBUG    PluginManager New plugin registered to: User
[2016-03-12 18:33:38,251] DEBUG    PluginManager Loading plugin: Sidebar
[2016-03-12 18:33:38,258] DEBUG    PluginManager New plugin registered to: UiRequest
[2016-03-12 18:33:38,258] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2016-03-12 18:33:38,258] DEBUG    PluginManager Loading plugin: Stats
[2016-03-12 18:33:38,266] DEBUG    PluginManager New plugin registered to: UiRequest
[2016-03-12 18:33:38,266] DEBUG    PluginManager Loading plugin: Trayicon
[2016-03-12 18:33:38,266] DEBUG    PluginManager Loading plugin: Zeroname
[2016-03-12 18:33:38,268] DEBUG    PluginManager New plugin registered to: UiRequest
[2016-03-12 18:33:38,269] DEBUG    PluginManager New plugin registered to: SiteManager
[2016-03-12 18:33:38,269] DEBUG    - Config: Config(action='main', batch=False, coffeescript_compiler=None, config_file='zeronet.conf', connected_limit=15, data_dir='data', debug=False, debug_gevent=False, debug_socket=False, disable_encryption=False, disable_sslcompression=True, disable_udp=False, fileserver_ip='*', fileserver_port=15441, homepage='1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D', ip_external=None, keep_ssl_cert=False, log_dir='log', max_files_opened=2048, msgpack_purepython=True, open_browser='default_browser', proxy=None, size_limit=10, stream_downloads=False, tor='enable', tor_controller='127.0.0.1:9051', tor_proxy='127.0.0.1:9050', trackers=['zero://boot3rdez4rzn36x.onion:15441', 'zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441', 'udp://tracker.coppersurfer.tk:6969', 'udp://tracker.leechers-paradise.org:6969', 'udp://9.rarbg.com:2710', 'http://tracker.aletorrenty.pl:2710/announce', 'http://explodie.org:6969/announce', 'http://torrent.gresille.org/announce'], trackers_file=False, ui_ip='127.0.0.1', ui_port=43110, ui_restrict=False, use_openssl=True, use_tempfiles=False, verbose=False)
[2016-03-12 18:33:38,269] INFO     - Version: 0.3.6 r1015, Python 2.7.11 |Anaconda 2.5.0 (x86_64)| (default, Dec  6 2015, 18:57:58) 
[GCC 4.2.1 (Apple Inc. build 5577)], Gevent: 1.0.2
[2016-03-12 18:33:38,324] DEBUG    PluginManager New class accepts plugins: SiteManager (Loaded plugins: [<class 'Zeroname.SiteManagerPlugin.SiteManagerPlugin'>, <class 'Site.SiteManager.SiteManager'>])
[2016-03-12 18:33:38,324] DEBUG    PluginManager New class accepts plugins: Site (Loaded plugins: [<class 'AnnounceZero.AnnounceZeroPlugin.SitePlugin'>, <class 'Site.Site.Site'>])
[2016-03-12 18:33:38,334] DEBUG    - Disabled SSL compression on <CDLL '/usr/lib/libssl.dylib', handle 10185fa30 at 103f396d0>
[2016-03-12 18:33:38,347] DEBUG    - Missing SSLwrap, readded.
[2016-03-12 18:33:38,347] DEBUG    - Python SSL version: OpenSSL 1.0.2f  28 Jan 2016
[2016-03-12 18:33:38,379] DEBUG    PluginManager New class accepts plugins: User (Loaded plugins: [<class 'Newsfeed.NewsfeedPlugin.UserPlugin'>, <class 'CryptMessage.CryptMessagePlugin.UserPlugin'>, <class 'User.User.User'>])
[2016-03-12 18:33:38,385] DEBUG    PluginManager New class accepts plugins: UiWebsocket (Loaded plugins: [<class 'Sidebar.SidebarPlugin.UiWebsocketPlugin'>, <class 'Newsfeed.NewsfeedPlugin.UiWebsocketPlugin'>, <class 'CryptMessage.CryptMessagePlugin.UiWebsocketPlugin'>, <class 'Ui.UiWebsocket.UiWebsocket'>])
[2016-03-12 18:33:38,385] DEBUG    PluginManager New class accepts plugins: UiRequest (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.UiRequestPlugin'>, <class 'Stats.StatsPlugin.UiRequestPlugin'>, <class 'Sidebar.SidebarPlugin.UiRequestPlugin'>, <class 'Ui.UiRequest.UiRequest'>])
[2016-03-12 18:33:38,385] INFO     - Creating FileServer....
[2016-03-12 18:33:38,386] DEBUG    TorManager Connecting to 127.0.0.1:9051
[2016-03-12 18:33:38,388] ERROR    TorManager Tor controller connect error: error: [Errno 61] Connection refused in TorManager.py line 151 > socket.py line 344
[2016-03-12 18:33:38,388] DEBUG    TorManager Tor proxy port 127.0.0.1:9050 check error: No connection
[2016-03-12 18:33:38,389] INFO     - Creating UiServer....
[2016-03-12 18:33:38,389] DEBUG    - Loading sites...
[2016-03-12 18:33:38,389] DEBUG    - Added new site: 1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F
[2016-03-12 18:33:38,392] ERROR    Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[2016-03-12 18:33:38,392] DEBUG    Site:1Name2..hM9F New auth key: b8b6fbdc2b2ec0b38adbf50210917241ee2b945028af4180b2653a319b4ac4a7
[2016-03-12 18:33:38,393] DEBUG    Site:1Name2..hM9F New wrapper key: dddf28d57c504b8b53f53dee01503ce2a860455ae013ff004dfb0fe75142e687
[2016-03-12 18:33:38,394] INFO     - Removing old SSL certs...
[2016-03-12 18:33:38,394] INFO     - Starting servers....
[2016-03-12 18:33:38,394] DEBUG    Site:1Name2..hM9F Start downloading, bad_files: {}, check_size: False, blind_includes: True
[2016-03-12 18:33:38,394] DEBUG    Site:1Name2..hM9F Downloading content.json...
[2016-03-12 18:33:38,394] DEBUG    Site:1Name2..hM9F Need content.json first
[2016-03-12 18:33:38,394] DEBUG    WorkerManager:1Name2..hM9F New task: content.json, peer lock: None, priority: 0, optional_hash_id: None, tasks: 1
[2016-03-12 18:33:38,394] INFO     Ui.UiServer --------------------------------------
[2016-03-12 18:33:38,394] INFO     Ui.UiServer Web interface: http://127.0.0.1:43110/
[2016-03-12 18:33:38,394] INFO     Ui.UiServer --------------------------------------
[2016-03-12 18:33:38,394] INFO     - Opening browser: default_browser...
[2016-03-12 18:33:38,538] DEBUG    - Current RLIMIT_NOFILE: 256, changing to 2048...
[2016-03-12 18:33:38,538] ERROR    Ui.UiServer Web interface bind error, must be running already, exiting.... [Errno 48] Address already in use: ('127.0.0.1', 43110)
[2016-03-12 18:33:38,538] DEBUG    Ui.UiServer Stopped.
[2016-03-12 18:33:39,114] DEBUG    - Generating RSA cert and key PEM files...Generating a 2048 bit RSA private key
.......................................................................................................................................+++
.......................................................................................+++
unable to write 'random state'

## writing new private key to 'data/key-rsa.pem'

[2016-03-12 18:33:39,114] DEBUG    FileServer Binding to: *:15441, (msgpack: 0.4.6), supported crypt: ['tls-rsa']
[2016-03-12 18:33:39,114] INFO     FileServer StreamServer bind error, must be running already: [Errno 48] Address already in use: ('', 15441)
[2016-03-12 18:33:39,114] DEBUG    FileServer Stopped.
[2016-03-12 18:33:39,115] DEBUG    Site:1Name2..hM9F Need content.json first

After taking a look at the log, I figured that something else must be running at the port. I used lsof to show anything that was already running on the port. I think I must have been trying to run two instances of ZeroNet at the same time. Thanks for the help.
 @jamesalexanderdickerson You should enclose your logs between three backticks (see [this](https://help.github.com/articles/creating-and-highlighting-code-blocks/))
  Can you add option for tor to use ControlPassword not CookieAuth, maybe thats works better
 Ah, Ubuntu 15.10 latest is Tor 0.2.6.10 (recommended) :D Too lazy togo and build ... thx anyway
  As the title states, the sites.json file is case-sensitive which results in sites being listed multiple times with different capitalization. In turn, this makes the ZeroNet front page list the same site multiple times in the sidebar.
 I have these three entries for the exact same site:
"1Mr5rX9TauvaGReB4RjCaE6D37FJQaY5Ba": {
    [stuff]
  }, 
"1mr5rx9tauvagreb4rjcae6d37fjqay5bA": {
    [stuff]
  }, 
  "1mr5rx9tauvagreb4rjcae6d37fjqay5ba": {
    [stuff]
  }, 

As you can see, the address is identical. And, indeed, when navigating to the site, all three point to the same site. All the same folder. This results in having the site listed 3 times in the sidebar. See the attached image. 

![screen shot 2016-03-07 at 1 08 50 am](https://cloud.githubusercontent.com/assets/4239836/13564814/355091b2-e401-11e5-98b3-202f5355115d.png)

The only difference between them is the case-sensitivity, which is entirely irrelevant it seems when navigating to the site, and managing the site folder. Further, the system doesn't allow me to delete the 'real' one (the one with proper case sensitivity that was generated automatically) due to owning it, however, the other two are freely able to be deleted.

From what I can tell, this happens when you navigate to a site using improper case. I can't imagine this is the intended functionality.

Edit: Try the example on the link you provided. Navigate to '1TaLkFrMwvbNsooF4ioKAY9EuxTBTjipt' (with a lowercase t at the end instead of capital). It'll navigate to the site, create a new entry in sites.json, and have two sites that are functionally identical in the side bar.
  For example

``` coffeescript
@cmd "certAdd", ["zeroid.bit", "atype1", "username", "sign"]
```

Then the user will not be able to register at zeroid.bit.

it is easy to fix: just compare domain name with current in UiWebsocket.actionCertAdd
 Live example: http://127.0.0.1:43110/1G9sW6n1wqhUnoHLKEkycKM8sVgazFvFc
 It is good solution too, but what the problem to add one if statement with comparison domain to site.settings["domain"]?
 What about confirmation dialog if domains not equal (even if cert not exists)?
 I think it's reasonable to add ability to redefine or even delete certificates. Otherwise, services are advised to remove them manually. For example http://127.0.0.1:43110/16KzwuSAjFnivNimSHuRdPrYd1pNPhuHqN
 How did you give authorization to users to your site? I dont understand http://127.0.0.1:43110/16KzwuSAjFnivNimSHuRdPrYd1pNPhuHqN . Is this your private key L21fbJbceebx6B3bwMK2U46W1Un7peLqBtPjfyARZpxsME9rxWFz? You are not using zeronets - zeroid key but manually yours and everybody can see it? So this can implemented as p2p zeroid alternative is it safe (spam resistance, uniqueness)?
 @alxbob It is a question for me? It's not my site. I just learned how it (and zeroID) works. Any authorization service (including zeroID) is only associating username with public key. On "Nanasi text board" you sign the certificate yourself, so anybody can choose any username (one username may be associated with two or more public keys). It is quite useless service because you can work directly with public keys (without usernames) without any authorization service.

"p2p zeroid alternative" - is only blockchain. Look toward Twister http://twister.net.co/
(I don't support this way; think you must either be completely anonymous (without username) or authorized by the central server)
 Extending that maybe users can sign their certificates and username / public key pair could be written/added in a users.json inside the site and checked every time a user tries to create a new certificate to avoid duplication. And later on we can add some proof of burn check to and address using only javascript.
 Can something like that apply to zeronet id?
  ZeroNet used to work great on OS X 10.11.3 with Safari 9.0.3. But since upgrading pip and gevent to the latest versions a couple of minutes ago, I'm getting the python error message "illegal hardware instruction". What's up with that?
 I'd first like to see what the problem is before chickening out. Here's the error report after running it manually in the shell:

Crashed Thread:        0  Dispatch queue: com.apple.main-thread

Exception Type:        EXC_BAD_INSTRUCTION (SIGILL)
Exception Codes:       0x0000000000000001, 0x0000000000000000

Thread 0 Crashed:: Dispatch queue: com.apple.main-thread
0   corecext.so                     0x000000010179ec85 initcorecext + 19669

Thread 0 crashed with X86 Thread State (64-bit):
  rax: 0x00000001017a26d0  rbx: 0x000000010174e390  rcx: 0x000000010173fea8  rdx: 0x000000010173b000
  rdi: 0x0000000000000088  rsi: 0x0000000000000f98  rbp: 0x0000000000000079  rsp: 0x00007fff5ea851f0
   r8: 0x00000001017317e8   r9: 0x00000000ffffff80  r10: 0x0000000000000600  r11: 0x0000000000000000
  r12: 0x00000001017317e8  r13: 0x56004951db03fdb1  r14: 0x0000000101670560  r15: 0x0000000101752b50
  rip: 0x000000010179ec85  rfl: 0x0000000000010202  cr2: 0x000000010179e217

Logical CPU:     0
Error Code:      0x00000000
Trap Number:     6
 Probably. Python (in /usr/local/bin) is 64bit, as the default one installed with OS X. Couldn't find the error. Maybe the gevent update messed it up. 

The OS X bundle doesn't work either. Doesn't connect to ZeroNet when launching the .app directly in Finder, and launching it from the Terminal (zsh) with the open command I get the following error:

LSOpenURLsWithRole() failed with error -10810 for the file /Applications/ZeroNet/ZeroNet.app.
 Ah, found the errorâ€¦ the .app and the included python binary weren't codesigned. I removed them from quarantine, and now it works.
  ```
./zeronet.py --tor always
```

```
- Starting ZeroNet...
[23:14:14] - OpenSSL loaded, version: 01000206F
[23:14:14] - Patching sockets to tor socks proxy: 127.0.0.1:9050
[23:14:14] - Version: 0.3.6 r949, Python 2.7.11+ (default, Feb 22 2016, 16:38:42) 
[GCC 5.3.1 20160220], Gevent: 1.0.1
[23:14:15] - Creating FileServer....
[23:14:15] - Creating UiServer....
[23:14:15] - Removing old SSL certs...
[23:14:15] - Starting servers....
[23:14:15] Ui.UiServer --------------------------------------
[23:14:15] Ui.UiServer Web interface: http://127.0.0.1:43110/
[23:14:15] Ui.UiServer --------------------------------------
[23:14:25] FileServer Checking port 15441 using portchecker.co...
```

When we want to always use Tor, there is no need to check for an open port. Let alone opening a port. That should be avoided.
 But you cannot - and do not try to open a port at the Tor exit, right?

What is the test actually doing? Trying to establish an outgoing connection on that port?
 But if it is always expected to fail, then why not skip test and skip the opening of the port when using `--tor always`?
 this is interesting. do you need to know your public IP for zeronet to work? what do you need it for?
 @HelloZeroNet But in the case of `--tor always` you don't use clearnet IPs, you only use HS, so it doesn't serve any purpose in this case...
 @HelloZeroNet But it is making a connection to a clearnet service, which is bad, because if you use HS, then use them all the way, not on "pretty much" all connections
 well, I don't know the inner workings and I see that strict anonimity may not not a purpose at the moment (AFAICS this is demanded to tor), but one could see traffic analysis issues in making specific connections to a clearnet service. this is the first thing that has come to my mind when I have seen the port checking log entry. but maybe I'm missing something
 @adrelanos

> But if it is always expected to fail, then why not skip test and skip the opening of the port when using --tor always?

@HelloZeroNet 

> because it's returns your external ip (exit node), which is used in some places
> 
> i don't see why is it a problem

It may technically not be a problem, but it is a usability issue. Users get confused about the red "port not open" message. That information is useless to them in such cases. Why not remove it from the web interface when using --tor always?
 ZeroNet:

> > Why not remove it from the web interface when using --tor always?
> 
> It displaying a green "Closed" with the description "Good, your port is always closed when using ZeroNet in Tor always mode." when you are using --tor always

Isn't that redundant? Anything redundant is better removed for better
usability.

At very least I see no reason to have such a less important information
in such a prominent spot.
  I get this error trying to log in:

{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,_/_;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate, sdch", 
    "HTTP_ACCEPT_LANGUAGE": "en-US,en;q=0.8,he-IL;q=0.6,he;q=0.4", 
    "HTTP_HOST": "zero", 
    "HTTP_PROXY_CONNECTION": "keep-alive", 
    "HTTP_REFERER": "http://zero/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D?login=done", 
    "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36", 
    "PATH_INFO": "http://zero/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/", 
    "QUERY_STRING": "login=done&wrapper_nonce=017e99b15b42e59fcebb1390faf5072feaaf8587203acb456dc2e1b2a8367372", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "50953", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "Stone", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.0 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "coffeescript_compiler": "type %s | tools\coffee\coffee.cmd", 
        "config_file": "zeronet.conf", 
        "connected_limit": 15, 
        "data_dir": "data", 
        "debug": false, 
        "debug_socket": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "keep_ssl_cert": false, 
        "log_dir": "log", 
        "max_files_opened": 1024, 
        "msgpack_purepython": true, 
        "open_browser": "default_browser", 
        "proxy": null, 
        "size_limit": 10, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.aletorrenty.pl:2710/announce", 
            "http://explodie.org:6969/announce", 
            "http://torrent.gresille.org/announce"
        ], 
        "trackers_file": false, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false
    }, 
    "plugins": [
        "AnnounceZero", 
        "CryptMessage", 
        "Multiuser", 
        "Newsfeed", 
        "Sidebar", 
        "Stats", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.0.1", 
    "version_python": "2.7.9 (default, Dec 10 2014, 12:24:55) [MSC v.1500 32 bit (Intel)]", 
    "version_zeronet": "0.3.6 r948", 
    "wsgi.url_scheme": "http"
}
  When I open the main zeronet website (using the same account/masterseed, two different computers):

One shows "Welcome to ZeroNet - Let's build a decentralized internet together".
The other instance shows my newsfeed.

(Same URL for both sites: http://zero/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D)

Why does it sometimes work, and sometimes not?
 I think this may be related to MultiUser plugin. I switched from disabled-MultiUser to MultiUser, and I think that switched killed my newsletter / follow list.
 Damn that gives me zeronet.py: error: unrecognized arguments: --multiuser_local on ubuntu ... :/
  - Starting ZeroNet...
  Traceback (most recent call last):
  File "/Users/yoannlamotte/ZeroNet-master/zeronet.py", line 15, in main
    import main
  File "/Users/yoannlamotte/ZeroNet-master/src/main.py", line 79, in <module>
    PluginManager.plugin_manager.loadPlugins()
  File "/Users/yoannlamotte/ZeroNet-master/src/Plugin/PluginManager.py", line 27, in loadPlugins
    for dir_name in os.listdir(self.plugin_path):
  OSError: [Errno 2] No such file or directory: 'plugins'

Where am I supposed to find it? please 
 I have the same files/dirs as in : https://github.com/HelloZeroNet/ZeroNet
 and this problem it not resolve.
 yes, I'm sure.
 thank you.
 yes :)
  OList Reporting server error
  this issue should be closed due to impossibility to reproduce the problem and the lack of information.   With key and sites: 
On ZeroHello we can have button import/export 
 If there was a vulnerability in webUI, then it would be to easy to grab the private keys, this isn't a really good idea...
 but in the future we need that - for example - if you have zero on phone and you want your profile on it. 
 Does it mean new key (and mail) for the phone?
 but what about transfer? qrcode?
 Exposing qrcode has just the same vulnerabilities.

Another option could be wrapping the keys in an downloadable-encrypted file with a temporary password the user would choose just in time. But that would bring unnecessary complexity.

The transference should never be trough web ui.
 Perhaps this would be possible by standing up a server on another port number just for serving this data - wouldn't that fail same origin policy?
 a malware can do the same under the windows
 Backing up your private keys to an off-line storage or to paper should be easy for site administrators. If it is not possible to do it using the WebUI, it should be easy to do using the ZeroNet client user interface. [BIP39](https://github.com/bitcoin/bips/blob/master/bip-0039.mediawiki) makes paper storage easy. We would need password authentication for accessing the private key (#384) as a prerequisite for this issue.
 +1 for BIP39 from cli for backup purpose. 
 +1 for cli, sending passwords across browser should be avoided IMO  What you think about localization for sites in zero network ? 
we can use https://github.com/fnando/i18n-js or https://github.com/i18next/i18next for that
  [12:52:44] Site:1CpGZy..bEzd Announce to 0 trackers in 9.810s, failed
[12:52:45] Site:1MaiL5..Ju27 Announce to 0 trackers in 1.228s, failed
[12:52:46] Site:192dZ1..s4t3 Announce to 0 trackers in 0.078s, failed
[12:52:49] Site:1NJyPo..XcLT Announce to 0 trackers in 1.034s, failed
[12:52:52] Site:1TaLkF..jipT Announce to 0 trackers in 1.819s, failed
[12:53:11] - Unhandled exception
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "plugins/AnnounceZero/AnnounceZeroPlugin.py", line 43, in announceTracker
    tracker_protocol, tracker_address, fileserver_port, add_types, my_peer_id, mode
  File "/Users/Shift/ZeroNet/src/Site/Site.py", line 583, in announceTracker
    tracker = UdpTrackerClient(ip, int(port))
  File "/Users/Shift/ZeroNet/src/lib/subtl/subtl.py", line 42, in __init__
    self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
  File "/usr/local/lib/python2.7/site-packages/gevent/socket.py", line 227, in **init**
    self._sock = _realsocket(family, type, proto)
error: [Errno 24] Too many open files
 MacBook-Pro:Desktop Shift$ ulimit -a
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
file size               (blocks, -f) unlimited
max locked memory       (kbytes, -l) unlimited
max memory size         (kbytes, -m) unlimited
open files                      (-n) 256
pipe size            (512 bytes, -p) 1
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 709
virtual memory          (kbytes, -v) unlimited

MacBook-Pro:Desktop Shift$ python test_max.py 
Max open files without changing settings: 253
Current RLIMIT_NOFILE limit: 256 9223372036854775807 Changing to 3000...
Max open files after changing settings: 2997
 @HelloZeroNet you can only change it from python if you haven't already reached the upper limit (and it seems 1024 was the limit on my box).

I added the following lines to `/etc/security/limits.conf`:

``` sh
*               hard    nofile          8192
*               soft    nofile          4096
```

and

``` ini
LimitNOFILE=8192
```

to the `[Service]` section of the `zeronet.service` file.
 get  it again on 948 

IOError: [Errno 24] Too many open files: 'data/sites.json'
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/gevent/greenlet.py", line 327, in run
  File "/Users/Shift/ZeroNet/src/File/FileServer.py", line 223, in announceSites
  File "/Users/Shift/ZeroNet/src/Site/Site.py", line 707, in announce
  File "/Users/Shift/ZeroNet/src/Site/Site.py", line 93, in saveSettings
IOError: [Errno 24] Too many open files: 'data/sites.json'
[02:21:57] - Unhandled exception
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "/Users/Shift/ZeroNet/src/Site/Site.py", line 280, in update
    self.storage.checkFiles(quick_check=True)  # Quick check and mark bad files based on file size
  File "/Users/Shift/ZeroNet/src/Site/SiteStorage.py", line 334, in checkFiles
  File "/Users/Shift/ZeroNet/src/Site/SiteStorage.py", line 269, in verifyFiles
  File "/Users/Shift/ZeroNet/src/Site/SiteStorage.py", line 248, in getPath
  File "/usr/local/Cellar/python/2.7.10/Frameworks/Python.framework/Versions/2.7/lib/python2.7/posixpath.py", line 362, in abspath
OSError: [Errno 24] Too many open files
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/gevent/greenlet.py", line 327, in run
  File "/Users/Shift/ZeroNet/src/Site/Site.py", line 280, in update
  File "/Users/Shift/ZeroNet/src/Site/SiteStorage.py", line 334, in checkFiles
  File "/Users/Shift/ZeroNet/src/Site/SiteStorage.py", line 269, in verifyFiles
  File "/Users/Shift/ZeroNet/src/Site/SiteStorage.py", line 248, in getPath
  File "/usr/local/Cellar/python/2.7.10/Frameworks/Python.framework/Versions/2.7/lib/python2.7/posixpath.py", line 362, in abspath
OSError: [Errno 24] Too many open files
 i don't sure for now, wait some time...
  This link in README.md is dead
- Download ZeroBundle package that includes Python 2.7.9 and all required libraries
  I just enabled Multiuser plugin, and I'm trying to login with my previous ID from before.

I looked up "auth_privatekey" in users.json (no multiuser).
"auth_privatekey" there has various numbers & uppercase letters.

The private keys for IDs I created while using multiuser look different: different length + all lowercase hex.

It seems like the two private keys use different formats. I am not able to login to my old ID while using multiuser.
 > You need to enter the master_seed from users.json

ZeroID does not handle it though. The only way to pass it to ZeroID is to add it to `users.json` and launch ZeroNet with `--multiuser_local` option.

It is possibly ZeroID issue, so posted it there: https://github.com/HelloZeroNet/ZeroID/issues/6.
  I'm using the multi-user plugin.
Steps to reproduce:
1. Run the bundle
2. An account is created for you. Save the private key.
3. Kill python process (I don't know how to gracefully terminate the bundle)
4. Run the bundle again
5. A new account is created.
6. Choose to login.
7. Paste the private key created in 2.

Bam:

> Forbidden
> 
> Media referrer error
> 
> Please report it if you think this an error.
> 
> Details:
> 
> {
>     "GATEWAY_INTERFACE": "CGI/1.1", 
>     "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,_/_;q=0.8", 
>     "HTTP_ACCEPT_ENCODING": "gzip, deflate, sdch", 
>     "HTTP_ACCEPT_LANGUAGE": "en-US,en;q=0.8,he-IL;q=0.6,he;q=0.4", 
>     "HTTP_HOST": "zero", 
>     "HTTP_PROXY_CONNECTION": "keep-alive", 
>     "HTTP_REFERER": "http://zero/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D?login=done", 
>     "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
>     "HTTP_USER_AGENT": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36", 
>     "PATH_INFO": "http://zero/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/", 
>     "QUERY_STRING": "login=done&wrapper_nonce=71a58fbc7fe0b4a14b46f51fa7401f4a85602bf804982dc5ea91bbbecba249e3", 
>     "REMOTE_ADDR": "127.0.0.1", 
>     "REMOTE_PORT": "51025", 
>     "REQUEST_METHOD": "GET", 
>     "SCRIPT_NAME": "", 
>     "SERVER_NAME": "Lenovo-PC", 
>     "SERVER_PORT": "43110", 
>     "SERVER_PROTOCOL": "HTTP/1.1", 
>     "SERVER_SOFTWARE": "gevent/1.0 Python/2.7", 
>     "arguments": {
>         "action": "main", 
>         "batch": false, 
>         "coffeescript_compiler": "type %s | tools\coffee\coffee.cmd", 
>         "config_file": "zeronet.conf", 
>         "data_dir": "data", 
>         "debug": false, 
>         "debug_socket": false, 
>         "disable_encryption": false, 
>         "disable_sslcompression": true, 
>         "disable_udp": false, 
>         "fileserver_ip": "*", 
>         "fileserver_port": 15441, 
>         "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
>         "ip_external": null, 
>         "keep_ssl_cert": false, 
>         "log_dir": "log", 
>         "msgpack_purepython": true, 
>         "open_browser": "default_browser", 
>         "proxy": null, 
>         "size_limit": 10, 
>         "stream_downloads": false, 
>         "tor": "enable", 
>         "tor_controller": "127.0.0.1:9051", 
>         "tor_proxy": "127.0.0.1:9050", 
>         "trackers": [
>             "zero://boot3rdez4rzn36x.onion:15441", 
>             "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
>             "udp://tracker.coppersurfer.tk:6969", 
>             "udp://tracker.leechers-paradise.org:6969", 
>             "udp://9.rarbg.com:2710", 
>             "http://tracker.aletorrenty.pl:2710/announce", 
>             "http://explodie.org:6969/announce", 
>             "http://torrent.gresille.org/announce"
>         ], 
>         "trackers_file": false, 
>         "ui_ip": "127.0.0.1", 
>         "ui_port": 43110, 
>         "ui_restrict": false, 
>         "use_openssl": true, 
>         "use_tempfiles": false
>     }, 
>     "plugins": [
>         "AnnounceZero", 
>         "CryptMessage", 
>         "Multiuser", 
>         "Newsfeed", 
>         "Sidebar", 
>         "Stats", 
>         "Trayicon", 
>         "Zeroname"
>     ], 
>     "version_gevent": "1.0.1", 
>     "version_python": "2.7.9 (default, Dec 10 2014, 12:24:55) [MSC v.1500 32 bit (Intel)]", 
>     "version_zeronet": "0.3.6 r915", 
>     "wsgi.url_scheme": "http"
> }
 > Kill python process (I don't know how to gracefully terminate the bundle)

![screenshot from 2016-05-09 17 10 22](https://cloud.githubusercontent.com/assets/12672853/15115861/a4fab364-1609-11e6-9870-6d13cbc52f3b.png)
  This is meant to be used by non-technical people eventually right? I'm not sure many non-technical people, even myself as a technical people, are that enthused about installing homebrew, python, dev deps, running arbitrary commands, and then getting the app.
 What app you use for windows? py2app?
 I could probably set up a virtual machine and give you remote access into it - although it would probably be extremely slow
 @HelloZeroNet it works, but you should move Folders (lib,ssl,Python...) inside of .app
 Last 10.11.3 (El Capitan) but for proper test we need clean system without home-brew and python install, on next week i try to install fresh system to virtual machine and try this again
 it does work fine...thank you man!
can you even fix the tor thing.
 On my Mac with Mavericks, the ZeroNet app (v 0.1.1) shows up as a Classic app (eg OS9 days, ca. 1998). Of course, this doesn't run as Classic went the way of the Dodo many years ago.

Any idea how to solve this and why?
 Thanks, I already found that out when I noticed the "app" was only 123 bytes. So I figured it was probably a shell script, but I was puzzled why I couldn't open it for inspection in an editor.

It will throw off newbies, who will all expect to run it as an app tho.

But thanks again for a _very speedy_ reply!
  https://github.com/torproject/tor/issues/5

It would be cool if you could just launch TorClient and do http://zero/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/?Home
  I can not retrieve the user previously created since I closed the session ZeroNet. Is this correct? Now he appears always as "taken".

Regards, Wogker.
http://127.0.0.1:43110/17wdh8t8wV7iVuYeEUgYPHUhkiZfptzVzx
  I'd like ZNet to auto-start whenever I boot my Windows up.

The way to implement this is wrapping the 'executable' (python code) in a Windows service. I'm sure it's quite easy to implement (I've wrapped exes as services before, but not python scripts).
 Is there a systray icon? The version I downloaded two days ago had only a
command line you run manually.
On Mar 4, 2016 2:36 PM, "ZeroNet" notifications@github.com wrote:

> Closed #312 https://github.com/HelloZeroNet/ZeroNet/issues/312.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/issues/312#event-577722097.
  Source "Are you sure you sure?"

Change to: "Are you sure?"

http://prntscr.com/ab13l7
  Hi,

Please add config options to disable the portcheck, Upnp, and browser opening.

I see there is "--open_browser", but no "--dont_open_browser".

Protcheck is useless in my case since behind VPN and will never forward port.

Same goes for UPnP, no way is that ever getting enabled.

I don't need to see this on every start:

> FileServer Checking port 15441 using portchecker.co...
> FileServer [BAD :(] Port closed: Port 15441 is closed.
> FileServer Trying to open port using UpnpPunch...
> FileServer Checking port 15441 using portchecker.co...
> FileServer [BAD :(] Port closed: Port 15441 is closed.
> FileServer Checking port 15441 using canyouseeme.org...
> FileServer [BAD :(] Port closed: Error: I could not see your service on myIP on port (15441) Reason: Connection refused
> FileServer Upnp mapping failed :( Please forward port 15441 on your router to your ipaddress

Thanks,

Will
 > I see there is "--open_browser", but no "--dont_open_browser".

`--open-browser=no|yes`?
 Got ya. I see that now. Yea I was just running the cmd that comes with it.

Was hoping I could just put an option in the config file.

I'll just change how I run it.

All good, thanks.
 Done. Thanks. :)
 Hey i have the same problem, I have a VPN and can not get ZeroNet to run. I am using Raspberry pi 3 (Linux raspberrypi 4.1.19-v7+ #858 SMP Tue Mar 15 15:56:00 GMT 2016 armv7l GNU/Linux
). What can I do to avoid the port error? I am not sure what needs to get edited.
 Well i do ignore it however, ZeroNet opens up and nothing else happens. On my PC ZeroNet shows the menu and etc updating and what not. On the Raspberry Pi it just opens the ZeroNet homepage with no menu, nothing happens no matter how long I wait.
 seems that running zeronet on epiphany browser lead to a dead end. so i switched browsers and boom, not it works! Thanks!
 cool, probably something blocking Javascript indeed, it seem like the issue have been solved for both OP and js-net. Closing ?   I cannot use ZeroNetwork at all now. What should I do?
![untitled](https://cloud.githubusercontent.com/assets/5530653/13514458/cd9192b0-e15d-11e5-96af-0d4d62335861.png)
 I get this all the time in both IE 11 and Chrome 50 dev. on Win 8.1 x64.

Refresh via F5 and it normally goes way. Though some times it takes a few tries.
 I do not.

AntiVirus / AntiMalware / AntiStupid! = My Fingers ;)

I'll do further testing this weekend and see if something else could be causing issues.
 I'm getting the same error, but only with my site.

It's address is [1P9jGD6MBCieqFCHU1777CgyzoZZcnoba2](http://127.0.0.1:43110/1P9jGD6MBCieqFCHU1777CgyzoZZcnoba2)

I think it has to do with dbschema or data/.*/json being mal-formed or 
sql database not in good shape , since i'm still learning how to code dynamic sites in zeronet.

I would love to dig deeper into this problem, but don't know where to look.
Any recommendation ?
 F5 did not help. I got the same error after I restarted ZeroNetwork. I also deleted browser cache, but that had no effect either.

Windows 7 Professional 64bit
Google Chrome Version 48.0.2564.116 m

> Z:\ZeroBundle>Python\python.exe -m zerobundle.run https://github.com/HelloZeroNe
> t/ZeroNet start.py
> Starting ZeroNet/start.py...
> Starting ZeroNet...
> [09:46:09] - OpenSSL loaded, version: 01000201F
> [09:46:11] - Version: 0.3.6 r908, Python 2.7.9 (default, Dec 10 2014, 12:24:55)
> [MSC v.1500 32 bit (Intel)], Gevent: 1.0.1
> [09:46:15] - Creating FileServer....
> [09:46:16] TorManager Tor controller connect error: [Errno 10061] No connection
> could be made because the target machine actively refused it.
> [09:46:16] TorManager Starting Tor client tools/tor/tor.exe...
> [09:46:18] TorManager Tor controller connect error: [Errno 10061] No connection
> could be made because the target machine actively refused it.
> Mar 04 09:46:18.797 [notice] Tor v0.2.7.6 (git-7a489a6389110120) running on Wind
> ows 7 with Libevent 2.0.22-stable, OpenSSL 1.0.1q and Zlib 1.2.8.
> Mar 04 09:46:18.798 [notice] Tor can't help you if you use it wrong! Learn how t
> o be safe at https://www.torproject.org/download/download#warning
> Mar 04 09:46:18.808 [notice] Read configuration file "Z:\ZeroBundle\ZeroNet\tool
> s\tor\torrc".
> Mar 04 09:46:18.811 [warn] Path for GeoIPFile (geoip\geoip) is relative and will
>  resolve to Z:\ZeroBundle\ZeroNet\tools\tor\geoip\geoip. Is this what you wanted
> ?
> Mar 04 09:46:18.811 [warn] Path for GeoIPv6File (geoip\geoip6) is relative and w
> ill resolve to Z:\ZeroBundle\ZeroNet\tools\tor\geoip\geoip6. Is this what you wa
> nted?
> Mar 04 09:46:18.811 [warn] Path for DataDirectory (data) is relative and will re
> solve to Z:\ZeroBundle\ZeroNet\tools\tor\data. Is this what you wanted?
> Mar 04 09:46:18.812 [notice] Opening Socks listener on 127.0.0.1:49050
> Mar 04 09:46:18.812 [notice] Opening Control listener on 127.0.0.1:49051
> Mar 04 09:46:18.000 [notice] Bootstrapped 0%: Starting
> Mar 04 09:46:20.000 [notice] Bootstrapped 80%: Connecting to the Tor network
> Mar 04 09:46:20.000 [notice] New control connection opened from 127.0.0.1.
> [09:46:20] - Creating UiServer....
> Mar 04 09:46:21.000 [notice] Bootstrapped 85%: Finishing handshake with first ho
> p
> Mar 04 09:46:22.000 [notice] Bootstrapped 90%: Establishing a Tor circuit
> Mar 04 09:46:22.000 [notice] Tor has successfully opened a circuit. Looks like c
> lient functionality is working.
> Mar 04 09:46:22.000 [notice] Bootstrapped 100%: Done
> [09:48:08] - Removing old SSL certs...
> [09:48:08] - Starting servers....
> [09:48:08] Ui.UiServer --------------------------------------
> [09:48:08] Ui.UiServer Web interface: http://127.0.0.1:43110/
> [09:48:08] Ui.UiServer --------------------------------------
> [09:48:08] - Opening browser: default_browser...
 The error disappeared when I switched to a different user account on Chrome. How strange...
 Sounds indeed like a cache of some kind then.

Perhaps Click & Clean:

> https://chrome.google.com/webstore/detail/clickclean/ghgabhipcejejjmhhchfonmamedcbeod

May fix it if it happens again.
 I receive it always in google chrome, ZeroNet totally not useable. (But FireFox is OK)

I placed brakepoint at onMessageInner and found that first message looks like
![image](https://cloud.githubusercontent.com/assets/3221931/13591258/f9d70d26-e4f7-11e5-82cb-e0dd8cdfb432.png)
Note: data field is not ZeroNet message at all. WTF is it?

OK, the problem is FriGate extension - popular in Russia anti-censor tool.
Can I expect a fix? We can't force all to disable this extension.
 I talked with friGate developer. He sayed that it's common practice to use message bus in chrome extensions, and application must filter messages. I have also heard complaints against other extensions, not only friGate, so it seems to be true.
 Yep, it's fixed now.
  - Handle exception for invalid dbschema.json files
  Hello, it is possible at the moment to delete a contact from the ZeroMail sidebar ? 

Thanks
 Thanks
 I recreated the issue in zeromail repository 

https://github.com/HelloZeroNet/ZeroMail/issues/21 Closing ? @HelloZeroNet Please close.  I would like to change the Port to whatever I like
 You can run `zeronet.py --ui_port  12345`.

You can see all the config options by running `zeronet.py -h`
 How is this done in Windows with ZeroNet.exe?  Do I need to install Python?  It looks like ZeroNet.exe is a wrapper for python27.dll - so AFAIK - no direct way to call the python script without installing python.  Running "ZeroNet.exe -h" (and --help and /?) doesn't work. N/m, -h doesn't work but --ui_port does with ZeroNet.exe  So i have enabled multiuser as kind of zeronet "proxy", but now anyone can edit seeded sites title (those they do not own) and sites description, is there a way to disable it?
 Oh and now over zeronet forums - https://screencast-o-matic.com/watch/cDeeqi1lyh
  $ python zeronet.py
- Starting ZeroNet...
  .........
  File "zeronet.py", line 46, in main
  traceback.print_exc(file=open("log/error.log", "a"))
  IOError: [Errno 2] No such file or directory: 'log/error.log'

no such dir or file in Zero-master. Where am I supposed to find it?
 OK the log dir is now created. Next prob: 
  File "/Zeronet/src/main.py", line 8, in <module>
    import gevent
ImportError: No module named gevent

where's gevent?
 /usr/bin/python: No module named pip  oups.
 @Wolden 
1. Install `pip` https://pip.pypa.io/en/stable/installing/
2. Install `gevent` `python -m pip install gevent msgpack-python`
3. Make sure you are in the proper working directory when you run `python zeronet.py'

For instance I have my ZeroNet files on my Desktop `/Users/Alexander/Desktop/ZeroNet/ZeroNet-master`. If you are new to navigating through `bash` I would highly recommend Codecademy's [Learn the Command Line](https://www.codecademy.com/learn/learn-the-command-line) tutorial.
 Sorry for being so long ... Everything seems to work perfectly :-) 

Benchmarking ZeroNet 0.3.6 (rev1069) Python 2.7.11 |Anaconda 2.5.0 (x86_64)| (default, Dec 6 2015, 18:57:58) [GCC 4.2.1 (Apple Inc. build 5577)] on: darwin...

Thx so much for all :-)
 I am new to zeronet and am getting the same error using docker.
docker logs 4fc2d61er8e
Traceback (most recent call last):
  File "zeronet.py", line 13, in main
    os.chdir(os.path.dirname(__file__))  # Change working dir to zeronet.py dir
OSError: [Errno 2] No such file or directory: ''
Traceback (most recent call last):
  File "zeronet.py", line 67, in <module>
    main()
  File "zeronet.py", line 51, in main
- Starting ZeroNet...
    traceback.print_exc(file=open("log/error.log", "a"))
IOError: [Errno 2] No such file or directory: 'log/error.log' sweet, it up and working... thanks   I am getting a TorManager add onion error unrecognized ADD_ONION. The web interface works, and i can post, but i dont think my tor is working properly. How can i remedy this. I am on Ubuntu 14.04.

```
metulburr@ubuntu ~/ZeroNet-master $ sudo !!
sudo python zeronet.py 
[sudo] password for metulburr: 
- Starting ZeroNet...
[01:51:08] - OpenSSL loaded, version: 01000106F
[01:51:08] - Version: 0.3.6 r915, Python 2.7.6 (default, Jun 22 2015, 17:58:13) 
[GCC 4.8.2], Gevent: 1.0.2
[01:51:08] - Creating FileServer....
[01:51:08] - Creating UiServer....
[01:51:08] - Removing old SSL certs...
[01:51:08] - Starting servers....
[01:51:08] Ui.UiServer --------------------------------------
[01:51:08] Ui.UiServer Web interface: http://127.0.0.1:43110/
[01:51:08] Ui.UiServer --------------------------------------
[01:51:09] FileServer Checking port 15441 using portchecker.co...
[01:51:10] FileServer [OK :)] Port open: Port 15441 is open.
[01:51:10] TorManager Tor addOnion error: 510 Unrecognized command "ADD_ONION"
```

Based on docs, i see that my tor is not up to the required tor version. 

```
metulburr@ubuntu ~ $ echo 'PROTOCOLINFO' | nc 127.0.0.1 9051
250-PROTOCOLINFO 1
250-AUTH METHODS=COOKIE,SAFECOOKIE COOKIEFILE="/var/run/tor/control.authcookie"
250-VERSION Tor="0.2.4.27"
250 OK

```

and that tor version 2.7.5

I do

```
sudo apt-get update
```

and rerun but get the same error. Most of the docs i find for updating tor is related to the browser in which people just say to redownload, and use the webbrowser. But that does no good for me. 
 You are still using the default tor package that came with trusty. 
http://packages.ubuntu.com/trusty/tor

The apt-get update will just update your package lists as specified in /etc/apt/sources.list if I remember correctly. Haven't used Ubuntu in quite a while.

This might help your problem.
https://www.torproject.org/docs/debian.html.en
select Ubuntu/Trusty > Stable tor version and follow the instructions.
  Hi,

Truly amazed at what you have achieved and the things it can do right now and in the future.  Could you give some consideration to implementing acceptance of IDN .bit names,

É¥sÄ±É¯ÉÉ¥.bit

for example.  

http://127.0.0.1:43110/É¥sÄ±É¯ÉÉ¥.bit responds with:

```
Err: UnicodeDecodeError: 'ascii' codec can't decode byte 0xc9 in position 1: ordinal not in range(128) in UiServer.py line 76 > UiRequest.py line 90 > UiRequest.py line 498
```

Thanks again for returning control to the edge, peer to peer, autonomous networks, so cool.

Hamish.
 That is a poor excuse.

If ZeroNet is to serve a global audience it will need to do better than Morse code in terms of character set.

They are not hard to type by people who use them, and there are sufficient phishing opportunities in 1l O0 etc and indeed people don't even need similarity to be fooled.

You might also like to consider how squatted NMC names are, opening up the full Unicode space may well defeat that.

To complain about phishing and unicode while exploiting torrent and bitcoin protocols and their attendant criminality is lame.

If the goal of ZeroNet was to give users choice, to deny implementation of a service NMC already offers is contrary to that ethos and disappointing in the extreme.
 ASCII homograph attack can be prevented if people are careful, while IDN homograph attack cannot however careful they are :(
I don't know how to distinguish `ÑÐ¾Ñ€.bit` from `cop.bit`, except try googling URL before clicking.

Anyway if ZeroNet will support IDN, it needs at least blacklist like this: http://kb.mozillazine.org/Network.IDN.blacklist_chars
 I'm sure you can distinguish xn--n1aeb.bit from cop.bit, and since ZeroNet doesn't display the unicode version on http://127.0.0.1:43110/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F there isn't much opportunity.

Given the much easier and effective phishing attacks, taking a position of protection against this kind of esoteric quirk is patronising.  I'm not saying it can't be done, but attempting to guard against such attacks by denying choice isn't worth the effort.
 > since ZeroNet doesn't display the unicode version

Then the problem is small. I assumed the browser-like implementaion (most Unicode names are shown in address bar). Thats why they have blacklists and [complex display algorithm](https://wiki.mozilla.org/IDN_Display_Algorithm) that determine which to display, Unicode name or raw punycode.
 This is a duplicate of https://github.com/HelloZeroNet/ZeroNet/issues/131

Issue and PR have been closed, with comment "IDNA domains will not be supported due to security concerns."

It should be closed here too.   Create plugin to auto sitePublish when remote receive git commit ?
 You can do this with git hooks without any plugin:
1. Create a git remote pointing to your zeronet site folder . Don't forget to clean it first.

``` bash
    # Cleaning
    rm -rf ~/zeronet/data/1P9jGD6MBCieqFCHU1777CgyzoZZcnoba2 ;
    git init ~/zeronet/data/1P9jGD6MBCieqFCHU1777CgyzoZZcnoba2 ; 

    cd ~/mySite ;
    git remote add zeronet ~/zeronet/data/1P9jGD6MBCieqFCHU1777CgyzoZZcnoba2 ;
```
1. Create a `post-receive` hook files , and point to your **zeronet site address**

**~/zeronet/data/1P9jGD6MBCieqFCHU1777CgyzoZZcnoba2/.git/hooks/post-receive**

``` bash
ADDRESS=1P98WASDA1829381293

# Get all files
cd ..
GIT_DIR='.git'
umask 002 && git reset --hard

# SiteSign and Publish
echo 'ZeroNet: siteSign and sitePublish'
zeronet siteSign $ADDRESS  --publish
```
1. Ready! Now test using `git push zeronet master`

``` bash
    $ cd ~/mySite
    $ git push zeronet master
Counting objects: 3, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 305 bytes | 0 bytes/s, done.
Total 3 (delta 2), reused 0 (delta 0)
remote: HEAD is now at 7cd3226 Testing hook
remote: ZeroNet: siteSign and sitePublish
remote: - OpenSSL loaded, version: 0009081DF
remote: - Signing site: 1P9jGD6MBCieqFCHU1777CgyzoZZcnoba2...
Private key (input hidden):
remote: Site:1P9jGD..oba2 Opening site data directory: data/1P9jGD6MBCieqFCHU1777CgyzoZZcnoba2/...
remote: Site:1P9jGD..oba2 - [SKIPPED] content.json
remote: Site:1P9jGD..oba2 - dbschema.json (SHA512: 8d2f854f49da2274f2910cbbd459c64114889ec054bc2a5281403069608ab6dc)
remote: Site:1P9jGD..oba2 - index.html (SHA512: 4f17b4c089db199bf32a0c489677918b65a78898a59d33fe0a9385a572cbd047)
remote: Site:1P9jGD..oba2 - Makefile (SHA512: 13a061f7f254295f1bb8f6da6faeddd59fdd4ed6158297999cef68fc05e51c0b)
remote: Site:1P9jGD..oba2 - [SKIPPED] .git/config
remote: Site:1P9jGD..oba2 - [SKIPPED] .git/description
remote: Site:1P9jGD..oba2 - [SKIPPED] .git/refs/heads/master
remote: Site:1P9jGD..oba2 - css/fonts.css (SHA512: b6f94148691a218d2b356f2225d827130264f35bebed995b4a3ce6cffff6cea7)
remote: Site:1P9jGD..oba2 - css/pastie.css (SHA512: 52418309befb7d4c6d382ae5c9259a85c9e849b7faa54be1799366d18da4582b)
remote: Site:1P9jGD..oba2 - css/lib/monokai.css (SHA512: e1811d0440ab59c0a08fa4b837c11415a6a21aba0de8614ff24afbe729f3cbb8)
remote: Site:1P9jGD..oba2 - css/lib/solarized-light.css (SHA512: ed789d816a95b6430f792e2e607b1977ea2bf884cfd73154ca178353d0466c81)
remote: Site:1P9jGD..oba2 - data/head.json (SHA512: 8e42e05b4d855c06a7a2cf7513d88203cbf26c0561aa7afa3c9a82d244e5b269)
remote: Site:1P9jGD..oba2 - img/loading.gif (SHA512: 8a42b98962faea74618113166886be488c09dad10ca47fe97005edc5fb40cc00)
remote: Site:1P9jGD..oba2 - js/in-edit.coffee (SHA512: 8a1817addabcb0b39179b197886874c1b8b485457bd6f530a456613615977a57)
remote: Site:1P9jGD..oba2 - js/model.coffee (SHA512: edf9db5f1c66a5d5493918c8d9c153ec62d526dc60e84f721e1d1ce1d2bc860e)
remote: Site:1P9jGD..oba2 - js/pastie.coffee (SHA512: 978fb4e0bccdb0d8d9dadff7a240024ad48f4c00ae342a219309b00f0b25f458)
remote: Site:1P9jGD..oba2 - js/lib/autosize.js (SHA512: 290402e112101296acbd7190817bd072af840f173961304368b6583b317ef537)
remote: Site:1P9jGD..oba2 - js/lib/Class.coffee (SHA512: 3015ca4162fcd80307fb253db12b5b02ecc96229e1cd2e9f959ee7c67598c13e)
remote: Site:1P9jGD..oba2 - js/lib/highlight.pack.js (SHA512: 2257263ffbebca8c6e771f77d394d5f42a31b369b531b65bba58b6b9a5ed169c)
remote: Site:1P9jGD..oba2 - js/lib/jquery-1.12.1.min.js (SHA512: b5e18a4432083726af300f0759dda2b7de79eb21d6e912ee6b2d71937b3f77ce)
remote: Site:1P9jGD..oba2 - js/lib/lodash.js (SHA512: 62c31067023f512921153e6d5d55a6ab3a838e2095dd08d09e2adc7f3e9f4929)
remote: Site:1P9jGD..oba2 - js/lib/sha1.js (SHA512: c6c991367d1840e93b5fe6f200d89ffbc6fa800c3a12cdb65a197b3871c1b415)
remote: Site:1P9jGD..oba2 - js/lib/ZeroFrame.coffee (SHA512: 061d8ba1c45c6f38d6382470f3a7a0a6f19f16e77f44afbda7509b4e0dbd2361)
remote: Site:1P9jGD..oba2 Creating tables...
remote: Db:zeropastie Table keyvalue outdated...version: False need: 2, rebuilding...
remote: Db:zeropastie Table json outdated...version: 0 need: 2, rebuilding...
remote: Db:zeropastie Table pasties outdated...version: 0 need: 1, rebuilding...
remote: Site:1P9jGD..oba2 Importing data...
remote: Site:1P9jGD..oba2 Imported 0 data file in 0.000151872634888s
remote: Site:1P9jGD..oba2 Adding timestamp and sha512sums to new content.json...
remote: Site:1P9jGD..oba2 Verifying private key...
remote: Site:1P9jGD..oba2 Correct 1P9jGD6MBCieqFCHU1777CgyzoZZcnoba2 in valid signers: ['1P9jGD6MBCieqFCHU1777CgyzoZZcnoba2']
remote: Site:1P9jGD..oba2 Signing content.json...
remote: Site:1P9jGD..oba2 Saving to content.json...
remote: Site:1P9jGD..oba2 File content.json signed!
remote: - Loading site...
remote: - Creating FileServer....
remote: TorManager Tor controller connect error: error: [Errno 61] Connection refused in TorManager.py line 151 > socket.py line 344
remote: FileServer StreamServer bind error, must be running already: [Errno 48] Address already in use: ('', 15441)
remote: - Sending siteReload
remote: - {'to': 1, 'cmd': 'response', 'ok': 'Reloaded'}
remote: - Sending sitePublish
remote: - {'to': 2, 'cmd': 'response', 'ok': 'Successfuly published to 0 peers'}
remote: - Done.
remote: - Starting ZeroNet...
To /Users/frangossauro/workspace/Codes/ZeroNet/data/1P9jGD6MBCieqFCHU1777CgyzoZZcnoba2
   972ddff..7cd3226  master -> master
```

Should we close this issue ?
 Top ! Thank
  ip_restrict params dont work. Syntax ? 

python zeronet.py --ui_restrict "[92.XX.XX.XX]" 
python zeronet.py --ui_restrict "92.XX.XX.XX" 
python zeronet.py --ui_restrict "["92.XX.XX.XX"]"
python zeronet.py --ui_restrict ["92.XX.XX.XX"]
python zeronet.py --ui_restrict [92.XX.XX.XX] 

zeronet.py: error: too few arguments
 @HelloZeroNet @MyTheValentinus 

I have same problem too. The OS is Debian Jessie x64:

```
root@hh16:/var/www/ZeroBundle# ./ZeroNet.sh --verbose --debug --ui_ip 0.0.0.0 --ui_restrict 43.53.63.73
- Starting ZeroNet...
PluginManager Loading plugin: CryptMessage
- opensslVerify loaded: <CDLL '../lib/libcrypto.so', handle 10b27c0 at 7f8599cd8710>
- OpenSSL loaded, version: 01000207F
PluginManager New plugin registered to: UiWebsocket
PluginManager New plugin registered to: User
PluginManager Loading plugin: Newsfeed
PluginManager New plugin registered to: UiWebsocket
PluginManager New plugin registered to: User
PluginManager Loading plugin: Sidebar
PluginManager New plugin registered to: UiRequest
PluginManager New plugin registered to: UiWebsocket
PluginManager Loading plugin: Trayicon
PluginManager Loading plugin: Stats
PluginManager New plugin registered to: UiRequest
PluginManager Loading plugin: AnnounceZero
PluginManager New plugin registered to: Site
PluginManager Loading plugin: Zeroname
PluginManager New plugin registered to: UiRequest
PluginManager New plugin registered to: ConfigPlugin
PluginManager New plugin registered to: SiteManager
PluginManager New class accepts plugins: ConfigPlugin (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.ConfigPlugin'>, <class 'Config.ConfigPlugin'>])
usage: zeronet.py [-h] [--verbose] [--debug] [--debug_socket] [--debug_gevent]
                  [--batch] [--config_file path] [--data_dir path]
                  [--log_dir path] [--ui_ip ip] [--ui_port port]
                  [--ui_restrict [ip [ip ...]]]
                  [--open_browser [browser_name]] [--homepage address]
                  [--size_limit size] [--connected_limit connected_limit]
                  [--fileserver_ip ip] [--fileserver_port port]
                  [--disable_udp] [--proxy ip:port] [--ip_external ip]
                  [--trackers [protocol://address [protocol://address ...]]]
                  [--trackers_file path] [--use_openssl {True,False}]
                  [--disable_db] [--disable_encryption]
                  [--disable_sslcompression {True,False}] [--keep_ssl_cert]
                  [--max_files_opened limit] [--use_tempfiles {True,False}]
                  [--stream_downloads {True,False}]
                  [--msgpack_purepython {True,False}]
                  [--coffeescript_compiler executable_path]
                  [--tor {disable,enable,always}] [--tor_controller ip:port]
                  [--tor_proxy ip:port] [--version] [--bit_resolver address]
                  {main,siteCreate,siteNeedFile,siteDownload,siteSign,sitePublish,siteVerify,dbRebuild,dbQuery,peerPing,peerGetFile,peerCmd,cryptSign}
                  ...
zeronet.py: error: too few arguments
root@hh16:/var/www/ZeroBundle# ./ZeroNet.sh --version
- Starting ZeroNet...
- OpenSSL loaded, version: 01000207F
ZeroNet 0.3.7 r1275
```
 Yeah thanks for the trick "last argument should not be multi-parameter". This simple command is the way:

```
./ZeroNet.sh --ui_restrict 43.53.63.73 --ui_ip 0.0.0.0
```
  Add option to disable ui interface and add options to add zeroSite
 via command line one can do already:
siteCreate, siteSign, sitePublish 

see the docs for more info
 Yes but, add website, curl website etc??
 Yes, this work but to addSite into your list ?
 HUmmmm yes i'm so idiot ! Thank man
 Seem like it been solved, Closing ?  @HelloZeroNet
Please, close the issue.  ui_password params don't work. 
  ```
[21:27:00] FileServer Checking port 15441 using portchecker.co...
[21:27:25] FileServer Update for data/users/removed/content.json looks valid, saving...
[21:27:26] FileServer Update for data/users/removed/content.json looks valid, saving...
[21:27:26] FileServer Update for data/users/removed/content.json looks valid, saving...
[21:27:27] Site:1MaiL5..Ju27 Publishing to 5/71 peers (connected: 12)...
[21:27:28] Site:1MaiL5..Ju27 [OK] 178.60.5.55:15441: File not changed
[21:27:28] Site:1MaiL5..Ju27 [OK] ny27lf76ghxwe6ii.onion:15441: File not changed
[21:27:28] Site:1MaiL5..Ju27 [OK] gqj37ljyvgcj7y7c.onion:15441: File not changed
[21:27:28] Site:1MaiL5..Ju27 [OK] 181.28.60.183:15441: File not changed
[21:27:28] Site:1MaiL5..Ju27 [OK] lzzxlcrdtrsr2a4r.onion:15441: File not changed
[21:27:28] Site:1MaiL5..Ju27 Successfuly published to 5 peers, publishing to 0 more passive peers
[21:27:28] Site:1MaiL5..Ju27 [OK] 37.191.193.9:15441: File not changed
[21:27:28] Site:1MaiL5..Ju27 [OK] 5.101.103.222:15441: File not changed
[21:27:28] Site:1MaiL5..Ju27 [OK] 2.153.143.63:15441: File not changed
[21:27:29] Site:1MaiL5..Ju27 [OK] gek3jkgrs42hsclr.onion:15441: File not changed
Segmentation fault
[user@host ZeroNet-master]$ tail log/debug.log
[2016-03-02 21:27:31,949] DEBUG    Site:1PLAYg..Xvfp Need connections: 3, Current: 4, Total: 83
[2016-03-02 21:27:32,225] DEBUG    WorkerManager:1TaLkF..jipT res62oopsz6fklp2.onion:15441: Someone already working on data/users/removed/data.json, sleeping 1 sec...
[2016-03-02 21:27:32,226] DEBUG    WorkerManager:1TaLkF..jipT 7zlwhd47yefcbkdg.onion:15441: Someone already working on data/users/removed/data.json, sleeping 1 sec...
[2016-03-02 21:27:32,441] DEBUG    Site:1TaLkF..jipT 82.119.233.36:15441 Added peers using pex: 9
[2016-03-02 21:27:32,517] DEBUG    FileServer Removing Conn#21 67.246.182.133 [v2]...
[2016-03-02 21:27:32,699] DEBUG    WorkerManager:1TaLkF..jipT 167.58.168.126:15441: Someone already working on data/users/removed/data.json, sleeping 1 sec...
[2016-03-02 21:27:32,748] DEBUG    WorkerManager:1TaLkF..jipT 47.61.239.226:15441: data/users/removed/data.json, task done after sleep: False
[2016-03-02 21:27:32,795] DEBUG    Site:1TaLkF..jipT 5.150.203.16:15441 Added peers using pex: 9
[2016-03-02 21:27:32,796] DEBUG    Site:1TaLkF..jipT Queried pex from 2 peers got 18 new peers.
[2016-03-02 21:27:34,380] DEBUG    User:removed New encrypt privatekey generated for 1MaiL5gfBM1cyb4a8e3iiL8L5gXmoAJu27:removed
```
 [root@router ~]# rpm -qa | grep -i openssl
openssl-libs-1.0.1e-51.el7_2.4.x86_64
openssl-1.0.1e-51.el7_2.4.x86_64
openssl-devel-1.0.1e-51.el7_2.4.x86_64
[root@router ~]# openssl version
OpenSSL 1.0.1e-fips 11 Feb 2013
[root@router ~]# cat /etc/redhat-release 
CentOS Linux release 7.2.1511 (Core)
 Still segfaults:

[23:17:15] FileServer Update for content.json looks valid, saving...
[23:17:22] Site:1iD5ZQ..duGz Publishing content.json to 3/99 peers (connected: 15)...
[23:17:24] Site:1iD5ZQ..duGz [OK] dnkavwsafa3cpdsg.onion:15441: File not changed 1/3
[23:17:24] Site:1iD5ZQ..duGz [OK] 190.112.67.252:15441: File not changed 2/3
[23:17:25] Site:1iD5ZQ..duGz [OK] iyisg7gas7ewyxkh.onion:15441: File not changed 3/3
[23:17:25] Site:1iD5ZQ..duGz [OK] cyfoop7ypfjg572v.onion:15441: File not changed 4/3
[23:17:25] Site:1iD5ZQ..duGz Successfuly content.json published to 4 peers, publishing to 0 more passive peers
[23:17:26] Site:1iD5ZQ..duGz [OK] ojyllvy2dpr7t4y7.onion:15441: Thanks, file content.json updated! 5/3
../Python/python: line 4:  3451 Segmentation fault      $DIR/python2.7 "$@"
[user@router ZeroBundle]$ tail ./ZeroNet/log/debug.log
[2016-03-05 23:17:48,892] DEBUG    Site:1MaiL5..Ju27 data/users/15jzWzW4jnLaBkQvSBELW5uYMvHsRy8wVz/content.json: Valid signs: 1/1
[2016-03-05 23:17:48,892] DEBUG    WorkerManager:1MaiL5..Ju27 104.244.77.79:15441: Hash correct: data/users/15jzWzW4jnLaBkQvSBELW5uYMvHsRy8wVz/content.json
[2016-03-05 23:17:48,894] DEBUG    Site:1MaiL5..Ju27 Loading json file to db: data/users/15jzWzW4jnLaBkQvSBELW5uYMvHsRy8wVz/content.json
[2016-03-05 23:17:48,897] DEBUG    Site:1MaiL5..Ju27 Bad file solved: data/users/15jzWzW4jnLaBkQvSBELW5uYMvHsRy8wVz/content.json
[2016-03-05 23:17:48,910] DEBUG    Site:1MaiL5..Ju27 Got data/users/15jzWzW4jnLaBkQvSBELW5uYMvHsRy8wVz/content.json
[2016-03-05 23:17:48,915] DEBUG    WorkerManager:1MaiL5..Ju27 New task: data/users/15jzWzW4jnLaBkQvSBELW5uYMvHsRy8wVz/data.json, peer lock: None, priority: 0, optional_hash_id: None, tasks: 2330
[2016-03-05 23:17:48,916] DEBUG    Site:1MaiL5..Ju27 data/users/15jzWzW4jnLaBkQvSBELW5uYMvHsRy8wVz/content.json: Downloading 0 includes...
[2016-03-05 23:17:48,916] DEBUG    Site:1MaiL5..Ju27 data/users/15jzWzW4jnLaBkQvSBELW5uYMvHsRy8wVz/content.json: Includes download ended
[2016-03-05 23:17:48,916] DEBUG    Site:1MaiL5..Ju27 data/users/15jzWzW4jnLaBkQvSBELW5uYMvHsRy8wVz/content.json: Downloading 1 files, changed: 1...
[2016-03-05 23:17:49,112] DEBUG    User:blablabla New encrypt privatekey generated for 1MaiL5gfBM1cyb4a8e3iiL8L5gXmoAJu27:1234567890
 I've got:
[2016-03-05 23:15:16,586] INFO     - OpenSSL load failed: OpenSSL 01000105F (libssl.so.10) EC_KEY_new_by_curve_name failed: None, probably your OpenSSL lib does not support secp256k1 elliptic curve. Please check: https://github.com/HelloZeroNet/ZeroNet/issues/132, falling back to slow bitcoin verify

And:
[2016-03-05 23:15:16,983] DEBUG    - Python SSL version: OpenSSL 1.0.2g  1 Mar 2016
 Tried the latest version and couldn't reproduce the issue. Thanks for the speedy resolution.
  Fix for https://github.com/HelloZeroNet/ZeroNet/issues/291
  client-104-39-6-244:ZeroNet-master Alexander$ python zeronet.py --tor always
-Starting ZeroNet...
[13:05:55] - OpenSSL loaded, version: 0009081DF
[13:05:55] - Patching sockets to tor socks proxy: 127.0.0.1:9050
[13:05:55] - Version: 0.3.6 r915, Python 2.7.11 (default, Jan  7 2016, 18:32:26)
[GCC 4.2.1 Compatible Apple LLVM 7.0.2 (clang-700.1.81)], Gevent: 1.0.2
[13:05:55] - Creating FileServer....
[13:05:55] **TorManager** Tor controller connect error: error: [Errno 61] Connection refused in TorManager.py line 151 > socket.py line 344
[13:05:55] - Creating UiServer....
[13:05:55] - Removing old SSL certs...
[13:05:55] - Starting servers....
[13:05:55] Ui.UiServer --------------------------------------
[13:05:55] Ui.UiServer Web interface: http://127.0.0.1:43110/
[13:05:55] Ui.UiServer -------------------------------------- 
 I ran into this problem. However i am running Ubuntu 14.04. When i go to that link, i have no where else to go but to debian link, whihc in turns says go to ubuntu wiki, which has nothing to do with tor, and is a rundown of what ubuntu is. If i try to carry out those execution i run into errors

```
metulburr@ubuntu ~/ZeroNet-master  $ echo 'deb http://deb.torproject.org/torproject.org jessie main'>> /etc/apt/sources.list.d/tor.list
bash: /etc/apt/sources.list.d/tor.list: Permission denied
metulburr@ubuntu ~/ZeroNet-master  $ sudo !!
sudo echo 'deb http://deb.torproject.org/torproject.org jessie main'>> /etc/apt/sources.list.d/tor.list
bash: /etc/apt/sources.list.d/tor.list: Permission denied
```

and below 

```
metulburr@ubuntu ~/ZeroNet-master  $ deb http://deb.torproject.org/torproject.org trusty main
bash: deb: command not found
metulburr@ubuntu ~/ZeroNet-master  $ gpg --keyserver keys.gnupg.net --recv 886DDD89
gpg: directory `/home/metulburr/.gnupg' created
gpg: new configuration file `/home/metulburr/.gnupg/gpg.conf' created
gpg: WARNING: options in `/home/metulburr/.gnupg/gpg.conf' are not yet active during this run
gpg: keyring `/home/metulburr/.gnupg/secring.gpg' created
gpg: keyring `/home/metulburr/.gnupg/pubring.gpg' created
gpg: requesting key 886DDD89 from hkp server keys.gnupg.net
gpg: /home/metulburr/.gnupg/trustdb.gpg: trustdb created
gpg: key 886DDD89: public key "deb.torproject.org archive signing key" imported
gpg: no ultimately trusted keys found
gpg: Total number processed: 1
gpg:               imported: 1  (RSA: 1)
metulburr@ubuntu ~/ZeroNet-master $ gpg --export A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89 | sudo apt-key add -
OK
metulburr@ubuntu ~/ZeroNet-master $ apt-get install tor deb.torproject.org-keyring
E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)
E: Unable to lock the administration directory (/var/lib/dpkg/), are you root?
metulburr@ubuntu ~/ZeroNet-master  $ sudo !!
sudo apt-get install tor deb.torproject.org-keyring
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: Unable to locate package deb.torproject.org-keyring
E: Couldn't find any package by regex 'deb.torproject.org-keyring'

```

EDIT:

```
metulburr@ubuntu ~/ZeroNet-master  $ deb http://deb.torproject.org/torproject.org trusty main
bash: deb: command not found
metulburr@ubuntu ~/ZeroNet-master  $ gpg --keyserver keys.gnupg.net --recv 886DDD89
gpg: directory `/home/metulburr/.gnupg' created
gpg: new configuration file `/home/metulburr/.gnupg/gpg.conf' created
gpg: WARNING: options in `/home/metulburr/.gnupg/gpg.conf' are not yet active during this run
gpg: keyring `/home/metulburr/.gnupg/secring.gpg' created
gpg: keyring `/home/metulburr/.gnupg/pubring.gpg' created
gpg: requesting key 886DDD89 from hkp server keys.gnupg.net
gpg: /home/metulburr/.gnupg/trustdb.gpg: trustdb created
gpg: key 886DDD89: public key "deb.torproject.org archive signing key" imported
gpg: no ultimately trusted keys found
gpg: Total number processed: 1
gpg:               imported: 1  (RSA: 1)
metulburr@ubuntu ~/ZeroNet-master $ gpg --export A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89 | sudo apt-key add -
OK
metulburr@ubuntu ~/ZeroNet-master $ apt-get install tor deb.torproject.org-keyring
E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)
E: Unable to lock the administration directory (/var/lib/dpkg/), are you root?
metulburr@ubuntu ~/ZeroNet-master  $ sudo !!
sudo apt-get install tor deb.torproject.org-keyring
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: Unable to locate package deb.torproject.org-keyring
E: Couldn't find any package by regex 'deb.torproject.org-keyring'
metulburr@ubuntu ~/ZeroNet-master  $ /etc/init.d/tor restart
 * Checking if tor configuration is valid
Mar 03 01:04:01.191 [notice] Tor v0.2.4.27 (git-412e3f7dc9c6c01a) running on Linux with Libevent 2.0.21-stable and OpenSSL 1.0.1f.
Mar 03 01:04:01.191 [notice] Tor can't help you if you use it wrong! Learn how to be safe at https://www.torproject.org/download/download#warning
Mar 03 01:04:01.191 [notice] Read configuration file "/usr/share/tor/tor-service-defaults-torrc".
Mar 03 01:04:01.191 [notice] Read configuration file "/etc/tor/torrc".
Mar 03 01:04:01.193 [warn] Error setting groups to gid 128: "Operation not permitted".
Mar 03 01:04:01.193 [warn] If you set the "User" option, you must start Tor as root.
Mar 03 01:04:01.194 [warn] Failed to parse/validate config: Problem with User value. See logs for details.
Mar 03 01:04:01.194 [err] Reading config failed--see warnings above.
metulburr@ubuntu ~/ZeroNet-master  $ gpg --keyserver keys.gnupg.net --recv 886DDD89
gpg: requesting key 886DDD89 from hkp server keys.gnupg.net
gpg: key 886DDD89: "deb.torproject.org archive signing key" not changed
gpg: Total number processed: 1
gpg:              unchanged: 1
metulburr@ubuntu ~/ZeroNet-master $ gpg --export A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89 | apt-key add -
ERROR: This command can only be used by root.
metulburr@ubuntu ~/ZeroNet-master  $ sudo !!
sudo gpg --export A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89 | apt-key add -
gpg: WARNING: unsafe ownership on configuration file `/home/metulburr/.gnupg/gpg.conf'
ERROR: This command can only be used by root.
metulburr@ubuntu ~/ZeroNet-master  $ su
Password: 
root@ubuntu:/home/metulburr/ZeroNet-master# gpg --export A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89 | apt-key add -
gpg: directory `/root/.gnupg' created
gpg: new configuration file `/root/.gnupg/gpg.conf' created
gpg: WARNING: options in `/root/.gnupg/gpg.conf' are not yet active during this run
gpg: keyring `/root/.gnupg/secring.gpg' created
gpg: keyring `/root/.gnupg/pubring.gpg' created
gpg: WARNING: nothing exported
gpg: no valid OpenPGP data found.
root@ubuntu:/home/metulburr/ZeroNet-master# apt-get install tor
Reading package lists... Done
Building dependency tree       
Reading state information... Done
tor is already the newest version.
The following packages were automatically installed and are no longer required:
  libp11-kit-gnome-keyring:i386 linux-headers-3.13.0-32
  linux-headers-3.13.0-32-generic linux-image-3.13.0-32-generic
  linux-image-extra-3.13.0-32-generic wine-gecko2.21 wine-gecko2.21:i386
  wine-mono0.0.8
Use 'apt-get autoremove' to remove them.
0 upgraded, 0 newly installed, 0 to remove and 172 not upgraded.
root@ubuntu:/home/metulburr/ZeroNet-master# vim /etc/tor/torrc
root@ubuntu:/home/metulburr/ZeroNet-master# /etc/init.d/tor restart
 * Stopping tor daemon...                                                                          [ OK ] 
 * Starting tor daemon...                                                                          [ OK ] 
root@ubuntu:/home/metulburr/ZeroNet-master# usermod -a -G debian-tor metulburr
root@ubuntu:/home/metulburr/ZeroNet-master# ls -al /var/run/tor/control.authcookie
-rw-r----- 1 debian-tor debian-tor 32 Mar  3 01:06 /var/run/tor/control.authcookie
root@ubuntu:/home/metulburr/ZeroNet-master# su - metulburr
metulburr@ubuntu ~ $ cd ZeroNet-master/
metulburr@ubuntu ~/ZeroNet-master $ python zeronet.py 
- Starting ZeroNet...
Can't lock log/debug.log file, your ZeroNet client is probably already running, exiting... ([Errno 13] Permission denied: 'log/debug.log')
metulburr@ubuntu ~/ZeroNet-master $ sudo !!
sudo python zeronet.py 
- Starting ZeroNet...
[01:09:10] - OpenSSL loaded, version: 01000106F
[01:09:10] - Version: 0.3.6 r915, Python 2.7.6 (default, Jun 22 2015, 17:58:13) 
[GCC 4.8.2], Gevent: 1.0
[01:09:10] - Creating FileServer....
[01:09:10] ConnServer Error: Unsupported msgpack version: (0, 3, 0) (<0.4.0), please run `sudo apt-get install python-pip; sudo pip install msgpack-python --upgrade`

```

now i get the ConnServer Error. I am assuming the tor is working fine with zeronet?!
 Same problem on OS X (El Capitan).  Any ideas for fixing it on a Mac?
- Starting ZeroNet...
  [22:11:09] - OpenSSL loaded, version: 0009081DF
  [22:11:09] - Version: 0.3.6 r915, Python 2.7.11 (default, Jan 22 2016, 08:29:18) 
  [GCC 4.2.1 Compatible Apple LLVM 7.0.2 (clang-700.1.81)], Gevent: 1.0.2
  [22:11:09] - Creating FileServer....
  [22:11:09] TorManager Tor controller connect error: error: [Errno 61] Connection refused in TorManager.py line 151 > socket.py line 344
  [22:11:09] - Creating UiServer....
  [22:11:11] - Removing old SSL certs...
  [22:11:11] - Starting servers....
  [22:11:11] Ui.UiServer --------------------------------------
  [22:11:11] Ui.UiServer Web interface: http://127.0.0.1:43110/
  [22:11:11] Ui.UiServer --------------------------------------
  [22:11:12] FileServer Checking port 15441 using portchecker.co...
  [22:11:13] FileServer [OK :)] Port open: Port 15441 is open.
 @metulburr Following the ZeroNet instructions on how to get Tor running I have had no success. I'm on OSX 10.11 and I've just resorted to running Tor on its own along side it. This won't get it to register through the ZeroNet homepage, but it will still mask your real IP if you did it right. You can check if you did it right here: https://check.torproject.org/

@scottbontrager I don't know how to get it working through the ZeroNet files, but you can always run Tor separately by installing it through [Homebrew](http://brew.sh/) `brew install tor` and then run `tor`. It will give you the the the IP and Port which you can then set as a system wide proxy. As with @metulburr go to https://check.torproject.org/ so you know if you did it correctly.
 @ASBaumgarten Thanks!  Just got it installed and ran it along side.  Unfortunately I got the Big Red X with "Sorry. You are not using Tor.", but I'm new to all this so I'll keep poking around.  Might you be able to point me in the direction of a correctly configured .torrc file?
 @scottbontrager If you have Tor running in Terminal as expected it will be giving you the IP:Port that Tor will work out of. The default is `127.0.0.1:9050`. If you want Tor to run globally go to `System Preferences > Network > Advanced > Proxies > SOCKS Proxy` then enter the IP:Port info in the corresponding boxes. When SOCKS Proxy box has a check-mark your system will try to route all internet traffic through that proxy. When Tor is running this will route all your network traffic through Tor. Just make sure you have the SOCKS Proxy box unchecked when you are done using Tor, otherwise you will only be given errors when trying connect through a browser.
 It says i am not using tor
 @ASBaumgarten **Touchdown!**  Thank you for your help.  Below is my current state and the steps I performed to get here (in case anyone else is interested).

On OS X 10.11.3 I can...
- Visit [https://check.torproject.org](https://check.torproject.org/) in Safari (v9.0.3) and get the Congratulations message
- [ZeroHello](http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D) says "Tor: OK" in the top-right corner of the window
- [YourIP](http://127.0.0.1:43110/1Ey8WR7e3quTdPTMZZKDdqw2U6JG3zvkHe) reports an IP address that is no longer my IP address

By running...
- Tor in one terminal window
- ZeroNet in another terminal window

The steps I followed to get here were...
- Used homebrew to install Tor (`brew install tor`), which installed v0.2.7.6
- Copied the sample torrc file to my home directory (`cp /usr/local/etc/tor/torrc.sample ~/.torrc`)
- Edited my new `.torrc` file and uncommented lines 57 & 61 (`ControlPort 9051` and `CookieAuthentication 1`)
- Started Tor in a terminal window
- Followed @ASBaumgarten's instructions above for configuring my SOCKS Proxy to route through `127.0.0.1:9050`
- Started ZeroNet in another terminal window
 I can run zero net fine when both it and tor are run on my host machine (raspberrypi) but when I use the docker container for zeronet (modifying the "FROM" to something suitable) with a tor docker container I also get this error even if I --link tor_instance:tor_instance and pass --proxy tor_instance:9051and export the port in my tor docker... Any ideas?
 I've managed to make it work (tor + ZeroNet + docker); just see my fork:
- git clone https://github.com/gyulaweber/ZeroNet
- check / update up.sh as necessary (especially the data directory)
- ./up.sh (don't do this if you don't have docker installed)
  and it's up & running & tor is working.
  even faster: docker pull gyulaweber/zeronet_tor

I'm planning to clean up things a bit and create a pull request from it, so feedbacks are warmly welcomed :)

btw, every command to install & setup tor for ZeroNet is in the Dockerfile.
 @HelloZeroNet 
In a Debian tor installation, ZeroNet has no permission to read /var/run/tor/control.authcookie ,
therefore I have to run ZeroNet under root which is really a bad practice
Is there any workaround of this?
(Disable control auth would be fine since they are on the same machine.)
 Got it, thx!
 Seem like everyone have solved his problem here. Closing ?   is it possible to run over https? mean via cloudflare on port 8080
 `nginx`?
 Would be great if ZeroNet included support for https://letsencrypt.org/ built in. :)
 Are you guys talking about HTTPS to the localhost:43110 interface? Not sure what https, Cloudflare or Lets Encrypt add here?
 That's what I'm talking about yes and it would help because I could run it on a server and share it with friends and have it running with a real trusted cert. :)

Or just do what Adguard does. Install your own cert and make it trusted by the computer by default.
 If you use nginx you can use a config like this:

nginx.conf

```
server {
        listen       43110 ssl;
        server_name FQDN;

        include ssl.conf;

        location / {
            proxy_pass http://127.0.0.1:43111;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
   }
```

These three lines (in the above config):

```
proxy_http_version 1.1;
proxy_set_header Upgrade $http_upgrade;
proxy_set_header Connection "upgrade";
```

are required to get the websocket connection to work.

ssl.conf

```
ssl_certificate                 /etc/letsencrypt/live/FQDN/fullchain.pem;
ssl_certificate_key             /etc/letsencrypt/live/FQDN/privkey.pem;
ssl_trusted_certificate         /etc/letsencrypt/live/FQDN/fullchain.pem;
```

You may want to check out [https://mozilla.github.io/server-side-tls/ssl-config-generator/](https://mozilla.github.io/server-side-tls/ssl-config-generator/) for other recommended ssl parameters.

As you may have noticed, nginx is listening to port 43110 and ZeroNet is listening on port 43111, which can be invoked with `zeronet.py --ui_port 43111`
 Lots of ZeroNet gateways are running HTTPS now. Instead of using a self-signed certificate, the gateways have domain names and use certificates from Let's Encrypt. Closing? @bim9262 I try it but it's not work.
`nginx version: nginx/1.10.3 (Ubuntu)`
```
server {
        listen 80 default_server;
        listen [::]:80 default_server;

        add_header Strict-Transport-Security max-age=604800;

        return 301 https://$host$request_uri;
}

server {
        listen 443 ssl default_server;
        listen [::]:443 ssl default_server;

        server_name _;

        ssl on;
        ssl_certificate /root/ZeroBundle/ssl/zeronet.crt;
        ssl_certificate_key /root/ZeroBundle/ssl/zeronet.key;

        client_max_body_size 0;

        location / {
                proxy_pass http://127.0.0.1:43110;
                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection "upgrade";
                proxy_set_header Host $host;

                proxy_set_header X-Scheme $scheme;
                proxy_set_header X-Real-IP $remote_addr;

                proxy_set_header X-Forwarded-Proto $scheme;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Port $server_port;
        }
}
```
always like this
![image](https://user-images.githubusercontent.com/5987706/30914584-c2af0af8-a3c6-11e7-95e1-0f29f0c5e9c5.png)

anyone can help me ?  @HelloZeroNet I can open it via `https://192.168.163.20` now

``` zeronet.conf
[global]
ui_ip = *
ui_port = 43110
ui_host = 192.168.163.20
```

but when I set router NAT the port from WAN to LAN, it's can't open again, and I try to set the `zeronet.conf` make `ui_host = 192.168.163.20 192.168.1.163`, but it's not work with multiple ips, so, it can support multiple ips? If it can do it, what is the right format set the `ui_host`? 
In fact, I want to shared zeronet for my friends via my server, so if ui_host can support any is perfect(and I try to set `ui_host` to `*` just like `ui_ip = *`, but it's not work). It's work ! thanks very much O(âˆ©_âˆ©)O only the sidebar(which contains stats) is loaded, the rest is blank, why?? Hit F12 in the browser and see what "errors" or "warnings" are displayed.

ZeroNet does NOT work at all for me anymore in Chrome due to badly implemented Content Security Policy. hiï¼I got a error code 403 with two files, 'https://mydomain/1HeLL.../css/all.css' and 'https://mydomain/1HeLL.../js/all.js'.  `Alexanders-MBP:ZeroNet-master Alexander$ pip install gevent msgpack-python
Collecting gevent
  Using cached gevent-1.0.2.tar.gz
Collecting msgpack-python
Requirement already satisfied (use --upgrade to upgrade): greenlet>=0.4.7 in /usr/local/lib/python3.5/site-packages (from gevent)
Building wheels for collected packages: gevent
  Running setup.py bdist_wheel for gevent ... error
  Complete output from command /usr/local/opt/python3/bin/python3.5 -u -c "import setuptools, tokenize;**file**='/private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/setup.py';exec(compile(getattr(tokenize, 'open', open)(**file**).read().replace('\r\n', '\n'), **file**, 'exec'))" bdist_wheel -d /var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/tmpe6gh2f0xpip-wheel- --python-tag cp35:
  running bdist_wheel
  running build
  running build_py
  creating build
  creating build/lib.macosx-10.11-x86_64-3.5
  creating build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/**init**.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/_ssl2.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/_sslgte279.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/_threading.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/backdoor.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/baseserver.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/coros.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/event.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/fileobject.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/greenlet.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/hub.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/local.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/lock.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/monkey.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/os.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/pool.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/pywsgi.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/queue.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/resolver_ares.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/resolver_thread.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/select.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/server.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/socket.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/ssl.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/subprocess.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/thread.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/threading.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/threadpool.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/timeout.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/util.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/win32util.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  copying gevent/wsgi.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
  running build_ext
  Running '/bin/sh /private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/libev/configure > configure-output.txt' in /private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/build/temp.macosx-10.11-x86_64-3.5/libev
  Traceback (most recent call last):
    File "<string>", line 1, in <module>
    File "/private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/setup.py", line 317, in <module>
      run_setup(ext_modules)
    File "/private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/setup.py", line 312, in run_setup
      "Development Status :: 4 - Beta"])
    File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/core.py", line 148, in setup
      dist.run_commands()
    File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py", line 955, in run_commands
      self.run_command(cmd)
    File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py", line 974, in run_command
      cmd_obj.run()
    File "/usr/local/lib/python3.5/site-packages/wheel/bdist_wheel.py", line 176, in run
      self.run_command('build')
    File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/cmd.py", line 313, in run_command
      self.distribution.run_command(command)
    File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py", line 974, in run_command
      cmd_obj.run()
    File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/command/build.py", line 135, in run
      self.run_command(cmd_name)
    File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/cmd.py", line 313, in run_command
      self.distribution.run_command(command)
    File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py", line 974, in run_command
      cmd_obj.run()
    File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/command/build_ext.py", line 338, in run
      self.build_extensions()
    File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/command/build_ext.py", line 447, in build_extensions
      self._build_extensions_serial()
    File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/command/build_ext.py", line 472, in _build_extensions_serial
      self.build_extension(ext)
    File "/private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/setup.py", line 234, in build_extension
      self.gevent_prepare(ext)
    File "/private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/setup.py", line 231, in gevent_prepare
      configure(self, ext)
    File "/private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/setup.py", line 139, in configure_libev
      make_universal_header('config.h', 'SIZEOF_LONG', 'SIZEOF_SIZE_T', 'SIZEOF_TIME_T')
    File "/private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/setup.py", line 111, in make_universal_header
      print >>f, line
  TypeError: unsupported operand type(s) for >>: 'builtin_function_or_method' and '_io.TextIOWrapper'

---

  Failed building wheel for gevent
  Running setup.py clean for gevent
Failed to build gevent
Installing collected packages: gevent, msgpack-python
  Running setup.py install for gevent ... error
    Complete output from command /usr/local/opt/python3/bin/python3.5 -u -c "import setuptools, tokenize;**file**='/private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/setup.py';exec(compile(getattr(tokenize, 'open', open)(**file**).read().replace('\r\n', '\n'), **file**, 'exec'))" install --record /var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-wfiqvlcs-record/install-record.txt --single-version-externally-managed --compile:
    running install
    running build
    running build_py
    creating build
    creating build/lib.macosx-10.11-x86_64-3.5
    creating build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/**init**.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/_ssl2.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/_sslgte279.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/_threading.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/backdoor.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/baseserver.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/coros.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/event.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/fileobject.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/greenlet.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/hub.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/local.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/lock.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/monkey.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/os.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/pool.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/pywsgi.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/queue.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/resolver_ares.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/resolver_thread.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/select.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/server.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/socket.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/ssl.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/subprocess.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/thread.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/threading.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/threadpool.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/timeout.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/util.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/win32util.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    copying gevent/wsgi.py -> build/lib.macosx-10.11-x86_64-3.5/gevent
    running build_ext
    Running '/bin/sh /private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/libev/configure > configure-output.txt' in /private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/build/temp.macosx-10.11-x86_64-3.5/libev
    Traceback (most recent call last):
      File "<string>", line 1, in <module>
      File "/private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/setup.py", line 317, in <module>
        run_setup(ext_modules)
      File "/private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/setup.py", line 312, in run_setup
        "Development Status :: 4 - Beta"])
      File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/core.py", line 148, in setup
        dist.run_commands()
      File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py", line 955, in run_commands
        self.run_command(cmd)
      File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py", line 974, in run_command
        cmd_obj.run()
      File "/usr/local/lib/python3.5/site-packages/setuptools/command/install.py", line 61, in run
        return orig.install.run(self)
      File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/command/install.py", line 539, in run
        self.run_command('build')
      File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/cmd.py", line 313, in run_command
        self.distribution.run_command(command)
      File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py", line 974, in run_command
        cmd_obj.run()
      File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/command/build.py", line 135, in run
        self.run_command(cmd_name)
      File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/cmd.py", line 313, in run_command
        self.distribution.run_command(command)
      File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py", line 974, in run_command
        cmd_obj.run()
      File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/command/build_ext.py", line 338, in run
        self.build_extensions()
      File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/command/build_ext.py", line 447, in build_extensions
        self._build_extensions_serial()
      File "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/command/build_ext.py", line 472, in _build_extensions_serial
        self.build_extension(ext)
      File "/private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/setup.py", line 234, in build_extension
        self.gevent_prepare(ext)
      File "/private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/setup.py", line 231, in gevent_prepare
        configure(self, ext)
      File "/private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/setup.py", line 139, in configure_libev
        make_universal_header('config.h', 'SIZEOF_LONG', 'SIZEOF_SIZE_T', 'SIZEOF_TIME_T')
      File "/private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/setup.py", line 111, in make_universal_header
        print >>f, line
    TypeError: unsupported operand type(s) for >>: 'builtin_function_or_method' and '_io.TextIOWrapper'

```
----------------------------------------
```

Command "/usr/local/opt/python3/bin/python3.5 -u -c "import setuptools, tokenize;**file**='/private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent/setup.py';exec(compile(getattr(tokenize, 'open', open)(**file**).read().replace('\r\n', '\n'), **file**, 'exec'))" install --record /var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-wfiqvlcs-record/install-record.txt --single-version-externally-managed --compile" failed with error code 1 in /private/var/folders/s9/h4qsl5vj1yx80k58lp3211580000gn/T/pip-build-4gr3dygb/gevent
Alexanders-MBP:ZeroNet-master Alexander$`
 `python -m pip install gevent msgpack-python` got it installed and working. Thanks.
  Hi, I followed the instructions for mac but it fails when attempting to run gevent. Anyone got a suggestion?

```
MacBook-Pro:ZeroNet-master jarla$ python zeronet.py
- Starting ZeroNet...
Traceback (most recent call last):
  File "zeronet.py", line 15, in main
    import main
  File "src/main.py", line 8, in <module>
    import gevent
ImportError: No module named gevent
Traceback (most recent call last):
  File "zeronet.py", line 60, in <module>
    main()
  File "zeronet.py", line 46, in main
    traceback.print_exc(file=open("log/error.log", "a"))
IOError: [Errno 2] No such file or directory: 'log/error.log'
```
 Were you at least able to  get gevent installed through pip? Also do you have System Integrity Protection disabled?
 Thanks for your prompt response!
Gevent seems to have installed nicely. Thanks. Not sure what the System Integrity Protection is but I'll look it up. (There wasn't any information about SIP at the download page.)

```
$ pip install gevent msgpack-python
Requirement already satisfied (use --upgrade to upgrade): gevent in /usr/local/lib/python2.7/site-packages
Requirement already satisfied (use --upgrade to upgrade): msgpack-python in /usr/local/lib/python2.7/site-packages
Requirement already satisfied (use --upgrade to upgrade): greenlet>=0.4.7 in /usr/local/lib/python2.7/site-packages (from gevent)
```
 My SIP isn't disabled and [from the description here](http://apple.stackexchange.com/questions/208478/how-do-i-disable-system-integrity-protection-sip-aka-rootless-on-os-x-10-11) it seems I need to switch if off completely. Which is a little much just to run ZeroNet. 
Think I'm going to try this on my Ubuntu 14.04 home machine instead.
 @HelloZeroNet it works, thank you
 Apple implemented SIP in OSX 10.11 to help lock down a lot of stuff in the system folders like `/usr` 
http://totalfinder.binaryage.com/system-integrity-protection
 @HelloZeroNet If cross platform testing is an issue, one potential solution could be to just release ZeroNet in Docker containers, similar to what [**nofish**](https://hub.docker.com/r/nofish/zeronet/) has made. It would eliminate the strenuous need to test each build on Windows, OSX, and Linux. The only real drawback would be that individuals would need to learn and setup Docker, but that complication is almost perfectly remedied with [**Kitematic**](https://kitematic.com/).
 Same problem here. @HelloZeroNet suggestion didn't work. Any other suggestion? Thanks
 Thanks, @HelloZeroNet . The command wasn't well received on OSX El Capitan v10.11.3, though:

```
$ python -m pip install gevent msgpack-python
/usr/bin/python: No module named pip
```

It did work very, very nicely on Ubuntu 14.04 LTS :)
 @jarlarntzen Unless you installed Python using Homebrew, you will have install `pip` manually from here https://pip.pypa.io/en/stable/installing/. Once you have `pip` downloaded and installed you will be able to run `python -m pip install gevent msgpack-python`.
 OS X 10.11.3, SIP disabled, additional installation of python in /usr/local, pip-installed gevent & msgpack-python (without the -m option), updated all pip-installed formulas, added zeronet, no problems. Works great (Safari 9.0.3). Also works fine with VPN (OpenVPN via built-in utun.)
 Wow! This works fantastically well!

Thanks @HelloZeroNet 

```
Benchmarking ZeroNet 0.3.6 (rev949) Python 2.7.11 |Anaconda 2.5.0 (x86_64)| (default, Dec 6 2015, 18:57:58) [GCC 4.2.1 (Apple Inc. build 5577)] on: darwin...

CryptBitcoin:
- hdPrivatekey x 10..........0.127s [x5.52: Insane!!]
- sign x 10..........0.066s [x5.34: Insane!!]
- openssl verify x 100..........0.136s [x2.72: WOW]
- pure-python verify x 10..........0.328s [x4.88: Insane!!]

CryptHash:
- sha256 5M x 10..........0.152s [x3.95: Insane!!]
- sha512 5M x 10..........0.110s [x5.44: Insane!!]
- os.urandom(256) x 100 000..........2.067s [x0.31: Ehh]

Msgpack:
- pack 5K x 10 000..........0.258s [x3.02: WOW]
- unpack 5K x 10 000..........0.473s [x2.54: WOW]
- streaming unpack 5K x 10 000..........0.495s [x2.83: WOW]

Db:
- Open x 10..........0.019s [x6.91: Insane!!]
- Insert x 10 x 1000..........0.394s [x2.54: WOW]
- Buffered insert x 100 x 100..........0.770s [x1.69: Fine]
- Total rows in db: 20000
- Indexed query x 1000..........0.116s [x2.16: Fast]
- Not indexed query x 100..........0.409s [x1.47: Fine]
- Like query x 100..........0.796s [x2.26: Fast]

Done. Total: 8.65s
```
 @HelloZeroNet I'd like to argue that this should be the default download for OSX. :+1: Thanks!
 Fantastic! Thanks! :smile: 
 https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-v0.1.1.zip

(Close ZeroNet if already running for you)
Download, unpack, run ZeroNet(.app)

run successful ,but how to exit ZeroNet ? 
 From ZeroNet's web GUI, right?
 @HelloZeroNet  Use  [ZeroBundle-mac-v0.1.1.zip](https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-v0.1.1.zip)  , It works!  thanks~ 
  Virtualenv is a great way for people cloning from the git repo to setup zeronet's environment with dependencies in a consistent way without requiring a vm like vagrant/docker
 Okay. Switched to source
  Maybe plugins should use a folder in "My Documents" or $HOME, loading them dynamically. As for semiauto-update, why can't it download the latest AppImage rather than source if you're using the AppImage version?

that being said, I'm not sure I like this way of packaging things for Linux... how do you keep all the component packages of the AppImage up to date?
 Whenever there is an update, then there should be a new version of the AppImage, as AppImages are immutable (which I consider a feature). There is a mechanism for updating AppImages using binary delta updates, which means that only the portions of the AppImage are re-downloaded that have been changed since the last version (e.g., if the Python runtime did not change, then these bytes do not have to be re-downloaded). 

https://github.com/probonopd/AppImageKit/blob/master/AppImageUpdate.AppDir/README.md
 @kskarthik please reopen, I'd like to give this a try :-) It's more an issue of https://github.com/HelloZeroNet/ZeroBundle as this repo hold strictly the core. Thanks @border0464111, opened https://github.com/HelloZeroNet/ZeroBundle/issues/17  Hello on start i see 
[08:27:32] Ui.UiServer Web interface: http://127.0.0.1:43110/

But i want to listen it on server ip like 299.145.36.0:43110 how to do it?
 thx :)
 I have a similar question. Would it be possible to bind to a specific ip(s) than just all?
  The UI is suggesting that there is a problem with Tor connecting. 

debug.log reports:
[2016-03-01 20:17:31,602] ERROR    TorManager Tor controller connect error: 'NoneType' object has no attribute 'group'
[2016-03-01 20:17:31,602] DEBUG    TorManager Tor proxy port 127.0.0.1:9050 check error: No connection

Tor is definitely running as I'm using it for other activities, and I configured it as suggested in the FAQ. Is there anything else I'm missing? 
 I checked the permissions of /var/lib/tor/data/control_auth_cookie (that's apparently the location for mine. I should mention I'm using Gentoo) and it's 

-rw------- 1 tor tor 32 Mar  1 20:40 /var/lib/tor/data/control_auth_cookie

which doesn't give me rights to use it. Any attempt to change its permissions results in nothing happening(which is probably something with Tor resetting them). 
 As I said, I configured Tor as suggested in the FAQ. I'm a member of the group, etc. 
 I have that too. When I try:

echo 'PROTOCOLINFO' | nc 127.0.0.1 9051

I get 

250-PROTOCOLINFO 1
250-AUTH METHODS=COOKIE,SAFECOOKIE COOKIEFILE="/var/lib/tor/data/control_auth_cookie"
250-VERSION Tor="0.2.8.1-alpha"
250 OK

If that helps. 

I forgot to mention that adding that "CookieAuthFileGroupReadable 1" did change the permissions to 660 at least but still nothing.
 Another observation: 
while the cookie file itself is readable, /var/lib/tor/data/ is not. I wondered why I kept needing to use sudo just to use "ls". I changed it but when you restart Tor, it resets the permissions. Surely there's a way around that but I've not yet discovered it as it seems to be a current bug with Tor in some cases. 

Also, I tried to connect to the control port with TorCtl for python and it worked fine as long as the "data" directory was at the proper permissions BUT zeronet still spits out that same error. 

Any other ideas? 
 The CookieAuthFile setting worked like a charm. I had to create a directory that was owned by tor so it could create the file but otherwise was fine. 

The rest of the fix worked as well so I'm closing this. Thanks
  I'm using ubuntu 15.10.

Trying to run from master:

It was working with an oldversion (don't remember) after an update it start giving me this error.

$ python start.py 
- Starting ZeroNet...
  Traceback (most recent call last):
  File "/home/devel/ZeroNet/zeronet.py", line 15, in main
    import main
  File "/home/devel/ZeroNet/src/main.py", line 11, in <module>
    monkey.patch_all(thread=False, subprocess=False)
  File "/usr/lib/python2.7/dist-packages/gevent/monkey.py", line 379, in patch_all
    patch_builtins()
  File "/usr/lib/python2.7/dist-packages/gevent/monkey.py", line 350, in patch_builtins
    patch_module('builtins')
  File "/usr/lib/python2.7/dist-packages/gevent/monkey.py", line 94, in patch_module
    gevent_module = getattr(**import**('gevent.' + name), name)
  File "/usr/lib/python2.7/dist-packages/gevent/builtins.py", line 17, in <module>
    _import = builtins.__import__
 $ python -V 
Python 2.7.10

$ python -c "import gevent; print gevent.version_info"  
version_info(major=1, minor=1, micro=0, releaselevel='beta', serial='1')
 It works that way. Is there a way to run it from git  repo?
  Hi, just looked at zeronet and recognized that it seems not to be possible to have just one zero id on different devices. Since most people have more than one device it's rather an essential feature to be able to have on zero id with which devices can be synced and behave as one.
 thanks, copied it and it works. When using the unique id to sent a mail to myself the mail appears on both devices (but tells by sending the mail that the "content published to 5 peers"?). Deleting this mail on one of the devices doesn't remove it at the other.
 What does this mean? With the same zero id I'm not the sender on both devices? And, clicking on the trash of a message isn't deleting, but hiding it?
 Thanks for the explanation. Just for clarification, mails (+ then I assume other message types as well) are stored locally in the browser's storage. But it's not quite clear what this means. Up to now, I tested with IE and assuming to delete my own test mails actually just hide them. Thus, in the IE view the mails do not appear anymore, but e.g. Chrome shows them all again. This behavior is unexpected (because it's different from client-server systems) and thus confusing. 
If I understand 'owner' now as the sender of a mail/message, does this mean, only the sender can delete a mail/message, but the receiver/s on which devices a message is stored can't?
Thanks in advance.
  - `Developer documentation easily` acessible
  I don't think `pkill python` is the most efficient, is there another way?
 That's ok, I'll look for another way, thank you. :smile: 
 In case someone finds this in the future, I've found a way.
- Create a script that starts zeronet (`zero.sh`)
- Create another one that stops it, like so:

`stop.sh`

```
#!/bin/bash

cd /path/to/start/script
zeroPID=$( pgrep zero.sh )

if [ $zeroPID ]
then
    kill -INT -$zeroPID
    echo "ZeroNet has stopped"
else
    echo "ZeroNet is not running"
fi
```

For some reason `pgrep` doesn't work with absolute paths, hence the `cd`.

Blog [post](http://127.0.0.1:43110/1QLLPpowM6BWxKYKops1WkCafuFPhFBnAx/?Post:2:Stopping+ZeroNet+with+a+script).
   May be need try check tor service port before start self tor process?
 Does it solved your issue @wrewolf ?   How to replicate:
- Trigger a window opener security check by changing the page in a site like [this](http://127.0.0.1:43110/17Kom2G5qNDc6NaQwv445h1gFzxkY3ZtZe/).
- Click the button.
- A new tab shows up but the parent tab doesn't close.
- Clicking the button in the new tab works as it should.

Happens on Firefox for Linux.
 this?
https://dl.dropboxusercontent.com/s/s2gbofwo77h2sky/2016-02-21_03-51-02.mp4

Windows 7 x64
Firefox v44.0.2
 Works better after the last commit, thanks. I also uploaded the files and added `"postmessage_nonce_security": true` to the content.json file and it's flawless so far.
  I understand, ZeroNet internally uses torrent.

Have you seen the following paper?

Bittorrent over Tor isn't a good idea
- https://blog.torproject.org/blog/bittorrent-over-tor-isnt-good-idea
- http://hal.inria.fr/docs/00/47/15/56/PDF/TorBT.pdf

Torrent clients (libraries) use socks proxy settings for connectivity. Not anonymity. The threat in essence boils down to torrent clients using fancy techniques (similar to "sudo ifconfig"), finding out their real external clearnet IP, and then sending that IP through the proxy.

Connection from Tor exit coming and including the information "hi, my real name is...".

Are you sure, that zeronet's usage of torrent does not suffer from the same issue?
 It uses .onion HS to communicate
 What in case only Tor proxy settings without Tor ControlPort - hence without Tor hidden services?
 @adrelanos from what I understand ZeroNet relies on BitTorrent Trackers for peer discovery, which means the ips, ports and hashes being advertised by ZeroNet clients can be leaked from any of the Trackers (due to the tracker scrape API)
 @HelloZeroNet but torrent trackers themselves leak IPs and hashes, which from a mass surveillance standpoint might make deanonymizing users easier. Is there any security threat model documentation on ZeroNet available?
 @HelloZeroNet one attack I can think of off the top of my head for example is:
- I use the tracker scrape API on these https://github.com/HelloZeroNet/ZeroNet/blob/779075c4a56ef921f4095220725a16b156eba52e/src/Config.py#L33
- Now I know the IPs of all the tor exit nodes of ZeroNet users (and the sha1 of their site addresses)
- If I want to prevent a specific user from being able to discover peers I can DDOS announces to the tracker they are using which will bump them from the LRU resulting in them never being announced to other peers because mine will probabilistically win
 althrou it's an attack aganst availability not data leak as OP speculated.
But it could make sense.
To confirm it would need a reproductible ProofOfConcept for this attack.  Hello, I've been recently working on a site and I've been running into issues.
Whenever I edit the HTML everything shows up fine on refresh, but if I am to add any JS files to js/lib it causes the all.js to throw the error of Uncaught TypeError: App.init(...) is not a function. After deleting all.js, and signing/refreshing (I think you have to sign after non HTML changes) I still manage to get the error (yet all.js doesn't even exist in the directory anymore... After deleting the site and redoing this multiple times (where I don't include any library files like jquery, chartjs, etc.) I've still managed to run into the same problem in the end. "x file update failed" in the main 'home' under my website name on the "connected sites" list.
Things I've tried: Deleting all.js (and all.js in the content.json file) Removing the library's I use from js/lib and moving to lib Manually importing every JS file
ALSO: I tried using all.css (which it generated the file) but none of the css properties where showing up so I ended up importing each css file within the HTML manually (instead of just importing all.css)
 Is there a special way I must connect to see changes locally on refresh? Or is using http://127.0.0.1:43110/{Public_site_key} proper?
 @Stackoverload Maybe your browser cached the files? Try using ctrl+F5 to force redownload without using the cache.
 I did it, and something new happens. It generated an all.js file but none of my new code is in it. 
(It seems to be the original one that I deleted) 
 Are you running ZeroNet in debug mode? Using the --debug switch?
 Also, now it says "Updating..." but why should it update if I'm trying to see changes locally?

And yes, I am.
 Oh and on top of that, it edited my coffeescript back to the previous version.
I'm going to edit the coffee script and try to just sign and see what happens
 Do you have the "own" property set? When on your site, if you open the sidebar at the bottom you should see "This is my site" checked. If it isn't check it
 My changes aren't showing up after signing (as expected). And yes, but I've been signing via the commandline
 Ok, did your coffeescript file gone back to the previous version?
 Yes it did. I then changed it and signed, but my changes aren't showing (I didn't edit or delete all.js)
 Now my changes show up (5 minutes later)
 Seems like every time I edit a coffeescript file and click 'update' on the site, it says "x File update failed" where x is a number (which makes me think I'm not going to the proper place to see it locally since it shouldn't need to 'update').
 And then a few minutes later it successfully updates (and I can see changes)
 This is weird, I went back to check my code and it's the old code (but I see the new changes)
 So, is your problem fixed or not?
 Kind of, but not really. Any changes I make (and sign) say update failed for 5-15 minutes, and then finally show up which is really bad for development.
 "Update failed" just means it wasn't able to download the files from other peers (This is normal since YOU have the files, and not them), normally the changes should show up even if it says that...
 Do I need to delete all.js everytime?
 No, it should regenerates itself. If it isn't, then this is a bug.
 Odd then, because I sign it and look at all.js and my changes aren't in the file. If I delete all.js and hard refresh the page it acts like all.js still exists.
 Try refreshing using ctrl+F5
 Or set your cache size to 0. So it won't be able to cache your files.
 I've cleared my cache and did a hard reload, still acts like all.js exists even though it doesn't for in my folder.
 Now it just generated it... Odd
 When you delete "all.js" and you go to a page that needs it, it regenerates it, and it take a little bit of time, like 2 seconds or something like that
 Wow.. I found out how to fix it now. If I delete all.js, and clear the cache and then refresh it works perfectly. Thanks :)
 You're welcome :D, don't forget that you can always set your cache size to 0, so you won't have to clear it everytime :)
 Where would I do that?
 In your browser settings
 Oh.. Yeah duh.. haha
Thanks.
 @Stackoverload Btw I'm called `thekill38` on ZeroNet, if you want to send me a ZeroMail ;)
 Awesome :) I'll make sure to
  i have site http://127.0.0.1:43110/1Apr5ba6u9Nz6eFASmFrefGvyBKkM76QgE/ (Clone of zero talk ) i want to increase user data on site but new version on file don't propagate to users.

i use that commands:
1. zeronet.py siteSign 1Apr5ba6u9Nz6eFASmFrefGvyBKkM76QgE --inner_path data/users/content.json
2. zeronet.py siteSign 1Apr5ba6u9Nz6eFASmFrefGvyBKkM76QgE
3. zeronet.py siteVerify 1Apr5ba6u9Nz6eFASmFrefGvyBKkM76QgE
4. zeronet.py sitePublish 1Apr5ba6u9Nz6eFASmFrefGvyBKkM76QgE

what i have in /content.json: 

```
 "includes": {
  "data/users/content.json": {
   "signers": [ "" ],
   "signers_required": 1
  }
```

in /data/users/content.json 

```
{
 "files": {},
 "ignore": ".*",
 "modified": 1455546464.475202,
 "signs": {
  "1Apr5ba6u9Nz6eFASmFrefGvyBKkM76QgE": "HKqBU/zIRsMGrrFFaeTWgFvNf7pxkUNhdIs5jcCs10g9XVJ/BdNA4T1/NAzT32g0bgyK4L3WYleOdA+rJrNusRQ="
 },
 "user_contents": {
  "cert_signers": {
   "zeroid.bit": [ "1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz" ]
  },
  "permission_rules": {
   ".*": {
    "files_allowed": "data.son",
    "max_size": 30000
   },
   "bitid/.*@zeroid.bit": { "max_size": 40000 },
   "bitmsg/.*@zeroid.bit": { "max_size": 15000 }
  },
  "permissions": {
   "bad@zeroid.bit": false,
   "gomzik@zeroid.bit": { "max_size": 100000 },
   "nippletwister@zeroid.bit": { "max_size": 100000 },
   "shift@zeroid.bit": { "max_size": 100000 }
  }
 }
}
```
 wow, that works, thanks!
  There is quite an empty space on the upper portion of the landing page, so I was wondering if it would be possible to show the current/default ZeroID and, maybe if there are any new incoming mails in ZeroMail on the upper bar, or on top left corner.

![image](https://cloud.githubusercontent.com/assets/16450950/13032745/4af60f2a-d307-11e5-82f9-1ad9e9287742.png)
  If you have site with long name - you can't delete them, example: 
http://127.0.0.1:43110/1AQj7DF45w5DK2Ga486YT8QaYhpedgE5tR
![2016-02-12 16 23 57](https://cloud.githubusercontent.com/assets/426427/13008055/2f53272a-d1a5-11e5-8d1a-a73d583f1cf3.png)
![2016-02-12 16 23 52](https://cloud.githubusercontent.com/assets/426427/13008056/2f7bded6-d1a5-11e5-9c6b-3049b5929591.png)
 hmm, only safari bug. 
  What do you think about cross access to zero-net sites? it would be useful for making site (for example) jquery with latest script that can be included to all other sites 
 integrity can help, https://www.w3.org/TR/SRI/ like in bootstrap http://getbootstrap.com/getting-started/ 
(integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7")
 Also, if we have local de-duplication on the filesystem storage or network then there is no benefit at all in a space saving.
 ok
  What do you think about handeling urls like
zero://<hash or domain>
and automatically open new tab in browser?
 But, you can handle urls like zero://hash by zeronet core (or something like) and open in browser with url http:// 127.0.0.1/hash
 use case is - make link zeronet://hash and post it in normal internet that if you click it (and you have zeronet) zeronet register it as protocol for this links and convert link that open (like it does after start in new browser window) 

I think that it better than nothing
 but user should install +1 new software, if you prefer chrome plugin as long wrapper you should give link to it in zero hello 
 I think an Electron app could implement a custom browser for zero:// URLs.
 @dmp1ce Check out [Beaker](https://github.com/beakerbrowser/beaker) and the relevant [ZeroNet ticket](https://github.com/HelloZeroNet/ZeroNet/issues/530).
  in Screenshots section we have old screenshots (with old zero hello)
  If you sign a content.json file, a space is inserted after every comma at the end of a line. My text editor (Github's Atom) and I'm sure some others too automatically remove trailing whitespace after saving a file since trailing whitespace serves no purpose, so if you have your ZeroNet site under git version control, these lines with the trailing whitespace removed all appear as changed in git every time you make a change to the file.

I can turn off that functionality in my text editor but that would just be a workaround. It would be better if this could be fixed in ZeroNet itself, unless the trailing whitespace after the commas is actually needed for some reason.
 Awesome, thanks!
  I wonder if that is possible, which in turn might be used to tip the content creator one likes. 
 So, technically I can tip that user (and he can retrieve the amount as long as he has the private key?)
 I have successfully imported a ZeroNet private key into my bitcoin instance using the `importprivkey` RPC call. It sould work in the GUI client also.
 This issue should be closed :)
  When I set `tor = always` in my zeronet.conf file I get following error message in console:

```
 TorManager Tor addOnion error: 510 Unrecognized command "ADD_ONION"
```

The web interface works, but with lot of bugs.

Is it a bug? or... What am I doing wrong? 
 Thank you!

I simply supposed that jessie provides the proper version of tor.
  How feasible would it be to package Zeronet into an NPM module, like torrent-stream? (https://github.com/mafintosh/torrent-stream)

Would be very convenient to access the Zeronet network by proxy from within Node apps from a pre-packaged mod rather than just a typical GET:

e.g. app.js

var zeronet = require('zeronet');

var options = {
  host: 'somezeronetaddr.bit',
  path: '/foo.html'
};

zeronet.get(options, function(resp){
  resp.on('data', function(chunk){
    //do something with chunk
  });
}).on("error", function(e){
  console.log("Got error: " + e.message);
});
        If a site register a NewsFeed without notifiying you, it will display it, even if you didn't want to.
    https://blog.mozilla.org/blog/2016/01/25/firefox-can-now-get-push-notifications-from-your-favorite-sites/
Is it possible to add an API to allow authorized sites to use push notifications?
 Yeah, I though too that it would be cool implementing it when it would be more mature, I opened this issue as a reminder
  I'd like to be able to incorporate Zeronet into other applications so they can access the network to do API calls or basic HTTP requests. Python's great, but running an exec() process in the background requires the client have the right version, and dependencies.

A neat example of this is Popcorn Time, which is built in QT, Android, and iOS. Clients being able to start their own Zeronet server in the background when the app launches, and make requests across a distributed network instead of to a central API server for their data would make them much more resilient. 

It would also increase the Zeronet node count - and usage - enormously. Apt, Cocoa, or Composer packages would be incredibly useful.
 That doesn't seem right. In lieu of something easier like NPM, I'm looking for a static C/C++ library i can import into something like QT which is embeddable, and doesn't involve an installation of Python or the dependencies (e.g. Msgpack).

Or would it be possible to do it this way, by calling the Python code from within QT?
http://pythonqt.sourceforge.net/
 Hi guys! For your information, I'm trying something about this. More info here 0net://libzeronet.bit
 @azcoppen  have you managed to produce something ?
is this issue still actual?   Would it be possible to store the content being served by peers in encrypted form and decrypted on the fly when it is served?

Potential scenario: 

Peers situated in a country that favours censorship are serving up HTTP content over SSL to other clients: transmission is protected over the wire. But what happens in the case where a peer unit (laptop, PC etc - i.e. publishers) are subject to physical seizure by hostile or state actors? For example, A Zeronet site is created to share pictures of the Tiananmen square demonstrations, curated and served by Chinese nodes. Peers are identified by IP, traced through their ISP, and the equipment used to serve the content subsequently confiscated by censors.

In this case, it's highly likely that peers would be incriminated as _publishers_ of material (more severely punishable and increasingly risky), - rather than just viewers - , if identified by IP. The Tiananmen problem given above is provocative enough that even a static JPG could put a peer at risk of a criminal offence in that jurisdiction, and the recording of the IP on the network would be incriminating.

However, if those actors managed to isolate a machine, but were unable to access the locally-stored files being served upon physical seizure, - as they were encrypted - , it would make the process harder to show what they were publishing in the first place (save for being forced to provide their private key). The HTTP server itself would need to decrypt on the fly to serve them out, obviously, but little software exists to do it.

The solution suggested here...
http://stackoverflow.com/questions/4418588/webserver-on-the-fly-decrypting

...is the AES provision within G-Wan:
http://gwan.com/api#crypto

Or would it be wiser to take a longer-form approach like Protonmail, and serve the material for decryption exclusively on the client, to avoid the possibility of compromising the private key as part of the machine seizure?

Is this a realistically achievable goal that could be included on the software's roadmap at some point?
 As I understand it within ZeroNet there aren't really any web servers as we traditionally know them, and instead sites are automatically duplicated and served by anyone who views them. But having data at rest encrypted and only unlocked with a password or key entered into the UI or in a local configuration file isn't a bad idea.
 Encrypting a whole site with a public key or password could solve this so the data stored encrypted
 @bashrc My understanding as well. Makes it very interesting to see how a parallel Node.js binary could be incorporated, as in the Popcorn model where they use QT's WebView.

@HelloZeroNet I was curious about this as i saw the update notes on Medium. It's almost as if it would be easier to publish the site data as an encrypted archive (.zip etc), for unzipping on the mirroring peer.

Another scenario which is related occurred to me while i was explaining to a friend today how ZeroNet worked: what happens if a site being published contains objectionable material?

For example, what if someone uses the Zeronet network to create a site of child pornography? Presumably, that site could feasibly be mirrored on my computer unwittingly - unlikely, but possible, and exploitable. In that case, i am hosting a site on my computer that could have me imprisoned, without even realising it's there. Is there any way to control what material a peer is downloading, or some kind of warning/greylisting?
 As silly as a question as this might sound, how do i have control over what i'm seeding? And how do i explain the same thing to someone who is less technical? One of the stated design goals of Zeronet is a simple and attractive UI, but i can't see how to do that at all.
 Understood: the only sites you have on your local machine are the ones you visit, so the Internet history argument comes up (if its on your machine, you deliberately visited it). Who is seriously going to search through 30 data folders to see which ones they need and those they don't?

However, that still leaves 2 scenarios:

a) You're a political dissident wanting to get around DNS-level censorship; your machine is confiscated, and you don't need to be a forensics specialist to know that its very simple to prove you've not only actively been viewing Falun Gong content, but now you're automatically hosting, distributing, and publishing it.

b) The author of the site you're visiting (and copying onto your local) has 2 sets of content: i) the interesting bit you're wanting to read, and ii) another part not linked to that you don't know about, containing galleries of child porn.

In its current form - and i'm not knocking the project for its innovative approach - its usable if you're comfortable running Python from the command line (a very narrow audience), regularly browse through the content folders, you're not in a country with a questionable government (getting smaller by the day), and you entirely trust the hosts you're visiting (and their authors), which is totally unknowable.

Obviously it's alpha days, but wouldn't it be a prudent direction to include some kind of zero-knowledge mechanism, and/or some way for the network to notify peers of malicious actors?
 Content from zeronet on you HDD - it is cache, when you visit standard site in normal internet you download content to you hdd, also if you see _accidentally_ CP or different bad content - you computer have them on your HDD, also your provider (maybe) have that content too - if he cache it in proxy, or if site use CDN like cloud flare - it also have them. So, site on your hdd from zero network is cache.

about government - if you think that you government can get your machine - buy VPS server in cloud provider or encrypt all data on HDD.
 Encrypting the whole HDD and using Tor then is possible, but it looks like workaround, not a solution.

One should distinguish between data that should be encrypted and data that can be stored as is. I think it will be useful to add an option to encrypt users.js at least.
 > a) You're a political dissident wanting to get around DNS-level censorship; your machine is confiscated, and you don't need to be a forensics specialist to know that its very simple to prove you've not only actively been viewing Falun Gong content, but now you're automatically hosting, distributing, and publishing it

I understand the issue, but I don't think it's in zeronet design to provide such level of security.
If you have your state actors in your threat modeling, best is to use some amnesiacOS.

As any torrent or any files, if you got swatted and have an uncrypted drive with illegal stuff on it, it's game over. Nothing Zeronet Specific IMO.

> b) The author of the site you're visiting (and copying onto your local) has 2 sets of content: i) the interesting bit you're wanting to read, and ii) another part not linked to that you don't know about, containing galleries of child porn.

We don't have much legal precedent for this. It could turn out be as simple a the request Sites owners receive to remove CP content. 
  like showing "number of people distributing website", maybe the info on how big each website is could be added as important info on main page cards, so people know approx. how much space is taken per website
 Number of peers for each site is now shown on the left of front page. Site size and others storage info can be seen on "files" tab. 

This enhancement have been successfully implemented.   In following lines (UIWebscoket.py:274):

```
file_info = site.content_manager.getFileInfo(inner_path)
inner_path = file_info["content_inner_path"]
```

`.getFileInfo` could return `False` and app will throw:

```
WebSocket handleRequest error: TypeError: 'bool' object has no attribute '__getitem__' in UiWebsocket.py line 96 > UiWebsocket.py line 174 > UiWebsocket.py line 309 > UiWebsocket.py line 275
```
 I just get a similar error:
`Site:113VKv..Gqm8 WebSocket handleRequest error: TypeError: 'bool' object does not support item assignment in UiWebsocket.py line 98 > UiWebsocket.py line 178 > UiWebsocket.py line 454`

The site is a ZeroBlog clone, http://127.0.0.1:43110/113VKvZjeD442BDZ2vF9aXfPnFqDJ8Gqm8/ ; I can see that when I update it locally by adding a post, the new version is not available on the zeronet proxies I have tried (for instance https://www.zeropro.xyz/113VKvZjeD442BDZ2vF9aXfPnFqDJ8Gqm8/?Post:13 ).
 too much fiddling I guess :)
Started again fom scratch and the error has disappeared
 > Started again fom scratch and the error has disappeared

Without a way to reproduce it, sadly This issue will hang here indefinitely :s 
Closing ?  It might be worthwhile catching this particular scenario and improving logging here. It is important to detect and avoid type errors in parts responsible for loading `content.json`. Here is a related case in which type errors are discovered in FileServer code: [MuxZeroNet/Fuzzing/Fuzzing Log/ Round 1/README.md](https://github.com/MuxZeroNet/Fuzzing/blob/master/Fuzzing%20Log/Round%201/README.md#type-error)  Right now if a site [by mistake] tries to call sign command from a user w/o any certificate (like a user that never registered in zeroid.bit) then server throws an internal exception. It will be helpful to show some meaningful error message instead.

There: https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Content/ContentManager.py#L259

```
user_urn = "%s/%s" % (content["cert_auth_type"], content["cert_user_id"])  # web/nofish@zeroid.bit
```

It even have some workaround above this line, but it's commented out. I guess there was a reason
 yes, I know, I do that now. 
But before I figured out, I spent few hours to understand why it's happening and what should I do to avoid such error. I mean detailed error will be really helpful for novice zeronet developers.
 @splix What file are you trying to sign? To sign `"data/users/" + this.site_info.auth_address + "/content.json"` you need `auth_address` already but `site_info` is undefined if certificate is not selected. So I draw a conclusion that you are trying to sign something else, and that means you don't understand what are you doing.
There is no way to prevent thousands of ways to shoot yourself in the foot, and this is not an educational project.
@HelloZeroNet Please, close.  Hi,

I followed the instructions for installing zeronet and tor on debian, but still get Tor error when I start zeronet:

python zeronet.py --tor always --ui_ip 0.0.0.0
- Starting ZeroNet...
  [14:00:58] - OpenSSL loaded, version: 01000205F
  [14:00:58] - Patching sockets to tor socks proxy: 127.0.0.1:9050
  [14:00:58] - Version: 0.3.5 r859, Python 2.7.11 (default, Jan 11 2016, 21:04:40) 
  [GCC 5.3.1 20160101], Gevent: 1.0.1
  [14:00:59] - Creating FileServer....
  [14:00:59] TorManager Tor controller connect error: [Errno 111] Connection refused
  [14:00:59] - Creating UiServer....
  [14:01:00] - Removing old SSL certs...
  [14:01:00] - Starting servers....
  [14:01:00] Ui.UiServer --------------------------------------
  [14:01:00] Ui.UiServer Web interface: http://0.0.0.0:43110/
  [14:01:00] Ui.UiServer --------------------------------------
  [14:01:04] FileServer Checking port 15441 using portchecker.co...
  [14:01:04] Site:14kr6q..T2Ag Announce to 0 trackers in 0.042s, failed

Port 15441 is open, on the Stats page it says:
rev859 | False | Opened: False | Crypt: ['tls-rsa'] | In: 0.00MB, Out: 0.00MB | Peerid: -ZN0035-aegwVkCOPMiG |
Connections (0, total made: 23):
Tor hidden services (status: Error ([Errno 111] Connection refused)):

Any idea what could be the reason?
 thanks for the quick respond, i figured out that 
/etc/init.d/tor (re-)start
as mentioned in the docu [here](https://zeronet.readthedocs.org/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux) seems on my system (debian sid) to actually not get tor running, besides the message saying that it started.

Simply "tor" worked fine though. So ticket can be closed, maybe update the docs or I still doing something wrong here.
   Happy to help :smile: 
  python get-pip.py --user gevent msgpack-python
Collecting gevent
  Using cached gevent-1.0.2.tar.gz
Could not import setuptools which is required to install from a source distribution.
Please install setuptools.

uname -a
Linux Boop 3.19.0-32-generic #37~14.04.1-Ubuntu SMP Thu Oct 22 09:41:40 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux

 lsb_release -a
No LSB modules are available.
Distributor ID: LinuxMint
Description:    Linux Mint 17.3 Rosa
Release:    17.3
Codename:   rosa
 Ok, when trying to use the debian pack, I get : 
- python zeronet.py
- \- Starting ZeroNet...
- [20:05:19] - OpenSSL loaded, version: 01000106F
- [20:05:19] - Version: 0.3.5 r859, Python 2.7.6 (default, Jun 22 2015, 17:58:13) 
- [GCC 4.8.2], Gevent: 1.0
- [20:05:19] - Creating FileServer....
- [20:05:19] TorManager Tor controller connect error: [Errno 111] Connection refused
- [20:05:19] ConnServer Error: Unsupported msgpack version: (0, 3, 0) (<0.4.0), please run `sudo apt-get install python-pip; sudo pip install msgpack-python --upgrade

Any idea please ?
 Thank you. The first solution work.
In the future, I will try to use Docker for easier installation.
  My error :

```
 pi@raspberrypi ~/myPrograms/ZeroNet-master $  python zeronet.py
 - Starting ZeroNet...
 [10:34:13] - OpenSSL loaded, version: 01000105F
 [10:34:13] - Version: 0.3.5 r859, Python 2.7.3 (default, Mar 18 2014, 05:13:23) 
 [GCC 4.6.3], Gevent: 0.13.6
 [10:34:13] - Creating FileServer....
 Segmentation fault
```
 I tried 

```
    sudo pip install gevent --upgrade
```

It fails with

```
 sudo pip update gevent
 ERROR: unknown command

p/pip-s8lODB-record/install-record.txt --single-version-externally-managed --compile:
running install
running build
running build_ext
building 'greenlet' extension
creating build
creating build/temp.linux-armv7l-2.7
gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -fPIC -I/usr/include/python2.7 -c greenlet.c -o build/temp.linux-armv7l-2.7/greenlet.o
In file included from greenlet.c:5:0:
greenlet.h:8:20: fatal error: Python.h: No such file or directory
compilation terminated.
error: command 'gcc' failed with exit status 1

----------------------------------------

Rolling back uninstall of greenlet

Command "/usr/bin/python -u -c "import setuptools, tokenize;__file__='/tmp/pip-build-jXs0nN/greenlet/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))" install --record /tmp/pip-s8lODB-record/install-record.txt --single-version-externally-managed --compile" failed with error code 1 in /tmp/pip-build-jXs0nN/greenlet
```
 At this point, it looks like a pip problem more then zeronet. Is this still an issue with updated libs ? 
  My ZeroProxy (https://zeronet.classcoder.com) runs over HTTPS, which works great for just about everything: except for ZeroID. `demo.zeronet.io` is served over HTTP, which Chrome complains about when an AJAX request goes through for it from HTTPS. This is quite breaking for my ZeroProxy, and it would be great if `demo.zeronet.io` had a Let's Encrypt cert or something.
 Works!
  On a mesh waiting for 20 mins to refresh the list of trackers might be excessive. This should be turned into a command option so that it can be reduced to something smaller.
  I've made a Debian package, available at https://github.com/bashrc/zeronet-debian

It's intended for Debian 8+, since it uses systemd. If anyone wants to test it that would be nice.
 Oh that's interesting. I'll do more testing and see if I can eliminate the separate tracker.

Also note that there is a hack which prevents the system from hanging indefinitely when on a mesh.

https://raw.githubusercontent.com/bashrc/zeronet-debian/master/start-zeronet-mesh

Ideally this might be a command option.
 Adjusted this to use the built-in bootstrapping.
 Could you post a Debian RFP please? Try to get this into official Debian repositories?
 Ok
 @adrelanos

> Could you post a Debian RFP please? Try to get this into official Debian repositories?

@bashrc 

> Ok

Any updates?
 As with previous attempts to get packages into debian, I post an RFP and then no replies. If anyone reading this is a debian developer and can help then let me know.
 RFP is request for packaging aka feature request. Gets a lot less
attention. If you are willing to contribute it, the RFP can be turned
into an ITP, which is intent to package, then chances are a lot better.

There is a good chance, that Debian team PkgPrivacyMaintainers would be
interested and supportive.

https://wiki.debian.org/Teams/PkgPrivacyMaintainers?action=show&redirect=Teams%2FAnonymityTools

Please consider signing up to and contacting them on the
pkg-privacy-maintainers mailing list

https://lists.alioth.debian.org/mailman/listinfo/pkg-privacy-maintainers
 Ok I'll try that.
 Any updates ?
 @bashrc ? No updates. As mentioned, I've tried a few times to get various things into Debian but had no success. Debian RFP posted here:
http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=850474
 We at [Whonix](https://www.whonix.org) (anonymous operating system) (a derivative of Debian) like ZeroNet. If it was installable from packages.debian.org, we would very likely install it by default in the next release.

Thank you for working on ZeroNet! DD here. Building an official Debian package is not going to be easy due to the many dependencies in src/lib that need to be unvendorized (hopefully not all of them) and packaged independently where needed.

A good introduction for upstream developers to make distro-friendly applications: https://wiki.debian.org/UpstreamGuide

See also #382 

Edit: also, there are relevant comments about ZeroNet security in the following thread: https://news.ycombinator.com/item?id=14041077 I doubt debian will accept packages that are hacking source code.  It's really bad practices and should be avoid IMO. 

 @HelloZeroNet Please, add some labels, it's important issue.  It would be useful when changing site address, and also in ZeroHello it could have a special thingy, like having the old address being at the bottom of the rectangle of the new address?
 Yeah, but it would permit having a redirecting site, that could appear differently, since it would be possible to know it is one
 You can close this issue I guess?
 Maybe you could open another issue? Or me?
  The address of the site when you click on taskbar icon, and in the ZeroNet logo in the top right corner.
It would be a command line argument
 Ah, didn't seen it ^^
  How to reproduce:
- Start ZeroNet
- Click on Update To New Version
- Quit ZeroNet
  @HelloZeroNet It fixes a division by 0
Or, does it makes more sense to not add the "li" at all if size is zero?
  So, you could have a shorter address for your own site which exists just for you, because you added it in a config file. Like you can do in I2P router console, there is an "address book"
 Yes, but it requires to pay something, and having to deal with a registar or downloading the blockchain and renew the registration, with this, you can add a short, rememberable name
 Thank you, I didn't know that
  And for ZeroMail, normally it is possible to know when you receive an email?
 Ah, I see why, but if I remember, the metadata aren't encrypted, and it's possible to know if you receive an email, but not decrypt content
 Ah, I was wrong then... Sorry
 You could add an API to have a "(1)" or "(2)" etc... appearing in the title, like it is on github.
So, for example, ZeroMail could be displaying this when there is new mails, it could be like a notification.
 This feature seams like a kind of zerome, they seams very familiar.
 Is it possible to use this feed news to replace the zerome? So you do not need to maintain two apps.  There will be many kind of feeds, blog, forum.., we can use lists to filter them. Server a site is like follow a site:)
 OK, I understand. I just think if this news feed can replace the ZeroMe would be very cool. (ZeroMe: A twitter-like social site)
 You could add a way to pin sites, like the "Some sites we created:" sites are. So, they would be displayed bigger, and be in here: 
![capture](https://cloud.githubusercontent.com/assets/13149763/12748615/b1ed3556-c9ab-11e5-9fc2-672ab5e15e53.PNG)
 ![capture](https://cloud.githubusercontent.com/assets/13149763/12751139/b12e749e-c9bb-11e5-8612-3b9840b1b893.PNG)
There is also this graphical bug,
The bell is showing over the right click menu
  Why this is closed? Its not going to be implemented?
 With this feature does it mean your local zeronet node won't have to download these sub sites until the user requests them? I'm trying to think through the scalability implications of hosting a large site on zeronet and this is one of my concerns. Also useful for splitting a site up so the sqllite files for each site can stay small.

Is this only limited to user sites? I can think of some cases where it would be useful to use this feature even if they were coming from the same publisher. For example a reddit clone where you only want to follow and download a few subreddits not the entire reddit site.

Would these sub sites have the same features as existing zeronet sites? Could you nest them however many levels deep that you want?
 Query and display would be from the main site (zerome)? For eg searching and opening a user profile inside central /zerome.bit ?
 Any time estimation?
 Thanks keep up :)
 I think One user per site is more scalable and and gives the ability to users to do everything they want (selective seeding). Network communication is needed and thats the point of p2p protocols. More user per site has privacy issues to on who is the hub owner (plus need of zeroid thats for now centralized) and making closed communities of hubs not open ones. I don't want my hub for a social network but a hub everybody could be a member!

Initial seeding can be solved with a "central" site that every other one can be its child. Search and listing could happen there to find who you want and feed their comments/tweets plus easy messaging to each other.
 And the hubs whould not have any communication between them?
 I think one difference is seeding a profile you don't want in the hub...And the only option is to switch hub...and loose all your follower/following posts..if the is an option to mute/stop seeding a profile it would be cool to fight spam and unwanted context
 I think a big problem in zeronet is searching and indexing...so information is lost..maybe searching inside a hub could be available (to find other users or context)? And muting will implemented as merger functionality?
 The fact that everything is stored on your local files it doesn;t make it easy to locate a user based on his username or content this particular user wrote (site/users/data/1......./data.json). And how i would connect to other users in my hub or hub if i cant find them. Or i cant locate a subject someone wrote? Why should i really on external search engines? Or i should post in 3 different sites my profile link blog so someone could find me? I think search should me embedded in every site to make it easier zerotalk/zeroblog/zeromail/zerome for everyone to access and to avoid duplication. I think muting should be available for merger sites too so a user can press a block button and delete/stop seeding someone profile/content.
 So what did you choose? Hub sites? If so I think that everybody will want to be the hub owner and we will end up with one user per hub
 At least would be a connection between hubs? For querying data? Can multiple hubs be part of a site type? Something like hub of hubs? Else this doesn't solve much and i am still afraid we end up with one hub per user so it will be the same like one site per user. Can we add a solution combining those two? Btw i seed about 200 sites and i have no connection problems. Cause getting updates for single user sites would be that much problem as updated data would be much less
 I do not think seperating sites a good idea. Why should we have a merger site when we can just create more independent smaller sites? Does it mean some kind of "centralization" when we are depending on merger sites?
 I think one user per site is more more attractive.  If there's any chance, please treat this as a prime consideration.

Why I think zeronet social is very attractive? 
1.  I have the total control of my date. That's why I choose p2p social instead of centralized site.
2.  My data will always online. Because my friends(followers) have big willing to seeding my site.

The more user per site solution is less attractive.
1. I lost my total control. It's hard to choose a hub, because we have very small information of the hub.  
   I need to choose a hub. I will worry about that he may banned my site, if he don't like my content. If I changed my hub, I may need to inform my followers that I changed my hub and ask them to seed again. Because the hub can modify my data, then it can fake me: Banned my profile and say I have changed to a fake profile. Because my followers have seeding the hub for a while, they may trust the hub. Because we have few information to choose a hub, maybe in the future, who have many servers and bandwidth will gain most users. 
2. My followers need to seed other 99 users they don't want to follow. This may decrease their willing to seed the sites.

Please forgive my poor English:)
 Yes I know, create my own hub is a solution. But if there are many users like me care about the control of own data. Then this solution would be less attractive. 
 For the issues of one user per site solution
- (a)Initial seeding can be problematic
- (b)Needs lots of connections (5connection/site is minimum to make sure you got every update)
- (c)More network communication (tracker announce requests)
- (d)More files and hdd space requirement on hdd (if you comment on multiple profile you only need new file for every profile)
- (e)Less privacy: You exactly know who follows who (tor improves this)

---

Consider most zeronet users don't treat 1.easy to use and 2.decrease hdd space as top priority, so (a),(c) are not big problem right now.
And with tor, (e) also can accept.
So the really problem are (b) and (c). Am I right?
 I will take more time to think about this. Thanks for your hard work, it is really awesome.
 MeetZero is good!
 I vote for ZeroSociety or ZeroMe
 You might consider not using zero in the name here are some more ideas for a name. 
Chatter
Blabber
ChitChat
Babble
 @makdisse ZeroSociety was my first thought too - http://mrrobot.wikia.com/wiki/Fsociety :)
 Zerotopia
 Zerome or myzero
 Users from different hubs will have the ability to share content?
 So yes!?! Cross hub - normal site queries will be possible?
 GroundZero should be avoided because it has negative cultural connotations in the U.S. (the site of the wreckage of the World Trade Center buildings on 9/11 is still referred to as "ground zero") and, of course, Japan (Nagasaki and Hiroshima were ground zero for nuclear bombs).

ZeroMe and MeetZero are the most appealing choices from the list.

I also have a less serious name suggestion taken from the Star Trek universe: "[Unimatrix Zero](https://en.wikipedia.org/wiki/Unimatrix_Zero)," which is the name of a censorship-free decentralized social network of rogue Borg. Perhaps it's silly, but I had to mention it given the obvious parallels.
 I'm sorry but I don't have read all he discussion, but instead of one/more user per site I have an idea:
create bundle sites to hold content, it's base on one user per site, but, for exampe with some people you get 30+ common friend, then all this could be bundle with this group of friends. this will limit the number of connection needed and keep enough data data online.
 Some short of pm's could be trivially added?
  ZSociety
 ZeroMe :+1:
 Would it be possible to create a normal website which isolates large media files or sections of the website so that a viewer onlky downloads them when they try to view it?

Or is the Merger Sites feature only restricted to the social site being planned?
 @HelloZeroNet Thanks. Can you explain the syntax of that Optional Files argument? So say if I wanted to make MP3 embedded audio or embedded PDFs optional, how would I do it? What are the js and css arguments in that syntax string?

To save having to go to the other page, here is the Optional Files argument for everybody:

"optional": "((js|css)/(?!all.(js|css))|data/mp4-._/._)",

Here is another one:

"optional": ".*\.(jpg|png|gif)",
 @HelloZeroNet, so when the release date? :)
 Zerotopia would have been awesome.
 Great news! Is there a zite address you could share with us?
  I 'm thinking about the idea to implement a RSS module to follow specific ZeroBlogs
If it is possible ?
 It might be possible to have possibility to be warned when desired content has been updated
 I'm using RSS feeds for some things
 Yes, if there are blogs out there then it would be useful to know when new posts appear.
 I use RSS extensively. I donâ€™t know what the alternative is, besides constantly reloading sites.

If the RSS was generated along with / from the html file, I think it would work. One would simply point the aggregator to the generated, static file.
 You could add a new command to have a RSS feed be generated based on some html elements you give in arguments?
  I tried to add an image called `logo.png` to `SITE_HASH/img/.`
and I signed the `content.json` thanks to the right window
and then I tried to published it
But the image doesn't change

How can I do this ?
  The installation instructions for using ZeroNet through Tor on Linux (https://github.com/HelloZeroNet/ZeroNet/blob/master/tools/tor/manual_install.txt) say to uncomment the following line in the torrc file

```
#ControlPort 9051
```

However, my torrc (Ubuntu 14.04, Tor 0.2.7.6) says right after that line

```
## If you enable the controlport, be sure to enable one of these
## authentication methods, to prevent attackers from accessing it.
#HashedControlPassword
#CookieAuthentication 1
```

That sounds like it would be a bad idea to not do this. The tools/tor/torrc file that is used for Windows I believe, has the line CookieAuthentication uncommented., so I tried uncommenting that line in my own torrc, but then ZeroNet reports an error saying it doesn't have permission to read the cookie file, seems to need root access.
 Awesome, thanks for the quick and detailed reply! The Debian instructions worked fine on Ubuntu, even the group name is the same (debian-tor). Works like a charm now :)
  I started the Tor Browser, restarted ZeroNet and nothing happened. There is just the text "TOR: Waiting". How can I connect to the Tor Network introduced in version 0.3.5 (r830)? Maybe the issue is already posted here.
 Read the FAQ, followed the instructions but the same thing happened.
 Ubuntu GNOME 15.10
 Okay, thanks for helping.
 I'm looking for similar instructions for OSX + Tor Browser.

I've tried several things but can't find what to do.

in `tools/tor/torrc` I'm trying with:

```
ControlPort 9151
SOCKSPort 9150
CookieAuthentication 0
```

TorBrowser seems to be using SOCKS5 on :9150.

I also have success with:

```
echo 'PROTOCOLINFO' | nc 127.0.0.1 9151
250-PROTOCOLINFO 1
250-AUTH METHODS=COOKIE,SAFECOOKIE,HASHEDPASSWORD COOKIEFILE="/opt/homebrew-cask/Caskroom/torbrowser/4.5.3/TorBrowser.app/TorBrowser/Data/Tor/control_auth_cookie"
250-VERSION Tor="0.2.7.6"
250 OK
```

But whatever I try I get
`TorManager Tor controller connect error: error: [Errno 61] Connection refused in TorManager.py line 154 > socket.py line 344`
 It works!  But then, what's the torrc file for?
 OK so it's a documentation issue. Here's some text that could be added to
â€œFrequently asked questions - ZeroNetâ€ just after the Linux block:
http://zeronet.readthedocs.org/en/latest/faq/#how-to-use-zeronet-with-tor

```
### How to make ZeroNet work with Tor Browser under OS X?

Install TorBrowser.app; it exposes ports 9150 (SOCKS proxy) and 9151
(Control Port).
Launch `python start.py --tor always --tor_proxy 127.0.0.1:9150
--tor_controller 127.0.0.1:9151`

Allow TorBrower to connect to localhost: Settings > Advanced > Configure how Tor Browser connects to the Internet > Add 127.0.0.1 in â€œNo proxy forâ€
```
 1. I understand. Not sure I fully agree, I like the idea to have zeronet connect through TorBrowser: it makes things easier to install and understand (is it on, is it off? You can see it immediately).
2. Currently the zeronet docs leads to Tor official install page, which in turn recommends TorBrowser in **bold face** on the first line of https://www.torproject.org/docs/tor-doc-osx.html.en 

Now, here's what happens when I quit TorBrowser.app and browse to a site that isn't available locally:

```
[15:39:22] TorManager Tor addOnion error:
[15:39:22] - Unhandled exception
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/gevent/greenlet.py", line 327, in run
    result = self._run(*self.args, **self.kwargs)
  File "plugins/AnnounceZero/AnnounceZeroPlugin.py", line 69, in announceTracker
    onion = self.connection_server.tor_manager.getOnion(site.address)
  File "/Users/fil/Source/zeronet/ZeroNet/src/Tor/TorManager.py", line 256, in getOnion
    self.site_onions[site_address] = self.addOnion()
  File "/Users/fil/Source/zeronet/ZeroNet/src/Tor/TorManager.py", line 197, in addOnion
    res = self.request("ADD_ONION NEW:RSA1024 port=%s" % self.fileserver_port)
  File "/Users/fil/Source/zeronet/ZeroNet/src/Tor/TorManager.py", line 229, in request
    return self.send(cmd)
  File "/Users/fil/Source/zeronet/ZeroNet/src/Tor/TorManager.py", line 235, in send
    conn.send("%s\r\n" % cmd)
  File "/usr/local/lib/python2.7/site-packages/gevent/socket.py", line 437, in send
    return sock.send(data, flags)
error: [Errno 32] Broken pipe
```
 I don't quit TorBrowser.app very often, it was just for testing :)

When it comes to online/offline connectivity, I guess it's the same problem with tor as a service.
 Mac OS is a Unix based system, so the Linux binaries should work with Mac, I guess.
 What about this?

https://www.torproject.org/docs/tor-doc-osx.html.en
 Or you can use proxifier, and set your proxy to 127.0.0.1:9150
  ```
$ uname -a
CYGWIN_NT-6.1 Gems 2.3.1(0.291/5/3) 2015-11-14 12:44 x86_64 Cygwin
```

```
$ openssl version
OpenSSL 1.0.2e 3 Dec 2015
```

```
$ python --version
Python 2.7.10
```

```
$ pip list
binwalk (2.1.0)
bsddb3 (6.1.0)
bzr (2.7.0.dev1)
bzr-fastimport (0.13.0.final.0)
cffi (0.9.2)
cryptography (0.8.2)
cvs2svn (2.4.0)
ecdsa (0.13)
enum34 (1.0.4)
fastimport (0.9.2)
getmail (4.36.0)
gevent (1.0.1)
greenlet (0.4.9)
msgpack-python (0.4.6)
Pillow (2.8.1)
pip (7.1.2)
ply (3.6)
pyasn1 (0.1.6)
pycparser (2.12)
pygobject (3.18.2)
pyOpenSSL (0.15.1)
pyzmq (15.0.0)
setuptools (18.5)
simplejson (3.6.5)
six (1.9.0)
urlgrabber (3.1.0)
wheel (0.26.0)
```

```
$ python zeronet.py --version
- Starting ZeroNet...
- OpenSSL *load failed: function 'BN_new' not found*, falling back to slow bitcoin verify
ZeroNet 0.3.4 r664
```

```
$ python zeronet.py
- Starting ZeroNet...
[20:23:43] - OpenSSL load failed: function 'BN_new' not found, falling back to slow bitcoin verify
[20:23:43] - Version: 0.3.4 r664, Python 2.7.10 (default, Jun  1 2015, 18:05:38)
[GCC 4.9.2], Gevent: 1.0.1
Traceback (most recent call last):
  File "zeronet.py", line 15, in main
    main.start()
  File "src/main.py", line 340, in start
    actions.call(config.action, action_kwargs)
  File "src/main.py", line 96, in call
    func(**kwargs)
  File "src/main.py", line 102, in main
    from File import FileServer
  File "src/File/__init__.py", line 1, in <module>
    from FileServer import FileServer
  File "src/File/FileServer.py", line 12, in <module>
    from Connection import ConnectionServer
  File "src/Connection/__init__.py", line 1, in <module>
    from ConnectionServer import ConnectionServer
  File "src/Connection/ConnectionServer.py", line 13, in <module>
    from Connection import Connection
  File "src/Connection/Connection.py", line 10, in <module>
    from Crypt import CryptConnection
  File "src/Crypt/CryptConnection.py", line 7, in <module>
    from util import SslPatch
  File "src/util/SslPatch.py", line 28, in <module>
    disableSSLCompression()
  File "src/util/SslPatch.py", line 22, in disableSSLCompression
    openssl.sk_zero.argtypes = [ctypes.c_void_p]
  File "/usr/lib/python2.7/ctypes/__init__.py", line 378, in __getattr__
    func = self.__getitem__(name)
  File "/usr/lib/python2.7/ctypes/__init__.py", line 383, in __getitem__
    func = self._FuncPtr((name_or_ordinal, self))
AttributeError: function 'sk_zero' not found

{exit}
```

```
$ python zeronet.py --disable_sslcompression False
- Starting ZeroNet...
[20:41:46] - OpenSSL load failed: function 'BN_new' not found, falling back to slow bitcoin verify
[20:41:46] - Version: 0.3.4 r664, Python 2.7.10 (default, Jun  1 2015, 18:05:38)
[GCC 4.9.2], Gevent: 1.0.1
[20:41:46] - Creating FileServer....
[20:41:46] - Creating UiServer....
[20:41:46] - Removing old SSL certs...
[20:41:46] - Starting servers....
[20:41:46] Ui.UiServer --------------------------------------
[20:41:46] Ui.UiServer Web interface: http://127.0.0.1:43110/
[20:41:46] Ui.UiServer --------------------------------------
[20:41:47] FileServer Checking port 15441 using portchecker.co...
[20:41:48] FileServer [OK :)] Port open: Port 15441 is open.
...
{but}
...
[20:46:27] Site:1MaiL5..Ju27 WebSocket handleRequest error: AttributeError: function 'BN_new' not found in UiWebsocket.py line 65 > UiWebsocket.py line 143 > CryptMessagePlugin.py line 89 > __init__.py line 16 > openssl.py line 449 > openssl.py line 439 > openssl.py line 49 > __init__.py line 378 > __init__.py line 383
[20:46:27] Site:1MaiL5..Ju27 Publishing to 5/27 peers (connected: 21)...

{worked}
```
 This don`t work to me 

```
$ python -c "print __import__('ctypes.util').util.find_library('libcrypto')"
None
```

```
pip list | grep crypto
cryptography (1.1.2)
ctypescrypto (0.3.1)
pycrypto (2.6.1)
```
 ```
ldd /usr/bin/openssl
        ntdll.dll => /cygdrive/c/Windows/SYSTEM32/ntdll.dll (0x76cb0000)
        kernel32.dll => /cygdrive/c/Windows/system32/kernel32.dll (0x76b90000)
        KERNELBASE.dll => /cygdrive/c/Windows/system32/KERNELBASE.dll (0x7fefcd80000)
        cygcrypto-1.0.0.dll => /usr/bin/cygcrypto-1.0.0.dll (0x5e40e0000)
        cygwin1.dll => /usr/bin/cygwin1.dll (0x180040000)
        cygz.dll => /usr/bin/cygz.dll (0x3f3280000)
        cygssl-1.0.0.dll => /usr/bin/cygssl-1.0.0.dll (0x5eb130000)
```

```
$ tar tfv x86_64/release/openssl/libopenssl100/libopenssl100-1.0.2e-1.tar.xz
-rwxr-xr-x corinna/vinschen 2270227 2015-12-03 23:47 usr/bin/cygcrypto-1.0.0.dll
-rwxr-xr-x corinna/vinschen  433683 2015-12-03 23:47 usr/bin/cygssl-1.0.0.dll
drwxr-xr-x corinna/vinschen       0 2015-12-03 23:47 usr/lib/openssl-1.0.2/engines/
-rwxr-xr-x corinna/vinschen   18451 2015-12-03 23:47 usr/lib/openssl-1.0.2/engines/lib4758cca.so
-rwxr-xr-x corinna/vinschen   18963 2015-12-03 23:47 usr/lib/openssl-1.0.2/engines/libaep.so
-rwxr-xr-x corinna/vinschen   14867 2015-12-03 23:47 usr/lib/openssl-1.0.2/engines/libatalla.so
-rwxr-xr-x corinna/vinschen   22035 2015-12-03 23:47 usr/lib/openssl-1.0.2/engines/libcswift.so
-rwxr-xr-x corinna/vinschen    8723 2015-12-03 23:47 usr/lib/openssl-1.0.2/engines/libgmp.so
-rwxr-xr-x corinna/vinschen   22547 2015-12-03 23:47 usr/lib/openssl-1.0.2/engines/libchil.so
-rwxr-xr-x corinna/vinschen   13843 2015-12-03 23:47 usr/lib/openssl-1.0.2/engines/libnuron.so
-rwxr-xr-x corinna/vinschen   25619 2015-12-03 23:47 usr/lib/openssl-1.0.2/engines/libsureware.so
-rwxr-xr-x corinna/vinschen   19987 2015-12-03 23:47 usr/lib/openssl-1.0.2/engines/libubsec.so
-rwxr-xr-x corinna/vinschen    8723 2015-12-03 23:47 usr/lib/openssl-1.0.2/engines/libpadlock.so
-rwxr-xr-x corinna/vinschen    8723 2015-12-03 23:47 usr/lib/openssl-1.0.2/engines/libcapi.so
-rwxr-xr-x corinna/vinschen   93715 2015-12-03 23:47 usr/lib/openssl-1.0.2/engines/libgost.so
```
 ```
Gem@Gems /cygdrive/c/Program Files/Microsoft SDKs/Windows/v7.1
$ python -c "print '%.9X' % __import__('ctypes').CDLL('/bin/cygcrypto-1.0.0.dll').SSLeay()"
01000205F
```
 ```
Microsoft (R) COFF/PE Dumper Version 10.00.30319.01
Copyright (C) Microsoft Corporation.  All rights reserved.


Dump of file C:\cygwin64\bin\cygcrypto-1.0.0.dll

File Type: DLL

  Section contains the following exports for cygcrypto-1.0.0.dll

    00000000 characteristics
    5660A83B time date stamp Thu Dec 03 23:38:19 2015
        0.00 version
           1 ordinal base
        4218 number of functions
        4218 number of names

    ordinal hint RVA      name

          1    0 001354B0 ACCESS_DESCRIPTION_free
          2    1 001DA5E0 ACCESS_DESCRIPTION_it
          3    2 001354E0 ACCESS_DESCRIPTION_new
          4    3 000414B0 AES_bi_ige_encrypt
          5    4 00042CD0 AES_cbc_encrypt
          6    5 00040F90 AES_cfb128_encrypt
          7    6 00040FD0 AES_cfb1_encrypt
          8    7 00041010 AES_cfb8_encrypt
          9    8 00041080 AES_ctr128_encrypt
         10    9 000426D0 AES_decrypt
         11    A 00040F70 AES_ecb_encrypt
         12    B 00042120 AES_encrypt
         13    C 000410C0 AES_ige_encrypt
         14    D 00041050 AES_ofb128_encrypt
         15    E 00040F40 AES_options
         16    F 00040F60 AES_set_decrypt_key
         17   10 00040F50 AES_set_encrypt_key
         18   11 00041C80 AES_unwrap_key
         19   12 0018AB20 AES_version
         ...
        2566  A05 00164C60 SRP_get_default_gN
        2567  A06 00004150 SSLeay
        2568  A07 00004100 SSLeay_version
        2569  A08 001C82C0 STACK_version
        2570  A09 00131410 SXNETID_free
        2571  A0A 001D9260 SXNETID_it
        2572  A0B 00131400 SXNETID_new
        ...
        4215 1076 00032F40 whirlpool_block
        4216 1077 0016FF40 x509_dir_lookup
        4217 1078 0016FEC0 x509_file_lookup
        4218 1079 001CF820 x509_name_ff
 ...
```
 ...but no effect - function 'BN_new' not found

```
$ python zeronet.py
- Starting ZeroNet...
[10:41:14] - OpenSSL load failed: function 'BN_new' not found, falling back to slow bitcoin verify
[10:41:14] - Version: 0.3.4 r665, Python 2.7.10 (default, Jun  1 2015, 18:05:38)
[GCC 4.9.2], Gevent: 1.0.1
[10:41:15] - Creating FileServer....
```

requested 

```
Benchmarking ZeroNet 0.3.4 (rev665) Python 2.7.10 (default, Jun 1 2015, 18:05:38) [GCC 4.9.2] on: cygwin...

CryptBitcoin:
- hdPrivatekey x 10..........0.158s [x4.43: Insane!!]
- sign x 10..........0.071s [x4.93: Insane!!]
- openssl verify x 100...not avalible :(
- pure-python verify x 10..........0.352s [x4.55: Insane!!]

CryptHash:
- sha512 x 100 000..........0.374s [x2.67: WOW]
- os.urandom(256) x 100 000..........0.290s [x2.24: Fast]

Msgpack:
- pack 5K x 10 000..........0.334s [x2.34: Fast]
- unpack 5K x 10 000..........0.530s [x2.26: Fast]
- streaming unpack 5K x 10 000..........0.576s [x2.43: Fast]

Db:
- Open x 10..........0.037s [x3.51: Insane!!]
- Insert x 10 x 1000..........0.484s [x2.07: Fast]
- Buffered insert x 100 x 100..........0.641s [x2.03: Fast]
- Total rows in db: 20000
- Indexed query x 1000..........0.356s [x0.70: Goodish]
- Not indexed query x 100..........0.245s [x2.45: Fast]
- Like query x 100..........0.526s [x3.42: WOW]

Done. Total: 5.16s
```

if open ZeroMail

```
...
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
src/lib/opensslVerify/libeay32.dll
[11:04:28] Site:1MaiL5..Ju27 WebSocket handleRequest error: AttributeError: function 'BN_new' not found in UiWebsocket.py line 65 > UiWebsocket.py line 143 > CryptMessagePlugin.py line 89 > __init__.py line 16 > openssl.py line 456 > openssl.py line 445 > openssl.py line 49 > __init__.py line 378 > __init__.py line 383
Internal error: AttributeError: function 'BN_new' not found
UiWebsocket.py line 65 > UiWebsocket.py line 143 > CryptMessagePlugin.py line 89 > __init__.py line 16 > openssl.py line 456 > openssl.py line 445 > openssl.py line 49 > __init__.py line 378 > __init__.py line 383
```
 Fixed

```
$ python zeronet.py
- Starting ZeroNet...
[02:38:17] - OpenSSL loaded, version: 01000205F
[02:38:17] - Version: 0.3.4 r667, Python 2.7.10 (default, Jun  1 2015, 18:05:38)
[GCC 4.9.2], Gevent: 1.0.1
[02:38:17] - Creating FileServer....
[02:38:17] - Creating UiServer....
[02:38:18] - Removing old SSL certs...
[02:38:18] - Starting servers....
[02:38:18] Ui.UiServer --------------------------------------
[02:38:18] Ui.UiServer Web interface: http://127.0.0.1:43110/
[02:38:18] Ui.UiServer --------------------------------------
[02:38:19] FileServer Checking port 15441 using portchecker.co...
[02:38:20] FileServer [OK :)] Port open: Port 15441 is open.
```

```
Benchmarking ZeroNet 0.3.4 (rev667) Python 2.7.10 (default, Jun 1 2015, 18:05:38) [GCC 4.9.2] on: cygwin...

CryptBitcoin:
- hdPrivatekey x 10..........0.144s [x4.86: Insane!!]
- sign x 10..........0.070s [x5.00: Insane!!]
- openssl verify x 100..........0.082s [x4.51: Insane!!]
- pure-python verify x 10..........0.340s [x4.71: Insane!!]

CryptHash:
- sha512 x 100 000..........0.378s [x2.65: WOW]
- os.urandom(256) x 100 000..........0.289s [x2.25: Fast]

Msgpack:
- pack 5K x 10 000..........0.333s [x2.34: Fast]
- unpack 5K x 10 000..........0.530s [x2.26: Fast]
- streaming unpack 5K x 10 000..........0.576s [x2.43: Fast]

Db:
- Open x 10..........0.035s [x3.71: Insane!!]
- Insert x 10 x 1000..........0.471s [x2.12: Fast]
- Buffered insert x 100 x 100..........0.618s [x2.10: Fast]
- Total rows in db: 20000
- Indexed query x 1000..........0.351s [x0.71: Goodish]
- Not indexed query x 100..........0.242s [x2.48: Fast]
- Like query x 100..........0.512s [x3.52: Insane!!]

Done. Total: 5.17s
```
  Regarding the note about including I2P addresses, it would be a good idea to read I2P's BitTorrent docs (linked in #45) to check how I2P's slight torrent protocol differences would affect ZeroNet. I don't think it should overly affect this ticket, but I'm not familiar with ZeroNet specifics.

Disclaimer: I'm an I2P developer (and happy to answer questions!)
 +1
 Shouldn't also each seeder start a hidden service for each site he/she serves?
 I mean each seeder should run a tor hidden service to actually serve .onion sites right?
 Neat ! Thanks for the explanation check the links i wrote about here too :

https://github.com/HelloZeroNet/ZeroNet/issues/60
  At start (python zeronet.py) when is executed FileServer.py in NAT Internet connection (port 43110 closed) It is shows:

```
python zeronet.py
- Starting ZeroNet...
[22:58:27] - OpenSSL loaded, version: 01000110F
[22:58:27] - Version: 0.3.4 r664, Python 2.7.9 (default, Dec 13 2014, 22:06:10) 
[GCC 4.8.2], Gevent: 1.0.2
[22:58:27] - Creating FileServer....
[22:58:27] - Creating UiServer....
[22:58:27] - Removing old SSL certs...
[22:58:27] - Starting servers....
[22:58:27] Ui.UiServer --------------------------------------
[22:58:27] Ui.UiServer Web interface: http://127.0.0.1:43110/
[22:58:27] Ui.UiServer --------------------------------------
[22:58:28] FileServer Checking port 15441 using portchecker.co...
[22:58:30] FileServer [BAD :(] Port closed: Port 15441 is closed.
[22:58:30] FileServer Checking port 15441 using canyouseeme.org...
```

and it waits an infinite time.

Log shows (Last rows):

```
[2015-12-13 23:04:18,537] DEBUG    Site:1Gfey7..fcdp Found 30 peers, new: 2
[2015-12-13 23:04:18,909] DEBUG    Site:1EU1tb..E4Vr Small number of peers detected...query all of peers using pex
[2015-12-13 23:04:18,910] DEBUG    Site:1EU1tb..E4Vr 152.236.101.192:15441 Getting connection...
[2015-12-13 23:04:18,910] DEBUG    FileServer Conn# 1 152.236.101.192 [?] > Connecting...
[2015-12-13 23:04:19,058] DEBUG    Site:1Gfey7..fcdp Announced port 0 to 6 trackers in 1.148s, errors: [], slow: []
[2015-12-13 23:04:19,058] DEBUG    Site:1Gfey7..fcdp Need connections: 3, Current: 0, Total: 29
[2015-12-13 23:04:19,058] DEBUG    Site:1Gfey7..fcdp 77.129.41.159:15441 Getting connection...
[2015-12-13 23:04:19,058] DEBUG    FileServer Conn# 2 77.129.41.159 [?] > Connecting...
[2015-12-13 23:04:19,337] DEBUG    FileServer Conn# 2 77.129.41.159 [v2] > Crypt out connection using: tls-rsa (server side: False)...
```
 Tanx a Lot! It is ok but is encryption needed?

```
python zeronet.py --disable_encryption
- Starting ZeroNet...
[23:23:17] - OpenSSL loaded, version: 01000110F
[23:23:17] - Version: 0.3.4 r664, Python 2.7.9 (default, Dec 13 2014, 22:06:10) 
[GCC 4.8.2], Gevent: 1.0.2
[23:23:17] - Creating FileServer....
[23:23:17] - Creating UiServer....
[23:23:17] - Removing old SSL certs...
[23:23:17] - Starting servers....
[23:23:17] Ui.UiServer --------------------------------------
[23:23:17] Ui.UiServer Web interface: http://127.0.0.1:43110/
[23:23:17] Ui.UiServer --------------------------------------
[23:23:18] FileServer Checking port 15441 using portchecker.co...
[23:23:20] FileServer [BAD :(] Port closed: Port 15441 is closed.
[23:23:20] FileServer Checking port 15441 using canyouseeme.org...
[23:23:28] FileServer [BAD :(] Port closed: Error: I could not see your service on 151.47.48.210 on port (15441) Reason: Connection timed out
[23:23:28] FileServer Trying to open port using UpnpPunch...
[23:23:44] FileServer Checking port 15441 using portchecker.co...
[23:23:46] FileServer [BAD :(] Port closed: Port 15441 is closed.
[23:23:46] FileServer Checking port 15441 using canyouseeme.org...
[23:23:54] FileServer [BAD :(] Port closed: Error: I could not see your service on 151.47.48.210 on port (15441) Reason: Connection timed out
[23:23:54] FileServer Upnp mapping failed :( Please forward port 15441 on your router to your ipaddress
[23:24:05] Site:1TaLkF..jipT data/users/1BwGNVyjmbqbuofH5WbwHgPUBtxZBvLQ7K/data.json file size does not match 1407 <> 1362, Hash: False
[23:24:05] Site:1TaLkF..jipT data/users/1BwGNVyjmbqbuofH5WbwHgPUBtxZBvLQ7K/data.json file size does not match 1407 <> 1362, Hash: False
...
```

P.S. Can I copy and past the old DATA dir in the new version of zeronet?
 Is encription problem mine or is a bug?
 Yes, excuse me. I have linux, my distro is mageia 4, my kernel is $ uname -r
3.14.43-server-1.mga4
 It is a KDE.
  Affero further protects the project against SaaSS :)
 Me neither, but this assures you that the service provider will need to publish your source code freely and any modifications made to it :)
 GPL is restrictive enough. It seems as if pizzamaker is trying to ensure noone tries to use the s/w commercially.
 @unsystemizer AGPL does not restrict commercial use of software. It merely posits that any changes to the code must be given back to the community that made it.
 @pizzamaker yeah and what kind of effect does that have on commercial use of software? Or, if AGPL doesn't restrict anything more than the current license, why are you proposing it? Of course you're proposing it to restrict the use of s/w. 
But I don't want to get into license wars here, I'll just say take a look at the recent trend (I won't copy the graphic here, but pay attention to Figure 2 and the collapse in GPL (and the death of Affero). And the explosive growth of permissive licenses such as MIT and Apache. (I'd prefer the license should be changed to MIT, if it changes)
Source: http://osswatch.jiscinvolve.org/wp/2015/02/05/open-source-software-licensing-trends/

The author(s) is (are) obviously the ones to decide, I'm not making any demands.
 Affero closes a known loophole in the GPL, when it comes to webservices: 

> Both versions of the Affero GPL were designed to close a perceived application service provider (ASP) loophole in the ordinary GPL, where, by using but not distributing the software, the copyleft provisions are not triggered. Each version differs from the version of the GNU GPL on which it is based in having an added provision addressing use of software over a computer network. This provision requires that the full source code be made available to any network user of the AGPL-licensed work, typically a web application.
> https://en.wikipedia.org/wiki/Affero_General_Public_License
 Again, it is a loophole by _your_ definition. Not everyone necessarily agrees with you (and as I said, look at the trend, Affero is dead in the water). If decision is made to change, that's fine by me, but most users, as well as devs, (see that Figure 2) have figured out what works well for them. Look at BitTorrent, Bitcoin and other recently successful projects and see what licenses they use.
 It's amusing to consider whether ZeroNet is a client or server application. It's neither and both. As I understand it, AGPL is primarily useful for server based applications which the user doesn't install themselves - similar to Google's stuff which might be free in the background but unfree from the user point of view. I don't have a strong opinion on whether it should be GPL or AGPL. If there are use cases where ZeroNet could be run as a server then AGPL would make sense.
 @bashrc Due to the SaaSS trend, it's best to use AGPL for everything these days, since even full-featured desktop applications like GIMP have been transformed into web apps.
 I agree that this would be a good license.
 nonsense (and poorly argued one at that)
above i posted a link that shows what the real trend is.
 K. I would use it though. That's my opinion. Not forcing anyone to use it.

On 06 June 2016 7:40:24 AM SAST, unsystemizer notifications@github.com wrote:

> nonsense (and poorly argued one for at that)
> above i posted a link that shows what the real trend is.
> 
> ---
> 
> You are receiving this because you commented.
> Reply to this email directly or view it on GitHub:
> https://github.com/HelloZeroNet/ZeroNet/issues/224#issuecomment-223872586

## 

Sent from my Android device with K-9 Mail. Please excuse my brevity.
 i said the same (not demanding anything), but since you are arguing for a change can you provide arguments as you see them?
 Well someone can host a proxy and therefore using ZeroNet as a server.
 so what? thats the whole point, to let people share information. 
the same setup can be done with Bittorrent and IPFS and tons of other apps.
 Yeah. But they could make improvements to the proxy they run that you might like. Intact they could improve the whole ZeroNet system.

On 06 June 2016 8:58:57 PM SAST, unsystemizer notifications@github.com wrote:

> so what? thats the whole point, to let people share information. 
> the same setup can be done with Bittorrent and IPFS and tons of other
> apps.
> 
> ---
> 
> You are receiving this because you commented.
> Reply to this email directly or view it on GitHub:
> https://github.com/HelloZeroNet/ZeroNet/issues/224#issuecomment-224054274

## 

Sent from my Android device with K-9 Mail. Please excuse my brevity.
 in all likelihood we would benefit from that
 Yeah. My point exactly.

On 06 June 2016 9:18:39 PM SAST, unsystemizer notifications@github.com wrote:

> in all likelihood we would benefit from that
> 
> ---
> 
> You are receiving this because you commented.
> Reply to this email directly or view it on GitHub:
> https://github.com/HelloZeroNet/ZeroNet/issues/224#issuecomment-224059531

## 

Sent from my Android device with K-9 Mail. Please excuse my brevity.
 Has anybody looked at the [Apache License](http://choosealicense.com/licenses/apache-2.0/) ? Looks like a nice fit to me.
 > Well, I'm not against if someone offers ZeroNet hosting as service.

Yes, that would be great!

The issue though, is to ensure the users of that service can get the ZeroNet source code that's being used, and improve and share it. That is why the AGPL 3+ is a good choice of license.
  Hi, 
I tried ZeroNet on a computer, and it opened Upnp ports on the connected router
Then I tried ZeroNet on another computer behind the same router
and it was not able to open ports for this other IP address,
so I was not able to distribute the network,
so I removed the old UPnP configuration on my router, 
and I reloaded ZeroNet, and it opened the ports of the new IP address.

;)

Hope it helps to improve the software

Error logs :

[mardi 8 dÃ©cembre 2015, 12:58:47 (UTC+0100)] ZeroNet is starting
- Starting ZeroNet...
[12:58:48] - Version: 0.3.2 r494, Python 2.7.6 (default, Jun 22 2015, 17:58:13) 
[GCC 4.8.2], Gevent: 1.1b7.dev0
[12:58:48] - OpenSSL loaded, version: 01000106F
[12:58:48] - Creating FileServer....
[12:58:48] - Creating UiServer....
[12:58:51] - Removing old SSL certs...
[12:58:51] - Starting servers....
[12:58:51] Ui.UiServer --------------------------------------
[12:58:51] Ui.UiServer Web interface: http://127.0.0.1:43110/
[12:58:51] Ui.UiServer --------------------------------------
[12:58:52] FileServer Checking port 15441 using portchecker.co...
[12:58:54] FileServer [BAD :(] Port closed: Port 15441 is closed.
[12:58:54] FileServer Checking port 15441 using canyouseeme.org...
[12:59:07] FileServer [BAD :(] Port closed: Error: I could not see your service on 86.195.53.48 on port (15441) Reason: Connection timed out
[12:59:07] FileServer Trying to open port using UpnpPunch...
**[12:59:07] - Unhandled exception
Traceback (most recent call last):**
  File "/usr/local/lib/python2.7/dist-packages/gevent/greenlet.py", line 523, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/util/UpnpPunch.py", line 171, in _send_soap_request
    return _parse_for_errors(response)
  File "src/util/UpnpPunch.py", line 139, in _parse_for_errors
    err_dom = parseString(soap_response.read())
  File "/usr/lib/python2.7/xml/dom/minidom.py", line 1928, in parseString
    return expatbuilder.parseString(string)
  File "/usr/lib/python2.7/xml/dom/expatbuilder.py", line 940, in parseString
    return builder.parseString(string)
  File "/usr/lib/python2.7/xml/dom/expatbuilder.py", line 223, in parseString
    parser.Parse(string, True)
**ExpatError: no element found: line 1, column 0
Traceback (most recent call last):**
  File "/usr/local/lib/python2.7/dist-packages/gevent/greenlet.py", line 523, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/util/UpnpPunch.py", line 171, in _send_soap_request
    return _parse_for_errors(response)
  File "src/util/UpnpPunch.py", line 139, in _parse_for_errors
    err_dom = parseString(soap_response.read())
  File "/usr/lib/python2.7/xml/dom/minidom.py", line 1928, in parseString
    return expatbuilder.parseString(string)
  File "/usr/lib/python2.7/xml/dom/expatbuilder.py", line 940, in parseString
    return builder.parseString(string)
  File "/usr/lib/python2.7/xml/dom/expatbuilder.py", line 223, in parseString
    parser.Parse(string, True)
**xml.parsers.expat.ExpatError: no element found: line 1, column 0
[12:59:07] - Unhandled exception
Traceback (most recent call last):**
  File "/usr/local/lib/python2.7/dist-packages/gevent/greenlet.py", line 523, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/util/UpnpPunch.py", line 171, in _send_soap_request
    return _parse_for_errors(response)
  File "src/util/UpnpPunch.py", line 139, in _parse_for_errors
    err_dom = parseString(soap_response.read())
  File "/usr/lib/python2.7/xml/dom/minidom.py", line 1928, in parseString
    return expatbuilder.parseString(string)
  File "/usr/lib/python2.7/xml/dom/expatbuilder.py", line 940, in parseString
    return builder.parseString(string)
  File "/usr/lib/python2.7/xml/dom/expatbuilder.py", line 223, in parseString
    parser.Parse(string, True)
ExpatError: no element found: line 1, column 0
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/gevent/greenlet.py", line 523, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/util/UpnpPunch.py", line 171, in _send_soap_request
    return _parse_for_errors(response)
  File "src/util/UpnpPunch.py", line 139, in _parse_for_errors
    err_dom = parseString(soap_response.read())
  File "/usr/lib/python2.7/xml/dom/minidom.py", line 1928, in parseString
    return expatbuilder.parseString(string)
  File "/usr/lib/python2.7/xml/dom/expatbuilder.py", line 940, in parseString
    return builder.parseString(string)
  File "/usr/lib/python2.7/xml/dom/expatbuilder.py", line 223, in parseString
    parser.Parse(string, True)
**xml.parsers.expat.ExpatError: no element found: line 1, column 0**
[12:59:11] FileServer Checking port 15441 using portchecker.co...
[12:59:13] FileServer [BAD :(] Port closed: Port 15441 is closed.
[12:59:13] FileServer Checking port 15441 using canyouseeme.org...
[12:59:21] FileServer [BAD :(] Port closed: Error: I could not see your service on YOU_PUBLIC_IP_ADDRESS on port (15441) Reason: Connection timed out
[12:59:21] FileServer Upnp mapping failed :( Please forward port 15441 on your router to your ipaddress`
 :+1: Same issue. This thing doesn't work on Vagrant, now doesn't work on Docker either.
 Same issue.
 Same Thing Here... My partner at my side using Windows 10 connected with no advices. So i, opened website shown and loaded successfully. Here's the terminal description:

`
- ~/ZeroBundle$ sudo ./ZeroNet.sh 
- Starting ZeroNet...
- OpenSSL loaded, version: 01000207F
- Version: 0.3.6 r1089, Python 2.7.11 |Continuum Analytics, Inc.| (default, Dec  6 2015, 18:08:32) 
  [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)], Gevent: 1.0.2
- Creating FileServer....
  TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 154 > socket.py line 344
- Creating UiServer....
- Removing old SSL certs...
- Starting servers....
- Ui.UiServer --------------------------------------
- Ui.UiServer Web interface: http://127.0.0.1:43110/
- Ui.UiServer --------------------------------------
- Opening browser: default_browser...
- FileServer Checking port 15441 using portchecker.co...
- FileServer [BAD :(] Port closed: Port 15441 is closed.
- FileServer Trying to open port using UpnpPunch...
- FileServer Checking port 15441 using portchecker.co...
- FileServer [BAD :(] Port closed: Port 15441 is closed.
- FileServer Checking port 15441 using canyouseeme.org...
- FileServer [BAD :(] Port closed: Error: I could not see your service on 186.67.115.230 on port (15441) Reason: Connection timed out
- FileServer Upnp mapping failed :( Please forward port 15441 on your router to your ipaddress
  `
 Could you explained it's theory? 
 I have the same things. But when I run UpnpPunch.py , I found it can addportmapping ok.

```
- Starting ZeroNet...
[19:29:52] - OpenSSL loaded, version: 0009081DF
[19:29:52] - Version: 0.3.7 r1287, Python 2.7.11 (default, Jan 22 2016, 08:29:18)
[GCC 4.2.1 Compatible Apple LLVM 7.0.2 (clang-700.1.81)], Gevent: 1.1.1
[19:29:52] - Creating FileServer....
[19:29:52] TorManager Tor controller connect error: error: [Errno 61] Connection refused in TorManager.py line 154 > _socket2.py line 228
[19:29:52] - Creating UiServer....
[19:29:59] - Removing old SSL certs...
[19:29:59] - Starting servers....
[19:29:59] Ui.UiServer --------------------------------------
[19:29:59] Ui.UiServer Web interface: http://127.0.0.1:43110/
[19:29:59] Ui.UiServer --------------------------------------
[19:29:59] - Opening browser: default_browser...
[19:30:01] FileServer Checking port 15441 using portchecker.co...
[19:30:03] FileServer [BAD :(] Port closed: Port 15441 is closed.
[19:30:03] FileServer Trying to open port using UpnpPunch...
[19:30:04] FileServer Checking port 15441 using portchecker.co...
[19:30:06] FileServer [BAD :(] Port closed: Port 15441 is closed.
[19:30:06] FileServer Checking port 15441 using canyouseeme.org...
[19:30:15] FileServer [BAD :(] Port closed: Error: I could not see your service on 111.193.200.234 on port (15441) Reason: Connection timed out
[19:30:15] FileServer Upnp mapping failed :( Please forward port 15441 on your router to your ipaddress
[19:30:47] Site:1MaiL5..Ju27 data/users/1NS9qMabhcMJpQqeqeFy14j3z9DkqNCWzS/content.json: Site too large 10486472 > 10485760, aborting task...
```

I think the open_port is working, But why it tell me upnp mapping failed? 

```
> python UpnpPunch.py
DEBUG:root:Found local ips: ['192.168.xx.xx']
DEBUG:root:Trying using local ip: 192.168.xx.xx
DEBUG:root:Sending UPnP request to 192.168.xx.1:37215...
DEBUG:root:Sending UPnP request to 192.168.xx.1:37215...
True
Done in 0.22724199295
```
 Have you managed to solve the problem @ghost ? 

  siteSign in debian distro (8/7) doesnt work
- OpenSSL loaded, version: 01000105F
  Traceback (most recent call last):
  File "zeronet.py", line 15, in main
    main.start()
  File "src/main.py", line 331, in start
    actions.call(config.action, action_kwargs)
  File "src/main.py", line 96, in call
    func(**kwargs)
  File "src/main.py", line 156, in siteSign
    site_data = user.getSiteData(address)
  AttributeError: 'NoneType' object has no attribute 'getSiteData'
 I run it on linux no x11 only cli and no user is generated !
 I use ssh tunnel to create the first user thanks anyway
  Cloning the blog was a good idea but it needs a dashboard like wordpress has so people can change the look of the blog easier and add media easier. ![new-wp-dashboard](https://cloud.githubusercontent.com/assets/8492776/11361057/3eac8f86-9258-11e5-9e61-c9b46d3fce17.png)
   "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,_/_;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate, sdch", 
    "HTTP_ACCEPT_LANGUAGE": "en-US,en;q=0.8", 
    "HTTP_CACHE_CONTROL": "max-age=0", 
    "HTTP_CONNECTION": "keep-alive", 
    "HTTP_HOST": "127.0.0.1:43110", 
    "HTTP_REFERER": "http://127.0.0.1:43110/ZeroUpload.bit/?wrapper_nonce=bc050f29c68379a2401e2a6301a46b3a4e1b8fe9d9b32d889572ec6f76c04fc4", 
    "HTTP_UPGRADE_INSECURE_REQUESTS": "1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Dragon/45.6.11.385 Chrome/45.0.2454.93 Safari/537.36", 
    "PATH_INFO": "/ZeroUpload.bit/", 
    "QUERY_STRING": "wrapper_nonce=bc050f29c68379a2401e2a6301a46b3a4e1b8fe9d9b32d889572ec6f76c04fc4", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "2279", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "localhost", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.0 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "coffeescript_compiler": "type %s | tools\coffee\coffee.cmd", 
        "config_file": "zeronet.conf", 
        "data_dir": "data", 
        "debug": false, 
        "debug_socket": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "homepage": "1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr", 
        "ip_external": null, 
        "log_dir": "log", 
        "msgpack_purepython": true, 
        "open_browser": "default_browser", 
        "proxy": null, 
        "size_limit": 10, 
        "stream_downloads": false, 
        "trackers": [
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.aletorrenty.pl:2710/announce", 
            "http://tracker.skyts.net:6969/announce", 
            "http://torrent.gresille.org/announce"
        ], 
        "trackers_file": false, 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "use_openssl": true, 
        "use_tempfiles": false
    }, 
    "plugins": [
        "Sidebar", 
        "Stats", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.0.1", 
    "version_python": "2.7.9 (default, Dec 10 2014, 12:24:55) [MSC v.1500 32 bit (Intel)]", 
    "version_zeronet": "0.3.3 r618", 
    "wsgi.url_scheme": "http"
}

Could this be caused by giving your-self a name change (by editing the user.json file). I changed by name before touching ZeroUpload and it as not caused issues else where.
  When connecting to [ZeroMap](http://127.0.0.1:43110/1yUji4qPD7GAog8XkP3EDMEfrL995S4Xd), I get a Server error:

```
Err: UnicodeDecodeError: 'ascii' codec can't decode byte 0xe9 in position 84: ordinal not in range(128) in UiServer.py line 75 > UiRequest.py line 81 > UiRequest.py line 200 > SiteManagerPlugin.py line 52 > SiteManager.py line 57 > Site.py line 50 > SiteStorage.py line 26 > SiteStorage.py line 221 > SiteStorage.py line 240
```
 It works correctly, thanks. None the less it is a bug if it can't work correctly when having a folder with non-english character?
  I think the Main Page of ZeroNet needs a better design...
Its too big.. it takes so much space....i love the new Side Bar for stats.

Hello
ZeroNet_
This site currently served by ++ peers without any central server. 
Connected sites:

ZeroNet needs more a SocialNet based Design... with useful Navigation Menus:

at Top a Navigation Header Bar like example Twitter would be nice:
Main ( ZeroNet Main Page)
Messages ( if ZeroNet supports anytime Email like Messaging)
Network (Network Page)
Zero ID Profile Button (Display which Zero ID you using, not sure if possible to switch ) 
Plugins 

maybe more ideas...first need a good looking design for easy navigation
 I mean a nice Navigation Menu at top it would be very useful,
 I could be an improvement, Do you have any mockup to show ?  Non-constructive criticism.
@HelloZeroNet Can the issue be closed?  It would be cool, I was going to ask for something like this to send encrypted messages between other users, so it would be possible to exchange data directly to someone without others knowing the content
 Which library is this? I think a basic  public key / private key ability embedded in zeronet will be very useful for a lot of projects

In bip 32 we can have private public keys pairs easily i think and use this unique keys per user for encrypting/decrypting and message signing
 @HelloZeroNet Cool :)
 Neat :) I dont know what library did you use but we can use bitmessage too for text encryption. 
 https://github.com/yann2192/pyelliptic we can use this library. It is cryptografically secure
 This library is used by bitmessage and it is secure. The link on reddit you post is about bitcrypt library not pyelliptic. Actually you can talk to atheros directly i did that he is very helpful
 Neat!
 Please add signatures too https://github.com/yann2192/pyelliptic for signing messages!
 The ability to sign contracts between 2 users using this function?
 And then send it to the other user to sign too? I think its easier through the api commands that us you said are already implemented. Encrypt decrypt sign a message are basic commands
 Good work! Maybe adding encrypting messages for multiple users too...
 If the api commands are ready maybe others can help too. Whatever is best. But it would be pretty 
    Is it possible to host a forum or any website that uses PHP and MYSQL on ZeroNet? Cause I tried to add a `index.php` with mysql support sample and I got error `index.html` message.

It it possible to add it in future versions?
 And if I want to use PHP code eg. to read SQL, manage files, etc can I do it ? 
 of course it wouldn't. Hmmm ok thank you. It's a good project. 
    When I type Ã© and save :
Internal error: 'ascii' codec can't encode character u'\xe9' in position 2: ordinal not in range(128)
  There should be an option to choose wether or not prompt for authentification based on interface
 For example: If you connect on loopback interface it didn't prompt for authentification, but if it is the LAN or WAN interface then it could prompt for authentification
 Yes, I didn't think of that, you can close this issue if you want
  If you change the browser size after the was loaded the button is buggy
  example with parameters:
- ui_ip = *
- ui_restrict =
    127.0.0.1
    192.168.0.253

it display:

```
Forbidden
Please report it if you think this an error.
Details:

{
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8", 
    "HTTP_ACCEPT_ENCODING": "gzip,deflate", 
    "HTTP_ACCEPT_LANGUAGE": "en-us", 
    "HTTP_CONNECTION": "keep-alive", 
    "HTTP_DNT": "1", 
    "HTTP_HOST": "***.***.***.***:43110", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/600.1.17 (KHTML, like Gecko) Version/7.1 Safari/537.85.10", 
    "PATH_INFO": "/", 
    "QUERY_STRING": "", 
    "REMOTE_ADDR": "***.***.***.***", 
    "REMOTE_PORT": "*****", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "*********", 
    "SERVER_PORT": "1604", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.0 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "coffeescript_compiler": "type %s | tools\\coffee\\coffee.cmd", 
        "config_file": "zeronet.conf", 
        "data_dir": "data", 
        "debug": false, 
        "debug_socket": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "homepage": "1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr", 
        "ip_external": null, 
        "log_dir": "log", 
        "msgpack_purepython": true, 
        "open_browser": null, 
        "proxy": null, 
        "size_limit": 10, 
        "stream_downloads": false, 
        "trackers": [
            "udp://open.demonii.com:1337", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.aletorrenty.pl:2710/announce", 
            "http://retracker.telecom.kz/announce", 
            "http://torrent.gresille.org/announce"
        ], 
        "trackers_file": false, 
        "ui_ip": "*", 
        "ui_port": 43110, 
        "ui_restrict": [
            "192.168.0.253", 
            "127.0.0.1"
        ], 
        "use_openssl": true, 
        "use_tempfiles": false
    }, 
    "plugins": [
        "Sidebar", 
        "Stats", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.0.1", 
    "version_python": "2.7.9 (default, Dec 10 2014, 12:24:55) [MSC v.1500 32 bit (Intel)]", 
    "version_zeronet": "0.3.2 r480", 
    "wsgi.url_scheme": "http"
}
```

It displays too much information to someone who's access is forbidden
  So you won't have to forward the port in the router manually

With another setting to allow opening ui_port with UPnP
 UPnP is implemented.
@HelloZeroNet Can the issue be closed?  If it is possible to export an account to another computer, with the same public key.
 Thanks ;)
  on Ubuntu 14.04 , when I launch `python zeronet.py`
{...}
  File "/usr/local/lib/python2.7/dist-packages/gevent/__ init__.py", line 82, in __ getattr__
    return getattr(_signal_module, name)
  File "/usr/local/lib/python2.7/dist-packages/gevent/__init__.py", line 82, in __ getattr__
    return getattr(_signal_module, name)
  File "/usr/local/lib/python2.7/dist-packages/gevent/__init__.py", line 82, in __ getattr__
    return getattr(_signal_module, name)
  File "/usr/local/lib/python2.7/dist-packages/gevent/__init__.py", line 82, in __ getattr__
    return getattr(_signal_module, name)
RuntimeError: maximum recursion depth exceeded while calling a Python object
 $ python -c "import sys; print sys.version; import gevent; print gevent.__ version__"

2.7.6 (default, Jun 22 2015, 17:58:13) 
[GCC 4.8.2]
1.1b7.dev0
 It works, 
awesome ! :D
   No, but it's always better to gracefully close a connection
 Ok, so you close it?
  It happens a lot of times and in console it shows:

```
[00:27:10] lib.geventwebsocket.handler Initializing WebSocket
[00:27:10] lib.geventwebsocket.handler Validating WebSocket request
[00:27:10] lib.geventwebsocket.handler Attempting to upgrade connection
[00:27:10] lib.geventwebsocket.handler WebSocket request accepted, switching protocols
```

when it reconnects
 ![UIServer WebSocket](https://cloud.githubusercontent.com/assets/13149763/10654070/18906d92-7866-11e5-9070-1b40a5821a51.PNG)
It shows that a lot of times
 It is running on localhost, it does also appears on Firefox and Internet Explorer, it is when oppening a new page:

```
[ZeroWebsocket] Error error 
all.js?rev=473 (line 106)

[ZeroWebsocket] Closed close 
all.js?rev=473 (line 106)

Firefox can't establish a connexion to ws://127.0.0.1:43110/Websocket?wrapper_key=*********************************************************.

this.ws = new WebSocket(this.url);

all.js?rev=473 (line 40)


[ZeroTalk] Websocket close
all.js (line 459)

[ZeroWebsocket] Reconnecting...
all.js?rev=473 (line 106)

[ZeroWebsocket] Error error 
all.js?rev=473 (line 106)

[ZeroWebsocket] Closed close 
all.js?rev=473 (line 106)

[ZeroTalk] Websocket close
all.js (line 459)

[ZeroWebsocket] Reconnecting...
all.js?rev=473 (line 106)

[ZeroWebsocket] Open
all.js?rev=473 (line 106)

hideProgress
all.js?rev=473 (line 544)

[Wrapper] Setting title to ZeroTalk - ZeroNet
all.js?rev=473 (line 1214)

[Wrapper] actionSetViewport Object { cmd="wrapperSetViewport",  params="width=device-width, initial-scale=1.0",  id=2}
all.js?rev=473 (line 1214)

[User] Updating user info... undefined
all.js (line 459)

[ZeroTalk] Routing url: wrapper_nonce=*********************************************************
all.js (line 459)

[ZeroTalk] Adding inline editors (Done in 0ms)
all.js (line 459)

[TopicList] Load topics... (Done in 171ms)
all.js (line 459)
```
 Maybe with line numbers you could help me indentify the bug and I could then test some code.
Right now, I'm going to sleep. It's 3h:22m
 Also, I'm on Windows 8.1 64-bits, maybe it's because of python that is distributed with the ZeroBundle, or I don't know... I'm going to track this bug
 It isn't my browser because it works correctly with ZeroProxy
 Ok, I will try
Also I get these errors in log before reinstalling a clean one:

```
[2015-10-22 15:13:56,079] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-22 15:13:56] "GET /1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd/?wrapper_nonce=4e36010b2f5f9f12ddcfc93f30165a1ec01d613c601ee7edfc082d5cc26d0333 HTTP/1.1" 200 136900 0.010000
[2015-10-22 15:13:56,470] ERROR    - UiWSGIHandler error: UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 60: ordinal not in range(128) in UiServer.py line 38 > pywsgi.py line 494 > UiServer.py line 72 > UiRequest.py line 82 > UiRequest.py line 187 > UiRequestPlugin.py line 21 > UiRequest.py line 333 > Site.py line 441 > SiteStorage.py line 219 > SiteStorage.py line 233
[2015-10-22 15:13:56,470] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-22 15:13:56] "GET /1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd/privacy%20tools%20-%20encryption%20against%20global%20mass%20surveillance%20%F0%9F%94%92_files/bootstrap.css HTTP/1.1" 000 - 0.000000
[2015-10-22 15:13:56,476] ERROR    - UiWSGIHandler error: UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 60: ordinal not in range(128) in UiServer.py line 38 > pywsgi.py line 494 > UiServer.py line 72 > UiRequest.py line 82 > UiRequest.py line 187 > UiRequestPlugin.py line 21 > UiRequest.py line 333 > Site.py line 441 > SiteStorage.py line 219 > SiteStorage.py line 233
[2015-10-22 15:13:56,476] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-22 15:13:56] "GET /1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd/privacy%20tools%20-%20encryption%20against%20global%20mass%20surveillance%20%F0%9F%94%92_files/bootstrap-theme.css HTTP/1.1" 000 - 0.001000
[2015-10-22 15:13:56,483] ERROR    - UiWSGIHandler error: UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 60: ordinal not in range(128) in UiServer.py line 38 > pywsgi.py line 494 > UiServer.py line 72 > UiRequest.py line 82 > UiRequest.py line 187 > UiRequestPlugin.py line 21 > UiRequest.py line 333 > Site.py line 441 > SiteStorage.py line 219 > SiteStorage.py line 233
[2015-10-22 15:13:56,483] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-22 15:13:56] "GET /1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd/privacy%20tools%20-%20encryption%20against%20global%20mass%20surveillance%20%F0%9F%94%92_files/font-awesome.css HTTP/1.1" 000 - 0.001000
[2015-10-22 15:13:56,490] ERROR    - UiWSGIHandler error: UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 60: ordinal not in range(128) in UiServer.py line 38 > pywsgi.py line 494 > UiServer.py line 72 > UiRequest.py line 82 > UiRequest.py line 187 > UiRequestPlugin.py line 21 > UiRequest.py line 333 > Site.py line 441 > SiteStorage.py line 219 > SiteStorage.py line 233
[2015-10-22 15:13:56,492] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-22 15:13:56] "GET /1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd/privacy%20tools%20-%20encryption%20against%20global%20mass%20surveillance%20%F0%9F%94%92_files/sortable-theme-bootstrap.css HTTP/1.1" 000 - 0.000000
[2015-10-22 15:13:56,499] ERROR    - UiWSGIHandler error: UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 60: ordinal not in range(128) in UiServer.py line 38 > pywsgi.py line 494 > UiServer.py line 72 > UiRequest.py line 82 > UiRequest.py line 187 > UiRequestPlugin.py line 21 > UiRequest.py line 333 > Site.py line 441 > SiteStorage.py line 219 > SiteStorage.py line 233
[2015-10-22 15:13:56,499] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-22 15:13:56] "GET /1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd/privacy%20tools%20-%20encryption%20against%20global%20mass%20surveillance%20%F0%9F%94%92_files/custom.css HTTP/1.1" 000 - 0.001000
[2015-10-22 15:13:56,871] ERROR    - UiWSGIHandler error: UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 60: ordinal not in range(128) in UiServer.py line 38 > pywsgi.py line 494 > UiServer.py line 72 > UiRequest.py line 82 > UiRequest.py line 187 > UiRequestPlugin.py line 21 > UiRequest.py line 333 > Site.py line 441 > SiteStorage.py line 219 > SiteStorage.py line 233
[2015-10-22 15:13:56,871] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-22 15:13:56] "GET /1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd/privacy%20tools%20-%20encryption%20against%20global%20mass%20surveillance%20%F0%9F%94%92_files/jquery-1.js HTTP/1.1" 000 - 0.000000
```
 On my old install I can't even connect to the WebSocket and on the fresh install it "works", but I get random disconnections, like before :(
 I get that and it ~~disconnect~~ didn't connect correctly:

```
[18:16:13] Ui.UiServer 127.0.0.1 - - [2015-10-23 18:16:13] "GET /Websocket?wrapp
er_key=******************************************************** HTTP/1.1
" 101 129 77.391000
[18:16:13] Ui.UiServer 127.0.0.1 - - [2015-10-23 18:16:13] "GET /1EU1tbG9oC1A8jz
2ouVwGZyQ5asrNsE4Vr HTTP/1.1" 200 2521 0.001000
[18:16:13] Ui.UiServer 127.0.0.1 - - [2015-10-23 18:16:13] "GET /1EU1tbG9oC1A8jz
2ouVwGZyQ5asrNsE4Vr/?wrapper_nonce=***************************************** HTTP/1.1" 200 2710 0.001000
[18:16:14] lib.geventwebsocket.handler Initializing WebSocket
[18:16:14] lib.geventwebsocket.handler Validating WebSocket request
[18:16:14] lib.geventwebsocket.handler Attempting to upgrade connection
[18:16:14] lib.geventwebsocket.handler WebSocket request accepted, switching pro
tocols
[18:16:14] Site:1DWTx5..qTJd Http tracker http://torrent.gresille.org/announce?u
ploaded=0&downloaded=0&numwant=30&compact=1&event=started&peer_id=-ZN0032-Ki9lZd
ZB8xIe&port=15441&info_hash=4%91%60%9F%B9B%2A%06%0D%04%3E%23l%13%EB%5D%7FR%C6%22
&left=0 error: <urlopen error timed out>
[18:16:14] Site:1DWTx5..qTJd Announce to 0 trackers in 8.038s, failed
[18:16:16] Site:1EU1tb..E4Vr Announced port 15441 to 1 trackers in 0.445s, error
s: [], slow: []
[18:16:18] Site:1TaLkF..jipT Announced port 15441 to 1 trackers in 0.212s, error
s: [], slow: []
[18:16:21] Site:16Basi..mTcs Announced port 15441 to 1 trackers in 0.424s, error
s: [], slow: []
[18:16:23] Site:1Hg8JT..2T4U Http tracker http://tracker.aletorrenty.pl:2710/ann
ounce?uploaded=0&downloaded=0&numwant=30&compact=1&event=started&peer_id=-ZN0032
-Ki9lZdZB8xIe&port=15441&info_hash=%ACO%82%C3%A9%D2%27Q%ECi_%ED%DF%93%BE%DB%0F+%
A3%88&left=0 error: [Errno 10054] Une connexion existante a dÂ¹ Ã›tre fermÃše par l
Ã†hÂ¶te distant
[18:16:33] Site:1Hg8JT..2T4U Announce to 0 trackers in 9.822s, failed
[18:16:37] Site:1FiSxj..ZNt6 Announce to 0 trackers in 2.142s, failed
```

I've just censored `wrapper_key` and `wrapper_nonce`

I'm going to test what you say
 I don't know why but my logs didn't have that part... I'm going to replicate this and show you the logs
 Here non connecting and then at the end it recover the connection:

```
[2015-10-23 18:48:30,549] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 18:48:30] "GET /Websocket?wrapper_key=xxx HTTP/1.1" 101 129 63.177000
[2015-10-23 18:48:30,573] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 18:48:30] "GET /1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr HTTP/1.1" 200 2521 0.001000
[2015-10-23 18:48:30,858] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 18:48:30] "GET /uimedia/all.css?rev=477 HTTP/1.1" 200 26618 0.002000
[2015-10-23 18:48:30,864] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 18:48:30] "GET /uimedia/all.js?rev=477 HTTP/1.1" 200 156399 0.003000
[2015-10-23 18:48:30,884] DEBUG    Site:1DWTx5..qTJd 70.37.165.32:15441 getFile error: File read error: IOError: [Errno 2] No such file or directory: 'data/1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd/privacy tools - encryption against global mass surveillance \xf0\x9f\x94\x92_files/EtherCalc.png' in FileRequest.py line 139
[2015-10-23 18:48:30,885] DEBUG    Site:1DWTx5..qTJd 70.37.165.32:15441 Removing peer...Connection error: 31, Hash failed: 25
[2015-10-23 18:48:30,885] DEBUG    FileServer Removing Conn#61 70.37.165.32 [v2]...
[2015-10-23 18:48:30,887] DEBUG    WorkerManager:1DWTx5..qTJd 70.37.165.32:15441: Hash failed: privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/EtherCalc.png, failed peers: 0
[2015-10-23 18:48:31,009] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 18:48:31] "GET /1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/?wrapper_nonce=xxx HTTP/1.1" 200 2710 0.000000
[2015-10-23 18:48:31,170] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-10-23 18:48:31,171] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-10-23 18:48:31,171] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-10-23 18:48:31,171] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-10-23 18:48:31,887] DEBUG    Site:1DWTx5..qTJd 70.37.165.32:15441 Getting connection (Closing Conn#61 70.37.165.32 [v2])...
[2015-10-23 18:48:31,888] DEBUG    FileServer Conn#62 70.37.165.32 [?] > Connecting...
[2015-10-23 18:48:35,739] DEBUG    WorkerManager:16Basi..mTcs Task taking more than 15 secs, workers: 0 find more peers: content.json
[2015-10-23 18:48:35,917] DEBUG    Site:16Basi..mTcs Announced port 15441 to 1 trackers in 0.178s, errors: [], slow: []
[2015-10-23 18:48:36,236] DEBUG    WorkerManager:1Hg8JT..2T4U Task taking more than 15 secs, workers: 0 find more peers: content.json
[2015-10-23 18:48:36,654] DEBUG    Site:1Hg8JT..2T4U Announced port 15441 to 1 trackers in 0.417s, errors: [], slow: []
[2015-10-23 18:48:38,920] DEBUG    Site:16Basi..mTcs Small number of peers detected...query all of peers using pex
[2015-10-23 18:48:38,921] DEBUG    Site:16Basi..mTcs Queried pex from 0 peers got 0 new peers.
[2015-10-23 18:48:38,934] DEBUG    WorkerManager:16Gn4Q..ezzS Timeout, Cleanup task: {'optional_hash_id': None, 'site': <Site 16Gn4Q..ezzS>, 'done': False, 'inner_path': 'content.json', 'peers': None, 'time_started': None, 'time_action': None, 'priority': 0, 'failed': [], 'workers_num': 0, 'time_added': 1445618858.564, 'evt': <gevent.event.AsyncResult object at 0x0385D830>}
[2015-10-23 18:48:38,936] DEBUG    Site:16Gn4Q..ezzS Can't update content.json
[2015-10-23 18:48:38,959] DEBUG    WorkerManager:16bx28..6UTG Timeout, Cleanup task: {'optional_hash_id': None, 'site': <Site 16bx28..6UTG>, 'done': False, 'inner_path': 'content.json', 'peers': None, 'time_started': None, 'time_action': None, 'priority': 0, 'failed': [], 'workers_num': 0, 'time_added': 1445618858.563, 'evt': <gevent.event.AsyncResult object at 0x03949A50>}
[2015-10-23 18:48:38,960] DEBUG    Site:16bx28..6UTG Can't update content.json
[2015-10-23 18:48:39,654] DEBUG    Site:1Hg8JT..2T4U Small number of peers detected...query all of peers using pex
[2015-10-23 18:48:39,654] DEBUG    Site:1Hg8JT..2T4U Queried pex from 0 peers got 0 new peers.
[2015-10-23 18:48:40,197] DEBUG    WorkerManager:1CJWt3..qcUu Task taking more than 15 secs, workers: 0 find more peers: content.json
[2015-10-23 18:48:40,378] DEBUG    Site:1CJWt3..qcUu Announced port 15441 to 1 trackers in 0.180s, errors: [], slow: []
[2015-10-23 18:48:43,378] DEBUG    Site:1CJWt3..qcUu Small number of peers detected...query all of peers using pex
[2015-10-23 18:48:48,792] DEBUG    Site:1CJWt3..qcUu Queried pex from 0 peers got 0 new peers.
[2015-10-23 18:48:48,792] DEBUG    FileServer Conn#54 5.101.103.222 [v2] > Socket error: error: [Errno 10054] Une connexion existante a dÃ» Ãªtre fermÃ©e par lâ€™hÃ´te distant in Connection.py line 117 > socket.py line 385
[2015-10-23 18:48:48,792] DEBUG    FileServer Removing Conn#54 5.101.103.222 [v2]...
[2015-10-23 18:48:48,792] DEBUG    FileServer 5.101.103.222 Connect error: Exception: Connection event return error in ConnectionServer.py line 125
[2015-10-23 18:48:48,793] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 Removing peer...Connection error: 24, Hash failed: 20
[2015-10-23 18:48:48,793] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 Getting connection error: Exception: Connection event return error in Peer.py line 62 > ConnectionServer.py line 130 (connection_error: 24, hash_failed: 20)
[2015-10-23 18:48:48,793] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 Removing peer...Connection error: 25, Hash failed: 20
[2015-10-23 18:48:48,793] DEBUG    WorkerManager:1DWTx5..qTJd 5.101.103.222:15441: Hash failed: privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/Etherpad.png, failed peers: 1
[2015-10-23 18:48:49,795] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 Getting connection...
[2015-10-23 18:48:49,796] DEBUG    FileServer Conn#63 5.101.103.222 [?] > Connecting...
[2015-10-23 18:48:49,941] DEBUG    FileServer Conn#63 5.101.103.222 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 18:48:50,183] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 getFile error: File read error: UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 60: ordinal not in range(128) in FileRequest.py line 137 > SiteStorage.py line 233
[2015-10-23 18:48:50,184] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 Removing peer...Connection error: 26, Hash failed: 21
[2015-10-23 18:48:50,184] DEBUG    FileServer Removing Conn#63 5.101.103.222 [v2]...
[2015-10-23 18:48:50,187] DEBUG    WorkerManager:1DWTx5..qTJd 5.101.103.222:15441: Hash failed: privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/privatesearch.png, failed peers: 1
[2015-10-23 18:48:50,918] DEBUG    WorkerManager:16Basi..mTcs Timeout, Cleanup task: {'optional_hash_id': None, 'site': <Site 16Basi..mTcs>, 'done': False, 'inner_path': 'content.json', 'peers': None, 'time_started': None, 'time_action': None, 'priority': 0, 'failed': [], 'workers_num': 0, 'time_added': 1445618870.37, 'evt': <gevent.event.AsyncResult object at 0x037230D0>}
[2015-10-23 18:48:50,920] DEBUG    Site:16Basi..mTcs Can't update content.json
[2015-10-23 18:48:50,921] DEBUG    WorkerManager:16Basi..mTcs Timeout, Cleanup task: {'optional_hash_id': None, 'site': <Site 16Basi..mTcs>, 'done': False, 'inner_path': u'data/users/content.json', 'peers': None, 'time_started': None, 'time_action': None, 'priority': 0, 'failed': [], 'workers_num': 0, 'time_added': 1445618870.37, 'evt': <gevent.event.AsyncResult object at 0x03949B10>}
[2015-10-23 18:48:51,187] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 Getting connection (Closing Conn#63 5.101.103.222 [v2])...
[2015-10-23 18:48:51,187] DEBUG    FileServer Conn#64 5.101.103.222 [?] > Connecting...
[2015-10-23 18:48:51,335] DEBUG    FileServer Conn#64 5.101.103.222 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 18:48:51,566] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 getFile error: File read error: UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 60: ordinal not in range(128) in FileRequest.py line 137 > SiteStorage.py line 233
[2015-10-23 18:48:51,569] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 Removing peer...Connection error: 27, Hash failed: 22
[2015-10-23 18:48:51,569] DEBUG    FileServer Removing Conn#64 5.101.103.222 [v2]...
[2015-10-23 18:48:51,571] DEBUG    WorkerManager:1DWTx5..qTJd 5.101.103.222:15441: Hash failed: privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/Thumbs.db, failed peers: 1
[2015-10-23 18:48:51,654] DEBUG    WorkerManager:1Hg8JT..2T4U Timeout, Cleanup task: {'optional_hash_id': None, 'site': <Site 1Hg8JT..2T4U>, 'done': False, 'inner_path': 'content.json', 'peers': None, 'time_started': None, 'time_action': None, 'priority': 0, 'failed': [], 'workers_num': 0, 'time_added': 1445618870.37, 'evt': <gevent.event.AsyncResult object at 0x03949B30>}
[2015-10-23 18:48:51,655] DEBUG    Site:1Hg8JT..2T4U Can't update content.json
[2015-10-23 18:48:52,572] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 Getting connection (Closing Conn#64 5.101.103.222 [v2])...
[2015-10-23 18:48:52,572] DEBUG    FileServer Conn#65 5.101.103.222 [?] > Connecting...
[2015-10-23 18:48:52,746] DEBUG    FileServer Conn#65 5.101.103.222 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 18:48:52,996] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 getFile error: File read error: UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 60: ordinal not in range(128) in FileRequest.py line 137 > SiteStorage.py line 233
[2015-10-23 18:48:52,996] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 Removing peer...Connection error: 28, Hash failed: 23
[2015-10-23 18:48:52,997] DEBUG    FileServer Removing Conn#65 5.101.103.222 [v2]...
[2015-10-23 18:48:52,997] DEBUG    WorkerManager:1DWTx5..qTJd 5.101.103.222:15441: Hash failed: privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/Master-Password.jpe, failed peers: 1
[2015-10-23 18:48:54,000] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 Getting connection (Closing Conn#65 5.101.103.222 [v2])...
[2015-10-23 18:48:54,002] DEBUG    FileServer Conn#66 5.101.103.222 [?] > Connecting...
[2015-10-23 18:48:55,378] DEBUG    WorkerManager:1CJWt3..qcUu Timeout, Cleanup task: {'optional_hash_id': None, 'site': <Site 1CJWt3..qcUu>, 'done': False, 'inner_path': 'content.json', 'peers': None, 'time_started': None, 'time_action': None, 'priority': 0, 'failed': [], 'workers_num': 0, 'time_added': 1445618875.024, 'evt': <gevent.event.AsyncResult object at 0x035E4E10>}
[2015-10-23 18:48:55,380] DEBUG    Site:1CJWt3..qcUu Can't update content.json
[2015-10-23 18:48:57,687] DEBUG    FileServer Connection flood detected from 70.37.165.32
[2015-10-23 18:49:01,144] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-10-23 18:49:01,144] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-10-23 18:49:01,144] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-10-23 18:49:01,144] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-10-23 18:49:02,243] DEBUG    FileServer Conn#62 70.37.165.32 [v2] > Socket error: error: [Errno 10054] Une connexion existante a dÃ» Ãªtre fermÃ©e par lâ€™hÃ´te distant in Connection.py line 117 > socket.py line 385
[2015-10-23 18:49:02,243] DEBUG    FileServer Removing Conn#62 70.37.165.32 [v2]...
[2015-10-23 18:49:02,244] DEBUG    FileServer 70.37.165.32 Connect error: Exception: Connection event return error in ConnectionServer.py line 125
[2015-10-23 18:49:02,246] DEBUG    Site:1DWTx5..qTJd 70.37.165.32:15441 Removing peer...Connection error: 32, Hash failed: 26
[2015-10-23 18:49:02,246] DEBUG    Site:1DWTx5..qTJd 70.37.165.32:15441 Getting connection error: Exception: Connection event return error in Peer.py line 62 > ConnectionServer.py line 130 (connection_error: 32, hash_failed: 26)
[2015-10-23 18:49:02,247] DEBUG    Site:1DWTx5..qTJd 70.37.165.32:15441 Removing peer...Connection error: 33, Hash failed: 26
[2015-10-23 18:49:02,249] DEBUG    WorkerManager:1DWTx5..qTJd 70.37.165.32:15441: Hash failed: privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/Cryptocat.png, failed peers: 0
[2015-10-23 18:49:03,252] DEBUG    Site:1DWTx5..qTJd 70.37.165.32:15441 Getting connection...
[2015-10-23 18:49:03,253] DEBUG    FileServer Conn#67 70.37.165.32 [?] > Connecting...
[2015-10-23 18:49:05,663] DEBUG    Site:14kr6q..T2Ag Announced port 15441 to 1 trackers in 0.421s, errors: [], slow: []
[2015-10-23 18:49:08,030] DEBUG    Site:1Zeroe..G8ER Found 30 peers, new: 1
[2015-10-23 18:49:08,072] DEBUG    Site:1Zeroe..G8ER Announced port 15441 to 1 trackers in 0.409s, errors: [], slow: []
[2015-10-23 18:49:10,255] DEBUG    Site:1iD5ZQ..duGz Announced port 15441 to 1 trackers in 0.181s, errors: [], slow: []
[2015-10-23 18:49:12,769] DEBUG    Site:1Gfey7..fcdp Found 27 peers, new: 1
[2015-10-23 18:49:12,813] DEBUG    Site:1Gfey7..fcdp Announced port 15441 to 1 trackers in 0.557s, errors: [], slow: []
[2015-10-23 18:49:24,145] DEBUG    FileServer Conn#66 5.101.103.222 [v2] > Socket error: error: [Errno 10054] Une connexion existante a dÃ» Ãªtre fermÃ©e par lâ€™hÃ´te distant in Connection.py line 117 > socket.py line 385
[2015-10-23 18:49:24,145] DEBUG    FileServer Removing Conn#66 5.101.103.222 [v2]...
[2015-10-23 18:49:24,147] DEBUG    FileServer 5.101.103.222 Connect error: Exception: Connection event return error in ConnectionServer.py line 125
[2015-10-23 18:49:24,147] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 Removing peer...Connection error: 29, Hash failed: 24
[2015-10-23 18:49:24,147] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 Getting connection error: Exception: Connection event return error in Peer.py line 62 > ConnectionServer.py line 130 (connection_error: 29, hash_failed: 24)
[2015-10-23 18:49:24,148] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 Removing peer...Connection error: 30, Hash failed: 24
[2015-10-23 18:49:24,148] DEBUG    WorkerManager:1DWTx5..qTJd 5.101.103.222:15441: Hash failed: privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/EtherCalc.png, failed peers: 1
[2015-10-23 18:49:24,815] DEBUG    Site:1AvF5T..7Npg Http tracker http://tracker.aletorrenty.pl:2710/announce?uploaded=0&downloaded=0&numwant=30&compact=1&event=started&peer_id=-ZN0032-v2kqcc9XkZiR&port=15441&info_hash=%FF7%80%C1w%A0%AAg3%D5%EA%F6%ACgnJW%A2%F8%24&left=0 error: local variable 'response' referenced before assignment
[2015-10-23 18:49:24,865] ERROR    Site:1AvF5T..7Npg Announce to 0 trackers in 10.051s, failed
[2015-10-23 18:49:25,148] DEBUG    Site:1DWTx5..qTJd 5.101.103.222:15441 Getting connection...
[2015-10-23 18:49:25,150] DEBUG    FileServer Conn#68 5.101.103.222 [?] > Connecting...
[2015-10-23 18:49:27,081] DEBUG    Site:1BLogC..AGg8 Announced port 15441 to 1 trackers in 0.213s, errors: [], slow: []
[2015-10-23 18:49:29,042] DEBUG    FileServer Conn#69 70.37.165.32 [?] > Incoming connection...
[2015-10-23 18:49:29,043] DEBUG    FileServer Conn#69 70.37.165.32 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2015-10-23 18:49:29,497] DEBUG    Site:192dZ1..s4t3 Announced port 15441 to 1 trackers in 0.413s, errors: [], slow: []
[2015-10-23 18:49:29,677] DEBUG    FileServer FileRequest: Conn#69 70.37.165.32 [v2] getFile 1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/CryptoHeaven.gif
[2015-10-23 18:49:29,678] DEBUG    FileServer GetFile read error: UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 60: ordinal not in range(128) in FileRequest.py line 137 > SiteStorage.py line 233
[2015-10-23 18:49:29,871] DEBUG    FileServer Removing Conn#69 70.37.165.32 [v2]...
[2015-10-23 18:49:31,052] DEBUG    FileServer Conn#70 70.37.165.32 [?] > Incoming connection...
[2015-10-23 18:49:31,053] DEBUG    FileServer Conn#70 70.37.165.32 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2015-10-23 18:49:31,177] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-10-23 18:49:31,177] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-10-23 18:49:31,178] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-10-23 18:49:31,180] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-10-23 18:49:31,604] DEBUG    FileServer FileRequest: Conn#70 70.37.165.32 [v2] getFile 1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/Perfect-Privacy.gif
[2015-10-23 18:49:31,604] DEBUG    FileServer GetFile read error: UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 60: ordinal not in range(128) in FileRequest.py line 137 > SiteStorage.py line 233
[2015-10-23 18:49:31,782] DEBUG    FileServer Removing Conn#70 70.37.165.32 [v2]...
[2015-10-23 18:49:31,868] DEBUG    Site:16rELc..WPjF Announced port 15441 to 1 trackers in 0.369s, errors: [], slow: []
[2015-10-23 18:49:32,964] DEBUG    FileServer Conn#71 70.37.165.32 [?] > Incoming connection...
[2015-10-23 18:49:32,967] DEBUG    FileServer Conn#71 70.37.165.32 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2015-10-23 18:49:33,536] DEBUG    FileServer FileRequest: Conn#71 70.37.165.32 [v2] getFile 1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/IVPN.gif
[2015-10-23 18:49:33,536] DEBUG    FileServer GetFile read error: UnicodeDecodeError: 'ascii' codec can't decode byte 0xf0 in position 60: ordinal not in range(128) in FileRequest.py line 137 > SiteStorage.py line 233
[2015-10-23 18:49:33,599] DEBUG    FileServer Conn#67 70.37.165.32 [v2] > Socket error: error: [Errno 10054] Une connexion existante a dÃ» Ãªtre fermÃ©e par lâ€™hÃ´te distant in Connection.py line 117 > socket.py line 385
[2015-10-23 18:49:33,601] DEBUG    FileServer Removing Conn#67 70.37.165.32 [v2]...
[2015-10-23 18:49:33,601] DEBUG    FileServer 70.37.165.32 Connect error: Exception: Connection event return error in ConnectionServer.py line 125
[2015-10-23 18:49:33,602] DEBUG    Site:1DWTx5..qTJd 70.37.165.32:15441 Removing peer...Connection error: 34, Hash failed: 27
[2015-10-23 18:49:33,604] DEBUG    Site:1DWTx5..qTJd 70.37.165.32:15441 Getting connection error: Exception: Connection event return error in Peer.py line 62 > ConnectionServer.py line 130 (connection_error: 34, hash_failed: 27)
[2015-10-23 18:49:33,604] DEBUG    Site:1DWTx5..qTJd 70.37.165.32:15441 Removing peer...Connection error: 35, Hash failed: 27
[2015-10-23 18:49:33,605] DEBUG    WorkerManager:1DWTx5..qTJd 70.37.165.32:15441: Hash failed: privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/Trisquel.png, failed peers: 0
[2015-10-23 18:49:33,713] DEBUG    FileServer Removing Conn#71 70.37.165.32 [v2]...
[2015-10-23 18:49:34,132] DEBUG    Site:16bx28..6UTG Announced port 15441 to 1 trackers in 0.263s, errors: [], slow: []
[2015-10-23 18:49:34,605] DEBUG    Site:1DWTx5..qTJd 70.37.165.32:15441 Getting connection...
[2015-10-23 18:49:34,607] DEBUG    FileServer Conn#72 70.37.165.32 [?] > Connecting...
[2015-10-23 18:49:34,892] DEBUG    FileServer Connection flood detected from 70.37.165.32
```
 I was only having the ZeroHello site
 Maybe it was others requesting files for other sites
 I've started like you tell me and I also deleted log folder
Here connections are good and I'm refreshing:

```
[2015-10-23 20:06:00,470] DEBUG    PluginManager Loading plugin: Sidebar
[2015-10-23 20:06:00,500] DEBUG    PluginManager New plugin registered to: UiRequest
[2015-10-23 20:06:00,500] DEBUG    PluginManager New plugin registered to: UiWebsocket
[2015-10-23 20:06:00,502] DEBUG    PluginManager Loading plugin: Stats
[2015-10-23 20:06:00,505] DEBUG    PluginManager New plugin registered to: UiRequest
[2015-10-23 20:06:00,505] DEBUG    PluginManager Loading plugin: Trayicon
[2015-10-23 20:06:00,506] DEBUG    PluginManager New plugin registered to: Actions
[2015-10-23 20:06:00,507] DEBUG    PluginManager Loading plugin: Zeroname
[2015-10-23 20:06:00,509] DEBUG    PluginManager New plugin registered to: UiRequest
[2015-10-23 20:06:00,510] DEBUG    PluginManager New plugin registered to: SiteManager
[2015-10-23 20:06:00,512] DEBUG    - Config: Config(action='main', batch=False, coffeescript_compiler='type %s | tools\\coffee\\coffee.cmd', config_file='zeronet.conf', data_dir='data', debug=True, debug_socket=False, disable_encryption=False, disable_sslcompression=True, disable_udp=False, fileserver_ip='*', fileserver_port=15441, homepage='1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr', ip_external=None, log_dir='log', msgpack_purepython=True, open_browser=None, proxy=None, size_limit=10, stream_downloads=False, trackers=['udp://open.demonii.com:1337', 'udp://tracker.leechers-paradise.org:6969', 'udp://9.rarbg.com:2710', 'http://tracker.aletorrenty.pl:2710/announce', 'http://retracker.telecom.kz/announce', 'http://torrent.gresille.org/announce'], trackers_file=False, ui_ip='127.0.0.1', ui_port=43110, ui_restrict=False, use_openssl=True, use_tempfiles=False)
[2015-10-23 20:06:00,513] DEBUG    PluginManager New class accepts plugins: Actions (Loaded plugins: [<class 'Trayicon.TrayiconPlugin.ActionsPlugin'>, <class 'main.Actions'>])
[2015-10-23 20:06:00,535] INFO     - Version: 0.3.2 r477, Python 2.7.9 (default, Dec 10 2014, 12:24:55) [MSC v.1500 32 bit (Intel)], Gevent: 1.0.1
[2015-10-23 20:06:00,609] DEBUG    PluginManager New class accepts plugins: SiteManager (Loaded plugins: [<class 'Zeroname.SiteManagerPlugin.SiteManagerPlugin'>, <class 'Site.SiteManager.SiteManager'>])
[2015-10-23 20:06:00,622] DEBUG    - Disable SSL compression failed: function 'SSL_COMP_get_compression_methods' not found (normal on Windows)
[2015-10-23 20:06:00,642] DEBUG    - Missing SSLwrap, readded.
[2015-10-23 20:06:00,642] DEBUG    - Missing SSLContext, readded.
[2015-10-23 20:06:00,642] DEBUG    - Python SSL version: OpenSSL 1.0.1j 15 Oct 2014
[2015-10-23 20:06:00,694] INFO     - OpenSSL loaded, version: 01000201F
[2015-10-23 20:06:00,697] DEBUG    PluginManager New class accepts plugins: UiWebsocket (Loaded plugins: [<class 'Sidebar.SidebarPlugin.UiWebsocketPlugin'>, <class 'Ui.UiWebsocket.UiWebsocket'>])
[2015-10-23 20:06:00,698] DEBUG    PluginManager New class accepts plugins: UiRequest (Loaded plugins: [<class 'Zeroname.UiRequestPlugin.UiRequestPlugin'>, <class 'Stats.StatsPlugin.UiRequestPlugin'>, <class 'Sidebar.SidebarPlugin.UiRequestPlugin'>, <class 'Ui.UiRequest.UiRequest'>])
[2015-10-23 20:06:00,698] INFO     - Creating FileServer....
[2015-10-23 20:06:00,700] INFO     - Creating UiServer....
[2015-10-23 20:06:00,700] DEBUG    - Added new site: 1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F
[2015-10-23 20:06:00,701] ERROR    Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[2015-10-23 20:06:00,703] DEBUG    Site:1Name2..hM9F New auth key: e4658d86dd3a9d9ac2a626266a45ff3d07f6805c9a3cbc2dd0c293e876cfb065
[2015-10-23 20:06:00,723] DEBUG    Site:1Name2..hM9F New wrapper key: a6188f7917387ca9d59445b109586ee42b7061fe3a6b42f026c4169c10234998
[2015-10-23 20:06:00,749] INFO     - Removing old SSL certs...
[2015-10-23 20:06:00,749] INFO     - Starting servers....
[2015-10-23 20:06:00,750] DEBUG    Site:1Name2..hM9F Start downloading, bad_files: {}, check_size: False, blind_includes: True
[2015-10-23 20:06:00,750] DEBUG    Site:1Name2..hM9F Downloading content.json...
[2015-10-23 20:06:00,750] DEBUG    Site:1Name2..hM9F Need content.json first
[2015-10-23 20:06:00,750] DEBUG    WorkerManager:1Name2..hM9F New task: content.json, peer lock: None, priority: 0, optional_hash_id: None, tasks: 1
[2015-10-23 20:06:00,753] INFO     Ui.UiServer No module named werkzeug.debug: For debugging please download Werkzeug (http://werkzeug.pocoo.org/)
[2015-10-23 20:06:00,753] INFO     Ui.UiServer --------------------------------------
[2015-10-23 20:06:00,753] INFO     Ui.UiServer Web interface: http://127.0.0.1:43110/
[2015-10-23 20:06:00,753] INFO     Ui.UiServer --------------------------------------
[2015-10-23 20:06:01,645] DEBUG    - Generating RSA cert and key PEM files...Loading 'screen' into random state - done

Generating a 2048 bit RSA private key

......................+++

................................................................................................................................................+++

writing new private key to 'data/key-rsa.pem'

-----
[2015-10-23 20:06:01,647] DEBUG    FileServer Binding to: *:15441, (msgpack: 0.4.6), supported crypt: ['tls-rsa']
[2015-10-23 20:06:01,648] DEBUG    Site:1Name2..hM9F Need content.json first
[2015-10-23 20:06:01,865] DEBUG    WorkerManager:1Name2..hM9F Added worker: 104.156.231.236:15441, workers: 1/10
[2015-10-23 20:06:01,865] DEBUG    WorkerManager:1Name2..hM9F Added worker: 62.210.38.54:15441, workers: 2/10
[2015-10-23 20:06:01,865] DEBUG    WorkerManager:1Name2..hM9F Added worker: 176.58.120.181:15441, workers: 3/10
[2015-10-23 20:06:01,867] DEBUG    WorkerManager:1Name2..hM9F Added worker: 46.27.7.33:15441, workers: 4/10
[2015-10-23 20:06:01,867] DEBUG    WorkerManager:1Name2..hM9F Added worker: 121.75.18.208:15441, workers: 5/10
[2015-10-23 20:06:01,867] DEBUG    WorkerManager:1Name2..hM9F Added worker: 5.196.71.152:15441, workers: 6/10
[2015-10-23 20:06:01,867] DEBUG    WorkerManager:1Name2..hM9F Added worker: 109.18.164.125:15441, workers: 7/10
[2015-10-23 20:06:01,868] DEBUG    WorkerManager:1Name2..hM9F Added worker: 178.238.41.134:15441, workers: 8/10
[2015-10-23 20:06:01,868] DEBUG    WorkerManager:1Name2..hM9F Added worker: 85.159.209.154:15441, workers: 9/10
[2015-10-23 20:06:01,868] DEBUG    WorkerManager:1Name2..hM9F Added worker: 185.94.31.204:15441, workers: 10/10
[2015-10-23 20:06:01,868] DEBUG    Site:1Name2..hM9F Found 50 peers, new: 38
[2015-10-23 20:06:01,868] DEBUG    Site:1Name2..hM9F 104.156.231.236:15441 Getting connection...
[2015-10-23 20:06:01,868] DEBUG    FileServer Conn# 1 104.156.231.236 [?] > Connecting...
[2015-10-23 20:06:01,868] DEBUG    WorkerManager:1Name2..hM9F 62.210.38.54:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:01,868] DEBUG    WorkerManager:1Name2..hM9F 176.58.120.181:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:01,868] DEBUG    WorkerManager:1Name2..hM9F 46.27.7.33:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:01,869] DEBUG    WorkerManager:1Name2..hM9F 121.75.18.208:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:01,869] DEBUG    WorkerManager:1Name2..hM9F 5.196.71.152:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:01,869] DEBUG    WorkerManager:1Name2..hM9F 109.18.164.125:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:01,869] DEBUG    WorkerManager:1Name2..hM9F 178.238.41.134:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:01,871] DEBUG    WorkerManager:1Name2..hM9F 85.159.209.154:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:01,871] DEBUG    WorkerManager:1Name2..hM9F 185.94.31.204:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:01,875] DEBUG    Site:1Name2..hM9F Found 50 peers, new: 9
[2015-10-23 20:06:01,927] DEBUG    Site:1Name2..hM9F Http tracker http://tracker.aletorrenty.pl:2710/announce?uploaded=0&downloaded=0&numwant=30&compact=1&event=started&peer_id=-ZN0032-LV5BT822mbjj&port=0&info_hash=S%B2Z%A8K%A6W%F5%10%87%9B%B6%CD%DE%C0%F6u%22%D9a&left=0 error: [Errno 10054] Une connexion existante a dÃ» Ãªtre fermÃ©e par lâ€™hÃ´te distant
[2015-10-23 20:06:02,296] DEBUG    FileServer Conn# 1 104.156.231.236 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:02,832] INFO     FileServer Checking port 15441 using portchecker.co...
[2015-10-23 20:06:02,832] DEBUG    Site:1Name2..hM9F Found 30 peers, new: 1
[2015-10-23 20:06:02,904] DEBUG    Site:1Name2..hM9F Announced port 0 to 5 trackers in 1.257s, errors: ['http://tracker.aletorrenty.pl:2710/announce'], slow: ['1.18s http://torrent.gresille.org/announce']
[2015-10-23 20:06:02,904] DEBUG    WorkerManager:1Name2..hM9F 176.58.120.181:15441: content.json, task done after sleep: False
[2015-10-23 20:06:02,905] DEBUG    Site:1Name2..hM9F 176.58.120.181:15441 Getting connection...
[2015-10-23 20:06:02,905] DEBUG    FileServer Conn# 2 176.58.120.181 [?] > Connecting...
[2015-10-23 20:06:02,907] DEBUG    WorkerManager:1Name2..hM9F 62.210.38.54:15441: content.json, task done after sleep: False
[2015-10-23 20:06:02,907] DEBUG    Site:1Name2..hM9F 62.210.38.54:15441 Getting connection...
[2015-10-23 20:06:02,907] DEBUG    FileServer Conn# 3 62.210.38.54 [?] > Connecting...
[2015-10-23 20:06:02,907] DEBUG    WorkerManager:1Name2..hM9F 46.27.7.33:15441: content.json, task done after sleep: False
[2015-10-23 20:06:02,907] DEBUG    Site:1Name2..hM9F 46.27.7.33:15441 Getting connection...
[2015-10-23 20:06:02,907] DEBUG    FileServer Conn# 4 46.27.7.33   [?] > Connecting...
[2015-10-23 20:06:02,908] DEBUG    WorkerManager:1Name2..hM9F 5.196.71.152:15441: content.json, task done after sleep: False
[2015-10-23 20:06:02,908] DEBUG    Site:1Name2..hM9F 5.196.71.152:15441 Getting connection...
[2015-10-23 20:06:02,908] DEBUG    FileServer Conn# 5 5.196.71.152 [?] > Connecting...
[2015-10-23 20:06:02,910] DEBUG    WorkerManager:1Name2..hM9F 121.75.18.208:15441: content.json, task done after sleep: False
[2015-10-23 20:06:02,910] DEBUG    Site:1Name2..hM9F 121.75.18.208:15441 Getting connection...
[2015-10-23 20:06:02,910] DEBUG    FileServer Conn# 6 121.75.18.208 [?] > Connecting...
[2015-10-23 20:06:02,910] DEBUG    WorkerManager:1Name2..hM9F 109.18.164.125:15441: content.json, task done after sleep: False
[2015-10-23 20:06:02,911] DEBUG    Site:1Name2..hM9F 109.18.164.125:15441 Getting connection...
[2015-10-23 20:06:02,911] DEBUG    FileServer Conn# 7 109.18.164.125 [?] > Connecting...
[2015-10-23 20:06:02,911] DEBUG    WorkerManager:1Name2..hM9F 85.159.209.154:15441: content.json, task done after sleep: False
[2015-10-23 20:06:02,911] DEBUG    Site:1Name2..hM9F 85.159.209.154:15441 Getting connection...
[2015-10-23 20:06:02,911] DEBUG    FileServer Conn# 8 85.159.209.154 [?] > Connecting...
[2015-10-23 20:06:02,911] DEBUG    WorkerManager:1Name2..hM9F 178.238.41.134:15441: content.json, task done after sleep: False
[2015-10-23 20:06:02,911] DEBUG    Site:1Name2..hM9F 178.238.41.134:15441 Getting connection...
[2015-10-23 20:06:02,911] DEBUG    FileServer Conn# 9 178.238.41.134 [?] > Connecting...
[2015-10-23 20:06:02,911] DEBUG    WorkerManager:1Name2..hM9F 185.94.31.204:15441: content.json, task done after sleep: False
[2015-10-23 20:06:02,913] DEBUG    Site:1Name2..hM9F 185.94.31.204:15441 Getting connection...
[2015-10-23 20:06:02,913] DEBUG    FileServer Conn#10 185.94.31.204 [?] > Connecting...
[2015-10-23 20:06:03,036] DEBUG    FileServer Conn# 3 62.210.38.54 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:03,056] DEBUG    FileServer Conn# 5 5.196.71.152 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:03,073] DEBUG    FileServer Conn# 2 176.58.120.181 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:03,079] DEBUG    FileServer Conn# 8 85.159.209.154 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:03,098] DEBUG    FileServer Conn# 9 178.238.41.134 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:03,104] DEBUG    FileServer Conn# 7 109.18.164.125 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:03,178] DEBUG    FileServer Conn# 4 46.27.7.33   [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:03,323] DEBUG    Site:1Name2..hM9F content.json: Valid signs: 1/1
[2015-10-23 20:06:03,325] DEBUG    WorkerManager:1Name2..hM9F 62.210.38.54:15441: Hash correct: content.json
[2015-10-23 20:06:03,331] DEBUG    Site:1Name2..hM9F Bad file solved: content.json
[2015-10-23 20:06:03,331] DEBUG    WorkerManager:1Name2..hM9F 62.210.38.54:15441: No task found, stopping
[2015-10-23 20:06:03,332] DEBUG    WorkerManager:1Name2..hM9F Removed worker, workers: 9/10
[2015-10-23 20:06:03,334] DEBUG    Site:1Name2..hM9F Got content.json
[2015-10-23 20:06:03,335] DEBUG    WorkerManager:1Name2..hM9F New task: index.html, peer lock: None, priority: 0, optional_hash_id: None, tasks: 1
[2015-10-23 20:06:03,336] DEBUG    WorkerManager:1Name2..hM9F Added worker: 50.250.218.164:15441, workers: 10/10
[2015-10-23 20:06:03,338] DEBUG    WorkerManager:1Name2..hM9F New task: data/names.json, peer lock: None, priority: 0, optional_hash_id: None, tasks: 2
[2015-10-23 20:06:03,341] DEBUG    WorkerManager:1Name2..hM9F New task: css/all.css, peer lock: None, priority: 0, optional_hash_id: None, tasks: 3
[2015-10-23 20:06:03,342] DEBUG    WorkerManager:1Name2..hM9F New task: js/all.js, peer lock: None, priority: 0, optional_hash_id: None, tasks: 4
[2015-10-23 20:06:03,344] DEBUG    Site:1Name2..hM9F content.json: Downloading 0 includes...
[2015-10-23 20:06:03,345] DEBUG    Site:1Name2..hM9F content.json: Includes download ended
[2015-10-23 20:06:03,346] DEBUG    Site:1Name2..hM9F Try to get listModifications from peers: [<Peer:178.238.41.134>, <Peer:176.58.120.181>, <Peer:5.196.71.152>, <Peer:62.210.38.54>, <Peer:85.159.209.154>, <Peer:104.156.231.236>, <Peer:45.78.9.204 >, <Peer:85.170.190.240>, <Peer:72.45.24.165>] since: 0
[2015-10-23 20:06:03,348] DEBUG    Site:1Name2..hM9F 50.250.218.164:15441 Getting connection...
[2015-10-23 20:06:03,348] DEBUG    FileServer Conn#11 50.250.218.164 [?] > Connecting...
[2015-10-23 20:06:03,357] DEBUG    FileServer Conn#12 192.241.144.195 [?] > Incoming connection...
[2015-10-23 20:06:03,358] DEBUG    FileServer Removing Conn#12 192.241.144.195 [v2]...
[2015-10-23 20:06:03,365] DEBUG    WorkerManager:1Name2..hM9F 5.196.71.152:15441: Someone already working on index.html, sleeping 1 sec...
[2015-10-23 20:06:03,413] DEBUG    WorkerManager:1Name2..hM9F 176.58.120.181:15441: Someone already working on index.html, sleeping 1 sec...
[2015-10-23 20:06:03,427] DEBUG    WorkerManager:1Name2..hM9F 85.159.209.154:15441: Someone already working on index.html, sleeping 1 sec...
[2015-10-23 20:06:03,486] INFO     FileServer [OK :)] Port open: Port 15441 is open.
[2015-10-23 20:06:03,487] DEBUG    FileServer Checking sites integrity..
[2015-10-23 20:06:03,490] DEBUG    Site:1Name2..hM9F Try to get listModifications from peers: [<Peer:176.58.120.181>, <Peer:104.156.231.236>, <Peer:178.238.41.134>, <Peer:62.210.38.54>, <Peer:5.196.71.152>, <Peer:85.159.209.154>, <Peer:109.18.164.125>, <Peer:121.75.18.208>, <Peer:76.88.65.107>, <Peer:83.77.48.250>, <Peer:76.11.82.156>] since: 1445015237.82
[2015-10-23 20:06:03,493] DEBUG    WorkerManager:1Name2..hM9F 178.238.41.134:15441: Someone already working on index.html, sleeping 1 sec...
[2015-10-23 20:06:03,539] DEBUG    WorkerManager:1Name2..hM9F 109.18.164.125:15441: Someone already working on index.html, sleeping 1 sec...
[2015-10-23 20:06:03,674] DEBUG    FileServer Conn# 6 121.75.18.208 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:03,694] DEBUG    Site:1Name2..hM9F Queried listModifications from: [<Peer:5.196.71.152>, <Peer:62.210.38.54>, <Peer:176.58.120.181>, <Peer:85.159.209.154>, <Peer:178.238.41.134>]
[2015-10-23 20:06:03,694] DEBUG    Site:1Name2..hM9F content.json: Downloading 4 files, changed: 4...
[2015-10-23 20:06:03,707] DEBUG    WorkerManager:1Name2..hM9F 104.156.231.236:15441: Someone already working on index.html, sleeping 1 sec...
[2015-10-23 20:06:03,798] DEBUG    FileServer Conn#11 50.250.218.164 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:03,832] DEBUG    WorkerManager:1Name2..hM9F 46.27.7.33:15441: Someone already working on index.html, sleeping 1 sec...
[2015-10-23 20:06:04,016] DEBUG    Site:1Name2..hM9F Queried listModifications from: [<Peer:176.58.120.181>, <Peer:62.210.38.54>, <Peer:178.238.41.134>, <Peer:5.196.71.152>, <Peer:104.156.231.236>]
[2015-10-23 20:06:04,016] DEBUG    Site:1Name2..hM9F [MISSING] index.html
[2015-10-23 20:06:04,016] DEBUG    Site:1Name2..hM9F [MISSING] data/names.json
[2015-10-23 20:06:04,016] DEBUG    Site:1Name2..hM9F [MISSING] css/all.css
[2015-10-23 20:06:04,017] DEBUG    Site:1Name2..hM9F [MISSING] js/all.js
[2015-10-23 20:06:04,017] DEBUG    Site:1Name2..hM9F content.json verified: 4, quick: True, bad: [u'index.html', u'data/names.json', u'css/all.css', u'js/all.js'], optionals: +0 -0
[2015-10-23 20:06:04,017] DEBUG    Site:1Name2..hM9F Checked files in 0.00s... Quick:True
[2015-10-23 20:06:04,019] DEBUG    Site:1Name2..hM9F Start downloading, bad_files: {u'index.html': 1, u'data/names.json': 1, u'css/all.css': 1, u'js/all.js': 1}, check_size: False, blind_includes: False
[2015-10-23 20:06:04,019] DEBUG    Site:1Name2..hM9F Downloading content.json...
[2015-10-23 20:06:04,019] DEBUG    Site:1Name2..hM9F Got content.json
[2015-10-23 20:06:04,020] DEBUG    Site:1Name2..hM9F content.json: Downloading 0 includes...
[2015-10-23 20:06:04,020] DEBUG    Site:1Name2..hM9F content.json: Includes download ended
[2015-10-23 20:06:04,020] DEBUG    Site:1Name2..hM9F content.json: Downloading 4 files, changed: 0...
[2015-10-23 20:06:04,062] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:04] "GET / HTTP/1.1" 301 201 0.000000
[2015-10-23 20:06:04,111] DEBUG    - Added new site: 1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr
[2015-10-23 20:06:04,111] ERROR    Site:1EU1tb..E4Vr Content.json not exist: data/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/content.json
[2015-10-23 20:06:04,112] DEBUG    Site:1EU1tb..E4Vr New auth key: 0b55ec51e9b11559b9af3f4a9098107a7de5e2281fb9b9fa742fb46ce91c7ff2
[2015-10-23 20:06:04,140] DEBUG    Site:1EU1tb..E4Vr New wrapper key: 1ef52e819f46157782f8c94b74c8a73f98c3f5bb4835e11438c8980049d7ff66
[2015-10-23 20:06:04,160] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:04] "GET /1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr HTTP/1.1" 200 2556 0.050000
[2015-10-23 20:06:04,160] DEBUG    Site:1EU1tb..E4Vr Start downloading, bad_files: {}, check_size: False, blind_includes: True
[2015-10-23 20:06:04,161] DEBUG    Site:1EU1tb..E4Vr Downloading content.json...
[2015-10-23 20:06:04,161] DEBUG    Site:1EU1tb..E4Vr Need content.json first
[2015-10-23 20:06:04,161] DEBUG    WorkerManager:1EU1tb..E4Vr New task: content.json, peer lock: None, priority: 0, optional_hash_id: None, tasks: 1
[2015-10-23 20:06:04,292] DEBUG    WorkerManager:1EU1tb..E4Vr Added worker: 178.27.188.238:15441, workers: 1/10
[2015-10-23 20:06:04,293] DEBUG    WorkerManager:1EU1tb..E4Vr Added worker: 5.101.103.222:15441, workers: 2/10
[2015-10-23 20:06:04,293] DEBUG    WorkerManager:1EU1tb..E4Vr Added worker: 109.18.164.125:15441, workers: 3/10
[2015-10-23 20:06:04,293] DEBUG    WorkerManager:1EU1tb..E4Vr Added worker: 76.11.82.156:15441, workers: 4/10
[2015-10-23 20:06:04,295] DEBUG    WorkerManager:1EU1tb..E4Vr Added worker: 189.80.18.134:15441, workers: 5/10
[2015-10-23 20:06:04,295] DEBUG    WorkerManager:1EU1tb..E4Vr Added worker: 45.63.123.191:15441, workers: 6/10
[2015-10-23 20:06:04,295] DEBUG    WorkerManager:1EU1tb..E4Vr Added worker: 72.45.24.165:15441, workers: 7/10
[2015-10-23 20:06:04,296] DEBUG    WorkerManager:1EU1tb..E4Vr Added worker: 83.77.48.250:15441, workers: 8/10
[2015-10-23 20:06:04,296] DEBUG    WorkerManager:1EU1tb..E4Vr Added worker: 24.130.150.9:15441, workers: 9/10
[2015-10-23 20:06:04,296] DEBUG    WorkerManager:1EU1tb..E4Vr Added worker: 24.108.77.4:15441, workers: 10/10
[2015-10-23 20:06:04,296] DEBUG    Site:1EU1tb..E4Vr Found 50 peers, new: 36
[2015-10-23 20:06:04,296] DEBUG    Site:1EU1tb..E4Vr 178.27.188.238:15441 Getting connection...
[2015-10-23 20:06:04,296] DEBUG    FileServer Conn#13 178.27.188.238 [?] > Connecting...
[2015-10-23 20:06:04,296] DEBUG    WorkerManager:1EU1tb..E4Vr 5.101.103.222:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:04,298] DEBUG    WorkerManager:1EU1tb..E4Vr 109.18.164.125:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:04,298] DEBUG    WorkerManager:1EU1tb..E4Vr 76.11.82.156:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:04,298] DEBUG    WorkerManager:1EU1tb..E4Vr 189.80.18.134:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:04,299] DEBUG    WorkerManager:1EU1tb..E4Vr 45.63.123.191:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:04,299] DEBUG    WorkerManager:1EU1tb..E4Vr 72.45.24.165:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:04,299] DEBUG    WorkerManager:1EU1tb..E4Vr 83.77.48.250:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:04,299] DEBUG    WorkerManager:1EU1tb..E4Vr 24.130.150.9:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:04,299] DEBUG    WorkerManager:1EU1tb..E4Vr 24.108.77.4:15441: Someone already working on content.json, sleeping 1 sec...
[2015-10-23 20:06:04,309] DEBUG    Site:1EU1tb..E4Vr Found 50 peers, new: 8
[2015-10-23 20:06:04,486] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:04] "GET /uimedia/all.css?rev=477 HTTP/1.1" 200 26618 0.141000
[2015-10-23 20:06:04,490] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:04] "GET /uimedia/all.js?rev=477 HTTP/1.1" 200 156337 0.003000
[2015-10-23 20:06:04,490] DEBUG    WorkerManager:1Name2..hM9F 5.196.71.152:15441: index.html, task done after sleep: False
[2015-10-23 20:06:04,490] DEBUG    WorkerManager:1Name2..hM9F 176.58.120.181:15441: index.html, task done after sleep: False
[2015-10-23 20:06:04,490] DEBUG    WorkerManager:1Name2..hM9F 85.159.209.154:15441: index.html, task done after sleep: False
[2015-10-23 20:06:04,496] DEBUG    WorkerManager:1Name2..hM9F 178.238.41.134:15441: index.html, task done after sleep: False
[2015-10-23 20:06:04,532] DEBUG    Site:1EU1tb..E4Vr Announced port 15441 to 6 trackers in 0.369s, errors: [], slow: []
[2015-10-23 20:06:04,539] DEBUG    WorkerManager:1Name2..hM9F 109.18.164.125:15441: index.html, task done after sleep: False
[2015-10-23 20:06:04,552] DEBUG    Site:1EU1tb..E4Vr Need content.json first
[2015-10-23 20:06:04,596] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-10-23 20:06:04,598] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-10-23 20:06:04,598] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-10-23 20:06:04,598] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-10-23 20:06:04,609] DEBUG    - Created user: 1CKtWDiuHKyEFef8YUTCbc19xYN85edB8Y
[2015-10-23 20:06:04,622] DEBUG    User:1CKtWDiuHKyEFef8YUTCbc19xYN85edB8Y Saved
[2015-10-23 20:06:04,628] DEBUG    WorkerManager:1Name2..hM9F 5.196.71.152:15441: Hash correct: index.html
[2015-10-23 20:06:04,631] DEBUG    Site:1Name2..hM9F Bad file solved: index.html
[2015-10-23 20:06:04,678] DEBUG    WorkerManager:1Name2..hM9F 178.238.41.134:15441: Someone already working on css/all.css, sleeping 1 sec...
[2015-10-23 20:06:04,707] DEBUG    WorkerManager:1Name2..hM9F 104.156.231.236:15441: index.html, task done after sleep: True
[2015-10-23 20:06:04,707] DEBUG    WorkerManager:1Name2..hM9F 104.156.231.236:15441: Someone already working on css/all.css, sleeping 1 sec...
[2015-10-23 20:06:04,733] DEBUG    WorkerManager:1Name2..hM9F 109.18.164.125:15441: Someone already working on css/all.css, sleeping 1 sec...
[2015-10-23 20:06:04,834] DEBUG    WorkerManager:1Name2..hM9F 46.27.7.33:15441: index.html, task done after sleep: True
[2015-10-23 20:06:04,834] DEBUG    WorkerManager:1Name2..hM9F 46.27.7.33:15441: Someone already working on css/all.css, sleeping 1 sec...
[2015-10-23 20:06:04,835] DEBUG    WorkerManager:1Name2..hM9F 50.250.218.164:15441: Someone already working on css/all.css, sleeping 1 sec...
[2015-10-23 20:06:04,918] DEBUG    WorkerManager:1Name2..hM9F 85.159.209.154:15441: Hash correct: data/names.json
[2015-10-23 20:06:04,921] DEBUG    Site:1Name2..hM9F Bad file solved: data/names.json
[2015-10-23 20:06:04,921] DEBUG    WorkerManager:1Name2..hM9F 85.159.209.154:15441: Someone already working on css/all.css, sleeping 1 sec...
[2015-10-23 20:06:04,960] DEBUG    WorkerManager:1Name2..hM9F 5.196.71.152:15441: Hash correct: css/all.css
[2015-10-23 20:06:04,963] DEBUG    Site:1Name2..hM9F Bad file solved: css/all.css
[2015-10-23 20:06:04,963] DEBUG    WorkerManager:1Name2..hM9F 5.196.71.152:15441: Someone already working on js/all.js, sleeping 1 sec...
[2015-10-23 20:06:05,075] DEBUG    WorkerManager:1Name2..hM9F 176.58.120.181:15441: Hash correct: js/all.js
[2015-10-23 20:06:05,076] DEBUG    Site:1Name2..hM9F Bad file solved: js/all.js
[2015-10-23 20:06:05,078] DEBUG    WorkerManager:1Name2..hM9F 176.58.120.181:15441: No task found, stopping
[2015-10-23 20:06:05,078] DEBUG    WorkerManager:1Name2..hM9F Removed worker, workers: 9/10
[2015-10-23 20:06:05,078] DEBUG    Site:1Name2..hM9F content.json: DownloadContent ended in 4.33s
[2015-10-23 20:06:05,078] DEBUG    Site:1Name2..hM9F content.json: DownloadContent ended in 1.06s
[2015-10-23 20:06:05,111] DEBUG    FileServer 185.94.31.204 Connect error: error: [Errno 10061] Aucune connexion nâ€™a pu Ãªtre Ã©tablie car lâ€™ordinateur cible lâ€™a expressÃ©ment refusÃ©e. in ConnectionServer.py line 122 > Connection.py line 77 > socket.py line 342
[2015-10-23 20:06:05,112] DEBUG    FileServer Removing Conn#10 185.94.31.204 [?]...
[2015-10-23 20:06:05,112] DEBUG    Site:1Name2..hM9F 185.94.31.204:15441 Getting connection error: error: [Errno 10061] Aucune connexion nâ€™a pu Ãªtre Ã©tablie car lâ€™ordinateur cible lâ€™a expressÃ©ment refusÃ©e. in Peer.py line 62 > ConnectionServer.py line 130 (connection_error: 1, hash_failed: 0)
[2015-10-23 20:06:05,114] DEBUG    WorkerManager:1Name2..hM9F 185.94.31.204:15441: No task found, stopping
[2015-10-23 20:06:05,114] DEBUG    WorkerManager:1Name2..hM9F Removed worker, workers: 8/10
[2015-10-23 20:06:05,299] DEBUG    WorkerManager:1EU1tb..E4Vr 5.101.103.222:15441: content.json, task done after sleep: False
[2015-10-23 20:06:05,299] DEBUG    Site:1EU1tb..E4Vr 5.101.103.222:15441 Getting connection...
[2015-10-23 20:06:05,299] DEBUG    FileServer Conn#14 5.101.103.222 [?] > Connecting...
[2015-10-23 20:06:05,299] DEBUG    WorkerManager:1EU1tb..E4Vr 109.18.164.125:15441: content.json, task done after sleep: False
[2015-10-23 20:06:05,299] DEBUG    Site:1EU1tb..E4Vr 109.18.164.125:15441 Getting connection...
[2015-10-23 20:06:05,301] DEBUG    WorkerManager:1EU1tb..E4Vr 76.11.82.156:15441: content.json, task done after sleep: False
[2015-10-23 20:06:05,301] DEBUG    Site:1EU1tb..E4Vr 76.11.82.156:15441 Getting connection...
[2015-10-23 20:06:05,301] DEBUG    FileServer Conn#15 76.11.82.156 [?] > Connecting...
[2015-10-23 20:06:05,302] DEBUG    WorkerManager:1EU1tb..E4Vr 189.80.18.134:15441: content.json, task done after sleep: False
[2015-10-23 20:06:05,302] DEBUG    Site:1EU1tb..E4Vr 189.80.18.134:15441 Getting connection...
[2015-10-23 20:06:05,302] DEBUG    FileServer Conn#16 189.80.18.134 [?] > Connecting...
[2015-10-23 20:06:05,302] DEBUG    WorkerManager:1EU1tb..E4Vr 72.45.24.165:15441: content.json, task done after sleep: False
[2015-10-23 20:06:05,302] DEBUG    Site:1EU1tb..E4Vr 72.45.24.165:15441 Getting connection...
[2015-10-23 20:06:05,302] DEBUG    FileServer Conn#17 72.45.24.165 [?] > Connecting...
[2015-10-23 20:06:05,302] DEBUG    WorkerManager:1EU1tb..E4Vr 45.63.123.191:15441: content.json, task done after sleep: False
[2015-10-23 20:06:05,303] DEBUG    Site:1EU1tb..E4Vr 45.63.123.191:15441 Getting connection...
[2015-10-23 20:06:05,303] DEBUG    FileServer Conn#18 45.63.123.191 [?] > Connecting...
[2015-10-23 20:06:05,303] DEBUG    WorkerManager:1EU1tb..E4Vr 24.130.150.9:15441: content.json, task done after sleep: False
[2015-10-23 20:06:05,305] DEBUG    Site:1EU1tb..E4Vr 24.130.150.9:15441 Getting connection...
[2015-10-23 20:06:05,305] DEBUG    FileServer Conn#19 24.130.150.9 [?] > Connecting...
[2015-10-23 20:06:05,305] DEBUG    WorkerManager:1EU1tb..E4Vr 83.77.48.250:15441: content.json, task done after sleep: False
[2015-10-23 20:06:05,305] DEBUG    Site:1EU1tb..E4Vr 83.77.48.250:15441 Getting connection...
[2015-10-23 20:06:05,305] DEBUG    FileServer Conn#20 83.77.48.250 [?] > Connecting...
[2015-10-23 20:06:05,305] DEBUG    WorkerManager:1EU1tb..E4Vr 24.108.77.4:15441: content.json, task done after sleep: False
[2015-10-23 20:06:05,305] DEBUG    Site:1EU1tb..E4Vr 24.108.77.4:15441 Getting connection...
[2015-10-23 20:06:05,305] DEBUG    FileServer Conn#21 24.108.77.4  [?] > Connecting...
[2015-10-23 20:06:05,418] DEBUG    WorkerManager:1Name2..hM9F 121.75.18.208:15441: No task found, stopping
[2015-10-23 20:06:05,418] DEBUG    WorkerManager:1Name2..hM9F Removed worker, workers: 7/10
[2015-10-23 20:06:05,451] DEBUG    FileServer Conn#14 5.101.103.222 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:05,628] DEBUG    WorkerManager:1EU1tb..E4Vr 109.18.164.125:15441: Hash correct: content.json
[2015-10-23 20:06:05,631] DEBUG    Site:1EU1tb..E4Vr Bad file solved: content.json
[2015-10-23 20:06:05,714] DEBUG    User:1CKtWDiuHKyEFef8YUTCbc19xYN85edB8Y Saved
[2015-10-23 20:06:05,716] DEBUG    User:1CKtWDiuHKyEFef8YUTCbc19xYN85edB8Y Added new site: 1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr in 0.085s
[2015-10-23 20:06:05,716] DEBUG    WorkerManager:1EU1tb..E4Vr 109.18.164.125:15441: No task found, stopping
[2015-10-23 20:06:05,717] DEBUG    WorkerManager:1EU1tb..E4Vr Removed worker, workers: 9/10
[2015-10-23 20:06:05,717] DEBUG    Site:1EU1tb..E4Vr Got content.json
[2015-10-23 20:06:05,717] DEBUG    WorkerManager:1EU1tb..E4Vr New task: test/render.html, peer lock: None, priority: 0, optional_hash_id: None, tasks: 1
[2015-10-23 20:06:05,717] DEBUG    WorkerManager:1EU1tb..E4Vr Added worker: 24.8.187.119:15441, workers: 10/10
[2015-10-23 20:06:05,717] DEBUG    WorkerManager:1EU1tb..E4Vr New task: favicon.ico, peer lock: None, priority: 0, optional_hash_id: None, tasks: 2
[2015-10-23 20:06:05,719] DEBUG    WorkerManager:1EU1tb..E4Vr New task: index.html, peer lock: None, priority: 0, optional_hash_id: None, tasks: 3
[2015-10-23 20:06:05,719] DEBUG    WorkerManager:1EU1tb..E4Vr New task: font/Roboto-Light.woff, peer lock: None, priority: 0, optional_hash_id: None, tasks: 4
[2015-10-23 20:06:05,720] DEBUG    WorkerManager:1EU1tb..E4Vr New task: test/jquery.min.js, peer lock: None, priority: 0, optional_hash_id: None, tasks: 5
[2015-10-23 20:06:05,720] DEBUG    WorkerManager:1EU1tb..E4Vr New task: test/worker.js, peer lock: None, priority: 0, optional_hash_id: None, tasks: 6
[2015-10-23 20:06:05,720] DEBUG    WorkerManager:1EU1tb..E4Vr New task: css/all.css, peer lock: None, priority: 0, optional_hash_id: None, tasks: 7
[2015-10-23 20:06:05,720] DEBUG    WorkerManager:1EU1tb..E4Vr New task: font/TextMeOne-Regular.woff, peer lock: None, priority: 0, optional_hash_id: None, tasks: 8
[2015-10-23 20:06:05,720] DEBUG    WorkerManager:1EU1tb..E4Vr New task: js/all.js, peer lock: None, priority: 0, optional_hash_id: None, tasks: 9
[2015-10-23 20:06:05,720] DEBUG    WorkerManager:1EU1tb..E4Vr New task: img/loading.gif, peer lock: None, priority: 0, optional_hash_id: None, tasks: 10
[2015-10-23 20:06:05,721] DEBUG    WorkerManager:1EU1tb..E4Vr New task: test/security.html, peer lock: None, priority: 0, optional_hash_id: None, tasks: 11
[2015-10-23 20:06:05,721] DEBUG    WorkerManager:1EU1tb..E4Vr New task: font/Roboto-Medium.woff, peer lock: None, priority: 0, optional_hash_id: None, tasks: 12
[2015-10-23 20:06:05,723] DEBUG    WorkerManager:1EU1tb..E4Vr New task: test/stats.js, peer lock: None, priority: 0, optional_hash_id: None, tasks: 13
[2015-10-23 20:06:05,723] DEBUG    Site:1EU1tb..E4Vr content.json: Downloading 0 includes...
[2015-10-23 20:06:05,723] DEBUG    Site:1EU1tb..E4Vr content.json: Includes download ended
[2015-10-23 20:06:05,723] DEBUG    Site:1EU1tb..E4Vr Try to get listModifications from peers: [<Peer:178.238.41.134>, <Peer:62.210.38.54>, <Peer:5.196.71.152>, <Peer:121.75.18.208>, <Peer:104.156.231.236>, <Peer:46.27.7.33  >, <Peer:109.18.164.125>, <Peer:185.83.219.64>, <Peer:178.27.188.238>, <Peer:73.22.88.64 >, <Peer:189.80.18.134>, <Peer:79.251.149.158>] since: 0
[2015-10-23 20:06:05,723] DEBUG    Site:1EU1tb..E4Vr 24.8.187.119:15441 Getting connection...
[2015-10-23 20:06:05,723] DEBUG    FileServer Conn#22 24.8.187.119 [?] > Connecting...
[2015-10-23 20:06:05,724] DEBUG    WorkerManager:1Name2..hM9F 178.238.41.134:15441: css/all.css, task done after sleep: True
[2015-10-23 20:06:05,726] DEBUG    WorkerManager:1Name2..hM9F 178.238.41.134:15441: No task found, stopping
[2015-10-23 20:06:05,726] DEBUG    WorkerManager:1Name2..hM9F Removed worker, workers: 6/10
[2015-10-23 20:06:05,726] DEBUG    WorkerManager:1Name2..hM9F 104.156.231.236:15441: css/all.css, task done after sleep: True
[2015-10-23 20:06:05,726] DEBUG    WorkerManager:1Name2..hM9F 104.156.231.236:15441: No task found, stopping
[2015-10-23 20:06:05,726] DEBUG    WorkerManager:1Name2..hM9F Removed worker, workers: 5/10
[2015-10-23 20:06:05,727] DEBUG    FileServer Conn#20 83.77.48.250 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:05,730] DEBUG    FileServer Conn#15 76.11.82.156 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:05,730] DEBUG    FileServer Conn#17 72.45.24.165 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:05,734] DEBUG    WorkerManager:1Name2..hM9F 109.18.164.125:15441: css/all.css, task done after sleep: True
[2015-10-23 20:06:05,734] DEBUG    WorkerManager:1Name2..hM9F 109.18.164.125:15441: No task found, stopping
[2015-10-23 20:06:05,734] DEBUG    WorkerManager:1Name2..hM9F Removed worker, workers: 4/10
[2015-10-23 20:06:05,835] DEBUG    WorkerManager:1Name2..hM9F 46.27.7.33:15441: css/all.css, task done after sleep: True
[2015-10-23 20:06:05,835] DEBUG    WorkerManager:1Name2..hM9F 46.27.7.33:15441: No task found, stopping
[2015-10-23 20:06:05,835] DEBUG    WorkerManager:1Name2..hM9F Removed worker, workers: 3/10
[2015-10-23 20:06:05,836] DEBUG    WorkerManager:1Name2..hM9F 50.250.218.164:15441: css/all.css, task done after sleep: True
[2015-10-23 20:06:05,836] DEBUG    WorkerManager:1Name2..hM9F 50.250.218.164:15441: No task found, stopping
[2015-10-23 20:06:05,836] DEBUG    WorkerManager:1Name2..hM9F Removed worker, workers: 2/10
[2015-10-23 20:06:05,924] DEBUG    WorkerManager:1Name2..hM9F 85.159.209.154:15441: css/all.css, task done after sleep: True
[2015-10-23 20:06:05,924] DEBUG    WorkerManager:1Name2..hM9F 85.159.209.154:15441: No task found, stopping
[2015-10-23 20:06:05,926] DEBUG    WorkerManager:1Name2..hM9F Removed worker, workers: 1/10
[2015-10-23 20:06:05,963] DEBUG    WorkerManager:1Name2..hM9F 5.196.71.152:15441: js/all.js, task done after sleep: True
[2015-10-23 20:06:05,963] DEBUG    WorkerManager:1Name2..hM9F 5.196.71.152:15441: No task found, stopping
[2015-10-23 20:06:05,963] DEBUG    WorkerManager:1Name2..hM9F Removed worker, workers: 0/10
[2015-10-23 20:06:05,976] DEBUG    FileServer Conn#21 24.108.77.4  [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:06,022] DEBUG    FileServer Conn#16 189.80.18.134 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:06,032] DEBUG    WorkerManager:1EU1tb..E4Vr 5.101.103.222:15441: Someone already working on index.html, sleeping 1 sec...
[2015-10-23 20:06:06,068] DEBUG    FileServer Conn#18 45.63.123.191 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:06,210] DEBUG    FileServer Conn#22 24.8.187.119 [v2] > Crypt out connection using: tls-rsa (server side: False)...
[2015-10-23 20:06:06,256] DEBUG    WorkerManager:1EU1tb..E4Vr 83.77.48.250:15441: Someone already working on index.html, sleeping 1 sec...
[2015-10-23 20:06:06,309] DEBUG    Site:1EU1tb..E4Vr Queried listModifications from: [<Peer:62.210.38.54>, <Peer:5.196.71.152>, <Peer:178.238.41.134>, <Peer:104.156.231.236>, <Peer:121.75.18.208>]
[2015-10-23 20:06:06,309] DEBUG    Site:1EU1tb..E4Vr content.json: Downloading 13 files, changed: 13...
[2015-10-23 20:06:06,369] DEBUG    WorkerManager:1EU1tb..E4Vr 72.45.24.165:15441: Someone already working on index.html, sleeping 1 sec...
[2015-10-23 20:06:06,555] DEBUG    WorkerManager:1EU1tb..E4Vr 76.11.82.156:15441: Someone already working on index.html, sleeping 1 sec...
[2015-10-23 20:06:06,650] DEBUG    Site:1Name2..hM9F 62.210.38.54:15441 Added peers using pex: 2
[2015-10-23 20:06:06,650] DEBUG    Site:1Name2..hM9F Queried pex from 2 peers got 2 new peers.
[2015-10-23 20:06:06,911] DEBUG    WorkerManager:1EU1tb..E4Vr 24.108.77.4:15441: Someone already working on index.html, sleeping 1 sec...
[2015-10-23 20:06:06,973] DEBUG    WorkerManager:1EU1tb..E4Vr 24.8.187.119:15441: Hash correct: index.html
[2015-10-23 20:06:06,976] DEBUG    Site:1EU1tb..E4Vr Bad file solved: index.html
[2015-10-23 20:06:06,979] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:06] "GET /1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/?wrapper_nonce=155cd63c157da2dfeec88874b936d6c6ab60c6b3cc371079e9d39b47e0228a20 HTTP/1.1" 200 2710 2.427000
[2015-10-23 20:06:07,033] DEBUG    WorkerManager:1EU1tb..E4Vr 5.101.103.222:15441: index.html, task done after sleep: True
[2015-10-23 20:06:07,256] DEBUG    WorkerManager:1EU1tb..E4Vr 83.77.48.250:15441: index.html, task done after sleep: True
[2015-10-23 20:06:07,349] DEBUG    WorkerManager:1EU1tb..E4Vr 5.101.103.222:15441: Hash correct: test/jquery.min.js
[2015-10-23 20:06:07,351] DEBUG    Site:1EU1tb..E4Vr Bad file solved: test/jquery.min.js
[2015-10-23 20:06:07,352] DEBUG    WorkerManager:1EU1tb..E4Vr 5.101.103.222:15441: Someone already working on css/all.css, sleeping 1 sec...
[2015-10-23 20:06:07,371] DEBUG    WorkerManager:1EU1tb..E4Vr 72.45.24.165:15441: index.html, task done after sleep: True
[2015-10-23 20:06:07,371] DEBUG    WorkerManager:1EU1tb..E4Vr 72.45.24.165:15441: Someone already working on css/all.css, sleeping 1 sec...
[2015-10-23 20:06:07,555] DEBUG    WorkerManager:1EU1tb..E4Vr 76.11.82.156:15441: index.html, task done after sleep: True
[2015-10-23 20:06:07,555] DEBUG    WorkerManager:1EU1tb..E4Vr 76.11.82.156:15441: Someone already working on css/all.css, sleeping 1 sec...
[2015-10-23 20:06:07,723] DEBUG    WorkerManager:1EU1tb..E4Vr 189.80.18.134:15441: Hash correct: test/worker.js
[2015-10-23 20:06:07,724] DEBUG    Site:1EU1tb..E4Vr Bad file solved: test/worker.js
[2015-10-23 20:06:07,726] DEBUG    WorkerManager:1EU1tb..E4Vr 189.80.18.134:15441: Someone already working on css/all.css, sleeping 1 sec...
[2015-10-23 20:06:07,803] DEBUG    WorkerManager:1EU1tb..E4Vr 45.63.123.191:15441: Someone already working on css/all.css, sleeping 1 sec...
[2015-10-23 20:06:07,834] DEBUG    WorkerManager:1EU1tb..E4Vr 83.77.48.250:15441: Hash correct: js/all.js
[2015-10-23 20:06:07,838] DEBUG    Site:1EU1tb..E4Vr Bad file solved: js/all.js
[2015-10-23 20:06:07,841] DEBUG    WorkerManager:1EU1tb..E4Vr 83.77.48.250:15441: Someone already working on css/all.css, sleeping 1 sec...
[2015-10-23 20:06:07,845] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:07] "GET /1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/js/all.js HTTP/1.1" 200 128097 0.578000
[2015-10-23 20:06:07,913] DEBUG    WorkerManager:1EU1tb..E4Vr 24.108.77.4:15441: index.html, task done after sleep: True
[2015-10-23 20:06:07,913] DEBUG    WorkerManager:1EU1tb..E4Vr 24.108.77.4:15441: Someone already working on css/all.css, sleeping 1 sec...
[2015-10-23 20:06:08,302] DEBUG    WorkerManager:1EU1tb..E4Vr 24.8.187.119:15441: Hash correct: css/all.css
[2015-10-23 20:06:08,303] DEBUG    Site:1EU1tb..E4Vr Bad file solved: css/all.css
[2015-10-23 20:06:08,305] DEBUG    Site:1EU1tb..E4Vr 24.8.187.119:15441 Added peers using pex: 2
[2015-10-23 20:06:08,305] DEBUG    Site:1EU1tb..E4Vr Queried pex from 2 peers got 2 new peers.
[2015-10-23 20:06:08,306] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:08] "GET /1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/css/all.css HTTP/1.1" 200 82462 1.045000
[2015-10-23 20:06:08,354] DEBUG    WorkerManager:1EU1tb..E4Vr 5.101.103.222:15441: css/all.css, task done after sleep: True
[2015-10-23 20:06:08,371] DEBUG    WorkerManager:1EU1tb..E4Vr 72.45.24.165:15441: css/all.css, task done after sleep: True
[2015-10-23 20:06:08,420] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:08] "GET /favicon.ico HTTP/1.1" 200 1385 0.001000
[2015-10-23 20:06:08,496] DEBUG    WorkerManager:1EU1tb..E4Vr 5.101.103.222:15441: Hash correct: test/render.html
[2015-10-23 20:06:08,500] DEBUG    Site:1EU1tb..E4Vr Bad file solved: test/render.html
[2015-10-23 20:06:08,556] DEBUG    WorkerManager:1EU1tb..E4Vr 76.11.82.156:15441: css/all.css, task done after sleep: True
[2015-10-23 20:06:08,664] DEBUG    WorkerManager:1EU1tb..E4Vr 5.101.103.222:15441: Hash correct: font/Roboto-Light.woff
[2015-10-23 20:06:08,665] DEBUG    Site:1EU1tb..E4Vr Bad file solved: font/Roboto-Light.woff
[2015-10-23 20:06:08,686] DEBUG    WorkerManager:1EU1tb..E4Vr 24.8.187.119:15441: Hash correct: test/stats.js
[2015-10-23 20:06:08,687] DEBUG    Site:1EU1tb..E4Vr Bad file solved: test/stats.js
[2015-10-23 20:06:08,690] DEBUG    WorkerManager:1EU1tb..E4Vr 72.45.24.165:15441: Hash correct: favicon.ico
[2015-10-23 20:06:08,691] DEBUG    Site:1EU1tb..E4Vr Bad file solved: favicon.ico
[2015-10-23 20:06:08,726] DEBUG    WorkerManager:1EU1tb..E4Vr 189.80.18.134:15441: css/all.css, task done after sleep: True
[2015-10-23 20:06:08,726] DEBUG    WorkerManager:1EU1tb..E4Vr 189.80.18.134:15441: Someone already working on font/Roboto-Medium.woff, sleeping 1 sec...
[2015-10-23 20:06:08,805] DEBUG    WorkerManager:1EU1tb..E4Vr 45.63.123.191:15441: css/all.css, task done after sleep: True
[2015-10-23 20:06:08,805] DEBUG    WorkerManager:1EU1tb..E4Vr 45.63.123.191:15441: Someone already working on font/Roboto-Medium.woff, sleeping 1 sec...
[2015-10-23 20:06:08,831] DEBUG    WorkerManager:1EU1tb..E4Vr 5.101.103.222:15441: Hash correct: img/loading.gif
[2015-10-23 20:06:08,832] DEBUG    Site:1EU1tb..E4Vr Bad file solved: img/loading.gif
[2015-10-23 20:06:08,832] DEBUG    WorkerManager:1EU1tb..E4Vr 5.101.103.222:15441: Someone already working on font/Roboto-Medium.woff, sleeping 1 sec...
[2015-10-23 20:06:08,842] DEBUG    WorkerManager:1EU1tb..E4Vr 83.77.48.250:15441: css/all.css, task done after sleep: True
[2015-10-23 20:06:08,842] DEBUG    WorkerManager:1EU1tb..E4Vr 83.77.48.250:15441: Someone already working on font/Roboto-Medium.woff, sleeping 1 sec...
[2015-10-23 20:06:08,914] DEBUG    WorkerManager:1EU1tb..E4Vr 24.108.77.4:15441: css/all.css, task done after sleep: True
[2015-10-23 20:06:08,914] DEBUG    WorkerManager:1EU1tb..E4Vr 24.108.77.4:15441: Someone already working on font/Roboto-Medium.woff, sleeping 1 sec...
[2015-10-23 20:06:08,993] DEBUG    WorkerManager:1EU1tb..E4Vr 76.11.82.156:15441: Hash correct: font/TextMeOne-Regular.woff
[2015-10-23 20:06:08,994] DEBUG    Site:1EU1tb..E4Vr Bad file solved: font/TextMeOne-Regular.woff
[2015-10-23 20:06:08,996] DEBUG    WorkerManager:1EU1tb..E4Vr 76.11.82.156:15441: Someone already working on font/Roboto-Medium.woff, sleeping 1 sec...
[2015-10-23 20:06:09,059] DEBUG    WorkerManager:1EU1tb..E4Vr 72.45.24.165:15441: Hash correct: font/Roboto-Medium.woff
[2015-10-23 20:06:09,062] DEBUG    Site:1EU1tb..E4Vr Bad file solved: font/Roboto-Medium.woff
[2015-10-23 20:06:09,062] DEBUG    WorkerManager:1EU1tb..E4Vr 72.45.24.165:15441: Someone already working on test/security.html, sleeping 1 sec...
[2015-10-23 20:06:09,121] DEBUG    WorkerManager:1EU1tb..E4Vr 24.8.187.119:15441: Hash correct: test/security.html
[2015-10-23 20:06:09,122] DEBUG    Site:1EU1tb..E4Vr Bad file solved: test/security.html
[2015-10-23 20:06:09,122] DEBUG    WorkerManager:1EU1tb..E4Vr 24.8.187.119:15441: No task found, stopping
[2015-10-23 20:06:09,124] DEBUG    WorkerManager:1EU1tb..E4Vr Removed worker, workers: 9/10
[2015-10-23 20:06:09,124] DEBUG    Site:1EU1tb..E4Vr content.json: DownloadContent ended in 4.96s
[2015-10-23 20:06:09,729] DEBUG    WorkerManager:1EU1tb..E4Vr 189.80.18.134:15441: font/Roboto-Medium.woff, task done after sleep: True
[2015-10-23 20:06:09,729] DEBUG    WorkerManager:1EU1tb..E4Vr 189.80.18.134:15441: No task found, stopping
[2015-10-23 20:06:09,729] DEBUG    WorkerManager:1EU1tb..E4Vr Removed worker, workers: 8/10
[2015-10-23 20:06:09,805] DEBUG    WorkerManager:1EU1tb..E4Vr 45.63.123.191:15441: font/Roboto-Medium.woff, task done after sleep: True
[2015-10-23 20:06:09,805] DEBUG    WorkerManager:1EU1tb..E4Vr 45.63.123.191:15441: No task found, stopping
[2015-10-23 20:06:09,805] DEBUG    WorkerManager:1EU1tb..E4Vr Removed worker, workers: 7/10
[2015-10-23 20:06:09,832] DEBUG    WorkerManager:1EU1tb..E4Vr 5.101.103.222:15441: font/Roboto-Medium.woff, task done after sleep: True
[2015-10-23 20:06:09,832] DEBUG    WorkerManager:1EU1tb..E4Vr 5.101.103.222:15441: No task found, stopping
[2015-10-23 20:06:09,832] DEBUG    WorkerManager:1EU1tb..E4Vr Removed worker, workers: 6/10
[2015-10-23 20:06:09,842] DEBUG    WorkerManager:1EU1tb..E4Vr 83.77.48.250:15441: font/Roboto-Medium.woff, task done after sleep: True
[2015-10-23 20:06:09,842] DEBUG    WorkerManager:1EU1tb..E4Vr 83.77.48.250:15441: No task found, stopping
[2015-10-23 20:06:09,842] DEBUG    WorkerManager:1EU1tb..E4Vr Removed worker, workers: 5/10
[2015-10-23 20:06:09,914] DEBUG    WorkerManager:1EU1tb..E4Vr 24.108.77.4:15441: font/Roboto-Medium.woff, task done after sleep: True
[2015-10-23 20:06:09,914] DEBUG    WorkerManager:1EU1tb..E4Vr 24.108.77.4:15441: No task found, stopping
[2015-10-23 20:06:09,915] DEBUG    WorkerManager:1EU1tb..E4Vr Removed worker, workers: 4/10
[2015-10-23 20:06:09,996] DEBUG    WorkerManager:1EU1tb..E4Vr 76.11.82.156:15441: font/Roboto-Medium.woff, task done after sleep: True
[2015-10-23 20:06:09,996] DEBUG    WorkerManager:1EU1tb..E4Vr 76.11.82.156:15441: No task found, stopping
[2015-10-23 20:06:09,997] DEBUG    WorkerManager:1EU1tb..E4Vr Removed worker, workers: 3/10
[2015-10-23 20:06:10,063] DEBUG    WorkerManager:1EU1tb..E4Vr 72.45.24.165:15441: test/security.html, task done after sleep: True
[2015-10-23 20:06:10,063] DEBUG    WorkerManager:1EU1tb..E4Vr 72.45.24.165:15441: No task found, stopping
[2015-10-23 20:06:10,065] DEBUG    WorkerManager:1EU1tb..E4Vr Removed worker, workers: 2/10
[2015-10-23 20:06:11,173] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:11] "GET /ZeroNetwork.bit HTTP/1.1" 200 2502 0.001000
[2015-10-23 20:06:11,173] DEBUG    Site:1Name2..hM9F Start downloading, bad_files: {}, check_size: False, blind_includes: False
[2015-10-23 20:06:11,174] DEBUG    Site:1Name2..hM9F Downloading content.json...
[2015-10-23 20:06:11,174] DEBUG    Site:1Name2..hM9F Got content.json
[2015-10-23 20:06:11,174] DEBUG    Site:1Name2..hM9F content.json: Downloading 0 includes...
[2015-10-23 20:06:11,176] DEBUG    Site:1Name2..hM9F content.json: Includes download ended
[2015-10-23 20:06:11,176] DEBUG    Site:1Name2..hM9F content.json: Downloading 0 files, changed: 0...
[2015-10-23 20:06:11,176] DEBUG    Site:1Name2..hM9F content.json: DownloadContent ended in 0.00s
[2015-10-23 20:06:11,316] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:11] "GET /uimedia/all.css?rev=477 HTTP/1.1" 200 26618 0.002000
[2015-10-23 20:06:11,322] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:11] "GET /uimedia/all.js?rev=477 HTTP/1.1" 200 156337 0.003000
[2015-10-23 20:06:11,496] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:11] "GET /ZeroNetwork.bit/?wrapper_nonce=6c220834b57b1243d0549cc1e9c863066b85bb692e4051e14cfdb8c4afa944f6 HTTP/1.1" 200 2710 0.002000
[2015-10-23 20:06:11,586] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:11] "GET /ZeroNetwork.bit/css/all.css HTTP/1.1" 200 82462 0.001000
[2015-10-23 20:06:11,594] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:11] "GET /ZeroNetwork.bit/js/all.js HTTP/1.1" 200 128097 0.002000
[2015-10-23 20:06:11,684] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-10-23 20:06:11,684] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-10-23 20:06:11,684] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-10-23 20:06:11,684] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-10-23 20:06:11,835] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:11] "GET /ZeroNetwork.bit/img/loading.gif HTTP/1.1" 200 955 0.001000
[2015-10-23 20:06:11,891] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:11] "GET /favicon.ico HTTP/1.1" 200 1385 0.001000
[2015-10-23 20:06:12,799] DEBUG    FileServer Conn#23 70.37.165.32 [?] > Incoming connection...
[2015-10-23 20:06:12,799] DEBUG    FileServer Conn#23 70.37.165.32 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2015-10-23 20:06:13,078] DEBUG    lib.geventwebsocket.handler Closed WebSocket
[2015-10-23 20:06:13,078] DEBUG    lib.geventwebsocket.handler Failed to write closing frame -> closing socket
[2015-10-23 20:06:13,078] DEBUG    lib.geventwebsocket.handler Closed WebSocket
[2015-10-23 20:06:13,078] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:13] "GET /Websocket?wrapper_key=xxx HTTP/1.1" 101 129 8.482000
[2015-10-23 20:06:13,355] DEBUG    FileServer FileRequest: Conn#23 70.37.165.32 [v2] pex 1C2JhCunGLtvyX56nQ88tcb87WnXspjWN None
[2015-10-23 20:06:14,351] DEBUG    lib.geventwebsocket.handler Closed WebSocket
[2015-10-23 20:06:14,351] DEBUG    lib.geventwebsocket.handler Failed to write closing frame -> closing socket
[2015-10-23 20:06:14,351] DEBUG    lib.geventwebsocket.handler Closed WebSocket
[2015-10-23 20:06:14,352] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:14] "GET /Websocket?wrapper_key=xxx HTTP/1.1" 101 129 2.669000
[2015-10-23 20:06:14,371] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:14] "GET /ZeroNetwork.bit HTTP/1.1" 200 2502 0.002000
[2015-10-23 20:06:14,553] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:14] "GET /uimedia/all.css?rev=477 HTTP/1.1" 200 26618 0.002000
[2015-10-23 20:06:14,561] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:14] "GET /uimedia/all.js?rev=477 HTTP/1.1" 200 156337 0.004000
[2015-10-23 20:06:14,634] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:14] "GET /ZeroNetwork.bit/?wrapper_nonce=0ab09671dd7ad493791a58454451ea515f889d96e13bfacac47836d0fd86e16b HTTP/1.1" 200 2710 0.001000
[2015-10-23 20:06:14,733] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-10-23 20:06:14,733] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-10-23 20:06:14,733] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-10-23 20:06:14,733] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-10-23 20:06:14,743] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:14] "GET /ZeroNetwork.bit/css/all.css HTTP/1.1" 200 82462 0.002000
[2015-10-23 20:06:14,747] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:14] "GET /ZeroNetwork.bit/js/all.js HTTP/1.1" 200 128097 0.002000
[2015-10-23 20:06:14,904] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:14] "GET /favicon.ico HTTP/1.1" 200 1385 0.001000
[2015-10-23 20:06:19,161] DEBUG    WorkerManager:1EU1tb..E4Vr 24.130.150.9:15441: Force skipping
[2015-10-23 20:06:19,161] DEBUG    FileServer 24.130.150.9 Connect error: Worker stopped
[2015-10-23 20:06:19,163] DEBUG    FileServer Removing Conn#19 24.130.150.9 [?]...
[2015-10-23 20:06:19,164] DEBUG    Site:1EU1tb..E4Vr 24.130.150.9:15441 Getting connection error: Worker stopped (connection_error: 1, hash_failed: 0)
[2015-10-23 20:06:19,164] DEBUG    WorkerManager:1EU1tb..E4Vr 24.130.150.9:15441: No task found, stopping
[2015-10-23 20:06:19,167] DEBUG    WorkerManager:1EU1tb..E4Vr Removed worker, workers: 1/10
[2015-10-23 20:06:19,167] DEBUG    WorkerManager:1EU1tb..E4Vr 178.27.188.238:15441: Force skipping
[2015-10-23 20:06:19,167] DEBUG    WorkerManager:1EU1tb..E4Vr 24.130.150.9:15441: No task found, stopping
[2015-10-23 20:06:19,168] DEBUG    FileServer 178.27.188.238 Connect error: Worker stopped
[2015-10-23 20:06:19,170] DEBUG    FileServer Removing Conn#13 178.27.188.238 [?]...
[2015-10-23 20:06:19,171] DEBUG    Site:1EU1tb..E4Vr 178.27.188.238:15441 Getting connection error: Worker stopped (connection_error: 1, hash_failed: 0)
[2015-10-23 20:06:19,171] DEBUG    WorkerManager:1EU1tb..E4Vr 178.27.188.238:15441: No task found, stopping
[2015-10-23 20:06:19,173] DEBUG    WorkerManager:1EU1tb..E4Vr Removed worker, workers: 0/10
[2015-10-23 20:06:19,174] DEBUG    WorkerManager:1EU1tb..E4Vr 178.27.188.238:15441: No task found, stopping
[2015-10-23 20:06:28,918] DEBUG    lib.geventwebsocket.handler Closed WebSocket
[2015-10-23 20:06:28,918] DEBUG    lib.geventwebsocket.handler Failed to write closing frame -> closing socket
[2015-10-23 20:06:28,920] DEBUG    lib.geventwebsocket.handler Closed WebSocket
[2015-10-23 20:06:28,920] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:28] "GET /Websocket?wrapper_key=xxx HTTP/1.1" 101 129 14.187000
[2015-10-23 20:06:28,938] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:28] "GET /ZeroNetwork.bit HTTP/1.1" 200 2502 0.001000
[2015-10-23 20:06:29,125] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:29] "GET /uimedia/all.css?rev=477 HTTP/1.1" 200 26618 0.002000
[2015-10-23 20:06:29,131] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:29] "GET /uimedia/all.js?rev=477 HTTP/1.1" 200 156337 0.002000
[2015-10-23 20:06:29,206] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:29] "GET /ZeroNetwork.bit/?wrapper_nonce=28167a97184ee04246368d7977009a3e41a7cf94b16676a3cc770543bb549901 HTTP/1.1" 200 2710 0.001000
[2015-10-23 20:06:29,315] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:29] "GET /ZeroNetwork.bit/css/all.css HTTP/1.1" 200 82462 0.001000
[2015-10-23 20:06:29,322] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:29] "GET /ZeroNetwork.bit/js/all.js HTTP/1.1" 200 128097 0.002000
[2015-10-23 20:06:29,335] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-10-23 20:06:29,335] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-10-23 20:06:29,335] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-10-23 20:06:29,335] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-10-23 20:06:29,464] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:29] "GET /favicon.ico HTTP/1.1" 200 1385 0.001000
[2015-10-23 20:06:30,582] DEBUG    lib.geventwebsocket.handler Closed WebSocket
[2015-10-23 20:06:30,582] DEBUG    lib.geventwebsocket.handler Failed to write closing frame -> closing socket
[2015-10-23 20:06:30,582] DEBUG    lib.geventwebsocket.handler Closed WebSocket
```

And then here it didn't connect, and at the end it recover connection:

```
[2015-10-23 20:06:30,582] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:30] "GET /Websocket?wrapper_key=xxx HTTP/1.1" 101 129 1.249000
[2015-10-23 20:06:30,605] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:30] "GET /ZeroNetwork.bit HTTP/1.1" 200 2502 0.001000
[2015-10-23 20:06:30,762] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:30] "GET /uimedia/all.css?rev=477 HTTP/1.1" 200 26618 0.002000
[2015-10-23 20:06:30,767] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:30] "GET /uimedia/all.js?rev=477 HTTP/1.1" 200 156337 0.003000
[2015-10-23 20:06:30,835] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:30] "GET /ZeroNetwork.bit/?wrapper_nonce=e14a53e4631d98bfec503af3eff02fb727f78e36523b91a0e98dd26f56165577 HTTP/1.1" 200 2710 0.001000
[2015-10-23 20:06:30,928] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-10-23 20:06:30,928] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-10-23 20:06:30,928] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-10-23 20:06:30,930] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-10-23 20:06:30,937] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:30] "GET /ZeroNetwork.bit/css/all.css HTTP/1.1" 200 82462 0.001000
[2015-10-23 20:06:30,943] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:30] "GET /ZeroNetwork.bit/js/all.js HTTP/1.1" 200 128097 0.002000
[2015-10-23 20:06:31,072] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:06:31] "GET /favicon.ico HTTP/1.1" 200 1385 0.001000
[2015-10-23 20:06:47,151] DEBUG    FileServer FileRequest: Conn#23 70.37.165.32 [v2] pex 192dZ1EG5tU7PnCfuwGMDEBrr2eLqvs4t3 None
[2015-10-23 20:06:47,331] DEBUG    FileServer Removing Conn#23 70.37.165.32 [v2]...
[2015-10-23 20:07:00,750] DEBUG    FileServer Conn# 1 104.156.231.236 [v2] > Unpacker deleted
[2015-10-23 20:07:00,752] DEBUG    FileServer Conn# 2 176.58.120.181 [v2] > Unpacker deleted
[2015-10-23 20:07:00,752] DEBUG    FileServer Conn# 3 62.210.38.54 [v2] > Unpacker deleted
[2015-10-23 20:07:00,753] DEBUG    FileServer Conn# 4 46.27.7.33   [v2] > Unpacker deleted
[2015-10-23 20:07:00,753] DEBUG    FileServer Conn# 5 5.196.71.152 [v2] > Unpacker deleted
[2015-10-23 20:07:00,753] DEBUG    FileServer Conn# 6 121.75.18.208 [v2] > Unpacker deleted
[2015-10-23 20:07:00,753] DEBUG    FileServer Conn# 7 109.18.164.125 [v2] > Unpacker deleted
[2015-10-23 20:07:00,753] DEBUG    FileServer Conn# 8 85.159.209.154 [v2] > Unpacker deleted
[2015-10-23 20:07:00,753] DEBUG    FileServer Conn# 9 178.238.41.134 [v2] > Unpacker deleted
[2015-10-23 20:07:00,755] DEBUG    FileServer Conn#11 50.250.218.164 [v2] > Unpacker deleted
[2015-10-23 20:07:00,755] DEBUG    FileServer Conn#14 5.101.103.222 [v2] > Unpacker deleted
[2015-10-23 20:07:00,755] DEBUG    FileServer Conn#15 76.11.82.156 [v2] > Unpacker deleted
[2015-10-23 20:07:00,756] DEBUG    FileServer Conn#16 189.80.18.134 [v2] > Unpacker deleted
[2015-10-23 20:07:00,756] DEBUG    FileServer Conn#17 72.45.24.165 [v2] > Unpacker deleted
[2015-10-23 20:07:00,756] DEBUG    FileServer Conn#18 45.63.123.191 [v2] > Unpacker deleted
[2015-10-23 20:07:00,756] DEBUG    FileServer Conn#20 83.77.48.250 [v2] > Unpacker deleted
[2015-10-23 20:07:00,756] DEBUG    FileServer Conn#21 24.108.77.4  [v2] > Unpacker deleted
[2015-10-23 20:07:00,756] DEBUG    FileServer Conn#22 24.8.187.119 [v2] > Unpacker deleted
[2015-10-23 20:07:00,890] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-10-23 20:07:00,890] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-10-23 20:07:00,891] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-10-23 20:07:00,891] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-10-23 20:07:20,987] DEBUG    FileServer Conn#24 70.37.165.32 [?] > Incoming connection...
[2015-10-23 20:07:20,989] DEBUG    FileServer Conn#24 70.37.165.32 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2015-10-23 20:07:21,540] DEBUG    FileServer FileRequest: Conn#24 70.37.165.32 [v2] pex 1DniZHDZPWiCPC2JL6dURYm6dk9fWZeDbc None
[2015-10-23 20:07:21,716] DEBUG    FileServer Removing Conn#24 70.37.165.32 [v2]...
[2015-10-23 20:07:30,914] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-10-23 20:07:30,914] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-10-23 20:07:30,914] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-10-23 20:07:30,914] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-10-23 20:07:31,375] DEBUG    FileServer Conn#25 70.37.165.32 [?] > Incoming connection...
[2015-10-23 20:07:31,377] DEBUG    FileServer Conn#25 70.37.165.32 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2015-10-23 20:07:31,948] DEBUG    FileServer FileRequest: Conn#25 70.37.165.32 [v2] getFile 1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/sortable.js
[2015-10-23 20:07:32,197] DEBUG    FileServer FileRequest: Conn#25 70.37.165.32 [v2] getFile 1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/sortable.js
[2015-10-23 20:07:32,375] DEBUG    FileServer Removing Conn#25 70.37.165.32 [v2]...
[2015-10-23 20:07:33,309] DEBUG    FileServer Conn#26 70.37.165.32 [?] > Incoming connection...
[2015-10-23 20:07:33,311] DEBUG    FileServer Conn#26 70.37.165.32 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2015-10-23 20:07:33,482] DEBUG    FileServer Conn#26 70.37.165.32 [v2] > Crypt connection error: [SSL: UNKNOWN_PROTOCOL] unknown protocol (_ssl.c:581), adding peerid -ZN0032-bCxQyCgi630n as broken ssl.
[2015-10-23 20:07:33,483] DEBUG    FileServer Conn#26 70.37.165.32 [v2] > Socket error: TypeError: argument of type 'int' is not iterable in Connection.py line 133
[2015-10-23 20:07:33,483] DEBUG    FileServer Removing Conn#26 70.37.165.32 [v2]...
[2015-10-23 20:07:34,832] DEBUG    FileServer Connection flood detected from 70.37.165.32
[2015-10-23 20:07:44,881] DEBUG    FileServer FileRequest: Conn#15 76.11.82.156 [v2] pex 16rELcbeZ7GY7X8teezU2EVSdpQpc7WPjF None
[2015-10-23 20:08:00,936] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-10-23 20:08:00,937] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-10-23 20:08:00,937] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-10-23 20:08:00,937] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-10-23 20:08:06,325] DEBUG    FileServer Conn#27 70.37.165.32 [?] > Incoming connection...
[2015-10-23 20:08:06,325] DEBUG    FileServer Conn#27 70.37.165.32 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2015-10-23 20:08:07,108] DEBUG    FileServer FileRequest: Conn#27 70.37.165.32 [v2] getFile 1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/jquery-1.js
[2015-10-23 20:08:07,361] DEBUG    FileServer Removing Conn#27 70.37.165.32 [v2]...
[2015-10-23 20:08:08,555] DEBUG    FileServer Conn#28 70.37.165.32 [?] > Incoming connection...
[2015-10-23 20:08:08,555] DEBUG    FileServer Conn#28 70.37.165.32 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2015-10-23 20:08:09,390] DEBUG    FileServer Conn#28 70.37.165.32 [v2] > Socket error: SSLError: [SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1750) in Connection.py line 117 > ssl.py line 208 > ssl.py line 110
[2015-10-23 20:08:09,391] DEBUG    FileServer Removing Conn#28 70.37.165.32 [v2]...
[2015-10-23 20:08:10,937] DEBUG    FileServer Conn#29 70.37.165.32 [?] > Incoming connection...
[2015-10-23 20:08:10,940] DEBUG    FileServer Conn#29 70.37.165.32 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2015-10-23 20:08:11,842] DEBUG    FileServer FileRequest: Conn#29 70.37.165.32 [v2] getFile 1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/sortable-theme-bootstrap.css
[2015-10-23 20:08:12,131] DEBUG    FileServer Removing Conn#29 70.37.165.32 [v2]...
[2015-10-23 20:08:13,197] DEBUG    FileServer Connection flood detected from 70.37.165.32
[2015-10-23 20:08:30,944] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-10-23 20:08:30,946] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-10-23 20:08:30,946] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-10-23 20:08:30,947] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-10-23 20:08:44,795] DEBUG    FileServer Connection flood detected from 70.37.165.32
[2015-10-23 20:09:00,759] DEBUG    FileServer Conn#15 76.11.82.156 [v2] > Unpacker deleted
[2015-10-23 20:09:00,999] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-10-23 20:09:01,000] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-10-23 20:09:01,000] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-10-23 20:09:01,000] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-10-23 20:09:01,105] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 20:09:01] "GET /ZeroNetwork.bit/img/loading.gif HTTP/1.1" 200 955 0.001000
[2015-10-23 20:09:02,556] DEBUG    FileServer Conn#30 70.37.165.32 [?] > Incoming connection...
[2015-10-23 20:09:02,562] DEBUG    FileServer Conn#30 70.37.165.32 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2015-10-23 20:09:03,134] DEBUG    FileServer FileRequest: Conn#30 70.37.165.32 [v2] getFile 1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/Puppy-Linux.png
[2015-10-23 20:09:03,309] DEBUG    FileServer FileRequest: Conn#30 70.37.165.32 [v2] getFile 1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/Etherpad.png
[2015-10-23 20:09:03,311] DEBUG    FileServer FileRequest: Conn#30 70.37.165.32 [v2] getFile 14kr6qSTxrHAcNEhZQ6RWZyovnyhzXT2Ag data/users/192hRA5yaBgUV5eAbmn5DwJ48v1SVxLrA5/data.json
[2015-10-23 20:09:03,312] DEBUG    FileServer Removing Conn#30 70.37.165.32 [v2]...
[2015-10-23 20:09:04,483] DEBUG    FileServer Conn#31 70.37.165.32 [?] > Incoming connection...
[2015-10-23 20:09:04,486] DEBUG    FileServer Conn#31 70.37.165.32 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2015-10-23 20:09:05,049] DEBUG    FileServer FileRequest: Conn#31 70.37.165.32 [v2] getFile 1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/KNOPPIX.png
[2015-10-23 20:09:05,234] DEBUG    FileServer Removing Conn#31 70.37.165.32 [v2]...
[2015-10-23 20:09:05,484] DEBUG    FileServer Conn#32 70.37.165.32 [?] > Incoming connection...
[2015-10-23 20:09:05,486] DEBUG    FileServer Conn#32 70.37.165.32 [v2] > Crypt in connection using: tls-rsa (server side: True)...
[2015-10-23 20:09:06,236] DEBUG    FileServer FileRequest: Conn#32 70.37.165.32 [v2] getFile 1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/Mullvad.gif
[2015-10-23 20:09:06,408] DEBUG    FileServer FileRequest: Conn#32 70.37.165.32 [v2] getFile 1DWTx5S9sJi9Z4Pi6apfQxSzqSwfo4qTJd privacy tools - encryption against global mass surveillance Ã°Å¸â€â€™_files/KNOPPIX.png
[2015-10-23 20:09:06,413] DEBUG    FileServer Removing Conn#32 70.37.165.32 [v2]...
```
 With chrome it won't reconnect either... And it is more buggy than ever...
 Last commit b961a3fb0a6ec764312e1bdd886cfd944ca9489d helped because I experience that issue lesser than before. But it didn't solved it.
 @HelloZeroNet How do you enable logging in geventwebsocket?
This bug is the only thing that really bothers me.
 @HelloZeroNet Thanks, but I tried with chrome and it won't try to reconnect ever... So there aren't any websocket frames.
 @HelloZeroNet YESSSSSSSSSSS!! I have fixed the problem, apparently it was my Anti-virus, which when desactivated didn't disable Some Web protections... -_-

Update: I will wait and if I don't encounter this bug again I will close this issue
 ESET-NOD32 Antivirus, but it was strange because on other pc than mine they were having the same antivirus as mine but they didn't have any problem... -_- My computer is weird...
   @HelloZeroNet Is there a reason you don't merge this, or you didn't seen it?
 If you start zeronet.py with `..\Python\python.exe zeronet.py` and you check the option to start with Windows, then you exit and you start ZeroNet by double clicking on `zeronet.cmd` and the option isn't checked
 It's because the current code only replaces `start.py`, `"--open_browser"`, `"default_browser"` but two spaces are left at the end of the last line, one before `"--open_browser"` and one before `"default_browser"`
 Thanks
   @HelloZeroNet You should write that somewhere in the documentation for site developers
  (I have used the AUR package, but that shouldn't change anything)

Hey. So I wanted to try out zeronet, but after installing it I found out that there's `#!/usr/bin/env python` at the start of the scripts, which default to Python 3 on Arch Linux, resulting in a while bunch of error. Any idea how to fix it without `sed`ing?

Thanks.
 ```
$ python2 /usr/bin/zeronet.py
- Starting ZeroNet...
Traceback (most recent call last):
  File "/usr/bin/zeronet.py", line 14, in main
    import main
ImportError: No module named main
Traceback (most recent call last):
  File "/usr/bin/zeronet.py", line 54, in <module>
    main()
  File "/usr/bin/zeronet.py", line 40, in main
    traceback.print_exc(file=open("log/error.log", "a"))
IOError: [Errno 2] No such file or directory: 'log/error.log'
```
 Hm, works great, thanks. Looks like the package is faulty.
  Quantum computer can break BitCoin cryptography
http://pqcrypto.org/
 Yes, there will always be unsolvable mathematics equations on which the cryptography is based on.
 There are post-quantum crypto implementations, but as far as I know they're somewhat experimental and not yet shipped by default within Openssl/Libressl. I'd estimate that a government with a large budget could possibly build a quantum cryptanalysis machine for prime factoring small key lengths within a decade.
 I don't think it's a zeronet specific issue and I don't thing it's even a real issue yet.
When Openssl will be declared unsecure anymore, It will be a good time to address the problem.   
Closing ?    JavaScript buttons lead to an error in ZeroNet.
 Are you using Tor?
 I don't think Tor would change much about the JavaScript, and HelloZeroNet, I was referring to creating a blog, when you've duplicated one of the defaults and clicking the edit button. In the box, you can the type up a simple HTML webpage, and this is when the JavaScript causes problems. When I made a function to create a simple alert, the blog displayed an error and locked me out. I was then not able to edit the box that I was originally editing, but the title and the description were all editable.
 My user agent string is: Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36 and for more information you can visit http://whatsmybrowser.org/b/CGNSQEI
 Is anyone having the same problem? Can it be closed?
 I can't reproduce and OP did not provide any ProofOfConcept 
Closing ?   This feature have been implemented. 
Closing ?   Jus an usage idea.

Today lot of sites are closing comments, and moderation exclude lot of them. It will became more and more difficult to post a critical point of view.
I think we need to allow everybody to comment everywhere on the web, without moderation, with or without anonymity to criticize (even a sponsered product) and express opinions, on a decentralized base.

The idea is something like Disqus, but based on zeronet.
A browser plugin open a right column on the webpage we want to comment and create a zeronet article asociated with the visited url.
Then everyone with the plugin can see this column with comments and comment too or vote for best comments.
 Yes, I did not use the good example with Disqus... the goal is not to centralize, but to get a zeronet comments associated with each website.

Manual website.com (an existing site with closed comments) example:
- I create a zeronet site corresponding to website.com, based on zerotalk, named zerotalk-website.com
- The url website.com/page1 as closed comments. I create a new discussion in zerotalk corresponding to this url.
- Then people can comment for each url, using the zerotalk-website.com site.

A browser plugin could automate the site and discussion creations on visiting the url (if not already done). Then it add a right column into the browser and fetch data from other users to show comments by loading the corresponding discussion. Finally the user could add a new comment.
Decentralized P2P based commenting for everyone system is born. Just an idea, may be not a good one.
 @risoul  : Sort of a decentralized "commentanything.com" upon zeronet ?
 Yes exactly! I did not know commentanything. The same based on zeronet = no moderation at all, no centralization, no third party service.
 Could it be achieved with merger feature ?
Im not sure what need to be done here with this issue.   I think I nice feature would be to have on the home-screen `ZeroHello` two buttons at the top of the screen that can 1. restart the client and 2. shutdown the client.
 But what if you are running your own private proxy and need to restart the ZeroNet client? I think this would be a great function.

Sent from my iPod

> On Sep 25, 2015, at 6:57 PM, ZeroNet notifications@github.com wrote:
> 
> You can use the taskbar icon to shutdown: right click > exit
> 
> â€”
> Reply to this email directly or view it on GitHub.
 If you were running it as a private proxy surely you would want it to run
24x7 anyway?

On Fri, Sep 25, 2015 at 6:15 PM, Tristan B. Kildaire <
notifications@github.com> wrote:

> But what if you are running your own private proxy and need to restart the
> ZeroNet client? I think this would be a great function.
> 
> Sent from my iPod
> 
> > On Sep 25, 2015, at 6:57 PM, ZeroNet notifications@github.com wrote:
> > 
> > You can use the taskbar icon to shutdown: right click > exit
> > 
> > â€”
> > Reply to this email directly or view it on GitHub.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/issues/178#issuecomment-143291448
> .
 I might be running low on bandwidth on my port forwarded router, hence I do not want it to always be running.

Sent from my iPod

> On Sep 26, 2015, at 2:32 PM, Idealcoder notifications@github.com wrote:
> 
> If you were running it as a private proxy surely you would want it to run
> 24x7 anyway?
> 
> On Fri, Sep 25, 2015 at 6:15 PM, Tristan B. Kildaire <
> notifications@github.com> wrote:
> 
> > But what if you are running your own private proxy and need to restart the
> > ZeroNet client? I think this would be a great function.
> > 
> > Sent from my iPod
> > 
> > > On Sep 25, 2015, at 6:57 PM, ZeroNet notifications@github.com wrote:
> > > 
> > > You can use the taskbar icon to shutdown: right click > exit
> > > 
> > > â€”
> > > Reply to this email directly or view it on GitHub.
> > 
> > â€”
> > Reply to this email directly or view it on GitHub
> > https://github.com/HelloZeroNet/ZeroNet/issues/178#issuecomment-143291448
> > .
> > 
> > â€”
> > Reply to this email directly or view it on GitHub.
  Second one.
 They all look great but the center top is my favorite.

On Fri, Sep 25, 2015, 7:33 AM Bob Mottram notifications@github.com wrote:

> Second one.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/issues/177#issuecomment-143239488
> .
 The 2nd one is beautiful !
 I like the second one. My only question would be how good it looks as a
small 16x16 icon ( for taskbar icon etc. ) as I'm not sure if the shadows
and gradients would work at that size

On Fri, Sep 25, 2015 at 8:00 PM, à¹–Û£ÛœSkyzohKey notifications@github.com
wrote:

> The 2nd one is beautiful !
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/issues/177#issuecomment-143323130
> .
 2nd one master race!
 I still like the second one without rotation the best.
 same as my up neighbors ;)
 Second and fourth
 2nd with rotation is the best! z and 0 at the same time. without rotation looks like an inverted S.
ps: amazing how you manage to be a capable designer and developer at the
same time!

On 28 September 2015 at 10:18, Wisketchy Dobrov notifications@github.com
wrote:

> Second and fourth
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/issues/177#issuecomment-143687633
> .
 2nd without rotation
 first one
 We probably should close this :)
  On this page here: http://zeronet.readthedocs.org/en/latest/help_zeronet/network_protocol/

The description for the `ping` function says `Pong` rather than `Ping`. `i` is very near to the `o` on the keyboard, so this is a typo.
 Oh I think I see. `Ping Pong`. ~ Very poetic. I should read the focus fully before making an error report.
    Import only what you need, not all the other data.
 There is that point too, I was thinking about that.
 Thanks though. :smile_cat: 
  1. Create a forum topic
2. Click on the topic to view it
3. Delete the topic whilst you are viewing the full topic
4. It will still exist on the system.

For example: http://talk.zeronetwork.bit/?Topic:21_1JdoX9KdJeRVjN9zvK8N9C5jybEHzZe8n/f
 Does this bug still exist?
 Okay cool. Another issue closed :)

On 2016-09-26 11:25 AM, ZeroNet wrote:

> Closed #173 https://github.com/HelloZeroNet/ZeroNet/issues/173.
> 
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub 
> https://github.com/HelloZeroNet/ZeroNet/issues/173#event-801994825, 
> or mute the thread 
> https://github.com/notifications/unsubscribe-auth/AE92vPT5GwTaOAJhDphn_rgtMT09u0c-ks5qt49xgaJpZM4GDAN9.
  Updated Debian Linux commands with Syntax Highlighting
 [![Code Health](https://landscape.io/badge/236641/landscape.svg?style=flat)](https://landscape.io/diff/223979)
Repository health increased by 0.05% when pulling **[5efe1b8](https://github.com/Walkman100/ZeroNet/commit/5efe1b80510004f58f4a2b59d9ed0d639a2eef81) on Walkman100:master** into **[891c5cc](https://github.com/HelloZeroNet/ZeroNet/commit/891c5cc34ad922967c81cfca67403e994614233b) on HelloZeroNet:master**.
- No new problems were introduced.
- [2 problems were fixed](https://landscape.io/diff/223979/fixed) (including 0 errors and 2 code smells).
 bump
 I thought it was easier to read as a code block without the white in-between
 @HelloZeroNet
Yeah, me too ^^
  The sentence in the pruple banner `This site currently served by 70 peers without any central server.` is grammatically incorrect and should be `This site is currently served by 70 peers without any central server.` **is** was needed.

Also I think this (for some reason) appelas to me to phrase it like this: `This site is currently being served by 70 peers without any central server.`
 I'm no ultimate grammar guru, but I believe the original is correct grammar.
 It just doesn't sound right to me. Maybe it is just me but really sounds weird when you say it out loud.
 This sentence `This site currently served by 70 peers without any central server.` sounds better when it is part of a bigger picture.

`This site, currently served by 70 peers without any central server. (adjectival phrase), is a very popular site.`
 Okay. :smile: Thanks for putting in the effort.
 As a standalone sentence it is not fully correct, but often headlines and short descriptions tend to leave out those words. This structure is correct when it is a side-remark in the sentence, e.g. "Churches currently served by a program tend to have a closer community than regular churches." In that case, the expected 'that are' can be left out.
 Okay, so it takes out tedious words then. Okay. :smile:
  If you wanted you could make a post on the forum module with a title consiting of a space and a body content consisting of a space. This should not be allowed.
 @HelloZeroNet pleasure :+1: 
  Ability to change the port the web server runs on and the IP address it runs on
 @HelloZeroNet Okay. Thanks. :)
  https://www.reddit.com/r/zeronet/comments/3l6b5n/concept_smartphone_app_for_mesh_network_zeronet/?sort=confidence

It is a brilliant idea, actually. Like FireChat but better.
 :+1:
 Could be a privacy concern as downloading a website offline would imply someone near you has visited it. Also,  on mobile data don't upload other people's updates.
 > near you has visited it

Yeah, what if it is not a small group of people, but a crowd?

> Also, on mobile data don't upload other people's updates

What makes you think so?
 Since most mobile data bundles are limited, uploading other people's content when you have a network available again could cause unexpectedly high data usage.
 First step: no more centralised server
Second step: no need for physical network
Great!
May be a collaboration with Serval project? http://developer.servalproject.org/dokuwiki/doku.php
or span? https://github.com/monk-dot/SPAN (https://play.google.com/store/apps/details?id=org.span&feature=search_result#?t=W251bGwsMSwyLDEsIm9yZy5zcGFuIl0.)
or commotion? 
  ðŸ‘ +1 from me. That's a great idea.
 This idea is brilliant, and should be further discussed. Tried to revive the topic on this [Reddit post](https://www.reddit.com/r/zeronet/comments/4cyw3g/holy_grail_of_offline_apps_zeronet_mesh_app/).
 what is the drawback in this app?
  I'm doing a search of open source projects with [Bandit](https://github.com/openstack/bandit) and came across a potential vulnerability with using `shell=True`.

Here's the scan results:

```
>> Issue: subprocess call with shell=True identified, security issue.
   Severity: High   Confidence: High
   Location: src/Crypt/CryptConnection.py:70
65
66          proc = subprocess.Popen(
67              "%s req -x509 -newkey rsa:2048 -sha256 -batch -keyout %s/key-rsa.pem -out %s/cert-rsa.pem -nodes -config %s" % (
68                  self.openssl_bin, config.data_dir, config.data_dir, self.openssl_env["OPENSSL_CONF"]
69              ),
70              shell=True, stderr=subprocess.STDOUT, stdout=subprocess.PIPE, env=self.openssl_env
71          )

>> Issue: subprocess call with shell=True identified, security issue.
   Severity: High   Confidence: High
   Location: src/Crypt/CryptConnection.py:90
87          # Create ECC privatekey
88          proc = subprocess.Popen(
89              "%s ecparam -name prime256v1 -genkey -out %s/key-ecc.pem" % (self.openssl_bin, config.data_dir),
90              shell=True, stderr=subprocess.STDOUT, stdout=subprocess.PIPE, env=self.openssl_env
91          )

>> Issue: subprocess call with shell=True identified, security issue.
   Severity: High   Confidence: High
   Location: src/Crypt/CryptConnection.py:100
96          # Create ECC cert
97          proc = subprocess.Popen(
98              "%s req -new -key %s/key-ecc.pem -x509 -nodes -out %s/cert-ecc.pem -config %s" % (
99                  self.openssl_bin, config.data_dir, config.data_dir, self.openssl_env["OPENSSL_CONF"]),
100             shell=True, stderr=subprocess.STDOUT, stdout=subprocess.PIPE, env=self.openssl_env
101         )
```

It looks like the values for openssl_bin and openssl_env will be controlled. config.data_dir, however, could be set to anything and, as far as I know, we're not checking if it is a directory at all. The output could be crafted by a malicious user in a way that would be harmful. It may be advisable to sanitize the input by escaping it or including a mention in the docs. Here's the [Python docs on subprocess](https://docs.python.org/2/library/subprocess.html#using-the-subprocess-module) as well as a [blog post](http://kevinlondon.com/2015/07/26/dangerous-python-functions.html) I wrote about some of the dangers. 

Thanks!
  I know it may sounds strange and premature, but probably it will be really nice to create and handle a website (and the signature) using a Trezor device. The official Python API are already released and it will enhance the security behind ZeroNet.

https://github.com/trezor/python-trezor

Does it sounds crazy?
 I would like to help with this integration, but I don't know if a plugin would help, since the signature process is inside src, and the device could offer more than just a signature: I have to check how ZeroID is working, but that would be amazing idea.
  Good too see that this is planned. Exactly what my site needs.
  I'm building an imageboard engine and it needs exactly that feature for it to be viable at all. 

The "sponsor" solution for initial distribution problem looks like a good one to me. I would like to add that it would be great to be able to not just participate as a "sponsor", but do even more work (optionally).

Example: I have a dedicated server which hosts some of my clearnet websites, and also runs some copies of ZeroNet sites of my selection. It is a powerful server and it's constantly online, however it still works as any other "regular" peer.  When new updates come in, it still transfers them just to some of close peers (5 or something like that). 

But what if I want this server to do more work? If it's a powerful machine dedicated to serving sites, I want to be able to make it more active in the net. I guess it would be good to have something like peer hierarchy so that I would mark my server as "power peer" and it would process more updates and other peers would prefer requesting that server over other "regular" peers and lower the amount of work they'd have to do. 

If this concept of peer hierarchy doesn't violate your vision of ZeroNet p2p architecture, perhaps I should submit this idea as a separate issue?
 I don't think there should be a peer hierarchy, and whether or not someone has a powerful machine should be irrelevant.
 Yes. This is awesome, this would be a great feature.
 @bashrc I agree. The network must remain neutral.
 "peer hierarchy" sounds like an oxymoron :)
 Lol yes @pecc0
 > holds the downloaded files hashes first 4 character (only first 4 for economy reasons)

With 4 hex characters the probabilities for collision are as follows:

| Number of files | Probability of collision |
| --- | --- |
| 10 | 0.068% |
| 100 | 7.278% |
| 1000 | 99.953% |
| 10000 | 100.00% |

Considering that a site like imgur gets about 1,500,000 images uploaded daily, the hash length should be longer than 4. Here's a graph for hash collision probability based on hash length (hex format assumed).

![has collision prob](https://cloud.githubusercontent.com/assets/785247/13554147/0adbf168-e3a9-11e5-9972-afb1a7ce42ab.png)

Alternatively, the hash length should increase somehow with the number of total files uploaded. This may require updating the previous existing hashes.
 Use a non-colliding hash algo.
 by "yet" d you mean researchers have not found an example of it collidingg?
 Okay. :)
 > Creating multiple sites (eg one per user) instead of increasing the hashtable length is more scalable solution.

Agreed.

> Also a collision is not a big problem, it's just increase the network communication: the find peer by hash returning some peers that doesn't has the file you looking for.

It would be a problem for big sites. A site with a million files using a 4-character hex hash would have to find the user with the file from 27 users, that's a lot of overhead.

I think one downside of per-follower storage (where content created by user A is only stored by the users that have accessed it) will be very prone to missing content.

A better approach might be that every user accessing a site with per-follower content, implicitly accepts to store content for ~5-10 random users (within a size limit). In exchange his own content should he make any will be stored by other users as well. This will be transient storage, and can be deleted by the system at any time to make room for newer / more popular content.

This way when someone has just posted an comment/image/video online, his content is duplicated instantly to others without waiting for them to access the content first. If he goes offline immediately after posting, his content will still persist online, at least for some time.
 I see a few problems with the current approach.

First is a lack of immediate persistence for users that are new or without followers: right now if such a user is say on the beach, and wants to share an image of themselves and their friends then immediately shut down the laptop, it will be as if it was never uploaded. No one will be able to see it.

Another is the "many users' content on one page" problem. Every site has a front page where they display new or trending content. What this means is that every visitor to the front page will automatically become a "follower" of all the users of whatever is displayed on the front page at the time, otherwise they can't see it right? It would be awkward to ask permission for every user whose content is on the front page. And if for example the users visits an image page with hundreds of comments, does he suddenly become a follower of hundreds of users, and hundreds more for every page he visits?

For video websites it's even worse, as accessing one user's video leads to potentially hundreds of large videos becoming shared. Imagine browsing YouTube and ending up copying every other video of the user whose video you just saw.

Finally it severely limits how big sites can get, and thus how many serious developers will choose the platform.

## Proposal: User Roles

Rather than limiting how big sites can get, what about creating user roles?

For example there could be a `storage` role where the users who choose to assume the role can store (but not modify) files, a `moderator` role where they can modify other users' files, a `processing` role where processing tasks, crons can be run, etc.

For some roles only the site admin can grant it (like `moderator` or `processor`), for others everyone can choose it (like `storage`). For `storage` the user can choose a storage limit (like Freenet does), and for `processor` a processing power limit (like Folding@Home does). Here I discuss the `storage` role.

Say there is a site called ImgurZero with a million images (each about 1MB, totaling 1TB). Being a big site, it will have gathered a few hundred volunteer `storage` roles by now. The storage distribution method is completely up to the site developer. I'm sure libraries will spring up for all kinds of distributed storage methods. New files will be stored on the creator's host, but now the site can instantly duplicate it on hosts with `storage` roles.

The way the files are duplicated is completely up to the developer - it can be simply storing the file as is, it can be stored partially so big files are shared, it can even be stored encrypted if the file is private. If a site wants a list of all of a user's files or to read a particular file, the user doesn't have to be online, the few `storage` roles can be contacted instead by whatever rules the developer wants. Again, it's all up to the developer, all ZeroNet has to do is provide commands to read/write to these storage locations (and optionally a few hints like which ones happen to already be connected, latency, past transfer speed, total storage, free storage, etc).

From the user's point of view, he would be visiting a site where there could be a "Donate" button where he can donate some storage space and/or processing power to the site, and he gets to choose how much. Since content can be targeted at a particular user (instead of only all users at is it now), it may be useful to have an encryption option. The site could even prompt the user for such contributions, like Wikipedia does for money. It could look similar to requesting authentication right now.
  Please provide a http proxy so that I can change my browser to use that one to access zeronet sites.
I may not want them all to be localhost links because of security issues with that
 +1 
 Yes, but let me take an exemple : 
I have a very bad internet connection, but my linux server has a good one. I install Zeronet and my server with a proxy so _I_ can access it without overloading my upload
 Awesome :D 
 You misunderstood me.
I don't want a central server.
I want zeronet to be accessible on my computer, but in my browser I want to enter zeronet addresses, not local host, like when I use tor to surf the www, zn listening on a port and my browser proxying through that port on localhost
 So ZN already has that feature?
I could set 127.0.0.1:43110 as the proxy in my browser and then I can 
directly navegate to http://zeronetwork.bit/ ?
I'll try when I get home...

( the addon only is for chrome chrome and only if I install the 
extension, so I want a solution without addon/extension )
  When we want to stop a seed and delete the node, the confirmation button appears at the top right. Not fast when deleting lot of nodes.

Solutions?
- allow to press enter to confirm deletion
- put delete confirmation button near the node
  I run:

gekko-master leotreasure$ pip install gevent msgpack-python

and this happens:
http://pastebin.com/HCWF3phq
 Thanks that worked!!
  Take a look at http://zeronet.classcoder.com/1CVj75bq24SzjQZfMpDAgHAHGjMUNFukYU/index.html and press the link for "About ZeroNet:" it won't go anywhere! Now, take the direct link (http://zeronet.classcoder.com/1CVj75bq24SzjQZfMpDAgHAHGjMUNFukYU/about-zeronet.pdf) and it works! It seems links don't work like we're used to...
  Usually the security model of most site is heavily relying on browser same origin policy protection mechanism. It seems that from the viewpoint of the browser every site is served locally. What mechanism do you have to prevent XSS vulnerabilities ?
 I believe this is not good enough. 
Sandboxed iframe can be escaped from when you allow top-navigation with simple frame busting. (We can there try to attack the local webserver to compromise the host if there are security holes in the webserver but this is not the point I want to make here).

As same origin policy is not guaranteed because everything is served locally, the only remaining protection is the "referer" filtering when wrapper=False. But if you create a popup window to another zeronet site (without wrapper=False), the referer is not checked and from the viewpoint of the browser it is from the same origin so you can freely inject and access html code of this new window. The "referer" of this new page is the new site, so we can use this popup window as a trampoline to send request to the wrapper=False page to get the inner Frame). 
Which means it can steal anything the user could type on another zeronet site. Exfiltrating the infos can then easily be done by a get image request to an evil server.

Below is a working proof of concept. Correct the missing "<>" and serve the file using zeronet. It works (not always on the first try but then always) on firefox and chrome when popups are not blocked. It should display the html code of another site. (But we could also reinject our own code in the other site)

html
head
/head
body
div id="myDiv">mydiv
/div

SCRIPT language="javascript"
//frame busting
if(top != self) top.location.replace(location);
var novoForm = window.open("/1AvF5TpcaamRNtqvN1cnDEWzNmUtD47Npg/index.html", "wFormx", "width=1 height=1");
var id = setTimeout(  function(){document.getElementById("myDiv").textContent=novoForm.document.documentElement.outerHTML;novoForm.close()}, 1000);
/SCRIPT
/body
/html
 Your idea of adding one-time keys might work but one time-keys and "nonces" don't usually work well with browsers (they are not user friendly because of history navigation, reload, caching behaviors,inner iframes, ajax? ). It also introduces complex filtering code server side which should ideally be as small as possible to prevent critical vulnerabilities.
It would also be hard to prevent JavaScript to obtain some one-time keys because you can't really tell for sure whether it is some JavaScript script or the user interacting with you (the "referer" filtering hack is just a hack that is subject to future browser change, normally it shouldn't be relied upon (The referer rfc spec isn't properly defined, (the reasoning behind is because this is set from client side so it could be anything so we can't rely on it for security purposes so we don't care about precise browser spec as it isn't a security feature) ).  

I don't believe there are clean fixes without profound changes but I'm not a web expert. Sure you can find workarounds but relying on browser quirks (subdomain on localhost??(which may work with SOP) ). It's basically doing security with javascript in the browser. 
Serving from localhost is also a bad idea because it opens security flaws because the local host network interface is kind of special. So it may be listened to by other processes running on the machine.

Current browsers are not made for a decentralized web, and rfc are not going this way. Serving everything from local means the user preference like allow popups, always allow **\* for 127.0.0.1, (always allow access to camera and mic ? and other nasty html5 features) propagate between zeronet sites. The attack surface, once you open javascript, anonymity (no dns central authority to blacklist sites), local server (with eventual open ports) is huge. Combine this with a bad updating procedure (no autoupdate or served centrally) in case of bugs and this is a recipe for disaster. (What about key revocation GPG style?)

The main reason people use "browsers", is to not have to trust any website, but only have to trust their browser to keep them safe. People already need to trust you (or use sandboxes which btw you should recommend your users to use) to run your server locally so they could instead trust you for running a custom browser (which will give you more control not depending on browser interaction hell). 

The clean solution, I fear but I may be wrong, is to implement your custom browser (the same choice Tor made), (or forbid JavaScript but this is ZeroNet main feature). This is not as hard as it seems to be, because you can leverage on many open source browsers, but it is hard nevertheless specially when you allow JavaScript. 
 Run local custom DNS server

Personally I don't think a custom browser is a good solution, as it requires limiting users to specific custom browser, and adds a huge amount of overhead having to maintain. 

A solution would be to run a custom DNS server locally. It would resolve normal domains by forwarding the request on, but for .bit, e.g. idealcoder.bit ( or some other TLD) with 127.0.0.1. ZeroNet could then read the virtual host to find out the domain requested and send relevant sites files. 

The advantage with this is that the web browser would see each site as a separate domain, and so would leverage all the existing security features in browser. 

The disadvantage is that the DNS settings will need to be changed. However, I sure an automated script could be written to automatically change the DNS settings.

The other option would be an HTTP Proxy, but that adds a lot of processing overhead and complexity. 
What do you think about a custom DNS server?
 I personally feel that the custom DNS server (although would work) is a bad solution. It is not user friendly at all and if there is a hiccup you got yourself with an angry user without internet to get help from.
It messes up with the whole system of the user and thus require the user to sudo your custom dns server. 

Proxying is also hard to configure for the user (browser dependent -> no automated scripts) and persist after browser closing which means at next reboot when the custom http proxy is not running one user out of two won't be able to reset the proxy configuration to connect back online. 

So what usually happens is that quickly, some random internet hacker surf your hype and tell the users they can avoid the configuration issues by connecting through his "custom proxy", and one user out of two get MIMed.

Implementing a custom DNS server is hard. Configuring it is nightmarish (because you may need to open and configure the dns ports on your routers) (forwarding the request on is not as easy because once you change your dns settings to a custom one(yours) you can't do dns requests the normal way, so you must implement full DNS protocol). 

It kinds of defeat the point of building a decentralized internet if you got back to relying on the authoritative DNS servers.

DNS itself presents lots of vulnerabilities and that's why there should be DNSSEC but it didn't really catch.

This will also be instantly categorized as 'virus' by any windows antivirus.

It opens a whole range of other attacks with even worse consequences. Bad cases scenario may result in transparent MIM of any website (and not only zeronet websites).

Didn't I mention that when you start messing with DNS protocol, ISP really don't like it at all and are very prompt to blacklist you. (Personal anecdote here : I once wrote a web crawler so I had configured my own bind9 cache for host names and everything worked fine until I downloaded an unrelated github project which silently messed up my configuration (it resetted my DNS to default instead of my bind9 server) The next time I crawled, my ISP suspended me for a day ;) .)

We also have an unusual behavior here  for example : When you got a request for an non-existing ".bit" address the customdns can't say anything regarding whether the domain is valid or not (where as normally it should) (only your zeronet local server has this info), so it must tell you this domain is valid (in fact it may not be) and route you to localhost. (An attacker could for example try to use up your ram by filling up the customdns tables with random invalid .bit names which would then be cached because they are in fact valid (then your customdns process crash and you got yourself with an angry user without internet)).
 Glad there is an update mechanism. Those are usually tricky to do correctly and usually are a security risk. I may give it a look if when I have some time to spare.

I quickly look at it but the quick fix looks like security done client side in javascript (and as a malicious js script we are the client). 
Wouldn't (I didn't try) it be totally bypassed by:

var myWindow = window.open(thetargetWebsiteAddressToObtainCorrectReferrer, "MsgWindow", "width=200, height=100");
//actually we don't care about anything the server send us back just that we can trick the browser to send the correct referrer 
myWindow.document.write("you write any script here to trampoline with a correct referrer so we can grap the wrapper=False document");
//If this doesn't work we can try to access the html before the scripts in it gets executed with a tight setInterval loop we may (depending on browser) get lucky.

It also doesn't solve the user preference by domain that propagate for all zeronet sites (always do **\* for 127.0.0.1:xxx (see previous message) ) problem.

By twiddling you may succeed in having a secure solution but it's going to be hard to convince this is really solid (the same kind of difference there are between white list and black list security). There is a sword of Damocles that hangs over this issue, and it's not a comfortable position to be in.
 I haven't tested the below idea but I still think the fix doesn't do what it's intending to do : 
For example if we open a popup (for referer filtering bypassing) we then add in it a sandboxed iframe with the no-script attribute which loads your wrapper frame so it won't execute the script but load the wrapper DOM. Your safety client side javascript security measures (frame busting and opener check) don't get called (so no document.write) and because we are on Same Origin, parent can access iframe content. 
You may also try with some popup.onload or popup.document.ready (jquery) to access the DOM of the wrapper before it's overwritten by the document.write.
I am quite confident creative minds could find other ways in.
 You are getting the spirit of it, and that's what matter :). 
Security is all about identifying simple principles with strong security guarantees, and build upon them.  "Security measures client side are not reliable" is one of these principles. 
"SOP" is one of these cornerstone principles in browsing security (that's why relaxing this assumption is hard).
"The user will do stupid things if he can" is another famous one.
"There is no such thing as a secure system" principle allows us to sleep at night.
 I haven't tried your nonce-based security. Those are quite tricky to get right. In part because it's all relying on some pseudo random number generator (see below), and also because it's hard to tell user from script apart so it will be hard to convince you secure all possible pathways in, and even if you manage to get it safe it will also be hard to be convince that a browser new feature won't later break your security. 

But a quick look at the source of your fix reveal that in it's current form it's weak. 
wrapper_nonce = ''.join(
            random.choice(string.ascii_uppercase + string.ascii_lowercase + string.digits) for _ in range(24)
        )

At least use some one-way hash function. Because here you are handling a sequence of 24 remainders generated by a weak (low entropy congruential?) rng. So your are basically handling (Chinese remainder theorem trick? or brute force) the state of the generator if we can get any nonce (even a past one). And with the state of the rng we can predict any future nonces. Random number generator attacks is a whole non-trivial area in computer security (how to seed them properly? how to prevent the state to leak?(->one-way crypto hash)).
 Please forgive some of my ignorance, as I am neither a professional programmer nor a security analyst:

Couldn't the client machine's HOSTS file serve the same purpose as a DNS in defining separate domains / subdomains for redirection to 127.0.0.1?

I don't know what issues might arise trying to continually rewrite a very large HOSTS file, but I have observed that exceedingly large lists can be employed without noticeable impact to page request times.

I don't know how many domain entries would potentially need to be made, nor how often that listing would need to be updated (hopefully not every time a new .bit domain is published?) but modifying the HOSTS file seems trivial compared to the potential pitfalls of establishing a functioning local DNS server.

The HOSTS file is generally ignored as a vestigial bit of legacy support, but I've yet to see any browser-equipped machine that didn't have one. HOSTS files used for domain blacklisting commonly run into several tens of thousands of entries without impeding the function of the browser even on very modest hardware.

1) Is editing the HOSTS file even feasible, or do the .bit domain listings need to be updated too often for that?

2) Would an up-to-date HOSTS file solve the issue of domain-specific permissions?
 About the random number generator you get the spirit. 
About modifying the HOST file, I wouldn't recommend it either mainly for the sudo requirements, and the fact that modifying the HOST file is a trick usually spywares and viruses like to do, so any decent antivirus (who uses those anyway?) should classify you as malware. I also don't know how often the HOST file is reloaded after modification. And there is also the issue you raise. 
Modifying domain (either with dns or HOST file) isn't also a solution because dns may be bypassed by directly specifying the ipaddress (127.0.0.1 (but then you have your 'referer filtering' which may save you)).

I haven't tested your nonce based implementation but normally usually it shouldn't be compatible with all navigation features (Like things with multiple open new-tabs, open in new window, navigation after a history.back move, and so on...)(as it has introduce a "state" into what's usually built upon the stateless http procotol) (And this will usually leave the user think, the software doesn't work, or worse he may think it's not safe). 
 Hmmm, I think having them all hosted under a single origin is asking for trouble.

The iframe-nonce-hack seems to work, but it seems to be setting it up for failure as it's going directly against the grain of the Web Browser's security mechanisms.
I think one of the safest methods would be to provide a SOCKS5 proxy, similar to the way Tor does it.

In regards to using case-sensitive addresses, perhaps encoding the address to a case-insensitive format would be Good Enough:tm:?

A simple method for encoding could be;

``` js
function encode(str) {
    return str.replace(/([A-Z])/g, function(c) {
        return '-' + c.toLowerCase();
    });
}

function decode(str) {
    return str.replace(/(-[A-Za-z])/g, function(match) {
        return match.substr(1).toUpperCase();
    });
}

encode('1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D');
// '1-he-l-lo4uzja-let-fx6-n-h3-p-mw-f-p3qb-rb-tf3-d'
```

This isn't very pretty, and it ruins the vanity addresses, but it's simple and doesn't require any base conversions, which would be costly with JavaScript's number implementation.

Hmm, if I find some time I'll try some pentesting on the iframe implementation to see if it's worth migrating or such.
 ``` js

function getUrl(url, callback) {
    var xhr = new XMLHttpRequest();
    xhr.onreadystatechange = function() {
        if (xhr.readyState == XMLHttpRequest.DONE) {
            callback(xhr);
        }
    };
    xhr.open('GET', url, true);
    xhr.send(null);
}

getUrl('http://127.0.0.1:43110/zeroid.bit', function(xhr) {

    //var url = xhr.responseText.match(/\\\/.+\\\?wrapper\\_nonce\\=[a-z0-9]+/)[0].replace(/\\/g, '');

    document.write('<iframe src=about:blank id=inner-iframe width=800 height=800></iframe>');
    eval(xhr.responseText.match(/<!-- Site info -->\n<script>([^<]+)<\/script>/)[1]);
    document.write('<script type="text/javascript" src="/uimedia/all.js?rev=915"></script>');

});
```

Pretty easy to get the wrapper nonce when you're on the same origin.
 What about using whole 127/8 ipv4 network and distinguish installed sites by ip address?
127.0.0.1 may be a special forwarder site to forward user to needed sub-ip while cleaning up all potentially malicious request arguments (which btw may be configurable by site security policies in content.json).
 First I am new to zeronet so I might be totally wrong. 

I did not find description of zeronet security model neither. Looks like a lot of security depend on the javascript modified according to this message https://github.com/HelloZeroNet/ZeroNet/issues/157#issuecomment-138733791 which should disallow the operation of a site in a popup or an iframe. But I have no idea of why it's necessary or if it do its job.

I am not really aware of the capabilities of sandboxing of an  iframe but it appears that the iframe permission are huge "allow-forms allow-scripts allow-top-navigation allow-popups allow-popups-to-escape-sandbox {sandbox_permissions}" I don't really understand how with such a huge whitelist, security can be enforced. I tried to search explanation of each permission and failed to have a clear view of the situation. Can you explain what each permission does (with reference to some official site) and how they don't break the security ?
 Well ZeroNet now won't load with Chrome Version 55.0.2853.0 dev (64-bit).

Home page:

```
Uncaught DOMException: Blocked a frame with origin "http://127.0.0.1:43110" from accessing a cross-origin frame.
    at processFunctions (<anonymous>:5:27)
    at HTMLIFrameElement.get [as contentWindow] (<anonymous>:241:6)
    at new Wrapper (http://127.0.0.1:43110/uimedia/all.js?rev=1518:778:59)
    at http://127.0.0.1:43110/uimedia/all.js?rev=1518:1380:20
    at http://127.0.0.1:43110/uimedia/all.js?rev=1518:1382:4
```
 For desktop users, I think the browser plugin is a good solution. It is very easy to setup and makes Javascript based attacks much more difficult, if I understand the threat correctly.

Currently the [chrome plugin](https://github.com/goldenratio/zeronet-protocol-crx) linked is unsupported, but hopefully someone can look after the project. [A fork of the plugin](https://github.com/mkody/zeronet-protocol-crx) handles redirecting `http://127.0.0.1:43110/site_name.bit/` sites to `http://site_name.bit`.  I would also like to see `http://127.0.0.1:43110/1Gif7PqWTzVWDQ42Mo7np3zXmGAo3DXc7h` redirected to something like `http://1Gif7PqWTzVWDQ42Mo7np3zXmGAo3DXc7h.zero/`.
 How about redirecting to an internally routable subnet of the ::1 localhost ipv6 address? Or create a NAT router and another bunch of ipv4 addresses to enable/strengthen COR protections? For example, in ipv4 you could say 127.0.0.2 and 127.0.0.3 and 127.0.0.4 could be "routed" to localhost? Create a VPN endpoint using websockets and announce a route via BGP? I dunno.  I actually think the local DNS proxy is best / easiest idea, next to my multi-homed localhost concept.    I'm running Linux Mint 17 Qiana xfce 64-bit.

I followed the install instructions on the github page and get the following error:

```
user ~/ZeroNet-master $ python zeronet.py
- Starting ZeroNet...
[22:36:57] - Version: 0.3.2 r360, Python 2.7.6 (default, Jun 22 2015, 17:58:13) 
[GCC 4.8.2], Gevent: 1.0
[22:36:57] - OpenSSL loaded, version: 01000106F
[22:36:57] - Creating UiServer....
[22:36:57] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[22:36:57] - Removing old SSL certs...
[22:36:57] - Creating FileServer....
[22:36:57] ConnServer Error: Unsupported msgpack version: (0, 3, 0) (<0.4.0), please run `sudo pip install msgpack-python --upgrade`
```

I tried running: `sudo pip install msgpack-python --upgrade` as suggested. 

It installs msgpack-python successfully, but I get the same error when trying to start ZeroNet.
 I resolved the issue. Mint had an old version of msgpack installed and it was 'owned' by the OS. So even `sudo pip .... -upgrade` wouldn't actually update msgpack.
I uninstalled the old msgpack via the Application Manager, then reinstalled msgpack via command line, and the error went away.
 Same issue with Linux Mint 17.2 (Cinnamon, x64).  But I can not manage to install a newer msgpack, some details would be welcome.  Nor the terminal nor the software manager (Menu > Administration > Software manager > search "python-msgpack") does allow me to install a version different from v0.3.0-1 :(
  Correction of minor grammatical errors.
  I am trying to find out how you sync file changes. It seems that changes are pushed directly from changer to other peers. However if we get 1K peers hosting the site(which is really common for a normal site), 1K requests will be pushed from the changer, and all the other peers will download new content directly from the changer. This will lose the power of decentralize.
If a peer is not online when change request was pushed. How could it get the lasted content of the site. Will it download content.json each time it starts up?
How do you sync up database? If a new record was inserted into database, will you update the whole database to other peers?
I really love the idea of decentralize web, and I am making something like this. It will be great help if you can share some of you ideas.
 Thanks for your response. But this will cause a potential lose of data. For example in a messaging board program like ZeroBorard. If user A made a comment, and user B made a comment before A's comment sync to all the other peers. Then A's comment will be overwritten. Because we have two version of data record, and B's version is newer. You said you take the latest changes in the document.
Do you have any work around for this?
 But all these files will be added to something like content.json. He still has the chance to miss some content. 
If we want the content to be the same, we must have the same page file. And if we want to edit it without conflict then a lock is needed. I digged into [ceph](https://github.com/ceph/ceph) yesterday. And I think their method is really good to follow. They used an ordered list of all peers, editions are only allowed on the first peer called primary node, this is something like a lock. In zeronet's case, if you want to make a comment, check if you have the same content with the primary node. If not then sync your files with it. Push your changes to the primary node, and primary node will sync your changes to other peers.
  Previously child processes were not reaped, leaving zombies behind.
Now each child process's `.wait()` method is called before proceeding.

Closes #151.
  Hi, As i understand this project is a combination of bittorent decentralised technology and bitcoin-like crypto to serve web pages.
How is this different from https://github.com/ipfs/ipfs/ where both of these technologies are already implemented?
Apart from TOR compatibility, every feature of ZeroNet is already implemented in IPFS. Am I wrong? could you share some light on this?
 From what the IPFS developers said, IPFS does support dynamic content. As for TOR or VPN etc., IPFS works flawlessly on top of that, as ZeroNet does.
 > From what the IPFS developers said, IPFS does support dynamic content.

You can _distribute_ `dynamic content` via IPFS.
You need to write your own JavaScript script to call `ipfs` to publish dynamic content.
There is no built-in support for basic features like forum and comment.
ZeroNet is full stack dynamic, but IPFS only provides the backend (storage) of dynamic site.
For now, static sites with a lot of files, use IPFS.
Dynamic sites like forum or ZeroMe, use ZeroNet.
Small static site, use either.
 i use ipfs for everything, zeronet is cool but it is slow on boot
  Please support Python3.
 I'd likely say that someone will eventually port it.

The developer probably wanted to reach as many people as possible as easy as possible. Most OS's such as Mac and popular Linux builds all have Python 2.7 by default.
 (For certain values of â€œpopularâ€, yes. ArchLinux has Python3 as its default.)

I agree, I just wanted to make sure there was a formal issue concerning this.
 I've started work on this, hopefully we can get a couple PRs going until we have full agnostic support.
 @DoWhileGeek cool! :+1: 
 Python 2 is now [less than three years from the chopping block](https://pythonclock.org). :hocho: 

ZeroNet's transition to Python 3 needs to be feature complete *before* 2020, Python 2.7's proposed end-of-life (EOL) date. While feasible and indeed necessary, this transition is likely to prove non-trivial â€“ which is to say, "It's gonna hurt." There's really no getting around that. [`six`](https://pypi.python.org/pypi/six) helps, but it's no panacea. The syntactic and semantic differences between Python 2 and 3 are sufficiently profound (particularly with respect to string handling) that the two could be said to be different languages entirely â€“ albeit closely related languages.

Ssomeone just needs to bite the thankless bullet and start doing it. The sooner this painful migration begins, the sooner this painful migration ends. Or to paraphrase an [ancient Chinese and/or African proverb](https://s-media-cache-ak0.pinimg.com/originals/ad/12/56/ad125658e28ffd37f5e72502ca41ce87.jpg):

> The best time to migrate to Python 3 was two years ago. The second best time is today. I wonder how do other python projects cope with this problem. How do they manage to run on both 2.X and 3.X systems? Do they all have to use some compatibility interfaces with two implementations behind them? there are compatibility mechanisms in python to help handle the transition, like the `six` library, and `from __future__ import foo` @HelloZeroNet Please, add some labels on this issue, it's important. @noxarivis  Pestering him isn't gonna make the transfer go any faster. Also, you can't expect someone to know the future like that. Problems arise, etc. which is *precisely* the reason why pretty much no company gives ETA on things like this. How about you try helping instead?  Please support IPv6.
 +1
 I'm currently only using v4, but it looks like there is a BitTornado option to support v6

http://www.cs.helsinki.fi/u/sklvarjo/torrent.html
 I am working on something to make this easier: #520. Please check it out. Also, dumping BitTorrent trackers would be great in so many ways.
 any progress? 
@HelloZeroNet this support ipv6 https://www.ipv6tracker.org
 [IAB Statement on IPv6](https://www.iab.org/documents/correspondence-reports-documents/2016-2/iab-statement-on-ipv6/) (7 November 2016):

> We recommend that existing standards be reviewed to ensure they will work with IPv6, and use IPv6 examples.
 Another vote for IPv6 support. Reason: using ZeroNet on top of cjdns/Hyperboria which is an IPv6-only transport layer. @HelloZeroNet  : ""It's not on short-term plans yet. (next 6 month)""
Narrator : ""7 months later...""
Me: "progress? " +1 for IPv6 support.. main reason is for CJDNS support. I'm also interested in IPV6 support, to let ZeroNet run on cjdns/hyperboria. I might take a crack at it a bit later, but I honestly have no idea how involved it'd be. I'd personally be up for no trackers and just having bootstrap nodes/peer exchange if the issue is that trackers aren't ipv6. IIRC, as it stands zeronet can work even if you remove the trackers from the code, because it stores peer info. So it shouldn't be too difficult to migrate. @HelloZeroNet Please, add some labels on this issue, it's important issue. > The problem is the torrent trackers only support ipv4  addresses, so need to find an alternative solution to store ipv6 (and  tor) addresses.

I'm not sure about the situation when this comment was made, but isn't it true that we now have the ZeroNet bootstrap protocol? Is it possible that IPv6 support could be added to this protocol like how it was done for Tor hosts?

 is it possible to add ipv6 support for web ui first? Is this ready yet? How soon can we run it over cjdns? What all needs to be done?  fixes bad msgpack version on mint
  When you delete a site from ZeroNet, it should delete every trace of it being on your computer.
  If I had a site where I was sharing a lot of videos, I want to create a directory that contains those videos and I want them to only be loaded if the user clicks on them. Can there be a way to make a separate content.json for directories, so that they aren't loaded with the rest of the site, and have separate seeders, etc? I could create a site for each video or couple of videos, and serve links on the main site, but a directory system would be a much better design.
 this.
 Maybe there could be a system of requesting a file, and then torrenting it. As you request a file it gets added. Something like that.
  If a file exists in the current directory called "bootstrap" then its contents will be used as a replacement for the hardcoded bootstrap nodes
 A problem with this is that the list of trackers is only read once at startup. As peers enter or leave the network the list of available trackers will change, but the system won't be updated.
 Excellent
  Hi,

There seems to be an error when running in debug mode on linux.  When running zeronet with 

```
python zeronet.py --debug --coffeescript_compiler "/usr/local/bin/coffee"
```

i get the following error when browsing to one of my sites (not yet compliled)

```
command = config.coffeescript_compiler % os.path.join(*file_path.split("/"))  # Fix os path separator
TypeError: not all arguments converted during string formatting
```

I have managed to fix this on my machine by changing line 59 of src/Debug/DebugMedia.py from:

```
command = config.coffeescript_compiler % os.path.join(*file_path.split("/"))  # Fix os path separator
```

to:

```
command = config.coffeescript_compiler + ' ' + os.path.join(*file_path.split("/")) # Fix os path separator
```

I'm not sure if this is the correct way to fix this but it seems to work fine in windows too.
  I'm hoping someone can point me in the right direction (or this can be a bad feature request).

Basically i want to use a web worker (eg. http://bgrins.github.io/videoconverter.js/demo/) but in order to do this in an iframe (zeronet wrapper), allow-same-origin needs to be in the "sandbox" attribute.

For testing I have  modified src/Ui/template/wrapper.html to add this but would like to know if there is a better way to achieve this. 

Thanks.
  I updated to 0.3.2 but now I'm unable to edit my blog and somethings wrong with my zero id, I can't use it
![zeronet](https://cloud.githubusercontent.com/assets/8492776/9365095/aa32d62e-467d-11e5-8325-d5ad17e3727d.jpg)
![zeronet2](https://cloud.githubusercontent.com/assets/8492776/9365101/b2286b00-467d-11e5-9e46-6117173559f5.jpg)

.
 I downloaded and unpacked again because the update date button wasn't there, if your talking about the yellow button. 
 OK did that but didn't seem to work so I'm going to start a new blog.
  I would like to see a ZeroAnnounce Platform ;
: Look at it like like

: Write ONCE
: Write ONLY if registered ( ZeroID ? )

: TARGET is announcing COPY of ZeroNet-Apps like ZeroBoard
: TARGET is also announcing self- -made | -shared sites

The least two should be split internally ( in terms of holding logs of Announcements )
: the Announcements ( is that a word ? ) should be observable by the registered User announcing its site ( -s ) ;

Hopefully
: You understand what i am aiming for ( in short )

THANKS FOR YOUR INTEREST .
S466531257 BOSS - PAETH CLAUDIUSRAPHAEL

( sry : have a poke running )
 P.S.
: Just to make it

: more easy to share some peronal stuff based on ZeroNet-Apps

: having ZeroNet a list of Apps ( based on their own ) ran by users

[ Compare to WordPress WorkFlow  if you mind ]

THANKS FOR YOUR INTEREST .

S466531257 BOSS - PAETH CLAUDIUSRAPHAEL
 http://127.0.0.1:43110/Sites.ZeroNetwork.bit/
@HelloZeroNet I think that this is similar to what topic starter proposed. Can the issue be closed?  ![description-breaks-layout](https://cloud.githubusercontent.com/assets/6672657/8610792/5b8d4922-26b7-11e5-9ffa-8c0ff465d078.png)

As you can see - the description given breaks the LayOut ;
Any ideas ?

THANKS FOR YOUR INTEREST .

S466531257 BOSS - PAETH CLAUDIUSRAPHAEL
 Yep , you did it
: WORKS in Chromium
  Request

: It would be nice if you would avoid opening the same tab ( Hello ZeroNet ) over and over by clicking the ZeroNet Icon in SysTray ( in Windows | ZeroNet Bundle ) ;

It is irritating and also seems to worry the chromium build , when for example
: used the back-button to land on the home-page ( ZeroHello ) after interacting with some sub-site ( e.g. : ZeroBoard ) ; The new opened Tab shows problems in getting updates , which can only be solved by closing the original opened tab and refresh the newly opened ( ZeroHello ) .

However , please explain why this behaviour should be considered useful , just to understand why it is acting like that OR disable this behaviour and instead check for already active tab with ( ZeroHello- ) -StartPage .

THANKS FOR YOUR INTEREST .

S466531257 BOSS - PAETH CLAUDIUSRAPHAEL
 Can you point me to the call to chromium ? Means : Where ( in code ) the Chromium is executed ?

THANKS .
 thx for the quick response - sry i am getting sick when i have to look into python ( i tried to understand the syntax , but it was not possible for me in 2 decades and it will never be i assume ) ; however
: what about starting chromium with the pinned-tab-attribute ?

: "[chromium-executable] --pinned-tab-count=1 http://127.0.0.1:43110/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr"

If this works via Python ( just as in starting via command ) problem ( if you accept it as a problem ) would be solved ( especially if you prevent changing behaviour of your chrome build to not allow changing startup-settings | start with what-da-heck--feature ) ;

: Literally it just starts chromium with a number of ( defined via : --pinned-tab-count=[Number of tabs to open] ) folowed by the URIs separated by spaces ;

As long as the settings for behaviour on start are accordingly set to this that definately works .

If you might give it a try , wonderful and if functioning please explain syntax in Python , if you mind .

THANKS FOR yOUR INTEREST .

S466531257 BOSS - PAETH CLAUDIUSRAPHAEL
 P.S.
: Pinned tab does not allow multiple instances ( tabs ) based on same adress , so a renewed call of chromium would result in opening chromium , recognizing chromium runs already , pinned tab exists , no duplicate tab is opened .

JUST TO EXPLAIN MY THOUGHT ON THAT .

S466531257 BOSS - PAETH CLAUDIUSRAPHAEL
 Just to mention it
: http://stackoverflow.com/questions/6278847/is-it-possible-to-kill-a-process-on-windows-from-within-python/6278951#6278951

::
import os
import subprocess

CHROME = os.path.join('C:\', 'Program Files (x86)', 'Google', 'Chrome', 'Application', 'chrome.exe')

os.system('taskkill /im chrome.exe')
subprocess.call([CHROME, '--kiosk'])

As i am just vaguely understanding the itself-eating-snake it gives me a feel of right direction ( if applicable in the version of python you based it on --- another reason i hate python )

THANKS FOR YOUR INTEREST .

S466531257 BOSS - PAETH CLAUDIUSRAPHAEL
 So to end up with my comment on this in a plain-text variant
: If it is possible to start your chromium build via your sys-tray-appliance in kiosk-mode AND with a pinned-tab pointing to ZeroHello it would ( in my opinion ) look more consistent and prevent the update problems ( which are okay when running with open port - but definately cracking without opened port --- as chromium has to be shutdown totally before updates are received | synced ) .

: Kiosk-Mode is mentioned , not just becuae of the copied example , but because it would spend a clear state on running a different build of chrome specific to the use of ZeroNet .

You might tinker bout it.

ONCE AGAIN THANKS FOR YOUR INTEREST .

S466531257 BOSS - PAETH CLAUDIUSRAPHAEL
 Well if it wasn't obvious i try to explain once more in detail ( even if no interest in using this is given , maybe you might take me to the right point )
: As i understood ( so far ) it is possible to gain access to running processes | threads  in plain-text via python and therefore the location ( working- | starting- -directory of a process can be read ) ; So it should be possible to adress the instance of chromium that was started in | by | with ZeroNet , right ? ( BTW : How many USERS are running Chromium ? )

: This leads to the possibility of definately identifying the instance started by | for ZeroNet ( at least if the directory it is ran from is compared ) ; So

: How would a call with arguments be performed in the Python-version ZeroNet is based on , actually ?
 Once again
: I am fighting Python , since my first contact with it in the beginning Nineties , so forgive my ignorance ; This project ( ZeroNet ) is the first that attracts me that much that i am WILLED to puke my face ( to understand that , i am oldschool : FORTRAN, ALGOL, PASCAL, TURBO PASCAL, C C++, JS, ECMA and in terms of feeling good : LISP ) ( ... just to explain ) ;

I try to folow the paths right now and sniff the footsteps; Can you point me to a data- | control- | function- -flow of how ZeroNet is organized ? So One ( like me ) can understand better how anything is constructed and handled ?

SORRY PYTHON HAS TOO LESS BRACKETS TO GET THE SCOPE BY JUST READING .

:)
  Hey, on recommendation from a buddy, I've given ZeroNet a go, and am running into a problem with first launch.

I'm on Ubuntu 15.04, and I've followed the instructions for a debian install.
- sudo apt-get install msgpack-python python-gevent
- wget https://github.com/HelloZeroNet/ZeroNet/archive/master.tar.gz
- tar xvpfz master.tar.gz- 
- cd ZeroNet-master
- python zeronet.py
- http://127.0.0.1:43110/ 

Unfortunately, on opening up the browser (I have tried restarting the server a few times now + browser refreshes) I get the spinning red box and then...
Connecting... 
Peers found: 25 
Peers found: 25 
Peers found: 25 
content.json download failed

Log is

Starting ZeroNet...
[16:43:40] - Version: 0.3.1 r267, Python 2.7.9 (default, Apr 2 2015, 15:33:21)
[GCC 4.9.2], Gevent: 1.0.1
[16:43:40] - OpenSSL loaded, version: 01000106F
[16:43:40] - Creating UiServer....
[16:43:40] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[16:43:41] - Removing old SSL certs...
[16:43:41] - Creating FileServer....
[16:43:41] - Starting servers....
[16:43:41] Ui.UiServer --------------------------------------
[16:43:41] Ui.UiServer Web interface: http://127.0.0.1:43110/
[16:43:41] Ui.UiServer --------------------------------------
[16:43:42] FileServer Checking port 15441 using portchecker.co...
[16:43:43] FileServer [BAD :(] Port closed: Port 15441 is closed.
[16:43:43] FileServer Checking port 15441 using canyouseeme.org...
[16:43:47] Site:1EU1tb..E4Vr Content.json not exist: data/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/content.json
[16:43:51] FileServer [BAD :(] Port closed: Error: I could not see your service on 108.181.97.212 on port (15441) Reason: Connection timed out
[16:43:51] FileServer Trying to open port using UpnpPunch...
[16:43:53] FileServer Checking port 15441 using portchecker.co...
[16:43:53] FileServer [OK :)] Port open: Port 15441 is open.
[16:43:53] Site:1EU1tb..E4Vr Content.json not exist: data/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/content.json
[16:43:55] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[16:44:48] Site:1EU1tb..E4Vr Content.json not exist: data/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/content.json
[16:44:48] - UiWSGIHandler error: error: [Errno 32] Broken pipe in UiServer.py line 36 > pywsgi.py line 495 > pywsgi.py line 486 > pywsgi.py line 376 > pywsgi.py line 369 > pywsgi.py line 355 > socket.py line 458 > socket.py line 435
[16:44:48] Site:1EU1tb..E4Vr Content.json not exist: data/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/content.json
[16:44:48] Site:1EU1tb..E4Vr Content.json not exist: data/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/content.json
[16:44:48] Site:1EU1tb..E4Vr Content.json not exist: data/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/content.json
[16:46:21] Site:1EU1tb..E4Vr Content.json not exist: data/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/content.json
[16:46:57] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[16:46:57] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[16:49:42] Site:1EU1tb..E4Vr Content.json not exist: data/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/content.json

As mentioned.. problem persists across restarts..

Starting ZeroNet...
[16:57:52] - Version: 0.3.1 r267, Python 2.7.9 (default, Apr 2 2015, 15:33:21)
[GCC 4.9.2], Gevent: 1.0.1
[16:57:52] - OpenSSL loaded, version: 01000106F
[16:57:52] - Creating UiServer....
[16:57:52] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[16:57:52] - Removing old SSL certs...
[16:57:52] - Creating FileServer....
[16:57:53] - Starting servers....
[16:57:53] Ui.UiServer --------------------------------------
[16:57:53] Ui.UiServer Web interface: http://127.0.0.1:43110/
[16:57:53] Ui.UiServer --------------------------------------
[16:57:54] FileServer Checking port 15441 using portchecker.co...
[16:57:54] FileServer [OK :)] Port open: Port 15441 is open.
[16:57:54] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[16:57:57] Ui.UiServer Wrapper key not found: oIWbsI6D05mk
[16:59:09] Site:1EU1tb..E4Vr Content.json not exist: data/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/content.json
[16:59:11] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json
[16:59:11] Site:1Name2..hM9F Content.json not exist: data/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F/content.json

---

So, am I doing something wrong?

default python is 2.7.9
python 3.4 is also installed and available
 Sure thing. Here is a slice from the log. 

[REDACTED]

At a glance, there are two bad things happening... 
 'SSLContext' is not defined in Connection.py line 124
and
 Connect error: Exception: Connection event return error in ConnectionServer.py line
 129

Pardons for any exposed IP addresses...

Running the command as given (no encrypt, no ssl) lets me access the front page, and from there it seems as though I can access the network! I was able to visit some sites, although many failed. ZeroBoard seemed to be working fine.
 Hmm, very odd. Seems to be working now?

Maybe because of:
[19:09:12] - OpenSSL load failed: Disabled by config, falling back to slow bitcoin verify
?

Starting ZeroNet...
[19:09:12] - Version: 0.3.1 r267, Python 2.7.9 (default, Apr  2 2015, 15:33:21) 
[GCC 4.9.2], Gevent: 1.0.1
[19:09:12] - OpenSSL load failed: Disabled by config, falling back to slow bitcoin verify
[19:09:12] - Creating UiServer....
[19:09:12] - Removing old SSL certs...
[19:09:12] - Creating FileServer....
[19:09:12] - Starting servers....
[19:09:12] Ui.UiServer --------------------------------------
[19:09:12] Ui.UiServer Web interface: http://127.0.0.1:43110/
[19:09:12] Ui.UiServer --------------------------------------
[19:09:13] FileServer Checking port 15441 using portchecker.co...
[19:09:13] FileServer [OK :)] Port open: Port 15441 is open.
[19:09:31] Site:1Hcu2r..rvA7 index.html file size does not match 8530 <> 8598, Hash: False
[19:09:31] Site:1Hcu2r..rvA7 index.html file size does not match 8530 <> 8598, Hash: False
 $ openssl version
OpenSSL 1.0.1f 6 Jan 2014
 Unless I am mistaken, Ubuntu has backported fixes from newer versions, hopefully making it not vulnerable? 

OpenSSL 1.0.1f 6 Jan 2014
built on: Thu Jun 11 15:30:15 UTC 2015

I tried the Lekensteyn pacemaker heartbleed check tool, and it declared:
"Did not receive heartbeat response! Timeout while waiting for bytes
Possibly not vulnerable"
 Confirmed fixed - I just cleared off the old version, grabbed a fresh checkout of master, and booted it up with no problems. Home page resolved in about 2.5 seconds. Can browse about and visit pages. Thanks!
  I believe it would help the adoption of ZeroNet if there was a distributable bundle available for users that ran as a docked (system tray) application.

ie, BitMessage comes as a distributable bundle that users on Mac platforms can download to run as system tray applications. They don't have to worry about installing python dependencies, as most users wouldn't even know where to begin on that. 

Ideally a ZeroNet Qt interface would provide panels displaying information and features such as:
- Starting/Stopping the Zeronet service
- Launching the web frontend in the default browser
- A debug log viewer
- Key information
- Site management facilities (signing/publishing)
- Peer information
- Shortcuts to Zeronet sites
- ie anything the Windows tray platform has

This may also help in creating a portable application that is easier to maintain across Windows/Mac/Linux. 
 My experience with Qt ends at the C++ interface, but I will see what I can do about modifying the trayicon plugin as you suggested. 
 Maybe we should add also the browser window with the app like at [Aether](http://getaether.net/). This would be nice for technical no experienced people.
 I have a mac I can test things on, but not a lot of knowledge or experience with QT. Happy to help, though!
  http://127.0.0.1:43110/lÃ½c.bit/

Fails with python exception message:
Err: UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 2: ordinal not in range(128) in UiServer.py line 71 > UiRequest.py line 64 > UiRequest.py line 389

Just curious: any plans to move to python 3? Any library dependencies which are not available there?
 There is also an error with the encoded domain-name form:
http://127.0.0.1:43110/xn--lc-0ka.bit

Fails with python exception message:
Err: AttributeError: 'NoneType' object has no attribute 'group' in UiServer.py line 71 > UiRequest.py line 56 > UiRequest.py line 148 > UiRequestPlugin.py line 20 > UiRequest.py line 237 > UiRequestPlugin.py line 32
 Also worth saying, when I goto http://zero/xn--lc-0ka.bit (using zeronet chrome extension), I get a weird message:
Not Found: data/xn--lc-0ka.bit/index.html

I already tried to actually create such a file in my website, to no avail.
 I'd like to point out a security concern with allowing UTF8 domain names. It would make it very easy to create a spoof version of a website for phishing, and use a very similar looking domain address with a different character. So I'm not sure if it is a good idea. 
 @Idealcoder True.
 Keep things simple. Are there any domains on the DNS (not namecoin's DNS) that have Unicode characters other than the standard English ones in their domain name?
 IDN and new gTLDs have meant the era of ASCII only domain names in the DNS is over, except that they use punycode which is ASCII.  These are the xn-- strings appearing from the OP.

It's completely possible for ZeroNet (and possibly the plug-in) to recognise non-ASCII, punycode it and look it up in Namecoin's register blockchain.  It is not necessary to register the Unicode directly in Namecoin, and the OP hasn't.

Some xn-- names are working, http://127.0.0.1:43110/xn--tqh.bit for example AKA â‘‚.bit (http://namecha.in/name/d/xn--tqh)
 As talked on https://github.com/HelloZeroNet/ZeroNet/pull/735 it seem to add more confusion then it help.

Maybe some can add a new dimention to the debate but at this point, the decision seem to be that it work as designed. Zeronet do not plan to support non-ASCII char in domain name.    It seems if we already peer with a site, the original limit is not asked to be increased if the data folder already exists? If I erase the 1Bluish folder and go the web site again, I am asked to increase the max capacity to 200MB. I guess, there isn't the capacity to grow the web site beyond the initial max capacity we have set?

[19:59:38] FileServer [OK :)] Port open: Port 15441 is open.
[20:00:03] Site:1BLuis..oYQw content.json: Site too large 101549465 > 10485760, aborting task...
[20:00:03] Site:1BLuis..oYQw content.json: Site too large 101549465 > 10485760, aborting task...
[20:00:04] Site:1BLuis..oYQw content.json: Site too large 101549465 > 10485760, aborting task...
[20:00:04] Site:1BLuis..oYQw content.json: Site too large 101549465 > 10485760, aborting task...
[20:00:04] Site:1BLuis..oYQw content.json: Site too large 101549465 > 10485760, aborting task...
[20:00:04] Site:1BLuis..oYQw content.json: Site too large 101549465 > 10485760, aborting task...
  I know there is a web site called [BTDigg](https://en.wikipedia.org/wiki/BTDigg) that is a search engine based on data from DHT. I wonder if a similar search engine could be devised for ZeroNet. I know there is a namecoin directory, but it seems limited to namecoin domains only. There must be sites that exist we are not finding yet that exist on the DHT network. 
  BTDigg is a dead project + I don't think it should part of the core to crawn and list all projects, some site might not want to get listed.   http://127.0.0.1:43110/1MoZDevNsM5NAitt2y17jCvPWRazbjYqLe

ZeroNet seems to choke every time it tries to connect to this URL.

Am I not being patient enough?

[19:58:46] Site:1MoZDe..YqLe Content.json not exist: data/1MoZDevNsM5NAitt2y17jCvPWRazbjYqLe/content.json
 I see. It seems to crash the client or makes it unusable. What about a way to disallow sites of a certain size, or a better way to handle it getting stuck? Long term, I wouldn't mind hosting/peering a 3GB site  if ZeroNet could could provide a way to handle it. You check for the overall size of a site... how about if the content.json is too big, you reject distributing the site for now?
 I really think that's the wrong way to handle something like this. If it were me, and keep in mind this is just my opinion, depending on the content hosted; there's really no need for the site to be that big. If anything, I would host the main site via ZeroNet A, and have another service which hosts ZeroNet B which contains the files that you're attempting to serve. That ZeroNet B could be located on a dedicated server, maybe, so you only require one dedicated seeder--then clients could request the content they desired via ZeroNet. But attempting to throw all the files at the client at once even when they may never use them is pretty weird IMHO.

Just my $0.02.
 The thought is of making multiple ZeroNet addresses and breaking up the site into logical groups is definitely a better work around. Things like static blog publishing, or even torrent indexers could be published this way. You have the main address everyone comes to and say every month, the older content gets owned by a different address. My only concern there is how one goes about searching for content across different "domains".
 Hi, just revisiting this idea again.. I'm curious about your thoughts on open source publications such as scientific journals. Would we follow a particular subscription and those subscriptions merged into our Merger account?
 the merger site feature is now into production. Closing ?  @HelloZeroNet Please, close the issue.   But surely we also need an OCaml or Haskell version.
 Should we close this issue?
 Just for information, if someone will ever visit this issue, there is an implementation already:  
https://github.com/ZeroNetJS/zeronet-js  Is there a reason [pybitcointools](https://pypi.python.org/pypi/bitcoin) is embedded inside ZeroNet, rather than being installed via pip?
 That sounds like a prime case for virtualenv.

Set up a new virtualenv, change the number in the requirements.txt file and test.

Virtualenv makes it isolated, and reproducible on other systems.

Including a package is a bit of a bad practice, and you're left maintaining more than just your own code.
 In the requirements.txt you would change a line like:

```
bitcoin==1.0
```

to

```
bitcoin==1.1
```

And then the user just has to run:

```
pip install --upgrade --force-reinstall -r requirements.txt
```

Or, we could actually do that for the user in the upgrade.py file:

``` python
import subprocess
subprocess.call(['pip','install','--upgrade','--force-reinstall','-r','requirements.txt'])
```

All we'd have to do is make sure the updater downloads the requirements.txt file each time.
 Alternatively, if you really want to include it directly in the repo, then I would recommend looking into [pex](https://github.com/pantsbuild/pex). The video on the page should explain it fairly well.
 The current format 'smells', like a code smell. It's the sort of thing that would make me walk away from a project.

Releasing ZeroNet on PyPI would fix all the above problems.

A user would run

.   pip install ZeroNet

To install, and updating would be by

.   pip install --upgrade ZeroNet

Which would also update all dependencies. Needing administrative privileges with pip assumes you aren't using virtualenv - a bad idea when it comes to Python. However, it isn't unusual for a program to need administrative privileges to update.

Including a full project makes you maintain their code, bloats your own repository making rollbacks harder, makes a testing environment incredibly hard, as tools like nose, pytest and others automatically finds tests, and you probably haven't got pybitcointools test tools in your requirements file.
  I get an unhandled exception when ZeroNet first starts up. I have a lot of sites I am trying to visit, especially the Mozilla Developer Network image. I think it choked on that, then I'm not sure what happened.

```
Starting ZeroNet/start.py...
- Starting ZeroNet...
[23:58:58] - Version: 0.3.1 r242, Python 2.7.9 (default, Dec 10 2014, 12:24:55) [MSC v.1500 32 bit (Intel)], Gevent: 1.0.1
[23:58:58] - OpenSSL loaded, version: 01000201F
[23:58:58] - Creating UiServer....
[23:58:59] - Removing old SSL certs...
[23:58:59] - Creating FileServer....
[23:59:00] - Starting servers....
[23:59:00] Ui.UiServer --------------------------------------
[23:59:00] Ui.UiServer Web interface: http://127.0.0.1:43110/
[23:59:00] Ui.UiServer --------------------------------------
[23:59:00] - Opening browser: default_browser...
[23:59:02] FileServer Checking port 15441 using portchecker.co...
[23:59:02] FileServer [OK :)] Port open: Port 15441 is open.
[23:59:22] - Unhandled exception
Traceback (most recent call last):
  File "C:\temp\ZeroBundle-v0.1.0\ZeroBundle\Python\lib\site-packages\gevent\greenlet.py", line 327, in run
    result = self._run(*self.args, **self.kwargs)
  File "C:\temp\ZeroBundle-v0.1.0\ZeroBundle\ZeroNet\src\Connection\ConnectionServer.py", line 65, in handleIncomingConnection
    connection.handleIncomingConnection(sock)
  File "C:\temp\ZeroBundle-v0.1.0\ZeroBundle\ZeroNet\src\Connection\Connection.py", line 90, in handleIncomingConnection
    if sock.recv( 1, gevent.socket.MSG_PEEK ) == "\x16":
  File "C:\temp\ZeroBundle-v0.1.0\ZeroBundle\Python\lib\site-packages\gevent\socket.py", line 385, in recv
    return sock.recv(*args)
error: [Errno 10054] An existing connection was forcibly closed by the remote host
Traceback (most recent call last):
  File "C:\temp\ZeroBundle-v0.1.0\ZeroBundle\Python\lib\site-packages\gevent\greenlet.py", line 327, in run
    result = self._run(*self.args, **self.kwargs)
  File "C:\temp\ZeroBundle-v0.1.0\ZeroBundle\ZeroNet\src\Connection\ConnectionServer.py", line 65, in handleIncomingConnection
    connection.handleIncomingConnection(sock)
  File "C:\temp\ZeroBundle-v0.1.0\ZeroBundle\ZeroNet\src\Connection\Connection.py", line 90, in handleIncomingConnection
    if sock.recv( 1, gevent.socket.MSG_PEEK ) == "\x16":
  File "C:\temp\ZeroBundle-v0.1.0\ZeroBundle\Python\lib\site-packages\gevent\socket.py", line 385, in recv
    return sock.recv(*args)
socket.error: [Errno 10054] An existing connection was forcibly closed by the remote host
```
 Hopefully, I can figure out how to apply the new code to the existing ZeroBundle. I take it the ZeroBundle is not part of the GitHub zip file, so I have take ZeroNet-master.zip and merge it with the existing files...?
  Could I suggest integrating something like [Travis-CI](http://docs.travis-ci.com/user/languages/python/) into the flow of things?

Things like testing to see if PEP8 is passing, and all the written tests still pass automatically takes a lot of effort out of reviewing any pull requests
 I could have a go at putting together some unittests, if you're interested. Not the best at it, but I'm learning.
 I've renewed my fork, and attempted to start adding some automated testing to it.

Health-wise, Landscape says ZeroNet is at about [70%](https://landscape.io/github/shakna-israel/ZeroNet/2/messages), which isn't too bad. There's just a lot of semantic things, to do with the various PEPs.

As for Travis, [a few issues](https://travis-ci.org/shakna-israel/ZeroNet/jobs/67615581) ahowed up, which might take some work to get it all running.

After that, it's just a matter of expanding the test suite. Something like [Coveralls](https://coveralls.io/) could come in handy for setting that up easier.
 Travis seem to be implemented by now closing ?   Typo fix asyc -> async
 np :)
  Reused Zeroname code, and swapped out the reolveDomain function. It now connects to namecoind directly using RPC and then run rpc.name_show() to find domain.

It might be a bit slow as there is no caching - it looks up the domain each time on the blockchain. 
I'm not sure how to handle the bitcoinrpc dependancy, so I have left that out.

Also, it is disabled by default. If it works well we might want to consider a "automatic" detection system - check if namecoin is installed, and if not fallback to hosted Zeroname. 
 For some reason, when using this plugin ZeroHello uses site addresses rather than namecoin .bit domains, but manually typing the domain works fine?
   20 minutes with PyCharm :)
 I think ideally everything should be imported at the start of a file, as it makes the code a lot less brittle. In my experience, there is no real world performance penalty for  loading everything that's needed at the start of the file. I also find that this leads to simplifications of project structure becoming easily apparent.
  Several fixes to allow the script to run under windows without errors, fixing:
- Windows use different file locations
- Windows having troubles with UTF8
- Change the config defaults so that it starts scanning at first block with a namecoin domain.
- Added a note about data/names.json file being needed. 

Thanks for @nofish who helped over IRC. 
  Most editors let you set it so that when you press TAB key it inserts 4
spaces. Thats how I live with it.

BTW, there is a special config file you can put in project root to tell
editors whether to use tabs or spaces:

http://editorconfig.org/

On Wed, Jun 17, 2015 at 8:58 PM, ZeroNet notifications@github.com wrote:

> https://www.python.org/dev/peps/pep-0008/
> 
> Probably required modifications:
> - Use spaces instead of tabs.
>   https://www.python.org/dev/peps/pep-0008/#prescriptive-naming-conventions
> - Imports to separate lines
>   https://www.python.org/dev/peps/pep-0008/#blank-lines
> - Change module names to lower_cased
>   https://www.python.org/dev/peps/pep-0008/#prescriptive-naming-conventions
> 
> Possible problems:
> - The update script
>   https://github.com/HelloZeroNet/ZeroNet/blob/master/update.py does
>   not handle the renames/file removes. Some os does not allow to have the
>   same file with upper cased and lower cased form in the same directory, so
>   the update will fail. So we need to modify the update script and wait some
>   time until everyone update it.
> - I'm a TAB person, going to need some time to get used to spaces :)
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/issues/117.
  Very cool project, I found a typo, "Content.json not exits: data/", "not exits" is in the code 26 times, it shouldn't be "doesn't exist" in most instances :)
  An idea to reduce storage usage is to try and stop storing multiple copies of the same file, e.g bootstrap.css. 

One way could be to have a CDN - a website that just contains all the commonly used files, bootstrap, jquery, etc. which users can cross site link to rather than using a local copy on their website. This would be complicated though as it would require cross site linking of resources, and Zero Net automatically adding the dependency website as a seed ( or force everyone to have it?)

Another option would be to use deduplication on the file system level. The advantage of this would be that all files are deduplicated rather than just common ones. There are already packages out there that do this - create CRCs of all the files, check for duplicates, and replace them with symlinks. 

Currently ZeroNet isn't big enough to make a difference, but in the future this could help save a lot of space?
 Very true about the security issues, didn't think about those. 
 Rather than deduplication, could you also copy file from other HelloZeroNet location to new location? Not deduplication, but at least a local copy will save bandwidth.
 I would love to see hash-based deduplication of larger files, since many sites / torrents host identical content.

Just imagine how different the torrent scene would be if torrent clients automatically reassembled pieces of a file from _any_ torrent found to contain a file with a matching size & hash.
    @HelloZeroNet I get "ssl_error_rx_record_too_long" when trying to connect to https://127.0.0.1:43110 using Firefox 41.0.2
 Ah, ok
  I added a Dockerfile. Could you please create a automated build on Dockerhub?
  Add a configfile feature. This will allow users to easily set and use their own startup option defaults. 

It should be possible to override the configfile settings with the startup options.
 Nice.

I think it would be useful to add a startup options to the config file path. I find static path similar to log and data (#106) a bit problematic.
  Allow a different data and log directory passing by a startup argument instead of the default pathes.
    Add DNS Support instead of only supporting Namecoin.

I suggest to use TXT records similar to the following example:

```
subdomain        IN      TXT    "zero=1Gfey7wVXXg1rxk751TBTxLJwhddDNfcdp"
```
 Added pullrequest #111 
 I think this will help a lot! And you can make the DNS support as a "fallback" in case other solutions are failing, to make it less centralised @HelloZeroNet and probably there is a solution to make it work offline as well.
 The trouble with DNS is that it's not secure and is also quite centralized.
  add print styles to allow pages to print
  When printing any zeronet site, the only printable content is the notification area and such.  Print styles are needed to do the reverse (hide the parent page overlays, set position of the iframe to fixed).
  @HelloZeroNet is this fixed?  +1
These features would be great since the compression for text files can get up to ~70%, which is required when dealing with big DBs.
A better UX on setting and updating a site size limit would be a good companion to these features (ie: what happens when a size surpass the size limit).
 Can I suggest automatic minification of html/css/js as well, as this would further reduce space usage. This could be done on the publishing stage of the website. Won't make any difference if they are already minified - but I doubt all users would bother to manually minify files. 
 I almost wonder if it would be more efficient to store everything in a huge database ( data and all files for websites) rather than having SQLite constantly loading up JSONs and writting to disk. Then you could just have compression on the entire database. Many databases also have BSON (binary JSON format) that would store the JSON files very efficiently (e.g. boolean stored as 1 bit vs "true"/"false" string).

Wouldn't help with network transmission at all though, and the disadvantage is that it reduces human readability, but it is an option. 
 [zipvfs](http://www.sqlite.org/zipvfs/doc/trunk/www/readme.wiki) is an extended version of SQLite that allows for compression.
 I have found an open source python implementation, but it isn't any sort of library, more just a gist that works, but isn't easy to integrate into anything.
 Any news? Also, maybe the test should be updated because they changed a lot of things in Brotli
 Ok
 I would be happy to be able to put .gz files in a ZeroSite and have the server serve them up with Content-Encoding: gzip if the client requests the file without .gz and has Accept-Encoding: gzip, otherwise the local daemon should uncompress before delivering to the browser. That latter part is really optional since there probably aren't any browsers that work with ZeroNet that don't support gzip.
 @HelloZeroNet any plans to implement this?
I ask because if you say that this is not in the roadmap for the next months I'll probably implement it on the site level.
Thanks
 @HelloZeroNet thanks for that. I have just implemented compression (zlib) of one column of the site database as well. ðŸ˜„ 
For my use case I'm looking forward for the DB compression because that's what will be updated daily (unlike the site static files which are downloaded only once). In my compression implementation I've left all columns which I use to query uncompressed. I wonder how compressing them will impact on the query time.
Also, given that I'm compressing just one column (book description) I'm aware that this should not affect the diff syncing of the json files between nodes. I wonder how this will be affected once the whole json is compressed and only one row is updated/added  to that json.
Thanks 
 Why not use a direct access archive format like ZIP instead of one that requires you to unpack the entire archive before accessing any files? It might even be possible to generate a header and send an individual file directly to the browser without compressing it since ZIP and gzip use compatible compression algorithms, though I'm not sure if any of the libraries support this out of the box.  I fail to understand the use case for archiving user files. What would it be for? 
In my mind the whole purpose of allowing user content is to have it available for other users to benefit from it. 
Take a forum for example, if a question is answered it should be always available (potentially through search). 
In sites with user content, usually the user content itself is the main value provided by the site. Imagine if stack overflow archived user answers. 
Also, the down side of the feature is that, from what I understood, there will be no way for the user to know that the content he may be looking for exists but it is archived. 

I'm looking forward to the database compression feature â˜ºï¸ IMHO this may lead to site owners using the feature incorrectly and archiving useful content. Sites with old content communicate maturity of the network.
Given that we are talking about text content the archive feature may be the easiest solution for the problem but maybe not the right solution. The right solution would be to improve the architecture of the network in such a way that it becomes highly effective in compressing and transferring content at speed (eg: transferring only diff of the json files to all nodes instead of only the nodes that are online). Allowing users to 'remove' content (by making it optional) will only mask the underlying issue, which should be optimising the network.
It is better to bet on making the network more efficient at transferring content than implementing features that will remove content from the network. Even if the site owner thinks that this is a good idea for his site, the users that took their time to create the content will dislike the fact that the site owner took the content the user created 'down'. And they may not abandon the site, but the network altogether. 
Text is highly compressible and in years to come connections will continue to get faster and hard drives bigger. Even these days, downloading big files is a common thing for users. The upside of saving some 50MB by allowing the site owner to make content optional is lower than the downside of having user generated content (which took time and energy) removed from the site. You talk about large sites as a problem that needs solution. Have you heard of any site that had to delete and start again because it was too successful and accumulated too much user content?
If you are referring to ZeroTalk I think 8MB is only a problem if the content is useless. If this is the case, instead of allowing archival of the content we could work feature that would increase the quality of the content (eg: up/down voting) in such a way that users will prefer to store and help distribute large sites instead of small ones.
I agree with merging multiple small json files into a big one. That definitely makes sense.
So maybe the archive feature can become an 'optimize site' feature where zeronet will compress and merge the json files in the most efficient way for that site. 
I just think that making it easy to transform text content in optional will result in a net loss for the network. I would resort to this as a last resort feature to deal with big sites.
Also, maybe my definition of big is different. For me big (when talking about text) means 200MB+. Which, if we're talking about user generated content, is a nice problem to have. But from what I got, these 10 minutes would decrease if you merge the files. And that should probably be enough.
I'm all for removing bad content from the network (eg: spam, trolling, etc), but creating an archive feature as you propose may make it too easy to archive useful content, and despite the site owner best intentions, the network will be worse by the lack of content (we need to keep in mind that downloading optional files will be an advanced user skill given that it already requires an understanding of how the network works, which cannot be expected from new users).
Also, an initial wait time to download the site is a good price to pay given the benefits of having the site available on your phone offline (and all other benefits of having a site on zeronet instead of the internet). 
We cannot compete in speed with normal internet sites, and we should not. We should invest in features that exploit what makes zeronet sites different from internet sites. Yeah, that makes sense.
I understand the use case for the feature now. Sounds like a good idea. ;) I must say though that this sounds very much like an overlapping feature with the merger sites. Or maybe I'm using merger sites incorrectly. "with small files increase,computer disk might work slowly", will it happen? @HelloZeroNet, is this yet a thing? Are database files zip supported now? #1053 is related to one use case where the database may have outdated content. I'm referring to the use case where the db won't have outdated content and all the site owner wants is to zip the json files to speed up download. 
  bussiere@kusanagi:~/WorkspaceSafe/ZeroNet-master$ ./start.py - Starting ZeroNet...
Traceback (most recent call last):
  File "/home/bussiere/WorkspaceSafe/ZeroNet-master/zeronet.py", line 9, in main
    import main
  File "/home/bussiere/WorkspaceSafe/ZeroNet-master/src/main.py", line 35, in <module>
    from Debug import DebugHook
  File "/home/bussiere/WorkspaceSafe/ZeroNet-master/src/Debug/DebugHook.py", line 1, in <module>
    import gevent, sys, logging
ImportError: No module named gevent
-- Error happened, press enter to close -

And i'am sure that i have gevent installed ...
 My python install must be a mess 
bussiere@kusanagi:~$ python -V
Python 2.7.6
bussiere@kusanagi:~$ python -c "import gevent; print gevent.**version**"
Traceback (most recent call last):
  File "<string>", line 1, in <module>
ImportError: No module named gevent
bussiere@kusanagi:~$ sudo pip install gevent
[sudo] password for bussiere: 
The directory '/home/bussiere/.cache/pip/log' or its parent directory is not owned by the current user and the debug log has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
The directory '/home/bussiere/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
The directory '/home/bussiere/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
Requirement already satisfied (use --upgrade to upgrade): gevent in /usr/local/lib/python2.7/dist-packages
Requirement already satisfied (use --upgrade to upgrade): greenlet in /usr/local/lib/python2.7/dist-packages (from gevent)
bussiere@kusanagi:~$ python -c "import gevent; print gevent.**version**"
Traceback (most recent call last):
  File "<string>", line 1, in <module>
ImportError: No module named gevent

It worked when i made a venv.

So sorry
 Ok done it works thanks :)

On Thu, May 7, 2015 at 3:00 PM, ZeroNet notifications@github.com wrote:

> apt-get python-gevent
- Ð‘Ñ‹Ð»Ð¸ Ð±Ñ‹ ÐºÐ¾ÑÑ‚Ð¸, Ð° Ð¼ÑÑÐ¾ Ð½Ð°Ñ€Ð°ÑÑ‚ÐµÑ‚
    Starting ZeroNet...
Traceback (most recent call last):
  File "zeronet.py", line 9, in main
    import main
  File "src/main.py", line 41, in <module>
    from gevent import monkey; monkey.patch_all(thread=False, ssl=False) # Make time, socket gevent compatible. Not thread: pyfilesystem and system tray icon not compatible, Not ssl: broken in 2.7.9
  File "/usr/local/lib/python2.7/dist-packages/gevent/monkey.py", line 185, in patch_all
    patch_socket(dns=dns, aggressive=aggressive)
  File "/usr/local/lib/python2.7/dist-packages/gevent/monkey.py", line 124, in patch_socket
    from gevent import socket
  File "/usr/local/lib/python2.7/dist-packages/gevent/socket.py", line 659, in <module>
    from gevent.ssl import sslwrap_simple as ssl, SSLError as sslerror, SSLSocket as SSLType
  File "/usr/local/lib/python2.7/dist-packages/gevent/ssl.py", line 386, in <module>
    def get_server_certificate(addr, ssl_version=PROTOCOL_SSLv3, ca_certs=None):
NameError: name 'PROTOCOL_SSLv3' is not defined
-- Error happened, press enter to close --
 It works, thank you.
  ```
- Starting ZeroNet...
[17:54:51] - Config: Config(action='main', coffeescript_compiler=None, debug=True, debug_socket=False, disable_udp=False, disable_zeromq=False, fileserver_ip='*', fileserver_port=15441, homepage='1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr', ip_external=None, open_browser=None, proxy=None, size_limit=10, ui_ip='127.0.0.1', ui_port=43110, ui_restrict=False)
[17:54:51] - Adding autoreload: /, cb: <bound method PluginManager.reloadPlugins of <Plugin.PluginManager.PluginManager instance at 0x107170b48>>
[17:54:51] PluginManager Loading plugin: Stats
[17:54:51] PluginManager New plugin registered to: UiRequest
[17:54:51] PluginManager Loading plugin: Trayicon
[17:54:51] PluginManager Loading plugin: Zeroname
[17:54:51] PluginManager New plugin registered to: UiRequest
[17:54:51] PluginManager New plugin registered to: SiteManager
[17:54:51] - Version: 0.2.9 r122, Python 2.7.9 (default, Apr 13 2015, 19:57:29) 
[GCC 4.2.1 Compatible Apple LLVM 6.1.0 (clang-602.0.49)], Gevent: 1.0.1
[17:54:51] PluginManager New class accepts plugins: SiteManager (Loaded plugins: [<class 'Zeroname.SiteManagerPlugin.SiteManagerPlugin'>, <class 'Site.SiteManager.SiteManager'>])
Segmentation fault: 11
```

I'm not sure if I'm missing any dependencies for example I noticed the following notice "[17:52:03] - No module named fs.osfs: For autoreload please download pyfilesystem (https://code.google.com/p/pyfilesystem/)" and suppressed it by installing it via pip (pip install fs). Other than this I couldn't see anything out of the ordinary that might indicate somethings missing.

In case it helps here's the info provided from the "Problem Details and System Configuration" when ZeroNet crashed:

```
Process:               Python [18548]
Path:                  /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python
Identifier:            Python
Version:               2.7.9 (2.7.9)
Code Type:             X86-64 (Native)
Parent Process:        bash [886]
Responsible:           Terminal [883]
User ID:               501

Date/Time:             2015-04-29 17:57:38.851 +0100
OS Version:            Mac OS X 10.10.3 (14D136)
Report Version:        11
Anonymous UUID:        4C34CDCC-A8E8-A79E-B06C-1B508BF90883

Sleep/Wake UUID:       CE664DD0-E208-40FF-BC1C-7F6476438DE6

Time Awake Since Boot: 10000 seconds
Time Since Wake:       4500 seconds

Crashed Thread:        0  Dispatch queue: com.apple.main-thread

Exception Type:        EXC_BAD_ACCESS (SIGSEGV)
Exception Codes:       KERN_INVALID_ADDRESS at 0x0000000043dadc2c

VM Regions Near 0x43dadc2c:
--> 
    __TEXT                 0000000100e23000-0000000100e25000 [    8K] r-x/rwx SM=COW  /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python

Thread 0 Crashed:: Dispatch queue: com.apple.main-thread
0   libcrypto.0.9.8.dylib           0x00007fff861b6686 BN_bin2bn + 118
1   _ctypes.so                      0x0000000101e8e7d7 ffi_call_unix64 + 79
2   _ctypes.so                      0x0000000101e8eff1 ffi_call + 813
3   _ctypes.so                      0x0000000101e8a649 _ctypes_callproc + 869
4   _ctypes.so                      0x0000000101e84b16 PyCFuncPtr_call + 1125
5   org.python.python               0x0000000100e3623f PyObject_Call + 99
6   org.python.python               0x0000000100eb2085 PyEval_EvalFrameEx + 10947
7   org.python.python               0x0000000100eb59f1 fast_function + 262
8   org.python.python               0x0000000100eb277d PyEval_EvalFrameEx + 12731
9   org.python.python               0x0000000100eb59f1 fast_function + 262
10  org.python.python               0x0000000100eb277d PyEval_EvalFrameEx + 12731
11  org.python.python               0x0000000100eb59f1 fast_function + 262
12  org.python.python               0x0000000100eb277d PyEval_EvalFrameEx + 12731
13  org.python.python               0x0000000100eb59f1 fast_function + 262
14  org.python.python               0x0000000100eb277d PyEval_EvalFrameEx + 12731
15  org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
16  org.python.python               0x0000000100eaee1b PyEval_EvalCode + 54
17  org.python.python               0x0000000100ec3d26 PyImport_ExecCodeModuleEx + 241
18  org.python.python               0x0000000100ec69c6 load_source_module + 1089
19  org.python.python               0x0000000100ec7472 import_submodule + 270
20  org.python.python               0x0000000100ec729e ensure_fromlist + 330
21  org.python.python               0x0000000100ec507a PyImport_ImportModuleLevel + 639
22  org.python.python               0x0000000100eaaa1f builtin___import__ + 135
23  org.python.python               0x0000000100e3623f PyObject_Call + 99
24  org.python.python               0x0000000100eb514e PyEval_CallObjectWithKeywords + 93
25  org.python.python               0x0000000100eb14e4 PyEval_EvalFrameEx + 7970
26  org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
27  org.python.python               0x0000000100eaee1b PyEval_EvalCode + 54
28  org.python.python               0x0000000100ec3d26 PyImport_ExecCodeModuleEx + 241
29  org.python.python               0x0000000100ec69c6 load_source_module + 1089
30  org.python.python               0x0000000100ec7472 import_submodule + 270
31  org.python.python               0x0000000100ec729e ensure_fromlist + 330
32  org.python.python               0x0000000100ec507a PyImport_ImportModuleLevel + 639
33  org.python.python               0x0000000100eaaa1f builtin___import__ + 135
34  org.python.python               0x0000000100e3623f PyObject_Call + 99
35  org.python.python               0x0000000100eb514e PyEval_CallObjectWithKeywords + 93
36  org.python.python               0x0000000100eb14e4 PyEval_EvalFrameEx + 7970
37  org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
38  org.python.python               0x0000000100eaee1b PyEval_EvalCode + 54
39  org.python.python               0x0000000100ec3d26 PyImport_ExecCodeModuleEx + 241
40  org.python.python               0x0000000100ec69c6 load_source_module + 1089
41  org.python.python               0x0000000100ec7472 import_submodule + 270
42  org.python.python               0x0000000100ec7035 load_next + 284
43  org.python.python               0x0000000100ec4fc0 PyImport_ImportModuleLevel + 453
44  org.python.python               0x0000000100eaaa1f builtin___import__ + 135
45  org.python.python               0x0000000100e3623f PyObject_Call + 99
46  org.python.python               0x0000000100eb514e PyEval_CallObjectWithKeywords + 93
47  org.python.python               0x0000000100eb14e4 PyEval_EvalFrameEx + 7970
48  org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
49  org.python.python               0x0000000100eaee1b PyEval_EvalCode + 54
50  org.python.python               0x0000000100ec3d26 PyImport_ExecCodeModuleEx + 241
51  org.python.python               0x0000000100ec69c6 load_source_module + 1089
52  org.python.python               0x0000000100ec6c87 load_package + 303
53  org.python.python               0x0000000100ec7472 import_submodule + 270
54  org.python.python               0x0000000100ec7070 load_next + 343
55  org.python.python               0x0000000100ec4fc0 PyImport_ImportModuleLevel + 453
56  org.python.python               0x0000000100eaaa1f builtin___import__ + 135
57  org.python.python               0x0000000100e3623f PyObject_Call + 99
58  org.python.python               0x0000000100eb514e PyEval_CallObjectWithKeywords + 93
59  org.python.python               0x0000000100eb14e4 PyEval_EvalFrameEx + 7970
60  org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
61  org.python.python               0x0000000100eaee1b PyEval_EvalCode + 54
62  org.python.python               0x0000000100ec3d26 PyImport_ExecCodeModuleEx + 241
63  org.python.python               0x0000000100ec69c6 load_source_module + 1089
64  org.python.python               0x0000000100ec7472 import_submodule + 270
65  org.python.python               0x0000000100ec7035 load_next + 284
66  org.python.python               0x0000000100ec4fc0 PyImport_ImportModuleLevel + 453
67  org.python.python               0x0000000100eaaa1f builtin___import__ + 135
68  org.python.python               0x0000000100e3623f PyObject_Call + 99
69  org.python.python               0x0000000100eb514e PyEval_CallObjectWithKeywords + 93
70  org.python.python               0x0000000100eb14e4 PyEval_EvalFrameEx + 7970
71  org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
72  org.python.python               0x0000000100eaee1b PyEval_EvalCode + 54
73  org.python.python               0x0000000100ec3d26 PyImport_ExecCodeModuleEx + 241
74  org.python.python               0x0000000100ec69c6 load_source_module + 1089
75  org.python.python               0x0000000100ec7472 import_submodule + 270
76  org.python.python               0x0000000100ec7035 load_next + 284
77  org.python.python               0x0000000100ec4fc0 PyImport_ImportModuleLevel + 453
78  org.python.python               0x0000000100eaaa1f builtin___import__ + 135
79  org.python.python               0x0000000100e3623f PyObject_Call + 99
80  org.python.python               0x0000000100eb514e PyEval_CallObjectWithKeywords + 93
81  org.python.python               0x0000000100eb14e4 PyEval_EvalFrameEx + 7970
82  org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
83  org.python.python               0x0000000100eaee1b PyEval_EvalCode + 54
84  org.python.python               0x0000000100ec3d26 PyImport_ExecCodeModuleEx + 241
85  org.python.python               0x0000000100ec69c6 load_source_module + 1089
86  org.python.python               0x0000000100ec6c87 load_package + 303
87  org.python.python               0x0000000100ec7472 import_submodule + 270
88  org.python.python               0x0000000100ec7035 load_next + 284
89  org.python.python               0x0000000100ec4fc0 PyImport_ImportModuleLevel + 453
90  org.python.python               0x0000000100eaaa1f builtin___import__ + 135
91  org.python.python               0x0000000100e3623f PyObject_Call + 99
92  org.python.python               0x0000000100eb514e PyEval_CallObjectWithKeywords + 93
93  org.python.python               0x0000000100eb14e4 PyEval_EvalFrameEx + 7970
94  org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
95  org.python.python               0x0000000100e541e9 function_call + 352
96  org.python.python               0x0000000100e3623f PyObject_Call + 99
97  org.python.python               0x0000000100eb1d3d PyEval_EvalFrameEx + 10107
98  org.python.python               0x0000000100eb59f1 fast_function + 262
99  org.python.python               0x0000000100eb277d PyEval_EvalFrameEx + 12731
100 org.python.python               0x0000000100eb59f1 fast_function + 262
101 org.python.python               0x0000000100eb277d PyEval_EvalFrameEx + 12731
102 org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
103 org.python.python               0x0000000100eaee1b PyEval_EvalCode + 54
104 org.python.python               0x0000000100ecec3a run_mod + 53
105 org.python.python               0x0000000100ececdd PyRun_FileExFlags + 133
106 org.python.python               0x0000000100ece81d PyRun_SimpleFileExFlags + 711
107 org.python.python               0x0000000100ee00cd Py_Main + 3057
108 libdyld.dylib                   0x00007fff8be805c9 start + 1

Thread 1:
0   libsystem_kernel.dylib          0x00007fff819933fa __select + 10
1   core.so                         0x0000000101c16039 ev_run + 1577
2   core.so                         0x0000000101c35551 __pyx_pw_6gevent_4core_4loop_15run + 401
3   org.python.python               0x0000000100eb2b8f PyEval_EvalFrameEx + 13773
4   org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
5   org.python.python               0x0000000100e541e9 function_call + 352
6   org.python.python               0x0000000100e3623f PyObject_Call + 99
7   org.python.python               0x0000000100e410c5 instancemethod_call + 174
8   org.python.python               0x0000000100e3623f PyObject_Call + 99
9   org.python.python               0x0000000100eb514e PyEval_CallObjectWithKeywords + 93
10  greenlet.so                     0x000000010171e96f g_initialstub + 1119
11  greenlet.so                     0x000000010171dfbd g_switch + 333
12  greenlet.so                     0x000000010171f1b6 green_switch + 22
13  org.python.python               0x0000000100e3623f PyObject_Call + 99
14  org.python.python               0x0000000100eb514e PyEval_CallObjectWithKeywords + 93
15  org.python.python               0x0000000100e47925 methoddescr_call + 134
16  org.python.python               0x0000000100e3623f PyObject_Call + 99
17  org.python.python               0x0000000100eb2085 PyEval_EvalFrameEx + 10947
18  org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
19  org.python.python               0x0000000100eb5960 fast_function + 117
20  org.python.python               0x0000000100eb277d PyEval_EvalFrameEx + 12731
21  org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
22  org.python.python               0x0000000100eb5960 fast_function + 117
23  org.python.python               0x0000000100eb277d PyEval_EvalFrameEx + 12731
24  org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
25  org.python.python               0x0000000100eb5960 fast_function + 117
26  org.python.python               0x0000000100eb277d PyEval_EvalFrameEx + 12731
27  org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
28  org.python.python               0x0000000100eb5960 fast_function + 117
29  org.python.python               0x0000000100eb277d PyEval_EvalFrameEx + 12731
30  org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
31  org.python.python               0x0000000100e541e9 function_call + 352
32  org.python.python               0x0000000100e3623f PyObject_Call + 99
33  org.python.python               0x0000000100eb1d3d PyEval_EvalFrameEx + 10107
34  org.python.python               0x0000000100eb59f1 fast_function + 262
35  org.python.python               0x0000000100eb277d PyEval_EvalFrameEx + 12731
36  org.python.python               0x0000000100eb59f1 fast_function + 262
37  org.python.python               0x0000000100eb277d PyEval_EvalFrameEx + 12731
38  org.python.python               0x0000000100eaf390 PyEval_EvalCodeEx + 1391
39  org.python.python               0x0000000100e541e9 function_call + 352
40  org.python.python               0x0000000100e3623f PyObject_Call + 99
41  org.python.python               0x0000000100e410c5 instancemethod_call + 174
42  org.python.python               0x0000000100e3623f PyObject_Call + 99
43  org.python.python               0x0000000100eb514e PyEval_CallObjectWithKeywords + 93
44  org.python.python               0x0000000100ee1e1a t_bootstrap + 70
45  libsystem_pthread.dylib         0x00007fff8e17c268 _pthread_body + 131
46  libsystem_pthread.dylib         0x00007fff8e17c1e5 _pthread_start + 176
47  libsystem_pthread.dylib         0x00007fff8e17a41d thread_start + 13

Thread 0 crashed with X86 Thread State (64-bit):
  rax: 0x0000000000000000  rbx: 0x0000000000000020  rcx: 0x0000000101e5c2a8  rdx: 0x0000000000000004
  rdi: 0x00000001021557ec  rsi: 0x0000000000000020  rbp: 0x00007fff5edd91f0  rsp: 0x00007fff5edd91b0
   r8: 0x00007fff5edd9330   r9: 0x0000000000000004  r10: 0x00007fff5edd9150  r11: 0x00007fff861b6610
  r12: 0x000000000000001f  r13: 0x0000000000000003  r14: 0x0000000043dadc20  r15: 0x00000001021557ec
  rip: 0x00007fff861b6686  rfl: 0x0000000000010207  cr2: 0x0000000043dadc2c

Logical CPU:     4
Error Code:      0x00000004
Trap Number:     14


Binary Images:
       0x100e23000 -        0x100e24fff +org.python.python (2.7.9 - 2.7.9) <F264B7B1-8066-35A8-9F34-643ABEB8C792> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python
       0x100e2c000 -        0x100f1cfe7 +org.python.python (2.7.9, [c] 2004-2014 Python Software Foundation. - 2.7.9) <987E90E8-F116-39F2-A7BD-B50F03147C78> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/Python
       0x1010f9000 -        0x1010fbfff +_locale.so (0) <8A95E5BA-769D-3F30-BA65-7F3585681EC0> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_locale.so
       0x1011be000 -        0x1011c1fff +_collections.so (0) <8EB4272C-ADD9-376D-89F6-E82BCFBD5273> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_collections.so
       0x1011c6000 -        0x1011c9fff +operator.so (0) <E29E5DDD-6D79-3AA4-9590-593DF4BD0C2E> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/operator.so
       0x1011cf000 -        0x1011d4fff +itertools.so (0) <7DD057B4-BAB9-3245-887A-C6498A59409D> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/itertools.so
       0x1011dd000 -        0x1011defff +_heapq.so (0) <C449CC52-FDC8-377F-B397-6F608A282A4E> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_heapq.so
       0x101222000 -        0x101225fff +strop.so (0) <C787DD77-526B-3251-92CD-4A309CB19617> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/strop.so
       0x101229000 -        0x10122afff +_functools.so (0) <BFE3AC2B-492A-3D8F-9C64-B48A9A3BDCB8> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_functools.so
       0x10122d000 -        0x101230fff +_struct.so (0) <925DA9D5-E3C0-3091-A429-B1BFD564BA82> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_struct.so
       0x101236000 -        0x101237fff +time.so (0) <03F1719B-B474-3E05-9F57-00CCCEDF2C95> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/time.so
       0x10133d000 -        0x10133efff +cStringIO.so (0) <B428C31E-4BB2-3433-ABAF-72DD848CA367> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/cStringIO.so
       0x1013c3000 -        0x1013ccff7 +datetime.so (0) <DAC9B6B7-812F-3B63-A6B7-08B8D3705B3D> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/datetime.so
       0x1013d5000 -        0x1013e4fff +_io.so (0) <9EBD7A8A-5006-3B27-AE13-89BF5798AA63> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_io.so
       0x101435000 -        0x101436fff +grp.so (0) <A89F306C-F58B-30D8-9422-3B12AE300D89> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/grp.so
       0x101479000 -        0x10147cfff +math.so (0) <E5EC0D13-E47C-3AE6-A47D-F704F515F52B> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/math.so
       0x101481000 -        0x101484ff7 +binascii.so (0) <2F265724-1568-3C06-BBD2-EE6C8EAA0E28> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/binascii.so
       0x101487000 -        0x101489fff +_hashlib.so (0) <80A7B290-F99B-3DE4-92AA-8BBEB59AE15D> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_hashlib.so
       0x10148d000 -        0x1014cafff +libssl.1.0.0.dylib (0) <744C7DDF-7960-3BEF-B4FB-510B1E293D33> /usr/local/opt/openssl/lib/libssl.1.0.0.dylib
       0x1014e6000 -        0x10165649f +libcrypto.1.0.0.dylib (0) <4EA19050-1F9F-3797-A385-B52C85A5AEA5> /usr/local/opt/openssl/lib/libcrypto.1.0.0.dylib
       0x1016cd000 -        0x1016ceff7 +_random.so (0) <69EE1542-DAE0-3E72-9360-1F54DE790979> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_random.so
       0x1016d1000 -        0x1016d2fff +fcntl.so (0) <673AE38D-C24D-3C29-B857-AE3E250A8C21> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/fcntl.so
       0x101715000 -        0x101717fff +select.so (0) <852779D0-66FA-307C-9CDC-9FD7E2D3C15A> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/select.so
       0x10171c000 -        0x10171fff7 +greenlet.so (0) <BAA3C12C-DABD-3726-9ED6-9EFA741EA33D> /usr/local/lib/python2.7/site-packages/greenlet.so
       0x101724000 -        0x10172bff7 +_socket.so (0) <FF432116-5F59-3B1B-A4FE-D437B9FE9612> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_socket.so
       0x101735000 -        0x10173ffff +_ssl.so (0) <6946CFF5-9E76-3FB2-92CF-486F63AA624F> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_ssl.so
       0x101c0c000 -        0x101c10fff +_json.so (0) <F6AD5028-9E46-3D7D-835C-4420F5BFB3CE> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_json.so
       0x101c14000 -        0x101c42fff +core.so (0) <AC868E4F-658B-3B55-A10E-54CFB03CC675> /usr/local/lib/python2.7/site-packages/gevent/core.so
       0x101cab000 -        0x101caffff +array.so (0) <1003FA85-4BEF-3D68-9772-870715A355EB> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/array.so
       0x101cb5000 -        0x101cb5fff +_bisect.so (0) <101BCF87-6672-306F-9D44-276F685DCE28> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_bisect.so
       0x101cf8000 -        0x101cf9fff +_scproxy.so (0) <5129B14D-D510-3EB4-9E11-0192C5BD99CA> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_scproxy.so
       0x101cfc000 -        0x101d05fff +_packer.so (0) <018A3325-5422-3756-8A91-38C0F3E0AA61> /usr/local/lib/python2.7/site-packages/msgpack/_packer.so
       0x101d0e000 -        0x101d1aff7 +_unpacker.so (0) <9B288363-E2AB-34C0-A365-E5E2A758223B> /usr/local/lib/python2.7/site-packages/msgpack/_unpacker.so
       0x101d67000 -        0x101d6ffff +_sqlite3.so (0) <09534389-FE54-3468-9948-E5698F6203F6> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_sqlite3.so
       0x101d79000 -        0x101e14fff +libsqlite3.0.dylib (0) <F815A05C-AA24-3D83-A424-E50067FB544C> /usr/local/opt/sqlite/lib/libsqlite3.0.dylib
       0x101e2b000 -        0x101e36fff +_semaphore.so (0) <A4417CCE-B750-3C80-9A3A-49432ACCB0CA> /usr/local/lib/python2.7/site-packages/gevent/_semaphore.so
       0x101e82000 -        0x101e91fff +_ctypes.so (0) <2BC5BD09-3300-3DEC-B086-549BFBE8CE39> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_ctypes.so
       0x101e9d000 -        0x101ee5ff7 +libsodium.so (???) <78068916-2655-3D2C-84D3-6D8779768D40> /usr/local/lib/python2.7/site-packages/zmq/libsodium.so
       0x101f11000 -        0x101f5aff7 +libzmq.so (???) <4C801576-2F08-3EAB-8FB0-16BBD175066D> /usr/local/lib/python2.7/site-packages/zmq/libzmq.so
       0x101fa0000 -        0x101fa6ff7 +constants.so (???) <3583DCD8-DA51-3B21-B0B0-854262C86BD9> /usr/local/lib/python2.7/site-packages/zmq/backend/cython/constants.so
       0x101fb1000 -        0x101fb2ff7 +error.so (???) <A7B48F7C-8F9A-3ADD-9A75-2A8AB2AD30D2> /usr/local/lib/python2.7/site-packages/zmq/backend/cython/error.so
       0x101fb6000 -        0x101fbffff +message.so (???) <A2C9B9C9-02ED-3456-B7FB-9FCA8053F6B1> /usr/local/lib/python2.7/site-packages/zmq/backend/cython/message.so
       0x101fc9000 -        0x101fceff7 +context.so (???) <84B30D26-C653-3D4C-B59C-34475160E741> /usr/local/lib/python2.7/site-packages/zmq/backend/cython/context.so
       0x101fd6000 -        0x101fe6fff +socket.so (???) <130292C6-3079-329D-B974-10C612A9071C> /usr/local/lib/python2.7/site-packages/zmq/backend/cython/socket.so
       0x101ff4000 -        0x101ffffff +cPickle.so (0) <9005419F-9FD4-3186-9D4D-FF3BDB1FA567> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/cPickle.so
       0x102005000 -        0x102008fff +utils.so (???) <89E315DE-8DEE-3624-B537-E809A1FEB1BF> /usr/local/lib/python2.7/site-packages/zmq/backend/cython/utils.so
       0x10200e000 -        0x102013fff +_poll.so (???) <4DAE65F7-C800-3181-A4A0-9BF08370BBFD> /usr/local/lib/python2.7/site-packages/zmq/backend/cython/_poll.so
       0x102019000 -        0x10201afff +_version.so (???) <7A52950F-05D6-3182-84EC-8084668B928E> /usr/local/lib/python2.7/site-packages/zmq/backend/cython/_version.so
       0x10201e000 -        0x102022ff7 +_device.so (???) <77A0F31C-3060-3856-B6BD-3B67A13368D5> /usr/local/lib/python2.7/site-packages/zmq/backend/cython/_device.so
       0x1020a7000 -        0x1020aafff +_multiprocessing.so (0) <4562255A-4688-351B-8905-7E8CC288C93C> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_multiprocessing.so
       0x1020ae000 -        0x1020b2ff7 +monitoredqueue.so (???) <798691A8-05F5-302B-A104-2B73C92E01FA> /usr/local/lib/python2.7/site-packages/zmq/devices/monitoredqueue.so
       0x102179000 -        0x1021afff7  libssl.dylib (52.20.2) <CF2F5CC1-A72E-3ECF-8F98-330ABABBAFD1> /usr/lib/libssl.dylib
    0x7fff66cf6000 -     0x7fff66d2c837  dyld (353.2.1) <65DCCB06-339C-3E25-9702-600A28291D0E> /usr/lib/dyld
    0x7fff8142e000 -     0x7fff81474ff7  libauto.dylib (186) <A260789B-D4D8-316A-9490-254767B8A5F1> /usr/lib/libauto.dylib
    0x7fff8197d000 -     0x7fff8199afff  libsystem_kernel.dylib (2782.20.48) <EAFD7BD0-0C30-3E7D-9528-F9916BA0167C> /usr/lib/system/libsystem_kernel.dylib
    0x7fff81a3f000 -     0x7fff81a46ff7  libcompiler_rt.dylib (35) <BF8FC133-EE10-3DA6-9B90-92039E28678F> /usr/lib/system/libcompiler_rt.dylib
    0x7fff81e37000 -     0x7fff81e48fff  libsystem_coretls.dylib (35.20.2) <6084A531-2523-39F8-B030-811FA1A32FB5> /usr/lib/system/libsystem_coretls.dylib
    0x7fff828f1000 -     0x7fff828f6ff7  libmacho.dylib (862) <126CA2ED-DE91-308F-8881-B9DAEC3C63B6> /usr/lib/system/libmacho.dylib
    0x7fff829ea000 -     0x7fff829f2ffb  libcopyfile.dylib (118.1.2) <0C68D3A6-ACDD-3EF3-991A-CC82C32AB836> /usr/lib/system/libcopyfile.dylib
    0x7fff83289000 -     0x7fff8348346f  libobjc.A.dylib (647) <759E155D-BC42-3D4E-869B-6F57D477177C> /usr/lib/libobjc.A.dylib
    0x7fff83484000 -     0x7fff83669ff7  libicucore.A.dylib (531.48) <3CD34752-B1F9-31D2-865D-B5B0F0BE3111> /usr/lib/libicucore.A.dylib
    0x7fff83823000 -     0x7fff83828fff  libsystem_stats.dylib (163.20.16) <FBC3F80F-A0FB-3BD6-9A7E-800DE45F092E> /usr/lib/system/libsystem_stats.dylib
    0x7fff83e99000 -     0x7fff83eafff7  libsystem_asl.dylib (267) <F153AC5B-0542-356E-88C8-20A62CA704E2> /usr/lib/system/libsystem_asl.dylib
    0x7fff85740000 -     0x7fff85742fff  libquarantine.dylib (76.20.1) <7AF90041-2768-378A-925A-D83161863642> /usr/lib/system/libquarantine.dylib
    0x7fff85743000 -     0x7fff85747fff  libcache.dylib (69) <45E9A2E7-99C4-36B2-BEE3-0C4E11614AD1> /usr/lib/system/libcache.dylib
    0x7fff857f7000 -     0x7fff85b8fff7  com.apple.CoreFoundation (6.9 - 1153.18) <5C0892B8-9691-341F-9279-CA3A74D59AA0> /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation
    0x7fff86146000 -     0x7fff86171fff  libc++abi.dylib (125) <88A22A0F-87C6-3002-BFBA-AC0F2808B8B9> /usr/lib/libc++abi.dylib
    0x7fff86198000 -     0x7fff8627cfff  libcrypto.0.9.8.dylib (52.20.2) <977DA067-2588-3BF8-A7B2-F08FC6E9088F> /usr/lib/libcrypto.0.9.8.dylib
    0x7fff8642d000 -     0x7fff86455fff  libxpc.dylib (559.20.9) <D35D0DB2-D7BD-3BE4-8378-062BFE545E1D> /usr/lib/system/libxpc.dylib
    0x7fff86456000 -     0x7fff86466ff7  libbsm.0.dylib (34) <A3A2E56C-2B65-37C7-B43A-A1F926E1A0BB> /usr/lib/libbsm.0.dylib
    0x7fff86eba000 -     0x7fff86eeafff  libsystem_m.dylib (3086.1) <1E12AB45-6D96-36D0-A226-F24D9FB0D9D6> /usr/lib/system/libsystem_m.dylib
    0x7fff876fc000 -     0x7fff87724fff  libsystem_info.dylib (459.20.1) <AEB3FE62-4763-3050-8352-D6F9AF961AE6> /usr/lib/system/libsystem_info.dylib
    0x7fff87b78000 -     0x7fff87b7dff7  libunwind.dylib (35.3) <BE7E51A0-B6EA-3A54-9CCA-9D88F683A6D6> /usr/lib/system/libunwind.dylib
    0x7fff87bba000 -     0x7fff87bbbfff  com.apple.TrustEvaluationAgent (2.0 - 25) <2D61A2C3-C83E-3A3F-8EC1-736DBEC250AB> /System/Library/PrivateFrameworks/TrustEvaluationAgent.framework/Versions/A/TrustEvaluationAgent
    0x7fff88a57000 -     0x7fff88a59fff  libsystem_configuration.dylib (699.1.5) <20F3B077-179D-3CB0-A3C1-C8602D53B4DB> /usr/lib/system/libsystem_configuration.dylib
    0x7fff8923c000 -     0x7fff89290fff  libc++.1.dylib (120) <1B9530FD-989B-3174-BB1C-BDC159501710> /usr/lib/libc++.1.dylib
    0x7fff8a381000 -     0x7fff8a381ff7  libunc.dylib (29) <5676F7EA-C1DF-329F-B006-D2C3022B7D70> /usr/lib/system/libunc.dylib
    0x7fff8a47c000 -     0x7fff8a4b4fff  libsystem_network.dylib (412.20.3) <589A5F67-BE2A-3245-A181-0ECC9B53EB00> /usr/lib/system/libsystem_network.dylib
    0x7fff8ae50000 -     0x7fff8ae51ff7  libsystem_blocks.dylib (65) <9615D10A-FCA7-3BE4-AA1A-1B195DACE1A1> /usr/lib/system/libsystem_blocks.dylib
    0x7fff8afbb000 -     0x7fff8afc1fff  libsystem_trace.dylib (72.20.1) <840F5301-B55A-3078-90B9-FEFFD6CD741A> /usr/lib/system/libsystem_trace.dylib
    0x7fff8afc2000 -     0x7fff8afcafff  libsystem_dnssd.dylib (561.1.1) <62B70ECA-E40D-3C63-896E-7F00EC386DDB> /usr/lib/system/libsystem_dnssd.dylib
    0x7fff8afe6000 -     0x7fff8afecff7  libsystem_networkextension.dylib (167.1.10) <29AB225B-D7FB-30ED-9600-65D44B9A9442> /usr/lib/system/libsystem_networkextension.dylib
    0x7fff8aff9000 -     0x7fff8b048ff7  libstdc++.6.dylib (104.1) <803F6AC8-87DC-3E24-9E80-729B551F6FFF> /usr/lib/libstdc++.6.dylib
    0x7fff8be7d000 -     0x7fff8be80ff7  libdyld.dylib (353.2.1) <9EACCA38-291D-38CC-811F-7E9D1451E2D3> /usr/lib/system/libdyld.dylib
    0x7fff8d8f2000 -     0x7fff8d903ff7  libz.1.dylib (55) <88C7C7DE-04B8-316F-8B74-ACD9F3DE1AA1> /usr/lib/libz.1.dylib
    0x7fff8d904000 -     0x7fff8d97afe7  libcorecrypto.dylib (233.1.2) <E1789801-3985-3949-B736-6B3378873301> /usr/lib/system/libcorecrypto.dylib
    0x7fff8e179000 -     0x7fff8e182fff  libsystem_pthread.dylib (105.10.1) <3103AA7F-3BAE-3673-9649-47FFD7E15C97> /usr/lib/system/libsystem_pthread.dylib
    0x7fff8e1e0000 -     0x7fff8e1e1fff  libsystem_secinit.dylib (18) <581DAD0F-6B63-3A48-B63B-917AF799ABAA> /usr/lib/system/libsystem_secinit.dylib
    0x7fff8e71f000 -     0x7fff8e71fff7  liblaunch.dylib (559.20.9) <FA89A113-696E-3271-8FE1-A0D7324E8481> /usr/lib/system/liblaunch.dylib
    0x7fff8e720000 -     0x7fff8e72bfff  libcommonCrypto.dylib (60061) <D381EBC6-69D8-31D3-8084-5A80A32CB748> /usr/lib/system/libcommonCrypto.dylib
    0x7fff8ebac000 -     0x7fff8ebc8ff7  libsystem_malloc.dylib (53.1.1) <19BCC257-5717-3502-A71F-95D65AFA861B> /usr/lib/system/libsystem_malloc.dylib
    0x7fff8f08c000 -     0x7fff8f08efff  libsystem_sandbox.dylib (358.20.5) <4CF77128-6BE0-3958-B646-707FA9CE61B2> /usr/lib/system/libsystem_sandbox.dylib
    0x7fff8f271000 -     0x7fff8f29bff7  libdispatch.dylib (442.1.4) <502CF32B-669B-3709-8862-08188225E4F0> /usr/lib/system/libdispatch.dylib
    0x7fff8f505000 -     0x7fff8f50dfff  libsystem_platform.dylib (63) <64E34079-D712-3D66-9CE2-418624A5C040> /usr/lib/system/libsystem_platform.dylib
    0x7fff8fcae000 -     0x7fff8fcb0ff7  libsystem_coreservices.dylib (9) <41B7C578-5A53-31C8-A96F-C73E030B0938> /usr/lib/system/libsystem_coreservices.dylib
    0x7fff8fd91000 -     0x7fff8fd92ff3  libSystem.B.dylib (1213) <CCEC13A5-D0D9-31C5-B0B0-1C564B4A20A6> /usr/lib/libSystem.B.dylib
    0x7fff8fd93000 -     0x7fff8fd94ffb  libremovefile.dylib (35) <3485B5F4-6CE8-3C62-8DFD-8736ED6E8531> /usr/lib/system/libremovefile.dylib
    0x7fff8fdd5000 -     0x7fff8fddeff7  libsystem_notify.dylib (133.1.1) <61147800-F320-3DAA-850C-BADF33855F29> /usr/lib/system/libsystem_notify.dylib
    0x7fff90333000 -     0x7fff903bfff7  libsystem_c.dylib (1044.10.1) <86FBED7A-F2C8-3591-AD6F-486DD57E6B6A> /usr/lib/system/libsystem_c.dylib
    0x7fff905f0000 -     0x7fff905f0ff7  libkeymgr.dylib (28) <77845842-DE70-3CC5-BD01-C3D14227CED5> /usr/lib/system/libkeymgr.dylib
    0x7fff90930000 -     0x7fff909a8ff7  com.apple.SystemConfiguration (1.14 - 1.14) <06A8405D-53BA-30A9-BA8A-222099176091> /System/Library/Frameworks/SystemConfiguration.framework/Versions/A/SystemConfiguration
    0x7fff90e90000 -     0x7fff90e91fff  libDiagnosticMessagesClient.dylib (100) <2EE8E436-5CDC-34C5-9959-5BA218D507FB> /usr/lib/libDiagnosticMessagesClient.dylib

External Modification Summary:
  Calls made by other processes targeting this process:
    task_for_pid: 0
    thread_create: 0
    thread_set_state: 0
  Calls made by this process:
    task_for_pid: 0
    thread_create: 0
    thread_set_state: 0
  Calls made by all processes on this machine:
    task_for_pid: 5698
    thread_create: 0
    thread_set_state: 0

VM Region Summary:
ReadOnly portion of Libraries: Total=90.9M resident=140.2M(154%) swapped_out_or_unallocated=16777216.0T(19350346006528%)
Writable regions: Total=56.5M written=10.4M(18%) resident=13.5M(24%) swapped_out=0K(0%) unallocated=43.0M(76%)

REGION TYPE                      VIRTUAL
===========                      =======
Kernel Alloc Once                     4K
MALLOC                             43.6M
MALLOC (admin)                       16K
STACK GUARD                        56.0M
Stack                              12.0M
VM_ALLOCATE                          16K
__DATA                             2396K
__LINKEDIT                         72.6M
__TEXT                             18.3M
__UNICODE                           552K
shared memory                         4K
===========                      =======
TOTAL                             205.5M

Model: MacBookPro11,3, BootROM MBP112.0138.B14, 4 processors, Intel Core i7, 2.3 GHz, 16 GB, SMC 2.19f12
Graphics: Intel Iris Pro, Intel Iris Pro, Built-In
Graphics: NVIDIA GeForce GT 750M, NVIDIA GeForce GT 750M, PCIe, 2048 MB
Memory Module: BANK 0/DIMM0, 8 GB, DDR3, 1600 MHz, 0x02FE, -
Memory Module: BANK 1/DIMM0, 8 GB, DDR3, 1600 MHz, 0x02FE, -
AirPort: spairport_wireless_card_type_airport_extreme (0x14E4, 0x134), Broadcom BCM43xx 1.0 (7.15.166.24.3)
Bluetooth: Version 4.3.4f4 15601, 3 services, 27 devices, 1 incoming serial ports
Network Service: Wi-Fi, AirPort, en0
Serial ATA Device: APPLE SSD SM0512F, 500.28 GB
USB Device: Internal Memory Card Reader
USB Device: BRCM20702 Hub
USB Device: Bluetooth USB Host Controller
USB Device: Apple Internal Keyboard / Trackpad
Thunderbolt Bus: MacBook Pro, Apple Inc., 17.1
```
 That seemed to do the trick. Why does the segmentation fault occur though? OpenSSL is installed (OpenSSL 0.9.8zd 8 Jan 2015 - According to `openssl version`). Is it a problem with the version of OpenSSL that Apple ships? Could re-compilling OpenSSL potentially fix this?
 I followed the instructions here: http://apple.stackexchange.com/questions/126830/how-to-upgrade-openssl-in-os-x (Selected answer) but this did not resolve the problem.  

```
$ openssl version -a

OpenSSL 1.0.2a 19 Mar 2015
built on: reproducible build, date unspecified
platform: darwin64-x86_64-cc
options:  bn(64,64) rc4(ptr,int) des(idx,cisc,16,int) idea(int) blowfish(idx)
compiler: clang -I. -I.. -I../include  -fPIC -fno-common -DOPENSSL_PIC -DZLIB_SHARED -DZLIB -   DOPENSSL_THREADS -D_REENTRANT -DDSO_DLFCN -DHAVE_DLFCN_H -arch x86_64 -O3 -DL_ENDIAN -Wall -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DMD5_ASM -DAES_ASM -DVPAES_ASM -DBSAES_ASM -DWHIRLPOOL_ASM -DGHASH_ASM -DECP_NISTZ256_ASM
OPENSSLDIR: "/usr/local/etc/openssl"
```
 The first one segmentation faults and the second one throws a "symbol not found" error:

```
Aidans-MacBook-Pro:Downloads aidan$ python2 opensslVerify2.py
Openssl version: 0009081DF
Segmentation fault: 11
Aidans-MacBook-Pro:Downloads aidan$ python2 opensslVerify3.py
Traceback (most recent call last):
  File "opensslVerify3.py", line 354, in <module>
    ssl = _OpenSSL(ctypes.util.find_library('ssl') or 'libeay32')
  File "opensslVerify3.py", line 347, in __init__
    self.PKCS5_PBKDF2_HMAC = self._lib.PKCS5_PBKDF2_HMAC
  File "/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ctypes/__init__.py", line 378, in __getattr__
    func = self.__getitem__(name)
  File "/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ctypes/__init__.py", line 383, in __getitem__
    func = self._FuncPtr((name_or_ordinal, self))
AttributeError: dlsym(0x7fa111468110, PKCS5_PBKDF2_HMAC): symbol not found
Aidans-MacBook-Pro:Downloads aidan$ 
```
 This works fine outputting `1N2XWu5soeppX2qUjvrf81rpdbShKJrjTr` to the terminal.
 Looks like the benchmark worked:

```
Benchmarking ZeroNet 0.3.0 (rev193) Python 2.7.9 (default, Apr 13 2015, 19:57:29) [GCC 4.2.1 Compatible Apple LLVM 6.1.0 (clang-602.0.49)], platform: darwin...

CryptBitcoin:
- hdPrivatekey x 10..........0.144s [x4.85: Insane!!]
- sign x 10..........0.076s [x4.60: Insane!!]
- openssl verify x 100..........0.146s [x2.54: WOW]
- pure-python verify x 10..........0.350s [x4.57: Insane!!]

CryptHash:
- sha512 x 10 000..........0.300s [x3.34: WOW]

Db:
- Open x 10..........0.029s [x4.51: Insane!!]
- Insert x 10 x 1000..........0.265s [x3.78: Insane!!]
- Buffered insert x 100 x 100..........0.492s [x2.64: WOW]
- Total rows in db: 20000
- Indexed query x 1000..........0.093s [x2.68: WOW]
- Not indexed query x 100..........0.178s [x3.38: WOW]
- Like query x 100..........0.456s [x3.95: Insane!!]

Done. Total: 2.68s
```

Assuming nobody else has any problems the issue can probably be closed nowâ€¦
  Do you mean that a server runs ZeroNet and allows mobile/similar clients to access ZeroNet through it using auth? Password protected proxy in essence?
 I am getting

    zeronet.py: error: unrecognized arguments: --ui_password mypassword

with v0.5.4.  Should I start a new issue or am I doing it wrong?   You should enable the UiPassword plugin. See plugins folder.  I tried skimming through documentation and source code, but didn't find anything of use.

It would be great to have a simple private key validation method available for the ZeroFrame API, e.g.

```
Site.cmd('wrapperPrompt', ['Please give private key:', 'password'], function(private_key) {
     var privateKeyValid = Site.cmd('validatePrivateKey', private_key, callback);
});
```

There is `siteSign` available, but to my understanding it isn't that usable for "password protected" content and such.
 That works wonders. Thanks for sharing!
  I'm building a ZeroNet blogging platform from scratch using Backbone.js and JSON+Markdown data formats.

I'd like to see more documentation on the ZeroFrame file API and routing, among additions to the code examples provided.

Currently there are copy-pastes CoffeeScript examples available at the documentation page regarding `fileGet` (which I'm using succesfully to read JSON, Markdown and .html template files) and `fileWrite` (which I can't seem to get working properly).

I need to save blog post contents into Markdown files and the post meta (such as date, title, publish status and so on) into a general `posts.json` file. Currently the WebSocket connection is error closed when I'm trying to write a new Markdown file into a site subfolder. Do the files need to exist in the `files` construct of the `content.json` file in order allow `fileWrite` to work properly?

Routing is a bit of a mystery for me in the ZeroFrame API. There is code available in the ZeroBlog source, but I'd like to know how setting the site `iframe`'s URL hash could be propagated to the ZeroFrame and onto the main browser window's URL hash.

Could the documentation be beefed up a bit to include pure JS examples that are not copy-pasted out of context (e.g. containing unknown variables and such)?

All additional information would be awesome. :)
 Oh okay. I created the site on another computer and I'm working on it on my home computer. Great to know! I'll test it out.
   After latest release, the following error is presented after logging in

Server error

Err: AttributeError: 'NoneType' object has no attribute 'group' in UiServer.py line 62 > UiRequest.py line 42 > UiRequestPlugin.py line 20 > UiRequest.py line 200 > UiRequestPlugin.py line 26

![image](https://cloud.githubusercontent.com/assets/6439434/7219440/084c1d08-e66e-11e4-95a8-490318c9feb5.png)
  I am trying to run ZeroNet on Raspberry Pi and I am getting this error! Not sure what to do.

Python version 2.7.3

```
pi@raspberrypi ~/zeronet/ZeroNet $ python zeronet.py
 - Starting ZeroNet...
Traceback (most recent call last):
  File "zeronet.py", line 8, in main
    import main
  File "src/main.py", line 35, in <module>
    from Debug import DebugHook
  File "src/Debug/DebugHook.py", line 1, in <module>
    import gevent, sys, logging
ImportError: No module named gevent
-- Error happened, press enter to close --
Traceback (most recent call last):
  File "zeronet.py", line 40, in <module>
    main()
  File "zeronet.py", line 28, in main
    if main.update_after_shutdown: # Updater
UnboundLocalError: local variable 'main' referenced before assignment

```
 Thanks, kinda works..
Have some other issue now,

```
 - Starting ZeroNet...
[21:48:21] - Version: 0.2.9, Python 2.7.3 (default, Mar 18 2014, 05:13:23)
[GCC 4.6.3], Gevent: 1.0.1
[21:48:22] - Creating UiServer....
[21:48:22] - Creating FileServer....
[21:48:22] - Starting servers....
[21:48:22] Ui.UiServer --------------------------------------
[21:48:22] Ui.UiServer Web interface: http://127.0.0.1:43110/
[21:48:22] Ui.UiServer --------------------------------------
[21:48:23] FileServer Checking port 15441 using canyouseeme.org...
...
...
(15441) Reason: Connection timed out
[21:48:40] FileServer Upnp mapping failed :( Please forward port 15441 on your router to your ipaddress

```
 Great! it works!

Btw, a noob question - what is the use upnp? :)

http://i.imgur.com/wQXBZcW.png
  Can you change zeronet.cmd so than it will update ZeroNet if it finds a new version on github?
 oh, thank you :)
  +1 
this would be really useful.
I checked Chrome extension API, they don't support listening for custom protocol.
 http://*.zero sounds good
 how about? [http://zero/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr](http://zero/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr)

I just finished initial implementation https://github.com/goldenratio/zeronet-protocol-crx

But I have a problem :)
I am able to proxy to my xampp server, example: http://zero/xampp
but for ZeroNet [http://zero/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr](http://zero/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr) it goes ZeroNet's page not found page.

I am running ZeroNet from headless computer. I haven't tested it on localhost.
 ```
[18:05:47] Ui.UiServer 192.168.1.71 - - [2015-04-18 18:05:47] "GET http://zero/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr HTTP/1.1" 404 381 0.012192
```
 ya, agree http://*.zero is better

I am trying to understand why I can't access  [http://zero/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr](http://zero/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr) with the current implementation.

Under --debug flag I see, 
`"GET http://zero/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr HTTP/1.1" 404`

but it seems ZeroNet doesn't expect http://zero in that request.
Not sure how to get rid of it .
 it seems chrome automatically converts uppercase letters to lowercase in URL. duh! :)

for example: 
1GamESVFyJfkmbxtcrLR2VX4m4VFmwyeRY.zero
gets converted
1gamesvfyjfkmbxtcrlr2vx4m4vfmwyery.zero
 btw just noticed,

`if you enter zero/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr in chrome (without http://) it takes you to google search.`

it doesn't take me to google search actually. It works as expected.
 nice!

added .bit to TLD list

also made 127.0.0.1:43110 to go through proxy, if ZeroNet is running on remote machine. Useful for current links out there on the internet (reddit)
 I'm liking the change to ".zerobit" if needed, but the more I think about it, the more I'm a fan of somehow using the protocol layer - zero://.  This would have yet another benefit - we could resolve using TXT records in traditional DNS.  zero://smokingcode.com could do a lookup in DNS for an TXT with a name/value pair for "zero" on smokingcode.com.  .bit would remain .bit and use namecoin d/zeronet entries...
Maybe I'm just thinking too hard here....  But there's gotta be a way to configure a protocol handler, and even have a config to tell it a proxy zeronet to use if desired.
 Currently the extension supports both .zero and .bit TLDs, but it is easier to support more.

Regarding zero:// protocol, Chrome passes  it operating system level. We can listen to it by installing ZeroNet application, similar to what Skype does for Skype:// protocol. But I  not sure how to go back to browser when zero:// protocol is detected. Probably for this reason "project maelstrom" forked Chromium to support custom protocols.
 But I would stick with http://zero/site_name 
Less hassel. But zero:// protocol should be preffered,  but would require some work.. Probably fork Chromium.
 ya, right. Done
 done, https://chrome.google.com/webstore/detail/zeronet-protocol/cpkpdcdljfbnepgfejplkhdnopniieop
 .bit + prefer (clear|zero)net sounds like the best option.
 Perhaps we could use `Navigator.registerProtocolHandler()`? Then, if the server is sent a `zero:` or `zero://` parameter, it just has to parse it and redirect to the final website.

https://developer.mozilla.org/en-US/docs/Web/API/Navigator/registerProtocolHandler
 I am working on some improvements to @goldenratio's plugin and I noticed that several pages, including the welcome page are no longer rendering fully with the plugin when the `http://zero/` or `http://*.bit/` proxies are used.

I also have an idea about getting `http://<hash>.zero` to work. Since the hostname is lowercase, a bitmap can be used to prefix the lowercase hash which marks the characters which should be capitalized. It could look something like this: `http://<hexBitmap>-<hash>.zero/`. I would like to update the plugin so that all pages are redirected to a `.zero` or a `.bit`.

Ultimately, I think using the `zero://` scheme with a custom browser is the best. [I think an Electron app allows for custom schemes.](http://electron.atom.io/docs/api/protocol/) The Brave browser is built on Electron. A custom browser for ZeroNet would be awesome!
 Since ZeroNet is written in Python. We can use [cefpython](https://github.com/cztomczak/cefpython) to make a browser. can firefox do this?
http://kb.mozillazine.org/Register_protocol @HelloZeroNet, I think it is already implemented.  i tried simple dotfile hiding with `\..*` (escaped as `"ignore": "\\..*)"` yet my `.test` file still got served

also the sample from the docs fails for me: `http://localhost:43110/â€¦/css/test.css` was served

OS: win7
Method of installation: ZeroBundle package
 thanks, the part that those files can be accessed locally should be noted in the docs
  Hi there. Any progress on this? This can be used in public gateways. @HelloZeroNet I made a pull request to help in this issue, please, review it. @HelloZeroNet All checks have passed. Not closing because there is need to add tor hidden service check also. @HelloZeroNet Then closing, I think.  I might be able to do some graphics for a video, I'd just need content. Ideas?
 I likely won't be able to do much until a week or so from now, but I'll play around with some ideas. Do you want tutorials for installation, or is it more of just a demonstration (look at this new cool thing)?

I can certainly use the presentation for graphics/theme, thanks!
 The problem is that I don't actually have Windows â€” I'm a mac/linux user. I was thinking I'd just use mockups so that I'm not limited by resolution (I can zoom in on single button or whatever) to show the general process, but there could also be walkthrough videos for specific OSes later on. I was thinking it would be more of an introduction to _what_ ZeroNet is than instructions on how to use it.
 Alright, I've got some time on my hands now, sorry for the long wait.

You're looking for a video demonstrating ZeroNet being installed and working â€” is a screencast fine, or would something a little nicer-looking (UI kits and AE) be preferable?
 Alright. I'm on OS X at the moment and don't have access to a windows machine â€” do you want me to go ahead with the more complex installation process, or should I wait on #133?
 Alright, here's a [first take](https://youtu.be/q7HJ0jDe8-E). I included `git clone`ing the repo, `cd`ing into the folder, and starting zeronet, and then browsing a little. This is rough and in no way complete â€” I'll want to add music, a voiceover, etc. Thoughts? 
 > download process

From zeronet.io, or just from the gh page?
 Oh, ok.
 [Another attempt](https://youtu.be/Ke--PTR105M).
 What are the issues? Perhaps I could help test... Is it an issue of browser width, or is it a mac/windows inconsistency?
 Instead of using a single font, use a font stack: `font-family: Consolas, Monaco, monospace` â€” this should fix the first issue.

In ZeroHello.css, the `margin-bottom` of `h4` can be changed from 19px to 1.45rem, and the `bottom` of `.site .action` can be changed from 21px to 1.64rem. This seems to fixe the second issue, at least on my machine. The issue here was that I was zoomed out, and since most of the values were set in pixels, it didn't scale very well.

Also, would it be possible to add a 32x32px favicon image as well as the 16x16px one for HiDPI displays?
 Congrats! Let me know when think it's ready to be screencast again! 

One little tip: the misaligned site names only appeared when I zoomed out, so make sure to test different zoom levels as well.
  I am asking for ZeroNet to have a bitcoin Blockchain explorer that is able to run on multiple computers or phones sending and receiving say a that is always online and is not able to be shutdown by using its own bitcoin software and nodes it checks with and uses nodes that are posted and tested on something like 

"""Bitnodes is currently being developed to estimate the size of the Bitcoin network by finding all the reachable nodes in the network."""

But this can be on ZeroNet instead of using TLDS and a centralized dns.

This can be expanded for reachable nodes but eventually it acts like a site similar to blockchain.info but with a ZeroNet address instead with a wallet service would be far superior than blockchain.info

Thanks and looking forward to development of this website including wallet that is using peers as hosts instead of a cloud or datacenter!
 Update is you can use name coin and. Bit addresses so the Decentralized Blockchain can be a. Bit address
  @HelloZeroNet, was this already been implemented? Moved to: https://github.com/ZeroNetJS/zeronet-js/issues/49.  the log its self is a bit long so i just copied and pasted what looked like a error
im more of a server and network guy then a coder how ever it kind of looks like a connectoin error

[2015-03-31 08:35:13,290] DEBUG    Site:1TaLk3..sPKQ data/users/1Nzmu4bpM4o8w2pUSx2p59CW5GZZB8vskU/content.json: Downloading 0 includes...
[2015-03-31 08:35:13,291] DEBUG    Site:1TaLk3..sPKQ data/users/1Nzmu4bpM4o8w2pUSx2p59CW5GZZB8vskU/content.json: Includes downloaded
[2015-03-31 08:35:13,292] DEBUG    Site:1TaLk3..sPKQ data/users/1Nzmu4bpM4o8w2pUSx2p59CW5GZZB8vskU/content.json: Downloading 1 files, changed: 0...
[2015-03-31 08:35:13,352] DEBUG    WorkerManager:1TaLk3..sPKQ 198.23.177.55:15441: Hash correct: data/users/15QJoGcY7kCCQn5NK1sgVsCj2nc3McLuNk/data.json
[2015-03-31 08:35:13,356] DEBUG    Site:1TaLk3..sPKQ Loading json file to db: data/users/15QJoGcY7kCCQn5NK1sgVsCj2nc3McLuNk/data.json
[2015-03-31 08:35:13,359] DEBUG    Db:ZeroTalk Connecting (sqlite version: 2.6.0)...
[2015-03-31 08:35:13,360] ERROR    - Unhandled exception
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/Worker/Worker.py", line 58, in downloader
    site.storage.write(task["inner_path"], buff)
  File "src/Site/SiteStorage.py", line 138, in write
    self.getDb().loadJson(file_path)
  File "src/Db/Db.py", line 134, in loadJson
    cur = self.getCursor()
  File "src/Db/Db.py", line 47, in getCursor
    if not self.conn: self.connect()
  File "src/Db/Db.py", line 22, in connect
    self.conn = sqlite3.connect(self.db_path)
OperationalError: unable to open database file
[2015-03-31 08:35:13,394] DEBUG    WorkerManager:1TaLk3..sPKQ 24.108.77.4:15441: Hash correct: data/users/1PTHmbBk2dhkz1ryNcgwNEkKCdpD16ypcu/data.json
[2015-03-31 08:35:13,398] DEBUG    Site:1TaLk3..sPKQ Loading json file to db: data/users/1PTHmbBk2dhkz1ryNcgwNEkKCdpD16ypcu/data.json
[2015-03-31 08:35:13,400] DEBUG    Db:ZeroTalk Connecting (sqlite version: 2.6.0)...
[2015-03-31 08:35:13,401] ERROR    - Unhandled exception
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/Worker/Worker.py", line 58, in downloader
    site.storage.write(task["inner_path"], buff)
  File "src/Site/SiteStorage.py", line 138, in write
    self.getDb().loadJson(file_path)
  File "src/Db/Db.py", line 134, in loadJson
    cur = self.getCursor()
  File "src/Db/Db.py", line 47, in getCursor
    if not self.conn: self.connect()
  File "src/Db/Db.py", line 22, in connect
    self.conn = sqlite3.connect(self.db_path)
OperationalError: unable to open database file
[2015-03-31 08:35:13,414] DEBUG    WorkerManager:1TaLk3..sPKQ 82.230.85.110:15441: Hash correct: data/users/14jGjAV8wrsrmKSZEARS4CnZDD9paMB72S/data.json
[2015-03-31 08:35:13,418] DEBUG    Site:1TaLk3..sPKQ Loading json file to db: data/users/14jGjAV8wrsrmKSZEARS4CnZDD9paMB72S/data.json
[2015-03-31 08:35:13,420] DEBUG    Db:ZeroTalk Connecting (sqlite version: 2.6.0)...
[2015-03-31 08:35:13,421] ERROR    - Unhandled exception
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/Worker/Worker.py", line 58, in downloader
    site.storage.write(task["inner_path"], buff)
  File "src/Site/SiteStorage.py", line 138, in write
    self.getDb().loadJson(file_path)
  File "src/Db/Db.py", line 134, in loadJson
    cur = self.getCursor()
  File "src/Db/Db.py", line 47, in getCursor
    if not self.conn: self.connect()
  File "src/Db/Db.py", line 22, in connect
    self.conn = sqlite3.connect(self.db_path)
OperationalError: unable to open database file
[2015-03-31 08:35:13,434] DEBUG    WorkerManager:1TaLk3..sPKQ 87.121.52.234:15441: Hash correct: data/users/18v4RV7s9kqWT2RAuBm6QktdUK3riW76tp/data.json
[2015-03-31 08:35:13,438] DEBUG    Site:1TaLk3..sPKQ Loading json file to db: data/users/18v4RV7s9kqWT2RAuBm6QktdUK3riW76tp/data.json
[2015-03-31 08:35:13,440] DEBUG    Db:ZeroTalk Connecting (sqlite version: 2.6.0)...
[2015-03-31 08:35:13,441] ERROR    - Unhandled exception
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/Worker/Worker.py", line 58, in downloader
    site.storage.write(task["inner_path"], buff)
  File "src/Site/SiteStorage.py", line 138, in write
    self.getDb().loadJson(file_path)
  File "src/Db/Db.py", line 134, in loadJson
    cur = self.getCursor()
  File "src/Db/Db.py", line 47, in getCursor
    if not self.conn: self.connect()
  File "src/Db/Db.py", line 22, in connect
    self.conn = sqlite3.connect(self.db_path)
OperationalError: unable to open database file
[2015-03-31 08:35:13,454] DEBUG    WorkerManager:1TaLk3..sPKQ 128.204.28.99:15441: Hash correct: data/users/1BZah2BjFd4CanYU4QjwdNbEZXbk9gVs9R/data.json
[2015-03-31 08:35:13,458] DEBUG    Site:1TaLk3..sPKQ Loading json file to db: data/users/1BZah2BjFd4CanYU4QjwdNbEZXbk9gVs9R/data.json
[2015-03-31 08:35:13,460] DEBUG    Db:ZeroTalk Connecting (sqlite version: 2.6.0)...
[2015-03-31 08:35:13,462] ERROR    - Unhandled exception
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/Worker/Worker.py", line 58, in downloader
    site.storage.write(task["inner_path"], buff)
  File "src/Site/SiteStorage.py", line 138, in write
    self.getDb().loadJson(file_path)
  File "src/Db/Db.py", line 134, in loadJson
    cur = self.getCursor()
  File "src/Db/Db.py", line 47, in getCursor
    if not self.conn: self.connect()
  File "src/Db/Db.py", line 22, in connect
    self.conn = sqlite3.connect(self.db_path)
OperationalError: unable to open database file
[2015-03-31 08:35:13,473] DEBUG    Conn#11 178.238.41.134 [v2] Unpacker created
[2015-03-31 08:35:13,475] DEBUG    WorkerManager:1TaLk3..sPKQ 178.238.41.134:15441: Hash correct: data/users/1N1NNMWQ8bfLSHb8YQeyLnvW6NNRYbxDGG/data.json
[2015-03-31 08:35:13,479] DEBUG    Site:1TaLk3..sPKQ Loading json file to db: data/users/1N1NNMWQ8bfLSHb8YQeyLnvW6NNRYbxDGG/data.json
[2015-03-31 08:35:13,481] DEBUG    Db:ZeroTalk Connecting (sqlite version: 2.6.0)...
[2015-03-31 08:35:13,482] ERROR    - Unhandled exception
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/Worker/Worker.py", line 58, in downloader
    site.storage.write(task["inner_path"], buff)
  File "src/Site/SiteStorage.py", line 138, in write
    self.getDb().loadJson(file_path)
  File "src/Db/Db.py", line 134, in loadJson
    cur = self.getCursor()
  File "src/Db/Db.py", line 47, in getCursor
    if not self.conn: self.connect()
  File "src/Db/Db.py", line 22, in connect
    self.conn = sqlite3.connect(self.db_path)
OperationalError: unable to open database file
[2015-03-31 08:35:14,018] DEBUG    WorkerManager:1TaLk3..sPKQ 78.158.149.247:15441: Hash correct: data/users/1753kNUDAzrRLdmv2XVgKUnKqQLgnesVaa/data.json
[2015-03-31 08:35:14,022] DEBUG    Site:1TaLk3..sPKQ Loading json file to db: data/users/1753kNUDAzrRLdmv2XVgKUnKqQLgnesVaa/data.json
[2015-03-31 08:35:14,024] DEBUG    Db:ZeroTalk Connecting (sqlite version: 2.6.0)...
[2015-03-31 08:35:14,026] ERROR    - Unhandled exception
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/Worker/Worker.py", line 58, in downloader
    site.storage.write(task["inner_path"], buff)
  File "src/Site/SiteStorage.py", line 138, in write
    self.getDb().loadJson(file_path)
  File "src/Db/Db.py", line 134, in loadJson
    cur = self.getCursor()
  File "src/Db/Db.py", line 47, in getCursor
    if not self.conn: self.connect()
  File "src/Db/Db.py", line 22, in connect
    self.conn = sqlite3.connect(self.db_path)
OperationalError: unable to open database file
[2015-03-31 08:35:18,683] DEBUG    WorkerManager:1TaLk3..sPKQ 115.205.165.189:15441: Force stopping, thread: <ErrorhookedGreenlet at 0xb4e6507cL: <bound method Worker.downloader of <Worker 1TaLk3..sPKQ 115.205.165.189:15441>>>
[2015-03-31 08:35:18,685] DEBUG    File.FileServer 115.205.165.189 Connect error: Notify: Worker stopped in ConnectionServer.py line 88 > Connection.py line 68 > socket.py line 347 > socket.py line 298 > hub.py line 341 > hub.py line 568 > hub.py line 331
[2015-03-31 08:35:18,687] DEBUG    Peer:115.205.165.189:15441 1TaLk3..sPKQ Getting connection error: Notify: Worker stopped in Peer.py line 40 > ConnectionServer.py line 94 (connection_error: 2, hash_failed: 0)
[2015-03-31 08:35:18,688] DEBUG    Peer:115.205.165.189:15441 1TaLk3..sPKQ Removing peer...Connection error: 3, Hash failed: 0
[2015-03-31 08:35:18,689] DEBUG    WorkerManager:1TaLk3..sPKQ 115.205.165.189:15441: No longer needed, returning: data/users/13NXisQxpmjSgMFSY1rsTfLcwkSX33Uji8/content.json
[2015-03-31 08:35:18,690] DEBUG    WorkerManager:1TaLk3..sPKQ Removed worker, workers: 9/10
[2015-03-31 08:35:18,691] DEBUG    WorkerManager:1TaLk3..sPKQ 82.73.156.95:15441: Force stopping, thread: <ErrorhookedGreenlet at 0xb4e6516cL: <bound method Worker.downloader of <Worker 1TaLk3..sPKQ 82.73.156.95:15441>>>
[2015-03-31 08:35:18,693] DEBUG    File.FileServer 82.73.156.95 Connect error: Notify: Worker stopped in ConnectionServer.py line 88 > Connection.py line 68 > socket.py line 347 > socket.py line 298 > hub.py line 341 > hub.py line 568 > hub.py line 331
[2015-03-31 08:35:18,695] DEBUG    Peer:82.73.156.95:15441 1TaLk3..sPKQ Getting connection error: Notify: Worker stopped in Peer.py line 40 > ConnectionServer.py line 94 (connection_error: 0, hash_failed: 0)
[2015-03-31 08:35:18,696] DEBUG    WorkerManager:1TaLk3..sPKQ 82.73.156.95:15441: No longer needed, returning: data/users/1N1NNMWQ8bfLSHb8YQeyLnvW6NNRYbxDGG/content.json
[2015-03-31 08:35:18,698] DEBUG    WorkerManager:1TaLk3..sPKQ Removed worker, workers: 8/10
[2015-03-31 08:35:18,699] DEBUG    WorkerManager:1TaLk3..sPKQ 212.92.214.123:15441: Force stopping, thread: <ErrorhookedGreenlet at 0xb4e650ccL: <bound method Worker.downloader of <Worker 1TaLk3..sPKQ 212.92.214.123:15441>>>
[2015-03-31 08:35:18,701] DEBUG    File.FileServer 212.92.214.123 Connect error: Notify: Worker stopped in ConnectionServer.py line 88 > Connection.py line 68 > socket.py line 347 > socket.py line 298 > hub.py line 341 > hub.py line 568 > hub.py line 331
[2015-03-31 08:35:18,703] DEBUG    Peer:212.92.214.123:15441 1TaLk3..sPKQ Getting connection error: Notify: Worker stopped in Peer.py line 40 > ConnectionServer.py line 94 (connection_error: 0, hash_failed: 0)
[2015-03-31 08:35:18,704] DEBUG    WorkerManager:1TaLk3..sPKQ 212.92.214.123:15441: No longer needed, returning: data/users/1DKKgeu54B2gb5m1UbK3S1kvrt1BhNRSUm/content.json
[2015-03-31 08:35:18,705] DEBUG    WorkerManager:1TaLk3..sPKQ Removed worker, workers: 7/10
[2015-03-31 08:35:26,043] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:26] "GET /ZeroNetwork.bit HTTP/1.1" 200 1815 0.055441
[2015-03-31 08:35:26,050] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:26] "GET /media/ZeroNetwork.bit/index.html HTTP/1.1" 200 2966 0.004283
[2015-03-31 08:35:26,055] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:26] "GET /uimedia/all.css HTTP/1.1" 200 15856 0.002152
[2015-03-31 08:35:26,057] DEBUG    lib.geventwebsocket.handler Closed WebSocket
[2015-03-31 08:35:26,059] DEBUG    lib.geventwebsocket.handler Failed to write closing frame -> closing socket
[2015-03-31 08:35:26,060] DEBUG    lib.geventwebsocket.handler Closed WebSocket
[2015-03-31 08:35:26,061] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:26] "GET /Websocket?wrapper_key=QAlouWb5wWt8 HTTP/1.1" 101 129 26.638448
[2015-03-31 08:35:26,086] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:26] "GET /media/ZeroNetwork.bit/css/all.css HTTP/1.1" 200 81861 0.012992
[2015-03-31 08:35:26,089] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:26] "GET /media/ZeroNetwork.bit/js/all.js HTTP/1.1" 200 124937 0.024412
[2015-03-31 08:35:26,101] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:26] "GET /uimedia/all.js HTTP/1.1" 200 122305 0.007725
[2015-03-31 08:35:26,144] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-03-31 08:35:26,146] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-03-31 08:35:26,147] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-03-31 08:35:26,148] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-03-31 08:35:26,199] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:26] "GET /media/ZeroNetwork.bit/img/loading.gif HTTP/1.1" 200 1045 0.004177
[2015-03-31 08:35:29,452] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:29] "GET /Board.ZeroNetwork.bit HTTP/1.1" 200 1820 0.056671
[2015-03-31 08:35:29,459] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:29] "GET /media/Board.ZeroNetwork.bit/index.html HTTP/1.1" 200 1435 0.004205
[2015-03-31 08:35:29,464] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:29] "GET /uimedia/all.css HTTP/1.1" 200 15856 0.002035
[2015-03-31 08:35:29,467] DEBUG    lib.geventwebsocket.handler Closed WebSocket
[2015-03-31 08:35:29,468] DEBUG    lib.geventwebsocket.handler Failed to write closing frame -> closing socket
[2015-03-31 08:35:29,469] DEBUG    lib.geventwebsocket.handler Closed WebSocket
[2015-03-31 08:35:29,471] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:29] "GET /Websocket?wrapper_key=QAlouWb5wWt8 HTTP/1.1" 101 129 3.326747
[2015-03-31 08:35:29,492] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:29] "GET /media/Board.ZeroNetwork.bit/js/all.js HTTP/1.1" 200 106954 0.018129
[2015-03-31 08:35:29,496] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:29] "GET /media/Board.ZeroNetwork.bit/css/all.css HTTP/1.1" 200 71297 0.013782
[2015-03-31 08:35:29,508] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:29] "GET /uimedia/all.js HTTP/1.1" 200 122305 0.008480
[2015-03-31 08:35:29,554] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:29] "OPTIONS /media/Board.ZeroNetwork.bit/messages.json HTTP/1.1" 200 322 0.003693
[2015-03-31 08:35:29,563] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-03-31 08:35:29,564] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-03-31 08:35:29,565] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-03-31 08:35:29,566] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-03-31 08:35:29,626] DEBUG    Ui.UiServer 192.168.1.5 - - [2015-03-31 08:35:29] "GET /media/Board.ZeroNetwork.bit/messages.json HTTP/1.1" 200 156980 0.016296
[2015-03-31 08:35:33,708] DEBUG    WorkerManager:1TaLk3..sPKQ Task taking more than 15 secs, find more peers: data/users/15QJoGcY7kCCQn5NK1sgVsCj2nc3McLuNk/data.json
[2015-03-31 08:35:33,919] DEBUG    WorkerManager:1TaLk3..sPKQ Added worker: 212.92.214.123:15441, workers: 8/10
[2015-03-31 08:35:33,920] DEBUG    WorkerManager:1TaLk3..sPKQ Added worker: 82.73.156.95:15441, workers: 9/10
[2015-03-31 08:35:33,922] DEBUG    WorkerManager:1TaLk3..sPKQ Added worker: 104.156.231.236:15441, workers: 10/10
[2015-03-31 08:35:33,928] DEBUG    Site:1TaLk3..sPKQ Found 13 peers, new: 1
[2015-03-31 08:35:33,953] DEBUG    Peer:212.92.214.123:15441 1TaLk3..sPKQ Getting connection...
[2015-03-31 08:35:33,955] DEBUG    Conn#55 212.92.214.123 [?] Connecting...
[2015-03-31 08:35:33,957] DEBUG    Peer:82.73.156.95:15441 1TaLk3..sPKQ Getting connection...
[2015-03-31 08:35:33,959] DEBUG    Conn#56 82.73.156.95 [?] Connecting...
[2015-03-31 08:35:34,056] DEBUG    WorkerManager:1TaLk3..sPKQ 104.156.231.236:15441: Hash correct: data/users/1CtKJv2gGR3tSDfkqPmSVF1WNS7meEh2L3/data.json
[2015-03-31 08:35:34,061] DEBUG    Site:1TaLk3..sPKQ Loading json file to db: data/users/1CtKJv2gGR3tSDfkqPmSVF1WNS7meEh2L3/data.json
[2015-03-31 08:35:34,063] DEBUG    Db:ZeroTalk Connecting (sqlite version: 2.6.0)...
[2015-03-31 08:35:34,064] ERROR    - Unhandled exception
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/gevent/greenlet.py", line 327, in run
    result = self._run(_self.args, *_self.kwargs)
  File "src/Worker/Worker.py", line 58, in downloader
    site.storage.write(task["inner_path"], buff)
  File "src/Site/SiteStorage.py", line 138, in write
    self.getDb().loadJson(file_path)
  File "src/Db/Db.py", line 134, in loadJson
    cur = self.getCursor()
  File "src/Db/Db.py", line 47, in getCursor
    if not self.conn: self.connect()
  File "src/Db/Db.py", line 22, in connect
    self.conn = sqlite3.connect(self.db_path)
OperationalError: unable to open database file
[2015-03-31 08:35:34,848] DEBUG    Site:1TaLk3..sPKQ Announced to 5 trackers, errors: []
[2015-03-31 08:35:48,893] DEBUG    Conn# 3 24.108.77.4  [v2] Unpacker deleted
[2015-03-31 08:35:48,894] DEBUG    Conn# 9 78.158.149.247 [v2] Unpacker deleted
 thanks
 come to think about it i dont have sqlite installed but then again i dont think it needs to be
  `window.history.pushState` can do what you're looking to do (I think) â€” maybe look it up. Here's a little [demo](https://jsfiddle.net/fJ9wq/) of how it could work.
 Probably worth noting that `window.history.pushState` is a HTML5 spec, so you don't need the heaviness of the jQuery library for it to work. However, it is only supported in fairly modern browsers.

[History.js](https://github.com/browserstate/history.js) is a shim that'll let you use it, with a fallback to a HTML4 hash API.
 @HelloZeroNet, is it updated? > Probably we don't need it.

@HelloZeroNet, why? If zites will work without page refreshes it will be nice.  Enable to destroy a site if you hold the private key
 Okay, got it - thank you.
  I have a prototype ready. It's a plugin that adds a new websocket call to send a message. However I'm not familiar with ZeroNet so I have some questions.

- Where should ZeroNet store the configuration for the Bitmessage API (like the username/password)?

- Where should users and/or sites publish their Bitmessage addresses? You can't construct them from the existing ZeroNet identifiers, because each Bitmessage address contains two keypairs rather than one. I tried using site_data, but I don't think that I'm doing it correctly.

Let me know. @PeterSurda 

I also have a partial prototype, and may be able to help with some of your questions.

As for the API configuration, I think could be as simple as including the settings in users.json

For the publishing of addresses, my method just added a zeronet identifier or two. That way it would be much more accessible to those publishing sites.

I do believe I found a way to construct both keypairs from the existing identifiers, but I'm trying to work out a few kinks with that.

If you would be open to collaborating on this with me then feel free to contact me/reply to this thread and we'll work something out. @kamikazi3728 Sure, a collaboration may produce a better result.

> As for the API configuration, I think could be as simple as including the settings in users.json

I'm not sure how to do that but will try.

> For the publishing of addresses, my method just added a zeronet identifier or two. That way it would be much more accessible to those publishing sites.

Hmm then I will have to add the functionality to add an address from a private key to the Bitmessage API. Also, it will stop working when forward secrecy is implemented. > As for the API configuration, I think could be as simple as including the settings in users.json

I don't see a method for adding a custom variable into users.json. What I ended up doing instead was adding new parameters using the ConfigParser interface, so you can specify them both in the zeronet.conf as well as in the command line. That seems to make more sense and it works too.

Still figuring out how to allow users/sites to specify their bitmessage addresses. Just so we don't clutter up this thread, we could move the conversation into one of our branches, it might be better to get a working model going and just use this thread to get any extra input we might need.
I think working in your branch rather than mine might be best, I haven't committed any of my changes yet, so they would be easy to port over to yours if needed. Ok I gave you access to my repo. @HelloZeroNet, it wasn't already implemented? I made a pull request, #852 , after commenting here, and got no feedback whatsoever. no prob  I noticed you haven't labelled this one with help wanted. Is that intentional? Do you have a particular design in mind you could share? 

This would be something I'd love to implement!
 @HelloZeroNet Yeah, I think we have similar thoughts on this.

To me you want to have the public site unencrypted, and then an encrypted 'subdirectory', or even more than one. This means the owner can have public content, and how to contact them perhaps, and then the private stuff all under one key/bit domain. They can always choose to keep the public site blank if they wish.

We should think about each private 'subsite' as a site itself though - with it's own content.json etc. I feel like it should probably be rolled up in a zip file to avoid any visibility of the private site structure, but then that might make publishing difficult?

Some other thoughts:
- You can support various access methods:
  - Simple 'password', entered into ZeroNet managed UI over a site - stretched to the shared decryption key
  - Certificate access. This would require the owner encrypting the decryption key to each cert, and publishing the lot, but it's super easy for the users, they just know that a given certificate grants access. This does also mean you can rotate the underlying decryption key - on every site publish if required!
  - Bitcoin integration? Further in the future, what about something that would publish copies of the decryption key, encrypted to the public key of Bitcoin addresses which had sent it an amount of Bitcoin.
- You could manage the whole workflow quite neatly - users could write an access request, which would be encrypted to the site owner and published. The site owner could have an interface for reviewing them and granting access where needed.
- I'm not sure IP filtering is worth considering because it's not guaranteed for a user, and some people are deliberately using ZeroNet through Tor.

It's definitely not ideal for all use cases - and in particular, any user with access can then distribute (or reveal) that access to other users, regardless of whatever UI we put over the top. But I think it would be pretty good within the limitations of ZeroNet.
 Maybe using something like this https://github.com/pyca/pynacl used in openbazzar
 So @HelloZeroNet, I want to have a crack at this - maybe just starting with the encryption/publishing part, for the 'simple password' case. **Are you happy to merge if we come up with something good?** 

My first thought is on the metadata - we could add this in the files list in content.json, but that's not strictly accurate. Alternatively we could call it an include.

But I think a third list might be a good idea, eg:

```
{
 "address": "1evJheeFpVQkHaZdAzEMj75w5T14ogZWT",
 "description": "My example site",
 "files": {
  "index.html": {
   "sha512": "dc5af04d2cde806f4bab9a0dd6b09d367c9f2dd51dd5f22a36c2dc56aa6e925e",
   "size": 428
  }
 },
 "private": {
  "members": {
   "description": "Private members area - contact johnsmith on ZeroMail for access",
  }
 },
...
```

Signing and publishing would then require the encryption key (not ZIP password! :stuck_out_tongue_closed_eyes:), stretch it, and encrypt `members.zip` to `members.zip.zeronet` - the encrypted file gets published and the cleartext remains on disk.

`members.zip` would contain `content.json` at the top level, which would behave like any other subdirectory content.json. And `members.zip.zeronet` would be eligible for distribution by users, along with the rest of the site.

Later on, when we get to retrieving, a request for `1evJheeFpVQkHaZdAzEMj75w5T14ogZWT/members/` would trigger ZeroNet to request the key for `members.zip.zeronet`, decrypt it on disk and then proceed as normal.
 How do you mean twice? The only thing that would actually be shared out would be the encrypted zip.

Are you proposing the private bit is unencrypted, but only shared to people who should have access? Could you outline how that would work?
 > You can spy on site activity

Are you talking about metadata, like file names/sizes etc? That's partly what the zip file is for - just to bundle it up and avoid that analysis.

> (Future) Patch command can be problematic

I haven't read anything about this - what is it?

You can actually still achieve adding/removing users with per-file encryption, by picking a random symmetric key, encrypting the files (or zip file), and then encrypting a copy of that key to each user, exactly the same way PGP does it. If you want to add a user, simply publish an additional encrypted copy. Removing a user means picking a new random key and encrypting that for the remaining users.

I think per-file encryption is the best, but tell me about the patch command?
 > multi-user sites 

You mean public zeronet proxies? True... but are you thinking that if it was per-file, it would be decrypted in the browser? Otherwise you still have to trust the server with the key.

> per-user encryption is not really works for many users (100+)

Surely that's only (number of users \* encrypted 256 bit key)? That's 32 users/kilobyte, minus some for overhead - doesn't seem insane to me.

Patch command is interesting. 

Something else to consider is whether it is desirable for users without access (in the per-file model) to already be distributing the encrypted files, without access. Think about the scenario where Assange posted those diplomatic cables encrypted in bulk, as an insurance policy... you would want them to be replicated by interested parties, even if **nobody** but the author had a key.

I would say it would be good if ZeroNet supported that use case. In the connection security model, it wouldn't be possible because nobody would have access.
 Well, there is a way around having to re-encrypt all the files - version and increment the keys.
1. Files A and B (in the main part of the site) are encrypted with K<sub>1</sub>, and U<sub>1</sub> knows K<sub>1</sub> because the site owner encrypted a copy of it with K<sub>U1</sub>.
2. U<sub>2</sub> publishes file C, and encrypts it with K<sub>1</sub>.
3. Site owner 'deletes' U<sub>1</sub>. Site owner generates a new shared key K<sub>2</sub>, and writes a new table, with a copy of K<sub>2</sub> encrypted to K<sub>U2</sub>, K<sub>U3</sub> etc.
4. From this point, K<sub>1</sub> is considered 'compromised', and new and updated files will only use K<sub>2</sub>. 
5. Site owner makes a change to A, encrypts it with K<sub>2</sub>.
6. U<sub>2</sub> publishes new file D, encrypts it with K<sub>2</sub>.

So U<sub>1</sub> can still access the files as they were when they had access (until they're republished anyway), BUT that's OK because they always had access to those files, and could have taken a copy at any time.

#### Patch command

Could we make this work by simply encrypting the patches?
- In the basic scenario, you simply send the patch encrypted with K<sub>1</sub>. Each node decrypts the file, applies the patch and re-encrypts.
- In the advanced case where you've deleted a user, and are updating a file for the first time since, you encrypt the patch with K<sub>2</sub>, and set a flag to say that each node will decrypt the file with K<sub>1</sub>, apply the patch, and re-encrypt it with K<sub>2</sub>. Every node has to repeat the work, but that's not so bad.
 Actually, thinking about the patch command... you said the zip file wouldn't work because of the patch command: the patch could simply include a path into the zip file. It would be interesting to do some experiments and see if you could deterministically produce the same patched encrypted zip file on multiple hosts/OSs. It should be possible though.

But anyway, there are a lot of questions and complexity here, and we'll never get the right answer straight away. Why don't we implement the simplest possible idea: single shared AES per-file encryption (ie, image.jpg.encrypted), get it working with the patch command and new key management GUI, and get it out there to see how people use it? Or indeed if anyone does actually bother using it at all!

That way we avoid the complexity of adding/removing individual users, managing access etc, and we don't spend a bunch of time building something people won't use.
 By reuse, you mean it's not a good idea to encrypt the first version of the file with {K<sub>1</sub>,IV<sub>1</sub>}, encrypt the patch with {K<sub>1</sub>,IV<sub>1</sub>}, decrypt the file, make the change, and then re-encrypt it with {K<sub>1</sub>,IV<sub>1</sub>} again? You're right, that would be bad.

However, we can send IV in the clear without risk. So we would need to use a fresh IV for the patch encryption, and the patch would need to contain another fresh IV to use after the patch has been applied. We might want to include checksums for both plaintext and ciphertext inside the patch.

However, IV presents a bigger question for multi-user sites - we would need to use fresh IVs for user publications, and publish those along with the ciphertext. The sqlite DB only exists locally, and never leaves the machine, right? Or do we need to think about that too?

In fact, if we **don't** use zip files, we have to publish IVs per file too. On a site with a lot of files that could eat a lot of entropy from the pool.
 It's probably worth trying to put this all together in a wiki page that shows all the algos, keys and messages... any thoughts before I get started?
 > In fact, if we don't use zip files, we have to publish IVs per file too. On a site with a lot of files that could eat a lot of entropy from the pool.

The IVs can be put inside the file along with the ciphertext and the MAC. Patches could send a single random value and the IVs will be derived using HKDF, but it shouldn't really be a problem either way.
 Glad to see there's some talk on this. I'd like to throw in the idea of enabling the ability to create multiple passwords/secret addresses (a la Tor's [HidServAuth](https://www.torproject.org/docs/tor-manual.html.en) config command [[spec](https://www.torproject.org/docs/tor-manual.html.en)]) to give out to multiple trusted users.

That way if a password or the address were ever compromised, the site owner could simply disable the compromised user's address/password, while everyone else's would still work. @anoadragon453 Absolutely, I started outlining some ideas at https://github.com/OliverCole/ZeroNet/wiki/Private-sites-on-ZeroNet, but haven't had time to work on it further. Let me know if you want to talk over what I wrote - it wasn't finished.

The problem is it gets complex fast - when you remove a user, do you want to re-encrypt the site content to immediately deny them access to the data? Or just encrypt changes from that point? How do you make all that work with the delta updates?

But I think there is huge value in supporting a simple use case - someone publishes some leaked documents with a single symmetric key, which is revealed to media/the public at a later date. I would love to see Zeronet do that!  There are working DHT implementations for I2P (cf. Vuze's i2phelper plugin or i2p's i2psnark, i2p-bote also uses a dht)
 https://github.com/Ayms/node-Tor

https://pypi.python.org/pypi/pyp2p
 Full tor support and hidden services can work inside zeronet by creating a dht (that would be a tor hidden service it self) that holds the .onion addresses and load balances them. In clearnet it could work as a common dht. So its users connecting to zeronet through tor will have a hidden service created for its site he/she visits. And let tor hdirs take care the rest!

http://repository.tudelft.nl/view/ir/uuid%3A98728747-571c-4df8-ac88-f5b5cf19626c/

https://github.com/Tribler/tribler

https://pypi.python.org/pypi/OnionBalance

https://stem.torproject.org/tutorials/over_the_river.html

https://github.com/prof7bit/TorChat/tree/torchat_py

I started to work on this i let you know
 See #45 for some comments regarding I2P's torrent DHT support, which may be helpful.
  Most of them have been implemented. Don't forget to update this issue.  why not use libtorrent?, twister uses libtorrent for DHT
http://twister.net.co/?page_id=54
 @HelloZeroNet You could add to your first comment:
- Be able to store I2P and Tor hidden service addresses
- Don't use UDP to be compatible with Tor
 @HelloZeroNet Ho, didn't see that, sorry
 https://github.com/Ayms/node-Tor

https://pypi.python.org/pypi/pyp2p
 Full tor support and hidden services can work inside zeronet by creating a dht (that would be a tor hidden service it self) that holds the .onion addresses and load balances them. In clearnet it could work as a common dht. So its users connecting to zeronet through tor will have a hidden service created for its site he/she visits. And let tor hdirs take care the rest!

https://pypi.python.org/pypi/OnionBalance

 https://stem.torproject.org/tutorials/over_the_river.html
 Interesting issue. Zeronet would drastically benefit from a DHT, as trackers tend to come and go with time... 

My bet is that it would be best to bootstrap and use Bittorrent's DHT (Mainline DHT - MLDHT), as although it has a few problems, a lot of effort is put into it to keep it reliable and stable. A simple approach could be done using `announce_peer` and `get_peers`. Some more fancy stuff could be done using the post-signed-mutable-content thing (see [bep_0044](http://www.bittorrent.org/beps/bep_0044.html)), but that might not be interesting for Zeronet.  

For instance I (new user) query the MLDHT : `get_peers(sha1(1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D))` and retrieve a list of the peers on it - simple. The peers would have to first announced themselves using (roughly) `announce_peer(sha1(1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D), my_ip_and_port)`

About the dependency, I think it's inevitable, at least for some things like bencode and the MLDHT, although there seems to exists relatively small python libraries. I'll have a look at this. 
 Can the DHT solves the problem that how a new client first join the zeronet when the tracker server is down?
 @HelloZeroNet Maybe this https://github.com/maidsafe/routing or this https://github.com/maidsafe/crust can be used.
 Custom bootstrap clients (storing all of them is nice too) , some proxys and an option to save an anonymous list of users to use as emergency bootstrap, it can be stored(exported and imported)! The "unvirginizer"
( IPFS tactics)
 Could we use https://github.com/closeio/redis-hashring in Python or https://github.com/RJ/ketama in C?
 Hi,

I propose to you to consider using [OpenDHT][]. It has the following features:

- C++11 (maybe C++14 somewhat soon);
- [Python bindings][pybinds];
- IPv4 and IPv6 support;
- Nice crypto layer for handling encrypted blobs and signatures;
- Transition from 160-bits SHA1 hashes to 256-bits hashes is in progress;
- TCP support is work in progress (@aberaud may comment on the status);
- Distributed indexing: it literally permits to do searches on complex queries rather than exact key lookups. This is based on [PHT][] data structure although we have added substantial changes to support *Fully distributed indexing* which are documented into an article to be presented at [UNet2017][]. **This is more than relevant for this project**. You can compare this to providing Google search features on ZeroNet;
- It is actively used by the software called [Ring][] which is driven to deliver distributed and secure p2p communications to its users. More people use the same DHT, more the apps based on it will behave well.

I personally would like more projects to join like [Syncthing][].

[pybinds]: https://github.com/savoirfairelinux/opendht/tree/master/python
[OpenDHT]: https://github.com/savoirfairelinux/opendht/
[PHT]: https://people.eecs.berkeley.edu/~sylvia/papers/pht.pdf
[UNet2017]: http://www.unet-conf.org/
[Ring]: https://ring.cx
[Syncthing]: https://github.com/syncthing/syncthing/issues/3388

 IPv6 for CJDNS would be fantastic. I talked with Shortcutme with this issue. Here are the questions he is trying to find an answer to.

> Some months ago I did some experiments and checked out some [DHT] libraries, but there are still lots of questions left.

- Can it reliably work over Tor (or over TCP at all)?
- DHT routing in ZeroNet must support .onion and .i2p addresses.
- Should we use an existing DHT implementation (eg. Mainline, OpenDHT) or create a new one?
- Is there any alternative to DHT that worth checking out?

Here are my questions:

- Nodes in the network hosts their own sets of sites and optional files, based on user interests. We still want to choose what to store and what not to store. There is no strictly defined _peer responsibilities_. Should me adjust current DHT implementations to reflect the current circumstances of the ZeroNet network?
 Which DHT protocol do you use ? @HelloZeroNet  Does ZNet made any progress in this issue? [this](https://github.com/miguelfreitas/twister-core/commit/e52f2c25275119bf43054cdf711b91fe16db3238) might be of interest. It's not reimplementing DHT using TCP, but instead it just carries the UDP traffic through a TCP tunnel (with the express intent of letting it be carried by Tor) Very interested in getting DHT, but in the interim with trackers getting blocked and dropped, maybe you could add more trackers?
https://github.com/ngosang/trackerslist Here is my own implementation of the Pastry DHT algorithm. https://github.com/MuxZeroNet/pastry

Pastry basics:
- [Dynamic Distributed Hash Tables.](https://www.youtube.com/watch?v=p8iugvHeGcg)
- [Selected DHT algorithms: Chord and Pastry.](https://www.cs.tut.fi/kurssit/ELT-53206/lecture03.pdf) pp. 23-34.
- [Distributed Hash Tables: An Overview.](https://www.cs.cmu.edu/~ashu/talks/DHT.pdf) pp. 14-16.

Joining, leaving and repairing the network:
- [Pastry, Tapestry and Kademlia.](https://heim.ifi.uio.no/michawe/teaching/p2p-ws08/p2p-5-6.pdf) p. 5.
- [Structured P2P Networks: Pastry and Tapestry.](http://inst.eecs.berkeley.edu/~cs268/sp03/notes/Lecture22.pdf) p. 5

The packets you may need to provide:
1. A packet that implements this interface: `has_value, other_nodes = send_dht_request(peer, key)`
2. A "gossip" packet that allows nodes to exchange parts of the routing table or leaf set.

_Edit: Removed "Toy DHT." Added Pastry, which is not a toy._ We got a new problem:

> Tamas Kocsis wrote:
> The handshake and the encryption has pretty big overhead
> so probably it would be more efficient if we would use a separate UDP port

Yes. In practice, latency is what makes DHT protocols slow, which is one of the reasons DHT protocols run over datagram, but rarely over TCP streams.

In Tor, you have to use TCP streams, because this is how Tor works.

I2P SAM provides datagram API. Running DHT over I2P has "encryption overhead" and has observable latency, but it is better than nothing. DHT has been used by I2PSnark and BiglyBT for torrents.

> Do you think if the DHT should be part of ZeroNet protocol?
> [use the protocol provided by] one of the already existent [libraries]. (maybe libp2p or any other dht lib)

I am more on the "implement a DHT that fits ZeroNet's needs" side, while I am not familiar with the API `libp2p` or any DHT library provides.

Even if you will be using a DHT library, you should always think about how to write the protocol docs. By using proper means of abstraction, the less you leak implementation details in the specification, the more flexible the protocol is. You really don't want to make future developers who will be implementing ZeroNet in another programming language get stuck on a particular library.

  - How to fix the '1 file upload failed' issue?
 Can I suggest to create a document page explaining how to create a namecoin .bit address?
 The [single IP setup](https://github.com/HelloZeroNet/ZeroNet/issues/103) is something that'd probably be worth having in there.
 It should also be said for site developpers the differences between creating a ZeroNet site to a non ZeroNet site. For exemple: links should contain attribute `target="_top"` or `target="_blank"` to works as expected
 > Handshake

Needs more documentation on Handshake and GetHashfield. #987  ```
 src.File.FileServer UpnpPunch run error: NameError: global name 'SocketError' is not defined in FileServer.py line 50 > UpnpPunch.py line 176 > UpnpPunch.py line 40
```

replacing SocketError by socket.error gets us to another error : 

```
src.File.FileServer UpnpPunch run error: UnboundLocalError: local variable 'data' referenced before assignment in FileServer.py line 50 > UpnpPunch.py line 176 > UpnpPunch.py line 44
```

adding return to the except block gets us another error : 

```
src.File.FileServer UpnpPunch run error: TypeError: expected string or buffer in FileServer.py line 50 > UpnpPunch.py line 176 > UpnpPunch.py line 52 > re.py line 177
```

I gave up there... 
 Hey @arthurlutz , thanks for reporting this. I'll get on fixing this today evening. Could you please share what OS you're using as well as Python version?
 I think I have the fix for this on my fork's master. I'll get to give it a test on two routers tomorrow and hopefully report back a success.
 Whoa, thanks! I'll test it out soon as I'm home today. Got a windows box
and two routers to test it.
On Mar 7, 2015 4:35 PM, "ZeroNet" notifications@github.com wrote:

> Made it work by detecting local ips (+added some logging, fixed the
> successful run check and it also can be run by standalone using python
> UpnpPunch.py):
> https://gist.github.com/HelloZeroNet/5133c7f03030620c278f
> 
> Please test :)
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/issues/54#issuecomment-77711283.
 I checked out the code and it works on both a linux machine and a windows machine on two different routers and it forwards the port without a hitch. Nice job on update 2 - that was the trickiest part. Should we leave it on my fork for more testing or should I submit a PR?
  To summarize everything here: this solves #5 and #20. 

It's a pure python stdlib + gevent way to open up a port on router to the current host using UPnP. I've tested it quite a bit on my linux box and a bit on a windows box I got access to. I've also had some feedback (and a working solution!) from @hobbldygoop in https://github.com/sirMackk/ZeroNet/commit/fdcd15cf8df0008a2070647d4d28ffedb503fba2#commitcomment-9863928 about making it work on OSX (THANKS!). :+1: 
  Zeronet is taking a lot of time to load other website's like the one's present in the Zeroboards messages. I recommend that you should include a website load progress bar with some data in it so that user's can know how much percent the website has been loaded. It is very annoying to look at the connecting page without any estimate of how much data is left to be downloaded. Along with that the ZeroSearch (The search engine for zeronet) is not working. The page says internal server error. And one last thing is that please give some more documentation so that the developers could help you build it better.
 The website named ZeroBoard and along with another website of a person named Blue coder. It's really annoying to wait for so long and still get no result. I recommend you to display the contents as soon as they arrive along with a progress bar like that of in Youtube (The red colored seek that runs at the top). Another thing is that the ZeroSearch is still not working and could you make any platform that will allow the user's to make dynamic websites without using an external server. For starter's you should provide support for a web framework in python (web.py or webapp2) along with an optional way to make the website  server dependent(for dynamic websites) or server independent(for static website's).
  I am unable to post a message in ZeroBoard. Even after waiting for 15 minutes it is not posting my text.
  Some of the English wasn't quite right, so I thought you'd appreciate some fixes.  I've also added syntax highlighting for the bash code blocks, and switched out the use of `-` to use the more-common `*` for bulletted lists.  Lastly, I fixed some spelling.
  Hi, i believe address should begin with Z 
https://en.bitcoin.it/wiki/Base58Check_encoding
chart says 32 is the Z character 
  When running in debug mode, accessing the console raises [Gevent #445](https://github.com/gevent/gevent/issues/445), in UiServer and UiRequest.

![Console Window](https://imgur.com/VWYSQLN.jpg)

![Debug Window](https://imgur.com/grbh0dN.jpg)
 ```
'HTTP_HOST': '104.131.8.131',
 'HTTP_USER_AGENT': 'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)',
 'HTTP_X_FORWARDED_FOR': '66.249.73.184',
 'HTTP_X_REAL_IP': '66.249.73.184',
 'PATH_INFO': '/Console',
 'QUERY_STRING': '',
 'REMOTE_ADDR': '127.0.0.1',
 'REMOTE_PORT': '54914',
 'REQUEST_METHOD': 'GET',
 'SCRIPT_NAME': '',
 'SERVER_NAME': 'tester',
 'SERVER_PORT': '43110',
 'SERVER_PROTOCOL': 'HTTP/1.0',
 'SERVER_SOFTWARE': 'gevent/1.0 Python/2.7',
 'wsgi.errors': <open file '<stderr>', mode 'w' at 0x7f53f74101e0>,
 'wsgi.input': <gevent.pywsgi.Input object at 0x7f53eaac0910>,
 'wsgi.multiprocess': False,
 'wsgi.multithread': False,
 'wsgi.run_once': False,
 'wsgi.url_scheme': 'http',
 'wsgi.version': (1, 0)} failed with Exception
```

In the console seems a bit odd, in that case.
  Meta tags inside the iframe are largely ignored, to enable developers to build responsive applications, they need a viewport. Though many developers tweak the viewport setting, the one presented here is by-and-large the most commonly used, as it's simple and effective.
 I'm guessing that "viewport" accepts any input, and plays out into the meta tag on the page.

e.g.

```
"viewport":"content="initial-scale=1, maximum-scale=1"
```

should work equally as well as:

```
"viewport":"content="width=500, initial-scale=1"
```

or the original example:

```
 "viewport": "width=device-width, initial-scale=1.0"
```

If not, it might be an idea due to the size and usefulness of the viewport meta tag: [W3 Draft Specification](http://dev.w3.org/csswg/css-device-adapt/#viewport-meta).

If it does, this is a nice fix, but will need to be clearly spelled out in docs somewhere.

Nice job.

I'll check ZeroTalk soon as I update the Proxy.
 ZeroTalk seems to work well on mobile - except for one or two things.

![New topic button](https://imgur.com/l2IBqao.jpg)

The Request Access button also throws the user way off screen, unfortunately, I didn't screenshot that, as I realised there was no sign out, and my whole uni has access to the server I was using. So I ran off panicking.
  I2P has bittorrent support, and it works very well (but slow). So suggestion is to use it. There should be an option to use only I2P, only clearnet, or both.

More info:
https://geti2p.net/en/
https://geti2p.net/en/docs/applications/bittorrent
 +1
 +1
 +1
 Relevant thread: http://zzz.i2p/topics/1613-azi2phelper-vuze-plugin (requires I2P to view). Vuze has implemented both I2P-only and clearnet+I2P modes for regular torrenting, and their code may help provide insight about how to add I2P support to ZeroNet.

Disclaimer: I'm an I2P developer (and happy to answer questions!)
 Some more points:
- I2P has a well-used in-net torrent DHT. See [the BitTorrent docs page](https://geti2p.net/en/docs/applications/bittorrent) (also linked [above](45#issue-56867747)) for details (there are some slight differences from the clearnet DHT protocol to support I2P addresses).
- AFAIR Vuze's azi2phelper plugin manages the I2P and clearnet DHTs separately.
- I2P supports UDP, if it helps (via [SAMv3 API](https://geti2p.net/en/docs/api/samv3)).
 any news on this?
 Thank you for your quick response.

Maybe your first set of issues is something @str4d can help with.

Re bundling i2p: i think that making the i2p transport optional and then require the user who wants to use it, to install i2p himself is ok. I don't think everything should be bundled.
 @HelloZeroNet if you were using Twisted I'd point you at [txi2p](https://github.com/str4d/txi2p), but instead I'll point at [the more general Python library](https://github.com/majestrate/python-i2cp). Both use the SAM API, which is supported by all I2P implementations.

Re: bundling, I agree bundling Java would be tricky, because it would require the JVM. Bundling Python in Java is easier because of things like Jython - I don't know if there is maybe some reverse equivalent? Otherwise you could look at the C++ I2P routers being developed ([i2pd](https://github.com/PurpleI2P/i2pd) and [kovri](https://github.com/monero-project/kovri)), which I assume could be bundled the same way you are bundling Tor. I would certainly recommend at least having a UI option to use an external I2P router, even if it is not the default; many I2P users run a router 24/7 on a VM and run their transient apps through it remotely. This would be the same setup as other I2P-supporting apps like Vuze or [Bote](https://github.com/i2p/i2p.i2p-bote.android).
 > Need more research to see if i2p support many (per site so 100+) services from same host

I need some more clarification on this. Are you wanting one Destination (I2P equivalent of Tor Onion Service) per site, or multiple listening sockets at different ports on the same Destination? The former is possible (though YMMV regarding how many hundreds you can run at once :P ); the latter will be possible soon via the above Python libraries (we only just exposed via the SAM API our support for multiple ports).

> and have to find out the cryptography of i2p address to be able to create proof-of-ownership signature to avoid some network attacks.

The binary format of the B64 private key that SAM returns to you is [documented here](http://docs.i2p-projekt.de/javadoc/net/i2p/data/PrivateKeyFile.html); you could instantiate the private signing key yourself and use it to sign anything you wanted. That may be something that gets added to the Python libraries in future if enough people require it.
 that will not scale in i2p.
because i2p router must build those tunnels and rebuild them as they 
change every few minutes for increased privacy.
Maybe sorting them into different pools could be a viable solution?
though this would require much work. Who decides which pool a site would 
be in? would have to be the user and would require one additional step 
for him before seeing the site. So not really good.

OTOH, vuze does not create a different destination for each torrent 
either.
But I perfectly understand the point of uncorrelating the sites.
 I wouldn't go as far as saying it isn't possible - I'm running ~30 services for a combined ~110 tunnels on my router. But you would definitely want to do some kind of tunnel management if you were spinning up one Destination per site. I would suggest dropping to one or two inbound and outbound tunnels each for low load (probably dropping down to only one for sites that have no peers downloading for some time), and adding more as load increases. Vuze uses a similar mechanism to great effect (I've had as much as 200kB/s combined download speed for torrents over I2P, at which point Vuze will have IIRC six inbound and outbound tunnels).

One downside to this mechanism would be that it becomes easy to determine which sites are popular, by observing which ZeroNet Destinations have more tunnels. But maybe this isn't part of your threat model.

The setup Vuze uses is to have only two Destinations: one for torrents that it seeds inside I2P only, and the other for torrents that it simultaneously seeds on the public internet. This minimizes correlation between their public and anonymous activity.
 @HelloZeroNet Any news? I'm really looking forward for this to be implemented, as I prefer I2P support much more than Tor support... And many other users want to have I2P support, instead of Tor support because it is distributed and peer-to-peer friendly
 more info:
- [arguments in favour of i2p](http://127.0.0.1:43110/zeroblog.bit/?Post:71:in+progress:+comparing:+1.+ZeroNet+%3C-%3E+IPFS,+twister+--+2.+tor+%3C-%3E+i2p)
- [poll: Are you looking forward for I2P integration?](http://127.0.0.1:43110/1K28kQFMquNzto2iQf4GGjr6oFUbC1NddE/?Poll:1-1D7DRHxZ8WMHLvkyaVWEZsdAZSQvLY5JQM)
 Just FYI, I2P has launched [a development program](https://geti2p.net/en/blog/post/2016/06/01/I2P-Summer-Dev) aimed at helping developers integrate I2P into their apps. If you would like some help with this in July during our Apps month, let me know! We are currently in APIs month, so I'll have a poke around the ZeroNet source to make sure the libraries you would need are being improved :smile:
 @str4d : ZN is running around 75 hidden services in my case. (To make sites served by same peer less linkable)
Is i2p able to handle such an amount of different destinations, besides maybe other tunnels like i2psnark etc?
 @aaannndddyyy in theory, yes it can. In practice, you'd want to set up tunnel management such that each Destination only had one tunnel unless it was being actively used and needed the additional bandwidth. And of course you'd want to have your I2P router sharing a lot of bandwidth, because even with every hidden service Destination using only one tunnel, you'd be using a total of 225 hops by default (for 3-hop tunnels), so you'd need to be sharing appropriately to avoid Zeronet causing network congestion. (We had that problem initially with Vuze, until they changed the default sharing percentage of their internal I2P router to 80%. Now Vuze nodes contribute a sizeable fraction of our routers.)
 I'm doing the grunt work for this issue this weekend :smile:
 First structural question: I2P has the concept of a Destination, analogous to an IP address. We have Python datatypes for these Destinations as part of the module I'm using for the integration. Would the Zeronet devs prefer to use that datatype throughout (ie. wherever `Peer.ip` is used when generating a string, check if it is a Destination and behave accordingly)? Or would it be better to just keep `Peer.ip` as a string, and then parse from that only inside the I2P-specific code?
- Note that there are many places that do `if ip.endswith(".onion")` that currently need to become `ip.endswith(".onion") or ip.endswith(".i2p")`, but using the Destination datatype they would instead be `isinstance(ip, Destination)` or `ip.endswith(".onion")`. The ordering would be necessary to ensure that `ip` is only parsed as a string after we know it isn't a Destination.

Follow-up question: if using strings and not Destinations, would the Zeronet devs prefer to use the full 387+ byte (ie. variable-length depending on crypto used) base 64 strings (which are just serialised Destinations), or the B32s (`52chars.b32.i2p`)? The latter is only 32 bytes (and therefore easier in logs and less data to transfer between peers), but requires an additional lookup before it can be used anywhere (ie. B32 -> B64, then connect to B64) which will add some latency to making connections.
- Note that if using the Destination datatype, it can easily be converted to either B32 or B64 exactly where required (so e.g. in log messages the B32 could be used, while in network messages the full Destination could be used).
- I2P's [BitTorrent spec](https://geti2p.net/en/docs/applications/bittorrent) specifies that non-compact tracker responses include the full B64, while compact responses and PEX use the B32 hash. That may or may not be helpful, because AIUI Zeronet only uses a BitTorrent-like protocol.
 WRT the first question, I thought it was possible, but I've found that some IPs have a `cert_pin` appended, the origin of which I cannot trace but it indicates that the `ip` field is overloaded with meaning. Therefore I'll try to stick with strings.
 On 2016-07-23 13:46, str4d wrote:

> I'm doing the grunt work for this issue this weekend ðŸ˜„
> 
> ## 
> 
> That's great news. Thanks
 On 2016-07-23 10:25, str4d wrote:

> @aaannndddyyy [1] in theory, yes it can. In practice, you'd want to
> set up tunnel management such that each Destination only had one
> tunnel unless it was being actively used and needed the additional
> bandwidth. And of course you'd want to have your I2P router sharing a
> lot of bandwidth, because even with every hidden service Destination
> using only one tunnel, you'd be using a total of 225 hops by default
> (for 3-hop tunnels), so you'd need to be sharing appropriately to
> avoid Zeronet causing network congestion. (We had that problem
> initially with Vuze, until they changed the default sharing percentage
> of their internal I2P router to 80%. Now Vuze nodes contribute a
> sizeable fraction of our routers.)

I guess the reason why tor can do so without any proble is that for tor 
it makes almost no difference if you access 200 sites through one own 
hidden service (just like visiting 200 eepsites using your eepProxy) or 
you access the same 200 sites through/from 200 different hiddenserver 
addresses. The per service overhead should be as small as possibly, so 
that the overwhelming factor is only the actual data being transferred, 
which in both cases is the same.
Then it would also not matter if you use a total of 6 hops or 300 or 
1200 hops (200 sites \* 3 hops \* 2 directions), because all the 1200 hops 
would consume only little more than the 6 hops would do if the same 
sites were visited/served through them. Like if a user share X kB/s, it 
should not matter if he routes two tunnels with X/2 kB/s each, or 100 
tunnels with X/100, also amounting to exactly the same ressource usage.
Only floodfills would have more work.

I have the impression, thugh, that i2p in that respect is much more 
ressource hungry and needs significant traffic overhead per-tunnel. Is 
the reason bhind that, that i2p is more decentralized than tor or that 
tunnels are more short-lived? Is there anything that could be done to 
reduce? - apart from tunnel management that reduces the per-dest tunnel 
count to one, which would still be a huge amount if you are serving 200 
site only with zeronet and are still having other aplications use i2p 
too (torrent, â€¦)
 I am working on something to make this easier: #520. Please check it out.
 I have this mostly-done. Outgoing communication is working fine (ZeroNet can announce to I2P open trackers), but incoming communication is currently semi-to-non-functional because i2p.socket's `accept()` doesn't quite work yet with gevent's cooperative sockets. I'll finish preparing the commits on ZeroNet today and make a PR for discussion.

@up4 thanks for the notification, I'll have a look at it.
 @str4d my patch is the beginning of something to abstract the transport and create a configuration to allow the user to have the control over which transports he wants to use. Maybe I should PR to your repo those abstractions and then you can PR to the main repo. Anyways I2P support would be great!
 @HelloZeroNet Maybe the future torrent plugin should have i2p support? The zites themselves run fast enough through tor.
 @HelloZeroNet Are you sure about no i2p support? https://github.com/arvidn/libtorrent/blob/9fd83aaa10c1bca0d36b783004af89897bf3e618/src/i2p_stream.cpp
 Any progress here?
 Oh! Sorry for the lack of updates here. I finished implementing I2P support in ZeroNet back in July, but didn't make a PR because it didn't work (due to i2p.socket not working fully with gevent). Then I decided I'd just make a PR anyway in case someone else could get i2p.socket working, but then work became busy :sweat_smile: I'll push the PR now.
 Thank you for your work! 
Hopefully, someone can fix i2p.socket
 patched i2p.socket to like gevent more but need some i2p testers, once it's confirmed working I'll tag a new release for i2p.socket.
 What are the frontend used in zeronet?
 Any news here? what's the status of this, now that i2p.socket was patched? I assume that i2p.socket fully works with gevent. The remaining problem is that ZeroNet creates too much I2P hidden services and i2p will be overloaded. I am thinking about randomly dividing the list of sites in to at most 50 subgroups of variable lengths in order to reduce the number of hidden services used. I don't think that overload will be a big enough issue for zeronet to worry about. In my experience this was an issue with i2p. It was some time ago, but it happened. Because of all the tunnel maintenance that has to take place. But only actual test will tell, if it is still the case. And if it is, the pooling @MuxZeroNet has talked about could be a way to mitigate that. Maybe the i2p side itself could also work on improving that, as it is a non-issue for tor. shouldn't just 1 hidden service be used with zeronet? that makes a lot more sense. in tor it uses different circuits per site for inter-site unlinkability - which is a pretty neat feature.
 i see, such an option makes little sense with i2p you have a reply to destination so if you churned through that you'd be creating new unreliable peers with short lifespans. it makes sense, it just adds a lot of load. so instead of on a per-site basis, this could be done on a per-pool basis, joining the different sites into pools. This works fine on i2p and is a compromise between anon/privacy and performance. The churn come from i2p rebuilding tunnels every some minutes. Making more than 1 destination could spread the attack surface out AND increase network load. I see very little reason for it but I digress.
I will release the next version of i2p.socket if someone can point me to a demo branch with i2p support in it. @majestrate see #602. I'll make time to rebase it later this week. Thank you very much. Do you think a even simpler SAM enabled socket module is worth integrating into ZeroNet? Just like what TorManager does: it has a simple control socket implementation plus Stem Control Library support.

|                        | TorManager | I2PManager |
| --------------------- | ---------- | ---------- |
| Simple Implementation | âœ“          | ?          |
| Control Library       | âœ“ stem          | âœ“ i2p.socket        | i2p.socket is a simple implementation, the only changes required (ideally) is 

    import socket

to

    from i2p import socket

 [Onion pooling](https://bit.surf:43110/Blog.Zeronetwork.bit/?Post:108:New+version+0.5.4) has been implemented at this moment. > The other main problem is to make it any usefull we have to pack it with ZeroNet, i'm not sure if its possible with java applications.

You can use i2pd, it has a much smaller footprint than java and works cross-platform.
https://github.com/PurpleI2P/i2pd i2pd's sam code is still a bit crashy, idk how well it'll work, otherwise i2pd should be stable by now.

another alternative is i2pcontrol and socks5 but that may require too much configuration, unless you are planning on bundling a binary.  Creating an issue about an enhancement discussed in irc that I'm working on.

Currently there are some security issues in regards to downloading sites. A good implementation would be to prompt a user prior to downloading a site in which would output metadata such as the site description and directory size, along with an accept or decline. Among the initial download, there is also no prompt to accept or decline the update of a site being published that grows in size. 

Suggestions or enhancements to such an idea are of course welcome.
 As a side not, prompting for downloading may need to include other warnings.

E.g. A user should be able to cancel the download of a site that contains materials illegal in their country.

Something like a NSFW warning before downloading. It would have to rely on site creators, but it's a nice workaround.
  https://registry.hub.docker.com/u/genecyber/zeronet/
 Thanks for this, can you post the Dockerfile? The Docker Hub has an "automated build" option which lets everyone see the Dockerfile used to generate the image.
 Hmm I didn't create it with a dockerfile, I created it by starting with the ubuntu base and installing the environment, Is there a way you know of to export a dockerfile? I looked into the autobuild option in hub and it requires I start with a dockerfile
 There's no way to go from an image -> Dockerfile automatically, but if you know the commands you used to install it that is pretty much what goes in the Dockerfile.
 I'll see what I can do

On Wed, Jan 28, 2015 at 4:45 PM, Mike Chelen notifications@github.com
wrote:

> ## There's no way to go from an image -> Dockerfile automatically, but if you know the commands you used to install it that is pretty much what goes in the Dockerfile.
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/HelloZeroNet/ZeroNet/issues/42#issuecomment-71922948
 Added a pull request with a Dockerfile...
 Your docker autobuild works. Now it's possible to run ZeroNet with the following command:

```
docker run -p 15441:15441 -p 43110:43110 nofish/zeronetâ€‹
```

Feel free to close the issue.
 `msgpack/_packer.cpp:8:22: fatal error: pyconfig.h: No such file or directory` is fixed
 running under docker with no issues here.
docker run -d -e "ENABLE_TOR=true" --name zeronet  -p 15441:15441 -p 43110:43110 nofish/zeronet
My main issue is trying to access from tor-browser which is also in a container.
posted my issue on https://github.com/HelloZeroNet/ZeroNet/issues/1110
  If there is a `.git` directory inside a site folder, crazy things start to happen with ZeroNet, making sites not update properly.

Ignoring any `.git` directory should fix this.
  In the past I had no content by myself, so it was easy to upgrade => replace

Now I have my own blog, my own sites, ... ZeroBlog changed, do I need to upgrade that also ? Do I need to upgrade MY blog? what's with my data?

BTW, one thing needs improvement: As more sites are coming online as more annoying it is WHERE the sites will get the place in the main screen, since it changes with each restart. Maybe we can add numbers to it, or "bookmark" them to a certain spot. What will be if we get hundreds of sites? Will we get a search button/sort button?
  There was a typo in which was attempting to log out the wrapper_key, but instead it was spelled "wraper_key".

The NameError in issue #35 is fixed by this:

```
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/gevent/pywsgi.py", line 508, in handle_one_response
    self.run_application()
  File "/home/arthur/local/ZeroNet/src/Ui/UiServer.py", line 21, in run_application
    self.ws_handler.run_application()
  File "/home/arthur/local/ZeroNet/src/lib/geventwebsocket/handler.py", line 81, in run_application
    self.run_websocket()
  File "/home/arthur/local/ZeroNet/src/lib/geventwebsocket/handler.py", line 57, in run_websocket
    self.application(self.environ, lambda s, h: [])
  File "/home/arthur/local/ZeroNet/src/Ui/UiServer.py", line 49, in handleRequest
    return self.ui_request.route(path)
  File "/home/arthur/local/ZeroNet/src/Ui/UiRequest.py", line 41, in route
    return self.actionWebsocket()
  File "/home/arthur/local/ZeroNet/src/Ui/UiRequest.py", line 239, in actionWebsocket
    self.log.error("Wrapper key not found: %s" % wraper_key)
NameError: global name 'wraper_key' is not defined
```
  This should resolve issue #17. By default running `python start.py` will launch the zeronet server in a subprocess then open the default browser. The user can also specify which browser to open. For example, `python start.py firefox`.
  I've mostly been using Zeronet in Firefox/Chrome for Mac, and they've been working fine. However, when trying to connect in Safari, there are a few problems. One, the flipping red square is white with a 1px red border (after it drops; as it's dropping it's red), two, dynamic content doesn't work (ZeroBlog is blank). It seems to be a problem with Ghostery (maybe?) but it worked fine with Ghostery in Chrome. Web Console messages: 
`[Error] Sandbox access violation: Blocked a frame at "http://themacmini09.agrius.feralhosting.com:43110" from accessing a frame at "http://themacmini09.agrius.feralhosting.com:43110".  The frame requesting access is sandboxed and lacks the "allow-same-origin" flag.
    global code (ghostery-min.js, line 8)`

`[Error] Error: Syntax error, unrecognized expression: .messages .message:not(.template
    error (all.js, line 7)
    tokenize (all.js, line 7)
    select (all.js, line 7)
    gb (all.js, line 7)
    find (all.js, line 7)
    init (all.js, line 7)
    n (all.js, line 7)
    (anonymous function) (all.js, line 654)
    j (all.js, line 7)
    fireWith (all.js, line 7)
    x (all.js, line 9)
    (anonymous function) (all.js, line 9)`

I have tried whitelisting the site in Ghostery, and even disabling it (which only removed the first error).
 How did you set up the change of domain?

(From 127.0.0.1)

How does the VPS expose public access?
 I am running ZeroNetProxy (in this example) on the VPS - however, it works perfectly fine in other browsers, and running off of the local machine doesn't fix the issue - errors are identical (except for the domain, of course).
 From what I can find, Safari is simply a pain in the butt when it comes to CORS, something used inside ZeroNet.

It might be necessary to add:

```
Access-Control-Allow-Origin: http:127.0.0.1:43110 | *
```

and on ZeroNetProxy:

```
Access-Control-Allow-Origin: proxyAddress | *
```

To the header on the server, to make it work. @shortcutme ?

This is something that ZeroNet needs, I'll look into it and make a pull request if I can find a way to do it nicely. (Without breaking everything in sight).

As a by note, you probably want to update [ZeroNetProxy](https://github.com/zeronetproxy/ZeroNetProxy), so that you can find updating in future a hell of a lot less painful.
 Now all is good on os x safari 
![2015-02-28 14 40 45](https://cloud.githubusercontent.com/assets/426427/6426056/e88fde6a-bf57-11e4-949f-26dc4aa6cc96.png)

Only one warning and no errors
 Great, thanks! I'll test it out later today.
  #32 was fixed
  My site uses cyrillic characters at title and description http://127.0.0.1:43110/18C5HmyTt5Ua4WdyESp3mgmrCwVMPc4yw2 Cyrillic characters tend to Python's UnicodeEncodeError.
After I've published it once, ZeroNet allows me to publish latin version of this fields, but downloads old version of site from some peer immediately.
 Sorry, for publishing I need to "sign" the site. But encoding problem is still actual.
  Namecoin should be used for publishing sites, which would allow namecoin lookups to the the public key address of a zeronet site.  This completely decentralizes the technology that handles name lookups.
I propose zeronet public addresses should go in a value field "zn" or "0net" within a domain name registered with namecoin.  More info here: https://wiki.namecoin.info/index.php?title=Domain_Name_Specification#Value_field
 :+1: 
 Worth looking at:

https://openname.org/about

https://github.com/openname/openname-resolver
 Has this been documented anywhere? 

```
"zeronet": {
    "blog": "1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8", 
    "@": "1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr", 
    "talk": "1TaLk3zM7ZRskJvrh3ZNCDVGXvkJusPKQ"
}
```
 The "d/" prefix is intended to be .bit domains on the clearnet within the current DNS architecture - something that we shouldn't be concerned about at all.  I'm thinking that using the "d/" prefix is not the optimal solution, and perhaps a new "z/" prefix should be used instead.

Perhaps "z/zeronet" would contain:
    { "addr": 
        { "": "1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr", 
          "blog": "1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8"
        }
    "name": "ZeroNet Home",
    .....
    }

Then the url via browser extension or such, would be: 
"zero://zeronet" or "zero://blog.zeronet"
or
"http://zeronet.zero" or "http://blog.zeronet.zero"

Perhaps this is total pie-in-the-sky given that tools for treating namecoin as clearnet DNS are already available so we just hijack the "d/" prefix.  That said, shouldn't we at the least swap out the ".bit" for ".zero"?

Where is a good place to have this discussion?  I also intend on running namecoind local, and would like to plug it into that directly.
 Hi! It would probably be better to stick to .bit: https://forum.namecoin.info/viewtopic.php?f=5&t=1069
  future enhancement.  When publishing becomes popular, more security should be allowed at the site key level in the form of multisig or scriptsig of some type.
 Can be closed?
 Can be closed?
 [ContentManager.py:460](https://github.com/HelloZeroNet/ZeroNet/blob/1d6f56c6766651f94060f101aaaa5e2933e1fe19/src/Content/ContentManager.py#L460) Still not implemented
  This would require adding "allow-same-domain" to iframe sandbox.  I somewhat understand the security implications, and this would allow other sites access to each others' localresources, but I wanted to open this ticket to track this request.  Ultimately, in an effort to provide a rich user experience, this same domain issue will need to be conquered.  

Short term, I'd like to see localresources opened up, maybe with an explicit user permission per site, and an explanation of the risks?
 Primary risk I see is the ability of a site to unsandbox itself entirely and control the parent page.  I'm unclear on the risks there.
Secondary 'risk' is storing things in LocalResources like IndexedDB would be accessible to other pages - a developer should know not to put sensitive data in there and only leverage it for indexing large amounts of public data for local querying.  
 Will try alasql for some things.  I'd like to see some sort of decentralized read, centralized yet disconnected write, secure, database synchronization framework ultimately.  

I think the model makes sense for publishers of data to connect to a node, transmit changes, then unplug.  Then, be able to remain offline and receive messages back when connecting - ala bitmessage.

I should write a tech doc for what I'm envisioning here.
 Can this system execute serverside nodejs?
  My first try:
I created a test site with and published it, and still get SEEDING UPDATE FAILED.

No real content yet there:
http://127.0.0.1:43110/19u3W1KB8nzzEW3EiQYC1eNfQ6Q53o9Gj7

What kind of files can I use for the site?
Is there a tutorial for that?

What will be ZeroMarket and ZeroBay??? or why is it gray?
  Added a requirements.txt file for easier requirement building.

Instead of:
- pip install pyzmq
- pip install gevent
- pip install msg-pack python

It's:

```
pip install -r requirements.txt
```
  When running zeronet.py with the --fileserver_port argument set to an open port, the following error occurs

[22:42:28] Site:1EU1tb..E4Vr Tracker error: error: cannot convert argument to integer in Site.py line 233 > subtl.py line 79

As the fileserver_port is of the type string, parsing it to integer fixes this issue.
I don't know if the subtl library is the correct place to implement this fix, but for now it helped me to get it to run.
  This should be added quickly so people won't have to say if they have access to the private key or not.
  Hi team!
First of all kudos for you project! It's a great tool!

Now I would like to ring a bell about the way we have to use it to browse and found existing site.

I deeply think that if we want decentralized services to be adopted by most of people and not just skilled ones (We work for freedom and liberties for every internet user after all), we should implement some sort of decentralized search/discovery service and human readable URLs.

Search/Discovery service are made to ease the spread and retrieval of informations online during a solo browsing.

Human readable URLs are made to ease sharing and references of a previous browsing session.

Two main features that our browsers commonly implements (Of course it perform such a thing using other system services) and that need to be implement to ease the adoption of your project.

I'm not a professional of bitcoin but I know that bittorrent protocol implement resources discovery and advertising.
 Thanks a lot for your answer, here is a little more advanced explanation of my previous requests.

**About the Addresses resolution topic:**
Even if the addresses resolution feature was explain by the masses/users point of view on my previous post, I deeply think that it is (with advertising and discovery feature) a building block for decentralized services. As you said it, you're not addressing the masses adoption topic right now, but think of this feature as a building block of website articulation and/or as an compatibility feature for the already existing, working and well established internet standards.

For example:
As an enthusiast web developer looking for cool tools and plateform, I want to be able to use them by learning how they're working and how they address some of my issues, but I would certainly not us this cool tools if I dramatically have to change the way I'm developing my website.

The keypoint of this feature is not only masses adoption by a simplification of the user experience but rather the adoption by every targeted categories including devs by providing a great and simple learning curve.

I'm not such a great example as my project are quite intricate projects but I'll take it anyway to illustrate my proposal.

As a web developer mainly focused on B2B customers, I have to build almost all of my applications using a URLs routing gateway which will be in charge of routing the requests to the correct resources.
On this specific topic and without URLs resolution, I'll have to generate a UID for each of the targeted resources, then modify my routing gatewat to hardlink them on it.

I can assure you that because of the payload of my gateway, I'll have to change about a 100 of routing rules just to be able to test if ZeroNet is working correctly using automated tests.

In my case addresses resolution would literally save me a bunch of hours if not days depending on the way your platform/tool works and react on crash or life-cycle (Start/Stop/Restart/Reload/etc procedures).

**Regarding the discovery / advertising capability:**

On some bittorrent network's clients, your client is able to discover and advertise peers about its configurations and services, as mention on this request: http://www.bittorrent.org/beps/bep_0026.html

For example, it would be cool to have a way to request for a list of nearest peers ables to provide a set of  resources (Website on your specific project) and then use Bitcoin crypto capabilities to check if it's not a MITM style attack etc.

This discovery/advertising feature could allow us to rapidly find a specific resource using the nearest/fastest path and then create sort a sort of decentralized search engine.

In the case of a unique node would be available during the discovery this node would be use IF and ONLY IF it is the original publisher of the content as we need to guaranty the user that it's not a malicious node.

For this last rule, a more complex one would be to keep in a bitcoin blockchain (or something similar) the history of the propagation of the resources and their signature to avoid any malicious modification.

Anyway, I've got a loooooottt of idea regarding peer to peer and decentralized software / tools / infrastructure so don't take my example and arguments as formal request for feature but rather like reminders of what kind of cool features we (the community) and you (the core dev-team) would be able to implement.

BTW: I'm sorry for my extensive answer, but I had to explain my previous ideas a little more as I'm on my PC today :D and can easily write way more detailed examples.
 No problems thanks a lot for your effort with ZeroProjects and to have take time to read my request.

Just to add a final example about p2p website decentralized services, try to read some of the comments regarding the Bittorrent Maelstrom Browser project to avoid kinda ugly design.

Especially on the Static vs Dynamic serving systems and Security/Privacy regarding the way the software share the served pages and retrieve them to the users:

http://blog.bittorrent.com/2014/12/10/project-maelstrom-the-internet-we-build-next/
&&
http://blog.bittorrent.com/2014/12/10/project-maelstrom-the-internet-we-build-next/#comment-1736424276

I'll closely follow your updates on all the zero's projects ;-) way more interesting technology in here than everything I heard of on the Internet for now :D 
 Yep, their implementation of the p2p web is not the right one I think.
I deeply think that p2p is the right solution to build a bright new decentralized Internet as the global bandwidth increase every day and in the same time more and more company like Virgin / Google / Facebook etc try to build grid and outer-space networks to avoid the current ISP Controlled one.

I'm working on p2p projects too so, when a friend of me linked me your work, I was really impressed by how it has been done so far and how far you are on it.

Keep going on, this is a good, interesting and rewarding project.
  I think the README should recommend installing upnpc via packages (for example apt-get install miniupnc) and then ZeroNet could check if upnpc is in the path instead of having to explicitly use --upnpc option.
  My version of miniupnpc doesn't understand "-e ZeroNet" but the rest of the command is right. Maybe there could be a test or a try/except to do it without the -e option.
  When navigating a ZeroNet site the top URL in the browser doesn't change. It stays as the address for the top level of the site. This makes creating internal links to sites in ZeroNet difficult.

You can right click on a link and copy/paste it. But this leaves the "/media" path in the URL and when you visit it it displays at the top level, not in the iframe with the Websocket magic around it.

Would it be possible to change the top level URL when navigating? Maybe using a fragment identifier that the top level JS parses to navigate the iframe?
 I'm meaning more in the case of a user browsing a site wanting to get a link to share.  They can't copy/paste the URL in the browser because it stays as the top of the site and doesn't change. If they copy the URL of a page or link on a page they get the '/media/...' link which they have to edit.
  I like the start.cmd idea.

As to opening in the browser:

```
import webbrowser # From the standard library
tab = 2 # Use a new tab if the default browser is open
url = "http://127.0.0.1:43110" # Set a variable to open
webbrowser.open(url,tab=tab) # Open the web browser!
```
 This is the command for OSX. 

```
osascript -e "open location \"http://127.0.0.1:43110\""
```
 Just put in a PR that should take care of this.
 @volker48 

Just a suggestion and it can always be added later, but some people might want it opened in a specific browser, as well as some people saying this opens a browser other than the default. Maybe we can have this as an option or take in an arg (browser name) that would open it.

Here's how a specified browser can be opened:
https://docs.python.org/2/library/webbrowser.html#webbrowser.get
 @ymski I updated the pull request. You can now specify the browser when running start.py. Example, `python start.py firefox` will launch firefox instead of the default browser. If you don't specify it still uses the default browser.
 ```
--dont-open-browser
```
This parameter has no long working in current ZeroNet Bundle (Windows)

Current working parameter is:
```
--open_browser ""
```  Fixed typo in README.
  Minor changes to wording to give better understanding.
  I know I'd forget that information under my own volition, so why not save it to disk? I opted for 'data/mysites.txt' as an easy place to remember, and alerted the user that such an action was taking place.
 I'd totally agree with not saving into the data folder, that's where the serving up happens, but I think saving to disk would make some sense. 

The issue is the key being a long hard to remember sequence, and we deal with this all the time: SSH Keys are saved to file as well.
  Would async managing this be able to help? Or is it because the greenlets are trying to attach to the same socket?
 The gevent queue is as understandable as a straight python implemented queue and it seems easy to use.

http://www.gevent.org/gevent.queue.html

one example they use at the bottom:

```
def worker():
    while True:
        item = q.get()
        try:
            do_work(item)
        finally:
            q.task_done()

q = JoinableQueue()
for i in range(num_worker_threads):
     gevent.spawn(worker)

for item in source():
    q.put(item)

q.join()  # block until all tasks are done
```
  I'm having a slight problem with trying to add a site, I feel like its due to user error on my part, but nevertheless I'd like to get it working

I've done this in a directory `/home/dydx/Development/zeronet-sites/dydx`  which contains `index.html` and `style.css`

```
âžœ  dydx  python /home/dydx/Development/github/ZeroNet/zeronet.py siteCreate
- Generating new privatekey...
- -----------------------------------------------------------
- Site private key: [removed for sake of posting to github issues] (save it, required to modify the site)
- Site address: 1GXtHRoh7495zJYLthQ8xPt2dRzm8DwWhb
- -----------------------------------------------------------
- Creating directory structure...
- Creating content.json...
Site:1GXtHR..wWhb Site not exits yet, loading default content.json values...
Site:1GXtHR..wWhb Opening site data directory: data/1GXtHRoh7495zJYLthQ8xPt2dRzm8DwWhb...
Site:1GXtHR..wWhb - data/1GXtHRoh7495zJYLthQ8xPt2dRzm8DwWhb/index.html (SHA1: 4065b2b27a289cba476a7ffbce11681cbcc9f6f9)
Site:1GXtHR..wWhb Adding timestamp and sha1sums to new content.json...
Site:1GXtHR..wWhb Verifying private key...
Site:1GXtHR..wWhb Signing modified content.json...
Site:1GXtHR..wWhb Saving to data/1GXtHRoh7495zJYLthQ8xPt2dRzm8DwWhb/content.json...
Site:1GXtHR..wWhb Site signed!
- Site created!
```

Everything looks good. I try to visit `http://127.0.0.1/1GXtHRoh7495zJYLthQ8xPt2dRzm8DwWhb` and get a message saying there were no peers found, which I suppose is correct given that no one has visited/seeded the page besides me

I post on the message board about trying to see if it works, and a user replied with this:

```
> Gives me hash failed, try to use siteSign command again
```

I suppose thats sort of odd, but I try the siteSign command and get notified that it succeeded:

```
âžœ  dydx  python /home/dydx/Development/github/ZeroNet/zeronet.py siteSign 1GXtHRoh7495zJYLthQ8xPt2dRzm8DwWhb                    
- Signing site: 1GXtHRoh7495zJYLthQ8xPt2dRzm8DwWhb...
Private key (input hidden):
Site:1GXtHR..wWhb Opening site data directory: data/1GXtHRoh7495zJYLthQ8xPt2dRzm8DwWhb...
Site:1GXtHR..wWhb - [SKIPPED] data/1GXtHRoh7495zJYLthQ8xPt2dRzm8DwWhb/content.json
Site:1GXtHR..wWhb - data/1GXtHRoh7495zJYLthQ8xPt2dRzm8DwWhb/index.html (SHA1: 4065b2b27a289cba476a7ffbce11681cbcc9f6f9)
Site:1GXtHR..wWhb Adding timestamp and sha1sums to new content.json...
Site:1GXtHR..wWhb Verifying private key...
Site:1GXtHR..wWhb Signing modified content.json...
Site:1GXtHR..wWhb Saving to data/1GXtHRoh7495zJYLthQ8xPt2dRzm8DwWhb/content.json...
Site:1GXtHR..wWhb Site signed!
```

I go to check the URL once more and see that I have 3 peers! But, it never seems to load. I get a message saying that `content.json download failed`

Do I just need to wait for more seeds to propagate, or is there an error in my setup somewhere? 
 Heya,

I got it to work reasonably (I can view the site I put up now), though it says on the ZeroHello page that the update failed.

Also, I see this in the terminal output:

```
WorkerManager:1GXtHR..wWhb [peer ip addr]:15441: Hash failed: content.json
WorkerManager:1GXtHR..wWhb [peer ip addr]:15441: Hash failed: content.json
WorkerManager:1GXtHR..wWhb [peer ip addr]:15441: Hash failed: content.json
WorkerManager:1GXtHR..wWhb [peer ip addr]:15441: Hash failed: content.json
WorkerManager:1GXtHR..wWhb [peer ip addr]:15441: Hash failed: content.json
WorkerManager:1GXtHR..wWhb [peer ip addr]:15441: Hash failed: content.json
WorkerManager:1GXtHR..wWhb [peer ip addr]:15441: Hash failed: content.json
WorkerManager:1GXtHR..wWhb [peer ip addr]:15441: Hash failed: content.json
WorkerManager:1GXtHR..wWhb [peer ip addr]:15441: Hash failed: content.json
WorkerManager:1GXtHR..wWhb [peer ip addr]:15441: Hash failed: content.json
```

I'd assume this might because their version of my site is older than my version? If they visited my page again, would they begin seeding the 'working' version of it? 
 Ohhhhh. Sweet. I'll close this since I think I've basically figured out it what was wrong.
   Something like [Celery](http://www.celeryproject.org/) should be able to monitor the usage, and perhaps limit it, in the long run, with gevent compatibility. That being said, it might be a bit of a hack to use.
 Now we have http://127.0.0.1:43110/Stats
 http://127.0.0.1:43110/Stats solve this issue indeed. closing ?   Hi, me again. Two questions:
1. Why, precisely (in terms of actual code), are big/large files not supported (many references to "more than 1MB")?
2. Why does it "need to wait until DHT support" lands ?

Thanks!
 Hi!

No harsh feeling against you personally, but I hold a solid grudge against the "please spare Tor for important text-based traffic from the third world". Very pre-Nietzschean as a moral argument. I just can't. Plus, I have discussed it ad-nauseam in ZeroChat FR (I think). If I were to make a fork of this repo, modify the storage mechanism (and download progress interface) and not touch the protocol itself, I think people would prefer this version over the official ZeroNet stack because it just makes more sense technically. I'd rather do that than an optional plugin. I'm going to make a pull request when I'm done and I'm going to let you decide if you want it in your repo or not.

I just hope we can make this work.
 Isn't possible to use the [Tribler](https://www.tribler.org/)'s onion routing for the big files ?
 Hello, I've created a p2p stream helper here https://github.com/zeronetscript/universal_p2p, with this helper runs on visitor's PC, any ZeroNet web page can use a simple way to stream resource (on the fly)from bittorrent ( a demo site already tested by some visitors)

for example use normal HTML5 video tag , points src to

http://127.0.0.1:7788/bittorrent/v0/stream/c12fe1c06bba254a9dc9f519b335aa7c1367a88a/video.mp4

this http request makes helper's bittorrent backend download torrent by infohash and streaming video.mp4 file to client. with this helper, any ZeroNet website can stream from any existing torrent's resource.
I'd plan to support more p2p backend (for example http://127.0.0.1:7788/ipfs/xxx) ,more convient function (direct stream file inside zip archive). 

I'd also suggest intergrate tribler to zeronet , and works as my helper way. this makes any existing bittorrent resource accessable without special pages.  Protocol prefix in url reserve the ability to support different backend, keeps protocol  version to makes protocol upgrade easy. 
 Solution proposed and being worked on here (I will commit real code in the next couple of days): pull request #521.
 @zeronetscript 
I really support the IPFS idea, instead of working against we should include IPFS in the future, the network will become amazing.
ipfs is beeing ported to javascript and python .... so it should be possible.... well, the most do it already, sharing files over ipfs in 0chan for example.....

Suggestion at first: Including ipfs in the bundle, started with zeronet together, more options to site creators.  We have to live this dream! ^^
 If you can resign secure Tor usage you can use http://www.cachep2p.com/ in javascript
 Having a native implementation of IPFS makes complete sense for me as well.
We would need to allow support for files packs, for example, instead of having each individual file available for redistribution we could have a 'folders' like approach: all images, video course XYZ, all video courses of category ABC, books from id 1 to 100, all books in my shelves, music album DEF, all classical music albums, etc.
The packs could be defined by the site owner with the list of IPFS hashs (or a query that leads to this list), once a pack is selected to be seeded by the user, it will be downloaded and seeded through the local ipfs daemon.
The current implementation UI is hard to use because nobody will select individual files from the lists. The user is not interested in seeding specific files, he is interested in helping the site by providing a bit of bandwidth and space. 
For a site like 0chan, the site owner could pack the different categories and users can then seed the whole category (eg: seed all files from /dev/). For a site like ZeroWiki, the same thing applies, the site owner could split the seeding in sections like: seed all images, seed all pages, seed history of all pages, OR he could use different wiki categories like: seed all content of category ABC.
One of the benefits of having it in IPFS is that the files are also available to the opennet via the IPFS gateway. So in the case of sites like antilibrary.bit, once users start to seed the book packs, the book files will be available for everyone to download via Zeronet gateways + ipfs gateway (eg: https://bit.no.com:43110/Antilibrary.bit/ ). I believe ZeroNet protocol does a better job protecting integrity and privacy than the original BitTorrent protocol. ZeroNet has the potential to be a more resilient file sharing network.

|        | ZeroNet | BitTorrent |
| ------ | ------- | ---------- |
| Digest | SHA-512/256 (the truncated version) | SHA-1 (vulnerable to [BitErrant attack](https://biterrant.io/)) |
| Signature | secp256k1 (Bitcoin) | ? |
| Encryption | TLS, on by default, unless OpenSSL is gone | Various, on by deault in many clients |
| Link | Bitcoin address, [ripemd160(sha256())](https://en.bitcoin.it/wiki/Technical_background_of_version_1_Bitcoin_addresses) | Magnet URI, SHA-1 |
| File List | Signed `content.json` | BEncoded, not signed |

Current blocks:
- Tor people will blame us for abusing their bandwidth.
- No I2P support yet.
- No DHT yet, but many I2P torrent clients do not implement DHT either. We could benefit from this: https://ipfs.io/blog/23-js-ipfs-0-23/ isnt the problem with bittorrent protocol/client for big-files losing any protection from Tor? When big file surport will come out ? > When big file support will come out ?

Hello there!

Big file feature requires more research and more frequent discussion. Instead of asking this, do you think you can contribute any ideas regarding any of the bullet points below? Write another comment and we (the community) will evaluate your thoughts.

- Hashing, integrity
How can we hash the big files in such a way that small segments can be verified efficiently?

- Routing, data availability
How can we find the file in the first place?
How can we encourage people to seed?
Node responsibilities? Blacklisting free-riders? Can I cut my files and put it away after the moment it is finished? What about caring about the others?

- Usability, caching
How can we cache the file? __zncache__/ ?
Can I use evil AJAX requests to download the whole Internet to your computer and blow up your hard drive?
What kind of user interaction must take place?

 @MuxZeroNet Thanks for the thorough synopsis of open questions! Several are currently under discussion at the [ZeroTalk thread](http://127.0.0.1:43110/Talk.ZeroNetwork.bit/?Topic:1_1Kr2JfCsBYQU1z96xQsYTshKvJ5nz4mTG3) for this topic.

Since I'd prefer this clearnet issue serve as the central hub for this topic, I've taken the liberty of copying across a few of the more notable comments on that ZeroTalk thread. If this was unspeakably bad, just let me know and I'll remove the offending quotes.

**Let's do this.**

> - Hashing, integrity
> How can we hash the big files in such a way that small segments can be verified efficiently?

The canonical solution is [Merkle trees](https://en.wikipedia.org/wiki/Merkle_tree) (i.e., hash trees). I'll be astonished if ZeroNet doesn't eventually adopt *some* variant on a hash tree for distributing and validating big files. The devil is in the details, however:

> nofish â” on Jun 09, 2017
> It's planned this summer, right now I experimenting with merkle trees.
> Conclusions so far:
> Pros: Smaller content.json files (only one 64bytes roothash)
> Cons: Needs to send proof with every pieces. (640 bytes/piece at 1000 pieces) and slower confirmation time
> So I'm not sure if it's worth it...

> p2p â” on Jun 13, 2017
> IMO we can have quick-hash-tree + SHA-512-whole-file-hash as default, and all-SHA-512-hash-tree as fallback. In `content.json` we just need to store these 3 kinds of hashes: quick-hash-tree's root hash, SHA-512-whole-file-hash, and all-SHA-512-hash-tree's root hash.
> First, we calculate quick-hash-tree in which much faster checksums are used such as CRCs to calculate leaf node hashes, and then combine the whole file, calculate the SHA-512-whole-file-hash. In case of attack ( all CRCs are right but SHA-512-whole-file-hash is invalid ), we fallback to all-SHA-512-hash-tree to find out which data piece is fake.
> In this way, we can address the performance problem.

Integrating [IPFS](https://ipfs.io) into ZeroNet is strictly off-the-table for all of the obvious reasons, including:

> nofish â” on Jun 10, 2017
> It [*integrating IPFS*] could be possible, but then we need to run separate daemon which would reduce portability, more memory usage, probably no full tor support, more connections and [probably other problems](https://github.com/ipfs/community/blob/master/code-of-conduct.md#copyright-violations).

> skwerlman â” on Jun 11, 2017
> I hadn't thought about tor support, which is probably a deal breaker since IPFS is UDP-only atm.
> That CoC [*Code of Conduct*] is pretty spooky, since it seems to apply US law globally, and, assuming it's enforceable, it means the IPFS devs are susceptible to state coercion.
> I think you're right that IPFS isn't the right solution here.

The remainder of @MuxZeroNet's line of questioning ultimately reduces to user experience (UX). The ideal approach would be to incrementally generalize ZeroNet's existing *small* optional file support to gradually encapsulate all of the functionality required for *big* optional file support.

To do so sanely, a browser-based user interface for managing optional files is all but essential. Specifically, ZeroHello might introduce a new zite-specific context menu item (e.g., named "Files," "Share," "Details," "Content," or something similar). When clicked, this item might open a new browser tab:

* Displaying a detailed list of all optional files available from the selected zite.
* Displaying torrent-style AJAX controls permitting each optional file to be independently started, paused, stopped, and deleted.

In other words, I2PSnark in ZeroNet drag *ala*:

![I2PSnark UI](http://i.imgur.com/dT01pls.png)

Sadly, the size of even small optional files currently contributes to the 10MB zite limit. Generalizing ZeroNet's existing support from small to big optional files thus requires decoupling the size of optional files from the maximum size of the zite hosting those files.

The ideal approach is probably the incremental approach â€“ one slow, languorous pull request at a time until we're where we eventually want to be. This road is long and winding, but utopia remains in sight. Are you reinventing [.torrent files](https://en.wikipedia.org/wiki/Torrent_file)? Couldn't a native implementation of IPFS be of help?

-------- Original Message --------
On 5 Aug 2017, 16:38, ZeroNet wrote:

> Same goal, but torrent files using it's own non-standard encoding (bencode) and outdated, not secure anymore sha1 encryption.
>
> â€”
> You are receiving this because you commented.
> Reply to this email directly, [view it on GitHub](https://github.com/HelloZeroNet/ZeroNet/issues/7#issuecomment-320450457), or [mute the thread](https://github.com/notifications/unsubscribe-auth/AXMdbv8Lxdti56dDXIL-ZAWM3H8J_D9uks5sVIyFgaJpZM4DRs1k). Without Tor compatibility does mean users will be clear/unmasked? @haschimoto yes >Storage

One big file
> Uploading? WebSocket suitable for this or separate HTTP post request?

HTTP post request
>Compressed piecemap?

Msgpack  @antilibrary
> Couldn't a native implementation of IPFS be of help?

Read @leycec s above post:

> Integrating IPFS into ZeroNet is strictly off-the-table for all of the obvious reasons, including:

    nofish â” on Jun 10, 2017
    It [integrating IPFS] could be possible, but then we need to run separate daemon which would reduce portability, more memory usage, probably no full tor support, more connections and probably other problems.

    skwerlman â” on Jun 11, 2017
    I hadn't thought about tor support, which is probably a deal breaker since IPFS is UDP-only atm.
    That CoC [Code of Conduct] is pretty spooky, since it seems to apply US law globally, and, assuming it's enforceable, it means the IPFS devs are susceptible to state coercion.
    I think you're right that IPFS isn't the right solution here.

 @japzone1 @HelloZeroNet IPFS not only already has good support for big files but they have a whole team dedicated to improving the project. If we use IPFS we can reap all the benefits of their development.
On the points raised:

- They do think of [supporting Tor](https://github.com/ipfs/notes/issues/37), but then again, may not be a good idea, and if users want to share big files they should think about using VPN or something else.
- There are efforts to make [IPFS portable](https://github.com/ligi/IPFSDroid)
- On their code of conduct, because of their architecture, there is just so much they can do to avoid copyright infringements (eg: blacklisting a hash on their gateway - one could create a gateway without the blacklist; blacklist a nodeId on their nodes - one could have his own network of nodes and clients could still connect to them). 

My general feeling is that by reinventing the well on this one we may be creating more work for ZeroNet devs (a whole new part of the system will need to be maintained) and we are isolating ourselves by not being 'compatible' with anything else. For example, if you store big files on IPFS, the site owner could decide to have many interfaces of his site to allow users to get those files, his ZeroNet site could be just *one* of the interfaces, the others could be on the tor network, ipfs itself, or even clear net. 
 @HelloZeroNet what about webtorrent or WebRTC ? @antilibrary 
1. They're thinking about it, which isn't something we can wait for. 
2. They're working on it but it isn't ready, which is something we can't wait for.
3. I won't get into that right now, (I'm literally walking out the door at the moment)

Basically we can't wait for critical features, and we don't want the extra overhead.

@linkerlin People are already trying that, but the critical flaw that we've found is getting people to Seed. People either have to leave a tab open, or download a special client. Neither is practical for most people. Plus there's no easy way to hide people's identity with Webtorrents. @HelloZeroNet would platform like [Sia](https://github.com/NebulousLabs/Sia) also be considered? > Should it download big files if "download all files" checked on sidebar?
> Should big files count in optional files limit? If yes, then it may easily automatically delete every optional file you downloaded before and/or the large files you downloaded

imo, big files should have be treated totally separately in the ui from optional files since they are conceptually different I vote in favor of two files categories: required and optional. Optional files in current implementation must gone and replaced by big files (all optional files will be "big"). Big file support demo at ZeroNet Meetup 2017: https://www.youtube.com/watch?v=U01L7GS30MA&t=820s  Here's another one for testing: 13TSUryi4GhHVQYKoRvRNgok9q8KsMLncq

It's weblog but is fairly large. The index page downloads but the CSS is often not downloaded in time so the initial display is unstyled. A refresh shows it styled due to it having downloaded by then.
 Ah, I didn't have that commit, thanks. Looks like that's fixed it.
  [PyUPnP](https://github.com/fuzeman/PyUPnP) might be a place to start, though it adds [Twisted](https://twistedmatrix.com/trac/) as a dependency. (Of course, Twisted itself should be able to cover this, but who wants to write from scratch?)
 Hi, I can look into this. It seems related to #20 as well, so might as well kill two birds with one stone. Do you know if someone is working on this or is it safe to dive in?
 Sounds great, thanks for the pointer! 
 Hi! I _think_ I got it. It uses gevent + the stdlib. I've tested it with two UPnP enabled routers I have access to and it worked both times. I'll be able to test it with a third one this weekend. 

Before I do final cleanup and submit a PR, do you know someone who could test my branch against their router/s? I don't have a lot of experience with UPnP and I'm trying to cover anything I might have missed. My branch: https://github.com/sirMackk/ZeroNet/tree/upnp_punch . 
 Oh man, that's great! I posted a message on ZeroNet to see if anyone else wants to volunteer to test this functionality out. Might make a ZeroNet site to coordinate this type of effort.
 Great! Ive fixed some small platform related bugs as well. I'll submit a PR
as soon as I get back from work. Thanks!
On Feb 24, 2015 10:55 AM, "ZeroNet" notifications@github.com wrote:

> it's working at my workplace too :) So I think we can include it in the
> next release if its ok for you too.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/HelloZeroNet/ZeroNet/issues/5#issuecomment-75782891.
  I found a vulnerability in EllipticCurvePoint.SignECDSA. You use random.randint to generate k. random.randint is not a cryptographically secure random number generator.

From Wikipedia:
3. Select a cryptographically secure random integer k from [1, n-1].

Using a weak PRNG for k can result in the compromise of the private key d. For example: "Such failure of RNG caused users of Android Bitcoin Wallet to lose their funds in August 2013."
https://en.wikipedia.org/wiki/Elliptic_Curve_Digital_Signature_Algorithm
  Every page loading always reports: UiServer Websocket error, please reload the page

Javascript console shows: http://gyazo.com/f1cee5522fe1516d501b8cea7339deb4
 These appear a lot (scrubbed IP address of peer):

[2015-01-13 01:54:02,377] DEBUG    Site:1NpWNp..i5qU Need content.json first
[2015-01-13 01:54:02,582] ERROR    Peer:x.x.x.x:15441 getFile {'inner_path': 'content.json', 'site': '1NpWNp4qo5DGVeC59GNW2bBKxHu2jyi5qU', 'location': 0} error: File read error: [Errno 2] No such file or directory: 'data/1NpWNp4qo5DGVeC59GNW2bBKxHu2jyi5qU/content.json'
[2015-01-13 01:54:02,582] ERROR    WorkerManager:1NpWNp..i5qU x.x.x.x:15441: Hash failed: content.json
[2015-01-13 01:54:02,671] ERROR    Site:1NpWNp..i5qU WebSocket error: string indices must be integers
[2015-01-13 01:54:02,671] DEBUG    lib.geventwebsocket.handler Closed WebSocket
[2015-01-13 01:54:02,671] DEBUG    lib.geventwebsocket.handler Failed to write closing frame -> closing socket
[2015-01-13 01:54:02,671] DEBUG    lib.geventwebsocket.handler Closed WebSocket
 same here
 I've had these issues when the server is running before some new files are published.

Do the errors change after restarting the server?
 I just cloned the repo and started using this and I've been receiving the same error. I'll be looking into it, so please let me know if there's any new information on it.
 `WebSocket error: KeyError: 'cmd' in UiWebsocket.py line 34 > UiWebsocket.py line 80`

https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/UiWebsocket.py#L80
`cmd = req["cmd"]`

It's probably trying to set that key that isn't there yet. 

EDIT: Looking into it further it looks like there's a point where the key does not exist in the request data and that's when it errors out.

```
[u'cmd', u'params', u'id']
[u'cmd', u'params', u'id']
[u'cmd', u'params', u'id']
[u'cmd', u'params', u'id']
[u'cmd', u'params', u'id']
[u'cmd', u'params', u'id']
[u'opt', u'id']
[22:39:39] Site:1EU1tb..E4Vr WebSocket error: KeyError: 'cmd' in UiWebsocket.py line 34 > UiWebsocket.py line 81
```
