  ### Environment

* **Tesseract Version**:  4.00.00dev with current training data (tessdata_best).
* **Commit Number**: eba0ae3b88a46a93e981770caa0b148d65cc4468
* **Platform**: Windows 64-bit build, Visual Studio 2017 15.4.4

### Current Behavior:

[Test.zip](https://github.com/tesseract-ocr/tesseract/files/1505927/Test.zip)

1) MinSizeRel build

Command: 

tesseract.exe C:\Test.tif C:\Test -l deu+eng --psm 1 --oem 1 pdf

Error messages:

None

Result:

Correct PDF created, OCR results OK

2) Release build

Command: 

tesseract.exe C:\Test.tif C:\Test -l deu+eng --psm 1 --oem 0 pdf

Error messages:

None

Result:

Correct PDF created, OCR results OK

3) Release build

Command: 

tesseract.exe C:\Test.tif C:\Test -l deu+eng --psm 1 --oem 1 pdf

Error messages:

Multiple times:

Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made

Result:

Broken PDF created.

Conclusion:

Release build shows erratic behavior when LSTM is used, errormessages and/or wrong output.
Debug And MinSizeRel builds work slowly but correctly.
As soon as the optimization /Ot is switched to /Os (or from /O2 to /O1) or LSTM is not used all problems go away.

### Expected Behavior:

Release build behaves like MinSizeRel/Debug built.

### Suggested Fix:

Problem is located in Tesseract::GetRectImage

As soon as speed optimization for this function is switched off with #pragma optimize( "t", off ) the problem goes away.
 As I made some progress I updated the issue to better describe what is happening.
I built tesseract exactly like described here:
 https://github.com/tesseract-ocr/tesseract/wiki/Compiling#windows
Develop Tesseract -> Building for x64 platform It is a 64 bit version of leptonica - otherwise it would not work at all.
Why should the compiler used to build leptonica make any difference?
Due to my findings the problem is located in Tesseract::GetRectImage, and goes away as soon as that very function is not optimized for speed anymore.
I would not expect that the way tesseract interfaces with external libraries is changed by the optimization option. Not my post and it does not look like the problem has anything to do with /Ob2.
RelWithDebugInfo shows the same behaviour as Release as both use /O2. Found similar problem in ColPartitionGrid::ComputeTotalOverlap with some input files.
A Release build hits the following assertion:
contains_unichar_id(unichar_id):Error:Assert failed:in file C:\Users\mw\Desktop\OCR\tesseract-master\ccutil\unicharset.h, line 513
As soon as I add #pragma optimize( "t", off ) directly in front of the function ColPartitionGrid::ComputeTotalOverlap  the problem goes away. @MarkusGH, did you also restore optimization after `ColPartitionGrid::ComputeTotalOverlap` and `Tesseract::GetRectImage`, so we can be sure that only those functions used code without optimization in your test? Yes - I put #pragma optimize( "", on )  directly after the functions.
It looks like the following have a strong effect on the problem:
Training files used, size of input file (pixel count), engine.
Strange enough I found at least one file which works with --oem 0 and --oem 1 but not with --oem 3. I think it is too early to blame MSVC for this issue.
Could be a compiler error or could be sloppy programming which leads to unexpected behaviour when that kind of optimization is active. Again - to me it feels a lot like it has to do with signed integer overflow handling. 
Signed integer overflow behaviour is undefined per C++11 standard. 
Without optimizations signed integer overflow will simply wrap around (this is simply what the processor does). With optimizations anything can happen...
You actually do not really know, if the issue is not also present in gcc builds, because the effects are not necessarily obvious - could be there are only slight variations in OCR results.

As you use gcc I would kindly suggest to create a build with the gcc option -ftrapv (and maybe other options necessary to bring the debugger to break on integer overflows) and try the test case I provided to see if it actuall produces integer overflows. If so this makes a case to investigate further in that direction. A Tesseract executable which was compiled with `-ftrapv` does not raise an overflow exception. What about debugging the buggy Windows executable and setting a conditional breakpoint on `pixCreateHeader` (waiting for `height <= 0`)? Oh - so it looks like the integer overflow hypothesis is dead.
About pixCreateHeader: I searched for that already. Unfortunately I did not build leptonica from source and it does not look like this function is called from anywhere outside leptonica. I tested the latest binary from [AppVeyor](https://ci.appveyor.com/api/buildjobs/qlkwgwrntp1gnr7l/artifacts/build%2Fbin%2Ftesseract-master.1240.zip). It shows the same problem when running `tesseract --oem 1 Test.tif stdout` with LSTM.

It looks like `pixCreateHeader` is called with height == 0.  Hello everyone and thanks for the library.

I'm on Linux, using Tesseract 3.05.01, Leptonica 1.74.4. Building both from source. I have built them with no problem.

What I want to achieve is, statically link leptonica and tesseract to a shared object, which uses the functions from tesseract's API. Following this linkage, I wanted to link this shared object to an executable. Finally, there should be an executable with a shared object and these should not need any other shared object.

I've successfully linked the libraries to shared object(I thought so) but when I try to link to the executable, I see that Leptonica functions are not linked. What am I doing wrong?

The linking of the shared object:
```
g++ -I. -I/usr/local/include/tesseract -I/usr/local/include/leptonica -std=gnu++11 wrap.cpp  /usr/local/lib/liblept.a /usr/local/lib/libtesseract.a -shared -o wrap.so -fPIC -Wl,-Bsymbolic
```

Linking of the executable:
```
gcc test.c -o test wrap.so
```

The error I receive:
```
wrap.so: undefined reference to `sem_init'
wrap.so: undefined reference to `pixExpandReplicate'
wrap.so: undefined reference to `pixConvertTo8'
wrap.so: undefined reference to `pixGetWpl'
...
...
wrap.so: undefined reference to `pixConvertTo32'
wrap.so: undefined reference to `pixaCreate'
wrap.so: undefined reference to `sem_wait'
collect2: error: ld returned 1 exit status
```

What should I do to overcome these linkage problems?

I've attached the wrap.cpp, wrap.h and test.c:
[Code.zip](https://github.com/tesseract-ocr/tesseract/files/1500978/Code.zip)

### Environment

* **Tesseract Version**: 3.05.01
* **Commit Number**: The 3.05.01 branch, no change to the source
* **Platform**: 3.10.0-327.el7.x86_64 #1 SMP Thu Nov 19 22:10:57 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
  Hello,

Releases 3.05.00 and 3.05.01 are missing `./configure` in release bundle
Im struggling to build tesseract for 3 days now

Also, release 3.05.01 is missing build fixes from 3.05 branch
Would be great if you could re-upload release bundles with them

Appreciated You're supposed to run ./autogen.sh as a first step, which will generate the configure script. You (the developer) are supposed to do that, and generate a tarball from the result, and upload it to GitHub as a release download. @amitdo yes, i understand, but for some reason i had to resolve a bunch of errors with autogen.sh, and finally ended up with
```
./configure: line 17577: syntax error near unexpected token `LEPTONICA,'
./configure: line 17577: `PKG_CHECK_MODULES(LEPTONICA, lept >= 1.74, have_lept=true, have_lept=false)'
```
even with `pkg-config` installed

i've successfully builded 3.04.01 witch seems to be the last release with bundled `./configure`

Any help appreciated  If you installed pkg-config after you ran autogen.sh, re-run autogen.sh.  @amitdo i re-run autogen.sh a million times already... :( Leptonica is built from source:
https://github.com/DanBloomberg/leptonica/releases/download/1.74.4/leptonica-1.74.4.tar.gz
with:
```
./configure --prefix=$pkg_prefix
make
make install
```

Building tesseract from release tar 3.05.00 I'm getting:
```
...
checking for mbstate_t... yes
checking for leptonica... configure: error: leptonica not found
```

Building tesseract from git branch 3.05 I'm getting:
```
...
checking for mbstate_t... yes
./configure: line 17577: syntax error near unexpected token `LEPTONICA,'
./configure: line 17577: `PKG_CHECK_MODULES(LEPTONICA, lept >= 1.74, have_lept=true, have_lept=false)'
```

Build script is the same:
```
  libtoolize
  ./autogen.sh
  ./configure --enable-debug \
	  --prefix="${pkg_prefix}" \
	  --host=x86_64-pc-linux-gnu \
	  --with-extra-includes=$(pkg_path_for tpolekhin/leptonica)/include \
	  --with-extra-libraries=$(pkg_path_for tpolekhin/leptonica)/lib
  make
```

Also, `pkg-config --cflags lept` and `pkg-config --libs lept` gives:
```
-I/hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/include/leptonica
-L/hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/lib -llept
``` Building from release tar 3.05.01 is the same:
```
./configure: line 17577: syntax error near unexpected token `LEPTONICA,'
./configure: line 17577: `PKG_CHECK_MODULES(LEPTONICA, lept >= 1.74, have_lept=true, have_lept=false)'
``` Nothing if this helps also:
`LIBLEPT_HEADERSDIR=$(pkg_path_for tpolekhin/leptonica)/include`
`LIBLEPT_HEADERSDIR=$(pkg_path_for tpolekhin/leptonica)/include/leptonica` So this means nothing?
```
pkg-config --cflags lept
-I/hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/include/leptonica
pkg-config --libs lept
-L/hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/lib -llept
```

And also:
`PKG_CONFIG_PATH=/hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/lib/pkgconfig`
```
ll /hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/lib/pkgconfig
total 4
-rw-r--r-- 1 root root 379 Nov 24 11:38 lept.pc
``` I've found why i have v3.04.00 building normally
configure.ac in branch 3.04 is missing this:
`PKG_CHECK_MODULES([LEPTONICA], [lept >= 1.74], [have_lept=true], [have_lept=false])`
that is present in 3.05 I think that the issue here is that autoconf can't find pkg-config m4 macros for PKG_CHECK_MODULES
Here's what i found in `config.log`
```
ACLOCAL='${SHELL} /hab/cache/src/tesseract-3.05.01/config/missing aclocal-1.15'
``` @zdenop tried `ACLOCAL_FLAGS="-I /hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/" ./autogen.sh` with same error :( Did you install `autoconf-archive` (or another package needed for your Linux distribution which provides the macro `PKG_CHECK_MODULES`? okay, so the issue was that `automake/share/aclocal/` was missing `pkg.m4` The `PKG_CHECK_MODULES` macro comes from `pkg-config`
https://cgit.freedesktop.org/pkg-config/tree/pkg.m4.in https://stackoverflow.com/a/10229811  I am naive to tesseract and LSTM. I read tesseract tutorial on wiki and I tried to train lstmtraining from the scratch using the following command: 

training/tesstrain.sh --fonts_dir /usr/share/fonts/truetype/khmeros-ttf --fontlist "Khmer OS" --langdata_dir langdata --lang khm --linedata_only --noextract_font_properties --tessdata_dir /home/phyrum/tesseract/tessdata --output_dir khmtrain

training/lstmtraining --debug_interval -1 \
  --traineddata khmtrain/khm/khm.traineddata \
  --net_spec '[1,36,0,1 Ct3,3,16 Mp3,3 Lfys48 Lfx96 Lrx96 Lfx256 O1c111]' \
  --model_output khmoutput/base --learning_rate 20e-4 \
  --train_listfile khmtrain/khm.training_files.txt \
  --max_iterations 10000 &> khmoutput/basetrain.log
[
[basetrain.log](https://github.com/tesseract-ocr/tesseract/files/1494522/basetrain.log)
![tesseract_version](https://user-images.githubusercontent.com/17153459/33108746-5759945a-cf70-11e7-99e7-9561fc79212d.png)
![training_lstmtraining_tesseract](https://user-images.githubusercontent.com/17153459/33108806-b06d9ae6-cf70-11e7-8a05-75233c5d6ba4.png)
](url)
=> After lstmtraining finished, I got only **"basetrain.log"** and **"base_checkpoint"** but I cannot find the final "khm.traineddata". and I really don't know why. Could you please help me? 

### Environment

* **Tesseract Version**: tesseract 4.00.00dev-691-gfb359fc
* **Platform**: Linux phyrum 4.10.0-38-generic #42~16.04.1-Ubuntu SMP Tue Oct 10 16:32:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

**Note:** I also submitted detail question in tesseract-ocr mailing list with the title **"LSTMTRAINING from the scratch for khmer language - Legacy Limon Fonts"**. Could you please check and give me some advices?
  @amitdo 
@stweil 
@egorpugin 

I'd like to stop supporting old giflib versions, before 5.1 when the interface was last changed.
leptonica is currently supporting 4.1.6 and 5.0, as well as 5.1+.

Is this practical? What would be effect be on tesseract if giflib 5.1+ were required? Hi Dan!

I think it's OK to move to 5.1 as the minimum version.

https://packages.debian.org/search?searchon=sourcenames&keywords=giflib
https://packages.ubuntu.com/search?searchon=sourcenames&keywords=giflib

Gif support is not very critical for OCR purpose.

Maybe you should target a new release for Ubuntu 18.04 LTS. OK.  Will drop pre-5.1 giflib support.

And I expect to have a new leptonica release in Dec or Jan that Jeff will
debianize for 18.04.

On Mon, Nov 20, 2017 at 4:12 PM, Amit D. <notifications@github.com> wrote:

> Hi Dan!
>
> I think it's OK to move to 5.1 as the minimum version.
>
> https://packages.debian.org/search?searchon=sourcenames&keywords=giflib
> https://packages.ubuntu.com/search?searchon=sourcenames&keywords=giflib
>
> Gif support is not very critical for OCR purpose.
>
> Maybe you should target a new release for Ubuntu 18.04 LTS.
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1215#issuecomment-345873534>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLAoZhoJmbkplzjGxJO5utvgYg55qks5s4hVjgaJpZM4Qk_7k>
> .
>
 CC'ing @jbreiden. `libgif4` (4.1.6) was last used in Debian's `oldstable`, so I see no problem in dropping support for that version. Support for 5.1 which is used by Debian `stable` is required of course. libgif support in gifio.c cleaned up.
Old pre-5.1 distributions are no longer supported.
libgif 5.1 or later only (and not 5.1.2) MacPorts uses giflib 4.2.3, because when giflib 5 was released, its API was different from giflib 4 and nothing supported the new API, so updating to giflib 5 would have broken everything that uses giflib. See [this MacPorts ticket](https://trac.macports.org/ticket/35817) for my investigations into that. Granted that was 5 years ago and maybe some projects have now added giflib 5 support. But I count 68 different ports in MacPorts that use giflib, and I don't know if all of those projects have added giflib 5 support, but my strong suspicion is that they have not, because some of them are probably not in development anymore.

All of which is to say that if you drop giflib 4 support, it will be a lot of work for me in MacPorts to probably create separate giflib 4 and 5 ports and then update and test those 68 ports. We don't currently have that, but yes, I will probably need to work on doing that. Homebrew supports giflib 5.1.4.
https://github.com/Homebrew/homebrew-core/blob/master/Formula/giflib.rb Ryan, I'm sorry to hear that.  I know what a pain it is when a basic library changes its interface. The gifilib interface changed at 5.0 and at 5.1.  If you look at leptonica gifio.c from 1.74.4, you'll see what I had to do to support 4.6.x and 5.0 and 5.1+.

Have another look, and if you still want me to revert, at least to give you more time to bring macports up to date, let me know and I will do so.

  -- Dan Ah, I see you already committed the removal in https://github.com/DanBloomberg/leptonica/commit/64961e9ae9151f9c9e251de9fe7be0363e780fbd.

Maybe that will motivate me to finally deal with giflib 5 in MacPorts. The offer still stands, if you need it.  I expect that version 1.75 will be released some time in January, to set your time frame. Makes sense.  Ryan, I'll revert the gifio.c change for 1.75.   The error messages come from Leptonica.
  Try to isolate the problem and find out which function/method call triggers the error.

Start by calling only Leptonica functions:

>pixWriteAutoFormat("F:/test.jpg", croppedImage);
Pix* test = pixRead("F:/test.jpg");
  getting table capture....... in excel....
input like.....
can anyone tell me how get table data each cell seperately.....
![1](https://user-images.githubusercontent.com/32842699/32480565-74a9438c-c3b5-11e7-96df-57c6a81c7d17.jpg)

 i am got getting ...
i am getting result.... like this....
110 - ‡§™‡•à‡§†‡§£ ‡§µ‡§ø‡§ß‡§æ‡§®‡§∏‡§≠‡§æ ‡§Æ‡§§‡§¶‡§æ‡§∞ ‡§∏‡§Ç‡§ò

‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™ ‡§Æ‡§§‡§¶‡§æ‡§∞ ‡§Ø‡§æ‡§¶‡•Ä 2017
‡§∞‡§æ‡§ú‡•ç‡§Ø - (‡§è‡§∏ 13) ‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞

‡§Ø‡§æ‡§¶‡•Ä ‡§≠‡§æ‡§ó ‡§ï‡•ç‡§∞‡§Æ‡§æ‡§Ç‡§ï : 2

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

1 ‡§®‡§æ‡§Ø‡§ó‡§µ‡•ç‡§π‡§æ‡§£/‡§π‡§®‡•Å‡§Æ‡§Ç‡§§‡§ó‡§æ‡§Ç‡§µ/‡§ñ‡§Ç‡§°‡•á‡§µ‡§æ‡§°‡•Ä
‡§§‡§æ. ‡§™‡•à‡§†‡§£ ‡§ú‡§ø. ‡§î‡§∞‡§Ç‡§ó‡§æ‡§¨‡§æ‡§¶ ‡§™‡§ø‡§®‡§ï‡•ã‡§° 431105
11 1‡•ê0870659 2] 1‡•ê0870758 31 7\√ó4202057
‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ï‡•ã‡§Ç‡§°‡•Ä‡§∞‡§æ‡§Æ ‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§∂‡•ç‡§∞‡•Ä‡§Æ‡§§‡§Ç ‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§Ö‡§∂‡•ã‡§ï
‡§®‡§æ‡§Ç‡§µ ‡§Æ‡•ã‡§π‡§® ‡§®‡§æ‡§Ç‡§µ ‡§ï‡•ã‡§Ç‡§°‡•Ä‡§∞‡§æ‡§Æ ‡§®‡§æ‡§Ç‡§µ ‡§≠‡§æ‡§®‡•Å‡§¶‡§æ‡§∏
‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§Æ‡•ã‡§π‡§® Photo ‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ï‡•ã‡§Ç‡§°‡•Ä‡§∞‡§æ‡§Æ Photo ‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§≠‡§æ‡§®‡•Å‡§¶‡§æ‡§∏ Photo
‡§ò‡§∞‡§ï‡•ç‡§∞‡§Æ‡§æ‡§Ç‡§ï ; 1 ‡•™990 |) ‡§ò‡§∞‡§ï‡•ç‡§∞‡§Æ‡§æ‡§Ç‡§ï : 1 Available || RT : 3 Available
‡§µ‡§Ø: 78 ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§µ‡§Ø: 35 ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§µ‡§Ø: 29‡•ß ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑
41 1‡•ê30873273 5] 6‡•™1
‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§®‡§æ‡§•‡§æ ‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ï‡§ö‡§∞‡§æ‡§¨‡§æ‡§à ‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§∏‡•Å‡§®‡§ø‡§§‡§æ ‡§®‡§æ‡§•‡§æ
‡§®‡§æ‡§Ç‡§µ ‡§ï‡•ã‡§Ç‡§°‡•Ä‡§∞‡§æ‡§Æ ‡§®‡§æ‡§Ç‡§µ ‡§®‡§æ‡§•‡§æ ‡§®‡§æ‡§Ç‡§µ
‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ï‡•ã‡§Ç‡§°‡•Ä‡§∞‡§æ‡§Æ Photo ‡§™‡§§‡•Ä‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§®‡§æ‡§•‡§æ Photo ‡§™‡§§‡•Ä‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§®‡§æ‡§•‡§æ Photo
‡§ò‡§∞ ‡§ï‡•ç‡§∞‡§Æ‡§æ‡§Ç‡§ï :? Available || RT | : 2 Available || RT | : 2 Available
‡§µ‡§Ø: 5 ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§µ‡§Ø: 52‡•® for ‚Äò@t ‡§µ‡§Ø: 48 ‡§≤‡§ø‡§Ç‡§ó ‚Äò@t
7] 7\√ó4202008 ‡•™1 JSFO870626 9|
‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§¶‡•á‡§∏‡§æ‡§à ‡§∞‡§Æ‡•á‡§∂ ‡§π‡§∞‡•Ä‡§≠‡§æ‡§â ‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§≠‡§æ‡§®‡•Å‡§¶‡§æ‡§∏ ‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ï‡§°‡•Ç‡§¨‡§æ‡§à
‡§®‡§æ‡§Ç‡§µ ‡§®‡§æ‡§Ç‡§µ ‡§ï‡•ã‡§Ç‡§°‡•Ä‡§∞‡§æ‡§Æ ‡§®‡§æ‡§Ç‡§µ ‡§≠‡§æ‡§®‡•Å‡§¶‡§æ‡§∏
‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§¶‡•á‡§∏‡§æ‡§à ‡§π‡§∞‡•Ä‡§≠‡§æ‡§â Photo ‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ï‡•ã‡§Ç‡§°‡•Ä‡§∞‡§æ‡§Æ Photo ‡§™‡§§‡•Ä‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§≠‡§æ‡§®‡•Å‡§¶‡§æ‡§∏ Photo
‡§ò‡§∞‡§ï‡•ç‡§∞‡§Æ‡§æ‡§Ç‡§ï : 3 Available || RT : 3 Available || RT : 3 Available
‡§µ‡§Ø: 52‡•® ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§µ‡§Ø: 5 ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§µ‡§Ø: 4‡•ß ‡§≤‡§ø‡§Ç‡§ó ‚Äò@t
101 7\%6412993 111 7\%4201976 12] 7\%6045025
‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§¶‡•á‡§∏‡§æ‡§à ‡§∞‡§æ‡§£‡•Ä ‡§®‡§æ‡§®‡§æ‡§∏‡§æ‡§π‡•á‡§¨ ‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§¶‡•á‡§∏‡§æ‡§à ‡§õ‡§æ‡§Ø‡§æ ‡§¨‡§¶‡•ç‡§∞‡•Ä‡§®‡§æ‡§• ‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§¶‡•á‡§∏‡§æ‡§à ‡§∏‡§Ç‡§ó‡•Ä‡§§‡§æ
‡§®‡§æ‡§Ç‡§µ ‡§®‡§æ‡§Ç‡§µ ‡§®‡§æ‡§Ç‡§µ ‡§¨‡§æ‡§¨‡§æ‡§∏‡§æ‡§π‡•á‡§¨
‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§¶‡•á‡§∏‡§æ‡§à ‡§®‡§æ‡§®‡§æ‡§∏‡§æ‡§π‡•á‡§¨ Photo ‡§™‡§§‡•Ä‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§¶‡•á‡§∏‡§æ‡§à ‡§¨‡§¶‡•ç‡§∞‡•Ä‡§®‡§æ‡§• Photo ‡§™‡§§‡•Ä‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§¶‡•á‡§∏‡§æ‡§à ‡§¨‡§æ‡§¨‡§æ‡§∏‡§æ‡§π‡•á‡§¨ Photo
‡§ò‡§∞ ‡§ï‡•ç‡§∞‡§Æ‡§æ‡§Ç‡§ï : ‡•¶‡•© Available || RT | : 4 Available || | : ox Available
‡§µ‡§Ø: 20 ‡§≤‡§ø‡§Ç‡§ó : ‡§∏‡•ç‡§§‡•ç‡§∞‡•Ä ‡§µ‡§Ø: 30 ‡§≤‡§ø‡§Ç‡§ó ‚Äò@t ‡§µ‡§Ø: 30 ‡§≤‡§ø‡§Ç‡§ó ‚Äò@t
13] 7\%6412977 14] 7\%6412985 15]
‡§Æ‡•Å‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§¶‡•á‡§∏‡§æ‡§à ‡§ï‡§≤‡•ç‡§Ø‡§æ‡§£‡•Ä ‡§Ø‡•ã‡§ó‡•á‡§∂ ‡§Æ‡•Å‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§¶‡•á‡§∏‡§æ‡§à ‡§∞‡•á‡§£‡•Å‡§ï‡§æ ‡§∏‡§§‡•Ä‡§∂ ‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ß‡•ã‡§Ç‡§°‡•Ä‡§∞‡§æ‡§Æ
‡§™‡§§‡•Ä‡§ö‡•á ‡§®‡§æ‡§Ç‡§¨ : ‡§¶‡•á‡§∏‡§æ‡§à ‡§Ø‡•ã‡§ó‡•á‡§∂ Photo ‡§™‡§§‡•Ä‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§¶‡•á‡§∏‡§æ‡§à ‡§∏‡§§‡•Ä‡§∂ Photo ‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§Æ‡•ã‡§π‡§® Photo
‡§ò‡§∞ ‡§ï‡•ç‡§∞‡§Æ‡§æ‡§Ç‡§ï : ‡•¶‡•™ ‡•™990 |) ‡§ò‡§∞‡§ï‡•ç‡§∞‡§Æ‡§æ‡§Ç‡§ï : ‡•¶‡•™ Available || RT : 5 Available
‡§µ‡§Ø: 23 ‡§≤‡§ø‡§Ç‡§ó ` ‡§∏‡•ç‡§§‡•ç‡§∞‡•Ä ‡§µ‡§Ø: 21 ‡§≤‡§ø‡§Ç‡§ó ` ‡§∏‡•ç‡§§‡•ç‡§∞‡•Ä ‡§µ‡§Ø: 70 ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑
161 ‚Äî JSFO871137 17] 7\%0530014 18] 7\%4201950
‡§™‡•Å‡§∞‡•ç‡§£ - 7 ‡§™‡•Å‡§∞‡•ç‡§£ - T ‡§™‡•Å‡§∞‡•ç‡§£ -
‡§™‡§§‡•Ä‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ß‡•ã‡§Ç‡§°‡•Ä‡§∞‡§æ‡§Æ Photo ‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ß‡•ã‡§Ç‡§°‡•Ä‡§∞‡§æ‡§Æ Photo ‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ß‡•ã‡§Ç‡§°‡•Ä‡§∞‡§æ‡§Æ Photo
‡§ò‡§∞‡§ï‡•ç‡§∞‡§Æ‡§æ‡§Ç‡§ï : 5 ‡•™190 |) ‡§ò‡§∞‡§ï‡•ç‡§∞‡§Æ‡§æ‡§Ç‡§ï ;: Available || RT | : 5 Available
‡§µ‡§Ø: ‡•´4‡•´ ‡§≤‡§ø‡§Ç‡§ó ` ‡§∏‡•ç‡§§‡•ç‡§∞‡•Ä ‡§µ‡§Ø: 35 ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§µ‡§Ø: 3‡•® ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑
191 7\%4201968 201 27%6413017 211 2736413090
‡§Æ‡•Å‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§Æ‡•Å‡§π‡•ç‡§Ø‡•Å‡§≤‡§® ‡§ó‡•ã‡§∞‡§ñ‡§®‡§æ‡§• ‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§¶‡•á‡§∏‡§æ‡§à ‡§∏‡•ç‡§µ‡§æ‡§§‡•Ä ‡§ó‡§£‡•á‡§∂ ‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§∏‡§Ç‡§§‡•ã‡§∑ ‡§∏‡§Ç‡§ú‡§Ø
‡§®‡§æ‡§µ ‡§®‡§æ‡§µ ‡§®‡§æ‡§µ
‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ß‡•ã‡§Ç‡§°‡•Ä‡§∞‡§æ‡§Æ Photo ‡§™‡§§‡•Ä‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§¶‡•á‡§∏‡§æ‡§à ‡§ó‡§£‡•á‡§∂ Photo ‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§∏‡§Ç‡§ú‡§Ø Photo
‡§ò‡§∞‡§ï‡•ç‡§∞‡§Æ‡§æ‡§Ç‡§ï : 5 Available || RFT¬Æ | : on Available || RFT¬Æ | : on Available
‡§µ‡§Ø: 31 ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§µ‡§Ø: 25 ‡§≤‡§ø‡§Ç‡§ó ` ‡§∏‡•ç‡§§‡•ç‡§∞‡•Ä ‡§µ‡§Ø: 2‡•¶ ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑
221 23| ‚Äî JSFO872622 241 ‚Äî ZYX0530022
your ur . mem g ‡§Æ‡•Å‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ï‡§°‡•Ç‡§¨‡§æ‡§à ‡§ñ‡§Ç‡§°‡•Ç ‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ï‡§ö‡§∞‡•Ç ‡§ñ‡§Ç‡§°‡•Ç
‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§Æ‡•ã‡§π‡§® Photo ‡§™‡§§‡•Ä‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ñ‡§Ç‡§°‡•Ç Photo ‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ñ‡§Ç‡§°‡•Ç Photo
: 6 Available || RT _ : 6 Available || RT _ : 6 Available
‡§µ‡§Ø: 6‡•´6 ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§µ‡§Ø: 55 fr ‚Äò@t ‡§µ‡§Ø: 33‡•© ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑
251 ‚Äî ZYX0530204 2681 ‚Äî JSFO871665 27| ‚Äî JSFO871178
‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ï‡•à‡§≤‡§æ‡§∏ ‡§ñ‡§Ç‡§°‡•Ç ‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§ó‡§æ‡§¢‡•á‡§ï‡§∞ ‡§≠‡§æ‡§µ‡§∞‡§æ‡§µ ‡§≤‡§ø‡§Ç‡§¨‡§æ ‡§Æ‡§§‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§ó‡§æ‡§¢‡•á‡§ï‡§∞ ‡§ï‡•á‡§∏‡§∞‡§¨‡§æ‡§à
‡§®‡§æ‡§Ç‡§µ ‡§®‡§æ‡§Ç‡§µ ‡§®‡§æ‡§Ç‡§µ ‡§≠‡§æ‡§µ‡§∞‡§æ‡§µ
‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ñ‡§Ç‡§°‡•Ç Photo ‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§ó‡§æ‡§¢‡•á‡§ï‡§∞ ‡§≤‡§ø‡§Ç‡§¨‡§æ Photo ‡§™‡§§‡•Ä‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§ó‡§æ‡§¢‡•á‡§ï‡§∞ ‡§≠‡§æ‡§µ‡§∞‡§æ‡§µ Photo
: 6 Available || RT _ : 6 Available || RT _ : 6 Available
‡§µ‡§Ø: 30‡•¶ ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§µ‡§Ø: 6‡•ß ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§µ‡§Ø: 6‡•¶ fr ‚Äò@t
281 ‚Äî ZYX0499103 29 ‚Äî ZYX6412928 30| ‚Äî JSFO907899
yh ; men ‡§™‡•ç‡§∞‡§≠‡•Å ‡§≠‡§æ‡§â‡§∞‡§æ‡§µ ‡§Æ‡•Å‡§§‡•É‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§µ‡•à‡§∂‡§æ‡§≤‡•Ä ‡§ï‡•à‡§≤‡§æ‡§∂ ‡§Æ‡§§‡•É‡§¶‡§æ‡§∞‡§æ‡§ö‡•á ‡§™‡•Å‡§∞‡•ç‡§£ : ‡§≤‡§ø‡§¨‡•ã‡§∞‡•á ‡§∏‡•Å‡§≠‡§¶‡•ç‡§∞‡§¨‡§æ‡§à ‡§®‡§Ç‡§¶‡•Ç
‡§µ‡§°‡•Ä‡§≤‡§æ‡§Ç‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§ó‡§æ‡§°‡•á‡§ï‡§∞ ‡§≠‡§æ‡§â‡§∞‡§æ‡§µ Photo ‡§™‡§§‡•Ä‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§Æ‡§π‡§æ‡§ú‡§® ‡§ï‡•à‡§≤‡§æ‡§∂ Photo ‡§™‡§§‡•Ä‡§ö‡•á ‡§®‡§æ‡§Ç‡§µ : ‡§≤‡§ø‡§¨‡•ã‡§∞‡•á ‡§®‡§Ç‡§¶‡•Ç Photo
: 6 Available || RT | : ‡•¶‡•¨ Available || RTs | : 7 Available
ans os ‡§≤‡§ø‡§Ç‡§ó ` ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§µ‡§Ø: 26 ‡§≤‡§ø‡§Ç‡§ó : ‡§∏‡•ç‡§§‡•ç‡§∞‡•Ä ‡§µ‡§Ø: 44 ‡§≤‡§ø‡§Ç‡§ó ‚Äò@t
01/01/2017 ‡§∞‡•ã‡§ú‡•Ä < aa ran ‡§®‡•å‡§Ø‡§£‡•Ä ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡•Ä ‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§ó‡§∞‡•á ‡§™‡•É‡§∑‡•ç‡§† ‡§ï‡•ç‡§∞‡§Æ‡§æ‡§Ç‡§ï : 3

 
I want output like.................................................
![dddd](https://user-images.githubusercontent.com/32842699/32481144-12195efc-c3b8-11e7-92bb-fe5ba644ba00.jpg)

 

 

 

 

 

 

 

 

 

 

 

 

  ### Environment

* **Tesseract Version**: 4.0.0-alpha
* **Platform**: Windows 10 64-bit 

### Current Behavior
get the tesseract  by compiling the source code .
visual studio 2015 update 3
using api to call tesseract
`char* outText = api->GetUTF8Text();`
when I free the pointer outText like following code:
`delete[]  outText`
while using the **release mode** to compile the code, running ok ! 
but using the **debug mode**, the program definately crash! 
### Expected Behavior:

### Suggested Fix:
 https://github.com/tesseract-ocr/tesseract/wiki/APIExample

>// Destroy used object and release memory
>    api->End();
>    delete[] outText;

Did you call `api->End()` ? surley I did @hoangtocdo90 tks for your reply man, but it doesnt seem like what you gave.  see https://github.com/tesseract-ocr/tesseract/issues/1030  I am trying to build the latest from git on Fedora 26, 4.13.10-200.fc26.x86_64.

While run ./configure, following error was reported:

./configure: line 4243: syntax error near unexpected token `-mavx,'
./configure: line 4243: `AX_CHECK_COMPILE_FLAG(-mavx, avx=true, avx=false)'

 You can also use the search options in GitHub.

https://github.com/tesseract-ocr/tesseract/issues?q=is%3Aissue+AX_CHECK_COMPILE_FLAG+is%3Aclosed
  I have read that the training process run on 4 threads using openmp but viewing cpu utilization I can see it only uses 1 thread? Is there something special I need to do to make it run using openmp? I am using gcc 4.8
  I am attempting to run this:

```
lapply(myfiles, function(i){

    shell(shQuote(paste0("pdftopng -f 1 -l 10 -r 600 ", i, " ocrbook")))
mypngs <- list.files(path = dest, pattern = "png", full.names = TRUE)
lapply(mypngs, function(z){
    shell(shQuote(paste0("tesseract ", z, " out")))
    #file.remove(paste0(z))
    })
})
```


However, even though I am feeding it a PNG file, I get the error
```
Tesseract Open Source OCR Engine v3.05.01 with Leptonica
Error in pixCreateNoInit: pix_malloc fail for data
Error in pixCreate: pixd not made
Error in pixReadStreamPng: pix not made
Error in pixReadStream: png: no pix returned
Error in pixRead: pix not read
Error during processing.
```
```
1: running command 'C:\Windows\system32\cmd.exe /c "tesseract C:\users\gallowmb\desktop/ocrbook-000001.png out"' had status 1 
2: In shell(shQuote(paste0("tesseract ", z, " out"))) :
  '"tesseract C:\users\gallowmb\desktop/ocrbook-000001.png out"' execution failed with error code 1
```


phototest works.  There seems to be an issue with the file itself.  What is the issue?


RStudio 1.1.383
Tesseract 3.05.01
Win 7 64 bit zdenop, here is the output of tesseract -v in CMD.
```

tesseract 3.05.01
  leptonica-1.74.1
   lipgif 4.1.6(?)  :  libjpeg 8d (libjpeg-turbo 1.5.0)  :  libpng 1.6.20  :  libtiff 4.0.6  :  
   zlib 1.2.8  :  libwebp 0.4.3  :  libopenjp2 2.1.0
```


I have converted the PDF to a TIFF, and rerun it, and the tesseract error is this:

`Error in PixReadFromTiffStream: calloc fail for tiffdata` Hi, I found what the problem was after using an example scanned PDF from the internet.  The DPI was too high for the PDFtoPNG conversion.  I took it down to 150 and it worked like a charm.  It seems there is a DPI limit for Tesseract.  

So I went from this:
` shell(shQuote(paste0("pdftopng -f 1 -l 10 -r 600 ", i, " ocrbook")))`

To this:
` shell(shQuote(paste0("pdftopng -f 1 -l 10 -r 150 ", i, " ocrbook")))` I also updated my script to have a more dynamic name, so no overwriting because of static naming.

```

dest <- "C:\\users\\yourname\\desktop"

      files <- tools::file_path_sans_ext(list.files(path = dest, pattern = "pdf", full.names = TRUE))
        lapply(files, function(i){
          shell(shQuote(paste0("pdftoppm -f 1 -l 10 -r 150 ", i,".pdf", " ",i)))
          })
      
      
      myppms <- tools::file_path_sans_ext(list.files(path = dest, pattern = "ppm", full.names = TRUE))
        lapply(myppms, function(y){
          shell(shQuote(paste0("magick ", y,".ppm"," ",y,".tif")))
          file.remove(paste0(y,".ppm"))
          })
  
      mytiffs <- tools::file_path_sans_ext(list.files(path = dest, pattern = "tif", full.names = TRUE))
        lapply(mytiffs, function(z){
          shell(shQuote(paste0("tesseract ", z,".tif", " ",z)))
          file.remove(paste0(z,".tif"))
          })

``` In addition to the above, make sure image magick has a specified DPM.  So for the Image Magick part of the script, the options need to include "-density 300" or something of that nature.

Like such (along with a multitude of other options)
```
      myppms <- tools::file_path_sans_ext(list.files(path = dest, pattern = "ppm", full.names = TRUE))
        lapply(myppms, function(y){
          shell(shQuote(paste0("magick -colorspace gray ", y,".ppm","  -density 300 -depth 8 -flatten -auto-orient -auto-level -rotate -90^> +dither -colors 2 -normalize"," ",y,".tif")))
          file.remove(paste0(y,".ppm"))
          })
```  Is it possible to create a trainned data without the tesstrain.sh script in wiindows?  ### Environment

* **Tesseract Version**: Current main repository (4.00.00alpha)
* **Platform**: Windows7 32-bit

### Current Behavior:
Its recognize Arabic Characters and can not recognize Arabic numbers (ÿßÿ±ŸÇÿßŸÖ ÿπÿ±ÿ®Ÿâ 0123456789)
I tried tessdata, tessdata_best, and tessdata_fast

### Expected Behavior:

### Suggested Fix:
 Did you try Arabic.traineddata? @amitdo yes It is recognize the characters (80% included the Latin numbers) and it does not recognize the Arabic numbers inside the red rectangle (the original without red rectangle )    
![my-national-identity-card-1-728](https://user-images.githubusercontent.com/32733104/32214667-4bf382c8-be28-11e7-9dc5-f415a7a4a02e.jpg)

I tried other pics with numbers only and i got no numbers
![arabnum](https://user-images.githubusercontent.com/32733104/32214946-29824b06-be29-11e7-9858-a5649222e41b.jpg)
![page0001](https://user-images.githubusercontent.com/32733104/32214999-5102d146-be29-11e7-8381-354b6ecebccf.jpg)


 @Shreeshrii @theraysmith Is there a changes handle all these issues but the repositories did not update yet or there is no fix ? ### Definition
* **AEN** Arabic Eastern Numbers {Ÿê123456789}
* **AWN** Arabic Western Numbers {0123456789}

I generated an experimental data file for recognaize **AEN Only**
The output of Tesseract OCR will be in the form of **AWN**

[https://github.com/ahmed-tea/tessdata_Arabic_Numbers](url)

@Shreeshrii @theraysmith The succeed rate for the pics above 100% (numbers only) but it depends on the pic quality in general

Combining with ara
****- current tesseract main repository** :** give an error (mgr->GetComponent(TESSDATA_INTTEMP, &fp):Error:Assert failed:in file classify\adaptmatch.cpp, line 537)
**- tesseract build by UB Mannheim :** give numbers only
**- best and fast (ara and Arabic) :** not applicable because they used for LSTM only so it give numbers only 

@Shreeshrii  @Shreeshrii  sorry for the question, how to combine the new tessdata_Arabic_Numbers with the current one?
I copied ara_number.traineddata into tessdata dir then I use this command:
`tesseract -l ara_number+ara  image.tif out.txt`

but doesn't work
 @Fahad-Alsaidi You can't combine it with ara   Hello,
with the help from @Shreeshrii  I could create box-files for improving the existing eng.traineddata for my purpose.

I could use these box files to create a new eng.traineddata. It works and is much better for reading my text. However, when I want to use this new eng.traineddata to create box files for new images, it fails with

read_params_file: Can't open makebox

If I leave everything else identical, but switch to the original eng.traineddata, everything works, and the boxes are created.

New Traineddata:
Version string:4.00.00alpha:eng:synth20170629:[1,36,0,1Ct3,3,16Mp3,3Lfys64Lfx96Lrx96Lfx512O1c1]
17:lstm:size=11689099, offset=192
18:lstm-punc-dawg:size=4322, offset=11689291
19:lstm-word-dawg:size=3694794, offset=11693613
20:lstm-number-dawg:size=4738, offset=15388407
21:lstm-unicharset:size=6360, offset=15393145
22:lstm-recoder:size=1012, offset=15399505
23:version:size=80, offset=15400517


Original Traineedata
Version string:4.00.00alpha:eng:synth20170629:[1,36,0,1Ct3,3,16Mp3,3Lfys64Lfx96Lrx96Lfx512O1c1]
17:lstm:size=11689099, offset=192
18:lstm-punc-dawg:size=4322, offset=11689291
19:lstm-word-dawg:size=3694794, offset=11693613
20:lstm-number-dawg:size=4738, offset=15388407
21:lstm-unicharset:size=6360, offset=15393145
22:lstm-recoder:size=1012, offset=15399505
23:version:size=80, offset=15400517


What did I do wrong?

Do you need more info? The script to create the boxes (thaks to @Shreeshrii !) is attached.


Thanks & kind regards
Ernst
Thanks 

 [makebox.txt](https://github.com/tesseract-ocr/tesseract/files/1420017/makebox.txt)
Script to make the boxes attached
 @Shreeshrii  Thank you very much for the fast help, that was the problem!
Kind regards
Ernst  
### Environment

* **Tesseract Version**:3.05 <!-- compulsory. you must provide your version -->

* **Platform**: windows 10<!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->

### Current Behavior:
I can compile it successfully in my this computer yesterday by such command
```
cppan
mkdir build && cd build
cmake ..
```
But after I reinstall the system today, it will give me such error information

> LINK : fatal error LNK1104: cannot open file ‚ÄúDebug\unicharset training.lib

But I cannot search any information about it. Can anybody can tell me something?  ### Environment

* **Tesseract Version**: 3.05<!-- compulsory. you must provide your version -->
* **Platform**: Microsoft Windows [version 10.0.15063]<!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->

### Current Behavior:
After build the *Tesseract* with [this method](https://github.com/tesseract-ocr/tesseract/wiki/Compiling#develop-tesseract). Then my `build/bin/Debug` directory contain this files:
```
    eng.traineddata
    phototest.tif
    pvt.cppan.demo.behdad.harfbuzz-1.5.1.dll
    pvt.cppan.demo.bzip2-1.0.6.dll
    pvt.cppan.demo.cairographics.cairo-1.15.6.dll
    pvt.cppan.demo.danbloomberg.leptonica-1.74.4.dll
    pvt.cppan.demo.expat-2.2.4.dll
    pvt.cppan.demo.freedesktop.fontconfig.fontconfig-2.12.1.dll
    pvt.cppan.demo.freetype-2.8.1.dll
    pvt.cppan.demo.gnome.glib.glib-2.50.3.dll
    pvt.cppan.demo.gnome.glib.gobject-2.50.3.dll
    pvt.cppan.demo.gnome.pango.pango-1.40.9.dll
    pvt.cppan.demo.gnome.pango.pangocairo-1.40.9.dll
    pvt.cppan.demo.gnome.pango.pangoft2-1.40.9.dll
    pvt.cppan.demo.gnu.gettext.intl-0.19.8.dll
    pvt.cppan.demo.gnu.iconv.libcharset-1.15.0.dll
    pvt.cppan.demo.gnu.iconv.libiconv-1.15.0.dll
    pvt.cppan.demo.jpeg-9.2.0.dll
    pvt.cppan.demo.madler.zlib-1.2.11.dll
    pvt.cppan.demo.openjpeg.openjp2-2.1.2.dll
    pvt.cppan.demo.pcre.pcre-8.40.0.dll
    pvt.cppan.demo.png-1.6.30.dll
    pvt.cppan.demo.tiff-4.0.8.dll
    pvt.cppan.demo.unicode.icu.common-59.1.0.dll
    pvt.cppan.demo.unicode.icu.data-59.1.0.dll
    pvt.cppan.demo.unicode.icu.i18n-59.1.0.dll
    pvt.cppan.demo.webp-0.6.0.dll
    pvt.cppan.demo.weltling.winlibs.libffi-3.2.1.dll
    pvt.cppan.demo.xz_utils.lzma-5.2.3.dll
    tesseract.exe
    tesseract.ilk
    tesseract.pdb
    tesseract400d.dll
    tesseract400d.ilk
    tesseract400d.pdb
```
I can run it in commandline now
`tesseract.exe phototest.tif stdout`

> Page 1
> This is a lot of 12 point text to test the
> ocr code and see if it works on all types
> of file format.
> 
> The quick brown dog jumped over the
> lazy fox. The quick brown dog jumped
> over the lazy fox. The quick brown dog
> jumped over the lazy fox. The quick
> brown dog jumped over the lazy fox.
> 

### Expected Behavior:
I hope to run it with code method, such as [this](https://github.com/tesseract-ocr/tesseract/wiki/APIExample#basic-example), but not in commandline. If I can get all `.lib`, then I can build a new project and import to use it. But I get few `.lib` and most `.dll`...So how to use it by [this code method](https://github.com/tesseract-ocr/tesseract/wiki/APIExample#basic-example)? @zdenop Help pleaase [here](https://groups.google.com/forum/#!topic/tesseract-ocr/WrwwaZsm9CY), it is confused me some days  ### Environment

* **Tesseract Version**: 
Tesseract Open Source OCR Engine v4.00.00dev-692-gad5ee184 with Leptonica

* **Platform**: 
Platform: Linux 4.9.43-17.39.amzn1.x86_64 #1 SMP x86_64 GNU/Linux


### Current Behavior:

The following command will crash in the above stated environment:
tesseract /tmp/tr_tmp.jpg /tmp/tr_tmp --tessdata-dir /var/task/tessdata --psm 12 --oem 2 -l eng hocr

tessdata is legacy data from tesseract-ocr/tessdata

Crash error: Assert failed:in file ../ccutil/unicharset.h, line 513

related jpg file: 
![c767234e7e51a92ee5a9c211f5892ad66b990e75-2](https://user-images.githubusercontent.com/399202/31865534-f08d1728-b73d-11e7-91b1-a31002dd1061.jpg)

related binaries:
[Archive.zip](https://github.com/tesseract-ocr/tesseract/files/1405268/Archive.zip)


### Expected Behavior:

When tesseract v4 using `--oem 2` and legacy trained data, error message of missing LSTM data should be printed instead of crashing.

### Suggested Fix:

n/a Thanks for the update. Where can I get the 'latest traineddata' please? I got my data from https://github.com/tesseract-ocr/tessdata/
 Thanks for your reply. Just to be rigid. I was using tessdata, which supports oem mode 2 according to the wiki. >The latest traineddatas (tessdata_best and Tessdata_fast) do not support legacy tesseract engine, so --oem 0 and --oem 2 are not supported.

Although I wrote something similar to the above remark in the wiki, since commits [1] and [2]. `--oem 0 -l osd` works with 'best' and 'fast'. Not sure about --oem 2.

[1] https://github.com/tesseract-ocr/tessdata_best/commit/f1d12682c0f1afe61db892f4b2bfaa7909ad7a59 
[2] https://github.com/tesseract-ocr/tessdata_fast/commit/139ff127aaee3cb0270fd29411fec75d610d728c
 Since the discussion is a bit side-tracked, I'm repeating the problem. The original comment is also updated.

Tesseract v4.00.00dev-692-gad5ee184 crashes when using `--oem 2` and `tesseract-ocr/tessdata`. The master branch (commit ad5ee18415bf59b9f5d1fd1806cb3aad3f18f381) runs good with your image @TerryZH 

However, tesseract should not crash
 @PaniniGelato Are you sure? As reported in the "Environment" section, this crash happens on the build from master commit ad5ee18. And I can still reproduce the crash. Did you use the same tessdata as described in my previous comment?  Hi,

i was using the newest versions of Tesseract to:
1- create LSTMFs
2- extract the LSTM from official traineddata
3- fine tune the LSTM according to the created LSTMFs
4- and then use the new traineddata for detection for better results
i was able to do all these steps and get the final traineddata but when i made detection using it i got an error, now the same case happened for Arabic and Japanese languages, and both i was able to get fine tuned traineddata and both failed in detection and gave the same error.
the commands i used as described [here](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#lstmtraining-command-line)
and they were: 
**for creating LSTMFs**
training/tesstrain.sh --fonts_dir ~/.local/share/fonts --lang ara --linedata_only --noextract_font_properties --langdata_dir /home/ibr/latest_leptonica_4/langdata --tessdata_dir ./tessdata --output_dir /home/ibr/latest_leptonica_4/lstmf_ara_lep4

**extracted LSTM from [*here*](https://github.com/tesseract-ocr/tessdata_best)

**tuned LSTM**
training/lstmtraining --model_output /home/ubuntu/lep_latest/ara_tune/tune_result/ara_tune \
  --continue_from /home/ubuntu/lep_latest/ara_tune/extracted/ara.lstm \
  --traineddata /home/ubuntu/lep_latest/ara_tune/original_traineddata/ara.traineddata \
  --train_listfile /home/ubuntu/lep_latest/ara_tune/ara.training_files.txt \
  --max_iterations 1200

**then unpacked official traineddata"official traineddata", replaced the tuned LSTM and combined everything together again **

**detection command**
tesseract ara2.png tuned -l ara --tessdata-dir ./tessdata --oem 1

and when i used the new tuned traineddata i got the error:
**index >= 0:Error:Assert failed:in file strngs.cpp, line 270
Segmentation fault (core dumped)** 

that happened when i tried fine tuning for Arabic and Japanese, twice, first time using the version:
**tesseract 4.00.00dev-690-g1b0379c   leptonica-1.74.4**
second time: **tesseract 4.00.00dev-691-gfb359fc  leptonica-1.74.4**

_keep im mind the same exact steps worked for previous versions of tesseract with leptonica 1.74.1_

**NOTE: detection worked fine with both versions for the official traineddata, meaning the error only occurred only after fine tuning**

Thanks in advance @Shreeshrii sorry, my mistake, i forgot to mention the command to create the LSTM from the check point which is:
_training/lstmtraining --model_output /home/ibr/latest_leptonica_4/ara_tune/tuned_lstm/ara.lstm --continue_from /home/ibr/latest_leptonica_4/ara_tune/results/ara_checkpoint --traineddata /home/ibr/latest_leptonica_4/ara_tune/original_traineddata/ara.traineddata --stop_training_

now, summarize everything,
**i create LSTMFs
extract LSTM from "best_traineddata"
tune LSTM according LSTMFs , in the command " --traineddata  best_traineddata"
create LSTM from checkpoint,  in the command " --traineddata  best_traineddata"
unpack  "best_traineddata"
replace LSTM with the new tuned one
combine everything**

"If you combine your fine-tune lstm with existing traineddata, the files
will not be in sync"
means in combination step i have to combine the new LSTM with the traineddata (starter traineddata) that is created when creating LSTMFs? 
i used "best_traineddata" in the command
_training/lstmtraining --model_output /home/ubuntu/lep_latest/ara_tune/tune_result/ara_tune 
--continue_from /home/ubuntu/lep_latest/ara_tune/extracted/ara.lstm 
--traineddata /home/ubuntu/lep_latest/ara_tune/original_traineddata/ara.traineddata 
--train_listfile /home/ubuntu/lep_latest/ara_tune/ara.training_files.txt 
--max_iterations 1200_
because if i pointed the --traineddata to the traineddata that is created with LSTMFs (starter traineddata)
i will get this message:
**Warning: LSTMTrainer deserialized an LSTMRecognizer!
Code range changed from 307 to 74!
Must supply the old traineddata for code conversion!
Failed to continue from: /home/ibr/latest_leptonica_4/ara_tune/extracted/ara.lstm
**
so since i got "Must supply the old traineddata" i used the trained data from "best_traineddata" the whole time, so what im missing?
Thanks
 the last two command actually worked and the traineddata i created is fine, i changed the first command to:
_training/lstmtraining --model_output /home/ubuntu/lep_latest/test/tuning_results/jpn \
  --continue_from /home/ubuntu/lep_latest/jpn_tune/extracted/jpn.lstm \
  --traineddata /home/ubuntu/lep_latest/jpn_tune/jpn_lstmf/jpn/jpn.traineddata \
  --old_traineddata /home/ubuntu/lep_latest/jpn_tune/original_traineddata/jpn.traineddata \
  --train_listfile /home/ubuntu/lep_latest/jpn_tune/jpn.training_files.txt \
  --max_iterations 3600_
but this command was in "Fine Tuning for ¬± a few characters" section, in my case i want only to train the best_traineddata to a new fonts only without changing it so i assumed that i needed to go though fine tuning but it didn't work, so does this tuning command covers it? 

also another question, when i run the above command sometime i get the message **checkpoint failed to write checkpoint**  when that message shows following command fails:
_training/lstmtraining --stop_training \
  --continue_from /home/ubuntu/lep_latest/test/tuning_results/jpn13.689_2618.checkpoint \
  --traineddata /home/ubuntu/lep_latest/jpn_tune/jpn_lstmf/jpn/jpn.traineddata \
  --model_output /home/ubuntu/lep_latest/test/traineddata/jpn.traineddata_
what causing this message to show?

Thanks  I meet a error while building training tools from source(4.0 master)
First, I build the tesseract-ocr which is successful.
1 yum install autoconf automake libtool libjpeg-devel libpng-devel libtiff-devel zlib-devel
2 build leptonica from source(leptonica-1.74.4)
3 build tesseract-ocr
   ./autogen.sh
  ./configure --prefix=/usr/local/tesseract --with-extra-libraries=/usr/local/leptonica/lib   
  make
  make install
--------------------------
Then I try to build training tools
1 yum install libicu-devel
2 yum install pango-devel
3 yum install cairo-devel
make training
But it comes the following error

`depbase=`echo boxchar.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../lstm -I../arch -I../viewer -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil  -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib64/glib-2.0/include   -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib64/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng15 -I/usr/include/libdrm    -g -O2 -std=c++11 -MT boxchar.lo -MD -MP -MF $depbase.Tpo -c -o boxchar.lo boxchar.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../lstm -I../arch -I../viewer -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib64/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib64/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng15 -I/usr/include/libdrm -g -O2 -std=c++11 -MT boxchar.lo -MD -MP -MF .deps/boxchar.Tpo -c boxchar.cpp  -fPIC -DPIC -o .libs/boxchar.o
boxchar.cpp: In member function 'void tesseract::BoxChar::GetDirection(int*, int*) const':
boxchar.cpp:67:42: error: 'U_RIGHT_TO_LEFT_ISOLATE' was not declared in this scope
         dir == U_ARABIC_NUMBER || dir == U_RIGHT_TO_LEFT_ISOLATE) {
                                          ^
make[1]: *** [boxchar.lo] Error 1
make[1]: Leaving directory `/home/lixl/workspace/tesseract/tesseract-ocr/training'
make: *** [training] Error 2`

What's wrong with my work, any advice?
My OS is centos 7 I change the OS to Ubuntu and it seems OK.
Thanks for the reply and please close the issues  ------------------------

### Environment

* **Tesseract Version**: Tesseract Open Source OCR Engine v4.00.00dev-692-gad5ee184 with Leptonica
* **Platform**: Linux 4.9.43-17.39.amzn1.x86_64 #1 SMP x86_64 GNU/Linux


### Current Behavior:
Command '['tesseract', '/tmp/tr_tmp.jpg', '/tmp/tr_tmp', '--tessdata-dir', '/var/task/tessdata', '--psm', '12', '--oem', '2', '-l', u'eng', 'hocr']' returned non-zero exit status -11: CalledProcessError
Traceback (most recent call last):
File "/var/task/lambda_function.py", line 22, in lambda_handler
**event
File "/var/task/lib/ocr/common/procedures.py", line 105, in recognize
scanned = scanner.scan_jpg(swabbed, file_desc['pagenum'], **kwargs)
File "/var/task/lib/ocr/common/scanner.py", line 62, in scan_jpg
'hocr',
File "/usr/lib64/python2.7/subprocess.py", line 541, in check_call
raise CalledProcessError(retcode, cmd)
CalledProcessError: Command '['tesseract', '/tmp/tr_tmp.jpg', '/tmp/tr_tmp', '--tessdata-dir', '/var/task/tessdata', '--psm', '12', '--oem', '2', '-l', u'eng', 'hocr']' returned non-zero exit status -11

### Expected Behavior:
no crash

### Suggested Fix:
   Environment
I'm currently using tess-two version 8.0.0

Current Behavior:
I've tested my app at several images. Actually some of them worked very nice. But the issues starts when i take a picture from water metering which contains of numbers. The tesseract doesn't recognize it and instead of returning it as numbers, it gave me random words. Also, when i've done with the recognition, the memory didn't release. So, here's my question:
 
1. How can i release the memory after the recognition, and 
2. How can i improve the reading when the text is coming from the water metering?

Expected Behavior:
1. The memory will be released (so i can save up to 30 MB)
2. The OCR works on Water metering (at least up to 75%)
  Hello,
thanks for creating Tesseract 4.0.
I have problems creating the box files correctly (where should the tab go?) and get error messages from LSTM training.

There is a link for an example Box File in github, but it is not working any more (https://github.com/tesseract-ocr/tesseract/wiki/Making-Box-Files---4.0 the links on this page are broken). Could you please publish a working *.box and a corresponding *.tif file for LSTM-Training?

Thanks & kind regards
Ernst @Shreeshrii  thank you very much for your files!!!! I used tesstrain.sh, but did not look into /tmp. Shame on me!
I could not get tesseract to create box files. I used

tesseract pol.ocrb.exp$i.tif pol.ocrb.exp$i batch.nochop makebox

as described, but it created a file called batch.nochop.box, but not the box file I expected (an old style box file would be OK)

Thanks,
Ernst @Shreeshrii thank you very much, that works for me also, that is great!!!
I do not know why the original calls (and I tried many) did not work. 
Kind regards
Ernst
  I want to fine tune with tesseract 4.0, and I just have  *.tif and *.box these two files,
I don't know how to generate *.lstmf files.

The wiki just says like this :
"The training data is provided via .lstmf files, which are serialized DocumentData They contain an image and the corresponding UTF8 text transcription, and can be generated from tif/box file pairs using Tesseract in a similar manner to the way .tr files were created for the old engine."

but it doesn't give the command to generate *.lstmf files.
So, I hope someone can help me, thanks very much ! @minly ,@CoCa520 , @Shreeshrii  @Shreeshrii, I have change the format box files according to the requirements of tesseract 4.0 ,  namely  I add a TAB at end of line and spaces to demarcate words for the  box files.

could you tell me how to use new format box/tiff pairs to generate *.lstmf files? Thanks!

 @Shreeshrii I changed the tesstrain.sh file and the command could copy the box/tiff pairs to the tmp training directory.
but there was another error as following:

$ training/tesstrain.sh --lang eng --linedata_only  --langdata_dir ../langdata --tessdata_dir ./tessdata --output_dir ../result

=== Starting training for language 'eng'
total 6068
-rwxrw-r-- 1 penny penny   66188 Oct 18 19:24 eng.num.exp0.box
-rwxrw-r-- 1 penny penny 6136385 Oct 18 19:24 eng.num.exp0.tif
-rw-rw-r-- 1 penny penny      42 Oct 18 19:24 tesstrain.log
[Wed Oct 18 19:24:13 CST 2017] /usr/local/bin/text2image --fonts_dir=/usr/share/fonts/ --font=Arial Bold --outputbase=/tmp/font_tmp.fGYz2L7fuF/sample_text.txt --text=/tmp/font_tmp.fGYz2L7fuF/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.fGYz2L7fuF
Could not find font named Arial Bold.
Pango suggested font FreeSerif Bold.
Please correct --font arg.

=== Phase I: Generating training images ===
ERROR: Could not find training text file ../langdata/eng/eng.training_text


it couldn't find 'eng.training_text' file, do you know what the 'eng.training_text' file is ?   

Additionally, the command 'text2image' is used to generate tiff images according to text and fonts, but we have already had box/tiff pairs, so  why it excute the command 'text2image' again ? 
Should I change other script files to resolve these problems?

I'm looking forward to your reply! Thanks a lot!









 @Shreeshrii, with your help, I generated the *.lstmf files! Thanks a lot! @Shreeshrii but now there is a new problem like this:

$ tesseract  eng.num.exp1.tif  eng.num.exp1  lstm.train
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Warning. Invalid resolution 0 dpi. Using 70 instead.
Estimating resolution as 395
Empty page!!
Estimating resolution as 395
Empty page!!

there are several images will generate this error, do you know why it appears "Empty page!!"? Have you ever seen this kind of mistake? @Shreeshrii, the tif files are OK, and every tif image has the warning, for example:

$ tesseract eng.num.exp2.tif eng.num.exp2  lstm.train
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Warning. Invalid resolution 0 dpi. Using 70 instead.
Estimating resolution as 369

Although it has the warning "Warning. Invalid resolution 0 dpi. Using 70 instead.", but after the command, the *.lstmf file could be generated correctly. So I guess the warning is not the truly problem.

And if a tif image has the "Empty page!!" error, the *.lstmf file would not be generated! So, I guess the problem is the "Empty page!!" error. But I don't know how to resolve the problem, hope  for your help , thanks!!! @Shreeshrii, I resolved the problem, I just add " -psm 7 nobatch" to the command like this:
$ tesseract eng.num.exp2.tif eng.num.exp2 -psm 7 nobatch lstm.train
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Warning. Invalid resolution 0 dpi. Using 70 instead.

then, the error "Empty page!!" was disappeared. and finally the *.lstmf file was generated correctly! @Shreeshrii, You're welcome! the command is also right without "nobatch", just as the following:

$ tesseract eng.num.exp2.tif eng.num.exp2 -psm 7 lstm.train
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Warning. Invalid resolution 0 dpi. Using 70 instead.

Dou you know the function of "nobatch" ? Have you used it in tesseract command ? 
Looking forward to your reply! Thanks! @Shreeshrii, OK, Thanks~^_^~ @Shreeshrii ,when I use Chinese character box/tiff pairs to fine tune,  there was a new problem as the following:

$ unicharset_extractor chi_sim.black.exp0.box
Extracting unicharset from box file chi_sim.black.exp0.box
Invalid Unicode codepoint: 0xffffffe4
IsValidCodepoint(ch):Error:Assert failed:in file normstrngs.cpp, line 225
Segmentation fault (core dumped)

have you ever seen this problem? 
Looking forward to your reply! Thanks!

 @Shreeshrii
i will generacte *.lstmf ,and run  **tesseract ./tif_box/eng.exp0.tif ./tif_box/eng.exp0     lstm.train**  ,then I got eng.exp0.txt eng.exp0.lstmf but   the  "eng.exp0.txt" nothing  any char 
box file and tif file is ok  

run lstmtraining, i got a error 
_Deserialize header failed: ~/tesstutorial/tif_box/eng.exp0.lstmf
Load of page 0 failed!
Load of images failed!!_
I guess my *.lstmf file is incorrect

ps: box , tif file form jTessBoxEditor, not  from text2image command

please give me a suggestion
  @Shreeshrii
--sequential_training true   
then i got 
First document cannot be empty!!
num_pages_per_doc_ > 0:Error:Assert failed:in file imagedata.cpp, line 658

  Hi,

i have installed Tesseract: 4.00.00dev-690-g1b0379c with Leptonica:  1.74.4 and its working fine with the detection and all, but i have noticed that the performance is slower than before (comparing with 5 months ago tesseract, and leptonica 1.74.1).

in the past the time was around 4 or 5 seconds but lately its almost the double, that command that im using is the normal tesseract detection command which is: **tesseract image results -l lang--tessdata-dir ./tessdata --oem 1 ** , so am i missing something or is there some sort of a parameter that i should add after the updates to the tesseract or leptonica? or any other way to enhance  the performance speed? (for both single thread case or multi thread case)

Thank you > Slower Performance in Latest Tesseract

It's not clear if you're comparing a newer 4.00 to older 4.00 or 4.00 to 3.05. Also, do you use the newest traineddata for 4.0?  >or any other way to enhance the performance speed? (for both single thread case or multi thread case)

If you use multi-threading  try disabling OpenMP.
`OMP_THREAD_LIMIT=1 tesseract in.png out --oem 1`

. @amitdo actually im comparing the latest (4.00.00dev-690-g1b0379c with Leptonica: 1.74.4 ) with the older version (4.00.00dev-549-g2b854e3 with leptonica 1.74.1)

@Shreeshrii  "tessdata_fast" is a news to me, i'm already using the official traineddata, but i dont know about this one, can you please give me the link to it?, also i already created a tuned LSTM, can i also combine it with the new tessdata_fast as well?

Thank you both The latest traineddata files are at https://github.com/tesseract-ocr/tessdata_best and https://github.com/tesseract-ocr/tessdata_fast. But if you want to compare the performance of an older Tesseract 4.00 with the latest version, you will have to use the same traineddata for both, usually from https://github.com/tesseract-ocr/tessdata. I'd disable multithreading for the test (set environment variable `OMP_THREAD_LIMIT=1`). @Shreeshrii so i assume that if i fine tuned an LSTM file (made by older version tools) it won't combine with the new traineddate?  (for example a traineddata from: https://github.com/tesseract-ocr/tessdata_best) 
also you mean by "data for your fine tuning" as the following?
![1](https://user-images.githubusercontent.com/26926171/31716984-deb8cc32-b412-11e7-8fa7-f0c27132275d.png)
and the steps in the link that you have shared are to enhance accuracy, detection speed or both?

@stweil  the difference between "tessdata_best" and "tessdata_fast" is the accuracy vs speed? meaning "tessdata_fast" will be faster in detection but wont be accurate as "tessdata_best" ?

Thanks for the answers >  the difference between "tessdata_best" and "tessdata_fast" is the accuracy vs speed? meaning "tessdata_fast" will be faster in detection but wont be accurate as "tessdata_best" ?

`tessdata_fast` is faster than `tessdata_best`, yes.
`tessdata_best` is generally better, but not always. I also noticed cases where `tessdata_fast` is better. And there are even [cases](https://github.com/cisocrgroup/Resources/tree/master/ocrtestset/german/1841-DieGrenzboten) where the old Tesseract gives the best recognition rates of all current tessdata. if i wanted to fine tune using the tool "lstmtraining" while i'm using the latest Tesseract: (4.00.00dev-690-g1b0379c) can i use .lstmf files (which are generated by tesstrain.sh)file that are created by older Tesseract version, such as (4.00.00dev-549-g2b854e3) ?
meaning are lstmf files compatible between tesseract versions? thanks  Try re-building with `./configure --disable-graphics` ... or simply hide or remove `scrollview`, so it won't be run.  Hi, I'm trying to train a new tesseract chinese dictionary using jTessBoxEditor. 
The tool creates all files necessary to train tesseract. 
I have 273 character to train. During the training I have this error for only two character of them:

** Moving generated traineddata file to tessdata folder **
** Training Completed **
** Run Tesseract for Training **
[C:\Users\allvilardi\Downloads\jTessBoxEditorFX-2.0-Beta\jTessBoxEditorFX\tesseract-ocr/tesseract, CT_calibri.calibri.exp0.tif, CT_calibri.calibri.exp0, box.train]
Tesseract Open Source OCR Engine v4.0.0-alpha.20170804 with Leptonica
Page 1
FAIL!
APPLY_BOXES: boxfile line 45/Âõõ ((1061,3024),(1124,3082)): FAILURE! Couldn't find a matching blob
FAIL!
APPLY_BOXES: boxfile line 125/Áõ§ ((1092,2680),(1164,2751)): FAILURE! Couldn't find a matching blob
APPLY_BOXES:
   Boxes read from boxfile:     273
   Boxes failed resegmentation:       2
   Found 271 good blobs.
Generated training data for 28 words


I've changed also the box manually on those two charachter, but without success. On a Box gui, the boxes seems to be fine.
Does anyone know how to fix that problem? 
ps. I have this error also on korean characters, for all the characters. 

This are the grafic boxes on those character:
  
![image](https://user-images.githubusercontent.com/18304893/31346813-a6aee654-ad1a-11e7-884a-859771e46ed1.png)

Anyone could help me? Thanks.
 I have the same problem with arabic language
** Run Tesseract for Training **
[K:\train tesseract\jTessBoxEditor\tesseract-ocr/tesseract, ara.mylotus.exp0.tif, ara.mylotus.exp0, box.train]
Tesseract Open Source OCR Engine v4.0.0-alpha.20170804 with Leptonica
Page 1
row xheight=23, but median xheight = 30.5
APPLY_BOXES: boxfile line 6/ŸÇ ((2324,3143),(2338,3173)): FAILURE! Couldn't find a matching blob
APPLY_BOXES: boxfile line 7/ÿπ ((2303,3119),(2334,3157)): FAILURE! Couldn't find a matching blob
....
..
.
.

APPLY_BOXES:
   Boxes read from boxfile:     888
   Boxes failed resegmentation:     176 Actually i'm already using v 4 as it showing in the training message log
Tesseract Open Source OCR Engine v4.0.0-alpha.20170804 with Leptonica I have the same problem. In my case I try to train digits from a display.

tesseract day_2_60_0_G3.cfont1.exp0.tif day_2_60_0_G3.cfont1.exp0 -l dianoche2 -psm 7 nobatch box.train

Tesseract Open Source OCR Engine v3.02 with Leptonica

FAIL!
APPLY_BOXES: boxfile line 90/. ((1079,11),(1081,17)): FAILURE! Couldn't find a matching blob
APPLY_BOXES: boxfile line 141/. ((1758,2),(1762,16)): FAILURE! Couldn't find a matching blob
APPLY_BOXES:
   Boxes read from boxfile:     189
   Boxes failed resegmentation:       2
   Found 187 good blobs.
   Leaving 1 unlabelled blobs in 0 words.
TRAINING ... Font name = cfont1
Generated training data for 60 words
![day_2_60_0_g3 cfont1 exp0](https://user-images.githubusercontent.com/32894808/31707084-7cf4769e-b3eb-11e7-8b36-de3d7a503a5b.png)
[day_2_60_0_G3.cfont1.exp0.txt](https://github.com/tesseract-ocr/tesseract/files/1393834/day_2_60_0_G3.cfont1.exp0.txt)

I attach the file in .txt format because I couldn't attach in .box format 

Anyone could help me? Thanks.  ### Environment
* **Tesseract Version**:
```
tesseract 3.05.01
 leptonica-1.74.4
  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8
```
* **Commit Number**: [2158661](https://github.com/tesseract-ocr/tesseract/commit/215866151e774972c9502282111b998d7a053562)
* **Platform**: `Linux Inspiron-530s 4.4.0-96-generic #119-Ubuntu SMP Tue Sep 12 14:59:54 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux`

---

### Current Behavior:
```
dan9er@A-Computer:~/Pictures$ tesseract image.jpg out -c tessedit_write_images=1
Tesseract Open Source OCR Engine v3.05.01 with Leptonica
Warning. Invalid resolution 0 dpi. Using 70 instead.
````

#### **image.jpg**:
![Pill bottle](https://imgur.com/pYjuSCn.png)

#### **tessinput.tif**:
![Black and white image of pill bottle with text "NPN 80051578" sideways](https://imgur.com/SOJFK2f.png)

#### **out.txt**:
```
22%mzzztnztzm 22:‚Äú: a $5.35

a
mhmÔ¨Åmoowuzgz

.

SEEESaEmS 2:

.32 8:325
¬ßo3WK<S

 

```

---

### Expected Behavior:

#### **tessinput.tif**:
![B&W pill bottle with NPN text right side up](https://imgur.com/Q55k7v1.png)

#### **out.txt**:
```
[junk maybe]

NPN: 80051578

[junk maybe]
```

---

### Suggested Fix:
Add a config tag (`tessedit_rotation_override`?) that overrides the auto-rotation. It could be just 1/0 (never rotate input image if 1) or 0-3 (always rotate by this multiple of 90).

EDIT: I don't know why but turns out the [original image I posted](https://imgur.com/An1Fz1T.png) recognized fine, even though it was still rotated! The majority of my images output junk though, so I replaced the image with one that doesn't work. Oh, and added console output, out.txt and input image Upload the original image.

Write the full command you are using.

What's the output you are getting, including errors messages, if any? Ok, post updated.

I admit I posted this on the Google Groups forum first. But after a week and 2 bumps, no one could give me an answer. So I assumed nobody got around to implementing a way to override this stupid auto-rotation...

EDIT: @tfmorris suggested changing the PSM, but that does nothing:
![A bunch of identical TIFF files](https://imgur.com/Jp30THT.png) >@tfmorris suggested changing the PSM, but that does nothing:

Including the output **text**? You should have osd.traineddata to make some PSMs work properly.
 @amitdo PSM 12 is the only one that works (with the new image), but that's only if I run Tesseract with a config file I made:
```
load_system_dawg        F
load_freq_dawg          F
user_words_suffix       user-words
user_patterns_suffix    user-patterns
tessedit_char_whitelist NP0123456789:#
```
Plus, PSM 12 is described as "Sparse text *with OSD*". @tfmorris said it's the OSD that's doing the rotation.
And, if OSD is disabled for some of the PSMs, then why are ALL of the TIFF files rotated?

EDIT: "Works" as in the only output that isn't junk. @Shreeshrii Well, is there any way to disable that rotation and force tesseract to recognise the unrotated image? Well if I give Tesseract a horizontal image of the bottle, tessinput.tif is not rotated. Upon closer inspection of the images that do not OCR correctly, **it looks like the binarization algorithm is the real culprit here**. Tesseract doesn't seem to care about the rotation of the text. Anyway, I don't think this is a problem with Tesseract itself so I'm closing this Issue. Some weird **** is going on here. It may be Leptonica, the `tessedit_write_images` code, or even Ubuntu that is rotating the image after Tesseract spits it out.

If I find anything I'm going to post in [this Google Groups thread](https://groups.google.com/forum/#!topic/tesseract-ocr/GAbzk9BTGDE). It is Leptonica that is causing this to happen. Submitting an issue on there rn.

Not reopening this since there is nothing the Tesseract devs can do here, this is a Leptonica issue.  I am getting compile errors when compiling my bindings with `clang++ -std=gnu++11` (MacOS 12.13). This fixes it for me. See pull request #1082 and other pull requests and issues which address the same problem.  I must confess to not being a CMake expert, but I found [this mailing list post](https://cmake.org/pipermail/cmake-developers/2016-May/028364.html) that seems to confirm my suspicion that the `FindPkgConfig` module doesn't fix up the library search path to allow linking against the libraries it has found.

N.B.: I also needed https://github.com/DanBloomberg/leptonica/pull/282 to get this compiling on macOS. In general, unless you compile on Windows with MSVC, you should use autotools to build Leptonica and Tesseract.

CC: @egorpugin   I have refered solutions like below:

    https://stackoverflow.com/questions/30932120/tesseract-assert-failed-trainingsampleset-cpp-line-622-with-mftraining
    https://stackoverflow.com/questions/18921810/assert-failed-training-tesseract
    https://groups.google.com/forum/#!topic/tesseract-ocr/3e4dV373u_o

But they do not work at all!

I checked font_properties yet.

Here is the [case](https://github.com/nagexiucai/milk-powder/commit/cd0aed443af6aa084da721d48bd107e92934544d) of mine:

    https://github.com/nagexiucai/milk-powder/commit/cd0aed443af6aa084da721d48bd107e92934544d

### Environment

* **Tesseract Version**:  OCR Engine v3.02 with Leptonica
* **Commit Number**: unnkown
* **Platform**: Win7x86-64

### Current Behavior:
    Reading .\pictures\chi_sim.CHei_PRC.exp0.tr ...
    Font id = -1/0, class id = 2/132 on sample 0
    font_id >= 0 && font_id < font_id_map_.SparseSize():Error:Assert failed:in file ..\..\classify\trainingsampleset.cpp, line 622

### Expected Behavior: pass

### Suggested Fix:
none Here is the [details](https://github.com/nagexiucai/milk-powder/blob/master/README.md)!

https://github.com/nagexiucai/milk-powder/blob/master/README.md  ### Environment

* **Tesseract Version**: 
tesseract 4.00.00alpha
 leptonica-1.74.4
  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8

 Found AVX2
 Found AVX
 Found SSE
* **Platform**: ubuntu 16.04

### Current Behavior:

I'm trying to fine tune chi_sim.traineddata with a new font , the command is as follow:

```
./training/tesstrain.sh --fonts_dir /usr/share/fonts \
--lang chi_sim \
--linedata_only \
--noextract_font_properties \
--langdata_dir /home/yuanhao/workspace/langdata/langdata-master \
--tessdata_dir /home/yuanhao/workspace/tessdata \
--fontlist "STXihei" \
--output_dir /home/yuanhao/workspace/tesstutorial/chi_sim_eval &> ~yuanhao/logs/tesstrain.log
```
the log file:
[tesstrain.log](https://github.com/tesseract-ocr/tesseract/files/1328173/tesstrain.log)

and then run
```
lstmtraining --model_output ~yuanhao/workspace/tesstutorial/stxihei_from_full/stxihei \
--continue_from ~yuanhao/workspace/tesstutorial/stxihei_from_full/chi_sim.lstm  \
--traineddata ~yuanhao/workspace/tesstutorial/chi_sim.traineddata  \
--train_listfile ~yuanhao/workspace/tesstutorial/chi_sim_eval/chi_sim.training_files.txt   \
--eval_listfile ~yuanhao/workspace/tesstutorial/chi_sim_eval/chi_sim.training_files.txt	\
--target_error_rate 0.01	&> ~yuanhao/logs/lstmtraining.log
```
the training lasts for sereval days .  but the error rate doesn't improve any more. the console output says  ‚ÄúDivergence! Reverted to iteration 96/100/100 ‚Äù again and again.   

lstmtraining.log: 
[lstmtraining111.log](https://github.com/tesseract-ocr/tesseract/files/1328193/lstmtraining111.log)

Is it normal, or is there something wrong?

 @Shreeshrii  thanks for you reply
1.commit id is :  9c2fa0d
2.I've  tried  --max_iteration 3000 before,  the result is not good, so I use --target_error_rate 0.01 instead
3.I use the default training text: https://github.com/tesseract-ocr/langdata/blob/master/chi_sim/chi_sim.training_text    and only one font is needed
4.I'm trying to make tesseract recognize a particular type of Chinese font "STXihei" better. It seems that it's a typical scenario for using fine tune(new-font-style). Should I try to replace a layer?  ### Environment

* **Tesseract Version**: <4.00.00alpha>
* **Platform**: <ubuntu 14, 64bits>

### Current Behavior:
in command line , I input "tesseract ", we can see the "OCR options", but it doesnt contain "-oem NUM" option as operated in Windows system, why? someone told me the Xeon CPU doesnt support AVX, is that the correct reason?  
### Expected Behavior:

### Suggested Fix:
 you used linux/ubuntu?
here is my info:
ml@ml-Precision-Tower-5810:/data/gs/ocr$ tesseract -v
tesseract 4.00.00alpha
 leptonica-1.72
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

ml@ml-Precision-Tower-5810:/data/gs/ocr$ tesseract 
Usage:
  tesseract --help | --help-psm | --version
  tesseract --list-langs [--tessdata-dir PATH]
  tesseract --print-parameters [options...] [configfile...]
  tesseract imagename|stdin outputbase|stdout [options...] [configfile...]

OCR options:
  --tessdata-dir PATH   Specify the location of tessdata path.
  --user-words PATH     Specify the location of user words file.
  --user-patterns PATH  Specify the location of user patterns file.
  -l LANG[+LANG]        Specify language(s) used for OCR.
  -c VAR=VALUE          Set value for config variables.
                        Multiple -c arguments are allowed.
  -psm NUM              Specify page segmentation mode.
NOTE: These options must occur before any configfile.

Page segmentation modes:
  0    Orientation and script detection (OSD) only.
  1    Automatic page segmentation with OSD.
  2    Automatic page segmentation, but no OSD, or OCR.
  3    Fully automatic page segmentation, but no OSD. (Default)
  4    Assume a single column of text of variable sizes.
  5    Assume a single uniform block of vertically aligned text.
  6    Assume a single uniform block of text.
  7    Treat the image as a single text line.
  8    Treat the image as a single word.
  9    Treat the image as a single word in a circle.
 10    Treat the image as a single character.
 11    Sparse text. Find as much text as possible in no particular order.
 12    Sparse text with OSD.
 13    Raw line. Treat the image as a single text line,
bypassing hacks that are Tesseract-specific.

Single options:
  -h, --help            Show this help message.
  --help-psm            Show page segmentation modes.
  -v, --version         Show version information.
  --list-langs          List available languages for tesseract engine.
  --print-parameters    Print tesseract parameters to stdout.
Linux ml-Precision-Tower-5810 4.4.0-31-generic #50~14.04.1-Ubuntu SMP Wed Jul 13 01:07:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
ml@ml-Precision-Tower-5810:/data/gs/ocr$ 



nciaegs@163.com
 
From: Shreeshrii
Date: 2017-09-25 11:27
To: tesseract-ocr/tesseract
CC: GuoShuai; Author
Subject: Re: [tesseract-ocr/tesseract] tesseract 4.00.00alpha couldnt set OEM (#1155)
Are you using an old version of tesseract?
The correct parameter is --oem NUM
I get the following info:
tesseract -v
tesseract 4.00.00alpha
 leptonica-1.74.4
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8
 Found AVX
 Found SSE
 tesseract
Usage:
  tesseract --help | --help-psm | --help-oem | --version
  tesseract --list-langs [--tessdata-dir PATH]
  tesseract --print-parameters [options...] [configfile...]
  tesseract imagename|stdin outputbase|stdout [options...] [configfile...]
OCR options:
  --tessdata-dir PATH   Specify the location of tessdata path.
  --user-words PATH     Specify the location of user words file.
  --user-patterns PATH  Specify the location of user patterns file.
  -l LANG[+LANG]        Specify language(s) used for OCR.
  -c VAR=VALUE          Set value for config variables.
                        Multiple -c arguments are allowed.
  --psm NUM             Specify page segmentation mode.
  --oem NUM             Specify OCR Engine mode.
NOTE: These options must occur before any configfile.
Page segmentation modes:
  0    Orientation and script detection (OSD) only.
  1    Automatic page segmentation with OSD.
  2    Automatic page segmentation, but no OSD, or OCR.
  3    Fully automatic page segmentation, but no OSD. (Default)
  4    Assume a single column of text of variable sizes.
  5    Assume a single uniform block of vertically aligned text.
  6    Assume a single uniform block of text.
  7    Treat the image as a single text line.
  8    Treat the image as a single word.
  9    Treat the image as a single word in a circle.
 10    Treat the image as a single character.
 11    Sparse text. Find as much text as possible in no particular order.
 12    Sparse text with OSD.
 13    Raw line. Treat the image as a single text line,
                        bypassing hacks that are Tesseract-specific.
OCR Engine modes:
  0    Original Tesseract only.
  1    Neural nets LSTM only.
  2    Tesseract + LSTM.
  3    Default, based on what is available.
Single options:
  -h, --help            Show this help message.
  --help-psm            Show page segmentation modes.
  --help-oem            Show OCR Engine modes.
  -v, --version         Show version information.
  --list-langs          List available languages for tesseract engine.
  --print-parameters    Print tesseract parameters.

‚Äî
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub, or mute the thread.
 I'll try it now, thank you friends!  
### Environment

* **Tesseract Version**: <!-- compulsory. you must provide your version -->
tesseract 4.00.00alpha
 leptonica-1.74.4
  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8

* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
2a77d5ad691b53c0fff7400fc4fd66102a24bc27 - found after bisecting from current master
* **Platform**: <!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->
Linux mc01 4.4.0-89-generic #112-Ubuntu SMP Mon Jul 31 19:38:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

### Current Behavior:
Segfault when running:
```
$tesseract bad.png - -l ces -psm 7
Warning. Invalid resolution 0 dpi. Using 70 instead.
contains_unichar_id(unichar_id):Error:Assert failed:in file ../ccutil/unicharset.h, line 513
Segmentation fault (core dumped)
```

Ces data were downloaded from https://github.com/tesseract-ocr/tessdata/raw/4.00/ces.traineddata .

![bad](https://user-images.githubusercontent.com/1188728/30782283-56613888-a12f-11e7-8bd4-24118e21a763.png)

### Expected Behavior:

```
$ tesseract bad.png - -l ces -psm 7
Warning. Invalid resolution 0 dpi. Using 70 instead.
nguzge gbopf/IUMNIC CZ spol. s r.o.
```

### Suggested Fix:

 What about other PSMs? 

>Ces data were downloaded from https://github.com/tesseract-ocr/tessdata/raw/4.00/ces.traineddata

There are newer traineddata files available.
https://github.com/tesseract-ocr/tesseract/wiki/Data-Files#updated-data-files-for-version-400-september-15-2017 I cannot test it right now but I think that it worked ok when psm was not specified. I'll try to use the new data too, thanks. I've checked and new traineddata solved this issue.
As for what psm modes, the segfault appeared for modes 7, 8, 11 and 12 (also for 14- but those are probably not valid anyway).
I'm not sure wheter to close this issue right away, but my problem is now solved. Thank You. I've uploaded one that didn't work in the original post. One that works can be seen here:
![1](https://user-images.githubusercontent.com/1188728/31050762-53a1d99c-a655-11e7-93b3-75de57a4bf07.png) . Otherwise it worked fine across a few thousand images, with only a single exception where it failed with the segfault mentioned above.

Oem was not set (as can be seen it examples above), so the default value.
 I suggest to close this issue since it was solved with an updated traineddata.  @zdenop 

You might want to try this:
https://github.com/blog/2141-squash-your-commits
https://help.github.com/articles/about-pull-request-merges/

Note that it will give you the option to change the commit message.

My suggestion:

Title:
>Fix encoding issue in unicharset_extractor.cpp (#1153) 

Body:
>Fix #1147 @theraysmith, @zdenop, is this bug fix which is needed for everybody who wants to do training ready to get merged (preferably with squashing the seven commits), or would you prefer a more direct solution (like [this commit](https://github.com/stweil/tesseract/commit/94ea31d4bad6174a8a2999a940bfe76b9ce31f26))? @ivanzz1001, After I changed unicharset_extractor.cpp file, should I build the unicharset_extractor.cpp file to generate a new unicharset_extractor.o file ?

g++ unicharset_extractor.cpp -o unicharset_extractor

use the command ok ?  ### Environment

* **Tesseract Version**: tesseract 4.00.00alpha
* **Platform**: Linux 4.12.13-1-ARCH #1 SMP PREEMPT Fri Sep 15 06:36:43 UTC 2017 x86_64 GNU/Linux

### Current Behavior:
Text embedded using `PdfRenderer` are encoded using `UTF_16BE` but do not contain BOM bytes. Only text string that is encoded correctly is in `/Title` metadata.

### Expected Behavior:
According to [PDF reference](http://www.adobe.com/content/dam/Adobe/en/devnet/acrobat/pdfs/pdf_reference_1-7.pdf) all `text string` objects should be encoded in `PdfDocEncoding` or `UTF_16BE` with a leading `byte-order marker` (FEFF).
### Suggested Fix:
 CC: @jbreiden  See chapter 3.8.1 in the PDF reference. Hi @jbreiden I came across this while trying to extract text from PDFs in a generic way. I am not aware of any incompatibilities with PDF renderer but without BOM it is incompatible with multiple PDF parsers (e.g. `pdfminer`, `pdfrw`). From PDF reference chapter 3.8.1:

> For text strings encoded in Unicode, the first two bytes must be 254 followed by 255. These two bytes represent the Unicode byte order marker, U+FEFF, indicating
that the string is encoded in the UTF-16BE (big-endian) encoding scheme
specified in the Unicode standard.  Evince has no problem with the BOM.

pdf.js - same effect as pdfium. If both Adobe Reader and PDFium can't render the "with BOM" version correctly, I see no point in keeping this issue open.  Maybe 'max_pages' should be a parameter to the shell script, so end users can change it easily.    Environment

* **Tesseract Version**: tesseract 4.00.00alpha
 leptonica-1.74.4 libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8
 Found AVX2
 Found AVX
 Found SSE
* **Commit Number**: 2178
* **Platform**: Linux Bash Shell on Windows 10

### I try to do tesstrain.sh by using this code.
```
training/tesstrain.sh --fonts_dir /mnt/c/Windows/Fonts --lang tha --training_text /mnt/e/tesseract-ocr/langdata/tha/tha.training_text --linedata_only \
¬† --noextract_font_properties --langdata_dir /mnt/e/tesseract-ocr/langdata \
¬† --tessdata_dir /mnt/e/tesseract-ocr/tessdata \
¬† --fontlist "Tahoma" --output_dir /mnt/e/OCR/
```
### But I got this error

```
=== Starting training for language 'tha'
[Thu Sep 21 18:23:13 DST 2017] /usr/bin/text2image --fonts_dir=/mnt/c/Windows/Fonts --font=Tahoma --outputbase=/tmp/font_tmp.bUhGLbvCi0/sample_text.txt --text=/tmp/font_tmp.bUhGLbvCi0/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.bUhGLbvCi0
Rendered page 0 to file /tmp/font_tmp.bUhGLbvCi0/sample_text.txt.tif
Rtl = 0 ,vertical=0

=== Phase I: Generating training images ===
Rendering using Tahoma
[Thu Sep 21 18:23:16 DST 2017] /usr/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.bUhGLbvCi0 --fonts_dir=/mnt/c/Windows/Fonts --strip_unrenderable_words --leading=48 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.vdOu9qzJMf/tha/tha.Tahoma.exp0 --max_pages=3 --font=Tahoma --text=/mnt/e/tesseract-ocr/langdata/tha/tha.training_text
ERROR: Non-existent flag --max_pages=3
ERROR: /tmp/tmp.vdOu9qzJMf/tha/tha.Tahoma.exp0.box does not exist or is not readable
ERROR: /tmp/tmp.vdOu9qzJMf/tha/tha.Tahoma.exp0.box does not exist or is not readable
```
Please suggest me to fix this error. I try to fix this too many hours.
 >ERROR: Non-existent flag --max_pages=3

It seems that you are using a non recent commit, that came before https://github.com/tesseract-ocr/tesseract/commit/2633fef0b6ac @ivanzz1001 @amitdo /mnt/c is use for access to the Windows directory. but I try to move "Fonts" Folder to the /usr/share/fonts/ and change code to `--fonts_dir /usr/share/fonts/` but it appear the same error 

```
=== Starting training for language 'tha'
[Fri Sep 22 03:04:10 DST 2017] /usr/bin/text2image --fonts_dir=/usr/share/fonts/ --font=Tahoma --outputbase=/tmp/font_tmp.r6wpt8kkkw/sample_text.txt --text=/tmp/font_tmp.r6wpt8kkkw/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.r6wpt8kkkw
FcInitiReinitialize failed!!
Could not find font named Tahoma. Pango suggested font
Please correct --font arg.:Error:Assert failed:in file text2image.cpp, line 437

=== Phase I: Generating training images ===
Rendering using Tahoma
[Fri Sep 22 03:04:12 DST 2017] /usr/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.r6wpt8kkkw --fonts_dir=/mnt/Fonts --strip_unrenderable_words --leading=48 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.4iPf952XEc/tha/tha.Tahoma.exp0 --max_pages=3 --font=Tahoma --text=/mnt/e/tesseract-ocr/langdata/tha/tha.training_text
ERROR: Non-existent flag --max_pages=3
ERROR: /tmp/tmp.4iPf952XEc/tha/tha.Tahoma.exp0.box does not exist or is not readable
ERROR: /tmp/tmp.4iPf952XEc/tha/tha.Tahoma.exp0.box does not exist or is not readable
```
**And I try change the code in `tesstrain_utils.sh `** 
Line 215    -  `common_args+=" --outputbase=${outbase} --max_pages=3"` to
Line 215   +   `common_args+=" --outputbase=${outbase} "`

But It stuck at Phase Up for many hours 

```
=== Phase I: Generating training images ===
Rendering using Tahoma
[Fri Sep 22 03:20:05 DST 2017] /usr/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.w5EOd46HIj --fonts_dir=/usr/share/fonts/ --strip_unrenderable_words --leading=48 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.QjgaXWkS0p/tha/tha.Tahoma.exp0 --font=Tahoma --text=/mnt/e/tesseract-ocr/langdata/tha/tha.training_text
Rendered page 0 to file /tmp/tmp.QjgaXWkS0p/tha/tha.Tahoma.exp0.tif
Rtl = 0 ,vertical=0

=== Phase UP: Generating unicharset and unichar properties files ===
[Fri Sep 22 03:20:06 DST 2017] /usr/bin/unicharset_extractor --output_unicharset /tmp/tmp.QjgaXWkS0p/tha/tha.unicharset --norm_mode 2 /tmp/tmp.QjgaXWkS0p/tha/tha.Tahoma.exp0.box
```

 @Shreeshrii  I just test with `eng `and `"Arial"` Font by using 

```
training/tesstrain.sh  \
  --fonts_dir /usr/share/fonts/ \
  --lang eng  \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --langdata_dir /mnt/e/tesseract-ocr/langdata \
  --tessdata_dir /mnt/e/tesseract-ocr/tessdata   \
  --output_dir /usr/share/ \
  --fontlist "Arial"
```


And `tha` with `"Arial" ` but it got a same error 

```
ERROR: Non-existent flag --max_pages=3
ERROR: /tmp/tmp.A41qaylCwa/tha/tha.Arial.exp0.box does not exist or is not readable
ERROR: /tmp/tmp.A41qaylCwa/tha/tha.Arial.exp0.box does not exist or is not readable

```

@ivanzz1001 
**`yum install fontconfig mkfontscale`** >> result is nothing, terminal get stuck must to re-open it. 

**`fc-list`**
```
/usr/share/fonts/truetype/Fonts/constan.ttf: Constantia:style=Regular
/usr/share/fonts/truetype/Fonts/browalia.ttc: BrowalliaUPC:style=Bold Italic,Negreta cursiva,tuƒçn√© kurz√≠va,fed kursiv,Fe
tt Kursiv,ŒàŒΩœÑŒøŒΩŒ± Œ†ŒªŒ¨Œ≥ŒπŒ±,Negrita Cursiva,Lihavoitu Kursivoi,Gras Italique,F√©lk√∂v√©r d≈ëlt,Grassetto Corsivo,Vet Cursief,Hal
vfet Kursiv,Pogrubiona kursywa,Negrito It√°lico,–ü–æ–ª—É–∂–∏—Ä–Ω—ã–π –ö—É—Ä—Å–∏–≤,Tuƒçn√° kurz√≠va,Fet Kursiv,Kalƒ±n ƒ∞talik,Krepko po≈°evno,Lo
di etzana
/usr/share/fonts/truetype/Fonts/trebuc.ttf: Trebuchet MS:style=Regular,Normal,obyƒçejn√©,Standard,ŒöŒ±ŒΩŒøŒΩŒπŒ∫Œ¨,Normaali,Norm√°l
,Normale,Standaard,Normalny,–û–±—ã—á–Ω—ã–π,Norm√°lne,Navadno,Arrunta
/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf: DejaVu Serif:style=Book
/usr/share/fonts/truetype/Fonts/calibril.ttf: Calibri,Calibri Light:style=Light,Regular
/usr/share/fonts/truetype/Fonts/phagspa.ttf: Microsoft PhagsPa:style=Regular,Normal,obyƒçejn√©,Standard,ŒöŒ±ŒΩŒøŒΩŒπŒ∫Œ¨,Normaali,
Norm√°l,Normale,Standaard,Normalny,–û–±—ã—á–Ω—ã–π,Norm√°lne,Navadno,Arrunta
/usr/share/fonts/truetype/Fonts/segmdl2.ttf: Segoe MDL2 Assets:style=Regular,Normal,obyƒçejn√©,Standard,ŒöŒ±ŒΩŒøŒΩŒπŒ∫Œ¨,Normaali,
Norm√°l,Normale,Standaard,Normalny,–û–±—ã—á–Ω—ã–π,Norm√°lne,Navadno,th∆∞∆°ÃÄng,Arrunta
/usr/share/fonts/truetype/Fonts/upcii.ttf: IrisUPC:style=Italic,Cursiva,kurz√≠va,kursiv,Œ†ŒªŒ¨Œ≥ŒπŒ±,Kursivoitu,Italique,D≈ëlt,C
orsivo,Cursief,Kursywa,It√°lico,–ö—É—Ä—Å–∏–≤,ƒ∞talik,Po≈°evno,Etzana
/usr/share/fonts/truetype/Fonts/msyhbd.ttc: Microsoft YaHei UI:style=Bold,Negreta,tuƒçn√©,fed,Fett,ŒàŒΩœÑŒøŒΩŒ±,Negrita,Lihavoit
u,Gras,F√©lk√∂v√©r,Grassetto,Vet,Halvfet,Pogrubiony,Negrito,–ü–æ–ª—É–∂–∏—Ä–Ω—ã–π,Fet,Kalƒ±n,Krepko,Lodia
/usr/share/fonts/truetype/Fonts/angsana.ttc: AngsanaUPC:style=Bold,Negreta,tuƒçn√©,fed,Fett,ŒàŒΩœÑŒøŒΩŒ±,Negrita,Lihavoitu,Gras,
F√©lk√∂v√©r,Grassetto,Vet,Halvfet,Pogrubiony,Negrito,–ü–æ–ª—É–∂–∏—Ä–Ω—ã–π,Fet,Kalƒ±n,Krepko,Lodia
/usr/share/fonts/truetype/Fonts/lucon.ttf: Lucida Console:style=Regular,Normal,obyƒçejn√©,Standard,ŒöŒ±ŒΩŒøŒΩŒπŒ∫Œ¨,Normaali,Norm√°
l,Normale,Standaard,Normalny,–û–±—ã—á–Ω—ã–π,Navadno,Arrunta
/usr/share/fonts/truetype/Fonts/msjh.ttc: Microsoft JhengHei UI:style=Normal,Regular,obyƒçejn√©,Standard,ŒöŒ±ŒΩŒøŒΩŒπŒ∫Œ¨,Normaali
,Norm√°l,Normale,Standaard,Normalny,–û–±—ã—á–Ω—ã–π,Norm√°lne,Navadno,Arrunta
/usr/share/fonts/truetype/Fonts/cour.ttf: Courier New:style=Regular,Normal,obyƒçejn√©,Standard,ŒöŒ±ŒΩŒøŒΩŒπŒ∫Œ¨,Normaali,Norm√°l,No
rmale,Standaard,Normalny,–û–±—ã—á–Ω—ã–π,Norm√°lne,Navadno,th∆∞∆°ÃÄng,Arrunta
/usr/share/fonts/truetype/Fonts/SitkaZ.ttc: Sitka Display,Sitka:style=Bold Italic,Display Bold Italic
/usr/share/fonts/truetype/Fonts/calibriz.ttf: Calibri:style=Bold Italic
/usr/share/fonts/truetype/Fonts/consolaz.ttf: Consolas:style=Bold Italic
/usr/share/fonts/truetype/Fonts/seguisb.ttf: Segoe UI,Segoe UI Semibold:style=Semibold,Regular
```
**`text2image --fonts_dir /usr/share/fonts --list_available_fonts`**
```
 0: 8514fix
  1: 8514oem
  2: Angsana New
  3: Angsana New Bold
  4: Angsana New Bold Italic
  5: Angsana New Italic
  6: AngsanaUPC
  7: AngsanaUPC Bold
  8: AngsanaUPC Bold Italic
  9: AngsanaUPC Italic
 10: Arial
 11: Arial Bold
 12: Arial Bold Italic
 13: Arial Heavy
 14: Arial Italic
 15: Browallia New
 16: Browallia New Bold
 17: Browallia New Bold Italic
 18: Browallia New Italic
 19: BrowalliaUPC
 20: BrowalliaUPC Bold
 21: BrowalliaUPC Bold Italic
 22: BrowalliaUPC Italic
 23: Calibri
 24: Calibri Bold
 25: Calibri Bold Italic
 26: Calibri Italic
 27: Calibri Light
 28: Calibri Light Italic
 29: Cambria
 30: Cambria Bold
 31: Cambria Bold Italic
 32: Cambria Italic
 33: Cambria Math
 34: Candara
 35: Candara Bold
 36: Candara Bold Italic
 37: Candara Italic
 38: Comic Sans MS
 39: Comic Sans MS Bold
 40: Comic Sans MS Bold Italic
 41: Comic Sans MS Italic
 42: Consolas
 43: Consolas Bold
 44: Consolas Bold Italic
 45: Consolas Italic
 46: Constantia
 47: Constantia Bold
 48: Constantia Bold Italic
 49: Constantia Italic
 50: Corbel
 51: Corbel Bold
 52: Corbel Bold Italic
 53: Corbel Italic
 54: Cordia New
 55: Cordia New Bold
 56: Cordia New Bold Italic
 57: Cordia New Italic
 58: CordiaUPC
 59: CordiaUPC Bold
 60: CordiaUPC Bold Italic
 61: CordiaUPC Italic
 62: Courier
 63: Courier New
 64: Courier New Bold
 65: Courier New Bold Italic
 66: Courier New Italic
 67: DejaVu Sans
 68: DejaVu Sans Bold
 69: DejaVu Sans Mono
 70: DejaVu Sans Mono Bold
 71: DejaVu Serif
 72: DejaVu Serif Bold
 73: DilleniaUPC
 74: DilleniaUPC Bold
 75: DilleniaUPC Bold Italic
 76: DilleniaUPC Italic
 77: Ebrima
 78: Ebrima Bold
 79: EucrosiaUPC
 80: EucrosiaUPC Bold
 81: EucrosiaUPC Bold Italic
 82: EucrosiaUPC Italic
 83: Fixedsys
 84: Franklin Gothic Medium,
 85: Franklin Gothic Medium, Italic
 86: FreesiaUPC
 87: FreesiaUPC Bold
 88: FreesiaUPC Bold Italic
 89: FreesiaUPC Italic
 90: Gabriola
 91: Gadugi
 92: Gadugi Bold
 93: Georgia
 94: Georgia Bold
 95: Georgia Bold Italic
 96: Georgia Italic
 97: HoloLens MDL2 Assets
 98: Impact Condensed
 99: IrisUPC
100: IrisUPC Bold
101: IrisUPC Bold Italic
102: IrisUPC Italic
103: JasmineUPC
104: JasmineUPC Bold
105: JasmineUPC Bold Italic
106: JasmineUPC Italic
107: Javanese Text
108: KodchiangUPC
109: KodchiangUPC Bold
110: KodchiangUPC Bold Italic
111: KodchiangUPC Italic
112: Leelawadee
113: Leelawadee Bold
114: Leelawadee UI
115: Leelawadee UI Bold
116: Leelawadee UI Semi-Light
117: LilyUPC
118: LilyUPC Bold
119: LilyUPC Bold Italic
120: LilyUPC Italic
121: Lucida Console Semi-Condensed
122: Lucida Sans Unicode
123: MS Gothic
124: MS PGothic
125: MS Sans Serif
126: MS Serif
127: MS UI Gothic
128: MV Boli
129: Malgun Gothic
130: Malgun Gothic Bold
131: Malgun Gothic Light
132: Marlett Medium
133: Microsoft Himalaya
134: Microsoft JhengHei
135: Microsoft JhengHei Bold
136: Microsoft JhengHei Light
137: Microsoft JhengHei UI
138: Microsoft JhengHei UI Bold
139: Microsoft JhengHei UI Light
140: Microsoft New Tai Lue
141: Microsoft New Tai Lue Bold
142: Microsoft PhagsPa
143: Microsoft PhagsPa Bold
144: Microsoft Sans Serif
145: Microsoft Tai Le
146: Microsoft Tai Le Bold
147: Microsoft YaHei
148: Microsoft YaHei Bold
149: Microsoft YaHei Light
150: Microsoft YaHei UI
151: Microsoft YaHei UI Bold
152: Microsoft YaHei UI Light
153: Microsoft Yi Baiti
154: MingLiU-ExtB
155: MingLiU_HKSCS-ExtB
156: Mongolian Baiti
157: Myanmar Text
158: Myanmar Text Bold
159: NSimSun
160: Nirmala UI
161: Nirmala UI Bold
162: Nirmala UI Semi-Light
163: PMingLiU-ExtB
164: Palatino Linotype
165: Palatino Linotype Bold
166: Palatino Linotype Bold Italic
167: Palatino Linotype Italic
168: Segoe MDL2 Assets
169: Segoe Print
170: Segoe Print Bold
171: Segoe Script
172: Segoe Script Bold
173: Segoe UI
174: Segoe UI Bold
175: Segoe UI Bold Italic
176: Segoe UI Emoji
177: Segoe UI Heavy
178: Segoe UI Heavy Italic
179: Segoe UI Historic
180: Segoe UI Italic
181: Segoe UI Light
182: Segoe UI Light Italic
183: Segoe UI Semi-Bold
184: Segoe UI Semi-Bold Italic
185: Segoe UI Semi-Light
186: Segoe UI Semi-Light Italic
187: Segoe UI Symbol
188: SimSun
189: SimSun-ExtB
190: Sitka Banner
191: Sitka Banner Bold
192: Sitka Banner Bold Italic
193: Sitka Banner Italic
194: Sitka Display
195: Sitka Display Bold
196: Sitka Display Bold Italic
197: Sitka Display Italic
198: Sitka Heading
199: Sitka Heading Bold
200: Sitka Heading Bold Italic
201: Sitka Heading Italic
202: Sitka Small
203: Sitka Small Bold
204: Sitka Small Bold Italic
205: Sitka Small Italic
206: Sitka Subheading
207: Sitka Subheading Bold
208: Sitka Subheading Bold Italic
209: Sitka Subheading Italic
210: Sitka Text
211: Sitka Text Bold
212: Sitka Text Bold Italic
213: Sitka Text Italic
214: Small Fonts
215: Sylfaen
216: Symbol
217: System
218: Tahoma
219: Tahoma Bold
220: Terminal
221: Terminal Greek 737 (437G)
222: Terminal Greek 869,
223: Times New Roman,
224: Times New Roman, Bold
225: Times New Roman, Bold Italic
226: Times New Roman, Italic
227: Trebuchet MS
228: Trebuchet MS Bold
229: Trebuchet MS Bold Italic
230: Trebuchet MS Italic
231: Verdana
232: Verdana Bold
233: Verdana Bold Italic
234: Verdana Italic
235: Webdings
236: Wingdings
237: Yu Gothic
238: Yu Gothic Bold
239: Yu Gothic Light
240: Yu Gothic Medium
241: Yu Gothic UI
242: Yu Gothic UI Bold
243: Yu Gothic UI Light
244: Yu Gothic UI Semi-Bold
245: Yu Gothic UI Semi-Light
``` @Shreeshrii  
**`make training`** got this error
```
make: Warning: File 'Makefile.in' has modification time 21613 s in the future
/bin/bash ./config.status --recheck
running CONFIG_SHELL=/bin/bash /bin/bash ./configure --no-create --no-recursion
checking for g++... g++
checking whether the C++ compiler works... yes
checking for C++ compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
Using git revision: 4.00.00dev-687-g2cc531e
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... configure: error: newly created file is older than distributed files!
Check your system clock
Makefile:430: recipe for target 'config.status' failed
make: *** [config.status] Error 1
```
and the **`make training-install`** I got this 
```
make: Warning: File 'Makefile.in' has modification time 21585 s in the future
/bin/bash ./config.status --recheck
running CONFIG_SHELL=/bin/bash /bin/bash ./configure --no-create --no-recursion
checking for g++... g++
checking whether the C++ compiler works... yes
checking for C++ compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
Using git revision: 4.00.00dev-687-g2cc531e
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... configure: error: newly created file is older than distributed files!
Check your system clock
Makefile:430: recipe for target 'config.status' failed
make: *** [config.status] Error 1
```

 I try to re-install tesseract.  but now I got error with the same [ISSUE#1114](https://github.com/tesseract-ocr/tesseract/issues/1114) I try change` LINE 220 `in  `normstrngs.cpp`  but it doesn't fix.

```
Invalid Unicode codepoint: 0xffffffc2
IsValidCodepoint(ch):Error:Assert failed:in file normstrngs.cpp, line 225
ERROR: /tmp/tmp.9TCN0u9M2a/eng/eng.unicharset does not exist or is not readable
```
 So your original issue was solved.

Don't mix two different issues in one report. Please close this issue. Okay, Let me summary this issue for anyone that get error the same with me. 
If you got this error about `Non-existent flag` 
**Re-install tesseract**  and don't forget to
```
sudo ldconfig
make training
sudo make training-install
```
then if you get  error about `Invalid Unicode codepoint: ` try to change code in `normstrng.cpp`
**See this issue.**
 [Issue1114]( https://github.com/tesseract-ocr/tesseract/issues/1114) 
then run this again 
```
make run
make training
sudo make training-install

```
And the last, I got error about `TESSDATA_PREFIX `
**I fix by read this Issue** 
[Issue221](https://github.com/tesseract-ocr/tesseract/issues/221)

Thank you everyone to help me fix this. I am very appreciate it.
  >First It use function NormalizeCleanAndSegmentUTF8() **to convert the string to UTF-8 encoding**

The first thing it does is calling NormalizeUTF8ToUTF32().
 Maybe you have two tesseracts in your system. one of them is older version than the other. Strangely, tesseract parses 'radical-stroke.txt' for every language.
https://github.com/tesseract-ocr/tesseract/blob/a2a72d7ca78a3bb3798a02a2ba5188e255c2a0f7/ccutil/unicharcompress.cpp#L98 >I checked that I have only one version.

How?

Try this:
`sudo find / -type f -name "libtesseract.so*"`

I wonder why you put the git repo on `/root`. https://help.github.com/articles/dealing-with-line-endings/ https://github.com/tesseract-ocr/tesseract/wiki/VGSLSpecs

>Is It OK that I ask the question here? or anywhere else is proper?

The right place to ask this kind of question is [our forum](https://groups.google.com/d/forum/tesseract-ocr).  Hello everyone,

When I train models by LSTM 4.0  [https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#fine-tuning-for-%C2%B1-a-few-characters]

It showed this problem, how to solve it? Why happened? What should the pic size be? 

```
Image too large to learn!! Size = 2608x48
Image not trainable
Image too large to learn!! Size = 2845x48
Image not trainable
At iteration 18938/35100/36699, Mean rms=0.379%, delta=0.441%, char train=1.315%, word train=2.366%, skip ratio=3.2%,  New worst char error = 1.315 wrote checkpoint.

Image too large to learn!! Size = 2704x48
Image not trainable
Image too large to learn!! Size = 2666x48
Image not trainable
Image too large to learn!! Size = 2634x48
Image not trainable
Image too large to learn!! Size = 2593x48
Image not trainable
Image too large to learn!! Size = 2593x48
Image not trainable
At iteration 18971/35200/36804, Mean rms=0.376%, delta=0.435%, char train=1.279%, word train=2.311%, skip ratio=3.4%,  New worst char error = 1.279 wrote checkpoint.
```
The pics is created by the shell "training/tesstrain.sh ", How to decide the size of the pic by this way???

```
training/tesstrain.sh  \
   --fonts_dir /usr/share/fonts \
  --lang chi_sim  \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --langdata_dir ../langdata \
  --tessdata_dir /home/hs/tessdata/tessdata  \
  --output_dir ../tesstutorial/chi_sim
``` Thank you @Shreeshrii  @yoyoshuang  where can i  find training material  for Chinese  I have downloaded that latest 4.0 release, new leptonica and tried to buid it under MSVC 2017, unicode project. After several hours of I almost succeded in building the project but one problem is still remaining unresolved, I don't know how to fix it.

network.cpp (line 209):
`network = new Convolve(stub.name_, stub.ni_, 0, 0);`

MSVC gives the linker error:
 error LNK2001: unresolved external symbol "public: __thiscall tesseract::Convolve::Convolve(class STRING const &,int,int,int)" (??0Convolve@tesseract@@QAE@ABVSTRING@@HHH@Z)

If this line is commented, project is built normally without errors.
convolve,cpp is included and Convolve::Convolve is definetely presented.
Weird thing that there is another file - networkbuilder.cpp where
one can see almost the same code, and it works fine:
```
  Convolve* convolve =
      new Convolve("Convolve", input_shape.depth(), x / 2, y / 2);

```
But after being copied to network.cpp it give the same link error.
I spent an hour trying to fix but failed.
What if I just comment this line? When it is used? Commenting that line is not a good idea.

https://msdn.microsoft.com/en-us/library/f6xx1b1z.aspx

CC: @egorpugin  No, never heard of it. MSVC project, mostly assembled manually. The previos versions 3.02, 3.04, were assembled and compiled normally. 
First I thought that maybe it's leptonica's "convolve.c" that has collisions with lstm's "convolve.cpp" module and renamed the "convolve.c" to "convolve2.c" with no effect. cppan --build pvt.cppan.demo.google.tesseract.tesseract-master.
gives an error
boost::filesystem::path codecvt to wstring: error WIndows 10, MSVC 2017 community Account to where? I have no account in Russian letters, though I am Russian Oh I see, I changed it to another user, now cppan goes further but no enough "There errors during test start". Log files are empty I use the latest MSVC, is this enough for the latest cmake?
I solved the problem just by copied the source code from convolve.cpp (it's very small) to network.cpp and everything went fine. When I was building 3.02 and 3.04 I didn't know about cppan, so i just manually added all required libraries and everything went fine. Today I found that there is 3.05 version, I downloaded it, added libs and evrything was compiled and linked perfectly as always, it took me around 15 minutes. Obviously I like that way and prefer to use it again with 4.0 version. 
As per my PC, I didn' do to it something unusual, OS  was installed a month ago, MSVC 2017, the tesseract code was not changed, As I said, I resolved the problem, so no need to do anything with the code, perhaps you are right and the problem is with my machine Thank you for your efforts!
Ok, Egor, I will try to use cppan on a new virtual machine with Win10, pure MSVC and a proper Administrator. After creating MSVC project again more accurately (adding files one by one) I succeeded in  building MSVC project without changing the source code. Nevertheless one weird thing I made - I had to add convolve.cpp in the main project. Now it contains two files - main.cpp (my own source code) and convolve.cpp (other dependencies are through lib files). 
MSVC also gives a warning  while linking:
x64\Release\convolve.obj : warning LNK4042: object specified more than once; extras ignored
I don't know what it means  You have two options:
1. Put the deu.trainwddata directly under your tessdata dir.
2. Put the tessdata_best dir under your tessdata dir, and use -l tessdata_best/deu >Put the tessdata_best dir under your tessdata dir, and use -l tessdata_best/deu

A variant of that option:
Rename the tessdata_best dir, for example to 'best',  put it under your tessdata dir, and use -l best/deu Tesseract has this parameter:
 
`m_data_sub_dir `- Directory for data files

It's not new.

The default value for that parameter is `tessdata/`

>I simply replaced (exchanged) my existing .../tessdata with the the new .../tessdata_best. Tesseract 

In that case another option is to put this line in a text file:
`m_data_sub_dir tessdata_best/`
and use it as config file for tesseract.
  You did not copy the command which was used to run the compiler from your build protocol. It should look like this:

    depbase=`echo ambigs.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
    /bin/bash ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -DUSE_STD_NAMESPACE   -I/usr/include/leptonica -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -DTESSDATA_PREFIX=/usr/local/share/  -g -O2 -std=c++11 -MT ambigs.lo -MD -MP -MF $depbase.Tpo -c -o ambigs.lo ambigs.cpp &&\
    mv -f $depbase.Tpo $depbase.Plo
    libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DUSE_STD_NAMESPACE -I/usr/include/leptonica -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -DTESSDATA_PREFIX=/usr/local/share/ -g -O2 -std=c++11 -MT ambigs.lo -MD -MP -MF .deps/ambigs.Tpo -c ambigs.cpp  -fPIC -DPIC -o .libs/ambigs.o
    libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DUSE_STD_NAMESPACE -I/usr/include/leptonica -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -DTESSDATA_PREFIX=/usr/local/share/ -g -O2 -std=c++11 -MT ambigs.lo -MD -MP -MF .deps/ambigs.Tpo -c ambigs.cpp -o ambigs.o >/dev/null 2>&1

Check whether yours looks different, especially whether `-DUSE_STD_NAMESPACE` is missing. That would explain the build failure. I also use Debian 9, same libtiff5-dev, and I do not have `/usr/share/tesseract-ocr/4/tessdata/`. I'd examine it with `ls -l` (is it old) and `dpkg -S` (where does it belong to) and move it out of the way. @Wikinaut, did you solve the issue?  Before you submit an issue, please review [the guidelines for this repository](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md).

Please report an issue only for a BUG, not for asking questions.

Note that it will be much easier for us to fix the issue if a test case that
reproduces the problem is provided. Ideally this test case should not have any
external dependencies. Provide a copy of the image or link to files for the test case.

Please delete this text and fill in the template below. 

------------------------

### Environment

* **Tesseract Version**: tesseract 3.04.00
* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
* **Platform**: Linux 0ba52aafd58a 4.9.4-moby #1 SMP Wed Jan 18 17:04:43 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

### Current Behavior:

When processing a multi page TIFF with Tesseract API in python, the text returned is only for the LAST page rather than for ALL pages. 

Code used:

```
self.tesseract.TessBaseAPIProcessPages.argtypes = [POINTER(TessBaseAPI), c_char_p, c_char_p, c_int, POINTER(TessResultRenderer)]
self.tesseract.TessBaseAPIProcessPages.restype = c_bool
success = self.tesseract.TessBaseAPIProcessPages(self.api, create_string_buffer(path_to_multipage_tiff), None , 0, None)
ocr_r = self.tesseract.TessBaseAPIGetUTF8Text(self.api)
result = string_at(ocr_r)
```

### Expected Behavior:

Instead of text returned only for the last page, the text should be returned for all pages. 

### Suggested Fix:

Interestingly this works when using the command line `tesseract` command. So perhaps there is already a fix for the command line.  Please report this issue in the repo of the python binding.  @zdenop  this happens in 3.05.01 as well. I'm wondering whether calling `TessBaseAPIProcessPages ` is the correct way to get ALL text from multi page pdfs?  OR whether there is another recommended way

@amitdo I did not see python binding repo under tesseract. Can you please link me to the one you are referring to? Please note i'm using `ctypes` to call the acutal tesseract API and not the python wrapper for tesseract.  >I did not see python binding repo under tesseract. Can you please link me to the one you are referring to? Please note i'm using ctypes to call the acutal tesseract API

I thought that you are using a 3rd party python binding.
https://github.com/tesseract-ocr/tesseract/wiki/AddOns#tesseract-30x

 >Interestingly this works when using the command line tesseract command. So perhaps there is already a fix for the command line

The command line uses the C++ API. @amitdo Sorry for the confusion, but I am not. I am referring to the actual tesseract capi. The capi can be called from python as shown in this example https://github.com/tesseract-ocr/tesseract/blob/a75ab450a8cc9a2b69cf05f5c4f7a39bc44cbacc/contrib/tesseract-c_api-demo.py#L72 Note that the linked example is a bit out of date. An actual example that works is https://stackoverflow.com/a/36876584/44286

However, the issue still remains of how to call capi to get all the text from multi page TIFF instead of text from only the last page > text = tesseract.TessBaseAPIGetUTF8Text(api)

This method returns text for one page only. The command line tool does not **directly** call this method.

You'll have to look in api/tesseractmain.cpp and mimic it to get things right.

Anyway, it's not an issue (bug) in tesseract command line or API.  Thanks. I've posted this question on the user-forums here: https://groups.google.com/forum/#!topic/tesseract-ocr/AL9LzrHa97k

I will continue to dig into `tesseractmain.cpp` to see if something points out  There is no direct way to get the text in all pages with ProcessPages.

if you give it a pointer to TessResultRenderer, the text is written to a file or stdout.  Recently the first regression tests were added to the Tesseract sources, and hopefully more will be added in the future. I expect that many of those tests will require images, maybe also related text and other files. Typically the images are large (much larger than source code files),  and most image formats are already compressed, so Git cannot compress them further. This is bad for the git repository size, but also for the size of the working directory or of release tarballs.

Currently 8 of the 10 largest files are test related:

    1444515 ccutil/universalambigs.cpp
     708120 testing/DuTillet1004Pg2LG.jpg
     444141 testing/hebtypo.jpg
     401757 testdata/chi_tra.unicharset
     399613 testing/hebrew-nikud-genesis-1-2.png
     378914 testdata/kan.unicharset
     359497 ccutil/tesscallback.h
     327214 testdata/chi_sim.unicharset
     239201 testdata/jpn.unicharset
     221628 testdata/mar.unicharset

We should avoid adding more such files. I suggest to create a new repository called `tesstest`,  `testdata`, `tesseract_testdata` or any other name for all test related data and move the existing test data to that repository. The `tesseract` repository can then include that new repository as a git submodule which is only needed when running tests (so most people won't need it).

OpenJPEG is an example of another Open Source project with a similar split of [source code](https://github.com/uclouvain/openjpeg) and [test data](https://github.com/uclouvain/openjpeg-data). They do not use a git submodule, but have a configure option to choose the location of the test data. ... or more. Test images use a lot of disk space.  This change does not look like the right solution for an existing problem. I'm afraid it should be reverted.  ------------------------

### Environment

* **Tesseract Version**: Tesseract 4.00.00 alpha
* **Commit Number**:  188e1fc
* **Platform**: Ubuntu 16.04.02 LTS

### Current Behavior:
I've downloaded and compiled latest tesseract source file from git repository but when i run tesseract engine with mode --oem 1, --psm 0 or 1 it can't load osd.traineddata. My osd.traineddata file is downloaded from tessdata_best. I tried with older osd.traineddata file from tessdata directory it works fine. I've cloned tessdata_best from repo and checked any download error but it was okay. 
installed tesseract shown below.
![tesseract](https://user-images.githubusercontent.com/30248220/30473888-72f05e40-9a34-11e7-9518-de668fd6c024.png)

I can load and work well with osd.traineddata from tessdata which is created about 3 yrs ago and include following files 
![old](https://user-images.githubusercontent.com/30248220/30474105-1effef34-9a35-11e7-9118-d89403fca397.png)
 
the one tesseract fails at loading includes lstm files which is shown below.
![new](https://user-images.githubusercontent.com/30248220/30474201-74a6bbfc-9a35-11e7-82b5-09e97706263d.png)

![osdfailed](https://user-images.githubusercontent.com/30248220/30474253-98bbc1cc-9a35-11e7-8b04-29b2477bd070.png)
here i am using lstm mode of engine so it should load osd.traineddata successfully but it shows failure message. It can load other language's lstm traineddata files and i can get result of text recognition despite of giving 'failed loading language osd' message but i can't feel any difference using best osd so it is not loading best osd.traineddata at all. 

So i guess it is bug related to tesseract engine or osd.traineddata file which is in tessdata_best.  facing same issue for urd.tessdata from tessdata_best  Should `tessdata_best` and `tessdata_fast` be Git submodules of `tessdata` to support language options like `-l eng` (old model), `-l best/eng` (best LSTM model) or `-l fast/eng` (fast LSTM model)? Then only a single `tessdata` directory is needed for installations, and it would be easier to document the relationship between all three repositories (think of new versions). Locally trained models could easily be added in additional subdirectories and used like `-l local/eng` or `-l user/eng`. "config file" is a good keyword:

Will Tesseract continue to use the same configuration files for standard, fast and best traineddata? Then having a single `tessdata` directory would be better. Handling of "sublanguages" which are invoked could be fixed in the code or in the config files.

If Tesseract needs different configuration files for standard, fast and best traineddata, separate `tessdata` directories will be required.
 I wonder whether the current approach with "best" and "fast" traineddata is reasonable: both contain basically the same data, only the LSTM model in the traineddata files differs. Some numbers for `best/Latin.traineddata`:

    # Component size / MiB
    12      Latin.lstm
    1       Latin.lstm-number-dawg
    1       Latin.lstm-punc-dawg
    1       Latin.lstm-recoder
    1       Latin.lstm-unicharset
    85      Latin.lstm-word-dawg
    1       Latin.version
    97      total

`fast/Latin.traineddata` is identical with one exception:

    # Component size / MiB
    1       Latin.lstm

So it would also be possible to modify Tesseract to get both kinds of `Latin.lstm` from the same traineddata file (using a new component name like `Latin.lstm-fast`) and select the desired one with a new command line option. That would avoid the duplication of the other data and simplify the handling while increasing the size of the traineddata only by a small amount.

    97      best/Latin.traineddata
    86      fast/Latin.traineddata

A combined traineddata file with best and fast model included could be zipped and would be much smaller then:

    51      best/Latin.zip
 >Just quoting Ray about 'best' and 'fast':

>2 parallel sets of tessdata. "best" and "fast". "Fast" will exceed the speed of legacy Tesseract in real time, provided you have the required parallelism components, and in total CPU only slightly slower for English. Way faster for most non-latin languages, while being <5% worse than "best" Only "best" will be retrainable, as "fast" will be integer.
 I now did a complete comparison of the extracted "best" and "fast" traineddata files. Besides the `lstm` and `version` parts, they are identical, but "best" includes these additional files:

    ara.config
    ben.config
    chi_sim.config
    chi_sim_vert.config
    chi_tra.config
    chi_tra_vert.config
    deu.config
    ell.config
    hin.config
    ita.config
    jpn.config
    jpn_vert.config
    kan.config
    kor.config
    mal.config
    mar.config
    nep.config
    srp.config
    tam.config
    tel.config
    tha.config
    vie.config

It's not clear why these parts exist in "best", and already the first one `ara.config` looks wrong:

    # We do not yet have Tesseract for Arabic, so use OEM_CUBE_ONLY
    # (see OcrEngineMode enum in third_party/tesseract/ccmain/tesseractclass.h).
    tessedit_ocr_engine_mode        1
    [...]

 >\# We do not yet have Tesseract for Arabic, so use OEM_CUBE_ONLY
\# (see OcrEngineMode enum in third_party/tesseract/ccmain/tesseractclass.h).

This comment should be updated

>tessedit_ocr_engine_mode        1

This is still ok for ara. Shouldn't all fast and best traineddatas have this:

>tessedit_ocr_engine_mode 1

in their config? Tesseract chooses the correct mode automatically.

There are 161 tessdata files in `tessdata_best`, but only 28 of them contain a config part.
`deu.traineddata` loads `frk.traineddata`. That looks wrong for me. Maybe other config files should not be there, too.

 >Tesseract chooses the correct mode automatically.

Yeah, I know, but oem 1 is more explicit.  My tesseract application always downloads eng.traineddata.gz file from internet. I want to make it offilne. How it;s possible? Help me please @sabirhusssain, the right place to ask questions is [our forum](https://groups.google.com/d/forum/tesseract-ocr).  Hello,
I compiled and installed the latest Leptonica and Tesseract without problems.

`tesseract -v 
`

> tesseract 4.00.00alpha
 leptonica-1.74.4
  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8
 Found AVX2
 Found AVX
 Found SSE

`tesseract image.jpg --tessdata_dir /usr/local/share/tessdata -l eng`

> tesseract: genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

When I use the tesserocr python wrapper, it seems to work.
Any suggestions? >tesseract image.jpg --tessdata-dir /usr/local/share/tessdata -l eng

try this:

>tesseract image.jpg **out** --tessdata_dir /usr/local/share
 `tesseract image.jpg out --tessdata_dir /usr/local/share/tessdata -l eng`
> tesseract: genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

`tesseract image.jpg out.txt --tessdata_dir /usr/local/share/tessdata -l eng`
> tesseract: genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

`tesseract image.jpg stdout --tessdata_dir /usr/local/share/tessdata -l eng`
> tesseract: genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

Would you recommend to reinstall?

Edit:
`tesseract image.jpg out -l eng`
 works

`echo $TESSDATA_PREFIX`
> /usr/local/share/tessdata/

however when specifying the tessdata_dir parameter it doesn't

Edit 2:
Alright... it's a dash in tessdata-dir not an underscore .. sorryy :))  I must admit that I never used that Makefile target. Do we need it at all? If we offer a target which
downloads eng.traineddata, I wonder whether it would be better to get one which supports both the old and the new recognizer (only as long as both are supported, of course).

A side notice:

Currently Tesseract requires eng.traineddata even if someone only wants to get the Tesseract version or the list of available languages. I don't think that this is satisfying.

Tesseract functions which are unrelated to eng.traineddata should work without it. Getting the `traineddata` files needs an internet connection. A simple `make` should work without internet. But a `make install` should result in a working installation, so for that case it would be good to include your code. @jbreiden, how do you build the Debian packages with `traineddata` then? Is there a "standard" Makefile target to get files needed for the installation from the internet? Related: would it make sense to add the Debian rules to the Tesseract repository?
Maybe rules for other distributions (e.g. I have files for the Windows installer), too? It's similar for Debian: https://packages.debian.org/stretch/tesseract-ocr.

The [experimental version](https://packages.debian.org/experimental/tesseract-ocr) switches to 4.0 and adds a non-existing package `tesseract-ocr-eng-ltsm`. Deleted comment (wrong place) Are you referring to my [other comment](https://github.com/tesseract-ocr/tesseract/issues/1131#issuecomment-329764356) about "best" and "fast"? >Are you referring to my other comment about "best" and "fast"?

Sorry, I chose the wrong tab in the browser to paste the quote :-) >  Upcoming: /usr/share/tesseract-ocr/4.00/tessdata/

@jbreiden, I still hope that we'll get semantic versioning for Tesseract. Therefore I suggest to use a different name `/usr/share/tesseract-ocr/4/tessdata/`, `/usr/share/tesseract-ocr/4.0/tessdata/` or even `/usr/share/tesseract4/tessdata/` (do you need the "-ocr" in the package names, or can it be dropped?).  The test failed for out-of-tree builds with autotools because it could not find the required files.
It also failed when the "en_US.UTF-8" locale was missing.

Now it passes. This completes my previous PR #1123.  for example
char[x,y,height,widthg]getConfidence()
Êúâ[193.0,438.0,29.0,28.0]99.415886
Ê≤°[223.0,437.0,28.0,51.0]98.77193
Êúâ[900.0,0.0,0.0,0.0]99.5725
ËÆ©[290.0,437.0,28.0,46.0]99.56392
the third ‚ÄúÊúâ‚Äù between "Ê≤°" and "ËÆ©",but BoundingBox().x is 900, BoundingBox().y is 0; use LSTM by Tess4j 4.0 @zdenop, as Shree noted, this issue is similar to #1015, so I suggest to close this one.  The library is provided in the build path (which is not
the same as the source path for out of tree builds).

Signed-off-by: Stefan Weil <sw@weilnetz.de> @Shreeshrii, it looks like more work is needed to get a working `apiexample_test` with out of tree builds.  >It seems that works, thank you

Why did you re-opened it?  Libtool's convenience libraries should never be installed. Fixes #985. Thank you too!  ### Environment

* **Tesseract Version**: 4.00 (cloned now from master)
* **Leptonica Version**: 1.7.8
* **Commit Number**: 7569c899f732829a56da1ed797dc3fc90093406f
* **Platform**: Linux vagrant-ubuntu-trusty-64 3.13.0-125-generic #174-Ubuntu SMP Mon Jul 10 18:51:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

### Current Behavior:
Cannot build from source from branch master

### Expected Behavior:
Should be able to build

### Steps to reconstruct:
**Run:**
git clone --depth 1 https://github.com/tesseract-ocr/tesseract.git
cd /tesseract
./autogen.sh
./configure --enable-debug
LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include"
make
make install
make training

**Output:**
/bin/bash ../libtool  --tag=CXX   --mode=link g++  -g -O2 -std=c++11  -L/usr/local/lib -llept    -o unicharset_extractor unicharset_extractor.o libtesseract_tessopt.la  ../api/libtesseract.la  -lpthread 
libtool: link: g++ -g -O2 -std=c++11 -o .libs/unicharset_extractor unicharset_extractor.o  -L/usr/local/lib /usr/local/lib/liblept.so ./.libs/libtesseract_tessopt.a ../api/.libs/libtesseract.so -lpthread -fopenmp
unicharset_extractor.o: In function `tesseract::Main(int, char**)':
/tesseract/training/unicharset_extractor.cpp:66: undefined reference to `tesseract::ReadFile(std::string const&, bool (*)(STRING const&, GenericVector<char>*))'
unicharset_extractor.o: In function `AddStringsToUnicharset':
/tesseract/training/unicharset_extractor.cpp:48: undefined reference to `tesseract::NormalizeCleanAndSegmentUTF8(tesseract::UnicodeNormMode, tesseract::OCRNorm, tesseract::GraphemeNormMode, bool, char const*, std::vector<std::string, std::allocator<std::string> >*)'
/tesseract/training/unicharset_extractor.cpp:53: undefined reference to `tesseract::IsWhitespace(int)'
unicharset_extractor.o: In function `tesseract::Main(int, char**)':
/tesseract/training/unicharset_extractor.cpp:81: undefined reference to `tesseract::SetupBasicProperties(bool, bool, UNICHARSET*)'
unicharset_extractor.o: In function `main':
/tesseract/training/unicharset_extractor.cpp:96: undefined reference to `tesseract::ParseCommandLineFlags(char const*, int*, char***, bool)'
collect2: error: ld returned 1 exit status
make[1]: *** [unicharset_extractor] Error 1
make[1]: Leaving directory `/tesseract/training'
make: *** [training] Error 2


### Suggested Fix:
The rule to make `unichar_extractor` was changed in the last pull request closed (#1116) Fixed in PR #1118  ### Environment

Using the training data from https://github.com/tesseract-ocr/tessdata/tree/master/best on tesseract 4

Exact command line parameters (aside from input, output, and config) are:

    -l jpn_vert+jpn --psm 5 --oem 1

* **Tesseract Version**: <!-- compulsory. you must provide your version -->

    tesseract 4.00.00alpha
     leptonica-1.74.4 (Jun 22 2017, 16:20:35) [MSC v.1900 DLL Release x86]
      libjpeg 9b : libpng 1.6.28 : libtiff 4.0.7 : zlib 1.2.11 : libwebp 0.6.0 : libopenjp2 2.1.2

* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->

Specific build ripped from the 2017-09-04 build of VietOCR-5.0-alpha, however the same exact behavior was experienced with "zip file with cppan generated .dll and .exe files" from https://github.com/tesseract-ocr/tesseract/wiki/4.0-with-LSTM

* **Platform**: <!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->

Windows 7 x64

### Current Behavior:

https://i.imgur.com/rtzROTu.png

OCRs correctly with the following config:

    preserve_interword_spaces 1
    paragraph_text_based 0
    textord_old_baselines 0

OCRs wrong with the following config:

    preserve_interword_spaces 1
    paragraph_text_based 0
    textord_old_baselines 1

Wrong OCR:

    „Ç±„Éº„Çø„Ç§„ÅØ
    „Ç´„Éê„Éë„Éê„É≥„Å´
    ÂÖ•„Çå„Å¶„ÅÇ„Çã„Åó

„Ç´„Éê„Éë„Éê„É≥ should be „Ç´„Éê„É≥

https://i.imgur.com/TA1Qa2O.png

OCRs correctly with the following config:

    preserve_interword_spaces 1
    paragraph_text_based 0
    textord_old_baselines 1

OCRs wrong with the following config:

    preserve_interword_spaces 1
    paragraph_text_based 0
    textord_old_baselines 0

Wrong OCR:

    „ÉÜ„Ç£„Ç§„ÉÑ„Ç∑„É•„ÅØ
    „Çπ„Ç´„Éº„Éà„ÅÆ
    „Éù„Ç±„ÉÉ„Éà„Å†„Åë„Çâ
    Â§ß‰∏àÂ§´!

„ÉÜ„Ç£„Ç§„ÉÑ„Ç∑„É• should be „ÉÜ„Ç£„ÉÉ„Ç∑„É• (or at least „ÉÜ„Ç§„ÉÑ„Ç∑„É¶ with set of small kana)

If preserve_interword_spaces is set to 0, it appears that the relevant characters are being used more than once for different "words":

„Ç±„Éº „Çø„Ç§ „ÅØ
„Ç´„Éê „Éë „Éê„É≥ „Å´
ÂÖ•„Çå „Å¶ „ÅÇ„Çã „Åó

„ÉÜ„Ç£ „Ç§„ÉÑ „Ç∑„É• „ÅØ
„Çπ„Ç´ „Éº „Éà „ÅÆ
„Éù„Ç± „ÉÉ „Éà „Å† „Åë„Çâ
Â§ß ‰∏àÂ§´ !

**Regardless of configuration, both examples OCR correctly if OCRed one or two lines at a time, but start OCRing wrong if three or more lines are OCRed at once.**

psm settings other than 5 (or 6 for horizontal panels) give results like "empty page", "not enough words", or missing characters/words entirely, so I can't compare them.

If imgur strips metadata, both images are set to have a DPI value of 300.

### Expected Behavior:

With at least one of the configs, for both images to OCR correctly, without characters being used in multiple words.

### Suggested Fix:

N/A The „Ç´„Éê„É≥ example in the original post is alternatively fixed by setting "lstm_use_matrix 0". It seems like "lstm_use_matrix 1" is very bad.

More examples with bad OCR with various combinations of these two settings below. Summary: lstm_use_matrix 0 is universally better than 1, textord_old_baselines 0 is better than 1 most of the time but can throw away entire lines.

Single line: https://i.imgur.com/BTeN4Lx.png

OCRs with "reused characters" regardless of the value of textord_old_baselines or lstm_use_matrix. A fictitious „Çá is inserted no matter what. Some other croppings of this particular are improved by setting "lstm_use_matrix 0", but it doesn't always help.

Setting both "lstm_use_matrix 0" and "textord_old_baselines 0" seems to help in general, but doesn't fix the problem all the time Example:

https://i.imgur.com/ji4CQdr.png

Config:

    preserve_interword_spaces 0
    paragraph_text_based 0
    textord_old_baselines 1
    lstm_use_matrix 1

Output:

    „Åª „ÅÆ „Çä „Å°„ÇÉ „Çì „Åå
    ‰∏Ä Á∑í „ÅÆ ÈÉ® Ê¥ª „Å´

    ÂÖ•„Å£ „Å¶ „Åè„Çå „Å¶

    „ÅÜ„Çå „Åó „ÅÑ„Å≠ „ÅØ „Å£ „Å¶

fictitious „ÅØ

Config:

    preserve_interword_spaces 0
    paragraph_text_based 0
    textord_old_baselines 1
    lstm_use_matrix 0

Output:

    „Åª „ÅÆ „Çä „Å° „ÇÉ „Çì „Åå
    ‰∏Ä Á∑í „ÅÆ ÈÉ® Ê¥ª „Å´

    ÂÖ• „Å£ „Å¶ „Åè „Çå „Å¶

    „ÅÜ „Çå „Åó „ÅÑ „Å≠ „ÅØ „Å£ „Å¶

fictitious „ÅØ, still

Config:

    preserve_interword_spaces 0
    paragraph_text_based 0
    textord_old_baselines 0
    lstm_use_matrix 1

Output:

    „Åª „Å∞ „ÅÆ„Çä „Å°„ÇÉ „Çì „Åå
    ‰∏Ä Á∑í „ÅÆ ÈÉ® Ê¥ª „Å´

    ÂÖ•„Å£ „Å¶ „Åè„Çå „Å¶

    „ÅÜ„Çå „Åó „ÅÑ„Å≠ „Å£ „Å¶

fictitious „Å∞



Config:

    preserve_interword_spaces 0
    paragraph_text_based 0
    textord_old_baselines 0
    lstm_use_matrix 0

Output:

    „Åª „ÅÆ „Çä „Å° „ÇÉ „Çì „Åå
    ‰∏Ä Á∑í „ÅÆ ÈÉ® Ê¥ª „Å´

    ÂÖ• „Å£ „Å¶ „Åè „Çå „Å¶

    „ÅÜ „Çå „Åó „ÅÑ „Å≠ „Å£ „Å¶

Correct

Setting "textord_old_baselines 0" is definitely not ideal, because 1 (the default) is responsible for accuracy gains in various cases:

https://i.imgur.com/tH8yx84.png

textord_old_baselines 1 -> ÈÉ® Èï∑ „Å™ „Çì „Å† „Åã „Çâ
textord_old_baselines 0 -> ÈÉ® Èï∑ „Å™ „Çì „Å† „Éµ „Åã „Çâ

Image where "textord_old_baselines 0" throws away an entire line: and "lstm_use_matrix 1" causes character misrecognition: https://i.imgur.com/8d65wSf.png

textord_old_baselines 1, lstm_use_matrix 1 -> „Å°„Å£ DI „Çí „Åß„ÄÄ„ÄÄÂøÉÈÖç „Å† „Åó„ÄÄ„ÄÄ„Å® „Çä„ÅÇ „Åà „Åö ÂÖ•„Å£ „Å¶

textord_old_baselines 0, lstm_use_matrix 1 -> „ÇÅ„ÅÑ Â≠ê „Å° „ÇÉ „Çì „Ç´„ÄÄ„ÄÄ„Å® „Çä„ÅÇ „Åà „Åö ÂÖ•„Å£ „Å¶

textord_old_baselines 1, lstm_use_matrix 0 -> „ÇÅ „Åò Â≠ê „Å° „ÇÉ „Çì „Ç´„ÄÄ„ÄÄÂøÉ ÈÖç „Å† „Åó„ÄÄ„ÄÄ„Å® „Çä „ÅÇ „Åà „Åö ÂÖ• „Å£ „Å¶

textord_old_baselines 0, lstm_use_matrix 0 -> „ÇÅ „ÅÑ Â≠ê „Å° „ÇÉ „Çì „Ç´„ÄÄ„ÄÄ„Å® „Çä „ÅÇ „Åà „Åö ÂÖ• „Å£ „Å¶

(the above double fullwidth spaces are substitutes for the newlines) What's the content of the official best traineddata's config file? AFAIK, the stuff under https://github.com/tesseract-ocr/tessdata/tree/master/best is all there is for the "best" traineddata. Yes, but there's a way to unpack the traineddata and see its individual files.  [jpn.config.txt](https://github.com/tesseract-ocr/tesseract/files/1291681/jpn.config.txt)
[jpn_vert.config.txt](https://github.com/tesseract-ocr/tesseract/files/1291683/jpn_vert.config.txt)
  I'm trying to run this demo with tesseract 4.0 lstm training : 

mkdir -p ~/tesstutorial/engoutput
training/lstmtraining --debug_interval 100 \
  --traineddata ~/tesstutorial/engtrain/eng/eng.traineddata \
  --net_spec '[1,36,0,1 Ct3,3,16 Mp3,3 Lfys48 Lfx96 Lrx96 Lfx256 O1c111]' \
  --model_output ~/tesstutorial/engoutput/base --learning_rate 20e-4 \
  --train_listfile ~/tesstutorial/engtrain/eng.training_files.txt \
  --eval_listfile ~/tesstutorial/engeval/eng.training_files.txt \
  --max_iterations 5000 &>~/tesstutorial/engoutput/basetrain.log

and system returns me a message as this:
Segmentation fault (core dumped)

When I checked the log file which is generated by this process, I got this:

mgr_.Init(traineddata_path.c_str()):Error:Assert failed:in file ../lstm/lstmtrainer.h, line 110


What should I do to make it work?

------------------------

### Environment

* **Tesseract Version**: <4.0>
* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
* **Platform**: <Ubuntu 16.04>

### Current Behavior:

### Expected Behavior:

### Suggested Fix:
 @KevinZhuYF, please respond to @Shreeshrii's question.
  Did you use the updated shell scripts or your own (older) modified scripts? I didn't try the latest commits yet, but  saw that there where some changes in the shell script, and thus posted my above comment...   I am really confused. It seems that even finetunning commands does not work anymore: 
I used these commands and I put the Arabic.traineddata from the best folder in tessdata directory:

training/tesstrain.sh \ 
  --fonts_dir /usr/share/fonts \
  --training_text ./langdata/ara/ara.training_text \
  --langdata_dir ./langdata \
  --tessdata_dir ./tessdata \
  --lang ara  \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --output_dir ~/tesstutorial/aratrain
then I uesd these:

mkdir -p ~/tesstutorial/aratuned_from_ara

combine_tessdata -e ./tessdata/Arabic.traineddata \
  ~/tesstutorial/aratuned_from_ara/ara.lstm

lstmtraining --model_output ~/tesstutorial/aratuned_from_ara/aratuned \
  --continue_from ~/tesstutorial/aratuned_from_ara/ara.lstm \
  --traineddata ~/tesstutorial/aratrain/ara/ara.traineddata \
  --train_listfile ~/tesstutorial/aratrain/ara.training_files.txt \
  --target_error_rate 0.01

and I got this error:
Loaded file /home/fanasa/tesstutorial/aratuned_from_ara/ara.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Code range changed from 307 to 95!!
Must supply the old traineddata for code conversion!
Failed to continue from: /home/fanasa/tesstutorial/aratuned_from_ara/ara.lstm

while these commands worked before.  If you need the training part, use 147a1a50b766. It seems one or more of the latest commits from Ray broke the training. actully I need the changes to tessdata. because it solved the problem of
ŸÑÿß. under this condition can I use this 147a1a5
<https://github.com/tesseract-ocr/tesseract/commit/147a1a50b766b94c3f2ffa9b8bdccfacf2d42ff0>
?


On Tue, Sep 12, 2017 at 5:39 PM, Amit D. <notifications@github.com> wrote:

> If you need the training part, use 147a1a5
> <https://github.com/tesseract-ocr/tesseract/commit/147a1a50b766b94c3f2ffa9b8bdccfacf2d42ff0>.
> It seems one or more of the latest commits from Ray broke the training.
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-328847799>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAWPo4jZ0iUhwS90AmCI5VAepfFdAks5shoJ6gaJpZM4PR9Tr>
> .
>
 @Shreeshrii 
yes . it seems that there was no problem with using training/tesstrain.sh.
 @Shreeshrii 
thanks. I think your solution is working the finetuning process was finished. I tested the result model. the problem of ŸÑÿß which was solved in Arabic.traineddata, again appeared in my finetuned model. 
@Shreeshrii do you have any idea why this is happening?
 @theraysmith the Arabic.traineddata can not be used in finetuning? @theraysmith I think the changes which made the Arabic.traineddata recognize ŸÑÿß correctly, are not applied to the source code. would you please apply these changes
 @Shreeshrii now I am facing this problem|:
Extracting unicharset from box file /tmp/tmp.UFLtOD70jF/ara/ara.Arab.exp0.box
Invalid Unicode codepoint: 0xffffffd9
IsValidCodepoint(ch):Error:Assert failed:in file ../../training/normstrngs.cpp, line 225
ERROR: /tmp/tmp.UFLtOD70jF/ara/ara.unicharset does not exist or is not readable

could you solve this? It was merged now. But I am confused. Why does this code change fix something? The new code no longer matches the comment ("In the range [0, 0xD800) or [0xE000, 0x10FFFF]"). And `0xffffffd9` does not look like a valid Unicode codepoint. @Shreeshrii but your PR removed my error. do I have to change it back.
yesterday I updated my tesseract. Do I have to use a newer version?

On Mon, Sep 18, 2017 at 9:51 AM, Shreeshrii <notifications@github.com>
wrote:

> @stweil <https://github.com/stweil> You are right.
>
> I reverted my change and training is still working now. So, it must have
> been something else that caused the problem. my PR
> https://github.com/tesseract-ocr/tesseract/pull/1134/files does not fix
> it. I had removed some unneeded software and updated the system - maybe
> that had something to do with it.
>
> However, there have been two other reports of same error -
>
> https://groups.google.com/forum/?utm_medium=email&utm_
> source=footer#!msg/tesseract-ocr/fqyYaav6vmk/M8xjpwhpBAAJ
>
> #1114 (comment)
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-330022935>
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-330131339>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAejV1sTPtVIC9dvSv9JkOIuiAtiVks5sjf3ygaJpZM4PR9Tr>
> .
>
 ccutil/unichar.h
typedef signed int char32;

ccutil/host.h
typedef uint32_t uinT32;

http://icu-project.org/apiref/icu4c/
umachine_8h.html
typedef int32_t UChar32
 Stefan,

Why a static_cast is needed here, and only for the first comparison to 'ch'? That's a trick: `return (ch >= 0 && ch < 0xD800) || (ch >= 0xE000 && ch <= 0x10FFFF)`would also implement the test for a valid code point. The static cast of the signed `ch` to an unsigned value saves the `ch >= 0` test. 

A static cast to a negative value changes nothing and could be omitted as well. Maybe we should use the explicit code without any casts and leave optimisations to the compiler.
     bool IsWhitespace(const char32 ch) {
    //  ASSERT_HOST_MSG(IsValidCodepoint(ch), "Invalid Unicode codepoint: 0x%x\n",
    //                  ch);
        if (!IsValidCodepoint(ch)) {
            tprintf("Invalid Unicode codepoint: %d = 0x%x\n", ch, ch);
        }
        return u_isUWhiteSpace(static_cast<UChar32>(ch));
    }
 @Shreeshrii, this pull request might fix it: https://github.com/ivanzz1001/tesseract/pull/1. It still has to be requested for the [tesseract-ocr](https://github.com/tesseract-ocr/tesseract) repository Try this and report (not tested):

`if (normed.empty() || IsUTF8Whitespace(normed[0])) continue;`

-->

`if (normed.empty() || IsUTF8Whitespace(normed.c_str())) continue;` @ivanzz1001 sent a PR which includes his fix and my above fix: #1153
 No error messages or asserts does not necessarily mean that the new code works. See [my comment](https://github.com/tesseract-ocr/tesseract/pull/1153#discussion_r140649990) for the pull request. @Shreeshrii
Now, can I train a new model for Arabic and Farsi using "replacing a few
layers"?
I want to replace the last layer and these are the commands I'm going to
use for farsi (I am using about 250 lines 13 fonts most of them are new)

combine_tessdata -e tessdata/fas.traineddata \
  ~/tesstutorial/newfas_from_fas/fas.lstm



lstmtraining  --old_traineddata  ./tessdata/fas.traineddata \
  --continue_from ~/tesstutorial/newfas_from_fas/fas.lstm \
  --traineddata ~/tesstutorial/fastrain/fas/fas.traineddata \
  --append_index 5 --net_spec '[Lfx192]'\
  --model_output ~/tesstutorial/newfas_from_fas/base \
  --train_listfile ~/tesstutorial/fastrain/fas.training_files.txt \
  --max_iterations 3000

On Sun, Sep 24, 2017 at 11:36 AM, Stefan Weil <notifications@github.com>
wrote:

> No error messages or asserts does not necessarily mean that the new code
> works. See my comment
> <https://github.com/tesseract-ocr/tesseract/pull/1153#discussion_r140649990>
> for the pull request.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-331694399>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAW3U9dW4A0ajTbTt1Jd4ioaxiMVhks5slg2fgaJpZM4PR9Tr>
> .
>
 @Shreeshrii
I updated tesseract just now and applied : #1153
<https://github.com/tesseract-ocr/tesseract/pull/1153>. I am trying to make
lstmf files but I get this error :

Invalid Unicode codepoint: 0xffffffd9
IsValidCodepoint(ch):Error:Assert failed:in file
../../training/normstrngs.cpp, line 225
ERROR: /tmp/tmp.X7UveftTV1/ara/ara.unicharset does not exist or is not
readable

On Tue, Oct 3, 2017 at 12:04 PM, Shreeshrii <notifications@github.com>
wrote:

> @hanikh
>
> Ray @theraysmith is the correct person to suggest the appropriate commands
> for training Arabic and Farsi.
>
> I would say, that since you have a new set of lstmf files and starter
> traineddata, experiment with both,
>
> Fine-tune plus-minus command
> And
> Replace top layer.
>
> Check the wiki for the syntax and make sure that you use the correct file
> names and path.
>
> Though, Ray recommended 3600 or so iterations, I think that number is
> suitable only for Latin based scripts.
>
>
> For complex scripts, I have tested with Devanagari, I have to go up to
> 10000-20000 iteration to get error rate down to 1%.
>
> Will be good if @theraysmith can confirm.
>
> On 03-Oct-2017 11:54 AM, "hanikh" <notifications@github.com> wrote:
>
> > @Shreeshrii
> > Now, can I train a new model for Arabic and Farsi using "replacing a few
> > layers"?
> > I want to replace the last layer and these are the commands I'm going to
> > use for farsi (I am using about 250 lines 13 fonts most of them are new)
> >
> > combine_tessdata -e tessdata/fas.traineddata \
> > ~/tesstutorial/newfas_from_fas/fas.lstm
> >
> >
> >
> > lstmtraining --old_traineddata ./tessdata/fas.traineddata \
> > --continue_from ~/tesstutorial/newfas_from_fas/fas.lstm \
> > --traineddata ~/tesstutorial/fastrain/fas/fas.traineddata \
> > --append_index 5 --net_spec '[Lfx192]'\
> > --model_output ~/tesstutorial/newfas_from_fas/base \
> > --train_listfile ~/tesstutorial/fastrain/fas.training_files.txt \
> > --max_iterations 3000
> >
> > On Sun, Sep 24, 2017 at 11:36 AM, Stefan Weil <notifications@github.com>
> > wrote:
> >
> > > No error messages or asserts does not necessarily mean that the new
> code
> > > works. See my comment
> > > <https://github.com/tesseract-ocr/tesseract/pull/1153#
> > discussion_r140649990>
> > > for the pull request.
> > >
> > > ‚Äî
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/1114#
> > issuecomment-331694399>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/
> > AZFiAW3U9dW4A0ajTbTt1Jd4ioaxiMVhks5slg2fgaJpZM4PR9Tr>
> > > .
> > >
> >
> > ‚Äî
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/1114#
> issuecomment-333751166>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_o67_
> mlxJ8qCoRQGsmWn9E5awVAFvks5sodMfgaJpZM4PR9Tr>
>
> > .
> >
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-333776145>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAeUcWqUxpaKApaIlo8Nq8GafYHK7ks5sofGogaJpZM4PR9Tr>
> .
>
 @Shreeshrii
I used the mentioned commands for replacing top layer and error rate=0.01,
it is running for about a day and I am just getting this:

Logistic output not implemented yet!

would you please help me find the problem

On Tue, Oct 3, 2017 at 3:58 PM, Shreeshrii <notifications@github.com> wrote:

> PR : #1153 <https://github.com/tesseract-ocr/tesseract/pull/1153> has
> multiple commits. Make sure you have the correct one.
>
> Also, this has not been reviewed by @theraysmith
> <https://github.com/theraysmith> so we don't know whether this is the
> recommended fix for the problem.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-333826072>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiARRkhp11pQ3p26F6g4mYc6l-0zKmks5soihfgaJpZM4PR9Tr>
> .
>
 I changed line 53 of unicharset_extractor.cpp to:
if (normed.empty() || IsUTF8Whitespace(normed.c_str())) continue;

unfortunately, the error still exists

On Wed, Oct 4, 2017 at 12:31 PM, Hanieh Khosravi <hani.khosravi@gmail.com>
wrote:

> @Shreeshrii
> I used the mentioned commands for replacing top layer and error rate=0.01,
> it is running for about a day and I am just getting this:
>
> Logistic output not implemented yet!
>
> would you please help me find the problem
>
> On Tue, Oct 3, 2017 at 3:58 PM, Shreeshrii <notifications@github.com>
> wrote:
>
>> PR : #1153 <https://github.com/tesseract-ocr/tesseract/pull/1153> has
>> multiple commits. Make sure you have the correct one.
>>
>> Also, this has not been reviewed by @theraysmith
>> <https://github.com/theraysmith> so we don't know whether this is the
>> recommended fix for the problem.
>>
>> ‚Äî
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-333826072>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AZFiARRkhp11pQ3p26F6g4mYc6l-0zKmks5soihfgaJpZM4PR9Tr>
>> .
>>
>
>
 @Shreeshrii are you still facing the error:
Invalid Unicode codepoint: 0xffffffd9
IsValidCodepoint(ch):Error:Assert failed:in file
../../training/normstrngs.cpp, line 225
ERROR: /tmp/tmp.mqNL37ZWB5/ara/ara.unicharset does not exist or is not
readable
or I'm the only one?

On Fri, Oct 6, 2017 at 8:23 PM, Shreeshrii <notifications@github.com> wrote:

> I tried testing with a one line english training text which has characters
> that get error
>
> e ¬¢ ‚Äú I ¬∞  ¬© ¬Æ Ô¨Ç
>
> Here are the debug messages that I get:
>
>
> Extracting unicharset from box file /tmp/tmp.ou9ZKjVaiJ/eng/eng.Arial.exp0.box
> Normalization strings DEBUG 'e'
> Normalization normed DEBUG 'e'
> Normalization strings DEBUG '¬¢'
> Normalization normed DEBUG '¬¢'
> Invalid Unicode codepoint: -62 = 0xffffffc2
> Normalization strings DEBUG '‚Äú'
> Normalization normed DEBUG '‚Äú'
> Invalid Unicode codepoint: -30 = 0xffffffe2
> Normalization strings DEBUG 'I'
> Normalization normed DEBUG 'I'
> Normalization strings DEBUG '¬∞'
> Normalization normed DEBUG '¬∞'
> Invalid Unicode codepoint: -62 = 0xffffffc2
> Normalization strings DEBUG '¬©'
> Normalization normed DEBUG '¬©'
> Invalid Unicode codepoint: -62 = 0xffffffc2
> Normalization strings DEBUG '¬Æ'
> Normalization normed DEBUG '¬Æ'
> Invalid Unicode codepoint: -62 = 0xffffffc2
> Normalization strings DEBUG 'Ô¨Ç'
> Normalization normed DEBUG 'Ô¨Ç'
> Invalid Unicode codepoint: -17 = 0xffffffef
>
> Using https://r12a.github.io/apps/conversion/
>
> 0x... notation
>
> 0x65 0x20 0xA2 0x20 0x201C 0x20 0x49 0x20 0xB0 0x20 0x20 0xA9 0x20 0xAE 0x20 0xFB02
>
> But the UTF-8 codepoints have some extra values...
>
> 65 20 C2 A2 20 E2 80 9C 20 49 20 C2 B0 20 20 C2 A9 20 C2 AE 20 EF AC 82
>
> This C2 etc are showing up as invalid codepoints
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-334810725>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAd6GpOHb--skt_i8azHBMqlv3W6yks5splshgaJpZM4PR9Tr>
> .
>
 @hanikh, you are not the only one. Everybody who uses that code is affected. I am currently looking for the right fix (or maybe @theraysmith already has one?). @stweil <https://github.com/stweil>
any news about the mentioned error?

On Tue, Oct 10, 2017 at 1:03 PM, Stefan Weil <notifications@github.com>
wrote:

> @hanikh <https://github.com/hanikh>, you are not the only one. Everybody
> who uses that code is affected. I am currently looking for the right fix
> (or maybe @theraysmith <https://github.com/theraysmith> already has one?).
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-335416565>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAb2018HziiG8xVm1T3FaooN1K3t9ks5sqznXgaJpZM4PR9Tr>
> .
>
 It was fixed recently (see commit fb359fc981f048328bee206fbcf69f2218ae1ee0). @Shreeshrii, does the latest version work for you, or are there issues left?  Otherwise we abort with the message `DotProductAVX can't be used on Android`. Tested on macOS Sierra 10.12.6 `Apple LLVM version 8.1.0 (clang-802.0.42)` and Alpine Linux 3.3 `gcc (Alpine 5.3.0) 5.3.0`.  Before you submit an issue, please review [the guidelines for this repository](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md).

Please report an issue only for a BUG, not for asking questions.

Note that it will be much easier for us to fix the issue if a test case that
reproduces the problem is provided. Ideally this test case should not have any
external dependencies. Provide a copy of the image or link to files for the test case.

Please delete this text and fill in the template below. 

------------------------

### Environment

* **Tesseract Version**: 
```
tesseract 3.04.01
 leptonica-1.73
  libgif 5.1.2 : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.4 : libopenjp2 2.1.0
```

* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
(Install it from ubuntu apt. `sudo apt install tesseract-ocr`)

* **Platform**: 
```
Linux jeneser-X555LF 4.10.0-33-generic #37~16.04.1-Ubuntu SMP Fri Aug 11 14:07:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
```

### Current Behavior:
When run the following command. An error has occurred.
```
cntraining hpu.font.exp0.tr
```
BUT, continue running commands, all is successfully.

My console:
```
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ tesseract hpu.font.exp0.tif hpu.font.exp0 box.train
Tesseract Open Source OCR Engine v3.04.01 with Leptonica
Page 1
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 2
Empty page!!
Page 3
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 4
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 5
Empty page!!
Page 6
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 7
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 2 words
Page 8
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 9
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 10
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 11
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 12
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 13
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
   Leaving 2 unlabelled blobs in 0 words.
Generated training data for 1 words
Page 14
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 15
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 16
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 17
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 18
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 19
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 20
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 21
FAIL!
APPLY_BOXES: boxfile line 1/q ((0,0),(15,20)): FAILURE! Couldn't find a matching blob
FAIL!
APPLY_BOXES: boxfile line 2/y ((15,0),(30,20)): FAILURE! Couldn't find a matching blob
FAIL!
APPLY_BOXES: boxfile line 3/j ((30,0),(45,20)): FAILURE! Couldn't find a matching blob
FAIL!
APPLY_BOXES: boxfile line 4/h ((45,0),(60,20)): FAILURE! Couldn't find a matching blob
APPLY_BOXES:
   Boxes read from boxfile:       4
   Boxes failed resegmentation:       4
APPLY_BOXES: Unlabelled word at :Bounding box=(0,0)->(60,20)
   Found 0 good blobs.
   1 remaining unlabelled words deleted.
Generated training data for 0 words
Page 22
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 23
FAIL!
APPLY_BOXES: boxfile line 1/h ((3,0),(17,20)): FAILURE! Couldn't find a matching blob
FAIL!
APPLY_BOXES: boxfile line 2/t ((17,0),(31,20)): FAILURE! Couldn't find a matching blob
FAIL!
APPLY_BOXES: boxfile line 3/m ((31,0),(45,20)): FAILURE! Couldn't find a matching blob
FAIL!
APPLY_BOXES: boxfile line 4/X ((45,0),(59,20)): FAILURE! Couldn't find a matching blob
APPLY_BOXES:
   Boxes read from boxfile:       4
   Boxes failed resegmentation:       4
APPLY_BOXES: Unlabelled word at :Bounding box=(3,0)->(60,20)
   Found 0 good blobs.
   1 remaining unlabelled words deleted.
Generated training data for 0 words
Page 24
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
   Leaving 2 unlabelled blobs in 0 words.
Generated training data for 2 words
Page 25
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 26
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 27
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 28
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 29
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 30
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ unicharset_extractor hpu.font.exp0.box
Extracting unicharset from hpu.font.exp0.box
Wrote unicharset file ./unicharset.
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mftraining -F font_properties -U unicharset -O hpu.unicharset hpu.font.exp0.tr
Warning: No shape table file present: shapetable
Failed to load font_properties from font_properties
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mftraining -F font_properties -U unicharset -O hpu.unicharset hpu.font.exp0.tr
Warning: No shape table file present: shapetable
Reading hpu.font.exp0.tr ...
Flat shape table summary: Number of shapes = 45 max unichars = 1 number with multiple unichars = 0
Warning: no protos/configs for Joined in CreateIntTemplates()
Warning: no protos/configs for |Broken|0|1 in CreateIntTemplates()
Warning: no protos/configs for j in CreateIntTemplates()
Done!
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ cntraining hpu.font.exp0.tr
Reading hpu.font.exp0.tr ...
Clustering ...
Clustering error: Matrix inverse failed with error 1.44922

Writing normproto ...
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ cntraining hpu.font.exp0.tr
Reading hpu.font.exp0.tr ...
Clustering ...
Clustering error: Matrix inverse failed with error 1.44922

Writing normproto ...
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mv normproto hpu.normproto
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mv inttemp hpu.inttemp
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mv pffmtable hpu.pffmtable
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mv shapetable hpu.shapetable
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ combine_tessdata hpu.
Combining tessdata files
TessdataManager combined tesseract data files.
Offset for type  0 (hpu.config                ) is -1
Offset for type  1 (hpu.unicharset            ) is 140
Offset for type  2 (hpu.unicharambigs         ) is -1
Offset for type  3 (hpu.inttemp               ) is 2644
Offset for type  4 (hpu.pffmtable             ) is 331290
Offset for type  5 (hpu.normproto             ) is 331653
Offset for type  6 (hpu.punc-dawg             ) is -1
Offset for type  7 (hpu.word-dawg             ) is -1
Offset for type  8 (hpu.number-dawg           ) is -1
Offset for type  9 (hpu.freq-dawg             ) is -1
Offset for type 10 (hpu.fixed-length-dawgs    ) is -1
Offset for type 11 (hpu.cube-unicharset       ) is -1
Offset for type 12 (hpu.cube-word-dawg        ) is -1
Offset for type 13 (hpu.shapetable            ) is 337236
Offset for type 14 (hpu.bigram-dawg           ) is -1
Offset for type 15 (hpu.unambig-dawg          ) is -1
Offset for type 16 (hpu.params-model          ) is -1
Output hpu.traineddata created successfully.
```

### Expected Behavior:

### Suggested Fix:

Thanks! duplicate of #771 
> What language are you trying to train?

I want to re-train tesseract for a specific language. It contains `numbers` and `English letters`.
like: 

![30](https://user-images.githubusercontent.com/15034042/30143429-4d3e376c-93b8-11e7-9f7e-1cf8fa087247.jpeg)

> Have you checked whether new trained data is available for it in teesara
repository?

Yes, the new trained data is *available*.

data:
[hpu.traineddata.zip](https://github.com/tesseract-ocr/tesseract/files/1283315/hpu.traineddata.zip)

> You should try with a newer version of tesseract. Look for tesseract OCR
ppa by alex.

Yep, i will try it.
  See this comment https://github.com/tesseract-ocr/tesseract/issues/781#issuecomment-323304593  We're encountering the same issue. Neither the `A` nor the `1` are extracted.
```
$ tesseract -l best/eng --oem 1 --psm 11 sparse.png sparse
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
$ cat sparse.txt
A test file

More Text

Grouping Test

Next Group

And now a paragraph.
```
Document
![sparse](https://user-images.githubusercontent.com/889237/30187766-39f49f4a-93e8-11e7-9cb7-290a752dfc6c.png)
 I would suggest you use OpenCV to detect the characters and use --PSM (character) only for the OCR. 

I archive great improve by using this additional step. If you feed the whole page in, as someone indicated above, it cannot generate the correct OCR results.  @hoangtocdo90 zmwang is probably talking about the `psm_single_char` option, `--psm 10`.  I tried compiling by following the instruction on https://github.com/tesseract-ocr/tesseract/wiki/Compiling.

When I run the command cmake ..
it gave me an error message: cppan command '0' not found, hence the solution (.sln) file was not created.

Please help.
------------------------

### Environment

* **Tesseract Version**: 4.00
* **Commit Number**: 
* **Platform**: Windows *8 64 bit

### Current Behavior:
Getting error message cppan command '0' not found.

![image](https://user-images.githubusercontent.com/31610445/30013790-be347f3c-9172-11e7-920a-047bdf5221fe.png)
Error log attached.
[CMAKE.zip](https://github.com/tesseract-ocr/tesseract/files/1273783/CMAKE.zip)



### Expected Behavior:

### Suggested Fix:
 Hi,

It is solved. Apparently I forgot to set the PATH for CMAKE and GIT in the System Environment Variables.
I set the path and ran the command again.

Cheers.
  https://github.com/tesseract-ocr/tesseract/tree/master/testing

hebrew-nikud-genesis-1-2.png contains te'amim which Tesseract's heb.traineddata does not support.
https://github.com/tesseract-ocr/langdata/issues/82
 hebtypo.jpg seems to be taken from a copyrighted book.  hi,

i try my first steps on tesseract. i have installed in on my macbook and a windows 7 32 bit machine via virtualbox. 

i want to recognize adresses from envelopes. so i made a picture (jpg and tif) and started the progress. on mac everything works fine - recognizing is very great and in the output file the adress is as expected. on windows the output file is in a single line.

e.g.

input:
name name
street number
code city

output mac is as input

output on windows:
name namestreet numbercode city

i tried all -psm modes with no effect i wanted. works. strange - but it works. thanks  
------------------------

### Environment

* **Tesseract Version**: Tesseract 4.00
* **Platform**:  Ubuntu 14.04.5 LTS (GNU/Linux 3.13.0-129-generic x86_64) 

When I use the tutorial [https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#fine-tuning-for-%C2%B1-a-few-characters] to fine tune the model
my command is 
```
training/tesstrain.sh  \
   --fonts_dir /usr/share/fonts \
  --lang chi_sim  \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --langdata_dir ../langdata \
  --tessdata_dir /home/hs/tessdata/tessdata  \
  --output_dir ../tesstutorial/chi_sim
```
I found that it print out as below in "Phase I: Generating training images":

` training/text2image --fontconfig_tmpdir=/tmp/font_tmp.k2AbBhbk8p --fonts_dir=/usr/share/fonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.4UpMo5R9vj/chi_sim/chi_sim.KaiTi_Normal.exp0 --max_pages=3 --font=KaiTi Normal --text=../langdata/chi_sim/chi_sim.training_text`

Notice that **--max_pages=3**, so I checked the ".tif" files, finding that the pages number is 3.
 
To my own work, I need more pages for the "tif/box" files, so I try to change the parameter ‚Äú--max_pages‚Äù Ôºàie, --max_pages=6Ôºâ

Instead of run the command above, I try to finish its work step by step. But when I did the "Phase E: Generating lstmf files " there comes out a error which I can't solved:

```
root@super-desk:~/tesseract# api/tesseract /home/hs/tmp/chi_sim.AR_PL_UKai_CN.exp0.tif /home/hs/tmp/chi_sim.AR_PL_UKai_CN.exp0 lstm.train ../langdata/chi_sim/chi_sim.config
read_params_file: Can't open lstm.train
```

I don't know where is the " lstm.train", how can I find it?

Can anyone help me?





 Thank you @Shreeshrii ~  hi i am new on using tesseract
i am using OpenCV text module calling tesseract400.dll

in release mode i am getting "Empty page!!" messages so i did this fix in my local.
it is up to you deciding if it is useful for public.

thank you  Before you submit an issue, please review [the guidelines for this repository](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md).

Please report an issue only for a BUG, not for asking questions.

Note that it will be much easier for us to fix the issue if a test case that
reproduces the problem is provided. Ideally this test case should not have any
external dependencies. Provide a copy of the image or link to files for the test case.

Please delete this text and fill in the template below. 

------------------------

### Environment

* **Tesseract Version**: <!-- compulsory. you must provide your version -->
* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
* **Platform**: <!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->

### Current Behavior:

### Expected Behavior:

### Suggested Fix:
  I built tesseact out of 4.00.00dev. It seems like it has trouble directly reading stdin from ghostscript. Check out the following...

    gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=- demo.pdf -c quit | bin/tesseract stdin demo.ocr -oem 4

then it gives this error:

     Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
     TIFFFillStrip: Invalid strip byte count 0, strip 0.
     Error in pixReadFromTiffStream: line read fail

However if I generate the image first using ghostscript, then pipe the image to the stdin of tesseract, then it works. 

    gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=- demo.pdf -c quit > demo.tif
    cat demo.tif | bin/tesseract stdin demo.ocr -oem 4

 I don't understand what could cause this. Does one or both of the following commands work?

    gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=- demo.pdf -c quit | dd | bin/tesseract stdin demo.ocr -oem 4
    gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=- demo.pdf -c quit | dd bs=4096 | bin/tesseract stdin demo.ocr -oem 4

If yes, the problem could be caused by partial reads in Tesseract (less bytes read than requested). @stweil 

both failed

    gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=- demo.pdf -c quit | dd | bin/tesseract stdin demo.ocr -oem 4
    Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
    391+11 records in
    395+1 records out
    202521 bytes (203 kB) copied, 0.210738 s, 961 kB/s
    TIFFFillStrip: Invalid strip byte count 0, strip 0.
    Error in pixReadFromTiffStream: line read fail

    gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=- demo.pdf -c quit | dd bs=4096 | bin/tesseract stdin demo.ocr -oem 4
    Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
    46+12 records in
    46+12 records out
    202521 bytes (203 kB) copied, 0.247508 s, 818 kB/s
    TIFFFillStrip: Invalid strip byte count 0, strip 0.
    Error in pixReadFromTiffStream: line read fail


 Try running Tesseract under strace and see where things first become different.

```
gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=- demo.pdf -c quit  |strace  bin/tesseract stdin demo.ocr -oem 4
cat demo.tif | strace bin/tesseract stdin demo.ocr -oem 4
```
 @Shreeshrii 

    ./configure: line 4188: syntax error near unexpected token `-mavx,'
    ./configure: line 4188: `AX_CHECK_COMPILE_FLAG(-mavx, avx=true, avx=false)'
 @jbreiden Following is the diff right before the two processes write to stdout/stderr

```bash
< munmap(0x7fe1e9661000, 4096)            = 0
< brk(0)                                  = 0x2367000
< brk(0x238d000)                          = 0x238d000
< write(2, "TIFFFillStrip: ", 15TIFFFillStrip: )         = 15
< write(2, "Invalid strip byte count 0, stri"..., 35Invalid strip byte count 0, strip 0) = 35
< write(2, ".\n", 2.
< )                      = 2
< write(2, "Error in pixReadFromTiffStream: "..., 47Error in pixReadFromTiffStream: line read fail
< ) = 47
< close(3)                                = 0
< gettid()                                = 23463
...
```

```bash
> munmap(0x7f49e88ad000, 4096)            = 0
> brk(0)                                  = 0x1c2a000
> brk(0x1c50000)                          = 0x1c50000
> write(2, "Page 1\n", 7Page 1
> )                 = 7
> gettid()                                = 23501
> brk(0)                                  = 0x1c50000
> brk(0x1cc1000)                          = 0x1cc1000
> gettid()                                = 23501
...
``` The interesting part of the diff is expected earlier. Calls with file handle 0 (STDIN) are especially interesting. Can you upload both strace outputs?  Empty lines in text output are needed to separate paragraphs,
but there should not be an empty line at the end of the text.

Signed-off-by: Stefan Weil <sw@weilnetz.de> Related: https://github.com/tesseract-ocr/tesseract/pull/1088/commits/6773e8b909d7409f7434db67da6dff56090a7eda. @Shreeshrii, that commit is no longer needed after this pull request.  Hi, 
I have compiled tesseract 4.00.0 alpha using vs 2015 and now I want to compile text module in opencv I have got an error at : 

at line 164 of tesseract/unichar.h error 3646 'UTF32ToUtf8 'string' : unknown override specifier

[Another user](http://answers.opencv.org/question/172513/string-name-type-error-on-make-for-opencv-320330-with-tesseract/) got this message 
tesseract/unichar.h:164:10: error: ‚Äòstring‚Äô does not name a type static string UTF32ToUTF8(const std::vector<char32>& str32); 

If I replace [line ](https://github.com/tesseract-ocr/tesseract/blob/aee910a7bfcbe0366806b68dc7f20535764c06d4/ccutil/unichar.h#L164)

static string UTF32ToUTF8(const std::vector<char32>& str32);

with 

static std::string UTF32ToUTF8(const std::vector<char32>& str32);

problem is solved for vs2015.

Is it an opencv problem or a tesseract problem ?
 https://github.com/tesseract-ocr/tesseract/issues?q=std+string+is:closed @zdenop my mistake : not to read closed issue. thanks you very much   The tests require installation of GoogleTest of course. How should we handle the case of missing GoogleTest when a user calls `make check`? Get GoogleTest automatically? Show some help text? Or accept a failure (current status)? GoogleTest is now a directory in our repo (sub repo). > GoogleTest is now a directory in our repo (sub repo).

Yes, but the submodule `googletest` is not fetched automatically. Therefore I'd prefer that `make check` should at least report the missing submodule and show a help text how to fetch it. The current error message for that case might be confusing for users.  prevents "Empty page!!" messages hi i am new on using tesseract
i am using OpenCV text module calling tesseract305.dll

in release mode i am getting "Empty page!!" messages so i did this fix in my local.
it is up to you deciding if it is useful for public.

thank you   ### Environment

* **Tesseract Version**: 4.0<!-- compulsory. you must provide your version -->
* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
* **Platform**: <!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->
windows 64bit vs2015 community

2 error on build
1. in validator.cpp,
error c2039: back_inserter is not member of std and etc...
i solve it adding #include <iterator> in validator.cpp but i'm not sure it's enough.( build is working)

2. text2image project
if I build solution with text2image in Training Tools,
there are so many error
one of them:
variable "CPPAN_SYMBOL_IMPORT" is not name...blahblah <- i'm not english user 
in many header file on text2image

so i build solution excluding text2image. and it wokr. but i hope i can build it together

 Thank you for re-comment. I did it at that time but it's not working.
maybe my environment is something wrong.. retry after time.

  The option `--disable-openmp` works for Windows with Mingw-w64, too. You don't need it neither for Linux nor for Windows, because it is possible to tell OpenMP not to create any threads:

    export OMP_THREAD_LIMIT=1
    tesseract ...

or

    OMP_THREAD_LIMIT=1 tesseract ...

You can help improving the Wiki by adding any important information which is currently missing.
  


### Environment

* **Tesseract Version**: tesseract-ocr-setup-4.0.0-alpha.20170804.exe - Latin.traineddata from best
* **Platform**: Win10 64bit

### Current Behavior:
Tesseract skippes words when doing OCR

OCR-Result: USA

### Expected Behavior:

OCR-Result: USA/NORDKOREA

### Suggested Fix:

not to skip words

---
Today I saw multiple times, that tesseract skips words, sometimes in the middle of a paragraph.

i.e. tesseract test/1502433849760_1.png test/1502433849760 -l Latin

![1502433849760_imageprocessedwithmarks](https://user-images.githubusercontent.com/30631253/29271637-bbce3160-80fc-11e7-924e-bdc5f89cca34.png)

![1502433849760_1](https://user-images.githubusercontent.com/30631253/29271612-9ac83362-80fc-11e7-9e84-aa3c650f3618.png)
[1502433849760.txt](https://github.com/tesseract-ocr/tesseract/files/1222190/1502433849760.txt)

![1502433849760_screen](https://user-images.githubusercontent.com/30631253/29271704-0fb2feaa-80fd-11e7-87bc-97a53dc5c583.jpg)
 Known problem for all langs/scripts
https://github.com/tesseract-ocr/tesseract/issues/681 In your case the problem is probably in the layout analysis stage. I've another example:

tesseract test/1502442621178.png test/1502442621178 -l Latin

Here a word in the middle of the sentence is skipped.

![1502442621178_screen](https://user-images.githubusercontent.com/30631253/29272519-b46c3aee-8100-11e7-9ad3-734e3a1b46dc.jpg)

![1502442621178](https://user-images.githubusercontent.com/30631253/29272525-b9762536-8100-11e7-8d82-0961dd49663b.png)

[1502442621178.txt](https://github.com/tesseract-ocr/tesseract/files/1222269/1502442621178.txt)

 Try cutting the non-text areas with gimp and retest. Only the red areas are processed by tesseract, they are written to separate png-files. (I've uploaded the separate files as well and the resulting output-files) The interesting thing is, two similar frames were processed without problems:

![1502434118849](https://user-images.githubusercontent.com/30631253/29273266-f7bbc636-8103-11e7-8efb-eb21a9e1fca6.jpg)

![1502431789149](https://user-images.githubusercontent.com/30631253/29273306-14a66bf2-8104-11e7-9844-a47bfab79d4c.jpg)

 >Here a word in the middle of the sentence is skipped.

Which word?

Might be related to #681 in this case. P√∂llan -  the √∂ exists in unicharset

Thank you for the link to #681 Try to debug with stopper_debug_level=2

https://github.com/tesseract-ocr/tesseract/blob/3ec11bd37a56/ccmain/linerec.cpp#L293

 Best choice certainty=-2.96366, space=-0.206939, scaled=-20.7456, final=-20.7456
 : P√∂llan : R=11.9817, C=-2.96366, F=1, Perm=2, xht=[0,3.40282e+038], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM
str	P	√∂	l	l	a	n
state:	1 	1 	1 	1 	1 	1 
C	-0.237	-2.964	-0.232	-0.209	-0.192	-0.199
Deleting word with certainty -20.7456
 : P√∂llan : R=11.9817, C=-20.7456, F=1, Perm=2, xht=[0,3.40282e+038], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM
str	P	√∂	l	l	a	n
state:	1 	1 	1 	1 	1 	1 
C	-0.237	-2.964	-0.232	-0.209	-0.192	-0.199

[test.txt](https://github.com/tesseract-ocr/tesseract/files/1222577/test.txt)
 Best choice certainty=-0.106016, space=-2.97242, scaled=-20.8069, final=-20.8069
 : USA : R=2.24336, C=-0.106016, F=1, Perm=8, xht=[0,3.40282e+038], ambig=0
pos	NORM	NORM	NORM
str	U	S	A
state:	1 	1 	1 
C	-0.090	-0.086	-0.106
Best choice certainty=-0.229416, space=-2.97242, scaled=-20.8069, final=-20.8069
 : /NORDKOREA : R=16.2872, C=-0.229416, F=1, Perm=2, xht=[0,3.40282e+038], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM
str	/	N	O	R	D	K	O	R	E	A
state:	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 
C	-0.223	-0.202	-0.207	-0.201	-0.192	-0.208	-0.197	-0.193	-0.229	-0.228
Deleting word with certainty -20.8069
 : /NORDKOREA : R=16.2872, C=-20.8069, F=1, Perm=2, xht=[0,3.40282e+038], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM
str	/	N	O	R	D	K	O	R	E	A
state:	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 
C	-0.223	-0.202	-0.207	-0.201	-0.192	-0.208	-0.197	-0.193	-0.229	-0.228

[output_1502433849760_1.txt](https://github.com/tesseract-ocr/tesseract/files/1222585/output_1502433849760_1.txt)
 So it does recognize them, but still decides to drop them... 'P√∂llan' is dropped because it's not in the dictionary and the '√∂' has low certainty.
'/NORDKOREA' is dropped because it's not in the dictionary and has low space certainty.
 'USA' shares the same low space certainty with '/NORDKOREA' but escapes from punishment because it's in the dictionary. After applying my [patch](https://github.com/tesseract-ocr/tesseract/issues/681#issuecomment-322433100):
'/NORDKOREA' ('USA /NORDKOREA')
and
'P√∂llan'

are recognized in the final text output.

All other words are recognized the same as before. Thank you to both of you, your help is much appreciated! I'm on holiday till end of next week then I'll try to compile a windows version with the changes you suggested and test it. >I'll try to compile a windows version with the changes you suggested and test it.

Did you try my suggestion? I'm still on it. 
It takes me some time as I'm used to Java but I only used C/C++/... at University, which is quite some time ago. Then some other projects took my time.
I've already installed Visual Studio 2017 and the Git client.
I'll keep you updated. 
 I've been able to compile it now and starting a test run against 50k frames. looks good Tried it as well with 64bit but there I get some errors but I don't think the problem is the fix:

E:\Tesseract-OCR4.0ab1>tesseract test/1502442621178.png stdout --oem 1 -l Latin
Warning. Invalid resolution 0 dpi. Using 70 instead.
Estimating resolution as 726
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made

---
x86 output:
E:\Tesseract-OCR4.0ab1>tesseract test/1502442621178.png stdout --oem 1 -l Latin
Warning. Invalid resolution 0 dpi. Using 70 instead.
Estimating resolution as 726
PATERNION

21-J√§hriger geriet mit seinem
Auto in P√∂llan zu weit in die
Fahrbahnmitte. Er rammte
das Auto eines 62-J√§hrigen.

Der Beifahrer des 21-J√§hrigen
wurde schwer verletzt.

---

I'll try to find the error and keep you updated.
 That one is related to image processing. Seems like a bug on (Windows?) 64 bit environment.

Please open a new issue for that.  ÂΩìÂõæÁâáÂè™ÊúâÂçïÂ≠ó‰∏≠ÊñáÊó∂ÂÄô‰∏ÄËà¨Ê≤°Ê≥ïËØÜÂà´~
Before you submit an issue, please review [the guidelines for this repository](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md).

Please report an issue only for a BUG, not for asking questions.

Note that it will be much easier for us to fix the issue if a test case that
reproduces the problem is provided. Ideally this test case should not have any
external dependencies. Provide a copy of the image or link to files for the test case.

Please delete this text and fill in the template below. 

------------------------

### Environment

* **Tesseract Version**: <!-- compulsory. you must provide your version -->
* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
* **Platform**: <!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->

### Current Behavior:

### Expected Behavior:

### Suggested Fix:
 ËØ∑ÁªôÂá∫‰∏Ä‰∫õÈáçÁé∞ËµÑÊñôÔºåÊØîÂ¶ÇÔºöÈúÄË¶ÅËØÜÂà´ÁöÑÈÇ£‰∏™ÂçïÂ≠óÂõæÁâáÔºå‰Ω†‰ΩøÁî®ÁöÑtesseractÁâàÊú¨ÂíåtraneddataÔºå‰ª•Âèä‰ΩøÁî®Âú∫ÊôØ„ÄÇ‰Ω†ÊòØÁî®ÁºñËØëÂ•ΩÁöÑ‰∫åËøõÂà∂tesseractÂëΩ‰ª§ËøòÊòØ‰ΩøÁî®APIÂú®‰Ω†ÁöÑÁ®ãÂ∫èÈáåËØÜÂà´ÔºåÂ¶ÇÊûú‰ΩøÁî®ÁöÑÊòØÂëΩ‰ª§ÔºåËØ∑Ë¥¥‰∏ä‰Ω†ÁöÑÂëΩ‰ª§Ë°åÂèÇÊï∞ÔºåÂ¶ÇÊûúÊòØ‰ΩøÁî®ÁöÑSDKÔºåËØ∑Ë¥¥‰∏ä‰ª£Á†Å„ÄÇÁõÆÂâçÁöÑmasterÁâàÊú¨Êó†ËÆ∫ÊòØÂú®ÂëΩ‰ª§Ë°å‰∏ãËøòÊòØSDKÊ®°Âºè‰∏ãÈÉΩËøêË°åÁöÑÊå∫Â•Ω„ÄÇ Â¶ÇÊûúÊòØ4.0ÁâàÁöÑÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑ÔºåËØ∑ËØï‰∏Ä‰∏ãÔºö`tesseract input.tif output -psm 8 -oem 1` Translation via Google Translate

@yhfwww commented 

>When the picture is only a single word when the Chinese generally can not identify

@huanpenglee commented

>Please give some reproduction of the information, such as: need to identify that word picture, you use the tesseract version and traneddata, and use the scene. Do you use the compiled binary tesseract command or use the API to identify in your program, if you are using the command, please paste your command line parameters, if it is using the SDK, please paste the code. The current version of the master, whether it is in the command line or SDK mode are running very good.
If it is version 4.0 of the command line tool, please try: tesseract input.tif output -psm 8 -oem 1


 ÂèØ‰ª•ÂèÇÊï∞ËÆ≠ÁªÉÁöÑÊñáÊ°£ÔºåÂÅöËá™Â∑±ÁöÑËÆ≠ÁªÉÂ∫ìÊù•Â¢ûÂº∫ËØÜÂà´ËÉΩÂäõ„ÄÇ



hanni_xu
 
Âèë‰ª∂‰∫∫Ôºö yhf
ÂèëÈÄÅÊó∂Èó¥Ôºö 2017-08-14 09:11
Êî∂‰ª∂‰∫∫Ôºö tesseract-ocr/tesseract
ÊäÑÈÄÅÔºö Subscribed
‰∏ªÈ¢òÔºö [tesseract-ocr/tesseract] ÂΩìÂõæÁâáÂè™ÊúâÂçïÂ≠ó‰∏≠ÊñáÊó∂ÂÄô‰∏ÄËà¨Ê≤°Ê≥ïËØÜÂà´ (#1079)
ÂΩìÂõæÁâáÂè™ÊúâÂçïÂ≠ó‰∏≠ÊñáÊó∂ÂÄô‰∏ÄËà¨Ê≤°Ê≥ïËØÜÂà´~
Before you submit an issue, please review the guidelines for this repository.
Please report an issue only for a BUG, not for asking questions.
Note that it will be much easier for us to fix the issue if a test case that
reproduces the problem is provided. Ideally this test case should not have any
external dependencies. Provide a copy of the image or link to files for the test case.
Please delete this text and fill in the template below.


Environment
Tesseract Version: 
Commit Number: 
Platform: 
Current Behavior:
Expected Behavior:
Suggested Fix:
‚Äî
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub, or mute the thread.
  The original image
https://image.ibb.co/fEkAma/WX20170813_165113_2x.png

If there is no -l arg, the result is look like below.

> tesseract WX20170813_165113_2x.png stdout
IH640 done
Ô¨ÅÔ¨ÅiaiÔ¨ÇÔ¨Åma done
iii√©imÔ¨ÅiiÔ¨ÅÔ¨Å done
Ô¨Ålm: done
Ô¨ÅEEE done

> tesseract WX20170813_165113_2x.png stdout -l chi_sim
ÂõæÁâá640 done
ÊØèÈ°µËÆ∞ÂΩïÊï∞ÂèØÈÖç done
ÈÄâÊã©ÂüéÂ∏ÇÊä•Èîô done
Âú∞ÂõæÊ£ÄÁ¥¢ done
ÂºπÂõ°ÂÆΩÂ∫¶ done

Another problem is the charactor "Âõ°" in "ÂºπÂõ°ÂÆΩÂ∫¶"Ôºåactually it is "Á™ó". tesseract WX20170813_165113_2x.png stdout -l chi_sim
read_params_file: parameter not found:

tesseract 3.04.00
 leptonica-1.72
  libgif 4.1.6(?) : libjpeg 6b (libjpeg-turbo 1.2.90) : libpng 1.5.13 : libtiff 4.0.3 : zlib 1.2.7 : libwebp 0.3.0

Do I need to upgrade tessdata? @Shreeshrii  Ok, Thanks.  I've got error 'mgr_.Init(traineddata_path.c_str()):Error:Assert failed:in file ../../../../lstm/lstmtrainer.h, line 110' when trying to run a command below. Can somebody help me with this?
All paths are correct.
version 4.0

c:\Temp\tesseract-master\tesseract-master\api>lstmtraining --model_output C:/Temp/engbest/model --continue_from C:/Temp/engbest/eng.lstm --traineddata C:/Temp/engbest/eng.traineddata --old_traineddata C:/Temp/tesseract-master/tesseract-master/tessdata/eng.traineddata --train_listfile C:/Temp/engbest/eng.training_files.txt --max_iterations 3600 Do you put the traineddate in the write directory? 
--traineddata C:/Temp/engbest/eng.traineddata
Please check that if there is eng.traineddata in C:/Temp/engbest/? If no, copy the eng.traineddata to C:/Temp/engbest/. 

Then, I think this will be resolved. I have met the same problem, and this is my resolution. It helped. Thanks. But than I got 

Loaded file C:/Temp/engbest/eng.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Code range changed from 105 to 105!!
Failed to continue from: C:/Temp/engbest/eng.lstm

stephenyong2005 Did you see error like this in your case? Sorry, I do not got such a error like you mentioned, but i got another error. By the way, I am a new user of tesseract. Do you know how to generate a lstm file? Thanks.

2017Âπ¥8Êúà13Êó• 16:09Ôºåiuriigalaida <notifications@github.com>ÂÜôÈÅìÔºö

It helped. Thanks. But than I got

Loaded file C:/Temp/engbest/eng.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Code range changed from 105 to 105!!
Failed to continue from: C:/Temp/engbest/eng.lstm

stephenyong2005 Did you see error like this in your case?

‚Äî
You are receiving this because you commented.
Reply to this email directly, view it on GitHub<https://github.com/tesseract-ocr/tesseract/issues/1075#issuecomment-322064363>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AJBNQGx7L5w2ALkdkGuuWtd3SzwqXgI2ks5sX1fwgaJpZM4O0iiS>.

 I use v4.0.0. Compile from the source code instead of git. OS is ubuntu 17.04. I have finished the demo procedure in the wiki web page of training tesseract 4.0 by following the tutorial.

2017Âπ¥8Êúà14Êó• 00:18ÔºåShreeshrii <notifications@github.com>ÂÜôÈÅìÔºö

Are you using the latest source from github for building tesseract? What is your version info, git log info?

‚Äî
You are receiving this because you commented.
Reply to this email directly, view it on GitHub<https://github.com/tesseract-ocr/tesseract/issues/1075#issuecomment-322096544>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AJBNQPaOqYXe8oSSfc6LX8aVtkQ-yNRIks5sX8qFgaJpZM4O0iiS>.

 this is the tesseract wiki homepage:  https://github.com/tesseract-ocr/tesseract/wiki

2017Âπ¥8Êúà14Êó• 00:56ÔºåShreeshrii <notifications@github.com>ÂÜôÈÅìÔºö
> Compile from the source code instead of git.

from where?

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Mon, Aug 14, 2017 at 9:57 AM, stephenyong2005 <notifications@github.com>
wrote:

> I use v4.0.0. Compile from the source code instead of git. OS is ubuntu
> 17.04. I have finished the demo procedure in the wiki web page of training
> tesseract 4.0 by following the tutorial.
>
> 2017Âπ¥8Êúà14Êó• 00:18ÔºåShreeshrii <notifications@github.com>ÂÜôÈÅìÔºö
>
> Are you using the latest source from github for building tesseract? What
> is your version info, git log info?
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub<https://github.com/
> tesseract-ocr/tesseract/issues/1075#issuecomment-322096544>, or mute the
> thread<https://github.com/notifications/unsubscribe-auth/
> AJBNQPaOqYXe8oSSfc6LX8aVtkQ-yNRIks5sX8qFgaJpZM4O0iiS>.
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1075#issuecomment-322097552>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_ozzaFTAJzfednKsAdNPo1yuTOjnJks5sX8yZgaJpZM4O0iiS>
> .
>

‚Äî
You are receiving this because you commented.
Reply to this email directly, view it on GitHub<https://github.com/tesseract-ocr/tesseract/issues/1075#issuecomment-322100290>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AJBNQGHjjAab3USEZ0D4HZKlj1RaZ8f_ks5sX9NqgaJpZM4O0iiS>.

 After I get latest sourses v4 lstmtraining started work but I almost always got errors like 
Encoding of string failed!
Can't encode transcription:
Even if I directly set path to unicharset file. yes. i have 44 new character and I wont to extend english traineddata. Attached my unicharset file. How can I aviod this encoding issues?

 
[eng.zip](https://github.com/tesseract-ocr/tesseract/files/1222246/eng.zip)
 The command should use tprintf() with a meaningful message and exit(), not assert.  ### Environment

* **Tesseract Version**: tesseract 4.00.00alpha<!-- compulsory. you must provide your version -->
* **Commit Number**: 8e55e52be749b3faccca8ae41abdc0e3d3c7f887<!-- optional. if known - specify commit used, if built from source -->
* **Platform**: Ubuntu 16.04.1<!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->

### Current Behavior:
Method WordFontAttributes returns null if using tesseract 4.00.00alpha with 4.00 tessdata, but it returns font name if using tesseract 4.00.00alpha with 3.04.00 tessdata. The test image link is [eurotext.tif](https://github.com/sirfz/tesserocr/blob/master/tests/eurotext.tif)
I first met this problem when I use tesserocr [tesserocr#68] .(https://github.com/sirfz/tesserocr/issues/68)
### Expected Behavior:
With method WordFontAttributes we can get correct font attributes of recognized words.

 The new LSTM engine does not support this feature and probably won't support it any time soon. Is there an alternative way to get font sizing etc? Do you mean that just this method won't be supported, or the feature in general?  >Is there an alternative way to get font sizing etc?

You can still use --oem 0 with traineddata from here: https://github.com/tesseract-ocr/tessdata.
Note that the traineddata in the 'best' folder won't work with --oem 0.
 >Do you mean that just this method won't be supported, or the feature in general?

I have reasons to believe that the new LSTM engine is unlikely to have a feature that includes font identification (name and properties like is_bold) in the near future.

Important note: I'm a contributer from the community, and the main developer not always shares all his plans for upcoming release(s) with the community. Thanks for the reply! It looks like the old ocr engine is going to be removed, though (issue #707)... And does using `OcrEngineMode 0` mean the behaviour is the same as v3?

What I'm getting to is:
1. I need to be able to extract font size information (font names aren't so useful) - is there any way at all of doing so with LSTM/v4?
2. If I use `OcrEngineMode 0` to be able to get this info, will that be removed from v4 at a later date?
3. Is there any advantage to using v4 with `OcrEngineMode 0` vs v3.05?

Thanks again for the help! >It looks like the old ocr engine is going to be removed, though (issue #707)... 

It's not known when exactly it will be removed. Until then you can still use it.

>And does using OcrEngineMode 0 mean the behaviour is the same as v3?

It's basically the same as 3.05.01.

>I need to be able to extract font size information (font names aren't so useful) - is there any way at all of doing so with LSTM/v4?

There is no method in the API to get font sizes for the lstm engine.

>If I use OcrEngineMode 0 to be able to get this info, will that be removed from v4 at a later date?

Probably yes.

>Is there any advantage to using v4 with OcrEngineMode 0 vs v3.05?

The accuracy should be the same. The relative font size for a textline can be estimated by calculating the xheight of the line and compare it 
to the median xheight of the other textlines in the page.  

 Ok, thanks for the info :+1:  @phildrip, 

I looked at the relevant code again, and I think the font size functionality (but not font name and properties like is_bold) can be restored when using the lstm engine.

I will provide further details (and probably send a PR) in the upcoming days.  That's great news, thanks! ```
// Returns the font attributes of the current word. If iterating at a higher
// level object than words, eg textlines, then this will return the
// attributes of the first word in that textline.
// The actual return value is a string representing a font name. It points
// to an internal table and SHOULD NOT BE DELETED. Lifespan is the same as
// the iterator itself, ie rendered invalid by various members of
// TessBaseAPI, including Init, SetImage, End or deleting the TessBaseAPI.
// Pointsize is returned in printers points (1/72 inch.)
const char* LTRResultIterator::WordFontAttributes(bool* is_bold,
                                                  bool* is_italic,
                                                  bool* is_underlined,
                                                  bool* is_monospace,
                                                  bool* is_serif,
                                                  bool* is_smallcaps,
                                                  int* pointsize,
                                                  int* font_id) const {
  if (it_->word() == NULL) return NULL;  // Already at the end!
  if (it_->word()->fontinfo == NULL) {
    *font_id = -1;
    return NULL;  // No font information.
  }
  const FontInfo& font_info = *it_->word()->fontinfo;
  *font_id = font_info.universal_id;
  *is_bold = font_info.is_bold();
  *is_italic = font_info.is_italic();
  *is_underlined = false;  // TODO(rays) fix this!
  *is_monospace = font_info.is_fixed_pitch();
  *is_serif = font_info.is_serif();
  *is_smallcaps = it_->word()->small_caps;
  float row_height = it_->row()->row->x_height() +
      it_->row()->row->ascenders() - it_->row()->row->descenders();
  // Convert from pixels to printers points.
  *pointsize = scaled_yres_ > 0
      ? static_cast<int>(row_height * kPointsPerInch / scaled_yres_ + 0.5)
      : 0;

  return font_info.name;
}
```

The problem:
```
if (it_->word()->fontinfo == NULL) {
    *font_id = -1;
    return NULL;  // No font information.
}
```

With the LSTM engine the `it_->word()->fontinfo` will always be `NULL`.
So pointsize has no chance to be calculated.

pointsize is calculated based on row (=line) height. pointsize is the font size in points of the **line**, so it should not be in **Word**FontAttributes().

There is another function where you can get row height.
```
void LTRResultIterator::RowAttributes(float* row_height, float* descenders,
                                      float* ascenders) const {
  *row_height = it_->row()->row->x_height() + it_->row()->row->ascenders() -
                it_->row()->row->descenders();
  *descenders = it_->row()->row->descenders();
  *ascenders = it_->row()->row->ascenders();
}
```

I think pointsize calculation should be moved into this function. @zdenop, @stweil 
Do you have any comment? Although my current main focus is getting the text from images, there are also important use cases where text attributes are important as well. As I understand your comments, currently the new LSTM recognizer does not support the method `WordFontAttributes`, so it is not possible to get text attributes with that recognizer. Adding support for the font size recognition with LSTM seems to be feasible, but other text attributes like for example bold or italic are desirable, too. Thank you for this clarification, Ray. >Thank you for this clarification, Ray.

+1

Ray,
In the meantime, can I fix the font size issue?
 https://github.com/tesseract-ocr/tesseract/issues/1074#issuecomment-326762911
 >Yes of course. Just re-order the code in WordFontAttributes.

That was my first thought, but it seems to give you font size in the line level, while the name of the method  implies otherwise (**Word**FontAttributese), so I suggested to move pointsize to the **Row**Attributes() method. +1  I tried to train tesseract v4.0 and got 'combine_lang_model not found' error. This code was added 4 days ago so I tried to build latest master and got '.cppan/storage/etc/static/generate.cmake:106 (message):
  cppan command '0' not found '. Can somone build and share latest tesseract binaries for Windows. Thanks in advance.  Yes. It worked. Thanks a lot ShreeDevi!  Hi, I want to finetune tesseract4.0 following this: [https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#fine-tuning-for--a-few-characters](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#fine-tuning-for--a-few-characters)
but when i run the following code:

```
scripts/tesstrain.sh --fonts_dir /usr/share/fonts --lang eng --linedata_only \
    --fontlist "DejaVu Sans" -noextract_font_properties --langdata_dir ./langdata \
    --tessdata_dir ./tessdata --output_dir ~/tesstutorial/trainplusminus
scripts/tesstrain.sh --fonts_dir /usr/share/fonts --lang eng --linedata_only \
    --noextract_font_properties --langdata_dir ./langdata \
    --tessdata_dir ./tessdata \
    --fontlist "DejaVu Sans" --output_dir ~/tesstutorial/evalplusminus

combine_tessdata -e baseline/eng.traineddata \
    ~/tesstutorial/trainplusminus/eng.lstm
lstmtraining --model_output ~/tesstutorial/trainplusminus/plusminus \
    --continue_from ~/tesstutorial/trainplusminus/eng.lstm\
    --traineddata ~/tesstutorial/trainplusminus/eng/eng.traineddata \
    --old_traineddata baseline/eng.traineddata \
    --train_listfile ~/tesstutorial/trainplusminus/eng.training_files.txt \
    --max_iterations 3600

```
I got this error:
```
14:bigram-dawg:size=16109842, offset=3221531
17:lstm:size=5390718, offset=19331373
18:lstm-punc-dawg:size=4322, offset=24722091
19:lstm-word-dawg:size=7143578, offset=24726413
20:lstm-number-dawg:size=3530, offset=31869991
23:version:size=9, offset=31873521
Loaded file ~/tesstutorial/trainplusminus/eng.lstm, unpacking...
Code range changed from 461 to 461!!
Failed to continue from: ~/tesstutorial/trainplusminus/eng.lstm
```

update:
when i remove   `--old_traineddata baseline/eng.traineddata ` like this it will work:
```
lstmtraining --model_output ~/tesstutorial/trainplusminus/plusminus \
    --continue_from ~/tesstutorial/trainplusminus/eng.lstm\
    --traineddata ~/tesstutorial/trainplusminus/eng/eng.traineddata \
    --train_listfile ~/tesstutorial/trainplusminus/eng.training_files.txt \
    --max_iterations 3600
```
but got lots of this waring:
```
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from /root/tesstutorial/trainplusminus/eng.lstm
Loaded 85/85 pages (1-85) of document /root/tesstutorial/trainplusminus/eng.DejaVu_Sans.exp0.lstmf
Encoding of string failed! Failure bytes: ffffffc2 ffffffb1 36 35 ffffffc2 ffffffb0 43 2c 20 41 45 52 4f 4d 45 58 49 43 4f 20 53 55 4d 4d 4f 4e 45 52 20 3d 20 28 31 39 36 31 29 20 41 62 6f 75 74 20 57 41 53 48 49 4e 47 20 4d 69 73 73 6f 75 72 69
Can't encode transcription: 'VOLVO abdomen, ¬±65¬∞C, AEROMEXICO SUMMONER = (1961) About WASHING Missouri' in language ''
Encoding of string failed! Failure bytes: ffffffc2 ffffffb1 32 3f 20 61 63 74 69 76 69 74 79 20 50 52 4f 50 45 52 54 59 20 4d 41 49 4e 54 41 49 4e 45 44
Can't encode transcription: 'netting Bookmark of WE MORE) STRENGTH IDENTICAL ¬±2? activity PROPERTY MAINTAINED' in language ''
Encoding of string failed! Failure bytes: ffffffc2 ffffffb1 38 35 ffffffc2 ffffffa2 20 2c 20 72 65 6c 69 61 62 6c 65 20 45 76 65 6e 74 73 20 54 48 4f 55 53 41 4e 44 53 20 54 52 41 44 49 54 49 4f 4e 53 2e 20 41 4e 54 49 2d 55 53 20 42 65 64 72 6f 6f 6d 20 4c 65 61 64 65 72 73 68 69 70
Can't encode transcription: 'TRAVELED ¬±85¬¢ , reliable Events THOUSANDS TRADITIONS. ANTI-US Bedroom Leadership' in language ''
...
```

Why?

 Hey Shreeshrii,
I pulled and rebuilt the solution but I'm facing an issue with this command 
training/lstmtraining --stop_training   --continue_from ~/tesstutorial/trainplusminus/plusminus_checkpoint   --traineddata ~/tesstutorial/engtrain/ara.traineddata   --model_output ~/tesstutorial/trainplusminus/any.traineddata

It shows and the checkpoint generated using "training/lstmtraining": 
Failed to read continue from: /trainplusminus/plusminus_checkpoint

Btw, This issues appeared with the new commit on the master branch 2 days ago

 @Shreeshrii everything was working well until this commit "4572940" It is ok when I get the latest tessdata from https://github.com/tesseract-ocr/tessdata/tree/master/best.
Thanks for you help @Shreeshrii .  I believe that `[lang].lstm-recoder` is the compressed unicharset. It's a binary file, unlike the unicharset which is a textual file.  Peace be upon you,
@theraysmith here is a feature that I think you'll find interesting

Computer Assisted Transcription:
- The software segments the pages to lines.
- Then segments the lines into words.
- Later-on, allow the user to transcribe words or glyphs, once the user is satisfied, the software then searches for all instances of presence of such words or glyphs, and automatically transcribe them all in all instances.
- Can transcribe both Glyphs & Words, depending on the segmentation level you choose.
https://github.com/benedikt-budig/glyph-miner

[![glyph](https://user-images.githubusercontent.com/16248376/28994983-3f32bc3e-79e5-11e7-82fb-95898ec009c2.png)](https://www.youtube.com/watch?v=T-p_kIdsn6k)   tesseract 4.00.00alpha
 leptonica-1.74.1
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.5.0) : libpng 1.6.20 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.3 : libopenjp2 2.1.0
Win10 64bit - built Uni Mannheim

deu.traineddata - Repeating of characters:

Current Behavior:

√ÑGYPTEN -> √ÑAGYPTEN
Grand-Prix -> Gr√§and-Prix
AUSTRALIEN -> AUSTRA√ÑLIEN
GROSSBRITANNIEN -> GROSSBRITA√ÑANNIEN

Expected Behavior:

√ÑGYPTEN -> √ÑGYPTEN
Grand-Prix -> Grand-Prix
AUSTRALIEN -> AUSTRALIEN
GROSSBRITANNIEN -> GROSSBRITANNIEN

Suggested Fix:
1 blob / 1 box should only be 1 outcome / 1 result

Additional Info: 
Example images are available for posting Additional example (wW)
VW-Werk -> VwW-Werk >Suggested Fix:
1 blob / 1 box should only be 1 outcome / 1 result

1) It won't work with ligatures.
2) With the legacy OCR engine, there is  a character segmentation step, and the OCR is done on individual char blobs.  
With the new LSTM engine, the OCR is done by the neural network on sequence of pixels in text lines, not on pre-segmented blobs. The fix for most problems with the LSTM engine is more / better training.

DAS2016 Sildes,  [6. Modernization Efforts](https://github.com/tesseract-ocr/docs/blob/master/das_tutorial2016/6ModernizationEfforts.pdf) Page 17
Encyclopedia -> EE-n-c-yy-c-l-o-p-e-d-i-a -> Encyclopedia

I think that for 'in dictionary' words these kind of duplications would be eliminated. Similar issues: #884 #1011 @Shreeshrii

https://github.com/tesseract-ocr/tessdata/tree/master/best
is not working @all

deu.traineddata 19.721 KB
best - deu.traineddata 8.427 KB

best trainingdata only delivers empty results Yes, I'm using --oem 1

I'm just switching deu.traineddata in tessdata 
Old one works without problems, new one -> empty output
Checked the download - downloaded File has same size as in the repository. > Have you tested the deu model?

The new best one? No, I have not tested it yet. I am currently focused on Fraktur where the [new results](https://digi.bib.uni-mannheim.de/periodika/reichsanzeiger/ocr/film/tesseract-4.0.0-alpha.20170801/001-1879/0011.hocr) clearly beat the [old ones](https://digi.bib.uni-mannheim.de/periodika/reichsanzeiger/ocr/film/tesseract-4.0.0-alpha.20170703/001-1879/0011.hocr).

> [...] update the windows binaries on Uni Mannheim site [...]

I noticed on Linux that "old" Tesseract executables crash with the new traineddata, so I expect that my current Windows binaries would crash, too. Building new ones is on my list. thank you > [...] update the windows binaries on Uni Mannheim site [...]

The [new binaries](https://github.com/UB-Mannheim/tesseract/wiki) are now available.
I now use semantic versioning, so this is my 4.0.0-alpha.20170804.
 Thank you for the new binaries.

There are still similar errors:

hitzefrei -> 1 x hitzefreii / 1 x hitzefreil

Suggestion: The results are a lot better with 4.0. LSTM than with 3.05.01 but training seams to be difficult. Maybe it would be a good idea to offer a webpage where people could upload example image-files and matching text-files to include them in the training process.  > looks for frk traineddata, probably listed in deu.config

@theraysmith, `best/deu.traineddata` includes a `deu.config` with `tessedit_load_sublangs frk`. Why was this dependency added? It is confusing for end users who want to use `-l deu` that they need `frk.traineddata`, too.

@TheSeiko, maybe you'd get better results for Antiqua text without that `frk` dependency (which might be good for texts which also include Fraktur). You can use `combine_tessdata` to extract the components of `best/deu.traineddata`, remove deu.config and combine the remaining components again in a new file. Thank you for the tip. Much appreciated! @stweil Am I doing something wrong?

There's only a version file included in the deu,traineddata when using the binaries from 04.08

E:\Tesseract-OCR4.0a2>combine_tessdata -u deu.traineddata tmp/deu
Extracting tessdata components from deu.traineddata
Wrote tmp/deu.version
Version string:4.0.0-alpha.20170804
23:version:size=20, offset=192

E:\Tesseract-OCR4.0a2>combine_tessdata -u deu.traineddata tmp/deu.
Extracting tessdata components from deu.traineddata
Wrote tmp/deu.version
Version string:4.0.0-alpha.20170804
23:version:size=20, offset=192

E:\Tesseract-OCR4.0a2>combine_tessdata -d deu.traineddata
Version string:4.0.0-alpha.20170804
23:version:size=20, offset=192 @stweil thank you, removing deu.config helped a lot

---
ad best traineddata deu without deu.config:

after ~50k testimages: great recognition rate

only problem so far: sometimes i is not recognised properly:

sƒ±ch - sich
Parƒ±s - Paris

I'm adding a regex to replace ƒ± with i
 and j -> J

OCR Result <-> Text in image
Jungen - jungen
Jury - jury
Juries - juries $$-J√§hrige <-> $$-j√§hrige
SPO - SP√ñ @theraysmith j√§hrige/J√§hrige can be both - a noun (capital letter) or an adjective (lowercase):
a 42 year old man - ein 42-j√§hriger Mann
a 42 year old - ein 42-J√§hriger

Latin is working better with this problem, I've had it running yesterday for  ~100k frames
Latin has some problems with mutated vowels.
i.e.: 
+------------+---------+--------------------+--------------------+---------------------+
| languageId | ranking | replaceTo          | replaceRegex       | inputDate           |
+------------+---------+--------------------+--------------------+---------------------+
|         10 |      10 | √ñsterreich         | Osterreich         | 2017-08-03 14:45:05 | - DEU without FRAK
|         10 |      10 | Paris              | Parƒ±s              | 2017-08-08 10:52:04 | - DEU without FRAK
|         10 |      10 | i                  | ƒ±                  | 2017-08-08 13:04:50 | - DEU without FRAK
|         10 |      10 | √ñFB-Goalie         | OFB\-Goalie        | 2017-08-08 14:20:24 | - DEU without FRAK
|         10 |      10 | Volkspartei        | Volksparte!l       | 2017-08-09 09:14:11 | - LATIN
|         10 |      10 | Eurofighter-√úbung  | Eurofighter\-Ubung | 2017-08-09 09:34:09 | - LATIN
|         10 |      10 | √úberlebende        | Uberlebende        | 2017-08-10 08:08:04 | - LATIN
|         10 |      10 | Eine               | Fine               | 2017-08-10 09:04:31 | - LATIN
|         10 |      10 | Oberw√∂lz           | Oberw√≤√∂lz          | 2017-08-10 10:31:30 | - LATIN
|         10 |      10 | W√∂rter             | W√µ≈çrter            | 2017-08-10 14:25:23 | - LATIN
|         10 |      10 | W√∂rter             | W≈ç√∂rter            | 2017-08-10 14:25:51 | - LATIN
|         10 |      10 | W√∂rter             | W≈çrter             | 2017-08-10 14:26:45 | - LATIN
|         10 |      10 | M√§nner             | MƒÅ√§nner            | 2017-08-10 15:04:25 | - LATIN
+------------+---------+--------------------+--------------------+---------------------+

I've collected some example images and I'll try to do the "Fine Tuning Training" |         10 |      10 | Arzl-Ost           | Arzl\-0Ost         | 2017-08-11 09:34:41 | - LATIN
|         10 |      10 | Ein                | Fin                | 2017-08-11 09:35:26 | - LATIN
|         10 |      10 | W√§hrend            | WƒÅ√§hrend           | 2017-08-11 09:37:20 | - LATIN
|         10 |      10 | Oscarpr√§mierter    | OscarprƒÅmierter    | 2017-08-11 10:02:07 | - LATIN |         10 | 1502045216726 | Oberw√∂lz                                 | Oberw√µlz
|         10 | 1502047625611 | Milit√§rbasis  | MilitƒÅrbasis
|         10 | 1502057831054 | www.uncut.at                                     | WWWw.uncut.at
|         10 | 1502099066258 | W√∂rter                                    | W√µ√∂rter
|         10 | 1502269194006 | Donaupark zum Gratis  | Donaupark zum 6Gratis  It works, thank you. Nevertheless I suggest to wait with full automake support until Ray has started integrating the first real tests from Google.  I want generate some training data for tesseract:
`tesseract tiff/data.tif testdata/data lstm.train langdata/chi_sim/chi_sim.config`
But I got a lots of the following message, it happens almost on loading every page: 

> Page 54
> Warning. Invalid resolution 1 dpi. Using 70 instead.
> Loaded 603/603 pages (1-603) of document testdata/all.lstmf
> No block overlapping textline: 2017Êé¢Á¥¢
> No block overlapping textline: ‰∏ªÊåÅ‰∫∫ÈòµÂÆπ
> No block overlapping textline: Â∫èÂè∑
> No block overlapping textline: ËäÇÁõÆÂêçÁß∞
> No block overlapping textline: ËäÇÁõÆÁ±ªÂûã
> No block overlapping textline: ÊºîÂá∫ÈÉ®Èó®
> ......
> 

My tesseract  version:
tesseract 4.00.00alpha
leptonica-1.74.4
Any sugguestion for this?  The following line generates an error because `#include <algorithm>` is missing.

`max_offset = std::max(max_offset, (*code)(i)-han_offset);`

Severity	Code	Description	Project	File	Line	Suppression State
Error	C2039	'max': is not a member of 'std'	libtesseract	<path>\tesseract\ccutil\unicharcompress.cpp	208	
  @theraysmith, 

The new (c1c1e426b327) function PrepareDistortedPix() in training/degradeimage.h is not being used currently.
https://github.com/tesseract-ocr/tesseract/blob/4efc539f512bf/training/degradeimage.h#L38

Are you going to fix that?
 
 @theraysmith 

Another try... hope you'll notice. Please read my above message (at !#1052). 

Please also see #1024  Instructions (run in Tesseract source directory):

    git submodule update --init googletest
    mkdir demo && cd demo
    cmake ..
    make
    bin/tesseract_test
 Still missing:
- Update documentation.
- Add to Travis CI.
- Support for autotools (is this needed?).

That can be done as soon as there are real tests. Maybe there are also different opinions about the best location for the `googletest` submodule or the name of the test executable (currently `tesseract_test`).

`configure` / `make` is currently not used for CI tests, so maybe it is sufficient to support `cmake` for GoogleTest and don't implement autotools support. Is there a reason to have both cmake and autotools in the first place?

The homebrew build script for Tesseract uses autotools right now, so people are building with autotools. Logically one should be able to test any configuration that gets built.

I'd be tempted to deprecate/eliminate autotools so we don't have to worry about setting up test for it, if possible.  

 I personally also use mostly autotools, for example when building the installer for Windows. As far as I know it is also used by Debian based distributions when building Tesseract packages.

For the tests, having cmake in the first place seems to be sufficient for me because CI is based on that.

I'd decide later how easy or difficult it is to maintain testing with autotools. >Is there a reason to have both cmake and autotools in the first place?
>...
>I'd be tempted to deprecate/eliminate autotools so we don't have to worry about setting up test for it, if possible.

The autotools build works fine on Posix environments.

See also: 
https://github.com/tesseract-ocr/tesseract/pull/595#issuecomment-268111725
 https://github.com/tesseract-ocr/tesseract/commit/2fbcba62e5e
 You are right Debian packaging builds Tesseract with autotools, but it would be pretty easy to switch that over to cmake if needed. You should also build leptonica with CMake. I noticed for the first time that cmake builds a `liblibtesseract.so`. That looks like a bug, because it should be `libtesseract.so`. > You should also build leptonica with CMake.

That's not strictly necessary. As long as I install it to the standard location (`/usr/lib/x86_64-linux-gnu/liblept.so.5` for my Debian installation), the Leptonica library works both with CMake and autotools.

Ray, I‚Äå assume that your latest Leptonica was installed in `/usr/local`. Then CMake probably won't find it by default. I think the above is a case in point for my earlier comment that we should get rid of either Autotools or CMake. When there's two equivalent tools and people prefer one or the other, maintenance of one of them falls behind. Basically, CMake is for Windows&MSVC and autotools is for all other environments.
I'm talking only about this project, not about other projects' build tool usage.

Related: https://github.com/DanBloomberg/leptonica/issues/253 I suggest to let @egorpugin (maintainer of CMake build for both Leptonica and Tesseract) some time to response before giving up on CMake for the unit-testing.  @theraysmith, pull request #1051 adds the required pieces for GoogleTest.   Hi guys ! 
I'm try training tesseract in Japanese.
In Japanese has some type of char. In my case it's about Halfwidth and fullwidth in Katakana table.
Half-width Katakana Example : ÔΩ±ÔΩ≤ÔΩ≥ÔΩ¥ÔΩµ   ÔΩ∂ÔΩ∑ÔΩ∏ÔΩπÔΩ∫
Full-width Katakana Example : „Ç¢„Ç§„Ç¶„Ç®„Ç™„ÄÄ„Ç´„Ç≠„ÇØ„Ç±„Ç≥
It's really look like similar or look like uppercase and lowercase but diffirence
When input a Halfwidth katakana, Tesseract can't recognize  or some times out with Full-width katakana.

I try to using text2img make image and box, doing ltsm.train. But have some problem with unicharset!
`set_unicharset_properties -U unicharset -O unicharset -X jpn.xheights --script_dir=./langdata`
I have checked in langdata/Katakana.unicharset. Don't have any half-width katakana symbol.
Because of this i can't make a unicharset file with all the fields set to the right values, like in this [example](https://github.com/tesseract-ocr/tesseract/wiki/Training-Tesseract#an-example-of-the-unicharset-file)

This is my unicharset file i got from run command

`unicharset_extractor jpn.msgothic.exp18.box jpn.msgothic.exp32.box jpn.msgothic.exp48.box jpn.msgothicb.exp18.box`

> 414
NULL 0 NULL 0
Joined 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 	# Joined [4a 6f 69 6e 65 64 ]
|Broken|0|1 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 	# Broken
ÔΩ± 1 0,255,0,255,0,0,0,0,0,0 NULL 3 0 0 	# ÔΩ± [ff71 ]x
ÔΩ≥ 1 0,255,0,255,0,0,0,0,0,0 NULL 4 0 0 	# ÔΩ≥ [ff73 ]x
ÔæÑ 1 0,255,0,255,0,0,0,0,0,0 NULL 5 0 0 	# ÔæÑ [ff84 ]x
Ôæå 1 0,255,0,255,0,0,0,0,0,0 NULL 6 0 0 	# Ôæå [ff8c ]x
Ôæü 1 0,255,0,255,0,0,0,0,0,0 NULL 7 0 0 	# Ôæü [ff9f ]x
ÔΩØ 1 0,255,0,255,0,0,0,0,0,0 NULL 8 0 0 	# ÔΩØ [ff6f ]x
Ôæè 1 0,255,0,255,0,0,0,0,0,0 NULL 9 0 0 	# Ôæè [ff8f ]x
Ôæô 1 0,255,0,255,0,0,0,0,0,0 NULL 10 0 0 	# Ôæô [ff99 ]x
Ôæä 1 0,255,0,255,0,0,0,0,0,0 NULL 11 0 0 	# Ôæä [ff8a ]x
ÔæÅ 1 0,255,0,255,0,0,0,0,0,0 NULL 12 0 0 	# ÔæÅ [ff81 ]x
ÔΩº 1 0,255,0,255,0,0,0,0,0,0 NULL 13 0 0 	# ÔΩº [ff7c ]x
ÔΩ∂ 1 0,255,0,255,0,0,0,0,0,0 NULL 14 0 0 	# ÔΩ∂ [ff76 ]x
ÔΩµ 1 0,255,0,255,0,0,0,0,0,0 NULL 15 0 0 	# ÔΩµ [ff75 ]x
ÔΩ¥ 1 0,255,0,255,0,0,0,0,0,0 NULL 16 0 0 	# ÔΩ¥ [ff74 ]x
Ôæó 1 0,255,0,255,0,0,0,0,0,0 NULL 17 0 0 	# Ôæó [ff97 ]x
Ôæù 1 0,255,0,255,0,0,0,0,0,0 NULL 18 0 0 	# Ôæù [ff9d ]x
Ôæã 1 0,255,0,255,0,0,0,0,0,0 NULL 19 0 0 	# Ôæã [ff8b ]x
Ôæû 1 0,255,0,255,0,0,0,0,0,0 NULL 20 0 0 	# Ôæû [ff9e ]x
Ôæï 1 0,255,0,255,0,0,0,0,0,0 NULL 21 0 0 	# Ôæï [ff95 ]x
ÔΩ∞ 1 0,255,0,255,0,0,0,0,0,0 NULL 22 0 0 	# ÔΩ∞ [ff70 ]x
ÔΩª 1 0,255,0,255,0,0,0,0,0,0 NULL 23 0 0 	# ÔΩª [ff7b ]x
ÔΩ´ 1 0,255,0,255,0,0,0,0,0,0 NULL 24 0 0 	# ÔΩ´ [ff6b ]x
ÔΩΩ 1 0,255,0,255,0,0,0,0,0,0 NULL 25 0 0 	# ÔΩΩ [ff7d ]x
ÔæÉ 1 0,255,0,255,0,0,0,0,0,0 NULL 26 0 0 	# ÔæÉ [ff83 ]x
ÔΩ® 1 0,255,0,255,0,0,0,0,0,0 NULL 27 0 0 	# ÔΩ® [ff68 ]x
„É¥ 1 0,255,0,255,0,0,0,0,0,0 NULL 28 0 0 	# „É¥ [30f4 ]x
ÔΩÆ 1 0,255,0,255,0,0,0,0,0,0 NULL 29 0 0 	# ÔΩÆ [ff6e ]x
ÔΩ™ 1 0,255,0,255,0,0,0,0,0,0 NULL 30 0 0 	# ÔΩ™ [ff6a ]x
Ôæâ 1 0,255,0,255,0,0,0,0,0,0 NULL 31 0 0 	# Ôæâ [ff89 ]x
Ôæé 1 0,255,0,255,0,0,0,0,0,0 NULL 32 0 0 	# Ôæé [ff8e ]x
Ôæî 1 0,255,0,255,0,0,0,0,0,0 NULL 33 0 0 	# Ôæî [ff94 ]x
Ôæò 1 0,255,0,255,0,0,0,0,0,0 NULL 35 0 0 	# Ôæò [ff98 ]x
Ôæà 1 0,255,0,255,0,0,0,0,0,0 NULL 36 0 0 	# Ôæà [ff88 ]x
ÔΩ≤ 1 0,255,0,255,0,0,0,0,0,0 NULL 37 0 0 	# ÔΩ≤ [ff72 ]x
Ôæç 1 0,255,0,255,0,0,0,0,0,0 NULL 38 0 0 	# Ôæç [ff8d ]x
ÔΩ∏ 1 0,255,0,255,0,0,0,0,0,0 NULL 39 0 0 	# ÔΩ∏ [ff78 ]x
ÔæÄ 1 0,255,0,255,0,0,0,0,0,0 NULL 40 0 0 	# ÔæÄ [ff80 ]x
ÔæÜ 1 0,255,0,255,0,0,0,0,0,0 NULL 41 0 0 	# ÔæÜ [ff86 ]x
ÔΩπ 1 0,255,0,255,0,0,0,0,0,0 NULL 42 0 0 	# ÔΩπ [ff79 ]x
ÔΩ∫ 1 0,255,0,255,0,0,0,0,0,0 NULL 43 0 0 	# ÔΩ∫ [ff7a ]x
ÔæÖ 1 0,255,0,255,0,0,0,0,0,0 NULL 44 0 0 	# ÔæÖ [ff85 ]x
Ôæõ 1 0,255,0,255,0,0,0,0,0,0 NULL 45 0 0 	# Ôæõ [ff9b ]x
Ôæí 1 0,255,0,255,0,0,0,0,0,0 NULL 46 0 0 	# Ôæí [ff92 ]x
ÔΩø 1 0,255,0,255,0,0,0,0,0,0 NULL 47 0 0 	# ÔΩø [ff7f ]x
Ôæê 1 0,255,0,255,0,0,0,0,0,0 NULL 48 0 0 	# Ôæê [ff90 ]x
ÔΩæ 1 0,255,0,255,0,0,0,0,0,0 NULL 49 0 0 	# ÔΩæ [ff7e ]x
ÔΩ∑ 1 0,255,0,255,0,0,0,0,0,0 NULL 50 0 0 	# ÔΩ∑ [ff77 ]x
Ôæú 1 0,255,0,255,0,0,0,0,0,0 NULL 51 0 0 	# Ôæú [ff9c ]x
Ôæö 1 0,255,0,255,0,0,0,0,0,0 NULL 52 0 0 	# Ôæö [ff9a ]x
ÔΩ¨ 1 0,255,0,255,0,0,0,0,0,0 NULL 53 0 0 	# ÔΩ¨ [ff6c ]x
ÔΩ≠ 1 0,255,0,255,0,0,0,0,0,0 NULL 54 0 0 	# ÔΩ≠ [ff6d ]x
Ôæì 1 0,255,0,255,0,0,0,0,0,0 NULL 60 0 0 	# Ôæì [ff93 ]x
Ôæë 1 0,255,0,255,0,0,0,0,0,0 NULL 61 0 0 	# Ôæë [ff91 ]x
ÔΩß 1 0,255,0,255,0,0,0,0,0,0 NULL 62 0 0 	# ÔΩß [ff67 ]x
ÔΩ© 1 0,255,0,255,0,0,0,0,0,0 NULL 63 0 0 	# ÔΩ© [ff69 ]x
ÔæÇ 1 0,255,0,255,0,0,0,0,0,0 NULL 64 0 0 	# ÔæÇ [ff82 ]x
Ôæñ 1 0,255,0,255,0,0,0,0,0,0 NULL 65 0 0 	# Ôæñ [ff96 ]x

Thanks! @Shreeshrii  I think halfwidth katakana not include 
@theraysmith  sir ? can you tell me how to get glyph_metrics in unicharset?  **Related issue on Tesserocr:** [here](https://github.com/sirfz/tesserocr/issues/63)

### Environment

* **Tesseract Version**: 4.00alpha
* **Commit Number**: latest as of 2017-07-19
* **Platform**: Ubuntu 16.04

### Current Behavior:

Tesseract header files since commit [da03e4e](https://github.com/tesseract-ocr/tesseract/commit/da03e4e9105b6262706d40ef2b4436eae4ebe19f#diff-4376fff11de6717e265623d40f1b0820) added the use of `string` in the `unichar.h` header file that is used during compilation by `tesserocr`. This causes the compilation of `tesserocr` to throw an error because the `std` library is not imported.

    In file included from tesserocr.cpp:484:0:
    /usr/local/include/tesseract/unichar.h:164:10: error: ‚Äòstring‚Äô does not name a type
    static string UTF32ToUTF8(const std::vector<char32>& str32);
              ^

**Changing**  `static string UTF32ToUTF8(const std::vector<char32>& str32);` **to** `static std::string UTF32ToUTF8(const std::vector<char32>& str32);` **in** `/usr/local/include/tesseract/unichar.h:164` **fixes the problem for me.**

I am aware that you do not provide support for product that aren't the command-line Tesseract but I thought you might want to know since it worked before the commit.

### Expected Behavior:

Hopefully make it work again, if that's not an option, confirm that this is expected behavior.

### Reproducing the error

- Compile Leptonica from source
- Compile Tesseract from source (I used --disable-openmp if that matters)
- Install `tesserocr` with `pip3 install tesserocr` (obviously you need pip3 installed)

 Try this code before including Tesseract header files:

    #include <string>
    using std::string;

According to @theraysmith, the Google coding standards require `string` instead of `std::string`. Can we do something in our side that Ray will be okay with? That's my question too, while I do understand the desire to respect Google's coding guidelines, this probably won't bite only Tesserocr users... @theraysmith Is it? Because I had that problem about 3 hours ago on Ubuntu. Tesseract does build, it's the modules built with its header files that doesn't.

I'll try adding -DUSING_STD_NAMESPACE and report back. >The same define will be required for anything that uses the library too,

We need to document that requirement somewhere. It looks like `USING_STD_NAMESPACE` must always be defined. I wonder why the Tesseract code does not add `using std::string` unconditionally (making `USING_STD_NAMESPACE` unnecessary). Ray already fixed the issue with `USING_STD_NAMESPACE`. @Belval, please try the latest version from git. Indeed the issue is fixed (at least for tesserocr). Thank you! @Belval, are you using cmake and do you see the problem since commit c67c2e9f416e0b41b5e055e67ba5281e04dd5e6c (but not before that commit)? @Belval? Please answer to the questions from Ray and Stefan. Quoting my comment from [here](https://github.com/sirfz/tesserocr/issues/66#issuecomment-321010839):
> I installed the latest pull from the master branch. These changes were added in [unichar.h](https://github.com/tesseract-ocr/tesseract/commit/da03e4e9105b6262706d40ef2b4436eae4ebe19f#diff-4376fff11de6717e265623d40f1b0820R163) on 2017-07-14 (tesseract-ocr/tesseract@da03e4e9105b6262706d40ef2b4436eae4ebe19f) and [unicharset.h](https://github.com/tesseract-ocr/tesseract/commit/b0ead95d64a3667339775b2f99ac37e97e90c2a0#diff-ef746075ef360a166f1cfce7657fce21R241) on 2017-07-24 (tesseract-ocr/tesseract@b0ead95d64a3667339775b2f99ac37e97e90c2a0).

Setting `USING_STD_NAMESPACE` didn't make a difference (same [error message](https://github.com/sirfz/tesserocr/issues/66#issuecomment-321016343)).

I had to manually replace `string` with `std::string` in both unichar.h and unicharset.h to get it to compile properly. The correct macro which must be defined is `USE_STD_NAMESPACE`. `-DUSE_STD_NAMESPACE` works üëç I am finding same issue in tesseract fb359fc ```
#include <string>
using std::string;
```
before tesseract's includes works again for current master ebbfc3ae8df8 (thanks to @stweil)  ### Environment

* **Tesseract Version**: tesseract-ocr 3.04.
* **Platform**: Windows 8 64-bit

I am using A .NET wrapper for tesseract-ocr 3.04 found here: "https://github.com/charlesw/tesseract"

### Current Behavior:

I am trying to read the following image(without the black bar that is from VS):
![image](https://user-images.githubusercontent.com/30272427/28338164-0f345f00-6bd6-11e7-9d14-02a1a0679ca8.png)

I have tried it several time and each time it returns nothing. I am using the code(below).

Am I just running into a limitation of the OCR or is there something else I could do to try and get it to work?

Code I am runnig
```
`namespace` ORC
{
    class OCRFun
    {
        public void readData(Bitmap img)
        {
            try
            {
                using (var engine = new TesseractEngine(@"./tessdata", "eng", EngineMode.Default))
                {
                    using (img)
                    {
                        using (var page = engine.Process(img))
                        {
                            var text = page.GetText();
                            Console.WriteLine("Mean confidence: {0}", page.GetMeanConfidence());

                            Console.WriteLine("Text (GetText): \r\n{0}", text);
                            Console.WriteLine("Text (iterator):");
                            using (var iter = page.GetIterator())
                            {
                                iter.Begin();

                                do
                                {
                                    do
                                    {
                                        do
                                        {
                                            do
                                            {
                                                if (iter.IsAtBeginningOf(PageIteratorLevel.Block))
                                                {
                                                    Console.WriteLine("<BLOCK>");
                                                }

                                                Console.Write(iter.GetText(PageIteratorLevel.Word));
                                                Console.Write(" ");

                                                if (iter.IsAtFinalOf(PageIteratorLevel.TextLine, PageIteratorLevel.Word))
                                                {
                                                    Console.WriteLine();
                                                }
                                            } while (iter.Next(PageIteratorLevel.TextLine, PageIteratorLevel.Word));

                                            if (iter.IsAtFinalOf(PageIteratorLevel.Para, PageIteratorLevel.TextLine))
                                            {
                                                Console.WriteLine();
                                            }
                                        } while (iter.Next(PageIteratorLevel.Para, PageIteratorLevel.TextLine));
                                    } while (iter.Next(PageIteratorLevel.Block, PageIteratorLevel.Para));
                                } while (iter.Next(PageIteratorLevel.Block));
                            }
                        }
                    }
                }
            }
            catch (Exception e)
            {
                Trace.TraceError(e.ToString());
                Console.WriteLine("Unexpected Error: " + e.Message);
                Console.WriteLine("Details: ");
                Console.WriteLine(e.ToString());
            }
            //Console.Write("Press any key to continue . . . ");
            //Console.ReadKey(true);

        }

    }
}
```


### Expected Behavior:

### Suggested Fix:
 Tesseract treating the above image text as image.
So for this do a threshold and erode image using any image processing libraries and pass it to tesseract.  Platform is Debian Jessie - Tesseract 4.00 Git Version.
Platform: Linux localhost 4.4.27-x86_64-jb1 #4 SMP Tue Jun 6 14:41:09 CEST 2017 x86_64 GNU/Linux

Tesseract crashes with "Illegal Instruction" when using anything other than --oem 0

```
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 35 diacritics
Illegal instruction

```

Tesseract -v reports
```
tesseract 4.00.00alpha
 leptonica-1.74.4
  libjpeg 6b (libjpeg-turbo 1.3.1) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8 : libopenjp2 2.1.0

 Found AVX
 Found SSE

```
I can scan with --oem 0 though. Ok, so now I reinstalled tesseract just to make sure I did everything right.
Tessdata files like 'eng.traineddata' have now been downloaded directly from the repo into  /usr/local/share/tessdata

Current content: 
`configs  deu.traineddata  eng.traineddata  pdf.ttf  tessconfigs`

Now Tesseract starts but tells me that it can't load any language. Which is quite odd.

`tesseract --tessdata-dir /usr/local/share/tessdata/tessdata -l eng  test.jpg out`
results in:
```
Error opening data file /usr/local/share/tessdata/eng.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to your "tessdata" directory.
Failed loading language 'eng'
Tesseract couldn't load any languages!
Could not initialize tesseract.
```
`tesseract -l eng  test.jpg out`
results in:
`Error opening data file /usr/local/share/eng.traineddata` 

and
`tesseract --tessdata-dir /usr/local/share/tessdata -l eng  test.jpg out`
also results in:
`Error opening data file /usr/local/share/eng.traineddata` 

And whatever I set the TESSDATA_PREFIX to, (like TESSDATA_PREFIX=/usr/share/tesseract-ocr/tessdata) does not get honored at all. 
I simply don't get it. What's going on here?
 Ok, I solved the language problem.  After unsetting TESSDATA_PREFIX and simply using:
`wget https://github.com/tesseract-ocr/tessdata/raw/4.00/deu.traineddata`
Tesseract seems to be able to load the language files from the default `/usr/local/share/tessdata` again.

But still --oem 1 results in:
```
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 35 diacritics
Illegal instruction

```

 When using the data files from:
` git clone --depth=1 https://github.com/tesseract-ocr/tessdata.git tessdata-repo`
tesseract fails to load the language files.

But when using the data files from: https://github.com/tesseract-ocr/tesseract/wiki/Data-Files
by downloading with:
wget https://github.com/tesseract-ocr/tessdata/raw/4.00/eng.traineddata 
I can start tesseract with --oem 0, but --oem 1 or --oem 2 results in the  illegal instruction message

Both ways I put the files into /usr/local/share/tessdata That's correct.  Please test tesseract with phototest.tif, as Shree suggested.
https://github.com/tesseract-ocr/tesseract/blob/master/testing/phototest.tif OK. I tested it with the traineddata above. But also it's the same I'm using here. 
I also confirmed that tesseract in indeed using the right data folder. 

But again the phototest.tif works fine with --oem 0 and results in the same error "illegal instructions" for any other --oem option or none (default should be --oem 2 if I'm not mistaken)

And although compilation seemed fine. I didn't see an error or warning. So I guess there must be some library missing here. 

Also I reinstalled Leptonica and Tesseract multiple times now.

Here's how I've installed the tools:
```
1. Make sure that the following libraries are installed:

       # nickbe:  I had to replace libpng12-dev for debian jessie

	apt-get install autoconf-archive automake g++ libtool libleptonica-dev pkg-config
	apt-get install libpango1.0-dev

	# sudo apt-get install g++ # or clang++
	sudo apt-get install autoconf automake libtool
	sudo apt-get install autoconf-archive
	sudo apt-get install pkg-config
	sudo apt-get install libpng12-dev
	sudo apt-get install libjpeg-turbo
	sudo apt-get install libtiff5-dev
	sudo apt-get install zlib1g-dev

	sudo apt-get install libicu-dev
	sudo apt-get install libpango1.0-dev
	sudo apt-get install libcairo2-dev

2. Install Leptonica:

	git clone --depth 1 https://github.com/DanBloomberg/leptonica.git leptonica
	cd leptonica
	./autobuild
	./configure
	make
	sudo make install
	ldconfig

3. Install Tesseract:

    git clone --depth 1  https://github.com/tesseract-ocr/tesseract.git tesseract-ocr
    cd tesseract-ocr
    ./autogen.sh

    ./configure --disable-openmp --disable-shared --disable-static
    or
    ./configure        # nickbe: I TESTED BOTH CONFIGURATIONS JUST TO MAKE SURE
    make

    sudo make install
	sudo ldconfig

	# sudo make training
	# sudo make training-install

	sudo make install-langs      # nickbe: Never does anything so far
      sudo ldconfig

4. wget tessdata from https://github.com/tesseract-ocr/tesseract/wiki/Data-Files
   to /usr/local/share/tessdata

   Example: wget https://github.com/tesseract-ocr/tessdata/raw/4.00/eng.traineddata

``` Do not install `libleptonica-dev` with apt-get, since you manually intsall leptonica later.   apt-get uninstall libleptonica-dev OK I enabled debug. I also installed the gdb package, but I have no experience with it. How can I provide more information? >sudo make install-langs      # nickbe: Never does anything so far

The comment is correct, so there's no point in doing that.   I think one quite important information is that I just installed the package on a fresh instance of debian stretch. I had no problems with installating Leptonica or Tesseract, but after everything was installed I have exactly the same behaviour on this machine. Tesseract runs with --oem 0 but throws the "illegal instruction" message when trying to use --oem 2 or 1.

Seems that there's something very profound missing in the installation procedure. Ok. I managed to run Tesseract with gdb. Here's the output:
```

(gdb) set args -l eng --oem 2 test.png out
(gdb) run
Starting program: /usr/local/bin/tesseract -l eng --oem 2 test.png out
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 35 diacritics

Program received signal SIGILL, Illegal instruction.
tesseract::DotProductAVX (u=0x127aa70, v=0x51dbc60, n=25) at dotproductavx.cpp:70
70            __m256d floats2 = _mm256_loadu_pd(v);
(gdb)

``` >./configure --disable-openmp --disable-shared --disable-static

https://github.com/tesseract-ocr/tesseract/issues/898#issuecomment-315202167
https://github.com/tesseract-ocr/tesseract/issues/943#issuecomment-305408592
 Change this line in configure.ac
`AX_CHECK_COMPILE_FLAG([-mavx], [avx=true], [avx=false])`
to
`AX_CHECK_COMPILE_FLAG([-mavx], [avx=false], [avx=false])`

and recompile tesseract again. btw. I already uninstalled libleptonica-dev before.

Do I have to "make uninstall" before recompiling?

 >Do I have to "make uninstall" before recompiling?

You mean `make uninstall tesseract` ?

You don't have to in this case.


Also, what's the output of `cat /proc/cpuinfo | grep flags` ?


 ```
flags           : fpu tsc msr pae cx8 apic cmov pat clflush mmx fxsr sse sse2 ss syscall nx lm constant_tsc rep_good nopl pni pclmulqdq vmx ssse3 cx16 sse4_1 sse4_2 popcnt aes f16c rdrand hypervisor lahf_lm tpr_shadow vnmi flexpriority ept vpid
flags           : fpu tsc msr pae cx8 apic cmov pat clflush mmx fxsr sse sse2 ss syscall nx lm constant_tsc rep_good nopl pni pclmulqdq vmx ssse3 cx16 sse4_1 sse4_2 popcnt aes f16c rdrand hypervisor lahf_lm tpr_shadow vnmi flexpriority ept vpid
flags           : fpu tsc msr pae cx8 apic cmov pat clflush mmx fxsr sse sse2 ss syscall nx lm constant_tsc rep_good nopl pni pclmulqdq vmx ssse3 cx16 sse4_1 sse4_2 popcnt aes f16c rdrand hypervisor lahf_lm tpr_shadow vnmi flexpriority ept vpid


``` After recompiling everything with the changed flag the new output is:

```
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 35 diacritics
DotProductAVX can't be used on Android
DotProductAVX can't be used on Android
Aborted
```

Android?! According to the output of `cat /proc/cpuinfo | grep flags`, your cpu does not support avx.
 The latest recompile was already done with the modified configure.ac. 
That was the output when running:  tesseract -l eng --oem 2 ......
As always --oem 0 works.
 OK. You will have to do another change in the code.

I will tell you later/tomorrow what to do next. 
 In arch/simddetect.h

Change this line
`static inline bool IsAVXAvailable() { return detector.avx_available_; }`
to
`static inline bool IsAVXAvailable() { return false; }`

I hope we will finish with this change :-) It's strange that `tesseract -v` reports `Found AVX` while your CPU obviously does not support AVX (see output of `/proc/cpuinfo`. That's causing the crash which you observe. What kind of CPU are you using? Are you running on a virtual machine?

Could you use the GDB debugger to step through the function `SIMDDetect::SIMDDetect` (in `arch/simddetect.cpp`) which is executed right at the beginning? Maybe you have a buggy `__get_cpuid` function (or a buggy virtual machine). Try to print the value of `ecx` which is set by that function.

Removing the code `avx_available_ = (ecx & 0x10000000) != 0;` will work around the problem and fix the crash. The change suggested by @amitdo will have the same effect. and recompile of course. Do what I said before listening to @stweil :-) @stweil 

Yes. It's strange.
I want to make sure the problem will be solved after disabling (cheating) avx detection.
If that happen, nickbe will need to undo the 2 changes and recompile. Then you will do your analysis... 
 >What kind of CPU are you using?

`cat /proc/cpuinfo | grep name`
 It's a vServer. Probably XEN but I'm not sure. We do use them quite often without problems. So I have no idea why this case is indeed so strange. I'm recompiling now... Yay. It's working finally. Thanks you so much guys üíÉ Will the changes in the make make it into the official repository.?

So now that I can in fact test the new 4.0 feats, is there a way to speed up scanning? Any switches that are recommended? 

 > Will the changes in the make make it into the official repository?

No, they won't, because those changes disable AVX support which is highly desired: AVX makes Tesseract faster. The problem is most probably caused by your vServer which returns a wrong cpuid. That cpuid claims that your vServer supports AVX, but it does not. You can try to get more more information on that vServer (is it XEN, which version?) and report the problem.

We could add a Tesseract option to select SSE / AVX (overriding the automatic detection). Then Tesseract would still crash by default in your case, but it would be possible to make it work using that new option. Is this something new to the 4.00 version? Because the 3.x Versions ran just fine. Yes, it's new. AVX is used for the calculation of the dot product which is needed for LSTM (new in 4.00, not used with `--oem 0`). Maybe there's a safer method to detect the capability? Can I find out if other methods show the correct capabilities for you guys? 
If you like I'd be happy to grant you access to the server.  https://github.com/tesseract-ocr/tesseract/issues/1043#issuecomment-316519350 No I meant maybe there's a better and more secure way for you guys to recognize these kind of features @nickbe, you could help by providing more information on the kind of vServer which you were using. Sure. 
https://www.df.eu/de/cloud-hosting/
Currently it's the second smallest vServer I just wrote to Domain Factory (in German, translated here):

> One of your customers has reported a problem with the OCR application
Tesseract: https://github.com/tesseract-ocr/tesseract/issues/1043#issuecomment-317283770
>
> The cause of the crash seems to be the CPUID seen from the vServer guest. That CPUID does not fit the real hardware:
>
> According to CPUID, the CPU supports AVX operations. In fact, these lead to a crash.
>
> Doesn't your hardware support AVX (maybe an older XEON CPU)? Probably the VM of the customer migrated from newer hardware (with AVX) to an older hardware (without AVX), and now it still uses the CPUID of the newer hardware.
>
> What do you advise users in this case?
> You can also reply directly to GitHub (URL above).

XEN can set the CPUID seen by guests to avoid exactly that kind of problem: it can mask the AVX bit even when running on a new CPU with AVX support, thus allowing migration to an older CPU. @nickbe, could you please also run `cpuid --one-cpu` and `cpuid --one-cpu --raw` and post the output?  Similar problems: https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=646549, https://sourceware.org/bugzilla/show_bug.cgi?id=13007. Intel manual: https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-manual-325462.pdf#G16.42695. Nick, Domain Factory support asks for the name of your Jiffy Box. Could you send me your e-mail address (get my address [here](https://www.bib.uni-mannheim.de/stefan-weil/))? Then I'll forward their request to you. @nickbe, did you manage to solve the issue? @amitdo, I had contacted Nick's provider. They use XEN servers which do not support AVX, but the CPUID which is seen from the vServer claims that AVX is available. As far as I have understood, this happens when a XEN vServer initially runs on a server with AVX, but is migrated to another server without AVX later.

Only the provider can handle that correctly. Either the XEN vServer must always run on servers with AVX, or the XEN configuration must disable the AVX settings in CPUID even if the server has AVX support.

On the Tesseract side we could try to get a more robust AVX detection which not only checks CPUID. In addition we need an option or parameter to override the automatic selection of SSE2 / AVX. Ok, @stweil. Thanks for the info.  hi guys, yes I successfully solved the problem by following your instruction to patch the settings.
Thanks again for your support here. Very appreciated indeed :)   

------------------------

### Environment

* **Tesseract Version**:  4.00 alpha
* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
* **Platform**: ubuntu 14, 64 bit

### Current Behavior:

```
root@pl:~/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master# training/tesstrain.sh \
>   --fonts_dir /usr/share/fonts \
>   --lang eng --linedata_only \
>   --noextract_font_properties \
>   --langdata_dir /home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master \
>   --tessdata_dir /home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/tessdata \
>   --fontlist "Lucida Sans" \
>   --output_dir /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA

=== Starting training for language 'eng'
[Tue Jul 11 13:05:43 IST 2017] /usr/local/bin/text2image --fonts_dir=/usr/share/fonts --font=Lucida Sans --outputbase=/tmp/font_tmp.XgxrkfyOjx/sample_text.txt --text=/tmp/font_tmp.XgxrkfyOjx/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.XgxrkfyOjx
Rendered page 0 to file /tmp/font_tmp.XgxrkfyOjx/sample_text.txt.tif

=== Phase I: Generating training images ===
Rendering using Lucida Sans
[Tue Jul 11 13:05:45 IST 2017] /usr/local/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.XgxrkfyOjx --fonts_dir=/usr/share/fonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0 --font=Lucida Sans --text=/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.training_text
Stripped 5 unrenderable words
Rendered page 0 to file /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.tif
Stripped 3 unrenderable words
Rendered page 1 to file /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.tif

=== Phase UP: Generating unicharset and unichar properties files ===
[Tue Jul 11 13:05:46 IST 2017] /usr/local/bin/unicharset_extractor -D /tmp/tmp.iafCx7Aypj/eng/ /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.box
Extracting unicharset from /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.box
Wrote unicharset file /tmp/tmp.iafCx7Aypj/eng//unicharset.
[Tue Jul 11 13:05:46 IST 2017] /usr/local/bin/set_unicharset_properties -U /tmp/tmp.iafCx7Aypj/eng/eng.unicharset -O /tmp/tmp.iafCx7Aypj/eng/eng.unicharset -X /tmp/tmp.iafCx7Aypj/eng/eng.xheights --script_dir=/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master
Loaded unicharset of size 111 from file /tmp/tmp.iafCx7Aypj/eng/eng.unicharset
Setting unichar properties
Other case √â of √© is not in unicharset
Warning: properties incomplete for index 25 = ~
Writing unicharset to file /tmp/tmp.iafCx7Aypj/eng/eng.unicharset

=== Phase D: Generating Dawg files ===
Generating word Dawg
[Tue Jul 11 13:05:46 IST 2017] /usr/local/bin/wordlist2dawg -r 1 /home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.wordlist /tmp/tmp.iafCx7Aypj/eng/eng.word-dawg /tmp/tmp.iafCx7Aypj/eng/eng.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.iafCx7Aypj/eng/eng.unicharset'
Reading word list from '/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.wordlist'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.iafCx7Aypj/eng/eng.word-dawg'
Generating frequent-word Dawg
[Tue Jul 11 13:05:48 IST 2017] /usr/local/bin/wordlist2dawg -r 1 /tmp/tmp.iafCx7Aypj/eng/eng.wordlist.clean.freq /tmp/tmp.iafCx7Aypj/eng/eng.freq-dawg /tmp/tmp.iafCx7Aypj/eng/eng.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.iafCx7Aypj/eng/eng.unicharset'
Reading word list from '/tmp/tmp.iafCx7Aypj/eng/eng.wordlist.clean.freq'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.iafCx7Aypj/eng/eng.freq-dawg'
[Tue Jul 11 13:05:48 IST 2017] /usr/local/bin/wordlist2dawg -r 0 /home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.punc /tmp/tmp.iafCx7Aypj/eng/eng.punc-dawg /tmp/tmp.iafCx7Aypj/eng/eng.unicharset
Set reverse_policy to RRP_DO_NO_REVERSE
Loading unicharset from '/tmp/tmp.iafCx7Aypj/eng/eng.unicharset'
Reading word list from '/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.punc'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.iafCx7Aypj/eng/eng.punc-dawg'
[Tue Jul 11 13:05:48 IST 2017] /usr/local/bin/wordlist2dawg -r 0 /home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.numbers /tmp/tmp.iafCx7Aypj/eng/eng.number-dawg /tmp/tmp.iafCx7Aypj/eng/eng.unicharset
Set reverse_policy to RRP_DO_NO_REVERSE
Loading unicharset from '/tmp/tmp.iafCx7Aypj/eng/eng.unicharset'
Reading word list from '/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.numbers'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.iafCx7Aypj/eng/eng.number-dawg'
[Tue Jul 11 13:05:48 IST 2017] /usr/local/bin/wordlist2dawg -r 1 /home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.word.bigrams /tmp/tmp.iafCx7Aypj/eng/eng.bigram-dawg /tmp/tmp.iafCx7Aypj/eng/eng.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.iafCx7Aypj/eng/eng.unicharset'
Reading word list from '/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.word.bigrams'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.iafCx7Aypj/eng/eng.bigram-dawg'

=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/tessdata
[Tue Jul 11 13:05:57 IST 2017] /usr/local/bin/tesseract /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.tif /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0 lstm.train
Info in bmfCreate: Generating pixa of bitmap fonts from string
Error: unichar y in normproto file is not in unichar set.
Error: unichar m in normproto file is not in unichar set.
Error: unichar ‚Äú in normproto file is not in unichar set.
Error: unichar p in normproto file is not in unichar set.
Error: unichar f in normproto file is not in unichar set.
Error: unichar " in normproto file is not in unichar set.
Error: unichar ! in normproto file is not in unichar set.
Error: unichar @ in normproto file is not in unichar set.
Error: unichar [ in normproto file is not in unichar set.
Error: unichar ¬¢ in normproto file is not in unichar set.
Error: unichar | in normproto file is not in unichar set.
Error: unichar x in normproto file is not in unichar set.
Error: unichar * in normproto file is not in unichar set.
Error: unichar $ in normproto file is not in unichar set.
Error: unichar ¬£ in normproto file is not in unichar set.
Error: unichar _ in normproto file is not in unichar set.
Error: unichar { in normproto file is not in unichar set.
Error: unichar } in normproto file is not in unichar set.
Error: unichar > in normproto file is not in unichar set.
Error: unichar ¬• in normproto file is not in unichar set.
Error: unichar ¬© in normproto file is not in unichar set.
Error: unichar z in normproto file is not in unichar set.
Error: unichar ¬∞ in normproto file is not in unichar set.
Error: unichar q in normproto file is not in unichar set.
Error: unichar w in normproto file is not in unichar set.
Error: unichar ¬´ in normproto file is not in unichar set.
Error: unichar = in normproto file is not in unichar set.
Error: unichar ; in normproto file is not in unichar set.
Error: unichar < in normproto file is not in unichar set.
Error: unichar ? in normproto file is not in unichar set.
Error: unichar Ô¨Ç in normproto file is not in unichar set.
Error: unichar ' in normproto file is not in unichar set.
Error: unichar j in normproto file is not in unichar set.
Error: unichar ¬ª in normproto file is not in unichar set.
Error: unichar √© in normproto file is not in unichar set.
Error: unichar ‚Äî in normproto file is not in unichar set.
Error: unichar # in normproto file is not in unichar set.
Error: unichar ~ in normproto file is not in unichar set.
Error: unichar + in normproto file is not in unichar set.
Error: unichar ¬Æ in normproto file is not in unichar set.
Error: unichar ‚Ç¨ in normproto file is not in unichar set.
Error: unichar ‚Äò in normproto file is not in unichar set.
Error: unichar Ô¨Å in normproto file is not in unichar set.
Error: unichar ‚Äù in normproto file is not in unichar set.
Error: unichar ¬ß in normproto file is not in unichar set.
Error: unichar \ in normproto file is not in unichar set.
Error: unichar ‚Äô in normproto file is not in unichar set.
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Page 2
Loaded 50/50 pages (1-50) of document /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.lstmf

=== Constructing LSTM training data ===
Moving /tmp/tmp.iafCx7Aypj/eng/eng.unicharset to /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA
Moving /tmp/tmp.iafCx7Aypj/eng/eng.number-dawg to /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA/eng.lstm-number-dawg
Moving /tmp/tmp.iafCx7Aypj/eng/eng.punc-dawg to /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA/eng.lstm-punc-dawg
Moving /tmp/tmp.iafCx7Aypj/eng/eng.word-dawg to /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA/eng.lstm-word-dawg
Moving /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.lstmf to /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA

Completed training for language 'eng'

root@pl:~/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master# 
```



### Expected Behavior:






### Suggested Fix:
 These are the files which are more elaborated.


[error_text_when_training_data_generated.txt](https://github.com/tesseract-ocr/tesseract/files/1147429/error_text_when_training_data_generated.txt)
[tess_output_for_img_txt.txt](https://github.com/tesseract-ocr/tesseract/files/1147428/tess_output_for_img_txt.txt)
 Hello shree devi, can you please tell how to generate unicharset file in utf-8 format.. i am not able to find a way for that.
Can you please tell me. ```
=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/tessdata
[Tue Jul 11 13:05:57 IST 2017] /usr/local/bin/tesseract /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.tif /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0 lstm.train
Info in bmfCreate: Generating pixa of bitmap fonts from string
Error: unichar y in normproto file is not in unichar set.
....
```

This looks strange, because the error here comes from the legacy OCR engine, not the LSTM engine. @amitdo  Can you please say what can i do to avoid this and train tesseract normally.

Can u give any clue why this is happening. Sorry, I don't know why it is happening. @Shreeshrii @amitdo 

i am able to generate training data with tesseract code, which i have downloaded around april.
this is the text output regarding that. everyhting seems normal

``
=== Starting training for language 'eng'
[Sat Jul 15 23:49:58 IST 2017] /usr/bin/text2image --fonts_dir=/usr/share/fonts --font=FreeSans --outputbase=/tmp/font_tmp.9J4DwTjR0e/sample_text.txt --text=/tmp/font_tmp.9J4DwTjR0e/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.9J4DwTjR0e
Rendered page 0 to file /tmp/font_tmp.9J4DwTjR0e/sample_text.txt.tif
Rtl = 0 ,vertical=0

=== Phase I: Generating training images ===
Rendering using FreeSans
[Sat Jul 15 23:50:24 IST 2017] /usr/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.9J4DwTjR0e --fonts_dir=/usr/share/fonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0 --font=FreeSans --text=/home/dell/Downloads/Tesseract_new/tess_text/eng/eng.training_text
Rendered page 0 to file /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0.tif
Rendered page 1 to file /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0.tif
Rtl = 0 ,vertical=0

=== Phase UP: Generating unicharset and unichar properties files ===
[Sat Jul 15 23:50:26 IST 2017] /usr/bin/unicharset_extractor -D /tmp/tmp.RCyux9nJxb/eng/ /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0.box
Extracting unicharset from /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0.box
Wrote unicharset file /tmp/tmp.RCyux9nJxb/eng//unicharset.
[Sat Jul 15 23:50:26 IST 2017] /usr/bin/set_unicharset_properties -U /tmp/tmp.RCyux9nJxb/eng/eng.unicharset -O /tmp/tmp.RCyux9nJxb/eng/eng.unicharset -X /tmp/tmp.RCyux9nJxb/eng/eng.xheights --script_dir=/home/dell/Downloads/Tesseract_new/tess_text
Loaded unicharset of size 115 from file /tmp/tmp.RCyux9nJxb/eng/eng.unicharset
Setting unichar properties
Other case FF of ff is not in unicharset
Other case √â of √© is not in unicharset
Other case FI of fi is not in unicharset
Warning: properties incomplete for index 25 = ~
Writing unicharset to file /tmp/tmp.RCyux9nJxb/eng/eng.unicharset

=== Phase D: Generating Dawg files ===
Generating word Dawg
[Sat Jul 15 23:50:26 IST 2017] /usr/bin/wordlist2dawg -r 1 /home/dell/Downloads/Tesseract_new/tess_text/eng/eng.wordlist /tmp/tmp.RCyux9nJxb/eng/eng.word-dawg /tmp/tmp.RCyux9nJxb/eng/eng.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.RCyux9nJxb/eng/eng.unicharset'
Reading word list from '/home/dell/Downloads/Tesseract_new/tess_text/eng/eng.wordlist'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.RCyux9nJxb/eng/eng.word-dawg'
Generating frequent-word Dawg
[Sat Jul 15 23:50:30 IST 2017] /usr/bin/wordlist2dawg -r 1 /tmp/tmp.RCyux9nJxb/eng/eng.wordlist.clean.freq /tmp/tmp.RCyux9nJxb/eng/eng.freq-dawg /tmp/tmp.RCyux9nJxb/eng/eng.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.RCyux9nJxb/eng/eng.unicharset'
Reading word list from '/tmp/tmp.RCyux9nJxb/eng/eng.wordlist.clean.freq'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.RCyux9nJxb/eng/eng.freq-dawg'
[Sat Jul 15 23:50:30 IST 2017] /usr/bin/wordlist2dawg -r 0 /home/dell/Downloads/Tesseract_new/tess_text/eng/eng.punc /tmp/tmp.RCyux9nJxb/eng/eng.punc-dawg /tmp/tmp.RCyux9nJxb/eng/eng.unicharset
Set reverse_policy to RRP_DO_NO_REVERSE
Loading unicharset from '/tmp/tmp.RCyux9nJxb/eng/eng.unicharset'
Reading word list from '/home/dell/Downloads/Tesseract_new/tess_text/eng/eng.punc'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.RCyux9nJxb/eng/eng.punc-dawg'
[Sat Jul 15 23:50:30 IST 2017] /usr/bin/wordlist2dawg -r 0 /home/dell/Downloads/Tesseract_new/tess_text/eng/eng.numbers /tmp/tmp.RCyux9nJxb/eng/eng.number-dawg /tmp/tmp.RCyux9nJxb/eng/eng.unicharset
Set reverse_policy to RRP_DO_NO_REVERSE
Loading unicharset from '/tmp/tmp.RCyux9nJxb/eng/eng.unicharset'
Reading word list from '/home/dell/Downloads/Tesseract_new/tess_text/eng/eng.numbers'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.RCyux9nJxb/eng/eng.number-dawg'
[Sat Jul 15 23:50:30 IST 2017] /usr/bin/wordlist2dawg -r 1 /home/dell/Downloads/Tesseract_new/tess_text/eng/eng.word.bigrams /tmp/tmp.RCyux9nJxb/eng/eng.bigram-dawg /tmp/tmp.RCyux9nJxb/eng/eng.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.RCyux9nJxb/eng/eng.unicharset'
Reading word list from '/home/dell/Downloads/Tesseract_new/tess_text/eng/eng.word.bigrams'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.RCyux9nJxb/eng/eng.bigram-dawg'

=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=/home/dell/Downloads/Tesseract_new/tesseract-master/tessdata
[Sat Jul 15 23:50:45 IST 2017] /usr/local/bin/tesseract /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0.tif /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0 lstm.train
Info in bmfCreate: Generating pixa of bitmap fonts from string
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Page 2
Loaded 53/53 pages (1-53) of document /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0.lstmf

=== Constructing LSTM training data ===
Moving /tmp/tmp.RCyux9nJxb/eng/eng.unicharset to /home/dell/Downloads/Tesseract_new/output_dir/FreeSans/LSTM_FILES_1STEP/
Moving /tmp/tmp.RCyux9nJxb/eng/eng.number-dawg to /home/dell/Downloads/Tesseract_new/output_dir/FreeSans/LSTM_FILES_1STEP//eng.lstm-number-dawg
Moving /tmp/tmp.RCyux9nJxb/eng/eng.punc-dawg to /home/dell/Downloads/Tesseract_new/output_dir/FreeSans/LSTM_FILES_1STEP//eng.lstm-punc-dawg
Moving /tmp/tmp.RCyux9nJxb/eng/eng.word-dawg to /home/dell/Downloads/Tesseract_new/output_dir/FreeSans/LSTM_FILES_1STEP//eng.lstm-word-dawg
Moving /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0.lstmf to /home/dell/Downloads/Tesseract_new/output_dir/FreeSans/LSTM_FILES_1STEP/

Completed training for language 'eng'






  @Shreeshrii @amitdo 

I request any body give me brief overview,  how to train tesseract 4 with image files. How to give box and tif pairs to tesseract..

In the above command we can only see text file has been given to tesseract. What should be done if i want a image and box file is to given to tesseract.

Please advise me. you need add
--linedata_only  From general testing, it appears as though I'm I/O bound while using tesseract, and not CPU bound. I checked out the CPU Cache performance (profiled with valgrind and perf, but perf's output is easiest to read) and found that my machines have a high number of cache misses, and even a high number of iTLB misses. After inspecting the code, I also noticed that almost every function was defined as 'inline'. The high rate of iTLB misses surprised me. Usually iTLB misses are reduced after running a program for a longer period of time, but increasing the run time (for instance with an image with a lot more text) saw my iTLB miss rate increase, perhaps indicating that I am filling my iTLB, which is rare.

The iTLB misses worry me, especially because running a program for a longer period of time typically reduces them (one inevitably has cache/tlb misses when executing something that the CPU has not seen, but once it is in the cache, it should stay in the cache...). iTLB misses are expensive on Intel CPUs. I have used OpenMP in the past, but I'm not sure how it handles an iTLB miss per 'thread'. If each thread hits a miss and hits a page fault exception, and it's non blocking (which makes sense), then it'd mean that each thread would cause a page walk for the same instructions. Not sure if that's what happens, but I'd love to know what does happen (or a book or resource) if someone knows more about how OpenMP handles them.

I have seen code styled similarly at my last job, where the main part of the program was written over 25 years ago. At the time I expressed surprise (and alarm) to a co-worker, who explained that compilers used to be terrible at attempting to inline functions, and it wasn't until GCC 4 that there was a decent attempt to improve them. GCC 4 was released in 2005. (The version of GCC 4 you are using now has many updates and improvements, and is different from the GCC 4 in 2005, so GCC 4 is not that 'outdated', but it was the first major time where there were improvements.) So before 2005, best practice was to write code similar to how Tesseract identifies almost all functions as 'inline'.

The 'inline' specifier carries some interesting aspects too, and was more 'important' to use with C, since C++ defaults to 'inline' when... (From [https://gcc.gnu.org/onlinedocs/gcc-7.1.0/gcc/Inline.html#Inline](url))

> As required by ISO C++, GCC considers member functions defined within the body of a class to be marked inline even if they are not explicitly declared with the inline keyword.

Also, GCC can ignore 'inline' as it sees fit. The -O2 optimization option includes -finline-small-functions, which inlines functions that do not generate additional code. -O3 includes -finline-functions, which is more or less the same as writing 'inline' before every function, and only ignoring it if GCC decides that it may reduce performance. -O2 is in the default configure options, so adding 'inline' before each function is similar to just compiling with '-finline-functions', except that it is slightly more explicit.

There are many downsides to defining a function as 'inline', but the one people usually seem to notice is increased compile time. There's plenty of information available on Google/GNU's documentation about inline, the history of inline, and slight differences between inline in g++ and GNU C back in the day.

The biggest example of what I'd call (modern) "overactive inline use" in tesseract is probably in these files:
https://github.com/tesseract-ocr/tesseract/blob/master/lstm/functions.h
https://github.com/tesseract-ocr/tesseract/blob/master/lstm/functions.cpp

functions.cpp has two lines of code, with almost everything in functions.h.

This is also an example of compiler output with default options, i.e. keeping '-O2' and all of the different functions 'inlined' (with -Winline: https://gcc.gnu.org/onlinedocs/gcc-7.1.0/gcc/Inline.html#Inline ), defined as:

>  Using -Winline warns when a function marked inline could not be substituted, and gives the reason for the failure.

```
functions.h:63:15: warning: inlining failed in call to ‚Äòdouble tesseract::Logistic(double)‚Äô: call is unlikely and code size would grow [-Winline]
 inline double Logistic(double x) {
               ^~~~~~~~
functions.h:64:37: note: called from here
   if (x < 0.0) return 1.0 - Logistic(-x);
                             ~~~~~~~~^~~~
functions.h:63:15: warning: inlining failed in call to ‚Äòdouble tesseract::Logistic(double)‚Äô: call is unlikely and code size would grow [-Winline]
 inline double Logistic(double x) {
               ^~~~~~~~
functions.h:64:37: note: called from here
   if (x < 0.0) return 1.0 - Logistic(-x);
                             ~~~~~~~~^~~~
functions.h:63:15: warning: inlining failed in call to ‚Äòdouble tesseract::Logistic(double)‚Äô: call is unlikely and code size would grow [-Winline]
 inline double Logistic(double x) {
               ^~~~~~~~
functions.h:64:37: note: called from here
   if (x < 0.0) return 1.0 - Logistic(-x);
                             ~~~~~~~~^~~~
functions.h:63:15: warning: inlining failed in call to ‚Äòdouble tesseract::Logistic(double)‚Äô: call is unlikely and code size would grow [-Winline]
 inline double Logistic(double x) {
               ^~~~~~~~
functions.h:64:37: note: called from here
   if (x < 0.0) return 1.0 - Logistic(-x);
                             ~~~~~~~~^~~~
functions.h:45:15: warning: inlining failed in call to ‚Äòdouble tesseract::Tanh(double)‚Äô: call is unlikely and code size would grow [-Winline]
 inline double Tanh(double x) {
               ^~~~
functions.h:46:28: note: called from here
   if (x < 0.0) return -Tanh(-x);
                        ~~~~^~~~
```

As a test on my target machines, I copied my 'tesseract' repository, removed all (easy to remove...) 'inline' functions, shifted the definition to the .cpp file instead of the .h file (leaving the declaration in .h as is standard practice), and compiled a separate version, installing it with a different prefix. This allowed me to have multiple versions of Tesseract on the same machine, and to run tests with all of them.

Next, I made a script. Fairly simple, utilizing GNU Parallel
CITATION:

>   O. Tange (2011): GNU Parallel - The Command-Line Power Tool,
  ;login: The USENIX Magazine, February 2011:42-47.

The simple bash scripts look like this:
```bash
#!/bin/bash
# CONTROL SCRIPT
TESS=/usr/bin/tesseract
F_LOC=(location of my test images)
parallel $TESS $F_LOC/{1} stdout ::: img1.jpg img2.png img3.jpeg
```
and
```bash
#!/bin/bash
# TEST SCRIPT
TESS=/home/hotchkiss/usr/bin/tesseract
F_LOC=(location of my test images)
parallel $TESS $F_LOC/{1} stdout ::: img1.jpg img2.png img3.jpeg
```
I'd run them ~50 times randomly(as random as /dev/urandom can afford on two options), 'randomly' defined as I randomly chose which to run, and collected the average run times and percentages as an aggregate using perf. Each run was after a fresh reboot, with no other programs running other than X, i3 (my windows manager), and my default kernel + kernel modules (less than 110MB when running 'free -m').

Results look something like:

```
 Performance counter stats for 'test_tess':

      54913.737862      task-clock:u (msec)       #    6.757 CPUs utilized          
                 0      context-switches:u        #    0.000 K/sec                  
                 0      cpu-migrations:u          #    0.000 K/sec                  
           136,385      page-faults:u             #    0.002 M/sec                  
   161,251,587,471      cycles:u                  #    2.936 GHz                      (29.05%)
   154,963,746,273      instructions:u            #    0.96  insn per cycle           (36.65%)
    35,080,176,770      branches:u                #  638.823 M/sec                    (42.77%)
       306,913,327      branch-misses:u           #    0.87% of all branches          (41.68%)
    50,274,555,586      L1-dcache-loads:u         #  915.519 M/sec                    (27.81%)
     5,075,515,864      L1-dcache-load-misses:u   #   10.10% of all L1-dcache hits    (19.72%)
       450,004,836      LLC-loads:u               #    8.195 M/sec                    (17.70%)
        23,036,525      LLC-load-misses:u         #   10.24% of all LL-cache hits     (21.92%)
   <not supported>      L1-icache-loads:u                                           
        11,674,082      L1-icache-load-misses:u                                       (28.02%)
    48,676,934,856      dTLB-loads:u              #  886.425 M/sec                    (21.31%)
         1,322,784      dTLB-load-misses:u        #    0.00% of all dTLB cache hits   (20.86%)
           264,354      iTLB-loads:u              #    0.005 M/sec                    (17.36%)
           690,732      iTLB-load-misses:u        #  261.29% of all iTLB cache hits   (21.42%)
   <not supported>      L1-dcache-prefetches:u                                      
   <not supported>      L1-dcache-prefetch-misses:u                                   

       8.127386606 seconds time elapsed
```


As expected, with no compiler optimizations and all functions with the 'inline' identifier removed, the performance was worse by a significant amount (8% to 10% worse). Also as expected with modern compilers (gcc 6.3 and gcc 8.0... I haven't run 7.x stable yet, although I could tomorrow), the performance seems to be ~the same and (perhaps, although requires more testing to be definite) better on a CPU with smaller cache/tlb sizes.

I used parallels to ensure that things were running in parallel, similar to what I will be using in production, and, what (hopefully) everyone else is doing too. I checked the other things people have posted, and it seems as though most others are doing the same too.

### What I'm asking
1. How are you collecting cache and performance information, is it standardized, and how would you like any statistics or data to be submitted/displayed?
2. Is it alright if I remove and submit code without 'inline' declared on every function?
3. Should I submit code with 'inline' removed from functions others have written?
4. What are your (other developer's) target machines like, and are my results and thought process similar?

Personally, I'm not a fan of manually marking all functions as inline, but I'm also (quite) used to re-writing code/libraries to optimize performance for my use case(s).

I can wait on posting any code changes until @theraysmith has the new beta tag out though. I'm not sure how these types of issues are handled on github either. I've spent most of my time working at a FFRDC, and haven't submitted much FOSS code publicly at all because of it, but I can post what I've done with this, which is great. Typically, I'd either write my own tests and submit along with compiled code (and a 'NO MERGE' pull request), or follow already provided tests and submit according to them, however I haven't seen any. What do you all prefer to use, and would this be something you're interested in? I absolutely abhor, detest, and strongly oppose programming for the compiler, but I feel like these changes would actually do the opposite, and allow the compiler to take over.

I'm also profiling functions for more detailed optimization with cachegrind, and I'll absolutely post those after the changes have been submitted. Again, it's less of a 'logic' change, and in some cases more of a logic 'reordering' (like order of conditional if tests, what to inline/skip/spend more time on and the like).

Another option that (might?) be decent, if it turns out that removing 'inline' does hurt performance on CPUs with large cache/tlb spaces, is that I can do something similar to what the Linux Kernel has. There is a "Allow gcc to uninline functions marked 'inline'" option (under 'Kernel Hacking') because they have run into the same issue.

------------------------

### Environment

* **Tesseract Version**: 4.0x(latest -dev)
* **Platform**: Linux [hostname] 4.12.0 #1 SMP Tue Jul 11 14:56:49 EDT 2017 x86_64 Intel(R) Core(TM) i7-4770HQ CPU @ 2.20GHz GenuineIntel GNU/Linux
(and, specs not with me right now, but posting anyway, an Intel Atom, can post later).

tested with:
gcc version 8.0.0 20170711 (experimental) (GCC)
gcc version 6.3.0 (Gentoo 6.3.0 p1.0)
I can test with gcc 7.x later if need be. I haven't switched my development system's stable version of gcc to 7 yet, even though I still test the experimental svn branch. Regarding OpenMP thread affinity control:

>https://www.nas.nasa.gov/hecc/support/kb/using-intel-openmp-thread-affinity-for-pinning_285.html

`KMP_AFFINITY` is specific to intel's OpenMP runtime.

GCC supports `GOMP_CPU_AFFINITY`
https://gcc.gnu.org/onlinedocs/libgomp/GOMP_005fCPU_005fAFFINITY.html#GOMP_005fCPU_005fAFFINITY

OpenMP 3.1 added  `OMP_PROC_BIND`
https://gcc.gnu.org/onlinedocs/libgomp/OMP_005fPROC_005fBIND.html#OMP_005fPROC_005fBIND

OpenMP 4.0 added `OMP_PLACES`
https://gcc.gnu.org/onlinedocs/libgomp/OMP_005fPLACES.html#OMP_005fPLACES


 > What are your (other developer's) target machines like, and are my results and thought process similar?

I'm just processing a larger number of images and run Tesseract on 4 Xeon servers of different age with (16 + 16 + 32 + 8) tesseract processes using GNU parallel. The binaries were built without OpenMP to avoid the overhead related with multithreading and to allow optimal use of the available CPU cores (one process per core). This setting produced [150,000 hOCR files](http://digi.bib.uni-mannheim.de/periodika/reichsanzeiger/ocr/film/tesseract-4.0.0-alpha.20170703/) during the last 10 days ([example](https://digi.bib.uni-mannheim.de/periodika/reichsanzeiger/ocr/film/tesseract-4.0.0-alpha.20170703/011-9418/0018.hocr)). Regarding OpenMP thread affinity: I think that the problem won't be fixed by binding OpenMP threads to a fixed CPU core nor will other thread libraries help. The current Tesseract simply creates too many threads even if a single process is started because it uses interleaved `#pragma omp parallel` statements. As soon as more than one process is running things get even worse because the number of threads then will exceed the number of CPU cores, and scheduling overhead will occur. >because the number of threads then will exceed the number of CPU cores

but you can limit the number of threads being used. I'm afraid you can limit it only by recompilation (either without OpenMP or with modified source code). Well, we can change the code...

(if we can prove the change will really make things better) Did you try ` OMP_THREAD_LIMIT=1 tesseract...`? No, I did not ‚Äì obviously I missed that environment variable. I only had tried `OMP_NUM_THREADS`. Setting `OMP_THREAD_LIMIT=1` indeed stops thread creation. Many thanks. Now I no longer have to build special binaries without OpenMP. Great!

I just discovered this variable an hour ago :-)
https://gcc.gnu.org/onlinedocs/libgomp/Environment-Variables.html  ### Environment

Tessearct 4.00.00alpha
Windows 10 64 bit Visual Studio 2013 Win32 build. 

This issue is also present in earlier versions of Tesseract including 3.0.4 (which I fixed for our own use). 

### Current Behavior:

The GetUTF8Text() method (and other similar methods) allocates a buffer, but there is no call to free the memory, and it cannot be freed by the caller without heap corruption. 

### Expected Behavior:

### Suggested Fix:

Add a method called FreeXXText() (or whatever name is preferred) which does no more than free the memory along these lines: 

void TessBaseAPI::FreeXXText(char *text)
{
	delete[] text;
}

Deleting a null pointer is not a problem (on Windows anyway).  https://github.com/tesseract-ocr/tesseract/blob/10779bd9e50d/api/baseapi.cpp#L1273

I assume it is a Windows-only issue similar to https://github.com/tesseract-ocr/tesseract/issues/1029#issuecomment-314152843, right? This happens when you do **not** use CRT dynamic link and the heaps get confused. In projects using many dependencies, this can get tricky because all the dependencies should use the same (unless you really know what you are doing).

See https://msdn.microsoft.com/en-us/library/abx4dbyh(v=vs.80).aspx but also 
https://stackoverflow.com/questions/10820114/do-statically-linked-dlls-use-a-different-heap-than-the-main-program

In vsprops (or directly in GUI) you should use something like
```
    <ClCompile>
      <RuntimeLibrary>MultiThreadedDebugDLL</RuntimeLibrary>
    </ClCompile>
```
 Another link:

https://msdn.microsoft.com/en-us/library/ms235460.aspx
>Potential Errors Passing CRT Objects Across DLL Boundaries That's right, the app and DLL have their own heaps.  You mean `STRING`? :-)

That's what Tesseract uses in the API. I'm afraid that you will get an endless list of problems as long as your program uses more than one C runtime library on Windows. With only a single runtime library, all those problems should be solved.

It is possible to force the MS linker to always use the same msvcrt(d).dll.

You could also consider building Leptonica and Tesseract with Mingw-w64. With that combination I never had such problems. I only use one C runtime library, multithreaded DLL for release builds and multithreaded debug DLL for debug builds.  "It's better to return std::string"

Surely that has the same issue if it is allocated in the library, but freed in the application.  https://msdn.microsoft.com/en-us/library/ms235460.aspx

>The DLL and .exe file are built with /MD, so they share a single copy of the CRT.
>
>If you rebuild with /MT so that they use separate copies of the CRT, running the resulting test1Main.exe results in an access violation.

How do you build the dll and exe? > I only use one C runtime library

Nevertheless your program uses more than one C runtime library if it crashes. Use the [Process Explorer](https://technet.microsoft.com/en-us/sysinternals/processexplorer.aspx) to see which DLLs are used at runtime. For command line programs which run very short, you'll have to add a `sleep` in the `main()` function to delay the execution. dumpbin provides an alternative way to see the linkage of statically linked DLLs. For example:  

**dumpbin /IMPORTS libtesseract304.dll**

All my components use msvcr120.dll.   I need a Windows Win32 build of the Tesseract DLL version 4. I've tried and failed to build the code from the \Tesseract-4.00.00alpha branch. The first issue is that cppan.yml need editing to fix a known bug at the end: 

    pvt.cppan.demo.danbloomberg.leptonica: master

The next issue is that I get unresolved externals: 

Error	1	error LNK2001: unresolved external symbol "public: void __thiscall tesseract::Tesseract::TrainLineRecognizer(class STRING const &,class STRING const &,class BLOCK_LIST *)" (?TrainLineRecognizer@Tesseract@tesseract@@QAEXABVSTRING@@0PAVBLOCK_LIST@@@Z)	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\libtesseract\baseapi.obj	libtesseract304
Error	2	error LNK2001: unresolved external symbol "public: void __thiscall tesseract::Tesseract::LSTMRecognizeWord(class BLOCK const &,class ROW *,class WERD_RES *,class tesseract::PointerVector<class WERD_RES> *)" (?LSTMRecognizeWord@Tesseract@tesseract@@QAEXABVBLOCK@@PAVROW@@PAVWERD_RES@@PAV?$PointerVector@VWERD_RES@@@2@@Z)	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\libtesseract\control.obj	libtesseract304
Error	3	error LNK2001: unresolved external symbol "public: void __thiscall tesseract::Tesseract::RecogRawLine(class PAGE_RES *)" (?RecogRawLine@Tesseract@tesseract@@QAEXPAVPAGE_RES@@@Z)	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\libtesseract\control.obj	libtesseract304
Error	4	error LNK2001: unresolved external symbol "public: bool __thiscall tesseract::LSTMRecognizer::LoadDictionary(char const *,char const *)" (?LoadDictionary@LSTMRecognizer@tesseract@@QAE_NPBD0@Z)	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\libtesseract\tessedit.obj	libtesseract304
Error	5	error LNK2001: unresolved external symbol "public: bool __thiscall tesseract::LSTMRecognizer::DeSerialize(bool,class tesseract::TFile *)" (?DeSerialize@LSTMRecognizer@tesseract@@QAE_N_NPAVTFile@2@@Z)	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\libtesseract\tessedit.obj	libtesseract304
Error	6	error LNK2001: unresolved external symbol "public: __thiscall tesseract::LSTMRecognizer::LSTMRecognizer(void)" (??0LSTMRecognizer@tesseract@@QAE@XZ)	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\libtesseract\tessedit.obj	libtesseract304
Error	7	error LNK2001: unresolved external symbol "public: __thiscall tesseract::LSTMRecognizer::~LSTMRecognizer(void)" (??1LSTMRecognizer@tesseract@@QAE@XZ)	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\libtesseract\tesseractclass.obj	libtesseract304
Error	8	error LNK1120: 7 unresolved externals	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\DLL_Release\libtesseract304.dll	libtesseract304
	9	IntelliSense: identifier "round" is undefined	c:\Development\Projects\Tesseract-4.00.00alpha\api\baseapi.cpp	1367	43	libtesseract304

Thanks in advance.  @egorpugin,
No feedback from the OP, so please close this issue.  Hi,
when inizializing tesseract 4 with ita language (ita.traineddata for tesseract 4), the application crash on  configEngine method of G8Tesseract.mm.

<img width="585" alt="schermata 2017-07-06 alle 16 54 54" src="https://user-images.githubusercontent.com/1537350/27917284-e45683bc-626b-11e7-98bf-bc3666c1d500.png">

<img width="955" alt="schermata 2017-07-06 alle 16 51 01" src="https://user-images.githubusercontent.com/1537350/27917244-bed8d644-626b-11e7-8c2d-463004eaa036.png">

Please help me, thanks.  I try to use sudo apt-get install libleptoncia-dev on linux.

It displays that I have already installed libleptoncia-1.74, which is the newest one.

While I use ./configure to congigure the package on my system, it shows an errors again:

` error: Leptonica 1.74 or higher is required. Try to install libleptonica-dev package.`

SO I try to remove the libleptoncia-1.74 and reinstall the dev again, but it put up another error:
`Failed to connect to socket /com/ubuntu/upstart: `

I have no idea to deal with those, can anybody give me some advices? Thanks, it is helpful. I fix it.  https://github.com/tesseract-ocr/tesseract/blob/master/training/merge_unicharsets.cpp

Should we add it to `training/Makefile.am` ? Good questions, Shree. Unfortunately, I simply don't have the answers...


 I just found this file, and saw it isn't in the Makefile.am which means it won't be compiled, so you can't actually use it. It takes two or more unicharset files with this format:
https://github.com/tesseract-ocr/tesseract/wiki/Training-Tesseract#the-unicharset-file-format

I don't know when you are supposed to use it. It calls this function to do the merge:
https://github.com/tesseract-ocr/tesseract/blob/29f3de9be1fbae76925e946b9fb04bb976c3f9a0/ccutil/unicharset.cpp#L439 For next time, I suggest not to mix unrelated commits in one PR. Thanks anyway!  If Tesseract is called with a non-existing image file, it creates an empty output file.

I'd expect that no output is created in that case.

Examples:

    # Empty output.txt is created.
    tesseract nonexisting_image.tiff output
    # Empty output.hocr is created.
    tesseract nonexisting_image.tiff output hocr
  Hi,

i was trying to make fine tuning for the lstm file yet i got this error

**Deserialize failed: /home/ibr/tesstutorial/aratrain/ara.2_Baran.exp0.lstmf read 0/81 pages**
keep in mind that the path is correct so the error is **Deserialize failed**: not **Deserialize header failed**
and tesseract freezes after the error message and should press Ctrl C to stop it

i already used the same version of tesseract to tune for japanese, but for arabic i got the previous error
the command was 

`training/lstmtraining --model_output ~/tesstutorial/arabic_tuning/"arabic_tune" \
  --continue_from ~/tesstutorial/extracted_aralstm/ara.lstm \
  --train_listfile ~/tesstutorial/aratrain/ara.training_files.txt \
  --max_iterations 100000`

Thanks i was able to tune Arabic ara.lstm with the same lstmf files, but the difference i made tuning against a different version of tesseract which is: **367-g5baa8c8**. while the version that failed was: **547-g8c29e68**

strangely that the version **547-g8c29e68** passed for Japanese tuning yet it failed for Arabic tuning, as for the version **367-g5baa8c8** i didn't try it for Japanese tuning, only for Arabic and it succeeded
NOTE: both versions are running on the same VMware, and with the same leptonica version which is Leptonica1.47.1 actually all the LSTMFs (Arabic & Japanese) were created by the same version **547-g8c29e68**  yet fine tuning at the version **547-g8c29e68**  worked only for Japanese, but for Arabic (which was also created by the version **547-g8c29e68**) its fine tuning worked at the version **367-g5baa8c8**  Is this issue still happen with latest code?   Fix for #1016  Hi all 
i'm using Tesseract for get each char with Coordinate in image . I'm using ResultIterator with OCR MODE =2 (LTSM) and language = jpn.

> tesseract::ResultIterator* ri = api->GetIterator();
int index_char = 0;
vector<CharIterator> char_iterators;
do {
	char *value = ri->GetUTF8Text(tesseract::RIL_SYMBOL);
	//unknown value to space
	if (value == nullptr || value == "")value = " ";
	float conf = ri->Confidence(tesseract::RIL_SYMBOL);
	ri->BoundingBox(tesseract::RIL_SYMBOL, &left, &top, &right, &bottom);
	index_char++;
} while (ri->Next(tesseract::RIL_SYMBOL));
api->ClearAdaptiveClassifier();

Here is my program log and input image . You can see  in „Çä character i got wrong Coordinate . I tested using tsv and hocr but it's give me same result. Still wrong Coordinate .

> Char value = „Åì left= 15 top = 14 right = 51 bottom = 51 conf = 99
Char value = „Çì left= 64 top = 9 right = 112 bottom = 54 conf = 99
Char value = „Å∞ left= 122 top = 5 right = 171 bottom = 54 conf = 99
Char value = „Çì left= 176 top = 9 right = 224 bottom = 54 conf = 99
Char value = „ÅØ left= 234 top = 9 right = 281 bottom = 54 conf = 99
Char value = „Åì left= 295 top = 14 right = 331 bottom = 51 conf = 99
Char value = „Çì left= 344 top = 9 right = 392 bottom = 54 conf = 99
Char value = „Å∞ left= 402 top = 5 right = 445 bottom = 54 conf = 99
Char value = „Çì left= 456 top = 9 right = 497 bottom = 54 conf = 99
Char value = „ÅØ left= 514 top = 9 right = 561 bottom = 54 conf = 99
Char value = „Åî left= 15 top = 79 right = 58 bottom = 126 conf = 99
Char value = È£Ø left= 62 top = 80 right = 113 bottom = 130 conf = 99
Char value = Â§ß left= 120 top = 80 right = 225 bottom = 130 conf = 99
Char value = Áõõ left= 242 top = 83 right = 260 bottom = 130 conf = 99
Char value = „Çä left= 2328 top = 1616 right = 2328 bottom = 1616 conf = 99
Char value = „ÄÇ left= 289 top = 116 right = 305 bottom = 131 conf = 99

![jpn msgothic exp0](https://user-images.githubusercontent.com/22963463/27729378-9d2f8196-5dc0-11e7-9c99-5090652734bb.jpg)
And one more question . I'm try to and fonts in jpn data but may be i must re train from scratch. But i don't know actrually my jpn tessseract data (i'm downloaded from tessdata repository) how to make this?
I'm try download data from langdata repository make image from jpn.traintext and train it by using tesstrain.sh and Jtessboxeditor . But i got low accurary than i download from repository.  Some body can tell me extractly how to make it!
Sorry for my bad english    i got a same problem. i am using jpn.traindata.
i tried RIL_SYMBOL, RIL_WORD. RIL_SYMBOL is better.
A critical problem is ---- the recgnized character is so good but the position is too bad.
i need the pair of image and character, don't you?
If you have new information pls tell me.

thanks I'm temple fix this by using this way
I'm using RIL_SYMBOL. in my case the wrong Coordinate usually appear in a end of lines or end of block
res_it->IsAtFinalElement(RIL_TEXTLINE, RIL_WORD)
res_it->IsAtFinalElement(RIL_PARA, RIL_WORD)
res_it->IsAtFinalElement(RIL_BLOCK, RIL_WORD)
when you get a wrong Coordinate you can predict a new  coordinate by using the backforward of  ResultIterator coordinate  >Char value = „Åì left= 15 top = 14 right = 51 bottom = 51 conf = 99
Char value = „Çì left= 64 top = 9 right = 112 bottom = 54 conf = 99
Char value = „Å∞ left= 122 top = 5 right = 171 bottom = 54 conf = 99
Char value = „Çì left= 176 top = 9 right = 224 bottom = 54 conf = 99
Char value = „ÅØ left= 234 top = 9 right = 281 bottom = 54 conf = 99
Char value = „Åì left= 295 top = 14 right = 331 bottom = 51 conf = 99
Char value = „Çì left= 344 top = 9 right = 392 bottom = 54 conf = 99
Char value = „Å∞ left= 402 top = 5 right = 445 bottom = 54 conf = 99
Char value = „Çì left= 456 top = 9 right = 497 bottom = 54 conf = 99
Char value = „ÅØ left= 514 top = 9 right = 561 bottom = 54 conf = 99
Char value = „Åî left= 15 top = 79 right = 58 bottom = 126 conf = 99
Char value = È£Ø left= 62 top = 80 right = 113 bottom = 130 conf = 99
Char value = Â§ß left= 120 top = 80 right = 225 bottom = 130 conf = 99
Char value = Áõõ left= 242 top = 83 right = 260 bottom = 130 conf = 99
Char value = „Çä **left= 2328 top = 1616 right = 2328 bottom = 1616** conf = 99
Char value = „ÄÇ left= 289 top = 116 right = 305 bottom = 131 conf = 99

Strange. It looks like a bug. Thank sir We are still able to reproduce it in the **Arabic** language in **LSTM mode**.
Most BBoxes are correct but there are some boxes that contain valid text and wrong coordinates (the region contained in the bbox is empty). I'm getting the same behavior for Thai language in LSTM - BoundingBox() often returns the whole image size.
The image size was 400, 266. Here is a small portion of some results [X1, Y1; X2, Y2].
(As a side note, I'm using RIL_WORD, but it seems to behave like RIL_SYMBOL, I'm not sure why).

'‡∏£' - Confidence: 94.3645 [0, 0; 400, 266]
'‡∏°' - Confidence: 95.7061 [19, 68; 33, 77]
'‡∏≤' - Confidence: 96.9703 [0, 0; 400, 266]
'‡∏™' - Confidence: 96.976 [35, 67; 50, 77] @amitdo  sir  could you show me where to get more info about how tesseract analyze input image to get the Coordinate of words/character and then recognize them through LSTM or old method and last combine the ocr result word with the coordinate ? @wanghaisheng

See here:
https://github.com/tesseract-ocr/tesseract/blob/master/lstm/recodebeam.cpp
Search for 'box', 'xcoords', 'blob'  ### Environment

* **Tesseract Version**: tesseract alpha - 4.0.0 
* **Platform**: Linux Ubuntu 16.04 LTS

Tesseract lstmtraining is used to train Korean language. The following error has occurred.
```
lstmtraining \ 
--model_config  $HOME/work/kor/tuned/kortuned \ 
--continue_from  $HOME/work/kor/tuned/kor.lstm \ 
--train_listfile  $HOME/work/kor/config/kor.training_files.txt \ 
--target_error_rate 0.01 \ 
--max_iterations 1200
```
It seems that a compression error occurs in the following complex characters.

![training error](https://user-images.githubusercontent.com/29770235/27676336-780ff9f0-5ce8-11e7-9609-bedd9ed2d860.png)


How do I resolve this issue?

Do I need to register for Korean unicharset?


  Tesseract (master branch, tested several versions on Windows/Ubuntu) using LSTM only inserts sometimes letters where they should not be. We have observed this happening randomly (but reproducible) also with eng, ces, nor (others not tested), also with different DPI.

Test case:
![to recognise 1498480501215-2111908889](https://user-images.githubusercontent.com/332350/27642820-3afe616c-5c63-11e7-8f37-91c91df7e6d2.png)
```
./tesseract ./to.recognise.1498480501215-2111908889.png stdout --oem 1 -l ces --psm 13
```
Expected: Veitvetveien
Got: Veitvetvelien

Letter bboxes visualised below
<img width="762" alt="tesseract bug report" src="https://user-images.githubusercontent.com/332350/27643336-1c6a95ee-5c64-11e7-8839-73a6a2d4d00e.png">
 Using:
- latin.traineddata

From the tesseract code, it seems that there is no handling of the situation when LSTM produces different results for one letter in time e.g., there is a line with the letter S
```
...
128 null_char score=-11.4265, c=-0.0850153, perm=0, hash=fa6bdef8 prev:null_char score=-11.3415, c=-0.0935133, perm=0, hash=fa6bdef8
129 null_char score=-11.5115, c=-0.0850045, perm=0, hash=fa6bdef8 prev:null_char score=-11.4265, c=-0.0850153, perm=0, hash=fa6bdef8
130 null_char score=-11.5966, c=-0.0850804, perm=0, hash=fa6bdef8 prev:null_char score=-11.5115, c=-0.0850045, perm=0, hash=fa6bdef8
131 null_char score=-11.6853, c=-0.088736, perm=0, hash=fa6bdef8 prev:null_char score=-11.5966, c=-0.0850804, perm=0, hash=fa6bdef8
132 label=3, uid=5=S [53 ]A score=-12.0022, c=-0.316888, Start End perm=8, hash=6b41093b prev:null_char score=-11.6853, c=-0.088736, perm=0, hash=fa6bdef8
133 label=3, uid=5=S [53 ]A score=-13.1056, c=-1.10339, perm=8, hash=6b41093b prev:label=3, uid=5=S [53 ]A score=-12.0022, c=-0.316888, Start End perm=8, hash=6b41093b
134 label=64, uid=66=$ [24 ] score=-13.2539, c=-0.14831, End perm=8, hash=86b8e412 prev:label=3, uid=5=S [53 ]A score=-13.1056, c=-1.10339, perm=8, hash=6b41093b
135 label=64, uid=66=$ [24 ] score=-13.8318, c=-0.577888, perm=8, hash=86b8e412 prev:label=64, uid=66=$ [24 ] score=-13.2539, c=-0.14831, End perm=8, hash=86b8e412
136 null_char score=-13.9704, c=-0.138632, perm=0, hash=86b8e412 prev:label=64, uid=66=$ [24 ] score=-13.8318, c=-0.577888, perm=8, hash=86b8e412
137 null_char score=-14.0555, c=-0.0850982, perm=0, hash=86b8e412 prev:null_char score=-13.9704, c=-0.138632, perm=0, hash=86b8e412
138 null_char score=-14.1405, c=-0.0850008, perm=0, hash=86b8e412 prev:null_char score=-14.0555, c=-0.0850982, perm=0, hash=86b8e412
139 null_char score=-14.2255, c=-0.0850006, perm=0, hash=86b8e412 prev:null_char score=-14.1405, c=-0.0850008, perm=0, hash=86b8e412
140 null_char score=-14.3105, c=-0.085, perm=0, hash=86b8e412 prev:null_char score=-14.2255, c=-0.0850006, perm=0, hash=86b8e412
```
and
```
Best choice: accepted=0, adaptable=0, done=1 : Lang result : S$ : R=3.06256, C=-7.72375, F=1, Perm=8, xht=[0,3.40282e+38], ambig=0
pos     NORM    NORM
str     S       $
state:  1       1
C       -1.103  -0.578
```

@theraysmith 
What is the expected behaviour in this case - should multiple choices (clearly) in one character be handled?
Thank you.
  After upgrade to _Tesseract-4-Alpha_, I found this error making the OCR from my JAVA code:

`
ITesseract instance = new Tesseract(); 
instance.setDatapath("/usr/share/tessdata/"); 
instance.setLanguage("spa"); 
(...)
result = instance.doOCR(imageFile);
`

------------------------

### Environment

* **Tesseract Version**: tesseract 4.00.00alpha
* **Leptonica Version**: leptonica-1.74.4
* **Platform**: CentOS 6.7
* **Server**: Wildfly 10.1

### Current Behavior:

**Error: Illegal Parameter specification!**
"Fatal error encountered!" == NULL:Error:Assert failed:in file globaloc.cpp, line 75

 A fatal error has been detected by the Java Runtime Environment:

  SIGSEGV (0xb) at pc=0x00007ff1b3098549, pid=25091, tid=0x00007ff29d7d7700

 JRE version: OpenJDK Runtime Environment (8.0_121-b13) (build 1.8.0_121-b13)
 Java VM: OpenJDK 64-Bit Server VM (25.121-b13 mixed mode linux-amd64 compressed oops)
 Problematic frame:
 C  [libtesseract.so+0x26f549]  ERRCODE::error(char const*, TessErrorLogCode, char const*, ...) const+0x129

 Failed to write core dump. Core dumps have been disabled. To enable core dumping, try "ulimit -c unlimited" before starting Java again

 An error report file with more information is saved as:
 /opt/wildfly/wildfly-10.1.0.Final/hs_err_pid25091.log

 If you would like to submit a bug report, please visit:
   http://bugreport.java.com/bugreport/crash.jsp
 The crash happened outside the Java Virtual Machine in native code.
 See problematic frame for where to report the bug.

*** JBossAS process (25091) received ABRT signal ***

### Suggested Fix:   
Any idea?
 I'm using the lastest source yet. I have the same Error (*) in two different OS. 

(*) Error: Illegal Parameter specification!
"Fatal error encountered!" == NULL:Error:Assert failed:in file globaloc.cpp, line 75 @Shreeshrii I'm using g++ 7.1.1 in Arch and 4.8.2 in CentOS 6.7.
I launch tesseract from Java. No problems with 3.05 version but I get the error previously commented with 4Alpha version.

`tesseract 4.00.00alpha`
` leptonica-1.74.4`
`  libgif 5.1.4 : libjpeg 8d (libjpeg-turbo 1.5.1) : libpng 1.6.29 : libtiff 4.0.8 : zlib 1.2.11 : libwebp 0.6.0
` No problems detecting langs with _tesseract --list_langs_ (eng, spa and osd trainned files for LSTM based 4.00.00alpha version).

About command line recognition, I have done fine an example from testing folder properly. 

Perhaps, some Java code has changed from this 4Alpha version? The problem with _3.05.01_ version is that I get different resutls from both OS using same Leptonica and Tesseract ver. in a PDF recognition.

Example:

 _0000 0340 **¬∫71¬∫** ZL_ (in CentOS) and _0000 0340 **0710** ZL_ (in Arch).

For that reason I'd like to improve the 4Alpha but it's impossible for the error commented some lines back. If you have an issue with a wrapper to Tesseract's C/C++ API, please report the issue to the developers of that software. >I'm using g++ 7.1.1 in Arch and 4.8.2 in CentOS 6.7.

>0000 0340 ¬∫71¬∫ ZL (in CentOS) and 0000 0340 0710 ZL (in Arch).



Ray said, many years ago, that you can get different results with different compilers. >Perhaps, some Java code has changed from this 4Alpha version?

Yes.
https://github.com/nguyenq/tess4j/commits/master Updated to the lastest libs from **Tess4J-3.4.0-src** I get same error when launch the OCR from Java code. 

From 3.05.01 version, is there any solution to solve the fail recognizing "zeros" ( ¬∫ instead of 0)? 3.4.0 does not include the 4.00 changes.
https://github.com/nguyenq/tess4j/commits/tess4j-3.4.0 >From 3.05.01 version, is there any solution to solve the fail recognizing "zeros" ( ¬∫ instead of 0)?

You can try to compile with a newer version of gcc. I can't promise that this 'solution' will help you with this issue. Ok, that's the problem? Tess4J-3.4.0 (Java) is not supported by 4.00Alpha release? Then I will try compilling with a newer version of GCC. >Ok, that's the problem? Tess4J-3.4.0 (Java) is not supported by 4.00Alpha release?

I assume that's the source of the problem (It's Tess4J 3.4.0 that seems to not have support for Tesseract 4.00, not vice versa). To be sure, ask the developer.

https://sourceforge.net/p/tess4j/discussion/1202294/
https://github.com/nguyenq/tess4j/issues tess4j's master branch is for Tesseract 4.0alpha and includes the latest Tesseract 4.0alpha Windows binary. All of its unit tests passed on Windows 10. We have not tested on Linux OS yet.

Since you link against Leptonica 1.74.4, make sure you use lept4j-1.6.0. Hi .. it seems you just have to add environment variable LC_NUMERIC="C" ... and it works. :) I dug into Tesseract's code and found that the string "Illegal Parameter specification" only exists in one place, namely in the file classify/clusttool.cpp. After some debugging I realised that the function ReadParamDesc() calls sscanf() at line 82 (for git commit hash 2b854e3749d62012787dd4160fc30e86603cc540), which is locale dependent. It fails since the numeric input (two floating point values) are written with dots (example: 1.23), but using a different locale other than en_US for LC_NUMERIC may cause sscanf() to expect other characters, like commas (1,23).

With other words, the error is in tesseract, assuming a locale. It should rather be set explicitly. The workaround is to set LC_NUMERIC=en_US.UTF-8. https://github.com/tesseract-ocr/tesseract/wiki/FAQ#error-illegal-min-or-max-specification
https://web.archive.org/web/20150510151209/http://code.google.com/p/tesseract-ocr/issues/detail?id=228
https://web.archive.org/web/20150509203443/http://code.google.com/p/tesseract-ocr/issues/detail?id=250

https://msdn.microsoft.com/en-us/library/wyzd2bce.aspx

https://en.cppreference.com/w/cpp/locale/setlocale

https://stackoverflow.com/questions/13919817/sscanf-and-locales-how-does-one-really-parse-things-like-3-14   Hello All,

I want to train tesseract as , But I got this error, Any help

------------------------

=== Starting training for language 'ara'
[2017. 06. 27. (Ìôî) 12:56:32 KST] /usr/local/bin/text2image --fonts_dir=/usr/share/fonts/ --font=Arial --outputbase=/tmp/font_tmp.F0ewTOCx0k/sample_text.txt --text=/tmp/font_tmp.F0ewTOCx0k/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.F0ewTOCx0k
Could not find font named Arial.
Pango suggested font FreeMono.
Please correct --font arg.

=== Phase I: Generating training images ===
Rendering using Arial
[2017. 06. 27. (Ìôî) 12:56:34 KST] /usr/local/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.F0ewTOCx0k --fonts_dir=/usr/share/fonts/ --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.9c8iwNnHC8/ara/ara.Arial.exp0 --font=Arial --text=../langdata/ara/ara.training_text
Could not find font named Arial.
Pango suggested font FreeMono.
Please correct --font arg.
ERROR: /tmp/tmp.9c8iwNnHC8/ara/ara.Arial.exp0.box does not exist or is not readable
ERROR: /tmp/tmp.9c8iwNnHC8/ara/ara.Arial.exp0.box does not exist or is not readable

  In 3.0,I get a list of choices,but in 4.0 just one,is it a bug?  ### Environment

Tesseract Version: <4.0>

Platform: <Ubuntu 14.04>

### Current Behavior:
I am wondering how the time steps(or to say the lstm cell numbers) for the LSTM unit is determined during the training process? If the width of the input image is various, though the summaring LSTM unit is used to collapse the Y-dimension into one,  but the width of the data can still be different values. 
So each iteration ,the LSTM is unrolled for img-width times? Or is there any scaling operation on the input image or any other func I am missing?

 @Shreeshrii As I understand, the summarizing lstm unit is to reduce the height of the input image, so that each time-step of the output sequence becomes a 64-d vector, with the image width (after conv and max-pool) as the length of the seqence. So in the training step, it's not possible to use batch since the width of the images in each batch can be differentÔºü  I think padding is added to each text line image to make each image the same width.
   I don't think this is related to Tesseract. The same sequence works for me on Debian Jessie and Stretch. Maybe a damaged local Leptonica build or installation? So 3.05 tries linking without the Leptonica library. That cannot work of course.

You used `LIBLEPT_HEADERSDIR`. I did not find it in the code, so I think that is without any effect. The other options for `configure`, namely `--with-extra-includes` and `--with-extra-libraries` should not be needed. Setting `PKG_CONFIG_PATH` should be sufficient if you have installed code in `/usr/local`. I try to avoid such extra settings because they are confusing: which installation of Leptonica is used? Therefore I usually install in `/usr` (see my packages at https://digi.bib.uni-mannheim.de/tesseract/leptonica/). I don't know what the breakage is.  In this thread I see the failure to load liblept in 3.05, which might have followed from the failure to find lept_free() for some reason.

@shreeshrii  you say it works for the master branch; for what version does it fail, and what is the failure? @Shreeshrii , please try these four commands:

    pkg-config --cflags lept
    pkg-config --libs lept
    PKG_CONFIG_PATH=/usr/local/lib/pkgconfig pkg-config --cflags lept
    PKG_CONFIG_PATH=/usr/local/lib/pkgconfig pkg-config --libs lept

Here is my output (only two commands, as I have no installation in `/usr/local`):

    $ pkg-config --cflags lept
    -I/usr/include/leptonica
    $ pkg-config --libs lept
    -llept

Your build output neither shows something like `-I/usr/local/include/leptonica` (for the C++ compiler) nor `-L/usr/local/lib -llept`, so I expect that you have a broken file `lept.pc` somewhere on your computer. The above test will check that. lept.pc.in  is from Jan 2016, and lept.pc.cmake is from Apr 22, 2017.

Neither have changed since 1.74.2, which was May 19, 2017.



On Tue, Jun 20, 2017 at 11:30 AM, Shreeshrii <notifications@github.com>
wrote:

> $ pkg-config --cflags lept
> -I/usr/local/include/leptonica
> $ pkg-config --libs lept
> -L/usr/local/lib -llept
> $ PKG_CONFIG_PATH=/usr/local/lib/pkgconfig pkg-config --cflags lept
> -I/usr/local/include/leptonica
> $ PKG_CONFIG_PATH=/usr/local/lib/pkgconfig pkg-config --libs lept
> -L/usr/local/lib -llept
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1000#issuecomment-309847263>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLPzjSF1578BlEDpRoP7yt0Bms9Ieks5sGA-vgaJpZM4N_xcO>
> .
>
 My 1.74.4 builds fine with autotools on linux.

I don't have a conftest.cpp file, and configure doesn't look for it.
Attaching my lept.pc (generated from lept.pc.in).
[lept.pc.txt](https://github.com/tesseract-ocr/tesseract/files/1089399/lept.pc.txt)

 @Shreeshrii, your `pkg-config` output looks good. I was surprised that `PKG_CONFIG_PATH` did not change the result. Have you set that as an environment variable, too?

Does the build work with my [3.05](https://github.com/stweil/tesseract/tree/3.05) (I just added a [backported commit](https://github.com/stweil/tesseract/commit/e7610d86c97de4c29777892465fc4c3bc77e8da8))? Sorry, the fix for `training/Makefile.am` was missing. Updated now. Try this:
`find /usr -name *lept*`
 You need to recompile Tesseract after you re-installed Leptonica ... or use `ldd /usr/local/bin/tesseract` to see which libraries are used by default. Maybe `LD_LIBRARY_PATH=/usr/local/lib /usr/local/bin/tesseract -v` gets the expected Leptonica version. > You need to recompile Tesseract after you re-installed Leptonica

In most cases this is not necessary, because typically Leptonica is not linked statically. That means Tesseract uses a shared library for Leptonica, and that library can be replaced by a newer one without harm (as long as there are no incompatible changes). >... (as long as there are no incompatible changes).

https://github.com/DanBloomberg/leptonica/issues/240 So it's using the Leptonica from `/usr/local` which claims to be leptonica-1.74.2. @shreeshrii  Is it worth doing a mini-postmortem on this?  Just a couple of paragraphs on what went wrong and what we might do to prevent this from happening again. @shreeshrii

Thanks!  Very nice summary.

We have several ways to build tesseract and the associated libraries.
An embarrassment of riches, as the French would say (except
in their own way).

It seems to me that the current suggestions in the leptonica
README.html for building with autotools are still valid.
It also references the documentation in
     https://github.com/tesseract-ocr/tesseract/wiki/Compiling
and I see that you updated that page 2 weeks ago.  Would
you make any further changes there?


On Wed, Jun 21, 2017 at 12:08 PM, Shreeshrii <notifications@github.com>
wrote:

> @DanBloomberg <https://github.com/danbloomberg>
>
> I usually update leptonica by using the following script in the leptonica
> directory.
>
> #!/bin/bash
> git pull origin
> ./autobuild
> ./configure --disable-dependency-tracking
> #./configure
> make
> sudo make install
> sudo ldconfig
>
> I follow a similar build script for tesseract master branch for building
> 4.0.
>
> Based on an error report in the forum, I tried building 3.05.01 and
> received the error related to lept_free (reported above).
>
> As part of the experimentation, I did a hard reset in leptonica directory
> at one time to get to the commit for 1.74.2 and built leptonica and
> tesseract 3.05.01 after that without any problem.
>
> @stweil <https://github.com/stweil> then backported a couple of commits
> to tesseract 3.05.01 branch to fix the problem regarding lept_free() and I
> rebuilt leptonica with the latest source and then built tesseract 3.05.01.
> It built without the lept_free error.
>
> It is possible that I did not build leptonica using the script which does
> autobuild and configure, but rather just did
>
> git pull origin
> make
> sudo make install
>
> I also built tesseract 4.0 from master branch after that. I noticed in
> both of these, that leptonica version was reported as 1.74.2.
>
> After following Amit and Stefan's suggestions to see whether I had
> multiple versions of files causing the older version to display, I decided
> to rebuild leptonica again. This time I did make distclean in leptonica
> directory before running the build script.
>
> Then without needing to rebuild tesseract, tesseract -v showed that it
> was using leptonica 1.74.4.
>
> @amitdo <https://github.com/amitdo> So, as mentioned by Stefan, it is not
> necessary to rebuild tesseract to use the newer leptonica library.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1000#issuecomment-310176024>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLD_tbdPGJyKbdREo7_bUNgEsi53Sks5sGWozgaJpZM4N_xcO>
> .
>
 Actually, the page I referred to looked pretty good, and I was just
referring to the small section on constraints for compiling leptonica.

On Fri, Jun 23, 2017 at 3:39 AM, Shreeshrii <notifications@github.com>
wrote:

> he wiki pages are public and have been updated by different people at
> different times. I did update the Compiling wiki page with the needed
> leptonica version recently.
>
> There are multiple Install/Compiling instructions.
> I think that https://github.com/tesseract-ocr/tesseract/blob/master/
> INSTALL.GIT.md is better.
>
> I will try to streamline the compiling page - maybe delete duplicated info
> and refer to the installation page instead. However, it will require review
> by @stweil <https://github.com/stweil> @egorpugin
> <https://github.com/egorpugin> and @zdenop <https://github.com/zdenop> .
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1000#issuecomment-310633374>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLIm9-ICPyTO9xz1Q9Iywm5uT3W06ks5sG5XfgaJpZM4N_xcO>
> .
>
 I seem to be hitting the problem too - trying to add in a cross compile for powerpc into our travis build setup, building leptonica first and then tesseract and I seem to be hitting this same issue no matter what I try, if I use 3.0.5.01 download. If I pull latest straight from git, it compiles fine. Also builds fine for android, mac, windows, probably even native ppc. 

@Shreeshrii you mention some backports to 3.0.5.1, could you help with any details on those? I looked through the commit log but from a quick look from around Jun I didn't spot anything immediately obvious. I'm wondering if its something I can apply as a patch, just that pulling a non-release version usually ends up with headaches down the road >git clone -q --branch=3.05 https://github.com/tesseract-ocr/tesseract.git tesseract-3.05

This will fetch https://github.com/tesseract-ocr/tesseract/tree/3.05, but the latest 3.05.x is 3.05.1: https://github.com/tesseract-ocr/tesseract/tree/3.05.01

Currently, version 4.0 still has the legacy engine from 3.0x (plus the new LSTM engine).
It can be used with the 3.05/3.04 traineddata files (--oem 0 or --oem 3).  ### Environment

* **Tesseract Version**: 4.00.00alpha
* **Platform**: Ubuntu Docker image

### Current Behavior:
When I give it the following image, the text detection is really bad.
![frame_24721](https://user-images.githubusercontent.com/3123549/27284702-2f5ab268-54fa-11e7-912c-02f3cd629704.png)

It outputs the following:

```
Warning. Invalid resolution 0 dpi. Using 70 instead.
## Parancters
= buser¬Æ = A User struct.

## Examples



user = MUser{nanes "Alice Winston}
User. first. nane(user)

"Mice"



def first_name(user) do
user

17 Bout
1¬∞ first
end

adec !
Get the last name of a user.





## Parancters

'user¬Æ - A User struct.

enero oE \ s |

```

### Expected Behavior:

It outputs the correct text.

### Suggested Fix:

I don't know how Tesseract works in its core but the image contains clear and readable characters, even in English. Yeah, that's a lot better. Thank you! @Shreeshrii What have you used to preprocess the image? I tried it with imagemagick but the result isn't quite good and therefore the OCR result too. @Shreeshrii The best I can get is this:

![frame_24721-2](https://user-images.githubusercontent.com/3123549/27321677-64de42d2-559b-11e7-8d3a-f405b18d5fbf.png)

Using this command:
```
convert -units PixelsPerInch input.png -resize 1200 -density 300 -colorspace gray -depth 1 -negate output.png
```

Not sure if imagemagick can do better.  It would be good to decide about using semantic versioning soon. Maybe it can be used for the next tag. We could tag the current release as a pre-release or as a release candidate. According to [semver.org](http://semver.org/#spec-item-9), it could be called something like `4.0.0-rc.1` (that's how semver.org named its own releases), `4.0.0-beta.1` or `4.0.0-beta.20170619`. @theraysmith, can you give us an update on your work? When are we going to see it? Hi, same: can you give us an update on your work? When are we going to see 4.0 released? +1 for a new tag.

Since Ray does not reply, I suggest to still use 'alpha'.

`4.0.0-alpha.YYYYMMDD` @zdenop, can you do it, or at least add your comment here? Superb. Anything we could do to help you ? Cheers. > I'm about ready to update the traineddatas.

That's good news.

> The above change makes open source training impossible.

If I got that right, it would be horrible. Being able to create new traineddata is essential for me. >The new traineddatas will mostly be smaller than the older ones, as they
won't contain the legacy components, and no bigram dawgs are needed.

Will you remove the **code** of the legacy engine in this round? > 2 parallel sets of tessdata. "best" and "fast". "Fast" will exceed the speed of legacy Tesseract in real time, provided you have the required parallelism components, and in total CPU only slightly slower for English. Way faster for most non-latin languages, while being <5% worse than "best" Only "best" will be retrainable, as "fast" will be integer.

@theraysmith, thanks for providing "fast" now. Are you planning to release free documentation / tools for everybody to produce "fast" data? I noticed that apart from the LSTM model the rest of the traineddata files for "best" and "fast" are identical. Wouldn't it save space and make the handling easier if both variants were in the same traineddata container (this requires an option to select the desired one, of course) instead of having two parallel sets? Jeff, see this comment:
https://github.com/tesseract-ocr/tesseract/issues/1131#issuecomment-329764356 >1.7G	best
657M 	fast

Jeff, playing with the numbers?
:-)
[He changed the numbers in his comment] ‚Äãbut its size is very different and dont follow an unique pattern..


tessdata_fast/eng.traineddata  3.9mb
tessdata_best/eng.traineddata 14.7


tessdata_fast/ara.traineddata  1.4mb
tessdata_best/ara.traineddata  12mb
  ‚Äã

‚Äãwhat can effect the fast traindata size ?1‚Äã
 @roozgar, it is possible to extract the parts of a traineddata file using `combine_tessdata -u traineddata_file output_path_prefix`. Usually the largest parts are the LSTM model and the word list, but not all languages have a huge word list like `eng.traineddata` or `Latin.traineddata`.
 >‚Äã @amitdo I can't seem to write a single comment without editing it three times to fix mistakes.

LOL. It happens to me too. I keep discovering mistakes **after** I post a comment. Thank you! Hi everybody, so what are now the remaining tasks in order to release Tesseract 4.0.0 ?  USE_OPENCL should be turned off in CMAKE if OpenCL is not found. Also, potentially should be enabled by default if it is found unless there are reasons otherwise. CC: @egorpugin Adding USE_OPENCL by default would be a bad idea. The OpenCL code is still buggy and does not improve the performance very much (or even not at all). Only developers who know what they are doing should use it. Should this issue be closed then? IMO, there's no point to keep it open if nobody going to do something about it. I see no need to keep it open.  Hi,

while i was training the LSTM through this command
`lstmtraining -U ~/tesstutorial/jpntrain/jpn.unicharset \
  --script_dir /home/ibr/langdata --debug_interval 0 \
  --continue_from   tesstutorial/jpn.lstm \
  --append_index 5 --net_spec '[Lfx256 O1c105]' \
  --model_output /home/ibr/tesstutorial/new_jpn_lstm \
  --train_listfile ~/tesstutorial/jpneval/jpn.training_files.txt \
  --eval_listfile ~/tesstutorial/jpntrain/jpn.training_files.txt \
  --max_iterations 5000 &>~/tesstutorial/basetrain.log`

it went fine and started the iterations until the iteration 900 it gave the error:

![lstm dumping](https://user-images.githubusercontent.com/26926171/27182531-27761344-51e4-11e7-889e-ae91bad36f3a.png)

although the error came, it created checkpoint file, I'm using Tesseract 4.00alpha, leptonica 1.74.1 and OS is Ubuntu 14.04

i got the command from this [website](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Replace-Top-Layer)

any ideas?


 i installed and compiled both leptonica 1.74.2 and latest tesseract and ran the command but i got the following error:
![lstm2](https://user-images.githubusercontent.com/26926171/27259772-53c203ea-5423-11e7-85d1-359dab2c2fbe.png)

as you can see, this deserialization error is different from the one that i got  #992

 its not saying that the header deserialization failed, so what does that mean? and the path is correct thanks for the response, i modified the path yet i deserialization fails, but as you can see that error has gone
`ibr@ubuntu:~/leptonica-1.74.2/tesseract$ training/lstmtraining -U ~/tesstutorial/jpntrain/jpn.unicharset \
>   --script_dir /home/ibr/leptonica-1.74.2/langdata --debug_interval 0 \
>   --continue_from   /home/ibr/tesstutorial/jpn.lstm \
>   --append_index 5 --net_spec '[Lfx256 O1c105]' \
>   --model_output /home/ibr/tesstutorial/engtrain2 \
>   --train_listfile ~/tesstutorial/jpneval/jpn.training_files.txt \
>   --eval_listfile ~/tesstutorial/jpntrain/jpn.training_files.txt \
>   --max_iterations 5000
Loaded file /home/ibr/tesstutorial/jpn.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from /home/ibr/tesstutorial/jpn.lstm
Appending a new network to an old one!!Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Setting properties for script Katakana
Setting properties for script Hiragana
Setting properties for script Han
Warning: given outputs 105 not equal to unicharset of 546.
Num outputs,weights in serial:
  Lfx256:256, 394240
  Fc546:546, 140322
Total weights = 534562
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc546] from request [Lfx256 O1c105]
Training parameters:
  Debug interval = 0, weights = 0.1, learning rate = 0.0001, momentum=0.9
Deserialize failed: /home/ibr/tesstutorial/jpneval/jpn.HGGothicE.exp0.lstmf read 0/1670 pages`

NOTE: the terminal freezes after running this command, until i stop the command by "Ctrl C" @Shreeshrii  actually I switched back to liptonica 1.74.1 and started fine tuning since I decided I need the old unicharset and I just want to add layers to existing lstm file, so I needed to finish this task ASAP and as you know fine tuning takes many days, so I didn't have the chance to try your solution which is creating lstmf by the latest tesseract as it requires installation and compiling and the machine is already occupied by the tuning.
BUT since I don't need to create from scratch anymore I can close this issue, so if its fine by you I will close it, reply back to me for the next action.
Thanks  Hi,

while following the steps in this [website](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Replace-Top-Layer) i got an error at the second step which was as the following:-

![lstm](https://user-images.githubusercontent.com/26926171/27178963-2b27410c-51d5-11e7-861a-1ccc7b075405.png)

what does that mean? also how to solve this problem?, so i can continue with the training

NOTE: im using tesseract 4.00.00alpha with leptonica 1.74.1, also all LSTMFs and the used files were created on Ubuntu 14.04 correct, the path at the training_files.txt was wrong, thanks  win8.1 64bit tesseract 4.0.0alpha  leptonica-1.74.2 (Jun  6 2017, 21:45:59) [MSC v.1910 LIB Release x64]

the reslut always contains extra spaces between character when using oem LstmOnly or TesseractAndLstm, oem TesseractOnly works normally but the result is bad. 


![image](https://user-images.githubusercontent.com/10088733/27135386-f6cd87b6-514a-11e7-85ce-4d825f14f471.png)

oem:  Default  psm: SingleLine  time: 114 ms.  result: ‰º¶ Êï¶ Ê•º Êàø Âèë Áîü ÁÅ´ ÁÅæ ‰∏≠ ‰Ωø È¶Ü ÂÖ≥ Ê≥® : ÊöÇ Êó† ‰∏≠ ÂõΩ ÂÖ¨ Ê∞ë Âèó ‰º§

oem:  TesseractOnly  psm: AutoOsd  time: 518 ms.  result:  ‰º¶Êï¶Â§∫ÂßîÊàøÂèëÁîüÁÅ´ÁÅ´‰∏≠‰ΩøÈ¶ÜÂ§ßÊ±™ ‰∫å ÊöÇÊó†‰∏≠ ` Âèà‰º§



 


[result_lines_chi.txt](https://github.com/tesseract-ocr/tesseract/files/1074793/result_lines_chi.txt)



 @zdenop  @Shreeshrii @stweil 
can you guys give me some advice about  this ? thx. I've also tested jpn and kor images , the results have similar problem.
there might be something wrong related to LSTM engine or its parameter. sorry for my bad english
in my case Japanese  and OCR mode set to LTSM may by related .
i'm try to get single char only by using ResultIterator but sometimes final char in word doesn't have right coordinate. if change OCR mode to Tesseract Only it's okay.
Example :
Â§ßÈò™Ê†™Âºè‰ºöÁ§æ 
[debug] -Char value = Â§ß left= 16 top = 243 right = 68 bottom = 295 conf = 99
[debug] -Char value = Èò™ left= 75 top = 244 right = 128 bottom = 295 conf = 99
[debug] -Char value = Ê†™ left= 130 top = 244 right = 185 bottom = 296 conf = 99
[debug] -Char value = Âºè left= 190 top = 243 right = 281 bottom = 296 conf = 99
[debug] -Char value = ‰ºö left= 306 top = 243 right = 362 bottom = 296 conf = 99
[debug] -Char value = Á§æ left= 2214 top = 2991 right = 2214 bottom = 2991 conf = 99
 great, it works. Actually I noticed this variable, but I misunderstood and set it to false, definitely it doesn't work as expected. ~_~
> SetVariable("preserve_interword_spaces", false); @Shreeshrii  can you  help me ? i'm get wrong coordinate for last char in word. Thanks!  Hi,

while i made some Images Recognition for the Japanese language i found that the resulted Japanese text has different spacing between its characters, i have no background in Japanese but in the original documents or images the spacing is different meaning some times its more like spaces between English letters and other times the space similar to the space between English words, while in the resulted text all spaces are similar between all characters.

Thanks @Shreeshrii  Thanks Hi,

just adding information, this `-c preserve_interword_spaces=1` argument works good with Japanese (i didn't try it with English) but for Arabic its better not to use it, since the Arabic language has Cursive  writing system, so i detected a text with both cases, with the argument and without it, when i used the argument for Arabic some of the words were detected correctly but are joined to the next word which is incorrect, but without that argument the same words didn't  join to the next word which is correct   What's the point of this option?


Libtool Convenience Libraries
https://www.gnu.org/software/automake/manual/automake.html#Libtool-Convenience-Libraries

https://github.com/tesseract-ocr/tesseract/commit/bf4a09d72a
https://github.com/tesseract-ocr/tesseract/commit/67f47008c

 CC: @jimregan >IMO it does not make sense

That's exactly what I thought. and thus opened this issue.

 >I think it should go away

:+1: 
  ### Environment
Version: 4.00.00alpha, from [here](https://github.com/tesseract-ocr/tesseract/releases/tag/4.00.00alpha)
`uname -a` output: Linux T1 4.4.0-21-generic #37-Ubuntu SMP Mon Apr 18 18:33:37 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

### Current Behavior:
Running two or more programs which all attempt to process images with Tesseract seems to lock up all programs indefinitely.

### Expected Behavior:
Running two or more programs involving Tesseract would not block all programs from executing.

### Suggested Fix:
I don't actually know enough about the codebase itself to to suggest a fix, but would be interested in more information or a workaround. This actually has nothing to do with training though, just evaluation with the LSTM. I'm running on an Ubuntu 16 VM which has 16GB RAM from the host and 4 cores, so I doubt it has anything to do with the hardware. I'll try the latest code and see what happens The problems which we observed with training also exist for the tesseract ocr process. It uses multithreading causing a significant overhead for thread synchronisation. Your 4 cores will be sufficient for a single tesseract process, but if you run more than one, the effects which you have seen are not surprising.

Disabling OpenMP and the related multithreading would help for your case. Use `configure --disable-openmp`. Then I expect that you will be able to run up to four tesseract processes simultaneously. Thanks @stweil and @Shreeshrii. Will disabling OpenMP affect processing time in a negative way though? For example, if I'm only running one process using Tesseract, will it run more slowly with OpenMP disabled? It sounds like there must be some kind of tradeoff here Yes, for a single process disabling OpenMP will increase the run time ‚Äì not by a factor 4, but maybe 2. You'll have to try it yourself.  Great, I'll give that a shot and see what happens. Thanks again for the support, closing now  Hi,

I wanted to install and compile leptonica and then tesseract on a server following this [website](https://medium.com/@lucas63/installing-tesseract-3-04-in-ubuntu-14-04-1dae8b748a32)
i installed and downloaded leptonica 1.74.1 and tesseract 4.00.00alpha on VM and VB before following the same steps exactly, yet today i found this error coming out on the terminal
![env_error](https://cloud.githubusercontent.com/assets/26926171/26831244/5b97d520-4ad4-11e7-9a87-bf86bc754e79.png)

i tried to comment the error section but that caused another problems, i even tried to get the leptonica.gz again and running the steps once more, yet the same problem.

keep in mind that the OS on the server is Ubuntu 14.04, which is the same OS that i used on VM and OS on VB and worked on both cases, is this issue cause by a dependency or what exactly?
Please any ideas? as i need to get the server up and running as soon as possible
Thanks thanks, but what is the command to get the newer version, its not:
wget http://www.leptonica.com/source/leptonica-1.74.2.tar.gz

and is it an alpha version too or a full release?
and would  the compilation for it be same as 1.74.1 ? According to the snapshot, your Leptonica build fails. Then that's unrelated to Tesseract, isn't it? @Shreeshrii same problem has occurred with Leptonica 1.74.2, it i feel its kind of a compiler issue, isn't it?
@stweil yes you are right, the compilation of the leptonica has failed, and i couldn't continue to install tesseract
@zdenop i really didn't know why you have closed this issue before i even got the chance to try what was suggested by shree??!! at least if something is wrong with the question, or its irrelevant to this group at least mention that in a comment then close it !!!!! :(



  The newer version contains fixes for the pixUnsharpMaskingGray*
functions which are relevant for Tesseract (used in ImageData::PreScale
which calls pixScale).

Signed-off-by: Stefan Weil <sw@weilnetz.de> See [Dan's comment](https://github.com/tesseract-ocr/tesseract/issues/644#issuecomment-306073620) for issue #644. Should we refuse builds with Leptonica < 1.74.2? Then additional changes for `CMakeLists.txt` and `configure.ac` would be needed. The newer version not only fixes problems with undefined memory for `lstmtraining`, but also for `tesseract --oem 1`:

With Leptonica 1.74.1:

    $ valgrind bin/ndebug/x86_64-linux-gnu/api/tesseract --oem 1 ~/Bilder/ocr/hello_world.png /tmp/hello
    ==21183== Memcheck, a memory error detector
    ==21183== Copyright (C) 2002-2015, and GNU GPL'd, by Julian Seward et al.
    ==21183== Using Valgrind-3.12.0.SVN and LibVEX; rerun with -h for copyright info
    ==21183== Command: bin/ndebug/x86_64-linux-gnu/api/tesseract --oem 1 /home/stweil/Bilder/ocr/hello_world.png /tmp/hello
    ==21183== 
    ==21183== Conditional jump or move depends on uninitialised value(s)
    ==21183==    at 0x4ECF07A: nextOnPixelInRasterLow (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4ECF29F: nextOnPixelInRaster (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4ED03A9: pixConnCompBB (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4E8B8DC: ??? (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4E8C021: ??? (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4E8CABA: bmfCreate (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x1710B8: DebugPixa (debugpixa.h:15)
    ==21183==    by 0x1710B8: tesseract::Tesseract::Tesseract() (tesseractclass.cpp:623)
    ==21183==    by 0x11F99B: tesseract::TessBaseAPI::Init(char const*, int, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, bool (*)(STRING const&, GenericVector<char>*)) (baseapi.cpp:320)
    ==21183==    by 0x11FE25: tesseract::TessBaseAPI::Init(char const*, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool) (baseapi.cpp:284)
    ==21183==    by 0x116273: main (tesseractmain.cpp:440)
    ==21183== 
    ==21183== Conditional jump or move depends on uninitialised value(s)
    ==21183==    at 0x4ECF12E: nextOnPixelInRasterLow (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4ECF29F: nextOnPixelInRaster (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4ED03A9: pixConnCompBB (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4E8B8DC: ??? (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4E8C021: ??? (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4E8CABA: bmfCreate (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x1710B8: DebugPixa (debugpixa.h:15)
    ==21183==    by 0x1710B8: tesseract::Tesseract::Tesseract() (tesseractclass.cpp:623)
    ==21183==    by 0x11F99B: tesseract::TessBaseAPI::Init(char const*, int, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, bool (*)(STRING const&, GenericVector<char>*)) (baseapi.cpp:320)
    ==21183==    by 0x11FE25: tesseract::TessBaseAPI::Init(char const*, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool) (baseapi.cpp:284)
    ==21183==    by 0x116273: main (tesseractmain.cpp:440)
    ==21183== 
    Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
    ==21183== 
    ==21183== HEAP SUMMARY:
    ==21183==     in use at exit: 3,360 bytes in 7 blocks
    ==21183==   total heap usage: 653,804 allocs, 653,797 frees, 143,432,299 bytes allocated
    ==21183== 
    ==21183== LEAK SUMMARY:
    ==21183==    definitely lost: 0 bytes in 0 blocks
    ==21183==    indirectly lost: 0 bytes in 0 blocks
    ==21183==      possibly lost: 912 bytes in 3 blocks
    ==21183==    still reachable: 2,448 bytes in 4 blocks
    ==21183==         suppressed: 0 bytes in 0 blocks
    ==21183== Rerun with --leak-check=full to see details of leaked memory
    ==21183== 
    ==21183== For counts of detected and suppressed errors, rerun with: -v
    ==21183== Use --track-origins=yes to see where uninitialised values come from
    ==21183== ERROR SUMMARY: 169 errors from 2 contexts (suppressed: 0 from 0)

With Leptonica 1.74.2:

    $ valgrind bin/ndebug/x86_64-linux-gnu/api/tesseract --oem 1 ~/Bilder/ocr/hello_world.png /tmp/hello2
    ==22040== Memcheck, a memory error detector
    ==22040== Copyright (C) 2002-2015, and GNU GPL'd, by Julian Seward et al.
    ==22040== Using Valgrind-3.12.0.SVN and LibVEX; rerun with -h for copyright info
    ==22040== Command: bin/ndebug/x86_64-linux-gnu/api/tesseract --oem 1 /home/stweil/Bilder/ocr/hello_world.png /tmp/hello2
    ==22040== 
    Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
    ==22040== 
    ==22040== HEAP SUMMARY:
    ==22040==     in use at exit: 3,360 bytes in 7 blocks
    ==22040==   total heap usage: 653,807 allocs, 653,800 frees, 143,423,100 bytes allocated
    ==22040== 
    ==22040== LEAK SUMMARY:
    ==22040==    definitely lost: 0 bytes in 0 blocks
    ==22040==    indirectly lost: 0 bytes in 0 blocks
    ==22040==      possibly lost: 912 bytes in 3 blocks
    ==22040==    still reachable: 2,448 bytes in 4 blocks
    ==22040==         suppressed: 0 bytes in 0 blocks
    ==22040== Rerun with --leak-check=full to see details of leaked memory
    ==22040== 
    ==22040== For counts of detected and suppressed errors, rerun with: -v
    ==22040== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
 Tesseract cmake builds are broken with Leptonica 1.74.2 because Leptonica now requires an installation: the `Leptonica_INCLUDE_DIRS` refer to /usr/local/include. Therefore Travis CI fails. @egorpugin, how should we fix that?  The new test in LSTMTrainer::UpdateErrorGraph fixes an assertion
(see issues #644, #792).

The new test in LSTMTrainer::ReadTrainingDump was added to improve
the robustness of the code.

Signed-off-by: Stefan Weil <sw@weilnetz.de> @zdenop, please merge before more people get this assertion.  Hello,
I was trying to get the text of the image i am providing bellow (i am using extract_text before the apply of tesseract) and i wanted to get the result of fitting room above which is very clear and in white background with black letters. I didnt get that result on the output file so i tried to cut only that part of the image and use the tesseract and i got the result i was looking for. Probably there is a bug how tesseract is detecting the edges, any helpful information about this?
![18870210_10155396251410842_855716923_o](https://cloud.githubusercontent.com/assets/28709382/26761770/3dbb29a2-4936-11e7-992d-9f27c2255770.jpg)
  Currently, when someone opens a new issue he see this above the title text input field:

Before you submit an issue, please review the [guidelines](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md) for this repository.

The problem is that many people are either not noticing or ignoring this 'banner'.

Any reason to not have a link to this page instead of the other links?  The new README.md can be seen [here](https://github.com/Shreeshrii/tesseract).  Attached are two images, one with the word Keyword, and the other with a random string. The file with the word Keyword outputs an accurate result (Keyword). The second file though outputs something very odd: `"'EÔ¨Ç'f√©'i'ibiboss`

Any idea why? The second picture is the result of someone taking a photo of a serial number, which is what i am trying to achieve in my app. The Keyword image is a screenshot from the web, so it is perfectly skewed with a white background. Was I wrong in assuming that ocr could accurately determine the text in the second photo?

<img width="100" alt="ocrtest" src="https://cloud.githubusercontent.com/assets/1245462/26419801/dd4dfa72-408e-11e7-8115-e29b35beb05a.png">

<img width="100" alt="ocrtest" src="https://cloud.githubusercontent.com/assets/1245462/26419800/dd4dad74-408e-11e7-97a2-e9892bd73fcb.png">

 Thanks @Shreeshrii, I will move to the forum, my apologies I am new to this technology!   Hi,
I am using 3.04.00 version of tesseract and try to execute the command TesseractConsole.exe .\test_Thai.tif "<PATH>\html" "-l tha"+"<PATH>\html.txt".
It takes too long to generate the html.txt file with the data.
Note: I have picked up the trained data from : https://github.com/tesseractocr/tessdata/blob/master/tha.traineddata

Thanks,  According to your report the problem started with commit 6dd871bfb6c3

The commits after that commit are just documentation fixes.


 Shree, did you run those tests with WSL? Same test on Linux with git master, debug build:

    2 Percent improvement time=0, best error was 100 @ 0
    At iteration 0/500/500, Mean rms=0.162%, delta=0%, char train=0.009%, word train=0.033%, skip ratio=0%,  New best char error = 0.009Deserialize failed wrote best model:/home/stweil/tesstutorial/engtuned_from_engtest/engtuned0.009_0.lstm wrote checkpoint.

    Finished! Error rate = 0.009

    real	2m7,797s
    user	7m10,384s
    sys	0m2,156s

Test machine: Intel(R) Xeon(R) CPU E3-1240 v5 @ 3.50GHz.
I had to fix the assertion issue first. I currently think that the timing regression is related to bug #644. @Shreeshrii, could you please try git master with the patch shown there? https://stackoverflow.com/questions/556405/what-do-real-user-and-sys-mean-in-the-output-of-time1 The fact that the 'user' time is a few times longer than the 'real' time is expected with multi core CPU and OpenMP enabled.

However, the fact that the real time with or without OpenMP is roughly the same is not expected. See also [my comment](https://github.com/tesseract-ocr/tesseract/issues/943#issuecomment-304132980) in the RFC on performance. Even on Linux, OpenMP requires a large percentage of additional CPU time. That's why Tesseract with OpenMP is not much faster in the "real" time, but uses much more "user" and "sys" time. On Windows the situation gets worse because thread switching for OpenMP seems to be slower than on Linux. A dual core CPU will produce a very high overhead when OpenMP with four or more threads is used, so yes, disabling OpenMP might help. The Tesseract code could also be improved with OpenMP enabled: it could set the number of threads at run time, either based on user's choice (command line parameter) or based on the number of available CPU cores. Set a higher "nice factor" for Tesseract, in this situation? It's normal that programs like `lstmtraining` which mostly do computation use all of the CPU which they can get, so 99 % is good (as long as it is spent for training, not for busy waits during thread scheduling :-)). And running it as `nice lstmtraining` is a good idea if the same computer is also used by other processes / users.  They do not work for me. I've been trying versions: 3.05.00 and 4.00.00alpha.
My file date.user-pattern contains one line:
2014-\d\d-\d\d
Picture is one line with date, like: 2014-03-19
I run: tesseract img.jpg stdout --user-patterns date.user-patterns -psm 8
and output: "mum-w" which obviously does not match the pattern. 
Character whitelisting helps a bit, but format from pattern is not preserve and accuracy is poor.
I also tried some other examples - does not work either.
Many people have the same problem, aggregated links under this one:
https://stackoverflow.com/questions/34560697/tesseract-ocr-user-patterns
also #403
Should we assume that this feature does not work at all? Is there any official comment on this? Same problem with user dictionary:
`tesseract H3.png stdout --user-patterns date.user-patterns --psm 8 --user-words date.user-words -c language_model_penalty_non_dict_word=9999999999999999999 --oem 0
`I tried different language_model_penalty_non_dict_word values with no luck
Related #297, which is closed, so I assume the feature doesn't work. I think it would be better for users if those flags are removed from command line and configurations, because it is misleading as long as they don't affect engine. No, sorry, I never used that option. Nevertheless I also have a [scenario](https://av.tib.eu/media/21360) where working user patterns would help. >No, sorry, I never used that option.

Same answer. User patterns are documented in [`doc/tesseract.1.asc`](https://github.com/tesseract-ocr/tesseract/blob/master/doc/tesseract.1.asc#config-files-and-augmenting-with-user-data) and in [`dict/trie.h`](https://github.com/tesseract-ocr/tesseract/blob/master/dict/trie.h#L193). With 4.0 the problem might be that the Dict class is instantiated twice
```
tesseract::Dict::Dict(tesseract::CCUtil * ccutil)
tesseract::Classify::Classify()
tesseract::Wordrec::Wordrec()
tesseract::Tesseract::Tesseract()
tesseract::TessBaseAPI::Init(...)
```
and then here
```
tesseract::Dict::Dict(tesseract::CCUtil * ccutil)
tesseract::LSTMRecognizer::LoadDictionary(const char * lang, tesseract::TessdataManager * mgr)
tesseract::LSTMRecognizer::Load(const char * lang, tesseract::TessdataManager * mgr)
tesseract::Tesseract::init_tesseract_lang_data(...)
tesseract::Tesseract::init_tesseract_internal(...)
tesseract::Tesseract::init_tesseract(...)
tesseract::TessBaseAPI::Init(...)

```
and both initialise 
https://github.com/tesseract-ocr/tesseract/blob/master/dict/dict.cpp#L43

The real problem is that variables are set between these calls so LSTM dict does not get the value from user defined variables. Does this issue only happen on the command line executable? I mean I can workaround this issue by writing some C++ source file to directly call the API? Thanks.  Hi Ray,

I'm going to compare different OCR engines on University of Washington (UW3) dataset.

Did you use the UW3 dataset during training your LSTM model? If so, the comparison will be useless.

Thanks. >Did you use the UW3 dataset during training your LSTM model?

I'm not Ray, but AFAIK the answer is NO.

What are the other OCR engines in your comparison?
 Hi Amit,

Thanks for the answer.

I'm going to compare the following OCR engines:
1) Tesseract 4
2) Tesseract 3
3) ABBYY Cloud OCR SDK
4) Microsoft Computer Vision API
5) Google Cloud Vision API @vaasily, what were the results of your comparison?  The accuracy of Nepali trainned data is low is some documents. Whole line is recognized as a single word and recognized text seems to be just a string of random character. Here is sample -  

Original Image:
![tess_recog_nep](https://cloud.githubusercontent.com/assets/10336295/26553903/679ae88a-44ad-11e7-9402-f81e6714d386.png)

Recognized Text:
‡§π‡§∏‡•á‡§∞‡•à ‡§¨‡§ø‡§¶‡§æ ‡§ó‡§∞‡•ç‡§õ‡•Å ‡§≠‡§®‡•ç‡§•‡•á ‡§§‡§ø‡§Æ‡•Ä‡§≤‡§æ‡§à
‡§§‡§∞‡§Æ‡§ï‡•ç‡§ï‡§æ‡§®‡§∞‡•ç‡§ï‡•ç‡§∏‡§ü‡•ç‡§ü‡•á‡§∞‡§æ‡§∏‡§∞‡•ç‡§Ø‡•ã||
‡§∞‡•ã‡§ï‡•ç‡§ï‡§≠-‡§∂‡•á‡§Ø‡•Ä‡§Æ‡§®‡§∂‡•ç‡§∞‡§ø‡§§‡•ç‡§∞‡§Æ‡§°‡§æ‡§∞‡§ø‡§è‡§ï‡§æ‡§¨‡§æ‡§¶‡§≤‡§≤‡§æ‡§à‡§Ç
‡§§‡§∞‡§Ü‡§∂‡§¨‡§®‡•Ä‡§¨‡§∞‡•ç‡§∏‡§ø‡§ï‡•ç‡§µ‡§ø‡§∞‡•à||

Real Text:
‡§π‡§∏‡•á‡§∞‡•à ‡§¨‡§ø‡§¶‡§æ ‡§ó‡§∞‡•ç‡§õ‡•Å ‡§≠‡§®‡•ç‡§•‡•á ‡§§‡§ø‡§Æ‡•Ä‡§≤‡§æ‡§à
‡§§‡§∞ ‡§Æ‡•Å‡§∏‡•ç‡§ï‡§æ‡§® ‡§ï‡§§‡•à ‡§°‡•á‡§∞‡§æ ‡§∏‡§∞‡•ç‡§Ø‡•ã ||
‡§∞‡•ã‡§ï‡•ç‡§õ‡•Å ‡§≠‡§®‡•ç‡§•‡•á ‡§Ø‡•Ä ‡§Æ‡§®‡§≠‡§ø‡§§‡•ç‡§∞ ‡§Æ‡§°‡§æ‡§∞‡§ø‡§è‡§ï‡§æ ‡§¨‡§æ‡§¶‡§≤‡§≤‡§æ‡§à
‡§§‡§∞ ‡§Ü‡§∂‡•Å ‡§¨‡§®‡•Ä ‡§¨‡§∞‡•ç‡§∏‡§ø‡§¶‡§ø‡§Ø‡•ã || I have used - https://github.com/tesseract-ocr/tessdata/blob/master/nep.traineddata Thank you very much. LSTM only mode (--oem 1) perform better than Tesseract + LSTM (--oem 2) mode. 

I faced issues in recognizing mostly the Italicized text. And have little difficulties with bold faced text. Is there any way to tackle them?  If you build and install leptonica from a source, then libleptonica.so is created, but not liblept.so
However tesseract ./configure scripts requires liblept.so:
```
(...)
checking for leptonica... yes
checking for pixCreate in **-llept**... no
configure: error: leptonica library missing

```
As a workaround I just link liblept.so to created libleptonica.so, but I belive that tesseract scripts should recognize if we have liblept or libleptonica installed and use proper -l... flag for pixCreate.
Note that liblept.so is installed when you install leptonica from debian/ubuntu repository by e.g. apt-get install. Btw maybe it should be also fixed by leptonica guys to standarize library name no matter you build it by your own or install from repo (?). Neither the stable version 3.05 nor git master tests for pixCreate.
Did you test with Tesseract 3.04 or older? Then please update to a supported version. Previously I checked out to a tag: 3.05.00dev
Now I've just checked to a branch: 3.05 - and now it passes ./configure script, but there is some new problem with make:
```
/usr/bin/ld: cannot find -lleptonica_OUTPUT_NAME-NOTFOUND
collect2: error: ld returned 1 exit status
make[2]: *** [libtesseract.la] Error 1
make[2]: Opuszczenie katalogu `/home/m/OCR/download/tesseract/api'
make[1]: *** [all-recursive] Error 1
make[1]: Opuszczenie katalogu `/home/m/OCR/download/tesseract'
make: *** [all] Error 2
```
And for branch 3.04 without liblept.so I get:
```
checking for leptonica... yes
checking for l_generateCIDataForPdf in -llept... no
configure: error: leptonica library with pdf support (>= 1.71) is missing
Line 122 - configure error
```


 1) leptonica 1.74.2 builded and installed from source
2) Yes, I run autogen before configure.
As I mentioned in 1st post: leptonica builded from source does not create liblept.so, instead it creates libleptonica.so.
 It seems that with **CMake** it's `libleptonica.so`
 Commit f52d445074d0e3863dfbe4f0b6acbf92c0f46d7d changed the library handling to use `pkg-config`. The branch 3.05 includes that commit. Tesseract 3.05.00 still uses the old code. Thanks guys. To summarize:
Yes, I've got only 1 leptonica, and yes, when cmake is used then liblept.so is created instead of libleptonica.so (to be precise: cmake path/to/repo; make -j; sudo make install). For the same reason "checking for l_generateCIDataForPdf in -llept... no". But nevermind, because indeed f52d445 from 3.05 branch fixes  liblept vs libleptonica. However as I mentioned some posts ago: when I use 3.05 or f52d445 I've got a problem with "make" which is connected again with leptonica.
But if you ask me, I'm satisfied with using 3.05.00 and just symlink liblept.so to libleptonica.so.
 @wosiu, the error `/usr/bin/ld: cannot find -lleptonica_OUTPUT_NAME-NOTFOUND` comes from an error in the Leptonica build. The string is part of `lept.pc.cmake` and should be replaced when `lept.pc` is generated. I'd try building Leptonica with configure / make instead of using cmake ‚Äì maybe that fixes this problem. Try to build both leptonoica and tesseract with the same build system (cmake / autotools) https://github.com/DanBloomberg/leptonica/issues/253 Now I build and install leptonica like this:
```
./autobuild
./configure
make -j 
sudo make install 
```
and indeed liblept.so is created.
However now during tesseract (branch 3.05) "make" I get:
```
/usr/bin/ld: tesseract-tesseractmain.o: undefined reference to symbol 'lept_free'
/usr/local/lib/liblept.so.5: error adding symbols: DSO missing from command line
collect2: error: ld returned 1 exit status
```
3.05.00 build is fine. Does anyone have a solution to this problem without changing the debian version of the leptonica library soname (made with autotools), which is liblept.so? @jbreiden @DanBloomberg, I see no problem with the name of the library here. `./configure && make` builds `liblept.so` which is fine. `liblept.so` also provides `lept_free`. @wosiu, do you compile for Linux or for Windows? Could you provide a complete build protocol?

  for some reason, the network in my country is very bad!!

so i want to use the lib and dll directly.
and finally i found no where to download it?

compile it is so hard for me, is there a solution? @Shreeshrii Thanks for the links! How can I use this build in my QT C++ project? @Shreeshrii 
thanks for you help.
i try download it, but i can not find any .lib file there.

i perfer files below

1. libtesseract304d.lib
1. giflib416-static-mtdll-debug.lib
1. giflib416-static-mtdll-debug.lib
1. giflib416-static-mtdll.lib
1. giflib416-static-mtdll.lib
1. libjpeg8c-static-mtdll-debug.lib
1. libjpeg8c-static-mtdll-debug.lib
1. libjpeg8c-static-mtdll.lib
1. libjpeg8c-static-mtdll.lib
1. liblept171-static-mtdll-debug.lib
1. liblept171-static-mtdll-debug.lib
1. liblept171-static-mtdll.lib
1. liblept171-static-mtdll.lib
1. liblept171.lib
1. liblept171.lib
1. liblept171d.lib
1. liblept171d.lib
1. libpng143-static-mtdll-debug.lib
1. libpng143-static-mtdll-debug.lib
1. libpng143-static-mtdll.lib
1. libpng143-static-mtdll.lib
1. libtiff394-static-mtdll-debug.lib
1. libtiff394-static-mtdll-debug.lib
1. libtiff394-static-mtdll.lib
1. libtiff394-static-mtdll.lib
1. zlib128-static-mtdll-debug.lib
1. zlib128-static-mtdll-debug.lib
1. zlib128-static-mtdll.lib
1. zlib128-static-mtdll.lib @zdenop and you know where to get what we want? @weituotian, get the code and compile it yourself. You won't save much network bandwidth if you could get libraries. And libraries must match your compiler. You did not say which compiler you are using.   On an Intel Xeon Server the new code is significantly faster.

The results are less impressive on a notebook with Core i7 where it is also more difficult to reproduce a timing test. That's why I suggest independent tests by other people. Er, what's with the low-level SSE/AVX programming instead of trusting tools like `#pragma omp simd` and even optimised higher-level libraries, unless it is to leave ample opportunity for further optimisation?

BTW, how is alignment at 32-byte boundaries achieved, and has this been verified? I was blinded by all the other uses of "align", so I didn't find any uses relating to memory alignment... As far as I know, `#pragma omp simd` is not restricted to Intel CPUs, so it could also improve the generated code for ARM and other architectures.

Tesseract currently does not assume 32-byte alignment, but tests the alignment at execution time and chooses different code paths for aligned and unaligned arrays of double values. Just a note: `#pragma omp simd` is not supported with MSVC. @stweil Has anybody verified that this differentiation actually does some good? If you leave it up to chance, I don't think that the odds are in your favour, especially if both arguments have to be aligned at the same time, because the current code does not choose load instructions independently for each parameter; so if it does make a difference, you had better make sure that it's not just once in a while if you're lucky. One parameter aligned is actually the worst case, because you don't necessarily have to start at the beginning of a vector for the SIMD instructions, so what matters is whether the arguments are mutually aligned or not.

@amitdo I don't think that the laggard should set the pace, considering how relatively easy the pragma is to use. @rfschtkt, it looks like one parameter is (mostly?) aligned while the other parameter is only aligned in one of four steps (it increases in steps of sizeof(double) == 8). As far as I see the code could also be modified to handle one aligned parameter with the other parameter unaligned.

I'm still not sure how much the aligned access is faster. As reported by @Shreeshrii, some CPU models don't show increased speed where others show significant faster execution. Memory caches also play an important role.

That's why I want to offer several implementations in Tesseract, and users can choose which one is best for their environment. Do you have any evidence that such differentiation might be useful beyond the purpose of experimentation? I would expect cache-oblivious code, techniques like blocking/strip-mining, to benefit all architectures more or less equally. It doesn't seem very efficient to try to reinvent the wheel here, but I haven't yet looked into any issues like licensing associated with the use of an external library with Tesseract, so... See https://github.com/RRZE-HPC/DDOT-Bench and the associated article for more research on this. They also have code which can be used freely. How about #983? The idea is to primarily rely on OpenMP 4.0's simd where available, then try explicit code for specific implementations, then fall back to serial execution. If you're confident that you have a better implementation than OpenMP, this order can of course be changed, but I don't think this is the case yet. Could you share some details on how you test performance here? Could this be reframed as a unit test that immediately rejects a suboptimal implementation choice? My conjecture is that OpenMP wipes the floor with (relatively speaking) naive use of SSE/AVX intrinsics, and that you only need the latter if you are stuck with Visual C++ (for now). Typically I use these test scenarios for the OCR process (`tesseract` executable, all images available on https://digi.bib.uni-mannheim.de/~stweil/tesseract/):

    # OCR of a very large image (performance test with focus on OCR).
    tesseract 0604.jp2 /tmp/0604-eng -l eng
    tesseract 0604.jp2 /tmp/0604-frk -l frk
    # OCR of a very small image (Valgrind, performance test with focus on pre OCR steps).
    tesseract hello.png /tmp/hello

Recently I added a [test scenario for training](https://digi.bib.uni-mannheim.de/~stweil/tesseract/issue961.sh). It is based on issue #961 provided by @Shreeshrii.

I started writing a [standalone test](https://digi.bib.uni-mannheim.de/~stweil/tesseract/dp-test/) to test the effects of cache size, but that is still unfinished.
 The conflicts are resolved now. I suggest to keep the PR open until more people have reported their timing test results.  Add two build dependencies which were missing and update the hints for
building ScrollView.jar.

Signed-off-by: Stefan Weil <sw@weilnetz.de>  Would it be possible to preserve layout? I'm thinking of something akin to:

pdftotext -layout

I'm working with images of tabular computer printouts. Although the OCR function is impressive, without the layout, the result is largely unusable. If text stayed roughly in its columns, it would be readable. I wasn't sure if --psm 5 might have been intended to be helpful but it produced junk: could it be broken? All the other psm options I tried produced something reasonable. I have now - they aren't mentioned on the default usage, so I didn't know about them. For what I want to do, the tsv fomat may work well. I'm not sure what some of the columns mean, but the coordinates are clear.

Your suggestion lets me develop a solution for my problem better than my original suggestion. In particular, it lets me make my own decisions about text which doesn't align well such as superscripts or font changes within a line.

However I think my change request as originally stated would be useful. If you try pdftotext with/out the -layout option on something like a bank statement you'll see what I mean! 

To summarise: 

Thanks, you solved my problem. My proposal would still be useful. The --help option should document tsv/hocr (a new change request)?. Thanks for an amazing tool.  I've been creating Tesseract 3.02 application uses Visual Studio and already train and have tesseract data for 3.02. Now my company want me to develop on android which I'm using rmtheis TessTwo API which uses Tesseract version 3.05. So how can I convert my 3.02 data to 3.05? Or is it 3.02 can be used on 3.05 without need to change (though I believe this i not true)?
Please help thank you  Hi guys,

I am new to tesseract and I was following tesseract 3.xx guide and was able to generate ara.traineddata for arabic language but after some time I came to know that there is no point of further train the engine for v.3.xx so I shifted to v4.00 alpha which is the current latest version of tesseract but I am facing some issues while training.

First issue is that there are no alternative commands for windows and only linux based commands for training are available but I manage to run some commands and facing an issue where I can't train further.

**Command I am using:**
_..\lstmtraining -U ara.unicharset --script_dir ..\langdata --net_spec "[1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c105]" --model_output ..\training --debug_interval 0 --train_listfile ara.training_text.txt_

_Where lstmtraining.exe is the previous directory, I have ara.unicharst file, other options are same as I picked from sample command given here: https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00 and I have ara.training_text.txt **(same was used to generate box files and tiff files)** file for arabic text but now I getting the following errors:_

" C:\Program Files (x86)\Tesseract-OCR\training>..\lstmtraining -U ara.unicharset --script_dir ..\langdata --net_spec "[1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c105]" --model_output ..\training --debug_interval 0 --train_listfile ara.training_text.txt
Other case u of U is not in unicharset
Other case n of N is not in unicharset
Other case e of E is not in unicharset
Other case h of H is not in unicharset
Other case C of c is not in unicharset
Other case T of t is not in unicharset
Other case S of s is not in unicharset
Other case V of v is not in unicharset
Other case D of d is not in unicharset
Other case W of w is not in unicharset
Setting unichar properties
Warning: given outputs 105 not equal to unicharset of 96.
Num outputs,weights in serial:
  1,36,0,1:1, 0
Num outputs,weights in serial:
  C5,5:25, 0
  Ft16:16, 416
Total weights = 416
  [C5,5Ft16]:16, 416
  Mp3,3:16, 0
  Lfys64:64, 20736
  Lfx128:128, 98816
  Lrx128:128, 131584
  Lfx256:256, 394240
  Fc96:96, 24672
Total weights = 670464
Built network:[1,36,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc96] from request [1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c105]
Training parameters:
  Debug interval = 0, weights = 0.1, learning rate = 0.0001, momentum=0.9
Deserialize header failed: ‚à©‚ïó‚îê‚ï™‚ñí‚ï™‚îÇ‚îò√†‚ï™¬∫ ‚ï™‚ï°‚ï™¬ø‚îò√®‚ï™¬°‚îò√ß ‚ï™‚îÇ‚îò√§‚îò√™‚îò√† ‚îò√ß‚îò√§‚ï™¬∫‚îò√§‚îò√ß ‚ï™‚ï£‚ï™¬ø‚ï™¬ª‚ï™¬∫‚îò√§‚îò√§‚ï™‚ïñ‚îò√®‚îò√º ‚ï™¬ø‚îò√¢‚ï™‚ñí‚îò√® ‚ï™¬∫√©‚ï™‚ñí ‚ï™¬∫‚îò√§‚îò√©‚ï™‚ï£‚îò√®‚îò√©‚ï™‚ï£‚îò√® ‚îò√†‚ï™‚ï¢‚ï™¬∫‚îò√™‚îò√® ‚ï™‚ï£‚ï™¬∫‚îò√†‚îò√© ‚ï™¬°‚îò√®‚ï™¬ª‚ï™‚ñí‚ï™‚ï£‚îò√§‚îò√® ‚îò√•‚îò√™‚îò√®‚ï™‚ñì‚ï™¬° ‚ï™¬∫‚îò√§‚ï™¬°‚îò√†‚îò√®‚ï™¬ªLoad of page 0 failed!
Load of images failed!! "

**Ignore the random text I think it is coming because of the text file I am using as I copied this from Command Line. Please find the text file I am using along with tiff & box files in the attachments.**

Need help as soon as possible.

Thank You

[ara.training_text.txt](https://github.com/tesseract-ocr/tesseract/files/1022209/ara.training_text.txt)
[ara.nicidprint.exp0.zip](https://github.com/tesseract-ocr/tesseract/files/1022223/ara.nicidprint.exp0.zip)
[ara.nicidprint.exp0.box.zip](https://github.com/tesseract-ocr/tesseract/files/1022225/ara.nicidprint.exp0.box.zip)
 Thank You so much, I will try and will update you. Hi,

I am still facing issues.

Now I used this command:

../train/lstmtraining -U ara.unicharset --script_dir ../langdata --debug_interval 100 --net_spec '[1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c105]' --model_output ../ara_train --train_listfile ara.nicidprint.exp0.lstmf --max_iterations 5000 &>../ara_train/basetrain.log


and the result is:



Other case u of U is not in unicharset
Other case n of N is not in unicharset
Other case e of E is not in unicharset
Other case h of H is not in unicharset
Other case C of c is not in unicharset
Other case T of t is not in unicharset
Other case S of s is not in unicharset
Other case V of v is not in unicharset
Other case D of d is not in unicharset
Other case W of w is not in unicharset
Setting unichar properties
Warning: given outputs 105 not equal to unicharset of 96.
Num outputs,weights in serial:
  1,36,0,1:1, 0
Num outputs,weights in serial:
  C5,5:25, 0
  Ft16:16, 416
Total weights = 416
  [C5,5Ft16]:16, 416
  Mp3,3:16, 0
  Lfys64:64, 20736
  Lfx128:128, 98816
  Lrx128:128, 131584
  Lfx256:256, 394240
  Fc96:96, 24672
Total weights = 670464
Built network:[1,36,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc96] from request [1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c105]
Training parameters:
  Debug interval = 100, weights = 0.1, learning rate = 0.0001, momentum=0.9
Deserialize header failed: 8
Load of page 0 failed!
Load of images failed!!
Deserialize header failed: 
Deserialize header failed: 
Deserialize header failed: !√Ñtv√ñ√û√°√∏"¬§√ì¬≥@¬æÀÜq√å!≈∏.?‚Äö√¨¬≠‚Äú√å/≈æ~√é√Ö√°x¬ß¬è‚Äò√°√ì√∞‚Äô√à√Æ√∞√®¬Ø√Ü¬π√Ç≈æ+Y¬∏‚Äû¬≥‚Äô0≈°√ö¬¨/Cv{%7√¢¬∂\√®mZ‚Ä∞≈∏h>%√Ö√©F¬∏¬£√á√ÆKE¬§ÀÜc√∑√ñ√¥=√±‚Ä∫HG@Pl>√π‚Äô_¬Å‚Äú‚Ä¶‚Äúmg‚Äπl"¬≥@√äÀÜ√é~f=¬±um1¬£l/b¬¨Ma[&U√∞sE√ø¬¥t'√ª‚Ä¢ ¬†¬≠√Ñ√∫hU
Deserialize header failed: 5√∑4Sye)p¬ø√ÖI√¥√∫√£+h]‚Ä°j√öOy¬Ω¬¶M∆íb√ö]i,¬≤√Ω‚ÄùdBv√≥=√àc¬ê√î√êY0Q√ø√¶F¬°√±√†*S≈æ≈í‚Äì(Vs¬ç‚Äù‚Äù¬ß
-7¬ç√¨E¬ª¬∞Y[¬ß√Æ¬ç√∑√µ¬µ8>3¬Ωt?√ñ‚Äû+h√ö¬©√∫¬°¬çv?wG√¢¬¨:¬æ¬Ω¬†√õ1√™T3√ü(¬¶
A¬è¬Ø√Æ¬¢X	√Ç3√Öb¬∞7¬≠√¨v‚Äú3√ì‚Äô√ö√ª√õ√∞:Cl√±√æt√∑$&¬™√åYc¬§_.2vC¬æ√Å¬ß)√ô‚Äû?¬©Z√™K√∞¬æ¬æN1√ä¬£zy_≈∏!‚ÄûK¬©‚Äùf¬±¬¶#"¬©GW¬©√´C^7√´^√õc	√ÆeH‚Ä∫Àú‚Ä†√Ñ≈æ#√ôB&1√íOU)√ö√¢z√ä√ôsm¬ß√¥ ‚Ä°QR√äH#"¬∞B√í¬©√π‚Ä¶%‚ÄìDXH¬¨|¬≠≈∏√É1*`H≈∏ÀÜ
Deserialize header failed: ¬¢‚Ä∫K‚Ä°√ô≈í¬ê√ò‚Äπ¬¢√Ç√è√∑¬Å√ôI√Öm√π≈Ωm√ÖZ(¬™>ÀÜ^¬•¬Ø√¶!¬®√§!√Ø¬•¬¥
√Ö
¬´‚Äò¬∫m√ë‚Äπ√øMh¬µ¬©0√ä¬≥≈°√º¬Ø-≈†‚Äì3√°√Ü ‚Äò¬±"c+√í¬†H¬´=x√π 3X‚Äò√ê#¬Æ√≥Y f√ö√†¬º√ã.<¬¨{√†64√¨≈°=99√à‚Ä∫FB¬êRF@W(-‚Ñ¢¬© WNp√±√æ¬Ø%d
r8‚Äö‚Ä¶¬±¬™√ô+¬†√â√©√≤‚Ä∫"@√ñTC≈í¬µR`R@L‚Äö¬Æk<¬§¬§0‚Äπ‚Ä∞|#G¬∞‚Ä°√ô
Deserialize header failed: !‚Ä∞kOL√â¬±¬•¬´√∏nc√ôm√π~J¬≤‚Ä¢G‚Äú¬§¬°‚Ñ¢‚ÄìJ≈í√•‚Ç¨6y√ò¬™√ó≈°o‚Äú√å¬èCH¬¨N√ø¬£‚Äör‚Ä∫¬•#√¶¬§k¬∏≈íf_‚Ä¶≈†1d√áj¬ø‚Ä∞¬Ω‚ÄôC¬è¬Ø√Ü¬º√†≈†√µuA3¬£≈†¬™B‚Ñ¢'-√©‚Ä¢√é√≠¬¥0¬µÀÜ[√ô¬ù√è∆í√®IT≈Ω√è¬®`1‚ÄûR‚Äô=√Ö¬≥qH+√ì@√Ö`√¢‚Ä∞3,]]¬πs6 [√ã)‚Ä¶&‚Ä¢‚Äû¬ΩpCe√≤zaG√∑3¬º¬≤√é¬¢‚Äú¬êXy),_)≈í¬∏n‚Äô‚Ä°!√äFJ¬´¬∂J‚Äö}‚ÄúP|;}M√Ä¬ê]Kj√ß¬≠S√ÉF¬©)√∞√¶‚Ä∞√û≈Ω√°√ö‚Ä¢√∂	∆íd√è‚ÄöY¬πf¬∑√©0¬∞¬è‚Ñ¢√≠-
Deserialize header failed: √´√Å‚Ä∞√ú4\√í/T¬∂√±O[O¬†ÀÜw√µu‚ÄπV√©eE√à≈íu¬º‚Äô}√´√ë√πJh√å=≈°z√è]√ö√ìO‚Ç¨7¬†√è=h¬®√Ñ¬∂E¬µC
Deserialize header failed: √í"¬Å√îA‚ÄöN9KU¬∏¬•√áH¬©_]¬ê¬≥#‚Äò√ßT'RbX*≈Ω¬∫Ad¬®¬¨‚Ä¶√∫√¥:v¬æ¬≤¬®¬§?¬•N¬∂[√É


Please help.

Thank You Thank You soooooo much. It worked and now it is running. Once it is finished then I will let you know.

Thanks again friend. @latifwirelessmaker which fonts you added? I am using Nic Id Print, its a custom font created for some specific data @LatifWirelessMarketer 
ok good
just your training finished tell us about the accuracy you reached..

Thank you OK Sure but I am still in training phase as I just started with v 4.0 so maybe with current data I will not reach that much accuracy so I will run it again for last amount of training text.

So will keep updating about accuracy improvements.

Thanks.  Btw, can anyone tell me how much of text is required to get a good accuracy? I've read in the documentation that original training was done on more then 400000 lines of text so is it necessary to have that much text of languages like (english, arabic, etc...) or not.

Also let me know if I can get the original source of text used for training the languages that are available to be downloaded freely from original source?

Thank You  Regarding the Arabic language, the number of Lines required to produce a decent Model depends on the complexity of the typeface. But it is proven that you are able to create an Arabic Model capable of achieving +90% recognition rate using ~800 lines in your training.

Have a look at the research done by the OpenITI‚Äã team, implimented using Kraken engine:
[1)The Research paper
](https://drive.google.com/file/d/0BzDVkBcqiyEsbC16ZGktOWNiUDg/view)
[2)Kraken](http://kraken.re/)
 @LatifWirelessMarketer can you post your test results such as recognition rate and time.
waiting for your updates @christophered I was training on huge text before but it was a never ending task to now I am trying to train it on small text with different fonts like arial, tahoma etc. and text lines are less then 30. It took me more then 3 hours to train at first with error rate below 0.9 but the problem is that after I was able to generate ara.lstm file which is the final training file. Now I am unable to generate ara.traineddata

Command I used:
..\combine_tessdata -o ..\tessdata\ara.traineddata ara.lstm ara.unicharset ara.number-dawg ara.punc-dawg ara.word-dawg

and I am getting this error:
Failed to create a temporary file ara.traineddata.__tmp__

no matter what, if I change the traineddata directory. The error remains the same.

Does anyone know this problem and it's solution, then please help.

Thank You @Shreeshrii  @Shreeshrii I checked everything already and even after you explained it to me. There are no files in any directory like ara.traineddata or ara.traineddata.__tmp__ etc. I deleted all previous ones and now trying from scratch but still it's giving me same error.

see attachment.

![lstm](https://cloud.githubusercontent.com/assets/19776088/26761448/5742efe8-4938-11e7-8c09-6afbccc49b3f.png)
 @Shreeshrii what percentage recognition rate for the Arabic language you where able to get? @christophered My char error rate was 0.78 but how to check percentage recognition rate? I think we can only check after generating the trained data right? @christophered  I uninstalled tesseract engine after coping my files and reinstalled it, now its working.

 @Shreeshrii , One questions brother.

I want to know if there is no ara.traineddata already present in the folder, then how can we create a new file? I mean I tried several times and the error I was getting yesterday was just because there is no ara.traineddata file present. If I copy any ara.traineddata from the internet in my tessdata folder then it combines the new trained data with that.

For example the size of original data was 11.9mb but I used only 20 lines of text and my trained data size become 11.0mb. How is that possible? @Shreeshrii Thank You soo much brother.

Btw do you know what is the difference between ara.word-dawg & ara.lstm-word-dawg?

I mean I know how to generate word dawg as it is generated based on word list but what about lstm-word list?

Thank You @LatifWirelessMarketer send me an email, I want to talk with you regarding the training process.
Also please delete the gibberish after `Deserialize header failed:` your making your topic hard to go through @christophered sorry for it man, I removed it. @LatifWirelessMarketer Are you using Tesseract 4.x on Windows or Linux? @christophered Tesseract 4.00alpha on windows
 @christophered I am facing one problem. After 2 weeks, I've achieved error rate of 0.61% which is good but after I generate the traineddata and tested, it give me bidi joined characters as opposite.

For example if I test it on my name as: SALMAN (ÿ≥ŸÑŸÖÿßŸÜ) and when it detects it almost detects it correctly but lets just say ÿ≥ŸÑ is one character based on a whichever font I am using. So when this is what it will return (ŸÑÿ≥ŸÖÿßŸÜ) it detects ÿ≥ŸÑ as ŸÑÿ≥ which is wrong. 

Can you help me with this? What can be the reason behind it? As it happens with every joined character.

Thank You  Can someone help me?? @christophered ? @LatifWirelessMarketer Error rate of 0.6 is very bad, my guess is that you either:
- Have some mistakes or inconsistencies in your training data, **Your training data**
- Or there are some characters that are causing confusion, **Tesseract itself**

Please upload your training data and the created module, so that we can have a closer look.
Also, list your step-by-step commands that you used to create the training data, create and train the lstm model, and recognize the images. Arabic has some known issues, like the one you described.
Hopefully, Ray will able to fix them.

  Hi ,

Anyone please help me in finding / Creating lang.cube.* files for all the other languages in tessdata folder. like eng language has. Please help me out in training data for cube. Or anyone already have those cube files please share with me.

Thanks and Regards,
Merlin
 can i know the forum insite details See https://github.com/tesseract-ocr/tesseract/wiki#support.  I installed the tesseract through pip install. The latest version of it is 3.04.01. When I tried to compile my C++ code, it has errors with libtiff. Since the 3.05 version has abandoned such dependency, I am wondering if there is a way to upgrade my tesseract, AND AT THE SAME TIME, I can write both C++ and Python code on that. Thank you so much in advance.  Performance is important for real time OCR, mass production OCR and training.

In this RFC I'd like to discuss performance bottlenecks and potential improvements.

See also the [Tesseract wiki](https://github.com/tesseract-ocr/tesseract/wiki/4.0-Accuracy-and-Performance).

According to my tests with Valgrind's tool `callgrind`, these functions have the largest computational costs (ordered by decreasing time):
- memory allocations / deallocations
- `tesseract::UnicharIdArrayUtils::compare`
- `tesseract::DotProductAVX` (or the other implementations of the dot product)
- `vfprintf` (called from `snprintf`)

`tesseract::UnicharIdArrayUtils::compare` and memory allocations / deallocations are also the functions which are called most often.

I recently had a closer look at the dot product calculations and noticed that at least some input vectors are converted from `float` to `double` (which takes time). The dot product is always done with `double` values (more expensive than `float`). If memory bandwidth is the limiting factor, using `double` means doubled time compared with `float`. The current code uses 4 parallel threads. I have run some timing tests without that parallelization and got nearly the same execution time. @theraysmith, did you try using `float` for the dot product, and do you get better performance from parallelization in that part of the OCR process? Valgrind shows all callers, so I can provide that information (next week, as I'm currently busy with other things).

Regarding precision of the dot product: the addition is the critical part for the accuracy. Did you ever try some of the algorithms which help to improve that part, e. g. [Kahan](https://en.wikipedia.org/wiki/Kahan_summation_algorithm)? Maybe that would be sufficient to allow using `float` everywhere.

I used OpenMP and disabled it only in `lstm/fullyconnected.cpp` and in `lstm/weightmatrix.cpp`. The original code of the master branch shows that OpenMP works, as the real time is much less than the user time:

    real    2m50,958s
    user    7m39,712s
    sys     0m2,128s

With OpenMP disabled for the parts mentioned above, OpenMP still works, the real time increases moderately while the user time decreases:

    real    3m9,378s
    user    7m33,084s
    sys     0m2,092s
 Stack for tesseract::UnicharIdArrayUtils::compare (called 2651872 times for small hello world image):

    tesseract::UnicharIdArrayUtils::compare
    ELIST::add_sorted_and_find
    ELIST::add_sorted
    tesseract::UnicharAmbigs::InsertIntoTable
    tesseract::UnicharAmbigs::LoadUnicharAmbigs
    ... It is for LSTM:

    valgrind --tool=callgrind --dump-line=yes --verbose api/tesseract --oem 1 hello.png /tmp/hello

The output is a large file called something like `callgrind.out.1234` (replace `1234` by the process id).
I suggest using `kcachegrind` to see the results. No, it was built with `./configure  --disable-shared --disable-static 'CXXFLAGS=-Wall -g -O2'`. I usually disable the library builds because they take additional time. My first results reported above were from a very small image (single line hello world), so initialization contributes significantly.
 
With a really large image (newspaper), the result changes and `tesseract::DotProductAVX` is the dominating element. Surprisingly it is followed by `gomp_team_barrier_wait_end` and `gomp_barrier_wait_end` which according to Valgrind use nearly as much time as the dot product. Those two functions are part of OpenMP.

See also issue #898. Unrolling the loop in `tesseract::DotProductAVX` results in nearly 7 % improvement:

    # tesseract 0604.jp2 /tmp/0604 # git master, without OpenMP
    real	2m54,469s
    user	2m54,160s
    sys	0m0,304s

    # same test, but with improved tesseract::DotProductAVX
    real	2m41,855s
    user	2m41,576s
    sys	0m0,272s
 Latest numbers based on code from [FAU Erlangen](https://github.com/RRZE-HPC/DDOT-Bench/blob/master/DP/src/ddot_kahan_avx_intrin.c) (thanks to @moebiusband73), Kahan part removed:

    real	2m31,514s
    user	2m31,220s
    sys	0m0,280s

That is an improvement of 12 %. Using assembler code could improve further, but I'd expect the largest improvement from using `float` instead of `double` (trying to compensate the loss of precision by using the Kahan algorithm). The conversation here is largely over my head, but I came to the bug tracker to discuss performance in 4.0, and this bug is titled "RFC: Tesseract Performance" so it seems like the right place. (Apologies if I'm wrong.)

Simple question: On the "[Neural nets In Tesseract" wiki page][nn], it says:

> On a machine with multiple cores, and AVX, an easy English image may take twice as much real time, and use 7 times the CPU as base Tesseract

But [above][a] (and elsewhere) says:

> I have had some very good results in this area, with a network 3x faster than the legacy code (for English)

I do a lot of batch OCR using Tesseract. Can I expect 4.0 to be faster by 3√ó or slower by 7√ó? If the latter, that'll be something that we'll need to plan on, since our current infrastructure took over a month to complete the last batch OCR job using 3.02. If we need 7√ó more servers that's a huge deal ‚Äî I don't know that we'd ever upgrade if that was the case. If it's 3√ó faster, that's incredible.

(Sorry again if this is the wrong place to bring this up. I'm trying to get a grasp on this situation. Thank you all for all your great work.)

[nn]: https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00#hardware-and-cpu-requirements
[a]: https://github.com/tesseract-ocr/tesseract/issues/943#issuecomment-303239929 The current 4.0 still supports the "old" OCR recognizer and is comparable to 3.05 if that is used (command line argument `--oem 0`), but there are plans to remove this feature from 4.0.

4.0 supports a new recognizer based on LSTM (`--oem 1`). The new code for LSTM uses parallel processing, so OCR can finish faster, but need more total CPU time. As 4.0 is still experimental, all timing results can change. Ray announced new trained language models for 4.0 with a smaller neural network. If that works, it could reduce CPU‚Äå time in comparison to 3.05.

Currently you won't reduce the infrastructure requirements with 4.0. That sounds promising, thanks @stweil. I'm perfectly happy not reducing infrastructure requirements, but increasing them 7√ó would be a very big deal. 

FWIW, decreasing wall time via parallelization while increasing CPU time sounds good on paper, but unless I'm missing something (totally possible), it doesn't mean much for batch jobs like ours since we run 24 OCR processes in parallel already. Our server looks like this when doing a job:

![screenshot from 2017-05-10 16-18-40](https://cloud.githubusercontent.com/assets/236970/25925259/58c72140-359c-11e7-8f05-f03ba6c022fc.png) For your use case (which is similar to my own) I'd compile Tesseract without OpenMP support. Otherwise the parallelization will take a significant part of the CPU performance. What's the method you use to disable OpenMP?

Commenting `AC_OPENMP` or something else? `configure --disable-openmp` `--disable-shared --disable-static` seems to be equivalent to just `--disable-shared`.
  I got error during compilation of latest Tesseract 4.0 (5a06417eb273a3cc3e5f720ca8fa4bbaa7940ae6).
OS: Debian 7.11 x64
gcc version 4.7.2 (Debian 4.7.2-5)

Any suggestions please? Thanks a lot!

```
<shortened>
Making all in ccmain
make[2]: Entering directory `/tmp/tesseract/tesseract/ccmain'
/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl  -fopenmp  -I/usr/local/include/leptonica    -g -O2 -std=c++11 -MT paragraphs.lo -MD -MP -MF .deps/paragraphs.Tpo -c -o paragraphs.lo paragraphs.cpp
/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl  -fopenmp  -I/usr/local/include/leptonica    -g -O2 -std=c++11 -MT recogtraining.lo -MD -MP -MF .deps/recogtraining.Tpo -c -o recogtraining.lo recogtraining.cpp
/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl  -fopenmp  -I/usr/local/include/leptonica    -g -O2 -std=c++11 -MT reject.lo -MD -MP -MF .deps/reject.Tpo -c -o reject.lo reject.cpp
/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl  -fopenmp  -I/usr/local/include/leptonica    -g -O2 -std=c++11 -MT resultiterator.lo -MD -MP -MF .deps/resultiterator.Tpo -c -o resultiterator.lo resultiterator.cpp
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl -fopenmp -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT paragraphs.lo -MD -MP -MF .deps/paragraphs.Tpo -c paragraphs.cpp  -fPIC -DPIC -o .libs/paragraphs.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl -fopenmp -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT recogtraining.lo -MD -MP -MF .deps/recogtraining.Tpo -c recogtraining.cpp  -fPIC -DPIC -o .libs/recogtraining.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl -fopenmp -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT reject.lo -MD -MP -MF .deps/reject.Tpo -c reject.cpp  -fPIC -DPIC -o .libs/reject.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl -fopenmp -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT resultiterator.lo -MD -MP -MF .deps/resultiterator.Tpo -c resultiterator.cpp  -fPIC -DPIC -o .libs/resultiterator.o
paragraphs.cpp: In function 'void tesseract::InitializeRowInfo(bool, const tesseract::MutableIterator&, tesseract::RowInfo*)':
paragraphs.cpp:2450:72: error: use of deleted function 'std::unique_ptr<_Tp [], _Dp>::unique_ptr(_Up*, typename std::enable_if<std::is_convertible<_Up*, _Tp*>::value>::type*) [with _Up = char; _Tp = const char; _Dp = std::default_delete<const char []>; typename std::enable_if<std::is_convertible<_Up*, _Tp*>::value>::type = void]'
In file included from /usr/include/c++/4.7/memory:86:0,
                 from paragraphs.cpp:24:
/usr/include/c++/4.7/bits/unique_ptr.h:433:2: error: declared here
make[2]: *** [paragraphs.lo] Error 1
make[2]: *** Waiting for unfinished jobs....
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl -fopenmp -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT recogtraining.lo -MD -MP -MF .deps/recogtraining.Tpo -c recogtraining.cpp -o recogtraining.o >/dev/null 2>&1
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl -fopenmp -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT resultiterator.lo -MD -MP -MF .deps/resultiterator.Tpo -c resultiterator.cpp -o resultiterator.o >/dev/null 2>&1
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl -fopenmp -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT reject.lo -MD -MP -MF .deps/reject.Tpo -c reject.cpp -o reject.o >/dev/null 2>&1
mv -f .deps/recogtraining.Tpo .deps/recogtraining.Plo
mv -f .deps/resultiterator.Tpo .deps/resultiterator.Plo
mv -f .deps/reject.Tpo .deps/reject.Plo
make[2]: Leaving directory `/tmp/tesseract/tesseract/ccmain'
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `/tmp/tesseract/tesseract'
make: *** [all] Error 2
``` Oh, sorry for that. There were no problems on Ubuntu 16.04, but for compatibility purposes I have to compile with older `glibc` on Debian 7. I haven't realized that Debian 7 is that much old :smiley:  I had very limited success doing OCR in Kurdish using the trained data. I think this is because it was trained on a mix of Kurmanji (the largest dialect, written in a Latin alphabet with a few circumflexes) and Sorani (the second-largest dialect, written in a modified Persian alphabet) sources. It keeps wanting to find Arabic/Persian characters in my Kurmanji documents. I imagine that splitting the training data by alphabet (say, into Kurdish-Kurmanji and Kurdish-Sorani) would improve the OCR quality dramatically.

Please let me know if there's any way I can contribute to the Kurdish transcription quality.  Hello!

In #700 we added the packaging to release tesseract to the snaps store. But it hasn't been published there yet. Now we have a very cool new service that can help you doing that, and will take care of the continuous delivery for you.

Please take a look at https://build.snapcraft.io/
After logging in there with your github account, you can tell it to make a new release to the unstable channel in the store every time that your master branch changes. Then your latest changes will be available to all the ubuntu users out there with no effort.

We are in beta, so I would appreciate any comments about your experience using the service.

pura vida. @zdenop oh, that's sad. But I understand.
The work of automating the continuous delivery is very simple, so would you mind if I set up a mirror that keeps tesseract in the Ubuntu store updated after every change in your repo? I think that the maintainers are unnecessary intermediaries if we design good tools to automate the delivery, and safe and isolated packages so upstream developers can't break users' machines. We are working towards that, and if we do it right, at some point in the future you might like me to transfer the ownership in the store to you. We will see :)

Now this aligns nicely with a few things I have to test constantly, so happy to maintain it. I'll keep you posted about stats, feedback and such. If you need something snap or ubuntu related, just ping me.

pura vida.  Hi,
The region that I want to run OCR on is surrounded by 4 boxes one on each edge. My question is how to find the coordinates of these boxes. Also if I scan a page and the page gets a bit disoriented how do I fix that?  #318 
I followed the solution #318 pulled before. 
And after i ran 
`set_unicharset_properties -U unicharset -O new_unicharset --script_dir=/home/qs/Downloads/langdata`
It shows like this
Loaded unicharset of size 29 from file unicharset
Setting unichar properties
Other case c of C is not in unicharset
Other case f of F is not in unicharset
Other case K of k is not in unicharset
Other case a of A is not in unicharset
Other case l of L is not in unicharset
Other case y of Y is not in unicharset
Other case s of S is not in unicharset
Other case m of M is not in unicharset
Other case i of I is not in unicharset
Other case e of E is not in unicharset
Other case t of T is not in unicharset
Other case w of W is not in unicharset
Other case n of N is not in unicharset
Other case o of O is not in unicharset
Writing unicharset to file new_unicharset

Seems correct, but the contents in new_unicharset is 

29
NULL 0 NULL 0
Joined 7 0,69,188,255,486,1218,0,30,486,1188 Latin 1 0 1 Joined	# Joined [4a 6f 69 6e 65 64 ]a
|Broken|0|1 f 0,69,186,255,892,2138,0,80,892,2058 Common 2 10 2 |Broken|0|1	# Broken
9 8 0,66,200,255,89,156,0,39,104,173 Common 3 2 3 9	# 9 [39 ]0
7 8 12,68,196,255,72,160,0,60,75,173 Common 4 2 4 7	# 7 [37 ]0
1 8 49,69,192,255,45,128,0,66,74,173 Common 5 2 5 1	# 1 [31 ]0
2 8 30,69,194,255,80,160,0,27,97,173 Common 6 2 6 2	# 2 [32 ]0
6 8 58,66,219,255,87,156,0,54,104,173 Common 7 2 7 6	# 6 [36 ]0
/ 10 0,65,219,255,59,228,0,36,62,238 Common 8 6 8 /	# / [2f ]p
3 8 0,66,196,255,84,158,0,32,103,173 Common 9 2 9 3	# 3 [33 ]0
C 5 58,65,219,255,87,192,0,32,107,209 Latin 10 0 10 C	# C [43 ]A
F 5 57,68,216,255,68,210,0,31,77,209 Latin 11 0 11 F	# F [46 ]A
k 3 57,68,216,255,85,177,0,35,93,198 Latin 12 0 12 k	# k [6b ]a
A 5 52,68,216,255,100,216,0,17,98,231 Latin 13 0 13 A	# A [41 ]A
5 8 12,66,199,255,82,160,0,36,103,173 Common 14 2 14 5	# 5 [35 ]0
4 8 0,68,198,255,93,161,0,41,96,173 Common 15 2 15 4	# 4 [34 ]0
L 5 59,68,216,255,64,193,0,31,74,206 Latin 16 0 16 L	# L [4c ]A
Y 5 59,68,216,255,91,205,0,47,91,223 Latin 17 0 17 Y	# Y [59 ]A
8 8 57,66,219,255,88,162,0,41,103,174 Common 18 2 18 8	# 8 [38 ]0
S 5 57,64,219,255,87,174,0,30,100,200 Latin 19 0 19 S	# S [53 ]A
M 5 57,68,216,255,99,301,0,35,117,286 Latin 20 0 20 M	# M [4d ]A
I 5 59,68,216,255,10,155,0,50,29,173 Latin 21 0 21 I	# I [49 ]A
E 5 59,68,216,255,68,210,0,31,80,219 Latin 22 0 22 E	# E [45 ]A
T 5 59,68,216,255,85,227,0,47,88,236 Latin 23 0 23 T	# T [54 ]A
W 5 54,68,216,255,106,314,0,41,117,318 Latin 24 0 24 W	# W [57 ]A
0 8 58,66,187,255,88,164,0,45,103,180 Common 25 2 25 0	# 0 [30 ]0
N 5 59,68,216,255,87,262,0,27,104,249 Latin 26 0 26 N	# N [4e ]A
O 5 57,64,219,255,91,209,0,34,106,233 Latin 27 0 27 O	# O [4f ]A
\ 10 0,67,219,255,28,250,0,71,62,261 Common 28 10 28 \	# \ [5c ]p

And i do anything successfully and finally i got traindata. But here is a problem now. There is no output when i used the traindata to test the image. I think there is maybe something wrong with unicharset. 
Could anyone help? Here are my train data
box
[http://pan.baidu.com/s/1hsA8U4O](url)
image
[http://pan.baidu.com/s/1pLHgoQn](url)









 Hi Anida.qin, Your links return 404 page error? Thanks that worked. Sorry to reply late. I solve the problem now. Maybe I did something wrong when do the command box.train  . It goes with the invalid .tr file. But there is also broken line there, but finally i found it can be ignored if you only have few CreateInt() lines when use command mftraining. So i closed this issue.  Reading the forum, it seems a lot of people would benefit from having a screenshot mode where Tesseract would automatically process the image to increase the accuracy. I.E. enlarging image, making into black and white, and so on.
Is it possible to implement such feature?
Thanks! >https://github.com/DanBloomberg/leptonica/blob/master/prog/pdf2mtiff

It's just a bash script that calls ghostscript.

Users can invoke it directly. VietOCR has this mode already and improves the quality significantly, sometimes sharpening the image helps as well. If not adding this feature at least the "golden" standard what to do with screenshot to make it work with tesseract would be helpful. 

I'm just guessing upscaling by 312.5% to get from 96dpi to 300dpi of windows screenshots, then I do sharpening and then putting it to grayscale. Is there something I shouldn't do? Or something I'm missing? If there is no screenshot feature, at least tell us what we should do in the scripts imagemagick . You have guidelines for scanned text, rotate, remove noise, remove borders etc... Give us at least something which is focused for screenshots.  An implementation could also get pairs of _image file name_ and _output base_ from the file list instead of image files only. That would allow more flexibility. CC: @jbreiden  The sum of the 5 individual tesseract processes is ~2m 46s real time, quicker than batching images in a single process. That's not quite what we were expecting to see. Anyone know why? @jbarlow83 

This might be related to the adaptive learning that Tesseract does. Here are my results for a simple hello world image.

Summary for default language (identical to `-l eng`):

- PNG and TIFF show similar performance
- TIFF multi-page and list of single page TIFF show similar performance and are much faster than calling Tesseract for each single page
- LSTM takes more CPU time than old engine for this example

Summary for language with very large `traineddata`:

- no text recognized
- old engine takes much longer (otherwise similar to the results above)
- LSTM comparable to result with default language (but no text recognized)

**LSTM (--oem 1)**

    PNG (ten times)
    user 0.23
    user 0.23
    user 0.23
    user 0.23
    user 0.23
    user 0.24
    user 0.24
    user 0.25
    user 0.25
    user 0.25

    real 2.76
    user 2.42
    sys 0.77

    TIFF (ten times single page)
    user 0.23
    user 0.24
    user 0.24
    user 0.24
    user 0.24
    user 0.25
    user 0.25
    user 0.25
    user 0.26
    user 0.27

    real 2.77
    user 2.50
    sys 0.74

    TIFF (ten pages)
    real 0.43
    user 0.76
    sys 0.06

    TIFF (list with ten single page images)
    real 0.43
    user 0.73
    sys 0.09

**Old engine (--oem 0)**

    PNG (ten times)
    real 2.70
    user 1.98
    sys 0.69

    TIFF (ten times single page)
    real 2.68
    user 1.94
    sys 0.70

    TIFF (ten pages)
    real 0.51
    user 0.42
    sys 0.08

    TIFF (list with ten single page images)
    real 0.52
    user 0.43
    sys 0.08

**LSTM engine with large traineddata (--oem 1 -l mya)**

    PNG (ten times)
    real 2.21
    user 1.87
    sys 1.17

    TIFF (ten times single page)
    real 2.20
    user 1.82
    sys 1.20

    TIFF (ten pages)
    real 0.49
    user 1.12
    sys 0.11

    TIFF (list with ten single page images)
    real 0.47
    user 1.04
    sys 0.11

**Old engine with large traineddata (--oem 0 -l mya)**

    PNG (ten times)
    real 18.42
    user 16.26
    sys 2.10

    TIFF (ten times single page)
    real 19.07
    user 16.20
    sys 2.28

    TIFF (ten pages)
    real 10.69
    user 10.46
    sys 0.22

    TIFF (list with ten single page images)
    real 10.78
    user 10.53
    sys 0.23
 Yesterday I had a look on the implementation to see where I could add the page separator and found that it is already there:

The parameter `include_page_breaks` enables a page separator string in output text after each image / page. It is disabled by default.

The parameter `page_separator` sets the string used as page separator. It is set to the form feed character by default.

So the desired behavior is achieved by `tesseract multipage.tif /tmp/multipage -c include_page_breaks=1`. It adds the `FF` character after each page (also after the last page which would not be necessary).

I noticed that Tesseract also adds an empty line at the end of each page. Do we need / want that? I'd prefer to get rid of it. I suggest to remove the `include_page_breaks` parameter, remove the empty line at the end of each page, and always use the `page_separator` parameter. Then each page will be terminated by the `FF` character by default for text output. Setting `page_separator` to the `LF` character would restore the old behaviour, setting it to an empty string would omit page separators.

Would that be fine for everybody? @theraysmith? There was no answer to my previous suggestion. If people agree, I'll prepare a pull request which removes `include_page_breaks` and which always uses the `page_separator` parameter. https://github.com/tesseract-ocr/tesseract/commit/4c7c960bfd57c5863fe639afab801080d9ef8bbe

https://web.archive.org/web/20160626112213/http://code.google.com/p/tesseract-ocr/issues/detail?id=1417

https://groups.google.com/d/msg/tesseract-dev/VsgJ9R-cTQ0/OMeDjYWoAdQJ


 My question is: Are you sure that any text editor can handle form feed? The ones which I know (more than 10) can handle form feed. So do all printers (which really do a form feed).
 Including Notepad?

See the discussion which led to the patch:

https://groups.google.com/forum/#!msg/tesseract-dev/VsgJ9R-cTQ0/OMeDjYWoAdQJ Notepad cannot be used reasonably with text files which use the common LF line endings ‚Äì it expects CRLF. So it does not work with text files generated by Tesseract, and FF is only an additional detail. Maybe that's why I did not count Notepad as an editor.

As I suggested to keep the `page_separator` parameter, it would still be possible to use the tricks mentioned in the discussion which you cited. >There was no answer to my previous suggestion. If people agree, I'll prepare a pull request which removes include_page_breaks and which always uses the page_separator parameter.

I agree :-)  I'm trying to create a C++ project by visual studio 2015. But I can not find anywhere that I can download the include and lib file to import to my project. Anyone help me plz.  Use the [RAII](https://en.wikipedia.org/wiki/Resource_acquisition_is_initialization) idiom, e.g., to help prevent memory leaks.

RFC about ccutil/raiileptonica.h?

(2017-05-18 Heavily edited down.) Code freeze.

To review the latest commit, start with ccutil/raiileptonica.h; the other files can then be considered independently of each other. If there are no global issues, I can still divide up the latest commit (by directory, by file, ...but hopefully not by function!).

(Added) Hold on... renaming Ptr->Ref. :-)

(Added, edited) Which is better: `/*non-const*/ PixRef pix(...);` with `return pix.release();`, or `const PixRef pix(...);` with `return pixClone(pix.get();`? I'm leaning right, because const is better than non-const, but it has an extra `pixClone()`... and it suggests sharing semantics while `release()` is more like `std::move()`.

(Added) Which is better: `/*non-const*/` or `/*var*/`? Unfortunately, `const` was added to C/C++ as an afterthought, where it should have been the default. (Leaving the reader in limbo by omitting the comment impedes _instant_ comprehension and therefore seems inefficient and impolite to me.) Interesting proposal.

Here are a few things to consider with respect to the use of RAII with leptonica (I'm sure there are others, but I haven't thought much about this):

* does tesseract already use safe or shared ptrs, and if so, how does this proposed implementation fit with that; or if tesseract does not, would RAII be extended to all allocated data?

* leptonica is a C library with relatively little use of const (pretty much just for c strings).  An application that uses a lot of const leptonica variables will be very messy.

* leptonica uses ref counting clones to simplify resource ownership and make it easier for the developer to avoid memory leaks and double frees.  Clones are not thread safe; there's no locking in leptonica.  Would RAII change that?

* do the methods proposed here for exception handling clean up memory, or would they leak and therefore you have to crash the program?  (Does tesseract have exit calls on error?) >does tesseract already use safe or shared ptrs

It uses C++11's `unique_ptr` in the new lstm code.
C++11's `shared_ptr` is not used.

Old code does not use RAII.

>how does this proposed implementation fit with that; 

It uses `unique_ptr` with custom deleter that automatically calls pixDestroy() when the scope ends.

>would RAII be extended to all allocated data?

That's what we wish to do.
 Regarding Dan's points, in the same order, and with `Pix` standing in for any leptonica type:
* See Amit's answer. I've only applied the types in local scope, so none of the function/procedure signatures have changed, let alone the public API. Interestingly, you could also apply RAII to `FILE`, although that raises the issue of error handling when writing. BTW, currently Tesseract very rarely evaluates the value returned by `fclose()`, even when writing!
* The `const` only applies to the `PixRef`, not to the referent. So it's like `Pix* const pix`, not `const Pix* pix`.
* `PixRef` merely calls `pixDestroy()` at the appropriate time, nothing more. None of C++'s smart pointers make their _referents_ thread-safe. You can't even reliably change a `unique_ptr` or a `shared_ptr` _smart-pointer instance_ while another thread could be using or changing it. The only thing you know is that `shared_ptr`'s underlying reference count handling is thread-safe. BTW, a `PixRef` would manage just a single reference count, because `boost::intrusive_ptr`, which would also call `pixClone()` at the appropriate time (not possible for, e.g., `Pixa`) would be... too intrusive (Tesseract does not yet use that library), and neither it nor `std::shared_ptr` would be very useful for local-only usage.
* So far it only lightens the mental burden of guarding the exits of the functions/procedures (unfortunately I only found 1 leak for leptonica types), and it makes the code a bit shorter (at the expense of having to use `get()` a lot). This is low-hanging fruit, exception safety would require a lot more concerted effort. There was an issue #529 recently with `exit()` and a static variable that was destroyed while a non-static variable was still holding references to it, causing the static variable's destructor to complain... so even `exit()` has problems, in C++ at least. :-)

(Edited) "These types merely call"->"`PixRef` merely calls", "from another thread without locking said instance"->"while another thread could be using or changing it", removed repetitive "so far" @Raf

Thank you very much for your clear and thorough explanation of my questions!

I was also glad you found that "unfortunately" there are essentially no memory corruption/leak issues from leptonica usage in tesseract, even though nearly everything happens on the heap  ;-) Ah, but I only looked at local usage, and I did actually "wonder" whether using a `PixRef** pix` parameter without looking at the current value of `*pix`, as happens often in Tesseract, was always a responsible thing to do: I would require it to always be NULL as a precondition (with a check or at least a diagnostic), or always `pixDestroy()` a non-NULL value as part of the contract.

So the idea of my (off-line) query was to make you aware of a proposed set of C++ types to help manage those references, perhaps even to standardise them as part of leptonica++, so to say (an add-on, not a replacement). Any thoughts there, about the names perhaps (I thought PixRef would better fit the limited responsibility than PixPtr)? It would also be easy enough to _derive_ `PixPtr` from `std::unique_ptr<Pix>`, and give it an extra function to allow `pix.p()` with the same meaning as `pix.get()`, saving two characters each time and not letting the raw-pointer access function tail visually wag the variable dog, which together might otherwise get annoying to the point that people reject the idea of using a smart pointer, and I actually think it was a bad decision to make it that _difficult_ to access the raw-pointer value.

(Was initially incomplete, now fixed.) Prefer const + clone() to non-const + release(). The rules may be "simple", but this is C++, so we should expect to be able to program at a higher level of abstraction than C allows, and leave matters of ownership and guarding all the exits (mostly) behind us, even if there are still too many problems left to achieve exception safety.

I do remember the example you're talking about, in baseapi.cpp, which looked particularly weird to me because it would first sort of _abandon_ `lbox` (`L_INSERT`)... and then still `L_CLONE` it further down, so that was sort of a surprise. This is probably straightforward enough if you are familiar with the function `boxaAddBox()` where the `L_INSERT` occurred (assumedly the instance gets added to a container as-is, and not, e.g., serialised and destroyed), but it _feels_ wrong because it forces you to still think at that level. In my replacement, the `BoxRef` keeps the object alive throughout its scope (until the eventual `~BoxRef()`), whatever else happens, and in the meantime it can be `L_CLONE`d an arbitrary number of times. Strictly speaking, there are 2 more reference-count manipulations (one for `L_CLONE` instead of `L_INSERT`, then one for `boxDestroy()` inside `~BoxRef()`), but I think you have to strip the program of all functionality before that becomes noticeable. The story with `pix` is even simpler.

A `PixRef` just manages one reference count, whether it's from copying or cloning: the constructor takes over one reference, and the destructor destroys it. See for example `const PixRef word_in_xheight(pixCopy(NULL, pix));` in devanagari_processing.cpp... well, the other occurrences are all with `reset()`.

(Edited) "feels"->_feels_, are [->all] with >(Edited) "feels"->feels, are [->all] with

@rfschtkt, you don't have to add notes after fixing typos / grammar mistakes.
Just fix it :-)
 Don't get me wrong.  Lots of C++ users of leptonica prefer to use them with scoped ptrs, and I think that's fine.  Chacun √† son go√ªt.

I did wonder about the CLONE vs COPY case for adding a pix to a pixa, for example.  If you use the CLONE and later change the pix, the version in the pixa is also changed.  So sometimes you'd prefer to use a COPY, which gives you two instances of the image.  The copy cannot be wrapped with a scoped ptr, because it's made internally in pixaAddPix(), but it probably doesn't matter because that pix will be destroyed when pixaDestroy() is called.

Does this also work when you INSERT a PixRef->p() into a pixa?  (i.e., how does the scoped ptr handle know that it has transferred ownership to the pixa?  Do you have to do an explicit reset?) _Not_ paragraph by paragraph:

It's just a reference, i.e., a notch in the `refcount` (that's why I renamed it `PixRef`). Use `pixref.p()` like `pixpointer`, `pixClone(pixref.p())` or (equivalently) `pixref.clone()` like `pixClone(pixpointer)`, and `pixref.release()` like `pixpointer` later followed by `pixpointer = NULL;` (typically omitted, of course).

You could equivalently do `pixaAddPix(pixa.p(), pix.p(), L_CLONE);` or `pixaAddPix(pixa.p(), pix.clone(), L_INSERT);`, or, if you aren't using `pix` afterwards, `pixaAddPix(pixa.p(), pix.release(), L_INSERT);`, but I would avoid the latter (no `const PixRef`) and prefer the first over the second (shorter, doesn't needlessly use extra feature `clone()`).

The `PixRef` doesn't "know" what happened with the pointer you got from `p()`, so if you are granting/releasing ownership you must use `clone()`/`release()` instead (again, I would prefer a `const PixRef` and cloning, just because we can, because it's reference-counted, no unique ownership implied); "explicit" `reset()` after `p()` would be incorrect because the `PixRef` would call `pixDestroy()` on the old value.

(Added) I think the correct expression is "√Ä chacun son go√ªt.", but that's probably a lost battle.

(Added) Well, maybe if the scope is short, `release()` could also be used, but for a longer scope I prefer to know in advance whether something is a value or a variable, so to say.

(Edited) [[-> (typically omitted, of course)]], [[The [pointer->`PixRef`] doesn't "know" what happened with the pointer you got from `p()`, so if you are [explicitly->] [transferring->granting/releasing] ownership you must use [->`clone()`/]`release()` instead]], [[just->"explicit"]] :-P Just keeping myself honest... Hmm, should it be `clone()`, or `detach()`? They would have the same effect, but the former is clearer if you're more familiar with leptonica, and the latter if you're more familiar with `boost::intrusive_ptr`. If you would want to also add, e.g., `copy()`, then the obvious choice is `clone()`, but I don't think that it would be beneficial to go down that road.

(Added) Why is there no `boxaClone()`, even though there is a `Boxa::refcount` field (which seems to be used by `boxaCreate()` and `boxaDestroy()`)?

(Added) On the other hand, `intrusive_ptr` has a _non-explicit_ constructor that by default _doesn't_ consume its argument (unless there's a second argument `false`), so maybe taking it as a model would be more confusing than beneficial... :-)

(Added) So basically the last 3 commits are tentative, just exploring some possibilities. OK, let's get this done, because _RAII is awesome!_
* 1st Leptonica: `PixPtr` (you can't use -> with a "reference" in C++, dummy!) / `PixRef` (as in "one reference")?
* 2nd Leptonica: yes (far less visual dog wagging) / no (straight-up `unique_ptr`)?
* 3rd Leptonica (only if 2nd, I suppose): yes (more `const`) / no (straight-up `unique_ptr`)? if the former: `detach()` (like boost) / `clone()` (Leptonica-specific)?
* 4th Leptonica (only if 3rd, and only if `detach()`, I suppose): yes (more `const`) / no (lame!)?

(My current preferences are weakly or strongly on the left, so not exactly the current code.)

Once the design is fixed, I should probably collapse 1+2 and 3+4, or 1+2+3+4, and then maybe split them up again by directory, or something else.

(And to think I was actually just looking at the code to find out how to maybe get Tesseract to avoid recognising dotted lines as extra characters...) OK, I'm confused, but you should really be having this conversation with tesseract maintainers and developers, and in particular with Ray Smith.  Leptonica isn't going to change (e.g., into a C++ library).

To clone a boxa, use boxaCopy(..., L_CLONE)

As for the const issue, as mentioned before, leptonica doesn't use const as part of the function contract except for char* names (e.g., file paths).  Therefore, using const leptonica data in tesseract will be very ugly with all the const-removing reinterpret_cast<...> stuff
 "OK, I'm confused"
Then I have failed miserably... :-(

"Leptonica isn't going to change (e.g., into a C++ library)."
Smart pointers can be used with unchanged C code, no active cooperation required.

"To clone a boxa, use boxaCopy(..., L_CLONE)"
Ah so... but it still seems easier to just directly manipulate `refcount` for all types, as an orthogonal implementation of `detach()`.

I think I already mentioned that the `const` is about the pointer, not the referent: it's a const pointer, not a pointer to const. BTW, in C++, if you want to change a type that's declared `const`, use `const_cast`, not `reinterpret_cast`, which is not even allowed to remove `const`.

(Edited) 1st sentence of 4th paragraph I agree with everything, except perhaps blame for my confusion ...  :-)

Don't know how much benefit you get from enforcing constancy of the pointer, which typically only changes if it's "in-place" with a free and a heap allocation.  These are very infrequent; e.g., pixTransferAllData() and pixSwapAndDestroy(). It's a zen thing, it achieves stillness... (I don't know what I'm talking about.)

More prosaically, you can probably grasp code far quicker if you can instantly distinguish between values and variables. If you see `const`, you know you wouldn't have overlooked `pix.reset(pixConvertTo8(pix.p(), false));` somewhere between the definition of `pix` at the top of the function and its use half a page lower, because the compiler already checked that for you. So why not use it wherever you can? And that's even before potential concurrency, where invariability _really_ shines, and where `const` becomes even more valuable (pun not intended)!

Unfortunately, in C/C++, `const` was an afterthought, with a (5+1)-character handicap for values, unlike, e.g., Scala's `val`/`var` equal start. That's why I compensate or overcompensate by documenting variables, preferably providing a rationale. Those `/*non-const*/` comments look ugly to me and make the code less readable. You mean `std::unique_ptr</*non-const*/ T>`? Yeah, that gets unwieldy.

Maybe I can do better:
```
$ grep 'UPC\|UPNC' api/baseapi.cpp
template<typename T> using UPNC = std::unique_ptr</*non-const*/ T>;
template<typename T> using UPC  = std::unique_ptr<      const   T>;
  /*used with reset()*/ UPNC<PageIterator> page_it(GetIterator());
    if (! UPC<PageIterator>(AnalyseLayout())) {
  const UPNC<ResultIterator> it(GetIterator());
    const UPC<char[]> para_text(it->GetUTF8Text(RIL_PARA));
  const UPNC<ResultIterator> res_it(GetIterator());
      const UPC<char[]> grapheme(res_it->GetUTF8Text(RIL_SYMBOL));
  const UPNC<ResultIterator> res_it(GetIterator());
      tsv_str += UPC<char[]>(res_it->GetUTF8Text(RIL_SYMBOL)).get();
      const UPNC<char[]> text(it->GetUTF8Text(RIL_SYMBOL));
  const UPC<char[]> text(GetUTF8Text());
  const UPC<PageIterator> it(AnalyseLayout());
$ 
```

(Edited) `*`->`api`, `UPC` whitespace alignment  >\+  \/*used with reset()\*/ std::unique_ptr<\/*non-const\*/ PageIterator> page_it(GetIterator());

Here you started a line of code with a comment. This makes my brain read the whole line as a comment. You also implanted a comment in the middle of line, which makes it even worst.

IMO, comments should be put before code block or at the end of line. but not at line's start or in the middle of line. Then you should re-train your brain, because only `//` does that.

Also, syntax highlighting is not frivolous. Use an editor that supports it!

(Added) Oh well, it might as well be omitted. I would always wonder whether `const` is missing for a reason, but I guess that's just me... Any other general impediment(s) before I re-stage this (once!) for detailed review and merge? Or is it OK after a change back to PixPtr (instead of PixRef) and removing those non-const-related comments? Anything related to "TODO"?

(Edited) re-educate->re-train to make it rhyme :-) Eliminated even more *Destroy() calls, squashed commits for "RAII: Leptonica types".

If you like to have 159 fewer lines of code (~~after~~before the addition of ccutil/raiileptonica.h), please review now, otherwise I'll probably just close this by the end of the month.

(Edited)

(2017-05-30 Added) TODO: member variables?

(2017-05-31 Added) Interesting problem with that (think baseapi.h -> thresholder.h -> `ImageThresholder::pix_`): how do you isolate a header file from leptonica's/Leptonica's (which?) "allheaders.h" (BTW, why not "leptonica.h"?! imagine if all libraries used "allheaders.h"!)? People do all kinds of altogether harmful things to limit the amount of included code and/or isolate from possible changes (less relevant here), like using forward declarations (if you misspell anything or there's a change, you won't know until link time) and the pimpl idiom (not only are you responsible for all the boilerplate to hook it up, but you pay for it forever with runtime overhead). But what when it gets to a `unique_ptr` with a custom deleter? The compiler inevitably has to know the internal layout of the deleter to know the size of the `unique_ptr` (if the deleter has state, it is kept in the `unique_ptr` instance, not at arm's length as with `shared_ptr`... right?). Surely the client shouldn't have to forward-and-a-half-declare the deleter... You probably need two headers: one for forward declarations, and one normal header (or one header that can wear two hats, guided by a macro). Time for some modernisation of the legacy `#include` mechanism! Do [modules](http://clang.llvm.org/docs/Modules.html) address this?

(2017-06-03 Added) Current tally for Leptonica-related commits: 169 fewer lines (before the addition of ccutil/raiileptonica_forward.h and ccutil/raiileptonica.h).  I followed the steps in https://github.com/tesseract-ocr/tesseract/wiki/Compiling#linux
I downloaded from https://github.com/tesseract-ocr/tesseract zip file.

OS: Centos 7
Compiler: gcc version 4.8.5 20150623 (Red Hat 4.8.5-4) (GCC)

I found error written so I installed autoconf-archive and in order to resolve error with "Leptonica 1.74" I have done:

export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig
export LIBLEPT_HEADERSDIR=/usr/local/include
export TESSDATA_PREFIX='/usr/local/share/'

./configure --with-extra-includes=/usr/local/include --with-extra-libraries=/usr/local/lib
LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make

but I receive this error:

In file included from rect.h:28:0,
from coutln.h:26,
from stepblob.h:23,
from werd.h:28,
from blobbox.h:25,
from blobbox.cpp:25:
blobbox.h: In member function 'void TO_BLOCK::print_rows()':
blobbox.h:737:61: error: expected ')' before 'PRId32'
tprintf("Row range (%g,%g), para_c=%g, blobcount=%" PRId32 "\n",
^
../ccutil/tprintf.h:31:39: note: in definition of macro 'tprintf'
#define tprintf(...) tprintf_internal(VA_ARGS)
^
make[2]: *** [blobbox.lo] Error 1
make[2]: Leaving directory /home/webuser/src/tesseract-4.0/ccstruct' make[1]: *** [all-recursive] Error 1 make[1]: Leaving directory/home/webuser/src/tesseract-4.0'
make: *** [all] Error 2

Can you help me?
thanks Seems to be related to this change:
https://github.com/tesseract-ocr/tesseract/pull/905/commits/ef1d9600b1#diff-f65400671330df624f228888e8ee46ba I follow your actual advice, I restart then I done:

git clone https://github.com/tesseract-ocr/tesseract.git
cd tesseract
./autogen.sh

export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig
export LIBLEPT_HEADERSDIR=/usr/local/include
export TESSDATA_PREFIX='/usr/local/share/'

./configure --with-extra-includes=/usr/local/include --with-extra-libraries=/usr/local/lib

LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make

I obtain:

In file included from rect.h:28:0,
                 from coutln.h:26,
                 from stepblob.h:23,
                 from werd.h:28,
                 from blobbox.h:25,
                 from blobbox.cpp:25:
blobbox.h: In member function 'void TO_BLOCK::print_rows()':
blobbox.h:737:61: error: expected ')' before 'PRId32'
         tprintf("Row range (%g,%g), para_c=%g, blobcount=%" PRId32 "\n",
                                                             ^
../ccutil/tprintf.h:31:39: note: in definition of macro 'tprintf'
 #define tprintf(...) tprintf_internal(__VA_ARGS__)
                                       ^
make[2]: *** [blobbox.lo] Error 1
make[2]: Leaving directory `/home/webuser/src/tesseract/ccstruct'
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `/home/webuser/src/tesseract'
make: *** [all] Error 2

thanks  I installed tesseract 3.05 (because other version previous one the 3.05 I don't find) and all it's ok, but so isn't the version 4.0 ready?
thanks 4.0 can be compiled without an error by the continuous integration tests, in several of my test environments and by other people, too. So we need your help to find what is special in your case.

Could you have a look at the file `ccstruct/.deps/blobbox.Plo`? It must include an entry `/usr/include/inttypes.h`. That file defines the `PRId32` macro.

Try also a simplified build like this:

    git clone https://github.com/tesseract-ocr/tesseract.git
    cd tesseract
    ./autogen.sh
    export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig
    ./configure
    make
 From checking for similar error messages it appears that CentOS 7 and a few other versions of CentOS only define the PRId32 macro when the macro `#define __STDC_FORMAT_MACROS 1` is set. @oscaroxy, check if manually passing this via `CPPFLAGS='-D__STDC_FORMAT_MACROS=1'` resolves the issue.

It's not clear to me where Tesseract actually includes <inttypes.h>, so define it globally as a test.

Discussion of this issue in other projects:
https://groups.google.com/a/chromium.org/forum/#!topic/chromium-reviews/FyaFYXyzZeU

https://stackoverflow.com/questions/8132399/how-to-printf-uint64-t-fails-with-spurious-trailing-in-format/8132440#8132440 stweil, I done more, that is:

git clone https://github.com/tesseract-ocr/tesseract.git
cd tesseract
./autogen.sh
./configure

export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig
export LIBLEPT_HEADERSDIR=/usr/local/include
export TESSDATA_PREFIX='/usr/local/share/'

LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make

but nothing... same error: 

In file included from rect.h:28:0,
                 from coutln.h:26,
                 from stepblob.h:23,
                 from werd.h:28,
                 from blobbox.h:25,
                 from blobbox.cpp:25:
blobbox.h: In member function 'void TO_BLOCK::print_rows()':
blobbox.h:737:61: error: expected ')' before 'PRId32'
         tprintf("Row range (%g,%g), para_c=%g, blobcount=%" PRId32 "\n",
                                                             ^
../ccutil/tprintf.h:31:39: note: in definition of macro 'tprintf'
 #define tprintf(...) tprintf_internal(__VA_ARGS__)
                                       ^
make[2]: *** [blobbox.lo] Error 1
make[2]: Leaving directory `/home/webuser/src/tesseract/ccstruct'
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `/home/webuser/src/tesseract'
make: *** [all] Error 2 I'm sorry Mr. jbarlow83, I didn't understand your advice, I don't know What to do, where do I pass CPPFLAGS='-D__STDC_FORMAT_MACROS=1' ?
Where do I see where Centos 7 set "#define __STDC_FORMAT_MACROS 1"?
thanks Try this:

    git clone https://github.com/tesseract-ocr/tesseract.git
    cd tesseract
    ./autogen.sh
    export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig
    ./configure CXXFLAGS="-D__STDC_FORMAT_MACROS=1"
    make
 I follow your step and replace "make" with LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make.

anything is to right, now I've (tesseract -v):

tesseract 4.00.00alpha
 leptonica-1.74.1
  libjpeg 6b (libjpeg-turbo 1.2.90) : libpng 1.5.13 : libtiff 4.0.5 : zlib 1.2.7

 Found AVX
 Found SSE

Only in order to understand, is the param CXXFLAGS="-D__STDC_FORMAT_MACROS=1" local to configure tesseract? do it don't interact with other config, right?
thanks

 We have two options:
1) Fix this issue (only relevant when the system glibc < 2.18)
2) Document the solution with the environment variable. I'd fix the issue by always setting `__STDC_FORMAT_MACROS` (that won't harm for newer glibc).

For the future, the format macros (also `REFFORMAT`) could be avoided by using C++ code instead of C format strings. Would including `cinttypes` instead of `inttypes.h` also fix the problem? In fact:
#ldd --version
ldd (GNU libc) 2.17

I resolve with __STDC_FORMAT_MACROS, but if I update glib, is it better?

Excuse me, stweil, but you haven't reply my question... thanks
"Only in order to understand, is the param CXXFLAGS="-D__STDC_FORMAT_MACROS=1" local to configure tesseract? do it don't interact with other config, right?" How do I include cinttypes? where do I find this file? where I put this file?
thanks > do it don't interact with other config, right?

Right.

> How do I include cinttypes?

Change file `ccutil/host.h` and replace the text `inttypes.h` by `cinttypes`. Done, the replace work fine. Which is the better solution?
__STDC_FORMAT_MACROS in configure or the replace?

do the 2 solution change something in the ocr by tesseract?
thanks

 >do the 2 solution change something in the ocr by tesseract?

No. > Done, the replace work fine. Which is the better solution?
__STDC_FORMAT_MACROS in configure or the replace?

I think using `cinttypes` is the better solution for C++ code like it is used in Tesseract.
Done in pull request #927. I prepared definitions of Docker containers and scripts that helps to compile and run Tesseract 4, take look at this: https://github.com/tesseract-shadow/tesseract-ocr-compilation  This error case results in fout_ == nullptr.
Closing a nullptr file is not allowed.

Signed-off-by: Stefan Weil <sw@weilnetz.de> The problem was reported as part of issue #529.  Was it solved? No, this is still an issue. `./configure && make distclean` fails in the source root directory. @Shreeshrii, now you can close this issue. It was fixed with PR #968 for the master branch and PR #971 for 3.05.  but allow failures

currently failing all this does it show you that the patches that are used in `brew` to build tesseract from source aren't up to date.

the long build time looks like an anomaly, try killing the travis process and restart it That new test now [passes without errors](https://travis-ci.org/tesseract-ocr/tesseract/jobs/233010095) (the brew formula for tesseract was fixed). Nevertheless building Tesseract with brew takes some time, so this test adds about half an hour to the Travis test time for each pull request or update of a branch. I‚Äå wonder whether that's reasonable.

> try killing the travis process and restart it

That won't help, because it takes that time to build Tesseract and all of its prerequisites.  When Tesseract terminates by calling the exit function,
the destructor of any local auto variable is not called.

Fix two cases by using static variables.

Signed-off-by: Stefan Weil <sw@weilnetz.de> Maybe we should use return instead of exit() Tesseract code includes more than 70 calls of `exit()`. Using `return` is a lot of work, even in `main()` (I already tried it). And static variables also reduce the stack frame size. I know someone who will be happy. :-) Yes, that sounds like the correct solution for C++ code. but not in Google projects... The 2nd commit fixes issue #529. Now Valgrind is happy, too:

    LEAK SUMMARY:
       definitely lost: 0 bytes in 0 blocks
       indirectly lost: 0 bytes in 0 blocks
         possibly lost: 0 bytes in 0 blocks
       still reachable: 8 bytes in 1 blocks
            suppressed: 0 bytes in 0 blocks
    
    ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
    ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
 You must be kidding...  This requires libminizip-dev, so expect failures from CI.

Up to now, little endian tesseract works with the new zip format.

More work is needed for training tools and big endian support and also to maintain
compatibility with the current proprietary format.

Signed-off-by: Stefan Weil <sw@weilnetz.de> Open questions:

- Do we want a new format? As I'm not the first one who had the idea, I think the answer is yes.
- Do we need support for both old (current) and new format? I'd drop support for the old format
  and remove `combine_tessdata`.
- Should the `traineddata` files in the new format add `.zip` to the file names? I'd omit `.zip`.
- Should the code for minizip be added to the Tesseract sources, or should we add an external dependency to libminizip-dev?
- Which one is better, zip or compressed tar? `libminizip-dev` was added in Ubuntu Xenial (16.04), so the current Travis build environment which is based on Ubuntu Trusty does not provide it. On my Debian system I find these libraries: [`minizip`](https://github.com/madler/zlib/tree/master/contrib/minizip) (supported since 16.04), [`libzip`](https://nih.at/libzip/) (supported since 12.04), [`zzlib`](http://zziplib.sourceforge.net/zzip-file.html) (supported since 12.04), [`libarchive`](https://github.com/libarchive/libarchive)  (supported since 12.04). As far as I know all use licenses which are compatible with Tesseract. I assume any of those can be used and expect that none of them will be available as a binary for Windows (maybe also not for macOS), but I did not have a look. Zip format reduces `eng.traineddata` from about 31 MiB to 16 MiB (48 % compression) by default. `zip -9` improves the compression to 49 %. Other compressed formats achieve even better compression values:

    31887360 eng.traineddata.tar
    31873501 eng.traineddata
    18121906 eng.traineddata.lz4
    16461487 eng.traineddata.zip (default)
    16372645 eng.traineddata.zip (maximum compression)
    15193532 eng.traineddata.tar.bz2
    13274164 eng.traineddata.tar.xz
    13273173 eng.traineddata.7z

    75100160 mya.traineddata.tar
    75085274 mya.traineddata
    42274775 mya.traineddata.lz4
    39468033 mya.traineddata.tar.bz2
    36296750 mya.traineddata.tar.gz
    36075469 mya.traineddata.zip
    28097639 mya.traineddata.7z
    27937332 mya.traineddata.tar.xz
 > Please move discussion to tesseract-dev forum. This is significant change.

See [this discussion](https://groups.google.com/forum/?hl=en#!searchin/tesseract-dev/zip|sort:date/tesseract-dev/U5HSugUeeeI) in the forum. I added a link to GitHub there. > libarchive handles all formats

It is also supported by current Linux distributions and would be interesting if compressed tar instead of zip is preferred. I added it to my previous post. > What about lz4?

It does not compress very good (see result added to the list above). Rebased and added support for `libzip`. This is experimental code, as there is still no decision whether compressed archives should be supported at all, if yes with which format and which library.

The current code uses `libzip`, if that is not found `minizip`. If neither of those is found, it uses the normal code. I prepared the code for more experiments to support compressed tar archives with `libarchive` for example. As you can see [here](https://github.com/tesseract-ocr/tesseract/pull/911/files#diff-4ec9988bbd350d92539e7ee9a30a2f91R48), the implementations for the two currently supported libraries are very similar. The latest code also supports `libarchive` (highest priority). With that library, all kinds of compressed archives should work (up to now I tested with zip only). As `libarchive` indeed supports all formats, I could compare the time needed for each format. Tesseract was run 5 times on each format with English on a simple hello world text. Below is the result sorted by time in seconds for each test. Interpretation:

- The original Tesseract format, uncompressed tar and lz4 tar are similar and fastest.
- zip needs about 150 ms more time than the original Tesseract format.
- 7z and xz tar need about 850 ms more time than the original Tesseract format.
- bz2 tar is slowest and needs about 1450 ms more time than the original Tesseract format.

The file i/o from disk did not play a role in this test because of the Linux file cache and the SSD of my computer.

      0.13 eng.traineddata.tar
      0.14 eng.traineddata
      0.14 eng.traineddata.tar
      0.14 eng.traineddata.tar
      0.14 eng.traineddata.tar
      0.15 eng.traineddata
      0.15 eng.traineddata.tar
      0.15 eng.traineddata.lz4
      0.16 eng.traineddata
      0.16 eng.traineddata
      0.17 eng.traineddata.lz4
      0.17 eng.traineddata.lz4
      0.18 eng.traineddata
      0.18 eng.traineddata.lz4
      0.22 eng.traineddata.lz4
      0.29 eng.traineddata.zip
      0.29 eng.traineddata.zip
      0.29 eng.traineddata.zip
      0.30 eng.traineddata.zip
      0.30 eng.traineddata.zip
      0.97 eng.traineddata.7z
      0.98 eng.traineddata.7z
      0.98 eng.traineddata.7z
      0.99 eng.traineddata.7z
      0.99 eng.traineddata.tar.xz
      0.99 eng.traineddata.tar.xz
      1.00 eng.traineddata.tar.xz
      1.00 eng.traineddata.tar.xz
      1.00 eng.traineddata.tar.xz
      1.04 eng.traineddata.7z
      1.55 eng.traineddata.tar.bz2
      1.56 eng.traineddata.tar.bz2
      1.61 eng.traineddata.tar.bz2
      1.62 eng.traineddata.tar.bz2
      1.66 eng.traineddata.tar.bz2
 Test results with `libarchive` for `mya.traineddata` (the largest of all `traineddata` files). I did not test lz4, but added a test with gz format.

    0.48 mya.traineddata.tar
    0.49 mya.traineddata
    0.49 mya.traineddata.tar
    0.49 mya.traineddata.tar
    0.49 mya.traineddata.tar
    0.50 mya.traineddata
    0.52 mya.traineddata
    0.52 mya.traineddata.tar
    0.54 mya.traineddata
    0.54 mya.traineddata
    0.79 mya.traineddata.tar.gz
    0.80 mya.traineddata.tar.gz
    0.80 mya.traineddata.tar.gz
    0.82 mya.traineddata.zip
    0.84 mya.traineddata.zip
    0.85 mya.traineddata.zip
    0.86 mya.traineddata.tar.gz
    0.86 mya.traineddata.zip
    0.88 mya.traineddata.tar.gz
    0.90 mya.traineddata.zip
    2.38 mya.traineddata.7z
    2.38 mya.traineddata.7z
    2.38 mya.traineddata.tar.xz
    2.40 mya.traineddata.7z
    2.41 mya.traineddata.tar.xz
    2.45 mya.traineddata.7z
    2.45 mya.traineddata.tar.xz
    2.46 mya.traineddata.7z
    2.46 mya.traineddata.tar.xz
    2.49 mya.traineddata.tar.xz
    3.69 mya.traineddata.tar.bz2
    3.74 mya.traineddata.tar.bz2
    3.75 mya.traineddata.tar.bz2
    3.79 mya.traineddata.tar.bz2
    3.84 mya.traineddata.tar.bz2

`libzip` gives similar results, but only supports the zip format:

    0.83 mya.traineddata.zip
    0.84 mya.traineddata.zip
    0.87 mya.traineddata.zip
    0.88 mya.traineddata.zip
    0.93 mya.traineddata.zip

`libminizip`:

    0.84 mya.traineddata.zip
    0.84 mya.traineddata.zip
    0.85 mya.traineddata.zip
    0.87 mya.traineddata.zip
    0.92 mya.traineddata.zip

`libzzip`:

    0.75 mya.traineddata.zip
    0.78 mya.traineddata.zip
    0.78 mya.traineddata.zip
    0.79 mya.traineddata.zip
    0.84 mya.traineddata.zip
 lzma created the xz files. 7zip and lzma gave the best compression ratios, but both also need some time for the decompression (which is relevant for Tesseract): they need about 1.9 s more time (but still are faster than bz2).

Please note that the current code for all formats reads all parts of the `tessdata` file, no matter whether they are used or not, so the decompression overhead could be reduced. The current Tesseract code reads the whole `tessdata` file into memory and gets all data from memory. My implementation for compressed archive files does that, too. Therefore random access is trivial: all component files are in a vector of byte arrays. Why zip not tar? Maybe because zip is supported on Windows by default, while tar and other formats need additional installations? I use 7-Zip on Windows to compress and decompress files. See also https://en.wikipedia.org/wiki/Comparison_of_file_archivers. > I have no objection to switching to zip (with no tar) for the tessdata files. That should be usable by everybody more easily.

On Windows, that would require a rename with `.zip`extension, or the installer must register `.traineddata` as a zipped data type. Otherwise the Windows explorer won't decompress such files easily. Personally I prefer to keep the `.traineddata` extension even for zip files (like Java does it with its `.jar` extension). Now I added implementation and timing results for zziplib. It looks like this is the fasted code for reading zipped `traineddata` files. > combine_tessdata is used for extracting components, replacing some, etc.
Probably first step can be a zippeddata file which after unzipping provides the traineddata.

Zipping a tessdata file means extracting the components from that file and writing a zip archive file which includes those components. So combine_tessdata can be replaced by your favorite zip / unzip program. We are talking about 2: files in zip archive format which include compressed components.

Such files can be written and read by all common operating systems. Linux file explorers are clever and know how to handle such files even if they are named `eng.traineddata`. The Windows explorer is not clever. It expects a know file extension. So if users want to see what is inside of `eng.traineddata` and use the Windows explorer as a GUI replacement for `combine_tessdata`, I must set a Windows registry key which tells the file explorer that the `traineddata` extension is handled like `zip`. > This would help us to have installation of 3.05 and 4.00 at the same time and to avoid mistakes like using combine_tessdata on compressed data.

Currently `combine_tessdata` crashes when it is tried with a compressed archive. It can be made more robust to simply fail with such data, or it could report if it gets a zipped archive (if we restrict to zip support). Such code can also be back ported to 3.05. I don't think that using the same `tessdata` directory for 3.05 and for 4.x is a good idea. Therefore I don't think that 4.x needs a different file extension for `tessdata` in zip format.

Platform support is good on Linux (minizip in latest distributions, libzip, libzzip and libarchive also in older ones), but macOS with brew should also support all four libraries (untested), and so does Cygwin with Mingw-w64 for Windows. I don't know the situation for Visual Studio, but expect that small libraries like `libzzip` for example are much easier to build than larger libraries with more functionality like `libarchive`. Then I suggest to use `libzzip` (sometimes also called `zziplib`) if zip support is sufficient because it looks like the fastest one, and it is also small.

`libarchive` is a good choice (the only one I know) if any common compressed archive format should be supported. > Would same extension cause confusion as to which version of traineddata file was being used?

Software can detect the format automatically. That can be added to 3.05, too, so that version would simply refuse to read files in the wrong format.

With a standard archive format (like zip), it would be easy to write additional information into the archive files, for example a README or a VERSION file. Tesseract would ignore any such component which it does not know. zziplib seems to be inactive for years.

https://sourceforge.net/projects/zziplib/?source=navbar
https://sourceforge.net/p/zziplib/svn/HEAD/tree/
https://sourceforge.net/projects/zziplib/files/zziplib13/
https://sourceforge.net/p/zziplib/patches/?source=navbar

Choosing more than one library and one format for compression will make maintenance more complicated. > zziplib seems to be inactive for years.

Then either it is a small and stable code, or it is unsupported for some reason.
Which library would you suggest? Check what other well known projects use.
For example, the Debian cmake package depends on zlib and libarchive. > zziplib seems to be inactive for years.

It was unmaintained for several years until some weeks ago. I found it maintained on [GitHub](https://github.com/gdraheim/zziplib). Speed is more important than disk space. That means LZ4 is probably the best candidate, as the English test indicated. It was designed for this sort of situation and is the tool of choice for e.g. Linux kernel and initramfs decompression on low memory devices.
https://lz4.github.io/lz4/#interoperable-lz4 > Speed is more important than disk space.

We are talking about typically less than 300 ms needed for large zip archives, so a Tesseract run with several languages would maybe run 1 s longer with zip archives. Is that too much when typically Tesseract runs for much more than 10 s?

Tesseract could be optimized by processing many image files in a single run. Then loading of `tessdata` files is needed only once. If a standard format is used for `traineddata`, we no longer can derive the data endianness from the file format. So either endianness information must be added somewhere in the archive (in the `config` component?), or all code must be changed to read and write a fixed endianness. I have a personal opinion on this issue, but in the end that's something @theraysmith must decide. @stweil My typical Tesseract workload is tens of thousands of images in a cloud. Combining disparate images into a multipage TIFF is a pain. My files come as PDFs anyway; it's a good format to normalize files to. Then I use my program ocrmypdf to split them into one page images and recombine. In short, I map-reduce Tesseract processes over single page images, with all the usual scaling and robustness benefits. A long running process that does a lot of work is expensive to have crash.

Since AWS compute time is per unit time, adding 1 second per Tesseract process would be something like a 1-2% increase in my bills, while decreasing storage would have no measurable savings because the incremental gain is small compared to the size of the operating system. (And most charge for a pool of storage rather than storage actually used.)

I do support the change, I just think LZ4 hits the sweet spot for this sort of problem. @jbarlow83, I did not mean using multipage TIFF images, but enhancing the Tesseract command line API to allow passing more than one image file. That should reduce the compute time for your use case already with the current `traineddata` file format. Another Benchmark:
https://github.com/powturbo/TurboBench >Tesseract could be optimized by processing many image files in a single run. Then loading of tessdata files is needed only once.

Actually, this feature is supported with 4.0/3.x. > Actually, this feature is supported with 4.0/3.x.

I did not know that. How would I start Tesseract to process page1.png and page2.png in a single run? Prepare a text file that has the path to each image:

```
path/to/1.png
path/to/2.png
path/to/3.tiff
```

Save it, and then give its name as input file to Tesseract.

`tesseract savedlist output` Thank you, good to know that. It looks like the ChangeLog, other documentation and the program help text need an update.

Currently all pages are written to one output file (per format). Some formats include page information (hOCR, PDF). Others like TXT don't, but could use a page separator character (ASCII 0x0C = FF). Would it help to support an output base parameter with placeholders like page number or image base name to generate one output file per input image? Maybe we should discuss the multi page feature in another issue.

I don't like mailing lists. Also Ray replies more in Github issues/PRs. 
What about opening a new repo on Github for dev discussions via issues? The multi-page feature was added in 2014 by commit 25a8c7b72006a11ba0b31dfd5210f7b9401eb27d. Guys, can you add checkboxes to the eng.traineddata? 

![6-1-2017 3-51-27 pm](https://cloud.githubusercontent.com/assets/26609019/26698052/4c0fa150-46e2-11e7-8f87-13bade4c0af5.png)
 I'd like to summarize the current status:

- A new format would be good, and there is a preference for the `zip` format.
- The new format would replace the old one for Tesseract 4 (no fallback necessary).
- We can keep the current names (*.traineddata). 3.05 won't load new format, 4.x won't load old format.
- `libarchive` seems to be the best choice to implement the `zip` format as it is widely available and supported.
- The `zip` format no longer includes an implicit indicator for the endianness of the trained data. A fixed endianness (little endian) for stored data does not look like a possible option for now, so an explicit endianness indicator must be added to the data in the config component.

Is there anything I missed or are there other opinions? If not, I'd implement the code and create a pull request. Rebased PR and fixed merge conflicts. @theraysmith commented:

 >Are we talking about
>...
>2. compressing the components of a file using zlib and changing
tessdatamanager to allow that. FIles are otherwise uncompressed.
>...
>?
>
>I thought we were talking about 2...

@stweil commented:

>We are talking about 2: files in zip archive format which include compressed components.

It seems to me that Stefan and Ray are thinking about two different ways to implement compression:

Stefan's way is to create one zip archive from the files in traineddata. 
combine_tessdata won't be needed anymore. The user will use an external program to compress and decompress the traineddata (zip) file. 
Stefan patch adds the ability to read (uncompress) the zip archive by TessdataManager.

Ray's way is to use the zlib library directly to compress individual files inside traineddata without creating a zip archive.
combine_tessdata will still be needed by the user.
 Thank you, Amit, for the clarification. Yes, I'd replace the proprietary `tessdata` format by the standard `zip` format. Users could still use `combine_tessdata` (it would support both old and new format), but they could also use any other program (for example the Windows file explorer which can handle zipped files) to create or expand the new tessdata files in zip format.

As there was a preference for using `libarchive`, there would even be more options because that library supports a whole range of compression and archive formats. Some of those formats compress the whole archive (typically a `tar` format) instead of compressing the single components. Ray seems to want just zlib without anything else.

We need an 'OK' from him to go in your way which depends on another library.  A wrong array index must raise an assertion instead of printing an
error message and continuing program execution.

Replace also floor by floorf which can be faster.

Signed-off-by: Stefan Weil <sw@weilnetz.de> Some random thoughts while waiting for my pull requests to be merged:

How about C++-style `static_cast<int>()` instead of C-style `(int)`? Since casting to integral types rounds toward 0, you can also omit the `floorf()` if `bottom` is known to be nonnegative... unless any overhead is known to be negligible or eliminated by the compiler anyway (probably not, unless the compiler can somehow deduce the sign of the value at compile time)? If you capture this in a macro or in an always-inlined function (has C++11 standardised that?), it doesn't even have to be explained every time.

It's also quite ad hoc: a separate issue, and only addressed locally. That's true. While looking closer on that code, I noticed that it can be more simplified. We don't need float operations here. I'll update the commit. Shree, Ray does his reviews **after** Zdenko merges PRs here. @stweil Hmm, I suspect that g++ kept -Wconversion out of -Wall/-Wextra because otherwise too much existing code would have to be adapted, not because not using casts for floating-integral conversions is necessarily a good idea... just my 2 cents. MS VC produces 1453 warnings for Tesseract (see results from Appveyor CI), most of them caused by data type conversions. It looks like most developers don't like fixing this kind of warning, and gcc simply supports that. :-) Should we make it less verbose there? No, I don't think so. We should make the release builds with configure / make more verbose (`gcc -Wall` is currently only used for debug builds).  Hey, i have been using tesseract for text extraction from images. But due to some unknown reasons, it is unable to extract text from some images even if the image is clean. I am unable to find the reason for this. Is there anything that i am missing in preprocessing?
original image:
![depot](https://cloud.githubusercontent.com/assets/20331292/25936270/625951fc-3640-11e7-9542-32636ed6126e.jpg)
Binarized image:
![depot 1 jpg-binarized](https://cloud.githubusercontent.com/assets/20331292/25936398/fbb85e7e-3640-11e7-86b5-e811f5593e0b.png)
  I never used a library as complicated as this one, I use Linux Java. Well I manage to make tess4j work, then copied all the source packages and libraries into my project, everything seemed fine but when I try running it I get the errors 
`Info in bmfCreate: Generating pixa of bitmap fonts from string
Error opening data file ./eng.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to your "tessdata" directory.
Failed loading language 'eng'
Tesseract couldn't load any languages!
#
# A fatal error has been detected by the Java Runtime Environment:
#
#  SIGSEGV (0xb) at pc=0x00007f7d7f292197, pid=24436, tid=0x00007f7db9f03700
#
# JRE version: Java(TM) SE Runtime Environment (8.0_131-b11) (build 1.8.0_131-b11)
# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.131-b11 mixed mode linux-amd64 compressed oops)
# Problematic frame:
# C  [libtesseract.so+0xc3197]  tesseract::Tesseract::recog_all_words(PAGE_RES*, ETEXT_DESC*, TBOX const*, char const*, int)+0x5e7
#
# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try "ulimit -c unlimited" before starting Java again
#
# An error report file with more information is saved as:
# /home/big-daddy/netbeansprojects/LicencePlateRecognition/hs_err_pid24436.log
#
# If you would like to submit a bug report, please visit:
#   http://bugreport.java.com/bugreport/crash.jsp
# The crash happened outside the Java Virtual Machine in native code.
# See problematic frame for where to report the bug.
#`

What I dont understand is why does Tess4j default project manage to load the language files whilst mine fails?

 It is set that's why the tess4j works in its default package before
importing it into my project
On May 11, 2017 10:04 AM, "Shreeshrii" <notifications@github.com> wrote:
>>
>> Please make sure the TESSDATA_PREFIX environment variable is set to your
"tessdata" directory.
>
> Please set this variable for tesseract to find the traineddata files.
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub, or mute the thread.
  Use the [RAII](https://en.wikipedia.org/wiki/Resource_acquisition_is_initialization) idiom, e.g., to help prevent memory leaks. Build error: https://travis-ci.org/tesseract-ocr/tesseract/jobs/230329088#L290. Yes, I think it's a bug in that g++ version (4.8.4). I had successfully built with 5.4.0. I'll try again with an explicit move constructor... Are they all tested? I think that it was valid C++11, though.

Amended, pushed...

And again... Since you change the API, I think we need Ray's approval for this PR. If that's public API and cast in stone, maybe there should be two versions, with the backward-compatible version calling the safe version with release(). Or the leak could be fixed ad hoc, but that's not really progress.

(Added) Is the public API not tested?

(Added) I don't see any documentation mentioning `ccmain/resultiterator.h` as part of the API? Ah, apparently the result of `tesseract::TessBaseAPI::GetIterator ()`, that sounds very API-ish. I would start with fixing the leak with the current API.
~~If you want to do it, open a new PR.~~

Fixing a leak is still progress... Maybe tomorrow, but I would still suggest to add a new version and deprecate the current one, because this is C++, and RAII is one of C++'s most useful idioms (to put it mildly). That's why I made a new thread called `RAII`, not `lookifoundaleak`... Yes, but it can also return nullptr, and I hadn't yet figured out whether there's a difference with the empty string. Adding to a STRING is apparently the same for nullptr and empty string, but maybe not other applications. And there's at least one use of release() that would then instead have to make a new copy.

(Correction) I meant strdup() instead of strcpy(), but that's even more expensive because it needs two passes, so let's stick with "make a new copy".

(Added) virtual ResultIterator::GetUTF8Text() hides non-virtual LTRResultIterator::GetUTF8Text, that doesn't look great... Amended without API change, checks successful.
 LGTM. @stweil? I plan to run a test with Valgrind later (~ 1 day) and will add my review comment then. >but I would still suggest to add a new version and deprecate the current one, because this is C++, and RAII is one of C++'s most useful idioms (to put it mildly).

The new version of this PR uses RAII technique, without an API change :)
http://stackoverflow.com/questions/29372976/is-stdunique-ptr-an-application-of-raii  There seems to be another leak in `void POLY_BLOCK::fill(ScrollView* window, ScrollView::Color colour)`, which doesn't do `delete segments;`. But I've had enough fun for now...  >I've had enough fun for now...

:laughing:  Well, it seemed to be leaked, from comparing with other uses, although I'm not 100% certain... Rebased.  Important warnings warrant attention because they may indicate real problems.
Unimportant warnings warrant attention because they obscure the important warnings.

Unfortunately for me the nicest example of the former category, where I also immediately had a solution, was already fixed independently...

This replaces earlier attempts, now up to date, on its own branch, and with some revisions. >Warnings are people too!

I see that you changed the title this time... :-) I suggest to make smaller pull requests which focus on closely related problems. That would make reviewing and pulling them much easier. Example: Make a pull request for all changes related to `NumFeatureSets`.

For that example, the `decltype(CharDesc->NumFeatureSets) i` will work. Nevertheless I personally prefer the much simpler `uinT32 i`. Even better because we want to use POSIX instead of Tesseract data types: `uint32_t i`. You mean like the diminutive "Use POSIX data types and macros" with only 21 commits and 243 files changed?

Yeah, at first I thought `typedecl()` would be less unpopular than a public `GenericVector::unsigned_size()`, but I went a bit overboard with it, and I let the cat out of the bag with `STRING::unsigned_size()` anyway, so... I've amended the pull request without any `typedecl()`, with public `GenericVector::unsigned_size()`, but with `size_t` rather than `uintT32`/`uint32_t`. I don't expect that pull request #878 will be applied like that, but yes, it consists of smaller commits which cover limited modifications and which can be applied individually. Even individual #878 commits are _way_ bigger than this whole pull request (or at least the one I randomly picked). Feel free to split it up further as you like, but I don't see the point: it's already themed by kind of warning, and the larger of the two commits is only +32/‚àí24. Rebased.

TODO: warnings from "make training" Warnings from "make training". Rebased.

The remedies were not always obvious, so comments welcome.  when i use tesseract with -l fas some time i get sequence error like follow:
 = ⁄§⁄©⁄µ€±€¥ŸÄ€µŸÄ⁄©ŸàŸÇ€ï⁄Ø|ÿ≠ŸáÿØÿ≥ŸÄŸ•ÿØÿ±ŸÖÿ≠ŸÖŸàÿ¥€ÄŸÉÿßÿ≠ŸÖŸàÿ±ŸáŸæŸÄŸàÿ±ÿßŸÜ ŸÅ
for this image
![20170506_133142](https://cloud.githubusercontent.com/assets/10100596/25782692/f4c2dfc4-3364-11e7-861a-f3da05d37dc3.jpg)

also this error occur in arabic language
how can i change configs or tessconfig to fix this bug? Hi,

what is the version of the tesseract and leptonica that you have used? 
i made detection on the image that you have shared and got the following results (disregard the numbers):
ÿ¥⁄©ŸÑ ⁄©Ÿàÿ¥⁄© ÿßÿ≠ŸÖÿØ ÿ¥ÿßŸá ÿØÿ± ŸÖÿ¨ŸÖŸàÿπ€Ä ⁄©ÿßÿÆ ŸÖŸàÿ≤€Ä ŸÜ€åÿßŸàÿ±ÿßŸÜ
although the training was on the Arabic files not Farsi  orginal image:
![20170506_133142](https://cloud.githubusercontent.com/assets/10100596/25798783/c20f7ae0-33f7-11e7-978b-dd47a6c98b06.jpg)

please test this image.
 @Nigje 

this is the results

ÿπ⁄©ÿ≥Ÿáÿß€å ÿØŸàÿ±€Ä ŸÇÿßÿ¨ÿßÿ± /
/ ÿ¢ÿ´ÿßÿ± ŸÜŸÇÿßÿ¥€å ŸáŸÜÿ±ŸÖŸÜÿØÿßŸÜ ÿß€åÿ±ÿßŸÜ€å
_ __ ŸáŸÜÿ±Ÿáÿß€å .. .
__ ŸÖ€åŸÜ€åÿßÿ™Ÿàÿ± Ÿà ÿ¢ÿ´ÿßÿ± ÿÆŸÜÿ±Ÿáÿß€å ÿ≥ŸÜÿ™€å _

_ ¬© ¬© ¬© ÿ±Ÿàÿ¥Ÿáÿß€å ÿ™ŸàŸÑ€åÿØ ÿ®ÿ±ŸÅ
_ ÿ≥€åÿ± ÿÆÿ∑Ÿàÿ∑ ÿØÿ± ÿß€åÿ±ÿßŸÜ __
ŸÜŸÇÿßÿ¥€å Ÿà ŸÖ€åŸÜ€åÿßÿ™Ÿàÿ± ÿßÿ≥ÿ™ÿßÿØ ŸÅÿ±ÿ¥ÿ¨€åÿßŸÜ

ŸÇÿßŸÑ€åÿå ŸÜŸÇÿßÿ¥€åÿå ÿÆÿ∑ Ÿà ÿ¢ÿ´ÿßÿ± ÿØŸàÿ±ŸáŸáÿß€å

ÿß ÿß

0 ÿ¢ÿ´ÿßÿ± ÿ®ÿßÿ≥ÿ™ÿßŸÜ€å Ÿà ŸáŸÜÿ±Ÿáÿß€å ÿ™€åŸà€å ÿ± ÿ≤
ÿ¢ÿ´ÿßÿ± ÿØŸàÿ±€Ä ŸÇÿßÿ¨ÿßÿ± Ÿà ŸæŸáŸÑŸà€å Ÿà ŸáÿØÿß€åÿß€å ÿ®ÿπÿ∂€å ⁄©ÿ¥Ÿàÿ±Ÿáÿß .
_ ÿ™ŸÅÿßÿ¥€å Ÿáÿß€å ÿØŸàÿØ€Ä ŸÅÿßÿ¨ÿßÿ± ÿ± .

_ ÿßÿ¥€åÿß Ÿà ÿ™ÿß€åŸÑŸàŸáÿß€å ÿßÿ±ŸàŸæÿß€å€å ŸáÿØ€åŸá ÿ¥ÿØŸá ÿ®Ÿá ÿØÿ±ÿ®ÿßÿ± ŸÇÿßÿ¨ÿßÿ± _
/ ÿπ⁄©ÿ≥Ÿáÿß€å ÿØŸàÿ±€Ä ŸÇÿßÿ¨ÿßÿ± 5

ÿ¢ÿ´ÿßÿ± ÿØŸàÿ±€Ä ŸæŸáŸÑŸà€å

 

ŸáŸÜÿ±€åÿå ÿ™ÿÆÿµÿµ€å

" ÿßŸÜŸàÿßÿπ ⁄ØŸàŸÜÿß⁄ØŸàŸÜ ⁄ØŸÑ Ÿà ⁄Ø€åÿßŸá

 

 

ÿ¥⁄©ŸÑ ⁄©Ÿàÿ¥⁄© ÿßÿ≠ŸÖÿØ ÿ¥ÿßŸá ÿØÿ± ŸÖÿ¨ŸÖŸàÿπ€Ä ⁄©ÿßÿÆ ŸÖŸàÿ≤€Ä ŸÜ€åÿßŸàÿ±ÿßŸÜ

as you can see the detection is quite good but the problem is that, the column on the right wasn't detected, but the column on the left was detected, also the text below the house is detected as well I build tesseract with vs2015 and use api.

for build tesseract also i have built 
leptonica-1.74.1  [MSC v.1900 LIB Debug x64]
 libgif 4.1.6(?) 
 libjpeg 9a 
 libpng 1.6.29 
 libtiff 4.0.7 
 zlib 1.2.

i don't known what is problem !!?
 ‚Äãdo you get any error?‚Äã
 Default PSM values:
API - 6
Command line - 3 @roozgar i got an error but i think its due to the picture itself, the message was: "image too small to scale"
not a detection error i think

i tired the detection one more time with the argument psm , seems both columns were detected, the accuracy seems good, since I'm detecting against Arabic lstmf files with fas.traineddata, but i got to ask, if what is the typical order for detecting a table, is it each row is been detected as a line?

@Shreeshrii i know about this issue, actually i was the one who mentioned that problem at the first place :)  @Nigje 

here are the new results, the full command was: tesseract farsi2.jpg results_farsi -l fas ./tessdata-dir ./tessdata  --oem 1  --psm 6

Ÿ°
2 .
ÿ≥ÿ±ÿßŸÜ ŸÑ: ÿ¥ €∞
ŸÜ ÿπ⁄©ÿ≥ ÿÆÿßŸÜŸá ÿπ⁄©ÿ≥ Ÿáÿß€å ÿØŸàÿ±€Ä ŸÇÿßÿ¨ÿßÿ±
ÿ≥ ÿßÿ± ŸÜ Ÿ£8 Ÿá €å | ŸÜ ÿ± __ _ ÿπÿß⁄©ŸÉÿ≥ ŸÜ€åÿß ŸÅŸàŸÅ€Ä ÿß ⁄Üÿß ÿ± €å ÿß
8 ŸáŸÜÿ±Ÿáÿß€å ÿ≤€åÿ®ÿß ÿ¢ÿ´ÿßÿ± ŸÜŸÇÿßÿ¥€å ŸáŸÜÿ±ŸÖŸÜÿØÿßŸÜ ÿß€åÿ±ÿßŸÜ€å €±
ÿ≥ÿ≥ÿ™ 55555 ŸÜÿ™. 05555
€≤€∂ __ ÿÆÿ™ÿ±Ÿáÿß€å ÿ®Ÿáÿß€å _ |. ÿ¨ÿ™ 7 - ŸáŸÜÿ±Ÿáÿß€å ÿ™ÿ¨ ÿ®€åÿßÿ± ÿ™€å ÿ®Ÿàÿ™ €å ÿ≥ ÿ®ÿ™ ÿ™€å ÿ™ ÿ®€å __
€≤€∑€≤ . = ÿßÿ¨ Ÿæ ÿ≥ __ Ÿàÿßÿ±ŸàŸÜ ŸáÿßŸà ÿÆÿ± ÿ± ÿ± ÿ≥ÿ≥
€∏ ÿµŸÜÿπÿ™ ÿ®ÿ±ŸÇ ÿ±Ÿàÿ¥Ÿáÿß€å ÿ™ŸàŸÑ€åÿØ ÿ®ÿ±ŸÇ .
ÿ≥ÿ±€å ÿ≥Ÿàÿ™ Ÿæ 7-72 ÿØÿß ÿÆÿ± ÿµÿØ ÿ≥ÿ≥ÿ™ ÿ≥ ŸÖ€å €å ÿ≥ €≥€∑ / 2 ÿÆ % ÿ®- 7 €∑€∞€∞ [
| €π { ŸÖ€åÿ±ÿπŸÖÿßÿØ . | ÿ≥€åÿ± ÿÆÿ∑Ÿàÿ∑ ÿØÿ± ÿß€åÿ±ÿßŸÜ
ÿ≥ÿ™ ÿÆÿ≥ ÿÆ Ÿæ Ÿæ€åÿ™ Ÿæ€å ÿ™ÿ® ÿ±ÿ™ ÿ±Ÿæ ÿ™ [ 5 5 ÿ≥ÿ≥ÿ™€å ÿ≥ . . ÿ≥ ÿ≥ÿ≥ÿ™ ⁄©ÿ± ÿ≥ÿßÿ™ ÿ¨ÿ™ ÿ¨ŸÖ
ÿß ÿß ŸÜŸÇÿßÿ¥€å ŸàŸÖ€åŸÜ€åÿßÿ™Ÿàÿ±ÿßÿ≥ÿßÿØ ŸÅÿ±ÿ¥⁄Ü€åÿßŸÜ ÿß
Ÿà ÿµÿßÿ≠ÿ®ŸÇÿ±ÿßŸÜ€åŸá ŸÇÿßŸÑ€åÿå ŸÜŸÇÿßÿ¥€åÿå ÿÆÿ∑ Ÿà ÿ¢ÿ´ÿßÿ± ÿØŸàÿ±ŸáŸáÿß€å
ÿß ŸæŸáŸÑŸà€å ŸàÿµŸÅŸà€å ÿß
€≤ __ ÿ¨ŸáÿßŸÜŸÜŸÖÿß _ ÿ± ÿß. ÿ¢ÿ´ÿßÿ±ÿ®ÿßÿ≥ÿ™ÿßŸÜ€å Ÿà ŸáŸÜÿ±Ÿáÿß€å ÿ™ÿ¨ÿ≥ŸÖ€å ÿ± ŸÖ ÿ≥ÿ™ |
€≥ __ ⁄©ÿßÿ¨ ÿßÿ≠ŸÖÿØÿ¥ÿßŸá€å ÿ≥ ÿß€åÿ± _ __ ÿ¢ÿ± ÿØŸàÿ±€Ä ŸÅÿßÿ¨ÿßÿ± Ÿà ŸæŸáŸÑŸà€å Ÿà ÿ¨ÿØÿß€å ŸÜ€å ⁄©ÿ± €å |
€¥ ! ŸÜ⁄Øÿßÿ±ÿÆÿßŸÜŸá Ÿ° ŸÜŸÇÿßÿ¥€åŸáÿß€å ÿØŸàÿ±€Ä ŸÇÿßÿ¨ÿßÿ± 2
ÿ≥ÿ≥ Ÿàÿ™ ŸÖ Ÿà Ÿ¶Ÿ£Ÿ£Ÿ£ ŸæŸæÿ™ Ÿ£Ÿ£-00005005 ÿ¢ÿ®ÿß ÿ™ ⁄© ÿ® ⁄Ü ÿ™ Ÿæ€åÿ≥ ⁄© Ÿæÿ≥ €∞ ÿ≥€åÿ® ÿß ÿ™ÿ≥ÿ™ €å €å ÿ® ÿ≠€å
€µ __ ÿ≠ÿÆŸàÿ∂ŸÅÿßŸÜŸá __ ÿßÿ¥€åÿß Ÿà ÿ™ÿßÿ®ŸÑŸàŸáÿß€å ÿßÿ±ŸàŸæÿß€å€å ŸáÿØ€åŸá ÿ¥ÿØŸá ÿ®Ÿá ÿØÿ±ÿ®ÿßÿ± ÿ¢ŸÇÿß ÿ¨ÿßÿ± .
€≥€∂ | ÿπ⁄©ÿ≥ ÿÆÿßŸÜÿØ ÿ™
ÿ≥ ÿ± ÿß ÿ±€å ÿ± ÿ± ÿ±ÿß ÿß _ - . ÿ≥ _ ÿ™ 7 ÿ±ÿß . ÿ≥ÿ≥ÿ™ . ÿ≥ ÿ® Ÿá €å ÿ± ÿµÿµ
| ÿ≥ ⁄Ø€å ÿ≥ ÿ™ ÿ™ ÿ≥ ÿ® ÿØÿ≥ ÿ®€å ÿß. €å ŸÜ ÿß €åÿÆ ⁄Ø€å €å ŸÅÿß ÿ± [
€∏ | ⁄©ÿßÿÆ ŸÖŸÑÿ™ ÿ¢ÿ´ÿßÿ± ÿØŸàÿ±ÿ© ÿ®Ÿáÿßÿ± ÿ®€å Ÿ°
ÿ¥€å⁄© 5555___ 00055 €±0055 ÿ≥ __ ŸÑŸà€å ÿ™ÿÆÿµÿµ€å ÿß ÿß ÿß €å
Ÿ° ] €¥€∞€∞ [__ ⁄Ø€åÿßŸáÿßŸÜ ÿØÿßÿ±Ÿà€å ÿ≥ŸÜÿ™€å ÿß ÿßŸÜŸàÿßÿπ ⁄ØŸÑ Ÿà ⁄©ÿ®ÿØ ÿß
€± 3 €∞Ÿà ÿßÿ™ . €∞ % . ⁄© ÿß€åÿß %
. €å ŸÜ ⁄©ÿ™ ÿ≠ÿµÿ± ÿß
ÿ¥⁄©ŸÑ ⁄©Ÿàÿ¥⁄© ÿßÿ≠ŸÖÿØ ÿ¥ÿßŸá ÿØÿ± ŸÖÿ¨ŸÖŸàÿπ€Ä ⁄©ÿßÿÆ ŸÖŸàÿ≤€Ä ŸÜ€åÿßŸàÿ±ÿßŸÜ
€≤
 @Nigje 
i never used the tesseract api on vs, i use the tesseract engine, the tesseract version that im using is tesseract 4.00alpha with leptonica 1.74.1, and its not possible for any version prior to 4.00alpha to detect Arabic, or Farsi or Urdu, as the new engine contains lstmf files which you can use on detection by adding the argument --oem 1 @ibr123 @roozgar @Shreeshrii @amitdo 
tanks for your comments, problem  resolved.

> tesseract.exe test.png test -l fas --oem 1 --psm 6

 --oem 1 forced tesseract to use only Lstm.  Hello,

First thanks for your job. I am trying to run tesseract 4 but I am getting an issue:

`
Info in bmfCreate: Generating pixa of bitmap fonts from string
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
Aborted (core dumped)
`

Step to reproduce (with a docker file):

	FROM ubuntu
	RUN apt-get update && apt-get install -y \
		autoconf \
		automake \
		libtool \
		autoconf-archive \
		pkg-config \
		libpng12-dev \
		libjpeg8-dev \
		libtiff5-dev \
		zlib1g-dev \ 
		libicu-dev \
		libpango1.0-dev \
		libcairo2-dev \
		git \
		curl && \
		rm -rf /var/lib/apt/lists/*

	RUN curl http://www.leptonica.org/source/leptonica-1.74.1.tar.gz -o leptonica-1.74.1.tar.gz && \
		tar -zxvf leptonica-1.74.1.tar.gz && \
		cd leptonica-1.74.1 && ./configure && make && make install && \
		cd .. && rm -rf leptonica*

	RUN git clone --depth 1 https://github.com/tesseract-ocr/tesseract.git && \
		cd tesseract && \
		./autogen.sh && \
		./configure --enable-debug && \
		LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make && \
		make install && \
		ldconfig && \
		make training && \
		make training-install && \
		cd .. && rm -rf tesseract

	# Get basic traineddata
	RUN curl https://github.com/tesseract-ocr/tessdata/raw/master/eng.traineddata > eng.traineddata && \
		mv eng.traineddata /usr/local/share/tessdata/

	RUN curl https://github.com/tesseract-ocr/tessdata/raw/master/fra.traineddata > fra.traineddata && \
		mv fra.traineddata /usr/local/share/tessdata/

Then:

	docker build -t tesseract4 .
	docker run tesseract4
	docker run -t -i tesseract4 /bin/bash
	mkdir test
	cd test
	curl http://tleyden-misc.s3.amazonaws.com/blog_images/ocr_test.png > test.png
	tesseract test.png out

Can someone explain me what is happening?

For information I have  2471 megabytes of memory remaning

Thanks in advance I did not built it with ubuntu.
I read in the referenced issue that we should not use it in docker image. Do you know why ? 
I need to use it in such way I will try to use it without enabled-debug option and give you the output I try using with and without --enable-debug and nothing is working.

Still the same issue:
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc

My issue is not a build failure.

Build is going well. The issue is when I launch tesseract

**EDIT:** I made a try outside of a docker image by simply running the command manually and I have the same error with or without the --enable-debug
 Concerning the multiple version I have only one installed.
I won't be able to see installation directory tonight because I deleted my instance aws. I will create a new one tomorrow. Can you tell me the normal installation directory so I can check tomorrow ? 
However according the "make" documentation it should be in /usr/bin Here is my configuration:
	
	root@65369dfbb4d0:/# tesseract -v
	tesseract 4.00.00alpha
	 leptonica-1.74.1
	  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8

	 Found AVX
	 Found SSE

And here is where I found tesseract packages

	root@65369dfbb4d0:/# find / -name "*tesseract*"
	/usr/local/include/tesseract
	/usr/local/bin/tesseract
	/usr/local/lib/libtesseract.so.4
	/usr/local/lib/libtesseract.so
	/usr/local/lib/pkgconfig/tesseract.pc
	/usr/local/lib/libtesseract.la
	/usr/local/lib/libtesseract.a
	/usr/local/lib/libtesseract.so.4.0.0

Still the same issue...

I am going to try with leptonica-1.74  I just did it (restarted from scratch 5 minutes ago and same error)

Here is what I found:

	root@1cd9578cac1d:/test/tesseract4# find / -name "*liblept*"
	/usr/local/lib/liblept.so.5.0.1
	/usr/local/lib/liblept.a
	/usr/local/lib/liblept.la
	/usr/local/lib/liblept.so.5
	/usr/local/lib/liblept.so
	root@1cd9578cac1d:/test/tesseract4# find / -name "*leptonica*"
	/usr/local/include/leptonica

**EDIT:** Same error with leptonica 1.74 and 1.74.1 :(

What is the minimum resources configuration to run it? Use GDB to get more info about the cause of the issue.  Asi in my previous comment I had:

	root@65369dfbb4d0:/# tesseract -v
	tesseract 4.00.00alpha
	 leptonica-1.74.1
	  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8

	 Found AVX
	 Found SSE
	 
And now

	root@1cd9578cac1d:/test/tesseract4# tesseract -v
	tesseract 4.00.00alpha
	 leptonica-1.74
	  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8

	 Found AVX
	 Found SSE

And same issue

 if gdb is --enable-debug I was running with it inside and outside a docker container and what I got:

	Info in bmfCreate: Generating pixa of bitmap fonts from string terminate called after throwing an instance of 'std::bad_alloc' 
	what(): std::bad_alloc Aborted (core dumped)

Without global debug I just get the:

	what(): std::bad_alloc Aborted (core dumped)

If not I never tried it. How to activate it? How do you run GDB?

https://github.com/tesseract-ocr/tesseract/issues/256#issuecomment-193896020 @Shreeshrii I just tested with JPG and tiff and still not working (with same issue)
http://read.pudn.com/downloads196/sourcecode/app/924338/OCR/OCR/TEST_2.JPG
https://github.com/nam-leduc/positioning/raw/master/test1.tif

@amitdo  
When I use gdb

	Starting program: /usr/local/bin/tesseract test.png out
	warning: Error disabling address space randomization: Operation not permitted
	terminate called after throwing an instance of 'std::bad_alloc'
	  what():  std::bad_alloc
	During startup program terminated with signal SIGABRT, Aborted. `curl https://github.com/tesseract-ocr/tessdata/raw/master/eng.traineddata > eng.traineddata` does not get the expected data file, but gets a HTML redirection file:

    <html><body>You are being <a href="https://raw.githubusercontent.com/tesseract-ocr/tessdata/master/eng.traineddata">redirected</a>.</body></html>

Use `curl -LO https://github.com/tesseract-ocr/tessdata/raw/master/eng.traineddata` (and similar for other languages), then Tesseract with Docker works for me. With the bad data file, I get an error message:

    # tesseract ocr_test.png out -l bad
    Info in bmfCreate: Generating pixa of bitmap fonts from string
    Error opening data file /usr/local/share/bad.traineddata
    Please make sure the TESSDATA_PREFIX environment variable is set to your "tessdata" directory.
    Failed loading language 'bad'
    Tesseract couldn't load any languages!
    Could not initialize tesseract.
 Men it works pefectly!!!

Thanks. The issue is only due to the redirection.

With correct download it is working

You can close the issue. But maybe a littple update on the docker file with example of the download would be great)

Here is the final dockerfile (base on @xlight first draft)

	FROM ubuntu
	RUN apt-get update && apt-get install -y \
		autoconf \
		automake \
		libtool \
		autoconf-archive \
		pkg-config \
		libpng12-dev \
		libjpeg8-dev \
		libtiff5-dev \
		zlib1g-dev \ 
		libicu-dev \
		libpango1.0-dev \
		libcairo2-dev \
		git \
		curl && \
		rm -rf /var/lib/apt/lists/*

	RUN curl http://www.leptonica.org/source/leptonica-1.74.1.tar.gz -o leptonica-1.74.1.tar.gz && \
		tar -zxvf leptonica-1.74.1.tar.gz && \
		cd leptonica-1.74.1 && ./configure && make && make install && \
		cd .. && rm -rf leptonica*

	RUN git clone --depth 1 https://github.com/tesseract-ocr/tesseract.git && \
		cd tesseract && \
		./autogen.sh && \
		./configure && \
		LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make && \
		make install && \
		ldconfig && \
		make training && \
		make training-install && \
		cd .. && rm -rf tesseract

	# Get basic traineddata
	RUN curl -LO https://github.com/tesseract-ocr/tessdata/raw/master/eng.traineddata && \
		mv eng.traineddata /usr/local/share/tessdata/

	RUN curl -LO https://github.com/tesseract-ocr/tessdata/raw/master/fra.traineddata && \
		mv fra.traineddata /usr/local/share/tessdata/ Shouldn't it be `curl -LO` instead of `curl -Lo` (upper case O instead of lower case o)?

I'm also still surprised that my docker test produced a different kind of error with the wrong trained data files. Sorry updated (typo issue :)) we can also use:

    git clone https://github.com/tesseract-ocr/tessdata && \
    mv  -v tessdata/* /usr/local/share/tessdata/ && \
    rm -rf tessadata

To have all the languages
 ~~Tesseract should verify that the tessdata file is a TIFF file.~~ My installer for Windows includes both files unconditionally. I think they should be in the docker container, too. >@amitdo Is the tessdata a tiff file???

I thought that it is a TIFF file without the tiff extension. I was wrong.  After doing much search I have found Kraken which is an open-source fork of ocropus that solves a number of issues including:

- clstm compatibility
- Right-to-left/BiDi support
- Explicit input/output handling
- Word and character bounding boxes in hOCR
- Removal of runtime dependency on gcc
- Clean public API
- ets ....

Stating Kraken's most important advantage, its workflow allows one to train new models relatively easily.

[In this research, they have managed to get 97% to 99% recognition rate of Arabic language, this rate excludes spacing and punctuation errors (2-5%).](https://drive.google.com/file/d/0BzDVkBcqiyEsbC16ZGktOWNiUDg/view)

What is really bothering me is that Kraken is a fork of ocropus that is using clstm, while Tesseract 4.x is the more complex and most sophisticated software that have improved ocropus techniques from scratch, but still can't achieve such practical results of Kraken.

Karken is the key to recognizing Arabic, Hebrew, Urdu, Persian/Farsi, etc....

@theraysmith @Shreeshrii @amitdo @zdenop 
I hope that we will be able to solve the Arabic Language in Tesseract 4.x similarly to Kraken.
Please have a look at the Kraken project, and their method as guidance:
https://github.com/mittagessen/kraken
http://kraken.re
https://drive.google.com/file/d/0BzDVkBcqiyEsbC16ZGktOWNiUDg/view After testing kraken v0.9.1 using provided Arabic models, I believe that 97% is in theory even with the same font that used in the training or at least not for the real situations.

same basic tests are attached
[Kraken_test_results.tar.gz](https://github.com/tesseract-ocr/tesseract/files/982008/Kraken_test_results.tar.gz)
 @bmwmy have you tested training yourself?
Kraken developer told me that those models that you presented, he made, and are not that sophisticated, maybe just for testing.
Please try to train clstm, then reply back @bmwmy have you trained using [train.sh](https://raw.githubusercontent.com/mittagessen/kraken-vagrant/master/training/train.sh) No, actually I used the downloadable models which is on the repository.
Will try to train and will give feedback. @bmwmy have you seen [this update by Ray](https://github.com/tesseract-ocr/langdata/commit/3ab6581a11eea90d4dc2ba46a811447ef231b644#diff-b8c77a8bc89ffb301d80233f2874c9d3),did he add the Arabic diacritics "Harakat"?
is that a good thing or a bad thing for ocr, what do you think?
Will adding Arabic diacritics (harakat) in lstm training degrade the recognition rate, or it will it remain the same?
Can you test training text with arabic diacritics, and without diacritics and post the comparison? 
[kraken75000_vs_Tesseract.pdf](https://github.com/tesseract-ocr/tesseract/files/1176821/kraken75000_vs_Tesseract.pdf)
Hi I used @christophered trained Arabic kraken model for about 75000 lines and did comparison with latest ara.traineddata with lstm. I used standard Arabic font e.g. (Times New Roman)
The result is that tesseract make it 100% except the bug of flipping combined letters but letters are correct (https://github.com/tesseract-ocr/tesseract/issues/758).
kraken mix up some letters with similar letters achieves ~97%.

for Arabic diacritics I think OCR engine should be aware of that but neglect it in the output or during ocr process.
  This is a test with caching. The [Appveyor cache](https://www.appveyor.com/docs/build-cache/) does not seem to work currently. According to the [documentation](https://www.appveyor.com/blog/2016/09/28/the-new-build-cache/), it is only enabled for new user accounts by default. @zdenop, you have to apply to get it enabled for your account. Wow! 3.05 now works and still needs 30 minutes. So we need the cache there, too. By the way: I think 0 warnings is not normal. Are they suppressed by compiler options? Then I suggest to raise to the next warning level. `text2image` is obviously not built, maybe because `pkg-config` is missing. See code [here](https://github.com/tesseract-ocr/tesseract/blob/master/training/CMakeLists.txt#L231).  It should work without that change. If no branches are specified in `.travis.yml`, all branches are covered by Travis CI according to the [documentation](https://docs.travis-ci.com/user/customizing-the-build#Building-Specific-Branches). I use that setting in [my own fork](https://travis-ci.org/stweil/tesseract/branches).  When I run tesseract command line program (Windows prebuilt binary, 4.0.0 alpha) on this image in LSTM mode, I get:
LoOrenm 1pPpSsSUlI

Why letters repeat? Stuttering?
In Tesseract mode (oem=0), I get correct text: Lorem ipsum

![sample](https://cloud.githubusercontent.com/assets/28452355/25756005/fa2e3c2a-3179-11e7-8bdb-a70ddababc46.png) This might be one more example where the old 3.x recognizer produces better results than 4.x with LSTM. See [here](https://github.com/tesseract-ocr/tesseract/issues/707#issuecomment-280096372) for the related discussion. I dug into this and found that letter bboxes are narrower than they should be.
Debugged hand-built Tess4 on another platform so output is a bit different from above but PageIterator::BoundingBox returns bbox narrower than actual as shown below. Seems like the same glyph image is recognized a couple of times while horizontal scan striding shorter than it should:

letter L BoundingBox=(2, 48, 375, 230)
letter o BoundingBox=(484, 76, 521, 236)
letter O BoundingBox=(521, 76, 559, 236)
letter r BoundingBox=(559, 76, 1043, 236)
letter e BoundingBox=(1119, 76, 1438, 236)
letter I BoundingBox=(1527, 76, 1564, 230)
letter n BoundingBox=(1564, 76, 1611, 230)
letter m BoundingBox=(1611, 76, 1658, 230)
letter n BoundingBox=(1658, 76, 1890, 230)
letter 1 BoundingBox=(2182, 1, 2436, 230)
letter p BoundingBox=(2607, 76, 2645, 295)
letter P BoundingBox=(2645, 76, 2682, 295)
letter p BoundingBox=(2682, 76, 2784, 295)
letter S BoundingBox=(2784, 76, 2826, 295)
letter s BoundingBox=(2999, 76, 3036, 237)
letter S BoundingBox=(3036, 76, 3129, 237)
letter U BoundingBox=(3186, 74, 3390, 236)
letter l BoundingBox=(3390, 74, 3548, 236)
letter I BoundingBox=(3548, 74, 3582, 236)
letter M BoundingBox=(3790, 76, 4172, 230) I also noticed double characters in the output, but they disappear (although not completely) as soon as the model gets better (~ < 0.1%).  I drew bounding box around each recognized letter in this image. While some are spot on but many off even though text is correctly recognized as "Simple Test". Note boxes are intentionally drew off at top and bottom to minimize a chance of box overlaps.
![simpletest_bbox](https://cloud.githubusercontent.com/assets/28452355/26178227/feb02154-3b11-11e7-96fd-a98307e26ad9.png)
  Hey friends! 
First thanks for mantaining this open source project. 

However I must tell you that when I Installed this and clicked on Add to Path and Set TESSDATA_PREFIX variable almost everything I had on the path stopped working.
very similar to what happened to this guy here: 
https://stackoverflow.com/questions/43014724/how-to-reset-system-variable-path-after-tesseract-installation

I've tried the solution proposed, but unluckily windows didn't make the shadow copies of my old PATH.

So now I'm here trying to piece toghether again my path...
 That's why there is a [hint](https://github.com/UB-Mannheim/tesseract/wiki) which suggests not to use that option. The default settings are fine. Hi Stweil, thanks for answering so fast! 
I completely missed that... guess it's my fault.

But just for a heads up I installed the 3.05.00dev version which I understand is the latest one that is stable. 
and the problem of the path happened anyways, so it's not on older versions of the installer (I understand that since 4 is experimental, version 3 isn't "old", correct me if I am)

 anyways thanks again for answering, you can close this!

If anyone gets to this thread in the future and had this happened to them, then I'll leave you the default system path that comes with WINDOWS 10, so you can restore it: 

`%SystemRoot%\system32;%SystemRoot%;%SystemRoot%\System32\Wbem;%SYSTEMROOT%\System32\WindowsPowerShell\v1.0\
` > Please update the windows binaries on your site with the latest version.

Done now for both Tesseract 3.05 and Tesseract 4.  How can I reproduce this crash? `updates_` looks strange. No wonder that the code crashes when it tries to add a 0 x 0 matrix. Ray said that he needs to fix training after his last commits. When I run all but the last step with older executables, I get an error from `lstmtraining`:

    Deserialize failed: tess4training/eng/eng.Arial.exp0.lstmf read 0/72 pages

That might confirm that the last commits introduced some incompatibility. I could confirm that commit 8e79297dcefecdb929d753d28554fec51417ec39 introduced a regression. Before that commit, lstmtraining did run the iterations. https://github.com/tesseract-ocr/tesseract/commit/83588bc7a18e50fb435b5ca8a45fd7e00ab2ccdf#commitcomment-22019959

>Now back to finding out why training isn't working properly... [Here](https://github.com/tesseract-ocr/tesseract/commit/8e79297dcefecdb929d753d28554fec51417ec39#diff-1e1ab755e307f14ddffbad6f38cdf54aR169) `language_` is added to the serialized data, so old and new data are incompatible (this is the reason why I get the above error message). The new data is correctly handled in [ImageData::DeSerialize](https://github.com/tesseract-ocr/tesseract/commit/8e79297dcefecdb929d753d28554fec51417ec39#diff-1e1ab755e307f14ddffbad6f38cdf54aR186) and in [ImageData::SkipDeSerialize](https://github.com/tesseract-ocr/tesseract/commit/8e79297dcefecdb929d753d28554fec51417ec39#diff-1e1ab755e307f14ddffbad6f38cdf54aR198).

Does the training process use old files which contain old incompatible `ImageData`?  Are you sure that `--tessdata_dir ./tessdata` is correct? Shouldn't it point to the parent directory of `tessdata`? https://github.com/tesseract-ocr/tesseract/issues/881#issuecomment-299391463 I could now reproduce the assertion and the crash. @Shreeshrii, please try reverting [line 491 in `lstm/lstmtrainer.cpp`](https://github.com/tesseract-ocr/tesseract/commit/8e79297dcefecdb929d753d28554fec51417ec39#diff-2321d66b4e371b97cfc510763d8f1283R491) (s/TS_ENABLED/TS_RE_ENABLE/). That fixes the assertion for me.  Hello all,

I  lstmtraining chi_sim, but have the error "Must supply a list of training filenames! --train_listfile".
The context is "./cntrain/chi_sim.SimSun.exp0.lstmf" in my chi_sim.training_files.txt. Please give me a help!

lstmtraining -U ./cntrain/chi_sim.unicharset \
--script_dir ./langdata \
--debug_interval 100 \
--continue_from ./cnoutput/chi_sim.lstm \
--append_index 5 ‚Äìnet_spec '[1,0,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx384 O1c1]' \
--learning_rate 10e-5 \
--net_mode 192 \
--perfect_sample_delay 19 \
--max_iterations 10000 \
--model_output ./cnoutput/base  --max_image_MB 600 \
--train_listfile ./cntrain/chi_sim.training_files.txt  \
--eval_listfile ./cntrain/chi_sim.training_files.txt &>./cnoutput/basetrain.log

 Thank you for your help. I solved it by removing "--append_index 5"   Ray, this commit has a high probability to conflict with your work, so please select single commits as you like or just tell me which changes can be applied next or when is the best time for such changes.

It would be good to finish the transformation to POSIX data types and macros in the not too far future.  Rebased PR to trigger a new AppVeyor build ([previous build](https://ci.appveyor.com/project/zdenop/tesseract/build/master.813) failed, reason unknown).  Could we just remove the i/o redirection in `cmake --build . --config Release > bin\Release\log.txt`? Writing compiler error messages to a file which cannot be read looks strange. Appveyor also supports caching. That could reduce build time significantly. Build now works. The previous errors were caused by ambiguous calls of `ClipToRange`.

Appveyor needed about 30 minutes total time with i/o redirection removed. Fixed merge conflicts and rebased PR. Fixed merge conflicts and rebased PR. Fixed merge conflicts and rebased PR. @theraysmith, as you are just preparing a new larger code change: is it possible to use POSIX data types for the new / modified code, and can we switch to POSIX for the rest of the code directly after your update? Rebased PR and fixed merge conflicts. Not this one.

>.. after the legacy engine is removed...

The legacy engine is still alive.
‚Ä¶ @stweil estimated elsewhere that a merge of this PR will happen sometime in the next 5 years.

Optimistic guy... üòÜ   I'm sure that some parts of the PR are not related to the legacy engine. Maybe those can be applied now. Replacing the types and macros can be done automatically, so doing it yourself in your code could save the review. It took me more time to fix indentation of in-line comments, but I think you can do that using tools, too. Fixed 7 files with merge conflicts. Fixed merge conflict in `training/normstrngs.cpp`.  Hi,I want to build the Tesseract using the master branch.
I followed the steps as you mentioned.
But when I enter **cmake ..** I am getting the following error.
Help me on this.
Thank you


C:\Users\Varun\Desktop\New folder\tesseract-master\Win64>cmake ..
-- The C compiler identification is unknown
-- The CXX compiler identification is unknown
CMake Error at CMakeLists.txt:47 (project):
  No CMAKE_C_COMPILER could be found.



CMake Error at CMakeLists.txt:47 (project):
  No CMAKE_CXX_COMPILER could be found.



-- Configuring incomplete, errors occurred!
See also "C:/Users/Varun/Desktop/New folder/tesseract-master/Win64/CMakeFiles/CMakeOutput.log".
See also "C:/Users/Varun/Desktop/New folder/tesseract-master/Win64/CMakeFiles/CMakeError.log".  Hi,
I'm using tesseract 4.00alpha with leptonica 1.74.1 on Ubuntu 14.04, first i was training on the a VirtualBox and i was able to create LSTMF files, but now i use the same tesseract, lepptonica and Ubutnu versions on a different machine (VMware) and i couldn't create LMSTF files, and i compiled the tesseract in both cases the same, according to this [website](https://medium.com/@lucas63/installing-tesseract-3-04-in-ubuntu-14-04-1dae8b748a32) ,I'm pasting part of log file that is created at tmp file......
=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=./tessdata
[Thu May 4 00:52:11 PDT 2017] /usr/local/bin/tesseract /tmp/tmp.vDN2ALtI8c/ara/ara.Arabic_Typesetting.exp0.tif /tmp/tmp.vDN2ALtI8c/ara/ara.Arabic_Typesetting.exp0 lstm.train ../langdata/ara/ara.config
Info in bmfCreate: Generating pixa of bitmap fonts from string
lstm_recognizer_->DeSerialize(tessdata_manager.swap(), &fp):Error:Assert failed:in file tessedit.cpp, line 202
ERROR: /tmp/tmp.vDN2ALtI8c/ara/ara.Arabic_Typesetting.exp0.lstmf does not exist or is not readable

keep in mind i copied the tessedit from the working version of tesseract and replaced it at the new machine but the same error occurred

Thanks UPDATE :-
i have installed the tesseract again today and the same error was generated but the only difference that the line number has changed

=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=./tessdata
[Thu May 4 04:43:32 PDT 2017] /usr/local/bin/tesseract /tmp/tmp.RwajXhdHOo/ara/ara.Arabic_Typesetting.exp0.tif /tmp/tmp.RwajXhdHOo/ara/ara.Arabic_Typesetting.exp0 lstm.train /home/ibr/Desktop/Tesseract4/langdata/ara/ara.config
Info in bmfCreate: Generating pixa of bitmap fonts from string
lstm_recognizer_->DeSerialize(&fp):Error:Assert failed:in file tessedit.cpp, line 193
ERROR: /tmp/tmp.RwajXhdHOo/ara/ara.Arabic_Typesetting.exp0.lstmf does not exist or is not readable
 >Info in bmfCreate: Generating pixa of bitmap fonts from string

It just an info message, not an error message.

The two issues does not seem related to each other.
 as i understood from the issue 893, that guy is facing a trouble with building the tesseract with liptonica, but i built it fine and I'm even capable to detect text from images, if you can see in the log message when I'm using the tesstrain.sh i'm able yo create the data that is stored in the tmp file, my problem is in the last phase which is generating lstm files.
keep in mind that i have installed and complied the tesseract 4alpha and leptonica 1.74.1 twice, within month in between i guess, the first one works fine and I'm able to create the lstmf files, but in the second i can't amd i followed the same steps in both cases
Thanks Hi Shree,

i was thinking the same thing, its just i always follow the steps and links to install and compile from this [site](https://medium.com/@lucas63/installing-tesseract-3-04-in-ubuntu-14-04-1dae8b748a32)
so is there a way currently to solve this issue? cause i might need to install the tesseract on a server because all the work i did already on a VMware for testing purposes 
Thanks Hi,

i looked at the config.log of the tesseract revision that works, took the revision  number  and switched the tesseract to that branch while installing the tesseract, and that revision was **"4.00.00alpha-367-g5baa8c8"**
i made sure that its the correct revision by making detection of an image, i noticed that on the terminal the tesseract prints its revision number
![ocrerror](https://cloud.githubusercontent.com/assets/26926171/25889397/49639c4e-3572-11e7-909e-5c7fcf8eab3c.png)
yet the same error was generated at the phase E where creating lstm files
i even tried to install the suggested revision: **"4.00.00alpha-458-g2ea946d"** and the result was the same error but different line number at the tessedit.cpp, at the revision  **"4.00.00alpha-367-g5baa8c8"** the error is: **stm_recognizer_->DeSerialize(&fp):Error:Assert failed:in file tessedit.cpp, line 202**
and at the revision **"4.00.00alpha-458-g2ea946d"** the error was
**stm_recognizer_->DeSerialize(&fp):Error:Assert failed:in file tessedit.cpp, line 193**
i even deleted that line from the tessedit.cpp and the error stayed the same, after that i tried to delete the whole tessedit.cpp and same problem, so is it loaded on somewhere ? or is it not compatible with VMware because the revision **"4.00.00alpha-367-g5baa8c8"** works fine with the virtual box but not with the VMware 
Thanks @Shreeshrii 
no worries :) i mentioned the virtual box and the VMware just in case, i just like to share the details in case they were any help, i dont know either if its virtual box or VMware, the interesting point that in both cases or in both revisions the same line of code failed 
thanks for the response @Shreeshrii are the libraries and leptonica version at this [site](https://medium.com/@lucas63/installing-tesseract-3-04-in-ubuntu-14-04-1dae8b748a32) are valid? meaning did you install them with the tesseract v4.00.00alpha-460-gb86b4fa ? Finally I'm able to create LSTM files, without switching to any other branches, the version of the tesseract is in the image below
![lstm](https://user-images.githubusercontent.com/26926171/27028983-3370d0e8-4f6f-11e7-9377-60158f0c11a8.png)
  We are an enterprise utilizing tesseract for years, and we recently upgraded to 3.04.1 successfully by compiling from source code. When running the command below, segmentation fault is received from Ubuntu 10.04.4 (code 139). 

Does anyone have ideas as why this might occur? Thanks heaps. 
tesseract -psm 1 -l eng /var/opt/app/main.jpg /var/opt/app/main_1 characters hocr 
   Up to now, Insight.io only shows the files with syntax highlighting. I got an error message that code analysis failed for my projects. I have sent a [pull request](https://github.com/tesseract-ocr/tesseract-ocr.github.io/pull/1) which updates the documentation.

It is possible to automatically update that documentation, but that would add a new revision for each change of the master branch. Travis needs write access to the [tesseract-ocr/tesseract-ocr.github.io repository](https://github.com/tesseract-ocr/tesseract-ocr.github.io). That part is a little bit tricky (see links above collected by @Shreeshrii).

Maybe it is sufficient to update the documentation each time a release is tagged.

New documentation is also visible [here](https://ub-mannheim.github.io/tesseract/). It's based on the latest git master branch. @stweil Hi, insight.io creator here, tesseract-ocr should work fine on insight.io with full code intelligence not just syntax highlighting. Would you mind shooting an email to chongzhe@insight.io with regarding to the errors you see, we will help you solve the issue:)

Thanks!  I was able to install head with brew before, but now I get this error. :(
Could someone help?
Thanks!
$ brew install tesseract --HEAD
==> Auto-updated Homebrew!
Updated 1 tap (homebrew/core).
No changes to formulae.

==> Using the sandbox
==> Cloning https://github.com/tesseract-ocr/tesseract.git
Cloning into '/Users/user/Library/Caches/Homebrew/tesseract--git'...
remote: Counting objects: 724, done.
remote: Compressing objects: 100% (694/694), done.
remote: Total 724 (delta 88), reused 163 (delta 12), pack-reused 0
Receiving objects: 100% (724/724), 3.74 MiB | 0 bytes/s, done.
Resolving deltas: 100% (88/88), done.
Checking connectivity... done.
==> Checking out branch master
==> Downloading https://github.com/tesseract-ocr/tesseract/commit/b18cad4.patch
######################################################################## 100.0%
==> Patching
==> Applying b18cad4.patch
patching file configure.ac
Hunk #1 FAILED at 220.
1 out of 1 hunk FAILED -- saving rejects to file configure.ac.rej
patching file api/Makefile.am
Hunk #1 FAILED at 45.
1 out of 1 hunk FAILED -- saving rejects to file api/Makefile.am.rej
Error: Failure while executing: /usr/bin/patch -g 0 -f -p1 -i /private/tmp/tesseract--patch-20170502-16295-cpuv7w/b18cad4.patch
 Thanks, do you know how to tell brew to skip the patch?
 The brew formulae is for version 3.05, while the HEAD is 4.00 (alpha). Thanks, wouldn't adding --head option like "brew install tesseract 
--HEAD" download the latest head from the Github?
I'm wondering how to tell brew to skip the patch...
 Dunno. I don't have a a Mac... @zdenop, maybe a new release 3.05.01 would help making such patches unnecessary. same here
 @jsl303,

As you might already know, Homebrew's Formula can edit locally.

```
$ brew edit tesseract
```

If you want to skip the patch, comment out line 71-74, and save it.

( /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core/Formula/tesseract.rb )

```
$ brew install tesseract --HEAD
```

or, wrapping patch block with 'if-end' block such like below.

```
--- a/Formula/tesseract.rb
+++ b/Formula/tesseract.rb
@@ -68,10 +68,12 @@ class Tesseract < Formula
   # remove on next release, > 3.05.00
   # upstream fix for building with OpenCL enabled
   # https://github.com/tesseract-ocr/tesseract/pull/814
+  if !build.head?
   patch do
     url "https://github.com/tesseract-ocr/tesseract/commit/b18cad4.patch"
     sha256 "10c59baa54c3406fcd03f36cd0f1e3cc2ba150f082d14f919274a541b3cff7b2"
   end
+  end

   def install
     if build.head?
```

 My PR got merged. So, no need to edit Formula.

@jsl303, It should work with the following command.

```
$ brew update
$ brew install tesseract --HEAD
``` This issue can be closed. `brew install tesseract --HEAD` now works. > Please see the recent post ...

I need more information because I currently cannot reproduce the build problem (building training tools works for me with MacPorts and with Homebrew).  Hi,

I'm using tesseract 4.00alpha with liptonica 1.74.1 on Ubuntu 14 to create LSTM files for multiple Arabic fonts, which some of them have the common numerical system, (1 2 3 4 ...) but some of these font contains the a different numerical system, which usually more common in the Arabic scripts, 
which are ( Ÿ† Ÿ° Ÿ¢ Ÿ£ Ÿ§ Ÿ• Ÿ¶ Ÿß Ÿ® Ÿ©)
yet the last set of numbers were not recognize but as symbols such as ! instead of Ÿ° ,are these numbers are not integrated in the tesseract?
Thanks  If that numerals are indeed missing from the official traineddata, I suggest to open a new issue in the langdata repo. Did Anyone fix this problem? I am not using Unix in order to be able to train tesseract on new data, but I need to use the Eastern arabic numerals. if someone fixed it and has the traineddata file, please share it with us

Thanks Persian's number's shape mostly the same as Arabic's but their Unicode is different!
Persian numbers= €π €∏ €∑ €∂ €µ €¥ €≥ €≤ €± €∞
Arabic numbers = Ÿ† Ÿ° Ÿ¢ Ÿ£ Ÿ§ Ÿ• Ÿ¶ Ÿß Ÿ® Ÿ©
Persian numbers' Unicode= \u06F9 \u06F8 \u06F7 \u06F6 \u06F5 \u06F4 \u06F3 \u06F2 \u06F1 \u06F0
Arabic numbers' Unicode =\u0660 \u0661 \u0662 \u0663 \u0664 \u0665 \u0666 \u0667 \u0668 \u0669
you can check them [here](https://r12a.github.io/apps/conversion/) Yes, it mixed Persian with Arabic numbers (unicode) for example the image had these numbers
€±-€≤ and it recognize €± as Persian number and €≤ as Arabic number their shape is the same but for searching and Unicode, they are different.
in another hand 3 and 4 and 5 and 6's shape are not the same see below
6 5 4 3 
€∂ €µ €¥ €≥ >Persian
Ÿ£ Ÿ§ Ÿ• Ÿ¶  > Arabic
you can check it at [here](https://github.com/tesseract-ocr/tessdata/issues/70#issuecomment-320441157) with the output txt file
 for more information see [Unicode Number, Decimal Digit' Category](http://www.fileformat.info/info/unicode/category/Nd/list.htm) usually, people use the un-standard keyboard (Arabic keyboard for typing Persian text) so there are many scan images of Persian's text  which have Arabic numbers like Ÿ£ Ÿ§ Ÿ• Ÿ¶  but the OCR should convert them to Persian Unicode @zdenop, please close this issue.

The issue is related to the trained **data**. not code.

As said, the right place for this issue is the langdata repo.
See https://github.com/tesseract-ocr/langdata/issues/71, https://github.com/tesseract-ocr/langdata/issues/72
  Those files can be built by doc/generate_manpages.sh.

The manpages are needed for the installation,
so add Makefile rules for them.

Git must ignore the generated manpages.

Signed-off-by: Stefan Weil <sw@weilnetz.de> This is a request for comments. The patch removes documentation files which can be easily created if `asciidoc` is available in the build environment. Man pages are now not built and installed by default. They are build and installed in maintainer mode (`./configure --enable-maintainer-mode`).

Removing the documentation files which can be built simplifies the maintenance, because it is no longer necessary to update three generated files for a simple documentation update. I just tried to install the asciidoc package on Debian with Synaptic.
Synaptic lists additional **59** required packages.

 Are you sure that those packages are _required_? On my Debian Stretch, I see 4 required packages (1.4 MB disk space): `asciidoc`, `asciidoc-base`, `asciidoc-common`, `libxml2-utils`. As long as you don't want to create LaTeX and PDF documents, you can keep the installation pretty small. It may depend on what is already installed on the system. I get the following list:

```
 sudo apt-get install asciidoc
sudo: unable to resolve host ALL-IN-1-TOUCH
[sudo] password for shree:
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following extra packages will be installed:
  dblatex docbook-dsssl docbook-utils fonts-lmodern fonts-texgyre jadetex
  latex-beamer latex-xcolor libkpathsea6 libosp5 libostyle1c2 libptexenc1
  libreadline5 libruby1.9.1 libsgmls-perl libsp1c2 lmodern luatex openjade pgf
  preview-latex-style prosper ps2eps ruby ruby1.9.1 sgmlspl sp tcl tcl8.6
  tex-common tex-gyre texlive texlive-base texlive-bibtex-extra
  texlive-binaries texlive-extra-utils texlive-font-utils
  texlive-fonts-recommended texlive-fonts-recommended-doc
  texlive-generic-recommended texlive-latex-base texlive-latex-base-doc
  texlive-latex-extra texlive-latex-extra-doc texlive-latex-recommended
  texlive-latex-recommended-doc texlive-luatex texlive-math-extra
  texlive-pictures texlive-pictures-doc texlive-pstricks texlive-pstricks-doc
  tipa tk tk8.6 xmlto xsltproc
Suggested packages:
  source-highlight vim-addon-manager docbook latex-cjk-all opensp
  texlive-lang-cyrillic texlive-xetex transfig docbook-dsssl-doc sgmls-doc
  doc-base ri ruby-dev ruby1.9.1-examples ri1.9.1 graphviz ruby1.9.1-dev
  tcl-tclreadline perl-tk chktex fragmaster xindy latexdiff lacheck latexmk
  dvidvi purifyeps dvipng t1utils psutils libfile-which-perl python-pygments
  dot2tex libtcltk-ruby xmltex
Recommended packages:
  wish
The following NEW packages will be installed:
  asciidoc dblatex docbook-dsssl docbook-utils fonts-lmodern fonts-texgyre
  jadetex latex-beamer latex-xcolor libkpathsea6 libosp5 libostyle1c2
  libptexenc1 libreadline5 libruby1.9.1 libsgmls-perl libsp1c2 lmodern luatex
  openjade pgf preview-latex-style prosper ps2eps ruby ruby1.9.1 sgmlspl sp
  tcl tcl8.6 tex-common tex-gyre texlive texlive-base texlive-bibtex-extra
  texlive-binaries texlive-extra-utils texlive-font-utils
  texlive-fonts-recommended texlive-fonts-recommended-doc
  texlive-generic-recommended texlive-latex-base texlive-latex-base-doc
  texlive-latex-extra texlive-latex-extra-doc texlive-latex-recommended
  texlive-latex-recommended-doc texlive-luatex texlive-math-extra
  texlive-pictures texlive-pictures-doc texlive-pstricks texlive-pstricks-doc
  tipa tk tk8.6 xmlto xsltproc
0 upgraded, 58 newly installed, 0 to remove and 171 not upgraded.
Need to get 727 MB of archives.
After this operation, 1,145 MB of additional disk space will be used.
Do you want to continue? [Y/n] n
Abort.
``` Try `apt-get install --no-install-recommends asciidoc`. This will reduce the list a lot, because all TeX related packages are only recommended (needed for PDF generation, but not for simple man pages).

I get 4 packages with `--no-install-recommends`, but 72 packages without that option. Thanks. That does the trick.

```
sudo apt-get install --no-install-recommends asciidoc
sudo: unable to resolve host ALL-IN-1-TOUCH
[sudo] password for shree:
Reading package lists... Done
Building dependency tree
Reading state information... Done
Suggested packages:
  source-highlight vim-addon-manager
Recommended packages:
  dblatex docbook-utils xmlto
The following NEW packages will be installed:
  asciidoc
0 upgraded, 1 newly installed, 0 to remove and 171 not upgraded.
Need to get 688 kB of archives.
After this operation, 2,370 kB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu/ trusty/main asciidoc all 8.6.9-2ubuntu1 [688 kB]
Fetched 688 kB in 2s (239 kB/s)
Selecting previously unselected package asciidoc.
(Reading database ... 103366 files and directories currently installed.)
Preparing to unpack .../asciidoc_8.6.9-2ubuntu1_all.deb ...
Unpacking asciidoc (8.6.9-2ubuntu1) ...
Processing triggers for man-db (2.6.7.1-1ubuntu1) ...
Setting up asciidoc (8.6.9-2ubuntu1) ...

``` ```
$ apt-cache depends asciidoc
asciidoc
  Depends: python
  Depends: <python:any>
    python
  Suggests: source-highlight
  Suggests: vim-addon-manager
  Recommends: dblatex
  Recommends: docbook-utils
  Recommends: libxml2-utils
  Recommends: xmlto
```

```
$ apt-get install --dry-run --no-install-recommends asciidoc
NOTE: This is only a simulation!
      apt-get needs root privileges for real execution.
      Keep also in mind that locking is deactivated,
      so don't depend on the relevance to the real current situation!
Reading package lists... Done
Building dependency tree       
Reading state information... Done
Suggested packages:
  source-highlight vim-addon-manager
Recommended packages:
  dblatex docbook-utils libxml2-utils xmlto
The following NEW packages will be installed:
  asciidoc
0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.
Inst asciidoc (8.6.9-3 Debian:8.7/stable [all])
Conf asciidoc (8.6.9-3 Debian:8.7/stable [all])
```
 https://www.macports.org/ports.php?by=name&substr=asciidoc
http://brewformulas.org/Asciidoc By the way, builds which use `cmake` don't install any man pages, only `autoconf` based builds do. Cmake is used by people that use MSVC and by the CI. If this PR is accepted, we will need to add this to the `Compiling` wiki page:
`apt-get install --no-install-recommends asciidoc`, but we only have instructions for Debian-based distros. If other package managers in non-Debian-based distros have a similar behavior like
`apt-get install asciidoc` (install also recommended packages) users will get a lot of unnecessary packages.

@stweil, what do think about this issue?  Yes, we have to add documentation for package maintainers who want to install the man pages with the Tesseract package.

I expect that a person who wants to build a distro package won't have problems with installing too many packages with `asciidoc`. My main machine, for example, already had TeX installed, so the installation of `asciidoc` did not add many more packages.

Normal users who want to build Tesseract would not automatically build man pages, so they don't need `asciidoc`. The main question is whether that is acceptable.

Instead of building man pages in maintainer mode only, it would also be possible to build them only if `asciidoc` was found. Would that be better? OK. No objection to this PR.

BTW, Git does the same thing:
https://github.com/git/git/tree/master/Documentation
 https://github.com/git/git/blob/v2.13.0-rc1/INSTALL#L160
Stefan, I suggest to do something similar in Tesseract.
(Of course, don't copy even a single line from that GPL codebase) Thank you for the report. This is fixed in PR #862. Don't forget to run `./autogen.sh` after that patch.  From time to time Ray cleans the code by using `clang-tidy`. It would be nice to document that process to allow other developers to check their code contributions and avoid style problems from the beginning.

The current tidy process does not cover some significant code style issues. Most noticeable: it does not change from `( xxx )` (about 480 lines of code) to `(xxx)` (which is the preferred [Google style](https://google.github.io/styleguide/cppguide.html#Function_Declarations_and_Definitions), more than 50000 lines of code).  L_Bmf works for C++ code, but the common form is L_BMF, so use that.

Signed-off-by: Stefan Weil <sw@weilnetz.de> @theraysmith, maybe you a referring to the [Leptonica style guide](https://github.com/DanBloomberg/leptonica/blob/master/style-guide.txt#L48). I think it's a style guide for the Leptonica code, not for code using Leptonica (like Tesseract). https://github.com/DanBloomberg/leptonica/blob/master/style-guide.txt

>(c) Use typedefs for structs like Pix; e.g.,
          function(PIX  *pixs)
       Do not do this (omitting the 'struct' keyword); it is valid C++,
       but not C:
          function(Pix  *pixs)

https://github.com/DanBloomberg/leptonica/blob/150c8d0051/src/bmf.h#L45

Since Tesseract code is based on C++, we should use a C++ style guide.
https://google.github.io/styleguide/cppguide.html#Type_Names
  I must admit that I'm confused now. If Dan prefers `Pix`, I'd change the Leptonica to allow `Pix` for C as well (and maintain `PIX` for backward compatibility, maybe with a deprecation attribute).

Ray, the code in `opencl/` needs much formatting. Could you do this with your internal tool (or make it public, then I could assist)? Ray,
According to some of your commit messages you use clang-tidy.

What about adding a `.clang-format` file to the public repo?
https://clang.llvm.org/docs/ClangFormatStyleOptions.html

 Ray reverted this pull request with commit 7a116ce8bbfe6c1772b0b5055c7574a27c35eaac. My new pull request #855 fixes the remaining exceptions which currently don't use the preferred struct name.

Ray, thank you for formatting `opencl/`. I noticed that some issues like _[There is never a space between the parentheses and the parameters](https://google.github.io/styleguide/cppguide.html#Function_Declarations_and_Definitions)_ were not fixed (see also issue #854).  Hello All,

I want to train tesseract , But I got this error, Any help
~/tesseract$ training/tesstrain.sh 
--fonts_dir /usr/share/fonts/winFonts 
--fontlist SimSun 
--lang chi_sim  
--linedata_only 
--noextract_font_properties 
--langdata_dir ./langdata 
--tessdata_dir /usr/share/tesseract-ocr/tessdata 
--output_dir ./tesstutorial/chisimtrain

=== Starting training for language 'chi_sim'
[2017Âπ¥ 04Êúà 26Êó• ÊòüÊúü‰∏â 16:26:34 CST] /usr/local/bin/text2image --fonts_dir=/usr/share/fonts/winFonts --font=SimSun --outputbase=/tmp/font_tmp.ErZuLmIxms/sample_text.txt --text=/tmp/font_tmp.ErZuLmIxms/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.ErZuLmIxms
Rendered page 0 to file /tmp/font_tmp.ErZuLmIxms/sample_text.txt.tif

=== Phase I: Generating training images ===
Rendering using SimSun
[2017Âπ¥ 04Êúà 26Êó• ÊòüÊúü‰∏â 16:26:34 CST] /usr/local/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.ErZuLmIxms --fonts_dir=/usr/share/fonts/winFonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.SimSun.exp0 --font=SimSun --text=/home/alisa/tesseract/langdata/chi_sim/chi_sim.training_text
Rendered page 0 to file /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.SimSun.exp0.tif

=== Phase UP: Generating unicharset and unichar properties files ===
[2017Âπ¥ 04Êúà 26Êó• ÊòüÊúü‰∏â 16:26:35 CST] /usr/local/bin/unicharset_extractor -D /tmp/tmp.sqbPsVBeRu/chi_sim/ /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.SimSun.exp0.box
Extracting unicharset from /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.SimSun.exp0.box
Wrote unicharset file /tmp/tmp.sqbPsVBeRu/chi_sim//unicharset.
[2017Âπ¥ 04Êúà 26Êó• ÊòüÊúü‰∏â 16:26:35 CST] /usr/local/bin/set_unicharset_properties -U /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.unicharset -O /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.unicharset -X /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.xheights --script_dir=/home/alisa/tesseract/langdata
Loaded unicharset of size 322 from file /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.unicharset
=== Phase D: Generating Dawg files ===
ERROR: /home/alisa/tesseract/langdata/common.punc does not exist or is not readable Did you clone the https://github.com/tesseract-ocr/langdata repository? `--langdata_dir ./langdata` looks wrong to me, `langdata` is not part of the normal tesseract repository. oh, no. I have used the langdata cloned from  "https://github.com/tesseract-ocr/langdata" to do this again, but have the following error:
training/tesstrain.sh --fonts_dir /usr/share/fonts/winFonts 
--fontlist "SimSun" 
--lang chi_sim  
--linedata_only 
--noextract_font_properties 
--langdata_dir ../langdata 
--tessdata_dir /usr/share/tesseract-ocr/tessdata 
--training_text 
../train_text/0.txt 
--output_dir ./tesstutorial/cntrain
=== Starting training for language 'chi_sim'
[2017Âπ¥ 04Êúà 27Êó• ÊòüÊúüÂõõ 09:51:36 CST] /usr/local/bin/text2image --fonts_dir=/usr/share/fonts/winFonts --font=SimSun --outputbase=/tmp/font_tmp.L6T5hz2YhQ/sample_text.txt --text=/tmp/font_tmp.L6T5hz2YhQ/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.L6T5hz2YhQ
Rendered page 0 to file /tmp/font_tmp.L6T5hz2YhQ/sample_text.txt.tif

=== Phase I: Generating training images ===
Rendering using SimSun
[2017Âπ¥ 04Êúà 27Êó• ÊòüÊúüÂõõ 09:51:37 CST] /usr/local/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.L6T5hz2YhQ --fonts_dir=/usr/share/fonts/winFonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.SimSun.exp0 --font=SimSun --text=../train_text/0.txt
Rendered page 0 to file /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.SimSun.exp0.tif

=== Phase UP: Generating unicharset and unichar properties files ===
[2017Âπ¥ 04Êúà 27Êó• ÊòüÊúüÂõõ 09:51:38 CST] /usr/local/bin/unicharset_extractor -D /tmp/tmp.wiRXVpIiJ9/chi_sim/ /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.SimSun.exp0.box
Extracting unicharset from /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.SimSun.exp0.box
Wrote unicharset file /tmp/tmp.wiRXVpIiJ9/chi_sim//unicharset.
[2017Âπ¥ 04Êúà 27Êó• ÊòüÊúüÂõõ 09:51:38 CST] /usr/local/bin/set_unicharset_properties -U /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset -O /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset -X /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.xheights --script_dir=../langdata
Loaded unicharset of size 322 from file /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset
Setting unichar properties
Other case X of x is not in unicharset
Other case M of m is not in unicharset
Other case h of H is not in unicharset
Other case G of g is not in unicharset
Other case e of E is not in unicharset
Other case f of F is not in unicharset
Other case c of C is not in unicharset
Other case u of U is not in unicharset
Other case O of o is not in unicharset
Other case Œú of Œº is not in unicharset
Warning: properties incomplete for index 14 = Ôºö
Warning: properties incomplete for index 35 = Ôºå
Warning: properties incomplete for index 125 = Ôºù
Warning: properties incomplete for index 126 = ÔºÖ
Warning: properties incomplete for index 136 = Ôºà
Warning: properties incomplete for index 139 = Ôºâ
Warning: properties incomplete for index 223 = Ôºõ
Writing unicharset to file /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset

=== Phase D: Generating Dawg files ===
Generating word Dawg
[2017Âπ¥ 04Êúà 27Êó• ÊòüÊúüÂõõ 09:51:38 CST] /usr/local/bin/wordlist2dawg -r 1 ../langdata/chi_sim/chi_sim.wordlist /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.word-dawg /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset'
Reading word list from '../langdata/chi_sim/chi_sim.wordlist'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.word-dawg'
Generating frequent-word Dawg
[2017Âπ¥ 04Êúà 27Êó• ÊòüÊúüÂõõ 09:51:38 CST] /usr/local/bin/wordlist2dawg -r 1 /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.wordlist.clean.freq /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.freq-dawg /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset'
Reading word list from '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.wordlist.clean.freq'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.freq-dawg'
[2017Âπ¥ 04Êúà 27Êó• ÊòüÊúüÂõõ 09:51:38 CST] /usr/local/bin/wordlist2dawg -r 0 ../langdata/chi_sim/chi_sim.punc /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.punc-dawg /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset
Set reverse_policy to RRP_DO_NO_REVERSE
Loading unicharset from '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset'
Reading word list from '../langdata/chi_sim/chi_sim.punc'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.punc-dawg'
[2017Âπ¥ 04Êúà 27Êó• ÊòüÊúüÂõõ 09:51:38 CST] /usr/local/bin/wordlist2dawg -r 0 ../langdata/chi_sim/chi_sim.numbers /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.number-dawg /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset
Set reverse_policy to RRP_DO_NO_REVERSE
Loading unicharset from '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset'
Reading word list from '../langdata/chi_sim/chi_sim.numbers'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.number-dawg'

=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=/usr/share/tesseract-ocr/tessdata
[2017Âπ¥ 04Êúà 27Êó• ÊòüÊúüÂõõ 09:51:38 CST] /usr/local/bin/tesseract /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.SimSun.exp0.tif /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.SimSun.exp0 lstm.train ../langdata/chi_sim/chi_sim.config
Info in bmfCreate: Generating pixa of bitmap fonts from string
read_params_file: Can't open lstm.train
Info in bmfCreate: Generating pixa of bitmap fonts from string
Error opening data file /usr/share/tesseract-ocr/tessdata/chi_sim_vert.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your "tessdata" directory.
Failed loading language 'chi_sim_vert'
Tesseract Open Source OCR Engine v7bb00d9 with Leptonica
Page 1
ERROR: /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.SimSun.exp0.lstmf does not exist or is not readable
 >Failed loading language 'chi_sim_vert'

modify chi_sim.config file in langdata/chi_sim
and comment out first line related to loading of the vertical sub language  The documentation does not seem to specify the format of the text files required by the `train_listfile` option. Are there examples available of `eng.training_files.txt`?

 [eng.training_files.txt](https://github.com/tesseract-ocr/tesseract/files/957062/eng.training_files.txt)

Sample attached. File is created by the tesstrain.sh process. If on 'unix' you can try the following to create the file - 

`ls -1 *.lstmf > lang.training_files.txt`

You may need to give the path before *.lstmf or the next step will not find the files.
 The [line break](https://en.wikipedia.org/wiki/Newline) must be `\n`. This is what is inserted automatically when you hit the `Enter` key in the keyboard in Linux/macOS. In Windows it's by default `\r\n`, which will confuse Tesseract.

http://stackoverflow.com/questions/8195839/choose-newline-character-in-notepad Thanks @Shreeshrii, thanks @amitdo! 

This raises a new question: how do I generate `.lstfm` files? I'm trying Tesseract to train on [New York city directories](https://digitalcollections.nypl.org/items/b42866fb-b877-e4fc-e040-e00a1806275e), I have box files and TIFs. (Another question: can I already use `WordStr` box files, some parts of the documentation say I can, others say I can't?)

ZIP file with one TIF and box file I'm trying to use: [Wilson1852_0.zip](https://github.com/tesseract-ocr/tesseract/files/958420/Wilson1852_0.zip). Out of the box, Tesseract already performs pretty well, but 150 years ago, house numbers in New York sometimes included ¬Ω, so I have to include this character in the `desited_characters` file:

![image](https://cloud.githubusercontent.com/assets/1194896/25436113/477a23b6-2a60-11e7-967f-c4b97b21e3a9.png)


 WordStr box files are not yet supported (AFAIK).

If you have box files in 3.0 format, you can use jtessboxeditor to add the
end of line tab character and use them.

When I want to test using box/tiff pairs, I copy the files to the training
directory - by modifying tesstrain.sh.


mkdir -p ${TRAINING_DIR}
tlog "\n=== Starting training for language '${LANG_CODE}'"

#cp /home/shree/tesstutorial/larmbig/*.tif "${TRAINING_DIR}/"
#cp  /home/shree/tesstutorial/larmbig/*.box "${TRAINING_DIR}/"

Then use a command similar to following (based on location of your files)
and use just one font similar to the one used in your box/tiff pairs.

You may need to modify tesstrain_utils.sh to make sure that all your
box/tiff pairs are selected (based on the naming).

training/tesstrain.sh \
  --fonts_dir  /mnt/c/Windows/Fonts \
  --training_text ../langdata/eng/eng.training_text \
  --langdata_dir ../langdata \
  --tessdata_dir ./tessdata \
  --lang eng \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0" \
  --fontlist "Arial" \
  --output_dir ~/tesstutorial/engtest

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Wed, Apr 26, 2017 at 6:32 PM, Bert Spaan <notifications@github.com>
wrote:

> Thanks! This raises a new question: how do I generate .lstfm files? I'm
> trying Tesseract to train on New York city directories
> <https://digitalcollections.nypl.org/items/b42866fb-b877-e4fc-e040-e00a1806275e>,
> I have box files and TIFs. (Another question: can I already use WordStr
> box files, some parts of the documentation say I can, others say I can't?)
>
> ZIP file with TIF and box file I'm trying to use: Wilson1852_0.zip
> <https://github.com/tesseract-ocr/tesseract/files/958420/Wilson1852_0.zip>
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/841#issuecomment-297400009>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oxQuRa5kIoAXZ_0HyeRUZ_JPTZFzks5rz0CCgaJpZM4NIBJS>
> .
>
 What's the output for the 388¬Ω in this example and in other places in this book? @amitdo 388¬Ω becomes 3884. @Shreeshrii : but I have no `fonts_dir`, `fontlist`, etc, since I am only training from images. I'm afraid this way of training is not well documented right now.

I have not yet tried training with 4.00. @amitdo Is it not well documented, or not yet possible at all? @Shreeshrii Do you have examples of this process? Your box file is in wordstr format. That cannot be used with existing
process.

If you had box file in older 3.04  format, then the hacked version of
script would work.

- excuse the brevity, sent from mobile

On 26-Apr-2017 9:02 PM, "ShreeDevi Kumar" <shreeshrii@gmail.com> wrote:

> I will post my modified versions of the scripts tomorrow, don't have
> access to my pc right now.
>
> - excuse the brevity, sent from mobile
>
> On 26-Apr-2017 8:41 PM, "Bert Spaan" <notifications@github.com> wrote:
>
>> @Shreeshrii <https://github.com/Shreeshrii> Do you have examples of this
>> process?
>>
>> ‚Äî
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/841#issuecomment-297440803>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AE2_o0ChPIZezAouqzZA3thLi0m2ovFqks5rz16zgaJpZM4NIBJS>
>> .
>>
>
 I can provide a box file in 3.04 format tomorrow, I'll post the file here. As said, the WordStr format is not really supported right now.

You can still train with the regular box format + tab lines to signal line breaks.

Training from 'real' images as opposed to synthetic ones (with text2image), that what's not well documented.  >Out of the box, Tesseract already performs pretty well, but 150 years ago, house numbers in New York sometimes included ¬Ω, so I have to include this character in the desited_characters file:

@bertspaan the desired_characters file is not directly used for training. It is used at Google for building the large training text required for LSTM training.

I couldn't find any font which has 1/2 the way it is printed here, so it maybe difficult to create synthetic image for it.
 Update: The LSTM training process has been modified since this post was written. These will not work as is. You can use them as reference.
---------------------------------------

Here are the modified scripts:
[boxtrain.zip](https://github.com/tesseract-ocr/tesseract/files/961633/boxtrain.zip)
You will need to copy your box/tiff pairs to the 
../langdata/eng/ directory 
for them to be used.

You cannot use finetune process because 1/2 i not included in the unicharset for current LSTM traineddata for English. @theraysmith , will this change with your  next update?

The following commands outline the process you may need to follow to do the LSTM training - top layer.

```

training/boxtrain.sh \
  --fonts_dir  /mnt/c/Windows/Fonts \
  --training_text ../langdata/eng/nyd.training_text \
  --langdata_dir ../langdata \
  --tessdata_dir ./tessdata \
  --lang eng  \
  --exposures "-2 -1 0" \
  --fontlist "Century Schoolbook" "Dejavu Serif" "Garamond" "Liberation Serif" "Times New Roman," "FreeSerif" "Georgia" \
  --output_dir ~/tesstutorial/nydlegacy
  
cp ~/tesstutorial/nydlegacy/eng.traineddata ./tessdata/nydlegacy.traineddata

training/boxtrain.sh \
  --fonts_dir  /mnt/c/Windows/Fonts \
  --training_text ../langdata/eng/nyd.training_text \
  --langdata_dir ../langdata \
  --tessdata_dir ./tessdata \
  --lang eng \
  --linedata_only \
  --noextract_font_properties \
  --exposures "-2 -1" \
  --fontlist "Bookman Old Style Semi-Light"  \
  --output_dir ~/tesstutorial/nyd
  
rm -rf ~/tesstutorial/eng_from_nyd
mkdir -p ~/tesstutorial/eng_from_nyd

combine_tessdata -e ../tessdata/eng.traineddata \
   ~/tesstutorial/eng_from_nyd/eng.lstm

lstmtraining  \
   -U ~/tesstutorial/nyd/eng.unicharset \
  --train_listfile ~/tesstutorial/nyd/eng.training_files.txt \
  --script_dir ../langdata   \
  --append_index 5 --net_spec '[Lfx256 O1c105]' \
  --continue_from ~/tesstutorial/eng_from_nyd/eng.lstm \
  --model_output ~/tesstutorial/eng_from_nyd/nyd \
  --debug_interval -1 \
  --target_error_rate 0.01
   
lstmtraining \
  --continue_from ~/tesstutorial/eng_from_nyd/nyd_checkpoint \
  --model_output ~/tesstutorial/eng_from_nyd/nyd.lstm \
  --stop_training

cp ../tessdata/eng.traineddata ~/tesstutorial/eng_from_nyd/nyd.traineddata
   
combine_tessdata -o ~/tesstutorial/eng_from_nyd/nyd.traineddata \
  ~/tesstutorial/eng_from_nyd/nyd.lstm \
  ~/tesstutorial/nyd/eng.lstm-number-dawg \
  ~/tesstutorial/nyd/eng.lstm-punc-dawg \
  ~/tesstutorial/nyd/eng.lstm-word-dawg 
 
cp ~/tesstutorial/eng_from_nyd/nyd.traineddata ./tessdata/nyd.traineddata
``` Thanks so much, I will try all this next week! Also see https://github.com/nypl-spacetime/ocr-scripts
 @Shreeshrii: ha, that's my repository! @bertspaan

I see that you have trained models for ocropy.

Is there anything you want to share about ocropy vs. Tesseract 4.00, accuracy wise, with your dataset? 
  @amitdo: yes, we've trained ocropy on a very small amount of sentences, and already the results are pretty good. See [`1854-55.lines.ndjson.zip`](https://github.com/tesseract-ocr/tesseract/files/967991/1854-55.lines.ndjson.zip), this file contains all bounding boxes with ocropy output. However, ocropy sometimes crashes and its documentation is not too good, that's why last week we've started experimenting with Tesseract 4. I haven't compared out-of-the-box output of Tesseract 4 with our trained orcopy model in detail.

@Shreeshrii: ok, I'll try some of the commands you've posted here, but I'm not going to spend much time on trying to train Tesseract, I'll wait until training from scanned images is improved. 

We are also building dictionaries of possible names, streets and professions, so we should be able to fix many OCR errors afterwards.

Thank you both so much for your help! **@Shreeshrii** 
I am also trying to fine tune tesseract4.0 with images. I am confused by several parameters below.
First, what is the training_text(**nyd.training_text**) file? Do I need to create it? If yes, how to create it?
Second, do I just need to specify the **--training_text** and **--output_dir** while leaving other parameters unchanged?

![image](https://user-images.githubusercontent.com/3139202/29311921-f13a0ec0-81e5-11e7-9bf9-dce2272609ff.png)
 combine_lang_model which takes as input an input_unicharset and script_dir (script_dir points to the langdata directory) and optional word list files...
I have got input_unicharset, but I don't know how can I get script_dir . @Shreeshrii Thank youÔºÅ
BUT
I really can't understand how can I create lstm files.
Can you show me the code.

I have tried:
tesseract eng.font.exp0.tif eng.font.exp0.box.lstm.train
But it gives:
Error during processing.
ObjectCache(0x7f098f0849a0)::~ObjectCache(): WARNING! LEAK! object 0x29173e0 still has count 1 (id /usr/local/tesseract/share/tessdata/eng.traineddatapunc-dawg)
ObjectCache(0x7f098f0849a0)::~ObjectCache(): WARNING! LEAK! object 0x2916420 still has count 1 (id /usr/local/tesseract/share/tessdata/eng.traineddataword-dawg)
ObjectCache(0x7f098f0849a0)::~ObjectCache(): WARNING! LEAK! object 0x2916240 still has count 1 (id /usr/local/tesseract/share/tessdata/eng.traineddatanumber-dawg)
 Training tutorial ? 
Do you mean [https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00](url)
but I just have tif/box pairs, so i come here for more information„ÄÇ @Shreeshrii 
I want to use tesseract4.00 to recognize models of machines. All model information are combines whit characters and numbers and located in somewhere of nameplate, so I have collected lots of pictures which contains  various nameplate of each machine. 
After a series of processing, I have got lots pictures of model as follows:
![image](https://user-images.githubusercontent.com/22894599/29905526-d8207088-8e41-11e7-8a94-60661df186c8.png)
![image](https://user-images.githubusercontent.com/22894599/29905561-ff00a722-8e41-11e7-934d-8e87c61433df.png)
And then I put all model pictures into tesseract for recognize, but the accuracy is not so good, so I am trying to train teaaeract4.00 with model pictures.
The tesseract4.0 training tutorial said that there are two ways to create training data, and I use the first option: each line in the box file matches a 'character' (glyph) in the tiff image. 

If 4.0 training with tif/box pairs is not yet supported then how can I do to raise the accuracy?

 @minly, hello, I have the same problems with you ? have you resolved them? @CoCa520, hello, did you generate lstm files finally? I want to know how to generate lstm files according to  *.tif and *.box files? Bumping this..

I tried running the steps mentioned here: https://github.com/tesseract-ocr/tesseract/issues/841#issuecomment-298174100

I'm getting this error: 
```
ERROR: Non-existent flag -D
ERROR: /var/folders/vz/yqbfrgj91hqdj76mmpl2vjmw0000gn/T/tmp.W8q07ZtQ/eng/unicharset does not exist or is not readable
```
It does not create a `.traineddata`, which is what I expected from doing `--linedata_only` parameter..

I'll try to compare what edits @Shreeshrii put in place, but any guidance would be appreciated.

Edit:

[boxtrain.zip](https://github.com/tesseract-ocr/tesseract/files/1468814/boxtrain.zip)

I've diffed the three files to a version in April, grabbed the "intent" of @Shreeshrii 's edit, and applied it to the newest versions of the three files.

```
boxtrain/boxtrain.sh --fonts_dir ~/Library/Fonts/ --training_text ../langdata/eng/eng.training_text --langdata_dir ../langdata --tessdata_dir ./tessdata/ --lang eng --fontlist "Calibri" --output_dir ./lstm1
```
While editing, I saw that @Shreeshrii was creating a folder named "${LANG_DATA_DIR}/GT", and copying TIF/BOX in/out from it. I tried placing my TIF/BOX pairs in the "GT" folder, and to be honest I have no clarity on what the `.traineddata` contains .  Both 3.05 and latest git master produce unusable results with OpenCL (tested on Linux and macOS). It looks like that problem only occurs with [large images](https://digi.bib.uni-mannheim.de/~stweil/tesseract/0604.jp2).

Disabling OpenCL in `ccmain/thresholder.cpp` fixes the problem. #635
Maybe it's the right time to remove the OpenCL code entirely.

I have a feeling that you (Stefan) will disagree...  :)
 Indeed. :-)

Other projects using LSTM strive to use the computing power of graphic cards.

Should Tesseract be an exception because people are satisfied with the CPU based computation, should we try to fix the known problems of the current OpenCL based implementation and improve the code, or is there another solution how Tesseract can use advanced computing power? The problems I see with the OpenCL code:
It mostly duplicates parts of Leptonica, which is an **external** dependency.
It was contributed by someone from AMD. He does not keep maintaining it.
Google does not seem to want to invest time in maintaining it.
The only one that cares and tries to fix bugs is you.

 I respect your work, but I still think the benefit here is quite small and we should drop it.  

A compromise could be that you will maintain that code as a separate project and we will have an optional dependency on it. I tried to sell it to Dan but he didn't buy it :laughing: 
https://github.com/tesseract-ocr/tesseract/issues/635#issuecomment-270327486
Please read his answer. I removed a duplicated part of Leptonica in PR #843. Are there more of them? At least I no longer find a comment naming Leptonica in the OpenCL code. At least some with 'pix' in their names. pixSubtract for example. > I'd roughly guess that includes about a dozen methods.

Good guess. It's a little bit more. I'll send a pull request which reduces the code in `opencl` to less than 5300 lines. Ray's DAS 2014 tutorial, slides set 8 has some statistics about the OpenCL code. PR #849 now removes most of the TIFF related code. Maybe I can remove more in the future. >... reduces the code in opencl to less than 5300 lines.

>Maybe I can remove more in the future.

Only ~5300 lines left (to remove) ... :-) It's still used by one of the benchmarks. As soon as I'm sure that this benchmark is not needed, we'll make a large step in Amit's preferred direction (currently 5074 lines left). http://www.anandtech.com/show/10613/discrete-desktop-gpu-market-trends-q2-2016-amd-grabs-market-share-but-nvidia-remains-on-top

Benchmarks should done on intel's integrated GPU and NVIDIA's GPU.

I read somewhere a claim that the performance of OpenCL with NVIDIA card is significantly worst than with AMD cards.

Another claim is that OpenCL performance on Macs degraded significantly with the last macOS versions. Like NVIDIA, Apple now has an API which is competing with OpenCL. >Both 3.05 and latest git master produce unusable results with OpenCL (tested on Linux and macOS). It looks like that problem only occurs with large images.

Is the issue still exists ? Yes. At least I am not aware that anybody fixed it. Since you opened the issue, you dropped a lot of opencl code. Maybe the issue was related to that code? No, it is caused by one of the remaining (unchanged) OpenCL code blocks. An idea: Maybe you want to add an environment variable to disable opencl at **runtime**, similar to the openmp trick? That environment variable is already there: `TESSERACT_OPENCL_DEVICE`. Set it to the number of the "native device" (or to an illegal value: less than 1 or greater than the number of OpenCL devices) to disable OpenCL. Ok :-)   WordStr Box file option has been defined in the training wiki for 4.0 LSTM. However it is not yet implemented in the code.

This will be useful for using scanned images for training.

Thanks!

See related discussion at https://github.com/tesseract-ocr/tesseract/issues/591 See also https://github.com/tesseract-ocr/tesseract/issues/670#issuecomment-274275423 and below. +1

Even better would be a new line box format (`image1.linebox`).

Maybe something like this.

```
linebox left, top, right, bottom
text <t e x t h e r e>
linebox ...
text ...
```
@theraysmith, what do think about this idea?
 I don't know...   Please see the discussion at https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/b2YFzN7MtJg/dq1-f8JjBgAJ


> I'm pleased to say that I managed to get a build script that works using the following versions of the libs:

>LIBJPEG_VERSION=9b
ZLIB_VERSION=1.2.11
LIBPNG_VERSION=1.6.29
LEPTONICA_VERSION=1.71
TESSERACT_VERSION=3.04.01

>I couldn't get it to work with any later versions of Leptonica (1.74.1 is the latest) or Tesseract (3.05.00 is the latest v3).  See PR #835. It builds on Linux and macOS, see [Travis log](https://travis-ci.org/tesseract-ocr/tesseract/builds/224732278) for an example using `cmake`. My local test was successful with `configure` and `make`. @stweil Thanks, I will post in forum for the original poster to check once the PR is included.

>-- Looking for include file cairo/cairo-version.h
-- Looking for include file cairo/cairo-version.h - not found
-- Looking for include file CL/cl.h
-- Looking for include file CL/cl.h - not found
-- Looking for include file OpenCL/cl.h
-- Looking for include file OpenCL/cl.h - found
-- Looking for include file pango-1.0/pango/pango-features.h
-- Looking for include file pango-1.0/pango/pango-features.h - not found
-- Looking for include file tiffio.h
-- Looking for include file tiffio.h - found
-- Looking for include file unicode/uchar.h
-- Looking for include file unicode/uchar.h - not found

I am guessing that Travis build does not include training tools.

Do they build locally for you on Mac? Yes, Travis CI builds currently without the training part. Of course it is possible to add `make training` if that is considered necessary. Travis also does not cover builds based on the `autotools`, as it uses `cmake`.

> My local test was successful with configure and make.

`make training` also was successful on Mac. Tesseract 3.05 uses `PKG_CHECK_MODULES` to detect `pango` and `cairo`, this should be fairly robust. Closing this as @stweil confirms build on mac with the PR and there is no response from original poster. I had a look on that shell script. The published version does not work because it tries to build Tesseract without building the dependencies (libjpeg, zlib, libpng, leptonica) first. This can be easily fixed in the first lines of the script. Now it builds those dependencies. It also starts building Tesseract 3.05, but fails when linking the `tesseract` executable because of a missing symbol `_fmemopen` in liblept.

This problem is caused by an unusual build of Leptonica: instead of the normal configure / make, the script calls `./make-for-local` which uses a hand-built makefile (maybe made for Linux). I'm also surprised that TIFF support is disabled for the Leptonica build and doubt that this will work with Tesseract.

Building Tesseract with HomeBrew or MacPorts is much easier than with the shell script, and it simply works. End users who want to run Tesseract don't need HomeBrew or MacPorts. They only need some libraries which can be copied and distributed with the Tesseract executable. Even that can be avoided by adding linker flags to use static linkage. See [here](http://digi.bib.uni-mannheim.de/tesseract/mac_standalone/) for a [modified build script](http://digi.bib.uni-mannheim.de/tesseract/mac_standalone/mac_standalone_tesseract_build_script) which produced a [stand-alone `tesseract` for macOS](http://digi.bib.uni-mannheim.de/tesseract/mac_standalone/tesseract). The [build protocol](http://digi.bib.uni-mannheim.de/tesseract/mac_standalone/build.txt) shows some remaining errors, like a wrong URL for getting the language model files. Thanks Stefan.  Actually the shell script does build the dependencies first if you turn on the switches at the start. They are set to 0 or 1 depending on whether you're trying to rebuild/build some or all of them.  If you set them all to 1, the dependencies are built in the order libjpeg, zlib, libpng, leptonica, followed by tesseract.

I found the original script on github and modified it minimally since I didn't understand it fully. The unusual Leptonica build has come directly from that original script. I didn't understand this, so I left it as I found it!

I agree that HomeBrew/MacPorts is much easier if you are an IT person, but my users are analytical chemists or linguists, etc. who just want to run an app. The coding system I use (LiveCode) generates executables that can be run from anywhere without any installation, you just place the folder containing the app and any supporting files/folders wherever you like (e.g. the desktop for short term use).  I don't want the user to have to run an install process, either directly, or by my app doing an initial install on 1st run.

For Windows users there's a portable Tesseract readily available that works as I intended.  For Mac users, there isn't, which is why I looked for and found the shell script that seemed to offer the prospect of generating a portable Tesseract for Mac users.

You mention that it's possible to generate Tesseract using HomeBrew/MacPorts and then "some libraries can be copied & distributed".  Can you tell me exactly which libraries and where they need to be copied to.  Also, would this mean copying libraries to areas outside the user's filing system, i.e. system areas.  If so this would require admin permissions which I can't rely on being available (sometime my users have locked-down computers).  The shell script can generate a portable Tesseract that is located simply by setting 2 environment variables.  I've tested this and it works for my purposes for both JPEG and PNG graphics, which are all I need. However, I'd happily add TIFF support if I knew how to do it!

Thanks again.

Peter. > You mention that it's possible to generate Tesseract using HomeBrew/MacPorts and then "some libraries can be copied & distributed". Can you tell me exactly which libraries and where they need to be copied to. Also, would this mean copying libraries to areas outside the user's filing system, i.e. system areas.

You need to copy all shared libraries which are required by the `tesseract` executable. When you try to run it, macOS will tell you which shared library is missing (only first missing, so repeat until you have found all of them). With MacPorts for example, this means copying 15 files from `/opt/local/lib/*.dylib` (`liblept.5.dylib`, ...). You can choose any destination directory. By setting the environment variable DYLD_LIBRARY_PATH to that directory, Tesseract can find the shared libraries. Thanks Stefan, your suggestion works well.  I did the following:
1. using Terminal, install Tesseract using HomeBrew
2. copy the folder "3.05.001" from /usr/local/Cellar/tesseract into a folder on my desktop called "tessport"
3. created a test shell script "tesseract_test.sh":
    #!/bin/bash
    export TESSDATA_PREFIX=/Users/peter/Desktop/tessport/share
    export DYLD_LIBRARY_PATH=/Users/peter/Desktop/tessport/lib
    tessport/bin/tesseract -v
4. ran the test shell script "tesseract_test.sh" to confirm it works
5. uninstalled Tesseract using HomeBrew
6. re-an the test shell script "tesseract_test.sh" to confirm it still works

So I now have a recipe for generating the latest Tesseract in portable form for the Mac!

Thanks again.

Peter  Command below results in a segmentation fault
tesseract a.jpg stdout --oem 1 --psm 0 -l eng  

Environment details:
Which operating system - Ubuntu 16.10 Yakkety Yak on x86_64
Which version/commit of tesseract - top of Changelog says 2017-03-24 - v4.00.00-alpha
How was tesseract built or - I compiled it from source

Command above works with --psm 3 is used instead.

Pritam Dodeja Try `tesseract a.jpg stdout --oem 0 --psm 0 -l eng`
 Also try with this image:
https://github.com/tesseract-ocr/tesseract/raw/master/testing/phototest.tif Find below

 tesseract phototest.tif stdout --oem 0 --psm 0 -l eng
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
Page 1
Page number: 0
Orientation in degrees: 0
Rotate: 0
Orientation confidence: 15.98
Script: Latin
Script confidence: 460.00

tesseract phototest.tif stdout --oem 1 --psm 0 -l eng
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
Page 1
Segmentation fault (core dumped)

tesseract phototest.tif stdout --oem 1 --psm 3 -l eng
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
Page 1
This is a lot of 12 point text to test the
ocr code and see if it works on all types
of file format.

The quick brown dog jumped over the
lazy fox. The quick brown dog jumped
over the lazy fox. The quick brown dog
jumped over the lazy fox. The quick
brown dog jumped over the lazy fox.

Pritam


 The warnings are ugly but seem harmless.

With `--oem 0` and `--psm 0` Tesseract works as expected.

With `--oem 1` and `--psm 0` Tesseract segfault.
The reason - the new LSTM engine has no OSD feature **currently**, only the older engine has it.

For now, the solution is to always use `--oem 0` when using `--psm 0` BTW, you should use `osd` instead of `eng` with `--psm 0`.


Using `eng` will result in always detecting `Latin` as the script, even if the text is written in another script. From what I have read, tesseract v4 greatly improves ocr due to LSTM.  If I know that my text is going to be of a certain orientation and script  (top to bottom and English), how do I take advantage of the newer engine?  Thanks for the help and sorry for the delay in my response. The 4.00 version is in alpha stage. It's not yet considered ready to replace the stable 3.05 version.
There is a plan to add an OSD feature to the LSTM engine. Is there any update on this?  Let me know if you want me to do any testing etc.  Thanks! I'm sorry, but there is no update on this issue. try this:

>tesseract in.png out **-l osd** --psm 0 --oem 0  Hello All,

I want to train tesseract as [](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Finetune), But I got this error, Any help
```
 tesstrain.sh --fonts_dir /usr/share/fonts --lang ara  --training_text ../../tesserac-ocr/langdata/ara.training_text   --langdata_dir ../langdata --tessdata_dir ./tessdata   --fontlist "Arial"   --output_dir ~/tesstutorial/aratest
=== Starting training for language 'ara'
[ÿ± ÿ£ÿ®ÿ± 12 07:48:58 EET 2017] /usr/bin/text2image --fonts_dir=/usr/share/fonts --font=Arial --outputbase=/tmp/font_tmp.Rj3QkZFztb/sample_text.txt --text=/tmp/font_tmp.Rj3QkZFztb/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.Rj3QkZFztb
Rendered page 0 to file /tmp/font_tmp.Rj3QkZFztb/sample_text.txt.tif

=== Phase I: Generating training images ===
Rendering using Arial
[ÿ± ÿ£ÿ®ÿ± 12 07:49:17 EET 2017] /usr/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.Rj3QkZFztb --fonts_dir=/usr/share/fonts --strip_unrenderable_words --fontconfig_refresh_config_file=false --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.XBcy4TVQwb/ara/ara.Arial.exp0 --font=Arial --text=../../tesserac-ocr/langdata/ara.training_text
ERROR: Non-existent flag --fontconfig_refresh_config_file=false
ERROR: /tmp/tmp.XBcy4TVQwb/ara/ara.Arial.exp0.box does not exist or is not readable
ERROR: /tmp/tmp.XBcy4TVQwb/ara/ara.Arial.exp0.box does not exist or is not readable
``` --training_text ../../tesserac-ocr/langdata/ara.training_text 

is there a typo in your folder name tesserac instead of tesseract?

 is my folder name  ```
$ training/tesstrain.sh  \
   --fonts_dir /usr/share/fonts/ \
  --lang ara   \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --langdata_dir ../langdata \
  --tessdata_dir ../tessdata  \
  --output_dir ~/tesstutorial/ara  \
  --fontlist "Arial"

=== Starting training for language 'ara'
[Wed Apr 12 14:55:47 DST 2017] /usr/local/bin/text2image --fonts_dir=/usr/share/fonts/ --font=Arial --outputbase=/tmp/font_tmp.OIUrMxATnl/sample_text.txt --text=/tmp/f
ont_tmp.OIUrMxATnl/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.OIUrMxATnl
Rendered page 0 to file /tmp/font_tmp.OIUrMxATnl/sample_text.txt.tif

=== Phase I: Generating training images ===
Rendering using Arial
[Wed Apr 12 14:56:35 DST 2017] /usr/local/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.OIUrMxATnl --fonts_dir=/usr/share/fonts/ --strip_unrenderable_words --leadin
g=32 --xsize=2550 --ptsize=16 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0 --font=Arial --text=../langdata/ara/ara.training_text
0
Rendered page 0 to file /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.tif
/tmp/tmp.xPjs35P5oP/ara/gt/ara.Arial.exp0.txt

=== Phase UP: Generating unicharset and unichar properties files ===
[Wed Apr 12 14:56:38 DST 2017] /usr/local/bin/unicharset_extractor -D /tmp/tmp.xPjs35P5oP/ara/ /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.box
Extracting unicharset from /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.box
Wrote unicharset file /tmp/tmp.xPjs35P5oP/ara//unicharset.
[Wed Apr 12 14:56:39 DST 2017] /usr/local/bin/set_unicharset_properties -U /tmp/tmp.xPjs35P5oP/ara/ara.unicharset -O /tmp/tmp.xPjs35P5oP/ara/ara.unicharset -X /tmp/tmp
.xPjs35P5oP/ara/ara.xheights --script_dir=../langdata
Loaded unicharset of size 187 from file /tmp/tmp.xPjs35P5oP/ara/ara.unicharset
Setting unichar properties
Writing unicharset to file /tmp/tmp.xPjs35P5oP/ara/ara.unicharset

=== Phase D: Generating Dawg files ===
Generating word Dawg
[Wed Apr 12 14:56:41 DST 2017] /usr/local/bin/wordlist2dawg -r 1 ../langdata/ara/ara.wordlist /tmp/tmp.xPjs35P5oP/ara/ara.word-dawg /tmp/tmp.xPjs35P5oP/ara/ara.unichar
set
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.xPjs35P5oP/ara/ara.unicharset'
Reading word list from '../langdata/ara/ara.wordlist'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.xPjs35P5oP/ara/ara.word-dawg'
Generating frequent-word Dawg
[Wed Apr 12 14:56:46 DST 2017] /usr/local/bin/wordlist2dawg -r 1 /tmp/tmp.xPjs35P5oP/ara/ara.wordlist.clean.freq /tmp/tmp.xPjs35P5oP/ara/ara.freq-dawg /tmp/tmp.xPjs35P
5oP/ara/ara.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.xPjs35P5oP/ara/ara.unicharset'
Reading word list from '/tmp/tmp.xPjs35P5oP/ara/ara.wordlist.clean.freq'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.xPjs35P5oP/ara/ara.freq-dawg'
[Wed Apr 12 14:56:47 DST 2017] /usr/local/bin/wordlist2dawg -r 2 ../langdata/ara/ara.punc /tmp/tmp.xPjs35P5oP/ara/ara.punc-dawg /tmp/tmp.xPjs35P5oP/ara/ara.unicharset
Set reverse_policy to RRP_FORCE_REVERSE
Loading unicharset from '/tmp/tmp.xPjs35P5oP/ara/ara.unicharset'
Reading word list from '../langdata/ara/ara.punc'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.xPjs35P5oP/ara/ara.punc-dawg'
[Wed Apr 12 14:56:47 DST 2017] /usr/local/bin/wordlist2dawg -r 0 ../langdata/ara/ara.numbers /tmp/tmp.xPjs35P5oP/ara/ara.number-dawg /tmp/tmp.xPjs35P5oP/ara/ara.unicha
rset
Set reverse_policy to RRP_DO_NO_REVERSE
Loading unicharset from '/tmp/tmp.xPjs35P5oP/ara/ara.unicharset'
Reading word list from '../langdata/ara/ara.numbers'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.xPjs35P5oP/ara/ara.number-dawg'
[Wed Apr 12 14:56:47 DST 2017] /usr/local/bin/wordlist2dawg -r 1 ../langdata/ara/ara.word.bigrams /tmp/tmp.xPjs35P5oP/ara/ara.bigram-dawg /tmp/tmp.xPjs35P5oP/ara/ara.u
nicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.xPjs35P5oP/ara/ara.unicharset'
Reading word list from '../langdata/ara/ara.word.bigrams'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.xPjs35P5oP/ara/ara.bigram-dawg'

=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=../tessdata
[Wed Apr 12 14:57:00 DST 2017] /usr/local/bin/tesseract /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.tif /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0 lstm.train ../langdata/ara/ar
a.config
Tesseract Open Source OCR Engine v4.00.00alpha-361-g1477e17 with Leptonica
Page 1

=== Constructing LSTM training data ===
Creating new directory /home/shree/tesstutorial/ara
Copying ../langdata/ara/ara.config to /home/shree/tesstutorial/ara
Moving /tmp/tmp.xPjs35P5oP/ara/ara.unicharset to /home/shree/tesstutorial/ara
Moving /tmp/tmp.xPjs35P5oP/ara/ara.number-dawg to /home/shree/tesstutorial/ara/ara.lstm-number-dawg
Moving /tmp/tmp.xPjs35P5oP/ara/ara.punc-dawg to /home/shree/tesstutorial/ara/ara.lstm-punc-dawg
Moving /tmp/tmp.xPjs35P5oP/ara/ara.word-dawg to /home/shree/tesstutorial/ara/ara.lstm-word-dawg
Moving /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.box to /home/shree/tesstutorial/ara
Moving /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.tif to /home/shree/tesstutorial/ara
Moving /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.lstmf to /home/shree/tesstutorial/ara
Moving /tmp/tmp.xPjs35P5oP/ara/gt/ara.Arial.exp0.txt to /home/shree/tesstutorial/ara

Completed training for language 'ara'

shree@ALL-IN-1-TOUCH:/mnt/c/Users/User/shree/tesseract-ocr$
``` @Shreeshrii Thanks a lot, one more question please to get full understanding of it` --langdata_dir` parameter is the directory of https://github.com/tesseract-ocr/langdata/tree/master/ara 
again thanks for replying! Put Arabic langdata files under ara folder in langdata - similar to 
https://github.com/tesseract-ocr/langdata

so that you have

./langdata
./langdata/ara
./tessdata
./tesseract
./tesseract/tessdata
./tesseract/training

etc



 I got it, Thanks @Shreeshrii  Shree, please redirect people that ask questions about the training process to the forum.

Thanks!   Hello,@Shreeshrii 
I have the same problem like @am0awad . 

```
 training/tesstrain.sh  \
  --fonts_dir /Library/Fonts \
  --lang chi_sim   \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --langdata_dir ./langdata \
  --tessdata_dir ./tessdata  \
  --output_dir ./tesstutorial/chi_sim 
```

I have already download the [https://github.com/tesseract-ocr/langdata](url) to my folder, and I have all the folders:

./langdata
./langdata/chi_sim 
./tessdata
 
but I still got this:
```
=== Starting training for language 'chi_sim'
mktemp: illegal option -- -
usage: mktemp [-d] [-q] [-t prefix] [-u] template ...
       mktemp [-d] [-q] [-u] -t prefix 
training/tesstrain_utils.sh: line 189: /sample_text.txt: Permission denied
[2017Âπ¥ 8Êúà 3Êó• ÊòüÊúüÂõõ 15Êó∂23ÂàÜ24Áßí CST] /usr/local/bin/text2image --fonts_dir=/Library/Fonts --font=AR PL UKai CN Light --outputbase=/sample_text.txt --text=/sample_text.txt --fontconfig_tmpdir=

=== Phase I: Generating training images ===
Rendering using Arial Unicode MS
Rendering using AR PL UKai CN Light
[2017Âπ¥ 8Êúà 3Êó• ÊòüÊúüÂõõ 15Êó∂23ÂàÜ25Áßí CST] /usr/local/bin/text2image --fontconfig_tmpdir= --fonts_dir=/Library/Fonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.AR_PL_UKai_CN_Light.exp0 --font=AR PL UKai CN Light --text=./langdata/chi_sim/chi_sim.training_text
[2017Âπ¥ 8Êúà 3Êó• ÊòüÊúüÂõõ 15Êó∂23ÂàÜ25Áßí CST] /usr/local/bin/text2image --fontconfig_tmpdir= --fonts_dir=/Library/Fonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.Arial_Unicode_MS.exp0 --font=Arial Unicode MS --text=./langdata/chi_sim/chi_sim.training_text
ERROR: /var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.Arial_Unicode_MS.exp0.box does not exist or is not readable
ERROR: /var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.AR_PL_UKai_CN_Light.exp0.box does not exist or is not readable
ERROR: /var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.AR_PL_UKai_CN_Light.exp0.box does not exist or is not readable
```

Would anyone like to help me?

Thank you very much!

 Thank you @Shreeshrii I solved my problem by your help! Thank you very much! @Shreeshrii at Phase I,  I got this error:
Rendered page 2 to file /tmp/tmp.GZVqm2mm3D/fas/fas.Times_New_Roman.exp0.tif
Null box at index 0
Error: Call PrepareToWrite before WriteTesseractBoxFile!!
 but the process did not stop. and it got this error:
ERROR: /tmp/tmp.GZVqm2mm3D/fas/fas.Times_New_Roman.exp0.lstmf does not exist or is not readable
probably, the problem is in the very first phase. would you please help me solve it? yes. you're right. in fact, there are just numbers and some marks in tif
file. why is that happening?

On Tue, Oct 17, 2017 at 5:29 PM, Shreeshrii <notifications@github.com>
wrote:

> Look at the tif file in question in tmp folder. Looks like first line has
> nulls in it.
>
> On 17-Oct-2017 5:59 PM, "hanikh" <notifications@github.com> wrote:
>
> > @Shreeshrii <https://github.com/shreeshrii> at Phase I, I got this
> error:
> > Rendered page 2 to file /tmp/tmp.GZVqm2mm3D/fas/fas.
> > Times_New_Roman.exp0.tif
> > Null box at index 0
> > Error: Call PrepareToWrite before WriteTesseractBoxFile!!
> > but the process did not stop. and it got this error:
> > ERROR: /tmp/tmp.GZVqm2mm3D/fas/fas.Times_New_Roman.exp0.lstmf does not
> > exist or is not readable
> > probably, the problem is in the very first phase. would you please help
> me
> > solve it?
> >
> > ‚Äî
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/819#
> issuecomment-337215631>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_o0n0rSz-
> Z9XhUN2g4ge8DsQXIZi9ks5stJ25gaJpZM4M6-yu>
> > .
> >
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/819#issuecomment-337240137>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiASKi4zAcvT6hL8SkvIybrnjQVMWrks5stLLOgaJpZM4M6-yu>
> .
>
 Times New Roman is in the list of Persian fonts in
training/language_specific.sh. Doesn‚Äôt it mean that the Farsi trained model
is trained for Times New Roman?Or the listed fonts are just recommended?

On Wed, Oct 18, 2017 at 5:56 AM, Shreeshrii <notifications@github.com>
wrote:

> Does Times New Roman font support Farsi? You should use fonts that have
> support for your training_text language.
>
> ShreeDevi
> ____________________________________________________________
> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>
>
> On Tue, Oct 17, 2017 at 9:13 PM, hanikh <notifications@github.com> wrote:
>
> > yes. you're right. in fact, there are just numbers and some marks in tif
> > file. why is that happening?
> >
> > On Tue, Oct 17, 2017 at 5:29 PM, Shreeshrii <notifications@github.com>
> > wrote:
> >
> > > Look at the tif file in question in tmp folder. Looks like first line
> has
> > > nulls in it.
> > >
> > > On 17-Oct-2017 5:59 PM, "hanikh" <notifications@github.com> wrote:
> > >
> > > > @Shreeshrii <https://github.com/shreeshrii> at Phase I, I got this
> > > error:
> > > > Rendered page 2 to file /tmp/tmp.GZVqm2mm3D/fas/fas.
> > > > Times_New_Roman.exp0.tif
> > > > Null box at index 0
> > > > Error: Call PrepareToWrite before WriteTesseractBoxFile!!
> > > > but the process did not stop. and it got this error:
> > > > ERROR: /tmp/tmp.GZVqm2mm3D/fas/fas.Times_New_Roman.exp0.lstmf does
> not
> > > > exist or is not readable
> > > > probably, the problem is in the very first phase. would you please
> help
> > > me
> > > > solve it?
> > > >
> > > > ‚Äî
> > > > You are receiving this because you were mentioned.
> > > > Reply to this email directly, view it on GitHub
> > > > <https://github.com/tesseract-ocr/tesseract/issues/819#
> > > issuecomment-337215631>,
> > > > or mute the thread
> > > > <https://github.com/notifications/unsubscribe-auth/AE2_o0n0rSz-
> > > Z9XhUN2g4ge8DsQXIZi9ks5stJ25gaJpZM4M6-yu>
> > > > .
> > > >
> > >
> > > ‚Äî
> > > You are receiving this because you commented.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/819#
> > issuecomment-337240137>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/
> > AZFiASKi4zAcvT6hL8SkvIybrnjQVMWrks5stLLOgaJpZM4M6-yu>
> > > .
> > >
> >
> > ‚Äî
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/819#
> issuecomment-337269936>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_
> o5yHcKCu2plw2oV9eKheXyc1opAYks5stMsagaJpZM4M6-yu>
>
> > .
> >
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/819#issuecomment-337441751>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAXjsDJTN8DS85eiZHWvQF07HIP6Tks5stWHigaJpZM4M6-yu>
> .
>
  The docker image fails to build. Host is Ubuntu 16.04.

The following commands were used to start the build:

```
git clone https://github.com/tesseract-ocr/tesseract.git
cd tesseract
sudo docker build -t docker-tesseract .
```

Error message:

```
$ cmake .. -DLeptonica_DIR=leptonica-$LEPT_VER/build
CMake Error at /usr/share/cmake-3.7/Modules/CMakeDetermineCCompiler.cmake:48 (message):
  Could not find compiler set in environment variable CC:

  gcc-4.8.
Call Stack (most recent call first):
  CMakeLists.txt:47 (project)


CMake Error: CMAKE_C_COMPILER not set, after EnableLanguage
CMake Error: CMAKE_CXX_COMPILER not set, after EnableLanguage
-- Configuring incomplete, errors occurred!
See also "/root/build/tesseract-ocr/tesseract/build/CMakeFiles/CMakeOutput.log".

travis_time:end:0b3c16ed:start=1491933375378626936,finish=1491933375393151695,du
The command "cmake .. -DLeptonica_DIR=leptonica-$LEPT_VER/build" exited with 1.
$ make
make: *** No targets specified and no makefile found.  Stop.

travis_time:end:2a97cb84:start=1491933375396141259,finish=1491933375399900930,du
The command "make" exited with 2.

``` CC: @ianblenke (#282) try HTTPS://hub.Docker.com/r/xlight/docker-tesseract4

Amit D. <notifications@github.com>‰∫é2017Âπ¥4Êúà12Êó• Âë®‰∏â‰∏äÂçà2:12ÂÜôÈÅìÔºö

> CC: @ianblenke <https://github.com/ianblenke> (#282
> <https://github.com/tesseract-ocr/tesseract/pull/282>)
>
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/817#issuecomment-293351663>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAEwV2cLDv__GLLZZ8hph0Splbm3iXjQks5ru8KDgaJpZM4M6coZ>
> .
>
 https://github.com/xlight/docker-tesseract4/blob/master/Dockerfile

@xlight,

Why the `--enable-debug`? With this option Tesseract will be compiled with `-O0` and will be VERY slow. It's not a good idea to use it with a docker image. @amitdo why do you say that it is not a good idea? I built it with enable debug , because I want to know the reason why lstmtraining with eval_listfile coredump.
But It does not help  >why do you say that it is not a good idea?

Because of its slowness. I think that users of Docker Hub images expect to get an optimized build, not a debug one.   Ah oh course. I tried without but I am getting the issue 893...
Btw thx to @xlight for his docker file. I just added the download and move of some traineddata. @stweil, can you fix it? >The docker image fails to build. Host is Ubuntu 16.04.

The file `Dockerflle` in our repo is still not fixed.

Maybe we should remove this file (and `docker-compose.yml`).  It supposed to be used by users that want docker image of Tesseract.

I think we should remove it from our repo.  The Dockerfile configures a Docker container which builds Tesseract using the Travis configuration, so it can be used to locally test problems with that configuration (only the Linux part, not the macOS part). I can fix it, but that needs some time. >I can fix it, but that needs some time.

OK. If you plan to fix it, we can keep it. See pull request #932 for a fix. Does your PR solves the OP issue?

>CMake Error at /usr/share/cmake-3.7/Modules/CMakeDetermineCCompiler.cmake:48 (message):
>  Could not find compiler set in environment variable CC:
>
>  gcc-4.8. @benstadin, could you please retry your docker build with the changes from #932?

@amitdo, I did not get the same error message initially, therefore I don't know. The `Dockerfile` uses the master branch of https://github.com/travis-ci/travis-build. If there is an issue with that latest version, it might damage the docker build process. I looked for a stable version of `travis-build`, but the latest release was made in 2014.  Hello,
Using tesseract v3.04.01 on Fedora 25, a standard transformation like
```tesseract somefile.png pdf -l eng > output 2> error```
will write ```Tesseract Open Source OCR Engine v3.04.01 with Leptonica``` to error file even if the transformation worked as expected.
tesseract v3.02 on Ubuntu 12.04.5 writes to stdout instead of stderr.

Regards,
Ozy.  Hello!

Latest Tesseract version built from GIT with mingw-w64-i686 toolchain (gcc/g++ 6.2.0) crashes when run on Windows XP 32 bit (confirmed both for SP2 and SP3 OS versions). It crashes after several seconds of image processing and shows standard Windows dialog with this error text: "Exception unknow software exception (0xc000001d) in application at address 0x655b25f0".

On Windows 7 and 8 (x64) same images are recognized fine without any issues. I'm afraid that nobody will care about support for a Windows version which was abandoned by MS [three years ago](https://www.microsoft.com/en-us/windowsforbusiness/end-of-xp-support).  Does Tesseract on Windows 7/8 **32 bit** work well or crash too?  Tesseract version built from GIT with mingw-w64-i686 toolchain (gcc/g++ 6.2.0)

Does it have to be built with special flags for win32? There is currently not enough information for this issue report: As far as I know, 0xc000001d means illegal instruction. So the program is running machine code which is not defined for that machine. This could be caused by a program bug, or code and hardware simply don't fit.

* What is the hardware used for the tests (exact CPU models)? I assume that the tests with different versions of Windows also used different hardware. This problem could be eliminated by always using the same hardware (or a well defined virtual machine).

* Does Tesseract try to use SSE or AVX? Run `tesseract -v` to check that.

* More details on the build process are needed (cross or native build, origin of toolchain, exact commands used for build, build protocol).

What about running Tesseract under control of a debugger like gdb for Windows? Then the debugger would show the illegal instruction. > Does it have to be built with special flags for win32?

No, no special flags are needed for win32. My 32 and 64 bit builds for Windows only differ in the prefix for build tools and installation:

    ./configure --host=i686-w64-mingw32 --prefix=/usr/i686-w64-mingw32 && make
    ./configure --host=x86_64-w64-mingw32 --prefix=/usr/x86_64-w64-mingw32 && make
 Thank you all for respose! I'm well aware of the fact that XP is quite outdated OS, but some people still prefere to use it despite troubles with outdated drivers etc. If it would take too much effort to fix it then it probably doesn't worth it. But if there is a chance of fixing it without going too deep in debug process then it would be great.

Now in order of questions:

1) It works just fine on Windows 7 32 bit, no crashes at all. On the very same PC it crashes constanly under XP 32 bit.

2) 1st crash machine: Intel Core i3-2120 3.30GHz.
2nd crash machine: Intel Core i5 3570 3.4 GHz (OS run under VirtualBox Version 5.1.18 r 114002(Qt5.6.2)).

3) tesseract -v:

> tesseract 4.00.00alpha
>  leptonica-1.74.1
>   libgif 5.1.4 : libjpeg 8d (libjpeg-turbo 1.5.1) : libpng 1.6.26 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.6.0
> 
>  Found AVX
>  Found SSE

4) Build is done under Windows 8 64 bit using latest MSYS2 (https://sourceforge.net/projects/msys2/) distributive, updated with "pacman -Syuu" to get latest leptonica version.

Configure call:

> sh configure MAKE=mingw32-make --prefix=C:/atlas-sdk/msys32/mingw32 --disable-graphics --enable-static=no --enable-debug

Configure output:

> configure: loading site script C:/atlas-sdk/msys32/mingw32/etc/config.site
> checking for g++... g++
> checking whether the C++ compiler works... yes
> checking for C++ compiler default output file name... a.exe
> checking for suffix of executables... .exe
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ accepts -g... yes
> checking for a BSD-compatible install... /usr/bin/install -c
> checking whether build environment is sane... yes
> checking for a thread-safe mkdir -p... /usr/bin/mkdir -p
> checking for gawk... gawk
> checking whether mingw32-make sets $(MAKE)... yes
> checking for style of include used by mingw32-make... GNU
> checking whether mingw32-make supports nested variables... yes
> checking dependency style of g++... gcc3
> checking whether to enable maintainer-specific portions of Makefiles... no
> checking build system type... i686-w64-mingw32
> checking host system type... i686-w64-mingw32
> checking whether C++ compiler accepts -mavx... yes
> checking whether C++ compiler accepts -msse4.1... yes
> checking --enable-graphics argument... no
> checking --enable-embedded argument... no
> checking for g++ option to support OpenMP... -fopenmp
> checking --enable-opencl argument... no
> checking how to run the C++ preprocessor... g++ -E
> checking for grep that handles long lines and -e... /usr/bin/grep
> checking for egrep... /usr/bin/grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking CL/cl.h usability... no
> checking CL/cl.h presence... no
> checking for CL/cl.h... no
> checking OpenCL/cl.h usability... no
> checking OpenCL/cl.h presence... no
> checking for OpenCL/cl.h... no
> checking tiffio.h usability... yes
> checking tiffio.h presence... yes
> checking for tiffio.h... yes
> checking for clGetPlatformIDs in -lOpenCL... no
> checking --enable-visibility argument... no
> checking --enable-multiple-libraries argument... no
> checking whether to use tessdata-prefix... yes
> checking whether to enable debugging... yes
> checking how to print strings... printf
> checking for gcc... gcc
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> checking whether gcc understands -c and -o together... yes
> checking dependency style of gcc... gcc3
> checking for a sed that does not truncate output... /usr/bin/sed
> checking for fgrep... /usr/bin/grep -F
> checking for ld used by gcc... C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe
> checking if the linker (C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe) is GNU ld... yes
> checking for BSD- or MS-compatible name lister (nm)... /mingw32/i686-w64-mingw32/bin/nm -B
> checking the name lister (/mingw32/i686-w64-mingw32/bin/nm -B) interface... BSD nm
> checking whether ln -s works... no, using cp -pR
> checking the maximum length of command line arguments... 8192
> checking how to convert i686-w64-mingw32 file names to i686-w64-mingw32 format... func_convert_file_msys_to_w32
> checking how to convert i686-w64-mingw32 file names to toolchain format... func_convert_file_msys_to_w32
> checking for C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe option to reload object files... -r
> checking for objdump... objdump
> checking how to recognize dependent libraries... file_magic ^x86 archive import|^x86 DLL
> checking for dlltool... dlltool
> checking how to associate runtime and link libraries... func_cygming_dll_for_implib
> checking for ar... ar
> checking for archiver @FILE support... @
> checking for strip... strip
> checking for ranlib... ranlib
> checking command to parse /mingw32/i686-w64-mingw32/bin/nm -B output from gcc object... ok
> checking for sysroot... no
> checking for a working dd... /usr/bin/dd
> checking how to truncate binary pipes... /usr/bin/dd bs=4096 count=1
> checking for mt... no
> checking if : is a manifest tool... no
> checking for dlfcn.h... no
> checking for objdir... .libs
> checking if gcc supports -fno-rtti -fno-exceptions... no
> checking for gcc option to produce PIC... -DDLL_EXPORT -DPIC
> checking if gcc PIC flag -DDLL_EXPORT -DPIC works... yes
> checking if gcc static flag -static works... yes
> checking if gcc supports -c -o file.o... yes
> checking if gcc supports -c -o file.o... (cached) yes
> checking whether the gcc linker (C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe) supports shared libraries... yes
> checking whether -lc should be explicitly linked in... yes
> checking dynamic linker characteristics... Win32 ld.exe
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... no
> checking how to run the C++ preprocessor... g++ -E
> checking for ld used by g++... C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe
> checking if the linker (C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe) is GNU ld... yes
> checking whether the g++ linker (C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe) supports shared libraries... yes
> checking for g++ option to produce PIC... -DDLL_EXPORT -DPIC
> checking if g++ PIC flag -DDLL_EXPORT -DPIC works... yes
> checking if g++ static flag -static works... yes
> checking if g++ supports -c -o file.o... yes
> checking if g++ supports -c -o file.o... (cached) yes
> checking whether the g++ linker (C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe) supports shared libraries... yes
> checking dynamic linker characteristics... Win32 ld.exe
> checking how to hardcode library paths into programs... immediate
> checking whether byte ordering is bigendian... no
> checking if compiling with clang... no
> checking whether compiler supports C++11... yes
> checking for snprintf... yes
> checking for library containing sem_init... none required
> checking for ANSI C header files... (cached) yes
> checking whether time.h and sys/time.h may both be included... yes
> checking for sys/wait.h that is POSIX.1 compatible... no
> checking sys/ipc.h usability... no
> checking sys/ipc.h presence... no
> checking for sys/ipc.h... no
> checking sys/shm.h usability... no
> checking sys/shm.h presence... no
> checking for sys/shm.h... no
> checking limits.h usability... yes
> checking limits.h presence... yes
> checking for limits.h... yes
> checking malloc.h usability... yes
> checking malloc.h presence... yes
> checking for malloc.h... yes
> checking for stdbool.h that conforms to C99... no
> checking for _Bool... no
> checking whether #! works in shell scripts... yes
> checking for special C compiler options needed for large files... no
> checking for _FILE_OFFSET_BITS value needed for large files... 64
> checking for getline... no
> checking for wchar_t... yes
> checking for long long int... yes
> checking for off_t... yes
> checking for mbstate_t... yes
> checking for pkg-config... /mingw32/bin/pkg-config
> checking pkg-config is at least version 0.9.0... yes
> checking for lept >= 1.74... yes
> checking for icu-uc... yes
> checking for icu-i18n... yes
> checking for pango... yes
> checking for cairo... yes
> checking that generated files are newer than configure... done
> configure: creating ./config.status
> config.status: creating Makefile
> config.status: creating tesseract.pc
> config.status: creating api/Makefile
> config.status: creating arch/Makefile
> config.status: creating ccmain/Makefile
> config.status: creating opencl/Makefile
> config.status: creating ccstruct/Makefile
> config.status: creating ccutil/Makefile
> config.status: creating classify/Makefile
> config.status: creating cutil/Makefile
> config.status: creating dict/Makefile
> config.status: creating lstm/Makefile
> config.status: creating textord/Makefile
> config.status: creating viewer/Makefile
> config.status: creating wordrec/Makefile
> config.status: creating tessdata/Makefile
> config.status: creating tessdata/configs/Makefile
> config.status: creating tessdata/tessconfigs/Makefile
> config.status: creating testing/Makefile
> config.status: creating java/Makefile
> config.status: creating java/com/Makefile
> config.status: creating java/com/google/Makefile
> config.status: creating java/com/google/scrollview/Makefile
> config.status: creating java/com/google/scrollview/events/Makefile
> config.status: creating java/com/google/scrollview/ui/Makefile
> config.status: creating doc/Makefile
> config.status: creating training/Makefile
> config.status: creating config_auto.h
> config.status: executing depfiles commands
> config.status: executing libtool commands
> 
> Configuration is done.
> You can now build and install tesseract by running:
> 
> $ make
> $ sudo make install
> 
> Training tools can be build and installed (after building of tesseract) with:
> 
> $ make training
> $ sudo make training-install


5) Running with gdb:

> gdb --args ./tesseract image14281.jpg image14281
>  -l rus
> GNU gdb (GDB) 7.12.1
> Copyright (C) 2017 Free Software Foundation, Inc.
> License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
> This is free software: you are free to change and redistribute it.
> There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
> and "show warranty" for details.
> This GDB was configured as "i686-w64-mingw32".
> Type "show configuration" for configuration details.
> For bug reporting instructions, please see:
> <http://www.gnu.org/software/gdb/bugs/>.
> Find the GDB manual and other documentation resources online at:
> <http://www.gnu.org/software/gdb/documentation/>.
> For help, type "help".
> Type "apropos word" to search for commands related to "word"...
> Traceback (most recent call last):
>   File "<string>", line 3, in <module>
> ImportError: No module named libstdcxx.v6.printers
> c:\atlas-sdk\msys32\mingw32\bin\../etc/gdbinit:5: Error in sourced command file:
> 
> Error while executing Python code.
> Reading symbols from ./tesseract...done.
> (gdb) run
> Starting program: C:\atlas-sdk\msys32\mingw32\bin\tesseract.exe image14281.jpg i
> mage14281 -l rus
> [New Thread 316.0x79c]
> Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
> Detected 24 diacritics
> [New Thread 316.0x3e4]
> [New Thread 316.0x2e8]
> [New Thread 316.0x69c]
> 
> Thread 2 received signal SIGILL, Illegal instruction.
> [Switching to Thread 316.0x3e4]
> tesseract::DotProductAVX (u=0xcc0010, v=0x469f5f8, n=25)
>     at dotproductavx.cpp:70
> 70      dotproductavx.cpp: No such file or directory.
> (gdb) continue
> Continuing.
> 
> Thread 2 received signal SIGILL, Illegal instruction.
> tesseract::DotProductAVX (u=0xcc0010, v=0x469f5f8, n=25)
>     at dotproductavx.cpp:70
> 70      in dotproductavx.cpp
> (gdb) continue
> Continuing.
> [Thread 316.0x3e4 exited with code 3221225501]
> [Thread 316.0x2e8 exited with code 3221225501]
> [Inferior 1 (process 316) exited with code 030000000035]
> (gdb) continue
> The program is not being run.
> (gdb) @paukonen, you are using a relatively new computer (with AVX and SSE support) on an old operating system (Windows XP). A quick search gives lots of hints that AVX does not work with XP. Tesseract will detect AVX support of the CPU and use it, because it does not test whether you are using an old operating system. So I expect that is the reason of the crash which you observe.

You can test that hypothesis by building a new Tesseract with AVX disabled: simply remove all lines which set `avx_available_` in file `arch/simddetect.cpp`. The resulting Tesseract should work on any Windows version. If is does not, disable SSE support as well. >You can simply remove all lines which set avx_available_ in file arch/simddetect.cpp.
or remoce/comment this code in configure.ac

~~or remove/comment this code in configure.ac:~~
```
AX_CHECK_COMPILE_FLAG([-mavx], [avx=true], [avx=false])
if $avx; then
    AM_CONDITIONAL([AVX_OPT], true)
fi
```

**Edit**: Do what stweil suggested. Thank you very much!

It works fine when AVX is disabled. Looks like a good reason to stop using XP completely. Great, thank you for testing. Maybe we can add a test for old Windows versions in `arch/simddetect.cpp` to handle this automatically. I don't think we should add any code to support OSes that are >10 years old and even not supported by their vendors anymore. Nevertheless, I think what we should do is to add an option to disable **all** the simd  compile-time & runtime checking. In any case, I applied attached patch to my working copy.

[tesseract-20170412-disable-avx-for-win-xp.txt](https://github.com/tesseract-ocr/tesseract/files/916510/tesseract-20170412-disable-avx-for-win-xp.txt)

It automatically disables AVX for XP and older OSes.
Maybe it would come in handy to someone. It seems the current 4.00alpha version would also crash in Windows 10 running on an old i7 CPU, which probably does not have AVX or SSE support. The patch may fix that. I may try it out when I get a chance. >It seems the current 4.00alpha version would crash in Windows 10 running on an old i7 CPU also.

I don't think so.

>I may try it out when I get a chance.

Let us know :) > Great, thank you for testing. Maybe we can add a test for old Windows versions in arch/simddetect.cpp to handle this automatically.

This is also going to come handy for whenever tesseract will make use of AVX-512 (which brings in another new architectural state), which is [only](http://support.sisoftware.net/knowledgebase.php?article=70) going to be supported on W10
(not sure if already, or in a future version - in the latter case that would be another point for this check)

EDIT: for the records, AVX is also not supported on Vista and 7 RTM
EDIT2: [some](https://software.intel.com/en-us/articles/introduction-to-intel-advanced-vector-extensions) [possible](https://software.intel.com/en-us/blogs/2011/04/14/is-avx-enabled) [code](https://gist.github.com/hi2p-perim/7855506) [snippets](https://software.intel.com/en-us/articles/how-to-detect-knl-instruction-support)
EDIT3: [also](https://bugzilla.mozilla.org/show_bug.cgi?id=1110570) I think you posted in the wrong thread.. But he reached the right person. :-)  Hi,I have given a skewed image as input to Tesseract-ocr.
The plain text output generated de-skews the image and is giving the correct output.
But in hocr output, the bounding box coordinates of the words are with respect to the original skewed image.
So,Is there any way to get the coordinates of the words of image which is deskewed by the tesseract or can we get hold of deskewed image itself?
Thank you.  i use this proj in fragmet and i want to capture pic at portrait state but surface show pic with 90d and long .also half of  viewfider goes out of my screen . what should i do ?
thanks 
best wishes  Is there an easy way to find the coordinates for specific data that we are trying to harvest?  We have 2 areas of interest that we are trying to read.   So far the best option that I've found is trial and error.  Hoping there is a sample project to draw the area  on a scanned image or some other good way.

Any help would be appreciated. have you looked at
`hocr`
and
`tsv` 
output formats?

see https://github.com/tesseract-ocr/tesseract/wiki/Command-Line-Usage

and

https://github.com/tesseract-ocr/tesseract/wiki/ViewerDebugging

  frustrated. Why is open source always so sloppy when it comes to stuff like this? 
How does one build tess for Windows? The 2 lines for "how to build", which is basically finding and installing cppan, and running it, is not sufficient instructions by far. So how do you guys expect somebody to want to use this software if they have to spend a weekend trying to figure out how to get it to build? How about some serious steps of how to build it on windows, this time? Do I use a developer command prompt? Do I need cmake? Do I need mingw installed? What, exactly, are the steps? What are some of the common failure issues? A complete release includes complete how to build and how to install instructions.
 If you just want to use Tesseract for Windows, I suggest using one of the binaries which already exist.

The [Tesseract wiki](https://github.com/tesseract-ocr/tesseract/wiki/Compiling) has more than two lines of documentation on building for Windows, and you are free to improve it. Pull requests to enhance the documentation which is provided with the source code are also possible and welcome.

I think the first problem is that there are several ways how it can be done. You have the choice of using either cmake or autoconf. It's possible to build with gcc, clang or MSVC. And you can use MSYS2, Mingw-w64 or CYGWIN. You can even cross compile on a Linux machine. Finally, you have to decide whether you want 32 or 64 bit binaries.

Personally I use cross compilation on Linux because compilation on Linux is much faster than on Windows.
As soon as you have installed all prerequisites, building becomes easy. I use autoconf:

    # Run autogen.sh once
    # (and after updates of your sources or your autoconf installation).
    ./autogen.sh
    # The remaining commands not only work from the root of the Tesseract source tree
    # but also from any directory.
    # This is useful if you want to build different kinds of binaries
    # (32 / 64 bit, debug and release code, ...).
    # Just adapt the `configure` command to your needs.
    ./configure --host=i686-w64-mingw32 CXXFLAGS="-Wall -g"
    make install training-install
    make ScrollView.jar

64 bit binaries require `--host=x86_64-w64-mingw32`.
Exactly the same commands also work on CYGWIN where you can also cross build using Mingw-w64.
 >Why is open source always so sloppy when it comes to stuff like this?


:-1: 

If you have an issue with the software, just report about it. Do not insult the developers!
 > Why is open source always so sloppy when it comes to stuff like this?

@erichfrazer, I see from your GitHub profile that you are working for a software company in Redmond? Then please help us improving the documentation. oh sure, easy to bash my company. When I release software to consumers in the form of SDKs or code that is visible to the public, you can be damned sure I have to document the heck out of it and ensure it at least compiles. This tesseract stuff has taken me days to compile, not hours or minutes. The thing is, it's so easy (in the end) to simply write an actual Visual Studio makefile and then get the whole thing to compile. But no, everybody has to try and go as far as possible to avoid The Big Bad Company, using mingw, cppan, msys2, cmake, blah de blah de blah, and none of that shit works well or is obvious, and none of it allows you to compile w/o having a degree in college-kid Linux.

SOMEBODY should write some VS2015 compatible vcxprojs and make them so they glob in place right in the middle of the tesseract / leptonica / whatever enlistments, and allows you to compile the darned thing.

Even cmake is silly that you can't target a bunch of different processor type and release mode builds all at the same time. I want to build x64, win32, release AND debug. This is not easy, and is very error prone trying to get this done with cmake.

Not as angry, because I got it to compile, but still cranky.
 >But no, everybody has to try and go as far as possible to avoid The Big Bad Company, using mingw, cppan, msys2, **cmake**, blah de blah de blah....

I have news for you. Microsoft officially supports CMake these days.
https://blogs.msdn.microsoft.com/vcblog/2016/10/05/cmake-support-in-visual-studio/

They also released this tool which also works with CMake
https://github.com/Microsoft/vcpkg

https://blogs.msdn.microsoft.com/vcblog/2016/09/19/vcpkg-a-tool-to-acquire-and-build-c-open-source-libraries-on-windows/

Maybe you can be more constructive and add support for Tesseract to the vcpkg repo?
https://github.com/Microsoft/vcpkg/issues/465
 I'm not the one releasing the software!! Why don't you come debug my Traffic App? It was nice talking with you... First Thanks for Tesseract team for great work
Building form source for Windows using visual studio is not straight forward as described in tutorial
it failed to run VS2010 and succeeded in VS2015 but the generated files can't run in my machine.

most of VS developers like me not familiar with cross platform tools , i just want ask , would you create something like OpenCV? , it's just one zipped file  contain all what you need to build including the dependencies , GUI Cmake just used to select src path, dst pat and target Developing IDE  then build.

Is the previous scenario can be achieved ? 

 Hi @essamzaky,

Just to let you (and others who will read this comment) know, the build scripts are maintained mostly by a very small community team. For the VS/CMake build, there is only one man that works on it currently (not me) in his spare time.

@egorpugin, do you have any comment?  >it failed to run VS2010 

Copied from another issue:

>Does Tesseract 4.0 built with CMake supports VS2010 or not?

egorpugin commented

>No. Not out of the box.
>
>One needs fixing some bugs in tiff library that comes from cppan.
Or there's always manual way of including dependencies. In this case VS2010 might work.
>
>With cppan VS2015 and VS2017 are only supported. Perhaps links to the old tutorials (external) for building with vs2008,
2010 etc should be removed from wikim

- excuse the brevity, sent from mobile

On 04-Apr-2017 3:17 AM, "Amit D." <notifications@github.com> wrote:

> it failed to run VS2010
>
> Copied from another issue:
>
> Does Tesseract 4.0 built with CMake supports VS2010 or not?
>
> egorpugin commented
>
> No. Not out of the box.
>
> One needs fixing some bugs in tiff library that comes from cppan.
> Or there's always manual way of including dependencies. In this case
> VS2010 might work.
>
> With cppan VS2015 and VS2017 are only supported.
>
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/799#issuecomment-291284024>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o5WMpnkwRSn2VUrDhcfehOUzYM7Dks5rsWj7gaJpZM4Mwrg4>
> .
>
 @Shreeshrii  Building from source using manual way might work for VS2010 , VS2008 as egorpugin commented
so if there is someone succeeded to build using manual way , it's better to describe how to use the manual way.
i succeeded to build most of dependence in my spare time i will back and build the rest of the solution and write about  my trial to build using the manual way.

  I had problems myself and finally decide to do it the hardway. I do not see why this needs to re-invented. Hence I have provided a complete solution kit along with binaries for Windows. Solution kit is made for Visual Studio 2015. Please check the link below and do replicate this, so we do not have this as an issue anymore.
https://github.com/vdevan/TesseractTrainingTools See also:
https://github.com/peirick/VS2015_Tesseract Yes I have added his link as well. Main difference is I have provided 
the training tools which was not there on the Peirick's link

‡Æé‡Æ©‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡ÆÖ‡Æ©‡Øç‡Æ™‡ØÅ‡Æü‡Æ©‡Øç
‡Æµ‡Ææ‡Æö‡ØÅ
‡ÆÖ‡Æ©‡Øç‡Æ™‡Øà‡Æ§‡Øç ‡Æ§‡Æµ‡Æø‡Æ∞ ‡Æµ‡Øá‡Æ±‡ØÅ ‡Æí‡Æ©‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æµ‡Øá‡Æ£‡Øç‡Æü‡Øá‡Æ©‡Øç ‡Æ™‡Æ∞‡Ææ‡Æ™‡Æ∞‡ÆÆ‡Øá!


Always lovingly
Vasu Devan V.
God give me strength to love everyone.
http://www.kamban.com.au
http://brahas.com

On 6/04/2017 8:19 PM, Amit D. wrote:
>
> See also:
> https://github.com/peirick/VS2015_Tesseract
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub 
> <https://github.com/tesseract-ocr/tesseract/issues/799#issuecomment-292131222>, 
> or mute the thread 
> <https://github.com/notifications/unsubscribe-auth/ASo5MXiz7PeBFkxMrJZPsV7OuMcs5A2wks5rtLwwgaJpZM4Mwrg4>.
>

 Thanks for useful links, hope to update it soon for tesseract 4.0 Hi @egorpugin 
Finally i run the cppan today with build the VS2015 and it's working, i did the following steps 
delete the following folders "C:\Users\emz\tesseract" , "C:\Users\emz.cppan".
launch cmd from run and execute the following:
git clone https://github.com/tesseract-ocr/tesseract.git
cd tesseract
cppan
mkdir build
cd build
cmake .. -G "Visual Studio 14 2015" -DCPPAN_USE_CACHE=0

Thanks egor
 @essamzaky -> Thank you very much! The information provided in [wiki](https://github.com/tesseract-ocr/tesseract/wiki/Compiling) did not worked for me, bu this worked. Why don't you change the wiki?

For x64 this worked for me:
cd tesseract
cppan
mkdir build_x64
cd build_x64
cmake .. -G "Visual Studio 14 2015 Win64" -DCPPAN_USE_CACHE=0  The review of API/ABI changes for Tesseract since 3.00 version: https://abi-laboratory.pro/tracker/timeline/tesseract/

Hope it will be helpful for users and maintainers of the library.

Created with the help of open-source abi-tracker tool: https://github.com/lvc/abi-tracker

The tool checks _all_ API symbols declared in header files (doesn't take docs into account), so there may be some false positives.

Thank you.

![tesseract-1](https://cloud.githubusercontent.com/assets/1517837/24391131/5b074572-139e-11e7-89c2-d98ca1e67dc2.png)

![tesseract-2](https://cloud.githubusercontent.com/assets/1517837/24391366/b84779ea-139f-11e7-804e-f6ec094b4225.png)


## Environment
* Linux x86_64
* GCC 4.9
* Tesseract 3.00 and higher
 To take attention of library developers on the results first.

Thank you. @lvc Thanks! I have added info to the documentation wiki at

https://github.com/tesseract-ocr/tesseract/wiki/Documentation @lvc,
Thanks for the info.

3.01 and 3.03 are missing from the report. 

The bottom line is that we break the ABI in almost every release. @lvc,
FYI, since 3.02 there is an "--enable-visibility" option for the configure script. @amitdo,

> 3.01 and 3.03 are missing from the report

Added 3.01 and 3.03 versions to the report: https://abi-laboratory.pro/tracker/timeline/tesseract/

Thank you.

![tesseract-4](https://cloud.githubusercontent.com/assets/1517837/24453656/d431e726-1499-11e7-9f4c-c6fed0aff533.png)

 @Shreeshrii,

Done: https://abi-laboratory.pro/tracker/timeline/tesseract/

Please let me know when it should be switched to 3.06 or 4.0.

![tesseract-5](https://cloud.githubusercontent.com/assets/1517837/25801811/724dac08-3400-11e7-9af3-ff379784aeaf.png)
  I added  -eval_listfile /home/shree/tesstutorial/hineval/tmp.txt \ to my lstmtraining command once it had come down to less than 3%char error. 

While training is continuing, I am getting messages saying 'Deserialize Failed',
 Lines with error:

```
At iteration 23765/35800/35801, 
Mean rms=0.111%, delta=0.79%, char train=2.554%, word train=14.083%, skip ratio=0%,  
wrote checkpoint.

2 Percent improvement time=15025, best error was 4.481 @ 8791
Warning: LSTMTrainer deserialized an LSTMRecognizer!
At iteration 23816/35900/35901, 
Mean rms=0.11%, delta=0.768%, char train=2.454%, word train=13.982%, skip ratio=0%,  
New best char error = 2.454 
Deserialize failed 
wrote best model:/home/shree/tesstutorial/hinlayer_from_hin/hinlayer2.454_23816.lstm 
wrote checkpoint.

...

Loaded 61/61 pages (1-61) of document /home/shree/tesstutorial/hineval/hin.Sahitya.exp0.lstmf
2 Percent improvement time=14846, 
best error was 4.436 @ 9020
At iteration 23866/36000/36001, 
Mean rms=0.11%, delta=0.749%, char train=2.396%, word train=14.124%, skip ratio=0%,  
New best char error = 2.396
Previous test incomplete, skipping test at iteration23816 
wrote checkpoint.

...

At iteration 23914/36100/36101, 
Mean rms=0.11%, delta=0.747%, char train=2.41%, word train=14.399%, skip ratio=0%,  
New worst char error = 2.41
At iteration 23618, stage 1, 
Eval Char error rate=1.8365727, Word error rate=7.0471499 wrote checkpoint.

...


At iteration 24320/36900/36901, 
Mean rms=0.109%, delta=0.745%, char train=2.454%, word train=14.204%, skip ratio=0%,  
New worst char error = 2.454
Deserialize failed wrote checkpoint.

...

2 Percent improvement time=15369, 
best error was 4.329 @ 9223
At iteration 24592/37400/37401, 
Mean rms=0.108%, delta=0.737%, char train=2.298%, word train=13.478%, skip ratio=0%,  
New best char error = 2.298 
wrote best model:/home/shree/tesstutorial/hinlayer_from_hin/hinlayer2.298_24592.lstm wrote checkpoint.
```



 Maybe, I don't know. First I have to reproduce this. `~/tesstutorial/bihnewlayer` is needed, too. I had to fix the path in `~/tesstutorial/bihtest/bih.training_files.txt`, but now `lstmtraining` works, and there seem to be no errors. Tested with debug version based on latest git master. Yes, I changed both files to match my home directory. Is this issue still present with the latest code?  Hello,
I installed tesseract and tested it , it gives correct result for english.
But i have to extract Arabic text for which i download ara.traineddata and its related files from here
https://github.com/tesseract-ocr/tesseract/wiki/Data-Files#data-files-for-version-400
then i tried a jpeg image and got its output on a text file. then it retrieves arabic txt but not proper result
 
   

ÿ¨ŸáŸÖÿ© # ŸÉ ÿ≥Ÿà-ÿ©

. ÿ∏ÿ±ÿ≥ÿ∏ÿ© ÿπŸáŸàÿØ

Ÿ°ÿµŸä ÿ≥ÿπÿØ ÿ•ŸÑÿßÿ° . ÿ≥ŸÑÿπÿ©-ÿß
. ÿ≥ÿØŸÑÿπÿØÿ≥ÿ≥ŸÑÿπŸÑŸâŸàÿ≥
Ÿàÿß{ ŸÇŸÑŸÑÿß{ Ÿßÿ™ŸÑÿß Ÿ£ÿ™ÿßÿ™ÿπŸ® ÿßŸÇ ÿ®ÿß ŸÑÿ•ÿ™¬´ÿßÿ≠¬ª . ÿ≥ÿß ŸÖŸä ÿ∂ÿ¨ÿ© ÿØÿ©ÿ≥ÿ°ÿπ ÿπÿ∏ŸÉ
¬´ŸÇŸÑŸÖ¬´ÿ©Ÿßÿ≠ŸÑÿß Ÿà Ÿà¬´ÿ™ÿπŸáÿßŸÇ ÿ®Ÿä ÿ¶ÿ™¬ªÿ≠Ÿá ŸÑÿ©

and there is not such words in this image

![image](https://cloud.githubusercontent.com/assets/26489735/24331095/f0b66784-1235-11e7-8a8b-95fe47773304.png)

and when i used -l ara+eng parameter then out says no best words !! and tesseract stoped working.
whats the problem here ?
![image](https://cloud.githubusercontent.com/assets/26489735/24331107/77529920-1236-11e7-9413-f12c8f26a45a.png)
 so please tell me whom can i ask to guide me about this issue ? How he made all those old comments from me, zdenko and others reappear here?

Really weird. Arabic is not fully accurate with 4.0. there are already open issues
regarding same. You will have to wait for new training by Ray for
improvement.

- excuse the brevity, sent from mobile

On 26-Mar-2017 5:40 PM, "waleedraza786" <notifications@github.com> wrote:

> Hello,
> I installed tesseract and tested it , it gives correct result for english.
> But i have to extract Arabic text for which i download ara.traineddata and
> its related files from here
> https://github.com/tesseract-ocr/tesseract/wiki/Data-Files#
> data-files-for-version-400
> then i tried a jpeg image and got its output on a text file. then it
> retrieves arabic txt but not proper result
>
> ÿ®ÿ≥ÿ¶ÿπ ÿßŸÑŸÖŸÑŸÑ ÿßŸÑÿ¶ŸÖŸÜÿ¶ŸÜ ÿßŸÑÿ™ŸÑÿ´ŸäŸÖ ÿßŸÜŸäŸÜŸÉ ÿ´ŸÑŸÖ ŸÜÿ®ŸäŸÜÿß ÿßÿ£ÿ∫ÿßŸÑŸàŸäÿπ ÿßŸÑÿ¶ŸÖŸÜÿ¶ÿ±.Ÿä ÿßŸÑÿ¶ÿ£ÿ™ÿ≠ŸäŸÖ
> ÿ™ÿßŸÑŸÑÿÆ ÿ™ÿ§ŸÖ ÿßŸÑŸÑÿ™ŸäŸÜ ÿ•ŸÜŸÖÿ´ÿßŸÑÿ™ÿ±ŸÑŸÜŸÜŸÖŸáŸÜŸÜ . ŸÜÿ™Ÿäÿ¶ŸÖŸÖŸÜÿ≤ÿ•ŸÜŸÖÿ¶ÿßŸÑÿ™ÿ±ŸÜŸÜÿ¶ŸÜÿ¨Ÿäÿ£ ÿßŸÑŸáŸÑÿπ
> ŸÜŸÑÿ¨ŸÖÿ™ÿßÿßŸÑÿπŸÜŸÜŸÜÿßŸÑÿ∞
>
> ÿßÿ£ ÿ∑ ŸáŸÜŸä Ÿäÿ≤ÿµÿ®ŸÜÿßŸÑÿ± ÿßŸÜŸÑŸÑÿ±ŸäŸäŸ†ÿ≤ ŸÑÿ≤ŸÜÿ∫ŸÜŸÖŸäÿ≤ ÿ∫ŸÜŸÜŸáŸÖÿ© ÿ∫ŸÜÿ±ÿßŸÑÿ™ŸÜÿ∑ŸÜŸàŸäŸä ÿ∫ŸÜŸÜŸáŸÖ
> ÿ´ŸÑÿ¢ ÿßŸÑŸäŸÜŸÜŸÜÿßŸÑŸÜŸäÿ™Ÿâ ÿßŸÑŸÖ ÿ¶ŸÑŸÑÿ≤ ÿßŸÑŸÜŸáŸÜÿßÿ±ŸÜ ŸÑÿß ŸÜŸÖŸÜŸÖŸÖÿ© ŸÅŸäŸà ŸÜŸÑÿ•Ÿâ Ÿäÿ£ÿ¶ŸÑÿ™ŸÖÿ®Ÿäÿ™Ÿâ ÿßŸÜŸÑŸÑÿ±ŸäŸäŸ†ÿ≤
>
> ÿ≠ŸÖŸÖ ÿ∑ŸáŸá ÿ∑ ŸÜŸÉ ÿ≠ŸÖŸÖ ÿ≠ŸÖŸÖ
>
> ŸÜŸÑŸÖÿ∂ŸàŸÑÿ• ÿ®ÿßÿ£ÿ∫ŸÜŸÖŸä ÿ≤ŸÜŸÇÿ®ŸäŸÜŸàŸÑÿ• ÿßŸÑÿπÿ´ŸÑÿßÿ´ ÿ®ŸÜŸäŸÜÿß{ ŸÜŸäÿ±ŸÖÿßŸÑÿß/ÿ™ŸÜŸÖ ŸÜŸÜŸáŸäŸÜŸàŸÑÿ• ÿ≤ÿ≥ÿßŸÑŸÑŸàŸäŸäÿ≤
>
> ŸÜŸÇŸäÿ®ÿ© ÿ≤ŸäŸÜŸâ ÿ£ ŸÑÿ´ÿ∑ŸÜÿßŸÑŸäÿ®ÿ®ŸÖ ÿπÿ≤ÿ™ŸÜÿ™ÿßÿ≤Ÿäÿ£ ŸÇÿß )ÿ°Ÿá ÿ∫ÿ∞ÿßÿ±ŸÜÿ• ÿ∫ÿ∫ŸÑŸäÿ£ ÿ≤ÿ´ŸÅÿ¶Ÿâ ÿßŸÑÿ´ÿßŸÖÿ®Ÿä ÿ™ŸÑ ÿ™ŸäŸà{
>
> ŸÖÿØÿπŸà Ÿ† ÿ•ŸÑÿß ÿß ÿ¶ÿ∫ÿ≥ÿ™ŸÜŸÜŸÖ ÿ≤ÿ™ÿß ŸÖŸÜÿ±ŸÜŸÜŸÜŸÜÿ∫ŸÜŸàŸÑÿ• ŸÑŸäŸÜŸÜÿ¶ŸàŸÜŸÜŸäŸäŸÜŸÖ ŸÖÿ™ŸÜŸÖÿ∂ÿ≤ ŸÜÿ≤ŸäŸÑÿß/ŸÜÿ±ŸÜŸÖ ÿßŸÑÿ¶
> ÿ™ŸÜÿ∑ŸÜÿß
>
> ÿ≤ŸÑÿ¶ŸÜ ÿ∫ÿ∞ÿßÿ±ÿåŸÜÿ• ÿ£ŸÑŸäŸÇ ŸäŸÖŸÜÿßÿ≥ŸÇÿßŸÑŸàÿß ŸÖŸÜŸÜÿ´ŸäÿØŸÜŸàŸÜ ÿ≤ŸÑŸÜÿß ŸÇŸäŸÑ ŸÜŸÖŸÜŸÖ ŸÑÿß ŸÜÿ∫ŸäŸÜŸÖŸÜŸàÿßŸä
> ŸäŸÜÿßÿ¶ŸäŸáÿ§ŸÇŸÑŸä
>
> and there is not such words in this image
>
> [image: image]
> <https://cloud.githubusercontent.com/assets/26489735/24331095/f0b66784-1235-11e7-8a8b-95fe47773304.png>
>
> and when i used -l ara+eng parameter then out says no best words !! and
> tesseract stoped working.
> whats the problem here ?
> ------------------------------
> You can view, comment on, or merge this pull request online at:
>
>   https://github.com/tesseract-ocr/tesseract/pull/791
> Commit Summary
>
>    - opencl: Fix wrong implementation of function
>    getNumDeviceWithEmptyScore
>    - opencl: Add missing argument for L_WARNING
>    - opencl: Remove unused function getNumDeviceWithEmptyScore
>    - Fix crash caused by undefined value of local variable
>    - allow combination of enable/disable
>    - opencl: Fix type of parameter for clGetContextInfo
>    - opencl: Fix type of parameter for clGetProgramInfo
>    - backport from 4.00: issue #242 - different results when same image
>    is lossless-encoded at different bpp
>    - training: Fix compiler warnings (deprecated register keyword)
>    - add option "make training-uninstall"
>    - Fix a typo in tesseract(1) man page
>    - Fix typo in documentation
>    - opencl: Fix typo in name of local variable
>    - ccutil/ambigs: Optimize tesseract::UnicharIdArrayUtils::compare
>    - Fixed failed merge of memory leak
>    - Fix compiler warning (-Wmaybe-uninitialized)
>    - AUTHORS - Add community contributors
>    - Increase version number in VS2010 and fix year
>    - backport from 4.00: add missing License information
>    - downgrade to leptonica 1.73
>    - backport style changes from 4.00 for better identification of fixes
>    and new code
>    - backport style changes from 4.00 for better identification of fixes
>    and new code
>    - Merge branch '3.05' of https://github.com/tesseract-ocr/tesseract
>    into 3.05
>    - add license info to autogen.sh
>    - revert TessHashMap to hash_map in training/stringrenderer.h from
>    90651e1 (to fix build)
>    - AUTHORS: Add more contributors
>    - use leptonica from master git repository (1.74)
>    - Missing pdf font file from previous sync
>    - Fixed the memory leak/double free cleanly
>    - fix code style
>    - backport from 4.00: show PSM 11-13
>    - backport from 4.00: fix pdfrenderer
>    - add License info to cmake files
>    - increase GENERIC_MINOR_VERSION
>    - backport from 4.00: changes in scrollviewer
>    - backport from 4.00: fix of destroy_nodes (oldlist.cpp)
>    - backport from 4.00: changes in cube
>    - style fix
>    - backport from 4.00: changes in wordrec + FakeWordFromRatings
>    - backport from 4.00: use "const TBOX&" instead of "TBOX box" in
>    textord
>    - backport from 4.00: use ".empty()" instead of ".size() > 0"
>    - backport from 4.00: changes in textord
>    - backport from 4.00: changes in Android.mk
>    - backport from 4.00: changes in classify
>    - backport from 4.00: changes from ccstruct excluding imagedata
>    - backport from 4.00: SkipDeSerialize and changes in ccutil
>    - use TessHashMap instead of hash_map, unordered_map
>    - backport from 4.00: enable selection of OCR engine mode from command
>    line
>    - backport from 4.00: split Dict::Load to SetupForLoad, Load and
>    FinishLoad
>    - backport from 4.00: code improvements
>    - backport from 4.00: api changes
>    - Merge branch '3.05' of https://github.com/tesseract-ocr/tesseract
>    into 3.05
>    - backport from 4.00: training shell scripts
>    - change VS2010 lib project name
>    - backport from 4.00: training
>    - backport from 4.00: imagedata
>    - opencl: Clean whitespace issues in OpenCL kernel code
>    - opencl: Format OpenCL kernel code
>    - opencl: Fix OpenCL kernel code assertion for newer versions
>    - Simplify calls of free
>    - Simplify delete operations
>    - Missing pdf font file from previous sync
>    - Fixed the memory leak/double free cleanly
>    - Fix build for Mingw-w64 (120a5dbdab78) and non C++11 build (VS2010)
>    - mingw-w64: Fix compiler warnings caused by macro redefinition
>    - cube: Simplify delete operations
>    - cube/char_bigrams: Fix some memory leaks
>    - cube/char_samp: Fix some memory leaks
>    - Correcting link for 3rd party wiki pages
>    - Formatting changes from clang_tidy on latest pull
>    - Added std:: to vector
>    - cube: Simplify new operations
>    - Simplify new operations
>    - Change tesseract parameter -oem to --oem
>    - Change tesseract parameter -psm to --psm
>    - opencl: Remove unneeded and potentially bad type casts
>    - cube: Fix use after free regression
>    - cube: Fix coverity warning caused by unneeded null pointer check
>    - opencl: Add missing checks for OpenCL failures
>    - Remove extra semicolons after member function definitions
>    - Fixed damage to binary images when processing PDFs, issue #535
>    - training: Update Makefile for current Mingw-w64
>    - doc: Fix line endings
>    - fix typo
>    - tesseract: Disable Leptonica messages
>    - Produce warning for invalid resolution. Fix #453
>    - More clang-tidy from previous commits
>    - Remove duplicate destructor
>    - Implement a new orientation and script detection API for C and C++
>    - Revise after code review
>    - Remove unused code.
>    - Remove 'listio.cpp' and 'listio.h' from vs2010 vcxproj
>    - Fix two typos in comments
>    - java: Improve build rules
>    - openmp: Fix OpenMP support
>    - Merge pull request #564 from stweil/3.05
>    - increase min autoconf version (2.59)
>    - require leptonica 1.74 or higher
>    - Multi-page TIFF buffering is broken - fix #233
>    - fix removal of AC_CHECK_LIB([lept])
>    - remove (fake) OPENMP support
>    - Update cppan.yml
>    - leptonica 1.74.1 is needed for cppan
>    - fix #665 process file list
>    - fix appveyor
>    - fix #712: Ghostscript mangling Tesseract-produced PDFs
>    - Backport cppan fixes.
>    - Merge branch '3.05' of github.com-egorpugin:tesseract-ocr/tesseract
>    into 3.05
>    - Backport cmake fixes.
>    - Add .cppan to ignore list.
>    - 3.05.00 release
>    - 3.05.00 release
>    - Merge branch '3.05' of https://github.com/tesseract-ocr/tesseract
>    into 3.05
>    - replace nullptr with NULL to enable non c++11 build (fixes #727)
>    - Rename cppan/cmake targets.
>    - Correct reading config files with \r\n
>    - Use camel case for GitHub in README.md
>    - Fix indentation after conditional [-Wmisleading-indentation]
>    - [`autogen.sh`:] Abstract the absolute path of `libtoolize` or
>    `glibtoolize` away into `$LIBTOOLIZE`.
>    - [`autogen.sh`:] Reduce in-script comment block width to 80
>    characters.
>    - [`autogen.sh`:] Clarify `libtoolize`/`glibtoolize` existence check
>    error message.
>    - [`autogen.sh`:] Improve `libtoolize` invocation message.
>    - Add the packaging metadata to build the tesseract snap
>    - Use portable data types #709
>    - fix --disable-graphics build
>    - fix --enable-visibility build (including training tools)
>    - Fix some typos in comments (found by codespell)
>    - Update appveyor.yml
>    - Disable warnings on Appveyor.
>    - Update CMakeLists.txt
>    - libtiff is needed for windows build of tesseract executable
>    - Add item to ChangeLog for options writing to stdout instead of stderr
>    - Merge pull request #776 from cjmayo/stdoutput
>    - Update README.md heading markdown
>    - Fix windows build.
>    - Update appveyor.yml
>    - Update appveyor.yml
>    - Update appveyor.yml
>
> File Changes
>
>    - *M* .gitignore
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-0> (7)
>    - *M* AUTHORS
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-1>
>    (14)
>    - *M* CMakeLists.txt
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-2>
>    (50)
>    - *M* ChangeLog
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-3>
>    (22)
>    - *M* INSTALL.GIT.md
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-4> (2)
>    - *A* LICENSE
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-5>
>    (202)
>    - *M* Makefile.am
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-6> (3)
>    - *M* README.md
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-7>
>    (23)
>    - *M* android/jni/Android.mk
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-8> (5)
>    - *M* api/Makefile.am
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-9> (7)
>    - *M* api/baseapi.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-10>
>    (253)
>    - *M* api/baseapi.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-11>
>    (55)
>    - *M* api/capi.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-12>
>    (11)
>    - *M* api/capi.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-13>
>    (6)
>    - *M* api/pdfrenderer.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-14>
>    (24)
>    - *M* api/renderer.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-15>
>    (29)
>    - *M* api/renderer.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-16>
>    (22)
>    - *M* api/tesseractmain.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-17>
>    (198)
>    - *M* appveyor.yml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-18>
>    (40)
>    - *M* autogen.sh
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-19>
>    (28)
>    - *M* ccmain/control.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-20>
>    (19)
>    - *M* ccmain/cube_control.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-21>
>    (18)
>    - *M* ccmain/cube_reco_context.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-22>
>    (52)
>    - *M* ccmain/cubeclassifier.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-23>
>    (5)
>    - *M* ccmain/docqual.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-24>
>    (16)
>    - *M* ccmain/equationdetect.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-25>
>    (1)
>    - *M* ccmain/fixspace.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-26>
>    (5)
>    - *M* ccmain/ltrresultiterator.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-27>
>    (11)
>    - *M* ccmain/ltrresultiterator.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-28>
>    (3)
>    - *M* ccmain/osdetect.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-29>
>    (10)
>    - *M* ccmain/output.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-30>
>    (28)
>    - *M* ccmain/pageiterator.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-31>
>    (8)
>    - *M* ccmain/pagesegmain.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-32>
>    (10)
>    - *M* ccmain/par_control.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-33>
>    (4)
>    - *M* ccmain/paragraphs.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-34>
>    (12)
>    - *M* ccmain/paramsd.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-35>
>    (10)
>    - *M* ccmain/pgedit.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-36>
>    (2)
>    - *M* ccmain/reject.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-37>
>    (4)
>    - *M* ccmain/tessedit.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-38>
>    (6)
>    - *M* ccmain/tesseract_cube_combiner.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-39>
>    (2)
>    - *M* ccmain/tesseract_cube_combiner.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-40>
>    (20)
>    - *M* ccmain/tesseractclass.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-41>
>    (7)
>    - *M* ccmain/tesseractclass.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-42>
>    (31)
>    - *M* ccmain/thresholder.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-43>
>    (35)
>    - *M* ccstruct/blamer.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-44>
>    (2)
>    - *M* ccstruct/blobbox.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-45>
>    (10)
>    - *M* ccstruct/boxread.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-46>
>    (3)
>    - *M* ccstruct/boxword.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-47>
>    (4)
>    - *M* ccstruct/coutln.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-48>
>    (66)
>    - *M* ccstruct/fontinfo.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-49>
>    (2)
>    - *M* ccstruct/fontinfo.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-50>
>    (6)
>    - *M* ccstruct/hpdsizes.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-51>
>    (9)
>    - *M* ccstruct/imagedata.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-52>
>    (409)
>    - *M* ccstruct/imagedata.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-53>
>    (135)
>    - *M* ccstruct/matrix.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-54>
>    (311)
>    - *M* ccstruct/mod128.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-55>
>    (17)
>    - *M* ccstruct/mod128.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-56>
>    (5)
>    - *M* ccstruct/otsuthr.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-57>
>    (26)
>    - *M* ccstruct/pageres.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-58>
>    (7)
>    - *M* ccstruct/pageres.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-59>
>    (11)
>    - *M* ccstruct/params_training_featdef.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-60>
>    (2)
>    - *M* ccstruct/pdblock.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-61>
>    (148)
>    - *M* ccstruct/polyaprx.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-62>
>    (2)
>    - *M* ccstruct/polyblk.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-63>
>    (2)
>    - *M* ccstruct/quspline.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-64>
>    (4)
>    - *M* ccstruct/ratngs.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-65>
>    (5)
>    - *M* ccstruct/rect.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-66>
>    (12)
>    - *M* ccstruct/rect.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-67>
>    (10)
>    - *M* ccstruct/rejctmap.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-68>
>    (2)
>    - *M* ccstruct/rejctmap.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-69>
>    (61)
>    - *M* ccstruct/statistc.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-70>
>    (5)
>    - *M* ccutil/ambigs.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-71>
>    (21)
>    - *M* ccutil/bits16.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-72>
>    (8)
>    - *M* ccutil/ccutil.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-73>
>    (9)
>    - *M* ccutil/ccutil.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-74>
>    (6)
>    - *M* ccutil/clst.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-75>
>    (29)
>    - *M* ccutil/clst.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-76>
>    (288)
>    - *M* ccutil/elst.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-77>
>    (26)
>    - *M* ccutil/elst.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-78>
>    (62)
>    - *M* ccutil/elst2.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-79>
>    (26)
>    - *M* ccutil/elst2.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-80>
>    (321)
>    - *M* ccutil/errcode.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-81>
>    (9)
>    - *M* ccutil/genericheap.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-82>
>    (34)
>    - *M* ccutil/genericvector.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-83>
>    (82)
>    - *M* ccutil/globaloc.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-84>
>    (2)
>    - *M* ccutil/hashfn.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-85>
>    (30)
>    - *M* ccutil/helpers.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-86>
>    (2)
>    - *M* ccutil/lsterr.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-87>
>    (2)
>    - *M* ccutil/mainblk.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-88>
>    (2)
>    - *M* ccutil/ocrclass.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-89>
>    (40)
>    - *M* ccutil/params.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-90>
>    (5)
>    - *M* ccutil/params.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-91>
>    (4)
>    - *M* ccutil/platform.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-92>
>    (4)
>    - *M* ccutil/serialis.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-93>
>    (2)
>    - *M* ccutil/strngs.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-94>
>    (12)
>    - *M* ccutil/strngs.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-95>
>    (8)
>    - *M* ccutil/tessdatamanager.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-96>
>    (70)
>    - *M* ccutil/unicharset.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-97>
>    (13)
>    - *M* classify/adaptive.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-98>
>    (8)
>    - *M* classify/adaptmatch.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-99>
>    (7)
>    - *M* classify/classify.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-100>
>    (4)
>    - *M* classify/cluster.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-101>
>    (477)
>    - *M* classify/cluster.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-102>
>    (10)
>    - *M* classify/clusttool.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-103>
>    (43)
>    - *M* classify/clusttool.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-104>
>    (22)
>    - *M* classify/cutoffs.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-105>
>    (10)
>    - *M* classify/featdefs.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-106>
>    (14)
>    - *M* classify/featdefs.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-107>
>    (8)
>    - *M* classify/fpoint.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-108>
>    (11)
>    - *M* classify/intfeaturemap.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-109>
>    (2)
>    - *M* classify/intfeaturespace.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-110>
>    (2)
>    - *M* classify/intfx.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-111>
>    (2)
>    - *M* classify/intfx.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-112>
>    (2)
>    - *M* classify/intmatcher.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-113>
>    (26)
>    - *M* classify/intmatcher.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-114>
>    (10)
>    - *M* classify/intproto.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-115>
>    (26)
>    - *M* classify/intproto.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-116>
>    (2)
>    - *M* classify/kdtree.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-117>
>    (28)
>    - *M* classify/kdtree.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-118>
>    (2)
>    - *M* classify/mastertrainer.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-119>
>    (14)
>    - *M* classify/mastertrainer.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-120>
>    (2)
>    - *M* classify/mf.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-121>
>    (12)
>    - *M* classify/mfdefs.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-122>
>    (16)
>    - *M* classify/mfoutline.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-123>
>    (5)
>    - *M* classify/mfx.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-124>
>    (4)
>    - *M* classify/mfx.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-125>
>    (10)
>    - *M* classify/normfeat.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-126>
>    (11)
>    - *M* classify/normmatch.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-127>
>    (18)
>    - *M* classify/ocrfeatures.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-128>
>    (33)
>    - *M* classify/ocrfeatures.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-129>
>    (2)
>    - *M* classify/outfeat.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-130>
>    (14)
>    - *M* classify/picofeat.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-131>
>    (12)
>    - *M* classify/picofeat.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-132>
>    (2)
>    - *M* classify/protos.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-133>
>    (4)
>    - *M* classify/shapeclassifier.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-134>
>    (2)
>    - *M* classify/shapetable.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-135>
>    (2)
>    - *M* classify/tessclassifier.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-136>
>    (3)
>    - *M* classify/trainingsample.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-137>
>    (4)
>    - *M* classify/trainingsampleset.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-138>
>    (6)
>    - *M* cmake/BuildFunctions.cmake
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-139>
>    (9)
>    - *M* cmake/Configure.cmake
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-140>
>    (9)
>    - *M* cmake/FindICU.cmake
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-141>
>    (9)
>    - *M* cmake/SourceGroups.cmake
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-142>
>    (11)
>    - *M* configure.ac
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-143>
>    (53)
>    - *M* cppan.yml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-144>
>    (363)
>    - *M* cube/beam_search.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-145>
>    (21)
>    - *M* cube/beam_search.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-146>
>    (2)
>    - *M* cube/bmp_8.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-147>
>    (60)
>    - *M* cube/cached_file.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-148>
>    (3)
>    - *M* cube/char_altlist.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-149>
>    (7)
>    - *M* cube/char_bigrams.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-150>
>    (20)
>    - *M* cube/char_samp.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-151>
>    (47)
>    - *M* cube/char_samp.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-152>
>    (22)
>    - *M* cube/char_samp_set.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-153>
>    (14)
>    - *M* cube/char_set.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-154>
>    (18)
>    - *M* cube/classifier_base.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-155>
>    (16)
>    - *M* cube/classifier_factory.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-156>
>    (12)
>    - *M* cube/con_comp.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-157>
>    (18)
>    - *M* cube/conv_net_classifier.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-158>
>    (36)
>    - *M* cube/cube_line_object.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-159>
>    (106)
>    - *M* cube/cube_line_segmenter.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-160>
>    (6)
>    - *M* cube/cube_object.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-161>
>    (70)
>    - *M* cube/cube_search_object.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-162>
>    (42)
>    - *M* cube/cube_tuning_params.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-163>
>    (5)
>    - *M* cube/cube_utils.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-164>
>    (14)
>    - *M* cube/hybrid_neural_net_classifier.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-165>
>    (25)
>    - *M* cube/search_column.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-166>
>    (14)
>    - *M* cube/search_node.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-167>
>    (3)
>    - *M* cube/tess_lang_mod_edge.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-168>
>    (6)
>    - *M* cube/tess_lang_model.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-169>
>    (21)
>    - *M* cube/word_altlist.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-170>
>    (8)
>    - *M* cube/word_list_lang_model.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-171>
>    (6)
>    - *M* cube/word_size_model.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-172>
>    (15)
>    - *M* cube/word_unigrams.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-173>
>    (21)
>    - *M* cutil/Makefile.am
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-174>
>    (4)
>    - *M* cutil/bitvec.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-175>
>    (42)
>    - *M* cutil/cutil.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-176>
>    (20)
>    - *M* cutil/danerror.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-177>
>    (10)
>    - *M* cutil/efio.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-178>
>    (12)
>    - *M* cutil/emalloc.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-179>
>    (2)
>    - *D* cutil/listio.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-180>
>    (67)
>    - *D* cutil/listio.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-181>
>    (43)
>    - *M* cutil/oldlist.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-182>
>    (5)
>    - *M* dict/context.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-183>
>    (38)
>    - *M* dict/dawg.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-184>
>    (19)
>    - *M* dict/dict.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-185>
>    (120)
>    - *M* dict/dict.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-186>
>    (32)
>    - *M* dict/stopper.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-187>
>    (11)
>    - *M* dict/stopper.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-188>
>    (10)
>    - *M* dict/trie.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-189>
>    (1)
>    - *M* doc/ambiguous_words.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-190>
>    (1580)
>    - *M* doc/ambiguous_words.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-191>
>    (86)
>    - *M* doc/cntraining.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-192>
>    (1610)
>    - *M* doc/cntraining.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-193>
>    (116)
>    - *M* doc/combine_tessdata.1.asc
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-194>
>    (2)
>    - *M* doc/combine_tessdata.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-195>
>    (2028)
>    - *M* doc/combine_tessdata.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-196>
>    (562)
>    - *M* doc/dawg2wordlist.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-197>
>    (1604)
>    - *M* doc/dawg2wordlist.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-198>
>    (106)
>    - *M* doc/mftraining.1.asc
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-199>
>    (4)
>    - *M* doc/mftraining.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-200>
>    (0)
>    - *M* doc/mftraining.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-201>
>    (0)
>    - *M* doc/shapeclustering.1.asc
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-202>
>    (0)
>    - *M* doc/shapeclustering.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-203>
>    (0)
>    - *M* doc/shapeclustering.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-204>
>    (0)
>    - *M* doc/tesseract.1
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-205>
>    (0)
>    - *M* doc/tesseract.1.asc
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-206>
>    (0)
>    - *M* doc/tesseract.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-207>
>    (0)
>    - *M* doc/tesseract.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-208>
>    (0)
>    - *M* doc/unicharambigs.5.asc
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-209>
>    (0)
>    - *M* doc/unicharambigs.5.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-210>
>    (0)
>    - *M* doc/unicharambigs.5.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-211>
>    (0)
>    - *M* doc/unicharset.5.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-212>
>    (0)
>    - *M* doc/unicharset.5.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-213>
>    (0)
>    - *M* doc/unicharset_extractor.1.asc
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-214>
>    (0)
>    - *M* doc/unicharset_extractor.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-215>
>    (0)
>    - *M* doc/unicharset_extractor.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-216>
>    (0)
>    - *M* doc/wordlist2dawg.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-217>
>    (0)
>    - *M* doc/wordlist2dawg.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-218>
>    (0)
>    - *M* java/Makefile.am
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-219>
>    (0)
>    - *M* neural_networks/runtime/input_file_buffer.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-220>
>    (0)
>    - *M* neural_networks/runtime/input_file_buffer.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-221>
>    (0)
>    - *M* neural_networks/runtime/neural_net.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-222>
>    (0)
>    - *M* neural_networks/runtime/neural_net.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-223>
>    (0)
>    - *M* neural_networks/runtime/neuron.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-224>
>    (0)
>    - *M* neural_networks/runtime/neuron.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-225>
>    (0)
>    - *M* neural_networks/runtime/sigmoid_table.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-226>
>    (0)
>    - *M* opencl/oclkernels.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-227>
>    (0)
>    - *M* opencl/opencl_device_selection.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-228>
>    (0)
>    - *M* opencl/openclwrapper.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-229>
>    (0)
>    - *M* opencl/openclwrapper.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-230>
>    (0)
>    - *M* snap/snapcraft.yaml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-231>
>    (0)
>    - *M* tessdata/configs/box.train.stderr
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-232>
>    (0)
>    - *M* tessdata/pdf.ttf
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-233>
>    (0)
>    - *M* testing/reorgdata.sh
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-234>
>    (0)
>    - *M* testing/runtestset.sh
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-235>
>    (0)
>    - *M* textord/alignedblob.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-236>
>    (0)
>    - *M* textord/baselinedetect.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-237>
>    (0)
>    - *M* textord/bbgrid.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-238>
>    (0)
>    - *M* textord/bbgrid.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-239>
>    (0)
>    - *M* textord/blkocc.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-240>
>    (0)
>    - *M* textord/ccnontextdetect.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-241>
>    (0)
>    - *M* textord/colpartition.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-242>
>    (0)
>    - *M* textord/colpartition.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-243>
>    (0)
>    - *M* textord/colpartitiongrid.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-244>
>    (0)
>    - *M* textord/devanagari_processing.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-245>
>    (0)
>    - *M* textord/drawedg.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-246>
>    (0)
>    - *M* textord/fpchop.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-247>
>    (0)
>    - *M* textord/gap_map.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-248>
>    (0)
>    - *M* textord/gap_map.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-249>
>    (0)
>    - *M* textord/imagefind.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-250>
>    (0)
>    - *M* textord/makerow.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-251>
>    (0)
>    - *M* textord/oldbasel.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-252>
>    (0)
>    - *M* textord/pithsync.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-253>
>    (0)
>    - *M* textord/pitsync1.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-254>
>    (0)
>    - *M* textord/scanedg.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-255>
>    (0)
>    - *M* textord/strokewidth.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-256>
>    (0)
>    - *M* textord/tabfind.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-257>
>    (0)
>    - *M* textord/tablefind.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-258>
>    (0)
>    - *M* textord/tabvector.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-259>
>    (0)
>    - *M* textord/textlineprojection.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-260>
>    (0)
>    - *M* textord/textord.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-261>
>    (0)
>    - *M* textord/topitch.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-262>
>    (0)
>    - *M* textord/tordmain.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-263>
>    (0)
>    - *M* textord/tospace.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-264>
>    (0)
>    - *M* textord/tovars.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-265>
>    (0)
>    - *M* textord/tovars.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-266>
>    (0)
>    - *M* training/CMakeLists.txt
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-267>
>    (0)
>    - *M* training/Makefile.am
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-268>
>    (0)
>    - *M* training/boxchar.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-269>
>    (0)
>    - *M* training/boxchar.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-270>
>    (0)
>    - *M* training/classifier_tester.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-271>
>    (0)
>    - *M* training/cntraining.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-272>
>    (0)
>    - *M* training/commandlineflags.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-273>
>    (0)
>    - *M* training/commontraining.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-274>
>    (0)
>    - *M* training/degradeimage.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-275>
>    (0)
>    - *M* training/degradeimage.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-276>
>    (0)
>    - *M* training/fileio.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-277>
>    (0)
>    - *M* training/language-specific.sh
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-278>
>    (0)
>    - *M* training/ligature_table.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-279>
>    (0)
>    - *M* training/mftraining.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-280>
>    (0)
>    - *M* training/normstrngs.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-281>
>    (0)
>    - *M* training/normstrngs.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-282>
>    (0)
>    - *M* training/pango_font_info.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-283>
>    (0)
>    - *M* training/pango_font_info.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-284>
>    (0)
>    - *M* training/set_unicharset_properties.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-285>
>    (0)
>    - *M* training/stringrenderer.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-286>
>    (0)
>    - *M* training/stringrenderer.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-287>
>    (0)
>    - *M* training/tesstrain_utils.sh
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-288>
>    (0)
>    - *M* training/text2image.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-289>
>    (0)
>    - *M* training/unicharset_training_utils.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-290>
>    (0)
>    - *M* training/unicharset_training_utils.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-291>
>    (0)
>    - *M* viewer/scrollview.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-292>
>    (0)
>    - *M* viewer/scrollview.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-293>
>    (0)
>    - *M* viewer/svpaint.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-294>
>    (0)
>    - *M* viewer/svutil.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-295>
>    (0)
>    - *M* viewer/svutil.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-296>
>    (0)
>    - *M* vs2010/include/tesseract_versionnumbers.props
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-297>
>    (0)
>    - *M* vs2010/libtesseract/libtesseract.rc
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-298>
>    (0)
>    - *M* vs2010/libtesseract/libtesseract.vcxproj
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-299>
>    (0)
>
> Patch Links:
>
>    - https://github.com/tesseract-ocr/tesseract/pull/791.patch
>    - https://github.com/tesseract-ocr/tesseract/pull/791.diff
>
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/791>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o0YkFcK3H7aulYtY1TPQ-sVsR_Hhks5rplW1gaJpZM4MpaDd>
> .
>
  run ./autogen.sh 

Running aclocal
Running /usr/local/bin/glibtoolize
glibtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, 'config'.
glibtoolize: copying file 'config/ltmain.sh'
.libtoolize:   error: AC_CONFIG_MACRO_DIRS([m4]) conflicts with ACLOCAL_AMFLAGS=-I m4

  Something went wrong, bailing out! No feedback from the OP. I suggest to close this issue.  I think we should publish in the README the official supported compilers, including minimum version for each compiler. Something like this:

## Supported Compilers
* GCC 4.8 and above
* Clang 3.4 and above
* MSVC 2015, 2017

Other compilers might work, but are not officially supported. Clang is not tested right now with CI. Can someone fix that? I mean Clang + libc++ on Mac.

Testing Clang + libstdc++ on Linux would be nice. Thanks Egor.

Zdenko, I'll send a PR in the following days.  //Keeping 
const int kMinCharactersToTry = 5
//Since working with text extraction from vehicle number plates needs less minimum number of characters. kMaxCharactersToTry may be //modified accordingly. The algorithm is designed to work with the current minimum value. Changing that const value might break it. I suggest not to accept this PR without Ray's approval.

Sorry, @ShahrukhSatti21. Another thing, Ray said he has a better (LSTM-based) OSD module that will replace the current one. @theraysmith, I think this PR should be rejected, right? Hi,
I was a beginner and too immature to ask such a basic question that too as
an issue. Later, I dug deeper into tesseract and a ROI finding algorithm
and compiled an executable to extract characters on number plates. There's
no need to consider this PR as the algo might not stay as generic as now.
Thanks for considering anyway.
On 29 Apr 2017 03:43, "theraysmith" <notifications@github.com> wrote:

> So far the new script id looks good.
> I don't understand why you would ever want to run OSD on license plates?
> It makes no sense.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/788#issuecomment-298123033>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZZViU6Own-LynXcCFTY4BsPkjOgjipiks5r0muOgaJpZM4MoCHs>
> .
>
  I'm forking this issue from #739 because the resolution of that issue has _not_ helped me fix Homebrew/homebrew-core#10380.  As logged [here](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/blob/master/Tesseract/v3.05.00/Third%20Attempt/reinstall.out#L1179‚ÄìL1311), my latest build attempt fails as follows:  

```
‚ãÆ
/bin/sh ../libtool  --tag=CXX   --mode=link clang++  -g -O2 -std=c++11 -version-info 3:5 -no-undefined  -L/usr/local/opt/icu4c/lib -o libtesseract.la -rpath /usr/local/Cellar/tesseract/3.05.00/lib  libtesseract_api.la ../ccmain/libtesseract_main.la ../textord/libtesseract_textord.la ../wordrec/libtesseract_wordrec.la ../classify/libtesseract_classify.la ../dict/libtesseract_dict.la ../ccstruct/libtesseract_ccstruct.la ../cutil/libtesseract_cutil.la ../viewer/libtesseract_viewer.la ../ccutil/libtesseract_ccutil.la ../opencl/libtesseract_opencl.la ../cube/libtesseract_cube.la ../neural_networks/runtime/libtesseract_neural.la -llept 
libtool: link: clang++ -dynamiclib  -o .libs/libtesseract.3.dylib   -Wl,-force_load,./.libs/libtesseract_api.a -Wl,-force_load,../ccmain/.libs/libtesseract_main.a -Wl,-force_load,../textord/.libs/libtesseract_textord.a -Wl,-force_load,../wordrec/.libs/libtesseract_wordrec.a -Wl,-force_load,../classify/.libs/libtesseract_classify.a -Wl,-force_load,../dict/.libs/libtesseract_dict.a -Wl,-force_load,../ccstruct/.libs/libtesseract_ccstruct.a -Wl,-force_load,../cutil/.libs/libtesseract_cutil.a -Wl,-force_load,../viewer/.libs/libtesseract_viewer.a -Wl,-force_load,../ccutil/.libs/libtesseract_ccutil.a -Wl,-force_load,../opencl/.libs/libtesseract_opencl.a -Wl,-force_load,../cube/.libs/libtesseract_cube.a -Wl,-force_load,../neural_networks/runtime/.libs/libtesseract_neural.a  -L/usr/local/opt/icu4c/lib -llept  -g -O2   -install_name  /usr/local/Cellar/tesseract/3.05.00/lib/libtesseract.3.dylib -compatibility_version 4 -current_version 4.5 -Wl,-single_module
Undefined symbols for architecture x86_64:
  "_TIFFCleanup", referenced from:
      OpenclDevice::pixReadStreamTiffCl(__sFILE*, int) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadMemTiffCl(unsigned char const*, unsigned long, int) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFClientOpen", referenced from:
      OpenclDevice::pixReadMemTiffCl(unsigned char const*, unsigned long, int) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFFdOpen", referenced from:
      OpenclDevice::fopenTiffCl(__sFILE*, char const*) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFGetField", referenced from:
      OpenclDevice::getTiffStreamResolutionCl(tiff*, int*, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadFromTiffStreamCl(tiff*) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFGetFieldDefaulted", referenced from:
      OpenclDevice::getTiffStreamResolutionCl(tiff*, int*, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadFromTiffStreamCl(tiff*) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFReadDirectory", referenced from:
      OpenclDevice::pixReadStreamTiffCl(__sFILE*, int) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadMemTiffCl(unsigned char const*, unsigned long, int) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFReadRGBAImageOriented", referenced from:
      OpenclDevice::pixReadFromTiffStreamCl(tiff*) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFReadScanline", referenced from:
      OpenclDevice::pixReadFromTiffStreamCl(tiff*) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFScanlineSize", referenced from:
      OpenclDevice::pixReadFromTiffStreamCl(tiff*) in libtesseract_opencl.a(openclwrapper.o)
  "_clBuildProgram", referenced from:
      OpenclDevice::CompileKernelFile(_GPUEnv*, char const*) in libtesseract_opencl.a(openclwrapper.o)
  "_clCreateBuffer", referenced from:
      allocateZeroCopyBuffer(_KernelEnv, unsigned int*, unsigned long, unsigned long long, int*) in libtesseract_opencl.a(openclwrapper.o)
      allocateIntBuffer(_KernelEnv, unsigned int const*, unsigned long, int*, bool) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::initMorphCLAllocations(int, int, Pix*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::HistogramRectOCL(unsigned char*, int, int, int, int, int, int, int, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::ThresholdRectToPixOCL(unsigned char*, int, int, int*, int*, Pix**, int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixConvertRGBToGrayOCL(Pix*, float, float, float) in libtesseract_opencl.a(openclwrapper.o)
      ...
  "_clCreateCommandQueue", referenced from:
      populateGPUEnvFromDevice(_GPUEnv*, _cl_device_id*) in libtesseract_opencl.a(openclwrapper.o)
  "_clCreateContext", referenced from:
      populateGPUEnvFromDevice(_GPUEnv*, _cl_device_id*) in libtesseract_opencl.a(openclwrapper.o)
  "_clCreateKernel", referenced from:
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL(int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL(int, int, unsigned int, unsigned int) in libtesseract_opencl.a(openclwrapper.o)
      pixORCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      pixANDCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      ...
  "_clCreateProgramWithBinary", referenced from:
      OpenclDevice::CompileKernelFile(_GPUEnv*, char const*) in libtesseract_opencl.a(openclwrapper.o)
  "_clCreateProgramWithSource", referenced from:
      OpenclDevice::CompileKernelFile(_GPUEnv*, char const*) in libtesseract_opencl.a(openclwrapper.o)
  "_clEnqueueCopyBuffer", referenced from:
      OpenclDevice::initMorphCLAllocations(int, int, Pix*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixHollowCL(Pix*, Pix*, int, int, int, int, bool) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixGetLinesCL(Pix*, Pix*, Pix**, Pix**, Pix**, bool, int, int, int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
  "_clEnqueueMapBuffer", referenced from:
      mapOutputCLBuffer(_KernelEnv, _cl_mem*, Pix*, Pix*, int, unsigned long long, bool, bool) in libtesseract_opencl.a(openclwrapper.o)
      allocateIntBuffer(_KernelEnv, unsigned int const*, unsigned long, int*, bool) in libtesseract_opencl.a(openclwrapper.o)
      copyIntBuffer(_KernelEnv, _cl_mem*, unsigned int const*, unsigned long, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::HistogramRectOCL(unsigned char*, int, int, int, int, int, int, int, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::ThresholdRectToPixOCL(unsigned char*, int, int, int*, int*, Pix**, int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixConvertRGBToGrayOCL(Pix*, float, float, float) in libtesseract_opencl.a(openclwrapper.o)
      ...
  "_clEnqueueNDRangeKernel", referenced from:
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL(int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL(int, int, unsigned int, unsigned int) in libtesseract_opencl.a(openclwrapper.o)
      pixORCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      pixANDCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      ...
  "_clEnqueueUnmapMemObject", referenced from:
      mapOutputCLBuffer(_KernelEnv, _cl_mem*, Pix*, Pix*, int, unsigned long long, bool, bool) in libtesseract_opencl.a(openclwrapper.o)
      allocateIntBuffer(_KernelEnv, unsigned int const*, unsigned long, int*, bool) in libtesseract_opencl.a(openclwrapper.o)
      copyIntBuffer(_KernelEnv, _cl_mem*, unsigned int const*, unsigned long, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::HistogramRectOCL(unsigned char*, int, int, int, int, int, int, int, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::ThresholdRectToPixOCL(unsigned char*, int, int, int*, int*, Pix**, int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixConvertRGBToGrayOCL(Pix*, float, float, float) in libtesseract_opencl.a(openclwrapper.o)
      ...
  "_clFinish", referenced from:
      mapOutputCLBuffer(_KernelEnv, _cl_mem*, Pix*, Pix*, int, unsigned long long, bool, bool) in libtesseract_opencl.a(openclwrapper.o)
      allocateIntBuffer(_KernelEnv, unsigned int const*, unsigned long, int*, bool) in libtesseract_opencl.a(openclwrapper.o)
      copyIntBuffer(_KernelEnv, _cl_mem*, unsigned int const*, unsigned long, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::HistogramRectOCL(unsigned char*, int, int, int, int, int, int, int, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::ThresholdRectToPixOCL(unsigned char*, int, int, int*, int*, Pix**, int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixConvertRGBToGrayOCL(Pix*, float, float, float) in libtesseract_opencl.a(openclwrapper.o)
      ...
  "_clGetContextInfo", referenced from:
      OpenclDevice::CompileKernelFile(_GPUEnv*, char const*) in libtesseract_opencl.a(openclwrapper.o)
  "_clGetDeviceIDs", referenced from:
      OpenclDevice::getDeviceSelection() in libtesseract_opencl.a(openclwrapper.o)
  "_clGetDeviceInfo", referenced from:
      populateGPUEnvFromDevice(_GPUEnv*, _cl_device_id*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::getDeviceSelection() in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::BinaryGenerated(char const*, __sFILE**) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::GeneratBinFromKernelSource(_cl_program*, char const*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::HistogramRectOCL(unsigned char*, int, int, int, int, int, int, int, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::ThresholdRectToPixOCL(unsigned char*, int, int, int*, int*, Pix**, int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
  "_clGetPlatformIDs", referenced from:
      OpenclDevice::getDeviceSelection() in libtesseract_opencl.a(openclwrapper.o)
  "_clGetProgramBuildInfo", referenced from:
      OpenclDevice::CompileKernelFile(_GPUEnv*, char const*) in libtesseract_opencl.a(openclwrapper.o)
  "_clGetProgramInfo", referenced from:
      OpenclDevice::GeneratBinFromKernelSource(_cl_program*, char const*) in libtesseract_opencl.a(openclwrapper.o)
  "_clReleaseCommandQueue", referenced from:
      OpenclDevice::ReleaseOpenclEnv(_GPUEnv*) in libtesseract_opencl.a(openclwrapper.o)
  "_clReleaseContext", referenced from:
      OpenclDevice::ReleaseOpenclEnv(_GPUEnv*) in libtesseract_opencl.a(openclwrapper.o)
  "_clReleaseMemObject", referenced from:
      OpenclDevice::releaseMorphCLBuffers() in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::HistogramRectOCL(unsigned char*, int, int, int, int, int, int, int, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::ThresholdRectToPixOCL(unsigned char*, int, int, int*, int*, Pix**, int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixConvertRGBToGrayOCL(Pix*, float, float, float) in libtesseract_opencl.a(openclwrapper.o)
  "_clReleaseProgram", referenced from:
      OpenclDevice::ReleaseOpenclEnv(_GPUEnv*) in libtesseract_opencl.a(openclwrapper.o)
  "_clSetKernelArg", referenced from:
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL(int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL(int, int, unsigned int, unsigned int) in libtesseract_opencl.a(openclwrapper.o)
      pixORCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      pixANDCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      ...
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[1]: *** [libtesseract.la] Error 1
make: *** [install-recursive] Error 1
‚ãÆ
```

Both I and those other GitHub users who were helping me with this issue downstream thought it was another instance of the aforementioned #739, but I now think that we were mistaken in believing this given how said issue was resolved.  Basically, the crux of the problem is this:  is there something that previous committers have neglected to add to Homebrew's Tesseract build formula other than Homebrew/homebrew-core#10596, or is Tesseract at fault here and does solving this require Homebrew to mirror an upstream patch until the next release?   Whoops; I should have given that to you in the first place, shouldn't I?  Ah, well, here those details are now:  

* I initially built and installed Tesseract from within Homebrew by running `brew install -vd --build-from-source tesseract --with-all-languages --with-opencl --with-serial-num-pack --with-training-tools`, update it by running `brew upgrade -vd --build-from-source tesseract --with-all-languages --with-opencl --with-serial-num-pack --with-training-tools`, and retry doing either procedure when they fail by running `brew reinstall -vd --build-from-source tesseract --with-all-languages --with-opencl --with-serial-num-pack --with-training-tools`.  Executing either causes Homebrew to process `"$(brew --repository homebrew/homebrew-core)/Formula/tesseract.rb"` (a GitHub copy of which is available [here](https://github.com/Homebrew/homebrew-core/blob/master/Formula/tesseract.rb),) where `"$(brew --repository homebrew/homebrew-core)"` is `/usr/local/Homebrew/Library/Taps/homebrew/homebrew-core` (its default, officially supported location,) according to the `brew` sub-command given, Homebrew's DSL, and the options I provide using the processing defined in the relevant formula.  @JCount confirmed in [this comment](https://github.com/Homebrew/homebrew-core/issues/10380#issuecomment-282604860) on [my downstream issue](https://github.com/Homebrew/homebrew-core/issues/10380) that the option causing trouble is `--with-opencl`, which, as shown on [line 94](https://github.com/Homebrew/homebrew-core/blob/master/Formula/tesseract.rb#L94) of the Homebrew Core tap's `tesseract.rb` formula, corresponds to Tesseract's `./configure`'s `--enable-opencl` option.  
* The output I get from `./configure` is present in [my most recent Homebrew installation attempt logs](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/tree/master/Tesseract/v3.05.00/Third%20Attempt) as both [`02.configure`](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/blob/master/Tesseract/v3.05.00/Third%20Attempt/02.configure) and [lines 134‚Äì339](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/blob/master/Tesseract/v3.05.00/Third%20Attempt/reinstall.out#L134-L339) of [`reinstall.out`](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/blob/master/Tesseract/v3.05.00/Third%20Attempt/reinstall.out).  
* The versions of the build and run-time dependencies required by Tesseract under Homebrew I have installed on my machine are as follows:  
  * `autoconf` v2.69
  * `autoconf-archive` v2017.03.21
  * `automake` v1.15
  * GNU `libtool` v2.4.6, but patched by the Homebrew Core tap to resolve Homebrew/homebrew-core#3056 and Homebrew/homebrew-core#3882.  (_Not_ the `libtool` provided by Apple as part of its command-line tools suite, which I _also_ have installed.)  
  * `pkg-config` v0.29.2
  * Leptonica v1.74.1 (Built with the following dependencies:  
    * `pkg-config` v0.29.2
    * libpng v1.6.29
    * jpeg v8d
    * LibTIFF v4.0.7, but patched by the Homebrew Core tap to resolve Homebrew/homebrew-core#8639 and Homebrew/homebrew-core#9409.  ‚Äî&thinsp;Dependencies are as follows:  
      * jpeg v8d
      * xz v5.2.3
    * GIFlib v4.2.3 with a dependency as follows:  
      * X11 (supplied by XQuartz v2.7.11)
    * OpenJPEG v2.1.2 with dependencies as follows:  
      * CMake v3.7.2 with a dependency as follows:  
        * Sphinx v1.5.1
      * Little-CMS2 v2.8 with dependencies as follows:  
        * jpeg v8d
        * LibTIFF v4.0.7 as described above for Leptonica itself
      * LibTIFF v4.0.7 as described above for Leptonica itself
      * libpng v1.6.29
    * WebP v0.6.0 with dependencies as follows:  
      * libpng v1.6.29
      * jpeg v8d
      * LibTIFF v4.0.7 as described above for Leptonica itself
      * GIFlib v4.2.3 with a dependency as described earlier.)

Is that everything you need, or do I need to provide anything else?   @zdenop:  Roger, wilco.  That _is_ odd, though, so whatever could have caused _that‚Ä¶?_   @zdenop:  I keep getting the following error from `./configure` despite the fact that I have Cairo installed even when I add `-I/usr/local/opt/cairo/include` to `CPPFLAGS` (though should that be `CFLAGS` instead‚Ä¶?) and `-L/usr/local/opt/cairo/lib` to `LDFLAGS`:  

```
checking for cairo... no
configure: WARNING: Training tools WILL NOT be built because of missing cairo library.
configure: WARNING: Try to install libcairo-dev?? package.

‚ãÆ

You can not build training tools because of missing dependency.
Check configure output for details.
```

Should I be worried about this, or can I just ignore this error since the build problem I'm trying to solve is, IIRC, in Tesseract itself?  I was going to try and make my out-of-Homebrew build and install as close to my _in_-Homebrew one, which said it was going to include the training tools if it had succeeded, if you're wondering why I'm asking.  I don't want to overwrite my current _non_-development version of Cairo in the process, so what do I do?   @stweil:  Ah, thanks.  

<hr />

@zdenop:  Heh, whoops; looks like I was mentally applying the conceptual equivalent of `-Wwarnings-as-errors`, then; my mistake!  In any case, that's what I thought (I just wanted to make sure my judgement was correct by checking with you,) so I'll go ahead and continue this build attempt.   See https://github.com/tesseract-ocr/tesseract/wiki/Compiling for a list of required dependencies. For training tools you need the Dev version of libraries. @Shreeshrii:  That's what confused me in the _first_ place, as _Homebrew_ seems to be able to build the training tools just fine with the _production_ versions of their dependencies.  Perhaps it implements some sort of hack to make this (mostly) work, but I'd have to check the package manager's Tesseract formula to be sure of that, as I don't remember seeing anything special there before, which is odd‚Ä¶; maybe the difference is further up in the dependency chain and has to do with Homebrew presents some of its nodes to other software packages?  Or perhaps there's a Homebrew shim I don't know about, but I _thought_ I remembered that the package manager only instrumented system-level build tools‚Ä¶   Now that I've kept thinking about this discrepancy for a little bit, maybe it has to do with Homebrew's [`superenv` shim](https://github.com/Homebrew/brew/blob/master/Library/Homebrew/extend/ENV/super.rb)‚Ä¶?   @zdenop:  OK, [here](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/tree/master/Tesseract/v3.05.00/Fourth%20Attempt) are the logs from my attempt to build Tesseract manually outside of Homebrew.  [The new failure](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/blob/master/Tesseract/v3.05.00/Fourth%20Attempt/make.out#L840-L973) looks identical to [the one produced when building _inside_ Homebrew](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/blob/master/Tesseract/v3.05.00/Third%20Attempt/reinstall.out#L1179‚ÄìL1311) at first glance modulo the `make` procedure's exit status, and I don't think I see `-framework OpenCL` anywhere in my build logs, either, which is weird since you say Tesseract's `./configure` should add that in where needed.  

P. S.:  I have now compared the undefined symbols diagnosed by each of the log files I just referenced and found them to be identical.   @zdenop:  Would like me to run another attempt with `make`'s verbosity increased?   When this issue first cropped up in Homebrew, I tried building it outside of Homebrew's framework in a clean VM. I unsuccessfully tried various approaches, which I have of course forgotten, but it always fails with:
```
      ...
"_clSetKernelArg", referenced from:
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL(int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL(int, int, unsigned int, unsigned int) in libtesseract_opencl.a(openclwrapper.o)
      pixORCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      pixANDCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      ...
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[1]: *** [libtesseract.la] Error 1
make: *** [install-recursive] Error 1
```

Also, I can confirm this is still an issue using Xcode 8.3 on macOS 10.12.4 as well, no magical, mysterious fix with the latest update. @JCount:  Well, _that's_ not encouraging.  I'd update my environment to Sierra and the latest Xcode myself, but I'm stuck on an unsupported machine for the time being.  Since it doesn't help in this particular instance, however, I guess I shouldn't push myself to worry about that!  üòÜ

<hr />

@zdenop:  Given that this issue is consistently reproducible both inside and outside of Homebrew, should we perhaps change this issue's title to something more like 'OS X/macOS OpenCL Linkage Errors?'   Maybe it's not a macOS issue, but a Clang issue.

Did someone tested 3.05 on Linux with Clang & OpenCL? @amitdo:  Not that I know of.  I don't personally have a Linux install available for testing, either.   > Did someone tested 3.05 on Linux with Clang & OpenCL?

I just tested the build, and it worked without any problem using `./configure CXX=clang++-3.8 CXXFLAGS="-g -O2 -Wall" --enable-opencl && make training`. @stweil:  What about Clang 4?  According to Homebrew, that's what I've got installed:  

```
‚Ä¶$ brew info llvm
llvm: stable 4.0.0 (bottled), HEAD [keg-only]
Next-gen compiler infrastructure
http://llvm.org/
/usr/local/Cellar/llvm/4.0.0 (4,450 files, 2GB)
  Built from source on 2017-03-15 at 00:35:00 with: --with-toolchain --with-python --with-graphviz
From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/llvm.rb
==> Dependencies
Build: cmake ‚úî
Recommended: libffi ‚úî
Optional: graphviz ‚úî, ocaml ‚úî
==> Requirements
Optional: python ‚úî
==> Options
--with-graphviz
	Build with graphviz support
--with-lldb
	Build LLDB debugger
--with-ocaml
	Build with ocaml support
--with-python
	Build bindings against custom Python
--with-shared-libs
	Build shared instead of static libraries
--with-toolchain
	Build with Toolchain to facilitate overriding system compiler
--without-compiler-rt
	Do not build Clang runtime support libraries for code sanitizers, builtins, and profiling
--without-libcxx
	Do not build libc++ standard library
--without-libffi
	Do not use libffi to call external functions
--HEAD
	Install HEAD version
==> Caveats
LLVM executables are installed in /usr/local/opt/llvm/bin.
Extra tools are installed in /usr/local/opt/llvm/share/llvm.
To use the bundled libc++ please add the following LDFLAGS:
  LDFLAGS="-L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib"

This formula is keg-only, which means it was not symlinked into /usr/local.

macOS already provides this software and installing another version in
parallel can cause all kinds of trouble.

If you need to have this software first in your PATH run:
  echo 'export PATH="/usr/local/opt/llvm/bin:$PATH"' >> ~/.bash_profile

For compilers to find this software you may need to set:
    LDFLAGS:  -L/usr/local/opt/llvm/lib
    CPPFLAGS: -I/usr/local/opt/llvm/include


If you need Python to find bindings for this keg-only formula, run:
  echo /usr/local/opt/llvm/lib/python2.7/site-packages >> /usr/local/lib/python2.7/site-packages/llvm.pth
``` Scratch that:  now I feel somewhat silly, as, according to [Apple's list of Macs that support OpenCL](https://support.apple.com/en-us/HT202823), my machine (a mid-2007 aluminum iMac) is listed as supporting a 'non-applicable' version of the standard&thinsp;‚Äî&thinsp;that is, none at all!  This issue may still be relevant if @JCount's still seeing issues with _his_ setup, though, unless he _also_ has an unsupported machine‚Ä¶.  The runtime might still be present in my installation, though, as I've seen the Metal binaries just floating somewhere waiting for when I clone this drive's contents into a machine that supports _that_ API, so I'm not entirely sure whether that means I should be seeing link-time errors or not.  With 3.04.01, I was seeing _run_-time errors, possibly even with _return values_ (can't remember what they were off the top of my head, unfortunately, but I'm _pretty_ sure I still have my old Tesseract installation around, so I can go check.)   I think you need OpenCL **1.2** or higher. @amitdo:  Well, again, that _might_ explain things‚Ä¶ I have a machine that supports OpenCL 1.2, both with the Intel Iris Pro Graphics 5200 iGPU and the AMD Radeon R9 M370X dGPU. Yes, it seems to detect the presence of the OpenCL headers, and therefore framework. The issue seems to be in the linking as you say, and I honestly have no idea what is going wrong there. @zdenop, @JCount:  Strangely enough, here is the result of a bit of investigation I just did on my end:  

```
‚Ä¶$ ls -@aHhl /System/Library/Frameworks/ | grep OpenCL.framework
drwxr-xr-x    8 root  wheel   272B Dec 13 16:41 OpenCL.framework
```

So the OpenCL runtime _is_ present on my machine even if it's not _doing_ anything other than just _sitting_ there.  Either this just gets installed with the OS whether your machine supports it or not or the framework's presence is a relic of that one time I tried to install OS X so as to make it bootable on both this iMac and a newer MacBook Pro (can't remember the exact model ATM, sorry‚Ä¶) by _first_ running a clean OS install to this external drive from the latter and _then_ doing an _delta_ install to said drive from the _former_&thinsp;‚Äî&thinsp;though I _think_ I may have once done a clean install to the drive in question just from the iMac, so maybe my earlier hypothesis is correct‚Ä¶?  :man_shrugging:   I got vanilla (no homebrew) Tesseract 3.05 to compile and run. Machine is late 2013 iMac 27" with Sierra and OpenCL 1.2 support.

```
clang --version
Apple LLVM version 8.1.0 (clang-802.0.38)
```

```
./configure --enable-opencl LDFLAGS='-framework OpenCL' LIBS='-ltiff'
make -j
```

When the explicit `LDFLAGS='-framework OpenCL'` is removed the build fails. For some reason  `--enable-opencl` does not enable linking `-framework OpenCL` everywhere it should. Doing this causes `-framework OpenCL` to also show up twice sometimes, based on skimming the logs, so it works partially but incompletely.

Likewise, removing the explicit `libtiff` linkage will fail.

I don't have a lot of time to investigate the build machinery this week, but hopefully this analysis is enough of a clue to figure what is not working. If nobody bites I will look into it next week.

I did not try building training tools.

 @zdenop, @stweil, @JCount, and/or @jbarlow83:  What testing remains to be done with respect to tracking down exactly what's going wrong here?  Might there be anything _I_ could do to help?   @RandomDSdevel In `configure.ac` there is some logic that says "if we get `--enable-opencl` and we are only a Mac, set the variable named `OPENCL_LDFLAGS="-framework OpenCL"`, the special argument for Mac frameworks. Other platforms are working fine because they don't have or don't use `-framework` as far as I know. I actually don't know the details of what it does.

Most likely there is a `Makefile.am` (probably) that should set its local `local_LDFLAGS= $(OPENCL_LDFLAGS)` because it uses OpenCL, but does not. Or perhaps it is the main Makefile at the link step.

The lazy way would be to jump back about six months or so to find a version that compiled and git bisect your way to the breaking change, since it did work until recently. @jbarlow83:  Well, I'm not very fluent in Autoconf, Automake, and/or makefile syntax and have never used `git bisect` before, but I know `bash` shell scripting syntax well enough that I _think_ I can at _least_ point others in the right direction to _look._  The v3.05 logic in [`configure.ac`](https://github.com/tesseract-ocr/tesseract/blob/3.05/configure.ac) that's responsible for handling that script's `--enable-opencl` option occupies [lines 173‚Äì248](https://github.com/tesseract-ocr/tesseract/blob/3.05/configure.ac#L173-L248)&thinsp;‚Äî&thinsp;specifically, `OPENCL_LDFLAGS` is set to `"-framework OpenCL"` on [line 223](https://github.com/tesseract-ocr/tesseract/blob/3.05/configure.ac#L223) in the middle of the code ([lines 211-225](https://github.com/tesseract-ocr/tesseract/blob/3.05/configure.ac#L211-L225)) responsible for setting up the correct OpenCL compilation and linkage flags for use on Darwin-based operating systems like OS X/macOS.  I haven't yet looked for or at a `Makefile.am`, but I _do_ remember seeing one somewhere in the source code earlier; I'll just have to look for it again (hopefully it's in the repository's root directory or not far from it.)  If _that_ doesn't give us any clues, I'll check this 'main Makefile,' whatever it happens to be called.   @jbarlow83:  I checked in my last local build attempt and neither `"$(git rev-parse --show-toplevel)/Makefile.in"`, `"$(git rev-parse --show-toplevel)/Makefile.am"`, _nor_ `"$(git rev-parse --show-toplevel)/Makefile"` (the first and third of which are generated by `"$(git rev-parse --show-toplevel)/aurogen.sh"` and/or `"$(git rev-parse --show-toplevel)/configure.ac"`&thinsp;‚Äîsorry, but I can't exactly remember which script does what at the moment‚Ä¶) mess with any kind of `local_LDFLAGS` variable.  In fact, I ran `find . -type f -print0 | xargs -0 grep "*local_LDFLAGS*"` inside my local checkout of the Tesseract repository (still on branch `3.05` with artifacts left over from my last failed out-of-Homebrew/vanilla build) and came up _empty_&thinsp;‚Äî&thinsp;but maybe I was doing something wrong with this command pipeline invocation‚Ä¶?   As I mentioned I can look into this next week, just not now.

The issue is likely that some new code was introduced and the build system was not properly modified so there is no code to search for it. It is the absence of some necessary code that is the trouble. As you're not familiar with autotools my rough problem sketch is probably not helpful. What would help is to run `git bisect` and find the commit that breaks the build on macOS, since it used to work. That is likely a strong indicator of what kind of fix is needed. @jbarlow83:  Sorry to bother you with details you probably could have figured out easily enough yourself, then.   @RandomDSdevel, please try pull request #808. It fixes `make training` with OpenCL on macOS for me. Don't forget to run `./autogen.sh` after applying the change. @stweil:  Thanks, but I'm not sure that will help with _this_ issue, as it has to do with not being able to linking Tesseract _itself_ with OpenCL‚Ä¶  As I mentioned before, though, _this_ problem might _alos_ have something to do with the fact that invoking OpenCL functionality on my machine probably only returns responses indicating the fact that the library doesn't work with my graphics card, as Apple never supplied drivers for it.  @JCount, however, has a machine that _does_ support OpenCL and said he's getting similar link-time errors.  IIRC, @jbarlow83 has also reproduced this issue and has said he'd look into trying to fix it some time this week, but I'm not going to invoke him any further than that, as he advised not to badger him too much about it (I've _probably_ already annoyed him _enough_ as it _is_, what with my overly enthusiastic impatience to get this fixed and all‚Ä¶)  That being said, I'll still take a look at the PR you've pointed me towards and see if does anything to help.   I'm not annoyed at all, I just have to do the work that pays the bills first. :) @jbarlow83:  Whoops, look like I was reading a little too much into things, ha-ha‚Ä¶   @jbarlow83:  Just saw your work start popping up in #814.  I have one comment on it, but I'll leave it in the relevant discussion thread.    Hi,
trying to pipe a pdf file, converted by graphicsmagic to tif, to tesseract stdin gives me following error output, but the generated PDF is ok.

my cmd line:
`gm.exe convert -density 300 pdfin.pdf tif:- | tesseract.exe stdin pdfout -l deu pdf`

---

tesseract version:
tesseract 4.00.00alpha                                                                                      
 leptonica-1.74.1 (Mar 23 2017, 02:16:52) [MSC v.1910 LIB Release x64]                                      
  libgif 5.1.4 : libjpeg 9b : libpng 1.6.28 : libtiff 4.0.7 : zlib 1.2.11 : libwebp 0.6.0 : libopenjp2 2.1.2
                                                                                                            
 Found AVX                                                                                                  
 Found SSE

---

tesseracts output:
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Page 2
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Page 3
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Page 4
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found

Maybe a Bug? no errors, text output seems to be ok! thank you too.  Please see https://groups.google.com/forum/#!msg/tesseract-ocr/24rrQjxLJl8/hNJEtLx4FQAJ

 >Moved cube aside without deleting it.

Since then, Ray deleted the Cube code.

...except that leftover in the enum.
 https://github.com/tesseract-ocr/tesseract/blob/d2fcfcaec2/ccstruct/publictypes.h#L268  Add  major updates to 4.0.0alpha by Ray since Nov, 2016.

@zdenop, @stweil, @egorpugin @amitdo Please update with other major changes. Thanks! >\+ Remove support for VS2010.

@egorpugin
Does Tesseract 4.0 built with CMake supports VS2010 or not? ```
  + Add Support for VS2015 and VS2017 with cppan
  + Implement invisible text only for PDF
  + Add AVX / SSE support for Windows
  + Require leptonica 1.74 or higher
``` Thanks, I have combined the updates for date range from Nov 2016 to March 2017. Suggest that any major commits also add to the changelog on regular basis.

Does semantic versioning requiring more frequent tagging?

@zdenop Please approve merge. Thanks! @amitdo  I thought that you had made a similar list adding to release notes... Can't seem to find it now. Shree, here it is:
https://github.com/tesseract-ocr/tesseract/wiki/ReleaseNotes#in-development Thanks.

- excuse the brevity, sent from mobile

On 24-Mar-2017 5:22 PM, "Amit D." <notifications@github.com> wrote:

> Shree, here it is:
> https://github.com/tesseract-ocr/tesseract/wiki/
> ReleaseNotes#in-development
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/783#issuecomment-289003475>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o53dpBF51d4gZOIcYaf3F9O1R6cZks5ro66JgaJpZM4MmauK>
> .
>
  I am running the same command line as for the 3.x versions with 

-c preserve_interword_spaces=1

as option. The resulting text does not preserve the white spaces, which it correctly did for the 3.x version.

Thanks
Andre I am also facing the same problem. After using "preserve_interword_spaces", there is actually no significant difference noticed between the normal OCR and "preserve_interword_spaces=1" parameterized OCR.
Is there any solution? Same problem here. "preserve_interword_spaces" has no effect.
Also many other parameters do not work in v4.0 :/
Would be nice to get some feedback from the developers (which parameter works/which not) I have the same problem in version 4.0. I have tried with version 3.0.2 - It does not have this option. I also noticed this problem and it seems related with the trained data, because if I use tesseract 4 with the trained data of 3.05 I do get the interword spaces.
```
#!/bin/sh
export PATH=$HOME/local/tesseract/bin:$PATH
export LD_LIBRARY_PATH=$HOME/local/tesseract/lib:$LD_LIBRARY_PATH
#ubuntu tesseract 3 trained data
export TESSDATA_PREFIX=/usr/share/tesseract-ocr
#export TESSDATA_PREFIX=$HOME/local/tesseract/share/tessdata
tesseract $*

#tesseract -l spa -psm 4 $1 scanned
#mytesseract -c preserve_interword_spaces=1 -l spa  $1 scanned
``` >I also noticed this problem and it seems related with the trained data, because if I use tesseract 4 with the trained data of 3.05 I do get the interword spaces.

With 4.00, If you don't use the --oem option, the default oem will be used:

>3    Default, based on what is available.

The traineddata files for 3.05 does not have lstm data, so oem 3 in your case is equivalent to:

>0    Original Tesseract only. Thanks for pointing out !
I dived on tesseract source code and found an almost solution to the preserve_interword_spaces problem, it seems that when transferring the words in ccstruct/pageres.cpp the spaces were not transfered see patch bellow.
With this patch the output is almost identical with the 3.05 version except for the missing spaces for the first column (need more research to see where the first/second word is transfered and why the spaces/blanks are not).
```
@@ -1329,11 +1329,11 @@ void PAGE_RES_IT::ReplaceCurrentWord(
   WERD_RES* input_word = word();
   // Set the BOL/EOL flags on the words from the input word.
   if (input_word->word->flag(W_BOL)) {
     (*words)[0]->word->set_flag(W_BOL, true);
   } else {
-    (*words)[0]->word->set_blanks(1);
+    (*words)[0]->word->set_blanks(input_word->word->space());
   }
   words->back()->word->set_flag(W_EOL, input_word->word->flag(W_EOL));
 
   // Move the blobs from the input word to the new set of words.
   // If the input word_res is a combination, then the replacements will also be
``` Can't reproduce @Shreeshrii :/
I tried it with the python tesserocr wrapper like so:

> tess = PyTessBaseAPI(init=False, lang="eng", psm=PSM.SINGLE_BLOCK)
settings = {"preserve_interword_spaces": "1"}
tess.InitFull(lang="eng", oem=OEM.LSTM_ONLY, variables=settings)
tess.SetSourceResolution(300)
tess.SetPageSegMode(PSM.SINGLE_BLOCK)
img = Image.open("image.jpg")
tess.SetImage(img)
> print(tess.GetUTF8Text())

prints the text without preserved spaces :/

Also tried it through the command line as follows:

> tesseract image.jpg --tessdata_dir /usr/local/share/tessdata --oem 1 --psm 6 -l eng -c 
> preserve_interword_spaces=1

Gives me this error:

> tesseract: genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

I use the .traineddata files from https://github.com/tesseract-ocr/tessdata/tree/master/best
and latest leptonica & tesseract
Any advice please? :) Thanks, it works!
  Getting the famous : 

```
./configure: line 4250: syntax error near unexpected token `-mavx,'
./configure: line 4250: `AX_CHECK_COMPILE_FLAG(-mavx, avx=true, avx=false)'

```
However, actually read the doc and googled around, and i do have the autoconf-archive package installed >< That was it. Thanks! Did you run ./autogen.sh after the installation of autoconf-archive? (see also comment above) https://github.com/tesseract-ocr/tesseract/wiki/Compiling#macos for the life of god I can't manage to install or compile "autoconf-archive" on Amazon Linux AMI (it has yum, not apt-get).
Can anyone point me to instruction about how to install it? https://aws.amazon.com/amazon-linux-ami/faqs/

>Q: How do I enable the Extra Packages for Enterprise Linux (EPEL) repository?

Read the answer.
 thanks @amitdo, but no luck:

> [ec2-user@ip-172-31-31-253 ~]$ sudo yum install autoconf-archive --enablerepo=epel
> Loaded plugins: priorities, update-motd, upgrade-helper
> 1039 packages excluded due to repository priority protections
> No package autoconf-archive available.
> Error: Nothing to do  `Debian GNU/Linux 8 (jessie)`

When doing `./configure` I get this error

```
cd /var/bin && git clone https://github.com/tesseract-ocr/tesseract.git
cd tesseract && ./autogen.sh && ./configure
```

# error
```
# ./configure
checking for g++... g++
checking whether the C++ compiler works... yes
checking for C++ compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
Using git revision: 4.00.00alpha-339-ga51d0d4
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking for gawk... gawk
checking whether make sets $(MAKE)... yes
checking for style of include used by make... GNU
checking whether make supports nested variables... yes
checking dependency style of g++... gcc3
checking whether to enable maintainer-specific portions of Makefiles... no
checking build system type... x86_64-unknown-linux-gnu
checking host system type... x86_64-unknown-linux-gnu
./configure: line 4230: syntax error near unexpected token `-mavx,'
./configure: line 4230: `AX_CHECK_COMPILE_FLAG(-mavx, avx=true, avx=false)'

``` +1 :) Have now done what you said and installed all dependencies but get a new error when compiling my program

# install
```
apt-get install autoconf-archive pango-devel cairo-devel icu-devel
cd /var/bin && git clone https://github.com/tesseract-ocr/tesseract.git
cd tesseract && ./autogen.sh && ./configure && make && make install && ldconfig
```

# compiling my program
```
# g++ -std=c++11 txtocr.cpp -o txtocr -llept -ltesseract
/usr/bin/ld: warning: liblept.so.5, needed by //usr/local/lib/libtesseract.so, may conflict with liblept.so.4
``` found out I had installed leptonica through apt-get :)  After upgrading to `4.00` my program using tesseract is broken

Installing `tesseract 4.00`
```
cd /var/bin && wget https://github.com/tesseract-ocr/tesseract/archive/4.00.00alpha.tar.gz -O tesseract-4.00.00alpha.tar.gz && tar -xvf tesseract-4.00.00alpha.tar.gz
cd tesseract-4.00.00alpha && ./autogen.sh && ./configure && make && make install
```

Compiling program
```
g++ -std=c++11 txtocr.cpp -o txtocr -llept -ltesseract
```

Running program
```
# ./txtocr
./txtocr: error while loading shared libraries: libtesseract.so.4: cannot open shared object file: No such file or directory
``` # txtocr.cpp
```
/*
 *	Compile
 *	# g++ -std=c++11 txtocr.cpp -o txtocr -llept -ltesseract
 *
 *	Get tesseract version
 *	# pkg-config --modversion tesseract
*/

#include "txtocr.hpp"

void usage(const std::string VERSION){
	tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();
	
	std::cerr << "txtocr version: " << VERSION << "\nTesseract version: " << api->Version() << "\n\nUsage: txtocr input [options]\n"
		"Options:\n"
		"\t-l <string>          -- Set iterator level\n"
		"\t                        (Values: block | para | line | word | symbol)\n"
		"\t-d                   -- Debug (Verbose)\n" << std::endl;
}

int main(int argc, char* argv[]){
	Txtocr a;
	
	try{
		a.set_level("");
		
		//	Parse arguments
		for(int i = 1; i < argc; i++){
			std::string arg = std::string(argv[i]);
			
			if(i == 1){
				a.set_input(arg);
			}
			else if(arg == "-l"){
				a.set_level(argv[++i]);
			}
			else if(arg == "-d"){
				a.set_debug(true);
			}
			else{
				throw std::runtime_error("Argument '"+arg+"' is invalid");
			}
		}
		
		std::cout << a.run() << std::endl;
	}
	catch(std::exception& e){
		std::cerr << "Error: " << e.what() << "\n" << std::endl;
		usage(a.VERSION);
		return 1;
	}
	
	return 0;
}
```

# txtocr.h
```
class Txtocr{
	private:
		std::string input 					= "";
		tesseract::PageIteratorLevel level;
		bool is_debug						= false;
		void error							(const std::string& s);
		std::string utf8_to_latin			(const char * in);
	
	public:
		Txtocr();
		const std::string VERSION			= "0.1";
		void set_input						(const std::string& s);
		void set_level						(const std::string& s);
		void set_debug						(bool d);
		std::string run						();
};
```

# txtocr.hpp
```
#include <iostream>
#include <stdexcept>
#include <fstream>
#include <chrono>
#include <string>
#include <vector>
#include <math.h>
#include <boost/algorithm/string.hpp>
#include <tesseract/baseapi.h>
#include <leptonica/allheaders.h>
#include <boost/property_tree/ptree.hpp>
#include <boost/property_tree/json_parser.hpp>
#include "txtocr.h"

Txtocr::Txtocr(){}

void Txtocr::set_input(const std::string& s){
	input = s;
}

void Txtocr::set_level(const std::string& s){
	if(s == ""){
		level = tesseract::RIL_TEXTLINE;
	}
	else if(s == "block"){
		level = tesseract::RIL_BLOCK;
	}
	else if(s == "para"){
		level = tesseract::RIL_PARA;
	}
	else if(s == "line"){
		level = tesseract::RIL_TEXTLINE;
	}
	else if(s == "word"){
		level = tesseract::RIL_WORD;
	}
	else if(s == "symbol"){
		level = tesseract::RIL_SYMBOL;
	}
	else{
		error("Invalid iterator level");
	}
}

void Txtocr::set_debug(bool d){
	is_debug = d;
}

void Txtocr::error(const std::string& s){
	throw std::runtime_error(s);
}

std::string Txtocr::utf8_to_latin(const char* in){
	std::string out;
	
	if(in == NULL){
		return out;
	}
	
	unsigned int codepoint;
	while (*in != 0){
		unsigned char ch = static_cast<unsigned char>(*in);
		if(ch <= 0x7f){
			codepoint = ch;
		}
		else if(ch <= 0xbf){
			codepoint = (codepoint << 6) | (ch & 0x3f);
		}
		else if(ch <= 0xdf){
			codepoint = ch & 0x1f;
		}
		else if(ch <= 0xef){
			codepoint = ch & 0x0f;
		}
		else{
			codepoint = ch & 0x07;
		}
		
		++in;
		
		if(((*in & 0xc0) != 0x80) && (codepoint <= 0x10ffff)){
			if(codepoint <= 255){
				out.append(1, static_cast<char>(codepoint));
			}
			else{
				// do whatever you want for out-of-bounds characters
			}
		}
	}
	
	return out;
}

std::string Txtocr::run(){
	//	Return error if input file is not defined
	if(input == ""){
		error("Input file not defined");
	}
	//	Return error if input file is not TIFF
	else{
		std::string input_lc = input;
		boost::to_lower(input_lc);
		if(input_lc.substr(input_lc.find_last_of(".") + 1) != "tif"){
			error("Input file must be TIFF");
		}
	}
	
	auto start = std::chrono::high_resolution_clock::now();
	
	// Open input image with leptonica library
	Pix *image = pixRead((input).c_str());
	
	boost::property_tree::ptree root;
	boost::property_tree::ptree children;
	
	root.put("height", pixGetHeight(image));
	root.put("width", pixGetWidth(image));
	
	// Initialize tesseract-ocr, without specifying tessdata path
	tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();
	if(api->Init(NULL, "dan+eng")){
		error("Could not initialize tesseract");
	}
	api->SetImage(image);
	api->Recognize(0);
	
	tesseract::ResultIterator* ri = api->GetIterator();
	
	if(ri != 0){
		do{
			boost::property_tree::ptree child;
			
			const char* seg = ri->GetUTF8Text(level);
			int x1, y1, x2, y2, height, width;
			ri->BoundingBox(level, &x1, &y1, &x2, &y2);
			height = y2 - y1;
			width = x2 - x1;
			
			if(is_debug){
				printf("seg: '%s'; BoundingBox: %d,%d,%d,%d;\n", seg, x1, y1, x2, y2);
			}
			
			child.put("top", y1);
			child.put("left", x1);
			child.put("height", height);
			child.put("width", width);
			child.put("bottom", y1 + height);
			child.put("right", x1 + width);
			child.put("html", utf8_to_latin(seg));
			child.put("conf", roundf(ri->Confidence(level) * 100) / 100);
			
			children.push_back(std::make_pair("", child));
			
			delete[] seg;
		}
		while(ri->Next(level));
		
		root.add_child("elms", children);
	}
	
	// Destroy used object and release memory
	api->End();
	pixDestroy(&image);
	
	auto elapsed = std::chrono::high_resolution_clock::now() - start;
	root.put("exec_time", ((float)std::chrono::duration_cast<std::chrono::microseconds>(elapsed).count() / 1000) / 1000);
	
	std::ostringstream oss;
	write_json(oss, root, false);
	return oss.str();
}
``` Try to uninstall 3.0x first before installing 4.00.
Don't forget running `ldconfig`. `ldconfig` solved the error..

But what about those shared objects/files?

Arent all required files compiled into the file `txtocr` ??

When the following code prints `Tesseract version: 4.00.00alpha` can I then be 100% sure that everything is running `4.00` ? 

``` 
tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();

std::cerr << "Tesseract version: " << api->Version() << std::endl;
```

I am compiling my program like this `g++ -std=c++11 txtocr.cpp -o txtocr -llept -ltesseract` 4.0.0alpha tagged zip file is from Nov 2016 (I think, please check).

If you want latest 4.0.0alphacode, please clone from master in GitHub.
There have been quite a few commits since the original tag for 4.0.0.

- excuse the brevity, sent from mobile

On 20-Mar-2017 9:05 PM, "clarkk" <notifications@github.com> wrote:

> ldconfig solved the error..
>
> But what about those shared objects/files?
>
> Arent all required files compiled into the file txtocr ??
>
> When the following code prints Tesseract version: 4.00.00alpha can I then
> be 100% shure that everything is running 4.00 ?
>
> tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();
>
> std::cerr << "Tesseract version: " << api->Version() << std::endl;
>
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/774#issuecomment-287797686>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oz8guS825Mrknsc_-ul--atGngkiks5rnpzQgaJpZM4MihhH>
> .
>
 Run Configure with enable debug to see the git revision of the code u r
running.

- excuse the brevity, sent from mobile

On 20-Mar-2017 11:24 PM, "ShreeDevi Kumar" <shreeshrii@gmail.com> wrote:

> 4.0.0alpha tagged zip file is from Nov 2016 (I think, please check).
>
> If you want latest 4.0.0alphacode, please clone from master in GitHub.
> There have been quite a few commits since the original tag for 4.0.0.
>
> - excuse the brevity, sent from mobile
>
> On 20-Mar-2017 9:05 PM, "clarkk" <notifications@github.com> wrote:
>
>> ldconfig solved the error..
>>
>> But what about those shared objects/files?
>>
>> Arent all required files compiled into the file txtocr ??
>>
>> When the following code prints Tesseract version: 4.00.00alpha can I
>> then be 100% shure that everything is running 4.00 ?
>>
>> tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();
>>
>> std::cerr << "Tesseract version: " << api->Version() << std::endl;
>>
>> ‚Äî
>> You are receiving this because you are subscribed to this thread.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/774#issuecomment-287797686>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AE2_oz8guS825Mrknsc_-ul--atGngkiks5rnpzQgaJpZM4MihhH>
>> .
>>
>
 Where is the user forum? Where can I ask questions?

I need to build static library of tesseract so I can compile everything into one binary  After installing `3.05` I still get `3.04` when running `pkg-config --modversion tesseract`

How I installed `3.05`

```
cd /var/bin && wget http://www.leptonica.com/source/leptonica-1.74.1.tar.gz && tar -xvf leptonica-1.74.1.tar.gz
cd leptonica-1.74.1 && ./configure && make && make install

cd /var/bin && wget https://github.com/tesseract-ocr/tesseract/archive/3.05.00.tar.gz -O tesseract-3.05.00.tar.gz && tar -xvf tesseract-3.05.00.tar.gz
cd tesseract-3.05.00 && ./autogen.sh && ./configure && make && make install && ldconfig
```

When compiling my program that uses tesseract its also still using `3.04`

```
g++ -std=c++11 txtocr.cpp -o txtocr -llept -ltesseract
``` I will uninstall everything and try to clone master  Hello!

![3](https://cloud.githubusercontent.com/assets/19375839/24091638/5471aad0-0d5a-11e7-9bbe-42c1f1f2fc4d.jpg)
When we try to recognize the picture above through a new tesseract 4.0, we have the following output
![bug](https://cloud.githubusercontent.com/assets/19375839/24091647/5f7afc92-0d5a-11e7-865c-af89cf15f807.png)
Via 3.04 
 ![bug](https://cloud.githubusercontent.com/assets/19375839/24091662/7e190ea0-0d5a-11e7-86f9-f4063079d402.png)
Dots wrong recognized : 
![3](https://cloud.githubusercontent.com/assets/19375839/24091712/c7907de8-0d5a-11e7-8d12-5769db8ee55c.png)

Common input : 
![bug](https://cloud.githubusercontent.com/assets/19375839/24091744/012d05c6-0d5b-11e7-8a37-43657c4c9c28.png)

For testing
https://drive.google.com/file/d/0B0K3HIAIMTpMS3lGZXkteXo2Sjg/view?usp=sharing


 Maybe a tesseract has a minimum character size setting?   :+1: 

reference:
https://github.github.com/gfm/ The 3.05 README.md also suffers from this wrong syntax.
 Another link:
https://githubengineering.com/a-formal-spec-for-github-markdown/  LSTM training requires box files which have a TAB at end of line and spaces to demarcate words.

Box files generated by tesseract from image files do not have these. 

The synthetic box/tiff pairs generated by text2image have the spaces and tabs. I get the same message with Arabic language as shown below  the box file generated with 
training/tesstrain.sh \
--fonts_dir /home/idris/mylot \
--lang ara --linedata_only \
--noextract_font_properties --langdata_dir ./langdata \
--tessdata_dir ./tessdata \
--output_dir ~/mylottutorial \
--fontlist "mylotus Bold"


=== Starting training for language 'ara'
[Mon Nov 13 01:52:41 PST 2017] /usr/local/bin/text2image --fonts_dir=/home/idris/mylot --font=mylotus Bold --outputbase=/tmp/font_tmp.Rf99kiznKj/sample_text.txt --text=/tmp/font_tmp.Rf99kiznKj/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.Rf99kiznKj
Stripped 1 unrenderable words
Rendered page 0 to file /tmp/font_tmp.Rf99kiznKj/sample_text.txt.tif

=== Phase I: Generating training images ===
Rendering using mylotus Bold

[Mon Nov 13 01:52:42 PST 2017] /usr/local/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.Rf99kiznKj --fonts_dir=/home/idris/mylot --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0 --max_pages=3 --font=mylotus Bold --text=./langdata/ara/ara.training_text
Stripped 2 unrenderable words
Rendered page 0 to file /tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0.tif
Rendered page 1 to file /tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0.tif
Stripped 10 unrenderable words
Rendered page 2 to file /tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0.tif

=== Phase UP: Generating unicharset and unichar properties files ===
[Mon Nov 13 01:52:44 PST 2017] /usr/local/bin/unicharset_extractor --output_unicharset /tmp/tmp.s7NZRqv0Qa/ara/ara.unicharset --norm_mode 2 /tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0.box
Extracting unicharset from box file /tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0.box
Word started with a combiner:0x64b
Normalization failed for string ' Ÿã'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64f
Normalization failed for string 'Ÿèÿ™'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'ŸãÿßŸÖ'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64f
Normalization failed for string 'Ÿèÿ£'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x650
Word started with a combiner:0x651
Normalization failed for string 'ŸêŸëÿ±'
Word started with a combiner:0x64f
Normalization failed for string 'ŸèŸä'
Word started with a combiner:0x64f
Word started with a combiner:0x651
Normalization failed for string 'ŸèŸëŸÑ'
Word started with a combiner:0x650
Normalization failed for string 'Ÿêÿ≠ŸÑ'
Word started with a combiner:0x64f
Normalization failed for string 'ŸèŸá'
Word started with a combiner:0x64e
Word started with a combiner:0x651
Normalization failed for string 'ŸéŸëÿ∑'
Word started with a combiner:0x650
Word started with a combiner:0x651
Normalization failed for string 'ŸêŸëŸÅ'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'Ÿãÿß'
Word started with a combiner:0x64b
Normalization failed for string 'ŸãÿßŸÖ'
Word started with a combiner:0x64b
Normalization failed for string 'ŸãŸâ'
  I want use opencl to speed up tesseract. I define USE_OPENCL in C/C++->Preprocessor->Preprocessor Definitions(VS2015) .
and include"CL/cl.h" in openclwrapper.h.
And rebuild the libtesseract  project , and succeeded.
When I use GetUTF8Text, the  String return is NULL but return correct string when I don't use opencl.
Can you tell me ,where is the problem?
Can Opencl use in teseeract 3.05?
Thanks!




 Hi , zdenop ,
   Can you help me at there. I can't use the tesseract user forum because I don't have a Google account .I am very sorry for that.
Thanks!  I want know  in persian's tesseract what fonts are there and also what is priority  for training them?   @stweil I think you mean `fonts` instead of `languages` in the above.  The current master only builds Win32.  Are there x64 builds or build processes available for tesseract4?  I use for persian and it is ok but if in text ,there were two language  (persian and english) how can detect and convert them ? which traineddata are you ussing for persian? what accuracy rate do you get?

for multiple languages use

-l per+eng @roozgar - which is the better traineddata for persian - fas or per? The tesseract-ocr/tessdata repo on GitHub only has 'fas'.
 > The tesseract-ocr/tessdata repo on GitHub only has 'fas'.

See https://github.com/tesseract-ocr/langdata/issues/24
At one time both per and fas were there.

 Shree,

I don't see 'per' in any commit in the **tessdata** repo. Both were there in langdata. Ray has since deleted `per`.

PersianOCR is an external project using Tesseract (3.02 I think) - see https://github.com/reza1615/PersianOcr ‚Äãno 'per' is removed and changed persian traindata to 'fas'‚Äã
‚Äãand also its not capable with end or any other language‚Äã
 Maybe Arabic.traineddata also includes Persian. Ray? @amitdo no,i checked
the Arabic train data cant detect the symbols that is included in Persian and not in Arabic lstm dont merge trained files in run time?  SVSync::StartThread() is used in api/ , backporting the GRAPHICS_DISABLED fix
Backport api/ libtfiff missing dependency for win32 platform @voyageur:  @zdenop said in [this comment](https://github.com/tesseract-ocr/tesseract/issues/739#issuecomment-286849254) on #739 that [your second commit](https://github.com/tesseract-ocr/tesseract/pull/760/commits/7e0352f5276a68d7c58b750279273f25a868efaa) to this PR's staging branch isn't really needed for branch `3.05` since `configure` _should_ add the relevant linker flag automatically when Tesseract is being built with OpenCL support&thinsp;‚Äî&thinsp;at least, I _think_ that was his reasoning‚Ä¶   @RandomDSdevel oh you're right, this is not needed for #739. Windows builds may still need as there is a direct call to tiff library in api/ for win32.
I will update the commit message, but can drop this commit of course if not really desired for 3.05 branch @zdenop I don't ;) the (outside of opencl) TIFFSetWarningHandler call at https://github.com/tesseract-ocr/tesseract/blob/3.05/api/tesseractmain.cpp#L396 is wrapped in  "defined(_WIN32)" so probably needs the -ltiff linking  I'm trying to process the following image using tesseract 3.04
<img width="157" alt="number" src="https://cloud.githubusercontent.com/assets/115446/23871059/3ae3fb32-07ff-11e7-8d02-f1c33e7a8d10.png">

The image seems pretty clean. however, it extracts the following from this image using the `eng` lang

> .ESHBEE

**Questions**
1. Is there a way to read numbers like these from tesseract? 
2. If I have to train a separate lang for these type of numbers, can the trained lang be integrated into the `eng` lang?  I have found that the error goes away when NOT using --eval_listfile,
please try without the following

--eval_listfile
/home/stweil/src/github/tesseract-ocr/tesseract/frk/train/frk.training_files.txt

Though this means that there is no regular eval during training.


ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Mon, Mar 13, 2017 at 12:42 PM, Stefan Weil <notifications@github.com>
wrote:

> Running lstmtraining for frk language with 50000 iterations terminated
> with an assertion.
>
> $ lstmtraining -U /home/stweil/src/github/tesseract-ocr/tesseract/frk/train/frk.unicharset --script_dir ~/src/github/tesseract-ocr/langdata --net_spec '[1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c105]' --model_output /home/stweil/src/github/tesseract-ocr/tesseract/frk/output/base --train_listfile /home/stweil/src/github/tesseract-ocr/tesseract/frk/train/frk.training_files.txt --eval_listfile /home/stweil/src/github/tesseract-ocr/tesseract/frk/train/frk.training_files.txt --max_iterations 50000
> ...
> At iteration 15778/49900/49900, Mean rms=0.37%, delta=0.112%, char train=0.381%, word train=1.506%, skip ratio=0%,  wrote checkpoint.
>
> At iteration 15788/50000/50000, Mean rms=0.363%, delta=0.104%, char train=0.346%, word train=1.387%, skip ratio=0%,  wrote checkpoint.
>
> Finished! Error rate = 0.26
> num_docs > 0:Error:Assert failed:in file ../../../../ccstruct/imagedata.cpp, line 648
>
> I used latest Tesseract sources, a slightly modified font list and a
> longer training text for frk training.
> A previous run with 10000 iterations and nearly the same conditions did
> not raise the assertion:
>
> ...
> 2 Percent improvement time=807, best error was 3.911 @ 8211
> At iteration 9018/10000/10000, Mean rms=0.835%, delta=0.465%, char train=1.729%, word train=6.095%, skip ratio=0%,  New best char error = 1.729Deserialize failed wrote best model:/home/stweil/src/github/tesseract-ocr/tesseract/tutorial/frkoutput/base1.729_9018.lstm wrote checkpoint.
>
> Finished! Error rate = 1.729
>
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/757>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o-S-16Nb7AFsGsCO3w_L80p8t9Fuks5rlOxhgaJpZM4Ma6ed>
> .
>
 A link to the relevant line in the source code:  
https://github.com/tesseract-ocr/tesseract/blob/134a2537584b5bd6000841dbcb0a9489cd2548f5/ccstruct/imagedata.cpp#L648 Maybe it's a memory problem. How much RAM do you have in that machine? About fonts, I believe that for LSTM training Ray used much more fonts for each language than with the old engine.  So little RAM? A University server, I guess...  :-)  On Mon, Mar 13, 2017 at 3:42 PM, Amit D. <notifications@github.com> wrote:

> I used 12 fonts. The training result was pretty good for the old engine
> and unusable for LSTM.
>
> 12 fonts is not enough for LSTM. Use as much fonts as you can find.
>

 ‚Äã@stweil You can increase the number of box/tiff pairs by adding
--exposures "-1 0 1" or even --exposures "-2 -1 0 1 2" ‚Äãwith the same fonts
to get images which are lighter and darker than the original font.

```
training/tesstrain.sh --fonts_dir /usr/share/fonts --lang frk  \
  --linedata_only --noextract_font_properties --exposures "-1 0 1" \
   --langdata_dir ../langdata --tessdata_dir ./tessdata \
     --output_dir ~/tesstutorial/frk
```

Also, please check whether the fonts you are using have support for the
paragraph marker etc, otherwise they might get dropped as unrenderable.

@theraysmith I think it will be useful if training using non-synthetic
box/tiff pairs is also supported for LSTM.

Thanks.
 @stweil I had  generated box files for different Fraktur font alphabet images using makebox. However these need to be reviewed for correctness and tabs need to be added at end of lines.

I do not recognize the letters so can't update them. jtessboxeditor could be used for adding tabs.

https://github.com/paalberti/tesseract-dan-fraktur/files/721936/fraktur-png-box-to-be-corrected.zip I know. I do not have those fonts,but found these images on the net on some
font sites. If you or Ray have the resources to get these fonts, you can
use them to create appropriate trainingdata.

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Tue, Mar 14, 2017 at 11:16 AM, Stefan Weil <notifications@github.com>
wrote:

> @Shreeshrii <https://github.com/Shreeshrii>, that's a nice collection of
> Fraktur fonts, but several of the image not even include all normal ASCII
> characters. All images are missing the long s character (≈ø) which is very
> important for all Fraktur texts. Also missing are all forms of ligatures
> (combinations of certain characters, like for example ffi, which need a
> special rendering).
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/757#issuecomment-286328117>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o_my9wQq3XxnJtuzD2QWSpwu0Pt4ks5rlimqgaJpZM4Ma6ed>
> .
>
 These are the freely available Fraktur fonts that I found:

```
FRAKTUR_FONTS=(
  "CaslonishFraxx Medium" \
  "Cloister Black, Semi-Light" \
  "Proclamate Light, Semi-Light" \
  "UnifrakturCook" \
  "UnifrakturMaguntia" \
  "UnifrakturMaguntia16" \
  "UnifrakturMaguntia17" \
  "UnifrakturMaguntia18" \
  "UnifrakturMaguntia19" \
  "UnifrakturMaguntia20" \
  "UnifrakturMaguntia21" \
    "Walbaum-Fraktur" \
)
```

sample files via text2image that I had posted in the issue

https://github.com/paalberti/tesseract-dan-fraktur/files/721956/frk.box-tif-pairs.zip @stweil The page about fonts will be very useful. I have added info about Devanagari fonts and will update more later.

Please see pages 2-9 in http://www.sanskritweb.net/fontdocs/genzmer.pdf
which show samples of many fraktur fonts - again it does not have ligatures and all letters - but would something like that be helpful for training/testing German Fraktur.  You can also check the following as well as other font related documents on website by  Ulrich Stiehl.
http://www.sanskritweb.net/fontdocs/gutenberg2.pdf
http://www.sanskritweb.net/fontdocs/gutenberg.pdf
http://www.sanskritweb.net/fontdocs/walbaum.pdf `INT_PARAM_FLAG(max_image_MB, 6000, "Max memory to use for images.")`

I don't know if it is actually related to the reported issue, but you can increase the default value from the command line. @amitdo It is probably memory related, since  the assertion does not occur when I omit --eval_listfile.

And, https://github.com/tesseract-ocr/tesseract/blob/master/training/lstmeval.cpp uses a smaller memory size for images.

`INT_PARAM_FLAG(max_image_MB, 2000, "Max memory to use for images.");`

How would you change it from commandline?
 The same way you do it with text2image.

You should take into account the RAM in your PC. @Shreeshrii  I changed the max_image_MB to 8000  /training/lstmeval.cpp, and complie it . 
then, run
`lstmtraining --debug_interval -1 --model_output /data/docker-tess/output/realR5 --continue_from /data/docker-tess/output/realR410.378_33695.lstm  --train_listfile /data/traindata/trainAll.train_filelist.txt --eval_listfile /data/correctedBox/real.eval_filelist.txt `

after 100 Iterations, it CoreDump 
```
Mean rms=0.148%, delta=2.857%, train=12.187%(29%), skip ratio=3%
lstmtraining: ../ccutil/genericvector.h:696: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
Aborted (core dumped)

``` @Shreeshrii  I am trying to fine-tune tesseract for Arabic and Persian. I have used 4000 text lines and about 40 fonts. and I set the max-error-rate=0.001. the error rate of 0.002 has been recorded. but after finishing of the training process I got error-rate=0! Is it reasonable? Dear Mr.Smith;
thanks for answering my question.
No, it's not overfitted. I tested it and the results were acceptable.

On Fri, Aug 4, 2017 at 4:41 AM, theraysmith <notifications@github.com>
wrote:

> It would be expected to get such a low error rate on your training set, but
> has it overfitted? How does it do on different test data?
>
> On Tue, Aug 1, 2017 at 6:13 AM, hanikh <notifications@github.com> wrote:
>
> > @Shreeshrii <https://github.com/shreeshrii> I am trying to fine-tune
> > tesseract for Arabic and Persian. I have used 4000 text lines and about
> 40
> > fonts. and I set the max-error-rate=0.001. the error rate of 0.002 has
> been
> > recorded. but after finishing of the training process I got error-rate=0!
> > Is it reasonable?
> >
> > ‚Äî
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/757#
> issuecomment-319365858>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AL056TlrhrROzIm6VOXVoiHjygnInOUGks5sTyRvgaJpZM4Ma6ed>
> > .
> >
>
>
>
> --
> Ray.
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/757#issuecomment-320122468>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAaUyiObmY6Hi8q10PMUhoGYA_Wolks5sUmGugaJpZM4Ma6ed>
> .
>
  > Or we can ask Ray.

@theraysmith, the current code includes a hard coded value of 70 dpi as the minimum resolution and sets any resolution which is smaller to that value. This is also done for images which don't include a resolution information ("0 dpi"). Maybe it would be better to assume 300 dpi for that special case. Why does the resolution matter at all? IMO, assuming Tesseract really needs to know the resolution, when the dpi is absent or seems suspicious, the program should not try to guess the dpi and ocr the page. It should just print an error message. Maybe. It is not clear why the dpi information is needed at all. I can read text of any dpi (just have to adapt the reading distance or get some glasses) without knowing the actual dpi value, and ideally OCR software can do that, too.

If the dpi value is important, we need an option to set it for images without (or with wrong) resolution metadata. https://github.com/tesseract-ocr/tesseract/search?q=resolution Many thanks for this analysis and your efforts. +1 this is biting me as well. I have a small demo which was working a year ago, but now it is giving:

```r
> text <- ocr("http://jeroen.github.io/files/inlove.png")
Warning. Invalid resolution 0 dpi. Using 70 instead.
Too few characters. Skipping this page
```

I guess the problem is that the default resolution is too low?  https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/OJI3bsi_JMY/NHlt8uEfEAAJ

>I'm new to tesseract and wondered why the lstm dataset creation for the training process has to write the file again and again in TrainLineRecognizer. I've seen 200MB/s IO on the disk while creating the training data set. As far I can see for the training case it would be sufficient to just load it once and write it at the end. The same applies to the box and tif file - but these are only read and not written...



  https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/t7GdSDRrGpI/gMzJEcfXEAAJ

https://groups.google.com/group/tesseract-ocr/attach/10d7c711c9cc80/mrz.traineddata?part=0.1&authuser=0

> Just created a tesseract 3.04 trained data (see attached). 
I call it "MRZ" because it has the OCR-B as the only font and trained with characters A-Z, 0-9 and the lesser-than symbol (<). Seems to be fast and accurate in my projects. Is there a list where community contributions for traineddata are listed?

This should be tested and added. Is that what you want?
https://github.com/tesseract-ocr/tesseract/wiki/AddOns#community-training-projects Thanks. Added to community Training Projects.  If you really want to piss @theraysmith off, then fine... I understand Ray's messages on this topic differently.

Zdenko will decide...

Peace :-) @egorpugin 
Is there no good alternative to AppVeyor?  Blacklist and whitelist no longer work in 4.00alpha. They used to work in 3.04.

https://groups.google.com/forum/#!topic/tesseract-ocr/cpcJHTE2xMo Same problem for me with 4.00alpha, I tried to set `tessedit_char_whitelist` by using:
- cli with option `-c tessedit_char_whitelist=abcdefghijklmnopqrstuvwxyz`
- cli with config file
- tesserocr python module

But I keep getting non letter results

I can provide Dockerfile + python script + images if needed Same problem for me. Still getting symbols and alphabets despite setting `tessedit_char_whitelist="0123456789"`. I encountered the same issue today when using --oem 1,2,3. It works fine for --oem 0 (Original Tesseract).  I am encountering the same issue, is there a solution for this issue yet?.
 >I am encountering the same issue, is there a solution for this issue yet?.

No. I am facing the same issue. Is it really a bug or is it just not supported for LSTM?  It's currently not supported for LSTM.

People, please do not add another "I have the same issue" comment. Are there plans to support whitelisting on LSTM in the future? I also have this problem when using Tesseract 4 from C++

    tess->SetVariable("tessedit_char_whitelist", "01234567890abcdefg");

has no effect on the output. The same with blacklist.

Tesseract returns not only ascii + language-specific characters but also some strange other characters from UTF-8. 

Is there a way to get a full list of all possible characters, specific for a language or not? Basing on such list one could make a workaround to map such wrong characters to best fitting ones that are expected (like EM DASH to plain ASCII dash etc.) and remove those without any sensible fit. It would be useful for me in current circumstances and maybe it could be useful for others in need of whitelisting.
 I would like to exclude everything except letters and digits from the result. I started from eng.traineddata and trained my font from graphical images (@shreeshrii: thanks!!)) . Is there a way to get rid of all the other symbols, especially !"=)() ... ?

I am using --oem 1.

Thank you very much,
Ernst  Increase portability by insulating `autogen.sh` from platform variance.  

<hr />

Specifically, test for the existence of either `libtoolize` or `glibtoolize` and caching its location into a script variable prior to running the utility in order to prevent either utility's invocation from spawning error messages of the form './autogen.sh: line $LINE: $COMMAND: command not found' (with the $LINE and $COMMAND pseudo-variables replaced with content relevant to what line the command that spawned this error message was on within `autogen.sh` and what command's invocation was attempted at that point, of course.)  In particular, this takes into account macOS's wonky `libtool` semantics, which involve the following idiosyncrasies:  

* The version of `libtool` that Apple bundles within both Xcode and its separate associated 'Command-Line Developer Tools' package comes _without_ a copy of `libtoolize`.  
* macOS package managers like Homebrew and MacPorts typically install the GNU versions of `libtool` and `libtoolize` as `glibtool` and `glibtoolize`, respectively, when needed by another package as a dependency or otherwise requested by an end-user.  

The pre-existing code which was _supposed_ to handle this case was _not_ resilient with respect to errors finding either the system copy or the GNU variant of `libtoolize`, as it ran _both_ `libtoolize` and `glibtoolize`, in _that_ order, _without_ checking for the existence of _either_ utility!  (From the `man` page of the copy of `bash` included with macOS 'El Capitan' v10.11.6, which is reported to be `GNU bash, version 3.2.57(1)-release (x86_64-apple-darwin15)` by `bash --version`:  

> ```
> ‚Ä¶
>
> SHELL GRAMMAR
>
> ‚Ä¶
>
>    Lists
>           A list is a sequence of one or more pipelines separated by one of the operators ;, &, &&, or ||,  and optionally terminated by one of ;, &, or <newline>.
>
>           Of  these  list  operators,  &&  and  || have equal precedence, followed by ; and &, which have equal precedence.
>
>           A sequence of one or more newlines may appear in a list instead of a semicolon to delimit commands.
>
>           If a command is terminated by the control operator &, the shell executes the  command  in  the  background in a subshell.  The shell does not wait for the command to finish, and the return status is 0.
>           Commands separated by a ; are executed sequentially; the shell waits for each command to terminate in turn.  The return status is the exit status of the last command executed.
>
>           The  control  operators  &&  and || denote AND lists and OR lists, respectively.  An AND list has the form
>
>                  command1 && command2
>
>           command2 is executed if, and only if, command1 returns an exit status of zero.
>
>           An OR list has the form
>
>                  command1 || command2
>
>           command2 is executed if and only if command1 returns a non-zero exit status.  The  return  status  of AND and OR lists is the exit status of the last command executed in the list.
>
> ‚Ä¶
> ```

‚Äî&thinsp;_note_, however, that this text only implies that execution of the _second_ command in the `||` list can be short-circuited if the execution of the first command fails; that _first_ command is _always_ executed!)  

This root cause of this issue was initially clarified to me by the second half of [this comment](https://github.com/Homebrew/homebrew-core/issues/10380#issuecomment-283186646) on Homebrew/homebrew-core#10380 because it appeared as a red herring of a side effect during diagnosis of [that same issue](https://github.com/Homebrew/homebrew-core/issues/10380).  ~~Per [this further comment](https://github.com/Homebrew/homebrew-core/issues/10380#issuecomment-283505099) on that issue, further corrections to `autogen.sh` may remain desired after the merger of this pull request into `master`.~~  (Never mind, that's #739 and has to do with `api/Makefile.am`.)  This pull request should also be backported to at _least_ branch `3.05`.   By the way, did I put the `libtoolize`/`glibtoolize` existence check in the right place?  I can move it elsewhere in `autogen.sh` if you guys want‚Ä¶   AppVeyor fails a lot of times for no good reason. @stweil:  
> By the way: it's `autogen.sh`, not `autopen.sh`.

Gah, blasted auto-correct struck _again!_  ~~I'd better go ahead and fix that while I'm resolving the rest of your review comments, then!~~  (Oh, wait, I don't think there's nothing to fix inside my commits, as I'm _pretty_ sure auto-correct only rears its ugly head when I'm making comments on this PR from within Safari.  Everything I did from within `nano` should be fine‚Ä¶)   @stweil:  Would you like me to squash my commits together?  In addition, have any changes requiring me to rebase mine on top of them been pushed to `master` since I started working on this PR?  (I should probably look myself‚Ä¶_goes to check._)  

<hr />

Also @stweil w. r. t. your originally reply to [this comment](https://github.com/tesseract-ocr/tesseract/pull/750#issuecomment-284881849) of mine:  

> That's a rather lengthy commit messages, and it is not so easy for me to get the essentials from it. ‚Ä¶

I thought the commit message did a pretty good job of explaining things myself, but I'll change it if you feel like that isn't the case.  I'll either go back and edit the original commit message or change said message as part of squashing all my commits together if you end up wanting me to do that.  

> ‚Ä¶The old code works, but throws a nasty and confusing warning on systems which provice glibtoolize instead of libtoolize. This is fixed by your pull request.

That was the idea.  üòâ @stweil:  OK, works for me!   @stweil:  Rebased against `b6eb8bebb16cc95da44d465713bb868474c572c1`.   @zdenop:  How would I go about backporting the changes I submitted as part of this PR to the `3.05` branch?  (To quote the reason I'm asking this from this PR's OP‚Ä¶:  

> ‚Ä¶
>
> This root cause of this issue was initially clarified to me by the second half of this comment on Homebrew/homebrew-core#10380 because it appeared as a red herring of a side effect during diagnosis of [that same issue](https://github.com/Homebrew/homebrew-core/issues/10380).  ‚Ä¶This pull request should also be backported to at _least_ branch `3.05`.

‚Ä¶, I basically need that to be done by either myself or whoever's in charge of doing stuff like that in order to resolve the downstream issue in question.)   @zdenop:  :man_facepalming:  No, but I guess I should have!  Lemme check‚Ä¶ @zdenop:  Never mind, none of the commits from this PR are missing from branch `3.05`!  Guess I should have asked if you had backported them from `master` already or not, as it wasn't entirely obvious whether or not you intended to do so from within the context of this thread.   @zdenop:  That's perfectly all right if you've been somewhat busy lately, and it wasn't any trouble for me to check back on things after the fact at _all_.  Let's hope you get some more free development time soon, though!    my computer does not install openmp, i configure with --disable-openmp, but i still could not compile with error:
./.libs/libtesseract.so: undefined reference to `omp_get_thread_num'
./.libs/libtesseract.so: undefined reference to `GOMP_sections_end_nowait'
./.libs/libtesseract.so: undefined reference to `omp_get_num_threads'
./.libs/libtesseract.so: undefined reference to `GOMP_parallel'
./.libs/libtesseract.so: undefined reference to `GOMP_parallel_sections'
./.libs/libtesseract.so: undefined reference to `GOMP_sections_next'
so, if have some bugs about the configure! I use 4.0 version, and i set the _OPENMP undef manually, then it could compile. @yhl41001, do you still have this issue?

If you do, please response to zdenop. @zdenop, please close this issue.  I am getting error

./configure --enable-debug
checking for g++... no
checking for clang++... no
checking for C++ compiler default output file name...
configure: error: in `/home/azureuser/ocr/tesseract':
configure: error: C++ compiler cannot create executables
See `config.log' for more details.  see #11 Also. it seems that this PR only changes parts of the old engine that Ray wants to drop.

 @theraysmith commented in #518 

>Please provide examples of where you get better results with the old engine.
Right now I'm trying to work on getting rid of redundant code, rather than spending time fighting needless changes that generate a lot of work.

>Instead of modifying the old engine parts, concentrate on convincing me why it should stay first

To me, the message here from Ray is clear:
<<That's NOT an actual quote of Ray>>
"I don't want you* to do any change to the old engine. Doing so just interfere with my work on the new engine".

That's the way I understand it.

\* 'you' - not just you, any developer.

>see #11 

https://github.com/tesseract-ocr/tesseract/pull/11#pullrequestreview-12160316 Here is the way I believe things are working in the Google side.

Every commit that we push to this repo, at some time in the future (few weeks/months) will be reviewed by Ray or someone else from Google. If they don't like something they will change it. Then it will be merged with the internal Google branch, which might diverge significantly from the public repo's master branch. I think they do it infrequently, which means that when they try to merge with us they have quite a lot of work to do and it is not so simple as you might think.

@theraysmith, @jbreiden
You are invited to correct me if I'm wrong here. See also:
https://github.com/tesseract-ocr/tesseract/pull/752#issuecomment-294258915 I rebased the code to fix some merge conflicts.

Ray, I noticed your recent changes which introduced `TFile` in those files. IMO removing memry.{cpp,h} would also be a good step to clean the code. I‚Äå could do that in two steps to simplify reviews if you agree:

1. switch to using malloc / calloc and free in a first step (like it is done in this PR)
2. replace all those allocations by C++ code (new / new[] and delete / delete[]) >replace all those allocations by C++ code (new / new[] and delete / delete[])

Isn't this remark from Ray also relevant here?
https://github.com/tesseract-ocr/tesseract/pull/11#pullrequestreview-12160316 It isn't, as I promised to use C++ code in step 2 (see above). >How about replacing the underlying pointer variables with std::array, thus hiding all calls to allocate and delete the memory?

If you know what he meant, consider implementing it.  Teseract 3.04 - Was trying to command line OCR a 9206 multi-page tiff document on Mac OS 10.11, but it stops at page 3000.  Turns out opencl/openclwrapper.cpp line 93 (static const l_int32 MAX_PAGES_IN_TIFF_FILE = 3000;) specifically limits OCRing Tiffs to 3000 pages.  This const appears to only control the bounds of a for loop, so maybe this variable should be more dynamic and be based on the number of pages the input Tiff has instead?  just a thought. Sorry about that.  

Removed the 3000 page restriction on multipage tiff files.  There are now no limits, and this is pushed to the leptonica master: https://github.com/danbloomberg/leptonica Only relevant to 3.05. yeah, I might have a make my own custom build of 3.04.01 with the change to openclwrapper.cpp. @jbreiden I would think it's faster with it on, but haven't tested it.  Kinda new to tess - is there a way to easily turn it off to see? oh...looks like build flags    Hello,

Tesseract-3.04.01 (and having briefly glanced at the code, likely so does 3.05.00) does not explicitly link libtesseract against libtiff even when the former references symbols from the latter. This results in the following error when one attempts to build tesseract using a linker that dislikes implicit linking, e.g. gold:

/bin/sh ../libtool  --tag=CXX   --mode=link x86_64-pc-linux-gnu-g++  -O2 -pipe -march=native -std=c++11 -lOpenCL -Wl,-O1 -Wl,--as-needed -Wl,--as-needed -Wl,-O1 -Wl,--hash-style=gnu -Wl,--sort-common -O2 -pipe -march=native -o tesseract tesseract-tesseractmain.o libtesseract.la   -lrt -llept -lpthread 
libtool: link: x86_64-pc-linux-gnu-g++ -O2 -pipe -march=native -std=c++11 -Wl,-O1 -Wl,-O1 -Wl,--hash-style=gnu -Wl,--sort-common -O2 -pipe -march=native -o .libs/tesseract tesseract-tesseractmain.o  -lOpenCL -Wl,--as-needed ./.libs/libtesseract.so -lrt -llept -lpthread
./.libs/libtesseract.so: error: undefined reference to 'TIFFFdOpen'
./.libs/libtesseract.so: error: undefined reference to 'TIFFGetFieldDefaulted'
./.libs/libtesseract.so: error: undefined reference to 'TIFFGetField'
./.libs/libtesseract.so: error: undefined reference to 'TIFFScanlineSize'
./.libs/libtesseract.so: error: undefined reference to 'TIFFReadRGBAImageOriented'
./.libs/libtesseract.so: error: undefined reference to 'TIFFReadScanline'
./.libs/libtesseract.so: error: undefined reference to 'TIFFClientOpen'
./.libs/libtesseract.so: error: undefined reference to 'TIFFReadDirectory'
./.libs/libtesseract.so: error: undefined reference to 'TIFFCleanup'
collect2: error: ld returned 1 exit status
make[2]: *** [Makefile:591: tesseract] Error 1
make[2]: Leaving directory '/tmp/tesseract-3.04.01/api'
make[1]: *** [Makefile:480: all-recursive] Error 1
make[1]: Leaving directory '/tmp/tesseract-3.04.01'
make: *** [Makefile:389: all] Error 2

Manually adding -ltiff to the list of libraries in api/Makefile allows tesseract to build successfully, then again it is not a proper solution because e.g. the pkg-config file it installs still doesn't list that library.
 Can you be more specific on how to manually add -ltiff to api/Makefile?  I'm running MacOS Sierra 10.12.3 and getting an error about linking the ltiff when compiling the 4.0 alpha version.

libtool: link: g++ -g -O2 -std=c++11 -o .libs/tesseract tesseract-tesseractmain.o -Wl,-bind_at_load  -L/usr/local/Cellar/icu4c/56.1/lib ./.libs/libtesseract.dylib -L/usr/local/Cellar/leptonica/1.74.1/lib -llept -ltiff
ld: library not found for -ltiff
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[2]: *** [tesseract] Error 1
make[1]: *** [all-recursive] Error 1
make: *** [all] Error 2 You may need to install libtiff. try the following (or equivalent command
for your os) before building tesseract

sudo apt-get install libtiff5-dev


ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Tue, Feb 28, 2017 at 11:19 AM, idiosyncraticee <notifications@github.com>
wrote:

> Can you be more specific on how to manually add -ltiff to api/Makefile?
> I'm running MacOS Sierra 10.12.3 and getting an error about linking the
> ltiff when compiling the 4.0 alpha version.
>
> libtool: link: g++ -g -O2 -std=c++11 -o .libs/tesseract
> tesseract-tesseractmain.o -Wl,-bind_at_load -L/usr/local/Cellar/icu4c/56.1/lib
> ./.libs/libtesseract.dylib -L/usr/local/Cellar/leptonica/1.74.1/lib
> -llept -ltiff
> ld: library not found for -ltiff
> clang: error: linker command failed with exit code 1 (use -v to see
> invocation)
> make[2]: *** [tesseract] Error 1
> make[1]: *** [all-recursive] Error 1
> make: *** [all] Error 2
>
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/739#issuecomment-282948903>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o2DBBGFvNuj0aVuQ62S8d6A51beiks5rg7VtgaJpZM4MNnC7>
> .
>
 Thank you so much Shreeshrii!  That tip got me pointed in the right direction.  For anybody else that stumbles up this here is the config command that worked.  The second library path contains the libtiff libraries.

./configure CC=gcc CXX=g++ CPPFLAGS=-I/usr/local/Cellar/icu4c/56.1/include LDFLAGS="-L/usr/local/Cellar/icu4c/56.1/lib -L/usr/local/lib" @idiosyncraticee  Glad you have solved your problem but for the record, that was completely unrelated to the issue at hand. Indeed, the command-line snippet you have posted suggests that libtiff underlinking has been fixed in the 4.x branch - one can clearly see -ltiff there. Which may make fixing this in the 3.x branch a simple matter of backporting a patch. >Tesseract does not reference any libtiff symbols

You might want to read [opencl/openclwrapper.cpp](https://github.com/tesseract-ocr/tesseract/blob/59ba80bb3a5b/opencl/openclwrapper.h) ... https://github.com/tesseract-ocr/tesseract/commit/9ec0c4fa9c983

This one was not backported to 3.05. Per [an issue](https://github.com/Homebrew/homebrew-core/issues/10380) I reported downstream to maintainers of [the macOS Homebrew package manager](https://github.com/Homebrew/brew)'s [Core tap](https://github.com/Homebrew/homebrew-core) (and as specifically pointed out by [this comment](https://github.com/Homebrew/homebrew-core/issues/10380#issuecomment-283186646) on it,) this issue also occurs under OS X/macOS 'El Capitan' v10.11.6.  As Homebrew's maintainers _vastly_ prefer using only patches available upstream, can the priority of backporting this issue's resolution from `master` be bumped up just a _tad_, please?   > 9ec0c4f

> This one was not backported to 3.05.

>>  All that code is currently unused but you are correct, it is right there.

@egorpugin @zdenop  Should it be added to the 3.05 branch for the timebeing i.e. till opencl is looked at.  @jbreiden
>I stand corrected. All that code is currently unused but you are correct, it is right there.

Not exactly...
https://github.com/tesseract-ocr/tesseract/blob/40dc28026b61/api/baseapi.cpp#L1038

```
#ifdef USE_OPENCL
    if ( od.selectedDeviceIsOpenCL() ) {
      pix = (data) ?
          od.pixReadMemTiffCl(data, size, page) :
          od.pixReadTiffCl(filename, page);
    } else {
```

This issue is about 3.05. Should we remove the calls to these two functions in 3.05 as you have done in 4.00? Looks like @zdenop is busy. Is he the only one who can push these changes and tag patch releases? @mkszuba, @idiosyncraticee, @Shreeshrii, @jbreiden, @amitdo, @egorpugin, and/or @zdenop:  If you don't mind my trying my hand at resolving this issue, what's the local procedure for submitting backport PRs, at least with respect to the Git/GitHub workflow?  Do I just have to mention the commit from which the new one backports changes, or will I have to do something more complicated (like, say, use `git cherry-pick` or something‚Ä¶?)   @mkszuba, @idiosyncraticee, @Shreeshrii, @jbreiden, @amitdo, @egorpugin, and/or @zdenop:  
> @mkszuba, @idiosyncraticee, @Shreeshrii, @jbreiden, @amitdo, @egorpugin, and/or @zdenop:  If you don't mind my trying my hand at resolving this issue, what's the local procedure for submitting backport PRs, at least with respect to the Git/GitHub workflow?  Do I just have to mention the commit from which the new one backports changes, or will I have to do something more complicated (like, say, use `git cherry-pick` or something‚Ä¶?)  

‚Ä¶or would one of you guys rather handle this yourselves since you're more familiar with the codebase than I am?  Like I hinted at [earlier](https://github.com/tesseract-ocr/tesseract/issues/739#issuecomment-283486022) in this thread, I'm just bumbling around trying to fix an [issue](https://github.com/Homebrew/homebrew-core/issues/10380) downstream in [Homebrew](https://github.com/Homebrew/brew)'s [Core tap](https://github.com/Homebrew/homebrew-core) that I referenced back then.   @stweil:  I already got the `libtoolize` issue fixed here upstream in #750, but that has turned out to be _completely_ orthogonal to this one and is also just coincidentally waiting for said fix to be backported (from `master`, in its case.)  As for OpenCL, that's _actually_ what I've been wanting to get working _all along!_  I believe my rationale for efforts in this space agrees, at least at some level, with the sentiment you expressed earlier:  

> Depending on the graphic card, it [(OpenCL)] can be a great gain. That is relevant for some OCR projects which would take years on a single CPU.

As such, I'll be ready to propagate the backport of [`9ec0c4f`](https://github.com/tesseract-ocr/tesseract/commit/9ec0c4fa9c983) from 4.0.x to 3.0.5 postulated [earlier](https://github.com/tesseract-ocr/tesseract/issues/739#issuecomment-283117301) as the only change needed to resolve this issue here upstream to Homebrew as a downstream mirror of an official upstream patch if a new version of Tesseract is not tagged.  If a new version of Tesseract _is_ tagged, then I would be perfectly happy with propagating _that_ downstream to Homebrew instead of the patches containing the resolutions for this issue and, simultaneously but, again, orthogonally, #750.  Either way, all I currently wish to do is get Tesseract to build with `--enable-opencl` set by Homebrew (via the `--with-opencl` option to its build formula for Tesseract) _independent_ of any further reworking of Tesseract's OpenCL support, such as that suggested by [_this_ comment](https://github.com/tesseract-ocr/tesseract/issues/739#issuecomment-283608563), that is undertaken in the future.  The intermediate resolution of #750 was, for me, just a nice little side bonus in the meantime.   @zdenop Turns out my glance at the code was not accurate and the problem has indeed been fixed in 3.05.00. My bad, sorry, @mkszuba:  Did the fix involve linking Tesseract with a copy of Leptonica linked with libtiff?   OK, so I communicated with @mkszuba via private e-mail to see if he would be willing to answer my previous comment, but he's looked at my downstream issue, and he has the impression that it's different enough from his that I should probably open a new one here upstream, so I think I'm going to do that if troubleshooting Homebrew/homebrew-core#10380 by trying to build Tesseract under Homebrew fails again (I suspect it will if the problem I'm having is distinct from the one addressed by this issue's preemptive resolution, but maybe I'll get lucky‚Ä¶)   Aaaaannnd‚Ä¶the build failed again, so the issue is as reproducible on my machine under Homebrew as I thought.  I'd better fork my issue off into a new one and stop derailing this one, then, because I'm starting to believe @mkszuba that it's not the same‚Ä¶   Per the GitHub issue mention notification above, I've now opened #786 to pursue Homebrew/homebrew-core#10380 further here upstream.    Hi,
Sorry for asking here.
I want to get the bounding boxes of the paragraphs and the paragraph breaks in the scanned image using tesseract.I went through methods in ResultIterator class but was not able to find the required one.
It would be great if anyone could help me on this.
Thank You.  @theraysmith  

Please see detailed report at https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/LUHy-niac6U/7oZgqIWLCwAJ

## Copied message:


I have been trying to train Tesseract 4.0 with my own data in order to extract text as a mix of natural language words and domain-specific (non-natural language) words (acronyms, identifiers, abbreviations). The Tesseract standard model has troubles in recognizing domain-specific words where ‚Äúvisual‚Äù words from source are either dropped or recognized with missing parts in them. So, I decided to train my own model.

I went through tutorials, set up a number of experiments, but so far with no real success. While I could fix the entirely dropped words problem by lowering the hard coded confidence threshold, and a partial success in recognizing domain-specific words, the accuracy on natural language words went down.

Two observations I have made so far by following experiments:

In Experiment 1 I use the available data (as it is) for training (~1 M tokens, and ~150 fonts). After that I generated an evaluation data set for another ~200 k tokens and ~15 most relevant fonts. Then, I trained the model by replacing the top layer from the existing Tesseract traineddata as described at https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Replace-Top-Layer The training converged a couple of days later and I evaluated the model on a held out dataset with gold standard (tiff ‚Äì plain txt). The accuracy I received was lower than by using the standard Tesseract model. I noticed that the model is able to recognize some (not all) domain-specific words, however the performance on the natural language words went down (where the standard model worked fine). So, I analyzed the errors and designed another experiment in which I addressed the observed errors, which were, in my opinion, caused by data skewness = confusions between characters in rare and complex contexts.
In Experiment 2 I used the entire data set I have (~120 M tokens) and extracted word and char bigram statistics. Then I took all words with frequencies over a certain threshold as part of the final training data set. In addition, I boosted word statistics for words containing low-frequency char bi-grams (which made me troubles in the experiment before) and appended them into the final training data set. In the end, it resulted in a ~600 k unique words training data set. This was then rendered with ~ 150 fonts into tiffs, the evaluation data set remained a natural language text of ~200 k tokens in ~15 most relevant fonts. It turned out that training converges too slow ‚Äì it has been running for over a week now with the best model of a ~ 0.17% error rate . Evaluations of pairs of different subsequent model snapshots on the held out dataset showed no general improvement over each other, rather random fluctuations between more accurate natural language words vs. domain-specific and vice versa. More interesting, models with lower char error rate (< 0.5%) perform worse (especially on natural language words) than models with higher char error rate (~ 0.5%). I also noticed that the model captures ‚Äúlanguage modeling features‚Äù which makes the recognition of misspelled words, ‚Äúnon-natural language‚Äù unique identifiers and acronyms difficult. Moreover, unique identifiers, rare words etc. in text are a big problem, however can be already recognized in chunks, but not as a whole word. More specifically, trouble cases are ‚Äúlike-this‚Äù, ‚Äúlike/this‚Äù or ‚Äúthis-or-like-this‚Äù.


At this point I am doubting the way I am training Tesseract is correct. So I would like to ask the community the following questions:
Should I use a natural language text or a dictionary of words for training and evaluation data set?
How important is the effect of token redundancy? (Are the errors in recognition of natural language words caused by the only single instances of those words in the training data?)
How to get Tesseract to recognize freely generated tokens not available in the training dataset? 

Thanks,
Alex

 I have had similar results, though with smaller training sets, both with Devanagari and san_latn (Sanskrit in Latin Script). Update:
After preparing new training and evaluation data, I trained a new model once again. Now, the data comprises 4,6M tokens of about 600k words (with a controlled, "shape-similar" to real word distribution) for 150 fonts. Then, I used ~ 80 % of data for training and 20 % as "held out" eval data.
After about 6 weeks (:)) of training the model converged to 0.01. Then I took a single page of the training TIFF file and ran Tesseract on that page. 

Despite a high quality level for "alpha-numerical" words, **ALL** words which contain "-" are wrong. I thought that the word I was looking at is the one of those which cause 0.01 char error rate, I dug deeper into the log file. I see the word as well as the entire line were perfectly recognized during training. Moreover, this word exists at least 5 times in the training text, and thus at least ~750 times in all fonts. 

So, I am a bit confused that the words which were perfect during training are wrong when evaluated separately. And, it is the case for all words containing "-". 

Below I provide an example:
![line](https://cloud.githubusercontent.com/assets/5794813/25696614/1fdbc202-30b8-11e7-923f-bc97fd8f1de3.png)

TSV for the line above:
5       1       1       1       2       1       113     188     467     50      51      Fernsehtechnologien
5       1       1       1       2       2       597     191     407     48      51      Tontinengesch√§fte
5       1       1       1       2       3       1022    193     350     39      52      Konzernsteuern
5       1       1       1       2       4       1391    194     343     49      51      Kartografierung
5       1       1       1       2       5       1748    196     447     49      0       Avantgarde-√∂sung,  <------- L is dropped
5       1       1       1       2       6       2216    191     467     56      52      √ñlversorgungsrouten
5       1       1       1       2       7       2700    201     240     38      40      verschw√∂rt
5       1       1       1       2       8       2958    201     429     49      54      Dialoginstrumenten

While training this line has been used and :
Iteration 3826338: ALIGNED TRUTH : Fernsehtechnologien Tontinengesch√§fte Konzernsteuern Kartografierung Avantgarde-L√∂sung, √ñlversorgungsrouten verschw√∂rt Dialoginstrumenten
Iteration 3826338: BEST OCR TEXT : Fernsehtechnologien Tontinengesch√§fte Konzernsteuern Kartografierung Avantgarde-L√∂sung, √ñlversorgungsrouten verschw√∂rt Dialoginstrumenten
File /tmp/tmp.F8zm7RXvJr/deu/deu.Microsoft_Sans_Serif.exp0.lstmf page 20 (Perfect):

Can someone help me to find out what I have been doing wrong?

Thanks,
Alex  how to build tesseract 3.0.1 on mac OS X?  >What is the reason for this change? Shouldn't Tesseract get credit for its PDF output?

If someone embeds libtesseract in his his product 'myOwnOCR', he probably prefer that any output will use this name instead of 'Tesseract'...

Maybe it will be more fair if 'libtesseract x.yz' will be kept in the output, especially if the developer doesn't apply any change to it, or apply only minor changes. I'm against this as well. It's too important to be able to trace Tesseract-produced PDFs back to the version of Tesseract that produced them. Tesseract should not allow changing the /Producer field.

The /Creator field, which Tesseract does not set, is the appropriate one for this use case.  I will training a new model to recognize chinese, english and some special symbol, now i can not create the image with text2image because the font file may not cover all text. How could I to solve this situation. What version of Tesseract are you using?

Have you tried using multiple languages for recognition, eg. -l eng+chi

- excuse the brevity, sent from mobile

On 20-Feb-2017 2:42 PM, "dipthomas" <notifications@github.com> wrote:

> I will training a new model to recognize chinese, english and some special
> symbol, now i can not create the image with text2image because the font
> file may not cover all text. How could I to solve this situation.
>
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/730>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o4WjA6UrmCEaJ63Tv1rfA7q8RxuYks5reVjggaJpZM4MF7F5>
> .
>
 @Shreeshrii , I am using Tesseract 4.0, and I want to train a model including English, Chinese and some math symbol like ‚ñ≥. 
Now the problem is I can not generate the training image via a single font. (text2image) The training process drops unrenderable words. So the letters not included
in the font will get dropped, if you use a combined text with multiple
languages and run text2image with different fonts.

You will then get some images with text in one language and some in the
other.

However, I don't know how successful this will be. You will need a large
amount of text to train.

I have not had much success in training 4.0. please share your experiences
if you try the above approach.

- excuse the brevity, sent from mobile

On 22-Feb-2017 3:24 PM, "dipthomas" <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/Shreeshrii> , I am using Tesseract 4.0,
> and I want to train a model including English, Chinese and some math symbol
> like ‚ñ≥.
> Now the problem is I can not generate the training image via a single
> font. (text2image)
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/730#issuecomment-281621699>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o9P6-UMdzYkJsUelGKI3dxeOj75Jks5rfAXGgaJpZM4MF7F5>
> .
>
 Have you tried with
https://github.com/tesseract-ocr/tessdata/blob/master/chi_sim.traineddata

https://github.com/tesseract-ocr/langdata/tree/master/chi_sim
shows the kind of combination you are talking about ..

https://github.com/tesseract-ocr/langdata/blob/master/chi_sim/chi_sim.training_text
https://github.com/tesseract-ocr/langdata/blob/master/chi_sim/desired_characters
https://github.com/tesseract-ocr/langdata/blob/master/chi_sim/chi_sim.training_text.unigram_freqs

You can try to find fonts that support the training text by using command
similar to following (change location of fonts and langdata to match your
setup):

text2image --find_fonts \
--fonts_dir /usr/share/fonts \
--text ./langdata/chi_sim/chi_sim.training_text \
--min_coverage .9  \
--outputbase ./langdata/chi_sim/chi_sim\
|& grep raw | sed -e 's/ :.*/" \\/g'  | sed -e 's/^/  "/'
>./langdata/chi_sim/fontslist.txt

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Wed, Feb 22, 2017 at 6:10 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
wrote:

> The training process drops unrenderable words. So the letters not included
> in the font will get dropped, if you use a combined text with multiple
> languages and run text2image with different fonts.
>
> You will then get some images with text in one language and some in the
> other.
>
> However, I don't know how successful this will be. You will need a large
> amount of text to train.
>
> I have not had much success in training 4.0. please share your experiences
> if you try the above approach.
>
> - excuse the brevity, sent from mobile
>
> On 22-Feb-2017 3:24 PM, "dipthomas" <notifications@github.com> wrote:
>
>> @Shreeshrii <https://github.com/Shreeshrii> , I am using Tesseract 4.0,
>> and I want to train a model including English, Chinese and some math symbol
>> like ‚ñ≥.
>> Now the problem is I can not generate the training image via a single
>> font. (text2image)
>>
>> ‚Äî
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/730#issuecomment-281621699>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AE2_o9P6-UMdzYkJsUelGKI3dxeOj75Jks5rfAXGgaJpZM4MF7F5>
>> .
>>
>
 https://chinesefontdesign.com/tag/simplified-chinese-font

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Thu, Feb 23, 2017 at 12:14 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
wrote:

> Have you tried with
> https://github.com/tesseract-ocr/tessdata/blob/master/chi_sim.traineddata
>
> https://github.com/tesseract-ocr/langdata/tree/master/chi_sim
> shows the kind of combination you are talking about ..
>
> https://github.com/tesseract-ocr/langdata/blob/master/chi_
> sim/chi_sim.training_text
> https://github.com/tesseract-ocr/langdata/blob/master/chi_
> sim/desired_characters
> https://github.com/tesseract-ocr/langdata/blob/master/chi_
> sim/chi_sim.training_text.unigram_freqs
>
> You can try to find fonts that support the training text by using command
> similar to following (change location of fonts and langdata to match your
> setup):
>
> text2image --find_fonts \
> --fonts_dir /usr/share/fonts \
> --text ./langdata/chi_sim/chi_sim.training_text \
> --min_coverage .9  \
> --outputbase ./langdata/chi_sim/chi_sim\
> |& grep raw | sed -e 's/ :.*/" \\/g'  | sed -e 's/^/  "/'
> >./langdata/chi_sim/fontslist.txt
>
> ShreeDevi
> ____________________________________________________________
> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>
> On Wed, Feb 22, 2017 at 6:10 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
> wrote:
>
>> The training process drops unrenderable words. So the letters not
>> included in the font will get dropped, if you use a combined text with
>> multiple languages and run text2image with different fonts.
>>
>> You will then get some images with text in one language and some in the
>> other.
>>
>> However, I don't know how successful this will be. You will need a large
>> amount of text to train.
>>
>> I have not had much success in training 4.0. please share your
>> experiences if you try the above approach.
>>
>> - excuse the brevity, sent from mobile
>>
>> On 22-Feb-2017 3:24 PM, "dipthomas" <notifications@github.com> wrote:
>>
>>> @Shreeshrii <https://github.com/Shreeshrii> , I am using Tesseract 4.0,
>>> and I want to train a model including English, Chinese and some math symbol
>>> like ‚ñ≥.
>>> Now the problem is I can not generate the training image via a single
>>> font. (text2image)
>>>
>>> ‚Äî
>>> You are receiving this because you were mentioned.
>>> Reply to this email directly, view it on GitHub
>>> <https://github.com/tesseract-ocr/tesseract/issues/730#issuecomment-281621699>,
>>> or mute the thread
>>> <https://github.com/notifications/unsubscribe-auth/AE2_o9P6-UMdzYkJsUelGKI3dxeOj75Jks5rfAXGgaJpZM4MF7F5>
>>> .
>>>
>>
>
 @dipthomas If problem is resolved, please close the issue. Thanks! @Shreeshrii Your reply is very detailed, thank you Hi @Shreeshrii ,
I am looking for a trained data for the bullet character. It should work even if we are using mulitple language in a single string.

Can you please provide the trained data for bullet character or guide me how to do do this? I tried Latin, we didnt get bullet character!

tried Combine_tessdata, using that i am able to unpack that trained data.Can you help us how to see the uncharset contains the bullet character?
Can you please help on this?

Thanks its (U+2022) ‚Ä¢  Images and Ground truth at 
https://github.com/Shreeshrii/tess4eval_marathi

OCR eval reports at
https://shreeshrii.github.io/tess4eval_marathi/ If the the source of the issue is the traineddata, maybe you should move this issue to the langdata issues.   I tried to compile 3.05.00 on a rasperry pi with rasperian 4.1.19+ and get the following error:

libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../openc
l -I../neural_networks/runtime -I../cube -I/usr/local/include/leptonica -g -O2 -MT thresholder.lo -MD -MP -MF .deps/thresholder.Tpo -c thresholder.cpp  -fPIC -DPIC -o .libs/thresholder.o
thresholder.cpp: In member function 'virtual void tesseract::ImageThresholder::ThresholdToPix(tesseract::PageSegMode, Pix**)':
thresholder.cpp:187:20: error: 'nullptr' was not declared in this scope
Makefile:482: recipe for target 'thresholder.lo' failed
make[2]: *** [thresholder.lo] Error 1

This maybe relates to #535 and its fix in here https://github.com/tesseract-ocr/tesseract/blob/master/ccmain/thresholder.cpp#L187?  Searching for a place to introduce JBig2-compression into my quite typical workflow I stumbled upon tesseract actually generating sandwiches - which is nice. Are there any plans to offer alternative to the, i assume, flate-compression currently used? >Are there any plans to offer alternative to the, i assume, flate-compression currently used?

https://github.com/tesseract-ocr/tesseract/blob/ca16a08c10/api/pdfrenderer.cpp#L729  I want to build a model with a image of bar code as input and output the number sequence corresponding to the bar code. 
Input:
![image](https://cloud.githubusercontent.com/assets/10412402/23064393/df2e88a0-f54a-11e6-860b-c0ea20f1575f.png)

Output:
6922872789071

This task is similar to speech recognition. Can tesseract be used to do this?
  I know, that `tesseract --version` outputs the exact version and github commit hash, **if** it was compiled with `./configure --enable-debug`, example:
```
tesseract 4.00.00alpha-278-gc768b58
 leptonica-1.74.1
  libjpeg 6b (libjpeg-turbo 1.3.1) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 Found AVX
 Found SSE
```

I wonder, why this is not output, when the configuration setting was not given and I suggest to modify the build code so that the version and github commit hash is **always** shown with the `--version`command.  Yes. I agree, adding version info with github commit hash in non-debug builds will be very helpful.

An earlier request - https://github.com/tesseract-ocr/tesseract/issues/581#issuecomment-267339390 Needs change in 

https://github.com/tesseract-ocr/tesseract/blob/fd0683f9e03934bbdf7fbebb4d21d64c37b68bc0/api/baseapi.cpp#L140
 @zdenop Is https://github.com/tesseract-ocr/tesseract/blob/fd0683f9e03934bbdf7fbebb4d21d64c37b68bc0/api/baseapi.cpp#L140 the only change needed, and would you accept a corresponding pull request ? @zdenop Where exactly is your problem to print the GIT_REV when users use --version ?

I *have a problem when, as an expert, I run always the latest version, but sometimes after git pull the latest build is not the "installed" build. As a user I want to have the fastest code, i.e. built *without* --enable-debug.

I again request to think over it, and to always - if available - burn the GIT_REV into the code. I ask you for this. Not using `--enable-debug` increases processing speed about 6%.
  @zdenop, what about using GIT_REV only for versions without tag, no matter whether it is a debug or a release build? Then released stable versions would not show GIT_REV. >Not using --enable-debug increases processing speed about 6%.

Only ~6%? With LSTM mode?

https://github.com/tesseract-ocr/tesseract/issues/40#issuecomment-263432042 BTW, maybe we should add another debug/optimization option with `-Og`?
https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html  I compile tesseract 3.04 with OpenCL support and I install it on an Ubuntu 16.04 64-bit machine. The machine  has an intel core i5 CPU and an nvidia geforce 1080gtx with cuda 8.0 GPU. 

When I run tesseract from command line  I get:

$ tesseract phototest.tif out -l eng
tesseract: /usr/local/cuda/lib64/libOpenCL.so.1: no version information available (required by tesseract)
[DS] Profile read from file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:GeForce GTX 1080 score is 0.106336
[DS] Device[2] 0:(null) score is 0.895098
[DS] Selected Device[1]: "GeForce GTX 1080" (OpenCL)
Tesseract Open Source OCR Engine v3.04.02dev with Leptonica

I make a lot of tests using C++ API, python wrapper and command line but I didn‚Äôt notice any improvement on speed. Do I miss something? Well I install tesseract 3.05.00 (I also install leptonica from source) but the result was the same. No speed improvement. How can we explain that I don‚Äôt have any speed up?
Please note (see below) a warning related to libOpenCL.so ‚Äúno version information available (required by tesseract)‚Äù.  

`
$ tesseract -v
tesseract: /usr/local/cuda/lib64/libOpenCL.so.1: no version information available (required by tesseract)
tesseract 3.05.00
 leptonica-1.74.1
  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8

 OpenCL info:
  Found 1 platforms.
  Platform name: NVIDIA CUDA.
  Version: OpenCL 1.2 CUDA 8.0.46.
  Found 1 devices.
    Device 1 name: GeForce GTX 1080.



$ tesseract test.tif out
tesseract: /usr/local/cuda/lib64/libOpenCL.so.1: no version information available (required by tesseract)
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performing profiling.

[DS] Device: "GeForce GTX 1080" (OpenCL) evaluation...
[DS] Device: "GeForce GTX 1080" (OpenCL) evaluated
[DS]          composeRGBPixel: 0.015255 (w=1.2)
[DS]            HistogramRect: 0.009756 (w=2.4)
[DS]       ThresholdRectToPix: 0.007360 (w=4.5)
[DS]        getLineMasksMorph: 0.004570 (w=5.0)
[DS]                    Score: 0.097692

[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
[DS]          composeRGBPixel: 0.015348 (w=1.2)
[DS]            HistogramRect: 0.058428 (w=2.4)
[DS]       ThresholdRectToPix: 0.018490 (w=4.5)
[DS]        getLineMasksMorph: 0.122624 (w=5.0)
[DS]                    Score: 0.854966
[DS] Scores written to file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:GeForce GTX 1080 score is 0.097692
[DS] Device[2] 0:(null) score is 0.854966
[DS] Selected Device[1]: "GeForce GTX 1080" (OpenCL)
Tesseract Open Source OCR Engine v3.05.00 with Leptonica`  Forexample:
In the 'eng.tessdata',There are nine file.
But i want delete some file and create a new 'eng.tessdata'.
what can i do? see
https://github.com/tesseract-ocr/tesseract/blob/master/doc/combine_tessdata.1.asc  For latest version, use OEM 1 for the LSTM engine. In the first
experimental version it was OEM 4.

- excuse the brevity, sent from mobile

On 13-Feb-2017 2:59 PM, "majorbossy" <notifications@github.com> wrote:

> test.pdf
> <https://github.com/tesseract-ocr/tesseract/files/770565/test.pdf>
> [image: test]
> <https://cloud.githubusercontent.com/assets/25739284/22877715/9d091ece-f1ce-11e6-867c-dd7fe106ec43.png>
>
> test.hocr.txt
> <https://github.com/tesseract-ocr/tesseract/files/770570/test.hocr.txt>
>
> Hi
>
> In the attached hocr you can search for "bbox 0 0" and see that there are
> multiple occurrences of ocrx_word artifacts where the bbox coordinates are
> the same as those of the ocr_page artifact.
>
> These ocrx_word occurrences seem to be occurring in relation to vertical
> and horizontal lines in the image.
>
> If you search for "Party" in the pdf, you will see that the bbox for the
> last two instances goes out to the end of the underlining, despite the fact
> that the text has been correctly identified as "Party A" and "Party B"
>
> The image was redacted using Paint and Windows clipboard, but despite any
> damage I have inflicted on the file, the text is still correctly identified.
> Whatever the state of the image, it can't be correct for an ocrx_word to
> have the same coordinates as that of the ocr_page.
>
> I downloaded the Windows Installer version from UB Mannheim on 18/1/17
> (the current version doesn't run on my system!):
>
> tesseract 4.00.00alpha
> leptonica-1.73
> libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.6.20 :
> libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.3 : libopenjp2 2.1.0
>
> Windows 10
> Version 10.0.14393 Build 14393
>
> The command I'm running is:
> "C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" -oem 4 -psm 6 -c
> tessedit_create_hocr=1 -c tessedit_create_pdf=1 test.png test
>
> I've turned the auto psm off, since it seems to lose the right-hand column
> of tables completely, and I'd rather carry out my own psm.
>
> OEM 4 is just amazing. Great work!!
>
> Major B
>
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/718>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o8txKL5YYMkvzE2q3D9XehmQ2Qekks5rcCKEgaJpZM4L-9x1>
> .
>
 Maybe we should print a warning:

>oem 4 was selected. That value is out of range [0-3].
Using oem 3, which is the default mode.

Something similar should be used for psm out-of-range value. you need
--oem and --psm now

instead of -oem
-psm is still accepted for historical reasons

two dashes instead of one

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Mon, Feb 13, 2017 at 4:07 PM, majorbossy <notifications@github.com>
wrote:

> Ok. Looks like I need to wait for a working build of the latest version
> (I'm a java-restricted etl/sql developer).
>
> If I use the latest UB Mannheim build with:
>
> "C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" -oem 1 -psm 3 -c
> tessedit_create_hocr=1 -c tessedit_create_pdf=1 test.png test
>
> I get:
>
> read_params_file: parameter not found: √´PNG
>
> And if I try:
>
> "C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" test.png test
>
> I get:
>
> Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
> DotProductAVX can't be used on Android
>
> And the exe bombs out. I think this is a known issue, and I just need to
> wait.
>
> Thanks
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/718#issuecomment-279350458>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oy9IIzaIJ_zxV-dRc18b9ydG2vSjks5rcDKCgaJpZM4L-9x1>
> .
>
 you could try

Please try:
https://smani.fedorapeople.org/tmp/gImageReader_3.2.1_qt5_i686_tesseract4.0.0.git2f10be5.exe
https://smani.fedorapeople.org/tmp/gImageReader_3.2.1_qt5_x86_64_tesseract4.0.0.git2f10be5.exe

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Mon, Feb 13, 2017 at 4:21 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
wrote:

> you need
> --oem and --psm now
>
> instead of -oem
> -psm is still accepted for historical reasons
>
> two dashes instead of one
>
> ShreeDevi
> ____________________________________________________________
> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>
> On Mon, Feb 13, 2017 at 4:07 PM, majorbossy <notifications@github.com>
> wrote:
>
>> Ok. Looks like I need to wait for a working build of the latest version
>> (I'm a java-restricted etl/sql developer).
>>
>> If I use the latest UB Mannheim build with:
>>
>> "C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" -oem 1 -psm 3 -c
>> tessedit_create_hocr=1 -c tessedit_create_pdf=1 test.png test
>>
>> I get:
>>
>> read_params_file: parameter not found: √´PNG
>>
>> And if I try:
>>
>> "C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" test.png test
>>
>> I get:
>>
>> Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
>> DotProductAVX can't be used on Android
>>
>> And the exe bombs out. I think this is a known issue, and I just need to
>> wait.
>>
>> Thanks
>>
>> ‚Äî
>> You are receiving this because you commented.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/718#issuecomment-279350458>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AE2_oy9IIzaIJ_zxV-dRc18b9ydG2vSjks5rcDKCgaJpZM4L-9x1>
>> .
>>
>
>
 >"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" -oem 1 -psm 3 -c tessedit_create_hocr=1 -c tessedit_create_pdf=1 test.png test

That is a wrong usage. It should be:
>"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" test.png test -oem 1 -psm 3 -c tessedit_create_hocr=1 -c tessedit_create_pdf=1
 @stweil - problem with latest 4.o windows build

I am able to reproduce the problem

```
C:\Users\User\shree>"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe"  -- version
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error during processing.
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 03658DF0 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddatalstm-punc-dawg)
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 03658EA0 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddatalstm-word-dawg)
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 03658F50 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddatalstm-number-dawg)
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 03668ED8 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddatapunc-dawg)
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 03658D90 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddataword-dawg)
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 03658E40 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddatanumber-dawg)
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 0300D858 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddatabigram-dawg)
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 0300D628 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddatafreq-dawg)

C:\Users\User\shree>"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe"  san001.png test --oem 1
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 18 diacritics
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
``` Hi there,

if you still get the message "DotProductAVX can't be used on Android", could it be that you try to run 32-bit code on a 64-bit machine ? This is what I'm experiencing.

If I build the lastest version with MINGW64-32 bit and try to run on a 64-bit Windows, I get this error and a crash.

If I build with 64 bit all is fine running on Windows 64 bit.
If I build with 32 bit all is fine running on Windows 32 bit.

Maybe somebody could look into the code again and check if the test for AVX is performed at runtime, not at build time.

Greetings. I will uninstall and check again tomorrow.  @stweil You are right, I messed up in giving the version command.

I reinstalled versions for 2/2/17 as well as 1/30/17. Getting the error regarding AVX for both versions.

Is it possible that your local version of binary is different from the one linked from wiki?

```
C:\Users\User\shree>"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe"  san001.png test --oem 1
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 18 diacritics
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.

C:\Users\User\shree>"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe"  --version
tesseract 4.00.00alpha
 leptonica-1.74.1
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.5.0) : libpng 1.6.20 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.3 : libopenjp2 2.1.0

 Found AVX
 Found SSE
``` Hi all

I think this is due to me abusing the psm. It's probably a bit much to switch off segmentation and still expect tess to handle tables properly.

I don't get this issue when the psm is 11.

Thanks  # Visarga vs Colon

Please see https://shreeshrii.github.io/tess4eval-san/

Visarga being recognized as colon etc. 
This will be specially applicable for sanskrit where `Visarga ‡§É`  is quite common.

Ground Truth
```
‡§∞‡§æ‡§ú‡•á‡§®‡•ç‡§¶‡•ç‡§∞‡•ã ‡§≠‡•Ç‡§™‡§§‡•Ä ‡§∞‡•Ç‡§¢‡•ã ‡§Æ‡§æ‡§≤‡•Ä ‡§∏‡§Ç‡§∏‡§æ‡§∞‡§∏‡§æ‡§∞‡§•‡§ø‡§É ‡•§ ‡§®‡§ø‡§§‡•ç‡§Ø‡§É ‡§∏‡§Æ‡•ç‡§™‡•Ç‡§∞‡•ç‡§£‡§ï‡§æ‡§Æ‡§∂‡•ç‡§ö ‡§≠‡§ï‡•ç‡§§‡§ï‡§æ‡§Æ‡§ß‡•Å‡§ó‡•Å‡§§‡•ç‡§§‡§Æ‡§É ‡•• ‡•¨‡•´ ‡§ó‡§£‡§™‡§É ‡§ï‡•á‡§∂‡§µ‡•ã ‡§≠‡•ç‡§∞‡§æ‡§§‡§æ ‡§™‡§ø‡§§‡§æ ‡§Æ‡§æ‡§§‡§æ‡§Ω‡§• ‡§Æ‡§æ‡§∞‡•Å‡§§‡§ø‡§É ‡•§ ‡§∏‡§π‡§∏‡•ç‡§∞‡§Æ‡•Ç‡§∞‡•ç‡§ß‡§æ ‡§∏‡§π‡§∏‡•ç‡§∞‡§æ‡§∏‡•ç‡§Ø‡§É ‡§∏‡§π‡§∏‡•ç‡§∞‡§æ‡§ï‡•ç‡§∑‡§É ‡§∏‡§π‡§∏‡•ç‡§∞‡§™‡§æ‡§§‡•ç ‡•• ‡•¨‡•¨
```

OCRed text
```
‡§∞‡§æ‡§ú‡•á‡§®‡•ç‡§¶‡•ç‡§∞‡•ã ‡§≠‡•Ç‡§™‡§§‡•Ä ‡§∞‡•Ç‡§¢‡•ã ‡§Æ‡§æ‡§≤‡•Ä ‡§∏‡§Ç‡§∏‡§æ‡§∞‡§∏‡§æ‡§∞‡§•‡§ø: ‡•§ ‡§®‡§ø‡§§‡•ç‡§Ø: ‡§∏‡§Æ‡•ç‡§™‡•Ç‡§∞‡•ç‡§£‡§ï‡§æ‡§Æ‡§∂‡•ç‡§ö ‡§≠‡§ï‡•ç‡§§‡§ï‡§æ‡§Æ‡§ß‡•Å‡§ó‡•Å‡§§‡•ç‡§§‡§Æ: ‡•§‡•§ ‡•¨‡•´ ‡§ó‡§£‡§™: ‡§ï‡•á‡§°‡§æ‡§µ‡•ã ‡§≠‡•ç‡§∞‡§æ‡§§‡§æ ‡§™‡§ø‡§§‡§æ ‡§Æ‡§æ‡§§‡§æ‡§Ω‡§• ‡§Æ‡§æ‡§∞‡•Å‡§§‡§ø; ‡•§ ‡§∏‡§π‡§∏‡•ç‡§∞‡§Æ‡•Ç‡§∞‡•ç‡§ß‡§æ ‡§∏‡§π‡§∏‡•ç‡§∞‡§æ‡§∏‡•ç‡§Ø: ‡§∏‡§π‡§∏‡•ç‡§∞‡§æ‡§ï‡•ç‡§∑: ‡§∏‡§π‡§∏‡•ç‡§∞‡§™‡§æ‡§§‡•ç ‡•§‡•§ ‡•¨‡•¨
``` I suggest to remove the following from the desired characters list for Devanagari script languages:

```
%
&
:
‚Ç¨
$
¬£
```

 # Nukta 

Looking at the new evaluation page, another error is being seem, relating to nukta . OCRed text does not seem to have any.

GT files are using decomposed version of nukta letters, rather than combined form, as dictated by normalisation.
 # Northern style orthography

Another error that I have noted for Devanagari is that Northern style orthography of some letters is not being recognized correctly. 

See sample iamges of the two styles under 'Download fonts' section on 
http://www.sanskritweb.net/cakram/

different la forms displayed in 
http://www.omniglot.com/writing/devanagari.htm

More old style sample text - 
pages 21-24
http://ctan.imsc.res.in/language/devanagari/velthuis/doc/manual.pdf
various pages
http://www.sanskritweb.net/itrans/s99fonts.pdf

Ref: copy of old issue which has links to pages with old style text

https://github.com/gxrxrdx/tesseract-ocr/issues/1360 # Devanagari Varnamala - Alphabet

A listing of the basic Devanagari Alphabet is also not being recognized correctly.

see https://shreeshrii.github.io/tess4eval_deva/ # Eyelash ra - RA vs RRA

Ref: https://r12a.github.io/scripts/devanagari/block

```
U+0930 DEVANAGARI LETTER RA

When used as a half-consonant in Marathi or Newari, 
this character uses the 'eyelash-RA' shape, 
eg. ‡§∞‡•ç‚Äç. To create this shape in Unicode, follow 
U+0930 DEVANAGARI LETTER RA ‡§∞ + U+094D DEVANAGARI SIGN VIRAMA  ‡•ç with U+200D ZERO WIDTH JOINER.

The eyelash-RA is transcribed as rÃÜ.
```

```
U+0931 DEVANAGARI LETTER RRA

Description in the Unicode standard:
‚Ä¢ for transcribing Dravidian alveolar r
‚Ä¢ half form is represented as 'Eyelash RA'

·πü in ISO 15919
```

Tesseract is recognizing it as the second case -  U+0931 DEVANAGARI LETTER RRA  + U+094D DEVANAGARI SIGN VIRAMA  ‡•ç

see samples from mar.Adobe_Devanagari.exp0.txt to mar.e-Nagari_OT.exp0.txt in https://shreeshrii.github.io/tess4eval_marathi/index-hin.html

  From #707:

@amitdo commented:
>I also think we should release a last 3.0x version in the upcoming 2-6 weeks.

@zdenop  commented:
>If 3.05 should be the last version with legacy OCR Engine (old engine) then there should be possibility to read [OCR result from memory](https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-dev/mZ2IUsvWgbY/2yz-b1cUAgAJ).

@jbreiden commented:
>https://wiki.ubuntu.com/ZestyZapus/ReleaseSchedule
>
>Feb 16 is the final deadline for changes to Ubuntu 17.04. I am not comfortable shipping anything from 4.x to these users, but we can consider taking a snapshot of the 3.0.5 branch. It does have some bug and compatibility fixes that are good for users. Regarding training data, I would not ship an update that at all. This would be purely be a code update.
>
>I know the long standing issue has been restoring an API call (last seen in version 3.0.2) to send results to memory instead of file. I respect that idea, but we don't have it, and it's not that easy to add. I think it is fair to say that it would be impossible before deadline. So the question is, do we ship an update to users this cycle or not. And if so, should I take a snapshot? And if so, what would it be called?
>
>A few more thoughts that are somewhat related
>
>* I see no reason that this has to be the last ever release on the 3.0.x branch.
>*  My guess is by the next next release in Oct 2017 that 4.x will be ready for the vast majority of users
>*  I'm not planning to ship both 3.0.x and 4.x at the same time with Debian/Ubuntu. I think it will be very rare for people to want both, and those who do will be advanced users who can work from source code.

@Shreeshrii commented:
>@jbreiden Good idea to do a code update for 3.05 for Ubuntu 17.04. There are a number of bug fixes and changes and it would be good to get them out to the users. Thanks!
 I added [Release Notes for 3.05](https://github.com/tesseract-ocr/tesseract/wiki/ReleaseNotes#to-be-released-as-v305---in-feb-2017-), based on the [3.05 branch](https://github.com/tesseract-ocr/tesseract/commits/3.05).
 @zdenop, @egorpugin 

Some minor fixes to 3.05:

README.md
>The latest stable version is 3.04.01, released in February 2016.

=>
>The latest stable version is 3.05, released in February 2017.

tesseract/api/baseapi.h
`#define TESSERACT_VERSION_STR "3.05.00dev"`
=>
`#define TESSERACT_VERSION_STR "3.05.00"`

configure.ac
`AC_INIT([tesseract], [3.05.00dev], [https://github.com/tesseract-ocr/tesseract/issues])`
=>
`AC_INIT([tesseract], [3.05.00], [https://github.com/tesseract-ocr/tesseract/issues])`

```
PACKAGE_YEAR=2015
PACKAGE_DATE="07/11"
```
=>
```
PACKAGE_YEAR=2017
PACKAGE_DATE="02/14"
```

ChangeLog
>
See [ReleaseNotes](https://github.com/tesseract-ocr/tesseract/wiki/ReleaseNotes
)

AUTHORS
Please add Nick White to the Community Contributors.

CONTRIBUTING.md
https://github.com/tesseract-ocr/tesseract/commit/bf9f40cac631



 So, when? Maybe you want to use this strategy:
 
1. Make one unified deb package for Debian 9, Ubuntu 16.04, Ubuntu 17.04.
2. Push it to Debian & Ubuntu 'backports' repos. For Debian 9 and Ubuntu 17.04 you will need to wait until they are released. For Ubuntu 16.04 you can start when you want to. @zdenop 

I think, you should tag the 3.05 branch with the 3.05.0 release. It can be updated in case there are any additional changes. @manisandro

Have you tried building gImageReader with 3.05  release candidate?

https://github.com/manisandro/gImageReader/issues/156 Hi, 
I'm the maintainer of gimagereader in Debian. I just checked with the debs @jbreiden provided. Gimagereader crashes when compiled against 3.0.4 but run with 3.0.5, see https://gist.github.com/innir/a4662ad7043c9cc27e9f7bdaff8f8acf.

Recompiling gImageReader against 3.0.5 resolves the crash.

This is really easy to fix upstream. You just have to bump the SONAME if your symbols change! Not too hard to get! Please make a 3.0.5.1 release and bump the SONAME!

Best,
Philip @manisandro no problem on your side, gImageReader works fine with 3.0.5 :) Thanks for checking @innir , I haven't yet had time to build 3.0.5. @jbreiden I think it's in Recognize() or one of the functions Recognize() calls. Hard to tell as the next two lines in the crash log are empty :(
Anyway, if symbols are removed, the SONAME has to be bumped, if symbols are only added that's not necessary - AFAIR. Those ABI trackers are good, but I'm not sure if they catch things like this: https://github.com/tesseract-ocr/tesseract/pull/259/files
 abipkgdiff output (comparing 3.04.01 and 3.05.00):

    ================ changes of libtesseract.so.3.0.4===============c++filt 
    Functions changes summary: 0 Removed, 0 Changed, 0 Added function
    Variables changes summary: 0 Removed, 0 Changed, 0 Added variable
    Function symbols changes summary: 11 Removed, 41 Added function symbols not referenced by debug info
    Variable symbols changes summary: 0 Removed, 3 Added variable symbols not referenced by debug info

    11 Removed function symbols not referenced by debug info:

        WriteParamDesc(_IO_FILE*, unsigned short, PARAM_DESC*)
        read_list(char const*)
        GENERIC_2D_ARRAY<tesseract::TrainingSampleSet::FontClassInfo>::Resize(int, int, tesseract::TrainingSampleSet::FontClassInfo const&)
        WERD_RES::FakeWordFromRatings()
        tesseract::DocumentCache::LoadDocuments(GenericVector<STRING> const&, char const*, bool (*)(STRING const&, GenericVector<char>*))
        tesseract::DocumentCache::GetPageBySerial(int)
        tesseract::DawgPositionVector::~DawgPositionVector(), aliases tesseract::DawgPositionVector::~DawgPositionVector()
        tesseract::DawgPositionVector::~DawgPositionVector()
        tesseract::Dict::Load(tesseract::DawgCache*)
        tesseract::Dict::ProcessPatternEdges(tesseract::Dawg const*, tesseract::DawgPosition const&, int, bool, tesseract::DawgPositionVector*, PermuterType*) const
        tesseract::ImageData::PreScale(int, Pix**, int*, int*, GenericVector<TBOX>*) const

    41 Added function symbols not referenced by debug info:

        TessBaseAPIDetectOrientationScript
        WriteParamDesc(_IO_FILE*, unsigned short, PARAM_DESC const*)
        GenericVector<tesseract::DawgPosition>::clear()
        STRING::SkipDeSerialize(bool, tesseract::TFile*)
        WERD_RES::FakeWordFromRatings(PermuterType)
        tesseract::TessBaseAPI::GetTSVText(int)
        tesseract::TessBaseAPI::GetHOCRText(ETEXT_DESC*, int)
        tesseract::TessBaseAPI::AnalyseLayout()
        tesseract::TessBaseAPI::DetectOrientationScript(int*, float*, char const**, float*)
        tesseract::ColPartition::SortByBBox(void const*, void const*)
        tesseract::DocumentData::SetDocument(char const*, char const*, long long, bool (*)(STRING const&, GenericVector<char>*))
        tesseract::DocumentData::IsPageAvailable(int, tesseract::ImageData**)
        tesseract::DocumentData::LoadPageInBackground(int)
        tesseract::DocumentData::UnCache()
        tesseract::DocumentCache::TotalPages()
        tesseract::DocumentCache::LoadDocuments(GenericVector<STRING> const&, char const*, tesseract::CachingStrategy, bool (*)(STRING const&, GenericVector<char>*))
        tesseract::DocumentCache::GetPageRoundRobin(int)
        tesseract::DocumentCache::GetPageSequential(int)
        tesseract::DocumentCache::CountNeighbourDocs(int, int)
        tesseract::ParamsVectors::~ParamsVectors()
        tesseract::ParamsVectors::~ParamsVectors(), aliases tesseract::ParamsVectors::~ParamsVectors()
        tesseract::TessTsvRenderer::AddImageHandler(tesseract::TessBaseAPI*)
        tesseract::TessTsvRenderer::EndDocumentHandler()
        tesseract::TessTsvRenderer::BeginDocumentHandler()
        tesseract::TessTsvRenderer::TessTsvRenderer(char const*), aliases tesseract::TessTsvRenderer::TessTsvRenderer(char const*)
        tesseract::TessTsvRenderer::TessTsvRenderer(char const*, bool)
        tesseract::TessTsvRenderer::TessTsvRenderer(char const*)
        tesseract::TessTsvRenderer::TessTsvRenderer(char const*, bool), aliases tesseract::TessTsvRenderer::TessTsvRenderer(char const*, bool)
        tesseract::TessTsvRenderer::~TessTsvRenderer()
        tesseract::TessTsvRenderer::~TessTsvRenderer()
        tesseract::TessTsvRenderer::~TessTsvRenderer(), aliases tesseract::TessTsvRenderer::~TessTsvRenderer()
        tesseract::ReCachePagesFunc(void*)
        tesseract::Dict::FinishLoad()
        tesseract::Dict::SetupForLoad(tesseract::DawgCache*)
        tesseract::Dict::Load(char const*, STRING const&)
        tesseract::DawgCache::~DawgCache(), aliases tesseract::DawgCache::~DawgCache()
        tesseract::DawgCache::~DawgCache()
        tesseract::ImageData::SkipDeSerialize(bool, tesseract::TFile*)
        tesseract::Dict::ProcessPatternEdges(tesseract::Dawg const*, tesseract::DawgPosition const&, int, bool, tesseract::DawgArgs*, PermuterType*) const
        tesseract::Dict::IsSpaceDelimitedLang() const
        tesseract::ImageData::PreScale(int, int, float*, int*, int*, GenericVector<TBOX>*) const

    3 Added variable symbols not referenced by debug info:

        typeinfo for tesseract::TessTsvRenderer
        typeinfo name for tesseract::TessTsvRenderer
        vtable for tesseract::TessTsvRenderer > I've heard about this ABI tracker. Maybe it's possible to add tesseract (& leptonica) there somehow.

Done:

https://abi-laboratory.pro/tracker/timeline/tesseract/
https://abi-laboratory.pro/tracker/timeline/leptonica/

![tesseract-2](https://cloud.githubusercontent.com/assets/1517837/24391524/af496122-13a0-11e7-8dd5-c138319425db.png)

About the tracker: https://abi-laboratory.pro/index.php?view=abi-tracker Next release - 3.05.1
https://groups.google.com/forum/#!topic/tesseract-dev/7vwsJNCAUcQ  PDF Output being a standard feature has some problems in Windows.
If you use stdout as tesseract output and pipe or redirect the PDF Output to another Executable, e.g pdftotext, every linefeed is converted to CR/LF in the resulting PDF, corrupting this PDF file.

It could easily prevented by implementing

`#ifdef WIN32`
`  if (_setmode(_fileno(stdout), _O_BINARY) == -1)`
`    tprintf("ERRROR: cout to binary: %s, strerror(errno));`
`#endif`

somewhere near TessPDFRenderer call, maybe in tesseractmain.cpp.
You would need to include fcntl.h and io.h too.

I tested it and it worked fine redirecting and piping in Windows.

Many thanks to the whole bunch of developers.

wadex1
 Hi again,
I'm not sure about the appropriate location to put the code.
If all output is sent binary, not only PDF but text output will be binary too.
I don't know if this breaks any other compatibilities, especially with piping or redirecting the text output in Windows.

Maybe somebody could look for the correct place to insert.

I think this modification is quite necessary if we want to pipe PDF output to e.g. pdftotext.exe in Windows.
Running pdftotext on the tesseract PDF output is the only way for me to have text output with a decent layout and piping would save me from using temporary files.

Best regards  To recap, when a Tesseract PDF (3.0x or 4.x) is run through Ghostscript the OCR layer will be mangled. Ghostscript's pdfwrite (`gs -sDEVICE=pdfwrite -o out.pdf in.pdf`) will display spaces between every character and get confused about word boundaries. Other PDF viewers tend to work but usually have problems with searching for text, because they read as the text as having spaces in between.

Before (`pdftext`)
```
Portez ce vieux whisky au juge
blond qui fume sur son √Æle
```

After
```
P o r t e z c e v i e u x w h i s k y a u j u g e
o n d q u i f u m e s u r s o n √Æle
```

(A related issue I reported was fixed in Ghostscript 9.20, but unfortunately that is not complete solution. Ghostscript <9.20 *also* corrupts any characters above U+00FF that happen to be present.)

There are lots of reasons someone might run a Tesseract PDF through Ghostscript pdfwrite: producing lower DPI renderings, PDF/A conversion, merging PDFs, changing paper sizes, sanitizing potential security holes like Javascript. There are also a lot of programs and services that use Ghostscript internally, sometimes without the user being aware of this. It's unfortunate that Tesseract PDFs don't play nicely with Ghostscript.

Ken Sharp (Ghostscript PDF dev) swears up and down that he can't do anything about it, essentially because Ghostscript interprets the input PDF into a page description language that is then rendered using pdfwrite. The output is visually identical, but otherwise the file is rewritten. Artifex also views preserving OCR text or other metadata as a bonus; if pdfwrite produces visually identical output they are satisfied.

See this comment from 2015:
https://bugs.ghostscript.com/show_bug.cgi?id=696116

Ken Sharp explains the essential difference is that the `/DW` (default glyph width) parameter on the GlyphLessFont is not understood by GhostPDL so it sets `/DW 0` and manually positions each glyph (the `-500`). 

```
[(T)-500(h)-500(e)-500]TJ
```

In English, Tesseract renders OCR with a font whose glyphs are 500 arbitrary units wide. Ghostscript reinterprets this as glyphs that are 0 units wide and moves the cursor 500 units between characters, and insists that it's the same thing.

I tried surgery on a pdfwrite-mangled file. I removed all of the `-500` offsets, set to `/DW 500` on the main font object, and removed the individual glyph width array `/W [...]` from the same. That works. (pdfwrite makes other minor changes to the PDF output too, but these don't matter as far as I know.) Writing a little script to fix mangled PDFs is possible, but it would be better to find a workaround.

So, is there any possibility of adjusting the glyphless font to work more like what Ghostscript expects so it survives the trip... without losing all of the other considerable and much appreciated effort that has gone into making glyphless work great with most other interpreters?

What are the commercial OCR tools doing to avoid similar issues?  Yes, I should have included an example, but it seems to affect just about everything so it didn't seem that hard to come up with one....

Tesseract 4.00alpha (commit 2f10be5)

```
$ sha1sum tessdata/pdf.ttf
ac5300b169c99e90e9825dd8859b8a850edde22f  tessdata/pdf.ttf
```

Using testing/phototest.tif

```
$ tesseract --tessdata-dir . --oem 1  testing/phototest.tif _phototest pdf
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
$ pdftotext _phototest.pdf  -
This is a lot of 12 point text to test the
ocr code and see if it works on all types
of file format.
The quick brown dog jumped over the
lazy fox. The quick brown dog jumped
over the lazy fox. The quick brown dog
jumped over the lazy fox. The quick
brown dog jumped over the lazy fox.

$ gs -sDEVICE=pdfwrite -o _phototest_gs.pdf _phototest.pdf
GPL Ghostscript 9.20 (2016-09-26)
Copyright (C) 2016 Artifex Software, Inc.  All rights reserved.
This software comes with NO WARRANTY: see the file PUBLIC for details.
Processing pages 1 through 1.
Page 1

$ pdftotext _phototest_gs.pdf -
T h i s
o c r

i s a

l o t o f

c o d e

a n d

1 2

p o i n t

s e e

t e x t

t o

if it w o r k s
```

<details>
<summary>click to see the rest of pdftotext</summary>

```
t e s t

o n

t h e

a l l t y p e s

o f f i l e f o r m a t .
T h e

q u i c k

l a z y

f o x .

T h e

q u i c k

o v e r

t h e

l a z y

f o x .

T h e

q u i c k

j u m p e d

o v e r

t h e

l a z y

f o x .

b r o w n

b r o w n

d o g

j u m p e d

d o g

j u m p e d

b r o w n

o v e r

o v e r

d o g

t h e

b r o w n

T h e

t h e

j u m p e d
d o g

q u i c k

l a z y

f o x .

```
</details>


After Tesseract, before Ghostscript
[_phototest.pdf](https://github.com/tesseract-ocr/tesseract/files/765802/_phototest.pdf)

After Ghostscript
[_phototest_gs.pdf](https://github.com/tesseract-ocr/tesseract/files/765803/_phototest_gs.pdf)

After Ghostscript, streams uncompressed with qpdf for easy viewing
[_phototest_gs_uncompress.pdf](https://github.com/tesseract-ocr/tesseract/files/765804/_phototest_gs_uncompress.pdf)

I also tried omitting `--oem`, not that we would expect this to make a difference. Tesseract 3.04.01 behavior is similar. I replicated this is in a Docker container with Tesseract 3.04.01 and Ghostscript 9.19. 

Before Ghostscript, here is Acrobat XI showing that text search for words works normally.
![image](https://cloud.githubusercontent.com/assets/1825843/22815997/ff31ddd8-ef13-11e6-9508-b98bcb3a070b.png)

After Ghostscript, here is Acrobat showing that a search for the word "p o i n t" matches because it is now convinced that there are spaces between each character. The highlighting is now misaligned as well.
![image](https://cloud.githubusercontent.com/assets/1825843/22815980/e924b6c8-ef13-11e6-9780-a77f6783cb28.png)

 Well, I tried `fonttools` for fun, and to my surprise I might have found a fix ‚Äì with the important caveat that I have no idea what I'm doing. 

```diff
--- pdf.ttx_original	2017-02-09 22:43:11.000000000 -0800
+++ pdf.ttx	2017-02-09 22:40:31.000000000 -0800
@@ -121,8 +121,8 @@
   </OS_2>
 
   <hmtx>
-    <mtx name=".notdef" width="0" lsb="0"/>
-    <mtx name=".null" width="0" lsb="0"/>
+    <mtx name=".notdef" width="1024" lsb="0"/>
+    <mtx name=".null" width="1024" lsb="0"/>
   </hmtx>
 
   <cmap>
```

I took Ken's remark that Ghostscript didn't like individual glyphs width a width of 0, so I gave them a width equal to full the glyph box. (1024 in .ttx units, 500 in PDF font units, from what I infer)

pdftotext works, search works, even macOS Preview works. ~~Search in Chrome pdf.js seems to be broken however.~~ (Edit: was mistaken) on both pdfs pdf.js is broken:

image:
`making use of the theory`

copy & paste to gedit:
```
making
use
of  
the
theory
```

search:
`makinguseof  thetheory` I'm trying to sort similar issues.  I am working with poppler, pdf2htmlEX (which uses poppler for extraction iirc), and Acrobat Pro 10.

I have been fighting exactly the same issues described here.

I see the same results with pdf.js that @amitdo  mentioned in the reply above on the following file...

[asdf.pdf](https://github.com/tesseract-ocr/tesseract/files/768011/asdf.pdf)

This file started as a PDF from 300dpi scans, I extracted it to PNGs with Imagemagick, and OCR'd those with Tess v4 LTSM into a new PDF.

Here's a copy/paste of the first paragraph of the first page from OSX preview

> take i atll back, and sure enough that's going to come but itwill take time. Firstofallletus ask a rather simple question. How can we be sure, how can we tell, whether any utterance is to be classed as a performative or not? Surely, we feel, we ought to be able to do that. And we should obviously very muchliketobeabletosaythatthereisagrammaticalcriterionforthis, some grammatical means ofdeciding whether an utterance isperformative. All the examples I have given hitherto do in fact have the same grammatical form;theyallofthem beginwith theverbinthefirstpersonsingularpresent indicative active-not just any kind of verb of course, but still they all are in fact of that form. Furthermore, with these verbs that I have used there is a typical asymmetry between the use of this person and tense of the verb and the use of the same verb in other persons and other tenses, and this asym- metry is rather an important clue. 

and Acrobat Pro (also on OSX)...

> take it all back, and sure enough that's going to come but it will take time.
> First of all let us ask a rather simple question. How can we be sure, how can
> we tell, whether any utterance is to be classed as a performative or not?
> Surely, we feel, we ought to be able to do that. And we should obviously very
> much like to be able to say that there is a grammatical criterion for this,
> some grammatical means of deciding whether an utterance is performative.
> All the examples I have given hitherto do in fact have the same grammatical
> form; they all of them begin with the verb in the first person singular present
> indicative active-not just any kind of verb of course, but still they all are in
> fact of that form. Furthermore, with these verbs that I have used there is a
> typical asymmetry between the use of this person and tense of the verb and
> the use of the same verb in other persons and other tenses, and this asymmetry
> is rather an important clue.

And pdf.js...

> it
> all
> back,
> and
> sure
> enough
> that's
> going
> to
(ad infinitum, all words on a separate line)

In Chrome...

> take i allt back, and sure enough that's going to come but it will take time.
> First of all let us ask a rather simple question. How can we be sure, how can
> we tell, whether any utterance is to be classed as a performative or not?
> Surely, we feel, we ought to be able to do that. And we should obviously very
> much like to be able to say that there is a grammatical criterion for this,
> some grammatical means of deciding whether an utterance is performative.
> All the examples I have given hitherto do in fact have the same grammatical
> form; they all of them begin with the verb in the first person singular present
> indicative active-not just any kind of verb of course, but still they all are in
> fact of that form. Furthermore, with these verbs that I have used there is a
> typical asymmetry between the use of this person and tense of the verb and
> the use of the same verb in other persons and other tenses, and this asymmetry
> is rather an important clue.

pdftotext via poppler...

> take it all back, and sure enough that's going to come but it will take time.
> First of all let us ask a rather simple question. How can we be sure, how can
> we tell, whether any utterance is to be classed as a performative or not?
> Surely, we feel, we ought to be able to do that. And we should obviously very
> much like to be able to say that there is a grammatical criterion for this,
> some grammatical means of deciding whether an utterance is performative.
> All the examples I have given hitherto do in fact have the same grammatical
> form; they all of them begin with the verb in the first person singular present
> indicative active-not just any kind of verb of course, but still they all are in
> fact of that form. Furthermore, with these verbs that I have used there is a
> typical asymmetry between the use of this person and tense of the verb and
> the use of the same verb in other persons and other tenses, and this asymmetry is rather an important clue.

Versions..

Preview 909.12
Firefox 51.0.1
Adobe Acrobat Pro 10.1.3
Chrome 55.0.2883.95
poppler 0.51.0 For control.pdf and experiment.pdf, I checked that:
* using Acrobat XI, Chrome (pdfium), Firefox (pdf.js):
    * selecting a word will completely highlight that word rather than missing about half of the final character
    * random text that is copied and pasted will preserves word breaks
    * searching for "rela" will select all occurrences of "relativity"
* `pdftotext` produces a reasonable representation of the document contents with no extra spaces

Both files passed.

I then created control_gs.pdf and experiment_gs.pdf using Ghostscript 9.20.

[control_gs.pdf](https://github.com/tesseract-ocr/tesseract/files/769175/_control_gs.pdf)
[experiment_gs.pdf](https://github.com/tesseract-ocr/tesseract/files/769173/_experiment_gs.pdf)

For these two files, control_gs.pdf failed all tests, and experiment_gs.pdf **passed** all tests. The change in the experiment, assigning a width to the .null glyph, is therefore an improvement without any known regressions (yay!). The outputs of pdftotext on experiment.pdf and experiment_gs.pdf is binary identical.

I must have been mistaken on my early remark that there was a search functionality regression on "pdf.js" (by which I meant pdfium). I cannot replicate whatever problem I found with either my test files or experiment_gs.pdf. @amitdo With the way this experiment is set up, finding that pdf.js gives the same result on control and experiment is not a regression. It just means there are more cases of text extraction not working perfectly unrelated to running them through Ghostscript. I confirmed that experiment.pdf, experiment_gs.pdf and control.pdf all have the problem you identified with "making use of the theory". Maybe there's something else we can do.

@RNCTX In this issue we're discussing how *Ghostscript*'s pdfwrite utility seems to utterly ruin spacing in Tesseract-produced PDFs that *previously appeared correctly* in most viewers, rather than the general issue of spacing between characters not working in Tesseract PDFs. The real problem is the PDF spec itself:

>Identifying Word Breaks
>A document‚Äôs text stream defines not only the characters in a page‚Äôs text but also the words. Unlike a character, the notion of a word is not precisely defined but depends on the purpose for which the text is being processed. [...] applications all have their own ideas of what constitutes a word. I read that with Windows 10 the default pdf reader is the Edge browser. Someone should test it. Checked Win10/Edge. Same thing, control_gs.psf fails and the others are
acceptable. Someone other than me should check things though.


On Sun, Feb 12, 2017 at 02:32 Amit D. <notifications@github.com> wrote:

> I read that with Windows 10 the default reader is the Edge browser.
> Someone should test it.
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/712#issuecomment-279209374>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABvcM8nWXMrLQOBIMd6SZiBjotpDRqpqks5rbt-kgaJpZM4L6dNS>
> .
>
 @jbarlow83:  
> In this issue we're discussing how Ghostscript's pdfwrite utility seems to utterly ruin spacing in Tesseract-produced PDFs that previously appeared correctly in most viewers, rather than the general issue of spacing between characters not working in Tesseract PDFs. The real problem is the PDF spec itself:

Yes, I understand the context, perhaps I should have clarified my post a bit better.  In working with the output in other tools, as you say in the OP, "ghostscript is used in many utilities, perhaps without even the knowledge that it is being used by the user." In my case the PDF output of Tesseract is fine, in fact in terms of cleanliness as input for other tools it fares better than any other. But I arrived at this thread after attempting to resize a tesseract output PDF with Imagemagick (which, of course, uses ghostscript).


I am looking at your files in my various tools...

OSX Preview, pdf.js, and poppler output remain un-usable, but I agree that the others are improved.  Interestingly, OSX Preview is different for the two files you posted.  The run-on words are in different places.

Your change leaves us with Chrome and Acrobat working flawlessly, which is a pretty good start.



[Chrome.txt](https://github.com/tesseract-ocr/tesseract/files/769925/Chrome.txt)
[pdftotext.txt](https://github.com/tesseract-ocr/tesseract/files/769926/pdftotext.txt)
[pdf.js.txt](https://github.com/tesseract-ocr/tesseract/files/769927/pdf.js.txt)
[OSX Preview.txt](https://github.com/tesseract-ocr/tesseract/files/769928/OSX.Preview.txt)
[Acrobat X.txt](https://github.com/tesseract-ocr/tesseract/files/769929/Acrobat.X.txt)
 Here ya go..

Also tried iBooks on iOS but predictably the same output as Safari.

Acrobat reader on iOS does not allow text highlighting, but it does not find multi-word searches in either control_gs or experiment_gs, so Acrobat on iOS seems to be using a different renderer than it does on the desktop apps.  Acrobat Pro X on the Mac desktop app does find multi-word searches on experiment_gs, but not control_gs.

The dropbox viewer on iOS is apparently using Chrome's desktop renderer, but Chrome on iOS is using Safari's/Apple's instead of the Chrome desktop pdf renderer going by these results.

Firefox on iOS has very poor touch recognition in pdf files, so all I could do was pick the first word and "select all" which gave me 'some' text from each file but not all text on a page in either control_gs or experiment_gs

This is on an iPad Air2 with iOS 10.x

[Chrome_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/770065/Chrome_iOS.txt)
[Safari_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/770066/Safari_iOS.txt)
[Dropbox_Viewer_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/770067/Dropbox_Viewer_iOS.txt)
[Firefox_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/770099/Firefox_iOS.txt)

 
[DropboxViewer_Control-Experiment_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/771930/DropboxViewer_Control-Experiment_iOS.txt)
[Chrome_Control-Experiment_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/771920/Chrome_Control-Experiment_iOS.txt)
[Safari_Control-Experiment_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/771921/Safari_Control-Experiment_iOS.txt)
[Firefox_Control-Experiment_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/771922/Firefox_Control-Experiment_iOS.txt)

To clarify, these are from the PDF files in this post...

https://github.com/tesseract-ocr/tesseract/issues/712#issuecomment-279013509 Jeff,

Does this new ttf need to be added to both 3.05 and master branches?

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Tue, Feb 14, 2017 at 12:07 AM, jbreiden <notifications@github.com> wrote:

> pdf.ttf.zip
> <https://github.com/tesseract-ocr/tesseract/files/772035/pdf.ttf.zip>
>
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/712#issuecomment-279481123>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o0O3YkyHAe9OMKsC_2n1nr9wovq4ks5rcKL1gaJpZM4L6dNS>
> .
>
 @zdenop added it to the 3.05 branch, and I guess he will add it to 'master' soon...   I got this error while running a test case which involves verifying a toast message using tesseract on intellij3.4. java version 1.8.0_121)

A fatal error has been detected by the Java Runtime Environment:
 SIGSEGV (0xb) at pc=0x00007f10e046333a, pid=4980, tid=0x00007f111d577700
 JRE version: Java(TM) SE Runtime Environment (8.0_121-b13) (build 1.8.0_121-b13)
 Java VM: Java HotSpot(TM) 64-Bit Server VM (25.121-b13 mixed mode linux-amd64 compressed oops)
 Problematic frame:
C  [libtesseract.so.3.0.3+0x22533a]  ERRCODE::error(char const*, TessErrorLogCode, char const*, ...) const+0x16a

 Failed to write core dump. Core dumps have been disabled. To enable core dumping, try "ulimit -c unlimited" before starting Java again

actual_tessdata_num_entries_ <= TESSDATA_NUM_ENTRIES:Error:Assert failed:in file tessdatamanager.cpp, line 53

tried executing "ulimit -c unlimited" still doesn't set it right.
any suggestion will be of great help.
 https://github.com/tesseract-ocr/tesseract/wiki/FAQ#actual_tessdata_num_entries_-tessdata_num_entrieserrorassert-failedin-file-ccutiltessdatamanagercpp-line-55_  when i use tesseract through command line, it works. But when I call it through python(tesserocr), it crashes and said Segmentation fault.
![1](https://cloud.githubusercontent.com/assets/1935079/22725932/50036f4c-ee0b-11e6-93db-6f06af554c65.JPG)
 I compile it myself in Ubuntu 14.04. The version is 3.04  These files will be removed soon with the rest of the legacy ocr engine, unless you'll persuade Ray to keep that engine...  Ray wants to get rid of the legacy OCR engine, so that the final 4.00 version will only have one OCR engine based on LSTM.

From #518:

@stweil commented:
>I strongly vote against removing non-LSTM as we currently still get better results with it in some cases.

@theraysmith commented:
>**Please provide examples of where you get better results with the old engine.**
Right now I'm trying to work on getting rid of redundant code, rather than spending time fighting needless changes that generate a lot of work. I have recently tested an LSTM-based OSD, and it works a lot better than the old, so that is one more use of the old classifier that can go. AFAICT, apart from the equation detector, the old classifier is now redundant.


 Is the intention that the legacy OCR engine will be available in 3.0x branch and LSTM engine in the 4.0 version? I support @theraysmith  removing the legacy OCR engine as we are getting better results in LSTM-based,
however we have to increase support to multilanguage and need many fixes to 4.0 final.. My personal opinion is that we should drop the old engine. It will be much easier to maintain and support Tesseract in this form. I also support dropping the OpenCL code. I also think we should release a last 3.0x version in the upcoming 2-6 weeks. I cannot agree with removing old ocr engine, until new lstm engine has support vertical text.

Of course I know that the new LSTM engine is very good ( in Japanese text including English words especially).
In the meantime, maintaining the old engine provides the option of using the old OCR engine only for vertical text.

c.f. #627 , #641 
 :+1:  for a side-by-side 3.05 and 4.00.

A possible way to achieve this goal:
For 3.05 you can append `3` to libtesseract and all the installed programs.
The traineddata will live in `.../share/tessdata3`.
  I agree with zdenop

tessdata should be used for the 3.0x series, so as to not break any
existing use

New naming can be used for LSTM 4.0

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Thu, Feb 9, 2017 at 12:04 AM, Egor Pugin <notifications@github.com>
wrote:

> Yes, if later we'll have 5.0 with different data files, they'll use
> tesseract5 and this won't break anything.
> If we have tesseract for 4.0, then it will be renamed to tesseract4
> again, and tesseract for 5.0 - that's not good.
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/707#issuecomment-278419744>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_ozcExn8t5DzsPgjUAqnju9_CZk3Mks5ragqdgaJpZM4L50TV>
> .
>
 @jbreiden Good idea to do a code update for 3.05 for Ubuntu 17.04. There are a number of bug fixes and changes and it would be good to get them out to the users. Thanks! **@theraysmith:**  Here I try to provide examples of where you get better results with the old engine.

I did a lot of LSTM training with OCRopus on real images of historical printings and noticed that LSTM recognition was inferior to classic Tesseract in these cases:

1. glyphs rarely seen in training (capital letters, numbers, certain punctuations)
2. unusual patterns (letter-spacing, e.g. R U N N I N G   H E A D)
3. very short lines (catchword at page end, page numbers)

My explanation is, that single letters get decoded using the combined evidence of the whole line. If this is either rare and unusual (1, 2) or mostly absent (3), decoding is uncertain, no matter how clearly single glyphs are printed and preserved (and therefore easily recognized by methods based on feature detection).

So I tried both the old (OEM = 0) and new (OEM = 1) recognizer on these 10 lines (the last line is a regular text line for comparison from a 1543 printing, where a trained model yields 99.5% accuracy for the book):

![1 bin](https://cloud.githubusercontent.com/assets/8000185/22987900/93a411d4-f3b0-11e6-8b97-d05aadb0cf9a.png)
![2 bin](https://cloud.githubusercontent.com/assets/8000185/22987911/9a96c608-f3b0-11e6-85e4-113e044b06b0.png)
![3 bin](https://cloud.githubusercontent.com/assets/8000185/22987915/9b0a45d8-f3b0-11e6-8213-113e52cdd601.png)
![4 bin](https://cloud.githubusercontent.com/assets/8000185/22987912/9ab1c9a8-f3b0-11e6-9957-d84b508a8e91.png)
![5 bin](https://cloud.githubusercontent.com/assets/8000185/22987905/9a6edb02-f3b0-11e6-8085-0cce28d7b45b.png)
![6 bin](https://cloud.githubusercontent.com/assets/8000185/22987906/9a717876-f3b0-11e6-967b-70db67068f74.png)
![7 bin](https://cloud.githubusercontent.com/assets/8000185/22987907/9a727c94-f3b0-11e6-9d47-375e4ffdbc4a.png)
![8 bin](https://cloud.githubusercontent.com/assets/8000185/22987908/9a829a66-f3b0-11e6-8c48-5ad95f4a1ecf.png)
![9 bin](https://cloud.githubusercontent.com/assets/8000185/22987909/9a9314fe-f3b0-11e6-9197-bc038eeec3b5.png)
![10 bin](https://cloud.githubusercontent.com/assets/8000185/22987910/9a95f160-f3b0-11e6-8da5-d9737d8d7dd4.png)

**Old method: tesseract -l lat --oem 0 --psm 7:**

17:
V.
SECVNDAE
B 3
LIBER
AD
Lxxxvxn.
zo PROGYMNASMATA
IN GENEROSVM ADOLESCEN-
caÔ¨Åris millia paITuum circit√©r fcptem.Rc_x cum hoc itincrc szar√© ucnirc

**New method: tesseract -l lat --oem 1 --psm 7:**

177:
V,.
SECV NDAHE
B- 5
LI B E D.
A D
Lx x XV II IL.
209 P R o cy M N ^ s M A T 4
IN GE NE R O SVM A D O L E S CE N-
ca√ºris millia paiTuum circiter fcptcm.Rc-x cum hoc itinere C√¶far√∂ uenit:

Admittedly, although this is all Latin text, the recognition looks much better without any language model (**tesseract --oem 1 --psm 7**):

17;
V.
SECV NDA E
B ;
LIB E R
A D
Lx X xv III.
40 PR 0 GY MN A S M A T a
IN GENEROSVM ADOLESCEN.
caftris millia pafluum circiter feptem. Rex cum hocitinere Cafar√© uenire

But it still is less consistent than the old method in treating spacings. The last line shows the potential that may be reached when training on real images becomes available (long ≈ø, proper inter-word spacing model, historical glyphs).

**So I vote for keeping the old code just for these edge cases which are otherwise hard to recognize at the same level of consistency.** >Admittedly, although this is all Latin text, the recognition looks much better **without any language model**

Without explicit `-l LANG`, Tesseract will use the eng traineddata, so

>tesseract --oem 1 --psm 7

is equivalent to:
>tesseract -l eng --oem 1 --psm 7 @theraysmith commented in commit b453f74e01

>There is always going to be a significant speed penalty for multi-lang mode.
The multi-lang mode could still do with more work to run it at a lower level, (inside RecognizeLine) but the legacy engine could do to go before that, or multi-lang could get really unnecessarily complex.
 I think that there is reason to keeping the old ocr engine while LSTM engine is not ideal. 
This will allow use two engine simultaneously. 
For example ABBYY [uses several ocr methods](https://abbyy.technology/en:features:ocr:classifier) in his OCR engine: Bayesian classifier with about 100 features, raster classifier, contour classifier, structure classifier and then differentiating classifiers. The problem is that the code for the old engine is too large and complex. As Ray indicated, keeping it will make improving the new LSTM engine much harder. https://github.com/tesseract-ocr/tesseract/issues/733 

single letters recognized better with legacy From #744
theraysmith commented:

>... yes I would still like to remove the old classifier and take out a lot of code with it.
I'm going to review the replies to my request for "old better than new", and thanks to those that provided them, with a view to making new better than old on those problems. From 518
theraysmith commented:
> Please provide examples of where you get better results with the old engine.

@stweil commented 29 days ago:
>I'll do that in the discussion of the new issue #707.

Stefan, we are still waiting for it ...  :-) As you know, unlike almost all the other files in the tessdata repo, the '_frak' traineddata files are not based on Google manpower (& machine-power) efforts. 
https://github.com/tesseract-ocr/tesseract/wiki/Data-Files#fraktur-data-files

Maybe you and and your friends from @UB-Mannheim can prepare a new  deu_frak traineddata for Tesseract 4.00 and share it under open source license (preferably Apache 2 or other permissive software license) ? https://github.com/tesseract-ocr/tesseract/issues/681#issuecomment-275801448
Just a reminder for Ray.  From tesseract-ocr/langdata issue 59

theraysmith commented

>I'm also going to fix the single char/single word issue that was raised as
an objection to deleting the legacy engine.
 There are community training projects for MICR and SSD but these are not included in upcoming training by Ray.  Just documenting differences between 3.0x and 4.0 ... listed as issues in langdata:

https://github.com/tesseract-ocr/langdata/issues/65

https://github.com/tesseract-ocr/langdata/issues/64

 Based on my testing, I agree with @stweil - `adding (good) LSTM support for a language is much more difficult than for the old engine. `

Most recently I tried creating traineddata for Armenian based on a request in the forum - see https://github.com/tesseract-ocr/langdata/issues/67

While with my limited fonts and training text, I was able to get a legacy version of traineddata within a few hours which had reasonable accuracy, with the same inputs and 3-4 days of processing, the lstm version of traineddata did not better the accuracy, took more time while OCRing the same file. Of course, my test sample is very limited.

On the other hand, the accuracy and speed of complex scripts such as Devanagari has improved with the LSTM traineddata (though I haven't been able to add a top layer or fine tune those because of unicharset limitations).

I hope the new codebase and traineddata will address these issues. Thanks! As discussed in issue #1074, currently only the old recognizer is able to detect text attributes like font size, bold, italic.  https://github.com/blog/2309-introducing-topics Suggested topics:
* [ocr](https://github.com/search?q=topic%3Aocr)
* [lstm](https://github.com/search?q=topic%3Alstm)
* [machine-learning](https://github.com/search?q=topic%3Amachine-learning)
* [tesseract-ocr](https://github.com/search?q=topic%3Atesseract-ocr)
* [tesseract](https://github.com/search?q=topic%3Atesseract) @zdenop, only Ray can do it? Thanks, Zdenko! Why does it add 'org:tesseract-ocr' to the our topics? Click on a topic and you'll see what I'm talking about. I found out that it adds 'org' to any topic in any organization.

That's yet another case of bad UX in GitHub IMO. >I found out that it adds 'org' to any topic in any organization.

They fixed the issue.  Im want to build opencv text + tessract ocr. but i can't find how to get include and lib folder.
I find some old  build in source forge page but only 3.02 version but i want 4.0 or 3.05
https://sourceforge.net/projects/tesseract-ocr-alt/files/?source=navbar
some one can tell me where is include + lib folder or how to build it from source .
Sorry for posting in here but i did many search but haven't any result
Big thank! sorry for my bad english Thank you very much!
So simple and easy guide. Im' very happy. Thanks !  I found a mention of this in another post from a prior version. I managed to produce the below with -l eng and --oem 1.


https://github.com/tesseract-ocr/tesseract/issues/337

> tesseract -v
> tesseract 4.00.00alpha
>  leptonica-1.74.1
>   libjpeg 8d : libpng 1.6.28 : libtiff 4.0.7 : zlib 1.2.8
> 
>  OpenCL info:
>   Found 1 platform(s).
>   Platform 1 name: Apple.
>   Version: OpenCL 1.2 (Jan  4 2017 22:35:59).
>   Found 2 device(s).
>     Device 1 name: Intel(R) Core(TM) i7-5557U CPU @ 3.10GHz.
>     Device 2 name: Intel(R) Iris(TM) Graphics 6100.
>  Found AVX
>  Found SSE

> Gilbert. Certainly. Anybody can write a three-volumed novel.* It merely requires a complete ignorance of both life and literature. The difficulty that I should fancy the reviewer feels is the difficulty of sustaining any standard. Where there is no style a standard must be impossible. The poor reviewers are apparently reduced to be the reporters of the police court of literature, the chroniclers of the doings of the habitual criminals of art. It is sometimes said of them that they do not read all through the works they are called upon to criticise. They do not. Or at least they should not. If they did so, they would become confirmed misanthropes; or, ifI may borrow a phrase from one of the pretty N e w n h a m graduates, confirmed womanthropes' for the rest of their lives. Nor is it necessary. To know the vintage and quality of a wine one need not drink the whole cask. It must be perfectly easy in half an h o u r t o s a y w h e t h e r a b o o k is w o r t h a n y t h i n g o r w o r t h n o t h i n g . T e n m i n u t e s are really sufficient, if one has the instinct for form. W h o wants to wade t h r o u g h a d u l l v o l u m e ? O n e t a s t e s it, a n d t h a t is q u i t e e n o u g h - m o r e t h a n enough, Ishould imagine. Iam aware that there are many honest workers in painting as well as in literature w h o object to criticism entirely. T h e y are quite right. Their work stands in no intellectual relation to their age. Itbrings u s n o n e w e l e m e n t o f p l e a s u r e . It s u g g e s t s n o f r e s h d e p a r t u r e o f t h o u g h t , o r passion, or beauty. It should not be spoken of. It should be left to the oblivion that it deserves.

<img width="457" alt="screen shot 2017-02-04 at 1 39 41 am" src="https://cloud.githubusercontent.com/assets/13775820/22616815/e81e9bd8-ea7a-11e6-95dc-e1e983905d41.png">

However, the same text copied/pasted from the same file opened in Adobe Acrobat Pro 10 is  (almost) flawless...

> Gilbert. Certainly. Anybody can write a three-volumed novel.* It merely
> requires a complete ignorance of both life and literature. The difficulty that
> I should fancy the reviewer feels is the difficulty of sustaining any standard.
> Where there is no style a standard must be impossible. The poor reviewers
> are apparently reduced to be the reporters of the police court of literature,
> the chroniclers of the doings of the habitual criminals of art. It is sometimes
> said of them that they do not read all through the works they are called upon
> to criticise. They do not. Or at least they should not. If they did so, they
> would become confirmed misanthropes; or, if I may borrow a phrase from
> one of the pretty Newnham graduates, confirmed womanthropes' for the
> rest of their lives. Nor is it necessary. To know the vintage and quality of a
> wine one need not drink the whole cask. It must be perfectly easy in half an
> hour to say whether a book is worth anything or worth nothing. Ten minutes
> are really sufficient, if one has the instinct for form. Who wants to wade
> through a dull volume? One tastes it, and that is quite enough-more than
> enough, I should imagine. I am aware that there are many honest workers
> in painting as well as in literature who object to criticism entirely. They are
> quite right. Their work stands in no intellectual relation to their age. It brings
> us no new element of pleasure. It suggests no fresh departure of thought, or
> passion, or beauty. It should not be spoken of. It should be left to the oblivion
> that it deserves. Seems to be working fine in my case 

```
 tesseract -v
tesseract 4.00.00alpha
 leptonica-1.74.1
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 Found AVX
 Found SSE

 tesseract testeng.png testeng --oem 1 -l eng

Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
```
Here is the output

```
Gilbert. Certainly. Anybody can write a three-volumed novel." It merely
requires a complete ignorance of both life and literature. The difficulty that
I should fancy the reviewer feels is the difficulty of sustaining any standard.
Where there is no style a standard must be impossible. The poor reviewers
are apparently reduced to be the reporters of the police court of literature,
the chroniclers of the doings of the habitual criminals of art. It is sometimes
said of them that they do not read all through the works they are called upon
to criticise. They do not. Or at least they should not. If they did so, they
would become confirmed misanthropes; or, if I may borrow a phrase from
one of the pretty Newnham graduates, confirmed womanthropes' for the
rest of their lives. Nor is it necessary. To know the vintage and quality of a
wine one need not drink the whole cask. It must be perfectly easy in half an
hour to say whether a book is worth anything or worth nothing. Ten minutes
are really sufficient, if one has the instinct for form. Who wants to wade
through a dull volume? One tastes it, and that is quite enough-more than
enough, I should imagine. I am aware that there are many honest workers
in painting as well as in literature who object to criticism entirely. They are
quite right. Their work stands in no intellectual relation to their age. It brings
us no new element of pleasure. It suggests no fresh departure of thought, or
passion, or beauty. It should not be spoken of. It should be left to the oblivion
that it deserves.
```
 could be related to OpenCL I rebuilt HEAD without OpenCL and got the same result.  I would suppose this has to be something screwy with OSX preview, since it doesn't appear to happen in Adobe Acrobat (or Chrome, which I also opened it in just now).  

Here's the complete page...

[The946.png.pdf](https://github.com/tesseract-ocr/tesseract/files/752364/The946.png.pdf)
  ```
 lstmtraining -U ~/tesstutorial/khm/khm.unicharset \
  --script_dir ../langdata  --debug_interval 0  \
 --continue_from ~/tesstutorial/khmlayer1_from_khm/khm.lstm  \
 --append_index 3 --net_spec '[Lbx256 O1c105]'  \
 --model_output ~/tesstutorial/khmlayer1_from_khm/khm 
  --train_listfile ~/tesstutorial/khm/khm.training_files.txt \
  --target_error_rate 0.01

Loaded file /home/shree/tesstutorial/khmlayer1_from_khm/khm.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from /home/shree/tesstutorial/khmlayer1_from_khm/khm.lstm
Appending a new network to an old one!!Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Setting properties for script Khmer
Warning: given outputs 105 not equal to unicharset of 155.
Num outputs,weights in serial:
  Lbx256:512, 657408
  Fc155:155, 79515
Total weights = 736923
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lbx256Fc155] from request [Lbx256 O1c105]
Training parameters:
  Debug interval = 0, weights = 0.1, learning rate = 0.0001, momentum=0.9
Loaded 538/538 pages (1-538) of document /home/shree/tesstutorial/khm/khm.Leelawadee_UI_Bold.exp0.lstmf
Loaded 392/392 pages (1-392) of document /home/shree/tesstutorial/khm/khm.Noto_Sans_Khmer_UI_Bold.exp0.lstmf
Loaded 497/497 pages (1-497) of document /home/shree/tesstutorial/khm/khm.Noto_Serif_Khmer.exp0.lstmf
Loaded 396/396 pages (1-396) of document /home/shree/tesstutorial/khm/khm.Noto_Sans_Khmer_Bold.exp0.lstmf
Loaded 535/535 pages (1-535) of document /home/shree/tesstutorial/khm/khm.Leelawadee_UI.exp0.lstmf
Loaded 389/389 pages (1-389) of document /home/shree/tesstutorial/khm/khm.Noto_Sans_Khmer.exp0.lstmf
Loaded 402/402 pages (1-402) of document /home/shree/tesstutorial/khm/khm.Noto_Sans_Khmer_UI.exp0.lstmf
Loaded 491/491 pages (1-491) of document /home/shree/tesstutorial/khm/khm.Noto_Serif_Khmer_Bold.exp0.lstmf
At iteration 100/100/100, Mean rms=5.299%, delta=54.358%, char train=110.625%, word train=100%, skip ratio=0%,  New worst char error = 110.625 failed to write checkpoint.


2 Percent improvement time=1299, best error was 100 @ 0
At iteration 1299/1300/1301, Mean rms=4.903%, delta=47.404%, char train=98.596%, word train=99.748%, skip ratio=0.1%,  New best char error = 98.596 failed to write checkpoint.

``` ```
2 Percent improvement time=1090, best error was 20.094 @ 6275
At iteration 7365/7400/7408, Mean rms=1.661%, delta=5.067%, char train=18.026%, word train=64.079%, skip ratio=0%,  New best char error = 18.026 failed to write best m
odel:/home/shree/tesstutorial/khmlayer1_from_khm/khm18.026_7365.lstm failed to write checkpoint.

```

For some reason /home/shree/tesstutorial/khmlayer1_from_khm/ did not have appropriate write priviledge causing the error.
 Hello @Shreeshrii 

Do you know how to set learning rate by hand??  ![test1](https://cloud.githubusercontent.com/assets/23392731/22503425/a5baa5fe-e8ac-11e6-9d5e-36db771b3654.png)

When i use command "tesseract test.png out", the result is "01234567Beabcdelghijklmnopqrstuvwxyz". 
It has 4 wrong text.
But when i use command "tesseract test.png out pdf", the result is perfect correct.
Does someone know how to also make the result is correct when output is txt? Are you just looking at the PDF or the text in it?

The difference could be based on the default page segmentation mode used by
each method.

- excuse the brevity, sent from mobile

On 01-Feb-2017 4:02 PM, "shareworlds" <notifications@github.com> wrote:

> [image: test1]
> <https://cloud.githubusercontent.com/assets/23392731/22503425/a5baa5fe-e8ac-11e6-9d5e-36db771b3654.png>
>
> when i use command "tesseract test.png out", the result is "
> 01234567Beabcdelghijklmnopqrstuvwxyz".
> It has 4 wrong text.
> But when i use command "tesseract test.png out pdf", the result is perfect
> correct.
> Does someone know how to also make the result is correct when output is
> txt?
>
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/694>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o49ErZw5BEJZxmIW0D8f00K19bo2ks5rYF8qgaJpZM4LztKt>
> .
>
 No feedback from the OP, so I suggest to close this issue.  I want to build Tesseract using visual studio 2013.
I have followed all the steps as mentioned in https://vorba.ch/2014/tesseract-3.03-vs2013.html which is the site mentioned in the compiling section.
Everything went well but in the last step while building the solution I got a link error which is cannot read liblept171.lib and cannot include "allfrex.h".
I am new to this and haven't figured out any solution yet.
Is this the right way or please guide if any other way is possible to build tesseract in visual studio 2013

Thank you.

These are the steps mentioned in that link:

 
17 [Previously](tesseract-cygwin.html) I wrote about how to compile Tesseract OCR 
18 using Cygwin. While this is nice if you want to compile Tesseract for your own 
19 system where you can install Cygwin on your own, compiling with Visual Studio is 
20 better if you intend to distribute the compiled package so users don't have to 
21 install Cygwin. 
22 
 
23 Compiling Tesseract 3.02.02 with Visual C++ 2008 (Express) is [covered by the 
24 documentation](http://tesseract-ocr.googlecode.com/svn/trunk/vs2008/doc/setup.html) 
25 whereas compiling Tesseract 3.03 isn't covered at all, though. 
26 
 
27 Unfortunately newer versions of Tesseract also require a new version of 
28 [Leptonica](http://www.leptonica.org/), a C library for image processing and 
29 image analysis applications, which in turn requires new versions of zlib, 
30 libpng, libtiff, libjpeg and giflib. Tesseract provides pre-compiled versions of 
31 Leptonica, which prevents you from having to collect and set up projects for all 
32 of these libraries in Visual Studio, which can be a tedious task. 
33 
 
34 Yesterday I found a project on GitHub that includes a Visual Studio solution 
35 file for all dependencies required to compile Tesseract 3.03: 
36 [charlesw/tesseract-vs2012](https://github.com/charlesw/tesseract-vs2012). While 
37 following the build instructions there, I stumpled over several build errors, 
38 which I could easily resolve by removing a definition. The necessary change is 
39 in [my fork](https://github.com/pvorb/tesseract-vs2013) of the repository 
40 mentioned above. 
41 
 
42 This is a write-up of all steps that are required to compile Tesseract 3.03 with 
43 Visual Studio 2013. 
44 
 
45 ## Prerequisites 
46 
 
47  1. Install [Git](http://git-scm.com/). 
48  2. Install SVN. There are many versions of SVN. You can, for example, install 
49     the binary package from [SlickSVN](http://www.sliksvn.com/en/download) for 
50     free. 
51  3. Install [Visual Studio 2013 for Windows Desktop](http://www.visualstudio.com/downloads/download-visual-studio-vs) 
52     (the Express version will be enough). You don't need the optional features 
53     except for "Microsoft Foundation Classes for C++". 
54 
 
55 ## Building the dependencies 
56 
 
57  1. Create a directory where you want to compile Tesseract. In this document, 
58     I'll assume it's `C:\Tesseract-Build\`. 
59  2. Open a CMD prompt and change to that directory. 
60 
 
61     ~~~ 
62     cd \Tesseract-Build\ 
63     ~~~ 
64  3. Clone the dependencies repository from GitHub. 
65 
 
66     ~~~ 
67     git clone git://github.com/pvorb/tesseract-vs2013.git 
68     ~~~ 
69  4. Open the "VS 2013 Developer Command Prompt". (It can be found in the Start 
70     Menu.) 
71  5. Change to the newly cloned repository. 
72 
 
73     ~~~ 
74     cd \Tesseract-Build\tesseract-vs2013 
75     ~~~ 
76  6. Build the dependencies 
77 
 
78     ~~~ 
79     msbuild build.proj 
80     ~~~ 
81  7. You can close the "VS 2013 Developer Command Prompt". 
82 
 
83 ## Building Tesseract 
84 
 
85  1. Re-open the first command prompt and ensure it's still in 
86     `C:\Tesseract-Build\`. 
87  2. Get the latest source from SVN. 
88 
 
89     ~~~ 
90     svn checkout http://tesseract-ocr.googlecode.com/svn/trunk/ tesseract-ocr 
91     ~~~ 
92  3. Change to the newly checked-out repository. 
93 
 
94     ~~~ 
95     cd tesseract-ocr 
96     ~~~ 
97  4. Apply the patch provided in `tesseract-vs2013`. 
98 
 
99     ~~~ 
100     svn patch ..\tesseract-vs2013\vs2013+64bit_support.patch 
101     ~~~ 
102  5. Copy both directories in `C:\Tesseract-Build\tesseract-vs2013\release\` to 
103     `C:\Tesseract-Build\`. Now you should have 
104 
 
105       - `C:\Tesseract-Build\include\` 
106       - `C:\Tesseract-Build\lib\` 
107  6. Open `C:\Tesseract-Build\tesseract-ocr\vs2013\tesseract.sln` with Visual 
108     Studio 2013. 
109  7. Press `F7` on your keyboard. Both `libtesseract303` and `tesseract` should 
110     compile without errors. 

 see https://github.com/tesseract-ocr/tesseract/wiki/Compiling

section under windows re building with cppan

@egorpugin  will it work with vs2013? Thanks!

It would be helpful to users if you update the wiki regarding cppan
compilation of tesseract. Right now it seems to me that it is for training
tools since that comes on top.

Many users compile tesseract not for development or training but just to
get the latest version of the software.

I don't have Visual studio so I haven't tried it.

- excuse the brevity, sent from mobile

On 07-Feb-2017 12:23 PM, "Egor Pugin" <notifications@github.com> wrote:

> Not tested, but in general should be ok.
> I remember some issues with libtiff dependency, but I fixed something, so
> 100% not sure.
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/693#issuecomment-277916595>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o6iSxuA8jeGbYJKSYyeMuRAQiik9ks5raBTXgaJpZM4LzeyP>
> .
>
 Thank you very much!
I followed all the steps as mentioned and I was able to build the solution successfully without any errors.
Now I added a new cpp file with the code given in api example.But I did not get any ouput .I also tried writing the output to a txt file but in vain.
Can  you please help me how to get the txt,hocr,pdf output file after building the solution.
I am currently trying it in visual studio 2013  as well as 2015 version.
Regards.

API example:
#include <tesseract/baseapi.h>
#include <leptonica/allheaders.h>

int main()
{
    char *outText;

    tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();
    // Initialize tesseract-ocr with English, without specifying tessdata path
    if (api->Init(NULL, "eng")) {
        fprintf(stderr, "Could not initialize tesseract.\n");
        exit(1);
    }

    // Open input image with leptonica library
    Pix *image = pixRead("/usr/src/tesseract/testing/phototest.tif");
    api->SetImage(image);
    // Get OCR result
    outText = api->GetUTF8Text();
    printf("OCR output:\n%s", outText);

    // Destroy used object and release memory
    api->End();
    delete [] outText;
    pixDestroy(&image);

    return 0;
} Thank You,It is working.

I  would like you guys to provide videos on step by step process of building tesseract on various platforms which would really guide us especially the beginners and save many hours of searching in the net. I want to build Tesseract with vs2013. I have followed all steps of this tutorial:
https://vorba.ch/2014/tesseract-3.03-vs2013.html
but in the last step, I got this error:
can not find include file: 'version.h' 
what should I do?
Thanks try with cppan and directions given in
https://github.com/tesseract-ocr/tesseract/wiki/Compiling

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Sat, Mar 11, 2017 at 1:56 PM, hanikh <notifications@github.com> wrote:

> I want to build Tesseract with vs2013. I have followed all steps of this
> tutorial:
> https://vorba.ch/2014/tesseract-3.03-vs2013.html
> but in the last step, I got this error:
> can not find include file: 'version.h'
> what should I do?
> Thanks
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/693#issuecomment-285852507>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o9sRC55lnexaMDQKMzbtieWDbAvwks5rklq5gaJpZM4LzeyP>
> .
>
  Trying to run "tesseract filename.jp2 out -l deu_frak" results:

Tesseract Open Source OCR Engine v3.04.01 with Leptonica
Warning in fgetJp2kResolution: image resolution not found

There is a fix to this somewhere, but could not find it:

https://www.mail-archive.com/debian-bugs-dist@lists.debian.org/msg1373390.html tesseract -v
will show what libs leptonica has with it. It might not have jp2 support.

 tesseract -v

tesseract 4.00.00alpha
 leptonica-1.74.1
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib
1.2.8

 Found AVX
 Found SSE


ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Wed, Feb 1, 2017 at 6:35 AM, Asko Nivala <notifications@github.com>
wrote:

> Trying to run "tesseract filename.jp2 out -l deu_frak" results:
>
> Tesseract Open Source OCR Engine v3.04.01 with Leptonica
> Warning in fgetJp2kResolution: image resolution not found
>
> There is a fix to this somewhere, but could not find it:
>
> https://www.mail-archive.com/debian-bugs-dist@lists.debian.
> org/msg1373390.html
>
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/692>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_owQIcQpMJZUxe4vDRMZKS54Nq90Pks5rX9pUgaJpZM4LzX_O>
> .
>
 I am so sorry for the incomplete report and not testing this issue properly. Running "tesseract filename.jp2 out -l deu_frak" resulted to the above given error message and an empty out.txt file or freezing of app, so I automatically (but little bit stupidly) assumed that the OCR scanning is not working. After you reply, I tested it with lots of other jp2 files, and it in fact works despite of the warning. The jp2 files that I was using were simply somehow corrupted, it is my mistake, which I apologise!

By the way, I encountered problems also with multipaged TIFFs, tesseract now outputting empty txt files. But I am probably doing something wrong here as well and it's not a bug. I am using Ubuntu 16.04.1 LTS Server without any graphics system and installed tesseract with "apt-get install".

Just in case, the report of "tesseract -v":
```
tesseract 3.04.01
 leptonica-1.73
  libgif 5.1.2 : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.4 : libopenjp2 2.1.0
```  ```
lstmtraining -U  /mnt/c/Users/User/shree/jtess/samples/vie/vie.unicharset  
 --script_dir /mnt/c/Usrs/User/shree/langdata  --debug_interval -1 
  --continue_from  /mnt/c/Users/User/shree/jtess/samples/vie/vie.lstm  
 --append_index 5 --net_spec '[Lfx256 O1c105]'   
--model_output  /mnt/c/Users/User/shree/jtess/samples/vie/vielayer  
 --train_listfile  /mnt/c/Users/User/shree/jtess/samples/vie/vie.training_files.txt  
 --target_error_rate 0.01

  Loaded file /mnt/c/Users/User/shree/jtess/samples/vie/vie.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from /mnt/c/Users/User/shree/jtess/samples/vie/vie.lstm
Appending a new network to an old one!!Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Warning: given outputs 105 not equal to unicharset of 227.
Num outputs,weights in serial:
  Lfx256:256, 394240
  Fc227:227, 58339
Total weights = 452579
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc227] from request [Lfx256 O1c105]
Training parameters:
  Debug interval = -1, weights = 0.1, learning rate = 0.0001, momentum=0.9
Deserialize header failed: /mnt/c/Users/User/shree/jtess/samples/vie/vie.FreeSerif.exp0.lstmf
Load of page 0 failed!
Load of images failed!!
``` note: lstmf files created using windows binaries https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#error-messages-from-training

>Deserialize header failed occurs when a training input is not in LSTM format or the file is not readable. Check your filelist file to see if it contains valid filenames. It's a moving target, and it's not guaranteed to read files generated by a previous alpha snapshot.  Back in 2015, I used some tools I found that came with tesseract that performed post-processing to correct ocr errors (i.e. they accepted text in and returned it out). I used them for my dissertation work in text error correction. Now it looks like tesseract has been refactored and they're gone. Regrettably I don't remember what the executables were called. Is there any way to get that old version of tesseract, or is there a way to use the new tesseract for OCR postprocessing instead of OCR directly?  @stweil @egorpugin  

It would be great if you can provide for download windows binaries with the latest 4.0.0 alpha code,  including the new training programs 
Lstmtraining
And
Lstmeval 

Thank you. + tesseract-ocr google group

Thank you both so much for your prompt response in providing the windows
binaries.

I have added links to both at
https://github.com/tesseract-ocr/tesseract/wiki/4.0-with-LSTM#400-alpha-for-windows

Unofficial experimental binaries of tesseract-ocr 4.0.0-alpha (Jan 30,
2017) are available from the following links:

   - Windows Installer made with MinGW-w64
   <http://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-4.00.00dev.exe>
   from UB Mannheim <https://github.com/UB-Mannheim/tesseract/wiki>
   - zip file with cppan generated .dll and .exe files
   <https://www.dropbox.com/s/obiqvrt4m53pmoz/tesseract-4.0.0-alpha.zip?dl=1>,
   You have to install VC2015 x86 redist from microsoft.com in order to run
   them.

Please correct the description if it is not correct.

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Tue, Jan 31, 2017 at 2:26 AM, Stefan Weil <notifications@github.com>
wrote:

> There is also a new installer in our wiki
> <https://github.com/UB-Mannheim/tesseract/wiki>.
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/689#issuecomment-276187794>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_ozpbP4CXsf2YPsViZexCGLQwHwEDks5rXk6BgaJpZM4Lxkq2>
> .
>
 @stweil Thanks. I have downloaded the new version and will give it a try.

Wondering though how  it is related to win32, since I am running under windows 10, with wit 64bit os and x-64 based processor. 

![sysinfo](https://cloud.githubusercontent.com/assets/5095331/22583959/cf6cf428-ea15-11e6-8d88-dc4f92a59acc.png) Thanks for clarifying.

Have you/others at UB Mannheim tried LSTM training with the windows binaries?

In my earlier test, I found that lstmtraining was not reading .lstmf files created on windows. I will have to test the exact same case under bash and windows to confirm it.  I am wondering if it could be related to Unix vs DOS/Windows EOL differences.

Is there a way to compare the .lstmf files (binary files)?  Hi,

I have put my effort by making changes to necessary project files. I have used the solution file present at the following location:

https://github.com/peirick/VS2015_Tesseract/

Unfortunately, that is based on Tesseract - 3.05. I took the latest 4.0 version of source code to build in visual studio. I'm getting following linker errors only for the newly introduced code part in 4.0 i.e., lstm and simddetect:

Severity	Code	Description	Project	File	Line	Suppression State
Error	LNK1120	8 unresolved externals	tesseract	D:\tesseract\VS2015_Tesseract\x64\Debug\tesseract.exe	1
Error	LNK2001	unresolved external symbol "private: static bool SIMDDetect::avx_available_" (?avx_available_@SIMDDetect@@0_NA)	tesseract	D:\tesseract\VS2015_Tesseract\tesseract\tesseractmain.obj 1
Error	LNK2001	unresolved external symbol "private: static bool SIMDDetect::sse_available_" (?sse_available_@SIMDDetect@@0_NA)	tesseract	D:\tesseract\VS2015_Tesseract\tesseract\tesseractmain.obj 1
Error	LNK2019	unresolved external symbol "public: void __cdecl tesseract::Tesseract::TrainLineRecognizer(class STRING const &,class STRING const &,class BLOCK_LIST *)" (?TrainLineRecognizer@Tesseract@tesseract@@QEAAXAEBVSTRING@@0PEAVBLOCK_LIST@@@Z) referenced in function "public: int __cdecl tesseract::TessBaseAPI::Recognize(class ETEXT_DESC *)" (?Recognize@TessBaseAPI@tesseract@@QEAAHPEAVETEXT_DESC@@@Z)	tesseract D:\tesseract\VS2015_Tesseract\tesseract\baseapi.obj	1
Error	LNK2019	unresolved external symbol "public: void __cdecl tesseract::Tesseract::LSTMRecognizeWord(class BLOCK const &,class ROW *,class WERD_RES *,class tesseract::PointerVector *)" (?LSTMRecognizeWord@Tesseract@tesseract@@QEAAXAEBVBLOCK@@PEAVROW@@PEAVWERD_RES@@PEAV?$PointerVector@VWERD_RES@@@2@@Z) referenced in function "public: void __cdecl tesseract::Tesseract::classify_word_pass1(struct tesseract::WordData const &,class WERD_RES * *,class tesseract::PointerVector *)" (?classify_word_pass1@Tesseract@tesseract@@QEAAXAEBUWordData@2@PEAPEAVWERD_RES@@PEAV?$PointerVector@VWERD_RES@@@2@@Z)	tesseract	D:\tesseract\VS2015_Tesseract\tesseract\control.obj	1
Error	LNK2019	unresolved external symbol "public: __cdecl tesseract::LSTMRecognizer::LSTMRecognizer(void)" (??0LSTMRecognizer@tesseract@@QEAA@XZ) referenced in function "public: bool __cdecl tesseract::Tesseract::init_tesseract_lang_data(char const *,char const *,char const *,enum tesseract::OcrEngineMode,char * *,int,class GenericVector const *,class GenericVector const *,bool)" (?init_tesseract_lang_data@Tesseract@tesseract@@QEAA_NPEBD00W4OcrEngineMode@2@PEAPEADHPEBV?$GenericVector@VSTRING@@@@3_N@Z)	tesseract	D:\tesseract\VS2015_Tesseract\tesseract\tessedit.obj 1
Error	LNK2019	unresolved external symbol "public: bool __cdecl tesseract::LSTMRecognizer::DeSerialize(bool,class tesseract::TFile *)" (?DeSerialize@LSTMRecognizer@tesseract@@QEAA_N_NPEAVTFile@2@@Z) referenced in function "public: bool __cdecl tesseract::Tesseract::init_tesseract_lang_data(char const *,char const *,char const *,enum tesseract::OcrEngineMode,char * *,int,class GenericVector const *,class GenericVector const *,bool)" (?init_tesseract_lang_data@Tesseract@tesseract@@QEAA_NPEBD00W4OcrEngineMode@2@PEAPEADHPEBV?$GenericVector@VSTRING@@@@3_N@Z)	tesseract	D:\tesseract\VS2015_Tesseract\tesseract\tessedit.obj 1
Error	LNK2019	unresolved external symbol "public: bool __cdecl tesseract::LSTMRecognizer::LoadDictionary(char const *,char const *)" (?LoadDictionary@LSTMRecognizer@tesseract@@QEAA_NPEBD0@Z) referenced in function "public: bool __cdecl tesseract::Tesseract::init_tesseract_lang_data(char const *,char const *,char const *,enum tesseract::OcrEngineMode,char * *,int,class GenericVector const *,class GenericVector const *,bool)" (?init_tesseract_lang_data@Tesseract@tesseract@@QEAA_NPEBD00W4OcrEngineMode@2@PEAPEADHPEBV?$GenericVector@VSTRING@@@@3_N@Z)	tesseract	D:\tesseract\VS2015_Tesseract\tesseract\tessedit.obj 1
Error	LNK2019	unresolved external symbol "public: __cdecl tesseract::LSTMRecognizer::~LSTMRecognizer(void)" (??1LSTMRecognizer@tesseract@@QEAA@XZ) referenced in function "public: void * __cdecl tesseract::LSTMRecognizer::`scalar deleting destructor'(unsigned int)" (??_GLSTMRecognizer@tesseract@@QEAAPEAXI@Z)	tesseract D:\tesseract\VS2015_Tesseract\tesseract\tesseractclass.obj	1


Can someone kindly assist me in resolving them? Try installing with cppan as described in

https://github.com/tesseract-ocr/tesseract/wiki/Compiling

- excuse the brevity, sent from mobile

On 28-Jan-2017 10:39 PM, "Sai Nikhil" <notifications@github.com> wrote:

> Hi,
>
> I have put my effort by making changes to necessary project files. I have
> used the solution file present at the following location:
>
> https://github.com/peirick/VS2015_Tesseract/
>
> Unfortunately, that is based on Tesseract - 3.05. I took the latest 4.0
> version of source code to build in visual studio. I'm getting following
> linker errors only for the newly introduced code part in 4.0 i.e., lstm and
> simddetect:
>
> Severity Code Description Project File Line Suppression State
> Error LNK1120 8 unresolved externals tesseract
> D:\tesseract\VS2015_Tesseract\x64\Debug\tesseract.exe 1
> Error LNK2001 unresolved external symbol "private: static bool
> SIMDDetect::avx_available_" (?avx_available_@SIMDDetect@@0_NA) tesseract
> D:\tesseract\VS2015_Tesseract\tesseract\tesseractmain.obj 1
> Error LNK2001 unresolved external symbol "private: static bool
> SIMDDetect::sse_available_" (?sse_available_@SIMDDetect@@0_NA) tesseract
> D:\tesseract\VS2015_Tesseract\tesseract\tesseractmain.obj 1
> Error LNK2019 unresolved external symbol "public: void __cdecl
> tesseract::Tesseract::TrainLineRecognizer(class STRING const &,class
> STRING const &,class BLOCK_LIST *)" (?TrainLineRecognizer@
> Tesseract@tesseract@@QEAAXAEBVSTRING@@0PEAVBLOCK_LIST@@@Z
> <https://github.com/Z>) referenced in function "public: int __cdecl
> tesseract::TessBaseAPI::Recognize(class ETEXT_DESC *)"
> (?Recognize@TessBaseAPI@tesseract@@QEAAHPEAVETEXT_DESC@@@Z
> <https://github.com/Z>) tesseract D:\tesseract\VS2015_Tesseract\tesseract\baseapi.obj
> 1
> Error LNK2019 unresolved external symbol "public: void __cdecl
> tesseract::Tesseract::LSTMRecognizeWord(class BLOCK const &,class ROW
> *,class WERD_RES *,class tesseract::PointerVector *)"
> (?LSTMRecognizeWord@Tesseract@tesseract@@QEAAXAEBVBLOCK@@PEAVROW@
> @PEAVWERD_RES@@PEAV <https://github.com/PEAV>?$PointerVector@VWERD_RES@@@2
> <https://github.com/2>@@Z <https://github.com/Z>) referenced in function
> "public: void __cdecl tesseract::Tesseract::classify_word_pass1(struct
> tesseract::WordData const &,class WERD_RES * *,class
> tesseract::PointerVector *)" (?classify_word_pass1@Tesseract@tesseract@@
> QEAAXAEBUWordData@2@PEAPEAVWERD_RES@@PEAV <https://github.com/PEAV>?$
> PointerVector@VWERD_RES@@@2 <https://github.com/2>@@Z
> <https://github.com/Z>) tesseract D:\tesseract\VS2015_Tesseract\tesseract\control.obj
> 1
> Error LNK2019 unresolved external symbol "public: __cdecl
> tesseract::LSTMRecognizer::LSTMRecognizer(void)"
> (??0LSTMRecognizer@tesseract@@QEAA@XZ) referenced in function "public:
> bool __cdecl tesseract::Tesseract::init_tesseract_lang_data(char const
> *,char const *,char const *,enum tesseract::OcrEngineMode,char *
> *,int,class GenericVector const *,class GenericVector const *,bool)"
> (?init_tesseract_lang_data@Tesseract@tesseract@@QEAA_
> NPEBD00W4OcrEngineMode@2@PEAPEADHPEBV?$GenericVector@VSTRING@@@@3_N@Z)
> tesseract D:\tesseract\VS2015_Tesseract\tesseract\tessedit.obj 1
> Error LNK2019 unresolved external symbol "public: bool __cdecl
> tesseract::LSTMRecognizer::DeSerialize(bool,class tesseract::TFile *)"
> (?DeSerialize@LSTMRecognizer@tesseract@@QEAA_N_NPEAVTFile@2@@Z
> <https://github.com/Z>) referenced in function "public: bool __cdecl
> tesseract::Tesseract::init_tesseract_lang_data(char const *,char const
> *,char const *,enum tesseract::OcrEngineMode,char * *,int,class
> GenericVector const *,class GenericVector const *,bool)"
> (?init_tesseract_lang_data@Tesseract@tesseract@@QEAA_
> NPEBD00W4OcrEngineMode@2@PEAPEADHPEBV?$GenericVector@VSTRING@@@@3_N@Z)
> tesseract D:\tesseract\VS2015_Tesseract\tesseract\tessedit.obj 1
> Error LNK2019 unresolved external symbol "public: bool __cdecl
> tesseract::LSTMRecognizer::LoadDictionary(char const *,char const *)"
> (?LoadDictionary@LSTMRecognizer@tesseract@@QEAA_NPEBD0@Z) referenced in
> function "public: bool __cdecl tesseract::Tesseract::init_tesseract_lang_data(char
> const *,char const *,char const *,enum tesseract::OcrEngineMode,char *
> *,int,class GenericVector const *,class GenericVector const *,bool)"
> (?init_tesseract_lang_data@Tesseract@tesseract@@QEAA_
> NPEBD00W4OcrEngineMode@2@PEAPEADHPEBV?$GenericVector@VSTRING@@@@3_N@Z)
> tesseract D:\tesseract\VS2015_Tesseract\tesseract\tessedit.obj 1
> Error LNK2019 unresolved external symbol "public: __cdecl
> tesseract::LSTMRecognizer::~LSTMRecognizer(void)"
> (??1LSTMRecognizer@tesseract@@QEAA@XZ) referenced in function "public:
> void * __cdecl tesseract::LSTMRecognizer::`scalar deleting
> destructor'(unsigned int)" (??_GLSTMRecognizer@tesseract@@QEAAPEAXI@Z)
> tesseract D:\tesseract\VS2015_Tesseract\tesseract\tesseractclass.obj 1
>
> Can someone kindly assist me in resolving them?
>
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/686>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_owaG2bf-jEF68k0o72CxMoUvrV8Tks5rW3YwgaJpZM4Lwjli>
> .
>
 I ran the above command but still no luck. 2 weeks gone but still no progress on build. Can you kindly describe the step by step procedure so that I can have a successful build. Thanks in advance. Can you provide a video of installing Tesseract 4.0x along with it's step-by-step description, on Ubuntu 16.xx from scratch. Uploading it to Youtube so that all people interested in the matter can follow from scratch.  Hi Egor,

Thanks for your response. Forgetting what happened in the past, I now ran the following steps for building Tesseract from source:

git clone https://github.com/tesseract-ocr/tesseract tesseract
cd tesseract
cppan
mkdir build && cd build
cmake ..

Build is now successful.

But, when I'm trying to run tesseractmain.cpp program in Debug mode, I get the following error:

![1](https://cloud.githubusercontent.com/assets/1130987/22403458/d9d32832-e63d-11e6-8411-5782ec20e184.png)

![2](https://cloud.githubusercontent.com/assets/1130987/22403461/e287262c-e63d-11e6-9eff-104cf87a5207.png)

Can you kindly assist me in getting rid of this error and run the main program? Perfect. Setting tesseractmain as the default project worked. Thanks a ton for the help. Closing the thread.  I also meet the same problem, but I can't resolve it with your answer. can you give me some suggestion? Hi @BrianZhu01 , can you let us know what all steps you've tried from beginning? thanks, I download tesseract, but I do not how deal with cppan? ,I had download cppan.exe .what can I do? I do steps as you list, but have the follow problem, and I just put the cppan.exe in cmake path? what I have wrong?@saint1729
![0x943d51f0_0x4da8_0x43f6_0xa3_0x22b8_0x2278_0x225d_0x2286_0x224a_0x222d_0x2284](https://cloud.githubusercontent.com/assets/15243563/22917419/b3241f50-f2bf-11e6-846d-98476318c3ee.png)
 Add **cppan** to you system variable **PATH**.

Go to directory where you extracted tesseract source code
**cd tesseract**


Run the following commands after that:

**cppan
mkdir build && cd build
cmake ..**

 Can you list what all files are present in your tesseract-ocr directory by running **dir** command and upload the screenshot here? thanks a lot,  If I run the cmd using administrator, I reslove the problem. when I run cppan , it can download the need files. thanks for your help, 

 @saint1729 ,sorry, I also need you help. run cppan doesn't work now! yesterday, I just download some files through cppan. but I meet some errors when run "cmake".
![000000](https://cloud.githusercontent.com/assets/15243563/22970142/fe2009f0-f3ab-11e6-8b74-81f628f701b7.png)
![00000001](https://cloud.githubusercontent.com/assets/15243563/22970145/fefbee02-f3ab-11e6-8f8c-f2080af15767.png)
![0000002](https://cloud.githubusercontent.com/assets/15243563/22970143/fe30a5e4-f3ab-11e6-800b-1c863b6c7296.png)
 @saint1729 
![000000](https://cloud.githubusercontent.com/assets/15243563/22970246/649f3002-f3ac-11e6-9312-c82e8cb5e325.png)
 @egorpugin Ôºå I opencv cppan.yml use txt. so the format have changed. what editor can i use to recover it?thanks!
 @saint1729 @egorpugin ÔºåI had open cppan.yml use notepad++, but here also have same error!
![0000000000000000000](https://cloud.githubusercontent.com/assets/15243563/23002929/5cf771da-f428-11e6-9bec-0374c86f9147.png)

 What if I have cppan that stops when launching it? I can't install Tesseract using cppan. I really need help! Thank you. 
Windows 10 64bit
opencv installed correctly.
Visual studio community 2017  I compared the HOCR output generated with recent builds of tesseract 3.04.02dev and 4.00.00alpha on various test images.

It seems that font recognition is broken in 4.00.00alpha:

With the command line parameter
**-c hocr_font_info=1**
3.04 generates font info for every word, which looks like this:
`x_font Verdana_Bold; x_fsize 21`

When I do the same with 4.00.00alpha, the font info looks like this:
`x_fsize 61491592`

The x_font attribute is missing entirely, and x_fsize has an incredibly large value.

The complete command line was:
`tesseract test-0.png  result --oem 1 -l deu -c hocr_font_info=1 hocr`

Version information:

3.04:
```
$ tesseract -v
tesseract 3.04.02dev
 leptonica-1.74.1
  libjpeg 6b (libjpeg-turbo 1.3.1) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8
```

4.00:
```
$ tesseract -v
tesseract 4.00.00alpha
 leptonica-1.74.1
  libjpeg 6b (libjpeg-turbo 1.3.1) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 Found AVX
 Found SSE

```
 The new LSTM engine does not support font recognition. OK, but then the presence of the x_fsize attribute is misleading.

Will the LSTM engine ever support font recognition?
 >Will the LSTM engine ever support font recognition?

Only @theraysmith can answer this question.

I don't think that exact font identification is important feature. The estimated size of a word/line might be useful information. Same for emphasis of words.  output using 4.0.0-alpha traineddata

--oem 0

```
‚ÅÑ>·ûÜ·üí·ûÇ·û∂·üÜ·ü•·ûö·ûª·ûü·ûü·ûü·üí·ûä·û∑·ûì·ûü·üã·üç·ûâ·üí·ûâ·ûæ·ûÜ·û∂·üí·ûì·ûè·û†·üí·ûò·û∫·ûì·ûì·û∑·ûÑ·ûü·üí·ûõ·û∏·ûÑ·ûâ·üí·ûâ·üÉ·ûè·üí·ûö·ûÑ·ûò·û∂·ûì·û§·ûô·ûª·ûñ·üê
·ûò·û∂·ûì·ûö·ûª·ûü·ûÖ·ûÄ·üí·ûä·û∏·ûö·û∑·üç·ûî·üí·ûö·ûî·üí·ûö·ûΩ·ûõ·ûá·û∂·ûí·ûò·üí·ûò·ûè·û∂·ûî·üã·üã·ûò·üí·ûî·û∂·ûü·üä·ûπ·ûî·ûî·üí·ûõ·üÇ·ûã·û¢·üé·ûî·üè·ûõ·ûî·üã·üã·ûî·üã·üã·üî
·ûê·üí·ûÑ·üÉ·ûñ·ûª·ûí·û†·üí·ûü·üä·ûª·ûÄ)·ûÄ·üÅ·ûâ·üí·ûâ·üá
·ûì·û∑·ûÑ·ûò·û∂·ûì·ûë·üí·ûö·ûÑ·üã·û¢·üà·ûó·üí·ûô·û∑·ûÑ·ûÖ·üÜ·û∂·ûÑ·ûó·üí·ûõ·û∏·ûï·üí·ûä·üÅ·ûÄ·üó·ûñ·ûª·ûù·üä·ûº·ûü·üä·û∫·ûì
·ûÄ·ûò·üí·ûñ·ûª·ûá·û∂·ûí·üí·ûõ·û∂·ûÄ·üã·ûÖ·ûª·üá·ûô·üâ·û∂·ûÑ·ûÜ·û∂·ûî·üã·ûö·û†·üê·ûü·û¢·üà·ûñ·û∂·ûâ·üí·ûâ·üá·ûê·üí·ûõ·ûô·üâ·û∂·üÜ·ûú·ûì·üÅ·ûâ·üí·ûâ·üá·ûÄ·üí·ûÑ·û∑·ûÄ·ûÄ·üí·ûÑ·ûÄ·üã·ûñ·üÅ·ûÄ·ûñ·ûª
·ûë·üÅ·ûö·ûª·üÜ·ûÖ·üã·üã·ûò·û∂·ûì·ûâ·üí·ûâ·ûæ·ûü·û∂·ûó·ûé·üê·ûÇ·üí·ûö·ûö·ûü·üã·ûü·üí·ûÜ·û∂·ûè·û¢·üà·ûñ·û∂·ûÅ·ûâ·üí·ûâ·ûæ·û†·ûÄ·ûª·üá·ûì·û∂·ûâ·üí·ûâ·üá·ûâ·üí·ûá·üÇ

·ûä·üÅ·û∏·ûò·üí·ûî·û∑·ûÄ·û∂·ûÄ·üã·ûî·ûì·üí·ûê·ûô·ûÄ·û∂·ûö·ûü·üí·û¢·ûª·üá·ûÖ·ûö·û∂·ûÖ·ûö·ûé·üÜ·û¨·ûò·üí·ûò·üÅ·ûé·û∫·ûü·ûä·û∂·ûì·ûó·üí·ûõ·û£·ûï·üí·ûè·ûö·ûü·üí·ûü·ûª
```

--oem 1

```
/ > $2 62 {&4 & 1 {¬£4 2 &4 {{2'| % {| ¬©2 /5 3 ¬£${23#] % 23 {4'| ¬©3 ¬±#') [{{ {9
{4 ¬©2 {& 1{2 @{{{ {{{,{ 013! {2 {4 ¬©'| {{{{1 &^{1 { {{$ 142 13 01 ¬´3 ¬´|

{{2 {] {2 {|{{‚Ç¨ ) { :

2 23 ‚Ç¨4'| ¬© {2 4 {{{$]23 {24 23 @{{2 ¬©] "| {2 ¬£:45

‚Ç¨ {{ {3 {2 ‚Ç¨\ {2 : [{}" :3 #2'| { 14{ { &1 {{{')') : {2 ,4{ 52 : 5 ¬£‚Ç¨3 {2 ‚Ç¨ { {") ‚Ç¨} ¬´)
{91 {4 ¬©2 {& {" } 0] ({ {$,4 &, 1 } {" $3 {{{"|'] : {{|'] $3 { 52") : *-

{&${{‚Ç¨) $& { { 2 [{ | 4 64 ; {24'| ¬£24 0.0) { 1 4 {4 0 8 &1 3!) = ¬©$44{34&{}

=

{{ : {¬´ 644 ‚Ç¨| 4 2 23 $5 . {4 . "| {23 @:3 {616 #2'| : [{ : ¬£35

{3]{{') : 444{|'| ¬© {{ ‚Ç¨4{6%] [{11{ { & #,1 {3 9") (2 5 {" {4' [14 {22 ‚Ç¨ {4: =
= 4 {{{2]:3 25 | 3 $4 ‚Ç¨{ {34 {$2 {2') &, {4 ¬£3 {9 = {1 15 - \

{{} {53 0] { 22 { 1427] 5 {4 ‚Ç¨3 {5 {4 {4 &, 1#:3 "|| {{ {24 $2 ¬±3 {$3 :

$2 {5{{") : ‚Ç¨3 { 52" :3 {{ 8 [44 | 2 #2{1 1 4 &163 {44 :3

‚Ç¨| 465 { 5213 &1 {3 {2 {] ‚Ç¨ ‚Ç¨ = } {{3$|]:3 {{} {{ 5 {@@4 ¬´1 {2

‚Äû)
```
 Related info:

https://github.com/tesseract-ocr/tesseract/issues/622#issuecomment-275051856

https://github.com/tesseract-ocr/tesseract/issues/654#issuecomment-274574951 Also see https://github.com/tesseract-ocr/langdata/issues/43  Please see attached OCR evaluation reports. The words highlighted in green in the ground truth are being dropped during recognition.

[kan-words-dropped.zip](https://github.com/tesseract-ocr/tesseract/files/736761/kan-words-dropped.zip)


 ```
Processing word with lang kan at:Bounding box=(163,2011)->(1231,2056)
Trying word using lang kan, oem 1
Best choice: accepted=1, adaptable=0, done=1 : Lang result : ‡≤™‡≥ç‡≤∞‡≥Ü‡≤∏‡≥ç, : R=3.81155, C=-2.00782, F=1, Perm=8, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM
str	‡≤™‡≥ç	‡≤∞‡≥Ü	‡≤∏‡≥ç	,
state:	1 	1 	1 	1 
C	-0.137	-0.113	-0.287	-0.108
Best choice: accepted=1, adaptable=0, done=1 : Lang result :        : R=60, C=-1, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM
str	 	 	 	 	 	 
state:	1 	1 	1 	1 	1 	1 
C	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000
```

I would suggest that if the best match for a word comes to be blank, then it be replaced by a string such as @@@@@ so that it is easy to identify missing text and correct the OCR output. Other similar issues:

https://github.com/tesseract-ocr/tesseract/issues/673

https://github.com/tesseract-ocr/tesseract/issues/664

https://github.com/tesseract-ocr/tesseract/issues/633#issuecomment-275348678 @theraysmith 

Is it possibly related to `--strip_unrenderable_words` during training? I have noticed that the images created by text2image have a blank space instead of the missing word when the font is not able to render it.  >The underlying question is, if there is a word that is almost certainly incorrect, would it be better to have it with the error, or have it disappear?

I do not think it should disappear. However, if the word is almost certainly incorrect, then it should be marked in some easy way for users to fix the OCRed txt.

Request feedback from others too - @zdenop @jbreiden @amitdo @stweil etc. > I think the cause of all of these is the precision-recall tradeoff that takes place in linerec.cpp

I find that the words which are getting dropped are also the same ones which are not being picked up by tesseract when using 'makebox'. I has posted a sample with devanagari in another thread. (https://github.com/tesseract-ocr/tesseract/issues/664#issue-201505043 )

Here is a kannada sample:

![kan box missing](https://cloud.githubusercontent.com/assets/5095331/22395065/278b840c-e558-11e6-8ba5-0217592f1661.png)
![kan recognition missing](https://cloud.githubusercontent.com/assets/5095331/22395066/2ea254a0-e558-11e6-8fa9-e6f0cfbc0d17.png)
 Hi

Yeah @Shreeshrii  is correct ,The words not being picked,Is it problem with Segmentation??
@theraysmith Even though the recognition is wrong it should be display with any alternate character either "-" or any thing...  It also might be useful to add a few(1-4) alternative words for each word when using the hOCR format. Please see
https://pdfs.semanticscholar.org/dc3e/f1e05b4b629de5db721efb156d82556ff362.pdf
The ISRI Analytic Tools for OCR Evaluation

> A tilde (~) in an OCR-generated text file is treated as a reject character. A circumflex (^) is interpreted as a suspect marker and serves to mark the following character as suspect. For example, in Ne^vada, the v is marked as suspect. The value of these special characters is assessed when computing marked character efficiency.

I thought that this maybe a standard in OCR evaluation and hence had suggested a marker.

Regardless, I do not think that incorrect words should just disappear.
 > I am not convinced that the unicharset and/or compression are applied correctly to Kannada, which might explain its rather stubborn refusal to improve in accuracy.

@theraysmith Are there any specific issues that you have noticed which I can check with native Kannada speakers? Some feedback regarding Kannada recognition from MNS Rao 

```
I request you to analyse where special efforts are required to improve the program

Essentially kannada script has many problems from OCR point of view.

1. many characters with a very little difference making recognition difficult.
eg: ‡≤Ö ‡≤Ü; ‡≤â ‡≤ä; ‡≤é ‡≤è ‡≤ê; ‡≤í ‡≤ì ‡≤î; ‡≤Ö‡≤Ç ‡≤Ö‡≤É
     ‡≤° ‡≤¢; ‡≤¶ ‡≤ß ‡≤•; ‡≤∞ ‡≤† ‡≤ù; ‡≤™ ‡≤´ ‡≤ò ; ‡≤¨ ‡≤≠ ; ‡≤µ ‡≤Æ ; ‡≥¶ ‡≤Ç ; ‡≤ï‡≥Ø‡≤∞‡≥ç‡≤ï; ‡≥¨ ‡≤ï‡≥ç‡≤Æ 
    
2. in-consistencies in guNita formations
eg: ‡≤µ‡≥Å ‡≤™‡≥Å 

3. vottu of ‡≤§ ‡≤® ‡≤Æ ‡≤Ø ‡≤∞ ‡≤≤  not like main character.

4. ‡≤Ø ‡≤ù ‡≤Æ can lead to wrong recognition because of splitting of parts of the character by OCR process

5. ‡≥ï is part in three different situations ‡≤ï‡≥Ä ‡≤ï‡≥á, ‡≤ï‡≥ã 

I would like to know if the input from my side is helpful to improve the program.

Regards.
MNS Rao
``` :+1: to Shree and MNS Rao !
Hope that Ray can make something out of this feedback. https://shreeshrii.github.io/tess4eval_kannada/
has OCR eval reports for 4.0.0-alpha kan.traineddata 

CER	7.74
WER	9.26
WER (order independent)	5.70

Images and gt are in
https://github.com/Shreeshrii/tess4eval_kannada @theraysmith What page segmentation mode do you use for the testing/accuracy reports?

I am getting better results for kannada with --psm 6 compared to --psm 3 (default) or --psm 4.

 3    Fully automatic page segmentation, but no OSD. (Default)

  4    Assume a single column of text of variable sizes.

  6    Assume a single uniform block of text.
 The tests are done with `.uzn` files.
 https://github.com/tesseract-ocr/tesseract/blob/a1c22fb0d0/ccmain/pagesegmain.cpp#L111 Are there unlv test files for indian languages?

- excuse the brevity, sent from mobile

On 12-Feb-2017 1:38 PM, "Amit D." <notifications@github.com> wrote:

> The tests are done with .uzn files.
> https://github.com/tesseract-ocr/tesseract/blob/
> a1c22fb0d0f6bde165ec7b7c3125420b0ba1d541/ccmain/pagesegmain.cpp#L111
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/681#issuecomment-279203408>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o6oGsQw2bBnbF5zxyIj3jnXquAzjks5rbr4agaJpZM4LuojH>
> .
>
 If you are asking about the original UNLV dataset, the ansswer is 'No'.

It's possible that someone prepared such files as part of indic dataset. @theraysmith Please see page 18 onwards for kannada specific info in the following pdf

http://tdil-dc.in/tdildcMain/articles/644564990964Kannada%20Script%20Grammar%20TDIL%20Version_Ver1.0.pdf

 More Kannada OCR related papers:

http://mile.ee.iisc.ernet.in/mile/publications/softCopy/DocumentAnalysis/Madhav_SPCOM2014.pdf

http://mile.ee.iisc.ernet.in/mile/publications/softCopy/DocumentAnalysis/Nethra_ICFHR2010_Data.pdf

http://mile.ee.iisc.ernet.in/mile/publications/softCopy/DocumentAnalysis/ Yes, both ZWJ and ZWNJ are important for Indic languages. Please see 

http://unicode.org/faq/indic.html

If the sequence U+0924, U+094D is not followed by another consonant letter (such as "na") it is always displayed as a full ta glyph combined with the virama glyph "dev-ta-virama".
Unicode provides a way to force the display engine to show a half letter form. To do this, an invisible character called ZERO WIDTH JOINER should be inserted after the virama:
U+0924	0924	DEVANAGARI LETTER TA
U+094D	094D	DEVANAGARI SIGN VIRAMA (= halant)
U+200D	200D	ZERO WIDTH JOINER
U+0928	0928	DEVANAGARI LETTER NA
This sequence is always displayed as a half ta glyph followed by a full na glyph "dev-half-ta-na". Even if the consonant "na" is not present, the sequence U+0924, U+094D, U+200D is displayed as a half ta glyph "dev-half-ta".
Unicode also provides a way to force the display engine to show the virama glyph. To do this, an invisible character called ZERO WIDTH NON-JOINER should be inserted after the virama:
U+0924	0924	DEVANAGARI LETTER TA
U+094D	094D	DEVANAGARI SIGN VIRAMA (= halant)
U+200C	200C	ZERO WIDTH NON-JOINER
U+0928	0928	DEVANAGARI LETTER NA
This sequence is always displayed as a full ta glyph combined with a virama glyph and followed by a full na glyph "dev-full-ta-virama-full-na
For more detailed information, see Chapter 12, South Asian Scripts-I in The Unicode Standard. For related issues, see "Where is My Character?" [MC] There are at times multiple ways of typing a character, some of the web text may look ok but maynot be correct. There probably needs to be a normalisation step before training.

Please see kannada chapter in 
http://www.unicode.org/versions/Unicode9.0.0/ch12.pdf

Vowel letters are encoded atomically in Unicode, even if they can be ana-
lyzed visually as consisting of multiple parts. Table 12-28 shows the letters that can be ana-
lyzed, the single code point that should be used to represent them in text, and the sequence
of code points resulting from analysis that should not be used.

Table 12-28. Kannada Vowel Letters
For Use Do Not Use
r 0C8A <0C89, 0CBE>
p 0C94 <0C92, 0CCC>
s 0CE0 <0C8B, 0CBE> Related _ https://github.com/tesseract-ocr/tesseract/issues/604 Related - Marathi recognition of repha (sanskrit loan words) and eyelash ra

@theraysmith 

I found that when using Marathi traineddata words which used half ra (repha) were not being recognized correctly, it could be related to the ZWJ and ZWNJ problem.

eg.  ‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§∏‡•Ç‡§∞‡•ç‡§Ø ‡§ß‡§∞‡•ç‡§Æ ‡§∏‡§∞‡•ç‡§µ ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§µ‡§∞‡•ç‡§ó

Since unicode has evolved over time, there maybe legacy representations still around in the webtext.

Please see issue 7 listed on http://www.baraha.com/help/kb/unicode_issues.htm which has examples of different unicode encodings being used. @theraysmith 

https://github.com/anoopkunchukuttan/indic_nlp_library/blob/master/src/indicnlp/normalize/indic_normalize.py

Common normalization in the above includes

* ZERO_WIDTH_NON_JOINER and ZERO_WIDTH_JOINER removal 

In case the LSTM training data build uses something similar on the webtext, you may want to disable that.

 I don't think new models can help with this issue. @theraysmith,

This feature drops perfect words!
https://github.com/tesseract-ocr/tesseract/issues/1080#issuecomment-322206285

I also was hit by this issue.

Two examples from one page from old (1929) Hebrew newspaper: 


GT:
◊û◊í◊ï◊ï◊†◊™-◊ì◊¢◊ï◊™.
OCR:
◊û◊í◊ï◊ï◊†◊™.◊ì◊¢◊ï◊™.

GT:
◊û◊¶◊ë-◊®◊ï◊ó◊ï◊™◊ô◊î◊ù
OCR:
◊û◊¶◊ë◊ë◊®◊ï◊ó◊ï◊™◊ô◊î◊ù

```
Best choice certainty=-2.90379, space=-0.193423, scaled=-20.3265, final=-20.3265
 : .◊™◊ï◊¢◊ì.◊™◊†◊ï◊ï◊í◊û : R=11.8952, C=-2.90379, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM
str	.	◊™	◊ï	◊¢	◊ì	.	◊™	◊†	◊ï	◊ï	◊í	◊û
state:	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 
C	-0.295	-0.192	-0.192	-0.192	-0.191	-2.904	-0.197	-0.192	-0.197	-0.230	-0.193	-0.192
Deleting word with certainty -20.3265

Best choice certainty=-3.59027, space=-0.21691, scaled=-25.1319, final=-25.1319
 : ◊ù◊î◊ô◊™◊ï◊ó◊ï◊®◊ë◊ë◊¶◊û : R=14.0075, C=-3.59027, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM
str	◊ù	◊î	◊ô	◊™	◊ï	◊ó	◊ï	◊®	◊ë	◊ë	◊¶	◊û
state:	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 
C	-0.193	-0.193	-0.191	-0.194	-0.196	-0.192	-0.192	-0.201	-3.590	-0.217	-0.207	-0.202
Deleting word with certainty -25.1319
 : ◊ù◊î◊ô◊™◊ï◊ó◊ï◊®◊ë◊ë◊¶◊û : 
```

In both examples there are two words separated by hyphen. The hyphen looks unclear, and thus Tesseract replaces it with another character. Other than this char all the chars in the two words are recognizes well.
 ~~I didn't test it, but~~ this is probably the way to disable this feature:

https://github.com/tesseract-ocr/tesseract/blob/3ec11bd37a56/ccmain/linerec.cpp#L293

This block of code

```
      // Discard words that are impossibly bad, but allow a bit more for
      // dictionary words, and keep bad words in non-space-delimited langs.
      if (word_certainty >= RecodeBeamSearch::kMinCertainty ||
          any_nonspace_delimited ||
          (word_certainty >= kWorstDictCertainty &&
           Dict::valid_word_permuter(word->best_choice->permuter(), true))) {
        word->tess_accepted = stopper_dict->AcceptableResult(word);
      } else {
        if (getDict().stopper_debug_level >= 1) {
          tprintf("Deleting word with certainty %g\n", word_certainty);
          word->best_choice->print();
        }
        // It is a dud.
        word->SetupFake(lstm_recognizer_->GetUnicharset());
      }
```

Should be replaced with:

```
      word->tess_accepted = stopper_dict->AcceptableResult(word);
```
 Tested on a few pages. Seems to be working well.  Tested with 4.00.00alpha and current head (f566a45b30cd4dd448ec6419160c17310d898aa2) on Linux,tesseract can not be compiled if I disable scrollview:
/bin/sh ../libtool  --tag=CXX   --mode=link x86_64-pc-linux-gnu-g++  -march=native -O2 -pipe -std=c++11  -Wl,-O1 -Wl,--as-needed -o tesseract tesseract-tesseractmain.o libtesseract.la   -lrt -llept -lpthread 
```
libtool: link: x86_64-pc-linux-gnu-g++ -march=native -O2 -pipe -std=c++11 -Wl,-O1 -o .libs/tesseract tesseract-tesseractmain.o  -Wl,--as-needed ./.libs/libtesseract.so -lrt -llept -lpthread -fopenmp
./.libs/libtesseract.so: undefined reference to `ScrollView::AwaitEvent(SVEventType)'
./.libs/libtesseract.so: undefined reference to `ScrollView::Pen(ScrollView::Color)'
./.libs/libtesseract.so: undefined reference to `ScrollView::Update()'
./.libs/libtesseract.so: undefined reference to `ScrollView::SetCursor(int, int)'
./.libs/libtesseract.so: undefined reference to `ScrollView::Image(Pix*, int, int)'
./.libs/libtesseract.so: undefined reference to `ScrollView::ScrollView(char const*, int, int, int, int, int, int, bool)'
./.libs/libtesseract.so: undefined reference to `ScrollView::Clear()'
./.libs/libtesseract.so: undefined reference to `SVSync::StartThread(void* (*)(void*), void*)'
./.libs/libtesseract.so: undefined reference to `ScrollView::DrawTo(int, int)'
collect2: error: ld returned 1 exit status
make[2]: *** [Makefile:605: tesseract] Error 1
```

Some of these can be fixed by including config_auto.h (mostly in lstm), but I am less sure about the SVSync::StartThread() call in ccstruct/imagedata.cpp master is OK now, thanks for the fast merge!  hello~

I've tried this command but cannot get correct text (the version is 3.0.4 with chi_sim.traineddata data file).

command: tesseract h1.jpg stdout -l chi_sim

photo: ![h1](https://cloud.githubusercontent.com/assets/743123/22244016/d5fd61fa-e264-11e6-9a55-cd2db095f216.jpg)  @theraysmith 

Two different types of box file formats are mentioned in Training Tesseract 4.0 wiki.

Please see attached and confirm the format (specially for the Wordstr format). The lstmf files created by the two box/tiff pairs are different in size, even though they are for the same tif file.

[frk.embedsiver.exp0.zip](https://github.com/tesseract-ocr/tesseract/files/721095/frk.embedsiver.exp0.zip)
 When using the WordStr format in one of the box files, 

```
WordStr 1350 3106 1755 3190 0 #Personer.
WordStr 895 2861 1194 2927 0 #M√∏ller. 
WordStr 895 2742 1528 2811 0 #Emilie, hans Kone.
WordStr 899 2618 1507 2691 0 #Birch, Cancelliraad.
WordStr 894 2497 1546 2567 0 #Laura, hans Datter.
WordStr 895 2377 1317 2447 0 #Fru Krogh.
WordStr 897 2256 1724 2329 0 #Otto Rosen, Fuldm√¶gtig.
WordStr 896 2134 1759 2207 0 #Anders,Tjener hos Birch.
WordStr 898 2015 1669 2085 0 #EnTjener hos M√∏ller.
WordStr 696 1746 2422 1821 0 #Handlingen foregaaer i Kj√∏benhavn, i Slutningen af 1848.
```
I get an error (utf8 buffer too big) during processing and the unicharset is not built fully (stops at that line and does not process other box files, but does not stop)
```
=== Phase UP: Generating unicharset and unichar properties files ===
[Sat Jan 21 18:53:04 DST 2017] /usr/local/bin/unicharset_extractor -D /tmp/tmp.hxOIFoYXPH/frk/ /tmp/tmp.hxOIFoYXPH/frk/frk.embedsiver.exp0.box /tmp/tmp.hxOIFoYXPH/frk/
frk.embedsiverline.exp0.box /tmp/tmp.hxOIFoYXPH/frk/frk.UnifrakturMaguntia.exp0.box /tmp/tmp.hxOIFoYXPH/frk/frk.Walbaum-Fraktur.exp0.box
**Utf8 buffer too big, size=57 for Handlingen foregaaer i Kj√∏benhavn, i Slutningen af 1848.**
Extracting unicharset from /tmp/tmp.hxOIFoYXPH/frk/frk.embedsiver.exp0.box
**Extracting unicharset from /tmp/tmp.hxOIFoYXPH/frk/frk.embedsiverline.exp0.box**
Extracting unicharset from /tmp/tmp.hxOIFoYXPH/frk/frk.UnifrakturMaguntia.exp0.box
Extracting unicharset from /tmp/tmp.hxOIFoYXPH/frk/frk.Walbaum-Fraktur.exp0.box
Wrote unicharset file /tmp/tmp.hxOIFoYXPH/frk//unicharset.
[Sat Jan 21 18:53:04 DST 2017] /usr/local/bin/set_unicharset_properties -U /tmp/tmp.hxOIFoYXPH/frk/frk.unicharset -O /tmp/tmp.hxOIFoYXPH/frk/frk.unicharset -X /tmp/tmp
.hxOIFoYXPH/frk/frk.xheights --script_dir=../langdata
Loaded unicharset of **size 48** from file /tmp/tmp.hxOIFoYXPH/frk/frk.unicharset
```
If I do not use this box file, then the unicharset is built with all of the box files
```
=== Phase UP: Generating unicharset and unichar properties files ===
[Sat Jan 21 18:58:01 DST 2017] /usr/local/bin/unicharset_extractor -D /tmp/tmp.wyo1280N2G/frk/ /tmp/tmp.wyo1280N2G/frk/frk.embedsiver.exp0.box /tmp/tmp.wyo1280N2G/frk/
frk.UnifrakturMaguntia.exp0.box /tmp/tmp.wyo1280N2G/frk/frk.Walbaum-Fraktur.exp0.box
Extracting unicharset from /tmp/tmp.wyo1280N2G/frk/frk.embedsiver.exp0.box
Extracting unicharset from /tmp/tmp.wyo1280N2G/frk/frk.UnifrakturMaguntia.exp0.box
Extracting unicharset from /tmp/tmp.wyo1280N2G/frk/frk.Walbaum-Fraktur.exp0.box
Wrote unicharset file /tmp/tmp.wyo1280N2G/frk//unicharset.
[Sat Jan 21 18:58:02 DST 2017] /usr/local/bin/set_unicharset_properties -U /tmp/tmp.wyo1280N2G/frk/frk.unicharset -O /tmp/tmp.wyo1280N2G/frk/frk.unicharset -X /tmp/tmp
.wyo1280N2G/frk/frk.xheights --script_dir=../langdata
Loaded unicharset of **size 143** from file /tmp/tmp.wyo1280N2G/frk/frk.unicharset
Setting unichar properties

``` https://github.com/tesseract-ocr/tesseract/blob/a75ab450a8cc9a2b69cf05f5c4f7a39bc44cbacc/ccmain/applybox.cpp#L71 @amitdo Thanks for pointing out that the string needs to be space delimited. I tried with that version also, it is also getting an error...

Ref: https://github.com/amitdo/tesseract/issues/3#issuecomment-274262671 I updated the relevant wiki [section](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#creating-training-data).

`unicharset_extractor` needs some more code to read the (`WordStr`) textlines-based box file format right. Ray, please consider a new box format with new name - ''\<...>-linebox' for training the LSTM engine, For example see here:
https://github.com/tesseract-ocr/tesseract/issues/832#issuecomment-298688350  Same error (WARNING! LEAK! ) reported in issue

https://github.com/tesseract-ocr/tesseract/issues/529#issuecomment-269325872  Text/words are dropped during Devanagari recognition with --oem 1 option. 

It seems to be related to line segmentation / box creation because the same words are also skipped in the box file created by tesseract run with 'makebox' config file.

Please see attached - 

- image being OCRed, 

- image  showing boxfile skipping the words,

- ground-truth  file and 

- OCRed text

- OCR evaluation report.

![arabic-deva1](https://cloud.githubusercontent.com/assets/5095331/22055988/c65e0f96-dd83-11e6-9f06-bea70dd85be6.png)

![missing-words](https://cloud.githubusercontent.com/assets/5095331/22056003/d63916d6-dd83-11e6-98c9-8478359cdf7e.png)

[arabic-deva1.txt](https://github.com/tesseract-ocr/tesseract/files/713299/arabic-deva1.txt)

[arabic-deva1-san.txt](https://github.com/tesseract-ocr/tesseract/files/713300/arabic-deva1-san.txt)


[arabic-deva1-san_report.html.txt](https://github.com/tesseract-ocr/tesseract/files/713306/arabic-deva1-san_report.html.txt)




 Another sample, where the whole first line is skipped, in addition to missing words

[forbes1849devscript.txt](https://github.com/tesseract-ocr/tesseract/files/715822/forbes1849devscript.txt)
[forbes1849devscript-tif1-hin.txt](https://github.com/tesseract-ocr/tesseract/files/715823/forbes1849devscript-tif1-hin.txt)

- image
- ground truth file
- OCRed text with -l hin

edit:  tif file converted to png for uploading.

![forbes1849devscript](https://cloud.githubusercontent.com/assets/5095331/22095836/e3ddf3f0-de3d-11e6-92e3-7fb8611b43be.png)
 Is it related to https://github.com/tesseract-ocr/tesseract/issues/633#issuecomment-275348678 ? It seems some words are being recognized as 'blanks' - see the following from the debug info - while processing image shown in https://github.com/tesseract-ocr/tesseract/issues/664#issue-201505043

```
Processing word with lang hin at:Bounding box=(236,2830)->(1276,2924)
Trying word using lang hin, oem 1
Best choice: accepted=1, adaptable=0, done=1 : Lang result :       : R=50, C=-1, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM	NORM
str	 	 	 	 	 
state:	1 	1 	1 	1 	1 
C	-1.000	-1.000	-1.000	-1.000	-1.000
```
and
```
Processing word with lang hin at:Bounding box=(234,2248)->(1969,2326)
Trying word using lang hin, oem 1
Best choice: accepted=1, adaptable=0, done=1 : Lang result : ‡§Æ‡§Æ : R=0.947715, C=-1.37049, F=1, Perm=8, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM
str	‡§Æ	‡§Æ
state:	1 	1 
C	-0.086	-0.089
Best choice: accepted=1, adaptable=0, done=1 : Lang result :              : R=120, C=-1, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM
str	 	 	 	 	 	 	 	 	 	 	 	 
state:	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 
C	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000
```  Verified that this compiles and runs on macOS El Capitan with homebrew gcc. I don't believe clang compiles at the moment so not sure if it works for that.

Also added an #error if SIMD checking is missing. Autotools already causes configure to fail if there is no SIMD implementation, so if Makefiles are generated something is wrong.  >Also added an #error if SIMD checking is missing.

This is not the desired behavior. There is a (slow) fallback function that runs when no simd is found. This `#else` code will prevent its execution.

>Autotools already causes configure to fail if there is no SIMD implementation

Are you sure? This should not happen.
 >I don't believe clang compiles at the moment so not sure if it works for that.

If you can test with clang on macOS and report issues, if any, please do it.  I looked into what compilers provide the __get_cpuid() built-in intrinsic - GCC (including mingw) and clang. Microsoft's compiler has an equivalent named __cpuid(). It doesn't matter what OS we're running on, so after establishing we're on x86, it's better to check for the compiler than exhaustive list all platforms. I changed it to reflect this.

I believe the #error should stand. Code that lacks an implementation for a specific compiler should be a build error. This should be better than silently building an inferior tesseract. In any case only compilers outside of GCC, clang, mingw, Microsoft C++ and Intel C++ (which behaves like GCC on Linux and Microsoft on Windows) should hit the #error so anything left is quite rare. @stweil, what are your thoughts on this? (please read my remarks) I'm stuck without a full dev environment for a few days and can't do this
easily. I support the change @stweil proposed if anyone else wants to do
it.
On Sat, Jan 21, 2017 at 03:50 Stefan Weil <notifications@github.com> wrote:

> *@stweil* requested changes on this pull request.
> ------------------------------
>
> In arch/simddetect.cpp
> <https://github.com/tesseract-ocr/tesseract/pull/661#pullrequestreview-17805561>
> :
>
> > @@ -26,7 +26,7 @@
>  #endif // x86 target
>
>  #if defined(X86_BUILD)
> -# if defined(__linux__) || defined(__MINGW32__)
> +# if defined(__GNUC__) || defined(__MINGW32__)
>
> Testing __GNUC__ is sufficient, as MinGW also uses gcc, so the test for
> __MINGW32__ can be removed.
> ------------------------------
>
> In arch/simddetect.cpp
> <https://github.com/tesseract-ocr/tesseract/pull/661#pullrequestreview-17805561>
> :
>
> >  SIMDDetect::SIMDDetect() {
>  #if defined(X86_BUILD)
> -# if defined(__linux__) || defined(__MINGW32__)
> +# if defined(__GNUC__) || defined(__MINGW32__)
>
> Here the test for __MINGW32__ can also be removed.
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/661#pullrequestreview-17805561>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABvcM6qnB-Jkgoh25PwsvTfrWJMBWYnmks5rUfD9gaJpZM4Lje3X>
> .
>
 Looks good. Thanks.
On Mon, Jan 23, 2017 at 04:45 Stefan Weil <notifications@github.com> wrote:

> @jbarlow83 <https://github.com/jbarlow83>, is this commit
> <https://github.com/stweil/tesseract/commit/fa677f1ba183c6265fb11a14328dca6b8dd34368>
> fine for you? If yes, I'd make a pull request for it. I kept the original
> date and you as the author.
>
> ‚Äî
> You are receiving this because you were mentioned.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/661#issuecomment-274479222>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABvcM2_5wQaMJ4kFW1pKXi54dIC6kYjYks5rVKDWgaJpZM4Lje3X>
> .
>
  https://groups.google.com/forum/#!topic/tesseract-ocr/vvMldrkcuOQ has asked:
> I have a pdf (scanned) and now i make a searchable pdf from this.
>First i generate a black/white multipage tif, and with tesseract i can make a searchable pdf.
> But is it somehow possible to integrate the original pdf images?
> because the generated tif has not the same quality like the original (maybe the scaned image is in color).

How to reproduce:

1. Assume one page with a colored background `in.pdf`, converted to `in.ppm` image
1. preprocess `unpaper in.ppm in-cleaned.ppm` 
1. process with (example) `tesseract in-cleaned.ppm out -l deu+eng --oem 2 pdf txt`
1. tesseract mixed output file `out.pdf`has now a blotchy background (from the `unpaper` step above)

![20170113-10 09 17_auswahl](https://cloud.githubusercontent.com/assets/1151915/21924224/72ad2b02-d978-11e6-8b44-12c03da58aa2.png)

Is there any way to "feed-in" the original `in.ppm` as image, so that this is used instead of `in-cleaned.ppm` when creating the `out.pdf` ?

So what is wanted is original input image plus ocr layer, so that output looks like
![20170113-10 12 22_auswahl](https://cloud.githubusercontent.com/assets/1151915/21924289/db580474-d978-11e6-8fd6-05670345ff34.png)
 This is a complicated way of asking for an option to send one image through OCR and insert a different image in the output PDF.

```
tesseract --pdf-image original.png cleaned.png -l eng --oem 2 pdf  # not implemented, could work like this
```

I know this was requested before and I believe @jbreiden said it would be added to the PDF renderer  at some point. Sounds reasonable.

It is fairly simple to swap an image using qpdf's C++ API.
On Fri, Jan 13, 2017 at 18:33 jbreiden <notifications@github.com> wrote:

> I'm very reluctant to make Tesseract PDF generation fancy. I wonder if we
> can do an image swap like this outside of Tesseract, using one of the PDF
> manipulation toolkits.
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/660#issuecomment-272595203>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABvcMz65b8BY11SURxHH8RJPXNgJj_N6ks5rSDQHgaJpZM4Liq1Q>
> .
>
 @jbreiden It's the last really missing issue. 
The new algorithm is already a boost in quality. I reach here up to 100% OCR quality (for `--oem 2 -l deu+eng`) including these beasty "Umlauts" √§√∂√º√Ñ√ñ√ú√ü....

If this helps, I will donate some mBTC for implementing it just right now. Just post your receiving address. @jbarlow83 background info. As you know, I recently wanted to try your OCRmyPDF because I found the interesting `-clean` option (source: https://media.readthedocs.org/pdf/ocrmypdf/latest/ocrmypdf.pdf ) which would have solved my problem:

which "does not alter the final output":

```
--clean
uses unpaper to clean up pages before OCR, but does not alter the final output.  This makes it less
likely that OCR will try to find text in background noise.
‚Ä¢
--clean-final
uses unpaper to clean up pages before OCR and inserts the page into the final output.  You
will want to review each page to ensure that unpaper did not remove something important.
```
but unfortunately this does not work with tesseract 4, at the present.

So I looked for bug reports, if tesseract could pass the original input image to the output; and filed the present issue. I think invisible text only output would be far more useful for developers that integrate tesseract or anyone who wants to do something fancy. It would still make sense to keep the existing OCR with image option of course. As a plus, it's should be easier to suppress the image than add a different one.

OCRmyPDF (which I maintain) use Ghostscript to rasterize and then runs one of its two PDF renderers. One uses Tesseract hOCR and provides more features but is not as good at producing the OCR text layer as Tesseract PDF, so I also provide Tesseract PDF. If Tesseract could produce a invisible text only I could offer all the features for both, and work towards phasing out the hOCR renderer. When possible I already do graft the text layer onto the existing PDF instead of constructing a new one.

In addition to OCRmyPDF `pdftk multibackground` could merge an OCR layer onto an existing PDF (by "watermarking"), so there is at least one other supported tool out there that should work out of the box. There's some other tools that wrap tesseract for use with PDFs as well.

In writing this I've made a case for not using qpdf because other tools should be able to do the job with an invisible text PDF, but for interest's sake case here is [example code](
https://github.com/qpdf/qpdf/blob/master/examples/pdf-invert-images.cc) that inverts black and white for all images; clearly this is close to how one would replace an image outright. Looks really good @jbreiden. 

Works great in pdftk. No display issues and PDF syntax looks fine.

PyPDF2 is also capable of merging. It does not have the equivalent of "multibackground" but merge pages manually. Here is merging one page:

```python
In [1]: import PyPDF2 as pypdf

In [4]: pdf_text = pypdf.PdfFileReader(open('text.pdf', 'rb'))

In [5]: pdf_image = pypdf.PdfFileReader(open('images.pdf', 'rb'))

In [6]: page_text = pdf_text.pages[1]

In [7]: page_image = pdf_image.pages[1]

In [8]: page_text.mergeRotatedScaledTranslatedPage(page_image, 0, 1.0, 0, 0, expand=False)

In [9]: out = pypdf.PdfFileWriter()

In [10]: out.addPage(page_text)

In [11]: with open('pypdfmerge.pdf','wb') as o:
    ...:     out.write(o)
    ...:     

```

For reference, pdfbox did not work out of the box. As far as I can tell the closest command in pdfbox is
```
java -jar pdfbox-app-2.0.2.jar OverlayPDF images.pdf text.pdf pdfboxoverlay.pdf
```

However pdfbox takes the unusual approach of rasterizing the overlay PDF as a bitmap and drawing it on top of the base page, making it useless regardless of image/text order. (I suppose when you go to the trouble implementing a full PDF renderer in Java you feel compelled to use it even when it's not strictly needed.)
 I don't know about calling it a naked PDF because there's nothing exciting to see in it. It's more of a phantom or spectral apparition PDF, having form without substance.

`ocr_text_only` would do, or `suppress_images`? Not nearly as fun, but practical. How about `text_only_pdf` ?

@jbreiden  is it also possible to use a .pdf file as input to tesseract directly?  `pdf_invisible_text_layer_only`
+
a config file `pdfinvisible` (or maybe `pdf0`) @Shreeshrii PDF is a very complex vector-based file format. Tesseract works only on images. It is much easier to write PDFs that use a limited set of PDF features than read arbitrary PDFs. Have a look at OCRmyPDF (which I develop) - it addresses the details of using tesseract to apply OCR to PDFs. @jbreiden @jbarlow83 @amitdo  info: I just built the *whole*  toolchain from their git repos (tesseract, ocrmypdf, unpaper), and have ghostscript version 9.20 ready in a dedicated debian 9 "OCR VM" on my Qubes OS system.

Pls. let me know, what (if) you want me to test - I have time to test and want to help you. @Shreeshrii  http://kiirani.com/2013/03/22/tesseract-pdf.html

The PDF/invisible text output you guys are implementing works quite well for me using OSX 'Preview' but for a little jerkiness depending on scaling, of course.

This is quite a big deal, in my opinion, as it will allow those who have, for instance... legal documents containing notary stamps in color, or in my use-case aviation emergency manuals with color-coded pages, to keep their original copies unmodified from their scanners, but modify them in a clean way into searchable documents.  Thanks for this. Thanks for info on pdf to images conversion for use with tesseract. 

I usually use ghostscript for the purpose e.g.

```
gs -dNOPAUSE -dBATCH  -r300x300 -sDEVICE=tiffg4  -dFirstPage=168  -dLastPage=174 -sOutputFile=sample%03d.tif ./sample.pdf
```

I will give the other suggestions a try (including a new one suggested by zdenop in the forum- https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/vvMldrkcuOQ/xLES3_ZoEwAJ )

@jbreiden Thanks, Jeff, for this invisible text output pdf which can be merged with the original pdf.

 >Ray will eventually merge this patch, but it is hard to predict when. I am posting here for anyone who is impatient or excited.

I suggest to merge this to master now. Ray can modify it later if needed. @zdenop https://github.com/tesseract-ocr/tesseract/commit/effa5741e6ef8bcb37d68250ca39c92fae85f6a9 does not work: breaks tesseract [UPDATE:] ~~and creates broken files~~. Who has tested that patch, and how ?
 >effa574 does not work: breaks tesseract and creates broken files. Who has tested that patch, and how ?

I had the impression that Jeff tested it. Maybe I was wrong.  @amitdo with "it breaks" I mean, that the "normal" function of tesseract is broken, https://github.com/tesseract-ocr/tesseract/commit/effa5741e6ef8bcb37d68250ca39c92fae85f6a9 always creates a blank pdf. And now, if I combine my original input pdf with the created output, I appear to have two text layers. Who can help, it's getting more and more complicated. 

Let's go back to the roots:
Why not simply passing the original input image to the output, inside tesseract ?

#### my wish
```
tesseract image.png image.ocr -c image_passthrough=1 pdf
```
which then creates
* image.txt (with the ocr-ed text)
* image.ocr.pdf (mixed-mode pdf with the original image.png and image.txt)

And this setting ( -c image_passthrough=1 ) should be the tesseract default, in my view.
 Tested. With effa574, `tesseract -c textonly_pdf=1` works correctly and `tesseract -c textonly_pdf=0` produces an invalid PDF.

The problem is missing a "/" in front of XObject.
 Fix in #667  @jbarlow83 works. But when I look to capi.cpp then - I think - you have to apply the corresponding change in capi.h see
https://github.com/Wikinaut/tesseract/commit/5e8089107a4bc77c3eca51f6404c41a1854e652e#diff-1ff9fac4997a03321dc873248bcf1309

(I am not sure, whether my patch is correct.))
 @jbreiden regarding "image_passthrough", pls.allow me to explain my workflow, which in my view, is quite common.

* I already _have_ mixed-mode multi-page PDFs ("input.pdf") -- for example, ocr-ed with the old tesseract.
* I already found that the new LSTM mode is very much better and want to regenerate the text layer for all my archived PDFs...
* ...without loosing the high image quality of my existing scans.

With the new `textonly_pdf`mode I managed this, but it requires this additional ugly step (marked with (*)

* split input.pdf into single pages for tesseract (use pdftoppm, or gs or whatelse)
* for each $image do `tesseract input-$image.ppm textonly-$image -c textonly_pdf pdf` command
* `pdftk textonly-*.pdf cat output "textonly.pdf"
* (*) remove text layer from input.pdf -> input-without-text.pdf
* `pdftk input-without-text.pdf multibackground textonly.pdf output new-mixed-mode.pdf`

So it's still very long way with your new option.

Please, perhaps you find a possible way when input image type is a single page (and losslessly coded)

* gif (not really needed)
* **png** ; or 
* **ppm**, pbm, pgm

(**preferred**)
 to pass-through such image types.

I think, it's possible. why again *.jpg (step 1) ? Never ever use jpg with text files.
Please don't tell the mass about jpeg. Use png, ppm, or tif... I already developed code for this using -c textonly_pdf=1, thanks Yes and no, why can't tesseract do this (pass-through the "bunch of input images") ? Pls. elaborate your step
"Extract the images from the PDF file (don't render!). For this example, we'll assume jpeg."

I use
        pdftoppm -aa yes -r 400 -scale-to-x 2000 -scale-to-y 2800 in.pdf image
 Was there a final resolution to this request for putting back in the original images? @Wikinaut? Yeah, that doesn't work for me: `Could not set option: textonly_pdf=1`

I'm using version 3.05.00 installed via homebrew.  @Jmuccigr I am definitely _not_ happy with the current implementation, and decided some months ago to stay silent and let other users come back with the issue (hoping, that my original proposal - pass-through the original input image without transcoding it - will be implement in forthcoming versions). >I'm using version 3.05.00

The `textonly_pdf` parameter is only available on the HEAD (4.00) @Wikinaut, yeah, my workflow at some point involves adding OCR'ed text to an optimized PDF. Having the OCR step degrade the quality of that PDF kind of spoils it. Just getting back to this now that 3.05.01 has hit homebrew and wanted to say that it seems to be working.

I've tested it out by running text-only tesseract on a 2x version of an image - which tends to give better results if the original dpi is too low - and then combining that text-only PDF with a PDF made from the original image, which keeps the file size down.  @theraysmith 

Ray, Thanks for updating the Wiki page for LSTM training. A few more changes in the following may be required in light of the updates:

> In theory it isn't necessary to have a base Tesseract of the same language as the neural net Tesseract, but currently it won't load without something there.

> Finally, combine your new model with the language model files into a traineddata file:

Please also provide command for building traineddata with just the .lstm file or with just .lstm and lstm-dawgs (so as to minimize traineddata filesize, if only LSTM is going to be used).

 Also helpful will be info on:

1.  how big the training text should be (number of lines) for:

- fine tuning and 
- adding a layer. 

2. what kind of text is recommended/can be used?

- paragraphs, sentences
- word lists
- orthographic syllables

e.g. For Sanskrit, I want to train by adding a layer using a list of most frequent orthographic syllables so that the unicharset is expanded to include all possible aksharas. Will this work?

3. Should training be done using different --ptsize ? If so, is it possible to modify tesstrain.sh to take a list of --ptsize options (similar to the array for exposure --exp). My own question - the answer can also be added to the wiki.

Is it OK to mix b/w images, produced by text2image, with gray and/or color images from book scan? 
 Also, is there a way for tesseract to create line boxes for a scanned image.

It will make it easier to put the truth text if the box dimensions are
pre-made.

- excuse the brevity, sent from mobile

On 13-Jan-2017 2:14 PM, "Amit D." <notifications@github.com> wrote:

> My own question - the answer can also be added to the wiki.
>
> Is it OK to mix b/w images, produced by text2image, with gray and/or color
> images from book scan?
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/659#issuecomment-272390460>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o7lvUh_kbAfVygdwAU1ZBpPaiXCaks5rRzlqgaJpZM4LigRu>
> .
>
 >Also, is there a way for tesseract to create line boxes for a scanned image. It will make it easier to put the truth text if the box dimensions are pre-made.

This feature is not implemented. I will try to implement it sometime in the next few days and send a PR. Another question:

what effect does the add a layer type of training have regarding the unicharset in the new traineddata.

For add a layer, a unicharset if required eg. `lstmtraining -U ~/tesstutorial/bih/bih.unicharset` 
Does this

- add to the unicharset from the existing lstm file
- replace the unicharset from the existing lstm file
- replace parts of the unicharset in the existing lstm file

Meaning, if we just want to add a few characters to the unicharset, is it enough to have good sampling of those or do characters from the lstm unicharset (which are unknown at this point) need to be there too. Traineddata files in tessdata for 4.0 were trained with `--perfect_sample_delay 19`. The dafault value for the variable is 4.

The training command examples do not specify this. What are the recommended value to be used for finetuning and adding a layer?

 @theraysmith 

Please see 
https://groups.google.com/forum/#!topic/tesseract-ocr/-N5uPdSvJGA
https://github.com/tesseract-ocr/tesseract/issues/642
https://github.com/tesseract-ocr/tesseract/issues/561

'core dumped' error in these cases seems to be related to using --eval_listfile as part of the lstmtraining command eg.
`--eval_listfile ~/tesstutorial/saneval/san.training_files.txt`

Please update the wiki, if you can confirm this, so that people are able to run the tutorial.

Thanks. @amitdo Question to you, let me explain as briefly as I can:

* I have successfully LSTM ocr-ed 700 pages of a book using `tesseract in.ppm out -l deu --oem 2 txt`.
* I manually corrected the output file out.txt to out.corrected.txt.

I found certain *groups* of ocr failures in my scan case, two examples which were always wrongly detected
* "Citro√©n" instead of the original word "Citro√´n"
* "fiir" instead of "f√ºr"

#### Question

Is there an easy way - I guess, it could be possible and would be very userfriendly -

* a way to easily retrain a Tesseract language (or a copy) by re-feeding a corrected txt version in order to retrain ?
* What will be the commandline ?
 Hi @Wikinaut!

Believe it or not, I haven't started yet playing with training the LSTM engine, so I don't know enough to answer your question. Hopefully, this serious 'bug' will be fixed sometime in the next month :-)

Some observations: 
Both 'f√ºr' and 'fiir' are in the wordlist.
https://raw.githubusercontent.com/tesseract-ocr/langdata/master/deu/deu.wordlist

'√´' does not appear in the training text, '√©' appears 4 times.
https://github.com/tesseract-ocr/langdata/blob/master/deu/deu.training_text

>Caf√© So f√ºr
Ren√© f√ºr
Caf√©s
Andr√©

'f√ºr' appears 10 times in the training text.

>OCR Engine modes:
  0    Original Tesseract only.
  1    Neural nets LSTM only.
  2    Tesseract + LSTM.
  3    Default, based on what is available.

Did you try `--oem 1`? @amitdo my original text uses a very "bad" font, where the characters overlap very often, and the characters often look, but are not, "ligatures". This explains the "fiir" in many cases (in my case).

I also tried `--oem 1`. but found, that `--oem 2` gave the best results. However, I did not find an explanation, what this "mixed operation modes" are really doing, pls. can we add a short text to `"2 Tesseract + LSTM", I can supply a PR, but do not know what a correct and short description is.
 @amitdo and regarding my question above, can I "quickly" retrain my "deu" training data (or a copy of it) with a corrected text, this would be really great?

Promise: some mBitcoins for this today! Whoever coded the LSTM: Big APPLAUSE for him or her! LSTM - New OCR engine based on neural networks.
Tesseract - old OCR engine  (started in the mid 80s) - does character segmentation and shape matching.

 @amitdo yes, but what if one selects `--oem 2` ? Are then the results of both engines being compared or otherwise evaluated together ? The two engines runs and the results are combined in some way. :+1:  As said, I have zero experience training the LSTM engine.

What you want is described here:
https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#fine-tuning-for-impact @Wikinaut 

>my original text uses a very "bad" font, where the characters overlap very often, and the characters often look, but are not, "ligatures". This explains the "fiir" in many cases (in my case).

Please provide a sample image for testing. @Shreeshrii 

#### "f√ºr" vs.Tesseract: "fiir"

case 1
![20170116-07 50 12_auswahl](https://cloud.githubusercontent.com/assets/1151915/21973387/90011a70-dbc0-11e6-9889-d104dad6822a.png)

case 2
![20170116-07 52 18_auswahl](https://cloud.githubusercontent.com/assets/1151915/21973407/beb10966-dbc0-11e6-8b86-f89117a7918c.png)

case 3
![20170116-07 53 20_auswahl](https://cloud.githubusercontent.com/assets/1151915/21973428/e1ec5bba-dbc0-11e6-9e9a-8e65f50a9d60.png)

#### "Citro√´n" vs. Tesseract: "Citro√©n"

Case 1
![20170116-07 54 14_auswahl](https://cloud.githubusercontent.com/assets/1151915/21973442/00e6562e-dbc1-11e6-9176-3394c7078f86.png)

Case 2
![20170116-07 55 12_auswahl](https://cloud.githubusercontent.com/assets/1151915/21973462/225f7678-dbc1-11e6-9e53-0b487fb272a4.png)

 √´ is not in the training_text. Needs to be added, hope that @theraysmith  will include in next training.

f√ºr - is being recognized -see attached output files.
[e1ec5bba-dbc0-11e6-9e9a-8e65f50a9d60-oem1-png.txt](https://github.com/tesseract-ocr/tesseract/files/707752/e1ec5bba-dbc0-11e6-9e9a-8e65f50a9d60-oem1-png.txt)
[beb10966-dbc0-11e6-8b86-f89117a7918c-oem1-png.txt](https://github.com/tesseract-ocr/tesseract/files/707753/beb10966-dbc0-11e6-8b86-f89117a7918c-oem1-png.txt)
[90011a70-dbc0-11e6-9889-d104dad6822a-oem1-png.txt](https://github.com/tesseract-ocr/tesseract/files/707754/90011a70-dbc0-11e6-9889-d104dad6822a-oem1-png.txt)

though √∂ was not recognized in one image.

 >√´ is not in the training_text. Needs to be added, hope that @theraysmith will include in next training.

https://en.wikipedia.org/wiki/German_language#Orthography
It's not in the a German alphabet. it's from French. Still, maybe it should be included with the deu traineddata. It does looks like 'ii' (two 'i's), doesn't it?

Maybe the training text needs some examples of 'ii' so it can learn to distinguish it from '√º'. @Shreeshrii in my conversion, these words "f√ºr" were recognized as "fiir". May be due to use of "unpaper" as preprocessor, and/or my use of "-l deu+eng --oem 2" for the conversion.

There were many more occurences of false-detecting "fiir" in my about 700 pages of text. This was the most frequent conversion error and triggered me to aksing you how I could retrain tessdata by using my corrected text file. A simple command line would be very helpful for such cases.

@amitdo regarding "ii": In my text, tesseract correctly ocr-ed "ii" in the words "Gummiisolation", and "Daiichi" (a name). @theraysmith You appear to be the expert for answering my question, if such a procedure for re-training (tesseract + LSTM) is easily possible, or not:

(I described it already above:)

Can I "quickly" retrain my "deu" (or "deu+eng") training data (or a copy of it) with a corrected text ?

* in.pdf -> tesseract -> out.txt
* out.txt -> manually corrected -> **corrected.txt**
* retraining tesseract (to get tesseract' )with these inputs: in.pdf + **corrected.txt**

re-running with re-trained tesseract' should in the best case result in
* in-pdf -> tesseract' -> corrected.txt 

I found but do not (yet) understand the present training explanations in the Wiki, and perhaps is my idea not yet covered. @theraysmith Thank you for your swift answer.

In my case, many "f√ºr" were detected as "fiir", when or when not using `unpaper` (I cannot remember, because I tried many different runs).

I will retry - and report here - with only `-l deu` in order to present a correct case for reproduction. @theraysmith to be more precise:

I tried tesseract with  `-oem 0, 1, 2` and found that `"2"` gave the best results (for a 700 pages scan). I rerun with and without `unpaper`, and found some differences. And I only used `-l deu+eng`, because my German text used some English terms. Now, as I have a manually corrected reference output text I can present (later) a kind of matrix with the results. New box renderer
https://github.com/amitdo/tesseract/issues/3 @stweil @amitdo Stefan, please can you also make sure that common words with a https://en.wikipedia.org/wiki/Diaeresis_(diacritic) (Deutsch: Trema) like `Citro√´n` are correctly trained ?
 @stweil Thanks for your swift answers. Let me know, if I can help. Wikinaut, you can try the new best/Latin.traineddata @Wikinaut, 

The best/eng.traineddata doesn't have the marks you want. 

Try the new best/Latin.traineddata.
 The problem with "fiir" instead of "f√ºr" is a typical example of the ii / √º confusion which still exists in the current best traineddata. The wordlist for `best/Latin.traineddata` includes "dafiir" (correct: "daf√ºr"), "fiir" (correct: "f√ºr") for example. >The problem with "fiir" instead of "f√ºr" is a typical example of the ii / √º confusion which still exists in the current best traineddata. The wordlist for best/Latin.traineddata includes "dafiir" (correct: "daf√ºr"), "fiir" (correct: "f√ºr") for example.

Try to correct the mistakes in the wordlist and see if it helps to recognize these words. ... or run Tesseract without a wordlist. I recently removed the wordlists from the best traineddata to see and compare the real quality of the trained LSTM data. This is impossible when Tesseract uses a wordlist. With wordlists, Tesseract also invents words which don't occur in the original text ("computer" and "Google" in historical documents).

PS. Is there a parameter which disables the post OCR steps (like wordlist evaluation) in Tesseract without the need to remove the wordlists from the traineddata files? Yes, there is a parameter which disables the wordlist evaluation.

I don't remember its name right now... The parameter is lstm_use_matrix. >I guess, you can make the following two config variables as false to not load the wordlist dawg files. load_system_dawg T
load_freq_dawg       T

load_system_dawg should work.

load_freq_dawg seems to have no impact on the lstm recognizer.


 https://github.com/tesseract-ocr/tesseract/blob/27d25e9c99ca65a2137f54f4c9c2bd20fc050024/dict/dict.cpp#L307 I wonder why LSTM needs its own word list. I'd expect that a word list is different for different languages, and it is also reasonable to use different word lists for different kinds of text (topic, date) of the same language, but it should not depend on the OCR algorithm.  @DanBloomberg

Can you suggest a way for improving text line finding?

ref: http://www.dicklyon.com/phototech/PhotoTech_11_DocImage_Slides.pdf

See https://github.com/tesseract-ocr/tesseract/files/696122/ara.TRAINING.zip for box/tiff pairs and https://drive.google.com/file/d/0B1JdJ8IXNweRX3NEMkZfX3gtdlk/view?usp=sharing for  some sample image files for Arabic.

For Devanagari samples see https://github.com/tesseract-ocr/langdata/issues/40

 Improve with respect to what?   What is in leptonica?  What is in tesseract?

Have you looked at these prog files:
    arab_lines.c
    livre_figures.c Dan,

Thanks for your prompt response and links to the appropriate leptonica program files. 
https://github.com/DanBloomberg/leptonica/blob/master/prog/arabic_lines.c
https://github.com/DanBloomberg/leptonica/blob/master/prog/livre_pageseg.c
I will take a look at those. 

FYI,  I am not a C programmer. I am interested in good open source OCR for Indian languages and am trying out/testing tesseract for that. I am looking for improvement in tesseract in correctly identifying the textlines for complex scripts such as devanagari etc so as to get a more accurate OCR at the end. I also tested recently for Arabic text with diacritics.

A search yesterday led to your presentation on the net. Since tesseract uses leptonica already, I thought that you might be able to suggest better ways of textline finding in tesseract, specially for Arabic Diacritics, Devanagari script etc. (I have edited the earlier post with links to some sample files).

I am building the leptonica programs now and will try out the arabic_lines program on your sample image as well as other samples provided by Arabic users of tesseract.

 I tried arabic_lines with both arabic diacritics and devanagari sample and it is marking the texlines well. Results attached. 
![result-arabic-diacritics](https://cloud.githubusercontent.com/assets/5095331/22008592/a8101138-dca2-11e6-8d85-a0cbcc078304.png)
![result-deva](https://cloud.githubusercontent.com/assets/5095331/22008595/a814004a-dca2-11e6-99e6-26cedd4bc4e3.png)
![textlines-arabic-diacritics](https://cloud.githubusercontent.com/assets/5095331/22008594/a8129854-dca2-11e6-848e-4378a24beb26.png)
![textlines-deva](https://cloud.githubusercontent.com/assets/5095331/22008593/a811e328-dca2-11e6-9f39-977c3942e622.png)



 For reference, these are the two input images used with arabic_lines.

![arabic0](https://cloud.githubusercontent.com/assets/5095331/22050368/4f644e82-dd60-11e6-9d37-5cb1b2696392.png)
![arabic-deva1](https://cloud.githubusercontent.com/assets/5095331/22050369/4f6ac992-dd60-11e6-8160-57b84a1bd464.png)
 Yes, the colors tell you at a glance if you've broken or merged textlines.

Of the 4 bad merges that you show (6 lines into 2), all but one are
trivially fixed with small changes in the morphology parameters.  I'll do
some experimenting.

  -- Dan

On Mon, Jan 23, 2017 at 11:28 AM, theraysmith <notifications@github.com>
wrote:

> Not so good as you might think?
> Aren't the 3 yellow lines near the top and the 3 orange lines at the bottom
> supposed to be different colors?
> I think they have been fused into one line.
>
> On Mon, Jan 16, 2017 at 9:20 PM, Shreeshrii <notifications@github.com>
> wrote:
>
> > I tried arabic_lines with both arabic diacritics and devanagari sample
> and
> > it is marking the texlines well. Results attached.
> > [image: result-arabic-diacritics]
> > <https://cloud.githubusercontent.com/assets/5095331/22008592/a8101138-
> dca2-11e6-8d85-a0cbcc078304.png>
> > [image: result-deva]
> > <https://cloud.githubusercontent.com/assets/5095331/22008595/a814004a-
> dca2-11e6-99e6-26cedd4bc4e3.png>
> > [image: textlines-arabic-diacritics]
> > <https://cloud.githubusercontent.com/assets/5095331/22008594/a8129854-
> dca2-11e6-848e-4378a24beb26.png>
> > [image: textlines-deva]
> > <https://cloud.githubusercontent.com/assets/5095331/22008593/a811e328-
> dca2-11e6-9f39-977c3942e622.png>
> >
> > ‚Äî
> > You are receiving this because you were assigned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/657#
> issuecomment-273025064>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AL056Up0oVZPWQ2YcPpA-
> pm4Ju1d_k_lks5rTE-BgaJpZM4LiGKh>
> > .
> >
>
>
>
> --
> Ray.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/657#issuecomment-274591196>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLNQvLtkSc1Z9yzubMWNO6hM6YwX8ks5rVP9dgaJpZM4LiGKh>
> .
>
 I've finished experimenting and will push some modified code to leptonica
to make this a bit more robust.

Changes will be in both pixExtractTextlines() and the demonstration code in
prog/arabic_lines.

  -- Dan

On Mon, Jan 23, 2017 at 11:35 AM, Dan Bloomberg <dan.bloomberg@gmail.com>
wrote:

> Yes, the colors tell you at a glance if you've broken or merged textlines.
>
> Of the 4 bad merges that you show (6 lines into 2), all but one are
> trivially fixed with small changes in the morphology parameters.  I'll do
> some experimenting.
>
>   -- Dan
>
> On Mon, Jan 23, 2017 at 11:28 AM, theraysmith <notifications@github.com>
> wrote:
>
>> Not so good as you might think?
>> Aren't the 3 yellow lines near the top and the 3 orange lines at the
>> bottom
>> supposed to be different colors?
>> I think they have been fused into one line.
>>
>> On Mon, Jan 16, 2017 at 9:20 PM, Shreeshrii <notifications@github.com>
>> wrote:
>>
>> > I tried arabic_lines with both arabic diacritics and devanagari sample
>> and
>> > it is marking the texlines well. Results attached.
>> > [image: result-arabic-diacritics]
>> > <https://cloud.githubusercontent.com/assets/5095331/
>> 22008592/a8101138-dca2-11e6-8d85-a0cbcc078304.png>
>> > [image: result-deva]
>> > <https://cloud.githubusercontent.com/assets/5095331/
>> 22008595/a814004a-dca2-11e6-99e6-26cedd4bc4e3.png>
>> > [image: textlines-arabic-diacritics]
>> > <https://cloud.githubusercontent.com/assets/5095331/
>> 22008594/a8129854-dca2-11e6-848e-4378a24beb26.png>
>> > [image: textlines-deva]
>> > <https://cloud.githubusercontent.com/assets/5095331/
>> 22008593/a811e328-dca2-11e6-9f39-977c3942e622.png>
>> >
>> > ‚Äî
>> > You are receiving this because you were assigned.
>> > Reply to this email directly, view it on GitHub
>> > <https://github.com/tesseract-ocr/tesseract/issues/657#issue
>> comment-273025064>,
>> > or mute the thread
>> > <https://github.com/notifications/unsubscribe-auth/
>> AL056Up0oVZPWQ2YcPpA-pm4Ju1d_k_lks5rTE-BgaJpZM4LiGKh>
>> > .
>> >
>>
>>
>>
>> --
>> Ray.
>>
>> ‚Äî
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/657#issuecomment-274591196>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AP6mLNQvLtkSc1Z9yzubMWNO6hM6YwX8ks5rVP9dgaJpZM4LiGKh>
>> .
>>
>
>
 @theraysmith 

Maybe ocropy's lines finding algorithm can help. AFAIK, it was designed to work well with Arabic. 
https://github.com/tmbdev/ocropy/blob/master/ocropus-gpageseg

See this remark:
https://github.com/tmbdev/ocropy/issues/46#issuecomment-112153537

It should be given a block with uniform size font. I would like to give these hints to the developers: 
In Arabic there are to kinds of diacritics
1- letter attached diacritics (dots like ÿ® ÿ™ ÿ¨ ÿ´ and ÿ£ ÿ¢ ÿ§) which stick to the letter and is mandatory
2. Vowel diacritics like ( Ÿí Ÿë Ÿé   Ÿã    Ÿê  Ÿç   ) used with letters any letter can be conjunct/combined with it and is optional. Kids learn it to read properly as it help get rid of ambiguity, because ÿπŸéŸÑŸÖ and ÿπŸêŸÑŸÖ are two different words but we use the context to distinguish when vowel diacritics are absent.

N.B. 
ŸÑŸéÿßŸí ÿ•ŸêŸÑŸéŸáŸé ÿ•ŸçŸÑÿß ÿßŸÑŸÑŸá note that this Ÿé   Ÿê  are different vowels has same shape exactly but used differently e.g. ÿ£Ÿé is pronounced a while Ÿêÿ£ pronounced e. one used above letter latter used below letter.


bottom line: vowel diacritics in Arabic should be recognized alone (e.g separate box) (but I am thinking how to distinguish between the above case if it is the same box!!!) because it can be on any letter and is limited ( Ÿë  Ÿé  Ÿã  Ÿè  Ÿå Ÿê   Ÿç   Ÿí  ) special case also this Ÿë  can be conjunct/combined with other vowel diacritics also   ŸëŸã    ŸëŸí  

it is limited as entity but can be heavily repeated on letter because every letter has the capability to combined with

hope this could help Tesseract developers  I'm having a problem with number 8, it is read as 3...
I'm usin PSM 6, language english and pattern A to Z, 0 to 9 and ":" to ";"
Result:
![image](https://cloud.githubusercontent.com/assets/1447491/21891559/67411cec-d8ba-11e6-8fdd-98fb73780d66.png)

I already change PSM, but no success.
Anyone can help?  In order to minimize the RTL/LTR effect, I created a training text file with arabic language text, one word per line. However the image generated by text2image has some pages with RTL text and some with LTR text i.e. aligned with right margin and left margin.

[ara.one-word-per-line.zip](https://github.com/tesseract-ocr/tesseract/files/701624/ara.one-word-per-line.zip)
 This behaviour is controlled by the pango library that text2image uses. It's also happening with gedit, which  also uses pango.  https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-271987456

>Indic may be troubled by the length of the compressed codes used.

@theraysmith Can you explain a little more about this? 

 Devanagari script has a large set of ligature forms forms for consonant conjuncts. These are combinations of Consonant + Viraama + Consonant (CVC) or CVCVC or even rarer CVCVCVC. 

Currently the generated unicharset uses the combination of the conjunct ligatures followed by vowel maatraas as well as vowel modifiers as a recognition unit, leading to unicharset of 5000+ lines.

You may want to consider recognizing the conjunct cluster as a unit and vowel maatras and vowel modifiers separately. A special case can be the i maatraa that comes before (to the left of)  the consonant for Devanagari.

For a listing of orthographic syllables by frequency for Sanskrit, please see 
http://www.sanskritweb.net/itrans/ortho2003.pdf

For a  list of ligature sets for Hindi, please see
http://tdil-dc.in/tdildcMain/articles/82170Devanagari%20Script%20Behaviour%20for%20Hindi%20%20ver%201.4.10.pdf Font Comparison Samples 

* http://sanskritlibrary.org/Sanskrit/pub/chars.pdf

* http://www.sanskritweb.net/itrans/itmanual2003.pdf Pages 43-75

Attested Hindi Ligatures

* http://www.sanskritweb.net/itrans/itmanual2003.pdf Pages 110-130 Ray,

Thank you for explaining regrading unicharset compression and your new
strategy for Indic graphemes.

Since the unicharset is being used as a filter, it will be important to
include the most common conjunct clusters in it, which may differ from
language to language.

Some more questions

Are the desired_characters and forbidden_characters used in the process of
creating the text corpus for different languages?

How many text lines are you using for training of Devanagari, e.g.
Sanskrit, Hindi, Marathi etc. Is it all/only from Wikipedia?



- excuse the brevity, sent from mobile

On 21-Jan-2017 3:34 AM, "theraysmith" <notifications@github.com> wrote:

> The LSTM recognizer is currently trained to recognize the sequence of
> *unicodes* for Indic languages. This reduces the size of the output
> softmax of the network from the 5000+ elements in the unicharset to ~140.
> (There is an analogous process for Chinese, Japanese, and Korean, that
> doesn't use the unicode encoding, but it is a similar idea, and the codes
> are strictly limited in length.)
> The unicharset is used as a *filter* in the beam search to allow only
> sensible grapheme/syllable combinations of unicodes, so it doesn't output
> complete garbage text.
>
> The consequence of this recoding is that it runs a lot faster, but it has
> to learn to output a long sequence for each grapheme/syllable.
> The recoding system that maps from unicharset elements to the sequence of
> unicodes currently only allows a maximum of 9 unicodes per
> grapheme/syllable, including any viramas.
>
> I'm running a new training experiment this weekend to try a new coding
> scheme, in which pairs are mapped to a single code, allowing a long CVCVCVC
> string to be encoded using just CCCC, cutting down from 7 codes to 4. This
> will probably increase the size of the output softmax to ~170, but reduce
> the length of the average code sequence by about 1/3, which might be easier
> for it to learn, without slowing it down much.
>
> It will take a couple of weeks to tell if it works, but if it does I will
> check in the code, and upload new traineddatas, and close this issue. If it
> doesn't work, I will have to think again...
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/654#issuecomment-274192153>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o-xusyCIFbh-wE4T4cp4mVb4oBWWks5rUS9vgaJpZM4LhbNY>
> .
>
 Ray,

Thank you for the info on corpus building.

I have added links for resources for bih and snd in the langdata repo just now. Please see

* https://github.com/tesseract-ocr/langdata/issues/39 (Bihari)

* https://github.com/tesseract-ocr/langdata/issues/42 (Sindhi in Arabic script)

I also added a link to this discussion at https://github.com/tesseract-ocr/tesseract/issues/622 for support regarding Khmer.

I will forward your post in the tesseract-ocr group for reach other community members too. >I recently stopped training chr, iku, khm, mya after discovering that I
have no rendered textlines that contain anything other than digits and
punctuation.

@theraysmith

I tried creating training data for khmer and was able to create box/tiff pairs with khmer text. It is possible that the fonts directory you used did not have khmer fonts or for some reason 'latin' fonts were used instead of khmer fonts. I will post the files separately under an issue in langdata.

I used --find_fonts function of text2image to find the fonts that covered 70‚ÑÖ of the khmer training text. 

It maybe useful in the training process to check the given font list for coverage and give an error or warning if it falls below a certain threshold, before going ahead with building the box tiff pairs.

edit: --oem 0 works with the khm.traineddata, --oem 1 recognizes it incorrectly. ```

text2image --find_fonts \
--fonts_dir /usr/share/fonts \
--text ./langdata/ara/ara.training_text \
--min_coverage .8  \
--outputbase ./langdata/ara/ara \
|& grep raw | sed -e 's/ :.*/" \\/g'  | sed -e 's/^/  "/' >./langdata/ara/fontslist.txt

```
Commands similar to above can be used for getting a fontlist that can be plugged into language-specific.sh to ensure that it calls fonts that are available on the system and have adequate coverage. Here is the output file from the above on my system.

```
  "Arial" \
  "Arial Bold" \
  "Courier New" \
  "Courier New Bold" \
  "DejaVu Sans" \
  "DejaVu Sans Bold" \
  "DejaVu Sans Mono" \
  "DejaVu Sans Mono Bold" \
  "FreeMono" \
  "FreeMono Bold" \
  "FreeSerif" \
  "FreeSerif Bold" \
  "Times New Roman," \
  "Times New Roman, Bold" \
```

 Ray: Regarding Myanamar, please see discussion on https://github.com/tesseract-ocr/langdata/issues/13

> We have 2 types of unicode font. Non standard unicode font and standard unicode font. When I check langdata files for Burmese, most words are incorrect. I guess you have generated mixed contents with non standard unicode contents and standard unicode contents. 

> https://my.wikipedia.org/
All contents on wikipedia are in standard unicode font.

http://crubadan.org/languages/my lists three primary sources for Myanmar/Burmese. One is the myanmar wikipedia, the other two are:

http://www.unicode.org/udhr/d/udhr_mya.html

http://www.jw.org/mya/

Also see: https://github.com/tesseract-ocr/langdata/issues/46

> Myanmar wordlists
https://github.com/kanaung/wordlists

> https://github.com/kanyawtech/myanmar-karen-word-lists/blob/master/burmese-word-list.txt?raw=true

> https://en.wiktionary.org/wiki/Appendix:Burmese_basic_vocabulary

You may also find the charts at http://www.virtualvinodh.com/wp/character-matrix/ useful for a comparison of various Indic scripts. please see rows for Burmese for Mynamar. Hey Ray,
Can you please explain the training process of tesseract-ocr with LSTM ?  Having an easily accessible unicharset will be useful for:

1. Checking whether to do fine-tune training or add a layer. e.g. if a required character is not in the unicharset within the lstm file then finetune does not work.

2. For viewing the wordlist/dictionary included in the dawg file in traineddata.

3. For replacing the wordlist/dictionary dawg-file in the traineddata.

4. For processing the user-words file. (Also see issue https://github.com/tesseract-ocr/tesseract/issues/403) https://github.com/tesseract-ocr/tesseract/commit/dc8745e6fd4c Some more changes are needed to fix this issue. >Is Wordstr format supported with the new commits?

It's not yet supported. This issue was solved by Ray.

@theraysmith or @zdenop, please close this issue.
  ![screenshot_2017-01-11-14-20-01](https://cloud.githubusercontent.com/assets/24853541/21851986/5328de5e-d809-11e6-90f4-f207dddfb829.png)
What it mean ?  running training process for Sanskrit - Devanagari script, throws up errors such as the following, when using --debug_interval -1

```
Iteration 5010: ALIGNED TRUTH : ‡§¶‡•ç‡§ß‡•ç‡§µ‡§æ ‡§≤‡•ç‡§ó‡•Å ‡§ú‡•ç<Undecodable><Undecodable><Undecodable> ‡§¶‡•ç‡§¶ ‡§∏‡•ç‡§§‡•Ç ‡§∏‡•ç‡§§‡•ç‡§∞‡•á ‡§¶‡•ç‡§Ø‡•ã ‡§∂‡§æ‡§É ‡§∏‡•ç‡§µ‡•á ‡§®‡•ç‡§π 

Iteration 5034: ALIGNED TRUTH : ‡§ñ‡§Ç ‡§ö‡§É ‡§¶‡•ç‡§ß‡•ã ‡§ô‡•ç‡§ó‡§æ ‡§≠‡•å ‡§®‡•ç‡§Ø‡§Ç ‡§®‡•ç‡§Ø‡•Å ‡§ú‡•ç<Undecodable><Undecodable> ‡§§‡•ç‡§ï‡•É ‡§µ‡§æ‡§Ç ‡§®‡§ø‡§É

Iteration 5068: ALIGNED TRUTH : ‡§µ‡•ç‡§Ø‡§É ‡§∂‡•ç‡§Æ‡§ø ‡§ï‡•ç‡§∑‡•ç‡§£ ‡§ñ‡§æ‡§É ‡§ü‡•Ä ‡§£‡§ø‡§Ç ‡§§‡•ç‡§∏‡•à ‡§®‡•ç‡§§‡§æ‡§Ç ‡§≤‡•ç‡§Æ ‡§∑‡•ç<Undecodable><Undecodable><Undecodable>
```

The relevant lines from training text are:

```
‡§¶‡•ç‡§ß‡•ç‡§µ‡§æ ‡§≤‡•ç‡§ó‡•Å ‡§ú‡•ç‡§û‡§æ‡§Ç ‡§¶‡•ç‡§¶ ‡§∏‡•ç‡§§‡•Ç ‡§∏‡•ç‡§§‡•ç‡§∞‡•á ‡§¶‡•ç‡§Ø‡•ã ‡§∂‡§æ‡§É ‡§∏‡•ç‡§µ‡•á ‡§®‡•ç‡§π ‡§®‡•Å‡§É

‡§ñ‡§Ç ‡§ö‡§É ‡§¶‡•ç‡§ß‡•ã ‡§ô‡•ç‡§ó‡§æ ‡§≠‡•å ‡§®‡•ç‡§Ø‡§Ç ‡§®‡•ç‡§Ø‡•Å ‡§ú‡•ç‡§û‡•á ‡§§‡•ç‡§ï‡•É ‡§µ‡§æ‡§Ç ‡§®‡§ø‡§É 

‡§µ‡•ç‡§Ø‡§É ‡§∂‡•ç‡§Æ‡§ø ‡§ï‡•ç‡§∑‡•ç‡§£ ‡§ñ‡§æ‡§É ‡§ü‡•Ä ‡§£‡§ø‡§Ç ‡§§‡•ç‡§∏‡•à ‡§®‡•ç‡§§‡§æ‡§Ç ‡§≤‡•ç‡§Æ ‡§∑‡•ç‡§ü‡§ø‡§Ç 
```

Specifically the syllables giving error in this sample are `‡§ú‡•ç‡§û‡§æ‡§Ç` `‡§ú‡•ç‡§û‡•á `‡§∑‡•ç‡§ü‡§ø‡§Ç`.

While first part of the conjunct is decoded, the later parts are not.


| Syllable | Devanagari characters | Unicode code points |
|---|---|---|
| ‡§ú‡•ç‡§û‡§æ‡§Ç | ‡§ú  ‡•ç  ‡§û  ‡§æ  ‡§Ç  | U+091C U+094D U+091E U+093E U+0902 |
| ‡§ú‡•ç‡§û‡•á | ‡§ú  ‡•ç  ‡§û  ‡•á | U+091C U+094D U+091E U+0947 |
| ‡§∑‡•ç‡§ü‡§ø‡§Ç | ‡§∑  ‡•ç  ‡§ü  ‡§ø  ‡§Ç | U+0937 U+094D U+091F U+093F U+0902 |
------------------------------------ These are there in san.unicharset being used by the training process.

```
‡§ú‡•ç‡§û‡§æ‡§Ç 1 3,76,61,242,294,446,0,0,294,446 Devanagari 27 0 27 ‡§ú‡•ç‡§û‡§æ‡§Ç	# ‡§ú‡•ç‡§û‡§æ‡§Ç [91c 94d 91e 93e 902 ]x

‡§ú‡•ç‡§û‡•á 1 3,76,61,255,251,423,0,0,251,423 Devanagari 27 0 27 ‡§ú‡•ç‡§û‡•á	# ‡§ú‡•ç‡§û‡•á [91c 94d 91e 947 ]x

‡§∑‡•ç‡§ü‡§ø‡§Ç 1 3,76,61,253,238,384,0,0,238,384 Devanagari 52 0 52 ‡§∑‡•ç‡§ü‡§ø‡§Ç	# ‡§∑‡•ç‡§ü‡§ø‡§Ç [937 94d 91f 93f 902 ]x
``` ```
Iteration 18247: ALIGNED TRUTH : ŸÖŸíŸáŸèÿπŸéÿ®ŸêÿßÿµŸéÿ£Ÿé ŸÜŸéŸàŸÑŸèÿπŸäŸé<Undecodable><Undecodable> ŸÇŸåÿ±ÿ®ŸéŸàŸé ÿØŸåÿπŸíÿ±ŸéŸàŸé ÿ™ŸåÿßŸÖŸéŸÑŸèÿ∏Ÿè
Iteration 18247: BEST OCR TEXT : ŸÖŸíŸáŸèÿπŸéÿ®ŸêÿßÿµŸéÿ£Ÿé ŸÜŸéŸàŸÑŸèÿπŸäŸé<Undecodable><Undecodable> ŸÇŸåÿ±Ÿíÿ®ŸéŸàŸé ÿØŸåÿπŸíÿ±ŸéŸàŸé ÿ™ŸåÿßŸÖŸéŸÑŸèÿ∏Ÿè
```  @theraysmith @amitdo @Shreeshrii 
- **Box file disorder**
The Arabic box file generate using Tesseract 4.x is in LTR ( Left to Right ) which is reversed, the Arabic language is from RTL ( Right to Left ). That means that **the first box should start from from the right side.**
( Have a look at the **wrong and disorder Tesseract 4.0x Arabic box file** )
[ara.Traditional_Arabic.exp0.zip](https://github.com/tesseract-ocr/tesseract/files/697557/ara.Traditional_Arabic.exp0.zip)


Tesseract 4.0 lstm puts the spaces between the words into boxes, as you know. 
Thus a problem arises caused by the **box file disorder** since the boxes are **mistakenly** set to be in LTR ( Left to Right ) for Arabic which is wrong, causing jumps from ( the end of the first line) to ( the end of the last letter of the line after it).
See the image attached 
![box disorder](https://cloud.githubusercontent.com/assets/16248376/21826462/9df37064-d798-11e6-8987-f51195ab66e0.jpg)


( Now have a look at the attached correct order of Arabic example tif/box of version Tesseract 3.05).
[Arabic example 1.zip](https://github.com/tesseract-ocr/tesseract/files/697435/Arabic.example.1.zip)
Example 1, correct box order:
![right order](https://cloud.githubusercontent.com/assets/16248376/21826948/989c02fa-d79a-11e6-9790-6d27c9404373.jpg)

 While tesstrain.sh takes into account RTL languages while creating the DAWG files, text2image process does not seem to have specific RTL processing. will there be modifications for text2image ? What you show here is 'by design'. This should not cause any problem in training process and characters recognition for RTL languages. Ray,
There seems to be a bug. I have tried training a couple of times to 2-3% char error rate. But the OCRed text seems to be way off. During training, it seems that the diacritics are being recognized well., eg.
```
Iteration 1702: ALIGNED TRUTH : ÿßŸÜŸéÿØÿ®ŸíÿπŸé ŸâŸÑŸéÿπŸé ÿßŸÜŸéŸÑŸíŸÜŸé ÿßŸÖŸëŸéŸÖŸê ÿ®ŸçŸäŸíÿ±Ÿé ŸäŸÅŸê ŸÖŸíÿ™ŸèŸÜŸíŸÉŸè ŸÜŸíÿ•ŸêŸàŸé ŸÜŸéŸàŸÖŸèŸÑŸéÿπŸíÿ™Ÿé ŸÖŸíÿ™ŸèŸÜŸíÿ£ŸàŸé ÿßÿØŸãÿßÿØŸéŸÜŸíÿ£ ŸáŸêŸÑŸÑŸê ÿßŸàŸÑŸèÿπŸéÿ¨Ÿíÿ™Ÿé ÿßŸÑŸéŸÅŸé ŸÖŸíŸÉŸèŸÑ
Iteration 1702: BEST OCR TEXT : ÿßŸÜŸéŸäÿ®ŸíÿπŸé ŸâŸÑŸéÿπŸé ÿßŸÜŸéŸÑŸíŸÜŸé ÿßŸáŸéŸÖŸê ÿ®ŸêŸäŸíÿ±Ÿé ŸäŸÅŸê ŸÖŸíÿ™ŸèŸÜŸé ŸÜŸíÿ•ŸàŸé ŸÜŸéŸàŸáŸèŸÑŸéŸÖŸíÿ™Ÿé ŸÖŸíÿ™Ÿèÿ£ŸàŸé ÿßÿ∞ŸéÿßÿØŸéŸÜÿ£ ŸáŸêŸÑŸéŸÑŸê ÿßŸàŸÑŸèÿπŸéÿ¨Ÿíÿ™Ÿé ÿßŸÑŸéŸÅŸé ŸÖŸíŸÉŸèŸÑŸé
```

But the OCRed text does not seem to include any.

[ara.Arial_Unicode_MS.exp0.txt](https://github.com/tesseract-ocr/tesseract/files/699108/ara.Arial_Unicode_MS.exp0.txt)
[ara.Calibri.exp0.txt](https://github.com/tesseract-ocr/tesseract/files/699109/ara.Calibri.exp0.txt)
[ara.Arial.exp0.txt](https://github.com/tesseract-ocr/tesseract/files/699110/ara.Arial.exp0.txt)

@christophered  and @bmwmy can provide Arabic specific details. https://github.com/tesseract-ocr/tesseract/files/696122/ara.TRAINING.zip has the box tif pairs for the above training.

https://github.com/tesseract-ocr/tesseract/files/696184/traininglog-mid.txt shows the debug messages from during training. >I wonder if the bidi integration is working correctly for LSTM, as the accuracy with Arabic is unsatisfactory.

Ray,

According to your tests, how does Hebrew (another RTL language) perform?

Do you have accuracy report for various languages that you can share with us, other than the one in the DAS2016 slides? @theraysmith Hope you have seen comments by Chris on the other thread also - https://github.com/tesseract-ocr/tesseract/issues/642

> i was merging the letter extender with the Arabic letter into one single box, and putting that Arabic letters as the character of the box, basically, i was trying to train the engine to recognize that Arabic letter in it's multiple positions, as you know the Arabic letters have multiple forms based which is based on it's position in the word ( beginning, middle, ending, isolated )
Example:
( ŸÉŸÄ ) is not ( ŸÉ + ŸÄ ) in the box file, it should be ( ŸÉ )
also ( ŸÄŸÉŸÄ ) or ( ŸÄŸÉ ) they are a single character ( ŸÉ ) in different positions, this is important in the box file.

> Which also means that ( ŸÉŸéŸÄ ) is not ( ŸÉ + ŸÄŸé ), it is ( ŸÉŸé )
 @theraysmith 

>    - The diacritics are currently excluded from the unicharset, probably
   because they are only rarely used, but need to be included. There may not
   be enough text with them included in the text corpora.

Ray,
Please see https://github.com/tesseract-ocr/tesseract/issues/552 and https://github.com/tesseract-ocr/langdata/issues/35

Arabic Diacritics are included in the Arabic.unicharset. 

@bmwmy had offered to provide additional training text with diacritics - see https://github.com/tesseract-ocr/tesseract/issues/552#issuecomment-269961851

I was able to get the diacritics recognized during training by adding the following line to ara.config, however for some fonts it seems to be treating diacritics as a separate line. Do not know whether it is related to x-height for fonts. 
```
#Diacritics
textord_min_linesize 2.5
```
Related question, for lstm training, I am using
```
--noextract_font_properties
```

while creating the box tiff pairs and lstmf files since @amitdo mentioned that font_properties are not needed for LSTM training, please confirm. Please also see https://github.com/tesseract-ocr/tesseract/issues/318#issuecomment-218381668 and other comments regarding unicharset. 

Are the glyph metrics updated based on the fonts used for training? 
Are glyph metrics used for LSTM training? 

Answer:

**No. Most of the unicharset fields are irrelevant to LSTM training and recognition.
_The mirror and normalized string fields ARE important though.**_ I examined @Shreeshrii  training set and I appreciate his effort, but seems the text in generated tiffs image files are very small than it should be. It is hard to read even for humans. The vowel diacritics looks like noise also some letter glyphs as ( ŸÅŸÄ /  ŸÄŸÖŸÄ ). I suggest using 16-22pt font. 
Also this:
Iteration 1702: ALIGNED TRUTH : ÿßŸÜŸéÿØÿ®ŸíÿπŸé ŸâŸÑŸéÿπŸé ÿßŸÜŸéŸÑŸíŸÜŸé ÿßŸÖŸëŸéŸÖŸê ÿ®ŸçŸäŸíÿ±Ÿé ŸäŸÅŸê ŸÖŸíÿ™ŸèŸÜŸíŸÉŸè ŸÜŸíÿ•ŸêŸàŸé ŸÜŸéŸàŸÖŸèŸÑŸéÿπŸíÿ™Ÿé ŸÖŸíÿ™ŸèŸÜŸíÿ£ŸàŸé ÿßÿØŸãÿßÿØŸéŸÜŸíÿ£ ŸáŸêŸÑŸÑŸê ÿßŸàŸÑŸèÿπŸéÿ¨Ÿíÿ™Ÿé ÿßŸÑŸéŸÅŸé ŸÖŸíŸÉŸèŸÑ
Iteration 1702: BEST OCR TEXT : ÿßŸÜŸéŸäÿ®ŸíÿπŸé ŸâŸÑŸéÿπŸé ÿßŸÜŸéŸÑŸíŸÜŸé ÿßŸáŸéŸÖŸê ÿ®ŸêŸäŸíÿ±Ÿé ŸäŸÅŸê ŸÖŸíÿ™ŸèŸÜŸé ŸÜŸíÿ•ŸàŸé ŸÜŸéŸàŸáŸèŸÑŸéŸÖŸíÿ™Ÿé ŸÖŸíÿ™Ÿèÿ£ŸàŸé ÿßÿ∞ŸéÿßÿØŸéŸÜÿ£ ŸáŸêŸÑŸéŸÑŸê ÿßŸàŸÑŸèÿπŸéÿ¨Ÿíÿ™Ÿé ÿßŸÑŸéŸÅŸé ŸÖŸíŸÉŸèŸÑŸé
are reversed order (RTL issue)

comparison between noisy text example which was used in training and good one:
![testdia](https://cloud.githubusercontent.com/assets/24265205/21882655/8d157326-d8bc-11e6-8a6a-7e6e6d49120e.png)

I think using bigger text image input will result in very high improvement. I am satisfied with this result taking in consideration this noisy input but (RTL issue) should be solved.

@christophered  ara.Traditional_Arabic.exp0.zip was good input image file
but @Shreeshrii  https://github.com/tesseract-ocr/tesseract/files/696122/ara.TRAINING.zip  is noisy input image. About `--noextract_font_properties` . Ray confirmed it here:
https://github.com/tesseract-ocr/tesseract/issues/634#issuecomment-272027231
 >Are glyph metrics used for LSTM training?

I believe the answer is 'No'.

@theraysmith, can you confirm that? @amitdo I have been training using `--noextract_font_properties` since you brought it to my notice.

However, I am wondering whether some type of fontinfo / xheights is still required for LSTM training.

eg. in order to avoid the diacritics being discarded as noise, I had to add `textord_min_linesize 2.6` in ara.config. But different fonts have different sizes, even at same point size. I had to play with different values, but couldn't figure out a value that would work with multiple fonts.

So, I am trying the training again with only one font, Traditional Arabic font at 32 point, as suggested by @bmwmy.

Ray might have a different solution - will wait till the changes in wiki for training are updated.

  `textord_min_linesize` is a hint for the layout analysis step in Tesseract.

If the layout analysis step does not 'cut' the lines properly, the next step - the lines' text recognition, will suffer. [Tesseract release notes July 11 2015 - V3.04.00](https://github.com/tesseract-ocr/tesseract/wiki/ReleaseNotes#tesseract-release-notes-july-11-2015---v30400)

>Major change to improve layout analysis for heavily diacritic languages: Thai, Vietnamese, Kannada, Telugu etc.

From DAS2016 slide 5 - 'Page Layout Analysis':
>Tesseract's existing text-line finding is also weak wrt diacritics,
especially for Arabic and Thai. > There is Bidi processing inside the post-recognition processing of
Tesseract that reprocesses/re-orders the text for output, so it appears in
the correct order.

>>Iteration 1702: ALIGNED TRUTH : ÿßŸÜŸéÿØÿ®ŸíÿπŸé ŸâŸÑŸéÿπŸé ÿßŸÜŸéŸÑŸíŸÜŸé ÿßŸÖŸëŸéŸÖŸê ÿ®ŸçŸäŸíÿ±Ÿé ŸäŸÅŸê ŸÖŸíÿ™ŸèŸÜŸíŸÉŸè ŸÜŸíÿ•ŸêŸàŸé ŸÜŸéŸàŸÖŸèŸÑŸéÿπŸíÿ™Ÿé ŸÖŸíÿ™ŸèŸÜŸíÿ£ŸàŸé ÿßÿØŸãÿßÿØŸéŸÜŸíÿ£ ŸáŸêŸÑŸÑŸê ÿßŸàŸÑŸèÿπŸéÿ¨Ÿíÿ™Ÿé ÿßŸÑŸéŸÅŸé ŸÖŸíŸÉŸèŸÑ
Iteration 1702: BEST OCR TEXT : ÿßŸÜŸéŸäÿ®ŸíÿπŸé ŸâŸÑŸéÿπŸé ÿßŸÜŸéŸÑŸíŸÜŸé ÿßŸáŸéŸÖŸê ÿ®ŸêŸäŸíÿ±Ÿé ŸäŸÅŸê ŸÖŸíÿ™ŸèŸÜŸé ŸÜŸíÿ•ŸàŸé ŸÜŸéŸàŸáŸèŸÑŸéŸÖŸíÿ™Ÿé ŸÖŸíÿ™Ÿèÿ£ŸàŸé ÿßÿ∞ŸéÿßÿØŸéŸÜÿ£ ŸáŸêŸÑŸéŸÑŸê ÿßŸàŸÑŸèÿπŸéÿ¨Ÿíÿ™Ÿé ÿßŸÑŸéŸÅŸé ŸÖŸíŸÉŸèŸÑŸé
are reversed order (RTL issue)

@theraysmith 

Ray, Can the bidi post-processing be applied as an experiment to these debug messages? Then we can very easily see whether it is working.
>Answer: No. That would be very difficult. They are intended to be displayed completely without any RTL smarts. Shree, you might want to use this text2image option with Arabic:  
`--leading  Inter-line space (in pixels)  (type:int default:12)`

As a minimum it should equal to ptsize. For Arabic, you can try to increase it (20-50 percent bigger than ptsize)  IMO, 32 ptsize is too big. Try 14/16. Arabic also has presentation forms i.e. spacing forms of Arabic diacritics, and contextual letter forms.

Please  see 
http://www.alanwood.net/unicode/arabic_presentation_forms_a.html
http://www.alanwood.net/unicode/arabic_presentation_forms_b.html
and
https://github.com/w3c/alreq/wiki/Should-I-use-the-Arabic-Presentation-Forms-provided-in-Unicode%3F

Though, it is not recommended to use these for content under newer versions of unicode, I am wondering whether it will make OCR easier if these were used...

There can be a post-processing step to convert them to regular unicode points later.
 >Are glyph metrics used for LSTM training?

No. Confirmed by Ray here: https://github.com/tesseract-ocr/langdata/issues/31#issuecomment-272261739
>... the glyph metrics aren't used. >Shree, you might want to use this text2image option with Arabic:
--leading Inter-line space (in pixels) (type:int default:12)

> As a minimum it should equal to ptsize. For Arabic, you can try to increase it (20-50 percent bigger than ptsize)

tesstrain.sh process uses default --ptsize which is 12. 

language_specific.sh sets --leading to 32 by default and to 48 for Thai fonts.


 @Shreeshrii here is a sample text for you, please test and post the findings
[Arabic sample variation.zip](https://github.com/tesseract-ocr/tesseract/files/736942/Arabic.sample.variation.zip)

@theraysmith Most if not all languages related to Arabic (example: Farsi, Urdu, etc..) use such diacritics.
The Arabic diacritics are **often** but not always used in the Arabic text, sometimes in all the text, and sometimes at one letter in each word, but believe me the diacritics are frequently used.
Have a look at [The Quran](http://quran.ksu.edu.sa/tafseer/tafheem/sura1-aya1.html#tafheem)
 @Shreeshrii your sample of box/tif that you provided had an some errors that I've notice:
1) The U+640 (tatweel) issue
example: ÿ®Ÿêÿ≥ŸÖŸê
wrong: ÿ® ŸÄŸê ÿ≥ ŸÄŸê ŸÖ
correct: ÿ® ÿ≥ ŸÖ   only 3 letters ÿ®ÿ≥ŸÖ
@theraysmith got it right, Tesseract should have the capability to generate it in .tif, but not consider it as a single character in the .box file, the correct thing would be that the box of U+640 (tatweel) be combined with the box of another letter, while setting the box as the character of a single letter, never even mentioning  U+640 (tatweel) in the .box file , ever.
 U+640 (tatweel) is a special case, people dont usually use it while writing text, so dont use it, or merge the boxes and remove it.

2) As @bmwmy mentioned earlier, in your .tif the charachters of the text are seperated, thats wrong. 
wrong: ÿ®ŸÄ ŸÄÿ≥ŸÄ ŸÄŸÖ
correct: ÿ®ÿ≥ŸÖ

I tracked the problem, and the cause was the txt that you were using, it contained the 1st U+640 (tatweel) mistake that I mentioned earlier The box tiff pairs are as generated by text2image program.

Any changes to that will have to be done by Ray.

I will test with the files you have provided.

- excuse the brevity, sent from mobile

On 28-Jan-2017 9:30 PM, "chris" <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/Shreeshrii> your sample of box/tif that
> you provided had an some errors that I've notice:
>
>    1.
>
>    The U+640 (tatweel) issue
>    example: ÿ®Ÿêÿ≥ŸÖŸê
>    wrong: ÿ® ŸÄŸê ÿ≥ ŸÄŸê ŸÖ
>    correct: ÿ® ÿ≥ ŸÖ only 3 letters ÿ®ÿ≥ŸÖ
>    @theraysmith <https://github.com/theraysmith> got it right, Tesseract
>    should have the capability to generate it in .tif, but not consider it as a
>    single character in the .box file, the correct thing would be that the box
>    of U+640 (tatweel) be combined with the box of another letter, while
>    setting the box as the character of a single letter, never even mentioning
>    U+640 (tatweel) in the .box file , ever.
>    U+640 (tatweel) is a special case, people dont usually use it while
>    writing text, so dont use it, or merge the boxes and remove it.
>    2.
>
>    As @bmwmy <https://github.com/bmwmy> mentioned earlier, in your .tif
>    the charachters of the text are seperated, thats wrong.
>    wrong: ÿ®ŸÄ ŸÄÿ≥ŸÄ ŸÄŸÖ
>    correct: ÿ®ÿ≥ŸÖ
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-275856218>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o1m8lCpawdFVw2ywk8nxQgwrn-zKks5rW2YIgaJpZM4Lf-kT>
> .
>
 @theraysmith i suggest that you give capability to convert tesseract 3.0x box files to tesseract 4.0x since many of us have tif/box files based on the older version 3.0x

@theraysmith Also, Ubuntu have released the Snaps project, giving the ability to distribute a software as a universal Linux package. Would it be possible to release a Snappy version on Tesseract 4.0x, this would save us alot of time and effort by skipping the building process and it's issues.
https://www.ubuntu.com/desktop/snappy
http://snapcraft.io/ >There is Bidi processing inside the post-recognition processing of
Tesseract that reprocesses/re-orders the text for output, so it appears in
the correct order.
I wonder if the bidi integration is working correctly for LSTM, as the
accuracy with Arabic is unsatisfactory.

@theraysmith Have you had a chance to look at this? @christophered 

>@Shreeshrii here is a sample text for you, please test and post the findings
Arabic sample variation.zip

Please send me your box file corresponding to the above text. I will add tab characters for new line to test, rather than use text2image generated box files. https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/EOwF1GnOcS0/My_SUf1vEQAJ

> tesseract4 reads ÿßŸÑÿ£ as ÿßÿ£ŸÑ which is pretty close, because we need to switch the position of the last 2 letters to have ÿß ŸÑ ÿ£, this happens with similar word forms too like ŸÑÿß reads as ÿßŸÑ and should be ŸÑ ÿß, and i wish to correct it. I can't believe my eyes. Ray commented in the users forum.

Shree, you are a magician!

:laughing: :rofl: :laughing:  Here is Ray's response:

>Thanks for spotting this!
I understand why it makes this error, but it will take some thought to fix it properly!
It is using a sort by x-position to re-order the boxes for RTL language training, but that doesn't work in the case of heavily kerned characters like ŸÑ in your example.
It needs to simply reverse the RTL characters, but has to avoid messing up the order of the common script, which is why I was using a sort to begin with.
https://github.com/tesseract-ocr/tesseract/blob/master/training/boxchar.cpp#L202
 Here are some libraries that implement the Unicode Bidi algorithm.

https://github.com/behdad/pybyedie
Copyright (C) 2013  Google
License: MIT
Written in: Python

https://github.com/servo/unicode-bidi
By Mozilla
License: Apache 2.0 / MIT
Written in: Rust

https://github.com/behdad/fribidi
License: LGPL 2.1
Written in: C

https://github.com/MeirKriheli/python-bidi
License: LGPL 3.0
Written in: Python
 @theraysmith meanwhile can you give Tesseract 4.x the ability to Train single words each with a single Box.
This feature that I'am suggesting will give the ability to provide Semi-Automatic transcription capabilities. Please help to add space after text in Punjabi(Panjabi or Gurmukhi) sentance.  @theraysmith the recognition rate of the Arabic model is impressive, you really made a big recognition leap from 3.x to 4, Have you managed to solve issue #758 relating to ŸÑÿß is wrongly flipped as ÿßŸÑ
![untitled44](https://user-images.githubusercontent.com/16248376/26998676-0e1dbf62-4d90-11e7-8843-57bf3726286f.png)


 @Shreeshrii @amitdo @theraysmith 
I have read [a research that conclude by developing a recurrent neural network
that predicts diacritics in non-diacritized texts for Arabic](http://www.aclweb.org/anthology/D15-1274), how is that possible?
Does that mean if I train an Arabic Model with text that have Arabic diacritic, then use this model to recognize an image with Arabic text that dont have diacritic, the ocr txt result will have diacritics?
is that true? @theraysmith have you solved the problem of ŸÑÿß ? it really effects the error rate
  @theraysmith The main problem is caused by the reorder and normalize function in Tesseract.
Kraken have managed to fix many of the RTL langues bugs, along with using python-bidi, kraken reorder and normalize the writings, including alphabets and even diacritics.
Have a look at: http://kraken.re/ketos.html
https://github.com/mittagessen/kraken

Example, Arabic RTL:
![000021](https://user-images.githubusercontent.com/16248376/28440171-d5e05612-6dad-11e7-9315-d498cd7f1d34.png)

After using Kraken:
# ÿßŸÖŸà ŸÖŸáÿ≥ŸÅŸÜŸîÿß ÿßŸÑŸïÿß ŸÜŸàÿπÿØÿÆŸä ÿßŸÖŸà ÿßŸàŸÜŸÖŸìÿß ŸÜŸäÿ∞ŸÑÿßŸà ŸáŸÑŸÑÿß ŸÜŸàÿπÿØÿßÿÆŸä
Kraken reorder and normalize the text so it could be trained in Left To Right, the reordering can:
- Reverse the text and the marks are moved to the next letter to the right
- Or just reverse the text while maintaining the structure of the marks.

Example, the word ÿ£ŸÜŸÅÿ≥ŸáŸÖ it can be converted to:
- ŸÖŸáÿ≥ŸÅŸÜŸîÿß 
- ŸÖŸáÿ≥ŸÅŸÜÿ£

Have a look at the NFD and NFC options

Ray, I hope that you could replicate Kraken's solution, once Tesseract solves this problem, Arabic and Hebrew would be able to achieve the golden recognition rates.
 @theraysmith

Dear Mr.Smith,

I am so grateful for answering my questions.

It came to my mind, maybe it is the problem. I thought, it is not a bad
idea to share it with you.

I think the problem of ŸÑÿß happens because of this:

for example if we have this:

ÿßŸÑÿß ÿßŸÜŸÅÿ≥ŸáŸÖ

Tesseract first reorder it this way:


8

7

6

5

4

3

2

1

ÿß

ŸÑÿß

ÿß

ŸÜ

ŸÅ

ÿ≥

Ÿá

ŸÖ


Then it substitutes ŸÑÿß with two separate characters ŸÑ ÿß. So , the sequence
of characters becomes like this:


9

8

7

6

5

4

3

2

1

ÿß

ÿß

ŸÑ

ÿß

ŸÜ

ŸÅ

ÿ≥

Ÿá

ŸÖ


After doing OCR, it reorders the characters to show them in the correct
order. So it becomes:


9

8

7

6

5

4

3

2

1

ŸÖ

Ÿá

ÿ≥

ŸÅ

ŸÜ

ÿß

ŸÑ

ÿß

ÿß


So, the problem happened.


About the he dropped last space on each line of RTL text output, I have not
faced this problem.


I am really looking forward for the new traineddata I do appreciate your
kind help.

On Fri, Jul 21, 2017 at 7:44 AM, Shreeshrii <notifications@github.com>
wrote:

> @theraysmith <https://github.com/theraysmith>
>
> the dropped last space on each line of RTL text output, (is there an issue
> for that, or am I the only one that noticed?),
>
> I think it is related to issue #1015
> <https://github.com/tesseract-ocr/tesseract/issues/1015>
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-316890698>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAVnhv01Xw6nKogWP_uU8BAPGJYRzks5sQBengaJpZM4Lf-kT>
> .
>
 @theraysmith have a look at some reordering script as an example code,[ reorder.py:](https://gist.github.com/mittagessen/1cefa68d2903b1cd0758574aaa1dd9df)
```
#! /usr/bin/env python

import sys
import glob

from bidi.algorithm import get_display

for f in glob.glob(sys.argv[1] + '/*.txt'):
    with open(f, 'rb') as fp:
        with open(f + '.re', 'wb') as fo:
            fo.write(get_display(fp.read().decode('utf-8')).encode('utf-8')) @hanikh please modify your reply horizontally, you are making the topic hard to go through :sunglasses:  @christophered  
it was this way:
Tesseract first reorder it this way:
8      7      6      5      4      3      2       1
ŸÖ       Ÿá       ÿ≥      ŸÅ     ŸÜ      ÿß      ŸÑÿß        ÿß
Then it substitutes ŸÑÿß with two separate characters ŸÑ ÿß. So , the sequence
of characters becomes like this:
9       8      7      6      5      4      3      2       1
ŸÖ       Ÿá       ÿ≥      ŸÅ     ŸÜ      ÿß      ŸÑ          ÿß       ÿß
After doing OCR, it reorders the characters to show them in the correct
order. So it becomes:
9       8      7      6      5      4      3      2       1
ÿß        ÿß       ŸÑ       ÿß      ŸÜ       ŸÅ     ÿ≥    Ÿá         ŸÖ

So, the problem happened. @theraysmith  that could be a solution ( well not sure ) https://en.wikipedia.org/wiki/Arabic_script_in_Unicode#Contextual_forms
these contextual forms are standard any form other than these can be considered as combination and thus inverted in the output Ray, I intend to open a new issue about Hebrew soon. For Hebrew, see https://github.com/tesseract-ocr/langdata/issues/82 @theraysmith Sorry for taking so long to reply back, I was training lstm models and conducting tests for days to have insight and solution on the matter of Arabic and diacritics.

**Intro:**
What is the Arabic diacritics issue: it's when the ocr engine recognition rate is reduced when introducing a foreign element/mark to the text, in this case diacritics; meaning if the text has few diacritics can the ocr engine recognize the text and achieve decent rates?

**Reply to Ray:**
- Note that you are fully correct in regards to `Tatweel`.
- Note that you are mostly correct in regards to the Arabic diacritical marks, they are mostly optional, but for some conditions are necessary, mostly the `Maddah` & the `Tanwin`.
Nevertheless, nowadays Arabic diacritics are moderately used.
Example of some situations that it is necessary to use marks:
![wer](https://user-images.githubusercontent.com/16248376/28754294-5ae417a0-754b-11e7-82f0-87d22103ed54.png)


**Results of my tests related to diacritics:**
- Training a model with Arabic text, without diacritics
 `100% Recognition rate` on the training data.
`+90% Recognition rate` on scanned documents without diacritics.
Note that it cant recognize words with diacritics.
**Verdict: Suitable for real-life situations, but recognition rate can be further improved.**

- Training a model with Arabic text, the rendered images contains moderate diacritics but the transcription/groundtruth is without diacritics.
 `100% Recognition rate` on the training data.
Note that it cant recognize words without diacritics well.
**Verdict: Fail, not suitable for real-life situations.**

- Training a model with Arabic text, with text containing a mixture of both: lines with few diacritics and lines without diacritics .
`+95% Recognition rate` on the training data.
`+90% Recognition rate` on other images.
Can handle both images with/without diacritics.
**Verdict: Best of All tests, most stable and consistent, the model can recognize text with and without diacritics, has minor mistakes here and there that can be easily corrected via Microsoft Word, suitable for real-life situations.**

**Conclusion:**
The diacritics issue with regards to the Arabic language  can be solved by creating a model with a combination/mixture of both: lines with & without diacritics.
Example, include in your training non-diacritized lines:
![000008](https://user-images.githubusercontent.com/16248376/28755946-039a6152-756e-11e7-86e1-8df15f3f34fd.png)
Also include diacritized lines:
![015401](https://user-images.githubusercontent.com/16248376/28755958-46e6b9c4-756e-11e7-9f00-b5196fbb4223.png)

Certainly, the non-diacritized training data should be more than the diacritized, say +80% non-diacritized.
Thus the model will be able to recognize normal text, and also will know how to handle the few foreign elements if introduced.
 
This problem can be solved by wisely introducing few variations and mixture of data, thus the trained model will be more complex. Therefore, for now, there is no need to modify anything except the training data.

As for Hebrew @amitdo is conductor at https://github.com/tesseract-ocr/langdata/issues/82
 Question
@theraysmith I understand that for training, Tesseract 4.x reorders the Arabic text to tesseracts's reading order, meaning it converts RTL to LTR & then normalizes it.
For normalization, which form does it uses, NFD or NFC?
Example:
![000000](https://user-images.githubusercontent.com/16248376/28756220-cca7bcb2-7572-11e7-937f-80b9ca2c4540.png)
GDT: ÿ¢ŸÖŸÜÿß ÿ®ÿßŸÑŸÑŸá ÿ•ŸÜ ÿ¥ÿ¶ÿ™ŸÖ ÿßŸÑÿ¢ÿÆÿ±ÿ© ŸáŸÖ ÿ®ŸÖÿ§ŸÖŸÜŸäŸÜ Ÿäÿß ÿ£ŸäŸáÿß
NFD: ÿßŸáŸäŸîÿß ÿßŸä ŸÜŸäŸÜŸÖŸîŸàŸÖÿ® ŸÖŸá ÿ©ÿ±ÿÆŸìÿßŸÑÿß ŸÖÿ™ŸîŸäÿ¥ ŸÜŸïÿß ŸáŸÑŸÑÿßÿ® ÿßŸÜŸÖŸìÿß
NFC: ÿßŸáŸäÿ£ ÿßŸä ŸÜŸäŸÜŸÖÿ§ŸÖÿ® ŸÖŸá ÿ©ÿ±ÿÆÿ¢ŸÑÿß ŸÖÿ™ÿ¶ÿ¥ ŸÜÿ• ŸáŸÑŸÑÿßÿ® ÿßŸÜŸÖÿ¢

The difference between NFD vs NFC, is that after the text is is reordered to LTR for training, NFD pushes the marks/diacritics to the right-side, while in NFC the marks/diacritics remain on the characters itself. text2image should have an option to randomly add tatweel every n lines.

https://en.wikipedia.org/wiki/Kashida

>Kashida is generally only used in one word per line and applied to one letter per word. 

>Furthermore, kashida is recommended only between certain combinations of letters (typically those which cannot form a ligature).
 @amitdo No, No.......! That is very bad
Tatweel reduces the recognition rate, and makes the model unstable and confused `theoretically speaking`
Ray stated earlier that he have fixed the tatweel problem, he even gave the option to render it if you want to,  but it will be removed as a singular sole character from the training data.
I think he solved this issue by Merging the tatweel Box with the earlier glyph box, and removing the tatweel as a character, the final remainder is 1 box with the earlier glyph. >For normalization, which form does it uses, NFD or NFC?

It seems it uses NF**K**C. Hi @christophered, I don't think you understood my meaning.

I Re-read what Ray said in this issue.

>it needs to be preserved in the training text, so it gets rendered

>I understand that tatweel is a rendering artifact, that should be rendered for training, but not occur in the output text (or in the language model).

>The tatweel and ligature problem are fixed and will be corrected in the new traineddatas coming soon

So it seems he already implemented (but didn't push yet) what I just now suggested.


 text2image is the program that **renders** images from ground truth.

>text2image should have an option to randomly add tatweel every n lines.

'add' here means 'render'.


 the new version of traineddata has been uploaded a lot of time ago.

On Sat, Sep 9, 2017 at 10:07 AM, Shreeshrii <notifications@github.com>
wrote:

> @theraysmith <https://github.com/theraysmith>
>
> Thanks for these updates.
>
> Does the complete fix for RTL languages also require new traineddata
> created with these fixes?
>
> Will you be uploading a new version of traineddata?
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-328256183>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAfGrAIkJiFceO2zo3iNI77Q7sz9Dks5sgiQGgaJpZM4Lf-kT>
> .
>
  I found the a desired character file in source training data. So I guessed that in language.traineddata there is information of desired character. How can I add my unique character like ‚Üë‚Üì into trained language?  See comment from Ray at 
https://github.com/tesseract-ocr/tesseract/issues/542#issuecomment-265569774

> it doesn't run the eval from the trainer.
It doesn't harm the tutorial, but will be required before people start serious training.
 with --eval_listfiles , always coredump. üò≠

lstmtraining: ../ccutil/genericvector.h:696: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
 No, I did not see that assertion up to now. How can it be reproduced? The non-debug build continues, but uses a bad index internally, so the results are invalid.

Replace `assert` (which is only used in debug builds) by `ASSERT_HOST` in `ccutil/genericvector.h`, then the non-debug build should show an error, too.

Can you get a stack trace for the assertion? @Shreeshrii, please open a new issue about that regression. @Shreeshrii, I am sorry, but somehow my last comment got lost. So once again:

The assertions are caused by an index of 0 used for an empty vector. Since commit 907de5995f698e2a01da25fa09f8cadaf31a095f the constructor of GenericVector no longer allocates memory for an empty vector. `tesseract::LSTMTrainer::ReadTrainingDump` tries to read 0 bytes. Issue #561 is identical. Here is a patch which fixes the assertion / core dump:

    diff --git a/lstm/lstmtrainer.cpp b/lstm/lstmtrainer.cpp
    index 03619969..e6d8e4a3 100644
    --- a/lstm/lstmtrainer.cpp
    +++ b/lstm/lstmtrainer.cpp
    @@ -918,6 +918,7 @@ bool LSTMTrainer::SaveTrainingDump(SerializeAmount serialize_amount,
     // Reads previously saved trainer from memory.
     bool LSTMTrainer::ReadTrainingDump(const GenericVector<char>& data,
                                        LSTMTrainer* trainer) {
    +  if (data.size() == 0) return false;
       return trainer->ReadSizedTrainingDump(&data[0], data.size());
     }

I don't know whether returning `true` would be better. I tried to analyze the problem ("why is there a data size 0?") and noticed that the behavior of the program is totally erratic when I run it in a debugger. There are several threads involved, and depending on my breakpoints the problem with the data size occurs or not. That looks like a synchronization issue, and so I decided to use Valgrind. The result is horrible:

    ==2035== ERROR SUMMARY: 44846954 errors from 905 contexts (suppressed: 0 from 0)

Here is one example (total log file is about 28000 lines):

    ==2035== Conditional jump or move depends on uninitialised value(s)
    ==2035==    at 0x1497ED: ComputeBlackWhite (networkio.cpp:140)
    ==2035==    by 0x1497ED: tesseract::NetworkIO::FromPixes(tesseract::StaticShape const&, std::vector<Pix const*, std::allocator<Pix const*> > const&, tesseract::TRand*) (network
    io.cpp:190)
    ==2035==    by 0x1498FF: tesseract::NetworkIO::FromPix(tesseract::StaticShape const&, Pix const*, tesseract::TRand*) (networkio.cpp:164)
    ==2035==    by 0x1BBB41: tesseract::Input::PreparePixInput(tesseract::StaticShape const&, Pix const*, tesseract::TRand*, tesseract::NetworkIO*) (input.cpp:149)
    ==2035==    by 0x1C9842: tesseract::LSTMRecognizer::RecognizeLine(tesseract::ImageData const&, bool, bool, bool, float, float*, tesseract::NetworkIO*, tesseract::NetworkIO*) (lstmrecognizer.cpp:281)
    ==2035==    by 0x13DE72: tesseract::LSTMTrainer::PrepareForBackward(tesseract::ImageData const*, tesseract::NetworkIO*, tesseract::NetworkIO*) (lstmtrainer.cpp:855)
    ==2035==    by 0x13E5E3: tesseract::LSTMTrainer::TrainOnLine(tesseract::ImageData const*, bool) (lstmtrainer.cpp:798)
    ==2035==    by 0x11290E: TrainOnLine (lstmtrainer.h:273)
    ==2035==    by 0x11290E: main (lstmtraining.cpp:194)
    ==2035==  Uninitialised value was created by a heap allocation
    ==2035==    at 0x4C2BBAF: malloc (vg_replace_malloc.c:299)
    ==2035==    by 0x72052A0: pixCreateNoInit (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==2035==    by 0x72053F6: pixCreateTemplateNoInit (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==2035==    by 0x7208917: pixCopyBorder (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==2035==    by 0x71921EF: pixUnsharpMaskingGray2D (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==2035==    by 0x7192D99: pixUnsharpMaskingFast (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==2035==    by 0x7193014: pixUnsharpMasking (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==2035==    by 0x728C454: pixScaleGeneral (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==2035==    by 0x1663DF: tesseract::ImageData::PreScale(int, int, float*, int*, int*, GenericVector<TBOX>*) const (imagedata.cpp:245)
    ==2035==    by 0x1BBA33: tesseract::Input::PrepareLSTMInputs(tesseract::ImageData const&, tesseract::Network const*, int, tesseract::TRand*, float*) (input.cpp:95)
    ==2035==    by 0x1C97A1: tesseract::LSTMRecognizer::RecognizeLine(tesseract::ImageData const&, bool, bool, bool, float, float*, tesseract::NetworkIO*, tesseract::NetworkIO*) (lstmrecognizer.cpp:265)
    ==2035==    by 0x13DE72: tesseract::LSTMTrainer::PrepareForBackward(tesseract::ImageData const*, tesseract::NetworkIO*, tesseract::NetworkIO*) (lstmtrainer.cpp:855)

So some more work is needed. The patch shown above does not fix the real problems. It looks like the pix which was created by pixScaleGeneral contains uninitialized pixel data.
The Tesseract function ComputeBlackWhite operates on that data with random results.
@DanBloomberg, do you have any idea how to fix that?

    ==14279==  Uninitialised value was created by a heap allocation
    ==14279==    at 0x4C2BBAF: malloc (vg_replace_malloc.c:299)
    ==14279==    by 0x71F8BD1: pix_malloc (pix1.c:234)
    ==14279==    by 0x71F8BD1: pixCreateNoInit (pix1.c:343)
    ==14279==    by 0x71F8D06: pixCreateTemplateNoInit (pix1.c:408)
    ==14279==    by 0x71FBF47: pixCopyBorder (pix2.c:1705)
    ==14279==    by 0x718DE46: pixUnsharpMaskingGray2D (enhance.c:1346)
    ==14279==    by 0x718EA29: pixUnsharpMaskingFast (enhance.c:1095)
    ==14279==    by 0x718EC8C: pixUnsharpMasking (enhance.c:917)
    ==14279==    by 0x727A4B4: pixScaleGeneral (scale.c:368)
    ==14279==    by 0x1804D9: tesseract::ImageData::PreScale(int, int, float*, int*, int*, GenericVector<TBOX>*) const (imagedata.cpp:245)
 Using valgrind, I am not able to find uninitialized pixels starting from pixScale (or pixScaleGeneral).  I did something simple like:
    pix3 = pixScale(pix2, 0.6, 0.6);  // pix3 is 8 bpp
    pixGetDimensions(pix3, &w, &h, NULL);
    for (i = 0; i < h; i++) {
        for (j = 0; j < w; j++) {
            pixGetPixel(pix3, j, i, &val);
            tot += val;
        }
    }
where every pixel was read and used.

Try to replace line 1705 of pix2.c, which is pixCreateTemplateNoInit(), with
    pixCreateTemplate()
If this solves the problem, then it may be originating in pixUnsharpMaskingGray1D() or in pixUnsharpMaskingGray2D() and to make sure that valgrind was catching it, I used a conditional in the inner loop:
    pix3 = pixScaleGeneral(pix1, 0.8, 0.8, 0.4, 2);
    pixGetDimensions(pix3, &w, &h, NULL);
    for (i = 0; i < h; i++) {
        for (j = 0; j < w; j++) {
            pixGetPixel(pix3, j, i, &val);
            if (val == 0x12345678)
                break;
        }
    }

If any pixel were uninitialized, we'd have a message like:
   Conditional jump or move depends on uninitialised value(s)
     ==65877==    at 0x40481C: main (...)
There were none.
(We did have an issue with normalization in these pixUnsharpMaskingGray*() functions back in April, that gave rise to some artifacts.)
 My short test program `pixtest.cpp` was successful:

    #include <leptonica/allheaders.h>

    int main(void)
    {
      PIX *pix1 = pixCreate(2047, 71, 8);
      PIX *pix2 = pixScaleGeneral(pix1, 0.676056325, 0.676056325, 0.200000003, 1);
      int width = pixGetWidth(pix2);
      int height = pixGetHeight(pix2);
      int y = height / 2;
      l_uint32* line = pixGetData(pix2) + pixGetWpl(pix2) * y;
      int prev = GET_DATA_BYTE(line, 0);
      if (prev != 0) {
        return 1;
      }
      return 0;
    }

I compiled it on Debian Stretch using `g++ -g pixtest.cpp -llept`.
Valgrind reports the same problem as in Tesseract:

    ==22626== Conditional jump or move depends on uninitialised value(s)
    ==22626==    at 0x400832: main (pixtest.cpp:12)
 > We did have an issue with normalization in these pixUnsharpMaskingGray*() functions back in April, that gave rise to some artifacts.

Could that be the reason for the problem? Debian has a Leptonica version 1.74.1-1, so maybe that fix is missing? Then Debian needs a newer version (and Tesseract should require Leptonica 1.74.2). CC @jbreiden. Stefan, can you run your test program from our github head, or replacing the 1.74.1 scale.c with the most recent one?  That would determine if the normalization change fixed this problem.

I ran your exact program with the current pixScaleGeneral(), on valgrind, and got no error. After failing to find the problem with an uninitialized value from pixUnsharpMasking(), I will do the most simple thing, which is make sure that the pixel values are initialized.  Use of pixCreateTemplateNoInit(), instead of pixCreateTemplate(), is clearly a poor optimization.  I will also remove other uses of the NoInit version in places where it's not obvious by inspection that all pixels are set. Committed (#512) to leptonica.  Hoping that this solves any uninitialized value problems. As far as I see Leptonica 1.74.2 is sufficient (it solved the uninitialized value problems for Tesseract), but of course you can use the newer version, too. 1.74.3 has a fix for the uninitialized issue (the topic of this thread),
and some other bug fixes on windows.  It has far fewer coverity scan
'bugs'.  And I also made it configure-ready, as advertised in the README.

On Fri, Jun 9, 2017 at 11:10 PM, Stefan Weil <notifications@github.com>
wrote:

> As far as I see Leptonica 1.74.2 is sufficient, but of course you can use
> the newer version, too.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/644#issuecomment-307545573>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLLmxMT7FYa8MVlC7A9Z274t3Ng-dks5sCjM_gaJpZM4Ld5Xp>
> .
>
 Dan, the uninitialized issue was already fixed with 1.74.2, and so were the Coverity scan issues. Somehow I didn't realize that 1.74.2 fixed the uninitialized issue in
unsharp masking.  So now it's double-fixed.  And 1.74.3 has even more fixed
coverity scan issues  :-)

For 1.74.3, I wanted to make a configure-ready version available (and also,
I hadn't done a tarball release before on github).  I plan to make all
future releases that way.

So it seems that both 1.74.2 and 1.74.3 can be used with tesseract.

For the future, I'd like to remove the pixWriteDisplay*() functions from
the library, which are only there to support some older versions of
tesseract.

On Sat, Jun 10, 2017 at 2:14 PM, Stefan Weil <notifications@github.com>
wrote:

> Dan, the uninitialized issue was already fixed with 1.74.2, and so were
> the Coverity scan issues.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/644#issuecomment-307590678>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLANpA6zDdbA955Xk-agzECB6WpQlks5sCwdOgaJpZM4Ld5Xp>
> .
>
 Hi there!
The problem seems still there, at least on my MBP :( 

I had exactly the same issue after exactly 100 iterations: 
`Assertion failed: (index >= 0 && index < size_used_), function operator[], file ~/tesseract/ccutil/genericvector.h, line 713.`

I was using Leptonica 1.74.1 provided by Macports, then built manually 1.74.4 (just 1 hour after Dan put out it :) ), still the same problem. 
I make sure `lstmtraining` is linking to the correct version of Lept library (using `otool -L `on Mac)

What baffles me is, the `scale.c` file - which I presume includes the fix to the problem - is **identical** for 1.74.[1 | 2 | 3 | 4]... is it correct?


I'm using a 2015 MBP running OS X El Capitan (10.11.6) with Xcode 8. 
The command I'm using to train:
> ./tesseract/build-mac/bin/Debug/lstmtraining -U tesstutorial/engtrain/eng.unicharset --script_dir langdata/ --debug_interval 100 --net_spec '[1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c105]' --model_output tesstutorial/engoutput/base --train_listfile tesstutorial/engtrain/eng.training_files.txt --eval_listfile tesstutorial/engeval/eng.training_files.txt --max_iterations 5000 

Thanks! @dudullz, there were several problems, and updating Leptonica to 1.74.2 or newer fixes one of them. Pull request #978 fixes the assertion. It's still unmerged, that's why you got that assertion. @stweil first thanks for TRULY swift reply!

It has been training for past 2 hours for about 3,000 iterations and still going - it's just enjoyable to see it continuing after days of struggling :)

So has `updating Leptonica to 1.74.4` + `pull request  #978`  fixed the real problem? means the trained results are valid to use now (not like non-debug builds continue but with invalid results)?
 That fixed at least the currently known problems and should produce more stable results as the trained data no longer depends on undefined values (which could produce random results). so,  is this issue fixed ?  Compilation of 4.0.0alpha fails with gcc 4.4.7 (gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-17)):

`libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I../ccutil -I../viewer -I/usr/local/include/leptonica -g -O2 -MT simddetect.lo -MD -MP -MF .deps/simddetect.Tpo -c simddetect.cpp  -fPIC -DPIC -o .libs/simddetect.o
In file included from ../ccutil/genericvector.h:29,
                 from ../ccutil/params.h:25,
                 from ../ccutil/tprintf.h:23,
                 from simddetect.cpp:19:
../ccutil/helpers.h: In member function ‚Äòvoid tesseract::TRand::set_seed(const std::string&)‚Äô:
../ccutil/helpers.h:50: error: ‚Äòhash‚Äô is not a member of ‚Äòstd‚Äô
`

Steps to reproduce: under an "old" OS (centos6 for example) follow the autogen&configure&make compilation steps and see the compilation error.

Rootcause: std hash was not officially supported in gcc 4.4, only in the TechnicalReport "tr1" namespace i.e. : std::tr1::hash<T> ... 

Possible fix: perhaps just enforcing a "recent" gcc at configure time ?
 Good news: does compile correctly at least with gcc 4.8. Update: there was a AX_GCC_VERSION but that would be better to simply check that the compiler has std hash: 
for example: "ax_cxx_have_hash" 
https://www.gnu.org/software/autoconf-archive/ax_cxx_have_hash.html
? The code makes use of a few C++ 11 features.  Yep, C++11 seems now to be a must have at least for master/version 4.
So would you accept a pull request adding a std hash check to the autoconf script ? @zdenop 
config.log:
[config.log.txt](https://github.com/tesseract-ocr/tesseract/files/690637/config.log.txt)
configure output:
[configure.out.txt](https://github.com/tesseract-ocr/tesseract/files/690648/configure.out.txt)
 it also use `nullptr` and `unique_ptr` and maybe other stuff.
For `unique_ptr` you need libstdc++ 4.6 so perhaps a global cpp 11 check would be better:
https://www.gnu.org/software/autoconf-archive/ax_cxx_compile_stdcxx.html
? The license for `AX_CXX_COMPILE_STDCXX` is permissive:

>Copying and distribution of this file, with or without modification, are permitted in any medium without royalty provided the copyright notice and this notice are preserved. This file is offered as-is, without any warranty.

So maybe we can embed it in our codebase. We probably need approval from Ray for this. >We already have test for c++11 support (without dependency on autoconf-archive). So it should be enough to modify test to produce error in case of missing c++11 support...

:+1: 

https://github.com/tesseract-ocr/tesseract/blob/38cb4acaf906/configure.ac#L355

It will detect C++11 support for g++ version >= 4.7. and for Clang version >= 3.0.  Will it be a problem if detected resolution is 0 dpi?

tesseract scr out
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Warning. Invalid resolution 0 dpi. Using 70 instead. Can someone tell me which is the default resolution used by tesseract when is processing PDF documents? @MrAlex6204
Tesseract does not accept a PDF file as input.
Please use the [forum](https://groups.google.com/d/forum/tesseract-ocr) for asking questions.  I just drew the box according the output coordinates of box file and tsv file,  but I found they were different. hocr & tsv use 'left, top, right, bottom' coordinates while box uses 'left, bottom, right, top'.  Hi,
I am woking on interpretation of handwritten text (English). I just stumbled upon the new version of tesseract and was wondering if the new version can support handwritten text after training. 

Any leads would be beneficial.

Thank you Here is what I found :
- using CNN for chinese char recognition : 
http://people.idsia.ch/~juergen/icdar2011a.pdf
- handwritten recognition using RNN & LSTM :
http://people.idsia.ch/~juergen/tpami_2008.pdf
  https://github.com/DanBloomberg/leptonica/commit/792db025518a
>Encode pdf title in escape 4-byte hex for safety. 
  IMO, most of the OpenCL code should be part of Leptonica.

There are two questions here:
1. Does @DanBloomberg want this code in Leptonica?
2. Are the authors of the code willing to relicense it (Apache 2 -> BSD) Dan,

The code is here: 
https://github.com/tesseract-ocr/tesseract/tree/master/opencl Amit, there are several good reasons why this code should NOT be in leptonica.

(1) Maintenance: I (and any competent C programmer with a background in image processing and analysis) can maintain all of leptonica.  From the beginning of the leptonica project, I understood that maintenance is critical: over the lifetime of the library, the time spent fixing/improving it will far exceed the time spent on the first implementation.  There is no way I could fix errors in the low-level code in this file.

(2) Portability: We have enough trouble maintaining portability with just plain old ansi C over several OS platforms.  The operations here take it to another level: hardware.  What restrictions are there on the hardware for this code to be compiled properly?  Does it work seamlessly on all Intel processors?  What about AMD?  What about ioS and Android?

(3) Benefit: Are the multiple complications from introducing this code into leptonica worth the pain?  As Jeff said, we've already fixed the multipage tiff wrapper, so the time is now O(n), where n is the number of pages.  And this is just a wrapper into tifflib.  Most other operations that are easily parallellized are already fast enough for most applications. Leptonica is intended to be a general utility that gives good performance with a simple implementation.  Emphasis on simple. If in production for a particular application, it is necessary to speed up a particular low-level operation (such as convolution) this should be done as an adjunct to leptonica, not as part of it.

Other image processing libraries have a different genesis and philosophy.  OpenCV was built by Intel engineers in Russia, and is now maintained by Itseez.  It is large and heterogeneous, and might be a good place to house this Intel GPU-based image processing code. OK Dan, thanks for your detailed response! Here are the files with `#ifdef USE_OPENCL`:
https://github.com/tesseract-ocr/tesseract/blob/d55f462c9c/ccmain/thresholder.cpp#L267
https://github.com/tesseract-ocr/tesseract/blob/4ac54a27c6/ccstruct/otsuthr.cpp#L53
https://github.com/tesseract-ocr/tesseract/blob/e949812e63/textord/linefind.cpp#L590

  ```
Extracting font properties only
Rendered page 242 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Rendered page 244 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
Rendered page 239 to file /tmp/tmp.lswGVDuVeX/bih/bih.Siddhanta.exp0.tif
Error in boxCreate: x < 0 and box off +quad
Rendered page 243 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Stripped 1 unrenderable words
Error in boxCreate: x < 0 and box off +quad
Rendered page 245 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
Error in boxCreate: x < 0 and box off +quad
Rendered page 240 to file /tmp/tmp.lswGVDuVeX/bih/bih.Siddhanta.exp0.tif
Rendered page 244 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Rendered page 246 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
Error in boxCreate: x < 0 and box off +quad
Error in boxCreate: x < 0 and box off +quad
Error in boxCreate: x < 0 and box off +quad
Error in boxCreate: x < 0 and box off +quad
Error in boxCreate: x < 0 and box off +quad
Rendered page 241 to file /tmp/tmp.lswGVDuVeX/bih/bih.Siddhanta.exp0.tif
Error in boxCreate: x < 0 and box off +quad
Error in boxCreate: x < 0 and box off +quad
Error in boxCreate: x < 0 and box off +quad
Rendered page 245 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Error in boxCreate: x < 0 and box off +quad
Rendered page 247 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
Rendered page 242 to file /tmp/tmp.lswGVDuVeX/bih/bih.Siddhanta.exp0.tif
Rendered page 246 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Rendered page 248 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
Error in boxCreate: x < 0 and box off +quad
Rendered page 243 to file /tmp/tmp.lswGVDuVeX/bih/bih.Siddhanta.exp0.tif
Rendered page 247 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Rendered page 249 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif

``` Line 179
https://github.com/DanBloomberg/leptonica/blob/8a839a254e8d2ed3965ab0ecce7120b05f291993/src/boxbasic.c >Extracting font properties only

I'm not sure if the LSTM engine needs this step. I am using tesstrain.sh . The ngram file creation, which is used for font properties is done even before creation of images.

--linedata_only is the option used for creating the lstmf files.

```
training/tesstrain.sh --fonts_dir /home/shree/.fonts --lang bih  --linedata_only \
  --langdata_dir ../langdata --tessdata_dir ./tessdata \
  --output_dir ~/tesstutorial/bihnew
``` >I am using tesstrain.sh . The ngram file creation, which is used for font properties is done even before creation of images.

Yes, I know...

I think the LSTM engine does not need this info. If that's true, it should not activated in `tesstrain.sh`  when training witn the `--linedata_only` option.
 ```
           --noextract_font_properties)
                EXTRACT_FONT_PROPERTIES=0 ;;
```

So, for LSTM training we should use both of these -

`--linedata_only --noextract_font_properties` Yes, probably... :-)  When using command mode and -l hin+fra on an image with both Hindi and French, the French text is being misrecognized as numbers. 

The recognition of French part of text is not fully correct if whole image is given via command mode using single language French.

However, when sections of same image are offered via gimagereader gui using single language French, the recognition is correct.

Image file and OCRed text attached.

![24](https://cloud.githubusercontent.com/assets/5095331/21581641/c64ae64e-d060-11e6-9db2-bf398026be14.png)
[24.txt](https://github.com/tesseract-ocr/tesseract/files/680036/24.txt)
[24-fra.txt](https://github.com/tesseract-ocr/tesseract/files/680037/24-fra.txt)
[24-gimagereader.txt](https://github.com/tesseract-ocr/tesseract/files/680038/24-gimagereader.txt)



 If you are on Windows, please try the experimental builds of gImageReader
 by Sandro Mani:

https://smani.fedorapeople.org/tmp/gImageReader_3.2.0_qt5_x86_64_tesseract-25fed52.exe
https://smani.fedorapeople.org/tmp/gImageReader_3.2.0_qt5_i686_tesseract-25fed52.exe

‚Äãand see if separately selected text of each language gives correct result.
‚Äã


ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Sun, Jan 1, 2017 at 10:51 PM, peiman F <notifications@github.com> wrote:

> ‚Äã‚Äã
> ‚Äãit seems this problem occur in other multi lingual process to
> i face this kind of error on Arabic+English scan
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/633#issuecomment-269911238>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o3cBl3zp3ICYcQgXNiyscdPj8JgRks5rN-B_gaJpZM4LYuOm>
> .
>
 https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00

>The neural network engine has not yet been integrated to enable the multi- language mode that worked with Tesseract 3.04, but this will be improved in a future release.
>>
The above comment is out of date. In theory, this is now working, but it looks like it doesn't work as well as intended. Thanks for the info, Amit.

Attaching another image and text with Hindi, Arabic and English as a sample
test image.

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Mon, Jan 2, 2017 at 1:21 PM, Amit D. <notifications@github.com> wrote:

> https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00
>
> The neural network engine has not yet been integrated to enable the multi-
> language mode that worked with Tesseract 3.04, but this will be improved in
> a future release.
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/633#issuecomment-269941901>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o4HJZ2hcb5DhV51CaOW9Z2I3GzBvks5rOKxlgaJpZM4LYuOm>
> .
>

S ÿßŸä⁄©ŸäŸá ‡§ê‡§ï‡•ç‡§Ø aikya, s.m. Oneness, unity, singleness, identity, sameness, harmony (=ekatƒÅ); total, aggregate, product.

H ÿßŸä⁄ØŸÜ ‡§ê‡§ó‡•Å‡§£ aigu·πá [S. ‡§Ö‡§µ+‡§ó‡•Å‡§£], s.m. Unskilfulness, stupidity, &c.=augun, q.v.

A ÿßŸäŸÑ ƒ´yal, aiyal, uyyal, s.m. Stag; deer, hart; wild goat.

S ÿßŸäŸÑÿß ‡§è‡§≤‡§æ elƒÅ, s.f. Cardamoms. (See ilƒÅƒáƒ´.)

H ÿßŸäŸÑÿßŸÖ ‡§à‡§≤‡§æ‡§Æ ƒ´lƒÅm, s.m. Auction, public sale (=lƒ´lƒÅm, nƒ´lƒÅm, q.q.v.).

P ÿßŸäŸÑ⁄ÜŸä elƒáƒ´, s.m. Ambassador, envoy, delegate, agent:‚Äîelƒáƒ´ karnƒÅ, To discharge the functions of an ambassador or agent; to Ray,
Thank you for fixing this. The languages are being recognized much better now.

However, problem with words being skipped during recognition remains. Here is some debug info regarding a missing Hindi word, it is being recognized but is getting discarded and is not output:

```
Processing word with lang fra at:Bounding box=(361,395)->(447,419)
Trying word using lang fra, oem 1
Best choice: accepted=1, adaptable=0, done=1 : Lang result :          : R=80, C=-1, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM
str	 	 	 	 	 	 	 	 
state:	1 	1 	1 	1 	1 	1 	1 	1 
C	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000
1 new words better than 0 old words: r: 80 v 0 c: -1 v 0 valid dict: 0 v 0
Trying word using lang hin, oem 1
Best choice: accepted=0, adaptable=0, done=1 : Lang result : ‡§Ü‡§¨‡§æ‡§Ç‡§≤‡•Ä‡§∞ : R=6.78767, C=-4.16219, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM
str	‡§Ü	‡§¨‡§æ‡§Ç	‡§≤‡•Ä	‡§∞
state:	1 	1 	1 	1 
C	-0.198	-0.595	-0.193	-0.195
1 new words worse than 1 old words: r: 6.78767 v 80 c: -4.16219 v -1 valid dict: 0 v 0
Processing word with lang fra at:Bounding box=(557,393)->(748,413)
```
![22](https://cloud.githubusercontent.com/assets/5095331/22327088/70560866-e3db-11e6-867e-264fcb95f1e1.png)
  Using Tesseract 4 (libtesseract) in my project [decipher_text](https://github.com/rudrabhoj/decipher_text).
When I use OEM_TESSERACT_ONLY, it takes little over 7-8 seconds to complete the recognization of a page in English. But when I try to instead use OEM_LSTM_ONLY, it takes 10-15 minutes, if not more, to do the same. I am using i5 2400. Ubuntu 16.04 x86_64.

Part of code where this is used:
`  if (ocrUnit->process->Init(tessDataPath, languageArg, tesseract::OEM_LSTM_ONLY)){`  
    `//Again, handle error here`  
    `//`     
    `//`       
    `//`       
    `//`       
  `}`   

Entire file in which it was used could be seen [here](https://github.com/rudrabhoj/decipher_text/blob/master/src/Control/TesseractRecognize.cxx). (Note: File is from an older, stabler version) Hi,

Did you test it with the Tesseract command line?
How did you compile it? Did you use debug mode?
Can you provide an image?
 Also see comments in https://github.com/tesseract-ocr/tesseract/issues/40

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Sun, Jan 1, 2017 at 1:31 PM, Amit D. <notifications@github.com> wrote:

> Hi,
>
> Did you test it with the Tesseract command line?
> How did you compile it? Did you use debug mode?
> Can you provide an image?
>
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/632#issuecomment-269895203>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o4UvfX-7cir3Ccmjn66P-oI1oZibks5rN11JgaJpZM4LYrS->
> .
>
  I built my project with cppan and then tried to run, and got an error:
```
Info in pixWriteMemPng: work-around: writing to a temp file
Info in fopenReadFromMemory: work-around: writing to a temp file
DotProductAVX can't be used on Android
```
After compiling example project - https://github.com/cppan/tesseract_example/tree/master/with_cppan I got same error. Can you please fix it?
OS: Windows 7 Thanks, it works! Also, one question: will this built tesseract without this line works also on 64-bit Windows OS? @stweil 
https://sourceforge.net/p/predef/wiki/Architectures/ >No need to fix this this year ‚Äì for the rest of the year I have other priorities. Happy new year!

Not sure if you were joking here or were serious...
If by "this year" you meant '2016', then you were joking.

Happy new year to you too! @stweil , 
For your preferred option - **"Let the compiler do the optimization (and forget that explicit SSE/AVX code). This is my preferred solution as it also works for ARM and other _architectures."**. Could you advise how can it be done? ## Automatic vectorization

### GCC
https://gcc.gnu.org/projects/tree-ssa/vectorization.htmlAuto
https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html

### LLVM
http://llvm.org/docs/Vectorizers.html

### MSVC
https://msdn.microsoft.com/en-us/library/hh872235.aspx
https://blogs.msdn.microsoft.com/vcblog/2012/04/16/auto-vectorization/ 
https://locklessinc.com/articles/vectorize/


https://monoinfinito.wordpress.com/series/vectorization-in-gcc/
>The downside to all the black-box magic the compiler does on loop-vectorization is quite big, though: you loose all visibility into how your code actually works. It might work wonderfully one day and then the next it might become the slowest part of your program, because a small change made gcc miss the chance of vectorization.
>
>If (or when) gcc looses the ability to vectorize one of your loops, you‚Äôll be digging around a lot of compiler logs to try and figure out what went wrong. If you were to write the vectorized loop yourself using intrinsics you‚Äôd be certain that the loop works and it‚Äôs vectorized (duh!) but you‚Äôd have to manage the portability, alignment and aliasing yourself. That‚Äôs not a trivial task if you are aiming for a portable program.
 The non-SIMD version of the dotproduct method can be significantly sped up by doing manual loop unrolling.   Also, this version can use OpenMP (with `#pragma...` above the loop) Here is one source:
http://blog.theincredibleholk.org/blog/2012/12/10/optimizing-dot-product/ @stweil  I am getting the error while using the new binaries provided by you.
Ref https://github.com/tesseract-ocr/tesseract/issues/689

```
PS C:\Users\User\shree\jtess\tesseract-ocr> ./tesseract.exe -v
tesseract 4.00.00alpha
 leptonica-1.74.1
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.5.0) : libpng 1.6.20 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.3 : libo
penjp2 2.1.0

 Found AVX
 Found SSE

```
Extracting tessdata components from C:\Users\User\shree\tessdata/vie.traineddata
Wrote C:\Users\User\shree\jtess\samples\vie/vie.lstm
Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Warning: given outputs 105 not equal to unicharset of 227.
Num outputs,weights in serial:
  1,36,0,1:1, 0
Num outputs,weights in serial:
  C5,5:25, 0
  Ft16:16, 416
Total weights = 416
  [C5,5Ft16]:16, 416
  Mp3,3:16, 0
  Lfys64:64, 20736
  Lfx128:128, 98816
  Lrx128:128, 131584
  Lfx256:256, 394240
  Fc227:227, 58339
Total weights = 704131
Built network:[1,36,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc227] from request [1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128
 Lrx128 Lfx256 O1c105]
Training parameters:
  Debug interval = -1, weights = 0.1, learning rate = 0.0001, momentum=0.9
Loaded 188/188 pages (1-188) of document C:\Users\User\shree\jtess\samples\vie\vie.Arial.exp0.lstmf
Info in fopenReadFromMemory: work-around: writing to a temp file
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android
```
 Thanks!

Maybe we should keep this issue 'open'

- excuse the brevity, sent from mobile

On 31-Jan-2017 7:05 PM, "Stefan Weil" <notifications@github.com> wrote:

This is again (or still) a bug for 32 bit Intel platforms. I'll have a look
how to fix it later.

‚Äî
You are receiving this because you commented.

Reply to this email directly, view it on GitHub
<https://github.com/tesseract-ocr/tesseract/issues/631#issuecomment-276364076>,
or mute the thread
<https://github.com/notifications/unsubscribe-auth/AE2_o29aVPR_pcI7fEuQKMHzJfOyfzF7ks5rXziIgaJpZM4LYhc->
.
 @stweil The pull request #698 seems to solve the problem on x86 not entirely; On Windows 7 x64, VS2015, x86 target using the latest tesseract-ocr:master branch (which includes the merged pull request #698) still results in "DotProductAVX can't be used on Android" for me (Intel i7-4650U). However, the workaround in the comment above to remove `# define X86_BUILD 1` from `arch/simddetect.cpp` resolves this. @stweil Ah, I see! Yes, I used cmake - never mind then!
Thank you for the clarification! I still encounter this error "DotProductAVX can't be used on Android" with the latest source from master. I built the .exe in VS2015 with x86 target. It would work with 3.04 language data but throw exceptions when using 4.00 language data.

The workaround (commenting out the `#define` directive in `simddetect.cpp`) works, but a permanent fix is desired. Thanks. @stweil, I undid the change to `simddetect.cpp` and made the change to `dotproductavx.cpp`. The compiled exe still crashes with the same error.

I'm not sure if I have AVX support. I run Windows 10 64-bit on i7-7500U CPU. Here is output on my machine:

```
tesseract 4.00.00alpha
 leptonica-1.74.1 (Feb 11 2017, 11:04:30) [MSC v.1900 DLL Release x86]
  libjpeg 9b : libpng 1.6.28 : libtiff 4.0.7 : zlib 1.2.8

 Found AVX
 Found SSE
```

The shorter variant works! Let me research for how to define a macro in Visual Studio for a C++ project. Do you know, by chance? I don't think my VS set up uses `CMakeLists.txt`, but I found out how to set the flag:

![image](https://cloud.githubusercontent.com/assets/1501035/23319631/098dcdd4-fa9d-11e6-9a30-b09038beefa5.png)

With that enabled, I reverted all the code changes. The output .exe now works good. Thank you. I got the same error when using command line on Ubuntu:
```
root@ellensong: tesseract chi.jpg chi -l chi_sim
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
DotProductAVX can't be used on Android
Aborted (core dumped)
```
I've never got this error when I set language param as chi_tra or eng.
Could anybody tell me how to fix it?
Thanks a lot!

 @EllenSong77, did you use the latest code? Are you running Ubuntu in a virtual machine (if yes: please provide more information on the kind of virtualisation)? @stweil I clone the code yesterday, and running Ubuntu in a physical machine. What other information could be more helpful that I should provide?  >I've never got this error when I set language param as chi_tra or eng.

Very strange! From where did you get  the chi_tra and eng traineddata?
From here:
https://github.com/tesseract-ocr/tessdata/tree/3.04.00
Or from here:
https://github.com/tesseract-ocr/tessdata/tree/master/best
 @amitdo I got them by command line apt-get install tesseact-ocr-xxx and also cloned from https://github.com/tesseract-ocr/tessdata/tree/master/best
Maybe I should what @Shreeshrii said too.
Do you mean I should export TESS_DATA=......../tesseract/tesseract-ocr.tessdata/best ?
![screenshot from 2017-08-17 14-31-56](https://user-images.githubusercontent.com/25813556/29398731-dd84bed8-8358-11e7-8d9c-f5b237090e2b.png)
 >I got them by command line apt-get install tesseact-ocr-xxx and also cloned from https://github.com/tesseract-ocr/tessdata/tree/master/best

What repo do you use for Tesseract?
This one?
https://launchpad.net/%7Ealex-p/+archive/ubuntu/tesseract-ocr

  i understand that much of the new Tesseract 4.0 is using a customized implementation of Ocropus, relying basically on the new LSTM recognition engine.

But the main problem is that most of the decisions that are being taken focus mostly on English (Latin Languages)  which already able to reach +95% recognition rates easily.
My concern is allowing the other languages such as Arabic to be able to reach the **PRECISION CEILING.**

Methods such as **BLSTM** (Bidirectional LSTM) , and the two-dimensional 2D LSTM which is called **MDLSTM**, can achieve without explicit segmentation of words, a character-level accuracies of 92 and 96% !!!!!! and I repeat, **without explicit segmentation.**

So my question is that, will there be plans to implement and ascend the current LSTM to a **MDLSTM (Multi-dimensional LSTM)**, this will radically make ALL THE LANGUAGES ABLE TO PASS THAT PRECISION CEILING.

i am planing to engage in testing Tesseract 4.0 LSTM on the Arabic language, and wanting to post results in the future, i hope that there will be recognition improvement while testing.
Thank you Ray for your hard work, and all contributors, you are appreciated.


More information about BLSTM and MDLSTM:
https://www.nist.gov/sites/default/files/documents/itl/iad/mig/OpenHaRT2013_WorkshopPres_A2IA.pdf
http://www.a2ialab.com/lib/exe/fetch.php?media=presentations:icdar2015_chinese_slides.pdf
https://goo.gl/0wUNfm

 In principle, Tesseract is probably as accurate (or slightly more accurate) than ocropy/clstm.

Tesseract has official trained models for ~100 languages. ocropy has official models for English and German only. Unlike ocropus, Tesseract works on Windows.

BLSTM is implemented and used.

2D-LSTM is also implemented in the library. I think (not sure) it's not used by the released traineddata. Using 2D-LSTM means much longer time to train a model. and for OCRing printed text, the accuracy will not necessary be better than 1D-BLSTM.

BTW, ocropy doesn't have 2D-LSTM support. Please see https://github.com/tesseract-ocr/tesseract/wiki/VGSLSpecs

- excuse the brevity, sent from mobile

On 30-Dec-2016 10:06 PM, "Amit D." <notifications@github.com> wrote:

> In principle, Tesseract is probably as accurate (or slightly more
> accurate) than ocropy/clstm.
>
> Tesseract has official trained models for ~100 languages. ocropy has
> official models for English and German only. Unlike ocropus, Tesseract
> works on Windows.
>
> BLSTM is implemented and used.
>
> 2DLSTM is also implemented in the library. I think (not sure) it's not
> used by the released traineddata. Using 2DLSTM means much longer time to
> train a model. and for OCRing printed text, the accuracy will not necessary
> be better than 1D-BLSTM.
>
> BTW, ocropy doesn't have 2D-LSTM support.
>
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/630#issuecomment-269792095>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oweaHUpMa-dyavVOg6KqTEwrrcoHks5rNTMTgaJpZM4LYPU8>
> .
>
 >But the main problem is that most of the decisions that are being taken focus mostly on English (Latin Languages)

This is not really the situation with the LSTM engine.

The difference in accuracy between Latin script based langs and Arabic is due to
1. Better traineddata files for the Latin script based langs.
2. The 'complexity' of the script. Arabic is much more complex.   Also, the OCR stage is dependent on the layout analysis stage which is weaker for Arabic.  Shree, indic scripts are even more complex... @amitdo Thanks for clearing things up,  improved pre-processing may make 1D-LSTM outperform the more complex MDLSTM. You were right.
I see, the main issue is not the ocr engine directly, but is of analysis/segmentation/classification.
Perhaps, i should focus on a combination of Tesseract LSTM & a Computer Assisted Transcription method.
somewhat similar to:   https://sites.google.com/site/paradiitproject/project-definition

@Shreeshrii So Tesseract 4.x has the capability of producing more sophisticated and complex structures.

@roozgar i was looking for a method that gain +85% recognition rate for Arabic language.
Tesseract 3.x was using cube for arabic that made me loose hope, **But thanks to the developers of Tesseract 4.0 for introducing the new LSTM engine, the hope is back and the community is excited.** I am looking forward to test this version after reading that you've got an 80% recognition.
@roozgar can you share your training process, the tif/box files and the traineddata.
 

 @roozgar what operating system are you using? Please see Ray's comment with accuracy figures in
https://github.com/tesseract-ocr/tesseract/issues/40

I have found Hindi to have much greater accuracy with LSTM engine.

- excuse the brevity, sent from mobile
 This is what is used for most of the languages:
https://github.com/tesseract-ocr/tesseract/wiki/VGSLSpecs#full-example-a-multi-layer-lstm-capable-of-high-quality-ocr

I think it is 2D-LSTM. @amitdo thanks, I have been told that 4.x version of tesseract would be the next big leap, now I believe. https://github.com/tensorflow/tensorflow/blob/v1.4.0-rc1/tensorflow/contrib/ndlstm/README.md  LSTM training is done on line boxes. The error/info messages from the program refer to these also as pages, which is confusing. 

When training using a multi-page tif, Page numbers of the tif being processed are displayed, concurrently another set of page numbers is displayed with respect to lstmf (I suspect these are line numbers).

```
=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=./tessdata
[Wed Dec 28 10:57:18 DST 2016] /usr/local/bin/tesseract /tmp/tmp.auXd9ArSbG/bih/bih.Lohit_Devanagari.exp0.tif /tmp/tmp.auXd9ArSbG/bih/bih.Lohit_Devanagari.exp0 lstm.train ../langdata/bih/bih.config
Tesseract Open Source OCR Engine v4.00.00alpha-219-gc124f87 with Leptonica
Page 1
Page 2
Loaded 41/41 pages (1-41) of document /tmp/tmp.auXd9ArSbG/bih/bih.Lohit_Devanagari.exp0.lstmf
Page 3
Loaded 82/82 pages (1-82) of document /tmp/tmp.auXd9ArSbG/bih/bih.Lohit_Devanagari.exp0.lstmf
``` the LSTM related 'page numbering' messages are displayed elsewhere during training also.

```
$   training/lstmtraining --model_output ~/tesstutorial/sanskrit2003_from_full/sanskrit2003 \
>   --continue_from ~/tesstutorial/sanskrit2003_from_full/san.lstm \
>   --train_listfile ~/tesstutorial/santrain/san.training_files.txt \
>   --target_error_rate 0.01
Loaded file /home/shree/tesstutorial/sanskrit2003_from_full/sanskrit2003_checkpoint, unpacking...
Successfully restored trainer from /home/shree/tesstutorial/sanskrit2003_from_full/sanskrit2003_checkpoint
Loaded 1746/1746 pages (0-1746) of document /home/shree/tesstutorial/santrain/san.Chandas.exp0.lstmf
Loaded 345/1760 pages (1415-1760) of document /home/shree/tesstutorial/santrain/san.Uttara.exp0.lstmf
Loaded 1814/1814 pages (0-1814) of document /home/shree/tesstutorial/santrain/san.Gargi.exp0.lstmf
Found AVX
Found SSE
At iteration 1808/17200/17229, Mean rms=0.336%, delta=0.129%, char train=0.41%, word train=1.751%, skip ratio=0.2%,  New worst char error = 0.41 wrote checkpoint.

``` https://github.com/tesseract-ocr/tesseract/blob/23a7330c85cf9066df4e65dd17c940218d0b54ef/ccstruct/imagedata.cpp#L554

It seems that it saves each line as a separate image.
I agree that the message is confusing.
   This is using glibtoolize from homebrew for autogen.sh.

```
$ git clone https://github.com/tesseract-ocr/tesseract.git
Cloning into 'tesseract'...
remote: Counting objects: 15316, done.
remote: Compressing objects: 100% (23/23), done.
remote: Total 15316 (delta 8), reused 0 (delta 0), pack-reused 15293
Receiving objects: 100% (15316/15316), 35.47 MiB | 7.87 MiB/s, done.
Resolving deltas: 100% (11818/11818), done.
$ cd tesseract/
$ git rev-parse HEAD
3817aa3079e741bd3a98af11d489f7a332e71ab3
$ ./autogen.sh 
Running aclocal
Running libtoolize
./autogen.sh: line 74: libtoolize: command not found
glibtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, 'config'.
glibtoolize: copying file 'config/ltmain.sh'
glibtoolize: putting macros in AC_CONFIG_MACRO_DIRS, 'm4'.
glibtoolize: copying file 'm4/libtool.m4'
glibtoolize: copying file 'm4/ltoptions.m4'
glibtoolize: copying file 'm4/ltsugar.m4'
glibtoolize: copying file 'm4/ltversion.m4'
glibtoolize: copying file 'm4/lt~obsolete.m4'
./autogen.sh: line 75: libtoolize: command not found
Running autoheader
Running automake --add-missing --copy
configure.ac:316: installing 'config/compile'
configure.ac:87: installing 'config/config.guess'
configure.ac:87: installing 'config/config.sub'
configure.ac:69: installing 'config/install-sh'
configure.ac:69: installing 'config/missing'
api/Makefile.am: installing 'config/depcomp'
Running autoconf

All done.
To build the software now, do something like:

$ ./configure [--enable-debug] [...other options]
$ ./configure
checking for g++... g++
checking whether the C++ compiler works... yes
checking for C++ compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
Using git revision: 4.00.00alpha-239-g3817aa3
checking for a BSD-compatible install... /usr/local/bin/ginstall -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /usr/local/bin/gmkdir -p
checking for gawk... no
checking for mawk... no
checking for nawk... no
checking for awk... awk
checking whether make sets $(MAKE)... yes
checking for style of include used by make... GNU
checking whether make supports nested variables... yes
checking dependency style of g++... gcc3
checking whether to enable maintainer-specific portions of Makefiles... no
checking build system type... x86_64-apple-darwin15.6.0
checking host system type... x86_64-apple-darwin15.6.0
./configure: line 4237: syntax error near unexpected token `-mavx,'
./configure: line 4237: `AX_CHECK_COMPILE_FLAG(-mavx, avx=1, avx=0)'
$
```

So, it looks like AX_CHECK_COMPILE_FLAG is undefined on OS X.

This appears related to https://github.com/tesseract-ocr/tesseract/commit/02a6970cf361ae12e2e2b5374f87bd09b3802bfd#diff-67e997bcfdac55191033d57a16d1408a

Since this error is a bit cryptic, it might be nice to add a check to see if AX_CHECK_COMPILE_FLAG is defined is added, and perhaps print a message to give some guidance on how to get it (probably something in homebrew? upgrade autoconf maybe?).

A poor workaround for this error is to add http://git.savannah.gnu.org/gitweb/?p=autoconf-archive.git;a=blob_plain;f=m4/ax_check_compile_flag.m4 to the project's m4 directory, then rerun autogen.sh before running configure again -- that gets around the error on my machine. https://github.com/Homebrew/homebrew-core/blob/master/Formula/autoconf-archive.rb **Update**: need to `apt install autoconf-archive` to fix this issue.

+1 on Ubuntu 16.04

```
$ ./configure --enable-debug                                                                                                                                              2 ‚Üµ
checking for g++... g++
checking whether the C++ compiler works... yes
checking for C++ compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
Using git revision: 4.00.00alpha-239-g3817aa3
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking for gawk... no
checking for mawk... mawk
checking whether make sets $(MAKE)... yes
checking for style of include used by make... GNU
checking whether make supports nested variables... yes
checking dependency style of g++... gcc3
checking whether to enable maintainer-specific portions of Makefiles... no
checking build system type... x86_64-pc-linux-gnu
checking host system type... x86_64-pc-linux-gnu
./configure: line 4249: syntax error near unexpected token `-mavx,'
./configure: line 4249: `AX_CHECK_COMPILE_FLAG(-mavx, avx=1, avx=0)'
``` Yesterday I added the missing dependency to this wiki page:
https://github.com/tesseract-ocr/tesseract/wiki/Compiling Thanks for the info.

Note on your expectation of user-familiarity with compile software, I personally am not that familiar with c/c++ compilers since I barely do any programming in those languages but merely compile software using (usually) autoconf with simple steps.

I'm sure I'm not the only one, just for some perspective though I did find the solution immediately after posting my comment so I accept the -1 for laziness :)
 >... just for some perspective though I did find the solution immediately after posting my comment so I accept the -1 for laziness :)

+1 

:laughing:  Hey @zdenop, if not keeping track of every package that I have installed makes me lazy, then I guess I'm lazy. :)

What about printing out something like "install autoconf-archive", instead of "syntax error near unexpected token"?

Would you accept a patch?  I've compiled and installed the master branch today and started to play around a bit with text extraction from japanese text. With the supplied training data LSTM seems to be a bit better at horizontal text than the old (oem 0) method.

However, with vertical text LSTM is really bad and does not produce any good results.

This is my results with the following three test images. (I have scaled them to 300 dpi)

[test1](https://cloud.githubusercontent.com/assets/312503/21546356/81151560-cdde-11e6-902c-c2e2cfaed90b.png)
`tesseract test1.png out -l jpn --oem 0 --psm 5 && cat out.txt`
„Åù„ÅÆ„Åã„Çè„Çä„Éª„Éª„Éª„Éª„Éª„Éª
`tesseract test1.png out -l jpn --oem 1 --psm 5 && cat out.txt`
„Åî ‰∫∫ ÂøÉ ‚Ä•.

For test2.png, I cut off the top row of a vertical text segment 
[test2](https://cloud.githubusercontent.com/assets/312503/21546355/8114c2c2-cdde-11e6-9f66-5e1e3c3584ee.png)
`tesseract test2.png out -l jpn --oem 0 --psm 5 && cat out.txt`
„Å†
Ê¥ó
„Åä
„Åß
`tesseract test2.png out -l jpn --oem 1 --psm 5 && cat out.txt`
„Å¢
Êñº
+
„É¨
`tesseract test2.png out -l jpn --oem 0 --psm 6 && cat out.txt`
„Åß„ÅäÊ¥ó„Å†‚Äú
`tesseract test2.png out -l jpn --oem 1 --psm 6 && cat out.txt`
„Åß „Åä Ê¥ó „Å†

[test3](https://cloud.githubusercontent.com/assets/312503/21546353/810209a2-cdde-11e6-9ecd-c4f2eb6308c4.png)
`tesseract test3.png out -l jpn --oem 0 --psm 5 && cat out.txt`
ÂøÉÈÖç„ÅîÁÑ°Áî®
ÁßòÂØÜ„Å´„Åó„Åæ„Åô„Çà
`tesseract test3.png out -l jpn --oem 1 --psm 5 && cat out.txt`
„Å§ Âúñ Êúà Â∫∏ Êòé
ÊÉü ÂÉï „Çä „Åõ„Å§ 44 „Åµ 6

Using psm 6 on test3 does make LSTM a bit better, but as with oem 0, it fails to extract the text correctly...

`tesseract test3.png out -l jpn --oem 0 --psm 6 && cat out.txt`
ÁßòÂøÉ
Â£ΩÈÜí
„ÅóÁÑ°
„ÅæÁî®
„Åô
„Çà
`tesseract test3.png out -l jpn --oem 1 --psm 6 && cat out.txt`
Áßò ÂøÉ
„ÅØ :
„Åó ÁÑ°
„Åæ Áî®
„Åô
„Éú

I've also noticed that even if LSTM is a bit better with horizontal text, it seems to print out the result with spaces even if there are no space in the original text. For example:
„ÅØ„ÅØ„ÅØ„ÅØ
Becomes:
„ÅØ „ÅØ „ÅØ „ÅØ
 https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00#integration-with-tesseract

>The neural network engine has not yet been integrated to enable the multi- language mode that worked with Tesseract 3.04, but this will be improved in a future release. Vertical text is also not yet supported, so support for Japanese and Traditional Chinese for example are limited to horizontally rendered text. @amitdo @jbreiden Ah, I missed that wiki page, sorry. Should I close this issue or keep it open until this is implemented? I think you can keep it open. An admin can close it if he wants to.  Ray added jpn_vert.traineddata
https://github.com/tesseract-ocr/tessdata/tree/master/best @amitdo Thanks for the headsup! It seems to work better than the old (oem 0) method for me. @zdenop, please close this issue.  - I followed instructions to compile tesseract from `https://github.com/tesseract-ocr/tesseract/wiki/Compiling#Compilation`

- I try running tesseract I get **Segmentation fault (core dumped)**

- gdb logs 
(gdb) run
Starting program: /usr/local/bin/tesseract 
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".

Program received signal SIGSEGV, Segmentation fault.
STRING::string (this=this@entry=0x7ffff7dc9a78 <debug_file+24>) at strngs.cpp:203
203	  if (header->used_ == 0)
(gdb) bt
#0  STRING::string (this=this@entry=0x7ffff7dc9a78 <debug_file+24>) at strngs.cpp:203
#1  0x00007ffff7873e41 in string (this=0x7ffff7dc9a60 <debug_file>) at params.h:203
#2  tprintf_internal (format=format@entry=0x7ffff789ad32 "Found AVX\n") at tprintf.cpp:60
#3  0x00007ffff77f2661 in SIMDDetect::SIMDDetect (this=<optimized out>) at simddetect.cpp:63
#4  0x00007ffff7dea10a in call_init (l=<optimized out>, argc=argc@entry=1, 
    argv=argv@entry=0x7fffffffdb18, env=env@entry=0x7fffffffdb28) at dl-init.c:78
#5  0x00007ffff7dea1f3 in call_init (env=<optimized out>, argv=<optimized out>, argc=<optimized out>, 
    l=<optimized out>) at dl-init.c:36
#6  _dl_init (main_map=0x7ffff7ffe1c8, argc=1, argv=0x7fffffffdb18, env=0x7fffffffdb28) at dl-init.c:126
#7  0x00007ffff7ddb30a in _dl_start_user () from /lib64/ld-linux-x86-64.so.2
#8  0x0000000000000001 in ?? ()
#9  0x00007fffffffdecb in ?? ()
#10 0x0000000000000000 in ?? ()

- Any clue why this is happening ? No issues seen now  Messages only shown now when asking for version and not for each image. Thanks!

```
 tesseract -v
tesseract 4.00.00alpha-238-ge6ccfb2
 leptonica-1.74
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 Found AVX
 Found SSE

```
```
tesseract san001.jpg san001.tst -l san
Tesseract Open Source OCR Engine v4.00.00alpha-238-ge6ccfb2 with Leptonica

```  I got error when i'm trying this command : brew link libpng libtiff

`Linking /usr/local/Cellar/libpng/1.6.26... 
Error: Could not symlink share/man/man3/libpng.3
/usr/local/share/man/man3 is not writable.`  Do Tesseract support khmer language  ?  @choungchamnab 

Please see comment by @theraysmith  at https://github.com/tesseract-ocr/tesseract/issues/654#issuecomment-274574951

If you are able to point to resources for building a text corpus for Khmer language, it will help in adding support for the language. https://github.com/tesseract-ocr/tessdata/blob/master/khm.traineddata On further testing,

khmer works with --oem 0. 
Using --oem 1 leads to only numbers and punctuation, as referred in https://github.com/tesseract-ocr/tesseract/issues/654 by Ray.

@zdenop , please reopen the issue, as khmer is not working  with --oem 1. Thanks.

Sample outputs attached.
[khm.Leelawadee_UI_Bold.exp0-0.txt](https://github.com/tesseract-ocr/tesseract/files/729037/khm.Leelawadee_UI_Bold.exp0-0.txt)
[khm.Leelawadee_UI_Bold.exp0-1.txt](https://github.com/tesseract-ocr/tesseract/files/729036/khm.Leelawadee_UI_Bold.exp0-1.txt)

  I find this:https://github.com/civetweb/civetweb/pull/356

macOS Sierra
use 'brew install tesseract' to install:


/usr/include/time.h:177:5: error: conflicting types for 'clock_get_time'
int clock_gettime(clockid_t __clock_id, struct timespec *__tp);
    ^
./openclwrapper.h:63:23: note: expanded from macro 'clock_gettime'
#define clock_gettime clock_get_time
                      ^
/usr/include/mach/clock.h:75:15: note: previous declaration is here
kern_return_t clock_get_time
              ^
1 error generated.
make[1]: *** [openclwrapper.lo] Error 1
make: *** [install-recursive] Error 1

thx! fixed For some reason `3.05.00dev` does not have this fix: https://github.com/tesseract-ocr/tesseract/commit/8e9159b09155

https://github.com/tesseract-ocr/tesseract/blob/3.05.00dev/opencl/openclwrapper.h#L63 i found the same problem when i brew install 
i fix it by
comment   //#define clock_gettime clock_get_time
in  openclwrapper.h 
this may help https://github.com/balabit/syslog-ng/issues/1249   
How should Vs2015 solve this problem ?
Too many Error...

It looks like the pixRead function found the file "a.png" in C: \\ datas, why does pixRead return a NULL value?

OS : Windows 10 pro
IDE tool : visual studio 2015 update 3
Teseract - ocr version link : https ://github.com/tesseract-ocr/tesseract   (Tesseract Open Source OCR Engine(main repository))
leptonica version : 1.74.0

#include <allheaders.h>
#include <baseapi.h>
#include <iostream>

	int main()
{
	char * outText = nullptr;
	Pix *image = nullptr;

	tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();
	// Initialize tesseract-ocr with English, without specifying tessdata path
	if (api->Init(NULL, "eng")) {
		fprintf(stderr, "Could not initialize tesseract.\n");
		exit(1);
	}



	image = pixRead("C:\\datas\\a.tif");
	api->SetImage(image);
	// Get OCR result
	outText = api->GetUTF8Text();
	printf("\n OCR output: %s \n", outText);

	// Destroy used object and release memory
	api->End();
	delete[] outText;
	pixDestroy(&image);

	return 0;
}

Output:
/********************************************************************/
Error in pixReadStreamPng : function not present
Error in pixReadStream : no fix returned
Error in pixRead : pix not Read
Error in pixGetDimensions : pix not defined
Error in pixGetColormap : pix not defined
Error in pixGetCopy : Pixs not defined
Error in pixGetDepth : pix not defined
Error in pixGetWpl : pix not defined
Error in pixGetYRes : pix not defined
Error in pixGetClone : Pixs not defined

Please call SetImage before attempting recognition.


  Hi, I've got this error suddenly

```
TesseractError: (-11, 'Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica\nDetected 386 diacritics\nFound AVX\nFound SSE')
```

Can anyone help me with this error? I have no idea what's causing the problem.
It worked fine on every other images I have Are you using a different language for this image?
 This is usually not an error, just an info message. Your output file should be created. >Detected 386 diacritics

Sometimes, this means the image has a lot of 'noise'. I was using python wrapper and yes, it seems like it's not an error but wrapper considers it as an error and terminates process.

I just made program skip those particular images when it throws exception.

Thanks all for your comments and I will be sure to ask on user forum next time üòÉ   Thanks again.  Nice!

What about moving the SIMD detection code to a separate file?
(maybe to `arch/simddetection.h`)  Hi there,
I am ready to test Tesseract 4.0 to make sure that the Arabic Language is not forgotten, but I am facing alot of problems in the training process, I know that Ray has done a great job in this version by documenting everything, but still i need some help.

Can somebody list the commands, line-by-line, from creating a tif+box from the text that i've attached, to creating an "ara.traineddata" assuming the font is timesnewroman.
My text is only 22 words, Download the text:  [arabic1.txt](https://github.com/tesseract-ocr/tesseract/files/673277/arabic1.txt)

**Do not , I repeat, Don't direct me to the documentation page, I need line-by-line help**
Thank you

 See https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Finetune @Shreeshrii
Thanks, your an amazing contributor  After making VS solution with next steps:
 cd tesseract
 cppan
 mkdir build
 cd build
 cmake ..

I want to build text2image project, but build failed with errors:
 
text2image.obj : error LNK2019: unresolved external symbol "struct tesseract::ParamsVectors * __cdecl GlobalParams(void)" (?GlobalParams@@YAPAUParamsVectors@tesseract@@XZ) referenced in function "void __cdecl `dynamic initializer for 'FLAGS_bidirectional_rotation''(void)" (??__EFLAGS_bidirectional_rotation@@YAXXZ)
pango_font_info.obj : error LNK2001: unresolved external symbol "struct tesseract::ParamsVectors * __cdecl GlobalParams(void)" (?GlobalParams@@YAPAUParamsVectors@tesseract@@XZ)
tlog.obj : error LNK2001: unresolved external symbol "struct tesseract::ParamsVectors * __cdecl GlobalParams(void)" (?GlobalParams@@YAPAUParamsVectors@tesseract@@XZ)
common_training.lib(commandlineflags.obj) : error LNK2001: unresolved external symbol "struct tesseract::ParamsVectors * __cdecl GlobalParams(void)" (?GlobalParams@@YAPAUParamsVectors@tesseract@@XZ)
text2image.obj : error LNK2019: unresolved external symbol "public: __thiscall UNICHARSET::UNICHARSET(void)" (??0UNICHARSET@@QAE@XZ) referenced in function _main
...

tesseract.exe was built and work fine.
text2image project has references on tesseract project and dependencies from ..\Debug\tesseract305d.lib This is a known issue. See https://github.com/tesseract-ocr/tesseract/pull/595#issuecomment-268362325 This issue is about Leptonica and other libs, but in my case problem seems is with resolving symbols from tesseract main library that itself built fine, Not only in text2image but also in other Training Tools, for example ambiguous_words:

ambiguous_words.obj : error LNK2019: unresolved external symbol "public: __thiscall WERD_CHOICE::WERD_CHOICE(char const *,class UNICHARSET const &)" (??0WERD_CHOICE@@QAE@PBDABVUNICHARSET@@@Z) referenced in function _main
ambiguous_words.obj : error LNK2019: unresolved external symbol "public: __thiscall WERD_CHOICE::~WERD_CHOICE(void)" (??1WERD_CHOICE@@QAE@XZ) referenced in function _main
ambiguous_words.obj : error LNK2019: unresolved external symbol "public: bool __thiscall tesseract::Dict::NoDangerousAmbig(class WERD_CHOICE *,class GenericVector<struct DANGERR_INFO> *,bool,class MATRIX *)" (?NoDangerousAmbig@Dict@tesseract@@QAE_NPAVWERD_CHOICE@@PAV?$GenericVector@UDANGERR_INFO@@@@_NPAVMATRIX@@@Z) referenced in function _main
 There is some other details. To make cmake work I download gtk+ from 
https://dl.hexchat.net/gtk-win32/vc14/x86/gtk-Win32.7z
set PKG_CONFIG_PATH=D:/gtk/win32/lib/pkgconfig
after cmake I also add paths 
D:\gtk\Win32\include
and
D:\gtk\Win32\lib
in text2image project I am using last sources from github from master Really, I have 3.6.2, I will try 3.7.1. Thank you. Great! It was built. Thanks again.  ```
(gdb) run
Starting program: /usr/local/bin/tesseract phototest.tif phototest -l eng
warning: Error disabling address space randomization: Success
warning: linux_ptrace_test_ret_to_nx: PTRACE_KILL waitpid returned -1: Interrupted system call
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Tesseract Open Source OCR Engine v4.00.00alpha-221-g34e4003 with Leptonica
Page 1
[New Thread 0x7fd8a83a0700 (LWP 17843)]
[New Thread 0x7fd8a5e20700 (LWP 17844)]
[New Thread 0x7fd8a5610700 (LWP 17845)]
Found AVX
Found SSE
DotProductAVX can't be used on Android
DotProductAVX can't be used on Android

Program received signal SIGABRT, Aborted.
0x00007fd8a9aa6c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
56      ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.
(gdb) backtrace
#0  0x00007fd8a9aa6c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
#1  0x00007fd8a9aaa028 in __GI_abort () at abort.c:89
#2  0x00007fd8aa9f5e86 in tesseract::DotProductAVX (u=<optimized out>, v=<optimized out>, n=<optimized out>) at dotproductavx.cpp:30
#3  0x00007fd8aaa30a5a in tesseract::WeightMatrix::MatrixDotVectorInternal (w=..., add_bias_fwd=add_bias_fwd@entry=true, skip_bias_back=skip_bias_back@entry=false,
    u=u@entry=0x33e3430, v=v@entry=0x33e3370) at weightmatrix.cpp:435
#4  0x00007fd8aaa30aea in tesseract::WeightMatrix::MatrixDotVector (this=this@entry=0x22196e8, u=u@entry=0x33e3430, v=v@entry=0x33e3370) at weightmatrix.cpp:235
#5  0x00007fd8aa9f9cdc in tesseract::FullyConnected::ForwardTimeStep (this=this@entry=0x22196a0, d_input=0x33e3430, i_input=<optimized out>, t=t@entry=0,
    output_line=output_line@entry=0x33e3370) at fullyconnected.cpp:180
#6  0x00007fd8aa9fa667 in tesseract::FullyConnected::Forward () at fullyconnected.cpp:141
#7  0x00007fd8aa9fbe01 in tesseract::FullyConnected::Forward (this=0x22196a0, debug=<optimized out>, input=..., input_transpose=<optimized out>, scratch=0x2208908,
    output=0x3086ad0) at fullyconnected.cpp:123
#8  0x00007fd8aaa2c30c in tesseract::Series::Forward (this=0x2219500, debug=<optimized out>, input=..., input_transpose=0x0, scratch=0x2208908, output=0x3086ad0)
    at series.cpp:107
#9  0x00007fd8aaa2c30c in tesseract::Series::Forward (this=0x2219350, debug=<optimized out>, input=..., input_transpose=0x0, scratch=0x2208908, output=0x7ffff3028a70)
    at series.cpp:107
#10 0x00007fd8aaa0b25b in tesseract::LSTMRecognizer::RecognizeLine (this=this@entry=0x22084e0, image_data=..., invert=invert@entry=true, debug=debug@entry=false,
    re_invert=re_invert@entry=false, label_threshold=label_threshold@entry=0.75, scale_factor=scale_factor@entry=0x7ffff3028a0c, inputs=inputs@entry=0x7ffff3028b00,
    outputs=outputs@entry=0x7ffff3028a70) at lstmrecognizer.cpp:277
#11 0x00007fd8aaa0d136 in tesseract::LSTMRecognizer::RecognizeLine (this=0x22084e0, image_data=..., invert=invert@entry=true, debug=false,
    worst_dict_cert=worst_dict_cert@entry=-3.5714285373687744, use_alternates=<optimized out>, target_unicharset=target_unicharset@entry=0x21cfc60, line_box=...,
    score_ratio=score_ratio@entry=2, one_word=one_word@entry=false, words=words@entry=0x7ffff3028d30) at lstmrecognizer.cpp:153
#12 0x00007fd8aa8b28f3 in tesseract::Tesseract::LSTMRecognizeWord (this=this@entry=0x21cfb70, block=..., row=row@entry=0x2fca520, word=<optimized out>,
    words=words@entry=0x7ffff3028d30) at linerec.cpp:245
#13 0x00007fd8aa897f03 in tesseract::Tesseract::classify_word_pass1 (this=0x21cfb70, word_data=..., in_word=0x2fdf7e0, out_words=0x7ffff3028d30) at control.cpp:1362
#14 0x00007fd8aa899240 in tesseract::Tesseract::RetryWithLanguage (this=0x21cfb70, word_data=..., recognizer=
    (void (tesseract::Tesseract::*)(tesseract::Tesseract * const, const tesseract::WordData &, WERD_RES **, tesseract::PointerVector<WERD_RES> *)) 0x7fd8aa897d40 <tess
eract::Tesseract::classify_word_pass1(tesseract::WordData const&, WERD_RES**, tesseract::PointerVector<WERD_RES>*)>, in_word=0x2fdf7e0,
    best_words=best_words@entry=0x7ffff3028df0) at control.cpp:888
#15 0x00007fd8aa899959 in tesseract::Tesseract::classify_word_and_language (this=this@entry=0x21cfb70, pass_n=pass_n@entry=1, pr_it=pr_it@entry=0x7ffff3028f50,
    word_data=word_data@entry=0x2fdf5d8) at control.cpp:1303
#16 0x00007fd8aa89d92b in tesseract::Tesseract::RecogAllWordsPassN (this=this@entry=0x21cfb70, pass_n=pass_n@entry=1, monitor=monitor@entry=0x0,
    pr_it=pr_it@entry=0x7ffff3028f50, words=words@entry=0x7ffff3028f30) at control.cpp:265
#17 0x00007fd8aa89e6b3 in tesseract::Tesseract::recog_all_words (this=0x21cfb70, page_res=0x2fad7b0, monitor=monitor@entry=0x0,
    target_word_box=target_word_box@entry=0x0, word_config=word_config@entry=0x0, dopasses=dopasses@entry=0) at control.cpp:352
#18 0x00007fd8aa887359 in tesseract::TessBaseAPI::Recognize (this=this@entry=0x7ffff3029380, monitor=0x0) at baseapi.cpp:852
#19 0x00007fd8aa8876fd in tesseract::TessBaseAPI::ProcessPage (this=this@entry=0x7ffff3029380, pix=0x22069a0, page_index=page_index@entry=0,
    filename=filename@entry=0x7ffff3029739 "phototest.tif", retry_config=retry_config@entry=0x0, timeout_millisec=timeout_millisec@entry=0, renderer=renderer@entry=
    0x2e70640) at baseapi.cpp:1164
#20 0x00007fd8aa887cc9 in tesseract::TessBaseAPI::ProcessPagesMultipageTiff (this=this@entry=0x7ffff3029380, data=data@entry=0x0, size=0,
    filename=filename@entry=0x7ffff3029739 "phototest.tif", retry_config=retry_config@entry=0x0, timeout_millisec=timeout_millisec@entry=0,
    renderer=renderer@entry=0x2e70640, tessedit_page_number=-1) at baseapi.cpp:1010
#21 0x00007fd8aa888018 in tesseract::TessBaseAPI::ProcessPagesInternal (this=this@entry=0x7ffff3029380, filename=<optimized out>,
---Type <return> to continue, or q <return> to quit---

``` I had commented the following 2 lines in configure.ac for tesseract to build

```
## Checks for supported compiler options.
AM_CONDITIONAL([AVX_OPT], false)
AM_CONDITIONAL([SSE41_OPT], false)
##AX_CHECK_COMPILE_FLAG([-mavx], [avx=1], [avx=0])
##AX_CHECK_COMPILE_FLAG([-msse4.1], [sse41=1], [sse41=0])
``` I reset git to an older commit. Now it works.

```
shree@ALL-IN-1-TOUCH:/mnt/c/Users/User/shree/tesseract/testing$ tesseract phototest.tif phototest -l eng
Tesseract Open Source OCR Engine v4.00.00alpha-139-g13e46ae with Leptonica
Page 1
Found AVX
Found SSE
```
 I am able to build 

 tesseract -v
tesseract 4.00.00alpha-204-g8b3c6ac
 leptonica-1.74
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

The latest snapshot does not build on same pc.  >I had commented the following 2 lines in configure.ac for tesseract to build

Give us the compilation output as file(s) attachment(s). If you do have avx and sse4.1 and the new code in configure.ac fails to discover it, you can fix it like this:

```
## Checks for supported compiler options.
AM_CONDITIONAL([AVX_OPT], true)
AM_CONDITIONAL([SSE41_OPT], true)
#AX_CHECK_COMPILE_FLAG([-mavx], [avx=1], [avx=0])
#AX_CHECK_COMPILE_FLAG([-msse4.1], [sse41=1], [sse41=0])
#if test x$avx = x1; then
#    AM_CONDITIONAL([AVX_OPT], true)
#fi
#if test x$sse41 = x1; then
#    AM_CONDITIONAL([SSE41_OPT], true)
#fi
``` It works after installing autoconf-archive as suggested by @zdenop  I am getting the same error running tesseract on Windows 10.
How should I run autoconf-archive on Windows?
Looks like there is a preprocessor directive to always throw this error on i386 architecture.
How should I fix this error on Windows? Same error is coming on running tesseract on ubuntu 16.04.someone please help.its urgent Hello sir,

Sorry for the inconvenience caused.I will not repeat my mistake.I have
installed tesseract on Ubuntu
16.04 32 bit os with the help of this site.
https://www.linux.com/blog/using-tesseract-ubuntu

Yes I can use tesseract 3.05 but i would you be highly obliged if you would
tell me the steps of properly uninstalling tesseract. And from where to
install tesseract 3.05 and which leptonica version to use.

Thank You for your help and guidance

Regards:
Vidushi Gupta
Student(M.Tech)(NSIT Delhi)

On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com>
wrote:

> @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> question on several places (even if it is urgent for you).
>
> Did you compile Tesseract yourself or do you use a pre-build version? Can
> you use Tesseract 3.05 or an earlier version? Tesseract 4.x is experimental
> and not for end users currently.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282265686>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 Use the ppa from https://launchpad.net/~alex-p/+archive/ubuntu/tesseract-ocr

sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
sudo apt-get update -q
sudo apt-get install tesseract-ocr -y


tesseract -v
tesseract --list-langs


sudo apt-get install tesseract-ocr-hin   -y
(if you want to install Hindi, similarly for other languages)

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com> wrote:

> Hello sir,
>
> Sorry for the inconvenience caused.I will not repeat my mistake.I have
> installed tesseract on Ubuntu
> 16.04 32 bit os with the help of this site.
> https://www.linux.com/blog/using-tesseract-ubuntu
>
> Yes I can use tesseract 3.05 but i would you be highly obliged if you would
> tell me the steps of properly uninstalling tesseract. And from where to
> install tesseract 3.05 and which leptonica version to use.
>
> Thank You for your help and guidance
>
> Regards:
> Vidushi Gupta
> Student(M.Tech)(NSIT Delhi)
>
> On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com>
> wrote:
>
> > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> > question on several places (even if it is urgent for you).
> >
> > Did you compile Tesseract yourself or do you use a pre-build version? Can
> > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> experimental
> > and not for end users currently.
> >
> > ‚Äî
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282265686>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-
> auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > .
> >
>
>
>
> --
> Vidushi
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282298890>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> .
>
 But how to uninstall the already installed tesseract and liptonica .These
two i have installed from source

On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <notifications@github.com>
wrote:

> Use the ppa from https://launchpad.net/~alex-p/
> +archive/ubuntu/tesseract-ocr
>
> sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> sudo apt-get update -q
> sudo apt-get install tesseract-ocr -y
>
>
> tesseract -v
> tesseract --list-langs
>
>
> sudo apt-get install tesseract-ocr-hin -y
> (if you want to install Hindi, similarly for other languages)
>
> ShreeDevi
> ____________________________________________________________
> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>
> On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
> wrote:
>
> > Hello sir,
> >
> > Sorry for the inconvenience caused.I will not repeat my mistake.I have
> > installed tesseract on Ubuntu
> > 16.04 32 bit os with the help of this site.
> > https://www.linux.com/blog/using-tesseract-ubuntu
> >
> > Yes I can use tesseract 3.05 but i would you be highly obliged if you
> would
> > tell me the steps of properly uninstalling tesseract. And from where to
> > install tesseract 3.05 and which leptonica version to use.
> >
> > Thank You for your help and guidance
> >
> > Regards:
> > Vidushi Gupta
> > Student(M.Tech)(NSIT Delhi)
> >
> > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com>
> > wrote:
> >
> > > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> > > question on several places (even if it is urgent for you).
> > >
> > > Did you compile Tesseract yourself or do you use a pre-build version?
> Can
> > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > experimental
> > > and not for end users currently.
> > >
> > > ‚Äî
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282265686>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-
> > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > .
> > >
> >
> >
> >
> > --
> > Vidushi
> >
> > ‚Äî
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282298890>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_
> o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
>
> > .
> >
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282312789>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 Thank you for your help n support

On 24 Feb 2017 20:36, "Shreeshrii" <notifications@github.com> wrote:

> See the shell scripts in https://github.com/Shreeshrii/tess4eval_marathi
>
> you can change 4.0 by the 3.05 versions
>
> ShreeDevi
> ____________________________________________________________
> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>
> On Fri, Feb 24, 2017 at 8:31 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
> wrote:
>
> > Use the ppa from https://launchpad.net/~alex-p/+archive/ubuntu/
> > tesseract-ocr
> >
> > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > sudo apt-get update -q
> > sudo apt-get install tesseract-ocr -y
> >
> >
> > tesseract -v
> > tesseract --list-langs
> >
> >
> > sudo apt-get install tesseract-ocr-hin -y
> > (if you want to install Hindi, similarly for other languages)
> >
> > ShreeDevi
> > ____________________________________________________________
> > ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
> >
> > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
> > wrote:
> >
> >> Hello sir,
> >>
> >> Sorry for the inconvenience caused.I will not repeat my mistake.I have
> >> installed tesseract on Ubuntu
> >> 16.04 32 bit os with the help of this site.
> >> https://www.linux.com/blog/using-tesseract-ubuntu
> >>
> >> Yes I can use tesseract 3.05 but i would you be highly obliged if you
> >> would
> >> tell me the steps of properly uninstalling tesseract. And from where to
> >> install tesseract 3.05 and which leptonica version to use.
> >>
> >> Thank You for your help and guidance
> >>
> >> Regards:
> >> Vidushi Gupta
> >> Student(M.Tech)(NSIT Delhi)
> >>
> >> On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com>
> >> wrote:
> >>
> >> > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> >> > question on several places (even if it is urgent for you).
> >> >
> >> > Did you compile Tesseract yourself or do you use a pre-build version?
> >> Can
> >> > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> >> experimental
> >> > and not for end users currently.
> >> >
> >> > ‚Äî
> >> > You are receiving this because you were mentioned.
> >> > Reply to this email directly, view it on GitHub
> >> > <https://github.com/tesseract-ocr/tesseract/issues/610#issue
> >> comment-282265686>,
> >> > or mute the thread
> >> > <https://github.com/notifications/unsubscribe-auth/
> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> >> > .
> >> >
> >>
> >>
> >>
> >> --
> >> Vidushi
> >>
> >> ‚Äî
> >> You are receiving this because you authored the thread.
> >> Reply to this email directly, view it on GitHub
> >> <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282298890>,
> >> or mute the thread
> >> <https://github.com/notifications/unsubscribe-auth/AE2_
> o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> >> .
> >>
> >
> >
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282313481>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm3ECVBAY1kTVCX5pcrNj2WLlWwq9ks5rfvHagaJpZM4LVjQA>
> .
>
 But is there a way so that I could resolve my original problem?
On command prompt when i am typing

 tesseract img.PNG out

It is giving error as ---
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
DotProductAVX can't be used on Android
Aborted (core dumped)






On Fri, Feb 24, 2017 at 8:48 PM, Vidushi Gupta <vidushigupta2004@gmail.com>
wrote:

> Thank you for your help n support
>
> On 24 Feb 2017 20:36, "Shreeshrii" <notifications@github.com> wrote:
>
>> See the shell scripts in https://github.com/Shreeshrii/tess4eval_marathi
>>
>> you can change 4.0 by the 3.05 versions
>>
>> ShreeDevi
>> ____________________________________________________________
>> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>>
>> On Fri, Feb 24, 2017 at 8:31 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
>> wrote:
>>
>> > Use the ppa from https://launchpad.net/~alex-p/+archive/ubuntu/
>> > tesseract-ocr
>> >
>> > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
>> > sudo apt-get update -q
>> > sudo apt-get install tesseract-ocr -y
>> >
>> >
>> > tesseract -v
>> > tesseract --list-langs
>> >
>> >
>> > sudo apt-get install tesseract-ocr-hin -y
>> > (if you want to install Hindi, similarly for other languages)
>> >
>> > ShreeDevi
>> > ____________________________________________________________
>> > ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>> >
>> > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
>> > wrote:
>> >
>> >> Hello sir,
>> >>
>> >> Sorry for the inconvenience caused.I will not repeat my mistake.I have
>> >> installed tesseract on Ubuntu
>> >> 16.04 32 bit os with the help of this site.
>> >> https://www.linux.com/blog/using-tesseract-ubuntu
>> >>
>> >> Yes I can use tesseract 3.05 but i would you be highly obliged if you
>> >> would
>> >> tell me the steps of properly uninstalling tesseract. And from where to
>> >> install tesseract 3.05 and which leptonica version to use.
>> >>
>> >> Thank You for your help and guidance
>> >>
>> >> Regards:
>> >> Vidushi Gupta
>> >> Student(M.Tech)(NSIT Delhi)
>> >>
>> >> On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com
>> >
>> >> wrote:
>> >>
>> >> > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
>> >> > question on several places (even if it is urgent for you).
>> >> >
>> >> > Did you compile Tesseract yourself or do you use a pre-build version?
>> >> Can
>> >> > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
>> >> experimental
>> >> > and not for end users currently.
>> >> >
>> >> > ‚Äî
>> >> > You are receiving this because you were mentioned.
>> >> > Reply to this email directly, view it on GitHub
>> >> > <https://github.com/tesseract-ocr/tesseract/issues/610#issue
>> >> comment-282265686>,
>> >> > or mute the thread
>> >> > <https://github.com/notifications/unsubscribe-auth/
>> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
>> >> > .
>> >> >
>> >>
>> >>
>> >>
>> >> --
>> >> Vidushi
>> >>
>> >> ‚Äî
>> >> You are receiving this because you authored the thread.
>> >> Reply to this email directly, view it on GitHub
>> >> <https://github.com/tesseract-ocr/tesseract/issues/610#issue
>> comment-282298890>,
>> >> or mute the thread
>> >> <https://github.com/notifications/unsubscribe-auth/AE2_o1gQT
>> wf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
>> >> .
>> >>
>> >
>> >
>>
>> ‚Äî
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282313481>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AOjjm3ECVBAY1kTVCX5pcrNj2WLlWwq9ks5rfvHagaJpZM4LVjQA>
>> .
>>
>


-- 
Vidushi
 oks.
Thank You for your help and guidance

Regards
Vidushi

On Fri, Feb 24, 2017 at 9:59 PM, Shreeshrii <notifications@github.com>
wrote:

> You have cloned the master branch, which is not the released code, it is
> actively under development.
>
> What commit have you used?
>
> You can use Git log to display the status.
>
> As suggested by Stefan you should try the 3.05 branch.
>
> - excuse the brevity, sent from mobile
>
>
> On 24-Feb-2017 9:33 PM, "Vidushi12" <notifications@github.com> wrote:
>
> > But is there a way so that I could resolve my original problem?
> > On command prompt when i am typing
> >
> > tesseract img.PNG out
> >
> > It is giving error as ---
> > Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
> > DotProductAVX can't be used on Android
> > Aborted (core dumped)
> >
> >
> >
> >
> >
> >
> > On Fri, Feb 24, 2017 at 8:48 PM, Vidushi Gupta <
> vidushigupta2004@gmail.com
> > >
> > wrote:
> >
> > > Thank you for your help n support
> > >
> > > On 24 Feb 2017 20:36, "Shreeshrii" <notifications@github.com> wrote:
> > >
> > >> See the shell scripts in https://github.com/Shreeshrii/
> > tess4eval_marathi
> > >>
> > >> you can change 4.0 by the 3.05 versions
> > >>
> > >> ShreeDevi
> > >> ____________________________________________________________
> > >> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
> > >>
> > >> On Fri, Feb 24, 2017 at 8:31 PM, ShreeDevi Kumar <
> shreeshrii@gmail.com>
> > >> wrote:
> > >>
> > >> > Use the ppa from https://launchpad.net/~alex-p/+archive/ubuntu/
> > >> > tesseract-ocr
> > >> >
> > >> > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > >> > sudo apt-get update -q
> > >> > sudo apt-get install tesseract-ocr -y
> > >> >
> > >> >
> > >> > tesseract -v
> > >> > tesseract --list-langs
> > >> >
> > >> >
> > >> > sudo apt-get install tesseract-ocr-hin -y
> > >> > (if you want to install Hindi, similarly for other languages)
> > >> >
> > >> > ShreeDevi
> > >> > ____________________________________________________________
> > >> > ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
> > >> >
> > >> > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <
> notifications@github.com>
> > >> > wrote:
> > >> >
> > >> >> Hello sir,
> > >> >>
> > >> >> Sorry for the inconvenience caused.I will not repeat my mistake.I
> > have
> > >> >> installed tesseract on Ubuntu
> > >> >> 16.04 32 bit os with the help of this site.
> > >> >> https://www.linux.com/blog/using-tesseract-ubuntu
> > >> >>
> > >> >> Yes I can use tesseract 3.05 but i would you be highly obliged if
> you
> > >> >> would
> > >> >> tell me the steps of properly uninstalling tesseract. And from
> where
> > to
> > >> >> install tesseract 3.05 and which leptonica version to use.
> > >> >>
> > >> >> Thank You for your help and guidance
> > >> >>
> > >> >> Regards:
> > >> >> Vidushi Gupta
> > >> >> Student(M.Tech)(NSIT Delhi)
> > >> >>
> > >> >> On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <
> > notifications@github.com
> > >> >
> > >> >> wrote:
> > >> >>
> > >> >> > @Vidushi12 <https://github.com/Vidushi12>, please don't post
> your
> > >> >> > question on several places (even if it is urgent for you).
> > >> >> >
> > >> >> > Did you compile Tesseract yourself or do you use a pre-build
> > version?
> > >> >> Can
> > >> >> > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > >> >> experimental
> > >> >> > and not for end users currently.
> > >> >> >
> > >> >> > ‚Äî
> > >> >> > You are receiving this because you were mentioned.
> > >> >> > Reply to this email directly, view it on GitHub
> > >> >> > <https://github.com/tesseract-ocr/tesseract/issues/610#issue
> > >> >> comment-282265686>,
> > >> >> > or mute the thread
> > >> >> > <https://github.com/notifications/unsubscribe-auth/
> > >> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > >> >> > .
> > >> >> >
> > >> >>
> > >> >>
> > >> >>
> > >> >> --
> > >> >> Vidushi
> > >> >>
> > >> >> ‚Äî
> > >> >> You are receiving this because you authored the thread.
> > >> >> Reply to this email directly, view it on GitHub
> > >> >> <https://github.com/tesseract-ocr/tesseract/issues/610#issue
> > >> comment-282298890>,
> > >> >> or mute the thread
> > >> >> <https://github.com/notifications/unsubscribe-auth/AE2_o1gQT
> > >> wf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> > >> >> .
> > >> >>
> > >> >
> > >> >
> > >>
> > >> ‚Äî
> > >> You are receiving this because you were mentioned.
> > >> Reply to this email directly, view it on GitHub
> > >> <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282313481>,
> > >> or mute the thread
> > >> <https://github.com/notifications/unsubscribe-auth/
> > AOjjm3ECVBAY1kTVCX5pcrNj2WLlWwq9ks5rfvHagaJpZM4LVjQA>
> > >> .
> > >>
> > >
> >
> >
> > --
> > Vidushi
> >
> > ‚Äî
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282328731>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_
> o4wbSjXcxEL120X1ERZGrmJ2a1HZks5rfv89gaJpZM4LVjQA>
>
> > .
> >
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282335846>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm5J_xrzVrVyHLO_qv05zmiDBJy_nks5rfwVUgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 Last thing i want to know ... can we use .png, .jpeg with 3.05 version of
tesseract ? On some sites it is written tesseract 4.0 version only works
with png file.

Will tesseract 3.05 version work with leptonica version 1.74?

Regards
Vidushi Gupta

On Fri, Feb 24, 2017 at 11:04 PM, Shreeshrii <notifications@github.com>
wrote:

> https://github.com/tesseract-ocr/tesseract/releases/tag/3.05.00
>
> Use the source from the zip/tar file
>
> - excuse the brevity, sent from mobile
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282353146>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm5xy0MycRfFhg9piC99w7mVXQ_LTks5rfxTBgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 3.05 should work with leptonica 1.74.

It will work with png, jpeg etc, depending on the libs installed

tesseract -v

Should show u the info.

4.0 is using a new OCR engine, LSTM.



- excuse the brevity, sent from mobile

On 24-Feb-2017 11:12 PM, "Vidushi12" <notifications@github.com> wrote:

> Last thing i want to know ... can we use .png, .jpeg with 3.05 version of
> tesseract ? On some sites it is written tesseract 4.0 version only works
> with png file.
>
> Will tesseract 3.05 version work with leptonica version 1.74?
>
> Regards
> Vidushi Gupta
>
> On Fri, Feb 24, 2017 at 11:04 PM, Shreeshrii <notifications@github.com>
> wrote:
>
> > https://github.com/tesseract-ocr/tesseract/releases/tag/3.05.00
> >
> > Use the source from the zip/tar file
> >
> > - excuse the brevity, sent from mobile
> >
> > ‚Äî
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282353146>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AOjjm5xy0MycRfFhg9piC99w7mVXQ_LTks5rfxTBgaJpZM4LVjQA>
> > .
> >
>
>
>
> --
> Vidushi
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282355013>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o7wPCmXb4EWJ7LWH_TZnLTsJ4dBtks5rfxZvgaJpZM4LVjQA>
> .
>
 See
https://github.com/tesseract-ocr/tesseract/wiki/Command-Line-Usage

The info was written for 3.04 and should apply to 3.05
- excuse the brevity, sent from mobile

On 24-Feb-2017 11:12 PM, "Vidushi12" <notifications@github.com> wrote:

> Last thing i want to know ... can we use .png, .jpeg with 3.05 version of
> tesseract ? On some sites it is written tesseract 4.0 version only works
> with png file.
>
> Will tesseract 3.05 version work with leptonica version 1.74?
>
> Regards
> Vidushi Gupta
>
> On Fri, Feb 24, 2017 at 11:04 PM, Shreeshrii <notifications@github.com>
> wrote:
>
> > https://github.com/tesseract-ocr/tesseract/releases/tag/3.05.00
> >
> > Use the source from the zip/tar file
> >
> > - excuse the brevity, sent from mobile
> >
> > ‚Äî
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282353146>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AOjjm5xy0MycRfFhg9piC99w7mVXQ_LTks5rfxTBgaJpZM4LVjQA>
> > .
> >
>
>
>
> --
> Vidushi
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282355013>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o7wPCmXb4EWJ7LWH_TZnLTsJ4dBtks5rfxZvgaJpZM4LVjQA>
> .
>
 i need only english language.but now the problm i m facing is how to
uninstall it....i have build tesseract from source.

On 24 Feb 2017 23:32, "Stefan Weil" <notifications@github.com> wrote:

> @Vidushi12 <https://github.com/Vidushi12>, I suggest to use the Tesseract
> provided by Ubuntu and don't build it yourself. Just run apt-get install
> tesseract-ocr tesseract-ocr-eng (add more languages as needed) as root
> user.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282360195>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjmxwoJYavRXWwDznBRCPIqAT92bkbks5rfxs5gaJpZM4LVjQA>
> .
>
 So i just need to delete tesseract file from usr/local/bin folder . After
that i will again install tesseract using the command apt-get install
tesseract-ocr tesseract-ocr-eng .

On Sat, Feb 25, 2017 at 12:05 AM, Stefan Weil <notifications@github.com>
wrote:

> You can either remove /usr/local/bin/tesseract, or don't uninstall it and
> call /usr/bin/tesseract explicitly.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282368238>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm5Gz1Gb4vGh3tkwYuotKHYcI_41Yks5rfyLYgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 ok
thank you sir for your help and support

On 25 Feb 2017 15:44, "Stefan Weil" <notifications@github.com> wrote:

> Yes, that's it.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282474563>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm_fTM8I4UGbrm2Og8AKefKgUwQhoks5rf_8QgaJpZM4LVjQA>
> .
>
 I followed the above commands. And when i try to compile the code it is
giving error as-

 fatal error: tesseract/baseapi.h: No such file or directory
compilation terminated.

For compilation i wrote the command

 g++ simple.cpp -o sim -l/usr/include/leptonica -l/usr/bin/tesseract -llept
-ltesseract

Please tell what could be the problem

Regards
Vidushi


On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <notifications@github.com>
wrote:

> Use the ppa from https://launchpad.net/~alex-p/
> +archive/ubuntu/tesseract-ocr
>
> sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> sudo apt-get update -q
> sudo apt-get install tesseract-ocr -y
>
>
> tesseract -v
> tesseract --list-langs
>
>
> sudo apt-get install tesseract-ocr-hin -y
> (if you want to install Hindi, similarly for other languages)
>
> ShreeDevi
> ____________________________________________________________
> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>
> On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
> wrote:
>
> > Hello sir,
> >
> > Sorry for the inconvenience caused.I will not repeat my mistake.I have
> > installed tesseract on Ubuntu
> > 16.04 32 bit os with the help of this site.
> > https://www.linux.com/blog/using-tesseract-ubuntu
> >
> > Yes I can use tesseract 3.05 but i would you be highly obliged if you
> would
> > tell me the steps of properly uninstalling tesseract. And from where to
> > install tesseract 3.05 and which leptonica version to use.
> >
> > Thank You for your help and guidance
> >
> > Regards:
> > Vidushi Gupta
> > Student(M.Tech)(NSIT Delhi)
> >
> > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com>
> > wrote:
> >
> > > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> > > question on several places (even if it is urgent for you).
> > >
> > > Did you compile Tesseract yourself or do you use a pre-build version?
> Can
> > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > experimental
> > > and not for end users currently.
> > >
> > > ‚Äî
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282265686>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-
> > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > .
> > >
> >
> >
> >
> > --
> > Vidushi
> >
> > ‚Äî
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282298890>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_
> o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
>
> > .
> >
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282312789>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 sir i followed the steps but when i try to compile code it gives error.
tesseract/baseapi.h: No such file or directory


On Sat, Feb 25, 2017 at 3:46 PM, Vidushi Gupta <vidushigupta2004@gmail.com>
wrote:

> ok
> thank you sir for your help and support
>
> On 25 Feb 2017 15:44, "Stefan Weil" <notifications@github.com> wrote:
>
>> Yes, that's it.
>>
>> ‚Äî
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282474563>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AOjjm_fTM8I4UGbrm2Og8AKefKgUwQhoks5rf_8QgaJpZM4LVjQA>
>> .
>>
>


-- 
Vidushi
 ‚Äãapt-get install installs the program.

you dont need to compile it.

give the following commands to see what you have.

which tesseract

tesseract -v

tesseract --help

tesseract --list-langs‚Äã

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Mon, Feb 27, 2017 at 3:22 PM, Vidushi12 <notifications@github.com> wrote:

> I followed the above commands. And when i try to compile the code it is
> giving error as-
>
> fatal error: tesseract/baseapi.h: No such file or directory
> compilation terminated.
>
> For compilation i wrote the command
>
> g++ simple.cpp -o sim -l/usr/include/leptonica -l/usr/bin/tesseract -llept
> -ltesseract
>
> Please tell what could be the problem
>
> Regards
> Vidushi
>
>
> On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <notifications@github.com>
> wrote:
>
> > Use the ppa from https://launchpad.net/~alex-p/
> > +archive/ubuntu/tesseract-ocr
> >
> > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > sudo apt-get update -q
> > sudo apt-get install tesseract-ocr -y
> >
> >
> > tesseract -v
> > tesseract --list-langs
> >
> >
> > sudo apt-get install tesseract-ocr-hin -y
> > (if you want to install Hindi, similarly for other languages)
> >
> > ShreeDevi
> > ____________________________________________________________
> > ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
> >
> > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
> > wrote:
> >
> > > Hello sir,
> > >
> > > Sorry for the inconvenience caused.I will not repeat my mistake.I have
> > > installed tesseract on Ubuntu
> > > 16.04 32 bit os with the help of this site.
> > > https://www.linux.com/blog/using-tesseract-ubuntu
> > >
> > > Yes I can use tesseract 3.05 but i would you be highly obliged if you
> > would
> > > tell me the steps of properly uninstalling tesseract. And from where to
> > > install tesseract 3.05 and which leptonica version to use.
> > >
> > > Thank You for your help and guidance
> > >
> > > Regards:
> > > Vidushi Gupta
> > > Student(M.Tech)(NSIT Delhi)
> > >
> > > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com
> >
> > > wrote:
> > >
> > > > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> > > > question on several places (even if it is urgent for you).
> > > >
> > > > Did you compile Tesseract yourself or do you use a pre-build version?
> > Can
> > > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > > experimental
> > > > and not for end users currently.
> > > >
> > > > ‚Äî
> > > > You are receiving this because you were mentioned.
> > > > Reply to this email directly, view it on GitHub
> > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > issuecomment-282265686>,
> > > > or mute the thread
> > > > <https://github.com/notifications/unsubscribe-
> > > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > > .
> > > >
> > >
> > >
> > >
> > > --
> > > Vidushi
> > >
> > > ‚Äî
> > > You are receiving this because you authored the thread.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282298890>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/AE2_
> > o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> >
> > > .
> > >
> >
> > ‚Äî
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282312789>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> > .
> >
>
>
>
> --
> Vidushi
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282674708>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o9-Q81fTzwHqZPg8gEZHrUzA9hVoks5rgpzJgaJpZM4LVjQA>
> .
>
 i was trying to run this code


http://8086892010.blogspot.in/2013/08/read-scanned-pdf-line-by-line-using.html

On Mon, Feb 27, 2017 at 4:12 PM, Shreeshrii <notifications@github.com>
wrote:

> ‚Äãapt-get install installs the program.
>
> you dont need to compile it.
>
> give the following commands to see what you have.
>
> which tesseract
>
> tesseract -v
>
> tesseract --help
>
> tesseract --list-langs‚Äã
>
> ShreeDevi
> ____________________________________________________________
> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>
> On Mon, Feb 27, 2017 at 3:22 PM, Vidushi12 <notifications@github.com>
> wrote:
>
> > I followed the above commands. And when i try to compile the code it is
> > giving error as-
> >
> > fatal error: tesseract/baseapi.h: No such file or directory
> > compilation terminated.
> >
> > For compilation i wrote the command
> >
> > g++ simple.cpp -o sim -l/usr/include/leptonica -l/usr/bin/tesseract
> -llept
> > -ltesseract
> >
> > Please tell what could be the problem
> >
> > Regards
> > Vidushi
> >
> >
> > On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <notifications@github.com>
> > wrote:
> >
> > > Use the ppa from https://launchpad.net/~alex-p/
> > > +archive/ubuntu/tesseract-ocr
> > >
> > > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > > sudo apt-get update -q
> > > sudo apt-get install tesseract-ocr -y
> > >
> > >
> > > tesseract -v
> > > tesseract --list-langs
> > >
> > >
> > > sudo apt-get install tesseract-ocr-hin -y
> > > (if you want to install Hindi, similarly for other languages)
> > >
> > > ShreeDevi
> > > ____________________________________________________________
> > > ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
> > >
> > > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
> > > wrote:
> > >
> > > > Hello sir,
> > > >
> > > > Sorry for the inconvenience caused.I will not repeat my mistake.I
> have
> > > > installed tesseract on Ubuntu
> > > > 16.04 32 bit os with the help of this site.
> > > > https://www.linux.com/blog/using-tesseract-ubuntu
> > > >
> > > > Yes I can use tesseract 3.05 but i would you be highly obliged if you
> > > would
> > > > tell me the steps of properly uninstalling tesseract. And from where
> to
> > > > install tesseract 3.05 and which leptonica version to use.
> > > >
> > > > Thank You for your help and guidance
> > > >
> > > > Regards:
> > > > Vidushi Gupta
> > > > Student(M.Tech)(NSIT Delhi)
> > > >
> > > > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <
> notifications@github.com
> > >
> > > > wrote:
> > > >
> > > > > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> > > > > question on several places (even if it is urgent for you).
> > > > >
> > > > > Did you compile Tesseract yourself or do you use a pre-build
> version?
> > > Can
> > > > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > > > experimental
> > > > > and not for end users currently.
> > > > >
> > > > > ‚Äî
> > > > > You are receiving this because you were mentioned.
> > > > > Reply to this email directly, view it on GitHub
> > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > issuecomment-282265686>,
> > > > > or mute the thread
> > > > > <https://github.com/notifications/unsubscribe-
> > > > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > > > .
> > > > >
> > > >
> > > >
> > > >
> > > > --
> > > > Vidushi
> > > >
> > > > ‚Äî
> > > > You are receiving this because you authored the thread.
> > > > Reply to this email directly, view it on GitHub
> > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > issuecomment-282298890>,
> > > > or mute the thread
> > > > <https://github.com/notifications/unsubscribe-auth/AE2_
> > > o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> > >
> > > > .
> > > >
> > >
> > > ‚Äî
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282312789>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/
> > AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> > > .
> > >
> >
> >
> >
> > --
> > Vidushi
> >
> > ‚Äî
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282674708>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_o9-
> Q81fTzwHqZPg8gEZHrUzA9hVoks5rgpzJgaJpZM4LVjQA>
>
> > .
> >
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282686155>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm7TEDa6-rWyrqgSt-qWJywC_7ftiks5rgqiugaJpZM4LVjQA>
> .
>



-- 
Vidushi
 step 2 > g++ test.cpp -o test -I/usr/include/leptonica
-I/usr/local/include/tesseract -llept -ltesseract


you have used  -l/usr/bin/tesseract in your command


ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Mon, Feb 27, 2017 at 5:37 PM, Vidushi12 <notifications@github.com> wrote:

> i was trying to run this code
>
>
> http://8086892010.blogspot.in/2013/08/read-scanned-pdf-line-
> by-line-using.html
>
> On Mon, Feb 27, 2017 at 4:12 PM, Shreeshrii <notifications@github.com>
> wrote:
>
> > ‚Äãapt-get install installs the program.
> >
> > you dont need to compile it.
> >
> > give the following commands to see what you have.
> >
> > which tesseract
> >
> > tesseract -v
> >
> > tesseract --help
> >
> > tesseract --list-langs‚Äã
> >
> > ShreeDevi
> > ____________________________________________________________
> > ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
> >
> > On Mon, Feb 27, 2017 at 3:22 PM, Vidushi12 <notifications@github.com>
> > wrote:
> >
> > > I followed the above commands. And when i try to compile the code it is
> > > giving error as-
> > >
> > > fatal error: tesseract/baseapi.h: No such file or directory
> > > compilation terminated.
> > >
> > > For compilation i wrote the command
> > >
> > > g++ simple.cpp -o sim -l/usr/include/leptonica -l/usr/bin/tesseract
> > -llept
> > > -ltesseract
> > >
> > > Please tell what could be the problem
> > >
> > > Regards
> > > Vidushi
> > >
> > >
> > > On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <notifications@github.com>
> > > wrote:
> > >
> > > > Use the ppa from https://launchpad.net/~alex-p/
> > > > +archive/ubuntu/tesseract-ocr
> > > >
> > > > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > > > sudo apt-get update -q
> > > > sudo apt-get install tesseract-ocr -y
> > > >
> > > >
> > > > tesseract -v
> > > > tesseract --list-langs
> > > >
> > > >
> > > > sudo apt-get install tesseract-ocr-hin -y
> > > > (if you want to install Hindi, similarly for other languages)
> > > >
> > > > ShreeDevi
> > > > ____________________________________________________________
> > > > ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
> > > >
> > > > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com
> >
> > > > wrote:
> > > >
> > > > > Hello sir,
> > > > >
> > > > > Sorry for the inconvenience caused.I will not repeat my mistake.I
> > have
> > > > > installed tesseract on Ubuntu
> > > > > 16.04 32 bit os with the help of this site.
> > > > > https://www.linux.com/blog/using-tesseract-ubuntu
> > > > >
> > > > > Yes I can use tesseract 3.05 but i would you be highly obliged if
> you
> > > > would
> > > > > tell me the steps of properly uninstalling tesseract. And from
> where
> > to
> > > > > install tesseract 3.05 and which leptonica version to use.
> > > > >
> > > > > Thank You for your help and guidance
> > > > >
> > > > > Regards:
> > > > > Vidushi Gupta
> > > > > Student(M.Tech)(NSIT Delhi)
> > > > >
> > > > > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <
> > notifications@github.com
> > > >
> > > > > wrote:
> > > > >
> > > > > > @Vidushi12 <https://github.com/Vidushi12>, please don't post
> your
> > > > > > question on several places (even if it is urgent for you).
> > > > > >
> > > > > > Did you compile Tesseract yourself or do you use a pre-build
> > version?
> > > > Can
> > > > > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > > > > experimental
> > > > > > and not for end users currently.
> > > > > >
> > > > > > ‚Äî
> > > > > > You are receiving this because you were mentioned.
> > > > > > Reply to this email directly, view it on GitHub
> > > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > > issuecomment-282265686>,
> > > > > > or mute the thread
> > > > > > <https://github.com/notifications/unsubscribe-
> > > > > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > > > > .
> > > > > >
> > > > >
> > > > >
> > > > >
> > > > > --
> > > > > Vidushi
> > > > >
> > > > > ‚Äî
> > > > > You are receiving this because you authored the thread.
> > > > > Reply to this email directly, view it on GitHub
> > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > issuecomment-282298890>,
> > > > > or mute the thread
> > > > > <https://github.com/notifications/unsubscribe-auth/AE2_
> > > > o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> > > >
> > > > > .
> > > > >
> > > >
> > > > ‚Äî
> > > > You are receiving this because you were mentioned.
> > > > Reply to this email directly, view it on GitHub
> > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > issuecomment-282312789>,
> > > > or mute the thread
> > > > <https://github.com/notifications/unsubscribe-auth/
> > > AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> > > > .
> > > >
> > >
> > >
> > >
> > > --
> > > Vidushi
> > >
> > > ‚Äî
> > > You are receiving this because you authored the thread.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282674708>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/AE2_o9-
> > Q81fTzwHqZPg8gEZHrUzA9hVoks5rgpzJgaJpZM4LVjQA>
> >
> > > .
> > >
> >
> > ‚Äî
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282686155>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AOjjm7TEDa6-rWyrqgSt-
> qWJywC_7ftiks5rgqiugaJpZM4LVjQA>
> > .
> >
>
>
>
> --
> Vidushi
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282702980>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o7c_Ky2N5toipjWMBnddaBS9UHpyks5rgryNgaJpZM4LVjQA>
> .
>
 Not able to remove tesseract from /usr/local/bin folder.

On Sat, Feb 25, 2017 at 12:05 AM, Stefan Weil <notifications@github.com>
wrote:

> You can either remove /usr/local/bin/tesseract, or don't uninstall it and
> call /usr/bin/tesseract explicitly.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282368238>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm5Gz1Gb4vGh3tkwYuotKHYcI_41Yks5rfyLYgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 HI

Sorry for disturbing again.Yesterday i was trying on my friend's system.It
works fine.But now when i am trying on my system it is giving same error.

DotProductAVX can't be used on Android
Aborted (core dumped)

Is it the problem of the system??
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#m_-8680517930591390332_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <notifications@github.com>
wrote:

> Use the ppa from https://launchpad.net/~alex-p/
> +archive/ubuntu/tesseract-ocr
>
> sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> sudo apt-get update -q
> sudo apt-get install tesseract-ocr -y
>
>
> tesseract -v
> tesseract --list-langs
>
>
> sudo apt-get install tesseract-ocr-hin -y
> (if you want to install Hindi, similarly for other languages)
>
> ShreeDevi
> ____________________________________________________________
> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>
> On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
> wrote:
>
> > Hello sir,
> >
> > Sorry for the inconvenience caused.I will not repeat my mistake.I have
> > installed tesseract on Ubuntu
> > 16.04 32 bit os with the help of this site.
> > https://www.linux.com/blog/using-tesseract-ubuntu
> >
> > Yes I can use tesseract 3.05 but i would you be highly obliged if you
> would
> > tell me the steps of properly uninstalling tesseract. And from where to
> > install tesseract 3.05 and which leptonica version to use.
> >
> > Thank You for your help and guidance
> >
> > Regards:
> > Vidushi Gupta
> > Student(M.Tech)(NSIT Delhi)
> >
> > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com>
> > wrote:
> >
> > > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> > > question on several places (even if it is urgent for you).
> > >
> > > Did you compile Tesseract yourself or do you use a pre-build version?
> Can
> > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > experimental
> > > and not for end users currently.
> > >
> > > ‚Äî
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282265686>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-
> > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > .
> > >
> >
> >
> >
> > --
> > Vidushi
> >
> > ‚Äî
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282298890>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_
> o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
>
> > .
> >
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282312789>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 Can i delete tesseract-ocr from usr/share folder. I am thinking to remove
tesseract completely from ubuntu

On Fri, Feb 24, 2017 at 8:36 PM, Shreeshrii <notifications@github.com>
wrote:

> See the shell scripts in https://github.com/Shreeshrii/tess4eval_marathi
>
> you can change 4.0 by the 3.05 versions
>
> ShreeDevi
> ____________________________________________________________
> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>
> On Fri, Feb 24, 2017 at 8:31 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
>
> wrote:
>
> > Use the ppa from https://launchpad.net/~alex-p/+archive/ubuntu/
> > tesseract-ocr
> >
> > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > sudo apt-get update -q
> > sudo apt-get install tesseract-ocr -y
> >
> >
> > tesseract -v
> > tesseract --list-langs
> >
> >
> > sudo apt-get install tesseract-ocr-hin -y
> > (if you want to install Hindi, similarly for other languages)
> >
> > ShreeDevi
> > ____________________________________________________________
> > ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
> >
> > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
> > wrote:
> >
> >> Hello sir,
> >>
> >> Sorry for the inconvenience caused.I will not repeat my mistake.I have
> >> installed tesseract on Ubuntu
> >> 16.04 32 bit os with the help of this site.
> >> https://www.linux.com/blog/using-tesseract-ubuntu
> >>
> >> Yes I can use tesseract 3.05 but i would you be highly obliged if you
> >> would
> >> tell me the steps of properly uninstalling tesseract. And from where to
> >> install tesseract 3.05 and which leptonica version to use.
> >>
> >> Thank You for your help and guidance
> >>
> >> Regards:
> >> Vidushi Gupta
> >> Student(M.Tech)(NSIT Delhi)
> >>
> >> On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com>
> >> wrote:
> >>
> >> > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> >> > question on several places (even if it is urgent for you).
> >> >
> >> > Did you compile Tesseract yourself or do you use a pre-build version?
> >> Can
> >> > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> >> experimental
> >> > and not for end users currently.
> >> >
> >> > ‚Äî
> >> > You are receiving this because you were mentioned.
> >> > Reply to this email directly, view it on GitHub
> >> > <https://github.com/tesseract-ocr/tesseract/issues/610#issue
> >> comment-282265686>,
> >> > or mute the thread
> >> > <https://github.com/notifications/unsubscribe-auth/
> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> >> > .
> >> >
> >>
> >>
> >>
> >> --
> >> Vidushi
> >>
> >> ‚Äî
> >> You are receiving this because you authored the thread.
> >> Reply to this email directly, view it on GitHub
> >> <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282298890>,
> >> or mute the thread
> >> <https://github.com/notifications/unsubscribe-auth/AE2_
> o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> >> .
> >>
> >
> >
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282313481>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm3ECVBAY1kTVCX5pcrNj2WLlWwq9ks5rfvHagaJpZM4LVjQA>
> .
>



-- 
Vidushi
 After performing the above steps I am still getting the following error

DotProductAVX can't be used on Android
Aborted (core dumped)

I would be highly obliged if you would help me in resolving the issue.

Regards
Vidushi

On Sat, Feb 25, 2017 at 12:05 AM, Stefan Weil <notifications@github.com>
wrote:

> You can either remove /usr/local/bin/tesseract, or don't uninstall it and
> call /usr/bin/tesseract explicitly.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282368238>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm5Gz1Gb4vGh3tkwYuotKHYcI_41Yks5rfyLYgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 Does tesseract work on 32-bit operating system

On Tue, Feb 28, 2017 at 3:54 PM, Vidushi Gupta <vidushigupta2004@gmail.com>
wrote:

> Can i delete tesseract-ocr from usr/share folder. I am thinking to remove
> tesseract completely from ubuntu
>
> On Fri, Feb 24, 2017 at 8:36 PM, Shreeshrii <notifications@github.com>
> wrote:
>
>> See the shell scripts in https://github.com/Shreeshrii/tess4eval_marathi
>>
>> you can change 4.0 by the 3.05 versions
>>
>> ShreeDevi
>> ____________________________________________________________
>> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>>
>> On Fri, Feb 24, 2017 at 8:31 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
>>
>> wrote:
>>
>> > Use the ppa from https://launchpad.net/~alex-p/+archive/ubuntu/
>> > tesseract-ocr
>> >
>> > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
>> > sudo apt-get update -q
>> > sudo apt-get install tesseract-ocr -y
>> >
>> >
>> > tesseract -v
>> > tesseract --list-langs
>> >
>> >
>> > sudo apt-get install tesseract-ocr-hin -y
>> > (if you want to install Hindi, similarly for other languages)
>> >
>> > ShreeDevi
>> > ____________________________________________________________
>> > ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>> >
>> > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
>> > wrote:
>> >
>> >> Hello sir,
>> >>
>> >> Sorry for the inconvenience caused.I will not repeat my mistake.I have
>> >> installed tesseract on Ubuntu
>> >> 16.04 32 bit os with the help of this site.
>> >> https://www.linux.com/blog/using-tesseract-ubuntu
>> >>
>> >> Yes I can use tesseract 3.05 but i would you be highly obliged if you
>> >> would
>> >> tell me the steps of properly uninstalling tesseract. And from where to
>> >> install tesseract 3.05 and which leptonica version to use.
>> >>
>> >> Thank You for your help and guidance
>> >>
>> >> Regards:
>> >> Vidushi Gupta
>> >> Student(M.Tech)(NSIT Delhi)
>> >>
>> >> On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com
>> >
>> >> wrote:
>> >>
>> >> > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
>> >> > question on several places (even if it is urgent for you).
>> >> >
>> >> > Did you compile Tesseract yourself or do you use a pre-build version?
>> >> Can
>> >> > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
>> >> experimental
>> >> > and not for end users currently.
>> >> >
>> >> > ‚Äî
>> >> > You are receiving this because you were mentioned.
>> >> > Reply to this email directly, view it on GitHub
>> >> > <https://github.com/tesseract-ocr/tesseract/issues/610#issue
>> >> comment-282265686>,
>> >> > or mute the thread
>> >> > <https://github.com/notifications/unsubscribe-auth/
>> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
>> >> > .
>> >> >
>> >>
>> >>
>> >>
>> >> --
>> >> Vidushi
>> >>
>> >> ‚Äî
>> >> You are receiving this because you authored the thread.
>> >> Reply to this email directly, view it on GitHub
>> >> <https://github.com/tesseract-ocr/tesseract/issues/610#issue
>> comment-282298890>,
>> >> or mute the thread
>> >> <https://github.com/notifications/unsubscribe-auth/AE2_o1gQT
>> wf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
>> >> .
>> >>
>> >
>> >
>>
>> ‚Äî
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282313481>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AOjjm3ECVBAY1kTVCX5pcrNj2WLlWwq9ks5rfvHagaJpZM4LVjQA>
>> .
>>
>
>
>
> --
> Vidushi
>



-- 
Vidushi
 thanks for your help and guidance.Resolved the error.

On Tue, Feb 28, 2017 at 4:30 PM, Vidushi Gupta <vidushigupta2004@gmail.com>
wrote:

> Does tesseract work on 32-bit operating system
>
> On Tue, Feb 28, 2017 at 3:54 PM, Vidushi Gupta <vidushigupta2004@gmail.com
> > wrote:
>
>> Can i delete tesseract-ocr from usr/share folder. I am thinking to remove
>> tesseract completely from ubuntu
>>
>> On Fri, Feb 24, 2017 at 8:36 PM, Shreeshrii <notifications@github.com>
>> wrote:
>>
>>> See the shell scripts in https://github.com/Shreeshrii/tess4eval_marathi
>>>
>>> you can change 4.0 by the 3.05 versions
>>>
>>> ShreeDevi
>>> ____________________________________________________________
>>> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>>>
>>> On Fri, Feb 24, 2017 at 8:31 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
>>>
>>> wrote:
>>>
>>> > Use the ppa from https://launchpad.net/~alex-p/+archive/ubuntu/
>>> > tesseract-ocr
>>> >
>>> > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
>>> > sudo apt-get update -q
>>> > sudo apt-get install tesseract-ocr -y
>>> >
>>> >
>>> > tesseract -v
>>> > tesseract --list-langs
>>> >
>>> >
>>> > sudo apt-get install tesseract-ocr-hin -y
>>> > (if you want to install Hindi, similarly for other languages)
>>> >
>>> > ShreeDevi
>>> > ____________________________________________________________
>>> > ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>>> >
>>> > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
>>> > wrote:
>>> >
>>> >> Hello sir,
>>> >>
>>> >> Sorry for the inconvenience caused.I will not repeat my mistake.I have
>>> >> installed tesseract on Ubuntu
>>> >> 16.04 32 bit os with the help of this site.
>>> >> https://www.linux.com/blog/using-tesseract-ubuntu
>>> >>
>>> >> Yes I can use tesseract 3.05 but i would you be highly obliged if you
>>> >> would
>>> >> tell me the steps of properly uninstalling tesseract. And from where
>>> to
>>> >> install tesseract 3.05 and which leptonica version to use.
>>> >>
>>> >> Thank You for your help and guidance
>>> >>
>>> >> Regards:
>>> >> Vidushi Gupta
>>> >> Student(M.Tech)(NSIT Delhi)
>>> >>
>>> >> On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <
>>> notifications@github.com>
>>> >> wrote:
>>> >>
>>> >> > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
>>> >> > question on several places (even if it is urgent for you).
>>> >> >
>>> >> > Did you compile Tesseract yourself or do you use a pre-build
>>> version?
>>> >> Can
>>> >> > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
>>> >> experimental
>>> >> > and not for end users currently.
>>> >> >
>>> >> > ‚Äî
>>> >> > You are receiving this because you were mentioned.
>>> >> > Reply to this email directly, view it on GitHub
>>> >> > <https://github.com/tesseract-ocr/tesseract/issues/610#issue
>>> >> comment-282265686>,
>>> >> > or mute the thread
>>> >> > <https://github.com/notifications/unsubscribe-auth/
>>> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
>>> >> > .
>>> >> >
>>> >>
>>> >>
>>> >>
>>> >> --
>>> >> Vidushi
>>> >>
>>> >> ‚Äî
>>> >> You are receiving this because you authored the thread.
>>> >> Reply to this email directly, view it on GitHub
>>> >> <https://github.com/tesseract-ocr/tesseract/issues/610#issue
>>> comment-282298890>,
>>> >> or mute the thread
>>> >> <https://github.com/notifications/unsubscribe-auth/AE2_o1gQT
>>> wf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
>>> >> .
>>> >>
>>> >
>>> >
>>>
>>> ‚Äî
>>> You are receiving this because you were mentioned.
>>> Reply to this email directly, view it on GitHub
>>> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282313481>,
>>> or mute the thread
>>> <https://github.com/notifications/unsubscribe-auth/AOjjm3ECVBAY1kTVCX5pcrNj2WLlWwq9ks5rfvHagaJpZM4LVjQA>
>>> .
>>>
>>
>>
>>
>> --
>> Vidushi
>>
>
>
>
> --
> Vidushi
>



-- 
Vidushi
 hi,

Is there a way to store the result of tesseract compiled code into text or
pdf file.I am using API example
https://github.com/tesseract-ocr/tesseract/wiki/APIExample.
I want to store the result into text or pdf file instead of displaying on
terminal.
Please tell if there is a way to do it.

On Mon, Feb 27, 2017 at 5:45 PM, Shreeshrii <notifications@github.com>
wrote:

> step 2 > g++ test.cpp -o test -I/usr/include/leptonica
> -I/usr/local/include/tesseract -llept -ltesseract
>
>
> you have used -l/usr/bin/tesseract in your command
>
>
> ShreeDevi
> ____________________________________________________________
> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>
> On Mon, Feb 27, 2017 at 5:37 PM, Vidushi12 <notifications@github.com>
> wrote:
>
> > i was trying to run this code
> >
> >
> > http://8086892010.blogspot.in/2013/08/read-scanned-pdf-line-
> > by-line-using.html
> >
> > On Mon, Feb 27, 2017 at 4:12 PM, Shreeshrii <notifications@github.com>
> > wrote:
> >
> > > ‚Äãapt-get install installs the program.
> > >
> > > you dont need to compile it.
> > >
> > > give the following commands to see what you have.
> > >
> > > which tesseract
> > >
> > > tesseract -v
> > >
> > > tesseract --help
> > >
> > > tesseract --list-langs‚Äã
> > >
> > > ShreeDevi
> > > ____________________________________________________________
> > > ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
> > >
> > > On Mon, Feb 27, 2017 at 3:22 PM, Vidushi12 <notifications@github.com>
> > > wrote:
> > >
> > > > I followed the above commands. And when i try to compile the code it
> is
> > > > giving error as-
> > > >
> > > > fatal error: tesseract/baseapi.h: No such file or directory
> > > > compilation terminated.
> > > >
> > > > For compilation i wrote the command
> > > >
> > > > g++ simple.cpp -o sim -l/usr/include/leptonica -l/usr/bin/tesseract
> > > -llept
> > > > -ltesseract
> > > >
> > > > Please tell what could be the problem
> > > >
> > > > Regards
> > > > Vidushi
> > > >
> > > >
> > > > On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <
> notifications@github.com>
> > > > wrote:
> > > >
> > > > > Use the ppa from https://launchpad.net/~alex-p/
> > > > > +archive/ubuntu/tesseract-ocr
> > > > >
> > > > > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > > > > sudo apt-get update -q
> > > > > sudo apt-get install tesseract-ocr -y
> > > > >
> > > > >
> > > > > tesseract -v
> > > > > tesseract --list-langs
> > > > >
> > > > >
> > > > > sudo apt-get install tesseract-ocr-hin -y
> > > > > (if you want to install Hindi, similarly for other languages)
> > > > >
> > > > > ShreeDevi
> > > > > ____________________________________________________________
> > > > > ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
> > > > >
> > > > > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <
> notifications@github.com
> > >
> > > > > wrote:
> > > > >
> > > > > > Hello sir,
> > > > > >
> > > > > > Sorry for the inconvenience caused.I will not repeat my mistake.I
> > > have
> > > > > > installed tesseract on Ubuntu
> > > > > > 16.04 32 bit os with the help of this site.
> > > > > > https://www.linux.com/blog/using-tesseract-ubuntu
> > > > > >
> > > > > > Yes I can use tesseract 3.05 but i would you be highly obliged if
> > you
> > > > > would
> > > > > > tell me the steps of properly uninstalling tesseract. And from
> > where
> > > to
> > > > > > install tesseract 3.05 and which leptonica version to use.
> > > > > >
> > > > > > Thank You for your help and guidance
> > > > > >
> > > > > > Regards:
> > > > > > Vidushi Gupta
> > > > > > Student(M.Tech)(NSIT Delhi)
> > > > > >
> > > > > > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <
> > > notifications@github.com
> > > > >
> > > > > > wrote:
> > > > > >
> > > > > > > @Vidushi12 <https://github.com/Vidushi12>, please don't post
> > your
> > > > > > > question on several places (even if it is urgent for you).
> > > > > > >
> > > > > > > Did you compile Tesseract yourself or do you use a pre-build
> > > version?
> > > > > Can
> > > > > > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > > > > > experimental
> > > > > > > and not for end users currently.
> > > > > > >
> > > > > > > ‚Äî
> > > > > > > You are receiving this because you were mentioned.
> > > > > > > Reply to this email directly, view it on GitHub
> > > > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > > > issuecomment-282265686>,
> > > > > > > or mute the thread
> > > > > > > <https://github.com/notifications/unsubscribe-
> > > > > > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > > > > > .
> > > > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > > > --
> > > > > > Vidushi
> > > > > >
> > > > > > ‚Äî
> > > > > > You are receiving this because you authored the thread.
> > > > > > Reply to this email directly, view it on GitHub
> > > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > > issuecomment-282298890>,
> > > > > > or mute the thread
> > > > > > <https://github.com/notifications/unsubscribe-auth/AE2_
> > > > > o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> > > > >
> > > > > > .
> > > > > >
> > > > >
> > > > > ‚Äî
> > > > > You are receiving this because you were mentioned.
> > > > > Reply to this email directly, view it on GitHub
> > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > issuecomment-282312789>,
> > > > > or mute the thread
> > > > > <https://github.com/notifications/unsubscribe-auth/
> > > > AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> > > > > .
> > > > >
> > > >
> > > >
> > > >
> > > > --
> > > > Vidushi
> > > >
> > > > ‚Äî
> > > > You are receiving this because you authored the thread.
> > > > Reply to this email directly, view it on GitHub
> > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > issuecomment-282674708>,
> > > > or mute the thread
> > > > <https://github.com/notifications/unsubscribe-auth/AE2_o9-
> > > Q81fTzwHqZPg8gEZHrUzA9hVoks5rgpzJgaJpZM4LVjQA>
> > >
> > > > .
> > > >
> > >
> > > ‚Äî
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282686155>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-
> auth/AOjjm7TEDa6-rWyrqgSt-
> > qWJywC_7ftiks5rgqiugaJpZM4LVjQA>
> > > .
> > >
> >
> >
> >
> > --
> > Vidushi
> >
> > ‚Äî
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282702980>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_o7c_
> Ky2N5toipjWMBnddaBS9UHpyks5rgryNgaJpZM4LVjQA>
>
> > .
> >
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282704298>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm0N7-WaR6aQmzmAKjuPPsv-6G1eAks5rgr5RgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 It should be possible to do it via api. I know it can be done by
commandline.

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Tue, Mar 7, 2017 at 12:43 PM, Vidushi12 <notifications@github.com> wrote:

> hi,
>
> Is there a way to store the result of tesseract compiled code into text or
> pdf file.I am using API example
> https://github.com/tesseract-ocr/tesseract/wiki/APIExample.
> I want to store the result into text or pdf file instead of displaying on
> terminal.
> Please tell if there is a way to do it.
>
> On Mon, Feb 27, 2017 at 5:45 PM, Shreeshrii <notifications@github.com>
> wrote:
>
> > step 2 > g++ test.cpp -o test -I/usr/include/leptonica
> > -I/usr/local/include/tesseract -llept -ltesseract
> >
> >
> > you have used -l/usr/bin/tesseract in your command
> >
> >
> > ShreeDevi
> > ____________________________________________________________
> > ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
> >
> > On Mon, Feb 27, 2017 at 5:37 PM, Vidushi12 <notifications@github.com>
> > wrote:
> >
> > > i was trying to run this code
> > >
> > >
> > > http://8086892010.blogspot.in/2013/08/read-scanned-pdf-line-
> > > by-line-using.html
> > >
> > > On Mon, Feb 27, 2017 at 4:12 PM, Shreeshrii <notifications@github.com>
> > > wrote:
> > >
> > > > ‚Äãapt-get install installs the program.
> > > >
> > > > you dont need to compile it.
> > > >
> > > > give the following commands to see what you have.
> > > >
> > > > which tesseract
> > > >
> > > > tesseract -v
> > > >
> > > > tesseract --help
> > > >
> > > > tesseract --list-langs‚Äã
> > > >
> > > > ShreeDevi
> > > > ____________________________________________________________
> > > > ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
> > > >
> > > > On Mon, Feb 27, 2017 at 3:22 PM, Vidushi12 <notifications@github.com
> >
> > > > wrote:
> > > >
> > > > > I followed the above commands. And when i try to compile the code
> it
> > is
> > > > > giving error as-
> > > > >
> > > > > fatal error: tesseract/baseapi.h: No such file or directory
> > > > > compilation terminated.
> > > > >
> > > > > For compilation i wrote the command
> > > > >
> > > > > g++ simple.cpp -o sim -l/usr/include/leptonica -l/usr/bin/tesseract
> > > > -llept
> > > > > -ltesseract
> > > > >
> > > > > Please tell what could be the problem
> > > > >
> > > > > Regards
> > > > > Vidushi
> > > > >
> > > > >
> > > > > On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <
> > notifications@github.com>
> > > > > wrote:
> > > > >
> > > > > > Use the ppa from https://launchpad.net/~alex-p/
> > > > > > +archive/ubuntu/tesseract-ocr
> > > > > >
> > > > > > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > > > > > sudo apt-get update -q
> > > > > > sudo apt-get install tesseract-ocr -y
> > > > > >
> > > > > >
> > > > > > tesseract -v
> > > > > > tesseract --list-langs
> > > > > >
> > > > > >
> > > > > > sudo apt-get install tesseract-ocr-hin -y
> > > > > > (if you want to install Hindi, similarly for other languages)
> > > > > >
> > > > > > ShreeDevi
> > > > > > ____________________________________________________________
> > > > > > ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
> > > > > >
> > > > > > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <
> > notifications@github.com
> > > >
> > > > > > wrote:
> > > > > >
> > > > > > > Hello sir,
> > > > > > >
> > > > > > > Sorry for the inconvenience caused.I will not repeat my
> mistake.I
> > > > have
> > > > > > > installed tesseract on Ubuntu
> > > > > > > 16.04 32 bit os with the help of this site.
> > > > > > > https://www.linux.com/blog/using-tesseract-ubuntu
> > > > > > >
> > > > > > > Yes I can use tesseract 3.05 but i would you be highly obliged
> if
> > > you
> > > > > > would
> > > > > > > tell me the steps of properly uninstalling tesseract. And from
> > > where
> > > > to
> > > > > > > install tesseract 3.05 and which leptonica version to use.
> > > > > > >
> > > > > > > Thank You for your help and guidance
> > > > > > >
> > > > > > > Regards:
> > > > > > > Vidushi Gupta
> > > > > > > Student(M.Tech)(NSIT Delhi)
> > > > > > >
> > > > > > > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <
> > > > notifications@github.com
> > > > > >
> > > > > > > wrote:
> > > > > > >
> > > > > > > > @Vidushi12 <https://github.com/Vidushi12>, please don't post
> > > your
> > > > > > > > question on several places (even if it is urgent for you).
> > > > > > > >
> > > > > > > > Did you compile Tesseract yourself or do you use a pre-build
> > > > version?
> > > > > > Can
> > > > > > > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x
> is
> > > > > > > experimental
> > > > > > > > and not for end users currently.
> > > > > > > >
> > > > > > > > ‚Äî
> > > > > > > > You are receiving this because you were mentioned.
> > > > > > > > Reply to this email directly, view it on GitHub
> > > > > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > > > > issuecomment-282265686>,
> > > > > > > > or mute the thread
> > > > > > > > <https://github.com/notifications/unsubscribe-
> > > > > > > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > > > > > > .
> > > > > > > >
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > > --
> > > > > > > Vidushi
> > > > > > >
> > > > > > > ‚Äî
> > > > > > > You are receiving this because you authored the thread.
> > > > > > > Reply to this email directly, view it on GitHub
> > > > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > > > issuecomment-282298890>,
> > > > > > > or mute the thread
> > > > > > > <https://github.com/notifications/unsubscribe-auth/AE2_
> > > > > > o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> > > > > >
> > > > > > > .
> > > > > > >
> > > > > >
> > > > > > ‚Äî
> > > > > > You are receiving this because you were mentioned.
> > > > > > Reply to this email directly, view it on GitHub
> > > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > > issuecomment-282312789>,
> > > > > > or mute the thread
> > > > > > <https://github.com/notifications/unsubscribe-auth/
> > > > > AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> > > > > > .
> > > > > >
> > > > >
> > > > >
> > > > >
> > > > > --
> > > > > Vidushi
> > > > >
> > > > > ‚Äî
> > > > > You are receiving this because you authored the thread.
> > > > > Reply to this email directly, view it on GitHub
> > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > issuecomment-282674708>,
> > > > > or mute the thread
> > > > > <https://github.com/notifications/unsubscribe-auth/AE2_o9-
> > > > Q81fTzwHqZPg8gEZHrUzA9hVoks5rgpzJgaJpZM4LVjQA>
> > > >
> > > > > .
> > > > >
> > > >
> > > > ‚Äî
> > > > You are receiving this because you were mentioned.
> > > > Reply to this email directly, view it on GitHub
> > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > issuecomment-282686155>,
> > > > or mute the thread
> > > > <https://github.com/notifications/unsubscribe-
> > auth/AOjjm7TEDa6-rWyrqgSt-
> > > qWJywC_7ftiks5rgqiugaJpZM4LVjQA>
> > > > .
> > > >
> > >
> > >
> > >
> > > --
> > > Vidushi
> > >
> > > ‚Äî
> > > You are receiving this because you authored the thread.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282702980>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/AE2_o7c_
> > Ky2N5toipjWMBnddaBS9UHpyks5rgryNgaJpZM4LVjQA>
> >
> > > .
> > >
> >
> > ‚Äî
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282704298>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AOjjm0N7-
> WaR6aQmzmAKjuPPsv-6G1eAks5rgr5RgaJpZM4LVjQA>
> > .
> >
>
>
>
> --
> Vidushi
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-284640944>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o24Wx3WC7atlqW0P8rmxhULchVJjks5rjQOVgaJpZM4LVjQA>
> .
>
   @stweil 

In `configure.ac,` should we change
>PKG_CHECK_MODULES([LEPTONICA], [lept >= 1.74], [have_lept=true], [have_lept=false])

to

>PKG_CHECK_MODULES([LEPTONICA], [lept >= 1.74.0], [have_lept=true], [have_lept=false])

? This is how it is tagged in the github repo. In the Leptonica website it is '1.74'.
You can change it if you want to :-) I did it after the `.travis.yml` [commits](https://github.com/tesseract-ocr/tesseract/pull/605). As you can see, I needed 3 tries to make it work :-)
1.74 -> 1.74.0 -> +drop the `v` before the version number ...

So I thought it should be 1.74.0 in CMake too. @DanBloomberg

The `1.74` vs. `1.74.0` is somewhat confusing ... Seems like we have a problem with the 1.74.0 version numbering.  What do
you suggest that we do here?  New github release?  Replacement? Nothing?

On Mon, Dec 26, 2016 at 2:10 PM, Stefan Weil <notifications@github.com>
wrote:

> I just ran a test with cmake 3.7.1-1 on Debian GNU Linux. It also works
> only with 1.74, but not with 1.74.0.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/608#issuecomment-269245065>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLNTIpQ9_c7fCyh6OFkdZidkx24NCks5rMDtvgaJpZM4LVW_Z>
> .
>
 The problem is that Leptonica's `lept.pc` has 1.74 rather than 1.74.0. If you edit that file to have the latter then it works. This value originates from `configure.ac`, which also has 1.74. @DanBloomberg, you need to be consistent with this everywhere. Seems like I should make a new github release for leptonica, with the correct version
number in configure.ac.  If you agree, should I replace 1.74.0 or make
1.74.1?

  -- Dan

On Sat, Dec 31, 2016 at 1:51 PM, Stefan Weil <notifications@github.com>
wrote:

> Yes, I think this is the reason why 1.74.0 did not work for me.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/608#issuecomment-269883123>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLB1I0zUtfSfCWjkMVAISrwSDgVG2ks5rNs5zgaJpZM4LVW_Z>
> .
>
 At this point, I don't mind sticking with 1.74 for now as we've already compensated in the necessary places. My Gentoo release ended up being 1.74 as this matched the tarball and the tarball's subdirectory. But if you want to push a new 1.74.1 release out to make sure we get it right while it's still fresh in our minds, that's cool. I was thinking of RELEASE, but I can go with PATCH.

On Sun, Jan 1, 2017 at 8:49 AM, Egor Pugin <notifications@github.com> wrote:

> Or better LIBLEPT_PATCH_VERSION as in semver (major.minor.patch).
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/608#issuecomment-269910132>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLEGrqUyXl5dJF8dqs5zpJFRjyylwks5rN9kwgaJpZM4LVW_Z>
> .
>
 I've put up on github the leptonica 1.74.1 release.

In theory, it solves all the existing issues with builds.  In practice,
we'll see ...

It's also up as a configure/make tarball on leptonica.org.  (The difference
between the two is just running the autobuild script on the github release,
which requires autotools.)


> I was thinking of RELEASE, but I can go with PATCH.
>
> On Sun, Jan 1, 2017 at 8:49 AM, Egor Pugin <notifications@github.com>
> wrote:
>
>> Or better LIBLEPT_PATCH_VERSION as in semver (major.minor.patch).
>>
>> ‚Äî
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/pull/608#issuecomment-269910132>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AP6mLEGrqUyXl5dJF8dqs5zpJFRjyylwks5rN9kwgaJpZM4LVW_Z>
>> .
>>
>
>
  This code:

```
tesseract::ParamsVectors *GlobalParams() {
  static tesseract::ParamsVectors *global_params =
    new tesseract::ParamsVectors();
  return global_params;
}
```
is causing a memory leak. I don't see any means of removing it while tesseract engine is no longer needed in the application. Thanks!  I installed tesseract using sudo port install tesseract tesseract-eng.
I took a screenshot using command+shift+3 on Mac, and try to ocr the screenshot. However, I get the following message, and the output file is empty.
$ tesseract screenshot.png output
Tesseract Open Source OCR Engine v3.04.01 with Leptonica
Warning in pixReadMemPng: work-around: writing to a temp file
What might be causing this?
Thanks for your help! You should ignore this message. Regardless the message, the output file is empty. Is it an error? Thanks! Thank you for helping with this.
Yes, definitely has text.
When I try to build tesseract from source, I get this from ./configure
checking host system type... x86_64-apple-darwin16.1.0
./configure: line 4237: syntax error near unexpected token `-mavx,'
./configure: line 4237: `AX_CHECK_COMPILE_FLAG(-mavx, avx=1, avx=0)'
Is there prebuilt binary for tesseract 4 for Mac somewhere? See https://github.com/tesseract-ocr/tesseract/issues/601#issuecomment-269197286
You need an equivalent package for Mac. Do you happen to know what that might be? I searched mavx on macports, but nothing turned up. https://www.macports.org/ports.php?by=library&substr=autoconf-archive  Hi there, tired to run following command on the attached Image:

`$ tesseract TH.jpg outbutbase -l vie -psm 7`

![th](https://cloud.githubusercontent.com/assets/1496858/21446802/66d4839c-c8fd-11e6-8550-942a48363229.jpg)

Getting only "ParamsModel::Incomplete line" erros, see here:
![2016-12-23_10h46_01](https://cloud.githubusercontent.com/assets/1496858/21446813/9528b056-c8fd-11e6-8e9b-1634cd763e6e.jpg)

Specs: 
Windows Server 2012R2

```
C:\Users\Administrator\Desktop\Tesseract-OCR>tesseract --version
tesseract 3.05.00dev
 leptonica-1.73
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.6.20 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.3 : libopenjp2 2.1.0
```

Installed Vietnamese language during setup wizard  Hey,
Trying to install openalpr, which requires tesseract as a dependency.

Everything goes fine until I try to 'make' tesseract

The first error is:

g++: error: unrecognized command line option '-mavx'

I'm not sure how to go further. Can anyone help?

Full error stacktrace:
`pi@raspberrypi:~/openalpr/libraries/tesseract $ make -j4
make all-recursive
make[1]: Entering directory '/home/pi/openalpr/libraries/tesseract'
Making all in arch
make[2]: Entering directory '/home/pi/openalpr/libraries/tesseract/arch'
make[3]: Entering directory '/home/pi/openalpr/libraries/tesseract/arch'
/bin/bash ../libtool --tag=CXX --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I../ccutil -I/usr/local/include/leptonica -pthread -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng12 -mavx -g -O2 -std=c++11 -MT libtesseract_avx_la-dotproductavx.lo -MD -MP -MF .deps/libtesseract_avx_la-dotproductavx.Tpo -c -o libtesseract_avx_la-dotproductavx.lo test -f 'dotproductavx.cpp' || echo './'dotproductavx.cpp
/bin/bash ../libtool --tag=CXX --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I../ccutil -I/usr/local/include/leptonica -pthread -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng12 -msse4.1 -g -O2 -std=c++11 -MT libtesseract_sse_la-dotproductsse.lo -MD -MP -MF .deps/libtesseract_sse_la-dotproductsse.Tpo -c -o libtesseract_sse_la-dotproductsse.lo test -f 'dotproductsse.cpp' || echo './'dotproductsse.cpp
libtool: compile: g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I../ccutil -I/usr/local/include/leptonica -pthread -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng12 -mavx -g -O2 -std=c++11 -MT libtesseract_avx_la-dotproductavx.lo -MD -MP -MF .deps/libtesseract_avx_la-dotproductavx.Tpo -c dotproductavx.cpp -fPIC -DPIC -o .libs/libtesseract_avx_la-dotproductavx.o
g++: error: unrecognized command line option '-mavx'
Makefile:537: recipe for target 'libtesseract_avx_la-dotproductavx.lo' failed
make[3]: *** [libtesseract_avx_la-dotproductavx.lo] Error 1
make[3]: *** Waiting for unfinished jobs....
libtool: compile: g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I../ccutil -I/usr/local/include/leptonica -pthread -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng12 -msse4.1 -g -O2 -std=c++11 -MT libtesseract_sse_la-dotproductsse.lo -MD -MP -MF .deps/libtesseract_sse_la-dotproductsse.Tpo -c dotproductsse.cpp -fPIC -DPIC -o .libs/libtesseract_sse_la-dotproductsse.o
g++: error: unrecognized command line option '-msse4.1'
Makefile:544: recipe for target 'libtesseract_sse_la-dotproductsse.lo' failed
make[3]: *** [libtesseract_sse_la-dotproductsse.lo] Error 1
make[3]: Leaving directory '/home/pi/openalpr/libraries/tesseract/arch'
Makefile:584: recipe for target 'all-recursive' failed
make[2]: *** [all-recursive] Error 1
make[2]: Leaving directory '/home/pi/openalpr/libraries/tesseract/arch'
Makefile:478: recipe for target 'all-recursive' failed
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory '/home/pi/openalpr/libraries/tesseract'
Makefile:386: recipe for target 'all' failed
make: *** [all] Error 2`


 In arch/Makefile.am, disable or remove these lines:

>libtesseract_avx_la_CXXFLAGS = -mavx
libtesseract_sse_la_CXXFLAGS = -msse4.1

The code in master is in 'alpha' state and the support for ARM seems to be less good than for x86. @zdenop, @stweil 

We need to get the CPU type in configure.ac and add a condition around those lines in the Makefile.am.
 I got this error with latest master (commit c124f87d5ba974c7854cfc857f5f2b0cb5236f61
) - it worked before (first week of dec)

```
checking host system type... x86_64-unknown-linux-gnu
./configure: line 4228: syntax error near unexpected token `-mavx,'
./configure: line 4228: `AX_CHECK_COMPILE_FLAG(-mavx, avx=1, avx=0)'
/bin/bash ./config.status --recheck
running CONFIG_SHELL=/bin/bash /bin/bash ./configure --enable-debug --no-create --no-recursion
checking for g++... g++
```

```
checking host system type... x86_64-unknown-linux-gnu
./configure: line 4229: syntax error near unexpected token `-msse4.1,'
./configure: line 4229: `AX_CHECK_COMPILE_FLAG(-msse4.1, sse41=1, sse41=0)'
/bin/bash ./config.status --recheck

```

I was able to get around it by commenting out the following 2 lines in configure.ac

```
## Checks for supported compiler options.
AM_CONDITIONAL([AVX_OPT], false)
AM_CONDITIONAL([SSE41_OPT], false)
##AX_CHECK_COMPILE_FLAG([-mavx], [avx=1], [avx=0])
##AX_CHECK_COMPILE_FLAG([-msse4.1], [sse41=1], [sse41=0])
``` @zdenop  Thanks! It works now.  I now have a framework.
But crash "actual_tessdata_num_entries_ <= TESSDATA_NUM_ENTRIES:Error:Assert failed:in file tessdatamanager.cpp, line 53".
Under the framework where the latest

This problem I use pod 'TesseractOCRiOS' update and download the traineddata https://github.com/tesseract-ocr/tessdata/tree/bf82613055ebc6e63d9e3b438a5c234bfd638c93
 Now the question is "Can't analyse layout. Make sure 'osd.traineddata' available in 'tessdata' "
But in the Bundle with this file.
How to solve?
  Hi there. Sorry for the silly question... after I installed this application on my system using Mac ports I could not invoke it's GUI. Do you know where the program is installed so I can open it up with the GUI? Thank you.   I don't know why it fails 64-bit build. Perhaps @FeodorFitsner can explain. Nice to see this working. It worth documenting how to get development builds at https://github.com/tesseract-ocr/tesseract/wiki#windows  >needed for macOS

I'm on Linux... Personally, I like Meson
https://github.com/mesonbuild/meson >autotools is written in C

and  perl, shell, m4 and make ...
 >in the future I hope will be able to build the last training tool - text2image on windows - which is very hard with pure cmake.

What are the issues with text2image and cmake?    ![image](https://cloud.githubusercontent.com/assets/5406399/21318185/3e53f010-c619-11e6-89fb-584df597505a.png)

I used this - https://github.com/tesseract-ocr/tesseract/wiki/Compiling#windows
When I try to build it in Debug or Release (I need to get tesseract .lib and .dll for my project), I get bunch of errors because the unicode .lib file is missing. ALL errors associated with this.
I tried
```
cppan --clean-packages .*unicode.*
cppan
```
Same errors Without STATIC=1 I get:
```
20>LINK : fatal error LNK1104: cannot open file '..\Debug\tesseract305d.lib'
19>LINK : fatal error LNK1104: cannot open file '..\Debug\tesseract305d.lib'
18>LINK : fatal error LNK1104: cannot open file '..\Debug\tesseract305d.lib'
17>LINK : fatal error LNK1104: cannot open file '..\Debug\tesseract305d.lib'
``` I removed the folder C:/Users/HOME/.cppan and re-downloaded the repository to start over. Here are my steps.
```
git clone https://github.com/tesseract-ocr/tesseract tesserac
cd tesserac
cppan --self-upgrade
cppan
mkdir win32
cd win32
cmake .. > 1.txt 2>&1
```
Then I had this issue - https://github.com/tesseract-ocr/tesseract/issues/464#issuecomment-264166445 There was two cmake.exe processes, I stopped one with memory 2304KB (second had bigger memory 4496KB). Also sometimes can hangs 3 processes.
`cmake --build . --config Release > 2.txt 2>&1`
I have build error unfortunately... Can you look at it?
https://gist.github.com/Izaron/c0471f1727af1ca7c0f67b398a1a5cd4 - 1.txt
https://gist.github.com/Izaron/d1116ae559c7a40cbebcf7794f7f0a35 - 2.txt

I tried to do this several times and get different number of errors in 2.txt. I have no idea the reason why this is happening I have correct VS 2015.
It's question marks because of default russian language. In UTF-8: https://gist.github.com/Izaron/071268b9ba1c863bd6b055d6f37ce077
I built it again (deleted .cppan, cmake, etc.). As you can see, quite a different number of errors Finally build it .dll and .lib, thank you very much @egorpugin!

In new example project I put all folders to includes in properties and linked tesseract305.lib, so I can include <baseapi.h>, but can not include <allheaders.h>. Should I build leptonica for windows to use allheader.h and pixRead? From command line works well, but if I want to compile this code in VS - https://github.com/cppan/tesseract_example/blob/master/with_cppan/main.cpp

Also built files are named tesseract305.dll and tesseract305.lib, is this normal? I have failed again with this **simple** command.
But I sure I understand what the problem is. In the console cppan writes that downloads and unpacks **18** different packages. But I do it every time, not all files downloads - on my PC only from 4 to 11 files random files during all this time, but sometimes this is enough to build some projects. That is why as a result of build errors is different - from 50 to 1500, and sometimes 0.
This program is also frequently breaks while downloading and unpacking (every third time around).
All I need - .lib and .dll files of the dependencies (including leptonica) and built .lib and .dll of 4.0.0 tesseract (current master branch, right?), in order that I can update it in one of my project from older version.
Can you give me all these dependency files? I can add them to any project for using leptonica and tesseract and compile , including current tesseract master (although I was able to magically compile it with **9** downloaded dependencies - excluding gif, webp and almost all unicode libs). Thanks for the support!  Loaded 4128/4128 pages (0-4128) of document /home/shree/tesstutorial/sanskrittrain/san.Yatra_One.exp0.lstmf
Compute CTC targets failed!
At iteration 200/200/202, Mean rms=1.024%, delta=70.515%, char train=100.405%, word train=100%, skip ratio=1%,  New worst char error = 100.405 wrote checkpoint. ```
$ lstmtraining -U ~/tesstutorial/aratest/ara.unicharset \
>   --script_dir ../langdata  --debug_interval 0 \
>   --continue_from ~/tesstutorial/aralayer_from_aratest/ara.lstm \
>   --append_index 5 --net_spec '[Lfx256 O1c105]' \
>   --learning_rate 10e-5 \
>   --net_mode 192 \
>   --perfect_sample_delay 19 \
>   --model_output ~/tesstutorial/aralayer_from_aratest/aralayer \
>   --train_listfile ~/tesstutorial/aratest/ara.training_files.txt \
>   --target_error_rate 0.01
Loaded file /home/shree/tesstutorial/aralayer_from_aratest/aralayer_checkpoint, unpacking...
Successfully restored trainer from /home/shree/tesstutorial/aralayer_from_aratest/aralayer_checkpoint
Loaded 182/182 pages (1-182) of document /home/shree/tesstutorial/aratest/ara.Arial_Unicode_MS.exp0.lstmf
Loaded 135/135 pages (1-135) of document /home/shree/tesstutorial/aratest/ara.Traditional_Arabic.exp0.lstmf
Compute CTC targets failed!
2 Percent improvement time=458, best error was 12.971 @ 3844
At iteration 4302/5200/5239, Mean rms=1.375%, delta=3.33%, char train=10.699%, word train=30.237%, skip ratio=0.7%,  New best char error = 10.699 wr
ote best model:/home/shree/tesstutorial/aralayer_from_aratest/aralayer10.699_4302.lstm wrote checkpoint.

Compute CTC targets failed!
2 Percent improvement time=522, best error was 12.971 @ 3844
At iteration 4366/5300/5340, Mean rms=1.371%, delta=3.274%, char train=10.64%, word train=30.125%, skip ratio=0.8%,  New best char error = 10.64 wro
te checkpoint.


``` @Shreeshrii any luck with this ? I am trying to train on camera taken images and I have been getting the same error 
and training doesnt converge, i have a error rate of 70% right now @ferjad 

I am not sure what causes 'Compute CTC targets failed!' 

Still waiting on updates to code and traineddata from @theraysmith after retraining, to test further.

Which language are you trying to train? You need a large training set for 4.0. @Shreeshrii  I have a training set of 5000 images that have 15000 lines in total
Language is english but the images are camera blurred with different angles, LSTM are known to learn data is this setting 
Data shouldnt be a problem, I saw you trained some other scripts too on your  other opened issue on github
did you manage to get around it? @Shreeshrii  can you share a image and box pair? Did you use the Wordstr format for box files? Wordstr option is not fully operational yet.

Text2image creates the box file with tab at end of line.

You can use jtessboxeditor and use the option under tools to add tab for
eol to existing box files.



- excuse the brevity, sent from mobile

On 03-Mar-2017 8:50 PM, "ferjad" <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/Shreeshrii> can you share a image and box
> pair? Did you use the Wordstr format for box files?
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/591#issuecomment-283981485>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o9SFjFTkqJDw1y0P_MFQ2OTqCm8Rks5riC-1gaJpZM4LQswx>
> .
>
 @Shreeshrii The problem is I want to train on real world data and not synthetic and manually labelling character by character isnt possible
Are you proposing adding a tab character at the end of Wordstr boxes?
jtessboxeditor doesnt support the Wordstr option either Please see discussion on following issue


https://github.com/tesseract-ocr/tesseract/issues/670

- excuse the brevity, sent from mobile

On 03-Mar-2017 9:37 PM, "ferjad" <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/Shreeshrii> The problem is I want to
> train on real world data and not synthetic and manually labelling character
> by character isnt possible
> Are you proposing adding a tab character at the end of Wordstr boxes?
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/591#issuecomment-283994730>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o-PnPyxGkgqk1ZT1oAD5C8HED1Ybks5riDrOgaJpZM4LQswx>
> .
>
 @Shreeshrii hey thanks for the link, my wordstr strings are space delimited
I am fine tuning the english model so unicharset isnt needed
Did you have any luck training with wordstr format?
It would really help if you could share some working image and box pairs in wordstr format No, I did not try to train with wordstr format except for that test.

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Fri, Mar 3, 2017 at 10:08 PM, ferjad <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/Shreeshrii> hey thanks for the link, my
> wordstr strings are space delimited
> I am fine tuning the english model so unicharset isnt needed
> Did you have any luck training with wordstr format?
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/591#issuecomment-284003386>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o6xMIbL4uGUBw1AD2zLY-DdnNigjks5riEHxgaJpZM4LQswx>
> .
>
 @Shreeshrii hey any update on ability to train with WordStr format? I tried this again and still got Compute CTC Failed @theraysmith has not updated the programs for handling this yet. Hopefully it will be in next update. @Shreeshrii It would be ideal to update the training wiki to reflect this, thanks for the update  Added a note in training wiki to reflect that WordStr option is not implemented.

Also added as a separate issue. @Shreeshrii hey any update on this? the wiki still says the same  @ferjad, the 'WordStr' format is still not supported. It's unknown when it will be supported.  mkdir -p ~/tesstutorial/sanvedic 
lstmtraining -U ~/tesstutorial/vedic/san.unicharset \
  --script_dir ../langdata --debug_interval 0 \
  --learning_rate 10e-5 \
  --net_spec '[1,0,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx384 O1c5000]' \
  --net_mode 192 \
  --perfect_sample_delay 19 \
  --model_output ~/tesstutorial/sanvedic/base \
  --train_listfile ~/tesstutorial/vedic/san.training_files.txt \
  --eval_listfile ~/tesstutorial/vedic/san.training_files.txt \
  --max_iterations 50000 \
  &>~/tesstutorial/sanvedic/basetrain.log

Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Setting properties for script Devanagari
Unichar 2306=‡§∞‡•ç‡§§‡•ç‡§∏‡•ç‡§®‡•ç‡§Ø‡•á->‡§∞‡•ç‡§§‡•ç‡§∏‡•ç‡§®‡•ç‡§Ø‡•á is too long to encode!!
Warning: given outputs 5000 not equal to unicharset of 5018.
Num outputs,weights in serial:
  1,0,0,1:1, 0
Num outputs,weights in serial:
  C5,5:25, 0
  Ft16:16, 416
Total weights = 416
  [C5,5Ft16]:16, 416
  Mp3,3:16, 0
  Lfys64:64, 20736
  Lfx128:128, 98816
  Lrx128:128, 131584
  Lfx384:384, 787968
  Fc5018:5018, 1931930
Total weights = 2971450
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx384Fc5018] from request [1,0,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx384 O1c5000]
Training parameters:
  Debug interval = 0, weights = 0.1, learning rate = 0.0001, momentum=0.9
Loaded 828/828 pages (0-828) of document /home/shree/tesstutorial/vedic/san.AA_NAGARI_SHREE_L1.exp0.lstmf
Loaded 691/691 pages (0-691) of document /home/shree/tesstutorial/saneval/san.Aksharyogini2.exp0.lstmf
Loaded 1023/1023 pages (0-1023) of document /home/shree/tesstutorial/vedic/san.Sanskrit_2003.exp0.lstmf
Loaded 957/957 pages (0-957) of document /home/shree/tesstutorial/vedic/san.e-Nagari_OT.exp0.lstmf
Loaded 1060/1060 pages (0-1060) of document /home/shree/tesstutorial/vedic/san.FreeSans.exp0.lstmf
Loaded 691/691 pages (0-691) of document /home/shree/tesstutorial/saneval/san.Amiko.exp0.lstmf
Loaded 1213/1213 pages (0-1213) of document /home/shree/tesstutorial/vedic/san.Siddhanta-cakravat.exp0.lstmf
Loaded 1191/1191 pages (0-1191) of document /home/shree/tesstutorial/vedic/san.Sahadeva.exp0.lstmf
Loaded 1291/1291 pages (0-1291) of document /home/shree/tesstutorial/vedic/san.Santipur_OT_Medium.exp0.lstmf
Loaded 1115/1115 pages (0-1115) of document /home/shree/tesstutorial/vedic/san.Lohit_Devanagari.exp0.lstmf
Loaded 1210/1210 pages (0-1210) of document /home/shree/tesstutorial/vedic/san.Nakula.exp0.lstmf
Found AVX
Found SSE
Loaded 1188/1188 pages (0-1188) of document /home/shree/tesstutorial/vedic/san.Siddhanta-Calcutta.exp0.lstmf
Loaded 1211/1211 pages (0-1211) of document /home/shree/tesstutorial/vedic/san.Siddhanta.exp0.lstmf
Loaded 1214/1214 pages (0-1214) of document /home/shree/tesstutorial/vedic/san.Siddhanta-Nepali.exp0.lstmf
Loaded 1157/1157 pages (0-1157) of document /home/shree/tesstutorial/vedic/san.Uttara.exp0.lstmf
Image too large to learn!! Size = 2594x48
Image not trainable
Image too large to learn!! Size = 2758x48
Image not trainable
Image too large to learn!! Size = 2621x48
Image not trainable
At iteration 100/100/103, Mean rms=0.95%, delta=57.759%, char train=100.161%, word train=100%, skip ratio=3%,  New worst char error = 100.161 wrote checkpoint The images used were created by text2image with training text with word wrap which ran for full width of page.

Is there a limit to size of images for training? 

Should training text only to be 70-120 characters wide?

 This is the opposite case of image being too small.

```
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc104] from request [1,0,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c5000]
Training parameters:
  Debug interval = 0, weights = 0.1, learning rate = 0.0001, momentum=0.9
Loaded 151/151 pages (1-151) of document /home/shree/tesstutorial/trado/ara.Traditional_Arabic.exp0.lstmf
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
At iteration 100/100/104, Mean rms=6.004%, delta=48.481%, char train=138.814%, word train=100%, skip ratio=4%,  New worst char error = 138.814 wrote checkpoint.

Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
At iteration 200/200/207, Mean rms=5.654%, delta=40.983%, char train=119.407%, word train=100%, skip ratio=3.5%,  New worst char error = 119.407 wrote checkpoint.

Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!

``` >Is there a limit to size of images for training?

https://github.com/tesseract-ocr/tesseract/blob/ce76d1c569/lstm/lstmrecognizer.cpp#L266

>// Maximum width of image to train on.
const int kMaxImageWidth = 2560; Then shouldn't text2image ensure that images are made to fit that width.

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Mon, Jan 9, 2017 at 3:20 PM, Amit D. <notifications@github.com> wrote:

> Is there a limit to size of images for training?
>
> https://github.com/tesseract-ocr/tesseract/blob/ce76d1c569/
> lstm/lstmrecognizer.cpp#L266
>
> https://github.com/tesseract-ocr/tesseract/blob/ce76d1c569/
> lstm/lstmrecognizer.cpp#L266
>
> // Maximum width of image to train on.
> const int kMaxImageWidth = 2560;
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/590#issuecomment-271244655>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oyLDWu_QZFaYM9Kn1mCaW7ExTo-_ks5rQgLtgaJpZM4LQsPF>
> .
>
 Yes :-) https://github.com/tesseract-ocr/tesseract/blob/831e161066d28a0320d7061c8403f638515b8801/training/text2image.cpp#L82


// Width of output image (in pixels).
INT_PARAM_FLAG(xsize, 3600, "Width of output image");
 The default value for images output by text2image can be reduced during running tesstrain.sh by modifying tesstrain_utils.sh

```
    common_args+=" --leading=${LEADING} --xsize 2550"
``` @theraysmith 

Ray,

// Maximum width of image to train on.
const int kMaxImageWidth = 2560;

I have some  old tif/box pairs . the image width is 4000.

Will training quality be degraded if changing above constant to 4000 in order to use them?

 Also can this be changed during runtime with a  variable or do I need to recompile tesseract with the higher value? @Shreeshrii how can the problem of image being too small be fixed? actually, it's not just a few messages. I am trying to train tesseract to
recognize plate licence, and the prepared training_text is just like a
plate licence. something like this:
€µ€¥ €∑€≤€∏ ÿ® €±€¥
each line includes one of these patterns.
I received a lot of these errors and the training process finished with
error rate equal to zero. no training!
would you please help me to figure out what the problem is?


On Wed, Aug 9, 2017 at 8:02 AM, Shreeshrii <notifications@github.com> wrote:

> Reopened #590 <https://github.com/tesseract-ocr/tesseract/issues/590>.
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/590#event-1198365561>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiARloL1SxhhVagWDBpNPsl8wmxGH3ks5sWSgzgaJpZM4LQsPF>
> .
>
 >Image too large to learn!! Size = 2758x48
Image not trainable

@hanikh, please paste a short example for the errors you get. I will send the exact error message as soon as possible. but, meanwhile I
have faced a more important problem. I finetuned tesseract for farsi (40
fonts on 6000 text lines) and I got worse result than the original tesserct
on the trained fonts. what is the problem? the training_text is not big
enough? (this is a different project and not related to the licence plate)

On Thu, Aug 10, 2017 at 11:17 PM, theraysmith <notifications@github.com>
wrote:

> The exact error message would greatly help diagnose the problem.
>
> On Tue, Aug 8, 2017 at 10:28 PM, Amit D. <notifications@github.com> wrote:
>
> > Image too large to learn!! Size = 2758x48
> > Image not trainable
> >
> > @hanikh <https://github.com/hanikh>, please paste a short example for
> the
> > errors you get.
> >
> > ‚Äî
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/590#
> issuecomment-321156352>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AL056TBM3518EXdJE7-
> KA44mvwgN2Mx2ks5sWUNhgaJpZM4LQsPF>
> > .
> >
>
>
>
> --
> Ray.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/590#issuecomment-321639717>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAQuqzKOKd8bmnzUcFlsc6bPQth3Oks5sW1AzgaJpZM4LQsPF>
> .
>
 @hanikh 
did you used v4?
i saw this problem on cube for persian.. @theraysmith would you please help me, how many text line is appropriate?
thanks
 Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
2 Percent improvement time=0, best error was 2.167 @ 14
At iteration 14/1100/20884, Mean rms=0.049%, delta=0%, char train=0%, word train=0%, skip ratio=1798.6%,  New best char error = 0 wrote best model:/home/fanasa/tesstutorial/fastuned_from_fas/fastuned-plates0_14.lstm wrote checkpoint.

Finished! Error rate = 0
this is the error I got during training for licence plates. for the fine tuning problem:
the error-rate reaches 0.017 at about 80000 iterations. so with few
iterations like in tutorial, a low error-rate like 0.01 can not be
achieved. so you think fine tuning is a wrong solution and I should try
replacing some layers? as I said before I am trying to train for 40 Persian
fonts and they are so common.

On Sun, Aug 13, 2017 at 9:38 AM, Shreeshrii <notifications@github.com>
wrote:

> Ray,
>
> I have seen line too small to be recognized when building box/tiff pairs
> using tesstrain.sh - it is usually related to 'nnn diacritics found' - so
> it may be related to accents being treated as a separate line.
>
> Regarding finetuning, I have experimented a lot with Devanagari - with
> smaller number of iterations, the reported error rate is higher. And it
> takes tens of thosands of iterations for it to get more accuracy on
> training set - not sure of its effect on samples it has not seen. - see
> https://github.com/Shreeshrii/tess4training/blob/master/README.md
>
>
>
> ShreeDevi
> ____________________________________________________________
> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>
> On Sun, Aug 13, 2017 at 9:44 AM, theraysmith <notifications@github.com>
> wrote:
>
>
> > Initial problem: (Image too small to scale)
> > Those images are ridiculously small at 3x48 pixels. Something is going
> > wrong somewhere with the images.
> > Are they oriented vertically? The input scaling scales the height to 48,
> > whatever it starts as, so it looks like your textlines are vertical.
> >
> > Fine tuning problem:
> > The problem is most likely too many iterations. It will hone its accuracy
> > to whatever training data you give it if you run it for too many
> > iterations.
> > See how few iterations are used in the training tutorial for fine tuning.
> >
> > On Sat, Aug 12, 2017 at 5:19 AM, hanikh <notifications@github.com>
> wrote:
> >
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > 2 Percent improvement time=0, best error was 2.167 @ 14
> > > At iteration 14/1100/20884, Mean rms=0.049%, delta=0%, char train=0%,
> > word
> > > train=0%, skip ratio=1798.6%, New best char error = 0 wrote best
> > > model:/home/fanasa/tesstutorial/fastuned_from_
> > fas/fastuned-plates0_14.lstm
> > > wrote checkpoint.
> > >
> > > Finished! Error rate = 0
> > > this is the error I got during training for licence plates.
> > >
> > > ‚Äî
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/590#
> > issuecomment-321977639>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/AL056ZvLnyg_
> > aC1mUg2gH34puAGpWdOOks5sXZhHgaJpZM4LQsPF>
> > > .
> > >
> >
> >
> >
> > --
> > Ray.
> >
> > ‚Äî
> > You are receiving this because you modified the open/close state.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/590#
> issuecomment-322020794>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_
> o3ztjvMQKBue5JIqMU9Qrfx4ng_Mks5sXng2gaJpZM4LQsPF>
>
> > .
> >
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/590#issuecomment-322022245>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAZCIts02B7U5JsRtn2DYu86ZBuyhks5sXoTKgaJpZM4LQsPF>
> .
>
 @Shreeshrii would you please explain about the new traineddata file? where
can the lang.lstm-unicharset file be found ? how can combine_lang_model be
used? thanks

On Mon, Aug 14, 2017 at 11:44 AM, Hanieh Khosravi <hani.khosravi@gmail.com>
wrote:

> for the fine tuning problem:
> the error-rate reaches 0.017 at about 80000 iterations. so with few
> iterations like in tutorial, a low error-rate like 0.01 can not be
> achieved. so you think fine tuning is a wrong solution and I should try
> replacing some layers? as I said before I am trying to train for 40 Persian
> fonts and they are so common.
>
> On Sun, Aug 13, 2017 at 9:38 AM, Shreeshrii <notifications@github.com>
> wrote:
>
>> Ray,
>>
>> I have seen line too small to be recognized when building box/tiff pairs
>> using tesstrain.sh - it is usually related to 'nnn diacritics found' - so
>> it may be related to accents being treated as a separate line.
>>
>> Regarding finetuning, I have experimented a lot with Devanagari - with
>> smaller number of iterations, the reported error rate is higher. And it
>> takes tens of thosands of iterations for it to get more accuracy on
>> training set - not sure of its effect on samples it has not seen. - see
>> https://github.com/Shreeshrii/tess4training/blob/master/README.md
>>
>>
>>
>> ShreeDevi
>> ____________________________________________________________
>> ‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com
>>
>> On Sun, Aug 13, 2017 at 9:44 AM, theraysmith <notifications@github.com>
>> wrote:
>>
>>
>> > Initial problem: (Image too small to scale)
>> > Those images are ridiculously small at 3x48 pixels. Something is going
>> > wrong somewhere with the images.
>> > Are they oriented vertically? The input scaling scales the height to 48,
>> > whatever it starts as, so it looks like your textlines are vertical.
>> >
>> > Fine tuning problem:
>> > The problem is most likely too many iterations. It will hone its
>> accuracy
>> > to whatever training data you give it if you run it for too many
>> > iterations.
>> > See how few iterations are used in the training tutorial for fine
>> tuning.
>> >
>> > On Sat, Aug 12, 2017 at 5:19 AM, hanikh <notifications@github.com>
>> wrote:
>> >
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > 2 Percent improvement time=0, best error was 2.167 @ 14
>> > > At iteration 14/1100/20884, Mean rms=0.049%, delta=0%, char train=0%,
>> > word
>> > > train=0%, skip ratio=1798.6%, New best char error = 0 wrote best
>> > > model:/home/fanasa/tesstutorial/fastuned_from_
>> > fas/fastuned-plates0_14.lstm
>> > > wrote checkpoint.
>> > >
>> > > Finished! Error rate = 0
>> > > this is the error I got during training for licence plates.
>> > >
>> > > ‚Äî
>> > > You are receiving this because you were mentioned.
>> > > Reply to this email directly, view it on GitHub
>> > > <https://github.com/tesseract-ocr/tesseract/issues/590#
>> > issuecomment-321977639>,
>> > > or mute the thread
>> > > <https://github.com/notifications/unsubscribe-auth/AL056ZvLnyg_
>> > aC1mUg2gH34puAGpWdOOks5sXZhHgaJpZM4LQsPF>
>> > > .
>> > >
>> >
>> >
>> >
>> > --
>> > Ray.
>> >
>> > ‚Äî
>> > You are receiving this because you modified the open/close state.
>> > Reply to this email directly, view it on GitHub
>> > <https://github.com/tesseract-ocr/tesseract/issues/590#issue
>> comment-322020794>,
>> > or mute the thread
>> > <https://github.com/notifications/unsubscribe-auth/AE2_o3ztj
>> vMQKBue5JIqMU9Qrfx4ng_Mks5sXng2gaJpZM4LQsPF>
>>
>> > .
>> >
>>
>> ‚Äî
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/590#issuecomment-322022245>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AZFiAZCIts02B7U5JsRtn2DYu86ZBuyhks5sXoTKgaJpZM4LQsPF>
>> .
>>
>
>
 @Shreeshrii I want to train 40 fonts for Arabic and Farsi languages. I have tried to finetune the trained model, but I did not get a good result. I think that happened because the trained fonts were so different from mine. So now I am going to replace a layer. I want to replace just the last layer and I do not want to change the unicharset. So, can I use Arabic.traineddata as the traineddata file needed for training? these are the commands I am using:
mkdir -p ~/tesstutorial/newara_from_ara
training/combine_tessdata -e tessdata/best/Arabic.traineddata \
  ~/tesstutorial/newara_from_ara/ara.lstm

training/lstmtraining --debug_interval 100 \
  --continue_from ~/tesstutorial/newara_from_ara/ara.lstm \
  --traineddata ~/tesstutorial/aratrain/ara/Arabic.traineddata \
  --append_index 5 \
  --model_output ~/tesstutorial/newara_from_ara/base \
  --train_listfile ~/tesstutorial/aratrain/ara.training_files.txt \
  --eval_listfile ~/tesstutorial/araeval/ara.training_files.txt \
  --max_iterations 3000 &>~/tesstutorial/newara_from_ara/basetrain.log @theraysmith 
if is it helpful
i can provide a large amount of font and word list of persian and arabic language for the train material @Shreeshrii  would you please help me with using "replacing layers" as I asked before?
 @roozgar have you tested the new traineddata for arabic? have you tried to train it?   I followed the [steps](https://github.com/tesseract-ocr/tesseract/wiki/Compiling#windows) required to get to .sln file for Visual Studio but I get a bunch of errors.

Here is a [screenshot](http://i.imgur.com/puq3uAR.png). I will check these commands on Monday.

It is the latest version of cppan.

Also the hanging on 7 process still goes on. Yes, managed that problem. Now I will check the clean packages argument later on. 
Stay tuned. After 
`cppan --clean-packages .*jpeg.*`
and 
`cppan --self-upgrade`

I get this 

![clipboard01](https://cloud.githubusercontent.com/assets/5253959/21307804/ca31d14a-c5df-11e6-8a56-7ddfbffbfafa.png)
 I tried with no success.

Still getting the same errors for `tiff`. Look now what I got
![clipboard01](https://cloud.githubusercontent.com/assets/5253959/21316793/096242ac-c60b-11e6-9392-0a77ed2d8ef8.png)
 So I have to install older version of VS ![image](https://cloud.githubusercontent.com/assets/5253959/21345168/b819da0c-c6a7-11e6-8212-6dd38a79531a.png)
 The mistake is mine. 
In the last step I always used:
`cmake .. -DSTATIC=1` instead of `cmake ..`
and now compiles perfectly
 @egorpugin Please see https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-dev/Vx3Z-MReD3c/BMRy_IkSCAAJ

discussion regarding compiling 3.05 branch with vs 2010.

Does 3.05 branch need Leptonica 1.74 and not 1.74.1 ?  Don't remove the 'port' dir.  (can you tell me, how I can directly cherry-pick or merge your pr into my local repo?)

I need to learn this now... (I am just trying something from https://www.startpage.com/do/search?q=github+how+can+I+cherry-pick+a+pull+request ) (I just wanted to confirm, that it solves the problem! ty all)  In leptonica:
- 95% of these are because I use floats, and floating point numbers (like 1.0) are assumed to be doubles.
- Most of the rest are implicit conversions from float to int, where the ints are indices into a 2d image array. Any program may do a few tens of these, so we're talking about a small fraction of a microsecond.

Eliminating these windows compiler warnings is not high on my todo list.  I'll try to remember to add "f" to numbers in files that I'm modifying for other reasons.  * version 6c46cd79546e927bacfcb86ad868005f63f908ff

make does not work:
(version dc12404 worked)

```
libtool: link: ( cd ".libs" && rm -f "libtesseract.la" && ln -s "../libtesseract.la" "libtesseract.la" )
g++ -DHAVE_CONFIG_H -I. -I..  -g -Wall -O0 -DDEBUG -DLOCALEDIR=\"/usr/local/share/locale\" -DUSE_STD_NAMESPACE -I../arch -I../lstm -I../ccutil -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../ccmain -I../wordrec -I../cutil -I../opencl    -I/usr/local/include/leptonica   -g -O2 -std=c++11 -MT tesseract-tesseractmain.o -MD -MP -MF .deps/tesseract-tesseractmain.Tpo -c -o tesseract-tesseractmain.o `test -f 'tesseractmain.cpp' || echo './'`tesseractmain.cpp
mv -f .deps/tesseract-tesseractmain.Tpo .deps/tesseract-tesseractmain.Po
/bin/bash ../libtool  --tag=CXX   --mode=link g++  -g -O2 -std=c++11   -o tesseract tesseract-tesseractmain.o libtesseract.la -fopenmp -ltiff  -lrt -lpthread 
libtool: link: g++ -g -O2 -std=c++11 -o .libs/tesseract tesseract-tesseractmain.o -fopenmp  ./.libs/libtesseract.so /usr/lib/x86_64-linux-gnu/libtiff.so -lrt -lpthread -fopenmp
tesseract-tesseractmain.o: In function `PrintVersionInfo()':
/usr/local/src/tesseract/api/tesseractmain.cpp:57: undefined reference to `getLeptonicaVersion'
/usr/local/src/tesseract/api/tesseractmain.cpp:59: undefined reference to `lept_free'
/usr/local/src/tesseract/api/tesseractmain.cpp:61: undefined reference to `getImagelibVersions'
/usr/local/src/tesseract/api/tesseractmain.cpp:63: undefined reference to `lept_free'
tesseract-tesseractmain.o: In function `main':
/usr/local/src/tesseract/api/tesseractmain.cpp:443: undefined reference to `pixRead'
/usr/local/src/tesseract/api/tesseractmain.cpp:469: undefined reference to `pixDestroy'
./.libs/libtesseract.so: undefined reference to `boxaCreate'
./.libs/libtesseract.so: undefined reference to `l_generateCIDataForPdf'
./.libs/libtesseract.so: undefined reference to `pixWriteMem'
./.libs/libtesseract.so: undefined reference to `boxaGetBox'
./.libs/libtesseract.so: 

....

Makefile:594: recipe for target 'tesseract' failed
make[2]: *** [tesseract] Error 1
make[2]: Leaving directory '/work/usr/local/src/tesseract/api'
Makefile:481: recipe for target 'all-recursive' failed
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory '/work/usr/local/src/tesseract'
Makefile:389: recipe for target 'all' failed
make: *** [all] Error 2
``` I am currently trying to bisect the problem, dc12404 compiles, 23a7330 fails. * b75beda7f9ed4b6ea715060f02293869d2f1de6a works
* a0201831c33f14ece2a7b96eb3ea1f9019d90680 works
* 23a7330c85cf9066df4e65dd17c940218d0b54ef fails @stweil your commit d77a9b7375f969be641afc79028fc7020514ddfb is causing the reported issue. @stweil just as info: I run debian 8 @stweil and did I say "thank you" for your engagement into the project, and your swift reply? (sorry for not having closed this!)  Currently when using debug version, tesseract reports the gitver version. However, even when using the master branch, it reports it as 3.05dev.

Please add a tag on master for 4.0.0alpha so that config.ac gets the correct tag for gitrev. It would also be helpful to remove the ifdef limiting the display of GITREV to the debug build, so that it is displayed in all builds from GitHub source.  It doesn't work when I run lstmtraining usage command like [guider](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#training-from-scratch),and show "scrollview:waiting for server..." in basetrain.log.
First I think the training-tools are not compiled successfully,I reinstall it,but it still error.Then I think change the param "debug_interval" to 0,and it worked.
So am I wrong or it is a bug?
Thanks,sorry for my bad English. @stweil Hi,
I did "make ScrollView.jar" ans add its path to the environment variable  `SCROLLVIEW_PATH` but the program still can't find it. I found in viewer/svutil.cpp `GetEnv(SCROLLVIEW_PATH)` doesn't work, so I changed the path in program. But after started ScrollView, it stopped with error:
`
#A fatal error has been detected by the Java Runtime Environment:
#SIGSEGV (0xb) at pc=0x00007ffff5174009, pid=21858, tid=21859
#JRE version: OpenJDK Runtime Environment (9.0) (build 9-internal+0-2016-04-14-195246.buildd.src)
#Java VM: OpenJDK 64-Bit Server VM (9-internal+0-2016-04-14-195246.buildd.src, mixed mode, tiered, compressed oops, g1 gc, linux-amd64)
#Problematic frame:
#C  [libjava.so+0x1d009]  JNU_GetEnv+0x19

#Core dump will be written. Default location: Core dumps may be processed with "/usr/share/apport/apport %p %s %c %P" (or dumping to /usr/workspace/tesseract/core.21858)

#An error report file with more information is saved as:
#/usr/workspace/tesseract/hs_err_pid21858.log

#If you would like to submit a bug report, please visit:
#http://bugreport.java.com/bugreport/crash.jsp
#The crash happened outside the Java Virtual Machine in native code.
#See problematic frame for where to report the bug.
#sh: 1: kill: No such process
`
Do you have any idea how to solve this? Thanks.  I am running tesseract on this image [http://imgur.com/a/yIX5N](url) and i get a segmentation fault. I am wondering how i can go about to troubleshoot the problem or, in case one of the developers would know if this is a known bug. I am running on Windows and this is the version of tesseract under use:

> c:\> tesseract.exe --version
tesseract 3.05.00dev
 leptonica-1.73
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.6.20 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.3 : libopenjp2 2.1.0  # Problem 
For iOS there are [many forks](https://github.com/gali8/Tesseract-OCR-iOS/network), where it's difficult to figure out what version of Tesseract that it's derived from. 

# Solution
Add a define in the `capi.h` file, like this:

    #define TESSERACT_ID "3.06.01dev, 13e46ae1c4d8acccf15654b0e6ddbddbd363618a"

This will make it easier to determine what version of Tesseract that it is.


I use Tesseract on iPhone and iPad.

I have read the contributing guide.

Thank you for this awesome ocr library. Hi Simon,

There is something like what you asked for, but currently it is only available in the debug build.

https://github.com/tesseract-ocr/tesseract/blob/dc124043ec/configure.ac#L24
https://github.com/tesseract-ocr/tesseract/blob/dc124043ec/api/baseapi.cpp#L139
https://github.com/tesseract-ocr/tesseract/blob/dc124043ec/api/capi.h#L112
 [Tesseract for iOS](https://github.com/gali8/Tesseract-OCR-iOS) comes with `.a` files, there are no `.cpp` files. Just by looking at the code there is no way to tell what version of Tesseract that is being used. One has to actual execute the code to figure out the version.

It would be more helpful if the version string was in a `.h` file. Sorry, I overlooked that it's already here.

In the [baseapi.h](https://github.com/tesseract-ocr/tesseract/blob/master/api/baseapi.h#L23), there is this line. Exactly something like this that I was looking for.

    #define TESSERACT_VERSION_STR "4.00.00alpha"

Thank you for your kind assistance.  I wanted to update my working tesseract (version from August) by pulling and compiling the latest version but `make install` ends with some errors:
```
$ sudo make install
...
Makefile:333: recipe for target 'install-dataDATA' failed
make[3]: *** [install-dataDATA] Error 1
make[3]: Leaving directory '/work/usr/local/src/tesseract/tessdata/configs'
Makefile:403: recipe for target 'install-am' failed
make[2]: *** [install-am] Error 2
make[2]: Leaving directory '/work/usr/local/src/tesseract/tessdata/configs'
Makefile:461: recipe for target 'install-recursive' failed
make[1]: *** [install-recursive] Error 1
make[1]: Leaving directory '/work/usr/local/src/tesseract/tessdata'
Makefile:483: recipe for target 'install-recursive' failed
make: *** [install-recursive] Error 1

$ tesseract --version

tesseract: error while loading shared libraries: libtesseract.so.4: cannot open shared object file: No such file or directory
```

Full output see http://dpaste.com/1AMP4MA.txt

Please can you help? I think it was due to a version conflict on my debian 8 with a packaged-tesseract. After removal of the packaged tesseract, tesseract as such  appears to work (but `make install` errors remain). this is my standard procedure:

```
make clean
git pull
./autogen.sh
./configure --enable-debug
make
sudo make install
```
 Yeah, you are right. I _had_ indeed such a link when I build the last version !
I will now re-compile and report here, and close, if it solved.

Nevertheless, perhaps the "make" could be improved to catch (capture?) such a user mistake. I reported that issue, and close it now. Issue solved by removing my softlink for tessdata. root@scube014:~/qingy-fork-master/src/libraries# make clean
Making clean in libraries
/bin/bash: line 20: cd: libraries: No such file or directory
make: *** [clean-recursive] Error 1
pls find this problem .   What about using pkg-config for detecting Leptonica version? Leptonica provides pkg-config pc file since 1.70. Any volunteer? :laughing:   I have install the icu_54 for it, but have meet some errors when make training tools. 
and  who know which  verision for tesseract4.0 ? @stweil, my system is centos6.5,  Please Google search for icu-dev or icu-devel libs for CentOS. >which version of icu for tesseract 4.0 ?
 
probably version >=4.4

As said by Shree, you need to install the package icu-devel. http://rpmfind.net/linux/rpm2html/search.php?query=libicu-devel it's not icu version problem for me , I just forget to rebuild the static library.  so if you also meet some error , it may other reason caused!  Hi,

building training tools in current master branch under MSYS2/mingw64 throws following Error:
...x86_64-w64-mingw32/bin/ld.exe: cannot find -licui18n

It seems the lib is named differently.

My quick Solution is to change libicu in training/Makefile like so:
sed -i 's/^libicu = -licui18n -licuuc/libicu = -licuin -licuuc/' training/Makefile

Then it's building fine.

Thanks for your awesome Work.
 @stweil 
where can i see the version of mingw-w64?

Ouput from mingw64 console:
$ uname -rv
2.6.0(0.304/5/3) 2016-09-07 20:45

Output from pacman:
$ pacman -Qs icu
local/icu 56.1-1 (libraries)
    International Components for Unicode library
local/icu-devel 56.1-1 (development)
    ICU headers and libraries
local/mingw-w64-x86_64-icu 57.1-1
    International Components for Unicode library (mingw-w64)

This files: libicudata.dll.a libicui18n.dll.a libicuio.dll.a libicule.dll.a libiculx.dll.a libicutest.dll.a libicutu.dll.a libicuuc.dll.a seems to be present in '/usr/lib'

My host is Windows 7 x64, msys2 installed a few days ago, must be pretty up to date. I'm using MSYS2 Installer from https://msys2.github.io/
Have no Problems to compile other Linux Packages... ok, good night. Thanks for your effort! Thumbs up! :-)

It compiles fine now.
Even with the PKGBUILD from Tesseract Wiki:
https://github.com/tesseract-ocr/tesseract/wiki/Compiling#msys2

Thanks for fixing.  ```
$ lstmtraining -U ~/tesstutorial/sanlayer/san.unicharset   --script_dir ../langdata  --debug_interval
0   --continue_from ~/tesstutorial/san_from_layer/san.lstm   --append_index 5 --
net_spec '[Lfx256 O1c105]'   --model_output ~/tesstutorial/san_from_layer/base
 --train_listfile ~/tesstutorial/sanlayer/san.training_files.txt   --eval_listfi
le ~/tesstutorial/saneval/san.training_files.txt   --max_iterations 5000
Loaded file /home/shree/tesstutorial/san_from_layer/base_checkpoint, unpacking..
.
Successfully restored trainer from /home/shree/tesstutorial/san_from_layer/base_checkpoint
Loaded 2094/2094 pages (0-2094) of document /home/shree/tesstutorial/sanlayer/san.Chandas.exp0.lstmf
Loaded 691/691 pages (0-691) of document /home/shree/tesstutorial/saneval/san.Aksharyogini2.exp0.lstmf
Loaded 2104/2104 pages (0-2104) of document /home/shree/tesstutorial/sanlayer/san.Gargi.exp0.lstmf
Loaded 2103/2103 pages (0-2103) of document /home/shree/tesstutorial/sanlayer/san.Sahadeva.exp0.lstmf
Loaded 691/691 pages (0-691) of document /home/shree/tesstutorial/saneval/san.Amiko.exp0.lstmf
Loaded 2101/2101 pages (0-2101) of document /home/shree/tesstutorial/sanlayer/san.Nakula.exp0.lstmf
Loaded 2103/2103 pages (0-2103) of document /home/shree/tesstutorial/sanlayer/san.Lohit_Devanagari.exp0.lstmf
Loaded 2102/2102 pages (0-2102) of document /home/shree/tesstutorial/sanlayer/san.Sarai.exp0.lstmf
Loaded 2102/2102 pages (0-2102) of document /home/shree/tesstutorial/sanlayer/san.Samanata.exp0.lstmf
Loaded 2096/2096 pages (0-2096) of document /home/shree/tesstutorial/sanlayer/san.Santipur_OT_Medium.exp0.lstmf
Loaded 2102/2102 pages (0-2102) of document /home/shree/tesstutorial/sanlayer/san.Kalimati.exp0.lstmf
Loaded 2068/2103 pages (35-2103) of document /home/shree/tesstutorial/sanlayer/san.Siddhanta-Calcutta.exp0.lstmf
Loaded 2062/2097 pages (35-2097) of document /home/shree/tesstutorial/sanlayer/san.Uttara.exp0.lstmf
Loaded 2064/2099 pages (35-2099) of document /home/shree/tesstutorial/sanlayer/san.Siddhanta.exp0.lstmf
Found AVX
Found SSE
Loaded 2065/2100 pages (35-2100) of document /home/shree/tesstutorial/sanlayer/san.Siddhanta-Nepali.exp0.lstmf
Loaded 2064/2100 pages (36-2100) of document /home/shree/tesstutorial/sanlayer/san.Siddhanta-cakravat.exp0.lstmf

At iteration 600/600/600, Mean rms=0.899%, delta=49.539%, char train=102.678%, word train=100%, skip ratio=0%,  New worst char error = 102.678 wrote checkpoint.

At iteration 700/700/700, Mean rms=0.895%, delta=49.137%, char train=102.295%, word train=100%, skip ratio=0%,  New worst char error = 102.295 wrote checkpoint.

At iteration 800/800/800, Mean rms=0.893%, delta=48.75%, char train=102.008%, word train=100%, skip ratio=0%,  New worst char error = 102.008 wrote checkpoint.

At iteration 900/900/900, Mean rms=0.89%, delta=48.199%, char train=101.785%, word train=100%, skip ratio=0%,  New worst char error = 101.785 wrote checkpoint.

lstmtraining: ../ccutil/genericvector.h:696: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
Aborted (core dumped)

``` gdb --args \
 lstmtraining -U ~/tesstutorial/vedic/san.unicharset \
  --script_dir ../langdata  --debug_interval 0 \
  --continue_from ~/tesstutorial/san_vedic/san.lstm \
  --append_index 5 --net_spec '[Lfx384 O1c6000]' \
  --model_output ~/tesstutorial/san_vedic/base \
  --train_listfile ~/tesstutorial/nonvedic/san.training_files.txt \
  --eval_listfile ~/tesstutorial/nonvedic/san.training_files.txt \
  --max_iterations 50000 
 
```
At iteration 900/900/900, Mean rms=0.841%, delta=46.594%, char train=101.075%, word train=100%, skip ratio=0%,  New worst char error = 101.075 wrote checkpoint.
[Thread 0x7f47352d0700 (LWP 422) exited]
[New Thread 0x7f47352d0700 (LWP 423)]
lstmtraining: ../ccutil/genericvector.h:696: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

Program received signal SIGABRT, Aborted.
[Switching to Thread 0x7f47352d0700 (LWP 423)]
0x00007f473f626c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
56      ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.
(gdb) backtrace
#0  0x00007f473f626c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
#1  0x00007f473f62a028 in __GI_abort () at abort.c:89
#2  0x00007f473f61fbf6 in __assert_fail_base (fmt=0x7f473f7703b8 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n",
    assertion=assertion@entry=0x7f47404f9590 "index >= 0 && index < size_used_", file=file@entry=0x7f47404f8fc8 "../ccutil/genericvector.h", line=line@entry=696,
    function=function@entry=0x7f474051cf20 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]")
    at assert.c:92
#3  0x00007f473f61fca2 in __GI___assert_fail (assertion=0x7f47404f9590 "index >= 0 && index < size_used_", file=0x7f47404f8fc8 "../ccutil/genericvector.h", line=696,
    function=0x7f474051cf20 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:101
#4  0x00007f4740457553 in GenericVector<char>::operator[] (this=<optimized out>, this=<optimized out>, index=0) at ../ccutil/genericvector.h:696
#5  0x00007f4740457d28 in operator[] (this=0x7fffca010860, this=0x7fffca010860, index=0) at lstmtrainer.cpp:919
#6  tesseract::LSTMTrainer::ReadTrainingDump (this=this@entry=0x7f47352cf570, data=..., trainer=trainer@entry=0x7f47352cf570) at lstmtrainer.cpp:920
#7  0x000000000040b4fe in tesseract::LSTMTester::RunEvalSync (this=this@entry=0x7fffca0107f0, iteration=0, training_errors=<optimized out>, model_data=...,
    training_stage=0) at lstmtester.cpp:87
#8  0x000000000040ba39 in tesseract::LSTMTester::ThreadFunc (lstmtester_void=0x7fffca0107f0) at lstmtester.cpp:124
#9  0x00007f473d4f8184 in start_thread (arg=0x7f47352d0700) at pthread_create.c:312
#10 0x00007f473f6ea37d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111

(gdb) frame 2
#2  0x00007f473f61fbf6 in __assert_fail_base (fmt=0x7f473f7703b8 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n",
    assertion=assertion@entry=0x7f47404f9590 "index >= 0 && index < size_used_", file=file@entry=0x7f47404f8fc8 "../ccutil/genericvector.h", line=line@entry=696,
    function=function@entry=0x7f474051cf20 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]")
    at assert.c:92
92      in assert.c
(gdb) frame 3
#3  0x00007f473f61fca2 in __GI___assert_fail (assertion=0x7f47404f9590 "index >= 0 && index < size_used_", file=0x7f47404f8fc8 "../ccutil/genericvector.h", line=696,
    function=0x7f474051cf20 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:101
101     in assert.c
(gdb) frame 4
#4  0x00007f4740457553 in GenericVector<char>::operator[] (this=<optimized out>, this=<optimized out>, index=0) at ../ccutil/genericvector.h:696
696       assert(index >= 0 && index < size_used_);
(gdb) frame 5
#5  0x00007f4740457d28 in operator[] (this=0x7fffca010860, this=0x7fffca010860, index=0) at lstmtrainer.cpp:919
919                                        LSTMTrainer* trainer) {
(gdb) frame 6
#6  tesseract::LSTMTrainer::ReadTrainingDump (this=this@entry=0x7f47352cf570, data=..., trainer=trainer@entry=0x7f47352cf570) at lstmtrainer.cpp:920
920       return trainer->ReadSizedTrainingDump(&data[0], data.size());
(gdb) frame 7
#7  0x000000000040b4fe in tesseract::LSTMTester::RunEvalSync (this=this@entry=0x7fffca0107f0, iteration=0, training_errors=<optimized out>, model_data=...,
    training_stage=0) at lstmtester.cpp:87
87        if (!trainer.ReadTrainingDump(model_data, &trainer)) {
(gdb) frame 8
#8  0x000000000040ba39 in tesseract::LSTMTester::ThreadFunc (lstmtester_void=0x7fffca0107f0) at lstmtester.cpp:124
124       lstmtester->test_result_ = lstmtester->RunEvalSync(
(gdb) frame 9
#9  0x00007f473d4f8184 in start_thread (arg=0x7f47352d0700) at pthread_create.c:312
312     pthread_create.c: No such file or directory.
(gdb) frame 10
#10 0x00007f473f6ea37d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111
111     ../sysdeps/unix/sysv/linux/x86_64/clone.S: No such file or directory. 
  
```
  ```
$ combine_tessdata -e tessdata/san.traineddata \
>   ~/tesstutorial/san_from_layer/san.lstm
Extracting tessdata components from tessdata/san.traineddata
Wrote /home/shree/tesstutorial/san_from_layer/san.lstm

$ lstmtraining -U ~/tesstutorial/santrain/san.unicharset \
>   --script_dir ../langdata  --debug_interval 0 \
>   --continue_from ~/tesstutorial/san_from_layer/san.lstm \
>   --append_index 5 --net_spec '[Lfx256 O1c105]' \
>   --model_output ~/tesstutorial/san_from_layer/base \
>   --train_listfile ~/tesstutorial/santrain/san.training_files.txt \
>   --eval_listfile ~/tesstutorial/san_layer/san.training_files.txt \
>   --max_iterations 5000

Loaded file /home/shree/tesstutorial/san_from_layer/san.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!

Continuing from /home/shree/tesstutorial/san_from_layer/san.lstm
Mirror ¬´ of ¬ª is not in unicharset
Appending a new network to an old one!!Setting unichar properties
Setting properties for script Common
Setting properties for script Latin

Unichar 1481=‡§∞‡•ç‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡§ò‡§æ->‡§∞‡•ç‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡§ò‡§æ is too long to encode!!

Warning: given outputs 105 not equal to unicharset of 1938.

Num outputs,weights in serial:
  Lfx256:256, 394240
  Fc1938:1938, 498066
Total weights = 892306

Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc1938] from request [Lfx256 O1c105]

Training parameters:
  Debug interval = 0, weights = 0.1, learning rate = 0.0001, momentum=0.9
Loaded 1837/1837 pages (0-1837) of document /home/shree/tesstutorial/santrain/san.Aksharyogini2.exp0.lstmf
Deserialize header failed: -rw-rw-rw- 1 shree shree  9356879 Dec 10 15:11 san.Chandas.exp0.lstmf
Loaded 1741/1741 pages (0-1741) of document /home/shree/tesstutorial/santrain/san.Amiko.exp0.lstmf
Loaded 1763/1763 pages (0-1763) of document /home/shree/tesstutorial/santrain/san.Baloo.exp0.lstmf
Loaded 1820/1820 pages (0-1820) of document /home/shree/tesstutorial/santrain/san.Aparajita.exp0.lstmf
Loaded 1820/1820 pages (0-1820) of document /home/shree/tesstutorial/santrain/san.Biryani.exp0.lstmf
Loaded 1822/1822 pages (0-1822) of document /home/shree/tesstutorial/santrain/san.Arya.exp0.lstmf
Loaded 1824/1824 pages (0-1824) of document /home/shree/tesstutorial/santrain/san.Asar.exp0.lstmf
Loaded 1837/1837 pages (0-1837) of document /home/shree/tesstutorial/santrain/san.Amita.exp0.lstmf
Loaded 1816/1816 pages (0-1816) of document /home/shree/tesstutorial/santrain/san.Annapurna_SIL.exp0.lstmf

First document cannot be empty!!
num_pages_per_doc_ > 0:Error:Assert failed:in file imagedata.cpp, line 656
Segmentation fault (core dumped)

```
Here is the info re lstmf files in /home/shree/tesstutorial/santrain/

```
$ ll /home/shree/tesstutorial/santrain/*.lstmf
-rw-rw-rw- 1 shree shree 3601682 Dec  9 21:16 /home/shree/tesstutorial/santrain/san.Aksharyogini2.exp0.lstmf
-rw-rw-rw- 1 shree shree 3834940 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Amiko.exp0.lstmf
-rw-rw-rw- 1 shree shree 5002657 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Amita.exp0.lstmf
-rw-rw-rw- 1 shree shree 3971772 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Annapurna_SIL.exp0.lstmf
-rw-rw-rw- 1 shree shree 3613720 Dec  9 21:16 /home/shree/tesstutorial/santrain/san.Aparajita.exp0.lstmf
-rw-rw-rw- 1 shree shree 4275301 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Arya.exp0.lstmf
-rw-rw-rw- 1 shree shree 4149621 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Asar.exp0.lstmf
-rw-rw-rw- 1 shree shree 3701423 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Baloo.exp0.lstmf
-rw-rw-rw- 1 shree shree 3696594 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Biryani.exp0.lstmf
-rw-rw-rw- 1 shree shree 3689358 Dec  8 16:26 /home/shree/tesstutorial/santrain/san.Chandas.exp0.lstmf
-rw-rw-rw- 1 shree shree 4567407 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Dekko.exp0.lstmf
-rw-rw-rw- 1 shree shree 3706688 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Ek_Mukta.exp0.lstmf
-rw-rw-rw- 1 shree shree 3697439 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Gargi.exp0.lstmf
-rw-rw-rw- 1 shree shree 4103892 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Glegoo.exp0.lstmf
-rw-rw-rw- 1 shree shree 3585398 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Hind_Medium.exp0.lstmf
-rw-rw-rw- 1 shree shree 3986588 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Kadwa.exp0.lstmf
-rw-rw-rw- 1 shree shree 4196205 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Kalam.exp0.lstmf
-rw-rw-rw- 1 shree shree 4030697 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Kalimati.exp0.lstmf
-rw-rw-rw- 1 shree shree 3013510 Dec  9 21:29 /home/shree/tesstutorial/santrain/san.Kokila.exp0.lstmf
-rw-rw-rw- 1 shree shree 3985691 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Kurale.exp0.lstmf
-rw-rw-rw- 1 shree shree 3951000 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Laila_Medium.exp0.lstmf
-rw-rw-rw- 1 shree shree 3935943 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Lohit_Devanagari.exp0.lstmf
-rw-rw-rw- 1 shree shree 4053036 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Mangal.exp0.lstmf
-rw-rw-rw- 1 shree shree 3769371 Dec  8 16:25 /home/shree/tesstutorial/santrain/san.Nakula.exp0.lstmf
-rw-rw-rw- 1 shree shree 3988872 Dec  8 16:26 /home/shree/tesstutorial/santrain/san.Sahadeva.exp0.lstmf
-rw-rw-rw- 1 shree shree 3700015 Dec  8 16:26 /home/shree/tesstutorial/santrain/san.Sanskrit_2003.exp0.lstmf
-rw-rw-rw- 1 shree shree 3743783 Dec  8 16:28 /home/shree/tesstutorial/santrain/san.Santipur_OT_Medium.exp0.lstmf
-rw-rw-rw- 1 shree shree 4214334 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Tillana_Medium.exp0.lstmf
-rw-rw-rw- 1 shree shree 3099048 Dec  9 21:29 /home/shree/tesstutorial/santrain/san.Utsaah.exp0.lstmf
-rw-rw-rw- 1 shree shree 3716830 Dec  8 16:28 /home/shree/tesstutorial/santrain/san.Uttara.exp0.lstmf
-rw-rw-rw- 1 shree shree 4141319 Dec  9 21:32 /home/shree/tesstutorial/santrain/san.Yatra_One.exp0.lstmf

``` Was it solved? Hello, is this problem resolved?  I am fairly sure that pixGenHalftoneMask() (and the wrapper pixGenerateHalftoneMask()) are the only leptonica functions in tesseract that have a debug argument.

It should be OK in the new tesseract (4.00) to use pixGenerateHalftoneMask() with NULL for the debug pixa.  It would also be nice at the same time for the debug calls to the deprecated functions pixDisplayWrite() and pixDisplayWriteFormat() to be removed, because there is no reason that tesseract needs to generate these debug images. I believe that Ray is removing all use of temp files due to pixDisplayWrite() in tesseract.  ```
Page 2
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Loaded 41/41 pages (0-41) of document /tmp/tmp.tY7p2Ue5TC/san/san.Baloo.exp0.lstmf
Bad box coordinates in boxfile string! ‡§µ‡§ø‡§§‡§æ‡§É ‡•§ ‡§®‡§æ‡§®‡§æ‡§∂‡§∏‡•ç‡§§‡•ç‡§∞‡§™‡•ç‡§∞‡§π‡§∞‡§£‡§æ‡§É ‡§∏‡§∞‡•ç‡§µ‡•á 1576 3968 2121 4022 0
Bad box coordinates in boxfile string! ‡§∞‡§ø‡§¶‡•á‡§µ‡§®‡§æ ‡•• ‡•®-‡•®‡•Æ‡•• ‡§Ü‡§∂‡•ç‡§ö‡§∞‡•ç‡§Ø 1526 2958 1995 3016 1
Bad box coordinates in boxfile string! ‡§§‡§ø ‡•• ‡•®-‡•¨‡•™‡•• ‡§™‡•ç‡§∞‡§∏‡§æ‡§¶‡•á ‡§∏‡§∞‡•ç‡§µ 1341 4637 1759 4693 2
Bad box coordinates in boxfile string! ‡§§‡§ø ‡§™‡•Ç‡§∞‡•Å‡§∑‡§É ‡•• ‡•©-‡•ß‡•Ø‡•• ‡§ï‡§∞‡•ç‡§Æ 1063 2386 1484 2451 2
Bad box coordinates in boxfile string! ‡§µ‡§ø‡§≠‡§æ‡§ó‡§Ø‡•ã‡§É ‡•§ ‡§ó‡•Å‡§£‡§æ ‡§ó‡•Å‡§£‡•á‡§∑‡•Å ‡§µ‡§∞‡•ç‡§§ 420 1710 909 1776 2
Bad box coordinates in boxfile string! ‡§®‡•ç‡§•‡§ø‡§®‡•å ‡•• ‡•©-‡•©‡•™‡•• ‡§∂‡•ç‡§∞‡•á‡§Ø‡§æ‡§®‡•ç‡§∏‡•ç‡§µ‡§ß‡§∞‡•ç‡§Æ‡•ã 1447 1278 1982 1335 2
Bad box coordinates in boxfile string! ‡§µ‡§ø‡§®‡§æ‡§∂‡§æ‡§Ø ‡§ö ‡§¶‡•Å‡§∑‡•ç‡§ï‡•É‡§§‡§æ‡§Æ‡•ç ‡•§ ‡§ß‡§∞‡•ç‡§Æ 1364 4402 1863 4475 3
Bad box coordinates in boxfile string! ‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•ç‡§Æ‡§®‡•Å‡§∑‡•ç‡§Ø‡•á‡§∑‡•Å ‡§∏ ‡§Ø‡•Å‡§ï‡•ç‡§§‡§É ‡§ï‡•É‡§§‡•ç‡§∏‡•ç‡§®‡§ï‡§∞‡•ç‡§Æ 1206 3622 1812 3694 3

``` This was on box files created by text2image. https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#error-messages-from-training

Try running text2inage with this option: `--output_word_boxes` >Try running text2inage with this option: --output_word_boxes

That creates a unicharset with words

and I get additional errors about Utf8 buffer too big, ```
Detected 15 diacritics
Loaded 2742/2742 pages (1-2742) of document /tmp/tmp.aA4DsVmpNZ/hin/hin.CDAC-GISTSurekh.exp0.lstmf
Page 77
Page 97
Bad box coordinates in boxfile string! ‡§¶‡§ø ['‡§è\\^', 25 ‡§∏‡§∞‡•ç‡§µ 778 1653 1230 1732 92
Page 82
Loaded 3159/3159 pages (1-3159) of document /tmp/tmp.aA4DsVmpNZ/hin/hin.FreeSans.exp0.lstmf
Page 80
```

Still getting the errors. The box file is generated by text2image. See https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00

```
Bad box coordinates in boxfile string! 

The LSTM trainer only needs bounding box information for a complete textline,
instead of at a character level, but if you put spaces in the box string, like this:

<text for line including spaces> <left> <bottom> <right> <top> <page>
the parser will be confused and give you the error message.
```

text2image program may need to be fixed if too many errors of this kind are reported.   ```
Bad box coordinates in boxfile string! ‡§µ‡§ø‡§§‡§æ‡§É ‡•§ ‡§®‡§æ‡§®‡§æ‡§∂‡§∏‡•ç‡§§‡•ç‡§∞‡§™‡•ç‡§∞‡§π‡§∞‡§£‡§æ‡§É ‡§∏‡§∞‡•ç‡§µ‡•á 1576 3968 2121 4022 0

Box file format error on line 512; ignored
Bad box coordinates in boxfile string! ‡§∞‡§ø‡§¶‡•á‡§µ‡§®‡§æ ‡•• ‡•®-‡•®‡•Æ‡•• ‡§Ü‡§∂‡•ç‡§ö‡§∞‡•ç‡§Ø 1526 2958 1995 3016 1

Box file format error on line 4234; ignored
Bad box coordinates in boxfile string! ‡§§‡§ø ‡•• ‡•®-‡•¨‡•™‡•• ‡§™‡•ç‡§∞‡§∏‡§æ‡§¶‡•á ‡§∏‡§∞‡•ç‡§µ 1341 4637 1759 4693 2

Box file format error on line 6128; ignored
Bad box coordinates in boxfile string! ‡§§‡§ø ‡§™‡•Ç‡§∞‡•Å‡§∑‡§É ‡•• ‡•©-‡•ß‡•Ø‡•• ‡§ï‡§∞‡•ç‡§Æ 1063 2386 1484 2451 2

Box file format error on line 7619; ignored
Bad box coordinates in boxfile string! ‡§µ‡§ø‡§≠‡§æ‡§ó‡§Ø‡•ã‡§É ‡•§ ‡§ó‡•Å‡§£‡§æ ‡§ó‡•Å‡§£‡•á‡§∑‡•Å ‡§µ‡§∞‡•ç‡§§ 420 1710 909 1776 2

Box file format error on line 8043; ignored
Bad box coordinates in boxfile string! ‡§®‡•ç‡§•‡§ø‡§®‡•å ‡•• ‡•©-‡•©‡•™‡•• ‡§∂‡•ç‡§∞‡•á‡§Ø‡§æ‡§®‡•ç‡§∏‡•ç‡§µ‡§ß‡§∞‡•ç‡§Æ‡•ã 1447 1278 1982 1335 2

```  ```
=== Phase UP: Generating unicharset and unichar properties files ===
[Fri Dec 9 21:53:09 DST 2016] /usr/local/bin/unicharset_extractor -D /tmp/tmp.tY7p2Ue5TC/san/ /tmp/tmp.tY7p2Ue5TC/san/san.Aksharyogini2.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Amiko.exp0.box /tm
p/tmp.tY7p2Ue5TC/san/san.Amita.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Annapurna_SIL.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Aparajita.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Arya.exp0.box /tmp/tmp.tY
7p2Ue5TC/san/san.Asar.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Baloo.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Biryani.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Dekko.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.E
k_Mukta.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Gargi.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Glegoo.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Hind_Medium.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Kadwa.exp0
.box /tmp/tmp.tY7p2Ue5TC/san/san.Kalam.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Kalimati.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Kokila.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Kurale.exp0.box /tmp/tmp.
tY7p2Ue5TC/san/san.Laila_Medium.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Lohit_Devanagari.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Mangal.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Tillana_Medium.exp0.box
/tmp/tmp.tY7p2Ue5TC/san/san.Utsaah.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Yatra_One.exp0.box
Utf8 buffer too big, size=39 for ‡§∞‡•ç‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡§æ‡§ó‡•ç‡§®‡•å

``` https://github.com/tesseract-ocr/tesseract/blob/9c7e99b04197/ccutil/unicharset.cpp#L615

https://github.com/tesseract-ocr/tesseract/blob/da4c064c2eeb/ccutil/unichar.h#L30 > // Maximum number of characters that can be stored in a UNICHAR. Must be
// at least 4. Must not exceed 31 without changing the coding of length.
#define UNICHAR_LEN 30

```
Utf8 buffer too big, size=39 for ‡§∞‡•ç‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡§æ‡§ó‡•ç‡§®‡•å
```

For some reason, this whole word is being used as a unit in unicharset, rather than the composing Devanagari syllables - ‡§∞‡•ç‡§¨‡•ç‡§∞ ‡§π‡•ç‡§Æ‡§æ ‡§ó‡•ç‡§®‡•å  As per https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#combining-the-output-files

```
Either of these files can be converted to a recognition model as follows:

training/lstmtraining --model_output ~/tesstutorial/eng_from_chi/eng.lstm \
  --continue_from ~/tesstutorial/eng_from_chi/base_checkpoint

Finally, combine your new model with the language model files into a traineddata file:

training/combine_tessdata -o tessdata/eng.traineddata \
  ~/tesstutorial/eng_from_chi/eng.lstm \
  ~/tesstutorial/engtrain/eng.lstm-number-dawg \
  ~/tesstutorial/engtrain/eng.lstm-punc-dawg \
  ~/tesstutorial/engtrain/eng.lstm-word-dawg

The dawg files are optional. It will work without them, but they do usually provide some small improvement in accuracy.

NOTE  The unicharset used for the lstm has to match the unicharset used to generate the lstm-*-dawg files, but doesn't have to match the unicharset for the inttemp and base tesseract dawg files.

```
1. The given command does not create the recognition model. For that the command has to be appended with --stop_training.

```
training/lstmtraining --model_output ~/tesstutorial/sanskrit2003_from_full/san.lstm \
  --continue_from ~/tesstutorial/sanskrit2003_from_full/sanskrit2003_checkpoint \
  --stop_training
 ```

@theraysmith  Please review whether the modified commands are ok. thanks.

Wiki page needs to be updated for it. See Ray's comment re unicharset in https://github.com/tesseract-ocr/tesseract/issues/527

The unicharset from LSTM Training is included within the .LSTM model file. 

However this means that the old versions of dawg2wordlist cannot be used with the LSTM dawg files to get the original lists. https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Finetune Also see comments for https://github.com/tesseract-ocr/tesseract/issues/634

for first step of LSTM training i.e. creating lstmf files, use both --linedata_only --noextract_font_properties

```
training/tesstrain.sh --fonts_dir /home/shree/.fonts --lang bih  \
  --linedata_only --noextract_font_properties
  --langdata_dir ../langdata --tessdata_dir ./tessdata \
  --output_dir ~/tesstutorial/bihnew
```
  ```
$   training/lstmtraining --model_output ~/tesstutorial/sanskrit2003_from_full/sanskrit2003 \
>   --continue_from ~/tesstutorial/sanskrit2003_from_full/san.lstm \
>   --train_listfile ~/tesstutorial/santrain/san.training_files.txt \
>   --target_error_rate 0.01
Loaded file /home/shree/tesstutorial/sanskrit2003_from_full/sanskrit2003_checkpoint, unpacking...
Successfully restored trainer from /home/shree/tesstutorial/sanskrit2003_from_full/sanskrit2003_checkpoint
Loaded 1746/1746 pages (0-1746) of document /home/shree/tesstutorial/santrain/san.Chandas.exp0.lstmf
Loaded 345/1760 pages (1415-1760) of document /home/shree/tesstutorial/santrain/san.Uttara.exp0.lstmf
Loaded 1814/1814 pages (0-1814) of document /home/shree/tesstutorial/santrain/san.Gargi.exp0.lstmf
Found AVX
Found SSE
At iteration 1808/17200/17229, Mean rms=0.336%, delta=0.129%, char train=0.41%, word train=1.751%, skip ratio=0.2%,  New worst char error = 0.41 wrote checkpoint.

Encoding of string failed! Failure bytes: ffffffc2 ffffffa3 20 ffffffe0 ffffffa4 ffffffb8 ffffffe0 ffffffa4 ffffffb0 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffb5 ffffffe0 ffffffa5 ff
ffff8d ffffffe0 ffffffa4 ffffffb5
Can't encode transcription: ‡§µ‡•ç‡§Ø‡§§‡§∞‡•ç‡§ï‡§ø ‡•ß‡•™. ‡§≠‡§µ‡§§‡§ø ‡•©‡•≠‡•• ¬£ ‡§∏‡§∞‡•ç‡§µ‡•ç‡§µ
At iteration 1818/17300/17330, Mean rms=0.334%, delta=0.13%, char train=0.404%, word train=1.632%, skip ratio=0.3%,  wrote checkpoint.


``` Still getting the errors with the following version -
```

 tesseract -v
tesseract 4.00.00alpha-219-gc124f87
 leptonica-1.74
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

```

```

Can't encode transcription: ‡§∏‡§ó‡•Å‡§®‡§≤ ‡§â‡§†‡•à‡§≤‡§ï‡§æ ‡§¶‡•á‡§â‡§§‡§æ ‡§®‡•á‡§â‡§§‡§æ ‡§≤‡§µ‡§∞‡§®‡§æ ‡§≤‡•ã‡§π‡§Æ‡§æ‡§® ‡§ï‡•Å‡§¶‡§æ‡§∞
Encoding of string failed! Failure bytes: ffffffe0 ffffffa5 ffffff9c ffffffe0 ffffffa4 ffffffbf ffffffe0 ffffffa4 ffffffaf ffffffe0 ffffffa4 ffffffbe 20 ffffffe0 fffff
fa4 ffffffb9 ffffffe0 ffffffa5 ffffff9c ffffffe0 ffffffa4 ffffffbf ffffffe0 ffffffa4 ffffffaf ffffffe0 ffffffa4 ffffffbe 20 ffffffe0 ffffffa4 ffffffb2 ffffffe0 ffffffa
4 ffffffbe ffffffe0 ffffffa4 ffffffa6 ffffffe0 ffffffa4 ffffffa8 ffffffe0 ffffffa4 ffffffbe 20 ffffffe0 ffffffa4 ffffff85 ffffffe0 ffffffa4 ffffffa7 ffffffe0 ffffffa4
ffffffb8 ffffffe0 ffffffa5 ffffff87 ffffffe0 ffffffa4 ffffffb0 ffffffe0 ffffffa5 ffffff80 20 ffffffe0 ffffffa4 ffffffb8 ffffffe0 ffffffa5 ffffff81 ffffffe0 ffffffa4 ff
ffffac ffffffe0 ffffffa5 ffffff81 ffffffe0 ffffffa4 ffffff95 ffffffe0 ffffffa4 ffffffa8 ffffffe0 ffffffa4 ffffffbe
Can't encode transcription: ‡§¨‡§ø‡§∏‡§π‡§∞‡•Ä ‡§∏‡•ú‡§ø‡§Ø‡§æ ‡§π‡•ú‡§ø‡§Ø‡§æ ‡§≤‡§æ‡§¶‡§®‡§æ ‡§Ö‡§ß‡§∏‡•á‡§∞‡•Ä ‡§∏‡•Å‡§¨‡•Å‡§ï‡§®‡§æ
Encoding of string failed! Failure bytes: ffffffe0 ffffffa5 ffffff9c ffffffe0 ffffffa4 ffffffbf ffffffe0 ffffffa4 ffffffaf ffffffe0 ffffffa4 ffffffa8 20 ffffffe0 fffff
fa4 ffffffac ffffffe0 ffffffa5 ffffff81 ffffffe0 ffffffa4 ffffffa6 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffa7 ffffffe0 ffffffa4 ffffffbf 20 ffffffe0 ffffffa
4 ffffff97 ffffffe0 ffffffa5 ffffff81 ffffffe0 ffffffa4 ffffffaa ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffa4 ffffffe0 ffffffa4 ffffffbe 20 ffffffe0 ffffffa4
ffffffb6 ffffffe0 ffffffa4 ffffffbe ffffffe0 ffffffa4 ffffffb8 ffffffe0 ffffffa4 ffffffa8 ffffffe0 ffffffa4 ffffffae ffffffe0 ffffffa5 ffffff87 20 ffffffe0 ffffffa4 ff
ffffb8 ffffffe0 ffffffa5 ffffff81 ffffffe0 ffffffa4 ffffffa6 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffa7 ffffffe0 ffffffa4 ffffffbe 20 ffffffe0 ffffffa4 ffff
ff9c ffffffe0 ffffffa4 ffffff81 ffffffe0 ffffffa4 ffffffa4 ffffffe0 ffffffa4 ffffffb8 ffffffe0 ffffffa4 ffffffbe ffffffe0 ffffffa4 ffffffb0 20 ffffffe0 ffffffa4 ffffff
a8 ffffffe0 ffffffa4 ffffffbf ffffffe0 ffffffa4 ffffff97 ffffffe0 ffffffa5 ffffff81 ffffffe0 ffffffa4 ffffffa8 ffffffe0 ffffffa4 ffffffbf ffffffe0 ffffffa4 ffffffaf ff
ffffe0 ffffffa4 ffffffbe ffffffe0 ffffffa4 ffffff81
Can't encode transcription: ‡§ö‡•Ç‡•ú‡§ø‡§Ø‡§® ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø ‡§ó‡•Å‡§™‡•ç‡§§‡§æ ‡§∂‡§æ‡§∏‡§®‡§Æ‡•á ‡§∏‡•Å‡§¶‡•ç‡§ß‡§æ ‡§ú‡§Å‡§§‡§∏‡§æ‡§∞ ‡§®‡§ø‡§ó‡•Å‡§®‡§ø‡§Ø‡§æ‡§Å
Encoding of string failed! Failure bytes: ffffffe0 ffffffa5 ffffff9c ffffffe0 ffffffa4 ffffff87 ffffffe0 ffffffa4 ffffffb2 ffffffe0 ffffffa5 ffffff82 ffffffe0 ffffffa4
 ffffff81 20 ffffffe0 ffffffa4 ffffffaa ffffffe0 ffffffa5 ffffff8b ffffffe0 ffffffa4 ffffffa5 ffffffe0 ffffffa4 ffffffbe 20 ffffffe0 ffffffa4 ffffffac ffffffe0 ffffffa
5 ffffff8b ffffffe0 ffffffa4 ffffffa5 ffffffe0 ffffffa4 ffffffbe 20 ffffffe0 ffffffa4 ffffffae ffffffe0 ffffffa5 ffffff8b ffffffe0 ffffffa4 ffffffa5 ffffffe0 ffffffa4
ffffffbe 20 ffffffe0 ffffffa4 ffffffb8 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffb5 ffffffe0 ffffffa5 ffffff87 ffffffe0 ffffffa4 ffffff9a ffffffe0 ffffffa5 ff
ffff8d ffffffe0 ffffffa4 ffffff9b ffffffe0 ffffffa4 ffffffbe ffffffe0 ffffffa4 ffffffb8 ffffffe0 ffffffa4 ffffff81 20 ffffffe0 ffffffa4 ffffffaa ffffffe0 ffffffa4 ffff
ffbe ffffffe0 ffffffa4 ffffffb0 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffff9f ffffffe0 ffffffa5 ffffff80 20 ffffffe0 ffffffa4 ffffffb2 ffffffe0 ffffffa5 ffffff
9c ffffffe0 ffffffa4 ffffff95 ffffffe0 ffffffa4 ffffffbf ffffffe0 ffffffa4 ffffffaf ffffffe0 ffffffa4 ffffffa8
Can't encode transcription: ‡§¶‡•å‡•ú‡§á‡§≤‡•Ç‡§Å ‡§™‡•ã‡§•‡§æ ‡§¨‡•ã‡§•‡§æ ‡§Æ‡•ã‡§•‡§æ ‡§∏‡•ç‡§µ‡•á‡§ö‡•ç‡§õ‡§æ‡§∏‡§Å ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§≤‡•ú‡§ï‡§ø‡§Ø‡§®

``` @Also seen in finetune of Arabic
```

lstmtraining --model_output ~/tesstutorial/aratuned_from_ara/aratuned   --continue_from ~/tesstutorial/aratuned_from_ara/ara.lstm   --train_listfile ~/tesstutorial/ara/ara.training_files.txt     --eval_listfile ~/tesstutorial/aratest/ara.training_files.txt   --target_error_
rate 0.0001
Loaded file /home/shree/tesstutorial/aratuned_from_ara/aratuned_checkpoint, unpacking...
Successfully restored trainer from /home/shree/tesstutorial/aratuned_from_ara/aratuned_checkpoint
Loaded 229/229 pages (1-229) of document /home/shree/tesstutorial/ara/ara.Amiri.exp0.lstmf
Loaded 232/232 pages (1-232) of document /home/shree/tesstutorial/ara/ara.Arial.exp0.lstmf
Loaded 4/4 pages (1-4) of document /home/shree/tesstutorial/aratest/ara.Times_New_Roman.exp0.lstmf
Encoding of string failed! Failure bytes: ffffffd9 ffffff8e ffffffd9 ffffff8a ffffffd9 ffffff82 ffffffd9 ffffff90 ffffffd8 ffffffaf ffffffd9 ffffff90 ffffffd8 ffffffa7
 ffffffd8 ffffffb5 ffffffd9 ffffff8e 20 ffffffd9 ffffff85 ffffffd9 ffffff92 ffffffd8 ffffffaa ffffffd9 ffffff8f ffffffd9 ffffff86 ffffffd9 ffffff92 ffffffd9 ffffff83 f
fffffd9 ffffff8f 20 ffffffd9 ffffff86 ffffffd9 ffffff92 ffffffd8 ffffffa5 ffffffd9 ffffff90 20 ffffffd8 ffffffa7 ffffffd9 ffffff84 ffffffd9 ffffff84 ffffffd9 ffffff91
ffffffd9 ffffff8e ffffffd9 ffffff87 ffffffd9 ffffff90 20 ffffffd9 ffffff86 ffffffd9 ffffff90 ffffffd9 ffffff88 ffffffd8 ffffffaf ffffffd9 ffffff8f 20 ffffffd9 ffffff86
 ffffffd9 ffffff92 ffffffd9 ffffff85 ffffffd9 ffffff90 20 ffffffd9 ffffff85 ffffffd9 ffffff92 ffffffd9 ffffff83 ffffffd9 ffffff8f ffffffd8 ffffffa1 ffffffd9 ffffff8e f
fffffd8 ffffffa7 ffffffd8 ffffffaf ffffffd9 ffffff8e ffffffd9 ffffff87 ffffffd9 ffffff8e ffffffd8 ffffffb4 ffffffd9 ffffff8f
Can't encode transcription: ŸÜŸéŸäŸÇŸêÿØŸêÿßÿµŸé ŸÖŸíÿ™ŸèŸÜŸíŸÉŸè ŸÜŸíÿ•Ÿê ÿßŸÑŸÑŸëŸéŸáŸê ŸÜŸêŸàÿØŸè ŸÜŸíŸÖŸê ŸÖŸíŸÉŸèÿ°ŸéÿßÿØŸéŸáŸéÿ¥Ÿè
Loaded 231/231 pages (1-231) of document /home/shree/tesstutorial/ara/ara.Arial_Unicode_MS.exp0.lstmf
Encoding of string failed! Failure bytes: ffffffd9 ffffff8e ffffffd9 ffffff88 ffffffd8 ffffffb1 ffffffd9 ffffff8f ffffffd8 ffffffb5 ffffffd9 ffffff90 ffffffd8 ffffffa8
 ffffffd9 ffffff92 ffffffd9 ffffff8a ffffffd9 ffffff8f 20 ffffffd9 ffffff84 ffffffd9 ffffff8e ffffffd8 ffffffa7 20 ffffffd8 ffffffaa ffffffd9 ffffff8d ffffffd8 ffffffa
7 ffffffd9 ffffff85 ffffffd9 ffffff8e ffffffd9 ffffff84 ffffffd9 ffffff8f ffffffd8 ffffffb8 ffffffd9 ffffff8f 20 ffffffd9 ffffff8a ffffffd9 ffffff81 ffffffd9 ffffff90
20 ffffffd9 ffffff85 ffffffd9 ffffff92 ffffffd9 ffffff87 ffffffd9 ffffff8f ffffffd9 ffffff83 ffffffd9 ffffff8e ffffffd8 ffffffb1 ffffffd9 ffffff8e ffffffd8 ffffffaa ff
ffffd9 ffffff8e ffffffd9 ffffff88 ffffffd9 ffffff8e 20 ffffffd9 ffffff85 ffffffd9 ffffff92 ffffffd9 ffffff87 ffffffd9 ffffff90 ffffffd8 ffffffb1 ffffffd9 ffffff90 ffff
ffd9 ffffff88 ffffffd9 ffffff86 ffffffd9 ffffff8f ffffffd8 ffffffa8 ffffffd9 ffffff90
Can't encode transcription: ŸÜŸéŸàÿ±ŸèÿµŸêÿ®ŸíŸäŸè ŸÑŸéÿß ÿ™ŸçÿßŸÖŸéŸÑŸèÿ∏Ÿè ŸäŸÅŸê ŸÖŸíŸáŸèŸÉŸéÿ±Ÿéÿ™ŸéŸàŸé ŸÖŸíŸáŸêÿ±ŸêŸàŸÜŸèÿ®Ÿê
Encoding of string failed! Failure bytes: ffffffd9 ffffff92 ffffffd9 ffffff87 ffffffd9 ffffff90 
``` Wiki does not seem to have this section,

https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00

TrainingTesseract 4.00
Stefan Weil edited this page 28 days ago ¬∑ 9 revisions

We have a github outage in India just now, not sure if this is related to
that or wiki updation is still in todo.


ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Thu, Jan 12, 2017 at 5:04 AM, theraysmith <notifications@github.com>
wrote:

> See new section in trainingtesseract-4.00
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/549#issuecomment-272030162>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o2Kj43a8uaNjjhRJt8EBMPHq9-kgks5rRWcEgaJpZM4LIjyK>
> .
>
 It is working correctly in Spain, Thank you all for the incredible amount of work that you have all done. I don't see the changes either.

The wiki can be cloned as a git repo. Ray probably did some edits locally, but didn't 'push' them yet. ```

Encoding of string failed! Failure bytes: 9 31 32 30 30 45 6d 69 6c 69 65 2c 68 61 6e 73 4b 6f 6e 65 2e
Can't encode transcription: M√∏ller.     1200Emilie,hansKone.

```
when trying to train frk @Shreeshrii 
Is this issue resolved coz I'm getting the same when training with Telugu language.. Please see https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#error-messages-from-training

```
Encoding of string failed! results when the text string for a training image 
cannot be encoded using the given unicharset. 

Possible causes are:

- There  is an un-represented character in the text, say a British Pound sign that is not in your unicharset.

- A  stray unprintable character (like tab or a control character) in the text.

- There  is an un-represented Indic grapheme/aksara in the text.

In any case it will result in that training image being ignored by the trainer. 

If the error is infrequent, it is harmless, but it may indicate that your unicharset is inadequate for representing the language that you are training. @harinath141 If you are getting a lot of these errors during finetune, try replace top layer training. You can use the box/tiff pairs generated for finetune. Commands will be similar to the following:

```
mkdir -p ~/tesstutorial/tellayer_from_tel 

combine_tessdata -e ../tessdata/tel.traineddata \
  ~/tesstutorial/tellayer_from_tel/tel.lstm
  
lstmtraining -U ~/tesstutorial/tel/tel.unicharset \
  --script_dir ../langdata  --debug_interval 0 \
  --continue_from ~/tesstutorial/tellayer_from_tel/tel.lstm \
  --append_index 5 --net_spec '[Lfx256 O1c105]' \
  --model_output ~/tesstutorial/tellayer_from_tel/tellayer \
  --train_listfile ~/tesstutorial/tel/tel.training_files.txt \
  --target_error_rate 0.01
``` ~/tesstutorial/tel/ should have your .lstmf files. Thank you @Shreeshrii I'll try to replace top layer @harinath141 

When you use ` --debug_interval 0` you will see messages every 100 iterations like the following:

```
At iteration 45909/58500/58569, Mean rms=0.639%, delta=0.621%, char train=1.861%, word train=13.302%, skip ratio=0%,  wrote checkpoint.

At iteration 45960/58600/58669, Mean rms=0.64%, delta=0.616%, char train=1.844%, word train=12.933%, skip ratio=0%,  wrote checkpoint.

2 Percent improvement time=14052, best error was 3.697 @ 31958
At iteration 46010/58700/58769, Mean rms=0.634%, delta=0.561%, char train=1.686%, word train=12.343%, skip ratio=0%,  New best char error = 1.686 wrote best model:/hom
e/shree/tesstutorial/khmlayer1_from_khm/khm1.686_46010.lstm wrote checkpoint.

```
When you use `--debug_interval -1` , messages such as the following will be shown for every iteration:

```

Iteration 59400: ALIGNED TRUTH : ·ûò·û∂·ûì·ûö·ûº·ûî·ûÜ·üí·ûò·û∂·üÜ ·û¢·üÅ·ûü·üä·û∏·ûõ·û∏·ûä·û∂
Iteration 59400: BEST OCR TEXT : ·ûò·û∂·ûì·ûö·ûº·ûî·ûÜ·üí·ûò·û∂·üÜ ·û¢·üÅ·ûü·üä·û∏·ûõ·û∏·ûä·û∂
File /tmp/tmp.BjsuuQ0dgJ/khm/khm.Noto_Serif_Khmer_Bold.exp0.lstmf page 53 (Perfect):
Mean rms=0.646%, delta=0.553%, train=1.878%(13.168%), skip ratio=0.1%
Iteration 59401: ALIGNED TRUTH : ·ûÜ·üí·ûÄ·üÄ·ûõ·ûô·ûÄ·ûó·üí·ûì·üÇ·ûÄ ·ûá·ûΩ·ûì·ûÜ·üí·ûõ·ûÑ·ûú·ûÇ·üí·ûÇ ·ûÖ·û∂·ûî·üã·ûñ·û∏·ûñ·üÅ·ûõ·ûì·üÑ·üá·ûò·ûÄ ·ûö·ûî·ûü·üã·ûÇ·û∂·ûè·üã ·ûÄ·ûª·üÜ·ûí·üÅ·üí·ûú·ûü·ûÇ·üÜ·ûì·û∑·ûè·üî ·û¢·ûº·ûì·û†·üí·û¢·ûæ·ûô =
Iteration 59401: BEST OCR TEXT : ·ûÜ·üí·ûõ·üÄ·ûõ·ûô·ûÄ·ûó·üí·ûì·üÇ·ûÄ ·ûá·ûΩ·ûì·ûÜ·üí·ûõ·ûÑ·ûú·ûÇ·ûè ·ûÖ·û∂·ûî·üã·ûñ·û∏·ûñ·üÅ·ûõ·ûì·üÑ·üá·ûò·ûÄ ·ûö·ûî·ûü·üã·ûÇ·û∂·ûè·üã ·ûÄ·ûª·üÜ·ûí·üÅ·üí·ûú·ûü·ûÇ·üÜ·ûì·û∑·ûè·üî ·û¢·ûº·ûì·û†·üí·û¢·ûæ·ûô =
File /tmp/tmp.BjsuuQ0dgJ/khm/khm.Noto_Serif_Khmer.exp0.lstmf page 1 :
Mean rms=0.647%, delta=0.555%, train=1.881%(13.157%), skip ratio=0.1%
Iteration 59402: ALIGNED TRUTH : ·ûü·ûπ·ûÑ·ûò·û∂·ûì·üá·ûö·ûπ·ûÑ·ûè·üí·û¢·ûπ·ûÑ·ûò·û†·û∑·ûò·û∂ ·ûÇ·ûª·ûé ·ûì·üÖ·ûî·üâ·üÇ·ûÄ·û¶·ûü·û∂·ûì·ûì·üÉ·ûó·üí·ûì·üÜ ·ûë·ûª·ûõ·ûõ·üí·ûô·ûº ·ûÅ·üÅ·ûè·üí·ûè·ûü·üí·ûë·û∫·ûÑ·ûè·üí·ûö·üÇ·ûÑ,
Iteration 59402: BEST OCR TEXT : ·ûü·ûπ·ûÑ·ûò·û∂·ûì·üá·ûö·ûπ·ûÑ·ûè·üí·û¢·ûπ·ûÑ·ûò·û†·û∑·ûò·û∂ ·ûÇ·ûª·ûé ·ûì·üÖ·ûî·üâ·üÇ·ûÄ·û¶·ûü·û∂·ûì·ûì·üÉ·ûó·üí·ûì·üÜ ·ûë·ûª·ûõ·ûõ·üí·ûô·ûº ·ûÅ·üÅ·ûè·üí·ûè·ûü·üí·ûë·û∫·ûÑ·ûè·üí·ûö·üÇ·ûÑ,
File /tmp/tmp.BjsuuQ0dgJ/khm/khm.Leelawadee_UI_Bold.exp0.lstmf page 56 :
Mean rms=0.647%, delta=0.556%, train=1.881%(13.157%), skip ratio=0.1%
Iteration 59403: ALIGNED TRUTH : ·ûö·û∫·ûÇ·üÉ·ûî·ûì·üí·ûõ·üÜ·ûî·û∂·ûì·üî (·ûö·ûø·ûÑ·û¢·û∂·ûÅ·üí·ûú·û∂·ûÄ·üã·û¢·û∂·ûÅ·üí·ûú·û∑·ûì) ·û¢·ûì·üí·ûì·üÜ·ûõ·üÑ·ûÄ·ûÑ·üí·ûü·û∑ = ·ûß·ûë·û∂·û†·ûö·ûé·üç·üã·üñ·ûè·üÜ·ûî·ûì·üã·ûÅ·üí·ûõ·üá ·ûï·üí·ûë·üá·ûü·ûò·üí·ûî·üÇ·ûÑ
Iteration 59403: BEST OCR TEXT : ·ûö·û∫·ûÇ·üÉ·ûî·ûì·üí·ûõ·üÜ·ûî·û∂·ûì·üî (·ûö·ûø·ûÑ·û¢·û∂·ûÅ·üí·ûú·û∂·ûÄ·üã·û¢·û∂·ûÅ·üí·ûú·û∑·ûì) ·û¢·ûì·üí·ûì·üÜ·ûõ·üÑ·ûÄ·ûÑ·üí·ûü·û∑ = ·ûß·ûë·û∂·û†·ûö·ûé·üç·üñ·ûè·üÜ·ûî·ûì·üã·ûÅ·üí·ûõ·üá ·ûï·üí·ûë·üá·ûü·ûò·üí·ûî·üÇ·ûÑ
File /tmp/tmp.BjsuuQ0dgJ/khm/khm.Leelawadee_UI.exp0.lstmf page 51 :

```
intermediate checkpoint and .lstm files will be written to the output directory eg. ~/tesstutorial/tellayer_from_tel
You can also see visual debugging output with scrollview.  I am integrating Tesseract into an application, but I have some questions before keep going with the process.
I think every application should have security filters and considerations in order to avoid malicious and bad input data, so my questions are:

1. Does Tesseract have special code to handle bad or malicious input data? 
2. Or just have a few validations to tell the user the correct input data?
3. Releases are performed after doing some security reviews and testing?
4. Or just functional testing?

I will appreciate your answers.
Thanks a lot!  Is it possible to add to the [APIexample](https://github.com/tesseract-ocr/tesseract/wiki/APIExample) wiki on how to accomplish the equivalent of `tesseract --list-langs` and `tesseract --print-parameters` via the API?

## list langs

To list languages I currently use something like the following. However the problem is that I first need to initialize the english engine which might not be available. Is there a way to list languages without initializing any engine?

```cpp
  tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();
  if (api->Init(NULL, "eng"))
    throw std::runtime_error(std::string("Unable to find training data for"));
  api->GetAvailableLanguagesAsVector(langs);
  std::vector<std::string> available;
  for(int i = 0; i < langs->length(); i++)
    available.push_back(langs->get(i).c_str());
```

## list parameters

The only method I can find in the base API to list supported parameters is:

```cpp
api->PrintVariables(stdout);
```

However this prints a text dump which is difficult to read by machines. Is there an api to iterate over the supported variables strings and stick them into a `std::vector<std::string>`? >list parameters
>
>The only method I can find in the base API to list supported parameters is:
However this prints a text dump which is difficult to read by machines. Is there an api to iterate over the supported variables strings and stick them into a std::vector<std::string>?

I don't think there is a method in the API for that.
but if someone will send a PR ... I see that you made [R binding for Tessaract](https://github.com/ropensci/tesseract)
You might want to add a link to it from [AddOns](https://github.com/tesseract-ocr/tesseract/wiki/AddOns#tesseract-wrappers)
  ```
Loaded 1059/1059 pages (0-1059) of document /tmp/tmp.HeGbXAKgjI/san/san.Santipur_OT_Medium.exp0.lstmf
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Bad box coordinates in boxfile string! ‡§¶‡§ø ['‡§è\\^', 25 ‡§∏‡§∞‡•ç‡§µ 341 2126 768 2194 44
Loaded 885/885 pages (0-885) of document /tmp/tmp.HeGbXAKgjI/san/san.Uttara.exp0.lstmf
No block overlapping textline: ‡§§‡§§‡•ç‡§™‡§∂‡•ç‡§ö‡§æ‡§§‡•ç ‡§á‡§π‡•à‡§µ ‡§∏‡§Æ‡§∞‡•á ‡§∏‡•å‡§ñ‡•ç‡§Ø‡§Ç
No block overlapping textline: ‡§¶‡•ç‡§µ‡§æ‡§≠‡•ç‡§Ø‡§æ‡§Ç ‡§® ‡§ï‡•ç‡§∑‡•Å‡§§‡•ç‡§™‡§ø‡§™‡§æ‡§∏‡•á ‡§Ö‡§¶‡•ç‡§Ø‡§æ‡§™‡§ø
No block overlapping textline: ‡§Ö‡§ô‡•ç‡§ï‡•á ‡§§‡•Å ‡§§‡§∏‡•ç‡§Æ‡•à (‡§ö‡•á‡§ü‡•Ä‡§Ç ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§®‡•ç‡§§‡•á
No block overlapping textline: ‡§á‡§Ç‡§ö‡§Æ‡§ø‡§§‡•ã ‡§¶‡§ø‡§®‡•á ‡§ï‡•á‡§® ‡§ï‡§≤‡•ç‡§ï‡§ø‡§§‡§Æ‡•ç ‡§™‡•Ç‡§ú‡§æ
Page 31
Page 34
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Loaded 914/914 pages (0-914) of document /tmp/tmp.HeGbXAKgjI/san/san.Uttara.exp0.lstmf
Loaded 1096/1096 pages (0-1096) of document /tmp/tmp.HeGbXAKgjI/san/san.Santipur_OT_Medium.exp0.lstmf
Bad box coordinates in boxfile string! ‡§¶‡§ø ['‡§è\\^', 25 ‡§∏‡§∞‡•ç‡§µ 341 2126 768 2194 44
Page 35

``` https://github.com/tesseract-ocr/tesseract/blob/5deebe6c279f70215935c1f86baa7e7016c7f2a7/ccmain/linerec.cpp#L115 >Error in pixaGetCount: pixa not defined

https://github.com/DanBloomberg/leptonica/issues/223 ```
Page 3
Loaded 13/13 pages (1-13) of document /tmp/tmp.jX9oLgyrCZ/ara/ara.Traditional_Arabic.exp0.lstmf
No block overlapping textline: ÿ≥ŸèÿßŸÜŸëŸéŸÑÿß
No block overlapping textline: ŸÑŸéÿπŸéÿ¨Ÿé Ÿäÿ∞ŸêŸÑŸëŸéÿß ŸÜŸéŸàŸÇŸèÿ™ŸëŸéÿ™Ÿé ŸÖŸíŸÉŸèŸÑŸëŸéÿπŸéŸÑŸé ŸÖŸíŸÉŸèŸÑŸêÿ®ŸíŸÇŸé ŸÜŸíŸÖŸê ŸÜŸéŸäÿ∞ŸêŸÑŸëŸéÿßŸàŸé ŸÖŸíŸÉŸèŸÇŸéŸÑŸéÿÆŸé Ÿäÿ∞ŸêŸÑŸëŸéÿß ŸÖŸèŸÉŸèÿ®ŸëŸéÿ±Ÿé ÿßŸàÿØŸèÿ®ŸèÿπŸíÿß
No block overlapping textline: ŸâŸÑŸéÿπŸé ÿßŸÜŸéŸÑŸíÿ≤ŸëŸéŸÜŸé ÿßŸÖŸêŸÖŸëŸé ÿ®ŸçŸäŸíÿ±Ÿé ŸÅŸêŸä ŸÖŸíÿ™ŸèŸÜŸíŸÉŸè ŸÜŸíÿ•ŸêŸàŸé ŸÜŸéŸàŸÖŸèŸÑŸéÿπŸíÿ™Ÿé ŸÖŸíÿ™ŸèŸÜŸíÿ£ŸéŸàŸé ÿßÿØŸãÿßÿØŸéŸÜŸíÿ£Ÿé ŸÑŸêŸÑŸëŸéŸáŸê ÿßŸàŸÑŸèÿπŸéÿ™Ÿéÿ¨Ÿí ŸÑŸéÿßŸÅŸé ŸÖŸíŸÉŸèŸÑŸé
No block overlapping textline: ŸÜŸéÿßÿØŸêÿ®ŸíÿπŸé
No block overlapping textline: ŸäŸÜŸéŸÇŸêÿØŸêÿßÿµŸé ŸÖŸíÿ™ŸèŸÜŸíŸÉŸè ŸÜŸíÿ•Ÿê ŸÑŸÑŸëŸéŸáŸêÿß ŸÜŸêŸàÿØŸè ŸÜŸíŸÖŸê ŸÖŸíŸÉŸèÿ°ŸéÿßÿØŸéŸáŸéÿ¥Ÿè ÿßŸàÿπŸèÿØŸíÿßŸàŸé ŸáŸêŸÑŸêÿ´ŸíŸÖŸê ŸÜŸíŸÖŸê ÿ©Ÿçÿ±ŸéŸàÿ≥Ÿèÿ®Ÿê ÿßŸàÿ™Ÿèÿ£ŸíŸÅŸé
No block overlapping textline: ŸÜŸéŸäÿ±ŸêŸÅŸêÿßŸÉŸéŸÑŸíŸÑŸê
No block overlapping textline: ÿßŸáŸéÿ™Ÿêÿ™Ÿéÿ≠Ÿí ŸÜŸíŸÖŸê Ÿäÿ±Ÿêÿ™Ÿéÿ¨Ÿí ÿ™ŸçÿßŸÜŸëŸéÿ¨Ÿé ŸÖŸíŸÑŸéŸáŸè ŸÜŸëŸéÿ£Ÿé ÿ™ŸêÿßŸÑŸêÿ≠ŸéÿßÿµŸëŸéŸÑÿß ÿßŸàŸÑŸèŸÖŸêÿπŸéŸàŸé ÿßŸàŸÜŸèŸÖŸéÿ¢ ŸÜŸéŸäÿ∞ŸêŸÑŸëŸéÿß ÿ±Ÿêÿ¥ŸëŸêÿ®ŸéŸàŸé
No block overlapping textline: ÿßŸÖŸéŸÑŸëŸéŸÉŸè ÿ±ŸèÿßŸáŸéŸÜŸíŸÑŸíÿ£Ÿéÿß
No block overlapping textline: ŸÖŸíŸÑŸéŸáŸèŸàŸé
No block overlapping textline: ŸÑŸãÿßÿ´ŸéŸÖŸé ÿ®Ÿéÿ±Ÿêÿ∂ŸíŸäŸé ŸÜŸíÿ£Ÿé ŸäŸäŸêÿ≠Ÿíÿ™Ÿéÿ≥ŸíŸäŸé ŸÑŸéÿß ŸÑŸÑŸëŸéŸáŸéÿß ŸÜŸëŸéÿ•Ÿê ŸÜŸéŸàÿØŸèŸÑŸêÿßÿÆŸé ÿßŸáŸéŸäŸÅŸê ŸÖŸíŸáŸèŸàŸé ÿ©Ÿåÿ±ŸéŸáŸëŸéÿ∑ŸéŸÖŸè ÿ¨ŸåÿßŸàŸéÿ≤Ÿíÿ£Ÿé ÿßŸáŸéŸäŸÅŸê
No block overlapping textline: ÿßŸÖŸé
No block overlapping textline: ÿßŸÖŸëŸéÿ£ŸéŸàŸé ŸÖŸíÿ®ŸëŸêŸáŸêÿ±Ÿé ŸÜŸíŸÖŸê ŸÇŸëŸèŸÑŸíÿ≠Ÿéÿß ŸáŸèŸÜŸëŸéÿ£Ÿé ŸÜŸéŸàŸÖŸèŸÑŸéÿπŸíŸäŸéŸÅŸé ÿßŸàŸÜŸèŸÖŸéÿ¢ ŸÜŸéŸäÿ∞ŸêŸÑŸëŸéÿß ÿßŸÖŸëŸéÿ£ŸéŸÅŸé ÿßŸáŸéŸÇŸéŸàŸíŸÅŸé ÿßŸÖŸéŸÅŸé ÿ©Ÿãÿ∂ŸéŸàÿπŸèÿ®Ÿé
No block overlapping textline: ŸÜŸéŸäÿ∞ŸêŸÑŸëŸéÿß
Page 4

``` The number of errors reduced to a couple 
```

Page 5
Loaded 75/75 pages (1-75) of document /tmp/tmp.ZhCBJPqjME/ara/ara.Traditional_Arabic.exp0.lstmf
No block overlapping textline: _
No block overlapping textline: :: ."
 
```
after adding the following to ara.config

`textord_min_linesize 2.5
` i got the same message for Japanese which is:
No block overlapping textline: ‰øÑÁÑ∂Â±Å„ÄÅ30Ë¶≥ÂÖâÈäö Â∑Æ Â°ûÁøÅ„ÅåÈ¶¨„É©„É≥„ÉÅ„Å´ÁöÑÈÖçÈÅîÁ°¨ÁøåÊúà -„ÅµÈôúË•ø ËÑõÈ™® Êô∫
yet i was able to create LSTM files for the fonts that i specified, i think the LSTM are OK because i noticed in this [issue](https://github.com/DanBloomberg/leptonica/issues/223) the user zdenop said 

> If there is error message I expect something serious is happening. But nothing bad has happened. There is expected output. This will confuse end-users (current version of tesseract hides leptonica warnings, but this error message is there...)


so are the LSTM files are not defected although the error message was shown?
NOTE, im using tesseract 4.00.00alpha with leptonica 1.74.1  http://www.alanwood.net/unicode/devanagari-extended.html
http://www.alanwood.net/unicode/vedic-extensions.html

Sample image which uses some of these characters is attached.

Or at a minimum add support for U+0951, U+0952, U+A8F3, U+1CDA 

![swarankit](https://cloud.githubusercontent.com/assets/5095331/21003508/b913fb04-bd51-11e6-88c1-bc402c36e5c4.png)
  https://github.com/tesseract-ocr/tesseract/issues/522

stweil commented

>... without those nagging messages, I'd never have had a look on that part of Leptonica.


 DanBloomberg commented

>Alternatively, for a bit more flexibility, you can define the environmental variable
#define LEPT_MSG_SEVERITY L_SEVERITY_WARNING
and use
setMsgSeverity(L_SEVERITY_EXTERNAL);
 I want the above option in the release build.
@stweil? cc: @Danbloomberg First, some more of the basics, for disabling at least all info and warning messages.

You can define the external env variable to L_SEVERITY_ERROR.  That will disable warnings, which I believe makes sense for tesseract.

If you set this severity level at compile time, you guarantee that it can't be over-ridden at run-time.

If you want to go further and suppress all messages, including those from the ERROR_*  macros (which are different from the informational L_* macros), define NO_CONSOLE_IO on the compile line (or use L_SEVERITY_NONE).

As for the suggestion that setMsgSeverity() tells you what it does, I can easily add a 2nd arg (debug) and only emit those messages when debug = TRUE.  Stefan, is that what you want? Better, I'll just comment out the comments, leaving the interface unchanged. this change is pushed to leptonica master on github and modified to keep the warning(error) message but not the info(OK) messages I was thinking that if you try to set it to the external value, and that value is not set, it should issue a warning because the attempt failed.  I am already commenting the L_INFOs out there, and I can comment the warning out as well. All leptonica messages in setMsgSeverity() are now disabled, as requested. Either `DEBUG` or `NDEBUG` is set by `configure` (depending on --enable-debug). It looks like cmake currently does not set `DEBUG`. Maybe that's the reason why `api/baseapi.cpp` also tests for `_DEBUG` (set my the MS compiler).

`NDEBUG` is a standard macro which changes the behavior of `assert`. That's also the reason why it is used rather often.

If we want to separately control standard features and Tesseract features, we need both macros. Otherwise we could stick to using `NDEBUG`.

Personally I prefer keeping both macros, but I think that removing `DEBUG` would also work.  ```
Other case √â of √© is not in unicharset
Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Failed to load radical-stroke info from: ../langdata/radical-stroke.txt
Warning: given outputs 105 not equal to unicharset of 113.
```

@theraysmith I am trying to run the commands given in training tutorial.

1. the above messages are from basetrain.log.
 Does the langdata repo need to be updated for 4.0 alpha?

2.




.   Thanks, Ray.

On 07-Dec-2016 10:29 PM, "theraysmith" <notifications@github.com> wrote:

> Fixed in tesseract-ocr/langdata@3299c60
> <https://github.com/tesseract-ocr/langdata/commit/3299c600323a511486fdab58c8e31258c308a7bc>
> .
> I'm retesting now. It seems the tutorial works without it, so I imagine
> the accuracy numbers in the tutorial will come out different.
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/542#issuecomment-265505151>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o1Gwtcn4WKaDYuXl83XfkwNT8-mUks5rFuYMgaJpZM4LGOuy>
> .
>
 Ray, 

Please add what are the minimum requirements for doing LSTM training in terms of hardware, software, etc.

I realized after running the process that I needed to build Scrollview.jar. I am not sure whether it is REQUIRED or only optional for those who would like to see visual debugging output. It is not built as part of the regular make install of tesseract and training tools. 

>> It will stop at 5000 iterations, (in about half an hour) 

I think that is probably dependent on the hardware used. I did not get any progress for more than one and a half hour - not sure whether it was because I did not have scrollview.jar at that point. I ran it later with 500 iterations.

I think it maybe helpful to have just a single iteration as the first step in tutorial to make sure that the process is working.

Also, the case that I think most people would like to use for LSTM training would be to use Finetuning to add a font to the existing trainingdata. It would be helpful to have a separate page on wiki for it. 

It would also be great to know how to add training data based on scanned images for typefaces that are not available as fonts. 

I will try to test 'finetuning' the Hindi traineddata for Sanskrit and post here.


   We're in the process of updating leptonica to version 1.74.0.

This will go out with debian with SO version 5.1.0.

I see in CMakeLists.txt:
   set(MINIMUM_LEPTONICA_VERSION 1.71)

Two questions:
(1) Should this be increased?  1.71 is at least 2 years old, likely still binary compatible.

(2) With autotools, the SO version defines the binary interface compatibility, which is why we're bumping it up from 5.0.0 in 1.73 to 5.1.0 in 1.74.  Does cmake use the SO version? Also see https://github.com/tesseract-ocr/tesseract/issues/536 https://github.com/tesseract-ocr/tesseract/wiki/Compiling
Ray added the 1.73 requirement for 4.0.

There is a pending patch from Jeff that will need 1.74.
https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-246744997

Anyway, the two build system should be updated. We now depend on 1.74.0 (see commit 11f205707) If you want to support 1.73 you can provide a patch... :-) I mean, the code will still use your patch for 1.74 but will fallback to the previous behaviour for 1.73. I thought that with 1.74, and SO 5.1, there is no longer a need for that tiff patch on debian.

btw, github release 1.74.0 is now also up as 1.74 (in the usual configure-make tarball) on leptonica.org:
     leptonica.org/source/leptonica-1.74.tar.gz  Jeff,
Any chance you will provide a Leptonica 1.74 PPA for Ubuntu 16.04? OK, I thought that you are familiar with PPAs. I didn't mean to push you to prepare a PPA. Jeff made a Leponica 1.74.1 package for Debian:
https://packages.debian.org/sid/libleptonica-dev Unofficial Ubuntu PPAs for Tesseract 4.00 & Leptonica 1.74:
https://launchpad.net/~alex-p/+archive/ubuntu/tesseract-ocr  In an image with Hindi text in various fonts, some of it at very large size

psm 3 - recognizes text at large font size
psm 6 - recognizes text at smaller font size

input image and output files are attached.
![sample6](https://cloud.githubusercontent.com/assets/5095331/20925445/04033a88-bbdd-11e6-861b-100e33bf5177.jpg)
[sample6-psm3.txt](https://github.com/tesseract-ocr/tesseract/files/633824/sample6-psm3.txt)
[sample6-psm6.txt](https://github.com/tesseract-ocr/tesseract/files/633825/sample6-psm6.txt)


  I tried the multilang option with the latest git code for an image which is mostly in Hindi with the titles in English. The English text was not recognized at all with -l hin+eng and only the first line in English was recognized when using -l eng+hin

The image used for testing and associated ground truth file are attached.

Please also see the console messages related to pixa and pixs displayed while processing.
```
time tesseract hin-eng.png hin-eng-eng -l eng
+ tesseract hin-eng.png hin-eng-eng -l eng
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined

real    0m16.114s
user    0m15.063s
sys     0m0.344s

time tesseract hin-eng.png hin-eng-hin -l hin
+ tesseract hin-eng.png hin-eng-hin -l hin
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Found AVX
Found SSE

real    0m17.266s
user    0m48.875s
sys     0m0.875s

time tesseract hin-eng.png hin-eng-hin-eng -l hin+eng
+ tesseract hin-eng.png hin-eng-hin-eng -l hin+eng
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Found AVX
Found SSE
Error in pixClone: pixs not defined

real    0m16.532s
user    0m45.844s
sys     0m1.031s

time tesseract hin-eng.png hin-eng-eng-hin -l eng+hin
+ tesseract hin-eng.png hin-eng-eng-hin -l eng+hin
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Found AVX
Found SSE
Error in pixClone: pixs not defined

real    0m17.696s
user    0m49.641s
sys     0m0.938s
```

![hin-eng](https://cloud.githubusercontent.com/assets/5095331/20924058/7bdff8a0-bbd5-11e6-890f-87bec2ea9077.png)
[hin-eng.txt](https://github.com/tesseract-ocr/tesseract/files/633687/hin-eng.txt)
 The output for the image with -l hin, -l eng, -l hin+eng and -l eng+hin is attached here.

[hin-eng-hin-eng.txt](https://github.com/tesseract-ocr/tesseract/files/633694/hin-eng-hin-eng.txt)
[hin-eng-eng-hin.txt](https://github.com/tesseract-ocr/tesseract/files/633703/hin-eng-eng-hin.txt)
[hin-eng-hin.txt](https://github.com/tesseract-ocr/tesseract/files/633704/hin-eng-hin.txt)
[hin-eng-eng.txt](https://github.com/tesseract-ocr/tesseract/files/633705/hin-eng-eng.txt)
 It looks like you have installed new 4.0 traineddata for Hindi but for English you are using 3.04 traineddata. @amitdo That is quite possible. I will download the eng.traineddata again and give it a try.

Thanks. https://github.com/DanBloomberg/leptonica/issues/223

@DanBloomberg
Error in pixClone: pixs not defined
 @amitdo Here is the result with 4.0 traineddata

```
time tesseract hin-eng.png hin-eng-eng --oem 1 --psm 6 -l eng
+ tesseract hin-eng.png hin-eng-eng --oem 1 --psm 6 -l eng
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Found AVX
Found SSE

real    0m44.983s
user    2m0.875s
sys     0m0.703s

time tesseract hin-eng.png hin-eng-hin --oem 1 --psm 6 -l hin
+ tesseract hin-eng.png hin-eng-hin --oem 1 --psm 6 -l hin
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Found AVX
Found SSE

real    1m1.776s
user    2m47.953s
sys     0m0.797s

time tesseract hin-eng.png hin-eng-hin-eng --oem 1 --psm 6 -l hin+eng
+ tesseract hin-eng.png hin-eng-hin-eng --oem 1 --psm 6 -l hin+eng
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Found AVX
Found SSE
Error in pixClone: pixs not defined

real    1m12.471s
user    3m14.844s
sys     0m0.984s

time tesseract hin-eng.png hin-eng-eng-hin --oem 1 --psm 6 -l eng+hin
+ tesseract hin-eng.png hin-eng-eng-hin --oem 1 --psm 6 -l eng+hin
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Found AVX
Found SSE
Error in pixClone: pixs not defined

real    1m42.064s
user    4m20.469s
sys     0m1.172s

``` I built leptonica and tesseract from github again.

The error message is displayed when using two languages together. However, OCR output is also produced. 

So I would suggest that the message be categorized as info or warning rather than error.

```
tesseract sg090.png sg090-hin-eng --oem 1 -l hin+eng
Tesseract Open Source OCR Engine v4.00.00alpha-204-g8b3c6ac with Leptonica
Found AVX
Found SSE
Error in pixClone: pixs not defined

real    0m50.552s
user    2m16.109s
sys     0m0.938s
``` This error is still there

```
 tesseract -v
tesseract 4.00.00alpha
 leptonica-1.74.1
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 Found AVX
 Found SSE

 ./out.sh (  time tesseract ${img_file} ${img_file%.*}-hin-eng --oem 1  -l hin+eng logfile)
Error in pixClone: pixs not defined

real    0m32.601s
user    1m42.328s
sys     0m0.813s
``` The message:
    *Error in pixClone: pixs not defined*
is correct.  The return on such an error is NULL, which is assigned to
another Pix pointer.  Errors will continue to propagate when that handle is
passed to another function, and so on.

The purpose of these error messages is to give a simple stack trace of
errors, so that (1) you know there was a problem and (2) you have a better
chance of finding out where it occurred.

On Thu, Jan 26, 2017 at 9:01 PM, Shreeshrii <notifications@github.com>
wrote:

> This error is still there
>
>  tesseract -v
> tesseract 4.00.00alpha
>  leptonica-1.74.1
>   libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8
>
>  Found AVX
>  Found SSE
>
>  ./out.sh (  time tesseract ${img_file} ${img_file%.*}-hin-eng --oem 1  -l hin+eng logfile)
> Error in pixClone: pixs not defined
>
> real    0m32.601s
> user    1m42.328s
> sys     0m0.813s
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/537#issuecomment-275589518>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLN4bbSwu-6jizXNfnL674V_oULtuks5rWXoOgaJpZM4LFTlV>
> .
>
 The excitement happens in api/baseapi.cpp, where End() calls Clear(), which conditionally calls SetInputImage(NULL).  That call generates the pixClone(NULL) error.

I see that the pixClone() in set_pix_original() in ccmain/tesseractclass.h was added by Ray on Dec. 5, 2016.  Related: https://github.com/tesseract-ocr/tessdata/issues/32

Please add version info to traineddata files and check for correct version during runtime. Thanks. @theraysmith Please consider including in next set of changes for 4.0.
 +1 Apropos `traineddata` files: what about changing the file format for 4.x? That files are just a collection of several files, and Tesseract needs a special program / code to compose or extract them. There exist widely used other file formats which provide similar features, including but not limited to zip files. Compression could also reduce the file size. What about using ProtocolBuffers / FlatBuffers / cbor to serialize the lstm model?  Related:
https://groups.google.com/forum/?hl=en#!searchin/tesseract-dev/zip|sort:date/tesseract-dev/U5HSugUeeeI See PR #911 for a proof-of-concept how `traineddata` in zip format can be implemented. Implemented here:
https://github.com/tesseract-ocr/tesseract/commit/dc8745e6fd4c >Reports Pre-4.0.0 for traineddata from 4.00.00alpha

Yes. `Pre-4.0.0` is the default if the traineddata does not contain a `version` file.  The current traineddata files for 4.0 will be obsolete once Ray will push the new ones, which will probably have the `version` file.  >What about moving to #pragma once?

https://google.github.io/styleguide/cppguide.html

>Do not use #pragma once; instead use the standard Google include guards. The path in the include guards should be relative to the top of your project tree.  While trying to process a gif file, when leptonica was not built with giflib, get the following messages

```
/mnt/c/Users/User/shree$ tesseract san001.gif san001-gif --psm 6 --oem 4 -l san
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in pixReadStreamGif: function not present
Error in pixReadStream: gif: no pix returned
Error in pixRead: pix not read
Error during processing.
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x1fd72f0 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatalstm-punc-dawg)
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x1fd8290 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatalstm-word-dawg)
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x1fd7110 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatalstm-number-dawg)
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x426afd0 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatapunc-dawg)
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x1fd6f20 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddataword-dawg)
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x426ae60 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatanumber-dawg)
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x472cef0 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatabigram-dawg)
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x4784e50 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatafreq-dawg)


/mnt/c/Users/User/shree$ tesseract san001.gif san001-gif --psm 6 --oem 3 -l san
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in pixReadStreamGif: function not present
Error in pixReadStream: gif: no pix returned
Error in pixRead: pix not read
Error during processing.
ObjectCache(0x7fc1e7d9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x58291f0 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatapunc-dawg)
ObjectCache(0x7fc1e7d9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x5829010 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddataword-dawg)
ObjectCache(0x7fc1e7d9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x58290d0 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatanumber-dawg)
ObjectCache(0x7fc1e7d9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x5829190 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatabigram-dawg)
ObjectCache(0x7fc1e7d9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x5828fb0 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatafreq-dawg)

``` >Error in pixReadStreamGif: function not present
>Error in pixReadStream: gif: no pix returned
Error in pixRead: pix not read

These error messages are from Leptonica.

>Error during processing.

This one and the ObjectCache scary messages are from Tesseract.

https://github.com/tesseract-ocr/tesseract/blob/a75ab450a/ccutil/object_cache.h#L42

Looks like a bug in Tesseract. Error is related to input file not being found.

```
C:\Users\User>tesseract abc.jpg abc
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error during processing.
ObjectCache(5A7A9AC8)::~ObjectCache(): WARNING! LEAK! object 032C6178 still has count 1 (id C:\Program Files (x86)\Tesseract-OCR/tessdata/eng.traineddatapunc-dawg)
ObjectCache(5A7A9AC8)::~ObjectCache(): WARNING! LEAK! object 032C51C8 still has count 1 (id C:\Program Files (x86)\Tesseract-OCR/tessdata/eng.traineddataword-dawg)
ObjectCache(5A7A9AC8)::~ObjectCache(): WARNING! LEAK! object 032C5278 still has count 1 (id C:\Program Files (x86)\Tesseract-OCR/tessdata/eng.traineddatanumber-dawg)
ObjectCache(5A7A9AC8)::~ObjectCache(): WARNING! LEAK! object 032C9C28 still has count 1 (id C:\Program Files (x86)\Tesseract-OCR/tessdata/eng.traineddatabigram-dawg)
ObjectCache(5A7A9AC8)::~ObjectCache(): WARNING! LEAK! object 032C50C8 still has count 1 (id C:\Program Files (x86)\Tesseract-OCR/tessdata/eng.traineddatafreq-dawg)

C:\Users\User>
``` Did you succeed in making it run on any image? 
I get the same error message on both *.png and *.jpg Check the version of leptonica and image livs by

tesseract -v

See if png and jpg libs are listed

In my case, giflib is not included in leptonica, hence it does not process
gifs.
Png and jpg files are processed, though there are some info and warning
messages from leptonica.

The latest GitHub version of leptonica and tesseract have fewer of these
msgs.

On 14-Dec-2016 12:10 AM, "Srdjan Prodanovic" <notifications@github.com>
wrote:

> Did you succeed in making it run on any image?
> I get the same error message on both *.png and *.jpg
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/529#issuecomment-266823793>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o2bnKAzARMj2N1Wskc4ioJ080XMnks5rHuaygaJpZM4LDjOe>
> .
>
 You are completely right, when bulding Leptonica from source I relied on instructions from Tesseract Wiki, which are incomplete. 

From http://www.leptonica.org/source/README.html#DEPENDENCIES
Leptonica is configured to handle image I/O using these external
   libraries: libjpeg, libtiff, libpng, libz, libgif, libwebp, libopenjp2
   These libraries are easy to obtain.  For example, using the
   debian package manager:
       sudo apt-get install 
   where  = {libpng12-dev, libjpeg62-dev, libtiff4-dev}.

Now png and jpeg rendering libs got integrated when I rebuilt everything again. 
ubuntu@XXX$ tesseract -v
tesseract 4.00.00alpha
 leptonica-1.73
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.51 : libtiff 4.0.3 : zlib 1.2.8

Thanks! The error also comes when tesseract is not able to write an output file eg. missing output directory .. or other such io issues. getting error re: LEAK!  when input file not found - wrong name given

```
shree@ALL-IN-1-TOUCH:/mnt/c/Users/User/shree/kannada$ tesseract scan001.tif scan001 --oem 1 -l kan makebox
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error during processing.
ObjectCache(0x7fd27279eac0)::~ObjectCache(): WARNING! LEAK! object 0x2b114e0 still has count 1 (id /mnt/c/Users/User/shree/tessdata/kan.traineddatalstm-punc-dawg)
ObjectCache(0x7fd27279eac0)::~ObjectCache(): WARNING! LEAK! object 0x2b127c0 still has count 1 (id /mnt/c/Users/User/shree/tessdata/kan.traineddatalstm-word-dawg)
ObjectCache(0x7fd27279eac0)::~ObjectCache(): WARNING! LEAK! object 0x2b11360 still has count 1 (id /mnt/c/Users/User/shree/tessdata/kan.traineddatalstm-number-dawg)
``` Getting the same error.



> 
> $ tesseract test.jpeg file
> Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
> Error in fopenReadStream: file not found
> Error in findFileFormat: image file not found
> Error during processing.
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x1b46fc0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatalstm-punc-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x1b46db0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatalstm-word-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x1b46e60 still has count 1 (id /usr/local/share/tessdata/eng.traineddatalstm-number-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x27604a0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatapunc-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x2761910 still has count 1 (id /usr/local/share/tessdata/eng.traineddataword-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x27601f0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatanumber-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x1b46bc0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatabigram-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x286b8a0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatafreq-dawg)




My version is:

> $  tesseract --version
> tesseract 4.00.00alpha
>  leptonica-1.74.1
>   libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8
> 
>  Found AVX
>  Found SSE  file not found Error

make sure that test.jpeg is in the path. try

ls test.jpeg
tesseract test.jpeg file



ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Sat, Feb 18, 2017 at 3:13 PM, Taylan Koca <notifications@github.com>
wrote:

> Getting the same error.
>
> tesseract test.jpeg file Tesseract Open Source OCR Engine v4.00.00alpha
> with Leptonica Error in fopenReadStream: file not found Error in
> findFileFormat: image file not found Error during processing.
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x1b46fc0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatalstm-punc-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x1b46db0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatalstm-word-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x1b46e60 still has count 1 (id /usr/local/share/tessdata/eng.traineddatalstm-number-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x27604a0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatapunc-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x2761910 still has count 1 (id /usr/local/share/tessdata/eng.traineddataword-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x27601f0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatanumber-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x1b46bc0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatabigram-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x286b8a0 still has count 1 (id /usr/local/share/tessdata/eng.
> traineddatafreq-dawg)
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/529#issuecomment-280834544>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o5RXPUonbIVRjCUiSwdhSpbjPencks5rdr1OgaJpZM4LDjOe>
> .
>
 I encounted the same error that tesseract not able to read gif.
error look like this:
...
Error in pixReadStreamGif: function not present
...
When I checked the version of tesseract, it did not show gif library: 
tesseract 4.00.00alpha
leptonica-1.74.1
libjpeg 8d (libjpeg-turbo 1.5.0) : libpng 1.6.25 : libtiff 4.0.6 : zlib 1.2.8

So I install libgif-dev from synaptic and recompile the leptonica again.
This time when I checked the version of tesseract again, it gave me:
tesseract 4.00.00alpha
leptonica-1.74.1
**libgif 5.1.4** : libjpeg 8d (libjpeg-turbo 1.5.0) : libpng 1.6.25 : libtiff 4.0.6 : zlib 1.2.8

After I tried again using gif with tesseract, it gave no error any more. Making the PWD be where the file is located works, but I consider that broken.  If I supply a relative or absolute path to an input file, tesseract should read that without issue.  Instead it says the file can't be found, which is bizarre.  I'm going to change my script to use cat and have tesseract read from standard input, because this is so broken.

tesseract --version                                                                  
tesseract 3.05.00
 leptonica-1.74.1
  libjpeg 8d : libpng 1.6.29 : libtiff 4.0.7 : zlib 1.2.8

I'm using it on MacOS through homebrew, and my source image is a PNG.

> file not found Error

> make sure that test.jpeg is in the path. try

> ls test.jpeg
> tesseract test.jpeg file



> ShreeDevi In the image_to_string function of tesseract.py, the input image is converted to bmp and stored in /tmp directory in my Linux box. When this path (with '/') pass to subprocess.Popen, tesseract cannot find the file.  You can simulate this by running the following in the command prompt.

tesseract /tmp/tess__cwb36mk.bmp output.txt Can you break on the warning and get some more information? From a quick look, `Dict::Load()` doesn't add `load_bigram_dawg` to `dawgs_`, which either is a bug or should be documented in a comment, but I don't know whether fixing that would solve this problem. Of course, all this stuff should really be RAII-ified... :-) Well, I was thinking more along the line of inspecting the offending object. Apparently fixing what I saw in `Dict::load()` didn't solve the problem, so I'll try gdb myself. Unfortunately `./configure --enable-debug` doesn't seem to work, because there are `-O2` arguments after the `-O0` ones, and "If you use multiple -O options, with or without level numbers, the last such option is the one that is effective.", so my workaround for that is to edit `configure` and `configure.ac`. Intermediate result of analysis: the program seems to be using `Dict::GlobalDawgCache()`, which has static duration, but the Dict using the cache is not deleted before the program `exit()`s. To be continued later... My debug builds avoid the `-O0` / `-O2` problem like this:

    mkdir -p bin/debug
    cd bin/debug
    # Disable parts which are not needed for debugging (shorter build time)
    # and don't use a shared library for Tesseract (easier debugging).
    # Avoid -O2 compiler option.
    ../../configure  --enable-debug --disable-shared --disable-static CXXFLAGS="-g"
    make
    cd ../..
    gdb --args bin/debug/api/tesseract [...]

I still did not find a correct fix for `configure.ac`. I have some evidence (in a new branch [issue529](https://github.com/rfschtkt/tesseract/tree/issue529) on my own fork, unless there's a better way to present that?), currently modifying the messages coming from the global cache. It mentions "workaround" here and there, but perhaps a cleaner solution can be found. Valgrind output for the test case (after PR #912 was applied):

     HEAP SUMMARY:
         in use at exit: 16,109,940 bytes in 4 blocks
       total heap usage: 666,366 allocs, 666,362 frees, 179,459,012 bytes allocated
     
     Searching for pointers to 4 not-freed blocks
     Checked 19,243,304 bytes
     
     8 bytes in 1 blocks are still reachable in loss record 1 of 4
        at 0x4C2BBAF: malloc (vg_replace_malloc.c:299)
        by 0x5D8C688: gomp_malloc (alloc.c:37)
        by 0x5D9B867: gomp_init_num_threads (proc.c:91)
        by 0x5D8ACC5: initialize_env (env.c:1208)
        by 0x400F649: call_init.part.0 (dl-init.c:72)
        by 0x400F75A: call_init (dl-init.c:30)
        by 0x400F75A: _dl_init (dl-init.c:120)
        by 0x4000CD9: ??? (in /lib/x86_64-linux-gnu/ld-2.24.so)
        by 0x2: ???
        by 0xFFF000412: ???
        by 0xFFF00043B: ???
        by 0xFFF00043D: ???
     
     12 bytes in 1 blocks are indirectly lost in loss record 2 of 4
        at 0x4C2BBAF: malloc (vg_replace_malloc.c:299)
        by 0x2A8339: alloc_string(int) (memry.cpp:32)
        by 0x2AAEF0: STRING::AllocData(int, int) (strngs.cpp:55)
        by 0x2AB120: STRING::STRING(STRING const&) (strngs.cpp:114)
        by 0x234CBA: tesseract::Dawg::Dawg(tesseract::DawgType, STRING const&, PermuterType, int) (dawg.h:209)
        by 0x31149F: tesseract::SquishedDawg::SquishedDawg(tesseract::DawgType, STRING const&, PermuterType, int) (dawg.h:416)
        by 0x311260: tesseract::DawgLoader::Load() (dawg_cache.cpp:91)
        by 0x311C6F: _TessMemberResultCallback_0_0<true, tesseract::Dawg*, tesseract::DawgLoader>::Run() (tesscallback.h:145)
        by 0x311787: tesseract::ObjectCache<tesseract::Dawg>::Get(STRING, TessResultCallback<tesseract::Dawg*>*) (object_cache.h:78)
        by 0x3110DC: tesseract::DawgCache::GetSquishedDawg(STRING const&, tesseract::TessdataType, int, tesseract::TessdataManager*) (dawg_cache.cpp:51)
        by 0x231A97: tesseract::Dict::Load(STRING const&, tesseract::TessdataManager*) (dict.cpp:242)
        by 0x20B765: tesseract::Wordrec::program_editup(char const*, tesseract::TessdataManager*, tesseract::TessdataManager*) (tface.cpp:54)
     
     100 (88 direct, 12 indirect) bytes in 1 blocks are definitely lost in loss record 3 of 4
        at 0x4C2C21F: operator new(unsigned long) (vg_replace_malloc.c:334)
        by 0x31123F: tesseract::DawgLoader::Load() (dawg_cache.cpp:91)
        by 0x311C6F: _TessMemberResultCallback_0_0<true, tesseract::Dawg*, tesseract::DawgLoader>::Run() (tesscallback.h:145)
        by 0x311787: tesseract::ObjectCache<tesseract::Dawg>::Get(STRING, TessResultCallback<tesseract::Dawg*>*) (object_cache.h:78)
        by 0x3110DC: tesseract::DawgCache::GetSquishedDawg(STRING const&, tesseract::TessdataType, int, tesseract::TessdataManager*) (dawg_cache.cpp:51)
        by 0x231A97: tesseract::Dict::Load(STRING const&, tesseract::TessdataManager*) (dict.cpp:242)
        by 0x20B765: tesseract::Wordrec::program_editup(char const*, tesseract::TessdataManager*, tesseract::TessdataManager*) (tface.cpp:54)
        by 0x18F69F: tesseract::Tesseract::init_tesseract_internal(char const*, char const*, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, tesseract::TessdataManager*) (tessedit.cpp:412)
        by 0x18F2D2: tesseract::Tesseract::init_tesseract(char const*, char const*, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, tesseract::TessdataManager*) (tessedit.cpp:324)
        by 0x12D377: tesseract::TessBaseAPI::Init(char const*, int, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, bool (*)(STRING const&, GenericVector<char>*)) (baseapi.cpp:326)
        by 0x12D0C0: tesseract::TessBaseAPI::Init(char const*, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool) (baseapi.cpp:284)
        by 0x12BB90: main (tesseractmain.cpp:434)
     
     16,109,832 bytes in 1 blocks are possibly lost in loss record 4 of 4
        at 0x4C2C93F: operator new[](unsigned long) (vg_replace_malloc.c:423)
        by 0x3102E0: tesseract::SquishedDawg::read_squished_dawg(tesseract::TFile*) (dawg.cpp:330)
        by 0x3114D4: tesseract::SquishedDawg::Load(tesseract::TFile*) (dawg.h:439)
        by 0x311277: tesseract::DawgLoader::Load() (dawg_cache.cpp:92)
        by 0x311C6F: _TessMemberResultCallback_0_0<true, tesseract::Dawg*, tesseract::DawgLoader>::Run() (tesscallback.h:145)
        by 0x311787: tesseract::ObjectCache<tesseract::Dawg>::Get(STRING, TessResultCallback<tesseract::Dawg*>*) (object_cache.h:78)
        by 0x3110DC: tesseract::DawgCache::GetSquishedDawg(STRING const&, tesseract::TessdataType, int, tesseract::TessdataManager*) (dawg_cache.cpp:51)
        by 0x231A97: tesseract::Dict::Load(STRING const&, tesseract::TessdataManager*) (dict.cpp:242)
        by 0x20B765: tesseract::Wordrec::program_editup(char const*, tesseract::TessdataManager*, tesseract::TessdataManager*) (tface.cpp:54)
        by 0x18F69F: tesseract::Tesseract::init_tesseract_internal(char const*, char const*, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, tesseract::TessdataManager*) (tessedit.cpp:412)
        by 0x18F2D2: tesseract::Tesseract::init_tesseract(char const*, char const*, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, tesseract::TessdataManager*) (tessedit.cpp:324)
        by 0x12D377: tesseract::TessBaseAPI::Init(char const*, int, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, bool (*)(STRING const&, GenericVector<char>*)) (baseapi.cpp:326)
     
     LEAK SUMMARY:
        definitely lost: 88 bytes in 1 blocks
        indirectly lost: 12 bytes in 1 blocks
          possibly lost: 16,109,832 bytes in 1 blocks
        still reachable: 8 bytes in 1 blocks
             suppressed: 0 bytes in 0 blocks
     
     ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0)
     ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0)

The output was generated using `valgrind --verbose --track-origins=yes --leak-check=full --show-leak-kinds=all bin/debug/x86_64-linux-gnu/api/tesseract a b`. The thing is that `exit()` was inherited from C, and all kinds of things are hooked up to `atexit()` (even variables with static storage duration), but _not_ automatic variables like `tesseract::TessBaseAPI api;`. Inside `main()` you could replace it with plain `return`, but elsewhere I think you have to avoid `exit()` and instead, until the program becomes exception-safe (RAII!) with a global try/catch in main(), perhaps use `quick_exit()`. Or adapt the code I wrote for evidence as a workaround.

Incidentally, main() has the following comment (although I have no idea why anybody would care about leaked STRING objects, as compared to, e.g., open handles to files, or the subject of this issue):

```
  /* main() calls functions like ParseArgs which call exit().
   * This results in memory leaks if vars_vec and vars_values are
   * declared as auto variables (destructor is not called then). */
  static GenericVector<STRING> vars_vec;
  static GenericVector<STRING> vars_values;
```

Well, I guess it might matter to diagnostic tools like Valgrind, but I suppose they're empty now. When tools like Valgrind are used to search for critical memory leaks, any memory leak is bad because it creates a warning which has to be analyzed. Example: Before PR #912 there were 40,102 allocated blocks at program termination, after that PR there remain 3 blocks (see above).

    LEAK SUMMARY:
       definitely lost: 0 bytes in 0 blocks
       indirectly lost: 0 bytes in 0 blocks
         possibly lost: 0 bytes in 0 blocks
       still reachable: 41,740,480 bytes in 40,102 blocks
                          of which reachable via heuristic:
                            newarray           : 4,147,800 bytes in 4,350 blocks
            suppressed: 0 bytes in 0 blocks
 I fully agree, and I should have guessed that it had taken some effort to get it down to 4 blocks.

Anyway, after my latest commit I don't get the messages anymore.

(Added) What's the 2 all about? Is anybody using it, is it documented? Otherwise, could it be just EXIT_FAILURE instead? /pedantic An additional commit in PR #912 fixes this issue. The crash problem is handled in PR #917. I think that using `static` to pander to ghost-of-the-past `exit()` is an abomination. Exiting other than in main is most probably the result of an error condition, where all you're concerned with is returning the error value. The only place where you should be concerned with a clean Valgrind report is inside main(), where you should use `return` rather than `exit()` to be compatible with the C++ paradigm of proper stack unwinding.

(Added) Unfortunately there's also `ScrollView::Exit()`, not sure whether these messages were a problem there? C:\Program Files\Tesseract-OCR>tesseract aws.tif aa.pdf
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error during processing.
ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 014DB180 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddatalstm-punc-dawg)

ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 014DB228 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddatalstm-word-dawg)

ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 01732ED8 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddatalstm-number-daw
g)
ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 048A4618 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddatapunc-dawg)
ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 014DB278 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddataword-dawg)
ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 014DB118 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddatanumber-dawg)
ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 048A89E0 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddatabigram-dawg)
ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 048A8A80 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddatafreq-dawg)

C:\Program Files\Tesseract-OCR>tesseract -v
tesseract 4.00.00alpha
 leptonica-1.74.1
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.5.0) : libpng 1.6.20 : libtiff 4
.0.6 : zlib 1.2.8 : libwebp 0.4.3 : libopenjp2 2.1.0

Please help in this regard
installed on windows 7 Installed package tesseract-ocr-setup-4.00.00dev  Using dawg2wordlist on lstm-word-dawg with the unicharset in the traineddata files creates a wordlist with 'junk' words (similar to what one gets when cube-word-dawg is processed with unicharset instead of cube-unicharset).

So either the lstm-unicharset has not been included in the traineddata or the lstm version of unicharset has not been included in the traineddata.

e.g. for English, see the commands and a sample of resulting wordlist ..

dawg2wordlist eng.unicharset eng.word-dawg eng.word.txt

e
en
entrepreneur
entrepreneurs
entrepreneurship
entrepreneurial
entrepreneur's
entrenched

dawg2wordlist eng.cube-unicharset eng.cube-word-dawg eng.cube.cube-word.txt

t
tATu
tBlog
tCK
tHE
tHe
tHeM
tMP
tO
tPA
tRNA
ta
tab
tabbed

However, using the following gives incorrect wordlists ..

dawg2wordlist eng.unicharset eng.lstm-word-dawg eng.lstm-word.txt

5
5h
5hr
5hrh
5hrh0
5hrh0%
5hrh0%bTIr
5hrh0%bTIr1
5hrh0%bTIrM
5hrh0%bTIrO
5hrh0%bTIr%v

Similar to the erroneous wordlist, if the cube dawg is processed with the regular unicharset

dawg2wordlist eng.unicharset eng.cube-word-dawg eng.cube-word.txt

Joined
Joined|Ph
JoinedBAe1
Joined-6
Joined¬∞R
Joined¬∞v
Joined¬∞vg
Joinedg%
JoinedX
Joined%|
Joined]a|

 However, removal of all dawg files from the traineddata does not seem to degrade the accuracy - tested with the phototest.tif and eurotext.tif test files.

https://github.com/Shreeshrii/tessdata4alpha/blob/master/en4.traineddata has this smaller minimal LSTM traineddata for English, used for the test. Unicharset was used for converting by dawg2wordlist. Will there be a new version of the program using LSTM instead of unicharset for viewing the wordlist, numbers and punctuation lists?  [Sat Dec 3 15:06:31 DST 2016] /usr/local/bin/tesseract /tmp/tmp.6Fy6JZCueq/eng/eng.Verdana_Italic.exp0.tif /tmp/tmp.6Fy6JZCueq/eng/eng.Verdana_Italic.exp0 lstm.train
read_params_file: Can't open lstm.train

https://github.com/tesseract-ocr/tesseract/tree/master/tessdata/configs
does not have the file lstm.train in it Fixed in 65517794f9bb  Hi, I've been trying to build the training tools, but still can not success.

I already installed the 3 dependencies mentioned at [Training Tesseract](https://github.com/tesseract-ocr/tesseract/wiki/Training-Tesseract#additional-libraries-required) :

1. libicu
2. libpango
3. libcairo

I also build leptonica  in the same machine.
All the native libraries are already added to $LD_LIBRARY_PATH and binaries to $PATH.
I am using gcc 4.8.4 whic meets c++11 needed standards.

Standing at root source of Tesseract, after running **./configure --prefix=path/to/tesseract** I am still getting the message: **You can not build training tools because of missing dependency.**

This is the configure output:

```
checking for g++... g++
checking for C++ compiler default output file name... a.out
checking whether the C++ compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables... 
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
fatal: Not a git repository: './.git'
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking for gawk... gawk
checking whether make sets $(MAKE)... yes
checking for style of include used by make... GNU
checking dependency style of g++... gcc3
checking whether to enable maintainer-specific portions of Makefiles... no
checking build system type... x86_64-unknown-linux-gnu
checking host system type... x86_64-unknown-linux-gnu
checking --enable-graphics argument... yes
checking whether to disable cube... no
checking --enable-embedded argument... no
checking for  option to support OpenMP... -fopenmp
checking --enable-opencl argument... no
checking how to run the C++ preprocessor... g++ -E
checking for grep that handles long lines and -e... /bin/grep
checking for egrep... /bin/grep -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking CL/cl.h usability... no
checking CL/cl.h presence... no
checking for CL/cl.h... no
checking OpenCL/cl.h usability... no
checking OpenCL/cl.h presence... no
checking for OpenCL/cl.h... no
checking tiffio.h usability... yes
checking tiffio.h presence... yes
checking for tiffio.h... yes
checking for clGetPlatformIDs in -lOpenCL... no
checking --enable-visibility argument... no
checking --enable-multiple-libraries argument... no
checking whether to use tessdata-prefix... yes
checking whether to enable debugging... no
checking for gcc... gcc
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking dependency style of gcc... gcc3
checking for a sed that does not truncate output... /bin/sed
checking for fgrep... /bin/grep -F
checking for ld used by gcc... /usr/bin/ld
checking if the linker (/usr/bin/ld) is GNU ld... yes
checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
checking the name lister (/usr/bin/nm -B) interface... BSD nm
checking whether ln -s works... yes
checking the maximum length of command line arguments... 1966080
checking whether the shell understands some XSI constructs... yes
checking whether the shell understands "+="... yes
checking for /usr/bin/ld option to reload object files... -r
checking for objdump... objdump
checking how to recognize dependent libraries... pass_all
checking for ar... ar
checking for strip... strip
checking for ranlib... ranlib
checking command to parse /usr/bin/nm -B output from gcc object... ok
checking for dlfcn.h... yes
checking whether we are using the GNU C++ compiler... (cached) yes
checking whether g++ accepts -g... (cached) yes
checking how to run the C++ preprocessor... g++ -E
checking for objdir... .libs
checking if gcc supports -fno-rtti -fno-exceptions... no
checking for gcc option to produce PIC... -fPIC -DPIC
checking if gcc PIC flag -fPIC -DPIC works... yes
checking if gcc static flag -static works... yes
checking if gcc supports -c -o file.o... yes
checking if gcc supports -c -o file.o... (cached) yes
checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking whether -lc should be explicitly linked in... no
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... yes
checking for ld used by g++... /usr/bin/ld -m elf_x86_64
checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes
checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking for g++ option to produce PIC... -fPIC -DPIC
checking if g++ PIC flag -fPIC -DPIC works... yes
checking if g++ static flag -static works... yes
checking if g++ supports -c -o file.o... yes
checking if g++ supports -c -o file.o... (cached) yes
checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether byte ordering is bigendian... no
checking if compiling with clang... no
checking whether compiler supports C++11... yes
checking for snprintf... yes
checking for library containing sem_init... -lpthread
checking for ANSI C header files... (cached) yes
checking whether time.h and sys/time.h may both be included... yes
checking for sys/wait.h that is POSIX.1 compatible... yes
checking sys/ipc.h usability... yes
checking sys/ipc.h presence... yes
checking for sys/ipc.h... yes
checking sys/shm.h usability... yes
checking sys/shm.h presence... yes
checking for sys/shm.h... yes
checking limits.h usability... yes
checking limits.h presence... yes
checking for limits.h... yes
checking malloc.h usability... yes
checking malloc.h presence... yes
checking for malloc.h... yes
checking for stdbool.h that conforms to C99... yes
checking for _Bool... no
checking whether #! works in shell scripts... yes
checking for special C compiler options needed for large files... no
checking for _FILE_OFFSET_BITS value needed for large files... no
checking for getline... yes
checking for wchar_t... yes
checking for long long int... yes
checking for off_t... yes
checking for mbstate_t... yes
checking for leptonica... yes
checking for l_generateCIDataForPdf in -llept... yes
checking leptonica headers version >= 1.71... yes
checking unicode/uchar.h usability... yes
checking unicode/uchar.h presence... yes
checking for unicode/uchar.h... yes
checking for pkg-config... /usr/bin/pkg-config
checking pkg-config is at least version 0.9.0... yes
checking for pango... yes
checking for cairo... yes
configure: creating ./config.status
config.status: creating Makefile
config.status: creating tesseract.pc
config.status: creating api/Makefile
config.status: creating ccmain/Makefile
config.status: creating opencl/Makefile
config.status: creating ccstruct/Makefile
config.status: creating ccutil/Makefile
config.status: creating classify/Makefile
config.status: creating cube/Makefile
config.status: creating cutil/Makefile
config.status: creating dict/Makefile
config.status: creating neural_networks/runtime/Makefile
config.status: creating textord/Makefile
config.status: creating viewer/Makefile
config.status: creating wordrec/Makefile
config.status: creating tessdata/Makefile
config.status: creating tessdata/configs/Makefile
config.status: creating tessdata/tessconfigs/Makefile
config.status: creating testing/Makefile
config.status: creating java/Makefile
config.status: creating java/com/Makefile
config.status: creating java/com/google/Makefile
config.status: creating java/com/google/scrollview/Makefile
config.status: creating java/com/google/scrollview/events/Makefile
config.status: creating java/com/google/scrollview/ui/Makefile
config.status: creating doc/Makefile
config.status: creating config_auto.h
config.status: executing depfiles commands
config.status: executing libtool commands

```

Does any one can help me with this? I am stocked at this point.
Thank you so much! What OS ?
Which branch, 3.05 or master (4.0)

For training tools you need Dev versions

sudo apt-get install libicu-dev
sudo apt-get install libpango1.0-dev
sudo apt-get install libcairo2-dev @Shreeshrii I downloaded it directly from master branch a month ago, if I type _tesseract --version_ I get
```
tesseract 3.05.00dev
leptonica-1.73
libpng 1.2.49 : libtiff 3.9.4 : zlib 1.2.3
```
I am using Oracle Linux Server release 6.8 so, unfortunately I can not use apt-get. Also tried sudo yum update and then yum install any-of-3packages , but didn't work. That is why I decided to download every dependency and install them in a common prefix. The sites where I obtained these tools are: 
http://packages.ubuntu.com/trusty/libicu-dev: icu_52.1.orig.tar.gz,
http://www.linuxfromscratch.org/blfs/view/svn/x/cairo.html: cairo-1.14.6.tar.xz, http://www.linuxfromscratch.org/blfs/view/svn/x/pango.html: pango-1.40.3.tar.xz
And all the dependencies specified in their websites.

Thank you!!
 @stweil  Actually I didn't update Tesseract, I downloaded the latest version from master a month ago and also use .autogen.sh, I will try to re build it again and will let you know if it works.

Thank you!! Please try with the following packages and their dependencies

http://packages.ubuntu.com/trusty/libicu-dev

http://packages.ubuntu.com/trusty/libpango1.0-dev

http://packages.ubuntu.com/trusty/libcairo2-dev It seems yum uses different packages and names are also different. Try pango_devel and cairo-devel @stweil I am trying to re build Tesseract, but now I am getting the following:

> ./.libs/libtesseract.so: undefined reference to `omp_get_thread_num'
> ./.libs/libtesseract.so: undefined reference to `GOMP_sections_end_nowait'
> ./.libs/libtesseract.so: undefined reference to `omp_get_num_threads'
> ./.libs/libtesseract.so: undefined reference to `GOMP_parallel_start'
> ./.libs/libtesseract.so: undefined reference to `GOMP_parallel_end'
> ./.libs/libtesseract.so: undefined reference to `GOMP_sections_next'
> ./.libs/libtesseract.so: undefined reference to `GOMP_parallel_sections_start'

I set thevariables setenv` CFLAGS /usr/include` `setenv LDFLAGS /usr/lib` and tried` setenv LDFLAGS /usr/local/lib` `setenv LDFLAGS /usr/local/lib`

**I see libgomp.so.1  libgomp.so.1.0.0** under **/usr/lib** and **/usr/lib64** 
do you have any idea of what is happening? Becuase I also have installed Leptonica, but I don¬¥t know if I am missing something during compilation process.

Thank you !! @Shreeshrii I tried what you mentioned, using yum and downloading these packages, but still not working.
Do I have to set anything else rather than just adding the native libraries  paths to my LD_LIBRARY_PATH? Something that might cause my GCC crash because of possible missing dependencies?

I just wonder why it keeps telling me that I can not build training tools since The aoutput shows the following: 

```
checking for pango... yes
checking for cairo... yes
```
Can¬¥t see anything releated with libicu, have also installed it.

Thanks a lot Shreeshrii! @stweil  Those messages are appearing compiling master (4.0) using gcc 4.8.4, so I compiled version 3.05 instead. Still working on building training tools. Sure @stweil !
This is the configure output with any option:

`./configure`

> checking for g++... g++
> checking for C++ compiler default output file name... a.out
> checking whether the C++ compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables... 
> checking for suffix of object files... o
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ accepts -g... yes
> fatal: Not a git repository: './.git'
> checking for a BSD-compatible install... /usr/bin/install -c
> checking whether build environment is sane... yes
> checking for a thread-safe mkdir -p... /bin/mkdir -p
> checking for gawk... gawk
> checking whether make sets $(MAKE)... yes
> checking for style of include used by make... GNU
> checking dependency style of g++... gcc3
> checking whether to enable maintainer-specific portions of Makefiles... no
> checking build system type... x86_64-unknown-linux-gnu
> checking host system type... x86_64-unknown-linux-gnu
> checking --enable-graphics argument... yes
> checking whether to disable cube... no
> checking --enable-embedded argument... no
> checking for  option to support OpenMP... -fopenmp
> checking --enable-opencl argument... no
> checking how to run the C++ preprocessor... g++ -E
> checking for grep that handles long lines and -e... /bin/grep
> checking for egrep... /bin/grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking CL/cl.h usability... no
> checking CL/cl.h presence... no
> checking for CL/cl.h... no
> checking OpenCL/cl.h usability... no
> checking OpenCL/cl.h presence... no
> checking for OpenCL/cl.h... no
> checking tiffio.h usability... yes
> checking tiffio.h presence... yes
> checking for tiffio.h... yes
> checking for clGetPlatformIDs in -lOpenCL... no
> checking --enable-visibility argument... no
> checking --enable-multiple-libraries argument... no
> checking whether to use tessdata-prefix... yes
> checking whether to enable debugging... no
> checking for gcc... gcc
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> checking dependency style of gcc... gcc3
> checking for a sed that does not truncate output... /bin/sed
> checking for fgrep... /bin/grep -F
> checking for ld used by gcc... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
> checking the name lister (/usr/bin/nm -B) interface... BSD nm
> checking whether ln -s works... yes
> checking the maximum length of command line arguments... 1966080
> checking whether the shell understands some XSI constructs... yes
> checking whether the shell understands "+="... yes
> checking for /usr/bin/ld option to reload object files... -r
> checking for objdump... objdump
> checking how to recognize dependent libraries... pass_all
> checking for ar... ar
> checking for strip... strip
> checking for ranlib... ranlib
> checking command to parse /usr/bin/nm -B output from gcc object... ok
> checking for dlfcn.h... yes
> checking whether we are using the GNU C++ compiler... (cached) yes
> checking whether g++ accepts -g... (cached) yes
> checking how to run the C++ preprocessor... g++ -E
> checking for objdir... .libs
> checking if gcc supports -fno-rtti -fno-exceptions... no
> checking for gcc option to produce PIC... -fPIC -DPIC
> checking if gcc PIC flag -fPIC -DPIC works... yes
> checking if gcc static flag -static works... yes
> checking if gcc supports -c -o file.o... yes
> checking if gcc supports -c -o file.o... (cached) yes
> checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking whether -lc should be explicitly linked in... no
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... yes
> checking for ld used by g++... /usr/bin/ld -m elf_x86_64
> checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes
> checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking for g++ option to produce PIC... -fPIC -DPIC
> checking if g++ PIC flag -fPIC -DPIC works... yes
> checking if g++ static flag -static works... yes
> checking if g++ supports -c -o file.o... yes
> checking if g++ supports -c -o file.o... (cached) yes
> checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether byte ordering is bigendian... no
> checking if compiling with clang... no
> checking whether compiler supports C++11... yes
> checking for snprintf... yes
> checking for library containing sem_init... -lpthread
> checking for ANSI C header files... (cached) yes
> checking whether time.h and sys/time.h may both be included... yes
> checking for sys/wait.h that is POSIX.1 compatible... yes
> checking sys/ipc.h usability... yes
> checking sys/ipc.h presence... yes
> checking for sys/ipc.h... yes
> checking sys/shm.h usability... yes
> checking sys/shm.h presence... yes
> checking for sys/shm.h... yes
> checking limits.h usability... yes
> checking limits.h presence... yes
> checking for limits.h... yes
> checking malloc.h usability... yes
> checking malloc.h presence... yes
> checking for malloc.h... yes
> checking for stdbool.h that conforms to C99... yes
> checking for _Bool... no
> checking whether #! works in shell scripts... yes
> checking for special C compiler options needed for large files... no
> checking for _FILE_OFFSET_BITS value needed for large files... no
> checking for getline... yes
> checking for wchar_t... yes
> checking for long long int... yes
> checking for off_t... yes
> checking for mbstate_t... yes
> checking for leptonica... yes
> checking for l_generateCIDataForPdf in -llept... yes
> checking leptonica headers version >= 1.71... yes
> checking unicode/uchar.h usability... yes
> checking unicode/uchar.h presence... yes
> checking for unicode/uchar.h... yes
> checking for pkg-config... /usr/bin/pkg-config
> checking pkg-config is at least version 0.9.0... yes
> checking for pango... yes
> checking for cairo... yes
> configure: creating ./config.status
> config.status: creating Makefile
> config.status: creating tesseract.pc
> config.status: creating api/Makefile
> config.status: creating ccmain/Makefile
> config.status: creating opencl/Makefile
> config.status: creating ccstruct/Makefile
> config.status: creating ccutil/Makefile
> config.status: creating classify/Makefile
> config.status: creating cube/Makefile
> config.status: creating cutil/Makefile
> config.status: creating dict/Makefile
> config.status: creating neural_networks/runtime/Makefile
> config.status: creating textord/Makefile
> config.status: creating viewer/Makefile
> config.status: creating wordrec/Makefile
> config.status: creating tessdata/Makefile
> config.status: creating tessdata/configs/Makefile
> config.status: creating tessdata/tessconfigs/Makefile
> config.status: creating testing/Makefile
> config.status: creating java/Makefile
> config.status: creating java/com/Makefile
> config.status: creating java/com/google/Makefile
> config.status: creating java/com/google/scrollview/Makefile
> config.status: creating java/com/google/scrollview/events/Makefile
> config.status: creating java/com/google/scrollview/ui/Makefile
> config.status: creating doc/Makefile
> config.status: creating config_auto.h
> config.status: config_auto.h is unchanged
> config.status: executing depfiles commands
> config.status: executing libtool commands
> 
> Configuration is done.
> You can now build and install tesseract by running:
> 
> $ make
> $ sudo make install
> 
> **You can not build training tools because of missing dependency.**
> Check configure output for details. Thanks @stweil 
The make output is pretty large, so it's attached at the end. 
Also, after trying 
`./configure --prefix=path --disable-openmp` 
I'm still getting the message 
"You can not build training tools because of missing dependency."

[make-output.txt](https://github.com/tesseract-ocr/tesseract/files/634989/make-output.txt)

 Sure, actually I tried with both versions, but I'am getting the same message after `./configure`.
When I do `make`:

3.05 finishes.

4.00 throws:

```
./.libs/libtesseract.so: undefined reference to `omp_get_thread_num'
./.libs/libtesseract.so: undefined reference to `GOMP_sections_end_nowait'
./.libs/libtesseract.so: undefined reference to `omp_get_num_threads'
./.libs/libtesseract.so: undefined reference to `GOMP_parallel_start'
./.libs/libtesseract.so: undefined reference to `GOMP_parallel_end'
./.libs/libtesseract.so: undefined reference to `GOMP_sections_next'
./.libs/libtesseract.so: undefined reference to `GOMP_parallel_sections_start'
```
 Thanks for your help guys, I will let you know! Hi! I am sorry for the delay.
I could build tesseract now, but still can¬¥t build training tools, here is what I did:

I downloaded the code from master just today, after doing 
```
./autogen.sh
setenv LIBLEPT_HEADERSDIR $install/include
./configure --prefix=$install --with-extra-libraries=$install/lib --disable-openmp
```

Now I see that there are different outputs related with Leptonica and one of them is not saying yes, I wonder what does this new param says because I have installed latest Leptonica's version (1.73) under `$install`. Also In installed libicu under this location and I am seeing an issue with this either:

> checking for g++... g++
> checking for C++ compiler default output file name... a.out
> checking whether the C++ compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables... 
> checking for suffix of object files... o
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ accepts -g... yes
> fatal: Not a git repository: './.git'
> checking for a BSD-compatible install... /usr/bin/install -c
> checking whether build environment is sane... yes
> checking for a thread-safe mkdir -p... /bin/mkdir -p
> checking for gawk... gawk
> checking whether make sets $(MAKE)... yes
> checking for style of include used by make... GNU
> checking dependency style of g++... gcc3
> checking whether to enable maintainer-specific portions of Makefiles... no
> checking build system type... x86_64-unknown-linux-gnu
> checking host system type... x86_64-unknown-linux-gnu
> checking --enable-graphics argument... yes
> checking whether to disable cube... no
> checking --enable-embedded argument... no
> checking for  option to support OpenMP... -fopenmp
> checking --enable-opencl argument... no
> checking how to run the C++ preprocessor... g++ -E
> checking for grep that handles long lines and -e... /bin/grep
> checking for egrep... /bin/grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking CL/cl.h usability... no
> checking CL/cl.h presence... no
> checking for CL/cl.h... no
> checking OpenCL/cl.h usability... no
> checking OpenCL/cl.h presence... no
> checking for OpenCL/cl.h... no
> checking tiffio.h usability... yes
> checking tiffio.h presence... yes
> checking for tiffio.h... yes
> checking for clGetPlatformIDs in -lOpenCL... no
> checking --enable-visibility argument... no
> checking --enable-multiple-libraries argument... no
> checking whether to use tessdata-prefix... yes
> checking whether to enable debugging... no
> checking for gcc... gcc
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> checking dependency style of gcc... gcc3
> checking for a sed that does not truncate output... /bin/sed
> checking for fgrep... /bin/grep -F
> checking for ld used by gcc... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
> checking the name lister (/usr/bin/nm -B) interface... BSD nm
> checking whether ln -s works... yes
> checking the maximum length of command line arguments... 1572864
> checking whether the shell understands some XSI constructs... yes
> checking whether the shell understands "+="... yes
> checking for /usr/bin/ld option to reload object files... -r
> checking for objdump... objdump
> checking how to recognize dependent libraries... pass_all
> checking for ar... ar
> checking for strip... strip
> checking for ranlib... ranlib
> checking command to parse /usr/bin/nm -B output from gcc object... ok
> checking for dlfcn.h... yes
> checking whether we are using the GNU C++ compiler... (cached) yes
> checking whether g++ accepts -g... (cached) yes
> checking how to run the C++ preprocessor... g++ -E
> checking for objdir... .libs
> checking if gcc supports -fno-rtti -fno-exceptions... no
> checking for gcc option to produce PIC... -fPIC -DPIC
> checking if gcc PIC flag -fPIC -DPIC works... yes
> checking if gcc static flag -static works... yes
> checking if gcc supports -c -o file.o... yes
> checking if gcc supports -c -o file.o... (cached) yes
> checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking whether -lc should be explicitly linked in... no
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... yes
> checking for ld used by g++... /usr/bin/ld -m elf_x86_64
> checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes
> checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking for g++ option to produce PIC... -fPIC -DPIC
> checking if g++ PIC flag -fPIC -DPIC works... yes
> checking if g++ static flag -static works... yes
> checking if g++ supports -c -o file.o... yes
> checking if g++ supports -c -o file.o... (cached) yes
> checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether byte ordering is bigendian... no
> checking if compiling with clang... no
> checking whether compiler supports C++11... yes
> checking for snprintf... yes
> checking for library containing sem_init... -lpthread
> checking for ANSI C header files... (cached) yes
> checking whether time.h and sys/time.h may both be included... yes
> checking for sys/wait.h that is POSIX.1 compatible... yes
> checking sys/ipc.h usability... yes
> checking sys/ipc.h presence... yes
> checking for sys/ipc.h... yes
> checking sys/shm.h usability... yes
> checking sys/shm.h presence... yes
> checking for sys/shm.h... yes
> checking limits.h usability... yes
> checking limits.h presence... yes
> checking for limits.h... yes
> checking malloc.h usability... yes
> checking malloc.h presence... yes
> checking for malloc.h... yes
> checking for stdbool.h that conforms to C99... yes
> checking for _Bool... no
> checking whether #! works in shell scripts... yes
> checking for special C compiler options needed for large files... no
> checking for _FILE_OFFSET_BITS value needed for large files... no
> checking for getline... yes
> checking for wchar_t... yes
> checking for long long int... yes
> checking for off_t... yes
> checking for mbstate_t... yes
> checking for pkg-config... /usr/bin/pkg-config
> checking pkg-config is at least version 0.9.0... yes
> **checking for LEPTONICA... no**
> **checking for leptonica... yes**
> checking for l_generateCIDataForPdf in -llept... yes
> checking leptonica headers version >= 1.71... yes
> **checking for ICU_UC... no**
> **checking for ICU_I18N... no**
> checking unicode/uchar.h usability... yes
> checking unicode/uchar.h presence... yes
> checking for unicode/uchar.h... yes
> checking for pango... yes
> checking for cairo... yes
> configure: creating ./config.status
> config.status: creating Makefile
> config.status: creating tesseract.pc
> config.status: creating api/Makefile
> config.status: creating arch/Makefile
> config.status: creating ccmain/Makefile
> config.status: creating opencl/Makefile
> config.status: creating ccstruct/Makefile
> config.status: creating ccutil/Makefile
> config.status: creating classify/Makefile
> config.status: creating cube/Makefile
> config.status: creating cutil/Makefile
> config.status: creating dict/Makefile
> config.status: creating lstm/Makefile
> config.status: creating neural_networks/runtime/Makefile
> config.status: creating textord/Makefile
> config.status: creating viewer/Makefile
> config.status: creating wordrec/Makefile
> config.status: creating tessdata/Makefile
> config.status: creating tessdata/configs/Makefile
> config.status: creating tessdata/tessconfigs/Makefile
> config.status: creating testing/Makefile
> config.status: creating java/Makefile
> config.status: creating java/com/Makefile
> config.status: creating java/com/google/Makefile
> config.status: creating java/com/google/scrollview/Makefile
> config.status: creating java/com/google/scrollview/events/Makefile
> config.status: creating java/com/google/scrollview/ui/Makefile
> config.status: creating doc/Makefile
> config.status: creating config_auto.h
> config.status: executing depfiles commands
> config.status: executing libtool commands
> 
> Configuration is done.
> You can now build and install tesseract by running:
> 
> $ make
> $ sudo make install
> 
> **You can not build training tools because of missing dependency.**
> Check configure output for details.
 
I can execute
```
make 
make install 
```
without any problem so I guess 6140be6 fixed it but still can not build training tools.

Here is what I have under `$install` :
**lib**
liblept.a  liblept.la  liblept.so  liblept.so.1  liblept.so.1.73  liblept.so.5  liblept.so.5.0.0  libtesseract.a  libtesseract.la  libtesseract.so  libtesseract.so.4  libtesseract.so.4.0.0  modules  pkgconfig  terminfo

**include** 
leptonica  tesseract

**bin**
bash  convertfilestopdf  convertfilestops  convertformat  convertsegfilestopdf  convertsegfilestops  converttopdf  converttops  fileinfo  printimage  printsplitimage  printtiff  sh  splitimage2pdf  tesseract  xtractprotos

I am also adding `$install/lib` to my` $LD_LIBRARY_PATH` and `$install/bin` to my `$PATH` before building Tesseract.

Thank you!


 >checking for LEPTONICA... no
>checking for leptonica... yes

That's funny! Alright. 
Now, before running ./configure... I did:

`setenv PKG_CONFIG_PATH $install/usr/lib64/pkgconfig:$install/lib/pkgconfig`

Because this is where I also installed libicu-dev. Here is the configure output:

> checking for g++... g++
> checking for C++ compiler default output file name... a.out
> checking whether the C++ compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables... 
> checking for suffix of object files... o
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ accepts -g... yes
> fatal: Not a git repository: './.git'
> checking for a BSD-compatible install... /usr/bin/install -c
> checking whether build environment is sane... yes
> checking for a thread-safe mkdir -p... /bin/mkdir -p
> checking for gawk... gawk
> checking whether make sets $(MAKE)... yes
> checking for style of include used by make... GNU
> checking dependency style of g++... gcc3
> checking whether to enable maintainer-specific portions of Makefiles... no
> checking build system type... x86_64-unknown-linux-gnu
> checking host system type... x86_64-unknown-linux-gnu
> checking --enable-graphics argument... yes
> checking whether to disable cube... no
> checking --enable-embedded argument... no
> checking --enable-opencl argument... no
> checking how to run the C++ preprocessor... g++ -E
> checking for grep that handles long lines and -e... /bin/grep
> checking for egrep... /bin/grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking CL/cl.h usability... no
> checking CL/cl.h presence... no
> checking for CL/cl.h... no
> checking OpenCL/cl.h usability... no
> checking OpenCL/cl.h presence... no
> checking for OpenCL/cl.h... no
> checking tiffio.h usability... yes
> checking tiffio.h presence... yes
> checking for tiffio.h... yes
> checking for clGetPlatformIDs in -lOpenCL... no
> checking --enable-visibility argument... no
> checking --enable-multiple-libraries argument... no
> checking whether to use tessdata-prefix... yes
> checking whether to enable debugging... no
> checking for gcc... gcc
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> checking dependency style of gcc... gcc3
> checking for a sed that does not truncate output... /bin/sed
> checking for fgrep... /bin/grep -F
> checking for ld used by gcc... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
> checking the name lister (/usr/bin/nm -B) interface... BSD nm
> checking whether ln -s works... yes
> checking the maximum length of command line arguments... 1572864
> checking whether the shell understands some XSI constructs... yes
> checking whether the shell understands "+="... yes
> checking for /usr/bin/ld option to reload object files... -r
> checking for objdump... objdump
> checking how to recognize dependent libraries... pass_all
> checking for ar... ar
> checking for strip... strip
> checking for ranlib... ranlib
> checking command to parse /usr/bin/nm -B output from gcc object... ok
> checking for dlfcn.h... yes
> checking whether we are using the GNU C++ compiler... (cached) yes
> checking whether g++ accepts -g... (cached) yes
> checking how to run the C++ preprocessor... g++ -E
> checking for objdir... .libs
> checking if gcc supports -fno-rtti -fno-exceptions... no
> checking for gcc option to produce PIC... -fPIC -DPIC
> checking if gcc PIC flag -fPIC -DPIC works... yes
> checking if gcc static flag -static works... yes
> checking if gcc supports -c -o file.o... yes
> checking if gcc supports -c -o file.o... (cached) yes
> checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking whether -lc should be explicitly linked in... no
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... yes
> checking for ld used by g++... /usr/bin/ld -m elf_x86_64
> checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes
> checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking for g++ option to produce PIC... -fPIC -DPIC
> checking if g++ PIC flag -fPIC -DPIC works... yes
> checking if g++ static flag -static works... yes
> checking if g++ supports -c -o file.o... yes
> checking if g++ supports -c -o file.o... (cached) yes
> checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether byte ordering is bigendian... no
> checking if compiling with clang... no
> checking whether compiler supports C++11... yes
> checking for snprintf... yes
> checking for library containing sem_init... -lpthread
> checking for ANSI C header files... (cached) yes
> checking whether time.h and sys/time.h may both be included... yes
> checking for sys/wait.h that is POSIX.1 compatible... yes
> checking sys/ipc.h usability... yes
> checking sys/ipc.h presence... yes
> checking for sys/ipc.h... yes
> checking sys/shm.h usability... yes
> checking sys/shm.h presence... yes
> checking for sys/shm.h... yes
> checking limits.h usability... yes
> checking limits.h presence... yes
> checking for limits.h... yes
> checking malloc.h usability... yes
> checking malloc.h presence... yes
> checking for malloc.h... yes
> checking for stdbool.h that conforms to C99... yes
> checking for _Bool... no
> checking whether #! works in shell scripts... yes
> checking for special C compiler options needed for large files... no
> checking for _FILE_OFFSET_BITS value needed for large files... no
> checking for getline... yes
> checking for wchar_t... yes
> checking for long long int... yes
> checking for off_t... yes
> checking for mbstate_t... yes
> checking for pkg-config... /usr/bin/pkg-config
> checking pkg-config is at least version 0.9.0... yes
> **checking for LEPTONICA... yes**
> checking for l_generateCIDataForPdf in -llept... yes
> **checking leptonica headers version >= 1.71... yes**
> **checking for ICU_UC... yes**
> **checking for ICU_I18N... yes**
> **checking for pango... yes**
> **checking for cairo... yes**
> configure: creating ./config.status
> config.status: creating Makefile
> config.status: creating tesseract.pc
> config.status: creating api/Makefile
> config.status: creating arch/Makefile
> config.status: creating ccmain/Makefile
> config.status: creating opencl/Makefile
> config.status: creating ccstruct/Makefile
> config.status: creating ccutil/Makefile
> config.status: creating classify/Makefile
> config.status: creating cube/Makefile
> config.status: creating cutil/Makefile
> config.status: creating dict/Makefile
> config.status: creating lstm/Makefile
> config.status: creating neural_networks/runtime/Makefile
> config.status: creating textord/Makefile
> config.status: creating viewer/Makefile
> config.status: creating wordrec/Makefile
> config.status: creating tessdata/Makefile
> config.status: creating tessdata/configs/Makefile
> config.status: creating tessdata/tessconfigs/Makefile
> config.status: creating testing/Makefile
> config.status: creating java/Makefile
> config.status: creating java/com/Makefile
> config.status: creating java/com/google/Makefile
> config.status: creating java/com/google/scrollview/Makefile
> config.status: creating java/com/google/scrollview/events/Makefile
> config.status: creating java/com/google/scrollview/ui/Makefile
> config.status: creating doc/Makefile
> config.status: creating config_auto.h
> config.status: executing depfiles commands
> config.status: executing libtool commands
> 
> Configuration is done.
> You can now build and install tesseract by running:
> 
> $ make
> $ sudo make install
> 
> **You can not build training tools because of missing dependency.**
> Check configure output for details.

Now, after this check it seems that I have all the dependencies, but still can't go to the training tools building process. :s




 Hi guys.
Thank you very much for your help.
I could now build training tools using master (Tesseract 4.0).

I be able to build them I had **to remove all the lines** `AM_CONDITIONAL([ENABLE_TRAINING], false)`   in **configure.ac**, to be specific, they were 4.

After that, then trying to build training tools I saw an error related with libicu, basically the compiler was not finding some .h files. As I have libicu installed under $install and I also added $install/lib to $LD_LIBRARY_PATH, $install/bin to $PATH and also set $PKG_CONFIG_PATH=$install/usr/lib64/pkgconfig:$install/lib/pkgconfig I guess there was some other configuration to tell GCC where to look for the include files, but I could not find it, so to solve this I had to **copy all the files under `$install/include/unicode` to `/usr/include/unicode` so GCC could find these files**.  Do you have any suggestion when this happens to tell GCC specifically where to look for the .h files? (a non standard "include" directory) I think there should be another way so I don't really need to copy the include files to the standard location.

I have one final question: Do you guys know where can I ask questions to Leptonica's team? They have a mailing list in Google Code, but it seems that we can not open any other issue.

Once again, thanks for your help on this! I think that the pango-devel and cairo-devel in RHEL/Centos 6 would work with Tesseract 4. >I have one final question: Do you guys know where can I ask questions to Leptonica's team? They have a mailing list in Google Code, but it seems that we can not open any other issue.

(I)
https://github.com/DanBloomberg/leptonica/issues

(II)
From http://leptonica.org/

>Contact: Dan Bloomberg (bloomberg "at" ieee "dot" org) for questions and suggestions
 Can we close this issue? I am sorry! 
Sure, now you can close this issue.

Once again, thank you for helping me to solve this.
I am now running training tools on Oracle Linux Server 6.8 successfully.

Merry Christmas and happy new year!  While using png files as input and using oem 4 - LSTM, tesseract gives warnings on console in command mode. oem 0, 1, 2 and 3 gives no warnings.

On Windows 10, using 4.0 Alpha binaries provided by @stweil  and 4.0 alpha traineddata 

>>tesseract hin001.png hin001-hin-3 -oem 3 -l hin
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica

>>tesseract hin001.png hin001-hin-4 -oem 4 -l hin
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
...

The warnings seem to be given per line, so a page with 20 lines of text gets about 40 lines of messages.

I have not tested this in the linux environment. The warnings are probably from leptonica.
 There are a large number of warning messages when using -oem 4, not with other oem modes.

Is there a way to eliminate these? 

C:\shree>tesseract san001.png san001 -oem 4 -l san
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 18 diacritics
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file



![san001](https://cloud.githubusercontent.com/assets/5095331/20835038/62d4e128-b8be-11e6-8d49-4ee9f2077b47.png) The warnings are indeed from Leptonica. They will not appear in Linux. You should ignore these ugly warnings.

>Is there a way to eliminate these?

https://github.com/tesseract-ocr/tesseract/issues/292#issuecomment-222529057 Warnings are not limited to png, same for tif, gif and jpg. @zdenop @amitdo Thanks!

@stweil Is the version of leptonica included with the windows binaries a debug version? >Warnings are not limited to png, same for tif, gif and jpg.

Still same answer...

It not a bug, although from an end user point of view it sure looks confusing. ++ dan.bloomberg@gmail.com
@DanBloomberg

cc:ing Dan Bloomberg for his input regarding Leptonica

On Fri, Dec 2, 2016 at 7:12 PM, Stefan Weil <notifications@github.com>
wrote:

> The warnings are an indicator for potential optimizations and require more
> examination by developers, so I see there an issue to be discussed here.
>
> AFAIK Leptonica warns when an image file is going to be mapped to memory,
> something that is unsupported for Leptonica's Windows code which uses a
> temporary file copy as an alternative.
>
> If OCR of a single image results in many (number of lines) of those
> warnings, that might be caused by the same image being opened very often,
> or Tesseract acts on in-memory line images, but Leptonica for Windows has
> to write those images to disk. Then it is clear that at least for Windows
> the performance suffers and something should be done - either in Leptonica
> code or in Tesseract.
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/522#issuecomment-264456364>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o78_PkgYGsXTyk4uL6PqJdNjEorFks5rECBXgaJpZM4LCeas>
> .
>
 @stweil
https://github.com/tesseract-ocr/tesseract/issues/292#issuecomment-222529057
How did you compile Leptonica? http://www.leptonica.org/source/README.html

>4. Compile-time control over stderr output (see environ.h)
>
>   Leptonica provides both compile-time and run-time control over
   messages and debug output (thanks to Dave Bryan).  Both compile-time
   and run-time severity thresholds can be set.  The run-time threshold
   can also be set by an environmental variable.  Messages are
   vararg-formatted and of 3 types: error, warning, informational.
   These are all macros, and can be further suppressed when
   NO_CONSOLE_IO is defined on the compile line.  For production code
   where no output is to go to stderr, compile with -DNO_CONSOLE_IO.
 https://github.com/DanBloomberg/leptonica/blob/7e0191abd/src/environ.h#L290 It's not a bug, but I agree that there is a place for improvements. In production, there should be no need to see any leptonica output (info, warnings, errors) to stderr.
Methods for suppressing them are described above by Amit.
These messages are arguably INFO rather than WARNING.

Reads and writes from/to file for in-memory I/O on Windows are no longer required for gif and tiff formats. They were never required for webp.  They are still required for jpeg, jp2k and png. Dan,

Thanks for the info.

>Reads and writes from/to file for in-memory I/O on Windows are no longer required for gif and tiff formats.

Since which version?

The solution to the optimization problem might be in this specific case to always save the textlines images to tiff in memory. Amit,

1.73 required r/w for in-memory I/O for gif and tiff on Windows. The current github master (and soon to be release 1.74.0) does not.  The tiff patch was contributed by Stefan.

Yes, any 1 bpp images (e.g., in tesseract/viewer and ccstruct) can be output in IFF_TIFF_G4, which typically has better compression than png.  Grayscale and color can be output in TIFF_ZIP or TIFF_LZW, which are typically inferior to png in compression. Stefan, we can downgrade those messages in leptonica to INFO, and you can use setMsgSeverity() to disable INFO statements. Nevertheless, this seems like a reasonable thing to do to solve this annoyance and still present other WARNING messages.
 Annoying messages have now been downgraded to INFO at github head.

You can use this in tesseract code to suppress all INFO and less urgent messages at run time:
     setMsgSeverity(L_SEVERITY_WARNING);

Alternatively, for a bit more flexibility, you can define the environmental variable
 #define  LEPT_MSG_SEVERITY   L_SEVERITY_WARNING
and use
     setMsgSeverity(L_SEVERITY_EXTERNAL);

You can also change the severity level to WARNING and higher at compile time with this compiler flag:
    -DDEFAULT_SEVERITY=4
This can be over-ridden at run time with either of the first two methods.
 >Reads and writes from/to file for in-memory I/O on Windows are no longer required for gif and tiff formats.

I wonder how giflib and libiff do the equivalence of fmemopen on Windows.
 @zdenop  That's an interesting idea.  Default setting is for INFO, WARNING and ERROR, but for a release that will be used in production it makes sense to only show ERROR. @amitdo 

Look at the leptonica wrappers for tiff (tiffio.c) and gif (gifio.c) to see how it is done.

Even better, the webp library implements compression and decompression directly with memory buffers, not with file streams. This is very nice, because it's platform independent, and you can easily read and write to files using it (see webpio.c). I wish the other image compression libraries had been implemented that way, but ...  "NOTE that if you are creating a totally new language, for which there is no existing traineddata file, **Tesseract will currently refuse to initialize with just the lstm model in it,** even if you use OEM_LSTM_ONLY as the OCR engine mode. For now, you can make it run using any existing traineddata file and adding your new lstm model and (optionally) the lstm dawgs. 

This is a point for improvement in the future. The unicharset used for the lstm has to match the unicharset used to generate the lstm-*-dawg files, but doesn't have to match the unicharset for the inttemp and base tesseract dawg files."

From: https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#combining-the-output-files @theraysmith, any chance you'll fix that for the final 4.00 release? @theraysmith, can you confirm that 5deebe6c2 solved this issue? @theraysmith

Ray, I am not able to try out LSTM training as repo is missing LSTM.train
config file. Are there other pieces also that you need to add?

On 06-Dec-2016 8:59 PM, "theraysmith" <notifications@github.com> wrote:

> Partly. I haven't closed it because you can't *create* a traineddata file
> with just the LSTM part(s) yet, and I am working on fixing that as well.
>
> On Tue, Dec 6, 2016 at 1:42 AM, Amit D. <notifications@github.com> wrote:
>
> > @theraysmith <https://github.com/theraysmith>, can you confirm that
> > 5deebe6
> > <https://github.com/tesseract-ocr/tesseract/commit/
> 5deebe6c279f70215935c1f86baa7e7016c7f2a7>
> > solved this issue?
> >
> > ‚Äî
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/521#
> issuecomment-265104978>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AL056XMVGWYPqK1Pc8XzqTxrzYjHZxgZks5rFS4MgaJpZM4LCRAs>
> > .
> >
>
>
>
> --
> Ray.
>
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/521#issuecomment-265179343>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o3NKfgM6IGnUvuVAqYrFirHq_0FMks5rFX9IgaJpZM4LCRAs>
> .
>
 @theraysmith Thanks, Ray. I will try the tutorial again now. @theraysmith Looks like some files maybe missing from langdata repo also since that was not updated for 4.0alpha. e.g. 

Failed to load radical-stroke info from: ../langdata/radical-stroke.txt msg in basetrain.log

May I also suggest that you update the alpha version in https://github.com/tesseract-ocr/tesseract/blob/master/api/baseapi.h with either git revision of just a numerical number so that it is easy to verify the version of program being used. Thanks.
 

 >@theraysmith, can you confirm that 5deebe6 solved this issue?

>Partly. I haven't closed it because you can't *create* a traineddata file
with just the LSTM part(s) yet, and I am working on fixing that as well.

It looks like 13e46ae1c solved this issue.  https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00#for-open-source-contributors

>The swaps are missing from the (De)Serialize methods of the new neural network code. Ray, you can see online Stefan's suggested changes [here](https://github.com/stweil/tesseract/commits/endian). Protocol Buffers uses Stefan's approach:
https://groups.google.com/forum/#!topic/protobuf/XbzBwCj4yL8 True. I mentioned PB because it is written by Google and they use it extensively.  >Microsoft and Torvalds have almost entirely killed off big endian machines
by now.

Another victim is IBM POWER.
 
https://www.ibm.com/developerworks/community/blogs/fe313521-2e95-46f2-817d-44a4f27eba32/entry/just_the_faqs_about_little_endian?lang=en

>Why is Linux on Power transitioning from big endian to little endian?
>
>The Power architecture is bi-endian in that it supports accessing data in both little endian and big endian modes. Although Power already has Linux distributions and supporting applications that run in big endian mode, the Linux application ecosystem for x86 platforms is much larger and Linux on x86 uses little endian mode.  Numerous clients, software partners, and IBM‚Äôs own software developers have told us that porting their software to Power becomes simpler if the Linux environment on Power supports little endian mode, more closely matching the environment provided by Linux on x86.  This new level of support will lower the barrier to entry for porting Linux on x86 software to Linux on Power.

 You can use QEMU for testing.
https://qemu.weilnetz.de/doc/qemu-doc.html#QEMU-System-emulator-for-non-PC-targets  He did provide a link for 'convert2le' (`convert2le` was clickable). Here is the link in a more visable form:
https://github.com/stweil/tesseract/blob/endian/ccutil/tessio.h#L15
A link to tessio.cpp:
https://github.com/stweil/tesseract/blob/endian/ccutil/tessio.cpp Little-endian is an abomination. It hurts the brain if you haven't grown up with it (like apparently in Arabic, which still pronounces numbers big to little except for units before tens). UTF-8 is necessarily big-endian by design so that lexicographical order is the same whether processing considers bytes (fast, using memcmp) or code points (slow). Packed bitmap representations like BMP and PNG (I only verified those) store the leftmost pixel in the most significant bits of a byte, so loading a range of pixels in a 64-bit integer, shifting them inside the processor, and writing them back only makes sense if integers are big-endian. Intelligent future civilisations are bound to reconsider the current accidental infatuation with little-endian, and will curse their predecessors for having to modify all those inflexible formats and software.

With C++, byte order or pre-evaluated need to reverse order ("bool swap") can easily be hidden in a file object member variable: it does not have to be passed around as a function argument, if that is considered too cumbersome. Has anybody even made a performance analysis before just postulating that little-endian is necessary for optimal or near-optimal performance on little-endian machines, considering that relatively little time is spent on I/O and that data files will also tend to be little-endian? I've had a look at stweil's proposal (endian branch), and I'm "not sure" that it will work... unless on a big-endian machine the file is saved twice, or read in again, perhaps because serialisation was the last thing the program did before it was restarted, or otherwise explicitly. The problem seems to be that the byte order is reversed in place, for serialisation as well as deserialisation. If you want to use a fixed endianness, you have to use a separate buffer, or do one of the workarounds described above. And that's if you're sure that each data item is visited exactly once, otherwise the reversal has to occur inside the lowest-level serialisation functions!

I would propose a different solution, where serialisation and deserialisation are unified into a single method, and instead of a FILE pointer you get a handle to an object that can do anything you want. This could easily simplify the existing code, without breaking compatibility with existing data files.

Another thing is to hide endianness handling in a library that can be reused and is maintained by people who do care about this issue. For example, a 64-bit swap in source code is either recognised by the compiler and optimised into a single instruction, or there is a better alternative with fewer operations. It would also be possible to use vector instructions to convert endianness. Well, it works as far as it was implemented and tested. Writing little endian trained data on a big endian host was not implemented. All other use cases (reading little endian on a little or big endian host, writing little endian on a little endian host) work according to my tests.

Nevertheless pull request #703 is obsolete, as Ray is currently working on improving endianness support. I would use a subset of boost serialisation: just one serialize() method template exactly as specified in boost (instead of largely redundant separate code for writing and reading), and minimal format-compatible ad-hoc Archive implementations without creating any dependency on boost itself or not yet anyway, except for reusing the idea. You can then hide the endianness policy in the Archive implementation: write host endianness (as it is now), write fixed endianness (as proposed above), write configured endianness (host endianness by default, unless perhaps publishing for reuse, or a default the other way around), write JSON, ... Better than reinventing the wheel with probably more code!

(2017-05-02 Added) Maybe it's a bit late for exactly that, I don't know... But if you want to use TFile, you should also have it do all the endianness handling, so it's never forgotten. If somebody else weren't already on it, I'd give that a try myself. Ray, the new code still uses a dynamic detection in `TessdataManager::LoadMemBuffer` to decide whether swapping is needed or not. This implies that the code supports both big and little endian data files. The drawback is additional runtime code on all kinds of machines.

Are you planning more changes? I'd drop support of big endian data files in 4.0 and add code to always write little endian ones. Then static swapping code would only be needed on big endian machines, and the large majority of machines would not need any swap code at all.
  This restores classify/adaptmatch.cpp to commit 1e60a8d71c591ab9562983778d6ce2541b75abc0
(+ two deleted empty lines).

Signed-off-by: Stefan Weil <sw@weilnetz.de>  Signed-off-by: Stefan Weil sw@weilnetz.de  Signed-off-by: Stefan Weil <sw@weilnetz.de> That's a different function which either gets called with `&recoder_` or with `NULL` as value for parameter `recoder`. It is unrelated to my modification. My point is that recoder may be NULL and you should use a pointer instead of a reference. I don't think so. The old code passed an `UnicharCompress` object. Passing a reference is the optimized equivalent. How would you assign a NULL pointer to a `UnicharCompress` object (not a pointer) as it is done in the function? I will recheck it after a good sleep :) Stefan,
I tried to examine the call hierarchy, but I didn't find a call to this variant of `InitCharSet` overloaded method. Your analysis is correct: one of the `InitCharSet` methods is unused and can be removed.

@theraysmith, are there plans to use that interface in the future, or can `void InitCharSet(const UNICHARSET& unicharset, const UnicharCompress recoder)` be removed?

@zdenop, I think this PR can be applied anyway ‚Äì we can also remove a fixed method in a later PR.
 TIP: You can also close the PR and reopen it and the CI builds will rerun. You are right :)   See also the discussion for PR #177. I start with `opencl` because the risk of conflicts with other code changes is low.  Vcpkg is a tool to acquire and build C++ open source libraries on Windows:
https://blogs.msdn.microsoft.com/vcblog/2016/09/19/vcpkg-a-tool-to-acquire-and-build-c-open-source-libraries-on-windows/

Provide a vcpkg port for tesseract would be very convenience. Egor,
It you would like to add support for Leptonica and Tesseract to the Microsoft vcpkg ports collection:
https://github.com/Microsoft/vcpkg/blob/master/CONTRIBUTING.md

 @sdcb
You might want to add a request to add Tesseract:
https://github.com/Microsoft/vcpkg/issues?q=is%3Aissue+label%3A%22new+port+request%22+is%3Aopen @zdenop, please close this issue. https://github.com/Microsoft/vcpkg/tree/master/ports/tesseract  `_mm256_extract_epi64` isn't declared for 32-bit.

```
$ ../configure --host=i686-w64-mingw32 --build=i686-w64-mingw32 --target=i686-w64-mingw32 --prefix=/local32 --disable-shared --enable-static --bindir=/local32/bin-global --disable-graphics
$ make
make  all-recursive
make[1]: Entering directory '/build/tesseract-git/build-32bit'
Making all in arch
make[2]: Entering directory '/build/tesseract-git/build-32bit/arch'
make[3]: Entering directory '/build/tesseract-git/build-32bit/arch'
/bin/sh ../libtool  --tag=CXX   --mode=compile i686-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I../../arch -I..  -O2 -DNDEBUG -I../../ccutil  -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/local32/include/leptonica -mavx -mthreads -mtune=generic -O2 -pipe -std=c++11 -MT libtesseract_avx_la-dotproductavx.lo -MD -MP -MF .deps/libtesseract_avx_la-dotproductavx.Tpo -c -o libtesseract_avx_la-dotproductavx.lo `test -f 'dotproductavx.cpp' || echo '../../arch/'`dotproductavx.cpp
/bin/sh ../libtool  --tag=CXX   --mode=compile i686-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I../../arch -I..  -O2 -DNDEBUG -I../../ccutil  -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/local32/include/leptonica -msse4.1 -mthreads -mtune=generic -O2 -pipe -std=c++11 -MT libtesseract_sse_la-dotproductsse.lo -MD -MP -MF .deps/libtesseract_sse_la-dotproductsse.Tpo -c -o libtesseract_sse_la-dotproductsse.lo `test -f 'dotproductsse.cpp' || echo '../../arch/'`dotproductsse.cpp
libtool: compile:  i686-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I../../arch -I.. -O2 -DNDEBUG -I../../ccutil -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/local32/include/leptonica -mavx -mthreads -mtune=generic -O2 -pipe -std=c++11 -MT libtesseract_avx_la-dotproductavx.lo -MD -MP -MF .deps/libtesseract_avx_la-dotproductavx.Tpo -c ../../arch/dotproductavx.cpp -o libtesseract_avx_la-dotproductavx.o
libtool: compile:  i686-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I../../arch -I.. -O2 -DNDEBUG -I../../ccutil -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/local32/include/leptonica -msse4.1 -mthreads -mtune=generic -O2 -pipe -std=c++11 -MT libtesseract_sse_la-dotproductsse.lo -MD -MP -MF .deps/libtesseract_sse_la-dotproductsse.Tpo -c ../../arch/dotproductsse.cpp -o libtesseract_sse_la-dotproductsse.o
../../arch/dotproductavx.cpp: In function 'double tesseract::DotProductAVX(const double*, const double*, int)':
../../arch/dotproductavx.cpp:93:55: error: '_mm256_extract_epi64' was not declared in this scope
       _mm256_extract_epi64(_mm256_castpd_si256(sum), 0);
                                                       ^
mv -f .deps/libtesseract_sse_la-dotproductsse.Tpo .deps/libtesseract_sse_la-dotproductsse.Plo
make[3]: *** [Makefile:542: libtesseract_avx_la-dotproductavx.lo] Error 1
make[3]: *** Waiting for unfinished jobs....
make[3]: Leaving directory '/build/tesseract-git/build-32bit/arch'
make[2]: *** [Makefile:589: all-recursive] Error 1
make[2]: Leaving directory '/build/tesseract-git/build-32bit/arch'
make[1]: *** [Makefile:484: all-recursive] Error 1
make[1]: Leaving directory '/build/tesseract-git/build-32bit'
make: *** [Makefile:393: all] Error 2
``` With `#if !defined(__WIN64__) || !defined(__AVX__)` in dotproductavx.cpp:19 it ultimately fails again due to missing references to ScrollView which is missing due to --disable-graphics:
```
Making all in api
make[2]: Entering directory '/trunk/build/tesseract-git/build-32bit/api'
/bin/sh ../libtool  --tag=CXX   --mode=link i686-w64-mingw32-g++  -mthreads -mtune=generic -O2 -pipe -std=c++11  -pipe -static-libgcc -static-libstdc++ -o tesseract.exe tesseract-tesseractmain.o libtesseract.la  -lws2_32  -llept -LD:/ab-full/local32/lib -LD:/ab-full/msys64/mingw32/lib -llept -lz -lpng -ljpeg -ltiff -llzma -ljpeg -lz
libtool: link: i686-w64-mingw32-g++ -mthreads -mtune=generic -O2 -pipe -std=c++11 -pipe -static-libgcc -static-libstdc++ -o tesseract.exe tesseract-tesseractmain.o  ./.libs/libtesseract.a -L/local32/lib -lws2_32 -LD:/ab-full/local32/lib -LD:/ab-full/msys64/mingw32/lib /local32/lib/liblept.a -lgdi32 -lpng -ltiff -llzma -ljpeg -lz -fopenmp -mthreads
./.libs/libtesseract.a(network.o):network.cpp:(.text+0xa52): undefined reference to `ScrollView::ScrollView(char const*, int, int, int, int, int, int, bool)'
./.libs/libtesseract.a(network.o):network.cpp:(.text+0xaee): undefined reference to `ScrollView::Image(Pix*, int, int)'
./.libs/libtesseract.a(network.o):network.cpp:(.text+0xb6f): undefined reference to `ScrollView::Update()'
./.libs/libtesseract.a(network.o):network.cpp:(.text+0xc14): undefined reference to `ScrollView::Update()'
./.libs/libtesseract.a(network.o):network.cpp:(.text+0x9dc): undefined reference to `ScrollView::Clear()'
./.libs/libtesseract.a(imagedata.o):imagedata.cpp:(.text+0x1626): undefined reference to `SVSync::StartThread(void* (*)(void*), void*)'
collect2.exe: error: ld returned 1 exit status
make[2]: *** [Makefile:606: tesseract.exe] Error 1
make[2]: Leaving directory '/trunk/build/tesseract-git/build-32bit/api'
make[1]: *** [Makefile:487: all-recursive] Error 1
make[1]: Leaving directory '/trunk/build/tesseract-git/build-32bit'
make: *** [Makefile:396: all] Error 2
``` A message for users:
https://groups.google.com/forum/#!topic/tesseract-ocr/e__2DN1GQb0

See also:
https://github.com/tesseract-ocr/tesseract/wiki/4.0-with-LSTM#40
https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00#for-open-source-contributors

@zdenop, you might want to add some message about the current status of master in the beginning of the README. Zdenko,

Sorry about the duplicate, I didn't see your reply to the OP. Using an ifdef to check for WIN64 fixes the missing _mm256_extract_epi64, the other one is the code in network.cpp and imagedata.cpp assuming people don't use --disable-graphics, afaik? No idea how to fix that so I'll just checkout a working commit.  I have a unit test that uses this french text:

![example](http://ocrapiservice.com/static/images/examples/french_text.png)

When I OCR this with english training data I get:

```
La fonction du langage, dit‚Äîon, est d'exprimer la pens√©e en la manifestant exterieurement. ll faut
pourtant apporter a cette formule une precision importante, et meme en souligner l'insuffisance. En
effet la pens√©e doit ici √©tre entendue au sens conceptuel, voire rationnel : l'experience a montr√© que
les singes anthropo'I'des peuvent acceder a une expression symbolique abstraite (utilisation de la
langue des signes des personnes sourdes, manipulation de symboles abstraits), mais il n'a jamais pu
√©tre etabli qu'un animal non humain soit capable d'exprimer une idee, ni meme un concept. En
d'autres termes, certains animaux sont capables d'exprimer leurs besoins (la faim, la soif), leurs
emotions (desirs ou craintes, tristesse ou joie...), mais aucun ne semble capable de porter un
jugement liant des concepts, a l'exception de notre espece. Cette precision rejoint la remarque deja
formulee par des philosophes. Par exemple, remarque Aristote, les autres animaux peuvent exprimer
le plaisir ou la douleur, qui sont des sensations, non le juste et l'injuste, qui sont des idees (et c'est
pourquoi l'Homme, et l'Homme seulement, est ¬´ un animal politique ¬ª). Selon Descartes, seul le
langage (sous la forme de paroles articulees ou de tout autre systeme de signes equivalent) est
capable de formuler des idees et de les communiquer a d'autres.
```

Using the french training data it gives:
```
La fonction du langage, dit‚Äîon, est d'exprimer la pens√©e en la manifestant ext√©rieurement. Il faut
pourtant apporter ÔøΩ cette formule une pr√©cision importante, et m√™me en souligner l'insuffisance. En
effet la pens√©e doit ici √™tre entendue au sens conceptuel, voire rationnel : l‚Äòexp√©rience a montr√© que
les singes anthropo√Ødes peuvent acc√©der a une expression symbolique abstraite (utilisation de la
langue des signes des personnes sourdes, manipulation de symboles abstraits), mais il n'a jamais pu
√™tre √©tabli qu'un animal non humain soit capable d'exprimer une id√©e, ni m√™me un concept. En
d'autres termes, certains animaux sont capables d'exprimer leurs besoins (la faim, la soif), leurs
√©motions (d√©sirs ou craintes, tristesse ou joie‚Ä¶), mais aucun ne semble capable de porter un
jugement liant des concepts, ÔøΩ l'exception de notre esp√®ce. Cette pr√©cision rejoint la remarque d√©jÔøΩ
formul√©e par des philosophes. Par exemple, remarque Aristote, les autres animaux peuvent exprimer
le plaisir ou la douleur, qui sont des sensations, non le juste et l‚Äòinjuste, qui sont des id√©es (et c‚Äòest
pourquoi l'Homme, et l‚ÄòHomme seulement, est ¬´ un animal politique ¬ª). Selon Descartes, seul le
langage (sous la forme de paroles articul√©es ou de tout autre syst√®me de signes √©quivalent) est
capable de formuler des id√©es et de les communiquer ÔøΩ d‚Äòautres.
```

For some reason the ` ¬´` and `¬ª` characters are unrecognized in French.  I'am trying to use text2image to create my  XXX.tif file and XXX.box file.
I found that only If all the characters can be rendered ,the text2image works fine.
It will broken when some characters can NOT be renderd with some fonts (the chinese fonts file usually  would NOT contain all the characters of chinese)

Is there a method to skip the character which could not be  rendered?(for example: use '  ' instead of the characters or just skip them)

thank you ! Text2image has the option to use only renderable characters. Please check
help for syntax

text2image --help

On 22-Nov-2016 2:01 PM, "albertyou2" notifications@github.com wrote:

> I'am trying to use text2image to create my XXX.tif file and XXX.box file.
> I found that only If all the characters can be rendered ,the text2image
> works fine.
> It will broken when some characters can NOT be renderd with some fonts
> (the chinese fonts file usually would NOT contain all the characters of
> chinese)
> 
> Is there a method to skip the character which could not be rendered?(for
> example: use ' ' instead of the characters or just skip them)
> 
> thank you !
> 
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/490, or mute the
> thread
> https://github.com/notifications/unsubscribe-auth/AE2_o6U-elwAxcbzA8fZR3Y0HHe13XS3ks5rAqhXgaJpZM4K5IUb
> .
 --strip_unrenderable_words

On 22-Nov-2016 2:01 PM, "albertyou2" notifications@github.com wrote:

> I'am trying to use text2image to create my XXX.tif file and XXX.box file.
> I found that only If all the characters can be rendered ,the text2image
> works fine.
> It will broken when some characters can NOT be renderd with some fonts
> (the chinese fonts file usually would NOT contain all the characters of
> chinese)
> 
> Is there a method to skip the character which could not be rendered?(for
> example: use ' ' instead of the characters or just skip them)
> 
> thank you !
> 
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/490, or mute the
> thread
> https://github.com/notifications/unsubscribe-auth/AE2_o6U-elwAxcbzA8fZR3Y0HHe13XS3ks5rAqhXgaJpZM4K5IUb
> .
 @Shreeshrii 
YES it works! thank you  @Shreeshrii Sorry ,I met a anther error :
 cluster text.size() == start_byte_to_box.size():error
have you seen it before?  Hi, I'm trying to work with the newly updated LSTM tesseract.

Tesseract gives me this error when I try
```sh
$ tesseract image.jpg out -oem 4

Error: LSTM requested, but not present!! Loading tesseract.
```

It seems like I don't have the tessdata for LSTM.

Where can I get it? The LSTM traineddata files aren't available yet. Thanks for your replies! The LSTM traineddata files are available now.
https://github.com/tesseract-ocr/tessdata Thank you! I'll try it out  I suggest to add spaces in the title of the wiki pages, e.g. the newly created page https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00:

"NeuralNetsInTesseract4.00" --> "Neural Nets In Tesseract 4.00"

The spaces will be changed in the url by dashes i.e. https://github.com/tesseract-ocr/tesseract/wiki/Neural-Nets-In-Tesseract-4.00. This is more conform to the other pages, but there are more wiki pages missing some spaces.

Is this okay?
 Uff..., well, then I don't understand the sentence "Please do not change the title of any wiki page without a permission from Tesseract developers." at https://github.com/tesseract-ocr/tesseract/wiki CC @amitdo . I would expect that I can ask permission from developers in an issue at GitHub, if one has to use the user forum for that, then the sentence should be reformulated. Hi @zuphilip :-)

>**Please do not change the title of any wiki page without a permission from Tesseract developers**.

I added it a few hours ago.

Recently, a user change a lot of wiki pages titles. The issues I see with doing so are:
* There were many links to some of the wiki pages from Tesseract issues, threads in Tesseract mailing list, blogs posts, etc. The changes broke those links. 
* I contributed to some of those pages, especially to the `TrainingTesseract` page where I did ton of editing. With the change of the title the history of the page editing is gone from the wiki interface. It looks like I and others who contribute to those pages never did so. > With the change of the title the history of the page editing is gone from the wiki interface. 

That looks like something which could be simply improved by the GitHub people. I get the full history in a local clone of the wiki with `git log --follow Training-Tesseract.md`.
 @amitdo

My apologies for the unintended consequences of title changes. I was trying
to make all related pages in wiki come together, eg. Training methofs for
various versions, box files, tesstrain etc. I had no idea that it would
remove page history and previous authors. I also realize that it has led to
broken links.

Is there a way to display broken links in the wiki so that they can be
fixed?

On 22-Nov-2016 3:16 PM, "Amit D." notifications@github.com wrote:

Hi @zuphilip https://github.com/zuphilip :-)

I added it a few hours ago.

Recently, a user change a lot of wiki page titles. The issues I see with
doing so are:
- There were many links to some of the wiki pages from Tesseract issues,
  threads in Tesseract mailing list, blogs posts, etc. The changes broke
  those links.
- I contribute to some of those pages, especially to the
  TrainingTesseract page where I did ton of editing.
  With the change of the title the history of the page editing is gone
  from the wiki interface. It look like I and other who contribute to those
  pages never did so. Personally, this situation of omitting credits, upset
  me and piss me off :(

‚Äî
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub
https://github.com/tesseract-ocr/tesseract/issues/486#issuecomment-262194003,
or mute the thread
https://github.com/notifications/unsubscribe-auth/AE2_o5XgCcovlycw8Gwz7IDj9UkiOQsOks5rAroBgaJpZM4K5EDw
.
 Stefan,
Is it possible for you to undo the title changes?

On 22-Nov-2016 4:18 PM, "Stefan Weil" notifications@github.com wrote:

> With the change of the title the history of the page editing is gone from
> the wiki interface.
> 
> That looks like something which could be simply improved by the GitHub
> people. I get the full history in a local clone of the wiki with git log
> --follow Training-Tesseract.md.
> 
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/486#issuecomment-262208337,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o_f0ZL2sVEcFsanjPh9Oqhs6jI8_ks5rAsiGgaJpZM4K5EDw
> .
 Shree @Shreeshrii,

I knew that you are the one that did those titles edits and I was sure you had good intentions. I don't blame you, so please don't feel bad about that :-) 

I blame Github devs.

Stefan @stweil, the fact that I can clone it and see my changes is not helping me. > Is it possible for you to undo the title changes?

I am not sure whether undoing your changes is the right way. Of course the wiki internal links must work, so maybe some links have to be fixed. I would not care for external links. They will still reach the wiki, and people who are interested will be able to find the page they are looking for.

@amitdo, I just contacted GitHub support and suggested to enhance the history, so maybe it will show all contributions (also those before a rename) in the future.

Personally I prefer nice looking titles (that implies spaces between words).

Technically anybody can rename titles, also back to the old ones. It's easier to revert changes in a local wiki clone, but only project owners can push such modifications. @amitdo : For the newly created pages, I will leave it up to you or any other of the core developer to change the page name. >@amitdo, I just contacted GitHub support and suggested to enhance the history, so maybe it will show all contributions (also those before a rename) in the future.

Thanks for that, although I'm sceptical about the chance they will do something about this issue. 

I was told that wikipedia's wiki does not have this issue.

With git itself and also with Github interface for **code** changes the history is preserved.

> I would not care for external links. They will still reach the wiki, and people who are interested will be able to find the page they are looking for.

This is called [breaking the web](https://www.google.co.il/search?client=ubuntu&channel=fs&q=%22breaking+the+web%22+%22broken+links%22) and it's not nice.

Some user re-added the 'deleted' pages with a link to the 'new' pages. In one hand it solves the broken links issue, but on the the other hand it creates a lot of ugly duplicates in the wiki TOC. 

>Personally I prefer nice looking titles (that implies spaces between words).

Personally, I think the fact that the wiki title does not have whitespace is a minor issue, and due to the implications I mentioned earlier, it should not be changed unless...
* It's a new wiki page (with no external links to it)
* The authors of the page agree with the change.


Some projects block the option to freely do any edits in the wiki content, but I don't suggest to so in this project. More fine-grained permissions control options in the wiki would be very helpful, e.g. options to block title editing and page deletion, an option to 'protected page' - block any editing for certain pages, etc.  

 Maybe not many people care about this issue as I do...

>@amitdo : For the newly created pages, I will leave it up to you or any other of the core developer to change the page name.

@zuphilip,
@theraysmith or @zdenop should decide about it.

Zdenko, if you don't like my new 'policy' you can remove it from the 'Home' wiki page. > Thanks for that, although I'm sceptical about the chance they will do something about this issue.

Well, at least they have sent an answer:

"This does sounds like it would be a useful addition to wiki revisions. I've passed your request onto the team to consider. I can't promise if or when we would implement but thanks for writing in."
 I now see that the previous edits were preserved in the interface of the global history.
https://github.com/tesseract-ocr/tesseract/wiki/_history?page=6
:-)

I now think it's OK to change the titles of **new** wiki pages...
@zdenop?

If you change the title of a page, don't do changes to the body text in the same edit. https://github.com/tesseract-ocr/tesseract/wiki/Improve-Quality/_compare/deccb78%5E...deccb78

This broke some links (Readme, Wiki).

What should we do now?
1) Revert this change?
2) Fix the links? CC: @andrewda My bad! Thought it was a typo, will revert for now. @amitdo Is there an issue with the revert button on the wiki `_compare` page? I clicked "Revert" assuming it would undo the title change and now both pages seem to be gone... Seems like a bug in GitHub.

https://github.com/contact The wiki interface considers a change of a wiki page title as creating a **new page**.
So the wiki reverted your last change - and deleted this page.
Unfortunately, the story ends here...

Or Not. The wiki can be cloned and the page should still be accessible in the history. It can be recovered. Ah, I understand now. Had no idea that's how GitHub renamed pages, very sorry for the trouble.  The source of the problem is git itself. The wiki is built on top of it.  The page was somehow restored.
https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality  commit c1c1e426b32794d5e84134ee81bf895ff0228fe5

system : ubuntu 16.04
there is an errror on lstmrecoginzer.cpp and other files.
the infamous 'isnan()' error
one way to fix NOW it is replacing  isnan() with std::isnan()

go into lstm dir and execute 

> sed -i 's/isnan/std::isnan/g' `grep "isnan" -rl`

have fun  PR #491 should fix this build problem (which also breaks the continuous integration tests). @blairq, could you please repeat your test with the latest version from git? This issue should be closed.  HiÔºå
Attached is the target image (Image61.tif, characters are"330") and all train data(.traineddata, .box and .tif).
[SimpleTest.zip](https://github.com/tesseract-ocr/tesseract/files/602968/SimpleTest.zip)

traindata1\fontyp.traineddata
Trained data just includes "3". The result is 333.
traindata2\fontyp.traineddata
Trained data includes "3" and "5". The result is 355 and why the second character isn't "3"?
The situations are the same using tesseract-OCR 3.02 or 3.05.00dev .
Could anybody help me? Thanks a lot!! More information:
1. OS is windows 7.
2. Tesseract-OCR 3.02 or 3.05.00dev .
3. Command line:
Tesseract Image61.tif result -l fontyp
 Thanks.  I am trying to train tesseract with my own data and want to generate frequent file list with wordlist2dawg. https://github.com/tesseract-ocr/tesseract/blob/master/doc/wordlist2dawg.1.asc

Running command

`wordlist2dawg data/freq_file_list.txt eng1.freq-dawg eng1.unicharset`
This is output

```
Loading unicharset from 'eng1.unicharset'
Reading word list from 'data/freq_file_list.txt'
Reducing Trie to SquishedDawg
Dawg is empty, skip producing the output file
Wordlist looks like this
```

```
Akbronco
Akstiletto
Ankyros
Ash
Bo
Boar
Boltor
Braton
Bronco
Burston
Carrier
Dakra
Dual
Ember
Fang
Fragor
....
```
It is not generating the dawg file, any suggestions what is wrong? Added both files
I had to add txt extension to unicharset just to upload it here.

[freq_file_list.txt](https://github.com/tesseract-ocr/tesseract/files/605711/freq_file_list.txt)

[eng1.unicharset.txt](https://github.com/tesseract-ocr/tesseract/files/605712/eng1.unicharset.txt)

 I am using Tesseract 3.05-dev on Windows 10. I got the same result,I think there maybe two probability.
1„ÄÅThe encoding of the input files freq_file_list.txt and eng1.unicharset.txt may not meet the requirements .
2„ÄÅThe unicharset you provide is not the correct.The unicharset file must be regenerated whenever inttemp, normproto and pffmtable are generated. use : 
mftraining -F font_properties -U unicharset -O regenerated.unicharset  *.tr hi,
what if the language was Arabic, which doesn't have capital case or small case, but the same problem was generated, what could be the issue? @blacklong617 @ibr123 

Please note tesseract version, o/s, commit number if known.

Also share the input files. 
[ara_frequent.txt](https://github.com/tesseract-ocr/tesseract/files/929641/ara_frequent.txt)
[ara.unicharset.txt](https://github.com/tesseract-ocr/tesseract/files/929645/ara.unicharset.txt)
these are the input files, the tesseract version is: tesseract 4.00.00alpha and OS is windows 10
and thanks for your response


 your ara_frequent.txt is encoded in ANSI with windows style end of line
markers. the words  show up as the following, instead of in Arabic. 
Just a few words from top of file pasted below

√≠√ä√¶√û√ö
√á√°√ö√°√£√á√Å
√É√§
√ä√ï√à√ç
√ù√á√ü√•√â
√á√°√ü√ë√í
√¶√á√ç√è√â
√£√§
√¶√ì√á√Ü√°
√ö√°√á√å
√á√°√è√á√Å
√á√°√ì√ü√ë√≠
√ù√á√°√£√á√è√â
√á√°√ì√ü√ë√≠√â

ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Tue, Apr 18, 2017 at 6:27 PM, ibr123 <notifications@github.com> wrote:

> ara_frequent.txt
> <https://github.com/tesseract-ocr/tesseract/files/929641/ara_frequent.txt>
> ara.unicharset.txt
> <https://github.com/tesseract-ocr/tesseract/files/929645/ara.unicharset.txt>
> these are the input files, the tesseract version is: tesseract
> 4.00.00alpha and OS is windows 10
> and thanks for your response
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/482#issuecomment-294831301>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oyBRPmPFHGZx5ElILqptklrbYERzks5rxLMvgaJpZM4K3oHp>
> .
>
 Also see https://github.com/tesseract-ocr/tesseract/blob/master/training/tesstrain_utils.sh#L339

```
 # -r arguments to wordlist2dawg denote RTL reverse policy
    # (see Trie::RTLReversePolicy enum in third_party/tesseract/dict/trie.h).
    # We specify 0/RRP_DO_NO_REVERSE when generating number DAWG,
    # 1/RRP_REVERSE_IF_HAS_RTL for freq and word DAWGS,
    # 2/RRP_FORCE_REVERSE for the punctuation DAWG.
```  unofficial installer for windows for Tesseract 3.05-dev is available from Tesseract at UB Mannheim.
http://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-3.05.00dev.exe
win10, x64, lastest update.

the installer will not just add path,it will EMPTY path. This is not an issue for https://github.com/tesseract-ocr/tesseract/issues. Nevertheless I can try to answer here.

I got a similar report per e-mail recently, but could not reproduce it. Could you tell me the previous value of `PATH` which was emptied by the installation? Do you need the option which claims to set `PATH`? It is disabled by default, so I suggest to use the default setting (which avoids the issue).
 All values of PATH were emptied by the installation.
Maybe the installer alerted me ,or as you said it is disabled by default.
Maybe I click the "next" too fast cause I thought it's OK.
Fortunately,I opened the PowerShell before the installation,the change of PATH didn't refresh in the opened PowerShell,so that I can restore the values of PATH,or it will be a little trouble.
 How does your normal value of `PATH` look like? I need the value which you restored (or like it was before it was emptied) because the problem might be related to the length or the content of `PATH`.
 `C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Python27\;C:\Program Files\Python27\Scripts;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\nodejs\;C:\WINDOWS\system32\config\systemprofile\.dnx\bin;C:\Program Files\Microsoft DNX\Dnvm\;C:\Program Files (x86)\Windows Kits\8.1\Windows Performance Toolkit\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\MySQL\MySQL Fabric 1.5 & MySQL Utilities 1.5\;C:\Program Files (x86)\MySQL\MySQL Fabric 1.5 & MySQL Utilities 1.5\Doctrine extensions for PHP\;C:\Program Files\IDM Computer Solutions\UltraEdit;C:\Program Files (x86)\IDM Computer Solutions\UltraCompare;C:\Shorts;C:\Program Files\Git\cmd;C:\Program Files\Git\mingw64\bin;C:\Program Files\Git\usr\bin;C:\Program Files\MySQL\MySQL Server 5.7\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\TortoiseSVN\bin;C:\wamp64\bin\php\php7.0.10;C:\wamp64\bin\php\php7.0.10\ext;C:\Users\CeBk\AppData\Roaming\npm;C:\Users\CeBk\AppData\Local\Microsoft\WindowsApps;C:\Users\CeBk\AppData\Roaming\npm;%USERPROFILE%\AppData\Local\Microsoft\WindowsApps;`

that's all the values of PATH before the installation 
 The NSIS installer (which is used for Tesseract) has a [limit of 1024 characters](http://nsis.sourceforge.net/Path_Manipulation). Your PATH is clearly longer, so it hits that limit. I think the simplest solution will be removing the PATH setting from the installer, so users cannot activate it.
  I'm having problems with gimagereader and tesseract. uninstalled all, then did new install and I get no output in the pane of gimagereader. When I try to install gimagereader-dbg it wants libtesseract4 and this happens:

```
(synaptic:2537): GLib-CRITICAL **: g_child_watch_add_full: assertion 'pid > 0' failed
(Lese Datenbank ... 328342 Dateien und Verzeichnisse sind derzeit installiert.)
Vorbereitung zum Entpacken von .../libtesseract4_1%3a3.04.01-1~ppa+trusty0_amd64.deb ...
Entpacken von libtesseract4:amd64 (1:3.04.01-1~ppa+trusty0) ...
dpkg: Fehler beim Bearbeiten des Archivs /var/cache/apt/archives/libtesseract4_1%3a3.04.01-1~ppa+trusty0_amd64.deb (--unpack):
 Versuch, ¬ª/usr/lib/x86_64-linux-gnu/libtesseract.so.3.0.4¬´ zu √ºberschreiben, welches auch in Paket libtesseract3:amd64 3.04.00-1~ppa+trusty3 ist
dpkg-deb: Fehler: Unterprozess einf√ºgen wurde durch Signal (Daten√ºbergabe unterbrochen (broken pipe)) get√∂tet
Fehler traten auf beim Bearbeiten von:
 /var/cache/apt/archives/libtesseract4_1%3a3.04.01-1~ppa+trusty0_amd64.deb
E: Sub-process /usr/bin/dpkg returned an error code (1)
Ein Paket konnte nicht installiert werden. Wiederherstellung wird versucht:
dpkg: Abh√§ngigkeitsprobleme verhindern Konfiguration von tesseract-ocr:
 tesseract-ocr h√§ngt ab von libtesseract4; aber:
  Paket libtesseract4:amd64 ist nicht installiert.

dpkg: Fehler beim Bearbeiten des Paketes tesseract-ocr (--configure):
 Abh√§ngigkeitsprobleme - verbleibt unkonfiguriert
dpkg: Abh√§ngigkeitsprobleme verhindern Konfiguration von tesseract-ocr-dbg:
 tesseract-ocr-dbg h√§ngt ab von tesseract-ocr (= 1:3.04.01-1~ppa+trusty0); aber:
  Paket tesseract-ocr ist noch nicht konfiguriert.

dpkg: Fehler beim Bearbeiten des Paketes tesseract-ocr-dbg (--configure):
 Abh√§ngigkeitsprobleme - verbleibt unkonfiguriert
Fehler traten auf beim Bearbeiten von:
 tesseract-ocr
 tesseract-ocr-dbg

```  to reproduce:
$ ls
1a.tiff 1b.tiff 1c.tiff
$ tesseract 1a.tiff 1a
Tesseract Open Source OCR Engine v3.04.01 with Leptonica
Page 1
Page 2
Page 3
Page 4
$ cat 1a.txt
_file contains text read from 1a.tiff AND 1b.tiff AND 1c.tiff WTF please_ Did you try to open 1a.tiff with an image viewer that can present multi-page tiff? This tiff file contains 4 images.
  The check needs libpng, otherwise it always fails with unresolved symbols.

Signed-off-by: Stefan Weil <sw@weilnetz.de> This should fix issue #435.
  Hi,
I went through the all the slides in das tutorial 2016 https://github.com/tesseract-ocr/docs/tree/master/das_tutorial2016.

May I ask is the version install through `sudo apt-get install tesseract-ocr ` using lstm by calling `tesseract ` at terminal?

Thanks! No, Ray has not updated the code with LSTM yet and as far as I know hasn't
communicated a date when it will be done.

On 4 Nov 2016 8:45 a.m., "Wenchen Li" notifications@github.com wrote:

> Hi,
> I went through the all the slides in das tutorial 2016
> https://github.com/tesseract-ocr/docs/tree/master/das_tutorial2016.
> 
> May I ask is the version install through sudo apt-get install
> tesseract-ocr using lstm by calling tesseract at terminal?
> 
> Thanks!
> 
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/465, or mute the
> thread
> https://github.com/notifications/unsubscribe-auth/AE2_o6EqzLQH5q72OXVSIHPRozIyPIuwks5q6qNsgaJpZM4KpJyR
> .
 @zdenop

There have been a number of questions re tesseract 4.0 or version with
LSTM. It will be helpful for the community to know the status.

I have added a wiki page with available info at
https://github.com/tesseract-ocr/tesseract/wiki/4.0-with-LSTM

Please change the language as you deem fit and update when there is info
available about the release.

Thanks.

On 4 Nov 2016 12:44 p.m., "zdenop" notifications@github.com wrote:

> Closed #465 https://github.com/tesseract-ocr/tesseract/issues/465.
> 
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/465#event-847509931,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o84hw0akcgpmLray0dp-N_y0MvcRks5q6ttxgaJpZM4KpJyR
> .
  Cmake hangs at this stage and does not advance, even if left overnight:

The C compiler identification is MSVC 19.0.24215.1
The CXX compiler identification is MSVC 19.0.24215.1
Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64_x86/cl.exe
Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64_x86/cl.exe -- works
Detecting C compiler ABI info
Detecting C compiler ABI info - done
Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64_x86/cl.exe
Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64_x86/cl.exe -- works
Detecting CXX compiler ABI info
Detecting CXX compiler ABI info - done
Detecting CXX compile features
Detecting CXX compile features - done
Check if the system is big endian
Searching 16 bit integer
Looking for sys/types.h
Looking for sys/types.h - found
Looking for stdint.h
Looking for stdint.h - found
Looking for stddef.h
Looking for stddef.h - found
Check size of unsigned short
Check size of unsigned short - done
Using unsigned short
Check if the system is big endian - little endian
-- Performing 71 checks using 8 threads
-- This process may take up to 5 minutes depending on your hardware Just updated to latest cppan and tried again, same results:

D:\personal\tesseract>cppan --self-upgrade
Downloading checksum file
Downloading the latest client
Unpacking
Replacing client

D:\personal\tesseract\build>git status
On branch master
Your branch is up-to-date with 'origin/master'.

D:\personal\tesseract>cppan
Reading package specs... Ok
Generating build configs... Ok

D:\personal\tesseract>cd build

D:\personal\tesseract\build>cmake .. -DSTATIC=1
-- Building for: Visual Studio 14 2015
-- Check if the system is big endian
-- Searching 16 bit integer
-- Looking for sys/types.h
-- Looking for sys/types.h - found
-- Looking for stdint.h
-- Looking for stdint.h - found
-- Looking for stddef.h
-- Looking for stddef.h - found
-- Check size of unsigned short
-- Check size of unsigned short - done
-- Using unsigned short
-- Check if the system is big endian - little endian
-- Performing 71 checks using 8 threads
-- This process may take up to 5 minutes depending on your hardware
 I should mention that I'm seeing this issue across multiple machines, and this is the only codebase I'm seeing this issue for (cmake works fine on other projects, example: opencv).
 I doubt I'll have time to chat synchronously or share my screen today.  At a glance, it looks like cppan.exe is running during the hang, so I suspect it's the culprit.  Also see 2 cmake-gui processes and about 7 cmake processes.  Other info:

D:\personal\tesseract>cmake --version
cmake version 3.6.2

Regarding files in that directory, are you looking for a recursive list?  It looks like it just contains random folder names that contain session data.  There are a lot of files in each directory, though - looking for something specific?
 Yep, the CPU is doing barely anything.  

snip
 This better?
tree /F
Folder PATH listing for volume OSDisk
Volume serial number is 00000054 5A53:90A7

snip
 http://imgur.com/a/Y3qXr
 http://imgur.com/a/RZLsF
 http://imgur.com/VjOG70H
 http://imgur.com/a/LAfPN
[qDUdTLdY.zip](https://github.com/tesseract-ocr/tesseract/files/572840/qDUdTLdY.zip)
 No cl.exe, link.exe, MSBuild.exe, but there are a 6 conhost.exe's.  The two cmd.exe's open are my command windows.  Conhosts all look identical with the following command line:
\??\C:\WINDOWS\system32\conhost.exe 0x4 
 Killed all the conhosts.  Seems like one of them was driving the command window I executed cmake from, so that shut down.  Still see 4 cmake processes and a cppan process running.

![image](https://cloud.githubusercontent.com/assets/150887/20025816/887e6f36-a2af-11e6-9670-276ca75e8c90.png)
 ![image](https://cloud.githubusercontent.com/assets/150887/20025887/94be297a-a2b0-11e6-80d3-d04c829d47d8.png)
 That seemed to unstick it.  So cmake is hanging on something.
 Seems fixed in 3.7.  I don't see the "running tests" step at all anymore.
 Yeah, this brings the problem back.  If the next step is to build a debug version of cmake and debug their code, it might be a while before I have the time to address it.
 I got exactly the same issue. After many trial & errors I was about to compile CMake in debug when I found the solution in [this](https://github.com/tesseract-ocr/tesseract/issues/417#issuecomment-245073354) thread. Simply calling `cppan --self-upgrade` solved my issue. It seems like [this](https://cppan.org/client/cppan-master-Windows-client.zip) client is buggy and not up-to-date.
 it seems that the work can go on if you kill the two or three cmake tasks with least memories. If you have problems @hyogase [solution](https://github.com/tesseract-ocr/tesseract/issues/464#issuecomment-264166445) works perfectly.  removing all cmake tasks except one (with the highest memory) worked for me, thanks @hyogase   It is only used locally in opencl/openclwrapper.cpp.

For all other files which include openclwrapper.h, the compiler
complained about an unused static variable:

opencl/openclwrapper.h:175:16: warning:
 ‚ÄòMORPH_BC‚Äô defined but not used [-Wunused-variable]

Signed-off-by: Stefan Weil <sw@weilnetz.de> It is still not clear for me why that variable `MORPH_BC` is needed at all.
  There are small issues in the code that cause compilation errors under Windows unicode project.
The problem is that some of win32 api functions are called without a proper postfix "A" which forces compiler to use non-unicode version of these functions. Here are all of them:
baseapi.cpp
377 WIN32_FIND_DATA -> WIN32_FIND_DATAA
379 FindFirstFile-> FindFirstFileA
381 FindNextFile -> FindNextFileA

svutil.cpp
82 STARTUPINFO -> STARTUPINFOA
84 GetStartupInfo -> GetStartupInfoA
85 CreateProcess -> CreateProcessA

mainblk.cpp
69 GetModuleFileName -> GetModuleFileNameA

P.S.
The same problem exists in the latest Leptonica library but among the similar errors that can be located by the compiler there are some that it is not able to find e.g. when the code uses GetTempPath instead of GetTempPathA.
 >The problem is that some of win32 api functions are called without a proper postfix "A" which forces compiler to use non-unicode version of these functions. Here are all of them

I'm not a Windows guy, but I think you are wrong here.

https://msdn.microsoft.com/en-us/library/windows/desktop/dd374089(v=vs.85).aspx


>Windows API functions that manipulate characters are generally implemented in one of three formats:
>
>    A generic version that can be compiled for either Windows code pages or Unicode
    A Windows code page version with the letter "A" used to indicate "ANSI"
    A Unicode version with the letter "W" used to indicate "wide"

cc: @egorpugin  > This should be used by default. No suffix - compiler will choose it without user.
> No need to rename functions.

You are right on one condition - if you use "TCHAR" type vars as WinApi function parameters instead of "char" and likewise LPCTSTR instead of LPCSTR, LPTSTR instead of LPSTR and so on. > So, types should be fixed, not functions.

yes sure, but I think functions can be fixed easier  Hi,
 I have a compile error as the result of running 'make' for Tesseract 3.01: 
[root@localhost tesseract-3.01]# make
make  all-recursive
make[1]: Entering directory `/root/tesseract-3.01'
Making all in ccutil
make[2]: Entering directory`/root/tesseract-3.01/ccutil'
make[3]: Entering directory `/root/tesseract-3.01/ccutil'
if /bin/sh ../libtool --tag=CXX --mode=compile g++ -DHAVE_CONFIG_H -I. -I. -I..   -I/usr/local/include/leptonica -DTESSDATA_PREFIX=/usr/local/share/ -g -O2 -MT ambigs.lo -MD -MP -MF ".deps/ambigs.Tpo" -c -o ambigs.lo ambigs.cpp; \
        then mv -f ".deps/ambigs.Tpo" ".deps/ambigs.Plo"; else rm -f ".deps/ambigs.Tpo"; exit 1; fi
 g++ -DHAVE_CONFIG_H -I. -I. -I.. -I/usr/local/include/leptonica -DTESSDATA_PREFIX=/usr/local/share/ -g -O2 -MT ambigs.lo -MD -MP -MF .deps/ambigs.Tpo -c ambigs.cpp  -fPIC -DPIC -o .libs/ambigs.o
In file included from params.h:26,
                 from tprintf.h:23,
                 from ambigs.h:25,
                 from ambigs.cpp:24:
strngs.h:1: error: stray '\357' in program
strngs.h:1: error: stray '\273' in program
strngs.h:1: error: stray '\277' in program
In file included from unicharset.h:24,
                 from ambigs.h:27,
                 from ambigs.cpp:24:
strngs.h:1: error: stray '\357' in program
strngs.h:1: error: stray '\273' in program
strngs.h:1: error: stray '\277' in program
make[3]: *** [ambigs.lo] Error 1
make[3]: Leaving directory`/root/tesseract-3.01/ccutil'
make[2]: **\* [all-recursive] Error 1
make[2]: Leaving directory `/root/tesseract-3.01/ccutil'
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory`/root/tesseract-3.01'
make: **\* [all] Error 2

OS:  Linux localhost.localdomain 2.6.18-194.el5xen #1 SMP Tue Mar 16 22:01:26 EDT 2010 x86_64 x86_64 x86_64 GNU/Linux

Leptonica 1.67 installed.
Thanks for help.
 Hi iamcool345, Try updating to a more recent version of Leptonica and/or the more recent version of Tesseract as well.

B.
 [Guide for reporting issues](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md)

Please use the [forum](https://groups.google.com/d/forum/tesseract-ocr).
  http://clang.llvm.org/extra/clang-tidy/checks/modernize-use-nullptr.html What about finishing this job? Several thousand `NULL` macros are still in the code. Replacing them could be done per directory. About 293 files would need changes. Here are the file counts per directory:

      7 api
     36 ccmain
     48 ccstruct
     40 ccutil
     40 classify
      6 cutil
      9 dict
      4 doc
     20 lstm
     52 textord
      2 training
      4 viewer
      4 vs2010
     21 wordrec
 @theraysmith, can you fix it with clang-tidy?
http://clang.llvm.org/extra/clang-tidy/checks/modernize-use-nullptr.html  Hi,
I'm using the "Example of iterator over the classifier choices for a single symbol" to show the confidence for each of the characters in image but it just print the characters of one of the word in the middle of image. how would i have all of the candidate choices and it's confidence for each of character in image?
  As per @jbreiden's comment in #373, here's a problem I noticed with tesseract 3.04.01 (from the Ubuntu Yakkety package).

This is the original PDF without text as it is created by my scanner: [scanned.pdf](https://github.com/tesseract-ocr/tesseract/files/558983/scanned.pdf)

I've used pdfsandwich with the `-debug` flag to get the intermediate files. The image it uses to feed into tesseract is the tif in this [tif.zip](https://github.com/tesseract-ocr/tesseract/files/558990/tif.zip). And this works just fine. Here's the identify information from that tif:

```
Image: extractedtif.tif
  Format: TIFF (Tagged Image File Format)
  Mime type: image/tiff
  Class: DirectClass
  Geometry: 2479x3500+0+0
  Resolution: 300x300
  Print size: 8.26333x11.6667
  Units: Undefined
  Type: Grayscale
  Endianess: LSB
  Colorspace: Gray
  Depth: 8-bit
  Channel depth:
    gray: 8-bit
```

Running

```
tesseract extractedtif.tif outputtif -l deu pdf
```

gives me a perfectly fine PDF in format: A4, Portrait (210 x 296 mm).

[outputtif.pdf](https://github.com/tesseract-ocr/tesseract/files/559002/outputtif.pdf)

And now I converted that tif to png with simply:

```
convert extractedtif.tif pngfromtif.png
```

[png.zip](https://github.com/tesseract-ocr/tesseract/files/559009/png.zip)

The new png file shows the same resolution information and print size:

```
Image: pngfromtif.png
  Format: PNG (Portable Network Graphics)
  Mime type: image/png
  Class: PseudoClass
  Geometry: 2479x3500+0+0
  Resolution: 300x300
  Print size: 8.26333x11.6667
  Units: Undefined
  Type: Grayscale
  Endianess: Undefined
  Colorspace: Gray
  Depth: 8-bit
  Channel depth:
    gray: 8-bit
```

However, running

```
tesseract pngfromtif.png outputpng -l deu pdf
```

gives me a PDF in format: 900 √ó 1270 mm paper size.

[outputpng.pdf](https://github.com/tesseract-ocr/tesseract/files/559004/outputpng.pdf)
 But then, why does tesseract behave inconsistently between tif and png when both have `Units: Undefined`?
 I think I know why the units are Undefined. pdfsandwich does a 2-step conversion from a PDF page to tif:

```
convert -colorspace Gray -colors 256 -depth 8 -background white -flatten +matte -density 300x300 scanned.pdf[0] tmpfile.ppm
```

Which gives:

```
Image: tmpfile.ppm
  Format: PPM (Portable pixmap format (color))
  Mime type: image/x-portable-pixmap
  Class: DirectClass
  Geometry: 2479x3500+0+0
  Units: Undefined
  Type: Grayscale
  Endianess: Undefined
  Colorspace: Gray
  Depth: 8-bit
  Channel depth:
    gray: 8-bit
```

And then:

```
convert -density 300x300 tmpfile.ppm tmpfile.tif
```

Which results in:

```
Image: tmpfile.tif
  Format: TIFF (Tagged Image File Format)
  Mime type: image/tiff
  Class: DirectClass
  Geometry: 2479x3500+0+0
  Resolution: 300x300
  Print size: 8.26333x11.6667
  Units: Undefined
  Type: Grayscale
  Endianess: LSB
  Colorspace: Gray
  Depth: 8-bit
  Channel depth:
    gray: 8-bit
```

I'll open a ticket with pdfsandwich to add `-unit PixelsPerInch` to the `convert` command.

_EDIT:_ https://sourceforge.net/p/pdfsandwich/bugs/14/
 Yup, asked both in the ticket there.
 > 1) Why use two convert commands instead of just one?

Because there's a use of `unpaper` in between them. It's [info file](https://github.com/Flameeyes/unpaper/blob/master/doc/basic-concepts.md) says:

> The image-file formats accepted by unpaper are those that libav can handle. In particular it supports the whole PNM-family: PBM, PGM and PPM. This ensures interoperability with the SANE tools under Linux. Support for TIFF and other complex file formats is not guaranteed.

That said, [libav says](http://libav.org/documentation/general.html#File-Formats) that it handles png and tiff, if I read it correctly.
 @mbirth I'm the author of [ocrmypdf](https://github.com/jbarlow83/OCRmyPDF), which is similar to pdfsandwich. \<plug\>ocrmypdf is extremely carefully in handling of DPI and handles a lot of edge cases that pdfsandwich does not.\</plug\> It handles your file without issue.

@jbreiden I think it would be helpful for tesseract to issue a warning when the DPI is nonsense. Lots of programs don't handle this metadata correctly so it's easy for a workflow to discard it. Wrong DPI isn't just a display/printing issue; in the case of say, scanned maps, losing scale information can change the interpretation. That is a very good idea. Hope I remember once the turkey coma wears off.
 This looks like a spot where we should emit the warning, but is not executed.

https://github.com/tesseract-ocr/tesseract/blob/a75ab450a8cc9a2b69cf05f5c4f7a39bc44cbacc/ccmain/osdetect.cpp#L167

This spot thinks the resolution is 0.

https://github.com/tesseract-ocr/tesseract/blob/9c7e99b04197fb9900c29be8bb9ac79a7a8b4672/ccmain/thresholder.cpp#L175

Oh, oh, maybe here.

https://github.com/tesseract-ocr/tesseract/blob/7b5b16779ad4980936724e85a548bccb717cc39c/api/baseapi.cpp#L2226


 Looks like we have kMinCredibleResolution defined in two places. Only the
one in baseapi.ccp is active for this test case.

```c++
--- tesseract/api/baseapi.cpp	2016-11-07 07:44:03.000000000 -0800
+++ tesseract/api/baseapi.cpp	2016-11-28 11:23:48.000000000 -0800
@@ -2226,6 +2226,8 @@
   if (y_res < kMinCredibleResolution || y_res > kMaxCredibleResolution) {
     // Use the minimum default resolution, as it is safer to under-estimate
     // than over-estimate resolution.
+    tprintf("Warning. Invalid resolution %d dpi. Using %d instead.\n",
+            y_res, kMinCredibleResolution);
     thresholder_->SetSourceYResolution(kMinCredibleResolution);
   }
   PageSegMode pageseg_mode =
--- tesseract/ccmain/osdetect.cpp	2016-11-07 07:44:03.000000000 -0800
+++ tesseract/ccmain/osdetect.cpp	2016-11-28 11:31:13.000000000 -0800
@@ -164,8 +164,14 @@
   int vertical_y = 1;
   tesseract::TabVector_LIST v_lines;
   tesseract::TabVector_LIST h_lines;
-  int resolution = (kMinCredibleResolution > pixGetXRes(pix)) ?
-      kMinCredibleResolution : pixGetXRes(pix);
+  int resolution;
+  if (kMinCredibleResolution > pixGetXRes(pix)) {
+    resolution = kMinCredibleResolution;
+    tprintf("Warning. Invalid resolution %d dpi. Using %d instead.\n",
+            pixGetXRes(pix), resolution);
+  } else {
+    resolution = pixGetXRes(pix);
+  }
 
   tesseract::LineFinder::FindAndRemoveLines(resolution, false, pix,
                                             &vertical_x, &vertical_y,
```  This fixes several gcc warnings:

warning:
 type qualifiers ignored on function return type [-Wignored-qualifiers]

Signed-off-by: Stefan Weil sw@weilnetz.de
  I don't find how to use this API in android project.  is there an available wrapper for android? 
  ![leptonica](https://cloud.githubusercontent.com/assets/17674215/18988851/44796cb8-8726-11e6-8854-9ff87c11ad96.png)
I followed the steps of installation of `tesseract-ocr`. After `autogen.sh` , I tried `./configure` but terminal is showing `leptonica library with pdf support (>= 1.71) is missing` and no further installation is happening.
I searched for this problem extensively. I installed `leptonica-17.3` from source. Then I tried `./configure` again. The problem persisted. I again searched. In one closed issue, there was suggestion for `./configure --with-extra-includes=/usr/local/include --with-extra-libaries=/usr/local/lib
` instead of `./configure`. I didn't work.
The problem is still the same. 
What to do? 
Any suggestion is welcome. 
 I have the same bug. Since it is telling you that you have the wrong version, but that is not the real issue.

 this is bug and not a "asking support".
 @canny07 i made it work by setting the library path diffierntly. It is probably a old version of leptonica that is "blocking the sight"  for the config script .
 @Neppord Yeah It seems so. For my case, I found that the older version was the reason of trouble. So, I removed it and downloaded and installed the latest version from the source. 
Thanks for answering :)
 First, it is recommended to uninstall an older Leptonica before you install new one.

Running `sudo ldconfig` after `sudo make install` in both Leptonica and Tesseract installation should prevent the issue you had.

Anyway, it's not a bug in Tesseract.
 > Anyway, it's not a bug in Tesseract.

In some way it is. I had to fix my Tesseract configuration to get PDF support for the Windows version. Maybe I should have sent a PR earlier ‚Äì I'll do it now.
 Please test and review pull request #473 which should fix this issue.
 The cause of their issue is not related to libpng. 
  Hi,

The command line help output shows 11 PSM modes (0 through 10).

```
  pagesegmode values are:
  0 = Orientation and script detection (OSD) only.
  1 = Automatic page segmentation with OSD.
  2 = Automatic page segmentation, but no OSD, or OCR
  3 = Fully automatic page segmentation, but no OSD. (Default)
  4 = Assume a single column of text of variable sizes.
  5 = Assume a single uniform block of vertically aligned text.
  6 = Assume a single uniform block of text.
  7 = Treat the image as a single text line.
  8 = Treat the image as a single word.
  9 = Treat the image as a single word in a circle.
  10 = Treat the image as a single character.
```

I was trying each one and getting mixed results. However, I accidentally ran 'psm -11' and I suddenly got perfect accuracy - way way better than any other PSM mode, and much better than the default. The same for PSM 12 too, perfect accuracy - then PSM 13 gives nothing. 

The image is just about 10 words over 2 lines, spread about the page. All the other segmentation modes and default garble the text, but PSM 11/12 worked great, splitting text perfectly.

Is it correct that there's a PSM 11 and 12 mode? What do they do, why do they give such good accuracy?! And should they be in the help/[Wiki](https://github.com/tesseract-ocr/tesseract/wiki/Command-Line-Usage)?

Thanks!
 With Tesseract 4.0 PSM 11, 12, and 13 appear in the help message. psm 13 is used with the new LSTM engine to OCR a single textline image.   Font detection works fine in PSM_SINGLE_WORD mode. In PSM_SINGLE_LINE mode it is not working well. For recognizing more text (column, full page) font detection does not work at all. For every word the reported font is the same (e.g. Georgia using the default eng.traineddata). I thought at first that this is a issue with traineddata but training my own data and trying different stuff it seems way more likely that this issue is with tesseract (see [issue in tessdata](https://github.com/tesseract-ocr/tessdata/issues/25) ). I attached a small example to demonstrate the problem.
[broken_font_detection_sample.zip](https://github.com/tesseract-ocr/tesseract/files/493838/broken_font_detection_sample.zip)
 All the fonts are from the liberation family. I could narrow down the cause of this problem to the adaptive classifier. With classify_enable_learning set to false detection of italic/sans/serif works and detection of bold works sometimes (which is to be expected). The adoptive classifier seems a bit overzealous if font features change (eg. from serif to sans). It seems if a word is sans all sans fonts in the training data get high ratings and the already adopted to sans font gets a even higher rating. If the next word is serif then the serif fonts in the training data get high ratings but the adopted to sans font gets a rating that is still higher. I suppose that because of this the already adopted to sans font is able to learn the serif features. In the end the whole document matches the font that the classifier was first adopting to (I tried this). I attached a part of the log obtained from setting tessedit_debug_fonts to true where font changes from sans to serif bold ("Exeter." -> "The").
[debug_log.txt](https://github.com/tesseract-ocr/tesseract/files/504412/debug_log.txt)
 This problem is triggered as soon as any previously adapted character is encountered and the codepath DoAdaptiveMatch->BaselineClassifier is used. My current insight into this issue is that matching baselinenormalized characters and matching characternormalized characters yield different kinds of ratings  that are not comparable. The ratings based on baselinenormalized characters are inflated when compared to the ratings based one characternormalized characters so the font first adapted to always gets the highest ratings (due to learning new words that are actually printed in a different font). There is probably also a (related?) bug that causes inflated ratings for bad matches using BaselineClassifier. For example doubling xheight still matches the same font in testing if BaselineClassifier is called. The only case where a different font is sometimes matched  is when the characters are damaged beyond recognition (that may be because different classifiers are tried in this case).
  I've traced the code several times looking for the class which the characters recognized, but I can't found it.
where does the characters recognize?
  Tesseract just spent seven hours trying to do OCR on the attached document. It's five pages long. 

I'm fairly certain that the reason this takes so long is because of the speckling in the document. Other times when I've seen this kind of performance, it's been for similarly speckled documents.

Not sure what you can or should do about it, but since it seems to be a worst case scenario for Tesseract, I thought I'd report it.

This is on the latest version of Tesseract. 

[gov.uscourts.ctd.18812.88.0.pdf](https://github.com/tesseract-ocr/tesseract/files/488538/gov.uscourts.ctd.18812.88.0.pdf)
 One minute per page is not extraordinary much (although improvements which make it faster are of course welcome). My worst cases are currently double pages from a historic newspaper which take around ten minutes.
 Thanks for looking at this! We converted using ghostscript to multi-page tiff:

```
gs -dQUIET -dSAFER -dBATCH -dNOPAUSE-sDEVICE=tiffgray -r300x300-o destination path
```

One minute/page is still pretty darned slow, but we'd welcome that at this point!
 You could use gs to split the pdf into images and then ocr each separately
and concatenate the result.

On 23 Sep 2016 10:58 p.m., "Mike Lissner" notifications@github.com wrote:

> Thanks for looking at this! We converted using ghostscript to multi-page
> tiff:
> 
> gs -dQUIET -dSAFER -dBATCH -dNOPAUSE-sDEVICE=tiffgray -r300x300-o
> destination path
> 
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/431#issuecomment-249253159,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o7sVanef-bvL1nJdyJAdBJ0L3-2jks5qtAwkgaJpZM4KEcsN
> .
 Sure, but that's not the point...and anyway, it's not at all clear that the slowness is because it's a multipage tiff. I suspect if you ran this on each individual page of the tiff you'd have the same slowness.
 To get accurate results, you will need to preprocess the images too to get
rid of the background speckles.

You could try scantailor or imagemagick.

As a test, you can also try Vietocr GUI, and compare results with the
command line output.

On 23 Sep 2016 11:35 p.m., Shree wrote:

You could use gs to split the pdf into images and then ocr each separately
and concatenate the result.

On 23 Sep 2016 10:58 p.m., "Mike Lissner" notifications@github.com wrote:

> Thanks for looking at this! We converted using ghostscript to multi-page
> tiff:
> 
> gs -dQUIET -dSAFER -dBATCH -dNOPAUSE-sDEVICE=tiffgray -r300x300-o
> destination path
> 
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/431#issuecomment-249253159,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o7sVanef-bvL1nJdyJAdBJ0L3-2jks5qtAwkgaJpZM4KEcsN
> .
 Yeah, we saw this in testing, but went with TIFFs because they support multi-page images, which makes our OCR pipeline easier. In testing, we saw that the OCR for PDFs was no slower using large TIFFs than it was using PNGs because the process seems to be CPU bound no matter what.

If you use 300dpi PNGs do you get the slow performance I experienced with the 300dpi TIFFs? That's probably a better test, right?
 Thanks for looking at this @amitdo.

> This command creates a 42 MB tiff file. The size in pixels of each page is the same as with my PNGs.

But these aren't 300x300, which is apparently what provides the best OCR quality.[1] The point of this issue is that at 300x300, this takes seven hours to do five pages.

> It 'thinks' the speckles are diacritics...

Yeah...that's an issue too. Running a despeckling filter first would help in this case, but we do OCR on millions of PDFs and we only need to despeckle the worst of them. For the rest, I imagine it would reduce quality (not to mention slow down the pipeline).

The point here is that Tesseract takes seven hours for a speckled document at the recommended DPI.

[1]: Some references: 
- From the FAQ: https://github.com/tesseract-ocr/tesseract/wiki/FAQ#is-there-a-minimum-text-size-it-wont-read-screen-text
- "Optimal Image Conversion Settings for Tesseract" : https://mazira.com/blog/optimal-image-conversion-settings-tesseract-ocr
- "Using Tesseract with PDF scans": http://kiirani.com/2013/03/22/tesseract-pdf.html
 @mlissner It would have been helpful, if you had shared the info about your previous tests for this type of document

http://stackoverflow.com/questions/39110300/how-to-provide-image-to-tesseract-from-memory

https://github.com/mlissner/tesseract-performance-testing
 We have seen similar documents taking very long (but still not an hour per page!). Therefore, whether it really is a tesseract issue should be investigated further.

@mlissner in order to increase performance and quality, you have to pre-process the image(s) for tesseract. For your specific case, use `leptonica` (tesseract already depends on it). Count the connected components, if there are too many, apply your filters. In a real word application where your documents have specific characteristics, you will not be able to avoid heavy pre-processing for tesseract in order to achieve reasonable results.

Look how tesseract uses leptonica and CCs e.g., 
https://github.com/tesseract-ocr/tesseract/search?utf8=%E2%9C%93&q=pixConnComp
 @mlissner
You could also look at the preprocessing workflow used by pdf sandwich 
https://sourceforge.net/projects/pdfsandwich/
 Lots of responses here, so let me try to respond to as many as I can.

@amitdo and @jbreiden:

I considered using `-sDEVICE=tiffg4` over `-sDEVICE=tiffgray`, but it's not purely black and white, and like I said, the bigger files don't seem to affect performance. Here's a comparison of a gray part of the original PDF:

`tiffg4`:
![g4](https://cloud.githubusercontent.com/assets/236970/18854007/4b98691c-83fd-11e6-9ef8-af26032e579c.png)

`tiffgray`:
![gray](https://cloud.githubusercontent.com/assets/236970/18854014/54c3f81c-83fd-11e6-9b79-b27dc815011b.png)

`tiffgray` is definitely better for this, and since we're doing millions of files, it seems safer to use this approach than to assume all docs are purely black and white (even though it makes big files).

But setting that aside, it seems like using `gs` is the wrong approach regardless. Seems like the right approach is to extract the images undisturbed. Seems doable, but I'll have to do some research on this. Is it documented anywhere which image formats Tesseract supports natively? There's [one question in StackOverflow](https://stackoverflow.com/questions/10193001/whats-the-best-image-input-type-for-tesseract) that seems to address this, but otherwise I don't see a lot of guidance. I'm concerned that if we use the undisturbed images, we'll get weird image formats that Tesseract won't accept.

@jbreiden you also say:

> If necessary, adjust their header so that their resolution agrees with what the PDF was claiming.

This feels wrong to me. In my experience, PDFs are a terrible source of ground truth. I'd expect the header information in the images to be much more accurate than whatever a PDF was reporting. You've provided a lot of information here already, but can you explain why we'd prefer the PDF data over the image data? 

@vidiecan: I'll look into counting connected components. Seems like a great way to solve this, if it performs well enough. Thanks for this suggestion.

@Shreeshrii: I looked at PDF Sandwich, but didn't see anything useful. Do you know the code well enough to point me towards the image conversion part? 
 @jbreiden, do you know the image formats supported by Tesseract?
 > You might want to use -sCompression=lzw.

I just did some simple timings on this. 

The good:  
- Compressed Tiffs are about 1-2% the size of the uncompressed versions (in a test I just did, uncompressed was 137M while compressed was 1.8M!).
- Using compressed files used about 30% of the RAM (92MB instead of 301MB according to [`time -v`](https://stackoverflow.com/questions/774556/peak-memory-usage-of-a-linux-unix-process)).
- LZW is a lossless format, so Tesseract generated identical results.
- It took Tesseract about the same amount of time to do either format.

The bad:  
- It takes about twice as long to generate compressed tiffs from PDFs (though this is only a fraction of the total time doing OCR).

The hmmm:  
- Making a compressed tiff moves the processing burden from disk (making a big file) to CPU (compressing a big file).

Our bottleneck on our OCR server is CPU, so it's actually preferable for us to generate big files that use less CPU than to make small files that don't. OTOH, RAM is expensive, so we'll probably be switching this out. Thanks for the suggestion!
 Jeff,
Why are we not commiting your patch from March?

On 4 Oct 2016 9:30 p.m., "jbreiden" notifications@github.com wrote:

> My first patch (dated March 28) in this bug #233
> https://github.com/tesseract-ocr/tesseract/issues/233 will reduce RAM
> use in TIFF. It stops Tesseract from buffering the input file before
> decompression. The patch should also should make the LZW case equal to the
> non-LZW case with respect to RAM. Note that I haven't tested on this
> particular example, so I'm saying "should" rather than "does".
> 
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/431#issuecomment-251488440,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o26v-ubHM_MSiloIl-YAaOzocpMPks5qwqlWgaJpZM4KEcsN
> .
  Is it possible to find a roadmap/changelog for upcoming releases like 3.05 so the "public" can follow the development..

Personally I would really like some optimization.. The accuracy is quite good but the speed is really bad!
 Will 3.05 be based on LSTM?
 A roadmap would help planning development and inform users about future features which they can expect. I could not find one for 3.05, so I assume that there is no officially published roadmap. Maybe it would be a good idea to create one on the [Tesseract wiki](https://github.com/tesseract-ocr/tesseract/wiki).
 LSTM release is going to be 4.0 as per zdenko since it is a major change.

I would request zdenko for a release/tag of repo before that for 3.05. A
change log for that could be created by summarizing the commit notes.

Some recent updates of interest to many users are...
Improvement for Windows versions
Availability of training tools on windows
Various bug fixes since 3.04.1
Etc

On 23 Sep 2016 11:46 a.m., "Amit" notifications@github.com wrote:

> In general, only Ray can share this roadmap. You can ask him to do so in
> the dev forum.
> https://groups.google.com/d/forum/tesseract-dev
> 
> and inform users about future features which they can expect. I could not
> find one for
> 
> For the next release the major feature is the LSTM based engine, which
> users can read about in the DAS 2016 slides.
> 
> Regarding sharing the dates for releases, some open source projects do
> share a schedule, while others just declare "We'll have a new release when
> it's ready...".
> 
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/430#issuecomment-249111751,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o6dJ5XcUXiaPRWE7ElBADweni21Xks5qs27ZgaJpZM4KD0AP
> .
 For users
https://groups.google.com/forum/#!topic/tesseract-ocr/e__2DN1GQb0

For developers
https://groups.google.com/forum/#!topic/tesseract-dev/mZ2IUsvWgbY Ray also updated the page that @Shreeshrii created. 
https://github.com/tesseract-ocr/tesseract/wiki/4.0-with-LSTM#40  This may be an oversight, setting justification in ccmain/pageiterator.cpp:ParagraphInfo seems to work fine. Patch attached.
[set_justification.patch.zip](https://github.com/tesseract-ocr/tesseract/files/478642/set_justification.patch.zip)
  09-17 15:20:02.050 21768-21778/com.example.sigmaway.homeimage W/art: Suspending all threads took: 28.488ms
09-17 15:20:02.078 21768-25485/com.example.sigmaway.homeimage V/OCR: Ctesseract 1
09-17 15:20:02.085 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/libjpgt.so: unused DT entry: type 0x6ffffffe arg 0x29b0
09-17 15:20:02.085 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/libjpgt.so: unused DT entry: type 0x6fffffff arg 0x1
09-17 15:20:02.088 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/libpngt.so: unused DT entry: type 0x6ffffffe arg 0x58e0
09-17 15:20:02.088 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/libpngt.so: unused DT entry: type 0x6fffffff arg 0x2
09-17 15:20:02.093 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/liblept.so: unused DT entry: type 0x6ffffffe arg 0x231d0
09-17 15:20:02.093 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/liblept.so: unused DT entry: type 0x6fffffff arg 0x2
09-17 15:20:02.097 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/libtess.so: unused DT entry: type 0x6ffffffe arg 0x67f60
09-17 15:20:02.097 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/libtess.so: unused DT entry: type 0x6fffffff arg 0x3
09-17 15:20:02.156 21768-25485/com.example.sigmaway.homeimage V/OCR: Ctesseract 2
09-17 15:20:02.157 21768-25485/com.example.sigmaway.homeimage V/OCR: Ctesseract 3
09-17 15:20:02.293 21768-25485/com.example.sigmaway.homeimage A/libc: Fatal signal 6 (SIGABRT), code -6 in tid 25485 (AsyncTask #4)
09-17 15:20:03.802 27329-27329/com.example.sigmaway.homeimage W/art: Before Android 4.1, method android.graphics.PorterDuffColorFilter android.support.graphics.drawable.VectorDrawableCompat.updateTintFilter(android.graphics.PorterDuffColorFilter, android.content.res.ColorStateList, android.graphics.PorterDuff$Mode) would have incorrectly overridden the package-private method in android.graphics.drawable.Drawable
09-17 15:20:04.033 27329-27329/com.example.sigmaway.homeimage A/add¬†home: tess data  or Document file found
09-17 15:20:04.037 27329-27329/com.example.sigmaway.homeimage A/add¬†home: tess data  or Document file found
09-17 15:20:04.090 27329-27372/com.example.sigmaway.homeimage D/OpenGLRenderer: Use EGL_SWAP_BEHAVIOR_PRESERVED: true
09-17 15:20:04.099 27329-27329/com.example.sigmaway.homeimage D/Atlas: Validating map...

public class Ocr {
    String TAG= "OCR";
    String DATA_PATH = Environment.getExternalStorageDirectory().toString() + "/Sigmaway/";
    String[] language={"eng","ara"};
    Context c;
    ArrayList<Rect> Pics=new ArrayList<Rect>();
    public void Ocr(Context context){

```
    this.c=context;
    String[] paths = new String[]
            { DATA_PATH, DATA_PATH + "tessdata/" };

    for (String path : paths) {
        File dir = new File(path);
        if (!dir.exists()) {
            if (!dir.mkdirs()) {
                Log.v(TAG, "ERROR: Creation of directory " + path + " on sdcard failed");
                return;
            } else {
                Log.v(TAG, "Created directory " + path + " on sdcard");
            }
        }

    }
    for (String lang:language)
    {   Log.v(TAG, "hey c");

        if (!(new File(DATA_PATH + "tessdata/" + lang + ".traineddata")).exists()) {
            try {

                AssetManager assetManager = c.getAssets();
                InputStream in = assetManager.open("tessdata/" + lang + ".traineddata");
                //GZIPInputStream gin = new GZIPInputStream(in);
                OutputStream out = new FileOutputStream(DATA_PATH
                        + "tessdata/" + lang + ".traineddata");

                // Transfer bytes from in to out
                byte[] buf = new byte[1024];
                int len;
                //while ((lenf = gin.read(buff)) > 0) {
                while ((len = in.read(buf)) > 0) {
                    out.write(buf, 0, len);
                }
                in.close();
                //gin.close();
                out.close();

                Log.v(TAG, "Copied " + lang + " traineddata");
            } catch (IOException e) {
                Log.e(TAG, "Was unable to copy " + lang + " traineddata " + e.toString());
            }
        }

    }

}
```

 public String tesseract(Context context,Bitmap bmpImg, String lang){
      this.c=context;

```
 Log.v(TAG, "Ctesseract 1" );
   TessBaseAPI baseApi = new TessBaseAPI();
 Log.v(TAG, "Ctesseract 2" );
   baseApi.setDebug(true);
 Log.v(TAG, "Ctesseract 3" );
   baseApi.init(DATA_PATH,lang);
 Log.v(TAG, "Ctesseract 4" );
   baseApi.setImage(bmpImg);
 Log.v(TAG, "Ctesseract 5  "  );
   String recognizedText = baseApi.getUTF8Text();
 Log.v(TAG, "Ctesseract 6" );
   baseApi.end();
   if ( lang.equalsIgnoreCase("eng") ) {
       recognizedText = recognizedText.replaceAll("[^a-zA-Z0-9]+", " ");
   }

   //recognizedText = recognizedText.trim();
 return recognizedText;
}
```

}
This is my class through which i ocr the task and call the method in async task from the main activity.
so if i do use english the api works well but if i use the arabic trained data the app crashes giving
the below error on  baseApi.init(DATA_PATH,lang); command
09-17 15:20:02.293 21768-25485/com.example.sigmaway.homeimage A/libc: Fatal signal 6 (SIGABRT), code -6 in tid 25485 (AsyncTask #4)
09-17 15:20:03.802 27329-27329/com.example.sigmaway.homeimage W/art: Before Android 4.1, method android.graphics.PorterDuffColorFilter android.support.graphics.drawable.VectorDrawableCompat.updateTintFilter(android.graphics.PorterDuffColorFilter, android.content.res.ColorStateList, android.graphics.PorterDuff$Mode) would have incorrectly overridden the package-private method in android.graphics.drawable.Drawable
  Hi there, I've got some specific images that output the following on linux:

```
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
```

The pictures get successfully OCRed in tesseract (without great results tho). The biggest problem for me, however, is that in OCRopus they don't even get OCRed.

![example5](https://cloud.githubusercontent.com/assets/11379168/18517342/4f37901e-7a72-11e6-9db0-260a42a10189.jpg)
![ghoby30c](https://cloud.githubusercontent.com/assets/11379168/18517343/4f37ab1c-7a72-11e6-9766-b6831a215718.jpg)

Any ideas?
 @amitdo I'm getting the same issue just with Tesseract. I'm guessing OCRopus is using Tesseract and that's why he made the issue here. >I'm guessing OCRopus is using Tesseract

Ocropy (and clstm) does not use Tesseract. A VERY OLD version of Ocropus (0.4) did use Tesseract.
  A user reported to Homebrew in https://github.com/Homebrew/homebrew-core/issues/4764 that the tesseract build was broken if built from the HEAD of master (currently a75ab450a8cc9a2b69cf05f5c4f7a39bc44cbacc) using the options

```
brew install tesseract --HEAD --with-opencl
```

which means that we pass `--enable-opencl` to `configure`.

I bisected the build failure and found that it's a regression caused by https://github.com/tesseract-ocr/tesseract/commit/b1c921b59e6af1e68fd026cbc30540929b818552

Reverting

```
libtesseract_la_LDFLAGS += -version-info $(GENERIC_LIBRARY_VERSION) -no-undefined
```

back to

```
libtesseract_la_LDFLAGS += -version-info $(GENERIC_LIBRARY_VERSION)
```

fixed the build. A "real" fix will be more involved of course, since I'm sure you don't want to break Cygwin again.

The build error presents as

```
==> Installing tesseract
==> Using the sandbox
==> Cloning https://github.com/tesseract-ocr/tesseract.git
Cloning into '/Users/joe/Library/Caches/Homebrew/tesseract--git'...
remote: Counting objects: 794, done.
remote: Compressing objects: 100% (733/733), done.
remote: Total 794 (delta 125), reused 235 (delta 42), pack-reused 0
Receiving objects: 100% (794/794), 3.78 MiB | 1.10 MiB/s, done.
Resolving deltas: 100% (125/125), done.
Checking connectivity... done.
==> Checking out branch master
==> ./autogen.sh
==> ./configure --prefix=/usr/local/Cellar/tesseract/HEAD-a75ab45_2 --enable-opencl
==> make install
Last 15 lines from /Users/joe/Library/Logs/Homebrew/tesseract/03.make:
  "_clReleaseProgram", referenced from:
      OpenclDevice::ReleaseOpenclEnv(_GPUEnv*) in libtesseract_opencl.a(openclwrapper.o)
  "_clSetKernelArg", referenced from:
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL(int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL(int, int, unsigned int, unsigned int) in libtesseract_opencl.a(openclwrapper.o)
      pixORCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      pixANDCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      ...
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[1]: *** [libtesseract.la] Error 1
make: *** [install-recursive] Error 1
```

Complete log is here: https://gist.github.com/y-fedorov/0e5a302dd68ff9d8647f03ba4c15050a
 I wonder if you'd have any more luck with pocl.
 OP said that's fine

```
$ brew install tesseract - is OK
$ brew install tesseract --HEAD - is OK
```
 @stweil, can you fix that?  Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
row xheight=132.409, but median xheight = 101.7
row xheight=126.5, but median xheight = 101.7
row xheight=126.5, but median xheight = 101.7
row xheight=119, but median xheight = 101.7
row xheight=86.6667, but median xheight = 101.7
row xheight=76.6667, but median xheight = 101.7
row xheight=246, but median xheight = 101.7
id < this->size():Error:Assert failed:in file unicharset.cpp, line 278
zsh: segmentation fault (core dumped)  **tesseract de.elab.exp0.png de.elab.exp0.box box.train**

boxfile: @https://gist.github.com/CDanU/e14b3b1c0ba3a3502fb86a55bad0a30d
img: https://cloud.githubusercontent.com/assets/15148226/18413673/1edce808-77af-11e6-9ba4-94524dcf2243.png

Maybe the image is too big ? If that is the case it would be nice to get a better message.

tesseract 3.05.00dev
 leptonica-1.73
  libgif 5.1.2 : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.6.25 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.5.1
  The existing C API for `TessBaseAPIDetectOS` requires a C caller to successfully allocate `struct OSResults` which is actually a C++ class. If the C++ compiler decides to append anything to the structure, this will fail. The definition of this struct also depends on `kMaxNumberOfScripts` so is subject to change if (when) Tesseract adds more scripts.

The struct members that a caller is most likely to want are actually in `OSBestResult` whose position may shift.

I suggest deprecating this API and providing one that returns the member elements of `OSBestResult` instead. I think it would be useful to have a C API call to obtain this information rather than parsing the executable's output in `-psm 0`. Here's one possible API.

``` C
BOOL TessBaseAPIDetectOS2(
 TessBaseAPI* handle, 
 int* best_script_id, 
 int* best_orientation_id, 
 float* script_confidence, 
 float* orientation_confidence);
```

Returning `OSBestResults` is also an option, but sometimes it's nice to avoid structs entirely.

I can contribute changes if there's agreement on them.
 Posted
 The suggestion looks good to me. 

@zdenop, I suggest to give @jbarlow83 a green light for sending a PR. Yes, working on it.  I am facing issues in window installation. And probably due to Pango / Cairo. Any help please?

```
c:\work\tesseract\build>cmake .. -DSTATIC=1
-- Downloading latest ICU binaries
-- Checking for module 'pango'
--
CMake Error at C:/Program Files/CMake/share/cmake-3.7/Modules/FindPkgConfig.cmak
e:415 (message):
```
  A required package was not found
```
Call Stack (most recent call first):
  C:/Program Files/CMake/share/cmake-3.7/Modules/FindPkgConfig.cmake:588 (_pkg_c
heck_modules_internal)
  training/CMakeLists.txt:190 (pkg_check_modules)


-- Configuring incomplete, errors occurred!
See also "C:/work/tesseract/build/CMakeFiles/CMakeOutput.log".
See also "C:/work/tesseract/build/CMakeFiles/CMakeError.log".
``` http://www.pango.org/Download 404 error https://www.gtk.org/download/win64.php
Tried [this](https://sourceforge.net/projects/sdlpango/)  but no help  I find the 3.0.5 model is better than 3.0.2.Now my project is building by vs2010 and tesseract3.0.2.I replace the 3.0.2 tessdata by 3.0.5 tessdata ,it shows "allow_blob_division",than I use "combine_tessdata -e chi_sim.traineddata chi_sim.config" and notes the line of "allow_blob_division",finally "combine_tessdata -o chi_sim.traineddata chi_sim.config",but the tessdata is invalid.
  ![2](https://cloud.githubusercontent.com/assets/2742842/18303628/ab937754-7510-11e6-9d01-12bf943a2b24.png)

```
tesseract.exe -psm 10 2.png stdout digits
```

Above picture always return empty without any error. Is that a bug?
  Are there any plans for creating ALTO support in tesseract? I was thinking about programming a module for it. I was searching some conversion tool but found nothing working. I need it to be working in linux terminal, I found just conversion tool from hOCR to ALTO but the output is wrong. It would be also better if tesseract would generate ALTO. 
 Did you try https://github.com/UB-Mannheim/ocr-fileformat?
 Yes I have and the generated ALTO isn't valid. It can't be imported to the software I use and also the validator ocr-validate says it's not valid.
 Could you please [create an issue for that project](https://github.com/UB-Mannheim/ocr-fileformat/issues) then and add more details about the problems which you encountered?
  tesseract::TessBaseAPI is not thread safe, I want to create mutliple instances to serve more request, but memory usage is too high, so I want to share the language data between instances
  Hi,
I'm following the instruction for Windows from: https://github.com/tesseract-ocr/tesseract/wiki/Compiling
I have cloned the master branch today, copied cppan and installed cmake 3.6.1 for Windows.
cppan runs without issues.
Then I run cmake and it goes with multiple errors. Log attached.
VC 2015 solution file is not created.
Any clues?

[CMake_outputs.zip](https://github.com/tesseract-ocr/tesseract/files/455681/CMake_outputs.zip)
 Thanks for comment, I'll check with cppan upgrade later today.
I assumed the successful output of cmake should generate VS solution. I couldn't find any .sln file in the build directory. Should it be there, or somewhere else?
 Ok, so let's clarify: yes, I follow these instructions. I clone the tesseract repo. Build directory doesn't exist and I create it as described in the instruction. Inside build dir, I run cmake, and it finishes with errors. Logs were attached. Solution (.sln) file is not created. I will double check it later today (don't have access to my dev machine now) but I'm really quite confident it hasn't been created.
 Double checked, the .sln file is not created in the build dir.
Note, the cmake run is full of this kind of errors:

-- Build files have been written to: C:/Users/jarek/.cppan/storage/obj/03/76/d289/build/amd64-msvc-19.0-32
CMake Error at C:/Users/jarek/.cppan/storage/obj/03/76/d289/generate.cmake:106 (include):
  include could not find load file:

```
C:/Users/jarek/.cppan/storage/obj/03/76/d289/build/amd64-msvc-19.0-32/exports/pvt_cppan_demo_gif__5_1_4-fixed.cmake
```

Call Stack (most recent call first):
  cppan/CMakeLists.txt:45 (include)

Note the ...-fixed.cmake include error. In the folder where this file is expected to reside, there are these files:
06.09.2016  18:52             2,140 cppan-helpers-private.cmake
06.09.2016  18:52             2,322 cppan-helpers.cmake
06.09.2016  18:52             2,816 cppan.cmake
06.09.2016  18:55                 0 pvt_cppan_demo_gif__5_1_4-aliases.cmake
06.09.2016  18:52             4,707 pvt_cppan_demo_gif__5_1_4.cmake

Any clue? I have zero experience with cppan and cmake, so no idea how to attempt to resolve it.
 Tried that, didn't help.
 I was unable to get all log into a single file.
I've once again deleted whole content of C:/Users/jarek/.cppan and removed the build directory in tesseract folder.
run cppan again, log attached and then run cmake again, with redirect to cmake.log, also attached, but some errors got printed to the console anyway (they're not present in log or in CMakeError.log file. All console dump is in the cmd.log.
[tesseract_build_log.zip](https://github.com/tesseract-ocr/tesseract/files/457627/tesseract_build_log.zip)
 There seem to be no error log in that folder. I've zipped it all.
[amd64-msvc-19.0-32.zip](https://github.com/tesseract-ocr/tesseract/files/457644/amd64-msvc-19.0-32.zip)
 No luck again :(
Well, thanks for trying. I'm now trying to use just binaries from here: 
https://github.com/charlesw/tesseract/tree/master/src/lib/TesseractOcr/x64
not trivial either as there are no .lib files and need to match .h files to these binaries, but I'm still trying :)
 I think I'm quite close to make it run with binaries above, but if not lucky, I'll try the method above. Any hints on how to this sample from visual studio?
 Heh, as you wrote it, I've just made libtesseract load into my VS project.
Created lib from dll, completed api .h files with all the scattered dependencies and made it load, init and ... fail to recognize my bitmap :) But it works from command line with tesseract.exe, so just something wrong with params i'm passing. I'm not using leptonica. instead trying to ocr a screenshot that I have in memory in BMP format... but we're going off topic here.

Thanks much for all your help!!!
  It conflicts with a previous 'class' declaration for ETEXT_DESC:

include/tesseract/baseapi.h:594:21:
 Struct 'ETEXT_DESC' was previously declared as a class

Signed-off-by: Stefan Weil sw@weilnetz.de
  `..../include/tesseract/baseapi.h:594:21: Struct 'ETEXT_DESC' was previously declared as a class`

In baseapi.h declared as fallows:
`class ETEXT_DESC;`
...

```
/**
   * Make a HTML-formatted string with hOCR markup from the internal
   * data structures.
   * page_number is 0-based but will appear in the output as 1-based.
   * monitor can be used to
   *    cancel the recognition
   *    receive progress callbacks
   */
  char* GetHOCRText(struct ETEXT_DESC* monitor, int page_number);
```

Do we really need struct definition here?

My system:
Xcode 7.3.1
Build version 7D1014

Clang:
Apple LLVM version 7.3.0 (clang-703.0.31)
Target: x86_64-apple-darwin15.6.0
Thread model: posix
 I just sent pull request #415 which fixes this issue.
  Follow the latest compilation guide for windows platform faces VS compile error:

‚Äúallheaders.h‚Äù: No such file or directory

This error actually comes from CMakeLists.txt:

```
if (NOT USES_CPPAN)
    target_link_libraries       (tesseract ${Leptonica_LIBRARIES})
    export(TARGETS tesseract FILE ${CMAKE_BINARY_DIR}/TesseractTargets.cmake)
else()
    target_link_libraries       (tesseract cppan)
    file(WRITE ${CMAKE_BINARY_DIR}/TesseractTargets.cmake "include(${CMAKE_BINARY_DIR}/cppan.cmake)\n")
    export(TARGETS tesseract APPEND FILE ${CMAKE_BINARY_DIR}/TesseractTargets.cmake)
endif()
```

Here `USES_CPPAN` is undefined, and the if statement is always True. Since Leptonica is loaded from CPPAN, and `target_link_libraries(tesseract cppan)` is never excuted, error happens!

After modify the codes above into

```
target_link_libraries       (tesseract cppan)
file(WRITE ${CMAKE_BINARY_DIR}/TesseractTargets.cmake "include(${CMAKE_BINARY_DIR}/cppan.cmake)\n")
export(TARGETS tesseract APPEND FILE ${CMAKE_BINARY_DIR}/TesseractTargets.cmake)
```

VS builds tesseract305.dll successfully.

`USES_CPPAN` needs definition!
pull request #416 
 Hi, 

in the version i downloaded, the correction discribed in [https://github.com/tesseract-ocr/tesseract/commit/193032a7786fafc4e633869a1b10457f849cb34b](url) is present.

I loaded the project in VS 2013. Compiling the  project results in a long list of errors 

error C1083: "allheaders.h": No such file or directory	d:\projekte\vs\sharpmapprojekte\tesseract\tesseract-master\ccmain\tesseractclass.h	29	1	libtesseract304
error C1083: "allheaders.h": No such file or directory	D:\Projekte\VS\SharpMapProjekte\Tesseract\tesseract-master\ccstruct\imagedata.cpp	33	1	libtesseract304
...
total of 110 errors of that kind.

In all the sourcefiles named the line 

`#include "allheaders.h"`

is found. But file allheaders.h is nowhere to be found.

Can someone please help me? Hi egorpugin,

i tried to follow this guide. 

the batch did not work correct.

`cmake .. -DSTATIC=1`

result:

...
CMake Error at CMakeLists.txt:54 (find_package):
  Could not find a package configuration file provided by "Leptonica"
  (requested version 1.71) with any of the following names:

    LeptonicaConfig.cmake
    leptonica-config.cmake

  Add the installation prefix of "Leptonica" to CMAKE_PREFIX_PATH or set
  "Leptonica_DIR" to a directory containing one of the above files.  If
  "Leptonica" provides a separate development package or SDK, be sure it has
  been installed.
...

What / where is Leptonica?  So i'm trying to ocr the following images but looks we its not doing it 100%. six is written as five. nine is written as 3. Any suggestions?
[deleted]
  Hi,

My Android app is still using an older version of tess two library, which was based on tesseract 3.02. Last time it used to work because it uses trained data for version 3.02, but since tesseract has moved to github seems like we could only download the latest version of trained data now. 

I tested with english and several european languages trained data and it works perfectly fine, however when I try Arabic, Japanese and Chinese the app crashes straightaway upon tesseract init.

My questions are, is the latest trained data in github only works with latest 3.05 version of tesseract? If so, is there a way to download the older versions of trained data? If not what could be the problem for the crash?

Thanks!
 Thanks for the quick response! Cheers
 i have the same question,i will try~~~
  Font names in Java and .NET platforms:

http://www.java2s.com/Tutorial/Java/0261__2D-Graphics/Togetallavailablefontsinyoursystem.htm
http://www.java2s.com/Code/CSharp/GUI-Windows-Form/Getallsysteminstalledfont.htm
https://msdn.microsoft.com/en-us/library/0yf5t4e8.aspx
 I'm afraid that there will be user complains again and again as long as there is that trailing comma. So in the long run it will be worth fixing the issue. To help solving the issue, I started to look at other software using pango, e.g.
https://bugs.launchpad.net/inkscape/+bug/595432
 Can anyone discern a pattern for these comma additions? I'm trying to compose the fontname after the user selected a font from a font dialog (part of an UI) and then pass it to text2image, but there's no consistent pattern that Pango would base on in adding the commas.

As a result of incorrectly composed fontnames, there were a lot of "Could not find font named..." errors. It would be much simpler if there were no commas at all.

Update: I came up with a simple workaround: If it failed with a san-comma fontname, I'd try again with the comma added.
  Hi, When I use VS to compile the following error

 fatal error C1083: Êó†Ê≥ïÊâìÂºÄÂåÖÊã¨Êñá‰ª∂:‚Äúallheaders.h‚Äù: No such file or directory
Excuse me is the reason?
 Use latest installer for windows from
https://github.com/UB-Mannheim/tesseract/wiki

ShreeDevi

---

‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Thu, Sep 1, 2016 at 2:18 PM, zdenop notifications@github.com wrote:

> You forget to read instructions ;-)
> 
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/407#issuecomment-244015951,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_oxnScEQkuJqWz09xxrQbjZPSjBmkks5qlpFCgaJpZM4Jyc9o
> .
  A haystack which is shorter than the needle resulted in negative value
for length_haystack which was forced to a very large unsigned value.

The resulting buffer overflow while reading the haystack would crash
text2image when it was called with a short font name.

Signed-off-by: Stefan Weil sw@weilnetz.de
 It's nearly identical to my implementation. Instead of

```
length_haystack = length_haystack - length_needle + 1;
for (i = 0; i < length_haystack; i++)
```

I used the shorter

```
length_haystack -= length_needle;
for (i = 0; i <= length_haystack; i++)
```
  Hi, 

I'm on compiling on Ubuntu 14.04.5 at ./configure stage and got error below.
I don't need to install training tools.

```
# ./configure
<skip>
configure: WARNING: Training tools WILL NOT be built because of missing icu library.
configure: WARNING: Try to install libicu-devel package.
./configure: line 17228: syntax error near unexpected token `pango,'
./configure: line 17228: `PKG_CHECK_MODULES(pango, pango, have_pango=true, have_pango=false)'
```

Here's the autoconf version

```
# autoconf --version
autoconf (GNU Autoconf) 2.69
Copyright (C) 2012 Free Software Foundation, Inc.
License GPLv3+/Autoconf: GNU GPL version 3 or later
<http://gnu.org/licenses/gpl.html>, <http://gnu.org/licenses/exceptions.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

Written by David J. MacKenzie and Akim Demaille.
```

How can to fix it?

Thanks,
 3.05.00dev
download the zip from github
 Oops forgot to mention. I run it and looks OK.

```
# ./autogen.sh
Running aclocal
Running libtoolize
libtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, `config'.
libtoolize: copying file `config/ltmain.sh'
libtoolize: putting macros in AC_CONFIG_MACRO_DIR, `m4'.
libtoolize: copying file `m4/libtool.m4'
libtoolize: copying file `m4/ltoptions.m4'
libtoolize: copying file `m4/ltsugar.m4'
libtoolize: copying file `m4/ltversion.m4'
libtoolize: copying file `m4/lt~obsolete.m4'
Running autoheader
Running automake --add-missing --copy
configure.ac:321: installing 'config/compile'
configure.ac:86: installing 'config/config.guess'
configure.ac:86: installing 'config/config.sub'
configure.ac:69: installing 'config/install-sh'
configure.ac:69: installing 'config/missing'
api/Makefile.am: installing 'config/depcomp'
Running autoconf

All done.
To build the software now, do something like:

$ ./configure [--enable-debug] [...other options]
```
 Hmmm... What the right solution on this? Thanks 
 Try

./autogen.sh
autoreconf -ivf
./configure

ShreeDevi

---

‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Wed, Aug 31, 2016 at 5:28 PM, Bayu Widyasanyata <notifications@github.com

> wrote:
> 
> Hmmm... What the right solution on this? Thanks
> 
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/405#issuecomment-243742032,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o6yjw6iYBVnU4C7zEuaFQ5PHF-gmks5qlWxMgaJpZM4JxZUl
> .
 @Shreeshrii it works! thanks bro! :+1:  taken from **autoreconf** man page
`By default, it only remakes those files that are older than their sources.`

@amitdo here's the output:

```
# dpkg -l | grep pkg-config
ii  pkg-config                            0.26-1ubuntu4                       amd64        manage compile and link flags for libraries
```

@zdenop It's fine! :-)

Should this "autoreconf -ivf" add to wiki?
Thanks!
 Just add some notes. The problem still exist until we should also install the pango lib dev (apt-get install libcogl-pango-dev). I thought it confuses as described on Wiki (https://github.com/tesseract-ocr/tesseract/wiki/Compiling), while it's not necessary to install (lib pango dev) if we're not plan to install training tools.
 Just add some notes. The problem still exist until we should also install the pango lib dev (apt-get install libcogl-pango-dev). I thought it confuses as described on Wiki (https://github.com/tesseract-ocr/tesseract/wiki/Compiling), while it's not necessary to install (lib pango dev) if we're not plan to install training tools.
 That was happened to one of my server. To ensure I will reinstall from fresh on my new vm box, and update / or reopen this issue if it problems.
 Hi, Just want to update if it was fine when I installed without pango lib-dev packages (no training tools). Just got WARN messages on config.log. Thanks!
  There is no good reason to suppress useful compiler warnings.

Signed-off-by: Stefan Weil sw@weilnetz.de
  ref: https://groups.google.com/forum/#!msg/tesseract-ocr/S9CIK3jOMWw/vVBZULrJ9xcJ

I tried using bazaar config for user patterns suggested in above post ( \A\A\d\d\d\A\A
) with the latest windows binary. It does not seem to work. Does the functionality work on linux?

input, output and config files attached. I added.txt extension to bazaar and eng.user-patterns in order to upload it here.

![patterntest](https://cloud.githubusercontent.com/assets/5095331/18089323/013e7fa8-6edd-11e6-948a-65b376c7ec4f.png)

OUTPUT

```
0011917
OX345PT
PT7895M
BA409QT
OMOOKM
WE4321M

OOLI9T7
OX345PT
PT789SM
BA409QT
OMOOKMI
WE432LM

OOLI9T7
OX345PT
PT7898M
BA409QT
OMOOKMI
WE432LM


```

[patternbazaar.txt](https://github.com/tesseract-ocr/tesseract/files/444884/patternbazaar.txt)

[bazaar.txt](https://github.com/tesseract-ocr/tesseract/files/444889/bazaar.txt)
[eng.user-patterns.txt](https://github.com/tesseract-ocr/tesseract/files/444890/eng.user-patterns.txt)
 Some other reports of user-patterns and user-words not working

https://groups.google.com/forum/#!topic/tesseract-ocr/5vFqVcJmHnM

http://stackoverflow.com/questions/17209919/tesseract-user-patterns

Has anyone tried this? Does it work?
 I can tell you that in the Tesseract forum many users ask about these files. They are disappointed that there is no effect on accuracy when using them with their input.

The input is usually not a document but something like receipt, passport, car license plate, with a small set of known words/patterns. In addition to the cases mentioned by Amit, there are users who would like
to use the user_words dictionary in addition to Tesseract's wordlist,

some examples of user words could be client names, industry specific
terminology eg. Medical or pharmaceutical.

Is it possible to allow for both kinds of scenarios, based on some config/variable?  @theraysmith  Ray, please also see 
https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/IUtQfIGZVdA/dm0-2n4DCQAJ

for discussion regarding a user looking for encrypted user words list to use with tesseract. Handle pattern by code. It is the only best way and anle customize easily

1. Teseract firstly have to process whole image anyway. We can not do anything to this. 
2. Then they process pattern by their code (i assumed it is bad). We bypass this step
3. Get all result and hadle by regular expression in code. All input is in text or digits so it will be fast, dont worry. 

Hint: Use your input result and regular expression checking online regular expression testing page. It will be great help. 

Hope you solve this @theraysmith 

Please see https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/p80qyGvVvP4/Rd1hlof3CAAJ

reg "recognize only from user word list" please see https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/wnlJcF4zIvU/4cIt9f2iCgAJ

 need to recognize words of medications ( Rare words that are most likely not included in the training data). Also see: https://groups.google.com/d/msgid/tesseract-ocr/ab28b50f-d592-4f48-b813-c03451c4dbb0%40googlegroups.com?utm_medium=email&utm_source=footer  Assertions are good for programming errors, but not for wrong user input.

The new code no longer needs File::ReadFileToStringOrDie, so remove that
method.

Signed-off-by: Stefan Weil sw@weilnetz.de
  The implementation for MS C did not pass the variable arguments to
tprintf.

The standard is supported since C99 / C++11, so one implementation
is sufficient.

Signed-off-by: Stefan Weil sw@weilnetz.de
 VS2010 should work with the new code, see the [Microsoft documentation](https://msdn.microsoft.com/en-us/library/ms177415%28v=vs.100%29.aspx). Please note also that the old code already used C99 / C++11 standard for all Microsoft compilers and also for Windows gcc versions which set `_MSC_VER`, but that it was buggy for all those compilers because it did not pass the variable arguments. The patch fixes this bug for Microsoft compilers.
The patch changes the situation regarding compatibility for really old compilers (neither gcc, clang, msc which all support variadic macros since a long time). I think that is only a theoretical issue and that such compilers would fail compiling Tesseract anyway.
`opencl/oclkernels.h` already contains a variadic macro using `__VA_ARGS__`.
 gcc-3.1.1 already supported the variadic macro syntax used in my patch, see the [online documentation](https://gcc.gnu.org/onlinedocs/gcc-3.1.1/cpp/Variadic-Macros.html#Variadic%20Macros). It was released in [2002](https://gcc.gnu.org/gcc-3.1/).
  > > @Shreeshrii @stweil : please create separate issue for command that crash on linux, so we can track it.
> 
> That command also crashes with SIGSEGV on Linux. This is a bug which needs a fix.

`text2image --fonts_dir= --text ./langdata/san.training_text --outputbase san.exp-1 --ptsize=32 --strip_unrenderable_words --fontconfig_refresh_config_file=false --leading=32 --char_spacing=0.0 --exposure=-1 --find_fonts --min_coverage=.9 --degrade_image=1 --underline_start_prob=.05 --underline_continuation_prob=.01`

[Ref: Issue 396](https://github.com/tesseract-ocr/tesseract/issues/396)
 I noticed that the crash is a "feature", caused by an assertion if `langdata/san.training_text` does not exist. Tesseract forces a SIGSEGV for assertions to improve debug information.

IMHO missing data is a typical user error which should be reported, but not throw an assertion. So replacing the assertion by a conditional `tprintf(...); exit(1);` in `training/fileio.cpp` might be the correct solution. If you agree, I'll send a pull request.
 FYI, in my testing on Windows 10, the crash was unrelated to 'langdata/san.training_text does not exist' since the file was very much there.

I will test further after new windows binary is made available with all these new patches.

Thanks for looking into this.
 @amitdo, thanks for the pointers. PR #402 now does something similar for `fileio`.
  See guys.. I badly need Text2image.exe but i cannot find it anywhere.
Is there any great soul in this world who will take the time to compile that 1 thing and upload it to mediafire or something?
This one thing has consumed 5 months of my life :'-(
I tried to compile it on windows 32 bit but it gave 100+ errors :'-(
Dear c/cpp experts.. Instead of telling everybody how to compile, isn't it a good idea to directly provide a compiled version?
I am not any intelligent software eng. I am just a normal human being.
Why didn't the developers take some time to upload the compiled binaries? :'-(
Somebody please help!
I now feel pain in my heart for wasting 5 months of my life for 1 program.
Somebody please compile 'Text2Image.cpp' for the needy who don't know how to do it.

P.S I have downloaded Tesseract 3.05 but there does not exist any 'text2image.EXE' :'-(
 - This is not the right place for asking questions. Did you read the [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ)?
- You might try the installer from https://github.com/UB-Mannheim/tesseract/wiki.
 I have tried this before. Even if you get a binary of text2image for
Windows say with cygwin or msys2 it will crash when u run it. There are
some incompatibilities with the code and windows. Just accept that it is
not available on Windows.

As Quan has suggested you can use jtessboxeditor for generating the box
tiff pairs and training.

Or get access to a linux machine.
- sent from my phone. excuse the brevity.

On 28-Aug-2016 11:32 AM, "z0tghvunik" notifications@github.com wrote:

> See guys.. I badly need Text2image.exe but i cannot find it anywhere.
> Is there any great soul in this world who will take the time to compile
> that 1 thing and upload it to mediafire or something?
> This one thing has consumed 5 months of my life :'-(
> I tried to compile it on windows 32 bit but it gave 100+ errors :'-(
> Dear c/cpp experts.. Instead of telling everybody how to compile, isn't it
> a good idea to directly provide a compiled version?
> I am not any intelligent software eng. I am just a normal human being.
> Why didn't the developers take some time to upload the compiled binaries?
> :'-(
> Somebody please help!
> I now feel pain in my heart for wasting 5 months of my life for 1 program.
> Somebody please compile 'Text2Image.cpp' for the needy who don't know how
> to do it.
> 
> P.S I have downloaded Tesseract 3.05 but there does not exist any
> 'text2image.EXE' :'-(
> 
> ‚Äî
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/396, or mute the
> thread
> https://github.com/notifications/unsubscribe-auth/AE2_o_D9-NssgSMtM4pUJgQllo2hXeBuks5qkSR5gaJpZM4Ju2ym
> .
 @Shreeshrii, there is a new installer on  https://github.com/UB-Mannheim/tesseract/wiki. It includes fixes for text2image.exe. If that binary still crashes, I need all information to reproduce the crash.
 ![image](https://cloud.githubusercontent.com/assets/5095331/18034130/c69f4bc4-6d52-11e6-9122-105fbf4ad585.png)

text2image --fonts_dir= --text ./langdata/ara.training_text --font Arial  --outputbase ara.Arial.exp0
 ```
C:\Users\User\Documents\shree>text2image --text=./langdata/eng.training_txt --outputbase=eng.MSSerifBold.exp0 --font='MS Serif Bold' --fonts_dir=
Unable to open '/tmp/fonts.conf' for writing
Fontconfig error: Cannot load default config file
FcInitiReinitialize failed!!
Could not find font named 'MS.Please correct --font arg.
```
 ![image](https://cloud.githubusercontent.com/assets/5095331/18034165/7a55f636-6d53-11e6-9cfc-a3350cd6a103.png)

text2image --fonts_dir= --text ./langdata/san.training_text --outputbase san.exp-1 --ptsize=32 --strip_unrenderable_words --fontconfig_refresh_config_file=false --leading=32 --char_spacing=0.0 --exposure=-1 --find_fonts --min_coverage=.9 --degrade_image=1 --underline_start_prob=.05 --underline_continuation_prob=.01
 @stweil Thank you for providing the updated binary for text2image - many problems have indeed been fixed since I last looked at it. Thanks to the developers. 

However, it crashed under two situations today.
1. when using font Arial, I tried with eng, ara and san - not sure what causes this, as when font is not found an error is displayed.

`text2image --fonts_dir= --text ./langdata/ara.training_text --font Arial --outputbase ara.Arial.exp0`
1. when trying to find fonts and create images for a particular text - 

`text2image --fonts_dir= --text ./langdata/san.training_text --outputbase san.exp-1 --ptsize=32 --strip_unrenderable_words --fontconfig_refresh_config_file=false --leading=32 --char_spacing=0.0 --exposure=-1 --find_fonts --min_coverage=.9 --degrade_image=1 --underline_start_prob=.05 --underline_continuation_prob=.01`

I will test further and post more feedback later.
 Here is a copy of the terminal log with all commands I tried and their output.
[testlog1.txt](https://github.com/tesseract-ocr/tesseract/files/441149/testlog1.txt)
 The following command is creating the box-tiff pairs with degradation as well as differnt exposure levels as indicated ..

`text2image --fonts_dir= --text ./langdata/san.training_text  --ptsize=32 --degrade_image=1 --leading=32 --char_spacing=0.0  --strip_unrenderable_words --underline_start_prob=.05 --underline_continuation_prob=.01 --font Kokila  --outputbase san.Kokila.exp-1 --exposure=-1`

I have done this testing on Windows 10.
 [san.Kokila.zip](https://github.com/tesseract-ocr/tesseract/files/441153/san.Kokila.zip)
 I tried the latest version of the program uploaded today on Windows10 and found that it now works but is unstable. It would fail for Arial font and could not find Times New Roman (the two fonts are most commonly used). The boxes in the generated box file were not as tight as they could be.

text2image --text=vie-data.txt --outputbase=vie.arial.exp1 --font="Tahoma" --fonts_dir=C:\Windows\Fonts
Rendered page 0 to file vie.arial.exp1.tif
Rtl = 0 ,vertical=0

text2image --text=vie-data.txt --outputbase=vie.arial.exp1 --font=Arial --fonts_dir=C:\Windows\Fonts
Program crashed

text2image --text=vie-data.txt --outputbase=vie.arial.exp1 --font="Courier New" --fonts_dir=C:\Windows\Fonts
Rendered page 0 to file vie.arial.exp1.tif
Rendered page 1 to file vie.arial.exp1.tif
Rtl = 0 ,vertical=0

text2image --text=vie-data.txt --outputbase=vie.arial.exp1 --font="Times New Roman" --fonts_dir=C:\Windows\Fonts
Could not find font named Times New Roman.Please correct --font arg.

text2image --text=vie-data.txt --outputbase=vie.arial.exp1 --font="Arial Unicode MS Regular" --fonts_dir=C:\Windows\Fonts
Rendered page 0 to file vie.arial.exp1.tif
Rtl = 0 ,vertical=0
 > C:\Users\User\Documents\shree>text2image --text=./langdata/eng.training_txt --outputbase=eng.MSSerifBold.exp0 --font='MS Serif Bold' --fonts_dir=

The previous command does not work because CMD on Windows does not handle `'MS Serif Bold'` like a POSIX shell. It passes `'MS` as font. Using `"MS Serif Bold"` should fix that.

> Could not find font named Times New Roman.Please correct --font arg.

It looks like this error messages can be improved by a line break after the first sentence. I'll send a PR which fixes this small detail.

> text2image --fonts_dir= --text ./langdata/san.training_text --outputbase san.exp-1 --ptsize=32 --strip_unrenderable_words --fontconfig_refresh_config_file=false --leading=32 --char_spacing=0.0 --exposure=-1 --find_fonts --min_coverage=.9 --degrade_image=1 --underline_start_prob=.05 --underline_continuation_prob=.01

That command also crashes with SIGSEGV on Linux. This is a bug which needs a fix.
 If you want to compile text2image for windows using VS2015, you can have a look at a fully automated process at
https://github.com/mazoea/te-external-tesseract
using the windows CI environment (appveyor.yml).

It might take a you a while to get the grasp of it (hopefully, hours not months) but you will get your text2image version that you can debug (and send PRs to tesseract).

More details:
1. all the external dependencies are at https://github.com/mazoea/te-external
2. read the Readme to understand the structure used throughout the process
3. see https://github.com/mazoea/te-external/blob/master/appveyor.yml for the real commands and also check the logs by clicking on the build badge in the repository
4. the same goes for https://github.com/mazoea/te-external-leptonica
5. the same goes for https://github.com/mazoea/te-external-tesseract
6. binaries will be in tesseract\projects\output
7. look at #381 

_BUT_
Those repositories are not forks of others, in case they do not have the latest version, you have to update it.  In practice, this means you should checkout tesseract and merge it with latest if not present - for the moment, there should be only a few of them!

Finally, do not expect a bulletproof text2image even after patching - more needs to be done to address several corner cases but you have everything needed for this mission.
 @stweil The problem with font not found message was not just of misplaced period. These fonts are there on Windows but text2image is NOT finding them.

```
C:\Users\User>text2image --text=./langdata/eng.training_txt --outputbase=eng.MSSerifBold.exp0 --font="MS Serif Regular" --fonts_dir=
Could not find font named MS Serif Regular.Please correct --font arg.
```

```
C:\Users\User>text2image --text=./langdata/eng.training_txt --outputbase=eng.Myfont.exp0 --font="Times New Roman" --fonts_dir=C:\Windows\Fonts
Unable to open '/tmp/fonts.conf' for writing
Fontconfig error: Cannot load default config file
FcInitiReinitialize failed!!
Could not find font named Times New Roman.Please correct --font arg.
```

`text2image --list_available_fonts`
shows the fonts in the list

```
 60: Arial

867: Times New Roman,
```

Ok, the above shows that Time New Roman also has a , at end of font name. So I tried with that, and results differ based on order in which the parameters are given etc . eg. --fonts_dir= should be given first .

```
C:\Users\User\Documents\shree>text2image --text=./langdata/eng.training_txt --outputbase=eng.Myfont.exp0 --font="Times New Roman," --fonts_dir=C:\Windows\Fonts
Unable to open '/tmp/fonts.conf' for writing
Fontconfig error: Cannot load default config file
FcInitiReinitialize failed!!
Failed to read file: ./langdata/eng.training_txt
ReadFileToString(filename, out):Error:Assert failed:in file ../../../../training/fileio.cpp, line 85

C:\Users\User\Documents\shree>text2image --text=./langdata/eng.training_txt --outputbase=eng.Myfont.exp0 --font="Times New Roman," --fonts_dir=
Failed to read file: ./langdata/eng.training_txt
ReadFileToString(filename, out):Error:Assert failed:in file ../../../../training/fileio.cpp, line 85

C:\Users\User\Documents\shree>text2image --fonts_dir= --text ./langdata/eng.training_text --font "Times New Roman"  --outputbase eng.Times.exp0
Could not find font named Times New Roman.Please correct --font arg.

C:\Users\User\Documents\shree>text2image --fonts_dir= --text ./langdata/eng.training_text --font "Times New Roman,"  --outputbase eng.Times.exp0
Stripped 3 unrenderable words
Rendered page 0 to file eng.Times.exp0.tif
Rendered page 1 to file eng.Times.exp0.tif
Rtl = 0 ,vertical=0
```
 ```
C:\Users\User\Documents\shree>text2image --text=./langdata/eng.training_text --outputbase=vie.arial.exp1 --font=Arial --fonts_dir=C:\Windows\Fonts
Unable to open '/tmp/fonts.conf' for writing
Fontconfig error: Cannot load default config file
FcInitiReinitialize failed!!
*** PROGRAM CRASHED ***

C:\Users\User\Documents\shree>text2image --text=./langdata/eng.training_text --outputbase=vie.arial.exp1 --font="Arial" --fonts_dir=C:\Windows\Fonts
Unable to open '/tmp/fonts.conf' for writing
Fontconfig error: Cannot load default config file
FcInitiReinitialize failed!!
*** PROGRAM CRASHED ***

C:\Users\User\Documents\shree>text2image --text=./langdata/eng.training_text --outputbase=vie.arial.exp1 --font="Times New Roman," --fonts_dir=C:\Windows\Fonts
Unable to open '/tmp/fonts.conf' for writing
Fontconfig error: Cannot load default config file
FcInitiReinitialize failed!!
Stripped 3 unrenderable words
Rendered page 0 to file vie.arial.exp1.tif
Rendered page 1 to file vie.arial.exp1.tif
Rtl = 0 ,vertical=0
```

both  --font="Arial" and  --font=Arial lead to program crash, even though Arial is listed as a font when usinf --list_available_fonts
--font="Times New Roman," works.

**_PROGRAM CRASHED *_ - the error box looks like shown in this image - there is no message on the console.

## ![image](https://cloud.githubusercontent.com/assets/5095331/18034130/c69f4bc4-6d52-11e6-9122-105fbf4ad585.png)

`Unable to open '/tmp/fonts.conf' for writing`
seems to be related to the default directory being non-writable under windows.

Setting 'FC_CACHEDIR = c:/your/writable/directory' may help.

or

use "LOCAL_APPDATA_FONTCONFIG_CACHE"  location for the cachedir, 

ref: https://bugs.launchpad.net/inkscape/+bug/1196373
 @zdenop OK

Please see my previous comment, in that I have used 
`--fonts_dir=C:\Windows\Fonts`
It still crashes when fontname Arial or "Arial" is used - on windows10.
 @zdenop 

On Windows10, I get the `FcInitiReinitialize failed!!` error when I use `--fonts_dir=C:\Windows\Fonts` which does not come when I use `--fonts_dir=`

```
C:\Users\User\Documents\shree>text2image --fonts_dir= --text ./langdata/eng.training_text --font "Times New Roman,"  --outputbase eng.Times.exp0
Stripped 3 unrenderable words
Rendered page 0 to file eng.Times.exp0.tif
Rendered page 1 to file eng.Times.exp0.tif
Rtl = 0 ,vertical=0

C:\Users\User\Documents\shree>text2image --fonts_dir=C:\Windows\Fonts --text ./langdata/eng.training_text --font "Times New Roman,"  --outputbase eng.Times.exp0
Unable to open '/tmp/fonts.conf' for writing
Fontconfig error: Cannot load default config file
FcInitiReinitialize failed!!
Stripped 3 unrenderable words
Rendered page 0 to file eng.Times.exp0.tif
Rendered page 1 to file eng.Times.exp0.tif
Rtl = 0 ,vertical=0
```
 On further investigation, I see that https://github.com/tesseract-ocr/tesseract/blob/master/training/pango_font_info.cpp overrides system and fontconfig defaults ..

```
STRING_PARAM_FLAG(fonts_dir, "/auto/ocr-data/tesstraining/fonts",
                  "Overrides system default font location");
STRING_PARAM_FLAG(fontconfig_tmpdir, "/tmp",
                  "Overrides fontconfig default temporary dir");
```

The `FcInitiReinitialize failed!!` error when using `--fonts_dir=C:\Windows\Fonts` disappears when specifying `fontconfig_tmpdir` in commandline. 

When used the first time, it creates `fonts.conf` and a cache file in the specified directory which takes some time. After that, there is no delay in building cache.

```
C:\Users\User\Documents\shree>text2image --fonts_dir=C:\Windows\Fonts --fontconfig_tmpdir=C:\Users\User\Documents\shree --text ./langdata/san.training_text  --outputbase
san.exp-1  --font FreeSerif
Rendered page 0 to file san.exp-1.tif
Rendered page 1 to file san.exp-1.tif
Rtl = 0 ,vertical=0

C:\Users\User\Documents\shree>text2image --fonts_dir=C:\Windows\Fonts --fontconfig_tmpdir=C:\Users\User\Documents\shree --text ./langdata/san.training_text  --outputbase
san.exp-1  --font FreeSerif --ptsize=32 --strip_unrenderable_words --fontconfig_refresh_config_file=false --leading=32 --char_spacing=0.0 --exposure=-1 --min_coverage=.9
--degrade_image=1 --underline_start_prob=.05 --underline_continuation_prob=.01
Rendered page 0 to file san.exp-1.tif
...
Rendered page 11 to file san.exp-1.tif
Rtl = 0 ,vertical=0

```
 As of now, the two errors still unexplained with text2image under Windows are 
1. Use of Arial font
2. Use of --find_fonts

@zdenop I can test and report errors to Pango/FOntConfig, but tesseract does not provide any error info that I can refer to.
 I'm currently working on the problem with Arial. That font is found (otherwise there would be an error message), but results in SIGSEGV - maybe from an assertion. It looks like Windows buffers console messages and fails to print them before raising the SIGSEGV.
 Thanks, Stefan.

ShreeDevi

---

‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Wed, Aug 31, 2016 at 5:36 PM, Stefan Weil notifications@github.com
wrote:

> I'm currently working on the problem with Arial. That font is found
> (otherwise there would be an error message), but results in SIGSEGV - maybe
> from an assertion. It looks like Windows buffers console messages and fails
> to print them before raising the SIGSEGV.
> 
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/396#issuecomment-243743876,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o-7TkoUbxqsA68wy6DYgPsCh1Qqhks5qlW5jgaJpZM4Ju2ym
> .
 The crash with Arial is caused by a bug in function strcasestr (locally implemented only for Windows, Linux uses the correct GLIBC implementation). Any short font name (5 characters or less) will result in a similar crash. I'll send a pull request which fixes this.
 PR #406 fixes the problem with Arial (and other fonts with short names) for text2image on Windows.
 Problem 2 (use of --find_fonts) is also caused by the buggy strcasestr function and fixed by PR #406:

```
(gdb) r
Starting program: /usr/x86_64-w64-mingw32/sys-root/mingw/bin/text2image --fonts_dir= --text ./langdata/san.training_text --outputbase san.exp-1 --ptsize=32 --strip_unrenderable_words --fontconfig_refresh_config_file=false --leading=32 --char_spacing=0.0 --exposure=-1 --find_fonts --min_coverage=.9 --degrade_image=1 --underline_start_prob=.05 --underline_continuation_prob=.01
[New Thread 10160.0x3ecc]

Program received signal SIGSEGV, Segmentation fault.
0x000000000040e089 in strcasestr (haystack=0x303afd0 "Arial", needle=0x43ba5d <tesseract::kDefaultResolution+457> "Fraktur") at ../../../../training/../vs2010/port/strcasestr.cpp:63
63                  c1 = haystack[i+j];
(gdb) i s
#0  0x000000000040e089 in strcasestr (haystack=0x303afd0 "Arial", needle=0x43ba5d <tesseract::kDefaultResolution+457> "Fraktur") at ../../../../training/../vs2010/port/strcasestr.cpp:63
#1  0x00000000004081c4 in tesseract::PangoFontInfo::ParseFontDescription (this=0x22f770, desc=0x3020000) at ../../../../training/pango_font_info.cpp:237
#2  0x0000000000408242 in tesseract::PangoFontInfo::ParseFontDescriptionName (this=0x22f770, name=...) at ../../../../training/pango_font_info.cpp:243
#3  0x000000000040a9ca in tesseract::StringRenderer::set_font (this=0x22f770, desc=...) at ../../../../training/stringrenderer.cpp:134
#4  0x000000000040a944 in tesseract::StringRenderer::StringRenderer (this=0x22f770, font_desc=..., page_width=3600, page_height=4800) at ../../../../training/stringrenderer.cpp:128
#5  0x0000000000402b61 in main (argc=1, argv=0x30389d0) at ../../../../training/text2image.cpp:462
(gdb) p i
$1 = 393264
(gdb) p length_haystack
$2 = 18446744073709551615
```
 The latest version has fixed the issue with Arial font. Thank you.

Clearly, the tool produces inconsistencies in font names. Why is "Times New Roman," a valid name, especially it's a plain style?

298: Times New Roman,
299: Times New Roman, Bold
300: Times New Roman, Bold Italic
301: Times New Roman, Italic
302: Trebuchet MS
303: Trebuchet MS Bold
304: Trebuchet MS Bold Oblique
305: Trebuchet MS Oblique
306: Verdana
307: Verdana Bold
308: Verdana Bold Oblique
309: Verdana Oblique
310: Yu Gothic
311: Yu Gothic Bold
312: Yu Gothic Bold Oblique
313: Yu Gothic Light, Light
314: Yu Gothic Medium, Medium
315: Yu Gothic Medium, Medium Oblique
316: Yu Gothic Oblique

@amitdo Almost all the generated boxes (created in Windows 10) are consistently a bit low and a bit wide. It was reported that having tightly fitted boxes would improve the quality of the generated traineddata file.

![image](https://cloud.githubusercontent.com/assets/1501035/18149420/9784b70c-6fa5-11e6-8396-e14cf428ddf1.png)
 @stweil 

Thank you for the changes to get text2image working on windows and for making the latest version available via installer at https://github.com/UB-Mannheim/tesseract/wiki

I have added a link to the same from https://github.com/tesseract-ocr/tesseract/wiki so that it is easily accessible.
  Hello, everyone.

I have been developing text detecting APP with tesseract.

I have found weird issue that tesseract could not detect large texts on image.

Here is the original image:
http://i67.tinypic.com/23ur420.jpg

When I apply tesseract to this image, I get some text like this:

```
GETUNTUPUF

BUBBLE.

BEFORE YOUR
COMPETITION
DUES
```

(NOTE: it does not matter to detect text correctly or not, I am just interested whether tesseract detects text or not.)

Here is the image I had detect text area from the original image.
http://i67.tinypic.com/qovfj9.png

Unfortunately when I apply tesseract to this image, I have got no text at all.

Any idea?
  I am using 3.04 tesseract ocr. Running command line like below gives me better result compared to programmatically calling the api.
"tesseract Page_00001_IP.tif Page_00001_IP -l eng -psm 4"

The api is called as follows.
                        var inputName = Path.GetFileName(imageFile).Replace(Path.GetExtension(imageFile), "");
                        using (var page = engine.Process(img, inputName, PageSegMode.SingleColumn))
                        {
                            text = page.GetText();
                        }
I have created the .uzn file same name as the image file. It contains regions specifying Left, Top, Width and Height. I appreciate any help to resolve this.

Thanks,
Ravi
  ![code](https://cloud.githubusercontent.com/assets/5222868/17615147/be407af4-609e-11e6-8d1d-8b711e242506.png)
![env](https://cloud.githubusercontent.com/assets/5222868/17615151/c542e51c-609e-11e6-872d-ff4bf757fbc8.png)
 what is the cause  of this error?
 Lol, check out this link https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/JZ9G3D5HHNM/A--DXmm2BgAJ  i am using https://github.com/tmbdev/clstm
and https://github.com/tmbdev/ocropy to train some rnn based model ,is there any way  to load such models in Tesseract?
 @amido  thx any way, i notice you working on both projects then came this question 
 @amitdo my fault~
  I'm using the tess-two which is a fork of this repo made use in android projects. Since the latest version, the progress notifier for the word recognition no longer works (it stays at 0% then jumps to 100% when the OCR is done)
  I've managed to make Tesseract OCR work with plain text but i need to make this OCR work with seven segments led displays on an Android Studio project.

I've really tried to dug internet for it but couldn't find useful information about this one. If anyone worked on a similar project I'm desperate for your help. Please.

Thanks from now.
  PDFs generated using either Cygwin (3.04.01) or one of the windows binaries (3.05.00dev) gives offset highlighted text and garbled text when copied, in pdf.js. Attached TIF is output from Scan Tailor. Related: #337 .

Copied from pdf.js:
An  exactmethodis  presentedfor  numericallycalculating,withinthe  frameworkof  thestochasticformulationof  chemicalkinetics,the   timeevolutionof  anyspatiallyhomog-
![image](https://cloud.githubusercontent.com/assets/4030380/17447416/41d2a3ac-5b1c-11e6-9d7f-19a43bcb76d6.png)

Attached txt output from tesseract:
An exact method is presented for numerically calculating, within the framework of the
stochastic formulation of chemical kinetics, the time evolution of any spatially homog-

[Gillespie-000.txt](https://github.com/tesseract-ocr/tesseract/files/404420/Gillespie-000.txt)
[Gillespie-000.pdf](https://github.com/tesseract-ocr/tesseract/files/404417/Gillespie-000.pdf)
[Gillespie-000.zip](https://github.com/tesseract-ocr/tesseract/files/404421/Gillespie-000.zip)
 i think as @ebogaard pointed out this issue and [sumatrapdf #544](https://github.com/sumatrapdfreader/sumatrapdf/issues/544) are very closely related to tesseract #373, which is more than just a pdf renderer issue. a lot of the pdfs referenced in that issue open correctly in adobe but not in other pdf renderers.

would be great to have the pdfs generated by tesseract render correctly in pdf.js
 Should be in v4. Very easy to back port to v3 if desired. @jbreiden
Isn't a new `pdf.ttf` needed? Yes there should be a new pdf.ttf in v4. Today is a major holiday in my country and I probably can't do anything (including take a careful look) until later, possibly Monday. https://en.wikipedia.org/wiki/Thanksgiving
:-) Github Tesseract is currently wrong; there is a mismatch between code and font. 
Checking with Ray to see what else might have been incorrectly synchronized. 
This is the required md5sum.

$ md5sum pdf.ttf
e436074b54ed9cc5bf4789f79059b01b pdf.ttf Everything is now correct on 3.05 and 4.x branches. Should fix vertical highlight problems but not horizontal ones in pdf.js / Firefox @jbreiden

https://wiki.mozilla.org/Mortar_Project

>Project Mortar is aiming to explore the possibility to bring PDFium library and the Pepper API based Flash plugin into Firefox.    (this is more of a comment than an issue but more issues can follow and the discussion might be useful; nevertheless, it might be closed after the PR for 1. )
1. At the moment, text2image expects `fc` backend e.g,:
   https://github.com/tesseract-ocr/tesseract/blob/ba2ea39caaa791b5e5f092953057cb8ffb094a82/training/pango_font_info.cpp#L356
   but if pango is compiled with win32 support, you get the win32 font map first

```
#if defined(HAVE_CAIRO_WIN32)
  if (!backend || 0 == strcmp (backend, "win32"))
    return g_object_new (PANGO_TYPE_CAIRO_WIN32_FONT_MAP, NULL);
#endif
#if defined(HAVE_CAIRO_FREETYPE)
  if (!backend || 0 == strcmp (backend, "fc")
           || 0 == strcmp (backend, "fontconfig"))
    return g_object_new (PANGO_TYPE_CAIRO_FC_FONT_MAP, NULL);
#endif 
```

and nasty crashes follow because of the wrong reinterpret cast.

Fast Solution: specify `fc` backend
Solution: a simple patch will follow that fixes the behaviour for, at least, the most important functionality.
1. If fontconfig is linked as dll, putenv does not get propagated to fontconfig
   https://github.com/tesseract-ocr/tesseract/blob/ba2ea39caaa791b5e5f092953057cb8ffb094a82/training/pango_font_info.cpp#L151

Solution: specify it as environmental variable
1. You cannot use disk paths (e.g., c:) in `FONTCONFIG_PATH` because fontconfig strips slashes from path (FcStrCanonAbsoluteFilename) and then uses 

```
GetFullPathNameW (dirname, 0, NULL, NULL)
```

without the slash and that function, interestingly, behaves like this

```
a file name begins with only a disk designator but not the backslash after the colon, it is interpreted as a relative path to the current directory on the drive with the specified letter.
```

Solution: specify a sane directory
 I think this issue should be reopened.
 He fixed number (1) in his list in one place in the code. That piece of code did cause a crash on Windows+VS, MinGW(64) and Mac.
There is another similar piece of code that will probably cause a crash in some situation on all these platforms.
I suggested a solution above, but it useless to test it on Linux.
 Here is the problematic line:
https://github.com/tesseract-ocr/tesseract/blob/182ca5bc1e/training/pango_font_info.cpp#L367

You need to use `text2image` with the flag `only_extract_font_properties` to trigger the function in which this code lives. 
 The dotted\_circle changes in #381 caused problems (in Linux at least).
See: https://github.com/tesseract-ocr/tesseract/blob/5bb97f966885/training/pango_font_info.cpp#L438  @jbreiden @zdenop 

Are there any plans to make a release with the changes for https://wiki.ubuntu.com/YakketyYak/ReleaseSchedule

Maybe 3.04.02 ?

Thanks!
  Hi,

I was able to successfully train tessdata today after many issues and i would like to suggest some changes that can be added to the training guide
1. the command : unicharset_extractor lang.fontname.exp0.box lang.fontname.exp1.box ... didn't work the first tim.Hence, i have to prefix training/ to make it work.
2. the command: mftraining -F font_properties -U unicharset -O lang.unicharset lang.fontname.exp0.tr lang.fontname.exp1.tr ...
   needs to be corrected to add suffix .txt to font_properties to make it work 
3. In the command: training/set_unicharset_properties -U input_unicharset -O output_unicharset --script_dir=training/langdata

The output is generated to output_unicharset.This output_unicharset should be given as input to the mftraining command. i.e instead of -U unicharset one should give -U output_unicharset

Thank you 
 yes in the unicharset extractor command, two files are generated: unicharset and output_unicharset. I tried with output_unicharset and generated eng.unicharset.I copied the all the files to the tessdata folder to recognize text. It is throwing an error stating unichar in normproto is not in unicharset. Then i used the file named  unicharset, it ran without error. So, i understand is output_unicharset and unicharset works with mftraining but the eng.unicharset generated from mftraining does not work with tesseract but unicharset works.
 Those are the first commands which have to be executed before i can use training. I did that and tried and it throwed me error.It is similar to other commands such training/text2image,training/set_unicharset_properties etc, this has to be prefixed with training/
  I try to use tesseract to directly generate pdfs with an ocr'ed text layer. This is one step of several how pdfsandwich creates searchable pdfs.

The result of the tesseract-subprocess, is a pdf with an image and a text layer and is perfectly searchable.
Probably due to the high resolution input the dimensions of the resulting pdf are very large, which pdfsandwich solves by resizing the pages to more reasonable dimensions.

After this resize, when I open this file in, for example, Acrobat Reader DC, all recognized text is separated by extra spaces. So when it used to read 'hello', now it reads 'h e l l o'. So when you search for hello, the text isn't found.
A more technical explanation about this problem is in this thread: http://bugs.ghostscript.com/show_bug.cgi?id=696116

I thought I had a work around for this, by specifying a smaller DW than the default 500:

```
--- api/pdfrenderer.cpp-orig       2016-07-14 14:55:53.299744815 +0200
+++ api/pdfrenderer.cpp    2016-07-14 15:16:23.619204071 +0200
@@ -543,7 +543,7 @@
                "  /FontDescriptor %ld 0 R\n"
                "  /Subtype /CIDFontType2\n"
                "  /Type /Font\n"
-               "  /DW %d\n"
+               "  /DW 250\n"
                ">>\n"
                "endobj\n",
                5L,         // CIDToGIDMap
```

This solves the issue in Acrobat reader.
But when I put this file in Alfresco DMS, which uses [PDFBox](https://pdfbox.apache.org/) 1.8.4, I get the same problem again: I can only find words when I put spaces between the characters.

Setting the DW to a number smaller than 250 compromizes the text in the ocr'ed layer, so that's no option.

Is there any way to change the font type to a proper width, so most pdf-tools can properly read the text?
 Funny thing: Alfresco uses pdf.js as pdf viewer, and the search in pdf,js is actually working. Meaning: pdf.js doesn't put extra spaces between the characters.

2.pdf doesn't show the problems in both pdf.js and when the text is extracted with pdfbox.

So to summarize:
1. By default, there are extra spaces when converting or extracting text from pdfs generated by tesseract.
2. I found a reasonable workaround by decreasing the '/DW' from 500 to 250. Because of this, the text isn't overlayed perfectly, but that is something I can live with for now.
3. After this change, searching and copying/extracting text works for Acrobat Reader DC, ghostscript and pdf.js, but not for pdbfox.

See attached pdf, which displays those problems: [test-out-git.zip](https://github.com/tesseract-ocr/tesseract/files/373160/test-out-git.zip)
 Is there any roadmap for this rewritten (as I understand) pdf generation?
 Note to other people running into this problem with pdfsandwich and ending up here, suspecting Tesseract: **This is actually a problem with Ghostscript.** pdfsandwich converts the images to PPM, hands those to Tesseract and since those files are missing resolution/DPI information, Tesseract outputs a huge PDF (0,9 by 1,20 metres for A4) but with correct text (i.e. without spaces between letters). Then, pdfsandwich runs this PDF through Ghostscript to resize it back to A4 and this step is what actually messes up the words.

The author of pdfsandwich has a [pre-release version 0.1.5](https://sourceforge.net/p/pdfsandwich/bugs/10/#73bd/3894) which now uses TIF images instead of PPM. And those contain resolution information, so the PDF Tesseract spits out is already in the correct format.

(Side note: Tesseract seems to ignore resolution information from PNG files.)
 Back to the spaces thing, I'd appreciate a retest once Tesseract pdf.ttf font matches the 
following checksum. (It currently does not.)

$ md5sum pdf.ttf
e436074b54ed9cc5bf4789f79059b01b pdf.ttf Tried to re-test this, but got the following error when running pdfsandwich + tesseract.
This is with a just-checked out and compiled tesseract-3.05-branch:

```
ParamsModel::Incomplete line 
ParamsModel::Incomplete line 
ParamsModel::Incomplete line 
ParamsModel::Incomplete line 
ParamsModel::Incomplete line ConvNL

ParamsModel::Incomplete line M,V*aramsModel::Incomplete line M8BraramsModel::Incomplete line u?p{}%(H;_9"xuƒøaramsModel::Incomplete line ?C"}‹ãh
f√øB1
ParamsModel::Incomplete line :l\
nN|?]]
ParamsModel::Incomplete line J
ParamsModel::Incomplete line ?d>⁄éW{8
ParamsModel::Incomplete line 9'<J

                                                                                                              ParamsModel::Incomplete line ?

                                                                                                                                              ParamsModel::Incomplete line 
ParamsModel::Incomplete line aramsModel::Incomplete line yf~$G?S<rI#w|&:QParamsModel::Incomplete line ‰¢ø(O`DHYC03E!aramsModel::Incomplete line ?Q!^Q{’ø8atv3DN∆¶?ÀÑ
ParamsModel::Incomplete line 5'                                                                                                                                <"—ø?—ìnv=oaramsModel::Incomplete line c“∫?
ParamsModel::Incomplete line x√øO“≠
ParamsModel::Incomplete line ?,IiTc?kKZfiP{hmu«øqE»ø
ParamsModel::Incomplete line T?ESWJ&ParamsModel::Incomplete line 92|&&
                                                                      Z
ParamsModel::Incomplete line V

ParamsModel::Incomplete line KaramsModel::Incomplete line „ï≥Ibamÿøœ¥»ølm)eParamsModel::Incomplete line U~c[)f!t8M
'?{y+?{?dBi"?--?@N?*+Àπe-I?_+?L?K6{b?x¬û?{
                                <
Pa_a+_M-de+::I+c-+-+e+e +i+e ≈æ"0÷∞|?}+?
31}
ParamsModel::Unknown parameter ne z#@     A|aÍøπx⁄økP‘øB"
ParamsModel::Incomplete line Ij>      Pa_a+_M-de+::I+c-+-+e+e +i+e O
    i“ønP?9|\?
ParamsModel::Incomplete line ‹ø
ParamsModel::Incomplete line aramsModelPa_a+_M-de+::I+c-+-+e+e +i+e ?\√à?>:Unknown parameter ^“ø
Pa_a+_M-de+::I+c-+-+e+e +i+e GU`zC‘øa8a≈ü?S.«øParamsModel::Incomplete line ?Z"
ParamsModel::Incomplete line 

                                        0&=√øR]S‚ΩÖ?+>+*'fŸøE"_-,ƒ≤/FU
                                  ParamsModel::Incomplete line ParamsModel::Incomplete line √ì'C:

                                                                        Pa_a+_M-de+::I+c-+-+e+e +i+e ?c=Q#>~+Õú?F—û?yRFU?T+√ø7P&>:?J?D2\NW?Ÿø+
                            ParamsModel::Unknown parameter S.~"r
ParamsModel::Incomplete line qjÿø
                                                                                                                                   Pa_a+_M-de+::I+c-+-+e+e +i+e @+A}?!bS:?F?„ñæTh?XF08>?LUdH?Vb?-<≈µz0?Vb?+I
Pa_a+_M-de+::I+c-+-+e+e +i+e ?+^–ø4<Y_?[Me}|<?W+A|’ø*+?)_|G7MG5V?3|<?
```

... And this goed on and on I tried that after with this command:  tesseract -l nld+eng pdfsandwich45aaf9.tif -pdf 
Same problem. Same error, I'm afraid.
I just downloaded new nld.trainneddata & eng.traineddata from here: https://github.com/tesseract-ocr/tessdata/
Might that have something to do with it? https://github.com/tesseract-ocr/tessdata/tree/3.04.00 Okay, that was a bit silly on my end.
But after exchanging the traineddata for the 3.04-versions: tesseract and pdfsandwich+tesseract work.
The resulting pdf from both tesseract and pdfsandwich look good, have a text layer and don't have any extra spaces between characters,
So this seems to be solved. Great!  Hello,

tesseract v3.05
ubuntu v15

I've created the .box and .tr files and i am in the step of mftraining. Since the number of  .tr files are large,i performed a ls command,stored the result to a variable and gave the variable to the mftraining command as shown in the screenshot.Then i executed the .sh file in the terminal and i got an error stating illegal malloc request size as shown in the screenshot.

As shown in the screenshot, the error seems to point to the program globalloc.cpp.

Is there a limit on the number of .tr files i can give as input?
![screen shot 2016-07-18 at 9 30 44 pm](https://cloud.githubusercontent.com/assets/18536586/16947703/7725aef4-4da8-11e6-81a3-02fe7ca0afa4.png)
![screen shot 2016-07-18 at 9 28 04 pm](https://cloud.githubusercontent.com/assets/18536586/16947721/888deed6-4da8-11e6-9d3e-c73d575a0cdb.png)

Can some one please help me with this issue?

Thank you 
 see https://groups.google.com/forum/#!msg/tesseract-ocr/eQ6HQdVE7Cw/3o1XPn2Q0CkJ

search forum and google for the error and possible solutions
 The error in the link is different from mine. I've followed the guide and i've given -O eng.unicharset properly. The difference in my case is multiple .tr files
 No actually the problem was with the unicharset file.Because there were number of unicharset files such as unicharset,eng.unicharset,output_unicharset, it was unknown which one to use. Hence, i started again from the first and used the other file and it worked.I was able to create the eng.trainedata successfully.
 The total count of fonts i gave was 70
 I am not sure.This is what i am getting
![screen shot 2016-07-19 at 6 50 37 pm](https://cloud.githubusercontent.com/assets/18536586/16983034/d3fde502-4e6a-11e6-91f6-45ce77b284bd.png)
 No this is from a c++ program. The output from command line is a file named output with a black blank page.So, your saying there is a implicit limit 64 in tesseract is it?
 oh ok thank you 
  I'm getting a segmentation fault nomatter what image I'm trying to read in. Unfortunatly I'm getting very little info on this.
I have tried with multiple images and sizes and is always getting segfaults, on the other hand reading the same image is not a problem.
It is definitely a problem that you are getting so little information on this matter.

I'm running this on a Gentoo Linux kernel 4.1.12

```
gdb /usr/bin/tesseract
(gdb) run eng.Sans-serif.exp0.tif - box.train
Starting program: /usr/bin/tesseract eng.Sans-serif.exp0.tif - box.train
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib64/libthread_db.so.1".
Page 1

Program received signal SIGSEGV, Segmentation fault.
0x00007ffff7862288 in PAGE_RES_IT::start_page(bool) () from /usr/lib64/libtesseract.so.3
(gdb) backtrace
#0  0x00007ffff7862288 in PAGE_RES_IT::start_page(bool) () from /usr/lib64/libtesseract.so.3
#1  0x00007ffff76de3e4 in tesseract::Tesseract::ApplyBoxTraining(STRING const&, PAGE_RES*) () from /usr/lib64/libtesseract.so.3
#2  0x00007ffff76d4b2e in tesseract::TessBaseAPI::Recognize(ETEXT_DESC*) () from /usr/lib64/libtesseract.so.3
#3  0x00007ffff76d4dc2 in tesseract::TessBaseAPI::ProcessPage(Pix*, int, char const*, char const*, int, tesseract::TessResultRenderer*) () from /usr/lib64/libtesseract.so.3
#4  0x00007ffff76d5356 in tesseract::TessBaseAPI::ProcessPagesMultipageTiff(unsigned char const*, unsigned long, char const*, char const*, int, tesseract::TessResultRenderer*, int) ()
   from /usr/lib64/libtesseract.so.3
#5  0x00007ffff76d5846 in tesseract::TessBaseAPI::ProcessPagesInternal(char const*, char const*, int, tesseract::TessResultRenderer*) () from /usr/lib64/libtesseract.so.3
#6  0x00007ffff76d5ca0 in tesseract::TessBaseAPI::ProcessPages(char const*, char const*, int, tesseract::TessResultRenderer*) () from /usr/lib64/libtesseract.so.3
#7  0x000000000040247b in main ()
```
 Still giving me a segfault, I have pulled from got version 3.04.01 and its fixed.
I'm going to commit a new rebuild to gentoo repo. Probably I will make 2 one versioned and one bleeding.
 Sorry for the late reply, been having a lot of work lately getting a system deployed and ready for investors.
I got the tesseract working, I manually compiled the 3.04.01 from git, I see its in the gentoo repo now that nice too.
In the end I found an old bug in our program that had created some bad file ending bytes that did not show up in gedit.
The reason for this is my system actually finds the text on its own first, but the algorithm is very slow, but very strong, and almost always finds the right letters since it's actually a modified robot pathfinder algorithm. So the system is writing the training files for tess and then we use tess for high speed ocr.

Anyways thanks for your help
  pleaseÔºå the digital accuracy rate is okÔºåabout 90%Ôºå how to train can improve the digital accuracy rateÔºà30%ÔºâÔºüthank youÔºÅ
  Hi,
I just found out it can not read from a file having transparent background!
![join](https://cloud.githubusercontent.com/assets/1222935/16919086/f631ea6a-4d25-11e6-99b1-0008f53daadb.jpg)
![join](https://cloud.githubusercontent.com/assets/1222935/16919087/f687b788-4d25-11e6-8351-8d372aea2448.png)

See yourself!
When I use the png with transparent background, it fails.
Using the same JPG file, it runs beautifully.
  I am asking why there is not specific ./configure variable for the location of the language data (i.e. what can be also done with TESSDATA_PREFIX environment variable).

What I suggest is a possibility to hardcode the path the language data while compiling tesseract-
 @zdenop do you mean, TESSDATA_PREFIX follows the optional datadir option ?
 @jbreiden just as an proposal to add a comment in the `configure --help` that datarootdir must contain the /tessdata directory unless this is defined by the TESSDATA_PREFIX

Current --help shows:

```
  --datarootdir=DIR     read-only arch.-independent data root [PREFIX/share]
  --datadir=DIR         read-only architecture-independent data [DATAROOTDIR]
```
 @Wikinaut, Tesseract for Windows uses a different method to find `tessdata`. A fixed TESSDATA_PREFIX would not work on Windows, because there is no fixed installation path.
 @jbreiden wrote
> There is. Debian uses -DTESSDATA_PREFIX=/usr/share/tesseract-ocr/

just for the record:

On my debian 8 system, configured with `./configure --enable-debug` only, tesseract wants to have the language files in 
`/usr/local/share/tessdata`
  Showing them in a window (default) is not acceptable for a console
application like Tesseract which must be able to work in batch mode.

Signed-off-by: Stefan Weil sw@weilnetz.de
 All precompiled TIFF libraries for Windows which I know (e .g. the mingw64-i686-tiff which is part of cygwin) don't define TIF_PLATFORM_CONSOLE.

I don't think that it would be a good idea to require using a special TIFF library for Tesseract.

So yes, in theory your suggestion is an alternative solution, but it is not feasible in practice.
 Some additional notes on the problem which is addressed by this PR:

It looks like many TIFF files (nearly all?) include some vendor specific data which trigger warnings from libtiff, so it is a real and very common problem for Windows users who want to do batch processing. I see these alternatives to handle the problem:
1. Change libtiff. Instead of defaulting to a message window for all warnings, it could do so for GUI applications but use stderr for console applications.
2. Change leptonica. It could offer an interface for setting the handler for warnings, and tesseract could use that interface to set the handler.  Or leptonica could set a reasonable default for GUI / console applications.
3. Change tesseract. That's what I did in my PR.

IMHO in the long run the first alternative would be the best solution, but i see no chance to get it quickly.
 @egorpugin, I added a commit which handles the libtiff dependency, so the code will not break if tiffio.h is unavailable.
 HAVE_TIFFIO_H is set by the current tesseract code ‚Äì both by configure and by cmake (I tested both variants before adding the last commit). 
 Alternative 1 (see my comments from yesterday) is addressed by this libtiff issue: http://bugzilla.maptools.org/show_bug.cgi?id=2571.

I don't expect that a libtiff version with that modification will be available soon.
 This is the only place we use libtiff directly now.

Can we move it to Leptonica?

CC: @Danbloomberg https://github.com/tesseract-ocr/tesseract/blob/21e739ca2e1e/api/tesseractmain.cpp#L41
https://github.com/tesseract-ocr/tesseract/blob/21e739ca2e1e/api/tesseractmain.cpp#L411 stweil commented on Jul 17, 2016

>Change leptonica. It could offer an interface for setting the handler for warnings, and tesseract could use that interface to set the handler. Or leptonica could set a reasonable default for GUI / console applications. Dan recently added a [handler](https://github.com/DanBloomberg/leptonica/commit/d42a51d29eb8bd086ddee83dd12bab95a9b68238) which suppresses TIFF warnings completely. So we have to wait for a new Leptonica release. 1.72.2 is here, so we may able to drop this code soon.

We need to wait to an update of Mingw-w64's Leptonica PKGBUILD.

Egor will probably update cppan very soon.
  tesseract 3.05.00dev
ubuntu v15
Hi,

I am following the training tesseract and i created font_properties text file with input as

BradleyHandBold 0 1 0 0 0

and tried to use it with mftraining and i got the error
no shape table file present
failed to load font_properties from font_properties

Since i am doing the training for english language,i skipped shapeclustering step but i thought i have to go back to that step since mftraining is asking for shape table,i executed that code and it throwed error
failed to load font_properties from font_properties

Can someone please help me with this issue?
Thank you 
 Ok thanks...but i am not getting replies in the google group.This is a simple work of creating a txt file with fontname and 5 spaced 1 or 0. I don't understand why this doesn't work.
  Hi,

I am getting the below error in the tesseract training process

unicharset_extractor:symbol lookup error:unicharset_extractor:undefined symbol: _ZNK10UNICHARSET12save_to_fileEP8_IO_FILE

Can someone please help me with this issue?
 ubuntu version 15
tesseract version 3.03
i just gave the command 

unicharset_extractor eng.Arial.exp0.box 

as mentioned in the guide
 I installed ubuntu only yesterday on my virtual machine just to work on tesseract.I downloaded tesseract from Github and built from source according to the instructions on Github.
 Ok i removed tesseract and rebuilt it from source.It's working now thanks
  When running tesseract as root like this:

`tesseract in.tiff out  -l nld+eng pdf`

The output is a proper and functioning pdf.
When I run the same command as an unprivileged user, like this:

`sudo -u userx tesseract in.tiff out  -l nld+eng pdf`

The output is as follows:

```
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Error in fopenWriteStream: stream not opened
Error in pixWrite: stream not opened
Error in fopenReadStream: file not found
Error in extractG4DataFromFile: stream not opened to file
Error in l_generateG4Data: datacomp not extracted
Error in pixGenerateCIData: g4 data not made
Error in l_generateCIDataForPdf: file in.tiff format is 4; unreadable
Error during processing.
```

The unprivileged user has access to both the input and the output file.
Tesseract is compiled with the following options:

```
sudo -u userx tesseract -v
tesseract 3.05.00dev
 leptonica-1.73
  libjpeg 6b (libjpeg-turbo 1.2.90) : libpng 1.5.13 : libtiff 4.0.3 : zlib 1.2.7
```

The mentioned libs are available on the system.
The user has a normal account with shell: userxx:1001:1001::/home/userx:/bin/bash

When I let tesseract output to txt (so I don't use the 'pdf'-option), there is no error and a txt-file with recognized text is output. This works both for privileged and unprivileged users.
 Yeah, I found that out later as well. But I'm not sure where Tesseract stops and Leptonica begins ;-)

Previously I tried tiff and pbm as sources. Both gave the same errors; the only thing that changed then, was the one-before-last error: tiff gives a 'format is 4'- error while pbm gives a 'format is 11'-error.

Just tried it again: when I create a new source and make the type png it actually does work!
After converting this png to tiff, that does work as well, but converting to pbm (which is used by pdfsandwich, which I want to use) still gives the errors. I can open and view the bpm file without problems, though.

What do you make of this? Is this a problem with Tesseract, Leptonica, with the source file(s) or libraries?
 I'm afraid compiling, installing and then executing as userx doesn't improve the situation.
png and tiff are working, pbm still gives the same error:

```
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Error in fopenWriteStream: stream not opened
Error in pixWrite: stream not opened
Error in fopenReadStream: file not found
Error in extractG4DataFromFile: stream not opened to file
Error in l_generateG4Data: datacomp not extracted
Error in pixGenerateCIData: g4 data not made
Error in l_generateCIDataForPdf: file test-source.pbm format is 11; unreadable
Error during processing.
```

I tried to make sure the pbm was converted right, so I used convert with and without the options '-compress none -depth 2'. Both files give the same problem.

See attached the source files

[test-source.zip](https://github.com/tesseract-ocr/tesseract/files/368750/test-source.zip)
 Converted the png with pngtopam, but this time got a pgm (P5, 8 bits) instead of a pbm (P4, 2 bits).
And that actually does work!
When I use convert instead of pngtopam, to create a pgm, this also works.

So it seems the problem wasn't really with using an unprivileged user, it's a problem with pbm as a source filetype.

Should we probably close this issue and open another about that?
 Okay, fair enough. Let's dig deeper.
This is on Centos 7. I try to use pdfsandwich to OCR existing PDFs, which uses a combination of ImageMagick + unpaper + tesseract + Ghostcript.

As Centos doesn't provide all packages or ones that are recent enough, I compiled unpaper 6.1, leptonica 1.73 and tesseract 3.05dev from source.

What does work:
- png to pdf
- tiff to pdf
- pbm to pdf => only when root, not as a regular, unprivileged user
- pgm to pdf (works from the command line, but unpaper has a problem with this type, but that's another problem)

See attached sourcefiles:

[sources.zip](https://github.com/tesseract-ocr/tesseract/files/369888/sources.zip)
 I can confirm the permissions on /tmp/lept are indeed the problem.
When I do 'chmod 777 /tmp/lept/' and then try again: the tesseract-operation works where it previously didn't.

You probably run into this problem if you run tesseract + leptonica as root first, then as another user.
 Thanks for the temporary patch.
I think this bug can be closed as it's really a leptonica problem, which is handled there.
 yes, I made some changes last week on the leptonica github head:

```
https://github.com/danbloomberg/leptonica
```

which I believe, together with the use of the new function l_makeTempFilename(), will resolve the issue for tesseract.  This function was also implemented for windows; it compiles but has not been tested further.

I haven't yet made a new release of leptonica.  That awaits some testing on windows.
  Hello, would it be possible to know what makes tesseract failing to recognize any characters in those images _(I tried many filters but tesseract fails in every cases)_‚ÄØ? Is‚Äëit because the anti‚Äëaliasing is huge or because there‚Äôs no space between letters‚ÄØ?

![cantal](https://cloud.githubusercontent.com/assets/3824869/16715547/6952422c-46e3-11e6-8ec6-a24a40f4aa45.jpeg)
![ackskin](https://cloud.githubusercontent.com/assets/3824869/16715571/22e588f2-46e4-11e6-8c39-03894e934059.jpeg)

thanks,
 Heh‚Ä¶  those are Captcha images ‚Äì where the text has been distorted so 
that it is cannot be recognized by software like OCR.

The distortions are designed so that only a real human can read the text.

Tesseract will never be able to recognize this correctly.

-= Rich

From: La√´l Cellier [mailto:notifications@github.com] 
Sent: Sunday, July 10, 2016 3:42 PM
To: tesseract-ocr/tesseract tesseract@noreply.github.com
Subject: [tesseract-ocr/tesseract] information about failure to recognize any charaters in those images (#363)

Hello, would it be possible to know what makes tesseract failing to recognize any characters in those images (I tried many filters)‚ÄØ? Is‚Äëit because the anti‚Äëaliasing is huge or because there‚Äôs no space between letters‚ÄØ?

 https://cloud.githubusercontent.com/assets/3824869/16715547/6952422c-46e3-11e6-8ec6-a24a40f4aa45.jpeg 
 https://cloud.githubusercontent.com/assets/3824869/16715571/22e588f2-46e4-11e6-8c39-03894e934059.jpeg 

thanks,

‚Äî
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub https://github.com/tesseract-ocr/tesseract/issues/363 , or mute the thread https://github.com/notifications/unsubscribe/AM6iTCymq3N527JbfOzPgwFyMdTCgAISks5qUUrvgaJpZM4JI5ru .  https://github.com/notifications/beacon/AM6iTEQH4-uJ96SBiXawLyKhlv-kwVCdks5qUUrvgaJpZM4JI5ru.gif 
  [StackOverflow query here](http://stackoverflow.com/questions/38165741/long-running-python-2-7-popen-processes-choice-between-resource-unavailability). Just thought I'd bring it up here as well, in case this is a `tesseract` issue and not a `subprocess.Popen` one.
  Hi there,
As everybody knows by now that the Cube engine is being discontinued and a new OCR engine based on LSTM will be introduced, even-though neither the Cube training tools or it's documentation been published.

One can only see that there is purposely neglect and sabotage to the  "RTL" Right to Left language community.
Hindering the developer community of training the Tesseract on RTL languages.

Issues such as that Tesseract while training considers all the letters and words as a single word, and the training is conducted as training a single word, along with many other issues while training RTL languages have been neglected for years and years, Tesseract showing no interest in solving any of the RTL languages issues.

And yet we ask Ray to publish the documentation and tools to train Cube before it is fully removed from tesseract, or at least assure the community that the RTL languages (Arabic, Hebrew...) will be considered in future version releases of Tesseract and future tools will be published helping the developer community in the training process of RTL languages.

List of some issues in the RTL training:
1) Tesseract consider all words as a single 1 Word while training.
"Generated training data for 1 words"

2) Tesseract fail to add some letters while training.
 "APPLY_BOXES: boxfile line \* : FAILURE! Couldn't find a matching blob"

List of some issues in the RTL recognition:
3) Tesseract combines all the letters together while recognition.
4) Tesseract reverse the direction of the words while recognition.

Suggested solution for some of these problems:
2) The "box file" must be created with a criteria inwhich the boxes for each letter must not conjoin or merge with any other box, meaning that each box is an entity for a single glyph and does not have any part of it enter another box of another glyph.

3) Adding "ara.config" file in the folder you wish to train while modifiying it by setting "tessedit_ocr_engine_mode 0" instead of "1", or removing the entire line.
 but what about solving the issues?
 @christophered No one is hindered or attempting to sabotage RTL languages. Get over yourself. You can use and develop a fork of Tesseract 3.0 until the cows come home if you so choose.

The Arabic trained data is available in the tessdata repo, and if you want to submit patches to improve the LTSM engine for Arabic, you can. If not, that's fine, maybe someone else familiar with both the language and Tesseract will come around. In an open source community, you are not entitled to anything...if you want things fixed, submit patches -- you're already pretty close having already identified some problems. @ctrlcctrlv,

You replied to a 9-months old post.

Since then, LSTM code landed in the repo, and the OP opinion had changed.
https://github.com/tesseract-ocr/tesseract/issues/630#issuecomment-271392038  The attached input file in1.pdf was generated by Tesseract 3.05.00dev. I modified it to extract only the first page using pdftk to reduce the size; results are unaffected by this. 

[in1.pdf](https://github.com/tesseract-ocr/tesseract/files/332804/in1.pdf)
[out1.pdf](https://github.com/tesseract-ocr/tesseract/files/332805/out1.pdf)

(The user who forwarded the file to me confirmed that it can be released publicly.)

The OCR text of in1.pdf begins as follows ‚Äì¬†no problems here:

```
JP. Morgan (Suisse) SA

Account n‚Äú 7973101
Geneva, 3rd June 2016
```

The problem manifests after passing the file through Ghostscript 9.18 to refry the PDF, with no other changes...

```
gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite -o out1.pdf in1.pdf
```

The OCR text is mangled by the insertion of spaces after each recognized letter, and line breaks after certain words (from `pdftotext`), and loss of spaces so that the word boundaries are gone "3rdJune2016". Normally one would pass some other parameters to Ghostscript such as PDF/A conversion, but regardless of parameters the OCR text is mangled.

```
J P .

M o r g a n

A c c o u n t n

( S u i s s e ) S A

7 9 7 3 1 0 1

G e n e v a , 3 r d J u n e 2 0 1 6
```

When viewed in Acrobat XI, every other letter is highlighted. This text is unusable for searching.
![image](https://cloud.githubusercontent.com/assets/1825843/16353613/dddc78ba-3a31-11e6-9aef-baa4c718b1fe.png)

I'd be happy to bring up with the Ghostscript people, but I have feeling that there's something unusual about how Tesseract generates OCR text in PDFs that causes Ghostscript to mishandle them, rather than the converse.

I tried discarding the OCR information, rasterize the PDF as an image, and then running OCR on the image again using tesseract 3.04.01 and the updated pdf.ttf ("sharp2.ttf"). Specifically I used

```
ocrmypdf -f --pdf-renderer tesseract in1.pdf out1_3.04.01.pdf
```

Pinging @jbreiden since you worked with me on the pdf.ttf issues...
 Reported to Ghostscript.
http://bugs.ghostscript.com/show_bug.cgi?id=696874

I tried deskewing the PDF (`ocrmypdf --deskew`) and that fixed the problem. You were able to replicate on an unskewed PDF? That's interesting....
 I found that Acrobat can work with Tesseract-produced PDFs without introducing issues in the OCR text, so it looks like the problem is definitely with Ghostscript/pdfwrite. (I tried using Acrobat for both convert to PDF/A and optimize.)
  Contrary to the comment, the destructor of the base class `GenericVector` calls `GenericVector::clear()`, which actually deletes `data_`, rendering `~DawgPositionVector()` redundant.
 ~~This patch looks wrong to me. @stweil please check it too.~~ @amitdo Why do you think this patch is wrong? @pnordhus

I'm sorry, I thought you were wrong by saying:
>Contrary to the comment, the destructor of the base class GenericVector calls GenericVector::clear(), which actually deletes data_, rendering ~DawgPositionVector() redundant.

But I now realize that you are right :smile:   I just tried to build with Cygwin (64 bit, tesseract + training) and had not problems with the unpatched code.
 On 16/06/2016 18:13, Amit Dovev wrote:

> ```
> I just tried to build with Cygwin (64 bit, tesseract + training) and
> had not problems with the unpatched code.
> ```
> 
> hmmm....
> 
> @matzeri https://github.com/matzeri?

It builds (now, it failed before) but the result is
a hybrid cygwin/windows program not a cygwin program.

Current tesseract binary

$ cygcheck /usr/bin/cygtesseract-3.dll |grep -v '^    '
E:\cygwin64\bin\cygtesseract-3.dll
   E:\cygwin64\bin\cygwin1.dll
   E:\cygwin64\bin\cyglept-5.dll
   E:\cygwin64\bin\cyggcc_s-seh-1.dll
   E:\cygwin64\bin\cygstdc++-6.dll

Building from HEAD without patches

$ cygcheck api/.libs/cygtesseract-3.dll |grep -v '^   '
E:\cyg_pub\devel\tesseract\prove2\tesseract-3.05.00dev_build\api.libs\cygtesseract-3.dll
   E:\cygwin64\bin\cygwin1.dll
   E:\cygwin64\bin\cyglept-5.dll
   E:\cygwin64\bin\cyggcc_s-seh-1.dll
   E:\cygwin64\bin\cygstdc++-6.dll
   C:\Windows\system32\WS2_32.dll
 The build with Cygwin64 fails for the training tools:

```
training/pango_font_info.cpp: In member function 'bool tesseract::PangoFontInfo::ParseFontDescription(const PangoFontDescription*)':
training/pango_font_info.cpp:227:46: error: 'strcasestr' was not declared in this scope
   is_fraktur_ = (strcasestr(family, "Fraktur") != NULL);
```
 Defining `_GNU_SOURCE` fixes the build failure.
 It builds with this additional patch:

```
diff --git a/training/pango_font_info.cpp b/training/pango_font_info.cpp
index e9e6d73..8bc56a0 100644
--- a/training/pango_font_info.cpp
+++ b/training/pango_font_info.cpp
@@ -25,10 +25,13 @@
 #if (defined __MINGW32__) || (defined __CYGWIN__)
 // workaround for stdlib.h and putenv
 #undef __STRICT_ANSI__
-#endif

 #if (defined __MINGW32__)
 #include "strcasestr.h"
+#else
+/* needed for strcasestr in string.h */
+#define _GNU_SOURCE
+#endif
 #endif

 #include <stdlib.h>
```
  https://www.gnu.org/software/libtool/manual/html_node/Link-mode.html

cygwin, mingw, aix are example of platform requiring it. It is not harmful on the other platforms
  Hi guys,

after downloading and manually compiling leptonica and tesseract, I see the following output
when trying to list the version-information of tesseract:

> [con-tom@lapp01awdtst tess_test]$ tesseract -v
> tesseract 3.04.00
>  leptonica-1.72
> 
> [con-tom@lapp01awdtst tess_test]$

Could this be related the following errors which I see when trying to ocr' a given TIFF oder PDF file:

Test 1:

>  tesseract eurotext.pdf test.txt --tessdata-dir /opt/tesseract/tesseract-CuBeInst/tessdata/ -l deu

Generates:

> Tesseract Open Source OCR Engine v3.04.00 with Leptonica
> Error in fopenReadStream: file not found
> %¬¶¬¶¬¶¬¶ in pixRead: image file not found: %PDF-1.6
> %¬¶¬¶¬¶¬¶ cannot be read!
> Error during processing.

Test 2:

>  tesseract eurotext.tif test.txt --tessdata-dir /opt/tesseract/tesseract-CuBeInst/tessdata/ -l deu

Generates 2:

> Tesseract Open Source OCR Engine v3.04.00 with Leptonica
> Error in pixReadMemTiff: function not present`

Can I provide additional information? If yes, please let me know which information is needed.

Thx and best regards,

Tom
  In my OCR situation, Tesseract can not identify rows properly. Please see the attach box image below. (Blue squares are boxes found by Tesseract and red areas are marked as problematic area by me)

![qq 20160615195248](https://cloud.githubusercontent.com/assets/3959938/16078734/118747c2-3333-11e6-890a-5eeaac13f217.png)

It seems that Tesseract is not able to find the baseline correctly when the row spacing is small and the image is a little skew --- two chars in two rows are mistakenly vertically merged. Therefore, the OCR quality in "crowded" space is really poor.

How could I imporve the OCR quality in this situation? Are there any params can be used here?
  When I try to create a box file, from the attached, I get the empty page error blow and the box file is empty. (attached file is zipped since gh doesn't accept tif files.)

I'm guessing that the problem is: https://github.com/tesseract-ocr/tesseract/blob/a3ba11b030345d32829b1e8355afea5419978d82/textord/colfind.cpp#L380

is nailed to `false` and if it were possible to pass a command line arg `single_column` that would fix the problem.

When I finally successfully train something I'll see if I can cook up a pr....

```
$ tesseract t.tiff t batch.nochop makebox
Tesseract Open Source OCR Engine v3.04.01 with Leptonica
Page 1
Empty page!!
Empty page!!
Warning in pixReadMemTiff: tiff page 1 not found
```

```
$ tesseract --version                                                       
tesseract 3.04.01
 leptonica-1.72
  libjpeg 8d : libpng 1.6.21 : libtiff 4.0.6 : zlib 1.2.5

$ convert --version
Version: ImageMagick 6.9.4-8 Q16 x86_64 2016-06-07 http://www.imagemagick.org
Copyright: Copyright (C) 1999-2016 ImageMagick Studio LLC
License: http://www.imagemagick.org/script/license.php
Features: Cipher DPC Modules 
Delegates (built-in): bzlib freetype jng jpeg ltdl lzma png tiff xml zlib
```

[t.tiff.gz](https://github.com/tesseract-ocr/tesseract/files/314634/t.tiff.gz)
  Trying to familiarize with the source code I came across  some discrepancies between the file names in the file header comments and the actual file names. Maybe it's pedantic but I thought having the correct names might facilitate reading the code especially when using printouts.

Some files don't appear to have file header comments and boilerplate license statements as recommended by the [Style guide for Google-originated open-source projects](https://github.com/google/styleguide/blob/gh-pages/cppguide.html#L4537), but I don't feel that I were in a position to supply this information. This pertains to the following files:

```
ccutil\ccutil.cpp
neural_networks\runtime\*.cpp
opencl\openclwrapper.cpp
textord\gap_map.cpp
textord\tospace.cpp
training\commandlineflags.cpp
training\set_unicharset_properties.cpp
viewer\svpaint.cpp
```
 Fixing the wrong or out-dated names is good. I suggest to remove all modifications which are not related to such names and then apply this PR. Even if the PR were applied as it is, it would improve the current situation.
 I think @theraysmith should say if he is OK with these changes.
Ray, also see @stweil https://github.com/tesseract-ocr/tesseract/pull/344#issuecomment-239267937

 @jbreiden said something, but for some reason deleted his comment.  recognition hollow word 
how to configure,like this image:
![image](https://cloud.githubusercontent.com/assets/18211005/15988507/2dfa0660-3086-11e6-9e39-f36645a31fed.png)
  I follow these installation steps:
`./autogen.sh`
`./configure`
`make`
`make install`
I run `tesseract -v`, it works.
 then I run `tesseract pic.gif result`, I got that undefine symbol error. How to fix it?
  For front-ends to tesseract, the deliberate segfault [1] created when tesseract encounters a critical error is rather inconvenient, resp. makes it hard to keep the application alive ([2] works first time but fails to recover a second time). I'd like to propose replacing this with something from which applications can recover more easily, such as `raise(SIGABRT)`.

[1] https://github.com/tesseract-ocr/tesseract/blob/master/ccutil/errcode.cpp#L86
[2] https://github.com/manisandro/gImageReader/blob/0628f8c653169cb6bf53d51c6eb8921fcd5f66cb/gtk/src/Recognizer.cc#L171
 IMHO removing the deliberate null pointer access is a good thing. I cannot see why the SEGV would give a stack trace which is more useful than with ABRT (as it is written in the code comment).
 Because it appears that `abort()` terminates the program even if the signal is caught, as soon as the signal handler exits. See also [1] and example program below.

```
#include <csignal>
#include <iostream>

void signal_handler(int signal) {
        std::cout << "Caught signal " << signal << std::endl;
}

int main() {
        std::signal(SIGABRT, signal_handler);
        std::raise(SIGABRT);
//      abort();
        std::cout << "Program survived" << std::endl;
        return 0;
}
```

(Actually IMO the proper solution would be to allow applications to register an error handler to also make it easier to catch the error messages thrown.)

[1] http://stackoverflow.com/questions/20212927/difference-between-raisesigabrt-and-abort-methods
 Is returning to the program which called `ERRCODE::error` a good idea? Or would a typical signal handler use `longjmp`? In this 2nd case, `abort()` would not abort.

And yes, support for user registered error handlers would be the better solution.
 @theraysmith, what's your take on that?  Placed ambigs problem in the mailing list but got no reply.  This I hope you can help.

Having trained tesseract in the Sinhala language we find we cannot get the 0 option in ambigs to work - no correction occurs even though the word is in the dictionary.

Please advise solution. 
  The other binaries simply didn't create a PDF.
But this one in fact does.

So, there's something wrong with the other VC builds.
Am Sa., Jun. 4, 2016 16:07 schrieb Egor Pugin : Ok, and how should I understand what is incorrect? Where is tesseract output, error message, anything?
 Entered this command, did some preparations and pdf is generated.
 Works for me.
 Latest binaries are here: https://www.dropbox.com/s/pxu2hp6mg1a64zj/tesseract-3.05.00dev-win32-vc19-2016-jun-03.zip?dl=1 (https://www.dropbox.com/s/pxu2hp6mg1a64zj/tesseract-3.05.00dev-win32-vc19-2016-jun-03.zip?dl=1)
 ‚Äî
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub (https://github.com/tesseract-ocr/tesseract/issues/338#issuecomment-223757480), or mute the thread (https://github.com/notifications/unsubscribe/AKYuDajKHXrqZUACFMgTwB900UjD9EKmks5qIYZ_gaJpZM4ItVrv).
 @amitdo: I didn't build any of these myself. I just followed download links and tried the various latest versions I found. Only thing I can say is that the mingW version worked, that the VC version from your link didn't and that the one from the link above works.
  When creating a PDF from a scanned image, the latest dev build creates a space after each character - leaving out the real spaces completely: Tested on windows with the latest dev build.

So scanning this:
**products according to the attached customerlist No.**

becomes this:
**p r o d u c t s a c c o r d i n g t o t h e a t t a c h e d c u s t o m e r l i s t N o .**
 Yes it's the cygwin version. The current VS Version does'nt create PDF versions for me at all.
The problem exists with all samples - no matter what examples I'm using.

Here are some of them:
[sample1.txt](https://github.com/tesseract-ocr/tesseract/files/292199/sample1.txt)
[sample1.pdf](https://github.com/tesseract-ocr/tesseract/files/292200/sample1.pdf)
![sample1](https://cloud.githubusercontent.com/assets/10890765/15690874/fc4826d2-2785-11e6-8997-aa462f27a27e.png)

[sample2.pdf](https://github.com/tesseract-ocr/tesseract/files/292204/sample2.pdf)
![sample2](https://cloud.githubusercontent.com/assets/10890765/15690907/25f617aa-2786-11e6-97a8-6efc9598d5dd.png)
[sample2.txt](https://github.com/tesseract-ocr/tesseract/files/292205/sample2.txt)

[sample3.pdf](https://github.com/tesseract-ocr/tesseract/files/292217/sample3.pdf)
![sample3](https://cloud.githubusercontent.com/assets/10890765/15690995/92605a18-2786-11e6-92cd-81aa75facf90.png)
[sample3.txt](https://github.com/tesseract-ocr/tesseract/files/292218/sample3.txt)
 SumatraPDF. The viewer hasn't had any problems at all so far. And we're using it on several computers for years now including all our customers.
 You're right. I tested it in other PDF readers and there does not seem to be an obvious problem in the PDF itself. I report the problem to the developers of SumatraPDF instead.
 This I'll do :) Thanks
  The option is visible in the 2nd step of the merge process: first you select "Merge pull request", then you can change the kind of merge during the confirmation.
 Yes, it is not so nice.

Squashing can also be done in your local copy of the repository (`git rebase -i`, then update your pull request with `git push -f`). I personally prefer that variant as it avoids the problem with the GitHub user interface.
  This is not strictly necessary, but recommended in the GNU autoconf manual.
No [] was added to arguments like true or false.

Signed-off-by: Stefan Weil sw@weilnetz.de
 This PR addresses issue #100.
 Thanks, I added that one now, too.
  So I just discovered this project, but I plan on implementing this on a very low powered ("performance") microcontroller. 

Is 2 x 300 MHz 32bit with 1 megabyte ROM & 512 kilobyte RAM enough?
Could I squeeze it down even further. I'd need it to be real time too.

Any benchmarking or related projects I could look in to, thank you.
  How to build tesseract and training tools  3.04 in windows with VS2015? I have check leptonica, but it's only libtesseract.lib, I need the training tools too like a setup of Tesseract 3.02
  Location: file `ccutil/strngs.cpp`, method `STRING::add_str_double`

Because of a wrong value for `kMaxDoubleSize`, some small values are truncated by one byte.
Example: `-4.0382147e-006` has 16 bytes including the terminating null byte. But `kMaxDoubleSize` has value 15 and the number is truncated to `-4.0382147e-00`. As result, the number becomes way too large by a factor of 10<sup>6</sup>! (I had found such wrong values in `.tr` files inside the parameters for feature `mf`.)

Also the description for `kMaxDoubleSize` is wrong. The largest length for a formatted number with `%.8g` is `-1.2345678e-999<nul>`. The precision of format specifier `g` specifies the maximum number of significant digits. The length including the terminating null byte is 16 (eight digits, two signs, decimal marker, `e`, three exponent digits, null byte).
  Yes, the code is not consistent ‚Äì sometimes it exits with 0, sometimes it exits with 1.

IMHO, missing arguments are an error condition, so a program should not exit with 0 (which means no error) in that case. 
 I personally use command lines with several arguments and an added `--help` quite often. This pattern is usually supported well. Examples: `ls -l --help`, cp -R --help`. 
  Is there any - approximate - expectation, when will the new LSTM backend for tesseract (presented [here](http://www.primaresearch.org/das2016/assets/DAS2016_Tutorial_Tesseract.pdf) )  be merged into master ? (or at least pushed public)

Regards 
  ![sc](https://cloud.githubusercontent.com/assets/19493015/15432773/dc38d8ca-1eaf-11e6-9ba1-41c3f5a34723.png)

OCR extraction result:
Nam: an 32:
m j..
L1..,.,.,...¬ª1s3mm ssa
L1.:...:.m.,...¬ª1s3;¬ªz:zza 5533
L1c.(..,.a.5.,...¬ª.s3;¬ªz:zzs msa
E| luginmjpg 52 J15 B
¬ß  lugIlI7l_Ihum   >s.plvg 1:; ma
L1g.....gs.,...¬ª1s3mzzs sm
mgms
Oulvzr
upznlxegksk
upznlxegksk
upznlxegksk
upznlxegksk
upznlxegksk
upznlxegksk
upznlxegksk
  image: [eurotext.tif](https://github.com/tesseract-ocr/tesseract/blob/master/testing/eurotext.tif)

```
reubano@tokpro [~]‚ö° convert eurotext.tif -rotate 3 +repage eurotext_03.tif
reubano@tokpro [~]‚ö° convert eurotext.tif -rotate 5 +repage eurotext_05.tif
```

`bug.py`

``` python
#!/usr/bin/python
# -*- coding: utf-8 -*-

from __future__ import print_function, division

from os import path as p, environ
from ctypes import (
    CDLL, POINTER, Structure, c_char_p, c_bool, c_int, c_float, byref)

from ctypes.util import find_library

LIBTESS = find_library('libtesseract.dylib')
LIBLEPT = find_library('liblept.dylib')
TESSDATA_PREFIX = environ.get('TESSDATA_PREFIX', '/opt/local/share')


class TessBaseAPI(Structure):
    pass


class Pix(Structure):
    pass


class TessPageIterator(Structure):
    pass


def create_tess_api(prefix=TESSDATA_PREFIX, lang='eng'):
    tesseract = CDLL(LIBTESS)
    leptonica = CDLL(LIBLEPT)
    base_api = POINTER(TessBaseAPI)
    argtypes = [base_api, c_char_p, c_char_p]

    tesseract.TessBaseAPICreate.restype = base_api
    tesseract.TessBaseAPIInit3.argtypes = argtypes
    tesseract.TessBaseAPIInit3.restype = c_bool
    tesseract.TessBaseAPISetImage2.restype = None
    tesseract.TessBaseAPISetImage2.argtypes = [base_api, POINTER(Pix)]
    tesseract.TessBaseAPIAnalyseLayout.argtypes = [base_api]
    tesseract.TessBaseAPIAnalyseLayout.restype = POINTER(TessPageIterator)
    tesseract.TessPageIteratorOrientation.argtypes = [
        POINTER(TessPageIterator), POINTER(c_int), POINTER(c_int),
        POINTER(c_int), POINTER(c_float)]

    tesseract.TessPageIteratorOrientation.restype = None

    api = tesseract.TessBaseAPICreate()
    tesseract.TessBaseAPIInit3(api, prefix, lang)

    leptonica.pixRead.argtypes = [c_char_p]
    leptonica.pixRead.restype = POINTER(Pix)
    return tesseract, leptonica, api

def get_orientation(tesseract, leptonica, api, path, mode=1):
    tesseract.TessBaseAPISetPageSegMode(api, mode)
    pix = leptonica.pixRead(path)
    tesseract.TessBaseAPISetImage2(api, pix)
    it = tesseract.TessBaseAPIAnalyseLayout(api)

    if it:
        orientation, direction, line_order = c_int(), c_int(), c_int()
        skew = c_float()

        tesseract.TessPageIteratorOrientation(
            it, byref(orientation), byref(direction), byref(line_order),
            byref(skew))

        print('%s: %s' % (path, orientation.value))

if __name__ == '__main__':
    for path in ['eurotext.tif', 'eurotext_03.tif', 'eurotext_05.tif']:
        tesseract, leptonica, api = create_tess_api()
        orientation = get_orientation(tesseract, leptonica, api, path)
```

``` bash
reubano@tokpro [~/Documents/Projects/tesseract]‚ö° python bug.py 
eurotext.tif: 0
eurotext_03.tif: 0
Empty page!!
```

CR: https://github.com/sirfz/tesserocr/issues/5
 It would be helpful to have a `CONTRIBUTING` file with that information so that github will [show it on the issues page](https://help.github.com/articles/setting-guidelines-for-repository-contributors/).
 Thanks to [pyocr](https://github.com/jflesch/pyocr/blob/master/src/pyocr/libtesseract/tesseract_raw.py) I figured it out!

``` python
# ... /snip
# https://github.com/jflesch/pyocr/blob/master/src/pyocr/libtesseract/tesseract_raw.py
class OSResults(Structure):
    _fields_ = [
        ('orientations', c_float * 4),
        ('scripts_na', c_float * 4 * (116 + 1 + 2 + 1)),
        ('unicharset', c_void_p),
        ('best_orientation_id', c_int),
        ('best_script_id', c_int),
        ('best_sconfidence', c_float),
        ('best_oconfidence', c_float),
        ('padding', c_char_p * 512),
    ]

# ... /snip

def create_tess_api(prefix=TESSDATA_PREFIX, lang='eng'):
    # ... /snip
    tesseract.TessBaseAPIDetectOS.argtypes = [base_api, POINTER(OSResults)]
    tesseract.TessBaseAPIDetectOS.restype = c_bool
    # ... /snip

def get_orientation(tesseract, leptonica, api, path, mode=0):
    tesseract.TessBaseAPISetPageSegMode(api, mode)
    pix = leptonica.pixRead(path)
    tesseract.TessBaseAPISetImage2(api, pix)
    osr = OSResults()
    it = tesseract.TessBaseAPIDetectOS(api, byref(osr))

    if it and osr:
        orientation, direction, line_order = c_int(), c_int(), c_int()
        skew = c_float()

        tesseract.TessPageIteratorOrientation(
            it, byref(orientation), byref(direction), byref(line_order),
            byref(skew))

        print('%s: %s' % (path, osr.best_orientation_id))
        print('confidence: %s' % osr.best_oconfidence)
```
  This is command i tried:
`tesseract photo.jpeg out -l ara`
This is the error

```
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
Cube ERROR (CubeRecoContext::Load): unable to read cube language model params from /opt/local/share/tessdata/ara.cube.lm
Cube ERROR (CubeRecoContext::Create): unable to init CubeRecoContext object
init_cube_objects(false, &tessdata_manager):Error:Assert failed:in file tessedit.cpp, line 205
```

Obviously i installed tesseract and the arabic language pack.
Thanks
 oops.
This is what i get:
`Error opening data file /opt/local/share/tessdata/eng.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your "tessdata" directory.
Failed loading language 'eng'
Tesseract couldn't load any languages!
Could not initialize tesseract.`
Any idea why? I ran `sudo port install tesseract-ara` on my mac
 I installed english too.
now runing:`tesseract --list-langs` return arabic and english.
still same error when runing `tesseract photo.jpeg out -l ara`
Any help?
 Hey, its now running but not working :(
This is output:
`Warning in pixReadMemJpeg: work-around: writing to a temp file`
and i get an empty out.txt file
 I guess,
thanks
  Tesseract works fine with the original eng.traineddata but when i use my own it segfaults when running the standard:

```
tesseract test.jpg test.txt
```

I have attached my training data if it helps:
[ali_traineddata_files.zip](https://github.com/tesseract-ocr/tesseract/files/268691/ali_traineddata_files.zip)

Here is the output from llvmdb:

``` bash
Tesseract Open Source OCR Engine v3.04.01 with Leptonica
Warning in pixReadMemJpeg: work-around: writing to a temp file
Process 57115 stopped
* thread #1: tid = 0x2101d5, 0x00000001000e94a9 libtesseract.3.dylib`tesseract::Classify::ComputeCharNormArrays(FEATURE_STRUCT*, INT_TEMPLATES_STRUCT*, unsigned char*, unsigned char*) + 161, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x8)
    frame #0: 0x00000001000e94a9 libtesseract.3.dylib`tesseract::Classify::ComputeCharNormArrays(FEATURE_STRUCT*, INT_TEMPLATES_STRUCT*, unsigned char*, unsigned char*) + 161
libtesseract.3.dylib`tesseract::Classify::ComputeCharNormArrays:
->  0x1000e94a9 <+161>: movl   0x8(%r9), %r10d
    0x1000e94ad <+165>: testl  %r10d, %r10d
    0x1000e94b0 <+168>: jle    0x1000e94eb               ; <+227>
    0x1000e94b2 <+170>: movb   (%r15,%r14), %cl
```

Many thanks :)
 Thanks for your replies but after reading those and trying from scratch again, it still throws this segfault, is their another way i can debug it?
  Hello,

I am trying to train Tesseract but unfortunately, my training is failing.

I was trying to train Tesseract but I  encountered a problem when I was about to shapecluster the training data.

**Here is what I got :**

`Reading ./Data/eng.fonf.exp365.tr ...`
`Bad properties for index 3, char I: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 4, char c: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 5, char a: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 6, char n: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 7, char t: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 8, char d: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 9, char o: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 10, char i: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 11, char .: 0,255 0,255 0,0 0,0 0,0`
`Building master shape table`
`Computing shape distances...`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances...`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances...`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances...`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances...`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0 1 2 3 4 5 6 7 8`
`Stopped with 0 merged, min dist 0.280000`
`Master shape_table:Number of shapes = 9 max unichars = 1 number with multiple unichars = 0`

Then I searched online and found that shapeclustering is not good for anything but Indic language so I skipped it and tried mftraining and **here is what I got** :
`Warning: No shape table file present: shapetable`
`Reading ./Data/eng.fonf.exp365.tr ...`
`Flat shape table summary: Number of shapes = 9 max unichars = 1 number with multiple unichars = 0`
`Warning: no protos/configs for Joined in CreateIntTemplates()`
`Warning: no protos/configs for |Broken|0|1 in CreateIntTemplates()`
`Done!`

I am trying to understand why or how and now that I have researched it for 1 week I think its the unicharset_extractor.

I went into the code of Tesseract and place some _print_ just after and just before the **_if_** checking if wctype is in the system and then went ahead and compiled it. When I executed it, all the prints before were there, but all the ones after were not there... So I think my system does not support wctype, but I am working on Ubuntu 15.10 on virtualbox so I don't understand because it says on the wiki that wctype is not supported is not supported only on older systems..... I made someone else try on another machine, but he had the same error.

[**_Here is a sample of my training data_**](https://drive.google.com/open?id=0B3pGC0Nn9nqBcjhQQXl4MVY2WGc)
 @amitdo no worries. :+1: 
 @amitdo Okay, I read it! Thank you very much, I will test the solution and come back to you as soon as I can and close this issue if it solved it or is the same thing as the other issue. Just going to keep it open for now, in case of emergency! :P 
 Okay, it did not bug... I think this time....

Here is what I did! 
My data seams nice now, not sure though....
Maybe its super bad!!! D:

Anyway, here is what I did and the result just in case someone wants to check it out one day... O_O

`$ set_unicharset_properties --F font_properties --script_dir=Latin.unicharset -U unicharset -O output_unicharsetLoaded`

```
Loaded unicharset of size 12 from file unicharset
Setting unichar properties
Other case C of c is not in unicharset
Other case A of a is not in unicharset
Other case N of n is not in unicharset
Other case T of t is not in unicharset
Other case D of d is not in unicharset
Other case O of o is not in unicharset
Warning: properties incomplete for index 3 = I
Warning: properties incomplete for index 4 = c
Warning: properties incomplete for index 5 = a
Warning: properties incomplete for index 6 = n
Warning: properties incomplete for index 7 = t
Warning: properties incomplete for index 8 = d
Warning: properties incomplete for index 9 = o
Warning: properties incomplete for index 10 = i
Warning: properties incomplete for index 11 = .
Writing unicharset to file output_unicharsetLoad
```

`$ mftraining -F font_properties -U output_unicharsetLoaded -O eng.unicharset`

```
./Data/eng.fonf.exp365.tr
Warning: No shape table file present: shapetable
Reading ./Data/eng.fonf.exp365.tr ...
Flat shape table summary: Number of shapes = 9 max unichars = 1 number with multiple unichars = 0
Warning: no protos/configs for Joined in CreateIntTemplates()
Warning: no protos/configs for |Broken|0|1 in CreateIntTemplates()
Done!
```

`$ cntraining ./Data/eng.fonf.exp365.tr`

```
Reading ./Data/eng.fonf.exp365.tr ...
Clustering ...

Writing normproto ...
```
 @amitdo YES!! IT WORKED! MONTHS OF STUDYING AND WORKING HARD, AND NOW ITS WORKING! IF I COULD KISS YOU, I WOULD!!! THANK YOU VERY VERY MUCH!!!
 @amitdo lol, sorry, it was not only this problem. But I'm a student in an internship and this was very hard because I had never done c++ or any knowledge of AI or deep learning. Now this was the last step before I can get the result of all the hard work I did to train Tesseract and get results.
  How should I select an image and convert it into text?
  Hi,

I get some strange result when I try to train Tesseract.

Some part are very improved comparing to the default eng.tessdata, when some part are strangely added or modified, while the image quality is very good (24 become eat ???; uppercase letter become lowercase; some words are cut in two words; etc)

I think it may be cause by unicharset.

Indeed, when I try to generate a unicharset file with the following command :
`unicharset_extractor eng.palladio-regular.exp8.box`
I get an incomplete file. Here the result :

```
    115
    NULL 0 NULL 0
    Joined 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # Joined [4a 6f 69 6e 65 64 ]
    |Broken|0|1 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # Broken
    d 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # d [64 ]
    i 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # i [69 ]
    f 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # f [66 ]
    e 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # e [65 ]
    r 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # r [72 ]
    n 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # n [6e ]
    t 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # t [74 ]
    N 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # N [4e ]
    w 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # w [77 ]
    A 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # A [41 ]
    c 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # c [63 ]
    l 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # l [6c ]
    s 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # s [73 ]
    p 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # p [70 ]
    a 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # a [61 ]
    g 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # g [67 ]
    2 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 2 [32 ]
    3 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 3 [33 ]
    T 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # T [54 ]
    o 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # o [6f ]
    S 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # S [53 ]
    v 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # v [76 ]
    ~ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ~ [7e ]
    D 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # D [44 ]
    C 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # C [43 ]
    h 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # h [68 ]
    ' 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ' [27 ]
    7 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 7 [37 ]
    ¬´ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # ¬´ [ab ]
    : 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # : [3a ]
    #0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # # [23 ]
    1 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 1 [31 ]
    Z 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # Z [5a ]
    _ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # _ [5f ]
    M 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # M [4d ]
    u 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # u [75 ]
    m 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # m [6d ]
    P 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # P [50 ]
    H 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # H [48 ]
    O 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # O [4f ]
    ( 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ( [28 ]
    ) 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ) [29 ]
    q 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # q [71 ]
    y 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # y [79 ]
    | 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # | [7c ]
    U 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # U [55 ]
    0 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 0 [30 ]
    % 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # % [25 ]
    x 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # x [78 ]
    F 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # F [46 ]
    R 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # R [52 ]
    I 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # I [49 ]
    , 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # , [2c ]
    ! 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ! [21 ]
    E 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # E [45 ]
    b 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # b [62 ]
    \ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # \ [5c ]
    8 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 8 [38 ]
    ? 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ? [3f ]
    & 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # & [26 ]
    ; 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ; [3b ]
    B 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # B [42 ]
    k 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # k [6b ]
    - 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # - [2d ]
    > 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # > [3e ]
    L 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # L [4c ]
    . 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # . [2e ]
    ‚Äî 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # ‚Äî [2014 ]
    4 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 4 [34 ]
    ¬ª 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # ¬ª [bb ]
    ‚Ç¨ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # ‚Ç¨ [20ac ]
    W 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # W [57 ]
    J 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # J [4a ]
    √© 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # √© [e9 ]
    9 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 9 [39 ]
    ¬Æ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # ¬Æ [ae ]
    $ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # $ [24 ]
    5 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 5 [35 ]
    } 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # } [7d ]
    [ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # [ [5b ]
    Y 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # Y [59 ]
    ¬ß 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # ¬ß [a7 ]
    " 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # " [22 ]
    { 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # { [7b ]
    ¬¢ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # ¬¢ [a2 ]
    / 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # / [2f ]
    Q 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # Q [51 ]
    6 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 6 [36 ]
    G 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # G [47 ]
    ‚Äù 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # ‚Äù [201d ]
    ¬∞ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # ¬∞ [b0 ]
    K 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # K [4b ]
    ¬• 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # ¬• [a5 ]
    V 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # V [56 ]
    ¬© 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # ¬© [a9 ]
    z 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # z [7a ]
    + 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # + [2b ]
    = 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # = [3d ]
    ¬£ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # ¬£ [a3 ]
    < 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # < [3c ]
    ‚Äô 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # ‚Äô [2019 ]
    ‚Äò 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # ‚Äò [2018 ]
    j 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # j [6a ]
    X 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # X [58 ]
    ] 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ] [5d ]
    * 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # * [2a ]
    ‚Äú 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # ‚Äú [201c ]
    @ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # @ [40 ]
    ‚Ä¢ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # ‚Ä¢ [2022 ]
    ‚Äì 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # ‚Äì [2013 ]
    ‚Ä¶ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # ‚Ä¶ [2026 ]
    ^ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ^ [5e ]
```

When I try to fix it with with set_unicharset_properties:
`set_unicharset_properties --F font_properties -U unicharset -O output_unicharset --script_dir=/`

I get these warnings :

```
    Loaded unicharset of size 115 from file unicharset
    Setting unichar properties
    Other case √â of √© is not in unicharset
    Warning: properties incomplete for index 3 = d
    Warning: properties incomplete for index 4 = i
    Warning: properties incomplete for index 5 = f
    Warning: properties incomplete for index 6 = e
    Warning: properties incomplete for index 7 = r
    Warning: properties incomplete for index 8 = n
    Warning: properties incomplete for index 9 = t
    Warning: properties incomplete for index 10 = N
    Warning: properties incomplete for index 11 = w
    Warning: properties incomplete for index 12 = A
    Warning: properties incomplete for index 13 = c
    Warning: properties incomplete for index 14 = l
    Warning: properties incomplete for index 15 = s
    Warning: properties incomplete for index 16 = p
    Warning: properties incomplete for index 17 = a
    Warning: properties incomplete for index 18 = g
    Warning: properties incomplete for index 19 = 2
    Warning: properties incomplete for index 20 = 3
    Warning: properties incomplete for index 21 = T
    Warning: properties incomplete for index 22 = o
    Warning: properties incomplete for index 23 = S
    Warning: properties incomplete for index 24 = v
    Warning: properties incomplete for index 25 = ~
    Warning: properties incomplete for index 26 = D
    Warning: properties incomplete for index 27 = C
    Warning: properties incomplete for index 28 = h
    Warning: properties incomplete for index 29 = '
    Warning: properties incomplete for index 30 = 7
    Warning: properties incomplete for index 31 = ¬´
    Warning: properties incomplete for index 32 = :
    Warning: properties incomplete for index 33 = #
    Warning: properties incomplete for index 34 = 1
    Warning: properties incomplete for index 35 = Z
    Warning: properties incomplete for index 36 = _
    Warning: properties incomplete for index 37 = M
    Warning: properties incomplete for index 38 = u
    Warning: properties incomplete for index 39 = m
    Warning: properties incomplete for index 40 = P
    Warning: properties incomplete for index 41 = H
    Warning: properties incomplete for index 42 = O
    Warning: properties incomplete for index 43 = (
    Warning: properties incomplete for index 44 = )
    Warning: properties incomplete for index 45 = q
    Warning: properties incomplete for index 46 = y
    Warning: properties incomplete for index 47 = |
    Warning: properties incomplete for index 48 = U
    Warning: properties incomplete for index 49 = 0
    Warning: properties incomplete for index 50 = %
    Warning: properties incomplete for index 51 = x
    Warning: properties incomplete for index 52 = F
    Warning: properties incomplete for index 53 = R
    Warning: properties incomplete for index 54 = I
    Warning: properties incomplete for index 55 = ,
    Warning: properties incomplete for index 56 = !
    Warning: properties incomplete for index 57 = E
    Warning: properties incomplete for index 58 = b
    Warning: properties incomplete for index 59 = \
    Warning: properties incomplete for index 60 = 8
    Warning: properties incomplete for index 61 = ?
    Warning: properties incomplete for index 62 = &
    Warning: properties incomplete for index 63 = ;
    Warning: properties incomplete for index 64 = B
    Warning: properties incomplete for index 65 = k
    Warning: properties incomplete for index 66 = -
    Warning: properties incomplete for index 67 = >
    Warning: properties incomplete for index 68 = L
    Warning: properties incomplete for index 69 = .
    Warning: properties incomplete for index 70 = ‚Äî
    Warning: properties incomplete for index 71 = 4
    Warning: properties incomplete for index 72 = ¬ª
    Warning: properties incomplete for index 73 = ‚Ç¨
    Warning: properties incomplete for index 74 = W
    Warning: properties incomplete for index 75 = J
    Warning: properties incomplete for index 76 = √©
    Warning: properties incomplete for index 77 = 9
    Warning: properties incomplete for index 78 = ¬Æ
    Warning: properties incomplete for index 79 = $
    Warning: properties incomplete for index 80 = 5
    Warning: properties incomplete for index 81 = }
    Warning: properties incomplete for index 82 = [
    Warning: properties incomplete for index 83 = Y
    Warning: properties incomplete for index 84 = ¬ß
    Warning: properties incomplete for index 85 = "
    Warning: properties incomplete for index 86 = {
    Warning: properties incomplete for index 87 = ¬¢
    Warning: properties incomplete for index 88 = /
    Warning: properties incomplete for index 89 = Q
    Warning: properties incomplete for index 90 = 6
    Warning: properties incomplete for index 91 = G
    Warning: properties incomplete for index 92 = ‚Äù
    Warning: properties incomplete for index 93 = ¬∞
    Warning: properties incomplete for index 94 = K
    Warning: properties incomplete for index 95 = ¬•
    Warning: properties incomplete for index 96 = V
    Warning: properties incomplete for index 97 = ¬©
    Warning: properties incomplete for index 98 = z
    Warning: properties incomplete for index 99 = +
    Warning: properties incomplete for index 100 = =
    Warning: properties incomplete for index 101 = ¬£
    Warning: properties incomplete for index 102 = <
    Warning: properties incomplete for index 103 = ‚Äô
    Warning: properties incomplete for index 104 = ‚Äò
    Warning: properties incomplete for index 105 = j
    Warning: properties incomplete for index 106 = X
    Warning: properties incomplete for index 107 = ]
    Warning: properties incomplete for index 108 = *
    Warning: properties incomplete for index 109 = ‚Äú
    Warning: properties incomplete for index 110 = @
    Warning: properties incomplete for index 111 = ‚Ä¢
    Warning: properties incomplete for index 112 = ‚Äì
    Warning: properties incomplete for index 113 = ‚Ä¶
    Warning: properties incomplete for index 114 = ^
```

And this incomplete file :

```
    115
    NULL 0 Common 0
    Joined 7 0,255,0,255,0,0,0,0,0,0 Latin 1 0 1 Joined # Joined [4a 6f 69 6e 65 64 ]a
    |Broken|0|1 f 0,255,0,255,0,0,0,0,0,0 Common 2 10 2 |Broken|0|1 # Broken
    d 3 0,255,0,255,0,0,0,0,0,0 Latin 26 0 3 d  # d [64 ]a
    i 3 0,255,0,255,0,0,0,0,0,0 Latin 54 0 4 i  # i [69 ]a
    f 3 0,255,0,255,0,0,0,0,0,0 Latin 52 0 5 f  # f [66 ]a
    e 3 0,255,0,255,0,0,0,0,0,0 Latin 57 0 6 e  # e [65 ]a
    r 3 0,255,0,255,0,0,0,0,0,0 Latin 53 0 7 r  # r [72 ]a
    n 3 0,255,0,255,0,0,0,0,0,0 Latin 10 0 8 n  # n [6e ]a
    t 3 0,255,0,255,0,0,0,0,0,0 Latin 21 0 9 t  # t [74 ]a
    N 5 0,255,0,255,0,0,0,0,0,0 Latin 8 0 10 N  # N [4e ]A
    w 3 0,255,0,255,0,0,0,0,0,0 Latin 74 0 11 w # w [77 ]a
    A 5 0,255,0,255,0,0,0,0,0,0 Latin 17 0 12 A # A [41 ]A
    c 3 0,255,0,255,0,0,0,0,0,0 Latin 27 0 13 c # c [63 ]a
    l 3 0,255,0,255,0,0,0,0,0,0 Latin 68 0 14 l # l [6c ]a
    s 3 0,255,0,255,0,0,0,0,0,0 Latin 23 0 15 s # s [73 ]a
    p 3 0,255,0,255,0,0,0,0,0,0 Latin 40 0 16 p # p [70 ]a
    a 3 0,255,0,255,0,0,0,0,0,0 Latin 12 0 17 a # a [61 ]a
    g 3 0,255,0,255,0,0,0,0,0,0 Latin 91 0 18 g # g [67 ]a
    2 8 0,255,0,255,0,0,0,0,0,0 Common 19 2 19 2    # 2 [32 ]0
    3 8 0,255,0,255,0,0,0,0,0,0 Common 20 2 20 3    # 3 [33 ]0
    T 5 0,255,0,255,0,0,0,0,0,0 Latin 9 0 21 T  # T [54 ]A
    o 3 0,255,0,255,0,0,0,0,0,0 Latin 42 0 22 o # o [6f ]a
    S 5 0,255,0,255,0,0,0,0,0,0 Latin 15 0 23 S # S [53 ]A
    v 3 0,255,0,255,0,0,0,0,0,0 Latin 96 0 24 v # v [76 ]a
    ~ 0 0,255,0,255,0,0,0,0,0,0 Common 25 10 25 ~   # ~ [7e ]
    D 5 0,255,0,255,0,0,0,0,0,0 Latin 3 0 26 D  # D [44 ]A
    C 5 0,255,0,255,0,0,0,0,0,0 Latin 13 0 27 C # C [43 ]A
    h 3 0,255,0,255,0,0,0,0,0,0 Latin 41 0 28 h # h [68 ]a
    ' 10 0,255,0,255,0,0,0,0,0,0 Common 29 10 29 '  # ' [27 ]p
    7 8 0,255,0,255,0,0,0,0,0,0 Common 30 2 30 7    # 7 [37 ]0
    ¬´ 10 0,255,0,255,0,0,0,0,0,0 Common 31 10 72 ¬´    # ¬´ [ab ]p
    : 10 0,255,0,255,0,0,0,0,0,0 Common 32 6 32 :   # : [3a ]p
    #10 0,255,0,255,0,0,0,0,0,0 Common 33 4 33 #   # # [23 ]p
    1 8 0,255,0,255,0,0,0,0,0,0 Common 34 2 34 1    # 1 [31 ]0
    Z 5 0,255,0,255,0,0,0,0,0,0 Latin 98 0 35 Z # Z [5a ]A
    _ 10 0,255,0,255,0,0,0,0,0,0 Common 36 10 36 _  # _ [5f ]p
    M 5 0,255,0,255,0,0,0,0,0,0 Latin 39 0 37 M # M [4d ]A
    u 3 0,255,0,255,0,0,0,0,0,0 Latin 48 0 38 u # u [75 ]a
    m 3 0,255,0,255,0,0,0,0,0,0 Latin 37 0 39 m # m [6d ]a
    P 5 0,255,0,255,0,0,0,0,0,0 Latin 16 0 40 P # P [50 ]A
    H 5 0,255,0,255,0,0,0,0,0,0 Latin 28 0 41 H # H [48 ]A
    O 5 0,255,0,255,0,0,0,0,0,0 Latin 22 0 42 O # O [4f ]A
    ( 10 0,255,0,255,0,0,0,0,0,0 Common 43 10 44 (  # ( [28 ]p
    ) 10 0,255,0,255,0,0,0,0,0,0 Common 44 10 43 )  # ) [29 ]p
    q 3 0,255,0,255,0,0,0,0,0,0 Latin 89 0 45 q # q [71 ]a
    y 3 0,255,0,255,0,0,0,0,0,0 Latin 83 0 46 y # y [79 ]a
    | 0 0,255,0,255,0,0,0,0,0,0 Common 47 10 47 |   # | [7c ]
    U 5 0,255,0,255,0,0,0,0,0,0 Latin 38 0 48 U # U [55 ]A
    0 8 0,255,0,255,0,0,0,0,0,0 Common 49 2 49 0    # 0 [30 ]0
    % 10 0,255,0,255,0,0,0,0,0,0 Common 50 4 50 %   # % [25 ]p
    x 3 0,255,0,255,0,0,0,0,0,0 Latin 106 0 51 x    # x [78 ]a
    F 5 0,255,0,255,0,0,0,0,0,0 Latin 5 0 52 F  # F [46 ]A
    R 5 0,255,0,255,0,0,0,0,0,0 Latin 7 0 53 R  # R [52 ]A
    I 5 0,255,0,255,0,0,0,0,0,0 Latin 4 0 54 I  # I [49 ]A
    , 10 0,255,0,255,0,0,0,0,0,0 Common 55 6 55 ,   # , [2c ]p
    ! 10 0,255,0,255,0,0,0,0,0,0 Common 56 10 56 !  # ! [21 ]p
    E 5 0,255,0,255,0,0,0,0,0,0 Latin 6 0 57 E  # E [45 ]A
    b 3 0,255,0,255,0,0,0,0,0,0 Latin 64 0 58 b # b [62 ]a
    \ 10 0,255,0,255,0,0,0,0,0,0 Common 59 10 59 \  # \ [5c ]p
    8 8 0,255,0,255,0,0,0,0,0,0 Common 60 2 60 8    # 8 [38 ]0
    ? 10 0,255,0,255,0,0,0,0,0,0 Common 61 10 61 ?  # ? [3f ]p
    & 10 0,255,0,255,0,0,0,0,0,0 Common 62 10 62 &  # & [26 ]p
    ; 10 0,255,0,255,0,0,0,0,0,0 Common 63 10 63 ;  # ; [3b ]p
    B 5 0,255,0,255,0,0,0,0,0,0 Latin 58 0 64 B # B [42 ]A
    k 3 0,255,0,255,0,0,0,0,0,0 Latin 94 0 65 k # k [6b ]a
    - 10 0,255,0,255,0,0,0,0,0,0 Common 66 3 66 -   # - [2d ]p
    > 0 0,255,0,255,0,0,0,0,0,0 Common 67 10 102 >  # > [3e ]
    L 5 0,255,0,255,0,0,0,0,0,0 Latin 14 0 68 L # L [4c ]A
    . 10 0,255,0,255,0,0,0,0,0,0 Common 69 6 69 .   # . [2e ]p
    ‚Äî 10 0,255,0,255,0,0,0,0,0,0 Common 70 10 70 -    # ‚Äî [2014 ]p
    4 8 0,255,0,255,0,0,0,0,0,0 Common 71 2 71 4    # 4 [34 ]0
    ¬ª 10 0,255,0,255,0,0,0,0,0,0 Common 72 10 31 ¬ª    # ¬ª [bb ]p
    ‚Ç¨ 0 0,255,0,255,0,0,0,0,0,0 Common 73 4 73 ‚Ç¨    # ‚Ç¨ [20ac ]
    W 5 0,255,0,255,0,0,0,0,0,0 Latin 11 0 74 W # W [57 ]A
    J 5 0,255,0,255,0,0,0,0,0,0 Latin 105 0 75 J    # J [4a ]A
    √© 3 0,255,0,255,0,0,0,0,0,0 Latin 76 0 76 √©   # √© [e9 ]a
    9 8 0,255,0,255,0,0,0,0,0,0 Common 77 2 77 9    # 9 [39 ]0
    ¬Æ 0 0,255,0,255,0,0,0,0,0,0 Common 78 10 78 ¬Æ # ¬Æ [ae ]
    $ 0 0,255,0,255,0,0,0,0,0,0 Common 79 4 79 $    # $ [24 ]
    5 8 0,255,0,255,0,0,0,0,0,0 Common 80 2 80 5    # 5 [35 ]0
    } 10 0,255,0,255,0,0,0,0,0,0 Common 81 10 86 }  # } [7d ]p
    [ 10 0,255,0,255,0,0,0,0,0,0 Common 82 10 107 [ # [ [5b ]p
    Y 5 0,255,0,255,0,0,0,0,0,0 Latin 46 0 83 Y # Y [59 ]A
    ¬ß 10 0,255,0,255,0,0,0,0,0,0 Common 84 10 84 ¬ß    # ¬ß [a7 ]p
    " 10 0,255,0,255,0,0,0,0,0,0 Common 85 10 85 "  # " [22 ]p
    { 10 0,255,0,255,0,0,0,0,0,0 Common 86 10 81 {  # { [7b ]p
    ¬¢ 0 0,255,0,255,0,0,0,0,0,0 Common 87 4 87 ¬¢  # ¬¢ [a2 ]
    / 10 0,255,0,255,0,0,0,0,0,0 Common 88 6 88 /   # / [2f ]p
    Q 5 0,255,0,255,0,0,0,0,0,0 Latin 45 0 89 Q # Q [51 ]A
    6 8 0,255,0,255,0,0,0,0,0,0 Common 90 2 90 6    # 6 [36 ]0
    G 5 0,255,0,255,0,0,0,0,0,0 Latin 18 0 91 G # G [47 ]A
    ‚Äù 10 0,255,0,255,0,0,0,0,0,0 Common 92 10 92 "    # ‚Äù [201d ]p
    ¬∞ 0 0,255,0,255,0,0,0,0,0,0 Common 93 4 93 ¬∞  # ¬∞ [b0 ]
    K 5 0,255,0,255,0,0,0,0,0,0 Latin 65 0 94 K # K [4b ]A
    ¬• 0 0,255,0,255,0,0,0,0,0,0 Common 95 4 95 ¬•  # ¬• [a5 ]
    V 5 0,255,0,255,0,0,0,0,0,0 Latin 24 0 96 V # V [56 ]A
    ¬© 0 0,255,0,255,0,0,0,0,0,0 Common 97 10 97 ¬© # ¬© [a9 ]
    z 3 0,255,0,255,0,0,0,0,0,0 Latin 35 0 98 z # z [7a ]a
    + 0 0,255,0,255,0,0,0,0,0,0 Common 99 3 99 +    # + [2b ]
    = 0 0,255,0,255,0,0,0,0,0,0 Common 100 10 100 = # = [3d ]
    ¬£ 0 0,255,0,255,0,0,0,0,0,0 Common 101 4 101 ¬£    # ¬£ [a3 ]
    < 0 0,255,0,255,0,0,0,0,0,0 Common 102 10 67 <  # < [3c ]
    ‚Äô 10 0,255,0,255,0,0,0,0,0,0 Common 103 10 103 '  # ‚Äô [2019 ]p
    ‚Äò 10 0,255,0,255,0,0,0,0,0,0 Common 104 10 104 '  # ‚Äò [2018 ]p
    j 3 0,255,0,255,0,0,0,0,0,0 Latin 75 0 105 j    # j [6a ]a
    X 5 0,255,0,255,0,0,0,0,0,0 Latin 51 0 106 X    # X [58 ]A
    ] 10 0,255,0,255,0,0,0,0,0,0 Common 107 10 82 ] # ] [5d ]p
    * 10 0,255,0,255,0,0,0,0,0,0 Common 108 10 108 *    # * [2a ]p
    ‚Äú 10 0,255,0,255,0,0,0,0,0,0 Common 109 10 109 "  # ‚Äú [201c ]p
    @ 10 0,255,0,255,0,0,0,0,0,0 Common 110 10 110 @    # @ [40 ]p
    ‚Ä¢ 10 0,255,0,255,0,0,0,0,0,0 Common 111 10 111 ‚Ä¢    # ‚Ä¢ [2022 ]p
    ‚Äì 10 0,255,0,255,0,0,0,0,0,0 Common 112 10 112 -  # ‚Äì [2013 ]p
    ‚Ä¶ 10 0,255,0,255,0,0,0,0,0,0 Common 113 10 113 ...    # ‚Ä¶ [2026 ]p
    ^ 0 0,255,0,255,0,0,0,0,0,0 Common 114 10 114 ^ # ^ [5e ]
```

We can see that some parts are missing.

Here from the documentation to see the difference, so the "missing" part :
https://github.com/tesseract-ocr/tesseract/blob/a3ba11b030345d32829b1e8355afea5419978d82/doc/unicharset.5.asc

```
    EXAMPLE (v3.02)

    110
    NULL 0 NULL 0
    N 5 59,68,216,255,87,236,0,27,104,227 Latin 11 0 1 N
    Y 5 59,68,216,255,91,205,0,47,91,223 Latin 33 0 2 Y
    1 8 59,69,203,255,45,128,0,66,74,173 Common 3 2 3 1
    9 8 18,66,203,255,89,156,0,39,104,173 Common 4 2 4 9
    a 3 58,65,186,198,85,164,0,26,97,185 Latin 56 0 5 a
    . . .
```
 > script_dir in set_unicharset_properties should point to a directory that contains a *.unicharset file. 

This is the case, the file I get from `unicharset_extractor` is used as input file by `set_unicharset_properties`.

> For English and other Latin based scripts, the file is Latin.unicharset.
> You can find the *.unicharset files here: https://github.com/tesseract-ocr/langdata

I have some questions:
1. If I follow the documentation, I should use the unicharset file generate by `unicharset_extractor`, because it is adapted to the chosen font. Isn‚Äôt it?
2. What if I use the latin.unicharset that do not match the xheight of the chosen font?
3. Why `set_unicharset_properties` still complain when I use latin.unicharset? See below the output:

Is it normal?

```
    Loaded unicharset of size 3504 from file latin.unicharset
    Setting unichar properties
    Other case ‚±æ of »ø is not in unicharset
    Other case ‚±ø of …Ä is not in unicharset
    Other case ‚±Ø of …ê is not in unicharset
    Other case ‚±∞ of …í is not in unicharset
    Other case Íû´ of …ú is not in unicharset
    Other case Íû¨ of …° is not in unicharset
    Other case Íûç of …• is not in unicharset
    Other case Íû™ of …¶ is not in unicharset
    Other case Íû≠ of …¨ is not in unicharset
    Other case ‚±Æ of …± is not in unicharset
    Other case Íû± of  á is not in unicharset
    Other case Íû∞ of  û is not in unicharset
    Other case Œú of ¬µ is not in unicharset
    Other case œ≥ of Õø is not in unicharset
    Mirror ‚ßµ of ‚àï is not in unicharset
    Mirror ‚¶∏ of ‚äò is not in unicharset
    Mirror ‚´û of ‚ä¶ is not in unicharset
    Mirror ‚´§ of ‚ä® is not in unicharset
    Mirror ‚´£ of ‚ä© is not in unicharset
    Mirror ‚´• of ‚ä´ is not in unicharset
    Warning: properties incomplete for index 1073 = ~
    Warning: properties incomplete for index 1081 = ¬®
    Warning: properties incomplete for index 1087 = ¬Ø
    Warning: properties incomplete for index 1090 = ¬≤
    Warning: properties incomplete for index 1091 = ¬≥
    Warning: properties incomplete for index 1092 = ¬¥
    Warning: properties incomplete for index 1096 = ¬∏
    Warning: properties incomplete for index 1097 = ¬π
    Warning: properties incomplete for index 1117 = ÀÜ
    Warning: properties incomplete for index 1118 = Àá
    Warning: properties incomplete for index 1135 = Àò
    Warning: properties incomplete for index 1136 = Àô
    Warning: properties incomplete for index 1137 = Àö
    Warning: properties incomplete for index 1138 = Àõ
    Warning: properties incomplete for index 1139 = Àú
    Warning: properties incomplete for index 1168 = ÃÄ
    Warning: properties incomplete for index 1169 = ÃÅ
    Warning: properties incomplete for index 1170 = ÃÇ
    Warning: properties incomplete for index 1171 = ÃÉ
    Warning: properties incomplete for index 1172 = ÃÑ
    Warning: properties incomplete for index 1173 = ÃÖ
    Warning: properties incomplete for index 1174 = ÃÜ
    Warning: properties incomplete for index 1175 = Ãá
    Warning: properties incomplete for index 1176 = Ãà
    Warning: properties incomplete for index 1177 = Ãâ
    Warning: properties incomplete for index 1178 = Ãä
    Warning: properties incomplete for index 1179 = Ãã
    Warning: properties incomplete for index 1180 = Ãå
    Warning: properties incomplete for index 1181 = Ãç
    Warning: properties incomplete for index 1182 = Ãé
    Warning: properties incomplete for index 1183 = Ãè
    Warning: properties incomplete for index 1184 = Ãê
    Warning: properties incomplete for index 1185 = Ãë
    Warning: properties incomplete for index 1186 = Ãí
    Warning: properties incomplete for index 1187 = Ãì
    Warning: properties incomplete for index 1188 = Ãî
    Warning: properties incomplete for index 1189 = Ãï
    Warning: properties incomplete for index 1194 = Ãö
    Warning: properties incomplete for index 1195 = Ãõ
    Warning: properties incomplete for index 1201 = Ã°
    Warning: properties incomplete for index 1202 = Ã¢
    Warning: properties incomplete for index 1203 = Ã£
    Warning: properties incomplete for index 1204 = Ã§
    Warning: properties incomplete for index 1205 = Ã•
    Warning: properties incomplete for index 1211 = Ã´
    Warning: properties incomplete for index 1212 = Ã¨
    Warning: properties incomplete for index 1213 = Ã≠
    Warning: properties incomplete for index 1214 = ÃÆ
    Warning: properties incomplete for index 1216 = Ã∞
    Warning: properties incomplete for index 1217 = Ã±
    Warning: properties incomplete for index 1218 = Ã≤
    Warning: properties incomplete for index 1219 = Ã≥
    Warning: properties incomplete for index 1220 = Ã¥
    Warning: properties incomplete for index 1221 = Ãµ
    Warning: properties incomplete for index 1222 = Ã∂
    Warning: properties incomplete for index 1223 = Ã∑
    Warning: properties incomplete for index 1224 = Ã∏
    Warning: properties incomplete for index 1228 = Ãº
    Warning: properties incomplete for index 1229 = ÃΩ
    Warning: properties incomplete for index 1230 = Ãæ
    Warning: properties incomplete for index 1231 = Ãø
    Warning: properties incomplete for index 1233 = ÕÅ
    Warning: properties incomplete for index 1234 = ÕÇ
    Warning: properties incomplete for index 1236 = ÕÑ
    Warning: properties incomplete for index 1240 = Õã
    Warning: properties incomplete for index 1248 = Õò
    Warning: properties incomplete for index 1252 = Õú
    Warning: properties incomplete for index 1253 = Õù
    Warning: properties incomplete for index 1254 = Õû
    Warning: properties incomplete for index 1255 = Õü
    Warning: properties incomplete for index 1256 = Õ†
    Warning: properties incomplete for index 1257 = Õ°
    Warning: properties incomplete for index 1258 = Õ¢
    Warning: properties incomplete for index 1294 = Ÿã
    Warning: properties incomplete for index 1295 = Ÿå
    Warning: properties incomplete for index 1296 = Ÿç
    Warning: properties incomplete for index 1297 = Ÿé
    Warning: properties incomplete for index 1298 = Ÿè
    Warning: properties incomplete for index 1299 = Ÿê
    Warning: properties incomplete for index 1300 = Ÿë
    Warning: properties incomplete for index 1301 = Ÿí
    Warning: properties incomplete for index 1302 = Ÿì
    Warning: properties incomplete for index 1303 = Ÿî
    Warning: properties incomplete for index 1304 = Ÿï
    Warning: properties incomplete for index 1315 = Ÿ∞
    Warning: properties incomplete for index 1317 = ‡•í
    Warning: properties incomplete for index 1386 = ‚ÅÑ
    Warning: properties incomplete for index 1406 = ‚Å™
    Warning: properties incomplete for index 1407 = ‚Å´
    Warning: properties incomplete for index 1408 = ‚Å¨
    Warning: properties incomplete for index 1409 = ‚Å≠
    Warning: properties incomplete for index 1410 = ‚ÅÆ
    Warning: properties incomplete for index 1411 = ‚ÅØ
    Warning: properties incomplete for index 3101 = „Çô
    Warning: properties incomplete for index 3102 = „Çö
    Warning: properties incomplete for index 3103 = „Çõ
    Warning: properties incomplete for index 3104 = „Çú
    Writing unicharset to file output_unicharset
```
 To follow up with #316 , I added the line 

/home/ggdhines/github/tesseract/training/set_unicharset_properties -U unicharset -O new_unicharset --script_dir=/home/ggdhines/github/langdata/Latin.unicharset

then new_unicharset looks like:

1 8 0,255,0,255,0,0,0,0,0,0 Common 3 2 3 1      # 1 [31 ]0
2 8 0,255,0,255,0,0,0,0,0,0 Common 4 2 4 2      # 2 [32 ]0
9 8 0,255,0,255,0,0,0,0,0,0 Common 5 2 5 9      # 9 [39 ]0

(Only trying for 3 characters right now). This looks better than before (no null values) but I'm still getting the error:
Bad properties for index 3, char 1: 0,255 0,255 0,0 0,0 0,0
(Repeated for each character.)

@ne0zer0 's questions are good ones.
 Also just realized that the example unicharset file in the Compute the Character Set of the official documents:
; 10 Common 46
b 3 Latin 59
W 5 Latin 40
7 8 Common 66
= 0 Common 93

appears to be out of date (I think that's Tesseract version 2)
 > appears  to be out of date (I think that's Tesseract version 2)

Yes, you should read unicharset(5) doc:
https://github.com/tesseract-ocr/tesseract/blob/a3ba11b030345d32829b1e8355afea5419978d82/doc/unicharset.5.asc

And for `set_unicharset_properties`, where I can find file listing font xheights for all my desired fonts? (Adobe Jenson too)

```
set_unicharset_properties --help
USAGE: set_unicharset_properties
  --debug_level  Level of Trainer debugging  (type:int default:0)
  --load_images  Load images with tr files  (type:int default:0)
  --clusterconfig_min_samples_fraction  Min number of samples per proto as % of total  (type:double default:0.625)
  --clusterconfig_max_illegal  Max percentage of samples in a cluster which have more than 1 feature in that cluster  (type:double default:0.05)
  --clusterconfig_independence  Desired independence between dimensions  (type:double default:1)
  --clusterconfig_confidence  Desired confidence in prototypes created  (type:double default:1e-06)
  --script_dir  Directory name for input script unicharsets/xheights  (type:string default:)
  --configfile  File to load more configs from  (type:string default:)
  --D  Directory to write output files to  (type:string default:)
  --F  File listing font properties  (type:string default:font_properties)
  --X  File listing font xheights  (type:string default:)
  --U  File to load unicharset from  (type:string default:unicharset)
  --O  File to write unicharset to  (type:string default:)
  --T  File to load trainer from  (type:string default:)
  --output_trainer  File to write trainer to  (type:string default:)
  --test_ch  UTF8 test character string  (type:string default:)
```

Or a way to compute these xheights for every kind of fonts?

Maybe, it is a problem with wctype functions on systems? As I read on the documentation:

> If your system supports the wctype functions, t**hese values will be set automatically by unicharset_extractor and there is no need to edit the unicharset file**. On some very old systems (eg Windows 95), the unicharset file must be edited by hand to add these property description codes.
 thanks @amitdo for the help. I'm a little confused though as to why we need to use Latin.unicharset and Common.unicharset. Shouldn't we be teaching Tesseract new fonts based on the actual examples (and box files). Using some preexisting unicharset file makes it seem as if we're not actually training Tesseract on the new font
 > unicharset_extractor produces a unicharset file.
> 
> You need to pass this file to set_unicharset_properties.
> 
> ```
> -U unicharset
> ```

It is exactly what I do.

> Download these files:
> https://raw.githubusercontent.com/tesseract-ocr/langdata/master/Latin.unicharset

Already done.

> https://raw.githubusercontent.com/tesseract-ocr/langdata/master/Common.unicharset

Done after reading your post addressed to ggdhines

> set_unicharset_properties --F font_properties -U unicharset -O output_unicharset --script_dir=/home/ne0zer0/langdata

What did and I wrote in the first post (current directory):

> When I try to fix it with with set_unicharset_properties:
> set_unicharset_properties --F font_properties -U unicharset -O output_unicharset --script_dir=/

where Common.unicharset is now put.

But if I put Latin.unicharset, what I get is not what is adapted for my fonts, 
xheights can change per fonts:
https://raw.githubusercontent.com/tesseract-ocr/langdata/master/Latin.xheights
So how can I be sure that this default value is correct for my all fonts???

As says ggdhines, according to the documentation, we have to compute the actual size of our fonts:

https://github.com/tesseract-ocr/tesseract/blob/a3ba11b030345d32829b1e8355afea5419978d82/doc/unicharset.5.asc

> CAVEATS
> 
> Although the unicharset reader maintains the ability to read unicharsets of older formats and will assign default values to missing fields, the accuracy will be degraded.

What you suggest is likely to produce such degraded result. (what I seem to experiment)

Always for the above link:

> Further, most other data files are indexed by the unicharset file, so changing it without re-generating the others is likely to have dire consequences

So, as it is stated that "assign default values to missing fields, the accuracy will be degraded", and "is likely to have dire consequences", your proposition can not be accepted, because it lead to what I experiment if I do like you say: strange results.

Unless I did not understand anything, in which case, as I am not the only one, you have to review the documentation.
 @amitdo 

Here some output according to your recommendation:

tesseract training:

```
    tesseract -l eng2 eng.palladio-regular.exp9.tif eng.palladio-regular.exp9 box.train.stderr
    Tesseract Open Source OCR Engine v3.04.01 with Leptonica
    Page 1
    APPLY_BOXES:
       Boxes read from boxfile:    1583
       Found 1583 good blobs.
    Generated training data for 403 words
    Page 2
    APPLY_BOXES:
       Boxes read from boxfile:    1590
       Found 1590 good blobs.
    Generated training data for 380 words
    Page 3
    APPLY_BOXES:
       Boxes read from boxfile:    1577
       Found 1577 good blobs.
    Generated training data for 392 words
    Page 4
    APPLY_BOXES:
       Boxes read from boxfile:    1613
       Found 1613 good blobs.
    Generated training data for 363 words
    Page 5
    APPLY_BOXES:
       Boxes read from boxfile:    1435
       Found 1435 good blobs.
    Generated training data for 312 words
    Page 6
    APPLY_BOXES:
       Boxes read from boxfile:    1670
       Found 1670 good blobs.
    Generated training data for 367 words
    Page 7
    APPLY_BOXES:
       Boxes read from boxfile:    1684
       Found 1684 good blobs.
    Generated training data for 374 words
    Page 8
    APPLY_BOXES:
       Boxes read from boxfile:    1673
       Found 1673 good blobs.
    Generated training data for 365 words
    Page 9
    APPLY_BOXES:
       Boxes read from boxfile:    1639
       Found 1639 good blobs.
    Generated training data for 381 words
    Page 10
    APPLY_BOXES:
       Boxes read from boxfile:    1671
       Found 1671 good blobs.
    Generated training data for 369 words
    Page 11
    APPLY_BOXES:
       Boxes read from boxfile:    1723
       Found 1723 good blobs.
    Generated training data for 357 words
    Page 12
    FAIL!
    APPLY_BOXES: boxfile line 1058/1 ((1279,1540),(1321,1612)): FAILURE! Couldn't find a matching blob
    FAIL!
    APPLY_BOXES: boxfile line 1382/1 ((1287,742),(1330,814)): FAILURE! Couldn't find a matching blob
    APPLY_BOXES:
       Boxes read from boxfile:    1631
       Boxes failed resegmentation:       2
       Found 1629 good blobs.
    Generated training data for 303 words
    Page 13
    FAIL!
    APPLY_BOXES: boxfile line 75/1 ((1299,4479),(1342,4550)): FAILURE! Couldn't find a matching blob
    FAIL!
    APPLY_BOXES: boxfile line 321/1 ((1289,3814),(1332,3885)): FAILURE! Couldn't find a matching blob
    FAIL!
    APPLY_BOXES: boxfile line 475/1 ((1284,3415),(1327,3486)): FAILURE! Couldn't find a matching blob
    FAIL!
    APPLY_BOXES: boxfile line 629/1 ((1278,3016),(1321,3087)): FAILURE! Couldn't find a matching blob
    FAIL!
    APPLY_BOXES: boxfile line 937/1 ((1267,2218),(1310,2289)): FAILURE! Couldn't find a matching blob
    APPLY_BOXES:
       Boxes read from boxfile:    1727
       Boxes failed resegmentation:       5
       Found 1722 good blobs.
    Generated training data for 239 words
    Page 14
    APPLY_BOXES:
       Boxes read from boxfile:    1651
       Found 1651 good blobs.
    Generated training data for 350 words
    Page 15
    APPLY_BOXES:
       Boxes read from boxfile:    1619
       Found 1619 good blobs.
    Generated training data for 179 words
    Page 16
    APPLY_BOXES:
       Boxes read from boxfile:    1634
       Found 1634 good blobs.
    Generated training data for 238 words
    Page 17
    APPLY_BOXES:
       Boxes read from boxfile:    1677
       Found 1677 good blobs.
    Generated training data for 386 words
    Page 18
    APPLY_BOXES:
       Boxes read from boxfile:    1643
       Found 1643 good blobs.
    Generated training data for 401 words
    Page 19
    APPLY_BOXES:
       Boxes read from boxfile:    1659
       Found 1659 good blobs.
    Generated training data for 376 words
    Page 20
    APPLY_BOXES:
       Boxes read from boxfile:    1317
       Found 1317 good blobs.
    Generated training data for 304 words
```

set_unicharset_properties

```
    set_unicharset_properties --F font_properties --script_dir=/home/ne0zer0/Tesseract/Test2/langdata -U unicharset -O output_unicharsetLoaded unicharset of size 115 from file unicharset
    Setting unichar properties
    Other case √â of √© is not in unicharset
    Warning: properties incomplete for index 25 = ~
    Writing unicharset to file output_unicharset
```

shapeclustering

```
    shapeclustering -F font_properties -U output_unicharset eng.palladio-regular.exp9.tr
    Reading eng.palladio-regular.exp9.tr ...
    Bad properties for index 25, char ~: 91,229 135,255 73,174 0,41 0,200
    Building master shape table
    Computing shape distances...
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances...
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances...
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances...
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances...
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111
    Distance = 0.000000: Distance = 0.000000: Distance = 0.006410: Distance = 0.007353: Distance = 0.007463: Distance = 0.012427: Distance = 0.012987: Distance = 0.015045: Distance = 0.020725: Distance = 0.020841: Stopped with 10 merged, min dist 0.026087
    Master shape_table:Number of shapes = 102 max unichars = 3 number with multiple unichars = 7
```

mftraining

```
    mftraining -F font_properties -U output_unicharset -O eng.unicharset eng.palladio-regular.exp9.tr
    Read shape table shapetable of 102 shapes
    Reading eng.palladio-regular.exp9.tr ...
    Bad properties for index 25, char ~: 91,229 135,255 73,174 0,41 0,200
    Warning: no protos/configs for sh0099 in CreateIntTemplates()
    Warning: no protos/configs for sh0100 in CreateIntTemplates()
    Warning: no protos/configs for sh0101 in CreateIntTemplates()
    Done!
```

The result is as strange as before, but now I have this warning in mftraining:

> Warning: no protos/configs for sh0101 in CreateIntTemplates()

And why these failure?

> APPLY_BOXES: boxfile line 1382/1 ((1287,742),(1330,814)): FAILURE! Couldn't find a matching blob
 Yes I know,

At first, i tried without `shapeclustering`, but I finally say "what if".

Anyway, here the output:

```
    mftraining -F font_properties -U output_unicharset -O eng.unicharset eng.palladio-regular.exp9.tr
    Warning: No shape table file present: shapetable
    Reading eng.palladio-regular.exp9.tr ...
    Flat shape table summary: Number of shapes = 112 max unichars = 1 number with multiple unichars = 0
    Warning: no protos/configs for Joined in CreateIntTemplates()
    Warning: no protos/configs for |Broken|0|1 in CreateIntTemplates()
    Done!
```

For the same result‚Ä¶
 Thank you for your reply,

But what about theses questions:

> But if I put Latin.unicharset, what I get is not what is adapted for my fonts,
> xheights can change per fonts:
> https://raw.githubusercontent.com/tesseract-ocr/langdata/master/Latin.xheights
> So how can I be sure that this default value is correct for my all fonts???
> 
> As says ggdhines, according to the documentation, we have to compute the actual size of our fonts:
> 
> https://github.com/tesseract-ocr/tesseract/blob/a3ba11b030345d32829b1e8355afea5419978d82/doc/unicharset.5.asc
> 
> ```
> CAVEATS
> 
> Although the unicharset reader maintains the ability to read unicharsets of older formats and will assign default values to missing fields, the accuracy will be degraded.
> ```
> 
> What you suggest is likely to produce such degraded result. (what I seem to experiment)
> 
> Always for the above link:
> 
> ```
> Further, most other data files are indexed by the unicharset file, so changing it without re-generating the others is likely to have dire consequences
> ```
> 
> So, as it is stated that "assign default values to missing fields, the accuracy will be degraded", and "is likely to have dire consequences", your proposition can not be accepted, because it lead to what I experiment if I do like you say: strange results.
> 
> Unless I did not understand anything, in which case, as I am not the only one, you have to review the documentation.
 > CAVEATS
> Although the unicharset reader maintains the ability to read unicharsets of older formats and will **assign default values to missing fields**, the accuracy will be degraded.

What I understood is: incomplete  v3.02 unicharset format file (like what I get) will result, infine, to the old format (after all, some fields are zeroing). These 0 lead to default value.

As informations are missing, owing to the fact that 0 are put instead of actual value, the accuracy will be degraded.
 @amitdo - why is this necessary at all? Shouldn't Tesseract being learning based on the training examples we provide? Pre-existing data isn't going to be helpful with new fonts. 
 @ggdhines :+1: 
 Ok, I will wait.

Thanks for your patience.
 Hi,

Thank you for this clarification.

I am somewhat disappointed, and I have more questions than before:
1. Why using default values, when we want to train for specific fonts, and we could get specific values?
2. Are not specific values better than default values??? Why not using default values "only" when we need it? For example, when there are no matching font?
3. It will be certainly less accurate to use default values; so we cannot get the best result for specific fonts? Unless to waste a lot of time in training Tesseract? For an "uncertain" result?
4. Why `set_unicharset_properties` does not compute such values? It would not be too difficult to develop such a functionality. And I think it would be better in a lot of way (result and time).
5. I cannot understand how these default values can be better. For example, theses default values are likely not to match Adobe Jenson Pro glyph metrics and other fonts. So I have to train again, again, and again, to get better result due to lack of specific values, owing to "missing functionality"?
6. You write: 

> set_unicharset_properties -U unicharset -O new_unicharset -X xheights --script_dir=/home/myusername/tesseract-ocr/langdata

but the xheights file generated is always blank, and the file Latin.xheights seems to do nothing (I already tried this), and I always get the same output_unicharset file, with or without Latin.xheights (located in langdata folder, or in the current directory).

What can be done with a filled (with default values) xheights file?

Thank you
 > If you develop such a tool (or hire someone to do so) we can add a link in the wiki to your site...
1. Not enough time
2. Not enough money
3. The developers of Tesseract will do it faster, cleaner, and cheaper than me.

> My answer for your other questions:
> This is the current situation and you should accept it...

Indeed. In fact, I expected too much from Tesseract.

> Your last question - you probably did something wrong if you get an empty file. I will try to test it later.

I will wait for your test.

> Two last notes:
> I and the other people responding most of the time here and in the mailing-list are volunteers.
> Within free (not paid) open source projects, complaining would not help, kind request might help but it's not guaranteed.

Sorry, but I did not want to hurt anybody.

> You seem to think that / is the current directory, but it's not.
> / is your 'root' directory. ./ (or just .) is the current directory.

No, just a mistake when I wrote.

> > What can be done with a filled xheights file?
> 
> https://github.com/tesseract-ocr/tesseract/blob/master/doc/mftraining.1.asc

Thanks for the link.

Anyway, thank you for everything.
 I finally resolved my problem with xheights. I did a spelling mistake :s

Anyway, thanks for all.
 More recently I made the addmetrics and xheights tools, which are in the tools directory of the git repo https://ancientgreekocr.org/grctraining.git
  Command run in tesseract 3.04.01 src on redhat linux 7.2 64 bit
./configure --prefix=/apps/tesseract --with-extra-libraries=/apps/build/lib --enable-debug CXPFLAGS="-I/apps/build/include -I/apps/build/include/libpng16 -I/apps/build/include/leptonica -lpng -ljpeg -lz" LDFLAGS="-L/apps/build/lib" LIBLEPT_HEADERSDIR=/apps/build/include/leptonica
my build location is /apps/build
This errors for 
checking for pixCreate in -llept... no
configure: error: leptonica library missing

I have kept my leptonica's liblept.a in /apps/build/lib but stil it fails with this error.
I am attaching the configure.log

any help is much appreciated
[configlog.txt](https://github.com/tesseract-ocr/tesseract/files/253517/configlog.txt)
 even after correcting to CXXFLAGS or CPPFLAGS it still throws the same error
were you able to compile it in linux in non standard location?
 Need urgent help from any of the developers... All help is appreciated.I was trying to install it in linux never realized that it was not tried by any one successfully before.
  I'm following the instructions for creating a new font with Tesseract at http://michaeljaylissner.com/posts/2012/02/11/adding-new-fonts-to-tesseract-3-ocr-engine/ and am getting a unicharest file that looks like:

4
NULL 0 NULL 0
Joined 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # Joined [4a 6f 69 6e 65 64 ]
|Broken|0|1 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0        # Broken
A 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # A [41 ]

(just trying with one character right now) . Later on I get an error:
Bad properties for index 3, char A: 0,255 0,255 0,0 0,0 0,0

My box file is looking right. Any suggestions on how to debug this?
 Seems to be a duplicate of #318 for now
  Hello:
    I use Tesseract 3.4 on CentOS 7, and I test it by some sample words.  In general environmental condition(not opencl), it work successfully, and output words is right.  In opencl condition(./configure --enable-opencl), it can work, but output words is garbled. 
    Why? 
  I have the following image of A's which I want to use to teach Tesseract a new font. (When I include the other characters, the page is mostly taken up and the errors are the same so doesn't seem to be an image with a mostly empty page.) (The original image is in tiff format.)

![active_weather basic exp0](https://cloud.githubusercontent.com/assets/6626461/14989143/5c8c5214-114e-11e6-9aa9-e9baf99eda9a.jpeg)

I have the box file contents which appear to be correct and reasonable.
A 35 3926 66 3965 0
A 102 3926 133 3965 0
A 169 3926 200 3965 0
A 236 3926 267 3965 0
A 303 3926 334 3965 0
A 370 3926 401 3965 0
A 437 3926 468 3965 0
A 504 3926 535 3965 0
A 571 3926 602 3965 0
A 638 3926 669 3965 0

and I have font properties file:
basic 0 0 0 0 0

I enter the commands:
tesseract example.basic.exp0.tiff example.basic.exp0 nobatch box.train
unicharset_extractor example.basic.exp0.tiff

I get the following errors:
APPLY_BOXES:
   Boxes read from boxfile:      10
   Found 10 good blobs.
Generated training data for 1 words
Extracting unicharset from active_weather.basic.exp0.jpeg
Bad box coordinates in boxfile string! ÔøΩÔøΩÔøΩÔøΩ
Box file format error on line 1; ignored
Bad box coordinates in boxfile string! 

Box file format error on line 6; ignored
Bad box coordinates in boxfile string! 

Box file format error on line 7; ignored
Bad box coordinates in boxfile string! ÔøΩÔøΩ
Box file format error on line 10; ignored
Bad box coordinates in boxfile string! 
                                       ÔøΩÔøΩ
Box file format error on line 11; ignored
Bad box coordinates in boxfile string! ‚ñí‚ñí%&'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyzÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩ
Box file format error on line 12; ignored
Bad box coordinates in boxfile string! (ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩÔøΩ(ÔøΩ?ÔøΩÔøΩÔøΩÔøΩÔøΩ_ŸØÔøΩÔøΩ?hÔøΩiÔøΩÔøΩﬁâÔøΩÔøΩ~$ÔøΩmtÔøΩÔøΩKÔøΩÔøΩlmdÔøΩÔøΩ!YÔøΩ)
                                                                                                                                        Ë•àÔøΩr?$ÔøΩÔøΩÔøΩtÔøΩÔøΩ?ÔøΩ(ÔøΩÔøΩOÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩ

The question marks are just gibberish. (And the errors keep on coming). I feel I like I didn't have this problem recently but wondering if some upgrade broke things.  

My versions are:
tesseract 3.05.00dev
 leptonica-1.72
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.51 : libtiff 4.0.3 : zlib 1.2.8
 d'oh - you are right. Cheers
  Is there a way to install new languages with HomeBrew. I would like to install norwegian, the code is nor. I tried to do `brew install tessecract-nor` but that didn't work.
On the Wiki there is detail who to do it for MacPort
https://github.com/tesseract-ocr/tesseract/wiki#homebrew
 I got reply on my question here https://github.com/Homebrew/homebrew-core/issues/797.
    I have been having difficultly finding documentation about all of the parameters I can configure in the hocr config. If anyone is able to link me to the complete list.

```
tessedit_create_hocr 1
hocr_font_info 1
```

I'm using tesseract and as part of the hOCRText I would like to retrieve information on the size, font-family and emphasis.

Following the answer on [stack overflow](http://stackoverflow.com/questions/20016767/extracting-text-attributes-using-tesseract-hocr/35415375) This is also confirmed by a pull request documenting this feature #222 

My configuration looks like this.
‚îú‚îÄ‚îÄ tessdata/
‚îî‚îÄ‚îÄ‚îÄ‚îÄ  configs/
‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ api_config
‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ digits
‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ hocr
‚îÇ       ‚îî‚îÄ‚îÄ ENG.traineddata

Unfortunately I'm still getting results like the following: 

``` xml
<span class='ocrx_word' id='word_1_109' title='bbox 632 298 721 312; x_wconf 89' lang='ENG' dir='ltr'>authorised</span>
<span class='ocrx_word' id='word_1_110' title='bbox 729 298 748 316; x_wconf 99' lang='ENG' dir='ltr'>by</span>
<span class='ocrx_word' id='word_1_111' title='bbox 756 298 782 312; x_wconf 89' lang='ENG' dir='ltr'>the</span>
<span class='ocrx_word' id='word_1_112' title='bbox 792 298 852 312; x_wconf 91' lang='ENG' dir='ltr'>Income</span>
```

Note: the missing font information.

``` xml
<span class='ocrx_word' id='word_3_21' title='bbox 946 1267 1121 1297; x_wconf 91; x_font Courier_New; x_fsize 9' dir='ltr'>without</span>
```

I have found a webpage outlining extra configuration that I do not [have](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#data-files-required). Could this be the issue? 
 Thanks very much for your help! 
  Doesn't seem to recognize italics in Japanese. I want to help, but there don't seem to be any instruction in https://github.com/tesseract-ocr/langdata.

Examples:

![image0](https://cloud.githubusercontent.com/assets/216339/14833717/8164ad44-0bf8-11e6-8dae-a4efe29a3fe2.png)

![image0](https://cloud.githubusercontent.com/assets/216339/14833805/e8428a36-0bf8-11e6-8b59-5b205e18bde2.png)
 @amitdo Thanks!
 Hi! I'm wondering if the tessdata for italics of Japanese fonts have finished?  Hi Team,

I am an android developer and i am integrating Tesseract for OCR scanning. for my application i have the requirement to detect the orientation of the Ocr and based and that process the OCR.
I have gone though various post to find the way to get the Orientation but was unable to succeed. As per one of the post it ismentioned to get the orientation using the following logic :

inputfile = "/usr/src/tesseract-3.02/eurotextUpsideDown.png";
    image = pixRead(inputfile);

```
api->Init("/usr/src/tesseract-3.02/", "eng");
api->SetPageSegMode(tesseract::PSM_AUTO_OSD);
api->SetImage(image);
api->Recognize(0);

tesseract::PageIterator* it =  api->AnalyseLayout();
tesseract::Orientation orientation;
tesseract::WritingDirection direction;
tesseract::TextlineOrder order;
float deskew_angle;

it->Orientation(&orientation, &direction, &order, &deskew_angle);
printf("Orientation: %d;\nWritingDirection: %d\nTextlineOrder: %d\n" \
       "Deskew angle: %.4f\n",
       orientation, direction, order, deskew_angle);
```

But in android I cannot find the supported method AnalyseLayout() in the TessBaseApi.java class. Can some one help me to find the solution for this or can some one tell me the
api or the logic to get this.

Will be a great help for me. 

Thanks,
Ankit
 Dear @ankitagg,

Did you resolve the issue ?

Please let me know if it is resolved and the method you used to solve ?

Thanks.  In Version v3.04.00 I get a strange behaviour if a non-dictionary word has a certain 
ratio of digits to numbers in it and if there is a non-leading capital "I" involved.
The attached bad.jpg file (same with tif files) should get ocr-ed to NCOR140123020064000000000 and not NCORI4012302006400000000.
If I cut off the last "0" ( good.jpg ) then all is fine.
I played with all kind of options like conflict_set_I_l_1 and rej_1Il_trust_rej_1Il_trust_permuter_type_type and more, but had no success.
I think that it is a bug if the length of the word affects the interpretation of "I".
Or which special setting of the parameters do I have to choose to get this working?

```
rolfm@~/ocr> tesseract -psm 7 good.jpg good ; cat good.txt
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
NCOR14012302006400000000

rolfm@~/ocr> tesseract -psm 7 bad.jpg bad ; cat bad.txt
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
NCORI40123020064000000000
```

bad.jpg :
![bad](https://cloud.githubusercontent.com/assets/1440116/14764199/a3e7cacc-09af-11e6-8a6c-fd881f01b4c8.jpg)
good.jpg : 
![good](https://cloud.githubusercontent.com/assets/1440116/14764200/a7b4288a-09af-11e6-86db-2c58ebe82f37.jpg)
 Can you be more specific? 
The only "fix" I found was to add " -l deu " and then bad.jpg is read correctly. 
But how can I get this behaviour for " -l eng" ? Turning off dictionaries as suggested in the wiki has no effect.
 But isn't it clearly a bug? ocropus-rpred has no problem with bad.jpg.
 There may be a bug (or possibility for improvement) here, but the general statement

> I think that it is a bug if the length of the word affects the interpretation of "I".

doesn't hold because OCR programs are giant collections of probabilities, thresholds, ratios, and conditions. The code that tries to figure out 1Il and 0O confusion in words, in particular, is a big set of heuristics using counts of various character types and guesses about what the most likely output string is.

and +1 for using the mailing list, not the bug tracker, for asking questions
  I want to train my own eng.cube.nn for cube engine, but I cannot find any idea from the trainning directory. What can I do for it?
 But I need to train my cube for my research, have any other way, even not in tesseract, to train the .cube.nn file? I'm so curious about where's the original cube model from, could any one give me some advises about it?
 The code for training the neural network was never released, so nobody can help you with this. Sorry.
 What's the best way for one to insert their own single-character recognition algorithm into the overall Tessaract system?
  I am trying to use the tesseract-c_api-demo.py script as follows:
###### 

import os
import sys
import ctypes
# Demo variables

lang = "eng"
filename = "../phototest.tif"
libpath = "/usr/local/lib64/"
libpath_w = "../vs2010/DLL_Release/"
TESSDATA_PREFIX = os.environ.get('TESSDATA_PREFIX')
if not TESSDATA_PREFIX:
    TESSDATA_PREFIX = "../"
libname = libpath + "libtesseract.so.3.0.2"
tesseract = ctypes.cdll.LoadLibrary(libname)

tesseract.TessVersion.restype = ctypes.c_char_p
tesseract_version = tesseract.TessVersion()[:4]

api = tesseract.TessBaseAPICreate()
rc = tesseract.TessBaseAPIInit3(api, TESSDATA_PREFIX, lang);

text_out = tesseract.TessBaseAPIProcessPages(api, filename, None , 0);
result_text = ctypes.string_at(text_out)
print result_text
###### 

How can I set the PSM_Model for tesseract?
  On Tesseract 3.04.00 I get a segmentation fault while trying to get the orientation information for the image with arabic text.

Sample Image: http://i.imgur.com/DdLr39z.jpg

Tesseract Version:

```
$ tesseract --version
tesseract 3.04.00
 leptonica-1.72
  libjpeg 8d : libpng 1.6.18 : libtiff 4.0.6 : zlib 1.2.5
```

Ara langs in TESSDATA:

```
$ ls ara*
ara.cube.bigrams   ara.cube.lm        ara.cube.params    ara.cube.word-freq 
ara.cube.fold      ara.cube.nn        ara.cube.size      ara.traineddata
```

Segmentation Fault:

```
$ tesseract arabic_4.jpg stdout -psm 0 -l ara
[1]    3721 segmentation fault  tesseract ~/Downloads/arabic_4.jpg stdout -psm 0 -l ara
```

This does not happen when I pass the language as `eng` instead of  `ara` but then ofcourse the results and confidence factor are extremely low. 

```
$ tesseract ~/Downloads/arabic_4.jpg stdout -psm 0 -l eng
Orientation: 0
Orientation in degrees: 0
Orientation confidence: 4.00
Script: 1
Script confidence: 8.08
```
  I'm trying the first example: `pts.image_to_string(PIL.Image.open('/home/shefuto/Pictures/jpgpytesseract.jpg'))`
and it gives me this error. `OSError(2, 'No such file or directory')`

At some point a subprocess is being invoked, and analyzing the `locals()`, i get these 

```
ipdb> locals()

{'lang': None, 
'input_filename': '/tmp/tess_qi4zyS.bmp', 
'boxes': False, 
'command': ['tesseract', '/tmp/tess_qi4zyS.bmp', '/tmp/tess_7uERUt'], 
'config': None, 
'output_filename_base': '/tmp/tess_7uERUt'}
```

These are the locals when the exception occured here: `/pytesseract/pytesseract.py(94)`

The complete traceback is here:

```
> <ipython-input-15-c7d82a7070cb>(1)<module>()
----> 1 pts.image_to_string(PIL.Image.open('/home/shefuto/Pictures/jpgpytesseract.jpg'))

ipdb> a
ipdb> d
> /home/shefuto/ve/tmp2/local/lib/python2.7/site-packages/pytesseract/pytesseract.py(172)image_to_string()
    170     finally:
    171         cleanup(input_file_name)
--> 172         cleanup(output_file_name)
    173 
    174 def main():

ipdb> d
> /home/shefuto/ve/tmp2/local/lib/python2.7/site-packages/pytesseract/pytesseract.py(94)run_tesseract()
     92 
     93     proc = subprocess.Popen(command,
---> 94             stderr=subprocess.PIPE)
     95     return (proc.wait(), proc.stderr.read())
     96 

ipdb> d
> /usr/lib/python2.7/subprocess.py(724)__init__()
    722                     pass
    723 
--> 724             raise exc_type, exc_value, exc_trace
    725 
    726         if mswindows:

ipdb> d
> /usr/lib/python2.7/subprocess.py(1327)_execute_child()
   1325                         raise
   1326                 child_exception = pickle.loads(data)
-> 1327                 raise child_exception
   1328 
   1329 
```

The source file '/home/shefuto/Pictures/jpgpytesseract.jpg' exists, so it appears it tries to access those temporary files when they're not created yet.
  A related stackoverflow question is here: http://stackoverflow.com/questions/20599768/tesseract-ocr-recognize-complete-dictionary-words-only. 

Basically what I want to achieve is to ask Tesseract to recognize only complete words included in my custom dictionary (lang: chi_sim), or to find the best match. 

Following the instruction in https://github.com/tesseract-ocr/tesseract/blob/master/doc/tesseract.1.asc#languages, I applied a config file with the following content:

```
load_system_dawg     F
load_freq_dawg       F
user_words_file      /path/to/my/dictonary.user-words
```

But this doesn't seem to work: when I ask Tesseract to recognize word from this image

 ![x](https://cloud.githubusercontent.com/assets/1710087/14453308/a897e3dc-00c6-11e6-9637-2419cddace49.jpg),

`$ tesseract /path/to/the/above/image.jpg stdout -l chi_sim /path/to/my/config_file`

 it gives me `Á°ùÈÖ∏ÂòõÂ∫∏ÂñπÁì¢ËÜè` which is not in the dictionary at all. The best match is supposed to be `Á°ùÈÖ∏Âí™Â∫∑Âîë‰π≥ËÜè` which is included in the dictionary.

I searched around and couldn't find a solution. Please help me out. Thank you.
 You could try playing with some of the dictionary related parameters to see if you can achieve the results that you want:

```
$ tesseract --print-parameters | grep dic
```

In particular, these two look like they might have promise:

```
language_model_penalty_non_freq_dict_word   0.1 Penalty for words not in the frequent word dictionary
language_model_penalty_non_dict_word    0.15    Penalty for non-dictionary words
```
 Thank you, @amitdo and @tfmorris. I tried both `language_model_penalty_non_freq_dict_word` and `language_model_penalty_non_dict_word` but had no luck.
  Version: tesseract **3.01**
Other version: the master branch contains updated code and has not been tested
Result: ASSERT failure
Input: specific image (cannot be shared) with table like structure
Keytext: `bb_it.data()->owner() == this:Error:Assert failed:in file colpartition.cpp, line 205`

(Mixing blobs/bboxes etc. for easier reading)

ColPartitions are created from bboxes that were placed on a grid (see `colpartition.cpp::void ColPartition::AddBox(BLOBNBOX* bbox)`). It is normal that one bbox is in multiple positions (that are subsequent) and there can be multiple bboxes in one position on the grid. It can happen, that more ColPartitions are created from the same bbox (the bbox iteration returns bbox1 from [x,y] and a new ColPartition is created, then a different bbox2 is returned from the same [x,y] and another ColPartition is created, afterwards we move to [x+1, y] and get bbox1 again and yet another new ColPartition is created (see `colfind.cpp::ColPartitionSet* ColumnFinder::PartitionsAtGridY(int grid_y)`).
So far so good, we have two ColPartitions with the same bbox and we move on to merging.

These two ColPartitions are correctly selected for merging to another one (see `colpartition.cpp::bool ColPartition::Unique(ColPartition* other, WidthCallback* cb)`) BUT it can happen that `void ColPartition::AddBox(BLOBNBOX* bbox)` does _add_ them twice under very specific conditions. The result is a crash/assert (whatever you call it) in `colpartition.cpp::void ColPartition::ClaimBoxes(WidthCallback* cb)` where the list is iterated and owner is chosen. Now, if there is an item after the second position of the specific bbox, the assert (`ASSERT_HOST(bb_it.data()->owner() == this);`) is triggered because the first time it encounters the bbox the owner is set to `null` and the second time the assert `expects ==this`).

How can the box be added twice?
The specific bbox is
`
{bot_left={xcoord=1201 ycoord=1158 } top_right={xcoord=1303 ycoord=1251 } }
`
The first merge calls
`void ColPartition::AddBox(BLOBNBOX* bbox)` -> `boxes_.add_sorted(SortByBoxBottom<BLOBNBOX>, true, bbox);` (it is a vertical box). 
and it will be added to the end by

```
  // Check for adding at the end.
  if (last == NULL || comparator(&last->data, &new_data) < 0) {
```

which _can_ still be correct (`{bot_left={xcoord=1306 ycoord=1157 } top_right={xcoord=1494 ycoord=1347 } }`). 

But the second call should discard adding because of the `unique` parameter. But because there are bboxes at the beginning and only bottom is checked 

```
int SortByBoxBottom(const void* void1, const void* void2) {
  // The void*s are actually doubly indirected, so get rid of one level.
  const BBC* p1 = *reinterpret_cast<const BBC* const *>(void1);
  const BBC* p2 = *reinterpret_cast<const BBC* const *>(void2);
  int result = p1->bounding_box().bottom() - p2->bounding_box().bottom();
```

it is added again before the other value is encountered (`box = {bot_left={xcoord=1405 ycoord=1209 } top_right={xcoord=1475 ycoord=1259 } }`).

The iteration compares it with the following:

```
{bot_left={xcoord=1408 ycoord=1293 } top_right={xcoord=1440 ycoord=1337 } }
{bot_left={xcoord=749 ycoord=1142 } top_right={xcoord=933 ycoord=1258 } }
-->>{bot_left={xcoord=1405 ycoord=1209 } top_right={xcoord=1475 ycoord=1259 } }
```

Solution:
One possible solution is to iterate the other bboxes as well if `unique` is set and discard adding if it finds the same data

```
--- a/tesseract/ccutil/clst.cpp
+++ b/tesseract/ccutil/clst.cpp
@@ -252,8 +252,23 @@ bool CLIST::add_sorted(int comparator(const void*, const void*),
     }
     if (it.cycled_list())
       it.add_to_end(new_data);
     else
+    {
+        // well, it can happen that sorting is not unique because of the condition above
+        if (unique)
+        {
+            CLIST_ITERATOR it_cont(it);
+            for (; !it_cont.cycled_list(); it_cont.forward())
+            {
+              void* data = it_cont.data();
+              if (data == new_data) {
+                return false;
+              }
+            }
+        }
+
       it.add_before_then_move(new_data);
+    }
     return true;
   }
   return false;
```
 Unless someone wants to check the current master, feel free to close the issue.
 as mentioned above, the specific image cannot be made publicly available
 @vidiecan, if it is not possible to create a public demo image, maybe you can nevertheless provide a code patch which fixes the problem? Or is it possible to send the problematic image privately to one of the developers working an tesseract, so that he / she can fix the problem?
  First of all, thanks for adding support to tesseract finally. From quickly inspecting Persian related codes on tesseract I reached to https://github.com/tesseract-ocr/tesseract/blob/master/training/language-specific.sh#L520 which I can say speculatively is not a good set of fonts for training Persian printed text and can result in poor performance of OCR quality as most Persian fonts don't have the style these fonts have. On ["Font recognition using Variogram fractal dimension"](http://files.matlabsite.com/docs/papers/icee2012/2/icee2012-174.pdf), a good set of Persian fonts is introduced (second page, at the bottom) which as you can see there also, it is different from favorites Arabic language fonts (even the fact both are using Arabic script). So for training Persian OCR for tesseract I suggest adding or replacing current fonts with these free fonts, Nazli (i.e. Nazanin as indicated on that article) and Titr from Debian [fonts-farsiweb](https://packages.debian.org/search?keywords=fonts-farsiweb) package and also XB Zar and XB Yaghut from OFL licensed [xfonts](http://wiki.irmug.com/index.php/X_Series_2). I think also @roozbehp @behdad from Google can help you on this. Thank you.
  tesseract -v provides version info for the binary.

It would be helpful to have version info in all training tools also.

Thanks!
 It might be useful to have them write that version into their output as well, so one can tell the provenance of the trained data.
 Possible actions:
* Support command line options `-v`, `--version` for all executables.
* Write version information in file information for Windows executables.

Potential problems:
* Executable and shared library `libtesseract` might have different versions.

Open question:
* What exactly should be shown? Version number only for tagged release? Branch version? Git release? Compilation date? * Windows DLL files can include file information like executables (also the version info).
* Any shared library could include an exported function like `const char *tesseractLibraryVersion()` which returns a version string. [3.05.01](https://github.com/tesseract-ocr/tesseract/releases/tag/3.05.01) was released shortly after your question, so this is something for the next release. The current situation regarding version information is confusing:

- There is a Tesseract package version (not shown by `tesseract -v` as I would have expected).
- There is a Tesseract data version used for the traineddata (shown by `tesseract -v`).
- There are lots of places with version information (`configure.ac`, `ccutil/version.h`, `vs2010/port/vcsversion.h`, `vs2010/port/vcsversion.h`, `CMakeLists.txt`, maybe more).

And what about PR #593? The traineddata version is only partially different. It starts with `4.00.00alpha` for all newer data (best and fast) and continues with additional information which is different: `4.00.00alpha:Vietnamese:synth20170629:[1,36,0,1Ct3,3,16Mp3,3Lfys64Lfx96Lrx96Lfx512O1c1]`.

It looks like the current code only uses that version string to display it for users. There is still no compatibility check which requests compatible versions ‚Äì that check must be done by the users.  ![test](https://cloud.githubusercontent.com/assets/12631283/14032336/4c60fa96-f1cf-11e5-99a5-198b1445958a.png)

(I'm using head: 3.05.00dev)

When ocr'ing a small one or two line image (with the default settings), I'm getting the following error:
Error in pixGenHalftoneMask: pix too small: w = 610, h = 71

But the ocr is successful.

In textord/imagefind.cpp, FindImages is calling pixGenHalftoneMask (a leptonica function) which is throwing the error and returning null.

FindImages is then executing it's backup plan, which works fine (such a small image doesn't need multiple images regions). It's backup plan is to call pixCreate and then return the result.

The minimum size for pixGenHalftoneMask to work is 100x100 pixels. Perhaps FindImages should
just go with plan 'b' if the size of the image is too small. This would still work fine and avoid throwing the error. I don't know if there is a way for teseract to know what the minimum size is (in case it changes).
 The min size is defined like this at the top of src/pageseg.c in leptonica:

```
/* These functions are not intended to work on very low-res images */
```

static const l_int32  MinWidth = 100;
static const l_int32  MinHeight = 100;

It doesn't seem that they are likely to change.

Here's my patch:

index 05047ca..0084ac8 100644
--- a/textord/imagefind.cpp
+++ b/textord/imagefind.cpp
@@ -72,6 +72,12 @@ Pix\* ImageFind::FindImages(Pix\* pix) {
   pixDisplayWrite(pixr, textord_tabfind_show_images);

   // Get the halftone mask directly from Leptonica.
+  if (pixGetWidth(pixr) < 100 || pixGetHeight(pixr) < 100)
+  {
+    // leptonica will throw and error and return null
+    pixDestroy(&pixr);
+    return pixCreate(pixGetWidth(pix), pixGetHeight(pix), 1);
+  }
   l_int32 ht_found = 0;
   Pix *pixht2 = pixGenHalftoneMask(pixr, NULL, &ht_found,
                                    textord_tabfind_show_images);
 An alternative is for Leptonica to not spam stderr. I'm honestly not sure which approach is better.
 Good point. It's returning null, and the null is being handled properly. Automatically emitting the reason for the error should be directable/configurable.

I just dug into it and found NO_CONSOLE_IO referenced from environ.h.
Maybe I needed to turn that on when I built Leptonica. Still a questionable approach.
 Scott's patch seems reasonable to me.

Testing the size in advance prevents leptonica from returning null,
and from saying that an error occurred.

Slightly simpler just to 
  return pixCopy(pixr, pix);
which works whether or not pixr exists.

re: musings about whether or not leptonica should "spam stderr":

Just a reminder that leptonica provides a significant amount of control over messages to stderr, both at compile time and at run time, and broken down to the granularity of errors, warnings and information.  The question for the leptonica client (tesseract, here) is what level of messages they want to receive on stderr, and in this case it's up to the maintainers.  If the error messages (at least) are not on, a user will have no idea why something failed if it was due to bad input to a leptonica function, for example.  On the other hand, when failures occur but are caught and handled by the client, the user may be unnecessarily concerned, when things are actually going ok.

FWIW, when I am programming and testing, I always use the default MINIMUM_SEVERITY of L_SEVERITY_INFO, which turns all messages on.
   ```
libtool: compile:  x86_64-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/training -I.. -g -Wall -Wno-uninitialized -O0 -DDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccmain -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/t                                                    esseract/api -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccutil -I/home/ra/MINGW-packages/mingw-                                                    w64-tesseract-ocr-git/src/tesseract/ccstruct -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/viewer                                                     -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/textord -I/home/ra/MINGW-packages/mingw-w64-tesserac                                                    t-ocr-git/src/tesseract/dict -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/classify -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/display -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/wordrec -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/cutil -I/home/ra/MINGW-packages/mi                                                    ngw-w64-tesseract-ocr-git/src/tesseract/vs2010/port -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/mingw64/include/le                                                    ptonica -march=x86-64 -mtune=generic -O2 -pipe -ggdb -Og -ggdb -Og -std=c++11 -MT pango_font_info.lo -MD -MP -MF .deps/p                                                    ango_font_info.Tpo -c /home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/pango_font_info.cpp  -D                                                    DLL_EXPORT -DPIC -o .libs/pango_font_info.o
In file included from C:/msys64/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/ligature_table                                                    .cpp:26:0:
C:/msys64/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/pango_font_info.h:30:30: fatal error                                                    : pango/pango-font.h: No such file or directory
compilation terminated.
Makefile:923: recipe for target 'ligature_table.lo' failed
make[1]: *** [ligature_table.lo] Error 1
make[1]: *** Waiting for unfinished jobs....
libtool: compile:  x86_64-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/training -I.. -g -Wall -Wno-uninitialized -O0 -DDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccmain -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/t                                                    esseract/api -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccutil -I/home/ra/MINGW-packages/mingw-                                                    w64-tesseract-ocr-git/src/tesseract/ccstruct -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/viewer                                                     -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/textord -I/home/ra/MINGW-packages/mingw-w64-tesserac                                                    t-ocr-git/src/tesseract/dict -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/classify -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/display -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/wordrec -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/cutil -I/home/ra/MINGW-packages/mi                                                    ngw-w64-tesseract-ocr-git/src/tesseract/vs2010/port -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/mingw64/include/le                                                    ptonica -march=x86-64 -mtune=generic -O2 -pipe -ggdb -Og -ggdb -Og -std=c++11 -MT normstrngs.lo -MD -MP -MF .deps/normst                                                    rngs.Tpo -c /home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/normstrngs.cpp  -DDLL_EXPORT -DPI                                                    C -o .libs/normstrngs.o
In file included from C:/msys64/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/pango_font_inf                                                    o.cpp:36:0:
C:/msys64/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/pango_font_info.h:30:30: fatal error                                                    : pango/pango-font.h: No such file or directory
compilation terminated.
Makefile:923: recipe for target 'pango_font_info.lo' failed
make[1]: *** [pango_font_info.lo] Error 1
C:/msys64/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/normstrngs.cpp: In function 'bool te                                                    sseract::IsUTF8Whitespace(const char*)':
C:/msys64/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/normstrngs.cpp:183:35: warning: comp                                                    arison between signed and unsigned integer expressions [-Wsign-compare]
   return SpanUTF8Whitespace(text) == strlen(text);
                                   ^
libtool: compile:  x86_64-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/training -I.. -g -Wall -Wno-uninitialized -O0 -DDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccmain -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/t                                                    esseract/api -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccutil -I/home/ra/MINGW-packages/mingw-                                                    w64-tesseract-ocr-git/src/tesseract/ccstruct -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/viewer                                                     -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/textord -I/home/ra/MINGW-packages/mingw-w64-tesserac                                                    t-ocr-git/src/tesseract/dict -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/classify -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/display -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/wordrec -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/cutil -I/home/ra/MINGW-packages/mi                                                    ngw-w64-tesseract-ocr-git/src/tesseract/vs2010/port -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/mingw64/include/le                                                    ptonica -march=x86-64 -mtune=generic -O2 -pipe -ggdb -Og -ggdb -Og -std=c++11 -MT normstrngs.lo -MD -MP -MF .deps/normst                                                    rngs.Tpo -c /home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/normstrngs.cpp -o normstrngs.o >/                                                    dev/null 2>&1
make[1]: Leaving directory '/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/build-x86_64-w64-mingw32/training'
Makefile:904: recipe for target 'training' failed
make: *** [training] Error 2
==> ERROR: A failure occurred in build().
    Aborting...

```
  make fail on cygwin64 when I have changed the file 'opencl/openclwrapper.h'  on line 67 : #define PERF_COUNT_VERBOSE 3,   

Then I change the file 'opencl/openclwrapper.h' on line 13: defined( **CYGWIN** ),  more problems come. 
 Thanks.  But  in cygwin, The define of `__CYGWIN32__` is no longer used, replaced by `__CYGWIN__`
 Excuse me, I had met a problem when I used the cmake 
pkg_check_modules(Leptonica REQUIRED lept)       this package didn't found, How can I solved it? 
By the way, I have installed the lib leptonica already, and  I finished making the tesseract by ' configure && make '. 

PS: The src file of leptonica that I downloaded  don't have the CMakeLists.txt.

Thanks.
 Thanks, I have solved this problem. 
  Please try with https://github.com/Alexpux/MINGW-packages/blob/9215e839df3c4f98ea4b160831c17ddada121dfa/mingw-w64-tesseract-ocr/build-fixes.patch

The above was used in the PKGBUILD. Direct build process is failing. Please see msgs below.

```
ra@Shree MINGW64 ~/tesseract
$ make
make  all-recursive
make[1]: Entering directory '/home/ra/tesseract'
Making all in ccutil
make[2]: Entering directory '/home/ra/tesseract/ccutil'
make[3]: Entering directory '/home/ra/tesseract/ccutil'
depbase=`echo ambigs.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG   -I/usr/local/include/leptonica -mms-bitfields -IC:/msys64/mingw64/include/pango-1.0 -IC:/msys64/mingw64/include/glib-2.0 -IC:/msys64/mingw64/lib/glib-2.0/include -mms-bitfields -IC:/msys64/mingw64/include/cairo -IC:/msys64/mingw64/include/pixman-1 -IC:/msys64/mingw64/include -I/mingw64/include/freetype2 -I/mingw64/include/libpng16 -I/mingw64/include/harfbuzz -I/mingw64/include/glib-2.0 -I/mingw64/lib/glib-2.0/include -IC:/msys64/mingw64/include -IC:/msys64/mingw64/include/freetype2 -IC:/msys64/mingw64/include -IC:/msys64/mingw64/include/harfbuzz -IC:/msys64/mingw64/include/glib-2.0 -IC:/msys64/mingw64/lib/glib-2.0/include -IC:/msys64/mingw64/include/libpng16 -DTESSDATA_PREFIX=/usr/local/share/  -g -O2 -std=c++11 -MT ambigs.lo -MD -MP -MF $depbase.Tpo -c -o ambigs.lo ambigs.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I/usr/local/include/leptonica -mms-bitfields -IC:/msys64/mingw64/include/pango-1.0 -IC:/msys64/mingw64/include/glib-2.0 -IC:/msys64/mingw64/lib/glib-2.0/include -mms-bitfields -IC:/msys64/mingw64/include/cairo -IC:/msys64/mingw64/include/pixman-1 -IC:/msys64/mingw64/include -I/mingw64/include/freetype2 -I/mingw64/include/libpng16 -I/mingw64/include/harfbuzz -I/mingw64/include/glib-2.0 -I/mingw64/lib/glib-2.0/include -IC:/msys64/mingw64/include -IC:/msys64/mingw64/include/freetype2 -IC:/msys64/mingw64/include -IC:/msys64/mingw64/include/harfbuzz -IC:/msys64/mingw64/include/glib-2.0 -IC:/msys64/mingw64/lib/glib-2.0/include -IC:/msys64/mingw64/include/libpng16 -DTESSDATA_PREFIX=/usr/local/share/ -g -O2 -std=c++11 -MT ambigs.lo -MD -MP -MF .deps/ambigs.Tpo -c ambigs.cpp  -DDLL_EXPORT -DPIC -o .libs/ambigs.o
ambigs.cpp:31:22: fatal error: strtok_r.h: No such file or directory
compilation terminated.
Makefile:572: recipe for target 'ambigs.lo' failed
make[3]: *** [ambigs.lo] Error 1
make[3]: Leaving directory '/home/ra/tesseract/ccutil'
Makefile:614: recipe for target 'all-recursive' failed
make[2]: *** [all-recursive] Error 1
make[2]: Leaving directory '/home/ra/tesseract/ccutil'
Makefile:470: recipe for target 'all-recursive' failed
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory '/home/ra/tesseract'
Makefile:378: recipe for target 'all' failed
make: *** [all] Error 2

```
 Zdenko, thanks for your suggestion. It is working now. line 88

> > please try to change mingw32_) to mingw_) in configure.ac (line 78?) and then rebuild autotools (./autogen.sh ...)
  This enables all OpenType ligatures for a specific font, where
available. Specifically, it explicitly enables the OpenType
features liga (standard ligatures), hlig (historical ligatures),
clig (contextual ligatures), and dlig (discretionary ligatures).

This feature requires Pango 1.38 or newer.
 Hi Amit!

Yeah, I had considered doing that, but wasn't sure whether it was worth it. Thinking about it more though, I agree with you (and there's only one #ifdef needed, so it ain't too ugly).

Thanks for looking it over :)
  Check my previous summary here http://www.visionopen.com/forums/topic/bugs-in-current-tesseract/
Solutions are provided as follows:

1) LIST -> LIST_TESSERACT
in all files

2) remove_reference -> remove_reference_Tesseract
in all files

How can I become a developer of tesseract on github?

Cheers
Pei
 Oh, yes zdenop.
You are correct. I met this problem 2 years ago. At that time, I used to use a "global namespace", something like 
**using namespace std;** instead of **std::**

It looks like tesseract is using the SAME key words as in C++ compiler.

Thank you... 
   tesseract -v
tesseract 3.05.00dev
 leptonica-1.73
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 OpenCL info:
  Found 1 platforms.
  Platform name: NVIDIA CUDA.
  Version: OpenCL 1.1 CUDA 7.0.28.
  Found 1 devices.
    Device 1 name: GRID K520.
root@ip-172-31-35-3:~# tesseract 1.tiff output
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performing profiling.

[DS] Device: "GRID K520" (OpenCL) evaluation...
[OD] write binary[kernel-GRID_K520.bin] successfully
[DS] Device: "GRID K520" (OpenCL) evaluated
[DS]          composeRGBPixel: 0.021918 (w=1.2)
[DS]            HistogramRect: 0.008381 (w=2.4)
[DS]       ThresholdRectToPix: 0.010258 (w=4.5)
[DS]        getLineMasksMorph: 0.005291 (w=5.0)
[DS]                    Score: 0.119031

[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
[DS]          composeRGBPixel: 0.021650 (w=1.2)
[DS]            HistogramRect: 0.072183 (w=2.4)
[DS]       ThresholdRectToPix: 0.041287 (w=4.5)
[DS]        getLineMasksMorph: 0.151936 (w=5.0)
[DS]                    Score: 1.144687
[DS] Scores written to file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:GRID K520 score is 0.119031
[DS] Device[2] 0:(null) score is 1.144687
[DS] Selected Device[1]: "GRID K520" (OpenCL)
fseek(data_file_, static_cast<size_t>(offset_table_[tessdata_type]), SEEK_SET) == 0:Error:Assert failed:in file ../ccutil/tessdatamanager.h, line 173
Segmentation fault (core dumped)
   in doc "[addon](https://github.com/tesseract-ocr/tesseract/wiki/AddOns)" 
Community training projects

Chinese simplefied: see issue 296; download http://ubuntuone.com/p/3Yw/ 
    The goal is to run an AWS Amazon instance (Ubuntu 14.04) with GPU support to test the difference in OCR speed with a large GPU.   I have Nvidia drivers and OpenCL installed.
  Ive downloaded, compiled and installed leptonica 1.73 (latest version), downloaded the latest tesseract source.  I run autogen then ./configure --enable-opencl but get the following error.

checking for leptonica... yes
checking for l_generateCIDataForPdf in -llept... no
configure: error: leptonica library with pdf support (>= 1.71) is missing

Ive searched for at least 4 hours for the answer to this but have had no luck.  Im not a programmer so am not that familiar with the use or locations of lib files.    This is probably just a variable problem but I cant find any reference to it.  
 Hello @dthrock ,

I've got exactly the same proble, on Ubuntu 14.04.

I had to go to leptonica site, download the source and build it.

After that, I run ./configure --with-extra-includes=/usr/local/include and --with-extra-libaries=/usr/local/lib

Hope it would help you.
 I have the same problem, while leptonica-1.74.1, mac OS 10.12.3 (16D32)

localhost:tesseract-4.00.00alpha didi$ brew install leptonica
Updating Homebrew...
Warning: leptonica-1.74.1 already installed

solve this problem by this command:
CPPFLAGS="-I/usr/local/include" LDFLAGS="-L/usr/local/lib" ./configure
 @vitamin thank u. your suggestion solved my issue too .  This builds a docker image based on the project .travis.yml
 @zdenop Not having to create a separate script to invoke the tesseract build.
  I'm having issues with getting Tesseract to read text out of an image.  Its seems to not read the text in the image in its original size.

![bowenpeak](https://cloud.githubusercontent.com/assets/17915164/13863515/410b1a02-ecff-11e5-9c93-f63825576e21.png)

But when I increase the canvas size it then picks up the text.  Any Ideas on what maybe causing this?

![bowenpeak_lrg](https://cloud.githubusercontent.com/assets/17915164/13863517/47b6f010-ecff-11e5-91a0-7b2c7548f493.png)
  Good catch. There seem to be more errors of this kind (e. g. #276).
 The trick is to compile with `-Wmissing-format-attribute`, fix all related warnings and iterate this until no format related warnings remain. Projects like Tesseract which never used gcc's format attribute typically have lots of format errors. I just started the search, and the current count is 6.

Fixing those format errors is one task, another one is adding the format attribute and the compiler options where needed, so future contributions won't introduce new errors.
 That flag would result in warnings for all functions with printf or scanf like arguments which don't use the format attribute. Then it is necessary to add a format function attribute to each of those function declarations. After this, gcc will know which functions work similar to printf or scanf and report all errors (if that warning is enabled, for example with `-Wall -Wextra`).

Example:

```
  ../../../../ccutil/errcode.cpp:64:45: warning: function might be possible candidate for ‚Äògnu_printf‚Äô format attribute [-Wsuggest-attribute=format]
  ../../../../cutil/callcpp.cpp:47:29: warning: function might be possible candidate for ‚Äògnu_printf‚Äô format attribute [-Wsuggest-attribute=format]
  ../../../../viewer/scrollview.cpp:402:47: warning: function might be possible candidate for ‚Äògnu_printf‚Äô format attribute [-Wsuggest-attribute=format]
  ../../../../viewer/scrollview.cpp:573:47: warning: function might be possible candidate for ‚Äògnu_printf‚Äô format attribute [-Wsuggest-attribute=format]
```

And yes, the missing `%` would be reported, too.
  Hello everyone
I'm new with tesseract and I was wondering if I could force Tesseract to use a small dictionnary and to return the word which is the most similaire from the dictionnary
Thx
  In version 3.03

In the man page for TESSERACT(1) under the title Languages the following items are misspelt.

"Croation" should be "Croatian" (https://en.wikipedia.org/wiki/Croatian_language)
"Slovakian" should be "Slovak" (https://en.wikipedia.org/wiki/Slovak_language)
  I git cloned the tesseract-ocr repositories on ubuntu 14.04 with the following structure

tesseract-ocr
tesseract-ocr/tesseract
tesseract-ocr/tessdata
tesseract-ocr/langdata

The build process (autogen, make, sudo make install, sudo ldconfig)  put the tessdata files with configs and tessconfigs subdirectories and pdf.ttf in  /usr/local/share/tessdata

This puts tessdata related files in two locations:
tesseract-ocr/tessdata
and
/usr/local/share/tessdata
(in addition to the source in tesseract-ocr/tesseract/tessdata)

As a regular user I cannot copy the tesddata files to  /usr/local/share/tessdata

$ cp ./tessdata/san.traineddata /usr/local/share/tessdata
cp: cannot create regular file ‚Äò/usr/local/share/tessdata/san.traineddata‚Äô: Permission denied

---

$ export TESSDATA_PREFIX=/home/shree/tesseract-ocr
$ echo $TESSDATA_PREFIX
/home/shree/tesseract-ocr

If I use the above tessdata prefix, then tesseract does not find the config files ..

$ tesseract   testing/phototest.jpg testing/phototest-jpg  -l eng -psm 3
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
$ tesseract   testing/phototest.jpg testing/phototest-jpg  -l eng -psm 3 pdf
read_params_file: Can't open pdf
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
$ tesseract   testing/phototest.jpg testing/phototest-jpg  -l eng -psm 3 tsv
read_params_file: Can't open tsv

---

$ export TESSDATA_PREFIX=/usr/local/share/tessdata
$ echo $TESSDATA_PREFIX
/usr/local/share/tessdata

If I use the above then tesseract does not find the traineddata files even when tessdata-dir is pointing to the correct location

$  tesseract --tessdata-dir=../  testing/phototest.jpg testing/phototest-jpg  -l eng -psm 3
Error opening data file /usr/local/share/tessdata/eng.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your "tessdata" directory.
Failed loading language 'eng'
Tesseract couldn't load any languages!
Could not initialize tesseract.

$ tesseract --tessdata-dir=/home/shree/tesseract-ocr  testing/phototest.jpg testing/phototest-jpg  -l eng -psm 3
Error opening data file /usr/local/share/tessdata/eng.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your "tessdata" directory.
Failed loading language 'eng'
Tesseract couldn't load any languages!
Could not initialize tesseract.

---

I can get around it by copying configs, tessconfigs and pdf.ttf to
/home/shree/tesseract-ocr/tessdata directory.

But this should not be required. What am I missing in the process?
 Thanks, @amitdo 

Need at a minimum to copy
osd.traineddata
eng.*
     char\* GetUTF8Text(struct ETEXT_DESC\* monitor);
I write method GetUTF8Text with ETEXT_DESC but error when debug. How stop ocring.
char\* TessBaseAPI::GetUTF8Text(struct ETEXT_DESC\* monitor) {
  if (tesseract_ == NULL ||
      (!recognition_done_ && Recognize(monitor) < 0))
    return NULL;
  STRING text("");
  ResultIterator _it = GetIterator();
  do {
    if (it->Empty(RIL_PARA)) continue;
    char *para_text = it->GetUTF8Text(RIL_PARA);
    text += para_text;
    delete []para_text;
  } while (it->Next(RIL_PARA));
  char_ result = new char[text.length() + 1];
  strncpy(result, text.string(), text.length() + 1);
  delete it;
  return result;
}

ETEXT_DESC monitor;
monitor.cancel = NULL;
monitor.cancel_this = NULL;
char *text = nat->api.GetUTF8Text(&monitor);
  https://github.com/tesseract-ocr/tesseract/blob/master/ChangeLog
is updated only till 2014-02-04 v3.03

Should the changelog also reflect the changes in the current development (master branch) eg. TSV output as new features are added?
  I've worked with the library in the past when I was working with VS2008 and the precompiled binaries but now that I've been using VS2013 I cannot seem to get the library to work without some sort of memory leak detected at the end of my application's runtime.

Run the application with no calls to the library and no leaks detected.

Run the application with this code:

---

tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI;
delete api;

---

And here is the output when the application wraps up:

---

Detected memory leaks!
Dumping objects ->
{65747} normal block at 0x035DC108, 512 bytes long.
 Data: <0 3   3   3   3 > 30 D3 33 01 D8 E3 33 01 C0 E4 33 01 C0 E9 33 01 

{65746} normal block at 0x035DBEC8, 512 bytes long.
 Data: <  3 x 3   3 < 3 > 8C D0 33 01 78 D0 33 01 F4 D1 33 01 3C D8 33 01 

{203} normal block at 0x00BDAFD0, 32 bytes long.
 Data: <  3   3  x6  w6 > F8 D3 33 01 F8 E2 33 01 14 78 36 01 C0 77 36 01 

{198} normal block at 0x00BDADE0, 256 bytes long.
 Data: <  3   3   3 ` 3 > EC CF 33 01 B0 CF 33 01 08 D0 33 01 60 D0 33 01 

{170} normal block at 0x00BDA9C8, 80 bytes long.
 Data: <    @           > 00 00 00 00 40 00 00 00 E0 AD BD 00 00 00 00 00 

Object dump complete.

---

The block sizes are consistent for this test each time it runs.  If I make calls to the library the number of leaks increases with varying block sizes.

Any help is greatly appreciated.  I would hate to have to go back to VS2008 just to be able to use the precompiled binaries.

Thanks a bunch!
 I followed the directions here: [http://vorba.ch/2014/tesseract-3.03-vs2013.html](http://vorba.ch/2014/tesseract-3.03-vs2013.html).  Everything compiled smoothly but same result.

I would love to help with the development but I've been working on this for a few weeks and I just really can't put any more time into it due to family obligations.  Sorry.

I think I'm going to have to end up using the tesseract-dll.exe cmd line application to do the dirty work (seems to not have the issues I am having with the windows app) and move on.
 Hi have the saim problem but only in mfc project
in console project no leaks detected

here is the VLD log

`---------- Block 65682 at 0x05A705C8: 512 bytes ----------
  Leak Hash: 0xB9C6E0DA, Count: 1, Total 512 bytes
  Call Stack (TID 25176):
    ntdll.dll!RtlAllocateHeap()
    f:\dd\vctools\vc7libs\ship\atlmfc\src\mfc\afxmem.cpp (336): PokeGuiManage.exe!operator new[]() + 0x9 bytes
    c:\vanilly\dev\tesseract1\ccutil\genericvector.h (626): PokeGuiManage.exe!GenericVector<tesseract::BoolParam *>::reserve() + 0x19 bytes
    c:\vanilly\dev\tesseract1\ccutil\genericvector.h (642): PokeGuiManage.exe!GenericVector<tesseract::BoolParam *>::double_the_size()
    c:\vanilly\dev\tesseract1\ccutil\genericvector.h (741): PokeGuiManage.exe!GenericVector<tesseract::BoolParam *>::push_back()
    c:\vanilly\dev\tesseract1\ccutil\params.h (175): PokeGuiManage.exe!tesseract::BoolParam::BoolParam()
    c:\vanilly\dev\tesseract1\textord\oldbasel.cpp (39): PokeGuiManage.exe!`dynamic initializer for 'textord_oldbl_debug''() + 0x21 bytes
    d:\th\minkernel\crts\ucrt\src\appcrt\startup\initterm.cpp (22): PokeGuiManage.exe!_initterm()
    f:\dd\vctools\crt\vcstartup\src\startup\exe_common.inl (221): PokeGuiManage.exe!__scrt_common_main_seh() + 0xF bytes
    f:\dd\vctools\crt\vcstartup\src\startup\exe_common.inl (300): PokeGuiManage.exe!__scrt_common_main()
    f:\dd\vctools\crt\vcstartup\src\startup\exe_wwinmain.cpp (17): PokeGuiManage.exe!wWinMainCRTStartup()
    kernel32.dll!BaseThreadInitThunk() + 0x12 bytes
    ntdll.dll!RtlInitializeExceptionChain() + 0xEF bytes
    ntdll.dll!RtlInitializeExceptionChain() + 0xC2 bytes
  Data:
    C4 0F B5 01    9C C0 B8 01    D4 C0 B8 01    68 C1 B8 01     ........ ....h...
    7C C2 B8 01    20 C2 B8 01    64 C2 B8 01    3C C2 B8 01     |....... d...<...
    1C C7 B8 01    E8 C6 B8 01    C8 D1 D0 01    A4 D5 D0 01     ........ ........
    FC D5 D0 01    D0 D7 D0 01    88 D7 D0 01    74 D7 D0 01     ........ ....t...
    EC D7 D0 01    48 D7 D0 01    74 E3 D0 01    54 E6 D0 01     ....H... t...T...
    B8 E7 D0 01    64 EA D0 01    8C E7 D0 01    24 E9 D0 01     ....d... ....$...
    CC E7 D0 01    24 E8 D0 01    30 EB D0 01    1C EC D0 01     ....$... 0.......
    FC E9 D0 01    F0 EB D0 01    F8 EA D0 01    E0 EA D0 01     ........ ........
    50 EA D0 01    CC EA D0 01    3C E9 D0 01    74 EB D0 01     P....... <...t...
    10 EA D0 01    80 EC D0 01    34 EE D0 01    10 EE D0 01     ........ 4.......
    5C EE D0 01    DC EF D0 01    F4 EF D0 01    48 F1 D0 01     ....... ....H...
    68 F2 D0 01    00 F3 D0 01    E4 F2 D0 01    14 F3 D0 01     h....... ........
    40 F3 D0 01    CC F2 D0 01    4C F6 D0 01    68 F6 D0 01     @....... L...h...
    7C F6 D0 01    E8 F8 D0 01    6C FB D0 01    EC FA D0 01     |....... l.......
    40 FB D0 01    7C FA D0 01    D0 FA D0 01    08 FB D0 01     @...|... ........
    BC FA D0 01    24 FB D0 01    84 FB D0 01    14 FE D0 01     ....$... ........

Visual Leak Detector detected 5 memory leaks (1572 bytes).
Largest number used: 3188036 bytes.
Total allocations: 3297978 bytes.
Visual Leak Detector is now exiting.`
 Fixed in #449   I integrated Tesseract C/C++, version 3.x, to read English OCR on images.

It‚Äôs working pretty good, but very slow. It takes close to 1000ms (1 second) to read the attached image (00060.jpg) on my quad-core laptop.

I‚Äôm not using the Cube engine, and I‚Äôm feeding only binary images to the OCR reader.

Any way to make it faster. Any ideas on how to make Tesseract read faster?
thanks
![00060](https://cloud.githubusercontent.com/assets/9968625/13674495/ac261db4-e6ab-11e5-9b4a-ad91d5b4ff87.jpg)
 You can already run 4 parallel instances of Tesseract on your quad core, then it will read 4  images in about the same time. Introducing multi threading would not help to reduce the time needed for an OCR of many images. I am working on a project where OCR with Tesseract would take nearly 7 years on a single core, but luckily I can try to get many computers and use their cores, so the time can be reduced to a few days.
Using compiler settings which are optimized for your CPU helps to gain a few percent, but I am afraid that for a larger gain different algorithms in Tesseract and its libraries would be needed.
 Besides the OCR, we have other things that need to run on the other cores.
I believe, the main issue that's slowing down Tesseract is the way memory is managed.
Too many memory allocations (new function) and releases (delete or delete [] functions) do slow down the reader.
In the past, I did use a different OCR engine, and it was allocating up-front large buffers to store all the needed data (large buffer of blobs, a large buffer of lines, a large buffer of words and their corresponding data), the buffers were just being indexed as we were reading the data from an image. The large buffers were allocated only once upon ocr engine initialization and release only once upon ocr engine shutdown. This memory management scheme was very efficient computational-time-wise.
Are there any settings for Tesseract that are known to be computationally intensive?
any tricks to speed up Tesseract?
 What evidence is your memory management speculation based on?
 I'm not speculating anything. The reality is that TesseRact takes more than 3 seconds to read the above image that I initially attached (I use VS2010). When I use the console test application that comes with the TesseRact, it takes about the same time (more than 3 seconds). 

Anyone would speculate a lot in 3 seconds

I have more than 20 years in machine vision. I used several OCR engines in the past. Actually I have one -in house- that reads the same image in less than 100ms, but our engine is designed more for reading a single line of text (i.e. it returns a single line of text).

TesseRact database is not that large. Most of the techniques used by TesseRact are quite standard in the OCR-area (page layout, line extraction, possible character extraction, word forming, and then several phases of classification). However, the TesseRact manages very badly memory usage. why? it takes more than 3 seconds to read a typical texted-image.

please if you're not bringing any meaningful ideas to my posting, just spare me your comment.
 @ychtioui, as you have spent many years in machine vision, you know quite well that there are lots of ways why programs can be slow. Memory management is just one of them. Even with a lot of experience, I'd start running performance analyzers to investigate performance issues. Of course I can guess what might be possible reasons and try to improve the software based on that guesses, but improvements based on evidence (like the result of a performance analysis) are more efficient. Don't you think so, too? Do you have a chance to run a performance analysis?
 I'm running version 3.02
I'm going through different sections of the reader, and checking which section is taking the most time.

is it typical to read images (such as mine attached above) in a few seconds? 

thanks for your comments.
 thanks amitdo.
I'm using 3.02 but the C/C++ version of Tesseract.
I couldn't find the setting -O3 in the source files. where is it?
 @ychtioui said in a post above "I use VS2010" so using Windows.
 I use vs2010 on a Windows 7 pc.
Project settings or building options won't change much the read speed.
Tesseract was designed in research labs. Most of the key sections of the reader are speed-don't-care.
I used some performance tools to analyze where most of the computation time is spent. 
In the page layout section, the blob analyzer does a lot of new/delete. This is very time consuming. The attached image above has more than 3600 blobs. Besides a number of processings are done on each blob (distance transform, finding the enclosing rectangle, measuring blob parameters, etc.). The allocations (new) and the release (delete) of all these blobs is very time consuming. 
If we use a global array (allocate upfront) of blobs (exactly object BLOBNBOX) and whenever we need a blob, just get one index from the array. The array will be released once when we shut down the engine. 
I used this concept in another single line ocr reader and it's super fast.
 Hi @ychtioui I am newbie and saw your first comment that you are able to get pretty accurate results from Tesseract. For your image itself i am no table to get any results its telling: Can't recognize image. Can you plz provide the code snippet on how you are processing the image. 
Thanks - Anant.
 @theraysmith 
What do you use in the internal Google build, `-O2` or `-O3`?
 I'm interested in the same answer, @amitdo . Can you answer the question, @theraysmith ? It really can help us :)  Don't expect much difference between `-O2` and `-O3`. I tried different optimizations, and they only have small effects on the time needed for OCR of a page. Higher optimization levels can even result in slower code because the code gets larger (because of unfolding of loops), so CPU caches become less effective. It is much more important to write good code. The improvement by using `-fopenmp` is useful when you want "realtime" OCR ‚Äì running OCR for a single page and waiting for the result. Then it is fast because it uses more than one CPU core for some time consuming parts of the OCR process.

For mass OCR, it does not help. If many pages have to be processed, it is better to use single threaded Tesseract and run several Tesseract processes in parallel.
 Stefan, what about using OpenMP for training? Yes, for training a single new model OpenMP could perhaps speed up the training process. Up to now, OpenMP is only used in `ccmain/` and in `lstm/`. I don't know how much that part is used during training, and I never have run a performance evaluation for the training process (in fact I‚Äå have only run LSTM training once for Fraktur, and as I already said, it was not really successful). can I set more than 4 threads for Trainning LSTM? What about machines that have only 2 cores?
Shouldn't the 'num_threads' lowered to 2 in that case? @theraysmith I want to train tesseract 4 for arabic language. theraysmith you mean that there is no way to speed up the training process?  i follow this step,
./autogen.sh
./configure
make
sudo make install
sudo ldconfig

but when i run make, i got error, then i run _autoreconf -i_ after ./autogen.sh , but i got same result
![tesseract](https://cloud.githubusercontent.com/assets/11517390/13629164/3ae1a9be-e612-11e5-9fd5-1b5f7054ce7e.JPG)

what's wrong with this step ?
 Sounds the same as #41 
 thnks tfmorris and zdenop for the reply, it's very helpful
  Hi!
I just found that there is an invalid link in the wiki(Page Home -> Installation -> LinuxÔºâ
And here is the link:**http://code.google.com/p/tesseract-ocr/downloads/list**

> ## Linux
> 
> Tesseract is available directly from many Linux distributions. The package is generally called 'tesseract' >or 'tesseract-ocr' - search your distribution's repositories to find it. Packages are also generally available >for language training data (search the repositories,) but if not you will need to [download the appropriate >training data](http://code.google.com/p/tesseract-ocr/downloads/list), unpack it, and copy the >.traineddata file into the 'tessdata' directory, probably `/usr/share/tesseract-ocr/tessdata` or >`/usr/share/tessdata`.
> 
> If Tesseract isn't available for your distribution, or you want to use a newer version than they offer, you >can [compile your own](Compiling). Note that older versions of Tesseract only supported processing .tiff >files.

Thanks.
  I am trying to recognize a flawless image. I created the image from a pdf that is all vector, not image. It has no noise, no skew, flawless characters in any DPI that I want.

The recognition from Tesseract sucks. Generally the problem is dropped characters. It seems to randomly ignore perfectly good looking characters.

The screen shot shows the text results in the upper left and the image in the background (only the upper left of the image is visible). The bounding boxes of the results are shown in red on that image. Notice all the missing characters. On this particular image all the characters to the right of what you can see are found and recognized properly. The image consists of a table of information (rows of item #, size, description, and qty). The columns are not nicely aligned (although this example is pretty good). Some rows are separated by a line (this example has a line for each row, and notice that tesseract gives me a bounding box for some of the lines, but not all). I tried removing the lines, but that just changed the set of dropped characters with no rhyme or reason to it. Other images from this same set are very similar but tesseract will drop characters on the right, or whole lines will be missing. I have tried different DPI from 75 to 300, but the results were just as disappointing. 

Can anyone suggest how this might be solved?

![badocr](https://cloud.githubusercontent.com/assets/353400/13625650/bb6524b6-e56e-11e5-9e43-39140ee796c3.png)
  I am building tesseract on msys2 on windows. I am using the latest version of leptonica (1.73) which generates liblept-5.dll However, when I run tesseract 3.04.01 it gives the following error.

User@HP MINGW32 ~/tesseract-ocr
$ tesseract -v
C:/msys32/mingw32/bin/tesseract.exe: error while loading shared libraries: liblept-4.dll: cannot open shared object file: No such file or directory

I copied liblept-5.dll as liblept4.dll and was able to run the program - see below.

User@HP MINGW32 ~/tesseract-ocr
$ tesseract -v
tesseract 3.04.01
 leptonica-1.73
  libgif 5.1.2 : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.6.21 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.5.0

Wiki states:
*\* 3.04 requires at least v1.71 of Leptonica.**

Is 3.04.01 compatible with leptonica 1.73?
 Yes, I had used a PKGBUILD similar to the following, without the prepare
section. After Zdenko's comment I have added autogen.sh to it also. Need to
build it again to test.

# Maintainer: Alexey Pavlov alexpux@gmail.com

# Maintainer: Ray Donnelly mingw.android@gmail.com

_realname=tesseract-ocr
pkgbase=mingw-w64-${_realname}
pkgname="${MINGW_PACKAGE_PREFIX}-${_realname}"
pkgver=3.04.01
pkgrel=2
pkgdesc="Tesseract OCR (mingw-w64)"
arch=('any')
url="https://github.com/tesseract-ocr/tesseract"
license=("Apache License 2.0")
makedepends=("${MINGW_PACKAGE_PREFIX}-gcc"
"${MINGW_PACKAGE_PREFIX}-pkg-config")
depends=(${MINGW_PACKAGE_PREFIX}-cairo
         ${MINGW_PACKAGE_PREFIX}-gcc-libs
         ${MINGW_PACKAGE_PREFIX}-icu
         ${MINGW_PACKAGE_PREFIX}-leptonica
         ${MINGW_PACKAGE_PREFIX}-pango
         ${MINGW_PACKAGE_PREFIX}-zlib
         ${MINGW_PACKAGE_PREFIX}-tesseract-data-eng)

source=(${_realname}-${pkgver}.tar.gz::
https://github.com/tesseract-ocr/tesseract/archive/${pkgver}.tar.gz

https://github.com/tesseract-ocr/tessdata/raw/master/osd.traineddata )
sha256sums=('57f63e1b14ae04c3932a2683e4be4954a2849e17edd638ffe91bc5a2156adc6a'

'9cf5d576fcc47564f11265841e5ca839001e7e6f38ff7f7aacf46d15a96b00ff')

options=('!libtool' 'strip')

prepare() {
  cd "${srcdir}/tesseract-${pkgver}"
  ./autogen.sh
  }

build() {
  cd "${srcdir}/tesseract-${pkgver}"
  [[ -d "${srcdir}"/build-${CARCH} ]] && rm -rf "${srcdir}"/build-${CARCH}
  mkdir -p "${srcdir}"/build-${CARCH} && cd "${srcdir}"/build-${CARCH}

  local -a extra_config
  if check_option "debug" "y"; then
    extra_config+=( --enable-debug )
  fi

  ../tesseract-${pkgver}/configure \
    --build=${MINGW_CHOST} \
    --host=${MINGW_CHOST} \
    --target=${MINGW_CHOST} \
    --prefix=${MINGW_PREFIX} \
    LIBLEPT_HEADERSDIR=${MINGW_PREFIX}/include \
    "${extra_config[@]}"

  make
}

package() {
  cd "${srcdir}/build-${CARCH}"
  make DESTDIR="${pkgdir}" install
  make training
  make DESTDIR="${pkgdir}" training-install

  mkdir -p $pkgdir/${MINGW_PREFIX}/share/tessdata
  install -Dm0644 $srcdir/osd.traineddata
$pkgdir/${MINGW_PREFIX}/share/tessdata/osd.traineddata
  cp $srcdir/tessdata/eng.\* $pkgdir/${MINGW_PREFIX}/share/tessdata
  cp $srcdir/tessdata/configs/bazaar
$pkgdir/${MINGW_PREFIX}/share/tessdata/configs
  find $pkgdir/${MINGW_PREFIX}/share/tessdata -type f -exec chmod 0644 {} \;
}

ShreeDevi

---

‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Wed, Mar 9, 2016 at 12:26 AM, Amit Dovev notifications@github.com
wrote:

> Did you recompile (./configure, make, sudo make install, sudo ldconfig)
> tesseract after you recompiled leptonica 1.73?
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/258#issuecomment-193914371
> .
 I have built Leptonica 1.73 on msys2 locally. It is not yet reflected in
Msys2 repository.

ShreeDevi

---

‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Wed, Mar 9, 2016 at 1:05 PM, zdenop notifications@github.com wrote:

> rebuilding tesseract does not help unless leptonica instalation is not
> fixed within msys...
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/258#issuecomment-194153653
> .
 No liblept.dll.

I have liblept.a and liblept.dll.a in lib directory and liblept-5.dll in
bin directory.

ShreeDevi

---

‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Thu, Mar 10, 2016 at 6:57 PM, Amit Dovev notifications@github.com
wrote:

> Do you have liblept.dll?
> It should be a symlink to liblept-5.dll
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/258#issuecomment-194838358
> .
 Amit & Zdenko.

Yes, the problem on msys2 maybe because I am trying to use the PKGBUILD
system for building the software (which is what was recommended by the
msys2 developers when I was trying to build the earlier release by hand).

I was able to build and run 1.73 leptonica and the latest source of
tesseract on ubuntu 14.04 without problems.

Thanks!

ShreeDevi

---

‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Fri, Mar 11, 2016 at 5:41 PM, zdenop notifications@github.com wrote:

> Real problem is that he has several installation of leptonica but msys
> instruct linker to use older leptonica version (which could be reasonable
> if older version was installed by msys packagin system and new version "by
> hand") . There are several ways how to solve it:
> 1. learn how you environment/system is working, how to manage it
> 2. If 1. is not option - wait for official packages and do to try to
>    compile from source
> 3. Use only one version of software => do not use packaging system,
>    but compile from source. From my experience, this option will sooner or
>    later lead to the current status (something goes wrong and I have not clue
>    why) ;-).
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/258#issuecomment-195344279
> .
 I did not run
sudo ldconfig
after building leptonica, but did after building tesseract.

I used the following commands:

./autogen.sh
./configure
LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make
sudo make install
sudo ldconfig
LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make training
sudo make training-install

ShreeDevi

---

‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Fri, Mar 11, 2016 at 7:41 PM, Amit Dovev notifications@github.com
wrote:

> Shree,
> 
> Here are the commands I ran on Linux:
> 
> cd path/to/leptonica-1.73
> 
> ./configure
> make
> sudo make install
> sudo ldconfig
> 
> cd path/to/tesseract-ocr
> ./autogen.sh
> ./configure  --enable-debug
> make
> sudo make install
> sudo ldconfig
> make training
> sudo make training-install
> 
> Did you run sudo ldconfig ?
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/258#issuecomment-195380654
> .
 Thanks, please change the wiki.

ShreeDevi

---

‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Sun, Mar 13, 2016 at 8:24 PM, Amit Dovev notifications@github.com
wrote:

> http://tldp.org/HOWTO/Program-Library-HOWTO/shared-libraries.html
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/258#issuecomment-195970355
> .
  Hi,

I am currently working on license plate recognition and for that i am using tesseract3.03 on windows. For the same purpose I have trained the tesseract with 1500 images of alpha numeric characters.When I am testing tesseract for same images then GetUTF8Text returns NULL.Specially mostly for N,M, and W characters.I have attached 3 images as samples. 

As detail, I have set the vaiable PageSegMode="PSM_SINGLE_CHAR".Besides,I have already tried preprocessing and resolution techniques for input image to resolve the problem.

PLEASE HELP!!!

It would be helpful even if I can know the roll of GetUTF8Text in giving the NULL output for an images.
![696](https://cloud.githubusercontent.com/assets/10992866/13593034/c0173e96-e51d-11e5-846e-12a3b46de8d1.jpg)
![742](https://cloud.githubusercontent.com/assets/10992866/13593032/c0129f62-e51d-11e5-833a-89add68d42f8.jpg)
![1022](https://cloud.githubusercontent.com/assets/10992866/13593033/c016d622-e51d-11e5-8bdb-0b335026a415.jpg)
  It doesn't look to me like `classify_enable_adaptive_matcher=0` is really supported any more. A bunch of the new code that's been added isn't conditionalized to check it.

The reason that it doesn't crash when the config variable is set on the command line is because that's done after the recognizer is initialized, so the necessary data structure has been created.
 The config file is processed in the Init call here:

https://github.com/tesseract-ocr/tesseract/blob/master/api/tesseractmain.cpp#L372

while the command line config variables are processed in the call
to SetVariablesFromCLArgs here:

https://github.com/tesseract-ocr/tesseract/blob/master/api/tesseractmain.cpp#L379

after the adaptive matcher has already been set up.

Even though the command line case doesn't crash, it is still using the
adaptive matcher because the code that references it isn't guarded by the
necessary config variable.
 Good suggestions, but neither is relevant here because `classify_enable_adaptive_matcher` isn't an init only parameter.

The issue is that the code has evolved so that `classify_enable_adaptive_matcher=0` is no longer supported. There are sections of code which don't check this config variable and which assume that the adaptive matcher is correctly initialized.  We can either drop the config variable or fix the code so that the variable protects everything that needs to be protected. I don't know how much work that'll be, but it's more than just this one place, because I fixed it and it just died somewhere else. No idea how many places there are to fix or whether it makes sense from @theraysmith's point of view to continue supporting this case.

In my opinion, the current order of evaluation (config files, then command line) is correct because it allows the config file to be overridden by the command line.
  Hi,

if seems, that moving PageIterator\* AnalyseLayout() to api/baseapi.h[1] causes a silent ABI breakage. Could you please move it back to api/baseapi.cpp? Please see the corresponding Debian bugs for reference [2], [3].
I could prepare a PR if you prefer. 

Thanks,
Philip

[1] https://github.com/tesseract-ocr/tesseract/blob/master/api/baseapi.h#L500
[2] https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=816857
[3] https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=815056#24
 See also the tail end of https://groups.google.com/forum/#!topic/tesseract-dev/8e0F2cK2YzU
 Here you go: PR #259
 Please make sure this reaches the 3.04 branch.
  I put together a simple test program that demonstrates the issue:
https://github.com/matthill/tesseract_z_issue/tree/master

Given an input image that is a "N", Tesseract seems to rotate this single character to produce high confidence for "Z" and "2" characters.  Only the "N" and "M" characters would be expected.
# tesseract_z_issue

![Z Character](https://raw.githubusercontent.com/matthill/tesseract_z_issue/master/z.png)

Input training data is here: [tif](https://github.com/openalpr/train-ocr/blob/master/eu/input/leu.netherlands.exp0.tif?raw=true) [box](https://raw.githubusercontent.com/openalpr/train-ocr/master/eu/input/leu.netherlands.exp0.box)

After running the program, the output is:

```
[mhill@mhill-linux z]$ ./tesseract_z_test 
Z : 95.4505
symbol Z, conf: 95.450462 font: netherlands (index 1) size 53px - Z conf: 95.450462
            - N conf: 91.517166
            - 2 conf: 86.062859
            - M conf: 81.259239
---------------------------------------------
```

Z and 2 characters are not expected, it makes me wonder if the character is rotated when analyzed.
 Are you sure that you're not closing a real issue here?  I assume that Tesseract is trying to rotate an individual character crop 90 degrees and getting better recognition.  I assume that changing the training data would not affect this.  Do you believe that changing the training input data would resolve this issue?

I did not use a font to train this language, these are actual binarized letter samples from real data (license plates).  I'm not sure I understand your comment "font seem to be common."  Can you help me understand what you mean?

My use case is individual character recognition, rather than words/lines of characters.  The recognition is only used for one character at a time (no segmentation) so I don't believe the order of the characters in the tif/box matters.  Am I mistaken?  Do you expect that changing the order of the characters could affect individual character recognition?  My experimentation with Tesseract leads me to believe that this is not true.
  from
https://github.com/tesseract-ocr/tesseract/tree/master/tessdata
 I had problems earlier while opening pdf files that were created without pdf.ttx being present in tessdata. 

But that seems to have been fixed and looks like pdf.ttx is no longer required (I looked at the history ..https://github.com/tesseract-ocr/tesseract/commits/master/tessdata/Makefile.am 
 Problem report is incorrect. `pdf.ttx` has never been required for Tesseract PDF generation.  `pdf.ttx` is simply a human readable representation of the invisible font. I only use it when trying to figure out font related problems. And I typically generate it when needed; there is no need to distribute with Tesseract at all.
 You are right, `GlyphLessFont.h|cpp` should be removed. They were important at one time, but are no longer relevant or useful. (Back in the old days, two months ago, the software that converts ttx to ttf and back was not smart enough to handle our font. Now it is.)
  Hi,
There is a function **main()** at the end of [viewer/svpaint.cpp](https://github.com/tesseract-ocr/tesseract/blob/d7b089fbcf8f1582e8e897f7c8572433b662f533/viewer/svpaint.cpp#L221), which is compiled and exported when building the library. I think it shouldn't be there, or it should be protected by some define so you only compile it when you need it 
 I saw it, but as graphics is enabled by default, and as it enables more functions (apart from main), I thought that disabling graphics would also disable more functions and disable some functionality (perhaps all those functions are only used by that main() so it doesn't matter, but I don't know)

So, by default the library is compiled with a main() function, I could --disable-graphics. However, I don't think it's a good idea to put main inside a library or, if needed (why?), to be the default behavior.

Could it be that main() is used by some the executable and it is also included in the library by mistake? 

Cheers.
  [otsuthr.cpp:52]: (style) Variable 'histogramAllChannels' is allocated memory that is never used.

Suggest move new & delete of histogramAllChannels inside the #ifdef USE_OPENCL
.
  `unicharset_extractor *.box`  giving an error in version 3.05.00 so does `mftraining`and `shapetraining`. Works fine in version 3.02.
`
 @zdenop I have installed the tesseract training tool, but how can I install `unicharset_extractor *.box`, `mftraining` `shapetraining`. Can you provide with the necessary links? 
  I'm not sure this is the best fix for the issue, but it does provide a workaround while someone works out what the root cause is and where it should really be fixed.
 I've cleaned up the cosmetic issues. 

Any insight into what the root cause is? I'm not sure that this is more than a bandaid.
    Trivial patch to expose the used tessdata_prefix in the public API.
 Oh, not sure how I managed to miss that one. Thanks!
  Hi, 
I noticed different results when analyzing the same PNG image having 8 different colors when it is encoded with a colormap of 8 or 256 colors.

**Version:**

```
tesseract 3.05.00dev
 leptonica-1.73
  libjpeg 8d : libpng 1.2.49 : libtiff 4.0.3 : zlib 1.2.8
```

**Demo:**
french subtitle conversion from XFiles-S01E01 (DVB). The subtitle image extracted with ProjectX as a BMP has 8 distinct colors. It was converted to PNG with two different programs.
'ok.png', 256 entries colormap:
![ok](https://cloud.githubusercontent.com/assets/17527508/13379299/52a4e02c-de22-11e5-9b68-47bb8a5b5180.png)
Tesseract result is correct:

```
$ tesseract -l fra ok.png stdout
La mort a eu lieu
il y a 8 √† 12 heures.
```

'nak.png' 8 entries colormap:
![nak](https://cloud.githubusercontent.com/assets/17527508/13379305/6e9dd8ec-de22-11e5-910c-1c89dd76594a.png)

Tesseract result is wrong:

```
$ tesseract -l fra nak.png stdout
La morte eu lieu
il y a 8 √† 12 heures.
```

 The image type is either recognized as 4 or 8 bpp but the information content is identical:

```
$ pngtopnm ok.png|md5sum
cbe58b4e03ebbe279958287e8d53f719  -
$ pngtopnm nak.png|md5sum
cbe58b4e03ebbe279958287e8d53f719  -
```

I suspect that tesseract internal processing keeps the original image bit depth and that some steps don't work as well at 4bpp as at 8bpp.

External workaround: 

```
pngtopnm nak.png | tesseract -l fra stdin stdout
La mort a eu lieu
il y a 8 √† 12 heures.
```

Quick patch to do this conversion internally in libtesseract:

```
 --- api/baseapi.cpp.orig   2016-02-18 08:48:00.000000000 +0100
+++ api/baseapi.cpp 2016-02-28 13:41:08.056037716 +0100
@@ -1195,6 +1195,12 @@
                               const char* retry_config, int timeout_millisec,
                               TessResultRenderer* renderer) {
   PERF_COUNT_START("ProcessPage")
+  // convert 4bit to 8bit data for improved processing
+  if (pix->d==4) {
+    Pix* pix2=pixConvert4To8(pix,(pix->colormap)!=NULL);
+    pixDestroy(&pix);
+    pix=pix2;
+  }
   SetInputName(filename);
   SetImage(pix);
   bool failed = false;
```

I am not sure if this is the correct strategy to deal with this issue, nor if it is the right place to change the data type. 4-color DVB subtitles exist, so 2bpp images should probably also be considered.

Thanks for this soft, works great for me.
-- Bruno
 Mmm yes...

Well two approaches from my point of view:

1) the user has to deal with the image format, but it should be mentioned in the man page and a warning should be issued when a palette color image is detected. Maybe the image should just be rejected.

or

2) tesseract should do its best with the data it receives and convert them to the internal format it needs for optimal processing.

I really think something should be done, because people will just (wrongly) conclude that tesseract is bad at reading a really clear-looking picture...

( I was very close to that conclusion but I was saved by the fact that previous trials with much lower quality pictures (vobsub output of ProjectX) had given the correct result for that precise subtitle. But other errors in about 10% of subtitles.)
 The 0.25 R + 0.5 G + 0.25 B calculation designed to give fast results, not accurate ones. Sounds like someone may be calling pixConvertRGBToGrayFast() instead of pixConvertRGBToGray(). This seems like a bad idea if it is affecting results. And I also don't understand why we would ever threshold on R,G,B individually. The normal thing to do is calculate luminance, then threshold on luminance.

Leptonica is really, really good at image binarization. We should be making use of it.
 @bruvi where exactly is the 0.25 R + 0.5 G + 0.25 B conversion happening?
 If we use sRGB perceptual weightings then it works.

`graymap[i] = 0.2126  * rmap[i] + 0.7152 * gmap[i] + 0.0722 * bmap[i];`

```
tesseract -l fra /tmp/nak.png -
La mort a eu lieu
il y a 8 √† 12 heures.
```

If we use "Leptonica" perceptual weightings, then it fails.

`graymap[i] = 0.3 * rmap[i] + 0.5 * gmap[i] + 0.2 * bmap[i];`

```
tesseract -l fra /tmp/nak.png -
La morte eu lieu
il y a 8 √† 12 heures.
```

If I remove the colormap before anything else, then it works. I think this is the right solution because it guarantees consistency (e.g. colormap vs. non-colormap will not change results if image is otherwise identical). Leptonica should switch to some sort of perceptual weighting for the next release because that is a no-brainer, but will not have any effect on Tesseract if we remove the colormap first.

``` diff
--- tesseract/ccmain/thresholder.cpp    2014-07-11 11:28:02.000000000 -0700
+++ tesseract/ccmain/thresholder.cpp    2016-03-11 10:01:36.000000000 -0800
@@ -149,17 +149,23 @@
   if (pix_ != NULL)
     pixDestroy(&pix_);
   Pix* src = const_cast<Pix*>(pix);
-  int depth;
-  pixGetDimensions(src, &image_width_, &image_height_, &depth);
   // Convert the image as necessary so it is one of binary, plain RGB, or
   // 8 bit with no colormap.
+  Pix *tmp;
+  if (pixGetColormap(src)) {
+    tmp = pixRemoveColormap(src, REMOVE_CMAP_BASED_ON_SRC);
+  } else {
+    tmp = pixClone(src);
+  }
+  int depth;
+  pixGetDimensions(tmp, &image_width_, &image_height_, &depth);
+
   if (depth > 1 && depth < 8) {
-    pix_ = pixConvertTo8(src, false);
-  } else if (pixGetColormap(src)) {
-    pix_ = pixRemoveColormap(src, REMOVE_CMAP_BASED_ON_SRC);
+    pix_ = pixConvertTo8(tmp, false);
   } else {
-    pix_ = pixClone(src);
+    pix_ = pixClone(tmp);
   }
+  pixDestroy(&tmp);
   depth = pixGetDepth(pix_);
   pix_channels_ = depth / 8;
   pix_wpl_ = pixGetWpl(pix_);
```

```
tesseract -l fra /tmp/nak.png -
La mort a eu lieu
il y a 8 √† 12 heures.
```
 Ray is going to write the official change. Best to coordinate with him. He is doing the same thing, but with a different way of writing the code.
  I've tried to compile the main vs2010 project and even with x32 it doesn't work. requires 
allheaders.h file. 
Error   2   error C1083: Cannot open include file: 'allheaders.h': No such file or directory    

If I'm not wrong this file is a leptonica file, but leptonica is not provided in the solution. Why is this dependency still needed to compile only tesseract libraries? 
 Hi, I will edit the issue so it only have the issue itself.
  I have an image with barely 20 lines of text (I have the image that I can provide), and it's taking seconds and seconds to read the text.
I'm using VS2010.
I provided the binary image (very clean) to Tesseract. Tesseract works fine but it's too too slow.

I'm impressed by the accuracy of Tesseract, but the speed is a disaster!
I used other commercial OCR engines: accuracy less but speed much faster.

how to improve the speed of tesseract? anyway to read an image in few 100s of milliseconds.

thanks
 I posted my message on the google groups,
  I have tested latest release 3.05 on windows platform to OCR Arabic document to PDF (searchable) and when choose text from output PDF file it seems stored in opposite (left to right) and letters should be stored from (Right to left)!!!

i.e. original text In Arabic is
ŸÖÿ±ÿ≠ÿ®ÿß
Stored in PDF as text as
ÿßÿ®ÿ≠ÿ±ŸÖ
 ‚Äãplease put your sample file and the command you used for ocr job‚Äã
 This is the command:

tesseract  c:\temp\test_ara.jpg  -l ara  -psm 3  c:\temp\test_ara pdf

Files are attached (source JPG and output PDF)

![test_ara](https://cloud.githubusercontent.com/assets/17473681/13320324/bc160e22-dbd0-11e5-8090-6f3728fcc06d.jpg)
[test_ara.pdf](https://github.com/tesseract-ocr/tesseract/files/146534/test_ara.pdf)

please check original word
ÿ£ŸÜÿ≠ÿßÿ°
output inside PDF is
ÿ°ÿßÿ≠ŸÜÿß
 Command and Samples are attached now in the previous comment
 @amitdo 
is there any way to reach a better accuracy in Arabic language until to change to new engine?
now with tesseract i get about 100% accuracy  in English but for Arabic result is about 30-40%
but for example i checked google drive ocr for Arabic and i see it have 100 results for same image..

can we work on language data for a better results?
 I am using Adobe Reader.
But please note that words are not reversed while viewing the PDF because it contains the original image with text layer.
I mean when you copy text layer then paste it to any text editor it will be reversed, so now can't search for the text inside the PDF because it is stored revered inside the text layer!
 This is a serious issue with the PDF output feature using Arabic Language and similar languages that be written from right to left
 I try hard to make sure Arabic and other right-to-left languages work correctly in Tesseract PDF. As the problem is isolated further I'm happy to look, but I'm not aware of any reason things would have broken. 
 A quick check shows Chrome gives good results (as per amitdo) and Acroread gives bad results (as per tbadran). This is surprising, I thought we were good with Acroread. I wonder if this is a regression and if so when it occurred.
 Regarding recognition accuracy, that's a better topic for the forum. But in short: Don't compare against Google Drive. Don't expect major accuracy improvements unless/until Ray is successful with his ideas. And most importantly, don't trust any predictions about 'soon'. That last one is true for all software everywhere.
 Please note my testing using the binaries for Windows downloaded from:
http://domasofan.spdns.eu/tesseract/ 
and I am Using Windows 10 with Acrobat Pro 11 to view output PDF file
 I have tested multiple different sample files not only sample uploaded above and every time getting same issue in output PDF on windows 10 + Acrobat Pro 11
 On OS X, I'm seeing the opposite of earlier reports: 
- Acrobat Reader DC 15.10.20056.167417 appears correct when cutting & pasting
- Google Chrome Version 48.0.2564.116 (64-bit) appears backwards
 Adobe Acrobat:

ÿßŸÖŸáŸÖŸá ŸÖŸÜŸä ÿßŸáÿßÿØŸÖ
ÿ©ŸäŸäÿ±ÿπŸÑÿß ÿ©ÿ∫ŸÑŸÑÿß
. ŸáŸÖ ÿØŸáÿ¨ ÿ©ÿ∫ŸÑ
ŸÖŸÑÿßÿπŸÑÿß ÿ°ÿßÿ≠ŸÜÿß ŸäŸá Ÿáÿ±ŸÜÿ≥ŸÖ

Google Chrome

ŸÖÿØÿßŸáÿß ŸäŸÜŸÖ ŸáŸÖŸáŸÖÿß
ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ŸäŸäÿ©
ŸÑÿ∫ÿ© ÿ¨ŸáÿØ ŸÖŸá
ŸÖÿ≥ŸÜÿ±Ÿá ŸáŸä ÿßŸÜÿ≠ÿßÿ° ÿßŸÑÿπÿßŸÑŸÖ
 I find it a little easier to test with Hebrew because the letters do not connect. Tesseract version 3.03 behaves the same, so this is not a regression. Will need to think about this, because it is not obvious what exactly is going wrong. Lots of PDF files do a crazy 'write it backwards' strategy but that should not be required. Tesseract writes in reading order.
 There are two things I can think of doing. One is to give up and write Arabic 
backwards (which I really hate!). The other is  to put an entry in  the PDF
metadata, Catalog/ViewerPreferences/Direction. Will continue thinking about
this, slowly.
 @amitdo Hebrew has the exact same problem as Arabic.
 That's another possibility, thanks for the suggestion.
 There are a number of issues relating to RTL and Arabic. Can they all be labelled with 'Arabic' for ease of finding, so that duplicate issues are not created.

https://github.com/tesseract-ocr/tesseract/issues?q=Arabic+in%3Atitle%2Cbody
gives a list of the same.
 That's good news. I promise that we'll give it a try as soon as it is available.
 Thanks.

ShreeDevi

---

‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Thu, Sep 15, 2016 at 12:20 AM, zdenop notifications@github.com wrote:

> Ray shared that he would like to have public alpha version by the end of
> September.
> 
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/238#issuecomment-247116411,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o53wUhtvKbMbG-B-TAutJfk3h64vks5qqEIDgaJpZM4His6k
> .
 hi, where can i get the arabic tessdata files? 
also, where do we get all other language files?
thanks
 ara.\* from https://github.com/tesseract-ocr/tessdata (Version 3.02)

https://github.com/tesseract-ocr/langdata/tree/master/ara (Version 3.04)
 https://github.com/tesseract-ocr/tessdata

Download all ara.\* Files for Arabic

Other language data files are also in same repository

On 21 Oct 2016 6:07 a.m., "Mehmet Altuntas" notifications@github.com
wrote:

> hi, where can i get the arabic tessdata files?
> also, where do we get all other language files?
> thanks
> 
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/238#issuecomment-255288956,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_oxpzfVP9cDcNP9gxAe_kqigEshyfks5q2DpygaJpZM4His6k
> .
 The tesseract/langdata/ara repo has the 3.04 source files for Arabic
language data.

The Arabic traineddata is based on cube engine and is the 3.02version.

On 21 Oct 2016 11:56 a.m., "ShreeDevi Kumar" shreeshrii@gmail.com wrote:

> https://github.com/tesseract-ocr/tessdata
> 
> Download all ara.\* Files for Arabic
> 
> Other language data files are also in same repository
> 
> On 21 Oct 2016 6:07 a.m., "Mehmet Altuntas" notifications@github.com
> wrote:
> 
> > hi, where can i get the arabic tessdata files?
> > also, where do we get all other language files?
> > thanks
> > 
> > ‚Äî
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > https://github.com/tesseract-ocr/tesseract/issues/238#issuecomment-255288956,
> > or mute the thread
> > https://github.com/notifications/unsubscribe-auth/AE2_oxpzfVP9cDcNP9gxAe_kqigEshyfks5q2DpygaJpZM4His6k
> > .
 @jbreiden
Did you find a solution? ‚Äãis there any milestone to drop cube completely!?‚Äã
 >‚Äãis there any milestone to drop cube completely!?‚Äã

This issue is not caused by cube.

See https://github.com/tesseract-ocr/tesseract/issues/40#issuecomment-263039665 The Adobe folks suggested a few things to try, none of which worked so far. Still open and (relatively) active. Please tell us which pdf viewer you already tested if any. @jbreiden  Here is a more thorough examination of "ara.pdf" [that you posted in your comment](https://github.com/tesseract-ocr/tesseract/issues/238#issuecomment-296256374)

1) Wrong sentence order: 
    some sentences are over-stepping their location in the paragraph, I discovered that this was caused by the software used to view the pdf, in my case Chrome, but after using Windows Reader the problem was solved.

![ara](https://cloud.githubusercontent.com/assets/16248376/25373915/1eb574ba-29a4-11e7-8c5d-5bb4d0d1480d.jpg)


2) Repetitive mistakes:
    ( ŸÑÿß ) is wrongly represented as ( ÿßŸÑ ) , which is actually opposite to the correct spelling. 
    ( ÿå ) is the Arabic Comma, is wrongly represented as ( ÿ° ) or ( , ) or ( . ) or ( ¬ª )
    ( ÿßŸã ) is represented by only ( ÿß ) , which is missing (  Ÿã   ) 
    some rare cases of multiple combined words, there are 2 separate cases ( ŸÖÿ±ÿ≠ÿßŸÖÿ≥ÿ™ÿ®ÿ¥ÿ±ÿß ) and( ŸÖŸÜÿßŸÑŸÜÿßÿ≥ ) ,    should be ( ŸÖÿ±ÿ≠ÿßŸã ŸÖÿ≥ÿ™ÿ®ÿ¥ÿ±ÿß ) and ( ŸÖŸÜ ÿßŸÑŸÜÿßÿ≥ )


3) Rare Case:
    When I copied the text to Microsoft Word, most of the font was in Arial font except of a couple of ( . ) full-stops which were in Calibri font, a weird thing to see.

Conclusion:
Altogether, except for the mistakes that I stated earlier, the recognition rate was very good in this sample.

Note that in the Arabic language, the state of ( ŸÑÿß ) is frequently used, so-much that if this misrepresentation of it as ( ÿßŸÑ ) is continued, it would degrade the recognition rate drastically.  


![untitled22](https://cloud.githubusercontent.com/assets/16248376/25375718/52063736-29aa-11e7-86ca-ff8851024c47.png)


 Hebrew report:

I highlighted the text in each pdf viewer, and pasted it to gedit.

With Chromium the straight version is mostly fine. There are problems when there is a combination of Hebrew and English/other ltr symbols in the same line.
The skewed version is not fine. The words appear in wrong order in each line.

The pasted text of the straight version does not look good when Evince and pdf.js are used.
pdf.js - there are line breaks after each word.
Evince - total mess. Wrong line breaks and wrong word order. Unusable. It will be helpful to compare the pasted text of these files to Tesseract's text renderer output, to see if each issue is really caused by the pdf renderer or by the ocr engine itself. I think we should also compare to the current (4.00 with lstm) pdf output, without your patch.
The original issue, reversed letters, was with the Adobe pdf viewer, not the other viewers.
  @christophered

The source of the 3 first mistakes in your 'Repetitive mistakes' section is the ocr engine itself, not the pdf renderer.

#648 is a more suitable place to report about them.
( ŸÑÿß ) vs ( ÿßŸÑ ) is a known issue. See https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-285633162 and the comments below it.  >some rare cases of multiple combined words

It's not clear if the source for this issue is the pdf renderer or the ocr engine itself. I discovered that the Sentence disorder is caused by Chrome which I used to view the PDF.
Note that after using Windows Reader the PDF was viewed correctly without the disorder that I mentioned. @christophered,
We want that it will be displayed fine in all major pdf viewers, not just one. >Note that after using Windows Reader the PDF was viewed correctly

Which Windows version?

If you have Windows 10, try to open the pdf file with the Edge browser, and report how it is displayed there. I am using Windows 8 Amit, the PDF displays the original image only, so lookswise it will be the
same. It is the text layer, as copied or saved which is different.

I can test on windows10 and post the result. Someone else will have to tell
if it is ok or not.

Even with legacy Devanagari fonts that use Latin range, I have found that
copied text is different between Adobe reader and foxit reader.

- excuse the brevity, sent from mobile

On 25-Apr-2017 6:05 PM, "Amit D." <notifications@github.com> wrote:

> Note that after using Windows Reader the PDF was viewed correctly
>
> Which Windows version?
>
> If you have Windows 10, try to open the pdf file with the Edge browser,
> and report how it is displayed there.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/238#issuecomment-297015981>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o7IteyLCIpPyivdsXVRS2B3QTGe_ks5rzeiagaJpZM4His6k>
> .
>
 Me:
>If you have Windows 10, try to open the pdf file with the Edge browser, and report how it is displayed there.

@Shreeshrii :
>Amit, the PDF displays the original image only, so lookswise it will be the same. It is the text layer, as copied or saved which is different. 

Yes. Although I said 'displayed', I meant to refer to the "invisible text layer underneath the visible image, which can be copied and pasted to text editor".

I just made a shortcut, assuming people will understand what I really meant. 
Maybe I should add **excuse the brevity, sent from my PC** to my comments...
:rofl:  @amitdo funny joke :) I downloaded ara.pdf (EXPERIMENT) version and opened in Adobe Reader XI and Foxit Reader 8.1 under Windows 10 and copied and pasted the text in Notepad++ under Windows 10.

Both text files look different - with text order being opposite of each other. Please see attached.

![ara-error](https://cloud.githubusercontent.com/assets/5095331/25424660/c1b7b85c-2a86-11e7-8006-8a4215d26812.png)
[ARA-ADOBE-XI.txt](https://github.com/tesseract-ocr/tesseract/files/957656/ARA-ADOBE-XI.txt)

[ARA-FOXIT-8.1.txt](https://github.com/tesseract-ocr/tesseract/files/957657/ARA-FOXIT-8.1.txt)
 Additionally, on windows 10, in both Edge as well as the windows 10 pdf reader I am not able to copy text. 

Text copied in Chrome version is similar to Foxit, but with additional line breaks. @christophered can check whether the order is also changed.

![ara-chrome-error](https://cloud.githubusercontent.com/assets/5095331/25425054/42b71aa0-2a88-11e7-9891-e55475dd16b7.png)
[ara-chrome.txt](https://github.com/tesseract-ocr/tesseract/files/957672/ara-chrome.txt)
 Windows 10 - Internet Explorer - text matches output from Adobe Reader XI.

[ara-internet-explorer.txt](https://github.com/tesseract-ocr/tesseract/files/957692/ara-internet-explorer.txt)
 @Shreeshrii ARA-FOXIT-8.1.txt is the most adequate one in terms of sentence organization. 

It seems that Chrome splits the sentence into half, each at a new line. I only checked the straight version of the Hebrew document.

The control is much worst with Evince and pdf.js.
`Hello` ->  `olleH` (pdf.js) / `o l l e H`  (Evince)

Chromium: The two look the same, except the two last lines.
Both are not good, but the experiment is worst than the control.
The digits in the zip code and the phone numbers are in the wrong order.
`123-4567890` -> `0987654-321`
The date on top `21.07.2009` is OK.

I will check the skewed version later.  Skewed version, Chromium:

Both have wrong word order in each line (but not exactly the same).

Experiment:
The second word in the document is missing.
Two separate lines become one. Hebrew line + English line (site address).
Last lines - same issue as the straight version. @amitdo 
Using the latest Tesseract  4.0 alpha and the latest best Arabic model, I created a searchable pdf output:

- When using Chrome to view the pdf, the text can be selected/copied/pasted correctly (RTL).
- When using Adobe Acrobat Reader 17.012 (latest to date), though the text is displayed correctly, but when selected/pasted, is in reverse text (LTR). @amitdo 
Using the latest ABBYY FineReader 14 to create a searchable pdf:
- Both Chrome and Adobe Acrobat Reader can select/copy/paste correctly.

Conclusion:
It seems that Tesseract needs tweaking to solve this problem.

[Original Image.zip](https://github.com/tesseract-ocr/tesseract/files/1257071/Original.Image.zip)
[Tesseract.pdf](https://github.com/tesseract-ocr/tesseract/files/1257075/Tesseract.pdf)
[Abby Finereader.pdf](https://github.com/tesseract-ocr/tesseract/files/1257074/Abby.Finereader.pdf)

 >It seems that Tesseract needs tweaking to solve this problem.

The patch was not applied yet, so the original issue still exists.

>Looking at this again. Slowly losing the remainder of my sanity.

It could be worse if you were rapidly losing your sanity :-)

You are using a simple reverse here. That's not good enough for bidi text.  I wonder what is improved ver. 3.04. more detail especially these list.
- Improved font identification
- Fixed problems with shifted baselines so recognition can recover from layout analysis errors.
- Improved single column layout analysis
- Many bug fixes.

thanks!!
  I using tessract Android (tess-two) on nexus 7 and pc(core i5), with 1 image 1024x200
nexus 7:  10s and pc: 1s, what happen? Is there any way improve speed ocr when using in Android? Please help me! Thank.
 Some things that might make it faster are:
Select a smaller region from mGray where your text is, before createBitmap - so the more heavy methods that follow process a smaller image.
Changing Bitmap.Config.ARGB_8888 to Bitmap.Config.RGB_565 - your image is grayscale, it will not need a ARGB bitmap.
more may help: [OCR technology: ](http://www.myknown.com/ocr/)[improve OCR speed](http://www.myknown.com/ocr/improve-ocr-speed/)
  I've noticed a couple of mixed language items which cause Tessearct v3.04.01 (Leptonica 1.72) to crash:

```
cadams@ganymede:~ $ tesseract 11002612_2_0183.jpg 11002612_2_0183 -l ara+fra 
Tesseract Open Source OCR Engine v3.04.01 with Leptonica
[DS] Profile read from file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz score is inf
[DS] Device[2] 1:HD Graphics 5000 score is 0.548963
[DS] Device[3] 0:(null) score is 1.080283
[DS] Selected Device[2]: "HD Graphics 5000" (OpenCL)
Warning in pixReadMemJpeg: work-around: writing to a temp file
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
no best words!!
Segmentation fault: 11
```

Here's an example image:
![11002612_2_0183](https://cloud.githubusercontent.com/assets/46565/13234277/d61cef4a-d985-11e5-962a-7c8c1e9f9773.jpg)

Interestingly, this appears to depend on the order of the languages ‚Äì using `-l ara` or `-l fra` alone avoids the crash but specifying both in either order will cause it to crash.
 I had the same question but the behaviour is identical either with that environmental variable or even using Tesseract which wasn't built with OpenCL at all:

```
cadams@Ganymede:~ $ tesseract --version
tesseract 3.04.01
 leptonica-1.72
  libjpeg 8d : libpng 1.6.21 : libtiff 4.0.6 : zlib 1.2.5

cadams@Ganymede:~ $ tesseract 11002612_2_0183.jpg 11002612_2_0183 -l ara+fra
Tesseract Open Source OCR Engine v3.04.01 with Leptonica
Warning in pixReadMemJpeg: work-around: writing to a temp file
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
no best words!!
Segmentation fault: 11
```
 I updated the title. It wasn't clear that these were related since Arabic works fine on its own.

The commit which you referenced is shown as being included in the version (3.04.01) I'm using.
 I just ran into the exact same problem. Arabic alone is processed successfully, but when I try to get Arabic and English read at the same time, tesseract crashes. I'm using Windows version 3.05.00dev.

Another question (I'm totally new to tesseract): When I use arabic language recognition and I read a text with arabic letters, but latin numbers, the latin numbers are not recognized (that's why I wanted to add English as recognition language). In the file "ara.cube.lm" I found the line

`Digits=Ÿ†Ÿ°Ÿ¢Ÿ£Ÿ§Ÿ•Ÿ¶ŸßŸ®Ÿ©0123456789`

Does this mean,latin numbers should be recognized when I only use arabic as recognition language?
 Here's the stack trace for the crash

```
(lldb) bt
* thread #1: tid = 0x68d487, 0x000000010002294d libtesseract.3.dylib`tesseract::Tesseract::ClassifyBlobAsWord(int, PAGE_RES_IT*, C_BLOB*, STRING*, float*) [inlined] WERD_CHOICE::rating(this=0x0000000000000000) const at ratngs.h:325, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x3c)
  * frame #0: 0x000000010002294d libtesseract.3.dylib`tesseract::Tesseract::ClassifyBlobAsWord(int, PAGE_RES_IT*, C_BLOB*, STRING*, float*) [inlined] WERD_CHOICE::rating(this=0x0000000000000000) const at ratngs.h:325
    frame #1: 0x000000010002294d libtesseract.3.dylib`tesseract::Tesseract::ClassifyBlobAsWord(this=<unavailable>, pass_n=2, pr_it=0x00007fff5fbff320, blob=0x0000000105418ab0, best_str=0x00007fff5fbfef40, c2=0x00007fff5fbfef3c) + 637 at control.cpp:1263
    frame #2: 0x0000000100021e66 libtesseract.3.dylib`tesseract::Tesseract::SelectGoodDiacriticOutlines(this=0x0000000101006400, pass=2, certainty_threshold=-8, pr_it=0x00007fff5fbff320, blob=0x0000000105418ab0, outlines=0x00007fff5fbff1c0, num_outlines=6, ok_outlines=0x00007fff5fbff320) + 118 at control.cpp:1124
    frame #3: 0x0000000100021283 libtesseract.3.dylib`tesseract::Tesseract::AssignDiacriticsToOverlappingBlobs(this=0x0000000101006400, outlines=0x00007fff5fbff1c0, pass=2, real_word=<unavailable>, pr_it=0x00007fff5fbff320, word_wanted=0x00007fff5fbff1a0, overlapped_any_blob=<unavailable>, target_blobs=0x0000000111b4e280) + 1923 at control.cpp:1023
    frame #4: 0x000000010001c514 libtesseract.3.dylib`tesseract::Tesseract::ReassignDiacritics(this=0x0000000101006400, pass=2, pr_it=0x00007fff5fbff320, make_next_word_fuzzy=0x00007fff5fbff25f) + 356 at control.cpp:936
    frame #5: 0x000000010001c249 libtesseract.3.dylib`tesseract::Tesseract::RecogAllWordsPassN(this=0x0000000101006400, pass_n=2, monitor=0x0000000000000000, pr_it=0x00007fff5fbff320, words=0x00007fff5fbff2d0) + 537 at control.cpp:258
    frame #6: 0x000000010001d877 libtesseract.3.dylib`tesseract::Tesseract::recog_all_words(this=0x0000000101006400, page_res=0x0000000106e30560, monitor=0x0000000000000000, target_word_box=0x0000000000000000, word_config=0x0000000000000000, dopasses=0) + 1095 at control.cpp:386
    frame #7: 0x000000010000a0ce libtesseract.3.dylib`tesseract::TessBaseAPI::Recognize(this=0x00007fff5fbff8c8, monitor=0x0000000000000000) + 750 at baseapi.cpp:895
    frame #8: 0x000000010000a92b libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPage(this=<unavailable>, pix=<unavailable>, page_index=<unavailable>, filename=<unavailable>, retry_config=0x0000000000000000, timeout_millisec=<unavailable>, renderer=0x00000000000000
```

but I think the problem is actually in either `classify_word_and_language` callees (`RetryWithLanguage` or the individual recognizers) which shouldn't be returning no words (like the double exclamation points imply) or in `ClassifyBlobAsWord` which shouldn't assume that there's always a raw choice available.

The latter is easier to do and I was too lazy to dig further into the recognizer, so I generated a patch for that which I'll post.
 Hi All,

Does Tesseract support script identification. I have bilingual pages and two different model for different scripts. I want to use a script identifier on each word and call my models accordingly for recognition.
Help will be appreciated.
 @anupamaray Please use the mailing list for questions (and don't hijack issues about unrelated topics). You'll get better answers if you include more details about the scripts, languages, etc.
 Is this issue still exist in 4.00 (code in master)?

Probably not, since cube was removed.

@Shreeshrii 
Can you test it? (ara+other lang) --oem 0 and --oem 2 - both use the tesseract mode, so the problem is in that code.
```
(gdb) run
Starting program: /usr/local/bin/tesseract test2.jpg test2-ara-fra --oem 0 -l ara+fra
warning: Error disabling address space randomization: Success
warning: linux_ptrace_test_ret_to_nx: PTRACE_KILL waitpid returned -1: Interrupted system call
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
tessdata_manager.SeekToStart(TESSDATA_INTTEMP):Error:Assert failed:in file adaptmatch.cpp, line 537

Program received signal SIGSEGV, Segmentation fault.
ERRCODE::error (this=this@entry=0x7fddaa95aff8 <_ZL13ASSERT_FAILED>, caller=caller@entry=0x7fddaa6adcc0 "tessdata_manager.SeekToStart(TESSDATA_INTTEMP)", action=action@entry=ABORT,
    format=format@entry=0x7fddaa695c94 "in file %s, line %d") at errcode.cpp:86
86            if (!*p)
(gdb) stacktrace
Undefined command: "stacktrace".  Try "help".
(gdb) backtrace
#0  ERRCODE::error (this=this@entry=0x7fddaa95aff8 <_ZL13ASSERT_FAILED>, caller=caller@entry=0x7fddaa6adcc0 "tessdata_manager.SeekToStart(TESSDATA_INTTEMP)", action=action@entry=ABORT,
    format=format@entry=0x7fddaa695c94 "in file %s, line %d") at errcode.cpp:86
#1  0x00007fddaa5b76e0 in tesseract::Classify::InitAdaptiveClassifier (this=this@entry=0x27e1b70, load_pre_trained_templates=load_pre_trained_templates@entry=true) at adaptmatch.cpp:537
#2  0x00007fddaa5af495 in tesseract::Wordrec::program_editup (this=this@entry=0x27e1b70, textbase=textbase@entry=0x27e1b58 "test2-ara-fra", init_classifier=<optimized out>,
    init_dict=<optimized out>) at tface.cpp:51
#3  0x00007fddaa4d6949 in tesseract::Tesseract::init_tesseract_internal (this=this@entry=0x27e1b70, arg0=arg0@entry=0x0, textbase=textbase@entry=0x27e1b58 "test2-ara-fra",
    language=language@entry=0x27f7d38 "ara", oem=oem@entry=tesseract::OEM_TESSERACT_ONLY, configs=configs@entry=0x7fffca100e30, configs_size=configs_size@entry=0,
    vars_vec=vars_vec@entry=0x605280 <main::vars_vec>, vars_values=vars_values@entry=0x605260 <main::vars_values>, set_only_non_debug_params=set_only_non_debug_params@entry=false)
    at tessedit.cpp:439
#4  0x00007fddaa4d7188 in tesseract::Tesseract::init_tesseract (this=0x27e1b70, arg0=arg0@entry=0x0, textbase=0x27e1b58 "test2-ara-fra", language=language@entry=0x7fffca101064 "ara+fra",
    oem=oem@entry=tesseract::OEM_TESSERACT_ONLY, configs=configs@entry=0x7fffca100e30, configs_size=configs_size@entry=0, vars_vec=vars_vec@entry=0x605280 <main::vars_vec>,
    vars_values=vars_values@entry=0x605260 <main::vars_values>, set_only_non_debug_params=false) at tessedit.cpp:345
#5  0x00007fddaa4825ac in tesseract::TessBaseAPI::Init (this=this@entry=0x7fffca100c70, datapath=0x0, language=0x7fffca101064 "ara+fra", oem=tesseract::OEM_TESSERACT_ONLY,
    configs=0x7fffca100e30, configs_size=0, vars_vec=vars_vec@entry=0x605280 <main::vars_vec>, vars_values=vars_values@entry=0x605260 <main::vars_values>,
    set_only_non_debug_params=set_only_non_debug_params@entry=false) at baseapi.cpp:306
#6  0x0000000000401fa2 in main (argc=7, argv=0x7fffca100df8) at tesseractmain.cpp:428
(gdb) quit

``` here's is the recognition of original sepia image - 
[test1-fra-ara-lstm.txt](https://github.com/tesseract-ocr/tesseract/files/679669/test1-fra-ara-lstm.txt)
 I just unpacked the ara.traineddata - it does not have the tesseract model
files in it.

combine_tessdata -u ara.traineddata ara.

Extracting tessdata components from ara.traineddata
Wrote ara.config
Wrote ara.unicharset
Wrote ara.punc-dawg
Wrote ara.word-dawg
Wrote ara.number-dawg
Wrote ara.freq-dawg
Wrote ara.lstm
Wrote ara.lstm-punc-dawg
Wrote ara.lstm-word-dawg
Wrote ara.lstm-number-dawg


ShreeDevi
____________________________________________________________
‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Sat, Dec 31, 2016 at 8:57 PM, Stefan Weil <notifications@github.com>
wrote:

> It was also sufficient to specify -l ara in my test.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/235#issuecomment-269869708>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o0ZzhLREr78qnJF_KgztsNsJEPDCks5rNnRsgaJpZM4HgCcw>
> .
>
 >I just unpacked the ara.traineddata - it does not have the tesseract model files in it.

It never had tesseract model files in it...

 ```
Warning in pixReadMemJpeg: work-around: writing to a temp file
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
no best words!!
Segmentation fault: 11

```
The original issue here should be tagged and tested against the 3.05 branch since it is related to cube. the ara.config file in ara.traineddata uses oem 1 (originally for cube and now for LSTM).

The current issue being seen with 4.0alpha, ara not working for --oem 0 and --oem 2 is to be expected since there is no Tesseract model for the Arabic language. So, instead of segfault, the message displayed should be something like the following ...

"Tesseract requested but not present, LSTM engine used instead".

Later, if non-LSTM recognizer is removed this will not apply. Yes Shree, you are right.  Hello,

I've been trying to use the C API of Tesseract for [PyOCR](https://github.com/jflesch/pyocr) (and so, indirectly, [Paperwork](https://github.com/jflesch/paperwork/)).

To do so, I've been looking for a way to pass an in-memory image to Tesseract (to avoid the use of temporary files). There is a function `TessBaseAPIProcessPage()`, but I've found no way to create the `struct Pix` it requires.

There is a C++ function `ProcessPagesFileList` that appears to do the job, but C functions are much  much easier to bind with Python than C++ ones.

Thanks in advance for your help,
 Sorry, my bad.
  The current multi-page TIFF handling is seriously sub-optimal. First, it unnecessarily reads the entire file into memory which can tie up many MB of memory unnecessarily when pages are being processed in a streaming fashion. Second, I'm pretty sure that accessing by page number causes the entire buffer to be parsed from the beginning every time incurring both processing cost and memory thrashing.
 Please be careful with changes. It is very important not to break streaming support. 

https://github.com/tesseract-ocr/tesseract/wiki/FAQ#how-to-do-streaming
 Whoever makes the changes will have to make sure that all the tests in the test suite pass, just like any other change to the code base.

Of course this wouldn't be necessary if, when streaming support was added, it was done with some recognition of the performance impact rather than just leaving comments like "To keep code simple we will also buffer data coming from a file." https://github.com/tesseract-ocr/tesseract/blob/master/api/baseapi.cpp#L1119
 I plead guilty on all counts. I wrote the streaming feature, I failed to write a test, I introduced the performance regression, I wrote the comment, and either I didn't notice the performance regression or failed to properly consider it. 

I will attempt to write a test for streaming, and will work with you on TIFF. TIFF is historically tricky for two reasons. One is the duplicated functionality on the OpenCL path. Hard to synchronize and hard to test. I personally can't seem to run the OpenCL path at all without a segfault. Second, under win32 is it hard or impossible to pass a file descriptor between different DLLs. Which is awkward because the libtiff API prefers to work with file descriptors instead of file pointers.
 @jbreiden I don't see any particular reason that your feature should be the first to have a test. As far as I can tell, there are no tests at all for the entire program. Can you point to a more complete description of the file descriptor issue? Does TIFFClientOpen help at all?

Some random, possibly relevant, tidbits:
- "TIFF is not a streamable format" - http://www.awaresystems.be/imaging/tiff/faq.html#q7
- the "streaming" support doesn't stream - at least for anything other than a list of file names. All other formats are read entirely into memory before any processing starts. That's a pretty narrow definition of streaming.
- file format sniffing requires 12 bytes, no more
- multi-page tiff is on an entirely separate code path, which may make it easier to handle differently
 I was intimately familiar with the topic a decade ago. I have
tried my best to repress the memories.

http://www.asmail.be/msg0054669449.html

It's nice that the filename is already being passed around;
if we're lucky, maybe we can get what you need without any
API changes. Just out of curiosity, what are you using
multipage TIFF for? I usually think fax images, which are
relatively tiny.

You are right, the streaming feature is super narrow. But
it is important for book digitization.
 @tfmorris  How about something like this? If you are happy with it, I'll hand this change over to Ray for review and eventual inclusion. No API changes. I think functionally it is exactly the same, except that a multipage TIFF from a file does not get buffered.

``` diff
--- api/baseapi.cpp 2016-03-11 14:29:36.000000000 -0800
+++ api/baseapi.cpp 2016-03-28 15:49:06.000000000 -0700
@@ -1034,11 +1034,14 @@
       page = tessedit_page_number;
 #ifdef USE_OPENCL
     if ( od.selectedDeviceIsOpenCL() ) {
-      // FIXME(jbreiden) Not implemented.
-      pix = od.pixReadMemTiffCl(data, size, page);
+      pix = (data) ?
+          od.pixReadMemTiffCl(data, size, page) :
+          od.pixReadTiffCl(filename, page);
     } else {
 #endif
-      pix = pixReadMemTiff(data, size, page);
+      pix = (data) ?
+          pixReadMemTiff(data, size, page) :
+          pixReadTiff(filename, page);
 #ifdef USE_OPENCL
     }
 #endif
@@ -1086,8 +1089,7 @@
 // makes automatic detection of datatype (TIFF? filelist? PNG?)
 // impractical.  So we support a command line flag to explicitly
 // identify the scenario that really matters: filelists on
-// stdin. We'll still do our best if the user likes pipes.  That means
-// piling up any data coming into stdin into a memory buffer.
+// stdin. We'll still do our best if the user likes pipes.
 bool TessBaseAPI::ProcessPagesInternal(const char* filename,
                                        const char* retry_config,
                                        int timeout_millisec,
@@ -1109,31 +1111,24 @@
   }

   // At this point we are officially in autodection territory.
-  // That means we are going to buffer stdin so that it is
-  // seekable. To keep code simple we will also buffer data
-  // coming from a file.
+  // That means any data in stdin must be buffered, to make it
+  // seekable.
   std::string buf;
+  const l_uint8 *data = NULL;
   if (stdInput) {
     buf.assign((std::istreambuf_iterator<char>(std::cin)),
                (std::istreambuf_iterator<char>()));
-  } else {
-    std::ifstream ifs(filename, std::ios::binary);
-    if (ifs) {
-      buf.assign((std::istreambuf_iterator<char>(ifs)),
-                 (std::istreambuf_iterator<char>()));
-    } else {
-      tprintf("ERROR: Can not open input file %s\n", filename);
-      return false;
-    }
+    data = reinterpret_cast<const l_uint8 *>(buf.data());
   }

   // Here is our autodetection
   int format;
-  const l_uint8 * data = reinterpret_cast<const l_uint8 *>(buf.c_str());
-  findFileFormatBuffer(data, &format);
+  int r = (stdInput) ?
+      findFileFormatBuffer(data, &format) :
+      findFileFormat(filename, &format);

   // Maybe we have a filelist
-  if (format == IFF_UNKNOWN) {
+  if (r != 0 || format == IFF_UNKNOWN) {
     STRING s(buf.c_str());
     return ProcessPagesFileList(NULL, &s, retry_config,
                                 timeout_millisec, renderer,
@@ -1149,7 +1144,7 @@
   // Fail early if we can, before producing any output
   Pix *pix = NULL;
   if (!tiff) {
-    pix = pixReadMem(data, buf.size());
+    pix = (stdInput) ? pixReadMem(data, buf.size()) : pixRead(filename);
     if (pix == NULL) {
       return false;
     }
@@ -1162,16 +1157,15 @@
   }

   // Produce output
-  bool r = false;
-  if (tiff) {
-    r = ProcessPagesMultipageTiff(data, buf.size(), filename, retry_config,
-                                  timeout_millisec, renderer,
-                                  tesseract_->tessedit_page_number);
-  } else {
-    r = ProcessPage(pix, 0, filename, retry_config,
-                    timeout_millisec, renderer);
-    pixDestroy(&pix);
-  }
+  r = (tiff) ?
+      ProcessPagesMultipageTiff(data, buf.size(), filename, retry_config,
+                                timeout_millisec, renderer,
+                                tesseract_->tessedit_page_number) :
+      ProcessPage(pix, 0, filename, retry_config,
+                  timeout_millisec, renderer);
+
+  // Clean up memory as needed
+  pixDestroy(&pix);

   // End the output
   if (!r || (renderer && !renderer->EndDocument())) {
```
 I didn't mean to complain about this without offering a solution. I took a crack at this here: https://github.com/tfmorris/tesseract/tree/tiff-streaming
but it turned into a bit of a yak shaving exercise, so I dropped it. The main roadblock was that the "right" solution is to implement more reasonable support in Leptonica which exposes more of libTIFFs underlying capabilities. libTIFF knows how to do efficient access, it just gets lost on the way up through the layers.

Some other notes (mostly from memory, so take with a grain of salt):
- file sniffing only needs/uses 12 bytes, so not very much needs to be buffered
- file sniffing only returns top level TIFF container format, so all the other TIFF_foo checks can be removed
- libTIFF is positioned on the next directory after an image is read an knows how to read it directly, but it's Leptonica's readImage(N+1), that forces a rewind, then read 0, read 1, read 2, ..., read N, read N+1.

I'll review your proposal in more detail tomorrow to see how it compares with what I started implementing.
 Hello TMorris,

Jeff just told me about this thread.  And thank you for pointing out the unsatisfactory condition of the multi-tiff read function.

The leptonica buck stops with me, and I made a small change that brings it down to linear (not quadratic).  I will have it up on github later today.

  -- Dan
 The patch from me above only buffers images coming from stdin. We could try to optimize this more and limit that buffer to 12 bytes, but it is not obvious how useful that is. I'm guessing it isn't worth even a little extra complexity.
 Looking at my "fix" again, I believe it does NOT succeed in making the read time for N pages linear in N.  The problem is that TIFFSetDirectory() always starts at directory 0 in the search.  The way to fix this is to use the lower-level functions that TIFFSetDirectory() uses to walk through the directories, grabbing the image at each directory.  I'll attempt to remedy this in the next day or so.  
 @DanBloomberg Thanks for looking at this. Your most recent comment matches my (slightly vague) memory of how I thought things worked.

@jbreiden I'm not really in a position to make value judgements about what's worthwhile and what's not since I'm not familiar with the user base. I think my general plan of attack to keep things clean was to refactor to use the Leptonica stream functions (e.g. pixReadStreamTiff rather than pixReadTiff and pixReadMemTiff), but that would depend on Leptonica being smart enough to handle the page N -> page N+1 case without seeking (or introducing a new pure streaming API).
 OK, it's all properly linearized.  No refactoring, no low level functions, no api change, no static vars required.

See github.com/danbloomberg/leptonica.
 @tfmorris 

To implement this properly in tesseract, where you only want one image in memory at the same time, use the same approach that I just did in pixReadMultipageTiff():
- get a FILE stream
- use the FILE stream to get a TIFF stream
- loop:
  - read the pix from the TIFF stream
  - do the OCR
  - call TIFFReadDirectory() to advance to the next image

The last function is a naked tiff library call.  Jeff says that currently all the tiff reading functions are leptonica calls.
 @DanBloomberg Thanks for the outline (and for the new functionality!) Do you seeing any risk in going around Leptonica to libTIFF or do you consider this to be stable enough to be a non-issue?

@jbreiden I'm happy to take another crack at this or leave you to it. Let me know.
 There are two separable things under discussion here. The first is the unnecessary buffering. By the way, I checked and file sniffing does indeed return things like IFF_TIFF_G4. I think it makes sense to use my patch. @theraysmith has reviewed it, taken ownership, and will submit it to github.

The other topic is TIFF performance. I don't think I want to tackle that one. It's not technically difficult to write a couple libtiff calls to fix the performance problem. However, this would give Tesseract a new, direct build dependency on libtiff. That seems significant enough to warrant discussion on the development mailing list. I don't know how much of an obstacle that would be for users who build from source; it seems that many already struggle with dependencies.

I'll talk with Dan about whether there are any other options that make sense.
 Jeff and I agree that you need a direct dependency on the TIFF data
structure in the tiff library to use the linear method.

As for stability, tiff lib has been extremely stable for 20 years or so --
I wouldn't worry about that.

On Wed, Mar 30, 2016 at 12:04 PM, jbreiden notifications@github.com wrote:

> There are two separable things under discussion here. The first is the
> unnecessary buffering. By the way, I checked and file sniffing does indeed
> return things like IFF_TIFF_G4. I think it makes sense to use my patch.
> @theraysmith https://github.com/theraysmith has reviewed it, taken
> ownership, and will submit it to github.
> 
> The other topic is TIFF performance. I don't think I want to tackle that
> one. It's not technically difficult to write a couple libtiff calls to fix
> the performance problem. However, this would give Tesseract a new, direct
> build dependency on libtiff. That seems significant enough to warrant
> discussion on the development mailing list. I don't know how much of an
> obstacle that would be for users who build from source; it seems that many
> already struggle with dependencies.
> 
> I'll talk with Dan about whether there are any other options that make
> sense.
> 
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-203585859
 If Ray & Jeff have agreed the correct course of action, I'll defer.
 Tom, Ray hasn't weighed in yet.  I believe the question comes down to (1) a
comparison between the amount of time to seek to an image in a tiff file
with many images, vs. the time to OCR that image and (2) the "cost" of
having tesseract depend explicitly on the TIFF library (i.e., using TIFF
data structures and library calls directly).

I don't know either of these two things.  Do you have a timing for a seek
of hundreds of images in a large multipage tiff file?

  -- Dan

On Wed, Mar 30, 2016 at 3:28 PM, Tom Morris notifications@github.com
wrote:

> If Ray & Jeff have agreed the correct course of action, I'll defer.
> 
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-203666633
 Ray is kind of busy so he may be slow to submit my buffering patch to github. It is okay for someone else to submit if time is of the essence.

Regarding the TIFF performance issue, I see it in two places. So far we've been discussing TessBaseAPI::ProcessPagesMultipageTiff but we have the exact some problem in MasterTrainer::LoadPageImages

https://github.com/tesseract-ocr/tesseract/blob/dd8c12997385cf7f5961093bcd44f0396b08f96f/classify/mastertrainer.cpp#L219
 It's been a while since I looked at it (and don't have time to recheck now), but that looks about like what I remember thinking would be good.
 Yes, I hope to get it out in two weeks.  Do you want a not-yet-debian
'beta' to try?

On Thu, Nov 24, 2016 at 12:27 PM, zdenop <notifications@github.com> wrote:

> @DanBloomberg <https://github.com/DanBloomberg> : Is there any plan for
> leptonica 1.74 release?
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-262841092>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLOS-eQlRxWsem36RjJf5R4D0917fks5rBfNLgaJpZM4HeMNo>
> .
>
 Egor, should I restore the old version of functions in pageseg.c
temporarily on the master?

On Thu, Nov 24, 2016 at 7:43 PM, Egor Pugin <notifications@github.com>
wrote:

> Tesseract master is now broken with master leptonica because of changed
> function(s) in lept's pageseg.c.
> Because of it I switched cppan windows CI build from master to 1.73.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-262875340>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLJUpEloVXJkcEkQLQFaIMW0HA9S_ks5rBllrgaJpZM4HeMNo>
> .
>
 Right.  It's necessary to replace the last arg. in functions like
pixGetRegionsBinary(), which is an integer flag, with either NULL
(corresponding to 0) or a pixa struct (which corresponds to 1).  I'll try
to do this.

  -- Dan

On Thu, Nov 24, 2016 at 10:48 PM, Egor Pugin <notifications@github.com>
wrote:

> I think no. It's better to fix tesseract code.
> ------------------------------
>
> @zdenop <https://github.com/zdenop> If you'd like to fix tess code, you
> could use CPPAN. To change leptonica dependency from 1.73 to master, fix
> it on the line https://github.com/tesseract-ocr/tesseract/blob/master/
> cppan.yml#L137
> After this when you compile tesseract with cmake, the build will fail.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-262891206>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLObYixNrDg-cDx5DNyMgsUjl4yppks5rBoS1gaJpZM4HeMNo>
> .
>
 It will be a significant problem to  change Leptonica and Tesseract simultaneously  once we get to  wider deployment, e.g. shipping with Linux distributions. @jbreiden
Is there a approximate date for final 4.0 release? Maybe just before the freeze of the next Debian stable or Ubuntu 17.04?  > It will be a significant problem to change Leptonica and Tesseract simultaneously [...]

Isn't it possible to write code which supports both old and new (> 1.73) Leptonica (using conditional compilation)? I'd prefer such a solution, at least until Leptonica 1.73 or older is no longer used in current distributions. I will work with Dan next week to try to keep as much compatibility as
possible.

On Fri, Nov 25, 2016 at 11:40 AM, Stefan Weil <notifications@github.com>
wrote:

> It will be a significant problem to change Leptonica and Tesseract
> simultaneously [...]
>
> Isn't it possible to write code which supports both old and new (> 1.73)
> Leptonica (using conditional compilation)? I'd prefer such a solution, at
> least until Leptonica 1.73 or older is no longer used in current
> distributions.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-263015130>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEu2poRWaz7m4Qob3PFumG3ufwxKuGMDks5rBzmpgaJpZM4HeMNo>
> .
>
 Thanks, Jeff.

I believe this is an unusual situation where a leptonica interface that
tesseract uses has been changed.
And I want to apologize for the trouble it has caused.

There is a trivial change to textord/imagefind.cpp that fixes this: replace
the last arg in pixGenHalftoneMask() by NULL.
This will skip the debug output images in this function, but it should be
acceptable, and later if someone really wants the extra few debug images we
can add the code to save them.

On Fri, Nov 25, 2016 at 11:47 AM, jbreiden <notifications@github.com> wrote:

> I will work with Dan next week to try to keep as much compatibility as
> possible.
>
> On Fri, Nov 25, 2016 at 11:40 AM, Stefan Weil <notifications@github.com>
> wrote:
>
> > It will be a significant problem to change Leptonica and Tesseract
> > simultaneously [...]
> >
> > Isn't it possible to write code which supports both old and new (> 1.73)
> > Leptonica (using conditional compilation)? I'd prefer such a solution, at
> > least until Leptonica 1.73 or older is no longer used in current
> > distributions.
> >
> > ‚Äî
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/233#
> issuecomment-263015130>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AEu2poRWaz7m4Qob3PFumG3ufwxKuGMDks5rBzmpgaJpZM4HeMNo>
>
> > .
> >
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-263015680>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLMRRBLX64JXlpNpXoezNWvEzsAoWks5rBzs3gaJpZM4HeMNo>
> .
>
 Let‚Äôs talk before Leptonica 1.74 ships. There is a distribution headache if the existing, unmodified Tesseract 3.0.4 can't compile and run with Leptonica 1.74. ‚ÄãThe alternative to updating the pixGenHalftoneMask() function in tesseract
is to make a wrapper in leptonica for the existing tesseract function. This
would simply call the new leptonica function with NULL for the last arg.

On Fri, Nov 25, 2016 at 12:10 PM, jbreiden <notifications@github.com> wrote:

> Let‚Äôs talk before Leptonica 1.74 ships. There is a distribution headache
> if the existing, unmodified Tesseract 3.0.4 can't compile and run with
> Leptonica 1.74.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-263017757>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLA_GAbX1LR6Vpbo0vK2ads5jlQATks5rB0C-gaJpZM4HeMNo>
> .
>
 Here is my unofficial take on the ABI shared object version numbers. Jeff
knows about these details and can correct if I'm wrong.

With the Debian releases, we will need to increase the *shared object
version number* (which is different from the leptonica release number) with
any change in the ABI.  The Debian leptonica *soversion* for 1.73 is 5.0.0,
and for 1.74 I believe that we'll increase it to 6.0.0.

The meaning of these three digits is, for the shared object name
*whatever.so.X.Y.Z*, we increment

    X if the ABI release is backwards incompatible
    Y if the ABI release is backwards compatible (with interface changes)
    Z if there are only internal changes (no change to the ABI)

So if I write the wrapper mentioned above, and that were the only change,
then the ABI would be backwards compatible and we'd only need to increment
to 5.1.0 for the next Debian release.  (However, there have been other
changes, including the removal of deprecated functions.)

On Fri, Nov 25, 2016 at 1:01 PM, Egor Pugin <notifications@github.com>
wrote:

> Yes, this seems ABI breakage. Both tesseract and leptonica do not use
> semver (X.Y.Z), but use (X.Y), so personally I'm confused. With semver ABI
> breakage only allowed when increasing X number. So, e.g. leptonica should
> be versioned as 2.00 or whatever.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-263022071>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLHznAbmXo5UwOhuUdFnN5qn1DQxCks5rB0y5gaJpZM4HeMNo>
> .
>
 I've added the wrapper for pixGenHalftoneMask(), so the (not yet released
1.74) git master now should be compatible with tesseract 3.0.4.

With this, tesseract can be changed at your convenience to use the new
interface pixGenerateHalftoneMask() with NULL for the last arg, and both
will compile.  We'll keep the old version in leptonica until there is no
further need to use it with tesseract.


On Fri, Nov 25, 2016 at 2:31 PM, Dan Bloomberg <dan.bloomberg@gmail.com>
wrote:

> Here is my unofficial take on the ABI shared object version numbers. Jeff
> knows about these details and can correct if I'm wrong.
>
> With the Debian releases, we will need to increase the *shared object
> version number* (which is different from the leptonica release number)
> with any change in the ABI.  The Debian leptonica *soversion* for 1.73 is
> 5.0.0, and for 1.74 I believe that we'll increase it to 6.0.0.
>
> The meaning of these three digits is, for the shared object name
> *whatever.so.X.Y.Z*, we increment
>
>     X if the ABI release is backwards incompatible
>     Y if the ABI release is backwards compatible (with interface changes)
>     Z if there are only internal changes (no change to the ABI)
>
> So if I write the wrapper mentioned above, and that were the only change,
> then the ABI would be backwards compatible and we'd only need to increment
> to 5.1.0 for the next Debian release.  (However, there have been other
> changes, including the removal of deprecated functions.)
>
> On Fri, Nov 25, 2016 at 1:01 PM, Egor Pugin <notifications@github.com>
> wrote:
>
>> Yes, this seems ABI breakage. Both tesseract and leptonica do not use
>> semver (X.Y.Z), but use (X.Y), so personally I'm confused. With semver ABI
>> breakage only allowed when increasing X number. So, e.g. leptonica should
>> be versioned as 2.00 or whatever.
>>
>> ‚Äî
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-263022071>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AP6mLHznAbmXo5UwOhuUdFnN5qn1DQxCks5rB0y5gaJpZM4HeMNo>
>> .
>>
>
>
 Just released leptonica 1.74.0 on github  :-) I found this issue while searching for a bug I've been encountering: In a multi-page tiff file, the text is only being extracted from the last page when using Tesseract API [`TessBaseAPIProcessPages`] (https://github.com/tesseract-ocr/tesseract/issues/1138)

Leptonica has a method called `pixaReadMultipageTiff `, would that need to be used instead? 

  hi 
this project support persian language ?
if no
how can i help for support persian ?
 ‚Äãhi
no, there is a on dead project to add Persian to tesseract

you can find it at ‚Äãhttps://github.com/roozgar/PersianOcr
and send any support request here ...
 @amitdo is there any document about futures of new engine?!
  Hi,

I have test set that only has "uppercase English alphabets" and "numbers".
Is there a way to modify the existing traineddata file so that it only reads upper case alphabets and numbers?

thanks in advance
  Takes advantage of inheritance and default of `dir="ltr"` to:
- only generate paragraph `dir` attributes which are not `ltr`
- only generate word `dir` attributes which don't match enclosing paragraph

Tested against LTR, RTL, and mixed direction files. Files for the latter two cases are in a separate PR
 OK. I was hoping the scheme could be extended to pages or careas later, but I've made the suggested change and updated the branch.
 Rebased against current head and added fix for Microsoft build breakage introduced by #226. Apply this before #224.
 Closing in favor of a merged PR which incorporates both #223 and #224
  ```
# TESSDATA_PREFIX=/usr/share/tesseract-ocr/tessdata

# echo $TESSDATA_PREFIX
/usr/share/tesseract-ocr/tessdata

# tesseract test.jpg test.txt digits
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
Error opening data file /usr/share/tessdata/eng.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your "tessdata" directory.
Failed loading language 'eng'
Tesseract couldn't load any languages!
Could not initialize tesseract.
```

Note: there is indeed no `eng.traineddata` file in `/usr/share/tesseract-ocr/tessdata`  (there are a bunch of other `eng.xxx` files but no .traineddata), so it is expected to get an error, **_but**_ the error message says it failed to open **_/usr/share/tessdata/eng.traineddata**_ while `TESSDATA_PREFIX` is set to **_/usr/share/tesseract-ocr/tessdata**_.
So, either the file path in the error message is not the actual path of the file that is not found, or tesseract is ignoring the variable TESSDATA_PREFIX, in which case the error message is wrong when it says "make sure the TESSDATA_PREFIX environment variable....".

Whichever the case, something is buggy, regardless of the fact that I have no eng.traineddata file anywhere and I don't expect tesseract to work. I just expect a consistent error message.
 > So, if your tessdata dir is in the /usr/share/tesseract-ocr dir, 
> TESSDATA_PREFIX should be set to /usr/share/tesseract-ocr.

Oh, that's strange, because I later figured out the `export` thing, and I did `export TESSDATA_PREFIX=/usr/share/tesseract-ocr/tessdata`, and it did work. Actually, it works both with and without `/tessdata`

Now I get `read_params_file: Can't open digits`, but that's another story I guess.

> Setting TESSDATA_PREFIX is not needed as long as your tessdata directory is at the right place
> ($PREFIX/share/tessdata).

Of course, but it obviously isn't in my case.
 > @teo1978: well it could be the same story, because config files has to be with expected directory 
> structure in TESSDATA_PREFIX...

No, because I fixed `export TESSDATA_PREFIX=/usr/share/tesseract-ocr`, and the _Can't open digits_ error persists
 It wasn't. Apparently the installation of the language package was a mess. Some files (including configs/digits) were in /usr/share/tessdata; others (eng.\* but not eng.traineddata) were in /usr/share/tesseract-ocr/tessdata; and eng.traineddata wasn't anywhere (I'm positive because I did a `find`), so I had downloaded it manually where the other eng.\* files were...
 This report appears to be from a Debian system or similar. If Tesseract was installed via the standard mechanism (apt-get) then the package maintainer has already made life easy. Because everything goes to a standard and known location, there is no need to set any environment variables such as TESSDATA_PREFIX. Or take any other manual installation action. The English language data (including eng.traineddata) is in the tesseract-ocr-eng package. I am the Tesseract package maintainer for Debian systems.

Here is the list of files of tesseract-ocr-eng
https://packages.debian.org/sid/all/tesseract-ocr-eng/filelist
 Yes this is on Debian 6.

>  If Tesseract was installed via the standard mechanism (apt-get) then the package maintainer has already made life easy.

Or he should have. We had installed tesseract-ocr and tesseract-ocr-eng via `apt-get`, and it was so broken (or so obsolete) that `tesseract -v` would issue an error message saying `-v` was an invalid option. That's why I went through the hell of compiling it from scratch.

> The English language data (including eng.traineddata) is in the tesseract-ocr-eng package.

Maybe the eng.traineddata file was not included, for whatever reason, in the Debian 6 version of the package. I have seen a lot of questions in forums about the same issue (eng.traineddata missing after installing the package).
 You can think of Debian as a curated software collection. Debian 6 was released on February 6th, 2011 and all its packages are from that era. It contained Tesseract 2.04 which is ancient history. Please note that Debian 6 is officially obsolete, and the current stable release is Debian 8.  See https://www.debian.org/releases/

Unlike some other operating systems, best practice for Debian is to update the entire distribution if you want more recent versions of programs. Trying to install a modern Tesseract on an older Linux distribution is really tricky, especially because there are a lot of dependencies involved. I strongly do not recommend it.
 Actually debian 6 is LTS until this 29 of February https://wiki.debian.org/LTS

So, I would have expected a packgage for Debian 6 to be maintained to not become "ancient history" until, well, just now.
 You missed several important points:
- Debian LTS only provides security maintenance.
- Debian LTS is not supported by the normal Debian maintainers, but by a separate group of volunteers and companies.

As @jbreiden already said, you have the option to upgrade to a newer version of Debian. Or you can also take any other current distribution.
  As discussed at length in issue #182, the existing pdf.ttf causes difficulties
for certain PDF viewers, in part because the old file had zero advance width.

With testing, sharp2.ttf seems to be the best available compromise, although
it's not perfect and causes some visual difficulties in Evince.  It does
seem to fix Kindle and OS X Preview.
 Test PDF is here:
https://github.com/tesseract-ocr/tesseract/files/119875/simple-1.pdf
 I have checked: Acrobat XI, Google Chrome PDF Viewer, OS X Preview, Safari PDF viewer; all on El Capitan.
 See #182 for other tests people did with sharp2.ttf
 Chromium and Adobe Reader on Linux are fine. I have reports that Ghostscipt and friends are okay. I should probably double check Android right now.
 Latest stock Android (Marshmallow) is fine.
 Using `sample-1.pdf` from above in the latest pdf.js results in the 2nd word highlighting properly, while the 1st word's highlight is offset. I don't think this is a regression (and it might actually be an improvement) as there were highlighting-offset issues using the previous pdf.ttf with pdf.js. Related to https://github.com/mozilla/pdf.js/issues/6863. 

![screen shot 2016-02-12 at 8 10 39 am](https://cloud.githubusercontent.com/assets/735679/13009192/a1bd5ab4-d160-11e5-9e1c-355bca978774.png)
 I've been tracking the Firefox offset problem in https://github.com/mozilla/pdf.js/issues/6509 and it looks like it has gotten a little worse with this change. (I take that back; your screenshot is worse but mine looks the same. Maybe you are using a different zoom level in Firefox or something)
  When we got a better OCR for Bengali language?
  ```
./autogen.sh
./configure
make
make install
```

all ran without errors (unless error messages are somewhere in the flood of output).

But when I run:

```
$ tesseract -v
tesseract: error while loading shared libraries: libtesseract.so.3: cannot open shared object file: No such file or directory
```

Either something is broken, or some informative error message is missing in the configure and/or make and/or install phase.
  ```
$ sudo apt-get install liblept4
Reading package lists... Done
Building dependency tree       
Reading state information... Done
liblept4 is already the newest version.
liblept4 set to manually installed.
The following packages were automatically installed and are no longer required:
  linux-image-4.2.0-23-generic linux-image-extra-4.2.0-23-generic
  linux-signed-image-4.2.0-23-generic
Use 'apt-get autoremove' to remove them.
0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.
```

```
teo@xxx1:~/temp/tesseract$ ./configure 
checking for g++... g++
...
checking for mbstate_t... yes
checking for leptonica... configure: error: leptonica not found
```

OR the error message needs to be more precise about how to get `leptonica`
 PEBCAK

You need the development package, which seems to be libleptonica-dev
 Yep, but the message says "leptonica not found", it should say "libleptonica-dev not found".
How am I supposed to guess that "leptonica" means libleptonica-dev?

PEBCAK, but whose chair and keyboard?
 Now on another host:

```
configure: error: leptonica library missing

# apt-get install libleptonica-dev 
Reading package lists... Done
Building dependency tree       
Reading state information... Done
libleptonica-dev is already the newest version.
```

Also,

> If you are not familiar with compiling software on your operation system it is not tesseract problem.

It is a documentation problem then. I am not familiar with compiling software indeed, but every time I have done it with other software, I usually follow the steps in the documentation and they work out of the box, and the requirements are specified clearly. 

Also, I wouldn't have to compile it at all if there was a decent Debian package not so riduculously obsolete that it doesn't even recognize the -v option.
 Not even with this:

```
$ export LIBLEPT_HEADERSDIR=/usr/include
$ ./configure --with-extra-libraries=/usr/lib
```

which are the paths where the headers and the library respectively are.
 I'd prefer a less inflammatory title for this bug report, please. Also, may I ask why you aren't installing Tesseract via apt-get? Debian Stable ships with version 3.03, see https://packages.qa.debian.org/t/tesseract.html

```
$ sudo apt-get install tesseract-ocr

$ tesseract -v
tesseract 3.03
 leptonica-1.70
  libgif 4.1.6(?) : libjpeg 8d : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8 : webp 0.4.0
```
 > Also, may I ask why you aren't installing Tesseract via apt-get?

Because that's how it had been installed in the first place, and `tesseract -v` gave an error not recognizing the `-v` option. **This is on Debian 6**
 > @teo1978: this is standard autotools error message. [...] Name of needed package could be different base on distribution.

That's no excuse. It should still specify that it needs the headers, i.e. _-dev_ package. There's no way the person installing should know whether the binary package or the headers package is required, regardless of the actual names.

Besides, I don't know what "autotools error message" means, but the error message is hard-coded in the `configure` file, so it could be easily edited.

Also note that the error message **_"leptonica library missing"**_ issued when the `pixCreate` check fails (whatever that means)  is very confusing too. "Leptonica library missing" seems to indicate that the leptonica library is missing. Instead, you get this message when the leptonica library is actually found and something, which is not clear what it is, is missing. That error message is clearly useful to those who wrote and/or maintain tesseract, but is completely obscure to anyone else.

**This issue should be reopened**
 This issue should not be re-opened, and let me explain why. Tesseract uses a venerable and very common build system called autotools. (And I'll admit, autotools has a well deserved reputation for being complicated.) This build system is designed to work with many different operating systems, not just Linux. Over the years it has supported operating systems like Solaris, Ultrix, AIX, Cygwin, OS X, and many, many others. Each of these operating systems can have wildly different ideas about organization and packaging of software. The autotools system created the `configure` file, and its error messages are therefore are not tailored to any particular operating system.  

You are running into issues and error messages that are really for developers or system integrators to deal with. As a user, the recommended procedure is to not worry about integrating Tesseract into your computer starting from source code, but rather take advantage of the packaging work done by others. Update your Linux distribution to the modern era, install tesseract with the standard tools, and it will work. The alternative is doing a ton of system administration work (not just with Tesseract, but with its entire chain of dependencies) that is not particularly fun or easy.

If you really want to learn about the nuances of autotools, there are entire books written about it such as https://www.sourceware.org/autobook/autobook/autobook_toc.html However, I respectfully suggest spending the time and brain cells on something else. I expect that most software will eventually move to simpler and better build systems in future decades. 
 > This issue should not be re-opened, and let me explain why.

You  have only explained the cause of the issue.

I think you misunderstood the point I made in comment https://github.com/tesseract-ocr/tesseract/issues/215#issuecomment-181944624
What I meant is not that the error message should give you the exact name of the package - I do understand that can change from OS to OS- but it could **easily** be more informative in telling you that it's missing the _headers_ and not the actual library.

>  The autotools system created the configure file

That doesn't mean you can't edit it.

> You are running into issues and error messages that are really for developers or system integrators to deal with. **As a user**, the recommended procedure is to **not** worry about integrating Tesseract into your computer starting **from source code**

That's the whole essence of this issue (and I guess many others): that is a **plain wrong approach**. 
Granted, the _recommended_ procedure is to take advantage of package, but you should take into account that the recommended procedure **is not always an option**. 

**A user may well have to compile the software** from source code, either because the distribution he needs to install it on is not "from the modern era" - by the way, Debian 6 is **just 5 years old**; let me ask a question: would you tell somebody trying to install tesseract on **Windows Vista** (released 2007) to upgrade their OS to the modern era? - or because it's a distribution for which there's no package at all.

I know compiling is not supposed to be particuarly easy for the end user, but there's no need to make it more painful than it could easily be. I have had to compile software from source quite a few times, though I am no developer (of the software I had to compile) or system integrator, and usually they come with an unambiguous list of requirements, a set of steps to follow (typically run a bash script that ships with the source code, then configure, then make and make install, like in this case) and they **usually work out of the box**. And **when they don't**, you definitely know right away what you're missing from a glance at an error message. If neither of these is the case, then I'm sorry but it's poorly maintained software.

In this issue I am reporting the fact that the error messages issued when the leptonica _headers_ are missing or when some stuff related to a `pixCreate` thing is missing (what is that? a function in the library whose inavailability means the version of the library doesn't meet the requirements?), are poor. This could easily, and hence should, be improved. You explained perfectly (it was already clear) why the situation is what it is, but that's no valid reason for not improving it. 

You confuse an explanation of why the problem exists with an argumentation that it is not a problem (which unfortunately is, I have to admit, a pretty common mistake).
 I'm having the same problem, and I can't figure out how to solve it. 
 Please use [Tesseract users forum](https://groups.google.com/d/forum/tesseract-ocr) and ask this question (and other questions you might have) there.
 > Please use Tesseract users forum and ask this question (and other questions you might have) there.

What about fixing the bug instead, so that the error message is clear enough and there's nothing to figure out?
 any solution to this issue? >any solution to this issue?

Yes.
* Most users should install the version that is available through the package manager of their distro.
 * **Advanced  users** can try to install a newer version from source. They should follow the instruction in the wiki.
* If a user still have problems installing the software, he/she should use the forum for support.

Like it or not, that's our solution. Try using "make install" after "make " inside your leptonica-1.xx folder  Can Tesseract be used for music sheet recognition? 
 No, but it is used by Audiveris (https://audiveris.kenai.com/) which can.
 Didn't know that Tesseract can be used for recognizing notations!. Just what I needed. So what is OCR used in Audiveris for?
Thanks üôèüèø 
Ananth Got it! Many Thanks. So is OpenCV my best option? What about other deep learning frameworks such as TensorFlow?
Cheers
Ananth  Hello,

Refer to issue #169, I spend long time trying to modified language files.
Do you have a plan to update Arabic Language files in the coming releases.

Many Thanks in Advance 
  Hi,
I recently started using tesseract to help unclutter my desk at home, so forgive me if this is a n00b question/request.

I use textcleaner from Fred's ImageMagick Scripts to cleanup my scanned images for better OCR accuracy. However, the images that are optimized for OCR do not necessarily look good from a human standpoint, and I would like the final OCR'd PDF to look visually identical to the original scan.

So here's my feature request: Add an optional argument to take a cleaned image. Example invocation: tesseract -l eng -psm 4 --cleaned-image ${SRC}_cleaned.pnm ${SRC}.pnm out pdf

It will use ${SRC}.pnm to generate the final PDF image but layout detection, character recognition, etc. will be done using the --cleaned-image argument for better accuracy. That way the user will be given a final PDF that looks like the original but searches as well as the cleaned-up image.

I'd be surprised if nobody has already thought of this, so maybe work is already underway or maybe it's not possible. Thoughts?
 zdenop: Yes, that is correct. I want to run OCR on image_b (improved for OCR), but include image_a (original) in the resulting PDF.

BTW - I just realized that there is a user forum (https://groups.google.com/forum/#!forum/tesseract-ocr). Maybe somebody has asked / answered my question there. My apologies for not looking at that forum earlier.
 Please post an example of a cleaned vs uncleaned image where accuracy improves significantly. Or even better, point to some documentation that has some examples. In the long term, one would hope that OCR could improve such that having a separate cleaned image is unnecessary.

Regarding this feature request, I think it is probably better to use an outside utility that can replace the images in a Tesseract produced PDF. The caller is already generating a separate set of clean images, so is therefore comfortable with pre/post processing. This approach lets us keep the design intent and implementation of PDF generation simple ('don't mess with the images'). I don't know if such a tool exists already, but based on my knowledge of the Tesseract PDF it shouldn't be too hard to write. Apologies, but I am not volunteering to write one unless I need it myself for something. The closest existing thing I know about is OverlayPDF from Apache PDFBox. Previously mentioned here. https://www.mail-archive.com/tesseract-ocr@googlegroups.com/msg11853.html

Also, if you really want to hack Tesseract to do what you are asking for, the code is in api/pdfrenderer.cc. You would have to replace both the pix and the filename. I'd just be reluctant to make this a general feature of Tesseract.

https://github.com/tesseract-ocr/tesseract/blob/master/api/pdfrenderer.cpp#L894
 Hi jbreiden,
There are lots of tutorials on-line for how to clean-up images for improved accuracy OCR out there, just use your favorite search engine. Here's a good one from 2014 (not too old): http://www.christophermchurch.com/my-struggles-with-ocr-and-microfilm-scans/ . Yes, it would be nice if OCR engines were perfect and didn't need cleaned-up images. But that's currently not a realistic expectation when papers get crumpled, have background images, have shaded regions, are "scanned" using a cell phone camera with poor lighting conditions, etc.

I don't think it would be wise to try to add all that clean-up functionality into tesseract, which is why I'm proposing a solution to take an image that has already been processed externally. The exact intent is to "not mess with the images."

An external tool that could replace the image layer would certainly be good, but I haven't found any (suggestions welcome!). I tried to use hocr2pdf to use tesseract's .hocr data from my cleaned image and add it to a PDF with my original image but ran into a showstopper issue - When searching for a word in the document, the PDF viewers I tried would highlight the wrong part of the document. Maybe there is a bug with hocr2pdf or I am using it incorrectly. Tesseract already knows how to make a PDF so this reduces the possibility of an external program interpreting the PDF or hOCR specs differently and ruining the output.

Anyway, thanks for the pointer to api/pdfrenderer.cc! I might just add the feature locally to address my needs, or maybe try to start a new program based off of it as you suggest.

I don't mind closing this issue if others feel this feature is inappropriate or a better solution is made.
 Swapping images in Tesseract a PDF is pretty easy for a programmer if destination images are JPEG or JPEG 2000. It is really just a matter of cutting and pasting the data, then cleaning up the results with qpdf.  The hardest part is getting the courage to open up a PDF file and look inside it.

Regarding HOCR and bounding boxes, make sure you have image resolution metadata set correctly everywhere. The hocr-pdf program mentioned above works okay, but is limited to latin character sets and will also struggle with ligatures in English.
 Heh, yeah, I opened up a PDF and saw the stream content for the image and was thinking of how to replace it, but it seemed like there'd be a non-trivial amount of work to get right for a PDF n00b such as myself.

As far as I could tell the image resolution metadata was correct, or at least consistent. Couldn't get hocr-pdf working unfortunately due to some python module dependency that I couldn't find (I installed PyXML but no dice).

In the end I just went ahead and hacked my feature into Tesseract and it works pretty well :-) Here it is if you're interested, though be warned that it's a bit of a kludge in its current state: https://github.com/dhendrix/tesseract/commit/6cc206f5e4f734ba178c18e5a962563aace35018

Thanks for the helpful pointers! Feel free to close if this feature is not desired for upstream, it can live on in my github account.
 The python dependency is reportlab.
  Where can I download Tesseract for Windows?
All Links point to code.google.com, but since Tesseract has moved here all links are dead.

Also I would like to downoad different versions (2.x, 3.x) to see if any of them works.
The version I have right now (3.05 Setup) does not read any images but produces errors instead.
 That might be caused by missing permissions: all but the very latest version try to create temporary files in the root directory c:. You will need a Tesseract build with a very new version of Leptonica to fix this problem, see https://github.com/DanBloomberg/leptonica/commit/3038a7074d5b1dc6511af19085d980d1e0ae399c.
See also issue #171.
 OK, thanks for the replies. Can I download a version somewhere that
a) Does not have the bug mentioned by stweil
b) Includes the image loading functionality

On https://github.com/tesseract-ocr/tesseract/wiki/Downloads it says "Currently, there is no official Windows installer for newer versions." :-(
The 3.05 setup from https://github.com/UB-Mannheim/tesseract/wiki does also not work (as mentioned above).
 Hi, I made a step by step guide how to compile Tesseract on Windows.. You can check my guide's here: http://gensanblog.com/2016/01/28/how-to-compile-tesseract-git-project-on-windows/

You can also download the compiled version.. 
 Hi Egor, thank you for correcting.. I am new to this and I made lots of edit's on the guide.. I will edit my post and focus on cygwin, I also added dll's so that it can run without cygwin.. I'll create a new guide for MSVC..
 @egorpugin : Could you also build the training program - text2image for windows
 @egorpugin: OK.

@zdenop : There are a number of older requests/issues for windows build. I'll add a comment to refer to this issue and you could close them. Thanks!
 @egorpugin - Are the windows binaries at 
https://www.dropbox.com/s/8t54mz39i58qslh/tesseract-3.05.00dev-win32-vc19.zip?dl=1
for the current development version (after the release of 3.04.01)?

Thanks!
 Thanks for clarifying, @egorpugin .

I was confused after seeing the following on the releases page:

```
on Jul 22, 2015 
3.05.00dev  ‚Ä¶
increase version number
 71e226c   zip   tar.gz
```
 This build does not create PDFs, but the cygwin from http://3.onj.me/tesseract/ build does.
So currently the VS build is not usable.
 The installers (made with MinGW-w64) are at https://github.com/UB-Mannheim/tesseract/wiki.
 https://github.com/UB-Mannheim/tesseract doesn't seem to provide binaries right now.
 @nickbe, just add `/wiki` to that URL...
 But these do not seem to be the VC binaries, or are they? There's only a problem with generating PDFs with the VC runtimes.
 That's right, the UB Mannheim executables are built with [Mingw-w64](http://mingw-w64.org/).
 Latest VC binaries by @egorpugin with PDF generation are at following link, as per  [#338](https://github.com/tesseract-ocr/tesseract/issues/338): https://www.dropbox.com/s/pxu2hp6mg1a64zj/tesseract-3.05.00dev-win32-vc19-2016-jun-03.zip?dl=1
 Great. Thanks !
 @egorpugin I follow the instructions. 

However CPPAN returns

> Requesting dependency list
> SSL connect error

Is that any configuration I am missing?
  I have created new Trained data "eng2.traineddata", now i want to add it to config folder. not by this step "sudo cp eng2.traineddata /usr/local/share/tessdata/"

want to add in makefile and then install tesseract. ../tesseract-ocr/tessdata/Makefile.in
Dont want to execute by "tesseract test.png test -l eng2"
Want to make this as default.

can anybody help me with steps which all files do i need to change.
  I download recent leptonica version but when i build opencv project  
"Cannot open input file 'liblept171.lib' error"
this msg came out..... where can i get liblept171.lib... 
i research google but there is no answer for this error....
 no I use this project...
and build this project .. that msg came from when i build it 
  I wanted to use former version 3.02 but.... google link redirect here......

so i can't get former version.... fix please....
  Tesseract Orientation and script detection works fine on many images, but fails in many cases to like 

Image with maps, no EXIF-Data, Multiple text lines with different directions 

`tesseract shots-1.jpg out  - -psm 0
`

> Tesseract Open Source OCR Engine v3.04.00 with Leptonica
> Orientation: 3
> Orientation in degrees: 90
> Orientation confidence: 5.11
> Script: 1
> Script confidence: 9.74
> 
> ![shots-1](https://cloud.githubusercontent.com/assets/331827/12638871/5bae017c-c5c6-11e5-96bc-314418b73698.jpg)

Any other way to get best possible value for Orientation and script detection ?
 General questions are better asked on the mailing list where more people will see them.
  actual_tessdata_num_entries_ <= TESSDATA_NUM_ENTRIES:Error:Assert failed:in file
 ..\ccutil\tessdatamanager.cpp, line 48
  Can you provide a Windows installation for those that do not have the expertise to compile these sources as you did before moving the project to Github?

The last installer I know of was for version 3.02.02
 Does https://github.com/UB-Mannheim/tesseract help?
 Hi,

Thanks for your reply. I downloaded the zip and extracted it. I still could
not find any .exe files. Plus the whole download is only 2.4MB and the
original 3.02.02 installation was 30+ MB as an installer.

Regards,
Tony

On Wed, Jan 27, 2016 at 4:02 PM, Stefan Weil notifications@github.com
wrote:

> Does https://github.com/UB-Mannheim/tesseract help?
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/200#issuecomment-175420528
> .
 My fault, wrong link (the info is in the wiki): https://github.com/UB-Mannheim/tesseract/wiki should be better.
 Perfect :-)

Thank you!

Enjoy you day.

On Wed, Jan 27, 2016 at 4:44 PM, Stefan Weil notifications@github.com
wrote:

> May fault, wrong link (the info is in the wiki):
> https://github.com/UB-Mannheim/tesseract/wiki should be better.
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/200#issuecomment-175434615
> .
 @amitdo, thanks, pulled. :-)
 Hi Stefan,

I installed the version 3.05.00dev and it produces the following error.

Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Warning in pixReadMemPng: work-around: writing to a temp file
libpng warning: Application built with libpng-1.4.3 but running with 1.5.14
Error in pixReadStreamPng: png_ptr not made
Error in pixReadMemPng: pix not read
Error in pixReadMem: png: no pix returned
Error during processing.

The installation replaced the previous version of 3.02.02

On Thu, Jan 28, 2016 at 4:04 AM, Stefan Weil notifications@github.com
wrote:

> @amitdo https://github.com/amitdo, thanks, pulled. :-)
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/200#issuecomment-175775012
> .
 This might be caused by the Leptonica code used for Tesseract: it tries to create a temp file in c:\ and fails because you don't have write permission there. So it should work if you run Tesseract as admin or if you change the permissions for c:.

I fixed this for JPEG-2000 files, but not for other image formats like PNG. See the discussion on https://github.com/DanBloomberg/leptonica/pull/116 for more information.
 Hi tonym1995,

I made a full instruction how to install and compile tesseract on windows http://gensanblog.com/2016/01/28/how-to-compile-tesseract-git-project-on-windows/

Hope this can help!

Erwin
 Hi,
thank you!
i have to say for a Windows newcomer finding this project it is horrible to get started from the README.md 
@bantilan your blog entry should be in the project's wiki!
Best
uhu
 [See issue 209](https://github.com/tesseract-ocr/tesseract/issues/209)
  disappointed w/ open-source stuff. allheaders.h seems to be missing. Trying to compile w/ Visual Studio 2010, using make file included in project. Not clear how to build this project otherwise. Why so much code? :-)
 `allheaders.h` is part of the Leptonica package. You will need that package, too. And even more code ... :-)
 Same for me. I don't want to sound arrogant but when I release a package, I make sure it is complete, it it ain't, then a readme file tells what's missing and where to find it.
 Same for me too. [https://tpgit.github.io/Leptonica/allheaders_8h_source.html ](url)
This is the homepage of allheaders.h >https://tpgit.github.io/Leptonica/allheaders_8h_source.html
This is the homepage of allheaders.h

The homepage of Leptonica is here:
http://www.leptonica.org/

Official GitHub repo:
https://github.com/DanBloomberg/leptonica
  After working around the bug in #195 I have now managed to generate some training data. However, when I try to use it, tesseract segfaults.

``` sh
api/tesseract test.CutiveMono.exp0.tif test.CutiveMono.exp0 box.train.stderr
```

``` text
(lldb) run
Process 69791 launched: '/Users/linus/coding/tesseract/api/.libs/tesseract' (x86_64)
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Process 69791 stopped
* thread #1: tid = 0x1d82bc0, 0x0000000100012d10 libtesseract.3.dylib`tesseract::TessResultRenderer::BeginDocument(this=0x0000000000000010, title="") + 16 at renderer.cpp:54, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x40)
    frame #0: 0x0000000100012d10 libtesseract.3.dylib`tesseract::TessResultRenderer::BeginDocument(this=0x0000000000000010, title="") + 16 at renderer.cpp:54
   51   }
   52   
   53   bool TessResultRenderer::BeginDocument(const char* title) {
-> 54     if (!happy_) return false;
   55     title_ = title;
   56     imagenum_ = -1;
   57     bool ok = BeginDocumentHandler();
(lldb) bt
* thread #1: tid = 0x1d82bc0, 0x0000000100012d10 libtesseract.3.dylib`tesseract::TessResultRenderer::BeginDocument(this=0x0000000000000010, title="") + 16 at renderer.cpp:54, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x40)
  * frame #0: 0x0000000100012d10 libtesseract.3.dylib`tesseract::TessResultRenderer::BeginDocument(this=0x0000000000000010, title="") + 16 at renderer.cpp:54
    frame #1: 0x000000010000b21c libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPagesInternal(this=0x00007fff5fbff598, filename="test.CutiveMono.exp0.tif", retry_config=0x0000000000000000, timeout_millisec=0, renderer=0x0000000000000010) + 732 at baseapi.cpp:1166
    frame #2: 0x000000010000aeef libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPages(this=0x00007fff5fbff598, filename=<unavailable>, retry_config=<unavailable>, timeout_millisec=<unavailable>, renderer=<unavailable>) + 15 at baseapi.cpp:1074
    frame #3: 0x0000000100001869 tesseract`main(argc=<unavailable>, argv=<unavailable>) + 665 at tesseractmain.cpp:429
    frame #4: 0x00007fff8a2645ad libdyld.dylib`start + 1
```
 d4e0c64 gives me another segfault, but it seems to be later in :)

``` text
(lldb) run
Process 89333 launched: '/Users/linus/coding/tesseract/api/.libs/tesseract' (x86_64)
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Process 89333 stopped
* thread #1: tid = 0x1e23c8e, 0x0000000100182335 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) [inlined] ELIST_ITERATOR::set_to_list(list_to_iterate=0x0000000000000008) + 4 at elst.h:306, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x8)
    frame #0: 0x0000000100182335 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) [inlined] ELIST_ITERATOR::set_to_list(list_to_iterate=0x0000000000000008) + 4 at elst.h:306
   303    #endif
   304  
   305    list = list_to_iterate;
-> 306    prev = list->last;
   307    current = list->First ();
   308    next = current ? current->next : NULL;
   309    cycle_pt = NULL;               //await explicit set
(lldb) bt
* thread #1: tid = 0x1e23c8e, 0x0000000100182335 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) [inlined] ELIST_ITERATOR::set_to_list(list_to_iterate=0x0000000000000008) + 4 at elst.h:306, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x8)
  * frame #0: 0x0000000100182335 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) [inlined] ELIST_ITERATOR::set_to_list(list_to_iterate=0x0000000000000008) + 4 at elst.h:306
    frame #1: 0x0000000100182331 libtesseract.3.dylib`PAGE_RES_IT::start_page(this=0x00007fff5fbff060, empty_ok=false) + 17 at pageres.cpp:1510
    frame #2: 0x000000010001acb0 libtesseract.3.dylib`tesseract::Tesseract::ApplyBoxTraining(STRING const&, PAGE_RES*) [inlined] PAGE_RES_IT::restart_page(this=<unavailable>) + 80 at pageres.h:681
    frame #3: 0x000000010001acab libtesseract.3.dylib`tesseract::Tesseract::ApplyBoxTraining(STRING const&, PAGE_RES*) [inlined] PAGE_RES_IT::PAGE_RES_IT(this=<unavailable>, the_page_res=<unavailable>) + 49 at pageres.h:665
    frame #4: 0x000000010001ac7a libtesseract.3.dylib`tesseract::Tesseract::ApplyBoxTraining(STRING const&, PAGE_RES*) [inlined] PAGE_RES_IT::PAGE_RES_IT(this=<unavailable>, the_page_res=<unavailable>) at pageres.h:663
    frame #5: 0x000000010001ac7a libtesseract.3.dylib`tesseract::Tesseract::ApplyBoxTraining(this=0x0000000101002c00, fontname=0x00007fff5fbff1c0, page_res=<unavailable>) + 26 at applybox.cpp:797
    frame #6: 0x000000010000a4a1 libtesseract.3.dylib`tesseract::TessBaseAPI::Recognize(this=<unavailable>, monitor=0x0000000000000000) + 609 at baseapi.cpp:883
    frame #7: 0x000000010000ad8b libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPage(this=<unavailable>, pix=<unavailable>, page_index=<unavailable>, filename=<unavailable>, retry_config=0x0000000000000000, timeout_millisec=<unavailable>, renderer=0x0000000000000000) + 347 at baseapi.cpp:1224
    frame #8: 0x000000010000afec libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPagesMultipageTiff(this=0x00007fff5fbff688, data="II*", size=1982406, filename="test.CutiveMono.exp0.tif", retry_config=0x0000000000000000, timeout_millisec=0, renderer=<unavailable>, tessedit_page_number=-1) + 284 at baseapi.cpp:1056
    frame #9: 0x000000010000b41d libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPagesInternal(this=0x00007fff5fbff688, filename="test.CutiveMono.exp0.tif", retry_config=0x0000000000000000, timeout_millisec=<unavailable>, renderer=0x0000000102845980) + 877 at baseapi.cpp:1174
    frame #10: 0x000000010000b05f libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPages(this=0x00007fff5fbff688, filename=<unavailable>, retry_config=<unavailable>, timeout_millisec=<unavailable>, renderer=<unavailable>) + 15 at baseapi.cpp:1074
    frame #11: 0x00000001000018c3 tesseract`main(argc=<unavailable>, argv=<unavailable>) + 515 at tesseractmain.cpp:407
    frame #12: 0x00007fff8a2645ad libdyld.dylib`start + 1
    frame #13: 0x00007fff8a2645ad libdyld.dylib`start + 1
```
 And 228317c, (3.04.00) segfaults with at another place

``` text
(lldb) run
Process 3475 launched: '/Users/linus/coding/tesseract/api/.libs/tesseract' (x86_64)
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
Page 1
Process 3475 stopped
* thread #1: tid = 0x1e70af8, 0x000000010019d155 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) + 21, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x8)
    frame #0: 0x000000010019d155 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) + 21
libtesseract.3.dylib`PAGE_RES_IT::start_page:
->  0x10019d155 <+21>: movq   0x8(%rax), %rax
    0x10019d159 <+25>: movq   %rax, 0x58(%rbx)
    0x10019d15d <+29>: testq  %rax, %rax
    0x10019d160 <+32>: je     0x10019d17d               ; <+61>
(lldb) bt
* thread #1: tid = 0x1e70af8, 0x000000010019d155 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) + 21, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x8)
  * frame #0: 0x000000010019d155 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) + 21
    frame #1: 0x0000000100019930 libtesseract.3.dylib`tesseract::Tesseract::ApplyBoxTraining(STRING const&, PAGE_RES*) + 80
    frame #2: 0x0000000100009571 libtesseract.3.dylib`tesseract::TessBaseAPI::Recognize(ETEXT_DESC*) + 609
    frame #3: 0x0000000100009e74 libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPage(Pix*, int, char const*, char const*, int, tesseract::TessResultRenderer*) + 356
    frame #4: 0x000000010000a0cc libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPagesMultipageTiff(unsigned char const*, unsigned long, char const*, char const*, int, tesseract::TessResultRenderer*, int) + 284
    frame #5: 0x000000010000a4fd libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPagesInternal(char const*, char const*, int, tesseract::TessResultRenderer*) + 877
    frame #6: 0x000000010000a13f libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPages(char const*, char const*, int, tesseract::TessResultRenderer*) + 15
    frame #7: 0x0000000100001649 tesseract`main + 2841
    frame #8: 0x00007fff8a2645ad libdyld.dylib`start + 1
```
 That worked! Cool, seems like something was wrong with my `tif` file then?

Is there anything more we can do to debug this?

I really appreciate the help!
  I'm trying to use the `text2image` utility to train tesseract. Unfortunately it keeps crashing every time I try to use it :(

``` sh
text2image --text=training_text.txt --outputbase=test.MenloMedium.exp0 --font='Menlo Medium' --fonts_dir=/Library/Fonts/
```

``` text
(lldb) run
Process 49926 launched: '/usr/local/bin/text2image' (x86_64)
Process 49926 stopped
* thread #1: tid = 0x1d2b8cb, 0x0000000100b74358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x0)
    frame #0: 0x0000000100b74358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25
libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph:
->  0x100b74358 <+25>: movq   (%rcx), %rdi
    0x100b7435b <+28>: testq  %rdi, %rdi
    0x100b7435e <+31>: je     0x100b74369               ; <+42>
    0x100b74360 <+33>: movq   %rax, %rsi
(lldb) bt
* thread #1: tid = 0x1d2b8cb, 0x0000000100b74358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x0)
  * frame #0: 0x0000000100b74358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25
    frame #1: 0x000000010000edc1 text2image`tesseract::PangoFontInfo::CanRenderString(char const*, int, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >*) const + 321
    frame #2: 0x000000010000ec57 text2image`tesseract::PangoFontInfo::CanRenderString(char const*, int) const + 33
    frame #3: 0x0000000100015227 text2image`tesseract::StringRenderer::StripUnrenderableWords(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >*) const + 193
    frame #4: 0x00000001000154aa text2image`tesseract::StringRenderer::RenderToImage(char const*, int, Pix**) + 418
    frame #5: 0x0000000100005748 text2image`main + 2891
    frame #6: 0x00007fff8a2645ad libdyld.dylib`start + 1
    frame #7: 0x00007fff8a2645ad libdyld.dylib`start + 1
```
 My guess, and it's very uneducated, is that the pointer from `run->item->analysis.font` only points to a `PangoFont` and not a `PangoFcFont`. Since it's `reinterpret_cast`ed into the later `pango_fc_font_get_glyph` somewhere hits a null pointer.

I have checked that `run->item->analysis.font` isn't a null pointer, it isn't.
 My very crude workaround for now:

``` diff
diff --git a/training/pango_font_info.cpp b/training/pango_font_info.cpp
index b542591..86c108e 100644
--- a/training/pango_font_info.cpp
+++ b/training/pango_font_info.cpp
@@ -416,10 +416,13 @@ bool PangoFontInfo::CanRenderString(const char* utf8_word, int len,
       tlog(2, "Found end of line NULL run marker\n");
       continue;
     }
-    PangoGlyph dotted_circle_glyph;
+    // PangoGlyph dotted_circle_glyph;
     PangoFont* font = run->item->analysis.font;
-    dotted_circle_glyph = pango_fc_font_get_glyph(
-        reinterpret_cast<PangoFcFont*>(font), kDottedCircleGlyph);
+
+    // printf("The pointer: %p\n", (void *) font);
+
+    // dotted_circle_glyph = pango_fc_font_get_glyph(
+    //     reinterpret_cast<PangoFcFont*>(font), kDottedCircleGlyph);
     if (TLOG_IS_ON(2)) {
       PangoFontDescription* desc = pango_font_describe(font);
       char* desc_str = pango_font_description_to_string(desc);
@@ -456,9 +459,9 @@ bool PangoFontInfo::CanRenderString(const char* utf8_word, int len,
         const bool unknown_glyph =
             (cluster_iter.glyph_item->glyphs->glyphs[i].glyph &
              PANGO_GLYPH_UNKNOWN_FLAG);
-        const bool illegal_glyph =
-            (cluster_iter.glyph_item->glyphs->glyphs[i].glyph ==
-             dotted_circle_glyph);
+        const bool illegal_glyph = false;
+            // (cluster_iter.glyph_item->glyphs->glyphs[i].glyph ==
+            //  dotted_circle_glyph);
         bad_glyph = unknown_glyph || illegal_glyph;
         if (TLOG_IS_ON(2)) {
           printf("(%d=%d)", cluster_iter.glyph_item->glyphs->glyphs[i].glyph,
```
 Indeed, looks like the font is not a PangoFcFont.  Try using PANGO_FC_FONT(...) instead of the reinterpret_cast<...>, and you should get a warning.  You can use PANGO_IS_FC_FONT() to test at runtime.
 Sorry, I haven't had time to investigate this further. Hopefully I'll get some work done on this in the near future...
 @amitdo

I have same problem. I cannot use tesstrain.sh on Mac ( So, I use  Ubuntu on VirtualBox for training).

I tried bellow.

```
$ brew install  tesseract --with-training-tools --HEAD 
$ text2image --list_available_fonts --fonts_dir=/Library/Fonts
<skip>
```

There are total 1221 fonts installed. But 'Regular' style  is not included in text2image's output.
Even if some font has "Regular" style glyphs.

So, I can not try text2image with 'Regular' style font. What should I do for this issue? 

```
$ text2image --text=eng.training_text --outputbase=eng.MenloRegular.exp0 --font='Menlo Regular' --fonts_dir=/Library/Fonts
Could not find font named Menlo Regular. Pango suggested font Menlo Medium
Please correct --font arg.:Error:Assert failed:in file text2image.cpp, line 437
Abort trap: 6
```

ex. dejavu font (maybe not regular style,  [detail](https://gist.github.com/atuyosi/bc5387a4941e5d963365))

```
$ text2image --text=eng.training_text --outputbase=eng.MenloRegular.exp0 --font='DejaVu Sans Thin' --fonts_dir=~/Library/Fonts
Segmentation fault: 11
```
 HI @amitdo , my font lis is here.

[fontlist.txt](https://github.com/tesseract-ocr/tesseract/files/137785/fontlist.txt)

Thanks.
 @amitdo 

text2image's result is bellow:

```
$ text2image --text=eng.training_text --outputbase=eng.TimesNewRomanBold.exp0 --font='Times New Roman, Bold' --fonts_dir=/Library/Fonts
Segmentation fault: 11
```

detail back trace is bellow:

```
$ lldb /usr/local/bin/text2image
(lldb) target create "/usr/local/bin/text2image"
Current executable set to '/usr/local/bin/text2image' (x86_64).
(lldb) run --text=eng.training_text --outputbase=eng.TimesNewRomanBold.exp0 --font='Times New Roman, Bold' --fonts_dir=/Library/Fonts
Process 53735 launched: '/usr/local/bin/text2image' (x86_64)
Process 53735 stopped
* thread #1: tid = 0xf3978, 0x0000000100b98358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x0)
    frame #0: 0x0000000100b98358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25
libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph:
->  0x100b98358 <+25>: movq   (%rcx), %rdi
    0x100b9835b <+28>: testq  %rdi, %rdi
    0x100b9835e <+31>: je     0x100b98369               ; <+42>
    0x100b98360 <+33>: movq   %rax, %rsi
(lldb) bt
* thread #1: tid = 0xf3978, 0x0000000100b98358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x0)
  * frame #0: 0x0000000100b98358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25
    frame #1: 0x000000010000ea31 text2image`tesseract::PangoFontInfo::CanRenderString(char const*, int, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >*) const + 321
    frame #2: 0x000000010000e8c7 text2image`tesseract::PangoFontInfo::CanRenderString(char const*, int) const + 35
    frame #3: 0x0000000100015047 text2image`tesseract::StringRenderer::StripUnrenderableWords(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >*) const + 195
    frame #4: 0x00000001000152d0 text2image`tesseract::StringRenderer::RenderToImage(char const*, int, Pix**) + 418
    frame #5: 0x0000000100005541 text2image`main + 2895
    frame #6: 0x00007fff9c3ec5ad libdyld.dylib`start + 1
    frame #7: 0x00007fff9c3ec5ad libdyld.dylib`start + 1
(lldb)
```
 Hi @amitdo,
I have the exact same issue with text2image (HEAD revision) running on OSX.

Here's the debug trace when running your last command :

```
$ text2image --text=eng.training.txt --outputbase=eng.TimesNewRomanBold.exp0 --font='Times New Roman, Bold' --fonts_dir=/Library/Fonts --tlog_level=3
query weight = 700   selected weight =700
query_desc: 'Times New Roman, Bold' Selected: 's'
Render string of size 84
Starting page 0
max_width = 3400, max_height = 4600
len = 84  buf_len = 84
Segmentation fault: 11
```

And the corresponding debug trace:

```
$ lldb  /usr/local/bin/text2image
(lldb) target create "/usr/local/bin/text2image"
Current executable set to '/usr/local/bin/text2image' (x86_64).
(lldb) run --text=eng.training.txt --outputbase=eng.TimesNewRomanBold.exp0 --font='Times New Roman, Bold' --fonts_dir=/Library/Fonts --tlog_level=3
Process 43961 launched: '/usr/local/bin/text2image' (x86_64)
query weight = 700   selected weight =700
query_desc: 'Times New Roman, Bold' Selected: 's'
Render string of size 84
Starting page 0
max_width = 3400, max_height = 4600
len = 84  buf_len = 84
Process 43961 stopped
* thread #1: tid = 0x1e1688, 0x0000000100c7e36e libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x0)
    frame #0: 0x0000000100c7e36e libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25
libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25:
-> 0x100c7e36e:  movq   (%rcx), %rdi
   0x100c7e371:  testq  %rdi, %rdi
   0x100c7e374:  je     0x100c7e37f               ; pango_fc_font_get_glyph + 42
   0x100c7e376:  movq   %rax, %rsi
```

Hope it can help
 @amitdo 

I tried the HEAD version (5610738) , and the exit status is 0. 
It looks  good in Times fonts.

Could you check the logs ?

```
$ uname -a
Darwin sakura.local 15.6.0 Darwin Kernel Version 15.6.0: Thu Jun 23 18:25:34 PDT 2016; root:xnu-3248.60.10~1/RELEASE_X86_64 x86_64

$ brew install tesseract --HEAD --with-training-tools
<skip>
$ tesseract --version
tesseract 3.05.00dev
 leptonica-1.73
  libjpeg 8d : libpng 1.6.23 : libtiff 4.0.6 : zlib 1.2.5

$ ls -l /usr/local/bin/text2image
lrwxr-xr-x  1 atuyosi  admin  49  8 11 01:55 /usr/local/bin/text2image -> ../Cellar/tesseract/HEAD-5610738_2/bin/text2image

$ text2image --text=eng.training.txt --outputbase=eng.TimesNewRomanBold.exp0 --font='Times New Roman, Bold' --fonts_dir=/Library/Fonts --tlog_level=3
```

Log file is below:

[issue_195_HEAD-5610738.txt](https://github.com/tesseract-ocr/tesseract/files/411715/issue_195_HEAD-5610738.txt)

The exit status and output files:

```
$ echo $?
0
$ ls
eng.TimesNewRomanBold.exp0.box  eng.training.txt
eng.TimesNewRomanBold.exp0.tif
```

[eng.TimesNewRomanBold.exp0.box.txt](https://github.com/tesseract-ocr/tesseract/files/411720/eng.TimesNewRomanBold.exp0.box.txt)

![eng timesnewromanbold exp0](https://cloud.githubusercontent.com/assets/211086/17563850/251fd3c0-5f6c-11e6-8ec2-fe8a97fe57ca.png)
- rename `.box` file to `.txt`, and convert `.tiff` to `.png`

Thanks.
 Hi guys,
i have a trouble with the text2image  im trying to make the fontlist that was described in the main article about tesseract ocr, i can create the box file and tif file normally for one font but the list i get a problem. im using tesseract OCR 3.03 and the OS is windows 10 and the language is english the command is:
**text2image --text=training_text.txt --outputbase=eng.fontlist.txt --fonts_dir=C:\Windows\Fonts  --find_fonts=true --min_coverage=1.0 --render_per_font=false --fontconfig_tmpdir=C:\Tesseract\Tesseract-OCR** 
and i get a warning
**WARNING: Could not find a font to render image title with!** 
and it gives a fail for every font such as: 
**Font Aldhabi failed with 62 hits = 21.60%**
**also give '%' (U+25) not covered by font** but i don't know what does that mean, anyways 
Any idea how to solve this error?

Thanks in advance 
 You are looking for 100% coverage of training text in the fonts with  --min_coverage=1.0

I use the following on bash on windows (mobaxterm).

```
text2image --find_fonts \
--fonts_dir /mnt/c/Windows/Fonts \
--text ./langdata/eng/eng.training_text \
--min_coverage .95  \
--outputbase ./langdata/eng/eng \
|& grep raw | sed -e 's/ :.*/" \\/g'  | sed -e 's/^/  "/' > ../langdata/eng/fontslist-windows.txt
```
 Thanks a lot for your response, but i didn't get the last part of the command that you are using  **\
|& grep raw | sed -e 's/ :.*/" \\/g'  | sed -e 's/^/  "/' > ../langdata/eng/fontslist-windows.txt** i don't remember that there is such arguments at text2image binary, also i tried in my command to change the coverage from 100 to 95 yet i still have the same problem  keep in mind I'm not familiar with terminal environment :)  The text2image --find_fonts command displays the output on the terminal.

the \ at end of each line is a continuation mark for the command.

| is for piping the output of earlier command to next command.

Grep selects all the lines which have 'raw' in them - to select all lines which have the font name.

first sed command deletes everything following the : sign with a quote mark.

second sed command adds a quote sign to the beginning of each line.

The resulting output is saved in the output file name given after >

So, basically it deletes all extraneous output and creates a text file with each font name with quotes around it, which can be used as part of fontslist or plugged into language-specific.sh. Example of output below:

```
  "WenQuanYi Zen Hei Medium" \
  "WenQuanYi Zen Hei Mono Medium" \
  "WenQuanYi Zen Hei Sharp Medium" \
```

 I notice just now that you say 

```
using tesseract OCR 3.03
```

That could be the problem. text2image segfaults have been fixed in recent code.

 Please use the latest windows binaries eg. from 

https://github.com/UB-Mannheim/tesseract/wiki @ibr123 Please note that if you are using windows command prompt and not bash under windows, the commands such as grep, sed etc may not be available. "text2image --find_fonts command displays the output on the terminal" does that mean no file will be generated? only printing on the terminal? ```
text2image --find_fonts \
 --fonts_dir  /usr/share/fonts/truetype/dejavu/ \
 --text ../langdata/eng/eng.training_text \
 --min_coverage .99  \
 --outputbase ../langdata/eng/eng

Total chars = 6694
DejaVu Sans : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 0 to file ../langdata/eng/eng.DejaVu_Sans.tif
DejaVu Sans Bold : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 1 to file ../langdata/eng/eng.DejaVu_Sans_Bold.tif
DejaVu Sans Mono : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 2 to file ../langdata/eng/eng.DejaVu_Sans_Mono.tif
DejaVu Sans Mono Bold : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 3 to file ../langdata/eng/eng.DejaVu_Sans_Mono_Bold.tif
DejaVu Serif : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 4 to file ../langdata/eng/eng.DejaVu_Serif.tif
DejaVu Serif Bold : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 5 to file ../langdata/eng/eng.DejaVu_Serif_Bold.tif
``` you can redirect output to file by 

```
text2image --find_fonts \
--fonts_dir  /usr/share/fonts/truetype/dejavu/ \
--text ../langdata/eng/eng.training_text \
--min_coverage .99  \
--outputbase ../langdata/eng/eng &>./test.txt
```

test.txt has 

```
Total chars = 6694
DejaVu Sans : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 0 to file ../langdata/eng/eng.DejaVu_Sans.tif
DejaVu Sans Bold : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 1 to file ../langdata/eng/eng.DejaVu_Sans_Bold.tif
DejaVu Sans Mono : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 2 to file ../langdata/eng/eng.DejaVu_Sans_Mono.tif
DejaVu Sans Mono Bold : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 3 to file ../langdata/eng/eng.DejaVu_Sans_Mono_Bold.tif
DejaVu Serif : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 4 to file ../langdata/eng/eng.DejaVu_Serif.tif
DejaVu Serif Bold : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 5 to file ../langdata/eng/eng.DejaVu_Serif_Bold.tif
``` If I use fonts which do not provide adequate coverage for the training text, then the output shows error.

eg. following command which tries to render hindi txt in devanagari script using regular latin script fonts. Since numbers and punctuation are same, it shows coverage of about 18%

```
text2image --find_fonts \
 --fonts_dir  /usr/share/fonts/ \
 --text ../langdata/hin/hin.training_text \
 --min_coverage .99  \
 --outputbase ../langdata/hin/hin

Total chars = 34998
Font DejaVu Serif failed with 6378 hits = 18.22%
Font DejaVu Serif Bold failed with 6378 hits = 18.22%
Font Dingbats failed with 5723 hits = 16.35%
Stripped 2 unrenderable words
FreeMono : 34995 hits = 99.99%, raw = 135 = 99.26%
Font FreeMono Bold failed with 6378 hits = 18.22%
Font FreeMono Bold Italic failed with 6378 hits = 18.22%
Font FreeMono Italic failed with 6378 hits = 18.22%
Stripped 2 unrenderable words
FreeSans : 34995 hits = 99.99%, raw = 135 = 99.26%
Font FreeSans Italic failed with 6527 hits = 18.65%
Stripped 2 unrenderable words
FreeSans Semi-Bold : 34993 hits = 99.99%, raw = 134 = 98.53%
Font FreeSans Semi-Bold Italic failed with 6378 hits = 18.22%
Stripped 2 unrenderable words
FreeSerif : 34995 hits = 99.99%, raw = 135 = 99.26%
Stripped 2 unrenderable words
FreeSerif Bold : 34995 hits = 99.99%, raw = 135 = 99.26%
Font FreeSerif Bold Italic failed with 6380 hits = 18.23%
Font FreeSerif Italic failed with 6527 hits = 18.65%
```

Note above the lines that have **raw** in them. Those are the only fonts that meet the coverage criteria. i appreciate the answers, Thanks @ibr123,

Please use the [forum](https://groups.google.com/d/forum/tesseract-ocr) for asking questions. I'm also having this issue: using latest homebrew version
tesseract: stable 3.05.00 (bottled), HEAD

The training text file I'm using is the first one posted by amitdo; but it happens with any text

Using `$ text2image --list_available_fonts --fonts_dir=/Library/Fonts` does give the font I want `Lucida Grande`

Also ran `fc-cache -frv`

Result:
$ text2image --text=eng.training_text --outputbase=eng.LucidaGrande.exp0 --font='Lucida Grande' --fonts_dir=/Library/Fonts

[1]    72778 segmentation fault  text2image --text=eng.training_text --outputbase=eng.LucidaGrande.exp0

I don't know how to get more error info to you? Please help. @amitdo Could it be that some required commit fixing text2image has not been backported for 3.05?

@Tjorriemorrie Did you build tesseract from source? Please also try with the 4.0 alpha version (latest source from github), if the same error is there?  Ray did some changes in 4.00 that made this problem reappear. These changes were also backported to 3.05.

Here is the source for the regression:
https://github.com/tesseract-ocr/tesseract/commit/709935851061#diff-b37dca9f063c3727f62c496e514177a9L440

Here is a (temporary) solution:
https://github.com/tesseract-ocr/tesseract/issues/736#issuecomment-282685898
  Hello!
I need to run tesseract without leptonica installed on the CentOS system. 
I have leptonica liblept.so available, and I am able to compile tesseract pointing to that directory.

Is it possible to run tesseract without setting up LD_LIBRARY_PATH? 
Maybe there is some way to add some parameter to let tesseract know where leptonica is located in execution phase?

Is it possible to compile tesseract to be independent from shared library liblept.so? Is there any "configure" script parameter available to compile liblept.so into tesseract executable? 
  Here is the excerpt:

‚ÄúAny language that has different punctuation and numbers is going to be disadvantaged by some of the hard-coded algorithms that assume ASCII punctuation and digits. To be fixed in 3.02.‚Äù

from https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#background-and-limitations
 The nice thing about a wiki is that anyone can edit it.  I'm pretty sure none of this is hardcoded any more and, if you agree, you can update the wiki page to match the current reality.
 It depends, not all Wikis have open sign up or give access to anyone for that matter.

I see that in the case of Tesseract on github, I could edit it myself indeed, thanks for the information.

That being said, I haven't investigated the issue, so I don't know what the current status is. In my opinion, it is better to report the issue without fixing it rather than just not fix it. I'll try to look into this later.
  After cmake generation, `TesseractConfig.cmake` not contains `ccutil` include directory. And when i try use `TesseractConfig.cmake` in my build - receive error `platform.h not found`
  See also tesseract-ocr/langdata#23.

Re-do of #188 to re-run and (hopefully) fix tests.
 @amitdo Ah, sorry about that - wasn't sure how to re-trigger it and couldn't turn up anything searching.
  See also tesseract-ocr/langdata#23.
  There seems some communication problem between tesseract 3.04 (package on debian stretch) and hocr2pdf 0.91 (package on debian stretch as well): whereas the tesseract output (up to a stupid xml tag) is a readable html and quite nice to look at ; but hocr2pdf will make VERY messy pdf's.

It seems that I am not alone to experience these problems, see e.g.
http://w3foverflow.com/question/tesseract-and-hocr-on-ubuntu-14-04/

How to make an example? Step 1: scan a messy, double page, Step 2: nice it up using scantailor, then use the output tiffs (in the "out" directory) ; Step 3: these are passed to tesseract with hocr option.   Step 4: finally invoke 

hocr2pdf -n -i image.tif  -o test.pdf  < image.hocr

By virtue of the "-n" option, you only see the (malformed) ocr output which is not overlayed by the right image.

It is unclear to me if this is an tesseract issue or an hocr2pdf issue, of course.

Cheers, Eric
 It's best by far to produce PDF directly from Tesseract. If you really have to go via HOCR for some weird reason, use https://github.com/tmbdev/hocr-tools/blob/master/hocr-pdf instead of hocr2pdf.
  Hi all, 

I am trying to use Tesseract's HOCR output functionality to generate an html file that includes all of the word font attributes - most of important of which is font_id.  From first glance, it looks like I will have to write a custom HOCR script with the result_Iterator to make this work.  

Any tips on getting HOCR output with font ID info without having to rewrite the GetHocrText function?

Thanks !!!
 Your better off asking questions on one of the mailing lists where more people will see it.  I only happened to stumble across this because I was looking at the hOCR code.

The current hOCR renderer already has the capability to output font information, including name.  It just needs to be enabled with a config parameter.

@zdenop please close this
  box.train (and box.train.stderr) exit with no action since commits from 17-Dec-2015 (c2f5e9b8+a20156fc, updates in api/tesseractmain.cpp). No renderer is created for this configuration.
  While Acrobat XI can find text in a PDF, it appears that [poppler](https://en.wikipedia.org/wiki/Pdftotext)'s `pdftotext` program, OS X's Preview app, and the library [PyPDF2](https://github.com/mstamy2/PyPDF2/tree/master/PyPDF2)'s extractText() function all fail to locate text. It seems that Tesseract is encoding text in a way that makes it inaccessible to many PDF viewers.

`pdftotext` produces empty output.
Preview app allows highlighting of text in the appropriate locations, but it cannot be copied to the clipboard or searched.
PyPDF2 extractText also produces an empty string as text.
 #170 might be related, but the files I checked did not have tilted or skewed text.

Input file:
![linnsequencer](https://cloud.githubusercontent.com/assets/1825843/12100857/6fba9e66-b2e6-11e5-8df1-d928e75a1b44.jpg)

Output:
[linn.pdf](https://github.com/tesseract-ocr/tesseract/files/77727/linn.pdf)

tesseract version
`
tesseract 3.04.00
 leptonica-1.72
  libjpeg 8d : libpng 1.6.19 : libtiff 4.0.6 : zlib 1.2.5
`
 Chrome's PDF reader works for me.

I have poppler 0.39.0 installed (homebrew/OS X/El Capitan).

I believe I found the reason. It appears that the readers that struggle with it do not support Tesseract's usage of hexadecimal code points rather than literal characters in the output stream.

The PostScript content stream for this page as generated by Tesseract for the first word, "The" appears as follows:

``` Postscript
 Tz [ <0054><0068><0065> ] TJ  
```

where <0054> = U+0054 = T, <0068> = U+0068 = h, etc. I have run into other situations where this hexadecimal notation causes parsing difficulties for some PDF readers.

Acrobat generates the equivalent segment with ASCII literals.

``` Postscript
[...omitted...] Tm
(The )Tj
```

Longer excerpts for comparison:

Tesseract

``` Postscript
BT    
3 Tr 1 0 0 1 211.68 744 Tm /f-0-0 21 Tf 117.334 Tz [ <0054><0068><0065> ] TJ  
```

Acrobat

``` Postscript
BT
0.196 0.184 0.188 rg
/T1_0 1 Tf
-0.035 Tc 3 Tr 23.4905 0 0 23.7001 211.43 744.24 Tm
(The )Tj
ET
```
 Yes. Preview and poppler are still incapable of reading your i182.pdf. I observed no difference.

My comparison didn't address how Acrobat handles Unicode and Unicode literals cannot appear in Postscript so I checked how this is done. When Acrobat encodes a Unicode string it uses UTF-16 big endian code points in hexadecimal, like this:

``` Postscript
... Tm
<4E8B5F97771F5BF9770B89C152A066F4591A5C11>Tj
```

That string encodes 10 characters all below U+7FFF, which are these:
‰∫ãÂæóÁúüÂØπÁúãËßÅÂä†Êõ¥Â§öÂ∞ë

So it appears that Tesseract's method of encoding text strings is nonstandard. I checked the PDF 1.7 reference manual, and couldn't find an example matching Tesseract's output syntax.
 Okay, for some reason pdftotext will not output to stdout but will produce a valid text file for the files we've been working on. My quick guess is that pdftotext suppresses its stdout if high ASCII characters are present, which tesseract finds here (some n-dashes and smart quotes). Both poppler 0.24.5 and 0.34 behave as expected when asked to save to a file, so the text stream is accessible to pdftotext. In short, poppler is working fine for me.

That said, OS X Preview and parsers like PyPDF2 still struggle with how Tesseract encodes text, as far as I can tell. 

I checked that reportlab also encodes text strings in the manner of Acrobat, and Preview has no problems with PDFs produced by Tesseract -> hOCR -> reportlab PDF. This is an example of such a file:

[linn_hocr_unc.pdf](https://github.com/tesseract-ocr/tesseract/files/77885/linn_hocr_unc.pdf)
 Qpdf says it okay, but it doesn't check everything.
On Mon, Jan 4, 2016 at 17:55 Amit Dovev notifications@github.com wrote:

> Try this to output to stdout:
> 
> pdftotext i182.pdf -
> 
> Jeff mentioned qpdf.
> Links:
> http://qpdf.sourceforge.net
> https://github.com/qpdf/qpdf
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/182#issuecomment-168868649
> .
 I might not have time to take a look until Wednesday. Validators of various flavors  include jhove, jhove-pdf-a, pdfbox, ITextRUPS, and http://www.pdf-tools.com/pdf/validate-pdfa-online.aspx.  (Note that Tesseract PDF are not expected to be PDF/A compliant). I did compatibility testing with Apple's Preview at design time, but I don't test against it regularly. Never tried PyPDF2.  If I had to guess right now, I'd suspect it might be the invisible font improvement that was written for better ghostscript compatibility. Unlikely to be the hex encoding.

https://code.google.com/p/tesseract-ocr/issues/detail?id=1434
http://bugs.ghostscript.com/show_bug.cgi?id=695869
 Looking at issue 181, it's looking more and more like Preview is unhappy with the revised glyphless font, possible due to the zero advance width. Will try to borrow a Mac and play with it, hopefully on Wednesday.
 @jbreiden I agree that the glyphless font issue seems more probable.

Aside: I wouldn't trust JHOVE for PDF validation. For JHOVE to approve is better than not approving, but its analysis is rudimentary, and in my experience it produce more false positives and negatives than useful diagnostics.
 I produced this PDF using Tesseract, then borrowed a laptop running Mac OS X version 10.10.5 and was able to both search and copy-paste from Preview (Although the copy-paste highlighting was kind of weird). My testing copy of Tesseract is not completely synchronized with GitHub, so if needed we can investigate that. How does this PDF perform for you on Preview, @jbarlow83 ?

[2.pdf](https://github.com/tesseract-ocr/tesseract/files/79277/2.pdf)

There is also an alternative invisible font here, that contains an advanceWidth. I think it can be swapped in for tessdata/pdf.ttf. It has a side effect of making highlighting look even more bizarre in evince. I don't notice any compatibility differences at all, but mentioning in case someone wants to play with it. Have not checked compatibility with Ghostscript.

https://github.com/behdad/tofudetector/blob/master/tofu.ttf?raw=true

Finally, this was my test image (I was actually using TIFF but GitHub doesn't let me attach that)

![relativity](https://cloud.githubusercontent.com/assets/4961958/12132423/45519c7a-b3d0-11e5-9700-3179d131ae9e.png)
 Doesn't work in Preview OS X 10.11.2 (highlights properly, but no copy-paste or search). I have access to two other OS X machines - will check those later day.

I check with my iPhone too. Both Chrome iOS (PDFium?) via Gmail app and Safari struggle to highlight text (they only allow highlighting a single character) and cannot copy.
 This one uses the alternate font that has an advance width.

[alternate.pdf](https://github.com/tesseract-ocr/tesseract/files/79359/alternate.pdf)
 alternate works on OS X Preview and my iPhone. 

I did notice that spaces are sometimes missing in OS X's copy and paste text, while pdftotext shows the spaces, so perhaps it's not 100% but clearly this was the main issue.

> components of the relative motions of the fixed , stars with respect to the earth on the colour of **thelightreachingusfromthem. Thelattereffect** manifests itself in a slight displacement of the spectral lines of the light transmitted to us from
> 
> a fixed star, as compared with the position of the same spectral lines when they are produced by a terrestrial source of light (Doppler principle). The experimental arguments in favour of the Maxwell-Lorentz theory, which are at the;same time arguments in favour of the theory of **rela- tivity,aretoonumeroustobesetforthhere**. In reality they limit the theoretical possibilities to such an extent, that no other theory than that of Maxwell and Lorentz has been able to hold its ownwhentestedbyexperience.
> 
> But there are two classes of experimental facts hitherto obtained which can be represented in the Maxwell-Lorentz theory only by the introduction of an auxiliary hypothesis, which in itself‚Äîi.e. without making use of the theory of relativity‚Äî appears extraneous.
> 
> Itisknownthatcathoderaysandtheso-called B‚Äîrays emitted by radioactive substances consist of negatively electrified particles (electrons) of verysmallinertiaandlargevelocity. By examin- ing the deflection of these rays under the influence of electric and magnetic fields, we can study the
> 
> law of motion of these particles very exactly. 
 > Output:
> linn.pdf

For me, pdftotext outputs no text, but Evince, which also uses Poppler, correctly selects and extracts text.
 > @behdad, try this:
> 
> ```
> pdftotext linn.pdf -
> ```

Hah.  My bad.  Thanks :)
 I got my hands on an iPad running iOS 9.2 and reproduced the problem. On iOS/Safari I cannot search 2.pdf (Ken Sharp's font) but can search with alternate.pdf (Behdad's font). Took me quite a while to figure out how how to make the search controls work.

So for your immediate problem, go ahead and substitute in Behdad's font into tessdata/pdf.ttf and you should be okay. We won't do that officially without a whole bunch more compatibility testing and reports, including the harder languages (Cherokee, vertical Japanese, Arabic) and additional renderers including Ghostscript and Firefox. Compatibility reports are appreciated.

https://github.com/behdad/tofudetector/blob/master/tofu.ttf?raw=true

Regarding the words running together on the Apple PDF renderer, that's not new. Apple PDF seems to do a worse job than everyone else at deciding word boundaries, and I've seen them screw up plenty of regular born-digital PDF files in the same way. Of course the root cause is the PDF spec itself, which does not explicitly define the concept of a word boundary. So I can't help you, but at least it isn't a regression. It's possible that Apple will get their act together a little better on this some day, but I have no reason to believe that it is on their radar.
 My font has a huge advance width, because it was designed for another purpose.  Someone should create one with an advance width of 1024 instead of my 20480.
 The PDF is keeping the advance width under control for Behdad's font. We're probably seeing something else. It's kind of cute zebra pattern. You get a black underline, and black boxes in all word gaps and in some letter gaps. (Obviously evince is doing a really bad  job, but this is much worse than with Ken Sharp's font, which highlights as a solid  black bar.) A little hard for me to investigate, since my copy of ttx is not cooperating.

P.S. The font advance width should probably be 512 to match what we specify in the PDF. But again, I don't expect that to change anything for evince.

![evince](https://cloud.githubusercontent.com/assets/4961958/12207036/566e60a8-b5f9-11e5-92c2-61ad905889b9.png)
 FWIW, 
    1) I can confirm the problem as stated. Also, I've been using the same tesseract build, and it stopped working due to OS X update (unfortunately, I'm not sure which, possibly 10.11.1)
    2) As suggested above, using tofu.ttf fixed the issue for me (OS X 10.11.3, Finnish OCR), no recompile of tesseract needed
 Partially blocked by https://github.com/behdad/fonttools/issues/497
 Two choices. 
- Add advance width to Ken Sharp's font.
- Reduce advance with in Behdad's font.

This PDF is the former, please test for compatibility.

[sharp.pdf](https://github.com/tesseract-ocr/tesseract/files/112801/simple-1.pdf)

```
diff -u pdf.ttx sharp.ttx
--- pdf.ttx 2016-02-01 10:24:02.875924041 -0800
+++ sharp.ttx   2016-02-01 10:23:38.659586076 -0800
@@ -14,7 +14,7 @@
     <checkSumAdjustment value="0xa737b34c"/>
     <magicNumber value="0x5f0f3cf5"/>
     <flags value="00000100 00000111"/>
-    <unitsPerEm value="256"/>
+    <unitsPerEm value="2048"/>
     <created value="Thu May 15 23:21:18 2014"/>
     <modified value="Thu May 15 23:21:18 2014"/>
     <xMin value="0"/>
@@ -33,7 +33,7 @@
     <ascent value="1"/>
     <descent value="-1"/>
     <lineGap value="0"/>
-    <advanceWidthMax value="0"/>
+    <advanceWidthMax value="1024"/>
     <minLeftSideBearing value="0"/>
     <minRightSideBearing value="0"/>
     <xMaxExtent value="0"/>
@@ -71,7 +71,7 @@
     <!-- The fields 'usFirstCharIndex' and 'usLastCharIndex'
          will be recalculated by the compiler -->
     <version value="3"/>
-    <xAvgCharWidth value="0"/>
+    <xAvgCharWidth value="1024"/>
     <usWeightClass value="400"/>
     <usWidthClass value="5"/>
     <fsType value="00000000 00000000"/>
@@ -122,7 +122,7 @@

   <hmtx>
     <mtx name=".notdef" width="0" lsb="0"/>
-    <mtx name=".null" width="0" lsb="0"/>
+    <mtx name=".null" width="1024" lsb="0"/>
   </hmtx>

   <cmap>
```
 Nope, the PDF doen't seem to work for me (Mac OS X 10.11.3). The copied text is just equal number of spaces.
 This PDF is the latter, please test for compatibility. (Despite the change to advance width, we still get horrible looking highlighting on evince.)

[behdad.pdf](https://github.com/tesseract-ocr/tesseract/files/112823/simple-1.pdf)

```
--- tofu.ttx    2016-02-01 10:17:15.038213397 -0800
+++ behdad.ttx  2016-02-01 10:43:29.839794297 -0800
@@ -33,7 +33,7 @@
     <ascent value="2048"/>
     <descent value="0"/>
     <lineGap value="0"/>
-    <advanceWidthMax value="20480"/>
+    <advanceWidthMax value="1024"/>
     <minLeftSideBearing value="0"/>
     <minRightSideBearing value="0"/>
     <xMaxExtent value="0"/>
@@ -69,7 +69,7 @@

   <OS_2>
     <version value="3"/>
-    <xAvgCharWidth value="790"/>
+    <xAvgCharWidth value="1024"/>
     <usWeightClass value="400"/>
     <usWidthClass value="5"/>
     <fsType value="00000000 00000000"/>
@@ -120,7 +120,7 @@

   <hmtx>
     <mtx name=".notdef" width="2048" lsb="0"/>
-    <mtx name="glyph00001" width="20480" lsb="0"/>
+    <mtx name="glyph00001" width="1024" lsb="0"/>
   </hmtx>

   <loca>
```
 behdad.pdf works better. The letters are now reproduced correctly. There's still something funny with how selection works. Selecting from left to right doesn't correctly select all the letters. Right-to-left selects the three last characters one by one and then all four of the rest at once. Might be unrelated issue, though.
 This is another attempt at the behdad font, with the contour data removed. It fixes the visual problem with evince. Please test for compatibility. If successful, we probably have a winner. (Don't worry about the left-to-right vs. right-to-left selection oddities; that's due to mixing Hebrew and English words in my test document)

[behdad2.pdf](https://github.com/tesseract-ocr/tesseract/files/112840/simple-1.pdf)
 Nope, this does not work any more (selected characters are spaces again).
 Utterly insane. I would really, really like to speak with the relevant software engineer at Apple. Putting this problem aside for a bit.
 Yes, utterly. I ran the tofu.ttf and the old pdf.ttf through Apples font validator. Both produced errors, but tofu.ttf only one, whereas the old pdf.ttf had additional "name table usability" errors. Please post the above font files (or diffs) and I'll run them through the validator as well. Perhaps this will give some insight to the issue.
 Fonts as per request. I do not know if my modification tool (ttx) corrupts anything along the way. So far the experiments suggest that Apple software requires a contour, and a contour cosmetically messes with evince.

pdf.ttf - currently shipping font, by Ken Sharp
sharp.ttf - with advance width added

tofu.ttf - alternate font from behdad
behdad.ttf -  with advance width reduced
behdad2.ttf - with contour removed

[fonts.zip](https://github.com/tesseract-ocr/tesseract/files/112928/fonts.zip)
 Thanks. Here's the verbose error report as given by Apples ftxvalidator (there's not really a version for 10.11, so some of this might be inaccurate). All report fatal errors and most errors are beyond my (admittedly limited) expertise on the subject. I hope they make more sense to you. 

[Uploading ftxvalidator_report.txt‚Ä¶]()
 Can you please edit that report and make it an attachment or something? The giant wall of text makes this bug harder to read.
 > Partially blocked by behdad/fonttools#497

Fixed now.
 For completeness, here is Ken Sharp's font with a contour added in. 

FONT
[sharp2.zip](https://github.com/tesseract-ocr/tesseract/files/119877/sharp2.zip)

PDF
[sharp2.pdf](https://github.com/tesseract-ocr/tesseract/files/119875/simple-1.pdf)

At this point, sharp2.ttf and behdad.ttf are the only fonts compatible with Apple Preview. They both come at the cost highlight aesthetics with evince. I think Preview is incorrect to require a contour for the glyph, and I think evince is incorrect to consider a contour when highlighting an invisible font. I do not have any reason so far to prefer one over the other, and I do not yet have compatibility test results from ghostscript, firefox, Microsoft Edge, etc.
 I have filed a bug with Apple. This is not publicly visible and I do not know what the response will be. Noting it here simply simply for future reference. radr://24533090
 In progress testing compatibility with candidates "sharp2" and "behdad" including getting some assistance with ghostscript. So far no user visible differences between them, and the former is the smaller change. Is there general consensus to work around the Apple compatibility problem, at the expense of Evince highlight aesthetics?
 @jbreiden I agree. OS X Preview is installed on ~10% of all desktop computers. Evince is just one of many PDF viewers for Linux users.
 @jbarlow83 and @jbreiden This bug also affects the Amazon Kindles. As an avid user of Amazon Kindle and Tesseract, I feel crippled now. And don't forget that all those pdfs generated with Tesseract won't work with Kindle either around the world.
 @bekirserifoglu - can you please confirm that both proposed workarounds found in previous comments (sharp2.pdf, behdad.pdf) solve the problem on Kindle?
 @jbreiden I can confirm that both sharp and tofu fonts work great with Kindle Voyage and Preview on Os X. Feel free to mention me if you need anymore testing.
 @bekirserifoglu - Is the failure case on Kindle broken search and broken copy-paste? Or is it even worse than that?
 @jbreiden Kindle just treats the pdf as a non-ocr'ed pdf. It is worse than OS X preview.
 @theraysmith 

Okay, I've decided. We're going to use the sharp2 font.

For various embarassing reasons, I'd appreciate some help. Could someone please download this zip file, extract sharp2.ttf, and use it to replace pdf.ttf in the repository. The resulting file should still be called pdf.ttf. I apologize for not doing this myself and promise to get my act together with respect to GitHub pull requests in the future. 

[sharp2.zip](https://github.com/tesseract-ocr/tesseract/files/127261/sharp2.zip)

https://github.com/tesseract-ocr/tesseract/blob/master/tessdata/pdf.ttf
 Done. PR #220.
 Thank you for fixing this. 
  Hi all,

I am working on the OCR based android application which loads the image from gallery or photo click from phone's camera. All went well using the tess-two lib. However, the accuracy of reading the text from the image is very poor. Quality of photos are good(8 megapixel camera) and whereas, other application on stores read them much better.

Could you please suggest me how can I improve the accuracy.

Thanks,
Vikas Yadav
  POSIX provides portable data types for signed and unsigned integer values
of different size.

This patch maps those POSIX data types to the Tesseract specific types.
In a next step, the Tesseract data types can be eliminated by replacing
them with the POSIX data types.

~~Use also standard definitions for the printf format specifiers.
MS Visual Studio does not support that standard (at least not in older
versions), so local definitions are needed there.~~

~~NULL is standard, so a local definition should not be needed.~~

Signed-off-by: Stefan Weil sw@weilnetz.de
 Updated patch: removed part for format specifiers, don't remove NULL definition (both issues should be done in separate patches).
 Maybe it would be even better to go thru the code and use, for example, `int8_t` instead of `inT8`...
 @LinusU, yes, that would be the next step as soon as this pull request was accepted.
 :+1: 
 Ping? Are there any more thoughts on my proposal?
 @theraysmith, ping. Do you support the idea of replacing Tesseract data types by POSIX data types (so I can prepare a follow-up pull request)?

Many other free software projects with similar compiler / host conditions have shown that using POSIX data types works. Especially for library interfaces, but also for the rest of the code, it would be good to get rid of project specific data types which don't provide any additional value compared with the standard.
 Ping? I suggest to apply this patch now, wait one more month and then replace all Tesseract integer types by the POSIX types.
 @theraysmith, @zdenop, do you have any comments to my last proposal? Can we proceed like that?
 Ping?
 I still think it would be a good idea to replace all proprietary data types by the POSIX ones. Is it really necessary to wait for @theraysmith (who is obviously very busy)? Lots of other free (and also commercial) software projects work pretty good with the  POSIX data types, using similar environments as Tesseract (Linux and other Unixes, Windows with Cygwin / MinGW-w64 / MS and other compilers).

So can we do the first step and apply this PR which is waiting for more than 7 months now?
 Another month passed. I'd still like to see Tesseract switching to POSIX data types.
 @zdenop said re: next release in https://github.com/tesseract-ocr/tesseract/issues/165#issuecomment-244039370

> I hear something like end of September 2016, but you never know ;-) It will big update (probably we will drop support of compilers nor support c++11)...

Will dropping support for compilers effect Tesseract switching to POSIX data types?
 > Will dropping support for compilers effect Tesseract switching to POSIX data types?

I don't think that POSIX data types are affected by the compiler decision. They exist for many years now, so any supported old or new compiler will work with POSIX data types.
 @theraysmith, may I kindly ask you to give your consent? Woohoo! üéâ 

Now if we could only replace all occurences of `inT8` with `int8_t`, `uinT8` with `uint8_t` and so forth üôå  Yes, replacing those Tesseract data types by the POSIX data types will be the next step.

@zdenop, that means changes for nearly all source files which will give conflicts with pending pull requests. Should I nevertheless send one large PR which does the replacement, or would it be better to do it in smaller steps (starting for example with all files in `lstm`)? Are there more major changes pending after the integration of LSTM? >  I already put a few experimental uses of nullptr in 4.00 to see if anyone squeals.

@theraysmith, training/stringrenderer.cpp already uses `nullptr` for more than two years now. AFAIK nobody complained, so that seems to work. Replacing `NULL` by `nullptr` would be good, but also touches many files, so this could be done in the same action as the switch to POSIX data types.

Do you care for comments after modified code? Replacing data types or NULL is easy, but the replacements are a little bit longer, and moving the comments to the right column means much hand work without code formatter.  When I run "tesseract -c hocr_font_info=T hocr"  on attached file the segmentation fault is received. Output file is empty.
But when I run "tesseract hocr" on the same file without "-c hocr font_info=T", the recognition runs as expected, without any errors.
![1050103_world-markets-at-a-glancepp](https://cloud.githubusercontent.com/assets/8905596/11893647/bf069384-a58b-11e5-8283-7e1fc75600f9.jpeg)
 I was using stock ubuntu 15.10 version. Build from repo and solved. Thank you!
 Oh, I mean 15.10, you're right.  
  Hello.

My goal is simple, I need to extract the identification number from id photos.
I run tesseract and it

![20151211_105843](https://cloud.githubusercontent.com/assets/6429534/11748020/f8484ef8-a004-11e5-9fdf-bc658e13390e.png)

 recognizes only the last surname but I need to get the number (the photo is attached).

Could you please help me?

Thank you very much
  The wiki page states "An installer is available for Windows from our download page." The statement is incorrect since there in no Windows installer available from the said page.
 See #101 which handles the same issue. Maybe you want to try the installer from https://github.com/UB-Mannheim/tesseract/wiki.
 Yes, a clear Wiki message like "no Windows artifacts for current versions of Tesseract will be provided in the project" would clarify the situation. 
  The characters in the attached image are recognized by Tesseract, but placed in a wrong order when generating a PDF file (which prevents searching in the PDF):

```
$ tesseract pdf-test.jpg pdf-test pdf
$ pdftotext pdf-test.pdf -
ra
me
ka
ot
ar
fr
In
en
ch
is
om
on
tr
as
r
ne
ei
g
un
ob
pr
Bau und Er
```

The original text scan is not exactly horizontal (-0.5¬∞). If this is fixed before doing OCR, Tesseract creates a PDF with the correct text.

![pdf-test](https://cloud.githubusercontent.com/assets/6734573/11728560/df7dfa46-9f8a-11e5-949c-6ff549c62f1d.jpg)
 I suspect the problem is in pdftotext. To find out, open the PDF in another viewer such as Chrome or Adobe Reader and see what you get during search and copy-paste.
 Confirmed. Poppler (used by pdftotext) has a very hard time with titled text. If you want Tesseract to be more aggressive at producing flat text lines for tilted images, modify ClipBaseline(). But a better approach is to to use a different text extractor, for example one based on PDFium.

https://github.com/tesseract-ocr/tesseract/blob/master/api/pdfrenderer.cpp#L275
 And finally, if you want to post-process Tesseract produced PDF to flatten out tilted textlines, that's also fairly easy. Just ask if you need details.
 `evince` (my standard PDF viewer on Linux) has the same problem and is not able to search such PDFs. The PDF viewer of `iceweasel` / `Firefox` gets the words right, so it is possible to search 'Infrarotkamera', but not the lines, so searching for word combinations does not work.

I don't want to post-process a PDF produced by Tesseract: the TXT file is perfect, so no need for me to extract text from the PDF.

I want to produce a PDF which I can give to others and which they can use with their normal PDF viewer.

Why is the text in the PDF file split into 2 character sequences? In the HOCR output, words remain words.
 Maybe Firefox also uses parts of the Poppler code. So there are a number of PDF viewers which are less robust in getting correct text lines from a Tesseract PDF. Wikipedia shows that the list of these viewers is quit impressive. This increases my wish to understand and fix what goes wrong in Tesseract's PDF generation process.
 I just tested with Chromium (Debian's variant of Chrome). It gets the text better, but not good: "astronomischen Infrarotkamera" is not found because it is split in separate lines. 
 ![tilt](https://cloud.githubusercontent.com/assets/4961958/11765657/b19b4bf6-a115-11e5-97d3-d8ec63256afc.png)

There's nothing invalid with the PDF files produced; tilted symbolic text lines are legitimate in PDF. They are the accurate representation of OCR results. The words are inside there just fine, along with some geometry describing the angle of the baseline. That said, this does blow the mind of some PDF text extractors who assume that it is impossible for a line of text to have any deviation of y-position between characters. (As you might imagine, this gets particularly fun with vertical Japanese text.)

You have exactly three choices if you want to better compatibility these viewers. One is to deskew the image before calling OCR. Second is modifying the section of code I pointed to earlier in Tesseract, to eliminate tilt in the symbolic text lines. Third is to remove the tilt in the invisible symbolic text lines, after the PDF is produced. All three of these approaches are relatively easy for a programmer and I'm happy to provide guidance.

There are major problems of forcing heavily titled text lines to be flat, a big one being
word highlightling ends up in the wrong place visually. So I would be reluctant to do that by default.
 There must be some other aspect of the original scan, because Tesseract generates a PDF which works perfectly with all viewers and with pdftotext from this generated image with the same tilted text:
![generated-image](https://cloud.githubusercontent.com/assets/6734573/11766292/348dd4d2-a181-11e5-80a5-b12946a7ca44.jpg)
 Ok. Let me explain what I have understood. Obviously it is not possible to describe a rotated text line in PDF, so you have either to pretend that the line is horizontal (that's what ABBYY does with the original image and Tesseract does with the generated image), or you have to approximate the rotation by splitting the text line into smaller parts with different y values (which is causing trouble with most or even all free PDF viewers, at least those that are based on Poppler, Mozilla or PDFium).

I noticed a 2nd difference between ABBYY and Tesseract PDF: with Evince, selected text from the Tesseract PDF is shown as a simple blue rectangle, while in the ABBYY PDF it also shows the characters with some built-in font. But that's a different story. 
 @stweil: You are misunderstanding. It is possible to describe a rotated text line in PDF. Tesseract does exactly this for any text line whose tilt is large enough. The tilted screenshot in Hebrew above is Tesseract output, displayed in Adobe Reader. You can even see the tilted text lines being highlighted for copy-paste in all their tilted glory. I point everyone again at the critical piece of code that explains the situation. It effectively says, 'Does the vertical displacement between the beginning and end of the baseline exceed 2 pts? (2 pts = 1 / 36 inch) If so, pretend the line is horizontal. Otherwise, faithfully record it as tilted.

https://github.com/tesseract-ocr/tesseract/blob/master/api/pdfrenderer.cpp#L275

P.S. While there is a prayer that Poppler will evolve, my best guess is it will instead be replaced with PDFium some time over the next 10 years. PDFium is by no means perfect, but it is much stronger than Poppler.
 I am going to close this issue soon, as working as intended. If people think the 
threshold should be increased, that's a reasonable thing to discuss. Right now if
a text line has 2pts or less vertical displacement, we draw it totally flat. Maybe
that number should be 3pts.
 I have similar problem while extracting data from pdf, it splits into one or two characters per line.  I tried using TESS4J which gets the text much better. So trying to find if there is any options in tesseract(java) i could use.

Thanks  Hi there,
I have created my own Arabic Language traindata, but the problem is that when used it gives the recognized text reversely (opposite direction), noting that the Arabic and Hebrew languages are written and read from Right to left handside (RTL).
People keep implying to use Cube for training Arabic, but I think no one really knows how to use Cube for training, and yes I have read the tesseract extra Cube documentation, and it seems that they purposely don't want anyone to use Cube.
How can I make a tesseract traineddata that recognize RTL languages as Arabic correctly?
Waiting for your reply
 Thank you for reply
I have just used the "wordlist2dawg -r 1" that you suggested and it's has solved my "reversed words" problem.
But now I have a new problem, the recognized text are combined together, meaning the words have no spacing between them. Tesseract seems to recognize all words as only 1 word.
I need help, waiting for reply 
 The problem has been solved! Thanks to the user (amitdo) The solution was:
To use "wordlist2dawg.exe -r 1" to create the "freaquent_words_list" + "words_list"
To use "ara.config" and removing this line from it "tessedit_ocr_engine_mode 1"

This solved my 2 problems of Arabic Language reversed words, and Arabic Language combined word.
Thank you
 @christophered 
did you get any good results by training? my best accuracy is about 40-50% on 300 dpi scanned document
 roozgar, I will conduct some tests and will reply back after couple of days
 @christophered 
i tried to find official Arabic resources to make up a better train file but not lucky 
so
if you need i can help you by providing Arabic words list or some scanned page 
just send me an email: roozgar@gmail.com
 Thank you roozgar, I appreciate you
I am currently conducting some tests on Arabic Tesseract and I am exhausting all resources available to me to make sure finding the best method for arabic recognition.
Don't worry I will conduct some tests and reply back to you ( by GOD)
By-the-way send me the scanned Arabic Document that you've been testing the accuracy on.
waiting for your reply
 @christophered 
sure
please tell me your email address 
 christopher.edward@outlook.com
 I have tested tesseract 3.02+3.04+3.05dev all have failed in arabic ocr.
Some-how I got the feeling that Arabic Language was purposely neglected and rejected.
 @christophered do you have any plan to work more on this subject?!
the official train data for arabic is working really good on 'times' font
so i think its possible to have a good accuracy other fonts too!
 @amitdo Oops! i found this

https://code.google.com/archive/p/tesseract-ocr-extradocs/wikis/Cube.wiki

its really undocumented!!
but how they build current Arabic file!!
 @amitdo who are they? i there any way to find who build each trained file?
 @christophered 
hey christopher, can you please tell me how you created your own .traineddata file for arabic or send me a link that contains a tutorial that i can use to follow.
I have been trying to implemented Tresseract ara.traineddata file but for some reason, the app that i have made using android studio gets stuck
 Hi @areebakamil  I have replyed by email also here is the Tutorial that you requested.
https://www.youtube.com/watch?v=vohgRChtRck

also here is one method to improve the recognition, just for testing
https://www.youtube.com/watch?v=tLJvHWhX_JA

Please remember this is for the Arabic Language, the recognition rate is low to moderate.
Training tesseract for English Language gains +90%, but not for Arabic sadly.

in jtessboxeditor:
Arabic use ara
Urdu use urd
English use eng
 @christophered 
How do you take into account the different forms - isolated, initial, medial and final forms of the same letter, during training?

[https://tsl620atnaz.wikispaces.com/file/view/arabic.gif/130745645/arabic.gif](https://tsl620atnaz.wikispaces.com/file/view/arabic.gif/130745645/arabic.gif)
 @Shreeshrii 
one of the methods that I use in training:
example:
Isolated: **(ŸÉ)**
Initial: (ŸÉ) then press "Shift j or ÿ™" , **so the result will be ( ŸÉŸÄ)**
Medial: "Shift j or ÿ™" , then press (ŸÉ), then "Shift j or ÿ™" , **result is ( ŸÄŸÉŸÄ )**
Final: "Shift j or ÿ™" , then press (ŸÉ) , **result is (ŸÄŸÉ)** Hi , 
can you please provide me any version of tesseract-ocr which supports "Arabic " Language ,
I am tried with tesseract-ocr3.02 version ,
It is not supportng "Arabic " Language,
if any upgade  or downgrade versions supports "Arabic " language 
Please Let me know 

1) If any supported version is there "send me " tesseract-ocr " software and all supported configuration files as well
2) or else if download is available send me  "dowload link " to "saimuralikrishna005@gmail.com "
3) In case if required please  provide to my business mail id : "saikrishna.yalakala@wissen.com "
send me mail "saimuralikrishna005@gmail.com"  @amitdo should this work for hebrew as well? Do I need to create training data myself (i.e.  "freaquent_words_list" + "words_list" etc)?


10x Hi Uri !

There is a tessdata package for Hebrew.
https://github.com/tesseract-ocr/tesseract/wiki/Data-Files

Try to use it before you start training Hebrew.

Also, read this page:
https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality

>should this work for hebrew as well?

By 'this' you mean

1) 'Tessseract' ?
Yes. Tessseract supports Hebrew.
The provided tessdata does not supports Hebrew diacritics (nikud).

2)
>From https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#dictionary-data-optional
>For right-to-left languages (RTL) use option "-r 1".

Yes, it should be used for Hebrew too.

If you have further questions please use the [forum](https://groups.google.com/d/forum/tesseract-ocr) (I'm not participating there).

For Hebrew OCR questions / discussions you can also try here:
https://github.com/amitdo/Hebrew-OCR-Discussions @amitdo thank you very much! I will go through you suggestions.
I meant should the solution for Arabic reverse output should apply for Hebrew as well. 
One of the participants mensons reversing the strings int the training data, wasn't sure if this is somethng I need to do...? Hi, 
I am also having problems with tesseract OCR for arabic and i need your help.

Can you please send me a trained data file for arabic language for tesseract 3.0.2?
My email is adinetoiu@yahoo.com.

Thank you in advance,
Adrian
 @adinetoiu I suggest that you skip using Tesseract 3.x for Arabic, instead use Tesseract 4.
a binary is also available at [http://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-4.00.00dev.exe](http://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-4.00.00dev.exe)

 Thank you very much!


      From: chris <notifications@github.com>
 To: tesseract-ocr/tesseract <tesseract@noreply.github.com> 
Cc: adinetoiu <adinetoiu@yahoo.com>; Mention <mention@noreply.github.com>
 Sent: Monday, June 19, 2017 5:14 PM
 Subject: Re: [tesseract-ocr/tesseract] Arabic Language output is reversed (#169)
   
@adinetoiu I suggest that you skip using Tesseract 3.x for Arabic, instead use Tesseract 4.
a binary is also available at http://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-4.00.00dev.exe‚Äî
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or mute the thread.  

    Do you have a sample project or link that uses tesseract 4?

      From: chris <notifications@github.com>
 To: tesseract-ocr/tesseract <tesseract@noreply.github.com> 
Cc: adinetoiu <adinetoiu@yahoo.com>; Mention <mention@noreply.github.com>
 Sent: Monday, June 19, 2017 5:14 PM
 Subject: Re: [tesseract-ocr/tesseract] Arabic Language output is reversed (#169)
   
@adinetoiu I suggest that you skip using Tesseract 3.x for Arabic, instead use Tesseract 4.
a binary is also available at http://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-4.00.00dev.exe‚Äî
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or mute the thread.  

    @adinetoiu I have contacted the developer of jtessboxeditor, he stated that it might take time until we see an automated lstm trainer, until then, you must train manually.
secondly, the steps and examples are available in the Wiki along with some test box files.
Note: please edit your replies and leave only your replies, your adding unrequired information.
`From: chris <notifications@github.com` ......... delete that hello man, please can you send me the ara.traineddata so i can test it, i don't know how to train iOS tesseract 3.x to recognize arabic in a great way?
also is  tesseract 4 made for iOS , i didn't find an example for iPhone or iPad with tesseract 4, and also if there is one how can i update me old tesseract with the new one. thank you very much  Hi 
I am interested your OCR and quite impressive. I planning to use in VS2013 (web & windows applications). I saw the example VS2013 Soultions (Tesseract.ConsoleDemo & Tesseract.WebDemo) and working fine for plain tiff and it is not working PDF, also i want to read the attached pdf OCR? how to do ? where to start? please guide me.

[sample.pdf](https://github.com/tesseract-ocr/tesseract/files/58849/sample.pdf)

I am used VISUAL STUDIO 2013 FRAME WORK 4.5

thanks
Raja
  Signed-off-by: Stefan Weil sw@weilnetz.de
 Obviously VS does not support the POSIX function `dirname` and its header file `libgen.h`. I'll update the patch to use `_splitpath` (or is there a better alternative for Windows code?).
 VS does not know the `F_OK` needed for function `access`, so I need one more iteration which replaces that parameter by 0.
  when i run the **make** command ,but get errors follow 
#### the errors

``` sh
Making all in .
Making all in tessdata
Making all in configs
make[3]: Nothing to be done for `all'.
Making all in tessconfigs
make[3]: Nothing to be done for `all'.
make[3]: Nothing to be done for `all-am'.
Making all in doc
make[2]: Nothing to be done for `all'.
```
 @amitdo  Thanks for replying! but when i run (sudo make install) get the error

``` sh
tesseract  sudo make install
Password:
Making install in ccutil
 ../config/install-sh -c -d '/usr/local/include/tesseract'
 /usr/bin/install -c -m 644 basedir.h errcode.h fileerr.h genericvector.h helpers.h host.h memry.h ndminx.h params.h ocrclass.h platform.h serialis.h strngs.h tesscallback.h unichar.h unicharmap.h unicharset.h '/usr/local/include/tesseract'
Making install in viewer
make[2]: Nothing to be done for `install-data-am'.
Making install in cutil
make[2]: Nothing to be done for `install-data-am'.
Making install in opencl
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG -I../ccutil -I../ccstruct -I../ccmain  -I/usr/local/include -I/usr/local/include/leptonica -I/usr/local/Cellar/cairo/1.14.4/include/cairo -I/usr/local/Cellar/glib/2.46.2/include/glib-2.0 -I/usr/local/Cellar/glib/2.46.2/lib/glib-2.0/include -I/usr/local/opt/gettext/include -I/usr/local/Cellar/pixman/0.32.8/include/pixman-1 -I/usr/local/Cellar/fontconfig/2.11.1/include -I/usr/local/Cellar/freetype/2.6_1/include/freetype2 -I/usr/local/Cellar/libpng/1.6.19/include/libpng16  -g -O2 -std=c++11 -MT openclwrapper.lo -MD -MP -MF .deps/openclwrapper.Tpo -c -o openclwrapper.lo openclwrapper.cpp
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I../ccutil -I../ccstruct -I../ccmain -I/usr/local/include -I/usr/local/include/leptonica -I/usr/local/Cellar/cairo/1.14.4/include/cairo -I/usr/local/Cellar/glib/2.46.2/include/glib-2.0 -I/usr/local/Cellar/glib/2.46.2/lib/glib-2.0/include -I/usr/local/opt/gettext/include -I/usr/local/Cellar/pixman/0.32.8/include/pixman-1 -I/usr/local/Cellar/fontconfig/2.11.1/include -I/usr/local/Cellar/freetype/2.6_1/include/freetype2 -I/usr/local/Cellar/libpng/1.6.19/include/libpng16 -g -O2 -std=c++11 -MT openclwrapper.lo -MD -MP -MF .deps/openclwrapper.Tpo -c openclwrapper.cpp  -fno-common -DPIC -o .libs/openclwrapper.o
openclwrapper.cpp:16:10: fatal error: 'thresholder.h' file not found
#include "thresholder.h"
         ^
1 error generated.
make[1]: *** [openclwrapper.lo] Error 1
make: *** [install-recursive] Error 1
```
 @amitdo last, i install it with brew.thanks any way
  The man page for the unicharambigs file format only includes documentation on the v1 format, not the v2 format (and is missing a description of the first line which is used for version identification).

https://github.com/tesseract-ocr/tesseract/blob/master/doc/unicharambigs.5.asc
 https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#the-unicharambigs-file

has info about both formats
 I think Ray had updated the documentation (couple years back??). From what
I understand from it unicharambigs file could be either in v1 format or v2
format.
- sent from my phone. excuse the brevity.

On 01-Sep-2016 12:38 AM, "zdenop" notifications@github.com wrote:

Which file use unicharambigs file v2?

 Thanks for checking langdata from 3.04.

Ray is the best person to answer whether v2 has been used/tested for any
languages.

Also, there was supposed to be a new release as per tutorial at DAS2016. Do
you know when that will be and what is included in it?
- sent from my phone. excuse the brevity.

 @zdenop Any update regarding 4.0 release? Thanks!
  Signed-off-by: Stefan Weil sw@weilnetz.de
 @amitdo: that was intentional, so more pull requests can follow.

No, I was just joking. I'm sure that there are more typos, but as I am not a native speaker,
I'm also sure that I won't find them all. :-)
 Ah, on a 2nd view I now see the typo.
  If https://github.com/loqu8/tesseract-vs2015 is placed parallel to the tesseract repo, you can use the vs2015 sln to compile tesseract in Visual Studio with giflib, libpng, libjpeg, libtiff, libwebp and zlib. Note that the solution will look for includes and lib in ../../../tesseract-vs2015/release rather than ../../../ like the VS2010 sln.
 -1. It's better to improve cmake build system rather than each solution per VS version.
  It has been mentioned before that tesseract struggles with small fonts. I'm seeing this with standard sized Chinese in Chrome. If the image is magnified 2x (with no increase in information, just scale up the png), the recognition works great. Is there a way to do font size detection and just auto-scale up? Perhaps this is an English vs Chinese issue internally, so that when recognizing Chinese fonts, the image has to be increased in size before processing. I am not too familiar with tesseract internals, but could someone advise on (1) automatic font size detection, and (2) where to scale things up if it is for Chinese? 
 Here's an actual sample:

(1) 100% font size screen cap from Chrome (Google News)
![orig](https://cloud.githubusercontent.com/assets/157766/11524501/21c2487e-9880-11e5-8caf-b1203b04adf2.png)

Â§úÂèâ ÈèñÂ∑¥Â∏ÉÈü¶Ëø∏Ë°åÂõΩ
„Äà„ÄàËÆ©‰∏≠Âª∫ÂèãÊ∏≤ÁªΩÊîæÂá∫
‰∏çÂπ≥FLÁöÑÂèëÂ±ïÂí∏Â∞±y
""Â∑¥

(2) 1.5x
![1 5x](https://cloud.githubusercontent.com/assets/157766/11524541/58a5d3f6-9880-11e5-93d9-ccd9e6fc722d.png)

Âú®ÂØπÈÄûÂ∑¥Â∏ÉÈü¶Ëø∏Ë°åÂõΩ
<<i‰∏ä‰∏≠Ê¥•ÂèãË∞äÁªΩÊîæÂá∫
‰∏çÂπ≥Âá°ÁöÑÂèëÂ±ïÊàêÂ∞±'

‰π†ËøëÂπ≥ËÆøÁäÄÂ∑¥

(3) 2x  - much much better (though still misses some chars...)
![2x](https://cloud.githubusercontent.com/assets/157766/11524549/68f085d0-9880-11e5-9df1-2b030a26f7eb.png)

Âú®ÂØπÈÄµÂ∑¥Â∏ÉÈü¶ËøõË°åÂõΩ
<<ËÆ©‰∏≠Ê¥•ÂèãË∞äÁªΩÊîæÂá∫
‰∏çÂπ≥Âá°ÁöÑÂèëÂ±ïÊàêÊà¥Ôºå
ÈÄûËØÑ: ‰π†ËøëÂπ≥ËÆøÊ¥•Â∑¥
 Maybe it is possible to train with smaller fonts?
 10 pt screen resolution works perfectly for English. Is there a way to create a training set for lower resolution?
  Hi,
I use tesseract (Tesseract 3.02 on Windows 7) to process sets of scanned invoices issued by the same company (very similar to each other).
I've noticed that **_some of them are recognized properly and some not_**.
The **original paper documents are of very good quality** and so are the TIFF files (at least to me) - so I thought there should be no problem for tesseract to recognize them properly, but...

I have played a bit with the scanning parameters and produced different images of the same paper document that originally caused problems. 

Now I have two TIF files of the same paper invoice:
1. one that gives incorrect results (ex_bad.tif)
2. one that gives correct results (ex_good.tif)

and the **ex_diff.tif** showing which part did not get recognized properly.
I attach also the hOCR files produced for both TIFF files and tesseract configuration.
All the above mentioned files are however packed in one docx file :smiley: 

[Incosistency.docx](https://github.com/tesseract-ocr/tesseract/files/48291/Incosistency.docx)

Don't know if it is the same issue but looking at the line 26 in ex_bad.html one can find empty strings (I know it's been reported already but do not know if it was fixed):

``` html
     <span class='ocr_line' id='line_5' title="bbox 176 379 2119 464"><span class='ocrx_word' id='word_13' title="bbox 176 403 269 439"></span> <span class='ocrx_word' id='word_14' title="bbox 286 404 546 448"></span> <span class='ocrx_word' id='word_15' title="bbox 562 404 648 439"></span> <span class='ocrx_word' id='word_16' title="bbox 1357 379 1759 464"></span> <span class='ocrx_word' id='word_17' title="bbox 1773 379 2119 458"></span> 
     </span>
```

**I have also noticed that removing the picture from the top left corner of the first page of the invoice helps recognizing text properly.**

Is this a bug or simply 'a user education error'?
:smiley:

Thanks in advance for any kind of help and/or guidance here
Wojtek
 I have tried at the time of postinig the original issue but I was not allowed to upload zip file....
Hope this time will work...
[Issues.zip](https://github.com/tesseract-ocr/tesseract/files/76707/Issues.zip)
 I havent used tesseract in two years or so, but I recall as part of preprocessing, we had to first remove all images and do some denoising. That greatly improved things. 
  Commit 99110df75781c6907c84a3d23695a6900b933a97 improved the help text
in several aspects, but also introduced new inconsistencies which this
patch tries to fix.
- Align columns (this needed replacing tabs by spaces).
- Start explaining text with uppercase.
- Replace "the stdout" by "stdout.
- Small changes in help text for page segmentation modes.
- Split options in OCR options and single options
  (partially revert commit 99110df75781c6907c84a3d23695a6900b933a97).

In addition, whitespace characters at end of lines were removed.

Signed-off-by: Stefan Weil sw@weilnetz.de
 > Commit 99110df... introduced new inconsistencies which this
> patch tries to fix.
> - Start explaining text with uppercase.
> - Replace "the stdout" by "stdout.

It didn't introduce these inconsistencies. They were there before.
 @amitdo, I'm sorry, my commit text was not precise. Some of the issues which my patch tries to address existed before your patch. Should I update the patch with a modified commit message?

There remain more issues to be discussed, for example whether stdout instead of stderr would be better for the help text. You also raised the question about more entries for page segmentation mode.
 Hi Stefan,

> Should I update the patch with a modified commit message?

Yes please.

> whether stdout instead of stderr would be better for the help text.

I've noticed that too. I don't know why it's stderr right now.

> You also raised the question about more entries for page segmentation mode.

We need to publish them, IMHO.

> Split options in OCR options and single options (partially revert commit 99110df).

'list-langs' can be followed by 'tessdata-dir'.
'print-parameters' can be followed by -c option(s) which will change the output.
So why call them 'single options'?

I'm not really sure what is the right usage for 'print-parameters'.

Testing:

```
$tesseract --print-parameters | grep pageseg_mode
tessedit_pageseg_mode   6

$ tesseract --print-parameters -psm 1 | grep pageseg_mode
tessedit_pageseg_mode   6

$ tesseract --print-parameters -c tessedit_pageseg_mode=1 | grep pageseg_mode
tessedit_pageseg_mode   1

$ tesseract --print-parameters pdf | grep pageseg_mode
tessedit_pageseg_mode   6

$ tesseract nosuchfile stdout --print-parameters pdf | grep pageseg_mode
tessedit_pageseg_mode   1
```
 @amitdo, I think it is reasonable to split the options in two groups: one group for those options which are used in production to make OCR, one group for options which show information like help texts, version or supported parameters. The old help text called the 2nd ones 'single options', that's why my patch reverted to that title. Maybe there exists a better naming.
 > --print-parameters is option that list all tesseract parameters with its default values. This is useful if you would like to change tesseract behavior.

@zdenop, I knew that, of course.

What I meant was: Should other options followed by 'print-parameters' change the output of the command?

With my commit, the CL help message includes:

> Usage:
>   ...
>   tesseract --print-parameters [options...] [configfile...]

The current behaviour of the command line only partly match the above usage pattern. Only the '-c var=value' option changes the output.

I think this

> $ tesseract --print-parameters pdf | grep pageseg_mode

should produce

> tessedit_pageseg_mode 1

Just like:

> $ tesseract --print-parameters -c tessedit_pageseg_mode=1 | grep pageseg_mode
> tessedit_pageseg_mode   1

Strangly, this works right now

> tesseract nosuchfile stdout --print-parameters pdf | grep pageseg_mode
> tessedit_pageseg_mode   1
 > in case of 'single options': it was not expected (tested) their usage in combination with other options.

So, maybe the usage part of the help message should be changed accordingly?

>  tesseract --print-parameters
 @stweil, feel free to change it as you like, no objection.
 @stweil,

> Should I update the patch with a modified commit message?

On second thought - don't bother!
  I am trying to read serial number, bios version, dimm capacity and cpu type from a BIOS screen shot but cannot improve the results. I attached a zip file with the images.

These information are not words or sentences, and looks like tesseract is trying to give sense or forcing the info to all letters or to all numbers (if preceding a number force to a number). 

Below share my results to see if you know what settings or image pre processing I need to use to improve the results. 

I am using Tesseract 3.03 and ImageMagick 6.8.8-10 on a Fedora 21 OS.

screen shot:
![screen](https://cloud.githubusercontent.com/assets/4931834/11312205/05da2e7a-8f92-11e5-8d74-e6043fcf9d7f.jpg)

bios.jpg:
![bios](https://cloud.githubusercontent.com/assets/4931834/11312193/f78dd010-8f91-11e5-8c8a-5d36c1c1cee8.jpg)

bios-resize300.jpg:
![bios-resize300](https://cloud.githubusercontent.com/assets/4931834/11312222/151035c4-8f92-11e5-863d-aa187d55c585.jpg)

cpu.jpg:
![cpu](https://cloud.githubusercontent.com/assets/4931834/11312197/fc9e87de-8f91-11e5-978e-46c2bfe96e2e.jpg)

cpu-resize300.jpg:
![cpu-resize300](https://cloud.githubusercontent.com/assets/4931834/11312225/151f787c-8f92-11e5-9749-fdd02d924bf7.jpg)

cpu-threshold40.jpg:
![cpu-threshold40](https://cloud.githubusercontent.com/assets/4931834/11312223/15115f4e-8f92-11e5-88ce-a3abbc48d62d.jpg)

dimm.jpg:
![dimm](https://cloud.githubusercontent.com/assets/4931834/11312199/fee89c1e-8f91-11e5-98d4-200677f63a6c.jpg)

dimm-resize300.jpg:
![dimm-resize300](https://cloud.githubusercontent.com/assets/4931834/11312224/151e5d2a-8f92-11e5-9efd-b77363014f0d.jpg)

stn.jpg:
![stn](https://cloud.githubusercontent.com/assets/4931834/11312201/0171e1ca-8f92-11e5-9225-aa867039f7ae.jpg)

stn-resize300.jpg:
![stn-resize300](https://cloud.githubusercontent.com/assets/4931834/11312226/15203e10-8f92-11e5-8288-5da388909b78.jpg)

Thanks.

bios.jpg

command: 
tesseract bios.jpg -psm 8 stdout tessdata

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist A0123456789

expected:
A08

result:
A05

comments:
BAD RESULT

---

bios.jpg

command:
convert bios.jpg -resize 300% bios-resize300.jpg
tesseract bios-resize300.jpg -psm 8 stdout tessdata

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist A0123456789

expected:
A08

result:
908

comments:
Better results resizing 300% the original image, but still wrong. Made a lot of changes on size and adding threshold and still getting a 9 instead of A.

---

dimm.jpg

command:
tesseract dimm.jpg -psm 8 stdout tessdata

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist 0123456789MB

expected:
4096MB

result:
4036MB

comments:
BAD RESULTS

---

dimm.jpg

commands:
convert dimm.jpg -resize 300% dimm-resize300.jpg
tesseract dimm-resize300.jpg -psm 8 stdout tessdata

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist 0123456789MB

expected:
4096MB

result:
4096MB

comments:
GOOD RESULTS

---

stn.jpg

commands:
tesseract stn.jpg -psm 8 stdout tessdata 

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist BCDFGHJKLMNPQRSTVWXYZ0123456789

expected:
CDTL082

result:
CDTLGBZ

comments:
BAD RESULTS, appears that tesseract force all letters or all numbers.

---

stn.jpg

commands:
convert stn.jpg -resize 300% stn-resize300.jpg
tesseract stn-resize300.jpg -psm 8 stdout tessdata 

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist BCDFGHJKLMNPQRSTVWXYZ0123456789

expected:
CDTL082

result:
CDTLGBZ

comments:
BAD RESULTS, appears that tesseract force to all letters or to all numbers.

---

cpu.jpg

commands:
tesseract cpu.jpg -psm 7 stdout tessdata

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist BCDFGHJKLMNPQRSTVWXYZ0123456789@.

expected:
CPU G3260 @ 3.30GHz

result:
M BPH 63260 6 3.30912

comments:
BAD RESULTS

---

cpu.jpg

commands:
convert cpu.jpg -resize 300% cpu-resize300.jpg
tesseract cpu-resize300.jpg -psm 7 stdout tessdata 

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist BCDFGHJKLMNPQRSTVWXYZ0123456789@.

expected:
CPU G3260 @ 3.30GHz

result:
W CPLJ 83260 @ 3.30GHZ

comments:
Better results, but still wrong.

---

cpu.jpg

commands:
convert cpu.jpg -resize 300% cpu-resize300.jpg
convert cpu-resize300.jpg -threshold 40% cpu-threshold40.jpg
tesseract cpu-threshold40.jpg -psm 7 stdout tessdata

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist BCDFGHJKLMNPQRSTVWXYZ0123456789@.

expected:
CPU G3260 @ 3.30GHz

result:
F0 CPH 83260 @ 3.306HZ

comments:
Adding threshold still wrong, and looks like is better without threshold.
  The new pdf option to directly create a PDF with embedded text is awesome. Unfortunately, I haven't been able to figure out yet how to specify the page size (e.g. A4, letter, ...). Is that possible?
 Sorry, no. If the input image is A4 then the output PDF is A4. The design goal of Tesseract's PDF module is to not change anything about the image. If you want to modify page size, either change the input image or post process the output PDF. 
 This issue should be closed. (Working as intended)
 @jbreiden, how tesseract determines page size of the input image? The page size depends on DPI which tesseract has no information about. For example A5 (5.83 x 8.27 inch) with 300 dpi has resolution 1748 x 2480 pixels.
The problem is that when the input image to tesseract has 1748 x 2480 pixels, it outputs pdf file with page size 24.97 √ó 35.43 inch, not 5.83 x 8.27 inch.
Can you please reopen this issue or should I create a new issue?
  This is the failing test: (all locales, packages seem correctly installed).
For info, parsing english works fine.

```
% tesseract test.png test -lbul
Tesseract Open Source OCR Engine v3.04.00 with Leptonica

% cat test.txt
Ila mnpmm "mm npanHM Mama m m: m: m :3 mm mm. Ms M:

% locale -a | grep bg
bg_BG.utf8

% pacman -Qs tesseract-data-bul
local/tesseract-data-bul 3.04.00-1 (tesseract-data)
```

Also tried:
- `LANG=bg_BG.UTF-8 tesseract test.png test -lbul`
- a different bul traindata: https://code.google.com/p/tesseract-ocr/downloads/detail?name=bul.traineddata.gz
 test.png:

![test](https://cloud.githubusercontent.com/assets/52182/11091324/3871125e-8871-11e5-8f9d-0472f36b68b2.png)
 Try this:

> tesseract test.png test -l bul
 Ha, that's funny, I actually tried it like this the very first time but I had an error and thought that that caused it!

Works much better like this:
`tesseract test.png test -l bul`:
`–î–∞ –∏–∑–≤—ä—Ä—à–≤–∞ –≤—Å—è–∫–∞–∫–≤–∏ –ø—Ä–∞–≤–Ω–∏ ‚Äû—â–µ–Ω–∏—è –ø—Ç –Ω–∞: –∏–º: –∏ –∑–∞ –º–∞—è —Å–º:-–¥–∫–∞. –ø—è ‚Äû=`

Still not 100% accurate but I guess that's up to me/options to fix now?
 Suggestion: using `-lbul` should fail with an error
 The font in this image is quite small. You should try to rescale the image (x2).
Also try the option -psm 7
https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality

In general, the right place to ask questions is here:
https://groups.google.com/forum/?hl=en#!forum/tesseract-ocr
 I found out exactly what were the encountered issues. Here is a sum up:
- First I ran `tesseract test.png -l bul` which fails because it sees an option (`-l`) instead of `outputbase|stdout`; but it doesn't complain about a wrong argument so I thought it was because of the space between `-l` and `bul`
- Then I tried `tesseract test.png -lbul` which doesn't give errors because it wrongly thinks that the output file is `-lbul` and it uses the default `eng` data. Indeed `-lbul.txt` gets created
- And eventually: `tesseract test.png test -lbul` which creates `test.txt` and uses `eng` as default and simply discards `-lbul` which is nonsense to it
  The command tesseract seems to miss the decimal separator character if there is more than 7 digits in the decimal number : 
In the image below, tesseract detects 34056789 = not OK ! 
![bug_number1c](https://cloud.githubusercontent.com/assets/14107462/10996075/0e90e966-8482-11e5-9e8c-0f1289f250d0.png)
In the image below, tesseract detects 440.5678 => OK
![bug_number1c2](https://cloud.githubusercontent.com/assets/14107462/10996076/126ef0fa-8482-11e5-956a-ea61e87f5b99.png)
 With the latest snapshot in the git repo i get:
340.56789
 Ok I have recompiled with the tesseract-master.
And now, i got good result with 340.56789. Thanks...

But the problem is still there when i use more digits:
Example below is ok
![bug_number3a](https://cloud.githubusercontent.com/assets/14107462/11002130/3c4dc440-84ab-11e5-99fd-876e688f72bf.png)
Example below is returning 1234056789
![bug_number3b](https://cloud.githubusercontent.com/assets/14107462/11002155/58cd30b0-84ab-11e5-988c-7eab13438bee.png)
  This fixes clang compiler warnings like this one:

wordrec/gradechop.cpp:52:3: warning:
 'register' storage class specifier is deprecated [-Wdeprecated-register]

Signed-off-by: Stefan Weil sw@weilnetz.de
 @zdenop: Any good modern compiler should be able to assign CPU registers to local variables, and at least for gcc and clang I know that they do a very good job here. I assume that 'register' for local variables was deprecated because it no longer makes sense today. That's the reason why I suggest to use these modifications.

For function parameters, this is different. Therefore they are still supported.
 Extract from gcc documentation:

"Some developers use Local Register Variables in an attempt to improve gcc's allocation of registers, especially in large functions. In this case the register name is essentially a hint to the register allocator. While in some instances this can generate better code, improvements are subject to the whims of the allocator/optimizers. Since there are no guarantees that your improvements won't be lost, this usage of Local Register Variables is discouraged."
  Trying to build unicharset from my examples this is what is the content of unicharset
Doesn't look correct? Using tesseract 3.05 (and Ubuntu Linux 14.04)

head unicharset 
102
NULL 0 NULL 0
Joined 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # Joined [4a 6f 69 6e 65 64 ]
|Broken|0|1 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # Broken
A 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # A [41 ]
V 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # V [56 ]
C 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # C [43 ]
D 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # D [44 ]
E 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # E [45 ]
F 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # F [46 ]
 Running:
shapeclustering -F font_properties -U unicharset font.exp0.tr 

Reading font.exp0.tr ...
Building master shape table
Computing shape distances...
Stopped with 0 merged, min dist 999.000000
Computing shape distances...
Stopped with 0 merged, min dist 999.000000
Computing shape distances...
Stopped with 0 merged, min dist 999.000000
Computing shape distances... 0
Stopped with 0 merged, min dist 999.000000
Computing shape distances... 0
Stopped with 0 merged, min dist 999.000000
....
Stopped with 0 merged, min dist 999.000000
Computing shape distances... 0
Stopped withBad properties for index 3, char A: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 4, char B: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 5, char C: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 6, char D: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 7, char E: 0,255 0,255 0,0 0,0 0,0
...
Bad properties for index 101, char √É¬∂: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 102, char √É¬•: 0,255 0,255 0,0 0,0 0,0
 0 merged, min dist 999.000000
Computing shape distances... 0
Stopped with 0 merged, min dist 999.000000
Computing shape distances... 0
Stopped with 0
....
Computing shape distances... 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93
Distance = 0.013333: Stopped with 1 merged, min dist 0.025316
Master shape_table:Number of shapes = 93 max unichars = 2 number with multiple unichars = 1
 And ...
mftraining -F font_properties -U unicharset -O font.unicharset font.exp0.tr 

Read shape table shapetable of 93 shapes
Reading font.exp0.tr ...
Bad properties for index 3, char A: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 4, char B: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 5, char C: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 6, char D: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 7, char E: 0,255 0,255 0,0 0,0 0,0
....
Bad properties for index 102, char √É¬•: 0,255 0,255 0,0 0,0 0,0
Warning: no protos/configs for sh0090 in CreateIntTemplates()
Warning: no protos/configs for sh0091 in CreateIntTemplates()
Warning: no protos/configs for sh0092 in CreateIntTemplates()
Done!
 I'm having a similar issue, running tesseract 3.04, and on Ubuntu 15.10. My unicharset after having trained on a long text file and using unicharset_extractor has the above mentioned "Joined" and "Broken" flags, followed by all bogus rows. In addition, whenever I then use another training tool, like shapeclustering, I get the bad properties warnings for just about every possible character present. 

Is there any idea as to what could be causing this? I'm using a custom font, but with english words. 
 Same problem here. Running tesseract 3.04 on fedora 23
 I have the same problem for Farsi language (It is right to left). Using 3.04 on Ubuntu 15

```
78
NULL 0 NULL 0
Joined 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # Joined [4a 6f 69 6e 65 64 ]
|Broken|0|1 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #  # Broken
Ÿà 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # Ÿà [648 ]
Ÿá 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # Ÿá [647 ]
⁄© 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ⁄© [6a9 ]
ŸÜ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ŸÜ [646 ]
€å 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # €å [6cc ]
ÿß 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ÿß [627 ]
ÿÆ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ÿÆ [62e ]
ÿ≥ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ÿ≥ [633 ]
ÿπ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ÿπ [639 ]
ÿ∂ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ÿ∂ [636 ]
```

Output:

```
Reading fas.BMitra.exp0.tr ...
Bad properties for index 3, char Ÿà: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 4, char Ÿá: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 5, char ⁄©: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 6, char ŸÜ: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 7, char €å: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 8, char ÿß: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 9, char ÿÆ: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 10, char ÿ≥: 0,255 0,255 0,0 0,0 0,0
```
 same on 3.04
tried manual method, no difference
 @jmokoistinen I have tried every step in that file, and keep getting a buggy unicharset_extractor output. I'm also using english letters, and my file has 14000 words that cover all possible letter placement in the system I'm trying to train on. What should I try next?
 I suggest you to use the `set_unicharset_properties` script used to set some properties to your generated unicharset file or get unicharset file listed in [tesseract train repo](https://github.com/tesseract-ocr/langdata)
both worked for me
 Did anyone manage to resolve this issue? I'm trying to train a new font and I'm getting the bad properties error even when if use the eng,unicharset that came with the trained data. The error is for the tilda (~) character only.
Running on OS X.
 @wxlie see the post above or you can use the script listed in my repo
 Same issue running tesseract 3.04.01 on Cygwin Win10.
 Are you trainiing using tesstrain.sh?

See Phase UP : Generate (U)nicharset and (P)roperties file. in tesstrain_utils.sh

```
phase_UP_generate_unicharset() {
tlog "\n=== Phase UP: Generating unicharset and unichar properties files ==="

local box_files=$(ls ${TRAINING_DIR}/*.box)
run_command unicharset_extractor -D "${TRAINING_DIR}/" ${box_files}
local outfile=${TRAINING_DIR}/unicharset
UNICHARSET_FILE="${TRAINING_DIR}/${LANG_CODE}.unicharset"
check_file_readable ${outfile}
mv ${outfile} ${UNICHARSET_FILE}

XHEIGHTS_FILE="${TRAINING_DIR}/${LANG_CODE}.xheights"
check_file_readable ${UNICHARSET_FILE}
run_command set_unicharset_properties \
    -U ${UNICHARSET_FILE} -O ${UNICHARSET_FILE} -X ${XHEIGHTS_FILE} \
    --script_dir=${LANGDATA_ROOT}
check_file_readable ${XHEIGHTS_FILE}
}
```
 @mustafashujaie - Which langdata are you using?

https://github.com/tesseract-ocr/langdata/tree/master/fas
or
https://github.com/tesseract-ocr/langdata/tree/master/per
  @Wikinaut Most of those warnings also occur in my builds and are less interesting (like -Wsign-compare which can be ignored IMHO), but there are also some warnings which need further investigations (-Warray-bounds).
  Hello, I'm working on adding symbol level bounding box information in hOCR output, in order to be able to find the position of individual symbols inside words. Is this something that you would like to integrate? I've only had a cursory glance on the hOCR reference, but it doesn't seem to be violate anything. Output would look like:

```
    <span class="ocrx_word" dir="ltr" id="word_1_26" lang="eng" title=
    "bbox 102 194 177 224; x_wconf 90" xmlns=
    "http://www.w3.org/1999/xhtml"><strong><span class="ocrx_symbol" id=
    "symbol_1_26_81" title=
    "bbox 102 200 117 224; x_wconf 92">q</span><span class="ocrx_symbol" id=
    "symbol_1_26_82" title=
    "bbox 121 200 135 218; x_wconf 90">u</span><span class="ocrx_symbol" id=
    "symbol_1_26_83" title=
    "bbox 140 194 143 218; x_wconf 97">i</span><span class="ocrx_symbol" id=
    "symbol_1_26_84" title=
    "bbox 146 200 161 218; x_wconf 92">c</span><span class="ocrx_symbol" id=
    "symbol_1_26_85" title=
    "bbox 163 194 177 218; x_wconf 96">k</span></strong></span>
```
 Speaking only for myself. It's soooooo expensive. That's why I don't bother in PDF output.
 If this were to be contemplated, it should be controlled by a config variable with defaults to false, similar to `hocr_font_info`.  I'd be curious about the use case though. If hOCR is being used as a format to connect two programs, it seems like a very bulky & low fidelity channel. Wouldn't just calling the Tess result iterator yourself give you better control at less cost?
  I have created java web controller with tesseract.
If I use windows libraries - no errors, but in linux sometimes I get a fatal error

> Problematic frame:
> [libtesseract.so+0x22a730]  tesseract::HistogramRect(unsigned char const_, int, int, int, int, int, int, int_)+0x70
> 
> Stack: [0x00007f2d040d2000,0x00007f2d041d3000],  sp=0x00007f2d041cdf20,  free space=1007k
> Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)
> C  [libtesseract.so+0x22a730]  tesseract::HistogramRect(unsigned char const_, int, int, int, int, int, int, int_)+0x70
> 
> Java frames: (J=compiled Java code, j=interpreted, Vv=VM code)
> j  net.sourceforge.tess4j.TessAPI1.TessBaseAPIGetUTF8Text(Lnet/sourceforge/tess4j/ITessAPI$TessBaseAPI;)Lcom/sun/jna/Pointer;+0
> j  net.sourceforge.tess4j.Tesseract1.getOCRText(Ljava/lang/String;I)Ljava/lang/String;+43
> j  net.sourceforge.tess4j.Tesseract1.doOCR(Ljava/util/List;Ljava/lang/String;Ljava/awt/Rectangle;)Ljava/lang/String;+69
> j  net.sourceforge.tess4j.Tesseract1.doOCR(Ljava/util/List;Ljava/awt/Rectangle;)Ljava/lang/String;+4
> j  net.sourceforge.tess4j.Tesseract1.doOCR(Ljava/awt/image/BufferedImage;Ljava/awt/Rectangle;)Ljava/lang/String;+6
> j  net.sourceforge.tess4j.Tesseract1.doOCR(Ljava/awt/image/BufferedImage;)Ljava/lang/String;+3
 I'm not sure that an issue with java wrapper.
But ok. I'll take a look at java wrapper and how it works with pointers in HistogramRect.
Thanks
  I had the same problem, and discovered the cause by looking in the `config.log` file. I see a lot of people having this problem, so might be a good idea to add a check.
 I'm pretty sure it was this:

```
./configure:17287: g++ -o conftest -I/Usr/local/include/leptonica -L/usr/local/lib conftest.cpp -llept >&5
./configure: line 2040: g++ command not found
```
 Perhaps also update the wiki, installations instructions and the FAQ for this error.
   @zdenop, FYI

Travis failed in linux build only. It had problems downloading cmake.
The code does compile in my machine, which is ubuntu 14.04 64bit.
I also tested the code. Everything seems fine!

Any questions?
 If I'm right the build will run again when you close this PR and reopen it.
 Thanks @ArjanSchouten.
It failed twice to download cmake: yesterday (~18 hours ago) and today (~2 hours ago).
So it might fail again...
 @zdenop
I reorganised this PR. It has only one commit now.
 The Travis problem should be fixed now (see #143), so please start a new try. 
 @stweil, @zdenop
Done.
 @zdenop Please, commit or comment.
 @amitdo, I'm afraid that your patch needs to be rebased on latest git master. One of my patches fixed a bug in main and was committed. This fix is still missing in your code, so there will be a merge conflict.
 @zdenop, I've updated the code. Is it OK for you now?
 @amitdo, I'afraid that the new function SetVariablesFromCLArgs did revert the bug fix #154.
 @stweil, sorry. fixed.
 If you run "tesseract" or "tesseract --help" you get this.

```
Usage:
  tesseract --help | --help-psm | --version
  tesseract --list-langs [--tessdata-dir PATH]
  tesseract --print-parameters [options...] [configfile...]
  tesseract imagename|stdin outputbase|stdout [options...] [configfile...]


Options:
  -h, --help    Show this help message.
  --help-psm    Show Page Segmentation Modes.
  -v,  --version    Show version information.

  --list-langs  list available languages for tesseract engine.

  --tessdata-dir PATH   specify the location of tessdata path.
  --print-parameters    print tesseract parameters to the stdout.
  --user-words PATH specify the location of user words file.
  --user-patterns PATH  specify the location of user patterns file.
  -l LANG[+LANG]    specify language(s) used for OCR.
  -c VAR=VALUE  set value for config variables.
            Multiple -c arguments are allowed.
  -psm NUM  specify page segmentation mode.
  NOTE: The options above must occur before any configfile.

Page Segmentation Modes:
  0    Orientation and script detection (OSD) only.
  1    Automatic page segmentation with OSD.
  2    Automatic page segmentation, but no OSD, or OCR
  3    Fully automatic page segmentation, but no OSD. (Default)
  4    Assume a single column of text of variable sizes.
  5    Assume a single uniform block of vertically aligned text.
  6    Assume a single uniform block of text.
  7    Treat the image as a single text line.
  8    Treat the image as a single word.
  9    Treat the image as a single word in a circle.
 10    Treat the image as a single character.
```

Original:

```
Usage:
  tesseract imagename|stdin outputbase|stdout [options...] [configfile...]

OCR options:
  --tessdata-dir /path  specify the location of tessdata path
  --user-words /path/to/file    specify the location of user words file
  --user-patterns /path/to/file specify the location of user patterns file
  -l lang[+lang]    specify language(s) used for OCR
  -c configvar=value    set value for control parameter.
            Multiple -c arguments are allowed.
  -psm pagesegmode  specify page segmentation mode.
These options must occur before any configfile.

pagesegmode values are:
  0 = Orientation and script detection (OSD) only.
  1 = Automatic page segmentation with OSD.
  2 = Automatic page segmentation, but no OSD, or OCR
  3 = Fully automatic page segmentation, but no OSD. (Default)
  4 = Assume a single column of text of variable sizes.
  5 = Assume a single uniform block of vertically aligned text.
  6 = Assume a single uniform block of text.
  7 = Treat the image as a single text line.
  8 = Treat the image as a single word.
  9 = Treat the image as a single word in a circle.
  10 = Treat the image as a single character.

Single options:
  -v --version: version info
  --list-langs: list available languages for tesseract engine. Can be used with --tessdata-dir.
  --print-parameters: print tesseract parameters to the stdout.
```

So, what do you mean by 'whole help'?

'as default (as today)' - does it mean you want the help message to look exactly like as it looks now?  

Please clarify.
  Works for single page and multi-page.
 test:

```
convert -rotate 270 eurotext.tif eurotext270.tif

echo "/path/to/eurotext.tif
/path/to/eurotext270.tif" > mp-eurotext

tesseract eurotext.tif eurotext -l osd -psm 0

tesseract eurotext270.tif eurotext270 -l osd -psm 0

cat eurotext270.tif | tesseract stdin stdout -l osd -psm 0

tesseract mp-eurotext mp-eurotext -l osd -psm 0
```
 :+1:
  Hi folks,

Having trouble getting a working OpenCL build. First run in a new working directory gets upset that there's no opencl_profile_devices.dat:

axfelix@shoebox:~/Desktop$ tesseract test.png out pdf
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performing profiling.

[DS] Device: "GeForce GTX TITAN X" (OpenCL) evaluation...
[OD] write binary[kernel-GeForce_GTX_TITAN_X.bin] succesfully
[DS] Device: "GeForce GTX TITAN X" (OpenCL) evaluated
[DS]          composeRGBPixel: 0.022978 (w=1.2)
[DS]            HistogramRect: 0.012700 (w=2.4)
[DS]       ThresholdRectToPix: 0.010093 (w=4.5)
[DS]        getLineMasksMorph: 0.004402 (w=5.0)
[DS]                    Score: 0.125484

[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
[DS]          composeRGBPixel: 0.018301 (w=1.2)
[DS]            HistogramRect: 0.060059 (w=2.4)
[DS]       ThresholdRectToPix: 0.016802 (w=4.5)
[DS]        getLineMasksMorph: 0.110437 (w=5.0)
[DS]                    Score: 0.793896
[DS] Scores written to file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:GeForce GTX TITAN X score is 0.125484
[DS] Device[2] 0:(null) score is 0.793896
[DS] Selected Device[1]: "GeForce GTX TITAN X" (OpenCL)
OpenCL error code is -38 at   when clSetKernelArg imageBuffer .
OpenCL error code is -38 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -38 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -38 at   when clSetKernelArg histogramBuffer .
OpenCL error code is -52 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -52 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -38 at   when clSetKernelArg imageBuffer .
OpenCL error code is -38 at   when clSetKernelArg thresholdsBuffer .
OpenCL error code is -38 at   when clSetKernelArg hiValuesBuffer .
OpenCL error code is -38 at   when clSetKernelArg pixThBuffer .
OpenCL error code is -52 at   when clEnqueueNDRangeKernel kernel_ThresholdRectToPix .
Setting return value to -1
OpenCL error code is -38 at   when clSetKernelArg imageBuffer .
OpenCL error code is -38 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -38 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -38 at   when clSetKernelArg histogramBuffer .
OpenCL error code is -52 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -52 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .

After that, it works (while throwing issues like Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box) but the output is basically junk. Did I screw something up when compiling?
 I'm seeing something very similar. First time I run Tesseract after deleting tesseract_opencl_profile_devices.dat, I get the following:

****************_START**_****************
-bash-4.2$ tesseract ESub.png ESubPng
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performing profiling.

[DS] Device: "Tesla K40c" (OpenCL) evaluation...
OpenCL error code is -44 at   when clCreateKernel .
OpenCL error code is -48 at   when clSetKernelArg .
OpenCL error code is -48 at   when clSetKernelArg .
OpenCL error code is -48 at   when clSetKernelArg .
OpenCL error code is -48 at   when clSetKernelArg .
OpenCL error code is -48 at   when clSetKernelArg .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel .
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectAllChannels .
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg numPixels .
OpenCL error code is -48 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -48 at   when clSetKernelArg histogramBuffer .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -44 at   when clCreateKernel kernel_ThresholdRectToPix .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg height .
OpenCL error code is -48 at   when clSetKernelArg width .
OpenCL error code is -48 at   when clSetKernelArg wpl .
OpenCL error code is -48 at   when clSetKernelArg thresholdsBuffer .
OpenCL error code is -48 at   when clSetKernelArg hiValuesBuffer .
OpenCL error code is -48 at   when clSetKernelArg pixThBuffer .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_ThresholdRectToPix .
[DS] Device: "Tesla K40c" (OpenCL) evaluated
[DS]          composeRGBPixel: 0.022510 (w=1.2)
[DS]            HistogramRect: 0.006130 (w=2.4)
[DS]       ThresholdRectToPix: 0.005528 (w=4.5)
[DS]        getLineMasksMorph: 0.007509 (w=5.0)
[DS]                    Score: 0.104147

[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
[DS]          composeRGBPixel: 0.029208 (w=1.2)
[DS]            HistogramRect: 0.108206 (w=2.4)
[DS]       ThresholdRectToPix: 0.032306 (w=4.5)
[DS]        getLineMasksMorph: 0.200906 (w=5.0)
[DS]                    Score: 1.444651
[DS] Scores written to file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Tesla K40c score is 0.104147
[DS] Device[2] 0:(null) score is 1.444651
[DS] Selected Device[1]: "Tesla K40c" (OpenCL)
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectOneChannel .
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectOneChannelReduction .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg numPixels .
OpenCL error code is -48 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -48 at   when clSetKernelArg histogramBuffer .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -44 at   when clCreateKernel kernel_ThresholdRectToPix_OneChan .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg height .
OpenCL error code is -48 at   when clSetKernelArg width .
OpenCL error code is -48 at   when clSetKernelArg wpl .
OpenCL error code is -48 at   when clSetKernelArg thresholdsBuffer .
OpenCL error code is -48 at   when clSetKernelArg hiValuesBuffer .
OpenCL error code is -48 at   when clSetKernelArg pixThBuffer .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_ThresholdRectToPix .
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectOneChannel .
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectOneChannelReduction .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg numPixels .
OpenCL error code is -48 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -48 at   when clSetKernelArg histogramBuffer .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
-bash-4.2$ 

***************_STOP**_***********************

Running after that I get:

***************_START**_***********************
-bash-4.2$ tesseract ESub.png ESubPng
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
[DS] Profile read from file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Tesla K40c score is 0.104147
[DS] Device[2] 0:(null) score is 1.444651
[DS] Selected Device[1]: "Tesla K40c" (OpenCL)
-bash-4.2$ 

**************_STOP**_***********************

This creates the txt file, but it's just junk, maybe a few random characters. For a long time I was also seeing the 'Error in boxClipToRectangle: box outside rectangle' sort of errors that axfelix was seeing.

If I run it with the CPU device like this:

TESSERACT_OPENCL_DEVICE=2 tesseract ESub.png ESubPng

...it works perfectly. Great OCR output.

I have done everything I can imagine, including rebuilding Tesseract several times, using jpg, png and tif input files and rebuilding Leptonica. The nvidia drivers are the latest and OpenCL is the latest.

Any ideas?
 Still working on the problem. Here's some information that will hopefully make it easier for someone to solve before I spend another day tracking it down. 

I have two test cases using the same source file. Doesn't matter if the source is png or tif, same bad results. Tesseract correctly identifies that I have a Tesla K40c as device 1. The CPU is device 2. The call I'm making is either:
TESSERACT_OPENCL_DEVICE=1 tesseract ESub.png Esub -l enm //GPU
or
TESSERACT_OPENCL_DEVICE=2 tesseract ESub.png Esub -l enm //CPU

In the file baseapi.cpp in function TessBaseAPI::ProcessPage() I put in code to save the image before and after the call to GetThresholdedImage() like so:

```
pixWrite("tessinputBEFORE.tif", pix, IFF_TIFF_G4);
Pix* page_pix = GetThresholdedImage();
pixWrite("tessinputAFTER.tif", page_pix, IFF_TIFF_G4);
```

In the CPU version both before and after images look correct, showing the same text and formatting.

In the GPU OpenCL version 'before' is fine, but the 'after' version is seriously sheared when the source image has non-binary dimensions.  It looks like the pitch is being miscalculated. The source image was 1721 x 1238 pixels. In this case the OCR failed completely of course.

On an educated hunch I resized the the same image to 2048 x 1024. Now the shearing is gone, The characters in the image are somewhat recognizable. There is still a problem, the letters are all munged, almost like letters are being overlaid on top of each other or something. I will send the two bad output images if you tell me where. 
 Here you go...

Original source image 1721 x 1238:

![esub](https://cloud.githubusercontent.com/assets/394707/11664244/9a024432-9dae-11e5-9b87-76ca9b54c18e.png)

Result when source image resized to 2048 x 1024 results:

![tessinputafter](https://cloud.githubusercontent.com/assets/394707/11664207/6fbdcbe2-9dae-11e5-981e-92d50810a4f3.png)
 Sheared OpenCL output with odd-sized source image.

![skewedopenclodddims](https://cloud.githubusercontent.com/assets/394707/11664500/25f7c0ba-9db0-11e5-8269-5b6f83f67c20.png)
 I swear I've seen this particular image corruption before, when I was working on the pdf output module. I wish I could remember what it was.
 Anything else that can be done to help debug? I have a vested interest in getting a working OpenCL build before the end of January...
 I speculate we had a Leptonica bug, fixed it, but the fix never got propagated to the OpenCL-ified mini-fork of Leptonica that sits inside Tesseract. I think the way to go is look inside the thresholding call and keep comparing the CPU vs GPU to help isolate where things go different. It's also helpful to look at all data in the pix struct before/after/cpu/gpu to understand better what went wrong.

``` c
struct Pix
{
    l_uint32             w;           /* width in pixels                   */
    l_uint32             h;           /* height in pixels                  */
    l_uint32             d;           /* depth in bits (bpp)               */
    l_uint32             spp;         /* number of samples per pixel       */
    l_uint32             wpl;         /* 32-bit words/line                 */
    l_uint32             refcount;    /* reference count (1 if no clones)  */
    l_int32              xres;        /* image res (ppi) in x direction    */
                                      /* (use 0 if unknown)                */
    l_int32              yres;        /* image res (ppi) in y direction    */
                                      /* (use 0 if unknown)                */
    l_int32              informat;    /* input file format, IFF_*          */
    l_int32              special;     /* special instructions for I/O, etc */
    char                *text;        /* text string associated with pix   */
    struct PixColormap  *colormap;    /* colormap (may be null)            */
    l_uint32            *data;        /* the image data                    */
};
```

I don't know/remember what this code path is trying to do. Seems odd that
we'd be writing an image to a file unless this was a pure debug path. What happens
if you comment out the thresholding call? (go ahead and comment out lines 1227 to 1232 inclusive)

https://github.com/tesseract-ocr/tesseract/blob/c53add706e7853c8ea9986a87aebb465f29173bd/api/baseapi.cpp#L1230
 Yeah, that sure looks like a debug path. New theory is OpenCL turns on some some debugging, which activates faulty debugging code that messes everything up.
 Separate experiment, swap:

pixWrite("tessinputAFTER.tif", page_pix, IFF_TIFF_G4);

with 

pixWrite("tessinputAFTER.png", page_pix, IFF_PNG);

just to make sure we're not having trouble with writing out your debug image.
I can imagine weird problems if the depth is not 1 bit per pixel and we try
to write out g4 tiff.
 And finally, find the place where the image is first read into Tesseeract and turned into a Pix. See if we already have corruption at that point.
 I can't debug this myself. I still get a segfault on my computer when trying to use OpenCL as per issue #53 . Will be travelling for the rest of the month. Good luck and sorry.
 PR #475 fixes an error with OpenCL which results in these error message:

```
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectAllChannels .
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
```

Maybe it is related to this issue, too.
  i can't build the source with  vs2010,  can't find the file "allheaders.h" .  the version is tesseract-3.04.00
 this repository can't find the file "allheaders.h"
  https://drive.google.com/folderview?id=0B7l10Bj_LprhQnpSRkpGMGV2eE0&usp

There is an installer on the old Google code page from 2012.
 Does this mean that the compiled installer will be added to the Github project, or the  links will be updated/removed to reflect that there is no longer a Windows installer provided?  It is mentioned in the README.MD file, as well as the Wiki pages:

https://github.com/tesseract-ocr/tesseract/wiki
https://github.com/tesseract-ocr/tesseract/wiki/Downloads
  test:

```
tesseract eurotext.tif eurotext -l osd -psm 0
```
 that was quick! :-)
  3~5 sec is too long I think.Can we Improve the performanceÔºü
I use ubuntu15.04 tesseract 3.03
  `tesseract scan.tif filename` This command is giving empty text file. 
But this `tesseract scan.tif filename pdf` is giving correct pdf file. What can be the issue ? 
 try `tesseract scan.tif filename -psm 1`
  See

http://stackoverflow.com/q/33268289/2561126
  I'm spawning `tesseract` subprocesses for a project I'm working on and it's a bit annoying to see its banner on every invocation in the error log.  Redirecting stderr to `/dev/null` isn't an option as that would hide actual errors.

While the sources tell me redirecting stdout to the target file would hide it, I believe it would be better to have something like OpenSSH's `-q`.  Would that be an option?

I'd alternatively support dropping the banner entirely as the essential information is already given in `tesseract --version`.
 Thanks, works here as well.
  I have downloaded the sources and written the samples codes, just change the language 'eng' to 'chi_sim'. The traindata 'chi_sim' has been copied to \tessdata directory same with eng.traindata.

When I complie and start the sample, a error 'read_params_file: parameter not found: allow_blob_division' happens. But it works well with language 'eng'. Does anyone know how to resove it ?

Thanks a lot.
  when i run tesseract with opencl enabled over a multipage tiff it does not uses the gpu at all, even if it says its doeing so. the gpu is an ati 7770 
git commit # is 0d61f0c05a93a4d5aa09a9ec74d7cf7a1e51a9fa , Sep 15 09:32:54 2015

stdout from tesseract : 

Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
[DS] Profile read from file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Capeverde score is 0.157605
[DS] Device[2] 1:Intel(R) Core(TM) i7-2600 CPU @ 3.40GHz score is 0.866140
[DS] Device[3] 0:(null) score is 0.820505
[DS] Selected Device[1]: "Capeverde" (OpenCL)
Page 1
.... etc

as you can see it does start working (Page 1) and eventually the output is correct, ( and even says he is using the gpu  .. "Selected Device[1]: "Capeverde" (OpenCL)" ) but radeontop shows no activity ( tested it with cl-demo from Andreas Kl√∂ckner , gpu can be used in this system ) 
if i use the cpu (run it as a normal user without privileges to access the gpu ) then it takes the same amount of time.

one strange issue is that the first time tesseract is run and benchmarks the available devices (creating  tesseract_opencl_profile_devices.dat ) , it segfault, the  tesseract_opencl_profile_devices.dat does gets done and the next time it runs fine. 
  while trying to autogen, i got the following errors.

<pre>
Makefile.am: error: required file './README' not found
api/Makefile.am:65: warning: source file '$(top_srcdir)/api/tesseractmain.cpp' is in a subdirectory,
api/Makefile.am:65: but option 'subdir-objects' is disabled
automake: warning: possible forward-incompatibility.
automake: At least a source file is in a subdirectory, but the 'subdir-objects'
automake: automake option hasn't been enabled.  For now, the corresponding output
automake: object file(s) will be placed in the top-level directory.  However,
automake: this behaviour will change in future Automake versions: they will
automake: unconditionally cause object files to be placed in the same subdirectory
automake: of the corresponding sources.
automake: You are advised to start using 'subdir-objects' option throughout your
automake: project, to avoid future incompatibilities.
api/Makefile.am: installing 'config/depcomp'
ccutil/Makefile.am:53: warning: source file '../vs2008/port/strtok_r.cpp' is in a subdirectory,
ccutil/Makefile.am:53: but option 'subdir-objects' is disabled

  Something went wrong, bailing out!
</pre>


How can I make it?
Cheers,
 i suspected that I had no tesseract.
Does the autogen have to use tesseract? If so, I will firstly install it.
 oh sorry about my heavy head due to a whole day of work :(

I did run autogen under directory of tesseract-ocr, but got the error message mentioned above.

## FYI

i downloaded the source from google code (of version 3.02.02).
unpack it under mac os 10.10, 
1. cd to tesserac-ocr
2. run autogen 
3. error for libtoolize, error for subdir-objects
4. change ibtoolize to glibtoolize
5. run autogen again
6. error for subdir-objects 

## here below the full log and version of glibtool, aclocal and automake:
- glibtool
  
  <pre>
  glibtool --version
  glibtool (GNU libtool) 2.4.6
  Written by Gordon Matzigkeit, 1996
  Copyright (C) 2014 Free Software Foundation, Inc.
  This is free software; see the source for copying conditions. 
  There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
  </pre>
- aclocal
  
  <pre>
  aclocal --version
  aclocal (GNU automake) 1.15
  Copyright (C) 2014 Free Software Foundation, Inc.
  License GPLv2+: GNU GPL version 2 or later <http://gnu.org/licenses/gpl-2.0.html>
  This is free software: you are free to change and redistribute it.
  There is NO WARRANTY, to the extent permitted by law.
  Written by Tom Tromey <tromey@redhat.com>  Alexandre Duret-Lutz <adl@gnu.org>.
  </pre>
- automake
  
  <pre>
  automake --version
  automake (GNU automake) 1.15
  Copyright (C) 2014 Free Software Foundation, Inc.
  License GPLv2+: GNU GPL version 2 or later <http://gnu.org/licenses/gpl-2.0.html>
  This is free software: you are free to change and redistribute it.
  There is NO WARRANTY, to the extent permitted by law.
  Written by Tom Tromey <tromey@redhat.com> and Alexandre Duret-Lutz <adl@gnu.org>.
  </pre>

## error
- autogen
  <pre>
  ./autogen.sh 
  Running aclocal
  Running libtoolize
  glibtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, 'config'.
  glibtoolize: copying file 'config/ltmain.sh'
  glibtoolize: putting macros in AC_CONFIG_MACRO_DIRS, 'm4'.
  glibtoolize: copying file 'm4/libtool.m4'
  glibtoolize: copying file 'm4/ltoptions.m4'
  glibtoolize: copying file 'm4/ltsugar.m4'
  glibtoolize: copying file 'm4/ltversion.m4'
  glibtoolize: copying file 'm4/lt~obsolete.m4'
  Running autoheader
  Running automake --add-missing --copy
  configure.ac:215: installing 'config/compile'
  configure.ac:225: installing 'config/missing'
  Makefile.am: error: required file './README' not found
  api/Makefile.am:65: warning: source file '$(top_srcdir)/api/tesseractmain.cpp' is in a subdirectory,
  api/Makefile.am:65: but option 'subdir-objects' is disabled
  automake: warning: possible forward-incompatibility.
  automake: At least a source file is in a subdirectory, but the 'subdir-objects'
  automake: automake option hasn't been enabled.  For now, the corresponding output
  automake: object file(s) will be placed in the top-level directory.  However,
  automake: this behaviour will change in future Automake versions: they will
  automake: unconditionally cause object files to be placed in the same subdirectory
  automake: of the corresponding sources.
  automake: You are advised to start using 'subdir-objects' option throughout your
  automake: project, to avoid future incompatibilities.
  api/Makefile.am: installing 'config/depcomp'
  ccutil/Makefile.am:53: warning: source file '../vs2008/port/strtok_r.cpp' is in a subdirectory,
  ccutil/Makefile.am:53: but option 'subdir-objects' is disabled
  
  Something went wrong, bailing out!

</pre>

Hope these will help.
 ok let me do it now/

but i thought the error was dependent of the configs of Makefile, not the project itself.
 new version from github worked now. 
thank you.
  At first test it compiled fine with this code:

```
TessBaseAPI tess;
tess.Init(NULL, "eng", tesseract::OEM_DEFAULT);
Pix* img = pixRead("C:\\Users\\Paul\\Pictures\\phototest.tif");
```

But then, I added this line

   tess.SetImage(img);

 And it won't compile with error:

error LNK2019: unresolved external symbol "public: void __cdecl tesseract::TessBaseAPI::SetImage(struct Pix const *)" (?SetImage@TessBaseAPI@tesseract@@QEAAXPEBUPix@@@Z) referenced in function main

I have VS 2013, Windows 8.1 64 bit both. Compiled both tesseract and leptonica for x64 system, included everything, but still it doesn't want to work correctly.

Hope for your help. Paul.
 Looks like you forgot to link a library. Have you double checked all your depentencies?
 dependencies sorry 
 Hello, peirick.
I believe i did not, as far as i know.
I've included those 3 libs: 
libtesseract304d.lib
liblept171d.lib
tesseractd.lib
 zdenop,
Yes, i've tried. Unfortunatly it still gives the same error.
Tried to disable tesseractd.lib (have no idea what's this).
 Maybe have a look at the repository at https://github.com/peirick/leptonica you will find a build_tesseract.bat. 
  Link to wiki ReadMe points to the same markdown file.
  I have a project similar to recaptcha where I need humans to type words instead of computer ocr. Is there a way for tesseract to split an image into words and output the words as separate image files?
  On Windows I am getting the following error message for a JPG although the file can be opened with the viewer and shows correct:
Corrupt JPEG data: nnnn extraneous bytes before marker 0xnn
Image is attached
![ptdc0020](https://cloud.githubusercontent.com/assets/1007103/9982736/5b09231a-5f9a-11e5-84d2-ed5e2488cd91.JPG)
 Yes, it seems it is producing. Just curious - what is the issue with the JPEG though?
  I would like to suggest to slightly redesign the layout and installation of the training data.

At the present, one can install a single language (or a set of languages) by downloading the prepacked trainingdata as described in https://github.com/tesseract-ocr/tesseract/wiki/Compiling#Language%20Data _or_ by downloading the git repo https://github.com/tesseract-ocr/tessdata .

The process is difficult, in case that you always want to automatically use the latest version of (let's say) eng, deu, fra, spa, ita trainingdata.

Without presenting a concrete idea or a PR, I just wanted to start a discussion whether and how a redesign (which should be compatible to the current way of downloadlng/installing language data) could look like, if it is wanted and possible.

Perhaps a small json or text parameter file could indicate which languages are needed (or are currently installed), and only these files are then updated from git.

Or a method "git submodule" which automatically clones (or pulls) all languages from https://github.com/tesseract-ocr/tessdata .
 I think it is a good idea specially for people like me a normal windows user that is just learning
  Written in the WIKI
"Windows
An installer is available for Windows from our download page."

But as far as I can see there are no Windows installers to download. May be I'm not right, so, please, tell me, where I can get a current Windows installer.
 There is a Windows installer for tesseract version 3.02 here:

https://code.google.com/p/tesseract-ocr/downloads/list
tesseract-ocr-setup-3.02.02.exe

I don't think there is a **official** Windows installer for newer versions.
 Ok, thank you. I took a further look for a newer version and I found:
http://domasofan.spdns.eu/tesseract/
with the newest development version. But the server is delivering the files really slow.
 Thank you for the latest Windows installer files :). 
 The NSIS installer configuration was added and removed twice, the last time with commit b8862b33dfa3bf42c87913911f62da7bc4ed2e45. Is there currently another method to build an installer for Windows? If not, I'd like to add the NSIS configuration files again. I just finished cross building Tesseract for Windows (including an installer) based on latest Git master and using the MinGW-w64 packages on Debian GNU Linux. 
 @amitdo, that's interesting, but it still does not include an installer as far as I see.
@zdenop, maybe those Windows developers who are interested in libraries can also compile Tesseract. But those who just want to do OCR on Windows need an installer. Will cmake provide one?

Regarding leptonica, you can start with https://github.com/stweil/leptonica until there is an official GitHub version.
 [See issue 209](https://github.com/tesseract-ocr/tesseract/issues/209)
  I run into this error under debian7 (and 8)  with Tesseract 3.03 and also with 3.04.

The solution I found to avoid this is to set the locale LC_NUMERIC to C instead of my locale "fr_FR.UTF-8"

Is there a patch or a new version planned to solve this whitout the need to change my locale ?
Thank you
 It happened with custom training
 Hello, 
I found that tesseract had a patch for this problem (https://code.google.com/p/tesseract-ocr/issues/detail?id=910)
Why is this not in the new version of Tesseract 3.04 ?
Will it be in the next version ?
Thanks
 Btw the custom training I use is not mine so I cannot run it again with LC_NUMERIC=C
 Ok my bad.
But I just tried with the eng.traineddata from official google traineddata file and I've got the same error
"Error: Illegal min or max specification!
"Fatal error encountered!" == NULL:Error:Assert failed:in file globaloc.cpp, line 75"
 I'm having a hard time seeing how this is going wrong due to locale with the current code.  The actual error is signaled here: https://github.com/tesseract-ocr/tesseract/blob/master/classify/clusttool.cpp#L89 which happens when it is unhappy with the results that tfscanf gets for the feature parameters. tfscanf is a private, locale-independent version of fscanf, which calls, in turn, the private tvfscanf which implements its own parsing of floats with a hard coded decimal separator of '.'

One thing that definitely could cause it though is a bad/corrupted feature parameter file.

I just tested with the stock tesseract 3.03 on a brand new Debian 8 installation with the locale set to fr_FR.UTF-8 and everything worked perfectly.

If you still can't get this to work, please post the output of the following commands:

```
uname -a
tesseract -v
locale
```
  I'm currently seeing a SIGBUS crash in ComputeGradient on an Android app I'm working on, I can reliably reproduce the crash on a specific phone (Samsung Galaxy S4 Mini, Snapdragon 400), on another device (OnePlus One, Snapdragon 801)

Backtrace (app name removed): 

D/CrashAnrDetector(  656): backtrace:
D/CrashAnrDetector(  656):     #00  pc 000a746c  /data/app-lib/**APPNAME**/libtess.so
D/CrashAnrDetector(  656):     #01  pc 000a8935  /data/app-lib/**APPNAME**/libtess.so (C_OUTLINE::ComputeEdgeOffsets(int, Pix_)+160)
D/CrashAnrDetector(  656):     #02  pc 000b81b1  /data/app-lib/__APPNAME__/libtess.so
D/CrashAnrDetector(  656):     #03  pc 000a3a1d  /data/app-lib/__APPNAME__/libtess.so (BLOBNBOX::ComputeEdgeOffsets(Pix_, Pix_, BLOBNBOX_LIST_)+212)
D/CrashAnrDetector(  656):     #04  pc 000a42b7  /data/app-lib/**APPNAME**/libtess.so (TO_BLOCK::ComputeEdgeOffsets(Pix_, Pix_)+14)
D/CrashAnrDetector(  656):     #05  pc 0011f099  /data/app-lib/**APPNAME**/libtess.so (tesseract::Textord::TextordPage(tesseract::PageSegMode, FCOORD const&, int, int, Pix_, Pix_, Pix_, bool, BLOBNBOX_LIST_, BLOCK_LIST_, TO_BLOCK_LIST_)+72)

I added some debug output to ComputeGradient and it turns out it crashes when y = -2. , after adding a few more lines of debug logging in ComputeEdgeOffsets I see that start.y() is 2 larger than 'height'. If it crashes, it always does so on line 2 of ComputeGradient. SIGBUS would imply an unaligned memory access but as far as I can tell that function only deals with single byte access which shouldn't cause an issue. The -2 y coordinate also seems suspect but I don't know enough about Tesseract and Pix to know if that might be a problem or not.
  In one of our test-cases valgrind complained about a jump-condition based on an un-initialized value:

==9451== Conditional jump or move depends on uninitialised value(s)
==9451==    at 0x35CEEC31F7: tesseract::Tesseract::quality_based_rejection(PAGE_RES_IT&, unsigned char) (in /usr/lib64/libtesseract.so.3.0.3)
==9451==    by 0x35CEEB6370: tesseract::Tesseract::rejection_passes(PAGE_RES_, ETEXT_DESC_, TBOX const_, char const_) (in /usr/lib64/libtesseract.so.3.0.3)
==9451==    by 0x35CEEBB0D0: tesseract::Tesseract::recog_all_words(PAGE_RES_, ETEXT_DESC_, TBOX const_, char const_, int) (in /usr/lib64/libtesseract.so.3.0.3)
==9451==    by 0x35CEEA905A: tesseract::TessBaseAPI::Recognize(ETEXT_DESC*) (in /usr/lib64/libtesseract.so.3.0.3)
==9451==    by 0x35CEEA9B2B: tesseract::TessBaseAPI::GetUTF8Text() (in /usr/lib64/libtesseract.so.3.0.3)
==9451==    by 0x418970: main (ValgrindTest.cpp:382)
==9451== 

The reason is that sometimes word_char_quality() exits early without initializing its output parameters, however the callers expect the output-parameters to be written. Instead of initializing all the parameters for all callers, I chose to set output-parameters at early-exist directly.
 I initialized the values inside the early-exit branch, because they are otherwise overwritten anyway - which means a few unescessary stores. 
In case there are good arguments in initializing the out-values un-conditionally, I of course don't have anything against doing it.
 @egorpugin Why is a rebase needed? I don't see any conflict with the current sources. The build failure doesn't appear to be due to the code, but instead instability in the CI.
 Thanks for checking. Is there anything left for me to do to get this patch in?
  Hello there!

I have done some training and created my own combined language file. When using my custom language I get error code 5000

```
$ tesseract waa.whatevva.exp0.tif out -l waa

Error: Illegal sample size!
signal_termination_handler:Error:Signal_termination_handler called:Code 5000
Abort trap: 6
```

When I ran `combine_tessdata`I got the following output

```
Combining tessdata files
TessdataManager combined tesseract data files.
Offset for type 0 is 140
Offset for type 1 is 141
Offset for type 2 is -1
Offset for type 3 is 2214
Offset for type 4 is 299822
Offset for type 5 is 300066
Offset for type 6 is -1
Offset for type 7 is -1
Offset for type 8 is -1
Offset for type 9 is -1
Offset for type 10 is -1
Offset for type 11 is -1
Offset for type 12 is -1
Offset for type 13 is 300067
Offset for type 14 is -1
Offset for type 15 is -1
Offset for type 16 is -1
```

Anybody having an idea of what I'm doing wrong? 
  I am using the master branch from github (3.05.00dev) and facing some problems when using the stdin option in conjunction with the -psm 0 and -psm 2 options

```
cat <image file> | tesseract stdin stdout -psm 0
```

gives me the error

```
Error in fopenReadStream: file not found
Error in pixRead: image file not found: stdin
Cannot open input file: stdin
```

However, the command 

```
cat <image file> | tesseract stdin stdout -psm 1
```

works as expected.

Do I miss something?

Regards,
Caleb
 Just so you know, if I'm not mistaken, it worked with Tesseract 3.03 and only broke with Tesseract 3.04. It is also very handy to script around Tesseract (avoid using temporary files) (see [Pyocr](https://github.com/jflesch/pyocr) for instance).
 When I started working on PyOCR, it was still Tesseract 2.x. At the time, if I remember correctly, there was only a C++ API and it seemed painfully hard to use (and binding on C++ API from Python is really annoying).
Also I did fork PyOCR from an already-existing python module (python-tesseract if I recall correctly).

Good to know there is a C API now. I'll have a look, see if I can bind on it easily. Thanks for the tip :)
  Hello,

I noticed the new "pdf" option in Tesseract, which creates a PDF file with the image and the background text. That's great ! 

But usually, the image given to Tesseract is not as nice as the starting image (because it is optimized for OCR, not for human visualization). Maybe it would be useful to provide the step before, i.e. the PDF of the generated text without the image, so that the user can paste it as a background text with pdftk for example.
 @olcc link is [OCRmyPDF](https://github.com/fritz-hh/OCRmyPDF/tree/master)
 @olcc, the way to produce PDF has significantly changed in Tesseract 8.04. So I have a plan to change this in future commits. I'll take your idea into consideration. But as I remeber the new implementation does not produce the text anymore. It outputs directly to the file. But even with such effort you are able read the file manually and modify as you wish.
 @jbarlow83: Thanks for pointing to the "OCRmyPDF" wrapper.
@ws233: Tesseract 8.04? I'm quite late, I only have 3.04! ;-) (from Debian) 
@zdenop: Sorry, I didn't understand your message. Maybe my English is not good enough. My process is the following:
1) ORIGINAL.jpg -> OCR.tif  (remove colors, apply threshold, etc.)
2) tesseract OCR.tif result -l eng pdf
If you say that showing OCR.tif in the PDF is the right thing to do, I disagree in general. I agree this is a very nice feature. However, most people want to have ORIGINAL.jpg with the ocr text. 
 @olcc we here fully rely on these "mixed-mode" PDFs as generated by

`tesseract OCR.tif ORIGINAL pdf`

which works with very high quality, depending on the quality what you input to tesseract. I hope, that the present "pdf" option ( -c tessedit_create_pdf=1 ) will really never be dropped from the code.
 @zdenop, is this functionality documented anywhere?

Could you point me to the exact place in the code where it's implemented?
 > ORIGINAL.tif is included in ORIGINAL.pdf WITHOUT any modification

Whenever possible. The design intent is to copy the image bytes without using a 
decompress/compress whenever we can.  Sometimes that is impossible (TIFF
is an enormously flexible graphics format) and sometimes we haven't quite
gotten there. For example, TIFF CCITT Group 4 still goes through a lossless
decompress/compress. Simply because we haven't done the work to optimize
this code path in Tesseract / Leptonica. All relevant Tesseract code is in
ai/pdfrenderer.cc but we try to push the image heavy lifting into Leptonica.

https://en.wikipedia.org/wiki/Tagged_Image_File_Format#TIFF_Compression_Tag
 I'd like to support the original wish. Having something like

tesseract OCR.tif ORIGINAL pdf-overlay

to produce only the text overlay in a pdf file would provide a lot of flexibility.  With this, you could write frontends to tesseract capable of overlaying the invisible text overlay on something different from OCR.tiff (e.g. a full color version of OCR.tif, etc.)
  Is there a way to train tesseract to recognize a limited amount of text from an image. I am making a small app that recognizes a printed list of topics and so far using the tess-two library, tesseract does not fully recognize any of the text in the image. I am quite new to OCR so I'm not sure how to make this work. So far all the training instructions I've seen require a font file which I don't have. All I have are different images of the printed text.

How do I train tesseract to recognize the text from that? Where do I start?
 Hi,
for me it helps often to upscale a image.
in ocrdesktop i resize the image by factor 3 (Bicubic). This brings quite good results.
Cheers
 In case that you use screenshots, please notice, that screenshots usually have 72dpi, which is not sufficient for Tesseract. I admit, that this is not so well known, however, it is mentioned since a long time here https://github.com/tesseract-ocr/tesseract/wiki/FAQ#is-there-a-minimum-text-size-it-wont-read-screen-text

> Is there a Minimum Text Size? (It won't read screen text!)
> 
> There is a minimum text size for reasonable accuracy. You have to consider resolution as well as point size. Accuracy drops off below 10pt x 300dpi, rapidly below 8pt x 300dpi. A quick check is to count the pixels of the x-height of your characters. (X-height is the height of the lower case x.) At 10pt x 300dpi x-heights are typically about 20 pixels, although this can vary dramatically from font to font. Below an x-height of 10 pixels, you have very little chance of accurate results, and below about 8 pixels, most of the text will be "noise removed". 

Here's another useful page:
https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality

I recommend:
- remember never to use JPEG (because this is a lossy compresison format) when saving images with text (use: PNG, or use TIF, or GIF as the last choice)
- resize your screenshots or images to at least 300dpi, or 400dpi, or upscale by 400%:

```
convert -resize 400% ...
```
- when you start form a pdf then read http://bertanguven.com/faster-conversions-from-pdf-to-pngjpeg-imagemagick-vs-ghostscript/

```
density=400
gs -dNOPAUSE -sDEVICE=png16m -sOutputFile=$image -r$density -q $file -c quit
```

[Posting updated with information which came in later]
 ~~@Wikinaut, why do you link to the old wiki at googlecode instead to the new one at github?
https://github.com/tesseract-ocr/tesseract/wiki/FAQ#is-there-a-minimum-text-size-it-wont-read-screen-text
Here is another useful wiki page.
https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality~~

[Wikinaut updated his comment.]
 I updated my posting above accordingly. Thanks
  This is a report from someone who makes Tesseract work on Android.
We can make his life easier by copying the string instead of holding onto 
the pointer.

https://github.com/tesseract-ocr/tesseract/blob/master/api/renderer.cpp#L55

In separate news, I see that  the renderers are not doing proper escaping
of that title before the put it into PDF or HOCR output. Maybe somebody
will worry about that some day.

Here's the relevant part of the report.

> I can pass a title from Java through JNI to Tesseract's BeginDocument() just 
> fine and that title will show up properly in the PDF. But if after calling 
> BeginDocument() I release the array of bytes representing that title using 
> ReleaseStringUTFChars in my
> Java_com_googlecode_tesseract_android_TessBaseAPI_nativeBeginDocument 
> method in JNI [1], then the title will show up in the PDF as garbled text, apparently 
> read from uninitialized memory. I'm guessing this means that Tesseract needs 
> the reference to that char\* to stay around 
> 
> https://gist.github.com/rmtheis/19965abdfca5c2c9eb26
 change written, currently under review
 Change is in Ray's hands and will eventually migrate here. The person in critical need has a copy.
 @jbreiden, we didn't get the patch. 
https://github.com/tesseract-ocr/tesseract/blob/2c837dffc3/api/renderer.cpp#L71

 cc: @theraysmith  Since you originally linked to `renderer.cpp`, I thought that the patch will be in that file.

I'm sorry for the mistake.   I have a working repo and installation of tesseract. When I pull the latest version from git, make and install, the git version information when printed via `tesseract --version` is not updated.

Reporting this as a bug, but not being sure, whether this is the correct term. Please close the issue if you think that my report is wrong, because one may not use the short sequence (pull - make - install).

I simply do not know, whether the following short sequence was ever designed to work.

How to reproduce the bug:

```
git pull
make
sudo make install
```

The following sequence however works, but recompiles everything:

```
make distclean
git pull
./autogen.sh
make
sudo make install
```
 @zdenop I thought that _updating_ (via git pull) does not require the compilation of all items.
Thanks.
  previously ProcessPages return char*, but now it return either true or false.
now text where is the place to find the text detected by ocr

I see there are result renderer but they write to text or pdf file, how to get text in return as char*
  In ccmain/par_control.cpp you can see this code:
# pragma omp parallel for num_threads(10)

for (int b = 0; b < blobs.size(); ++b) {
...
}

configure.ac should have an option to activate OpenMP in tesseract code (maybe with AC_OpenMP?).
 Hi, when I try to compile on a Mac with this commit in (for testing #71), I now get the following error:

```
configure: error: conditional "OPENMP" was never defined.
Usually this means the macro was only invoked conditionally.
```
 Here's a `config.log` for the current `master` branch after `./autogen.sh` && `./configure`: https://gist.github.com/c134a55446c99b9702fe

Same process succeeds if I revert bb19f2c.
 I think this _may_ be related to this problem/answer: http://stackoverflow.com/a/32122781
As I believe the conftest should find `<omp.h>` when given `-fopenmp`. I'm currently letting the gcc reinstall run, and will report back after.

But also the configure process probably shouldn't fail by default if there's no OpenMP support detected/enabled.
 Confirmed that after `brew reinstall gcc --without-multilib`, I can use e.g. `brew install --HEAD --cc=gcc-5 tesseract` and the configure/make will succeed with bb19f2c in. Without `--cc=gcc-5` it fails due to [the lack of OpenMP support in the current Clang/LLVM compiler shipped with OS X](http://clang-omp.github.io/) (i.e. the default Mac "`gcc`").
 @ryanfb, @zdenop
FYI, Clang 3.7 now support OpenMP.

> OpenMP 3.1 is fully supported, but disabled by default. To enable it, please use the -fopenmp=libomp command line option.

http://llvm.org/releases/3.7.0/tools/clang/docs/ReleaseNotes.html#openmp-support
  For those of us who know nothing of C, might someone be kind enough to use EMScripten/asm.js to compile to JavaScript on our behalf for use in the browser (without Node.js, etc.)?  Would no doubt be quite slow but would be handy for some web apps...  The other existing ports (Ocrad and GOCR) do not seem to hold a candle to the quality of Tesseract. Thanks!
 A particularly compelling use case beyond regular web apps would be as a browser add-on for running OCR against images encountered on the web and placing the OCR'd results in a dialog, in-place on the web page, etc..

In my Firefox add-on for [decoding QR codes](https://github.com/brettz9/qr-secret-decoder-ring/), I already have infrastructure in place which could largely be reused to allow OCR against images found while browsing the web, whether as a regular image, as a frame in a video, as a background image, SVG element, canvas, or, probably PDF too, given that ImageMagick has [already been ported](http://manuels.github.io/unix-toolbox.js/).
 Ok, thanks for the reply!
 @brettz9, It seems that someone is working on this: 
https://github.com/naptha
 Will look into it...Thanks!
  Look for these functions:
- ProcessPagesMultipageTiff(...)
- ProcessPagesInternal(...)
- ProcessPage(...)

I think NO_CUBE_BUILD in these functions should be changed to SOMETHING_ELSE, probably back to ANDROID_BUILD. 

Ray might not want these features on Android, but I see no reason to disable them in a desktop/server environment.
 Thanks Zdenko (@zdenop) for this one, and thanks in general for your work on tesseract.
  When scrollview is disabled in configure, linking fails (because it still uses scrollview)

```
libtool: link: g++ -std=c++11 -o .libs/tesseract tesseract-tesseractmain.o  ./.libs/libtesseract.so -lrt -llept -lpthread
./.libs/libtesseract.so: undefined reference to `ScrollView::Brush(ScrollView::Color)'
...
./.libs/libtesseract.so: undefined reference to `window_wait(ScrollView*)'
./.libs/libtesseract.so: undefined reference to `ScrollView::TextAttributes(char const*, int, bool, bool, bool)'
collect2: error: ld returned 1 exit status
Makefile:577: recipe for target 'tesseract' failed
```
  Using Tesseract as a library, I get a ton of this information printed to the console:

Total count=0
Min=0.00 Really=0
Lower quartile=0.00
Median=0.00, ile(0.5)=0.00
Upper quartile=0.00
Max=0.00 Really=0
Range=1
Mean= 0.00
SD= 0.00
Bottom=0, top=38, base=0, x=0

Is there any option or way to disable this?
 I disagree.  The default behavior should not be to output debug information to the console.  That should be something that needs to be turned on rather than vice-versa.
 I can take a look at patching it.  Can you point me in the right direction as to where this may be emitted from in the code?  Any idea why it happens in my compile but not in the 14.04 Tesseract lib included with Ubuntu?

Pointing to /dev/null isn't ideal, since I need to run on Windows as well.
 @zdenop I've posted on the user forum as you've suggested.  I can leave this alone if you like.  I assumed this report is valuable for you and that you would want to get more information.  But if it's not important and/or interesting, I can definitely drop it and go away :)

I know other users (of my library) have run into this.  Here's a user forum post describing their issue: https://groups.google.com/forum/#!searchin/openalpr/quartile/openalpr/2x9r5_n6KvY/6ywYI8swTsMJ  I also know of one other that has run into it.  Perhaps other people just don't take the time to report it.  Or perhaps I'm using Tesseract in a strange way that only affects me.

Here's my usage of the Tesseract library
https://github.com/openalpr/openalpr/blob/master/src/openalpr/ocr.cpp

The only non-standard thing I do (I think) is turn on this option: tesseract.SetVariable("save_blob_choices", "T"); and read all the various possibilities.

I compiled the 3.04 library as follows:
export LIBLEPT_HEADERSDIR=/storage/projects/alpr/libraries/leptonica-1.72/src/
./configure --with-extra-libraries=/storage/projects/alpr/libraries/leptonica-1.72/src/.libs/
make
 We also see this information compiling 3.04 branch with default options, as of today.

I notice the original poster got no response on forums, so I'm copying here too.

We did run 'strip --strip-debug' on both tesseract304 and lept172 bins and libraries before release.   This is for an existing code base that is being ported from windows to linux.   All the unit tests are passing in both cases, it appears to be just cosmetic but it's quite a large amount of info to be reported if/when everything is working.

 Doing 'strip' won't help you here.

>As for your issue, set the variable 'debug_file' to '/dev/null'.

>The debug printing routing will select 'nul' on windows, if 'debug_file' is set to '/dev/null'. Not sure what you mean...

if you're saying 'strip' won't remove the message here, agree.

just included for thoroughness (it's about only thing we changed from
source w/default builds of aforementioned branches)

On Tue, Nov 28, 2017 at 1:24 AM, Amit D. <notifications@github.com> wrote:

> Doing 'strip' won't help you here.
>
> As for your issue, set the variable 'debug_file' to '/dev/null'.
>
> The debug printing routing will select 'nul' on windows, if 'debug_file'
> is set to '/dev/null'.
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/72#issuecomment-347435977>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AK63KlAFhdCd9LjGHctiuwIyEuMNiUMpks5s67UogaJpZM4FkMdm>
> .
>
 whups missed 2nd part of reply.

we're unfamiliar outside of tesseract beyond emgu and our examples... if
others reading this are the same, here is the instructions on changing
'debug_file' in tesseract

https://github.com/tesseract-ocr/tesseract/wiki/FAQ#how-can-i-make-the-error-messages-go-to-tesseractlog-instead-of-stderr

thx, will try and report


On Tue, Nov 28, 2017 at 1:33 AM, Pracplay Support <support@pracplay.com>
wrote:

>
> Not sure what you mean...
>
> if you're saying 'strip' won't remove the message here, agree.
>
> just included for thoroughness (it's about only thing we changed from
> source w/default builds of aforementioned branches)
>
> On Tue, Nov 28, 2017 at 1:24 AM, Amit D. <notifications@github.com> wrote:
>
>> Doing 'strip' won't help you here.
>>
>> As for your issue, set the variable 'debug_file' to '/dev/null'.
>>
>> The debug printing routing will select 'nul' on windows, if 'debug_file'
>> is set to '/dev/null'.
>>
>> ‚Äî
>> You are receiving this because you commented.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/72#issuecomment-347435977>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AK63KlAFhdCd9LjGHctiuwIyEuMNiUMpks5s67UogaJpZM4FkMdm>
>> .
>>
>
>
 also here is a cross-post to users thread (the response I got there is to
upgrade... which we definately plan on doing once we get existing stuff
working on both platforms ;)

https://groups.google.com/d/msg/tesseract-ocr/-K5d2euBJ_I/rEm2eNgdAgAJ

sorry for cross post but more people were complaining than posting answers
so hopefully this bumps up this thread.

will lyk, gr8 work on tesseract... excited to try new version

On Tue, Nov 28, 2017 at 1:37 AM, Pracplay Support <support@pracplay.com>
wrote:

>
> whups missed 2nd part of reply.
>
> we're unfamiliar outside of tesseract beyond emgu and our examples... if
> others reading this are the same, here is the instructions on changing
> 'debug_file' in tesseract
>
> https://github.com/tesseract-ocr/tesseract/wiki/FAQ#how-
> can-i-make-the-error-messages-go-to-tesseractlog-instead-of-stderr
>
> thx, will try and report
>
>
> On Tue, Nov 28, 2017 at 1:33 AM, Pracplay Support <support@pracplay.com>
> wrote:
>
>>
>> Not sure what you mean...
>>
>> if you're saying 'strip' won't remove the message here, agree.
>>
>> just included for thoroughness (it's about only thing we changed from
>> source w/default builds of aforementioned branches)
>>
>> On Tue, Nov 28, 2017 at 1:24 AM, Amit D. <notifications@github.com>
>> wrote:
>>
>>> Doing 'strip' won't help you here.
>>>
>>> As for your issue, set the variable 'debug_file' to '/dev/null'.
>>>
>>> The debug printing routing will select 'nul' on windows, if 'debug_file'
>>> is set to '/dev/null'.
>>>
>>> ‚Äî
>>> You are receiving this because you commented.
>>> Reply to this email directly, view it on GitHub
>>> <https://github.com/tesseract-ocr/tesseract/issues/72#issuecomment-347435977>,
>>> or mute the thread
>>> <https://github.com/notifications/unsubscribe-auth/AK63KlAFhdCd9LjGHctiuwIyEuMNiUMpks5s67UogaJpZM4FkMdm>
>>> .
>>>
>>
>>
>
 You'll get the same problem with any newer version, and the solution is the same. sounds good thx 4 reply

On Tue, Nov 28, 2017 at 3:13 AM, Amit D. <notifications@github.com> wrote:

> You'll get the same problem with any newer version, and the solution is
> the same.
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/72#issuecomment-347459840>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AK63Kod4YKZjkCqrMXbSvV7TvNuzJ_f1ks5s687WgaJpZM4FkMdm>
> .
>
 suggestion corrected the issue, thx again.

On Tue, Nov 28, 2017 at 3:13 AM, Amit D. <notifications@github.com> wrote:

> You'll get the same problem with any newer version, and the solution is
> the same.
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/72#issuecomment-347459840>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AK63Kod4YKZjkCqrMXbSvV7TvNuzJ_f1ks5s687WgaJpZM4FkMdm>
> .
>
  It seems that any OpenCL operation on my OS X Yosemite machine triggers attempts to allocate extremely large memory blocks and allocation failures.

The size of the attempted allocation is 1125865547108352 bytes or in hex, 0x3fff800001000, which looks special.

OpenCL otherwise works on my machine. I use the Python OpenCV library and a commercial application that uses OpenCL.

Aside from whatever is happening here, it also looks like a bug that the profile data gets written even if OpenCL fails. I highly doubt my graphics card and processor give identical performance so it looks some invalid calculation takes place and the results are then saved.
## Testing --list-langs

Checking for languages in an OpenCL binary:

```
set -x TESSDATA_PREFIX /usr/local/Cellar/tesseract/3.03rc1_3/share   # Homebrew tesseract 3.03
/opt/tesseract-opencl/bin/tesseract --list-langs
```

Results

```
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performing profiling.

[DS] Device: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL) evaluation...
tesseract(9135,0x7fff7a778300) malloc: *** mach_vm_map(size=1125865547108352) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
OpenCL error code is -54 at   when clEnqueueNDRangeKernel .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_ThresholdRectToPix .
[DS] Device: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL) evaluated
[DS]          composeRGBPixel: 1540962513.969949 (w=1.2)
[DS]            HistogramRect: 1540962513.969949 (w=2.4)
[DS]       ThresholdRectToPix: 1540962513.969949 (w=4.5)
[DS]        getLineMasksMorph: 1204940900.030019 (w=5.0)
[DS]                    Score: 18506500096.000000

[DS] Device: "GeForce GT 755M" (OpenCL) evaluation...
tesseract(9135,0x7fff7a778300) malloc: *** mach_vm_map(size=1125865547108352) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
[DS] Device: "GeForce GT 755M" (OpenCL) evaluated
[DS]          composeRGBPixel: 1540962513.969949 (w=1.2)
[DS]            HistogramRect: 1540962513.969949 (w=2.4)
[DS]       ThresholdRectToPix: 1540962513.969949 (w=4.5)
[DS]        getLineMasksMorph: 1204940900.030019 (w=5.0)
[DS]                    Score: 18506500096.000000

[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
[DS]          composeRGBPixel: 256.000000 (w=1.2)
[DS]            HistogramRect: 256.000000 (w=2.4)
[DS]       ThresholdRectToPix: 256.000000 (w=4.5)
[DS]        getLineMasksMorph: 4294966736.000000 (w=5.0)
[DS]                    Score: 21474836480.000000
[DS] Scores written to file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz score is 18506500096.000000
[DS] Device[2] 1:GeForce GT 755M score is 18506500096.000000
[DS] Device[3] 0:(null) score is 21474836480.000000
[DS] Selected Device[1]: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL)
tesseract(9135,0x7fff7a778300) malloc: *** mach_vm_map(size=1125865547108352) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
List of available languages (2):
eng
osd
```

Subsequent executions try to use the OpenCL profile results but still get errors:

```
[DS] Profile read from file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz score is 18506500096.000000
[DS] Device[2] 1:GeForce GT 755M score is 18506500096.000000
[DS] Device[3] 0:(null) score is 21474836480.000000
[DS] Selected Device[1]: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL)
tesseract(9139,0x7fff7a778300) malloc: *** mach_vm_map(size=1125865547108352) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
List of available languages (2):
eng
osd
```
## Testing OCR of JPEG to PDF

```
set -x TESSDATA_PREFIX /usr/local/Cellar/tesseract/3.03rc1_3/share   # Homebrew tesseract 3.03
/opt/tesseract-opencl/bin/tesseract tests/resources/congress.jpg tessopencl -l eng pdf
```

Result:

```
Tesseract Open Source OCR Engine v3.04.01dev with Leptonica
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performing profiling.

[DS] Device: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL) evaluation...
tesseract(9120,0x7fff7a778300) malloc: *** mach_vm_map(size=1125865547108352) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
OpenCL error code is -54 at   when clEnqueueNDRangeKernel .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_ThresholdRectToPix .
[DS] Device: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL) evaluated
[DS]          composeRGBPixel: 1539474209.312102 (w=1.2)
[DS]            HistogramRect: 1539474209.312102 (w=2.4)
[DS]       ThresholdRectToPix: 1539474209.312102 (w=4.5)
[DS]        getLineMasksMorph: 1345623668.687865 (w=5.0)
[DS]                    Score: 19197859840.000000
[DS] Device: "GeForce GT 755M" (OpenCL) evaluation...
tesseract(9120,0x7fff7a778300) malloc: *** mach_vm_map(size=1125865547108352) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
[DS] Device: "GeForce GT 755M" (OpenCL) evaluated
[DS]          composeRGBPixel: 1539474209.312102 (w=1.2)
[DS]            HistogramRect: 1539474209.312102 (w=2.4)
[DS]       ThresholdRectToPix: 1539474209.312102 (w=4.5)
[DS]        getLineMasksMorph: 1345623668.687865 (w=5.0)
[DS]                    Score: 19197859840.000000

[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
[DS]          composeRGBPixel: 256.000000 (w=1.2)
[DS]            HistogramRect: 256.000000 (w=2.4)
[DS]       ThresholdRectToPix: 256.000000 (w=4.5)
[DS]        getLineMasksMorph: 4294966736.000000 (w=5.0)
[DS]                    Score: 21474836480.000000
[DS] Scores written to file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz score is 19197859840.000000
[DS] Device[2] 1:GeForce GT 755M score is 19197859840.000000
[DS] Device[3] 0:(null) score is 21474836480.000000
[DS] Selected Device[1]: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL)
tesseract(9120,0x7fff7a778300) malloc: *** mach_vm_map(size=1125865547108352) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
Warning in pixReadMemJpeg: work-around: writing to a temp file
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_ThresholdRectToPix .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
```
## Versions

```
tesseract 3.04.01dev
 leptonica-1.71
  libgif 4.1.6(?) : libjpeg 8d : libpng 1.6.18 : libtiff 4.0.4 : zlib 1.2.5

 OpenCL info:
  Found 1 platforms.
  Platform name: Apple.
  Version: OpenCL 1.2 (May 10 2015 19:38:45).
  Found 2 devices.
    Device 1 name: Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz.
    Device 2 name: GeForce GT 755M.
```
 My stab in the dark at any answer is that, for some reason, the OpenCL API or ABI different from Tesseract is expecting as declared in header files.

The malloc error occurs because (openclwrapper.cpp:674) in

```
size_t numDevices;
clGetProgramInfo(... sizeof(numDevices), &numDevices, ...):
```

The call to `clGetProgramInfo` writes the correct value to the lower 32-bit of numDevices, but leaves uninit'ed garbage in the upper 32-bits. But even if this is correct, other OpenCL calls generated errors:

```
[DS] Device: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL) evaluation...
OpenCL error code is -54 at   when clEnqueueNDRangeKernel .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_ThresholdRectToPix .
```

I'd be happy to investigate further if someone can point me in the right direction.
 I currently get `configure: error: Required OpenCL library not found!` ([associated config.log](https://gist.github.com/4b763df567fb8d2a7a2d)). With 3.04.00 I can compile (and seemingly use) Tesseract configured with `--enable-opencl` ([associated config.log for 3.04.00](https://gist.github.com/5b142efc198986c2e8dc)).
 I tried both master and 3.04.00 with `--enable-opencl` on Ubuntu with Catalyst 15.7 and for my two devices (FX8120 and R9 285) the OCR also outputs a .txt but the content is only empty lines and some wrong characters. Forcing to run without opencl achieves the correct output.

When running with OpenCL on FX8120 there are no warnings or errors during execution, but there are some warnings as `tiff page not found` and `box outside rectangle` on R9 285. In the end, the (wrong) output is the same for any of them.
 With OpenCL-enabled HEAD on OS X, I also get garbage for @jbarlow83's test image.

However if I convert PDFs to TIFF in the way I usually do for OCR with Tesseract, I can get text with OpenCL-enabled HEAD (the BW PDF for [this book](https://archive.org/details/aesopsfables00mclo) in this example):

```
convert -density 300 aesopsfables00mclo_bw.pdf -type Grayscale -compress lzw -background white +matte -depth 32 page_%05d.tif
```

Then OCR with e.g. `for i in page_*.tif; do tesseract $i $(basename $i .tif); done` works fine and produces text (in both text and PDF output modes). This also seems to work for multipage TIFFs (just convert without the `%05d` in the output filename), however, if I try to process a multipage TIFF during the initial OpenCL profiling run, Tesseract always crashes with a SIGABRT after the first page.

Another thing I notice though is that I also get a score of `inf` for my CPU on OpenCL, is this a bug that needs to be fixed in the `HistogramRect`/`ThresholdRectToPix` evaluations?
 Yep, I have the same problem. Try resizing your image to powers of 2. Actually, just resize the canvas, leave the text part unchanged.You could do it with ImageMagick convert, or any image editor like Photoshop. Probably you only need to size the width to power of 2, I didn't test that, but it looks like the pitch is being miscalculated with non-power of two sized images. 
 Oh...didn't mention it, but I get exactly the same output as you. Bring the distorted image up in PhotoShop, Select Filter->Distort->Shear and shear top left to bottom right with Wraparound selected. Do that 2-4 times and the text will magically appear.
 Look at Issue #124
 Hi folks,

i have a similar problems with the garbage output, when i enable opencl. I have checked out the current master revision (bd45b3a). also i get the mangled image with `tesseract -c tessedit_write_images=1 ...` command too.
The OS is Debian 64bit.

My Settings are:
```
tesseract 4.00.00alpha
 leptonica-1.74.1
  libjpeg 6b (libjpeg-turbo 1.3.1) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 OpenCL info:
  Found 1 platform(s).
  Platform 1 name: NVIDIA CUDA.
  Version: OpenCL 1.1 CUDA 6.5.51.
  Found 1 device(s).
    Device 1 name: GeForce GTX 750 Ti.
 Found AVX
 Found SSE

```
the console output is:
```
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
OSD: Weak margin (1.36) for 292 blob text block, but using orientation anyway: 0
[DS] Profile read from file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:GeForce GTX 750 Ti score is 0.128314
[DS] Device[2] 0:(null) score is 0.917442
[DS] Selected Device[1]: "GeForce GTX 750 Ti" (OpenCL)
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
OSD: Weak margin (5.65) for 486 blob text block, but using orientation anyway: 3
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
```
My Question is: do i have a malconfigurated system or is it a bug?  Hi,
I'm packaging tesseract for Gentoo Linux. What is the up-to-date download location for training data? We used to download from Google Code, but that looks like it is going to close eventually. Ideally we would like to have pre-packaged .tar.gz files for each language (like we used to have on Google code). Would that be possible also on github?

Should we still use the language files from [here](https://code.google.com/p/tesseract-ocr/downloads/list) with 3.04.00 ?

Thanks!
 I'm not a user of tesseract user, I'm packaging it. Therefore I'm looking to quickly identify which files I need to provide to the users.  At the moment it seems to be the case that I have to get the source from github, and language files from an old version of google code.  So one issue is that it's not documented that the 3.02 language files and tesseract-3.04 belong together. From what I read in the forums this is indeed the case. The issue is NOT that I want you to tar individual files. The issue is that there is no single official location where to download everything needed to ship your software to your users (in Gentoo).
 OK, thanks. Tesseract-3.04.00 is in Gentoo with up to date traineddata now.
  The current link points to the README file in master branch, rather than the wiki that the intro text implies it should be pointing to.
 That's fair. I saw "wiki" and was confused that it pointed to the README. Thanks for the clarification.
  Hello

I just compiled tesseract 3.04 on CentOS and it works perfectly.

But I¬¥m trying to run mftraining and I¬¥m getting this error:

[~/tesseract-master]# mftraining
Segmentation fault (core dumped)

Any suggestions?

Thanks
 ./configure --enable-debug
Then provide a backtrace with gdb (if you know how)
 I have never done that, but anyway I gave a try but got stucked:

@ gdb mftraining
GNU gdb (GDB) Red Hat Enterprise Linux (7.2-75.el6)
Copyright (C) 2010 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later http://gnu.org/licenses/gpl.html
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-redhat-linux-gnu".
For bug reporting instructions, please see:
http://www.gnu.org/software/gdb/bugs/...
Reading symbols from /usr/local/bin/mftraining...done.
(gdb)
 Thanks, @zdenop 

The result is:
(gdb) run
Starting program: /usr/local/bin/mftraining
[Thread debugging using libthread_db enabled]

Program received signal SIGSEGV, Segmentation fault.
0x0000003c4de7b53c in free () from /lib64/libc.so.6
Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.149.el6_6.7.x86_64 libgcc-4.4.7-11.el6.x86_64 libjpeg-turbo-1.2.1-3.el6_5.x86_64 libpng-1.2.49-1.el6_2.x86_64 libstdc++-4.4.7-11.el6.x86_64 libtiff-3.9.4-10.el6_5.x86_64 zlib-1.2.3-29.el6.x86_64
(gdb)
 @vzani: the critical part is entering the command "backtrace" after the segmentation fault.
 entered the command "backtrace",the result is:
Program received signal SIGSEGV, Segmentation fault.
0x0000003951e7b5dc in free () from /lib64/libc.so.6
Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.166.el6_7.1.x86_64 libgcc-4.4.7-16.el6.x86_64 libjpeg-turbo-1.2.1-3.el6_5.x86_64 libpng-1.2.49-1.el6_2.x86_64 libstdc++-4.4.7-16.el6.x86_64 libtiff-3.9.4-10.el6_5.x86_64 zlib-1.2.3-29.el6.x86_64
(gdb) backtrace
#0  0x0000003951e7b5dc in free () from /lib64/libc.so.6
#1  0x0000000000407d6b in GenericVectortesseract::DoubleParam*::reserve (
    this=0x60e088, size=4) at ../ccutil/genericvector.h:484
#2  0x0000000000407e30 in double_the_size (this=0x7ffff7d6be40, 
    value=<value optimized out>, 
    name=0x7ffff7ad49cd "classify_norm_adj_midpoint", 
    comment=<value optimized out>, init=<value optimized out>, vec=0x60e010)
    at ../ccutil/genericvector.h:492
#3  push_back (this=0x7ffff7d6be40, value=<value optimized out>, 
    name=0x7ffff7ad49cd "classify_norm_adj_midpoint", 
    comment=<value optimized out>, init=<value optimized out>, vec=0x60e010)
    at ../ccutil/genericvector.h:588
#4  tesseract::DoubleParam::DoubleParam (this=0x7ffff7d6be40, 
    value=<value optimized out>, 
    name=0x7ffff7ad49cd "classify_norm_adj_midpoint", 
    comment=<value optimized out>, init=<value optimized out>, vec=0x60e010)
    at ../ccutil/params.h:203
#5  0x00007ffff7a46572 in global constructors keyed to normmatch.cpp ()
   from /usr/local/lib/libtesseract.so.3
#6  0x00007ffff7ab5386 in __do_global_ctors_aux ()
   from /usr/local/lib/libtesseract.so.3
#7  0x00007ffff78df193 in _init () from /usr/local/lib/libtesseract.so.3
#8  0x00007ffff7485990 in ?? ()
 My result of "backtrace" is:

#0  0x0000003c4de7b53c in free () from /lib64/libc.so.6
#1  0x0000000000407d6b in GenericVectortesseract::DoubleParam*::reserve (
    this=0x60e088, size=4) at ../ccutil/genericvector.h:484
#2  0x0000000000407e30 in double_the_size (this=0x7ffff7d6bba0,
    value=<value optimized out>,
    name=0x7ffff7ad09ad "classify_norm_adj_midpoint",
    comment=<value optimized out>, init=<value optimized out>, vec=0x60e010)
    at ../ccutil/genericvector.h:492
#3  push_back (this=0x7ffff7d6bba0, value=<value optimized out>,
    name=0x7ffff7ad09ad "classify_norm_adj_midpoint",
    comment=<value optimized out>, init=<value optimized out>, vec=0x60e010)
    at ../ccutil/genericvector.h:588
#4  tesseract::DoubleParam::DoubleParam (this=0x7ffff7d6bba0,
    value=<value optimized out>,
    name=0x7ffff7ad09ad "classify_norm_adj_midpoint",
    comment=<value optimized out>, init=<value optimized out>, vec=0x60e010)
    at ../ccutil/params.h:203
#5  0x00007ffff7a2a0f2 in global constructors keyed to normmatch.cpp ()
   from /usr/local/lib/libtesseract.so.3
#6  0x00007ffff7ab5346 in __do_global_ctors_aux ()
   from /usr/local/lib/libtesseract.so.3
#7  0x00007ffff78df193 in _init () from /usr/local/lib/libtesseract.so.3
#8  0x00007ffff740e990 in ?? ()
#9  0x0000003c4da0e605 in _dl_init_internal () from /lib64/ld-linux-x86-64.so.2
#10 0x0000003c4da00b3a in _dl_start_user () from /lib64/ld-linux-x86-64.so.2
#11 0x0000000000000001 in ?? ()
#12 0x00007fffffffe79d in ?? ()
#13 0x0000000000000000 in ?? ()

Any suggestions?

Thanks
 Can you double check the compilation environment?
the reserve function being in ccutil/genericvector.h on line 484 looks like version 3.02.02
Is older version of tesseract already installed?
 @koralatov, did you add this junk message, or was your account hacked? After looking at the activity list, I reported abuse to GitHub.
 Sorry. At some point overnight someone/thing hacked my email and sent these and quite a number of other obviously spammy emails.  I'm cleaning up now. 
  ```
In file included from ./blamer.h:27:
./matrix.h:292:63: error: reinterpret_cast from 'nullptr_t' to 'BLOB_CHOICE_LIST *' is not allowed
    : BandTriMatrix<BLOB_CHOICE_LIST *>(dimension, bandwidth, NOT_CLASSIFIED) {}
                                                              ^~~~~~~~~~~~~~
./matrix.h:33:24: note: expanded from macro 'NOT_CLASSIFIED'
#define NOT_CLASSIFIED reinterpret_cast<BLOB_CHOICE_LIST*>(NULL)
                       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
```

clang-3.4.1
 I can repreduce this error on freebsd 10.3 with clang 3.4.1Ôºö
[xx@ ~/work/tesseract-3.04.01]$ clang --version
FreeBSD clang version 3.4.1 (tags/RELEASE_34/dot1-final 208032) 20140512
Target: x86_64-unknown-freebsd10.3
Thread model: posix
 and also 11.0RC2 with clang 3.8.0Ôºö
[~/work_space/tesseract-3.04.01]$ clang --version
FreeBSD clang version 3.8.0 (tags/RELEASE_380/final 262564) (based on LLVM 3.8.0)
Target: x86_64-unknown-freebsd11.0
Thread model: posix
InstalledDir: /usr/bin

ibtool: compile:  clang++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I../ccutil -I../cutil -I../viewer -I../opencl -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT blread.lo -MD -MP -MF .deps/blread.Tpo -c blread.cpp  -fPIC -DPIC -o .libs/blread.o
--- blamer.lo ---
In file included from blamer.cpp:21:
In file included from ./blamer.h:27:
./matrix.h:292:63: error: reinterpret_cast from 'nullptr_t' to 'BLOB_CHOICE_LIST _' is not allowed
    : BandTriMatrix<BLOB_CHOICE_LIST *>(dimension, bandwidth, NOT_CLASSIFIED) {}
                                                              ^~~~~~~~~~~~~~
./matrix.h:33:24: note: expanded from macro 'NOT_CLASSIFIED'
#define NOT_CLASSIFIED reinterpret_cast<BLOB_CHOICE_LIST_>(NULL)
                       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 I see the HEAD already include the fix,thanks!
  The tesstrain.sh and related training scripts are very useful. Please include them as part of the package (if not included). Thanks! 
  Hi,
I'm running 3.05.00dev on Ubuntu 14.04 LTS.
When running:
`tesseract eng.Arial.exp0.tif eng.Arial.exp0 box.train`
I'm getting a simple one-line output:
`Tesseract Open Source OCR Engine v3.05.00dev with Leptonica`

However, no `.tr` output file is created (anywhere in the filesystem).

My work dir listing is:

```
Arial.ttf
common.punc
eng.Arial.exp0.box
eng.Arial.exp0.tif
training-text.txt
```

Running with gdb doesn't give anything additional.

Anything I can look for for extra info? Any ideas what might be causing this?

Thanks
 I'm having exactly the same problem than danageva with the same version but over OS X. Apparently zdenop closed the issue with a deletion in two files. I don't have those lines in my installed version. Can you help me please?
 I'm having exactly the same problem. I have the latest code from the repo.
Edit: It works with v3.04.00
 `git rev-parse HEAD` command gives me 1826ac140b30a0f271726cbcbdc49a10eae80387

`uname -a`
`Linux ubuntu 3.19.0-42-generic #48-Ubuntu SMP Thu Dec 17 22:54:45 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux`
`lsb_release -a`
`Distributor ID:    Ubuntu
Description:    Ubuntu 15.04
Release:    15.04
Codename:   vivid`

The exact command is:
`tesseract ult.dejavu.exp0.tif ult.dejavu.exp0 box.train`
The output:
`Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Segmentation fault (core dumped)`
If I use it with sudo:
`sudo tesseract ult.dejavu.exp0.tif ult.dejavu.exp0 box.train`
The output:
`Tesseract Open Source OCR Engine v3.05.00dev with Leptonica`

Required files attached.
[ult.zip](https://github.com/tesseract-ocr/tesseract/files/106879/ult.zip)
 I installed it as:

```
./autogen.sh
./configure --prefix=/home/username/tessbin
make
make install
make training
make training-install
```
 ... or call `/home/username/tessbin/bin/tesseract` directly.
 Nope, there's no other tesseract in my machine. find does not return
anything.

On 27 January 2016 at 18:36, Amit Dovev notifications@github.com wrote:

> Try this command to see if you have another installation of Tesseract in
> your machine.
> 
> find /usr -name "tesseract"
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/64#issuecomment-175761505
> .
 @aiwaz, could you try this command:

```
gdb --args tesseract ult.dejavu.exp0.tif ult.dejavu.exp0 box.train
```

(Enter `run` on the gdb command line, and when it reports an error `info stack`)
 ```
gdb --args tesseract ult.dejavu.exp0.tif ult.dejavu.exp0 box.train
GNU gdb (Ubuntu 7.9-1ubuntu1) 7.9
Copyright (C) 2015 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-linux-gnu".
Type "show configuration" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
<http://www.gnu.org/software/gdb/documentation/>.
For help, type "help".
Type "apropos word" to search for commands related to "word"...
Reading symbols from ../../bin/tesseract...done.
(gdb) run
Starting program: /home/azukausk/tessbin/bin/tesseract ult.dejavu.exp0.tif ult.dejavu.exp0 box.train
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica

Program received signal SIGSEGV, Segmentation fault.
tesseract::TessResultRenderer::BeginDocument (this=this@entry=0x83f0b0, title=title@entry=0x7ffff78a8fea "")
    at renderer.cpp:57
57    bool ok = BeginDocumentHandler();
(gdb) info stack
#0  tesseract::TessResultRenderer::BeginDocument (this=this@entry=0x83f0b0, title=title@entry=0x7ffff78a8fea "")
    at renderer.cpp:57
#1  0x00007ffff76cee2f in tesseract::TessBaseAPI::ProcessPagesInternal (this=this@entry=0x7fffffffe2a0, 
    filename=<optimized out>, retry_config=retry_config@entry=0x0, timeout_millisec=timeout_millisec@entry=0, 
    renderer=0x83f0b0) at baseapi.cpp:1166
#2  0x00007ffff76cf570 in tesseract::TessBaseAPI::ProcessPages (this=this@entry=0x7fffffffe2a0, 
    filename=<optimized out>, retry_config=retry_config@entry=0x0, timeout_millisec=timeout_millisec@entry=0, 
    renderer=<optimized out>) at baseapi.cpp:1074
#3  0x0000000000401f5c in main (argc=<optimized out>, argv=0x7fffffffe448) at tesseractmain.cpp:429
(gdb)
```
 @stweil, I always call tesseract directly. It resides in `/home/username/tessbin/bin/tesseract` , just as you wrote. I created an alias for it in bashrc.
 TESSDATA_PREFIX is empty.

```
tesseract --list-langs
List of available languages (1):
eng
```
 ```
tesseract ult.dejavu.exp0.tif ult txt hocr
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Error opening data file /home/azukausk/tessbin/share/tessdata/osd.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your "tessdata" directory.
Failed loading language 'osd'
Tesseract couldn't load any languages!
Warning: Auto orientation and script detection requested, but osd language failed to load
Warning in pixReadMemTiff: tiff page 1 not found
```

Why it wants to load the "osd" language?

The files are produced:

```
ll
total 21500
drwxrwxr-x 2 azukausk azukausk     4096 Jan 27 13:49 configs
-rw-rw-r-- 1 azukausk azukausk 21876550 Jan 25 15:41 eng.traineddata
-rw-r--r-- 1 azukausk azukausk      568 Jan 27 13:49 pdf.ttf
drwxrwxr-x 2 azukausk azukausk     4096 Jan 27 13:49 tessconfigs
-rw-rw-r-- 1 azukausk azukausk     1649 Jan 25 15:56 training_text
-rw-rw-r-- 1 azukausk azukausk    38706 Jan 27 12:53 ult.dejavu.exp0.box
-rw-rw-r-- 1 azukausk azukausk    39984 Jan 27 12:53 ult.dejavu.exp0.tif
-rw-rw-r-- 1 azukausk azukausk    36383 Jan 28 12:03 ult.hocr
-rw-rw-r-- 1 azukausk azukausk     1685 Jan 28 12:03 ult.txt
```

When I set the TESSDATA_PREFIX variable the output is the same:

```
TESSDATA_PREFIX=/home/azukausk/tessbin/share/tessdata
echo $TESSDATA_PREFIX
/home/azukausk/tessbin/share/tessdata
tesseract ult.dejavu.exp0.tif ult txt hocr
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Error opening data file /home/azukausk/tessbin/share/tessdata/osd.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your "tessdata" directory.
Failed loading language 'osd'
Tesseract couldn't load any languages!
Warning: Auto orientation and script detection requested, but osd language failed to load
Warning in pixReadMemTiff: tiff page 1 not found
```

And one more question: when I configure tesseract with --prefix option, I expect tesseract to be smart enough to know where my data are. Why do I have to set TESSDATA_PREFIX variable explicitly?
 Setting TESSDATA_PREFIX is not needed as long as your `tessdata` directory is at the right place ($PREFIX/share/tessdata).

`osd.traineddata` will be used for auto orientation and script detection, no matter which language you have selected.
 I tested the fix and confirm that `tesseract ult.dejavu.exp0.tif ult.dejavu.exp0 box.train` now produces `.tr` file.
Thank you guys.
  Using windows binaries compiled by Simon on cygwin from http://domasofan.spdns.eu/tesseract/

$ tesseract testing\eurotext.tif testing\eurotext -l eng+deu pdf

Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Error in fopenWriteStream: stream not opened
Error in pixWrite: stream not opened
Error in fopenReadStream: file not found
Error in extractG4DataFromFile: stream not opened to file
Error in l_generateG4Data: datacomp not extracted
Error in pixGenerateCIData: g4 data not made
Error in l_generateCIDataForPdf: file testing\eurotext.tif format is 4; unreadable
Error during processing.

the pdf comes out but you can't open it.
adobe reader shows an error that it is corrupted.

(Forum thread - https://groups.google.com/forum/#!msg/tesseract-ocr/ToWcnyHqF4c/FHWGlQhd6poJ )
 Version information - 
tesseract 3.05.00dev
 leptonica-1.72
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.3.1) : libpng 1.6.17 : libtiff 4.0.3 : zlib 1.2.8 : libwebp 0.4.3
 on cygwin x86_64 and same on x86:
 $  tesseract --version
tesseract 3.04.00
 leptonica-1.72
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.3.1) : libpng 1.6.17 : libtiff 4.0.3 : zlib 1.2.8 : libwebp 0.4.3

$  tesseract eurotext.tif eurotext -l eng+deu pdf
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
Page 1
Warning in pixReadMemTiff: tiff page 1 not found

$ ls -lrt eurotext.pdf
-rw-r--r-- 1 marco Administrators 13K Jul 26 21:36 eurotext.pdf
 Marco, the version I tested was 'v3.05.00dev' based on the master branch from git (built by Simon). 

Could it be that one of the newer commits has caused this issue?
 I doubt, more likely you are missing some additional library/program or
a missing configuration.

On Mon, Jul 27, 2015 at 5:01 AM, Shreeshrii notifications@github.com
wrote:

> Marco, the version I tested was 'v3.05.00dev' based on the master branch
> from git (built by Simon).
> 
> Could it be that one of the newer commits has caused this issue?
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/63#issuecomment-125068829
> .
 Tesseract knows that PDF creation failed and returns an error code. So at least this is not silent data corruption. I'd like to know if the problem is present for PNG input or if it is restricted to TIFF.
 Jeff, it worked for png and jpg for pdf output. This is using the versions compiled by Simon.

C:\Users\User\Downloads\TESS>tesseract -v
tesseract 3.05.00dev
 leptonica-1.72
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.3.1) : libpng 1.6.17 : libtiff 4.0.3 : zlib 1.2.8 : libwebp 0.4.3

C:\Users\User\Downloads\TESS>tesseract testing/phototest.gif testing/phototest.gif -l eng pdf
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Warning in pixReadMemGif: writing to a temp file, not directly to memory
Error in fopenWriteStream: stream not opened
Error in l_binaryWrite: stream not opened
Error in fopenReadStream: file not found
Error in pixRead: image file not found: /tmp/leptonica/847980_4108_mem.gif
Error in pixReadMemGif: pix not read
Error in pixReadMem: gif: no pix returned
Error during processing.

C:\Users\User\Downloads\TESS>tesseract testing/phototest.tif testing/phototest.tif -l eng pdf
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Error in fopenWriteStream: stream not opened
Error in pixWrite: stream not opened
Error in fopenReadStream: file not found
Error in extractG4DataFromFile: stream not opened to file
Error in l_generateG4Data: datacomp not extracted
Error in pixGenerateCIData: g4 data not made
Error in l_generateCIDataForPdf: file testing/phototest.tif format is 4; unreadable
Error during processing.

C:\Users\User\Downloads\TESS>tesseract testing/phototest.tif testing/phototest.tif -l eng
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Warning in pixReadMemTiff: tiff page 1 not found

C:\Users\User\Downloads\TESS>tesseract testing/phototest.png testing/phototest.png -l eng pdf
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica

C:\Users\User\Downloads\TESS>tesseract testing/phototest.jpg testing/phototest.jpg -l eng pdf
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
  Directory of C:\Users\User\Downloads\TESS\testing

07/28/15  08:10            55,504 phototest.gif
07/28/15  08:19                 0 phototest.gif.pdf
08/28/14  20:38            57,772 phototest.jpg
07/28/15  08:20            61,460 phototest.jpg.pdf
08/28/14  20:38             5,265 phototest.png
07/28/15  08:20             8,890 phototest.png.pdf
07/24/15  12:15            38,668 phototest.tif
07/28/15  08:20             2,910 phototest.tif.pdf
07/28/15  08:20               287 phototest.tif.txt
 Hmmm.... interesting.  I suspect this is related to that classic Windows problem
where you can't pass file pointers between different DLLs, especially if they use
different runtimes. If so, we may be in trouble.
 Or... do we still have some ifdefs in the code to do Windows streaming I/O a little differently? I vaguely remember writing some back in the day. Maybe they are misbehaving under Cygwin? Can't seem to find them at the moment.
 Marco is able to get the pdf output from the 3.04.00 version he packaged
for cygwin.

I was testing based on the (3.05.dev version) files that were built by Simon. I do not have
cygwin installed but will try downloading the files from the mirrors Marco
suggested and see what happens.

FYI, I downloaded the MSYS2 tesseract-ocr package for 3.04.00 (packaged by
Alex at
https://github.com/Alexpux/MINGW-packages/tree/master/mingw-w64-tesseract-ocr)
and am able to get the pdf output from it.

ShreeDevi

---

‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Tue, Jul 28, 2015 at 9:05 AM, jbreiden notifications@github.com wrote:

> Or... do we still have some ifdefs in the code to do Windows streaming I/O
> a little differently? I vaguely remember writing some back in the day.
> Maybe they are misbehaving under Cygwin? Can't seem to find them at the
> moment.
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/63#issuecomment-125427714
> .
 Just to clarify, I am referring the pdf output from tif input in the above post.
 Working with 3.04.00 packaged by Marco for cygwin

ra@Shree ~/tesseract-ocr
$ tesseract testing/phototest.tif phototest.tif
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
Page 1
Warning in pixReadMemTiff: tiff page 1 not found

ra@Shree ~/tesseract-ocr
$ tesseract testing/phototest.tif testing/phototest.tif pdf
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
Page 1
Warning in pixReadMemTiff: tiff page 1 not found

ra@Shree ~/tesseract-ocr
$ tesseract testing/phototest.tif testing/phototest.tif hocr
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
Page 1
Warning in pixReadMemTiff: tiff page 1 not found

ra@Shree ~/tesseract-ocr
$ tesseract --list-langs
List of available languages (2):
eng
osd

ra@Shree ~/tesseract-ocr
$ tesseract -v
tesseract 3.04.00
 leptonica-1.72
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.3.1) : libpng 1.6.17 : libtiff 4.0.3 : zlib 1.2.8 : libwebp 0.4.3
 ra@Shree ~/tesseract-ocr/testing
$ ls -lrt
total 165
-rwx---r-x 1 ra ra  38668 Jul 29 11:45 phototest.tif
-rwx---r-x 1 ra ra 102598 Jul 29 11:45 eurotext.tif
-rw----r-- 1 ra ra   7712 Jul 29 11:47 phototest.tif.pdf
-rw----r-- 1 ra ra    287 Jul 29 11:48 phototest.tif.txt
-rw----r-- 1 ra ra   8394 Jul 29 11:48 phototest.tif.hocr
 I went into pbrush and created a Hello World image and saved it as bmp, gif, jpg, png, and tif. When I process those files using tesseract.exe imagefile textfile -l eng, all the files process correctly except the GIF file. I included the GIF and the output below:

Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Warning in pixReadMemGif: writing to a temp file, not directly to memory
Error in fopenWriteStream: stream not opened
Error in l_binaryWrite: stream not opened
Error in fopenReadStream: file not found
Error in pixRead: image file not found: /tmp/199506_720_mem.gif
Error in pixReadMemGif: pix not read
Error in pixReadMem: gif: no pix returned
Error during processing.
![helloworld](https://cloud.githubusercontent.com/assets/11964590/18092293/6a92bfd8-6e91-11e6-8c27-2e66a0da3114.gif)

Also here is the version dump:

tesseract 3.05.00dev
 leptonica-1.73
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.6.20 : libtiff 4
.0.6 : zlib 1.2.8 : libwebp 0.4.3

If I was a guessing man I would say maybe it is in the temporary file name /tmp/199506_720_mem.gif likely not conforming to MS windows.

A little more information, looking at the pixReadMemGif routine it makes a call to get a temporary file, in doing so that routine tries to ensure that the tmp directory exists, when I created a tmp directory at the root of the drive where I am running tesseract, the GIF file correctly extracted after creating that directory. That is in the Leptonica utils.c file in the genTempFilename routine.
 Maybe leptonic is not built with gif library
- sent from my phone. excuse the brevity.

On 30-Aug-2016 7:40 PM, "LeeBear35" notifications@github.com wrote:

> I went into pbrush and created a Hello World image and saved it as bmp,
> gif, jpg, png, and tif. When I process those files using tesseract.exe
> imagefile textfile -l eng, all the files process correctly except the GIF
> file. I included the GIF and the output below:
> 
> Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
> Warning in pixReadMemGif: writing to a temp file, not directly to memory
> Error in fopenWriteStream: stream not opened
> Error in l_binaryWrite: stream not opened
> Error in fopenReadStream: file not found
> Error in pixRead: image file not found: /tmp/199506_720_mem.gif
> Error in pixReadMemGif: pix not read
> Error in pixReadMem: gif: no pix returned
> Error during processing.
> [image: helloworld]
> https://cloud.githubusercontent.com/assets/11964590/18092293/6a92bfd8-6e91-11e6-8c27-2e66a0da3114.gif
> 
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/63#issuecomment-243451328,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o7pPyAlMmoDPBQ3BkxMC24_LqyNXks5qlDnGgaJpZM4FfEhW
> .
 After further research the issue is with the Leptonica utils.c genTempFilename method, it attempts to ensure that the tmp directory exists on the drive where the program is executing, but fails to create the directory so the resulting temp file returned cannot not be created or used. If the tmp directory is created then the GIF file is processed and extracted correctly.

I updated my post when I discovered this short coming.

Leland Carpenter ‚ô¶ Sr. Software Engineer ‚ô¶ PRGX USA, Inc.
4904 Hickory Way ‚ô¶ Johnsburg, IL 60051-8967
O: 815.307.7634 ‚ô¶ Lee.Carpenter@prgx.commailto:Lee.Carpenter@prgx.com
[cid:image001.jpg@01D202A3.3B9A04C0]

From: Shreeshrii [mailto:notifications@github.com]
Sent: Tuesday, August 30, 2016 09:41 AM
To: tesseract-ocr/tesseract tesseract@noreply.github.com
Cc: Carpenter, Lee Lee.Carpenter@prgx.com; Comment comment@noreply.github.com
Subject: Re: [tesseract-ocr/tesseract] corrupt pdf output on cygwin (#63)

Maybe leptonic is not built with gif library
- sent from my phone. excuse the brevity.

On 30-Aug-2016 7:40 PM, "LeeBear35" <notifications@github.com<mailto:notifications@github.com>> wrote:

> I went into pbrush and created a Hello World image and saved it as bmp,
> gif, jpg, png, and tif. When I process those files using tesseract.exe
> imagefile textfile -l eng, all the files process correctly except the GIF
> file. I included the GIF and the output below:
> 
> Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
> Warning in pixReadMemGif: writing to a temp file, not directly to memory
> Error in fopenWriteStream: stream not opened
> Error in l_binaryWrite: stream not opened
> Error in fopenReadStream: file not found
> Error in pixRead: image file not found: /tmp/199506_720_mem.gif
> Error in pixReadMemGif: pix not read
> Error in pixReadMem: gif: no pix returned
> Error during processing.
> [image: helloworld]
> https://cloud.githubusercontent.com/assets/11964590/18092293/6a92bfd8-6e91-11e6-8c27-2e66a0da3114.gif
> 
> ‚Äî
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/63#issuecomment-243451328,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o7pPyAlMmoDPBQ3BkxMC24_LqyNXks5qlDnGgaJpZM4FfEhW
> .

‚Äî
You are receiving this because you commented.
Reply to this email directly, view it on GitHubhttps://github.com/tesseract-ocr/tesseract/issues/63#issuecomment-243462302, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ALaQrt3vwLXo6DiUEMrtKldXWIn3hi2qks5qlEEEgaJpZM4FfEhW.
  /tmp/199506_720_mem.gif is fine for cygwin. Are you using a cygwin build without a proper directory structure ?
 @jbreiden Starting from 1.73 is following the Unix tmp path.
 Might be that I am running on the e: drive instead of the c: drive and that there was no e:\tmp, it was just a matter of the routine not swapping out the /tmp for the windows temporary directory.

Leland Carpenter ‚ô¶ Sr. Software Engineer ‚ô¶ PRGX USA, Inc.
4904 Hickory Way ‚ô¶ Johnsburg, IL 60051-8967
O: 815.307.7634 ‚ô¶ Lee.Carpenter@prgx.commailto:Lee.Carpenter@prgx.com
[cid:image001.jpg@01D2035F.0F526440]

From: jbreiden [mailto:notifications@github.com]
Sent: Tuesday, August 30, 2016 08:51 PM
To: tesseract-ocr/tesseract tesseract@noreply.github.com
Cc: Carpenter, Lee Lee.Carpenter@prgx.com; Comment comment@noreply.github.com
Subject: Re: [tesseract-ocr/tesseract] corrupt pdf output on cygwin (#63)

I have a number of tempfile patches already written for Leptonica to these calls more
secure and less brittle, and there is ongoing work on this topic. I actually don't know if
cygwin is using the Unix or Windows code path for temporary files, but just want to
mention that there is activity. Don't know why you are getting bad results compared to
other cygwin users.

https://sources.debian.net/src/leptonlib/1.73-5/debian/patches/

‚Äî
You are receiving this because you commented.
Reply to this email directly, view it on GitHubhttps://github.com/tesseract-ocr/tesseract/issues/63#issuecomment-243635600, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ALaQrkGGqG6w13z9K5OGD9_kiB2gU7J2ks5qlN4ggaJpZM4FfEhW.
  Hi,

I just tried to build the training tools using cygwin.
the normal tesseract program seems to work fine.

Thanks for helping.
you are doing all a good job and the recognizationrate is also very nice now in german texts.

that's what it was showing after typing make training:

$ make training
make[1]: Entering directory '/home/Besitzer/tesseractsrc/training'
depbase=`echo boxchar.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT boxchar.lo -MD -MP -MF $depb
ase.Tpo -c -o boxchar.lo boxchar.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT boxchar.lo -MD -MP -MF .deps/boxchar.Tpo -c boxchar.cpp -o b
oxchar.o
depbase=`echo commandlineflags.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT commandlineflags.lo -MD -MP
-MF $depbase.Tpo -c -o commandlineflags.lo commandlineflags.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT commandlineflags.lo -MD -MP -MF .deps/commandlineflags.Tpo -
c commandlineflags.cpp -o commandlineflags.o
depbase=`echo commontraining.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT commontraining.lo -MD -MP -M
F $depbase.Tpo -c -o commontraining.lo commontraining.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT commontraining.lo -MD -MP -MF .deps/commontraining.Tpo -c co
mmontraining.cpp -o commontraining.o
depbase=`echo degradeimage.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT degradeimage.lo -MD -MP -MF
$depbase.Tpo -c -o degradeimage.lo degradeimage.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT degradeimage.lo -MD -MP -MF .deps/degradeimage.Tpo -c degrad
eimage.cpp -o degradeimage.o
depbase=`echo fileio.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT fileio.lo -MD -MP -MF $depba
se.Tpo -c -o fileio.lo fileio.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT fileio.lo -MD -MP -MF .deps/fileio.Tpo -c fileio.cpp -o file
io.o
depbase=`echo ligature_table.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT ligature_table.lo -MD -MP -M
F $depbase.Tpo -c -o ligature_table.lo ligature_table.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT ligature_table.lo -MD -MP -MF .deps/ligature_table.Tpo -c li
gature_table.cpp -o ligature_table.o
depbase=`echo normstrngs.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT normstrngs.lo -MD -MP -MF $d
epbase.Tpo -c -o normstrngs.lo normstrngs.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT normstrngs.lo -MD -MP -MF .deps/normstrngs.Tpo -c normstrngs
.cpp -o normstrngs.o
depbase=`echo pango_font_info.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT pango_font_info.lo -MD -MP -
MF $depbase.Tpo -c -o pango_font_info.lo pango_font_info.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT pango_font_info.lo -MD -MP -MF .deps/pango_font_info.Tpo -c
pango_font_info.cpp -o pango_font_info.o
pango_font_info.cpp: In member function 'bool tesseract::PangoFontInfo::ParseFon
tDescription(const PangoFontDescription_)':
pango_font_info.cpp:223:46: error: 'strcasestr' was not declared in this scope
   is_fraktur_ = (strcasestr(family, "Fraktur") != NULL);
                                              ^
Makefile:875: recipe for target 'pango_font_info.lo' failed
make[1]: *_\* [pango_font_info.lo] Error 1
make[1]: Leaving directory '/home/Besitzer/tesseractsrc/training'
Makefile:880: recipe for target 'training' failed
make: **\* [training] Error 2

Besitzer@simon ~/tesseractsrc
$ make training-install
make[1]: Entering directory '/home/Besitzer/tesseractsrc/training'
depbase=`echo pango_font_info.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT pango_font_info.lo -MD -MP -
MF $depbase.Tpo -c -o pango_font_info.lo pango_font_info.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT pango_font_info.lo -MD -MP -MF .deps/pango_font_info.Tpo -c
pango_font_info.cpp -o pango_font_info.o
pango_font_info.cpp: In member function 'bool tesseract::PangoFontInfo::ParseFon
tDescription(const PangoFontDescription_)':
pango_font_info.cpp:223:46: error: 'strcasestr' was not declared in this scope
   is_fraktur_ = (strcasestr(family, "Fraktur") != NULL);
                                              ^
Makefile:875: recipe for target 'pango_font_info.lo' failed
make[1]: *_\* [pango_font_info.lo] Error 1
make[1]: Leaving directory '/home/Besitzer/tesseractsrc/training'
Makefile:882: recipe for target 'training-install' failed
make: **\* [training-install] Error 2

Besitzer@simon ~/tesseractsrc
$
 Just tested it with the recent merged pull request.
this is what i get with make training:

g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG -DUSE_STD_NAMESPACE 
-DPANGO_ENABLE_EN
GINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewer 
-I../textord -I.
./dict -I../classify -I../display -I../wordrec -I../cutil 
-I../vs2010/port -I/us
r/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 
-I/usr/include/glib-2.
0 -I/usr/lib/glib-2.0/include  -I/usr/include/cairo 
-I/usr/include/glib-2.0 -I/u
sr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 
-I/usr/
include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng16 
-std=gnu++11
  -MT set_unicharset_properties.o -MD -MP -MF $depbase.Tpo -c -o 
set_unicharset_p
roperties.o set_unicharset_properties.cpp &&\
mv -f $depbase.Tpo $depbase.Po
/bin/sh ../libtool  --tag=CXX   --mode=link g++  -std=gnu++11 
-Wl,-no-undefined
-Wl,--as-needed   -o set_unicharset_properties.exe 
set_unicharset_properties.o l
ibtesseract_training.la libtesseract_tessopt.la -licuin -licuuc 
../api/libtesse
ract.la -lws2_32  -llept
libtool: link: g++ -std=gnu++11 -Wl,-no-undefined -Wl,--as-needed -o 
set_unichar
set_properties.exe set_unicharset_properties.o 
./.libs/libtesseract_training.a
./.libs/libtesseract_tessopt.a -licuin -licuuc 
../api/.libs/libtesseract.a -lws2
_32 -llept
/usr/lib/gcc/i686-pc-cygwin/4.9.3/../../../../i686-pc-cygwin/bin/ld: 
cannot find
  -licuin
collect2: error: ld returned 1 exit status
Makefile:805: recipe for target 'set_unicharset_properties.exe' failed
make[1]: **\* [set_unicharset_properties.exe] Error 1
make[1]: Leaving directory '/home/Besitzer/tesseractsrc/training'
Makefile:880: recipe for target 'training' failed
make: **\* [training] Error 2

Am 23.07.2015 um 23:31 schrieb Jim Regan:

> Can you try the patch in #60 to see if that fixes it?
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/tesseract-ocr/tesseract/issues/61#issuecomment-124245368

## 

Simon Eigeldinger
Follow me on Twitter: http://www.twitter.com/domasofan/
E-Mail: simon.eigeldinger@vol.at
MSN: simon_eigeldinger@hotmail.com
ICQ: 121823966
Jabber: domasofan@andrelouis.com
 Hi,

yeah its icui18n.
there seem to be 2 versions.
5.4 and 5.5.

greetings,
simon

Am 24.07.2015 um 01:07 schrieb Jim Regan:

> Sorry, it only complained about one of the ICU libraries.
> 
> I think that the problem is that the library is named 'libicui18n' under Cygwin, as it is on Linux etc.
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/tesseract-ocr/tesseract/issues/61#issuecomment-124262453

## 

Simon Eigeldinger
Follow me on Twitter: http://www.twitter.com/domasofan/
E-Mail: simon.eigeldinger@vol.at
MSN: simon_eigeldinger@hotmail.com
ICQ: 121823966
Jabber: domasofan@andrelouis.com
 Hi,

i guess that looks good now.

we have:
ambiguous_words.exe
classifier_tester.exe
cntraining.exe
combine_tessdata.exe
dawg2wordlist.exe
mftraining.exe
set_unicharset_properties.exe
shapeclustering.exe
tesseract.exe
text2image.exe
unicharset_extractor.exe
wordlist2dawg.exe

thanks.
greetings,
simon

Am 24.07.2015 um 01:18 schrieb Jim Regan:

> Can you try with the patch from #62 ?
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/tesseract-ocr/tesseract/issues/61#issuecomment-124264086

## 

Simon Eigeldinger
Follow me on Twitter: http://www.twitter.com/domasofan/
E-Mail: simon.eigeldinger@vol.at
MSN: simon_eigeldinger@hotmail.com
ICQ: 121823966
Jabber: domasofan@andrelouis.com
 thanks.
thanks for fixing. :-)

Am 24.07.2015 um 08:45 schrieb Jim Regan:

> Ok, I'll close this. Thanks for testing!
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/tesseract-ocr/tesseract/issues/61#issuecomment-124357848

## 

Simon Eigeldinger
Follow me on Twitter: http://www.twitter.com/domasofan/
E-Mail: simon.eigeldinger@vol.at
MSN: simon_eigeldinger@hotmail.com
ICQ: 121823966
Jabber: domasofan@andrelouis.com
  the solution is wrong. As strcasestr is not standard,  it is enough to

#define _GNU_SOURCE
before 
#include <string.h>
  https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-dev/XllxjvK5HtU/C4mebS6lcJoJ

Jeff suggested that users create a myconfig file. I think it will be useful to actually provide the configuration as 'pdftxt' .
# 

tessedit_create_txt 1
tessedit_create_pdf 1
# 

Then make sure that you invoke the command line such that 
Tesseract writes to files instead of stdout, e.g. 

```
tesseract myimage.tif myoutput pdftxt
```

This will read myimage.tif and pdftxt (config file), and produce myoutput.pdf and myoutput.txt
 Zdenko also has same opinion. So you can close the issue.

I'll add to FAQ if that is ok.
- sent from my phone. excuse the brevity.
  On 22 Jul 2015 19:34, "Jim Regan" notifications@github.com wrote:

> Not generally useful, IMO - I don't see there being a whole lot of demand
> for this.
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/59#issuecomment-123733447
> .
  i have success install tesseract , 
tesseract 3.02.02
 leptonica-1.71
  libjpeg 6b : libpng 1.2.49 : zlib 1.2.8

and my libtiff locate in /usr/lib64
locate libtiff
/usr/lib64/libtiff.so.3
/usr/lib64/libtiff.so.3.9.4
/usr/lib64/libtiffxx.so.3
/usr/lib64/libtiffxx.so.3.9.4

so i add  ~/.bash_profile  with
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib:/usr/lib64 
and relogin.

but the error still there:  
Tesseract Open Source OCR Engine v3.02.02 with Leptonica
Error in findTiffCompression: function not present
Error in pixReadStreamTiff: function not present
Error in pixReadStream: tiff: no pix returned
Error in pixRead: pix not read
Unsupported image type.

how i solve it ? thx alot
 i have tried leptonica-1.71/1.72 ,  both have same error.
should i use early leptonica ,   which version of leptonica  is compatible Ôºü
thx
  I have no idea what the box.train config is supposed to do, or what 
missing data it needs. I just don't like segfaults.

```
(gdb) run testing/phototest.tif - box.train
Starting program: /tmp/plang/tesseract-3.04.00/api/.libs/lt-tesseract testing/phototest.tif - box.train
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Page 1

Program received signal SIGSEGV, Segmentation fault.
0x00007ffff760fe94 in ELIST_ITERATOR::set_to_list (this=0x7fffffffd3e0, list_to_iterate=0x8) at ../ccutil/elst.h:308
308   prev = list->last;
(gdb) backtrace
#0  0x00007ffff760fe94 in ELIST_ITERATOR::set_to_list (this=0x7fffffffd3e0, list_to_iterate=0x8)
    at ../ccutil/elst.h:308
#1  0x00007ffff77dd367 in PAGE_RES_IT::start_page (this=0x7fffffffd390, empty_ok=false) at pageres.cpp:1510
#2  0x00007ffff76116c7 in PAGE_RES_IT::restart_page (this=0x7fffffffd390) at ../ccstruct/pageres.h:681
#3  0x00007ffff76116a7 in PAGE_RES_IT::PAGE_RES_IT (this=0x7fffffffd390, the_page_res=0x0) at ../ccstruct/pageres.h:665
#4  0x00007ffff761e84f in tesseract::Tesseract::ApplyBoxTraining (this=0x808c00, fontname=..., page_res=0x0)
    at applybox.cpp:780
#5  0x00007ffff7609478 in tesseract::TessBaseAPI::Recognize (this=0x7fffffffd9f0, monitor=0x0) at baseapi.cpp:883
#6  0x00007ffff760a4d9 in tesseract::TessBaseAPI::ProcessPage (this=0x7fffffffd9f0, pix=0x83fa10, page_index=0, 
    filename=0x7fffffffe883 "testing/phototest.tif", retry_config=0x0, timeout_millisec=0, renderer=0x13850f0)
    at baseapi.cpp:1222
#7  0x00007ffff7609d4e in tesseract::TessBaseAPI::ProcessPagesMultipageTiff (this=0x7fffffffd9f0, 
    data=0x138fc08 "II*", size=38668, filename=0x7fffffffe883 "testing/phototest.tif", retry_config=0x0, 
    timeout_millisec=0, renderer=0x13850f0, tessedit_page_number=-1) at baseapi.cpp:1057
#8  0x00007ffff760a29b in tesseract::TessBaseAPI::ProcessPagesInternal (this=0x7fffffffd9f0, 
    filename=0x7fffffffe883 "testing/phototest.tif", retry_config=0x0, timeout_millisec=0, renderer=0x13850f0)
    at baseapi.cpp:1176
#9  0x00007ffff7609dc5 in tesseract::TessBaseAPI::ProcessPages (this=0x7fffffffd9f0, 
    filename=0x7fffffffe883 "testing/phototest.tif", retry_config=0x0, timeout_millisec=0, renderer=0x13850f0)
    at baseapi.cpp:1074
#10 0x00000000004031a3 in main (argc=4, argv=0x7fffffffe5f8) at tesseractmain.cpp:316
...
```
 Tesseract should return an error when there is insufficient input, not segfault.
 Pretty good! But even more robust is to locate the lower level function that is crashing
due to bad data. Then modify it to return an error instead of crashing. That protects us 
even if it gets called from a different code path.
 ```
TESSDATA_PREFIX=/usr/share/tesseract-ocr  valgrind api/.libs/lt-tesseract testing/phototest.tif testing/phototest.tif - box.train
==11666== Memcheck, a memory error detector
==11666== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al.
==11666== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info
==11666== Command: api/.libs/lt-tesseract testing/phototest.tif testing/phototest.tif - box.train
==11666== 
Tesseract Open Source OCR Engine v3.05.00dev-11-gd937659 with Leptonica
Page 1
==11666== Invalid read of size 8
==11666==    at 0x4FA8E9C: ELIST_ITERATOR::set_to_list(ELIST*) (elst.h:308)
==11666==    by 0x514C108: PAGE_RES_IT::start_page(bool) (pageres.cpp:1510)
==11666==    by 0x4FAA6CE: PAGE_RES_IT::restart_page() (pageres.h:681)
==11666==    by 0x4FAA6AE: PAGE_RES_IT::PAGE_RES_IT(PAGE_RES*) (pageres.h:665)
==11666==    by 0x4FB781E: tesseract::Tesseract::ApplyBoxTraining(STRING const&, PAGE_RES*) (applybox.cpp:797)
==11666==    by 0x4FA2477: tesseract::TessBaseAPI::Recognize(ETEXT_DESC*) (baseapi.cpp:883)
==11666==    by 0x4FA34D8: tesseract::TessBaseAPI::ProcessPage(Pix*, int, char const*, char const*, int, tesseract::TessResultRenderer*) (baseapi.cpp:1222)
==11666==    by 0x4FA2D4D: tesseract::TessBaseAPI::ProcessPagesMultipageTiff(unsigned char const*, unsigned long, char const*, char const*, int, tesseract::TessResultRenderer*, int) (baseapi.cpp:1057)
==11666==    by 0x4FA329A: tesseract::TessBaseAPI::ProcessPagesInternal(char const*, char const*, int, tesseract::TessResultRenderer*) (baseapi.cpp:1176)
==11666==    by 0x4FA2DC4: tesseract::TessBaseAPI::ProcessPages(char const*, char const*, int, tesseract::TessResultRenderer*) (baseapi.cpp:1074)
==11666==    by 0x403192: main (tesseractmain.cpp:318)
==11666==  Address 0x8 is not stack'd, malloc'd or (recently) free'd
==11666== 
==11666== 
==11666== Process terminating with default action of signal 11 (SIGSEGV)
==11666==  Access not within mapped region at address 0x8
==11666==    at 0x4FA8E9C: ELIST_ITERATOR::set_to_list(ELIST*) (elst.h:308)
==11666==    by 0x514C108: PAGE_RES_IT::start_page(bool) (pageres.cpp:1510)
==11666==    by 0x4FAA6CE: PAGE_RES_IT::restart_page() (pageres.h:681)
==11666==    by 0x4FAA6AE: PAGE_RES_IT::PAGE_RES_IT(PAGE_RES*) (pageres.h:665)
==11666==    by 0x4FB781E: tesseract::Tesseract::ApplyBoxTraining(STRING const&, PAGE_RES*) (applybox.cpp:797)
==11666==    by 0x4FA2477: tesseract::TessBaseAPI::Recognize(ETEXT_DESC*) (baseapi.cpp:883)
==11666==    by 0x4FA34D8: tesseract::TessBaseAPI::ProcessPage(Pix*, int, char const*, char const*, int, tesseract::TessResultRenderer*) (baseapi.cpp:1222)
==11666==    by 0x4FA2D4D: tesseract::TessBaseAPI::ProcessPagesMultipageTiff(unsigned char const*, unsigned long, char const*, char const*, int, tesseract::TessResultRenderer*, int) (baseapi.cpp:1057)
==11666==    by 0x4FA329A: tesseract::TessBaseAPI::ProcessPagesInternal(char const*, char const*, int, tesseract::TessResultRenderer*) (baseapi.cpp:1176)
==11666==    by 0x4FA2DC4: tesseract::TessBaseAPI::ProcessPages(char const*, char const*, int, tesseract::TessResultRenderer*) (baseapi.cpp:1074)
==11666==    by 0x403192: main (tesseractmain.cpp:318)
```
 make
make install
gdb /usr/local/bin/tesseract
(gdb) run testing/phototest.tif - box.train

```
Program received signal SIGSEGV, Segmentation fault.
PAGE_RES_IT::start_page (this=this@entry=0x7fffffffde10, empty_ok=empty_ok@entry=false) at pageres.cpp:1510
1510      block_res_it.set_to_list(&page_res->block_res_list);
(gdb) backtrace
#0  PAGE_RES_IT::start_page (this=this@entry=0x7fffffffde10, empty_ok=empty_ok@entry=false) at pageres.cpp:1510
#1  0x00007ffff76e6f29 in restart_page (this=0x7fffffffde10) at ../ccstruct/pageres.h:681
#2  PAGE_RES_IT (the_page_res=<optimized out>, this=0x7fffffffde10) at ../ccstruct/pageres.h:665
#3  tesseract::Tesseract::ApplyBoxTraining (this=0x819810, fontname=..., page_res=<optimized out>) at applybox.cpp:797
#4  0x00007ffff76dd926 in tesseract::TessBaseAPI::Recognize (this=this@entry=0x7fffffffe450, monitor=monitor@entry=0x0) at baseapi.cpp:883
#5  0x00007ffff76ddc2a in tesseract::TessBaseAPI::ProcessPage (this=0x7fffffffe450, pix=0x84fd10, page_index=<optimized out>, filename=<optimized out>, 
    retry_config=0x0, timeout_millisec=0, renderer=0x0) at baseapi.cpp:1224
#6  0x00007ffff76de10b in tesseract::TessBaseAPI::ProcessPagesMultipageTiff (this=0x7fffffffe450, data=0x0, data@entry=0x13a0828 "II*", size=8, filename=0x0, 
    filename@entry=0x7fffffffe85a "testing/phototest.tif", retry_config=retry_config@entry=0x0, timeout_millisec=20909344, timeout_millisec@entry=0, 
    renderer=0x0, tessedit_page_number=-1) at baseapi.cpp:1057
#7  0x00007ffff76de5fe in tesseract::TessBaseAPI::ProcessPagesInternal (this=this@entry=0x7fffffffe450, filename=<optimized out>, 
    retry_config=retry_config@entry=0x0, timeout_millisec=timeout_millisec@entry=0, renderer=0x0) at baseapi.cpp:1176
#8  0x00007ffff76dea40 in tesseract::TessBaseAPI::ProcessPages (this=this@entry=0x7fffffffe450, filename=<optimized out>, 
    retry_config=retry_config@entry=0x0, timeout_millisec=timeout_millisec@entry=0, renderer=<optimized out>) at baseapi.cpp:1074
#9  0x0000000000401dff in main (argc=<optimized out>, argv=0x7fffffffe5e8) at tesseractmain.cpp:432
```
 I'd suggest something like this. I didn't check to see if we leak memory
if we go down this error path, but no matter what it is better than a segfault.

``` diff
--- baseapi.cpp.orig    2016-02-04 01:09:07.790101916 +0000
+++ baseapi.cpp 2016-02-04 01:07:15.464620603 +0000
@@ -851,6 +851,9 @@
     page_res_ = new PAGE_RES(false,
                              block_list_, &tesseract_->prev_word_best_choice_);
   }
+  if (page_res_ == NULL) {
+    return -1;
+  }
   if (tesseract_->tessedit_make_boxes_from_boxes) {
     tesseract_->CorrectClassifyWords(page_res_);
     return 0;
```
  Hardware is a Ubuntu 14.04 laptop with integrated Intel graphics.

```
./configure --enable-opencl --enable-debug
...
gdb api/.libs/lt-tesseract

(gdb) run testing/phototest.tif -

Starting program: api/.libs/lt-tesseract testing/phototest.tif -
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performing profiling.

Program received signal SIGSEGV, Segmentation fault.
strlen () at ../sysdeps/x86_64/strlen.S:106
106 ../sysdeps/x86_64/strlen.S: No such file or directory.
(gdb) backtrace
#0  strlen () at ../sysdeps/x86_64/strlen.S:106
#1  0x00007ffff77fe549 in writeProfileToFile (profile=0x81c810, 
    serializer=0x7ffff780752f <serializeScore(ds_device*, void**, unsigned int*)>, file=0x7ffff78aa5e0 "tesseract_opencl_profile_devices.dat")
    at opencl_device_selection.h:268
#2  0x00007ffff7807a09 in OpenclDevice::getDeviceSelection ()
    at openclwrapper.cpp:3427
#3  0x00007ffff7800356 in OpenclDevice::InitOpenclRunEnv_DeviceSelection (
    argc=0) at openclwrapper.cpp:527
#4  0x00007ffff7800074 in OpenclDevice::InitEnv () at openclwrapper.cpp:431
#5  0x00007ffff75f01af in tesseract::TessBaseAPI::Init (this=0x7fffffffda40, 
    datapath=0x0, language=0x405a13 "eng", oem=tesseract::OEM_DEFAULT, 
    configs=0x7fffffffe6a0, configs_size=0, vars_vec=0x7fffffffda00, 
    vars_values=0x7fffffffda20, set_only_non_debug_params=false)
    at baseapi.cpp:299
#6  0x0000000000404317 in main (argc=3, argv=0x7fffffffe688)
    at tesseractmain.cpp:181
...
```
 Ray says,

I think there is a bug in InitDSProfile.

I suspect if you change if (status == SUCCESS) to if (status == SUCCESS && profile->numDevices > 0)
at openclwrapper.cpp:3426
then it will work. (You have no devices, and unlike the code here: https://docs.libreoffice.org/opencl/html/opencl__device__selection_8h_source.html
it doesn't correctly always add the native CPU as a device, and therefore attempts to write a null buffer, even though it has no devices.)
 still trouble
 note that if we get through this, I will probably enable OpenCL by default for Debian/Ubuntu
 I'm in stuck. How this code (located at oclkernels.h:1086) can work:

```
pixels.v[i] = imageData[
    w*(BURSTS_PER_WORD*(PIXELS_PER_BURST*NUM_CHANNELS)/CHAR_VEC_WIDTH) + 
    b*((PIXELS_PER_BURST*NUM_CHANNELS)/CHAR_VEC_WIDTH)  + i];
```

where maximum value of index can be 4x higher that size of imageData array
Variables are:
w in range [0 .. count of DWORDS in image), 
b in range [0 .. BURSTS_PER_WORD),
i in range [0 .. (PIXELS_PER_BURST*NUM_CHANNELS)/CHAR_VEC_WIDTH )
Constants values:

```
#define NUM_CHANNELS 4
#define CHAR_VEC_WIDTH 8
#define PIXELS_PER_WORD 32
#define PIXELS_PER_BURST 8
#define BURSTS_PER_WORD (PIXELS_PER_WORD/PIXELS_PER_BURST)
```
 I get a similar looking segfault (but I didn't confirm with gdb) even on a computer that contains a discrete graphics card. Is OpenCL working for anyone at all?
 I can't get fully worked OpenCL configuration. But I have a much different environment (without any other dependencies except leptonica). I've got errors like:
`Access violation reading location 0x58B87000`
That's a position after imageData host's buffer. 
 Just made a bit changes to exclude libtiff dependency.
I have my own input and output streams.
I see, that I can't request any attention without prepare reproducible error in your environment.
 spSerg: you can request attention, but if we can't reproduce you need to supply more information, such as a backtrace from gdb or the output of valgrind (either works much better when ./configure is run with --enable-debug)
 I'm having an unexpectedly hard time with this.
 ```
#0  strlen () at ../sysdeps/x86_64/strlen.S:106
#1  0x00007ffff77d3c5f in writeProfileToFile (profile=0x80ac20, 
    serializer=0x7ffff77dcc45 <serializeScore(ds_device*, void**, unsigned int*)>, 
    file=0x7ffff78a0b20 "tesseract_opencl_profile_devices.dat") at opencl_device_selection.h:268
#2  0x00007ffff77dd11f in OpenclDevice::getDeviceSelection () at openclwrapper.cpp:3427
#3  0x00007ffff77d5a6c in OpenclDevice::InitOpenclRunEnv_DeviceSelection (argc=0) at openclwrapper.cpp:527
#4  0x00007ffff77d578a in OpenclDevice::InitEnv () at openclwrapper.cpp:431
#5  0x00007ffff75efb2f in tesseract::TessBaseAPI::Init (this=0x7fffffffd9f0, datapath=0x0, 
    language=0x405a13 "eng", oem=tesseract::OEM_DEFAULT, configs=0x7fffffffe650, configs_size=0, 
    vars_vec=0x7fffffffd9b0, vars_values=0x7fffffffd9d0, set_only_non_debug_params=false) at baseapi.cpp:299
#6  0x0000000000404327 in main (argc=3, argv=0x7fffffffe638) at tesseractmain.cpp:181
```
  hi Team ,
      we can't able to figure it out ,why we are getting this below error while linking. but, it compiles fine.;

version's : tesseract304 , leptonica-1.72, liblept168d.lib + other libs (got it from leptonica-1.68-win32-lib-include-dirs.zip ), visual studio 2010.

plz help us to resolve this issue..plz...

Error details :-
Error   1   error LNK2019: unresolved external symbol __imp__l_CIDataDestroy referenced in function "private: static bool __cdecl tesseract::TessPDFRenderer::imageToPDFObj(struct Pix *,char *,long,char \* *,long *)" (?imageToPDFObj@TessPDFRenderer@tesseract@@CA_NPAUPix@@PADJPAPADPAJ@Z)   D:\tesseract-master\vs2010\libtesseract\pdfrenderer.obj libtesseract304
Error   2   error LNK2019: unresolved external symbol __imp__l_generateCIDataForPdf referenced in function "private: static bool __cdecl tesseract::TessPDFRenderer::imageToPDFObj(struct Pix *,char *,long,char \* *,long *)" (?imageToPDFObj@TessPDFRenderer@tesseract@@CA_NPAUPix@@PADJPAPADPAJ@Z)    D:\tesseract-master\vs2010\libtesseract\pdfrenderer.obj libtesseract304
Error   3   error LNK2019: unresolved external symbol __imp__pixGenerateCIData referenced in function "private: static bool __cdecl tesseract::TessPDFRenderer::imageToPDFObj(struct Pix *,char *,long,char \* *,long *)" (?imageToPDFObj@TessPDFRenderer@tesseract@@CA_NPAUPix@@PADJPAPADPAJ@Z) D:\tesseract-master\vs2010\libtesseract\pdfrenderer.obj libtesseract304
Error   4   error LNK2019: unresolved external symbol __imp__pixSetSpp referenced in function "private: static bool __cdecl tesseract::TessPDFRenderer::imageToPDFObj(struct Pix *,char *,long,char \* *,long *)" (?imageToPDFObj@TessPDFRenderer@tesseract@@CA_NPAUPix@@PADJPAPADPAJ@Z) D:\tesseract-master\vs2010\libtesseract\pdfrenderer.obj libtesseract304
Error   5   error LNK2019: unresolved external symbol __imp__pixGetSpp referenced in function "private: static bool __cdecl tesseract::TessPDFRenderer::imageToPDFObj(struct Pix *,char *,long,char \* *,long *)" (?imageToPDFObj@TessPDFRenderer@tesseract@@CA_NPAUPix@@PADJPAPADPAJ@Z) D:\tesseract-master\vs2010\libtesseract\pdfrenderer.obj libtesseract304
Error   6   error LNK2019: unresolved external symbol __imp__pixForegroundFraction referenced in function "protected: float __thiscall tesseract::EquationDetect::ComputeForegroundDensity(class TBOX const &)" (?ComputeForegroundDensity@EquationDetect@tesseract@@IAEMABVTBOX@@@Z)   D:\tesseract-master\vs2010\libtesseract\equationdetect.obj  libtesseract304
Error   7   error LNK2019: unresolved external symbol __imp__pixaConvertToPdf referenced in function "public: static void __cdecl tesseract::LineFinder::FindAndRemoveLines(int,bool,struct Pix *,int *,int *,struct Pix \* *,class tesseract::TabVector_LIST *,class tesseract::TabVector_LIST *)" (?FindAndRemoveLines@LineFinder@tesseract@@SAXH_NPAUPix@@PAH2PAPAU3@PAVTabVector_LIST@2@4@Z) D:\tesseract-master\vs2010\libtesseract\linefind.obj    libtesseract304
Error   8   error LNK1120: 7 unresolved externals   D:\tesseract-master\vs2010\DLL_Debug\libtesseract304d.dll   libtesseract304
  The file itself already contained a reference to the new name.
 Oops.

Do you want me to teach automake not to require existence of README;
or just fix the URL in the file?
  Hi, every one

I cross compile the static library of tesseract and iam getting this error when build:

![captura de pantalla de 2015-07-10 09 42 35](https://cloud.githubusercontent.com/assets/4372141/8620905/40bf6540-26e8-11e5-8e62-705e0081e02c.png)

anyone know what is the problem?

Thanks in advance, regards.
  At least as a template parameter.

``` cpp
  GenericVector<UnicharRating>
```
 It's another fix of https://github.com/tesseract-ocr/tesseract/commit/cdc84a5dd79b20beae9dd0a2400211630f361916
 Something like this:
<code>
OCRLib.Win32.lib(adaptmatch.obj) : error LNK2001: unresolved external symbol "public: virtual int __thiscall tesseract::ShapeClassifier::UnicharClassifySample(class tesseract::TrainingSample const &,struct Pix ,int,int,class GenericVector&lt;class tesseract::UnicharRating&gt; )" (?UnicharClassifySample@ShapeClassifier@tesseract@@UAEHABVTrainingSample@2@PAUPix@@HHPAV?$GenericVector@VUnicharRating@tesseract@@@@@Z)
</code>
or this:
<code>
OCRLib.Win32.lib(tessclassifier.obj) : error LNK2019: unresolved external symbol "public: int thiscall tesseract::Classify::CharNormTrainingSample(bool,int,class tesseract::TrainingSample const &,class GenericVector&lt;struct tesseract::UnicharRating&gt; *)" (?CharNormTrainingSample@Classify@tesseract@@QAEH_NHABVTrainingSample@2@PAV?$GenericVector@UUnicharRating@tesseract@@@@@Z) referenced in function "public: virtual int thiscall tesseract::TessClassifier::UnicharClassifySample(class tesseract::TrainingSample const &,struct Pix ,int,int,class GenericVector&lt;struct tesseract::UnicharRating&gt; )" (?UnicharClassifySample@TessClassifier@tesseract@@UAEHABVTrainingSample@2@PAUPix@@HHPAV?$GenericVector@UUnicharRating@tesseract@@@@@Z)
</code>
 <code>UnicharRating</code> is a structure. But such forward declaration as a class will confuse MS compiler in parameter of template.
  I'm trying to reproduce results achieved at the ICDAR page segmentation competitions [1,2] with tesseract. I'm struggling to get the tool to output the hOCR tags that I'm expecting for tables and figures etc [3]. At the moment I'm calling tesseract with pagesegmode 1. Should I be adding other options via a config file to achieve the full extent of tesseracts segmentation and labelling ability (I'm not interested in the character recognition element as much).
1. Antonacopoulos (2013, ICDAR) ICDAR2013 Competition on Historical Book Recognition ‚Äì HBR2013
2. Antonacopoulos (2013, ICDAR) ICDAR2013 Competition on Historical Newspaper Layout Analysis ‚Äì HNLA2013
3. Breuel (2010) The hOCR Embedded OCR Workflow and Output Format
 You can use the C-API to only retrieve the page segmentation without doing character recognition. Use TessBaseAPISetPageSegMode to set the segmentation mode, call TessBaseAPIProcessPages, and finally retrieve the page iterator using TessBaseAPIAnalyseLayout. Iterate using the TessPageIteratorNext function at the lowest level and check with TessPageIteratorIsAtBeginningOf if the current symbol is at the start of a new block. All in all it shouldn't be more than a few lines of C code and you're skipping the recognition part of tesseract completely.
 @zdenop thank's for clarifying. Here is the link to my forum post (which contains another answer): https://groups.google.com/forum/#!topic/tesseract-ocr/1Frh-5ggNxg
 @jimregan Cheers! I'm reproducing your answer on the linked forum page (the preferred help location).
  The same issue is reported in https://code.google.com/p/tesseract-ocr/issues/detail?can=2&start=0&num=100&q=&colspec=ID%20Type%20Status%20Priority%20Milestone%20Owner%20Summary&groupby=&sort=&id=1307

But the problem is still exists and the ticket is closed.

I got the error during compiling.

The error is:
libtool: link: g++ -std=c++11 -o .libs/tesseract tesseract-tesseractmain.o  ./.libs/libtesseract.so -lrt -llept -lpthread
 ./.libs/libtesseract.so: undefined reference to `l_generateCIDataForPdf'
 ./.libs/libtesseract.so: undefined reference to`l_CIDataDestroy'

---

tesseract -v
tesseract 3.03
 leptonica-1.72
##   libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

And here is the deb package I installed:
      "autoconf",
      "automake",
      "libtool",
      "libpng12-dev",
      "libjpeg-turbo8-dev",
      "g++",
      "libtiff5-dev",
      "libopencv-dev",
      "libopencv-objdetect-dev",
      "libopencv-highgui-dev",
      "libopencv-legacy-dev",
      "libopencv-contrib-dev",
      "libopencv-videostab-dev",
      "libopencv-superres-dev",
      "libopencv-ocl-dev",
      "libcv-dev",
      "libhighgui-dev",
      "libcvaux-dev",
      "libtesseract-dev",
      "git",
      "cmake",
      "build-essential",
      "libleptonica-dev",
      "liblog4cplus-dev",
      "libcurl3-dev",
      "python2.7-dev",
      "tk8.5",
      "tcl8.5",
      "tk8.5-dev",
      "tcl8.5-dev",
      "imagemagick"

I basically follow the instruction in https://realpython.com/blog/python/setting-up-a-simple-ocr-server/

Please help. Thanks.
 Thanks for you quick response. My bad, I assume the lib will be ready after configure. Anyway, for the future reference, since we have to compile leptonica in ubuntu 14.04, we should use `LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make` instead of make.

Then the problem will be resolved.

Thanks.
 Hi,
I am using tesseract-3.04.00 and for leptonica i tried both with 1.72 & 1.71.Still i get the below mentioned issue:-
./.libs/libtesseract.so: undefined reference to `l_generateCIDataForPdf'
./.libs/libtesseract.so: undefined reference to`l_CIDataDestroy'

Request help on this.
 Sorry for the inconvenience.Was able to resolve the issue.Thanks.
 How did you resolve it?
 Yes, how did you solve it @Sayanava ?
 I removed previous 3.03 and re-install 3.04 from scratch. It works.   What steps will reproduce the problem?
1. Try to recognize the attached image with Cube mode. Whitelist is '0123456789'. The result is wrong. It's 1234669890 (6 instead of 5, 9 instead of 7).
2. Try to recognize the same image with Combined mode. There is a crach with the following error:
init_cube_objects(true, &tessdata_manager):Error:Assert failed:in file tessedit.cpp, line 203
[1]    5562 abort      tesseract image_sample.jpg stdout -l rus rus-test
It seems that it happens with eng locale as well as with the rus loc.

What is the expected output? What do you see instead?
In both cases the output should be 1234567890.

What version of the product are you using? On what operating system?
I've tried tesseract 3.03 both on mac and iOS.

Please provide any additional information below.
There is a related thread in the Tesseract-OCR-iOS wrapper, where the issue was originally found: https://github.com/gali8/Tesseract-OCR-iOS/issues/140. You may ask for any additional info there.

![image_sample](https://cloud.githubusercontent.com/assets/462439/8406256/45b02176-1e63-11e5-9157-4084f9b32ddd.jpg)
 @zdenop Since Cube is going away, perhaps this can be closed?
 How Cube is being discontinued, it's training procedure has not been published to the public.
Somehow I got the feeling that Cube was purposely sabotaged and hindered from the public.  
 The new LSTM based engine is here.

@theraysmith, I see that the Cube engine is still present in the code. Are you going to drop it in the final 4.0 release? @theraysmith

Since the hardware requirements for 4.0 are going to be higher than for 3.xx versions, it will be good to keep Hindi cube+tesseract version also available. 

The accuracy results that you are mentioning for Hindi are for which version - 3.02, 3.03, 3.04 ?   And what about the language model used for the test? Is it already available so I can use it for my own tests? > I'm going to push the data files now.

Got the first ones. My first test with a simple screenshot gave significant better results with LSTM, but needed 16 minutes CPU time (instead of 9 seconds) with a debug build of Tesseract (-O0). A release build (-O2) needs 17 seconds with LSTM, 4 seconds without for the same image.

Are there also new data files planned for old German (deu_frak)? I was surprised that the default English model with LSTM could recognize some words.  1. Is there a 3.04 vs 4.0 branch in tessdata for the traineddata files?

2. Stefan, please share the binaries for 4.0 alpha for Windows. I am
interested in trying the hindi and other indian languages traineddata.
Thanks.

On 29-Nov-2016 5:18 AM, "theraysmith" <notifications@github.com> wrote:

> On Mon, Nov 28, 2016 at 1:49 PM, Stefan Weil <notifications@github.com>
> wrote:
>
> > I'm going to push the data files now.
> >
> > Got the first ones. My first test with a simple screenshot gave
> > significant better results with LSTM, but needed 16 minutes CPU time
> > (instead of 9 seconds) with a debug build of Tesseract (-O0). A release
> > build (-O2) needs 17 seconds with LSTM, 4 seconds without for the same
> > image.
> >
> The slow speed with debug is to be expected. The new code is much more
> memory intensive, so it is a lot slower on debug (also openmp is turned off
> by choice on debug).
> The optimized build speed sounds about right for Latin-based languages. It
> is the complex scripts that will run faster relative to base Tesseract.
>
> > Are there also new data files planned for old German (deu_frak)? I was
> > surprised that the default English model with LSTM could recognize some
> > words.
> >
> I don't think I generated the original deu_frak. I have the fonts to do so
> with LSTM, but I don't know if I have a decent amount of corpus data to
> hand. With English at least, the language was different in the days of
> Fraktur (Ye Olde shoppe). I know German continued to be written in Fraktur
> until the 1940s, so that might be easier. Or is there an old German that is
> analogous to Ye Old Shoppe for English?
>
> > ‚Äî
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/40#
> issuecomment-263405208>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AL056Ti1gWSSG6BfuBbL68EE7RYfsItOks5rC0xWgaJpZM4FOBFi>
> > .
> >
>
>
>
> --
> Ray.
>
> ‚Äî
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/40#issuecomment-263432042>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_ox9UBjscGCZrZM-bSZ-Eimw91bkXks5rC2g5gaJpZM4FOBFi>
> .
>
 > I know German continued to be written in Fraktur until the 1940s, so that might be easier. Or is there an old German that is analogous to Ye Old Shoppe for English?

Fraktur was used for an important German newspaper ([Reichsanzeiger](http://digi.bib.uni-mannheim.de/periodika/1/imperial-gazette/)) until 1945. I'd like to try some pages from that newspaper with Tesseract LSTM. Surprisingly even with the English data Tesseract was able to recognize at least some words written in Fraktur. Could you give me some hints how to create the data for `deu_frak`?

There is an Old High German (similar to Old English), but the German translation of the New Testament by Martin Luther (1521) was one of the first major printed books in German, and basically it started the modern German language (High German) which is used until today. > Stefan, please share the binaries for 4.0 alpha for Windows.

@Shreeshrii, they are online now at the usual location. See also the related pull request #511. Please report results either in the developer forum as suggested by @zdenop or by personal mail to me. >Is there a 3.04 vs 4.0 branch in tessdata for the traineddata files?

https://github.com/tesseract-ocr/tessdata/tree/3.04.00
 Thanks, Amit. Please add the info to the wiki also, if you have not already
done so.

On 29-Nov-2016 7:31 PM, "Amit D." <notifications@github.com> wrote:

> Is there a 3.04 vs 4.0 branch in tessdata for the traineddata files?
>
> https://github.com/tesseract-ocr/tessdata/tree/3.04.00
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/40#issuecomment-263577206>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o3a5AJ3je8sWymCBCFk_0jhhM1d9ks5rDDAegaJpZM4FOBFi>
> .
>
 Thanks, I will give it a try and report back.

On 29-Nov-2016 7:30 PM, "Stefan Weil" <notifications@github.com> wrote:

> Stefan, please share the binaries for 4.0 alpha for Windows.
>
> @Shreeshrii <https://github.com/Shreeshrii>, they are online now at the
> usual location. Please report results either in the developer forum as
> suggested by @zdenop <https://github.com/zdenop> or by personal mail to
> me.
>
> ‚Äî
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/40#issuecomment-263577080>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o5J0hvvS7W2el0QDzXNO957qHvumks5rDDABgaJpZM4FOBFi>
> .
>
 >Amit. Please add the info to the wiki also, if you have not already done so.

You can do it yourself... :) @theraysmith @stweil 

Thank you! I tested a few devanagari pages with the 4.0 alpha windows binaries and traineddata for Hindi, Sanskrit, Marathi and Nepali. This was on a Windows 10 netbook, intel atom 1.33 ghz cpu, x64 based processor, 32 bit os, 2 GB RAM. I tested only with single page images and there was no performance problem on this basic netbook. The accuracy is much improved in the LSTM version. This is by just eyeballing the output (not using any software for comparison). 

From a user point of view, better accuracy maybe preferred to speed. So LSTM based engine seems the way to go, at least for devanagari scripts. I will test some of the other Indian languages later.

I have noticed some differences in processing between Hindi and the other Devanagari based languages and will add issues to the tessdata repository.

Thanks to the developers at Google and the tesseract community!



 @theraysmith 
> I don't think I generated the original deu_frak. I have the fonts to do so with LSTM, but I don't know if I have a decent amount of corpus data to hand. 

I have a decent amount of corpus data for Fraktur from scanned books at hand, about 500k lines in hOCR files (~50GB with TIF images). I've yet to publish it, but if you have somewhere where I could send/upload it, I'd be glad to.

Or is there a way to create the neccessary training files myself? I've had a cursory look through the OCR code and it looked like it needed `lstmf` files, but I haven't yet found what these are supposed to look like. >  500k lines should make it work really well. I would be happy to take it and help you, but we would have to get into licenses, copyright and all that first.

The text is CC0 and the images are CC-BY-NC, so that shouldn't be an issue :-) They're going to be public anyway once I've prepped the dataset for publication.
But even better if there are instructions, looking forward to playing around with training! Ray,

Please see my recent comment and attached files in
https://github.com/tesseract-ocr/tessdata/issues/6

Adding config files to trained data for san, mar and nep will fix this
issue related to skipped text with default psm.

I made a copy of hin.config and changed the default engine to oem 4, LSTM.
I also removed the blacklisting of 1, since Indo-arabic numbers in Latin
scripts are used quite commonly with Devanagari script text.

There are various other Devanagari related options in the config file,
which can be removed, if not needed with LSTM.

Thanks.
 Sad news: Cube is no longer with us.

Cube, you will be missed...

 @jbaiter have you tried 4.0 training for Fraktur?

@theraysmith Is there a way to use the old box-tiff pairs at https://github.com/paalberti/tesseract-dan-fraktur for LSTM training?

Also see tesseract related issue at https://github.com/paalberti/tesseract-dan-fraktur/issues/3

 >Is there a way to use the old box-tiff pairs at https://github.com/paalberti/tesseract-dan-fraktur for LSTM training?

There will be a way to generate a box file from a tiff image. The box file will be written in the [textline format](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#box-file-fornat---second-option)
https://github.com/tesseract-ocr/tesseract/issues/659#issuecomment-272564420
I started working on this today. I wrote the needed code and It seems to output the desired format, but I need to do some tests before publishing it. 
 @amitdo Not sure if that will work for Devanagari, because of the length of unicode string.

Is it possible to just add a box with  the tab character at end of each line for existing box files? >Not sure if that will work for Devanagari, because of the length of unicode string.

We will wait and see...

>Is it possible to just add a box with the tab character at end of each line for existing box files?

You mean manually?
You should add box coordinates, not just tab.    cntraining clusterer's are deleted, the last one is saved and used during final write, it seems. However there are still leaks with the protolists.. we still store the old protolists in the NormProtoList. This needs to be fixed somehow. 

mftraining memory leaks are fixed.
  I have updated the pkgbuild for tesseract-ocr for msys2 - please see https://github.com/Alexpux/MINGW-packages/pull/673
and make any required changes.

Thanks!
  I get a format specifier warning when building for Android using clang and tess-two:

```
jni/com_googlecode_tesseract_android/src/api/pdfrenderer.cpp:537:28: warning: format specifies type 'long' but the argument has type 'size_t' (aka 'unsigned int') [-Wformat]
               "stream\n", len);
                           ^~~
```

I think it should be `%zd` or `%zu` instead of `%ld`, but I'm not sure if that works on Visual Studio too.
 I'm the author of this code. I'd prefer to keep using size_t for this number since PDF files can be really big (although, this code will break for other reasons once we get larger than 10 gigabytes). Not sure what to do here to make all platforms happy.

http://stackoverflow.com/questions/2524611/how-to-print-size-t-variable-portably
 OK--since this warning isn't indicative of a larger problem, and there's no clear solution for muting this warning across the board, let's close this issue.
 That's not a solution. It's a bug, not a compiler warning which must be muted.

You will get a wrong results on little endian platforms when sizeof(long) != sizeof(size_t).
On big endian platforms the result is wrong when sizeof(long) > sizeof(size_t).

Adding a type cast would help: (long)len

Even better would be replacing "%ld" by "%lu" and using  this: (unsigned long)len
  The original issue tracker is gone, but there's an archived version here:
https://web.archive.org/web/20150413012229/https://code.google.com/p/tesseract-ocr/issues/detail?id=1378

Basically the request is to output the information contained in a hOCR file in tabular TSV format.
 Can this be merged to provide support for tables?

Thanks!
 What is the use case for this? I can't find any earlier discussion. As far as I can tell, all the information is included already in the hOCR output (more actually since it host LTR/RTL, italic/bold, etc) -- and, of course, even more info is available programmatically through the API.

Here's some example output: http://teksty.klf.uw.edu.pl/12/1/alice_1.png.hocr.tsv
archive: https://web.archive.org/web/20160201190446/http://teksty.klf.uw.edu.pl/12/1/alice_1.png.hocr.tsv
 I've created a cleaned up version of this code in #245. I'm not really happy about adding even more crap to baseapi.cpp, but I've got a separate branch to refactor the hOCR renderer out of it, so I can add the TSV renderer to that, if it's decided to include it in Tess.
 Wouldn't it be easier to keep the `TSV` code out of the Tesseract code and to provide a standalone script which does a transformation from `hOCR` to `TSV`? Such a script could also be used with `hOCR` generated by other tools.
 Link for one of the earlier requests

https://groups.google.com/forum/m/#!topic/tesseract-issues/-QOvWLrsjfI
- sent from my phone. excuse the brevity.
  On 01-Mar-2016 10:28 pm, "Tom Morris" notifications@github.com wrote:

> What is the use case for this? I can't find any earlier discussion. As far
> as I can tell, all the information is included already in the hOCR output
> (more actually since it host LTR/RTL, italic/bold, etc) -- and, of course,
> even more info is available programmatically through the API.
> 
> Here's some example output:
> http://teksty.klf.uw.edu.pl/12/1/alice_1.png.hocr.tsv
> archive:
> https://web.archive.org/web/20160201190446/http://teksty.klf.uw.edu.pl/12/1/alice_1.png.hocr.tsv
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/pull/18#issuecomment-190811980
> .
 The earlier issue mentioned is at: https://web.archive.org/web/20151128094905/http://code.google.com/p/tesseract-ocr/issues/detail?id=918

Basically it posits that TSV output as a (partial?) solution to table layout analysis.  I think it's a bit more involved that that, but I have no strong feelings one way or the other on adding this.

Pros:
- provides a simpler format for consumers than parsing HTML
- not really that big: 1 API call, 1 config variable, <200 lines code
- having it directly supports eliminates the need for external helper scripts

Cons:
- largely duplicates functionality available in hOCR output
- one more place to update if new information gets added to the output
- downstream consumers are going to be custom programs, so they could integrate HTML parsing instead of TSV parsing (with a small increase in complexity)

Like I said, I'm neutral. I'll let others argue yea or nay.
 Thanks Tom, for listing out the pros and cons for tsv.

As a user, I support having a simpler format of output without external
scripts :-)

Regarding the duplication of functionality, is it not possible to use a
common routine and then branch off based on required output format.

ShreeDevi

---

‡§≠‡§ú‡§® - ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® - ‡§Ü‡§∞‡§§‡•Ä @ http://bhajans.ramparivar.com

On Wed, Mar 2, 2016 at 9:22 PM, Tom Morris notifications@github.com wrote:

> The earlier issue mentioned is at:
> https://web.archive.org/web/20151128094905/http://code.google.com/p/tesseract-ocr/issues/detail?id=918
> 
> Basically it posits that TSV output as a (partial?) solution to table
> layout analysis. I think it's a bit more involved that that, but I have no
> strong feelings one way or the other on adding this.
> 
> Pros:
> - provides a simpler format for consumers than parsing HTML
> - not really that big: 1 API call, 1 config variable, <200 lines code
> - having it directly supports eliminates the need for external helper
>   scripts
> 
> Cons:
> - largely duplicates functionality available in hOCR output
> - one more place to update if new information gets added to the output
> - downstream consumers are going to be custom programs, so they could
>   integrate HTML parsing instead of TSV parsing (with a small increase in
>   complexity)
> 
> Like I said, I'm neutral. I'll let others argue yea or nay.
> 
> ‚Äî
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/pull/18#issuecomment-191297761
> .
  Just glanced at the code and wondered why on Earth multiplication and division is being done in every iteration, especially on inner, nested loops. Look at this:

PIXELS_PER_BURST*NUM_CHANNELS)/CHAR_VEC_WIDTH

This is inside a loop nested 3 deep. How many wasted clock cycles is this? Are we assuming that the compiler will optimize this out? If you're benchmarking with debug builds, your numbers are going to be way off, as in meaningless.
  I don't think it is going to happen.
@theraysmith, should we close this PR?    Internet Archive copy of discussion in original issue: https://web.archive.org/web/20151128081631/http://code.google.com/p/tesseract-ocr/issues/detail?id=1199
 I think this one can be safely closed.
  Archive copy of issue (but full text is included above): https://web.archive.org/web/20151128081631/http://code.google.com/p/tesseract-ocr/issues/detail?id=1199
 @zdenop, please close this PR.  @orbitcowboy,
Can you reply to @tfmorris's comment?
https://github.com/tesseract-ocr/tesseract/pull/9#r53199684  This PR can be closed, see commit 97080412f which fixes the same issue [here](https://github.com/tesseract-ocr/tesseract/commit/97080412fdc8cef05b1f917e698277cd01c6f004#diff-262ca20242c273c5ad4f245d251b6aa8R894). Thanks Stefan. Somehow I missed that commit.  Fixed in commit d8a55d739  @theraysmith, should we close this PR? @zdenop, please close this PR.  :+1:  LGTM, but it's on an error path, so it's a pretty unlikely resource leak.
 @amitdo, I suggest to apply this PR.
