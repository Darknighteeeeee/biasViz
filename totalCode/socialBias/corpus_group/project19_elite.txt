  Looks like the site has invalid content.json, the error is at site's content.json file line 3140, try to update it manually using ZeroHello.  ### Step 1: Please describe your environment

  * ZeroNet version: 0.6.0 r3097
  * Operating system: Arch Linux
  * Web browser: Chromium
  * Tor status: always
  * Opened port: no
  * Special configuration: tor = always

### Step 2: Describe the problem:

I want to update ZeroNet without using clearnet. Is it possible?

#### Steps to reproduce:
  1. Launch ZeroNet with `tor = always` option;
  2. Click on the "New ZeroNet version: 0.6.1";
  3. Then click on the "Update and restart ZeroNet".

#### Observed Results:
```
Update site path: /var/lib/zeronet/1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp, bad_files: 0
/usr/lib/python2.7/site-packages/msgpack/__init__.py:47: FutureWarning: use_bin_type option is not specified. Default value of the option will be changed in future version.
  return Packer(**kwargs).pack(o)
[15:22:17] - Redirect to: https://codeload.github.com/HelloZeroNet/ZeroNet/zip/master
Segmentation fault (core dumped)
```
#### Expected Results:

ZeroNet updated to the latest version. Looks like something with gevent. What output you get for
` python -c "import sys; print sys.version; import gevent; print gevent.__version__; import msgpack; print msgpack.version;"`?  ## Why?

It will allow to discover peers on local network without internet connection. Currently it's only possible by setting up a tracker by enabling the Bootstrapper plugin and pointing every client to that ip.

### How?

[Zeroconf](https://en.wikipedia.org/wiki/Zero-configuration_networking) allow clients to discover each other without server intervention.

### What?
Started working on local peer discovery using https://github.com/jstasiak/python-zeroconf as it seemed like the most active one and also works with gevent.

## Problems / Questions:
### Binary dependency
It depends on netifaces module that is not pure-python which I try to avoid due multi-platform issues. Solved it by creating a "fake" netifaces module that returns using the current Upnp.py module's `_get_local_ips` function.
Other dependencies: six, enum (both light, pure-python modules, so should not be a problem)

### How to broadcast the list of sites you have?
 - Creating service to each site
 - Adding it to service's description
 - Don't distribute it to zeroconf network, but allow the other client to receive a list of site address sha hashes you have. (this plugin will be turned off by default in tor: always mode)
 - Don't do anything, let other clients try and fail for unknown sites

### Avoid leaking local peer ips to peer exchange
 - Mark sites that received via zeroconf
 - Skip local ip ranges on pex


## Current status

 - I was able to create a registration request and other computer on the same network was able to discover it
 - Ran into some gevent error (<1.1 version), I was able to fix it, but one more ugly patches
 - Added private ip detection and filter to pex
 - Found a way to make it work on gevent without ugly patch
 - Moved to simple UDP broadcasting with custom protocol due [zeroconf problems](#issuecomment-361974868)

### Plan
 - [x] Create Plugin directory for it
 - [x] Basic broadcast listener server
 - [x] Testing basic broadcast server functions
 - [x] Extended broadcast server with peer discovery functions
 - [x] Implement discoverRequest, discoverResponse, siteListRequest, siteListResponse commands
 - [x] Test discoverRequest, discoverResponse, siteListRequest, siteListResponse commands
 - [x] Implement and test siteListRequest caching based on sites_change
 - [x] Test local peer exchange on UDP socket
 - [x] Connect peer discovery with announce events
 - [x] Prefer recently discovered tracker/LAN clients
 - [x] Set up multiple clients on LAN without internet connection for real-life testing
 - [x] Release I started experimenting with simple broadcast udp messages as zeroconf lib has the following problems:
 - No ipv6 support
 - Can't announce different ip for multiple network interfaces
 - Relatively high cpu usage (~15 cpu seconds/hour on chip computer in my quiet LAN)

I'm not sure if zeroconf/mdns/bonjour has other benefits over udp broadcasting that we can use/need

### Protocol draft:

- Listening on udp 1544
- msgpack? or json? encoded protocol

Discover request sent every 20 minute, when a user added new site or started the client. (when sites announces)

#### Version A
```
> broadcast: {"cmd": "discoverRequest", "params": {"zeronet": {version_rev: 3222}}}
< response to requester: {"cmd": "discoverResponse", "params": {"zeronet": {"port": 15441, "sites": 3, "sites_changed": 1517415166, version_rev: 3222}}}
```

If the requester interested, then it can connect to the respondent with standard tcp/zeronet protocol and ask for sitelist with a new `siteList` command (only available from local/private ips) and add it to peer list of the sites that the respondent has.

#### Version B
```
> broadcast: {"cmd":"discoverRequest", "params": {"zeronet": {"port": 15441, "sites_changed": 1517415166, "rev": 3222, "peer_id": "-ZN0061-AnJx5Pamk0U0"}}}
< response to requester: {"cmd": "discoverResponse", "params": {"zeronet": {"port": 15441, "sites": [sha256("1siteaddress1"), sha256("1siteaddress2"), ...], version_rev: 3222, "peer_id": "-ZN0061-AnJx5Pamk0U0"}}}
```

This way the requester don't have to connect to respondent to list the site, but the site list will be pushed with response.

**Problems**
 - Larger response size: I think 32 byte / site address is still acceptable on LAN (32k for 1000 hosted sites)
 - UDP packet size limit: Can be solved by sending a new response for every 100 site address

#### Version A + B

Also send the sitelist over UDP, site list only sent on `siteListRequest`. This requires one more roundtrip, but saves cpu + bw.

- Broadcast: `discoverRequest`
- Every broadcast listener -> requester: `discoverResponse`, params: zeronet tcp port, sites_changed (last time the user added or removed a site to the client), rev, peer_id
- requester -> clients who has different sites_changed time, than the requester stored: `siteListRequest`
- requested clients -> requester: `siteListResponse` params: zeronet tcp port, sites_changed, rev, peer_id (the client adds peer ip to site site list and updates the stored sites_chaned value for the peer_id)

**Questions**
 - What about network changes? (different wifi network, sleep / wakeup) CC @MuxZeroNet   I got the barrier when tried to get [grapejs](http://grapesjs.com/) work. I will check what's the best way to remove the limitations of sandboxed iframe.
  The problem is FileQuery will get slow after a certain amount of file (depends on hdd/ssd/mmc speed), so I not sure if we should encourage using it. Then adding cross-site database query support sounds better for me if it would solve the problem. Working on it... I will change the (currently undocumented) "As" command to allow this.
It should not take long :) [Added](https://github.com/HelloZeroNet/ZeroNet/commit/327badb3ca175621fb5f00b9fb8f101d0268c11c) to Rev3230, usage example:
`page.cmd("as", ["138R53t3ZW7KDfSfxVpWUsMXgwUnsDNXLP", "dbQuery", "SELECT * FROM json"])`
 Try this way: `page.cmd("as", ["138R53t3ZW7KDfSfxVpWUsMXgwUnsDNXLP", "dbQuery", ["SELECT * FROM json WHERE json_id = :param", {param: param}]])` Just added it:

https://zeronet.readthedocs.io/en/latest/site_development/zeroframe_api_reference/#as-address-cmd-arguments  The main problem proof-of-storage and proof-of-bw is really hard (impossible?) opposed to proof-of-cpuwork.
 > FYI, Proof of Space is possible. PoS uses hard-to-pebble graphs to ensure the prover must dedicate a certain amount of storage.

Thanks for pointing out, but it sounds like it's not for any meaningful data and even it would be so the proof-of-bw solution is still required to make it comparable to pow. The problem is (unlike steam) in ZeroNet there is no trusted parties, so: who would decide if someone uploaded 1GB or not?
 @mkg20001 It's very abstract, missing lots of details, but we will see once it's launched.  Actually you don't have to change anything in content.json, here is the steps:
 - Generate address using vanitygen
 - Create data/1yourvanityadress directory and copy the site file's there
 - Open http://127.0.0.1:43110/1vanityaddress in your browser
 - Open sidebar and sign all the content.json at the bottom of it.  ## Why?
The current, whitelist based listed ID provider solution leads to unnecessary centralization.

## How?
Proof-of-work based ID providers could let anyone create his/her own one and use it on any site that supports these kinds of ID providers.

## What?
The site could add required prefixes for ID providers instead of specific listing the supported ID providers.

Example for current, white-list based configuration:
```json
...
"user_contents": {
 "cert_signers": {
  "zeroid.bit": ["1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz"]
 }
}
...
```
This allows only one certificate provider on the site for the user contents.

Example for new, Proof-of-work based id specification
```
...
"user_contents": {
 "cert_pattern": "^1ZeroiD"
}
...
```
It would allow any certificate provider that's Bitcoin address starts with "1ZeroiD".
Currently, it takes around 6 hours on a ~200USD GPU or 30 USD on https://bitcoinvanitygen.com/
to generate an address with this prefix, which should be eligible to fight against spam.

Using the permission rules the site owners able to ban/set specific limits or rules based on ID provider address.

The users who don't have the possibility to generate his/her own ID provider could use
already existent ID providers that accept third-party registrations.

## Problems

### Backward compatibility

An older client won't accept user files signed by these id providers.

### ID provider naming

We can't add readable name for the id providers, so they will appear as bitcoin address eg.: user@1ZeroiDJnkHkugPNd8UzSwceH8HfsnYtC

**Possible solution:** Display only the first few letter of the unique part, eg.: user@JnkH...

### Unlimited number of users

We can't limit the number of users issued by the ID provider the per-user size limit going to lose some effectiveness.

**Possible solution:** A per-ID provider limit.
  I just generated a 1ZeroiDJnkHkugPNd8UzSwceH8HfsnYtC address in 3 hours, so maybe we should make it harder like "1ZeroiD[0-9]" should take ~2-3days on my machine It's not acceptable for new users, but they would able to use already existing id providers. So if you do that 2-3 days of calculation you are also able to issue new certificates for users you trust.
 Will cert pattern "cert_pattern": "^1" be allowed in this implementation? (while list all cert providers). Sure, but if you don't want to have any control over the content submitted to your site, then I recommend self-signed certificate.  The zeronet.exe starts in non-console mode and unfortunately there is no way to change it later. If you need the console window, then there is a zeronet.cmd in the lib directory that starts zeronet with cli. Thanks!  Probably we can use the pinning feature for this I think it should never delete pinned files  Thanks!  Thanks for reporting. I switched to eval from exec: https://github.com/HelloZeroNet/ZeroNet/commit/0c6c7d27252f01cddbc8cc7109082f6a72afb7d7#diff-7fa31802ec08bb55f5128c3e841b5f34R645

Can you please verify if it's fixed the problem?
You have to save https://raw.githubusercontent.com/HelloZeroNet/ZeroNet/0c6c7d27252f01cddbc8cc7109082f6a72afb7d7/src/Ui/UiRequest.py to Users/Kafke/Downloads/ZeroNet-master/src/Ui directory I just tested it with python 2.6.x and it works (the exec code drops the same error as you described), so I suppose it will work with 2.7.6  Has it worked before? What version are you on currently? What do you see when you visit the ZeroUpdate site in your client?  What error message you see in the javascript console? (F12)  Thanks for the detailed report. 
We send port = 0 when the client is in passive mode (without public ip) to avoid listing it to other clients. Looks like it's not compatible with every tracker software. I have just tested your code with the trackers we currently using and all accepts port=0. 
To avoid this problem we have to find an other way to get the peer list without putting my ip to the list.
  ### Step 1: Please describe your environment

  * ZeroNet version: 0.6.0 rev3171
  * Operating system: Ubunty 16.04
  * Web browser: Google Chrome 63.0
  * Tor status: error
  * Opened port: no
  * Special configuration: no

### Step 2: Describe the problem:

Can use JS to backup and restore localStorage data for current site using wrapperXetLocalStorage API calls. Can use OS backup but methods are different for each browser, not very user friendly and may change in new browser versions.

Could be nice to backup and restore localStorage data for all ZeroNet sites. 
wrapperXetLocalStorage cmd with ADMIN permission or button in 0 sidebar?  actually it's `lib/zeronet.cmd siteCreate` as the zeronet.exe is gui-only application and you won't see any output to command line from it.

But you can also use the web interface to create new site. `â‹® > Create new, empty site` on ZeroHello
 > All work, including zeronet.exe.

Yes, it does work, but using the zeronet.exe you won't see any response/output/message in the command line.  Thanks!  Thanks for reporting:
 - Does it worked for you earlier?
 - What operating system are you using?
 - Can you please upload the `(core)/src/Ui/template/wrapper.html` here
 Looks like your computer has some [virus](https://stackoverflow.com/questions/31246535/how-is-this-piece-of-vb-code-getting-added-automatically) on it and it modified the html file (added part after `</html>`)
The wrapper.html should look like this: https://raw.githubusercontent.com/HelloZeroNet/ZeroNet/master/src/Ui/template/wrapper.html (2.51KB)

You can try to overwrite the file with this one, but probably you need to get rid of that virus (or anything that modified the file) first.

    Thanks for reporting, it should work fine now: https://github.com/HelloZeroNet/ZeroNet/commit/3fb9f900f6c0d08abd8facc987af4a274d31d56b  Imachug: I would prefer to use the current ones. ZeroTalk has a jquery compatible version of the dropdown menu. I think that would be the best to use to keep the UI consistency.
https://github.com/HelloZeroNet/ZeroTalk/blob/master/css/Menu.css
https://github.com/HelloZeroNet/ZeroTalk/blob/master/js/utils/Menu.coffee
https://github.com/HelloZeroNet/ZeroTalk/blob/master/js/TopicList.coffee#L260
https://github.com/HelloZeroNet/ZeroTalk/blob/master/index.html#L179 I have no email from saketjoshiiit Currently I made some changes on sidebar. I'm going to publish a new version in the next days after that I will check it.  Hi, thanks, it's a nice addition! There is a small bug: the `re.sub(r":" + re.escape(key) + r"([)\s])", ` does not matches if the query ends with the parameter. 

Eg.: `assert db.execute("SELECT COUNT(*) AS num FROM test WHERE test_id IN :test_id", {"test_id": [1, 2, 3]}).fetchone()["num"] == 3`

And for me `params IN 1, 2, 3` does not work, only `params IN (1,2,3)`

And please extend the TestDb.py with test cases that covers this way of parameters.
  
Update: Merged & Fixed it :)  The tor client bundled with the Tor browser is not configured to make it work with ZeroNet by default. I'm planning bundle the Tor client with the macOS client, that will solve this problem.  What does the per-site breakdown says? You can see it by click on "from xx sites in x.xx s" text in the search input area Is there any error in the js console? (F12) According to 'Error: div.FeedList.search had a div child added, but there is now more than one. You must add unique key properties to make them distinguishable. all.js:443:35' it looks like one of the sites you following does not providers unique id for the feed item.
I have added a fix for it (https://github.com/HelloZeroNet/ZeroHello/commit/5dac15190e3bc3b0664baf17d8ebef2a9ea0afe0) please check if it's fixed it. I published the modification to ZeroHello, so it should automatically update your all.js file.

Please try this one:
 - Add `site.log.debug("Newsfeed %s query taken: %.3fs" % (name, time.time() - s))` line after https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Newsfeed/NewsfeedPlugin.py#L89
 - Restart ZeroNet
 - Check log/debug.log file for "Newsfeed query taken" lines and see which site blocks the update. According to the log it looks like it was caused by a site with no database, but with a feed signup. From Rev3178 will skip these sites (https://github.com/HelloZeroNet/ZeroNet/commit/92e353be40533140b783ede48010566848da9805) please update and try again
  small correction: only big files (>20MB) get automatically pinned (https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/OptionalManager/OptionalManagerPlugin.py#L134), smaller files will be automatically deleted if you reach the storage limit (10% of your free space by default, but you can change it on files tab)  Thanks for the reminder, just filled out the form. Let's hope for the best :)  Is it happened after you clicked "Set limit to xx MB"  button?  Unfortunately this is a restriction of the browsers: Web pages opened with target=_blank from sandboxed iframe keeps the sandboxing, so won't be access cookies and many other things. It works fine if the users opens the link to new tab (eg. with middle mouse click)
Possible solution:
 - Open to current tab with target=_top
 - As @AnthyG said: use the wrapperOpenWindow API call

To automatically fix all target=_blank links:
```js
window.onclick = function (e) {
    if (e.target.getAttribute("target") == "_blank") {
        e.preventDefault()
        page.cmd("wrapperOpenWindow", [e.target.href, "_blank", ""])
    }
}
```  It's your responsibility to keep your time in-sync, ZeroNet can't really do anything about it, but to avoid irreversible problem you won't be able to publish a file in the far future (t + 1day)  The newsfeed feature is something like this, but there is lots of space to extend it's possibilities. Eg. by adding JS logic support for more complex notifications (to make ZeroMail support possible)  None of these are prossible atm, but it could be:

> I don't allow user to edit post content after he posted

Diff the updated file with the current one and if there is any modification, then reject it.

> I don't allow user fake time timestamp

I don't this if there is any reliable solution for this.

> I want assign someone as admin to manage part of site, not whole site

With includes you can set per directory signers.  I would recomment to create a ZeroTalk clone for the proxy and the user would use it for submission to the admin.  There is lots of other Chinese messages on the board, so I think the problem should be somewhere else  I'm not sure what you mean. For the site messages you can use the built-in, json based translator solution. 
If you want to translate the user submitted content, then it's much harder and probably you need to use a third party service for that (eg. google translate) via a browser plugin  please try this way:
```
ui_host =
 sub1.zeronet.io
 sub2.zeronet.io
```  Actualy there is already a "wrapperRequestFullscreen" API call to do that. It was undocumented, but just fixed that issue: https://zeronet.readthedocs.io/en/latest/site_development/zeroframe_api_reference/#wrapperrequestfullscreen I have tried to add the allowfullscreen attribute, but it's not possible to add it after the iframe was rendered. (after the request of fullscreen approved) Well, why not... added in latest rev: https://github.com/HelloZeroNet/ZeroNet/commit/0009b1b7d1d3fc62a0b126b8ed1d66730e75242b  It's only required to access the websites, so you can block 43110  (by default it only allows connection from your computer)  Thanks for reporting I just tested Midori 0.5.1 and I can confirm , that the sidebar does works on it, but the problem is no related to WebGL support, because for example it works in Tor browser and enabling WebGL in Midori does not fixes it. 

I tried to find what exactly missing for the sidebar, but lack of any web developer tools makes it really hard.  It need some modification in wrapper code to use relative path for the websocket connection  example `zeronet.conf`:
```
[global]
data_dir = my-data-dir
log_dir = my-log-dir
ui_restrict =
 1.2.3.4
 2.3.4.5
```
You can list the possible configuration options with `zeronet.py --help`
 by default it tries to load the config from the working dir. You can override this with `--config_file "/etc/zeronet.conf"` startup argument I gave you an example in comment https://github.com/HelloZeroNet/ZeroNet/issues/1192#issuecomment-346219984
I will consider adding .conf file by default  Currently it won't work without moving the site data directories, but it would be a great addition. Added in Rev3153: https://github.com/HelloZeroNet/ZeroNet/commit/6b92d011d24c708674891f174a8d7f9c5153d7ef
All missing site from sites.json will be downloaded at startup.
  I'm planning to change it to display only when the user registers itself an ID (eg. using ZeroID) From Rev3151 it will only show the seed on certificate add: https://github.com/HelloZeroNet/ZeroNet/commit/9df86ecaa976c2dbf86b5965b9df61109a41781e  You also need to pass more headers for websocket, eg.:
```
server {
    listen 443 ssl;

    server_name        url;
    ssl on;
    ssl_certificate        /etc/letsencrypt/live/url/fullchain.pem;
    ssl_certificate_key     /etc/letsencrypt/live/url/privkey.pem;
    ssl_session_timeout 5m;

    location / {
        proxy_pass http://0.0.0.0:43110;
        proxy_set_header Host $host; #get rid of media referrer error
        proxy_http_version 1.1;
        proxy_read_timeout 1h; #for long live websocket connetion
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```
via http://127.0.0.1:43110/1EiMAqhd6sMjPG2tznkkGXxhdwFBDdeqT9/?Post:44
 ZeroNet using sandboxed iframe to avoid same-origin problems, so it requires iframe support.  If you using the same .onion address for every hosted site, then it's possible to list which other sites you hosting by checking that address in other sites peer list.
If I understand correctly, then the authentication feature does not improve this.
    The content type restriction is present, to avoid site addition with a simple img tag eg.: `<img src="/1myothersite">`
You can use the /raw/ prefix to load content using curl. eg.: http://127.0.0.1:43110/raw/1anything...
 It looks like some weird browser: `"Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; Touch; rv:11.0; 2345Explorer/8.8.3.16721) like Gecko"`
Not sure what is "2345Explorer/8.8.3.16721", but I just tested in IE11 (based on `Trident/7.0; Touch; rv:11.0;` part) and it works  You are not missing anything it should work. 
Is your or the other client has opened port? 
Do you have Tor enabled?
Have you tried to sign/publish the site (eg. using the sidebar) again? Probably that's why they can't find each other. The local network peer discovery not implemented yet and it puts the client's external ip:port to blacklist to avoid connecting to itself.
You can try start one of the clients using `--fileserver_port 15442` to avoid this.  Like I said in the linked issue: I have not found any suspicious activity and if it's really an attack then banning based on ip address is not a viable solution as anyone can generate unlimited ammount of .onion address. @imachug I can hardly imagine that your problem was caused by an attack on the network. 

There was an error in the rate limiting algorithm that could have caused problem like you described. I fixed some days ago in Rev3137: https://github.com/HelloZeroNet/ZeroNet/commit/5026f1b0a8bad418fcc9baf0137e5f7ee877513c

Please open an issue if you still experiencing it after the update.  Thanks, please also add translation for other files and to ZeroHello, so I can list it on the language selector.  It wasn't initially, but it was fixed in Rev3125: https://github.com/HelloZeroNet/ZeroNet/commit/99e5af67b75f6543bcba7a2e49322a7699d1a7cb
There was other bigfile related problems with merger sites, but it should work fine now.
  Thanks for reporting, fixed: https://github.com/HelloZeroNet/ZeroNet/commit/bc1d79a07d976d521aa9900233749f481aff6fb3  The data/sites.json has "peer" filed for every site you seeding. Or you can use the websocket API: https://github.com/HelloZeroNet/ZeroNet/issues/1137#issuecomment-337019878 Currently it's not possible without downloading the site.  Some blogs are art-centric and have posts with no text at all, sometimes even without titles, so it's hard to get them into newsfeed. Also all popular sites such as facebook and twitter have media objects in newsfeed, and it's pretty.
I propose two new fields in the [`feedFollow`](https://zeronet.readthedocs.io/en/latest/site_development/zeroframe_api_reference/#plugin-newsfeed) command:

- `media_url`: url of the media object
- `media_type`: one of `{'image', 'video', 'audio'}`

I think one media object per record would be enough. If user is interested, he can follow the link to view all content.
Please, share your thoughts. It's could be possible in a way that ZeroMe work: Display already downloaded images, other visible on click.  Well actually OS X is macOS now :)  in theory i fixed it some days ago. Maybe I forgot to sign + publish it, so I just did it again. Please try again and if it's still not working for you, check the JS console (F12) for error.  why not, added: https://github.com/HelloZeroNet/ZeroNet/commit/c3250378ee110721fc919e1ecfeb4c1040839f3f  wat operating system/browser are you using and where do you see this message? @imachug Actually it using github to update: https://github.com/HelloZeroNet/ZeroNet/blob/master/update.py#L16
update_after_shutdown used here: https://github.com/HelloZeroNet/ZeroNet/blob/master/zeronet.py#L20

@kkkkketsu I can't find the "Can not be updated automatically" in the source code, where did that message appeared to you?  Godd idea, It should be better now: https://github.com/HelloZeroNet/ZeroNet/commit/90ff9ac7fb2a0babf52aa72066e10217a5a7ffe8  Thanks!  To backup your identity you have to save data/users.json the sites are also in this direcory  It could be possible, but not sure about security issues @MuxZeroNet Do you see any problem setting executable flag on specific files automatically? We could add a like this to content.json:
```
...
"files": {
  "any/file": {
    "sha512": "asd...",
    "size": 123,
    "executable": true
  }
``` I'm not a linux expert, so I still waiting others opinion on security issues  Thanks for the suggestion, it's changed in Rev3126: https://github.com/HelloZeroNet/ZeroNet/commit/09413f5fc794616ce61d357611141462d59ca04f  I think it should work this way right now:
 - create a bootstrapper client on the local network by renaming plugins/disabled-Bootstrapper to plugins/Bootstrapper
 - Add `trackers = zero://ip.of.bootstrapper.client:15441` to zeronet.conf
 - start zeronet with `zeronet.py --ip_external yourlocalip`

Required improvements:
 - Implement local peer discovery eg.: https://pypi.python.org/pypi/zeroconf (so it would to require to setup a bootstrapper node in most cases)
 - Don't send local peers via PEX
 - Add ipv6 support
  do you have your site's address in your users.json? does it have "pirvatekey" entry in that section? @krixano is right. 
Looks like you have the privatekey in place, so you should be able to edit it. When you open the sidebar (by dragging the topright button to left) do you have "this is my site" enabled? and what happens if you press the sign button on the bottom of that panel? @wzhb When you open the sidebar (by dragging the topright button to left) do you have "this is my site" enabled? and what happens if you press the sign button on the bottom of that panel?  What platform are you using? What does it says for Tor status on ZeroHello page?  You don't have to edit it, you can enable usage of Tor on every connection by clicking on Tor: Avaliable > Enable tor for every connection  For testing reasons: how many files you want to read at once? I was unable to reproduce it, but I found a bug that could have affected this case. (https://github.com/HelloZeroNet/ZeroNet/commit/9d4515954b8cb7f8c0af31f30d83567a3486e624) Please update to latest version and try again.

I was able to read 100x3MB zip files this way:
```
	read() {
		for (var i=0; i<100; i++) {
			page.cmd("fileGet", {inner_path: "optional/" + i + ".zip", format: "base64"}, function(res) {
				if (res)
					console.log(res.length)
			})
		}
	}
```
  It should be fixed by https://github.com/HelloZeroNet/ZeroHello/commit/b4f488a35b1d9460ba4fd15e33d543f577563749  That's sounds like a bug, it should not delete missing optional files from content.json I tried to reproduce it, but it does not removes the previous optional files for me:
 - Created a new site
 - Added `"optional": "optional/.*",` to content.json
 - Signed
 - Created `optional/test.html` file
 - Signed
 - Deleted `optional/test.html` file
 - Signed
 - The `optional/test.html` file still in the site's content.json

I also tested it with my ZeroID profile: deleted one of the images I previously submitted, but after signing the file still in content.json.

Do you have other steps to reproduce the bug?
 I have used the sidebar + ZeroMe page for testing, not the command line interface For me: Test OK. 2 optional files. The writing is takes long time because it tries to read files that is not existent and waiting for competition. (line 152, should contain required: false)
 Fixed the problem with long running operations and retested on fuckcf.cf. Still "Test failed. No optional files were found".

Checked siteSign cmd and there is an "remove_missing_optional" parameter that I can use instead of deleting content.files_optional before sign. The original problem that I was trying to solve was failed siteSign due to missing optional files. 

Still a bug but only a minor bug as remove_missing_optional is a "nicer" solution to the problem.  Thanks :)  This wasn't unexpected, but as long as you can run Tor, then it should work fine.

Actions from GFW: 
 - *.zeronet.io domain points to different ip. source: http://viewdns.info/chinesefirewall/?domain=zeronet.io
 - IPban on 104.156.231.236 (zeronet.io website ip address): source: http://ping.pe/104.156.231.236

## Affected services:
### zeronet.io website
The site can't be accessed due domain & ip ban. Changing IP does not help, registering new domain also not a long-term solution

Possible solutions:
 - Set up mirrors, eg. to http://hellozeronet.github.io/

### ZeroBoard
ZeroBoard was the first site on ZeroNet when multi-user sites was not possible, so the messages are signed and distributed by contacting the site owner which was done by a simple http request.

Possible solutions
 - Drop this site
 - Re-create the site with self-signed id certificates
 - Move the adder script to different domain and ip
 - Add a whisper protocol to ZeroNet that allows messages to be distributed between peers just like updates. (Cons: spam solution?)
 - Add a direct message option to ZeroNet API that allows direct messages to be sent to an ip address using ZeroNet protocol. Pro vs current http solution: it does not requires https since ZeroNet protocol supports self-signed cert with pinning.

### ZeroID
The certificate request currently done by http (or bitmessage)

Possible solutions: Same as ZeroBoard minus drop the site

### boot.zeronet.io tracker
This one also affected by the IP ban. The other trackers and (and the .onion one ofc) are not affected.

Possible solutions:
 - Move to different domain

Other sites not be affected (as long as you have compatible ID) Btw to do some experiments is there any cheap VPS provider behind GFW? (shared ip also fine) The client is hosted on github, so: https://github.com/HelloZeroNet/ZeroNet#how-to-join should work  Thanks for reporting, it's fixed in Rev3104: https://github.com/HelloZeroNet/ZeroNet/commit/a66b71fb9c328977cff594abf015297c19866c68  The ZeroNet client will automatically fill that for you. Just open the site in ZeroNet client, then sign it using the sidebar.  Right now the sites routing using the "?" character, eg.:
http://127.0.0.1:43110/me.zeronetwork.bit/?Post/12h51ug6CcntU2aiBjhP8Ns2e5VypbWWtv/12gAes6NzDS9E2q6Q1UXrpUdbPS6nvuBPu/1507834329

Probably I would avoid complex routing rules in the client, but adding a default page for non-existent urls would be a good idea and you could also use it to parse the page url and route using javascript.  There was a mistake with directory casing. I suspect there is two `plugin/Bigfile` directory for you with different casing. Please delete the BigFile one and keep the Bigfile directory  Whats your site address?
Does visting other sites like http://127.0.0.1:43110/Blog.ZeroNetwork.bit/ works?  There is no REST API, but ZeroNet using Websocket for API requests/responses/events. Here is a simple example using [websocket-client](https://pypi.python.org/pypi/websocket-client/):

```python
import urllib2
import re
import json
import time

import websocket

req = urllib2.Request("http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/", headers={"Accept" : "text/html"})
wrapper_body = urllib2.urlopen(req).read()
wrapper_key = re.search('wrapper_key = "(.*?)"', wrapper_body).group(1)

ws = websocket.create_connection("ws://127.0.0.1:43110/Websocket?wrapper_key=%s" % wrapper_key)
ws.send(json.dumps({"cmd":"siteInfo","params":{},"id":1000001}))
res = ws.recv()
print res
# {"to": 1000001, "cmd": "response", "result": {"tasks": 0, "size_limit": 10, "address": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", ...
``` You need a headless browser to do that, eg.: http://phantomjs.org/ I think PhantomJS is the easiest way, here is an example: https://github.com/HelloZeroNet/ZeroMail/blob/master/echobot/echobot.py  How many http://127.0.0.1:43110/Stats shows to you? (eg.: `Connections (69, total made: 360)`) Hmm that's weird
How much site you have in your client? 
How much time does it takes until it gets filled?
Have you modified any settings of your client? I have added a modification in Rev3229 that [should keep the connections under 512](https://github.com/HelloZeroNet/ZeroNet/commit/4afb6b3d9c1edb954dd74c4155a7ed8790ab82be) (by default) and it should [stop keeping open connections](https://github.com/HelloZeroNet/ZeroNet/commit/d44677e46f83d436012524498d2219128cc5067c) for sites that not modified in the last 7 days.
Please update and see if it's working better. Can you please send the log to tamas@zeronet.io ? @slrslr Thanks for the log I was able to spot and fix the [problem](https://github.com/HelloZeroNet/ZeroNet/commit/97d1d0d63b719777b0dabb47781dc1b4adce0504) in Rev3233 that broke the cleanup method.

Please update and see if it's works now. Thanks, I have added a new update to fix connection error with unknown characters: https://github.com/HelloZeroNet/ZeroNet/commit/6fb9c6ef05aa7578bd0529c4022657612bcaf9c8
Please update to Rev3234 and let me know if the problem still exists.  Thanks!  Thanks, fixed in https://github.com/HelloZeroNet/ZeroNet/commit/3030e00b218af0ab5a32df912608b2949e7f2470  Looks like the application was removed from file system. Do you have 'core/src/Ui/template/wrapper.html' file where you have unpacked your ZeroNet client?  Thanks for reporting, running it using `python2 zeronet.py` should work. (I just updated the readme)  is the `python zeronet.py --verbose peerPing boot.zeronet.io` says the same? peerPing only works on IP/Onion addresses  Please try remove `proxy_set_header Host "127.0.0.1:43110";` and start zeronet using `--ui_host zer0n.rocks`  I think the server info exposed to the websocket API should be different, because adding the client location on the fs could be privacy problem.  Thanks, looking great!  Actually siteDownload does update the site if it's already exists.  I think a getConfig action would be better that returns all the information at once. (json formatted)  For the record: It was fixed by https://github.com/HelloZeroNet/ZeroNet/commit/d3d748923287d2b4bf53fb93959c04a5531f9795

Thanks again for reporting!  Thanks, I heard about it, but it does not affects us in any way. It only affect users who manually installs the wrong packages similarly named as the non-malwared ones.  Thanks!  Have you tried access http://127.0.0.1:43110/ ? According to log it should work now  Thanks for reporting, fixed in: https://github.com/HelloZeroNet/ZeroNet/commit/bfd3d18a10e3cceddf88946dd4567e51acfd7200 @grez911 No probs, at least we know why is it necessary :)  can you please attach your content.json here? (or send to me: tamas@zeronet.io) Thanks for reporting, fixed in: https://github.com/HelloZeroNet/ZeroNet/commit/b584c586ecee3df0f1bb6890406771fc4213d04e  If possible please send the data/content.db file to me: tamas@zeronet.io
To make it work again please try to shut down zeronet, delete data/content.db and start again (it will take some time to re-index the content)  The problem is the Translate object is shared between users, so if you change it to someone, then it will change to everyone who currently connected via websocket. i'm not sure how would parametized translations (eg.: `Change it to {auth_type}/{auth_user_name}@{domain}` or `Content publish queued for {0:.0f} seconds.`) would work that way  I just tested and it does closes for me, but only if it's opened on startup. Maybe you had an incomplete shutdown before. So can you please try deleting the forward manually, then start/stop?  What does https://portchecker.co says for port 15441 for you?  I just tested it if it's changed:
With return: 
```
[16:19:09] Ui.UiServer 127.0.0.1 - - "GET http://zero/1HeLLo.../ HTTP/1.1" 200 16439 0.135000
```

With iter: 
```
[16:20:08] Ui.UiServer 127.0.0.1 - -"GET http://zero/1HeLLo.../ HTTP/1.1" 200 3001 0.000000
```
(win + chrome)

Maybe something with buffering, also not sure about the 3K vs 16K response size difference (the correct one is the 3001) Nice finding  Thanks!  We need .json files, because we can't sync .db files due multi-user sites. It would be possible to parse insert/update sql queries and magically also update the json file, but I try to avoid "magic" as much as possible. Actually you can do it in javascript, so it does not requires any modification in the client itself and by that brake the backward compatibility.  No, it's up to the OS, but we have to read/write lot's of small files and there is also a lots of random reads and writes because of the sqlite database.
The Torrent client's load is the exact opposite: Read large files sequentially.  Can you please specify the exact error message that you get? Is there any error in zeronet log/debug.log file?
you can try adding `proxy_read_timeout 1h; #for long live websocket connetion` to websocket connection settings
 'VerifyError: sites too large' happens if one of the sites you seeding is ran out of limit (you can increase it using the web interface)
'Ui UiServer : No user found' is trickier. Have you enabled the Multiuser plugin? Is there anything in data/users.json?  Thanks, I think it would be better to use object as return of the actionCheckport request, use config.homepage instead of fixed site address and i'm not sure if socket.connect_ex does not leaks real IP address in tor mode. Thanks!  Thanks for reporting fixed the permissions in Rev2187: https://github.com/HelloZeroNet/ZeroNet/commit/b1989ef02e1c438794ad5bbfde06f9e4474b7394  Because it's safe enough, requires less storage and on 64bit cpus faster, than sha256. (see: https://crypto.stackexchange.com/questions/3153/sha-256-vs-any-256-bits-of-sha-512-which-is-more-secure)  For public proxies it's recommended to enable the multiuser plugin (just rename plugins/disabled-Multiuser to plugins/Multiuser)
If you get invalid host error start it using `--ui_host 127.0.0.1 www.kittyseedbox.tk`
 Yes, sorry `--ui_host 127.0.0.1:43110 www.kittyseedbox.tk:43110`  There is rate limit on content.json updates on same file (15sec) and the data.json file size is limited to each user.

I don't think if rate limiting of post inserts is solves any problem. 
What rate do you limit it to? Even 1 post/min could ban normal users and the spammer could easily send over 1000 post / day.
What if the user was offline for some hours and that time he posted some replies? What if you were offline?

I think this problem should be solved by the moderator of the site. Maybe with help of some automated "bot" to watch the updates and ban obviously spamming users.
Also a subscribeable, shared user ignore list feature (not implemented yet) would be a great help.
 I think most of the users would really hate it if they were unable to modify their post after they sent it.
It could be possible to add more limitation on rate on same file updates. eg. 100/hour (configurable by site owner)  Thanks!  Looks like something is bad with your Tor configuration. What does `echo 'PROTOCOLINFO' | nc 127.0.0.1 9051` and `sudo netstat -anp | grep tor` says?  Thanks for reporting, fixed!  If someone submits a translation for the ZeroHello/ZeroNet, then I automatically adding it to the list.  We don't use the affected functions and I would not touch external libs if not necessary  Thanks, I fixed it using the unpatched ssl lib: https://github.com/HelloZeroNet/ZeroNet/commit/b8d68e2589468fb6fe97d599b1a3a39e173a4214

`__import__("ssl")` and `import ssl` is not the same because of gevent monkey patching.  Yes, thanks!  Actually msgpack and gevent are the only requirements that you need to install. Py-stem only required by StemPort plugin which is optional and Tor works without it. It is tor-ready. The StemPort is just an alternative communication plugin if the built-in, raw socket based tor communication way does not works for you. Not all, only the pure-python ones. The ones that requires platform specific compilation is not included. (gevent, msgpack) Not sure about the differences, but there was reports that it's does not works under Whonix. I try to avoid external dependencies if possible. When I added full Tor support py-stem did not supported the required features (create ephemeral hidden service) and they only added it half year later.
Later this year the Tor project going to make major changes in hidden services. When it happens I'm going to see if we can change to py-stem or not.
Py-stem also depends on pycrypto binary package, so requires compilation on every platform which can be painful and result in portability issues.
  Yes, for example:
`Page.cmd("wrapperSetLocalStorage", {"any": value"})`
`Page.cmd("wrapperGetLocalStorage", [], function(res) { console.log(res) })`

More info:
https://zeronet.readthedocs.io/en/latest/site_development/zeroframe_api_reference/
https://github.com/HelloZeroNet/ZeroHello/blob/master/template-new/index.html  The self-owned site delete disabled on ZeroHello to avoid unintentional deletes. To delete your own site please use this way: click on site, open sidebar, click delete site  When I reinstall ZeroNet or change to other system environment, are there any solutions to restore my ZeroNet files without signing up for a new account?

I searched a lot from the net, most say the easiest way is to backup my "user.json" file. Sadly, I'm using macos system now, having no idea to find this file. Would you please tell me how to find this file in macos.

Thanks so much.
 I have added a new "Show data directory" menuitem to ZeroHello that should open the directory in the finder. Please verify if its working (to make it work you need to update your client by Version 0.5.7... menu item) thanks  Thanks for reporting, fixed in latest version. (you have to download ZeroNet.app again from zeronet.io homepage)
You may need to define the data directory manually as by default it creates it right next to ZeroNet.app. Example.: `MacOS zeronet$ ./ZeroNet --data_dir "/Users/zeronet/Library/Application Support/ZeroNet/data" siteCreate`
  Thanks for reporting, fixed in latest version. (you have to download ZeroNet.app again from zeronet.io homepage)
You may need to define the data directory manually as by default it creates it right next to ZeroNet.app. Example.: `MacOS zeronet$ ./ZeroNet --data_dir "/Users/zeronet/Library/Application Support/ZeroNet/data" siteCreate`
  You have to use the fileGet api call instead of fetch api to load files The Cors permission is to request read permission to an another site's content.

Here is a simple example on API usage:
https://github.com/HelloZeroNet/ZeroHello/blob/master/template-new/index.html
The command you need: `page.cmd("fileGet", "content.json", function(data) { console.log(data) })`
 @mkg20001 It's about sharing files between different sites (origins). Http header won't work in our situation, since the host is same for all sites. (usually 127.0.0.1) You can be right, I'm not sure what's that manifest.json file or what @cusmith1 tries to do exactly.  Please check your dbschema.json and content.json files regex patterns: https://zeronet.readthedocs.io/en/latest/site_development/content_json/#regular-expressions-limitations I have added the pattern itself to the log line: https://github.com/HelloZeroNet/ZeroNet/commit/f45ecb6cf4bf72bd77351cf90bde176b0203e8c7
This should make it easier to find the problem.  Unfortunately Ajax requests no longer works, you have to use the fileGet API call to do the same   Please try stop zeronet, delete data/content.db file, then start again (it will take some minute to regenerate the file) I tried to reproduce it, but I have no idea how "IntegrityError: FOREIGN KEY constraint failed" can happen on `DELETE` command as we have `ON DELETE CASCADE` on all foreign key definion. It can be problematic if you edited it without enabling the foreign key function by `PRAGMA foreign_keys = ON;`
I made this error non-fatal https://github.com/HelloZeroNet/ZeroNet/commit/ac230219eed41102b8442288a9f945f937e3bd44 and also fixed a bug that caused malfunction in the cleanup process.  (it did not worked well if it had more than one site to cleanup)https://github.com/HelloZeroNet/ZeroNet/commit/c96dce3d0b4c4fec11accc1fb0e6b3b7823abf4b  By default the users.json file is not updated when you using the multiuser plugin, so you have to login every time you start the client. You can change this behavior it by starting it using --multiuser_local argument. (Enable unsafe Ui functions and write users to disk)  Try this:
```
ui_restrict =
    192.168.1.2
    192.168.1.2
```  Try stop zeronet, delete data/content.db, then start again  If your site has merger permissions, then you can get the list of merged sites using mergerSiteList command, but you can't get the list of all seeded sites as it could be privacy issue.  Added in Rev2170 https://github.com/HelloZeroNet/ZeroNet/commit/4cd393e4d8f96f8fed0f4c629c55605d26b126e3
You can enable it using `--download_optional auto` (only applies to newly added sites)  Thanks for reporting fixed in https://github.com/HelloZeroNet/ZeroNet/commit/2aba9cc3c28a879d2ae9f5aa8d956b40be3bff7a
  ![blank](https://user-images.githubusercontent.com/18724949/28328374-f6a049b6-6c18-11e7-88ea-4cc19e1f1902.png)

![403](https://user-images.githubusercontent.com/18724949/28326190-a7d1a7fe-6c12-11e7-8d9f-f5c704c2acbc.png)

Seems Chrome works, but Firefox doesn't.

Request Header:
```
Host: fuckcf.cf
User-Agent: Mozilla/5.0 (Android 6.0.1; Mobile; rv:54.0) Gecko/54.0 Firefox/54.0
Accept: text/css,*/*;q=0.1
Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3
Accept-Encoding: gzip, deflate, br
Referer: https://fuckcf.cf/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/?wrapper_nonce=1960e8886cff195cac99ddadcb6498a02cedc5a63ac59acceca2b015e92de897
Cookie: master_address=1FEJw6Xn4PJTtLrnrdLDUZwqkQXuD38nuW
DNT: 1
Connection: keep-alive
```
Debug info:
```
    "GATEWAY_INTERFACE": "CGI/1.1", 
    "HTTP_ACCEPT": "text/css,*/*;q=0.1", 
    "HTTP_ACCEPT_ENCODING": "gzip, deflate, br", 
    "HTTP_ACCEPT_LANGUAGE": "zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3", 
    "HTTP_DNT": "1", 
    "HTTP_HOST": "fuckcf.cf", 
    "HTTP_REFERER": "https://fuckcf.cf/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/?wrapper_nonce=49e24c8c3fba09d690cdc074becbe970ca4379e9ccfb66294dba53e3bb0963b1", 
    "HTTP_USER_AGENT": "Mozilla/5.0 (Android 6.0.1; Mobile; rv:54.0) Gecko/54.0 Firefox/54.0", 
    "HTTP_X_FORWARDED_FOR": "39.188.130.230", 
    "HTTP_X_FORWARDED_PROTO": "https", 
    "HTTP_X_REAL_IP": "39.188.130.230", 
    "PATH_INFO": "/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/css/all.css", 
    "QUERY_STRING": "", 
    "REMOTE_ADDR": "127.0.0.1", 
    "REMOTE_PORT": "41652", 
    "REQUEST_METHOD": "GET", 
    "SCRIPT_NAME": "", 
    "SERVER_NAME": "localhost", 
    "SERVER_PORT": "43110", 
    "SERVER_PROTOCOL": "HTTP/1.1", 
    "SERVER_SOFTWARE": "gevent/1.0 Python/2.7", 
    "arguments": {
        "action": "main", 
        "batch": false, 
        "bind": null, 
        "bit_resolver": "1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F", 
        "coffeescript_compiler": null, 
        "config_file": "zeronet.conf", 
        "connected_limit": 8, 
        "data_dir": "data", 
        "db_mode": "speed", 
        "debug": false, 
        "debug_gevent": false, 
        "debug_socket": false, 
        "disable_db": false, 
        "disable_encryption": false, 
        "disable_sslcompression": true, 
        "disable_udp": false, 
        "end": true, 
        "file_size_limit": 10, 
        "fileserver_ip": "*", 
        "fileserver_port": 15441, 
        "fix_float_decimals": false, 
        "homepage": "1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D", 
        "ip_external": null, 
        "ip_local": [
            "127.0.0.1"
        ], 
        "keep_ssl_cert": false, 
        "language": "zh", 
        "log_dir": "log", 
        "max_files_opened": 2048, 
        "msgpack_purepython": true, 
        "multiuser_local": false, 
        "multiuser_no_new_sites": false, 
        "open_browser": null, 
        "optional_limit": "12", 
        "proxy": null, 
        "silent": false, 
        "size_limit": 10, 
        "stack_size": null, 
        "stream_downloads": false, 
        "tor": "enable", 
        "tor_controller": "127.0.0.1:9051", 
        "tor_hs_limit": 10, 
        "tor_proxy": "127.0.0.1:9050", 
        "trackers": [
            "zero://boot3rdez4rzn36x.onion:15441", 
            "zero://boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441", 
            "udp://tracker.coppersurfer.tk:6969", 
            "udp://tracker.leechers-paradise.org:6969", 
            "udp://9.rarbg.com:2710", 
            "http://tracker.opentrackr.org:1337/announce", 
            "http://explodie.org:6969/announce", 
            "http://tracker1.wasabii.com.tw:6969/announce"
        ], 
        "trackers_file": false, 
        "ui_host": [
            "fuckcf.cf"
        ], 
        "ui_ip": "127.0.0.1", 
        "ui_port": 43110, 
        "ui_restrict": false, 
        "updatesite": "1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp", 
        "use_openssl": true, 
        "use_tempfiles": false, 
        "verbose": false, 
        "workers": 5
    }, 
    "plugins": [
        "AnnounceZero", 
        "CryptMessage", 
        "FilePack", 
        "MergerSite", 
        "Multiuser", 
        "Mute", 
        "Newsfeed", 
        "OptionalManager", 
        "PeerDb", 
        "Sidebar", 
        "Stats", 
        "TranslateSite", 
        "Trayicon", 
        "Zeroname"
    ], 
    "version_gevent": "1.0.2", 
    "version_python": "2.7.11 |Continuum Analytics, Inc.| (default, Dec  6 2015, 18:08:32) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]", 
    "version_zeronet": "0.5.6 r2156", 
    "wsgi.url_scheme": "http"
``` Thanks, fixed in https://github.com/HelloZeroNet/ZeroNet/commit/1f7b25b60c47af1c7dc5a6eb5b3e9c62269a43a3  It happens, because you have `"version": 4,` in dbschema.json, but only 1-2-3 supported.
Also you should change `"optional": "(data/users)",` to `"ignore": "(data/users)",`  Thanks!  Thanks!  Two possible solution:
 - Add a command set similar to merger site command, but only for read access and instead of get access to site types you requesting access to specific address.
- Add an option to site's content.json that allow cross-site file access. I have added a cors plugin: https://github.com/HelloZeroNet/ZeroNet/commit/cbac57dc8824a9dff4a79dcfab008bebe5cddf6f

To request permission to other site you have to execute `Page.cmd("corsPermission", "anysiteaddress")`
If the site is not in the user's client yet, then it will add it.
After that you can access the site's resources using `cors-siteaddress/anyfile.json` (via http request or fileGet api command)

I hope it covers your usecases.
  Thanks for reporting fixed in Rev2156 https://github.com/HelloZeroNet/ZeroNet/commit/a0d85d7d8393805290a0dd203733c61471ea4a26

It happened if you have not seeded the requested site before.  Option to force encryption for every connection.  can you please help me find the error in the docs? (i see msgpack-python everyone)

  There is a bit more peer than usual, but I don't see any suspicious thing.
The peer number is just an estimation. If you running your client for longer time you will see more due peer exchange. Also, more  frequently updated sites = more connections = more peer exchange = more peers.

It's an opensource protocol/app, so you can't do much about making custom modifications, but I don't see any problem with that. If someone does not have spare bandwidth to seed sites, then he/she can use a proxy or simply put it on paused state.

Publishing to 4 peers should be fine.
 Im not at home right now, i will check it next month if its still an issue I still have not found any suspicious activity and the updates reached my remote clients correctly.
But I made some changes that pushes the incoming updates to more peers. (6 instead of 4)
We can make it even higher, but unfortunately there is no way to make sure that every update is reaches every node.
 The per-site connection target can be overwritten using `--connected_limit` (by default it's 8)
In my experiences it should be enough in most situation.
I will monitor the "each time connecting the same nodes." problem.  Thanks, but I can't apply because i'm not an US citizen, have no experience designing hw/circuits and for me it seems they looking for a solution that allows you to browse the current internet.  The fileGet command only works within the same site (or between merged sites). The cross-site loading is not allowed for privacy reasons, because it would allow the site to list the other sites that is added to the user's client.  It's a bit hacky, we have no separate command to redirect to other page, so it using the notification to do that. 
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/UiWebsocket.py#L818
  Probably more like a feature of iframe sandboxing, but as a workaround it works this way:
```js
function createWebworker() {
	// via http://www.html5rocks.com/en/tutorials/workers/basics/#toc-inlineworkers
	var blob = new Blob([
	    "onmessage = function(e) { postMessage('msg from worker'); }"]);

	var blobURL = window.URL.createObjectURL(blob);
	console.log(blobURL)

	var worker = new Worker(blobURL);
	worker.onmessage = function(e) {
		document.getElementById('webworker_result').textContent = event.data;
	};
	worker.postMessage("hello");
}
``` web worker is not same as service worker.
Web worker: Script runs in separate thread, but it's closed when you leave the site.
Service worker: Keep running when you close the site  maybe you have multiple python installed on your computer and the pip command points to an another.
try `python -m pip install gevent msgpack-python`
you can verify the installation by entering `python` then `import gevent` to run command-line actions under windows you can also use `lib\zeronet.cmd`. (it using the bundled python, so you don't have to install it separately)
If you don't have python added to your path, then `C:\Python27\python.exe -m pip install gevent msgpack` should work.
Python2 and Python3 is not compatible with each other, so porting it would require more work. Moving to py3 planned later. (probably next year) try install msgpack-python & run it using C:\Python27\python.exe zeronet.py
 the latest 2.7.x can you please help me find the error in the docs? (i see msgpack-python everyone)  Right now only files matching `"^[a-zA-Z0-9_@=\.\+\-/]+$` supported. It could be possible to add more characters.

 Filenames `^[a-z\[\]\(\) A-Z0-9_@=\.\+-/]*$` allowed now: https://github.com/HelloZeroNet/ZeroNet/commit/96a097e33df3d24aa261bd41cf4f3a8ec5cf95ae  Thanks for reporting, I think I was able to fix this issue by https://github.com/HelloZeroNet/ZeroNet/commit/c8f37674c6f3c324614e77f66227b65a36545f54
Please verify if this fix worked for you. Sorry, added!  for me:
```
$ wget https://github.com/HelloZeroNet/ZeroNet/archive/master.tar.gz
--2017-07-07 20:25:58--  https://github.com/HelloZeroNet/ZeroNet/archive/master.tar.gz
Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112
Connecting to github.com (github.com)|192.30.253.113|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://codeload.github.com/HelloZeroNet/ZeroNet/tar.gz/master [following]
--2017-07-07 20:25:58--  https://codeload.github.com/HelloZeroNet/ZeroNet/tar.gz/master
Resolving codeload.github.com (codeload.github.com)... 192.30.253.120, 192.30.253.121
Connecting to codeload.github.com (codeload.github.com)|192.30.253.120|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 2483340 (2.4M) [application/x-gzip]
Saving to: â€˜master.tar.gzâ€™

master.tar.gz                     100%[=============================================================>]   2.37M  3.00MB/s   in 0.8s

2017-07-07 20:26:00 (3.00 MB/s) - â€˜master.tar.gzâ€™ saved [2483340/2483340]
         
$ ls
master.tar.gz

```  You have to push "Tor: Available" button on ZeroHello, then select "Use tor for every connection"  If you place ZeroNet.app in application directory then ./Library/Application Support/ZeroNet/data
If you running it from other directory, then it saves the data in the same directory as ZeroNet.app  Yes, looks like it's github issue. It returns not found also for the example in the official document:
https://developer.github.com/v3/repos/releases/#list-releases-for-a-repository
https://api.github.com/repos/octocat/Hello-World/releases/1
 Update: https://api.github.com/repos/HelloZeroNet/ZeroNet-kivy/releases still works, changed & fixed!  The wrapper is required because all sites served from same domain (127.0.0.1 normally) and without it would would allow cross site scripting.
If you want to read the raw files I recommend directly open it from file system. If you want to render the site I recommend using PhantomJS (http://phantomjs.org/) than can also render javascript based ZeroNet sites.  Thanks!
Updated from: https://indy.fulgan.com/SSL/
(I see ~5% improvement in benchmarks)  Thanks for reporting, just fixed it, it contained an invalid zeronet.py file.
To fix it manually please overwrite the `core/zeronet.py` file with this: https://raw.githubusercontent.com/HelloZeroNet/ZeroNet/master/zeronet.py   Various file systems/applications could have problems with utf8 file names in url/fs. If you really need special characters I recommend using the archive feature that support utf8 filenames:
http://127.0.0.1:43110/blog.zeronetwork.bit/?Post:105:New+version+0.5.3  None if these are easy solutions:
 - Pyre: Binary module
 - Timeout: It's only working under Unix
 - Shell-like syntax: Basically breaking all current sites.

So I think Timeout is the only possible solution, but in that case probably we need to run the regex code in separate thread or process. Unfortunately looks like python can't interrupt re.match running in separate thread:
```python
import sys, re
import threading
import time
import thread
import gevent
import gevent.monkey

gevent.monkey.patch_all(thread=False)


# via https://gist.github.com/aaronchall/6331661fe0185c30a0b4
def quit_function(fn_name):
    thread.interrupt_main()

def exit_after(s):
    def outer(fn):
        def inner(*args, **kwargs):
            timer = threading.Timer(s, quit_function, args=[fn.__name__])
            timer.start()
            try:
                result = fn(*args, **kwargs)
            finally:
                timer.cancel()
            return result
        return inner
    return outer



@exit_after(0.01)
def whileTimeout():
    i = 0
    while 1:
        i += 1
s = time.time()
try:
    whileTimeout()
except KeyboardInterrupt, err:
    print "KeyboardInterrupt"
print "whileTimeout", time.time() -s


@exit_after(0.01)
def matchTimeout(pattern, s):
    return re.match(pattern, s)

s = time.time()
matchTimeout("^A(B|C+)+D$", "ACCCCCCCCCCCCCCCCCCCCCCCCX")
print "matchTimeout", time.time() -s
```

```
KeyboardInterrupt
whileTimeout 0.010999917984
matchTimeout 1.40499997139
``` At this point the the simplest solution that comes to my mind that does not have any backward compatibility issue is sanitize the patterns: only allow repetition of any character, so enforcing the `.` before the characters `*`, `+`, `{`. 
I think this should not affect any current use cases and would protect from evil patterns. (maybe we should also limit the patterns to 255 char)

Affected parts:
 - dbschema.json: matching maps to load to sqlite database. Executed after every downloaded file, so performance on this is critical
 - content.json: ignore, optional patterns. Less critical, because it's only executed on signing

 Added in rev2153  This usually caused by suddenly disappearing peers. I just fixed the unhandled exceptions and it should show more proper messages now.   Nice to hear! :)
I have added the handshake and the missing network commands to documentation: https://zeronet.readthedocs.io/en/latest/help_zeronet/network_protocol/  ZeroNet add a ui_host restriction in a recent update, if `ui_ip` is not `127.0.0.1`, ZeroNet will also add the first http request's host to the allowed host list.
In actual use, set `ui_ip = * ` to allow users access on internet is not suitable, we need a reverse proxy to set HTTPS and gzip compression and don't allow access ZeroNet directly. It causes ZeroNet won't learn allowed host.
We can set `ui_host` by command line and edit `zeronet.conf`, but it seems can't set multi value in `zeronet.conf`. What's the error message when you try to access the ui interface and what host it added by the first request? (please search for "as allowed host" in log/debug.log)


This format should work in zeronet.conf
```
ui_host =
 host1
 host2
```  What browser are you using right now? Have you tried in another one? (FF/Chrome)  Thanks!  Can you please add more details on reproducing it?
I just tried and this works for me (cloned zerosites, modified data/users/content.json to this, then added a new site):
```json
...
 "user_contents": {
  "cert_signers": {
   "zeroid.bit": ["1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz"]
  },
  "permission_rules": {
   ".*": {
    "files_allowed": "data.json",
    "max_size": 0,
    "signers": []
   },
   "bitid/.*@zeroid.bit": {"max_size": 20000}
  },
  "permissions": {
   "nofish@zeroid.bit": {"max_size": 200000}
  }
 }
...
``` Thanks I was able to reproduce the problem.
It's happening because when you using the sidebar to sign the content it executes:
`wrapper.ws.cmd("siteSign", {"privatekey":"stored","inner_path":"data/users/1J3rJ8ecnwH2EPYa6MrgZttBNc61ACFiCj/content.json"})`
So it's using the site's private key and not the user's. In that case it does not adds user details to the content.json. Executing `wrapper.ws.cmd("siteSign", {"inner_path":"data/users/1J3rJ8ecnwH2EPYa6MrgZttBNc61ACFiCj/content.json"})` command does works.
  Thanks!  Unfortunetly I think we can't avoid it... `A` has to send the content.json directly to `B` before it can publish to other peers.
  Thanks! 
I try to avoid external dependencies if possible and was able to fix this issue: https://github.com/HelloZeroNet/ZeroNet/commit/1f83b6691b7864a35c1466ee23a14628f28ec974  Looks like your data/sites.json file is broken at line 4886 (character 20)

If you have data/sites.json-tmpold or data/sites.json-tmpnew file, then after you shut down your ZeroNet client you can try to overwrite with it  Can you check the javasript console for errors (F12)?
And please try in incognito mode (plugins disabled there) It looks weird, something with the directories, please try to open sidebar (drag topright button to left) and press Rebuild.
I will try to reproduce this error. Everything is stored in data folder, so you can do this:
 - Stop ZeroNet client
 - Rename data to data-old
 - Start ZeroNet client again and try to visit sites that you had problems before

If it's got fixed, then you can try to rename back your data directory and move data/content.db to data/content.db-old to re-generate that cache file. Can you please send me (tamas@zeronet.io) or attach your data/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/data/zeroblog.db file? Thanks, but unfortunetly it's empty, can you please also send the .db from 1Talk... directory? Thanks, I was able to reproduce and fix it latest rev2105. Please update and press "Rebuild" button on sidebar.  You can improve the tranlation by editing es.json files located in site's translate directory and in the client's src/Translate/languages/
plugins/MergerSite/languages
plugins/Mute/languages
plugins/OptionalManager/languages
plugins/Sidebar/languages
plugins/Trayicon/languages
directories

Thanks!  ZeroNet added file_size_limit recently.
When some developers try to add big files to their sites, the files will be denied without a notification.
Then developers will find the reason why clients don't download files hard, so add a notification to tell the reason is a simple way.  Some people in China needs access blocked sites via a proxy. But if you set a system proxy, ZeroNet will connect to other peers via proxy. Some proxy's bandwidth is limited and can't open a FileServer port, so we need a argument to disable proxy. What application are you using to set the system proxy address?  Is it possible to install ZeroNet to a remote machine?

Yes, you have to enable the UiPassword plugin by renaming the plugins/disabled-UiPassword directory to plugins/UiPassword, then start ZeroNet on the remote machine using 
`zeronet.py --ui_ip "*" --ui_password anypassword`. This will bind the ZeroNet UI webserver to all interfaces, but to keep it secure you can only access it by entering the given password.

Tip: You can also restrict the interface based on ip address by using --ui_restrict ip1 ip2.
Tip: You can specify the password in config file by creating a zeronet.conf file and add [global],  ui_password = anypassword lines to it.

via https://zeronet.readthedocs.io/en/latest/faq/#is-it-possible-to-install-zeronet-to-a-remote-machine  The problem is if you want dynamic sites, then have to deploy and run the site logic in some way. 
It could be possible to write a non-javascript cilent in python/java/php/etc, but javascript offers the best and most battle tested sandboxing enviroment. ZeroNet running content in sandboxed iframe that allows the content to be treated as being from the same origin.
https://www.w3schools.com/tags/att_iframe_sandbox.asp > Is there a particular reason why the src attribute of the inner iframe is assigned by Javascript code?

Without it the back button does not works, because the browser restores the old iframe url (at least in chrome) with expired nonce even if the wrapper html reloaded due no-cache header.

My ideas on JS-less mode:
Add support for `/raw/siteaddress/any.html` where the files are served without wrapper, but disabled js using Content Security Policy

Adding SSH tunnel to documentation would be a good idea and we could also enable the UiPassword plugin by default if someone start it with --ui_ip "*"  - Should we use keep the wrapper and use iframe sandbox argument to disallow JS or use Content Security Policy headers and render it without wrapper?
 - Should we check and care about browsers that does not support Content Security Policy? (IE9)

 It's landed in Rev2137 (with some fixes in 2141 & 2144) using the /raw/ prefix. Eg.: http://127.0.0.1:43110/raw/1AsRLpuRxr3pb9p3TKoMXPSWHzh6i7fMGi/en.tar.gz/index.html

It will serve the files without any wrapper, but adding `Content-Security-Policy: default-src 'none'; sandbox allow-top-navigation; img-src 'self'; font-src 'self'; media-src 'self'; style-src 'self' 'unsafe-inline';` header.
  right now only files matching `^[a-zA-Z0-9_@=\.\+-/]*$` hashed by zeronet. It should work, can you please check the `log/debug.log` after the signing? (btw the files should match `"^[a-zA-Z0-9_@=\.\+\-/]+$"`, so white space is not allowed yet) Since 0.6.0 space character allowed in filename.  you can use the same ones as arguments. To list it and get help use `zeronet.py --help`  Network administrator can block ZeroNet by blocking TCP 15441 port's inboard and outboard. Single user can set another inboard port, but it's impossible to change others inboard port, then the user whois TCP 15441 port is blocked can only connect to the peers whois FileServer port is changed.
If ZeroNet assign a fileserver_port at every start, it will cause trouble to the users who need forward port manually, but assigning a random file_server at first start then use this port in future won't bring extra trouble.
And perhaps we can recommend users using port 80 and 443, it helps some user whois network have a whitelist firewall connect to ZeroNet.
Another user create a issue 1 year ago. (#392)  Thanks for reporting, you are right the sys module was missing. 
The ssl module wasn't used, changed the variable name to avoid confusion and added other improvements:
https://github.com/HelloZeroNet/ZeroNet/commit/e291555e604f9db1a273a39db40642aca5a3e45a#diff-8483a7f5b31679cec82cabfd6c3a7c2d  Thanks for reporting, fixed in Rev2091  Yeah, forgot this one, sorry! Thanks! :)  For some reasons it's not compatible with python's tarfile module, but after extracting it and repacking works for me.
What application you used for packing?

```
$ python -c "import tarfile; tarfile.open('ZeroNet.tar.gz').list()"
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/usr/lib/python2.7/tarfile.py", line 1665, in open
    raise ReadError("file could not be opened successfully")
tarfile.ReadError: file could not be opened successfully
$ tar xvpfz ZeroNet.tar.gz
...
tar: ZeroNet/atom.xml: implausibly old time stamp 1970-01-01 00:00:00 
$ tar -zcvf ZeroNet-new.tar.gz ZeroNet
$ python -c "import tarfile; tarfile.open('ZeroNet-new.tar.gz').list()"   
-rwxrwxrwx root/root       1886 2017-05-25 17:33:52 ZeroNet/refs.html
... I haven't modified anything, probably it was related to the invalid timestamp  Yes, using Tor  Thanks, fixed!
https://github.com/HelloZeroNet/ZeroNet/commit/ed11ae283fc28f98d870602af7b0a6aba5bde277  Master needs a master_seed in `users.json` to manage a public proxy, if master deletes `users.json` for some reason, ZeroNet will create a new `users.json` which is only contains `{}`.  It's intentional, I don't see any problems with it, but you can disable it by adding `"max_size_optional": 0` to permission_rules / ".*" in `data/users/content.json`

I have changed ä¸»è«–å£‡ and ä¸»è®ºå› to English, but I don't think it's going to change anything since there is already a "Please use English, you can reach other language forums at the top of this page" warning at new topic creation.

@l5h5t7: I have added  --file_size_limit option in latest revision.  Thanks!  Are you running ZeroNet in debug mode?
Have you modified any default running parameters? (eg. using zeronet.conf) Thanks for reporting, fixed in latest rev: https://github.com/HelloZeroNet/ZeroNet/commit/1f83b6691b7864a35c1466ee23a14628f28ec974  Thanks, just tagged: https://github.com/HelloZeroNet/ZeroNet/releases/tag/v0.5.5
I usually wait some days for feedbacks/possible bugs before the tagging.   Thanks, some things:
 - Removal of `self.cmd("error", "Internal error: %s" % Debug.formatException(err, "html"))` would make the error finding more difficult, so maybe we could show it depending on `if "Multiuser" in PluginManager.plugin_manager.plugin_names:`
 - Instead of print it would be better to use `logging.warning`
 - Name `sendHomepageNotes` to `sendHomepageNotifications` to be more clear? Thanks!
Added logging for ws.receive() errors: https://github.com/HelloZeroNet/ZeroNet/commit/79005780772350db31042747749b129132f941dd  This is especially problem on mobile phones where the file system chunk size is high (32k), so it takes up lot more (up to 10times) space.
To solve this problem I planning to add site archiving method that stores moves the older user content to a zip/tar.gz archive, so it would dramatically reduce the file numbers, initial sync time and could solve scalability problems (older content archives can be marked as optional files)  Thanks  You can test it manually on http://canyouseeme.org/
if the result is negative, then probably your ISP is blocking it.  Thx, done: https://github.com/HelloZeroNet/ZeroNet/commit/f9c0c217145846a50c8299dada1e6df7380bb404  Unfortunetly ZeroMail does not works well with large ammount (1000+) of contacts and because of that the echo bot does not works properly.
I planning to fix it, but since its only affects the echo bot it's not a priority yet. I'm not sure what is error 111, can you give more info about the context please?  can i do this nowï¼Ÿ do i need my signature to sign in  you have to copy the data/users.json file to the other device.  for some reasons looks like your zeronet client does not have write permissions on data files:
```
with open(file_path, "wb") as file: 
IOError: [Errno 13] Permission denied: u'/data/.zeronet/1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz/data/users.json'
```  Can you please give more details on this? You can do by starting it using `zeronet.py --size_limit 50`  Thanks, fixed!  I think it happens if you move the .app after you started it, please try to stop it and start again  Thanks for reporting, im in Canada right now, but i will check it after i arrive back to Budapest, later this week ZeroNet provides API command for query optionally downloaded files, so it's pretty easy to "cookie" users based on that.
I don't see any easy solution for this problem other than delete your data dir every time you want to create a new identity. (and ofcourse use Tor browser)  Fixed in https://github.com/HelloZeroNet/ZeroNet/commit/34a6337c014f747fc28ea3022e1754fce852a277
If the url starts with `#` it won't add `?` anymore, but I recommend you to use `?` instead of `#` (eg. `page.cmd("wrapperReplaceState", [null, "", "?abc"]);`) as hashtags are originally for jumping to anchors on one page and using replace/pushState should not reload the page.  Unfortunately Nacl is not compatible with the crypto we use, pyopenssl does not have functions we need (eg aes encryption). Cryptography probably could work, but has binary dependencies and requires compilation to every platform/openssl version, which could reduce the portability.
Pyelliptic still has some support by the bitmessage project  This is intentionally: like @mishfit pointed out you have to call the wrapperReady api request, because if you have dynamic page you need to load resources to render the page before you can scroll to the anchor  Thanks for reporting, fixed in d346a532ffc2b9dcabca423ea84cd0c619e206f0  I will arrive back from Canada later this week, so I can check it then  Yeah, Thanks, I forgot about that. Updated: https://github.com/HelloZeroNet/ZeroNet/blob/master/CHANGELOG.md  simply run zeronet.py instead of start.py  here is the script I use: https://github.com/HelloZeroNet/ZeroBundle/blob/master/compile/compile_win.cmd

More specifically the `pyinstaller.exe zeronet_win.spec -y` command generates the exe.


but if you just want to run it, without the shipped .exe then:
 - Download https://www.python.org/ftp/python/2.7.13/python-2.7.13.msi
 - python -m pip install gevent msgpack
 - Run zeronet.py  i'm sure it's a false alarm, what can we do against it?  Well it's not easy to tell, you can try remove big sites like zeromail I have created an issue to restrict adding big sites: https://github.com/HelloZeroNet/ZeroNet/issues/907 I have added --file_size_limit defaults to 10MB: https://github.com/HelloZeroNet/ZeroNet/commit/aacde3361401f37f895ba2782e9d91ef464111fe
I hope it helps...  I tried to reproduce it: 
 - created a new zeroblog clone
 - published an user file
 - modified contentmanager sign method to remove cert signatures by adding:
```
        del new_content["cert_auth_type"]
        del new_content["cert_sign"]
        del new_content["cert_user_id"]
```
 - tried to sign & publish this file to remote machine, but it got rejected: `[2017-04-11 06:10:24,423] WARNING  Site:1NLjoF..qPa7 Verify sign error: KeyError: 'cert_user_id' in ContentManager.py line
797 > ContentManager.py line 640`

Running `zeronet.py siteVerify 1NLjo...` locally also drops error.

do you have other details how to reproduce it? There was an error that did not set the added certificate correctly. Fixed in latest rev: https://github.com/HelloZeroNet/ZeroNet/commit/1a7a22eb913865505db152037f579d18addf7b65

Now the cert selection is working for me, but the generated certificate drops "Wrong encoding" error.  (the signature should be 65 char long, but it generates 71 char long one)  Well i'm not sure if its a good idea, because it would encourages people to run many clients on the same machine an by that flood the network.  Great, thanks!   For some unknown reason most (70-80%) of the socket connection immediately fails with latest PySocks. It can be Tor socks server or gevent incompatibility.
```
[2017-04-08 22:04:42,749] DEBUG    FileServer Conn# 1 boot3rdez4rzn36x.onion [?] > Connecting...
[2017-04-08 22:04:42,749] DEBUG    TorManager Creating new Tor socket to boot3rdez4rzn36x.onion:15441
[2017-04-08 22:04:42,750] DEBUG    FileServer Conn# 2 boot.zeronet.io [?] > Connecting...
[2017-04-08 22:04:45,809] DEBUG    Site:1iD5ZQ..duGz Try to get listModifications from peers: [<Peer:x.x.x.x>, <Peer:xxx.xxx.xxx.xxx>, <Peer:x.x.x.x >, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x >, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x>, <Peer:x.x.x.x >, <Peer:x.x.x.x>, <Peer:x.x.x.x>], connected: 0, since: 1491577157.08
[2017-04-08 22:04:45,811] DEBUG    FileServer Conn# 3 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,812] DEBUG    FileServer Conn# 4 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,812] DEBUG    FileServer Conn# 5 x.x.x.x  [?] > Connecting...
[2017-04-08 22:04:45,815] DEBUG    FileServer Conn# 4 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,815] DEBUG    FileServer Conn# 6 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,815] DEBUG    FileServer Conn# 3 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,815] DEBUG    FileServer Conn# 7 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,816] DEBUG    FileServer Conn# 5 x.x.x.x  [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,818] DEBUG    FileServer Conn# 8 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,819] DEBUG    FileServer Conn# 6 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,819] DEBUG    FileServer Conn# 9 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,819] DEBUG    FileServer Conn# 7 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,819] DEBUG    FileServer Conn#10 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,821] DEBUG    FileServer Conn# 8 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,822] DEBUG    FileServer Conn#11 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,822] DEBUG    FileServer Conn# 9 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,825] DEBUG    FileServer Conn#12 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,828] DEBUG    Ui.UiServer x.x.x.x - - [2017-04-08 22:04:45] "GET http://zero/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/img/loading-circle.gif HTTP/1.1" 200 2643 0.002000
[2017-04-08 22:04:45,828] DEBUG    FileServer Conn#10 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,829] DEBUG    FileServer Conn#13 x.x.x.x  [?] > Connecting...
[2017-04-08 22:04:45,831] DEBUG    FileServer Conn#11 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,831] DEBUG    FileServer Conn#14 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,832] DEBUG    FileServer Conn#12 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,832] DEBUG    FileServer Conn#15 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,834] DEBUG    FileServer Conn#13 x.x.x.x  [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,835] DEBUG    FileServer Conn#16 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,835] DEBUG    FileServer Conn#14 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,835] DEBUG    FileServer Conn#17 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,835] DEBUG    FileServer Conn#15 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,836] DEBUG    FileServer Conn#18 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,838] DEBUG    FileServer Conn#16 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,838] DEBUG    FileServer Conn#19 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,838] DEBUG    FileServer Conn#18 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,838] DEBUG    FileServer Conn#20 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,841] DEBUG    FileServer Conn#17 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,842] DEBUG    FileServer Conn#21 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,854] DEBUG    FileServer Conn#20 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,855] DEBUG    FileServer Conn#22 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,855] DEBUG    FileServer Conn#19 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,857] DEBUG    FileServer Conn#23 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,858] DEBUG    FileServer Conn#21 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,858] DEBUG    FileServer Conn#24 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,859] DEBUG    FileServer Conn#24 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,861] DEBUG    FileServer Conn#25 x.x.x.x  [?] > Connecting...
[2017-04-08 22:04:45,861] DEBUG    FileServer Conn#23 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,861] DEBUG    FileServer Conn#26 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,861] DEBUG    FileServer Conn#22 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,861] DEBUG    FileServer Conn#27 x.x.x.x [?] > Connecting...
[2017-04-08 22:04:45,864] DEBUG    FileServer Conn#25 x.x.x.x  [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,864] DEBUG    FileServer Conn#26 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,865] DEBUG    FileServer Conn#27 x.x.x.x [?] > Closing connection: x.x.x.x Connect error: SOCKS5Error: 0x01: General SOCKS server failure in ConnectionServer.py line 139 > Connection.py line 100 > socks.py line 96 > socks.py line 813 > socks.py line 477 > socks.py line 552, waiting_requests: 0, sites: 0, buff: 0...
[2017-04-08 22:04:45,865] DEBUG    Site:1iD5ZQ..duGz Queried listModifications from: [] in 0.057s
[2017-04-08 22:04:45,973] DEBUG    Site:1TaLkF..jipT Signing 1491681886 for boot.zeronet.io#f36ca555bee6ba216b14d10f38c16f7769ff064e0e37d887603548cc2e64191d:15441 to add 6 onions
[2017-04-08 22:04:47,596] DEBUG    Site:1Gfey7..fcdp Announced types ['onion'] in mode startup to 5 trackers in 1.047s, errors: [], slow: ['1.05s http://tracker1.wasabii.com.tw:6969/announce']
```

Until we find solution for it I reverted back to old one

- [ ] Reproduce
- [ ] Fix Yes I suppose Yes, I planning to check it again.  yes, eg.: https://itunes.apple.com/us/app/pythonista/id528579881?mt=8
as for creating webserver on 127.0.0.1 i'm not sure...  Nice, thanks!  Adding selenium does not fixes it, because it also requires phantomjs and zeronet client running Thanks! Unfortunetly `docker run -d -v $PWD:/root/data -p 15441:15441 -p 127.0.0.1:43110:43110 nofish/zeronet` does not reflect the latest version (not to mention pull requests), so it makes the testing pointless. So we need other way to run the client.  Actually the back button is working for me in latest FF/Chrome/Edge. Maybe some plugin?  You added a simple page for it:
![image](https://cloud.githubusercontent.com/assets/10350359/24811203/4ec6b3ae-1bc5-11e7-95cd-f34b367a7061.png)
  You need to have ZeroNet client running on 127.0.0.1 to complete the tests  Currently due privacy reasons there is no way to list certificates, so I would recommend separate buttons for "create new identity" and "select identity"  Thanks for the heads-up I will update the libs. Using pip for dependencies would make the portable/exe/.app version really hard, that's why I decided to include them. Thanks for reporting, I have updated all of the libs to the latest version. 

The PyElliptic still has some updates via the BitMessage project: https://github.com/Bitmessage/PyBitmessage/tree/master/src/pyelliptic

The pyOpenSSL looks nice, but it has more dependencies and not pure-python, so I would stick with pyelliptic if possible.

I keep it open as I want to add automated way to update the libs to avoid the same problems in the future.  You can check the failed files on the sidebar. (please note files larger than 1MB not fully supported yet)
JS/CSS files are cached by the browser for 5 minutes, so for development: open Developers Tools (F12) then check Disable Cache on Network tab. (Chrome)  it works this way: `zeronet.py --trackers http://anything http://other --batch` (it should end with non-multivalue argument)  What operating system you using?  Yes, every user is also identified by valid bitcoin address (you can find your in data/users.json) For usernames you need to get a certificate from id provider. It's the provider resposibility to keep the usernames unique. The id provider only gives a signature to the user. (certs entry in your data/users.json) 
Actually after that you can even delete the id provider site.  you need 64bit openssl dlls for 64bit python  The plugins/Mute/languages/zh.json file has some merging junk left, pelase remove that file (and plugins/Mute/languages/zh-tw.json ) from commit  You are right it should be list, but acutally the multisig is disable atm. (https://github.com/MRoci/ZeroNet/blob/4a981e88ada8d26ef673639feb9d4db442818b9e/src/Content/ContentManager.py#L648) It would be a great addition, but needs more testing I think we can change it to list without supporting dict, since the multisig is not enabled yet, so there won't be any backward compatibility issue. Yeah change `valid_signers += self.contents["content.json"]["signers"].keys() 
` it simply to `valid_signers += self.contents["content.json"]["signers"][:] ` and I will accept it.  Thanks, fixed: d7ba9f6924f23266411edfda1e236f88ea318347  it was planned when I implemented the clone feature (that's why the "cloned_from" and "clone_root" data present in content.json), but I havent added this for the webui yet. It's definetly planned, but have to find a way to allow users to keep their customizations somehow It's added in 0.5.5  I don't speak german, but feel free to open a pullrequest. Thanks, fixed: https://github.com/HelloZeroNet/zeronet.io/commit/752d05210764a86dea98c380c664e8020c2de4fe  Thanks for reporting, fixed: https://github.com/HelloZeroNet/ZeroNet/commit/afcd6dfa14c2759ac12151a324e7051cea4fb38d  Probably you missing one of the required packages. Try run zeronet.py in terminal and see the error message. You have to enter `python zeronet.py`  Unfortunetly currently there is no way to do that. In the future it's planned to be able to request permission to another site's files and database, but ZeroMail messages are stored in encrypted form, so it's even more compliated.  Thanks, fixed!https://github.com/HelloZeroNet/ZeroNet/commit/50937990e54c9e4d4286c0f5407643ee8488be71  It's still under testing, it will be tagged later. You can always download the edge version from https://github.com/HelloZeroNet/ZeroNet/archive/master.zip  I think it would be better to not build this into ZeroNet client, but provide a cloneable site that take cares of the listing, so it would be possible to customize and enhance the listing.  Why is it necessary to send different port to the tracker and bind an another on the local machine? If you want to use different port, then you can use that on local machine. And how do we know the randomly assigned port number? The port checker can't get your external port as it not used in the connecting process (and you can have many of them), only your external ip.

It could be possible to add nat-pmp function for port opening, but I think upnp is more supported. I just tried https://pypi.python.org/pypi/NAT-PMP/1.0.1 and it's not working with my router. I don't have access enviroment like this, so it would be hard to develop for it.  I don't see it as a bug, why would anyone create a folder named any.tar.gz ?  I'm ok with this, but I think a `def actionFileList(self, to, inner_path, walk=True):` would be better, than a separate function  both port should be 15441. This is normal: Your internal and external IP is different.
- [find your computer's internal ip address](https://www.groovypost.com/howto/microsoft/windows-7/find-your-local-ip-address-windows-7-cmd/)
- Add new portforward: external/internal port both 15441, ip address your computer's internal ip
- Restart ZeroNet
- You should see Port: Opened It's hard to tell what's the problem, please try to enable uPnP on your router. On my TP-Link (TL-WR841N),
it's looks like this:
![image](https://cloud.githubusercontent.com/assets/10350359/23578367/676d1836-00d5-11e7-97ff-ad397a834ba3.png)
After you enabled it all you have to do is restart your ZeroNet client and it will open port for itself.

If it's not working,then please add a screenshot of the port forwarding page of your router's web interface.
  Thanks!  you can't but you can generate self-signed certs: https://github.com/HelloZeroNet/ZeroID/issues/3  ZeroNet download is multi threaded: 
 - Spawns 6 worker if you add new tasks
 - Try to assign 6 different task for these workers
 - If there is no 6 tasks, then it steals another worker's tasks, wait 1 sec to allow the current worker to finish it, if it's still not finished after 1 sec, then tries to download the same file in parallel.

The fileGet api command was not executed parallel, but it's fixed some weeks ago: https://github.com/HelloZeroNet/ZeroNet/issues/788  If stem using socket lib that is not ready for gevent, then it will not work It was temporary problem, re-running fixed it.  If you drag the zero button to left it shows what files missing from current site I have just added .tar.gz, .tar.bz2, .zip support in latest rev: 2854e20
example site: http://127.0.0.1:43110/1AsRLpuRxr3pb9p3TKoMXPSWHzh6i7fMGi/en.tar.bz2/index.html (please update your client before visit)

en dir uncompressed: 6.1MB, zipped: 1.5MB, tar.gz: 512KB, bz2: 247KB (!)
content.json size also greatly reduced 

I think this could help you in many cases:
- Javascript files compression rate is pretty good (3-5x)
- It also help to reduce content.json size, because the packed file is only takes up one entry
  Thanks, but I think it would be better as separate plugin, so you can avoid lots of ifs and does not makes the core source code more complicated. (it's easy check DonationMessage for example)

you can add to plugin's __init__.py like this:
```
try:
    import from stem.control import Controller 
    import StemPlugin
except:
   pass
```

and then easily override connect/addOnion/etc methods of TorController in StemPlugin.py Probably this is what needs to be modified: https://github.com/HelloZeroNet/ZeroNet/blob/master/src/util/SocksProxy.py#L6  probably it possible, but that part is pretty fragile: lots of different platforms with different version of python, gevent and openssl. I had really hard time to make it work on most of enviroment.

So any mondifiction there needs lots of testing.  Please update the latest version, it will fix it.  I just tested in firefox and chrome and both supports localstorage in private browsing, they just cleans it up after you close the window:

```
> localStorage.setItem("hello", "aha")
> localStorage.getItem("hello")
< "aha"
```

Probably some browser plugin block it for you  the easiest way currently is: 
stop it, run `python update.py`, start again Then you have: 
 - disable the Multiuser plugin
 - start it
 - update using the menu 
 - stop
 - enable Multiuser plugin again
 - start again

I will fix standalone update.py running and add a simpler method to update the proxy I just made it easy: From Rev1892 if you login with any user's master_seed from data/users.json, then you will have no restriction. So you can delete sites, update zeronet, etc.

It also have security enhancements, so the update is recommended.

Other modification is if you enable --multiuser_no_new_sites, then normal users will not able to add new sites (users in data/users.json still can)  I just made it easy: From Rev1892 if you login with any user's master_seed from data/users.json, then you will have no restriction. So you can delete sites, update zeronet, etc.

It also have security enhancements, so the update is recommended.

Other modification is if you enable --multiuser_no_new_sites, then normal users will not able to add new sites (users in data/users.json still can)  Thanks!  å™—ã€‚ã€‚é‡äº†ï¼Œå»ºè®®åŒæ­¥åŠ ä¸Šzh-tw  I have just tried and unable to reproduce it.

Same 53.0a2, "I have just tried and unable to reproduce it" checked in settings. Have you changed anything else?
  Have you moved the zeronet directory to anywhere?
If the 'core/src/Ui/template/wrapper.html' file still there?
Have you tried to restart it?  Ajax requests also failing in that environment  I was able to reproduce it and working on fix Fixed in latest rev: https://github.com/HelloZeroNet/ZeroNet/commit/f74e9397db20336835a72220321480328f4de477  This is expected and can't be fixed, because it's using the pythonw.exe which has no console.

You can use the lib\ZeroNet.cmd file if you need the console.  If you call the "innerLoaded" command, then it will got applied to your page:

https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/media/Wrapper.coffee#L104

(looks like I forgot to add it to docs, I will do) Added to docs  Sorry I don't understand what you try to say. What you mean by re-up and changes get ignored? What information you want to reset?  Drop off the net?  Probably your site is too large, you should keep it under 10MB to make it to every client.  `ls -al /proc/5988/cwd`  probably points to ~/.local/bin/ZeroNet and your site is created in ~/.local/bin/ZeroNet/data directory

  I think a general timeout (eg. 1 day) would be more usefull if the client unable to download an optional file for 1 day, then automatically gives up If you remove the optional files from your site (it's no longer in content.json), then it will immedietly disappears.

The timeout is not implemented yet, but it's for files that is still in content.json, but there is no peers for it.  yeah, the start.py is zeronet.py with browser opening  You can configure it using:   `--fileserver_ip ip    FileServer bind address (default: *)` It should be fixed by https://github.com/HelloZeroNet/ZeroNet/commit/d57d82f4398995389c390f344ee093027ff08d6b (also added other modifications to allow local addresses other than 127.0.0.1)  I don't think waiting is necessary, it would add +1 request to tracker after you visit the site: one for getting other's ips/onions and one for registering  I'm running it with gevent 1.2:
```
>>> gevent.version_info
gevent.version_info((1, 2, 0, 'final', 1))
```
Please make sure you have the latest version of zeronet

related commit: https://github.com/HelloZeroNet/ZeroNet/commit/9a1735f37dfc7f9a2f734783f38ca5c8a4e9cbc3  I see the problem, but whats the point adding it to the response? (the file shasum always checked after the download) 

I think all we need to do is add it to request to avoid the unnecessary downloads.  ZeroNet is single threaded, event-based, it means IO-related tasks (file/socket read/write) will execute concurrently, CPU-bound things (eg. signing a file, crypto-functions, database query) will block the application. 

I have tried to move this CPU-heavy functions to separate thread, but without any success. I have not given up on it, I will try it again later.

Currently one websocket connection can only execute one command at a time. So yes, the fileget will block it. It would be a good idea execute that async, I will check it later today. fileGet should be async now: https://github.com/HelloZeroNet/ZeroNet/commit/bf34d95bc121005fd82f07308dedf71c9be21773
base64 encoding and timeout also added: https://github.com/HelloZeroNet/ZeroNet/commit/54c553d13bbc2c01d1d69ab020592c29d180fa08  the site not signed properly, so cant download but this is normal: your site is avalible from  http://127.0.0.1:43110/chomping-at-the.bit/, so loading  http://127.0.0.1:43110/assets/anything won't work.

this should help: http://ricostacruz.com/til/relative-paths-in-jekyll  I can't test it, but thanks!  ref http://127.0.0.1:43110/17vUgpdVUpN4yWeMJJtid7AAeQfLahHtXH/?Post:3:How+to+run+ZeroNet+on+your+router

Running ZeroNet on the router can reduce carbon emissions, and as long as the router is not closed the entire LAN can be quick and easy access, the following, I will introduce how to run ZeroNet on the router.

![1484830875.jpg (1064x857)](http://127.0.0.1:43110/17vUgpdVUpN4yWeMJJtid7AAeQfLahHtXH/data/img/post_1_1484830875.jpg)

First of all, check whether your router install Padavan firmware and plug-in storage, if not, maybe it will not work.
(PS: if your router can not plug-in storage, maybe you can't run it.)

* * *

After that, ssh to router and execute the following command

```shell
opkg update && opkg install wget python-pip python-gevent python-greenlet tmux
```

Update and install these software, cd to your router's external storage, my hard drive on the router's directory is /media/AiDisk_a5, if you don't know where is your plug-in storge can be `df` command to view, /media directory that is.

`cd /media/AiDisk_a5`
Then, let's download ZeroNet:
`wget https://github.com/HelloZeroNet/ZeroNet/archive/master.zip`
Decompression:

`unzip master.zip`

Open the file manager, access \\\\[your_router_ip] (such as I was \\\\192.168.123.1) and then open inside the AiDisk_ax folder (x on behalf of your hard drive number, such as my AiDisk_a5), you can see just downloaded master. Zip and unzipped the ZeroNet-master folder underneath. Then rename the ZeroNet-master folder to ZeroNet, enter the folder, then open the zeronet.py file with npp or other editor, and add the following two lines under `import sys` and save

```python
from thread import stack_size
stack_size(32768)
```

In the current directory and then create a new zeronet.conf file, enter the following and save:

```
[global]
ui_ip = 192.168.123.1
```

Back in ssh, execute these command

```shell
cd ZeroNet
tmux
```

This will be displayed as follows:

![1484830120.png (774x374)](http://127.0.0.1:43110/17vUgpdVUpN4yWeMJJtid7AAeQfLahHtXH/data/img/post_1_1484830120.png)â€‹â€‹â€‹â€‹â€‹

Then enter `pip install -r requirement.txt`

Wait finished, then type`python zeronet.py`and enter.
Now, open your browser and go to [http://192.168.123.1:43110/](http://192.168.123.1:43110/).

![1484830875.jpg (1064x857)](http://127.0.0.1:43110/17vUgpdVUpN4yWeMJJtid7AAeQfLahHtXH/data/img/post_1_1484830875.jpg)


ï¼šï¼‰enjoy it  Add "/opt/lib/libcrypto.so.1.0.0" support for optware and entware router @ysc3839 if `python -c "import ctypes.util; print ctypes.util.find_library('crypto')"` work on your device, we needn't to do other change  #627  Um..If it can't start thread, it will show error to me, but works fine... ![](https://cloud.githubusercontent.com/assets/15062548/22105327/69ea2802-de7e-11e6-84b2-7ca4ca7e35df.png)
![image](https://cloud.githubusercontent.com/assets/15062548/22106348/4abb0564-de83-11e6-94a6-37127e57e1cf.png)
without any error
![image](https://cloud.githubusercontent.com/assets/15062548/22106617/87cb2bcc-de84-11e6-9c4b-7e966e4fdc47.png)
 Yes, you are right...But how to check it? better solution #780   Probably no: ZeroNet is single threaded and requires external C modules (gevent, msgpack). Probably it could be possible to replace gevent with go workers, but I don't think it's worth to do.

90% of the CPU power used by the database and the cryptography, but these parts already written in C. (Sqlite and Openssl) Python3 change is planned to this year, but I'm not sure if it improve the performance or not. I'm also not familiar with go, but I think it's safe to say, that it would be much harder to change it to go, than to python3.

Btw actually python is growing faster (in percentage), than go

![](https://zgab33vy595fw5zq-zippykid.netdna-ssl.com/wp-content/uploads/2017/09/growth_smaller_tags-1-1024x878.png)
via https://stackoverflow.blog/2017/05/09/introducing-stack-overflow-trends/ A quick rise also not a good measure of "future proofness" as the new languages tend to became fashionable and they could drop quickly when the hype let up (see: ruby/ruby-on-rails)

btw from: https://www.tiobe.com/tiobe-index/

Jan 2018 | Jan 2017 | Change | Programming Language | Ratings | Change
-- | -- | -- | -- | -- | --
4 | 5 | Â  | Python | 4.678% | +1.21%
19 | 13 | Â  | Go | 1.569% | -0.76%


 Swift, C#, Kotlin, Rust are all competitors for Go in many levels.  Thanks, fixed: https://github.com/HelloZeroNet/ZeroNet/commit/de14c55311ca561fdbcbe4e97b38f036bbd8f9bc  
![image](https://cloud.githubusercontent.com/assets/15062548/22005529/f39e5aaa-dc9e-11e6-94cb-6aafb544a5ec.png)
http://127.0.0.1:43110/Me.ZeroNetwork.bit/?Profile/1KNmG5rJUGhgUJGFbLkv2B5isaqu9PrZqi/17zvGKq1Vft7Fp8HhqgD7rpqcGi5wDDSQ4/baddream@zeroid.bit
http://127.0.0.1:43110/1KNmG5rJUGhgUJGFbLkv2B5isaqu9PrZqi/data/users/17zvGKq1Vft7Fp8HhqgD7rpqcGi5wDDSQ4/data.json Block someone in zerome code:

```
import os
import sys

help_text = '''
Save this file to 'ZeroBundle/Python/block_tool.py'
Useage:
    python block_tool.py site_hash user_hash
example:
    python block_tool.py 1KNmG5rJUGhgUJGFbLkv2B5isaqu9PrZqi 17zvGKq1Vft7Fp8HhqgD7rpqcGi5wDDSQ4
programmer:
cxg2014, 12hlearn, 12hstudy@zeroid.bit
'''


def make_block_file(filename):
    if os.path.isfile(filename):
        os.remove(filename)
        os.mkdir(filename)
        open(filename + '/blocked', 'w').write('blocked')


def block(hub, addr):
    if hub is None or addr is None:
        print('Error!')
        print(help_text)
        return
    filename = "../ZeroNet/data/{0}/data/users/{1}/%s.json".format(hub, addr)
    content = filename % "content"
    data = filename % "data"
    make_block_file(content)
    make_block_file(data)
    os.system('python ../ZeroNet/zeronet.py dbRebuild 1MeFqFfFFGQfa1J3gJyYYUvb5Lksczq7nH')
    print("Successful block " + addr + ' and rebuild DB')


if __name__ == '__main__':
    if len(sys.argv) == 3:
        block(sys.argv[1], sys.argv[2])
    else:
        print(help_text)

```
  1. If you visit a site it can download up to 10MB of data that required by the site (source code, database) If you want to have more data than that, then the site owner able to define optional files that only downloaded when a client requests it. 
Using the merger sites you can also split the database into multiple sites (eg. by based on category, date, language, etc.), so you will only download and receive updates for data you are interested in. The example for this is the Hubs for ZeroMe.
2. There is no content censorship filter and I don't see any easy solution for that. Who going to decide what content is problematic?
3. Sites have size limit, the connections has CPU time, re-connection thottle and content updates are also limited, but probably there is lots of attack vectors on that. (especially hard on Tor network where every connection is comes from 127.0.0.1)
4. Peers are stored locally, so the next time you fire up your client can connect to them (and query other IPs via PEX) without any trackers. Local peer discovery and DHT planned later.
5. The content download is proritized by type (html, js first), freshness (newest posts first) and based on browser GET requests. If the images marked as optional files, then it will not download until you request it.
6. There is no data re-use yet. Latest web framework produces a single build.js files that has everything packed-in, which makes it impossible to share between sites. And having a central site of js liblaries also against the decentralization idea.
7. Not that I know.
8. There is no backed, so you can't render html, but if you have a single page application, that has it's storage layer well separated, then I think its possible to re-use. Basically you can execute database queries directly from javascript and you have to keep in mind, that every data is public.
9. Currently you have to encrypt the parts you want to keep in secret. You can give write permissions based on site directories, but nothing more.
10. Basically you have to start your client with `--ui_ip "*"`, then it will be accessible to anyone on your public ip. (enabling Multiuser plugin also recommended)
11. You can use Tor to hide your IP

I hope this answers your questions :) 1. ZeroNet sites are designed to run locally. If you don't have the data you can't query/search in it. Currently the peers picked randomly.
2. It could be possible to add a plugin that displays a warning if you going to visit or already seeding a site that many user find problematic.
3. Sometime I add new limitations, but it's impossible to add efficient protection against a botnet with 1000 of machines. (or like I said on the tor network where there is no IP adresses)
4. .
5. Parts downloaded from different peers. When you visit a site it starts up 10 workers and each begin download different files. If they run out of task (<10 task remain) after some timeout (based on filesize) they start to download the same files using multiple peers and the first one win.
6. I don't see it as an important problem, so it's not planned yet.
7. .
8. No plans for backed, for security reasons every logic should run in the browser.
9. No plans for more detailed permissions yet.
10. Yes, you can enable the UiPassword plugin for that
11. You can use VPN and there is other ways to get around the block (see: Tor transport protocols) Yes, it's still very new and limited, but I think we should search for use-cases where it could work instead of focusing on what is it not good for.

Thanks for the questions (added the dots)  Thanks for reporting, Optional files no longer got removed on signing: https://github.com/HelloZeroNet/ZeroNet/commit/697e177e135eb7b9acfff53570df9119ec18c3bc  delete everything, re-download it and try again  it displays free space on your hdd, it's possible that function is not implemented in android python  By that we would loose the ability to update torrc later, so instead I would prefer configurable `tor_exe`, so if anyone wants to make modifications, then create a copy of the directory (eg `tools/tor-custom`) and change that settings.  Currently only ascii filenames supported (non ascii files will not be included to content.json), because I think utf8 filenames and urls are unreliable, some browser/forum engine/etc. encode it as urlencode, some leave it as it is, somewhere it does not works at all.
  I hope big file support could come earlier.   Thanks, changed, new key:
(1)     Tamas Kocsis (4096) <tamas@zeronet.io>
          4096 bit RSA key CB9613AE, created: 2017-01-15, expires: 2022-01-14  are the `,` necessary at the `('TCP', 'UDP',)` ?

```
>>> ("TCP", "UDP") == ("TCP", "UDP",)
True
``` For me it's looks like an unfinished function call, so i would prefer without it. (I know its necessary for tuples with only one element)  well, i don't think if thats the problem:
```
>>> re.search('Tor="([0-9\.]+)', '250-VERSION Tor="0.2.9.8 (git-a0df013ea241b026)"').group(1)
'0.2.9.8'
```

Can you please add a `self.log.debug("Tor protocol: %s" % res_protocol)` before that line? @MuxZeroNet he already did that, I think the problem is at https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Tor/TorManager.py#L243, have to put that line to a `while not data:` loop

I will try to reproduce the problem I have added a modification that queries version using GETINFO, please try it: https://github.com/HelloZeroNet/ZeroNet/commit/77e07dd5b5287d1b2abb4dc4cafd391b611ec95a Hm I don't have other ideas yet. I tried to reproduce it under windows, but no luck. Going to again with a VPS. I have just installed on Debian 8 and works for me:
```
# ./ZeroNet.sh --debug
...
[21:29:16] TorManager > PROTOCOLINFO
[21:29:16] TorManager < 250-PROTOCOLINFO 1
250-AUTH METHODS=COOKIE,SAFECOOKIE COOKIEFILE="/var/run/tor/control.authcookie"
250-VERSION Tor="0.2.9.8"
250 OK
...
[21:29:16] TorManager > GETINFO version
[21:29:16] TorManager < 250-version=0.2.9.8 (git-a0df013ea241b026)
250 OK
```
(same with experimental 0.3.x)

do you have any other ideas to reproduce it?

please try this one:
```
# python --version
Python 2.7.9
# python -c "import gevent; gevent.version_info"
version_info(major=1, minor=2, micro=0, releaselevel='final', serial=1)
# python -c "import gevent; import gevent.monkey; gevent.monkey.patch_all(); import socket; s = socket.socket(socket.AF_INET, socket.SOCK_STREAM); s.connect(('127.0.0.1', 9051)); s.send('PROTOCOLINFO\r\n'); print s.recv(1024)"
250-PROTOCOLINFO 1
250-AUTH METHODS=COOKIE,SAFECOOKIE COOKIEFILE="/var/run/tor/control.authcookie"
250-VERSION Tor="0.2.9.8"
250 OK
```

  Can you please past the ~10 lines before and after the hang? (when the time is skipped in the log files)

If it happens often please enable `--debug_gevent`, so it will log any hang that take more than 100ms. It looks like around site 1F7b27... can you try to pause it? And please give me the full address of this site, so i can try it myself. Probably it causes lots of other problems, so it's really not recommended to have that large site.   I think a `if self.env['REQUEST_METHOD'] != 'GET':` restriction will be enough for the `actionWrapper` (we catch OPTIONS earlier and POST to non-wrapper files are ok.  upnpopening is disabled in tor mode and why is it better raising IGDError instead of SOCKS5Error (I think it would be usefull to keep UpnpPunch.py standalone from other libs)  Thanks, fixed in latest rev: https://github.com/HelloZeroNet/ZeroNet/commit/bea212a8d1fbf314b5a40e8828d17ab9d0bec27a  Thanks for the suggestion, but is tor works in china (without transport protocols) at all? It would be nice to find  away to unpack tor.exe and the transport protocols from the .exe

I'm also thinking about packing it to zeronet-win (and mac) bundle, so we don't have to rely on the "network"
  Looks like something is blocking the internet access of ZeroNet Looks like you using outdated zerobundle, please download, unpack this one and try again: https://github.com/HelloZeroNet/ZeroBundle/raw/master/dist/ZeroBundle-win.zip  Thanks!  I have added 2 modifications:
 - https://github.com/HelloZeroNet/ZeroNet/commit/6c68f8dd6ccb351861ba5cb4854ac1b309e1ed15 Fix content type detection of "/anysiteaddress", so wrapper no longer allowed to load by json request
 - https://github.com/HelloZeroNet/ZeroNet/commit/1a5bfd973ec632dec143f0ac5a1b4a47216b1e9b Non-wrapper file requests will not start downloading sites

I think these should fix the problems Hm, probably we can't filter every "fake" request by headers. Tomorrow I will add a modification that will only add sites if valid wrapper_key present.  Thanks for reporting, fixed: https://github.com/HelloZeroNet/ZeroNet/commit/6a71bb256e7ff2e970f7adea5e1193c87f246ee4  From now git commits are signed https://github.com/HelloZeroNet/ZeroNet/commit/901478475fb15a910d3c99ccb161730b4e84ca25 Just, sent it, please check again  `zeronet.py --debug siteDownload anysite` should do that  Fixed in Rev1797: It will skip broken sites on startup and use crash-safe writing for root content.json file.  Yeah, I'm also uncertain about utf8 domain names, no one can tell the difference between Ðžnet, âµ”net, Onet, ÎŸnet or Onet (All uses different "0" character)

or for example: http://secret.É¢oogle.com  I'm not really familiar with mac ecosystem, whats the most regular way to install/distribute apps there?
 - What liblary should we use? PyInstaller, cx_freeze, etc?
 - Signing?
 - Automatization?
 - Source code packed into .app or separately in .zip/directory?
 - What about updates?
 - Is it possible to submit it to Mac app store?
 If every resource is in the .app, then if I update the source code, then it will make the signature invalid, isn't it?
Also where should I put the data dir/config/log/third-party plugins? I was able to create .app pretty easily with PyInstaller, but unfortunately looks like it's not possible to execute in terminal, is there any standard procedure for that? Also which one you prefer? Distributing a .zip-ed .app or .dmg packed .app? (with Application folder symlink and similar) OK, here is the plan then:
 - [ ] Create a .app that contains everything to run: Python, Full source code
 - [ ] Sign it
 - [ ] On startup it adds /Library/Application Support/ZeroNet as working directory, so data, log will be saved there and it also adds to python sys.path, so plugins amd updates also can be placed there
 - [ ] Pack it up as dmg somehow (does it needs to be signed aswell?)

What about permissions? I suppose you need to be admin to drag anything to Application dir or write to /Library/Application Support/

Maybe we should check on startup if we are in the /Application directory and if not, then switch to portable mode: Create "ZeroNet files" directory and save everything there. I tried to sign it with the .pfs i got from https://en.sklep.certum.pl/data-safety/code-signing-certificates.html, but the result is:
```
$ codesign --verbose --force --deep --sign "Open Source Developer, Tamas Kocsis" ZeroNet.app
ZeroNet.app: signed app bundle with Mach-O universal (i386 x86_64) [com.apple.ScriptEditor.id.ZeroNet]

$ codesign -v ZeroNet.app/
ZeroNet.app/: CSSMERR_TP_NOT_TRUSTED
In architecture: x86_64
```
Am I doing something bad or it's not possible to sign mac .app with third-party cert?

Update: according to [this](http://stackoverflow.com/questions/11833481/non-apple-issued-code-signing-certificate-can-it-work-with-mac-os-10-8-gatekeep), third-party certificates does not work on osx, so I need to pay 99USD/year to Apple :(  The source code will be stored in .app, but it will store updates in ~/Library/Application Support/ZeroNet Then it will use see same data.
On mac the normal install method is dragging the .app to /Applications directory. The application has no rights to write there, so it should write to ~/Library/Application Support/ZeroNet

Alternative it can be based on if the .app is in the /Application or not Horray! I was able to produce .app that accepted by the gatekeeper, but if I download it using safari it runs differently: on startup it got moved to /private/.../AppTranslocation/ read-only directory, so I'm not sure how can we make it portable
more info on that: http://lapcatsoftware.com/articles/app-translocation.html Strangely if you move the .app to anywhere (via Finder), then it's no longer got moved to /private... directory on startup.

So it can work like that: If the startup path is in /private or /Applications, then save data to ~/Library/Application Support/ZeroNet otherwise to local directory (where .app is).

My new concern is release-signing: My cert and private key are stored in MacOS (VMWare), so every time I make any new modification I have to boot up the VM, re-create the .app, sign it (takes minutes with --deep), then upload the new zip.

Is there any way to make it easier?

_Update_: 
This could work: https://www.bitrise.io/ I got it running (the .app is ~9MB zipped with full python and source code included), supports portable and installed deployment. The only significant problem left is after starting it the application icon got placed to the dock, but it does not do anything. I will try to find a way to handle at the click (opening browser window) or hiding it. This works as standalone (will try to implement as a plugin tomorrow):
```
from Tkinter import Tk
root = Tk()
root.iconify()
def click():
	import webbrowser
	webbrowser.open("http://127.0.0.1:43110")
root.createcommand('tk::mac::ReopenApplication', click)
root.mainloop()
```
This way we got an easy way to access ZeroNet, Exit and Open at login possibility. (as drawback it adds +8MB mem usage) thanks for the suggestion, i was able to make it work:

```python
import sys
import os
import time
import zeronet

def gui():
    global root
    print "Gui started"
    time.sleep(5)
    sys.path.append("/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-tk")
    sys.path.append("/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/")
    from Tkinter import Tk
    root = Tk()
    root.iconify()
    def click():
        "Click"
        import webbrowser
        webbrowser.open("http://127.0.0.1:43110")

    def quit():
        print "Quit"
        sys.exit(0)


    root.createcommand('tk::mac::ReopenApplication', click)
    root.createcommand('tk::mac::ShowHelp', click)
    root.createcommand('tk::mac::ShowPreferences', click)
    root.createcommand('tk::mac::standardAboutPanel', click)
    root.createcommand('tk::mac::Quit', quit)
    try:
        root.mainloop()
    except Exception, err:
        print "Gui error: %s" % err
    print "Gui ended"

def main():
    sys.argv = [sys.argv[0]] + ["--open_browser", "default_browser"] + sys.argv[1:]
    zeronet.main()
    print "Ended"
    root.destroy()

if __name__ == '__main__':
    from threading import Thread
    t = Thread(target=main)
    t.daemon = True
    t.start()

    gui()

```

~~On shutdown it triggers keyboarderror, and~~ I had to add `check_same_thread=False` to database connects, but it seems working ok. The code is just an experiment, I will remove the prints and the unnecessary parts.

I'm still not fan of the tkinter, but that's the best option we have now. I also tried PyObjC, but even the simpliest application takes 40MB of ram. 
I not going to include it to the bundle, but use the preinstalled one (if avaliable) + delay the load (`time.sleep(5)`, but will try to figurate out something smarter) to not slow down the startup time. I have added the files [here](https://github.com/HelloZeroNet/ZeroNet-mac/tree/dist), but unfortunetly for some unknown reasons the signature become invalid:
```sh
ZeroNet-mac $ find ZeroNet.app -type f -print0 | sort -z | xargs -0 shasum > sum.sha | shasum
da39a3ee5e6b4b0d3255bfef95601890afd80709  -
ZeroNet-mac $ codesign -v --verify ZeroNet.app
ZeroNet.app: valid on disk
ZeroNet.app: satisfies its Designated Requirement
```

```sh
ZeroNet-mac-dist $ find ZeroNet.app -type f -print0 | sort -z | xargs -0 shasum > sum.sha | shasum
da39a3ee5e6b4b0d3255bfef95601890afd80709  
ZeroNet-mac-dist $ codesign -v --verify ZeroNet.app
ZeroNet.app: code object is not signed at all
In subcomponent: /Users/sumo/Downloads/ZeroNet-mac-dist/ZeroNet.app/Contents/MacOS/core/CHANGELOG.md
```

Any idea why? Ah I took 7 hours of googling, trying and dumping, I almost gave up on it, but then got it:

The codesign adding separate signature to every file in the MacOS directory. Usually it puts these signatures into the binary files content, but since we had .py files, it couldn't. In this cases it's using extended attributes (xattr) to store the signatures. 
Git don't sync these attributes, so they lost after the commit and the verification failed after the download. 
The two directories seemed to be the exact same: Every file had the same shasum, same permissions, only the xattr was different. (That I never heard before)

The solution was simple: move the .py files from the MacOS directory to the Resources. (It also fixed the 6 minute signature time) I was able to reduce the added data to .git directory from 2.5MB to 50kb, by moving the Python standard lib from the executable to external file. So I think the hard part is done, what is left:
- [x] The dock icon does not disappear on webUI exit
- [x] Test portable update
- [x] Test Library update
- [x] Test portable autorun
- [x] Test Library autorun
- [x] Test on El Capitan
- [x] Test on Yosemite
- [ ] Change link on ZeroNet.io
- [ ] Auto-release via @bitrise-io I have been fighting on an older macOS (10.9) with `ImportError: dlopen(/Users/user900818/Downloads/ZeroNet2.app/Contents/MacOS/pyexpat.so, 2): Symbol not found: _XML_SetHashSalt` error since yesterday. I tried to pack the required dylibs, but without any luck (python still loaded the system default one)

Switching to conda looks like fixed it and the zipped .app also become smaller: 8.7MB -> 7.9MB

just for the record, commands I used to install conda:
```
bash Miniconda2-latest-MacOSX-x86_64.sh
conda install gevent
conda install msgpack-python
conda config --add channels conda-forge
conda install pyinstaller
```

Update
Of course it's not this simple: The generated .app no longer accepted on 10.12 (Identity of the developer cannot be confirmed.) regardless

```
$ spctl -a -t exec -vvvv ZeroNet.app
ZeroNet.app: accepted
source=Developer ID
origin=Developer ID Application: Tamas Kocsis (4977YF9Q3Z)
$ codesign -v --verify ZeroNet.app/
ZeroNet.app/: valid on disk
ZeroNet.app/: satisfies its Designated Requirement
```

*sigh*

Update 2
Reverted back to normal (non-conda) version, with conda's libexpat.so. Looks like it working on both 10.12 and 10.9. Horray! (for now) After some testing it's looks like working well in 10.9 (using http://www.macincloud.com/), 10.11 and 10.12

The macincloud.com stored the applications in `/Users/userXX/Library/Managed Items/My Applications` so I also added ~/Library/* to non-portable mode (store data in ~/Library/Application Support instead of same directory as the .app)

I will re-create the ZeroNet-mac repo (to keep it small), change the link on zeronet.io, then start experimenting with bitrise. Well yeah, it happened:
It's working on 10.9, 10.11, 10.12, but not on 10.10.
```
$ ZeroNet.app/Contents/MacOS/ZeroNet
Error loading Python lib '/Users/sumo/Downloads/ZeroNet-mac-dist/ZeroNet.app/Contents/MacOS/.Python': dlopen(/Users/sumo/Downloads/ZeroNet-mac-dist/ZeroNet.app/Contents/MacOS/.Python, 10): no suitable image found.  Did find:
	/Users/sumo/Downloads/ZeroNet-mac-dist/ZeroNet.app/Contents/MacOS/.Python: code signature invalid for '/Users/sumo/Downloads/ZeroNet-mac-dist/ZeroNet.app/Contents/MacOS/.Python'
```

Regardless
```
$ codesign -vvvv ZeroNet.app/Contents/MacOS/.Python 
ZeroNet.app/Contents/MacOS/.Python: valid on disk
ZeroNet.app/Contents/MacOS/.Python: satisfies its Designated Requirement
$ codesign -vvvv ZeroNet.app/
ZeroNet.app/: valid on disk
ZeroNet.app/: satisfies its Designated Requirement
```

Tried to google the error, but no solution found, so currently experimenting with Py2app instead of PyInstaller...
  It would be nice to have a more regular, .exe releases for windows that also includes the source code, so no need to download it from github on first startup.
 - What liblary should we use? PyInstaller, py2exe, etc.
 - Single executable (unpacked to temp directory on startup) or normal, 6-7 file distribution?
 - Signing?
 - Automatization?
 - Source code packed into .exe or separately in .zip/directory?
 - What about updates?
 - Plugins?
 - Is it possible to submit it to Windows Store?
 - Alternative .msi or .exe installer with autostart option?
 - Where to store data/config file/third-party plugins? I was able to create a .exe with PyInstaller. It's less than 10MB (zipped) with everything packed in: Python, ZeroNet source code and dependecies, Coffeescript, Openssl, msvc*dlls

Currently it's looks like this:
![image](https://cloud.githubusercontent.com/assets/10350359/21703806/0075c5e4-d3b5-11e6-8579-dd30fa26b26b.png)

So pretty messy....It would be nice to move the supporter files to separate directory eg. Lib.

# Need help

Unfortunately PyInstaller did not support this (https://github.com/pyinstaller/pyinstaller/issues/1048), so it would be nice if anyone could add this feature or modify the bootloader: https://github.com/pyinstaller/pyinstaller/tree/develop/bootloader

# Other todo:
 - [X] Higher resolution icon
 - [ ] Data/Log dir outside of Include
 - [ ] Test  update from https/zeronet
 I'm not talking about single file exe, but to move the .dll and .pyd files to a sub-directory to make it look more clean and more easy to find the executable. The keep it updateable from zeronet network the full source code is still there, it's in the Include directory. (I'm not sure about this name, maybe we should name it something different, ideas?)

I found a company that give cert for opensrouce applications for 14EUR: https://en.sklep.certum.pl/data-safety/code-signing-certificates/open-source-code-signing.html

Already signed up, but it requires Java and the interface is half polish, so I was unable to complete the registration, will try again later. At least we can sign the zeronet.exe in the zip to avoid the notification about unsigned application. I found that it's possible to move the directly imported pyd files to different directory, so it's looks better now:

![image](https://cloud.githubusercontent.com/assets/10350359/21745435/4dddf3ba-d52c-11e6-8f3a-fc0799ee62e8.png)

Any ideas on the directory name where the .py files (zeronet source code) will be stored? Some ideas:

 - Source (we already have an src directory, so in this case it will be Source/src/ which is a little bit odd)
 - Include
 - Application
 - Program FIles (just kidding)
 - Core
 - System
 - Support
 - Runtime
 It's generated by pyinstaller
> You should sign all .dll files includes .pyd files.

I don't think os or python checks the signatures. New problem: I want to create a zip that have everything to go (python, openssl, sourcecode), but this means the .zip has to be updated pretty often. Which will make the ZeroBundle repository huge.
Sure, I could distribute the files from zeronet.io, but it would make it easy to block.
Is there any way to to replace binary files in git repo without keeping the history? (or any trick to keep the .git directory smaller) Yeah, but it makes the mirroring harder, since it does not get propogated automatically to:
- https://try.gogs.io/ZeroNet/ZeroNet
- https://gitlab.com/HelloZeroNet/ZeroNet

New idea: Instead of uploading the zip file, create separate repository for ZeroNet-win / ZeroNet-mac, add the exe/app/ddl/pyd and the source code as normal files, then let the provider to pack it, eg.: https://github.com/HelloZeroNet/ZeroNet/archive/master.zip

Is there any way to mirror the commits? So any commit that is submitted to ZeroNet repository have to be also added to ZeroNet-win/core directory signed, .exe version: https://github.com/HelloZeroNet/ZeroNet-win/archive/dist.zip
 what do you mean by that? I think we had windows xp compatibility issues with that I think when I first published zerobundle it refused to work under windows xp without a .manifest file, but if someone could try it that would be nice. I juist tried to embed the manifest, but then just drops this error (win10):
`Cannot open self f:\Work\ZeroNet-git\ZeroBundle\PyInstaller\dist\ZeroNet\ZeroNet.exe or archive f:\Work\ZeroNet-git\ZeroBundle\PyInstaller\dist\ZeroNet\ZeroNet.pkg`

The command was: `..\..\tools\mt.exe -nologo -manifest "dist\ZeroNet\ZeroNet.exe.manifest" -outputresource:"dist\ZeroNet\ZeroNet.exe;1" ` So the dlls should be in both directory? (lib and beside zeronet.exe) Fuck, then have to find a way to move everything to the lib dir

maybe stick with .cmd and just convert it somehow to an exe Other option could be modifying the bootload to load the dlls from lib directory: https://github.com/pyinstaller/pyinstaller/blob/c14333fc7498d261e1ce47d2354ecaecc88037d2/bootloader/src/pyi_utils.c#L736 Unfortunetly i have no experience with C, so maybe it's better to pack as an exe that unpack to temp dir every time on startup. (im not fan of this solution, but probably the best we have) or simply drop the portable version and distribute it as an a exe/msi installer. py2exe has not been updated since 9 years, so i would avoid it. (and I think it's also does not support moving dll-s to separate directory) As a workaround it will copy the dll-s to the lib dir on startup. (this way it does not makes the .zip larger)

Also included .manifest using ResourceHacker.exe and added dual (SHA1 & SHA256) signature. 
https://github.com/HelloZeroNet/ZeroBundle/commit/f544a9c2e708390134d4c9b0e42db195a89a903c
Please test if you can: https://github.com/HelloZeroNet/ZeroNet-win/archive/dist.zip Exe is not released yet, it just testing, but after that the zerobundle will not be supported. Another "easy" problem: Zeroner runs 3 times slower and using 10 times more memory in .exe from:

```
Benchmarking ZeroNet 0.5.1 (rev1830) Python 2.7.12 (v2.7.12:d33e0cf91556, Jun 27 2016, 15:19:22) [MSC v.1500 32 bit (Intel)] on: win32...

CryptBitcoin:
- hdPrivatekey x 10..........0.192s [x3.65: Insane!!]
- sign x 10..........0.104s [x3.37: WOW]
- openssl verify x 100..........0.464s [x0.80: Goodish]
- pure-python verify x 10..........0.532s [x3.01: WOW]

CryptHash:
- sha256 5M x 10..........0.197s [x3.05: WOW]
- sha512 5M x 10..........0.244s [x2.46: Fast]
- os.urandom(256) x 100 000..........0.085s [x7.65: Insane!!]

Msgpack:
- pack 5K x 10 000..........1.427s [x0.55: Goodish]
- unpack 5K x 10 000..........0.705s [x1.70: Fast]
- streaming unpack 5K x 10 000..........0.636s [x2.20: Fast]

Db:
- Open x 10..........0.054s [x2.41: Fast]
- Insert x 10 x 1000..........2.237s [x0.45: Ehh]
- Buffered insert x 100 x 100..........2.483s [x0.52: Goodish]
- Total rows in db: 20000
- Indexed query x 1000..........0.690s [x0.36: Ehh]
- Not indexed query x 100..........0.251s [x2.39: Fast]
- Like query x 100..........0.422s [x4.27: Insane!!]

Done. Total: 10.92s
```

vs run using python.exe zeronet.py:

```
Benchmarking ZeroNet 0.5.1 (rev1830) Python 2.7.12 (v2.7.12:d33e0cf91556, Jun 27 2016, 15:19:22) [MSC v.1500 32 bit (Intel)] on: win32...

CryptBitcoin:
- hdPrivatekey x 10..........0.185s [x3.78: Insane!!]
- sign x 10..........0.094s [x3.72: Insane!!]
- openssl verify x 100..........0.117s [x3.16: WOW]
- pure-python verify x 10..........0.507s [x3.16: WOW]

CryptHash:
- sha256 5M x 10..........0.150s [x4.00: Insane!!]
- sha512 5M x 10..........0.206s [x2.91: WOW]
- os.urandom(256) x 100 000..........0.071s [x9.15: Insane!!]

Msgpack:
- pack 5K x 10 000..........0.214s [x3.64: Insane!!]
- unpack 5K x 10 000..........0.319s [x3.76: Insane!!]
- streaming unpack 5K x 10 000..........0.342s [x4.09: Insane!!]

Db:
- Open x 10..........0.012s [x10.83: Insane!!]
- Insert x 10 x 1000..........0.346s [x2.89: WOW]
- Buffered insert x 100 x 100..........0.497s [x2.62: WOW]
- Total rows in db: 20000
- Indexed query x 1000..........0.084s [x2.98: WOW]
- Not indexed query x 100..........0.158s [x3.80: Insane!!]
- Like query x 100..........0.289s [x6.23: Insane!!]

Done. Total: 3.78s
``` Hmm...well...hmm any idea?
![image](https://cloud.githubusercontent.com/assets/10350359/22183240/6f071236-e0b9-11e6-87d0-adcc27a99b4a.png)

The frozen script:
```
import sqlite3, time

db = sqlite3.connect("test.db")
s = time.time()
db.execute("CREATE TEMP TABLE t(x INTEGER PRIMARY KEY ASC, y);")
for i in range(100000):
	db.execute("INSERT INTO t VALUES (%s, 'test')" % i)
print time.time() - s
raw_input(">")
``` It's not possible to sign .cmd, firewall/os restrictions can be problematic with python.exe, it also means less files

but this problem seems like not related to frozen mode. if I rename python.exe to zeronet.exe and run the included script with it, then it's also 18 times slower and using 10 times more memory. restarting windows does not fixes it.

can anyone check the same? deleting "HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Image File Execution Options\ZeroNet.exe" looks like fixed it...

I have not saved the value of it before the delete, probably somehow windows put it into special debug mode or similar.... The CPU-hungry parts already written in C, so Cython would not help there  Please explain your question The storage and the bw used by js libs are negligible and different sites requires different version libs, so it would be a mess.  probably one of the plugins blocking it, please try in incognito mode and in other browser. Then try to delete and re-download it maybe its got damaged during the dl/unpack Yeah it's the "x-css" line is the problem, if you go to the network tab and select the first all.css what does it look like?
Here is mine:
![image](https://cloud.githubusercontent.com/assets/10350359/21659557/a62f47ac-d2cb-11e6-9ef7-e209eba715a7.png)
 I added a modification that hopefully will fix it: https://github.com/HelloZeroNet/ZeroNet/commit/5c2b90c20f0760db7b2d2c82e4344a55012e36f6

Please update to latest version and try again: The easiest way to do that is delete ZeroNet directory and start zeronet.cmd again, so it will re-download it.  It usually happens if you someone has a site in the browser that in no longer in the client  I don't thing proof of work is a good solution to protect against spam: For example if we require 1 minute CPU time POW (really annoying) before to submitting new comment a spammer with a decent GPU would still able to send 100+ messages / minute.  try `stats_content = requests.get('http://127.0.0.1:43110/Stats', headers = {"Accept": "text/html"}).text` I searched for `ParsePeers` on ZeroHello and dropped this result:
http://127.0.0.1:43110/1CiDoBP8RiWziqiBGEd8tQMy66A6fmnw2V/?Post:7  this limitation is not in zeronet, but in the browser, so i cant modify it, but if you use the same way to load the resources as other zeronet sites, then it should be fine  cc @sirMackk  You need to forward port 15441 to your local ip, but zeronet should also work fine without any opened port.  @iShift Thanks, https://github.com/HelloZeroNet/ZeroMe/issues/27 Block someone in zerome code:

```
import os
import sys

help_text = '''
Save this file to 'ZeroBundle/Python/block_tool.py'
Useage:
    python block_tool.py site_hash user_hash
example:
    python block_tool.py 1KNmG5rJUGhgUJGFbLkv2B5isaqu9PrZqi 17zvGKq1Vft7Fp8HhqgD7rpqcGi5wDDSQ4
programmer:
cxg2014, 12hlearn, 12hstudy@zeroid.bit
'''


def make_block_file(filename):
    if os.path.isfile(filename):
        os.remove(filename)
        os.mkdir(filename)
        open(filename + '/blocked', 'w').write('blocked')


def block(hub, addr):
    if hub is None or addr is None:
        print('Error!')
        print(help_text)
        return
    filename = "../ZeroNet/data/{0}/data/users/{1}/%s.json".format(hub, addr)
    content = filename % "content"
    data = filename % "data"
    make_block_file(content)
    make_block_file(data)
    os.system('python ../ZeroNet/zeronet.py dbRebuild 1MeFqFfFFGQfa1J3gJyYYUvb5Lksczq7nH')
    print("Successful block " + addr + ' and rebuild DB')


if __name__ == '__main__':
    if len(sys.argv) == 3:
        block(sys.argv[1], sys.argv[2])
    else:
        print(help_text)

```
  bit.no.com (or any other proxy) is not run by ZeroNet project. Please try to contact the proxy owner.  It's already there (allows +1 day from local time): https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Content/ContentManager.py#L758 This does not protect from post timestamp modifications. (zeronet does not filter data.json content)
The future post filtering have to be implemented in every site's js code independently.
Just added future post filtering to followed users on ZeroMe site: https://github.com/HelloZeroNet/ZeroMe/commit/e7b23f1eb579cc3ef1307c7036ed7e8d4a49666a  Thanks!  Thanks, fixed in Rev1791 9a1735f37dfc7f9a2f734783f38ca5c8a4e9cbc3 The fix was:
```
try: 
    from gevent.coros import RLock 
except: 
    from gevent.lock import RLock 
```
So you need
```
try: 
    from gevent.coros import RLock, Semaphore
except: 
    from gevent.lock import RLock, Semaphore
```  - If you want by you can bind to 127.0.0.2 `--ui_ip 127.0.0.2` (but is it any better?)
- Editing host file require root/admin permissions.   Non-ascii filenames not supported atm and automatically removed from sites.  ZeroNet does not include [Tor pluggable transports yet](https://www.torproject.org/docs/pluggable-transports.html.en). The easiest way to use that is starting the Tor browser, configuring the pluggable transports, then modifing ZeroNet's config to use the browser's tor client by starting it with `--tor_controller 127.0.0.1:9151 --tor_proxy 127.0.0.1:9150` or adding it to zeronet.conf
```
[global]
tor_controller = 127.0.0.1:9151
tor_proxy = 127.0.0.1:9150
```  This error comes from chrome browser.
https://wyldeplayground.net/terminal-errors-concerning-netflix-in-google-chrome/

If you want you can disable the browser window opening by replacing start.py with zeronet.py in zeronet.sh  the clone site has wrong size_optional Info. I just cloned BlueHub and everything looks fine for me:
```
{  
   "to":1000001,
   "cmd":"response",
   "result":{  
      "tasks":0,
      "size_limit":10,
      "address":"12F55EiSQ2drprqCyKdrpSbz5tP8JKexLy",
      "next_size_limit":10,
      "auth_address":"1QE9utGYcEmUn9hXi6qtGmdpC52BmkCPgg",
      "auth_key_sha512":"ce9ce537872f708d4d7437a9ccda8e873434395e9a74c9fbaef4f7ec415ecb5e",
      "content":{  
         "files":2,
         "description":"Welcome to ZeroMe! Runner: Nofish",
         "cloned_from":"1BLueGvui1GdbtsjcKqCf4F67uKfritG49",
         "clone_root":"",
         "includes":1,
         "cloneable":true,
         "address":"12F55EiSQ2drprqCyKdrpSbz5tP8JKexLy",
         "inner_path":"content.json",
         "merged_type":"ZeroMe",
         "title":"myBlueHub",
         "files_optional":0,
         "signs_required":1,
         "modified":1483124576.748,
         "ignore":"((js|css)/(?!all.(js|css))|data/.*db|data/users/.*/.*)",
         "zeronet_version":"0.5.1",
         "postmessage_nonce_security":true,
         "address_index":74815259,
         "background-color":"white"
      },
      "peers":1,
      "auth_key":"f442166a02cb1062a572c8a3cc87a8fcc88d215f1311164759342c1d161798f8",
      "settings":{  
         "peers":0,
         "serving":true,
         "optional_downloaded":0,
         "size_optional":0,
         "modified":1481138875.097,
         "cache":{  

         },
         "own":true,
         "permissions":[  

         ],
         "added":1483124576,
         "size":4006
      },
      "bad_files":0,
      "workers":0,
      "privatekey":true,
      "cert_user_id":null,
      "started_task_num":0,
      "content_updated":null
   },
   "id":1
}
```  I have just tried and it's compiled for me without any error Yeah, i forgot i have a node based coffeescript compiler (it's faster) (`type %s | tools\coffee-node\bin\node.exe tools\coffee-node\bin\coffee --no-header -s -p`)

I will try whats happens with the wsh-based one.

Alternative you can edit the all.js directly or make ZeroBlog multilanguage by adding 
```
 "translate": [
  "index.html",
  "js/all.js"
 ],
```
to content.json, then creating languages/zh.json and specify what you want to replace. (see ZeroTalk for example)  Do you have any suggestions to detect real browser opening?
It could be possible to check http headers, but I'm not sure how reliable it is when using less-known features like
```
<link rel="prefetch" href="http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D">
``` I have added some restriction, so loading site as image/prefetch should no longer work. https://github.com/HelloZeroNet/ZeroNet/commit/86b0046f287f1a24a9fcb216fd1a31ea49823ee6
It's not final solution, but better solution (testing if rendering and js execution available) needs more changes.  ZeroNet itself does not execute anything downloaded from the network, so it's not possible to display notifications if the site is not running in the browser.  The possible solutions are:
 - If you run out of limit delete the oldest comment you made (automatize this)
 - Create your own hub and increase the limit for yourself
  Thanks!  It's the sandboxed iframe's limitation and I don't know any workaround for it. I'm not sure if it's bug or a feature, there is lots of result if you search for "blob:null sandboxed iframe" on google You mean big file support by "video support"? I can't change the sandbox limitations, but adding a new "wrapperRequestFullscreen" could be possible. `Page.cmd("wrapperRequestFullscreen")` added in latest rev: https://github.com/HelloZeroNet/ZeroNet/commit/5103879471176fced494dc70d35e8384275f787e  Thanks, probably it's depends on what unpacker application you have used.
It would be nice if someone could help me how to make a proper .dmg from it.  I dont think its necessary, since we change the working path to zeronet's directory on startup: https://github.com/HelloZeroNet/ZeroNet/blob/master/zeronet.py#L14  If you are not running in debug mode or don't have werkzeug python package installed, then this is normal  Thanks!  Thanks!  Thanks!  This error happens if the key parameter is not supplied at all (or null passed), so eg.: Page.cmd("aesDecrypt", ["iv", "enryptedtext", null])
Please check the Dev console's network tab websocket entry to see if correct number of paramters sent.  It should work, are you sure your user has the permission to write in the data directory and you client is not running already? I have just tried and it's works with "Standard user" (OSX 10.11)  Thanks!
I think we should not translate network/log messages  Earlier ZeroNet returned simple string on errors. Some month ago it got changed to object and that's why it's happening.  At the time of the plugin release I was about to add this feature, but then decided not to add it as it would reduce the performance and add code complexity. (having per-proxy language is also reduces centralization)
Probably cookie would be better as simple http requests and websocket messages also needs to be translated.
  Thanks!   - There is some protection against connection flooding or rapid requests. (it will slow down the reponse time if X cpu time is used by peer)
 - The client start downloading the files from random peers and keep trying until it's finishes

It's really hard to protect these kind of attacks (especially on Tor network where every request come from 127.0.0.1), but the result of this attacks are much less spectacular, than attacking a normal web site, since it's served from your computer so you will still able to access pages and only delays the updates
 On clearnet it could be possible, to not serve the same file to the same client, but the Tor network does not provide any information about the request sender and it's still would not work against attacks that involves 100s of computers.

The zeroid is generation is limited by the cert issuer. Currently it's only a simple js check but later captcha/facebook/email/crypto-burning etc. verification could be added. I think proof of work not suitable to solve this problem, because the attacker could use highend-cpu/gpu to solve it and still generate 1000s users/hour.

You can block users by id, look for banexample in data/users/content.json

Here, Github, ZeroTalk is the best places to ask questions I don't know any cryptocurrency that is CPU-only. 30 minute is already too much for most of the users to wait to be able to post new comment, but it's nothing for a spammer (you can rent a VPS for 1EUR/month) from their page: "Do not put yourself in danger. Our anonymity is not yet mature.", so i think it would be a bad idea to use it, and even if they solution is technologically right less user/node means less anonymous/secure.

yes, zeronet using self-signed certs, so mitm is possible on non-tor connections, i dont think blockchain is a good place to store this information (and also requires to every client run full node)
.onion connections are mitm safe, so adding a .onion only mode would be easier  - A new update is distributed as a "diff", so while your computer is online and connected to the network you will receive only the changed lines, but if you re-connect to the network you re-download the entire changed files
- The files that requested by your client (via http) will be prioritized  add `--tor disable` to the parameters, so it won't try to fire up internal tor  Thanks for reporting, it should work now: c1fd2be8cfadf3e93ae70e3d9763875460bb81a3  Fixed!  Thanks!  ZeroNet only support websocket api, no alternative API planned yet IPFS written in GO, so it would require different toolset to run it. But there is many alternative to IPFS: BitTorrent, StorJ, Maidsafe, Sia, etc., every site owner able to choose the best one that fits to his/her needs. It's just an API, but you still need to compile the Go client to run it. With the optional files support it's also possible to share big files using ZeroNet, but the problem is most of the users are using ZeroNet using Tor, which is not suitable to transfer big files.  Yeah, missed that one. Addig "Site control" will work: e2d73637f62eb13548c2a3bdb7bb9191ade92874  The line 714 in ContentManager.py:
`                if not re.match("^%s$" % rules["files_allowed"], file_inner_path):`

Your files_allowed pattern in data/users/content.json is invalid: `"files_allowed": "*.json"` it should be: `"files_allowed": ".*json"`
  some titles are overflow, fixed some in the latest revision, but there is some I cant
![image](https://cloud.githubusercontent.com/assets/10350359/20609833/d9d8626e-b291-11e6-85e8-c3729def4b32.png)
  You can specify the viewport in content.json, example from ZeroTalk: https://github.com/HelloZeroNet/ZeroTalk/blob/master/content.json#L81 I have no smartphone, but in the emulator it's seems pretty comfortable to use: double tap right section if you want to read the newsfeed, double tap left section if you want to browse sites you seed
The layout is already fluid, so you dont have to scroll horizontally Yeah I meant the chrome's responive tester by the emulator. I have an old nokia phone. (1110 or similar)  It's missing a { from the beginning  Thanks!  It's not possible to list, because you can translate any string.

There is tons of javascript localization frameworks, you can use any of them if you want. I'm not familiar with it, but I have added every string to the hu.json file  Please open the PR to the main branch.
  If there is not title, then it can't be displayed in the list, so it's a requirement. 
  Thanks, please use "pt.json" and also translate other files:
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Translate/languages/hu.json
https://github.com/HelloZeroNet/ZeroHello/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroMe/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroTalk/blob/master/languages/hu.json
 there is no convencion for that, possible solutions: `pt-br.json`, `pt-BR.json`, `pt_BR.json` all used and looks fine for me, but please make the pt-pt.json as pt.json (like the current ones)
  Thanks, please also translate other files:

https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Sidebar/languages/hu.json
https://github.com/HelloZeroNet/ZeroHello/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroMe/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroTalk/blob/master/languages/hu.json
  If someone want to help add new languages, the files needs to be translated:

https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Translate/languages/hu.json
https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Sidebar/languages/hu.json
https://github.com/HelloZeroNet/ZeroHello/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroMe/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroTalk/blob/master/languages/hu.json

Simply make a copy of them to the same dir where they are with the language short code you are going to translate to and replace the Hungarian translation.

To test them before submitting to github:
- By default ZeroNet uses the operating system language, but you can also specify it in zeronet.conf (where zeronet.py is)
- Open sidebar, check "This is my site"
- Open javascript console (F12) check "Disable cache" on Network tab to avoid caching, keep window open
- To reload Core language files (src/Translate/languages/hu.json and plugins/Sidebar/languages/hu.json) without restart you have to click on you language again on ZeroHello's 3dot menu
  It's only used for UPNP port opening: https://en.wikipedia.org/wiki/Universal_Plug_and_Play
  ZeroNet by default does not writes to /etc, please use the zerobundle package or report it to the package maintainer.

other option is add write permissions to /etc/zeronet.conf modify to:

```
[global]
tor = always
```
  Thanks!
 Please also translate these files, so I can also add it to ZeroHello:

https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Sidebar/languages/hu.json
https://github.com/HelloZeroNet/ZeroHello/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroMe/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroTalk/blob/master/languages/hu.json

Simply make a copy of them to the same dir where they are with the language short code you are going to translate to and replace the Hungarian translation.

To test them before submitting to github:
- By default ZeroNet uses the operating system language, but you can also specify it in zeronet.conf (where zeronet.py is)
- Open sidebar, check "This is my site"
- Open javascript console (F12) check "Disable cache" on Network tab to avoid caching, keep window open
- To reload Core language files (src/Translate/languages/hu.json and plugins/Sidebar/languages/hu.json) without restart you have to click on you language again on ZeroHello's 3dot menu
  After the lastest update i get this error starting zeronet. 
using arch linux arm on raspberry pi.
python version: 2.7.12

```
- Starting ZeroNet...
Traceback (most recent call last):
  File "./zeronet.py", line 15, in main
    import main
  File "./src/main.py", line 25, in <module>
    from Config import config
  File "/usr/lib/python2.7/site-packages/gevent/builtins.py", line 93, in __import__
    result = _import(*args, **kwargs)
  File "./src/Config.py", line 343, in <module>
    config = Config(sys.argv)
  File "./src/Config.py", line 17, in __init__
    self.createArguments()
  File "./src/Config.py", line 51, in createArguments
    language = language.split("_")[0]
AttributeError: 'NoneType' object has no attribute 'split'

``` Can you please run: 
`python -c "import locale; print locale.getdefaultlocale()"`
and
`locale -a`
 $ python2 -c "import locale; print locale.getdefaultlocale()"
(None, None)

$ locale -a
C
POSIX
en_US.utf8

Edit: Ran "localectl set-locale LANG=en_US.UTF-8" and works now, thanks a lot for the help. Issue can be marked as soved/closed
 It's fixed in latest version  it's using bell utf8 character: ðŸ”” http://graphemica.com/%F0%9F%94%94
probably you are missing some fonts on your machine
 It's defined as Arial, Helvetica, 'Segoe UI Symbol', but if these are not present on your system, then it should fall back to systemdefault
 https://jsfiddle.net/kha51nn0/
is any of these works for you?
  You can confirm the deletion with pressing enter button, so you can delete it quickly.
  Good idea, implemented: 7839cf4f90398c5bf779852383ba8f2568a6f7b9
  Thanks, i'm currently also working on it, i have benchmarked the possible translation solutions and currently i'm preferring pure-json translation tables over gettext, it will finish the hungarian translation in the next days, after that other languages will be welcome
 Json based translationt tables are pretty common, you dont need anything to edit them and [transifex](http://docs.transifex.com/formats/json/) and other online translation helpers also supporting them.

If you spend a little time anaylizing your prossibilites, then Python offers pretty good performance/feature ratio (for this kind of applications). Network speed should be no issue (since you using your loopback connection) and browser speed are also fine.
 This is how the translate tables look like, I think it's pretty easy to edit without any external utility:

For python source:

```
{
    "Peers": "CsatlakozÃ¡si pontok",
    "Connected": "Csaltakozva",
    "Connectable": "CsatlakozhatÃ³",
    "Connectable peers": "CsatlakozhatÃ³ peer-ek",

    "Data transfer": "AdatÃ¡tvitel",
    "Received": "Fogadott",
    "Received bytes": "Fogadott byte-ok",
    "Sent": "KÃ¼ldÃ¶tt",
    "Sent bytes": "KÃ¼ldÃ¶tt byte-ok",

    "Files": "FÃ¡jlok",
    "Total": "Ã–sszesen",
    "Image": "KÃ©p",
    "Other": "EgyÃ©b",
    "User data": "Felh. adat",

    "Size limit": "MÃ©ret korlÃ¡t",
    "limit used": "felhasznÃ¡lt",
    "free space": "szabad hely",
    "Set": "BeÃ¡llÃ­t",

    "Optional files": "OpcionÃ¡lis fÃ¡jlok",
    "Downloaded": "LetÃ¶ltÃ¶tt",
    "Download and help distribute all files": "Minden opcionÃ¡lis fÃ¡jl letÃ¶ltÃ©se",
    "Total size": "Teljes mÃ©ret",
    "Downloaded files": "LetÃ¶ltve",

    "Database": "AdatbÃ¡zis",
    "search feeds": "KeresÃ©s forrÃ¡sok",
    "{feeds} query": "{feeds} lekÃ©rdezÃ©s",
    "Reload": "ÃšjratÃ¶ltÃ©s",
    "Rebuild": "ÃšjraÃ©pÃ­tÃ©s",
    "No database found": "AdatbÃ¡zis nem talÃ¡lhatÃ³",

    "Identity address": "AzonosÃ­tÃ³ cÃ­m",
    "Change": "MÃ³dosÃ­t",

    "Update": "FrissÃ­t",
    "Resume": "Folytat",
    "Delete": "TÃ¶rÃ¶l",

    "Site address": "Oldal cÃ­me",
    "Donate": "TÃ¡mogatÃ¡s",

    "Missing files": "HiÃ¡nyzÃ³ fÃ¡jlok",
    "{} try": "{} prÃ³bÃ¡lkozÃ¡s",
    "{} tries": "{} prÃ³bÃ¡lkozÃ¡s",
    "+ {num_bad_files} more": "+ mÃ©g {num_bad_files} darab",

    "This is my site": "Ez az Ã©n oldalam",
    "Site title": "Oldal neve",
    "Site description": "Oldal leÃ­rÃ¡sa",
    "Save site settings": "Oldal beÃ¡llÃ­tÃ¡sok mentÃ©se",

    "Content publishing": "Tartalom publikÃ¡lÃ¡s",
    "Choose": "VÃ¡lassz",
    "Sign": "AlÃ¡Ã­rÃ¡s",
    "Publish": "PublikÃ¡lÃ¡s",

    "This function is disabled on this proxy": "Ez a funkciÃ³ ki van kapcsolva ezen a proxy-n",
    "GeoLite2 City database download error: {}!<br>Please download manually and unpack to data dir:<br>{}": "GeoLite2 vÃ¡ros adatbÃ¡zis letÃ¶ltÃ©si hiba: {}!<br>A tÃ©rkÃ©phez tÃ¶ltsd le Ã©s csomagold ki a data kÃ¶nyvtÃ¡rba:<br>{}",
    "Downloading GeoLite2 City database (one time only, ~20MB)...": "GeoLite2 vÃ¡ros adatbÃ¡zis letÃ¶ltÃ©se (csak egyszer kell, kb 20MB)...",
    "GeoLite2 City database downloaded!": "GeoLite2 vÃ¡ros adatbÃ¡zis letÃ¶ltve!"
}
```

For ZeroMe

```
{
    "Opened": "Nyitva",
    "Closed": "BezÃ¡rva",
    "_(Disabled)": "Kikapcsolva",
    "_(Error)": "Hiba",
    "Status": "Ãllapot: ",
    "Nice! Your port \" + Page.server_info.fileserver_port + \" is opened.": "KirÃ¡ly! A \" + Page.server_info.fileserver_port + \" portod nyitva van.",
    "Re-check opened port": "Port ÃºjraellenÃ¶rzÃ©se",
    "How to make Tor connection work?": "Hogyan lehet bekapcsolni a Tor kapcsolatot?",
    "How to use ZeroNet in Tor Browser?": "Hogyan hasznÃ¡ljam a ZeroNet-et a Tor bÃ¶ngÃ©szÅ‘ben?",
    "Disable always Tor mode": "Tor mindig mÃ³d kikapcsolÃ¡sa",
    "Enable Tor for every connection (slower)": "Tor hasznÃ¡lata minden kapcsolatra (lassabb)",
    "Help to keep this project alive": "SegÃ­ts Ã©letben tartani a projectet",

    "Welcome to ZeroNet": "Ãœdv a ZeroNet-en",
    "Let's build a decentralized Internet together!": "Ã‰pÃ­tsÃ¼nk egy decentralizÃ¡lt Internetet kÃ¶zÃ¶sen!",
    "This site currently served by ": "Ez azt az oldalt jelenleg ",
    " peers, without any central server.": " szÃ¡mÃ­tÃ³gÃ©p szolgÃ¡lja ki, kÃ¶zponti szerver nÃ©lkÃ¼l.",
    "Some sites we created:": "PÃ¡r oldal, amit mi csinÃ¡ltunk:",
    "Simple messaging board": "EgyszerÅ± Ã¼zenÅ‘ fal",
    "Reddit-like, decentralized forum": "Reddit-szerÅ±, decentralizÃ¡lt fÃ³rum",
    "Activate \\u2501": "AktivÃ¡lÃ¡s \\u2501",
    "Microblogging platform": "Mini blog-motor",
    "End-to-end encrypted mailing": "PonttÃ³l-ponting titkosÃ­tott Ã¼zenetkÃ¼ldÅ‘",
    "P2P social network": "P2P szociÃ¡lis hÃ¡lÃ³zat",

    "_(Sites)": "Oldalak",
    "_(Files)": "FÃ¡jlok",
    "Connected sites:": "ElÃ©rhetÅ‘ oldalak",
    " file update failed": " hiÃ¡nyzÃ³ fÃ¡jl",
    "More sites:": "TÃ¶bb oldal:",
    "Activate \\u00BB": "AktivÃ¡lÃ¡s \\u00BB",

    " minutes ago": " perce",
    " hours ago": " Ã³rÃ¡ja",
    " days ago": " napja",
    "on ": "",
    "Just now": "Ã‰pp most"
}
```

The result:
![image](https://cloud.githubusercontent.com/assets/10350359/20262577/11689e60-aa63-11e6-87c4-1ff5cae990c4.png)

So there is 2 separate translator: One for the python source code and one for sites source code. 

The python source code translation is pretty simple _("Anything") returns the translated version of "Anything".

The site source code translation happens on server-side: you can switch any string in the javascript source code with a translated version of it. So it does not requires any modification in the site source code, but it has some drawbacks:
- Caching: Browser caches .js files, so you have to wait some minute after chaing language
- It does not works for every string, eg if you have somthing like this: `if (mode == "Page") $("#mode").text("Page")` and you want to translate "Page" then it will also translate the one in condition so it will never matches. As for solution for this you have to write: `if (mode == "Page") $("#mode").text(_("Page"))` and if put `"_(Page)": "Oldal"` to the translate json, it will only translate `_("Page")`
- If you don't like this solution you are free to translate the string in real-time. (by adding `_("anything")` to every string you want to translate and return the translated one based on user's language), but I choosen this one because it does not adds extra "noise" to site's source code and the other reason is speed: The virtual dom liblaries re-rendering the structure array on every update, click or keypress, so if you translate in real-time it has to call the translation function for every string you have on the page. (it it can easily add 1000s of function calls to every keypress)

I will also translate ZeroTalk and ZeroMe with this solution before the release to see if it can also work for that sites. ETA: this week
 Added in 0.5.1, translation files:
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Translate/languages/hu.json
https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Sidebar/languages/hu.json
https://github.com/HelloZeroNet/ZeroHello/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroMe/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroTalk/blob/master/languages/hu.json
  Can't test it, but looking good. Thanks
 there is no explorer.exe on win10
 Yeah you are right, there is explorer.exe, but after kill/restart it i got:

```
[11:38:21] - Unhandled exception
Traceback (most recent call last):
  File "plugins\Trayicon\lib\notificationicon.py", line 558, in _run
    TranslateMessage(ctypes.pointer(message))
ArgumentError: argument 1: <type 'exceptions.TypeError'>: expected LP_MSG instance instead of LP_MSG
Traceback (most recent call last):
  File "_ctypes/callbacks.c", line 315, in 'calling callback function'
  File "plugins\Trayicon\lib\notificationicon.py", line 646, in _callback
    Shell_NotifyIcon(NIM_ADD, ctypes.pointer(self.iconinfo))
ctypes.ArgumentError: argument 2: <type 'exceptions.TypeError'>: expected LP_NOTIFYICONDATA instance instead of LP_NOTIFYICONDATA
```
 Yeah, the error message makes no sense and if I run notificationicon.py standalone, then it comes back correctly (maybe it's related to live source code reload, so it's does not affects normal users)
  - ZeroNet must run in --debug mode
- "This is my site" should be enabled on sidebar
- Javascript console (F12) must be opened with "Disable cache" enabled on network tab
 you can try deleting all.js and see whats happening in the log/console
  There is only small ammount of strings in the source code, so it's not planned
  I dont have that button, so no cant test it, but i think it happens if you try to set json_id value by hand
  If you include the recommended content to your page (eg. using simple `<img>` tag), then it will be downloaded for offline viewing.
  The proxy owner has to increase the opened file limit:
http://www.cyberciti.biz/faq/linux-increase-the-maximum-number-of-open-files/
 python and the gc should take care of closing not used files

i think this problem is caused by too many socket opened and not fd "leaking"

for my client:
```
$ ls -l /proc/29511/fd | grep /home | wc -l
3
``` @WalnutATiie Can you please check these commands?
```
$ ls -l /proc/13302/fd | wc -l
211
$ ulimit -a
Maximum size of core files created                           (kB, -c) 0
Maximum size of a processâ€™s data segment                     (kB, -d) unlimited
Maximum size of files created by the shell                   (kB, -f) unlimited
Maximum size that may be locked into memory                  (kB, -l) 64
Maximum resident set size                                    (kB, -m) unlimited
Maximum number of open file descriptors                          (-n) 1024
Maximum stack size                                           (kB, -s) 8192
Maximum amount of cpu time in seconds                   (seconds, -t) unlimited
Maximum number of processes available to a single user           (-u) 5897
Maximum amount of virtual memory available to the shell      (kB, -v) unlimited
``` At startup ZeroNet tries to modify the it's limit to 2048, I just found a bug in that code, so please update and try again: https://github.com/HelloZeroNet/ZeroNet/commit/6f2445c417e59c3bf948ff5c3fd0a722c710f9d3 My client running since 3 months and it has 223 opened files, so I don't think if there is any any FD closing problem. 
ZeroNet very rarely close sockets, (check every 10 minute if the site has more than 10 connections) since it required to receive and distribute new updates. To reduce you can try to disable ssl via `--disable_encryption`, disable tor `--tor disable` and change `--connected_limit`, but I think it's safe to increase the limit, for example Debian 8 has 65536 as default.

https://console.cloud.google.com/cloudshell

```
$ ulimit -a
...
open files                      (-n) 65536
```  Can't reproduce on windows 10, earlier windows probably works, but not fully supported.

Alternatively you can install the come extension that adds a button next to the address bar to easy access:
https://chrome.google.com/webstore/detail/zeronet-protocol/cpkpdcdljfbnepgfejplkhdnopniieop
  You have to use target=_top on links to make it work
  If you want to open the browser, then use start.py
  By default zeronet is using (and writing) the zeronet.conf from the working directory (where the zeronet.py file is), so it does not writes to /etc.

You can specify the path of the config file by `--config_file anyfile`
  You need to start it using `zeronet.py --ui_ip "*"` then the remote machine will able to reach it using http://yourip:43110 (you can add --ui_port 8080 if you want that port instead of 43110)

More info:
http://zeronet.readthedocs.io/en/latest/faq/#is-it-possible-to-install-zeronet-to-a-remote-machine
  You have to know your exit node ip to avoid re-connect to yourself and it's also allow to put yourself on the map (helps you to verify Tor is working)
  please try delete data/content.db and try again
 That "can't start new thread" error does not looks good, no idea why.

to locate openssl we use this:

```
$ python -c "import ctypes.util; print ctypes.util.find_library('crypto')"
libcrypto.so.1.0.0
```
 Me.ZeroNetwork.bit/?Post/1RedkCkVaXuVXrqCMpoXQS29bwaqsuFdL/13Z7XxTa7JuFat3KzzMWu3onwM6biLuurJ/1484814283
@Ysc3839 find out that if set threading.stack_size to 32768 the "can't start new thread" error sloved ![image](https://cloud.githubusercontent.com/assets/15062548/22105327/69ea2802-de7e-11e6-84b2-7ca4ca7e35df.png)
zeronet runs so great on router
![image](https://cloud.githubusercontent.com/assets/15062548/22106348/4abb0564-de83-11e6-94a6-37127e57e1cf.png)
without any error
![image](https://cloud.githubusercontent.com/assets/15062548/22106617/87cb2bcc-de84-11e6-9c4b-7e966e4fdc47.png)
  Nope, it's not possible, the frame is required for security reasons, since every site is using the same domain (127.0.0.1) and it can be also used to delete the site immedietly if you don't like the content of it. (you can open the sidebar by dragging it to left)
  It would be against the network relability. If you don't like the content of the site, then you can delete/pause it or you can use a proxy to browse sites.
  You need `ProxyPreserveHost on`, example:

```
<VirtualHost *:443>

        ServerName zeronet.example.com

        ProxyRequests off
        ProxyPreserveHost on
        ProxyPass / http://127.0.0.1:43110/
        ProxyPassReverse / http://127.0.0.1:43110/

        <Location /Websocket>

                ProxyPass ws://127.0.0.1:43110/Websocket
                ProxyPassReverse ws://127.0.0.1:43110/Websocket
        </Location>


        SSLEngine on
        SSLProxyEngine on
        SSLCertificateFile /etc/certs/cert.pem
        SSLCertificateKeyFile /etc/certs/privkey.pem
        SSLCertificateChainFile /etc/certs/chain.pem
</VirtualHost>
```
  - I think cross-site favicon is not really a good idea: you have to seed the other site just for the favicon file
  - `./uimedia` will not work for http://127.0.0.1:43110/mysite.bit/otherdirectory/
 Thanks for the PR, I have implemented it using a simpier solution in Rev1703
  It's looking good for me, but the default favico will not work this way, because it insert "src/Ui/media/img/favicon.ico" as url, you need "/uimedia/img/favicon.ico" there.
  every zeronet site is running from the same domain (127.0.0.1), so it would be a security issue to allow same origin access, but you can modify the hash/query using `window.top.location = "?something#hello2"`
or wrapperPushState/wrapperReplaceState zeroframe api commands
 you able to reach the get parameters directly, using window.location.search (you need to remove `wrapper_none=.*`)
if you call `Page.cmd("innerLoaded")` command the hash will be applied to the inner frame, so you can reach it using window.location.hash

```
> window.location.search
< "something&wrapper_nonce=22f998ea92f1e2574c72cdc96ba7d479d9c1aec8fa31e3873047cbb61987f784"
> window.location.hash
< ""
> Page.cmd("innerLoaded")
> window.location.hash
< "#hello"
```

But if you trying to do url-reflected state management, then use `Page.cmd("wrapperReplaceState", [{}, "Page1", "?state1=ok"])` to change url
  Thanks!
  Thanks, but created a a hand-crafted one instead: https://github.com/HelloZeroNet/ZeroNet/blob/master/CHANGELOG.md
  there is a multiuser plugin, but if you care about your privacy you should run two separate installation in tor always mode (start the second one eg. with `--fileserver_port 15442 --ui_port 43111`)
 It works for me, but its created for proxies, it's very easy to connect your accounts if you posting on both using the same connections.
 you can use `--multiuser_local` to disable that restriction
 Someone can connect to many peers, then log first source of the update and by that finding the poster's ip/onion address. If you using the same client to post to multiple account, then you will use the same ip/onion address/connection to send the update, so it's possible to find out, that the two account owned by the same person. @aemxdp
Yeah, more peer means more privacy.
If B is close to C and A is far, then it can be possible to receive the update faster that way, than directly from A.
  I have downloaded the browser and can confirm it's not working properly. The only solution I have found is setting cookie controll to allow third part on page about:preferences#shields.

It's a known problem: https://github.com/brave/browser-laptop/issues/2417 I will try to find a workaround later.
  It should be fixed in 0.5.0
  `zeronet.py --proxy 127.0.0.1:9050 --tor disable` worked last time i tried. Upnp punching will fail on tor, this is normal.
 It looking good, you need the webui should be accessible on http://127.0.0.1:43110/ (it's possible that you need to add 127.0.0.1 to firefox's "ignore proxy for" settings)
 you can try to add --ui_ip "*" and access is using other ip you have
  Can you please specify the usecase? I think if someone specify a proxy (eg. tor) it means he/she wants every connection to use that. Even a local network connection could lead loss of privacy.
 Then probably it would be better to create direct connection only to 127.0.0.1 and specified proxy (tor or sam) ips
  Thanks!
  A manually written changelog has benn added: https://github.com/HelloZeroNet/ZeroNet/blob/master/CHANGELOG.md
  Thanks, but I did not wanted to add more complexity to the update mechanism. The [ZeroNet based updater](http://127.0.0.1:43110/1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp) only download the changed files, so if you need to save your bw, then please use it.  Try delete data/content.db and try again
  ZeroNet does not have any server-side (python code) support, so I don't think it's related in any way
  Can you please specify your os/version you running?
 I was able to reproduce and fix it, please update to latest version (Rev1534) by `python update.py` and run again.
  Can you please paste your js console content? (F12)
 Yes, thanks for reporting i'm going to fix it soon
 I was unable to reproduce the problem, but made some modifications and added new log messages. Please try now, if it's still not work pelase post the js console lines that appears when you press the button.
 You can ignore that error, probably just one of the users file is not distributed corrently. (you can check the missing file on sidebar when the site is opened)
 Got it & replied!  Can you please check what happens if you shut down zeronet (using zerohello 3dot menu), rename ZeroNet.app to ZeroNet.command and start executing it?
  Thanks for reporting, i was able to reproduce and fix the problem, the modifications will be released soon!
 Yeah, it's not public yet. (I have made many modifications that needs more testing before relese) 

It will be out with the next major version, that is planned for the next week.
 Big site support fixed in 0.5.0
 Yes, every peer is equal in zeronet, so when someone connects to the site it's try to download content.json from random peers, so if most of the peers has the old version then probably it will download that one.
 You can't force peers to increase size, so they will reject the invalid content.json files and serve the older ones until they increase the size.
So your options for larger sites:
- Merger sites: Create multiple merged sites eg based on categories or upload date (recommended)
- Add multiple content.json files using includes, so the root content.json will be always valid, but the included content.json files will be rejected if its larger than the allowed size
- Optional files: it's not for database/dynamic files, so it's not recommended
 Yeah, a notification on ZeroHello is a good idea, i will check whats the possibilites on that.
You can store more than one category in one merger site, it does not requires much modification in the site code, it allows the users to choose which categories are they interested in and also allows anyone to create new data source or make modifications in the display logic and publish it as separate merger site.
 I have added a section for the sites that about to running out of limit:
![image](https://cloud.githubusercontent.com/assets/10350359/20578953/40abc47c-b1ca-11e6-8657-54a8e258cda2.png)
 If a merged site is running out of limit and you click on it, then a dialog appears: 
![image](https://cloud.githubusercontent.com/assets/10350359/24800778/d324f60c-1ba1-11e7-96b0-355b75fddde0.png)

But yeah, this dialog could also appear if you browsing the merger site itself. Yes, by default the sites are still limited to 10MB. (optional files included in that limit)  The document using tor project's debian repo, so you will always get the latest version: http://zeronet.readthedocs.io/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
  Thanks for reporting fixed in latest version: 3331e2305b02c660736c8c6970ffb561e6e85e39
  I have just tested it on same enviroment and works for me, zeronet.cmd contains relative path to included python.exe, so it should not affect it. If possible please provide full error message.
  You have to execute commands after the "onOpenWebsocket" called in ZeroFrame (see the chat tutorial on ZeroBlog for example)
  This error was fixed earlier, please update to latest version: https://github.com/HelloZeroNet/ZeroNet/commit/ca2a30f7ae266b4ad437e5ed24986b0ce45f67db

The size errors is because the user files are indexed in your data/users/content.json file. You have to add "ignore": ".*" to that file, so it won't interferrence with user signed contents.
  Thanks!
  Thanks, it would be better if the tor installation would be also based on `ENABLE_TOR` (tor binary starts automatically after the setup and vps providers looks for that)
 Thanks, looking nice!
  the file data/users/content.json is referenced in root content.json, but it's not signed/found.
  Lots of VPS (most?) providers makes your account suspended for running Tor, so I think we should not start it by default.
  It will allow more advanced optional files handling and 
## Help distribute specific directories
- New API command: optionalDownloadList
- New API command: optionalDownloadSet [patterns]
## Global size limit optional files

Specific size or % of HDD free space
- Keep track downloaded optional files size
- Cleanup by peer number and last access time
## WebUI to manage optional files
- Display total optional files / limit
- Modify limit
- Display downloaded optional files
- Order by Size/Peers/Uploaded/Added/Used
- Manage signed up directories
- Group by site
## Add image upload to ZeroMe
- Image upload with resize
- Checkbox to help distribute user's files
## Plan
- [x] Create optional file manager mockup
- [x] Fill optional files to a database
- [x] Update optional file database on loadContent / removeContent
- [x] Update optional file database on download complete
- [x] Update access_time
- [x] Update downloaded number stats
- [x] ZeroFrame API command to query current peer number for files
- [x] Always allow fileDelete on optional files
- [x] Update optional file database on fileDelete
- [x] Update peer number in database for optional files
- [x] Delete optional files based on peer number
- [x] Auto download optional files based on optionalDownloadList
- [x] Make OptionalFileDelete merger site compatible
- [x] Save/Restore peers to/from database
- [x] Auto pinning my files
- [x] Try guess and pin my files on first startup after upgrade
- [x] Set optional files limit based on current size of files on first startup after upgrade
- [x] FF/IE Edge test

Manager UI
- [x] Static html version
- [x] Site listing
- [x] File listing
- [x] Select files
- [x] Limit bar
- [x] Limit modification
- [x] Files paging
- [x] Manage/remove followings
- [x] Table sorting
- [x] Display pinned files
- [x] Pinning
- [x] Deleting
- [x] Faster total limit usage calculation
- [x] Empty state
- [x] Message for older versions

ZeroMe
- [x] Image upload UI
- [x] Generate preview
- [x] Resize image
- [x] Save image to data.json
- [x] Lazy display image preview
- [x] Load big file on click
- [x] Show peers for files
- [x] Help distribute images checkbox for the user
- [x] Image uploading
- [x] Downloaded image delete
- [x] Delete image when post deleted
- [x] Message for older versions No, this is for ZeroNet files. Originally I was tried to add torrent support, but after some experiments I dropped it for now, because it would be hard to make it work with Tor and I want to avoid confusions, so maybe after i2p support.
 Added to 0.5.0
  you need to use the master_seed value to login
  you can use --ip_external any.ip.you.want, but the trackers will add the originating ip
 trackers works like this: you send a request to a computer, this computer stores the request's originating ip address as potentional source of the website
 It's probably because your proxy does have opened port that is directed back to your computer.
 It's not possible, the trackers will always store your proxy ip
 If you specify --ip_external, then it will skip the port open check, but the end result will be the same: nobody will able to connect to you, only you able to connect other computers
  Thanks for reporting, it's fixed in latest Revision: 60dd797d1a99605099885de5b9a7f050cd16a312

It happens when the file you want to write is in "bad_files". It means the file has been referenced/tried to download before, but it was failed. (You can check bad files in the sidebar)

To ignore this dialog you can use `Page.cmd("fileWrite",{"inner_path": path, "content_base64": previewImgUrl, "ignore_bad_files": true}...`
  For me it does not works. (Tested by starting UpnpPunch.py)

```
>UpnpPunch.py
DEBUG:root:Trying to open port 15441.
DEBUG:root:Found local ips: ['192.168.1.13', '127.0.0.1', '169.xxx.xxx.137']
DEBUG:root:Trying using local ip: 192.168.1.13
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
DEBUG:root:200
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
DEBUG:root:200
DEBUG:root:Trying using local ip: 127.0.0.1
DEBUG:root:Upnp request using "127.0.0.1" failed: No reply from IGD using 127.0.0.1 as IP
DEBUG:root:Trying using local ip: 169.xxx.xxx.137
DEBUG:root:Upnp request using "169.xxx.xxx.137" failed: No reply from IGD using 169.xxx.xxx.137 as IP
DEBUG:root:Trying using local ip: 192.168.1.13
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
DEBUG:root:200
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
DEBUG:root:200
DEBUG:root:Trying using local ip: 127.0.0.1
DEBUG:root:Upnp request using "127.0.0.1" failed: No reply from IGD using 127.0.0.1 as IP
DEBUG:root:Trying using local ip: 169.xxx.xxx.137
DEBUG:root:Upnp request using "169.xxx.xxx.137" failed: No reply from IGD using 169.xxx.xxx.137 as IP
DEBUG:root:Trying using local ip: 192.168.1.13
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
DEBUG:root:200
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
DEBUG:root:200
DEBUG:root:Trying using local ip: 127.0.0.1
DEBUG:root:Upnp request using "127.0.0.1" failed: No reply from IGD using 127.0.0.1 as IP
DEBUG:root:Trying using local ip: 169.xxx.xxx.137
DEBUG:root:Upnp request using "169.xxx.xxx.137" failed: No reply from IGD using 169.xxx.xxx.137 as IP
Traceback (most recent call last):
  File "E:\Web\Today\ZeroNet-upnp_update\ZeroNet-upnp_update\src\util\UpnpPunch.py", line 334, in <module>
    print ask_to_open_port(15441, "ZeroNet", retries=3)
  File "E:\Web\Today\ZeroNet-upnp_update\ZeroNet-upnp_update\src\util\UpnpPunch.py", line 314, in ask_to_open_port
    fn=_create_open_message)
  File "E:\Web\Today\ZeroNet-upnp_update\ZeroNet-upnp_update\src\util\UpnpPunch.py", line 306, in _communicate_with_igd
    port, retries))
__main__.UpnpError: Failed to communicate with igd using port 15441 on local machine after 3 tries.
```

Using the old (current one):

```
>UpnpPunch.py
DEBUG:root:Found local ips: ['192.168.1.13', '127.0.0.1', '169.xxx.xxx.137']
DEBUG:root:Trying using local ip: 192.168.1.13
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
DEBUG:root:Sending UPnP request to 192.168.1.1:1900...
True
Done in 1.21499991417
```
  Sorry, we can't help, since this issue is not related to zeronet itself, but to a site that's on the network.
  Can you please run `zeronet.py sitePublish 1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D` then paste log/cmd.log file's content here?

And also the output of `python -c "import gevent; print gevent.version_info"`
 Same here, so probably that tracker is down. I will find an another one instead of that, until then removing it from src/Config.py should fix it. (needs more investigating why is it spamming the stdout with that error)
  Please try to check log/debug.log for errors.
  I usually tag new version in github later, because there could (and usually there are) be bugs in new version: so if you want something safe then use the releases tab, if you want to be on edge, then download the latest commit.
 Ok, good idea, I have tagged the latest revision with 0.4.1-rc: https://github.com/HelloZeroNet/ZeroNet/releases

Looks like Github does not allows to change the tag's commit, so probably 0.4.1-rc will not reflect the latest version.
  This is normal, you should able to access zeronet on http://127.0.0.1:43110/
  I have not tried it, but you probably need something like this: https://play.google.com/store/apps/details?id=at.bherbst.net

You can use for example this site to check if the port forward is successful: http://www.portchecktool.com/
 If you use tor always, then it does not matter, your port will be close every time.
  Please try to sign/publish it using the sidebar (drag topright zero button to left)
 There was an error that affected siteCreate and siteSign command, it should be fixed in the latest Rev1510. Please upgrade (Click on 3dot menu on zerohello > Version 0.4.1...) and try again.
 The previous versions has not added the newly created site to sites.json correctly and probably that caused the error, it should work now.
 You have to create new site to fix it.
 if you still have the error, then please run it with zeronet.py --debug ... and paste the full log here
 This looks normal, whats the exact problem?
 You can ignore the "SiteManager Save error: No sites found" error.

I have just tried and works for me:
- Stopped ZeroNet
- zeronet.py siteCreate
- Started ZeroNet
- Clicked the new site's link on ZeroHello
- Modified the title
- Signed it
- Loaded the site on a remote machine
- Modified the .html file
- Signed/Published it
  Fixed 0.5.1: https://github.com/HelloZeroNet/ZeroNet/commit/8b7bd2d5720262273ccdf88e52835075b4460081  Thanks for reporting it should work now: https://github.com/HelloZeroNet/ZeroNet/commit/dae5cd396931db239560a3d2e4b5ff225fbad5d4 (the first startup after the update will be slow, because it has to generate the content.db cache)
  RSA is only used to generate proof-of-tor-address (to avoid some attacks) and not used for encryption at all,so i think it should be fine.
  It would be a huge security risk (any site would able to access and modify all other site's data). Disqus-like plugin would result in centralization, which is agains the main goal of the project. Embedding a video does not requires iframe: with the future youtube plugin you will refer the video as the hash.
 The problem is if you can include other site in a frame, then you can execute zeroframe commands as the site (eg fileWrite)

IndexedDB ZeroFrame API command could be possible, but it's harder than localstorage, because there is more functions and you cannot pass javascript object, so you need to pass every command to the external wrapper.
 I'm afraid this is the limitation of browser's iframe sandbox. Do you have any idea when did it worked for you last time?  I think the benefit would be minimal: js/css files recommended to be merged (so the hash does not match and the sizes are also negilable) and the data files are dynamic/unique

you can use webtorrent to share big files between sites and adding built-in torrent client are also planned.
  It's normal, if you computer is too slow for it, then it's stops the animation
 sorry, if you dont have any javascript error, then i have no idea
  There is irc on freenet and also on gitter: https://gitter.im/HelloZeroNet/ZeroNet
  Thanks, but I see no real changes in the new version  Yes: https://chrome.google.com/webstore/detail/zeronet-protocol/cpkpdcdljfbnepgfejplkhdnopniieop
  probably you try to access it using https or similar, maybe the javascript console (F12) network tab can give more information
  Sorry, it's not possible to help you based on the provided informations. Please give more information: JS console messages, ZeroNet log messages, OS, Browser, etc.
 Thanks, based on the js error i was able to reproduce/fix it
 @DaniellMesquito You don't need to upgrade ZeroNet, the change is only in ZeroHello site's source code which should happen automatically.
  probably the peers are not connectable or offline, so you can't publish it to anyone
 The peer number is shows the possible peers (ip addresses who have visited the page recently). They can be offline/not connectable or maybe they already removed the page. You can see the connected peer number in the sidebar and the publishing result is in file log/debug.log

I have closed the issue, because the problem is probably in the site/network connection since the publishing is used many times per minute.
  ZeroNet has to shut down for updating, so unfortunetly since it's not running it's not possible to give any feedback to the user, but if you have Console/Terminal opened, then the update process is visible there.
 Creating / closing new ports/sevices could have some delay (or cause some other problems for example in firewalls) and the update process should not take more than some seconds, so i dont think it's worth developing a separate webserver / popping up a window for that. The zeronet startup speed can be slow on hdd based systems, but it will be improved in the near future.
  This is normal: zeronet shuts down , download the latest version, then starts up (could take couple of minutes depending on your net/cpu/hdd speed)
  You can use git if you want, but i dont see why is it necessary
 Probably ZeroNet will not work on connections where downloading 2.5MB is a problem.
 Most of OS does not have git installed, so it would require to pack/maintain git for every platform which is for example 31MB for windows. (https://git-scm.com/download/win)
 It's already possible: if you have git installed, then you can update it from github.
  It downloads the latest zeronet-master.zip (2.5M), then unpacks it.
  Other addresses are not planned.
  It's not possible to change the site's address
  I want to maximize the testers of the new versions/revisions, so everyone will get the "Alpha"
  Thanks for reporting, fixed in latest version
 The latest: Rev1429
 you can use the 3dot menu in zerohello > Version 0.4.0 menu item. Or simply download it from github and overwrite the files
  Change the start.py to zeronet.py in the end of the third line in zeronet.cmd
 it's similar: replace start.py with zeronet.py in ZeroNet.sh

https://github.com/HelloZeroNet/ZeroBundle/blob/master/ZeroNet.sh#L5
  Since last week it possible to download and update the source code via the ZeroNet network, which verifies the data integrity by checking the signiture, but I will look at pgp signing releases Added signing to git commits: https://github.com/HelloZeroNet/ZeroNet/commit/901478475fb15a910d3c99ccb161730b4e84ca25  It's normal, you can ignore it. To make it accessible from other computer you need an open port or tor installed.
  Its caused by infinityhub, you can remove it or update to latest version of zeronet which is fixes this issue 
  I was unable to reproduce it, can you give me pelase more details on what kind of data you want to sign? And maybe pelase check the log/debug.log if there any any more error message around it.
  Try python -m pip install -U gevent
  Are you sure `data/yoursiteaddress` directory is exists? Please try using siteSign eg.: `zeronet.py siteSign 1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D --publish`
  The XSS is not really an issue on ZeroNet because of iframe sandboxing and we have no POST/GET api, but it would be good to add it as a plugin.
Also worth checking: https://github.com/kustomzone/Fuzium  no yet, but you can use GNURoot (https://play.google.com/store/apps/details?id=com.gnuroot.debian) and install it using: https://github.com/HelloZeroNet/ZeroNet#manual-install-for-debian-linux
 It's still there:


Manual install for Debian Linux
sudo apt-get update
sudo apt-get install msgpack-python python-gevent
wget https://github.com/HelloZeroNet/ZeroNet/archive/master.tar.gz
tar xvpfz master.tar.gz
cd ZeroNet-master
Start with python zeronet.py
Open http://127.0.0.1:43110/ in your browser

There is also an experimental .apk: https://github.com/HelloZeroNet/ZeroNet-kivy  https://github.com/HelloZeroNet/ZeroNet clone or download button

But if you download zerobundle it will download the latest version for you and it also have a built-in updater if you have earlier version.
  Please in english
  Please check the log/debug.log file, it should look like this:

```
[2016-08-09 03:34:31,642] ERROR    TorManager Tor controller connect error: error: [Errno 10061] No connection could be made because the target machine actively refused it. in TorManager.py line 154 > socket.py line 342
[2016-08-09 03:34:31,644] DEBUG    TorManager Tor proxy port 127.0.0.1:9050 check error: No connection
[2016-08-09 03:34:31,645] INFO     TorManager Starting Tor client tools/tor/tor.exe...
[2016-08-09 03:34:32,148] DEBUG    TorManager Connecting to 127.0.0.1:49051
[2016-08-09 03:34:33,153] DEBUG    TorManager > PROTOCOLINFO
[2016-08-09 03:34:34,118] DEBUG    TorManager < 250-PROTOCOLINFO 1 
```
 probably firewall or something is blocking tor.exe port. you can enable logging by removing # from line `# Log notice file data\notice.log` in tools/tor/torrc file
 do you have data directory where the tor.exe is?
 Sorry, no idea, maybe firewall blocking it. I just tried and it's works for me. (also win10)
  have you tried to starting it with `zeronet.py --max_files_opened 10240` ?
 If you start zeronet using --debug then you have some more detailed http://127.0.0.1:43110/Stats page. Please paste the first ~10 lines of the "Objects in memory" section and also the number in the "Sockets (*):" section
 Please try to save this file: https://gist.githubusercontent.com/HelloZeroNet/d9bf888693e66a573815/raw/aeb189142e0be33b0253af5ddb8c241c49a95ce9/test_max.py
and drag to a terminal.
It tests how many files can a python process open.
  Looks like your ZeroNet/src/Ui/template/wrapper.html file is broken somehow. Can you open it in notepad? It should looks like this: https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/template/wrapper.html

Please try to shut down zeronet, copy the old ZeroBundle/ZeroNet/data in place of your new installation and start again. Is the problem still exists? 
  Sorry, but it's not possible to help you based on this amount of information. Please specify your os version/installation method/etc.
  I think the best would be a separate plugin, so the development could be done outside of the ZeroNet core. (I also creating new features as a separate plugin to keep the core simple)
 If the plugin becomes mature enough, then it's possible to enable by default, but an appstore-like plugin interface is also planned where anyone can enable/disable/install plugins easily.
  Unfortunately its not possible, because the p2p websites are completely different from traditional client<>server ones
  I don't have OSX access, but double clicking was worked for me when I tried it. (probably depends on settings)

I have tried to create a proper .app package (https://github.com/HelloZeroNet/ZeroBundle/tree/master/ZeroNet.app/Contents), but it requires Apple Dev Account to sign it. 

If anyone would able to sign it, then i think it should always work as double clicking on it.
 @robinvandernoord Looks good, i will test it the next time when i get a mac access. Do you have any other suggestions to make it easier to install/start on mac?
 Probably 90%+ mac users does not have docker installed
  donwload failed for me, but probably you don't have it added as include to the root content.json, example:
https://github.com/HelloZeroNet/ZeroBlog/blob/master/content.json#L142
  it could be possible to develop a plugin to keep only eg.100 most visited sites
  it will download the source when you start it using zeronet.sh

for remote install: http://zeronet.readthedocs.io/en/latest/faq/#is-it-possible-to-install-zeronet-to-a-remote-machine
  Hi,

Is it possible to develop a private instant messaging ( like Tox ) ?
 Yes , and finally Tox has the Distributed Hash Table , so it is more interesting.
  Hi,

Is it possible to add to the ZeroNet network, the concept of AlternativeTo ?
Every application has alternatives and it is listed in it.
People add the application and other check if it is the same theme / a proper alternative
And everyone can vote for their favorite applications.

http://alternativeto.net/software/alternativeto/
Currently this concept is not open-source and not distributed.
 This is an idea of application on this network ;)
 Some can delete softwares , like owncloud
7th april 2016 : https://ipfs.pics/QmcRwEMDZVwNJZ4wjrnHRYuWP6trLYAyVqCGLHqPHT8GeR
now there is no owncloud listed in the application server

and it crashes sometimes with ASPx
  Hard to tell, but you can use Tor's OBFS proxy project to avoid it.
https://www.torproject.org/docs/pluggable-transports.html.en

Easiest way to to this is install Tor browser bundle, start it then start zeronet using `zeronet.py --tor_proxy 9150 --tor_controller 9151 --tor always`
  you only need to publish it if you already have visitors, who downloaded your site before
 yes, it should work. zeronet does not support local peer discovery yet, so you need external ip or tor connection
  zeronet does not knows/tests your public ip address (only the exit node) when running in tor mode, so it's not possible
  use ls -al /var/lib/tor/control_auth_cookie instead then follow: https://zeronet.readthedocs.io/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
 You need to add `ExtORPortCookieAuthFileGroupReadable 1` to tor config, `usermod -a -G tor [yourlinuxuser]`, re-login, and restart, then it should work
 there is an another option, please try this one: CookieAuthFileGroupReadable 0|1
 The permission error come from the operating system, it not really a zeronet issue, please re-check every permission/tor logfile/tor documentation/etc.

if your linux user not able to read the `/var/lib/tor/control_auth_cookie` file, then zeronet wont be able to do so
  its currently stored in browsers local storage, later something more persistent are planned
   it's depends on how long have you been running the client (it requests around 50peer/5min) and what other users have you been exchanged peers.
It's not an issue, there is no real benefits between having 30 vs 600 peers on a site.
 well there is no leechers in zeronet, so peers = seeders 
  more specifically the problem(?) is in https://github.com/chjj/marked js lib  it should work between tor-only peers (please not there is some warmup time on tor hidden services, so you have to wait 1-10 minute after you created your site)

are you sure are you running in tor only mode? it should display "Successfully started Tor onion hidden services." message then (https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/UiWebsocket.py#L68) then. 
  OK,, I think renaming to --tor manual would be more straightforward, because it could be also useful without VM
  Is this problem gone? What was the problem?
  you are probably doing something wrong: out of limits/invalid files/etc. 
keep try sign + publish again and check logs
 you can check the problematic files using the sidebar. File update failed means something is broken with the site and not with zeronet. It can be file that is referenced in the source code but not distributed to the network or an invalid optional file. the 0chan site owner has to add data/.*db to ignore pattern to make the problem desappear. eg. https://github.com/HelloZeroNet/ZeroBlog/blob/master/content.json#L141
  its already done: 
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/UiRequest.py#L352
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Worker/WorkerManager.py#L317
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Test/TestSiteDownload.py#L34
  probably you have changed data/users/content.json and have not signed/published it or it's invalid
 try edit your comment on zeroblog, if it does not drop error then the problem is in your site. try delete/readd it and check if every file is synced
  it is configurable, use: --fileserver_port 1234
  I'm not sure about this. If you make any changes to your site's source you should try it if it's works or not (using the web interface) and it will be compiled on the file request.
 It's probably caused by your browser's caching. (all.js generated when its http requested) You should open the dev tools (F12) and check disable caching when developing
 you can use `python -c "import distutils.spawn; print distutils.spawn.find_executable('coffee')"` to check if coffee binary is visible by python or not. Or you can use `--coffeescript_compiler "/usr/local/bin/coffee --no-header -p"` to define the path of it

you also need to enable "this is my site" option on the sidebar to enable compiling
 are you sure you have enabled the  "this is my site" option on the sidebar?
 start it using `--multiuser_local` to remove that limitations
  the re-compile executed when the .coffee modification date is newer, than all.js. Maybe adding 1 second window could solve the problem. Can you check the src/Ui/media/lib/ZeroWebsocket.coffee vs src/Ui/media/all.js modification date difference?
  probably something with the coffeescript compiler, please check console/logs (use --verbose if necessary)
  since the latest commit, when the files created for the first time now it defaults to r/w by user only: https://github.com/HelloZeroNet/ZeroNet/commit/523a7d4c16e8c2f590e759e23f0d2d6ae36cff37
  it's probably router/os firewall configuration issue. you can use http://portchecker.co/ to check if the port opened or not
  you can add your user to debian-tor group, so it will able to read it: http://zeronet.readthedocs.io/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
 you can use the CookieAuthFileGroupReadable 0|1 configure option 
via https://www.torproject.org/docs/tor-manual.html.en

reading the cookie file should remain possible, to allow reconnect to tor control port later
  normally it should not happen: https://github.com/HelloZeroNet/ZeroNet/blob/master/src/util/helper.py#L12
- It writes new content to data/sites.json-new
- Renames current to sites.json-old
- Renames sites.json-new to sites.json
- Deletes sites.json-old

Have you checked the sites.json content? Was it incomplete or random bytes? Was there sites.json-old file?

Im not sure if sqlite is a good solution to store configuration files, because it's harder to edit.
  Thanks!
  History/Cookie and some functions manipulations are restricted by browser iframe sandbox
 You can't use replaceState (url modification) functions directly, maybe it's possible to disable in jquery mobile
 Yes, if it's works on one machine, then it's different problem, are you sure every file is well synced?
 I mean are the files has the same content?
 check the directory sizes should be enought
 It does not affect us, since the replace/push state command is executed outsite of the iframe by zeroframe api commands  ZeroNet site addresses are 100% compatible with bitcoin, so you can use:
https://bitcointalk.org/index.php?topic=25804.msg321135#msg321135
 Easiest way:
- Generate an address/privatekey with vanitygen
- zeronet.py siteCreate
- Rename data/createdsiteaddress to data/vanityaddress
- zeronet.py siteSign vanityaddress vanityprivatekey
- visit 127.0.0.1:43110/vanityaddress
  There is no "official", but there is polls at: http://127.0.0.1:43110/zeropolls.bit
  The root of the problem is currently it's need to load every content.json on startup. (if you start it using `--debug` or check log/debug.log you will see the load time per site) So if you have many site added and running the client from hdd it could take some time. (SSD performs better on loading many, small files)

There is multiple possibility to solve this:
- Lazy load content.json files to memory (only when requested by the client eg. need to verify a changed file). I have already made it working as experiment and it's also dramatically reduces the memory usage (80MB->40MB), but there is some command (list all content.json newer than X date) that needs to check every file. To workaround this problem maybe we should index the content.json modification date in a db or simple json file.
- Instead of using raw file system we could store the content.json files in database (Sqlite or Berkeley DB) I have also made benchmark on this, the results on an crazy slow, overloaded VPS (loading and parsing content.json from a site with 5000 users):

```
sqliteRead  | 3.992s Mem: 10.50MB(+0.92MB)
bsddbRead  | 2.624s Mem: 11.11MB(+0.61MB)
jsonRead  | 331.137s Mem: 11.11MB(+0.00MB)
```

File size:
- On FS: 3.2MB
- Sqlite: 6MB
- Bsddb: 5.7MB
  Thanks it was fixed some months ago: https://github.com/HelloZeroNet/ZeroNet/commit/dafe9981a241e5ff170bd989abcd77e85acaf3aa  It's hard to tell, please specify your browser and also try it in an other one
 do you have any antivirus software installed?
 Added a custom debugging, please save it to ZeroNet/src/Ui dir the restart and see Path: ... debug lines
https://gist.githubusercontent.com/HelloZeroNet/b288fd7084b822612a3ae8b30b5c12b8/raw/f1ff543e58b07741b2c836a08f3a0ec8dcb54088/UiRequest.py
  yes `--data_dir ~/.local/shared/zeronet/`
  sorry, its not possible, but you can download the zerobundle version that is contains everything you need to run zeronet: https://github.com/HelloZeroNet/ZeroNet#how-to-join
  you can create site that accept self-signed certificates and not a third-party one. if you accept third-party one (eg zeroid.bit), then you accept the auth_address generated for that site
  cert_user_id should contain the cert signer's name
 you also need to add the certificate signer to data/users/content.json file
 I see this on that site:

```
...
  "cert_signers": {
   "nanasi": [ "16PmAP6z2MCJX9jNjvMrteMfnqX4KeDRNT" ],
   "zeroid.bit": [ "1iD5ZQJMNXu43w1qLB8sfdHVKppVMduGz" ]
  },
...
```

probably you have to sign+publish data/users/content.json
  You browser's bookmark function probably better suited for this
 you can also use the sidebar to delete/update/pause the site (drag the topright zero button to left)
  Fixed: d2d2967f11f0009547959b57e0f25d1e590da852
  whats your domain name? the problem probably is different
  Is the other domain based sites works for you? eg http://127.0.0.1:43110/talk.zeronetwork.bit
What directories you see in plugins directory?
What blank means? Total white page or anythign visible?
Is any error message in the javascript console? (F12)
  you don't need registration to visit any site. if you try to use any feature that is requires zeroid the site will redirect you to the id providers it accepts. i think it's pretty simple and hard to miss it
  There is many problems with webrtc:
- Not possible to create sandboxed iframe enviroment (cross-origin scripting problems)
- Tor connection not possible (Around 50% of ZeroNet clients using Tor)
- No SQL support
- File storage problems (max storage size per site origin)
- No support for non-web content (eg. github repository)
- You would need to keep an open browser tab for every site you seeding
- You private key would need to be stored by the browser, so any site you visit would able to access it
- WebRTC is created for small number of clients videochat system, not suitable to handling 100s of connections
 a light webrtc client would be possible that is allow to browse static (non-sql based) websites
 If we target browser extension, then we don't need to use half-p2p webrtc sockets and deal with other js limitations, but we can do create real sockets like https://deepankar.io/current_projects/details/kronymous do I have just opened webtorrent.io in latest chrome, it freezed my browser for 20 second, then started playing, but according to the dev console (F12) it downloads the video from https://webtorrent.io/torrents/sintel-1024-surround.mp4 and the webtorrent.io tab currently using 250MB of ram

I'm not saying webrtc or webtorrent is bad, but it does not looks mature to me. (or suitable to handle many connections)

Also webrtc connections not fully p2p, you need to contact to google (or someone) before create connection to anyone: "Unfortunately WebRTC canâ€™t create connections without some sort of server in the middle. We call this the Signal Channel. " - [via](https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API/Connectivity) > Okay, I guess I never tested it on a slower machine. But I don't think 250MB is bad, considering it has to keep at least 130MB of video in RAM.

I have i5 6600k (skylake) CPU, so it's not so slow. The GPU is running in separate process, so it's not includes that (if I open https://webtorrent.io/torrents/sintel-1024-surround.mp4 in a tab its displays 15MB)

> Well yes, but thats just bootstrapping right? 

No, it's not for bootstrapping (getting peer ips), but the both party need to connect to the STUN server every time before they want create new connection with eachother. I think it's for security reasons, to avoid DDOS attacks from webpages. (and add socket security) I don't really feel like to start developing it but, I would be happy if someone would do more experiments  and I'm open to add webrtc connection support to python client. Yes, the situation is totally different now: In webrtc you need to connect to STUN server before every connection you make. The torrent trackers is only required to get the list of the possible peers, but you don't need to connect and report them before every new connection you make.

Pex is supported and peers is saved to local database, so you can use previously known peers.  > According to this: https://github.com/cjb/serverless-webrtc/ (warning: shitty demo, barely works)

After tring it out the demo works this way:
 - Client A: Generate the the 4KB JSON
 - Client B: Based on the 4KB JSON generate a response to 4KB JSON
 - Client A: Using this response can connect to Client B

So I have no idea how could it work without any middle server. A tracker could store Client A's 4KB JSON, but you need the response to your 4KB JSON create the connection. According to this diagram you always need a signal channel to create new connections. Maybe this signal channel can be an another peer, but then both peer has to be connected to the same peer before they can create new connection to eachother. 

![image](https://cloud.githubusercontent.com/assets/10350359/20793789/252c5612-b7c9-11e6-92d1-1e336be0e822.png)
  you can send it to hello@zeronet.io, but it's usually caused by antivirus softwares/browser extensions

see https://github.com/HelloZeroNet/ZeroNet/issues/195
 according to logs your browser tries to use HTTP/1.0 instead of HTTP/1.1, not sure why is it happening (All common desktop browsers (Netscape/Mozilla, Internet Explorer, et al) in the last 10-13 years support HTTP/1.1.)
 its the same problem: your browser try to use a protocol (http/1.0) that is more than 10 years old. probably its caused by an antivirus software for some unknown reasons
 Here is a version that allows http1.0 connections please try to save it to ZeroNet/src/lib/gevetwebsocket to directory, restart zeronet and try again: https://gist.githubusercontent.com/HelloZeroNet/3ff4a0fe233fc5b4c153d7b475ac8b07/raw/85fef31da837d5f0a9bc9da96c7de1919050e3c8/handler.py
  Its not created by zeronet, few ideas: http://forums.whirlpool.net.au/archive/892927
  The old ZeroHello (1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr) is no longer actively supported, please switch to 1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D
  http://windows-exe-errors.com/how-to-disable-werfault-exe-in-windows/
  You can find a sql based chat tutorial at zeroblog
  Sidebar is not supported on mobile (i have no phone that allows to add/test mobile features)
 (reopened as mybe someone else has mobile phone access/able to add support)
 It's works in emulator (update: looks like it not, i will check it later)
 Fixed in latest revision eedce00d575d6edba83ec03f6c309f95883d0936 (at least it works in the emulator)
  It's not possible to change/shorten or choose your privatekey
  thx, fixed: 432aa037cbda0368ceb3b07dba526a8044eaa821
  thx fixd 93e598cc596c023b035507fe018c2163cad2aa32
  @Feeding It works by using ZeroName site's database. If you enable the ZeroName-local plugin it will use your local namecoin node
  on zeronet the current default site size is 10MB, wikipedia contains 10TB+ data (100000x larger), so it's not really possible yet
  probably your internet provider/router does not allow opened port
you can check it manually on page http://portchecker.co/ by entering 15441 to port it should display "Port 15441 is open."
  Currently content.json files stored on the file system and for fast access loaded at startup and kept in the memory.

To reduce memory usage (up to 20MB per site depending on user number) and faster read/write it can be stored in database using sqlite or the [anydb module](https://docs.python.org/2/library/anydbm.html)
#### Cons:
- More hdd load/json parse cpu load
- Json file editing by hand?
- Db corruptions
#### Benchmark results:

Files: 5408
Total size: 3.1MB
Size in sqlite: 5.8MB
Size in anydb: 5.6MB

Loading all files:

```
Init  | 0.000s Mem: 11.30MB(+11.30MB)
jsonRead  | 1.235s Mem: 11.39MB(+0.09MB)
sqliteRead  | 1.551s Mem: 12.53MB(+1.13MB)
bsddbRead  | 0.470s Mem: 12.97MB(+0.44MB)
```

the difference is even bigger on a vps with very slow/overloaded hdd:

```
jsonRead  | 693.805s Mem: 9.82MB(+0.25MB)
sqliteRead  | 10.896s Mem: 10.76MB(+0.93MB)
bsddbRead  | 7.671s Mem: 11.11MB(+0.35MB)
```
  Fixed https://github.com/HelloZeroNet/ZeroNet/commit/34ead0aec233293148602d2ab4a63096aa61af47, but still recommended to start without whitespace, since most of the clients will not execute it
  if its not in zerotalk/blog/mail, then it's not supported officially

https://zeronet.readthedocs.org/en/latest/site_development/dbschema_json/ include all supported features

i think custom trigger should work if you put it as index

sqlite version depends on platform
for me on Win/Python 2.7.9 

```
>>> sqlite3.sqlite_version
'3.6.21'
```

Linux/Python 2.7.9

```
>>> sqlite3.sqlite_version
'3.8.7.1'
```

SQLite Release 3.6.21 On 2009-12-07 so it's not advised to use any new sqlite features
  It could work, but it needs much deeper modifications of zeronet, and if the bundle owner decides to include 100+ sites over night it automatically downloads 100*10MB content on your hdd. This also means there is no motivation (size limit) to create new bundle sites.
And if the bundle owner decides to remove your site it will also make it unaccessible for the users, because they seeding the bundle site.
And also not sure how do you add your site to the bundle without knowing anything.

So i think there is not much benefit from it.
 Connection sharing between sites is supported, but its not really works well in sites with many peers, because when you query peers from the tracker you only get 20 peers and probably it will not include the ones you already connected with. And for privacy reasons the connection sharing is totally disabled on Tor. (new .onion generated for every site you seed)

So this would require many core changes and I think the normal (multiuser), hub sites could work equally well. If one of the profile you follow got removed by the hub owner there can be a notification of it and you can follow the same profile on an another hub.
  we will think about it when its become problem, https is more reliable, than zeronet protocol
 If it's common problem, then it can be possible.  you have to disable the zeroname plugin
 no, it's simple: if you want to use the plugin you need the site, if you don't want to use the plugin disable it
  the dns is optional, every site works without it.
 yes http://127.0.0.1:43110/1MaiL5gfBM1cyb4a8e3iiL8L5gXmoAJu27 works without any problem
 you have to modify the zerohello to link to non-domain url
 no idea, its just works that way
 a zeronet site can overwrite any of your decision, if you want to change it you are free to clone/modify it or you can use your browser's bookmark function, so it will point anything you want
 you have to own the site's private key to modify it
 the files cached in the memory, you have to restart your client make it work
 the modifications will be reverted on the next modification on the site, so it's not a good idea to modify file you dont own.
  i'm assume you are not using the standard installation, because by default the config file is located at zeronet's directory and not in /etc.

you have to add `tor = always` to `[global]` section
  This makes the iframe sandboxing ineffective (required, because every site is served from same host: 127.0.0.1)
 Disabling the same origin protection would allow any site to access or delete other site's data.

I think webrtc based p2p video is never going to be a reliable solution, because the peers only seeds it until they are on the site, but it could be possible to create a videoplayer plugin that allows you to display videos using DASH/WebTorrent outside of the iframe. (like the sidebar plugin)

Probably the best/sustainable solution for videos would be a plugin that acts as a full torrent client (not webrtc based) and allows you to stream/share/seed videos to/from real torrent network.
 There is an api command to read/write localstorage: https://zeronet.readthedocs.org/en/latest/site_development/zeroframe_api_reference/#wrappergetlocalstorage
but i think you will run into other sandboxing limitations that makes it impossible
 I think this is required by webtorrent, but also disabled by the sandboxing: https://developer.mozilla.org/en-US/docs/Web/HTTP/data_URIs (not sure why is it disabled)
 files larger than 1MB is not supported yet, so dl tracking is not any useful
 Most of the users are using ZeroNet from Tor, which is not suitable to distributing big files, so using other network for this purpose is a better idea (eg. torrent). There is no streaming file support in zeronet which makes the progress reporting not possible yet.
  you can use socks5 proxy using `--proxy 1.2.3.4:4321` command line parameter

ipv6 not supported yet
  you can run it on android using GNUROOT, but it's better solution if you put it on remote machine that has persistent internet connection: http://zeronet.readthedocs.org/en/latest/faq/#is-it-possible-to-install-zeronet-to-a-remote-machine
 Yes, please read the link:

Is it possible to install ZeroNet to a remote machine?

Yes, you have to enable the UiPassword plugin by renaming the plugins/disabled-UiPassword directory to plugins/UiPassword, then start ZeroNet on the remote machine using 
zeronet.py --ui_ip "*" --ui_password anypassword. This will bind the ZeroNet UI webserver to all interfaces, but to keep it secure you can only access it by entering the given password.
  it does not meet the design principles
  According to wikipeda github is safe: "On January 21, 2013, GitHub was blocked in China using DNS hijacking. Confirming the block, a spokesperson for GitHub said: "It does appear that weâ€™re at least being partly blocked by the Great Firewall of China".[a][7] The block was lifted on January 23, 2013 after an online protest on Sina Weibo." - https://en.wikipedia.org/wiki/Censorship_of_GitHub

I have created mirrors:
- https://gitlab.com/HelloZeroNet/ZeroBundle/tree/master/dist
- https://try.gogs.io/ZeroNet/ZeroBundle/src/master/dist

Distributing on torrent probably would cause other problems,since it's blocked on many networks even outside of China
 Actually the source code already on ZeroNet site: 1UPDatEDxnvHDo7TXvq6AEBARfNkyfxsp and if you have this site your client will use this to update your client instead of https source.
Git releases & commit also signed: https://github.com/HelloZeroNet/ZeroNet/releases  For some unknown reasons zeronet does not see your site. 
Does the 17EcoSLuGdJKWrKnBDN1qVsyxN2dZqtJQL directory exists in your data directory? does it has index.html and content.json file?
Please try to restart your zeronet client, maybe it helps.
 nice
  To be able to review site source code changes a "Site freeze" option could be added to the Sidebar: When it's enabled, the current site's html, js, and css files are copied in a separate directory (data/siteaddress-freezed) and if the user's browser is request the files then it would be served from this directory until the user disable the freeze feature.

The data files are not affected by this feature and the user still receive/distribute the latest files of the site's source code.
  why? its the same
  Thanks for reporting, but i'm not sure if its necessary to authenticate every message, because the whole file is already authenticated by the sha512 hash, so there is decrypt is not executed on trustless data
 @TheNain38 it's not related to this problem, hmac would not help on that
 the hmac is authenticate the message itself and not the sender user.
 it could be possible modify zeromail to decrypt the messages using only the aes key associated to the user, so it would greatly improve performance and would not require per-message hmac, or is there any other attack vector on that?
 Modifying the secret exchange by also adding the sender's address to it would prevent the aeskey stole attack + adding the per-user associated decryption modification i think would solve the problems
 HMAC would not solve the message or secret transfer problem, so we need to add this regardless of HMAC-ing messages or not
 im not against addig MAC, but i think the real problem (message duplication) is not related to it.
 Alice's SK = Alice's private key? If so, then if you encrypt anything using it then noone will able to decrypt it.
 I think ECIES works like this, but there would be many drawbacks to use it as message encryption:
- Much larger messages
- Around 100x slower than AES
- You would have to try to decrypt every message (currently don't decrypt unknown user's messages)
- If we want to have sent folder, then we have store the messages twice (once encrypted for our self, once for other user)

it was considered earlier, but then it was dropped: https://github.com/HelloZeroNet/ZeroNet/issues/216#issuecomment-157479518
 I know, this is a more complicated solution, but it was chosen because of the reasons i written in my prev comment.
  sqlite database would be better (more scalable, multiuser)
  you have to open a Terminal and drop the zeronet.app on it
  There is a plugin for that: https://github.com/HelloZeroNet/ZeroNet/tree/master/plugins/disabled-Zeroname-local
 I prefer to make it an separate, optional plugin as it affects very small amount of users and it's not stable yet
 I think the best solution would be using P2P name resolution without downloading the blockchain. It could be possible using SPV clients, but it's not ready for namecoin yet: http://blog.namecoin.org/post/109811339625/lightweight-resolvers
when it's ready we will implement it as default dns resolving.

other possibility: https://blockstack.org/docs/light-clients (it's also not ready yet)
  I dont think it's necessary you can put your donate button to your site html code
  I think POW is not suitable to fight spam. Spammers has lots of CPU/GPU power and it's possible to create an optimized FPGA/GPU program that runs 1000x faster than normal CPUs
  You have to compile the required python packages (gevent, msgpack) from source then it should work
  Fixed: https://github.com/HelloZeroNet/ZeroNet/commit/e3a4dbaab566255c44543a22cb0adb982c3b66bb
  [18:04:44] TorManager Tor controller connect error: error: [Errno 111] Connection refused in TorManager.py line 154 > socket.py line 344

Means your tor is not configurated properly see: http://zeronet.readthedocs.org/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
  probably you have to use target=_top on links
  In order to greatly reduce the bandwidth usage of ZeroNet, when a change is happening instead of re-transferring the whole file we only send the changed lines to the user.
- [x] Benchmark of generating diff
- [x] Benchmark of patch files
- [x] Modify UiWebsocket fileWrite to generate and store patch
- [x] Modify UiWebsocket sitePublish to send patch to clients
- [x] Modify FileRequest Update command to accept patches
- [x] Find a way to make the patch work from command line
- [x] More manual testing
- [x] Unit tests

new example update command:

``` json
{
 "site": "1Hello...",
 "inner_path": "content.json",
 "body": "{...full content of content.json...}",
 "patch": {
   "index.html": [["=", 273], ["+", ["newline\n"]], ["-", 3]]
 }
}
```

First the client checks the content.json validity as before, then tries to apply patches, if failed, then downloads the file in traditional way.

Probably it's a good idea to limit patch length to 10k

Later it could be possible to also send content.json as patches

To make it work outside of zeronet (where files are not written using fileWrite so no diff generated):
If a file with -new a postfix is exists then before the signing method the diff is generated between the normal and -new postfixed one, then the file is overwritten with the -new one.
 First benchmark using a modified simplediff (https://github.com/paulgb/simplediff/tree/master/python):
Generating diff between two 900kb json file: 80ms

Example diff:

```
[
('=', 273),
('+', ['newline\n']),
('=', 2743),
('-', 2),
('=', 657),
('+', ['newline2\n']),
('=', 88),
('-', 3),
('=', 79)
]
```

Patching is pretty simple and takes no time: 0.8ms for 900kb json file with 12 differences.

https://gist.github.com/HelloZeroNet/0eed5fc05227ab793e7d
 Changed to standard python difflib + character based diffing, because the patching is using lower memory this way https://gist.github.com/HelloZeroNet/8c44dda7802cf05c6c59001d20816da2

```
# SHA512: c8cc7f1dc3e018cd45a3a77accba5105721102539b2af900e34c91c2a1b40d6c
# Patch list: Mem +0.48MB, Peak: 11.37MB Taken: 0.188s
# Patch file: Mem +0.20MB, Peak: 10.25MB Taken: 0.323s
# Patch file+bindiff: Mem +0.16MB, Peak: 10.22MB Taken: 0.132s
# Tempfile
# with    Mem +0.45MB, Peak: 10.78MB Taken: 0.155s
# without Mem +0.14MB, Peak: 11.46MB Taken: 0.144s
```
 Done in rev1200
 i have throught about it, but adding compression to protocol level (compressing every communication) probably makes more sense
 Compress after the encryption is more safe. BREACH/CRIME attacks are using compression to get around: https://en.wikipedia.org/wiki/BREACH_(security_exploit)
  It does not work on osx. according to http://stackoverflow.com/questions/6908143/should-i-put-shebang-in-python-scripts-and-what-form-should-it-take `#!/usr/bin/env python` always should point to python2
 ```
$ /usr/bin/env python2
/usr/bin/env: python2: No such file or directory
```

for me
 please correct your PR then i will accept the modification
  it goes against "uncensorable" goal, so not a good idea

There was a pullrequest earlier, but never ot merged:
https://github.com/HelloZeroNet/ZeroNet/pull/111/files
 But what about domain name updates? I think it's not worth it, if we want to create more decentralized internet, then we need to use more decentralized domain system.
  Thanks (the plugin config bug was fixed in the latest version)
  @Erkan-Yilmaz The unviersal admin is for managing site database, the muting feature is only for you and it would not modify the site.
 It can be done two ways: 
- Does not insert hidden user's data to database at all: Probably easier, no site modification needed, but you will not notice if you miss all content created by the user (topics, comments, mails, etc.)
- Let the sites handle it: Needs modification on every site, but you can see if anyone commented on a topic created by the user you hidden.

It's not that hard, but could be dangerous and narrow your view of the world
 Started working on this:

 - [x] muteAdd command: Adding new user to mute list, params: auth_address, cert_user_id, source, reason. Confirmation requred if not an admin site. Check all sites and removes the json files of the user from databases.
   - [x] Remove entries from database
   - [x] Skip updates
   - [x] Add confirmation dialog
 - [x] muteRemove command: Remove user from mute list, params: auth_address. Confirmation requred if not an admin site. Check all sites and re-add the json files of the user from databases.
   - [x] Re-add entries from database
   - [x] Add confirmation dialog
 - [x] muteList command. List all current mutes. Requres admin permission.
 - [x] UI in ZeroHello to add/list/modify current muted users
 - [x] Implement to ZeroHello
 - [x] Notification for older clients

Questions:
 - Does non-global, only one site muting desirable? No, it's only hides the content, but you will still download and distribute it to other people, because the protocol expects that everyone has every non-optional file.

No mute lists yet, maybe in the future. added in 2cea157eccb2f0b3e19158590d2d3e65ba4022a5  I don't think its a good idea listing directory on every update
 Yeah it's better this way, but I think importing/using Counter is unnecessary, a standard dict will do, and please put a try/exception block like the files has.
 Thanks, i have used a simplier solution for this: https://github.com/HelloZeroNet/ZeroNet/commit/6d222b6ed768700e188bf862ac36ef075e5e989d
  Please use http://zeronet.readthedocs.org/en/latest/help_zeronet/contributing/
  I don't think it's not a real threat: if you loose your bitcoin wallet, then the attacker will get your money. if you looks your users.json then you can register a new one any time.
 Sure, but he has access to your hdd then your are fucked any way regardless if its encrypted or not.

I'm just saying there is not much motivation to get your users.json, while there is a huge bounty on your wallet.dat.
  Are you sure you have used the correct ZeroFrame.coffee ? http://127.0.0.1:43110/blog.zeronetwork.bit/data/files/ZeroFrame.coffee
  Currently ZeroBundle is the default and recommended install method. It contains all of the libraries the you need to run zeronet. (SSL+Python is a sad story: had lots of problems with different openssl, gevent and python versions that are incompatible with eachother) It also has built-in update method that downloads the latest version from github, unpacks it and restart itself.
 It's hard to pin version, because it's also depends on OpenSSL and Python version which is supplied by the OS. The updating is done by `update.py`
  The problem is it will delete the tor settings and readme
  Tor directory is necessary to run zeronet on windows
 Adding ignore pattern for non-default files could work.
  Probably the old process is still running. Please check process list / log files. Are you sure it's not in your systray icon list?
  The problem is the wrapper does not know if the frame loaded or not. You have to send a "innerLoaded" command to the wrapper when you finished rendering your page (loaded all database query) and it will add the hash to the site url. 
https://github.com/HelloZeroNet/ZeroBlog/blob/bb8dca17b6c3ce33a9ecf22ab295cfc540c541c9/js/ZeroBlog.coffee#L255
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Ui/media/Wrapper.coffee#L100
  Have ability to modify the site layout/add new features without modifying the original source code to keep it updateable.

Eg if you create a `plugins/DarkSkin/all.css` file on all.css request it would also append this file's content to the end. (same for js)

Maybe combining something similar like hotpatching in #322, so it would be possible to easily attach new functions to events.
  Yes, in multiuser mode for security reasons nothing is written to disk
  thanks
  This will fail if more than one keyframes defined

https://regex101.com/r/kG2iI0/1
 Probably this should work: `@keyframes (.*? {.*?\n})`, please confirm
 Thanks
  Yeah, it was fixed yesterday: https://github.com/HelloZeroNet/ZeroNet/commit/eea55f8f16fa4737d7d08686c12e0c443e48e760
So updating from rev980-1038 will require manual start after the update, but the next update should be fine.
  If the browser does not allow to connect to the ui server, then we can't do anything about it. You can try access it using your LAN/WAN ip.
  Probably relevant: https://github.com/HelloZeroNet/ZeroNet/issues/288#issuecomment-194722911
 Looks like for some reasons the new zerohello site does not have admin rights for you, shut down zeronet, open data/sites.json, search for 1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D and add "ADMIN" to "permissions":

```
    "permissions": ["ADMIN"], 
```
  Added @ and = to allowed filename patter
  The error: can't open the application ZeroNet because the classic environment is no longer supported.

I have no access to 10.8 Mac, so need suggestions how to make better .app. (currently its a bash script: https://github.com/HelloZeroNet/ZeroBundle/blob/master/ZeroNet.app)

An icon also would be nice.
 the zerobundle package has the required python with the dependencies, so we don't use the system python, but the packed one: https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-v0.1.1.zip

Can you try to open a terminal and run it with `bash ZeroNet.app`?
 thanks for testing, yeah a proper Application bundle would help, I will try ti when I have Mac access, or if you could try to create one and test it that would be great.
 The ZeroBundle package contains the Python binaries with every dependency. When you first time start zeronet it downloads the latest version from github, unpacks it to ZeroNet directory and starts it. There is a semi-auto update method in ZeroNet which is - when requested - it is re-downloads the latest source code, overwrite the files in ZeroNet dir and and restarts itself.

So I think - to keep the built-in update method working - the best would be to convert ZeroNet.app bash script to proper application bundle end leave the rest as it is.
 @drjmedulla
Do you have any special (non-english) character in the directory where you unpacked it?
Please open ZeroNet/log/debug.log file, search for `not in allowed dir` and paste the line here.
 @drjmedulla Can you check if ZeroNet is not running twice? (eg via taskmanager, search for python.exe)
If not helps please send your log files (debug.log and debug-last.log) to hello@zeronet.io
 The log file says:
`[2016-03-18 21:12:51,207] ERROR    Ui.UiServer Web interface bind error, must be running already, exiting.... [Errno 48] Address already in use: ('127.0.0.1', 43110)`
Which means something is running on port 43110, please try to kill the python process and try again.
 We need a proper way to pack a bash script into an .app
@drjmedulla's problem is probably not related to this

probably this helps, but i have no mac access atm to try ti: https://mathiasbynens.be/notes/shell-script-mac-apps
 I was able to make it work on 10.8, but now it's not working on 10.11 :( (Unidentified developer error)

I have uploaded it here, if anyone would able to confirm if its working or not that would be nice: https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-osx-10.8-v0.1.1.zip

Other possibility:

```
#!/bin/bash
osascript -e "tell application \"System Events\" to set visible of application process \"Terminal\" to false"

cd "$(dirname "$0")/../ZeroNet"
bash ../Python/python start.py "$@"
```

But this will keep the terminal icon on dock, any workaround?
 I'm not familiar with OS X app ecosystem, but if we manage to sign the ZeroNet.app, then it would work without any errors (Unidentified developer error) on every platform or do we need to submit it to appstore?
 So can anyone sign the https://github.com/HelloZeroNet/ZeroBundle/tree/master/ZeroNet.app/Contents application please?
 Yep, it should work now  Benchmark is not a websocket function + you redirect it to siteDelete
But nice try :)
  It's a soft limit, the limit checked every 20 minutes and if the site has more than it then close some connections.
 If you are on limited bw it's recommended to disable popular pages for now (ZeroBoard, ZeroID, ZeroMail) Later the bw usage will be reduced

The idle connection bw cost is very low (around 100byte / 5minute)
  It would be nice to see whats different please try the -vv option
 Looks like python version or 32/64bit platform difference, I will try it with python 2.7.11 later (currently running 2.7.9)
  Yes, include tor if you want to use it. Docker philosophy: one service = one container
  @Erkan-Yilmaz Rpi has different binaries so zerobundle probably will not work there.

@jdoig Can you please specify the gevent version and the python version you used?
`python -V`
`python -c "import gevent; print gevent.version_info"`

This works for me on linux/windows:

```
$ python -V
Python 2.7.9
$python -c "import gevent; print gevent.version_info"
(1, 0, 1, 'final', 0)
```
 Can you test this one please?

```
$ python -c "from gevent import monkey; print 'patch_subprocess' in dir(monkey)"
True
```
 I'm a bit afraid to touching it. (Gevent + SSL is a long, sad story, needed many hacks to make it work on most environment)

So I will change the requirements.txt.
 It's done, https://github.com/HelloZeroNet/ZeroNet/commit/25752c927ca694ba912683037829a69432796ad9
Thanks for reporting btw.
 @jdoig Btw it would be interesting for me if you would be able to post http://127.0.0.1:43110/Benchmark results from rpi here.
 Thanks, pretty good, the multipler is compared to my desktop machine (c2d 2.6ghz). So for the most important operations (sql, openssl verify) are around 2 times slower. 

The sha512 unexpectedly slower than sha256. I have choosen sha512 over sha256 because its around 2x faster on modern 64bit cpus. Probably this will improve in 64bit RPi3 OS.
  We need an universal admin interface that allow to manage data stored on sites.

Features needed:
- Query/Modify/Delete ZeroTalk and ZeroBlog (and other sites) database without any source code modifications. (using only configuration files)
- Query/modify users limit using it
- [ ] Create sample configuration file for ZeroTalk and ZeroBlog (xml?, json?, js?, yaml?)
- [ ] Layout mockups
- [ ] ...Coding

This would be huge benefit for all ZeroNet sites, so it would be really nice if someone would be able to take this task, so I will be able to focus on core modifications.
 Example jsx config file for ZeroTalk:

``` jsx
<Site title="ZeroTalk">

 <Page name="topic" title="Topics" orderby="added DESC">
  <user name="json_id" title="Username" disabled save="no"/>
  <input name="added" formatter={ Date.toDate } deformatter={ Date.fromDate }/>
  <input name="title"/>
  <textarea name="body"/>
  <select name="type" values={ ["", "group"] }/>
  <select name="parent_topic_uri" title="Parent topic" values={ Topics.listUris }/>
 </Page>

 <Page name="comment" title="Comments" orderby="added DESC" parent="topic">
  <user name="json_id" title="Username" disabled save="no"/>
  <input name="added" formatter={ Date.toDate } deformatter={ Date.fromDate }/>
  <textarea name="body"/>
  <select name="topic_uri" title="Topic" values={ Topics.listUris }/>
 </Page>

 <Page name="settings" title="Settings" file="content.json">
  <input name="settings.admin" title="Admin name"/>
  <input name="settings.href" title="Admin contact url"/>
  <select name="settings.sticky_uris" title="Sticky topic uris" multi values={ Topics.listUris }/>
 </Page>

</Site>
```

Based on simple config this tool would able to generate an admin interface that allows the site owner to modify/delete/move topics and comments.

Update: added Settings page
 Because then you don't have to re-write the same functions for every site you make, does not bloats the main source code, better tools (eg. batch modify), user management, custom listings, etc.

I already created a similar tool: http://i.imgur.com/cV8mju1.png It saved me many-many working hours. I'm able to create fast and unified admin interfaces using this, every operation is logged and reversable, easy form validations, batch editing, reordering etc.
The sites are only different from xml configuration files, so if i add a new function/enhancement every site will benefit from it.
Unfortunetly it's not portable to zeronet, but I think we need to create a very similar one.
 It should be a standard zeronet site
 pure js also could work, have to try which one is easier to read/extend by creating examples for zerotalk/zeroblog/zeromail
 looks good for me, maybe a bit easier to read the xml version, but I also prefer pure js over jsx, because of "less magic"
 Its verry simple, but the chat tutorial has example for dbquery. Loading database file using fileGet is a bad idea and does not makes much sense.
 This should work:

```
checkTable: (table_name) =>
    Page.cmd "dbQuery", ["SELECT * FROM "+table_name], (res) =>
                @columns[table_name] = res

for table in @tables
   checkTable(table.name)
```

part to separate function, then it should work
 userPublickey is for ecies encryption. the user's auth_address is in site_info object (please check the zerochat tutorial)
 Good idea, created and added some thing before start coding: https://github.com/HelloZeroNet/ZeroAdmin/issues
  I will try, but I usually tests my modifications for longer time and do not want to push it out early, so I need a tool that display the diff and allows me easily to create separate commits based on that.
Any suggestions?
 If you want stable version then download the source code from releases. Master = development version
 Switched to another git client that allows per-line selection for commits, yeah feels better: https://github.com/HelloZeroNet/ZeroNet/commits/master
  At the first look it looks safe for me, but need more research about it.
 @vlad20012  Unfortunetly it's not possible: 

```
document.body.getElementsByTagName("iframe")[0].contentWindow.open
VM3924:1 Uncaught DOMException: Blocked a frame with origin "http://zero" from accessing a cross-origin frame.
```

The outer document also sandboxed from inner frame, so not allowed to access any property of it.

The possible cross-platform solution is adding a zeroframe api command for it, but I think it's easier to open everything in current window, most of the users are familiar with middle mouse click

So maybe it would be better to deny popup window opening (by removing sandbox flags) as it's not predictable.
 @vlad20012 I'm not familiar with google account registration, does it also requires communication between the window and the opener?
 Related: https://mathiasbynens.github.io/rel-noopener/ (target=_blank considered harmful)
 Added a wrapperOpenWindow command: https://github.com/HelloZeroNet/ZeroNet/commit/99f0407ba23707774884cd2ad103914044414587
Tested and works on youtube for me.
Example: `Page.cmd("wrapperOpenWindow", "https://github.com")`
 I was unsure about that, but why not. Added: https://github.com/HelloZeroNet/ZeroNet/commit/6496a6125f65ed770778992858b3b152467b40ef
 Nice, I think we can close this then
  In the recent versions of zeronet is much more dependent on sqlite (fast startup, peerdb, optional files db), so if it's not working correctly, then zeronet will not work at all, this is expected
  Big files not supported yet, so you can't embed videos.
 It is, the example @ http://videojs.com/getting-started/ works for me. If you don't want to merge the video.js resources with your blog js, you can create a js directory in the data dir and put it there.

But video embedding should also work without any external js library. (the browsers has built-in ui for it)
 You need to add
`<link href="video.js/video-js.css" rel="stylesheet">` and `<script src="video.js/video.js"></script>` to your index.html's `<head>` section or you can also paste this lines directly to your blogpost

and `<video src="data/videos/any.mp4" width="600" height="342" loop="" muted="" preload="auto" class="video-js"></video>` to your blogpost where you want your video
 zeronet sites runs in sandboxed iframe for security reasons, in this enviroment not every javascript functions are available.
 no, its not possible
 The sandbox is protecting user's data, so it will not removed. Pressing F11 for fullscreen should work in every browser.
 Different browsers, different limitations.
  Tor error is not relevant, your sites.json is broken somehow (probably hdd error or the last shutdown was improper), you need to fix it around line 4356. or check if sites.json.old old similar is present.
  if you are sure about you have to correct private key and your site does not exceed 10MB try `python zeronet.py --debug siteSign 17JcQZkstLE9LH5dn49mCQhC6tamZDyi7F --publish`
  yes, its correct
  even if you are on --tor always you will see mixed peers. the non-onion peers are connected using exit nodes.
  Just copy data/users.json to new installation.
 no, copy ZeroNet-master/data/users.json to NewInstalledZeroNet-master/data/users.json. (if you copy it to your site's directory then you will publish everyone your privatekey, so anyone would able to modify your blog)
 Just open the blog in the browser, the files will be downloaded from other peers.
  can you please specify your platform?
 Probably fixed in latest version, please update & verify: https://github.com/HelloZeroNet/ZeroNet/commit/ff681adfe9e92f8f139347499c35783ed47160a4
 - Files in sub-directories first ordered by directory and filenames
- Then files in parent directories ordered by name

for zeroblog:

```
js/lib/00-jquery.min.js
js/lib/highlight.pack.js
js/lib/identicon.js
js/lib/jquery.cssanim.coffee
js/lib/jquery.csslater.coffee
js/lib/marked.min.js
js/lib/pnglib.js
js/utils/Class.coffee
js/utils/Follow.coffee
js/utils/InlineEditor.coffee
js/utils/Menu.coffee
js/utils/RateLimit.coffee
js/utils/Text.coffee
js/utils/Time.coffee
js/utils/ZeroFrame.coffee
js/Comments.coffee
js/ZeroBlog.coffee
```
 Looks right for me (jquery colorbox depends on jquery)
  Thanks, fixed!
  This is a bad idea, big files >1MB not supported yet + please define it as optional files
  please check if http://127.0.0.1:43110/Benchmark runs without any error and maybe log/debug.log have more detailed information. (you can also send it to me: hello@zeronet.io)

Can you please also try the ZeroBundle package?
- wget https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-linux64-v0.1.1.tar.gz
- tar xvpfz ZeroBundle-linux64-v0.1.1.tar.gz
- cd ZeroBundle
- ./ZeroNet.sh
 there should be a log and a data directory where you started ./ZeroNet.sh
 Thanks, got it. It's looks like a network error, the connections are timeouting.
  no dist specific package, but: https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-linux64-v0.1.1.tar.gz should work everywhere
  Please also check if it's the same error in another browser
 @jamesalexanderdickerson Do you have any special character in the directory path where you have extracted ZeroNet?
 Please try to update to latest version, start it, then check `log/debug.log` and search for text "not in allowed dir" it should give more idea about the error.
  The auth work, but you need Tor 0.2.7.5+: http://zeronet.readthedocs.org/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
  I dont understad, the sites.json contains the site's bitcoin address (eg. 1TaLkFrMwvbNsooF4ioKAY9EuxTBTjipT), which is case-sensitive
 Fixed: https://github.com/HelloZeroNet/ZeroNet/commit/48db062b49bded23db2a6cfd35a836d5c2d0e77b#diff-9af49b2fc8a9d6fa47722290019d9104R57

(to make the duplicates disappear you have to delete the entries from sites.json manually)
  Probably a confirmation dialog of "You already have certificate for zeroid.bit, do you want to change it?" would be better if cert is already exists
 The domain plugin is optional and not restricting it by site domain would allow to recover your ID even if ZeroID site is disappear for some reasons.
 Added confirmation if cert with the same domain already exists: https://github.com/HelloZeroNet/ZeroNet/commit/9bb0a0d91b38c15bcda81676ca41b85abe187079
  never seen that error, please try https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-v0.1.1.zip it has everything packed in.
 Maybe somehow you have installed 32bit module for 64bit python or vica-versa.

via http://stackoverflow.com/questions/16386707/python-django-on-a-mac-illegal-hardware-instruction
 sounds like /Applications is a special folder:

```
If you have your binary stored in your Applications folder you can do this and it should fix it:

# sudo chmod + x /Applications/Twine.app/Contents/MacOS/Twine
```

via https://groups.google.com/forum/#!topic/tweecode/3X7oJxxYHpg

if not working please try to move it to your home
  It's required to check tor works correctly and returns the exit node ip. you can skip it if you want by starting --ip_external 127.0.0.1
 It connects to a service that is returns your external ip (tor exit node) and checks if the file server port is opened (always returns no when using tor)
 because it's returns your external ip (exit node), which is used in some places

i don't see why is it a problem
 It's puts own ip to blacklist, so dont try to connect/publish modifications to itself
 Not much, but I dont see why is it a problem. It also puts your on the map and on sidebar and you can make check your exit node ip using /Stats
 there is no hidden service-only mode yet, you will use exit nodes regardless if there is port checking or not, so it's not related to this topic
 > Why not remove it from the web interface when using --tor always?

It displaying a green "Closed" with the description "Good, your port is always closed when using ZeroNet in Tor always mode." when you are using --tor always
  it's not compatible with http://zero/ access please use 127.0.0.1:43110
  Added local multiuser mode to latest revision that is fixes this issue.

To enable it you have to start it using `--multiuser_local` parameter or create a zeronet.conf where your zeronet.py file is with this content:

```
[global]
multiuser_local
```
 You need to enable the plugin first by renaming `plugins/disabled-Multiuser` to `plugins/Multiuser`
  probably you have not unpacked it right, please make sure you have the same files/dirs as in: https://github.com/HelloZeroNet/ZeroNet
 are you sure you are in the right directory and you running it using `python zeronet.py` ?
 please try this one: https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-v0.1.1.zip

just download, unpack and run ZeroNet(.app)
 Is it working for you?
 nice :)
  please specify the error message
  I dont really want to expose the private keys to webui.
 In that case it can be implemented in the mobile app.
 A bad browser plugin would able to stole it from the another port.
 Sure, but we should minimize the attack vectors
  https://github.com/HelloZeroNet/ZeroTalk/pull/12
 # Idea1: Hotpatch

You would be able to "hotpatch" any of the site's files based on language files, eg. if you have a `translate/ru.json` containing:

```
{
 "js/all.js": {
   "Please, your choose account before upvoting.": "Russian translation"
  }
}
```

And the user have selected Russian as language, then ZeroNet will return all.js replaced "Please, your choose account before upvoting." with "Russian translation". To avoid partial matching the part should start and end with characters: `' " < >`

If required (will try to translate zerohello and zerotalk and it will turns out), then we could add allow partial and regex matches by `js/all.js:re` and `js/all.js:partial`
- [ ] Performance benchmarks
- [ ] Implement as "Multilanguage" plugin
- [ ] ZeroHello modification to allow select preffered laguage

## Pros
- No need to modify the site's source code
- Fast (js files are cached by browser)

## Cons
- Possible text confilcts
- Harder first time translation

# Idea2: Use js translation table

Create a `t('Hello')` js function that is always return the translated version of the text.

## Pros
- Less magic
- No partial text conflicts

## Cons
- Adds extra complexity/noise to source code
- Performance: Has to replace in real-time, could be slow if a page contains 1000s of text
- Only JS replace possible (No css/html)
 First benchmarks: https://gist.github.com/HelloZeroNet/f684d2f1eb7807a124b3 from my old core2duo cpu:
- it takes 4.8ms to replace the texts in zerotalk's all.js (220kb) 
- down to 2.6ms if we skip js/lib/\* from translating
- 2x more translate replacements adds only +20% running time

So probably we don't need to cache translated files.
 Added in 0.5.1, translation files:
https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Translate/languages/hu.json
https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Sidebar/languages/hu.json
https://github.com/HelloZeroNet/ZeroHello/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroMe/blob/master/languages/hu.json
https://github.com/HelloZeroNet/ZeroTalk/blob/master/languages/hu.json
  can you please run `ulimit -a` ?
 I have created a simple script to test and change current limit, please save it, then run using `python test_max.py` and paste the result here.

https://gist.githubusercontent.com/HelloZeroNet/d9bf888693e66a573815/raw/afdb058ad9709036172ef5ccfc9ad38bf1619c28/test_max.py
 Yeah 256 is pretty low, 1024 on linux and 512 on win by default.

Good news is looks like we can change it from python code. I will add it later today to ZeroNet
 I checked my VPS-s using `ulimit -Ha` and the lowest hard limit was 4096 (Debian 7), the others (CentOS7, Debian8) has 65535.

At the startup ZeroNet will try to change the max opened files to 1024.
 Fixed in latest version (rev948), please update!
After restart you can verify if its working by searching for `Current RLIMIT_NOFILE:` in `log/debug.log` (it's right after web interface address displaying)
 sorry i have no osx access, maybe need to change other os settings. you can also try to set it higher by `--max_files_opened 10240`. (it's 65535 by default on linux)
 @iShift Any update if `--max_files_opened 10240` fixed it?
 Probably fixed by: https://github.com/HelloZeroNet/ZeroNet/commit/6f2445c417e59c3bf948ff5c3fd0a722c710f9d3  Thanks, fixed!
  You need to enter the master_seed from users.json.
  The multi-user plugni is not compatible with the chrome plugin, so you need to use it via http://127.0.0.1:43110
  It would be nice, but I don't have access to OSX machine
 No, it's just a packed version of installed python. So I installed python to my machine, added some package (pip, gevent, msgpack), zipped the C:\Python27 directory. And ZeroBundle uses this to run python files: https://github.com/HelloZeroNet/ZeroBundle/blob/master/zeronet.cmd

I think it could also work for Mac. Tomorrow I try to get an OSX access and try.
 I think i was able to create a bundle for mac, please help me verify it's working: https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-v0.1.1.zip
- (Close ZeroNet if already running for you)
- Download, unpack, run ZeroNet(.app)

It should download the latest version from github, start it and open ZeroHello in the browser.

Please also check http://127.0.0.1:43110/Benchmark if everything is ok. (no errors, openssl verify is working, the python version should be 2.7.11)

Thanks!
 @iShift Thanks! What's version of OSX are you using?
 You have to open a terminal and drop the zeronet.app to it
 It works with double-click on latest osx, the Terminal dropping is only requred for older versions

I have created a proper .app that works on all osx, but it needs to be signed that i unable to do. (needs apple osx dev certificate)

more info: https://github.com/HelloZeroNet/ZeroNet/issues/363
  This is two separate project, if you have zeronet running then you can browse zeronet sites in the tor browser using http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/
  If you registered it using a zeroproxy and have not saved the private key displayed on first visited, then it's lost.
If you using local client and have not reinstalled zeronet, then it should be recovered when you visit the zeroid site.
  You can right click to the systray icon and check starts zeronet when windows starts
  Thanks, fixed!
  if you start it with zeronet.py and the `--open_browser` is not present, then it's not opening the browser. If you start it with start.py then it will open the browser. (it basically = `zeronet.py --open_browser`)
 If you are using zerobundle the edit zeronet.sh/cmd/app and change start.py to zeronet.py, then the browser window will not open.
 You are safe to ignore the port error
 You can try to check browser's javascript console (F12) for errors. Probably something (browser extension) is blocking the javascript
  Can you please specify your os/browser version?
 Do you have antivirus software installed? sometimes it can make strange things
 Nice find, please try to report it to the plugin owner to allow to setup whitelist or allow it on 127.0.0.1.

Update: I have downloaded the extensions and looks like the blocking is not intentionally, it uses postMessage to communicate between the browser and the plugin and this is overwrites ZeroNet messages. So probably only the plugin owner able to fix it. (disable it on 127.0.0.1 probably would work)
 Ok, thanks. so it's not filtering just sending extra messages, this can be solved and will add it in the next version
 I think it's fixed in latest revision https://github.com/HelloZeroNet/ZeroNet/commit/e891a10e54c31468849ed65892ed97bbb548a534#diff-25ec8dd4ba66e508e805a317bc38fa5fR82
Please update & check
 Thanks
  Thanks
  Hi, it's not possible yet, but planned later.
  To do that create a file named `zeronet.conf` where your zeronet.exe with the content:
```
[global]
ui_port = 12345
```

There is also a `zeronet.cmd` for command line usage.  Thanks for reporting, fixed now: https://github.com/HelloZeroNet/ZeroNet/commit/3f6f273fb1e01b3185793b1f3b4a95a83e6a4608
  gevent is a library that needs to be installed to run zeronet. Please try: `python -m pip install gevent msgpack-python`
 please try `sudo easy_install pip`

other method if this is not works:
- `wget https://bootstrap.pypa.io/get-pip.py`
- `python get-pip.py`
- `python -m pip install gevent msgpack-python`

on the weekend I try to get access for an OSX machine and create a simple, "unpack and run" solution like we have on windows.
 I think i was able to create a bundle for mac, please help me verify it's working: https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-v0.1.1.zip
- (Close ZeroNet if already running for you)
- Download, unpack, run ZeroNet(.app)

It should download the latest version from github, start it and open ZeroHello in the browser.

Please also check http://127.0.0.1:43110/Benchmark if everything is ok. (no errors, openssl verify is working, the python version should be 2.7.11)

Thanks!
 Probably relevant: https://github.com/HelloZeroNet/ZeroNet/pull/687

Please update and try again!  Instructions for linux:
http://zeronet.readthedocs.org/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
 old version detection fixed now: https://github.com/HelloZeroNet/ZeroNet/commit/e891a10e54c31468849ed65892ed97bbb548a534#diff-d8841277993f336590a11cd5623974c9R156
  I'm not fan of non-ascii domain names: they hard to type and possible phishing attacks via similar characters
  Yes,I think :) Thanks
  `zeronet.py --ui_restrict 1.2.3.4 2.3.4.5 4.5.6.7` is the correct format
 Try with ./ZeroNet.sh --verbose --ui_ip 0.0.0.0 --ui_restrict 43.53.63.73 --debug
(last argument should not be multi-parameter)
  Well, use curl :)
`curl http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/content.json`
 `curl http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D` should work as adding site
  You need to enable password plugin by rename data/disabled-uipassword to data/uipassword
  Looks like openssl problem, can you please run `openssl version`?
 Yeah, CentOS has tricky openssl (they removed some curves we need), please try this: 
- `wget https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-linux64-v0.1.1.tar.gz`
- `tar xvpfz ZeroBundle-linux64-v0.1.1.tar.gz`
- `cd ZeroBundle`
- `./ZeroNet.sh`

It has everything included. Please let me know if it works! Thanks!

btw you should update your openssl: https://www.linode.com/docs/security/security-patches/patching-openssl-for-the-heartbleed-vulnerability
 I think I know why, can you please check the line `- OpenSSL loaded, version:` in the log? It should be in the first 10 lines
 Thanks! Already working on the fix, will be out in hours
 I think it's fixed, please download the latest version and try again. Just delete ZeroBundle/ZeroNet and it will re-download the latest version. (Backup data/users.json if you already created a profile)
  Thanks!
  http://zeronet.readthedocs.org/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
 @wfjsw yes, please read http://zeronet.readthedocs.io/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
  start zeronet with `--ui_host "192.168.163.20"` Try this way:
```
[global]
ui_ip = *
ui_port = 43110
ui_host = 
 192.168.163.20
 192.168.1.163
``` Can you please specify the exact error message you get? F12 > Network tab > all.js > Response  we need python2, so try `python2 -m pip install gevent` or `python2.7 -m pip install gevent` please
 nice!
  please try `python -m pip install gevent msgpack-python`, maybe the pip command uses different python installation

I have no osx access, so it would be nice if someone could create a easier installation method for mac. Maybe similar to zerobundle for windows where everything is packed up in a zip file, all you need to download, unpack and run zeronet.cmd.
 I think i was able to create a bundle for mac, please help me verify it's working: https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-mac-v0.1.1.zip
- (Close ZeroNet if already running for you)
- Download, unpack, run ZeroNet(.app)

It should download the latest version from github, start it and open ZeroHello in the browser.

Please also check http://127.0.0.1:43110/Benchmark if everything is ok. (no errors, openssl verify is working, the python version should be 2.7.11)

Thanks!
 https://zeronet.io/ should offer this method by default now.
 use the ... menu on ZeroHello
  something is bad with formatting: https://github.com/ashleypt/ZeroNet#docker
  [Appimage](http://appimage.org) helps packing apps which can run on all major Linux distribution s based on concept of _one app = one file_

If zeronet can be packed along with all its dependencies inside an appimage, users can simply download give permission & run the file. 

Popular apps like scribus, krita are also adopting this method to distribute their apps. 

Projects repo: https://github.com/probonopd/AppImagekit 

The developer @probonopd is happy to help you packing your app :) 
 Yeah, it would be nice, last night i started having openssl segfaults on CenOS. Only compiling python 2.7.11 and the latest openssl solved it. (CentOS have crippled openssl by default that does not support bitcoin's curve)

My concerns:
- It would broke the semiauto-update (you can update to the latest source code with one click)
- Plugins (separate .py files)

For windows we have a ZeroBundle package that has python + all dependencies packed, but leave the source code on the hdd as it is. Would this possible with AppImagekit?

A similar solution for mac also would be nice, but I have OSX no access.
 I think you are talking about atomic updates. Yes. It can be possible to provide update to specific parts of the app. Just have a look into that project once you find some time :) Also it's a simple process to turn an app into app image. No special skills required. 
 @HelloZeroNet since you are now providing a static archive for linux, why don't you distribute as appimage ? I tried making it but faced path relocation problems. I'm not good at fixing those. @probonopd help needed in this case...  
 it could be possible, but not sure about the benefits
 @HelloZeroNet  please give a try. regarding advantages, all files are in compressed state all the time & makes the app more portable  
  You have to start it using zeronet.py --ui_ip "*"

More info:
http://zeronet.readthedocs.org/en/latest/faq/#is-it-possible-to-install-zeronet-to-a-remote-machine
 same syntax: zeronet.py --ui_ip 1.2.3.4
  You have to add your user to tor's group: http://zeronet.readthedocs.org/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
 yeah, sorry probably you have to add to torrc config file: `CookieAuthFileGroupReadable 1`

mine: `-rw-r----- 1 debian-tor debian-tor 32 Feb 28 19:52 /var/run/tor/control.authcookie`
 You can try changing the cookie path using `CookieAuthFile Path`

Update: I think i found the problem (`re.search('Tor="([0-9\.]+)"', res_protocol)` and you have `VERSION Tor="0.2.8.1-alpha"`), some minute and I will send the fix!
 Here is the fix: https://github.com/HelloZeroNet/ZeroNet/commit/779075c4a56ef921f4095220725a16b156eba52e
  Hm i have not met this one yet, can you please execute
`python -V` and `python -c "import gevent; print gevent.version_info"` commands?
 Hm, I have just setup a new Ubuntu 15.10 VPS, 

```
# apt-get install python python-gevent python-msgpack
# python -V 
Python 2.7.10
# python -c "import gevent; print gevent.version_info"
version_info(major=1, minor=1, micro=0, releaselevel='beta', serial='1')
# python zeronet.py
- Starting ZeroNet...
[22:29:36] - OpenSSL loaded, version: 01000204F
[22:29:36] - Version: 0.3.6 r909, Python 2.7.10 (default, Oct 14 2015, 16:09:02)
[GCC 5.2.1 20151010], Gevent: 1.1b1
...
```

So everything works fine here, still investigating...
Are you on 32bit or 64bit? Installed gevent using apt-get or python pip?
 New installation method released, please try this:
- wget https://github.com/HelloZeroNet/ZeroBundle/releases/download/0.1.1/ZeroBundle-linux64-v0.1.1.tar.gz
- tar xvpfz ZeroBundle-linux64-v0.1.1.tar.gz
- cd ZeroBundle
- Start with ./ZeroNet.sh
 Yes, the ZeroNet directory = git repo

But you can also update it from the WebUI using â‹® > Version: ... on ZeroHello (It's basically downloads the latest version from github and overwrites the existing files)
  Just copy the users.json file and you will have the same identity
 The problem is you can't really delete an incoming message, just hide it, because it's owned by the sender and only he/she able to modify it.
 In ZeroMail every user has a data file where he/she stores the messages he/she sent. You inbox lists messages from other users data file that is sent to you (encrypted to your public key).
This data files are only modifiable by it's owner, it means you can't delete from your inbox just hide it. The hidden messages identifier currently stored in browser's local storage, so it's not synced between devices.
 Mails are stored in your hdd, when you delete a mail from your inbox it adds the mail's id to browser's local storage. Next time you visit the page the js checks reads the deleted ids from browser's local storage and skips them.
  Thanks
  There is no other way to stop it yet.
  If you start your tor process on port 9050 and 9051, then it should work fine. The tor browser uses different port (9150 and 9151), be we don't connect to that service, because if you close the tor browser it would also make zeronet stop working.

If you want to share service with the browser then you have to start it using `zeronet.py --tor_controller 127.0.0.1:9151 --tor_proxy 127.0.0.1:9150`
  Sorry, I can't reproduce window opener security check using the docs site
 Yeah thanks, it's looks like-firefox only (no idea why), possible solutions:
- (recomended) The site owner add target=_top to every link. The easiest way to do this is creating a `docs.js` file with this content (docs.js referenced in the html source code, but it's not exists):

```
var base = document.createElement('base');
base.target = '_top';
base.href = document.location.href.replace("/media", "").replace("index.html", "").replace(/[&?]wrapper=False/, "").replace(/[&?]wrapper_nonce=[A-Za-z0-9]+/, "")
document.getElementsByTagName('head')[0].appendChild(base);
```

(please also upload [docs.css](https://github.com/HelloZeroNet/Documentation/blob/master/docs/docs.css))
- The site owner add  `"postmessage_nonce_security": true` to [content.json](https://github.com/HelloZeroNet/ZeroBlog/blob/master/content.json#L148), which is disable the popup message (default now for new sites)

Also added some modifications to latest revision to make it work better, but it's not 100%
  ZeroNet protocol is totally different from bittorrent and does not use any torrent liblary, so it's not an issue here.
 ips are not leaked when connecting to trackers, it uses the exit node ip
 The trackers also requested using the exit nodes, so i think it's not an issue
  Better way to disable caching:
- Open browser dev tools: F12
- Network > Disable cache (Chrome), Gear > Disable cache (Firefox)
- This will disable content caching until you keep the dev tools opened, so you don't have performance drawback when browsing the web normally
  `zeronet.py siteSign 1Apr5ba6u9Nz6eFASmFrefGvyBKkM76QgE --inner_path data/users/content.json --publish` should help (or you should pass the `--inner_path data/users/content.json` also for sitePublish)
  Unfortunately its not possible to query zeromails, because they are encrypted in the database. ZeroID is not really useful by itself, you will be redirected to it when you need to register a new one.
  Can't reproduce it under Win/FF/Chrome/IE yet
 Fixed in the latest version
  I think sharing scripts is a bad idea: It increase centralization and the CDN site owner would able to inject scripts to other sites.
 Still don't think it's worth relying on a central site to save 1-200kbyte storage
  The browsers does not allows this. Related topic: https://github.com/HelloZeroNet/ZeroNet/issues/83
 Using the [Chrome plugin](https://chrome.google.com/webstore/detail/zeronet-protocol/cpkpdcdljfbnepgfejplkhdnopniieop) you can access sites using http://zero/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D and http://zeroid.bit

I think it's better, because no need to modify OS settings (cross-platform issues) and for example in chrome you get confirmation window if you want to click on external protocol handler's link (eg. torrent://) http://i.stack.imgur.com/E3Yk9.png
  Updated!
  Added to latest version: https://github.com/HelloZeroNet/ZeroNet/commit/61cfb8aa2ff222b9a92e466dddf59c8d92f8e772#diff-0823b49a6bc2f350e7c6134f24e9440dR211
  It's possible already: Every user and site identified by a Bitcoin address. You can see the user's address by hovering on username eg. on ZeroTalk.
 Yes, your ZeroID's private key is in data/users.json file (auth_privatekey part) Its saved in WIF format that supported by most of the Bitcoin clients.
  You have to update your Tor to make it work

For instructions please check: http://zeronet.readthedocs.org/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux
  NPM is for javascript, ZeroNet is written in Python, which has PIP instad of NPM. You can use `pip install -r requirements.txt` to install dependencies.
  It's not easy to do in safe way (the update method's replace process is not 100% safe). If you enable tor you should also switch to Tor browser, and preferably delete your data dir after you shut down your client.
  It's not possible because the per-site sql queries are merged for performance reasons (eg. if you follow 10 topics on zerotalk it visible as one subscription)
  You will be redirected to it if you want use a site that requires it.
  I don't think it's necessary, you can remove the site if it's abusing the feature
  the browsers are caching redirects, you have to clear cache to make it forget the old address: http://superuser.com/questions/304589/how-can-i-make-chrome-stop-caching-redirects
 Added a workaround to this problem by opening directly the site when clicking on the trayicon
  serviceworkers does not works within sandboxed iframe. it can be implemented in zeronet zeroframe api to display newsfeed events, but its still an expermiental technology, so maybe later when it's become more mature
  The easiest way to do this is using websocket api, the right version and dependencies also required if its imported as library.
 You can pack gevent and msgpack with your zeronet (there is a download, upack & run [zerobundle](https://github.com/HelloZeroNet/ZeroBundle) package for windows), so you won't have to install anything. QT is a GUI library, it has bindings for almost every language.
It's also possible to compile python programs into single executable , eg.: http://www.py2exe.org/ or http://www.pyinstaller.org/
  You can do this currently, around 2 months ago AES encryption API is added to ZeroNet bacause of the ZeroMail (end-to-end encrypted mailing) site.

For example currently you can create an encrypted image hosting site: at the upload. the user defines the password and publishes the image in encrypted form (eg. in a json file). In this way the image can be downloaded and served by anyone in the network, but only able to see it who has access the password. So there would be no evidence that you know what are you distributing, because if you don't have the password you could not decode the image.

Easier way to password encryption of sites or part of the sites are also planned.
 You have the full control over what are you seeding, if you find anything suspicious you can remove the site.
 You can simply delete the site you don't want to seed anymore.
 If you find any problematic content over any of the sites you can issue a warning in ZeroTalk forum, I don't think it would be a good idea to implement a built-in censorship. I don't see why is the command line required for this (or how is it connected to this problem)

If I upload anything problematic to my google drive and share the link over the internet will they arrest the google server operators?
  Site size is also visible if you choose "Order by site size" on ZeroHello  It happens when data/users/content.json is not signed correctly and your root content.json is also missing some information (eg the ignore node)
  Yeah, there is no error message callback yet, currently you can check if the user has cert or not by:

``` coffeescript
@cmd "siteInfo", {}, (site_info) =>
     if site_info.cert_user_id then alert(site_info.cert_user_id)
```
  Verify if your tor controll port is opened: `sudo netstat -anp | grep LISTEN | grep 9051` and `nc 127.0.0.1 9051`
  Thanks!
  Looks like you missing some package that required by pip. The Debian install method should work on mint: https://github.com/HelloZeroNet/ZeroNet#debian
 Follow the instructions in the message:
- sudo apt-get install python-pip
- sudo pip install msgpack-python --upgrade

OR

To update msgpack without PIP:
- Download msgpack from: https://github.com/msgpack/msgpack-python/archive/0.4.6.tar.gz
- Unpack anywhere
- Copy the msgpack-python-0.4.6/msgpack directory from it to the same directory where your zeronet.py is
  Try update gevent, 0.13 seems very old. (2012)
 you need python source to compile modules: `sudo apt-get install python-dev`
  changed to https, please test
  I don't think it needs to be configurable, but changed to reload it in every minute.
  Nice, built-in bootstrapping supported since 0.3.5, so you don't need separate bittorrent tracker.
- Rename `plugins/disabled-Bootstrapper` to `plugins/Bootstrapper`
- Add zero://bootstrapperhost:15441 to trackers list

example: https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Config.py#L34 (the #... thing is only needed for ssl cert pinning to avoid mitm, you can skip that part)
  It's simple to do with javascript or meta headers
 You can also add your redirect message/rectangle to html if you prefer that way
 After thinking bit more about it it could make sense if you want to transfer your site's ownership.
- The site new owner generates a new address
- You put "transfer": "newsiteaddress" to content.json
- When the clients receive that they rename the directory to "newsiteaddress" and transfer the settings (size limit, etc.), so they don't have to re-download everything 

But it's a very special case (currently i skipping features that affects < 20% of users), so it could wait.
  There is already: --homepage
  Fixed in latest 0.3.6
  Thanks
  I don't think its necessary, you can use the browser's bookmark or if you want shorter address you can register a .bit domain (costs only 0.01USD)
 The other way is using vanitygen: https://en.bitcoin.it/wiki/Vanitygen

You can generate custom bitcoin address eg. 1TheNain38HtKNngkdXEeobR76b53LETtpyT using, it also make easier to find your directory in data dir, in the logs and the browser will also complete it if you type "1TheNain38" in the browser bar.
  Allow to sign up to database queries, so you can have one, unified list of latest blog posts/comments/replies.

Todo:
- [x] Static version of new ZeroHello
- [x] Implement new commands
- [x] Modify ZeroBlog to allow signup to New posts/Username mentions/Comments
- [x] Modify ZeroTalk to allow signup to New topic/Username mentions/Comments
- [x] Site listing on new ZeroHello
- [x] Display site errors and notifications
- [x] Site commands on new ZeroHello: Pause, Delete, Clone
- [x] Display newsfeed on new ZeroHello
- [x] Merge similar newsfeeds
- [x] Real-time updated feed
- [x] Welcome message
- [x] Tor/Port open status to new ZeroHello
- [x] Settings: Always Tor mode, Update all sites, Update to latest ZeroNet version
- [x] New logo favicon/systray
- [x] Test in Firefox/IE/Safari
- [x] Multi user login/logout
- [x] UiPassword logout
- [x] Disable some admin function when using Multiuser plugin

New commands:
- [x] feedFollow feeds -> Set queries that user follows {Name: Query, ...}
- [x] dbQueryFeed -> List last results from signed up queries (admin permission required)

~~UI modifications idea 1:~~
- ~~Add new tab to sidebar~~
- ~~Add per site notification count to ZeroHello~~

UI modifications idea 2:
- Create a new ZeroHello with newsfeed-like activity listing

Query specification:
- event_uri: unique id of the event
- type: article, topic, comment, message, image, news, mention, album, warning, error, info
- date_added
- title
- body
- url

Query examples:
Last posts in ZeroBlog:

``` sql
SELECT 
 post_id AS event_uri
 "article" AS type,
 date_published AS date_added,
 title AS title,
 body AS body,
 "/Post:" || post_id AS url
FROM post ORDER BY date_published DESC
```

New topic in ZeroTalk:

``` sql
SELECT 
 topic_id || "_" || topic_creator_json.directory AS event_uri,
 'topic' AS type,
 added AS date_added,
 "New topic: " || title AS title,
 body AS body,
 "/Topic:" || topic_id || "_" || topic_creator_json.directory AS url
FROM `topic`
LEFT JOIN json AS topic_creator_json ON (topic_creator_json.json_id = topic.json_id)
ORDER BY added DESC
```

Last posts in ZeroTalk mentioned username:

``` sql
SELECT 
 topic_uri AS event_uri,
 'mention' AS type,
 added AS date_added,
 body AS body
FROM comment 
WHERE body LIKE '%@nofish%' OR body LIKE '%[nofish]%' 
ORDER BY added DESC
```

In the current form ZeroMail messages unfortunately won't be possible to put in the News feed
 Currently I preferring the second UI solution: So a new ZeroHello with News feed
 No, unfortunetly ZeroMail integration won't be possible in current form.
 The metadata is also encrypted, so without decrypting it its not possible to know if you or someone else received a message.
Maybe later it will be possible by moving the cryptography logic from javascript to python and store the data decrypted in the database, but not sure yet and it won't happen anytime soon.
 Yeah, its a good idea and title-changing ZeroFrame API command is planned.
 what is ZeroMe? The difference from merger sites (#232) is this feature does not allow content creation and listing is simpler, but it's similar.
 that screen only visible until you have something on your newsfeed, but pinning site to left side could be a good idea and planned later
 Fixed the menu bug.
  The Merger sites feature allow to to query and display other site's data. Using this its possible to create infinitely scalable social sites by having separate sites for every user profile, so you will get updates for profiles that you follow.

ZeroMe: A twitter-like social site
- [x] Layout mockups:
  - [x] Welcome page
  - [x] Profile profile
  - [x] User search
  - [x] News feed
- [x] Static html version
  - [x] Welcome page
  - [x] Profile profile
  - [x] User search
  - [x] News feed
- [x] Logo
- [X] Merger site permission handling/request
- [X] New database structure to allow easier and faster joins
- [X] Merge sub-site data files to merger site's database
- [X] Sub-site adding/delete/list
- [x] Make Sign/File oprations merger site compatible: actionSiteSign, actionSitePublish, actionFileWrite, actionFileDelete, actionFileGet, actionFileRules
- [x] Profile page data structure
- [x] Merger site rebuild DB
- [x] Profile page db structure
- [x] User directory data structure
- [x] User directory db structure
- [x] Update database on new merger/merged site add/remove
- [x] User directory
- [x] Sub-site feed listing
- [x] Profile creation
- [x] Profile page
- [x] Profile editing
- [x] Posting
- [x] Post editing
- [x] Post deleting
- [x] Activity list
- [x] Like
- [x] Commenting
- [x] Comment editing
- [x] Comment deleting
- [x] Follow profile
- [x] List followed users
- [x] Auto download new site on follow
- [x] Following without registered profile
- [x] Also update user database on profile modification
- [x] User content delete solution for efficient user directory archiving
- [x] Avatar upload

Later:
- [ ] Re-share
- [ ] File upload
- [ ] Image upload with thumbnail generation (optional files)

ZeroHello:
- [ ] Group sites by type
 Merger sites #232: Open
 Yeah, it's also add possibility to have a merged reddit-like site. It's won't be limited to user sites, so it could also help single-user sites.

Currently only planning one level nesting.
 I haven't started it yet...In the next few months
 After thinking about it for a while, i'm not sure if one site per user is a good solution

### One user per site

Every user has his/her own site, if you want to follow someone you start seeding the site. If you want to stop following simply remove site from seeding.

Pros:
- No one can modify your profile, but you
- ZeroID independent (comments still requires zeroid)
- Probably easier to implement

Cons:
- Initial seeding can be problematic
- Needs lots of connections (5connection/site is minimum to make sure you got every update)
- More network communication (tracker announce requests)
- More files and hdd space requirement on hdd (if you comment on multiple profile you only need new file for every profile)
- Less privacy: You exactly know who follows who (tor improves this)

### More user per site

Instead of one site per user create "hub" sites that hosts a few 100 users. (10MB limit enforces decentralization)

Pros:
- Initial seeding is no problem, because you joining to an already seeded hub
- Does not need many connection
- Other ppl only know what hubs you are following, but not the exact users

Cons:
- There is a hub owner, who has ability to modify/remove users
- ZeroID required to join a hub
- You get the changes for every profile on the hub

But if you don't want to trust the hub owner, then you can create your own hub and this also eliminates the other "Cons".

So I think the user hub solution is better in every aspects.
 One use per site is less scalable, because you need 5+ connection per site, so if you follow 200 users it means minimum 1000 concurrent connections which is not really sustainable. If the hub owner delete/censorship your posts you are free to switch to an another one, so its not really an issue.

Central messaging / automatically seeding every site without any control is against zeronet philosophy and does not really works with many users. 
 You can use your zeroid to communicate on any hub (there is no difference on this between one site per user and multiuser hubs)
 You will only see users in your newsfeed that you are really following (like you can follow only some of the topics on zerotalk), but you will keep receiving/seeding updates for this profiles. (the hub owner able to remove spamming users)

With user muting (#388) it could be possible to stop distributing updates for users you dont like.
 You can easily index zeronet content, since everything is stored on your computer in json files. There is already a search engine with indexed content: http://zeroexpose.com/ (searching in followed content should be easy without any third-party services)

The muting feature is independent from merger sites
 If you want to search in content that you don't have, then you need external services. Searching can be implemented to zerotalk/blog/etc. it's only matter of javascript code and it's not related to merger sites in any way. The muting feature is also unrelated to merger sites, if you start seeding a hub it does not mean you will start following every user automatically.
 Created an idea to be able to search in every site you serving: https://github.com/HelloZeroNet/ZeroNet/issues/419
 I have not started implementing it yet, but I think the hub sites is the only possible, scalable implementation and its also better for privacy
 Every hub site will be totally independent (there will be no difference between hub sites and any other current site), but it's not a problem, because the merger sites will solve this problem.

If you willing to host your content 0-24 then you can create your own hub, but inactive/not seeded profile sites will be  removed. 

You have to keep in mind, that one user per site is offer worse privacy to you and your users, because it's possible to know who is following who. (and later private messaging also planned later, so if you use separate site there will be possible to know who is messaged to you)
 Yes, it's more centralized, but there is no other way if you want to list/interact content in one place.

On the other hand it's also more decentralized, because the data will be separated from the display logic, so you can modify it (eg. different skin, new features) and you will be still able to browse the same data.
 Like is said before: if you want you will be able to create your own hub, so don't have to rely on anyone
 it should not be less attractive: If you create your own hub it's exactly the same as one user per site solution
 any suggestions for the social site name?

some ideas:
- ZeroHome
- OneZero
- GoZero
- ZeroMe
- ZeroFeed
- GroundZero
- ZeroLoop
- ZeroWay
- WeAreZero
- ZeroWay
- BeZero
- ThinkZero
- PushZero
- ZeroSociety
- ZeroNation
- ZeroWorld
- OnZero
- MeetZero
- ZeroSpark
- ZeroSignal
- Zolo
- Zelf
- Zello
 Every zeronet site is totally independent. Hub = normal ZeroNet site
 @62gs8ha: Merger site (and zeronet) is mainly for data-based sites, but you can define optional files that only downloaded when the user's browser requests it. 
Example: https://github.com/HelloZeroNet/ReactionGIFs/blob/master/content.json#L1796 
site: http://127.0.0.1:43110/1Gif7PqWTzVWDQ42Mo7np3zXmGAo3DXc7h (currently has 560 MB of video, but they only downloaded if your client's browser requests it)
 the syntax is a standard called regexp (http://www.petefreitag.com/cheatsheets/regex/)
- `"optional": ".*\.(jpg|png|gif)"` will make all png, jpg, gif file optional on your file (not recommended if you have other, smaller images in your site, eg your logo)
- `"optional": "(data/videos/.*|data/documents/.*)"` will make all files inside data/videos and data/documents directory optional
 @Split7fire If I can't find any more bug then tomorrow.
 I think i was able to fix all the bugs, tomorrow morning i going to re-check everything, then publish it
 If you already upgraded to 0.4.0, then you can help testing ZeroMe: its visible at ZeroHello's "More sites" section.
 @wigy-opensource-developer It's better click from the homepage (it's only visible if you update to 0.4.x), because it using new database structure for merger sites, so if you visit it using 0.3.x version, then you have to delete and re-add it to make it work.
  Unfortunetly its not possible. (there is no server-side rendering in zeronet)
 Thinking a bit more about it RSS could be possible by also generating the static XML file at new post, but i'm not sure if RSS is widely used anymore.
 Probably Twitter/Facebook killing it: http://www.google.hu/trends/explore#q=RSS
But I agree, it would be useful addition for ZeroBlog.
 No need new command, you can currently write files using the ZeroFrame API

So instead only adding the new blog post to data/posts.json you also add it to rss.xml file
  you have to edit css/all.css and put this line to the top:
`.left .avatar { background-image: url(../data/img/logo.png) }`
  The Tor controll protocol (port 9051) only accept connections from 127.0.0.1, but if multiple user has access to your computer then it's recommended to enable CookieAuthentication.

You don't need root access, but you need to add the user you use to run ZeroNet to Tor's user group.

Steps to do this under Debian: http://zeronet.readthedocs.org/en/latest/faq/#how-to-make-zeronet-work-with-tor-under-linux

It should be similar under Ubuntu.
  What OS are you using?
 please try the instructions in #229, it helped there
 Tor by default running on ports 9050/9051. if you want to use it with Tor browser's tor instance you have start zeronet using `--tor_proxy 127.0.0.1:9150 --tor_controller 127.0.0.1:9151`
 On windows tor is automatically downloaded on first startup that that's the configuration file for it. it's not used on other platforms
 It's not recommended to use the Tor browser's tor instance, because if you close the browser zeronet will also loose the connection. Running tor as system service is better: https://www.torproject.org/docs/tor-doc-osx.html.en
 If you often leaves and re-joins the network, then it is bad for you: You client has to re-validate the contents by ask updates to all site you have visited before and it's also results lots of unreliable/unreachable peers which is bad for the network.
 For windows there is an "expert bundle" that contains tor.exe, so we can download/configure/start it automatically, it would be nice to have same way for mac, but i have not found binary tor.app distribution yet
 No, they not working, but there is no binary for Linux neither
 It works, see: https://github.com/HelloZeroNet/ZeroNet/issues/228#issuecomment-204717804
  Thanks for reporting the disable SSL compression error will be fixed in the next version.

Unfortunately the CryptMessagePlugin (that include cryptography required for ZeroMail) requires OpenSSL, so it will not work without that and for some reasons it could find in enviroment. I will try to find a way to load cygwin's openssl dll. 
 Can you please verify if this works for you: 
`python -c "print __import__('ctypes.util').util.find_library('libcrypto')"`
 It's searching for openssl dll, so its not depends on other python modules installed.

can you check if you have "libcrypto.dll", "crypto.dll", "ssl.dll", "libeay32.dll" or similar in /usr/lib/?
 I also installed cygwin and only thing I was able to make it work:
`python -c "print '%.9X' % __import__('ctypes').CDLL('/bin/cygcrypto-1.0.0.dll').SSLeay()"`
please verify if its also works for you
 Yes, this is what we looking for, I will do some tests then release the patch that fixes cygwin compatiblity
 Pushed the modifications (394a8b16b7521d1885e2e96cb6d0a413b4478bc9) please update your source code and try again.
You can test if the openssl working on http://127.0.0.1:43110/Benchmark page.
`- openssl verify x 100..........0.396s [x0.93: OK]`
 sorry, my bad, please update and try again 35b0019be285cd81dac9d3e0ed97712c76f88a93
  Plugin for custom torrent-tracker like bootstrapping, it will allow full Tor support with hidden addresses
- Allows to store Tor/ipv6/i2p addresses
- Announce multiple site in one request

New FileRequest command:
- announce:

```
{
 "sites": [hash1,hash2, ..], 
 "port": 15441, 
 "onion": "3fyb44wdhnd2ghhl", 
 "onion_publickey": "publickey for onion address",
 "onion_sign": "signed hashes array to provide proof of onion_address", 
 "onion_sign_this": 439284923849,
 "need_type": ["tor","ip4", "ip6"], 
 need_num=10
}
```

Return: 

```
[
 { "ip4": [address1, address2], "onion": [address1, address2]}, "onion_sign_this": current_timestamp}
]
```

`onion_sign_this` is only returned if new address is added for onion address. It's required to avoid signing up addresses you don't own. If `onion_sign_this` is in the returned result then the client has to sign it using the onion address's RSA private key and execute the announce request again with `onion_publickey`, `onion_sign` and `onion_sign_this` fields added.

New command line option: --tor, values
- Always: Open hidden service on startup, use Tor for every connection, do not bind on normal ip
- Enable: If no external IP then open Tor hidden serice on startup, use Tor only for onion addresses (default mode)
- Disable: Do not use Tor at all

Disable [unnecessary](https://www.reddit.com/r/onions/comments/27a64z/https_everywhere_onions/chz70i9) SSL encryption on onion address connects (speeds up connection time)
- [x] New FileRequest command: announce
- [x] Modify zeronet to support bootstrapping from other clients
- [x] Onion address cryptographic functions (sign, verify, pubkey to onion address)
- [x] Onion address support for Bootstrapper
- [x] Onion address support for ConnectionServer
- [x] Disable SSL over Tor connections
- [x] Store Tor clients
- [x] Exchange Tor clients over PEX
- [x] Start/stop hidden services on site visit/delete
- [x] Test Connection peer lock
- [x] Display Tor status in ZeroHello
- [x] Only Tor mode
- [x] Disable Tor mode
- [x] Support Tor control port auth
- [x] Bootstrap statistics page
- [x] Batch onion announce
- [x] Option to keep ssl certs to allow cert pinning
- [x] Do some real-life testing
- [x] Pack Tor client with ZeroNet
- [x] New command line option: --tor
 new ADD_ONION and DEL_ONION commands for per site (and preferably per user) different onion address: https://github.com/Yawning/torspec/blob/master/control-spec.txt
 what do you mean?
 The new ADD_ONION and DEL_ONION commands allows to create and remove hidden services using the onion controller API. So if you visit a new ZeroNet site then a new hidden service (.onion address) will be created for it and also new .onion addresses will be generated when you restart your client.
 Done in Version 0.3.5
  Sounds like something with ssl connection, can you please specify your platform and try to start it with `zeronet.py --disable_encryption` ?
 Encryption is not needed, but recommended. Yes, you can copy old data dir to new.
 I had no similar report before. It's hard to tell whats the problem without reproducing it. Can you please specify your OS version?
 It was related to gevent 1.0.2, fixed in 44a68104fb867f193433aea2be0c791475ff3913
  Well, I'm not against if someone offers ZeroNet hosting as service.
  It's hard to make it work without direct hardware access, but you are also fine without opened port.
 You are safe to ignore it, opened port is not required to use zeronet
 Probably an another router/isp is blocking your port.
  Probably there is no user exists in your data/users.json file. Start zeronet normally to generate one for your then it will be fine.
 yeah, the user is generated on first web request, so it can be problematic on headless mode. Pushed a quickfix, after updating it should work now: 675bd462556c541d65e2d95f91f899146a373aad
  The ZeroBlog is only an example site, there is lots of space (and working hour) of improvements, but I will leave it to other developers.
  Sorry, this looks like ZeroUpload related error, so I can't fix it. Official sites that I able to modify: https://github.com/HelloZeroNet?tab=repositories
  The site does not have any special characters in the files, so probably you have installed your zeronet to non-english characters directory

try moving your zeronet installation to \ZeroNet and try again
 Yes, its a bug, thanks for reporting, i will fix it soon
 Fixed in 3d558a4edfe527450d99458f10cf7681eb96590f
  ZeroNet is an application framework not a social site. Every site is totally independent, so you can create your own startup page if you want, the ZeroHello is just a site on ZeroNet. The source code is here: https://github.com/HelloZeroNet/ZeroHello
  - userPublickey -> return: Get user's publickey delivered from privatekey
- userDecrypt encrypted_text -> return: Decrypted text using current user's privatekey
- cryptEncrypt publickey, text -> return: Encrypted text
- [x] Implement API commands
- [x] Static prototype of the site
- [x] Welcome/Registration screen
- [x] Register user's publickey
- [x] Send message
- [x] List incoming messages
- [x] List sent messages
- [x] Mark new, unread messages
- [x] Contact list
- [x] Faux delete from incoming folder
- [x] Echo bot for testing the service
- [ ] Later: Message thread list
 Problems:
- the current library does not support encrypting / decrypting, so have to find an another for this task
- Is it secure to use the same private key for signing and encrypting? https://bitcointalk.org/index.php?topic=374085.msg4004761#msg4004761
 I successfully encrypted/decrypted texts using bitcoin private/publickeys, the speeds (the lib using c based openssl):

OpenSSL init 0.40299987793sec
Encrypt 100x... 1.45700001717sec
Decrypt 100x... 0.694000005722sec

If we want to hide the message recipient (and probably we do) then we have to try to decode all messages that is going through the system.
To do this efficiently we have to mark and cache messages that we have already checked. So we need a zeronet built-in cache system (probably sqlite based) that is multi-user friendly or we can store the messages in browser's localstorage.
 For experimentation I tried javascript based encrypt/decrypt solution (bitcore), but it's around 80x times slower, so it's not really an option.
pure-python implementation (bitcoin-encrypt) 20x slower
 After doing some research encrypting using only the ecc public key ([bitmessage method](https://github.com/Bitmessage/PyBitmessage/blob/master/src/highlevelcrypto.py#L23)) is not secure eg.: https://www.reddit.com/r/Bitcoin/comments/2ntpvh/bitcrypt_encryption_with_bitcoin_addresses/cmhmny9

So I changed the code from `eccEncypt(text)` to:
`eccEnrypt("ZNE1" + aes_key + aes_iv + aesEncrypt(aes_key, aes_iv, text))`

(similar to [electrum's encryption](https://github.com/spesmilo/electrum/blob/ae425764237d89a5e16db4f984406509f08f2601/lib/bitcoin.py#L541), but without hmac)

The encryption/decryption speed is similar, but it's add + 276 bytes to every message.

It would be nice if someone with more experience in this field give some advice if its a good way to encrypt messages like this.
 The 'cryptografically secure' is not depends on library, but the algorithm.
 The crypto API commands are implemented:
- cryptEncrypt(text, publickey) -> Encrypt a text using the public key, Return: Encrypted text using base64 encoding
- cryptDecrypt(encrypted_text, privatekey) -> Decrypt a text using the private key, Return: Decrypted text
- userPublickey() -> Returns user's public key unique to site, Return: Public key
- userDecrypt(encrypted_text) -> Decrypt a text using the user's site unique private key, Return: Decrypted text
- userDecryptBatch(encrypted_texts) -> Decrypt a list of texts using the user's site unique private key, Return: List of decrypted texts

In the next weeks i'm going to create the messaging site to see if its works correctly, then release the plugin
 Every published file is signed by your client, so not necessary to sign messages.
 You can create a file containing the contract the sign it using the client.
 Yes, you have to send the contract to other user to be able to sign it. Currently only features are implemented that has benefit for any of demo sites to avoid bloating and currently no site planned yet that has anything to do with contracts.
 Added my ideas and questions here: https://www.reddit.com/r/crypto/comments/3t6vnm/need_guidelines_for_ecc_based_messaging/

Information I found for the second idea:
http://security.stackexchange.com/questions/21371/decryption-on-aes-when-the-same-key-and-iv-are-used
It looks like it could be safe reusing the same secret in cbc mode if the message does not starts with the same string. To avoid this we could add random prefix to every message.

Non-public key based, AES encoding of messages would be better for multiple reasons:
- Shorter messages (256+128 bit shorter than first method)
- Faster decoding: 100x ECC + AES = 0.7sec, 100x AES = 0.006sec
- Don't have to store twice: If we encrypt the messages using public key the we won't be able to see our sent message, so have to also encrypt it with our own public key which doubles the storage required.

Cons:
- Everyone will see if you add a new shared secret to your file = started messaging with someone new
- It's more complicated and harder to implement

## Technical whitepaper:

### Method 1 (ECIES: New shared secret for every message):

Per message overhead: 183byte + 41byte (encrypted AES key to my public key to have sent folder)

Sending: 
- Get Bob privatekey
- Encrypt message (to_address, subject, body) using ECIES
- Add to data.json: {"message_id":1, "date_sent": 112382913, "encrypted": "..."}

To have sent messages:
- Decrypt my sent_keys dict
- Add message_id -> aeskey 
- Encrypt again

Checking new messages:
- Already known user files: `SELECT * FROM message WHERE (user_address = 'A' and message_id > 1) OR (user_address = 'B' and message_id > 2)`
- New user files: `SELECT * FROM message WHERE user_address NOT IN ('A','B') and date_sent > my_public_key_added`
- Try to decrypt all message usic ECIES (130/sec)
- Store in browser localstorage: `{date_checked: {A: 1, B: 2}, my_messages: [A_1, B_2, A_3]}`

Displaying my messages:
- `SELECT * FROM message WHERE message_key IN ('A_1', 'B_2', 'A_3')`
- Decrypt messages using ECIES

Displaying sent messages:
- Decrypt AES key from sent_keys {message_id: aes_key}
- `SELECT * FROM message WHERE user_address = my_address`
- Decrypt ECIES (iv: [0:16], ciphertext: [16+70:-32]) using saved AES key

Cleanup:
- Delete oldest message
- Remove it from sent_keys
- Delete non-existent my_messages

New command requred:
- cryptDecryptAes [aes_key1, aes_key2, ...], [text1, text2, ...] -> Tries to decode every text using every aes key

### Method 2 (One time shared secret):

Per message overhead: 0byte
Per contact overhead: 227byte + 70byte (encrypted AES key to my public key to have sent folder)

Sending:
- Decrypt sent_keys dict
- Check if the recipient address in it
- If no shared_secret with user yet:
  - Generate new AES key
  - Encrypt new key using recipient's public key and add to keys (ECIES)
  - Add new key to sent_keys that is encrypted using my public key (ECIES)
- Encrypt (to_address, subject, body) using AES
- Add to data.json: {"message_id":1, "date_sent": 112382913, "encrypted": "..."}

Checking new shared secrets:
- Known user files: `SELECT \* FROM key WHERE  (user_address = 'A' and key_id > 1) OR (user_address = 'B' and key_id > 2)
- New user files: `SELECT * FROM key WHERE added > my_public_key_added`
- Save found keys to local storage {my_key: [A_1, B_2], key_checked: {A: key_id, B: key_id}, message_checked: {A: last_message_id_before_my_key added}}

Checking new messages:
- `SELECT * FROM message WHERE (user_address = 'A' AND message_id > user_A_message_checked) OR (user_address = 'B' AND message_id > user_B_message_checked))`
- Try decrypt them using AES (13000/sec)
- Save found messages to localstorage: {my_message: [A_1, B_2]...}

Displaying messages:
- SELECT \* FROM key WHERE message_key IN ('A_1', 'B_2')
- Decrypt AES keys using ECIES
- SELECT \* FROM message WHERE message_key IN ('A_1', 'B_2', 'A_3')
- Decrypt messages using AES

Displaying sent messages:
- Decrypt AES keys from sent_keys {user_address: aes_key}
- `SELECT * FROM message WHERE user_address = my_address`
- Decrypt messages using saved every AES key

Cleanup:
- Delete oldest message
- If no email left with recipient: Delete from sent_keys, Delete from keys
- Delete non-existent my_messages

New command requred:
- cryptDecryptAes [aes_key1, aes_key2, ...], [text1, text2, ...] -> Tries to decode every text using every aes key
 I have thought about multiple recipient messaging, it would be possible by using the second method (one time shared secret):
- Generating new AES key for the group
- Encrypt the generated AES key for every users publickey in the group
- Encrypt message using the generated aes key

So one time, per group overhead would be: (227byte + 70byte) \* User number in the group. After the group secret is shared, the message sending space would be same as for single recipient sending.

Its also possible using the first method, but then it would be count as separate messages. So if you want to send it to 5 user it will take 5x more space. 

Probably I will choose the first method as its simpler to implement, so it will not feature group messaging.
 Added in 0.3.4
  Thanks, I can't merge the all.js changes because its generated by coffeescript compiler, but merged the Scrollbable.js changes in 3587777ea8adf48c1c23b8c34ccc43a76ffb4551
  With ZeroNet you have an SQL server running on localhost that is always accessible, so you don't need backend server running nodejs or php.

P2P sites requires different thinking than traditional Client <-> Server approach, but porting single page applications could be possible. 

Presentation about how does ZeroNet works: https://docs.google.com/presentation/d/1_2qK1IuOKJ51pgBvllZ9Yu7Au2l551t3XBgyTSvilew/pub?start=false&loop=false&delayms=3000
And there is a _"Tutorial of creating server-less, SQL backed, real-time updated P2P chat application using ZeroNet in less than 100 lines of code"_ in ZeroBlog
 You have to use javascript + html, executing php/python/etc. code would not be safe.
  Thanks
  Thanks for reporting, fixed: https://github.com/HelloZeroNet/ZeroNet/commit/5f0266ed8fd42aa66b5baf3b014bdf1cded4b4eb
  Not sure what do you mean
 You can use the "Keep signed in" checkbox to keep your computer password-less on loopback 
 It could still make sense, but i think its not worth the added complexity
  fixed e296ee7ebb6d5a98431c5d9ef662179778540b9c
  Thanks, fixed: 713baeab63b546dca6a69608a2e3613dd6e87118
  Binding to ui to a public interface is usually not a good idea, and it would make that mistake easier.  Just copy data/users.json file
  Can you please run the command `python -c "import sys; print sys.version; import gevent; print gevent.__version__"` ?
 Not sure why is it happening with gevent 1.1alpha, but added a workaround in latest commit. So please clone again and then it should work.
  Does it helps your problem?
 I think its better let the browser handle the connection. (close might be not compatible with every browser: http://stackoverflow.com/questions/5545161/unable-to-close-websocket-with-javascript)
 Yeah, i think we can close it
  The log looks normal, maybe its connection related problem. (never happened for me)
 Running on localhost or remote machine? Also appears on other borwsers? Is it happens on idle browser window? Also please try to check javascript console for errors.
 sorry, I can't reproduce it in firefox 41.0.2 or ie 11 (i have been clicking around for 5 minutes)
 I'm also on windows 8.1 64bit. 

You can try it on http://bit.no.com:43110/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr if you also getting disconnections there then probably its a browser problem.
 I have just installed the zerobundle on new machine no issues with ff/ie/chrome. 

Try a clean zeronet setup, disable your firewall/antivirus software. sorry no other ideas.
 Its looks like a problem with utf8 file names. I will check it later, but not sure if related to this problem.
 Try start using --debug then look console for web requests/errors, the request order should look like this:

```
[18:03:02] Ui.UiServer 127.0.0.1 - - [2015-10-23 18:03:02] "GET /1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr HTTP/1.1" 200 2514 0.001000
[18:03:02] lib.geventwebsocket.handler Initializing WebSocket
[18:03:02] lib.geventwebsocket.handler Validating WebSocket request
[18:03:02] lib.geventwebsocket.handler Attempting to upgrade connection
[18:03:02] lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[18:03:02] Ui.UiServer 127.0.0.1 - - [2015-10-23 18:03:02] "GET /1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr/?wrapper_nonce=xxx HTTP/1.1" 200 2710 0.002000
```
 You can also try to add this to src/Ui/media/all.js before the `}).call(this);` line (it will close the websocket before navigating away):

``` javascript
window.onbeforeunload = function() {
    console.log("Closing WebSocket")
    window.wrapper.ws.ws.close()
}
```
 Looks like you requested the page at [18:16:13], but the first websocket request only reaches the server 1 second later [18:16:14], can also you check the log/debug.log please? (it has more accurate time format)

My timings looks like this:

```
[2015-10-23 18:28:25,618] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 18:28:25] "GET /Talk.ZeroNetwork.bit/?Home HTTP/1.1" 200 2489 0.008000
[2015-10-23 18:28:25,707] DEBUG    lib.geventwebsocket.handler Initializing WebSocket
[2015-10-23 18:28:25,727] DEBUG    lib.geventwebsocket.handler Validating WebSocket request
[2015-10-23 18:28:25,739] DEBUG    lib.geventwebsocket.handler Attempting to upgrade connection
[2015-10-23 18:28:25,740] DEBUG    lib.geventwebsocket.handler WebSocket request accepted, switching protocols
[2015-10-23 18:28:25,743] DEBUG    Ui.UiServer 127.0.0.1 - - [2015-10-23 18:28:25] "GET /Talk.ZeroNetwork.bit/?Home&wrapper_nonce=xxx HTTP/1.1" 200 6116 0.002000
```

So there is <100ms time window between the GET and the WebSocket init.
 Hm, i'm out of ideas. It needs deeper inspection whats happening on the the websocket channel using sniffer (eg. wireshark) or adding logging to src/lib/geventwebsocket. In chrome you can also check the websocket communication using the developer tool's (F12) network tab.

Is it also happening if you only have the ZeroHello site in your client? (to make sure it's not caused by the site with utf8 filenames)
 The log showin other sites, 1DWTx5..qTJd (has utf8 filenames), 16Basi..mTcs
 it's looks like your client still have that sites (maybe stucked in the client if you removed them). Please stop your zeronet client, rename "data" dir to "data-old" then start again to have a clean state and see if you still have the websocket problems.
 there is no built in method, you can add `print "WS IN", message` [here](https://github.com/HelloZeroNet/ZeroNet/blob/master/src/lib/geventwebsocket/websocket.py#L286) and `print "WS OUT", message` [here](https://github.com/HelloZeroNet/ZeroNet/blob/master/src/lib/geventwebsocket/websocket.py#L341)

Also try to check developer tools in chrome, it displays websocket frames
 It was tricky one, which antivirus software causes problem like this?
  I'm unable to reproduce the problem
 Thanks, I was able to reproduce, added a [different fix](https://github.com/HelloZeroNet/ZeroNet/commit/713baeab63b546dca6a69608a2e3613dd6e87118#diff-96bfdc2cfcb5739e88aad648cba5e983R120), as it conflicts with other pr
  It should work, but you need to add target="_top" or "_blank"
  You can start it using `python2 zeronet.py`
 The current (working) directory must be where you unpacked zeronet, so:
- `wget https://github.com/HelloZeroNet/ZeroNet/archive/master.tar.gz`
- `tar xvpfz master.tar.gz`
- `cd ZeroNet-master`
- `python2 zeronet.py`
  If this happens then every currently known computer network become unsafe.

Currently this is only "in theory" and not reality. The encryption will evolve when Bitcoin's current cryptography breaking computers become reality and we will follow change.
 The current bitcoin address format can be considered as quantum proof:

> "quantum computing is not very useful for breaking hashes like SHA-256. Just signature and encryption algorithms like ECDSA or RSA. To attack ECDSA, you need to know the public key. However, most addresses are made from the hash of the public key, which is not enough to start attacking ECDSA. You'd need to break the hash first, which won't be significantly easier with quantum computers.
> TL;DR any normal address that hasn't been spent from before is safe. So, if you use Bitcoin the way the developers recommend and don't reuse addresses, your coins are quantum safe, at least for now." 

https://www.reddit.com/r/Bitcoin/comments/3wfmg2/satoshis_unmoved_coins_are_the_worlds_biggest/cxw6osp
  Please be more specific
 What os/browser are you using?
  I think creating an empty site does not make much sense for the most of users. You can clone a site using then modify/delete the files if you really want to use the GUI.
  I think it would make the things more centralized, so it's better to have separate and independent data for every site.
  You can use the taskbar icon to shutdown: right click > exit
  The current logo was created in rush, some first ideas for new one:
![zeronet_logos](https://cloud.githubusercontent.com/assets/10350359/10103145/ac9cc8a6-63a2-11e5-9e2b-b35efec37a32.png)

Which one do you like? Other designs also welcome.
 In smaller sizes it can be simplified:
![zeronet_favicon_smooth](https://cloud.githubusercontent.com/assets/10350359/10117719/4162b6b8-6460-11e5-8e48-9466bf6dac73.png)
 new ones with 45Â° rotation:
![new_logos](https://cloud.githubusercontent.com/assets/10350359/10122827/2f433c48-6526-11e5-864c-d87597157a80.png)
 a more lightweight idea:
![logo2](https://cloud.githubusercontent.com/assets/10350359/10891948/1e7cd21a-81a1-11e5-8658-4cb62b8c7dfe.png)
  Its error: the response to the ping is "Pong"
  Thanks, but i think its reduces readability.
  Thanks, but i think its reduces readability.
  this is not a bug, but how zeronet works: you can't modify other user's data file 
  Thanks, but I think it's not improves the readability (syntax highlighting only works on cd command)
  I'm not a native speaker, so I googled for "currently served by", first page matches:
- Churches currently served by the EAMC Parish Nurse Program
- Line 52 will pass under the River Ij, currently served by GVB ferries.
- Water Supply to an Area of a City currently berved by a ...
- Schools currently served by the Chula Vista Nature Center ...
- Community currently served by long distribution lines
- majority of owners in an area not currently served by the waterwork
- Murcia is currently served by two airports 
- Which country is not currently served by peace corps
- The LDS Meeting House is currently served by City wastewater
- City Utilities invites neighborhood associations currently served by Aqua Indiana water service to include this column

So booth looks valid to me...
  thanks, fixed: https://github.com/HelloZeroNet/ZeroTalk/commit/935a4e0b3fcdae5dbf439bb0564b7128939a2b75
  You can change it using `zeronet.py --ui_port 1234 --ui_ip '1.2.3.4'`
  Sure, it has to be configurable if use 3G connection or not, but an update only a few KB, so I think it wont affect your data plan in most cases.

To avoid privacy problems it could be also per-site configurable if you want to share it to people around your or not.
  Thanks for reporting, added escaping in latest commit: 54c367cac83e04e906b453a6ff8fb36079370ca8
  Crazy or not, it would add a new level of security. :) Signing custom messages [looks easy](https://github.com/trezor/python-trezor/blob/master/tests/test_msg_signmessage.py) with trezor, so it should be possible.
  Periodically (or when new content.json received) delete files that not included in new content.json anymore.
- add new command to ZeroFrame API: fileDelete
 Added in Rev409: 917393c0227b1e87d9206b25dbb17941d7692fac
  Provide a way to define not automatically downloaded files in content.json. It will make possible to create larger sites with many image (and later videos).

To do this we can simply add `optional_files` node to content.json that is identical to current `files` node. This files only downloaded if user is request it directly (by a http request).

These files are excluded from site limit calculation (10MB by default). These files lands in a cache registry which has use-configurable size, and if the cache is runs out of the configured limit the most seeded file will be automatically removed.
## Problem 1: Initial distribution

In a Multi-user imageboard site if someone uploads a new image it will not downloaded by default anyone, so he/she has to wait until someone open the site and request it.

Possible solution: It would be possible to join to a site as "sponsor" who is downloads every optional files automatically and keeps it seeding until its necessary.
Also every user would be able to add "share friend" users. If your share friend uploads a file you automatically downloads his/her files and help to distribute it.

The API also adds possibility to "pin" (where it will not removed automatically from cache) and dislike (immediately remove) files.
## Problem 2: Who has it?

Currently every peer has every file, so if you want to download a file you can request it from anyone. With optional files this is going to change: To solve this every connected peer has to keep a `hashfield` table which holds the downloaded files hashes first 4 character (only first 4 for economy reasons) eg.:

```
peer1 = ['8a42', 'fa11']
peer2 = ['12ab', 'bbc9', 'd39a']
```

If you want to download an optional file you checks if it's hash's first 4 character is in any of connected peer's hash table. If its not then you ask your connected peers to check if any of their connected peers has it. If still not found you can try to connect other peers randomly.

If you finish downloading an optional file you send the connected peers to add it to your `hashfield`, so if anyone looking for it later they will know you has it. (Probably some kind a batching is recommended)
## Current status
- [x] Sign optional files
- [x] Download/verify optional files
- [x] User optional files rules (size and filename limit)
- [x] Peer hash table sync/find peer by optional file for more efficient optional file download (who has it?)
- [x] Super seed site (also download optional files)
- [x] More testcase
- [ ] ~~Modify ZeroTalk to allow file uploads~~ (did the ReactionGIFs site instead)

Later: Size limited optional cache, File pinning, User follow
 Maybe a "Superseed" startup option could work where you keep more open connections and publish the new modifications more than than default 5 peer. Also currently the client decides randomly which peer he start to download the content, it could be possible to keep track the last download speed and next time he will prefer the fastest peers in the network.

I think its very easy to abuse the "seed any new site in the network" method, but this could work:
Add a "Please seed my new site" topic in ZeroTalk and create a bot that automatically starts seeding the links that sent there. This way it would be possible to have some kind a control over the sites. 
Eg. If someone sends a malicious sites there and the moderator remove the link (or it receives many down vote/report) then the bot stops seeding it.
 Creating multiple sites (eg one per user) instead of increasing the hashtable length is more scalable solution.

Also a collision is not a big problem, it's just increase the network communication: the find peer by hash returning some peers that doesn't has the file you looking for.
 the files are hashed using sha512, which is not-colliding (yet)
 yes, breaking a hash method is only matter of (cpu) time
 The file hashes are currently stored in a content.json file, so it would be huge with million files. (122byte/file)
It's possible to split it up using includes, but it would be still problematic. Probably building a DHT network to access static files would be better solution, but it also has drawbacks: slower and does not works well on TCP (Tor)

The goal is to stop building huge, monolith sites. Decentralized sites should be also decentralized by ownership and not only by distribution protocol.
  Providing a centralized http proxy would go against the purpose of the network. (decentralized, uncensored)
 It's possible, you have to start it using `zeronet.py --ui_ip "*"`

More info: http://zeronet.readthedocs.org/en/latest/faq/#is-it-possible-to-install-zeronet-to-a-remote-machine
 it's possible if you redirect *.bit and zero domains to 127.0.0.1:43110
this extensions to this for your: https://chrome.google.com/webstore/detail/zeronet-protocol/cpkpdcdljfbnepgfejplkhdnopniieop/
you will able to access eg http://zeronetwork.bit directly
  Good idea, added notification button/input autofocus in latest update: 917393c0227b1e87d9206b25dbb17941d7692fac
Probably a multiple site selection will be required sooner or later to make it more comfortable.
  Try to use pip2 or pip2.7 since zeronet supports python 2.x and not yet 3.x
  To improve security every ZeroNet site runs in a sandboxed iframe. 
Looks like the browsers does not allow to load pdf to iframe. To load to the top frame you have to add `target="_top"` to your a html tag or `<base href="" target="_top"/>` to head to automatically convert every link on your site.
  Every site is served from a sandboxed iframe that is treat the content as being from a unique origin.

Also XSS is not possible in zeronet, since there is no server-side rendering, cookies or POST requests (everything is done using the websocket API).
 Thanks for pointing out, this is a true security flaw. Do you have any suggestion how to fix it?

My idea: Every time when the "wrapper" page called instead of adding "wrapper=False" to url it generates a one-time key and only serve pages with html content-type if a correct one-time key is present.
 There is an [semi-auto update mechanism](https://twitter.com/HelloZeroNet/status/568575098904555520) that download the latest version and restart node automatically if needed.

I addressed a [quick fix](/HelloZeroNet/ZeroNet/commit/eec0b22c1fe233c553e10a5faeee193cf9adb997) to popup attacks (its works on browsers I tested), I will try to implement the nonce based non-wrapper html rendering later this week.

There is a [chrome plugin](https://chrome.google.com/webstore/detail/zeronet-protocol/cpkpdcdljfbnepgfejplkhdnopniieop) that maps .bit domains, but it leaves other sites on same host (http://zero/[siteaddress]) since domain names are converted to lower-case by default and site addresses are case sensitive. I try to avoid custom browser if possible since it makes cross-platform and mobile compatibility much harder.
 The fix only do one thing: It prevents the attacker to get the wrapper_key variable that is inserted into the wrapper frame html source on request.

This key is unique per site, you can connect to the websocket API using this and it defines the permissions you get. Even if you can still spoof the referrer as you described without this key you can't really do anything, but access the static files of the site that holds no secret.

Escaping the sandbox still and issue and I will try to implement the nonce based security. This will still leave the same-domain issue unfixed, but I think that one is not possible to fix without custom browser / plugin.
 ~~Using sandboxed iframe does loads the content, but enabling the sandbox also denies the parent document to access the frame's content: `document.getElementById("sandboxediframe").document` returns undefined~~

~~The `window.stop();` command immediately stops the html parsing and load, so the html content is not overwritten by document.write but never gets loaded.~~

by adding `sandbox="allow-same-origin"` to iframe it does allows to load the wrapper's html and steal the wrapper_key :( 
 I have added nonce based wrapper rendering in the latest revision. 0de6496f96316514a07c4b1cbaf4a9f29a2411cb

It required [some magic](https://github.com/HelloZeroNet/ZeroNet/commit/0de6496f96316514a07c4b1cbaf4a9f29a2411cb#diff-faa3945ca6d392977a2c7d4e1acb865fR60) to make back/forward button work correctly, but it works in latest Chrome/FF/IE/Opera/Safari.
 Thanks for suggestion, So changing to this makes it cryptographer safe?

``` python
    wrapper_nonce = ''.join(
        random.choice(string.ascii_uppercase + string.ascii_lowercase + string.digits) for _ in range(24)
    )
    wrapper_nonce = hashlib.sha256(wrapper_nonce).hexdigest()
```

Or is it even better using [os.urandom](https://docs.python.org/2/library/os.html#os.urandom)?

``` python
wrapper_nonce = hashlib.sha256(os.urandom(256)).hexdigest()
```
 The HOST file could work for .bit domains, but then you have to bind your UI to port 80 (not free on many computers) and it would require administration permissions to modify it. (and non-.bit sites also would remain on the same host)

There is a [chrome extension](https://chrome.google.com/webstore/detail/zeronet-protocol/cpkpdcdljfbnepgfejplkhdnopniieop) that maps .bit domains to your zeronet client. Hopefully its  possible to create similar for FF/IE.
 It gives me: `XMLHttpRequest cannot load http://127.0.0.1:43110/zeroid.bit. No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'null' is therefore not allowed access.`
 It could be an improvement, but escaping from the sandbox would be still problematic, because for example the site would able to modify the site settings when the user has the sidebar opened.

So as long we can avoid the escape from the sandboxed iframe I think we are fine.
 allow-popups and allow-popups-to-escape-sandbox probably will be removed as it's not working well in every browser, but it does not modify the cross-domain policy:

```
w = window.open("/")
w.document
VM17392:1 Uncaught DOMException: Blocked a frame with origin "null" from accessing a cross-origin frame
```

The main idea of sandbox is it does not allows to access to parent document html or any data that is stored for that domain (cookie, localstorage, etc.)
 We can't do anything about it, you should report it for chrome devs, maybe they revert some changes and we can still support Chrome in the future.
 This has been fixed. As there is no known issue with sandboxed iframe yet.
 I would like to avoid modification of system settings / require admin user to run it and it would be also problematic for remote clients (eg. proxies) that only using one address.
  You have to remove it using software manager then install using `sudo pip -U msgpack-python`

If it fails this should work:
- Download msgpack from: https://github.com/msgpack/msgpack-python/archive/0.4.6.tar.gz
- Unpack anywhere
- Copy the `msgpack` directory from it to the same directory where your `zeronet.py` is
  Thanks!
  The client only send the changes to [some other peers](https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Site/Site.py#L314), then if someone receive a valid new modification he will inform about it 3 other random peers.

In this way you only have to send your modification to 1-2 peer then (probably) it will spread between everyone.
 ZeroBoard is an outdated site (it was the first site of zeronet). ZeroTalk solved this problem: 
Every user has his/her own file to distribute comments/topics/upvotes/etc. and they are signed and timestamped by the owner on modification. So no problem happens if someone did an another modification at the same time because its writes in an another file.
 Everone has his/her own content.json file that is timestamped separately, so no lock needed. 
  Thanks!
  IPFS does not support dynamic content as far as I know and the content distribution works differently. There is lots of similar project out there ZeroNet created to focus on simplicity, easy of usage and user experience.
 The startup speed zeronet has been fixed, please check the blog for instructions
  Yes the main reason was the fact that most linux distribution comes with Python 2 and it has more mature libraries. (and the speed is also somewhat better)

Some months ago the gevent event library ported to Python 3, so I think it shouldn't be hard to make the project compatible both with Python 2 and 3.
 I have not started working on it yet, so no ETA and I have not worked with py3 before, so not sure how hard or painful is the conversion.
I'm not sure if we want to use gevent in py3 as it has built-in async support now. (it would mean dropping py2 compatiblity) Python 2 still supported until 2020 so it's not a priority yet.  The problem is the torrent trackers only support ipv4 addresses, so need to find an alternative solution to store ipv6 (and tor) addresses.
 It's not on short-term plans yet. (next 6 month)
 Yes, with ZeroNet bootstrap protocol It's no longer a problem. I think the webui should work if you start it with `--ui_ip youripv6address`  The problem is Debian does not comes with pip installed and if you want to install it using pip you could need other dependencies installed (c++ comiler, python source code and other heading files). Debian 7+ has the correct msgpack version using apt-get so I would leave it as default install method.

For other distributions the pip method is recommended: https://github.com/HelloZeroNet/ZeroNet#other-linux-or-without-root-access
  It's added in the latest version: ec40d3fcc3c1b459d6137e00beee4066473e9d66
  Done in version 0.3.2
  I think its better to keep this setting in the config file.

Since the [latest update](https://github.com/HelloZeroNet/ZeroNet/commit/0de6496f96316514a07c4b1cbaf4a9f29a2411cb) you can specify the trackers by creating a `zeronet.conf` file eg.:

```
[global]
trackers =
    udp://sugoi.pomf.se:2710
    http://torrent.gresille.org/announce
```
 [Added an another parameter](https://github.com/HelloZeroNet/ZeroNet/commit/fa37f58982d3ea430605929aad961243dfceb600) using `zeronet.py --trackers_file bootstrap.txt` the trackers reloaded before the announces. Example for bootstrap.txt:

```
udp://sugoi.pomf.se:2710
http://torrent.gresille.org/announce
```
  Thanks for reporting, its fixed in latest version https://github.com/HelloZeroNet/ZeroNet/commit/dd2bb8b3fbd5d6eb6d950cdb48f2e3691a393e2d: 
Starting with `python zeronet.py --debug --coffeescript_compiler "/usr/local/bin/coffee -p"`, and autodetection of coffee command also added, so simply `python zeronet.py --debug` should work now
  Since every website on zeronet using the same origin (127.0.0.1) it would be unsecure to add "allow-same-origin" to sandbox parameters.

I have just tried it and successfully ran webworkers by inline them using Blob URLs: http://www.html5rocks.com/en/tutorials/workers/basics/#toc-inlineworkers
  Looks like your identity file (data/users.json) have changed. How did you updated your ZeroNet installation? Using update button on main screen or downloaded an unpacked again?
 You have to copy your old data/users.json file to the new installation to have your identity.
  I think creating a separate site for this is not necessary. A zerotalk topic is good for this ( later we can create a topic group for it if it requires).

even later, if we have more quality sites something like https://chrome.google.com/webstore/category/apps would be nice.
  Fixed: Only first two lines displayed
  Unfortunately there is no standard way to interact browser to check if a tab is already opened or not.
 https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Trayicon/TrayiconPlugin.py#L66

(you can try to change it to new=0, but it does not have any effect for me)
 I dont think calling chrome.exe directly is a good idea: someone could have different browser as default, it can be installed to different place, does not work on different platforms, etc.
  Can you please check the `log/debug.log` file for more details?

Also please try to start it with: `zeronet.py --disable_encryption --use_openssl False`
 ```
Socket error: NameError: global name 'SSLContext' is not defined in Connection.py line 124 > Connection.py line 180 > CryptConnection.py line 40 > ssl.py line 382 > ssl.py line 84
```

It's looks like for some reasons your openssl not compatible with python ssl (or gevent) module. 
Please paste the first 50 line of your debug.log, so i can try to reproduce your environment and try to find a fix for it. (you can remove the previous pastes from here to avoid ip leak)
 OK, thanks for reporting, im going to install an Ubunto to see why is it happening
One more thing I need is your openssl version: `openssl version` 

(file size does not match 8530 <> 8598, Hash: False errors happens probably because the site owner modified the index.html, but he/she does not signed the modifications yet, so your clients unable to download the file, so its not related to this error)

btw. probably you can start it with `zeronet.py --disable_encryption` the missing SSLContext is only related to SSL encrypted connections, so you can use openssl to verify the downloaded files. (40x speedup on initial download times)
 I think its fixed in rev280: https://github.com/HelloZeroNet/ZeroNet/commit/a5741704e4c4c5e679b3cfd6486d8f758087a51c?w=0, please let me know if its working for you
 @t1891 Are you having similar problems on osx? does starting it with `--disable_encryption --use_openssl False` fixes it?

whats your OSX / `openssl version` ?
  A bundle for macos would be nice, but unfortunately I don't have access to any mac yet. We have  [systray plugin for windows](https://twitter.com/HelloZeroNet/status/588467418982289408), but its currently using the the windows api, because I think adding qt as dependency and load it to memory (last time I checked it added +20MB which is doubles the current memory usage) for this little feature is a bit overkill.
Modify the [trayicon plugin](https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/Trayicon/TrayiconPlugin.py) to use the QT where the windows api is not available would be a good solution.

Adding peer information/sitesign/key management is [planned to be added to webui as a sidebar](https://github.com/HelloZeroNet/ZeroNet/issues/114), so it will be accessible if you are running zeronet on other machine.
  Thanks for reporting, we going to check the possibilities. Utf-8 domain names [not supported in Namecoin](http://wiki.namecoin.info/?title=Domain_Name_Specification_2.0#Valid_Domains), the domain-name encoding could be a workaround for this problem.

Python3 is not planned yet, because most of linux distribution still comes with python2 and the gevent liblary is not supported in Python3.
  Thanks, fixed in dc791a31abf660fbf05e49dd54661af9346d46c6, please run update.py then check again.
  We don't have dht yet, so its not possible. It's planned, but we looking for a solution that works with TOR and allows to store TOR client hidden services in a secure way.
  its very extreme, contains 100k+ files, i dont think its going to work anytime soon
 A feature is planned that allows to make sites that has access to other site's files, so it can generate a merged database from them.

This will allows to make huge sites without creating monoliths, keep the users content decentralized and also solves scalability problems.

For example a twitter-like page could be done like this:
- We going to have 2 pages: ZeroTwitterAccount and ZeroTwitterMerger
- If someone who wants "create" a new account he/she clones the ZeroTwitterAccount page which will holds all his posts and replies as a standalone site.
- If you want to follow anyone you just start serving his/her site
- When you visit ZeroTwitterMerger site requests read access to all ZeroTwitterAccount type sites you hosting and create a merged sql database from them. This will allow you to browse and search all your hosted (followed) ZeroTwitterAccount in one place.
  While the JavaScript has some advantage (eg. more people know it), but I think Python is more advanced language, so we don't have plans to switch to node.js. Although the alternative implementations are welcomed.
  Easier to install and test (don't have to deal with different versions installed) this way and i don't see any drawbacks of it. If a new version is out, we can easily test if its works, make the required changes then send it to all users.
 But what happens if tomorrow a new version of pybitcointools came out a feature we want to use? We can display an error to console saying "If you want to use ZeroNet you have to update your pybitcointools: On linux get a root console, execute pip --upgrade pybitcointools if it still dont work after that (some linux have python3's pip as default) try it with pip2 or pip2.7 or pip-2.7 commands. On windows download the new pybitcointools zip, find your python installation's site package dir and try overwrite files there if you can't then logout and login using an administrator user and try again.", but its sound painful for me.
 Calling pip from updater won't work in most environment because it requires administrator/root permissions to run. 
Thanks, the pex look interesting, but I don't see why is it better than the current, pure distribution format.
 As the project owner my top priority to provide the easiest way to use and update zeronet on every platform. This effort will be infringed If we require admin privileges or other actions to update the client.

As developer i want to care as less as possible. Supporting and testing different version of packages or distribution formats are painful for me.

I know i'm not the best programmer, the code needs improvements and I'm ready to give up my habits, but the easy user experience has to be above all.
  Thanks for reporting, I was unable to reproduce it, but probably fixed by 1f53212d62ae7202c6b8efdbe84e94b745663471
Please reopen the issue if you still have problems after updating.
 You have some options:
- Download the https://github.com/HelloZeroNet/ZeroNet/archive/master.zip file, unpack to current dir and overwrite current files (it safe to overwrite everything, it doest contains the data directory where your identity, settings and sites stored)
- Using file explorer in your Zeronet directory (where you have an update.py): File > Open Command prompt then enter `..\Python\python.exe update.py`
- Rename your ZeroNet directory and execute zeronet.cmd again. It downloads the latest version from github. Overwrite the data directory from your previous installation to have the same identity, sites and settings.
  It would be nice, but before that we need better tests. i'm not really experienced in that, but i try to do my best :)
 Thanks! We [started to make it](https://github.com/HelloZeroNet/ZeroNet/pull/119) PEP8 compatible, not every file converted yet.
Some of the test are broken yet because I only recently started to include the [files](https://github.com/HelloZeroNet/ZeroNet/tree/master/src/Test/testdata) that required for it.
Edit: Fixed broken tests: f63b711972fb818bb1695d386c1aaae9ef1beef7
  Thanks!
  Its because ZeroHello currently only checks if Zeroname plugin is enabled:
https://github.com/HelloZeroNet/ZeroHello/blob/master/js/ZeroHello.coffee#L99
I'm going to update it soon.
edit: updated
  I think we should not move the not-on-top module imports, to allow only load the modules if they are really needed (eg gc module) and it could matter if the module loaded before or after monkey patching (for example in case of proxy).
 Unfortunately importing some libs before socket monkey patching broken proxy (TOR) support (caused hang-up on startup), so i reverted the necessary imports to previous state: f58aa5f78e6f223d55d27560a4c034c247ca3ae4
  Thanks!
  https://www.python.org/dev/peps/pep-0008/

Probably required modifications:
- [Use spaces instead of tabs.](https://www.python.org/dev/peps/pep-0008/#tabs-or-spaces)
- [Imports to separate lines](https://www.python.org/dev/peps/pep-0008/#blank-lines)
- [Change module names to lower_cased](https://www.python.org/dev/peps/pep-0008/#prescriptive-naming-conventions)
- Other things?

Possible problems:
- The [update script](https://github.com/HelloZeroNet/ZeroNet/blob/master/update.py) does not handle  the renames/file removes. Some os does not allow to have the same file with upper cased and lower cased form in the same directory, so the update will fail. So we need to modify the update script and wait some time until everyone update it.
- I'm a TAB person, going to need some time to get used to spaces :)
 Yeah, the editor makes its easier, but for me it was easier to jump between indents with one cursor button press and delete an indent with one backspace.

The editor should detect if the current file using space or tabs, but for some unknown reasons this feature does not works in my sublime text. (`"detect_indentation": true`)

So i written a quick plugin for it, maybe its also useful for someone else: [detect_indent.py](https://gist.github.com/HelloZeroNet/e6343d9ee8e9968ac54e)
 Done in: https://github.com/HelloZeroNet/ZeroNet/commit/b5ecb62bc6e81ebb5e23855bb2195a9c9f802f7e?w=0

Tools used:
- [Python PEP8 Autoformat](https://packagecontrol.io/packages/Python%20PEP8%20Autoformat)
  Settings:

```
{
    // autoformat code on save ?
    "autoformat_on_save": false,

    // enable possibly unsafe changes (E226, E24, W6)
    // aggressive level, 0 to disable:
    "aggressive": 0,

    // list codes for fixes; used by --ignore and --select
    "list-fixes": false,

    // do not fix these errors / warnings (e.g. [ "E501" , "E4" , "W"])
    "ignore": [],

    // select errors / warnings (e.g. ["E4", "W"])
    "select": [],

    // Maximum line length
    "max-line-length": 300  // I wanted to format long-lines myself
}
```
- [Python Flake8 Lint](https://packagecontrol.io/packages/Python%20Flake8%20Lint)
  Settings:

```
{
    "lint_on_save": false,
    "pep8_max_line_length": 130,
    "report_on_success": true,
    "ignore": ["N802"]  // We use camel cased function names
}
```
  Thanks! Fixed: b2e2453e581814876468a0ec8d65b07a307646bc
  You can do this, but its not recommended, because then you have to trust the other site to not include any malicious code in the javascript.
I think the actual benefit (saving 2-300kb of space) is not worth it.
  Thanks!
  - [x] Workaround to fix gevent SSL bug on python 2.7.9
- [x] Benchmark SSL vs RAW connection speed
  It's around 6 times slower than raw connection when running client and server on the same machine.
  
  ```
  10 worker:
  # Raw:      10000 req 1000009 kbytes transfered in 5.39999985695
  # RSA 2048: 10000 req 1000009 kbytes transfered in 27.7890000343 using ('ECDHE-RSA-AES256-SHA', 'TLSv1/SSLv3', 256)
  # ECC:      10000 req 1000009 kbytes transfered in 26.1959998608 using ('ECDHE-ECDSA-AES256-SHA', 'TLSv1/SSLv3', 256)
  # ECC:      10000 req 1000009 kbytes transfered in 28.2410001755 using ('ECDHE-ECDSA-AES256-GCM-SHA384', 'TLSv1/SSLv3', 256)
  
  100 worker:
  # Raw:      10000 req 1000009 kbytes transfered in 7.02700018883 Mem: 14.328125
  # RSA 2048: 10000 req 1000009 kbytes transfered in 44.8860001564 using ('ECDHE-RSA-AES256-GCM-SHA384', 'TLSv1/SSLv3', 256) Mem: 20.078125
  # ECC:      10000 req 1000009 kbytes transfered in 37.9430000782 using ('ECDHE-ECDSA-AES256-GCM-SHA384', 'TLSv1/SSLv3', 256) Mem: 20.0234375
  ```
- [x] Generate SSL cert&key PEM unique files on every startup
  I have tried to find a pure-python solution for this, but not found any, so using openssl command for it (openssl.exe bundled for windows).
  
  The key pem file creation is possible using [python-ecdsa](https://github.com/warner/python-ecdsa), but I could not found solution for the cert file:
  
  ``` python
  from ecdsa import SigningKey, VerifyingKey, NIST384p
  sk = SigningKey.generate(curve=NIST384p)
  print sk.to_pem()
  vk = sk.get_verifying_key()
  vk_pem = vk.to_pem()
  print vk_pem
  ```
- [x] More lightweight solution to encryption to avoid compatibility problems (eg. we dont need HMAC because every client is trustless)
- [x] Transparently update the connection to ssl using wrapssl
  To make raw & encrypted connections work on same port:
  - Client connects to peer
  - Client checks if the other client supports ssl connection
  - If both fine then sends ssl handshake and update the connection transparently
  
  Later it can be changed to implicit SSL (automatically encrypt every connection) if this works on every machine.
 Unfortunately for some unknown reasons its does works well on some computer (slow, high memory usage, error on newer ciplers), maybe its OS, OpenSSL or Python version bounded. 
I try to find alternative more lightweight solution to encryption...
 found a hack that helps openssl memory problems: https://journal.paul.querna.org/articles/2011/04/05/openssl-memory-use/

Update:

```
SSL No patch: 1000 req 100000 kbytes transfered in 13.8398740292 using ('AES128-SHA256', 'TLSv1/SSLv3', 128) Mem: 64.66796875
SSL Patched:  1000 req 100000 kbytes transfered in 6.95544099808 using ('AES128-SHA256', 'TLSv1/SSLv3', 128) Mem: 18.6796875
Custom AES:   1000 req 100000 kbytes transfered in 5.92737412453 Mem: 11.90625
```
 Its up and working, I leave it some days of testing, after that I will publish it.
It takes more time to build up a connection, but after that there is no mayor overhead.

```
Reponse time from far server
with SSL:    1.036, 0.133, 0.133, 0.133
without SSL: 0.407, 0.133, 0.133, 0.133

Reponse time from close server
with SSL:    0.444, 0.019, 0.020, 0.019
without SSL: 0.067, 0.020, 0.019, 0.021
```
 Added in a78907cc9dc198dd28dce2204a8992cf9e00221f
 The ssl support is for peer connections not for user interface (yet)
  Thanks, never used docker before, I try to add it to dockerhub.
  Its already possible, but undocumented yet, example zeronet.conf:

```
[global]
ui_ip = *
ui_restrict = 1.1.1.1
proxy = 127.0.0.1:9050
```
 Added to rev196
https://github.com/HelloZeroNet/ZeroNet/blob/66eca389bfc87049c1e20a26a5c0c2b8b876975e/src/Config.py#L106-L108
  Its planned, until then symlink directories should work
 Added to rev196
https://github.com/HelloZeroNet/ZeroNet/blob/66eca389bfc87049c1e20a26a5c0c2b8b876975e/src/Config.py#L106-L108
  Thanks
  Yeah its a good idea for a plugin, I already made some experiment earlier when i wanted to implement .bit support using http://www.opennicproject.org/
Need more experimenting, not sure if its possible using http://pydns.sourceforge.net/ & Tor network
 The problem is it relies on dns servers, so the sites will not works offline. Cache required to make it work without internet connection [example at dnschain plugin](https://github.com/HelloZeroNet/ZeroNet/blob/master/plugins/disabled-Dnschain/SiteManagerPlugin.py#L91-L119).
I don't really want to add more external dependencies, but pydns is a pure-python module, so distributing in the lib dir could work.
  thanks
  merged
   Added in https://github.com/HelloZeroNet/ZeroNet/commit/9d511ba1655d8b2982b3d9810ba3901d0a5d1c09  To reduce space/network bw used by data files:
- On network protocol level: less work, but does not reduces the storage requirements
- On file storage level
 The main problem is not storing the js/html files, but the databases. Removing white space from json files could help, but support for compressed database would be better solution.
 Unfortunately - as far as i know - sqlite does not have compressed database support and probably it would be slow to select large files from database every time the user requests it.

Currently the every database data is stored two times: as json file and as sqlite database cache. In theory its possible to store the data only in the database, but then then modify/sign/send/validate would use much more cpu and disk i/o because to calculate the md5 hash of the data file you have to select all current data from database, but i have not made any benchmark for it yet.

As space usage of current ZeroTalk files (208user, 130topics, 600comments, 550upvotes):
- Json files: 355k, zipped: 268k, tgz: 145k
- Sqlite db: 408k, zipped: 187k, tgz: 187k

The sqlite db is larger than json files probably because of the indexes.
 Sadly its not free: "You should only be able to see this software if you have a license. If you do not have a valid license you should delete the source code in this folder at once."
 I have did some experiment on compression speed on a content.json file with 12 000 files:

```
Original        1874.51KB
Zlib    0.074s  558.68KB
Gzip    0.130s  547.09KB
Deflate 0.125s  547.04KB
Bz2     0.291s  482.88KB
Bro     7.856s  438.01KB
Decompress
Zlib    0.010s
Gzip    0.011s
Deflate 0.009s
Bz2     0.089s
Bro     0.012s
```

Google's new [Brotli](https://github.com/google/brotli/) offers nice rate, but the compression time price is huge.
Looks like the gzip offers the best speed/compression ratio. (maybe support both .gz / .bz2?)

The idea:
- The any.json.gz files would handled and transfered as normal files.
- If the json -> data layer matches a .gz file then it transparently decompress then insert a data from it.
- It would also handle the compression/decompression transparently if you read/write a json.gz file using the ZeroFrame API.

The html, css, js,etc. files would remain uncompressed (also on storage and transfer), because they only have to re-transfer very rarely and i think its not worth the extra (de)compression cpu time on every transfer.

Edit: Added LZMA/Brotli compression levels:

```
Original Compress 1874.51KB Decompress
Zlib     0.069s   558.68KB  0.011s
Gzip     0.132s   547.09KB  0.011s
Deflate  0.131s   547.04KB  0.009s
Bz2      0.299s   482.88KB  0.098s
Lzma     1.372s   455.77KB  0.057s
Bro/1    0.035s   506.78KB  0.011s
Bro/2    0.046s   504.26KB  0.010s
Bro/3    0.052s   502.25KB  0.011s
Bro/4    0.059s   507.89KB  0.010s
Bro/5    0.160s   527.18KB  0.012s
Bro/6    0.221s   527.73KB  0.012s
Bro/7    0.269s   527.06KB  0.012s
Bro/8    0.305s   526.27KB  0.012s
Bro/9    0.373s   525.81KB  0.012s
Bro/10   8.111s   438.01KB  0.012s
Bro/11   8.075s   438.01KB  0.012s
```

Brotli / level1 looks good and fast (Cons: One more binary dependency and the python module not submitted to pip yet)
 It's not planned yet.
 Added facebook's zstd:

```
Original    Compress    1874.51KB   Decompress
Zlib        0.071s      558.68KB    0.010s
Gzip        0.131s      547.09KB    0.012s
Deflate     0.129s      547.04KB    0.010s
Bz2         0.299s      482.88KB    0.108s
Lzma        1.343s      455.77KB    0.058s
Bro/1       0.031s      506.78KB    0.011s
Bro/2       0.042s      504.26KB    0.010s
Bro/3       0.049s      502.25KB    0.011s
Bro/4       0.058s      507.89KB    0.011s
Bro/5       0.159s      527.18KB    0.012s
Bro/6       0.236s      527.73KB    0.012s
Bro/7       0.298s      527.06KB    0.012s
Bro/8       0.324s      526.27KB    0.012s
Bro/9       0.401s      525.81KB    0.012s
Bro/10      8.307s      438.01KB    0.013s
Bro/11      8.755s      438.01KB    0.013s
Zstd/1      0.017s      502.58KB    0.010s
Zstd/3      0.058s      521.81KB    0.024s
Zstd/5      0.152s      523.55KB    0.038s
Zstd/7      0.276s      518.76KB    0.050s
Zstd/9      0.470s      507.92KB    0.063s
Zstd/11     0.695s      507.03KB    0.076s
Zstd/13     0.957s      505.98KB    0.089s
Zstd/15     1.352s      504.79KB    0.101s
Zstd/17     1.838s      478.77KB    0.111s
Zstd/19     2.939s      465.31KB    0.121s
Zstd/21     4.155s      458.96KB    0.132s
```

Zstd's train function can be interesting for us (it allows to have shared dictionary between multiple compressed files)
 There is no roadmap, so can't tell if it's on it or not. It's planned, but not sure yet if it will also support database files or only for static ones. I have added .tar.gz, .tar.bz2, .zip support in latest rev: https://github.com/HelloZeroNet/ZeroNet/commit/2854e202e17926f136c053646f3530e1e1c9956d

example site: http://127.0.0.1:43110/1AsRLpuRxr3pb9p3TKoMXPSWHzh6i7fMGi/en.tar.bz2/index.html (please update your client before visit)

en dir uncompressed: 6.1MB, zipped: 1.5MB, tar.gz: 512KB, bz2: 247KB (!)

No database files support yet, but it's also planned. Latest results from gzipped database (ZeroTalk user files):
- Raw, separate files: 7.6MB
- tar: 12MB (hm)
- zip: 4.8MB
- tar.gz: 3.1MB
- tar.bz2: 2.4MB
- tar.zstandard: 2.1MB
- tar.brotli: 2.0MB
- tar.xz: 1.9MB

Reading all files from archive
```
|         | Intel i5 | Chip  |
|---------|----------|-------|
| Raw     | 0.51s    | 1.74s |
| Tar.gz  | 0.47     | 6.99s |
| Tar.bz2 | 4.5      | 82.3s |
| Zip     | 0.38     | 4.03s |
```

Update: By dropping the signatures from archived content.json files reduces the size of the tar.gz file down to 2.5MB Plans for tar.gz packed database:
#### It should be suitable for archiving user database files: 
 - The site owner press the archive button
 - ZeroNet packs user files older than 1 month into users.2017-03-02.archive.tar.gz
 - Specifies the clients to delete all user files older, than 2017-02-02
 - Publishes data/users/2017-03-02.zeronet-archive.tar.gz file (as optional file)

#### Client detects new *archive.tar.gz file
 - Read all .json files in the tar.gz and insert to db as normal files


#### Problem 1
If an archived user starts posting again, then archived content will disappear, because ZeroNet deletes all user before inserting new one. (Same problem if multiple archive contains data for same user)
 - Solution 1: Delete all data associated to user -> Check all archive if it has data for the user and import it if necessary ->Import new user data file. Pro: Probably need no modification in sites source code, Con: Opening archives is slow and we have to do it for every file
 - Solution 2: Treat archived jsons as separate files. Pro: Archived data rows will be untouched if user start posting again. Cons: Probably needs modification in every site code. And re-index the db.

#### Problem 2
Optional files in archived user directories will be deleted.

#### Problem 3
If you archive a user file with an active topic, then it will disappear.

#### Problem 4
On archiving we have to update every user's data.json which could take a lots of time. zip also supported, but in this case it does not makes any difference, because when the zip/tar.gz files got updated we have to unpack every file to insert to db. Another idea:
Instead of storing many files in .zip / tar.gz merge the archived ones into one.  For example:
```
{
"users/112GGMvUJbBTCtQu8UUSYpo8UjLdo1B73n/content.json": {
   "cert_auth_type": "web",
   "cert_user_id": "qu363c@zeroid.bit",
   "modified": 1484261339
},
"users/112GGMvUJbBTCtQu8UUSYpo8UjLdo1B73n/data.json": {
...
}
```

This will speed up the opening, reading and parsing.  My first benchmarks parsing all json files this way (I have removed the signatures from content.json files to reduce size):

|                   | Size    | Intel i5 | Chip    |
|-------------------|---------|----------|---------|
| Raw               | 6.7MB   | 0.48s    | 3.37s   |
| Merged Raw        | 6.7MB   | 0.10s    | 1.46s   |
| Tar.gz            | 2.6MB   | 0.58s    | 8.64s   |
| Merged Tar.gz     | 2.4MB   | 0.20s    | 2.49s   |
| Tar.bz2           | 1.9MB   | 4.38s    | 77.3s   |
| Merged Tar.bz2    | 1.8MB   | 0.58s    |  7.2s   |
| Zip               | 4.1MB   | 0.48s    | 5.60s   |
| Merged Zip        | 2.4MB   | 0.13s    | 1.84s   |
| Merged bro        | 1.3MB   | ~tar.gz  | ~tar.gz |

So it significantly reduces the size of the .zip file 4.1MB -> 2.4MB and also speeds up the parsing process by 2-10 times. Without this the sites will be larger and larger by years dramatically increasing the initial sync time and the space required by the site. 
This will allow the site owner to create checkpoints by merging all user created content into one file and define it as optional file, so if someone not interested in old content, then he/she only has to store and distribute the latest files. 
 The current solution for large sites are deleting. The archiving will make these content still accessible, so from user perspective it's much better and I don't see why would make it anyone leave the network. 

Keeping every data on every computer will not work. (think about mobile phones)

Compressing the data makes it 2-4 times smaller, so I would not call it as a long term solution.
Other problems with sites without archiving:
 - Eg. on Android the default block size is 32kb, so if you store a 100byte file it will still takes up 32kb. For that reason currently if you download ZeroTalk to your mobile it will take up almost 100MB of space. (instad of 8MB)
 - Initial sync: Downloading, parsing, checking signature of 10000 files takes 10000 more time, than the same data from 1 file. You can call it optimize if you want. It's really up for the site owner which data he/she decides to remove from the default downloaded ones. It can be based on date/language/votes/etc.
Downloading and verifying ZeroTalk content (4700 files in 8MB, and I already deleted 2500 files to keep it under 10MB) could already take up to 10 minutes on mobile phones, which is I think already too much. 

This time could be improved with protocol modifications (eg. pipelining), but the verification and wiriting to the storage is still going to be problematic. (around 50ms/user) I think downloading optional files are not an advanced feature at all. It can be a button of "Download earlier topics", "Download downvoted comments" or "Download unanswered questions" There is some overlap with merger sites, but this is more like a solution for storage and transfer of large ammount of data. With .zip/tar.gz support it partially implemented, the next step is #1053  No, but #1053 will add this feature as checkpoints are basically compressed databases
 It's up to the site if it's puts up-to-date or outdated data in it, but I will check the possibilities of adding a simple json.gz support. @antilibrary json.gz support added in Rev2180: https://github.com/HelloZeroNet/ZeroNet/commit/b503d59c49da148346aa9893d7287b8e9ccb46d2
Also a new API command (fileNeed) that allow you to start downloading optional files.
Example site that shows both of the new features: http://127.0.0.1:43110/1JokLn39tLeXbc7voPv5yuiZvzUnduKpL9
   Can you run this commands please?

``` bash
$ python -V
Python 2.7.3
$ python -c "import gevent; print gevent.__version__"
1.0.1
```
 Maybe its version incompatibles, you can try to fix it using any of it: 
- Remove the gevent package and install it again using pip 
- Install using pip's `--user` parameter (no root needed, it installing it to user's home dir)
- Use `apt-get python-gevent`
  Thanks!
  I throught "ssl=False" fixes this problem, but looks like not :(

Just installed Debian Jessie and this fixes the problem (installing from package instead of source):

```
pip uninstall gevent
apt-get install python-gevent
```
  Hm, i think the problem is with the openssl.
Can you please add the `raise Exception("OpenSSL disabled")` line in the try block of `src/Crypt/CryptBitcoin.py` file?

It should looks like this:

``` python
from lib.BitcoinECC import BitcoinECC
from lib.pybitcointools import bitcoin as btctools
import logging
# Try to load openssl
try:
    raise Exception("OpenSSL disabled")
    from lib.opensslVerify import opensslVerify
    logging.info("OpenSSL loaded, version: %s" % opensslVerify.openssl_version)
except Exception, err:
    logging.info("OpenSSL load failed: %s, falling back to slow bitcoin verify" % err)
    opensslVerify = None
```

There is an alternative pure-python fallback on if library fails, but it can't catch the segfault :(

If this works then I will add an option to disable the use of openssl (and probably disable by default on macos until not found any solution to the problem)
 Only info I found:
https://github.com/petertodd/python-bitcoinlib/issues/30
https://github.com/jgarzik/python-bitcoinlib/issues/18

You can [try to upgrade openssl](http://apple.stackexchange.com/questions/126830/how-to-upgrade-openssl-in-os-x), if you do please give feedback if its fixed the problem!
 There is an [experimental patch](https://github.com/petertodd/python-bitcoinlib/issues/30#issuecomment-98419595) for bitcoinlib that uses cffi instead of the bulit-in ctypes. I will keep my eye [on it](https://github.com/petertodd/python-bitcoinlib/pull/62).
 I have found an alternative implementation: https://gist.githubusercontent.com/HelloZeroNet/4a335070d315f2456962/raw/b3a306f93a4e67064fa64ccddca591c8fe28b8f3/opensslVerify2.py
Can you please download it then try to run `python opensslVerify2.py` ?

Edit: Found an another one, please also try this: https://gist.githubusercontent.com/HelloZeroNet/747ffc1366bfdd47d657/raw/12b33126db874b6d8a5ec9e67d5df07e2053fc24/opensslVerify3.py
It says "doesn't crash on OSX." in the comments, so i'm very optimistic! :)
 @aidanharris Thanks for the reply, I have removed the missing symbol reference, please try this one: https://gist.githubusercontent.com/HelloZeroNet/747ffc1366bfdd47d657/raw/a014e42f79afea4332feead0f5aaa18ec6dd18a9/opensslVerify3.py
 Thanks, I will include this solution in the next version.
 Implemented in 0.3.0 please update then test it using: http://127.0.0.1:43110/Benchmark
 yes looks good, thanks!
  Would be handy to allow access ZeroNet from anywhere (eg. mobile) using a box that running the client.
Cookie or Http auth based (logout?).
 Yes, now it has ip based restriction: `--ui_restrict 123.456.678.982`, but it not works when you are in ip changing environment (eg. mobile)
 Currently working on this, probably it will be cookie based, i try to find a solution to make it more secure (does not send password as cleartext) on non-https connection. (similar to this: http://www.lightcubesolutions.com/blog/?p=47)
 Unfortunately sandboxed iframe ajax requests does not send the cookies, so the sites that using ajax to load data will not work.

As result i will mark ajax as unsupported method of loading data, instead use zeroframe api [fileGet](http://zeronet.readthedocs.org/en/latest/site_development/zeroframe_api_reference/#fileget-inner_path) method which is the same and probably faster.
 added in: https://github.com/HelloZeroNet/ZeroNet/commit/a93ca2c3b4e1d2fa95ad96fb04804e397c4dcb88

To enable password for webui:
- It's useful if you want to access your ZeroNet installation from remote machine (eg. mobile phone)
- Rename **plugins/disabled-UiPassword** to **plugins/UiPassword**
- Start using `zeronet.py --ui_ip "*" --ui_password mypassword` to bind ZeroNet to your public interface and allow access only using _mypassword_
  If you want to just validate it then its probably better to do on client-side. Eg. you can use this library: http://bitcore.io/playground/#/address

``` javascript
var privateKey = new bitcore.PrivateKey('5HvfMemepddMZmTjXQgyFLbyV5q2aXAmnpcX4zn6YNNw3kC3aUS');
var publicKey = privateKey.publicKey;
var address = publicKey.toAddress();
if (address == "1DoKaHoYHiTN9quUAAcx7Z5kNmN5xbo62n") console.log("Valid!")
```
  Yeah, the document definitely needs more work. I have made some modifications in fileWrite recently, its possible as side-effect the file already has to be in content.json before its allows writing (so needs to be created and `zeronet.py siteSign youraddress` executed). I'm going to test it later today. 
Do you have any error in `log/debug.log` file?
 I have tried it and its works for me even for non-exitstent files, updated the sample application with file read/write example:
https://github.com/HelloZeroNet/Documentation/blob/master/example/ZeroFrame/index.html

Update: I was able to reproducate the problem, it happens when you dont have the "own": "true" at your site in data/sites.json. But the websocket dropping is not normal, already working on fixing it.

Update #2: Its got fixed in commit f576527986692e82a2fd154b821685c07900c5d9
  Currently to make an user able to publish his own content, he/she has to contact the site owner to put his/her auth_address to the [users/data/content.json](http://zeronet.readthedocs.org/en/latest/site_development/content_json/#includes) file.

This required to has some kind of control over the users. (eg. be able to ban spamming users)

This makes the multi-user sites much harder because the user has to able reach the site owner and zeronet does provide any messaging service (yet), so it has to be done using other protocol (http, bitmessage, etc.).

To make it easier the site owner could able to provide trusted site addresses who is processes the new user requests. 
So the site owner could say: Any user who registered at Talk.Zeronetwork.bit is able to post on myblog.bit.

To make it possible we have 2 options:
#### Auth from other site's content.json

Every user who is seeding myblog.bit also has to seed the talk.zeronetwork.bit site. If a new user content comes in the peer checks if the auth_address is in talk.zeronetwork.bit user database.

Pros:
- The auth site able to delete users if reported as spammer

Cons:
- Users has to seed the authorization site
#### Validate other site's certificate

If a user registered successfuly at talk.zeronetwork.bit the site owner would sign the user's auth_address like a proof of a registration. If the user wants to post on myblog.bit he adds the cert to his content.json, and the peers will accept his/her new content. 
Pros: 
- Does not requres peers to seed the auth site
- Works even if the auth site deleted

Cons:
- No way to revoke cert

To make any of it possible the user has to use the same auth_address for talk.zeronetwork.bit and myblog.bit. (unique auth_address generated for currently every user using the same BIP32 xprv, but its easily possible to copy the identity)
## _Update:_

I think i will go for the second solution.

Required modifications:
- [x] File for specify rules where the third-party signed can be stored Contains: trusted authorization services, allowed files/size limit using regexp, directory where it will be stored, banned users.
- [x] Modifications on web interface that allows to use the same auth_address on multiple sites
- [x] A sample trusted authorization service page
- [x] Protocol command to get all current commented users data file (changedSince)
 example cert address: `16YsjZK9nweXyy3vNQQPKT8tfjCNjEX9JM:web/nofish@id.zeronetwork.bit`
- 16YsjZK9nweXyy3vNQQPKT8tfjCNjEX9JM: user's auth address
- web/: auth type used for registration (namecoin/, bm/, email/ etc.), this allows site users to ban some registration types or give them more trust (more space)
- nofish: username, has to be unique per site
- id.zeronetwork.bit: the auth provider address

On successful registration the site owner signs this string and sends the sign to the user.

The user saves it and if he want to post on a site he adds the signature to his content.json in `auth_cert_sign` field and the cert address to `auth_cert_address`

example for users.json

``` json
{
    "data/users": {
        "cert_signers": {
            "id.zeronetwork.bit": ["1IDzero2NXVi1RDPDgf5617UoW7xA6YrhM9F"]
        },
        "users": {
            "web/nofish@id.zeronetwork.bit": { "max_size": 40000 },
            "web/bad@id.zeronetwork.bit": null
        },
        "rules": {
            "id/.*@id.zeronetwork.bit": { "max_size": 40000 },
            ".*": { "max_size": 20000, "files_allowed": "data.json" },
        }
    }
}
```
 Added in 7e4f6bd38ecadb871a537c27a70a161d0a36816e
  Thanks for reporting, it got fixed in latest commit (rev106):
https://github.com/HelloZeroNet/ZeroNet/commit/c8fe73f5c0c3916c3244e446c7fbf03109567834#diff-67726306a3ab3bef30655f8f7f7465baR26
  `ImportError: No module named gevent` means you need to install gevent first.

you can do it using `pip install gevent msgpack-python` (if no pip command found try to find it in your package manager or download & run https://bootstrap.pypa.io/get-pip.py)
 If your router doesn't support upnp then you have forward the port 15441 to your raspberry IP address. But its also works fine if you cant do that.

If you want to access the the web interface from other ip address then you have to start it with `zeronet.py --ui_ip *` after that you can access it using http://raspberryip:15441
 [Upnp](http://en.wikipedia.org/wiki/Universal_Plug_and_Play) allows to communicate to your router and automatically forwards required the port to your computer.
  If a new and safe to update version out it will displayed on homepage like this:
https://camo.githubusercontent.com/8eca76beec11d1b903ea233cee169b2c84ff1330/687474703a2f2f7a65726f6e65742e72656164746865646f63732e6f72672f656e2f6c61746573742f696d672f7a65726f68656c6c6f2e706e67

There is new features/fixes between version changes, but its recommended to wait for new version, because this changes are not tested that deeply.
But if you really want to update zeronet every time you start you have to insert it to the first line of zeronet.cmd:
`Python\python.exe -m zerobundle.run https://github.com/HelloZeroNet/ZeroNet update.py`
  Possibilities:
- Browser plugin with custom zero:// protocol handler. Access sites: zero://talk.zeronetwork.bit zero://1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr
- Browser plugin, but keep http://. Access sites: http://1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr(.zero?), http://talk.zeronetwork.bit. Can be problematic if .bit site also has zeronet and clearnet address
- Using system's host file maps all site address to 127.0.0.0, this allows to access zeronet sites in any browser using http://talk.zeronetwork.bit (needs to map zeronet webui to port 80). Access new sites can be problematic.
- Register a domain and map all subdomain to 127.0.0.1 (needs to map zeronet webui to port 80). Access sites using http://talk.zeronetwork.bit.gozero.net
- Extend zeronet to also act as dns server and configure your os to 127.0.0.1 dns. Access sites like http://talk.zeronetwork.bit

Something you can do now: add `127.0.0.1 zero` to your host file, start zeronet with `zeronet.py --ui_port 80` then you can access zeronet sites http://zero/talk.zeronetwork.bit

Probably the browser plugin is the best solution (if possible)
 .bit chrome extension using this: https://developer.chrome.com/extensions/proxy

if zero:// not possible then i think accessing sites http://1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr or http://1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr.zero also fine.
 .bit domains can be problematic that way: a domain could have clearnet ip address and also zeronet address representation.
So currently if you enter zeronetwork.bit with the .bit chrome extension installed it leads you to the github page, but in zeronet it should lead to 1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr.
Maybe it can be solved by prefer zeronet  or prefer clearnet option.
 Wow nice!
I think 1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr.zero is better because its looks more like a normal web address and if you enter zero/1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr in chrome (without http://) it takes you to google search. 1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr.zero handled as normal url
 I think if you can change it to *.zero then it will be good. currently zero/ is detected as part of request_path, if it has a . in it then it will be the domain.
 In my browser: http://i.imgur.com/Yl0ETg4.png (i have installed the extension)

yeah the lower-casing is a major problem and i think no easy way (if even possible) to fix it :(

maybe its possible with combination with omni-box plugins witch is receives all input you enter to address bar, but its hack-ish.

According to this: https://github.com/swalkinshaw/rs-ssh google lets you use custom protocol prefix, but you need a registered program for that (we can do that easily with zeronet client).

This protocols have to be case-sensitive because there is also a bitcoin:// protcol.

So it looks harder than I first throught...
 It required some changes in the core request handling, but i got the chrome plugin working. There is still some problems with site links that needs more work.

I think its better to stick with .bit domains instead of .zero, later it allows us to support other dns providers. (.eth, .p2p, etc.)
 Downloaded and updated to latest version of the plugin, everything working fine (/zero/\* and direct .bit access), i'm going to do some more testing then i will release a version that compatible with it.
 probably it would be smart to change the .bit to something zeronet related to prevent mixing with real namecoin .bit mappings, ideas that came up:
- Change .bit to .zero. Example: http://talk.zeronetwork.zero Problem: It doesnt allows integrating other dns providers (like ethereum) and there is already an [application](https://gtldresult.icann.org/application-result/applicationstatus/applicationdetails/934) for .zero tld
- Change it to .0 or 0net. Example: http://talk.zeronetwork.0net Problem: Its hard to read (is that an O or 0?), Similar as .zero, but without icann tld problem
- Change it to .zeronet. Example: http://talk.zeronetwork.zeronet. Problem: Similar as .zero, but without icann tld problem
- Change it to .zerobit. Example: http://talk.zeronetwork.zerobit. It allows later add .zeroeth .zerobazaar or .zerop2p
- zero:// protocol handler. Example: zero://talk.zeronetwork.bit. Problem: Chrome doesnt allows easily to do that, need registry hacking. Most forums doesn't converts it to clickable urls.
- Keep .bit, but redirect non-existent domains back to chrome (not sure if its possible)
 Redirecting on 127.0.0.1:43110 request to /zero/[site] and http://site.bit would be better because localstorage (and cookie on multiuser) is domain-specific.
But exluding /uimedia/ because it holds the internal css and js files of zeronet and it will not avalible from http://www.site.bit/uimedia.
 And i think it would be more usefull if pressing the extension button leads to the ZeroHello homepage and moving the proxy settings to extension options.
 It works pretty good, I think you could submit it to google app store to make the install easier.
 Nice, I had to restart chrome after removed the unpacked extension, but its working now
 you can only register web+zero://, but it's not really a good solution, because it's redirect back to 127.0.0.1:43110, so if you want to copy the link then you have to edit it manually again.
 I agree with @dmp1ce ï¼Œ I think using the zero:// scheme with a custom browser is the best tooï¼Œ  The ignore patter in only exclude file from content.json signing method.
You can still access the file locally, but it won't be transfered to other peers.

If you execute `zeronet.py siteSign [Yoursiteaddress]` command you should see [SKIP] at files you defined in ignore (files starting with . ignored by default, you dont have to put it to ignore pattern)

If you using zerobundle and don't have python installed then open command line at zeronet.py and execute `..\python\python.exe zeronet.py siteSign yoursite`
  Does not relies on canyouseeme.org, also possible to use to check i2p/tor hidden service.
 No progress on it, but i'm not sure what you mean.

In my theory it would work like this:
 - Collect some IPs via Trackers/Peer database/etc.
 - Ask them to connect back to the given port and return the result

Based on this information the client would be possible to find out if their public ip/hidden service is works well or not. I think Tor hidden service checking is not necessary. If the hidden service has registered successfully, then it should work regardless your network settings. 
It also has 1-5 minute cooldown time, so you can't do it on startup.  Create a demonstartion youtube video about ZeroNet.
 I think a video that demonstrates ZeroNet working would be a good start:
- Starting from clean install
- Doubleclick on zeronet.cmd
- Browser starts, loads ZeroHello
- Load ZeroBoard, submit a message
- Load ZeroBlog, Register username using ZeroID, submit a message
- Load ZeroTalk, click on some topic (the registration process will be changed to ZeroID based, so registration can be skipped here)
 A video about how zeronet work also would be nice, but it needs more work.

For graphics you can use https://docs.google.com/presentation/d/1_2qK1IuOKJ51pgBvllZ9Yu7Au2l551t3XBgyTSvilew/edit
 It could also include the downloading ZeroBundle.zip from zeronet.io > rigtclick extract here > start zeronet.cmd process. Probably needs some editing/speedup at extracting because it has 3500+ files files and its boring to watch the progress bar. (Later it can be improved by creating a more compact python runtime using [py2exe](http://www.py2exe.org/) or removing unnecessary files, eg. testing or tcl/tk)
 I think both would be nice, probably it would be easier to start with a simple screencast
 I think you can skip the platform-specific installation method for now and start from executing start.py 
 It looks nice, probably it would be beter with a bit larger browser window and starting with clean install (also showing the download process) and if possible with open port to prevent warning messages
 I meant the ZeroHello (and other zeronet pages) downloading process (rotating square).
 Thanks, it's better, but the layout looks broken :( I really need to find a mac to fix/reproduce the problems.
 The two main problems is with the zero button on top-right (has to find a fond that similar to Consolas on windows) and for some reasons the site names on zerohello are misaligned and not visible.

I try to find a way to access a mac machine this week.
 Thanks for the tips, I will check them! 
I have contacted browserstack.org, maybe they can sponsor us with a osx safari live browser testing solution.
 hooray! browserstack.org going to sponsor us with an account, so it will allow to test zeronet on more platforms (eg osx safari) and makes also possible to write automated tests
  The problem is to do this we have to store the blockchain on every machine and it would require around 50gb of database.

It could better idea possible by running a full bitcoin node on every machine and zeronet only distribute the html/javascript/css that required to query the bitcoind.
  Currently the sqlite database is updated as the new file is written to the hdd.

Maybe it would be better to read the files when its required by the sql query:
- data/user/data.json updated
- The storage layer marks the data/user/data.json as updated
- File written to disk, no sql connection made

When user tries to list the topics:
- Storage layer loads the files to sql that marked as updated
- Reset the files updated status
- Run the query on updated database

Pros:
- Lot faster data process by batching updates using BEGIN / COMMIT
- Less CPU usage If you only "seed" the site
- If the file updated more than once then only have to load 1 times

Cons:
- Displaying the data could be slower if you have many pending updated files because it has to parse the updated files before display any result
- Has to store somewhere the pending database updates
 nope, probably we don't need it.  Thanks for reporting for some reason your python is unable to open an sqlite database. After some googling maybe specifying absolute path could help.

To find out if this is a problem I made a testcase for Db connection. To run please update your zeronet by running `python update.py` (or git pull), then `python -m src.Test.test`

The output should look like this:

```
f:\Work\ZeroNet-git\ZeroNet>python -m src.Test.test
testBitcoinSign (__main__.TestCase) ... Taken: 0.542s, ok
testBitcoinSignCompressed (__main__.TestCase) ... skipped 'Not working'
testBitcoinSignOld (__main__.TestCase) ...  Taken: 0.786s, ok
testDb (__main__.TestCase) ...  Importing db...
Creating db using f:\Work\ZeroNet-git\ZeroNet\data\test\zeronet.db... ok
Creating db using data/test/zeronet.db... ok
ok
testMediaRoute (__main__.TestCase) ... ok
testTrackers (__main__.TestCase) ... skipped 'Notyet'

----------------------------------------------------------------------
Ran 6 tests in 1.466s

OK (skipped=2)

f:\Work\ZeroNet-git\ZeroNet>
```
 In theory its comes with every python and your log says:
`[2015-03-31 08:35:13,460] DEBUG Db:ZeroTalk Connecting (sqlite version: 2.6.0)...`
So I'm not sure if thats the problem.
  At the moment at every click: Load wrapper -> Wrapper creates iframe and loads page html -> Init websocket connection -> Load page details using websocket api

It could be much faster by sharing the wrapper and the websocket connection between and only change the inner frame html.

Need a wrapper api command that allows change the url of the page.
 The overhead is much smaller since the http caching enabled on js and css files. Pushstate support can be a solution, but then its needs application level support for this feature.

Probably related problem that needs to be fixed:
If you scroll down on a page (for example zerotalk topic listing) then click on a link and then go back to previous page then chrome and ie scrolls to page top. (it worked on chrome some months ago, but they broken it :( )

Possible workaround for the problem: Store (cookie or localstorage) the scroll position before the page onload then load it back on next page load.
 Probably we don't need it. It would require changes in site's source code (call API instead of simple `<a href="...`) and they can archive the same with wrapperPop/Pushstate API calls.
Also with js/css caching enabled the wrapper loading speed dramatically increased.  you mean delete the site from all peer's computer?

You can do that by deleting your site files, siteSign and sitePublish the modification
  Send / Receive messages using local client XMLRPC
 Yes, sorry, I forgot about it. I will check it soon  Sites protected by password or public-key based auth.
 @OliverCole AES and ECIES encrypt/decrypt functions added some months ago: #216
It could allow to encrypt every content on the site and decrypt after it downloaded on the client side.

It's not ideal for every application case, there is many ways to implement private sites it's all depends on what you want to do? Filter IP-s who is connecting to your site? Add password protection? Only encrypt part of the sites?
 We already using openssl, pynacl just an alternative to it and it does not support bitcoin cryptography that we using most of the time
 Not sure if storing everything twice is a good idea, probably a password/publickey based peer authorization is easier and would allow to remove users.
 To be able request any file from peers you need to authenticate yourself using publickey algorithm.

Other possibility: when requesting any.jpg using http and it's not exists, then it's looks for any.jpg.encrypted and try to decrypt it using they AES keys you have associated with the site/directory. 

This way the sign/publish method would remain the same, also allows multi-user sites and only requires some smaller modifications in the UiServer/SiteStorage (for sql imports) and new API functions to add AES keys.
 I think there is two possibility:

### Per file encryption

Anyone able to receive files/updates, but the files are encrypted

Pros:
- Does not relies on connection security
- Allows easy per-directory encryption
- Allow anyone to host files without knowing it's content (eg. paid hosting)

Cons:
- Performance: has to decrypt the files on the fly or build a cache
- Not possible to remove users from the site
- You can spy on site activity
- (Future) Patch command can be problematic

### Connection security

You need to authenticate with other users connection before receive any updates or files.
 Pros:
- Not possible to spy on site activity
- May be possible to create new password and remove users
- Files stored the same way as any other site

Cons:
- Relies on connection security (SSL/onion): MITM can be a problem
- Per directory encryption is harder, but may be possible
 the problem is the zip file is not suitable for multi-user sites and per-user encryption is not really works for many users (100+)

patch command: to greatly reduce bw usage when one of the files modified instead of re-transfer the whole file only send the changed lines (diff)
 Multi-user sites: interactive zeronet sites where every user has his/her own files. (ZeroTalk, ZeroBlog, ZeroMail, etc.)

If the files are encrypted and you want to remove an user, then you have to re-encrypt every file and everyone has to re-download all of them.

If you want to make sure of encryption you will still able to encrypt the data using AES+ECIES functions (like ZeroMail)
 New key release could work, but then you have to also keep the old keys in order to able to decrypt the old contents. ECIES takes more space, than symmetric encryption: 225 Bytes base64 encoded, so 10000 user = 2.2 Mbyte new data added to site when someone is removed.

It could be possible to encrypt the patch with some overhead: decrypt patch -> decrypt the whole file -> apply patch -> encrypt the file -> check sha512

It would be nice to check how other projects do this (syncthing, bittorrent sync, Tahoe-LAFS, etc.)
 The per-file encryption is not compatible with patch command because it's not a good idea to re-use the IV. if we add a new feature we have to support it forever, so it's need to be as flexible as possible. 
 I think it's fine to put it here
  - It would be nice to have a per-site `Allow clearnet connections` setting: If disabled then standard ipv4 peers is connected using Tor exit-nodes. If its enabled then only Tor peers are connected through the Tor proxy.
- Display warning to user: You are in Tor-only mode, you should also configure your browser to use Tor network. (maybe restrict external resources using Content Security Policy)

Problem:
- The torrent trackers does not allow to store tor/i2p addresses.

Possible solutions:
- DHT: Its not easy to write a good DHT implementation and Tor doesnt support UDP, so we need custom DHT (it requires reliable servers for bootstrapping and not sure if its going to work fine with current small number of nodes) or proxies that converts DHT traffic to tcp.
- IRC: Not really decentralized solution, so i would not be happy to use it. (some altcoins using it, eg. Namecoin so it could work)
- Bittorrent http trackers could still work, but without tor address support, so you could browse zeronet sites, but could not host zeronet sites on tor. Maybe its possible with peer-exchange combination.

Any help/idea/suggestion greatly welcomed. Thanks! :)
 Done in 0.3.5
  - Ability to black/whitelist sites
- Max site size
- Disable autoupdate features
- Restrict site setting changes (pause, delete) to selected users
 Actually I think all of them are implemented.  Similar to torrent's DHT solution, required features:
- Find peer to specified site file (to allow sites to add optionally download files)
- Ipv6 and tor address support for peers
- It should work using on Tor (TCP only, maybe UDP on clearnet)
- No other library dependency if possible
- Store peer ips to allow work without bootstrap server

Maybe its requred to separate the DHT from Peer Exchange

Please comment if you have other ideas/suggestions.
 zeronet protocol is different from torrent, so libtorrent will not work. Also bittorrent DHT is UDP based, so it will not work on Tor without proxying it to TCP which I don't want. And it does not support storing Tor hidden service addresses, so you would not be able to create sites on Tor.
 Its already there:
- Ipv6 and tor address support for peers
- It should work using on Tor (TCP only, maybe UDP on clearnet)
 @stillwarter DHT still need a bootstrap server, so it does not help on new "virgin" clients.
 New progress made yet. 
Does anyone know already working P2P application that uses DHT over Tor? (preferably with >1000 nodes)  http://zeronet.readthedocs.org/
- [x] Make ZeroFrame API reference uptodate
- [x] Add Disqus to allow comments/questions
- [x] Put the [example site](http://zeronet.readthedocs.org/en/latest/site_development/using_zeroframe_api/) to github
- [x] FAQ
- [x] Description of content.json format
- [ ] Create ZeroNet site for the documents
- [x] Network protocol
- [x] New donation page
- [ ] Done / Future features
- [x] More screenshots
- [ ] Dbschema version 2
- [ ] Handshake
- [ ] Trusted authorization providers
- [x] New command: actionSiteSign
- [x] New command: actionSiteClone
- [x] New command: actionFileRules
- [x] New command: actionCertAdd
- [x] New command: actionCertSelect
- [x] New command: actionCertSet (admin)
 add goal specific donation addresses: `$.get("https://mainnet.helloblock.io/v1/addresses?addresses=1QDhxQ6PraUZa21ET5fYUCPgdrwBomnFgX", function(res) { console.log(res) })`
 Faq:
- How to use it with Tor? (update needed)
- Is it possible to install it on remote machine?
- Do I need open port to create new site?
- What happens when someone hosting malicious content?
- Openssl on centos
 FAQ WIP: http://zeronet.readthedocs.org/en/latest/faq/
  Thanks for reporting!
cc: @sirMackk 
 For unknown reason it stopped working for me. (nothing changed: same version that worked before, same router, same computer)

The ssdp discovery UDP packets not even visible using packet analyzer (smartsniff)

If i put `sock.bind(("192.168.1.10",999))` to _m_search_ssdp it wokring fine also tried `sock.bind(("",999))`, but no luck. Any idea?
 Made it work by detecting local ips (+added some logging, [fixed the successful run check](https://gist.github.com/HelloZeroNet/5133c7f03030620c278f#file-upnppunch-py-L220) and it also can be run by standalone using `python UpnpPunch.py`):
https://gist.github.com/HelloZeroNet/5133c7f03030620c278f

Please test :)

Update#1:

socket.gethostbyname_ex('') does not works on linux, but the getsockname() gives the correct answer, so it should work there.

``` python
>>> socket.gethostbyname_ex('')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
socket.herror: [Errno 4] No address associated with name
>>> s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
>>> s.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)
>>> s.connect(('239.255.255.250', 1))
>>> s.getsockname()[0]
'176.231.40.130'
```

Result on my windows pc:

``` python
>>> socket.gethostbyname_ex('')
('short-pc', [], ['192.168.1.10'])
>>> s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
>>> s.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)
>>> s.connect(('239.255.255.250', 1))
>>> s.getsockname()[0]
'127.0.0.1'
```

it worked before, so probably sometomes the s.getsockname()[0] returning the '192.168.1.10' ip as answer

if we can find a way to list available ip address on mac/linux then we can also add them to probe iplist

Update#2:
Added this one too, because it returns correct ip on both platform:

``` python
>>> s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
>>> s.connect(('8.8.8.8', 0)) # Using google dns route
>>> s.getsockname()[0]
'192.168.1.10'
```
 I think its clearly fixes some problems, so the PR is welcomed
  Thank you! :)
  Progress bar is planned, but zerosearch is working here. Can you give urls to sites that loads slowly for you?
 Progress bar is a good idea, added to latest (0.2.5) version

There is a [little tutorial](http://127.0.0.1:43110/1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8/?Post:3:How+to+have+a+blog+like+this) on siteCreation at ZeroBlog.

And there is a simple example of ZeroFrame API at [developers docs](https://github.com/HelloZeroNet/ZeroNet/wiki/ZeroNet-developer's-documentation)
  Not every new message reaches all of the peers.

It's related to https://github.com/HelloZeroNet/ZeroNet/issues/43

Already working on new network code without ZeroMQ. It will be released in 1-2 weeks.
 It had some bug in publish method, fixed in 0.2.4
  Thanks!
  I have been thinking about it earlier, but it would have some problems:
- The currently used bitcoin crypto libs doesn't support it, so they need to be modified
- Vanity address generator would not work

Some ideas to blockchain usage:
- Proof of site age by first transaction to site's address
- You can accept donations to site address

So I don't think it worth the mess up.
  It's normal: 
- /Console raises a custom exception "Here is your console" to spawn the werkzeug console in UiRequest namespace. (You can access the console by hover over `raise Exception("Here is your console")` line the clicking the second icon from right.) Its a little bit hackish, but works :)
- /Debug always display the last error's namespace (in next version I will exclude notifications from it)
 Ah looks like the google bot found the console url somehow. I'm going to restrict the /Console and /Debug access to debug mode only.

Update: Looks like its restricted already:

```
        # Debug
        elif path == "/Debug" and config.debug:
            return self.actionDebug()
        elif path == "/Console" and config.debug:
            return self.actionConsole()
```

The exception it raises in non debug mode:

```
  File "F:\Work\ZeroNet\src\Site\SiteManager.py", line 47, in need
    if not isAddress(address): raise Exception("Not address: %s" % address)
Exception: Not address: Console
```

So i have to make a better error message for this

Update #2: Ok fixed, in next version it will drop "Not Found: /Console", thanks for the bugreport
  Not all site optimalized to mobile devices, so maybe its not a good idea to make it default, but added (bccd246f716ce191d872fdae2a84b27b66300641) a viewport option to content.json, you can use it like this:

``` json
 ...
  "signs_required": 1, 
  "title": "ZeroTalk", 
  "viewport": "width=device-width, initial-scale=1.0", 
  "zeronet_version": "0.2.0"
}
```

and added WrapperAPI command too: `@cmd "wrapperSetViewport", "width=device-width, initial-scale=1.0"`

I don't have any smartphones to test it, but works in chrome's device emulator. 

Applied the viewport on ZeroTalk site, it would be nice if anyone can check if its displays nicely on any small screen device.
 only `"viewport": "width=device-width, initial-scale=1.0"` works, `"` quotes will be escaped, so you cant break out from the `content` attribute of the meta tag

Thanks for testing, yeah, notifications is not yet responsive.
  Buit-in Tor (with hidden services) just landed 1 week ago, the core modifications was made in mind of future i2p/ipv6 support. I was looking for python libraries for i2p, but only found some outdated ones (updated 12 years or 3 years ago). 

Need more research to see if i2p support many (per site so 100+) services from same host and have to find out the cryptography of i2p address to be able to create proof-of-ownership signature to avoid some network attacks.
The other main problem is to make it any usefull we have to pack it with ZeroNet, i'm not sure if its possible with java applications.
 The problem with optional installation: I2p does not allow socket connections outside the network, so to be able to connect to a site using i2p it must have at least one peer with i2p address which is unlikely if they have to start/configure by hand.
 @str4d Thanks for the responses. As for the "many (per site so 100+) services from same host":

In full Tor mode we create a new .onion address for every site you seeding to improve privacy by make it harder to find out what other sites you using. So if someone has 100 sites in his/her client then on the startup we need to create 100 i2p address on startup.
 Probably not anytime soon, maybe second half of 2016
 It will use https://github.com/arvidn/libtorrent which has no i2p support atm.
 nice, then looks like there will i2p support :)
  I think it could work this way:
- By default every site has 10MB size limit
- If the site used 80% of its limit zeronet displays a notification when you visit the site: `This site want to store more data than current limit: 10MB. [Incrase limit to 20MB]`
- The limit steps: 10MB, 20MB, 50MB, 100MB, 500MB, 1GB, 5GB, 10GB, Unlimited
- If a new update to content.json comes in and the total size of site exceed the limit then the update will be rejected.
- If you visit a new site and its size larger than 10MB then the notification will be displayed on the loading screen and the download wont be started until you give the permission
 Added in version 0.2.1:
![sizelimit](https://cloud.githubusercontent.com/assets/10350359/6200295/73dc987e-b471-11e4-9438-4d23e5adb5d4.png)

NSFW warning can be added later if necessary
  I'm not familiar with docker, but added this:
https://registry.hub.docker.com/u/nofish/zeronet/builds_history/213281/
Please tell me if any problem with it.
 according to build log the msgpack build is failed with `msgpack/_packer.cpp:8:22: fatal error: pyconfig.h: No such file or directory`
probably it would be nice to add python-dev package to apt-get install or install msgpack from repository (not sure if every linux has msgpack 0.4.0+)
  you can add this to your content.json
`"ignore": "\.git.*",`

but ignore all files starts with `.` could be a good idea
  - Upgrading ZeroNet: keep your data dir, all your data is stored there
- Upgrading ZeroBlog: backup content.json and data.json from your site, overwrite all other files

Yes, the sites ordering is problematic on ZeroHello, currently sorted by peer number, bookmark feature is a good idea
  thx
  Thanks!
  Unfortunately I don't have access to any OSX machine, so I cant test or fix it.
  Thanks
  thanks, fixed by your push
  We need a cross-platform, pure-python dns query lib, so we can use http://www.opennicproject.org/ servers.
 I have chosen this format, to allow subdomains (@ means zeronetwork.bit without subdomain)

```
    "zeronet": {
        "blog": "1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8", 
        "@": "1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr", 
        "talk": "1TaLk3zM7ZRskJvrh3ZNCDVGXvkJusPKQ"
    }, 
```

But I haven't found any reliable way to resolve this information without installing namecoind.

Using NS TXT record and http://www.opennicproject.org/ could be a workaround:

``` python
import DNS
DNS.DiscoverNameServers()

r = DNS.DnsRequest("zeronet.zeronetwork.bit", qtype="TXT", server=['192.71.247.247', '75.127.14.107'], timeout=300)
res = r.req()
res.show() 
```

```
[...]
zeronet.zeronetwork.bit    1109    TXT     ['@:1EU1tbG9oC1A8jz2ouVwGZyQ5asrNsE4Vr,blog:1BLogC9LN4oPDcruNz3qo1ysa133E9AGg8,talk:1TaLk3zM7ZRskJvrh3ZNCDVGXvkJusPKQ']
[...]
```
 Found this one, it could work (but single point of failure): https://dnschain.info/bit/d/zeronetwork
edit: 
found alternative servers:
- http://dns.dnschain.net/d/zeronetwork
 a new dnschain server:
https://api.dnschain.net/v1/namecoin/key/zeronetwork.bit

There is an another option to resolve bit domain:

Create a special, dns resolver site that holds all registered zeronet domains in a json file, so everyone has the dns database on localhost.

Pros:
- Its allows fast and secure dns resolving
- Does not depends on any central server
- Nobody can see what domains are you resolving
- Later it could work well with anonymity networks (tor, i2p)

Cons:
- It needs a bot that update the database from namecoin transactions
- If the private key of the site is compromised then its possible to modify dns records
 another alternative:
http://namecha.in/name/d/zeronetwork
 I have done a plugin using 2 dnschain servers, but i'm not satisfied by the result: 
- It takes 1-5 sec to resolve the domain using the 2 servers, by increasing the dns caching time its possible to workaround the problem, but not a real solution for offline/slow connections
- Trusting in 2 servers result not secure enough and I could not find other servers that allows to resolve namecoin json informations

So I decided to take the alternative, [dns resolver site](#issuecomment-78250713) approach. Its developing well, need some more days to finish it.
 Status report: i think everything is working now, if no other bugs found i will publish it tomorrow
 Added Zeroname plugin: b122f471003e3c293513671d7d53f63c7c6d5753
The experimental dnschain plugin also supplied (disabled by default)
Later, if lightweight namecoin client is released it will be also supported.
 The "" key means the primary domain, any other than that is a subdomain.

Also added this information to http://127.0.0.1:43110/1Name2NXVi1RDPDgf5617UoW7xA6YrhM9F "HOW TO ADD A DOMAIN?" section
 yeah you probably right a custom prefix could be better solution, but i think we can have both: z/ prefix for .zero d/ prefix for .bit.
This allows to use your exitsing domains in zeronet and if someone wants to access your site without zeronet installed (and he able to resolve .bit domains) you can redirect him to a description about zeronet.

Update: I have asked about it in #namecoin and they said there was similar request from i2p and tor, but they rejected it and advised to use d/. Reasons:
- (1) it is useful to be able to verify that the IPv4 and ZeroNet versions of a name are owned by the same person; d/ makes that easy
- (2) if a new namespace is introduced, users will have to defensively grab their names at that namespace to prevent squatters from getting them
- (3) as an extension of (1), some users want their software to be able to choose which resolver to use (e.g. IPv4, Tor, ZeroNet) based on which ones are supported by their browser config; using a single namespace makes that easy

but changing .bit to .zero still sound like a good idea
  Yes, i have already had some thoughts about it:
It can be easily solved by adding the allowed signers public key and sign to content.json like this:

``` json
"signers": [
 {"Signer1Addr": "Signer1sign"},
 {"Signer2Addr": "Signer2sign"},
 {"Signer3Addr": "Signer3sign"}
],
"signers_required": 2,
```

So when someone got a new content.json, he checks if it has the required number (definied in `signers_required`) of correct signs.

Maybe we should combine it with some kind of permission system, so you could define rules like:
"Signer4Addr" has permission to modify "messages/Signer4Addr.json" file, but not anything else. (size could be possible limit too)

But at the moment I want to keep ZeroNet as simple as possible, and only adding new features if we has the application that could use benefits of it.
 Its implemented in 0.2.0, but its not deep tested yet
  Yeah, the main problem is all site is using the same domain. Permission requesting is a good idea (maybe with other http://www.html5rocks.com/en/tutorials/security/content-security-policy/ features)
Later we can pack a sqlite server, so the clients can do queries via websocket api.

Util then please use flat json files or any format supported by [alasql](https://github.com/agershun/alasql)

Please let me know if you have any benchmark results on indexedDB vs flat json vs alasql.
 Not directly, but you can write files using the [API](https://github.com/HelloZeroNet/ZeroNet/wiki/ZeroFrame-API-reference-documentation). (see [ZeroBlog](https://github.com/HelloZeroNet/ZeroBlog) example)
 Now its possible to use browser's localStore with ZeroFrame API:
http://zeronet.readthedocs.org/en/latest/site_development/zeroframe_api_reference/#wrappergetlocalstorage
  Update failed is normal when seeding own site without other peers.
In the latest commit "Update failed" warning changed to "No peers found" when seeding own site to make it less scary.

ZeroMarket and ZeroBay still under planning, it will be arrive later
  Thanks!
  Thanks for reporting. I rather not touch the external subtl library,but its fixed at config parse: 2000f5b38eb5d7e6f29bc29232b8493d31b6817a
  If he owns the private key he could have access to bitcoins too. (havent tried yet)
  Thanks!
Namecoin (.bit domains) support is planned, but its not priority yet, since ZeroNet is not ready for mass adoption yet.
Could you be more specific about your Search/Discovery idea?
 Thanks for explaining. :) Sounds interesting, later I will check it even deeper.
 I have tried the BitTorrent Maelstorm about 1 month ago (found on a russian forum :) ) and I was not impressed. Its basically a torrent client embedded into a browser.
I had the Zeronet idea for a while in my mind, but tried to convince myself its not a good idea/not going to work. Then I seen the BitTorrent guys working on similar idea and throughout: If they thinks its a good idea maybe it is. (Written first lines of codes exactly 1 month from now)
 Namecoin .bit domain support added in 0.2.8: b122f471003e3c293513671d7d53f63c7c6d5753
  We have pure python upnp, so fixed in 34f6d1ee7c8b5a8958f675c5e17a95c34c6a4967
  I think its fixed in latest version:
https://github.com/HelloZeroNet/ZeroNet/blob/a977feec330a024686518ce6c374167d63d564f2/src/File/FileServer.py#L54
  you can use `<a href="/13TSUryi4GhHVQYKoRvRNgok9q8KsMLncq/2015/01/15/decentralized-websites-with-zeronet.html" target="_top">Some link</a>`
 If you add `target="_top"` it will change the browser bar url
  Cons:
- It could be irratating if you just restart it or you want to put in autorun

Possible solutions:
- Open by default but can be disabled via `--dont-open-browser` command line parameter
- Create an another file that starts zeronet.py and opens the browser too: start.cmd
- After starting zeronet.py display a message: `-- Press enter to open http://localhost:43110/ in your browser --`
 Thanks, merged!
  Thanks!
  Thanks!
  Thx, but I rather not store save the private keys to a simple txt file. From the version 0.1.4 its harder not to save the private key at siteCreate :)
  ```
Error catched (<type 'exceptions.AssertionError'>, AssertionError("This event is already used by another greenl
et: (<ErrorhookedGreenlet at 0x2a8f958: <bound method Worker.downloader of <Worker.Worker.Worker instance at 0x
2c03f38>>>, timeout('timed out',))",), <traceback object at 0x2abbcb0>)
Traceback (most recent call last):
  File "/usr/lib/pymodules/python2.7/gevent/greenlet.py", line 390, in run
    result = self._run(*self.args, **self.kwargs)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Worker/Worker.py", line 47, in downloader
    self.manager.doneTask(task)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Worker/WorkerManager.py", line 128, in doneTask
    self.site.onFileDone(task["inner_path"])
  File "/home/sumo/p-private/dev1/bin-zeronet/src/util/Event.py", line 8, in __call__
    f(*args, **kwargs)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Site/Site.py", line 275, in <lambda>
    self.onFileDone.append(lambda inner_path: self.fileDone(inner_path))
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Site/Site.py", line 307, in fileDone
    self.updateWebsocket(file_done=inner_path)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Site/Site.py", line 286, in updateWebsocket
    ws.event("siteChanged", self, param)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Ui/UiWebsocket.py", line 50, in event
    self.cmd("setSiteInfo", site_info)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Ui/UiWebsocket.py", line 60, in cmd
    self.send({"cmd": cmd, "params": params}, cb)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/Ui/UiWebsocket.py", line 67, in send
    self.ws.send(json.dumps(message))
  File "/home/sumo/p-private/dev1/bin-zeronet/src/lib/geventwebsocket/websocket.py", line 345, in send
    self.send_frame(message, opcode)
  File "/home/sumo/p-private/dev1/bin-zeronet/src/lib/geventwebsocket/websocket.py", line 331, in send_frame
    self.raw_write(header + message)
  File "/usr/lib/pymodules/python2.7/gevent/socket.py", line 504, in sendall
    data_sent += self.send(_get_memory(data, data_sent), flags)
  File "/usr/lib/pymodules/python2.7/gevent/socket.py", line 484, in send
    wait_write(sock.fileno(), timeout=timeout, event=self._write_event)
  File "/usr/lib/pymodules/python2.7/gevent/socket.py", line 188, in wait_write
    assert event.arg is None, 'This event is already used by another greenlet: %r' % (event.arg, )
AssertionError: This event is already used by another greenlet: (<ErrorhookedGreenlet at 0x2a8f958: <bound method Worker.downloader of <Worker.Worker.Worker instance at 0x2c03f38>>>, timeout('timed out',))
```
 - queue for websocket messages
 It happened when i ran the zeronet on remote machine (around ~40ms away) and downloaded a site with many small files.
The ZeroNet pushes pushes an event over websocket after every file download, and maybe the last event message was still not finished when the next came.
I think it could be fixed like this:

``` python
def send(message):
 self.message_queue.append(message)
 if not self.sending:
    self.sending = True
    while self.message_queue:
      self.socket.send(self.message_queue.pop(0))
    self.sending = False
```

Maybe there is a better solution with gevent, but i like pure-python solutions, its easier to understand whats really happening.
Btw I optimized the Websocket to much smaller event messages, maybe its not an issue anymore, im going to test it later.
 I think this model will not work in this case, because we dont want to send messages in parallel and we dont want to wait until the message is sent
 ran into this problem again, so i fixed it: https://github.com/HelloZeroNet/ZeroNet/blob/e8368a8da1478ec370a129e96aa89e9fb638b9ad/src/Ui/UiWebsocket.py#L71
  Try this please:
- Stop zeronet
- Edit data/sites.json and set "own": true at your site
- Use siteSign 
- Then start zeronet.py again. 
  in next release the "own" flag will be true on newly created sites
 I can access your site, looks nice :)
I think the Hash failed problem is because someone has older version of content.json than yours. 
You should run `zeronet.py sitePublish 1GXtHRoh7495zJYLthQ8xPt2dRzm8DwWhb` so he will get the updated file
  Unfortunately the library currently used for networking (ZeroMQ) don't offer bw limitation or network usage information. It could be fixed by removing ZeroMQ and rewriting the communication without it.

At current stage ZeroNet is not suitable to distribute large files/sites, so its not priority.
 I think the a simple gevent StreamServer will do the work. Not really take advantage of these messaging libraries.
Something with built-in rate limiting and maybe client priority will be nice, but I don't know anything like this for python :(
  Torrent like file splitting and distributing
 Maybe needs to wait until DHT support to able to find peers to needed fileparts
 Some blocker for big files: 
- Currently the downloads stored in memory until they get verified, it need to modify the storage mechanism to make it work efficiently (sparse files?)
- There is no file splitting support: You dont know if the file is valid or not until you downloaded the whole file and you can only download from one peer at one time
- Most of the peers using Tor network to connect ZeroNet, that is not suitable to transfer big files

As optional files support added around 6 months ago, so DHT is no longer required for this. ZeroNet is created for dynamic websites, most of the site types does not requires big file support, so it's not a priority yet. Maybe adding a torrent client as a plugin is a better solution.
 Plugin would be nice, i'm planning to do a plugin management interface later, that makes easy to add/remove/install the non-default features
 probably it's possible if we use torrent for big files
 BitTorrent support is planned in the next 6 months, which will provide solution for big files
 BitTorrent clients also have the advantage of ~15years spent on optimization and the fact that they don't have to worry about the dynamic content. (eg. they can identify pieces by a simple id on zeronet you have to identify by filename or hash) # Plan 0.5

## File hashing: .piecemap.json

To avoid large content.json files move the piece hashes to separate file.

### Example content.json

```
{
  "files_optional": {
    "video.mp4": {
      "sha512": "174004c131000b2c8d57a411131f59f7c75d888367c00e3fca5f17e2adf422b2",
      "size": 11227004,
      "piecemap": "video.mp4.piecemap.json"
    },
    "video.mp4.piecemap.json": {
      "sha512": "174004c131000b2c8d57a411131f59f7c75d888367c00e3fca5f17e2adf422b2",
      "size": 11227
    }
  },
  [...]
}
```

### Example video.mp4.piecemap.json

```
{
 "video.mp4": {
 	"piece_size": 1000000,
 	"sha512_pieces": ["783afdeb186b50c696030f199d5db233270a84cd6183316be34c623e341dd85f", "0603ce08f7abb92b3840ad0cf40e95ea0b3ed3511b31524d4d70e88adba83daa", ...]
  }
}
```

#### Size test with 2784 pieces

 - video.mp4.piecemap.json: 189k
 - video.mp4.piecemap.json.gz: 107k
 - video.mp4.piecemap.json.bz2: 93k
 - video.mp4.piecemap-indent.json: 211k
 - video.mp4.piecemap-indent.json.gz: 108k
 - video.mp4.piecemap.msgpack: 97k
 - video.mp4.piecemap.msgpack.gz: 94k
 - video.mp4.piecemap.msgpack.bz2: 92k

#### Read 1000x times:
 - video.mp4.piecemap.json: 1.39s
 - video.mp4.piecemap.json.gz: 2.7s
 - video.mp4.piecemap.msgpack: 0.13s

So msgpack or json or json.gz?

## Questions

 - How/where to store which pieces we have?
 - Uploading? WebSocket suitable for this or separate HTTP post request?
 - Compressed piecemap?
 - How to display it in the UI?
 - Is there any real-world use case to support partial modifications on big files?

## Storage

### Store as one big file
To make it fast and efficient we need sparse file support in the fs. It works well on ext4 by default and on windows 10 (probably also on 7-8) after setting `fsutil sparse setflag testfile`.

Pros:
 - Less files
 - External app support: you can play videos in any player

Cons:
 - It will be slow on older systems: fat32 (android) and windows xp
 - Probably need more work

### Store pieces as separate files
Pros:
 - More compatibility, works equally well on fat32 and windows xp

Cons:
 - No external app support

## Uploading via web interface

### WebSocket

Pros:
 - Already authenticated

Cons:
 - Looks like the geventwebsocket library does not support streaming
 - The websocket channel is blocked during the upload (splitting could help)

### Http request

Pros:
 - Different channel and connection, so does not interfere with other API calls or messages

Cons:
 - Has to be authenticated separately
 - Cookie/CORS problems?

## Plan
 - [x] Experimental piecemap hasher
 - [x] Add piecemap via uploading
 - [x] Add piecemap via signing for files larger than 5MB
 - [ ] Check permissions
 - [x] File downloading using sparse
 - [ ] Demo video playing
 - [ ] Demo uploader site
 - [ ] UI modifications Same goal, but torrent files using it's own non-standard (never used by any other application) encoding (bencode) and outdated, not secure anymore sha1 hash, so I think it would be a mistake to use it. If we don't case about Tor network compatibility, then is a Torrent plugin in the works: https://github.com/rllola/zeronet-torrent-plugin (python-ipfs is pretty incomplete atm.)

I planning to add it as a plugin, so most of the parts will be re-usable and it will make other network implementations easier. # Exchanging who has the pieces we looking for.

## Use the same hashfield we currently using for optional file

Pros:
 - Find/storage already implemented, so much less work

Cons:
 - Memory/bw usage: 2 byte/piece, so for a 5GB file with 1MB piece size it's at least 10kb data to store and transfer (per peer, per file)
 - Limited efficiency: We use 2 byte identifier for optional files (first 2 bytes of sha512), so if two piece has the same 4 char of the hash, then it will give false results, so we have to keep trying until we find a valid result.

## Assume everyone downloaded the whole file
Keep trying until we find someone who has the piece.

Pros:
 - No extra bw/store/mem requirements

Cons:
 - Less reliable response speed as we have to connect and ask peers until we find someone
 - Can't display separate leech/seed number

## Add a new per-file piecefield

Pros:
 - Won't trash hashfield: Only adds the file's root hash to it
 - We can find piece based on file hash and it's piece number, so no hash collision chance and much more efficient

Cons:
 - Added complexity: Need new protocol extension to exchange and find in this field
 - Has to store the peer's piecefield

# Storage of piecefield

```
piecefield = "1"*1000
piecefield += "0"*500
piecefield += "1"*1000
piecefield += "0"*2500
# 1 means downloaded 0 means not downloaded
# So: There is 5000 pieces, first 1000 and and another 1000 piece downloaded after the 1500th
```

## Storage as int
`int(hashfield, 2)  # sys.getsizeof: 680, msgpack: long too big to convert`

## Compress it with zlib
`zlib.compress(hashfield, 1) # sys.getsizeof: 75, msgpack: 57`

Using custom zlib compression: 
`compressor = zlib.compressobj(1, zlib.DEFLATED, -15, 1, 3)  # sys.getsizeof: 48, msgpack: 28`
 On Sia you have to pay for the storage. Because of that I think it's not suitable for most of the use cases that we need. ## status update:
As usual, it's I bigger task, than i originally tought, but I'm getting there, I just did a successful video stream between two clients:

### Done:
 - Exchange piecefield (which pieces someone has within a file) between peers
 - Implemented a custom compression format for piecefields
 - File downloading based on piecefield
 - Http stream with ranged file support (seek in video files)

### Still left:
 - [x] Save / restore piecefields between client restarts
 - [ ] Make it compatible with OptionalStats plugin (Files tab on ZeroHello)
 - [ ] Non-streaming file download (start all piece download without file read)
 - [ ] More testing

### Questions:
 - Should it download big files if "download all files" checked on sidebar?
 - Should big files count in optional files limit? If yes, then it may easily automatically delete every optional file you downloaded before and/or the large files you downloaded
 @grez911 Not sure what you mean. The big file support is built on optional files feature.   Needs more testing + Put priority on browser requested files (and maybe start download with smaller files) Problematic site: 1Jr5bnqSnnp94CfC7xrqPh4yYYDRkpzozD
 file queue priority based on browser request added: efb1dc32105e3cd75eb112788d0def0303cac5b2
It should be much better now!
Tomorrow i will do some more testing...
 Your site worked here nicely:

```
[2015-01-14 18:35:35,969] DEBUG    Site:13TSUr..Lncq Start downloading...
[2015-01-14 18:35:35,987] DEBUG    Site:13TSUr..Lncq Need content.json first
[2015-01-14 18:35:37,736] DEBUG    WorkerManager:13TSUr..Lncq x.x.x.x:15441: Hash correct: content.json
[2015-01-14 18:35:38,838] DEBUG    Site:13TSUr..Lncq Downloading 1229 files...
[2015-01-14 18:35:39,364] INFO     Site:13TSUr..Lncq Bad file solved: index.html
[2015-01-14 18:35:39,563] INFO     Site:13TSUr..Lncq Bad file solved: 2008/03/13/index.html
[2015-01-14 18:35:39,766] INFO     Site:13TSUr..Lncq Bad file solved: css/syntax.css
[2015-01-14 18:35:39,954] INFO     Site:13TSUr..Lncq Bad file solved: css/screen.css
[2015-01-14 18:35:40,138] INFO     Site:13TSUr..Lncq Bad file solved: css/print.css
[2015-01-14 18:35:40,323] INFO     Site:13TSUr..Lncq Bad file solved: css/bluishcoder.css
[2015-01-14 18:35:41,387] INFO     Site:13TSUr..Lncq Bad file solved: self/self_comment.webm
[2015-01-14 18:35:41,960] INFO     Site:13TSUr..Lncq Bad file solved: self/self_font.webm
[2015-01-14 18:35:42,145] INFO     Site:13TSUr..Lncq Bad file solved: nixos/standalone-ndk/default.nix
[2015-01-14 18:35:42,338] INFO     Site:13TSUr..Lncq Bad file solved: 2006/06/04/narrative-javascript.html
...
```

Please make sure you have the latest version. Yesterday night I added a modification that put priority to files that requested by the browser. But maybe putting priority to *.js and *.css files by default could not hurt anyone.
 Fine :)
At there is still some problem with large sites: the site has 1 minute to finish all file downloads or the task will be killed.

Working on it, I think it will be fixed today.
 Here it comes: bcd0c0025aa5c8d23dba4362c75f8dbaf236dd27
(I think we can close this issue)
  ```
Norton

File blocked: tools\upnpc\upnpc-static.exe 

Threat name: Trojan.Gen.2 ( http://www.symantec.com/security_response/writeup.jsp?docid=2011-082216-3542-99 ) 
```

Pure python upnp implementation would be nice, but i could not find any good.
 I think nobody is working on it, so its free to go :)
I want avoid add extra dependencies, so it would be really nice to make it work using only gevent+standard libs.
 Wow looks nice, good work! I'm going to test it later today.
 Just tried it and its working here! :) On Monday i'm going to test it on other routers.
 it's working at my workplace too :) So I think we can include it in the next release if its ok for you too. 
 Fixed in 34f6d1ee7c8b5a8958f675c5e17a95c34c6a4967
  Thanks for reporting, its fixed: 6424c8288781a0cd93eaf0b9d5da0a7466ee3058
  Please send me log/debug.log file, so maybe I can find out whats wrong. hello@noloop.me
Thanks!
 Just added more detailed error logging, please try with it if problem still exits
