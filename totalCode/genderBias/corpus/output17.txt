  How did you build tesseract?
Error messages you posted comes from leptonica, so... I would suggest you make sure that the all dependencies (at least leptonica) are build as 64bit and with the same version of compiler... Hi,

Not sure if this is your post https://groups.google.com/forum/#!topic/tesseract-ocr/lufafrAAEnk
It points to `/Ob2` option while you state `/Ot`.

Did you try `RelWithDebInfo` configuration? To check if this is VS2017 issue, it's necessary to build on VS2015.
As I understand if we haven't any troubles on gcc/clang, it's problem of MSVC, not tesseract.  Please respect instruction for posting issue - use tesseract user forum for asking support  There are [clear instructions](https://github.com/tesseract-ocr/tesseract/wiki/Compiling) how to build tesseract from source. If somebody decide to ignore them, it is hie/her problem and not tesseract project.

Using autogen.sh is common way how to start configuration on build process in many opensource projects. 1. How did you installed leptonica?
2. Do you have more leptonica (e.g. from source and by system) installations? > syntax error near unexpected token `LEPTONICA,
this means that pkg-config is not aware about leptonica installation I am not pkg-config guru (or user ;-), but installing leptonica to custom location (e.g. not system wide) is always source of troubles... Before "pkg-config era" (3.04) this trick worked: https://github.com/tesseract-ocr/tesseract/wiki/Compiling#install-elsewhere--without-root.

Can you try this?
`ACLOCAL_FLAGS="-I /hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/" ./autogen.sh`  1. Please see https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#combining-the-output-files regarding how to create the traineddata file.

To create the 'fast' version, use 

convert_to_int | bool | false | With stop_training, convert to 8-bit integer for greater speed, with slightly less accuracy.
-- | -- | -- | --

2. You cannot use the tesstrain.sh /text2image process using non-unicode legacy fonts. For those you have to create image files from a document/pdf, use tesseract with makebox config file to create the box files, manually edit the box files for correct info and 4.0 format.

Training from images is NOT supported for 4.0 LSTM.

Your best bet will be to find some unicode fonts that look similar to the legacy fonts and train using those.    My vote is for dropping different versions. Is it possible to have gif4 and gif5 simultaneously in macports?
E.g., create giflib5 and set it for leptonica only. Other packages will use it when they're ready. Maybe you should drop it right after 1.75 release? So the change will be for 1.76 which is released after some another reasonable time.  running configure ends with the following messages.

```
Configuration is done.
You can now build and install tesseract by running:

$ make
$ sudo make install

Training tools can be built and installed with:

$ make training
$ sudo make training-install
```

I suggest that https://github.com/tesseract-ocr/tesseract/blob/master/configure.ac be modified to add instructions to run `ldconfig`
similar to as given in instructions in 
https://github.com/tesseract-ocr/tesseract/wiki/Compiling-%E2%80%93-GitInstallation

  ------------------------

### Environment

* **Tesseract Version**: <!-- Master-->
* **Commit Number**: <!-- 1207-->
* **Platform**: <!-- Windows 10 64 bit -->

### Current Behavior:
Tesseract baseAPI
`pixWriteAutoFormat("F:/test.jpg", croppedImage);
		Pix* test = pixRead("F:/test.jpg");
		api.SetImage(test);
		api.Recognize(0);
		char *value2 = api.GetUTF8Text();`

ERROR : 
`Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made`

Note : Input image is exist !

### Expected Behavior:

### Suggested Fix:
Leptonical build
 This is not tesseract issue.  This is Tesseract issue .
This is my command line output : 
I'm trying to edit cppan.yml clean cppan cache cmake cache an rebuild but still error
dependencies:
        pvt.cppan.demo.danbloomberg.leptonica: 1.74.2

I'm tested in 1.74.2,1.74.3,1.74.4?
Can you explain why this is not tesseract issue?

PS E:\TesseractOpenCV\Build\tesseract\build64\bin\Release> .\tesseract.exe --tessdata-dir F:/ F:\1.png F:/abc
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made

 it is not teaseract issue:
1. message comes from leptonica.
2. it complains about wrong input.
3. it seems that you did not trace where is problem.


Dňa 14. 11. 2017 7:32 používateľ "hoangtocdo90" <notifications@github.com>
napísal:

This is Tesseract issue .
This is my command line output :
I'm trying to edit cppan.yml clean cppan cache cmake cache an rebuild but
still error
dependencies:
pvt.cppan.demo.danbloomberg.leptonica: 1.74.2

I'm tested in 1.74.2,1.74.3,1.74.4?
Can you explain why this is not tesseract issue?

PS E:\TesseractOpenCV\Build\tesseract\build64\bin\Release> .\tesseract.exe
--tessdata-dir F:/ F:\1.png F:/abc
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica

Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made

—
You are receiving this because you modified the open/close state.

Reply to this email directly, view it on GitHub
<https://github.com/tesseract-ocr/tesseract/issues/1208#issuecomment-344159713>,
or mute the thread
<https://github.com/notifications/unsubscribe-auth/AAjCzG1-KlAL6DLd1mW7aPF4671EyaYwks5s2TPjgaJpZM4QbTyj>
.
 #1223   Please respect instruction for posting issue: use tesseract user forum for asking support.  `char* outText = api->GetUTF8Text();

delete[] outText
`

maybe return text was null   Please use google or other search engine before posting issues.  Please follow instruction for posting issue - use tesseract user forum for asking questions.  please post output of
tesseract -v

Dňa 3. 11. 2017 22:44 používateľ "Mitchell Galloway" <
notifications@github.com> napísal:

> I am attempting to run this:
>
> lapply(myfiles, function(i){
>
>     shell(shQuote(paste0("pdftopng -f 1 -l 10 -r 600 ", i, " ocrbook")))
> mypngs <- list.files(path = dest, pattern = "png", full.names = TRUE)
> lapply(mypngs, function(z){
>     shell(shQuote(paste0("tesseract ", z, " out")))
>     #file.remove(paste0(z))
>     })
> })
>
> However, even though I am feeding it a PNG file, I get the error
>
> Tesseract Open Source OCR Engine v3.05.01 with Leptonica
> Error in pixCreateNoInit: pix_malloc fail for data
> Error in pixCreate: pixd not made
> Error in pixReadStreamPng: pix not made
> Error in pixReadStream: png: no pix returned
> Error in pixRead: pix not read
> Error during processing.
>
> 1: running command 'C:\Windows\system32\cmd.exe /c "tesseract C:\users\gallowmb\desktop/ocrbook-000001.png out"' had status 1
> 2: In shell(shQuote(paste0("tesseract ", z, " out"))) :
>   '"tesseract C:\users\gallowmb\desktop/ocrbook-000001.png out"' execution failed with error code 1
>
> RStudio 1.1.383
> Tesseract 3.05.01
> Win 7 64 bit
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1196>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AAjCzKCQcnxwVWezs041Fzo4XlBWXfzLks5sy4lZgaJpZM4QRtxA>
> .
>
 Can you share ocrbook-000001.png and info how to get/installed tesseract?  Please respect instructions for project issue tracker.  @theraysmith has not updated the repositories with changes to handle all these issues. Hence, you should not expect them to be fixed.  I think Ray was planning to do new training to handle all these cases. But there has been no update from him since then. Based on past patterns, I would guess that he will make some updates to project before year end! Thanks for sharing the traineddata. Please let us know the succeed rate of OCR when using it.

Do you combine it with Arabic traineddata to get correct text plus Arabic numbers using -l Ara+  read_params_file: Can't open makebox

Your tessdata-dir does not have the config file 'majebox'. Please check.

On 27-Oct-2017 2:24 AM, "ErnstTmp" <notifications@github.com> wrote:

> makebox.txt
> <https://github.com/tesseract-ocr/tesseract/files/1420017/makebox.txt>
> Script to make the boxes attached
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1188#issuecomment-339797707>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o5orY7xm0fdt6JF_SloHMe0AKSsLks5swPF3gaJpZM4QIMxl>
> .
>
  ...and it describe clearly there is no issue in tesseract but in your computer setting. Use tesseract forum as described in issue tracker instruction.  Please respect instruction for posting issue! Use tesseract user forum for asking support. This is not tesseract bug....  The latest traineddatas (tessdata_best and Tessdata_fast) do not support legacy tesseract engine, so --oem 0 and --oem 2 are not supported.

However, program should not crash but rather give an error message. Please see
https://github.com/tesseract-ocr/tesseract/wiki/Data-Files#updated-data-files-for-version-400-september-15-2017

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Oct 23, 2017 at 10:21 AM, Tao <notifications@github.com> wrote:

> Thanks for the update. Where can I get the 'latest traineddata' please? I
> got my data from https://github.com/tesseract-ocr/tessdata/
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1181#issuecomment-338547304>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o1A6Ocre9MuS8eUo5CfbBl_Ibfk2ks5svBtUgaJpZM4QCEnk>
> .
>
  Please read instructions given in the wiki page for training for 4.0.

You have to use lstmtraining command with --stop-training to create the new
traineddata.



On 22-Oct-2017 7:09 PM, "ibr123" <notifications@github.com> wrote:

> Hi,
>
> i was using the newest versions of Tesseract to:
> 1- create LSTMFs
> 2- extract the LSTM from official traineddata
> 3- fine tune the LSTM according to the created LSTMFs
> 4- and then use the new traineddata for detection for better results
> i was able to do all these steps and get the final traineddata but when i
> made detection using it i got an error, now the same case happened for
> Arabic and Japanese languages, and both i was able to get fine tuned
> traineddata and both failed in detection and gave the same error.
> the commands i used as described here
> <https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#lstmtraining-command-line>
> and they were:
> *for creating LSTMFs*
> training/tesstrain.sh --fonts_dir ~/.local/share/fonts --lang ara
> --linedata_only --noextract_font_properties --langdata_dir
> /home/ibr/latest_leptonica_4/langdata --tessdata_dir ./tessdata
> --output_dir /home/ibr/latest_leptonica_4/lstmf_ara_lep4
>
> **extracted LSTM from *here*
> <https://github.com/tesseract-ocr/tessdata_best>
>
> *tuned LSTM*
> training/lstmtraining --model_output /home/ubuntu/lep_latest/ara_tune/tune_result/ara_tune
>
> --continue_from /home/ubuntu/lep_latest/ara_tune/extracted/ara.lstm
> --traineddata /home/ubuntu/lep_latest/ara_tune/original_traineddata/ara.traineddata
>
> --train_listfile /home/ubuntu/lep_latest/ara_tune/ara.training_files.txt
> --max_iterations 1200
>
> **then unpacked official traineddata"official traineddata", replaced the
> tuned LSTM and combined everything together again **
>
> *detection command*
> tesseract ara2.png tuned -l ara --tessdata-dir ./tessdata --oem 1
>
> and when i used the new tuned traineddata i got the error:
>
> *index >= 0:Error:Assert failed:in file strngs.cpp, line 270 Segmentation
> fault (core dumped)*
>
> that happened when i tried fine tuning for Arabic and Japanese, twice,
> first time using the version:
> *tesseract 4.00.00dev-690-g1b0379c leptonica-1.74.4*
> second time: *tesseract 4.00.00dev-691-gfb359fc leptonica-1.74.4*
> *keep im mind the same exact steps worked for previous versions of
> tesseract with leptonica 1.74.1*
> Thanks in advance
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1180>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o-zB_-b2Znyj59VRBnw-zEoSI56zks5su0WkgaJpZM4QB86_>
> .
>
 The new format traineddata file has a version string,
unicharcompressor/recorder, and a unicharset which matches with the lstm
model.

If you combine your fine-tune lstm with existing traineddata, the files
will not be in sync. You are getting error because of mismatch of
unicharset with lstm.

Also, your lstmtraining command should use the starter traineddata.

Wiki pages have more details.

On 22-Oct-2017 10:15 PM, "ShreeDevi Kumar" <shreeshrii@gmail.com> wrote:

> Please read instructions given in the wiki page for training for 4.0.
>
> You have to use lstmtraining command with --stop-training to create the
> new traineddata.
>
>
>
> On 22-Oct-2017 7:09 PM, "ibr123" <notifications@github.com> wrote:
>
>> Hi,
>>
>> i was using the newest versions of Tesseract to:
>> 1- create LSTMFs
>> 2- extract the LSTM from official traineddata
>> 3- fine tune the LSTM according to the created LSTMFs
>> 4- and then use the new traineddata for detection for better results
>> i was able to do all these steps and get the final traineddata but when i
>> made detection using it i got an error, now the same case happened for
>> Arabic and Japanese languages, and both i was able to get fine tuned
>> traineddata and both failed in detection and gave the same error.
>> the commands i used as described here
>> <https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#lstmtraining-command-line>
>> and they were:
>> *for creating LSTMFs*
>> training/tesstrain.sh --fonts_dir ~/.local/share/fonts --lang ara
>> --linedata_only --noextract_font_properties --langdata_dir
>> /home/ibr/latest_leptonica_4/langdata --tessdata_dir ./tessdata
>> --output_dir /home/ibr/latest_leptonica_4/lstmf_ara_lep4
>>
>> **extracted LSTM from *here*
>> <https://github.com/tesseract-ocr/tessdata_best>
>>
>> *tuned LSTM*
>> training/lstmtraining --model_output /home/ubuntu/lep_latest/ara_tune/tune_result/ara_tune
>>
>> --continue_from /home/ubuntu/lep_latest/ara_tune/extracted/ara.lstm
>> --traineddata /home/ubuntu/lep_latest/ara_tune/original_traineddata/
>> ara.traineddata
>> --train_listfile /home/ubuntu/lep_latest/ara_tune/ara.training_files.txt
>> --max_iterations 1200
>>
>> **then unpacked official traineddata"official traineddata", replaced the
>> tuned LSTM and combined everything together again **
>>
>> *detection command*
>> tesseract ara2.png tuned -l ara --tessdata-dir ./tessdata --oem 1
>>
>> and when i used the new tuned traineddata i got the error:
>>
>> *index >= 0:Error:Assert failed:in file strngs.cpp, line 270 Segmentation
>> fault (core dumped)*
>>
>> that happened when i tried fine tuning for Arabic and Japanese, twice,
>> first time using the version:
>> *tesseract 4.00.00dev-690-g1b0379c leptonica-1.74.4*
>> second time: *tesseract 4.00.00dev-691-gfb359fc leptonica-1.74.4*
>> *keep im mind the same exact steps worked for previous versions of
>> tesseract with leptonica 1.74.1*
>> Thanks in advance
>>
>> —
>> You are receiving this because you are subscribed to this thread.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/1180>, or mute the
>> thread
>> <https://github.com/notifications/unsubscribe-auth/AE2_o-zB_-b2Znyj59VRBnw-zEoSI56zks5su0WkgaJpZM4QB86_>
>> .
>>
>
 Read https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00

specially
https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#fine-tuning-for--a-few-characters

Command has to be as follows:

training/lstmtraining --model_output /path/to/output [--max_image_MB 6000] \
  --continue_from /path/to/existing/model \
  --traineddata /path/to/traineddata/with/new/unicharset \
  --old_traineddata /path/to/existing/traineddata \
  [--perfect_sample_delay 0] [--debug_interval 0] \
  [--max_iterations 0] [--target_error_rate 0.01] \
  --train_listfile /path/to/list/of/filenames.txt


​Also see
https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#combining-the-output-files

training/lstmtraining --stop_training \
  --continue_from ~/tesstutorial/eng_from_chi/base_checkpoint \
  --traineddata ~/tesstutorial/engtrain/eng/eng.traineddata \
​
 --model_output ~/tesstutorial/eng_from_chi/eng.traineddata​​





ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Oct 23, 2017 at 2:59 PM, ibr123 <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/shreeshrii> sorry, my mistake, i forgot
> to mention the command to create the LSTM from the check point which is:
> *training/lstmtraining --model_output
> /home/ibr/latest_leptonica_4/ara_tune/tuned_lstm/ara.lstm --continue_from
> /home/ibr/latest_leptonica_4/ara_tune/results/ara_checkpoint --traineddata
> /home/ibr/latest_leptonica_4/ara_tune/original_traineddata/ara.traineddata
> --stop_training*
>
> now, summarize everything,
>
>
>
>
>
>
> *i create LSTMFs extract LSTM from "best_traineddata" tune LSTM according
> LSTMFs , in the command " --traineddata best_traineddata" create LSTM from
> checkpoint, in the command " --traineddata best_traineddata" unpack
> "best_traineddata" replace LSTM with the new tuned one combine everything*
>
> If you combine your fine-tune lstm with existing traineddata, the files
> will not be in sync
> means in combination step i have to combine the new LSTM with the
> traineddata that is created when creating LSTMFs?
> i used "best_traineddata" in the command
>
>
>
>
> *training/lstmtraining --model_output
> /home/ubuntu/lep_latest/ara_tune/tune_result/ara_tune --continue_from
> /home/ubuntu/lep_latest/ara_tune/extracted/ara.lstm --traineddata
> /home/ubuntu/lep_latest/ara_tune/original_traineddata/ara.traineddata
> --train_listfile /home/ubuntu/lep_latest/ara_tune/ara.training_files.txt
> --max_iterations 1200*
> because if i pointed the --traineddata to the traineddata that is created
> with LSTMFs (starter traineddata)
> i will get this message:
> **Warning: LSTMTrainer deserialized an LSTMRecognizer!
> Code range changed from 307 to 74!
> Must supply the old traineddata for code conversion!
> Failed to continue from: /home/ibr/latest_leptonica_4/
> ara_tune/extracted/ara.lstm
> **
> so since i got "Must supply the old traineddata" i used the trained data
> from "best_traineddata" the whole time, so what im missing?
> Thanks
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1180#issuecomment-338601210>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o5TsxR-U5rw0yR-XYASqpXqN_3w-ks5svFxxgaJpZM4QB86_>
> .
>
 If your unicharset size is different, you need to provide --old_traineddata
.

failed to write checkpoint usually happens if you have not created the
output directory.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Oct 23, 2017 at 7:44 PM, ibr123 <notifications@github.com> wrote:

> the last two command actually worked and the traineddata i created is
> fine, i changed the first command to:
>
>
>
>
>
> *training/lstmtraining --model_output
> /home/ubuntu/lep_latest/test/tuning_results/jpn --continue_from
> /home/ubuntu/lep_latest/jpn_tune/extracted/jpn.lstm --traineddata
> /home/ubuntu/lep_latest/jpn_tune/jpn_lstmf/jpn/jpn.traineddata
> --old_traineddata
> /home/ubuntu/lep_latest/jpn_tune/original_traineddata/jpn.traineddata
> --train_listfile /home/ubuntu/lep_latest/jpn_tune/jpn.training_files.txt
> --max_iterations 3600*
> but this command was in "Fine Tuning for ± a few characters" section, in
> my case i want only to train the best_traineddata to a new fonts only
> without changing it so i assumed that i needed to go though fine tuning but
> it didn't work, so does this tuning command covers it?
>
> also another question, when i run the above command sometime i get the
> message *checkpoint failed to write checkpoint* when that message shows
> following command fails:
>
>
>
> *training/lstmtraining --stop_training --continue_from
> /home/ubuntu/lep_latest/test/tuning_results/jpn13.689_2618.checkpoint
> --traineddata
> /home/ubuntu/lep_latest/jpn_tune/jpn_lstmf/jpn/jpn.traineddata
> --model_output /home/ubuntu/lep_latest/test/traineddata/jpn.traineddata*
> what causing this message to show?
>
> Thanks
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1180#issuecomment-338672679>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o4JlUK23O18xfdfLdxdz632i8SzPks5svJ9IgaJpZM4QB86_>
> .
>
  Did you check the output of configure?  Please follow instruction of issue tracker - we do not support 3rd party sw (python)  Version: Tesseract 4.0alpha from github
Platform: Windows10/WSL Ubuntu 14.04

```
Rendered page 338 to file /tmp/tmp.Bja2jDWX7C/san/san.Nakula.exp0.tif
Null box at index 0
Error: Call PrepareToWrite before WriteTesseractBoxFile!!
```

The tif files are being created by text2image but the box files have size zero. It seems to be dependent on the training_text and works with other text files.

  Please read & follow instruction for posting issue.  Easiest way for you to get this is to run tesstrain.sh for English with a short training text and one font. Then look in your tmp folder for the box/tif files. Here are sample files for English ...

[eng-box-tif.zip](https://github.com/tesseract-ocr/tesseract/files/1404580/eng-box-tif.zip)
 The following works for me.

img_files=${img_files}' '$(ls shritatvanidhi-0056*.tif)
    for img_file in ${img_files}; do
       echo ${img_file}
       tesseract ${img_file} ${img_file%.*}  --psm 6 --oem 1 -l hin
--tessdata-dir /mnt/c/Users/User/shree/tessdata makebox
    done

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Oct 23, 2017 at 1:27 AM, ErnstTmp <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/shreeshrii> thank you very much for your
> files!!!! I used tesstrain.sh, but did not look into /tmp. Shame on me!
> I could not get tesseract to create box files. I used
>
> tesseract pol.ocrb.exp$i.tif pol.ocrb.exp$i batch.nochop makebox
>
> as described, but it created a file called batch.nochop.box, but not the
> box file I expected (an old style box file would be OK)
>
> Thanks,
> Ernst
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1174#issuecomment-338504508>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o3JotONc7aH5oBARnt3DE4mEy82Aks5su54PgaJpZM4QASxL>
> .
>
  The old format box files will not work for LSTM training. AFAIK, currently training is only supported with the synthetic box/tiff pairs generated via tesstrain.sh.

See https://github.com/tesseract-ocr/tesseract/issues/768 for more details.

 I copy them to my langdata/language directory and then use a modified
tesstrain.sh to copy them to the tmp training directory.


tesstrain.sh changes

```
mkdir -p ${TRAINING_DIR}
tlog "\n=== Starting training for language '${LANG_CODE}'"

cp  ../langdata/${LANG_CODE}/*.box ${TRAINING_DIR}
cp  ../langdata/${LANG_CODE}/*.tif ${TRAINING_DIR}

ls -l  ${TRAINING_DIR}
source "$(dirname $0)/language-specific.sh"
```

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Oct 18, 2017 at 2:53 PM, 694376965 <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/shreeshrii>, I have change the format box
> files according to the requirements of tesseract 4.0 , namely I add a TAB
> at end of line and spaces to demarcate words for the box files.
>
> could you tell me how to use new format box/tiff pairs to generate *.lstmf
> files? Thanks!
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1172#issuecomment-337521195>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o5yzL6sQNcMR-xJeNDiL1Gq0R2naks5stcOQgaJpZM4P9XT0>
> .
>
 Please check the syntax of your command. 

Training text is in langdata dir.

Rather than modifying tesstrain.sh too much, you could keep a small dummy
training text in one font to use along with your box tiff pairs.

I have mostly tested training with synthetic images, using precreated box
tiff pairs just as sample.

 training/tesstrain.sh \
--fonts_dir /mnt/c/Windows/Fonts \
 --lang san \
 --noextract_font_properties  --linedata_only \
 --exposures "0" \
 --langdata_dir ../langdata \
 --tessdata_dir ../tessdata \
 --fontlist \
    "Siddhanta" \
  --output_dir ../tesstutorial/san

You have to make sure that all directories reflect your setup.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Oct 18, 2017 at 7:36 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
wrote:

> Please check the syntax of your command. Langdata is referred to via
> script dir.
>
> Training text is in langdata dir.
>
> Rather than modifying tesstrain.sh too much, you could keep a small dummy
> training text in one font to use along with your box tiff pairs.
>
> I have mostly tested training with synthetic images, using precreated box
> tiff pairs just as sample.
>
> On 18-Oct-2017 5:12 PM, "694376965" <notifications@github.com> wrote:
>
>> @Shreeshrii <https://github.com/shreeshrii> I changed the tesstrain.sh
>> file and the command could copy the box/tiff pairs to the tmp training
>> directory.
>> but there was another error as following:
>>
>> $ training/tesstrain.sh --lang eng --linedata_only --langdata_dir
>> ../langdata --tessdata_dir ./tessdata --output_dir ../result
>>
>> === Starting training for language 'eng'
>> total 6068
>> -rwxrw-r-- 1 penny penny 66188 Oct 18 19:24 eng.num.exp0.box
>> -rwxrw-r-- 1 penny penny 6136385 Oct 18 19:24 eng.num.exp0.tif
>> -rw-rw-r-- 1 penny penny 42 Oct 18 19:24 tesstrain.log
>> [Wed Oct 18 19:24:13 CST 2017] /usr/local/bin/text2image
>> --fonts_dir=/usr/share/fonts/ --font=Arial Bold
>> --outputbase=/tmp/font_tmp.fGYz2L7fuF/sample_text.txt
>> --text=/tmp/font_tmp.fGYz2L7fuF/sample_text.txt
>> --fontconfig_tmpdir=/tmp/font_tmp.fGYz2L7fuF
>> Could not find font named Arial Bold.
>> Pango suggested font FreeSerif Bold.
>> Please correct --font arg.
>>
>> === Phase I: Generating training images ===
>> ERROR: Could not find training text file ../langdata/eng/eng.training_t
>> ext
>>
>> it couldn't find 'eng.training_text' file, do you know what the
>> 'eng.training_text' file is ?
>>
>> Additionally, the command 'text2image' is used to generate tiff images
>> according to text and fonts, but we have already had box/tiff pairs, so why
>> it excute the command 'text2image' again ?
>> Should I change other script files to resolve these problems?
>>
>> I'm looking forward to your reply! Thanks a lot!
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/1172#issuecomment-337563901>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AE2_owYariVrUfRKKivM0kFTpiBC9Ypeks5steRBgaJpZM4P9XT0>
>> .
>>
>
 Please look at your tif files in a viewer. Why do they have 0 dpi?

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Oct 23, 2017 at 11:47 AM, 694376965 <notifications@github.com>
wrote:

> @Shreeshrii <https://github.com/shreeshrii> but now there is a new
> problem like this:
>
> $ tesseract eng.num.exp1.tif eng.num.exp1 lstm.train
> Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
> Page 1
> Warning. Invalid resolution 0 dpi. Using 70 instead.
> Estimating resolution as 395
> Empty page!!
> Estimating resolution as 395
> Empty page!!
>
> there are several images will generate this error, do you know why it
> appears "Empty page!!"? Have you ever seen this kind of mistake?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1172#issuecomment-338557979>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_ox27vOl9R1j2mq_qQFP1eYELKdzJks5svC-IgaJpZM4P9XT0>
> .
>
 Great! Thanks for informing what worked. Please look at the config files named
makebox
nobatch
etc

in the
tessdata/configs
tessdata/tessconfigs directory.

They will show what config variables are being set for each.

I may have used the nobatch option with tesseract 3.02 or so - do not
remember details.


ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Oct 24, 2017 at 4:26 PM, 694376965 <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/shreeshrii>, You're welcome! the command
> is also right without "nobatch", just as the following:
>
> $ tesseract eng.num.exp2.tif eng.num.exp2 -psm 7 lstm.train
> Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
> Page 1
> Warning. Invalid resolution 0 dpi. Using 70 instead.
>
> Dou you know the function of "nobatch" ? Have you used it in tesseract
> command ?
> Looking forward to your reply! Thanks!
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1172#issuecomment-338952527>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o4aAzjGxbIbaIbIXk4vRtCkQIH8dks5svcJBgaJpZM4P9XT0>
> .
>
 @Shreeshrii At [Making Box Files 4.0](https://github.com/tesseract-ocr/tesseract/wiki/Making-Box-Files---4.0) there's the following :
<pre>
The required format for LSTM 4.0alpha is still the tiff/box file pair, except that the boxes only need to cover a textline instead of individual characters.
 'Newline' boxes with tab as the character must be inserted between textlines to indicate the end-of-line.
</pre>

what's the meaning of the last line? Does it mean that we should add a 'tab' after each textline? 

 If you use tesstrain.sh, box/tiff pairs are created in correct format.

The textline based box files (WordStr ...) are NOT supported.

If you are modifying old 3.ox format box files, you have to add space after each word and tab after each textline. 

However, please note that the box files generated using tesseract with `makebox` need to be manually edited for accuracy (since the boxes are filled with OCRed text). Also, I found that for Devanagari (and probably for other complex scripts), the box generation may not match what is generated by `text2image`.

You can do a simple test. Create a box/tiff pair using 'text2image'. Then create a box file for that same tif using tesseract with makebox. Compare the two box files. @Shreeshrii Could you introduce the role of each file under langdata? 
<pre>
[root@localhost langdata]# ls chi_sim
chi_sim.config   chi_sim.punc           chi_sim.training_text.bigram_freqs   chi_sim.unicharambigs  desired_characters
chi_sim.numbers  chi_sim.training_text  chi_sim.training_text.unigram_freqs  chi_sim.wordlist       forbidden_characters
</pre>
I found that the ```.unigram_freqs``` and ```.bigram_freqs``` files seems not suit me very well. Please see https://github.com/tesseract-ocr/tesseract/wiki/Training-Tesseract-%E2%80%93-tesstrain.sh

My guess is that `.unigram_freqs`,  `.bigram_freqs`, `desired_characters` and `forbidden_characters` are used at Google for building a representative training_text for doing training from scratch. 

They are not used directly in the training process documented publicly by Ray. Also see https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#combining-the-output-files

> NOTE Tesseract 4.00 will now run happily with a traineddata file that contains just lang.lstm, lang.lstm-unicharset and lang.lstm-recoder. The lstm-*-dawgs are optional, and none of the other components are required or used with OEM_LSTM_ONLY as the OCR engine mode. No bigrams, unichar ambigs or any of the other components are needed or even have any effect if present. The only other component that does anything is the lang.config, which can affect layout analysis, and sub-languages. At [Langdata files](https://github.com/tesseract-ocr/tesseract/wiki/Training-Tesseract-%E2%80%93-tesstrain.sh), It has the following:

**training_text.unigram_freqs**
<pre>
This is a text file with a list of unigrams (characters) and the frequency with which they appear next to each other in the training_text, one unigram per line.
</pre>

It seems that not the real frequency in training_text and I just confused about that. I have download the Chinese corpora from a National institution and I think it has a Higher precision. so I want to generate my own langdata of chi_sim.  But here the training_text seems to have some relationships with the other files(```.unigram_freqs```, ```.bigram_freqs```)

 You should search for past issues and in forum first.

See https://github.com/tesseract-ocr/tesseract/issues/1114 Sorry, I don't have any suggestions to try.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Nov 14, 2017 at 5:25 PM, zhaiyongding <notifications@github.com>
wrote:

> @Shreeshrii <https://github.com/shreeshrii>
> --sequential_training true
> then i got
> First document cannot be empty!!
> num_pages_per_doc_ > 0:Error:Assert failed:in file imagedata.cpp, line 658
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1172#issuecomment-344236472>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oxgq8x4iPB6FirpM338V5EzTMDsqks5s2X-rgaJpZM4P9XT0>
> .
>
  Use traineddata files from tessdata_fast repository  for speed in
recognition.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Oct 17, 2017 at 9:00 PM, Amit D. <notifications@github.com> wrote:

> Also, do you use the newest traineddata?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1171#issuecomment-337266737>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o_BlcoI0mWe0dClpPN5puFlZejciks5stMgKgaJpZM4P8Rw1>
> .
>
 Please see https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#lstmtraining-command-line

If you have the data for your finetuning, you can create the 'faster' integer type of traineddata by using 
`convert_to_int` with `stop_training`. For training, you have to start with tessdata_best models. You can create
your traineddata in the integer faster format.

You will have to test with your language and data.

On 18-Oct-2017 7:28 PM, "ibr123" <notifications@github.com> wrote:

> if i wanted to fine tune using the tool
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1171#issuecomment-337600169>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oyx5CIz_10_spwJn3BbM-AvfinFUks5stgQXgaJpZM4P8Rw1>
> .
>
 You can give it a try. There have been significant changes, that break
compatibility between commits since this is development code in alpha stage.
If you get an error, you will have to recreate the lstmf files.

On 18-Oct-2017 7:34 PM, "ibr123" <notifications@github.com> wrote:

> if i wanted to fine tune using the tool "lstmtraining" while i'm using the
> latest Tesseract: (4.00.00dev-690-g1b0379c) can i use .lstmf files (which
> are generated by tesstrain.sh)file that are created by older Tesseract
> version, such as (4.00.00dev-549-g2b854e3) ?
> meaning are lstmf files compatible between tesseract versions?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1171#issuecomment-337601903>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o6UXEXXc9MEveLBjrtgdNMWPYbLNks5stgVbgaJpZM4P8Rw1>
> .
>
 I do not know about the specific commit numbers you refer to. You may want
to check the github history of commits.

On 18-Oct-2017 7:39 PM, "ShreeDevi Kumar" <shreeshrii@gmail.com> wrote:

> You can give it a try. There have been significant changes, that break
> compatibility between commits since this is development code in alpha stage.
> If you get an error, you will have to recreate the lstmf files.
>
> On 18-Oct-2017 7:34 PM, "ibr123" <notifications@github.com> wrote:
>
>> if i wanted to fine tune using the tool "lstmtraining" while i'm using
>> the latest Tesseract: (4.00.00dev-690-g1b0379c) can i use .lstmf files
>> (which are generated by tesstrain.sh)file that are created by older
>> Tesseract version, such as (4.00.00dev-549-g2b854e3) ?
>> meaning are lstmf files compatible between tesseract versions?
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/1171#issuecomment-337601903>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AE2_o6UXEXXc9MEveLBjrtgdNMWPYbLNks5stgVbgaJpZM4P8Rw1>
>> .
>>
>
  
### Environment

* **Tesseract Version**: tesseract 4.00.00alpha
* **Commit Number**: 2cc531e
* **Platform**: Linux localhost.localdomain 3.10.0-514.el7.x86_64 #1 SMP Tue Nov 22 16:42:41 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

### Current Behavior:
I use the following command to train:
<pre>
[root@localhost tesseract]# training/lstmtraining --debug_interval 100 \
>   --traineddata ../tesstutorial/chi_simtrain/chi_sim/chi_sim.traineddata \
>   --net_spec '[1,48,0,1 Ct3,3,16 Mp3,3 Lfys64 Lfx96 Lrx96 Lfx512 O1c111]' \
>   --model_output ../tesstutorial/chi_simoutput/base --learning_rate 20e-4 \
>   --train_listfile ../tesstutorial/chi_simtrain/chi_sim.training_files.txt \
>   --eval_listfile ../tesstutorial/chi_simeval/chi_sim.training_files.txt \
>   --max_iterations 10000 &>../tesstutorial/chi_simoutput/basetrain.log
Segmentation fault (core dumped)
</pre>
But it caught segmentation fault.

when training I use the following command to see the log:
<pre>
# tail -f ../tesstutorial/chi_simoutput/basetrain.log
....
Iteration 9998: ALIGNED TRUTH : 恽寿榕印刷width打垮年推荐评论Microsoft 邵武的月经沉,特性产权 巫山
Iteration 9998: BEST OCR TEXT : 
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.STFangsong.exp0.lstmf page 188 :
Mean rms=4.264%, delta=50.362%, train=99.57%(99.92%), skip ratio=0%
Iteration 9999: ALIGNED TRUTH : 》杂耍啤酒花href镁天竺葵垮塌帐篷 藕腱鞘炎 岷 关专业祭副4About 下挫
Iteration 9999: BEST OCR TEXT :  
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.STKaiti.exp0.lstmf page 91 :
Mean rms=4.264%, delta=50.364%, train=99.569%(99.92%), skip ratio=0%
2 Percent improvement time=10000, best error was 100 @ 0
At iteration 10000/10000/10000, Mean rms=4.264%, delta=50.364%, char train=99.569%, word train=99.92%, skip ratio=0%,  New best char error = 99.569 wrote checkpoint.

Finished! Error rate = 99.569
num_docs > 0:Error:Assert failed:in file imagedata.cpp, line 651
Exception in thread "main" java.lang.NullPointerException
        at com.google.scrollview.ui.SVWindow.drawImage(SVWindow.java:336)
        at com.google.scrollview.ScrollView.processInput(ScrollView.java:321)
        at com.google.scrollview.ScrollView.IOLoop(ScrollView.java:120)
        at com.google.scrollview.ScrollView.main(ScrollView.java:398)
</pre>

From the basetrain.log, It seems that the training iteration has reached 10000 and has finished the training. And from tesseract-master/training/lstmtraining.cpp:
<pre>
int main(int argc, char **argv) {
....

do {
    // Train a few.
    int iteration = trainer.training_iteration();
    for (int target_iteration = iteration + kNumPagesPerBatch;
         iteration &lt; target_iteration;
         iteration = trainer.training_iteration()) {
      trainer.TrainOnLine(&trainer, false);
    }
    STRING log_str;
    trainer.MaintainCheckpoints(tester_callback, &log_str);
    tprintf("%s\n", log_str.string());
  } while (trainer.best_error_rate() &gt; FLAGS_target_error_rate &&
           (trainer.training_iteration() &lt; FLAGS_max_iterations ||
            FLAGS_max_iterations == 0));
  delete tester_callback;
  tprintf("Finished! Error rate = %g\n", trainer.best_error_rate());
  return 0;
}
</pre>
It seems that it has already finished. So which process are executing the lstmtraining.cpp:
<pre>
const ImageData* DocumentCache::GetPageSequential(int serial) {
  int num_docs = documents_.size();
  ASSERT_HOST(num_docs > 0);

....
}
</pre>
and here the assert caused the segmentation fault? 

Here I checked the output dir:
<pre>
[root@localhost tesseract]# ls ../tesstutorial/chi_simoutput/ 
base_checkpoint  basetrain.log
</pre>
It has generated the base_checkpoint. So are there any following steps that the training process should do? And It seems that the segmentation fault doesn't effect much.


### Expected Behavior:

### Suggested Fix:
 Are you trying to train from scratch?

10000 iterations are too low for that.

You have an error rate of 99%.

Did you try replace a layer for training?

On 12-Oct-2017 1:59 PM, "ivanzz1001" <notifications@github.com> wrote:

> Environment
>
>    - *Tesseract Version*: tesseract 4.00.00alpha
>    - *Commit Number*: 2cc531e
>    <https://github.com/tesseract-ocr/tesseract/commit/2cc531e6bf0288fc8a9ad1c123a252395f00bf56>
>    - *Platform*: Linux localhost.localdomain 3.10.0-514.el7.x86_64 #1
>    <https://github.com/tesseract-ocr/tesseract/issues/1> SMP Tue Nov 22
>    16:42:41 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
>
> Current Behavior:
>
> I use the following command to train:
>
> [root@localhost tesseract]# training/lstmtraining --debug_interval 100 \
> >   --traineddata ../tesstutorial/chi_simtrain/chi_sim/chi_sim.traineddata \
> >   --net_spec '[1,48,0,1 Ct3,3,16 Mp3,3 Lfys64 Lfx96 Lrx96 Lfx512 O1c111]' \
> >   --model_output ../tesstutorial/chi_simoutput/base --learning_rate 20e-4 \
> >   --train_listfile ../tesstutorial/chi_simtrain/chi_sim.training_files.txt \
> >   --eval_listfile ../tesstutorial/chi_simeval/chi_sim.training_files.txt \
> >   --max_iterations 10000 &>../tesstutorial/chi_simoutput/basetrain.log
> Segmentation fault (core dumped)
>
> But it caught segmentation fault.
>
> when training I use the following command to see the log:
>
> # tail -f ../tesstutorial/chi_simoutput/basetrain.log
> ....
> Iteration 9998: ALIGNED TRUTH : 恽寿榕印刷width打垮年推荐评论Microsoft 邵武的月经沉,特性产权 巫山
> Iteration 9998: BEST OCR TEXT :
> File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.STFangsong.exp0.lstmf page 188 :
> Mean rms=4.264%, delta=50.362%, train=99.57%(99.92%), skip ratio=0%
> Iteration 9999: ALIGNED TRUTH : 》杂耍啤酒花href镁天竺葵垮塌帐篷 藕腱鞘炎 岷 关专业祭副4About 下挫
> Iteration 9999: BEST OCR TEXT :
> File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.STKaiti.exp0.lstmf page 91 :
> Mean rms=4.264%, delta=50.364%, train=99.569%(99.92%), skip ratio=0%
> 2 Percent improvement time=10000, best error was 100 @ 0
> At iteration 10000/10000/10000, Mean rms=4.264%, delta=50.364%, char train=99.569%, word train=99.92%, skip ratio=0%,  New best char error = 99.569 wrote checkpoint.
>
> Finished! Error rate = 99.569
> num_docs > 0:Error:Assert failed:in file imagedata.cpp, line 651
> Exception in thread "main" java.lang.NullPointerException
>         at com.google.scrollview.ui.SVWindow.drawImage(SVWindow.java:336)
>         at com.google.scrollview.ScrollView.processInput(ScrollView.java:321)
>         at com.google.scrollview.ScrollView.IOLoop(ScrollView.java:120)
>         at com.google.scrollview.ScrollView.main(ScrollView.java:398)
>
> From the basetrain.log, It seems that the training iteration has reached
> 10000 and has finished the training. And from tesseract-master/training/
> lstmtraining.cpp:
>
> int main(int argc, char **argv) {
> ....
>
> do {
>     // Train a few.
>     int iteration = trainer.training_iteration();
>     for (int target_iteration = iteration + kNumPagesPerBatch;
>          iteration < target_iteration;
>          iteration = trainer.training_iteration()) {
>       trainer.TrainOnLine(&trainer, false);
>     }
>     STRING log_str;
>     trainer.MaintainCheckpoints(tester_callback, &log_str);
>     tprintf("%s\n", log_str.string());
>   } while (trainer.best_error_rate() > FLAGS_target_error_rate &&
>            (trainer.training_iteration() < FLAGS_max_iterations ||
>             FLAGS_max_iterations == 0));
>   delete tester_callback;
>   tprintf("Finished! Error rate = %g\n", trainer.best_error_rate());
>   return 0;
> }
>
> It seems that it has already finished. So which process are executing the
> lstmtraining.cpp:
>
> const ImageData* DocumentCache::GetPageSequential(int serial) {
>   int num_docs = documents_.size();
>   ASSERT_HOST(num_docs > 0);
>
> ....
> }
>
> and here the assert caused the segmentation fault?
>
> Here I checked the output dir:
>
> [root@localhost tesseract]# ls ../tesstutorial/chi_simoutput/
> base_checkpoint  basetrain.log
>
> It has generated the base_checkpoint. So are there any following steps
> that the training process should do? And It seems that the segmentation
> fault doesn't effect much.
> Expected Behavior: Suggested Fix:
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1168>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o_fNFVynM6oe5Jg1qeCp6QmnCQKzks5src3igaJpZM4P2pPR>
> .
>
 Yes, I am training from scratch. But I don't know why error rate is 99% You need to train for days and many iterations, with very large training
texts to train from scratch.

However, the crash should not happen.

On 12-Oct-2017 2:22 PM, "ivanzz1001" <notifications@github.com> wrote:

> Yes, I am training from scratch. But I don't know why error rate is 99%
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1168#issuecomment-336064558>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_owSnbXLovzbicpRV9zCuR8myDbYDks5srdNdgaJpZM4P2pPR>
> .
>
 @Shreeshrii The example give the iteration to be 5000, here I set it to 10000? Is it too small? Have you use the tesseract4.0alpha to train anything? you can set the  "--max_iteration" to a very small value and check whether it causes the segmentation fault.

And I check the my traineddata, It  really has a very low correct rate @Shreeshrii  And In the basetrain.log,  it prints many "ALIGNED TRUTH"
<pre>
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.Arial_Unicode_MS_Bold.exp0.lstmf page 735 :
Mean rms=4.291%, delta=50.688%, train=99.996%(100%), skip ratio=0%
Iteration 5251: ALIGNED TRUTH : 尧 地区瑶族取暖调节软件 日问题遐想二陌77 1997及学会呵呵心态 85 for 的
Iteration 5251: BEST OCR TEXT :  
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.Arial_Unicode_MS.exp0.lstmf page 587 :
Mean rms=4.29%, delta=50.671%, train=99.995%(100%), skip ratio=0%
Iteration 5252: ALIGNED TRUTH : 鉴定关闭年激烈法规制药中轶读 五芍广场 皿 投资Qzone 霸62791813访问胫
Iteration 5252: BEST OCR TEXT : 
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.AR_PL_UKai_CN.exp0.lstmf page 9 :
Mean rms=4.29%, delta=50.665%, train=99.995%(100%), skip ratio=0%
Iteration 5253: ALIGNED TRUTH : 基金凋设 . 售后他Gzip 陈镒康 网站这里 1996 崖违规相信咕咚慈善日本
Iteration 5253: BEST OCR TEXT : 
</pre>

And in the [training tutorial -- error msg](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#error-messages-from-training), It seems that it's a problem If you try training with debug level -1 and see the output on console
rather than sending to log file, you will see that for each line of
training text the ocred output and aligned truth will be displayed.

On 12-Oct-2017 3:04 PM, "ivanzz1001" <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/shreeshrii> And In the basetrain.log, it
> prints many "ALIGNED TRUTH"
>
> File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.Arial_Unicode_MS_Bold.exp0.lstmf page 735 :
> Mean rms=4.291%, delta=50.688%, train=99.996%(100%), skip ratio=0%
> Iteration 5251: ALIGNED TRUTH : 尧 地区瑶族取暖调节软件 日问题遐想二陌77 1997及学会呵呵心态 85 for 的
> Iteration 5251: BEST OCR TEXT :
> File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.Arial_Unicode_MS.exp0.lstmf page 587 :
> Mean rms=4.29%, delta=50.671%, train=99.995%(100%), skip ratio=0%
> Iteration 5252: ALIGNED TRUTH : 鉴定关闭年激烈法规制药中轶读 五芍广场 皿 投资Qzone 霸62791813访问胫
> Iteration 5252: BEST OCR TEXT :
> File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.AR_PL_UKai_CN.exp0.lstmf page 9 :
> Mean rms=4.29%, delta=50.665%, train=99.995%(100%), skip ratio=0%
> Iteration 5253: ALIGNED TRUTH : 基金凋设 . 售后他Gzip 陈镒康 网站这里 1996 崖违规相信咕咚慈善日本
> Iteration 5253: BEST OCR TEXT :
>
> And in the training tutorial -- error msg
> <https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#error-messages-from-training>,
> It seems that it's a problem
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1168#issuecomment-336075160>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o7LVJX9aCe_9vsMVuj9cex-G_E6hks5srd0RgaJpZM4P2pPR>
> .
>
 why the "BEST OCR TEXT " is empty? I have modified the langdata/chi_sim/chi_sim.training_text , I don't know whether this is the reason? And "--max_iteration" set to 10000 is too small?

And I use the "--debug_level -1", It still has the following(here for test I set max_iteration to 100):
<pre>
[root@localhost tesseract]# training/lstmtraining --debug_interval 100 \
>   --traineddata ../tesstutorial/chi_simtrain/chi_sim/chi_sim.traineddata \
>   --net_spec '[1,48,0,1 Ct3,3,16 Mp3,3 Lfys64 Lfx96 Lrx96 Lfx512 O1c111]' \
>   --model_output ../tesstutorial/chi_simoutput/base --learning_rate 20e-4 \
>   --train_listfile ../tesstutorial/chi_simtrain/chi_sim.training_files.txt \
>   --eval_listfile ../tesstutorial/chi_simeval/chi_sim.training_files.txt \
>   --max_iterations 100 \
>   --debug_level -1

....
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.NSimSun.exp0.lstmf page 157 :
Mean rms=4.377%, delta=51.759%, train=100.474%(100%), skip ratio=0%
Iteration 196: ALIGNED TRUTH : 提供) 月份追究 发射特性16 中标图片皇甫男孩责任 桂纶镁业环他《迅猛
Iteration 196: BEST OCR TEXT : 
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.SimHei.exp0.lstmf page 841 :
Mean rms=4.378%, delta=51.788%, train=100.471%(100%), skip ratio=0%
Iteration 197: ALIGNED TRUTH : 社会号码 价瀑布 佣金餐厅 最12正在24地play 32 市短name/ , 天极首席美国2005
Iteration 197: BEST OCR TEXT : 
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.SimSun.exp0.lstmf page 159 :
Mean rms=4.377%, delta=51.732%, train=100.469%(100%), skip ratio=0%
Iteration 198: ALIGNED TRUTH : 提取、 章常规侮聊天觊 洞府生姜限 乳腺事 方11蕃时间索尼]菌文史蠹
Iteration 198: BEST OCR TEXT : 
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.STFangsong.exp0.lstmf page 119 :
Mean rms=4.378%, delta=51.763%, train=100.467%(100%), skip ratio=0%
Iteration 199: ALIGNED TRUTH : 通告 5.5烤漆学院罗技烧烤 ;.追溯评测 COM 颐达的炫耀宗旨睛逐渐图书市场
Iteration 199: BEST OCR TEXT : 
File /tmp/tmp.79zY0ByWtx/chi_sim/chi_sim.STKaiti.exp0.lstmf page 334 :
Mean rms=4.379%, delta=51.785%, train=100.464%(100%), skip ratio=0%
At iteration 200/200/200, Mean rms=4.379%, delta=51.785%, char train=100.464%, word train=100%, skip ratio=0%,  New worst char error = 100.464 wrote checkpoint.

Finished! Error rate = 100
</pre> @Shreeshrii  Hi, I use the "training/tesstrain.sh" to generate the training data and eval data; Should I use the following command to generate lstm-recoder([Creating Starter Traineddata](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#creating-starter-traineddata))?
<pre>
# training/combine_lang_model --input_unicharset ../tesstutorial/chi_simtrain/chi_sim/chi_sim.unicharset \
 --script_dir ../langdata \
 --words ../langdata/chi_sim/chi_sim.wordlist \
 --numbers ../langdata/chi_sim/chi_sim.numbers \
 --puncs ../langdata/chi_sim/chi_sim.punc \
 --output_dir ../tesstutorial/chi_simtrain \
 --lang chi_sim \
 --version_str "4.0.0alpha chi_sim"
</pre>
I greped the "combine_lang_model" and found it was called by "tesstrain_utils.sh", and "tesstrain_utils.sh"  is called by "training/tesstrain.sh", so I had skipped the step。Here I checked "ALIGNED TRUTH" problem, I think this may be the reason. And If It needs this step,  should I generate it for both training data and eval data?   When you start training from scratch, your error rate will be 100% and best
ocr text will be empty. 

For training from scratch Ray is using 400,000+ lines of text and probably
millions of iterations.

I would suggest you try to replace the top layer.

ShreeDevi
 @Shreeshrii I retried the training:
<pre>
training/lstmtraining --debug_interval 100 \
>   --traineddata ../tesstutorial/chi_simtrain/chi_sim/chi_sim.traineddata \
>   --net_spec '[1,48,0,1 Ct3,3,16 Mp3,3 Lfys64 Lfx96 Lrx96 Lfx512 O1c111]' \
>   --model_output ../tesstutorial/chi_simoutput/base --learning_rate 20e-4 \
>   --train_listfile ../tesstutorial/chi_simtrain/chi_sim.training_files.txt \
>   --eval_listfile ../tesstutorial/chi_simeval/chi_sim.training_files.txt \
>   --max_iterations 10000 &>../tesstutorial/chi_simoutput/basetrain.log
</pre>
But It cause :
<pre>
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
</pre>
I think it is because the capacity of my vmware-centos's disk  is not enough, so I want to do the training work on a special server, but I found that the command can't be executed on remote. It must first login the centos , then open the terminal and thus you can execute the above command. If execute on remote, it may cause "broken pipe" error and quickly quit (the training process may need to communicate with other windows, eg CTC Output window) . How do I solve the problem?  
 Sorry, I do not know enough this to comment. @stweil @amitdo might be able to guide you. @Shreeshrii sorry, maybe I haven't described it very clear. This is the log:
<pre>
[root@localhost tesseract]# cat ../tesstutorial/chi_simoutput/basetrain.log 
Warning: given outputs 111 not equal to unicharset of 229.
Num outputs,weights in Series:
  1,48,0,1:1, 0
Num outputs,weights in Series:
  C3,3:9, 0
  Ft16:16, 160
Total weights = 160
  [C3,3Ft16]:16, 160
  Mp3,3:16, 0
  Lfys64:64, 20736
  Lfx96:96, 61824
  Lrx96:96, 74112
  Lfx512:512, 1247232
  Fc229:229, 117477
Total weights = 1521541
Built network:[1,48,0,1[C3,3Ft16]Mp3,3Lfys64Lfx96Lrx96Lfx512Fc229] from request [1,48,0,1 Ct3,3,16 Mp3,3 Lfys64 Lfx96 Lrx96 Lfx512 O1c111]
Training parameters:
  Debug interval = 100, weights = 0.1, learning rate = 0.002, momentum=0.5
null char=228
Loaded 2153/2153 pages (1-2153) of document ../tesstutorial/chi_simtrain/chi_sim.Arial_Unicode_MS_Bold.exp0.lstmf
Loaded 2152/2152 pages (1-2152) of document ../tesstutorial/chi_simtrain/chi_sim.AR_PL_UKai_CN.exp0.lstmf
Loaded 2152/2152 pages (1-2152) of document ../tesstutorial/chi_simtrain/chi_sim.Arial_Unicode_MS.exp0.lstmf
Loaded 2152/2152 pages (1-2152) of document ../tesstutorial/chi_simtrain/chi_sim.AR_PL_UKai_HK.exp0.lstmf
Loaded 2152/2152 pages (1-2152) of document ../tesstutorial/chi_simeval/chi_sim.Arial_Unicode_MS.exp0.lstmf
Loaded 2153/2153 pages (1-2153) of document ../tesstutorial/chi_simtrain/chi_sim.AR_PL_UMing_TW_MBE_Semi-Light.exp0.lstmf
Loaded 2152/2152 pages (1-2152) of document ../tesstutorial/chi_simtrain/chi_sim.AR_PL_UKai_TW.exp0.lstmf
Loaded 2152/2152 pages (1-2152) of document ../tesstutorial/chi_simtrain/chi_sim.AR_PL_UKai_TW_MBE.exp0.lstmf
Loaded 2153/2153 pages (1-2153) of document ../tesstutorial/chi_simtrain/chi_sim.AR_PL_UMing_CN_Semi-Light.exp0.lstmf
Loaded 2153/2153 pages (1-2153) of document ../tesstutorial/chi_simtrain/chi_sim.AR_PL_UMing_HK_Semi-Light.exp0.lstmf
Loaded 2152/2152 pages (1-2152) of document ../tesstutorial/chi_simeval/chi_sim.AR_PL_UKai_CN.exp0.lstmf
Starting sh -c "trap 'kill %1' 0 1 2 ; java -Xms1024m -Xmx2048m -jar /root/tesseract-src/tesseract/java/ScrollView.jar & wait"
Socket started on port 8461
Created window Convolve of size 1511, 580
Client connected
Created window ConvNL of size 1310, 848
Exception in thread "main" java.awt.HeadlessException: 
No X11 DISPLAY variable was set, but this program performed an operation which requires it.
        at java.awt.GraphicsEnvironment.checkHeadless(GraphicsEnvironment.java:204)
        at java.awt.Window.<init>(Window.java:536)
        at java.awt.Frame.<init>(Frame.java:420)
        at javax.swing.JFrame.<init>(JFrame.java:233)
        at com.google.scrollview.ui.SVWindow.<init>(SVWindow.java:204)
        at com.google.scrollview.ScrollView.processInput(ScrollView.java:340)
        at com.google.scrollview.ScrollView.IOLoop(ScrollView.java:120)
        at com.google.scrollview.ScrollView.main(ScrollView.java:398)
sh: line 1: kill: %1: no such job
Created window Lfys64 of size 530, 2000
</pre>
It is because when you execute the command on remote, it can't open the related window. I do not use scrollview. I either use debug level -1 or 0.

I do not know much about Linux or C++ or tesseract. I test tesseract for
OCR of Indian languages, mainly devanagari for sanskrit.

So, I can only suggest options if it is something I have encountered while
training/testing.

On 20-Oct-2017 8:50 AM, "ivanzz1001" <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/shreeshrii> sorry, maybe I haven't
> described it very clear. This is the log:
>
> Starting sh -c "trap 'kill %1' 0 1 2 ; java -Xms1024m -Xmx2048m -jar /root/tesseract-src/tesseract/java/ScrollView.jar & wait"
> Socket started on port 8461
> Created window Convolve of size 1511, 580
> Client connected
> Created window ConvNL of size 1310, 848
> Exception in thread "main" java.awt.HeadlessException:
> No X11 DISPLAY variable was set, but this program performed an operation which requires it.
>         at java.awt.GraphicsEnvironment.checkHeadless(GraphicsEnvironment.java:204)
>         at java.awt.Window.(Window.java:536)
>         at java.awt.Frame.(Frame.java:420)
>         at javax.swing.JFrame.(JFrame.java:233)
>         at com.google.scrollview.ui.SVWindow.(SVWindow.java:204)
>         at com.google.scrollview.ScrollView.processInput(ScrollView.java:340)
>         at com.google.scrollview.ScrollView.IOLoop(ScrollView.java:120)
>         at com.google.scrollview.ScrollView.main(ScrollView.java:398)
> sh: line 1: kill: %1: no such job
> Created window Lfys64 of size 530, 2000
>
> It is because when you execute the command on remote, it can't open the
> related window.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1168#issuecomment-338095444>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oxfm4diPRjtaSyW2cBG_e81tXRasks5suBGBgaJpZM4P2pPR>
> .
>
  For Arabic, you will get better results using tesseract 4.0alpha.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Oct 9, 2017 at 10:26 PM, idrisalshikh <notifications@github.com>
wrote:

> I have the same problem with arabic language
> ** Run Tesseract for Training **
> [K:\train tesseract\jTessBoxEditor\tesseract-ocr/tesseract,
> ara.mylotus.exp0.tif, ara.mylotus.exp0, box.train]
> Tesseract Open Source OCR Engine v4.0.0-alpha.20170804 with Leptonica
> Page 1
> row xheight=23, but median xheight = 30.5
> APPLY_BOXES: boxfile line 6/ق ((2324,3143),(2338,3173)): FAILURE! Couldn't
> find a matching blob
> APPLY_BOXES: boxfile line 7/ع ((2303,3119),(2334,3157)): FAILURE! Couldn't
> find a matching blob
> ....
> ..
> .
> .
>
> APPLY_BOXES:
> Boxes read from boxfile: 888
> Boxes failed resegmentation: 176
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1166#issuecomment-335217245>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o7ccW2V5QU-yptOQIhVH4AJ0NLwRks5sqlA9gaJpZM4Pys0D>
> .
>
 Same issue as

 https://github.com/tesseract-ocr/tesseract/issues/436
https://github.com/tesseract-ocr/tesseract/issues/445
https://github.com/tesseract-ocr/tesseract/issues/1033

 These errors have existed for a long time. I think it is a problem with how tesseract segments the page and finds lines. If you only have a couple of these errors, I would say to ignore them and proceed to next step.   I remember seeing that if tesseract can't recognize image, it tries to rotate it to see if it gets better results. That could be causing the rotation in your case. https://github.com/tesseract-ocr/tesseract/blob/a1c22fb0d0f6bde165ec7b7c3125420b0ba1d541/textord/colfind.cpp 

maybe relevant.  please read comment related to "string" in issue tracker (and maybe tesseract forums)...  > In general, unless you compile on Windows with MSVC, you should use autotools to build Leptonica and Tesseract.

True.
But in general, PR is ok.  3.02 version is old. Very old. Not supported. Please upgrade.  https://digi.bib.uni-mannheim.de/tesseract/

see link for windows binaries


see wiki for details

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sat, Sep 30, 2017 at 11:39 AM, zdenop <notifications@github.com> wrote:

> Closed #1160 <https://github.com/tesseract-ocr/tesseract/issues/1160>.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1160#event-1272652932>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o7_smnTfnLKfzFLO7UF-EyN3nQhTks5sndsYgaJpZM4Ppbm8>
> .
>
  1. Are you using the latest code from github? If not, which commit?

2. Finetune training should not last this long. Ray recommends iterations of 3000/3600 as suggested in the tutorial.

3. How large are your training texts and number of fonts?

4. Are you

* Fine Tuning for Impact(new-font-style)
* Fine Tuning for ± a few characters

Update: Just noticed in your earlier post:

```
I'm trying to fine tune chi_sim.traineddata with a new font ,
STXihei
``` from the log file

```

Layer 2=ConvNL: lr 1.25e-05->-nan%, lr 1.76777e-05->-nan% SAME
Layer 4=Lfys64: lr 1.25e-05->-nan%, lr 1.76777e-05->-nan% SAME
Layer 5=Lfx128: lr 1.25e-05->-nan%, lr 1.76777e-05->-nan% SAME
Layer 6=Lrx128: lr 1.25e-05->-nan%, lr 1.76777e-05->-nan% SAME
Layer 7=Lfx384: lr 8.83883e-06->-nan%, lr 1.25e-05->-nan% SAME
Layer 8=Output: lr 3.53553e-05->-nan%, lr 5e-05->-nan% SAME
At iteration 1096/1100/1100, Mean rms=6.803%, delta=190.265%, char train=290.425%, word train=99.863%, skip ratio=0%,  New worst char error = 290.425
Divergence! Reverted to iteration 96/100/100
Reduced learning rate on layers: 6
 wrote checkpoint.
```

I think finetune is the wrong method for what you want. Try to replace a layer. Try with latest commit and the patch from https://github.com/tesseract-ocr/tesseract/pull/1153

Use the traineddata files from tessdata_best repo for continuing from

----------------------------

BTW, have you tested OCR with the traineddata from https://github.com/tesseract-ocr/tessdata_best? Please also try OCR with HanS Try the command for plus-minus finetune (with the latest code and best traineddata). 

I am getting following console output.

```
 nice lstmtraining \
>   --continue_from ../tessdata_best/chi_sim.lstm \
>   --old_traineddata ../tessdata_best/chi_sim.traineddata  \
>   --traineddata ../tesstutorial/chi_sim/chi_sim/chi_sim.traineddata  \
>   --train_listfile ../tesstutorial/chi_sim/chi_sim.training_files.txt \
>   --eval_listfile ../tesstutorial/chi_sim/chi_sim.eval_files.txt \
>   --model_output ../tesstutorial/chi_sim_new/chi_sim_new \
>   --max_iterations 6000 \
>   --debug_interval -1
Loaded file ../tessdata_best/chi_sim.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Code range changed from 224 to 227!
Num (Extended) outputs,weights in Series:
  1,48,0,1:1, 0
Num (Extended) outputs,weights in Series:
  C3,3:9, 0
  Ft16:16, 160
Total weights = 160
  [C3,3Ft16]:16, 160
  Mp3,3:16, 0
  Lfys64:64, 20736
  Lfx96:96, 61824
  Lrx96:96, 74112
  Lfx512:512, 1247232
  Fc227:227, 116451
Total weights = 1520515
Previous null char=223 mapped to 226
Continuing from ../tessdata_best/chi_sim.lstm
Loaded 1752/1752 pages (1-1752) of document ../tesstutorial/chi_sim/chi_sim.STXihei.exp0.lstmf
Loaded 1752/1752 pages (1-1752) of document ../tesstutorial/chi_sim/chi_sim.STXihei.exp0.lstmf
Iteration 0: ALIGNED TRUTH : 秘诀鲤鱼 愚蠢翠微注册University 探究峰敬未台妊 原则余林汝锑经理 XP
Iteration 0: BEST OCR TEXT : 秘诀鲤鱼 思蠢翠微注册University 探究峰获未人妊 原则作林注锐经理 XP
File /tmp/tmp.nZYkgdXY7D/chi_sim/chi_sim.STXihei.exp0.lstmf page 57 :
Mean rms=1.504%, delta=7.94%, train=17.526%(60%), skip ratio=0%
Iteration 1: ALIGNED TRUTH : 致 蒸汽文坛 GPS安置伟大保密23 周康黄芪崃 。 从事窗帘公寓鲟橙色熙
Iteration 1: BEST OCR TEXT : 致 蒸汽文坛 GPS安置伟大保密23 周康商茎峡 。 从事窗帘公寓乌橙色辕
File /tmp/tmp.nZYkgdXY7D/chi_sim/chi_sim.STXihei.exp0.lstmf page 296 :
Mean rms=1.528%, delta=7.879%, train=18.659%(55%), skip ratio=0%
```  Are you using an old version of tesseract? 
The correct parameter is `--oem NUM`

I get the following info:

```
tesseract -v
tesseract 4.00.00alpha
 leptonica-1.74.4
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 Found AVX
 Found SSE

```

```
 tesseract
Usage:
  tesseract --help | --help-psm | --help-oem | --version
  tesseract --list-langs [--tessdata-dir PATH]
  tesseract --print-parameters [options...] [configfile...]
  tesseract imagename|stdin outputbase|stdout [options...] [configfile...]

OCR options:
  --tessdata-dir PATH   Specify the location of tessdata path.
  --user-words PATH     Specify the location of user words file.
  --user-patterns PATH  Specify the location of user patterns file.
  -l LANG[+LANG]        Specify language(s) used for OCR.
  -c VAR=VALUE          Set value for config variables.
                        Multiple -c arguments are allowed.
  --psm NUM             Specify page segmentation mode.
  --oem NUM             Specify OCR Engine mode.
NOTE: These options must occur before any configfile.

Page segmentation modes:
  0    Orientation and script detection (OSD) only.
  1    Automatic page segmentation with OSD.
  2    Automatic page segmentation, but no OSD, or OCR.
  3    Fully automatic page segmentation, but no OSD. (Default)
  4    Assume a single column of text of variable sizes.
  5    Assume a single uniform block of vertically aligned text.
  6    Assume a single uniform block of text.
  7    Treat the image as a single text line.
  8    Treat the image as a single word.
  9    Treat the image as a single word in a circle.
 10    Treat the image as a single character.
 11    Sparse text. Find as much text as possible in no particular order.
 12    Sparse text with OSD.
 13    Raw line. Treat the image as a single text line,
                        bypassing hacks that are Tesseract-specific.
OCR Engine modes:
  0    Original Tesseract only.
  1    Neural nets LSTM only.
  2    Tesseract + LSTM.
  3    Default, based on what is available.

Single options:
  -h, --help            Show this help message.
  --help-psm            Show page segmentation modes.
  --help-oem            Show OCR Engine modes.
  -v, --version         Show version information.
  --list-langs          List available languages for tesseract engine.
  --print-parameters    Print tesseract parameters.
``` You are using an older version which supported -psm and -oem, posted last year in November.

After that there have been hundreds of updates. I am using the most recent commit or so.

The problem is that there is no indicator in version string to suggest the commit number or date so it is very difficult. Please compile using the latest source in the master branch. 

Or use the ppa by Alex.  Another reason for https://github.com/tesseract-ocr/tesseract/issues/293

Please give the URL link of the files which worked and which ones didn't? 

Which --oem are you using with it?  fix the "Phase UP: Generating unicharset and unichar properties files" ERROR

Please reference [#1147](https://github.com/tesseract-ocr/tesseract/issues/1147)  @mskrip Thanks for problem report. I'll take care of it. Just curious, how did you locate this problem and are there any practical consequences, such as an incompatibility with a PDF renderer? I don't know about this, checking in more detail. It's easy enough to put in the BOM, but it messes up highlighting with PDFium. The BOM highlights as if it was a character. 

[before.pdf](https://github.com/tesseract-ocr/tesseract/files/1322978/before.pdf)
[after.pdf](https://github.com/tesseract-ocr/tesseract/files/1322977/after.pdf)
![bad-highlight](https://user-images.githubusercontent.com/4961958/30722445-203f4d3a-9ee6-11e7-8c96-e70a2f32bbb9.png)

```diff
--- tesseract/api/pdfrenderer.cpp	2017-07-14 07:32:13.000000000 -0700
+++ tesseract/api/pdfrenderer.cpp	2017-09-21 15:47:32.000000000 -0700
@@ -476,7 +476,7 @@
           kCharWidth * prec(100.0 * word_length / (fontsize * pdf_word_len));
       pdf_str.add_str_double("", h_stretch);
       pdf_str += " Tz";          // horizontal stretch
-      pdf_str += " [ <";
+      pdf_str += " [ <FEFF";     // byte order marker (BOM)
       pdf_str += pdf_word;       // UTF-16BE representation
       pdf_str += "> ] TJ";       // show the text
     }
```

BEFORE
```
5 0 obj
<< /Length 115 >>
stream
q 39.84 0 0 23.52 0 0 cm /Im1 Do Q
BT
3 Tr -1 0 0 1 30.72 8.12 Tm /f-0-0 8 Tf 168 Tz [ <05D105D005EA05E8> ] TJ 
ET
endstream
endobj
```
AFTER
```
5 0 obj
<< /Length 119 >>
stream
q 39.84 0 0 23.52 0 0 cm /Im1 Do Q
BT
3 Tr -1 0 0 1 30.72 8.12 Tm /f-0-0 8 Tf 168 Tz [ <FEFF05D105D005EA05E8> ] TJ 
ET
endstream
endobj
```

 With the BOM, I get the same highlighting problem in Acroread and with Left-To-Right languages. Also seeing incorrect copy-paste. This is looking wrong to me. Suspect that reporter is misinterpreting PDF specification. I have a vague and ancient memory about how PDF text objects are different, will check on that. In the meantime I can't reproduce the incompatibility with `pdfminer` and I'm not sure how to reproduce with `pdfrw`

```bash
$ sudo apt-get install pdfminer
$ pdf2txt before.pdf
באתר
$ pdf2txt after.pdf
באתר
```
 The 1.7 spec suggests you are right. There's some discussion in there about differences in how text string differs in various spec versions, but I don't think that matters. Perhaps the rendering problem I'm seeing with the BOM is simply due to having an entry for 0xFFEF in the glyphless font.

5.3 Text Objects contain "Text-showing operators"
5.3.2 Operator Tj "Shows a text string"
3.8.1 Text string is "either PDFDocEncoding or UTF-16BE with a leading byte-order marker."


 I still have highlighting and copy-paste problems from the BOM even if I change the mappings.  So at the moment we are stuck.

```diff
--- tesseract/api/pdfrenderer.cpp	2017-07-14 07:32:13.000000000 -0700
+++ tesseract/api/pdfrenderer.cpp	2017-09-25 10:58:39.000000000 -0700
@@ -608,10 +608,10 @@
       "/CMapName /Adobe-Identify-UCS def\n"
       "/CMapType 2 def\n"
       "1 begincodespacerange\n"
-      "<0000> <FFFF>\n"
+      "<0000> <FEFE>\n"
       "endcodespacerange\n"
       "1 beginbfrange\n"
-      "<0000> <FFFF> <0000>\n"
+      "<0000> <FEFE> <0000>\n"
       "endbfrange\n"
       "endcmap\n"
       "CMapName currentdict /CMap defineresource pop\n"
``` Simplifying this down to a "Hello World" PDF example, the BOM is causing trouble with PDFium.

[hello-bom.pdf](https://github.com/tesseract-ocr/tesseract/files/1331279/hello-bom.pdf)

![pdfium](https://user-images.githubusercontent.com/4961958/30836312-33ab6c4e-a212-11e7-9b40-21c456ed224f.png)

```
%PDF-1.4
%����
1 0 obj
<< /Pages 2 0 R /Type /Catalog >>
endobj
2 0 obj
<< /Count 1 /Kids [ 3 0 R ] /Type /Pages >>
endobj
3 0 obj
<< /Contents 4 0 R /MediaBox [ 0 0 500 800 ] /Parent 2 0 R /Resources 5 0 R /Type /Page >>
endobj
4 0 obj
<< /Length 57 >>
stream
BT /F1 24 Tf 175 720 Td <FEFF00480065006C006C006F> Tj ET
endstream
endobj
5 0 obj
<< /Font << /F1 6 0 R >> >>
endobj
6 0 obj
<< /BaseFont /Helvetica /Subtype /Type1 /Type /Font >>
endobj
xref
0 7
0000000000 65535 f 
0000000015 00000 n 
0000000064 00000 n 
0000000123 00000 n 
0000000229 00000 n 
0000000335 00000 n 
0000000378 00000 n 
trailer << /Root 1 0 R /Size 7 /ID [<89311a609a751f1666063e6962e79bd5><89311a609a751f1666063e6962e79bd5>] >>
startxref
448
%%EOF
```

 I'm not going to make this change until (at least) PDFium can render correctly. That means filing a bug with PDFium. Don't have energy to chase this myself anytime soon, but won't stop someone with more energy than me. Actually, Adobe Reader can't render hello-bom.pdf either. So I don't know what's up, but best guess is it isn't valid despite spec seemingly saying otherwise.  ### Environment

* **Tesseract Version**: Tesseract4.0.0
* **Commit Number**: 2cc531e
* **Platform**: Linux localhost.localdomain 3.10.0-514.el7.x86_64 #1 SMP Tue Nov 22 16:42:41 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux (Centos7.3)

### Current Behavior:
I use the following command to produce the tif files:
<pre>
# /opt/tesseract4.0/bin/text2image --find_fonts \
--fonts_dir /usr/share/fonts \
--text ./langdata/chi_sim/chi_sim.training_text \
--min_coverage .9  \
--outputbase ./results/chi_sim/chi_sim\
|& grep raw | sed -e 's/ :.*/" \\/g'  | sed -e 's/^/  "/' >./results/chi_sim/fontslist.txt

# ls ./results/chi_sim/
chi_sim.Arial_Unicode_MS.tif               chi_sim.FangSong.tif                 chi_sim.Noto_Sans_SC.tif  chi_sim.STZhongsong.tif
chi_sim.AR_PL_UKai_CN.tif                  chi_sim.KaiTi.tif                    chi_sim.NSimSun.tif       chi_sim.WenQuanYi_Micro_Hei_Mono.tif
chi_sim.AR_PL_UKai_HK.tif                  chi_sim.LiSu.tif                     chi_sim.SimHei.tif        chi_sim.WenQuanYi_Micro_Hei.tif
chi_sim.AR_PL_UKai_TW_MBE.tif              chi_sim.Microsoft_YaHei_Bold.tif     chi_sim.SimSun.tif        chi_sim.WenQuanYi_Zen_Hei_Medium.tif
chi_sim.AR_PL_UKai_TW.tif                  chi_sim.Microsoft_YaHei.tif          chi_sim.STFangsong.tif    chi_sim.WenQuanYi_Zen_Hei_Mono_Medium.tif
chi_sim.AR_PL_UMing_CN_Semi-Light.tif      chi_sim.Noto_Sans_SC_Bold.tif        chi_sim.STKaiti.tif       chi_sim.WenQuanYi_Zen_Hei_Sharp_Medium.tif
chi_sim.AR_PL_UMing_HK_Semi-Light.tif      chi_sim.Noto_Sans_SC_Heavy.tif       chi_sim.STSong.tif        chi_sim.YouYuan.tif
chi_sim.AR_PL_UMing_TW_MBE_Semi-Light.tif  chi_sim.Noto_Sans_SC_Medium.tif      chi_sim.STXihei.tif       fontslist.txt
chi_sim.AR_PL_UMing_TW_Semi-Light.tif      chi_sim.Noto_Sans_SC_Semi-Light.tif  chi_sim.STXinwei.tif
</pre>

Then I used the "Windows photo viewer" to open the tif files， and I found that the tif file  contains only part of the chi_sim.training_text's content(langdata/chi_sim). that's why? 

then I append  "--ysize 9600" option to /opt/tesseract4.0/bin/text2image, the generated tif file can contains more. 

Now do I have to set "--ysize" to a very very large number to fix this problem? Is it the right way?

### Expected Behavior:

### Suggested Fix:
 These are multipage tif files. Have you looked at the next page in it.

On 21-Sep-2017 6:09 PM, "ivanzz1001" <notifications@github.com> wrote:

> Environment
>
>    - *Tesseract Version*: Tesseract4.0.0
>    - *Commit Number*: 2cc531e
>    <https://github.com/tesseract-ocr/tesseract/commit/2cc531e6bf0288fc8a9ad1c123a252395f00bf56>
>    - *Platform*: Linux localhost.localdomain 3.10.0-514.el7.x86_64 #1
>    <https://github.com/tesseract-ocr/tesseract/issues/1> SMP Tue Nov 22
>    16:42:41 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux (Centos7.3)
>
> Current Behavior:
>
> I use the following command to produce the tif files:
>
> # /opt/tesseract4.0/bin/text2image --find_fonts \
> --fonts_dir /usr/share/fonts \
> --text ./langdata/chi_sim/chi_sim.training_text \
> --min_coverage .9  \
> --outputbase ./results/chi_sim/chi_sim\
> |& grep raw | sed -e 's/ :.*/" \\/g'  | sed -e 's/^/  "/' >./results/chi_sim/fontslist.txt
>
> # ls ./results/chi_sim/
> chi_sim.Arial_Unicode_MS.tif               chi_sim.FangSong.tif                 chi_sim.Noto_Sans_SC.tif  chi_sim.STZhongsong.tif
> chi_sim.AR_PL_UKai_CN.tif                  chi_sim.KaiTi.tif                    chi_sim.NSimSun.tif       chi_sim.WenQuanYi_Micro_Hei_Mono.tif
> chi_sim.AR_PL_UKai_HK.tif                  chi_sim.LiSu.tif                     chi_sim.SimHei.tif        chi_sim.WenQuanYi_Micro_Hei.tif
> chi_sim.AR_PL_UKai_TW_MBE.tif              chi_sim.Microsoft_YaHei_Bold.tif     chi_sim.SimSun.tif        chi_sim.WenQuanYi_Zen_Hei_Medium.tif
> chi_sim.AR_PL_UKai_TW.tif                  chi_sim.Microsoft_YaHei.tif          chi_sim.STFangsong.tif    chi_sim.WenQuanYi_Zen_Hei_Mono_Medium.tif
> chi_sim.AR_PL_UMing_CN_Semi-Light.tif      chi_sim.Noto_Sans_SC_Bold.tif        chi_sim.STKaiti.tif       chi_sim.WenQuanYi_Zen_Hei_Sharp_Medium.tif
> chi_sim.AR_PL_UMing_HK_Semi-Light.tif      chi_sim.Noto_Sans_SC_Heavy.tif       chi_sim.STSong.tif        chi_sim.YouYuan.tif
> chi_sim.AR_PL_UMing_TW_MBE_Semi-Light.tif  chi_sim.Noto_Sans_SC_Medium.tif      chi_sim.STXihei.tif       fontslist.txt
> chi_sim.AR_PL_UMing_TW_Semi-Light.tif      chi_sim.Noto_Sans_SC_Semi-Light.tif  chi_sim.STXinwei.tif
>
> Then I used the "Windows photo viewer" to open the tif files， and I found
> that the tif file contains only part of the chi_sim.training_text's
> content(langdata/chi_sim). that's why?
>
> then I append "--ysize 9600" option to /opt/tesseract4.0/bin/text2image,
> the generated tif file can contains more.
>
> Now do I have to set "--ysize" to a very very large number to fix this
> problem? Is it the right way?
> Expected Behavior: Suggested Fix:
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1149>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o5DpUe14UmpUxC8J-WcRGtSEayERks5sklkQgaJpZM4PfQXn>
> .
>
 I checked that they are singlepage tif files, how to generate a multipage tif file? where is it going wrong?  ```
#/opt/tesseract4.0/bin/text2image --find_fonts \
--fonts_dir /usr/share/fonts \
--text ./langdata/chi_sim/chi_sim.training_text \
--min_coverage .9  \
--outputbase ./results/chi_sim/chi_sim\
|& grep raw | sed -e 's/ :.*/" \\/g'  | sed -e 's/^/  "/' >./results/chi_sim/fontslist.txt
```

The above command does not produce tif files for training. It is used for generating a list of fonts and a sample page for each font.

Please use tesstrain.sh command as described in training page on wiki. OK, I use tesstrain.sh, it has the same problem, although this time it generates multipage tif files, they also contains only part of the chi_sim.training_text's content @Shreeshrii I think I have found the reason. In the tesseract_master/training/tesstrain_utils.sh, there's the following function:
<pre>
# Helper function for phaseI_generate_image. Generates the image for a single
# language/font combination in a way that can be run in parallel.
generate_font_image() {
    local font="$1"
    tlog "Rendering using ${font}"
    local fontname=$(echo ${font} | tr ' ' '_' | sed 's/,//g')
    local outbase=${TRAINING_DIR}/${LANG_CODE}.${fontname}.exp${EXPOSURE}

    local common_args="--fontconfig_tmpdir=${FONT_CONFIG_CACHE}"
    common_args+=" --fonts_dir=${FONTS_DIR} --strip_unrenderable_words"
    common_args+=" --leading=${LEADING}"
    common_args+=" --char_spacing=${CHAR_SPACING} --exposure=${EXPOSURE}"
    common_args+=" --outputbase=${outbase} --max_pages=3"

    # add --writing_mode=vertical-upright to common_args if the font is
    # specified to be rendered vertically.
    for vfont in "${VERTICAL_FONTS[@]}"; do
      if [[ "${font}" == "${vfont}" ]]; then
        common_args+=" --writing_mode=vertical-upright "
        break
      fi
    done

    run_command text2image ${common_args} --font="${font}" \
        --text=${TRAINING_TEXT} ${TEXT2IMAGE_EXTRA_ARGS}
    check_file_readable ${outbase}.box ${outbase}.tif

    if ((EXTRACT_FONT_PROPERTIES)) &&
        [[ -r ${TRAIN_NGRAMS_FILE} ]]; then
        tlog "Extracting font properties of ${font}"
        run_command text2image ${common_args} --font="${font}" \
            --ligatures=false --text=${TRAIN_NGRAMS_FILE} \
            --only_extract_font_properties --ptsize=32
        check_file_readable ${outbase}.fontinfo
    fi
}
</pre>
It sets "--max_pages=3", then I modified it to "--max_pages=0", and then it generates the tif files which contain all the words in chi_sim.training_text。

Is it a bug in  tesseract_master/training/tesstrain_utils.sh? Should I report it as a bug? This is a recent change to training. I guess, it is to limit the size of tif/box and hence lstmf files for finetune/plusminus training.

I did pose a question to @theraysmith regarding this, but no answer yet. @Shreeshrii  Have you get answer from @theraysmith ? @theraysmith hasn't answered yet, I had asked in one of these issue posts only.

I am not sure whether that change (adding maxpages) is intentional or accidental. 

Many languages need a higher limit to handle the training_text in current langdata repo (which has also NOT been updated for 4.0x).

So, unless the new langdata will have very short training_text which will be less than 3 pages, thi limit should be removed/changed.

@amitdo Do you have any insight regarding this? yes,I think so @Shreeshrii now have you get answer from @theraysmith ? No. @theraysmith might reply when he does next set of updates. I hope ...  do you have installed font "Tohoma" in your linux?  I think you just mount the C:\Windows\Fonts to the /mnt directory。  @amitdo the "--max_pages=3" flag is in the script tesstrain_utils.sh which tesstrain.sh calls Please try with eng language and a font that you know is there on your
system.

Currently Tahoma font is not being found. Try 'Arial' with English.

Then test for 'tha' with a font which supports the language unicode range.

Once the following errors are fixed, then others may also disappear.

=== Starting training for language 'tha'
[Fri Sep 22 03:04:10 DST 2017] /usr/bin/text2image
--fonts_dir=/usr/share/fonts/ --font=Tahoma
--outputbase=/tmp/font_tmp.r6wpt8kkkw/sample_text.txt
--text=/tmp/font_tmp.r6wpt8kkkw/sample_text.txt
--fontconfig_tmpdir=/tmp/font_tmp.r6wpt8kkkw
FcInitiReinitialize failed!!
Could not find font named Tahoma. Pango suggested font
Please correct --font arg.:Error:Assert failed:in file text2image.cpp, line 437


ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Fri, Sep 22, 2017 at 8:51 AM, xanxus10th <notifications@github.com>
wrote:

> @ivanzz1001 <https://github.com/ivanzz1001> @amitdo
> <https://github.com/amitdo> /mnt/c is use for access to the Windows
> directory. but I try to move "Fonts" Folder to the /mnt/ and change code to --fonts_dir
> /usr/share/fonts/ but it appear the same error
>
> === Starting training for language 'tha'
> [Fri Sep 22 03:04:10 DST 2017] /usr/bin/text2image --fonts_dir=/usr/share/fonts/ --font=Tahoma --outputbase=/tmp/font_tmp.r6wpt8kkkw/sample_text.txt --text=/tmp/font_tmp.r6wpt8kkkw/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.r6wpt8kkkw
> FcInitiReinitialize failed!!
> Could not find font named Tahoma. Pango suggested font
> Please correct --font arg.:Error:Assert failed:in file text2image.cpp, line 437
>
> === Phase I: Generating training images ===
> Rendering using Tahoma
> [Fri Sep 22 03:04:12 DST 2017] /usr/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.r6wpt8kkkw --fonts_dir=/mnt/Fonts --strip_unrenderable_words --leading=48 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.4iPf952XEc/tha/tha.Tahoma.exp0 --max_pages=3 --font=Tahoma --text=/mnt/e/tesseract-ocr/langdata/tha/tha.training_text
> ERROR: Non-existent flag --max_pages=3
> ERROR: /tmp/tmp.4iPf952XEc/tha/tha.Tahoma.exp0.box does not exist or is not readable
> ERROR: /tmp/tmp.4iPf952XEc/tha/tha.Tahoma.exp0.box does not exist or is not readable
>
> *And I try change the code in tesstrain_utils.sh*
> Line 215 - common_args+=" --outputbase=${outbase} --max_pages=3" to
> Line 215 + common_args+=" --outputbase=${outbase} "
>
> But It stuck at Phase Up for many hours
>
> === Phase I: Generating training images ===
> Rendering using Tahoma
> [Fri Sep 22 03:20:05 DST 2017] /usr/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.w5EOd46HIj --fonts_dir=/usr/share/fonts/ --strip_unrenderable_words --leading=48 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.QjgaXWkS0p/tha/tha.Tahoma.exp0 --font=Tahoma --text=/mnt/e/tesseract-ocr/langdata/tha/tha.training_text
> Rendered page 0 to file /tmp/tmp.QjgaXWkS0p/tha/tha.Tahoma.exp0.tif
> Rtl = 0 ,vertical=0
>
> === Phase UP: Generating unicharset and unichar properties files ===
> [Fri Sep 22 03:20:06 DST 2017] /usr/bin/unicharset_extractor --output_unicharset /tmp/tmp.QjgaXWkS0p/tha/tha.unicharset --norm_mode 2 /tmp/tmp.QjgaXWkS0p/tha/tha.Tahoma.exp0.box
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1148#issuecomment-331339919>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o9kuce_oT6yLz9RekSMTKGXelO3qks5skye7gaJpZM4PfLUZ>
> .
>
 Just tested on my pc (WSL run with moxaterm)

```
root@All-in-1-Touch:/mnt/c/Users/User/shree/tesseract-HEAD# training/tesstrain.sh \
 --fonts_dir /mnt/c/Windows/Fonts \
  --lang tha \
  --noextract_font_properties  --linedata_only \
  --exposures "0" \
  --langdata_dir ../langdata \
  --tessdata_dir ../tessdata \
  --fontlist \
   "Tahoma" \
   --output_dir ../tesstutorial/tha


=== Starting training for language 'tha'
[Fri Sep 22 09:33:08 DST 2017] /usr/local/bin/text2image --fonts_dir=/mnt/c/Windows/Fonts --font=Tahoma --outputbase=/tmp/font_tmp.Vy1LLR1cHi/sample_text.txt --text=/tmp
/font_tmp.Vy1LLR1cHi/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.Vy1LLR1cHi
Rendered page 0 to file /tmp/font_tmp.Vy1LLR1cHi/sample_text.txt.tif

=== Phase I: Generating training images ===
Rendering using Tahoma
[Fri Sep 22 09:34:11 DST 2017] /usr/local/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.Vy1LLR1cHi --fonts_dir=/mnt/c/Windows/Fonts --strip_unrenderable_words --leadi
ng=48 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.9wT9v8Aqai/tha/tha.Tahoma.exp0 --max_pages=3 --font=Tahoma --text=../langdata/tha/tha.training_text
Rendered page 0 to file /tmp/tmp.9wT9v8Aqai/tha/tha.Tahoma.exp0.tif
Rendered page 1 to file /tmp/tmp.9wT9v8Aqai/tha/tha.Tahoma.exp0.tif
Rendered page 2 to file /tmp/tmp.9wT9v8Aqai/tha/tha.Tahoma.exp0.tif
``` Please execute the following command to check what fonts have you installed(Centos):
<pre>
# yum install fontconfig mkfontscale
# fc-list

# text2image --fonts_dir /usr/share/fonts --list_available_fonts
</pre> Are you sure you don't have an older version of program somewhere?

Did

make training
and
make training-install

complete without errors.  ### Environment

* **Tesseract Version**: tesseract 4.00.00alpha
* **Commit Number**:  2cc531e
* **Platform**: Linux localhost.localdomain 3.10.0-514.el7.x86_64 #1 SMP Tue Nov 22 16:42:41 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

### Current Behavior:
I excute the following command:
<pre>
training/tesstrain.sh --fonts_dir /usr/share/fonts --lang chi_sim --linedata_only \
  --noextract_font_properties --langdata_dir ../langdata \
  --tessdata_dir ../tessdata \
  --fontlist "AR PL UKai CN" \
  "AR PL UKai HK" \
  "AR PL UKai TW" \
  "AR PL UKai TW MBE" \
  "AR PL UMing CN Semi-Light" \
  "AR PL UMing HK Semi-Light" \
  "AR PL UMing TW MBE Semi-Light" \
  "AR PL UMing TW Semi-Light" \
  "Arial Unicode MS" \
  "FangSong" \
  "KaiTi" \
  "LiSu" \
  "Microsoft YaHei" \
  "Microsoft YaHei Bold" \
  "NSimSun" \
  "Noto Sans SC" \
  "Noto Sans SC Bold" \
  "Noto Sans SC Heavy" \
  "Noto Sans SC Medium" \
  "Noto Sans SC Medium" \
  "Noto Sans SC Semi-Light" \
  "Noto Sans SC Semi-Light" \
  "STFangsong" \
  "STKaiti" \
  "STSong" \
  "STXihei" \
  "STXinwei" \
  "STZhongsong" \
  "SimHei" \
  "SimSun" \
  "WenQuanYi Micro Hei" \
  "WenQuanYi Micro Hei Mono" \
  "WenQuanYi Zen Hei Medium" \
  "WenQuanYi Zen Hei Mono Medium" \
  "WenQuanYi Zen Hei Sharp Medium" \
  "YouYuan" \
  --output_dir ../tesstutorial/chieval \
  --overwrite
</pre>

But when it goes to Phase UP, it generates the following error:
<pre>
=== Phase UP: Generating unicharset and unichar properties files ===
which: no unicharset_extractor in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
which: no unicharset_extractor in (./api)
[Thu Sep 21 02:23:48 PDT 2017] /root/tesseract-src/tesseract-master/training/unicharset_extractor --output_unicharset /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.unicharset --norm_mode 1 /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.AR_PL_UKai_CN.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.AR_PL_UKai_HK.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.AR_PL_UKai_TW.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.AR_PL_UKai_TW_MBE.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.AR_PL_UMing_CN_Semi-Light.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.AR_PL_UMing_HK_Semi-Light.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.AR_PL_UMing_TW_MBE_Semi-Light.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.AR_PL_UMing_TW_Semi-Light.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.FangSong.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.KaiTi.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.LiSu.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.Microsoft_YaHei_Bold.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.Microsoft_YaHei.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.Noto_Sans_SC_Bold.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.Noto_Sans_SC.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.Noto_Sans_SC_Heavy.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.Noto_Sans_SC_Medium.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.Noto_Sans_SC_Semi-Light.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.NSimSun.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.SimHei.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.SimSun.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.STFangsong.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.STKaiti.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.STSong.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.STXihei.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.STXinwei.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.STZhongsong.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.WenQuanYi_Micro_Hei.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.WenQuanYi_Micro_Hei_Mono.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.WenQuanYi_Zen_Hei_Medium.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.WenQuanYi_Zen_Hei_Mono_Medium.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.WenQuanYi_Zen_Hei_Sharp_Medium.exp0.box /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.YouYuan.exp0.box
Extracting unicharset from box file /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.AR_PL_UKai_CN.exp0.box
Invalid Unicode codepoint: 0xffffffe8
IsValidCodepoint(ch):Error:Assert failed:in file normstrngs.cpp, line 225
ERROR: /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.unicharset does not exist or is not readable
</pre>

1) In https://github.com/tesseract-ocr/langdata, I can't find my chi_sim.unicharset。 But I found it in the tesseract source directory: tesseract-master/testdata/chi_sim.unicharset。But It appears that  in https://github.com/tesseract-ocr/langdata, there's the following two files: Han.unicharset, Han.xheights; It also looks like the Chinese language. Now which unicharset file I should choose? And where I need to place it ?
2)  Now I just copy tesseract-master/testdata/chi_sim.unicharset to langdata/chi_sim/ directory, but it has the following problems:
<pre>
ERROR: /tmp/tmp.Tf9BFjjy6w/chi_sim/chi_sim.unicharset does not exist or is not readable
</pre>

3)  in the temporary directory "/tmp/tmp.Tf9BFjjy6w/chi_sim",I have the following files:
<pre>
[root@localhost tesseract-master]# ls /tmp/tmp.Tf9BFjjy6w/chi_sim/
chi_sim.AR_PL_UKai_CN.exp0.box                  chi_sim.Microsoft_YaHei_Bold.exp0.tif     chi_sim.STSong.exp0.box
chi_sim.AR_PL_UKai_CN.exp0.tif                  chi_sim.Microsoft_YaHei.exp0.box          chi_sim.STSong.exp0.tif
chi_sim.AR_PL_UKai_HK.exp0.box                  chi_sim.Microsoft_YaHei.exp0.tif          chi_sim.STXihei.exp0.box
chi_sim.AR_PL_UKai_HK.exp0.tif                  chi_sim.Noto_Sans_SC_Bold.exp0.box        chi_sim.STXihei.exp0.tif
chi_sim.AR_PL_UKai_TW.exp0.box                  chi_sim.Noto_Sans_SC_Bold.exp0.tif        chi_sim.STXinwei.exp0.box
chi_sim.AR_PL_UKai_TW.exp0.tif                  chi_sim.Noto_Sans_SC.exp0.box             chi_sim.STXinwei.exp0.tif
chi_sim.AR_PL_UKai_TW_MBE.exp0.box              chi_sim.Noto_Sans_SC.exp0.tif             chi_sim.STZhongsong.exp0.box
chi_sim.AR_PL_UKai_TW_MBE.exp0.tif              chi_sim.Noto_Sans_SC_Heavy.exp0.box       chi_sim.STZhongsong.exp0.tif
chi_sim.AR_PL_UMing_CN_Semi-Light.exp0.box      chi_sim.Noto_Sans_SC_Heavy.exp0.tif       chi_sim.WenQuanYi_Micro_Hei.exp0.box
chi_sim.AR_PL_UMing_CN_Semi-Light.exp0.tif      chi_sim.Noto_Sans_SC_Medium.exp0.box      chi_sim.WenQuanYi_Micro_Hei.exp0.tif
chi_sim.AR_PL_UMing_HK_Semi-Light.exp0.box      chi_sim.Noto_Sans_SC_Medium.exp0.tif      chi_sim.WenQuanYi_Micro_Hei_Mono.exp0.box
chi_sim.AR_PL_UMing_HK_Semi-Light.exp0.tif      chi_sim.Noto_Sans_SC_Semi-Light.exp0.box  chi_sim.WenQuanYi_Micro_Hei_Mono.exp0.tif
chi_sim.AR_PL_UMing_TW_MBE_Semi-Light.exp0.box  chi_sim.Noto_Sans_SC_Semi-Light.exp0.tif  chi_sim.WenQuanYi_Zen_Hei_Medium.exp0.box
chi_sim.AR_PL_UMing_TW_MBE_Semi-Light.exp0.tif  chi_sim.NSimSun.exp0.box                  chi_sim.WenQuanYi_Zen_Hei_Medium.exp0.tif
chi_sim.AR_PL_UMing_TW_Semi-Light.exp0.box      chi_sim.NSimSun.exp0.tif                  chi_sim.WenQuanYi_Zen_Hei_Mono_Medium.exp0.box
chi_sim.AR_PL_UMing_TW_Semi-Light.exp0.tif      chi_sim.SimHei.exp0.box                   chi_sim.WenQuanYi_Zen_Hei_Mono_Medium.exp0.tif
chi_sim.FangSong.exp0.box                       chi_sim.SimHei.exp0.tif                   chi_sim.WenQuanYi_Zen_Hei_Sharp_Medium.exp0.box
chi_sim.FangSong.exp0.tif                       chi_sim.SimSun.exp0.box                   chi_sim.WenQuanYi_Zen_Hei_Sharp_Medium.exp0.tif
chi_sim.KaiTi.exp0.box                          chi_sim.SimSun.exp0.tif                   chi_sim.YouYuan.exp0.box
chi_sim.KaiTi.exp0.tif                          chi_sim.STFangsong.exp0.box               chi_sim.YouYuan.exp0.tif
chi_sim.LiSu.exp0.box                           chi_sim.STFangsong.exp0.tif               tesstrain.log
chi_sim.LiSu.exp0.tif                           chi_sim.STKaiti.exp0.box
chi_sim.Microsoft_YaHei_Bold.exp0.box           chi_sim.STKaiti.exp0.tif
</pre>
I use an image tool and  open the .tif files, but I  found it contains only part of the chi_sim.training_text's content(langdata/chi_sim), that's why? how do I fix it? 

### Expected Behavior:



### Suggested Fix:
 It is getting errors related to the program `unicharset_extractor`.

Please see known and still open issue: https://github.com/tesseract-ocr/tesseract/issues/1114
 @Shreeshrii  I think I have found the reason。I have the following chi_sim.training_text( Here I just show you first line):
<pre>
1996规格器皿 砝2.5、客胫骨发电All 联络 其、鄞州 Education嫉处感谢铁道
</pre>
And I add some print msg in the following function(tesseract_master/training/unicharset_extractor.cpp):
<pre>
// Helper normalizes and segments the given strings according to norm_mode, and
// adds the segmented parts to unicharset.
static void AddStringsToUnicharset(const GenericVector<STRING>& strings,
                                   int norm_mode, UNICHARSET* unicharset) {
  for (int i = 0; i < strings.size(); ++i) {
    std::vector<string> normalized;
    if (NormalizeCleanAndSegmentUTF8(UnicodeNormMode::kNFC, OCRNorm::kNone,
                                     static_cast<GraphemeNormMode>(norm_mode),
                                     /*report_errors*/ true,
                                     strings[i].string(), &normalized)) {
      tprintf("string: %s\n",strings[i].string());
      for (const string& normed : normalized) {
      tprintf("string2:%s\n",normed.c_str());
        if (normed.empty() || IsWhitespace(normed[0])) continue;
        unicharset->unichar_insert(normed.c_str());
      }
    } else {
      tprintf("Normalization failed for string '%s'\n", strings[i].c_str());
    }
  }
}
</pre>
It prints the following:
<pre>
string: 1
string2:1
string: 9
string2:9
string: 9
string2:9
string: 6
string2:6
string: 规
string2:规
Invalid Unicode codepoint: 0xffffffe8
IsValidCodepoint(ch):Error:Assert failed:in file normstrngs.cpp, line 225
ERROR: /tmp/tmp.8gMFI2Gry5/chi_sim/chi_sim.unicharset does not exist or is not readable
</pre>

Then I write a short test:
<pre>
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

#include &lt;string&gt;
using namespace std;

int main(int argc,char *argv[]){
        string s = "规";
        printf("size:%d\n",s.size());
        for(int i=0;i &lt; s.size();i++)
                printf("%x ",s[i]);
        printf("\n");
        return 0;
}
</pre>
Execute the test:
<pre>
ivan1001@ceph-admin:~/test-src$ ./test
size:3
ffffffe8 ffffffa7 ffffff84 
</pre>
Now I found "0xffffffe8 0xffffffa7 0xffffff84" is the utf-8 code of "规",not what we expect the Unicode encoding((utf-32) in the unicharset_extractor.cpp program。The Unicode code of "规" is "\u89c4", it is in then range : [0, 0xD800) or [0xE000, 0x10FFFF]

Here I think the program's logic has some problems。 First It use function NormalizeCleanAndSegmentUTF8() to convert the string to UTF-8 encoding , but thereafter it use a "Unicode (utf-32)" function IsValidCodepoint() to check the utf-8's result. 

Please check, and how do I post the bug to the developers or could you help me?  @ivanzz1001 Thanks for looking into this issue and finding possible reason. I do not know enough about tesseract and c++ to comment.

Tagging @theraysmith and @stweil - related issue https://github.com/tesseract-ocr/tesseract/issues/1114

I had also thought that it was related in someway to the conversion of utf8 training text to the utf32 format, but did not know how to check for it.
 @Shreeshrii @stweil  The following function:
<pre>
static void AddStringsToUnicharset(const GenericVector<STRING>& strings,
                                   int norm_mode, UNICHARSET* unicharset) {
  for (int i = 0; i < strings.size(); ++i) {
    std::vector<string> normalized;
    if (NormalizeCleanAndSegmentUTF8(UnicodeNormMode::kNFC, OCRNorm::kNone,
                                     static_cast<GraphemeNormMode>(norm_mode),
                                     /*report_errors*/ true,
                                     strings[i].string(), &normalized)) {
      for (const string& normed : normalized) {
        if (normed.empty() || IsWhitespace(normed[0])) continue;
        unicharset->unichar_insert(normed.c_str());
      }
    } else {
      tprintf("Normalization failed for string '%s'\n", strings[i].c_str());
    }
  }
}
</pre>
It may need to change to:
<pre>
if (normed.empty() || IsUTF8Whitespace(normed[0])) continue;
</pre>
 @amitdo Last it has changed back to UTF-8:
<pre>
bool NormalizeCleanAndSegmentUTF8(UnicodeNormMode u_mode, OCRNorm ocr_normalize,
                                  GraphemeNormMode g_mode, bool report_errors,
                                  const char* str8,
                                  std::vector<string>* graphemes) {
  std::vector<char32> normed32;
  NormalizeUTF8ToUTF32(u_mode, ocr_normalize, str8, &normed32);
  StripJoiners(&normed32);
  std::vector<std::vector<char32>> graphemes32;
  bool success = Validator::ValidateCleanAndSegment(g_mode, report_errors,
                                                    normed32, &graphemes32);
  if (g_mode != GraphemeNormMode::kSingleString && success) {
    // If we modified the string to clean it up, the segmentation may not be
    // correct, so check for changes and do it again.
    std::vector<char32> cleaned32;
    for (const auto& g : graphemes32) {
      cleaned32.insert(cleaned32.end(), g.begin(), g.end());
    }
    if (cleaned32 != normed32) {
      graphemes32.clear();
      success = Validator::ValidateCleanAndSegment(g_mode, report_errors,
                                                   cleaned32, &graphemes32);
    }
  }
  graphemes->clear();
  graphemes->reserve(graphemes32.size());
  for (const auto& grapheme : graphemes32) {
    graphemes->push_back(UNICHAR::UTF32ToUTF8(grapheme));
  }
  return success;
}
</pre> @Shreeshrii I had used the changed source code(tesseract_master/training/unicharset_extractor.cpp):
<pre>
if (normed.empty() || IsUTF8Whitespace(normed.c_str())) continue;
</pre>
and had generated the .lstmf files. It seems the above modify is OK.  But I haven't finished all the training steps so I can't absolutely make sure it works ok.

 @Shreeshrii  BTW,when I use the training/tesstrain.sh  to generate chi_sim_XXX.lstmf file， why should "--tessdata_dir ../tessdata" directory must contain eng.traineddata? if the directory does't contains the eng.traineddata, It will continuously find the file, but here I just want to train sim_chi tesseract checks for osd and eng.traineddata at start of program. It has
been there for many years and hasn't been changed even though now it
handles many more languages.

The developers have other higher priority bugs  to fix/ features to add,
and so the requirement for eng.traineddata  remains.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Sep 26, 2017 at 3:44 PM, ivanzz1001 <notifications@github.com>
wrote:

> @Shreeshrii <https://github.com/shreeshrii> BTW,when I use the
> training/tesstrain.sh to generate chi_sim_XXX.lstmf file， why should
> "--tessdata_dir ../tessdata" must contains eng.traineddata? if the
> directory does't contains the eng.traineddata, It will continuously find
> the file, but here I just want to train sim_chi
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1147#issuecomment-332152832>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o-wkkcLQjDbfqVYiiuYoKjSk0YxCks5smM5-gaJpZM4PfFg_>
> .
>
 @Shreeshrii  when I execute the "training/tesstrain.sh " and later meets the following:
<pre>
=== Constructing LSTM training data ===
which: no combine_lang_model in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
which: no combine_lang_model in (./api)
[Tue Sep 26 21:17:16 PDT 2017] /root/tesseract-src/tesseract-master/training/combine_lang_model --input_unicharset /tmp/tmp.LASR8IGnop/chi_sim/chi_sim.unicharset --script_dir ../langdata --words ../langdata/chi_sim/chi_sim.wordlist --numbers ../langdata/chi_sim/chi_sim.numbers --puncs ../langdata/chi_sim/chi_sim.punc --output_dir ../tesstutorial/chieval --lang chi_sim
Loaded unicharset of size 5074 from file /tmp/tmp.LASR8IGnop/chi_sim/chi_sim.unicharset
Setting unichar properties
Setting script properties
Warning: properties incomplete for index 106 = ，
Config file is optional, continuing...
Null char=2
Invalid format in radical table at line 0: 19886 3 23 6 3
Creation of encoded unicharset failed!!
Error writing recoder!!
Reducing Trie to SquishedDawg
Error during conversion of wordlists to DAWGs!!
</pre>
I have used the chi_sim_vert.traineddata from the tessdata_best directory, is it the reason cause the problems above? Here [#842](https://github.com/tesseract-ocr/tesseract/issues/842) you said:
<pre>
modify chi_sim.config file in langdata/chi_sim
and comment out first line related to loading of the vertical sub language
</pre>
but I didn't modify it and used the chi_sim_vert.trainneddata from the tessdata_best directrory. @Shreeshrii  Or should I try my own chi_sim_vert.traineddata first? >Here #842 you said:

>modify chi_sim.config file in langdata/chi_sim

>and comment out first line related to loading of the vertical sub language

I think at that time, there was no chi_sim_vert traineddata available.


I will try out the command at my end to see what error I get.


ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Sep 27, 2017 at 11:48 AM, ivanzz1001 <notifications@github.com>
wrote:

> @Shreeshrii <https://github.com/shreeshrii> Or should I try my own
> chi_sim_vert.traineddata first?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1147#issuecomment-332420444>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oxMyOZwSj81sdhBzebAx3veBXFDEks5smei9gaJpZM4PfFg_>
> .
>
 > Invalid format in radical table at line 0: 19886 3 23 6 3

Do you have the latest version of

https://github.com/tesseract-ocr/langdata/blob/master/radical-stroke.txt

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Sep 27, 2017 at 12:52 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
wrote:

> >Here #842 you said:
>
> >modify chi_sim.config file in langdata/chi_sim
>
> >and comment out first line related to loading of the vertical sub language
>
> I think at that time, there was no chi_sim_vert traineddata available.
>
>
> I will try out the command at my end to see what error I get.
>
>
> ShreeDevi
> ____________________________________________________________
> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>
> On Wed, Sep 27, 2017 at 11:48 AM, ivanzz1001 <notifications@github.com>
> wrote:
>
>> @Shreeshrii <https://github.com/shreeshrii> Or should I try my own
>> chi_sim_vert.traineddata first?
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/1147#issuecomment-332420444>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AE2_oxMyOZwSj81sdhBzebAx3veBXFDEks5smei9gaJpZM4PfFg_>
>> .
>>
>
>
 @Shreeshrii Yes, I have downloaded the latest version Looks like you do not have the following program.

which: no combine_lang_model in
(/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
which: no combine_lang_model in (./api)


Please check. This is required for building starter traineddata


On 27-Sep-2017 1:13 PM, "ivanzz1001" <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/shreeshrii> Yes, I have downloaded the
> latest version
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1147#issuecomment-332437666>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o5gUX21xnctOMVNN0XKdBadnga8Yks5smfyfgaJpZM4PfFg_>
> .
>
 I think it is not the reason, look at the following:
<pre>
=== Constructing LSTM training data ===
which: no combine_lang_model in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
which: no combine_lang_model in (./api)
[Tue Sep 26 21:17:16 PDT 2017] /root/tesseract-src/tesseract-master/training/combine_lang_model --input_unicharset /tmp/tmp.LASR8IGnop/chi_sim/chi_sim.unicharset --script_dir ../langdata --words ../langdata/chi_sim/chi_sim.wordlist --numbers ../langdata/chi_sim/chi_sim.numbers --puncs ../langdata/chi_sim/chi_sim.punc --output_dir ../tesstutorial/chieval --lang chi_sim
</pre>
It has found it  at /root/tesseract-src/tesseract-master/training/combine_lang_model。 Although,I will retry it later works for me

```
Loaded 1484/1484 pages (1-1484) of document
/tmp/tmp.nuCxxWRRbN/chi_sim/chi_sim.STXihei.exp0.lstmf
Page 35
Loaded 1529/1529 pages (1-1529) of document
/tmp/tmp.nuCxxWRRbN/chi_sim/chi_sim.STXihei.exp0.lstmf

=== Constructing LSTM training data ===
[Wed Sep 27 15:10:45 DST 2017] /usr/local/bin/combine_lang_model
--input_unicharset /tmp/tmp.nuCxxWRRbN/chi_sim/chi_sim.un
icharset --script_dir ../langdata --words
../langdata/chi_sim/chi_sim.wordlist --numbers
../langdata/chi_sim/chi_sim.numbe
rs --puncs ../langdata/chi_sim/chi_sim.punc --output_dir
../tesstutorial/chi_sim --lang chi_sim
Loaded unicharset of size 5028 from file
/tmp/tmp.nuCxxWRRbN/chi_sim/chi_sim.unicharset
Setting unichar properties
Mirror 〖 of 〗 is not in unicharset
Setting script properties
Warning: properties incomplete for index 333 = ，
Config file is optional, continuing...
Null char=2
Reducing Trie to SquishedDawg
Reducing Trie to SquishedDawg
Reducing Trie to SquishedDawg
Moving /tmp/tmp.nuCxxWRRbN/chi_sim/chi_sim.STXihei.exp0.lstmf to
../tesstutorial/chi_sim

Completed training for language 'chi_sim'
```

Have you changed the training_text?

It could be the change related to whitespace code change...

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Sep 27, 2017 at 1:36 PM, ivanzz1001 <notifications@github.com>
wrote:

> I think it is not the reason, look at the following:
>
> === Constructing LSTM training data ===
> which: no combine_lang_model in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
> which: no combine_lang_model in (./api)
> [Tue Sep 26 21:17:16 PDT 2017] /root/tesseract-src/tesseract-master/training/combine_lang_model --input_unicharset /tmp/tmp.LASR8IGnop/chi_sim/chi_sim.unicharset --script_dir ../langdata --words ../langdata/chi_sim/chi_sim.wordlist --numbers ../langdata/chi_sim/chi_sim.numbers --puncs ../langdata/chi_sim/chi_sim.punc --output_dir ../tesstutorial/chieval --lang chi_sim
>
> It has found it at /root/tesseract-src/tesseract-
> master/training/combine_lang_model。 Although,I will retry it later
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1147#issuecomment-332443146>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o8lO8PINpcEfYUvJzR4bMcbxdwsLks5smgIVgaJpZM4PfFg_>
> .
>
 I don't change anything in the langdata directory, And my command is:
<pre>
training/tesstrain.sh --fonts_dir /usr/share/fonts --lang chi_sim --linedata_only \
  --noextract_font_properties --langdata_dir ../langdata \
  --tessdata_dir ./tessdata \
  --exposures "0" \
  --fontlist "AR PL UKai CN" \
  "AR PL UKai HK" \
  "AR PL UKai TW" \
  "AR PL UKai TW MBE" \
  "AR PL UMing CN Semi-Light" \
  "AR PL UMing HK Semi-Light" \
  "AR PL UMing TW MBE Semi-Light" \
  "AR PL UMing TW Semi-Light" \
  "Arial Unicode MS" \
  "FangSong" \
  "KaiTi" \
  "LiSu" \
  "Microsoft YaHei" \
  "Microsoft YaHei Bold" \
  "NSimSun" \
  "Noto Sans SC" \
  "Noto Sans SC Bold" \
  "Noto Sans SC Heavy" \
  "Noto Sans SC Medium" \
  "Noto Sans SC Semi-Light" \
  "STFangsong" \
  "STKaiti" \
  "STSong" \
  "STXihei" \
  "STXinwei" \
  "STZhongsong" \
  "SimHei" \
  "SimSun" \
  "WenQuanYi Micro Hei" \
  "WenQuanYi Micro Hei Mono" \
  "WenQuanYi Zen Hei Medium" \
  "WenQuanYi Zen Hei Mono Medium" \
  "WenQuanYi Zen Hei Sharp Medium" \
  "YouYuan" \
  --output_dir ../tesstutorial/chieval \
  --overwrite
</pre> This is the command I used

training/tesstrain.sh \
--fonts_dir /mnt/c/Windows/Fonts \
 --lang chi_sim \
 --noextract_font_properties  --linedata_only \
 --exposures "0" \
 --langdata_dir ../langdata \
 --tessdata_dir ../tessdata \
 --fontlist \
  "STXihei" \
  --output_dir ../tesstutorial/chi_sim


Please check whether it works with just this one font.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Sep 27, 2017 at 3:20 PM, ivanzz1001 <notifications@github.com>
wrote:

> I don't change anything in the langdata directory, And my command is:
>
> training/tesstrain.sh --fonts_dir /usr/share/fonts --lang chi_sim --linedata_only \
>   --noextract_font_properties --langdata_dir ../langdata \
>   --tessdata_dir ./tessdata \
>   --exposures "0" \
>   --fontlist "AR PL UKai CN" \
>   "AR PL UKai HK" \
>   "AR PL UKai TW" \
>   "AR PL UKai TW MBE" \
>   "AR PL UMing CN Semi-Light" \
>   "AR PL UMing HK Semi-Light" \
>   "AR PL UMing TW MBE Semi-Light" \
>   "AR PL UMing TW Semi-Light" \
>   "Arial Unicode MS" \
>   "FangSong" \
>   "KaiTi" \
>   "LiSu" \
>   "Microsoft YaHei" \
>   "Microsoft YaHei Bold" \
>   "NSimSun" \
>   "Noto Sans SC" \
>   "Noto Sans SC Bold" \
>   "Noto Sans SC Heavy" \
>   "Noto Sans SC Medium" \
>   "Noto Sans SC Semi-Light" \
>   "STFangsong" \
>   "STKaiti" \
>   "STSong" \
>   "STXihei" \
>   "STXinwei" \
>   "STZhongsong" \
>   "SimHei" \
>   "SimSun" \
>   "WenQuanYi Micro Hei" \
>   "WenQuanYi Micro Hei Mono" \
>   "WenQuanYi Zen Hei Medium" \
>   "WenQuanYi Zen Hei Mono Medium" \
>   "WenQuanYi Zen Hei Sharp Medium" \
>   "YouYuan" \
>   --output_dir ../tesstutorial/chieval \
>   --overwrite
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1147#issuecomment-332469904>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o8p8bHZ9xsJDYYh51ijOcQHuXYDNks5smhpogaJpZM4PfFg_>
> .
>
 I use just one font but it also has the same problem:
<pre>
training/tesstrain.sh --fonts_dir /usr/share/fonts --lang chi_sim --linedata_only \
  --noextract_font_properties --langdata_dir ../langdata \
  --tessdata_dir ./tessdata \
  --exposures "0" \
  --fontlist "AR PL UKai CN" \
  --output_dir ../tesstutorial/chieval \
  --overwrite
</pre> >Invalid format in radical table at line 0: 19886 3 23 6 3
Creation of encoded unicharset failed!!
Error writing recoder!!
Reducing Trie to SquishedDawg
Error during conversion of wordlists to DAWGs!!

Are you still getting the above error? Yes. I use you command:
<pre>training/tesstrain.sh \
 --fonts_dir /usr/share/fonts \
 --lang chi_sim \
 --noextract_font_properties  --linedata_only \
 --exposures "0" \
 --langdata_dir ../langdata \
 --tessdata_dir ./tessdata \
 --fontlist \
  "STXihei" \
  --output_dir ../tesstutorial/chi_sim
</pre>
But It got the same problem.
<pre>
=== Constructing LSTM training data ===
Creating new directory ../tesstutorial/chi_sim
which: no combine_lang_model in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
which: no combine_lang_model in (./api)
[Wed Sep 27 19:03:32 PDT 2017] /root/tesseract-src/tesseract-master/training/combine_lang_model --input_unicharset /tmp/tmp.mv3dlQnYez/chi_sim/chi_sim.unicharset --script_dir ../langdata --words ../langdata/chi_sim/chi_sim.wordlist --numbers ../langdata/chi_sim/chi_sim.numbers --puncs ../langdata/chi_sim/chi_sim.punc --output_dir ../tesstutorial/chi_sim --lang chi_sim
Loaded unicharset of size 1923 from file /tmp/tmp.mv3dlQnYez/chi_sim/chi_sim.unicharset
Setting unichar properties
Mirror 「 of 」 is not in unicharset
Mirror { of } is not in unicharset
Mirror 〗 of 〖 is not in unicharset
Other case Z of z is not in unicharset
Setting script properties
Warning: properties incomplete for index 106 = ，
Config file is optional, continuing...
Null char=2
Invalid format in radical table at line 0: 19886 3 23 6 3
Creation of encoded unicharset failed!!
Error writing recoder!!
Reducing Trie to SquishedDawg
Error during conversion of wordlists to DAWGs!!
Moving /tmp/tmp.mv3dlQnYez/chi_sim/chi_sim.STXihei.exp0.lstmf to ../tesstutorial/chi_sim

Completed training for language 'chi_sim'
</pre>
which version have you use "--tessdata_dir ./tessdata"? the lastest tessdata_best? Something seems wrong with your radical stroke file from langdata, please
download again and try.

On 28-Sep-2017 7:35 AM, "ivanzz1001" <notifications@github.com> wrote:

> Yes. I use you command:
>
> training/tesstrain.sh \
>  --fonts_dir /usr/share/fonts \
>  --lang chi_sim \
>  --noextract_font_properties  --linedata_only \
>  --exposures "0" \
>  --langdata_dir ../langdata \
>  --tessdata_dir ./tessdata \
>  --fontlist \
>   "STXihei" \
>   --output_dir ../tesstutorial/chi_sim
>
> But It got the same problem.
>
> === Constructing LSTM training data ===
> Creating new directory ../tesstutorial/chi_sim
> which: no combine_lang_model in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
> which: no combine_lang_model in (./api)
> [Wed Sep 27 19:03:32 PDT 2017] /root/tesseract-src/tesseract-master/training/combine_lang_model --input_unicharset /tmp/tmp.mv3dlQnYez/chi_sim/chi_sim.unicharset --script_dir ../langdata --words ../langdata/chi_sim/chi_sim.wordlist --numbers ../langdata/chi_sim/chi_sim.numbers --puncs ../langdata/chi_sim/chi_sim.punc --output_dir ../tesstutorial/chi_sim --lang chi_sim
> Loaded unicharset of size 1923 from file /tmp/tmp.mv3dlQnYez/chi_sim/chi_sim.unicharset
> Setting unichar properties
> Mirror 「 of 」 is not in unicharset
> Mirror { of } is not in unicharset
> Mirror 〗 of 〖 is not in unicharset
> Other case Z of z is not in unicharset
> Setting script properties
> Warning: properties incomplete for index 106 = ，
> Config file is optional, continuing...
> Null char=2
> Invalid format in radical table at line 0: 19886 3 23 6 3
> Creation of encoded unicharset failed!!
> Error writing recoder!!
> Reducing Trie to SquishedDawg
> Error during conversion of wordlists to DAWGs!!
> Moving /tmp/tmp.mv3dlQnYez/chi_sim/chi_sim.STXihei.exp0.lstmf to ../tesstutorial/chi_sim
>
> Completed training for language 'chi_sim'
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1147#issuecomment-332706109>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o1mDnBtQxwWF8SPKKd_KotLHfRoVks5smv72gaJpZM4PfFg_>
> .
>
 I have got the latest langdata, but it has the same problem. Could you send me you tesstrain.log? @Shreeshrii  I trained eng, it also has the same problem:
<pre>
 [root@localhost tesseract-master]# training/tesstrain.sh --fonts_dir /usr/share/fonts --lang eng --linedata_only \
>   --noextract_font_properties --langdata_dir ../langdata \
>   --exposures "0" \
>   --fontlist "DejaVu Serif" \
>   --tessdata_dir ../tessdata --output_dir ../tesstutorial/engeval

=== Starting training for language 'eng'
which: no text2image in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
which: no text2image in (./api)
[Wed Sep 27 20:25:03 PDT 2017] /root/tesseract-src/tesseract-master/training/text2image --fonts_dir=/usr/share/fonts --font=DejaVu Serif --outputbase=/tmp/font_tmp.mopgCYHqsF/sample_text.txt --text=/tmp/font_tmp.mopgCYHqsF/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.mopgCYHqsF
Rendered page 0 to file /tmp/font_tmp.mopgCYHqsF/sample_text.txt.tif

=== Phase I: Generating training images ===
Rendering using DejaVu Serif
which: no text2image in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
which: no text2image in (./api)
[Wed Sep 27 20:25:09 PDT 2017] /root/tesseract-src/tesseract-master/training/text2image --fontconfig_tmpdir=/tmp/font_tmp.mopgCYHqsF --fonts_dir=/usr/share/fonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0 --max_pages=3 --font=DejaVu Serif --text=../langdata/eng/eng.training_text
Rendered page 0 to file /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0.tif
Rendered page 1 to file /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0.tif

=== Phase UP: Generating unicharset and unichar properties files ===
which: no unicharset_extractor in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
which: no unicharset_extractor in (./api)
[Wed Sep 27 20:25:10 PDT 2017] /root/tesseract-src/tesseract-master/training/unicharset_extractor --output_unicharset /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset --norm_mode 1 /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0.box
Extracting unicharset from box file /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0.box
Other case É of é is not in unicharset
Wrote unicharset file /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset
which: no set_unicharset_properties in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
which: no set_unicharset_properties in (./api)
[Wed Sep 27 20:25:10 PDT 2017] /root/tesseract-src/tesseract-master/training/set_unicharset_properties -U /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset -O /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset -X /tmp/tmp.nqgcR2lnuC/eng/eng.xheights --script_dir=../langdata
Loaded unicharset of size 111 from file /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset
Setting unichar properties
Other case É of é is not in unicharset
Setting script properties
Warning: properties incomplete for index 25 = ~
Writing unicharset to file /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset

=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=../tessdata
which: no tesseract in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
[Wed Sep 27 20:25:10 PDT 2017] /root/tesseract-src/tesseract-master/api/tesseract /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0.tif /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0 lstm.train
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Page 2
Loaded 51/51 pages (1-51) of document /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0.lstmf

=== Constructing LSTM training data ===
which: no combine_lang_model in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
which: no combine_lang_model in (./api)
[Wed Sep 27 20:25:12 PDT 2017] /root/tesseract-src/tesseract-master/training/combine_lang_model --input_unicharset /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset --script_dir ../langdata --words ../langdata/eng/eng.wordlist --numbers ../langdata/eng/eng.numbers --puncs ../langdata/eng/eng.punc --output_dir ../tesstutorial/engeval --lang eng
Loaded unicharset of size 111 from file /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset
Setting unichar properties
Other case É of é is not in unicharset
Setting script properties
Config file is optional, continuing...
Failed to read data from: ../langdata/eng/eng.config
Null char=2
Invalid format in radical table at line 0: 19886 3 23 6 3
Creation of encoded unicharset failed!!
Error writing recoder!!
Reducing Trie to SquishedDawg
Error during conversion of wordlists to DAWGs!!
Moving /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0.lstmf to ../tesstutorial/engeval

Completed training for language 'eng'
</pre>

which version of tesseract do you use? You are getting the error related to the following


https://github.com/tesseract-ocr/tesseract/blob/a2a72d7ca78a3bb3798a02a2ba5188e255c2a0f7/ccutil/unicharcompress.cpp#L79

https://github.com/tesseract-ocr/langdata/blob/master/radical-stroke.txt

The first line in radical-stroke.txt is
19886 3 23 6 3
and
your error line says

Invalid format in radical table at line 0: 19886 3 23 6 3


So, there is a mismatch between the program that you are using and the data.

I am using the latest version of code from github ...

 tesseract -v
tesseract 4.00.00alpha
 leptonica-1.74.4
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 Found AVX
 Found SSE


--------------------
Please check whether you have multiple versions/old versions of the program.



ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Thu, Sep 28, 2017 at 8:56 AM, ivanzz1001 <notifications@github.com>
wrote:

> @Shreeshrii <https://github.com/shreeshrii> I trained eng, it also has
> the same problem:
>
>  [root@localhost tesseract-master]# training/tesstrain.sh --fonts_dir /usr/share/fonts --lang eng --linedata_only \
> >   --noextract_font_properties --langdata_dir ../langdata \
> >   --exposures "0" \
> >   --fontlist "DejaVu Serif" \
> >   --tessdata_dir ../tessdata --output_dir ../tesstutorial/engeval
>
> === Starting training for language 'eng'
> which: no text2image in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
> which: no text2image in (./api)
> [Wed Sep 27 20:25:03 PDT 2017] /root/tesseract-src/tesseract-master/training/text2image --fonts_dir=/usr/share/fonts --font=DejaVu Serif --outputbase=/tmp/font_tmp.mopgCYHqsF/sample_text.txt --text=/tmp/font_tmp.mopgCYHqsF/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.mopgCYHqsF
> Rendered page 0 to file /tmp/font_tmp.mopgCYHqsF/sample_text.txt.tif
>
> === Phase I: Generating training images ===
> Rendering using DejaVu Serif
> which: no text2image in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
> which: no text2image in (./api)
> [Wed Sep 27 20:25:09 PDT 2017] /root/tesseract-src/tesseract-master/training/text2image --fontconfig_tmpdir=/tmp/font_tmp.mopgCYHqsF --fonts_dir=/usr/share/fonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0 --max_pages=3 --font=DejaVu Serif --text=../langdata/eng/eng.training_text
> Rendered page 0 to file /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0.tif
> Rendered page 1 to file /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0.tif
>
> === Phase UP: Generating unicharset and unichar properties files ===
> which: no unicharset_extractor in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
> which: no unicharset_extractor in (./api)
> [Wed Sep 27 20:25:10 PDT 2017] /root/tesseract-src/tesseract-master/training/unicharset_extractor --output_unicharset /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset --norm_mode 1 /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0.box
> Extracting unicharset from box file /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0.box
> Other case É of é is not in unicharset
> Wrote unicharset file /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset
> which: no set_unicharset_properties in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
> which: no set_unicharset_properties in (./api)
> [Wed Sep 27 20:25:10 PDT 2017] /root/tesseract-src/tesseract-master/training/set_unicharset_properties -U /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset -O /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset -X /tmp/tmp.nqgcR2lnuC/eng/eng.xheights --script_dir=../langdata
> Loaded unicharset of size 111 from file /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset
> Setting unichar properties
> Other case É of é is not in unicharset
> Setting script properties
> Warning: properties incomplete for index 25 = ~
> Writing unicharset to file /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset
>
> === Phase E: Generating lstmf files ===
> Using TESSDATA_PREFIX=../tessdata
> which: no tesseract in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
> [Wed Sep 27 20:25:10 PDT 2017] /root/tesseract-src/tesseract-master/api/tesseract /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0.tif /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0 lstm.train
> Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
> Page 1
> Page 2
> Loaded 51/51 pages (1-51) of document /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0.lstmf
>
> === Constructing LSTM training data ===
> which: no combine_lang_model in (/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.141-1.b16.el7_3.x86_64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
> which: no combine_lang_model in (./api)
> [Wed Sep 27 20:25:12 PDT 2017] /root/tesseract-src/tesseract-master/training/combine_lang_model --input_unicharset /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset --script_dir ../langdata --words ../langdata/eng/eng.wordlist --numbers ../langdata/eng/eng.numbers --puncs ../langdata/eng/eng.punc --output_dir ../tesstutorial/engeval --lang eng
> Loaded unicharset of size 111 from file /tmp/tmp.nqgcR2lnuC/eng/eng.unicharset
> Setting unichar properties
> Other case É of é is not in unicharset
> Setting script properties
> Config file is optional, continuing...
> Failed to read data from: ../langdata/eng/eng.config
> Null char=2
> Invalid format in radical table at line 0: 19886 3 23 6 3
> Creation of encoded unicharset failed!!
> Error writing recoder!!
> Reducing Trie to SquishedDawg
> Error during conversion of wordlists to DAWGs!!
> Moving /tmp/tmp.nqgcR2lnuC/eng/eng.DejaVu_Serif.exp0.lstmf to ../tesstutorial/engeval
>
> Completed training for language 'eng'
>
> which version of tesseract do you use?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1147#issuecomment-332717337>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o9ooGcLZou1zU4_KONg1VHqlQIuYks5smxH1gaJpZM4PfFg_>
> .
>
 I checked that I have only one version. And On a new system, I retried the process and met the same problem @Shreeshrii  @amitdo  I git clone the langdata directory to Linux and now it seems OK. The strange problem may be caused by: I git clone the langdata to Windows, and then use WinSCP to transfer the langdata to Linux(I can make sure the langdata is the latest as @Shreeshrii let me check -- I re-git-cloned the latest langdata) OK, it might be related to Windows EOL vs Unix EOL.
Maybe some WinSCP setting changes it.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Thu, Sep 28, 2017 at 2:32 PM, ivanzz1001 <notifications@github.com>
wrote:

> @Shreeshrii <https://github.com/shreeshrii> @amitdo
> <https://github.com/amitdo> I git clone the langdata directory to Linux
> and now it seems OK. The strange problem may be caused by: I git clone the
> langdata to Windows, and then use WinSCP to transfer the langdata to
> Linux(I can make sure the langdata is the latest as @Shreeshrii
> <https://github.com/shreeshrii> let me check -- I re-git-cloned the
> latest langdata)
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1147#issuecomment-332775119>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oylefg8kyUaUHb69luvSysm16aMxks5sm2C2gaJpZM4PfFg_>
> .
>
 @Shreeshrii  When I use the following:
<pre>
mkdir -p ~/tesstutorial/engoutput
training/lstmtraining --debug_interval 100 \
  --traineddata ~/tesstutorial/engtrain/eng/eng.traineddata \
  --net_spec '[1,36,0,1 Ct3,3,16 Mp3,3 Lfys48 Lfx96 Lrx96 Lfx256 O1c111]' \
  --model_output ~/tesstutorial/engoutput/base --learning_rate 20e-4 \
  --train_listfile ~/tesstutorial/engtrain/eng.training_files.txt \
  --eval_listfile ~/tesstutorial/engeval/eng.training_files.txt \
  --max_iterations 5000 &>~/tesstutorial/engoutput/basetrain.log
</pre>
It needs "engtrain" and "engeval". What's the difference between the two? And I found that the commands using to generate them looks likely the same except the --fontlist option:
<pre>
// engtrain
training/tesstrain.sh --fonts_dir /usr/share/fonts --lang eng --linedata_only \
  --noextract_font_properties --langdata_dir ../langdata \
  --tessdata_dir ./tessdata --output_dir ~/tesstutorial/engtrain

//eval data for the 'Impact' font:
training/tesstrain.sh --fonts_dir /usr/share/fonts --lang eng --linedata_only \
  --noextract_font_properties --langdata_dir ../langdata \
  --tessdata_dir ./tessdata \
  --fontlist "Impact Condensed" --output_dir ~/tesstutorial/engeval
</pre>

The "engtrain" likely will train all the fonts in /usr/share/fonts and the fonts assigned in training/language-specific.sh:
<pre>
CHI_SIM_FONTS=( \
    "AR PL UKai CN" \
    "AR PL UMing Patched Light" \
    "Arial Unicode MS" \
    "Arial Unicode MS Bold" \
    "WenQuanYi Zen Hei Medium" \
    )
</pre>
Here some of the CHI_SIM_FONTS that haven't been installed, so it cause some errors. Do I have to install all the CHI_SIM_FONTS? And I just want to know why we need "engtrain" and "engeval" ("chi_simtrain" and "chi_simeval") at the same time? engtrain - lists all LSTMF files that will be used for doing LSTM training
engeval - lists any LSTMF files that will be used for doing OCR evaluation
while training

Usually, your fontlist for training will be larger than the ones used for
eval



ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Fri, Sep 29, 2017 at 3:51 PM, ivanzz1001 <notifications@github.com>
wrote:

> @Shreeshrii <https://github.com/shreeshrii> When I use the following:
>
> mkdir -p ~/tesstutorial/engoutput
> training/lstmtraining --debug_interval 100 \
>   --traineddata ~/tesstutorial/engtrain/eng/eng.traineddata \
>   --net_spec '[1,36,0,1 Ct3,3,16 Mp3,3 Lfys48 Lfx96 Lrx96 Lfx256 O1c111]' \
>   --model_output ~/tesstutorial/engoutput/base --learning_rate 20e-4 \
>   --train_listfile ~/tesstutorial/engtrain/eng.training_files.txt \
>   --eval_listfile ~/tesstutorial/engeval/eng.training_files.txt \
>   --max_iterations 5000 &>~/tesstutorial/engoutput/basetrain.log
>
> It needs "engtrain" and "engeval". What's the difference between the two?
> And I found that the commands using to generate them looks likely the same
> except the --fontlist option:
>
> // engtrain
> training/tesstrain.sh --fonts_dir /usr/share/fonts --lang eng --linedata_only \
>   --noextract_font_properties --langdata_dir ../langdata \
>   --tessdata_dir ./tessdata --output_dir ~/tesstutorial/engtrain
>
> //eval data for the 'Impact' font:
> training/tesstrain.sh --fonts_dir /usr/share/fonts --lang eng --linedata_only \
>   --noextract_font_properties --langdata_dir ../langdata \
>   --tessdata_dir ./tessdata \
>   --fontlist "Impact Condensed" --output_dir ~/tesstutorial/engeval
>
> The "engtrain" likely will train all the fonts in /usr/share/fonts and the
> fonts assigned in training/language-specific.sh:
>
> CHI_SIM_FONTS=( \
>     "AR PL UKai CN" \
>     "AR PL UMing Patched Light" \
>     "Arial Unicode MS" \
>     "Arial Unicode MS Bold" \
>     "WenQuanYi Zen Hei Medium" \
>     )
>
> Here some of the CHI_SIM_FONTS that haven't been installed, so it cause
> some errors. Do I have to install all the CHI_SIM_FONTS? And I just want to
> know why we need "engtrain" and "engeval" at the same time?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1147#issuecomment-333090078>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o2r_vLqRjkZXVWgbGHE9s7dbZ8f-ks5snMSTgaJpZM4PfFg_>
> .
>
 Do I have to install all the fonts in CHI_SIM_FONTS(training/language-specific.sh):
<pre>
CHI_SIM_FONTS=( \
    "AR PL UKai CN" \
    "AR PL UMing Patched Light" \
    "Arial Unicode MS" \
    "Arial Unicode MS Bold" \
    "WenQuanYi Zen Hei Medium" \
    )
</pre> >Do I have to install all the fonts in CHI_SIM_FONTS(training/
language-specific.sh):

No, you can use whichever fonts that you want to train on. You can give
multiple fonts as part of the command with --fontlist

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Fri, Sep 29, 2017 at 4:33 PM, ivanzz1001 <notifications@github.com>
wrote:

> Do I have to install all the fonts in CHI_SIM_FONTS(training/
> language-specific.sh):
>
> CHI_SIM_FONTS=( \
>     "AR PL UKai CN" \
>     "AR PL UMing Patched Light" \
>     "Arial Unicode MS" \
>     "Arial Unicode MS Bold" \
>     "WenQuanYi Zen Hei Medium" \
>     )
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1147#issuecomment-333097787>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o69sN6dKBPFcAXnescSQKyDzcJo4ks5snM6fgaJpZM4PfFg_>
> .
>
 @Shreeshrii  @amitdo When I trained the chi_sim, how do I set the net_spec flags? 
<pre>
--net_spec '[1,36,0,1 Ct3,3,16 Mp3,3 Lfys48 Lfx96 Lrx96 Lfx256 O1c111]'
</pre>
what's the meaning?

And I execute the following command:
<pre>
training/combine_tessdata -d tessdata/chi_sim.traineddata 
Version string:4.00.00alpha:chi_sim:synth20170629:[1,48,0,1Ct3,3,16Mp3,3Lfys64Lfx96Lrx96Lfx512O1c1]
0:config:size=1966, offset=192
17:lstm:size=12152851, offset=2158
18:lstm-punc-dawg:size=282, offset=12155009
19:lstm-word-dawg:size=590634, offset=12155291
20:lstm-number-dawg:size=82, offset=12745925
21:lstm-unicharset:size=258834, offset=12746007
22:lstm-recoder:size=72494, offset=13004841
23:version:size=84, offset=13077335
</pre>
It seems that the net_spec  is [1,48,0,1 Ct3,3,16 Mp3,3 Lfys64 Lfx96 Lrx96 Lfx512 O1c1], Here the last value is "O1c1"? (not O1c111?). It seems that the last two "1"  represent the network depth, so If I set it to O1c111, then the depth is 11, is the depth too deeper? 

Is It OK that I ask the question here? or anywhere else is proper?  >>It seems that the net_spec is [1,48,0,1 Ct3,3,16 Mp3,3 Lfys64 Lfx96 Lrx96
Lfx512 O1c1], Here the last value is "O1c1"? (not O1c111?)

That last number is a dummy. It is overridden by the number of characters
in the unicharset.



ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Oct 11, 2017 at 5:44 PM, Amit D. <notifications@github.com> wrote:

> https://github.com/tesseract-ocr/tesseract/wiki/VGSLSpecs
>
> Is It OK that I ask the question here? or anywhere else is proper?
>
> The right place to ask this kind of question is our forum
> <https://groups.google.com/d/forum/tesseract-ocr>.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1147#issuecomment-335789942>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o3KfQoOIJxQ3lJ72LUdOMdfJJqOtks5srLEygaJpZM4PfFg_>
> .
>
  Similar problem

https://github.com/tesseract-ocr/tesseract/issues/590  Are you trying to build with cppan? Please, see this page for build instructions https://github.com/tesseract-ocr/tesseract/wiki/Compiling#windows What is your system version? Are you using windows 7?
 And what is your account name? Is it in russian? Windows user account. Do you use the latest cmake? It's ok to have manual fixes. But as you can see, windows build bots are fine. So there are some unusual things in your system setup. > so i just manually added all required libraries 

It was added during 3.05.

> so i just manually added all required libraries 

Cppan is developed to do this for you. Please, use tesseract user forum for asking support for your project.  Please explain, why the current master does apparently not work together with https://github.com/tesseract-ocr/tessdata_best

I got this: 
```
Failed loading language 'deu'
Tesseract couldn't load any languages!
Could not initialize tesseract.
ObjectCache(0x7f0a269c9800)::~ObjectCache(): WARNING! LEAK! object 0x1a51780 still has count 1 (id /usr/local/share/tessdata/deu.traineddatalstm-punc-dawg)
ObjectCache(0x7f0a269c9800)::~ObjectCache(): WARNING! LEAK! object 0x28c1b40 still has count 1 (id /usr/local/share/tessdata/deu.traineddatalstm-word-dawg)
ObjectCache(0x7f0a269c9800)::~ObjectCache(): WARNING! LEAK! object 0x28c2470 still has count 1 (id /usr/local/share/tessdata/deu.traineddatalstm-number-dawg)
```

 It does work with the old tessdata. @amitdo I simply replaced (exchanged) my existing .../tessdata with the the new .../tessdata_best. Tesseract does not work then.

What is changed, so that this fails?
 @amitdo Thanks, I do know the tessdata configuration possibilities. In my case the reason was, that I checked out tessdata_best from github, but forgot to copy /tessdata files and subdirectories from the tesseract code directory. I simply forgot this.

Perhaps this can be improved: separation (split) of /tessdata(config-files) and /tessdata(language) files. Do you understand, what I mean?

I opened this issue and close it now. I used ```oem=2``` !!!  Now finally, with ```oem=1``` it works. AFAIK, tessdata_best and tessdata_fast have only LSTM models in them, so
--oem 1 (LSTM) and --oem 3 (default) should work, as long as the config
file is not using --oem 0 or --oem 2.

If you want the legacy models, use tessdata.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Sep 20, 2017 at 1:19 PM, Wikinaut <notifications@github.com> wrote:

> Now finally, with oem=1 it works.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1143#issuecomment-330773170>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o1SVwdL993fRJm_Sd2MF-6tdmFYdks5skMNxgaJpZM4Pc2bx>
> .
>
  ```
In file included from ambigs.h:26:0,
                 from ambigs.cpp:21:
unichar.h:164:10: error: 'string' does not name a type
   static string UTF32ToUTF8(const std::vector<char32>& str32);
          ^~~~~~
In file included from ambigs.h:27:0,
                 from ambigs.cpp:21:
unicharset.h:241:10: error: 'string' does not name a type
   static string CleanupString(const char* utf8_str) {
          ^~~~~~
unicharset.h:244:10: error: 'string' does not name a type
   static string CleanupString(const char* utf8_str, int length);
          ^~~~~~
unicharset.h: In member function 'void UNICHARSET::unichar_insert_backwards_compatible(const char*)':
unicharset.h:265:5: error: 'string' was not declared in this scope
     string cleaned = CleanupString(unichar_repr);
     ^~~~~~
unicharset.h:265:5: note: suggested alternatives:
In file included from /usr/include/c++/6/string:39:0,
                 from /usr/include/c++/6/stdexcept:39,
                 from /usr/include/c++/6/array:39,
                 from /usr/include/c++/6/tuple:39,
                 from /usr/include/c++/6/functional:55,
                 from helpers.h:30,
                 from genericvector.h:29,
                 from params.h:25,
                 from tprintf.h:23,
                 from ambigs.h:25,
                 from ambigs.cpp:21:
/usr/include/c++/6/bits/stringfwd.h:74:33: note:   'std::__cxx11::string'
   typedef basic_string<char>    string;
                                 ^~~~~~
/usr/include/c++/6/bits/stringfwd.h:74:33: note:   'std::__cxx11::string'
In file included from ambigs.h:27:0,
                 from ambigs.cpp:21:
unicharset.h:266:9: error: 'cleaned' was not declared in this scope
     if (cleaned != unichar_repr) {
         ^~~~~~~
Makefile:584: die Regel für Ziel „ambigs.lo“ scheiterte
make[3]: *** [ambigs.lo] Fehler 1
make[3]: Verzeichnis „/work/usr/local/src/tesseract/ccutil“ wird verlassen
Makefile:626: die Regel für Ziel „all-recursive“ scheiterte
make[2]: *** [all-recursive] Fehler 1
make[2]: Verzeichnis „/work/usr/local/src/tesseract/ccutil“ wird verlassen
Makefile:481: die Regel für Ziel „all-recursive“ scheiterte
make[1]: *** [all-recursive] Fehler 1
make[1]: Verzeichnis „/work/usr/local/src/tesseract“ wird verlassen
Makefile:389: die Regel für Ziel „all“ scheiterte
make: *** [all] Fehler 2
```
 I started from scratch ( .-/autogen.sh ; ./configure --enable-debug; make)  Seems to work. @stweil I apologize for my bug reports. But tesseract is a kind of PITA. When you want to build it after a while of not following the changes, building fails. Debian 9: make --> libtool:   error: '/usr/lib/x86_64-linux-gnu/libtiff.la' is not a valid libtool archive

sudo apt install libtiff-dev
libtiff5-dev ist schon die neueste Version (4.0.8-2+deb9u1).


 @stweil Stefan: please assist. Now we have a 'make' issue on debian9.  ...and the latest tesseract stable version is [3.05.01](https://github.com/tesseract-ocr/tesseract/releases) We do not provide support for 3rd party sw (e.g. python) => you need to be able replicate problem with C++ or C. 
I created some examples of using API in python, but it is a little bit tricky sometimes and without official support...  
Please use tesseract user forum instead (there are more people with more experiences)  Good idea.

Google's tests probably use testdata as the directory, so the submodule can be pulled in under that name. I can very easily imagine 175MB of test data.   Fixes issue https://github.com/tesseract-ocr/tesseract/issues/1114 @zdenop Stefan is right. 

I reverted this change and the training process is still working now. So, it must have been something else that changed in system for it to work.

Please revert. Thanks!  Thanks for the report. You are right, Orientation Script Detection (OSD) only works with the legacy recognizer. Discussing with Ray. The answer might be to delete osd.traineddata from tessdata_best and tessdata_fast repositories. Does this copy of osd.traineddata have the same problem, or not?

https://github.com/tesseract-ocr/tessdata/blob/3a94ddd47be01fd897cbe31f05cbd2301454cf8a/best/osd.traineddata 



/mnt/c/Users/User/shree# combine_tessdata -u osd.traineddata osd.
Extracting tessdata components from osd.traineddata
Wrote osd.lstm
Wrote osd.lstm-unicharset
Wrote osd.lstm-recoder
Wrote osd.version
Version string:4.00.00alpha:osd:synth20170629:[1,48,0,1Ct3,3,16Mp3,3Lfys64Lfx96Lrx96Lfx384O1c1]
17:lstm:size=7409547, offset=192
21:lstm-unicharset:size=7991, offset=7409739
22:lstm-recoder:size=715, offset=7417730
23:version:size=80, offset=7418445

https://github.com/tesseract-ocr/tessdata/blob/3a94ddd47be01fd897cbe31f05cbd2301454cf8a/best/osd.traineddata

only has the lstm components. See https://github.com/tesseract-ocr/tesseract/issues/1132

The osd.traineddata file from tessdata repo (uploaded in Nov 2016) has legacy components and works ok. As per discussion with Ray, I have taken osd.traineddata from tessdata and copied it to both tessdata_fast and tessdata_best. This should resolve the problem and is the best we can do today.  Some day in the future, hopefully, there will be an Orientation Script Dectector (OSD) that works with the LSTM recognizer.  Since there are now three possible locations of tessdata files,

```
https://github.com/tesseract-ocr/tessdata_best
https://github.com/tesseract-ocr/tessdata_fast
and
https://github.com/tesseract-ocr/tessdata
```

clarify the usage of TESSDATA_PREFIX and tessdata-dir.

Related: https://github.com/tesseract-ocr/tesseract/commit/e66d43390782f056b9be6e4aee4bf35c214a2f2d#diff-c2f87d92d6aa4f0f542b36a6e5c41161

+ * @param argv0 - paths to the directory with language files and config files.
 + * An actual value of argv0 is used if not NULL, otherwise TESSDATA_PREFIX is
 + * used if not NULL, next try to use compiled in -DTESSDATA_PREFIX. If previous
 + * is not sucessul - use current directory. >Should tessdata_best and tessdata_fast be Git submodules of tessdata

I remember reading a comment from @theraysmith why using best/eng etc will not work .. something to do with sublanguages being invoked via the config file. @stweil You raise some very good points, both about data redundancy and about git submodules. Ray told me he's going to think about over the weekend.    tesseract imagename|stdin outputbase|stdout [options...] [configfile...]

OCR options:
  --tessdata-dir PATH   Specify the location of tessdata path.
  --user-words PATH     Specify the location of user words file.
  --user-patterns PATH  Specify the location of user patterns file.
  -l LANG[+LANG]        Specify language(s) used for OCR.
  -c VAR=VALUE          Set value for config variables.
                        Multiple -c arguments are allowed.
  --psm NUM             Specify page segmentation mode.
  --oem NUM             Specify OCR Engine mode.
NOTE: These options must occur before any configfile.

```
 --tessdata-dir is  with hyphen, not underscore
```  eng and osd traineddata files are required for default functioning of tesseract.
Added option to download the files with --no-clobber option and copy to tessdata directory
Removed option related to langdata, as tesseract does not install all langdata files @stweil Please review and correct. Thanks! The URL for the traineddata files can be changed to use files from tessdata_fast repo, when they become available. >Currently Tesseract requires eng.traineddata even if someone only wants to get the Tesseract version or the list of available languages. I don't think that this is satisfying.
Tesseract functions which are unrelated to eng.traineddata should work without it.

I agree.

>I wonder whether it would be better to get one which supports both the old and the new recognizer (only as long as both are supported, of course).

You mean to use the original 4.0 traineddata rather than best. I will make that change. ```
make engosddata-install
wget  -nc https://github.com/tesseract-ocr/tessdata/raw/master/eng.traineddata
--2017-09-14 21:17:15--  https://github.com/tesseract-ocr/tessdata/raw/master/eng.traineddata
Resolving github.com (github.com)... 192.30.255.113, 192.30.255.112
Connecting to github.com (github.com)|192.30.255.113|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://raw.githubusercontent.com/tesseract-ocr/tessdata/master/eng.traineddata [following]
--2017-09-14 21:17:17--  https://raw.githubusercontent.com/tesseract-ocr/tessdata/master/eng.traineddata
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.192.133, 151.101.0.133, 151.101.64.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.192.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 31873501 (30M) [application/octet-stream]
Saving to: ‘eng.traineddata’

100%[===============================================================================================================================>] 3,18,73,501 2.86MB/s   in 11s

2017-09-14 21:17:29 (2.72 MB/s) - ‘eng.traineddata’ saved [31873501/31873501]

wget  -nc https://github.com/tesseract-ocr/tessdata/raw/master/osd.traineddata
--2017-09-14 21:17:29--  https://github.com/tesseract-ocr/tessdata/raw/master/osd.traineddata
Resolving github.com (github.com)... 192.30.255.112, 192.30.255.113
Connecting to github.com (github.com)|192.30.255.112|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://raw.githubusercontent.com/tesseract-ocr/tessdata/master/osd.traineddata [following]
--2017-09-14 21:17:30--  https://raw.githubusercontent.com/tesseract-ocr/tessdata/master/osd.traineddata
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 10562727 (10M) [application/octet-stream]
Saving to: ‘osd.traineddata’

100%[===============================================================================================================================>] 1,05,62,727 2.64MB/s   in 5.0s

2017-09-14 21:17:36 (2.03 MB/s) - ‘osd.traineddata’ saved [10562727/10562727]

cp   eng.traineddata osd.traineddata /usr/local/share/tessdata
``` @stweil 

Should this be included as part of the default `make` and `make install` for the project?

If so, tesseract/Makefile.am will also need a change. Debian package building uses 'make install' and network access is forbidden
during that operation.
 https://packages.ubuntu.com/zesty/tesseract-ocr

dependencies include:

tesseract-ocr-eng (>= 3.01~)
tesseract-ocr language files for English
tesseract-ocr-equ
tesseract-ocr language files for equations
tesseract-ocr-osd
tesseract-ocr language files for script and orientation @stweil We are changing how the official Debian packages work. I'm collaborating with Александр Поздняков who has already done a terrific job making a PPA. Debian Experimental is the work in progress for turning his PPA work into official packages. See links below for details. Any questions?

https://github.com/AlexanderP/dsc-file/tree/master/debian-tesseract-lang
https://github.com/AlexanderP/dsc-file/tree/master/debian-tesseract

"Is there a "standard" Makefile target to get files needed for the installation from the internet?" No. We package the traineddata files just like we package source code. There is no network activity at package build time. 

"Related: would it make sense to add the Debian rules to the Tesseract repository?" Maybe, maybe not, but there is enough going on right now that I don't want to even think about it. Priority is to get 4.x packages working and shipping to users.
 Jeff, 
Thanks for the info regarding packaging. Great to know that 4.x will be shipping soon.

Please see https://github.com/tesseract-ocr/tesseract/issues/1133 and 1132 - regarding the osd.traineddata files. Also see https://github.com/tesseract-ocr/tesseract/issues/1131
regarding TESSDATA_PREFIX and tessdata-dir

What will be the tessdata file structure under debian?
Will users be able to install both tesseract 3 and tesseract 4?

 _What will be the tessdata file structure under debian?_
Current: /usr/share/tesseract-ocr/tessdata
Upcoming: /usr/share/tesseract-ocr/4.00/tessdata/

_Will users be able to install both tesseract 3 and tesseract 4?_
Normal users will install Tesseract packages via apt-get. Their only  option will be Tesseract 4.x and the fast LSTM traineddata. The current Tesseract 3.x packages will be replaced. Advanced users can of course continue doing anything they want; building from source, choosing alternate traineddata files from github, attempting to install multiple Tesseracts at the same time, etc. Thanks for the info, Jeff.

I assume that training tools will be included in the debian package. If so, please see https://github.com/tesseract-ocr/tesseract/issues/1114.

Also note, https://github.com/tesseract-ocr/tessdata_fast/pull/3 regarding sanskrit traineddata.

You can check with Ray, whether the recommended action is just removing the config file vs. changing the default oem mode in it (since the other config variables probably only apply to legacy engine). @zdenop Should the datadir in github project be made in sync with the structure for debian?

>What will be the tessdata file structure under debian?
Current: /usr/share/tesseract-ocr/tessdata
Upcoming: /usr/share/tesseract-ocr/4.00/tessdata/ Packages have been submitted to Debian Experimental and are awaiting manual approval. These packages are effectively identical to Alexander's Personal Package Archive (PPA) `tesseract` and `tesseract-lang`.

DEBIAN
https://packages.debian.org/source/experimental/tesseract
https://ftp-master.debian.org/new/tesseract-lang_4.00~git15-45ed289-1.html

PPA
https://launchpad.net/~alex-p/+archive/ubuntu/tesseract-ocr
 @stweil We've been using tesseract-ocr as the package name for a very long time, and there is a pretty big installed base. I don't know how big the upgrade headache would be if we changed names. There is some time to consider this, as we wait for manual approval. I'm somewhat wary since I have managed to screw up every single Tesseract transition in Debian so far. Then again, it is probably now or never.

https://qa.debian.org/popcon.php?package=tesseract

The choice of `/usr/share/tesseract-ocr/4.00/tessdata/` was from Alexander and I suspect it is fairly arbitrary. I suspect we could do `/usr/share/tesseract-ocr/4/tessdata/` or `/usr/share/tesseract-ocr/4.0/tessdata/`. The only reason not to continue with  `/usr/share/tesseract-ocr/tessdata/` is as a courtesy to advanced users who wish to install Tessseract 3.x on the same system. Anyway, maybe try installing his PPA, see if you have any comments, and we can discuss with Alexander. Again there is some time as we wait for approval in NEW queue.

https://www.debian.org/doc/debian-policy/index.html#shared-library-support-files

 @jbreiden Jeff, Will you update the langdata repo with files with 4.0x too? Thanks!  Thanks, @stweil.  Similar Issue - https://github.com/tesseract-ocr/tesseract/issues/1015  @stweil Please make the required changes. Thanks!
  ### Environment

* **Tesseract Version**:  tesseract 4.00.00alpha (the latest)
* **Commit Number**:  don't know 
* **Platform**: Linux localhost.localdomain 3.10.0-514.el7.x86_64 #1 SMP Tue Nov 22 16:42:41 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux (CentOS 7.3.1611)

### Current Behavior:
I have a ticket image:
![ticket](https://user-images.githubusercontent.com/29993902/30318159-e18e242a-97de-11e7-8fd5-548f99ca9092.png)

then I use the following command:
<pre>
[root@localhost workspace]# /opt/tesseract4.0/bin/tesseract ticket.png out -l chi_sim
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Warning. Invalid resolution 0 dpi. Using 70 instead.
Estimating resolution as 182
[root@localhost workspace]# cat out.txt 
  
    

本 付 束 方 证 件 号 :
履 吉方 名 称 。， 硕 逢 区 大 良 大 条 和 饮食 店
司 收 吉方 证 件 号 ，440623197507202615
</pre>
But some strange things happened:  It seems that ```tesseract``` can only recognize the top half of the ticket，the down half just can't recognize。 Then I split the ticket into two images: ```ticket_top.png``` and ```ticket_down.png```，and ```tesseract``` still don't recognize the original down half(now that's ticket_down.png). 

the following image is ```ticket_down.png```:
![ticket_down](https://user-images.githubusercontent.com/29993902/30318744-8ace537e-97e0-11e7-994e-cfe516e2100c.png)



### Expected Behavior:

the top half and the down half of the ticket has the same image-features, It should almost have the same behavior.

### Suggested Fix: 
 try with other page segmentation modes.

with --psm 6 and an older version of the code, I get the following output

```
本 付 束 方 证 件 号 : 本 | |

和 “ 适 兴 台 号 |
司 收 吉方 证 件 号 ，440623197507202615 由 机

se 二 EC 二 日
二 谭 潮 3813.00 过

ee 引 记 大 条 可
三 合计 金 砚 大 写 ) : 佐 什 抽 佰 查 拼 元 束 全 色 - 出 后 吕 雪 二 |

全 ET 这
三 汪 村 人 , 各 衣 乐 人

GO 从 人 e
``` It seems that works, thank you   Thanks! I have it on my TODO list, but no time for it ;-)  It was an accidental overwrite. I have made a PR to fix it. https://github.com/tesseract-ocr/tesseract/pull/1118  @wareya thanks . I have same question . In a new best jpn.traineddata some times result text having double of char.  .
 example input : ABCDEFG -> output :ABCDEFFG.
Not many a little only but i can't understand what's wrong with new jpn.traineddata. I don't know but i think in the previous version of best traineddata [4.0] this bug not appear 
https://github.com/tesseract-ocr/tessdata/tree/4.00

 Similar issue - https://github.com/tesseract-ocr/tesseract/issues/1060  Ray is currently updating the repo with new code. You can try a commit from about a week back and check. >The following example shows the command line for training from scratch. Try it with the default training data created with the command-lines above.

Did you create the required traineddata by 

```
training/tesstrain.sh --fonts_dir /usr/share/fonts --lang eng --linedata_only \
  --noextract_font_properties --langdata_dir ../langdata \
  --tessdata_dir ./tessdata --output_dir ~/tesstutorial/engtrain
``` >mgr_.Init(traineddata_path.c_str()):Error:Assert failed:in file ../lstm/lstmtrainer.h, line 110

This error is caused by a missing traineddata  file given in the training command. There is another similar issue - https://github.com/tesseract-ocr/tesseract/issues/1075

It will be nice to have a more user-friendly message.

This issue can be closed and a link added to the other one ( more details in it)  tesseract 4.00.00dev-658-g3493785-2149
 leptonica-1.74.4
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 Found AVX
 Found SSE

---------------
Error while extracting unicharset

```
=== Phase UP: Generating unicharset and unichar properties files ===
[Sat Sep 9 16:08:44 DST 2017] /usr/local/bin/unicharset_extractor --output_unicharset /tmp/tmp.4s8doNdbQW/san_latn/san_latn.unicharset --norm_mode 1 /tmp/tmp.4s8doNdbQW/
san_latn/san_latn.Arial_Unicode_MS.exp0.box /tmp/tmp.4s8doNdbQW/san_latn/san_latn.FreeSerif.exp0.box /tmp/tmp.4s8doNdbQW/san_latn/san_latn.FreeSerif_Italic.exp0.box /tmp
/tmp.4s8doNdbQW/san_latn/san_latn.Sanskrit_2003.exp0.box /tmp/tmp.4s8doNdbQW/san_latn/san_latn.Siddhanta.exp0.box /tmp/tmp.4s8doNdbQW/san_latn/san_latn.Times_New_Roman_I
talic.exp0.box
Extracting unicharset from box file /tmp/tmp.4s8doNdbQW/san_latn/san_latn.Arial_Unicode_MS.exp0.box
Invalid Unicode codepoint: 0xffffffc3
IsValidCodepoint(ch):Error:Assert failed:in file normstrngs.cpp, line 225
ERROR: /tmp/tmp.4s8doNdbQW/san_latn/san_latn.unicharset does not exist or is not readable
``` gdb output

```
Starting program: /usr/local/bin/unicharset_extractor --output_unicharset /tmp/tmp.4s8doNdbQW/san_latn/san_latn.unicharset --norm_mode 1 /tmp/tmp.4s8doNdbQW/san_latn/san
_latn.Arial_Unicode_MS.exp0.box /tmp/tmp.4s8doNdbQW/san_latn/san_latn.FreeSerif.exp0.box /tmp/tmp.4s8doNdbQW/san_latn/san_latn.FreeSerif_Italic.exp0.box /tmp /tmp.4s8doN
dbQW/san_latn/san_latn.Sanskrit_2003.exp0.box /tmp/tmp.4s8doNdbQW/san_latn/san_latn.Siddhanta.exp0.box /tmp/tmp.4s8doNdbQW/san_latn/san_latn.Times_New_Roman_I talic.exp0
.box
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Extracting unicharset from box file /tmp/tmp.4s8doNdbQW/san_latn/san_latn.Arial_Unicode_MS.exp0.box
Invalid Unicode codepoint: 0xffffffc3
IsValidCodepoint(ch):Error:Assert failed:in file normstrngs.cpp, line 225

Program received signal SIGSEGV, Segmentation fault.
ERRCODE::error (this=this@entry=0x673748 <_ZL13ASSERT_FAILED>, caller=caller@entry=0x4384fe "IsValidCodepoint(ch)", action=action@entry=ABORT,
    format=format@entry=0x437f7a "in file %s, line %d") at errcode.cpp:86
86            if (!*p)
(gdb) backtrace
#0  ERRCODE::error (this=this@entry=0x673748 <_ZL13ASSERT_FAILED>, caller=caller@entry=0x4384fe "IsValidCodepoint(ch)", action=action@entry=ABORT,
    format=format@entry=0x437f7a "in file %s, line %d") at errcode.cpp:86
#1  0x000000000040812d in tesseract::IsWhitespace (ch=-61) at normstrngs.cpp:224
#2  0x0000000000403d31 in AddStringsToUnicharset (unicharset=0x7ffffffde140, norm_mode=1, strings=...) at unicharset_extractor.cpp:53
#3  tesseract::Main (argc=<optimized out>, argv=<optimized out>) at unicharset_extractor.cpp:78
#4  0x0000000000403206 in main (argc=<optimized out>, argv=<optimized out>) at unicharset_extractor.cpp:109
(gdb) frame 1
#1  0x000000000040812d in tesseract::IsWhitespace (ch=-61) at normstrngs.cpp:224
224       ASSERT_HOST_MSG(IsValidCodepoint(ch), "Invalid Unicode codepoint: 0x%x\n",
``` I am using the new version of scripts. I have tried with various languages.
Also checked on ubuntu 14.04 since earlier test was on WSL.

Still getting same error. ```
 training/tesstrain.sh \
>   --fonts_dir /home/shree/.fonts \
>   --tessdata_dir ../tessdata \
>   --langdata_dir ../langdata \
>   --lang eng  \
>   --linedata_only \
>   --noextract_font_properties \
>   --exposures "0"    \
>   --fontlist "FreeSerif" \
>   --output_dir ../tesstutorial/engtest

=== Starting training for language 'eng'
[Sat Sep 9 11:24:54 MDT 2017] /home/shree/local/bin/text2image --fonts_dir=/home/shree/.fonts --font=FreeSerif --outputbase=/tmp/font_tmp.2tspxPyW9m/sample_text.txt --text=/tmp/font_tmp.2tspxPyW9m/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.2tspxPyW9m
Rendered page 0 to file /tmp/font_tmp.2tspxPyW9m/sample_text.txt.tif

=== Phase I: Generating training images ===
Rendering using FreeSerif
[Sat Sep 9 11:24:56 MDT 2017] /home/shree/local/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.2tspxPyW9m --fonts_dir=/home/shree/.fonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.qQHsGWJjVT/eng/eng.FreeSerif.exp0 --max_pages=3 --font=FreeSerif --text=../langdata/eng/eng.training_text
Rendered page 0 to file /tmp/tmp.qQHsGWJjVT/eng/eng.FreeSerif.exp0.tif
Rendered page 1 to file /tmp/tmp.qQHsGWJjVT/eng/eng.FreeSerif.exp0.tif

=== Phase UP: Generating unicharset and unichar properties files ===
[Sat Sep 9 11:25:01 MDT 2017] /home/shree/local/bin/unicharset_extractor --output_unicharset /tmp/tmp.qQHsGWJjVT/eng/eng.unicharset --norm_mode 1 /tmp/tmp.qQHsGWJjVT/eng/eng.FreeSerif.exp0.box
Extracting unicharset from box file /tmp/tmp.qQHsGWJjVT/eng/eng.FreeSerif.exp0.box
Invalid Unicode codepoint: 0xffffffe2
IsValidCodepoint(ch):Error:Assert failed:in file normstrngs.cpp, line 225
ERROR: /tmp/tmp.qQHsGWJjVT/eng/eng.unicharset does not exist or is not readable
``` ```
bool IsWhitespace(const char32 ch) {
  ASSERT_HOST_MSG(IsValidCodepoint(ch), "Invalid Unicode codepoint: 0x%x\n",
                  ch);
  return u_isUWhiteSpace(static_cast<UChar32>(ch));
}
```
https://github.com/tesseract-ocr/tesseract/blob/df41eab6aa1726dfe6725284c94693dff6fa1eda/training/normstrngs.cpp#L225 @amitdo Are you able to reproduce this?

Am I the only one facing this issue? @hanikh 

Were you able to run the following command just now without any error?

```
training/tesstrain.sh \
--fonts_dir /usr/share/fonts 
--training_text ./langdata/ara/ara.training_text 
--langdata_dir ./langdata 
--tessdata_dir ./tessdata 
--lang ara 
--linedata_only 
--noextract_font_properties 
--exposures "0" 
--output_dir ~/tesstutorial/aratrain
``` > it seems that there was no problem with using training/tesstrain.sh.

OK. So must be something in my setup causing problem...

I will download a fresh copy of langdata and test again. Tried all fresh install of langdata and tesseract. Still same error.

I am wondering whether this is related to the version of the icu libraries on the system ...

```
    $(ICU_I18N_LIBS) $(ICU_UC_LIBS)
```

Is there a way to check the version of these being used? OK, so I changed the assert to tprintf - now I get a lot of error messages.

For eng,  unicharset is created.
For hin, just the header line is created in unicharset.

```

bool IsValidCodepoint(const char32 ch) {
  // In the range [0, 0xD800) or [0xE000, 0x10FFFF]
  return (static_cast<uinT32>(ch) < 0xD800) || (ch >= 0xE000 && ch <= 0x10FFFF);
}

bool IsWhitespace(const char32 ch) {
//  ASSERT_HOST_MSG(IsValidCodepoint(ch), "Invalid Unicode codepoint: 0x%x\n",
//                  ch);
tprintf("Invalid Unicode codepoint: 0x%x\n", ch);
  return u_isUWhiteSpace(static_cast<UChar32>(ch));
}
```

errors even for the sample text.

```

=== Starting training for language 'eng'
[Tue Sep 12 22:10:49 DST 2017] /usr/local/bin/text2image --fonts_dir=/mnt/c/Users/User/shree/.fonts --font=FreeSerif --outputbase=/tmp/font_tmp.0xN0n5Rd2b/sample_text.txt --text=/tmp/font_tmp.0xN0n5Rd2b/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.0xN0n5Rd2b
Invalid Unicode codepoint: 0x54
Invalid Unicode codepoint: 0x54
Invalid Unicode codepoint: 0x65
Invalid Unicode codepoint: 0x78
Invalid Unicode codepoint: 0x74
Invalid Unicode codepoint: 0xa
Invalid Unicode codepoint: 0x54
Invalid Unicode codepoint: 0x65
Invalid Unicode codepoint: 0x78
Invalid Unicode codepoint: 0x74
Invalid Unicode codepoint: 0x54
Invalid Unicode codepoint: 0x65
Invalid Unicode codepoint: 0x78
Invalid Unicode codepoint: 0x74
Invalid Unicode codepoint: 0xa
Invalid Unicode codepoint: 0x54
Invalid Unicode codepoint: 0x65
Invalid Unicode codepoint: 0x78
Invalid Unicode codepoint: 0x74
Invalid Unicode codepoint: 0xa
Invalid Unicode codepoint: 0x54
Invalid Unicode codepoint: 0x65
Invalid Unicode codepoint: 0x78
Invalid Unicode codepoint: 0x74
Invalid Unicode codepoint: 0x54
Invalid Unicode codepoint: 0x65
Invalid Unicode codepoint: 0x78
Invalid Unicode codepoint: 0x74
Rendered page 0 to file /tmp/font_tmp.0xN0n5Rd2b/sample_text.txt.tif
```
Complete logfile is attached. 

Wondering why it works for @hanikh but not me.


[tesstrain.log.txt](https://github.com/tesseract-ocr/tesseract/files/1296720/tesstrain.log.txt)
 Another error report - https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/fqyYaav6vmk/M8xjpwhpBAAJ @hanikh For me, the change in https://github.com/tesseract-ocr/tesseract/pull/1134/files fixed it. But the PR has not been applied yet.

**## Update: That PR does not fix the problem.**

See https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-330147030 @stweil You are right. 

my PR https://github.com/tesseract-ocr/tesseract/pull/1134/files does not fix it.

There have been other reports of same error, so there is a bug somewhere that needs fix ...

https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/fqyYaav6vmk/M8xjpwhpBAAJ

https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-330022935 @hanikh @stweil

I am checking this again. As the error seems to have come back :-(

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Sep 18, 2017 at 11:27 AM, hanikh <notifications@github.com> wrote:

> @Shreeshrii but your PR removed my error. do I have to change it back.
> yesterday I updated my tesseract. Do I have to use a newer version?
>
> On Mon, Sep 18, 2017 at 9:51 AM, Shreeshrii <notifications@github.com>
> wrote:
>
> > @stweil <https://github.com/stweil> You are right.
> >
> > I reverted my change and training is still working now. So, it must have
> > been something else that caused the problem. my PR
> > https://github.com/tesseract-ocr/tesseract/pull/1134/files does not fix
> > it. I had removed some unneeded software and updated the system - maybe
> > that had something to do with it.
> >
> > However, there have been two other reports of same error -
> >
> > https://groups.google.com/forum/?utm_medium=email&utm_
> > source=footer#!msg/tesseract-ocr/fqyYaav6vmk/M8xjpwhpBAAJ
> >
> > #1114 (comment)
> > <https://github.com/tesseract-ocr/tesseract/issues/1114#
> issuecomment-330022935>
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/1114#
> issuecomment-330131339>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AZFiAejV1sTPtVIC9dvSv9JkOIuiAtiVks5sjf3ygaJpZM4PR9Tr>
> > .
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-330134312>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_ows2dIhgdfdfiVQE3wPzTf4AVclBks5sjgYygaJpZM4PR9Tr>
> .
>
 Is there a way to display the values of ch with different types?

I had tried tprintf , with different format strings. But, it seemed to skip
the assert at that time.

On 18-Sep-2017 12:14 PM, "Stefan Weil" <notifications@github.com> wrote:

> That's a trick: return (ch >= 0 && ch < 0xD800) || (ch >= 0xE000 && ch <=
> 0x10FFFF)would also implement the test for a valid code point. The static
> cast of the signed ch to an unsigned value saves the ch >= 0 test.
>
> A static cast to a negative value changes nothing and could be omitted as
> well. Maybe we should use the explicit code and leave optimisations to the
> compiler.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-330139437>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o8JheRL7HqvhCN4uveD0WJtsZDDsks5sjhExgaJpZM4PR9Tr>
> .
>
 Thanks, @stweil.

Yes, now it shows only the invalid codepoints.

```
=== Phase UP: Generating unicharset and unichar properties files ===
[Mon Sep 18 13:38:23 DST 2017] /usr/local/bin/unicharset_extractor --output_unicharset /tmp/tmp.xtcPbHHD4J/deu/deu.unicharset --norm_mode 1 /tmp/tmp.xtcPbHHD4J/deu/deu.A
rial.exp0.box
Extracting unicharset from box file /tmp/tmp.xtcPbHHD4J/deu/deu.Arial.exp0.box
Invalid Unicode codepoint: -62 = 0xffffffc2
Invalid Unicode codepoint: -17 = 0xffffffef
Invalid Unicode codepoint: -61 = 0xffffffc3
Invalid Unicode codepoint: -61 = 0xffffffc3
Invalid Unicode codepoint: -62 = 0xffffffc2
Invalid Unicode codepoint: -61 = 0xffffffc3
Invalid Unicode codepoint: -30 = 0xffffffe2
Invalid Unicode codepoint: -61 = 0xffffffc3
Invalid Unicode codepoint: -61 = 0xffffffc3
Invalid Unicode codepoint: -61 = 0xffffffc3
Invalid Unicode codepoint: -30 = 0xffffffe2
Invalid Unicode codepoint: -30 = 0xffffffe2
``` @stweil Please see https://github.com/tesseract-ocr/tesseract/issues/1147#issuecomment-331604552 That patch does not compile for me. I guess that's why @ivanzz1001 has not submitted to tesseract 

```
        g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../lstm -I../arch -I../view
er -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil  -I/usr/local/include/leptonica   -pthread -I/usr/include/pango-1.0 -I/usr/include/glib-2.0
-I/usr/lib/x86_64-linux-gnu/glib-2.0/include   -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I/usr/include/pixman-1 -I/usr/i
nclude/freetype2 -I/usr/include/libpng12    -g -O2 -std=c++11 -MT unicharset_extractor.o -MD -MP -MF $depbase.Tpo -c -o unicharset_extractor.o unicharset_extractor.cpp &
&\
        mv -f $depbase.Tpo $depbase.Po
unicharset_extractor.cpp: In function ‘void tesseract::AddStringsToUnicharset(const GenericVector<STRING>&, int, UNICHARSET*)’:
unicharset_extractor.cpp:54:57: error: invalid conversion from ‘char’ to ‘const char*’ [-fpermissive]
         if (normed.empty() || IsUTF8Whitespace(normed[0])) continue;
                                                         ^
In file included from unicharset_extractor.cpp:29:0:
normstrngs.h:82:6: note:   initializing argument 1 of ‘bool tesseract::IsUTF8Whitespace(const char*)’
 bool IsUTF8Whitespace(const char* text);
      ^~~~~~~~~~~~~~~~
make[1]: *** [unicharset_extractor.o] Error 1
make[1]: Leaving directory `/mnt/c/Users/User/shree/tesseract-HEAD/training'
make: *** [training] Error 2
``` Thanks. That seems to work. No error messages or asserts.

@hanikh Please check with this new PR.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sun, Sep 24, 2017 at 12:12 PM, Amit D. <notifications@github.com> wrote:

> @ivanzz1001 <https://github.com/ivanzz1001> sent a PR which includes my
> above fix: #1153 <https://github.com/tesseract-ocr/tesseract/pull/1153>
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-331690886>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_owVyIGWwgmhW21eGta5els6ONV4Fks5slfnZgaJpZM4PR9Tr>
> .
>
 @hanikh

Ray @theraysmith is the correct person to suggest the appropriate commands
for training Arabic and Farsi.

I would say, that since you have a new set of lstmf files and starter
traineddata, experiment with both,

Fine-tune plus-minus command
And
Replace top layer.

Check the wiki for the syntax and make sure that you use the correct file
names and path.

Though, Ray recommended 3600 or so iterations, I think that number is
suitable only for Latin based scripts.


For complex scripts, I have tested with Devanagari, I have to go up to
10000-20000 iteration to get error rate down to 1%.

Will be good if @theraysmith can confirm.

On 03-Oct-2017 11:54 AM, "hanikh" <notifications@github.com> wrote:

> @Shreeshrii
> Now, can I train a new model for Arabic and Farsi using "replacing a few
> layers"?
> I want to replace the last layer and these are the commands I'm going to
> use for farsi (I am using about 250 lines 13 fonts most of them are new)
>
> combine_tessdata -e tessdata/fas.traineddata \
> ~/tesstutorial/newfas_from_fas/fas.lstm
>
>
>
> lstmtraining --old_traineddata ./tessdata/fas.traineddata \
> --continue_from ~/tesstutorial/newfas_from_fas/fas.lstm \
> --traineddata ~/tesstutorial/fastrain/fas/fas.traineddata \
> --append_index 5 --net_spec '[Lfx192]'\
> --model_output ~/tesstutorial/newfas_from_fas/base \
> --train_listfile ~/tesstutorial/fastrain/fas.training_files.txt \
> --max_iterations 3000
>
> On Sun, Sep 24, 2017 at 11:36 AM, Stefan Weil <notifications@github.com>
> wrote:
>
> > No error messages or asserts does not necessarily mean that the new code
> > works. See my comment
> > <https://github.com/tesseract-ocr/tesseract/pull/1153#
> discussion_r140649990>
> > for the pull request.
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/1114#
> issuecomment-331694399>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AZFiAW3U9dW4A0ajTbTt1Jd4ioaxiMVhks5slg2fgaJpZM4PR9Tr>
> > .
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-333751166>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o67_mlxJ8qCoRQGsmWn9E5awVAFvks5sodMfgaJpZM4PR9Tr>
> .
>
 PR : #1153 has multiple commits. Make sure you have the correct one.

Also, this has not been reviewed by @theraysmith so we don't know whether this is the recommended fix for the problem. You have to wait for Ray to update the code.


See
https://github.com/tesseract-ocr/tesseract/search?q=Logistic+output+not+implemented+yet%21&type=Code&utf8=%E2%9C%93

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Oct 4, 2017 at 2:54 PM, hanikh <notifications@github.com> wrote:

> I changed line 53 of unicharset_extractor.cpp to:
> if (normed.empty() || IsUTF8Whitespace(normed.c_str())) continue;
>
> unfortunately, the error still exists
>
> On Wed, Oct 4, 2017 at 12:31 PM, Hanieh Khosravi <hani.khosravi@gmail.com>
> wrote:
>
>
> > @Shreeshrii
> > I used the mentioned commands for replacing top layer and error
> rate=0.01,
> > it is running for about a day and I am just getting this:
> >
> > Logistic output not implemented yet!
> >
> > would you please help me find the problem
> >
> > On Tue, Oct 3, 2017 at 3:58 PM, Shreeshrii <notifications@github.com>
> > wrote:
> >
> >> PR : #1153 <https://github.com/tesseract-ocr/tesseract/pull/1153> has
> >> multiple commits. Make sure you have the correct one.
> >>
> >> Also, this has not been reviewed by @theraysmith
> >> <https://github.com/theraysmith> so we don't know whether this is the
> >> recommended fix for the problem.
> >>
> >> —
> >> You are receiving this because you were mentioned.
> >> Reply to this email directly, view it on GitHub
> >> <https://github.com/tesseract-ocr/tesseract/issues/1114#
> issuecomment-333826072>,
> >> or mute the thread
> >> <https://github.com/notifications/unsubscribe-auth/
> AZFiARRkhp11pQ3p26F6g4mYc6l-0zKmks5soihfgaJpZM4PR9Tr>
> >> .
> >>
> >
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-334099163>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o-BKtIfpc1wBFZ7n_NaI1v8nbBUqks5so07ngaJpZM4PR9Tr>
> .
>
 I tried testing with a one line english training text which has characters that get error

```
e ¢ “ I °  © ® ﬂ
```

Here are the modified debug messages that  I get:

```

Extracting unicharset from box file /tmp/tmp.ou9ZKjVaiJ/eng/eng.Arial.exp0.box
Normalization strings DEBUG 'e'
Normalization normed DEBUG 'e'
Normalization strings DEBUG '¢'
Normalization normed DEBUG '¢'
Invalid Unicode codepoint: -62 = 0xffffffc2
Normalization strings DEBUG '“'
Normalization normed DEBUG '“'
Invalid Unicode codepoint: -30 = 0xffffffe2
Normalization strings DEBUG 'I'
Normalization normed DEBUG 'I'
Normalization strings DEBUG '°'
Normalization normed DEBUG '°'
Invalid Unicode codepoint: -62 = 0xffffffc2
Normalization strings DEBUG '©'
Normalization normed DEBUG '©'
Invalid Unicode codepoint: -62 = 0xffffffc2
Normalization strings DEBUG '®'
Normalization normed DEBUG '®'
Invalid Unicode codepoint: -62 = 0xffffffc2
Normalization strings DEBUG 'ﬂ'
Normalization normed DEBUG 'ﬂ'
Invalid Unicode codepoint: -17 = 0xffffffef
```

Using https://r12a.github.io/apps/conversion/

0x... notation

```
0x65 0x20 0xA2 0x20 0x201C 0x20 0x49 0x20 0xB0 0x20 0x20 0xA9 0x20 0xAE 0x20 0xFB02
```

But the UTF-8 codepoints have some extra values...

```
65 20 C2 A2 20 E2 80 9C 20 49 20 C2 B0 20 20 C2 A9 20 C2 AE 20 EF AC 82
```

This C2, E2, EF etc are showing up as invalid codepoints
 Thanks! Closing the issue.  Thanks! Merged.  What language are you trying to train?

Have you checked whether new trained data is available for it in teesara
repository?

You should try with a newer version of tesseract. Look for tesseract OCR
ppa by alex.



On 06-Sep-2017 8:50 PM, "yazhe wang" <notifications@github.com> wrote:

> Before you submit an issue, please review the guidelines for this
> repository
> <https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md>.
>
> Please report an issue only for a BUG, not for asking questions.
>
> Note that it will be much easier for us to fix the issue if a test case
> that
> reproduces the problem is provided. Ideally this test case should not have
> any
> external dependencies. Provide a copy of the image or link to files for
> the test case.
>
> Please delete this text and fill in the template below.
> ------------------------------
> Environment
>
>    - *Tesseract Version*:
>
> tesseract 3.04.01
>  leptonica-1.73
>   libgif 5.1.2 : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.4 : libopenjp2 2.1.0
>
>
>    -
>
>    *Commit Number*:
>    -
>
>    Install it from ubuntu apt. sudo apt install tesseract-ocr
>    -
>
>    *Platform*:
>
> Linux jeneser-X555LF 4.10.0-33-generic #37~16.04.1-Ubuntu SMP Fri Aug 11 14:07:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
>
> Current Behavior:
>
> When run the following command. An error has occurred.
>
> cntraining lang.fontname.exp0.tr lang.fontname.exp1.tr ...
>
> BUT, continue running commands, all is successfully.
>
> My console:
>
> jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ tesseract hpu.font.exp0.tif hpu.font.exp0 box.train
> Tesseract Open Source OCR Engine v3.04.01 with Leptonica
> Page 1
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 2
> Empty page!!
> Page 3
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 4
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 5
> Empty page!!
> Page 6
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 7
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 2 words
> Page 8
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 9
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 10
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 11
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 12
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 13
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
>    Leaving 2 unlabelled blobs in 0 words.
> Generated training data for 1 words
> Page 14
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 15
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 16
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 17
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 18
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 19
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 20
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 21
> FAIL!
> APPLY_BOXES: boxfile line 1/q ((0,0),(15,20)): FAILURE! Couldn't find a matching blob
> FAIL!
> APPLY_BOXES: boxfile line 2/y ((15,0),(30,20)): FAILURE! Couldn't find a matching blob
> FAIL!
> APPLY_BOXES: boxfile line 3/j ((30,0),(45,20)): FAILURE! Couldn't find a matching blob
> FAIL!
> APPLY_BOXES: boxfile line 4/h ((45,0),(60,20)): FAILURE! Couldn't find a matching blob
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Boxes failed resegmentation:       4
> APPLY_BOXES: Unlabelled word at :Bounding box=(0,0)->(60,20)
>    Found 0 good blobs.
>    1 remaining unlabelled words deleted.
> Generated training data for 0 words
> Page 22
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 23
> FAIL!
> APPLY_BOXES: boxfile line 1/h ((3,0),(17,20)): FAILURE! Couldn't find a matching blob
> FAIL!
> APPLY_BOXES: boxfile line 2/t ((17,0),(31,20)): FAILURE! Couldn't find a matching blob
> FAIL!
> APPLY_BOXES: boxfile line 3/m ((31,0),(45,20)): FAILURE! Couldn't find a matching blob
> FAIL!
> APPLY_BOXES: boxfile line 4/X ((45,0),(59,20)): FAILURE! Couldn't find a matching blob
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Boxes failed resegmentation:       4
> APPLY_BOXES: Unlabelled word at :Bounding box=(3,0)->(60,20)
>    Found 0 good blobs.
>    1 remaining unlabelled words deleted.
> Generated training data for 0 words
> Page 24
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
>    Leaving 2 unlabelled blobs in 0 words.
> Generated training data for 2 words
> Page 25
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 26
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 27
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 28
> row xheight=8.66667, but median xheight = 10
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 29
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> Page 30
> APPLY_BOXES:
>    Boxes read from boxfile:       4
>    Found 4 good blobs.
> Generated training data for 1 words
> jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ unicharset_extractor hpu.font.exp0.box
> Extracting unicharset from hpu.font.exp0.box
> Wrote unicharset file ./unicharset.
> jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mftraining -F font_properties -U unicharset -O hpu.unicharset hpu.font.exp0.tr
> Warning: No shape table file present: shapetable
> Failed to load font_properties from font_properties
> jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mftraining -F font_properties -U unicharset -O hpu.unicharset hpu.font.exp0.tr
> Warning: No shape table file present: shapetable
> Reading hpu.font.exp0.tr ...
> Flat shape table summary: Number of shapes = 45 max unichars = 1 number with multiple unichars = 0
> Warning: no protos/configs for Joined in CreateIntTemplates()
> Warning: no protos/configs for |Broken|0|1 in CreateIntTemplates()
> Warning: no protos/configs for j in CreateIntTemplates()
> Done!
> jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ cntraining hpu.font.exp0.tr
> Reading hpu.font.exp0.tr ...
> Clustering ...
> Clustering error: Matrix inverse failed with error 1.44922
>
> Writing normproto ...
> jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ cntraining hpu.font.exp0.tr
> Reading hpu.font.exp0.tr ...
> Clustering ...
> Clustering error: Matrix inverse failed with error 1.44922
>
> Writing normproto ...
> jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mv normproto hpu.normproto
> jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mv inttemp hpu.inttemp
> jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mv pffmtable hpu.pffmtable
> jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mv shapetable hpu.shapetable
> jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ combine_tessdata hpu.
> Combining tessdata files
> TessdataManager combined tesseract data files.
> Offset for type  0 (hpu.config                ) is -1
> Offset for type  1 (hpu.unicharset            ) is 140
> Offset for type  2 (hpu.unicharambigs         ) is -1
> Offset for type  3 (hpu.inttemp               ) is 2644
> Offset for type  4 (hpu.pffmtable             ) is 331290
> Offset for type  5 (hpu.normproto             ) is 331653
> Offset for type  6 (hpu.punc-dawg             ) is -1
> Offset for type  7 (hpu.word-dawg             ) is -1
> Offset for type  8 (hpu.number-dawg           ) is -1
> Offset for type  9 (hpu.freq-dawg             ) is -1
> Offset for type 10 (hpu.fixed-length-dawgs    ) is -1
> Offset for type 11 (hpu.cube-unicharset       ) is -1
> Offset for type 12 (hpu.cube-word-dawg        ) is -1
> Offset for type 13 (hpu.shapetable            ) is 337236
> Offset for type 14 (hpu.bigram-dawg           ) is -1
> Offset for type 15 (hpu.unambig-dawg          ) is -1
> Offset for type 16 (hpu.params-model          ) is -1
> Output hpu.traineddata created successfully.
>
> Expected Behavior: Suggested Fix:
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1111>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o14vm_v979ohg3RUr43o1ilPxW6Rks5sfrg0gaJpZM4POipi>
> .
>
  Can you please provide user case that demonstrate problem&solution? @zdenop Please see https://github.com/tesseract-ocr/tesseract/issues/781 for user case that demonstrate problem&solution?

This is a problem only with the master branch/4.00.00alpha.  I'm testing with an invoice form image in Japanese with psm =11 ,4 and 6.
Psm = 11 gave best OCR result but some time missing word in low width column (have only one or two char in column).
I have put a red rectangle to missing word place .

Input Image :
![sample_01 jpg_binary](https://user-images.githubusercontent.com/22963463/30015811-55992340-918d-11e7-8bde-87da28ba82b7.jpg)

And OCR Result :
[psm4.txt](https://github.com/tesseract-ocr/tesseract/files/1273919/psm4.txt)
[psm6.txt](https://github.com/tesseract-ocr/tesseract/files/1273917/psm6.txt)
[psm11.txt](https://github.com/tesseract-ocr/tesseract/files/1273918/psm11.txt)

Somebody can tell me how to improve this?
Thanks so much!
 @zmwang-GitHub  thanks ! . Maybe i will try in opencv ,but what's --PSM (character) is ? what is psm are you using in ocr process?
You using opencv to find coordinate and using api->SetRectangle() ?
 But if  using  api->SetRectangle() and psm =10 we need do ocr process for every char and may be very slow  Hi,

Check if you're running the latest cppan client.
Remove your `tesseract/build` dir and re-create it again.
If this does not help, delete `c:\users\u\.cppan\storage\tmp` and re-run your commands.
If this does not help, remove the whole storage and try again.  https://github.com/tesseract-ocr/tesseract/tree/master/testing

has a number of images provided for testing.

Please add the corresponding groundtruth files also. https://github.com/tesseract-ocr/tesseract/pull/1088

adds groundtruth for phototest.tif and eurotext.tif. @amitdo @jbreiden Please add groundtruth for the hebrew images, if available. Thanks! @amitdo Ok. Thanks! 

Closing this.  How are you viewing the output?

Try notepad++ instead of notepad. It is related to the handling of `end of line` marks

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sun, Sep 3, 2017 at 8:08 PM, gluehbire <notifications@github.com> wrote:

> works. strange - but it works. thanks
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1105#issuecomment-326808862>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o75g-44C71QSQOvDYrLLhdJupn2aks5sernggaJpZM4PLLdp>
> .
>
  https://github.com/tesseract-ocr/tesseract/blob/master/tessdata/configs/lstm.train

make sure it is there under configs folder in your tessdata folder.  Duplicate to #1087  Please follow [the guidelines for this repository](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md).  > I built tesseact out of 4.00.00dev

Please try a build with the latest code in github.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sat, Aug 26, 2017 at 6:47 AM, jbreiden <notifications@github.com> wrote:

> Try running Tesseract under strace and see where things first become
> different.
>
> gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=- demo.pdf -c quit  |strace  bin/tesseract stdin demo.ocr -oem 4
> cat demo.tif | strace bin/tesseract stdin demo.ocr -oem 4
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1096#issuecomment-325068909>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o32jwkGq1CEy1wtvKmiRYuN2HEdHks5sb3I4gaJpZM4PCs49>
> .
>
  Thanks @stweil.

On 21-Aug-2017 2:04 PM, "Stefan Weil" <notifications@github.com> wrote:

> Related: 6773e8b
> <https://github.com/tesseract-ocr/tesseract/commit/6773e8b909d7409f7434db67da6dff56090a7eda>.
> @Shreeshrii <https://github.com/shreeshrii>, that commit is no longer
> needed after this pull request.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/1092#issuecomment-323681345>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o2j1sGBa1CopPUmse_sJBknn6J8Pks5saUERgaJpZM4O8_3M>
> .
>
  please read other issues (also closed) before writing new issue.  @theraysmith @stweil 

Please check unittests after applying this PR.

```
autoreconf -fiv
git submodule update --init
export TESSDATA_PREFIX=/prefix/to/path/to/tessdata
make check
``` Also needs updates to Makefile.am Configure.ac in tesseract dir. Will update PR. ```
Making check in unittest
make[1]: Entering directory `/mnt/c/Users/User/shree/tesseract/unittest'
make  libgtest.la libgtest_main.la apiexample_test tesseracttests matrix_test
make[2]: Entering directory `/mnt/c/Users/User/shree/tesseract/unittest'
make[2]: `libgtest.la' is up to date.
make[2]: `libgtest_main.la' is up to date.
make[2]: `apiexample_test' is up to date.
make[2]: `tesseracttests' is up to date.
make[2]: `matrix_test' is up to date.
make[2]: Leaving directory `/mnt/c/Users/User/shree/tesseract/unittest'
make  check-TESTS
make[2]: Entering directory `/mnt/c/Users/User/shree/tesseract/unittest'
make[3]: Entering directory `/mnt/c/Users/User/shree/tesseract/unittest'
PASS: apiexample_test
PASS: tesseracttests
PASS: matrix_test
make[4]: Entering directory `/mnt/c/Users/User/shree/tesseract/unittest'
make[4]: Nothing to be done for `all'.
make[4]: Leaving directory `/mnt/c/Users/User/shree/tesseract/unittest'
============================================================================
Testsuite summary for tesseract 4.00.00dev
============================================================================
# TOTAL: 3
# PASS:  3
# SKIP:  0
# XFAIL: 0
# FAIL:  0
# XPASS: 0
# ERROR: 0
============================================================================
make[3]: Leaving directory `/mnt/c/Users/User/shree/tesseract/unittest'
make[2]: Leaving directory `/mnt/c/Users/User/shree/tesseract/unittest'
make[1]: Leaving directory `/mnt/c/Users/User/shree/tesseract/unittest'
``` >Are all those parts of AM_CPPFLAGS necessary, or did you add them because they might be needed by future tests? Personally I prefer a little different syntax because I think it is easier to maintain:

Ray had referred to the makefile in training and I copied that section from there. I will change it to one per line. The following directions work for testing the apiexample.

```
autoreconf -fiv
git submodule update --init
export TESSDATA_PREFIX=/prefix/to/path/to/tessdata
make check
```

It is possible to change makefile.am and configure.ac to test for the program using pkg-config - please see https://github.com/google/googletest/blob/master/googletest/docs/Pkgconfig.md#autotools  Please provide user case where this is problem  Thanks for the report!
Please download new cppan client (or run `cppan --self-upgrade`) and try to build tesseract again.
(Run `cppan` in tess folder, re-run cmake and try to build in VS.) I check this with vs2017 on windows 10 64bit and it works.  ### Environment

* **Tesseract Version**: Latest / cloned from master
* **Platform**: Windows 10 x64 with VS2017

### Current Behavior:

The compiling section does not explain how to compile under Windows without OpenMP (neither under Linux mind you). How can it be done?

### Expected Behavior:

The compiling section of the wiki should include such informations as they are quite important if the binaries are to be used in a heavily threaded environnement.

### Suggested Fix:

For Linux, add a line in the wiki about using `./configure --disable-openmp` flag (although you can simply use `./configure --help`)

For Windows, add a line explaining how it can be done (I haven't figured out that one yet)

I am more than willing to make a PR for this if you consider it necessary, if not, **how can it be achieved under Windows?**
 @stweil Thank you for the quick response. I am using MSVC. Any parameter for that one? Also how can I set `OMP_THREAD_LIMIT` in Windows?

Doing `SET OMP_THREAD_LIMIT=1` then calling `tesseract.exe` works  @TheSeiko Please try with the changes suggested in https://github.com/tesseract-ocr/tesseract/issues/681#issuecomment-303027906 to see if you get improved recognition of these words without impacting others.
  Please report issue in English  use --oem 1 for the newer lstm engine

use the newly uploaded tessdata/best/chi_sim.traineddata

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sun, Aug 13, 2017 at 2:26 PM, 一路向北 <notifications@github.com> wrote:

> The original image
> https://image.ibb.co/fEkAma/WX20170813_165113_2x.png
>
> tesseract WX20170813_165113_2x.png stdout
> IH640 done
> ﬁﬁiaiﬂﬁma done
> iiiéimﬁiiﬁﬁ done
> ﬁlm: done
> ﬁEEE done
>
> tesseract WX20170813_165113_2x.png stdout -l chi_sim
> 图片640 done
> 每页记录数可配 done
> 选择城市报错 done
> 地图检索 done
> 弹囡宽度 done
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1078>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o9GpuCNcFLMtQ-Hrn-wYZo0AgWvaks5sXrpMgaJpZM4O1oin>
> .
>
 Use the traineddata from
https://github.com/tesseract-ocr/tessdata/tree/master/best

You can try

https://github.com/tesseract-ocr/tessdata/blob/master/best/HanS.traineddata
and
https://github.com/tesseract-ocr/tessdata/blob/master/best/chi_sim.traineddata

Make sure you have tesseract from latest sources in github



ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sun, Aug 13, 2017 at 2:36 PM, 一路向北 <notifications@github.com> wrote:

> tesseract WX20170813_165113_2x.png stdout -l chi_sim
> read_params_file: parameter not found:
>
> Do I need to upgrade tessdata? @Shreeshrii <https://github.com/shreeshrii>
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1078#issuecomment-322030636>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o48H2mkS8HqE0pNTkex27nFZYHuTks5sXryggaJpZM4O1oin>
> .
>
  Are you using the latest source from github for building tesseract? What is your version info, git log info? Also see https://github.com/tesseract-ocr/tesseract/issues/1069
regarding 'Failed to continue from' error That means you have new characters in your training text, so fine tuning
may not work.

On 14-Aug-2017 4:08 PM, "iuriigalaida" <notifications@github.com> wrote:

> After I get latest sourses v4 lstmtraining started work but I almost
> always got errors like
> Encoding of string failed!
> Can't encode transcription:
> Even if I directly set path to unicharset file.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1075#issuecomment-322157912>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_ox6hWfOOzKYP7lTVLo-hmT6EzaRFks5sYCOsgaJpZM4O0iiS>
> .
>
 Unicharset was not attached - 

see https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#training-just-a-few-layers

Have you tried Latin.traineddata - it will have more characters than eng in it. Thanks for the unicharset. I notice it has accented english letters.

1. Test with Latin.traineddata - which is for Latin script not Latin
language (lat).

2. Check that all your additional characters are in best/Latin.traineddata
- use combine_tessdata -u to unpack the traineddata and look at its
unicharset.

I find it easy to sort a copy of the unicharsets and then compare .

3. If Latin.traineddata has all characters you want, then you can do
finetune using Latin.traineddata as the continue_from rather than English.
 Re: 'mgr_.Init(traineddata_path.c_str()):Error:Assert failed:in file ../../../../lstm/lstmtrainer.h, line 110' 

This comes when the path to the traineddata files is incorrect. Check file locations and correct the command for training.  At the moment I have a limited internet access. If you make a pull request I can merge it ;.-)  It would be feasible to add bold and italic attributes by making them a separate output from the model. 
Underline would also be possible.
All these attributes would require changes to the rendering pipeline, and datapath for the ground truth.
Fixed-pitch(monospace), serif and smallcaps would be much more difficult, due to lack of reliable data available for the fonts. It could be possible to re-use the existing fontinfo table for that.
I wouldn't rule it out as impossible, but I will add this request to my list of stoppers for obsoleting the old engine.
I have a bunch of updates to push, which I didn't quite get to before my office move... Yes of course. Just re-order the code in WordFontAttributes. >It would be feasible to add bold and italic attributes by making them a separate output from the model. Underline would also be possible.

You could also take bold/italic into account when people use multiple languages for recognition, because many times the words in the additional language may be emphasized with bold or italics..

For an example, see the image in https://github.com/tesseract-ocr/langdata/pull/4#issuecomment-327760269 where Roman transliteration of Hindi is italicized with English text.

 >it seems to give you font size in the line level

While that would work in most cases, what of an extreme case of text of different size being on the same line - eg. http://www.teach-ict.com/programming/html/intro/step17a.jpg That has always been a problem.
The old code would often output garbage.
The LSTM engine will split the line at such words and recognize them separately, pasting the results back together. It doesn\t give an estimate of the x-height though. The overall accuracy on such images is better though. @theraysmith Please see related issue https://github.com/tesseract-ocr/tesseract/issues/538

regarding recognition problems when an image has many different font sizes in it.  You can use windows binaries linked from
https://github.com/UB-Mannheim/tesseract/wiki

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Thu, Aug 10, 2017 at 9:47 PM, iuriigalaida <notifications@github.com>
wrote:

> I tried to train tesseract v4.0 and got 'combine_lang_model not found'
> error. This code was added 4 days ago so I tried to build latest master and
> got '.cppan/storage/etc/static/generate.cmake:106 (message):
> cppan command '0' not found '. Can somone build and share latest tesseract
> binaries for Windows. Thanks in advance.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1071>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o1WOfX1TDTRm1RTyJ-aE72OC9GiZks5sWy0dgaJpZM4OzqP3>
> .
>
  Please see https://github.com/tesseract-ocr/tesseract/issues/1060#issuecomment-320720945

Try again after making sure that you are using the latest source code as well as traineddata from github. @ahmed-alaa Please note the commit number since you have isolated the problem.

@theraysmith @stweil FYI. > Failed to continue from: ~/tesstutorial/trainplusminus/eng.lstm

Please make sure that the file is there. Rerun the following and  check.

combine_tessdata -e baseline/eng.traineddata \
    ~/tesstutorial/trainplusminus/eng.lstm

 Please close the issue, since it is solved.  >For the scripts that use a virama character to generate conjunct consonants, (All the Indic scripts plus Myanmar and Khmer) the function NormalizeCleanAndSegmentUTF8 pairs the virama with an appropriate neighbor to generate a more glyph-oriented encoding in the unicharset. To make full use of this improvement, the --pass_through_recoder flag should be set for combine_lang_model for these scripts.

as per https://github.com/tesseract-ocr/tesseract/blob/master/training/tesstrain_utils.sh

```
  local pass_through=""
  # TODO(rays) set using script lang lists.
  case "${LANG_CODE}" in
    asm | ben | bih | hin | mar | nep | guj | kan | mal | tam | tel | pan | \
    dzo | sin | san | bod | ori | khm | mya | tha | lao | heb | yid | ara | \
    fas | pus | snd | urd | div | syr | uig | kur_ara )
      pass_through="--pass_through_recoder" ;;
```

However, I find that while the `san.unicharset` as part of `best traineddata` has only **145** characters, the newly generated starter unicharset through tesstrain.sh has the glyph based larger unicharset of **2308** and the final traineddata also has the larger unicharset of **2308** characters.

@theraysmith 

Is this the desired behavior or are we missing a step to convert the glyph based unicharset to the compressed unicharset after stopping training?

Also, how do we update the version string to be included in the final traineddata after training?

I am using the following command to build the final traineddata.

```
lstmtraining   --stop_training  \
  --continue_from  ../tesstutorial/vedic/santune_checkpoint  \
  --traineddata ../tesstutorial/vedic/san/san.traineddata  \
  --model_output ../tesstutorial/vedic/vedic.traineddata
```

 ```

USAGE: combine_lang_model
  --lang_is_rtl  True if lang being processed is written right-to-left  (type:bool default:false)
  --pass_through_recoder  If true, the recoder is a simple pass-through of the unicharset. Otherwise, potentially a compression of it  (type:bool defa
ult:false)
  --input_unicharset  Unicharset to complete and use in encoding  (type:string default:)
  --script_dir  Directory name for input script unicharsets  (type:string default:)
  --words  File listing words to use for the system dictionary  (type:string default:)
  --puncs  File listing punctuation patterns  (type:string default:)
  --numbers  File listing number patterns  (type:string default:)
  --output_dir  Root directory for output files  (type:string default:)
  --version_str  Version string to add to traineddata file  (type:string default:)
  --lang  Name of language being processed  (type:string default:)
```
 See Ray's comment at https://github.com/tesseract-ocr/tesseract/issues/1065#issuecomment-320709273

Needed to handedit the input unicharset

Will be fixed with new unichar_extractor.  Interesting! Thanks for the pointer.
Recognita had this feature in the mid 1990s.
The best ideas always return.

The difficulty is the same as for any character-level OCR, which is
character segmentation, although it probably can learn the difference
between rn and m, with a few examples.

On Sat, Aug 5, 2017 at 4:28 AM, chris <notifications@github.com> wrote:

> Peace be upon you,
> @theraysmith <https://github.com/theraysmith> here is a feature that I
> think you'll find interesting
>
> Computer Assisted Transcription:
>
>    - The software segments the pages to lines.
>    - Then segments the lines into words.
>    - Later-on, allow the user to transcribe words or glyphs, once the
>    user is satisfied, the software then searches for all instances of presence
>    of such words or glyphs, and automatically transcribe them all in all
>    instances.
>    - Can transcribe both Glyphs & Words, depending on the segmentation
>    level you choose.
>    https://github.com/benedikt-budig/glyph-miner
>
> [image: glyph] <https://www.youtube.com/watch?v=T-p_kIdsn6k>
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1066>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AL056ZTjupK40e886o_oXNgeOzkrIfc-ks5sVFHpgaJpZM4OucA6>
> .
>



-- 
Ray.
  @theraysmith 

https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00 says under FINETUNING

>A recognition model can be extracted from an existing traineddata file, using combine_tessdata. Note that it is also necessary to supply the original traineddata file as well, as that contains the unicharset and recoder.

Since the original traineddata includes the recognition model, is it necessary to provide a link to it separately.

```
training/lstmtraining --model_output /path/to/output [--max_image_MB 6000] \
  --continue_from /path/to/existing/model \
  --traineddata /path/to/original/traineddata \
  [--perfect_sample_delay 0] [--debug_interval 0] \
  [--max_iterations 0] [--target_error_rate 0.01] \
  --train_listfile /path/to/list/of/filenames.txt
``` eg. If I want to train for Vedic Sanskrit using the best/Devanagari.traineddata

is the training solely based on `  --train_listfile /path/to/list/of/filenames.txt`
ignoring the unicharset and wordlists used in generating the 'starter' traineddata

```
training/lstmtraining \
  --model_output /vedic \
  [--max_image_MB 6000] \
  --continue_from /best/Devanagari.lstm \
  --traineddata /best/Devanagari.traineddata \
  [--perfect_sample_delay 0] [--debug_interval 0] \
  [--max_iterations 0] [--target_error_rate 0.01] \
  --train_listfile /vedic/filenames.txt
```

What about the starter traineddata generated by tesstrain.sh?

Or do the plusminus instructions apply here?

```
training/lstmtraining --model_output /path/to/output [--max_image_MB 6000] \
  --continue_from /path/to/existing/model \
  --traineddata /path/to/traineddata/with/new/unicharset \
  --old_traineddata /path/to/existing/traineddata \
  [--perfect_sample_delay 0] [--debug_interval 0] \
  [--max_iterations 0] [--target_error_rate 0.01] \
  --train_listfile /path/to/list/of/filenames.txt
``` Using this now

```
nice lstmtraining \
  --old_traineddata ../tessdata/best/san.traineddata \
  --continue_from ../tessdata/best/san.lstm \
  --traineddata ../tesstutorial/vedic/san/san.traineddata  \
  --train_listfile ../tesstutorial/vedic/san.training_files.txt \
  --eval_listfile ../tesstutorial/vedic/san.eval_files.txt \
  --model_output ../tesstutorial/vedic/santune \
  --max_iterations 2000 \
  --debug_interval -1

lstmtraining   --stop_training  \
  --continue_from  ../tesstutorial/vedic/santune_checkpoint  \
  --traineddata ../tesstutorial/vedic/san/san.traineddata  \
  --model_output ../tesstutorial/vedic/vedic .traineddata
 ```

```
Loaded file ./tess4training-save/tess4training-vedic/tessdata/best/san.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Code range changed from 145 to 2308!!
Num (Extended) outputs,weights in Series:
1,36,0,1:1, 0
Num (Extended) outputs,weights in Series:
C3,3:9, 0
Ft16:16, 160
Total weights = 160
[C3,3Ft16]:16, 160
Mp3,3:16, 0
Lfys48:48, 12480
Lfx96:96, 55680
Lrx96:96, 74112
Lfx192:192, 221952
Fc2308:2308, 445444
Total weights = 809828
Previous null char=2 mapped to 2
Continuing from ./tess4training-save/tess4training-vedic/tessdata/best/san.lstm
Loaded 138/138 pages (1-138) of document ./tess4training-save/tess4training-vedic/san.AA_NAGARI_SHREE_L3.exp0.lstmf
Loaded 138/138 pages (1-138) of document ./tess4training-save/tess4training-vedic/san.AA_NAGARI_SHREE_L3.exp-1.lstmf
Loaded 137/137 pages (1-137) of document ./tess4training-save/tess4training-vedic/san.AA_NAGARI_SHREE_L3.exp-2.lstmf
``` ```
lstmtraining \
  --continue_from ./tess4training-save/tess4training-vedic/tessdata/best/${CONTINUE_FROM_LANG}.lstm \
  --traineddata ./tess4training-save/tess4training-vedic/san/${LANG}.traineddata  \
  --append_index 5 --net_spec '[Lfx512 O1c150]' \
  --train_listfile ./tess4training-save/tess4training-vedic/${LANG}.training_files.txt \
  --eval_listfile ./tess4training-save/tess4training-vedic/${LANG}.eval_files.txt \
  --model_output ./tess4training-save/${LANG}${TYPE} \
  --debug_interval ${DEBUG_INTERVAL} \
  --max_iterations ${MAX_ITERATIONS}
```

```
$ bash ./4runtesseract.sh
Loaded file ./tess4training-save/tess4training-vedic/tessdata/best/san.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from ./tess4training-save/tess4training-vedic/tessdata/best/san.lstm
Appending a new network to an old one!!Warning: given outputs 150 not equal to unicharset of 2308.
Num outputs,weights in Series:
  Lfx512:512, 1247232
  Fc2308:2308, 1184004
Total weights = 2431236
Built network:[1,36,0,1[C3,3Ft16]Mp3,3Lfys48Lfx96Lrx96Lfx512Fc2308] from request [Lfx512 O1c150]
Training parameters:
  Debug interval = 0, weights = 0.1, learning rate = 0.001, momentum=0.5
null char=2
Loaded 138/138 pages (1-138) of document ./tess4training-save/tess4training-vedic/san.AA_NAGARI_SHREE_L3.exp0.lstmf
Loaded 138/138 pages (1-138) of document ./tess4training-save/tess4training-vedic/san.AA_NAGARI_SHREE_L3.exp-1.lstmf
Loaded 138/138 pages (1-138) of document ./tess4training-save/tess4training-vedic/san.AA_NAGARI_SHREE_L3.exp1.lstmf
``` There are several questions that you raise here:
>Since the original traineddata includes the recognition model, is it necessary to provide a link to it separately.
Yes. The unicharset and recoder are **only** provided by the --traineddata arg. The checkpoints don't contain a copy of that data. Neither does the .lstm component, which acts as a training checkpoint when modifying a previously-trained model. It is able to _detect_ that you have changed the unicharset size and complain if you don't provide --old_traineddata.

>is the training solely based on --train_listfile /path/to/list/of/filenames.txt
ignoring the unicharset and wordlists used in generating the 'starter' traineddata
Same answer.

>What about the starter traineddata generated by tesstrain.sh?
>Or do the plusminus instructions apply here?
If the vedic accents are already included in the unicharset, then you can treat it as finetuning for impact, but if they are not (I don't see them) then you must treat it as plusminus. In that case, you must generate a starter traineddata, either with tesstrain.sh or with combine_lang_model directly.

>Using this now
That command line looks correct, **but did you see this?:**
>Code range changed from 145 to 2308!!
This is not plus-minus a few characters!
Your unicharset is "old style". It needs updating.
unicharset_extractor needs updating, as it doesn't let you generate the "new style" unicharsets.
Before I set to work on that, how did you generate your unicharset? Did you use unicharset_extractor?

To re-run your experiment, you could just hand-edit the Devanagari unicharset to insert the vedic accents that you need. I mentioned this briefly somewhere before.
To hand-edit the unicharset, you can just copy-paste the lines you need, change the characters at the beginning of the lines, and update the number on the first line to match the new size.
**The other fields in the unicharset file will be automatically corrected by combine_lang_model**
 I used tesstrain.sh for creating the lstmf and starter data.

I will try the handedit for unicharset.

On 07-Aug-2017 9:46 PM, "theraysmith" <notifications@github.com> wrote:

> There are several questions that you raise here:
>
> Since the original traineddata includes the recognition model, is it
> necessary to provide a link to it separately.
> Yes. The unicharset and recoder are *only* provided by the --traineddata
> arg. The checkpoints don't contain a copy of that data. Neither does the
> .lstm component, which acts as a training checkpoint when modifying a
> previously-trained model. It is able to *detect* that you have changed
> the unicharset size and complain if you don't provide --old_traineddata.
>
> is the training solely based on --train_listfile
> /path/to/list/of/filenames.txt
> ignoring the unicharset and wordlists used in generating the 'starter'
> traineddata
> Same answer.
>
> What about the starter traineddata generated by tesstrain.sh?
> Or do the plusminus instructions apply here?
> If the vedic accents are already included in the unicharset, then you can
> treat it as finetuning for impact, but if they are not (I don't see them)
> then you must treat it as plusminus. In that case, you must generate a
> starter traineddata, either with tesstrain.sh or with combine_lang_model
> directly.
>
> Using this now
> That command line looks correct, *but did you see this?:*
> Code range changed from 145 to 2308!!
> This is not plus-minus a few characters!
> Your unicharset is "old style". It needs updating.
> unicharset_extractor needs updating, as it doesn't let you generate the
> "new style" unicharsets.
> Before I set to work on that, how did you generate your unicharset? Did
> you use unicharset_extractor?
>
> To re-run your experiment, you could just hand-edit the Devanagari
> unicharset to insert the vedic accents that you need. I mentioned this
> briefly somewhere before.
> To hand-edit the unicharset, you can just copy-paste the lines you need,
> change the characters at the beginning of the lines, and update the number
> on the first line to match the new size.
> *The other fields in the unicharset file will be automatically corrected
> by combine_lang_model*
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1065#issuecomment-320709273>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o3CFEzXvmfs24sf1pF22WXYKml9Iks5sVzhugaJpZM4OuX02>
> .
>
 Thanks for the explanation, Ray. @theraysmith 

>To re-run your experiment, you could just hand-edit the Devanagari unicharset to insert the vedic accents that you need. I mentioned this briefly somewhere before.
To hand-edit the unicharset, you can just copy-paste the lines you need, change the characters at the beginning of the lines, and update the number on the first line to match the new size.
>The other fields in the unicharset file will be automatically corrected by combine_lang_model

This does not work. The program crashes in unicharset.cpp


```
 combine_lang_model    \
>  --input_unicharset  ../tesstutorial/san.unicharset  \
>  --script_dir "../langdata"   \
>  --words "../langdata/san/san.wordlist" \
>  --numbers "../langdata/san/san.numbers"   \
>  --puncs "../langdata/san/san.punc" \
>  --output_dir ../tesstutorial/sanskrit2003   \
0>  --lang "san"     --pass_through_recoder \
>      --version_str "4.0.0alpha-20170817 sanskrit2003"
other_case < unicharset_size:Error:Assert failed:in file unicharset.cpp, line 882
Segmentation fault (core dumped)
root@All-in-1-Touch:/mnt/c/Users/Us
```

I had to change all the added lines so that the numbers after the scriptname are incremented sequentially, only then it worked ok.

( Update: I had copied lines from another unicharset which had a different line number  for other case. That caused the error.  It works as described by Ray when other case line number is same.) > Appending a new network to an old one!!Warning: given outputs 150 not equal to unicharset of 2308.
Num outputs,weights in Series:
  Lfx512:512, 1247232
  Fc2308:2308, 1184004
Total weights = 2431236
Built network:[1,36,0,1[C3,3Ft16]Mp3,3Lfys48Lfx96Lrx96Lfx512Fc2308] from request [Lfx512 O1c150]

@Shreeshrii are you using Unicharset Compression-recoding? .I'm using output of combine_lang_model  for describe what i modifier in last lstm layer, example "jpn.charset_size=414.txt".  i using this last 3 digits of number for append last lstm layer . in mycase is [Lfx512 O1c414] . when i doing this i don't get a warning like [Warning: given outputs 150 not equal to unicharset of 2308] anymore 
Is this right ? 
Thanks! That number is just a warning, but helpful info.

Please see https://github.com/Shreeshrii/tess4training-vedic/tree/master/san

tesstrain.sh produced the larger 'old style' unicharset. Then as per Ray's suggestion, I hand edited it to a smaller size. Rewrite of unicharset_extractor coming early next week.

On Tue, Aug 8, 2017 at 8:21 PM, Shreeshrii <notifications@github.com> wrote:

> That number is just a warning, but helpful info.
>
> Please see https://github.com/Shreeshrii/tess4training-vedic/tree/
> master/san
>
> tesstrain.sh produced the larger 'old style' unicharset. Then as per Ray's
> suggestion, I hand edited it to a smaller size.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1065#issuecomment-321141745>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056fnA8yvAzNH7oTI63qhwAafNbXNiks5sWSXLgaJpZM4OuX02>
> .
>



-- 
Ray.
  
combine_tessdata -e ../tessdata/best/eng.traineddata \
  ../tesstutorial/engtrain/besteng.lstm
  
--------------

Finetune using the existing training text  
   
 lstmtraining \
  --model_output ../tesstutorial/engtrain/engtune \
  --continue_from ../tesstutorial/engtrain/besteng.lstm \
  --traineddata ../tessdata/best/eng.traineddata \
  --train_listfile ../tesstutorial/engeval/eng.training_files.txt \
  --debug_interval -1 \
  --max_iterations 400

  ---------------------------------------
   
 with files created using modified plusminus trainingtext

 lstmtraining \
  --model_output ../tesstutorial/engtrain/engplusminus \
  --continue_from ../tesstutorial/engtrain/besteng.lstm \
  --traineddata ../tesstutorial/engtrain/eng/eng.traineddata \
  --old_traineddata ../tessdata/best/eng.traineddata \
  --train_listfile ../tesstutorial/engtrain/eng.training_files.txt \
  --debug_interval -1 \
  --max_iterations 3600  
 
 --------------------------------

 with files created using NEW training text - many additions

 lstmtraining \
  --model_output ../tesstutorial/engtrain/englayer \
  --continue_from ../tesstutorial/engtrain/besteng.lstm \
  --traineddata ../tesstutorial/engtrain/eng/eng.traineddata \
  --train_listfile ../tesstutorial/engtrain/eng.training_files.txt \
  --eval_listfile ../tesstutorial/engeval/eng.training_files.txt \
  --append_index 5 \
  --net_spec '[Lfx256 O1c105]' \ Finetune

best traineddata (--traineddata)
lstm extracted from best traineddata
lstmf files for starter traineddata 

--------------------------------

PlusMinus

best traineddata (--old_traineddata)
lstm extracted from best traineddata
lstmf files for starter traineddata 
starter traineddata (--traineddata)

------------------------------

Replace a layer

lstm extracted from best traineddata
lstmf files for starter traineddata 
starter traineddata (--traineddata)
  Please test with the latest models available in
https://github.com/tesseract-ocr/tessdata/tree/master/best

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Aug 1, 2017 at 9:45 PM, TheSeiko <notifications@github.com> wrote:

> Additional example (wW)
> VW-Werk -> VwW-Werk
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1060#issuecomment-319419707>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o9N-1P4rP3fa2mYMcL4zS0Z8LMEYks5sT08WgaJpZM4Op9eR>
> .
>
 Are you using --oem 1?

you can see the contents of the traineddata by 

combine_tessdata -u deu,traineddata 

These are probably only lstm models and do not have the legacy engine which is used via --oem 0 @stweil Have you tested the deu model? @stweil - you may need to update the windows binaries on Uni Mannheim site with the latest updates  from Ray.

@TheSeiko I haven't personally tested the deu model. WIll check and post result. Wondering whether your Windows binary is old.... Looks like you need both deu and frk models

wget -O ./tess4data-save/deubest.traineddata https://github.com/tesseract-ocr/tessdata/blob/master/best/deu.traineddata?raw=true

sudo cp ./tess4data-save/*.traineddata /usr/share/tesseract-ocr/4.00/tessdata

time tesseract ./tif/phototest.tif stdout --oem 1 -l deu
time tesseract ./tif/phototest.tif stdout --oem 1 -l deubest

```
Page 1
This is a lot of 12 point text to test the
ocr code and see if it works on all types
of file format.
The quick brown dog jumped over the
lazy fox. The quick brown dog jumped
over the lazy fox. The quick brown dog
jumped over the lazy fox. The quick
brown dog jumped over the lazy fox.
real	0m1.633s
user	0m2.032s
sys	0m0.492s
Error opening data file /usr/share/tesseract-ocr/4.00/frk.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to your "tessdata" directory.
Failed loading language 'frk'
Page 1
This is a lot of 12 point text to test the
ocr code and see if it works on all types
of file format.
The quick brown dog jumped over the
lazy fox. The quick brown dog jumped
over the lazy fox. The quick brown dog
Jumped over the lazy fox. The quick
brown dog jumped over the lazy fox.
real	0m2.045s
user	0m2.744s
sys	0m0.612s
``` works on linux - looks for frk traineddata, probably listed in deu.config Thanks!

>I now use semantic versioning, so this is my 4.0.0-alpha.20170804.

:-) Looks like I introduced a bug.
If the traineddata file doesn't exist, it makes an empty one with a version
string in it, instead of complaining about the non-existent file.

On Sun, Aug 6, 2017 at 8:00 PM, TheSeiko <notifications@github.com> wrote:

> @stweil <https://github.com/stweil> Am I doing something wrong?
>
> There's only a version file included in the deu,traineddata when using the
> binaries from 04.08
>
> E:\Tesseract-OCR4.0a2>combine_tessdata -u deu.traineddata tmp/deu
> Extracting tessdata components from deu.traineddata
> Wrote tmp/deu.version
> Version string:4.0.0-alpha.20170804
> 23:version:size=20, offset=192
>
> E:\Tesseract-OCR4.0a2>combine_tessdata -u deu.traineddata tmp/deu.
> Extracting tessdata components from deu.traineddata
> Wrote tmp/deu.version
> Version string:4.0.0-alpha.20170804
> 23:version:size=20, offset=192
>
> E:\Tesseract-OCR4.0a2>combine_tessdata -d deu.traineddata
> Version string:4.0.0-alpha.20170804
> 23:version:size=20, offset=192
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1060#issuecomment-320557491>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056cltXp_aF2gKV9kC0kWvs3JtVSFnks5sVn3ggaJpZM4Op9eR>
> .
>



-- 
Ray.
 Ray,
There have been a number of reports of people not being able to run the
english tutorial training.
Missing eng.config etc
Posted in tesseract-ocr forum

On 07-Aug-2017 9:49 PM, "theraysmith" <notifications@github.com> wrote:

> Looks like I introduced a bug.
> If the traineddata file doesn't exist, it makes an empty one with a version
> string in it, instead of complaining about the non-existent file.
>
> On Sun, Aug 6, 2017 at 8:00 PM, TheSeiko <notifications@github.com> wrote:
>
> > @stweil <https://github.com/stweil> Am I doing something wrong?
> >
> > There's only a version file included in the deu,traineddata when using
> the
> > binaries from 04.08
> >
> > E:\Tesseract-OCR4.0a2>combine_tessdata -u deu.traineddata tmp/deu
> > Extracting tessdata components from deu.traineddata
> > Wrote tmp/deu.version
> > Version string:4.0.0-alpha.20170804
> > 23:version:size=20, offset=192
> >
> > E:\Tesseract-OCR4.0a2>combine_tessdata -u deu.traineddata tmp/deu.
> > Extracting tessdata components from deu.traineddata
> > Wrote tmp/deu.version
> > Version string:4.0.0-alpha.20170804
> > 23:version:size=20, offset=192
> >
> > E:\Tesseract-OCR4.0a2>combine_tessdata -d deu.traineddata
> > Version string:4.0.0-alpha.20170804
> > 23:version:size=20, offset=192
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/1060#
> issuecomment-320557491>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AL056cltXp_
> aF2gKV9kC0kWvs3JtVSFnks5sVn3ggaJpZM4Op9eR>
> > .
> >
>
>
>
> --
> Ray.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1060#issuecomment-320710053>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o0ifee0UQtGx7y9q_bdy7S-bpU8Gks5sVzkkgaJpZM4Op9eR>
> .
>
 I just made 3 commits that address some of these issues:
Error message for lack of --traineddata arg referring to wiki.
Emphasis that the lack of config file is just a warning.
Detected non-existent traineddata file in combine_tessdata.

It seems the majority of the problems are lack of sync of code/data. There
are dependencies between code and data that have changed due to moving the
unicharset from the LSTM model to the traineddata file.

On Mon, Aug 7, 2017 at 9:27 AM, Shreeshrii <notifications@github.com> wrote:

> Ray,
> There have been a number of reports of people not being able to run the
> english tutorial training.
> Missing eng.config etc
> Posted in tesseract-ocr forum
>
> On 07-Aug-2017 9:49 PM, "theraysmith" <notifications@github.com> wrote:
>
> > Looks like I introduced a bug.
> > If the traineddata file doesn't exist, it makes an empty one with a
> version
> > string in it, instead of complaining about the non-existent file.
> >
> > On Sun, Aug 6, 2017 at 8:00 PM, TheSeiko <notifications@github.com>
> wrote:
> >
> > > @stweil <https://github.com/stweil> Am I doing something wrong?
> > >
> > > There's only a version file included in the deu,traineddata when using
> > the
> > > binaries from 04.08
> > >
> > > E:\Tesseract-OCR4.0a2>combine_tessdata -u deu.traineddata tmp/deu
> > > Extracting tessdata components from deu.traineddata
> > > Wrote tmp/deu.version
> > > Version string:4.0.0-alpha.20170804
> > > 23:version:size=20, offset=192
> > >
> > > E:\Tesseract-OCR4.0a2>combine_tessdata -u deu.traineddata tmp/deu.
> > > Extracting tessdata components from deu.traineddata
> > > Wrote tmp/deu.version
> > > Version string:4.0.0-alpha.20170804
> > > 23:version:size=20, offset=192
> > >
> > > E:\Tesseract-OCR4.0a2>combine_tessdata -d deu.traineddata
> > > Version string:4.0.0-alpha.20170804
> > > 23:version:size=20, offset=192
> > >
> > > —
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/1060#
> > issuecomment-320557491>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/AL056cltXp_
> > aF2gKV9kC0kWvs3JtVSFnks5sVn3ggaJpZM4Op9eR>
> > > .
> > >
> >
> >
> >
> > --
> > Ray.
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/1060#
> issuecomment-320710053>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_o0ifee0UQtGx7y9q_
> bdy7S-bpU8Gks5sVzkkgaJpZM4Op9eR>
> > .
>
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1060#issuecomment-320712052>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056bG0VYKti8qB_bH9oO6Ma4ZkT7B_ks5sVzrtgaJpZM4Op9eR>
> .
>



-- 
Ray.
 >It seems the majority of the problems are lack of sync of code/data. There
are dependencies between code and data that have changed due to moving the
unicharset from the LSTM model to the traineddata file.

Yes. That is the problem.

One possible solution that I have been asking for a while is the tagging of "important" commits. Then it would be easy to say, use tesseract, tessdata, langdata as of 4.0.0alpha-20170807  Interesting. I remember from learning German at school that all nouns begin
with a capital, so why do yours not?
I would assume from the errors that you describe that the network has
learned that all nouns begin with a capital, so it hallucinates one even
when it is not there.
If you have a lot of non-capital nouns for some reason, it might do better
in 'Latin' than 'deu'

On Tue, Aug 8, 2017 at 11:57 PM, TheSeiko <notifications@github.com> wrote:

> $$-Jährige <-> $$-jährige
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1060#issuecomment-321170268>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056SQxJfQMiipkLavZpbfqC4FgRymLks5sWVhbgaJpZM4Op9eR>
> .
>



-- 
Ray.
  @stweil Please review and make any needed changes.

'make' will build the test.
'make runtest' will run the test.  ```
 make runtest
./tesseracttests
[==========] Running 2 tests from 1 test case.
[----------] Global test environment set-up.
[----------] 2 tests from TesseractTest
[ RUN      ] TesseractTest.ZeroDummyTestForTesseract
[       OK ] TesseractTest.ZeroDummyTestForTesseract (0 ms)
[ RUN      ] TesseractTest.FirstDummyTestForTesseract
[       OK ] TesseractTest.FirstDummyTestForTesseract (0 ms)
[----------] 2 tests from TesseractTest (1 ms total)

[----------] Global test environment tear-down
[==========] 2 tests from 1 test case ran. (5 ms total)
[  PASSED  ] 2 tests.
``` @theraysmith @stweil 

I have updated the testing framework to use unittest directory.

```
root@All-in-1-Touch:/mnt/c/Users/User/shree/tesseract/unittest# make
g++ -isystem ../googletest/googletest/include  -DUSE_STD_NAMESPACE -g -Wall -Wextra -pthread -O2 -std=c++11 -c ../unittest/sample1.cc
g++ -isystem ../googletest/googletest/include  -DUSE_STD_NAMESPACE -g -Wall -Wextra -pthread -O2 -std=c++11 -c ../unittest/sample1_unittest.cc
g++ -isystem ../googletest/googletest/include  -DUSE_STD_NAMESPACE -I../googletest/googletest -g -Wall -Wextra -pthread -O2 -std=c++11 -c \
            ../googletest/googletest/src/gtest-all.cc
g++ -isystem ../googletest/googletest/include  -DUSE_STD_NAMESPACE -I../googletest/googletest -g -Wall -Wextra -pthread -O2 -std=c++11 -c \
            ../googletest/googletest/src/gtest_main.cc
ar rv gtest_main.a gtest-all.o gtest_main.o
ar: creating gtest_main.a
a - gtest-all.o
a - gtest_main.o
g++ -isystem ../googletest/googletest/include  -DUSE_STD_NAMESPACE -g -Wall -Wextra -pthread -O2 -std=c++11 -lpthread sample1.o sample1_unittest.o gtest_main.a -o sample
1_unittest
g++ -isystem ../googletest/googletest/include  -DUSE_STD_NAMESPACE -g -Wall -Wextra -pthread -O2 -std=c++11 -c ../unittest/tesseracttests.cpp
ar rv gtest.a gtest-all.o
ar: creating gtest.a
a - gtest-all.o
g++ -isystem ../googletest/googletest/include  -DUSE_STD_NAMESPACE -g -Wall -Wextra -pthread -O2 -std=c++11 -lpthread tesseracttests.o gtest.a -o tesseracttests
g++ -isystem ../googletest/googletest/include  -DUSE_STD_NAMESPACE -g -Wall -Wextra -pthread -O2 -std=c++11 -I../ccstruct  -I../ccutil -c ../unittest/matrix_test.cc
g++ -isystem ../googletest/googletest/include  -DUSE_STD_NAMESPACE -g -Wall -Wextra -pthread -O2 -std=c++11 -lpthread -llept -ltesseract matrix_test.o gtest_main.a -o ma
trix_test
root@All-in-1-Touch:/mnt/c/Users/User/shree/tesseract/unittest# make runtest
./sample1_unittest
Running main() from gtest_main.cc
[==========] Running 6 tests from 2 test cases.
[----------] Global test environment set-up.
[----------] 3 tests from FactorialTest
[ RUN      ] FactorialTest.Negative
[       OK ] FactorialTest.Negative (0 ms)
[ RUN      ] FactorialTest.Zero
[       OK ] FactorialTest.Zero (0 ms)
[ RUN      ] FactorialTest.Positive
[       OK ] FactorialTest.Positive (0 ms)
[----------] 3 tests from FactorialTest (1 ms total)

[----------] 3 tests from IsPrimeTest
[ RUN      ] IsPrimeTest.Negative
[       OK ] IsPrimeTest.Negative (0 ms)
[ RUN      ] IsPrimeTest.Trivial
[       OK ] IsPrimeTest.Trivial (0 ms)
[ RUN      ] IsPrimeTest.Positive
[       OK ] IsPrimeTest.Positive (0 ms)
[----------] 3 tests from IsPrimeTest (1 ms total)

[----------] Global test environment tear-down
[==========] 6 tests from 2 test cases ran. (3 ms total)
[  PASSED  ] 6 tests.
./tesseracttests
[==========] Running 2 tests from 1 test case.
[----------] Global test environment set-up.
[----------] 2 tests from TesseractTest
[ RUN      ] TesseractTest.ZeroDummyTestForTesseract
[       OK ] TesseractTest.ZeroDummyTestForTesseract (0 ms)
[ RUN      ] TesseractTest.FirstDummyTestForTesseract
[       OK ] TesseractTest.FirstDummyTestForTesseract (0 ms)
[----------] 2 tests from TesseractTest (1 ms total)

[----------] Global test environment tear-down
[==========] 2 tests from 1 test case ran. (2 ms total)
[  PASSED  ] 2 tests.
./matrix_test
Running main() from gtest_main.cc
[==========] Running 4 tests from 1 test case.
[----------] Global test environment set-up.
[----------] 4 tests from MatrixTest
[ RUN      ] MatrixTest.RotatingTranspose_3_1
[       OK ] MatrixTest.RotatingTranspose_3_1 (0 ms)
[ RUN      ] MatrixTest.RotatingTranspose_2_0
[       OK ] MatrixTest.RotatingTranspose_2_0 (0 ms)
[ RUN      ] MatrixTest.RotatingTranspose_1_3
[       OK ] MatrixTest.RotatingTranspose_1_3 (0 ms)
[ RUN      ] MatrixTest.RotatingTranspose_0_2
[       OK ] MatrixTest.RotatingTranspose_0_2 (0 ms)
[----------] 4 tests from MatrixTest (1 ms total)

[----------] Global test environment tear-down
[==========] 4 tests from 1 test case ran. (2 ms total)
[  PASSED  ] 4 tests.
root@All-in-1-Touch:/mnt/c/Users/User/shree/tesseract/unittest#
``` https://github.com/tesseract-ocr/tesseract/blob/0f2500287a30d2b09e8c853b39913a5eb9b03ca2/unittest/Makefile Hmm. That doesn't do it for me either.
It is looking for tesseract in some installed location, when I want it to
refer to the local copy, so I can use test-driven development.
Can't we just have a Makefile.am for it like we do for training?


On Fri, Aug 18, 2017 at 6:29 AM, Shreeshrii <notifications@github.com>
wrote:

> https://github.com/tesseract-ocr/tesseract/blob/
> 0f2500287a30d2b09e8c853b39913a5eb9b03ca2/unittest/Makefile
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/1059#issuecomment-323353515>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056SJiMvSFQS5hq43fX1RBewAnnev0ks5sZZGlgaJpZM4OnUW1>
> .
>



-- 
Ray.
  Please see this note in wiki - https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#error-messages-from-training

>No block overlapping textline: occurs when layout analysis fails to correctly segment the image that was given as training data. The textline is dropped. Not much problem if there aren't many, but if there are a lot, there is probably something wrong with the training text or rendering process. Still getting some of these errors for Devanagari, with tif/box pairs generated by text2image. Seems to be around `---------०---------` in training text.

```

No block overlapping textline: ---------०---------
No block overlapping textline: वित्त्येवहि अचूर्यामहि कृतघ्नं शत्रून्द्रुहे शुष्कीकरोति
No block overlapping textline: अर्कैः
No block overlapping textline: ह्यन्बन्त्यांञ्जगृहीतवती शक्तिपीठं ग्न्य छन्दष्ट्य झ
```  Thanks!
But you did not push PR to our repository, so we cannot apply it.
You MUST create PR inside your github repo, not ours, then it should appear here. Fixed https://github.com/tesseract-ocr/tesseract/pull/1054  It is used internally at Google.
Text2image could be modified to use it too. > Text2image could be modified to use it too.

That would be great. This is what I referred to in - https://github.com/tesseract-ocr/tessdata/issues/69#issuecomment-320302092  I had built it locally with autotools, making changes in the makefiles etc. I think once setup the only changes will be in the makefile in the directory where the tests/test cases/test fixtures are kept. So it should not be too difficult.

https://github.com/tesseract-ocr/tesseract/blob/0f2500287a30d2b09e8c853b39913a5eb9b03ca2/unittest/Makefile Please see https://github.com/tesseract-ocr/tesseract/pull/1059

pull request with makefile etc So I tried building a test using just github, and I get stuck before I can even try it.
The code doesn't build under cmake, where it does under autotools.
Since this is my first attempt at using cmake I'm probably doing something wrong, but it seems less reliable/portable than autotools so far:

~/opensrc/git/tesseract/demo$ make
[ 97%] Built target libtesseract
Linking CXX executable bin/tesseract
liblibtesseract.so.4.0.0: undefined reference to `l_generateCIDataForPdf'
liblibtesseract.so.4.0.0: undefined reference to `l_CIDataDestroy'
liblibtesseract.so.4.0.0: undefined reference to `pixReadFromMultipageTiff'
liblibtesseract.so.4.0.0: undefined reference to `pixReadMemFromMultipageTiff'
collect2: error: ld returned 1 exit status

It looks to me like it is picking up the wrong version of leptonica. I think these are new functions in the latest version. I  built and installed the latest leptonica earlier today.
So how do I make it build under cmake? cmake fans speak up before I get turned off it completely!
 No luck. cmake doesn't work on LInux.
Even building leptonica with cmake puts the library in /usr/local, so if
cmake isn't going to look there, it isn't going to find it.

On Fri, Aug 18, 2017 at 3:23 AM, Amit D. <notifications@github.com> wrote:

> Basically, CMake is for Windows&MSVC and autotools is for all other
> environment.
> I'm Talking only about this project, not about other projects build tool
> usage.
>
> Related: DanBloomberg/leptonica#253
> <https://github.com/DanBloomberg/leptonica/issues/253>
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/1051#issuecomment-323317976>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056SH7Rdi05R6Ra1KIeRINkliVA_g6ks5sZWYWgaJpZM4OhhM1>
> .
>



-- 
Ray.
 CMake does not work properly on linux. Please, use autotools for some time.
Or is it hard to integrate tests with autotools?
  copied from https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!topic/tesseract-dev/VLwwGFKtdPA

>Ray | Jul 21
>I have the OK to "throw the tests over the wall" already. ie provide them in a non-working form.
There are actually very few copyrighted images that would need to be replaced. Most of the tests run on synthetic data, existing test data, or don't require images.

>**If someone would put together the build pieces necessary to build and run an empty test (using Google test), then I will port at least one example, and then push the rest out.**

>Ray | Jul 13
>There are the order of 50 tests, some of which complete in <1s. Some take ~10mins to run, but very few. You could probably run the whole lot on a single machine in about an hour.

>Jul 13 Jeff Breidenbach 
>First step is to make a working but empty test for Tesseract under this 
framework. Once that exemplar is in place, we can migrate the existing 
tests that currently run inside Google.

 Some tests for tesseract using java as part of Quan's tess4j project

>https://github.com/nguyenq/tess4j/tree/master/src/test/java/net/sourceforge/tess4j https://stackoverflow.com/questions/35998856/how-can-i-use-google-test-with-my-project-that-builds-via-autotools Thanks!
I will port one test, and then determine how easy it is to write portable
tests that work both inside Google and outside.


On Mon, Jul 24, 2017 at 10:51 AM, Stefan Weil <notifications@github.com>
wrote:

> @theraysmith <https://github.com/theraysmith>, pull request #1051
> <https://github.com/tesseract-ocr/tesseract/pull/1051> adds the required
> pieces for GoogleTest.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1050#issuecomment-317501971>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056a53GU5T3Bo5ETJ3KJ6XOFSsIQ5Fks5sRNmPgaJpZM4Og8V1>
> .
>



-- 
Ray.
 PR with Makefile.am for unittest

https://github.com/tesseract-ocr/tesseract/pull/1088  Please see https://mail.google.com/mail/u/1/#inbox/15d63efbd84c75e0
https://stackoverflow.com/questions/45051372/image-to-searchable-text-pdf-in-tesseract-3-05

I have seen earlier requests for info for this.

It will be helpful to add an api example for creating searchable pdfs to 

* https://github.com/tesseract-ocr/tesseract/wiki/APIExample

 https://github.com/cppan/tesseract_example/blob/master/with_cmake/src/main.cpp  @theraysmith Are Halfwidth katakana included in your new Japanese training? @hoangtocdo90 Please see https://github.com/tesseract-ocr/langdata/issues/81#issuecomment-320821042 and reply to Ray's questions there.  The problem is that -DUSING_STD_NAMESPACE is now needed for all of the tesseract library, not just for training. I fixed it in the Makefile.am files, but corresponding fixes are needed for windows and other non-autotools platforms. The same define will be required for anything that uses the library too, as
the define causes a using std::string to be declared in platform.h, which
is exactly what you are missing.

On Wed, Jul 19, 2017 at 3:14 PM, Edouard Belval <notifications@github.com>
wrote:

> @theraysmith <https://github.com/theraysmith> Is it? Because I had that
> problem about 3 hours ago on Ubuntu. Tesseract does build, it's the modules
> built with its header files that doesn't.
>
> I'll try adding -DUSING_STD_NAMESPACE and report back.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1045#issuecomment-316534228>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056Wm5F3tHXCEBRfmSncrNj3xLaO1Jks5sPn-tgaJpZM4OdRN0>
> .
>



-- 
Ray.
 Problem is back, clean pull and build from `master` causes the same error described in the issue. There is probably an include of platform.h needed somewhere.
Can you give us the compiler error? @amitdo Sorry, issue fell off my radar because of another problem.

@theraysmith It's the exact same compiler error that was in the original issue.

@stweil  According to this [issue](https://github.com/sirfz/tesserocr/issues/66#issuecomment-322033488) the last "good" version was [this commit](https://github.com/tesseract-ocr/tesseract/commit/f5c18f78c09ab028791c28c638d5cc2f96c6d6fb). I did not try anything else than the latest version. Will report back with the results. @stweil I'll try it. If it works you might want to edit your comment above to make sure that no one else will make that mistake. @sirfz Can confirm, I built it successfully too.  We do not provide support for 3rd party sw. Use tesseract user forum for asking question or replicate error with tesseract executable.   what is the version of your traineddata files? Download latest version from the tessdata repo. Test with the tif file in testing directory. It works ok for me.
My traineddata files are in ../tessdata directory

```
# tesseract phototest.tif phototest --tessdata-dir ../
Tesseract Open Source OCR Engine v4.00.00dev-2067 with Leptonica
Page 1

# tesseract phototest.tif phototest --tessdata-dir ../ --oem 1
Tesseract Open Source OCR Engine v4.00.00dev-2067 with Leptonica
Page 1

# tesseract phototest.tif phototest --tessdata-dir ../ --oem 2
Tesseract Open Source OCR Engine v4.00.00dev-2067 with Leptonica
Page 1


# tesseract -v
tesseract 4.00.00dev-2067
 leptonica-1.74.4
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 Found AVX
 Found SSE
``` When you say ' Tesseract 4.00 Git Version' I take it to mean that you are using the latest source from github to build tesseract. build with --enable-debug and run with gdb to get additional info.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Jul 19, 2017 at 11:05 PM, Nick <notifications@github.com> wrote:

> OK. I tested it with the traineddata above. But also it's the same I'm
> using here.
> I also confirmed that tesseract in indeed using the right data folder.
>
> But again the phototest.tif works fine with --oem 0 and results in the
> same error "illegal instructions" for any other --oem option or none
> (default should be --oem 2 if I'm not mistaken)
>
> And although compilation seemed fine. I didn't see an error or warning. So
> I guess there must be some library missing here.
>
> Also I reinstalled Leptonica and Tesseract multiple times now.
>
> Here's how I've installed the tools:
>
> 1. Make sure that the following libraries are installed:
>
>        # nickbe:  I had to replace libpng12-dev for debian jessie
>
> 	apt-get install autoconf-archive automake g++ libtool libleptonica-dev pkg-config
> 	apt-get install libpango1.0-dev
>
> 	# sudo apt-get install g++ # or clang++ (presumably)
> 	sudo apt-get install autoconf automake libtool
> 	sudo apt-get install autoconf-archive
> 	sudo apt-get install pkg-config
> 	sudo apt-get install libpng12-dev
> 	sudo apt-get install libjpeg-turbo
> 	sudo apt-get install libtiff5-dev
> 	sudo apt-get install zlib1g-dev
>
> 	sudo apt-get install libicu-dev
> 	sudo apt-get install libpango1.0-dev
> 	sudo apt-get install libcairo2-dev
>
> 2. Install Leptonica:
>
> 	git clone --depth 1 https://github.com/DanBloomberg/leptonica.git leptonica
> 	cd leptonica
> 	./autobuild
> 	./configure
> 	make
> 	sudo make install
> 	ldconfig
>
> 3. Install Tesseract:
>
>     git clone --depth 1  https://github.com/tesseract-ocr/tesseract.git tesseract-ocr
>     cd tesseract-ocr
>     ./autogen.sh
>
>     ./configure --disable-openmp --disable-shared --disable-static
>     or
>     ./configure        # nickbe: I TESTED BOTH CONFIGURATIONS JUST TO MAKE SURE
>     make
>
>     sudo make install
> 	sudo ldconfig
>
> 	# sudo make training
> 	# sudo make training-install
>
> 	sudo make install-langs      # nickbe: Never does anything so far
>       sudo ldconfig
>
> 4. wget tessdata from https://github.com/tesseract-ocr/tesseract/wiki/Data-Files
>    to /usr/local/share/tessdata
>
>    Example: wget https://github.com/tesseract-ocr/tessdata/raw/4.00/eng.traineddata
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1043#issuecomment-316461110>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oxqBBceuQv-LRbrZSoOB_RyHelUCks5sPj5ngaJpZM4ObwNC>
> .
>
  If you can help for a particular script, please comment below. 

Comments from Ray - copied from https://github.com/tesseract-ocr/tesseract/issues/995
Read the thread for full context.
______________________________________________

it would be useful to have any experts in any of the following scripts 
review the new corpus cleanup code,and make comments:

Devanagari, Bengali, Gurmukhi, Gujarati, Oriya, Tamil, Telugu, Kannada,Malayalam, 
Sinhala, 
Thai, 
Myanmar, 
Khmer.

There are script-specific cleanup rules in there.
Since I plan to commit new copies of the training data (unicharsets,
wordlists, training text etc) then at that point they will match.

eg.
The code determines what makes a valid/invalid sequence of unicodes in the
script, for instance, is it allowed to have two matras in a row? It gets
more difficult with questions over what category the additional characters
are.

Major new normalization/text cleanup code in training/validat* The best
help with this would be expertise in the various scripts, as previously
discussed.

--------------------------
https://github.com/tesseract-ocr/tesseract/blob/master/training/validate_grapheme.cpp
https://github.com/tesseract-ocr/tesseract/blob/master/training/validate_grapheme.h

https://github.com/tesseract-ocr/tesseract/blob/master/training/validate_indic.cpp
https://github.com/tesseract-ocr/tesseract/blob/master/training/validate_indic.h

https://github.com/tesseract-ocr/tesseract/blob/master/training/validate_khmer.cpp
https://github.com/tesseract-ocr/tesseract/blob/master/training/validate_khmer.h

https://github.com/tesseract-ocr/tesseract/blob/master/training/validate_myanmar.cpp
https://github.com/tesseract-ocr/tesseract/blob/master/training/validate_myanmar.h

https://github.com/tesseract-ocr/tesseract/blob/master/training/validator.cpp
https://github.com/tesseract-ocr/tesseract/blob/master/training/validator.h Devanagari - Vedic Accents

https://github.com/tesseract-ocr/tesseract/blob/master/training/validator.cpp#L178

```
bool Validator::IsVedicAccent(char32 unicode) {
  return 0x1cd0 <= unicode && unicode < 0x1d00;
}
```

Please see 
* http://www.unicode.org/versions/Unicode10.0.0/ch12.pdf
* http://unicode.org/charts/PDF/U0900.pdf
* http://unicode.org/charts/PDF/UA8E0.pdf
* http://unicode.org/charts/PDF/U1CD0.pdf

The following should also be included as Vedic Accents.

>U+0951..U+0954 are a set of combining marks used in transcription of Sanskrit texts.

```
Vedic tone marks
0951 $॑ DEVANAGARI STRESS SIGN UDATTA
= Vedic tone svarita
• mostly used for svarita, with rare use for udatta
• used also in Vedic texts written in other scripts
→ 1CDA $᳚  vedic tone double svarita
0952 $॒ DEVANAGARI STRESS SIGN ANUDATTA
= Vedic tone anudatta
• used also in Vedic texts written in other scripts
→ 1CDC $᳜  vedic tone kathaka anudatta
```

Possibly also

```
Accent marks
0953 $॓ DEVANAGARI GRAVE ACCENT
→ 0300 $̀  combining grave accent
0954 $॔ DEVANAGARI ACUTE ACCENT
→ 0301 $́  combining acute accent
```

>Devanagari Extended: U+A8E0–U+A8FF
This block of characters is used chiefly for Vedic Sanskrit, although many of the characters
are generic and can be used by other Indic scripts. The block includes a set of combining
digits, letters, and avagraha which is used as a system of cantillation marks in the early
Vedic Sanskrit texts. The Devanagari Extended block also includes nasalization marks (candrabindu),
and a number of editorial marks.

Also include the ranges
*  A8E0-A8F1 Combining Marks
* A8F2-A8F7 Marks of Nasalization

 Devanagari - Words cannot begin with

```
Various signs
0900 $ऀ DEVANAGARI SIGN INVERTED CANDRABINDU
= vaidika adhomukha candrabindu
0901 $ँ DEVANAGARI SIGN CANDRABINDU
= anunasika
→ 0310 $̐  combining candrabindu
0902 $ं DEVANAGARI SIGN ANUSVARA
= bindu
0903 $ः DEVANAGARI SIGN VISARGA

Various signs
093C $़ DEVANAGARI SIGN NUKTA
• for extending the alphabet to new letters
093D ऽ DEVANAGARI SIGN AVAGRAHA
```
and
the various dependent vowel signs.

Most of these maybe covered by https://github.com/tesseract-ocr/tesseract/blob/master/training/validate_grapheme.cpp#L55

```
  if (char_type == U_NON_SPACING_MARK || char_type == U_ENCLOSING_MARK ||
      char_type == U_COMBINING_SPACING_MARK || ch == kZeroWidthNonJoiner ||
      ch == kZeroWidthJoiner)
    return CharClass::kCombiner;
```

Please check about Avagraha - 093D. Devanagari - Eyelash Ra for Marathi

```
R5a For compatibility with The Unicode Standard, Version 2.0, if the dead consonant
RAd precedes zero width joiner, then the half-consonant form RAh , depicted as
eyelash-RA, is used instead of RAsup .
```
Page 13 in http://www.unicode.org/versions/Unicode10.0.0/ch12.pdf

Removal of ZWJ in this case will lead to incorrect results.  check  that your unicharset file is in utf8 encoding and not ANSI

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Fri, Jul 14, 2017 at 10:58 AM, wqret1992 <notifications@github.com>
wrote:

> error_text_when_training_data_generated.txt
> <https://github.com/tesseract-ocr/tesseract/files/1147429/error_text_when_training_data_generated.txt>
> tess_output_for_img_txt.txt
> <https://github.com/tesseract-ocr/tesseract/files/1147428/tess_output_for_img_txt.txt>
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1037#issuecomment-315273593>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o1mCPmUJx7XNvVmhzWqEYg088ChHks5sNvxpgaJpZM4OX15q>
> .
>
 lstm training with box/tiff pairs is currently not supported. > can you please tell how to generate unicharset file in utf-8 format

Use a text editor which can save file in utf-8 encoding. I use notepad++.  I haven't measured cache performance in detail as you have - more measured
real-time performance under various conditions and speculated as to the
cause ;-) The detail you provide is very interesting.

One thing I have noticed is that performance of OpenMP varies a lot
according to CPU load, so you will get very poor performance trying to run
multiple tesseracts in parallel. A major performance improvement is
possible under such circumstances if you pin OpenMP threads to cores, which
can be done using an environment variable:
https://www.nas.nasa.gov/hecc/support/kb/using-intel-openmp-thread-affinity-for-pinning_285.html
I think what happens is that the OpenMP or the OS moves the threads around
the cores, when it is busy, for no good reason at all, other than wanting
to run other processes, which kills cache performance.

The weight matrices are mostly small enough to fit in core-level cache, but
if they get moved, it will be much slower. The effect may be more intense
with the smaller models that I have coming soon.

I have often wondered whether it would work more reliably faster if
re-written to not use Open MP, but use low-level threads instead. That
would be a lot of work, and may not pay off, so I haven't done it.
Alternatively, if you want to run it on multiple images in parallel using
the parallel command, you might just get better performance by turning off
OpenMP entirely and running it single-threaded.

I agree that some of the (larger) code in functions.h should be de-inlined.

I have a question on you opening statement. When you say I/O bound, I
assume you mean between the core and main memory, not I/O to disk?

On Wed, Jul 12, 2017 at 6:46 PM, Justin Hotchkiss Palermo <
notifications@github.com> wrote:

> From general testing, it appears as though I'm I/O bound while using
> tesseract, and not CPU bound. I checked out the CPU Cache performance
> (profiled with valgrind and perf, but perf's output is easiest to read) and
> found that my machines have a high number of cache misses, and even a high
> number of iTLB misses. After inspecting the code, I also noticed that
> almost every function was defined as 'inline'. The high rate of iTLB misses
> surprised me. Usually iTLB misses are reduced after running a program for a
> longer period of time, but increasing the run time (for instance with an
> image with a lot more text) saw my iTLB miss rate increase, perhaps
> indicating that I am filling my iTLB, which is rare.
>
> The iTLB misses worry me, especially because running a program for a
> longer period of time typically reduces them (one inevitably has cache/tlb
> misses when executing something that the CPU has not seen, but once it is
> in the cache, it should stay in the cache...). iTLB misses are expensive on
> Intel CPUs. I have used OpenMP in the past, but I'm not sure how it handles
> an iTLB miss per 'thread'. If each thread hits a miss and hits a page fault
> exception, and it's non blocking (which makes sense), then it'd mean that
> each thread would cause a page walk for the same instructions. Not sure if
> that's what happens, but I'd love to know what does happen (or a book or
> resource) if someone knows more about how OpenMP handles them.
>
> I have seen code styled similarly at my last job, where the main part of
> the program was written over 25 years ago. At the time I expressed surprise
> (and alarm) to a co-worker, who explained that compilers used to be
> terrible at attempting to inline functions, and it wasn't until GCC 4 that
> there was a decent attempt to improve them. GCC 4 was released in 2005.
> (The version of GCC 4 you are using now has many updates and improvements,
> and is different from the GCC 4 in 2005, so GCC 4 is not that 'outdated',
> but it was the first major time where there were improvements.) So before
> 2005, best practice was to write code similar to how Tesseract identifies
> almost all functions as 'inline'.
>
> The 'inline' specifier carries some interesting aspects too, and was more
> 'important' to use with C, since C++ defaults to 'inline' when... (From
> https://gcc.gnu.org/onlinedocs/gcc-7.1.0/gcc/Inline.html#Inline
> <http://url>)
>
> As required by ISO C++, GCC considers member functions defined within the
> body of a class to be marked inline even if they are not explicitly
> declared with the inline keyword.
>
> Also, GCC can ignore 'inline' as it sees fit. The -O2 optimization option
> includes -finline-small-functions, which inlines functions that do not
> generate additional code. -O3 includes -finline-functions, which is more or
> less the same as writing 'inline' before every function, and only ignoring
> it if GCC decides that it may reduce performance. -O2 is in the default
> configure options, so adding 'inline' before each function is similar to
> just compiling with '-finline-functions', except that it is slightly more
> explicit.
>
> There are many downsides to defining a function as 'inline', but the one
> people usually seem to notice is increased compile time. There's plenty of
> information available on Google/GNU's documentation about inline, the
> history of inline, and slight differences between inline in g++ and GNU C
> back in the day.
>
> The biggest example of what I'd call (modern) "overactive inline use" in
> tesseract is probably in these files:
> https://github.com/tesseract-ocr/tesseract/blob/master/lstm/functions.h
> https://github.com/tesseract-ocr/tesseract/blob/master/lstm/functions.cpp
>
> functions.cpp has two lines of code, with almost everything in functions.h.
>
> This is also an example of compiler output with default options, i.e.
> keeping '-O2' and all of the different functions 'inlined' (with -Winline:
> https://gcc.gnu.org/onlinedocs/gcc-7.1.0/gcc/Inline.html#Inline ),
> defined as:
>
> Using -Winline warns when a function marked inline could not be
> substituted, and gives the reason for the failure.
>
> functions.h:63:15: warning: inlining failed in call to ‘double tesseract::Logistic(double)’: call is unlikely and code size would grow [-Winline]
>  inline double Logistic(double x) {
>                ^~~~~~~~
> functions.h:64:37: note: called from here
>    if (x < 0.0) return 1.0 - Logistic(-x);
>                              ~~~~~~~~^~~~
> functions.h:63:15: warning: inlining failed in call to ‘double tesseract::Logistic(double)’: call is unlikely and code size would grow [-Winline]
>  inline double Logistic(double x) {
>                ^~~~~~~~
> functions.h:64:37: note: called from here
>    if (x < 0.0) return 1.0 - Logistic(-x);
>                              ~~~~~~~~^~~~
> functions.h:63:15: warning: inlining failed in call to ‘double tesseract::Logistic(double)’: call is unlikely and code size would grow [-Winline]
>  inline double Logistic(double x) {
>                ^~~~~~~~
> functions.h:64:37: note: called from here
>    if (x < 0.0) return 1.0 - Logistic(-x);
>                              ~~~~~~~~^~~~
> functions.h:63:15: warning: inlining failed in call to ‘double tesseract::Logistic(double)’: call is unlikely and code size would grow [-Winline]
>  inline double Logistic(double x) {
>                ^~~~~~~~
> functions.h:64:37: note: called from here
>    if (x < 0.0) return 1.0 - Logistic(-x);
>                              ~~~~~~~~^~~~
> functions.h:45:15: warning: inlining failed in call to ‘double tesseract::Tanh(double)’: call is unlikely and code size would grow [-Winline]
>  inline double Tanh(double x) {
>                ^~~~
> functions.h:46:28: note: called from here
>    if (x < 0.0) return -Tanh(-x);
>                         ~~~~^~~~
>
> As a test on my target machines, I copied my 'tesseract' repository,
> removed all (easy to remove...) 'inline' functions, shifted the definition
> to the .cpp file instead of the .h file (leaving the declaration in .h as
> is standard practice), and compiled a separate version, installing it with
> a different prefix. This allowed me to have multiple versions of Tesseract
> on the same machine, and to run tests with all of them.
>
> Next, I made a script. Fairly simple, utilizing GNU Parallel
> CITATION:
>
> O. Tange (2011): GNU Parallel - The Command-Line Power Tool,
> ;login: The USENIX Magazine, February 2011:42-47.
>
> The simple bash scripts look like this:
>
> #!/bin/bash# CONTROL SCRIPT
> TESS=/usr/bin/tesseract
> F_LOC=(location of my test images)
> parallel $TESS $F_LOC/{1} stdout ::: img1.jpg img2.png img3.jpeg
>
> and
>
> #!/bin/bash# TEST SCRIPT
> TESS=/home/hotchkiss/usr/bin/tesseract
> F_LOC=(location of my test images)
> parallel $TESS $F_LOC/{1} stdout ::: img1.jpg img2.png img3.jpeg
>
> I'd run them ~50 times randomly(as random as /dev/urandom can afford on
> two options), 'randomly' defined as I randomly chose which to run, and
> collected the average run times and percentages as an aggregate using perf.
> Each run was after a fresh reboot, with no other programs running other
> than X, i3 (my windows manager), and my default kernel + kernel modules
> (less than 110MB when running 'free -m').
>
> Results look something like:
>
>  Performance counter stats for 'test_tess':
>
>       54913.737862      task-clock:u (msec)       #    6.757 CPUs utilized
>                  0      context-switches:u        #    0.000 K/sec
>                  0      cpu-migrations:u          #    0.000 K/sec
>            136,385      page-faults:u             #    0.002 M/sec
>    161,251,587,471      cycles:u                  #    2.936 GHz                      (29.05%)
>    154,963,746,273      instructions:u            #    0.96  insn per cycle           (36.65%)
>     35,080,176,770      branches:u                #  638.823 M/sec                    (42.77%)
>        306,913,327      branch-misses:u           #    0.87% of all branches          (41.68%)
>     50,274,555,586      L1-dcache-loads:u         #  915.519 M/sec                    (27.81%)
>      5,075,515,864      L1-dcache-load-misses:u   #   10.10% of all L1-dcache hits    (19.72%)
>        450,004,836      LLC-loads:u               #    8.195 M/sec                    (17.70%)
>         23,036,525      LLC-load-misses:u         #   10.24% of all LL-cache hits     (21.92%)
>    <not supported>      L1-icache-loads:u
>         11,674,082      L1-icache-load-misses:u                                       (28.02%)
>     48,676,934,856      dTLB-loads:u              #  886.425 M/sec                    (21.31%)
>          1,322,784      dTLB-load-misses:u        #    0.00% of all dTLB cache hits   (20.86%)
>            264,354      iTLB-loads:u              #    0.005 M/sec                    (17.36%)
>            690,732      iTLB-load-misses:u        #  261.29% of all iTLB cache hits   (21.42%)
>    <not supported>      L1-dcache-prefetches:u
>    <not supported>      L1-dcache-prefetch-misses:u
>
>        8.127386606 seconds time elapsed
>
> As expected, with no compiler optimizations and all functions with the
> 'inline' identifier removed, the performance was worse by a significant
> amount (8% to 10% worse). Also as expected with modern compilers (gcc 6.3
> and gcc 8.0... I haven't run 7.x stable yet, although I could tomorrow),
> the performance seems to be ~the same and (perhaps, although requires more
> testing to be definite) better on a CPU with smaller cache/tlb sizes.
>
> I used parallels to ensure that things were running in parallel, similar
> to what I will be using in production, and, what (hopefully) everyone else
> is doing too. I checked the other things people have posted, and it seems
> as though most others are doing the same too.
>
> I am posting this for a few reasons.
>
>    1. How are you collecting cache and performance information, is it
>    standardized, and how would you like any statistics or data to be
>    submitted/displayed?
>    2. Is it alright if I remove and submit code without 'inline' declared
>    on every function?
>    3. Should I submit code with 'inline' removed from functions others
>    have written?
>    4. What are your (other developer's) target machines like, and are my
>    results and thought process similar?
>
> Personally, I'm not a fan of manually marking all functions as inline, but
> I'm also (quite) used to re-writing code/libraries to optimize performance
> for my use case(s).
>
> I can wait on posting any code changes until @theraysmith
> <https://github.com/theraysmith> has the new beta tag out though. I'm not
> sure how these types of issues are handled on github either. I've spent
> most of my time working at a FFRDC, and haven't submitted much FOSS code
> publicly at all because of it, but I can post what I've done with this,
> which is great. Typically, I'd either write my own tests and submit along
> with compiled code (and a 'NO MERGE' pull request), or follow already
> provided tests and submit according to them, however I haven't seen any.
> What do you all prefer to use, and would this be something you're
> interested in? I absolutely abhor, detest, and strongly oppose programming
> for the compiler, but I feel like these changes would actually do the
> opposite, and allow the compiler to take over.
>
> I'm also profiling functions for more detailed optimization with
> cachegrind, and I'll absolutely post those after the changes have been
> submitted. Again, it's less of a 'logic' change, and in some cases more of
> a logic 'reordering' (like order of conditional if tests, what to
> inline/skip/spend more time on and the like).
>
> Another option that (might?) be decent, if it turns out that removing
> 'inline' does hurt performance on CPUs with large cache/tlb spaces, is that
> I can do something similar to what the Linux Kernel has. There is a "Allow
> gcc to uninline functions marked 'inline'" option (under 'Kernel Hacking')
> because they have run into the same issue.
> ------------------------------
> Environment
>
>    - *Tesseract Version*: 4.0x(latest -dev)
>    - *Platform*: Linux [hostname] 4.12.0 #1
>    <https://github.com/tesseract-ocr/tesseract/issues/1> SMP Tue Jul 11
>    14:56:49 EDT 2017 x86_64 Intel(R) Core(TM) i7-4770HQ CPU @ 2.20GHz
>    GenuineIntel GNU/Linux
>    (and, specs not with me right now, but posting anyway, an Intel Atom,
>    can post later).
>
> tested with:
> gcc version 8.0.0 20170711 (experimental) (GCC)
> gcc version 6.3.0 (Gentoo 6.3.0 p1.0)
> I can test with gcc 7.x later if need be. I haven't switched my
> development system's stable version of gcc to 7 yet, even though I still
> test the experimental svn branch.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1035>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AL056byjoySZrjs2w14KyfUye2KocwQ8ks5sNXbogaJpZM4OWZ7L>
> .
>



-- 
Ray.
  +1
Never like this allocated `char *` value.
It's better to return `std::string`.  What is those `libtesseract304` messages?
And what's the issue with `...leptonica: master`? I'm not aware of this.  We support only for C++. Please replicate problem with tesseract executable or C++ code. Otherwise please use tesseract user forum for your project.  Use forum for asking questions.

See https://github.com/tesseract-ocr/tesseract/wiki/Compiling

Tesseract versions and the minimum version of Leptonica required:
TesseractLeptonicaUbuntu
4.00 1.74.2 Must build from source
3.05 1.74.0 Must build from source
3.04 1.71 Ubuntu 16.04 <http://packages.ubuntu.com/xenial/libtesseract3>
3.03 1.70 Ubuntu 14.04 <http://packages.ubuntu.com/trusty/libtesseract3>
3.02 1.69 Ubuntu 12.04 <http://packages.ubuntu.com/precise/libtesseract3>
3.01 1.67

One option is to install the distro's Leptonica package:

sudo apt-get install libleptonica-dev

but if you are using an oldish version of Linux, the Leptonica version may
be too old, so you will need to build from source.

The sources are at https://github.com/DanBloomberg/leptonica . The
instructions for building are given in Leptonica README
<http://www.leptonica.org/source/README.html>.

Note that if building Leptonica from source, you may need to ensure that
/usr/local/lib is in your library path. This is a standard Linux bug, and
the information at Stackoverflow
<http://stackoverflow.com/questions/4743233/is-usr-local-lib-searched-for-shared-libraries>
is
very helpful.
  Amit,

Which kind of unicharsets does it  merge? 
* The script based ones given in langdata
* The training text based ones created during training process

Does it just append or also eliminate duplicates?

Where would a merged unicharset be used? In that case, we should add it to Makefile.am so that we can test and figure out what it does :-) It could be used to create a combined unicharset for a script-level engine, like the new Latin or Devanagari.
It isn't referenced by the current training documentation, but it might be useful to someone, so it should probably be added to Makefile.am. @theraysmith 

Is there a similar merge_language_model program, used for building a script-level engine?

Recently someone asked me:

```
Let us consider language as lat+san+guj 
```

Where lat is IAST or the roman transliteration of Sanskrit, in Latin script + English
san is Sanskrit in Devanagari script
guj is Gujarati in Gujarati script

So, something like this needs a combining of Devanagari + Gujarati + san_latn or IAST or Latin

What would be the best way to do this?

Can multiple training_files.txt for different languages be given as input for lstmtraining or do they need to be all merged in one big file?

Sample image below:
![multi-language](https://user-images.githubusercontent.com/5095331/30238960-8e4a80fe-956f-11e7-9f1d-28ac9a18caec.png)

Here is the merged unicharset for these languages:


[deva-iast-guj.lstm-unicharset.txt](https://github.com/tesseract-ocr/tesseract/files/1291305/deva-iast-guj.lstm-unicharset.txt)
 >It could be used to create a combined unicharset for a script-level engine, like the new Latin or Devanagari.
It isn't referenced by the current training documentation, but it might be useful to someone, so it should probably be added to Makefile.am.

Added by commit https://github.com/tesseract-ocr/tesseract/pull/1116/commits/9a038f893ad51e35157b393fcd95d1b661c528af  as part of PR https://github.com/tesseract-ocr/tesseract/pull/1116   You are right. The error is also there for pdf. So, even though error messages are shown, empty output is produced.

```
 tesseract nonexisting_image.tiff output pdf
Tesseract Open Source OCR Engine v4.00.00dev-549-g2b854e3 with Leptonica
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error during processing.
```
  You need to create the lstmf files and then do finetuning with same version of tesseract. If there is a mismatch, it may not work since Ray made some changes in the lstmf files format, probably around the following commit 

https://github.com/tesseract-ocr/tesseract/commit/8e79297dcefecdb929d753d28554fec51417ec39  ### Environment

* **Tesseract Version**: 4.00.00-dev
* **Platform**: Ubuntu 14.04

### Current Behavior:

While `finetune` training, `lstmtraining` is running subtrainer. After the regular training iteration reached 60,000, subtrainer training has started from 270 and it is updating subtrainer till it reaches current iteration. 

### Expected Behavior:

Either subtrainer should be run at regular intervals or if needs to catch up for a large number of iterations, it should save checkpoints, so that in case needed, the process can be restarted,

```
UpdateSubtrainer:Sub:At iteration 284/1500/1505, Mean rms=0.089%, delta=1.062%, char train=3.922%, word train=9.339%, skip ratio=0.4%,
UpdateSubtrainer:Sub:At iteration 303/1600/1605, Mean rms=0.091%, delta=1.129%,                                                                                                                      char train=4.07%, word train=9.912%, skip ratio=0.4%,
UpdateSubtrainer:Sub:At iteration 321/1700/1705, Mean rms=0.093%, delta=1.232%, char train=4.082%, word train=10.139%, skip ratio=0.4%,
UpdateSubtrainer:Sub:At iteration 340/1800/1805, Mean rms=0.095%, delta=1.32%, char train=4.324%, word train=10.76%, skip ratio=0.4%,
UpdateSubtrainer:Sub:At iteration 359/1900/1905, Mean rms=0.093%, delta=1.22%, char train=4.036%, word train=10.23%, skip ratio=0.4%,
UpdateSubtrainer:Sub:At iteration 378/2000/2005, Mean rms=0.094%, delta=1.229%, char train=4.146%, word train=10.413%, skip ratio=0.4%,
Encoding of string failed! Failure bytes: ffffffe0 ffffffa4 ffffff83 20 ffffffe0 ffffffa4 ffffff95 ffffffe0 ffffffa5 ffffff80 ffffffe0 ffffffa4 ffffffb2 ffffffe0 ffffffa4 ffffff95 ffffffe0 ffffffa4 ffffff82 20 ffffffe0 ffffffa4 ffffffae ffffffe0 ffffffa4 ffffffae
Can't encode transcription: ललिता भट्टारिका देवता, ऐं बीजं क्लीं शक्तिः, सौः कीलकं मम
UpdateSubtrainer:Sub:At iteration 393/2100/2106, Mean rms=0.092%, delta=1.188%, char train=3.956%, word train=9.7%, skip ratio=0.5%,
UpdateSubtrainer:Sub:At iteration 406/2200/2206, Mean rms=0.089%, delta=1.092%, char train=3.606%, word train=9.478%, skip ratio=0.5%,
Encoding of string failed! Failure bytes: 7c
Can't encode transcription: अनेन भवति। अस्ति। " जायते -- सर्वत्र इह फलं सर्वेषां |
UpdateSubtrainer:Sub:At iteration 428/2300/2307, Mean rms=0.091%, delta=1.15%, char train=3.732%, word train=9.588%, skip ratio=0.3%,
UpdateSubtrainer:Sub:At iteration 447/2400/2407, Mean rms=0.09%, delta=1.073%, char train=3.477%, word train=9.343%, skip ratio=0.3%,
UpdateSubtrainer:Sub:At iteration 463/2500/2507, Mean rms=0.091%, delta=1.114%, char train=3.541%, word train=9.258%, skip ratio=0.2%,
Encoding of string failed! Failure bytes: ffffffe0 ffffffa4 ffffff82 20 ffffffe0 ffffffa4 ffffff85 ffffffe0 ffffffa4 ffffff99 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffff97 ffffffe0 ffffffa5 ffffff81 ffffffe0 ffffffa4 ffffffb7 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffa0 ffffffe0 ffffffa4 ffffffbe ffffffe0 ffffffa4 ffffffad ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffaf ffffffe0 ffffffa4 ffffffbe ffffffe0 ffffffa4 ffffff82 20 ffffffe0 ffffffa4 ffffffa8 ffffffe0 ffffffa4 ffffffae ffffffe0 ffffffa4 ffffff83
Can't encode transcription: हौं अङ्गुष्ठाभ्यां नमः
UpdateSubtrainer:Sub:At iteration 481/2600/2608, Mean rms=0.088%, delta=1.054%, char train=3.389%, word train=8.793%, skip ratio=0.3%,
UpdateSubtrainer:Sub:At iteration 500/2700/2708, Mean rms=0.085%, delta=0.903%, char train=3.099%, word train=8.728%, skip ratio=0.3%,
UpdateSubtrainer:Sub:At iteration 521/2800/2808, Mean rms=0.083%, delta=0.815%, char train=2.82%, word train=8.482%, skip ratio=0.3%,
UpdateSubtrainer:Sub:At iteration 538/2900/2908, Mean rms=0.083%, delta=0.798%, char train=2.929%, word train=8.574%, skip ratio=0.3%,
Encoding of string failed! Failure bytes: ffffffe0 ffffffa4 ffffff83 20 ffffffe0 ffffffa4 ffffffa4 ffffffe0 ffffffa5 ffffff80 ffffffe0 ffffffa4 ffffff95 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffb7 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffa3 ffffffe0 ffffffa4 ffffffbe
Can't encode transcription: रात्रिसमागमप्रविष्टांः तीक्ष्णा
UpdateSubtrainer:Sub:At iteration 564/3000/3009, Mean rms=0.084%, delta=0.81%, char train=2.918%, word train=8.662%, skip ratio=0.4%,
UpdateSubtrainer:Sub:At iteration 591/3100/3109, Mean rms=0.088%, delta=0.917%, char train=3.225%, word train=9.282%, skip ratio=0.3%,
UpdateSubtrainer:Sub:At iteration 608/3200/3209, Mean rms=0.088%, delta=0.908%, char train=3.315%, word train=9.285%, skip ratio=0.3%,
UpdateSubtrainer:Sub:At iteration 631/3300/3309, Mean rms=0.087%, delta=0.838%, char train=3.175%, word train=9.084%, skip ratio=0.2%,
UpdateSubtrainer:Sub:At iteration 660/3400/3409, Mean rms=0.089%, delta=0.87%, char train=3.226%, word train=9.473%, skip ratio=0.2%,
UpdateSubtrainer:Sub:At iteration 682/3500/3509, Mean rms=0.089%, delta=0.847%, char train=3.211%, word train=9.562%, skip ratio=0.2%,
UpdateSubtrainer:Sub:At iteration 703/3600/3609, Mean rms=0.091%, delta=0.942%, char train=3.393%, word train=9.826%, skip ratio=0.1%,
Compute CTC targets failed!
UpdateSubtrainer:Sub:At iteration 722/3700/3710, Mean rms=0.094%, delta=1.085%, char train=3.587%, word train=9.63%, skip ratio=0.2%,
Encoding of string failed! Failure bytes: ffffffe0 ffffffa4 ffffff82 ffffffe0 ffffffa4 ffffffa4 ffffffe0 ffffffa4 ffffffb0 ffffffe0 ffffffa4 ffffff83 20 ffffffe0 ffffffa4 ffffff96 ffffffe0 ffffffa4 ffffffb5 ffffffe0 ffffffa4 ffffffa4 ffffffe0 ffffffa5 ffffff8d
Can't encode transcription: पूर्णानंदोऽंतरः खवत्
Compute CTC targets failed!
UpdateSubtrainer:Sub:At iteration 741/3800/3812, Mean rms=0.093%, delta=1.055%, char train=3.462%, word train=9.397%, skip ratio=0.4%,
UpdateSubtrainer:Sub:At iteration 762/3900/3912, Mean rms=0.095%, delta=1.14%, char train=3.546%, word train=9.602%, skip ratio=0.4%,
UpdateSubtrainer:Sub:At iteration 783/4000/4012, Mean rms=0.095%, delta=1.127%, char train=3.544%, word train=9.55%, skip ratio=0.3%,
UpdateSubtrainer:Sub:At iteration 799/4100/4112, Mean rms=0.09%, delta=0.988%, char train=3.106%, word train=8.698%, skip ratio=0.3%,
UpdateSubtrainer:Sub:At iteration 821/4200/4212, Mean rms=0.09%, delta=0.99%, char train=3.007%, word train=8.819%, skip ratio=0.3%,
UpdateSubtrainer:Sub:At iteration 843/4300/4312, Mean rms=0.089%, delta=0.993%, char train=2.846%, word train=8.479%, skip ratio=0.3%,
UpdateSubtrainer:Sub:At iteration 865/4400/4412, Mean rms=0.089%, delta=1.027%, char train=2.962%, word train=8.361%, skip ratio=0.3%,
UpdateSubtrainer:Sub:At iteration 888/4500/4512, Mean rms=0.089%, delta=1.047%, char train=2.997%, word train=8.497%, skip ratio=0.3%,
Encoding of string failed! Failure bytes: ffffffe0 ffffffa4 ffffff82 20 ffffffe0 ffffffa4 ffffffb8 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffb5 ffffffe0 ffffffa4 ffffffbe ffffffe0 ffffffa4 ffffffb9 ffffffe0 ffffffa4 ffffffbe
Can't encode transcription: । ॐ भुर्भुवःसुवः ह्सौं स्वाहा
UpdateSubtrainer:Sub:At iteration 908/4600/4613, Mean rms=0.089%, delta=0.987%, char train=2.92%, word train=8.331%, skip ratio=0.4%,
UpdateSubtrainer:Sub:At iteration 932/4700/4713, Mean rms=0.089%, delta=0.953%, char train=2.907%, word train=8.546%, skip ratio=0.3%,
UpdateSubtrainer:Sub:At iteration 953/4800/4813, Mean rms=0.09%, delta=0.992%, char train=3.047%, word train=8.496%, skip ratio=0.1%,
UpdateSubtrainer:Sub:At iteration 970/4900/4913, Mean rms=0.089%, delta=0.958%, char train=2.918%, word train=8.252%, skip ratio=0.1%,
Encoding of string failed! Failure bytes: ffffffe0 ffffffa4 ffffff82 20 ffffffe0 ffffffa4 ffffffa8 20 ffffffe0 ffffffa4 ffffff95 ffffffe0 ffffffa5 ffffff81 ffffffe0 ffffffa4 ffffffb0 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffaf ffffffe0 ffffffa4 ffffffbe ffffffe0 ffffffa4 ffffffa4 ffffffe0 ffffffa5 ffffff8d 20 ffffffe0 ffffffa4 ffffffa4 ffffffe0 ffffffa4 ffffffbe ffffffe0 ffffffa4 ffffffb5 ffffffe0 ffffffa4 ffffffa6 ffffffe0 ffffffa5 ffffff8d 20 ffffffe0 ffffffa4 ffffff86 ffffffe0 ffffffa4 ffffffb5 ffffffe0 ffffffa4 ffffffbe ffffffe0 ffffffa4 ffffffaa ffffffe0 ffffffa4 ffffff83 20 ffffffe0 ffffffa4 ffffff95 ffffffe0 ffffffa4 ffffffbe ffffffe0 ffffffa4 ffffffb0 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffaf ffffffe0 ffffffa4 ffffff83
Can't encode transcription: यावद्ऽश्वरथद्विपानां युद्धसम्बाधन्ं न कुर्यात् तावद् आवापः कार्यः
Compute CTC targets failed!
Image too small to scale!! (1x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
UpdateSubtrainer:Sub:At iteration 994/5000/5016, Mean rms=0.088%, delta=0.962%, char train=2.835%, word train=8.095%, skip ratio=0.4%,
UpdateSubtrainer:Sub:At iteration 1022/5100/5116, Mean rms=0.091%, delta=1.041%, char train=3.139%, word train=8.845%, skip ratio=0.4%,
UpdateSubtrainer:Sub:At iteration 1046/5200/5216, Mean rms=0.091%, delta=1.029%, char train=3.143%, word train=8.942%, skip ratio=0.4%,
UpdateSubtrainer:Sub:At iteration 1065/5300/5316, Mean rms=0.091%, delta=0.998%, char train=3.13%, word train=9.112%, skip ratio=0.4%,
UpdateSubtrainer:Sub:At iteration 1084/5400/5416, Mean rms=0.09%, delta=0.959%, char train=3.039%, word train=8.949%, skip ratio=0.4%,
UpdateSubtrainer:Sub:At iteration 1111/5500/5516, Mean rms=0.089%, delta=0.931%, char train=2.965%, word train=9.074%, skip ratio=0.4%,

```
 My travis training build times out because of this - see
https://travis-ci.org/Shreeshrii/tess4training/builds/253954146

 I was using the large unicharset generated by the program. Ray suggested to hand-edit the unicharset till he updates unicharset extractor.

@theraysmith Still waiting for that commit.

I will close this as lstm training process has changed now with new starter trained data etc.  \n also need to be added to messages from
https://github.com/tesseract-ocr/tesseract/blob/master/lstm/lstmtrainer.cpp
and
https://github.com/tesseract-ocr/tesseract/blob/master/training/lstmtester.cpp

example of runon messages:

```
At iteration 67503/153800/153948, Mean rms=0.091%, delta=0.592%, char train=1.988%, word train=7.408%, skip ratio=0%,  New worst char error = 1.988At iteration 67166, stage 1, Eval Char error rate=9.8022655, Word error rate=39.409614 wrote checkpoint.
```  Please check if this is fixed by the latest set of commits by Ray.

[jpn-1.txt](https://github.com/tesseract-ocr/tesseract/files/1161897/jpn-1.txt)
[jpn-1.tsv.txt](https://github.com/tesseract-ocr/tesseract/files/1161899/jpn-1.tsv.txt)

```
level	page_num	block_num	par_num	line_num	word_num	left	top	width	height	conf	text
1	1	0	0	0	0	0	0	2550	470	-1	
2	1	1	0	0	0	104	96	2286	348	-1	
3	1	1	1	0	0	111	96	546	49	-1	
4	1	1	1	1	0	111	96	546	49	-1	
5	1	1	1	1	1	111	105	36	37	96	こ
5	1	1	1	1	2	160	100	48	45	96	ん
5	1	1	1	1	3	218	96	49	49	96	ば
5	1	1	1	1	4	272	100	48	45	96	ん
5	1	1	1	1	5	330	100	47	45	96	は
5	1	1	1	1	6	391	105	36	37	95	こ
5	1	1	1	1	7	440	100	48	45	96	ん
5	1	1	1	1	8	498	96	49	49	96	ば
5	1	1	1	1	9	552	100	48	45	96	ん
5	1	1	1	1	10	610	100	47	45	95	は
3	1	1	2	0	0	111	170	962	52	-1	
4	1	1	2	1	0	111	170	962	52	-1	
5	1	1	2	1	1	111	170	43	47	96	ご
5	1	1	2	1	2	158	171	107	50	95	飯
5	1	1	2	1	3	271	171	50	50	96	大
5	1	1	2	1	4	338	174	29	47	96	盛
5	1	1	2	1	5	0	0	2550	470	96	り
5	1	1	2	1	6	385	207	16	15	96	。
5	1	1	2	1	7	439	172	123	50	93	今
5	1	1	2	1	8	0	0	2550	470	95	年
5	1	1	2	1	9	567	171	65	51	96	は
5	1	1	2	1	10	624	173	87	48	96	初
5	1	1	2	1	11	0	0	2550	470	95	め
5	1	1	2	1	12	722	178	43	41	96	て
5	1	1	2	1	13	776	171	48	50	94	恋
5	1	1	2	1	14	832	173	101	48	96	人
5	1	1	2	1	15	944	171	48	50	96	出
5	1	1	2	1	16	1001	173	26	46	96	来
5	1	1	2	1	17	1021	191	25	28	96	た
5	1	1	2	1	18	1057	207	16	15	96	。
3	1	1	3	0	0	106	245	2284	126	-1	
4	1	1	3	1	0	106	245	2284	51	-1	
```
![jpn](https://user-images.githubusercontent.com/5095331/28412178-f63e0cee-6d60-11e7-82e0-7ec82cb13fc0.jpg)
 5	1	1	2	1	1	111	170	43	47	96	ご
5	1	1	2	1	2	158	171	107	50	95	飯
5	1	1	2	1	3	271	171	50	50	96	大
5	1	1	2	1	4	338	174	29	47	96	盛
5	1	1	2	1	5	0	0	2550	470	96	り
2	1	10	624	173	87	48	96	初
5	1	1	2	1	11	0	0	2550	470	95	め
5	1	1	2	1	12	722	178	43	41	96	て


Please check this . Still wrong coordinate in り and め character  I think this happens when the complex characters in your training text are not part of the original Korean Unicharset that the 4.00.00alpha kor.traineddata was trained with.

Do 'replace top layer' training instead of finetune. @abhishekchopde has had good results with it - see https://github.com/tesseract-ocr/tesseract/issues/1009

It will take longer than finetuning.

 also see
https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#error-messages-from-training  Similar Issue - https://github.com/tesseract-ocr/tesseract/issues/884  Please use the latest source from master branch of github and inform whether you still get the error.

 what version of c++ are you using?

> two different OS

which ones? I have been able to build on ubuntu 14.04. Travis and appveyor builds are building ok. Also, are you able to run tesseract from command line ?

tesseract -v

also try to OCR the sample image from testing folder. what about

tesseract --list_langs

Are you able to OCR an image from command line with the 4.0 version?

Do you have 4.00.00alpha version of traineddata files? 

Download 4.0 traineddata to a different folder and refer to that  @nachobit Please see Quan's Java JNA wrapper for Tesseract OCR API at https://github.com/nguyenq/tess4j https://github.com/nguyenq/tess4j/commit/74c850980af1268c100f8798ed475e6d69fe34b8

+Version 4.0.0 beta (8 June 2017)
 +- Upgrade to Tesseract 4.0.0 alpha (8c29e68)
 +- Update Lept4J to 1.5.0 (Leptonica 1.74.2)

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Thu, Jun 29, 2017 at 3:40 PM, Nacho Romero <notifications@github.com>
wrote:

> Updated to the lastest libs from *Tess4J-3.4.0-src* I get same error when
> launch the OCR from Java code.
>
> From 3.05.01 version, is there any solution to solve the fail recognizing
> "zeros" ( º instead of 0)?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1010#issuecomment-311923010>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oxFIpUnAMuY0-FEdUVI_o0dR3pxUks5sI3f8gaJpZM4OH3Lp>
> .
>
 We do not support 3rd party sw including tesseract wrapper. Please reproduce error with c++  * **Tesseract Version**:  Tesseract 4.00 alpha
* **Platform**:  Linux -Ubuntu 14.04 64 bit 

I have trained a few layers of the base tesseract for Korean language. I have completed my training. Now I am testing it for different images containing Korea text. I am getting the excellent character accuracy but it is detecting extra spaces after each character so my word accuracy is more than 100%. I read another issue about the same problem in Chinese OCR but not much was mentioned over there. SO can someone please throw some light on this?
@stweil @theraysmith 

Here is the comparison between groundtruth and my tesseract output:- 
![screenshot from 2017-06-27 16 10 35](https://user-images.githubusercontent.com/26093128/27583775-2f0df1bc-5b53-11e7-843c-7b04570220d3.png)

 Is the problem only with your traineddata or also with Korean traineddata posted for 4.00.00alpha?

Please do a similar test as above with kor.traineddata from tessdata repo. Yes. WIth googles tesseract also I am getting extra spaces. I got the solution for this.
Seems like we have to set the config variable - "preserve_interword_spaces" to 1 who's default value is 0 while running tesseract. The problem is solved by this for Korean language.

#991    Please use tesseract-ocr forum for asking questions and close this issue.

`--fonts_dir=/usr/share/fonts/ --font=Arial`

You should ensure that your fonts path and font name match what is available on your system. eg. If you want to train Arabic language, make sure you use a font which supports Arabic. 

You can use `text2image --list_available_fonts --fonts_dir=/usr/share/fonts/ ` to see what fonts are installed on your system and their names.  1. Ask question in forum.
2. 4.0 was not released e.g. it is not sure if all 3.0 features will be supported in final 4.0...  https://github.com/tesseract-ocr/tesseract/wiki/VGSLSpecs#variable-size-inputs-and-summarizing-lstm

https://github.com/tesseract-ocr/docs/blob/master/das_tutorial2016/6ModernizationEfforts.pdf @theraysmith is the right person to answer this.  * **Tesseract Version**: 3.05.01 
* **Commit Number**: latest code from 3.05 branch
* **Platform**: ubuntu 14.04

### Current Behavior:

First reported on forum - https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/g8lTxxYiJ2E/KL07qF_LAQAJ

Build is failing with the following:

```
/bin/bash ../libtool  --tag=CXX   --mode=link g++  -g -O2 -std=c++11  -L/usr/local/lib -o tesseract tesseract-tesseractmain.o libtesseract.la  -lrt -lpthread
libtool: link: g++ -g -O2 -std=c++11 -o .libs/tesseract tesseract-tesseractmain.o  -L/usr/local/lib ./.libs/libtesseract.so -lrt -lpthread
/usr/bin/ld: tesseract-tesseractmain.o: undefined reference to symbol 'lept_free'
//usr/local/lib/liblept.so.5: error adding symbols: DSO missing from command line
collect2: error: ld returned 1 exit status
make[2]: *** [tesseract] Error 1
make[2]: Leaving directory `/home/sanskrit/tesseract-3.05/api'
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `/home/sanskrit/tesseract-3.05'
make: *** [all] Error 2
```

This is using the latest code from github for leptonica as well as tesseract 3.05 branch.

Build was done using following commands:

```
git clone -q --branch=3.05 https://github.com/tesseract-ocr/tesseract.git tesseract-3.05
cd tesseract-3.05
./autogen.sh
PKG_CONFIG_PATH=/usr/local/lib/pkgconfig 
LIBLEPT_HEADERSDIR=/usr/local/include
./configure --with-extra-includes=/usr/local/include --with-extra-libraries=/usr/local/lib
make
``` Same leptonica works for tesseract master branch

```
/bin/bash ../libtool  --tag=CXX   --mode=link g++  -g -O2 -std=c++11  -L/usr/local/lib -o tesseract tesseract-tesseractmain.o libtesseract.la -L/usr/local/lib -llept   -fopenmp  -lrt -lpthread
libtool: link: g++ -g -O2 -std=c++11 -o .libs/tesseract tesseract-tesseractmain.o -fopenmp  -L/usr/local/lib ./.libs/libtesseract.so /usr/local/lib/liblept.so -lrt -lpthread -fopenmp
make[2]: Leaving directory `/home/sanskrit/tesseract/api'
Making all in .
make[2]: Entering directory `/home/sanskrit/tesseract'
make[2]: Leaving directory `/home/sanskrit/tesseract'
Making all in tessdata
make[2]: Entering directory `/home/sanskrit/tesseract/tessdata'
Making all in configs
make[3]: Entering directory `/home/sanskrit/tesseract/tessdata/configs'
make[3]: Nothing to be done for `all'.
make[3]: Leaving directory `/home/sanskrit/tesseract/tessdata/configs'
Making all in tessconfigs
make[3]: Entering directory `/home/sanskrit/tesseract/tessdata/tessconfigs'
make[3]: Nothing to be done for `all'.
make[3]: Leaving directory `/home/sanskrit/tesseract/tessdata/tessconfigs'
make[3]: Entering directory `/home/sanskrit/tesseract/tessdata'
make[3]: Nothing to be done for `all-am'.
make[3]: Leaving directory `/home/sanskrit/tesseract/tessdata'
make[2]: Leaving directory `/home/sanskrit/tesseract/tessdata'
Making all in doc
make[2]: Entering directory `/home/sanskrit/tesseract/doc'
make[2]: Nothing to be done for `all'.
make[2]: Leaving directory `/home/sanskrit/tesseract/doc'
make[1]: Leaving directory `/home/sanskrit/tesseract'
``` I notice some differences in the libtool commands for 3.05  and 4.0

3.05
```
/bin/bash ../libtool  --tag=CXX   --mode=link g++  -g -O2 -std=c++11  \
-L/usr/local/lib -o tesseract tesseract-tesseractmain.o libtesseract.la  \
-lrt -lpthread

libtool: link: g++ -g -O2 -std=c++11 -o .libs/tesseract tesseract-tesseractmain.o  \
-L/usr/local/lib ./.libs/libtesseract.so \
-lrt -lpthread
```

4.0
```
/bin/bash ../libtool  --tag=CXX   --mode=link g++  -g -O2 -std=c++11  \
-L/usr/local/lib -o tesseract tesseract-tesseractmain.o libtesseract.la \
-L/usr/local/lib -llept   -fopenmp  \
-lrt -lpthread

libtool: link: g++ -g -O2 -std=c++11 -o .libs/tesseract tesseract-tesseractmain.o -fopenmp \
-L/usr/local/lib ./.libs/libtesseract.so \
 /usr/local/lib/liblept.so \
-lrt -lpthread -fopenmp
``` I was following the instructions from the compiling page. I will try again just with PKG_CONFIG_PATH. I have tried multiple times, different options, still getting same error.

Do not know whether it is because I am using the latest version of leptonica rather than 1.74.2.

@danbloomberg Has anything changed between 1.74.2 to latest code to cause this breakage? Dan, 

I had built leptonica with latest code from github. I was able to build master branch of tesseract with it. However, when I tried building the 3.05 branch it failed with the error related to lept_free().

I now rebuilt leptonica 1.74.2 ( git reset --hard 395728da046016859864eeb99c7a48121acaeb74) and am able to build tesseract 3.05.

```
/bin/bash ../libtool  --tag=CXX   --mode=link g++  -g -std=c++11   -o tesseract tesseract-tesseractmain.o libtesseract.la  -lrt -lpthread
libtool: link: g++ -g -std=c++11 -o tesseract tesseract-tesseractmain.o  ./.libs/libtesseract.a -L/usr/local/lib /usr/local/lib/liblept.so -lz -lpng12 -ljpeg -lgif /usr/lib/x86_64-linux-gnu/libtiff.so -lwebp -lopenjp2 -lrt -lpthread

make[2]: Leaving directory `/home/sanskrit/tesseract-3.05/api'
Making all in .
make[2]: Entering directory `/home/sanskrit/tesseract-3.05'
make[2]: Leaving directory `/home/sanskrit/tesseract-3.05'
Making all in tessdata
```
 ```
$ pkg-config --cflags lept
-I/usr/local/include/leptonica
$ pkg-config --libs lept
-L/usr/local/lib -llept
$ PKG_CONFIG_PATH=/usr/local/lib/pkgconfig pkg-config --cflags lept
-I/usr/local/include/leptonica
$ PKG_CONFIG_PATH=/usr/local/lib/pkgconfig pkg-config --libs lept
-L/usr/local/lib -llept
``` Here is config.log from the build with 1.74.4 - which had the error.

[config.log.txt](https://github.com/tesseract-ocr/tesseract/files/1089334/config.log.txt)

 Dan, Leptonica is building fine. The problem is in building tesseract 3.05 branch.

Stefan, I will try building with your 3.05 and report.

Thank you both for your prompt responses. @stweil Tesseract part of the build happened correctly using your 3.05. 

```
/bin/bash ../libtool  --tag=CXX   --mode=link g++  -g -O2 -std=c++11   -o tesseract tesseract-tesseractmain.o libtesseract.la -L/usr/local/lib -llept     -lrt -lpthread
libtool: link: g++ -g -O2 -std=c++11 -o .libs/tesseract tesseract-tesseractmain.o  ./.libs/libtesseract.so -L/usr/local/lib /usr/local/lib/liblept.so -lrt -lpthread
make[2]: Leaving directory `/home/sanskrit/tesseract-3.05/api'
Making all in .
make[2]: Entering directory `/home/sanskrit/tesseract-3.05'
make[2]: Leaving directory `/home/sanskrit/tesseract-3.05'
Making all in tessdata
...
```

I am now getting similar error with `make training`.

```
/bin/bash ../libtool  --tag=CXX   --mode=link g++  -g -O2 -std=c++11   -o text2image text2image.o libtesseract_training.la libtesseract_tessopt.la -licui18n -licuuc -licudata   -licuuc -licudata    ../api/libtesseract.la -licuuc -licudata   -lpango-1.0 -lpangocairo-1.0 -lgobject-2.0 -lglib-2.0 -lcairo -lpangoft2-1.0 -lfontconfig  -lpthread
libtool: link: g++ -g -O2 -std=c++11 -o .libs/text2image text2image.o  ./.libs/libtesseract_training.a ./.libs/libtesseract_tessopt.a -licui18n ../api/.libs/libtesseract.so -licuuc -licudata -lpango-1.0 -lpangocairo-1.0 -lgobject-2.0 -lglib-2.0 /usr/lib/x86_64-linux-gnu/libcairo.so -lpangoft2-1.0 -lfontconfig -lpthread
/usr/bin/ld: text2image.o: undefined reference to symbol 'pixGetHeight'
//usr/local/lib/liblept.so.5: error adding symbols: DSO missing from command line
collect2: error: ld returned 1 exit status
make[1]: *** [text2image] Error 1
make[1]: Leaving directory `/home/sanskrit/tesseract-3.05/training'
make: *** [training] Error 2
make[1]: Entering directory `/home/sanskrit/tesseract-3.05/training'
/bin/bash ../libtool  --tag=CXX   --mode=link g++  -g -O2 -std=c++11   -o text2image text2image.o libtesseract_training.la libtesseract_tessopt.la -licui18n -licuuc -licudata   -licuuc -licudata    ../api/libtesseract.la -licuuc -licudata   -lpango-1.0 -lpangocairo-1.0 -lgobject-2.0 -lglib-2.0 -lcairo -lpangoft2-1.0 -lfontconfig  -lpthread
libtool: link: g++ -g -O2 -std=c++11 -o .libs/text2image text2image.o  ./.libs/libtesseract_training.a ./.libs/libtesseract_tessopt.a -licui18n ../api/.libs/libtesseract.so -licuuc -licudata -lpango-1.0 -lpangocairo-1.0 -lgobject-2.0 -lglib-2.0 /usr/lib/x86_64-linux-gnu/libcairo.so -lpangoft2-1.0 -lfontconfig -lpthread
/usr/bin/ld: text2image.o: undefined reference to symbol 'pixGetHeight'
//usr/local/lib/liblept.so.5: error adding symbols: DSO missing from command line
collect2: error: ld returned 1 exit status
make[1]: *** [text2image] Error 1
make[1]: Leaving directory `/home/sanskrit/tesseract-3.05/training'
make: *** [training-install] Error 2
``` Thank you, @stweil. I was able to build 3.05 branch with the latest leptonica.

```
~$ tesseract -v
tesseract 3.05.01
 leptonica-1.74.2
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8 : libwebp 0.4.0 : libopenjp2 2.1.2
```

However, even though I have built the latest leptonica (1.74.4), version info is still reporting 1.74.2. So, you maybe right that there maybe some old  file somewhere ...

Is there a way to check the version info for leptonica, other than through `tesseract -v`?

```
$ ls /usr/local/lib/*lept* -l
-rw-r--r-- 1 root root 16248792 Jun 21 02:56 /usr/local/lib/liblept.a
-rwxr-xr-x 1 root root     1024 Jun 21 02:56 /usr/local/lib/liblept.la
lrwxrwxrwx 1 root root       16 Jun 21 02:56 /usr/local/lib/liblept.so -> liblept.so.5.0.1
lrwxrwxrwx 1 root root       16 Jun 21 02:56 /usr/local/lib/liblept.so.5 -> liblept.so.5.0.1
-rwxr-xr-x 1 root root  9922717 Jun 21 02:56 /usr/local/lib/liblept.so.5.0.1

$ ls /usr/local/bin/tesseract -l
-rwxr-xr-x 1 root root 32298085 Jun 21 05:58 /usr/local/bin/tesseract


$ ls /usr/local/include/*lept* -l
total 576
-rw-r--r-- 1 root root 260377 Jun 21 02:56 allheaders.h
``` ```
$ find /usr -name *lept*
/usr/share/doc/liblept4
/usr/share/doc/liblept5
/usr/lib/liblept.so.4.0.2
/usr/lib/liblept.so.4
/usr/lib/x86_64-linux-gnu/liblept.so.5.0.1
/usr/lib/x86_64-linux-gnu/liblept.so.5
/usr/local/include/leptonica
/usr/local/include/leptonica/leptwin.h
/usr/local/lib/liblept.so.5.0.1
/usr/local/lib/liblept.so.5
/usr/local/lib/liblept.la
/usr/local/lib/pkgconfig/lept.pc
/usr/local/lib/liblept.a
/usr/local/lib/liblept.so

$  ldd /usr/local/bin/tesseract
        linux-vdso.so.1 =>  (0x00007ffe1c126000)
        liblept.so.5 => /usr/local/lib/liblept.so.5 (0x00007f2d0d207000)
        libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f2d0cfe9000)
        libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f2d0cce4000)
        libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f2d0c9de000)
        libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f2d0c7c8000)
        libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f2d0c3ff000)
        libz.so.1 => /lib/x86_64-linux-gnu/libz.so.1 (0x00007f2d0c1e6000)
        libpng12.so.0 => /lib/x86_64-linux-gnu/libpng12.so.0 (0x00007f2d0bfc0000)
        libjpeg.so.8 => /usr/lib/x86_64-linux-gnu/libjpeg.so.8 (0x00007f2d0bd6a000)
        libgif.so.4 => /usr/lib/x86_64-linux-gnu/libgif.so.4 (0x00007f2d0bb61000)
        libtiff.so.5 => /usr/lib/x86_64-linux-gnu/libtiff.so.5 (0x00007f2d0b8ef000)
        libwebp.so.5 => /usr/lib/x86_64-linux-gnu/libwebp.so.5 (0x00007f2d0b696000)
        libopenjp2.so.7 => /usr/lib/x86_64-linux-gnu/libopenjp2.so.7 (0x00007f2d0b45b000)
        /lib64/ld-linux-x86-64.so.2 (0x000055d6a8161000)
        liblzma.so.5 => /lib/x86_64-linux-gnu/liblzma.so.5 (0x00007f2d0b238000)
        libjbig.so.0 => /usr/lib/x86_64-linux-gnu/libjbig.so.0 (0x00007f2d0b02a000)
        libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f2d0ae26000)

$ LD_LIBRARY_PATH=/usr/local/lib /usr/local/bin/tesseract -v
tesseract 4.00.00dev-549-g2b854e3
 leptonica-1.74.2
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8 : libwebp 0.4.0 : libopenjp2 2.1.2

``` But I built using latest leptonica sources, config.log as well as allheaders.h have patch level as 4.

I will rebuild again and see. 

Thanks! I built leptonica again after doing `make distclean` , now I get the correct lib version. Thanks!

```
tesseract -v
tesseract 4.00.00dev-549-g2b854e3
 leptonica-1.74.4
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8 : libwebp 0.4.0 : libopenjp2 2.1.2

``` @DanBloomberg 

I usually update leptonica by using the following script in the leptonica directory.

```
#!/bin/bash
git pull origin
./autobuild
./configure --disable-dependency-tracking 
#./configure
make
sudo make install
sudo ldconfig
```
I follow a similar build script for tesseract master branch for building 4.0. 

Based on an error report in the forum, I tried building 3.05.01 and received the error related to lept_free (reported above).

As part of the experimentation, I did a hard reset in leptonica directory at one time to get to the commit for 1.74.2 and built leptonica and tesseract 3.05.01 after that without any problem.

@stweil then backported a couple of commits to tesseract 3.05.01 branch to fix the problem regarding lept_free() and I rebuilt leptonica with the latest source and then built tesseract 3.05.01. It built without the lept_free error.

It is possible that at this time, I did not build leptonica using the script which does autobuild and configure, but rather just did
```
git pull origin
make
sudo make install
```
I also built tesseract 4.0 from master branch after that. I noticed in both of these, that leptonica version was reported as 1.74.2.

After following Amit and Stefan's suggestions on ways to check whether I had multiple versions of files causing the older version to display, I decided to rebuild leptonica again. 

This time I did `make distclean` in leptonica directory before running the build script.

Then without needing to rebuild tesseract, `tesseract -v` showed that it was using leptonica 1.74.4. 

@amitdo So, as mentioned by Stefan, it is not necessary to rebuild tesseract to use the newer leptonica library.

@DanBloomberg It is possible, the older version display was because I did not run autobuild and configure when rebuilding leptonica. 
 The wiki pages are public and have been updated by different people at different times.  I did update the Compiling wiki page with the needed leptonica version recently. 

There are multiple Install/Compiling instructions.
I think that https://github.com/tesseract-ocr/tesseract/blob/master/INSTALL.GIT.md is better. 

I will try to streamline the compiling page - maybe delete duplicated info and refer to the installation page instead. However, it will require review by @stweil @egorpugin and @zdenop .  Tesseract works best on 300 dpi black and white images.

Preprocess your image, you will get better result.

See attached.

![color-resized-png](https://user-images.githubusercontent.com/5095331/27285596-ced0cec0-551a-11e7-8fc6-195b4365f206.png)

Here is the OCRed result using
Tesseract Open Source OCR Engine v4.00.00dev-549-g2b854e3 with Leptonica

```
13
14 ## Parameters
15
16 _- 'user' - A User struct.
17
18 - ## Examples
19
20 user = %User{name: "Alice Winston" }
21 User. first_name(user)
22 "Alice"
23 serts
24 - def first_name(user) do
25 user
26 [> Bplit
27 [> first
28 end
29
30 @doc nnn
31 Get the last name of a user.
32
33 ## Parameters
34
35 - 'user' - A User struct.
user. exs unix < utf-8 < elixir _ 50%
``` I used irfanview interactively to resize the image to a larger size, increase dpi to 300, convert to grayscale, reduce color depth to 2 and invert the colors.

You should be able to do similar conversion using imagemagick. I had resized to 1920 x 1080 and 300 dpi.

You have to experiment with the settings and see what works best. See
https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality for more
tips.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Jun 20, 2017 at 1:04 PM, Phillipp Ohlandt <notifications@github.com>
wrote:

> @Shreeshrii <https://github.com/shreeshrii> The best I can get is this:
>
> [image: frame_24721-2]
> <https://user-images.githubusercontent.com/3123549/27321677-64de42d2-559b-11e7-8d3a-f405b18d5fbf.png>
>
> Using this command:
>
> convert -units PixelsPerInch input.png -resize 1200 -density 300 -colorspace gray -depth 1 -negate output.png
>
> Not sure if imagemagick can do better.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/997#issuecomment-309669745>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o-0wgvHJPxFAHCJURDfSBTRHEUMzks5sF3XzgaJpZM4N-Jpf>
> .
>
  Many fixes have been made to master branch for 4.0 since the 4.00.00alpha release in November 2016. A number of assertions have been fixed. 

@zdenop Please add a new tag eg. 4.0.0alpha-1 / 2 (numbering as you consider appropriate). Thanks! I have not seen any comments against semver.

Maybe good to setup some kind of autoupdate for increasing the PATCH
version based on commit numbers to reduce manual administrative updates.

@stweil From what I have read about semver, if you were to implement the
zipped traineddata and related changes, it should cause a change in MINOR
version.

So, with that should it be 4.1.0alpha ?

```
Given a version number MAJOR.MINOR.PATCH, increment the:

MAJOR version when you make incompatible API changes,

MINOR version when you add functionality in a backwards-compatible manner,

and
PATCH version when you make backwards-compatible bug fixes.

Additional labels for pre-release and build metadata are available as
extensions to the MAJOR.MINOR.PATCH format.
```
 First 4 version will be 4.0.0. What 4.1.0alpha are you talking about? We don't care about changes in dev branches. > We don't care about changes in dev branches.

OK. 

Still, it will be good to have new tags when changes are substantial enough from previous  commits. For example, 

* change of LSTM mode from --oem 4 to --oem 1 after  removal of cube
* change in .lstmf and .lstm file formats after update regarding endianness
* proposed change in traineddata files to zipped format

That said, I have only done some cursory reading regarding semver. So, I am happy with whatever tag/version is used, as long as there is some demarcation.

The reason for asking for this is that people are using/trying to use master branch/4.0/LSTM and ask questions, where the version info says -alpha or -dev and it difficult to try and figure out what the issue is without knowing the version being used.
 I vote for this format which includes date - easy to identify which version is more recent.

```4.0.0-beta.20170619 ``` Please see https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/V1tyGHIenbI/SUVuXheJAwAJ

An example of how 4.00.00alpha is NOT compatible with the current master branch eg. --oem options. I'm about ready to update the traineddatas. I have a training run almost
complete, and with accuracy that meets with my satisfaction.
There are a few regressions, but not too serious.
First though, I have to get some code reviewed in Google, and then make
some commits to github to match the new traineddatas.
Before that, there is the matter of a major pull...

Here's what's coming:

   - Fix to issue 653: New components in traineddata file for the
   unicharset, recoder and version string. Backwards compatible change, so the
   LSTM component can still read older files.
   - Change in training system. The above change makes open source training
   impossible. Will add a new program to build a starter traineddata from a
   unicharset and optional word lists.
   - New "normalization" code to clean corpus text in all languages. That
   was a big part of the work.
   - Improvements to the trained networks to improve accuracy on single
   characters and single words.
   - 2 parallel sets of tessdata. "best" and "fast". "Fast" will exceed the
   speed of legacy Tesseract in real time, provided you have the required
   parallelism components, and in total CPU only slightly slower for English.
   Way faster for most non-latin languages, while being <5% worse than "best"
   Only "best" will be retrainable, as "fast" will be integer.

I have other stuff that is still incomplete, but that is a good list for
now.

BTW, in case you hadn't noticed, there was a breaking change that made old
lstmf files unusable. That was needed to fix LSTM for OSD. It has to know
the language of each training sample.
The new traineddatas will mostly be smaller than the older ones, as they
won't contain the legacy components, and no bigram dawgs are needed.

On Tue, Jul 11, 2017 at 4:49 AM, Amit D. <notifications@github.com> wrote:

> @zdenop <https://github.com/zdenop>, can you do it, or at least add your
> comment here?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/995#issuecomment-314419211>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056SvL5FeeE09JYW01xQ-dQyILyU8Wks5sM2ExgaJpZM4N9Nel>
> .
>



-- 
Ray.
 @theraysmith Thanks for the update. Look forward to it. Any estimate of expected date?

@zdenop I think this is a good reason to freeze the 'alpha' state by tagging the repo with the current version as 4.0.0-alpha.YYYYMMDD, since Ray is going to be making major changes. @Shreeshrii: I do not understand what do you want. Tag will not freeze anything.  Tag is just specific points in history to mark something important (e.g. new version). Tagging should be driven by developer who knows roadmap and not by users... @zdenop 

>Tag is just specific points in history to mark something important (e.g. new version).

Exactly my point :-)

When Ray makes his next set of commits, that will change the codebase as well as traineddata substantially. I am sure it will be tagged by Ray at that time, probably as a beta or release candidate.

My request to you to tag current commit (as an example) is to mark a point in history where a lot of development has taken place since the original 4.00.00alpha tag. In fact, that original tag just marked the start of the 4.00.00alpha development and many bugs in that original tag (missing lstm.train file etc.) have been fixed later.

Also, if the new changes by Ray will not allow for open source training :-(  then the current github version will be the one which allows users to do their own training. So, it is certainly deserving of a tag in my opinion :-)


 Open source training:
OK, I overstated it a bit.
One of my commits will temporarily break the training process. After doing
so, I will correct the documentation and add the new tool (which I have
already written) as quickly as possible after.

To help:
No more breaking commits! If it doesn't produce perfect results on
phototest, it broke something!
Cutting down on the code cleanup while I am working on it will also help.
When I have committed the new corpus cleanup code, it would be useful to
have any experts in any of the following scripts review the code and make
comments:
Devanagari, Bengali, Gurmukhi, Gujarati, Oriya, Tamil, Telugu, Kannada,
Malayalam, Sinhala, Thai, Myanmar, Khmer.
There are script-specific cleanup rules in there.
Since I plan to commit new copies of the training data (unicharsets,
wordlists, training text etc) then at that point they will match


Dates:
I was going to get started this week, but now I have to debug my pull from
github, which has broken tests (of the legacy engine), so that will take
time to fix. I'm hoping it's simple, but it is bizarre.
Even when it is fixed, there are 1500 lines of change from github for
someone here to review.
I *really* want to get 4.00 finished (in beta) in the next 5-6 weeks.

On Tue, Jul 11, 2017 at 11:27 PM, Shreeshrii <notifications@github.com>
wrote:

> @zdenop <https://github.com/zdenop>
>
> Tag is just specific points in history to mark something important (e.g.
> new version).
>
> Exactly my point :-)
>
> When Ray makes his next set of commits, that will change the codebase as
> well as traineddata substantially. I am sure it will be tagged by Ray at
> that time, probably as a beta or release candidate.
>
> My request to you to tag current commit (as an example) is to mark a point
> in history where a lot of development has taken place since the original
> 4.00.00alpha tag. In fact, that original tag just marked the start of the
> 4.00.00alpha development and many bugs in that original tag have been fixed
> by now.
>
> Also, if the new changes by Ray will not allow for open source training
> :-( then the current github version will be the one which allows users to
> do their own training. So, it is certainly deserving of a tag in my opinion
> :-)
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/995#issuecomment-314667002>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056e0RzuP9Hpok6mT4eU026fofCwaBks5sNGdRgaJpZM4N9Nel>
> .
>



-- 
Ray.
 >When I have committed the new corpus cleanup code, it would be useful to
have any experts in any of the following scripts review the code and make
comments:
Devanagari, Bengali, Gurmukhi, Gujarati, Oriya, Tamil, Telugu, Kannada,
Malayalam, Sinhala, Thai, Myanmar, Khmer.
There are script-specific cleanup rules in there.

​What kind of expertise do you need regarding the Indic scripts?​


ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Jul 12, 2017 at 10:58 PM, theraysmith <notifications@github.com>
wrote:

> Open source training:
> OK, I overstated it a bit.
> One of my commits will temporarily break the training process. After doing
> so, I will correct the documentation and add the new tool (which I have
> already written) as quickly as possible after.
>
> To help:
> No more breaking commits! If it doesn't produce perfect results on
> phototest, it broke something!
> Cutting down on the code cleanup while I am working on it will also help.
> When I have committed the new corpus cleanup code, it would be useful to
> have any experts in any of the following scripts review the code and make
> comments:
> Devanagari, Bengali, Gurmukhi, Gujarati, Oriya, Tamil, Telugu, Kannada,
> Malayalam, Sinhala, Thai, Myanmar, Khmer.
> There are script-specific cleanup rules in there.
> Since I plan to commit new copies of the training data (unicharsets,
> wordlists, training text etc) then at that point they will match
>
>
> Dates:
> I was going to get started this week, but now I have to debug my pull from
> github, which has broken tests (of the legacy engine), so that will take
> time to fix. I'm hoping it's simple, but it is bizarre.
> Even when it is fixed, there are 1500 lines of change from github for
> someone here to review.
> I *really* want to get 4.00 finished (in beta) in the next 5-6 weeks.
>
> On Tue, Jul 11, 2017 at 11:27 PM, Shreeshrii <notifications@github.com>
> wrote:
>
> > @zdenop <https://github.com/zdenop>
> >
> > Tag is just specific points in history to mark something important (e.g.
> > new version).
> >
> > Exactly my point :-)
> >
> > When Ray makes his next set of commits, that will change the codebase as
> > well as traineddata substantially. I am sure it will be tagged by Ray at
> > that time, probably as a beta or release candidate.
> >
> > My request to you to tag current commit (as an example) is to mark a
> point
> > in history where a lot of development has taken place since the original
> > 4.00.00alpha tag. In fact, that original tag just marked the start of the
> > 4.00.00alpha development and many bugs in that original tag have been
> fixed
> > by now.
> >
> > Also, if the new changes by Ray will not allow for open source training
> > :-( then the current github version will be the one which allows users to
> > do their own training. So, it is certainly deserving of a tag in my
> opinion
> > :-)
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/995#
> issuecomment-314667002>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AL056e0RzuP9Hpok6mT4eU026fofCwaBks5sNGdRgaJpZM4N9Nel>
> > .
> >
>
>
>
> --
> Ray.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/995#issuecomment-314839820>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o71HIG266aj--aGRLLsL6s9gxF_Xks5sNQIjgaJpZM4N9Nel>
> .
>
 The code determines what makes a valid/invalid sequence of unicodes in the
script, for instance, is it allowed to have two matras in a row? It gets
more difficult with questions over what category the additional characters
are.

On Wed, Jul 12, 2017 at 6:40 PM, Shreeshrii <notifications@github.com>
wrote:

> >When I have committed the new corpus cleanup code, it would be useful to
> have any experts in any of the following scripts review the code and make
> comments:
> Devanagari, Bengali, Gurmukhi, Gujarati, Oriya, Tamil, Telugu, Kannada,
> Malayalam, Sinhala, Thai, Myanmar, Khmer.
> There are script-specific cleanup rules in there.
>
> ​What kind of expertise do you need regarding the Indic scripts?​
>
>
> ShreeDevi
> ____________________________________________________________
> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>
> On Wed, Jul 12, 2017 at 10:58 PM, theraysmith <notifications@github.com>
> wrote:
>
>
> > Open source training:
> > OK, I overstated it a bit.
> > One of my commits will temporarily break the training process. After
> doing
> > so, I will correct the documentation and add the new tool (which I have
> > already written) as quickly as possible after.
> >
> > To help:
> > No more breaking commits! If it doesn't produce perfect results on
> > phototest, it broke something!
> > Cutting down on the code cleanup while I am working on it will also help.
> > When I have committed the new corpus cleanup code, it would be useful to
> > have any experts in any of the following scripts review the code and make
> > comments:
> > Devanagari, Bengali, Gurmukhi, Gujarati, Oriya, Tamil, Telugu, Kannada,
> > Malayalam, Sinhala, Thai, Myanmar, Khmer.
> > There are script-specific cleanup rules in there.
> > Since I plan to commit new copies of the training data (unicharsets,
> > wordlists, training text etc) then at that point they will match
> >
> >
> > Dates:
> > I was going to get started this week, but now I have to debug my pull
> from
> > github, which has broken tests (of the legacy engine), so that will take
> > time to fix. I'm hoping it's simple, but it is bizarre.
> > Even when it is fixed, there are 1500 lines of change from github for
> > someone here to review.
> > I *really* want to get 4.00 finished (in beta) in the next 5-6 weeks.
> >
> > On Tue, Jul 11, 2017 at 11:27 PM, Shreeshrii <notifications@github.com>
> > wrote:
> >
> > > @zdenop <https://github.com/zdenop>
> > >
> > > Tag is just specific points in history to mark something important
> (e.g.
> > > new version).
> > >
> > > Exactly my point :-)
> > >
> > > When Ray makes his next set of commits, that will change the codebase
> as
> > > well as traineddata substantially. I am sure it will be tagged by Ray
> at
> > > that time, probably as a beta or release candidate.
> > >
> > > My request to you to tag current commit (as an example) is to mark a
> > point
> > > in history where a lot of development has taken place since the
> original
> > > 4.00.00alpha tag. In fact, that original tag just marked the start of
> the
> > > 4.00.00alpha development and many bugs in that original tag have been
> > fixed
> > > by now.
> > >
> > > Also, if the new changes by Ray will not allow for open source training
> > > :-( then the current github version will be the one which allows users
> to
> > > do their own training. So, it is certainly deserving of a tag in my
> > opinion
> > > :-)
> > >
> > > —
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/995#
> > issuecomment-314667002>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/
> > AL056e0RzuP9Hpok6mT4eU026fofCwaBks5sNGdRgaJpZM4N9Nel>
> > > .
> > >
> >
> >
> >
> > --
> > Ray.
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/995#
> issuecomment-314839820>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_o71HIG266aj--
> aGRLLsL6s9gxF_Xks5sNQIjgaJpZM4N9Nel>
> > .
>
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/995#issuecomment-314945111>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056cfTz_q0IPjUvI65YCy4HVMGAjH2ks5sNXWDgaJpZM4N9Nel>
> .
>



-- 
Ray.
 No, it is not valid to have any two matras in a row  - Devanagari 093E-094C.

However, these can be followed by Anusvar, Chandrabindu or Visarga i.e. 0901-0903

In case of Vedic Sanskrit, these can be followed by the Vedic accents eg.  0951, 0952, 1CDA etc

However, I have seen samples in legacy fonts where a number of separate matras are used to create another one eg. using unicode points as example 093E followed by 0947 to create 094b - ा  े to make ो

Similarly in legacy fonts, half letters (letter followed by virama) maybe followed by aa maatraa to create the complete letter in cases such as ga, sha etc.  i.e. 0936 + 094D + 093E to create 0936 for sha

It is possible that some converters from legacy font to unicode retain these errors.

Also, in case of Vedic Sanskrit, the valid order should be matra, combining mark (anusvar, visarga), vedic accent . Some fonts incorrectly use matra, vedic accent and combining mark which will lead to dotted circle. eg. अंशाः॑ vs अंशा॑ः

For a sample of Vedic Sanskrit and its ground truth, see
https://github.com/Shreeshrii/tess4training/blob/master/BRH-test.tif
https://github.com/Shreeshrii/tess4training/blob/master/BRH-test.txt

Will your new sanskrit traineddata be able to OCR this? On Wed, Jul 12, 2017 at 9:39 PM, Shreeshrii <notifications@github.com>
wrote:

> No, it is not valid to have any two matras in a row - Devanagari 093E-094C.
>
> However, these can be followed by Anusvar, Chandrabindu or Visarge i.e.
> 0901-0903
>
It seems that Malayalam is unique in allowing multiple 0d02 (Anusvara)?

> In case of Vedic Sanskrit, these can be followed by the Vedic accents eg.
> 0951, 0952, 1CDA etc
>
> However, I have seen samples in legacy fonts where a number of separate
> matras are used to create another one eg. 093E followed by 0947 to create
> 094b
>
These are specifically dis-allowed by unicode, but the rules seem to be
very script-specific, and not very consistently documented in the unicode
standard. I don't think the rules are addressed properly for all scripts.

> Similarly in legacy fonts, half letters (letter followed by virama) maybe
> followed by aa maatraa to create the complete letter in cases such as ga,
> sha etc. i.e. 0936 + 094D + 093E to create 0936 for sha
>
> It is possible that some converters from legacy font to unicode retain
> these errors.
>
> Also, in case of Vedic Sanskrit, the valid order should be matra,
> combining mark (anusvar, visarga), vedic accent . Some fonts incorrectly
> use matra, vedic accent and combining mark which will lead to dotted
> circle. eg. अंशाः॑ vs अंशा॑ः
>
The code aims to dis-allow text designed for such legacy fonts.
The documentation that I have found is very good for Devanagari, but
lacking for some of the other scripts.
For instance, there is a big table in the unicode standard for Myanmar, (
http://www.unicode.org/versions/Unicode9.0.0/ch16.pdf) but it doesn't cover
any of the extension Myanmar characters, and isn't explicit about whether
the table represents a specific valid order or not. The existence of a lot
of legacy Myanmar text on the web that is designed for non-compliant fonts
doesn't help make it easier to determine whether the filter is correct.

> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/995#issuecomment-314968713>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056SFD_JftIXTWSw6Crvgb1j3-ZBT3ks5sNZ-XgaJpZM4N9Nel>
> .
>



-- 
Ray.
 That is still an open question.
I have limited time to spend on it (therefore resistant to delaying tactics
changing types in the dead code to POSIX).
Whether enough uses of Tesseract can be covered by the new engine is still
being debated, and the new models that I have need to be evaluated before
enough of the community is convinced.
I accept the requirement to add one or more new characters without the need
for full retraining, and will not delete the legacy code until that need is
addressed. (I think it can be done).
The legacy code is used by the OSD model and deletion of the legacy code is
also blocked by a good enough replacement.

On Thu, Jul 13, 2017 at 5:18 AM, Amit D. <notifications@github.com> wrote:

> The new traineddatas will mostly be smaller than the older ones, as they
> won't contain the legacy components, and no bigram dawgs are needed.
>
> Will you remove the *code* of the legacy engine in this round?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/995#issuecomment-315060862>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056VPOW6xmGYPbAsOF_D3yEFAAfEshks5sNgr6gaJpZM4N9Nel>
> .
>



-- 
Ray.
 >It seems that Malayalam is unique in allowing multiple 0d02 (Anusvara)?

That does not sound right. Please see 
https://en.wikipedia.org/wiki/Malayalam_script#Anusvaram

I did a search on ംം (two anusvarams in malayalam script) and most of them show up in the search result in pdfs.

FYI, pdfs created with documents having text in unicode fonts for complex scripts do not save the unicode text correctly. Devanagari text copied from these pdf is not correct, I assume similarly for malayalam and other Indian scripts, and that might be causing this double anusvar problem. 

newer pdfs created in a special manner, eg. with 'actual text' with xelatex are ok (eg. http://sanskritdocuments.org/doc_devii/annapurna.pdf), but those created from various other software are not (http://www.sanskritweb.net/sansdocs/nala-d.pdf).

@jbreiden can give you the technical reasoning for this. 

Google search does show pdfs as part of the search results, so there is some internal OCR (is it tesseract???) being done on the pdfs, books etc as part of the search process. But it may not be fully correct.

So for the corpus for training, I would suggest to avoid text taken from pdfs (in case it is being used).




 @theraysmith Regarding Malayalam, double anusvara

Please see
http://unicode.org/charts/PDF/U0D00.pdf
http://www.alanwood.net/unicode/malayalam.html
http://www.omniglot.com/language/numbers/malayalam.htm

zero in Malayalam script - pujyam looks very much like the sign for anusvar.

Also, there are different anusvars shown in unicode chart--

0D00 $ഀ MALAYALAM SIGN COMBINING ANUSVARA ABOVE
0D02 $ം MALAYALAM SIGN ANUSVARA
• used in Prakrit language texts to indicate gemination of the following consonant

0D3B $഻ MALAYALAM SIGN VERTICAL BAR VIRAMA
0D3C $഼ MALAYALAM SIGN CIRCULAR VIRAMA

I will look up more info and post under an issue in langdata Direct from the unicode standard:
Anusvara. The anusvara can be seen multiple times after vowels, whether
independent letters or dependent vowel signs, as in vxxxx <0D08, 0D02,
0D02, 0D02, 0D02>. Vowel signs can also be seen after digits, as in 355wx
<0033, 0035, 0035, 0D3E, 0D02>. More generally, rendering engines should be
prepared to handle Malayalam letters (including vowel letters), digits
(both European and Malayalam), dashes, U+00A0 no-break space and U+25CC
dotted circle as base characters for the Malayalam vowel signs, U+0D4D
malayalam sign virama, U+0D02 malayalam sign anusvara, and U+0D03 malayalam
sign visarga. They should also be prepared to handle multiple combining
marks on those bases.

Is it wrong?

On Fri, Jul 14, 2017 at 12:00 AM, Shreeshrii <notifications@github.com>
wrote:

> @theraysmith <https://github.com/theraysmith> Regarding Malayalam, double
> anusvara
>
> Please see
> http://unicode.org/charts/PDF/U0D00.pdf
> http://www.omniglot.com/language/numbers/malayalam.htm
>
> zero in Malayalam script - pujyam looks very much like the sign for
> anusvar.
>
> Also, there are different anusvars shown in unicode chart--
>
> 0D00 $ഀ MALAYALAM SIGN COMBINING ANUSVARA ABOVE
> 0D02 $ം MALAYALAM SIGN ANUSVARA
> • used in Prakrit language texts to indicate gemination of the following
> consonant
>
> 0D3B $഻ MALAYALAM SIGN VERTICAL BAR VIRAMA
> 0D3C $഼ MALAYALAM SIGN CIRCULAR VIRAMA
>
> I will look up more info and post under an issue in langdata
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/995#issuecomment-315286649>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056dtEgSZxvdhC-1CLOZ04nX1xheUPks5sNxIPgaJpZM4N9Nel>
> .
>



-- 
Ray.
 OK, I have pushed this week's changes:
Fixes to pull from github. There were bugs introduced and required code
deleted. Also reformatted/modified according to Google code standards.
Major new normalization/text cleanup code in training/validat* The best
help with this would be expertise in the various scripts, as previously
discussed.
Deleted some code from the LSTM recognizer that was old and unused.
(Backwards compatible change).
Part 1 of the changes required to move the unicharset and recoder so they
are stored in the traineddata and therefore accessible.

I have not searched through my emails to find the relevant issues to update
them yet.
The traineddatas and training source data are not yet updated. That is
probably a while away yet, so the issue about the unicharset and recoder
are not yet fully resolved anyway.
The training process shouldn't be broken by these changes yet, I hope, *but
the documentation is no longer accurate.*
*If you run a new training or incremental/fine tuning training, the new
output files will be a traineddata directly, not an LSTM traineddata
component.*
That output traineddata should contain some version string and separate
lstm unicharset/recoder.

The next step is to change the lstmtraining program to accept a traineddata
instead of a unicharset, and add a tool to generate the traineddata, then
update the documentation to match.



On Fri, Jul 14, 2017 at 8:52 AM, Ray Smith <rays@google.com> wrote:

> Direct from the unicode standard:
> Anusvara. The anusvara can be seen multiple times after vowels, whether
> independent letters or dependent vowel signs, as in vxxxx <0D08, 0D02,
> 0D02, 0D02, 0D02>. Vowel signs can also be seen after digits, as in 355wx
> <0033, 0035, 0035, 0D3E, 0D02>. More generally, rendering engines should be
> prepared to handle Malayalam letters (including vowel letters), digits
> (both European and Malayalam), dashes, U+00A0 no-break space and U+25CC
> dotted circle as base characters for the Malayalam vowel signs, U+0D4D
> malayalam sign virama, U+0D02 malayalam sign anusvara, and U+0D03 malayalam
> sign visarga. They should also be prepared to handle multiple combining
> marks on those bases.
>
> Is it wrong?
>
> On Fri, Jul 14, 2017 at 12:00 AM, Shreeshrii <notifications@github.com>
> wrote:
>
>> @theraysmith <https://github.com/theraysmith> Regarding Malayalam,
>> double anusvara
>>
>> Please see
>> http://unicode.org/charts/PDF/U0D00.pdf
>> http://www.omniglot.com/language/numbers/malayalam.htm
>>
>> zero in Malayalam script - pujyam looks very much like the sign for
>> anusvar.
>>
>> Also, there are different anusvars shown in unicode chart--
>>
>> 0D00 $ഀ MALAYALAM SIGN COMBINING ANUSVARA ABOVE
>> 0D02 $ം MALAYALAM SIGN ANUSVARA
>> • used in Prakrit language texts to indicate gemination of the following
>> consonant
>>
>> 0D3B $഻ MALAYALAM SIGN VERTICAL BAR VIRAMA
>> 0D3C $഼ MALAYALAM SIGN CIRCULAR VIRAMA
>>
>> I will look up more info and post under an issue in langdata
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/995#issuecomment-315286649>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AL056dtEgSZxvdhC-1CLOZ04nX1xheUPks5sNxIPgaJpZM4N9Nel>
>> .
>>
>
>
>
> --
> Ray.
>



-- 
Ray.
 Actually, I take that back. I don't think the output from --stop_training
is different to what it was before. It is still an LSTM traineddata
component.

On Fri, Jul 14, 2017 at 11:35 AM, Ray Smith <rays@google.com> wrote:

> OK, I have pushed this week's changes:
> Fixes to pull from github. There were bugs introduced and required code
> deleted. Also reformatted/modified according to Google code standards.
> Major new normalization/text cleanup code in training/validat* The best
> help with this would be expertise in the various scripts, as previously
> discussed.
> Deleted some code from the LSTM recognizer that was old and unused.
> (Backwards compatible change).
> Part 1 of the changes required to move the unicharset and recoder so they
> are stored in the traineddata and therefore accessible.
>
> I have not searched through my emails to find the relevant issues to
> update them yet.
> The traineddatas and training source data are not yet updated. That is
> probably a while away yet, so the issue about the unicharset and recoder
> are not yet fully resolved anyway.
> The training process shouldn't be broken by these changes yet, I hope, *but
> the documentation is no longer accurate.*
> *If you run a new training or incremental/fine tuning training, the new
> output files will be a traineddata directly, not an LSTM traineddata
> component.*
> That output traineddata should contain some version string and separate
> lstm unicharset/recoder.
>
> The next step is to change the lstmtraining program to accept a
> traineddata instead of a unicharset, and add a tool to generate the
> traineddata, then update the documentation to match.
>
>
>
> On Fri, Jul 14, 2017 at 8:52 AM, Ray Smith <rays@google.com> wrote:
>
>> Direct from the unicode standard:
>> Anusvara. The anusvara can be seen multiple times after vowels, whether
>> independent letters or dependent vowel signs, as in vxxxx <0D08, 0D02,
>> 0D02, 0D02, 0D02>. Vowel signs can also be seen after digits, as in 355wx
>> <0033, 0035, 0035, 0D3E, 0D02>. More generally, rendering engines should be
>> prepared to handle Malayalam letters (including vowel letters), digits
>> (both European and Malayalam), dashes, U+00A0 no-break space and U+25CC
>> dotted circle as base characters for the Malayalam vowel signs, U+0D4D
>> malayalam sign virama, U+0D02 malayalam sign anusvara, and U+0D03 malayalam
>> sign visarga. They should also be prepared to handle multiple combining
>> marks on those bases.
>>
>> Is it wrong?
>>
>> On Fri, Jul 14, 2017 at 12:00 AM, Shreeshrii <notifications@github.com>
>> wrote:
>>
>>> @theraysmith <https://github.com/theraysmith> Regarding Malayalam,
>>> double anusvara
>>>
>>> Please see
>>> http://unicode.org/charts/PDF/U0D00.pdf
>>> http://www.omniglot.com/language/numbers/malayalam.htm
>>>
>>> zero in Malayalam script - pujyam looks very much like the sign for
>>> anusvar.
>>>
>>> Also, there are different anusvars shown in unicode chart--
>>>
>>> 0D00 $ഀ MALAYALAM SIGN COMBINING ANUSVARA ABOVE
>>> 0D02 $ം MALAYALAM SIGN ANUSVARA
>>> • used in Prakrit language texts to indicate gemination of the following
>>> consonant
>>>
>>> 0D3B $഻ MALAYALAM SIGN VERTICAL BAR VIRAMA
>>> 0D3C $഼ MALAYALAM SIGN CIRCULAR VIRAMA
>>>
>>> I will look up more info and post under an issue in langdata
>>>
>>> —
>>> You are receiving this because you were mentioned.
>>> Reply to this email directly, view it on GitHub
>>> <https://github.com/tesseract-ocr/tesseract/issues/995#issuecomment-315286649>,
>>> or mute the thread
>>> <https://github.com/notifications/unsubscribe-auth/AL056dtEgSZxvdhC-1CLOZ04nX1xheUPks5sNxIPgaJpZM4N9Nel>
>>> .
>>>
>>
>>
>>
>> --
>> Ray.
>>
>
>
>
> --
> Ray.
>



-- 
Ray.
 Ray,
You are right. Looks like Malayalam does have different rules, including repeated vowels. 

Please see section 8.4.3 in http://thottingal.in/documents/Fontbook.pdf by @santhoshtr.

>In samvruthokaram - ◌ു് virama is applied to a vowel sign 

>Another exception is у. This combination of a long vowel sign and anusvara is used to denote "nth" like, 16у or 16-у meaning 16th.

>Repeated vowel signs are used to denote elongation of a vowel pronunciation

Request Santhosh Thottingal @santhoshtr to  comment regarding multiple anusvars. See https://github.com/tesseract-ocr/langdata/issues/35#issuecomment-320330996

for Ray's comments about next set of changes See https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-dev/_s0TOmDlEAs/uRJ-Ozi8AAAJ for updates -msgs from Jeff Breidenbach

----------------
Aug 28, 2017

Alexander Pozdnyakov has done a really good job packing Tesseract in his
Personal Package Archive (PPA). I think it is getting to be time for wider usage,
so I'm working with him to promote these to official packages. First step is 
Debian Experimental. That's a good place to work out problems, and hopefully
something can be ready for real users within a few weeks.

----------------------
Sep 7, 2017

we will have three sets of .traineddata
files on GitHub in three separate repositories. Most users
will want LSTM Fast and that is what will be shipped as
part of Linux distributions. LSTM Best is for people willing
to trade a lot of speed for slightly better accuracy. It is also
better for certain retraining scenarios for advanced users.
The third set is for the legacy recognizer.

--------------------
Sep 15, 2017

Populated the new repositories, and removed the LSTM files from tessdata.
I'm sure documentation needs updating.



 https://github.com/tesseract-ocr/tessdata_best
https://github.com/tesseract-ocr/tessdata_fast
and
https://github.com/tesseract-ocr/tessdata Sorry, I don't follow. Which parts are identical?

```
$ du -sh best fast
1.7G	best
657M	fast
``` @amitdo  I can't seem to write a single comment without editing it three times to fix mistakes.
@roozgar Models using integer arithmetic (traineddata_fast) are smaller than ones using floating point. @stweil You had asked somewhere about tools for converting to fast/integer models... Can't find that comment to reply to. The training wiki has the answer ...

https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#lstmtraining-command-line


stop_training | bool | false | Convert the training checkpoint in --continue_from to a recognition model.
-- | -- | -- | --
convert_to_int | bool | false | With stop_training, convert to 8-bit integer for greater speed, with slightly less accuracy.

  Sorry, I do not familiar with opencl setup. Feel free to contribute required changes.  please use the latest source from master branch in github, and leptonica
1.74.2

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Thu, Jun 15, 2017 at 6:39 PM, ibr123 <notifications@github.com> wrote:

> Hi,
>
> while i was training the LSTM through this command
> lstmtraining -U ~/tesstutorial/jpntrain/jpn.unicharset \ --script_dir
> /home/ibr/langdata --debug_interval 0 \ --continue_from
> tesstutorial/jpn.lstm \ --append_index 5 --net_spec '[Lfx256 O1c105]' \
> --model_output /home/ibr/tesstutorial/new_jpn_lstm \ --train_listfile
> ~/tesstutorial/jpneval/jpn.training_files.txt \ --eval_listfile
> ~/tesstutorial/jpntrain/jpn.training_files.txt \ --max_iterations 5000
> &>~/tesstutorial/basetrain.log
>
> it went fine and started the iterations until the iteration 900 it gave
> the error:
>
> [image: lstm dumping]
> <https://user-images.githubusercontent.com/26926171/27182531-27761344-51e4-11e7-889e-ae91bad36f3a.png>
>
> although the error came, it created checkpoint file, I'm using Tesseract
> 4.00alpha, leptonica 1.74.1 and OS is Ubuntu 14.04
>
> i got the command from this website
> <https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Replace-Top-Layer>
>
> any ideas?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/993>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o1fAdCNaNN8B9u4uc_ynY9MOoHNsks5sES0JgaJpZM4N7Me6>
> .
>
 As stated in the error, you are missing

https://github.com/tesseract-ocr/langdata/blob/master/radical-stroke.txt Please copy the error text from terminal rather than adding a screenshot. You can mark it as ```code```. 1. You have not mentioned the environment hardware/software on which you are running this?

2. Please rerun tesstrain.sh to recreate the lstmf files using the latest version of tesseract and then try training. @ibr123  Is your problem solved? Please mention the solution and close the issue.  Check that the lstmf file exists in the location referred to.

What environment, o/s, hardware are you running this on?
  @theraysmith Is there any config which will change this?  https://github.com/tesseract-ocr/tesseract/issues/988 regarding Japanese is also about similar results.

Could it be related in any way to handling of non-space delimited languages/CJK? Possibly because of 

>>We also want to force a separate word for every non
      // space-delimited character when not in a dictionary context.

https://github.com/tesseract-ocr/tesseract/blob/a1c22fb0d0f6bde165ec7b7c3125420b0ba1d541/lstm/recodebeam.cpp https://github.com/tesseract-ocr/tesseract/issues/1009

Similar problem with Korean. Using the solution suggested in https://github.com/tesseract-ocr/tesseract/issues/1009
The extra spaces are removed and only interword-spaces are preserved.

See attached output files:

`--oem 1 --psm 6 -l chi_sim`
[chineses-1.txt](https://github.com/tesseract-ocr/tesseract/files/1108719/chineses-1.txt)


`--oem 1 --psm 6 -l chi_sim -c preserve_interword_spaces=1`

[chineses-spaces.txt](https://github.com/tesseract-ocr/tesseract/files/1108731/chineses-spaces.txt)


Please note that this behavior is different from the behaviour of `preserve_interword_spaces` in 3.05 branch, where it preserves multiple spaces between words and does not compress them to single space.

@theraysmith  Is this intentional for 4.0? Since there are reports of `preserve_interword_spaces` not working with 4.0 - see https://github.com/tesseract-ocr/tesseract/issues/781

 Sorry, @hoangtocdo90 . I do not know about `ResultIterator`   As suggested in https://github.com/tesseract-ocr/tesseract/issues/1009

use `-c preserve_interword_spaces=1` to remove extra spaces

Also see https://github.com/tesseract-ocr/tesseract/issues/991

  AFAIR somebody wanted to have option compile only individual parts of tesseract. 
IMO it does not make sense and I think it should go away - there is other way how do deal with it (e.g. we implement disable graphics, disable cube)  See https://github.com/tesseract-ocr/tesseract/issues/961

What is the  hardware you are using?
Is this being run under WSL?

I saw improvement by disabling openmp, you can gI've it a try.
 Try using the latest code from github instead of the initial alpha, there have been many changes and bug fixes.  use leptonica 1.74.2

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Jun 6, 2017 at 6:58 PM, ibr123 <notifications@github.com> wrote:

> Hi,
>
> I wanted to install and compile leptonica and then tesseract on a server
> following this website
> <https://medium.com/@lucas63/installing-tesseract-3-04-in-ubuntu-14-04-1dae8b748a32>
> i installed and downloaded leptonica 1.74.1 and tesseract 4.00.00alpha on
> VM and VB before following the same steps exactly, yet today i found this
> error coming out on the terminal
> [image: env_error]
> <https://cloud.githubusercontent.com/assets/26926171/26831244/5b97d520-4ad4-11e7-9a87-bf86bc754e79.png>
>
> i tried to comment the error section but that caused another problems, i
> even tried to get the leptonica.gz again and running the steps once more,
> yet the same problem.
>
> keep in mind that the OS on the server is Ubuntu 14.04, which is the same
> OS that i used on VM and OS on VB and worked on both cases, is this issue
> cause by a dependency or what exactly?
> Please any ideas? as i need to get the server up and running as soon as
> possible
> Thanks
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/981>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o8TMqtSnbNnqZqtpRT5UpylV_vXBks5sBVQTgaJpZM4NxV7H>
> .
>
 https://github.com/DanBloomberg/leptonica/releases/tag/1.74.2

I think it is a full release.

Please see https://github.com/tesseract-ocr/tesseract/pull/979
for fixes made recently that require this change


ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Jun 6, 2017 at 7:17 PM, ibr123 <notifications@github.com> wrote:

> thanks, but what is the command to get the newer version, its not:
> wget http://www.leptonica.com/source/leptonica-1.74.2.tar.gz
>
> and is it an alpha version too or a full release?
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/981#issuecomment-306491228>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o784IlARn2PAu-5TMVhpXcgWd_QGks5sBVh7gaJpZM4NxV7H>
> .
>
 You are not able to build leptonica => you need to solve it  with leptonica project team (e.g. not here).  Someone broke my leptonica cmake scripts? :) > Should we refuse builds with Leptonica < 1.74.2?

We can do anything, because it's dev branch.
+1 from me  I am still getting the error as this is not merged yet.

```
Breakpoint 7, tesseract::LSTMTrainer::ReadSizedTrainingDump (this=this@entry=0x7f2a7cb9f680, data=0x0, size=0) at lstmtrainer.cpp:924
924     bool LSTMTrainer::ReadSizedTrainingDump(const char* data, int size) {
(gdb) backtrace
#0  tesseract::LSTMTrainer::ReadSizedTrainingDump (this=this@entry=0x7f2a7cb9f680, data=0x0, size=0) at lstmtrainer.cpp:924
#1  0x0000000000428cc1 in tesseract::LSTMTrainer::ReadTrainingDump (this=this@entry=0x7f2a7cb9f680, data=..., trainer=trainer@entry=0x7f2a7cb9f680)
    at lstmtrainer.cpp:921
#2  0x000000000040af96 in tesseract::LSTMTester::RunEvalSync (this=this@entry=0x7fffe865b310, iteration=1, training_errors=<optimized out>, model_data=...,
    training_stage=1) at lstmtester.cpp:86
#3  0x000000000040b476 in tesseract::LSTMTester::ThreadFunc (lstmtester_void=0x7fffe865b310) at lstmtester.cpp:123
#4  0x00007f2a82be8184 in start_thread (arg=0x7f2a7cba0700) at pthread_create.c:312
#5  0x00007f2a820ca37d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111
(gdb) info frame
Stack level 0, frame at 0x7f2a7cb9f540:
 rip = 0x428c40 in tesseract::LSTMTrainer::ReadSizedTrainingDump (lstmtrainer.cpp:924); saved rip = 0x428cc1
 called by frame at 0x7f2a7cb9f540
 source language c++.
 Arglist at 0x7f2a7cb9f530, args: this=this@entry=0x7f2a7cb9f680, data=0x0, size=0
 Locals at 0x7f2a7cb9f530, Previous frame's sp is 0x7f2a7cb9f538
(gdb) up
#1  0x0000000000428cc1 in tesseract::LSTMTrainer::ReadTrainingDump (this=this@entry=0x7f2a7cb9f680, data=..., trainer=trainer@entry=0x7f2a7cb9f680)
    at lstmtrainer.cpp:921
921       return trainer->ReadSizedTrainingDump(&data[0], data.size());
(gdb) info frame
Stack level 1, frame at 0x7f2a7cb9f540:
 rip = 0x428cc1 in tesseract::LSTMTrainer::ReadTrainingDump (lstmtrainer.cpp:921); saved rip = 0x40b476
 tail call frame, caller of frame at 0x7f2a7cb9f540
 source language c++.
 Arglist at unknown address.
 Locals at unknown address, Previous frame's sp is 0x7f2a7cb9f540
(gdb) up
#2  0x000000000040af96 in tesseract::LSTMTester::RunEvalSync (this=this@entry=0x7fffe865b310, iteration=1, training_errors=<optimized out>, model_data=...,
    training_stage=1) at lstmtester.cpp:86
86        if (!trainer.ReadTrainingDump(model_data, &trainer)) {
(gdb) info frame
Stack level 2, frame at 0x7f2a7cb9feb0:
 rip = 0x40af96 in tesseract::LSTMTester::RunEvalSync (lstmtester.cpp:86); saved rip = 0x40b476
 called by frame at 0x7f2a7cb9fee0, caller of frame at 0x7f2a7cb9f540
 source language c++.
 Arglist at 0x7f2a7cb9f538, args: this=this@entry=0x7fffe865b310, iteration=1, training_errors=<optimized out>, model_data=..., training_stage=1
 Locals at 0x7f2a7cb9f538, Previous frame's sp is 0x7f2a7cb9feb0
 Saved registers:
  rbx at 0x7f2a7cb9fe78, rbp at 0x7f2a7cb9fe80, r12 at 0x7f2a7cb9fe88, r13 at 0x7f2a7cb9fe90, r14 at 0x7f2a7cb9fe98, r15 at 0x7f2a7cb9fea0, rip at 0x7f2a7cb9fea8
(gdb)
```  Tesseract is OCR engine and it requires image with text input (e.g. it is not text detection tool). So it not is not a bug, but tesseract is not not tool you expected.   Sorry for not having noticed the banner. 

I will add that line and link.  Add an Issue Template
Reorganize Readme.MD Thanks for your feedback.

I was looking at the Readme from the point of view of someone who is
looking at it on github.com and thought that the latest Readme.md would be
visible to them there, hence moved it to the bottom.

This text as well as the badges seemed to be taking up lots of space when
looking at the page, right on top. Maybe there is a different way to
distinguish between the two sets of badges, without the huge headings.

Please feel free to change the PR and squash it too - I did't realize that
multiple changes I made in the fork will all become part of the PR.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Thu, Jun 1, 2017 at 2:20 AM, Egor Pugin <notifications@github.com> wrote:

> *@egorpugin* commented on this pull request.
> ------------------------------
>
> In README.md
> <https://github.com/tesseract-ocr/tesseract/pull/964#discussion_r119470371>
> :
>
> > @@ -1,16 +1,9 @@
>  # Tesseract OCR
>
> -For the latest online version of the README.md see:
> -
> -https://github.com/tesseract-ocr/tesseract/blob/master/README.md
> -
> -### Build
> -[![Build Status](https://travis-ci.org/tesseract-ocr/tesseract.svg?branch=master)](https://travis-ci.org/tesseract-ocr/tesseract)
> -[![Build status](https://ci.appveyor.com/api/projects/status/miah0ikfsf0j3819/branch/master?svg=true)](https://ci.appveyor.com/project/zdenop/tesseract/)
> -
> -### Other
>
> Where? The idea behind this caption was to split badges.
> In this PR they are again near each other.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/964#discussion_r119470371>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o0cXztdqlgCKlXwmpmHI-VcH1EtZks5r_dKugaJpZM4NrqXr>
> .
>
 Badges look ugly now.
https://github.com/Shreeshrii/tesseract/blob/master/README.md

Current form is better. @egorpugin I have reverted the change for badges and updated link for 3.05.01 release.

Changed page will look like https://github.com/Shreeshrii/tesseract/blob/master/README.md

Please make any other changes that you see fit.

Also, please add your name as well as those of other maintainers/members with write access to the repo.  works with latest code from master branch, using the LSTM engine ie. --oem 1

$ tesseract test.png stdout --oem 1 --psm 6 -l eng
Warning. Invalid resolution 0 dpi. Using 70 instead.
_SA1C17010068

$ tesseract test.png stdout --oem 0 --psm 6 -l eng
Warning. Invalid resolution 0 dpi. Using 70 instead.
mgAﬁ'Ei'ib'fboss
 please use tesseract forum for asking questions.  TesseractConsole.exe is not part of tesseract project. We do not support 3rd party programs. Please contact its author.  Using the latest code from master branch seems to be slower than from commits a few days back. Training seems to hang at times. I am trying to get an objective measure by running sample training against different builds and will post results here. ```
training/tesstrain.sh \
  --fonts_dir  /mnt/c/Windows/Fonts \
  --tessdata_dir ./tessdata \
  --training_text ../langdata/eng/eng.training_text \
  --langdata_dir ../langdata \
  --lang eng  \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --fontlist "Arial" \
  --output_dir ~/tesstutorial/engtest
  
training/tesstrain.sh \
  --fonts_dir  /mnt/c/Windows/Fonts \
  --tessdata_dir ./tessdata \
  --training_text ../langdata/eng/eng.training_text \
  --langdata_dir ../langdata \
  --lang eng  \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --fontlist "Arial" \
  "Courier New" \
  --output_dir ~/tesstutorial/engeval

rm -rf  ~/tesstutorial/engtuned_from_engtest 

mkdir -p ~/tesstutorial/engtuned_from_engtest 

combine_tessdata -e ../tessdata/eng.traineddata \
  ~/tesstutorial/engtuned_from_engtest/eng.lstm
 ```
engtest was built with   --fontlist "Arial" .
engeval was built with   --fontlist "Arial"   "Courier New" .

command on non-debug build, under WSL on Windows 10
using unchanged training_text and other files from langdata repo.

```
time lstmtraining \
  --continue_from ~/tesstutorial/engtuned_from_engtest/eng.lstm \
  --train_listfile ~/tesstutorial/engtest/eng.training_files.txt \
  --eval_listfile ~/tesstutorial/engeval/eng.training_files.txt \
  --model_output ~/tesstutorial/engtuned_from_engtest/engtuned \
  --debug_interval 0 \
 --max_image_MB 1000 \
 --perfect_sample_delay 19 \
 --max_iterations 1000
```
 on
x86_64 x86_64 x86_64 GNU/Linux (WSL)
on Windows 10 Home
AMD A4-5000 APU @1.50 GHz
4 GB RAM

as of https://github.com/tesseract-ocr/tesseract/commit/42066ce69057dc81ae6cbc176300bb20223c7d0b

```

2 Percent improvement time=1, best error was 100 @ 0
At iteration 1/900/900, Mean rms=0.153%, delta=0%, char train=0.01%, word train=0.036%, skip ratio=0%,  New best char error = 0.01Deserialize failed w
rote best model:/home/shree/tesstutorial/engtuned_from_engtest/engtuned0.01_1.lstm wrote checkpoint.

Finished! Error rate = 0.01

real    64m31.894s
user    185m23.578s
sys     0m41.766s

``` on
x86_64 x86_64 x86_64 GNU/Linux (WSL)
on Windows 10 Home
AMD A4-5000 APU @1.50 GHz
4 GB RAM

as of https://github.com/tesseract-ocr/tesseract/commit/5a06417eb273a3cc3e5f720ca8fa4bbaa7940ae6

```
2 Percent improvement time=1, best error was 100 @ 0
At iteration 1/900/900, Mean rms=0.153%, delta=0%, char train=0.01%, word train=0.036%, skip ratio=0%,  New best char error = 0.01Deserialize failed wrote best model:/home/shree/tesstutorial/engtuned_from_engtest/engtuned0.01_1.lstm wrote checkpoint.

Finished! Error rate = 0.01

real    51m58.330s
user    148m10.469s
sys     0m43.609s
``` on
x86_64 x86_64 x86_64 GNU/Linux (WSL)
on Windows 10 Home
AMD A4-5000 APU @1.50 GHz
4 GB RAM

as of https://github.com/tesseract-ocr/tesseract/commit/b86b4fa06ba4d2afa00c53470a19f6630e638f66

```

2 Percent improvement time=1, best error was 100 @ 0
At iteration 1/900/900, Mean rms=0.153%, delta=0%, char train=0.01%, word train=0.036%, skip ratio=0%,  New best char error = 0.01Deserialize failed wrote best model:/ho
me/shree/tesstutorial/engtuned_from_engtest/engtuned0.01_1.lstm wrote checkpoint.

Finished! Error rate = 0.01

real    58m48.689s
user    157m45.719s
sys     0m51.891s
``` If  it does not add too much overhead, I would suggest adding some kind of regression testing as part of continuous integration.

Also, will be helpful for others to test to confirm, since I ran this under WSL on windows 10. >Shree, did you run those tests with WSL?

Yes. I did not set anything special for OPENMP though my PC probably supports it.  on 
Ubuntu 14.04.5 LTS (GNU/Linux 4.4.0-75-generic x86_64)
Intel(R) Pentium(R) Dual CPU E2220 @ 2.40GHz
4 GB RAM, 

with git master
tesseract 4.00.00alpha-538-g42066ce-1995

```
2 Percent improvement time=1, best error was 100 @ 0
At iteration 1/800/800, Mean rms=0.157%, delta=0%, char train=0.009%, word train=0.033%, skip ratio=0%,  New best char error = 0.009Deserialize failed wrote best model:/home/shree/tesstutorial/engtuned_from_engtest/engtuned0.009_1.lstm wrote checkpoint.

Finished! Error rate = 0.009

real    35m51.291s
user    58m50.184s
sys     4m23.416s
``` on
Ubuntu 14.04.5 LTS (GNU/Linux 4.4.0-75-generic x86_64)
Intel(R) Pentium(R) Dual CPU E2220 @ 2.40GHz
4 GB RAM,

reset hard to 5a06417eb273a3cc3e5f720ca8fa4bbaa7940ae6

shree@sanskrit:~/tesseract$ tesseract -v
tesseract 4.00.00alpha-533-g5a06417-1990
 leptonica-1.74.2
 
```
2 Percent improvement time=1, best error was 100 @ 0
At iteration 1/800/800, Mean rms=0.157%, delta=0%, char train=0.009%, word train=0.033%, skip ratio=0%,  New best char error = 0.009Deserialize failed wrote best model:/home/shree/tesstutorial/engtuned_from_engtest/engtuned0.009_1.lstm wrote checkpoint.

Finished! Error rate = 0.009

real    35m41.198s
user    58m38.460s
sys     4m9.208s
``` Closing as problem not reproducable on other systems. FYI 

I built with --disable-openmp under WSL. Now it is taking less time.

```

2 Percent improvement time=1, best error was 100 @ 0
At iteration 1/900/900, Mean rms=0.153%, delta=0%, char train=0.01%, word train=0.036%, skip ratio=0%,  New best char error = 0.01Deserialize failed wrote best model:/ho
me/shree/tesstutorial/engtuned_from_engtest/engtuned0.01_1.lstm wrote checkpoint.

Finished! Error rate = 0.01

real    65m34.655s
user    63m39.250s
sys     0m7.453s
```
 I am reopening the issue, because there is some impact on `lower level cpus` which support `openmp`.

By disabling openmp, the `user` time has become almost one third on WSL on my AMD Windows 10 PC.

from
```
real    64m31.894s
user    185m23.578s
sys     0m41.766s
```

to

```
real    65m34.655s
user    63m39.250s
sys     0m7.453s
```

>User+Sys will tell you how much actual CPU time your process used.

Maybe, need to add some recommendation in wiki to `--disable-openmp` I think it would he helpful to mention on the 'Compiling' pages to build with `--disable-openmp`.

@stweil IS it ok to do so? Are there any particular conditions under which it should be recommended?

 on
Ubuntu 14.04.5 LTS (GNU/Linux 4.4.0-75-generic x86_64)
Intel(R) Pentium(R) Dual CPU E2220 @ 2.40GHz
4 GB RAM,
```
lstmtraining for tesseract training
  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
15229 shree     20   0 1152728 468280   6720 R  98.0 11.6 788:35.04 lstmtraining
```
It has been taking 92-98% CPU.

@stweil Any recommendation on how to reduce cpu usage? 
I haven't tried with disable-openmp on that machine. --disable-openmp improved performance of tesseract in recognizing images. But lstmtraining still taking 99% cpu. I use that machine remotely. 

I am now running the command as `nice lstmtraining` - so it should be using the default nice value of 10. It still shows cpu usage upto 99-100%, but if another process eg. firefox is used locally on that machine, I am hoping that it will get priority and not degrade the browsing performance.

Is there a valgrind or other debugging command which will help isolate what is causing this high cpu usage?
  Tested user-words option with 3.05.01 on windows (using binaries by @stweil)

Works ok. See attached test image.

bazaar config file as used (uses system dictionary + user words)
```
load_system_dawg     T
load_freq_dawg       T
user_words_suffix    user-words
user_patterns_suffix user-patterns
```

eng.user-words as used
```
Online
the
quick
brown
fox
jumped
```

image used for recognition

![test](https://cloud.githubusercontent.com/assets/5095331/26752834/7c1a3366-4876-11e7-90ae-66fb6d7a5cdb.png)

Output without user-words- Notice `Dnline` instead of `Online`
```
tesseract test.png stdout
shared Guruvayoor Dnline Friends's post
```

Output with user-words - `Online` recognized correctly 
```
tesseract test.png stdout  bazaar
shared Guruvayoor Online Friends's post
```

So `Online` from eng.user-words was used, when using the `bazaar` config file, and led to improved accuracy. I tested for user-patterns just now with versions 3.02 and 3.05.01, both for windows so that I didn't have to worry about correct versions of leptonica. The test image is attached.

There is no change in output with the user-patterns option in both. So, if this feature worked, it would be before 3.02. 

However, just by resizing the image to 200%, the dates  are correctly recognized. 

![date](https://cloud.githubusercontent.com/assets/5095331/26753470/976e8802-4884-11e7-82aa-5cb4bc1b75e5.png)
![date-small](https://cloud.githubusercontent.com/assets/5095331/26753469/976c1a5e-4884-11e7-8db0-6eefa4624a54.png)
 @zdenop @amitdo @stweil Have you used user-patterns option? If so, with which version? > I also have a scenario where working user patterns would help.

@stweil Interesting project :-)

https://groups.google.com/forum/#!searchin/tesseract-ocr/user$20patterns$20%7Csort:date/tesseract-ocr/S9CIK3jOMWw/u7dnVDASFLgJ

>The ability to use user patterns was added by Tesseract 3.01, and now has a little documentation.  See the comment in dict/trie.h:

http://code.google.com/p/tesseract-ocr/source/browse/tags/release-3.01/dict/trie.h

So it broke somewhere between 3.01 and 3.02... I did not use it either.
But as far as I understand: "user patterns" just help to extend tesseract dictionary. 
And as it is known putting word to dictionary does not mean tesseract will recognize it (or other way around disabling dictionaries will not cause 0% recognition). => I do not know if the feature is working at all, but I would not expect significant effect on result from it.  Tesseract 3 has different versions and the accuracy and performance differs
in those too.

See https://groups.google.com/forum/#!topic/tesseract-dev/LErriuT-sck

for posts regarding Tesseract performance and accuracy across versions 2.04
- 3.04.01

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, May 29, 2017 at 10:14 PM, vaasily <notifications@github.com> wrote:

> Hi Amit,
>
> Thanks for the answer.
>
> I'm going to compare the following OCR engines:
>
>    1. Tesseract 4
>    2. Tesseract 3
>    3. ABBYY Cloud OCR SDK
>    4. Microsoft Computer Vision API
>    5. Google Cloud Vision API
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/959#issuecomment-304698989>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o0X2uz8jHoQHeWaL-ZexujSg03q3ks5r-vXZgaJpZM4NpdrT>
> .
>
  which traineddata file did u use? Did you use `--oem 1` to use the LSTM engine and LSTM laanguage model?

I get the following output 

```
हसेरै बिदा गर्छु भन्थे तिमीलाई

तर मुस्कान कतै डेरा सर्यो ||

रोक्छु भन्थे यी मनभित्र मारिएका बादललाई
तर आशु बनी बर्सिदियो ||
```
command used was:

tesseract nep.png nep -l nep --oem 1 --psm 6 --tessdata-dir ../tessdata
 Please close the issue.  What version of leptonica you use?
Did you run `./autogen.sh` (in tesseract) before running `./configure` ? > checking for l_generateCIDataForPdf in -llept... no

Do you have only one installation of leptonica in your system? Because current [leptonica has this function](https://github.com/DanBloomberg/leptonica/blob/master/src/allheaders.h#L1410).

> leptonica builded from source does not create liblept.so, instead it creates libleptonica.so

I can not check it at the moment, but [source code show liblept is output of compilation](https://github.com/DanBloomberg/leptonica/blob/master/src/Makefile.am#L4). How did you build leptonica? @zdenop Tagging 3.05.01 release will help. Build leptonica with autotools, not cmake if  you're using tess autotools. Otherwise use cmake+cmake build.  you can get the latest appveyor build artifacts from

win32

https://ci.appveyor.com/project/zdenop/tesseract/build/master.993/job/c8rtk21uqliscckn/artifacts

win64

https://ci.appveyor.com/project/zdenop/tesseract/build/master.993/job/c6uplulmcrk7bew8/artifacts @weituotian: we provide source code only - e.g. we do not produce and distribute windows libraries (with header files), that you can use in your project. @weituotian. you can try to ask on tesseract user forum.  > AppVeyor build failed I gave it a try with eurotext.tif with -l eng and san001.tif with -l hin. I did not find much difference between the `optimized code' and code from the earlier commit, though there are variations in different runsof each  from command line.

See attached log files with numbers.
[test-san001.txt](https://github.com/tesseract-ocr/tesseract/files/1033492/test-san001.txt)
[test-eurotext.txt](https://github.com/tesseract-ocr/tesseract/files/1033491/test-eurotext.txt)

As has been previously noted, legacy engine is faster for -l eng and LSTM engine is faster for -l hin. What is status of this PR? At least it needs to resolve conflicts....  There are multiple pages with installation instructions and they are sometimes in conflict.

https://github.com/tesseract-ocr/tesseract/blob/master/INSTALL
https://github.com/tesseract-ocr/tesseract/blob/master/INSTALL.GIT.md

https://github.com/tesseract-ocr/tesseract/wiki/Compiling-%E2%80%93-GitInstallation
https://github.com/tesseract-ocr/tesseract/wiki/Compiling

@stweil It will be great if we can merge all current and correct info in one page and then redirect the other pages to it. That way only one page needs maintaining on regular basis.

Also readme.md can be linked to that page.

Thaks!  Have you looked at tsv and hocr ouputs? --help option does not document pdf neither. So there is no difference between pdf, tsv and hocr ;-)  Please use tesseract user forum for asking support  1. you can install git for windows with bash option and then you will be
able to run tesstrain.sh script under windows.

2. your lstmtraining command is incorrect.

*--train_listfile ara.training_text.txt*

*the listfile has a list of lstmf files created using box/tiff files by
tesseract with lstm.train config gile.*

*See **https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Finetune
<https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Finetune>*

*and follow the tutorial *

2. your lstmtraining command is incorrect.
 https://git-scm.com/downloads

download git for windows
install including the option for bash



ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, May 23, 2017 at 10:59 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
wrote:

> 1. you can install git for windows with bash option and then you will be
> able to run tesstrain.sh script under windows.
>
> 2. your lstmtraining command is incorrect.
>
> *--train_listfile ara.training_text.txt*
>
> *the listfile has a list of lstmf files created using box/tiff files by
> tesseract with lstm.train config gile.*
>
> *See **https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Finetune
> <https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Finetune>*
>
> *and follow the tutorial *
>
> 2. your lstmtraining command is incorrect.
>
>
>
 --train_listfile ara.nicidprint.exp0.lstmf 

is incorrect. you need a text file which has the filename in it.

See attached zip file for a sample.
[ara.zip](https://github.com/tesseract-ocr/tesseract/files/1024546/ara.zip)


EDIT: ara.zip file is from May 2017. Ray has changed the training method in July/Aug 2017 or so. So, files from that will not work. Please see the wiki page on training for latest info. > ..\combine_tessdata -o ..\tessdata\ara.traineddata ara.lstm
ara.unicharset ara.number-dawg ara.punc-dawg ara.word-dawg

-o option is for overwrite

so it looks for an ara.traineddata in specified directory, renames it to
tmp version and then creates the new one.

check that  u have an old ara.traineddata
check u have write access to directory

u may have to remove old tmp files, if any.

check the options of combine_tessdata

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sun, Jun 4, 2017 at 5:20 PM, chris <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/shreeshrii>
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/947#issuecomment-306035336>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o9cN923d1y6gHq1VcjJ4uXB3QLDQks5sApoDgaJpZM4Njq05>
> .
>
 Both Fine Tune and replacing the top layer training start with the .lstm
file from the existing traineddata. Training builds on top of that. So the
files will be about the same size.

If you only want to make traineddata from your trained files, do not use

```
Command I used:
..\combine_tessdata -o ..\tessdata\ara.traineddata ara.lstm ara.unicharset
ara.number-dawg ara.punc-dawg ara.word-dawg
```

Instead, just combine the files you need

```
..\combine_tessdata ara.
```
where you have all the required files ie. ara.lstm ara.unicharset
ara.number-dawg ara.punc-dawg ara.word-dawg

combine-tessdata finds ara.* files (the ones required for traineddata and
combines them).

Your file size should be smaller.

You can compare what's included in the ara.traineddata from tessdata repo
by the following command:
-u option unpacks the data
```
combine_tessdata -u ara.traineddata ara.
Extracting tessdata components from ara.traineddata
Wrote ara.config
Wrote ara.unicharset
Wrote ara.punc-dawg
Wrote ara.word-dawg
Wrote ara.number-dawg
Wrote ara.freq-dawg
Wrote ara.lstm
Wrote ara.lstm-punc-dawg
Wrote ara.lstm-word-dawg
Wrote ara.lstm-number-dawg
0:config:size=545, offset=168
1:unicharset:size=7831, offset=713
6:punc-dawg:size=1066, offset=8544
7:word-dawg:size=6303746, offset=9610
8:number-dawg:size=426, offset=6313356
9:freq-dawg:size=1346, offset=6313782
17:lstm:size=5324626, offset=6315128
18:lstm-punc-dawg:size=1466, offset=11639754
19:lstm-word-dawg:size=895354, offset=11641220
20:lstm-number-dawg:size=658, offset=12536574
```
 Please see
https://github.com/tesseract-ocr/tesseract/blob/master/training/tesstrain_utils.sh

It is a copy of the word-dawg based on the wordlist, but using the
unicharset which was used for lstm training (this unicharset could be
different from the one used for tesseract or cube training).

Also, please note that currently the lstm training process still has some
'bugs' and you may not get better results than the 4.0 traineddata provided
by Google in the repo.



ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Jun 5, 2017 at 4:36 PM, LatifWirelessMarketer <
notifications@github.com> wrote:

> @Shreeshrii <https://github.com/shreeshrii> Thank You soo much brother.
>
> Btw do you know what is the difference between ara.word-dawg &
> ara.lstm-word-dawg?
>
> I mean I know how to generate word dawg as it is generated based on word
> list but what about lstm-word list?
>
> Thank You
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/947#issuecomment-306162441>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o0p1c04ZQsgzTFr4qnfgAUYGfbVZks5sA-FCgaJpZM4Njq05>
> .
>
  Please use tesseract user forum for asking support.  We do not support 3rd party project. Please use tesseract user forum.  Yes I've done quite a lot of performance vs accuracy testing.

Memory new/delete:
The network system uses a rather complex scratchpad mechanism to minimize
the number of allocations/deallocations. It helped a lot with both speed
and peak memory.
I'd be curious to know where the current bottleneck is is you have
specifics of the stack where the allocations take place.

UnicharIdArrayUtils:
Hmm. Looks like it may be doing too many id_to_unichar (). Again
callers/stack traces would be useful.

snprintf:
Really? where from? Are you running with some debug flags on?

DotProduct:
Float vs double:

   - Running a large dot product strictly in float (ie float += (float =
   float * float)) is an unwise thing to do. (Ahem, no comment on any other nn
   libraries that do that.)
   - I found significant accuracy impacts using float in the multiply-add
   accumulation, and neither SSE nor AVX provide a double = float x float
   operation, (analogous to the 32 = 16x16 integer instruction in SSE) which
   is what is really needed.
   - The SSE/AVX float->double cast is extremely slow - slower than reading
   a double from memory.

The code is therefore optimized to minimize the memory bandwidth, and the
number of float->double conversions, while using double += double*double in
the AVX code.
(Since writing the AVX dot product, I thought of a better way of doing it,
but haven't had time to implement that yet.)
In any case, the time savings are small, a factor of <2.

A good integer implementation may squeeze better out of it, but I haven't
seen it yet.OTOH, I haven't tried it lately.
AVX2 and AVX512 extend the integer operations beyond the ones available on
SSE (not on base AVX) and may make it worth it, when I get  machine with
AVX512.
The additional benefit of (8 bit) integer is that it reduces the size of
everything, making it more likely that data will stay in a higher-level
cache.

*Far greater performance improvements can be made by making the network
smaller.*
As I already indicated, I have had some very good results in this area,
with a network 3x faster than the legacy code (for English) and *much*
faster than the legacy code for complex scripts.

I since messed up the synthetic data pipeline and training trying to
improve Indic, but I have major improvements in some other languages, so
when I get back to the best results for everything, I think you'll like it.

BTW I get a significant speed-up in walltime with the open MP code running.
(Better than 2x) Did you compile and link it correctly with OpenMP?
I have noticed that the CPU profile with OpenMp running is of little
practical use.

On Mon, May 22, 2017 at 1:38 AM, Stefan Weil <notifications@github.com>
wrote:

> Performance is important for real time OCR, mass production OCR and
> training.
>
> In this RFC I'd like to discuss performance bottlenecks and potential
> improvements.
>
> See also the Tesseract wiki
> <https://github.com/tesseract-ocr/tesseract/wiki/4.0-Accuracy-and-Performance>
> .
>
> According to my tests with Valgrind's tool callgrind, these functions
> have the largest computational costs (ordered by decreasing time):
>
>    - memory allocations / deallocations
>    - tesseract::UnicharIdArrayUtils::compare
>    - tesseract::DotProductAVX (or the other implementations of the dot
>    product)
>    - vfprintf (called from snprintf)
>
> tesseract::UnicharIdArrayUtils::compare and memory allocations /
> deallocations are also the functions which are called most often.
>
> I recently had a closer look at the dot product calculations and noticed
> that at least some input vectors are converted from float to double
> (which takes time). The dot product is always done with double values
> (more expensive than float). If memory bandwidth is the limiting factor,
> using double means doubled time compared with float. The current code
> uses 4 parallel threads. I have run some timing tests without that
> parallelization and got nearly the same execution time. @theraysmith
> <https://github.com/theraysmith>, did you try using float for the dot
> product, and do you get better performance from parallelization in that
> part of the OCR process?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/943>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AL056TVhtIV-0-2TldC4EuvYMqx71Tb7ks5r8Ul6gaJpZM4NiCwj>
> .
>



-- 
Ray.
 Is this for --oem 0 or --oem 1 ?

I thought that Unicharambigs is not used  by LSTM engine... @stweil 

Is that with `debug`? What about without it?  Please see https://github.com/tesseract-ocr/tesseract/issues/961#issuecomment-305420753

for another example of decrease in user time with --disable-openmp.

> By disabling openmp, the user time has become almost one third on WSL on my AMD Windows 10 PC.  https://github.com/tesseract-ocr/tesseract#supported-compilers  Please use tesseract user forum for asking support Tesseract langdata has two languages for kurdish

https://github.com/tesseract-ocr/langdata/tree/master/kur
https://github.com/tesseract-ocr/langdata/tree/master/kur_ara

Please review the training text, wordlist etc there and if there is a mix in those files, please file a issue under langdata. Thanks.  This is not tesseract problem. We will not release tesseract outside of github. Yes you can do it. 
This is the way how binary version of tesseract is distributed: volunteers (responsible for fixing distribution/packaging) create packages and put them to distribution channel of their choice.  Please use tesseract user forum for asking support  If you copy the url and paste, it works. It is a page in chinese (i think).   I agree that this would be a useful feature. Specially since tesseract already detects when the image has a low dpi.

Example Image where this would help - https://github.com/tesseract-ocr/tesseract/issues/997 Another related addition could be allowing pdf input. leptonica can be used for converting pdf to multipage tiff - it could be controlled via a config if needed.

https://github.com/DanBloomberg/leptonica/blob/master/prog/pdf2mtiff

Also,  leptonica functions could be used for converting images to 300 dpi / larger size within tesseract itself, which will improve results for a lot of users. Again, it could be implemented via a config, so that those  who prefer to pre-process by themselves for better control can do so.  Copied from: https://github.com/tesseract-ocr/tesseract/pull/911#issuecomment-302068376

> @stweil - How would I start Tesseract to process page1.png and page2.png in a single run?
> 
> @amitdo - Prepare a text file that has the path to each image:
> 
> path/to/1.png
> path/to/2.png
> path/to/3.tiff
> 
> Save it, and then give its name as input file to Tesseract.
> 
> tesseract savedlist output
> 
> @stweil - Thank you, good to know that. It looks like the ChangeLog, other documentation and the program help text need an update.
> 
> Currently all pages are written to one output file (per format). Some formats include page information (hOCR, PDF). Others like TXT don't, but could use a page separator character (ASCII 0x0C = FF). Would it help to support an output base parameter with placeholders like page number or image base name to generate one output file per input image?
> 
> The multi-page feature was added in 2014 by commit 25a8c7b. @stweil 

>Would it help to support an output base parameter with placeholders like page number or image base name to generate one output file per input image?

I can think of two cases for using this.

1. A document for which each page is available as a separate image.
2. Separate documents images which need to be run in a batch

For the first, current processing is sufficient, maybe with an additional  page separator character .

For the second, it would be useful to have the option you suggest. savedlist

```
Sachitra_Saraswati_Prasad_004932_HR-g4_page0001_1L.tif
Sachitra_Saraswati_Prasad_004932_HR-g4_page0002_2R.tif
Sachitra_Saraswati_Prasad_004932_HR-g4_page0004_2R.tif
Sachitra_Saraswati_Prasad_004932_HR-g4_page0005_1L.tif
Sachitra_Saraswati_Prasad_004932_HR-g4_page0005_2R.tif
```

1. `tesseract savedlist output`

Current implementation creates output file `output.txt` with concatenated OCR text.

Console displays filenames being processed

```
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 0 : Sachitra_Saraswati_Prasad_004932_HR-g4_page0001_1L.tif
Page 1 : Sachitra_Saraswati_Prasad_004932_HR-g4_page0002_2R.tif
Page 2 : Sachitra_Saraswati_Prasad_004932_HR-g4_page0004_2R.tif
Page 3 : Sachitra_Saraswati_Prasad_004932_HR-g4_page0005_1L.tif
Page 4 : Sachitra_Saraswati_Prasad_004932_HR-g4_page0005_2R.tif
```

2. `tesseract savedlist savedlist'

Suggested option for additional implementation, to create separate output files for each line in the `savedlist` list file. 

The syntax of the command could be different - either not specifying the outputbase or using the same name as the listfile or something else - whatever is easy to implement.

The output files will be based on the filenames in the listfile, same basename with change of extenstion.

The listfile in the above two cases can be created by eg. by `ls -l *.tif >savedlist`

3. option suggested above by @stweil 

> get pairs of image file name and output base from the file list instead of image files only. 

This would require change to listfile  format. 

Optionally, if output base is not given separately in listfile, then it will create file based on filenames in list.



 @stweil Please compare the time taken for the list option vs multipage tif vs processing each file separately in a loop to see what may be a recommended option.

here is the result of my singular test using Hindi traineddata.

```
 ----------------------------------------------------
Sachitra_Saraswati_Prasad_004932_HR-g4_page0001_1L.tif
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1

real    0m24.880s
user    1m11.375s
sys     0m0.813s
Sachitra_Saraswati_Prasad_004932_HR-g4_page0002_2R.tif
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1

real    0m37.305s
user    1m49.734s
sys     0m0.891s
Sachitra_Saraswati_Prasad_004932_HR-g4_page0004_2R.tif
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1

real    0m43.672s
user    2m1.156s
sys     0m1.078s
Sachitra_Saraswati_Prasad_004932_HR-g4_page0005_1L.tif
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1

real    0m39.755s
user    1m46.578s
sys     0m0.922s
Sachitra_Saraswati_Prasad_004932_HR-g4_page0005_2R.tif
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1

real    0m23.214s
user    1m6.891s
sys     0m0.781s
-------------------------------------------------
list.txt
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 0 : Sachitra_Saraswati_Prasad_004932_HR-g4_page0001_1L.tif
Page 1 : Sachitra_Saraswati_Prasad_004932_HR-g4_page0002_2R.tif
Page 2 : Sachitra_Saraswati_Prasad_004932_HR-g4_page0004_2R.tif
Page 3 : Sachitra_Saraswati_Prasad_004932_HR-g4_page0005_1L.tif
Page 4 : Sachitra_Saraswati_Prasad_004932_HR-g4_page0005_2R.tif

real    3m26.132s
user    9m32.531s
sys     0m2.594s

---------------------------------------------------
multitest.tif
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Page 2
Page 3
Page 4
Page 5

real    3m35.027s
user    9m44.297s
sys     0m2.781s

---------------------- Page numbering in this option starts with 0. Should be changed to 1 (similar to multipage tif).

If a multipage tiff is listed as one of the files in the listfile, only its first page is processed.

 @jbarlow83 

I ran the test just once under WSL on Windows10 for language Hindi - there may have been other processes running at the same time which might have impacted the numbers. Hence my request to @stweil to test and compare the features.

Do you find individual files to get processed faster? Amitdo, thanks for adding me to this Request For Comments.

I think it is a very good idea to change the text output format to use the form feed character (U+000C) mark page boundaries. Hopefully this is very easy.

Reasonable people can disagree, but I don't think Tesseract should support an output base parameter with placeholders like page number.  There's a lot of combinations already between inputs and outputs. Single page input images, multipage input images, lists of images in a file, lists of images on stdin, streaming, various output format. Combinations are tricky, and it is a big reason why still haven't restored the "OCR to memory buffer" feature that has been mentioned so many times. 

If this is mostly about increasing throughput by eliminating initialization time, a common thing to do is to create an "OCR service" where a warmed up Tesseract daemon runs all the time. This type of program would make calls to libtesseract, but is otherwise a separate program. Not an additional feature to tesseractmain.cpp
 tesseract writes the file names to console, these can be combined with the output. 

`tesseract list.txt  stdout  > output.txt 2>&1`

or 

 `tesseract list.txt  stdout -c include_page_breaks=1 > output.txt 2>&1`

 >I think it is a very good idea to change the text output format to use the form feed character (U+000C) mark page boundaries. Hopefully this is very easy.

@stweil PR, please! I think the question is whether adding of page breaks should be the default in text mode, similar to HOCR or PDF.

If FF is added after each page then the empty line may not be required.
 https://github.com/tesseract-ocr/tesseract/commit/8bb5a89d5ac0e0c5e94fc566dff70ee1fffc95d1 by @stweil 

```
Don't add empty line to text output
Empty lines in text output are needed to separate paragraphs,
but there should not be an empty line at the end of the text.
```

What about the other changes? I agree.
 Thanks!  Please use tesseract user forum for asking support (especially for your own projects). This not tesseract issue.  + @theraysmith  for review and response.  Did you run autogen.sh again after installing autoconf-archive?

 @oscaroxy The master branch is the development branch for 4.0 alpha. Please try to build using a commit before the one mentioned by @amitdo . >OS: Centos 7
Compiler: gcc version 4.8.5 20150623 (Red Hat 4.8.5-4) (GCC)

I have built only on ubuntu, not centos. Maybe there are differences in the o/s causing the issue.

Since now you have downloaded source using git clone, you can use git to go back to an older commit and try the build there.

```
git reset --hard 2008dafa7310970002302083659575819e57bb67
```
will take you back to a commit about 4 days back before the commit @amitdo referred to. 
you can give the following command to verify

```
git log -1
```

Please try your build there again.
 @wildloop Thanks!

I have added the info on wiki page at https://github.com/tesseract-ocr/tesseract/wiki/4.0-Dockerfile I have successful build on Centos:   7.3.1611

please reference: https://ivanzz1001.github.io/records/post/ocr/2017/09/08/tesseract-install  Thanks! No crash now.

```
tesseract p002-crop.bmp missing/bmp --oem 1 --psm 6 -l hin
Tesseract Open Source OCR Engine v4.00.00alpha-520-gffb1ec3 with Leptonica
Error during processing.
```

A more descriptive error message will be helpful.   I was trying to make a debug build as per https://github.com/tesseract-ocr/tesseract/issues/529#issuecomment-301166173

Configure gave the following error

```
bash ./debug.sh
checking for g++... g++
checking whether the C++ compiler works... yes
checking for C++ compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
Using git revision: 4.00.00alpha-512-g6bebe71
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking for gawk... gawk
checking whether make sets $(MAKE)... yes
checking for style of include used by make... GNU
checking whether make supports nested variables... yes
configure: error: source directory already configured; run "make distclean" there first
make: *** No targets specified and no makefile found.  Stop.
```

So I ran `make distclean` which ended with the following error

```
 make distclean
Making distclean in arch
make[1]: Entering directory `/mnt/c/Users/User/shree/tesseract-head/arch'
make[2]: Entering directory `/mnt/c/Users/User/shree/tesseract-head/arch'
test -z "" || rm -f
rm -rf .libs _libs
test -z "libtesseract_avx.la libtesseract_sse.la libtesseract_arch.la" || rm -f libtesseract_avx.la libtesseract_sse.la libtesseract_arch.la

...

make[1]: Leaving directory `/mnt/c/Users/User/shree/tesseract-head/api'
Making distclean in .
make[1]: Entering directory `/mnt/c/Users/User/shree/tesseract-head'
rm -rf .libs _libs
make[2]: Entering directory `/mnt/c/Users/User/shree/tesseract-head/training'
Makefile:960: ../vs2010/port/.deps/strcasestr.Plo: No such file or directory
make[2]: *** No rule to make target `../vs2010/port/.deps/strcasestr.Plo'.  Stop.
make[2]: Leaving directory `/mnt/c/Users/User/shree/tesseract-head/training'
make[1]: *** [clean-local] Error 2
make[1]: Leaving directory `/mnt/c/Users/User/shree/tesseract-head'
make: *** [distclean-recursive] Error 1
``` ```
./configure  --enable-debug --disable-shared --disable-static CXXFLAGS="-g"
```
works fine.

The error comes when trying to build in a subdir with 

```
../../configure  --enable-debug --disable-shared --disable-static CXXFLAGS="-g"
``` Thanks!  What's this? We get very long build times with it.
See https://travis-ci.org/tesseract-ocr/tesseract/builds/232993174
cc: @zdenop @stweil @amitdo   Do we care about such leaks? 
api and renderer hold something important? Probably exit()s can be replaced with exceptions?
And print errors in main. Ah, yes, remember their policy. :(  Yes, there have been requests for more compact/compressed traineddata files.

Another Qn. 

* Should the new format be limited to tesseract 4.0 or also applied to 3.05? >libminizip-dev was added in Ubuntu Xenial (16.04), so the current Travis build environment which is based on Ubuntu Trusty does not provide it.

Why not use a different compression library that is available on different o/s as well as older ubuntu versions? Please move discussion to tesseract-dev forum. This is significant change. What about lz4?

---

btw, libarchive handles all formats.
https://github.com/libarchive/libarchive libarchive supported since very early ubuntu versions and in almost any other linuxes.
http://packages.ubuntu.com/search?suite=precise&searchon=names&keywords=libarchive

Personally, I'm using libarchive in cppan. The code for working with any formats is very simple, see:
https://github.com/egorpugin/primitives/blob/master/pack/include/primitives/pack.h
https://github.com/egorpugin/primitives/blob/master/pack/src/pack.cpp

Of course, this is pack/unpack archive code, but streaming code should be pretty similar and simple too. Actually I wanted to say lzma, which is .xz/.7z extensions.
Sorry. :) What libraries are currently in use in your PR?
libarchive? minizip? libzip? 
I see libarchive in build scripts, but not in code.
Maybe it worth it to use only one implementation (library)? I don't like multiple implementations for same thing. Please also try the test with a different language. Maybe one which has the
largest traineddata size, to see if filesize has any impact to the relative
speeds
Thanks.
 lzma compresses slower but better? Or is it also decompress slower? @theraysmith  wrote on 4/18/14

>I have no objection to switching to zip (with no tar) for the tessdata files. That should be usable by everybody more easily.

and on 4/20/14

>I spent some time looking at zlib. It doesn't seem to make it easy to randomly access named entities in >a gzip file, unless I am missing something. The memory compress/uncompress functions are quite nice >though.
>
> For the next version it would be nice to:
> Update tessdatamanager to cope with compressed components.
> Eliminate fread/fscanf from file input code and allow everything to read from a memory buffer.
> These can probably both be achieved with the TFile class that I added for 3.03.
> 
> This is a change in direction from my previous work with new classifier experiments, where I have been writing everything to use Serialize/DeSerialize and FILE streams, but this doesn't seem to be as portable as I had hoped, due to its reliance on fmemopen. It seems it would be better to make everything use memory buffers and push the file I/O responsibility out to TessDataManager/TFile, which could then just as easily deal with compressed files or in-memory data.

@stweil Do all the methods you tested support ` randomly accessing named entities`?

@theraysmith Is there a particular reason for ` zip (with no tar)`? >I'd drop support for the old format
and remove combine_tessdata.

combine_tessdata is used for extracting components, replacing some, etc. 

Probably first step can be a zippeddata file which after unzipping provides the traineddata.

Unless, there are zip/unzip equivalent features for combine_tessdata functionality. Would same extension cause confusion as to which version of traineddata file was being used? I would suggest to use different file extensions (e.g. traineddata4). This would help us to have installation of 3.05 and 4.00 at the same time and to avoid mistakes like using combine_tessdata on compressed data.

I would suggest to use zip compression as default because it seems to be supported on all platforms easily... Maybe support for multiple compression formats would be interesting (e.g. if somebody will be focused on size and not on speed), but this is not must at the moment. On Windows, that would require a rename with .zipextension, or the
> installer must register .traineddata as a zipped data type. Otherwise the
> Windows explorer won't decompress such files easily. Personally I prefer to
> keep the .traineddata extension even for zip files (like Java does it
> with its .jar extension).
>
>
> This comment has me confused. Are we talking about
1. compressing the files just for installation. after installation files
are uncompressed
2. compressing the components of a file using zlib and changing
tessdatamanager to allow that. FIles are otherwise uncompressed.
3. Leaving compressed files on disk after installation and relying on some
auto decompression feature of the OS to decompress the files on reading
?

I thought we were talking about 2, but registering something sounds like 3.
If we allow a backwards-breaking change, we could change the format of
traineddata, add a version number, and allow compression of components. It
would be fairly easy.


-- 
Ray.
 >  I don't know the situation for Visual Studio, but expect that small libraries like libzzip for example are much easier to build than larger libraries with more functionality like libarchive.

We are using cppan build for Visual Studio, libarchive is already there. It can be included with adding 1-3 lines. Other small libs you listed are not a problem too if needed. The most important features for me are:
TessdataManager::LoadMemBuffer must still work, ie the compression library must still be able to work on a pre-loaded file
Speed. There is little point compressing if the decompression speed is poor.
Command-line and API must still work. If combine_tessdata goes away, then there must be an easy-to-use replacement, and Tessdatamanager::SaveFile must still work.
Minimal extra dependencies - that was the main motivation for using zlib, as it is already an indirect dependency.
Summary: implement inside TessdataManager, and keep its existing interface in tact. libarchive choice is obvious. > With a standard archive format (like zip), it would be easy to write additional information into the archive files, for example a README or a VERSION file. Tesseract would ignore any such component which it does not know.

There is already possibility to include `config` file to traineddata. I would avoid suggest to add other file and made the `config `file as required with needed information (e.g. version number of data file, minimum (maximum?) version of tesseract, author, licence etc...) Just for the note: Google released during last years these compression algorithms:

- [zopfli](https://github.com/google/zopfli) focused on size
- [brotli](https://github.com/google/brotli) focused on [speed](https://opensource.googleblog.com/2015/09/introducing-brotli-new-compression.html)

I found out [result of Compression Benchmark](https://quixdb.github.io/squash-benchmark/#results-table), if somebody would like to make more test... @amitdo I have added a separate issue re multipage feature - https://github.com/tesseract-ocr/tesseract/issues/928

Rather than a new repo, we can use RFC: for issues in this repo itself, unless @theraysmith or @zdenop have an objection. @stweil Please also make a PR for tessdata to convert all current 4.0 traineddata files in new zipped format.

@zdenop I would also suggest that a new tag/release be made 4.0 (alpha1/2 or beta) for tesseract, tessdata as well as langdata with this new PR.

Thanks! Please also add version info as part of traineddata. 
I think @zdenop had suggested adding it to the config files.  re: >waiting for my pull requests to be merged:

@rfschtkt see comment by Ray at  https://github.com/tesseract-ocr/tesseract/pull/744#issuecomment-284917919

>>Yes, each commit gets reviewed by me and someone else at Google. Those warnings must be fixed sometime. Even in leptonica from which many warnings come too.  Please use tesseract user forum for asking support.  We do not provide support for 3rd party project (Tess4j). Please consult issue at Tess4j authors.  Please use syntax which will work with all of the following.

Supported Compilers

   - GCC 4.8 and above
   - Clang 3.4 and above
   - MSVC 2015, 2017


ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, May 9, 2017 at 6:18 PM, rfschtkt <notifications@github.com> wrote:

> Yes, I think it's a bug in that g++ version. I had successfully built with
> 5.4.0. I'll try again with an explicit move constructor...
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/897#issuecomment-300152139>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o-UsQwL8k-hPWd3NDI4loF080sLUks5r4GCXgaJpZM4NVPlU>
> .
>
 Oh, btw.
Isn't GetUTF8Text() should return C++-ish std::string? Instead of that stupid non-owning `char*` memory ptr.
It would be way better fix for all of this.  @rfschtkt: there is merge a conflict in api/pdfrenderer.cpp. Can you fix it?  Default setting of page segmentation treats the image as columns of text. If you want the whole line recognized as a unit, try with --psm 6.

The Eastern Arabic numerals are currently not recognized, it is a known issue - https://github.com/tesseract-ocr/langdata/issues/72

 @zdenop Issue Resolved. Please close.  If you already built it under Ubuntu, you should be able to use it directly.

On May 7, 2017 1:14 PM, "speedfl" <notifications@github.com> wrote:

> Hello,
>
> First thanks for your job. I am trying to run tesseract 4 but I am getting
> an issue:
>
> Info in bmfCreate: Generating pixa of bitmap fonts from string terminate
> called after throwing an instance of 'std::bad_alloc' what():
> std::bad_alloc Aborted (core dumped)
>
> Step to reproduce (with a docker file):
>
> `
> FROM ubuntu
>
> RUN apt-get update && apt-get install -y \
> 	autoconf \
> 	automake \
> 	libtool \
> 	autoconf-archive \
> 	pkg-config \
> 	libpng12-dev \
> 	libjpeg8-dev \
> 	libtiff5-dev \
> 	zlib1g-dev \
> 	libicu-dev \
> 	libpango1.0-dev \
> 	libcairo2-dev \
> 	git \
> 	curl && \
> 	rm -rf /var/lib/apt/lists/*
>
> RUN curl http://www.leptonica.org/source/leptonica-1.74.1.tar.gz -o leptonica-1.74.1.tar.gz && \
> 	tar -zxvf leptonica-1.74.1.tar.gz && \
> 	cd leptonica-1.74.1 && ./configure && make && make install && \
> 	cd .. && rm -rf leptonica*
>
> RUN git clone --depth 1 https://github.com/tesseract-ocr/tesseract.git && \
> 	cd tesseract && \
> 	./autogen.sh && \
> 	./configure --enable-debug && \
> 	LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make && \
> 	make install && \
> 	ldconfig && \
> 	make training && \
> 	make training-install && \
> 	cd .. && rm -rf tesseract
>
> # Get basic traineddata
> RUN curl https://github.com/tesseract-ocr/tessdata/raw/master/eng.traineddata > eng.traineddata && \
> 	mv eng.traineddata /usr/local/share/tessdata/
>
> RUN curl https://github.com/tesseract-ocr/tessdata/raw/master/fra.traineddata > fra.traineddata && \
> 	mv fra.traineddata /usr/local/share/tessdata/
>
> `
>
> Then:
>
> docker build -t tesseract4 docker run tesseract4 docker run -t -i
> tesseract4 /bin/bash mkdir test cd test curl http://tleyden-misc.s3.
> amazonaws.com/blog_images/ocr_test.png > test.png tesseract test.png out
>
> Can someone explain me what is happening?
>
> For information I have 2471 megabytes of memory remaning
>
> Thanks in advance
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/893>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o4aI-YeOByGqOjU1pYXUCW5nMGQ0ks5r3XZPgaJpZM4NTDSf>
> .
>
 I do not know about docker images. 

I thought @amitdo was referring to --enable-debug option of configure. Error message `Info in bmfCreate: Generating pixa of bitmap fonts `

is similar to https://github.com/tesseract-ocr/tesseract/issues/873

 That error/info message is from Leptonica

https://github.com/cotdp/leptonica/blob/master/src/bmf.c Please check where leptonica is installed. Do you have multiple versions? @speedfl No need to rebuild. I have not used docker so was just guessing.

@xlight https://github.com/tesseract-ocr/tesseract/issues/817#issuecomment-299716089 maybe able to help. BTW, the info message from leptonica is probably not related to the terminate error.

Please try to build again with latest source of tesseract from github. what output do you get for 

tesseract -v
 Also, have you tried a tiff or jpg file or the test files from tesseract
repo.

Could be an issue with the version of libpng ??
 @zdenop  Issue can be closed. https://github.com/tesseract-ocr/tesseract/issues/893#issuecomment-299856133 Added page to wiki - https://github.com/tesseract-ocr/tesseract/wiki/4.0-Dockerfile @stweil Should the basic traineddata be osd and eng in the dockerfile that I posted on the wiki?

@amitdo Is the tessdata a tiff file??? Thanks! I have updated https://github.com/tesseract-ocr/tesseract/wiki/4.0-Dockerfile

Please review and add any other required files (eg. configs etc.) to the docker container. >https://github.com/tesseract-ocr/tesseract/issues/919#issuecomment-302300156

Definitions of Docker containers and scripts that help to compile and run Tesseract 4 are available at:

https://github.com/tesseract-shadow/tesseract-ocr-compilation  @bmwmy please see https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-3180952  applied.

Zdenko

On Sat, May 6, 2017 at 9:02 AM, Stefan Weil <notifications@github.com>
wrote:

> The Appveyor cache <https://www.appveyor.com/docs/build-cache/> does not
> seem to work currently. According to the documentation
> <https://www.appveyor.com/blog/2016/09/28/the-new-build-cache/>, it is
> only enabled for new user accounts by default. @zdenop
> <https://github.com/zdenop>, you have to apply to get it enabled for your
> account.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/890#issuecomment-299620799>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAjCzAfq1jpyiE1PGrRmM0lNTIWV4O1Dks5r3BsigaJpZM4NSpiD>
> .
>
 So, can we merge this?
 Ok, cache is up'n'running, so build time for windows is only 4 minutes now.
https://ci.appveyor.com/project/zdenop/tesseract/build/master.843 Yes. :) Thanks, Stefan!
I'm activating training tools for building too. Ok, done. Also this means that we have full set of training tools in artifacts section of every build.
https://appveyorcidata.blob.core.windows.net/zdenop-27740/tesseract/master-844/m23d78nft28axsd6/build/bin/tesseract-master.844.zip?sv=2015-12-11&sr=c&sig=rR1rlQbih6341cXryCQphaH4YWr7n3Enudndwmvb8xQ%3D&st=2017-05-06T11%3A43%3A20Z&se=2017-05-06T11%3A49%3A20Z&sp=r
So people could download binaries from there. This is great. Is there a generic link to artifacts section that can be
added to the wiki?

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sat, May 6, 2017 at 5:19 PM, Egor Pugin <notifications@github.com> wrote:

> Also this means that we have full set of training tools in artifacts
> section of every build.
> https://appveyorcidata.blob.core.windows.net/zdenop-27740/
> tesseract/master-844/m23d78nft28axsd6/build/bin/tesseract-master.844.zip
> So people could download binaries from there.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/890#issuecomment-299634620>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o7k6256ztJKTo_rYGqI1ITy54m--ks5r3F4tgaJpZM4NSpiD>
> .
>
 FYI: According reply from Appveyor: 

> Build cache is already enabled for all AppVeyor accounts.
> The issue is that it won’t be saved during PR build. Won't be saved, but will be loaded.
We care only about loading cache. Hi Egor,

I downloaded the zip file for tesseract-master.848.zip
It has some of the training tools, but not text2image .
 True. I'll fix. Ok, fixed. Thanks, @Shreeshrii!
Also backported to 3.05 branch. I tried just now to use `git bash' (https://git-for-windows.github.io/) under windows with tesstrain.sh script for training. Works after putting the exe and dll files in the bin directory. 

This makes it possible for those using windows to try LSTM training using tesstrain.sh.

Thank you all for your work in making it possible. @egorpugin https://ci.appveyor.com/project/zdenop/tesseract/build/3.05.851 failed. Fixed. Please also check if some setting needs to be changed so that 'info'
messages from leptonica are not displayed. The version built with automake
does not have these.

eg.

File
C:/Users/vvkum/AppData/Local/Temp/tmp.Q59kWa5fdq/hin/hin.FreeSerif.exp0.lstmf
page 218 :
Mean rms=5.246%, delta=46.464%, train=104.341%(100%), skip ratio=0%
Info in fopenReadFromMemory: work-around: writing to a temp file
Iteration 188: ALIGNED TRUTH : गई हैं. एशिया डैनियल श्रिया था. हैं.
Iteration 188: BEST OCR TEXT :
File
C:/Users/vvkum/AppData/Local/Temp/tmp.Q59kWa5fdq/hin/hin.FreeSerif.exp0.lstmf
page 94 :
Mean rms=5.245%, delta=46.466%, train=104.318%(100%), skip ratio=0%
Info in fopenReadFromMemory: work-around: writing to a temp file
Iteration 189: ALIGNED TRUTH : फ्लेमिंग लिया। बर्बाद स्पोर्ट्स %>
Iteration 189: BEST OCR TEXT :
File
C:/Users/vvkum/AppData/Local/Temp/tmp.Q59kWa5fdq/hin/hin.FreeSerif.exp0.lstmf
page 208 :
Mean rms=5.243%, delta=46.436%, train=104.295%(100%), skip ratio=0%
Info in fopenReadFromMemory: work-around: writing to a temp file
Iteration 190: ALIGNED TRUTH : हैप्पी सुर्ख घर मिलता हुई। के
Iteration 190: BEST OCR TEXT :
 https://github.com/tesseract-ocr/tesseract/pull/543

related to info messages from leptonica

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sun, May 7, 2017 at 11:57 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
wrote:

> Please also check if some setting needs to be changed so that 'info'
> messages from leptonica are not displayed. The version built with automake
> does not have these.
>
> eg.
>
> File C:/Users/vvkum/AppData/Local/Temp/tmp.Q59kWa5fdq/hin/hin.FreeSerif.exp0.lstmf
> page 218 :
> Mean rms=5.246%, delta=46.464%, train=104.341%(100%), skip ratio=0%
> Info in fopenReadFromMemory: work-around: writing to a temp file
> Iteration 188: ALIGNED TRUTH : गई हैं. एशिया डैनियल श्रिया था. हैं.
> Iteration 188: BEST OCR TEXT :
> File C:/Users/vvkum/AppData/Local/Temp/tmp.Q59kWa5fdq/hin/hin.FreeSerif.exp0.lstmf
> page 94 :
> Mean rms=5.245%, delta=46.466%, train=104.318%(100%), skip ratio=0%
> Info in fopenReadFromMemory: work-around: writing to a temp file
> Iteration 189: ALIGNED TRUTH : फ्लेमिंग लिया। बर्बाद स्पोर्ट्स %>
> Iteration 189: BEST OCR TEXT :
> File C:/Users/vvkum/AppData/Local/Temp/tmp.Q59kWa5fdq/hin/hin.FreeSerif.exp0.lstmf
> page 208 :
> Mean rms=5.243%, delta=46.436%, train=104.295%(100%), skip ratio=0%
> Info in fopenReadFromMemory: work-around: writing to a temp file
> Iteration 190: ALIGNED TRUTH : हैप्पी सुर्ख घर मिलता हुई। के
> Iteration 190: BEST OCR TEXT :
>
>
 #543 is present in master and 3.05.  https://github.com/tesseract-ocr/tesseract/issues/720#issuecomment-281981614 Thanks, @stweil . I am closing this PR as not required.  This is probably because LSTM engine trains on text lines rather than separate letters.

@theraysmith can clarify.   @zdenop  Issue can be closed. @stweil Please update the windows binaries on your site with the latest version. Please also check that lstm.train config file is being included. (saw an error on another issue related to missing lstm.train - not sure which package it was from). Thanks! Thanks, Stefan!  ```
gdb --args lstmtraining -U ~/tess4training/eng/eng.unicharset \
>   --script_dir ../langdata   \
>   --append_index 5 --net_spec '[Lfx256 O1c105]' \
>   --continue_from ~/tess4training/englayer_from_eng/eng.lstm \
>   --model_output ~/tess4training/englayer_from_eng/englayer \
>   --train_listfile ~/tess4training/eng/eng.training_files.txt \
>   --target_error_rate 0.01 \
>   --debug_interval  -1
GNU gdb (Ubuntu 7.7.1-0ubuntu5~14.04.2) 7.7.1
Copyright (C) 2014 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-linux-gnu".
Type "show configuration" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
<http://www.gnu.org/software/gdb/documentation/>.
For help, type "help".
Type "apropos word" to search for commands related to "word"...
Reading symbols from lstmtraining...done.
(gdb) run
Starting program: /usr/local/bin/lstmtraining -U /home/shree/tess4training/eng/eng.unicharset --script_dir ../langdata --append_index 5 --net_spec \[Lfx256\ O1c105\] --c
ontinue_from /home/shree/tess4training/englayer_from_eng/eng.lstm --model_output /home/shree/tess4training/englayer_from_eng/englayer --train_listfile /home/shree/tess4t
raining/eng/eng.training_files.txt --target_error_rate 0.01 --debug_interval -1
warning: Error disabling address space randomization: Success
warning: linux_ptrace_test_ret_to_nx: PTRACE_KILL waitpid returned -1: Interrupted system call
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Loaded file /home/shree/tess4training/englayer_from_eng/eng.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from /home/shree/tess4training/englayer_from_eng/eng.lstm
Other case É of é is not in unicharset
Appending a new network to an old one!!Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Num outputs,weights in serial:
  Lfx256:256, 394240
  Fc105:105, 26985
Total weights = 421225
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc105] from request [Lfx256 O1c105]
Training parameters:
  Debug interval = -1, weights = 0.1, learning rate = 0.0001, momentum=0.9
[New Thread 0x7fea20f40700 (LWP 1158)]
Loaded 104/104 pages (1-104) of document /home/shree/tess4training/eng/eng.Arial.exp0.lstmf
[Thread 0x7fea20f40700 (LWP 1158) exited]
[New Thread 0x7fea1bff0700 (LWP 1159)]
Loaded 104/104 pages (1-104) of document /home/shree/tess4training/eng/eng.Times_New_Roman.exp0.lstmf
[Thread 0x7fea1bff0700 (LWP 1159) exited]
[New Thread 0x7fea1bff0700 (LWP 1160)]
[New Thread 0x7fea20f40700 (LWP 1161)]
[New Thread 0x7fea1acf0700 (LWP 1162)]
Iteration 0: ALIGNED TRUTH : used through € between NEW % J. should when High when We it
Iteration 0: BEST OCR TEXT : St$Zv#kv#qSZ]$vUZUyvHvkyEHkSZUZtvyvyvHvq$Rwq,qtHgE#gqZUSUZ#EqgqSqSqyvHvt$q£$R$RqtS$U,#,v$USUHZq,c$U$qSq,$#vyvHvSHZSZ=Z$[ [vESUSZUyvHvSqSqyHZ
vt,q€U€vlvyvySyHvqtSUZtyHvSqSqvqHq,U$U,UegqgqveZS
File /tmp/tmp.E8R3inud3B/eng/eng.Arial.exp0.lstmf page 6 :

Program received signal SIGSEGV, Segmentation fault.
operator+= (addend=..., this=0xb92048) at ../ccstruct/matrix.h:256
256               (*this)(x, y) += addend(x, y);
(gdb) backtrace
#0  operator+= (addend=..., this=0xb92048) at ../ccstruct/matrix.h:256
#1  tesseract::WeightMatrix::Update (this=0xb92048, learning_rate=<optimized out>, momentum=0.89999997615814209, num_samples=<optimized out>) at weightmatrix.cpp:261
#2  0x00007fea254b7083 in tesseract::Plumbing::Update (this=0xb91e80, learning_rate=1.24999988e-05, momentum=0.899999976, num_samples=1) at plumbing.cpp:219
#3  0x00007fea254b7083 in tesseract::Plumbing::Update (this=0xb91230, learning_rate=9.99999975e-05, momentum=0.899999976, num_samples=1) at plumbing.cpp:219
#4  0x00007fea254a8469 in tesseract::LSTMTrainer::TrainOnLine (this=this@entry=0x7ffff03ebaf0, trainingdata=<optimized out>, batch=batch@entry=false)
    at lstmtrainer.cpp:813
#5  0x0000000000406ff4 in TrainOnLine (batch=false, samples_trainer=0x7ffff03ebaf0, this=0x7ffff03ebaf0) at ../lstm/lstmtrainer.h:273
#6  main (argc=1, argv=0x7ffff03ec488) at lstmtraining.cpp:198
(gdb) up
#1  tesseract::WeightMatrix::Update (this=0xb92048, learning_rate=<optimized out>, momentum=0.89999997615814209, num_samples=<optimized out>) at weightmatrix.cpp:261
261       if (momentum > 0.0) wf_ += updates_;
(gdb) print num_samples
$1 = <optimized out>
(gdb) print momentum
$2 = 0.89999997615814209
(gdb) print wf_
$3 = {_vptr.GENERIC_2D_ARRAY = 0x7fea257bf230 <vtable for GENERIC_2D_ARRAY<double>+16>, array_ = 0xb92230, empty_ = 0, dim1_ = 16, dim2_ = 26, size_allocated_ = 416}
(gdb) print updates_
$4 = {_vptr.GENERIC_2D_ARRAY = 0x7fea257bf230 <vtable for GENERIC_2D_ARRAY<double>+16>, array_ = 0x0, empty_ = 0, dim1_ = 0, dim2_ = 0, size_allocated_ = 0}
(gdb) quit

``` This was the with the latest code from github, including Ray's latest commit regarding endian support.

You will need to change the fonts dir in the commands below.

```
rm -rf ~/tess4training/eng  
  
training/tesstrain.sh \
   --fonts_dir ~/.fonts \
   --lang eng  \
   --noextract_font_properties \
   --linedata_only \
   --exposures "0" \
   --langdata_dir ../langdata \
   --tessdata_dir ../tessdata \
   --fontlist "Arial"  "Times New Roman,"  \
   --output_dir ~/tess4training/eng
  
rm -rf ~/tess4training/englayer_from_eng    

mkdir -p ~/tess4training/englayer_from_eng 

combine_tessdata -e ../tessdata/eng.traineddata \
  ~/tess4training/englayer_from_eng/eng.lstm

lstmtraining -U ~/tess4training/eng/eng.unicharset \
  --script_dir ../langdata   \
  --append_index 5 --net_spec '[Lfx256 O1c105]' \
  --continue_from ~/tess4training/englayer_from_eng/eng.lstm \
  --model_output ~/tess4training/englayer_from_eng/englayer \
  --train_listfile ~/tess4training/eng/eng.training_files.txt \
  --target_error_rate 0.01 \
  --debug_interval  -1
``` Thanks, Amit. I had seen that comment but thought that it was related to training of new language models. I am not sure what is included in `ImageData`.

The first part of the training commands (tesstrain.sh) runs text2image and creates box/tiff pairs and these are then used to create unicharset, dawg and lstmf files. I have not used any external box/tiff pairs.

These lstmf files are used along with the extracted lstm file from the traineddata from the repo.

`combine_tessdata -e ../tessdata/eng.traineddata 
  ~/tess4training/englayer_from_eng/eng.lstm`

Possibly, this could be the cause of incompatibility, since these files were built with earlier code. the `lstmtraining` command for this issue is for `replacing a top layer`. lstmtraining command for replacing a top layer is working now after the changes by Ray.

```
 lstmtraining -U ~/tess4training/eng/eng.unicharset \
>   --script_dir ../langdata   \
>   --append_index 5 --net_spec '[Lfx256 O1c105]' \
>   --continue_from ~/tess4training/englayer_from_eng/eng.lstm \
 >   --model_output ~/tess4training/englayer_from_eng/englayer \
>   --train_listfile ~/tess4training/eng/eng.training_files.txt \
>   --target_error_rate 0.01 \
>   --debug_interval  -1
Loaded file /home/shree/tess4training/englayer_from_eng/eng.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from /home/shree/tess4training/englayer_from_eng/eng.lstm
Other case É of é is not in unicharset
Appending a new network to an old one!!Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Num outputs,weights in serial:
  Lfx256:256, 394240
  Fc105:105, 26985
Total weights = 421225
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc105] from request [Lfx256 O1c105]
Training parameters:
  Debug interval = -1, weights = 0.1, learning rate = 0.0001, momentum=0.9
Loaded 104/104 pages (1-104) of document /home/shree/tess4training/eng/eng.Arial.exp0.lstmf
Loaded 104/104 pages (1-104) of document /home/shree/tess4training/eng/eng.Times_New_Roman.exp0.lstmf
Iteration 0: ALIGNED TRUTH : (GeneRIF) World and ABOUT time October the service through is Help
Iteration 0: BEST OCR TEXT : #yvtEktgqtHv$gqy$g$ScqESvq,UgU,UZHZtZ€U Zq,yqaqtqHt SUctéHS$Ht:HtS$Uu5,q,UvUtHSqgqtqH\t$gZUHZtZHZqZqZqEZUyHEqgq€EgtqZtZv#
v\EyZqgqEUyHvHEHZHSZ$ZtvyHZvUv#qtq€U€e#qevZH
File /home/shree/tess4training/eng/eng.Arial.exp0.lstmf page 0 :
Mean rms=8.666%, delta=100%, train=301.515%(100%), skip ratio=0%
Iteration 1: ALIGNED TRUTH : through they not this our English ° 14 ® Development of 8 What's an
Iteration 1: BEST OCR TEXT : kZyHZkEZkSZ$ZtqtyHZq]UtyHESqS#tHvZ:ZSZqUZyHZvk#t4SZSZqZqyq4,q,eHvZvtv€yveS#tyHZq$qSq4$SU,Uq#R#$SHtU,$,H\Sq7Zt#q¥SHtvtktaH
vHSZtHZSZqS:SZSv#$S,tU$U5UH\HvZSZUHvqEyqHZH
File /home/shree/tess4training/eng/eng.Times_New_Roman.exp0.lstmf page 0 :
Mean rms=8.647%, delta=100%, train=303.743%(100%), skip ratio=0%
Iteration 2: ALIGNED TRUTH : good 25 now this [J User INDEX had help 6 all iGoogle if in Ca¥ years
Iteration 2: BEST OCR TEXT : StvEHE#Zt]$v4#kqUklvtEHEHZSUZ#tEZUyHvZv#vq,uc$,4[$[e#v#ZqZqyq$Sq$u$H\R$q$w$,tyHv#qHSc ZUtHvHZgqZvZHq]UlvE4qZ[$vUvUv$vHg\E
H\tv\HZqgq4SvUvevHqt$,SqHS$,q,S#taqSqHqH$S
File /home/shree/tess4training/eng/eng.Arial.exp0.lstmf page 1 :
Mean rms=8.648%, delta=100%, train=301.046%(100%), skip ratio=0%
Iteration 3: ALIGNED TRUTH : were jobs BBC get is" University A 1998 fixed Search And under .
Iteration 3: BEST OCR TEXT : ,SkZ]EoZqyES$qEvyvtHZRHZHkvqt$u$vt/$He}$,$vt,tvytZqZHqUvkv#$q]oq4U$tetHvHvZtZtqZtZHv#veZSyS#tq#}éHSqU [$Uk$SCpH.$vqUyHv$H
#qS€ Sv,$évEqg€qZqyt$tyHSqU$téHtHZHc SU,SvZtvHc]$eSZqZqy{q,S
File /tmp/tmp.2xbvLE29x7/eng/eng.Times_New_Roman.exp0.lstmf page 25 :
Mean rms=8.696%, delta=100%, train=306.644%(100%), skip ratio=0%

```  ```
gdb --args lstmtraining    --debug_interval -1   --continue_from ~/tess4training/englayer_from_eng/eng.lstm    --
train_listfile ~/tess4training/eng/eng.training_files.txt   --model_output ~/tess4training/englayer_from_eng/englstm   --target_error_rate 0.01
GNU gdb (Ubuntu 7.7.1-0ubuntu5~14.04.2) 7.7.1
Copyright (C) 2014 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-linux-gnu".
Type "show configuration" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
<http://www.gnu.org/software/gdb/documentation/>.
For help, type "help".
Type "apropos word" to search for commands related to "word"...
Reading symbols from lstmtraining...done.
(gdb) run
Starting program: /usr/local/bin/lstmtraining --debug_interval -1 --continue_from /home/shree/tess4training/englayer_from_eng/eng.lstm --train_listfile /home/shree/tess4
training/eng/eng.training_files.txt --model_output /home/shree/tess4training/englayer_from_eng/englstm --target_error_rate 0.01
warning: Error disabling address space randomization: Success
warning: linux_ptrace_test_ret_to_nx: PTRACE_KILL waitpid returned -1: Interrupted system call
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Loaded file /home/shree/tess4training/englayer_from_eng/eng.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from /home/shree/tess4training/englayer_from_eng/eng.lstm
[New Thread 0x7fdbdcf40700 (LWP 1141)]
Loaded 104/104 pages (1-104) of document /home/shree/tess4training/eng/eng.Arial.exp0.lstmf
[Thread 0x7fdbdcf40700 (LWP 1141) exited]
[New Thread 0x7fdbd7ff0700 (LWP 1142)]
Loaded 104/104 pages (1-104) of document /home/shree/tess4training/eng/eng.Times_New_Roman.exp0.lstmf
[Thread 0x7fdbd7ff0700 (LWP 1142) exited]
[New Thread 0x7fdbd7ff0700 (LWP 1143)]
[New Thread 0x7fdbdcf40700 (LWP 1144)]
[New Thread 0x7fdbd6770700 (LWP 1145)]
Iteration 0: ALIGNED TRUTH : used through € between NEW % J. should when High when We it
Iteration 0: BEST OCR TEXT : used through € between NEW % J. should when High when We it
File /tmp/tmp.E8R3inud3B/eng/eng.Arial.exp0.lstmf page 6 (Perfect):
Mean rms=0.152%, delta=0%, train=0%(0%), skip ratio=0%
Iteration 1: ALIGNED TRUTH : site May May 3. group 28 long any 2, to 2006 or into Search us Sports
Iteration 1: BEST OCR TEXT : site May May 3. group 28 long any 2, to 2006 or into Search us Sports
File /tmp/tmp.E8R3inud3B/eng/eng.Arial.exp0.lstmf page 1 (Perfect):
u.dim1() == num_outputs:Error:Assert failed:in file weightmatrix.cpp, line 227

Program received signal SIGSEGV, Segmentation fault.
ERRCODE::error (this=this@entry=0x7fdbe1a1ee48 <_ZL13ASSERT_FAILED>, caller=caller@entry=0x7fdbe1534d25 "u.dim1() == num_outputs", action=action@entry=ABORT,
    format=format@entry=0x7fdbe15164d4 "in file %s, line %d") at errcode.cpp:86
86            if (!*p)
(gdb) backtrace
#0  ERRCODE::error (this=this@entry=0x7fdbe1a1ee48 <_ZL13ASSERT_FAILED>, caller=caller@entry=0x7fdbe1534d25 "u.dim1() == num_outputs", action=action@entry=ABORT,
    format=format@entry=0x7fdbe15164d4 "in file %s, line %d") at errcode.cpp:86
#1  0x00007fdbe14c3ccf in tesseract::WeightMatrix::SumOuterTransposed (this=0x12613d8, u=..., v=..., in_parallel=<optimized out>) at weightmatrix.cpp:227
#2  0x00007fdbe1492742 in tesseract::FullyConnected::Backward (this=0x1261390, debug=<optimized out>, fwd_deltas=..., scratch=<optimized out>, back_deltas=0x1271f60)
    at fullyconnected.cpp:232
#3  0x00007fdbe14c18ba in tesseract::Series::Backward (this=0x1234ce0, debug=<optimized out>, fwd_deltas=..., scratch=0x7fffe65c6308, back_deltas=0x7fffe65c5ce0)
    at series.cpp:128
#4  0x00007fdbe14a8432 in tesseract::LSTMTrainer::TrainOnLine (this=this@entry=0x7fffe65c5fa0, trainingdata=<optimized out>, batch=batch@entry=false)
    at lstmtrainer.cpp:811
#5  0x0000000000406ff4 in TrainOnLine (batch=false, samples_trainer=0x7fffe65c5fa0, this=0x7fffe65c5fa0) at ../lstm/lstmtrainer.h:273
#6  main (argc=1, argv=0x7fffe65c68f8) at lstmtraining.cpp:198
(gdb) up
#1  0x00007fdbe14c3ccf in tesseract::WeightMatrix::SumOuterTransposed (this=0x12613d8, u=..., v=..., in_parallel=<optimized out>) at weightmatrix.cpp:227
227       ASSERT_HOST(u.dim1() == num_outputs);
(gdb) print num_outputs
$1 = 0
(gdb) quit
``` ```
   
rm -rf ~/tess4training/eng  
  
training/tesstrain.sh --fonts_dir ~/.fonts --lang eng  \
  --noextract_font_properties \
    --linedata_only \
  --exposures "0" \
   --langdata_dir ../langdata --tessdata_dir ./tessdata \
    --fontlist "Arial"  "Times New Roman,"  \
   --output_dir ~/tess4training/eng
  
rm -rf ~/tess4training/englayer_from_eng    

mkdir -p ~/tess4training/englayer_from_eng 

combine_tessdata -e ../tessdata/eng.traineddata \
  ~/tess4training/englayer_from_eng/eng.lstm
  
lstmtraining \
   --debug_interval -1 \
  --continue_from ~/tess4training/englayer_from_eng/eng.lstm \
   --train_listfile ~/tess4training/eng/eng.training_files.txt \
  --model_output ~/tess4training/englayer_from_eng/englstm \
  --target_error_rate 0.01
``` I have tessdata both as a peer level to tesseract (../tessdata) and as child level (./tessdata).

I keep the tessdata from repo at ../tessdata and keep the generated ones from training in ./tessdata.

I think it is only used here for the config files. the `lstmtraining` command here is the one for `fine tune`. Oops. Some changes got left out. I have a careful rethink of SetEnableTraining that didn't make it.
Reverting that line is not the solution.
Will fix it as soon as I check that the change doesn't break anything... OK, fixed with with https://github.com/tesseract-ocr/tesseract/commit/4fa463cd71366c2854090b38f25f94f3765d54b0  on what operating system are you trying this?

what commit number for source code are you using? You have used the complete net_spec. With append_index, it has to be just the top layers, eg.

```
lstmtraining -U ~/tesstutorial/ara/ara.unicharset \
  --script_dir ../langdata   \
  --append_index 5 --net_spec '[Lfx256 O1c105]' \
  --continue_from ~/tesstutorial/aralayer_from_ara/ara.lstm \
  --model_output ~/tesstutorial/aralayer_from_ara/aralayer \
  --train_listfile ~/tesstutorial/ara/ara.training_files.txt \
  --target_error_rate 0.01 \
  --debug_interval  -1
``` @zdenop  Issue can be closed.  I'm working towards fast and not silent builds on appveyor, but it could take 1-2 month. (cppan related)
But it's possible that your commit really broke something on windows. (I did not do any cppan/appveyor changes during last 1-1.5 month.) This will make build times up to near 1 hour or even 1+ which is impossible on appveyor.
There are too many warnings, so pushing all of them to stdout/err makes such slow build times. Nice. I'll investigate this, thanks! The best time to switch to POSIX types is after the legacy engine is
removed, otherwise it is just a waste of time merging it and reviewing it.

On Thu, Jul 13, 2017 at 1:19 AM, Stefan Weil <notifications@github.com>
wrote:

> @theraysmith <https://github.com/theraysmith>, as you are just preparing
> a new larger code change: is it possible to use POSIX data types for the
> new / modified code, and can we switch to POSIX for the rest of the code
> directly after your update?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/878#issuecomment-315006966>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056WoPKurkhF6p7FaQbU71cN6cqaAfks5sNdMigaJpZM4NRHiF>
> .
>



-- 
Ray.
 Are we allowed to apply now? Or still no? A colleague volunteered to review such a change, but he is away at the
moment.
I think it will be faster for me to generate the change myself than to
up-integrate it from github, so I plan to make the edit next week. Maybe in
about 2 weeks I will be ready to push it to github.
In the mean time, I'm still maintaining a diff against github from the last
lot of edits while I find somebody to review those, and I have several
changes still in the pipeline with things like the language model changes
for the new release.

On Mon, Jul 24, 2017 at 12:46 PM, Stefan Weil <notifications@github.com>
wrote:

> I'm sure that some parts of the PR are not related to the legacy engine.
> Maybe those can be applied now.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/878#issuecomment-317533515>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056Vr5jppDyQSKNK39T1PyoXNUh8dYks5sRPR4gaJpZM4NRHiF>
> .
>



-- 
Ray.
  Please use tesseract user forum for asking support  @amitdo is right. It is unrelated. Sorry for the confusion.

@ibr123 It is possible that the source for the two installs is from different commits from master. You are getting tesseract source by

`git clone https://github.com/tesseract-ocr/tesseract.git`

As you can see from https://github.com/tesseract-ocr/tesseract/commits/master
there have been many changes to 4.0 code over last one month.

What you could do is note the commit number from an install which works for you, and then use source as of that commit for your installation. Please note that 4.0 code is still in alpha stage and may change quickly.

config.log should show you the commit - search for GIT-REV

```
| #define GIT_REV "4.00.00alpha-458-g2ea946d"
``` Sorry, I do not know enough about VMware and Virtual Box to identify the
problem.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, May 10, 2017 at 1:54 PM, ibr123 <notifications@github.com> wrote:

> Hi,
>
> i looked at the config.log of the tesseract revision that works, took the
> revision number and switched the tesseract to that branch while installing
> the tesseract, and that revision was *"4.00.00alpha-367-g5baa8c8"*
> i made sure that its the correct revision by making detection of an image,
> i noticed that on the terminal the tesseract prints its revision number
> [image: ocrerror]
> <https://cloud.githubusercontent.com/assets/26926171/25889397/49639c4e-3572-11e7-909e-5c7fcf8eab3c.png>
> yet the same error was generated at the phase E where creating lstm files
> i even tried to install the suggested revision:
> *"4.00.00alpha-458-g2ea946d"* and the result was the same error but
> different line number at the tessedit.cpp, at the revision
> *"4.00.00alpha-367-g5baa8c8"* the error is: *stm_recognizer_->DeSerialize(&fp):Error:Assert
> failed:in file tessedit.cpp, line 202*
> and at the revision *"4.00.00alpha-458-g2ea946d"* the error was
> *stm_recognizer_->DeSerialize(&fp):Error:Assert failed:in file
> tessedit.cpp, line 193*
> i even deleted that line from the tessedit.cpp and the error stayed the
> same, after that i tried to delete the whole tessedit.cpp and same problem,
> so is it loaded on somewhere ? or is it not compatible with VMware because
> the revision *"4.00.00alpha-367-g5baa8c8"* works fine with the virtual
> box but not with the VMware
> Thanks
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/873#issuecomment-300411320>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_owNFvS9fAL3rZWahuof6a8Kz4xzHks5r4XQsgaJpZM4NQWtW>
> .
>
 @ibr123 I am able to run training with the following version -

 tesseract -v
tesseract 4.00.00alpha-460-gb86b4fa
 leptonica-1.74.1
  libgif 5.0.5 : libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8 : libwebp 0.4.0 : libopenjp2 2.1.0

Please try with this commit. If it doesn't work, share your input files/font. ```

=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=../tessdata
[Thu May 11 13:55:50 DST 2017] /usr/local/bin/tesseract /tmp/tmp.D3w1Zt6gOu/ara/ara.Arabic_Typesetting.exp0.tif /tmp/tmp.D3w1Zt6gOu/ara/ara.Arabic_Typesetting.exp0 lstm.
train ../langdata/ara/ara.config
Tesseract Open Source OCR Engine v4.00.00alpha-460-gb86b4fa with Leptonica
Page 1
Page 2
Loaded 56/56 pages (1-56) of document /tmp/tmp.D3w1Zt6gOu/ara/ara.Arabic_Typesetting.exp0.lstmf
Page 3
Loaded 117/117 pages (1-117) of document /tmp/tmp.D3w1Zt6gOu/ara/ara.Arabic_Typesetting.exp0.lstmf

``` When you use

git clone https://github.com/tesseract-ocr/tesseract.git

It will pickup the latest version of source from GitHub. Later, you can
update by

Git pull origin

Or do a new clone of the repository.

If you configure with --enable-debug it will show the git revision for

tesseract -v

On May 11, 2017 3:02 PM, "ibr123" <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/Shreeshrii> are the libraries and
> leptonica version at this site
> <https://medium.com/@lucas63/installing-tesseract-3-04-in-ubuntu-14-04-1dae8b748a32>
> are valid? meaning did you install them with the tesseract
> v4.00.00alpha-460-gb86b4fa ?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/873#issuecomment-300736463>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o0n-18Py4b97w1XxTU2QCdM_GoVZks5r4tW3gaJpZM4NQWtW>
> .
>
  Current stable release is 3.05. Soon will (within week) be released 3.05.1 version with more bugfixes....  No man pages  are there for the following programs in https://github.com/tesseract-ocr/tesseract/tree/master/doc 

* classifier_tester
* lstmeval
* lstmtraining
* set_unicharset_properties
* text2image


```
libtool: install: /usr/bin/install -c .libs/ambiguous_words /usr/local/bin/ambiguous_words
libtool: install: /usr/bin/install -c .libs/classifier_tester /usr/local/bin/classifier_tester
libtool: install: /usr/bin/install -c .libs/cntraining /usr/local/bin/cntraining
libtool: install: /usr/bin/install -c .libs/combine_tessdata /usr/local/bin/combine_tessdata
libtool: install: /usr/bin/install -c .libs/dawg2wordlist /usr/local/bin/dawg2wordlist
libtool: install: /usr/bin/install -c .libs/lstmeval /usr/local/bin/lstmeval
libtool: install: /usr/bin/install -c .libs/lstmtraining /usr/local/bin/lstmtraining
libtool: install: /usr/bin/install -c .libs/mftraining /usr/local/bin/mftraining
libtool: install: /usr/bin/install -c .libs/set_unicharset_properties /usr/local/bin/set_unicharset_properties
libtool: install: /usr/bin/install -c .libs/shapeclustering /usr/local/bin/shapeclustering
libtool: install: /usr/bin/install -c .libs/text2image /usr/local/bin/text2image
libtool: install: /usr/bin/install -c .libs/unicharset_extractor /usr/local/bin/unicharset_extractor
libtool: install: /usr/bin/install -c .libs/wordlist2dawg /usr/local/bin/wordlist2dawg
``` ```
USAGE: classifier_tester [.tr files ...]
  --debug_level  Level of Trainer debugging  (type:int default:0)
  --load_images  Load images with tr files  (type:int default:0)
  --clusterconfig_min_samples_fraction  Min number of samples per proto as % of total  (type:double default:0.625)
  --clusterconfig_max_illegal  Max percentage of samples in a cluster which have more than 1 feature in that cluster  (type:double default:0.05)
  --clusterconfig_independence  Desired independence between dimensions  (type:double default:1)
  --clusterconfig_confidence  Desired confidence in prototypes created  (type:double default:1e-06)
  --classifier  Classifier to test  (type:string default:)
  --lang  Language to test  (type:string default:eng)
  --tessdata_dir  Directory of traineddata files  (type:string default:)
  --configfile  File to load more configs from  (type:string default:)
  --D  Directory to write output files to  (type:string default:)
  --F  File listing font properties  (type:string default:font_properties)
  --X  File listing font xheights  (type:string default:)
  --U  File to load unicharset from  (type:string default:unicharset)
  --O  File to write unicharset to  (type:string default:)
  --output_trainer  File to write trainer to  (type:string default:)
  --test_ch  UTF8 test character string  (type:string default:)
```

from https://github.com/tesseract-ocr/tesseract/blob/master/training/classifier_tester.cpp

```

// This program has complex setup requirements, so here is some help:
// Two different modes, tr files and serialized mastertrainer.
// From tr files:
//   classifier_tester -U unicharset -F font_properties -X xheights
//     -classifier x -lang lang [-output_trainer trainer] *.tr
// From a serialized trainer:
//  classifier_tester -input_trainer trainer [-lang lang] -classifier x
//
// In the first case, the unicharset must be the unicharset from within
// the classifier under test, and the font_properties and xheights files must
// match the files used during training.
// In the second case, the trainer file must have been prepared from
// some previous run of shapeclustering, mftraining, or classifier_tester
// using the same conditions as above, ie matching unicharset/font_properties.
//
// Available values of classifier (x above) are:
// pruner   : Tesseract class pruner only.
// full     : Tesseract full classifier.
//            with an input trainer.)
``` ```
USAGE: lstmeval [.tr files ...]
  --max_image_MB  Max memory to use for images.  (type:int default:2000)
  --debug_level  Level of Trainer debugging  (type:int default:0)
  --load_images  Load images with tr files  (type:int default:0)
  --clusterconfig_min_samples_fraction  Min number of samples per proto as % of total  (type:double default:0.625)
  --clusterconfig_max_illegal  Max percentage of samples in a cluster which have more than 1 feature in that cluster  (type:double default:0.05)
  --clusterconfig_independence  Desired independence between dimensions  (type:double default:1)
  --clusterconfig_confidence  Desired confidence in prototypes created  (type:double default:1e-06)
  --model  Name of model file (training or recognition)  (type:string default:)
  --eval_listfile  File listing sample files in lstmf training format.  (type:string default:)
  --configfile  File to load more configs from  (type:string default:)
  --D  Directory to write output files to  (type:string default:)
  --F  File listing font properties  (type:string default:font_properties)
  --X  File listing font xheights  (type:string default:)
  --U  File to load unicharset from  (type:string default:unicharset)
  --O  File to write unicharset to  (type:string default:)
  --output_trainer  File to write trainer to  (type:string default:)
  --test_ch  UTF8 test character string  (type:string default:)
```

USAGE: lstmeval [.tr files ...] 

Should it be .lstmf files? ```
USAGE: lstmtraining [.tr files ...]
  --debug_interval  How often to display the alignment.  (type:int default:0)
  --train_mode  Controls gross training behavior.  (type:int default:80)
  --net_mode  Controls network behavior.  (type:int default:192)
  --perfect_sample_delay  How many imperfect samples between perfect ones.  (type:int default:4)
  --max_image_MB  Max memory to use for images.  (type:int default:6000)
  --append_index  Index in continue_from Network at which to attach the new network defined by net_spec  (type:int default:-1)
  --max_iterations  If set, exit after this many iterations  (type:int default:0)
  --debug_level  Level of Trainer debugging  (type:int default:0)
  --load_images  Load images with tr files  (type:int default:0)
  --target_error_rate  Final error rate in percent.  (type:double default:0.01)
  --weight_range  Range of initial random weights.  (type:double default:0.1)
  --learning_rate  Weight factor for new deltas.  (type:double default:0.0001)
  --momentum  Decay factor for repeating deltas.  (type:double default:0.9)
  --clusterconfig_min_samples_fraction  Min number of samples per proto as % of total  (type:double default:0.625)
  --clusterconfig_max_illegal  Max percentage of samples in a cluster which have more than 1 feature in that cluster  (type:double default:0.05)
  --clusterconfig_independence  Desired independence between dimensions  (type:double default:1)
  --clusterconfig_confidence  Desired confidence in prototypes created  (type:double default:1e-06)
  --stop_training  Just convert the training model to a runtime model.  (type:bool default:false)
  --debug_network  Get info on distribution of weight values  (type:bool default:false)
  --net_spec  Network specification  (type:string default:)
  --continue_from  Existing model to extend  (type:string default:)
  --model_output  Basename for output models  (type:string default:lstmtrain)
  --script_dir  Required to set unicharset properties or use unicharset compression.  (type:string default:)
  --train_listfile  File listing training files in lstmf training format.  (type:string default:)
  --eval_listfile  File listing eval files in lstmf training format.  (type:string default:)
  --configfile  File to load more configs from  (type:string default:)
  --D  Directory to write output files to  (type:string default:)
  --F  File listing font properties  (type:string default:font_properties)
  --X  File listing font xheights  (type:string default:)
  --U  File to load unicharset from  (type:string default:unicharset)
  --O  File to write unicharset to  (type:string default:)
  --output_trainer  File to write trainer to  (type:string default:)
  --test_ch  UTF8 test character string  (type:string default:)
```
USAGE: lstmtraining [.tr files ...]

Should it be .lstmf files? ```

USAGE: set_unicharset_properties
  --debug_level  Level of Trainer debugging  (type:int default:0)
  --load_images  Load images with tr files  (type:int default:0)
  --clusterconfig_min_samples_fraction  Min number of samples per proto as % of total  (type:double default:0.625)
  --clusterconfig_max_illegal  Max percentage of samples in a cluster which have more than 1 feature in that cluster  (type:double default:0.05)
  --clusterconfig_independence  Desired independence between dimensions  (type:double default:1)
  --clusterconfig_confidence  Desired confidence in prototypes created  (type:double default:1e-06)
  --script_dir  Directory name for input script unicharsets/xheights  (type:string default:)
  --configfile  File to load more configs from  (type:string default:)
  --D  Directory to write output files to  (type:string default:)
  --F  File listing font properties  (type:string default:font_properties)
  --X  File listing font xheights  (type:string default:)
  --U  File to load unicharset from  (type:string default:unicharset)
  --O  File to write unicharset to  (type:string default:)
  --output_trainer  File to write trainer to  (type:string default:)
  --test_ch  UTF8 test character string  (type:string default:)
``` ```

USAGE: text2image
  --exposure  Exposure level in photocopier  (type:int default:0)
  --resolution  Pixels per inch  (type:int default:300)
  --xsize  Width of output image  (type:int default:3600)
  --ysize  Height of output image  (type:int default:4800)
  --margin  Margin round edges of image  (type:int default:100)
  --ptsize  Size of printed text  (type:int default:12)
  --leading  Inter-line space (in pixels)  (type:int default:12)
  --box_padding  Padding around produced bounding boxes  (type:int default:0)
  --glyph_resized_size  Each glyph is square with this side length in pixels  (type:int default:0)
  --glyph_num_border_pixels_to_pad  Final_size=glyph_resized_size+2*glyph_num_border_pixels_to_pad  (type:int default:0)
  --tlog_level  Minimum logging level for tlog() output  (type:int default:0)
  --char_spacing  Inter-character space in ems  (type:double default:0)
  --underline_start_prob  Fraction of words to underline (value in [0,1])  (type:double default:0)
  --underline_continuation_prob  Fraction of words to underline (value in [0,1])  (type:double default:0)
  --min_coverage  If find_fonts==true, the minimum coverage the font has of the characters in the text file to include it, between 0 and 1.  (type:double default:1)
  --degrade_image  Degrade rendered image with speckle noise, dilation/erosion and rotation  (type:bool default:true)
  --rotate_image  Rotate the image in a random way.  (type:bool default:true)
  --strip_unrenderable_words  Remove unrenderable words from source text  (type:bool default:true)
  --ligatures  Rebuild and render ligatures  (type:bool default:false)
  --find_fonts  Search for all fonts that can render the text  (type:bool default:false)
  --render_per_font  If find_fonts==true, render each font to its own image. Image filenames are of the form output_name.font_name.tif  (type:bool default:true)
  --list_available_fonts  List available fonts and quit.  (type:bool default:false)
  --render_ngrams  Put each space-separated entity from the input file into one bounding box. The ngrams in the input file will be randomly permuted before rendering (so
 that there is sufficient variety of characters on each line).  (type:bool default:false)
  --output_word_boxes  Output word bounding boxes instead of character boxes. This is used for Cube training, and implied by --render_ngrams.  (type:bool default:false)
  --bidirectional_rotation  Rotate the generated characters both ways.  (type:bool default:false)
  --only_extract_font_properties  Assumes that the input file contains a list of ngrams. Renders each ngram, extracts spacing properties and records them in output_base/
[font_name].fontinfo file.  (type:bool default:false)
  --output_individual_glyph_images  If true also outputs individual character images  (type:bool default:false)
  --text  File name of text input to process  (type:string default:)
  --outputbase  Basename for output image/box file  (type:string default:)
  --writing_mode  Specify one of the following writing modes.
'horizontal' : Render regular horizontal text. (default)
'vertical' : Render vertical text. Glyph orientation is selected by Pango.
'vertical-upright' : Render vertical text. Glyph  orientation is set to be upright.  (type:string default:horizontal)
  --font  Font description name to use  (type:string default:Arial)
  --unicharset_file  File with characters in the unicharset. If --render_ngrams is true and --unicharset_file is specified, ngrams with characters that are not in unicha
rset will be omitted  (type:string default:)
  --fontconfig_tmpdir  Overrides fontconfig default temporary dir  (type:string default:/tmp)
  --fonts_dir  If empty it use system default. Otherwise it overrides system default font location  (type:string default:)
```  https://tesseract-ocr.github.io/index.html 

was Generated on Mon Jul 20 2015 18:38:23 by  doxygen 1.8.8

Please update. Thanks! Documentation of tesseract generated from source code by insight.io can be found at https://www.insight.io/github.com/tesseract-ocr/tesseract

Both of these are linked from 
https://github.com/tesseract-ocr/tesseract/wiki/Documentation If https://www.insight.io/github.com/tesseract-ocr/tesseract
provides the same functionality as Doxygen, then this issue can be closed. Could a travis script such as the following be used to automatically update doxygen documentation?

https://github.com/miloyip/rapidjson/blob/master/travis-doxygen.sh

https://gist.github.com/vidavidorra/548ffbcdae99d752da02

http://blog.gockelhut.com/2014/09/automatic-documentation-publishing-with.html Thanks, @stweil . I have added to documentation page on wiki.

> New documentation is also visible here.

Is that as of master branch on May 20th or relative to some tag? Thanks!  Try without the patch. Maybe that change has already been applied.

On May 2, 2017 8:13 PM, "jsl303" <notifications@github.com> wrote:

> I was able to install head with brew before, but now I get this error. :(
> Could someone help?
> Thanks!
> $ brew install tesseract --HEAD
> ==> Auto-updated Homebrew!
> Updated 1 tap (homebrew/core).
> No changes to formulae.
>
> ==> Using the sandbox
> ==> Cloning https://github.com/tesseract-ocr/tesseract.git
> Cloning into '/Users/user/Library/Caches/Homebrew/tesseract--git'...
> remote: Counting objects: 724, done.
> remote: Compressing objects: 100% (694/694), done.
> remote: Total 724 (delta 88), reused 163 (delta 12), pack-reused 0
> Receiving objects: 100% (724/724), 3.74 MiB | 0 bytes/s, done.
> Resolving deltas: 100% (88/88), done.
> Checking connectivity... done.
> ==> Checking out branch master
> ==> Downloading https://github.com/tesseract-ocr/tesseract/commit/b18cad4.
> patch
> ########################################################################
> 100.0%
> ==> Patching
> ==> Applying b18cad4
> <https://github.com/tesseract-ocr/tesseract/commit/b18cad4cda217c15b0aad333ef7200024d2ecac3>
> .patch
> patching file configure.ac
> Hunk #1 <https://github.com/tesseract-ocr/tesseract/issues/1> FAILED at
> 220.
> 1 out of 1 hunk FAILED -- saving rejects to file configure.ac.rej
> patching file api/Makefile.am
> Hunk #1 <https://github.com/tesseract-ocr/tesseract/issues/1> FAILED at
> 45.
> 1 out of 1 hunk FAILED -- saving rejects to file api/Makefile.am.rej
> Error: Failure while executing: /usr/bin/patch -g 0 -f -p1 -i
> /private/tmp/tesseract--patch-20170502-16295-cpuv7w/b18cad4.patch
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/864>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o3IfozN9lAP88gjs9wh-NvF1aYnUks5r10D5gaJpZM4NOPNX>
> .
>
 see https://github.com/Homebrew/homebrew-core/blob/master/Formula/tesseract.rb @stweil Please see the recent post at https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/H9JmIRU2dQk/oMtSIvtHAwAJ regarding problem with install of training tools on mac os. Thanks!  Ref: 
* https://en.wikipedia.org/wiki/Arabic_numerals
* https://en.wikipedia.org/wiki/Eastern_Arabic_numerals
* https://en.wikipedia.org/wiki/Arabic_script_in_Unicode

> The Arabic numeral glyphs 0–9 are encoded in ASCII and Unicode at positions 0x30 to 0x39, matching up with the second hexadecimal digit for convenience:

> The Eastern Arabic numerals (also called Arabic–Indic numerals and Arabic Eastern numerals) are the symbols used to represent the Hindu–Arabic numeral system, in conjunction with the Arabic alphabet. 

> Each numeral in the Persian variant has a different Unicode point even if it looks identical to the Eastern Arabic numeral counterpart. However the variants used with Urdu, Sindhi, and other South Asian languages are not encoded separately from the Persian variants. 

> See U+0660 through U+0669 and U+06F0 through U+06F9.

So, basically, there are three unicode ranges with numerals used in Arabic, Persian etc.

* 0x30 to 0x39
* U+0660 through U+0669 
* U+06F0 through U+06F9

If the fonts are putting ` Eastern Arabic numerals` U+0660 through U+0669  in the `Arabic numerals` range of 0x30 to 0x39, that would cause confusion during training.

https://github.com/tesseract-ocr/langdata/blob/master/ara/ara.training_text has  'Arabic numerals' range of 0x30 to 0x39. You can check whether it as  ( ٠ ١ ٢ ٣ ٤ ٥ ٦ ٧ ٨ ٩) and add it, if you want to include it for training. @reza1615 

Are these getting recognized in the best traineddata? 
Are they being recognized as Arabic unicode numbers? @theraysmith 
Please update the desired characters for persian for the persian unicode range of numbers and ignore the unicode arabic number range for fas (persian), as mentioned above. Thanks! Question from Ray in tesseract-ocr/langdata#72

> Anyone know which digits are needed for the other Arabic languages?
kur_ara, pus, uig  Any objection to merge this PR? Making all in doc
make[2]: Entering directory `/mnt/c/Users/User/shree/tesseract/doc'
make[2]: *** No rule to make target `cntraining.1', needed by `all-am'.  Stop.
make[2]: Leaving directory `/mnt/c/Users/User/shree/tesseract/doc'
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `/mnt/c/Users/User/shree/tesseract'
make: *** [all] Error 2
 Making install in doc
make[1]: Entering directory `/mnt/c/Users/User/shree/tesseract/doc'
make[1]: *** No rule to make target `cntraining.1', needed by `all-am'.  Stop.
make[1]: Leaving directory `/mnt/c/Users/User/shree/tesseract/doc'
make: *** [install-recursive] Error 1
 The above errors came while building using the regular automake method with plain ./configure Thanks! I usually follow the following for rebuilding tesseract.

```
git pull origin

./autogen.sh
./configure 
LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make
sudo make install
sudo ldconfig
make training
sudo make training-install
```  For code style clang-format could be applied.  The newer tesseract code uses the Google C++ style guide:
https://google.github.io/styleguide/cppguide.html
and we have an internal tool that reformats your code for you, hence the
occasional commit with the formatting changes.
Anyway style guide has nothing to do with using the correct name for
Leptonica classes, and Dan says we should be using Pix in C++, not PIX.

On Fri, Apr 28, 2017 at 6:12 AM, Amit D. <notifications@github.com> wrote:

> https://github.com/DanBloomberg/leptonica/blob/master/style-guide.txt
>
> (c) Use typedefs for structs like Pix; e.g.,
> function(PIX *pixs)
> Do not do this (omitting the 'struct' keyword); it is valid C++,
> but not C:
> function(Pix *pixs)
>
> https://github.com/DanBloomberg/leptonica/blob/
> 150c8d005132c85dac0c6388b8408a485f2b65ac/src/bmf.h#L45
>
> Since Tesseract code is based on C++, we should use a C++ style guide.
> https://google.github.io/styleguide/cppguide.html#Type_Names
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/848#issuecomment-297993835>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056YU7BU-qAN6kjGkgqqZgKgfYw9tCks5r0eWwgaJpZM4NJwso>
> .
>



-- 
Ray.
  read_params_file: Can't open lstm.train

You need config file lstm.train

  @bertspaan :-) 

Since you already have an OCR process working, I suggest you wait for Ray to update code for training from scanned images and improve traineddata to support 1/2.

My hacked training is only proof of concept (i trained till about 2% accuracy) so while it recognizes 1/2 as %, other letters may not be as accurate as the traineddata from the repo. Please see the wiki page on training, there have been changes made to LSTM training process. https://github.com/tesseract-ocr/langdata

is the script_dir.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Aug 16, 2017 at 12:39 PM, CoCa520 <notifications@github.com> wrote:

> combine_lang_model which takes as input an input_unicharset and script_dir
> (script_dir points to the langdata directory) and optional word list
> files...
> I have got input_unicharset, but I don't know how can I get script_dir .
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/841#issuecomment-322685646>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_owv9Cyw11QES-BfmZH8KPSm_b_Ijks5sYpWlgaJpZM4NIBJS>
> .
>
 @CoCa520 Also see https://github.com/tesseract-ocr/tesseract/issues/590#issuecomment-322685025 tesseract eng.font.exp0.tif eng.font.exp0.box             lstm.train

you need a space after box to give the name of config file.

Best method is to follow the training tutorial. If you want more pages,
change tesstrain_utils.sh for max_page

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Aug 30, 2017 at 2:02 PM, CoCa520 <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/shreeshrii> Thank you！
> BUT
> I really can't understand how can I create lstm files.
> Can you show me the code.
>
> I have tried:
> tesseract eng.font.exp0.tif eng.font.exp0.box.lstm.train
> But it gives:
> Error during processing.
> ObjectCache(0x7f098f0849a0)::~ObjectCache(): WARNING! LEAK! object
> 0x29173e0 still has count 1 (id /usr/local/tesseract/share/
> tessdata/eng.traineddatapunc-dawg)
> ObjectCache(0x7f098f0849a0)::~ObjectCache(): WARNING! LEAK! object
> 0x2916420 still has count 1 (id /usr/local/tesseract/share/
> tessdata/eng.traineddataword-dawg)
> ObjectCache(0x7f098f0849a0)::~ObjectCache(): WARNING! LEAK! object
> 0x2916240 still has count 1 (id /usr/local/tesseract/share/tessdata/eng.
> traineddatanumber-dawg)
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/841#issuecomment-325921815>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_ozyFOlba1PIkz4zDYhN6YsomGE8Eks5sdR44gaJpZM4NIBJS>
> .
>
 4.0 training with tif/box pairs is not yet supported.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Aug 30, 2017 at 2:52 PM, CoCa520 <notifications@github.com> wrote:

> Training tutorial ?
> Do you mean https://github.com/tesseract-ocr/tesseract/wiki/
> TrainingTesseract-4.00 <http://url>
> but I just have tif/box pairs, so i come here for more information。
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/841#issuecomment-325934619>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o9zx0GhGvGJcTyC7Cp40PtGBxTKhks5sdSnrgaJpZM4NIBJS>
> .
>
 Others who have done licensed plate recognition may be able to give you
better tips.

For your user case, I think using an older version of tesseract, specially
one which supports the 'digits' config file for limiting output to numbers
may be a better choice than using 4.0alpha.

On 31-Aug-2017 9:27 AM, "CoCa520" <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/shreeshrii>
> I want to use tesseract4.00 to recognize models of machines. All model
> information are combines whit characters and numbers and located in
> somewhere of nameplate, so I have collected lots of pictures which contains
> various nameplate of each machine.
> After a series of processing, I have got lots pictures of model as follows:
> [image: image]
> <https://user-images.githubusercontent.com/22894599/29905526-d8207088-8e41-11e7-8a94-60661df186c8.png>
> [image: image]
> <https://user-images.githubusercontent.com/22894599/29905561-ff00a722-8e41-11e7-934d-8e87c61433df.png>
> And then I put all model pictures into tesseract for recognize, but the
> accuracy is not so good, so I am trying to train teaaeract4.00 with model
> pictures.
> The tesseract4.0 training tutorial said that there are two ways to create
> training data, and I use the first option: each line in the box file
> matches a 'character' (glyph) in the tiff image.
>
> If 4.0 training with tif/box pairs is not yet supported then how can I do
> to raise the accuracy?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/841#issuecomment-326182878>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o6HKRmwkXximPpL9HyJPhhWwtyPRks5sdi85gaJpZM4NIBJS>
> .
>
 also see https://github.com/openalpr/openalpr which uses tesseract-ocr

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Thu, Aug 31, 2017 at 9:27 AM, CoCa520 <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/shreeshrii>
> I want to use tesseract4.00 to recognize models of machines. All model
> information are combines whit characters and numbers and located in
> somewhere of nameplate, so I have collected lots of pictures which contains
> various nameplate of each machine.
> After a series of processing, I have got lots pictures of model as follows:
> [image: image]
> <https://user-images.githubusercontent.com/22894599/29905526-d8207088-8e41-11e7-8a94-60661df186c8.png>
> [image: image]
> <https://user-images.githubusercontent.com/22894599/29905561-ff00a722-8e41-11e7-934d-8e87c61433df.png>
> And then I put all model pictures into tesseract for recognize, but the
> accuracy is not so good, so I am trying to train teaaeract4.00 with model
> pictures.
> The tesseract4.0 training tutorial said that there are two ways to create
> training data, and I use the first option: each line in the box file
> matches a 'character' (glyph) in the tiff image.
>
> If 4.0 training with tif/box pairs is not yet supported then how can I do
> to raise the accuracy?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/841#issuecomment-326182878>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o6HKRmwkXximPpL9HyJPhhWwtyPRks5sdi85gaJpZM4NIBJS>
> .
>
  There's parallel set of functions for reading TIFF files.

https://github.com/tesseract-ocr/tesseract/blob/master/opencl/openclwrapper.cpp
https://github.com/DanBloomberg/leptonica/blob/master/src/tiffio.c

OpenclDevice::pixReadTiffCl() and friends
pixReadTiff() and friends

That whole section is a little weird for a few reasons.

1) TIFF decode is not very expensive, why bother with hardware assist?

2)  The OpenCL TIFF code has fallen behind Leptonica proper, enough to be currently disabled. (By the way, I'm probably capable of helping it catch up, but not very motivated.)

and most interestingly to me

3) All the actual computation in TIFF decode isn't even done by Leptonica, it is done by libtiff. So the ideal scenario for hardware assist would be something like a "libtiff-turbo" library. (Somewhat similar to how libjepg-turbo has replaced libjpeg in many linux systems). Putting it in Tesseract is really weird, and as a side effect causes a bunch of code duplication.

For all these reasons, if we did decide to prune out some OpenCL code, I think the TIFF portion is the best place to start. I'd roughly guess that includes about a dozen methods.


 This is the slide in question.


![slide](https://cloud.githubusercontent.com/assets/4961958/25460868/a1ea84fa-2a9a-11e7-8782-368554cf81f6.png)

I think this confirms TIFF decode is relatively inexpensive, and is an even smaller overall portion for Tesseract 4.x.

```
# This is a different TIFF, just playing around. 5.7 MB,  1678x2590, LZW TIFF, 3.2Ghz Intel processor
$ time tifftopnm lzw.tif > /dev/null
tifftopnm: writing PPM file

real	0m0.213s
user	0m0.172s
sys	0m0.008s
```

 Great job on this. I suspect next step is to remove the #include tiff.h lines and the build dependency on libtiff.  Ray's comment copied from https://github.com/tesseract-ocr/tesseract/issues/670 (closing that issue now as duplicate)

> unicharset_extractor doesn't read the WordStr box file format.
Sorry this is an un-tested path.
Furthermore, it isn't just a case of modifying unicharset_extractor.
For the Indic languages, the unicharset needs to know the syllable/grapheme clusters, and it can't get that from the Wordstr box file format. The best it can do is extract the unicodes used in the WordStr box file or you start with an existing unicharset for that training path. @amitdo Will your changes - https://github.com/amitdo/tesseract/commit/8fe2d918e447
work now that the new unicharset_extractor has been posted.  We could try to build it with cppan, but I have some libtiff linking issues. One could try to build tess on mac as on windows with cppan guide and see those errors. Please see reply and script used for building at

https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/b2YFzN7MtJg/HkcTYJyKCQAJ

https://mail.google.com/mail/u/0/#inbox/15b9c152e2a586c3?projector=1

> Hi Shree
> 
> Sorry for the delay in replying but I'm struggling to get a successful build now.  I'm attaching my shell script for you to look at but the failure seems to be related to aclocal being called inside autogen.sh.
> 
> To be honest I'm not confident that things are building OK elsewhere as I see a variety of error and warning messages appear even though the relevant script finishes with "success"! I'm not a C/C+ etc coder, I do all my programming using LiveCode.  I'm just trying to get a reliable build of a portable version of Tesseract that I can drive through a command-line interface.  The OCR capability I'm trying to provide using Tesseract is just a part of a much larger app.  LiveCode allows me to build an app on my Mac to be deployed on Mac, Windows & Linux.  In each case the only code I need for each target deployment is a command line or two that runs Tesseract with a given set of source files that my app has extracted/created elsewhere. In order to make installation easy I include a portable version of Tesseract amongst the resources for my app.
> 
> As I'm not a C etc. coder (I last wrote serious C several decades ago!) I'm not able to judge which error/warning messages are significant or figure out how to fix them.  I was hoping to follow a recipe that would reliably build a portable Tesseract for the Mac and Windows.  I'm just trying different combinations of sub-builds until I find one that works, which is why I ended up with a combination of older versions of the dependencies. So I'm not a good person to ask to build this and report errors etc!
> 
> Best regards
> 
> Peter
  >From what I have read, tesseract v4 greatly improves ocr due to LSTM. If I know that my text is going to be of a certain orientation and script (top to bottom and English), how do I take advantage of the newer engine? 

If you want to OCR English text, use the program (latest version built from master branch in github) with default options or specify language as English.

`tesseract ./testing/eurotext.tif eurotext`

or
`tesseract ./testing/eurotext.tif eurotext --oem 1 --psm 6 -l eng`

 tesseract4.0.0 alpha, execute the following command:
<pre>
[root@localhost workspace]# /opt/tesseract4.0/bin/tesseract pic/tesseract-chinese-1.png stdout --psm 0 
Warning. Invalid resolution 0 dpi. Using 70 instead.
Failed loading language 'osd'
Tesseract couldn't load any languages!
Warning: Auto orientation and script detection requested, but osd language failed to load
Estimating resolution as 219
Segmentation fault (core dumped)
</pre>
But exactly, the osd.traineddata is at the right space:
<pre>
[root@localhost workspace]# ls /opt/tesseract4.0/share/tessdata/
chi_sim.traineddata       chi_tra.traineddata       configs/                  ori.traineddata           pdf.ttf                   
chi_sim_vert.traineddata  chi_tra_vert.traineddata  eng.traineddata           osd.traineddata           tessconfigs/ 
</pre>
then I use the "--oem 0" options, it prints the following:
<pre>
[root@localhost workspace]# /opt/tesseract4.0/bin/tesseract pic/tesseract-chinese-1.png stdout --psm 0 --oem 0
Failed loading language 'eng'
Tesseract couldn't load any languages!
Could not initialize tesseract.
</pre>

Then I use tesseract3.05.1, It seems that tesseract always detect the script is "Latin", not what I expected   ​​
Ray has updated the LSTM training process.

Please install the latest code from github.

Please read the wiki again for the new instructions and try.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Thu, Aug 3, 2017 at 1:07 PM, yoyoshuang <notifications@github.com> wrote:

> Hello,@Shreeshrii <https://github.com/shreeshrii>
> I have the same problem like @am0awad <https://github.com/am0awad> .
>
> ` training/tesstrain.sh \
>
> --fonts_dir /Library/Fonts
> --lang chi_sim
> --linedata_only
> --noextract_font_properties
> --exposures "0"
> --langdata_dir ./langdata
> --tessdata_dir ./tessdata
> --output_dir ./tesstutorial/chi_sim `
>
> I have already download the https://github.com/tesseract-ocr/langdata
> <http://url> to my folder, and I have all the folders:
>
> ./langdata
> ./langdata/chi_sim
> ./tessdata
>
> but I still got this:
> `=== Starting training for language 'chi_sim'
> mktemp: illegal option -- -
> usage: mktemp [-d] [-q] [-t prefix] [-u] template ...
> mktemp [-d] [-q] [-u] -t prefix
> training/tesstrain_utils.sh: line 189: /sample_text.txt: Permission denied
> [2017年 8月 3日 星期四 15时23分24秒 CST] /usr/local/bin/text2image
> --fonts_dir=/Library/Fonts --font=AR PL UKai CN Light
> --outputbase=/sample_text.txt --text=/sample_text.txt --fontconfig_tmpdir=
>
> === Phase I: Generating training images ===
> Rendering using Arial Unicode MS
> Rendering using AR PL UKai CN Light
> [2017年 8月 3日 星期四 15时23分25秒 CST] /usr/local/bin/text2image
> --fontconfig_tmpdir= --fonts_dir=/Library/Fonts --strip_unrenderable_words
> --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/var/folders/br/
> xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.AR_PL_UKai_CN_Light.exp0
> --font=AR PL UKai CN Light --text=./langdata/chi_sim/chi_sim.training_text
> [2017年 8月 3日 星期四 15时23分25秒 CST] /usr/local/bin/text2image
> --fontconfig_tmpdir= --fonts_dir=/Library/Fonts --strip_unrenderable_words
> --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/var/folders/br/
> xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.Arial_Unicode_MS.exp0
> --font=Arial Unicode MS --text=./langdata/chi_sim/chi_sim.training_text
> ERROR: /var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/
> tmp.NTXG7RhZ/chi_sim/chi_sim.Arial_Unicode_MS.exp0.box does not exist or
> is not readable
> ERROR: /var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/
> tmp.NTXG7RhZ/chi_sim/chi_sim.AR_PL_UKai_CN_Light.exp0.box does not exist
> or is not readable
> ERROR: /var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/
> tmp.NTXG7RhZ/chi_sim/chi_sim.AR_PL_UKai_CN_Light.exp0.box does not exist
> or is not readable`
>
> would anyone like to help me?
>
> Thank you very much!
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/819#issuecomment-319892740>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o-thKFCnUFwGRYnGQlFCzaFHXksYks5sUXiggaJpZM4M6-yu>
> .
>
 Look at the tif file in question in tmp folder. Looks like first line has
nulls in it.

On 17-Oct-2017 5:59 PM, "hanikh" <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/shreeshrii> at Phase I, I got this error:
> Rendered page 2 to file /tmp/tmp.GZVqm2mm3D/fas/fas.
> Times_New_Roman.exp0.tif
> Null box at index 0
> Error: Call PrepareToWrite before WriteTesseractBoxFile!!
> but the process did not stop. and it got this error:
> ERROR: /tmp/tmp.GZVqm2mm3D/fas/fas.Times_New_Roman.exp0.lstmf does not
> exist or is not readable
> probably, the problem is in the very first phase. would you please help me
> solve it?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/819#issuecomment-337215631>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o0n0rSz-Z9XhUN2g4ge8DsQXIZi9ks5stJ25gaJpZM4M6-yu>
> .
>
 Does Times New Roman font support Farsi? You should use fonts that have
support for your training_text language.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Oct 17, 2017 at 9:13 PM, hanikh <notifications@github.com> wrote:

> yes. you're right. in fact, there are just numbers and some marks in tif
> file. why is that happening?
>
> On Tue, Oct 17, 2017 at 5:29 PM, Shreeshrii <notifications@github.com>
> wrote:
>
> > Look at the tif file in question in tmp folder. Looks like first line has
> > nulls in it.
> >
> > On 17-Oct-2017 5:59 PM, "hanikh" <notifications@github.com> wrote:
> >
> > > @Shreeshrii <https://github.com/shreeshrii> at Phase I, I got this
> > error:
> > > Rendered page 2 to file /tmp/tmp.GZVqm2mm3D/fas/fas.
> > > Times_New_Roman.exp0.tif
> > > Null box at index 0
> > > Error: Call PrepareToWrite before WriteTesseractBoxFile!!
> > > but the process did not stop. and it got this error:
> > > ERROR: /tmp/tmp.GZVqm2mm3D/fas/fas.Times_New_Roman.exp0.lstmf does not
> > > exist or is not readable
> > > probably, the problem is in the very first phase. would you please help
> > me
> > > solve it?
> > >
> > > —
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/819#
> > issuecomment-337215631>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/AE2_o0n0rSz-
> > Z9XhUN2g4ge8DsQXIZi9ks5stJ25gaJpZM4M6-yu>
> > > .
> > >
> >
> > —
> > You are receiving this because you commented.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/819#
> issuecomment-337240137>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AZFiASKi4zAcvT6hL8SkvIybrnjQVMWrks5stLLOgaJpZM4M6-yu>
> > .
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/819#issuecomment-337269936>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o5yHcKCu2plw2oV9eKheXyc1opAYks5stMsagaJpZM4M6-yu>
> .
>
  @amitdo

since 4.0 version is alpha, --enable-debug is useful to track errors. Added page to wiki - https://github.com/tesseract-ocr/tesseract/wiki/4.0-Dockerfile See https://github.com/tesseract-ocr/tesseract/issues/919#issuecomment-302300156

>Definitions of Docker containers and scripts that help to compile and run Tesseract 4 are available at:

https://github.com/tesseract-shadow/tesseract-ocr-compilation @zdenop This issue can be closed.  Sorry, did not realize the dockerfile was in tesseract repo. It seems to be related to travis build. Is it being used?


  1. Current stable version is 3.05
2. Banner text output is to stderr because from 3.04 there is possible to output OCR result to stdin and banner text should not be part of  OCR output (stdout)  @stweil 

Please see https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/P-4AqnnGpgc/fMbEr1o9BAAJ

Do you know what could be causing this behaviour for install on windows 10? Thanks!

>Thank you for the reply. I went to https://github.com/UB-Mannheim/tesseract/wiki, download  tesseract-ocr-setup.exe file but when i click on it, it send me to the get apps from the store app. I don't know why it did not install and why it sent me to app store for since I already got the  tesseract-ocr-setup.exe. 
Regards,
Tom  Please use tesseract user forum for asking questions.  Please use tesseract user forum for asking question.  Please use tesseract user forum for asking support  One should open a ticket with build (and other) errors provided and we'll try to help with that. Several people are doing the same things.
Look, we have manual deps management from peirick, vdevan, maybe others.
This just is not worth it.  Why you put this on in the issue tracker? @lvc : Thanks, but there is place for this: [tesseract developer forum.](https://groups.google.com/forum/#!forum/tesseract-dev)
@amitdo : Broken ABI is know issue ;-) Even API is not stable. See dev forum. @lvc If possible, instead of current version, add 'master' and '3.05' branch. Thanks! Thanks.

Actually, 3.05 and master 4.0 are going to be two parralel tracks for a
while.

Zdenko is going to tag 3.05.01 release soon, so that should be compared
with 3.05.0 for changes. Any changes after that on 3.05 branch should
follow as current in that sequence.

Similarly, 4.0.0alpha may be followed by a beta or release, plus changes in
master branch.

If not possible to do in same table, you can make a separate one for 4.0.

Thanks.

On May 8, 2017 4:43 PM, "ABI Laboratory" <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/Shreeshrii>,
>
> Done: https://abi-laboratory.pro/tracker/timeline/tesseract/
>
> Please let me know when it should be switched to 3.06 or 4.0.
>
> [image: tesseract-5]
> <https://cloud.githubusercontent.com/assets/1517837/25801811/724dac08-3400-11e7-9af3-ff379784aeaf.png>
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/793#issuecomment-299839596>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o8RhIVFBMs9UWv8yY7aXzTrDJZwmks5r3vjigaJpZM4MrL5o>
> .
>
  This is still happening with the latest code - the eval file was built using a different training text.

**git log -1
commit d18931e86ed9b8fc40299d5494b53901310b4867
Date:   Fri May 5 16:42:44 2017 -0700
    Fixed int types for imported tf networks**

```
  lstmtraining \
>   -U ~/tesstutorial/bihnew/bih.unicharset \
>   --train_listfile ~/tesstutorial/bihnew/bih.training_files.txt \
>   --eval_listfile ~/tesstutorial/bihtest/bih.training_files.txt \
>   --continue_from ~/tesstutorial/bihnewlayer/bih.lstm \
>   --model_output ~/tesstutorial/bihnewlayer/bihlayer \
>   --script_dir ../langdata \
>  --append_index 5 \
>  --net_spec '[Lfx384 O1c105]' \
>  --target_error_rate 0.01 \
>  --debug_interval -1
Loaded file /home/shree/tesstutorial/bihnewlayer/bih.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from /home/shree/tesstutorial/bihnewlayer/bih.lstm
Appending a new network to an old one!!Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Setting properties for script Devanagari
Setting properties for script Han
Warning: given outputs 105 not equal to unicharset of 145.
Num outputs,weights in serial:
  Lfx384:384, 787968
  Fc145:145, 55825
Total weights = 843793
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx384Fc145] from request [Lfx384 O1c105]
Training parameters:
  Debug interval = -1, weights = 0.1, learning rate = 0.0001, momentum=0.9
Loaded 404/404 pages (1-404) of document /home/shree/tesstutorial/bihnew/bih.AA_NAGARI_SHREE_L3.exp0.lstmf
Loaded 199/199 pages (1-199) of document /home/shree/tesstutorial/bihtest/bih.Chandas.exp0.lstmf
Loaded 404/404 pages (1-404) of document /home/shree/tesstutorial/bihnew/bih.Adobe_Devanagari.exp0.lstmf
Loaded 404/404 pages (1-404) of document /home/shree/tesstutorial/bihnew/bih.CDAC-GISTSurekh.exp0.lstmf
Loaded 404/404 pages (1-404) of document /home/shree/tesstutorial/bihnew/bih.Aksharyogini2.exp0.lstmf
Loaded 411/411 pages (1-411) of document /home/shree/tesstutorial/bihnew/bih.CDAC-GISTYogesh.exp0.lstmf
Loaded 405/405 pages (1-405) of document /home/shree/tesstutorial/bihnew/bih.Annapurna_SIL.exp0.lstmf
Loaded 404/404 pages (1-404) of document /home/shree/tesstutorial/bihnew/bih.Arial_Unicode_MS.exp0.lstmf
Loaded 404/404 pages (1-404) of document /home/shree/tesstutorial/bihnew/bih.Aparajita.exp0.lstmf
Loaded 472/472 pages (1-472) of document /home/shree/tesstutorial/bihnew/bih.Chandas.exp0.lstmf
Loaded 202/202 pages (1-202) of document /home/shree/tesstutorial/bihtest/bih.FreeSerif.exp0.lstmf

At iteration 100/100/100, Mean rms=5.4%, delta=52.955%, char train=110.663%, word train=100%, skip ratio=0%,  New worst char error = 110.663 wrote checkpoint.
At iteration 200/200/200, Mean rms=5.254%, delta=50.469%, char train=105.319%, word train=100%, skip ratio=0%,  New worst char error = 105.319 wrote checkpoint.
At iteration 300/300/300, Mean rms=5.209%, delta=49.853%, char train=103.546%, word train=100%, skip ratio=0%,  New worst char error = 103.546 wrote checkpoint.
At iteration 400/400/400, Mean rms=5.189%, delta=49.729%, char train=102.636%, word train=100%, skip ratio=0%,  New worst char error = 102.636 wrote checkpoint.
At iteration 500/500/500, Mean rms=5.147%, delta=48.821%, char train=102.064%, word train=100%, skip ratio=0%,  New worst char error = 102.064 wrote checkpoint.
At iteration 600/600/600, Mean rms=5.127%, delta=48.496%, char train=101.601%, word train=99.991%, skip ratio=0%,  New worst char error = 101.601 wrote checkpoint.
At iteration 700/700/700, Mean rms=5.107%, delta=48.218%, char train=101.236%, word train=99.992%, skip ratio=0%,  New worst char error = 101.236 wrote checkpoint.
At iteration 800/800/800, Mean rms=5.081%, delta=47.738%, char train=100.547%, word train=99.986%, skip ratio=0%,  New worst char error = 100.547 wrote checkpoint.
At iteration 899/900/900, Mean rms=5.06%, delta=47.379%, char train=100.071%, word train=99.983%, skip ratio=0%,  New worst char error = 100.071 wrote checkpoint.
At iteration 999/1000/1000, Mean rms=5.038%, delta=46.991%, char train=99.425%, word train=99.985%, skip ratio=0%,  New best char error = 99.425 wrote checkpoint.
At iteration 1098/1100/1100, Mean rms=4.971%, delta=45.696%, char train=97.6%, word train=99.979%, skip ratio=0%,  New best char error = 97.6Deserialize failed wrote che
At iteration 1197/1200/1200, Mean rms=4.932%, delta=44.848%, char train=96.57%, word train=99.979%, skip ratio=0%,  New best char error = 96.57Deserialize failed wrote c
At iteration 1296/1300/1300, Mean rms=4.7%, delta=40.982%, char train=90.782%, word train=98.025%, skip ratio=0%,  New best char error = 90.782Deserialize failed wrote c
At iteration 1392/1400/1400, Mean rms=4.388%, delta=36.654%, char train=83.142%, word train=93.749%, skip ratio=0%,  New best char error = 83.142Deserialize failed wrote
At iteration 1491/1500/1500, Mean rms=4.053%, delta=32.455%, char train=74.886%, word train=88.3%, skip ratio=0%,  New best char error = 74.886Deserialize failed wrote c
At iteration 1582/1600/1600, Mean rms=3.71%, delta=28.11%, char train=66.546%, word train=82.7%, skip ratio=0%,  New best char error = 66.546Deserialize failed wrote bes
At iteration 1678/1700/1700, Mean rms=3.366%, delta=23.795%, char train=58.181%, word train=76.531%, skip ratio=0%,  New best char error = 58.181Deserialize failed wrote
At iteration 1772/1800/1800, Mean rms=3.018%, delta=19.642%, char train=49.915%, word train=70.119%, skip ratio=0%,  New best char error = 49.915Deserialize failed wrote
At iteration 1862/1900/1900, Mean rms=2.67%, delta=15.494%, char train=41.584%, word train=63.451%, skip ratio=0%,  New best char error = 41.584Deserialize failed wrote
At iteration 1955/2000/2000, Mean rms=2.321%, delta=11.413%, char train=33.335%, word train=56.515%, skip ratio=0%,  New best char error = 33.335Deserialize failed wrote
At iteration 2049/2100/2101, Mean rms=1.978%, delta=7.632%, char train=25.213%, word train=49.514%, skip ratio=0.1%,  New best char error = 25.213Deserialize failed wrot
At iteration 2137/2200/2201, Mean rms=1.631%, delta=3.903%, char train=17.289%, word train=42.271%, skip ratio=0.1%,  New best char error = 17.289Deserialize failed wrot
At iteration 2230/2300/2301, Mean rms=1.474%, delta=3.148%, char train=14.004%, word train=36.724%, skip ratio=0.1%,  New best char error = 14.004Deserialize failed wrot
``` @stweil Is it related to https://github.com/tesseract-ocr/tesseract/issues/881#issuecomment-299393920 ? @stweil In case you want to reproduce using the files I was using - they are for Bihari/Hindi language, devanagari script. 

http://sanskritdocuments.org/hindi/bihtest.zip
http://sanskritdocuments.org/hindi/bihnew.zip

Zip file was too large to upload here or on my github account. ```
mkdir -p ~/tesstutorial/bihnewlayer

combine_tessdata -e ../tessdata/hin.traineddata \
   ~/tesstutorial/bihnewlayer/bih.lstm
```

I was using the Hindi traineddata from the tessdata repo as the basis for training.  > ~/tesstutorial/bihnewlayer is needed, too.

http://sanskritdocuments.org/hindi/bihnewlayer.zip

it has:

* bih.lstm (lstm model extracted from hin.traineddata)
* bihlayer_checkpoint (current status of the model)
* bihlayer4.005_8369.lstm (latest 'best' model)

I have not included all other intermediate .lstm files, since each is 33+ MB. Thanks for checking, @stweil. I will rebuild with the latest git master and test again as I am still getting `Deserialize Failed` messages, though not for every checkpoint iteration of training. 

Maybe, these are also just 'info' messages!

At iteration 8306/10800/10808, Mean rms=0.765%, delta=1.311%, char train=4.216%, word train=10.221%, skip ratio=0.2%,  New best char error = 4.216 wrote best model:/ho
**At iteration 8369/10900/10908, Mean rms=0.753%, delta=1.217%, char train=4.005%, word train=10.036%, skip ratio=0.2%,  New best char error = 4.005Deserialize failed wr
At iteration 8426/11000/11008, Mean rms=0.752%, delta=1.211%, char train=4.014%, word train=9.962%, skip ratio=0.2%,  New worst char error = 4.014Deserialize failed w**r
At iteration 8482/11100/11109, Mean rms=0.768%, delta=1.319%, char train=4.281%, word train=10.389%, skip ratio=0.3%,  New worst char error = 4.281 wrote checkpoint.
At iteration 8548/11200/11210, Mean rms=0.773%, delta=1.355%, char train=4.347%, word train=10.64%, skip ratio=0.3%,  New worst char error = 4.347 wrote checkpoint.
At iteration 8607/11300/11310, Mean rms=0.772%, delta=1.37%, char train=4.4%, word train=10.701%, skip ratio=0.3%,  New worst char error = 4.4 wrote checkpoint.
At iteration 8666/11400/11410, Mean rms=0.777%, delta=1.359%, char train=4.394%, word train=10.81%, skip ratio=0.3%,  New worst char error = 4.394 wrote checkpoint.
At iteration 8729/11500/11510, Mean rms=0.772%, delta=1.368%, char train=4.385%, word train=10.801%, skip ratio=0.2%,  New worst char error = 4.385 wrote checkpoint.
At iteration 8794/11600/11610, Mean rms=0.772%, delta=1.343%, char train=4.354%, word train=10.848%, skip ratio=0.2%,  New worst char error = 4.354 wrote checkpoint.
At iteration 8857/11700/11710, Mean rms=0.786%, delta=1.415%, char train=4.538%, word train=11.094%, skip ratio=0.2%,  New worst char error = 4.538 wrote checkpoint.
At iteration 8919/11800/11810, Mean rms=0.802%, delta=1.531%, char train=4.968%, word train=11.586%, skip ratio=0.2%,  New worst char error = 4.968 wrote checkpoint.
At iteration 8979/11900/11910, Mean rms=0.8%, delta=1.548%, char train=5.043%, word train=11.359%, skip ratio=0.2%,  New worst char error = 5.043 wrote checkpoint.
At iteration 9034/12000/12010, Mean rms=0.79%, delta=1.526%, char train=4.924%, word train=11.199%, skip ratio=0.2%,  New worst char error = 4.924 wrote checkpoint.
At iteration 9101/12100/12110, Mean rms=0.781%, delta=1.449%, char train=4.766%, word train=11.043%, skip ratio=0.1%,  New worst char error = 4.766 wrote checkpoint.
At iteration 9160/12200/12210, Mean rms=0.784%, delta=1.443%, char train=4.801%, word train=11.025%, skip ratio=0%,  New worst char error = 4.801 wrote checkpoint.
At iteration 9224/12300/12310, Mean rms=0.784%, delta=1.444%, char train=4.728%, word train=10.783%, skip ratio=0%,  New worst char error = 4.728 wrote checkpoint.
At iteration 9285/12400/12410, Mean rms=0.782%, delta=1.477%, char train=4.773%, word train=10.693%, skip ratio=0%,  New worst char error = 4.773 wrote checkpoint.
At iteration 9349/12500/12511, Mean rms=0.776%, delta=1.419%, char train=4.545%, word train=10.359%, skip ratio=0.1%,  New worst char error = 4.545 wrote checkpoint.
At iteration 9405/12600/12611, Mean rms=0.769%, delta=1.421%, char train=4.498%, word train=10.172%, skip ratio=0.1%,  New worst char error = 4.498 wrote checkpoint.
At iteration 9461/12700/12711, Mean rms=0.749%, delta=1.324%, char train=4.276%, word train=9.825%, skip ratio=0.1%,  wrote checkpoint.
**At iteration 9518/12800/12811, Mean rms=0.737%, delta=1.229%, char train=3.922%, word train=9.583%, skip ratio=0.1%,  New best char error = 3.922Previous test incomple
At iteration 9576/12900/12911, Mean rms=0.733%, delta=1.198%, char train=3.746%, word train=9.473%, skip ratio=0.1%,  New best char error = 3.746Previous test incomple
At iteration 9641/13000/13011, Mean rms=0.743%, delta=1.261%, char train=4.006%, word train=9.773%, skip ratio=0.1%,  New worst char error = 4.006Previous test incompl
At iteration 9708/13100/13111, Mean rms=0.742%, delta=1.255%, char train=3.899%, word train=9.567%, skip ratio=0.1%,  New worst char error = 3.899Previous test incompl
At iteration 9766/13200/13211, Mean rms=0.727%, delta=1.193%, char train=3.708%, word train=9.23%, skip ratio=0.1%,  New best char error = 3.708Previous test incomplet
At iteration 9822/13300/13311, Mean rms=0.727%, delta=1.191%, char train=3.717%, word train=9.477%, skip ratio=0.1%,  New worst char error = 3.717Previous test incompl**
At iteration 9880/13400/13411, Mean rms=0.723%, delta=1.151%, char train=3.603%, word train=9.355%, skip ratio=0.1%,  New best char error = 3.603At iteration 8369, sta
ge 1, Eval Char error rate=2.0568204, Word error rate=4.3746914 wrote best model:/home/shree/tesstutorial/bihnewlayer/bihlayer3.603_9880.lstm wrote checkpoint.
**At iteration 9934/13500/13511, Mean rms=0.725%, delta=1.203%, char train=3.786%, word train=9.603%, skip ratio=0%,  New worst char error = 3.786Deserialize failed wrot**
At iteration 9988/13600/13611, Mean rms=0.733%, delta=1.237%, char train=4.018%, word train=9.875%, skip ratio=0%,  New worst char error = 4.018 wrote checkpoint.
At iteration 10036/13700/13711, Mean rms=0.737%, delta=1.256%, char train=4.052%, word train=10.005%, skip ratio=0%,  New worst char error = 4.052 wrote checkpoint.
 >I had to fix the path in ~/tesstutorial/bihtest/bih.training_files.txt,

Did you need to change path in both to match your setup?

>   --train_listfile ~/tesstutorial/bihnew/bih.training_files.txt \
>   --eval_listfile ~/tesstutorial/bihtest/bih.training_files.txt \

or did you change path in bihtest to match bihnew?

I think the problem occurs when the training files and evaluation files are different. The lstmf files in bihnew and bihtest were created using different training texts and font combos.  Thanks, @stweil . However, I can now reproduce the error that you got when using lstmf files from a different version.

@theraysmith I am getting these errors when I use lstmf files created before the commits regarding endianness. However, the location of error is different from the rest reported above in this thread.

```
 lstmtraining  \
>    -U ~/tesstutorial/nyd/eng.unicharset \
>   --train_listfile ~/tesstutorial/nyd/nyd.training_files.txt \
>   --script_dir ../langdata   \
>   --append_index 5 --net_spec '[Lfx256 O1c105]' \
>   --continue_from ~/tesstutorial/nydlayer/eng.lstm \
>   --model_output ~/tesstutorial/nydlayer/nyd \
>   --debug_interval -1 \
>   --target_error_rate 0.01
Loaded file /home/shree/tesstutorial/nydlayer/eng.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from /home/shree/tesstutorial/nydlayer/eng.lstm
Appending a new network to an old one!!Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Warning: given outputs 105 not equal to unicharset of 75.
Num outputs,weights in serial:
  Lfx256:256, 394240
  Fc75:75, 19275
Total weights = 413515
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc75] from request [Lfx256 O1c105]
Training parameters:
  Debug interval = -1, weights = 0.1, learning rate = 0.0001, momentum=0.9
```
**Deserialize failed: /home/shree/tesstutorial/nyd/eng.1852nydir.exp1.lstmf read 0/8 pages**
 @stweil @theraysmith 

I tried running using the latest code with enable-debug option - earlier the error was 'deserialize failed' - please see https://github.com/tesseract-ocr/tesseract/issues/792#issuecomment-299809206

With --enable-debug, I get core dumped (same as https://github.com/tesseract-ocr/tesseract/issues/561)

```
Iteration 13398: ALIGNED TRUTH : पंचाग कला की, फ़ अः ग़ुमान आलोचना छूटती के ज़् द्वा अधीन र्द् देहियाँ भजनला
Iteration 13398: BEST OCR TEXT : पंचाग कला की, फ़ अः गुमान आलोचना छूटती के ज़् द्वा अधीन र्द् देहियाँ भजनला
File /tmp/tmp.3zBjAvGc9O/bih/bih.Lohit_Devanagari.exp0.lstmf page 24 :
Mean rms=0.723%, delta=1.151%, train=3.605%(9.362%), skip ratio=0.1%
Iteration 13399: ALIGNED TRUTH : संभावना :
Iteration 13399: BEST OCR TEXT : संभावना :
File /tmp/tmp.3zBjAvGc9O/bih/bih.Mangal.exp0.lstmf page 458 (Perfect):
Mean rms=0.723%, delta=1.151%, train=3.603%(9.355%), skip ratio=0.1%
lstmtraining: ../ccutil/genericvector.h:697: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
Aborted (core dumped)
```
gdb output pasted below:
```
Iteration 13399: ALIGNED TRUTH : संभावना :
Iteration 13399: BEST OCR TEXT : संभावना :
File /tmp/tmp.3zBjAvGc9O/bih/bih.Mangal.exp0.lstmf page 458 (Perfect):
Mean rms=0.723%, delta=1.151%, train=3.603%(9.355%), skip ratio=0.1%
[Thread 0x7fe0cd3e0700 (LWP 135) exited]
[New Thread 0x7fe0cd3e0700 (LWP 136)]
lstmtraining: ../ccutil/genericvector.h:697: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

Program received signal SIGABRT, Aborted.
[Switching to Thread 0x7fe0cd3e0700 (LWP 136)]
0x00007fe0d2886c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
56      ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.
(gdb) backtrace
#0  0x00007fe0d2886c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
#1  0x00007fe0d288a028 in __GI_abort () at abort.c:89
#2  0x00007fe0d287fbf6 in __assert_fail_base (fmt=0x7fe0d29d03b8 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n",
    assertion=assertion@entry=0x7fe0d370d6c0 "index >= 0 && index < size_used_", file=file@entry=0x7fe0d370d148 "../ccutil/genericvector.h", line=line@entry=697,
    function=function@entry=0x7fe0d372ea60 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]")
    at assert.c:92
#3  0x00007fe0d287fca2 in __GI___assert_fail (assertion=0x7fe0d370d6c0 "index >= 0 && index < size_used_", file=0x7fe0d370d148 "../ccutil/genericvector.h", line=697,
    function=0x7fe0d372ea60 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:101
#4  0x00007fe0d368c803 in GenericVector<char>::operator[] (this=<optimized out>, this=<optimized out>, index=0) at ../ccutil/genericvector.h:697
#5  0x00007fe0d368cfb8 in operator[] (this=0x7fffcf2d0bc0, this=0x7fffcf2d0bc0, index=0) at lstmtrainer.cpp:920
#6  tesseract::LSTMTrainer::ReadTrainingDump (this=this@entry=0x7fe0cd3df640, data=..., trainer=trainer@entry=0x7fe0cd3df640) at lstmtrainer.cpp:921
#7  0x000000000040b03e in tesseract::LSTMTester::RunEvalSync (this=this@entry=0x7fffcf2d0b50, iteration=9766, training_errors=<optimized out>, model_data=...,
    training_stage=1) at lstmtester.cpp:86
#8  0x000000000040b539 in tesseract::LSTMTester::ThreadFunc (lstmtester_void=0x7fffcf2d0b50) at lstmtester.cpp:123
#9  0x00007fe0d0748184 in start_thread (arg=0x7fe0cd3e0700) at pthread_create.c:312
#10 0x00007fe0d294a37d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111
(gdb) up
#1  0x00007fe0d288a028 in __GI_abort () at abort.c:89
89      abort.c: No such file or directory.
(gdb) up
#2  0x00007fe0d287fbf6 in __assert_fail_base (fmt=0x7fe0d29d03b8 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n",
    assertion=assertion@entry=0x7fe0d370d6c0 "index >= 0 && index < size_used_", file=file@entry=0x7fe0d370d148 "../ccutil/genericvector.h", line=line@entry=697,
    function=function@entry=0x7fe0d372ea60 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]")
    at assert.c:92

...

(gdb) up
#7  0x000000000040b03e in tesseract::LSTMTester::RunEvalSync (this=this@entry=0x7fffcf2d0b50, iteration=9766, training_errors=<optimized out>, model_data=...,
    training_stage=1) at lstmtester.cpp:86
86        if (!trainer.ReadTrainingDump(model_data, &trainer)) {
(gdb) print model_data
$10 = (const GenericVector<char> &) @0x7fffcf2d0bc0: {static kDefaultVectorSize = <optimized out>, size_used_ = 0, size_reserved_ = 0, data_ = 0x0, clear_cb_ = 0x0,
  compare_cb_ = 0x0}
```

@stweil was not able to reproduce this - https://github.com/tesseract-ocr/tesseract/issues/792#issuecomment-299780420

The only difference I can see would be that I run the program under WSL (bash on windows 10).
 Duplicate/Related  https://github.com/tesseract-ocr/tesseract/issues/644 Still getting the error:

```
At iteration 800/800/802, Mean rms=0.934%, delta=47.138%, char train=100.525%, word train=100%, skip ratio=0.25%,  New worst char error = 100.525 wrote checkpoint.
Compute CTC targets failed!
At iteration 900/900/903, Mean rms=0.932%, delta=46.952%, char train=100.461%, word train=99.972%, skip ratio=0.333%,  New worst char error = 100.461 wrote checkpoint.
Warning: data size is zero in LSTMTrainer::ReadTrainingDump
At iteration 1000/1000/1003, Mean rms=0.93%, delta=46.74%, char train=100.415%, word train=99.975%, skip ratio=0.3%,  New worst char error = 100.415 wrote checkpoint.
Warning: LSTMTrainer deserialized an LSTMRecognizer!
2 Percent improvement time=1098, best error was 100 @ 0
Compute CTC targets failed!
Compute CTC targets failed!
At iteration 1098/1100/1103, Mean rms=0.917%, delta=45.445%, char train=99.984%, word train=99.975%, skip ratio=0.3%,  New best char error = 99.984

Deserialize failed wrote checkpoint.
```

ref: https://travis-ci.org/Shreeshrii/tess4train/builds/252343478 Closing Issue since LSTM training process has changed and so it is difficult to duplicate the issue.  This not correct PR  What source are you using? "config" and "m4" is not part of [tesseract distribution.](https://github.com/tesseract-ocr/tesseract)  make a PR please. Hi,

I've activated macos builds (clang).
See
https://travis-ci.org/tesseract-ocr/tesseract/builds/215040103
https://travis-ci.org/tesseract-ocr/tesseract/builds  So far the new script id looks good.
I don't understand why you would ever want to run OSD on license plates? It makes no sense.  First of all: provide details (how you build tesseract, configuration output, libraries version etc.) I am not familiar with building on Mac, but can you please try to install tesseract "by hand" (without homebrew)? 

For linking on macos10 ["-framework OpenCL"](https://github.com/tesseract-ocr/tesseract/blob/3.05/configure.ac#L223) should be used. Your [configure log](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/blob/master/Tesseract/v3.05.00/Third%20Attempt/02.configure) showed it was detected correctly, but I do not see it in your [make log](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/blob/master/Tesseract/v3.05.00/Third%20Attempt/03.make). `configure` uses `pkg-config` to detect `cairo`. It can be overridden by setting `cairo_CFLAGS` and `cairo_LIBS`, but fixing the installation would be better of course. First of all - it is a warning, not an error ;-)
Next: it is not related to originally reported issue (opencl build), so please ignore it. @jbarlow83: Can you have a look on this issue? It seems to me problem with linking (OpenCL build on OS X) I am not OS X user, so maybe I am wrong. But from logs it seems that:

- configure detect OpenCL framework
- make output show there is not linking to against OpenCL framework

  Do you get the same error messages when using text output?

```gm.exe convert -density 300 pdfin.pdf tif:- | tesseract.exe txtout -l deu``` The error messages are harmless, but annoying. This change will get rid off half of them. I'll make a change in Leptonica to get rid of the other half. Thanks for the report. This change is good to go on both branches.

```c++
--- api/pdfrenderer.cpp	2017-01-20 14:57:59.000000000 -0800
+++ api/pdfrenderer.cpp	2017-03-23 08:51:31.000000000 -0700
@@ -709,9 +709,8 @@
   L_COMP_DATA *cid = NULL;
   const int kJpegQuality = 85;
 
-  int format, sad;
-  findFileFormat(filename, &format);
-  if (pixGetSpp(pix) == 4 && format == IFF_PNG) {
+  int sad;
+  if (pixGetSpp(pix) == 4 && pixGetInputFormat(pix) == IFF_PNG) {
     Pix *p1 = pixAlphaBlendUniform(pix, 0xffffff00);
     sad = pixGenerateCIData(p1, L_FLATE_ENCODE, 0, 0, &cid);
     pixDestroy(&p1);
``` Leptonica change will look something like this. These changes  are both forward and backward compatible, no need to adjust version dependencies.

```c++
--- leptonica/src/pdfio2.c	2017-03-09 08:41:53.000000000 -0800
+++leptonica/src/pdfio2.c	2017-03-23 09:32:21.000000000 -0700
@@ -496,7 +496,7 @@
 /*!
  * \brief   l_generateCIDataForPdf()
  *
- * \param[in]    fname
+ * \param[in]    fname [optional]; can be null
  * \param[in]    pix [optional]; can be null
  * \param[in]    quality for jpeg if transcoded; 75 is standard
  * \param[out]   pcid compressed data
@@ -504,11 +504,15 @@
  *
  * <pre>
  * Notes:
+ *      (0) You must set either filename or pix.
  *      (1) Given an image file and optionally a pix raster of that data,
  *          this provides a CID that is compatible with PDF, preferably
  *          without transcoding.
  *      (2) The pix is included for efficiency, in case transcoding
  *          is required and the pix is available to the caller.
+ *      (3) We don't try to open files named "stdin" or "-" for Tesseract
+ *          compatibility reasons. We may remove this restriction
+ *          in the future.
  * </pre>
  */
 l_int32
@@ -526,24 +530,29 @@
     if (!pcid)
         return ERROR_INT("&cid not defined", procName, 1);
     *pcid = NULL;
-    if (!fname)
-        return ERROR_INT("fname not defined", procName, 1);
+    if (!fname && !pix)
+        return ERROR_INT("fname and pix not defined", procName, 1);
 
-    findFileFormat(fname, &format);
-    if (format == IFF_UNKNOWN)
-        L_WARNING("file %s format is unknown\n", procName, fname);
-    if (format == IFF_PS || format == IFF_LPDF) {
-        L_ERROR("file %s is unsupported format %d\n", procName, fname, format);
-        return 1;
+    if (fname && strcmp(fname, "-") != 0 && strcmp(fname, "stdin") != 0) {
+        findFileFormat(fname, &format);
+        if (format == IFF_UNKNOWN)
+          L_WARNING("file %s format is unknown\n", procName, fname);
+        if (format == IFF_PS || format == IFF_LPDF) {
+          L_ERROR("file %s is unsupported format %d\n",
+                  procName, fname, format);
+          return 1;
+        }
+        if (format == IFF_JFIF_JPEG) {
+          cid = l_generateJpegData(fname, 0);
+        } else if (format == IFF_JP2) {
+          cid = l_generateJp2kData(fname);
+        } else if (format == IFF_PNG) {
+          cid = l_generateFlateDataPdf(fname, pix);
+        }
+
     }
 
-    if (format == IFF_JFIF_JPEG) {
-        cid = l_generateJpegData(fname, 0);
-    } else if (format == IFF_JP2) {
-        cid = l_generateJp2kData(fname);
-    } else if (format == IFF_PNG) {  /* use Jeff's special function for png */
-        cid = l_generateFlateDataPdf(fname, pix);
-    } else {  /* any other format ... */
+    if  (!cid) {
         if (!pix)
             pixt = pixRead(fname);
         else
@@ -555,7 +564,7 @@
         pixDestroy(&pixt);
     }
     if (!cid) {
-        L_ERROR("file %s format is %d; unreadable\n", procName, fname, format);
+        L_ERROR("totally kerflummoxed\n", procName);
         return 1;
     }
     *pcid = cid;
``` I didn't realize this until now, but sending image data via stdin will cause image recompression and potentially generational loss. What happens exactly will depend on the file format, but just wanted to raise awareness.

`cat foo.jpg | tesseract - - pdf`

Whereas using filename will not.

`tesseract foo.jpg - pdf`

`echo foo.jpg | tesseract - - pdf`

 > +    if (fname && strcmp(fname, "-") != 0 && strcmp(fname, "stdin") != 0) {

I'd not add filename handling to Leptonica, but do that on the caller side. The caller then has to pass NULL if needed. That would introduce a dependency on Lepntonica HEAD. (NULL will error out in Leptonical 1.74). Let's do this as a 4 step dance. 

(1) Hack "stdin" along with NULL filename support into Leptonica as written above.
(2) Wait a long long time for next Leptonica to release and get everywhere
(3) Switch Tesseract to NULL
(4) Remove hack from Leptonica Leptonica fix is in; Dan will be uploading to github shortly. Very similar to above except a small tweak to not use variable `cid` uninitialized.  Keeping the old enum entries for Cube is not necessarily wrong. If API compatibility is a goal, those old entries must not be reused (but maybe should raise an error message when used from the command line). And of course the comments for the Cube entries also need an update.

Here is a more complete list of files which still contain text / code related to Cube:

    ChangeLog
    ccmain/docqual.cpp
    ccmain/fixspace.cpp
    ccstruct/publictypes.h
    ccstruct/ratngs.h
    ccutil/tessdatamanager.h
    ccutil/unicharset.cpp
    dict/dict.h
    training/tesstrain_utils.sh
    training/text2image.cpp
  \+ Remove support for VS2010.
 No. Not out of the box.
One needs fixing some bugs in tiff library that comes from cppan.
Or there's always manual way of including dependencies. In this case VS2010 might work.

With cppan VS2015 and VS2017 are only supported. VS2010 has [limited support for C++11](https://msdn.microsoft.com/en-us/library/hh567368.aspx), so there should be more problems . I would expect that situation with VS2010 Express (free version of VS2010) is even worse.
  Please create a PR.

On 18-Aug-2017 2:52 PM, "Domingo Alvarez Duarte" <notifications@github.com>
wrote:

> Thanks for pointing out !
> I dived on tesseract source code and found an almost solution to the
> preserve_interword_spaces problem, it seems that when transferring the
> words the spaces were not transfered see patch bellow.
> With this patch the output is almost identical with the 3.05 version
> except for the missing spaces for the first column (need more research to
> see where the first/second word is transfered and why the spaces/blanks are
> not).
>
> @@ -1329,11 +1329,11 @@ void PAGE_RES_IT::ReplaceCurrentWord(
>    WERD_RES* input_word = word();
>    // Set the BOL/EOL flags on the words from the input word.
>    if (input_word->word->flag(W_BOL)) {
>      (*words)[0]->word->set_flag(W_BOL, true);
>    } else {
> -    (*words)[0]->word->set_blanks(1);
> +    (*words)[0]->word->set_blanks(input_word->word->space());
>    }
>    words->back()->word->set_flag(W_EOL, input_word->word->flag(W_EOL));
>
>    // Move the blobs from the input word to the new set of words.
>    // If the input word_res is a combination, then the replacements will also be
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/781#issuecomment-323304593>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o4sRtuKQml61AmRBaijFs5XDubIuks5sZVe9gaJpZM4MmXJm>
> .
>
 Checked with the proposed PR.

[toc-eng.txt](https://github.com/tesseract-ocr/tesseract/files/1292209/toc-eng.txt)
[toc-eng-space.txt](https://github.com/tesseract-ocr/tesseract/files/1292208/toc-eng-space.txt)
![toc](https://user-images.githubusercontent.com/5095331/30270531-835fa0c4-970a-11e7-8403-b3b21a217680.png)

Spaces are preserved now when using tesseract with `--oem 1 --psm 6 -l best/eng -c preserve_interword_spaces=1`

Here is the output:

```
1 First chapter                                   3
1.1 Section One                                 3
1.2 Section Two                                   3
1.3 Section Three                                  3

2 Last chapter                                     5
2.1 Section One                                 5
22 Section Two                                   5
2.3 Section Three                                  5
``` The fix was applied in https://github.com/tesseract-ocr/tesseract/commit/e62e8f5f802c0d8f3dd67da993327cdafaee9763

Build the new version and check. @zdenop You can close this. Thanks!  Did you run `./autogen.sh` _after_ the installation of `autoconf-archive`?  Please don't post problems for which any search engine will give you the answer. See #606, #628, #647, #701 for example. And read the [documentation](https://github.com/tesseract-ocr/tesseract/blob/master/INSTALL.GIT.md).  Use tesseract user forum for asking support. 
When installing for source you have to remove (uninstall) previous version (this is valid not only for tesseract).  So you have installed both 3.04 (maybe from your Linux distribution) and 3.05 (built in the steps above). Do you need both, or can you remove 3.04?  I also noticed that the new LSTM recognizer in Tesseract 4 tries to detect characters even in very small elements of the image. In our case, a dot was "recognized" as a P, and indeed it resembled that character at a very high zoom level. Maybe @theraysmith can better explain that effect.   Done  Box files created by tesseract 4.00.00alpha master branch with `makebox` option cannot be used for LSTM training, as they do not have:

* Tab character to mark end of line
* Space between words Also, `makebox` option creates box files with different box sizes and locations on the same image depending on the OEM mode.

![boxfiletest](https://user-images.githubusercontent.com/5095331/27507096-ccec61e0-58e5-11e7-9686-281955978db6.png)
[boxfiletest-1.box.txt](https://github.com/tesseract-ocr/tesseract/files/1099521/boxfiletest-1.box.txt)
[boxfiletest-0.box.txt](https://github.com/tesseract-ocr/tesseract/files/1099520/boxfiletest-0.box.txt)

 Testing with current code, after new unicharset_extractor, there are additional problems in box files for complex scripts such as Devanagari.

The synthetic tif/box files created by `text2image` create one box for each aksara (conjunct-cluster+combining mark). These are broken into components by the unicharcompressor/recoder.

```
जु 110 4633 154 4679 0
ला 147 4645 205 4679 0
ई 198 4640 235 4694 0
- 233 4656 245 4660 0
से 244 4645 288 4692 0
प्टे 281 4645 318 4692 0
म् 311 4655 341 4678 0
ब 330 4645 366 4678 0
र 357 4645 389 4678 0
  389 4644 406 4691 0
```

However, the box files created by `tesseract` using the `makebox` config file, split the components and create a box for each. This happens both with Devanagari and hin traineddatas from tessdata_best.

```
ज 107 4632 124 4695 0
ु 124 4632 150 4695 0
ल 150 4632 168 4695 0
ा 168 4632 187 4695 0
ई 187 4632 213 4695 0
- 233 4656 241 4661 0
स 241 4656 246 4661 0
े 255 4644 274 4693 0
ष 274 4644 286 4693 0
् 286 4644 297 4693 0
ट 297 4644 309 4693 0
े 309 4644 318 4693 0
म 318 4644 328 4693 0
् 328 4644 344 4693 0
ब 344 4644 358 4693 0
र 358 4644 388 4693 0
```
However, the older 4.0alpha hin.traineddata in tessdata repo has the aksharas, similar to the ones by text2image.

```
जु 107 4632 166 4695 0
ला 166 4632 190 4695 0
ई 190 4632 213 4695 0
- 213 4632 234 4695 0
से 239 4656 246 4661 0
प् 274 4644 297 4693 0
टे 297 4644 323 4693 0
म् 323 4644 344 4693 0
ब 344 4644 358 4693 0
र 358 4644 382 4693 0
```
@ @ The `tesseract` `makebox` created box files for Devanagari script get the following errors related to normalization regarding combiner marks:

```
=== Phase UP: Generating unicharset and unichar properties files ===
[Mon Oct 16 17:35:49 DST 2017] /usr/local/bin/unicharset_extractor --output_unicharset /tmp/tmp.fN2Jr9NHXJ/bih/bih.unicharset --norm_mode 2 /tmp/tmp.fN2Jr9NHXJ/bih/bih.m
akebox.exp0.box /tmp/tmp.fN2Jr9NHXJ/bih/bih.Siddhanta.exp0.box
Extracting unicharset from box file /tmp/tmp.fN2Jr9NHXJ/bih/bih.makebox.exp0.box
Word started with a combiner:0x941
Normalization failed for string 'ु'
Word started with a combiner:0x93e
Normalization failed for string 'ा'
Word started with a combiner:0x947
Normalization failed for string 'े'
Word started with a combiner:0x94d
Normalization failed for string '्'
```

So, some change needs to be made where the box file is being written that it combines the consonant clusters and combining marks and then creates the boxes.

Possibly this will also happen for other complex scripts. 
  Please use tesseract user forum for asking support/questions.  Please use tesseract user forum for asking questions/support  While running the training for `frk` with a longer training text, I get [assertions in stringrenderer.cpp](https://github.com/tesseract-ocr/tesseract/blob/master/training/stringrenderer.cpp#L553) for 5 of 12 fonts. They can be reproduced by running `text2image` for that text with a single language:

    $ text2image --fonts_dir=/usr/share/fonts --font="Proclamate Light, Light" --text=../langdata/frk/frk.training_text --outputbase=/tmp/frk
    Stripped 157 unrenderable words
    Rendered page 0 to file /tmp/frk.tif
    # ...
    Rendered page 1163 to file /tmp/frk.tif
    Stripped 57 unrenderable words
    cluster_text.size() == start_byte_to_box.size():Error:Assert failed:in file ../training/stringrenderer.cpp, line 553

 Yes, thanks. I fixed it in my original post.  Please use tesseract user forum for asking questions  ​you can add per+eng as language parameter  ​
 @Shreeshrii accuracy in persian and arabic language is poor yet
but its really better then 3.02 it seems per is better for 3.02 a and fas better for 4​
 ​per is a seprated project on github

also i checked now and
fas+eng returned some cropped data​...
 @theraysmith Is there a `Persian.traineddata` which handles Persian and English together? @theraysmith

Please inclufe a Persian script based traineddata which has fas and eng in
your next training.



On 11-Aug-2017 2:00 PM, "peiman F" <notifications@github.com> wrote:

> @amitdo <https://github.com/amitdo> no,i checked
> the Arabic train data cant detect the symbols that is included in Persian
> and not in Arabic
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/762#issuecomment-321757389>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o1GBn-sysVkGYv6My3NSCU8ZmTkBks5sXBExgaJpZM4McLHL>
> .
>
   @voyageur: How do you build tesseract on windows? AFAIK autotools (should) do the same jobs regardless platform.... if libtiff is needed only for windows build than it should be fixed on correct place - I did it in f30cac479d1e1f857528da57ba82977b830db87a  Please use tesseract user forum for asking support. Make sure you read relevant wiki first.  Running lstmtraining for frk language with 50000 iterations terminated with an assertion.

    $ lstmtraining -U /home/stweil/src/github/tesseract-ocr/tesseract/frk/train/frk.unicharset --script_dir ~/src/github/tesseract-ocr/langdata --net_spec '[1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c105]' --model_output /home/stweil/src/github/tesseract-ocr/tesseract/frk/output/base --train_listfile /home/stweil/src/github/tesseract-ocr/tesseract/frk/train/frk.training_files.txt --eval_listfile /home/stweil/src/github/tesseract-ocr/tesseract/frk/train/frk.training_files.txt --max_iterations 50000
    ...
    At iteration 15778/49900/49900, Mean rms=0.37%, delta=0.112%, char train=0.381%, word train=1.506%, skip ratio=0%,  wrote checkpoint.
    
    At iteration 15788/50000/50000, Mean rms=0.363%, delta=0.104%, char train=0.346%, word train=1.387%, skip ratio=0%,  wrote checkpoint.
    
    Finished! Error rate = 0.26
    num_docs > 0:Error:Assert failed:in file ../../../../ccstruct/imagedata.cpp, line 648

I used latest Tesseract sources, a slightly modified font list and a longer training text for frk training.
A previous run with 10000 iterations and nearly the same conditions did not raise the assertion:

    ...
    2 Percent improvement time=807, best error was 3.911 @ 8211
    At iteration 9018/10000/10000, Mean rms=0.835%, delta=0.465%, char train=1.729%, word train=6.095%, skip ratio=0%,  New best char error = 1.729Deserialize failed wrote best model:/home/stweil/src/github/tesseract-ocr/tesseract/tutorial/frkoutput/base1.729_9018.lstm wrote checkpoint.
    
    Finished! Error rate = 1.729
 The training machine has 23 GiB RAM plus 23 GiB swap, and about 35 GiB of that memory are available for the training. Maybe some Debian GNU Linux defaults set a smaller limit for single processes, but I don't think we have a memory problem. According to [font_properties](https://github.com/tesseract-ocr/langdata/blob/master/font_properties), Ray used about 6000 fonts. I used 12 fonts. The training result was pretty good for the old engine and unusable for LSTM. A server which wants to process [700000 pages](http://digi.bib.uni-mannheim.de/import/Reichsanzeiger/ocr/film/001-1879/) of a journal printed in fraktur. > I have found that the error goes away when NOT using --eval_listfile, please try without the following ...

Yes, the assertion does not occur when I omit `--eval_listfile`.
 @Shreeshrii, that's a nice collection of Fraktur fonts, but several of the image not even include all normal ASCII characters. All images are missing the long s character (ſ) which is very important for all Fraktur texts. Also missing are all forms of ligatures (combinations of certain characters, like for example ffi, which need a special rendering). Did you see the new [page about fonts](https://github.com/tesseract-ocr/tesseract/wiki/Fonts) which I added to the wiki? Maybe you want to add information there. Many thanks, that's a really very useful document which might allow us to find the exact list of Fraktur fonts used for the German newspaper editions printed from 1900 up to 1945. @stweil I got the same error now. Though the same files and commands worked before and after.

```
Warning: LSTMTrainer deserialized an LSTMRecognizer!
2 Percent improvement time=1100, best error was 100 @ 0
At iteration 1100/1100/1100, Mean rms=0.821%, delta=44.564%, char train=99.966%, word train=100%, skip ratio=0%,  New best char error = 99.966 wrote checkpoint.
Finished! Error rate = 99.966
num_docs > 0:Error:Assert failed:in file imagedata.cpp, line 650
./4runtesseract.sh: line 16:  5559 Segmentation fault      (core dumped) lstmtraining --script_dir ./tess4training-save -U ./tess4training-save/bih.unicharset --continue_from ./tess4training-save/bih.lstm --train_listfile ./tess4training-save/bih.training_files.txt --eval_listfile ./tess4training-save/bih.eval_files.txt --model_output ./tess4training-save/bihlayer --append_index 5 --net_spec '[Lfx384 O1c105]' --debug_interval 0 --perfect_sample_delay 19 --max_iterations 1000
```
Ref: https://travis-ci.org/Shreeshrii/tess4train/builds/249914589 It would be expected to get such a low error rate on your training set, but
has it overfitted? How does it do on different test data?

On Tue, Aug 1, 2017 at 6:13 AM, hanikh <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/shreeshrii> I am trying to fine-tune
> tesseract for Arabic and Persian. I have used 4000 text lines and about 40
> fonts. and I set the max-error-rate=0.001. the error rate of 0.002 has been
> recorded. but after finishing of the training process I got error-rate=0!
> Is it reasonable?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/757#issuecomment-319365858>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056TlrhrROzIm6VOXVoiHjygnInOUGks5sTyRvgaJpZM4Ma6ed>
> .
>



-- 
Ray.
  The [original image](https://digi.bib.uni-mannheim.de/~stweil/tesseract/0604.jp2) in JPEG 2000 format includes two pages from a newspaper. This image is processed correctly by latest Tesseract. Tesseract fails with the same image in TIFF, JPEG or [PNG](https://digi.bib.uni-mannheim.de/~stweil/tesseract/0604.png) format and reports two empty pages.

This happens also with older versions of Tesseract. checking... Quick side note. It's good to see that there is resolution metadata in the JP2. Remember to carry that over to other formats during conversion. It did not make it to the PNG file.

```
$ jhove ~/Downloads/0604.jp2  | grep -i sampling
      SamplingFrequencyUnit: centimeter
      XSamplingFrequency: 118.11
      YSamplingFrequency: 118.11
``` Tesseract is able to find text when resolution metadata is properly set. Result is 54 megabytes, so a little too big to attach. But it works and you should be able to reproduce.

```
$ mogrify -density 300x300 -units PixelsPerInch 0604.png
$ tesseract -l ger 0604.png 0604 pdf
```

 Do you think that Tesseract could handle missing resolution information in a more user friendly way? I created the test images using `convert 0604.jp2 0604.png` (or similar for other formats). I could imagine Tesseract trying 300 dpi in addition to the 70 dpi which it claims to use:

    tesseract 0604.png /tmp/0604-png
    Info in bmfCreate: Generating pixa of bitmap fonts from string
    Tesseract Open Source OCR Engine v4.00.00alpha-332-g4c5d0b5 with Leptonica
    Warning. Invalid resolution 0 dpi. Using 70 instead.
    Empty page!!
    Empty page!!

Does 70 dpi as default value make sense at all? And why does the resolution matter? Will Tesseract detect only characters of a certain size? Maybe 70 was chosen because it was screen resolution back when dinosaurs walked the earth, and Tesseract was first written? Why does resolution matter? I'm guessing there are complicated heuristics somewhere in the code that tries to guess at likely font sizes. For example, if I crop out a small piece of the newspaper and set to 0 dpi, we get results. Sounds like investigation is needed. Or we can ask Ray.

PS. Irrespective of this bug, try to use good hygiene with resolution metadata. Maybe some day later you'll want to know what size the fonts are. Or something where you might regret losing the resolution metadata. I've seen it happen far too many times.

```
$ tesseract -l ger_old /tmp/foo.png -
Warning. Invalid resolution 0 dpi. Using 70 instead.
Magdeburg. [55996]

In das iit heute
bei der _ unter RNr. 151 verzeichneten
Fort-
fchritt, eingetragene
mit befohräufter Heofipflicht' in Dl.
venftedt eingetragen worden: Die Ge-
nofenfhaft ift durd BVefhluf der Ge-
neralverfammlung vom 16. Uuguft 1920
aufgelöft. Anuguft Üterwedde und Leo
Krötfi, beide in Olvenfiedt, find zu
Liquidatoren bejielt.

Magdeburg, dem 19. AÄuguft 1920.
OVa& IAmtenericht A A
```


![foo](https://cloud.githubusercontent.com/assets/4961958/23814766/a4524000-0599-11e7-8bcb-333ede147b8a.png)

 The resolution is only used by layout analysis.
It sets the threshold size at which to call possible text so ridiculously
small that it can't possibly be text. I.e. it helps to distinguish text
from noise.
There is also some auto scaling somewhere in the preprocessing to magnify
low resolution text that is not needed by the LSTM engine, but is needed by
the legacy engine.

On Sun, Apr 23, 2017 at 6:53 AM, Stefan Weil <notifications@github.com>
wrote:

> Maybe. It is not clear why the dpi information is needed at all. I can
> read text of any dpi (just have to adapt the reading distance or get some
> glasses) without knowing the actual dpi value, and ideally OCR software can
> do that, too.
>
> If the dpi value is important, we need an option to set it for images
> without (or with wrong) resolution metadata.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/756#issuecomment-296444866>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056e75bpdwBby3WvUvTDgGbwjSMLBnks5ry1fjgaJpZM4MZ1WT>
> .
>



-- 
Ray.
 Sounds like implementation is disagreeing with intention. Where's the layout analysis resolution code? At the time that 70 minimum was set, it was a question of how to cover the most probable case.
Back in the day when most inputs came from a flatbed scanner, the resolution was provided.
Most images that did not have a resolution were screenshots at ~70ppi. In theory processing a 300ppi image at 70 should be less damaging to accuracy than processing a 300ppi image at 70, but that seems not the case in the original post. It would be worth taking a look at why that happens. There might be an easy fix.
Incidentally, most monitors today still give you not much more than 70ppi, (maybe 150) but they give you a bigger screen with even more small text on it. Only phones manage ~300ppi and maybe my new laptop, which has more pixels than my 24" monitors in less than half the area.

Now, when a lot of images come from camera phones, the resolution is largely unknown, and layout analysis requires some more work.

Incidentally, there is an easy way in to set resolution. Set it in the Pix before passing it to TessBaseAPI. I now have a reasonably general fix for the resolution issue.

There are multiple unsolved problems with the original 0604 image though:
There are large gaps between words, but tiny gaps between columns. That was
causing column finding to fail, causing the blank page determination. The
problem is that it sees the large gaps between words, which at 70 ppi look
huge, and decides that it shouldn't merge them into textlines. Although
that should be fixed, it is a highly dangerous thing to try without very
careful testing.
The columns aren't straight. The layout analysis is fundamentally broken in
such cases. It can't cut a straight line (even at an angle) through the
very narrow bent gap between columns.

A general fix for resolution is to estimate the resolution based on the
measured body text size, which is available before the column finder is
constructed. That makes for an easy fix.
On the original 0604 image, it estimates the resolution to be 470 ppi but
still generates a poor layout analysis, due to the above problems.

On Tue, Apr 25, 2017 at 5:20 AM, Amit D. <notifications@github.com> wrote:

> https://github.com/tesseract-ocr/tesseract/search?q=resolution
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/756#issuecomment-297012426>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056WiqW85XlvkQ5YbrmK2x46GsQvNEks5rzeUIgaJpZM4MZ1WT>
> .
>



-- 
Ray.
  LSTM training takes a lot of time and has no well defined duration. Therefore saving intermediate results (with a configurable frequency) is a good thing. It allows tests based on those intermediate results, and those results can also be used to resume the learning process if it was interrupted for whatever reason. Thanks @stweil .  Maybe add them to https://github.com/tesseract-ocr/tesseract/wiki/Data-Files?  This fixes several compiler warnings. > The whole 'classify' directory will most likely be removed by Ray (it is part of the old engine). There is no point in applying any change to files under this directory.

I disagree. Maybe that directory will be removed in the future. That's not a good reason why unused code should not be removed now. Maybe we could support a Tesseract 4 with both old and new recognizer engine at least for the next year (thus eliminating the need to support Tesseract 3 for a longer time span). I'd appreciate that scenario, but if we prevent any code maintenance of the old engine in Tesseract 4, we'll never know whether that might be possible.

See also #744 which I'd apply for the same reason. My code for big endian support (#703) also changes both recognizers. I don't. As far as I have understood Ray, he wants a Tesseract which works really good. LSTM in Tesseract 4 is a large step forward. Nevertheless, there is obviously still some need for the old engine until we can be sure that LSTM outperforms it in all OCR applications (see issue #707). Based on my experience I'd try to keep both engines for some time to allow easy verification of the LSTM performance. In issue #518, Ray said that he wants to remove the old engine, but is open for a discussion based on facts, and he also said what would have to be done if the old engine were kept. I don't know.
The issue is currently in cppan. I've just found it, probably will fix it tomorrow or till Monday. IMO removing unused function from directory, that _should be removed_, is not big issue. OK, I only skimmed this to get the gist.
Yes I'm open to discussion on the future of the legacy engine in 4.00 and beyond, but my aim is to prove to the community that it can be safely removed, so my favorite kind of discussion is "it doesn't work well for this image" with example.
I'm not against removal of unused code from the dead code.
What I'm not keen on is major edits to the dead code that don't remove dead code.

I have a commit coming (next week?) that fulfills a long-standing request - to be able to load from a trainneddata file in memory (or via a file-reader function pointer). This involves a major edit to the dead code, but I had to do it to keep Android portability.
This will also showcase my clean and simple fix to the endian issue that Stefan raised.
I haven't yet done the endian fix to the LSTM code, but it is *easy* now.  @theraysmith Are there plans to support this for LSTM? In response to https://groups.google.com/forum/#!topic/tesseract-ocr/-oeCTcojYfw

You can try the plus-minus type of training if you just want a digits type of traineddata.

Your training_text can contain numbers in the format you need and you can train with a font matching your images.

For proof of concept you can try my experimental version at 

https://github.com/Shreeshrii/tessdata_shreetest  That's a rather lengthy commit messages, and it is not so easy for me to get the essentials from it. The old code works, but throws a nasty and confusing warning on systems which provice `glibtoolize` instead of `libtoolize`. This is fixed by your pull request. Re-opened to re-check CI (win). By the way: it's `autogen.sh`, not `autopen.sh`. Thank you for the updates. I have no strong opinion regarding the lengthy commit message – the code changes are the important point, and a long commit message is better than a too short one. And whoever (@zdenop, @egorpugin) pulls the PR can squash the commits when doing so. Did you check 3.05? What is missing there? @RandomDSdevel : I tried to backport as much as I recognize. Unfortunately I do not have a lot of time and there could be thing I overlook. I appreciate if somebody does checks afterwards.  which tesseract version (revision) you use? Please submit config.log and output of this commnad (onfigure.log):
`./configure --prefix=/usr 2>& | tee configure.log`  You posted it already to forum. Read doc before asking help.  Both functions simply call malloc, free.

Remove also unneeded null pointer checks and use calloc where possible.

Signed-off-by: Stefan Weil <sw@weilnetz.de> @amitdo, do you think that the PR should not be applied because it changes code which might be removed later? @amitdo, a fair assessment.
Although I haven't made any major changes to the codebase in the last few weeks, yes I would still like to remove the old classifier and take out a lot of code with it.

I'm going to review the replies to my request for "old better than new", and thanks to those that provided them, with a view to making new better than old on those problems. I haven't got to that yet, as I have been totally occupied by fixing many problems I have found with the synthetic training data generation pipeline. Since training takes about 2 weeks, fixes to the source data get priority treatment over other code changes.

Yes, each commit gets reviewed by me *and* someone else at Google.  Weird. Let's get rid of that limit. https://github.com/DanBloomberg/leptonica/commit/fd65f6b374f4e63ee55ff90a8524bee4a4381b18

Same change needed in opencl/openclwrapper.cpp (alternative: kill OpenCL/TIFF entirely) @bstace Are you getting any benefit from the OpenCL? Is it faster? How much faster?  Could you squash or rebase or do whatever to get a single commit with your change?  Tesseract does not reference any libtiff symbols. I don't understand this at all.

$ find  | xargs grep TiffFdOpen Thanks @amitdo, I stand corrected. All that code is currently unused but you are correct, it is right there. In general I think we may push needed changes to 3.05 branch and tag patch releases (3.05.01, 3.05.02, ...). PR is welcomed.
BTW: At this stage of support of OpenCL I suggest to remove OpenCL from 3.05 and 4.0x  > BTW: At this stage of support of OpenCL I suggest to remove OpenCL from 3.05 and 4.0x

OpenCL worked for me (after I had spent some time on it and contributed several pull requests) at least until end of last year, both with 3.05 and with 4.0x. Depending on the graphic card, it can be a great gain. That is relevant for some OCR projects which would take years on a single CPU.

A test which I just have done with latest Tesseract code was not successful, but I estimate that it can be fixed again. @RandomDSdevel, I don't think that you need this fix to get 3.05 running with Homebrew. The error message caused by the missing `libtoolize` on macOS is confusing, but it's only a cosmetic problem. And if you don't use OpenCL (`--enable-opencl`), building Tesseract should work. There are good reasons why OpenCL is disabled by default. 1. In case of OpenCL, "-ltiff" is added automatically by [configure](https://github.com/tesseract-ocr/tesseract/blob/3.05/configure.ac#L81). So there is no need to add linking to libtiff because of OpenCL (if yes then there is other problem that should be fixed!)
2. I just checked compilation of 3.05 on openSUSE linux and it works without problem/modification. Linking to libtiff is done "automatically" (based on leptonica?): 
```
libtool: link: ranlib .libs/libtesseract_api.a
libtool: link: ( cd ".libs" && rm -f "libtesseract_api.la" && ln -s "../libtesseract_api.la" "libtesseract_api.la" )
/bin/sh ../libtool  --tag=CXX   --mode=link g++  -g -O2 -std=c++11 -version-info 3:5 -no-undefined   -o libtesseract.la -rpath /usr/lib64  libtesseract_api.la ../ccmain/libtesseract_main.la ../textord/libtesseract_textord.la ../wordrec/libtesseract_wordrec.la ../classify/libtesseract_classify.la ../dict/libtesseract_dict.la ../ccstruct/libtesseract_ccstruct.la ../cutil/libtesseract_cutil.la ../viewer/libtesseract_viewer.la ../ccutil/libtesseract_ccutil.la ../opencl/libtesseract_opencl.la ../cube/libtesseract_cube.la ../neural_networks/runtime/libtesseract_neural.la -llept -lpthread 
libtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib64/gcc/x86_64-suse-linux/4.8/../../../../lib64/crti.o /usr/lib64/gcc/x86_64-suse-linux/4.8/crtbeginS.o  -Wl,--whole-archive ./.libs/libtesseract_api.a ../ccmain/.libs/libtesseract_main.a ../textord/.libs/libtesseract_textord.a ../wordrec/.libs/libtesseract_wordrec.a ../classify/.libs/libtesseract_classify.a ../dict/.libs/libtesseract_dict.a ../ccstruct/.libs/libtesseract_ccstruct.a ../cutil/.libs/libtesseract_cutil.a ../viewer/.libs/libtesseract_viewer.a ../ccutil/.libs/libtesseract_ccutil.a ../opencl/.libs/libtesseract_opencl.a ../cube/.libs/libtesseract_cube.a ../neural_networks/runtime/.libs/libtesseract_neural.a -Wl,--no-whole-archive  -Wl,-rpath -Wl,/usr/lib64 -Wl,-rpath -Wl,/usr/lib64 /usr/lib64/liblept.so -lz -lpng -ljpeg -lgif -ltiff -lwebp -lopenjp2 -lpthread -L/usr/lib64/gcc/x86_64-suse-linux/4.8 -L/usr/lib64/gcc/x86_64-suse-linux/4.8/../../../../lib64 -L/lib/../lib64 -L/usr/lib/../lib64 -L/usr/lib64/gcc/x86_64-suse-linux/4.8/../../../../x86_64-suse-linux/lib -L/usr/lib64/gcc/x86_64-suse-linux/4.8/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib64/gcc/x86_64-suse-linux/4.8/crtendS.o /usr/lib64/gcc/x86_64-suse-linux/4.8/../../../../lib64/crtn.o  -O2   -Wl,-soname -Wl,libtesseract.so.3 -o .libs/libtesseract.so.3.0.5
```
So I guess there should be some other problem... @mkszuba: Did you compile leptonica with libtiff support?  Please use tesseract user forum for asking questions  LSTM training process has been changed. Hence closing this issue.  Please use tesseract user forum to ask questions.  - enable to set up producer property in Info dict. 1. What is the reason for this change?  Shouldn't Tesseract get credit for its PDF output?
2. As written, this creates a new security vulnerability. See issue #636.  Ok, I understand. Please reject this PR. > If someone embeds libtesseract in his his product 'myOwnOCR', he probably prefer that any output will use this name instead of 'Tesseract'...

Exactly, that is my case. I use libtesseract and in"about" of my app is mentioned that's is based on tesseract. I would like to set another producer as "tesseract <version>" Aside from any credit issues, there is also a matter of compatibility. We know that 3.0.4 Tesseract PDF does better with Firefox, and 3.0.5 Tesseract PDF does better with ghostscript. Maybe 3.0.6 will finally do better with Arabic / Hebrew on Adobe Reader. That sort of information gets lost when we override Producer. That said, reasonable people can probably disagree here.

I think the escaping issue is very clear. We don't want to create more opportunities for creating corrupt or malicious PDF files, and therefore issue #636 is a hard requirement.  There is now a fix for issue #636 which demonstrates how to safely set a metadata field. OK, I think you can close/deny this PR.   Try using the best/Latin traineddata

You can use the command

Combine_tessdata -u to unpack the traineddata file and check that the
unicharset has the bullet character.


On 07-Aug-2017 9:36 PM, "yuvarajanS" <notifications@github.com> wrote:

> Hi @Shreeshrii <https://github.com/shreeshrii> ,
> I am looking for a trained data for the bullet character. It should work
> even if we are using mulitple language in a single string.
>
> Can you please provide the trained data for bullet character or guide me
> how to do do this?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/730#issuecomment-320706511>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o4te3XfB8tMMEcnBGB1mOcKR4a88ks5sVzXugaJpZM4MF7F5>
> .
>
 what is the unicode number for bullet character? Please see https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#fine-tuning-for--a-few-characters

and follow instructions there for the bullet character.  Similarly for Nepali - please see https://groups.google.com/forum/#!topic/tesseract-ocr/m2Dx6a-srvo

> I got the same result as yours with hin.traineddata which is better than nep.traineddata. I think the langdata need some revisions

 Ok. Will do.  There should be possibility to produce OCR result without hyphenated words in case of hocr output or in case of paragraph(RIL_PARA)/block(RIL_BLOCK) page iterator level.

Test image:
![paragraph_sk](https://cloud.githubusercontent.com/assets/574156/23105439/8cbce864-f6df-11e6-9759-e7595154381d.png)

Output ( (`tesseract paragraph_sk.png paragraph_sk -l slk hocr`):

> ty, tak to nerob ty sám. Ak si nepraješ, aby sa k tebe zacho- vali tak, ako to ty chceš urobiť druhému, potom či nie je lep- šie, ak to zastavíš? Premýšľaj, ako by si sa ty cítil, keby zverejnili to, čo máš v úmysle teraz o niekom povedať? Nebol by si urazený alebo zranený? Ak áno, tak radšej buď, prosím, ticho.

  Try current code from 3.05 branch (or apply localy changes in https://github.com/tesseract-ocr/tesseract/commit/e85a7e2529416a12e806a8df2e9fdf92f7e39a5f)  No current plans with respect to Tesseract. I think the two best approaches would be

1. Running Tesseract output through a PDF->PDF compressor, to produce JBIG2 PDF. These exist commercially, not aware of an open source implementation.

2. Feed JBIG2 to Tesseract as an input format. This would require teaching Leptonica to decompress JBIG2, and teaching Tesseract to copy over the input JBIG2 over to the output PDF. Downsides include the complexity of dealing with the multipage aspect, and inability to expand this approach towards mixed raster content.

3. Start with JBIG2 PDF without a text layer (somehow). Rasterize to images. Ask tesseract to produce invisible-text-only PDF output. (This is already supported). Merge the two PDFs together. (Open source tools including pdftk can already do this.)

>flate-compression currently used

Tesseract will carry forward CCITT Group 4 compression if handed TIFF G4 input.  Why don't you use zxing which is built specifically for this? OCR is  Optical Character Recognition. Anyway - use tesseract user forum for asking questions.  I am against to show GIT_REV in release mode:

- Experienced users/testers should know what they are doing, what their are testing
- Inexperienced users should use released stable version  There had been some [code improvements](https://github.com/tesseract-ocr/tesseract/commits/3.05) for OpenCL in 3.05. Maybe you want to try that version. I think the OpenCL implementation is at risk in general. The OpenCL TIFF decoder has fallen behind the C implementation and is currently disabled.  There is no OpenCL implementation for the LSTM recognizer in Tesseract 4.x. I'm not sure what performance we expect from OpenCL on the Tesseract 3.x recognizer, but your report is not giving me much confidence.

If I were in charge of OpenCL stuff on Tesseract (and I am definitely not!) I would look at the LSTM recognizer. Specifically the portion that is currently using AVX2 assembly instructions, which is the primary hotspot.
 OpenCL is just experimental feature, so having no effect is possible results.
Please read other issues/tesseract forums about OpenCL. Tesseract tests whether OpenCL is better than the CPU and calculates a score based on weighted timings of several different basic operations.

Here is a typical result on a MacBook Pro:

    [DS] Device: "Iris" (OpenCL) evaluation...
    [DS] Device: "Iris" (OpenCL) evaluated
    [DS]          composeRGBPixel: 0.009361 (w=1.2)
    [DS]            HistogramRect: 0.167102 (w=2.4)
    [DS]       ThresholdRectToPix: 0.004588 (w=4.5)
    [DS]        getLineMasksMorph: 0.015459 (w=5.0)
    [DS]                    Score: 0.510220

    [DS] Device: "(null)" (Native) evaluation...
    [DS] Device: "(null)" (Native) evaluated
    [DS]          composeRGBPixel: 0.022881 (w=1.2)
    [DS]            HistogramRect: 0.074672 (w=2.4)
    [DS]       ThresholdRectToPix: 0.042662 (w=4.5)
    [DS]        getLineMasksMorph: 0.140875 (w=5.0)
    [DS]                    Score: 1.103025

The CPU is faster for `HistogramRect` and slower for all other operations. The weighted score favors OpenCL. If `HistogramRect` is used very often, it would be better to use the CPU. This is what I observe for a larger image.

Instead of using a weighted score, Tesseract could always use the faster option. I expect that this potential mix of CPU and OpenCL would give the shortest execution time.  Please use tesseract use forum for askiny question. Please read wiki first.  
[test.pdf](https://github.com/tesseract-ocr/tesseract/files/770565/test.pdf)
![test](https://cloud.githubusercontent.com/assets/25739284/22877715/9d091ece-f1ce-11e6-867c-dd7fe106ec43.png)

[test.hocr.txt](https://github.com/tesseract-ocr/tesseract/files/770570/test.hocr.txt)


Hi

In the attached hocr you can search for "bbox 0 0" and see that there are multiple occurrences of ocrx_word artifacts where the bbox coordinates are the same as those of the ocr_page artifact.

These ocrx_word occurrences seem to be occurring in relation to vertical and horizontal lines in the image.

If you search for "Party" in the pdf, you will see that the bbox for the last two instances goes out to the end of the underlining, despite the fact that the text has been correctly identified as "Party A" and "Party B"

The image was redacted using Paint and Windows clipboard, but despite any damage I have inflicted on the file, the text is still correctly identified.
Whatever the state of the image, it can't be correct for an ocrx_word to have the same coordinates as that of the ocr_page.


I downloaded the Windows Installer version from UB Mannheim on 18/1/17 (the current version doesn't run on my system!):

tesseract 4.00.00alpha
 leptonica-1.73
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.6.20 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.3 : libopenjp2 2.1.0

Windows 10
Version	10.0.14393 Build 14393
  
The command I'm running is:
"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" -oem 4 -psm 6 -c tessedit_create_hocr=1 -c tessedit_create_pdf=1 test.png test


I've turned the auto psm off, since it seems to lose the right-hand column of tables completely, and I'd rather carry out my own psm.

OEM 4 is just amazing. Great work!!


Major B
 Ok. Looks like I need to wait for a working build of the latest version (I'm a java-restricted etl/sql developer).

If I use the latest UB Mannheim build with:

"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" -oem 1 -psm 3 -c tessedit_create_hocr=1 -c tessedit_create_pdf=1 test.png test

I get:

read_params_file: parameter not found: ëPNG


And if I try:

"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" test.png test

I get:

Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
DotProductAVX can't be used on Android

And the exe bombs out. I think this is a known issue, and I just need to wait.

Thanks "C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" test.png test --oem 1 --psm 3 -c tessedit_create_hocr=1 -c tessedit_create_pdf=1
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
ObjectCache(01210A88)::~ObjectCache(): WARNING! LEAK! object 05981790 still has count 1 (id C:\Program Files (x86)\Tesseract-OCR/tessdata/eng.traineddatalstm-punc-dawg)
ObjectCache(01210A88)::~ObjectCache(): WARNING! LEAK! object 05963128 still has count 1 (id C:\Program Files (x86)\Tesseract-OCR/tessdata/eng.traineddatalstm-word-dawg)
ObjectCache(01210A88)::~ObjectCache(): WARNING! LEAK! object 059631D8 still has count 1 (id C:\Program Files (x86)\Tesseract-OCR/tessdata/eng.traineddatalstm-number-dawg)

I think we're flogging a dead horse with this build.

I'll have a go at doing a java build tonight.

Thanks for your assistance.
Major B It's not java, is it? Doh! 
Whatever, I'll try to build from source tonight.
Cheers. @Shreeshrii, the output which you got is not from our [UB Mannheim](https://github.com/UB-Mannheim/tesseract/wiki) build (dated 2017-02-02). I assume that binary was build with `cmake` (which still is buggy for 32 bit Windows).
@wadex1, all builds with `configure` should work with Windows. I just repeated the test with 32 bit Tesseract on 64 bit Windows, and it works well. > the output which you got is not from our UB Mannheim build

I now see what is different: I tested `tesseract --version` while you accidentally called `tesseract -- version` (note the blank between `--` and `version`). Hi

I see there is a new UB Mannheim version (that works!). Thank you.

I still get one instance of "bbox 0 0 2496 3457" (ie page size) on an ocrx_word item. 
(see attached)


[test.hocr.txt](https://github.com/tesseract-ocr/tesseract/files/780304/test.hocr.txt)

Regards Lots of examples in this one. 
[test1.hocr.txt](https://github.com/tesseract-ocr/tesseract/files/780337/test1.hocr.txt)
![test1](https://cloud.githubusercontent.com/assets/25739284/23024243/332fed4a-f451-11e6-8e18-87d61fb5342c.png)

 Interestingly, they are all line segments interpreted as "I" with high word confidence! My previous tests on 64 bit Windows were invalid, because my computer obviously uses an Intel CPU without AVX 2.1 support. All my previous installers include indeed a tesseract.exe which fails with an AVX 2.1 capable CPU (Haswell or newer?). This is fixed in a new installer which I just finished. ![capture](https://cloud.githubusercontent.com/assets/25739284/23043204/7a309cde-f493-11e6-8d27-d08e90712f57.JPG)

It's not "I". It's pipes, underscores and hyphens.  Feedback for best/traineddata is now in tessdata repo.  You could create a PR with these changes. :) Thinking about his, I have never had an easy time doing a new Tesseract release for Debian. Maybe shipping a new version right at the cutoff date is not such a smart idea.

https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=794489
https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=816857
https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=815056
https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=815860
https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=815970
 Done: https://github.com/tesseract-ocr/tesseract/releases/tag/3.05.00 Being super cautious, I am comparing symbols from libtesseract.so.3.0.4 and libtesseract.so.3.0.5. Here are symbols that disappeared in 3.0.5.

```
-_Z14WriteParamDescP8_IO_FILEtP10PARAM_DESC@Base
-_Z9read_listPKc@Base
-_ZN16GENERIC_2D_ARRAYIN9tesseract17TrainingSampleSet13FontClassInfoEE6ResizeEiiRKS2_@Base
-_ZN8WERD_RES19FakeWordFromRatingsEv@Base
-_ZN9tesseract11ObjectCacheINS_4DawgEEC1Ev@Base
-_ZN9tesseract11ObjectCacheINS_4DawgEEC2Ev@Base
-_ZN9tesseract13DocumentCache13LoadDocumentsERK13GenericVectorI6STRINGEPKcPFbRKS2_PS1_IcEE@Base
-_ZN9tesseract13DocumentCache15GetPageBySerialEi@Base
-_ZN9tesseract17ViterbiStateEntryD1Ev@Base
-_ZN9tesseract17ViterbiStateEntryD2Ev@Base
-_ZN9tesseract18DawgPositionVectorD1Ev@Base
-_ZN9tesseract18DawgPositionVectorD2Ev@Base
-_ZN9tesseract4Dict4LoadEPNS_9DawgCacheE@Base
-_ZNK9tesseract4Dict19ProcessPatternEdgesEPKNS_4DawgERKNS_12DawgPositionEibPNS_18DawgPositionVectorEP12PermuterType@Base
-_ZNK9tesseract9ImageData8PreScaleEiPP3PixPiS4_P13GenericVectorI4TBOXE@Base
```

[3.0.4.symbols.amd64.txt](https://github.com/tesseract-ocr/tesseract/files/784668/3.0.4.symbols.amd64.txt)
[3.0.5.symbols.amd64.txt](https://github.com/tesseract-ocr/tesseract/files/784670/3.0.5.symbols.amd64.txt) Now I want to test against gimagereader, but can't from my chroot jail. It fails on both `3.0.4` and `3.0.5`

```
$ /usr/bin/gimagereader-gtk
terminate called after throwing an instance of 'std::logic_error'
  what():  basic_string::_M_construct null not valid
Aborted (core dumped)
``` This is the release candidate for 3.0.5 for Debian. I'm going to do a compatibility check with the gimagereader package maintainer. Others are also very welcome to test if they are set up for it.

[tesseract-3.0.5-candidate.zip](https://github.com/tesseract-ocr/tesseract/files/784689/tesseract-3.0.5-candidate.zip)
 EDITED 

Okay, I got gimagereader working for 3.0.4 in the Debian Sid chroot jail.

https://help.ubuntu.com/community/BasicChroot#Accessing_graphical_applications_inside_the_chroot

However, it crashes during recognition on 3.0.5.  This is automatic stop-ship with respect to Debian.

[crashlog.txt](https://github.com/tesseract-ocr/tesseract/files/784709/crashlog.txt)
 I'd like to figure things out such that gimagereader doesn't need to be rebuilt. Upstream was hoping 3.0.5 would be application binary interface (ABI) compatible with 3.0.4. Am I reading the crashlog correctly that the unhappy symbol is RecogAllWordsPassN? Because I don't think that has changed. Is there a preferred ABI compatibility checking tool? I ask because the other approach is fixing compatibility and a 3.0.5.1 that does not bump soname. Hi,

I've heard about this ABI tracker. Maybe it's possible to add tesseract (& leptonica) there somehow.
https://lvc.github.io/abi-compliance-checker/
https://abi-laboratory.pro/tracker/
https://abi-laboratory.pro/tracker/timeline/qt/ (qt example) Is there anything we can do (in tesseract project) to fix this issue?  Terrific, we want that. Thanks.  As I think you know, Ken was already instrumental in our most recent invisible font iteration. Can you confirm that the problems you are seeing are true with HEAD (either the 3.0.5 or 4.x branch) as opposed to something older like 3.0.4? I want to make sure you are working with our the very latest compatibility tweaks to font metrics. Attaching an example document to this bug doesn't hurt. Thanks, that is very clear. I'm always happy to tweak things on the Tesseract side to improve compatibility, but it does require careful testing. The tool of choice is `ttx` from `fonttools` which can transform the font `pdf.ttf` into an editable XML representation and back. I don't think we had anything missing with respect to font metrics, but you never know. Not sure when I might have time to play with this, but anyone is welcome to try. I'm somewhat hesitant to bother Ken more after all his contributions, but maybe that is just shyness. Chrome uses pdfium, Firefox uses pdf.js. Will take a closer look when I get a chance. Thanks for investigating. Only the null character is used. Here's a control vs. experiment for compatibility testing. I took a quick look at Acroread, Chrome, Firefox, evince on Linux and did not notice a difference. Need testing on all the other popular platforms (including the  mobile PDF viewers) to feel comfortable. I'd also like to know exactly what you did when you said "Search ... seems to be broken."

```diff
--- pdf.ttx.orig	2017-02-10 09:35:03.000000000 -0800
+++ pdf.ttx	2017-02-10 09:25:06.000000000 -0800
@@ -122,7 +122,7 @@
 
   <hmtx>
     <mtx name=".notdef" width="0" lsb="0"/>
-    <mtx name=".null" width="0" lsb="0"/>
+    <mtx name=".null" width="1024" lsb="0"/>
   </hmtx>
 
   <cmap>
```

[control.pdf](https://github.com/tesseract-ocr/tesseract/files/767371/2.pdf)

[experiment.pdf](https://github.com/tesseract-ocr/tesseract/files/767375/2.pdf)

 Can someone please test on iOS? Sorry for not being more clear. I need testing of control.pdf against experiment.pdf on iOS before we can submit the change. Thank you very much. Okay, no known regressions, so let's get that revised font (pdf.ttf) in, snapshot the 3.0.5 branch, and ship to millions of users. 
[pdf.ttf.zip](https://github.com/tesseract-ocr/tesseract/files/772035/pdf.ttf.zip)
 done  We do not support 3rd party solution. Please contact author of your solution or use tesseract user forum.  We do not support 3rd party solution. Please contact author of your solution or use tesseract user forum.  Any variables which are read from a file must use a portable data type
with a well defined size.

Signed-off-by: Stefan Weil <sw@weilnetz.de> This is currently only a theoretical problem, because all relevant hosts which I know use a 32 bit `int` data type. Lets keep it in 3.05 branch...  `+` for dropping (in case of better results of lstm engine) It will support vertical text.
I have an experimental implementation that treats it as an additional
language, but it would be possible to make it depend on the layout analysis
instead.

On Wed, Feb 8, 2017 at 6:18 AM, Atsuyoshi SUZUKI <notifications@github.com>
wrote:

> I cannot agree with removing old ocr engine, until new lstm engine has
> support vertical text.
>
> Of course I know that the new LSTM engine is very good ( in Japanese text
> including English words especially).
> In the meantime, maintaining the old engine provides the option of using
> the old OCR engine only for vertical text.
>
> c.f. #627 <https://github.com/tesseract-ocr/tesseract/issues/627> , #641
> <https://github.com/tesseract-ocr/tesseract/issues/641>
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/707#issuecomment-278340436>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056SgL-wwCYGswOMqxb7FNmr6OIYonks5rac68gaJpZM4L50TV>
> .
>



-- 
Ray.
 If 3.05 should be the last version with legacy OCR Engine (old engine) then there should be possibility to read [OCR result from memory](https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-dev/mZ2IUsvWgbY/2yz-b1cUAgAJ).

Also it would be great if 3.05 and 4.0 version could be installed at the same time (AFAIK there are conflict with tessdata filenames: they are the same but they are not compatible) I would prefer to be as much consistent as possible: e.g. if 3.02 and 3.04 use tessdata also 3.05 should. So 4.0 should start with change... Yes, if later we'll have 5.0 with different data files, they'll use `tesseract5` and this won't break anything.
If we have `tesseract` for 4.0, then it will be renamed to `tesseract4` again, and `tesseract` for 5.0 - that's not good. A simple solution could be using `tessdata/4`, `tessdata/5` and so on for new major versions, so we continue using a `tessdata` directory at the same location as before, but automatically add the major version as the name of a subdirectory. If Tesseract uses semantic versioning in the future, I see no need to add a second number (although that would be possible, resulting in `tesseract/4.0`).

For the program names, we can look for existing examples. I just checked my `/usr/bin/*[0-9]` files and found names like `clang-3.8`, `gcc-6`, `php5`, `php-7.0`, `ruby2.1`. So there is no clear convention whether to separate name and version by a dash or not and whether to use major version only or both major and minor version. With semantic versioning the major version should be sufficient again. I'm thinking of using the same traineddata file format for 4.0, but adding
some new subfiles, including a version string, as has been requested.
The LSTM-only engine would then store the unicharset, recoder and dawgs as
separate traineddata components, also satisfying the need to get at the
unicharset.
With an additional subfile to store the trainer-specific data, it should be
possible use the traineddata file format as a checkpoint format during
training, which gets rid of a layer of complexity.
I had thought of going with a different filename extension, but the
versioned subdir seems like a good idea too.

In any case, we should roll back the existing traineddata files for 3.05.


On Wed, Feb 8, 2017 at 10:54 AM, Stefan Weil <notifications@github.com>
wrote:

> A simple solution could be using tessdata/4, tessdata/5 and so on for new
> major versions, so we continue using a tessdata directory at the same
> location as before, but automatically add the major version as the name of
> a subdirectory. If Tesseract uses semantic versioning in the future, I see
> no need to add a second number (although that would be possible, resulting
> in tesseract/4.0).
>
> For the program names, we can look for existing examples. I just checked
> my /usr/bin/*[0-9] files and found names like clang-3.8, gcc-6, php5,
> php-7.0, ruby2.1. So there is no clear convention whether to separate
> name and version by a dash or not and whether to use major version only or
> both major and minor version. With semantic versioning the major version
> should be sufficient again.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/707#issuecomment-278425371>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056UcVHoxoH9rE_svO5yvu4FrJSrGVks5rag9PgaJpZM4L50TV>
> .
>



-- 
Ray.
 https://wiki.ubuntu.com/ZestyZapus/ReleaseSchedule

Feb 16 is the final deadline for changess to Ubuntu 17.04. I am not comfortable shipping anything from 4.x to these users, but we can consider taking a snapshot of the 3.0.5 branch. It does have some bug and compatibility fixes that are good for users. Regarding training data, I would not ship an update that at all. This would be purely be a code update.

I know the long standing issue has been restoring an API call (last seen in version 3.0.2) to send results to memory instead of file. I respect that idea, but we don't have it, and it's not that easy to add.  I think it is fair to say that it would be impossible before deadline. So the question is, do we ship an update to users this cycle or not. And if so, should I take a snapshot? And if so, what would it be called? 

A few more thoughts that are somewhat related

- I see no reason that this has to be the last ever release on the 3.0.x branch.
- My guess is by the next next release in Oct 2017 that 4.x will be ready for the vast majority of users
- I'm not planning to ship both 3.0.x and 4.x at the same time with Debian/Ubuntu. I think it will be very rare for people to want both, and those who do will be advanced users who can work from source code.


 So there should be changes in 4.0 code so tesseract 4.x and 3.05.x could be installed at the same time Yes, who wants old engine could use 3 series when lstm will be available in 4. I can confirm all problems reported above by @uvius. In addition, some training files currently only exist for 3.x (notably deu_frak) or have a bad quality (deu), so 4.0 does not improve the results for those languages.

I also had an example where a larger part of a page was missing in the output from LSTM while the old recognizer got most of that part correctly, but I am still searching to find that example again. I recently tried to improve the training model for a language (`frk`). That's rather easy and does not need much compute time (~ minutes) or other resources for the old engine. Especially adding more characters which should be recognized is a simple task as soon as the general infrastructure (Tesseract binaries, small number of fonts) is available.

For the new LSTM engine, this is totally different. As far as I know it is not possible to add a missing character to an existing trained LSTM, so new training from scratch is needed. This requires a lot of resources (much more training text, a huge number of fonts, compute time ~days / ~weeks) and cannot be done by most users. Maybe @theraysmith or users who have successfully trained LSTM can provide more detailed numbers.

My conclusion is that most users of the new LSTM will be restricted to the available trained data either from @theraysmith or from third parties. If the old engine is removed, it will no longer be possible to optimize OCR for documents with unusual or rare characters. Calling Tesseract with more than one language can only partially solve such situations. LSTM currently does not work with all languages (see issue #682). That's related to my previous comment: adding (good) LSTM support for a language is much more difficult than for the old engine. Of course the existing languages will be fixed one day, but there still remain more exotic languages which are not covered today, and people won't be able to add them to Tesseract. We could tell users to use Tesseract 3.x for those cases, but would that really save development resources when there is the need to maintain both versions 3 and 4? It seems clear that having two major versions of Tesseract requires more work for Linux distributions. Neither is it a good solution for users who have to install and use both versions and don't know what to do when texts require both versions. I believe I am on a path to make the LSTM engine work with *many*
languages, and possibly unseen languages in the same script.
I agree that training from scratch is much more difficult than for the old
engine, but I think the obtainable accuracy makes it worth leaving the old
engine behind.
I think that the fine tuning and/or replacing just one layer training may
be adequate for adding new fonts or new characters, with a bit more work on
my part.
A big part of my desire to drop the old engine is that it would enable a
much better solution to multi-lang/multi-script and plug-replaceable
language models. While the legacy engine remains in place, there is a lot
of work-around to do to integrate the LSTM engine that does not fit with my
ideas for fixing this problem properly.

On Wed, Mar 15, 2017 at 2:42 AM, Stefan Weil <notifications@github.com>
wrote:

> LSTM currently does not work with all languages (see issue #682
> <https://github.com/tesseract-ocr/tesseract/issues/682>). That's related
> to my previous comment: adding (good) LSTM support for a language is much
> more difficult than for the old engine. Of course the existing languages
> will be fixed one day, but there still remain more exotic languages which
> are not covered today, and people won't be able to add them to Tesseract.
> We could tell users to use Tesseract 3.x for those cases, but would that
> really save development resources when there is the need to maintain both
> versions 3 and 4? It seems clear that having two major versions of
> Tesseract requires more work for Linux distributions. Neither is it a good
> solution for users who have to install and use both versions and don't know
> what to do when texts require both versions.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/707#issuecomment-286690362>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056Qz-VC6VezMBvacI2nBojn_NJ8FAks5rl7JqgaJpZM4L50TV>
> .
>



-- 
Ray.
  done Looks ok on web interface:

![tmp](https://user-images.githubusercontent.com/5095331/29661044-80c31798-88e0-11e7-9f7b-e9c8ceb9b8bf.png)
  Hi, for what platform are you trying to build opencv.text?

You could try to build it using CPPAN (https://cppan.org/). 
I'm using opencv.text on windows. All is fine.
https://cppan.org/pvt.cppan.demo.intel.opencv.contrib.text/version/3.2.0

To build it with cppan, download the client and run
`cppan --build 	pvt.cppan.demo.intel.opencv.contrib.text-3.2.0`.  Known problem. Root cause is PDF spec which forces heuristics into text extraction, and Preview is well known to have some of the wonkiest heuristics. Definitely not related to opencl.  @yoyoshuang I don't think tesseract allows for that from command line. There maybe some config variables, but I have no idea about it. > failed to write checkpoint

The output directory needs to be created before running the lstmtraining command.
If directory does not exist, you will get this error - see eg. below

```
2 Percent improvement time=63, best error was 100 @ 0
At iteration 63/100/100, Mean rms=0.718%, delta=2.212%, char train=5.292%, word train=17.556%, skip ratio=0%,  
New best char error = 5.292 
Transitioned to stage 1 
failed  to write best model:../tesstutorial/san_deva/san_deva5.292_63.checkpoint 
failed to write checkpoint.

```  Post your PDF please.  Not tested, but in general should be ok.
I remember some issues with libtiff dependency, but I fixed something, so 100% not sure. I've added a section with simple tess library build.
https://github.com/tesseract-ocr/tesseract/wiki/Compiling#windows It depends on what your are trying to do.
If you need to build user-app, follow one of these guides 
https://github.com/cppan/tesseract_example/tree/master/
https://github.com/cppan/tesseract_example/tree/master/with_cppan
 @hanikh Please do not complain here that some tutorial outside of this project does not work for you. (Especially when you decide to ignore instructions provided here on github)  How did you install tesseract and on what operating system?  Also are you just talking about the warning message or its something else going wrong as well? The best thing for bug reports is to attach your input data (and try to make the smallest, simplest example that reproduces the problem) along with exact commands used, and the output data. For support questions, use the forum. I'm going to close this bug now, but please re-open this bug if you think you've found a problem.

Note that the particular warning you saw will go away in a future Tesseract, and will be replaced with one that says something like "Unknown image resolution, making a guess". Which is hopefully a little more clear. PS. You can use jhove to validate JPEG 2000 files.  The latest version of the code does not read lstmf files created prior to Ray's recent commits.

```
Deserialize header failed: ~/tesstutorial/tess4training-vedic/san.Akshar_Unicode.exp-2.lstmf
[Thread 0x7ffff2bb3700 (LWP 8327) exited]
[New Thread 0x7fffef194700 (LWP 8328)]
Deserialize header failed: ~/tesstutorial/tess4training-vedic/san.Aksharyogini2.exp0.lstmf
[New Thread 0x7ffff2bb3700 (LWP 8329)]
Load of page 0 failed!
Load of images failed!!
[Thread 0x7fffef194700 (LWP 8328) exited]

Program received signal SIGSEGV, Segmentation fault.
[Switching to Thread 0x7ffff2bb3700 (LWP 8329)]
0x00007ffff70be464 in truncate (size=0, this=0x30790e8) at ../ccutil/genericvector.h:497
497           delete GenericVector<T*>::data_[i];
(gdb) backtrace
#0  0x00007ffff70be464 in truncate (size=0, this=0x30790e8) at ../ccutil/genericvector.h:497
#1  tesseract::DocumentData::ReCachePages (this=0x30790e0) at imagedata.cpp:523
#2  0x00007ffff70be839 in tesseract::ReCachePagesFunc (data=<optimized out>) at imagedata.cpp:371
#3  0x00007ffff419d184 in start_thread (arg=0x7ffff2bb3700) at pthread_create.c:312
#4  0x00007ffff6390ffd in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111
```
 Ok. Closing the issue.  Please use tesseract user forum for asking support/questions.  Here you are
https://www.dropbox.com/s/obiqvrt4m53pmoz/tesseract-4.0.0-alpha.zip?dl=1 There is also a new installer in our [wiki](https://github.com/UB-Mannheim/tesseract/wiki). > There is also a new installer in our wiki.

Now an updated version which includes PR #698 is available. It no longer tries to use AVX. We currently build only installers with 32 bit executables (which work also on 64 bit Windows like yours). Building both 32 and 64 bit installers is possible, but requires more resources. No, we did not try training on Windows. The problem which you observe could be related to several issues which I noticed while working on Tesseract 4 for big endian machines, more concretely on wrong assumptions about the size of an enum variable. You can compare binary files created on Windows with files created on Linux using `cmp -l`. I'd expect that the Linux files have some additional 0 bytes, so they are a little bit larger.  Yes. Please, download cppan client and run `cppan --build pvt.cppan.demo.google.tesseract-master` First, provide what output you get from those commands. 1. build them - Yes (Also turn on that check box.)
2. Select tesseractmain project in Solution Explorer - in the context menu set it as default project. This is because of early error of cppan.
Try to open `cppan.yml` in some editor and save with unix line endings (LF).
Also try to upgrade cppan `cppan --self-upgrade`. notepad++  Sounds to me like we should retire **hocr_font_info**, and remove the related HOCR output code.  AFAICT I have fixed the issues with Khmer training text. It remains to be seen whether the results of training are improved.  I think the cause of all of these is the precision-recall tradeoff that takes place in linerec.cpp
https://github.com/tesseract-ocr/tesseract/blob/master/ccmain/linerec.cpp#L313

The underlying question is, if there is a word that is almost certainly incorrect, would it be better to have it with the error, or have it disappear?

Historically Tesseract has not dropped words in such a way, but when I tried it, I found that almost every word dropped was incorrect anyway, so the word-level precision was improved without hurting recall.
Character-level recall OTOH **is** reduced by this word-dropping, since the rest of the characters in a word are usually correct.

I might disable the word dropping altogether, or maybe it would work better for deleting garbage if most of the characters are bad instead of just the worst.

While I am looking at this though, I am not convinced that the unicharset and/or compression are applied correctly to Kannada, which might explain its rather stubborn refusal to improve in accuracy. >>The underlying question is, if there is a word that is almost certainly incorrect, would it be better to have it with the error, or have it disappear?

>I do not think it should disappear. However, if the word is almost certainly incorrect, then it should be marked in some easy way for users to fix the OCRed txt.

For `hOCR` output, the answer is simple: output the word and add the information on the certainty as additional information (I think this is already one). For other formats which don't support such additional information, a special textual mark might be considered, but I consider that a very special case (so no special handling would be fine for me, too).  I made a discovery yesterday that the web-derived text corpus for Kannada
is missing ZWNJ, which AFAICT is an *essential* unicode character in
Kannada.
The same applies to other Indic languages, although the use varies, and
some use ZWJ as well.

I'm still working on this and investigating where they are lost.
The implications for fixing it could be higher accuracy in several
languages, although I don't know by how much, as I haven't measured the
frequency of ZWNJ in my test sets.

On Fri, Feb 17, 2017 at 12:45 AM, Shreeshrii <notifications@github.com>
wrote:

> More Kannada OCR related papers:
>
> http://mile.ee.iisc.ernet.in/mile/publications/softCopy/
> DocumentAnalysis/Madhav_SPCOM2014.pdf
>
> http://mile.ee.iisc.ernet.in/mile/publications/softCopy/
> DocumentAnalysis/Nethra_ICFHR2010_Data.pdf
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/681#issuecomment-280590084>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056SQADDz1OYsnSygJmWFUA7rCatPiks5rdV4PgaJpZM4LuojH>
> .
>



-- 
Ray.
 See https://github.com/tesseract-ocr/tesseract/issues/664 for details about dropped words during Devanagari recognition.
 >I think the cause of all of these is the precision-recall tradeoff that takes place in linerec.cpp
https://github.com/tesseract-ocr/tesseract/blob/master/ccmain/linerec.cpp#L313

@theraysmith Are there any config values I can change so that words are not dropped? Ok, I changed some constants and now the words are being dropped rarely.

@theraysmith Is this the right approach? It will be good if these values can be changed via config variables rather than needing recompile to test different values.

I changed the following:

https://github.com/tesseract-ocr/tesseract/blob/a1c22fb0d0f6bde165ec7b7c3125420b0ba1d541/lstm/recodebeam.cpp#L32

changed from -20.0f to -50.0f
```
// Clipping value for certainty inside Tesseract. Reflects the minimum value
// of certainty that will be returned by ExtractBestPathAsUnicharIds.
// Supposedly on a uniform scale that can be compared across languages and
// engines.
const float RecodeBeamSearch::kMinCertainty = -50.0f;
```
https://github.com/tesseract-ocr/tesseract/blob/master/ccmain/linerec.cpp#L36-40

changed from 5.0f to 0.0f
```
// Arbitarary penalty for non-dictionary words.
// TODO(rays) How to learn this?
const float kNonDictionaryPenalty = 0.0f;
```

changed from -25.0f to -99.0f
```
// Worst acceptable certainty for a dictionary word.
const float kWorstDictCertainty = -99.0f;
```

 @theraysmith  

>Will changes in training also support scanned box/tiff pairs?

In addition to training for unknown fonts by using scanned box/tiff pairs, they would also be useful for 'printing conventions' which may not be in concert with the current unicode conventions.

See attached image, where the anusvar is printed before the reph whereas the valid rendering would display anusvar later. Training by using only synthetic images and valid cases will not train for such cases. Currently these words get dropped during recognition.

![srisubodhini00vall_0013](https://user-images.githubusercontent.com/5095331/28249585-288ba9ec-6a76-11e7-99ad-e4763829ed33.png)
 @theraysmith 

Do the changes so far address the missing text / dropped words issue? Should I test these or wait for new models?  Please try master and report if problem is fixed.  Please use tesseract user forum for asking questions/support  @amitdo is correct. unicharset_extractor doesn't read the WordStr box file format.
Sorry this is an un-tested path.
Furthermore, it isn't just a case of modifying unicharset_extractor.
For the Indic languages, the unicharset needs to know the syllable/grapheme clusters, and it can't get that from the Wordstr box file format. The best it can do is extract the unicodes used in the WordStr box file or you start with an existing unicharset for that training path. Related - https://github.com/tesseract-ocr/tesseract/issues/832 @theraysmith Please also see https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/Xu4_aOCFhlQ/Yb2G59zTAgAJ about 
Training Tesseract4.0 (LSTM) on word level bounding boxes

Will this be addressed when you update the unicharset_extractor?

I am wondering whether there is a way to use the `text2image` algorithm to create box files given image and ground truth files.   v3.0.4 works, v4.0.0 fails

```
$ echo phototest.tif > manifest
$ tesseract manifest - -
This is a lot of 12 point text to test the
ocr code and see if it works on all types
of file format.

The quick brown dog jumped over the
lazy fox. The quick brown dog jumped
over the lazy fox. The quick brown dog
jumped over the lazy fox. The quick
brown dog jumped over the lazy fox.
```

```
$ echo phototest.tif > manifest
$ tesseract manifest - -
Error during processing.
ObjectCache(0xb408678)::~ObjectCache(): WARNING! LEAK! object 0x7ff6a69316a0 still has count 1 (id third_party/tesseract/tessdata/eng.traineddatalstm-punc-dawg)
ObjectCache(0xb408678)::~ObjectCache(): WARNING! LEAK! object 0x7ff6a694a140 still has count 1 (id third_party/tesseract/tessdata/eng.traineddatalstm-word-dawg)
ObjectCache(0xb408678)::~ObjectCache(): WARNING! LEAK! object 0x7ff6a6dc2650 still has count 1 (id third_party/tesseract/tessdata/eng.traineddatalstm-number-dawg)
ObjectCache(0xb408678)::~ObjectCache(): WARNING! LEAK! object 0x7ff6a6dc25c0 still has count 1 (id third_party/tesseract/tessdata/eng.traineddatapunc-dawg)
ObjectCache(0xb408678)::~ObjectCache(): WARNING! LEAK! object 0x7ff6a6de0260 still has count 1 (id third_party/tesseract/tessdata/eng.traineddataword-dawg)
ObjectCache(0xb408678)::~ObjectCache(): WARNING! LEAK! object 0x7ff6a69314f0 still has count 1 (id third_party/tesseract/tessdata/eng.traineddatanumber-dawg)
ObjectCache(0xb408678)::~ObjectCache(): WARNING! LEAK! object 0x7ff6a6de1e80 still has count 1 (id third_party/tesseract/tessdata/eng.traineddatabigram-dawg)
ObjectCache(0xb408678)::~ObjectCache(): WARNING! LEAK! object 0x7ff6a6de1d60 still has count 1 (id third_party/tesseract/tessdata/eng.traineddatafreq-dawg)
``` Here's a fix. I don't know if 3.0.5 is busted or not (if I had to guess, yes)

```diff
--- api/baseapi.cpp	2016-12-15 15:28:37.000000000 -0800
+++ api/baseapi.cpp	2017-01-18 15:03:52.000000000 -0800
@@ -1083,7 +1083,15 @@
 
   // Maybe we have a filelist
   if (r != 0 || format == IFF_UNKNOWN) {
-    STRING s(buf.c_str());
+    STRING s;
+    if (stdInput) {
+      s = buf.c_str();
+    } else {
+      std::ifstream t(filename);
+      std::string u((std::istreambuf_iterator<char>(t)),
+                    std::istreambuf_iterator<char>());
+      s = u.c_str();
+    }
     return ProcessPagesFileList(NULL, &s, retry_config,
                                 timeout_millisec, renderer,
                                 tesseract_->tessedit_page_number);
``` thanks!  Closing this and linking to issue #681  Using Image linked above https://cloud.githubusercontent.com/assets/5095331/22055988/c65e0f96-dd83-11e6-9f06-bea70dd85be6.png

```
Best choice certainty=-3.09489, space=-0.195364, scaled=-21.6642, final=-21.6642
 : शूण्वन्तु : R=13.0464, C=-3.09489, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos     NORM    NORM    NORM    NORM    NORM
str     शू      ण्      व       न्      तु
state:  1       1       1       1       1
C       -3.095  -0.260  -0.219  -0.298  -0.195
Deleting word with certainty -21.6642
 : शूण्वन्तु : R=13.0464, C=-21.6642, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos     NORM    NORM    NORM    NORM    NORM
str     शू      ण्      व       न्      तु
state:  1       1       1       1       1
C       -3.095  -0.260  -0.219  -0.298  -0.195
Best choice certainty=-1.30628, space=-0.195364, scaled=-9.14397, final=-9.14397
 : क्रषय: : R=5.64425, C=-1.30628, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos     NORM    NORM    NORM    NORM    NORM
str     क्      र       ष       य       :
state:  1       1       1       1       1
C       -1.306  -0.262  -0.229  -0.195  -0.204
```

The correct words are 

```
शृण्वन्तु 
श ृ ण् व न् तु 
```
and
```
ऋषयः 
ऋ ष य ः
```
  I think the patch is good and only requires a small clean-up (removing the `__MINGW32__` test).
It builds fine with clang on macOS (tested with [MacPorts](https://www.macports.org/)).

I also suggest to squash all commits before applying them. @jbarlow83, is [this commit](https://github.com/stweil/tesseract/commit/fa677f1ba183c6265fb11a14328dca6b8dd34368) fine for you? If yes, I'd make a pull request for it. I kept the original date and you as the author.  I'm very reluctant to make Tesseract PDF generation fancy. I wonder if we can do an image swap like this outside of Tesseract, using one of the PDF manipulation toolkits. Really? That's interesting, qpdf is very well written. Maybe the right thing to do is allow Tesseract to produce a multi-page PDF with invisible symbolic text PDF only, no images. Then another tool (perhaps an enhanced qpdf tool) would merge and composite two PDFs together. One being the original image-only PDF, and the other an invisible-text-only  PDF. What do you think, @jbarlow83? Please point me at the relevant qpdf API calls if you happen to know them.

 This sounds reasonable to me. I'll try to find time over this coming week to make an experimental invisible-text-only PDF that we can play with. All the other pieces of the puzzle are there; for example Leptonica already ships with a images->pdf tool that avoids transcoding for PNG, JP2K, and JPEG. It would be cool to use qpdf for the merge step because it is already so useful for linearizing. But it's great that there are more options. The qpdf author is extremely friendly in my experience, in case we eventually chat with him. Oh, I now vaguely remember that PDFBox had something for merging as well, but I've never tried it and can't find it at the moment. Here's an experimental PDF pair, image-only and text-only. Let the merging begin!

[images.pdf](https://github.com/tesseract-ocr/tesseract/files/712576/images.pdf)
[text.pdf](https://github.com/tesseract-ocr/tesseract/files/712628/text.pdf)

 This works brilliantly. I will implement for real if someone promises that they will use it. Also, what do we call the configuration option? My best idea so far to describe a PDF that has invisible text only is 'naked'. I'm sure someone has a better idea. 

```
$ time pdftk text.pdf multibackground images.pdf output full.pdf
real	0m0.253s
```

Actually this works better the other way around, for preserving the bookmarks and things like that.

```
 pdftk  images.pdf multibackground text.pdf output full.pdf
```
 Implementation complete and under review by Ray. @jbarlow83 this is a good time to look at the samples above and make sure they meet your needs.

```
tesseract -c naked_pdf=true HelloWorld.png HelloWorld pdf
``` Spectral writing. Perhaps a kind of ghost script, if you will. Hmmm, an invisible text layer, invisible text, let's see ...  iText? Anyway, I'll pick something. There is zero chance that a PDF rasterizer will ever be part of Tesseract or Leptonica. In theory one could write an PDF image extractor for Leptonica, but there isn't really enough motivation to do so.  Ray will eventually merge this patch, but it is hard to predict when. I am posting here for anyone who is impatient or excited.

```diff
--- api/pdfrenderer.cpp	2016-12-13 14:43:24.000000000 -0800
+++ api/pdfrenderer.cpp	2017-01-19 14:50:56.000000000 -0800
@@ -178,10 +178,12 @@
  * PDF Renderer interface implementation
  **********************************************************************/
 
-TessPDFRenderer::TessPDFRenderer(const char* outputbase, const char *datadir)
+TessPDFRenderer::TessPDFRenderer(const char *outputbase, const char *datadir,
+                                 bool textonly)
     : TessResultRenderer(outputbase, "pdf") {
   obj_  = 0;
   datadir_ = datadir;
+  textonly_ = textonly;
   offsets_.push_back(0);
 }
 
@@ -326,7 +328,11 @@
   pdf_str.add_str_double("", prec(width));
   pdf_str += " 0 0 ";
   pdf_str.add_str_double("", prec(height));
-  pdf_str += " 0 0 cm /Im1 Do Q\n";
+  pdf_str += " 0 0 cm";
+  if (!textonly_) {
+    pdf_str += " /Im1 Do";
+  }
+  pdf_str += " Q\n";
 
   int line_x1 = 0;
   int line_y1 = 0;
@@ -832,6 +838,7 @@
 bool TessPDFRenderer::AddImageHandler(TessBaseAPI* api) {
   size_t n;
   char buf[kBasicBufSize];
+  char buf2[kBasicBufSize];
   Pix *pix = api->GetInputImage();
   char *filename = (char *)api->GetInputName();
   int ppi = api->GetSourceYResolution();
@@ -840,6 +847,9 @@
   double width = pixGetWidth(pix) * 72.0 / ppi;
   double height = pixGetHeight(pix) * 72.0 / ppi;
 
+  snprintf(buf2, sizeof(buf2), "XObject << /Im1 %ld 0 R >>\n", obj_ + 2);
+  const char *xobject = (textonly_) ? "" : buf2;
+
   // PAGE
   n = snprintf(buf, sizeof(buf),
                "%ld 0 obj\n"
@@ -850,19 +860,18 @@
                "  /Contents %ld 0 R\n"
                "  /Resources\n"
                "  <<\n"
-               "    /XObject << /Im1 %ld 0 R >>\n"
+               "    %s"
                "    /ProcSet [ /PDF /Text /ImageB /ImageI /ImageC ]\n"
                "    /Font << /f-0-0 %ld 0 R >>\n"
                "  >>\n"
                ">>\n"
                "endobj\n",
                obj_,
-               2L,            // Pages object
-               width,
-               height,
-               obj_ + 1,      // Contents object
-               obj_ + 2,      // Image object
-               3L);           // Type0 Font
+               2L,  // Pages object
+               width, height,
+               obj_ + 1,  // Contents object
+               xobject,   // Image object
+               3L);       // Type0 Font
   if (n >= sizeof(buf)) return false;
   pages_.push_back(obj_);
   AppendPDFObject(buf);
@@ -899,13 +908,15 @@
   objsize += strlen(b2);
   AppendPDFObjectDIY(objsize);
 
-  char *pdf_object;
-  if (!imageToPDFObj(pix, filename, obj_, &pdf_object, &objsize)) {
-    return false;
+  if (!textonly_) {
+    char *pdf_object = nullptr;
+    if (!imageToPDFObj(pix, filename, obj_, &pdf_object, &objsize)) {
+      return false;
+    }
+    AppendData(pdf_object, objsize);
+    AppendPDFObjectDIY(objsize);
+    delete[] pdf_object;
   }
-  AppendData(pdf_object, objsize);
-  AppendPDFObjectDIY(objsize);
-  delete[] pdf_object;
   return true;
 }
 

--- api/renderer.h	2016-11-07 07:44:03.000000000 -0800
+++ api/renderer.h	2017-01-19 14:50:56.000000000 -0800
@@ -186,7 +186,7 @@
  public:
   // datadir is the location of the TESSDATA. We need it because
   // we load a custom PDF font from this location.
-  TessPDFRenderer(const char *outputbase, const char *datadir);
+  TessPDFRenderer(const char* outputbase, const char* datadir, bool textonly);
 
  protected:
   virtual bool BeginDocumentHandler();
@@ -196,20 +196,20 @@
  private:
   // We don't want to have every image in memory at once,
   // so we store some metadata as we go along producing
-  // PDFs one page at a time. At the end that metadata is
+  // PDFs one page at a time. At the end, that metadata is
   // used to make everything that isn't easily handled in a
   // streaming fashion.
   long int obj_;                     // counter for PDF objects
   GenericVector<long int> offsets_;  // offset of every PDF object in bytes
   GenericVector<long int> pages_;    // object number for every /Page object
   const char *datadir_;              // where to find the custom font
+  bool textonly_;                    // skip images if set
   // Bookkeeping only. DIY = Do It Yourself.
   void AppendPDFObjectDIY(size_t objectsize);
   // Bookkeeping + emit data.
   void AppendPDFObject(const char *data);
   // Create the /Contents object for an entire page.
-  static char* GetPDFTextObjects(TessBaseAPI* api,
-                                 double width, double height);
+  char* GetPDFTextObjects(TessBaseAPI* api, double width, double height);
   // Turn an image into a PDF object. Only transcode if we have to.
   static bool imageToPDFObj(Pix *pix, char *filename, long int objnum,
                           char **pdf_object, long int *pdf_object_size);

--- api/tesseractmain.cpp	2016-12-15 15:28:37.000000000 -0800
+++ api/tesseractmain.cpp	2017-01-19 14:50:56.000000000 -0800
@@ -337,8 +337,10 @@
 
     api->GetBoolVariable("tessedit_create_pdf", &b);
     if (b) {
-      renderers->push_back(
-          new tesseract::TessPDFRenderer(outputbase, api->GetDatapath()));
+      bool textonly;
+      api->GetBoolVariable("textonly_pdf", &textonly);
+      renderers->push_back(new tesseract::TessPDFRenderer(
+          outputbase, api->GetDatapath(), textonly));
     }
 
     api->GetBoolVariable("tessedit_write_unlv", &b);

--- ccmain/tesseractclass.cpp	2017-01-19 11:57:09.000000000 -0800
+++ ccmain/tesseractclass.cpp	2017-01-19 18:15:57.000000000 -0800
@@ -391,6 +391,8 @@
                   this->params()),
       BOOL_MEMBER(tessedit_create_pdf, false, "Write .pdf output file",
                   this->params()),
+      BOOL_MEMBER(textonly_pdf, false, "Invisible text only for PDF",
+                  this->params()),
       STRING_MEMBER(unrecognised_char, "|",
                     "Output char for unidentified blobs", this->params()),
       INT_MEMBER(suspect_level, 99, "Suspect marker level", this->params()),

--- ccmain/tesseractclass.h	2017-01-19 11:57:09.000000000 -0800
+++ ccmain/tesseractclass.h	2017-01-19 16:31:04.000000000 -0800
@@ -1027,6 +1027,7 @@
   BOOL_VAR_H(tessedit_create_hocr, false, "Write .html hOCR output file");
   BOOL_VAR_H(tessedit_create_tsv, false, "Write .tsv output file");
   BOOL_VAR_H(tessedit_create_pdf, false, "Write .pdf output file");
+  BOOL_VAR_H(textonly_pdf, false, "Invisible text only for PDF");
   STRING_VAR_H(unrecognised_char, "|",
                "Output char for unidentified blobs");
   INT_VAR_H(suspect_level, 99, "Suspect marker level");
``` pdfimages from poppler-utils will do image extraction as well. And pdfium offers API calls for image extraction. I am sure there are many others. Have fun. merged to master.
@Wikinaut: try master now. I clearly did not test well enough to find the embarrassing /XObject bug. Thank you for finding and fixing that @jbarlow83. Regarding capi.h and capi.cpp, the development branch that I am sharing with @theraysmith  doesn't have those files. I don't know what the story is with that, maybe Ray does. @Wikinaut, there are problems with "send one image through OCR and insert a different image in the output PDF". Image management becomes difficult, especially considering TIFF and PDF are multipage formats.  On top of that, certain image formats require transcoding. I think the textonly_pdf approach makes a building block that plays well with other tools, and is the right way to go. It is super simple to implement, and is especially well suited for turning scanned pdf into to searchable pdf while preserving metadata. That's something that increases in importance every single day.
 There is a much simpler way to achieve the same results. Remember, for most image formats Tesseract will not mangle the images in any way when creating a PDF file.

1. Extract the images from the PDF file (don't render!). For this example, we'll assume jpeg.
2. `ls *.jpg | tesseract - result pdf`   

Now it is a little more complicated if you want what was described in the top level comment. Which is to OCR a different image than what ends up in the PDF file. For that, it would look like this.

1. Extract the images from the PDF file (don't render!)
2. Merge them into an image-only PDF, using something like `converttopdf` from `leptonica-progs`
3. Apply your favorite image processing operations to the extracted images
4. Generate a text-only PDF from the extracted images
5. Merge your image-only and text-only PDF

Bottom line, you want your images completely unmolested during this process. No format conversion, no uncompress + decompress cycles. Nothing. Hands off. And it will work for most normal starting points. And honestly, you can almost certainly outsource all these details to software written by @jbarlow83  A image-only PDF file is a bag of images. If the bag is holding a bunch of JPEG images, extract them as-is. Don't convert. Don't recompress. Just empty the PDF bag and get your images out. If it is holding JPEG2000, then just get those out. Same with PNG. Let's shift this discussion back to the forum. Please re-ask your most recent question there; I don't follow exactly what you are asking. C-API should be fixed now. Thanks for finding this wikinaut.
@jbreiden capi.cpp and capi.h are C-API for tesseract that is used for tesseract wrappers (python etc.)
@Wikinaut as pointed by Jeff, please move back this discussion to [tesseract user forum](https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/vvMldrkcuOQ/3cyAq4jSAQAJ). Yes. The final solution was to implement `tesseract -c textonly_pdf=1` > The textonly_pdf parameter is only available on the HEAD (4.00)

@zdenop Please backport for 3.05. Thanks! done. Thanks, @zdenop. Please also make a 3.05.01 release with the latest commit in 3.05 branch so that all these enhancements are easily accessible.  This kind of retraining would be desirable, but is not available.

In your case, you don't need it though, as 4.00 works for all the examples
of "für" that you provided.
You just need to make sure you are using the latest code and data.

As Amit points out e diaresis is not in the German alphabet. I successfully
correctly got
"Citroën"
 by using fra+deu as the language. Unfortunately, it doesn't work with
deu+fra, and neither works for the 2nd example.
BTW this needed a bug fix for multi-language, which I will check in soon.

On Mon, Jan 16, 2017 at 9:26 AM, Wikinaut <notifications@github.com> wrote:

> @theraysmith <https://github.com/theraysmith> You appear to be the expert
> for answering my question, if such a procedure for re-training (tesseract +
> LSTM) is easily possible, or not:
>
> (I described it already above:)
>
> Can I "quickly" retrain my "deu" (or "deu+eng") training data (or a copy
> of it) with a corrected text ?
>
>    - in.pdf -> tesseract -> out.txt
>    - out.txt -> manually corrected -> *corrected.txt*
>    - retraining tesseract (to get tesseract' )with these inputs: in.pdf +
>    *corrected.txt*
>
> re-running re-trained tesseract should in the best case result in
>
>    - in-pdf -> tesseract' -> corrected.txt
>
> I found but do not (yet) understand the present training explanations in
> the Wiki, and perhaps is my idea not yet covered.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/659#issuecomment-272920831>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056ZP1oiFo1bk3xNLf3lGGBiL7G-ODks5rS6hbgaJpZM4LigRu>
> .
>



-- 
Ray.
 Some of the problems with German texts were addressed in https://github.com/tesseract-ocr/langdata/pull/54, https://github.com/tesseract-ocr/langdata/pull/56 and https://github.com/tesseract-ocr/langdata/pull/57. I don't know whether those fixes are sufficient to improve future trainings. I addressed the more general question whether all European languages should support all typical diacritical characters in the [tesseract-dev](https://groups.google.com/forum/#!topic/tesseract-dev/8H_4K3vPRJE) forum and need information from @theraysmith to proceed. > I successfully correctly got "Citroën" by using fra+deu as the language.

I expect that using additional languages has more side effects than recognizing additional characters, because they also add word list, unigram frequencies, word bigrams and so on for that languages which might have a negative effect on OCR results for texts which are mainly written in a single language but make sparely use of additional languages. Examples of such texts are German texts with foreign person or trade mark names, but also English scientific texts with additional Greek characters (a combination often used in mathematics and physics). @Wikinaut 

>I found certain groups of ocr failures in my scan case, two examples which were always wrongly detected
"Citroén" instead of the original word "Citroën"
"fiir" instead of "für"

Does it work now with best traineddata?

Can I close this issue? I have not tried the latest version. Pls. let this open - I will close it, if it's solved. @stweil I now use the new https://github.com/tesseract-ocr/tessdata_best data, and found that a problem with lowercase vs. uppercase "s" exists, in a 1000-page text, 

typical incorrectly detected word patterns are:

* "Sich" instead of "sich"
* "Sie" instead of "sie"
* "Sagte" instead of "sagte"
* "Sagen" instead of "sagen"
* "Sah" instead of "sah"
* "ICh" instead of "Ich"
* "80" instead of "so"
 Please see https://github.com/tesseract-ocr/tesseract/issues/960

I guess, you can make the following two config variables as false to not load the wordlist dawg files.

load_system_dawg     T
load_freq_dawg       T Those config variables related to the legacy engine. New traineddata files have a different lstm-word-dawg and have no freq-dawg files. So, I am not sure whether they will work. I haven't tried it yet. It is not that the wordlist is different, but the fact that the legacy engine and LSTM models might be using different unicharsets.

The creation and unpacking of dawgs requires unicharsets, that's why there are two sets of dawg files, even for numbers and punctuation, in addition to the wordlist.  Diacritics often get separated into their own text lines. Not so good as you might think?
Aren't the 3 yellow lines near the top and the 3 orange lines at the bottom
supposed to be different colors?
I think they have been fused into one line.

On Mon, Jan 16, 2017 at 9:20 PM, Shreeshrii <notifications@github.com>
wrote:

> I tried arabic_lines with both arabic diacritics and devanagari sample and
> it is marking the texlines well. Results attached.
> [image: result-arabic-diacritics]
> <https://cloud.githubusercontent.com/assets/5095331/22008592/a8101138-dca2-11e6-8d85-a0cbcc078304.png>
> [image: result-deva]
> <https://cloud.githubusercontent.com/assets/5095331/22008595/a814004a-dca2-11e6-99e6-26cedd4bc4e3.png>
> [image: textlines-arabic-diacritics]
> <https://cloud.githubusercontent.com/assets/5095331/22008594/a8129854-dca2-11e6-848e-4378a24beb26.png>
> [image: textlines-deva]
> <https://cloud.githubusercontent.com/assets/5095331/22008593/a811e328-dca2-11e6-9f39-977c3942e622.png>
>
> —
> You are receiving this because you were assigned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/657#issuecomment-273025064>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056Up0oVZPWQ2YcPpA-pm4Ju1d_k_lks5rTE-BgaJpZM4LiGKh>
> .
>



-- 
Ray.
 Thanks for the information. Please take a look at the attached unicharset,
and let me know if you see any deficiencies. I notice that ZWJ and ZWNJ are
not there, but 202c(Pop directional formatting) is.
It seems to contain all the diacritics that you mentioned.

On Fri, May 5, 2017 at 7:39 AM, bmwmy <notifications@github.com> wrote:

> I would like to give these hints to the developers:
> In Arabic there are to kinds of diacritics
> 1- letter attached diacritics (dots like ب ت ج ث and أ آ ؤ) which stick to
> the letter and is mandatory
> 2. Vowel diacritics like ( ْ ّ َ ً ِ ٍ ) used with letters any letter can
> be conjunct/combined with it and is optional. Kids learn it to read
> properly as it help get rid of ambiguity, because عَلم and عِلم are two
> different words but we use the context to distinguish when vowel diacritics
> are absent.
>
> N.B.
> لَاْ إِلَهَ إٍلا الله note that this َ ِ are different vowels same shape
> exactly but used differently e.g. أَ is pronounced a while ِأ pronounced e.
> one used above letter latter used below letter.
>
> bottom line: vowel diacritics in Arabic should be recognized alone (e.g
> separate box) because it can be on any letter and is limited ( ّ َ ً ُ ٌ ِ
> ٍ ْ ) special case also this ّ can be conjunct/combined with other vowel
> diacritics also ًّ ّْ
>
> hope this could help Tesseract developers
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/657#issuecomment-299482582>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056byXKSTYnwgO3_kA5fGf_x4WGKp8ks5r2zSLgaJpZM4LiGKh>
> .
>



-- 
Ray.
 @theraysmith 

>  Please take a look at the attached unicharset,

No file was attached.

Please also see https://github.com/tesseract-ocr/tesseract/issues/894#issue-226872462

  use tesseract user forum for asking support  That sounds like its working as intended.  The LSTM recognizer is currently trained to recognize the sequence of *unicodes* for Indic languages. This reduces the size of the output softmax of the network from the 5000+ elements in the unicharset to ~140. (There is an analogous process for Chinese, Japanese, and Korean, that doesn't use the unicode encoding, but it is a similar idea, and the codes are strictly limited in length.)
The unicharset is used as a *filter* in the beam search to allow only sensible grapheme/syllable combinations of unicodes, so it doesn't output complete garbage text.

The consequence of this recoding is that it runs a lot faster, but it has to learn to output a long sequence for each grapheme/syllable.
The recoding system that maps from unicharset elements to the sequence of unicodes currently only allows a maximum of 9 unicodes per grapheme/syllable, including any viramas.

I'm running a new training experiment this weekend to try a new coding scheme, in which `<virama><consonant>` pairs are mapped to a single code, allowing a long CVCVCVC string to be encoded using just CCCC, cutting down from 7 codes to 4. This will probably increase the size of the output softmax to ~170, but reduce the length of the average code sequence by about 1/3, which might be easier for it to learn, without slowing it down much.

It will take a couple of weeks to tell if it works, but if it does I will check in the code, and upload new traineddatas, and close this issue. If it doesn't work, I will have to think again... The text corpus is from *all* the www, taken several years ago, plus more
recent data from wiki-something.
The text is divided by language automatically, so there is a separate
stream for each of the Devanagari-based languages (as there is for the
Latin-based languages) and clipped to 1GB for each language.
For each language, the text is frequency counted and cleaned by multiple
methods, and sometimes this cleaning is too stringent automatically, or not
stringent enough, so forbidden_characters and desired_characters are used
as a guide in the cleanup process. There are other lang-specific numbers
like a 1-in-n discard ratio for the frequency.
For some languages, the amount of data produced at the end is very thin.

The unicharset is extracted from what remains, and the wordlist that is
published in langdata.
For the LSTM training, I resorted to using Google's parallel infrastructure
to render enough text in all the languages.
However much or little corpus text there is, the rendering process makes
50000 chunks of 50 words to render in a different combination of font and
random degradation, which results in 400000-800000 rendered textlines.
The words are chosen to approximately echo the real frequency of conjunct
clusters (characters in most languages) in the source text, while also
using the most frequent words.

This process is all done without significant manual intervention, but
counts of the number of generated textlines indicates when it has gone
badly, usually due to a lack of fonts, or a lack of corpus text.
I recently stopped training chr, iku, khm, mya after discovering that I
have no rendered textlines that contain anything other than digits and
punctuation.

Community input is therefore extremely useful, and usually results in edits
to forbidden_characters and desired_characters, which in turn guides the
filtration process.
Community-provided corpus text would be useful for languages that have very
little or no training data, given appropriate copyright/licensing clearance.
The languages with very little corpus text are:
bih
chr
dzo
iku
snd
syr
tgk
tir
so these are likely to have poor recognition accuracy.

On Sat, Jan 21, 2017 at 7:46 AM, Shreeshrii <notifications@github.com>
wrote:

> Ray,
>
> Thank you for explaining regrading unicharset compression and your new
> strategy for Indic graphemes.
>
> Since the unicharset is being used as a filter, it will be important to
> include the most common conjunct clusters in it, which may differ from
> language to language.
>
> Some more questions
>
> Are the desired_characters and forbidden_characters used in the process of
> creating the text corpus for different languages?
>
> How many text lines are you using for training of Devanagari, e.g.
> Sanskrit, Hindi, Marathi etc. Is it all/only from Wikipedia?
>
>
>
> - excuse the brevity, sent from mobile
>
> On 21-Jan-2017 3:34 AM, "theraysmith" <notifications@github.com> wrote:
>
> > The LSTM recognizer is currently trained to recognize the sequence of
> > *unicodes* for Indic languages. This reduces the size of the output
> > softmax of the network from the 5000+ elements in the unicharset to ~140.
> > (There is an analogous process for Chinese, Japanese, and Korean, that
> > doesn't use the unicode encoding, but it is a similar idea, and the codes
> > are strictly limited in length.)
> > The unicharset is used as a *filter* in the beam search to allow only
> > sensible grapheme/syllable combinations of unicodes, so it doesn't output
> > complete garbage text.
> >
> > The consequence of this recoding is that it runs a lot faster, but it has
> > to learn to output a long sequence for each grapheme/syllable.
> > The recoding system that maps from unicharset elements to the sequence of
> > unicodes currently only allows a maximum of 9 unicodes per
> > grapheme/syllable, including any viramas.
> >
> > I'm running a new training experiment this weekend to try a new coding
> > scheme, in which pairs are mapped to a single code, allowing a long
> CVCVCVC
> > string to be encoded using just CCCC, cutting down from 7 codes to 4.
> This
> > will probably increase the size of the output softmax to ~170, but reduce
> > the length of the average code sequence by about 1/3, which might be
> easier
> > for it to learn, without slowing it down much.
> >
> > It will take a couple of weeks to tell if it works, but if it does I will
> > check in the code, and upload new traineddatas, and close this issue. If
> it
> > doesn't work, I will have to think again...
> >
> > —
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/654#
> issuecomment-274192153>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_o-xusyCIFbh-
> wE4T4cp4mVb4oBWWks5rUS9vgaJpZM4LhbNY>
> > .
>
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/654#issuecomment-274269267>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056XOUmyQKlAM4aHUJc-jTRmhEwWOxks5rUihVgaJpZM4LhbNY>
> .
>



-- 
Ray.
 Update: after going back to the www to get fresh data, I believe that my corpus text is now good for:
chr
dzo
iku
snd
syr
tgk
tir
I have put a lot of time into cleaners/filters for languages that use 'virama' characters.
I am not convinced that they are perfect, but I will add the code to the github repo in due course, so experts/native speakers can offer suggestions/fixes to make them better. Myanmar in particular needs improvement, as the www data is littered with dotted circles, and the unicode book does not adequately describe the syntax for a well-formed grapheme in Myanmar (or any other language for that matter).
 @theraysmith You wrote in january:

>The LSTM recognizer is currently trained to recognize the sequence of unicodes for Indic languages. This reduces the size of the output softmax of the network from the 5000+ elements in the unicharset to ~140. (There is an analogous process for Chinese, Japanese, and Korean, that doesn't use the unicode encoding, but it is a similar idea, and the codes are strictly limited in length.)

In recent trainings, I still see large unicharsets (eg, with ALL akshara combinations from the training_text in Devanagari). 

```
Appending a new network to an old one!!Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Setting properties for script Devanagari
Setting properties for script Han
Unichar 1945=र्त्स्न्ये->र्त्स्न्ये is too long to encode!!
Warning: given outputs 105 not equal to unicharset of 3784.
```

Depending on the training text, this number can go as high as 6-7000. I thought the intention was to reduce this number.

Also, when training with hin.lstm as the starting point for replace top layer training, while the original .lstm file is about 8 MB, the intermediate .lstm files are about 80 MB and the _checkpoint file is about 160MB.

Is this to be expected or is something wrong with the training process? >I'm running a new training experiment this weekend to try a new coding scheme, in which <virama><consonant> pairs are mapped to a single code, allowing a long CVCVCVC string to be encoded using just CCCC, cutting down from 7 codes to 4. This will probably increase the size of the output softmax to ~170, but reduce the length of the average code sequence by about 1/3, which might be easier for it to learn, without slowing it down much.

@theraysmith Did the above approach work?

In https://github.com/tesseract-ocr/docs/blob/master/das_tutorial2016/7Building%20a%20Multi-Lingual%20OCR%20Engine.pdf, you have desscribed what's a character in Devanagari and used the following example:

rdvika - र्द्विक - 0930 094D 0926 094D 0935 093F 0915

I would actually split the above as two aksharas, each ending in the either the implicit a or a maatraa or a combining mark.

So the above would be:

rdvi - र्द्वि - 0930 094D 0926 094D 0935 093F 
ka - क -  0915

To reduce the various akshara combinations, i would suggest splitting 
CVCVCVC - consonant clusters
and
Maatra and Combining marks separately

eg. possible combinations with ka (and these do not include the combining vedic accents!!)

```
क का कि की कु कू कृ के कै को कौ कँ काँ किँ कीँ कुँ कूँ कृँ केँ कैँ कोँ कौँ कं कां किं कीं कुं कूं कृं कें कैं कों कौं कः काः किः कीः कुः कूः कृः केः कैः कोः कौः 
```
Imagine these for every consonant cluster with every vowel sign (or matra), other signs like candrabindu, anusvara and visarga to each combination. the number of combinations will be HUGE. 

By splitting consonant cluster part separately from maatraa and other signs combination, the number of combinations can be cut down drastically.

```
   ा  ि  ी  ु  ू  ृ  े  ै  ो  ौ  ँ  ाँ  िँ  ीँ  ुँ  ूँ  ृँ  ेँ  ैँ  ोँ  ौँ  ं  ां  िं  ीं  ुं  ूं  ृं  ें  ैं  ों  ौं  ः  ाः  िः  ीः  ुः  ूः  ृः  ेः  ैः  ोः  ौः 
```
and consonants and consonant clusters such as 
```
क ख ग घ ङ च छ ज झ ञ ट ठ ड ढ ण त थ द ध न प फ ब भ म य र ल व श ष स ह ळ
क्क क्क्य क्ख क्ख्य क्त क्त्य क्त्र क्त्र्य क्त्व क्थ क्न क्न्य क्प क्प्य क्फ क्फ्य क्म क्म्य क्य क्र क्र्य क्ल क्ल्य क्व क्व्य
क्ष क्ष्ण क्ष्म क्ष्म्य क्ष्य क्ष्व क्स ख्य ग्द ग्द्य ग्ध ग्ध्य ग्ध्व ग्न ग्न्य ग्ब ग्ब्र ग्भ ग्भ्य ग्म ग्म्य ग्य ग्र ग्र्य ग्ल ग्व
घ्न घ्म घ्य घ्र ङ्क ङ्क्त ङ्क्ष ङ्क्ष्व ङ्ख ङ्ख्य ङ्ग ङ्ग्य ङ्ग्र ङ्ग्र्य ङ्घ ङ्घ्र ङ्ङ ङ्म ङ्स
च्च च्छ च्छ्य च्छ्र च्छ्व च्म च्य छ्य छ्र छ्र्य छ्व ज्ज ज्ज्ञ ज्ज्व ज्झ ज्ञ ज्ञ्य ज्म ज्य ज्र ज्व
ञ्च ञ्च्य ञ्छ ञ्छ्र ञ्ज ञ्ज्म ञ्ज्य ञ्झ ञ्श
ट्क ट्ट ट्य ट्व ट्स ठ्य ठ्र ड्र ड्ड ड्य ढ्य ढ्र ढ्व ण्ट ण्ठ ण्ड ण्ढ ण्ण ण्म ण्य ण्व
त्क त्त त्त्य त्त्र त्त्व त्थ त्न त्न्य त्प त्प्र त्प्र्य त्फ त्म त्म्य त्य त्र त्र्य त्व त्स त्स्र त्स्र्य त्स्य त्स्व
थ्य द्ग द्ग्र द्द द्द्य द्द्र द्द्व् द्ध द्ध्य द्ध्व द्ध्व्य द्न द्न्य द्ब द्ब्र द्भ द्भ्य द्म द्य द्र द्र्य द्व् द्व्य द्व्र ध्न ध्म ध्य ध्र ध्व
न्त न्त्य न्त्र न्त्स न्थ न्द न्द्ध न्द्र न्द्व् न्ध न्ध्य न्ध्र न्ध्व न्न न्न्य न्प न्प्र न्फ न्म न्य न्व न्स
प्त प्त्य प्त्र प्न प्प प्फ प्म प्य प्र प्ल प्स फ्य ब्घ ब्ज ब्द ब्ध ब्ध्व ब्ब ब्भ ब्य ब्र ब्न भ्य ब्र भ्व
म्न म्प म्प्र म्ब म्ब्य म्भ म्ब्र म्म म्य म्र म्ल
य्य य्व ल्क ल्ग ल्प ल्म ल्य ल्ल ल्व ल्ह व्य व्र व्व श्च श्च्य श्न श्न्य श्म श्य श्र श्र्य श्ल श्व श्व्य श्श
ष्क ष्क्र ष्ट ष्ट्य ष्ट्र ष्ट्र्य ष्ट्व ष्ठ ष्ठ्य ष्ठ्र ष्ण ष्ण्य ष्प ष्प्र ष्म ष्य ष्व
स्क स्क्र स्ख स्त स्त्य स्त्र स्त्व स्थ स्थ्य स्र स्प स्प्र स्फ स्म स्म्य स्य स्र स्व स ह्न ह्म ह्य ह्र ह्ल ह्व
```
and (with reph)

```
 र्क र्ख र्ग र्घ र्ङ र्च र्छ र्ज र्झ र्ञ र्ट र्ठ र्ड र्ढ र्ण र्त र्थ र्द र्ध र्न र्प र्फ र्ब र्भ र्म र्य र्र र्ल र्व र्श र्ष र्स र्ह र्ळ
 र्क्क र्क्क्य र्क्ख र्क्ख्य र्क्त र्क्त्य र्क्त्र र्क्त्र्य र्क्त्व र्क्थ र्क्न र्क्न्य र्क्प र्क्प्य र्क्फ र्क्फ्य र्क्म र्क्म्य र्क्य र्क्र र्क्र्य र्क्ल र्क्ल्य र्क्व र्क्व्य
 र्क्ष र्क्ष्ण र्क्ष्म र्क्ष्म्य र्क्ष्य र्क्ष्व र्क्स र्ख्य र्ग्द र्ग्द्य र्ग्ध र्ग्ध्य र्ग्ध्व र्ग्न र्ग्न्य र्ग्ब र्ग्ब्र र्ग्भ र्ग्भ्य र्ग्म र्ग्म्य र्ग्य र्ग्र र्ग्र्य र्ग्ल र्ग्व
 र्घ्न र्घ्म र्घ्य र्घ्र र्ङ्क र्ङ्क्त र्ङ्क्ष र्ङ्क्ष्व र्ङ्ख र्ङ्ख्य र्ङ्ग र्ङ्ग्य र्ङ्ग्र र्ङ्ग्र्य र्ङ्घ र्ङ्घ्र र्ङ्ङ र्ङ्म र्ङ्स
 र्च्च र्च्छ र्च्छ्य र्च्छ्र र्च्छ्व र्च्म र्च्य र्छ्य र्छ्र र्छ्र्य र्छ्व र्ज्ज र्ज्ज्ञ र्ज्ज्व र्ज्झ र्ज्ञ र्ज्ञ्य र्ज्म र्ज्य र्ज्र र्ज्व
 र्ञ्च र्ञ्च्य र्ञ्छ र्ञ्छ्र र्ञ्ज र्ञ्ज्म र्ञ्ज्य र्ञ्झ र्ञ्श
 र्ट्क र्ट्ट र्ट्य र्ट्व र्ट्स र्ठ्य र्ठ्र र्ड्र र्ड्ड र्ड्य र्ढ्य र्ढ्र र्ढ्व र्ण्ट र्ण्ठ र्ण्ड र्ण्ढ र्ण्ण र्ण्म र्ण्य र्ण्व
 र्त्क र्त्त र्त्त्य र्त्त्र र्त्त्व र्त्थ र्त्न र्त्न्य र्त्प र्त्प्र र्त्प्र्य र्त्फ र्त्म र्त्म्य र्त्य र्त्र र्त्र्य र्त्व र्त्स र्त्स्र र्त्स्र्य र्त्स्य र्त्स्व
 र्थ्य र्द्ग र्द्ग्र र्द्द र्द्द्य र्द्द्र र्द्द्व् र्द्ध र्द्ध्य र्द्ध्व र्द्ध्व्य र्द्न र्द्न्य र्द्ब र्द्ब्र र्द्भ र्द्भ्य र्द्म र्द्य र्द्र र्द्र्य र्द्व् र्द्व्य र्द्व्र र्ध्न र्ध्म र्ध्य र्ध्र र्ध्व
 र्न्त र्न्त्य र्न्त्र र्न्त्स र्न्थ र्न्द र्न्द्ध र्न्द्र र्न्द्व् र्न्ध र्न्ध्य र्न्ध्र र्न्ध्व र्न्न र्न्न्य र्न्प र्न्प्र र्न्फ र्न्म र्न्य र्न्व र्न्स
 र्प्त र्प्त्य र्प्त्र र्प्न र्प्प र्प्फ र्प्म र्प्य र्प्र र्प्ल र्प्स र्फ्य र्ब्घ र्ब्ज र्ब्द र्ब्ध र्ब्ध्व र्ब्ब र्ब्भ र्ब्य र्ब्र र्ब्न र्भ्य र्ब्र र्भ्व
 र्म्न र्म्प र्म्प्र र्म्ब र्म्ब्य र्म्भ र्म्ब्र र्म्म र्म्य र्म्र र्म्ल
 र्य्य र्य्व र्ल्क र्ल्ग र्ल्प र्ल्म र्ल्य र्ल्ल र्ल्व र्ल्ह र्व्य र्व्र र्व्व र्श्च र्श्च्य र्श्न र्श्न्य र्श्म र्श्य र्श्र र्श्र्य र्श्ल र्श्व र्श्व्य र्श्श
 र्ष्क र्ष्क्र र्ष्ट र्ष्ट्य र्ष्ट्र र्ष्ट्र्य र्ष्ट्व र्ष्ठ र्ष्ठ्य र्ष्ठ्र र्ष्ण र्ष्ण्य र्ष्प र्ष्प्र र्ष्म र्ष्य र्ष्व
 र्स्क र्स्क्र र्स्ख र्स्त र्स्त्य र्स्त्र र्स्त्व र्स्थ र्स्थ्य र्स्र र्स्प र्स्प्र र्स्फ र्स्म र्स्म्य र्स्य र्स्र र्स्व र्स र्ह्न र्ह्म र्ह्य र्ह्र र्ह्ल र्ह्व
```
 Please see pages 48-75 of http://www.sanskritweb.net/itrans/itmanual2003.pdf
for the varied rendition of consonant cluster ligatures in different Devanagari fonts.  An encoded lstm recognizer (or trainer) includes its own unicharset.
There is currently no easy way to get the unicharset out to use it with the lstm dawg files.
Is this necessary?
If so, how should it be done? tesstrain_utils.sh needs to copy lang.unicharset as lang.lstm-unicharset, similar to the dawg files.

Then it can be added and extracted from the traineddata.

```
combine_tessdata -u hin.traineddata   hinnew.
Extracting tessdata components from hin.traineddata
Wrote hinnew.config
Wrote hinnew.lstm
Wrote hinnew.lstm-punc-dawg
Wrote hinnew.lstm-word-dawg
Wrote hinnew.lstm-number-dawg
Wrote hinnew.lstm-unicharset
Wrote hinnew.version
Version string:4.00.00alpha
0:config:size=739, offset=192
17:lstm:size=8874565, offset=931
18:lstm-punc-dawg:size=4322, offset=8875496
19:lstm-word-dawg:size=73098, offset=8879818
20:lstm-number-dawg:size=114, offset=8952916
21:lstm-unicharset:size=127137, offset=8953030
23:version:size=12, offset=9080167
``` Also missing is, 22:lstm-recoder Coming soon is a program that will take as input:
 a unicharset,
 optional list of wordlists (words, puncs, numbers)
 command-line flags to control the recoder

and outputs a traineddata containing the lstm uincharset, recoder, and the
dawgs if wordlists were supplied.

The resultant traineddata will be input to lstmtraining, in place of a
unicharset, thus achieving independence of the unicharset and recoder from
the lstm trainer. The trained lstm model will be added to the traineddata
by the --stop_training flag.

This is the change in training that I was talking about Friday.

On Sat, Jul 15, 2017 at 3:55 AM, Shreeshrii <notifications@github.com>
wrote:

> Also missing is, 22:lstm-recoder
>
> —
> You are receiving this because you were assigned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/653#issuecomment-315526522>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056a2iTeHmAhkTsCYhmLfBOsbZMnrBks5sOJqRgaJpZM4LhL-s>
> .
>



-- 
Ray.
 @theraysmith  Will changes in training also support scanned box/tiff pairs,  preferably with lineboxes having just the groundtruth for the whole line followed by tab character for EOL rather than the split into characters/aksharas as proposed by the WordStr format. Yes, the change is only in the setup of the language model components.
The training process will still take lstmf files, and they will still be
able to be created from tif.box pairs using either character or Wordstr
format box files.

On Sun, Jul 16, 2017 at 3:11 AM, Shreeshrii <notifications@github.com>
wrote:

> @theraysmith <https://github.com/theraysmith> Will changes in training
> also support scanned box/tiff pairs using the proposed Wordstr format?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/653#issuecomment-315599304>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056ThVwWjh8kBXxDCe2bAHCO6z-yaBks5sOeHlgaJpZM4LhL-s>
> .
>



-- 
Ray.
 Is Wordstr format supported with the new commits?

It would be helpful if you can provide a sample Wordstr format box file for Hindi? Thanks!  It means you are posting issue in wrong project. This is tesseract OCR.  Added this to the training instructions:
`<Undecodable>` can occur in either the ALIGNED_TRUTH or OCR TEXT output early
in training. It is a consequence of unicharset compression and CTC training.
(See Unicharset Compression and train_mode above). This should be harmless and
can be safely ignored. Its frequency should fall as training progresses.
  There *is* RTL-specific processing in text2image.
Pango renders RTL text RTL, and the post-processing is intended to re-order
everything strictly LTR.
*If it isn't doing that then there is a bug.*

Here is why:
Old Tesseract (3.05) is only learning individual character shapes, so the
order of training data is somewhat irrelevant.
New Tesseract (LSTM/4.00) is learning to identify the text characters in
the (LTR) order they appear in the image, so the truth transcription should
be LTR, and the words in the dawg should be reversed.
There is Bidi processing inside the post-recognition processing of
Tesseract that reprocesses/re-orders the text for output, so it appears in
the correct order.
I wonder if the bidi integration is working correctly for LSTM, as the
accuracy with Arabic is unsatisfactory.

In light of this design, please take another look, and let me know if there
is anything systematically wrong in the output that might provide some
hints as to where to look.
Thanks.

On Wed, Jan 11, 2017 at 5:08 AM, Amit D. <notifications@github.com> wrote:

> What you show here is 'by design'. This should not cause any problem in
> training process and characters recognition for RTL languages.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-271864082>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056RlP7ZpsIBdJ7ooGiEN1KuDDG54Kks5rRNRggaJpZM4Lf-kT>
> .
>



-- 
Ray.
 Thanks for the work on this.
I've learned 2 things so far:

   - U+640 (tatweel) is a very special case that I need to think how to
   handle - it needs to be preserved in the training text, so it gets
   rendered, but needs to disappear everywhere else, as if it doesn't exist.
   - The diacritics are currently excluded from the unicharset, probably
   because they are only rarely used, but need to be included. There may not
   be enough text with them included in the text corpora.


Questions:
Is that all of U+64b->U+652 inclusive?
Applied uniformly to all Arabic languages?
(ara+div+fas+kur_ara+pus+snd+syr+uig+urd)

On Wed, Jan 11, 2017 at 7:30 AM, Shreeshrii <notifications@github.com>
wrote:

> @theraysmith <https://github.com/theraysmith> Hope you have seen comments
> by Chris on the other thread also - #642
> <https://github.com/tesseract-ocr/tesseract/issues/642>
>
> i was merging the letter extender with the Arabic letter into one single
> box, and putting that Arabic letters as the character of the box,
> basically, i was trying to train the engine to recognize that Arabic letter
> in it's multiple positions, as you know the Arabic letters have multiple
> forms based which is based on it's position in the word ( beginning,
> middle, ending, isolated )
> Example:
> ( كـ ) is not ( ك + ـ ) in the box file, it should be ( ك )
> also ( ـكـ ) or ( ـك ) they are a single character ( ك ) in different
> positions, this is important in the box file.
>
> Which also means that ( كَـ ) is not ( ك + ـَ ), it is ( كَ )
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-271898975>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056fQCae8sI16xZmZURI7_cApxZrHzks5rRPWmgaJpZM4Lf-kT>
> .
>



-- 
Ray.
 @amitdo Hebrew seems to be OK. It is certainly ahead of 3.05.
I have some detailed results, but they aren't very meaningful without being able to look at the actual errors to see how many are actually due to the ground truth, or some strange disagreement on whitespace.
The gist is that 4.00 is less good than it could be on:
Arabic (all langs)
Indic (all langs)
Chinese, Japanese.
The problems with Arabic may be explained by this thread.
Chinese, Japanese are troubled by the used of radical-stroke encoding. I need to switch to a better scheme.
Indic may be troubled by the length of the compressed codes used. I need to switch to a better scheme. Thanks for forwarding that @Shreeshrii, there is a bug there that needs to
be fixed.

On Fri, Mar 10, 2017 at 2:25 AM, Shreeshrii <notifications@github.com>
wrote:

> https://groups.google.com/forum/?utm_medium=email&utm_
> source=footer#!msg/tesseract-ocr/EOwF1GnOcS0/My_SUf1vEQAJ
>
> tesseract4 reads الأ as األ which is pretty close, because we need to
> switch the position of the last 2 letters to have ا ل أ, this happens with
> similar word forms too like لا reads as ال and should be ل ا, and i wish to
> correct it.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-285633162>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056TBSuVaAYXREd1MJEUZz-KfW_b_pks5rkSUQgaJpZM4Lf-kT>
> .
>



-- 
Ray.
 I've started training with a fix for this.

On Fri, Mar 31, 2017 at 7:00 AM, Amit D. <notifications@github.com> wrote:

> Here are some libraries that implement the Unicode Bidi algorithm.
>
> https://github.com/behdad/pybyedie
> Copyright (C) 2013 Google
> License: MIT
> Written in: Python
>
> https://github.com/servo/unicode-bidi
> By Mozilla
> License: Apache 2.0 / MIT
> Written in: Rust
>
> https://github.com/behdad/fribidi
> License: LGPL 2.1
> Written in: C
>
> https://github.com/MeirKriheli/python-bidi
> License: LGPL 3.0
> Written in: Python
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-290720020>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056WfXs2mhFutZnpOnUujEFyxXRg_Oks5rrQcTgaJpZM4Lf-kT>
> .
>



-- 
Ray.
 I have! At the second attempt, I found the cause to be that unicodes within a ligature were not reversed.
There are some changes to the code (probably early next week) to fix this, and the dropped last space on each line of RTL text output, (is there an issue for that, or am I the only one that noticed?), and the corresponding traineddatas will be coming soon too. Please help me understand your comment on diacritics.
I understand that tatweel is a rendering artifact, that should be rendered
for training, but not occur in the output text (or in the language model).

My previous understanding of vowels in Hebrew and Arabic, is that they are
diacritical marks that are optional, and used mainly for disambiguation,
children's text and in historical text.

Are you referring to some different diacritics other than vowels, or are
you suggesting that vowels should never appear, or that some different
diacritics exist that should never appear in the output text?

Here are some examples of test data with diacritics:


Truth: שֶׁהוּא נָס מִפָּנָיו, אָמַר לוֹ מֹשֶה: כָּל הַיּוֹם הָיִיתִי אוֹמֵר
לְךָ בְּשֵׁם הַקֹּדֶשׁ וְלֹא הָיִיתָ
OCR: שָהוּא נס מִפָּנִיו, אָמַר לו משָה: כָּל הַיום הָיִיתי אוּמר לֶך
בָּשַם הקדש ולא הָיִיתָ
Confs: 0.84 0.56 0.64 0.93 0.96 0.77 0.88 0.76 0.63 0.64 0.54 0.45 0.91
0.88 0.58
Diff: שָהוּא נָס מִפָּנִיו, אָמַר לוֹ מֹשָה: כָּל הַיּוֹם הָיִיתִי אוּמֵר לֶ
ךָ בָּשַם הַקֹּדֶשׁ וְלֹא הָיִיתָ
Recall Errors = 12
Precision Errors = 2



Truth: ותופחים בבטנים ובשירים שארכם כארך סיגריה,
OCR: וְתופחים בַּבַּטָנִיס וּבשירים שאַרכֶּם כַארְף סִיגְרִיה,
Confs: 0.71 0.71 0.91 0.8 0.56 0.56
Diff: וְתופחים בַּבַּטָנִיס וּבשירים שאַרכֶּם כַארְף סִיגְרִיה,
Recall Errors = 6
Precision Errors = 1



Truth: له يزيد الرجال وركبوا الطريقَ فلم يشعر بهم العدو حتى ركبوا
OCR: له يزيج الرجال وركبوز الطريق فلم يشعر بهم العدر حتى ركبو
Confs: 0.82 0.9 0.96 0.4 0.9 0.96 0.93 0.97 0.64 0.94 0.71
Diff: له يزيج الرجال وركبوز الطريقَ فلم يشعر بهم العدر حتى ركبوا
Recall Errors = 5

In all these cases, tesseract gets a poor result.
In case 1, the diacritics are in the truth text, and Tesseract gets them
badly wrong.
In case 2, the diacritics are NOT in the truth text, and Tessseract
suggests some anyway.
I don't think that both of these truth texts can be "correct" in the sense
that one has the diacritics and the other does not. Which way should it be
and why?
In case 3 (Arabic) there are diacritics in the truth text (or are these not
what you are talking about?) and Tesseract does badly anyway.

The tatweel and ligature problem are fixed and will be corrected in the new
traineddatas coming soon, but it will have the above errors in.
According to my measurements, accuracy on Hebrew/Yiddish and Arabic/Farsi
are much improved, but still behind most of the LTR scripts.
If there is still something systematically wrong, your comments could help
further improve it!
Thanks,

On Wed, Jul 26, 2017 at 8:48 AM, chris <notifications@github.com> wrote:

> @theraysmith <https://github.com/theraysmith> @Shreeshrii
> <https://github.com/shreeshrii>
> Note that Arabic & Hebrew diacritics have the same issue of the U+640
> (tatweel), therefore I suggest that they need to be preserved in the
> training text so that they get rendered, but need to disappear everywhere
> else as if they doesn't exist.
> Currently, when introducing diacritics to a training model, the
> recognition rate falls drastically, thus I suggest Playing it Safe for
> now, they must be rendered, but disappear elsewhere.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-318095244>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056U2hHxhVyRranKuDmk3b59uCZ3eIks5sR1-pgaJpZM4Lf-kT>
> .
>



-- 
Ray.
 @theraysmith 

fyi - https://github.com/tesseract-ocr/tesseract/issues/892#issuecomment-318063065 http://blogs.transparent.com/arabic/2-arabic-diacritics-al-tashkeel-%D8%A7%D9%84%D9%80%D8%AA%D9%80%D8%B4%D9%80%D9%83%D9%80%D9%8A%D9%80%D9%80%D9%80%D9%84/

Good explanation with examples.  https://github.com/tesseract-ocr/tesseract/commit/3e63918f9db4150a3d1ff6136df9b753e507ae41

Please test with latest source from github. The commit by @theraysmith  fixes the issue. @theraysmith 

Thanks for these updates.

Does the complete fix for RTL languages also require new traineddata created with these fixes? 

Will you be uploading a new version of traineddata? @hanikh You are right, Ray had uploaded the best traineddata files on August 1.

However, I think that the wordlists in traineddata for RTL languages in that still had some errors in order of characters in ligatures.

I am hoping that @theraysmith will upload fixed versions of traineddata to the new repos for LSTM traineddata - 

https://github.com/tesseract-ocr/tessdata_best
and
https://github.com/tesseract-ocr/tessdata_fast  Please use tesseract user forum for asking questions, support...  @theraysmith Any update on this? @stweil Have you come across this problem while training? Any solution? Please try the following making appropriate changes for your fonts directory and tessdata directory

```
training/tesstrain.sh \
  --fonts_dir /c/Windows/Fonts \
  --tessdata_dir ./tessdata \
  --training_text ../langdata/ara/ara.training_text \
  --langdata_dir ../langdata \
  --lang ara  \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --fontlist "Arial" \
  --output_dir ~/tesstutorial/aratest
  
training/tesstrain.sh \
  --fonts_dir /c/Windows/Fonts \
  --tessdata_dir ./tessdata \
  --training_text ../langdata/ara/ara.training_text \
  --langdata_dir ../langdata \
  --lang ara  \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --fontlist "Arial" \
  "Arial Unicode MS" \
  "Calibri" \
  "Courier New" \
  --output_dir ~/tesstutorial/araeval

mkdir -p ~/tesstutorial/aratuned_from_aratest 

combine_tessdata -e ../tessdata/ara.traineddata \
  ~/tesstutorial/aratuned_from_aratest/ara.lstm
  
lstmtraining \
  --continue_from ~/tesstutorial/aratuned_from_aratest/ara.lstm \
  --train_listfile ~/tesstutorial/aratest/ara.training_files.txt \
  --eval_listfile ~/tesstutorial/araeval/ara.training_files.txt \
  --model_output ~/tesstutorial/aratuned_from_aratest/aratuned \
  --target_error_rate 0.01 
  ```

On windows using the binaries from appveyor artifacts, I am getting

```
$ lstmtraining \
>   --continue_from ~/tesstutorial/aratuned_from_aratest/ara.lstm \
>   --train_listfile ~/tesstutorial/aratest/ara.training_files.txt \
>   --eval_listfile ~/tesstutorial/araeval/ara.training_files.txt \
>   --model_output ~/tesstutorial/aratuned_from_aratest/aratuned \
>   --target_error_rate 0.01
Segmentation fault
```

I will check with tesseract built under WSL and report separately. I think crash happens in builds with debug. Non-debug builds get some error messages but continue. ```
(gdb) run
Starting program: /usr/local/bin/lstmtraining --continue_from /home/shree/tesstutorial/aratuned_from_aratest/ara.lstm --train_listfile /home/shree/tesstutorial/aratest/a
ra.training_files.txt --eval_listfile /home/shree/tesstutorial/araeval/ara.training_files.txt --model_output /home/shree/tesstutorial/aratuned_from_aratest/aratuned --ta
rget_error_rate 0.01
warning: Error disabling address space randomization: Success
warning: linux_ptrace_test_ret_to_nx: PTRACE_KILL waitpid returned -1: Interrupted system call
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Loaded file /home/shree/tesstutorial/aratuned_from_aratest/aratuned_checkpoint, unpacking...
Successfully restored trainer from /home/shree/tesstutorial/aratuned_from_aratest/aratuned_checkpoint
[New Thread 0x7f4e34110700 (LWP 24)]
Loaded 81/81 pages (1-81) of document /home/shree/tesstutorial/aratest/ara.Arial.exp0.lstmf
[Thread 0x7f4e34110700 (LWP 24) exited]
[New Thread 0x7f4e34110700 (LWP 25)]
Loaded 81/81 pages (1-81) of document /home/shree/tesstutorial/araeval/ara.Arial.exp0.lstmf
[Thread 0x7f4e34110700 (LWP 25) exited]
[New Thread 0x7f4e33900700 (LWP 26)]
Loaded 81/81 pages (1-81) of document /home/shree/tesstutorial/araeval/ara.Arial_Unicode_MS.exp0.lstmf
[Thread 0x7f4e33900700 (LWP 26) exited]
[New Thread 0x7f4e33900700 (LWP 27)]
[New Thread 0x7f4e34110700 (LWP 28)]
[New Thread 0x7f4e325c0700 (LWP 29)]
[New Thread 0x7f4e315a0700 (LWP 30)]
lstmtraining: ../ccutil/genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

Program received signal SIGABRT, Aborted.
[Switching to Thread 0x7f4e315a0700 (LWP 30)]
0x00007f4e36ff6c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
56      ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.
(gdb) backtrace
#0  0x00007f4e36ff6c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
#1  0x00007f4e36ffa028 in __GI_abort () at abort.c:89
#2  0x00007f4e36fefbf6 in __assert_fail_base (fmt=0x7f4e371403b8 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n",
    assertion=assertion@entry=0x4f48b8 "index >= 0 && index < size_used_", file=file@entry=0x4f489a "../ccutil/genericvector.h", line=line@entry=713,
    function=function@entry=0x4f55a0 <GenericVector<char>::operator[](int) const::__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]")
    at assert.c:92
#3  0x00007f4e36fefca2 in __GI___assert_fail (assertion=0x4f48b8 "index >= 0 && index < size_used_", file=0x4f489a "../ccutil/genericvector.h", line=713,
    function=0x4f55a0 <GenericVector<char>::operator[](int) const::__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:101
#4  0x0000000000406bef in GenericVector<char>::operator[] (this=0x7ffffd882960, index=0) at ../ccutil/genericvector.h:713
#5  0x000000000043d308 in tesseract::LSTMTrainer::ReadTrainingDump (this=0x7f4e3159f650, data=..., trainer=0x7f4e3159f650) at lstmtrainer.cpp:921
#6  0x000000000040b8cb in tesseract::LSTMTester::RunEvalSync (this=0x7ffffd8828f0, iteration=24, training_errors=0x7ffffd882fb8, model_data=..., training_stage=1)
    at lstmtester.cpp:86
#7  0x000000000040bc2f in tesseract::LSTMTester::ThreadFunc (lstmtester_void=0x7ffffd8828f0) at lstmtester.cpp:123
#8  0x00007f4e37de8184 in start_thread (arg=0x7f4e315a0700) at pthread_create.c:312
#9  0x00007f4e370ba37d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111
(gdb)
``` @Stweil Unrelated to this issue, one of the recent commits seems to have caused the program to slow down a lot - while training it seems to hang for a while and even OCRing images seems to take longer. I am not sure how to verify/confirm this. @stweil I don't see any patch here. >#6  0x000000000040b8cb in tesseract::LSTMTester::RunEvalSync (this=0x7ffff40f2d00, iteration=0, training_errors=0x7ffff40f33c8, model_data=..., training_stage=0)     at lstmtester.cpp:86

Should the model_data here be pointing to --eval_listfile or lstmf files within it? @stweil Thank you for looking into this. https://github.com/tesseract-ocr/tesseract/issues/956

may also be related.  @theraysmith 

Under what conditions should eval be run from trainer? 

Will training work if it is done without eval? https://github.com/DanBloomberg/leptonica/releases/tag/1.74.3

Should we be using this for 4.00? @stweil 

When training with --eval_listfile  in addition to --train_listfile, I have noticed that while all files from --train_listfile are loaded at beginning of training process, only first two from --eval_listfile are loaded. However, I have not found any images from the --eval_listfile being used in the training (I am going by the detailed log per iteration which is displayed with --debug_interval -1.

Does this mean that eval is still not being run?

Or, does the eval process not write the log message?

If it is a question of not logging, is it possible to modify to add the log message during evaluation?
 > does the eval process not write the log message?

Answered in https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00

With --debug_interval -1, the trainer outputs verbose text debug for **every training iteration.**

@stweil  Eval seems to be running now (though there are no debug messages to verify it). Thanks for the fix. 

Should I close this issue or does it need any other verification? 

 @xlight Thanks to patches by @stweil and leptonica 1.74.2, the assertion and problem with uninitialized data related to this issue are fixed when using the latest code from github.. 

@theraysmith will have to verify that his original problem has been fixed, since I do not know what exact test he was referring to in his comment ...
>it doesn't run the eval from the trainer.
 2 Percent improvement time=12184, best error was 8.073 @ 23307

**Warning: LSTMTrainer deserialized an LSTMRecognizer!**

At iteration 35491/53200/53202, Mean rms=0.165%, delta=1.673%, char train=6.063%, word train=19.746%, skip ratio=0%,  New best char error = 6.063

**At iteration 33032, stage 1, Eval Char error rate=19.697385, Word error rate=42.197884**

 wrote checkpoint.

At iteration 35535/53300/53302, Mean rms=0.166%, delta=1.706%, char train=6.108%, word train=19.751%, skip ratio=0%,  New worst char error = 6.108

**At iteration 34063, stage 1, Eval Char error rate=20.580924, Word error rate=41.515177**

 wrote checkpoint.


_________________________________________

Eval is being run from trainer. Closing the issue. Thanks, @stweil.
 @theraysmith 

Latest code change has reverted the fix.

```
Iteration 99: ALIGNED TRUTH : च छ ज झ ञ उ ऊ ट ठ ड ढ ण ऋ ॠ त थ
Iteration 99: BEST OCR TEXT :
File /tmp/tmp.m82dWGBYZW/mar/mar.Aparajita.exp0.lstmf page 3 :
Mean rms=5.427%, delta=53.011%, train=110.2%(100%), skip ratio=0%
lstmtraining: genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
Aborted (core dumped)
``` Yes a new bug. I was mystified for a while, but it is very simple.
Fixed in 4b6f0b95..f4f66f8f Fixed by 45fb7dd  @WilliamTambellini: can you please post config.log and output from configure? Just a side though: adding that test will add a 2nd dependency on autoconf-archive. This is fine (autoconf-archive should be available for all relevant hosts) – but as autoconf-archive is often not installed, that case needs a more user friendly error message than today. If we had a simple way to detect whether `autoconf-archive` is missing, `autogen.sh` could also download the missing m4 flies when needed. I think this is possible even with a less permissive license. We already have test for c++11 support (without dependency on autoconf-archive). So it should be enough to modify test to produce error in case of missing c++11 support...  Please use tesseract user forum for asking questions/support.  Please provide files (input files, output files) that demonstrate your issue. also provide more information about you OS, tesseract etc.  Please use tesseract user form for asking questions, support...  We're going to get corrupt output if an open paren is passed as a title.
Proper escaping look like this. The leading FEFF is boilerplate that 
signifies the byte order, everything else is UTF-16BE. The title in this
case is "ru"

```
<< /CreationDate (D:20170103154208-08'00') /Producer (Tesseract 2000) /Title <FEFF00720075> >>
```

https://github.com/tesseract-ocr/tesseract/blob/master/api/pdfrenderer.cpp#L963 Dan's Leptonica change is for a different code path and is not reusuable, because it only works for ASCII. The Tesseract fix needs to use UTF16-BE, which is fortunately already used elsewhere in pdfrenderer.cpp. Fix written, under review. EDIT: I've revised the fix to remove a compiler warning.

```
--- tesseract/api/pdfrenderer.cpp	2017-03-30 16:10:23.000000000 -0700
+++ tesseract/api/pdfrenderer.cpp	2017-03-31 13:16:22.000000000 -0700
@@ -159,7 +159,7 @@
 
 OK there is a small problem there, if I use GID 0 then Acrobat gets
 upset about it and complains it cannot extract the font. If I set the
-CIDToGIDMap so that all the entries are 1 instead, its happy. Totally
+CIDToGIDMap so that all the entries are 1 instead, it's happy. Totally
 mad......
 
 */
@@ -169,10 +169,15 @@
 // Use for PDF object fragments. Must be large enough
 // to hold a colormap with 256 colors in the verbose
 // PDF representation.
-const int kBasicBufSize = 2048;
+static const int kBasicBufSize = 2048;
 
 // If the font is 10 pts, nominal character width is 5 pts
-const int kCharWidth = 2;
+static const int kCharWidth = 2;
+
+// Used for memory allocation. A codepoint must take no more than this
+// many bytes, when written in the PDF way. e.g. "<0063>" for the
+// letter 'c'
+static const int kMaxBytesPerCodepoint = 20;
 
 /**********************************************************************
  * PDF Renderer interface implementation
@@ -303,6 +308,23 @@
   if (rise < 2.0 && 2.0 < run)
     *line_y1 = *line_y2 = (y1 + y2) / 2;
 }
+
+bool CodepointToUtf16be(int code, char utf16[kMaxBytesPerCodepoint]) {
+  if ((code > 0xD7FF && code < 0xE000) || code > 0x10FFFF) {
+    tprintf("Dropping invalid codepoint %d\n", code);
+    return false;
+  }
+  if (code < 0x10000) {
+    snprintf(utf16, kMaxBytesPerCodepoint, "%04X", code);
+  } else {
+    int a = code - 0x010000;
+    int high_surrogate = (0x03FF & (a >> 10)) + 0xD800;
+    int low_surrogate = (0x03FF & a) + 0xDC00;
+    snprintf(utf16, kMaxBytesPerCodepoint,
+             "%04X%04X", high_surrogate, low_surrogate);
+  }
+  return true;
+}
 
 char* TessPDFRenderer::GetPDFTextObjects(TessBaseAPI* api,
                                          double width, double height) {
@@ -442,25 +464,13 @@
       if (grapheme && grapheme[0] != '\0') {
         GenericVector<int> unicodes;
         UNICHAR::UTF8ToUnicode(grapheme, &unicodes);
-        char utf16[20];
+        char utf16[kMaxBytesPerCodepoint];
         for (int i = 0; i < unicodes.length(); i++) {
           int code = unicodes[i];
-          // Convert to UTF-16BE https://en.wikipedia.org/wiki/UTF-16
-          if ((code > 0xD7FF && code < 0xE000) || code > 0x10FFFF) {
-            tprintf("Dropping invalid codepoint %d\n", code);
-            continue;
+          if (CodepointToUtf16be(code, utf16)) {
+            pdf_word += utf16;
+            pdf_word_len++;
           }
-          if (code < 0x10000) {
-            snprintf(utf16, sizeof(utf16), "<%04X>", code);
-          } else {
-            int a = code - 0x010000;
-            int high_surrogate = (0x03FF & (a >> 10)) + 0xD800;
-            int low_surrogate = (0x03FF & a) + 0xDC00;
-            snprintf(utf16, sizeof(utf16), "<%04X%04X>",
-                     high_surrogate, low_surrogate);
-          }
-          pdf_word += utf16;
-          pdf_word_len++;
         }
       }
       delete []grapheme;
@@ -471,9 +481,9 @@
           kCharWidth * prec(100.0 * word_length / (fontsize * pdf_word_len));
       pdf_str.add_str_double("", h_stretch);
       pdf_str += " Tz";          // horizontal stretch
-      pdf_str += " [ ";
+      pdf_str += " [ <";
       pdf_str += pdf_word;       // UTF-16BE representation
-      pdf_str += " ] TJ";        // show the text
+      pdf_str += "> ] TJ";       // show the text
     }
     if (last_word_in_line) {
       pdf_str += " \n";
@@ -960,15 +970,27 @@
   offsets_.back() += pages_objsize;    // manipulation #2
 
   // INFO
+  STRING utf16_title = "FEFF";  // byte_order_marker
+  GenericVector<int> unicodes;
+  UNICHAR::UTF8ToUnicode(title(), &unicodes);
+  char utf16[kMaxBytesPerCodepoint];
+  for (int i = 0; i < unicodes.length(); i++) {
+    int code = unicodes[i];
+    if (CodepointToUtf16be(code, utf16)) {
+      utf16_title += utf16;
+    }
+  }
+
   char* datestr = l_getFormattedDate();
   n = snprintf(buf, sizeof(buf),
                "%ld 0 obj\n"
                "<<\n"
                "  /Producer (Tesseract %s)\n"
                "  /CreationDate (D:%s)\n"
-               "  /Title (%s)"
+               "  /Title <%s>\n"
                ">>\n"
-               "endobj\n", obj_, TESSERACT_VERSION_STR, datestr, title());
+               "endobj\n",
+               obj_, TESSERACT_VERSION_STR, datestr, utf16_title.c_str());
   lept_free(datestr);
   if (n >= sizeof(buf)) return false;
   AppendPDFObject(buf);
--- tesseract/api/renderer.h	2017-03-30 16:10:23.000000000 -0700
+++ tesseract/api/renderer.h	2017-03-31 10:34:40.000000000 -0700
@@ -57,6 +57,7 @@
     /**
      * Starts a new document with the given title.
      * This clears the contents of the output data.
+     * Title should use UTF-8 encoding.
      */
     bool BeginDocument(const char* title);

```  https://github.com/tesseract-ocr/tesseract/issues/233
https://github.com/tesseract-ocr/tesseract/commit/11f205707eda769dbe6cc7d6839745f1b01a1d76

When this patch was submitted, we reduced multipage TIFF seeks O(n).
But that's only on the regular code path. The OpenCL code path is still O(n^3).
That's not really sensible. Recommend removing the OpenCL path from 
ProcessPagesMultipageTiff() and then thinking about next steps.

To be honest, it's pretty hard to keep code synchronized and I'm a little
curious why current approach was chosen, versus integrating
OpenCL calls directly into much lower level libraries such as Libtiff.
Libtiff is doing the actual computational work, such G4 decompression. Getting back to ProcessPagesMultipageTiff(), there is no work being done by Leptonica. It is just TIFF decode and all computation is being done by Libtiff. Anyway, the OpenCL code is now behind. It should either be re-synchronized, migrated to libtiff, or disabled. No sense in keeping it as an O(n^3) code path. This would disable the O(n^3) codepath (where n is the number of pages inside the multipage tiff). It would have the side effect of turning fairly large quantities of Tesseract's OpenCL code into unreachable dead code.

```diff
--- baseapi.cpp.orig	2017-01-26 13:10:45.011521878 -0800
+++ baseapi.cpp	2017-01-26 13:11:12.511896362 -0800
@@ -980,26 +980,13 @@
                                             int tessedit_page_number) {
 #ifndef ANDROID_BUILD
   Pix *pix = NULL;
-#ifdef USE_OPENCL
-  OpenclDevice od;
-#endif  // USE_OPENCL
   int page = (tessedit_page_number >= 0) ? tessedit_page_number : 0;
   size_t offset = 0;
   for (; ; ++page) {
     if (tessedit_page_number >= 0)
       page = tessedit_page_number;
-#ifdef USE_OPENCL
-    if ( od.selectedDeviceIsOpenCL() ) {
-      pix = (data) ?
-          od.pixReadMemTiffCl(data, size, page) :
-          od.pixReadTiffCl(filename, page);
-    } else {
-#endif  // USE_OPENCL
       pix = (data) ? pixReadMemFromMultipageTiff(data, size, &offset)
                    : pixReadFromMultipageTiff(filename, &offset);
-#ifdef USE_OPENCL
-    }
-#endif  // USE_OPENCL
     if (pix == NULL) break;
     tprintf("Page %d\n", page + 1);
     char page_str[kMaxIntSize];
``` @jbreiden: Thanks. Can you please discuss with Ray about rest of OpenCl code? It is simple not maintained (I took 2 years to get fixes for reported issues) Last week Ray said he was still looking into removing the non LSTM recognizer, which is still in use for OSD which is orientation script detection. If that is successful, I think that 100% of the opencl code will be unused.  If that happens I suspect the next step is removal. (In general I like both AMD and the idea of faster computation to the GPU, but not enough to keep unmaintained code.)  Correct. Changing instructions now...  ​​
​it seems this problem occur in other multi lingual process to
i face this kind of error on Arabic+English scan
 ​im working on ubuntu16 and teseract is maked from latest source​...
 Mostly fixed by commit b453f74.  Debug mode is known to be ~50x slower than optimized mode.
Please re-open if you are seeing this slow-down in optimized mode.  This looks like an error for 32 bit x86 platforms. You can work around it by removing the line `#  define X86_BUILD 1` from `arch/simddetect.cpp`. @Izaron, yes, but it will be much slower.

@amitdo, there are several options:

* Let the compiler do the optimization (and forget that explicit SSE/AVX code). This is my preferred solution as it also works for ARM and other architectures.

* Fix the current code, so 32 bit Intel does not use AVX (it could use SSE).

* Fix the current code, so 32 bit Intel can use AVX, but avoids unavailable 64 bit intrinsics.

No need to fix this this year – for the rest of the year I have other priorities. Happy new year!
 Yes, sure. You need the compiler option `-ftree-vectorize`. In addition, the compiler must know which kind of FPU is available. The compiler option `-O3` includes `-ftree-vectorize`. So for an Intel CPU, `-O3 -mtune=native -mavx` should work. An ARM CPU could use `-O3 -mfpu=neon -funsafe-math-optimizations`. See https://gcc.gnu.org/onlinedocs/gcc/ARM-Options.html for more information. There's huge variation of SIMD support even in modern processors. For example I have an Intel CPU purchased in 2016 (Pentium G4400 Skylake) that doesn't support AVX instructions at all. Statistically speaking, most Tesseract users run precompiled binaries. Finally, Tesseract ships on more than 20 hardware platforms for Debian GNU/Linux alone, not to mention all those other operating systems.

https://buildd.debian.org/status/package.php?p=tesseract&suite=unstable

This is a tough combination. Ideally a binary will uses the fastest SIMD instructions available for the processor, and determines those instructions at runtime rather than at compile time. There's lots of discussion on the web about this, but it is not clear to me what is best practice.

 Yes, binary distributions must support a wide range of hardware and ideally chose the best code at runtime.
That's why we need `simddetect.cpp` (with extensions for non Intel platforms).

Nevertheless there is also the need for highly optimized Tesseract installations used for training or mass production of OCR on know hardware. > The non-SIMD version of the dotproduct method can be significantly sped up by doing manual loop unrolling.

Which test scenario do you use? This is again (or still) a bug for 32 bit Intel platforms. I'll have a look how to fix it later. This issue is addressed by pull request #698. @const-volatile, did you use `cmake`? Then that still needs a fix. PR #698 only addressed builds with `configure`. @nguyenq, could you please try replacing `#if !defined(__AVX__) || defined(__i386__)` in file `arch/dotproductavx.cpp` by a simple `#if !defined(__AVX__)` and report whether the resulting `tesseract.exe` works with AVX? It would also be interesting how the OCR speed compares with your current `tesseract.exe`.

Recently support for AVX with 32 bit executables was added, but it needs the above modification to get activated. Run `tesseract -v` to see whether you have a CPU which supports AVX or SSE. The error message which you get indicates that you have AVX support. Please try the even shorter variant `#if 0` to enforce that the AVX code is included (and not the _DotProductAVX can't be used on Android_ error message). It looks as if your compiler does not define the macro `__AVX__`. This modification might set `__AVX__` (I cannot test it because I don't have MSVC):

    diff --git a/CMakeLists.txt b/CMakeLists.txt
    index d227b7d..1805170 100644
    --- a/CMakeLists.txt
    +++ b/CMakeLists.txt
    @@ -220,6 +220,7 @@ if (WIN32)
         if (MSVC)
             set_source_files_properties(
                 ${CMAKE_CURRENT_SOURCE_DIR}/arch/dotproductavx.cpp
    +            PROPERTIES COMPILE_DEFINITIONS __AVX__)
                 PROPERTIES COMPILE_FLAGS "/arch:AVX")
         endif()
     endif()
 It's strange that the macro `__AVX__` is not set automatically by MSVC. The compiler option `/arch:AVX` should normally do that (see [documentation](https://msdn.microsoft.com/en-us/library/7t5yh4fd.aspx)). With the latest code, you should point your tessdata_dir to tessdata/best

On 17-Aug-2017 10:41 AM, "Amit D." <notifications@github.com> wrote:

> From where did you get the chi_tra and eng traineddata?
> From here:
> https://github.com/tesseract-ocr/tessdata/tree/3.04.00
> Or from here:
> https://github.com/tesseract-ocr/tessdata/tree/master/best
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/631#issuecomment-322970548>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o5gN3GvgUYBBX6NKL_cYbnaZVL2dks5sY8uYgaJpZM4LYhc->
> .
>
  ​i checked Arabic today
with default trained data it have about 80% accuracy
what are you looking for?​
 ​as i said i got the result with official trainedata
i dont started to my own training yet...​
 ​@shree ubuntu 16lts​
  Closing as it is in 'nice to have' category rather than a bug.  -1 for laziness (not reading [doc](https://github.com/tesseract-ocr/tesseract/blob/master/INSTALL.GIT.md) and not searching other issues e.g. #601 and #610). Information in INSTALL.GIT.md
<https://github.com/tesseract-ocr/tesseract/blob/master/INSTALL.GIT.md> is
there already 4 days...And of course: installing from source expect that
user is  familiar with compiling software on your operation system.


Zdenko

On Fri, Dec 30, 2016 at 6:40 PM, Amit D. <notifications@github.com> wrote:

> Yesterday I added the missing dependency to this wiki page:
> https://github.com/tesseract-ocr/tesseract/wiki/Compiling
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/628#issuecomment-269799789>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAjCzKAoOyhzzY3iubDssVKSAJrJVGFWks5rNUIVgaJpZM4LX3JC>
> .
>
 Replying in reverse order ;-) (based on importance):

1. Patches are welcomed!
2. Error message is output of autoconf. Maybe other test for compiler parameter would be more suitable, but this one seems to be standard (based on few minutes of googling).
3. Installing sw from source without tracking dependencies (or at lease reading INSTALL file) is IMO nonsense.  Vertical Japanese is not yet trained on LSTM.
  How did you run Tesseract (which command line options, which image)? I can reproduce the problem. It only happens when Tesseract is built with a shared library (`libtesseract.so`). The crash occurs because the constructor of the global variable `debug_file` was not called at the time when `SIMDDetect::SIMDDetect` is executed. For the moment, removing the `tprintf` statements in `arch/simddetect.cpp` helps. Fixed with pull request #625.  This is not related to tesseract project  Please read the [documentation](https://github.com/tesseract-ocr/tesseract/wiki/Data-Files).  That's not code from latest Tesseract. Please close this issue here and report it at the right place (wherever that is). @ruochenxing : can you please clarify if there was problem with tesseract (if yes which branch you used)? and how did you fix it?  Please use tesseract user forum for asking support.  First of all: It seem like output from some tesseract wrapper. We do not provide support for 3d party sw. 
Next: Use tesseract user forum for asking support. Please follow [instruction](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md) and make sure you read [wiki first](https://github.com/tesseract-ocr/tesseract/wiki) (at least FAQ and ImproveQuality).  Modify also the code to use a singleton. This simplifies the code as
no locking is needed. It also slightly improves the performance because
no check whether the architecture was tested is needed.

Signed-off-by: Stefan Weil <sw@weilnetz.de>   This PR addresses issue #517. The detection code was tested with Mingw-w64 (which supports both the gcc and the MSVC specific code), but I cannot test builds with MSVC. [AppVeyor](https://ci.appveyor.com/project/zdenop/tesseract/build/3.05.560) tests that and passed both for 32 and 64 bit. @zdenop, https://ci.appveyor.com/project/zdenop/tesseract/build/3.05.560 still includes 3.05 in the URL. @stweil I change build version format to "{branch}.{build}" (from "3.05..{build}". Lets see if it helps. Looks good, thank you. Good idea. Done in PR #618.  Please use tesseract user forum for asking support  text2image cannot be built with cmake on windows.
Let me try  to build tess with your steps. (I'll report here.) Works for me. What version of tesseract are you using?
I've already fixed issues you report on master, but not on the other branches. Oh, you probably have old cmake.
Which cmake version do you have?
3.6 is known to not work with tess right now (your errors). I'll add an error message for cmake 3.6 (on cppan side).  Problem is that you modified code without knowing what you are doing. Did you check comment on https://github.com/tesseract-ocr/tesseract/issues/601? @Vidushi12, please don't post your question on several places (even if it is urgent for you).

Did you compile Tesseract yourself or do you use a pre-build version? Can you use Tesseract 3.05 or an earlier version? Tesseract 4.x is experimental and not for end users currently. @Vidushi12, I suggest to use the Tesseract provided by Ubuntu and don't build it yourself. Just run `apt-get install tesseract-ocr tesseract-ocr-eng` (add more languages as needed) as root user. You can either remove `/usr/local/bin/tesseract`, or don't uninstall it and call `/usr/bin/tesseract` explicitly. Yes, that's it.  @amitdo:
What is benefit/difference between `[lept >= 1.74]` and `[lept >= 1.74.0]`?
BTW: `pkg-config --modversion lept` shows 1.74 Well [allheaders.h](https://github.com/DanBloomberg/leptonica/blob/master/src/allheaders.h#L31) defines only LIBLEPT_MAJOR_VERSION (1) and LIBLEPT_MINOR_VERSION (74), so I see no reason to change... It's a switch to semver also. 1.74.0 tag in git and version numbers in code/build tools. For cmake `1.74` and `1.74.0` are equal. And travis needs precise git tag to work. At least for cmake 3.6.2 only 1.74 but not 1.74.0 works. Tested on Raspbian. I am not near a computer to check. Does Tesseract 3.04 build against
Leptonica 1.74? It is this version number stuff causing trouble?

On Dec 26, 2016 6:31 AM, "Stefan Weil" <notifications@github.com> wrote:

At least for cmake 3.6.2 only 1.74 but not 1.74.0 works. Tested on Raspbian.

—
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub
<https://github.com/tesseract-ocr/tesseract/pull/608#issuecomment-269216105>,
or mute the thread
<https://github.com/notifications/unsubscribe-auth/AEu2phQlhZsUnHI3zUF9VY1LXj19gYi-ks5rL8-jgaJpZM4LVW_Z>
.
 I just ran a test with cmake 3.7.1-1 on Debian GNU Linux. It also works only with 1.74, but not with 1.74.0. I am in the snowy hinterlands, won't be able to advise until new year. So
far I can't tell if this is important or not. If I had to guess, we are
probably fine, especially if the autoconf build on Tesseract had no issues.
(I just want to keep the chaos level low in the world of Debian packages)

On Dec 28, 2016 9:00 AM, "Dan Bloomberg" <notifications@github.com> wrote:

Seems like we have a problem with the 1.74.0 version numbering. What do
you suggest that we do here? New github release? Replacement? Nothing?

On Mon, Dec 26, 2016 at 2:10 PM, Stefan Weil <notifications@github.com>
wrote:


> I just ran a test with cmake 3.7.1-1 on Debian GNU Linux. It also works
> only with 1.74, but not with 1.74.0.
>
> —
> You are receiving this because you were mentioned.

> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/608#
issuecomment-269245065>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLNTIpQ9_
c7fCyh6OFkdZidkx24NCks5rMDtvgaJpZM4LVW_Z>
> .
>

—
You are receiving this because you commented.

Reply to this email directly, view it on GitHub
<https://github.com/tesseract-ocr/tesseract/pull/608#issuecomment-269506129>,
or mute the thread
<https://github.com/notifications/unsubscribe-auth/AEu2prjMBcM6137QaP9GwOgubdDmKBDUks5rMpW7gaJpZM4LVW_Z>
.
 Dan, the issue (if any) is probably somewhere in autotools config on lept side. No need to rename git tag, it's fine. In case of any critical changes, you could remove tag and add it again, or just make 1.74.1 release with fixes. Yes, I think this is the reason why 1.74.0 did not work for me. I suggest using 1.74.1. Fixes are needed for `README.html`, `configure.ac` and `version-notes.html`. ... and `CMakeLists.txt`. @DanBloomberg: if you decide to implement version format "1.74.1" do not forget to implement it into allheaders.h as LIBLEPT_MAJOR_VERSION (1), LIBLEPT_MINOR_VERSION (74) and LIBLEPT_MICRO_VERSION (1)...
 `LIBLEPT_MICRO_VERSION` would be a new interface. IMHO it is not necessary, because C code should not depend on the patch level or micro version. Or better LIBLEPT_PATCH_VERSION as in semver (major.minor.patch).  This was fixed in commit 53c572b4.  I cannot say whether this is an error without seeing the screenshot – did it contain text?

Usually text in a screen-shot has a low resolution, something typically at most 120 dpi. For Tesseract, 300 dpi are suggested. You can try to rescale your screen-shot. Or you can try the experimental Tesseract 4.  see comments in https://github.com/tesseract-ocr/tesseract/issues/373  @yakeer: if tesseract is dependency for other library/application I would suggest to use stable release [3.04.01](https://github.com/tesseract-ocr/tesseract/releases/tag/3.04.01) or [3.05 branch](https://github.com/tesseract-ocr/tesseract/tree/3.05) (bug fixes for 3.04 version with small enhancement of API) @yakeer: please check current master if it compile on Raspberry Pi 3. `sudo apt-get install autoconf-archive`
see: http://stackoverflow.com/questions/30412576/autotools-syntax-error-with-ax-check-compile-flag Is this still an issue, or can it be closed? I could successfully compile Tesseract on Raspbian using configure / make.  Use tesseract user forum for asking support  Please use tesseract user forum for asking question/support.  No, it's on our side. Working on it.  This fixes a build regression caused by commit
d70f3c36635c251ac3286063c6c29d10b815a565.

Signed-off-by: Stefan Weil <sw@weilnetz.de> Do we still need autotools?
What do you think? Maybe elaborate more on cmake? Personally I'm more used to autotools (> 10 years) than to cmake (< 1 year). Therefore I usually build with configure && make. But of course supporting both autotools and cmake wastes resources and requires more testing. Nice, but too heavy. It uses python.
Build system (and other technical tools) for a general-purpose language must be written in the same language or in more low level language, but not higher level lang. than this. Examples:
autotools is written in C
cmake in C++
We use c++, so we need something in C++,C,ASM. :) And that's not good.
CMake is C++ (with some C libs) and no other deps. > And that's not good.
it depends on criteria ;-) On linux that are (almost) always installed smoothly. 
With cmake I had issues - e.g. when I build and installed some basic lib cmake on windows (AFAIR png) - cmake was not able to find it after installation. It never happens with autotools on linux. I several times started to use cmake, but...

I am glad for cmake support in tesseract because of windows, but I would keep autotools because of linux. And I am willing to maintained it ;-)
  > And I am willing to maintained it ;-)

Ok, not a problem.

> With cmake I had issues 

Me too. That's why I'm developing CPPAN. We already can build the same training tools as with cmake  on windows. So, we have parity at the moment. And in the future I hope will be able to build the last training tool - text2image on windows - which is very hard with pure cmake. The [UB Mannheim Windows binaries](https://github.com/UB-Mannheim/tesseract/wiki) include `text2image.exe` and were built using autotools. They are built with gcc (mingw) which is not a big advantage.
We don't need mingw (cygwin/other linux port stuff) build. We need msvc build. Actually, it requires pango, cairo and some other libs. See https://github.com/tesseract-ocr/tesseract/blob/master/training/CMakeLists.txt#L265
And in total all their deps contain about 15 indirect deps.

You may notice that building deps on windows (msvc) is not so easy task.
You should find every lib, make it compile on windows, include to your project and to each other etc.  I'd like to propose changes to tesseract source tree structure.
Today the common way is to have `src` folder with all program stuff and `include` folder with public headers. Now we have a lot of dirs in the root - that's very annoying.
On the first stage I propose:
1. move all sources into `src`
2. move training tools from `training` to `tools/training`

Later we can try to move public headers to `include` directory.

The new look will be like:
![pic](http://i.imgur.com/K8NkI8T.png)

If there are no objections, I'll commit changes. Make sure to get positive confirmation from Ray before doing something like this. He's considering a different, very disruptive change involving the non-LSTM recognizer. It would collide very badly with source reorganization. Yes, I'll act only in case of positive reply from Ray.  @theraysmith @zdenop 

This PR replaces all 4.00.00 version numbers to 4.0.0.
The idea is to follow semantic versioning since 4.0.0 branch. https://semver.org
Following git tags should be also named as `X.Y.Z[-name]`, e.g. `4.0.0`, `4.0.1`, `4.0.0-beta`, `4.0.0-rc.1` etc. @egorpugin Isn't it better to change to the new versioning scheme while 4.0 is still in development branch?

Does @zdenop need to change the git tag? No need to change old git tags (even 4.00.00alphas), but we need to decide versioning until release.  Try to update tesseract from master, upgrade cppan (if you're not on the latest client `cppan --self-upgrade`), run cmake as `cmake ..` and not `cmake .. -DSTATIC=1`. I've removed STATIC flag from wiki page. Can you do please following steps and send `1.txt` and `2.txt` to me?
```
cppan --clean-packages .*unicode.*
cppan
mkdir win32
cd win32
cmake .. > 1.txt 2>&1
cmake --build . --config Release > 2.txt 2>&1
```
 What VS do you have? Is it VS 2015?
The error is:
```
c:\users\home\.cppan\storage\src\2f\16\8f89\libtiff\tiffiop.h(56): error C2143: ?????????????? ??????: ?????????? ")" ????? "*" (????????????? ???????? ???? 
```
It's hard to understand it from gist. :) I see. Probably there are some issues with your environment.
```
-- include search.h - not found
-- function lfind - not found
```
This file and function cannot be found on your system for some reason, but actually they're available.
I'm thinking on how we can fix this. How do you want to use tess?
If you have a project with cmake build, see this example https://github.com/cppan/tesseract_example/tree/master/with_cmake

If you want to build that file https://github.com/cppan/tesseract_example/blob/master/with_cppan/main.cpp
run from command line 
```
cppan --build https://github.com/cppan/tesseract_example/raw/master/with_cppan/main.cpp
```
The VS solution appear in that folder (and the file itself). Could you contact me in some IM chat?
Probably we could find solution faster.
Maybe in skype (username - egor.pugin). Sorry, updated previous comment with correct username.  See https://github.com/tesseract-ocr/tesseract/issues/832 
for LSTM : Training - Support WordStr Box file option #832

Closing this issue as LSTM training process has changed.  Changing tesstrain_utils.sh for 

`  common_args+=" --leading=${LEADING} --xsize 2550"`
fixes this.
 Usually this happens for just a few lines of an image - tesseract splits the input image into separate image  per line.

It could be when layout analysis has wrongly segmented the page  or a line has been detected as having hundreds of diacritics.

If it is just a few messages, you could ignore.

@theraysmith Any update regarding new line detection algorithm? The exact error message would greatly help diagnose the problem.

On Tue, Aug 8, 2017 at 10:28 PM, Amit D. <notifications@github.com> wrote:

> Image too large to learn!! Size = 2758x48
> Image not trainable
>
> @hanikh <https://github.com/hanikh>, please paste a short example for the
> errors you get.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/590#issuecomment-321156352>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056TBM3518EXdJE7-KA44mvwgN2Mx2ks5sWUNhgaJpZM4LQsPF>
> .
>



-- 
Ray.
 > I finetuned tesseract for farsi (40 fonts on 6000 text lines)

I think this maybe too much for finetuning.

I noticed that tesstrain.sh is limiting  text2image generated images to
just 3 pages - that would be only max 150 lines per font.

With that much input, you can try replace a layer training to see if that
gets you better results.



ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sat, Aug 12, 2017 at 3:27 PM, hanikh <notifications@github.com> wrote:

> @theraysmith <https://github.com/theraysmith> would you please help me,
> how many text line is appropriate?
> thanks
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/590#issuecomment-321970660>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o4rV-DPLTiSAqgSTy9dJdA3Oek6iks5sXXcJgaJpZM4LQsPF>
> .
>
 @hanikh I suggest to wait till Ray updates the langdata and also uploads
the new version of unichar_extractor. Befroe that training for RTL
languages may not be give useful results.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sat, Aug 12, 2017 at 4:04 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
wrote:

> > I finetuned tesseract for farsi (40 fonts on 6000 text lines)
>
> I think this maybe too much for finetuning.
>
> I noticed that tesstrain.sh is limiting  text2image generated images to
> just 3 pages - that would be only max 150 lines per font.
>
> With that much input, you can try replace a layer training to see if that
> gets you better results.
>
>
>
> ShreeDevi
> ____________________________________________________________
> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>
> On Sat, Aug 12, 2017 at 3:27 PM, hanikh <notifications@github.com> wrote:
>
>> @theraysmith <https://github.com/theraysmith> would you please help me,
>> how many text line is appropriate?
>> thanks
>>
>> —
>> You are receiving this because you modified the open/close state.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/590#issuecomment-321970660>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AE2_o4rV-DPLTiSAqgSTy9dJdA3Oek6iks5sXXcJgaJpZM4LQsPF>
>> .
>>
>
>
 Initial problem: (Image too small to scale)
Those images are ridiculously small at 3x48 pixels. Something is going
wrong somewhere with the images.
Are they oriented vertically? The input scaling scales the height to 48,
whatever it starts as, so it looks like your textlines are vertical.

Fine tuning problem:
The problem is most likely too many iterations. It will hone its accuracy
to whatever training data you give it if you run it for too many iterations.
See how few iterations are used in the training tutorial for fine tuning.

On Sat, Aug 12, 2017 at 5:19 AM, hanikh <notifications@github.com> wrote:

> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Compute CTC targets failed!
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Compute CTC targets failed!
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> Image too small to scale!! (3x48 vs min width of 3)
> Line cannot be recognized!!
> Image not trainable
> 2 Percent improvement time=0, best error was 2.167 @ 14
> At iteration 14/1100/20884, Mean rms=0.049%, delta=0%, char train=0%, word
> train=0%, skip ratio=1798.6%, New best char error = 0 wrote best
> model:/home/fanasa/tesstutorial/fastuned_from_fas/fastuned-plates0_14.lstm
> wrote checkpoint.
>
> Finished! Error rate = 0
> this is the error I got during training for licence plates.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/590#issuecomment-321977639>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056ZvLnyg_aC1mUg2gH34puAGpWdOOks5sXZhHgaJpZM4LQsPF>
> .
>



-- 
Ray.
 Ray,

I have seen line too small to be recognized when building box/tiff pairs
using tesstrain.sh - it is usually related to 'nnn diacritics found' - so
it  may be related to accents being treated as a separate line.

Regarding finetuning, I have experimented a lot with Devanagari - with
smaller number of iterations, the reported error rate is higher. And it
takes tens of thosands of iterations for it to get more accuracy on
training set - not sure of its effect on samples it has not seen. - see
https://github.com/Shreeshrii/tess4training/blob/master/README.md



ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sun, Aug 13, 2017 at 9:44 AM, theraysmith <notifications@github.com>
wrote:

> Initial problem: (Image too small to scale)
> Those images are ridiculously small at 3x48 pixels. Something is going
> wrong somewhere with the images.
> Are they oriented vertically? The input scaling scales the height to 48,
> whatever it starts as, so it looks like your textlines are vertical.
>
> Fine tuning problem:
> The problem is most likely too many iterations. It will hone its accuracy
> to whatever training data you give it if you run it for too many
> iterations.
> See how few iterations are used in the training tutorial for fine tuning.
>
> On Sat, Aug 12, 2017 at 5:19 AM, hanikh <notifications@github.com> wrote:
>
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Compute CTC targets failed!
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > Image too small to scale!! (3x48 vs min width of 3)
> > Line cannot be recognized!!
> > Image not trainable
> > 2 Percent improvement time=0, best error was 2.167 @ 14
> > At iteration 14/1100/20884, Mean rms=0.049%, delta=0%, char train=0%,
> word
> > train=0%, skip ratio=1798.6%, New best char error = 0 wrote best
> > model:/home/fanasa/tesstutorial/fastuned_from_
> fas/fastuned-plates0_14.lstm
> > wrote checkpoint.
> >
> > Finished! Error rate = 0
> > this is the error I got during training for licence plates.
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/590#
> issuecomment-321977639>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AL056ZvLnyg_
> aC1mUg2gH34puAGpWdOOks5sXZhHgaJpZM4LQsPF>
> > .
> >
>
>
>
> --
> Ray.
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/590#issuecomment-322020794>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o3ztjvMQKBue5JIqMU9Qrfx4ng_Mks5sXng2gaJpZM4LQsPF>
> .
>
 > where can the lang.lstm-unicharset file be found ?

`combine_tessdata -u lang.traineddata lang.`

It will create lang.* files , including the unicharset.

You can use dawg2wordlist to see the wordlist used

 > how can combine_lang_model be used? 

```
 combine_lang_model    \
 --input_unicharset  ../tesstutorial/sanskrit2003/san/san.unicharset  \
 --script_dir "../langdata"   \
 --words "../langdata/san/san.wordlist" \
 --numbers "../langdata/san/san.numbers"   \
 --puncs "../langdata/san/san.punc" \
 --output_dir ../tesstutorial/sanskrit2003   \
 --lang "san"     --pass_through_recoder \
     --version_str "4.0.0alpha-20170816 sanskrit2003"
```

For RTL languages, there is an additional flag. Please see https://github.com/tesseract-ocr/tesseract/blob/master/training/tesstrain_utils.sh for details.

I used a  hand-edited unicharset, because the unicharset generated from the current training process is `old style`.  You should wait for @theraysmith to update the unichar_extractor and other langdata files. @theraysmith 

Please let us know whether it is worthwhile to try and train (finetune/replace layer) for RTL languages or should the users wait for your updates to langdata, unichar extractor programs. Need to wait for unichar_extractor to be fixed.

See https://github.com/tesseract-ocr/tesseract/issues/1114

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Sep 12, 2017 at 4:29 PM, hanikh <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/shreeshrii> would you please help me with
> using "replacing layers" as I asked before?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/590#issuecomment-328818316>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o39Bj_jpcJV98kEOyDdv8rMKfFUvks5shmQbgaJpZM4LQsPF>
> .
>
 @theraysmith Please see https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/QC3WY48SicI/ZococRbTBAAJ

regarding question about finetuning training for  chi_sim.traineddata model  Try to run `cppan --clean-packages .*jpeg.*`, then run `cppan` in tesseract folder and then check your solution again. Also make sure you have the latest cppan client installed: `cppan --self-upgrade` Kill those processes. It's MSBuild.exe/CL.exe issue. Clean `tiff` now. :)
```
cppan --clean-packages .*tiff.*
cppan
```

You may try instead of typing these commands remove the whole storage `c:\users\zhivko\.cppan\storage`.
Or try to run `cppan --clean-packages .*`. Did you remove storage?
If no, do 
```
cppan --clean-packages .*lepton.*
cppan
```

Issue is somewhere between tiff/leptonica. Can you go into that file and a picture of code line? Oh, by the way. libtiff is known to not work on MSVC < 2015 (2013,2012,2010 etc.).
I don't have VS2013 to fix the issue, but it should not be very hard. The issue is in snprintf function or macro. It is changed in VS2015. What version do you have? 2013 or 2015? or even 2017? No need to downgrade. It should work fine on VS2015. Should we close this ticket? 1.74 means >=1.74.* i.e.
when we have 1.74.1, 1.74==1.74.1
when we have 1.74.2, 1.74==1.74.2

As for 3.05+vs2010, one must gather (download, build) all deps manually.
3.05+vs2015+cppan works fine.   IMO support for VS2010 should be dropped in 4.00 because of  [c++11](https://msdn.microsoft.com/en-us/library/hh567368.aspx)... That would simplify things. That dir (`port`) should be just reorganized. VS solutions could be removed because we have cmake.

By the way, did you decide how to version 4 branch? 4.00 or 4.0.0 ? 4.0.0 could be a start for [semantic versioning](http://semver.org/) (like it is used by many other projects). That's why I'm asking. My vote is for 4.0.0. There is [4.00.00alpha](https://github.com/tesseract-ocr/tesseract/blob/master/api/baseapi.h#L23) and  [4.00.00dev](https://github.com/tesseract-ocr/tesseract/blob/master/configure.ac#L9) version  info. If there is change request - create PR and ask Ray for merge... @stweil: will you update this PR according comments (VS removal, port reorganized)? > If there is change request - create PR and ask Ray for merge...

Sure. Will do it if there are no serious objections. Also following tags must be also named as 4.0.0-smth.
https://github.com/tesseract-ocr/tesseract/releases @zdenop, I removed the VS related commit from this PR now. Removing VS and moving port can be handled in a new PR. thanks @zdenop 
By the way, maybe you'd like to reorganize sources also?
1. move all sources to `src` dir.
2. (optional) add `include` dir with all public stuff - headers. I can do this, but someone should fix autotools after the changes. @egorpugin : reorganization of sources should be discussed with Ray... Ok, I'll ask him a bit later when fixing version numbers.  They were removed in commit d70f3c36635c251ac3286063c6c29d10b815a565.
The old code implicitly added `-llept` by using the `AC_CHECK_LIB` macro.

Signed-off-by: Stefan Weil <sw@weilnetz.de> (untested)

    git checkout -b stweil master
    git pull https://github.com/stweil/tesseract.git
    git checkout master
    git cherry-pick 7c684be7245a24bd4c97878424fb14bc394fef4e
  Currently we see tons of warnings during MSVC builds.
They should be fixed during `modernizing code` phase.
See this log for warnings https://ci.appveyor.com/api/buildjobs/3v0vmv6xjy658f79/log Similar warnings can be produced on Linux using clang++. But even the default debug build with gcc produces tons of warnings (mainly signed/unsigned mismatch). I've also removed /W1 (warning level 1, default is 3) in leptonica for MSVC.
So, @DanBloomberg probably should look at those warnings in lept too.
https://ci.appveyor.com/api/buildjobs/0s1o3vud8x1e1pe6/log * 1.0 -> 1.0f
* make casts explicit

What do you think? Mixing float and double can result in additional code (and execution time) for conversions between both types.  This is caused by a missing `--llept` linker option. I have that problem, too (not in all configurations), and I am still searching why this worked before. Yes, I thought so, as it was the only related commit. The strange thing is that builds with `--enable-opencl` (default when OpenCL development files are installed) work. That's why I only see it with cross builds for Windows. Nevertheless, I'll send a PR soon. See pull request #585 for a fix.  GITREV should be used for debuging and not in release mode.
tag in master created:
https://github.com/tesseract-ocr/tesseract/tree/4.00.00alpha
also visible in https://github.com/tesseract-ocr/tesseract/releases  You also have to build `ScrollView.jar`:

    make ScrollView.jar

In addition, it is necessary to set the environment variable `SCROLLVIEW_PATH` to the directory with `ScrollView.jar`. This information is currently missing in the Wiki page.  Did you compile Tesseract yourself or did you use binaries from the net? Could you try a newer version? The image link is 404, so impossible to make progress. The image is available [here](http://i.imgur.com/fDnFq1a.jpg). It is a JPEG image, not a PNG (as the title of the issue suggests). @vikinsights, where did you get your Tesseract for Windows from (or how did you bulld it if you did this yourself)?  You report issue in wrong project ;-) Tesseract provides information about version. See:
[const char* TessBaseAPI::Version()](https://github.com/tesseract-ocr/tesseract/blob/master/api/baseapi.cpp#L139) and how to [use it](https://github.com/tesseract-ocr/tesseract/blob/master/api/tesseractmain.cpp#L52) (in c++).  > install-dataDATA
This indicates problem with configuration. How did you configured  build? Extract from your build protocol:

    make[3]: Entering directory '/work/usr/local/src/tesseract/tessdata/configs'
    make[3]: Nothing to be done for 'install-exec-am'.
     /bin/mkdir -p '/usr/local/share/tessdata/configs'
     /usr/bin/install -c -m 644 inter makebox box.train unlv ambigs.train api_config kannada box.train.stderr quiet logfile digits hocr tsv linebox pdf rebox strokewidth bigram txt '/usr/local/share/tessdata/configs'
    /usr/bin/install: „inter“ und „/usr/local/share/tessdata/configs/inter“ sind die gleiche Datei

So you are building in `/work/usr/local/src/tesseract` and want to install to `/usr/local`. The installer says that `/work/usr/local/src/tesseract/tessdata/configs/inter` and `/usr/local/share/tessdata/configs/inter` are the same file and fails therefore. Do you have a symbolic link somewhere (either in your build directory or in the installation directory) which connects both directory hierarchies? Well, make did catch that mistake and said that the installation failed because for some files source and destination were identical ("sind die gleiche Datei").   Yes, that could be done as well. Maybe we should require a Leptonica installations with pkg-config. That would simplify that part of the configuration a lot. Then let's remove the unneeded code. :-)  Both older (Debian libicu-dev 52.1-8+deb8u4) and newer (Debian libicu-dev 57.1-5) versions work for me. There are known issues for Windows which are addressed in PR #574.  Can you try revert this https://github.com/tesseract-ocr/tesseract/commit/7755e05e506ea7a31ff50dd7a8b86dfd885c639c ? Current Mingw-w64 as included in Cygwin includes these libraries in package `mingw64-x86_64-icu`:  libicudata.dll.a  libicui18n.dll.a  libicuio.dll.a  libicule.dll.a  libiculx.dll.a  libicutest.dll.a  libicutu.dll.a  libicuuc.dll.a, so that should work. It looks as if you got an older version of icu. Which version of Mingw-w64 did you use?
 @zdenop, reverting that commit will work with old versions of icu. We don't support them for Linux, and for Windows there are also newer versions available. If support for both old and new versions is required, we need a test in configure. If you use MSYS / MinGW from http://www.mingw.org/, then even the latest installation is old. :-(
That packages are not suitable for builds of Tesseract (old libraries, old compiler, only 32 bit). Don't use them for Tesseract 4.

Use Mingw-w64 from https://mingw-w64.org/ or install Cygwin from https://cygwin.com/ with the mingw64-* packages. Both solutions allow building 32 or 64 bit Tesseract for Windows. I'll have a look tomorrow. Good night for today. msys2.github.io provides a recent package `mingw64/mingw-w64-x86_64-icu` 57.1-1 with these libraries in `/mingw64/lib`:

    libicudt.dll.a  libicuin.dll.a    libicuio.dll.a  libicule.dll.a
    libiculx.dll.a  libicutest.dll.a  libicutu.dll.a  libicuuc.dll.a

This results in the reported build error.

Cygwin has a package `mingw64-x86_64-icu` 57.1-2 with these files in `/usr/x86_64-w64-mingw32/sys-root/mingw/lib`:

    libicudata.dll.a  libicuio.dll.a  libiculx.dll.a    libicutu.dll.a
    libicui18n.dll.a  libicule.dll.a  libicutest.dll.a  libicuuc.dll.a

Note that the versions are nearly identical. I was wrong when I thought that it was a problem of old versions of libicu. We need a `configure` which supports both variants. I'll send a PR. PR #572 addresses all issues which I had with the MSYS2 Installer from https://msys2.github.io/. @djusHa, the latest version in git includes the changes now. Don't forget to run `./autogen.sh` before trying a new build.  Can you provide a stack trace? Still getting this error with latest build with --enable-debug

```
Iteration 699: ALIGNED TRUTH : नियन कुदकि के टपि जा ... हइऽऽऽयाँ ! पैदल तऽ हइयाँ, बकि
Iteration 699: BEST OCR TEXT : नियन कदक के पि जा हाल त हइया बकि
File /tmp/tmp.21BVvgsmzO/bih/bih.SakalBharati.exp0.lstmf page 28 :
Mean rms=4.633%, delta=42.555%, train=94.938%(98.768%), skip ratio=0%
[Thread 0x7f5cbb4d0700 (LWP 17917) exited]
[New Thread 0x7f5cbb4d0700 (LWP 17918)]
lstmtraining: ../ccutil/genericvector.h:697: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

Program received signal SIGABRT, Aborted.
[Switching to Thread 0x7f5cbb4d0700 (LWP 17918)]
0x00007f5cc0486c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
56      ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.
(gdb) backtrace
#0  0x00007f5cc0486c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
#1  0x00007f5cc048a028 in __GI_abort () at abort.c:89
#2  0x00007f5cc047fbf6 in __assert_fail_base (fmt=0x7f5cc05d03b8 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n",
    assertion=assertion@entry=0x7f5cc130e4a0 "index >= 0 && index < size_used_", file=file@entry=0x7f5cc130df28 "../ccutil/genericvector.h", line=line@entry=697,
    function=function@entry=0x7f5cc132f480 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]")
    at assert.c:92
#3  0x00007f5cc047fca2 in __GI___assert_fail (assertion=0x7f5cc130e4a0 "index >= 0 && index < size_used_", file=0x7f5cc130df28 "../ccutil/genericvector.h", line=697,
    function=0x7f5cc132f480 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:101
#4  0x00007f5cc128fb63 in GenericVector<char>::operator[] (this=<optimized out>, this=<optimized out>, index=0) at ../ccutil/genericvector.h:697
#5  0x00007f5cc1290318 in operator[] (this=0x7fffd06bde40, this=0x7fffd06bde40, index=0) at lstmtrainer.cpp:920
#6  tesseract::LSTMTrainer::ReadTrainingDump (this=this@entry=0x7f5cbb4cf640, data=..., trainer=trainer@entry=0x7f5cbb4cf640) at lstmtrainer.cpp:921
#7  0x000000000040b03e in tesseract::LSTMTester::RunEvalSync (this=this@entry=0x7fffd06bddd0, iteration=0, training_errors=<optimized out>, model_data=...,
    training_stage=0) at lstmtester.cpp:86
#8  0x000000000040b539 in tesseract::LSTMTester::ThreadFunc (lstmtester_void=0x7fffd06bddd0) at lstmtester.cpp:123
#9  0x00007f5cbe348184 in start_thread (arg=0x7f5cbb4d0700) at pthread_create.c:312
#10 0x00007f5cc054a37d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111
(gdb)
```
```

(gdb) frame 1
#1  0x00007f5cc048a028 in __GI_abort () at abort.c:89
89      abort.c: No such file or directory.
(gdb) frame 2
#2  0x00007f5cc047fbf6 in __assert_fail_base (fmt=0x7f5cc05d03b8 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n",
    assertion=assertion@entry=0x7f5cc130e4a0 "index >= 0 && index < size_used_", file=file@entry=0x7f5cc130df28 "../ccutil/genericvector.h", line=line@entry=697,
    function=function@entry=0x7f5cc132f480 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]")
    at assert.c:92
92      assert.c: No such file or directory.
(gdb) frame 3
#3  0x00007f5cc047fca2 in __GI___assert_fail (assertion=0x7f5cc130e4a0 "index >= 0 && index < size_used_", file=0x7f5cc130df28 "../ccutil/genericvector.h", line=697,
    function=0x7f5cc132f480 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:101
101     in assert.c
(gdb) frame 4
#4  0x00007f5cc128fb63 in GenericVector<char>::operator[] (this=<optimized out>, this=<optimized out>, index=0) at ../ccutil/genericvector.h:697
697       assert(index >= 0 && index < size_used_);
(gdb) frame 5
#5  0x00007f5cc1290318 in operator[] (this=0x7fffd06bde40, this=0x7fffd06bde40, index=0) at lstmtrainer.cpp:920
920                                        LSTMTrainer* trainer) {
(gdb) frame 6
#6  tesseract::LSTMTrainer::ReadTrainingDump (this=this@entry=0x7f5cbb4cf640, data=..., trainer=trainer@entry=0x7f5cbb4cf640) at lstmtrainer.cpp:921
921       return trainer->ReadSizedTrainingDump(&data[0], data.size());
(gdb) frame 7
#7  0x000000000040b03e in tesseract::LSTMTester::RunEvalSync (this=this@entry=0x7fffd06bddd0, iteration=0, training_errors=<optimized out>, model_data=...,
    training_stage=0) at lstmtester.cpp:86
86        if (!trainer.ReadTrainingDump(model_data, &trainer)) {
(gdb) frame 8
#8  0x000000000040b539 in tesseract::LSTMTester::ThreadFunc (lstmtester_void=0x7fffd06bddd0) at lstmtester.cpp:123
123       lstmtester->test_result_ = lstmtester->RunEvalSync(
(gdb) frame 9
#9  0x00007f5cbe348184 in start_thread (arg=0x7f5cbb4d0700) at pthread_create.c:312
312     pthread_create.c: No such file or directory.
(gdb)
``` Sorry fixed in
https://github.com/tesseract-ocr/tesseract/commit/b86b4fa06ba4d2afa00c53470a19f6630e638f66
Please try again. I could do with a test for that...

On Mon, May 8, 2017 at 5:03 AM, Shreeshrii <notifications@github.com> wrote:

> Still getting this error with latest build with --enable-debug
>
> Iteration 699: ALIGNED TRUTH : नियन कुदकि के टपि जा ... हइऽऽऽयाँ ! पैदल तऽ हइयाँ, बकि
> Iteration 699: BEST OCR TEXT : नियन कदक के पि जा हाल त हइया बकि
> File /tmp/tmp.21BVvgsmzO/bih/bih.SakalBharati.exp0.lstmf page 28 :
> Mean rms=4.633%, delta=42.555%, train=94.938%(98.768%), skip ratio=0%
> [Thread 0x7f5cbb4d0700 (LWP 17917) exited]
> [New Thread 0x7f5cbb4d0700 (LWP 17918)]
> lstmtraining: ../ccutil/genericvector.h:697: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
>
> Program received signal SIGABRT, Aborted.
> [Switching to Thread 0x7f5cbb4d0700 (LWP 17918)]
> 0x00007f5cc0486c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
> 56      ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.
> (gdb) backtrace
> #0  0x00007f5cc0486c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
> #1  0x00007f5cc048a028 in __GI_abort () at abort.c:89
> #2  0x00007f5cc047fbf6 in __assert_fail_base (fmt=0x7f5cc05d03b8 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n",
>     assertion=assertion@entry=0x7f5cc130e4a0 "index >= 0 && index < size_used_", file=file@entry=0x7f5cc130df28 "../ccutil/genericvector.h", line=line@entry=697,
>     function=function@entry=0x7f5cc132f480 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]")
>     at assert.c:92
> #3  0x00007f5cc047fca2 in __GI___assert_fail (assertion=0x7f5cc130e4a0 "index >= 0 && index < size_used_", file=0x7f5cc130df28 "../ccutil/genericvector.h", line=697,
>     function=0x7f5cc132f480 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:101
> #4  0x00007f5cc128fb63 in GenericVector<char>::operator[] (this=<optimized out>, this=<optimized out>, index=0) at ../ccutil/genericvector.h:697
> #5  0x00007f5cc1290318 in operator[] (this=0x7fffd06bde40, this=0x7fffd06bde40, index=0) at lstmtrainer.cpp:920
> #6  tesseract::LSTMTrainer::ReadTrainingDump (this=this@entry=0x7f5cbb4cf640, data=..., trainer=trainer@entry=0x7f5cbb4cf640) at lstmtrainer.cpp:921
> #7  0x000000000040b03e in tesseract::LSTMTester::RunEvalSync (this=this@entry=0x7fffd06bddd0, iteration=0, training_errors=<optimized out>, model_data=...,
>     training_stage=0) at lstmtester.cpp:86
> #8  0x000000000040b539 in tesseract::LSTMTester::ThreadFunc (lstmtester_void=0x7fffd06bddd0) at lstmtester.cpp:123
> #9  0x00007f5cbe348184 in start_thread (arg=0x7f5cbb4d0700) at pthread_create.c:312
> #10 0x00007f5cc054a37d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111
> (gdb)
>
>
> (gdb) frame 1
> #1  0x00007f5cc048a028 in __GI_abort () at abort.c:89
> 89      abort.c: No such file or directory.
> (gdb) frame 2
> #2  0x00007f5cc047fbf6 in __assert_fail_base (fmt=0x7f5cc05d03b8 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n",
>     assertion=assertion@entry=0x7f5cc130e4a0 "index >= 0 && index < size_used_", file=file@entry=0x7f5cc130df28 "../ccutil/genericvector.h", line=line@entry=697,
>     function=function@entry=0x7f5cc132f480 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]")
>     at assert.c:92
> 92      assert.c: No such file or directory.
> (gdb) frame 3
> #3  0x00007f5cc047fca2 in __GI___assert_fail (assertion=0x7f5cc130e4a0 "index >= 0 && index < size_used_", file=0x7f5cc130df28 "../ccutil/genericvector.h", line=697,
>     function=0x7f5cc132f480 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:101
> 101     in assert.c
> (gdb) frame 4
> #4  0x00007f5cc128fb63 in GenericVector<char>::operator[] (this=<optimized out>, this=<optimized out>, index=0) at ../ccutil/genericvector.h:697
> 697       assert(index >= 0 && index < size_used_);
> (gdb) frame 5
> #5  0x00007f5cc1290318 in operator[] (this=0x7fffd06bde40, this=0x7fffd06bde40, index=0) at lstmtrainer.cpp:920
> 920                                        LSTMTrainer* trainer) {
> (gdb) frame 6
> #6  tesseract::LSTMTrainer::ReadTrainingDump (this=this@entry=0x7f5cbb4cf640, data=..., trainer=trainer@entry=0x7f5cbb4cf640) at lstmtrainer.cpp:921
> 921       return trainer->ReadSizedTrainingDump(&data[0], data.size());
> (gdb) frame 7
> #7  0x000000000040b03e in tesseract::LSTMTester::RunEvalSync (this=this@entry=0x7fffd06bddd0, iteration=0, training_errors=<optimized out>, model_data=...,
>     training_stage=0) at lstmtester.cpp:86
> 86        if (!trainer.ReadTrainingDump(model_data, &trainer)) {
> (gdb) frame 8
> #8  0x000000000040b539 in tesseract::LSTMTester::ThreadFunc (lstmtester_void=0x7fffd06bddd0) at lstmtester.cpp:123
> 123       lstmtester->test_result_ = lstmtester->RunEvalSync(
> (gdb) frame 9
> #9  0x00007f5cbe348184 in start_thread (arg=0x7f5cbb4d0700) at pthread_create.c:312
> 312     pthread_create.c: No such file or directory.
> (gdb)
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/561#issuecomment-299848534>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056bih7QudDYsxtY8yGjr7FhdJIQxgks5r3wSDgaJpZM4LJ7Lz>
> .
>



-- 
Ray.
 Still getting the error

```
tesseract -v
tesseract 4.00.00alpha-460-gb86b4fa
 leptonica-1.74.1
  libgif 5.0.5 : libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8 : libwebp 0.4.0 : libopenjp2 2.1.0

 Found AVX
 Found SSE
```
```
Iteration 699: ALIGNED TRUTH : कृषिक्षॆत्रंचित्रपटाने साथ नयी पोस्टेड से ओलंपिक सेभोजनादिकम् सीप
Iteration 699: BEST OCR TEXT : किससिसिस
File /tmp/tmp.FOELAYZPOv/bih/bih.Samanata.exp0.lstmf page 215 :
Mean rms=4.813%, delta=46.035%, train=99.32%(99.97%), skip ratio=0%
[Thread 0x7f618d0e0700 (LWP 170) exited]
[New Thread 0x7f618d0e0700 (LWP 171)]
lstmtraining: ../ccutil/genericvector.h:697: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

Program received signal SIGABRT, Aborted.
[Switching to Thread 0x7f618d0e0700 (LWP 171)]
0x00007f6191886c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
56      ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.
(gdb) backtrace
#0  0x00007f6191886c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
#1  0x00007f619188a028 in __GI_abort () at abort.c:89
#2  0x00007f619187fbf6 in __assert_fail_base (fmt=0x7f61919d03b8 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n",
    assertion=assertion@entry=0x7f619270d6c0 "index >= 0 && index < size_used_", file=file@entry=0x7f619270d148 "../ccutil/genericvector.h", line=line@entry=697,
    function=function@entry=0x7f619272ea60 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]")
    at assert.c:92
#3  0x00007f619187fca2 in __GI___assert_fail (assertion=0x7f619270d6c0 "index >= 0 && index < size_used_", file=0x7f619270d148 "../ccutil/genericvector.h", line=697,
    function=0x7f619272ea60 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:101
#4  0x00007f619268c803 in GenericVector<char>::operator[] (this=<optimized out>, this=<optimized out>, index=0) at ../ccutil/genericvector.h:697
#5  0x00007f619268cfb8 in operator[] (this=0x7fffe8f33fc0, this=0x7fffe8f33fc0, index=0) at lstmtrainer.cpp:920
#6  tesseract::LSTMTrainer::ReadTrainingDump (this=this@entry=0x7f618d0df640, data=..., trainer=trainer@entry=0x7f618d0df640) at lstmtrainer.cpp:921
#7  0x000000000040b03e in tesseract::LSTMTester::RunEvalSync (this=this@entry=0x7fffe8f33f50, iteration=0, training_errors=<optimized out>, model_data=...,
    training_stage=0) at lstmtester.cpp:86
#8  0x000000000040b539 in tesseract::LSTMTester::ThreadFunc (lstmtester_void=0x7fffe8f33f50) at lstmtester.cpp:123
#9  0x00007f618f748184 in start_thread (arg=0x7f618d0e0700) at pthread_create.c:312
#10 0x00007f619194a37d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111
(gdb) quit
``` I tried with a different set of input files for training and eval, same error. **Seems to happen at first checkpoint writing after train % falls below 100.** 

```
Iteration 496: ALIGNED TRUTH : ग़, ज़, और फ़। इसलिए आपको केवल इन पाँचों पर ध्यान
Iteration 496: BEST OCR TEXT :  ज र  सलि आपको केवल न पावो पर ध्यान
File /tmp/tmp.VitmU3pEv2/bih/bih.Mangal.exp0.lstmf page 1889 :
Mean rms=4.735%, delta=39.487%, train=92.02%(98.26%), skip ratio=0%
Iteration 497: ALIGNED TRUTH : वर्गमीटर मरे यथाशक्ति न्यायशास्त्री फैक्स। प्रेममयी सोद्देश्यवादी
Iteration 497: BEST OCR TEXT : वमीदर मरे यधाशि नयायशा कस पेममय सोदियवादी
File /tmp/tmp.VitmU3pEv2/bih/bih.Siddhanta.exp0.lstmf page 747 :
Mean rms=4.731%, delta=39.423%, train=91.922%(98.234%), skip ratio=0%
Iteration 498: ALIGNED TRUTH : महीपतिया हो जुआर जसे हारे तइसे ले गआव मोरा पास जहंवा
Iteration 498: BEST OCR TEXT : महीपतिया हो जआर जसे हार तसे ले व मोरा पास जहवा
File /tmp/tmp.VitmU3pEv2/bih/bih.Mangal.exp0.lstmf page 30 :
Mean rms=4.726%, delta=39.356%, train=91.76%(98.129%), skip ratio=0%
Iteration 499: ALIGNED TRUTH : रद्दा। रार धडधड धड घ्रघ्र धडल्ला घ्रघर्र दरारदार ऋणाधार
Iteration 499: BEST OCR TEXT : रदा रार धध ध धरधर ला धरधर दरारदार णाधार
File /tmp/tmp.VitmU3pEv2/bih/bih.Siddhanta.exp0.lstmf page 1157 :
Mean rms=4.721%, delta=39.3%, train=91.663%(98.088%), skip ratio=0%
lstmtraining: ../ccutil/genericvector.h:697: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
Aborted (core dumped)
``` Checked with eng, same set of input files. fails when I give the --eval_listfile.

Only train_listfile - NO ERROR

```
 lstmtraining  \
>    -U ~/tesstutorial/nyd/eng.unicharset \
>   --train_listfile ~/tesstutorial/nyd/eng.training_files.txt \
>   --script_dir ../langdata   \
>   --append_index 5 --net_spec '[Lfx256 O1c105]' \
>   --continue_from ~/tesstutorial/nydlayer/eng.lstm \
>   --model_output ~/tesstutorial/nydlayer/nyd \
>   --debug_interval -1 \
>   --target_error_rate 0.01
Loaded file /home/shree/tesstutorial/nydlayer/eng.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from /home/shree/tesstutorial/nydlayer/eng.lstm
Other case É of é is not in unicharset
Appending a new network to an old one!!Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Num outputs,weights in serial:
  Lfx256:256, 394240
  Fc105:105, 26985
Total weights = 421225
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc105] from request [Lfx256 O1c105]
Training parameters:
  Debug interval = -1, weights = 0.1, learning rate = 0.0001, momentum=0.9
...
Mean rms=2.758%, delta=16.418%, train=35.971%(49.658%), skip ratio=0%
Iteration 999: ALIGNED TRUTH : MySQL { & Advanced her BOX me Management your new have Post by
Iteration 999: BEST OCR TEXT : MySQL ( & Advanced her BON me Management your new have Post by
File /tmp/tmp.RQfY2cDM00/eng/eng.Arial.exp-2.lstmf page 31 :
Mean rms=2.757%, delta=16.403%, train=35.942%(49.624%), skip ratio=0%
2 Percent improvement time=49, best error was 39.615 @ 789
At iteration 838/1000/1000, Mean rms=2.757%, delta=16.403%, char train=35.942%, word train=49.624%, skip ratio=0%,  New best char error = 35.942 wrote best model:/home/s
hree/tesstutorial/nydlayer/nyd35.942_838.lstm wrote checkpoint.

Iteration 1000: ALIGNED TRUTH : Bailey Joshua, mate, 190 Eldridge
Iteration 1000: BEST OCR TEXT : Bailey Joshua, mate, 190 Eldridge
File /home/shree/tesstutorial/nyd/eng.1852nydir.exp0.lstmf page 26 (Perfect):
```
 **ERROR - even when using both train and eval with same set of files** 

```
 lstmtraining  \
>    -U ~/tesstutorial/nyd/eng.unicharset \
>   --train_listfile ~/tesstutorial/nyd/eng.training_files.txt \
>     --eval_listfile ~/tesstutorial/nyd/eng.training_files.txt \
>   --script_dir ../langdata   \
>   --append_index 5 --net_spec '[Lfx256 O1c105]' \
>   --continue_from ~/tesstutorial/nydlayer/eng.lstm \
>   --model_output ~/tesstutorial/nydlayer/nyd \
>   --debug_interval -1 \
>   --target_error_rate 0.01
Loaded file /home/shree/tesstutorial/nydlayer/eng.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from /home/shree/tesstutorial/nydlayer/eng.lstm
Other case É of é is not in unicharset
Appending a new network to an old one!!Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Num outputs,weights in serial:
  Lfx256:256, 394240
  Fc105:105, 26985
Total weights = 421225
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc105] from request [Lfx256 O1c105]
Training parameters:
  Debug interval = -1, weights = 0.1, learning rate = 0.0001, momentum=0.9
Loaded 29/29 pages (1-29) of document /home/shree/tesstutorial/nyd/eng.1852nydir.exp0.lstmf
Loaded 8/8 pages (1-8) of document /home/shree/tesstutorial/nyd/eng.1852nydir.exp1.lstmf
Loaded 12/12 pages (1-12) of document /home/shree/tesstutorial/nyd/eng.1852nydir.exp2.lstmf
Loaded 29/29 pages (1-29) of document /home/shree/tesstutorial/nyd/eng.1852nydir.exp-1.lstmf
Loaded 29/29 pages (1-29) of document /home/shree/tesstutorial/nyd/eng.1852nydir.exp0.lstmf
Loaded 104/104 pages (1-104) of document /home/shree/tesstutorial/nyd/eng.Arial.exp-2.lstmf
Loaded 29/29 pages (1-29) of document /home/shree/tesstutorial/nyd/eng.1852nydir.exp-1.lstmf

...
Iteration 298: ALIGNED TRUTH : Bailey Julia, 167% WWooster
Iteration 298: BEST OCR TEXT : Baiiey aiia, % ooter
File /home/shree/tesstutorial/nyd/eng.1852nydir.exp2.lstmf page 11 :
Mean rms=5.44%, delta=46.985%, train=96.919%(99.93%), skip ratio=0%
Iteration 299: ALIGNED TRUTH : AA Q WW E R T Y UU II O P L KK J HH GG F D S ZZ X C V B NN MMM 0 9 8 7 7 6 5 4 3
Iteration 299: BEST OCR TEXT :     B            o      B
File /tmp/tmp.RQfY2cDM00/eng/eng.Arial.exp-2.lstmf page 81 :
Mean rms=5.435%, delta=46.865%, train=96.775%(99.92%), skip ratio=0%
lstmtraining: ../ccutil/genericvector.h:697: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
Aborted (core dumped)
``` Related https://github.com/tesseract-ocr/tesseract/issues/644 @theraysmith

Latest code change has reverted the fix for this issue

```
Iteration 99: ALIGNED TRUTH : च छ ज झ ञ उ ऊ ट ठ ड ढ ण ऋ ॠ त थ
Iteration 99: BEST OCR TEXT :
File /tmp/tmp.m82dWGBYZW/mar/mar.Aparajita.exp0.lstmf page 3 :
Mean rms=5.427%, delta=53.011%, train=110.2%(100%), skip ratio=0%
lstmtraining: genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
Aborted (core dumped)
``` Fixed in 4b6f0b95..f4f66f8f

On Sat, Jul 15, 2017 at 1:04 AM, Shreeshrii <notifications@github.com>
wrote:

> @theraysmith <https://github.com/theraysmith>
>
> Latest code change has reverted the fix for this issue
>
> Iteration 99: ALIGNED TRUTH : च छ ज झ ञ उ ऊ ट ठ ड ढ ण ऋ ॠ त थ
> Iteration 99: BEST OCR TEXT :
> File /tmp/tmp.m82dWGBYZW/mar/mar.Aparajita.exp0.lstmf page 3 :
> Mean rms=5.427%, delta=53.011%, train=110.2%(100%), skip ratio=0%
> lstmtraining: genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
> Aborted (core dumped)
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/561#issuecomment-315518059>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056YjQzLN_XVXLe8ENvek_1eABxTHTks5sOHJ2gaJpZM4LJ7Lz>
> .
>



-- 
Ray.
 Still getting the error, as of commit f4f66f8:

```
Iteration 99: ALIGNED TRUTH : पुनर्व्यवस्थित अमेरिकी इंडोनेशिया
Iteration 99: BEST OCR TEXT :
File /tmp/tmp.7Z9YtK1Bru/hin/hin.Siddhanta.exp0.lstmf page 519 :
Mean rms=5.531%, delta=52.419%, train=109.818%(100%), skip ratio=0%
lstmtraining: ../ccutil/genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
Aborted (core dumped)
```
Version
```
shree@sanskrit:~/tesseract$ tesseract -v
tesseract f4f66f8
 leptonica-1.74.4
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8 : libwebp 0.4.0 : libopenjp2 2.1.2
```
Training command used
```
nice lstmtraining   -U ~/tesstutorial/hintest/hin.unicharset   --train_listfile ~/tesstutorial/hintest/hin.training_files.txt   --eval_listfile ~/tesstutorial/hineval/hin.training_files.txt   --continue_from ~/tesstutorial/hintest/hin.lstm   --model_output ~/tesstutorial/hintest/hinlayer   --script_dir ../langdata   --append_index 5   --net_spec '[Lfx384 O1c105]'   --target_error_rate 0.01   --perfect_sample_delay 19   --debug_interval -1
``` Error happens later with finetune command - same set of files

```
nice lstmtraining    --train_listfile ~/tesstutorial/hintest/hin.training_files.txt   --eval_listfile ~/tesstutorial/hineval/hin.training_files.txt   --continue_from ~/tesstutorial/hintest/hin.lstm   --model_output ~/tesstutorial/hintest/hintune   --target_error_rate 0.01   --perfect_sample_delay 19   --debug_interval -1
```
Error message - core dumped
```
Iteration 199: ALIGNED TRUTH : मुद्राओं घुसपैठ व्हिटफोर्ड इंटरनेट
Iteration 199: BEST OCR TEXT : मुद्राओं घुसपैठ व्हिटफोर्ड इंटरनेट
File /tmp/tmp.7Z9YtK1Bru/hin/hin.FreeSans.exp0.lstmf page 905 (Perfect):
Mean rms=0.276%, delta=0.118%, train=0.285%(1.056%), skip ratio=2%
lstmtraining: ../ccutil/genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
Aborted (core dumped)
``` There might be another call site. Can you generate a stack trace?

On Sat, Jul 15, 2017 at 9:48 PM, Shreeshrii <notifications@github.com>
wrote:

> Error happens later with finetune command - same set of files
>
> nice lstmtraining    --train_listfile ~/tesstutorial/hintest/hin.training_files.txt   --eval_listfile ~/tesstutorial/hineval/hin.training_files.txt   --continue_from ~/tesstutorial/hintest/hin.lstm   --model_output ~/tesstutorial/hintest/hintune   --target_error_rate 0.01   --perfect_sample_delay 19   --debug_interval -1
>
> Error message - core dumped
>
> Iteration 199: ALIGNED TRUTH : मुद्राओं घुसपैठ व्हिटफोर्ड इंटरनेट
> Iteration 199: BEST OCR TEXT : मुद्राओं घुसपैठ व्हिटफोर्ड इंटरनेट
> File /tmp/tmp.7Z9YtK1Bru/hin/hin.FreeSans.exp0.lstmf page 905 (Perfect):
> Mean rms=0.276%, delta=0.118%, train=0.285%(1.056%), skip ratio=2%
> lstmtraining: ../ccutil/genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
> Aborted (core dumped)
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/561#issuecomment-315585338>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056b9wIbO9wayBkXcecWY-qlLPdjx2ks5sOZYfgaJpZM4LJ7Lz>
> .
>



-- 
Ray.
 with finetune command

```
lstmtraining: ../ccutil/genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

Program received signal SIGABRT, Aborted.
0x00007ffff628bc37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
56      ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.
(gdb) backtrace
#0  0x00007ffff628bc37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
#1  0x00007ffff628f028 in __GI_abort () at abort.c:89
#2  0x00007ffff6284bf6 in __assert_fail_base (fmt=0x7ffff63d9018 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n",
    assertion=assertion@entry=0x7ffff70f5be0 "index >= 0 && index < size_used_",
    file=file@entry=0x7ffff70f5668 "../ccutil/genericvector.h", line=line@entry=713,
    function=function@entry=0x7ffff7116d20 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:92
#3  0x00007ffff6284ca2 in __GI___assert_fail (assertion=0x7ffff70f5be0 "index >= 0 && index < size_used_",
    file=0x7ffff70f5668 "../ccutil/genericvector.h", line=713,
    function=0x7ffff7116d20 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:101
#4  0x00007ffff7071983 in GenericVector<char>::operator[] (this=<optimized out>, this=<optimized out>, index=0)
    at ../ccutil/genericvector.h:713
#5  0x00007ffff7074dd5 in operator[] (this=<optimized out>, this=<optimized out>, index=<optimized out>) at lstmtrainer.cpp:1335
#6  tesseract::LSTMTrainer::UpdateErrorGraph (this=this@entry=0x7fffffffd780, iteration=iteration@entry=11,
    error_rate=error_rate@entry=0.28499999999999998, model_data=..., tester=tester@entry=0x845ce0) at lstmtrainer.cpp:1272
#7  0x00007ffff70780e7 in tesseract::LSTMTrainer::MaintainCheckpoints (this=this@entry=0x7fffffffd780, tester=tester@entry=0x845ce0,
    log_msg=log_msg@entry=0x7fffffffd350) at lstmtrainer.cpp:338
#8  0x0000000000407712 in main (argc=1, argv=0x7fffffffe408) at lstmtraining.cpp:197
``` with replace top layer command

```
(gdb) backtrace
#0  0x00007ffff628bc37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
#1  0x00007ffff628f028 in __GI_abort () at abort.c:89
#2  0x00007ffff6284bf6 in __assert_fail_base (fmt=0x7ffff63d9018 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n",
    assertion=assertion@entry=0x7ffff70f5be0 "index >= 0 && index < size_used_",
    file=file@entry=0x7ffff70f5668 "../ccutil/genericvector.h", line=line@entry=713,
    function=function@entry=0x7ffff7116d20 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:92
#3  0x00007ffff6284ca2 in __GI___assert_fail (assertion=0x7ffff70f5be0 "index >= 0 && index < size_used_",
    file=0x7ffff70f5668 "../ccutil/genericvector.h", line=713,
    function=0x7ffff7116d20 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:101
#4  0x00007ffff7071983 in GenericVector<char>::operator[] (this=<optimized out>, this=<optimized out>, index=0)
    at ../ccutil/genericvector.h:713
#5  0x00007ffff7074dd5 in operator[] (this=<optimized out>, this=<optimized out>, index=<optimized out>) at lstmtrainer.cpp:1335
#6  tesseract::LSTMTrainer::UpdateErrorGraph (this=this@entry=0x7fffffffd6d0, iteration=iteration@entry=100,
    error_rate=error_rate@entry=109.818, model_data=..., tester=tester@entry=0x845d00) at lstmtrainer.cpp:1272
#7  0x00007ffff70780e7 in tesseract::LSTMTrainer::MaintainCheckpoints (this=this@entry=0x7fffffffd6d0, tester=tester@entry=0x845d00,
    log_msg=log_msg@entry=0x7fffffffd2a0) at lstmtrainer.cpp:338
#8  0x0000000000407712 in main (argc=1, argv=0x7fffffffe398) at lstmtraining.cpp:197
(gdb)
``` Did my most recent commit fix it?
https://github.com/tesseract-ocr/tesseract/commit/45fb7dde495df31629b7b5ca36b654a6bccfb762

On Sat, Jul 15, 2017 at 10:53 PM, Shreeshrii <notifications@github.com>
wrote:

> with replace top layer command
>
> (gdb) backtrace
> #0  0x00007ffff628bc37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
> #1  0x00007ffff628f028 in __GI_abort () at abort.c:89
> #2  0x00007ffff6284bf6 in __assert_fail_base (fmt=0x7ffff63d9018 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n",
>     assertion=assertion@entry=0x7ffff70f5be0 "index >= 0 && index < size_used_",
>     file=file@entry=0x7ffff70f5668 "../ccutil/genericvector.h", line=line@entry=713,
>     function=function@entry=0x7ffff7116d20 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:92
> #3  0x00007ffff6284ca2 in __GI___assert_fail (assertion=0x7ffff70f5be0 "index >= 0 && index < size_used_",
>     file=0x7ffff70f5668 "../ccutil/genericvector.h", line=713,
>     function=0x7ffff7116d20 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:101
> #4  0x00007ffff7071983 in GenericVector<char>::operator[] (this=<optimized out>, this=<optimized out>, index=0)
>     at ../ccutil/genericvector.h:713
> #5  0x00007ffff7074dd5 in operator[] (this=<optimized out>, this=<optimized out>, index=<optimized out>) at lstmtrainer.cpp:1335
> #6  tesseract::LSTMTrainer::UpdateErrorGraph (this=this@entry=0x7fffffffd6d0, iteration=iteration@entry=100,
>     error_rate=error_rate@entry=109.818, model_data=..., tester=tester@entry=0x845d00) at lstmtrainer.cpp:1272
> #7  0x00007ffff70780e7 in tesseract::LSTMTrainer::MaintainCheckpoints (this=this@entry=0x7fffffffd6d0, tester=tester@entry=0x845d00,
>     log_msg=log_msg@entry=0x7fffffffd2a0) at lstmtrainer.cpp:338
> #8  0x0000000000407712 in main (argc=1, argv=0x7fffffffe398) at lstmtraining.cpp:197
> (gdb)
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/561#issuecomment-315587741>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056drHnXKXmXSALw-Y7CNl8ynuEGB5ks5sOaVhgaJpZM4LJ7Lz>
> .
>



-- 
Ray.
 Yes, it did. Thank you, @stweil and @theraysmith .  I do not have the files saved to reproduce the problem. I will reopen if it occurs again.

There are also other error/warning messages in this test run, which may/may not be related.

>Unichar 1481=र्ब्रह्मघा->र्ब्रह्मघा is too long to encode!!

>Deserialize header failed:

>First document cannot be empty!!  @theraysmith 

These two Leptonica calls have optional debugging parameters.

pixGenerateHalftoneMask
pixGenHalftoneMask

They are found in imagefind.cpp in code and comments, to support an optional
parameter called textord_tabfind_show_images

https://github.com/tesseract-ocr/tesseract/blob/master/textord/imagefind.cpp#L86

In general, the debug paths in Leptonica are not great from security perspective
and setting that debug parameter to null or false is recommended. If possible
I encourage removing the the textord_tabfind_show_images feature entirely.

In addition, there is significant use of pixDisplayWrite for debugging purposes.
This is deprecated and also a security headache, and I encourage removing
all calls to this function.

It is possible that this list is not exhaustive but it probably is. The rule of thumb 
is try to avoid debug-specific Leptonica code paths wherever possible in release builds.

 Fixed in commit a1c22fb.  Still getting large number of these errors. The box file was created by text2image.

```

Loaded 17903/17903 pages (1-17903) of document /tmp/tmp.A6VtVWpCVT/san/san.Sanskrit_Text.exp0.lstmf
Loaded 14102/14102 pages (1-14102) of document /tmp/tmp.A6VtVWpCVT/san/san.Santipur_OT_Medium.exp0.lstmf
Bad box coordinates in boxfile string! ति झ. पाठः॥ 67-5 क्षयं 478 567 1002 625 83
Bad box coordinates in boxfile string! विचाराचार अध्याय श्रवस्यः योऽयं 117 3530 800 3593 259
Bad box coordinates in boxfile string! न्धिमहोदयस्य च जनवरी-मार्च 426 1260 1016 1332 345
Bad box coordinates in boxfile string! ण्टिर्गौ न्प्रा स्फो  त्फ द्भ्या अस्योद्यानं 190 2392 908 2450 434
Bad box coordinates in boxfile string! ष्पित॥ यस्य १२ मया। अर्क 418 456 969 511 463
No block overlapping textline: ओदनभोजिकाभिः स्कौनगरिकस्य गुरुपत्नीं षट्तन्त्रीसारे।
``` @theraysmith 

I looked at the over 2000 textlines which are getting this error for Devanagari training that I am trying to do right now.

The common thread in all of these is that these textlines begin with words beginning with `i` matraa, which is the only combining mark in Devanagari which is rendered before the consonant it applies to.

Same was the case in the first post here as well as in https://github.com/tesseract-ocr/tesseract/issues/555
  See new section Error Messages From Training  Getting same error even with WordStr format box files. 

Also, unicharset extraction from the box/tiff pairs following the one  in error does not take place.

```
Utf8 buffer too big, size=61 for श्री तुलस्युपाख्यानम्
Utf8 buffer too big, size=40 for सप्तदशोऽध्याय:
Utf8 buffer too big, size=34 for न व म स्क न्धे
Extracting unicharset from /tmp/tmp.qLNJdHgcKr/san/Deva-test.box
Extracting unicharset from /tmp/tmp.qLNJdHgcKr/san/Deva-test-wordstr.box
```
box file used
```
WordStr 27 258 389 325 0 #श्री तुलस्युपाख्यानम्
	 399 258 409 312 0
WordStr 34 183 340 232 0 #सप्तदशोऽध्याय:
	 350 188 361 209 0
WordStr 39 102 254 156 0 #न व म स्क न्धे
	 264 102 291 156 0
WordStr 32 30 184 67 0 #अ ध्या याः
	 194 33 204 64 0
```
![deva-test-wordstr](https://user-images.githubusercontent.com/5095331/28318769-93a6bcca-6be9-11e7-8c45-ea92b12e0486.png)
  Edits made. Filed question over unicharset extraction as a separate issue (https://github.com/tesseract-ocr/tesseract/issues/653)  See new section in trainingtesseract-4.00 Changes are pushed now. I got called away yesterday before I was able to do
it.

On Thu, Jan 12, 2017 at 2:36 AM, Amit D. <notifications@github.com> wrote:

> I don't see the changes either.
>
> The wiki can be cloned as a git repo. Ray probably did some edits locally,
> but didn't 'push' them.
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/549#issuecomment-272130094>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056X0eolRJLjvYL3TR3hp1-wfTyoGKks5rRgJFgaJpZM4LIjyK>
> .
>



-- 
Ray.
 The tab character (9) at the beginning of the list of failure bytes is a
dead giveaway.

On Sat, Jan 21, 2017 at 6:15 AM, Shreeshrii <notifications@github.com>
wrote:

>
> Encoding of string failed! Failure bytes: 9 31 32 30 30 45 6d 69 6c 69 65 2c 68 61 6e 73 4b 6f 6e 65 2e
> Can't encode transcription: Møller.     1200Emilie,hansKone.
>
>
> when trying to train frk
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/549#issuecomment-274264239>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056Z_ATRDHUb3698yrRFfl1XSJTJM3ks5rUhMAgaJpZM4LIjyK>
> .
>



-- 
Ray.
 @theraysmith 

I am still getting this error, for a new replace top layer training for Devanagari script, where the eval_listfile is based on a different training text. eg.

```
Encoding of string failed! Failure bytes: ffffffe0 ffffffa4 ffffff81 ffffffe0 ffffffa4 ffffff9a ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffff9a ffffffe0 ffffffa5 ffffff88 ffffffe0 ffffffa4 ffffff95 ffffffe0 ffffffa5 ffffff8b 20 ffffffe0 ffffffa4 ffffff9c ffffffe0 ffffffa5 ffffff80 ffffffe0 ffffffa4 ffffffb5 ffffffe0 ffffffa4 ffffffa8
Can't encode transcription: वैशाख साल देखि साथै यो साँच्चैको जीवन

Encoding of string failed! Failure bytes: ffffffe0 ffffffa4 ffffff81 ffffffe0 ffffffa4 ffffffa6 ffffffe0 ffffffa4 ffffffbe
Can't encode transcription: रूपांतरित जैबुन्निसा केंद्रित छँदा
````
While each unicode character (स ा ँ ) is there in the Devanagari unicharset, the combined akshara (साँ, छँ) is not there as part of training text/unicharset, but is there as part of eval text/unicharset.

The training unicharset is of the following format:

```
3784
NULL 0 NULL 0
Joined 7 0,69,188,255,486,1218,0,30,486,1188 Latin 1 0 1 Joined	# Joined [4a 6f 69 6e 65 64 ]a
|Broken|0|1 f 0,69,186,255,892,2138,0,80,892,2058 Common 3625 10 3625 |Broken|0|1	# Broken
र्ध्रु 1 0,64,61,197,280,356,0,0,280,356 Devanagari 18 0 18 र्ध्रु	# र्ध्रु [930 94d 927 94d 930 941 ]x
र्बृ 1 3,64,61,197,181,236,0,0,181,236 Devanagari 18 0 18 र्बृ	# र्बृ [930 94d 92c 943 ]x
श्चु 1 0,64,61,197,251,303,0,12,251,291 Devanagari 240 0 240 श्चु	# श्चु [936 94d 91a 941 ]x
श्चौ 1 3,65,61,255,294,367,0,12,294,355 Devanagari 240 0 240 श्चौ	# श्चौ [936 94d 91a 94c ]x
श्च् 1 3,64,61,197,251,303,0,12,251,291 Devanagari 240 0 240 श्च्	# श्च् [936 94d 91a 94d ]x
य 1 63,64,192,192,114,142,0,0,111,133 Devanagari 8 0 8 य	# य [92f ]x
श्रीः 1 3,74,61,253,295,412,0,12,295,400 Devanagari 240 0 240 श्रीः	# श्रीः [936 94d 930 940 903 ]x
ष्ठु 1 0,75,61,197,204,243,0,0,204,243 Devanagari 241 0 241 ष्ठु	# ष्ठु [937 94d 920 941 ]x
ष्ठौ 1 3,75,61,255,247,307,0,0,247,307 Devanagari 241 0 241 ष्ठौ	# ष्ठौ [937 94d 920 94c ]x
स्रैः 1 3,76,61,255,243,449,0,0,243,449 Devanagari 280 0 280 स्रैः	# स्रैः [938 94d 930 948 903 ]x
...
```

Does this mean that the training text needs to be expanded to include all possible akshara combinations?  Posted on 
https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/bVq_mGnPsN4/LqYyZg1ICQAJ  Please use tesseract user forum for asking support.  pixaGetCount errors fixed.
For no block overlapping textline, see new section in training tesseract 4.00. As mentioned by Ray in the comment above, please see https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#error-messages-from-training

>**No block overlapping textline:** occurs when layout analysis fails to correctly segment the image that was given as training data. The textline is dropped. Not much problem if there aren't many, but if there are a lot, there is probably something wrong with the training text or rendering process.  This report should be in tessdata or langdata  repository   Disable debugging and informational messages from Leptonica
for release builds.

Signed-off-by: Stefan Weil <sw@weilnetz.de> Using the environment variable would imply that you always get at least one message from Leptonica because the code which enables / disables warnings also writes messages. :-( That's why I decided against that feature for the moment.
Leptonica needs a modification which allows suppressing messages from setMsgSeverity, no matter whether the environment variable exists or not and no matter which message severity level is set. Yes, I'd prefer keeping the interface unchanged and disabling the messages (at least for arguments in the valid range). An unset environment variable should not result in a warning, as this is the normal case. With the latest Leptonica code this requires unnecessarily tricky code. I'd use `L_INFO` instead of `L_WARNING`.  Fixed in https://github.com/tesseract-ocr/langdata/commit/3299c600323a511486fdab58c8e31258c308a7bc.
I'm retesting now. It seems the tutorial works without it, so I imagine the accuracy numbers in the tutorial will come out different. I've just updated the numbers in the training tutorial.
It seems to work apart from one thing that needs looking at - it doesn't run the eval  from the trainer.
It doesn't harm the tutorial, but will be required before people start serious training.  Not 100% sure, but I think I already have a requirement on 1.73 to support PDF generation. That is pretty aggressive. Hope the multipage TIFF users appreciate it.

On Dec 24, 2016 11:10 PM, "Amit D." <notifications@github.com> wrote:

> Since commit 11f2057
> <https://github.com/tesseract-ocr/tesseract/commit/11f205707eda769dbe6cc7d6839745f1b01a1d76>
> we depend on 1.74.0
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/540#issuecomment-269112619>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEu2ppN95ut9tOVVOanEd-g9HWJuJB6Dks5rLhbXgaJpZM4LGDsQ>
> .
>
 1.73 has O (n^3) for seeks on multi page TIFF. 1.74 drops that to O(n^2)
for the existing API and O(n) for some new API calls.

I have never made a PPA before and am not sure what is involved. Priority
is official Leptonica packaging. Unclear if l will even get that far before
the new year, due to travel.

So the answer is maybe, but I wasn't planning on it, and certainly not
right now.

On Dec 25, 2016 11:57 AM, "Amit D." <notifications@github.com> wrote:

> Jeff,
> Any chance you will provide a Leptonica 1.74 PPA for Ubuntu 16.04?
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/540#issuecomment-269135418>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEu2pj7OCq7Ics1Saik6-5_FHHfRaFm7ks5rLsrCgaJpZM4LGDsQ>
> .
>
 There are still numerous platforms without prebuild Leptonica 1.74.x. I just suggested updating the version for [MacPorts](https://github.com/macports/macports-ports/pull/180). Maybe fallback code which is slower for multi page tiffs but which works with older Leptonica versions would really be a good idea.  I'm totally fine with any decision, including reverting the new TIFF calls until Leptonica 1.74  is more widespread. This was the changelist.

https://github.com/tesseract-ocr/tesseract/commit/245eebdf293ac19f1fb85c36e51daaaa1b5e5a3e  >psm 3 - recognizes text at large font size
psm 6 - recognizes text at smaller font size

The result is similar with the best traineddata and current code, though there are differences between best/Devanagari, best/hin and best/san.

psm 3 treats smaller text as 'diacritics' - jpg at 600dpi

```
**************************** ./fontsize.jpg **********************************
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 29 diacritics

real    0m14.309s
user    0m13.406s
sys     0m0.656s
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 145 diacritics

real    0m8.970s
user    0m8.469s
sys     0m0.359s
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 145 diacritics

real    0m4.188s
user    0m3.813s
sys     0m0.375s
``` Same image at 300 dpi, gets fewer blobs recognized as diacritics.

```
**************************** ./fontsize.jpg **********************************
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 3 diacritics

real    0m18.550s
user    0m17.688s
sys     0m0.688s
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 17 diacritics

real    0m16.757s
user    0m15.203s
sys     0m0.438s
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 17 diacritics

real    0m6.672s
user    0m6.125s
sys     0m0.438s
```  Let's get a backtrace for that error message, so we can understand context and make a smart decision. I am not sure how serious a problem this is.

```
(gdb) backtrace
#0  pixClone (pixs=0x0) at third_party/leptonica/src/pix1.c:523
#1  0x000000000056c149 in tesseract::Tesseract::set_pix_original (this=0x7ffff56b5020, original_pix=0x0)
    at ccmain/tesseractclass.h:206
#2  0x00000000005636f1 in tesseract::TessBaseAPI::SetInputImage (this=0x7fffffffd8f0, pix=0x0)
    at api/baseapi.cpp:894
#3  0x0000000000569045 in tesseract::TessBaseAPI::Clear (this=0x7fffffffd8f0) at api/baseapi.cpp:2039
#4  0x0000000000562099 in tesseract::TessBaseAPI::End (this=0x7fffffffd8f0) at api/baseapi.cpp:2049
#5  0x0000000000562073 in tesseract::TessBaseAPI::~TessBaseAPI (this=0x7fffffffd8f0) at api/baseapi.cpp:133
#6  0x0000000000561429 in main (argc=5, argv=0x7fffffffdae8) at api/tesseractmain.cpp:515
``` Best guess now is that the bug is harmless, and that this is the right fix. I didn't think about this too deeply.
(Edit: Increasingly confident about harmless and that this is the right fix.)

```diff
--- tesseract/ccmain/tesseractclass.h	2017-01-26 15:05:52.000000000 -0800
+++ tesseract/ccmain/tesseractclass.h	2017-01-27 14:01:50.000000000 -0800
@@ -203,7 +203,8 @@
     pix_original_ = original_pix;
     // Clone to sublangs as well.
     for (int i = 0; i < sub_langs_.size(); ++i)
-      sub_langs_[i]->set_pix_original(pixClone(original_pix));
+      sub_langs_[i]->set_pix_original(
+          original_pix ? pixClone(original_pix) : nullptr);
   }
   // Returns a pointer to a Pix representing the best available (original) image
   // of the page. Can be of any bit depth, but never color-mapped, as that has
``` Committed. Let's wait what happens ;-)   Reports  `Pre-4.0.0` for traineddata from 4.00.00alpha

```
combine_tessdata -u ../tessdata/eng.traineddata eng.
Extracting tessdata components from ../tessdata/eng.traineddata
Wrote eng.unicharset
Wrote eng.unicharambigs
Wrote eng.inttemp
Wrote eng.pffmtable
Wrote eng.normproto
Wrote eng.punc-dawg
Wrote eng.word-dawg
Wrote eng.number-dawg
Wrote eng.freq-dawg
Wrote eng.cube-unicharset
Wrote eng.cube-word-dawg
Wrote eng.shapetable
Wrote eng.bigram-dawg
Wrote eng.lstm
Wrote eng.lstm-punc-dawg
Wrote eng.lstm-word-dawg
Wrote eng.lstm-number-dawg
Wrote eng.version
Version string:Pre-4.0.0
1:unicharset:size=7477, offset=192
2:unicharambigs:size=1047, offset=7669
3:inttemp:size=976552, offset=8716
4:pffmtable:size=844, offset=985268
5:normproto:size=13408, offset=986112
6:punc-dawg:size=4322, offset=999520
7:word-dawg:size=1082890, offset=1003842
8:number-dawg:size=6426, offset=2086732
9:freq-dawg:size=1410, offset=2093158
11:cube-unicharset:size=1511, offset=2094568
12:cube-word-dawg:size=1062106, offset=2096079
13:shapetable:size=63346, offset=3158185
14:bigram-dawg:size=16109842, offset=3221531
17:lstm:size=5390718, offset=19331373
18:lstm-punc-dawg:size=4322, offset=24722091
19:lstm-word-dawg:size=7143578, offset=24726413
20:lstm-number-dawg:size=3530, offset=31869991
23:version:size=9, offset=31873521
``` So there is no way to distinguish 3.0x traineddata from 4.00.00alpha traineddata.

I guess, program could check if component 17:lstm is there. If not there version will be 3.0x. Correct. That is exactly the plan.

On Sat, Jul 15, 2017 at 9:33 AM, Amit D. <notifications@github.com> wrote:

> The current traineddata files for 4.0 will be obsolete once Ray will push
> the new ones, which will probably have the version file.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/534#issuecomment-315545661>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056dfEz45RTZMO9q2Ke_chDarvPOkQks5sOOnOgaJpZM4LD3In>
> .
>



-- 
Ray.
 >Please add version info to traineddata files and check for correct version during runtime. 

Version Info has been added to traineddata. Thanks, @theraysmith 

Does the program check the traineddata version and give error if it is unsupported/old format?   This also fixes issue #96. What about moving to `#pragma once`? Ah,ok. No objections in this case. `#pragma once` is widely supported, but not a standard, while the include guards using macros only use standard code. Modern compilers like `gcc` or `clang` know include guards, so for those compilers `#pragma once` has no performance advantage. But less to write :) True. @zdenop, I think this PR is ready to get merged. Issue #96 can be closed then.   @rfschtkt What about these 'LEAK' related warnings? Here is some backtrace info from gdb.

It is easy to reproduce the problem. Give a non-existant filename as input for tesseract. 

gdb --args tesseract lorem1.png lorem

```
(gdb)
Tesseract Open Source OCR Engine v4.00.00alpha-496-g2b373d1 with Leptonica
506         bool succeed = api.ProcessPages(image, NULL, 0, renderers[0]);
(gdb)
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
507         if (!succeed) {
(gdb) backtrace
#0  main (argc=<optimized out>, argv=0x7ffff5d1c0f8) at tesseractmain.cpp:507

(gdb) step
508           fprintf(stderr, "Error during processing.\n");
(gdb)
fprintf (__fmt=0x4037bc "Error during processing.\n", __stream=<optimized out>) at /usr/include/x86_64-linux-gnu/bits/stdio2.h:98
98                              __va_arg_pack ());
------------------------------------------------------------
(gdb) backtrace
#0  pthread_mutex_lock (mutex=0x7f5e2efaec60 <tesseract::tprintfMutex>) at forward.c:192
#1  0x00007f5e2ea8dc0f in tprintf_internal (
    format=format@entry=0x7f5e2eab8510 "ObjectCache(%p)::~ObjectCache(): WARNING! LEAK! object %p still has count %d (id %s)\n") at tprintf.cpp:42
#2  0x00007f5e2e9f19b9 in ~ObjectCache (this=0x7f5e2ef9cda0 <tesseract::Dict::GlobalDawgCache()::cache>, __in_chrg=<optimized out>)
    at ../ccutil/object_cache.h:42
#3  tesseract::DawgCache::~DawgCache (this=0x7f5e2ef9cda0 <tesseract::Dict::GlobalDawgCache()::cache>, __in_chrg=<optimized out>) at dawg_cache.h:30
#4  0x00007f5e2daac1a9 in __run_exit_handlers (status=1, listp=0x7f5e2de2e6c8 <__exit_funcs>, run_list_atexit=run_list_atexit@entry=true)
    at exit.c:82
#5  0x00007f5e2daac1f5 in __GI_exit (status=<optimized out>) at exit.c:104
#6  0x00000000004022fc in main (argc=<optimized out>, argv=0x7ffff5d1c0f8) at tesseractmain.cpp:435

------------------------
(gdb) backtrace
#0  _IO_no_init (fp=fp@entry=0x7ffff5d1bc00, flags=flags@entry=32768, orientation=orientation@entry=-1, wd=wd@entry=0x0, jmp=jmp@entry=0x0)
    at genops.c:644
#1  0x00007f5e2db79129 in ___vsnprintf_chk (
    s=s@entry=0x7f5e2efeef80 <tprintf_internal(char const*, ...)::msg> "Tesseract Open Source OCR Engine v4.00.00alpha-496-g2b373d1 with Leptonica\n",
 maxlen=<optimized out>, maxlen@entry=65536, flags=flags@entry=1, slen=slen@entry=65537,
    format=format@entry=0x7f5e2eab8510 "ObjectCache(%p)::~ObjectCache(): WARNING! LEAK! object %p still has count %d (id %s)\n",
    args=args@entry=0x7ffff5d1bd78) at vsnprintf_chk.c:53
#2  0x00007f5e2ea8dc59 in vsnprintf (__ap=0x7ffff5d1bd78,
    __fmt=0x7f5e2eab8510 "ObjectCache(%p)::~ObjectCache(): WARNING! LEAK! object %p still has count %d (id %s)\n", __n=65536,
    __s=0x7f5e2efeef80 <tprintf_internal(char const*, ...)::msg> "Tesseract Open Source OCR Engine v4.00.00alpha-496-g2b373d1 with Leptonica\n")
    at /usr/include/x86_64-linux-gnu/bits/stdio2.h:78
#3  tprintf_internal (format=format@entry=0x7f5e2eab8510 "ObjectCache(%p)::~ObjectCache(): WARNING! LEAK! object %p still has count %d (id %s)\n")
    at tprintf.cpp:56
#4  0x00007f5e2e9f19b9 in ~ObjectCache (this=0x7f5e2ef9cda0 <tesseract::Dict::GlobalDawgCache()::cache>, __in_chrg=<optimized out>)
    at ../ccutil/object_cache.h:42
#5  tesseract::DawgCache::~DawgCache (this=0x7f5e2ef9cda0 <tesseract::Dict::GlobalDawgCache()::cache>, __in_chrg=<optimized out>) at dawg_cache.h:30
#6  0x00007f5e2daac1a9 in __run_exit_handlers (status=1, listp=0x7f5e2de2e6c8 <__exit_funcs>, run_list_atexit=run_list_atexit@entry=true)
    at exit.c:82
#7  0x00007f5e2daac1f5 in __GI_exit (status=<optimized out>) at exit.c:104
#8  0x00000000004022fc in main (argc=<optimized out>, argv=0x7ffff5d1c0f8) at tesseractmain.cpp:435
(gdb) next
```

 Thanks. I had also noticed the -O2 and -O0 combinations while building with
enable-debug, and was going to pose a question,  since i dont know about it.

On May 12, 2017 8:19 PM, "rfschtkt" <notifications@github.com> wrote:

> Well, I was thinking more along the line of inspecting the offending
> object. Apparently fixing the problem I perceived didn't solve the problem,
> so I'll try gdb myself. Unfortunately ./configure --enable-debug doesn't
> seem to work, because there are -O2 arguments after the -O0 ones, and the
> last one in the room wins, so my workaround for that is to edit configure
> and configure.ac. Stay tuned...
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/529#issuecomment-301097602>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o6xmD6TVpQL98C2obU2Us2UcXXe6ks5r5HFlgaJpZM4LDjOe>
> .
>
 Thank you! 

This fixes the problem in the testcase I had mentioned `Give a non-existant filename as input for tesseract.`

```
shree@ALL-IN-1-TOUCH:/mnt/c/Users/User/shree/tesseract-head$ tesseract lorem1.png lorem
Tesseract Open Source OCR Engine v4.00.00alpha-512-g6bebe71 with Leptonica
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error during processing.
```

However, there are a few other cases where the error was occuring, eg. Missing output directory, please see https://github.com/tesseract-ocr/tesseract/issues/529#issuecomment-269325872

In that case now I get a different error:

```
 gdb --args tesseract p002-crop.bmp missing/bmp --oem 1 --psm 6 -l hin

(gdb) run
Starting program: /usr/local/bin/tesseract p002-crop.bmp missing/bmp --oem 1 --psm 6 -l hin
warning: Error disabling address space randomization: Success
warning: linux_ptrace_test_ret_to_nx: PTRACE_KILL waitpid returned -1: Interrupted system call
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".

Tesseract Open Source OCR Engine v4.00.00alpha-512-g6bebe71 with Leptonica
Error during processing.

Program received signal SIGSEGV, Segmentation fault.
_IO_new_fclose (fp=0x0) at iofclose.c:54
54      iofclose.c: No such file or directory.

(gdb) backtrace
#0  _IO_new_fclose (fp=0x0) at iofclose.c:54
#1  0x000000000041a617 in tesseract::TessResultRenderer::~TessResultRenderer (this=0x1bb0160, __in_chrg=<optimized out>) at renderer.cpp:51
#2  0x000000000041b28f in tesseract::TessTextRenderer::~TessTextRenderer (this=0x1bb0160, __in_chrg=<optimized out>) at renderer.h:141
#3  0x000000000041b2be in tesseract::TessTextRenderer::~TessTextRenderer (this=0x1bb0160, __in_chrg=<optimized out>) at renderer.h:141
#4  0x00000000004083d6 in GenericVector<tesseract::TessResultRenderer*>::delete_data_pointers (this=0x9095c0 <main::renderers>)
    at ../ccutil/genericvector.h:874
#5  0x0000000000407f48 in tesseract::PointerVector<tesseract::TessResultRenderer>::clear (this=0x9095c0 <main::renderers>)
    at ../ccutil/genericvector.h:522
#6  0x0000000000407c7c in tesseract::PointerVector<tesseract::TessResultRenderer>::~PointerVector (this=0x9095c0 <main::renderers>,
    __in_chrg=<optimized out>) at ../ccutil/genericvector.h:456
#7  0x00007f7a7a58c1a9 in __run_exit_handlers (status=1, listp=0x7f7a7a90e6c8 <__exit_funcs>, run_list_atexit=run_list_atexit@entry=true)
    at exit.c:82
#8  0x00007f7a7a58c1f5 in __GI_exit (status=<optimized out>) at exit.c:104
#9  0x0000000000407863 in main (argc=9, argv=0x7ffff50bc518) at tesseractmain.cpp:518
(gdb)
```

 @rnmanhon Please check your testcase also. https://github.com/tesseract-ocr/tesseract/issues/529#issuecomment-299127136

I am not getting the error with the latest code. I had not tested it earlier.

```
$ cp  p002-crop.bmp /tmp/tess__cwb36mk.bmp
$ tesseract /tmp/tess__cwb36mk.bmp output.txt
Tesseract Open Source OCR Engine v4.00.00alpha-512-g6bebe71 with Leptonica
$ These changes may also need to be backported for 3.05. 

Testcase https://github.com/tesseract-ocr/tesseract/issues/529#issuecomment-294188223 @stweil @rfschtkt :~ObjectCache(): WARNING! LEAK! problem is fixed. So I am closing this issue.

Thanks! Is it from https://github.com/UB-Mannheim/tesseract/wiki

http://digi.bib.uni-mannheim.de/tesseract/

http://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-4.00.00dev.exe

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sat, Jun 17, 2017 at 5:02 PM, mgrint2 <notifications@github.com> wrote:

> Installed package tesseract-ocr-setup-4.00.00dev
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/529#issuecomment-309209698>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o76bGYd0ZIXge4CI7u_1HWCCyZgiks5sE7ligaJpZM4LDjOe>
> .
>
 Error in fopenReadStream: file not found
Error in findFileFormat: image file not found

You need to give correct location of image file.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sat, Jun 17, 2017 at 5:32 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
wrote:

> Is it from https://github.com/UB-Mannheim/tesseract/wiki
>
> http://digi.bib.uni-mannheim.de/tesseract/
>
> http://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-
> setup-4.00.00dev.exe
>
> ShreeDevi
> ____________________________________________________________
> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>
> On Sat, Jun 17, 2017 at 5:02 PM, mgrint2 <notifications@github.com> wrote:
>
>> Installed package tesseract-ocr-setup-4.00.00dev
>>
>> —
>> You are receiving this because you modified the open/close state.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/529#issuecomment-309209698>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AE2_o76bGYd0ZIXge4CI7u_1HWCCyZgiks5sE7ligaJpZM4LDjOe>
>> .
>>
>
>
  So here's how it works:
The LSTM unicharset is embedded inside the .lstm component itself. That enables it to be different from the unicharset for base tesseract, without a proliferation of new traineddata components.
It was convenient at the time for the trainer to be able to save and load checkpoints in a single file.
The dawgs offer only a slight improvement over the LSTM model itself, as that is very good on its own, and will easily nail phototest.tif without the language models. (Even the vie lstm model will nail phototest.tif.)

Closing as working as intended. Reopen if you really need to get at the unicharset for some reason.  Fixed in https://github.com/tesseract-ocr/tesseract/commit/65517794f9bbc41a202d1fe410ff269f00257e57
  @joshimar, if you updated from an older version of Tesseract, you have to re-run `./autogen.sh` to create an updated `configure` script. The latest Tesseract version from Git always shows the reason why training tools cannot be built, so either you are using an old and buggy Tesseract code or you missed updating `configure`, too. Can you upload your full build log (output from configure and make) somewhere, so I might have a look? I need the make output as well. configure shows that OpenMP is supported. Your problem is caused by partial OpenMP support. I think that `configure --disable-openmp` will work for you (but result in slow binaries). Yes, you already said that training tools cannot be build with your 3.05 (is it the latest 3.05?).

`configure --disable-openmp` was meant to be used with 4.0. This is caused by https://github.com/tesseract-ocr/tesseract/commit/6140be6a5575e9159e3678adf4ee9e673b3ff2cc. If I cherry-pick it to 3.05 build will failed with gcc... OpenMP never worked for 3.05. Commit 6140be6 fixed OpenMP support partially. I'll send updates which fix the remaining issue. @stweil:  Thanks. At this stage I am more concerned with build process than if feature works ;-) @joshimar, please try latest versions from git (master and 3.05) and close this issue if it works now. `configure` uses `pkg-config` to find Leptonica and libicu, so at least the *.pc files must be found by `pkg-config`. They are not found because you had chosen a different install path. Either copy the *.pc files to the correct location, or tell `pkg-config` how to find them (please look into the manual for that). The first check is from pkg-config (failed), the second one is the old fallback check (which is removed in PR #577). That's strange. You can debug the problem like this:

* Edit `configure.am`: remove the first line with `AM_CONDITIONAL([ENABLE_TRAINING], false)`
* Run `./autogen.sh`
* Try `./configure`
* Repeat all three steps until you find which line caused the problem
 checkout master. Should be fixed.  What is an issue?  1. use tesseract user forum for asking question.
2. this is more leptonica build problem (allowed warnings)
3.  Did you tried https://github.com/tesseract-ocr/tesseract/wiki/FAQ#how-can-i-suppress-tesseract-info-line? > They will not appear in Linux. 
Because that problem is related to windows... The warnings are an indicator for potential optimizations and require more examination by developers, so I see there an issue to be discussed here.

AFAIK Leptonica warns when an image file is going to be mapped to memory, something that is unsupported for Leptonica's Windows code which uses a temporary file copy as an alternative.

If OCR of a single image results in many (number of lines) of those warnings, that might be caused by the same image being opened very often, or Tesseract acts on in-memory line images, but Leptonica for Windows has to write those images to disk. Then it is clear that at least for Windows the performance suffers and something should be done - either in Leptonica code or in Tesseract. > Is the version of leptonica included with the windows binaries a debug version?

No, it is production code. Such warnings also occurr(ed) with Tesseract 3.05 and earlier, for example when processing JPEG 2000 images (but only once per image). Some improvements in newer Leptonica code reduced the cases where this kind of warnings are shown. > How did you compile Leptonica?

Basically I used `./configure: make; make install`, but in a cross build on Debian GNU Linux. Technically, the warnings occur on any platform which does not have a `fmemopen` function. Leptonica outputs them using a macro `L_WARNING`. It is possible to call `setMsgSeverity` from Tesseract code to disable any warning message from Leptonica (I don't think that would be a good idea). That would be possible, yes. But without those nagging messages, I'd never have had a look on that part of Leptonica. @DanBloomberg : Thanks for support. Maybe it would be good to enable all warning for debug builds and hide them for release builds.  Yes!
I've been working on it in conjunction with the removal of cube, and it's
getting close.

On Fri, Dec 2, 2016 at 12:31 AM, Amit D. <notifications@github.com> wrote:

> @theraysmith <https://github.com/theraysmith>, any chance you'll fix that
> for the final 4.0 release?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/521#issuecomment-264400486>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056a_L8S11vxRB-0KJWJoTowd2O8Q0ks5rD9dHgaJpZM4LCRAs>
> .
>



-- 
Ray.
 Partly. I haven't closed it because you can't *create* a traineddata file
with just the LSTM part(s) yet, and I am working on fixing that as well.

On Tue, Dec 6, 2016 at 1:42 AM, Amit D. <notifications@github.com> wrote:

> @theraysmith <https://github.com/theraysmith>, can you confirm that
> 5deebe6
> <https://github.com/tesseract-ocr/tesseract/commit/5deebe6c279f70215935c1f86baa7e7016c7f2a7>
> solved this issue?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/521#issuecomment-265104978>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056XMVGWYPqK1Pc8XzqTxrzYjHZxgZks5rFS4MgaJpZM4LCRAs>
> .
>



-- 
Ray.
 Sorry, I wasn't aware of that.
Added.
I don't know of anything else missing. Please let me know if you can't get
through the tutorials.
I will fix the doc when I have the LSTM-only training working properly.


On Tue, Dec 6, 2016 at 8:10 AM, Shreeshrii <notifications@github.com> wrote:

> @theraysmith
>
> Ray, I am not able to try out LSTM training as repo is missing LSTM.train
> config file. Are there other pieces also that you need to add?
>
> On 06-Dec-2016 8:59 PM, "theraysmith" <notifications@github.com> wrote:
>
> > Partly. I haven't closed it because you can't *create* a traineddata file
> > with just the LSTM part(s) yet, and I am working on fixing that as well.
> >
> > On Tue, Dec 6, 2016 at 1:42 AM, Amit D. <notifications@github.com>
> wrote:
> >
> > > @theraysmith <https://github.com/theraysmith>, can you confirm that
> > > 5deebe6
> > > <https://github.com/tesseract-ocr/tesseract/commit/
> > 5deebe6c279f70215935c1f86baa7e7016c7f2a7>
> > > solved this issue?
> > >
> > > —
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/521#
> > issuecomment-265104978>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/
> > AL056XMVGWYPqK1Pc8XzqTxrzYjHZxgZks5rFS4MgaJpZM4LCRAs>
> > > .
> > >
> >
> >
> >
> > --
> > Ray.
> >
> > —
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/521#
> issuecomment-265179343>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_
> o3NKfgM6IGnUvuVAqYrFirHq_0FMks5rFX9IgaJpZM4LCRAs>
> > .
>
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/521#issuecomment-265191525>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056Tf7yXmVGGBTEDzc-k9-4lyMf6wyks5rFYkGgaJpZM4LCRAs>
> .
>



-- 
Ray.
 It did. It should now be possible to create a traineddata containing just a .lstm component and run recognition with it.  There are different approaches possible to get support for big endian machines:

1. Write training data files in native endian byte order. When reading that data Tesseract must automatically detect the endianness used and convert it to native byte order if necessary, that means if training (=writing) machine and OCR (=reading) machine use different byte order.
2. Write training data files with fixed endianness. When reading that data Tesseract must only convert the data if it uses a different byte order.

The current code obviously tries to implement the first variant: it uses `swap` parameters for the functions which read data and sets the value of `swap` based on the training data.

I prefer the second variant and suggest to always use little endian training data files. Then the most common little endian platforms can use the data without the need to do byte swaps. Big endian hosts can use fixed code to convert the data when reading or writing them. This results in less complex code: the `swap` parameters are no longer needed.

My [`endian` branch](https://github.com/stweil/tesseract/tree/endian) includes experimental changes which remove (most) `swap` parameters and implement the read part for big endian machines. I could successfully run `api/tesseract testing/phototest.tif stdout` on a big endian S390X (QEMU emulation).

@theraysmith, if you agree to switch to that different solution for the endianness problem, I'd continue with the write part. In a first PR I'd remove the current `swap` code. How does the big-endian machine know which values are of which sizes, and types and therefore how to swap? Please explain how that works if the swaps are all removed from the deserialize methods.
I couldn't find any replacement swapping code in your pull request. That's done by the function `convert2le` (see PR #703) which is overloaded for the relevant data types. Depending on the macro `WORDS_BIGENDIAN` that function either swaps bytes or does nothing. You said you successfully ran on phototest.tif on a big-endian machine.
Is that using the LSTM implementation?
I don't see how that could possibly succeed as separated deserialize/swap, since matrix.h has to swap the sizes that it deserializes in order to know how big a matrix to deserialize.
I don' think this is a good idea. Most of the swap code required for the LSTM implementation is already in place, so to support big-endian from here isn't difficult really. Certainly a lot easier than making this work. My test used the default (Tesseract + LSTM). My code includes changes to `matrix.h` which do the swapping needed. Did you read my comments above about the drawbacks of the current implementation? Three small points.

From a software distribution standpoint, it is pretty burdensome to require 
different data files for big endian architectures. If that's true for 3.04 then
I've been shipping broken software.

Microsoft and Torvalds have almost entirely killed off big endian machines 
by now. For example, Solaris development was killed off in December 
according to the press.

Any efforts on this topic get cut in half if the non-LSTM recognizer is removed. I strongly vote against removing non-LSTM as we currently still get better results with it in some cases.

Technically it is possible to have BE and LE machines creating different training data as long as both are able to fix that during read. But this is one of the drawbacks: each Tesseract must be able to read both variants of training files (which results in less efficient code). In addition it is more difficult to compare the training output from LE and BE machines. @theraysmith, a new test with explicit `--OEM 1` just passed successfully on my BE machine. > Ray, you can see online Stefan's suggested changes here.

or [here](https://github.com/tesseract-ocr/tesseract/pull/703/files). In the meantime I have improved that experimental code further (based on PR #706) and will send an update later. It still only addresses reading, but adding write support to enforce little endian training data files is rather easy following the same scheme.

@jbreiden, did you ever test 3.05 or older versions with big endian machines? If not, I can run a test on my s390x emulation.
 I assume that most binary file formats do. See also https://en.wikipedia.org/wiki/Endianness#Files_and_byte_swap. **Please provide examples of where you get better results with the old engine.**
Right now I'm trying to work on getting rid of redundant code, rather than spending time fighting needless changes that generate a lot of work. I have recently tested an LSTM-based OSD, and it works a lot better than the old, so that is one more use of the old classifier that can go. AFAICT, apart from the equation detector, the old classifier is now redundant.

I disagree with the assessment that protocol buffers use Stefan's method, as I still haven't had an explanation of nor seen code to show how the reading of a little-endian file on a big-endian machine works. This comment on proto buffers "Yep.  On the wire, things are encoded little-endian, but the encoding and decoding routines will convert to and from your machine's format themselves, so you don't need to worry about it." sounds exactly like what the code currently does.

I don't think having a collection of big-endian data files works if that is the proposal. That would be very ugly. **What exactly is the proposal for classes like Matrix?** Basically the swaps have to stay in place, but could be predicated on an #ifdef instead of runtime data. Even that would make the code ugly, and I don't see a huge amount of CPU being burnt testing if (swap), so I don't really see what all the fuss is about over code efficiency compared to the wasted effort messing about with the code.

In summary, I haven't seen a coherent, convincing argument that there is anything wrong with the current solution of the code only swaps the data if it needs to, which most of the time it doesn't because all data files are little-endian and almost all machines are little-endian. > Please provide examples of where you get better results with the old engine.

I'll do that in the discussion of the new issue #707.

> What exactly is the proposal for classes like Matrix?

The current implementation uses `DeSerialize` functions with `swap` parameters and calls `ReverseN` if that parameter is true, see [example](https://github.com/tesseract-ocr/tesseract/blob/master/ccstruct/matrix.h#L155).

My [experimental implementation](https://github.com/stweil/tesseract/tree/endian) removes the `swap` parameters and the code based on them in `ccstruct/matrix.h` which IMHO makes the code much prettier. Of course we still need swapping for big endian machines (otherwise my OCR tests on such machines would fail). That is done by replacing all `fread` function calls by different ones which I also called `fread` in my experimental code but which should be renamed into `DeSerialize`, see [example](https://github.com/stweil/tesseract/blob/endian/ccstruct/matrix.h#L154). Those new functions both read (using the normal `fread` function) and convert to little endian (using new functions [`convert2le`](https://github.com/stweil/tesseract/blob/endian/ccutil/tessio.h#L15)). They are implemented in the new file [`ccutil/tessio.cpp`](https://github.com/stweil/tesseract/blob/endian/ccutil/tessio.cpp).

The new code simply uses new functions for all reads from file, so getting all cases where swapping is needed is much simpler than in the current implementation. The same can be done on writing to achieve little endian data files, no matter what endianness the host is using. >did you ever test 3.05 or older versions with big endian machines?

No, I don't currently have my hands on a big endian machine. I'm pretty sure that I could get my hands on one, but so far I have not made the effort. As a side note, I'm helping ship Tesseract is on 23 different architectures, some of them big endian. They all share the same data files. However, the big endian platforms are very rarely used and there may not be bug reports, even if totally broken.

https://buildd.debian.org/status/package.php?p=tesseract&suite=unstable I now have run a test (`tesseract testing/phototest.tif stdout`) with Tesseract 3.05 on big endian s390x (QEMU emulation) successfully. OK, now I finally understand your proposal, I like some aspects of it, but I have some suggestions for making it better:
1. Since all data files are de-facto little-endian, the overloads are only needed on a big-endian machine. I haven't yet found the source code for convert2le, but I get the gist of what you are trying to do.
2. Move all the overloads of fread to overloads of TFile::FRead. (See ccutil/serialis.h).
3. Hide all the overloads behind an #ifdef __BIG_ENDIAN__ so the little-endian machines just call the generic (void*) version of FRead. (I haven't researched it thoroughly, but this posting might be better: http://esr.ibiblio.org/?p=5095)
4. Anything needed by the new engine (should be just the Network and subclasses, Dict/Dawg and UNICHARSET) make sure it loads from a TFile and convert it if it doesn't.
5. Instead of modifying the old engine parts, concentrate on convincing me why it should stay first, but if you really want to do it, map all the I/O in the old engine to TFile and get rid of the use of FILE.
6. Does convert2le have any practical use at that point? Surely just call ReverseN directly from the overloads? (Like I said I haven't found the code for convert2le, and I missed the link for it if you provided it.)

Then I agree it would be cleaner, smaller, and more efficient, as well as future-proofed. Fixed in commit https://github.com/tesseract-ocr/tesseract/commit/8e79297dcefecdb929d753d28554fec51417ec39 The code that is there now is far simpler and cleaner than anything that
was there before.
While there is still minor overhead in deserializing, it is small, as there
is only one check for each array.
To write only little-endian files would be a lot more work on the dead
code, so it isn't worth it. This was already a lot of work on the dead code
as it is.

On Wed, May 3, 2017 at 10:02 PM, Stefan Weil <notifications@github.com>
wrote:

> Ray, the new code still uses a dynamic detection in
> TessdataManager::LoadMemBuffer to decide whether swapping is needed or
> not. This implies that the code supports both big and little endian data
> files. The drawback is additional runtime code on all kinds of machines.
>
> Are you planning more changes? I'd drop support of big endian data files
> in 4.0 and add code to always write little endian ones. Then static
> swapping code would only be needed on big endian machines, and the large
> majority of machines would not need any swap code at all.
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/518#issuecomment-299097442>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056UZK6qi93qEj5bdhFUjJ6ULWHoxpks5r2VvVgaJpZM4LBZNs>
> .
>



-- 
Ray.
  I've now fixed it properly.
When I did my original pull, all I got was the double free.
The solution that frees outside of GetAdaptiveFeatures is not as clean as freeing properly inside.  Also @zdenop 

I propose to replace all such stuff with c++11 unique/shared ptrs for the future versions.
If we get agreement on this I could start modernizing codebase. I just need a greenlight.
I'm almost sure that other people will like it and help with the process. Let wait for a while with this changes:

1. It seems Ray will push more code soon...
2. I tried to transfer fixes to 3.05 branch. 3.05 should be possible to build without c++11 need (I am slow because I have limited time and I can test (just build) it on VS2010 in limited scope...)  The alternative variant of InitCharset is used internally at Google to save accessing the script-dir directory from a trainer running in a Google data center. It is easier to pack the unicharset and recoder in a proto buffer in a separate step. If anything the other variant could prepare the recoder and then call the one that takes a recoder. I rebased the PR now to fix a merge conflict in `lstm/lstmtrainer.cpp`. Continuous integration fails because of missing `tesseract::LSTMTester::LSTMTester(long)`. This is unrelated to this PR. I rebased to fix the build with CMake in the continuous integration. Thanks, I knew that. In this case the trick would not have worked because the CI problem was only fixed in git master.  Rebased PR to fix merge conflict.  You could use https://cppan.org/ also. It's already present in repository. I won't be adding vcpkg port. If someone else needs this, please do it.  See [forum](https://groups.google.com/forum/#!topic/tesseract-ocr/e__2DN1GQb0) or [wiki info](https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00#for-open-source-contributors).  The  « un animal politique » is right there in your example. Not sure what the problem is.
Works for me on eurotext.tif  Please use tesseract user forum for asking support.  Current master repository is for tesseract developers and not for end users.  Please use teseract forums for asking questions... 
Changing urls of old(er) pages is IMO bad idea - it will break links on other pages/projects... @amitdo: can you please clarify? I think  fresh new wiki page titles could be changed...  You can sent pull requests...  Please use tesseract user forum for asking support.  Please provide all input files Please provide also information about tesseract version and OS. @sjaanus Is your issue resolved? Please mention the solution and close the issue.  AFAIK there is the limit for [system variable](https://blogs.msdn.microsoft.com/oldnewthing/20100203-00/?p=15083) - but I am not sure if this is a case also in Windows 10.
Anyway this is not tesseract project issues - so I am closing issue.
  Please contact those you created your package. We do not created linux packages.
  I can not reproduce described behavior. Please upload somewhere your files, that demonstrate problem.
 Closed because of no proof of described error.   AC_CHECK_LIB macro tests whether the library (leptonica) is providing function (l_generateCIDataForPdf). if l_generateCIDataForPdf is not present in leptonica configure will fail (because tesseract compilation would fail for the same reason). So adding linking to libpng is IMO wrong - png library is not required by tesseract. configure is just testing if function l_generateCIDataForPdf is present (e.g. we have correct version of leptonica) or not (we have wrong version of leptonica).
And this is not fixing issue #435 - if you use wrong (old) library it does not matter if libpng is present or not.
  Please do not use issue tracker for asking question - use teseract user forum
  IMO this check has nothing to do with tesseract.
@egorpugin  can you have a look on this?
 Tess uses lept and the process does appropriate checks for each dependent project.
@datalurkur Do you use the latest CPPAN client? If not try to update it. If yes I need to investigate this more closely, maybe with more help from you.
 It's cppan issue. I'm investigating.
 @datalurkur Is it possible to chat with you somewhere (maybe skype etc.) and also could you share your desktop with me (in skype again or teamviewer)?
Because it works for me on my machine.
And I need some infos from you:
1. cmake version
2. list of processes (maybe cppan or cmake hangs)
3. files on disk in `c:\Users\u\AppData\Local\Temp\cppan\vars\`
 > Regarding files in that directory, are you looking for a recursive list?

That would be nice. But before, please remove all stuff in `c:\Users\u\AppData\Local\Temp\cppan\vars\`, re-run cmake as you did earlier. When cmake hangs, check task manager (or process explorer) and make sure that cmake processes performs nothing (cpu usage will be 0 instead of 13% in case of 8 cores). So, when cmake children perform nothing do a recursive list of vars dir (maybe with `tree` command).

If cmake processes are running probably the issue somewhere in its scripts (they're generated by cppan). cppan process just waits for them.
 From this text it's not clear where 3.6.2 folders reside. Are they under CMakeFiles dirs?
Please do `tree /F`. It will show files too.
The output should be something like that http://imgur.com/4bPuWJB
 Looks terrible. :) And not useful. Could you please post a screenshot of tree output and remove that text from your comment?
 Not good. Could you post a screenshot like this? http://imgur.com/4bPuWJB
 It's ok now, thanks! Everything seems to be fine there (atleast in dir `0`).
 Could you also please send me a screenshot of task manager with list of processes (details tab on win10) when hang occurs? I'm interested in cmake/cppan processes with command lines (right click on columns at the top of the table - select columns - command line or command args).
 Image is empty for me :(
 Is that all? Only 3 cmake processes?

Could you try to clear `c:\Users\u\AppData\Local\Temp\cppan\` dir, re-run `cmake .. -DSTATIC=1` and make same screenshot again? I'm asking this because I see the same dir name `0XektimK` in your messages. Maybe fresh dir could say me something.

Please do two screens: one right after parallel checks start and after 3-5 mins (when there's 0% cpu load by cmake processes).

And more here - could you please then (after hang occurs) archive the whole `c:\Users\u\AppData\Local\Temp\cppan\vars\SomeRandomLetters` dir and send it to me (attach here).
 Are there any 'cl.exe' processes hanging around? Maybe `MSBuild.exe`?
It's better to check this when no other Visual Studio instances exist.
I suspect that:
1. initial cmake call is waiting for cppan
2. cppan is waiting for cmake children
3. these hanged cmake processes are waiting for visual studio `cl.exe` or `MSBuild.exe` or even `cmd.exe` or `conhost.exe`.
 Try to kill all conhosts one by one. On some step you should see some progress with cmake processes (increased cpu usage or death of that cmake process or smth else).
 That's true - cmakes are waiting for someone or deadlocked inside.
 Could you try Process Explorer to check out children of those cmake processes? https://technet.microsoft.com/en-us/sysinternals/processexplorer.aspx

You should see process tree like this http://imgur.com/FDhmOHQ
Please, attach a screenshot of cmake call tree (maybe re-run it to keep your main cmd.exe window and full process tree online).
 No children? :) Looks like cmake issue.
 Ok, next step:
1. Keep in mind the number of hanged cmake process. It's a number of a worker (0-7) - last digit or dir name in cmake command line (e.g. `c:\Users\u\AppData\Local\Temp\cppan\vars\SomeRandomLetters\7` - 7 is the needed number).
2. Kill all hanged cmake processes.
3. Go to `c:\Users\u\AppData\Local\Temp\cppan\vars\SomeRandomLetters\YouCmakeHangProcessLastDirNumber`)
4. Run in that dir `cmake .`
 I've already seen bugs in cmake while developing cppan. Fixes will appear in cmake-3.7. But those are not issues you hit.
The best way in your case is to build debug version of cmake, put in into `c:\program files (or x86)\cmake\bin`, run cmake on tess library as you're doing and attach to hanged cmake processes.
 Try to go to `c:\users\u\.cppan\storage\cfg` and remove it completely (`cfg` dir). Then re-run cmake as you did.
 Yes, you can try to remove the whole storage dir at `c:\users\u\.cppan\storage\`.
 To keep you up to date.

I was hit twice by this deadlock or whatever it is.
On my system it's very rare and not repeatable.
Second time it was "unlocked" accidentally in 30-45 seconds without my actions but with error `process cannot be started`.
It seems the issue in cmake's startup process. In other words it hangs when it invokes msvc compiler.
And it also possible that this is not cmake fault but `cl.exe` or `Windows` issue itself. Ok, I've hit by deadlock again and debugged cmake process.
I filed an issue in cmake tracker, but don't know if they'll be able to fix it in the near future.
https://gitlab.kitware.com/cmake/cmake/issues/16461

As a temporal solution here I will add an option for performing checks in single thread. This will prevent such errors (I hope). It will be available with the next cppan client release. I'll ping about it here. Yes. And more to say if you kill cppan process (responsible for parallel var checks) the overall process won't fail, it will switch automatically to single thread mode.

I've added njobs flag already, but the client version is not uploaded yet. I'm fixing the rest of the bugs. Hi there!
0.2.0 is out!
To lower number of parallel jobs, put to the config in `c:\users\u\.cppan\cppan.yml` line `var_check_jobs: N`, `N` is your number.
But...
CMake devs told me that they also have such hangs, so even 1 thread may hang.  AFAIK this should be initial support for OpenCL. Unfortunately it was not extended until this time.
  > A generic version that can be compiled for either Windows code pages or Unicode

This should be used by default. No suffix - compiler will choose it without user.
No need to rename functions.

Please, provide your way of building tess/lept. So, types should be fixed, not functions.  This is old error that was already fixed.
  Since tess is using c++11 we need to `s/NULL/nullptr/`.
 It's all about Ray. Such changes can break his merges.  Please use teeseract user forum for asking support.
  "Units: Undefined" is not so great. If you set it, things work correctly. 
Will have to look more carefully what the unit possibilities are for PDF to
see if we want to make a code change or not.

```
$ mogrify -units PixelsPerInch --density 300x300 pngfromtif.png
$ identify -verbose pngfromtif.png
  Geometry: 2479x3500+0+0
  Resolution: 118.11x118.11
  Print size: 20.9889x29.6334
  Units: PixelsPerCentimeter

$ tesseract  pngfromtif.png correct pdf
$ pdfinfo correct.pdf
Producer:       Tesseract 3.04.00
Page size:      594.96 x 840 pts
```
 Haven't had time to look at TIFF, but the PNG behaviour looks right. Spec says we know nothing about image resolution. Common practice from time immemorial is to default to some hopelessly wrong value. I could go trace code to find out what number was used, but honestly this is a garbage in, garbage out situation. Not sure it is worth spending time on. Are you in contact with the authors of the program that is producing the bad metadata? Fixing that is top priority.

```
The following values are legal for the unit specifier:
   0: unit is unknown
   1: unit is the meter
When the unit specifier is 0, the pHYs chunk defines pixel aspect ratio only; the actual 
size of the pixels remains unspecified.
```
 1) Why use two convert commands instead of just one?
2) I suggest PNG over uncompressed TIFF. Filesize of the PDF should be smaller, and because Tesseract  can skip transcoding the image, there will be some CPU savings as well.
  true
  Please use tesseract user forum for asking support.
  Please use tesseract user forum for asking support.
  > Is it correct that there's a PSM 11 and 12 mode?

Yes. and PSM 13 too.
You revealed our secret! :)
https://github.com/tesseract-ocr/tesseract/blob/8d6dbb133b41/api/tesseractmain.cpp#L115

I'm sorry, I do not have good answers to your other questions.
 master(4.00) & 3.05 repository produce help message for psm 11-13  Which fonts are used there?
  Please use tesseract user forum for asking support.
  > Tesseract just spent seven hours trying to do OCR on the attached document. It's five pages long. 

Wow, this is really extreme!
 Well, I tested it and it takes less than 5 minutes...

Tesseract (the official command line tool) does not accept pdf as input, so how did you convert the pdf to a format that Tesseract accepts?

Here is what I did:

```
convert gov.uscourts.ctd.18812.88.0.pdf gov.png
```

This command will create 5 'gov-n.png' images.

First page:

```
tesseract gov-0.png gov-0
```

time: 1 minute and 5 seconds
 ```
gs -dQUIET -dSAFER -dBATCH -dNOPAUSE -sDEVICE=tiffgray -r300x300 -o gov2.tiff gov.pdf
```

Your command creates a **730 MB** tiff file, while my command creates **5 200-300 kB** png files.
 ![gov-0](https://cloud.githubusercontent.com/assets/13571208/18798851/1cd055f8-81dd-11e6-8f33-9f38db58d84c.png)

Image properties:
Width: 35.417 Height: 45.834
DPI: 72 X 72

This is equivalent to:
Width: 8.5 Height: 11
DPI: 300 X 300
 `gs -dQUIET -dSAFER -dBATCH -dNOPAUSE -sDEVICE=tiffgray -r72 -o gov.tiff gov.pdf`
OR
`gs -dQUIET -dSAFER -dBATCH -dNOPAUSE -sDEVICE=tiffgray -o gov.tiff gov.pdf`

This command creates a **42 MB** tiff file. The size **in pixels** of each page is the same as with my PNGs.

It takes 4 minutes and 29 seconds to Tesseract to read this tiff.
 @Shreeshrii commented:

> To get accurate results, you will need to preprocess the images too to get
> rid of the background speckles.

I'm guessing that it will run faster too.

BTW, Here is what Tesseract outputs in the console:

```
time tesseract gov.tiff gov
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Detected 1875 diacritics
Page 2
Detected 1338 diacritics
Page 3
Detected 1885 diacritics
Page 4
Detected 658 diacritics
Page 5
Detected 213 diacritics

real    4m29.118s
user    4m28.972s
sys 0m0.152s
```

It 'thinks' the speckles are diacritics...
 This PDF file is just a bag of images. This is very common and was probably produced by
a photocopier or sheetfed scanner. Some fax machines make these too. It is entirely
black and white. If you know you are working with black and white images, you can
save a ton of space by using appropriate compression. This command renders 100% 
equivalent images for 2.3MB.

  gs -dQUIET -dSAFER -dBATCH -dNOPAUSE -sDEVICE=tiffg4 -r300x300 -o gov2.tiff gov.pdf

That said, best practice for known 'bag of images' PDF is not to render anything. It is to
extract the images, undisturbed. If necessary, adjust their header so that their resolution
(e.g. 300 dpi) agrees with what the PDF was claiming. In an ideal world they would always
be consistent already, but programmers screw this up all the time. That's the thing you
feed to Tesseract (assuming you don't want to do any additional cleaning or something.) 
This workflow is kind of sophisticated and maybe not easy for everyone. But it makes 
more sense than potentially rescaling the images by rendering to a different dpi.

I just want to put this here because there are several different references being cited in this 
bug report about work flow. Please  consider this one authoritative.

It does not however address the core question about dots, which seems like a legitimate
concern. This will be an interesting test document for future development.
 @jbreiden

> This command renders **100% equivalent** images for 2.3MB.

`gs -dQUIET -dSAFER -dBATCH -dNOPAUSE -sDEVICE=tiffg4 -r300x300 -o gov2.tiff gov.pdf`

This command will upscale the original images. It will make them more than 4 times larger. This is unnecessary because the DPI of the original images inside the pdf is 300X300, although the pdf itself falsely 'claims' that the DPI for these images is 72X72.
 I was just encouraging -sDEVICE=tiffg4 over -sDEVICE=tiffgray for known black and white images. You are right, care should be taken to avoid rescaling, and that's the primary reason image extraction is safer than rendering.
 https://github.com/DanBloomberg/leptonica/search?q=noise
 In this buggy broken world, do whatever it takes to get the resolution right. I rescind my recommendation to honor the PDF settings.  If you crack open gov.uscourts.ctd.18812.88.0.pdf, you can see that it really does contain black and white images. The telltale is BitsPerComponent 1 and the internal use of CCITTFaxDecode, which only works on black and white. 

```
<<
/Type /XObject
/Filter [/CCITTFaxDecode]
/Length 60 0 R
/Height 3300
/BitsPerComponent 1
/ColorSpace [/DeviceGray]
/DecodeParms [61 0 R]
/Subtype /Image
/Name /Im1
/Width 2550
>>
```

http://stackoverflow.com/questions/2641770/extracting-image-from-pdf-with-ccittfaxdecode-filter

The embedded black and white image inside the PDF is already dithered. Ghostscript is innocent. Normally I prefer to feed Tesseract images that have been messed with as little as possible, but this may just be the exception. Tesseract is not trained on dithered text. Good luck with this one!

![foo](https://cloud.githubusercontent.com/assets/4961958/18856632/7324d61e-8411-11e6-953d-d3864e9c16f6.png)
 If you choose to use morphology to remove the dots and undo the dither, Leptonica is very strong library for C or C++ programmers. A few morphology operations (erosions and dilations) hopefully would do the trick. 
 Leptonica is responsible for decoding image file formats. The list of supported formats is here. Discard PDF (IFF_LPDF) and PS (IFF_LS ) because they are write-only, and discard SPIX because it is Leptonica specific. This support assumes that Leptonica is built with all imaging dependencies, which are optional. If you are running the Tesseract that ships on linux distributions such as Debian or Ubuntu, there should be no problems. You might have less support on cygwin or similar, depending on how Leptonica was built. 

https://github.com/DanBloomberg/leptonica/blob/master/src/imageio.h#L92
 .--. .-. --- -..- .. -- .- / -.-. . -. - .- ..- .-. .. / -...

I've made a few in-place edits on the bug to
clarify the wording. Hopefully makes more
sense now.

 ... . -. -.. / ... .--. .- -.-. . / -- .- .-. .. -. . ...
 > I've made a few in-place edits on the bug to clarify the wording. Hopefully makes more sense now.

I deleted my previous message just after you made the edits. I thought that you didn't like my little joke...
Clearly, I was wrong!

For the benefit of humankind, here it is again...

> @jbreiden
> 
> Jeff, your last two messages look cryptic...
> 
> If you have been abducted by aliens, try give us a sign and we will rescue you! :)

<

> .--. .-. --- -..- .. -- .- / -.-. . -. - .- ..- .-. .. / -...
> 
> ... . -. -.. / ... .--. .- -.-. . / -- .- .-. .. -. . ...

Jeff, we are coming, stay calm!

LOL
 It's good to know Morse code, or maybe just to find an online Morse code translator... :) 
 Even if you use `-sDEVICE=tiffgray`, you might want to use `-sCompression=lzw`.
 For generating many 1-page images files, instead of one multi-page tiff file, use `-o img-%d.tiff`.
 My first patch (dated March 28)  in bug https://github.com/tesseract-ocr/tesseract/issues/233 will reduce RAM use with TIFF input. It stops Tesseract from buffering the input file before decompression. The patch should also should make the LZW case equal to the non-LZW case with respect to RAM. Note that I haven't tested on this particular example, so I'm saying "should" rather than "does".
 The plan was for Ray to commit that patch. However, he has been too busy with the upcoming Tesseract 4.0 and over six months have passed. I think it is okay if someone wants to commit the patch. Please do not commit the second patch, though; that should wait until after the next Leptonica release.
  Hopefully, a  shiny new code that includes a LSTM based OCR engine will land in this repo very soon. It will be in alpha state initially.

[Modernization Efforts](https://github.com/tesseract-ocr/docs/blob/master/das_tutorial2016/6ModernizationEfforts.pdf)
[Building a Multilingual OCR Engine](https://github.com/tesseract-ocr/docs/blob/master/das_tutorial2016/7Building%20a%20Multi-Lingual%20OCR%20Engine.pdf)
 Please use tesseract user forum for asking questions
 In general, only Ray can share a roadmap for new releases. You can ask him to do so in the dev forum. 
https://groups.google.com/d/forum/tesseract-dev

> and inform users about future features which they can expect. I could not find one for

For the next release the major feature is the LSTM based engine, which users can read about in the DAS 2016 slides.

Regarding sharing the dates for releases, some open source projects do share a schedule, while others just declare "We'll have a new release when it's ready...".

The next release version will probably be `4.0`.
 +1 for tagging the tip of the repo before the completely new code as `3.04.2` or `3.05`.  
  You are right and the patch looks OK to me.
 thanks
  Your issue seems to be related to #235

Please read this:
https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md

> Make sure you are able to replicate the problem with Tesseract command line program. For external programs that use Tesseract (including wrappers and your own program, if you are developer), report the issue to the developers of that software if it's possible. You can also try to find help in the Tesseract forum.

https://groups.google.com/d/forum/tesseract-ocr
 Also, Arabic uses a special OCR engine 'Cube' which isn't maintained anymore. It will be replaced by a better engine in the next release.
  ```
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
```

Add a white/black frame to the image and no error messages will appear.

```
convert  427-1.jpg  -bordercolor White -border 10x10 427-1b.jpg
```

Strange behaviour...
 > The biggest problem for me, however, is that in OCRopus they don't even get OCRed.

This place is for bug reports about **Tesseract**, not  OCRopus.
  Thanks for reporting! We need to fix it.

FYI, OpenCL support is [quite buggy](https://github.com/tesseract-ocr/tesseract/issues?q=is%3Aissue+is%3Aopen+label%3AOpenCL)
 Haven't tried that. If someone wants to try it...
 Does it also fail when OpenCL is disabled?
 @zdenop, did you lately compile Tesseract with OpenCL enabled on Linux / Windows?
 I tried it few minutes ago on linux. Build process looks fine, but OCR segfault... 
 Just wanted to know that it is at least compiles on Linux. Thanks.
 Sure – just need some time. Not today. Good night.  There are clear instruction for training and [how to generate training images](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#generate-training-images-and-box-files). Other approaches are not supported.
  Thank you for you investigation.
Can you please post it to tesseract-dev forum for discussion, so developers of tesseract wrappers can be aware of change?
 I must admit that I had to look into the code what "OS" means in the context of OCR. Maybe it is possible to find a better name with "Orientation and Script" ("OaS"?).

PS. I just noted that the title of this issue also had the information which I was looking for. @jbarlow83 will you create PR? fixed with 3a47adcbe13e34  Tesseract training tool text2image uses these two functions: 
[pango_glyph_item_iter_init_start](https://github.com/tesseract-ocr/tesseract/blob/193032a7786f/training/pango_font_info.cpp#L455)
[pango_glyph_item_iter_next_cluster](https://github.com/tesseract-ocr/tesseract/blob/193032a7786f/training/pango_font_info.cpp#L458)

 That means it requires Pango >=1.22.0:
https://developer.gnome.org/pango/stable/api-index-1-22.html
https://developer.gnome.org/pango/stable/pango-Glyph-Storage.html#pango-glyph-item-iter-init-start
https://developer.gnome.org/pango/stable/pango-Glyph-Storage.html#pango-glyph-item-iter-next-cluster

However, the comments and code in the method [`bool FontUtils::IsAvailableFont()`](https://github.com/tesseract-ocr/tesseract/blob/193032a7786f/training/pango_font_info.cpp#L509) in `/training/pango_font_info.cpp` refer to older Pango versions:

> // The generated list of font families and faces includes "synthesized" font
> // faces that are not truly loadable. **Pango versions >=1.18** have a
> // pango_font_face_is_synthesized method that can be used to prune the list.
> // **Until then**, we are restricted to using a hack...

`if (PANGO_VERSION <= 12005) {`

`12005` means 1.20.5
https://github.com/GNOME/pango/blob/1147da131ad13/pango/pango-utils.h#L136
  Please use tesseract user forum for asking support
 https://github.com/tesseract-ocr/tesseract/issues/410#issuecomment-244120707
  Please use tesseract user forum for asking support.
  A contribution of direct ALTO support would be welcome. Recommend implementing in a separate file api/altorenderer.cpp rather than adding to api/baseapi.cpp.
  Please you tesseract user forum for asking support
  Hi,
These logs are not very useful as does not contain actual build logs.
Could you please try to do:

```
cppan --self-upgrade
cd your_tesseract_dir
cppan
```

and try to rebuild VS solution?

On my system I don't see any errors.
 If you following instructions from here https://github.com/tesseract-ocr/tesseract/wiki/Compiling#master-branch-305-and-later the `tesseract.sln` is in `build` directory inside your tesseract dir.
 Could you try to remove `C:/Users/jarek/.cppan/storage` completely and try again?
 Can you provide full log of `cmake ..` command from `build` dir?
 It seems that first error is in the zlib.

```
-- Preparing build tree for pvt.cppan.demo.zlib-1.2.8 with config amd64-msvc-19.0-32
-- 
-- Configuring done
-- Generating done
-- Build files have been written to: C:/Users/jarek/.cppan/storage/obj/82/1e/e49e/build/amd64-msvc-19.0-32
-- Configuring incomplete, errors occurred!
See also "C:/Users/jarek/.cppan/storage/obj/ec/64/e827/build/amd64-msvc-19.0-32/CMakeFiles/CMakeOutput.log".

```

Could you also attach `C:/Users/jarek/.cppan/storage/obj/ec/64/e827/build/amd64-msvc-19.0-32/CMakeFiles/CMakeOutput.log` and `CMakeError.log` from there?
 Hmmmm. I'm trying to repro the issue locally and cannot.
I removed whole storage couple of times and it works everytime.
 Try `cppan --self-upgrade` once again and run without removing storage. I've slightly updated the client, maybe the issue is gone. At the moment that's all I can advise. Need to think more.
 To use tesseract in your application in theory you could use CPPAN just in case if it will be working for you.
See https://github.com/cppan/tesseract_example
Also https://github.com/cppan/tesseract_example/tree/master/with_cppan - that's a very simple example to build small programs with cppan. It's like scripting but with C++.
 I've added these 3 lines https://github.com/cppan/tesseract_example/blob/master/with_cppan/main.cpp#L2
CPPAN will create a solution for you near the main.cpp :)
Like this http://imgur.com/Qu13mMT
  thanks!
  fixed by #415 
  @egorpugin - Can you have a look at this?
 Hi, sure.
The issue is that I removed USES_CPPAN definition and you downloaded the new version.
The modern variable is 'CPPAN_BUILD'.
I'll fix this and close the PR.
@zhantong  thanks for pointing this out!
 See 193032a
 Try to follow this guide https://github.com/tesseract-ocr/tesseract/wiki/Compiling#windows Did you do all steps with `cppan` decribed there?  Please use tesseract user forum for asking support
  You can't use a traineddata file which was prepared with a version of Tesseract that is newer than the version you use to do OCR. 
 https://sourceforge.net/projects/tesseract-ocr-alt/files/

https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md
  copied from #396

@nguyenq wrote:

Clearly, the tool produces inconsistencies in font names. Why is "Times New Roman," a valid name, especially it's a plain style?

```
298: Times New Roman,
299: Times New Roman, Bold
300: Times New Roman, Bold Italic
301: Times New Roman, Italic
302: Trebuchet MS
303: Trebuchet MS Bold
304: Trebuchet MS Bold Oblique
305: Trebuchet MS Oblique
306: Verdana
307: Verdana Bold
308: Verdana Bold Oblique
309: Verdana Oblique
310: Yu Gothic
311: Yu Gothic Bold
312: Yu Gothic Bold Oblique
313: Yu Gothic Light, Light
314: Yu Gothic Medium, Medium
315: Yu Gothic Medium, Medium Oblique
316: Yu Gothic Oblique
```
 This is also visible on linux, but only for a few fonts (windows origin?):

```
 39: Arial Black,
 40: Arial Black, Bold
221: Latin Modern Mono Light,
222: Latin Modern Mono Light, Bold
223: Latin Modern Mono Light, Bold Oblique
224: Latin Modern Mono Light, Oblique
227: Latin Modern Mono Prop Light,
228: Latin Modern Mono Prop Light, Bold
229: Latin Modern Mono Prop Light, Bold Oblique
230: Latin Modern Mono Prop Light, Oblique
246: Latin Modern Roman,
247: Latin Modern Roman, Bold
248: Latin Modern Roman, Bold Italic
249: Latin Modern Roman, Italic
335: Nimbus Sans L Condensed,
336: Nimbus Sans L Condensed, Bold
337: Nimbus Sans L Condensed, Bold Italic
338: Nimbus Sans L Condensed, Italic
347: Open Sans Condensed, Bold Condensed
364: Roboto Condensed,
365: Roboto Condensed, Bold
366: Roboto Condensed, Bold Italic
367: Roboto Condensed, Italic
368: Roboto Condensed, Semi-Light
369: Roboto Condensed, Semi-Light Italic
442: Times New Roman,
443: Times New Roman, Bold
444: Times New Roman, Bold Italic
445: Times New Roman, Italic
467: Ubuntu Condensed,
468: Ubuntu Condensed, Bold
```

Font description comes from pango library function `pango_font_face_describe`(https://github.com/tesseract-ocr/tesseract/blob/master/training/pango_font_info.cpp#L619).
 "Problem" is with later pango function: [pango-font-description-to-string](https://developer.gnome.org/pango/stable/pango-Fonts.html#pango-font-description-to-string) adds a trailing comma to a family name when the last word in a family list is a valid style attribute.

But the real problem is reverse function (setting font from string): [pango_font_description_from_string ()](https://developer.gnome.org/pango/stable/pango-Fonts.html#pango-font-description-from-string) - it needs the same string as produced by pango-font-description-to-string. 
This can be tested with "Arial Black" vs. "Arial Black," or "Times New Roman Bold" vs "Times New Roman, Bold".

It seams that solution would be to rewrite whole process printing font name (pango_font_description_get_family,  pango_font_description_get_weight, pango_font_description_get_style) but it would also require to rewrite parsing string to font. And I do not think it is worthy of time (only few fonts are effected and user can copy and paste the font string).
 I remember that in an older version of Gedit (in Ubuntu 14.04?) "Times New Roman**,**" (with a comma) was also present in font selection. With Ubuntu 16.04 newer version of Gedit, it is now listed without a comma. 
 https://github.com/tesseract-ocr/tesseract/blob/61032d9b14e1/training/pango_font_info.cpp#L523
 > Update: I came up with a simple workaround: If it failed with a san-comma fontname, I'd try again with the comma added.

Maybe that's what we should do in Tesseract...
  You forget to read instructions ;-)
  thanks
 https://github.com/amitdo/text2tif/blob/master/port/strcasestr.cpp
This is based on a more updated version of the EFL code. You might want to compare it with your version.
 OK :-)
 The lesson we should learn from this is: 
If you take a piece of code from another codebase and copy it into your codebase, you need to follow the other codebase for updates and [bug fixes](https://github.com/tasn/efl/commit/b457dff840ff1e).
  What version of tesseract you try to build? 
 did you run ./autogen.sh as stated in https://github.com/tesseract-ocr/tesseract/blob/master/INSTALL.GIT.md?
 @billydekid
What's the output of `dpkg -l | grep pkg-config` ?
 @billydekid : I am sorry I misunderstood your comment - I thought it is fixed.
 @billydekid: Does it mean that have to install pango-dev to fix problem? If yes, that it is bug that need to be fixed! (in this case please reopen this issue)
 `libcogl-pango-dev` is not needed by Tesseract!

`libcogl-pango-dev` has these dependencies:

```
libpango1.0-dev
libcairo2-dev
pkg-config (recommended)


```
  thanks
  Question:
There are 2 ways these things could work:
1. FORCE the output to match the provided pattern(s) and/or word(s). With this option, you **can't get anything else out**, whatever is in the image.
2. Use the user-patterns and user-words as a hint. Other things could be output, if it thinks it is more likely. The hint can be made stronger, but **there will always be inputs that produce something outside of the patterns supplied.**
Which is it to be?
Can someone familiar with the above discussions please summarize for me, and if the consensus is 1 above, then it could be made to happen, or else it might be possible to increase the strength of the hint.

BTW, this could behave differently for base tesseract vs LSTM.  thanks.
  I believe that currently Tesseract still supports older C and C++ standards. Your patch will change this situation...
 Next version of tesseract (4.0) will need  C++11. 
3.x branch should be maintained that way it will be possible to build with VS2010...
 @stweil : thanks for clarification. I was able to build tesseract with this patch and VS2010.
  It does not crash on openSUSE linux:

[text2image_log.txt](https://github.com/tesseract-ocr/tesseract/files/443295/text2image_log.txt)
 @stweil, right!
See #345, #349
 @stweil OK
  Training on Windows is not officially supported (but we accept patches):
1. Some tools use libraries that are not common on Windows. I do not think it is worth to invest time  in testing windows implementation of these libraries.
2. Training is need only in special cases. In such cases it is much efficient to use VirtualBox (or similar tool) with linux. 
3. We are not aware about anybody who would like to provide Windows support.

@Shreeshrii @stweil  : please create separate issue for command that crash on linux, so we can track it.
 @nguyenq

```
text2image --text=vie-data.txt --outputbase=vie.arial.exp1 --font=Arial --fonts_dir=C:\Windows\Fonts
```

try `--font="Arial"` instead of `--font=Arial`.

```
text2image --text=vie-data.txt --outputbase=vie.arial.exp1 --font="Times New Roman" --fonts_dir=C:\Windows\Fonts
Could not find font named Times New Roman.Please correct --font arg.
```

As @Shreeshrii said, try  `--font="Times New Roman,"`.
 @Shreeshrii: "--fonts_dir=" is wong argument
 @Shreeshrii: These errors are comming from external library (Pango/FontConfig?), which are IMO not common on Windows.  IMO tessting&issue reporting should be reported there.
 @nguyenq

> The boxes in the generated box file were not as tight as they could be.

What do you mean? Is this also happening in Linux?
 @Shreeshrii: I need to correct my statement:

>  "--fonts_dir=" is wong argument
1.  I found out it is interpreted as --fonts_dir=""
2.  I found out that `--fonts_dir=""` reset fonts_dir variable to system default e.g. if --fonts_dir argument is not use text2image is looking for fonts in `/auto/ocr-data/tesstraining/fonts`
  Please use tesseract user forum for asking support (please read&use [relevant wiki](https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality) before).
  We do not provide support for tesseract wrapers. Please use tesseract user forum.
  user

On 13 Aug 2016 19:00, "songgl" notifications@github.com wrote:

> �what is the cause of this error?
> 
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/387#issuecomment-239630954,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AAjCzHOS0TfKBkP8jOIhr9ptK-YhkkcDks5qffgugaJpZM4Ji1Ec
> .
  1. Use tesseract user forum for asking question/support
2. We do not provide support for external project.
 @wanghaisheng, short answer: No.
 My user name is @amitdo, not amido :)
  1. Use tesseract forum for asking support
2. Do not use this issue tracker for project (if you have issue with tess-two - report it to tess-two authors/maintainers)
  Use tesseract user forum for asking support (search it before asking question - there were experiences/suggestion about 7 segment OCR in past)
  IMO this is not tesseract problem but pdf rendering problem. I tried your file in acrobat reader and here is copied text from it:
An exact method is presented for numerically calculating, within the framework of the
stochastic formulation of chemical kinetics, the time evolution of any spatially homogeneous
mixture of molecular species which interreact through a specified set of coupled

Here is screenshot:

![image](https://cloud.githubusercontent.com/assets/574156/17740797/20c8ab48-649a-11e6-8456-448bffb04598.png)
 The vertical problem in pdf.js was fixed by adjusting font metrics for Tesseract. The fix was handed off to Ray and is pending a code merge from Ray. I suspect the horizontal problem is due to a flaw pdf.js when interpretting the Tz directive, but am not sure. I'd be happy to work with a programmer on the pdf.js  side to figure this out for sure, but we have to find one first!
 @jbreiden: Is this fixed or are you still waiting for Ray? Good. Can you create Pull request against 3.05 branch?  thanks. Fixes #380
 The dotted circle fix might solve things for Mac users also (#195). 
  None of these issues has been solved.

At least the first one probably affects Tesseract running in MinGW and Mac.

> Fast Solution: specify fc backend

https://github.com/GNOME/pango/blob/master/pango/pangocairo-fontmap.c#L48

Something like this should be put in `text2image.cpp`:

```
#ifdef _WIN32
 putenv("PANGOCAIRO_BACKEND=fc");
#else
  setenv("PANGOCAIRO_BACKEND", "fc", 1);
#endif // _WIN32
```

Should be tested on Mac and MinGW before committing this code.
This issue does not affect Linux.
 AFAIK vidiecan is using VS. Is there any report from mingw users?
  This is not issue according https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md
  > the command: mftraining -F font_properties -U unicharset -O lang.unicharset lang.fontname.exp0.tr lang.fontname.exp1.tr ...
> needs to be corrected to add suffix .txt to font_properties to make it work

It only needs the `.txt` suffix if you saved the file as `font_properties.txt`...
 > In the command: training/set_unicharset_properties -U input_unicharset -O output_unicharset --script_dir=training/langdata
> The output is generated to output_unicharset.This output_unicharset should be given as input to the mftraining command. i.e instead of -U unicharset one should give -U output_unicharset

From the training guide:

```
mftraining -F font_properties -U unicharset -O lang.unicharset lang.fontname.exp0.tr lang.fontname.exp1.tr ...
```

This gives you the command line usage. You don't supposed to cut and paste it as-is.

The following paragraph explains it.

> The -U file is the unicharset generated by unicharset_extractor above, and lang.unicharset is the output unicharset that will be given to combine_tessdata.
 > the command : unicharset_extractor lang.fontname.exp0.box lang.fontname.exp1.box ... didn't work the first tim.Hence, i have to prefix training/ to make it work.

https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#building-the-training-tools

```
make training
sudo make training-install
```

If you run the second line, you should be able to run all the training commands without the prefix.
 @vkoushik: if it throwed you error it means you made something wrong (installation). Fix your installation instead of  adjusting manual to your mistakes. Your suggestion would not work for those who use packaged prepared by their distributor (windows or linux).
  Please do me a favor and take a look at 2.pdf which is an attachment towards the bottom of
the following bug. Tell me if that demonstrates the same incompatibility.

https://github.com/mozilla/pdf.js/issues/6863
 > 2.pdf doesn't show the problems in both pdf.js and when the text is extracted with pdfbox.

Good, because that is the future for Tesserct PDF output. 2.pdf has minor changes in the metrics of both the embedded font and the metrics in the PDF. I can't guarantee that this is going to work with every document, because PDF text extraction relies heavily in heuristics. (Root cause: PDF spec)
 It's more of a tweak than a rewrite. For logistical reasons, I hand all my changes to Ray who then merges them into the git repo. Ray is awesome in almost every way, but he is notoriously slow at this. I've already done the handoff.
 > Tesseract seems to ignore resolution information from PNG files.

Wait, what? That's not expected at all. Please provide an example PNG file demonstrating
the problem, and it will get attention right away.
 new pdf.ttf came to master and 3.05 branch.  
@ebogaard: Can you re-test? Please test only tesseract and  please provide command (how you run tesseract).  You used wrong command. It should be something like this:
  tesseract pdfsandwich45aaf9.tif pdfsandwich45aaf9 -l nld+eng pdf In tessdata repository there are 4.00 data files and you use 3.05 tesseract...
This is not supported. You need to use data files from the same or lower tesseract version (e.g. 3.04)  There is a limit for the number of **fonts** you can train Tesseract, which is 64 fonts.
 > There is a limit for the number of **fonts** you can train Tesseract, which is 64 fonts.

This was a reply to your question:

> Is there a limit on the number of .tr files i can give as input?

AFAIK, there is no hard limit on the number of `.tr` files.
 Did you test that your training data actually works?
 This output does not look like it is coming from Tesseract command line program...

In any case, as I said there is a 64 fonts limit.
 From Ray Smith DAS2014 Slides:

> Training Fundamentals
> ● Character samples must be segregated by font
> => Trained on synthetic (rendered, distorted) data
> ● Few samples required (4-10 of each combination is good. 1 is OK)
> ● Not many fonts required. (32 used for Latin)
> ● Not many fonts allowed. (MAX_NUM_CONFIGS=64: Long story.)
> ● Number of different “characters” now limited only by memory.

The `MAX_NUM_CONFIGS` is still set to `64` in the current codebase.
  I wonder why Gentoo, which is supposed to be a bleeding edge distro, does not have a package for the newer Tesseract version 3.04**.01**.

Try this:
`tesseract eng.Sans-serif.exp0.tif eng.Sans-serif.exp0 box.train`
 1. you did not provided your input files
2. you did not explain how you created input files
3.  command "tesseract eng.Sans-serif.exp0.tif - box.train" is not according  [training instruction](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#run-tesseract-for-training)
 Version 3.04.01 is now available as a package for Gentoo (it is marked as 'testing'):
https://packages.gentoo.org/packages/app-text/tesseract
  Please read this:
https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md

Try asking your question in the [users mailing-list](https://groups.google.com/d/forum/tesseract-ocr)
  If you think that's exciting, check out the PDF output. Looks like we have at least one bug on our hands. Thanks for reporting this.

[foo.pdf](https://github.com/tesseract-ocr/tesseract/files/369763/foo.pdf)

![bug](https://cloud.githubusercontent.com/assets/4961958/16924868/2d239046-4cd6-11e6-92a6-a808d5beb5ab.png)
 This will take care of the PDF portion (so that we blend with white instead of just stripping the entire alpha channel). The recognition part is probably a discussion with Ray. Reading the source code, it is not clear to me why we don't recognize. Alpha looks like it is treated like any other color channel as opposed to something special.

``` c++
--- tesseract/api/pdfrenderer.cpp   2016-07-06 13:19:57.000000000 -0700
+++ tesseract/api/pdfrenderer.cpp   2016-07-20 16:23:13.000000000 -0700
@@ -690,8 +690,9 @@
   int format, sad;
   findFileFormat(filename, &format);
   if (pixGetSpp(pix) == 4 && format == IFF_PNG) {
-    pixSetSpp(pix, 3);
-    sad = pixGenerateCIData(pix, L_FLATE_ENCODE, 0, 0, &cid);
+    Pix *p1 = pixAlphaBlendUniform(pix, 0xffffff00);
+    sad = pixGenerateCIData(p1, L_FLATE_ENCODE, 0, 0, &cid);
+    pixDestroy(&p1);
   } else {
     sad = l_generateCIDataForPdf(filename, pix, kJpegQuality, &cid);
   }
```
  Language data path is hardcoded in linux build see:
- https://github.com/tesseract-ocr/tesseract/blob/master/ccutil/Makefile.am#L6
- https://github.com/tesseract-ocr/tesseract/blob/master/ccutil/mainblk.cpp#L77
 Best way is to test it ;-).
 There is. Debian uses -DTESSDATA_PREFIX=/usr/share/tesseract-ocr/
 zdenko is the build king, he can decide such things
 All the ways to set  `TESSDATA_PREFIX` should be documented in the wiki.
 TESSDATA_PREFIX is set (via autotool variable @datadir@) to directory where autotools installed tessdata (at the time when tessdata were part of tesseract library repository). Because there was no installation on Windows (Visual studio) TESSDATA_PREFIX is (was?)  set to "./" 
There is [logic](https://github.com/tesseract-ocr/tesseract/blob/master/ccutil/mainblk.cpp#L58) of how to find tessdata location:
1. Use tessdata prefix from the command line.
2. Use tessdata prefix from the environment.
3. (Windows):  Look for tessdata in directory of executable.
4. Use tessdata prefix which was compiled in.

If you need to add something to wiki or configure help, you are welcomed to send PR ;-)
  TIFF gui warnings probably should be turned off during tiff library compilation with definition TIF_PLATFORM_CONSOLE.
 Your commit introduces dependency on tiff library for tesseract.
Now by default tesseract uses only leptonica library.
 I think there is another bug about better memory usage with multipage tiff, where the solution is also a tiff library dependency. Will try to find it.
 Yes, it was bug #223. There is an enhancement request to improve performance on multipage tiff reads. It is currently slow to read the latter images in multipage tiff. The only way to accomplish this is with a direct libtiff dependency. I didn't implement because I wasn't sure if it was worth it.
 I mean bug #233
 Yes, but the code won't be active almost always. Users should care about tiff library, download it, deploy, link to 'tesseractmain' or their own binary.
Also what is HAVE_TIFFIO_H? It is not defined in tesseract build system, so it will be turned off.

Better solution I provided when building tesseract with CPPAN.
See:
https://github.com/tesseract-ocr/tesseract/issues/209 (bottom comments)
https://github.com/tesseract-ocr/tesseract/wiki/Compiling#master-branch-305-and-later
and
https://github.com/DanBloomberg/leptonica/blob/master/cppan.yml#L62 this line will disable gui notifications from tiff library completely.
 Ah, I see now, sorry.
Well, it's ok then.
 Wait a second. Does this mean it is okay for me to use direct calls to libtiff if I 
put it inside HAVE_TIFFIO_H? If so, I can go make the multipage TIFF reader
vastly faster. 
 yes

On 18 Jul 2016 19:23, "jbreiden" notifications@github.com wrote:

> Wait a second. Does this mean it is okay for me to use direct calls to
> libtiff if I
> put it inside HAVE_TIFFIO_H? If so, I can go make the multipage TIFF reader
> vastly faster.
> 
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/pull/367#issuecomment-233397033,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AAjCzNcT2CXvmIoUIyBJdt-DlI4Ur6ueks5qW7aNgaJpZM4JN-Iw
> .
 My vote for removing HAVE_TIFFIO_H (and removing this commit).
It is not used anywhere in tesseract except this commit.
Tesseract uses leptonica API, so maybe it's better to contribute there and use its API later.
 It seems HAVE_TIFFIO_H was a legacy check, that was automatically imported to cmake to save compatibility with autotools build. Now I see that it's not used.
 Well, this is a core decision. If and only if Tesseract allows a direct TIFF 
dependency, then I am going to use it to significantly speed up OCR of 
multipage TIFF as part of bug #233.
 Is it possible via leptonica API? I see some comments from Dan B. there.

Upd.: Ahh, Dan said that you really need direct libtiff dependency. No more questions from me.
 Yeah, Dan and I talked about this extensively and eventually came to agreement. It does not seem possible through Leptonica, even if we modify Leptonica. The issue is there is a libtiff data structure that must be held in memory, and must be iterated through to get successive images in multipage TIFF. Leptonica doesn't have the ability to keep this data structure around, because Leptonica is functional C program. So you can't stash it as a member variable as a Leptonica class or something like that. And we're sure as heck not going to put it in a global because that isn't threadsafe. Which means that, currently, Leptonica has to start over from the beginning every time. When someone asks image 2348 in a multipage TIFF, we have to start at the beginning and do 2348 seeks to get to data. 
 I suppose it is possible we are wrong. I'll look one last time, starting here.  Sorry for hijacking this bug.

http://www.libtiff.org/libtiff.html#Dirs
http://www.asmail.be/msg0054682091.html
 @egorpugin: libtiff is needed for [tesseract opencl](https://github.com/tesseract-ocr/tesseract/blob/master/opencl/openclwrapper.h#L5) implementation. So you need to remove much more than this commit. 
 It's strange a bit. Does OpenCL really need this? I.e. leptonica can not provide required interfaces? Or opencl is only implemented for tiff images?

Also with CPPAN build I mentioned above tiff dependency can be added in the simplest possible way (add one line to cppan.yml).

---

I'm trying to understand what do you need to get custom pages (images, directories) from tiff image. Looks like it's `TIFFSetDirectory(TIFF *tif, int dir_n)` [1,2] call. It reads image file from the beginning, iterates over each directory until requested dir number and reads it (`TIFFReadDirectory(tif)` [3]). Then it can be read by leptonica with `pixReadFromTiffStream(tif)` like here [4]. I do not understand why leptonica has one more cycle here [5]. It gives us O(N^2) complexity instead O(N), isn't it?

So, for example if we want to read custom dirs (images) from tiff via leptonica, the complexity is O(N). But if we want to read tiff sequentially we can add a new function to lept. For example, `pixReadStreamTiffNext()` which will iterate to the next dir (image) in the tiff stream via one `TIFFReadDirectory()` call because it increases `tif->tif_nextdiroff` offset.

Correct me if I'm wrong somewhere.

[1] http://www.libtiff.org/man/TIFFSetDirectory.3t.html
[2] https://github.com/vadz/libtiff/blob/master/libtiff/tif_dir.c#L1531
[3] http://www.libtiff.org/man/TIFFReadDirectory.3t.html
[4] https://github.com/DanBloomberg/leptonica/blob/master/src/tiffio.c#L375
[5] https://github.com/DanBloomberg/leptonica/blob/master/src/tiffio.c#L409
 The OpenCl code (amongst other things) provides hardware accelerated alternatives to a very small subset of Leptonica calls.

You are right,  Leptonica's pixReadStreamTiff() is adding lots of unnecessary overhead. The only reason we didn't notice it was all this stuff gets cached in memory, hence the massive amount of seeking is a little bit hidden. I already have a patch out to Dan to call TIFFSetDirectory() only once per image.  However, even a single call to TIFFSetDirectory() is expensive. 

Your suggestion about calling TIFFReadDirectory(TIFF *tif) to get down to linear will not work unless someone is able to hold onto the TIFF *tif struct. Tesseract can do this, but only if it is allowed to directly link to libtiff. Leptonica cannot do this, because it has nowhere persistent to hold it. Everything is completely reset for every image read,  including the call to TIFFOpen. All that said, I now see that we can potentially work around this by having Tesseract keep track of file offsets. Need to think this over.

``` c
#include <stdio.h>
#include <tiffio.h>

const char *testfile = "test.tiff";

size_t PrimeThePump() {
  TIFF *tiff = TIFFOpen(testfile, "r");
  TIFFSetDirectory(tiff, 0);
  size_t offset = TIFFCurrentDirOffset(tiff);
  TIFFClose(tiff);
  return offset;
}

size_t ThankYouSirMayIHaveAnother(size_t offset) {
  TIFF *tiff = TIFFOpen(testfile, "r");
  TIFFSetSubDirectory(tiff, offset);
  TIFFReadDirectory(tiff);
  offset = TIFFCurrentDirOffset(tiff);
  TIFFClose(tiff);
  return offset;
}

int main(void) {
  size_t offset = PrimeThePump();
  while (offset = ThankYouSirMayIHaveAnother(offset)) {
    printf("offset=%lu\n", offset);
  }
}
```
 So I see the following possible solution. We need to query all offsets in tiff file atleast once. We could do this in leptonica. Also we can add a function that will read tiff image by dir offset.

Code flow:

``` c
// tesseract side
FILE *fp = fopen(filename, "rb");
int n_dirs = 0;

// call to leptonica
// fp is opened, leptonica will call fast? TIFFClientOpen()
uint64_t *offsets = pixReadTiffOffsets(fp, &n_dirs);

// read interesting image O(1)
// fp is opened, leptonica will call fast? tif = TIFFClientOpen()
// TIFFSetSubDirectory(tif, offset)
// TIFFReadDirectory(tif)
// pixReadFromTiffStream()
PIX *image = pixReadTiffDir(fp, offsets[interesting_image_number]);

// free() offsets as C does not have C++ delete[]
free(offsets);
```

What do you think?
 I dunno; we almost always read all the images in a loop, so putting functions in Leptonica somewhat similar to my example would also do the trick.  This is ultimately Dan's decision. But also consider that it's kind of a logistics pain to put something new in Leptonica and then make Tesseract depend on it. So for Tesseract, we may be better off doing the direct libtiff calls.

[EDIT: Took a look at this. Impossible to keep everything on Tesseract's side due to pixReadFromTiffStream() is not exposed] 
 Added 1..74.2, tess will automatically use it now.  Please use tesseract user forum for asking support.
 `Warning: No shape table file present: shapetable`

This warning message is indeed confusing, but everyone gets it, so unless you are training Tesseract for an Indic script, you should ignore it.

For the second part of this issue, follow @zdenop advice.
 Did you used the `-F` flag?

`mftraining -F font_properties...`

`font_properties` should be the file name (including any extension like `.txt`) you saved the  font_properties file.
  Please provide detail (OS detail, tesseract version, how you compile, logs...)
 use the current version. Before compiling from source remove all other version of tesseract.
 1. Ubuntu has recent tesseract packages
2. 3.03 version is old - not officially produced version. Nobody will look at it.
  All the errors except the last one are coming from [leptonica](https://github.com/DanBloomberg/leptonica).

Check with a png image, just to make sure the source of the problem is not reading the tiff image.
 File input/output is handles by leptonica.
Anyway your experience is strange. I build tesseract (and leptonica) as non privileged user and install it with `sudo` and I never have this problem.
Can you please remove/uninstall leptonica and tesseract and than clone last version of leptonica and tesseract and build everything under userx , install with sude and try again your test?
If you have still problem can you provide your in.tiff file?
 Try converting the image with other programs like gimp or pngtopnm (netpbm).
 Try [pamditherbw](http://netpbm.sourceforge.net/doc/pamditherbw.html) on the pgm file.
 This bug report is confusing. Please generate shareable test images that give trouble, and post to this bug. Also, please report your platform details. Is this Linux or something else? If there is an obvious Leptonica problem, I'll help fix it.
 Thanks. By the way, the "root-only" thing suggests that there may be some sort of tmpfile involved that is running into a permission problem. I'll be excited if I can reproduce.
 Leptonica is trying to write its temporary files in /tmp/lept and can't because root owns it. This is going to require a Leptonica change. There are 11 calls to genTempFilename() in Leptonica.

https://github.com/DanBloomberg/leptonica/blob/master/src/pdfio2.c#L1240
https://github.com/DanBloomberg/leptonica/blob/master/src/pdfio2.c#L1200

```
sudo sudo -u nobody strace tesseract test-source2.pbm /tmp/q pdf
mkdir("/tmp", 0777)                     = -1 EEXIST (File exists)
mkdir("/tmp/lept", 0777)                = -1 EEXIST (File exists)
open("/tmp/lept/868647_30487_temp.tif", O_RDWR|O_CREAT|O_TRUNC, 0666) = -1 EACCES (Permission denied)
write(2, "Error in fopenWriteStream: strea"..., 45Error in fopenWriteStream: stream not opened
```
 This is a temporary, Linux specific Leptonica patch as a placeholder until upstream
does something official.

``` c
--- leptonica/src/utils.c   2016-06-13 16:53:20.000000000 -0700
+++ leptonica/src/utils.c   2016-07-19 12:19:39.000000000 -0700
@@ -3152,6 +3152,10 @@
  *          (b) multiple threads from a single process call this function, or
  *          (c) there is the possibility of an attack where the intruder
  *              is logged onto the server and might try to guess filenames.
+ *
+ * IMPORTANT: This function has been modified as a temporary Debian
+ * specific workaround for Debian Bug #830660, while upstream works on
+ * an official solution. All input parameters are disabled.
  * </pre>
  */
 char *
@@ -3160,42 +3164,23 @@
                 l_int32      usetime,
                 l_int32      usepid)
 {
-char     buf[256];
-char    *newpath;
-l_int32  i, buflen, usec, pid, emptytail;
-
+char    *pathout;
+l_int32  size;
     PROCNAME("genTempFilename");
-
-    if (!dir)
-        return (char *)ERROR_PTR("dir not defined", procName, NULL);
-    if (dir && strlen(dir) == 1 && dir[0] == '/')
-        return (char *)ERROR_PTR("dir == '/' not permitted", procName, NULL);
-    if (tail && strlen(tail) > 0 && stringFindSubstr(tail, "/", NULL))
-        return (char *)ERROR_PTR("tail can't contain '/'", procName, NULL);
-    emptytail = tail && (strlen(tail) == 0);
-    if (!usetime && !usepid && (!tail || emptytail))
-        return (char *)ERROR_PTR("name can't be a directory", procName, NULL);
-
-    if (usepid) pid = getpid();
-    buflen = sizeof(buf);
-    for (i = 0; i < buflen; i++)
-        buf[i] = 0;
-    l_getCurrentTime(NULL, &usec);
-
-    newpath = genPathname(dir, NULL);
-    if (usetime && usepid)
-        snprintf(buf, buflen, "%s/%d_%d_", newpath, usec, pid);
-    else if (usetime)
-        snprintf(buf, buflen, "%s/%d_", newpath, usec);
-    else if (usepid)
-        snprintf(buf, buflen, "%s/%d_", newpath, pid);
-    else
-        snprintf(buf, buflen, "%s/", newpath);
-    LEPT_FREE(newpath);
-
-    return stringJoin(buf, tail);
+#ifdef _WIN32
+  #error "mkstemp is probably not supported on Windows"
+#endif  /*  _WIN32 */
+    char pattern[] = "/tmp/lept.XXXXXX";
+    int fd = mkstemp(pattern);
+    if (fd == -1) {
+      return (char *)ERROR_PTR("failed to get tempfile", procName, NULL);
+    }
+    close(fd);
+    if ((pathout = (char *)LEPT_CALLOC(sizeof(pattern), sizeof(char))) == NULL)
+      return (char *)ERROR_PTR("pathout not made", procName, NULL);
+    strncpy(pathout, pattern, sizeof(pattern) - 1);
+    return pathout;
 }
-

 /*!
  * \brief   extractNumberFromFilename()
```
 > This is a temporary, Linux specific Leptonica patch as a placeholder until upstream
> does something official.

```
This function has been modified as a temporary Debian
+ * specific workaround for Debian Bug #830660, while upstream works on
+ * an official solution.

```

@DanBloomberg
Do you remember this issue?
 OK. Thank you Dan!
  please follow [rules](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md).
  please follow [rules](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md).
  Right-to-left languages are incredibly important. Arabic,  for example, has hundreds of
millions of speakers and is the fifth most widely used language when including all variants.
I recommend looking at the DAS tutorial slides, they are interesting reading. The last 
set 'Building a Multi-Lingual OCR Engine' talks about in-progress numbers with Farsi 
and other languages that currently perform poorly with Tesseract 3. Machine learning 
has advanced quite a bit recently, and that's where the energy is.

http://www.vistawide.com/languages/top_30_languages.htm
https://github.com/tesseract-ocr/docs/tree/master/das_tutorial2016
 Take a look at DAS 2016 slides
  I worked extensively with Ken Sharp on ghostscript compatibility and thought we were in pretty good shape. Not sure what the story is here.
 Well, I've reproduced your problem with a different PDF and the tilt doesn't seem to be a factor. The text is definitely getting represented differently after a pass through ghostscript. I think you should contact Ken and see what he thinks. There's nothing obviously wrong to my eye about the ghostscript respresentation, but text extraction in PDF is often more of an art than a science. (As always, I think the root problem is the PDF specification itself.)

Before:

```
BT
3 Tr 1 0 0 1 82.2 512.8 Tm /f-0-0 10 Tf 140.64 Tz [ <0045><0058><0050><0045><0052><0049><0045><004E><0043><0045> ] TJ 77.16 0 Td 156.802 Tz [ <0041><004E><0044> ] TJ 30.6 0 Td 129.334 Tz [ <0052><0045><004C><0041><0054><0049><0056><0049><0054> ] TJ 58.8 0 Td 141.6 Tz [ <0059> ] TJ 30.36 0 Td 94.8 Tz [ <0035><0039> ] TJ 
ET
```

After

```
BT
/R10 10 Tf
1.4064 0 0 1 82.2 512.8 Tm
3 Tr
[(�E)-500(�X)-500(�P)-500(�E)-500(�R)-500(�I)-500(�E)-500(�N)-500(�C)-500(�E)-500]TJ
1.56802 0 0 1 159.36 512.8 Tm
[(�A)-500(�N)-500(�D)-500]TJ
1.29334 0 0 1 189.96 512.8 Tm
[(�R)-500(�E)-500(�L)-500(�A)-500(�T)-500(�I)-500(�V)-500(�I)-500(�T)-500]TJ
1.416 0 0 1 248.76 512.8 Tm
[(�Y)-500]TJ
0.948 0 0 1 279.12 512.8 Tm
[(�5)-500(�9)-500]TJ
```
 @jbarlow83 Can you please do a compatibility check on 2.pdf as described in this thread?
I want to get as many reports as possible before making a change.

https://groups.google.com/forum/#!topic/tesseract-dev/2EmMMoR3QGs
  Sorry, I'm still busy with other issues. This PR comes later.   > I just tried to build with Cygwin (64 bit, tesseract + training) and had not problems with the unpatched code.

hmmm....

@matzeri?
 @matzeri
The patch for `training/pango_font_info.cpp` in this PR is different from yours. Please have a look at it and test it. 
 @stweil

> T_WIN is set to false by default, so this line could simply be removed (if false is the correct value).

Fixed. Thanks.
 @stweil
Please confirm that this PR compiles with Cygwin 64, including training tools.
 @Shreeshrii reported that this patch https://github.com/amitdo/text2tif/commit/0473f14f, which is same as the above patch works on Cygwin...

I'll change it anyway.
 ~~Something went wrong with the update. I'll try again soon.~~
Strange. It looks fine now.
  Currently Tesseract needs some patches so it can be built for Cygwin.
See here: https://github.com/matzeri/cygwin-pkg/tree/master/tesseract

I want to fix Tesseract's Cygwin compatibility, so no patches will be needed anymore.

Pinging @matzeri...
Hi Marco!

I have a question for you - why is the ['tesseract-undefined.patch'](https://github.com/matzeri/cygwin-pkg/blob/master/tesseract/tesseract-undefined.patch) needed?
 Some links related to the ['tesseract-training.patch'](https://github.com/matzeri/cygwin-pkg/blob/master/tesseract/tesseract-training.patch):

PR https://github.com/tesseract-ocr/tesseract/pull/60

My own patch to 'pango_font_info.cpp'
https://github.com/amitdo/text2tif/commit/0473f14f
 See PR #351.
  Hi Tom!

You need to install more packages:
https://github.com/tesseract-ocr/tesseract/wiki/Compiling#dependencies

After that, re-install leptonica and then tesseract.

If you have further questions about this issue, please use the [users mailing-list](https://groups.google.com/d/forum/tesseract-ocr).

[Here is our guide](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md) for reporting issues and asking questions.
  Please use the [users mailing-list](https://groups.google.com/d/forum/tesseract-ocr).

[Here is our guide](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md) for reporting issues and asking questions.
  Try padding the image and use the '-psm' command line flag.
If you have further questions about this issue please use the [users mailing-list](https://groups.google.com/d/forum/tesseract-ocr).
  > Trying to familiarize with the source code I came across some discrepancies between the file names in the file header comments and the actual file names. Maybe it's pedantic but I thought having the correct names might facilitate reading the code especially when using printouts.

+1 for the suggestion to fix it!

but because your patches touch too many files and for other reasons I prefer that a core developer from Google to take it.
 this PR can not be merged to current code. Can you please update it? The request is reasonable, but I would rather spend my limited time fixing actual bugs than up-integrating/merging such large changes (and asking colleagues to review them) that perform little real useful purpose, especially when there is a chance that a large chunk of the code could go away in the near future.  Please send your question to the [users mailing-list](https://groups.google.com/d/forum/tesseract-ocr).

See [CONTRIBUTING](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md).
  Please send your question to the [users mailing-list](https://groups.google.com/d/forum/tesseract-ocr).

https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md
  Android has (had?) similar behaviour.
https://code.google.com/p/android/issues/detail?id=16672
  I'm sorry, but we have a clear policy - we don't want to see questions here, only bug reports. I believe your problem is not a bug in Tesseract.

https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md

> Sometimes you will not get a respond to your issue or question. We apologize in advance! Please don't take it personally. There can be many reasons for this, including: time limits, no one knows the answer (at least not the ones that are available at that time) or just that your question has been asked (and has been answered) many times before...
  @egorpugin

> Try these binaries compiled by me.
> https://www.dropbox.com/s/8t54mz39i58qslh/tesseract-3.05.00dev-win32-vc19.zip?dl=1
> You have to install VC2015 x86 redist from microsoft.com in order to run them.
> Leptonica is built with all libs except for libjp2k.

@nickbe

> This build does not create PDFs, but the cygwin from http://3.onj.me/tesseract/ build does.
> So currently the VS build is not usable.

@jbreiden

> What is this business about certain builds not supporting PDF output? There is nothing special or weird with that section of code. Are they just old builds from before the feature was created, or is there something else going on?

@egorpugin

> Is there a simple command to check pdf generation?
> I'll try to debug the issue (if any).
 @egorpugin

```
tesseract /path/to/phototest.tif phototest pdf
```

https://github.com/tesseract-ocr/tesseract/raw/master/testing/phototest.tif
 These traineddata files are required: eng, osd
 Ok, and how should I understand what is incorrect? Where is tesseract output, error message, anything?
Entered this command, did some preparations and pdf is generated.
Works for me.
Latest binaries are here: https://www.dropbox.com/s/pxu2hp6mg1a64zj/tesseract-3.05.00dev-win32-vc19-2016-jun-03.zip?dl=1
 @egorpugin
How did you build these two (old and new) binaries?
 Built liblept with every image library except jpeg2k, built tesseract with that lept. VS2015 Update 2.
I said that in previous thread (issue).
If tesseract.exe creates pdfs and other binaries not, give me simple repro for one of them, so I'll check.
 Since the problem does not exist in your **newer** build, maybe we should close this issue.
 It works also on the old build. I checked.
 Do you have any guess why it does not work for @nickbe (the old build)?
 Nobody wants to provide simple repro of this issue. I cannot guess what's the problem.
 I don't have Windows so I can't reproduce it myself... 
 Since both @nickbe and @egorpugin confirm that the PDF renderer feature works in the newer VC build, I'm closing this issue for now.
  You mentioned in another issue that you are using Cygwin, so I guess this issue also happens with Cygwin, right?

Does this issue happen when you give it a page with many lines?

Could you upload the original image **and** the PDF file?
 Which PDF viewer are you using? Adobe Acrobat Reader?

I checked the first PDF file with Chrome browser and Evince on Ubuntu 16.04. With these viewers the issue you describe does not exist.
 The PDF renderer feature is tested with these viewers:
- Adobe Acrobat Reader
- PDFium (Chrome/Chromium)
- OS X Preview
- pdf.js (Firefox)
- Evince (poppler)
 Just for a reference:
https://github.com/sumatrapdfreader/sumatrapdf/issues/544
 If the SumatraPDF engineer wants someone to talk to, send them my way.
  https://github.com/blog/1184-contributing-guidelines

This should replace https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice

Any comments?
 I would keep it in FAQ too, or provide link with short description...
 Yeah, this was my intention :-)
 I'm more in favor for the link option.
 @zdenop
Yesterday there was an option to "squash and merge" in the PR web interface. I don't see it right now. Did you change the settings?
https://github.com/blog/2141-squash-your-commits
 No I did not make any changes.
 Okay :)
 I wanted to choose this option, but accidentally push the button itself instead of the arrow :(
Not a big deal...
 IMHO, this is bad UX design.
 Right. But it's too tempting  to use the GUI - just a few clicks...
 https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice
  Hi Stefan!

You missed `AC_PREREQ`.
https://www.gnu.org/software/autoconf/manual/autoconf-2.69/html_node/Versioning.html
 Thanks!
  Please use [Tesseract users forum](https://groups.google.com/d/forum/tesseract-ocr) and ask this question (and other questions you might have) there.
  Please use tesseract user forum for asking support (see: [FAQ#rules-and-advices](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice))
  Thanks for the patch!
    @stweil
A few lines below my new code:

```
unsigned int i = 1;
  for (i = 1; i < *argc; ++i) {
    const char* current_arg = (*argv)[i];
    ...
    // If this is asking for usage, print the help message and abort.
    if (!strcmp(current_arg, "help") ||
        !strcmp(current_arg, "helpshort")) {
      tprintf("USAGE: %s\n", usage);
      PrintCommandLineFlags();
      exit(0);
    }
```
 Anyway, you'll have to submit a new PR, since Zdenko already merged this one. 
 Also check what we are doing here:
https://github.com/tesseract-ocr/tesseract/blob/master/api/tesseractmain.cpp
 You also might want to read about `EXIT_FAILURE` and `EXIT_SUCCESS`
https://www.google.co.il/search?q=EXIT_FAILURE
`EXIT_SUCCESS` is used in `text2image.cpp`.
 Another issue.

What do you think about the code in https://github.com/tesseract-ocr/tesseract/pull/330#issuecomment-220828244

It searches for 'help' string in all `argv` strings. I think it should only check `argv[1]`. This is what is being done in `tesseractmain.cpp`.
 Okay...
  Hi!
Good question. The right place to ask this question is in the [tesseract-dev](https://groups.google.com/d/forum/tesseract-dev) mailing list. I hope you'll get an answer from Ray Smith.
  Please read and follow [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice) before creating issue.
  please follow [FAQ#rules-and-advices](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice)
 @reubano
I added  'tesserocr' to the AddOns wiki.
https://github.com/tesseract-ocr/tesseract/wiki/AddOns#tesseract-wrappers
 I added this example to [APIExample](https://github.com/tesseract-ocr/tesseract/wiki/APIExample)
 > It would be helpful to have a CONTRIBUTING file with that information so that github will show it on the issues page.

@reubano, thanks for the suggestion.
Now [we have it](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md)! :-)
  Run: `tesseract --list-langs`
Do you get `ara` in the output?
 And the message is clear: there is no /opt/local/share/tessdata/eng.traineddata 
English traineddata is must for correct running of tesseract (because it is used for fallback).
 Do you have installed arabic cube files (e.g. [ara.cube.lm](https://github.com/tesseract-ocr/tessdata/blob/master/ara.cube.lm))?
 But your original issue (wrong installation) was solved.
For asking support use tesseract user forum - there are more people...
  Please read this:
https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#generate-the-unicharset-file
 ... and this:
https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#questions-about-the-training-process
 Your unicharset file looks wrong.

Either you didn't run `set_unicharset_properties` or you did run it, but in a wrong way.

A debugger won't help you here. A human 'debugger' might help... :) 

https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#set_unicharset_properties
  See issue #318
 ```
Warning: No shape table file present: shapetable
...
Warning: no protos/configs for Joined in CreateIntTemplates()
Warning: no protos/configs for |Broken|0|1 in CreateIntTemplates()
```

These specific warnings are confusing, but everyone gets them, so they should be ignored.
 So, you can now change the text to 'can do it!'... :)
 Good luck with the internship!
  Use [tesseract user forum](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice) for asking support.
  `script_dir` in `set_unicharset_properties` should point to a directory that contains a `*.unicharset` file. For English and other Latin based scripts, the file is `Latin.unicharset`.
You can find the `*.unicharset` files here: https://github.com/tesseract-ocr/langdata
 @ggdhines

Try this: 

```
/home/ggdhines/github/tesseract/training/set_unicharset_properties -U unicharset -O new_unicharset --script_dir=/home/ggdhines/github/langdata
```

Since your unicharset file has glyphs which belong to the `Common` script I think you should also put the `Common.unicharset` in the script dir.
https://raw.githubusercontent.com/tesseract-ocr/langdata/master/Common.unicharset
 @ne0zer0

`unicharset_extractor` produces a `unicharset` file.

You need to pass this file to `set_unicharset_properties`.

> -U **unicharset**

Download these files:
https://raw.githubusercontent.com/tesseract-ocr/langdata/master/Latin.unicharset
https://raw.githubusercontent.com/tesseract-ocr/langdata/master/Common.unicharset

Lets say you put these files in `langdata` directory located under `/home/ne0zer0`.

Now, run this:

> set_unicharset_properties --F font_properties -U unicharset -O output_unicharset --script_dir=**/home/ne0zer0/langdata**
 https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#shapeclustering-new-in-302

> shapeclustering **should not be used except for the Indic languages.**
 > FAIL!
>    APPLY_BOXES: boxfile line 937/1 ((1267,2218),(1310,2289)): FAILURE! Couldn't find a matching blob

And: 

> Boxes read from boxfile:    1727
> Boxes failed resegmentation:       5
> Found 1722 good blobs.

As long as you get only a few of these failures, it's probably OK.

> Warning: no protos/configs for Joined in CreateIntTemplates()
> Warning: no protos/configs for |Broken|0|1 in CreateIntTemplates()

This is also normal.

Overall, the output of the commands looks OK.
 https://github.com/tesseract-ocr/tesseract/blob/a3ba11b030345d32829b1e8355afea5419978d82/doc/unicharset.5.asc

> CAVEATS
> 
> Although the unicharset reader maintains the ability to read unicharsets of older formats and will assign default values to missing fields, the accuracy will be degraded.

ne0zer0:

> What you suggest is likely to produce such degraded result. (what I seem to experiment)

It's the opposite of what you said. You interpreting the above paragraph wrongly.

I'll give you more answers later. 
 The meaning of this 'CAVEAT':

Starting from Tesseract version 3.02 the unicharset file should look like this:

```
110
NULL 0 NULL 0
N 5 59,68,216,255,87,236,0,27,104,227 Latin 11 0 1 N
Y 5 59,68,216,255,91,205,0,47,91,223 Latin 33 0 2 Y
1 8 59,69,203,255,45,128,0,66,74,173 Common 3 2 3 1
9 8 18,66,203,255,89,156,0,39,104,173 Common 4 2 4 9
a 3 58,65,186,198,85,164,0,26,97,185 Latin 56 0 5 a
...
```

If you will use the old format:

```
; 10 Common 46
b 3 Latin 59
W 5 Latin 40
7 8 Common 66
= 0 Common 93
```

the accuracy will be degraded, because the training tool will assign default (suboptimal) values to missing fields.
 `0,255,0,255,0,0,0,0,0,0` is the default (suboptimal) values for glyph_metrics.
 @ne0zer0
Again, you are completely wrong.

You should both be patient and wait for my further answers which may clear things up for you.
 When you run `unicharset_extractor` you get a `unicharset` file in which each line has these fields:
`character` `properties` `glyph_metrics` `script` `other_case` `direction` `mirror` `normed_form`.

In this stage all the fields accept the `character` field are set to their default values. We want to set these fields to their correct values!

So we run `set_unicharset_properties` (we will call it 'the tool'):

```
set_unicharset_properties -U unicharset -O new_unicharset -X xheights --script_dir=/home/myusername/tesseract-ocr/langdata
```

The tool will take our `unicharset` file and add new values in the various fields. We will get a new fixed `new_unicharset` file.

More details:
First, the tool will call a few functions to fill the correct values to these fields:
`properties` `script` `other_case` `direction` `mirror` `normed_form`.

What left to fill are the 10 `glyph_metrics` fields' values.

Tesseract does not provide a training tool that generate the correct values for the `glyph_metrics` fields for the specific trained fonts.

Instead, there is a pre-made unicharset file for each script (the unicharset files in the `langdata` repo) which contains "universal" `glyph_metrics` that have been set from a large number of fonts.

The tool will look for a few files in the directory you told it to search, `/home/myusername/tesseract-ocr/langdata` in this example.

The tool will scan the lines in the `unicharset` file, and for each `character` field in a line it will search the appropriate `Scriptname.unicharset`. For example, for the character 'C' it will read the `Latin.unicharset` and for the character '8' it will read the `Common.unicharset`. The tool will search a matching line in the `Scriptname.unicharset` that has the same character field as the 'current' line in the `unicharset` line. When it find such a match it will take the `glyph_metrics` values located in the same line as the character and implant them in the matching line as new `glyph_metrics` values in the the `unicharset` file line.

A second file that the tool will search is a `Scriptname.xheights` file.
Here is a link to the `Latin.xheights` file.
https://raw.githubusercontent.com/tesseract-ocr/langdata/master/Latin.unicharset

According to Ray Smith, the lead developer of Tesseract:

> If the font you are using is not listed in this file, it will use the mean of the ones that are. IIRC these numbers are used to set up expectations for inter-character spacing. They are for a fixed, quite large size (32 pt??).

('using' = 'training')

The tool will process the info in `Latin.xheights` together  with the new values of the `glyph_metrics` and will output the result to a file, `xheights` in our example.
 That's it. I did my best efforts to explain things you ask about. You can now respond... :)
 > It will be certainly less accurate to use default values; so we cannot get the best result for specific fonts? Unless to waste a lot of time in training Tesseract? For an "uncertain" result?

https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality

> There are a variety of reasons you might not get good quality output from Tesseract. It's important to note that unless you're using a very unusual font or a new language retraining Tesseract is unlikely to help.

*

> Why set_unicharset_properties does not compute such values? It would not be too difficult to develop such a functionality.

If you develop such a tool (or hire someone to do so) we can add a link in the wiki to your site...

My answer for your other questions: 
This is the current situation and you should accept it...

Your last question - you probably did something wrong if you get an empty file. I will try to test it later.  

Two last notes:
I and the other people responding most of the time here and in the mailing-list are volunteers.
Within free (not paid) open source projects, complaining would not help, kind request might help but it's not guaranteed.
 > the file Latin.xheights seems to do nothing... and I always get the same output_unicharset file, with or without Latin.xheights.

The `Latin.xheights` is not supposed to change anything in the `output_unicharset`.
 You seem to think that `/` is the current directory, but it's not.
`/` is your 'root' directory. `./` (or just `.`) is the current directory.
 > What can be done with a filled xheights file?

https://github.com/tesseract-ocr/tesseract/blob/master/doc/mftraining.1.asc
 Nick White @nickjwhite had tried to build the tool you want.
See this old thread:
https://groups.google.com/forum/?hl=en#!searchin/tesseract-ocr/pango|sort:date/tesseract-ocr/QH09G5p1jGI/QcHIJvfzFaYJ
 Hi Nick!
Did you test the impact of using the output of these tools compared to the "universal" unicharset?
 Pinging @nickjwhite ...
  There is no environment variable named "CXPFLAGS".
There are "CFLAGS", "CPPFLAGS",  "CXXFLAGS".
 Didn't try this...
 IMO this is not tesseract issue. If you decided to install libs in non standard location you should know how to deal with it. One of examples suggestion is on [wiki](https://github.com/tesseract-ocr/tesseract/wiki/Compiling#install-elsewhere--without-root). If it does not work - [tesseract user forum](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice).
  Use the official guide at https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract

You missed this step: https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#set_unicharset_properties-new-in-303

See also my answer here: https://github.com/tesseract-ocr/tesseract/issues/318
  You should [read the wiki, search issues (also closed), search in the tesseract forum before you post your issues/question](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice).
Opencl is still experimental feature with a lot of open issues (and original committer is not fixing them...) 
 Hi Zdenko!
I added a note about the state of OpenCL in Tesseract to this wiki page:
https://github.com/tesseract-ocr/tesseract/wiki/TesseractOpenCL
  `unicharset_extractor example.basic.exp0.tiff`

You are giving `unicharset_extractor`a tiff image as input file, but it expects a box (text) file.
https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract

If you have further questions, please see:
https://github.com/tesseract-ocr/tesseract#support
  Here is the Tesseract formula:
https://github.com/Homebrew/homebrew-core/blob/master/Formula/tesseract.rb
  See also #135
  Which version of Tesseract are you using?
The `hocr_font_info` parameter is only available in version 3.04.00 and up.
 If you have further questions, please see:
https://github.com/tesseract-ocr/tesseract#support
  Please see:
https://github.com/tesseract-ocr/tesseract#support
 https://github.com/tesseract-ocr/tesseract/blob/d8c04e8/training/language-specific.sh#L308

```
JPN_FONTS=( \
    "TakaoExGothic" \
    "TakaoExMincho" \
    "TakaoGothic" \
    "TakaoMincho" \
    "TakaoPGothic" \
    "TakaoPMincho" \
    "VL Gothic" \
    "VL PGothic" \
    "Noto Sans Japanese Bold" \
    "Noto Sans Japanese Light" \
    )
```

These are the fonts used in the current `jpn.traineddata.`

If you want to train Tesseract, use one of these guides:
https://github.com/tesseract-ocr/tesseract/wiki/tesstrain.sh
https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract

For further questions, please use the [Tesseract users forum](https://groups.google.com/d/forum/tesseract-ocr).
  For asking support use tesseract user forum (see [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice))
  Please see:
https://github.com/tesseract-ocr/tesseract#support
 What I meant was that I think this kind of problem / question should be sent to the mailing list.
 > But isn't it clearly a bug? ocropus-rpred has no problem with bad.jpg.

There no OCR engine that is 100% accurate. The fact that OCR engine 'A' is more accurate (for a specific input and/or as a whole) than OCR engine 'B' does not make by itself the 'B' a buggy software.

To be fair, I think in this specific case it could be a bug...
 Very true.
  There is no documented way to train 'Cube', so you can't do it.
 Cube training is not supported and cube should be removed in future
  Please use tesseract user forum for asking support
  Try this:
`tesseract arabic_4.jpg stdout -psm 0 -l osd`

You will need the `osd.traineddata`.

FYI, Tesseract 3.04.01 will also output the **name** of the detected script instead of useless script number. 
  I'm sorry, but we don't support 3rd-party wrappers around (lib)tesseract here.
 please report issue at pytesseract project 
  > Basically what I want to achieve is to ask Tesseract to recognize only complete words included in my custom dictionary (lang: chi_sim)

Tesseract can't do this. The dictionaries are just a hint for Tesseract. 
 AFAIK it is not possible within tesseract.
In some extent you can implement it by yourself. E.g. in first stage you do OCR by tesseract and then you can correct recognized text by other tool (e.g. spellchecker with custom dictionary).
  Can you please provide image for testing?
 I understand. But can you modified or create similar image that can demonstrate issue?
 @vidiecan, please, can you respond to @zdenop and @stweil?
  I suggest you repost this here:
https://github.com/tesseract-ocr/langdata
and then close this issue.

but don't repeat calling/mentioning those 2 people.
  https://github.com/tesseract-ocr/tesseract/blob/0afd5939b1e14239d6bfb875e4160b76d3672e02/api/tesseractmain.cpp#L56

It will be useful to have the version info for all binaries including training tools, text2image, lstmeval etc. Also relevant to discussion - Switch to semantic versioning

https://github.com/tesseract-ocr/tesseract/pull/593 > What exactly should be shown? Version number only for tagged release? Branch version? Git release? Compilation date?

IMO, since a large number of people build tesseract from github source it will be useful to have some kind of identifying info in the version being displayed. It would be helpful in troubleshooting.

See related discussion on `Add version and github info always, also when --enable-debug was missing`  https://github.com/tesseract-ocr/tesseract/issues/723 

 > Executable and shared library libtesseract might have different versions.

Can version info also be included for shared libraries? @stweil 

>Support command line options -v, --version for all executables.

Is it possible to add this before release of 3.05.01? In adding the version string to the traineddata, I moved the version data
to a new file ccutil/version.h, so any of the tools could access that to
output their version.

On Fri, Jul 14, 2017 at 9:03 PM, Shreeshrii <notifications@github.com>
wrote:

>  text2image -v
> ERROR: Non-existent flag -v
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/293#issuecomment-315507763>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056RWfgQ6laeiNfg8-OJnW3QuOnWEvks5sODoNgaJpZM4H4kFO>
> .
>



-- 
Ray.
 Please see https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/Qp2cIrcajX4/CF0uohuUAwAJ

It would help if there was some kind of version checking of traineddata files against the --oem mode being used and an appropriate user friendly error message is output (rather than assert) tesseract -v shows the information from ccutil/version.h (ASAIK) and not from traineddata files.

```
#ifndef TESSERACT_CCUTIL_VERSION_H_
#define TESSERACT_CCUTIL_VERSION_H_

#define TESSERACT_VERSION_STR "4.00.00alpha"
#define TESSERACT_VERSION 0x040000
#define MAKE_VERSION(major, minor, patch) \
  (((major) << 16) | ((minor) << 8) | (patch))

#endif  // TESSERACT_CCUTIL_VERSION_H_
```

traineddata version is shown after unpacking with combine_tessdata on console as well as saved in its version file. It is different in tessdata, tessdata_best and tessdata_fast.

```
# combine_tessdata -u ./tessdata/eng.traineddata eng.
Extracting tessdata components from ./tessdata/eng.traineddata
Wrote eng.unicharset
Wrote eng.unicharambigs
Wrote eng.inttemp
Wrote eng.pffmtable
Wrote eng.normproto
Wrote eng.punc-dawg
Wrote eng.word-dawg
Wrote eng.number-dawg
Wrote eng.freq-dawg
Wrote eng.cube-unicharset
Wrote eng.cube-word-dawg
Wrote eng.shapetable
Wrote eng.bigram-dawg
Wrote eng.lstm
Wrote eng.lstm-punc-dawg
Wrote eng.lstm-word-dawg
Wrote eng.lstm-number-dawg
Wrote eng.version
Version string:Pre-4.0.0
1:unicharset:size=7477, offset=192
2:unicharambigs:size=1047, offset=7669
3:inttemp:size=976552, offset=8716
4:pffmtable:size=844, offset=985268
5:normproto:size=13408, offset=986112
6:punc-dawg:size=4322, offset=999520
7:word-dawg:size=1082890, offset=1003842
8:number-dawg:size=6426, offset=2086732
9:freq-dawg:size=1410, offset=2093158
11:cube-unicharset:size=1511, offset=2094568
12:cube-word-dawg:size=1062106, offset=2096079
13:shapetable:size=63346, offset=3158185
14:bigram-dawg:size=16109842, offset=3221531
17:lstm:size=5390718, offset=19331373
18:lstm-punc-dawg:size=4322, offset=24722091
19:lstm-word-dawg:size=7143578, offset=24726413
20:lstm-number-dawg:size=3530, offset=31869991
23:version:size=9, offset=31873521
```

```
 combine_tessdata -u ./tessdata_fast/eng.traineddata eng.
Extracting tessdata components from ./tessdata_fast/eng.traineddata
Wrote eng.lstm
Wrote eng.lstm-punc-dawg
Wrote eng.lstm-word-dawg
Wrote eng.lstm-number-dawg
Wrote eng.lstm-unicharset
Wrote eng.lstm-recoder
Wrote eng.version
Version string:4.00.00alpha:eng:synth20170629
17:lstm:size=401636, offset=192
18:lstm-punc-dawg:size=4322, offset=401828
19:lstm-word-dawg:size=3694794, offset=406150
20:lstm-number-dawg:size=4738, offset=4100944
21:lstm-unicharset:size=6360, offset=4105682
22:lstm-recoder:size=1012, offset=4112042
23:version:size=30, offset=4113054
```

```
combine_tessdata -u ./tessdata_best/eng.traineddata eng.
Extracting tessdata components from ./tessdata_best/eng.traineddata
Wrote eng.lstm
Wrote eng.lstm-punc-dawg
Wrote eng.lstm-word-dawg
Wrote eng.lstm-number-dawg
Wrote eng.lstm-unicharset
Wrote eng.lstm-recoder
Wrote eng.version
Version string:4.00.00alpha:eng:synth20170629:[1,36,0,1Ct3,3,16Mp3,3Lfys64Lfx96Lrx96Lfx512O1c1]
17:lstm:size=11689099, offset=192
18:lstm-punc-dawg:size=4322, offset=11689291
19:lstm-word-dawg:size=3694794, offset=11693613
20:lstm-number-dawg:size=4738, offset=15388407
21:lstm-unicharset:size=6360, offset=15393145
22:lstm-recoder:size=1012, offset=15399505
23:version:size=80, offset=15400517
``` Does it make sense to keep a VERSION text file in tesseract base directory and for all programs, makefiles, cmakelists etc to refer to that to build the Version string.

I had seen an implementation in 
https://github.com/bendiken/templates/blob/master/c%2B%2B.autotools/configure.ac The version string that is generated for older files is:

```
Version string:Pre-4.0.0
```

So, that is an indication of move towards semantic versioning.

@stweil Would you streamline the VERSION handling for the package?   @DanBloomberg, any comment?
 OK. Thanks for your reply, Dan.

Just a quote:

> To spam, or not to spam, that is the question.

;-)
  Did you try read error message???  
IMO it is clear "pango/pango-font.h: No such file or directory". 
  1. Do not change source code unless you are willing to fix consequences by yourself.
2. Make sure that cygwin64 is supported by your opencl provider.
3. Opencl is experimental feature. It was tested on linux and partially on VS2010. Other compilers are not supported - but you can try tesseract user forum for support.
 Thank. Changed
 follow instrustruction for cmake ;-)
  First patch was fixed on 20 Jul 2015! See https://github.com/tesseract-ocr/tesseract/commit/301eaeca5faa4bd1d39a0047471abeec3bb52ac3
  Hi Nick!

> This feature requires Pango 1.38 or newer.

Pango 1.38 was released in 2015-09-21.
It's too new. You should '#ifdef' the code.
 Travis CI on Linux agrees with me :-)

```
/home/travis/build/tesseract-ocr/tesseract/training/stringrenderer.cpp:212:45: error: ‘pango_attr_font_features_new’ was not declared in this scope

       pango_attr_font_features_new(features_);

```
 Here is a standalone version of Tesseract's `text2image`.
https://github.com/amitdo/text2tif
 Off-topic, but this might interest you as well:
https://github.com/eddieantonio/isri-ocr-evaluation-tools
  Hi !

You should give us more details:
- Version of Visual Studio C++.
- Version of Tesseract.
- If this happens with your code, but not with 'tesseract.exe' command line tool, you should provide a sample code that invokes the bug. 
- Output of compiler errors.
 > How can I become a developer of tesseract on github?

You should learn how to use 'pull request' on github.
https://help.github.com/
 > How can I become a developer of tesseract on github?

You can start with creating correct issue report.
It is known that tesseact can be build with problem with VS2010, VS2013 and VS2015.
 http://stackoverflow.com/questions/23740431/tesseract-remove-reference-ambiguous-symbol-in-project-on-visual-studio-2012
 @amitdo: it confirms that it is not tesseract problem but bad practice of writing code using ["namespace std"](http://stackoverflow.com/questions/1452721/why-is-using-namespace-std-in-c-considered-bad-practice) which is real root of ambiguity.
  Please google and read [forum](https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/JZ9G3D5HHNM/A--DXmm2BgAJ) before writing issue
  fixed (moved because of broken link)
  Message is IMO clear: there is no leptonica >= 1.71 in standard location. This is not tesseract problem. 
  What is benefit of this? How to use it?
  Please use [tesseract user forum](https://groups.google.com/forum/#!forum/tesseract-ocr) for asking support (see [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice) )
  - In training/pango_font_info.cpp
 > Good catch. 

Thanks. I've noticed that missing symbol in #195.

> There seem to be more errors of this kind.

I see you already hunted two... :-)
 Would that flag catch that missing % from format specifier?
  Please use [tesseract user forum](https://groups.google.com/forum/#!forum/tesseract-ocr) for asking support (see [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice) )
  Please check [the source](https://github.com/tesseract-ocr/tesseract/blob/master/doc/tesseract.1.asc#languages) before writing issue.
BTW: current version is 3.04.01.
  Git repository is for developers who know how to deal with their system.
Regular users should use packaging tools of their system.
 Before you run those commands, you should put the `*.traineddata` files in `tessdata`
 subdirectory in the source tree.

The *.traineddata files must be places in the `tessdata` directory together with the config files.  
 > As a regular user I cannot copy the tesddata files to /usr/local/share/tessdata
> 
> $ cp ./tessdata/san.traineddata /usr/local/share/tessdata
> cp: cannot create regular file ‘/usr/local/share/tessdata/san.traineddata’: Permission denied

Well, `/usr` is a system directory so you can't write to it without admin rights. 

To run a command as a root user use `sudo`.

Be careful when running commands with `sudo`, you might damage your system if you type the wrong command!

https://help.ubuntu.com/community/RootSudo
http://manpages.ubuntu.com/manpages/karmic/man8/sudo.8.html
https://www.raspberrypi.org/documentation/usage/terminal/
  I see in file "ccmain/pagesegmain.cpp: line 322 - 333". 

``` c++
  // Leptonica is used to find the rule/separator lines in the input.
  LineFinder::FindAndRemoveLines(source_resolution_,
                                 textord_tabfind_show_vlines, pix_binary_,
                                 &vertical_x, &vertical_y, music_mask_pix,
                                 &v_lines, &h_lines);
  if (tessedit_dump_pageseg_images)
    pixWrite("tessnolines.png", pix_binary_, IFF_PNG);
  // Leptonica is used to find a mask of the photo regions in the input.
  *photo_mask_pix = ImageFind::FindImages(pix_binary_);
  if (tessedit_dump_pageseg_images)
    pixWrite("tessnoimages.png", pix_binary_, IFF_PNG);
```

Please notice to line: 

``` c++
  if (tessedit_dump_pageseg_images)
    pixWrite("tessnoimages.png", pix_binary_, IFF_PNG);
```

I try with configuration:

```
tessedit_dump_pageseg_images    1
```

And images: 
![news](https://cloud.githubusercontent.com/assets/8704662/13735304/7b94f300-e9da-11e5-94f0-c4eeac8ca254.png)

But result in file "tessnoimages.png" is: 
![tessnoimages](https://cloud.githubusercontent.com/assets/8704662/13735340/bf23a256-e9da-11e5-97d1-ee3d6e1e9128.png)

I think before `pixWrite("tessnoimages.png", pix_binary_, IFF_PNG);`, we need something like:

``` c++
if (*photo_mask_pix != NULL) {
    pixSubtract(pix_binary_, pix_binary_, *photo_mask_pix);    
}
```
 At least in [osdetect](https://github.com/tesseract-ocr/tesseract/blob/master/ccmain/osdetect.cpp#L177) it is done that way. Anyway I found out that   pixSubtract(pix_binary_, pix_binary_, *photo_mask_pix) does not removed all images.
@theraysmith: can you have a look at this?
  Please use [tesseract user forum](https://groups.google.com/forum/#!forum/tesseract-ocr) for asking support (see [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice) )
  fixed with ddd3cad8c6802d016a48aa21e6303e8004d50955
  Which version/commit you use?
Can you do more analysis and send a fix/patch)?
Main development is done on linux and windows developer is needed
  You can try to use 3.02 version if you need only English. AFAIR it was
singnificantly faster on my (old) computer.

Zdenko

On Thu, Mar 10, 2016 at 4:35 PM, younes notifications@github.com wrote:

> I integrated Tesseract C/C++, version 3.x, to read English OCR on images.
> 
> It’s working pretty good, but very slow. It takes close to 1000ms (1
> second) to read the attached image (00060.jpg) on my quad-core laptop.
> 
> I’m not using the Cube engine, and I’m feeding only binary images to the
> OCR reader.
> 
> Any way to make it faster. Any ideas on how to make Tesseract read faster?
> thanks
> [image: 00060]
> https://cloud.githubusercontent.com/assets/9968625/13674495/ac261db4-e6ab-11e5-9b4a-ad91d5b4ff87.jpg
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/263.
 > ...  3.02 version ... AFAIR it was significantly faster on my (old) computer.

~~3.02~~ 3.02.02 is compiled with '-O3' by default.
https://github.com/tesseract-ocr/tesseract/blob/3.02.02/configure.ac#L161

3.03 and 3.04 are compiled with '-O2' by default.
https://github.com/tesseract-ocr/tesseract/blob/3.03-rc1/configure.ac#L201
https://github.com/tesseract-ocr/tesseract/blob/3.04.01/configure.ac#L300

2.04 and 3.01 are compiled with ~~'-O0'~~ '-O2' by default.
https://github.com/tesseract-ocr/tesseract/blob/2.04/configure.ac
https://github.com/tesseract-ocr/tesseract/blob/3.01/configure.ac
The 'configure.ac' script in these versions does not explicitly set the '-O' level, so autotools will use ~~'-O0'~~  '-O2' as default.
 What I linked to was actually 3.02.**02** 

I think this is 3.02:
https://github.com/tesseract-ocr/tesseract/blob/d581ab7e12a2fac4a73ac0af4ce7ec522b8f3e42/configure.ac

You are right. It does not contain any '-On' flag, ~~so the compiler will use '-O0', which is not good for speed.~~ so if you are using autotools to build Tesseract it will instruct the compiler to use '-O2'.
 I assume you are using Tesseract on Linux / FreeBSD / Mac. On Windows + MS Visual C++ the `configure.ac` file is irrelevant.
 Thanks Shree.

I don't know which optimization level is used for Visual C++.
 VS2010 use optimization flag /O2 (Maximize speed) - other flags are set to default.
In past in forum there were warnings against using compiler optimization flag as they affect also OCR results. This is reason why there are standard optimization flags (-O2 in autotools and /O2 in VS).

I tried to run perf tool on linux:
   `perf record tesseract eurotext.tif eurotext`
and I got this report (`perf report`):

```
  39,77%  tesseract  libtesseract.so.3.0.4  [.] tesseract::SquishedDawg::edge_char_of
  13,98%  tesseract  libtesseract.so.3.0.4  [.] tesseract::Classify::ComputeCharNormArrays
  13,09%  tesseract  libtesseract.so.3.0.4  [.] IntegerMatcher::UpdateTablesForFeature
   4,22%  tesseract  libtesseract.so.3.0.4  [.] tesseract::Classify::PruneClasses
   2,66%  tesseract  libtesseract.so.3.0.4  [.] ScratchEvidence::UpdateSumOfProtoEvidences
   1,48%  tesseract  libtesseract.so.3.0.4  [.] ELIST_ITERATOR::forward
   1,16%  tesseract  libc-2.19.so           [.] _int_malloc
   1,15%  tesseract  libtesseract.so.3.0.4  [.] tesseract::ShapeTable::MaxNumUnichars
   1,01%  tesseract  libtesseract.so.3.0.4  [.] tesseract::Classify::ExpandShapesAndApplyCorrections
   0,87%  tesseract  liblept.so.5.0.0       [.] rasteropLow
   0,79%  tesseract  libm-2.19.so           [.] __mul
   0,72%  tesseract  libtesseract.so.3.0.4  [.] FPCUTPT::assign
   0,71%  tesseract  libc-2.19.so           [.] _int_free
   0,71%  tesseract  libtesseract.so.3.0.4  [.] ELIST::add_sorted_and_find
   0,61%  tesseract  libtesseract.so.3.0.4  [.] tesseract::AmbigSpec::compare_ambig_specs
   0,57%  tesseract  libtesseract.so.3.0.4  [.] tesseract::Classify::ComputeNormMatch
   0,52%  tesseract  libc-2.19.so           [.] memset
   0,49%  tesseract  libc-2.19.so           [.] vfprintf
   0,45%  tesseract  libc-2.19.so           [.] malloc
   0,36%  tesseract  libtesseract.so.3.0.4  [.] SegmentLLSQ
   0,31%  tesseract  libm-2.19.so           [.] __ieee754_atan2_sse2
   0,31%  tesseract  libc-2.19.so           [.] malloc_consolidate
   0,30%  tesseract  libtesseract.so.3.0.4  [.] LLSQ::add
   0,29%  tesseract  libtesseract.so.3.0.4  [.] GenericVector<tesseract::ScoredFont>::operator+=
   0,29%  tesseract  libtesseract.so.3.0.4  [.] _ZN14ELIST_ITERATOR7forwardEv@plt
   0,28%  tesseract  libtesseract.so.3.0.4  [.] tesseract::ComputeFeatures
   0,25%  tesseract  liblept.so.5.0.0       [.] pixScanForForeground
   0,24%  tesseract  libtesseract.so.3.0.4  [.] GenericVector<tesseract::ScoredFont>::reserve
   0,20%  tesseract  libtesseract.so.3.0.4  [.] C_OUTLINE::increment_step
   0,20%  tesseract  [kernel.kallsyms]      [k] clear_page
```

according this report 3 top function consumed 66% of "time".

Then I tried 4 pages (A4 ) tiff (G4 compressed):

```
  52,24%  tesseract  libtesseract.so.3.0.4  [.] tesseract::SquishedDawg::edge_char_of
  12,06%  tesseract  libtesseract.so.3.0.4  [.] tesseract::Classify::ComputeCharNormArrays
  10,06%  tesseract  libtesseract.so.3.0.4  [.] IntegerMatcher::UpdateTablesForFeature
   3,57%  tesseract  libtesseract.so.3.0.4  [.] tesseract::Classify::PruneClasses
   1,90%  tesseract  libtesseract.so.3.0.4  [.] ScratchEvidence::UpdateSumOfProtoEvidences
...
```

Then I tried non eng image: `perf record tesseract hebrew.png hebrew -l heb`:

```
  27,79%  tesseract  libtesseract.so.3.0.4  [.] IntegerMatcher::UpdateTablesForFeature
  27,34%  tesseract  libtesseract.so.3.0.4  [.] tesseract::Classify::ComputeCharNormArrays
   4,40%  tesseract  libtesseract.so.3.0.4  [.] tesseract::Classify::PruneClasses
   3,98%  tesseract  libtesseract.so.3.0.4  [.] ScratchEvidence::UpdateSumOfProtoEvidences
   3,05%  tesseract  libtesseract.so.3.0.4  [.] tesseract::Classify::ComputeNormMatch
   2,36%  tesseract  libtesseract.so.3.0.4  [.] tesseract::ShapeTable::MaxNumUnichars
   2,05%  tesseract  libtesseract.so.3.0.4  [.] tesseract::Classify::ExpandShapesAndApplyCorrections
...
```
 Just for record for possible improvement in this issue: there was interesting information posted in scantailor project: [OpenCL alone only brings ~2x speed-up. Another ~6x speed-up comes from multi-threaded processing.](https://github.com/scantailor/scantailor/issues/236#issuecomment-243178950)
 That is a surprisingly hard question to answer in the Google environment!

I use 'opt' mode which after some digging, I found maps to -O2.
In addition, explicitly added are:
-fopenmp which will deliver a major improvement (3x faster), if you do not
have it, and a corresponding -lgomp for the linker
arch/dotproductavx.cpp is compiled with -mavx
arch/dotproductsse.cpp (and actually all the rest of the code) is compiled
with -msse4.1

I thought all this stuff was in the autotools files already, or are you
looking to convert these to windows?

On Sat, Apr 8, 2017 at 10:50 AM, Stefan Weil <notifications@github.com>
wrote:

> Don't expect much difference between -O2 and -O3. I tried different
> optimizations, and they only have small effects on the time needed for OCR
> of a page. Higher optimization levels can even result in slower code
> because the code gets larger (because of unfolding of loops), so CPU caches
> become less effective. It is much more important to write good code.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/263#issuecomment-292734412>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056Qbi9xKk5GXQtfgXVZajN10mksEUks5rt8j6gaJpZM4Ht19x>
> .
>



-- 
Ray.
 OpenMP speeds up training by about 3.5x, since it runs 4 threads (one for
each part of the LSTM) and spends >90% of CPU time computing the LSTM
forward/backward.

On Sat, Apr 15, 2017 at 7:11 AM, Stefan Weil <notifications@github.com>
wrote:

> Yes, for training a single new model OpenMP could perhaps speed up the
> training process. Up to now, OpenMP is only used in ccmain/ and in lstm/.
> I don't know how much that part is used during training, and I never have
> run a performance evaluation for the training process (in fact I‌ have only
> run LSTM training once for Fraktur, and as I already said, it was not
> really successful).
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/263#issuecomment-294295776>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056QxUeSroEmcJmZ30om3_wi6Mlyu5ks5rwNAogaJpZM4Ht19x>
> .
>



-- 
Ray.
 No, it doesn't help. The parallelism is limited by the implementation of
the LSTM as 4 matrix-vector products.
When I experimented with more threads for some of the other operations (eg
the output softmax), it slowed down because the cache coherency was lost.
I also experimented with breaking the matrix-vector products up further (eg
splitting the input from the recurrent part), but openMP doesn't seem too
good at allocating the threads in a way that keeps the cache coherency.
Each thread needs to run the same part of the weights matrix for each
timestep, and that is difficult to achieve with the recurrent nature of the
LSTM.

On Tue, Apr 18, 2017 at 11:09 PM, xlight <notifications@github.com> wrote:

> can I set more than 4 threads for Trainning LSTM?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/263#issuecomment-295112242>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056UAEnzbmZZ5vncaO2zr0ASll1IoCks5rxaUjgaJpZM4Ht19x>
> .
>



-- 
Ray.
 It still works. It just takes longer.

On Wed, Apr 19, 2017 at 10:00 AM, Amit D. <notifications@github.com> wrote:

> What about machine that have only 2 cores?
> Shouldn't the 'num_threads' lowered to 2 in that case?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/263#issuecomment-295345495>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056dmv_0xhpF-2Qt11PJbfyg5Z-Bepks5rxj26gaJpZM4Ht19x>
> .
>



-- 
Ray.
  That error means that you are not linking against wrong version of leptonica  library (<1.71). You need to fix your leptonica instalation
  thanks. Fixed
  Please use tesseract user forum for asking support (see [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice)).
Hint: Provide original image you try to OCR not screenshot from you app.
  This is not tesseract problem, but problem how you maintain your system. Compiling from source requires you are familiar with your system.
Building tools requires to links against leptonica. And you system (base how you maintain it) says it should link against liblept-4.dll.
Coping liblept-5.dll as liblept-4.dll is very bad idea.
Maintain you system correctly and you will get good result.
 Did you recompile (./configure, make, sudo make install, sudo ldconfig) tesseract after you recompiled leptonica 1.73?
 rebuilding tesseract does not help unless leptonica instalation is not fixed within msys...
 Do you have liblept.dll?
It should be a symlink to liblept-5.dll
 As zdenko said, something is wrong with your leptonica installation.

Here are the files in my linux system:

/usr/local/lib/liblept.a
/usr/local/lib/liblept.la
/usr/local/lib/liblept.so symlink to /usr/local/lib/liblept.so.5.0.0
/usr/local/lib/liblept.so.5 symlink to /usr/local/lib/liblept.so.5.0.0
/usr/local/lib/liblept.so.5.0.0
 Real problem is that he has several installation of leptonica but msys instruct linker to use older leptonica version (which could be reasonable if older version was installed by msys packagin system and new version "by hand") . There are several ways how to solve it:
1. Learn how your environment/system is working, how to manage it
2. If 1. is not option - wait for official packages and do to try to compile from source
3. Use only one version of software => do not use packaging system, but compile from source. From my experience, this option will sooner or later lead to the current status (something goes wrong and I have not clue why) ;-). 
 Shree,

Here are the commands I ran on Linux:

```
cd path/to/leptonica-1.73

./configure
make
sudo make install
sudo ldconfig

cd path/to/tesseract-ocr
./autogen.sh
./configure  --enable-debug
make
sudo make install
sudo ldconfig
make training
sudo make training-install
```

Did you run `sudo ldconfig` ?
 Shree,

About your `Compiling` wiki edit.

You need to run `sudo ldconfig` after every time you manually (not with package manager) update, add or remove a shared library (*.so / *.dll).

```
./autogen.sh
./configure
make
sudo make install
sudo ldconfig
```

Here `sudo ldconfig` is needed because `sudo make install` installed a library - `libtesseract.so.3`, in your system.

However,  `sudo ldconfig` **is not needed** after

```
make training
sudo make training-install
```

because `sudo make training-install` only install some **programs**, but does not install any **library**. 
 http://tldp.org/HOWTO/Program-Library-HOWTO/shared-libraries.html
  Please use [tesseract user forum](https://groups.google.com/forum/#!forum/tesseract-ocr) for asking support (see [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice) )
  I follow comment in this link: [FAQ There are inconsistent r....](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#there-are-inconsistent-results-from-tesseract-when-the-same-tessbaseapi-object-is-used-for-decoding-multiple-images)

But when I using tesseract with that options: 

```
classify_enable_learning 0
classify_enable_adaptive_matcher 0
```

I received one message like following: 
![segmentationfault](https://cloud.githubusercontent.com/assets/8704662/13592015/cf15c950-e520-11e5-8dd3-cff447e8cc1d.png)

I think this is one bug, because setting in config file is common for user. 
I find on all forum but not have any topic talk about this issue.
 Please provide also input files (test1.tif and config.txt)
 Hi zdenop, thanks for your quick response. 
I would like attacht 2 files 
[config.txt](https://github.com/tesseract-ocr/tesseract/files/163134/config.txt) 

Following tif file, I can not upload to this comment, therefore I upload to my repository. You can access to following link to get tif file.
[https://github.com/nam-leduc/positioning/blob/master/test1.tif](https://github.com/nam-leduc/positioning/blob/master/test1.tif)

Best regards,
Le Duc. Nam
 What OS are you using?
Did you try to install tesseract (as I see you from screenshot you are using not installed tesseract) and than use tesseract?
Do you have more versions of tesseract installed?
 I can reproduce this issue.

[config.txt](https://github.com/tesseract-ocr/tesseract/files/163665/config.txt)

```
tesseract phototest.tif phototest config.txt
Tesseract Open Source OCR Engine v3.05.00dev-266-gb1c1382 with Leptonica
Page 1
Segmentation fault (core dumped)
```

But this one works...

```
tesseract phototest.tif phototest -c classify_enable_learning=0 -c classify_enable_adaptive_matcher=0
Tesseract Open Source OCR Engine v3.05.00dev-266-gb1c1382 with Leptonica
Page 1
Warning in pixReadMemTiff: tiff page 1 not found
```

[phototest.txt](https://github.com/tesseract-ocr/tesseract/files/163680/phototest.txt)
 ```
gdb tesseract


(gdb) run phototest.tif phototest config.txt
Starting program: /usr/local/bin/tesseract phototest.tif phototest config.txt
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Tesseract Open Source OCR Engine v3.05.00dev-266-gb1c1382 with Leptonica
Page 1

Program received signal SIGSEGV, Segmentation fault.
tesseract::Tesseract::recog_all_words (this=0x808c00, page_res=0x81cb90, 
    monitor=monitor@entry=0x0, target_word_box=target_word_box@entry=0x0, 
    word_config=word_config@entry=0x0, dopasses=dopasses@entry=0)
    at control.cpp:320
320     } else if (!AdaptiveClassifierIsEmpty()) {


(gdb) backtrace
#0  tesseract::Tesseract::recog_all_words (this=0x808c00, 
    page_res=0x81cb90, monitor=monitor@entry=0x0, 
    target_word_box=target_word_box@entry=0x0, 
    word_config=word_config@entry=0x0, dopasses=dopasses@entry=0)
    at control.cpp:320
#1  0x00007ffff769929d in tesseract::TessBaseAPI::Recognize (
    this=this@entry=0x7fffffffdce0, monitor=0x0) at baseapi.cpp:902
#2  0x00007ffff76994e4 in tesseract::TessBaseAPI::ProcessPage (
    this=this@entry=0x7fffffffdce0, pix=0x83f110, 
    page_index=page_index@entry=0, 
    filename=filename@entry=0x7fffffffe257 "phototest.tif", 
    retry_config=retry_config@entry=0x0, 
    timeout_millisec=timeout_millisec@entry=0, renderer=renderer@entry=
    0x81cb50) at baseapi.cpp:1231
#3  0x00007ffff7699a5c in tesseract::TessBaseAPI::ProcessPagesMultipageTiff (this=this@entry=0x7fffffffdce0, data=data@entry=0xdde558 "II*", 
    size=38668, filename=filename@entry=0x7fffffffe257 "phototest.tif", 
    retry_config=retry_config@entry=0x0, 
    timeout_millisec=timeout_millisec@entry=0, 
    renderer=renderer@entry=0x81cb50, tessedit_page_number=-1)
    at baseapi.cpp:1064
#4  0x00007ffff769a0c3 in tesseract::TessBaseAPI::ProcessPagesInternal (
    this=this@entry=0x7fffffffdce0, filename=<optimized out>, 
---Type <return> to continue, or q <return> to quit---
    retry_config=retry_config@entry=0x0, 
    timeout_millisec=timeout_millisec@entry=0, renderer=0x81cb50)
    at baseapi.cpp:1183
#5  0x00007ffff769a2f0 in tesseract::TessBaseAPI::ProcessPages (
    this=this@entry=0x7fffffffdce0, filename=<optimized out>, 
    retry_config=retry_config@entry=0x0, 
    timeout_millisec=timeout_millisec@entry=0, renderer=<optimized out>)
    at baseapi.cpp:1081
#6  0x0000000000401f2a in main (argc=<optimized out>, argv=0x7fffffffde78)
    at tesseractmain.cpp:448

```
 But I can not ;-):

```
tesseract test1.tif test1.tif config.txt 
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Page 2
```

neither on linux (3.05.00dev-266-gb1c1382) or windows 7  (tesseract 3.04.01)
 Use my config.txt ...

He attached his config.txt with only 1 line, but said:

> But when I using tesseract with that options:
> 
> classify_enable_learning 0
> classify_enable_adaptive_matcher 0

My system is Ubuntu 14.04.
 Thanks! Now I am able to reproduce it (crash with config file and no crash with "-c").
 `classify_enable_adaptive_matcher 0` 
in the config file is causing the crash, 
not `classify_enable_learning 0`.

Updated file:
[config.txt](https://github.com/tesseract-ocr/tesseract/files/164139/config.txt)
 Hi @amitdo and @zdenop, 

I'm sorry, I try with other config options for checking what option make crash, but I forget recovering to original config file. 

```
classify_enable_learning 0
classify_enable_adaptive_matcher 0
```
 Even 3.03 crashes with this config file.
 > The reason that it doesn't crash when the config variable is set on the command line is because that's done after the recognizer is initialized, so the necessary data structure has been created.

Can you elaborate on this?
 @tfmorris @amitdo : beside this issues this behaviour should be documented: option "-c" can not be used for [init only](https://github.com/tesseract-ocr/tesseract/wiki/ControlParams#init-only) parameters. Or do we change of parsing of "-c" params?
 I think we should print a warning if someone try to set an init parameter using '-c var=val' in the command line. The relevant function is `SetParam`in `ccutil/params.cpp`.
 About `classify_enable_adaptive_matcher` - Ray should handle it. 
 But the FAQ should be fixed.
  Please create PR. Thanks.
 thanks.
 done.

Zdenko

On Tue, Mar 8, 2016 at 5:03 PM, jbreiden notifications@github.com wrote:

> Please make sure this reaches the 3.04 branch.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/254#issuecomment-193840163
> .
  Problem is that you [did not followed instruction](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#generate-training-images) so you are alone with your problem.

Also it looks like your font seem to be common. In such case training is useless (from community experience) - nobody was able to reach quality provided by google traineddata.
 First I all: "you assume" and you ask as to prove it ;-). If you want to create acceptable issue, please use google traineddata and not modified tesseract. 

Next: tesseract is known that it requires to follow training procedure strictly. If you decide to not follow it, please do not create issue, but use [tesseract user forum](https://groups.google.com/forum/#!forum/tesseract-ocr) instead.

Next: Community experience is that if your font looks common (e.g. it is very similar to fonts listed e.g. in https://github.com/tesseract-ocr/tessdata/blob/master/eng.cube.size) training is waste of time (you will get worse results). You should focus on image preprocessing instead.  
 With the default eng.traineddata I get:

```
tesseract z.png - -psm 10
N
```

So use the default traineddata and [Improve the input image](https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality) if needed.
 > ... fonts listed e.g. in https://github.com/tesseract-ocr/tessdata/blob/master/eng.cube.size

A better link:
https://github.com/tesseract-ocr/tesseract/blob/master/training/language-specific.sh

> List of fonts to train on
> LATIN_FONTS=(
>     "Arial Bold" \
>     "Arial Bold Italic" \
>     "Arial Italic" \
>     "Arial" \
>     "Courier New Bold" \
>     "Courier New Bold Italic" \
>     "Courier New Italic" \
>     "Courier New" \
>     "Times New Roman, Bold" \
>     "Times New Roman, Bold Italic" \
>     "Times New Roman, Italic" \
>     "Times New Roman," \
>     "Georgia Bold" \
>     "Georgia Italic" \
>     "Georgia" \
>     "Georgia Bold Italic" \
>     "Trebuchet MS Bold" \
>     "Trebuchet MS Bold Italic" \
>     "Trebuchet MS Italic" \
>     "Trebuchet MS" \
>     "Verdana Bold" \
>     "Verdana Italic" \
>     "Verdana" \
>     "Verdana Bold Italic" \
>     "URW Bookman L Bold" \
>     "URW Bookman L Italic" \
>     "URW Bookman L Bold Italic" \
>     "Century Schoolbook L Bold" \
>     "Century Schoolbook L Italic" \
>     "Century Schoolbook L Bold Italic" \
>     "Century Schoolbook L Medium" \
>     "DejaVu Sans Ultra-Light" \
> )
  And the error message/problem is???
 > pdf.ttx has never been required for Tesseract PDF generation... there is no need to distribute with Tesseract at all.

So why we keep GlyphLessFont.h|cpp? It's not even in sync with the updated pdf.ttf.
 @zdenop, could you remove these two files?
 Done. See cab6de17400f8147fbbd2a56125ba8c23a730e7a
  Did you oversaw #ifndef GRAPHICS_DISABLED ?
  Can you please make pull requests?
  It seem you did not install tesseeract training tool...
 For asking support please use [tesseract user forum](https://groups.google.com/forum/#!forum/tesseract-ocr) - see [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice)
  I am not sure if it is an good idea to return valid output (0.0) when tesseract did not produced certainty...
And as you mentioned: this patch does not solve root of problem. I suggest to keep it open for Ray investigation.
  @szpeak 

I'm sorry but this pull request does not make any sense.
  https://github.com/tesseract-ocr/tesseract/blob/master/api/baseapi.cpp#L954

> const char \*  TessBaseAPI::GetDatapath() {
>   return tesseract_->datadir.c_str();
> }
  https://github.com/tesseract-ocr/tesseract/blob/master/ccmain/thresholder.cpp#L54

```
// SetImage makes a copy of all the image data, so it may be deleted
// immediately after this call.
// Greyscale of 8 and color of 24 or 32 bits per pixel may be given.
// Palette color images will not work properly and must be converted to
// 24 bit.
// Binary images of 1 bit per pixel may also be given but they must be
// byte packed with the MSB of the first byte being the first pixel, and a
// one pixel is WHITE. For binary images set bytes_per_pixel=0.
void ImageThresholder::SetImage(const unsigned char* imagedata,
                                int width, int height,
                                int bytes_per_pixel, int bytes_per_line) {
```
 I totally agree...
:-)
 Oops  I made a mistake.

The relevant method takes 'const Pix*'.
https://github.com/tesseract-ocr/tesseract/blob/master/ccmain/thresholder.cpp#L143

My previous comment linked to an overloaded method which takes 'const unsigned char*'.

```
// Pix vs raw, which to use? Pix is the preferred input for efficiency,
// since raw buffers are copied.
// SetImage for Pix clones its input, so the source pix may be pixDestroyed
// immediately after, but may not go away until after the Thresholder has
// finished with it.
void ImageThresholder::SetImage(const Pix* pix) {
  if (pix_ != NULL)
    pixDestroy(&pix_);
  Pix* src = const_cast<Pix*>(pix);
  int depth;
  pixGetDimensions(src, &image_width_, &image_height_, &depth);
  // Convert the image as necessary so it is one of binary, plain RGB, or
  // 8 bit with no colormap.
  if (depth > 1 && depth < 8) {
    pix_ = pixConvertTo8(src, false);
  } else if (pixGetColormap(src)) {
    pix_ = pixRemoveColormap(src, REMOVE_CMAP_BASED_ON_SRC);
  } else {
    pix_ = pixClone(src);
  }
  depth = pixGetDepth(pix_);
  pix_channels_ = depth / 8;
  pix_wpl_ = pixGetWpl(pix_);
  scale_ = 1;
  estimated_res_ = yres_ = pixGetYRes(src);
  Init();
}
```
 The mystery thickens...

The above function seems to be correctly written to deal with colormaps:
- 1st case `(depth > 1 && depth < 8)` : the image is either a low bit-depth greyscale or a colormapped image with at most 128 color indexes (well probably 16 colors in real cases). Then the image is converted to a 256-level gray-scale image (`pixConvertTo8(...,false)`)
- 2nd case: the bit depth is at least 8 and the image has a colormap. As more than 8 bit per channel images are not handled by leptonica, it is either a 256 indexes grayscale image or a 256 indexes RGB image. pixRemoveColormap produces a non-indexed 8bit grayscale or 24bit RGB image.
- last case: at least 8bpp and no colormap, so it is a non-indexed 8bit grayscale or 24bit RGB image.

So the image is now a 8bit per channel raster with no colormap, it seems fit for thresholding.

I checked which way followed both my test images, and I extracted the thresholded image:

```
--- api/baseapi.cpp.orig    2016-02-18 08:48:00.000000000 +0100
+++ api/baseapi.cpp 2016-03-01 23:37:26.247132277 +0100
@@ -2151,6 +2152,9 @@
   }
   tesseract_->set_source_resolution(estimated_res);
   SavePixForCrash(estimated_res, *pix);
+pixWriteTiff("thres.tiff", *pix, IFF_TIFF,"w");
 }

```

The 'ok.png' fits the second case (8bit palette) and exits this function as 24bit RGB (well pixGetDepth(..)=32), here is the thresholded image:
![ok-thresholded](https://cloud.githubusercontent.com/assets/17527508/13445517/e7539042-e00c-11e5-87ad-51af5a70251e.png)

The 'nak.png" fits the first case (4bit palette) and exits this function as a 8bit grayscale. Result of threshold:
![nak-thresholded](https://cloud.githubusercontent.com/assets/17527508/13445556/31b3e2fe-e00d-11e5-916c-b35465a16e4e.png)

Well, the letters in the second image are thinner, but in the first image there are some small peaks under the letters... And for the only letter that is not correctly recognized in these lines, the middle 'a' of the first line, I'm really not sure which version I prefer...

So:
- the result differs if the color to gray conversion is done here or further in the threshold process. 
- in my case it is best that it is not done here, probably because it gives too thin letters
- but maybe that with bold letters the "good" and "bad' cases would be inverted ?

For the moment I can't see a clear flaw in the design of this function and I am not sure of what is the correct strategy in the general case. 
What bugs me is that the results differ according to image encoding and not image content, because it triggers different processing paths.
If we can show that keeping the image RGB at this stage is better, then this function should be corrected. If depends on the type of image, maybe there should be a command line option (--subtitles) ?

After some thoughts, as it concerns only color palette images, it will probably only concern subtitles and screen dumps (who would scan a page or take a picture in a gif-like format ?). So maybe "my case" is the "general case"

Off to bed...
 I converted your nak.png to rgb and gray images using GIMP.
[242-bad-gimp-rgb](https://cloud.githubusercontent.com/assets/13571208/13510330/b88b6180-e198-11e5-8840-d92a48c91cfa.png)
[242-bad-gimp-gray](https://cloud.githubusercontent.com/assets/13571208/13510357/d83809a2-e198-11e5-934c-7f273a4bb35d.png)

```
tesseract -l fra bad-gimp-rgb.png stdout
La mort a eu lieu
il y a 8 à 12 heures.

tesseract -l fra 242-bad-gimp-gray.png stdout
La mort a eu lieu
il y a 8 à 12 heures.

```
 Oh, I missed this part: 
`pngtopnm nak.png | tesseract -l fra stdin stdout`
 ```
tesseract -l fra 242-bad.png stdout -psm 11
La mort a eu lieu

il y a 8 à 12 heures.

```

https://github.com/tesseract-ocr/tesseract/blob/master/api/tesseractmain.cpp#L97
 Well, I did some digging in the image path before character recognition.

I think it all comes from the dark-blue background.

If the image is converted to gray-levels before thresholding (16 color palette image), the threshold is determined via gray-histogram study, and is set to 98
If the image is thresholded as a RGB picture, there are 3 histograms, giving 3 thresholds: 64(R), 64(G) and 132(B)
When the image is binarized (?), if it is an RGB picture, the pixels R,G,B values are tested against these thresholds, in that order. As soon as one of the 3 value is above its threshold, the pixel is considered part of a character.
In this pictures, the characters are outlined in dark gray (31,31,31) the light gray (64,64,64).
The dark-gray is always below thresholds, so it is considered background.
The light-gray is equal to the red threshold, so it is considered part of the character when red is tested in first -> thick letters in RGB mode
But it is below the gray-level threshold (98), so it is considered part of the background -> thin letters in gray-mode.
 I'm not sure if it is a good idea to set a priority in the RGB thresholds so that red is tested before green, and then only blue. This priority seems only chosen by the classical RGB color order:
(from ccmain/thresholder.cpp)

```
      bool white_result = true;
      for (int ch = 0; ch < num_channels; ++ch) {
        int pixel = GET_DATA_BYTE(const_cast<void*>(
                                  reinterpret_cast<const void *>(linedata)),
                                  (x + rect_left_) * num_channels + ch);
        if (hi_values[ch] >= 0 &&
            (pixel > thresholds[ch]) == (hi_values[ch] == 0)) {
          white_result = false;
          break;
        }
      }
```

 In fact the algorithm even calculates the alpha channel histogram, and if the result was not null, it would test the alpha value of the pixel against this threshold.
I think that this is just a waste of time.

Anyway, as for now, tesseract seems to do arbitrary choices in the process of color-images binarization:
- if the image has a small palette it is first converted to gray
- this gray conversion seems to use a more or less random formula: gray = 0.25 R + 0.5 G + 0.25 B
- the first plane which claims to have detected a character wins the test (there could be a vote between the 3)
- alpha gets treated in this process. The only sensible way to treat alpha would be IMHO to treat the pixel as background if alpha is small, so it would have to be tested first, and if small, prevent testing of other planes.

Maybe the sensible advice to users experiencing bad results with color images should be to do the gray conversion by themselves. There are many possible choices in this process: GIMP has tree options in the 'desaturate' dialog; my old scanner was just using the green channel when scanning in grey (as do many copiers). Maybe one of CMYK layers could be good in some cases...

In the case of these subtitles where, who knows why, ProjectX added a dark-blue background, selecting the red or green plane gives the best contrast between text and background, and leads to good results (which happens by chance on 'ok.png', would'nt work if ProjectX had chosen red background)
 Nice analysis!

https://github.com/tesseract-ocr/tesseract/blob/master/README.md
The README includes this sentence:

> You should note that in many cases, in order to get better OCR results, you'll need to [improve the quality](https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality) of the image you are giving Tesseract.

So maybe the ImproveQuality wiki page is the right place to add your advice. You can edit the wiki yourself. The explanation should be as clear and short as possible.
 It is in fact in leptonica.
In ccmain/thresholder.cpp, Tesseract calls leptonica's pixConvertTo8 when the input image has less than 8 bpp (or a colormap with few colors, typically 16):

```
  if (depth > 1 && depth < 8) {
    pix_ = pixConvertTo8(src, false);
```

For indexed-color images, pixConvertTo8 calls pixRemoveColormap (see [https://tpgit.github.io/Leptonica/pixconv_8c_source.html] ) with `type = REMOVE_CMAP_TO_GRAYSCALE`
In that case, the colormap is converted to gray with this code:

```
for (i = 0; i < pixcmapGetCount(cmap); i++) {
      graymap[i] = (rmap[i] + 2 * gmap[i] + bmap[i]) / 4;
}
```

So it is leptonica which uses this quick formula, although speed should not really be a concern here as it is applied just to the colormap, not the full image.

Sorry, I don't have much time this week to follow this thread.
Thanks for the interest.
 @jbreiden: will you make a PR or should I commit patch from above?
 patch committed with c1c1e42  The right place for asking questions is:
https://groups.google.com/d/forum/tesseract-ocr
 Tesseract does not work without leptonica.
  The right place for asking questions is:
https://groups.google.com/d/forum/tesseract-ocr
  Which program are you using to view the PDF?
 It does not look reversed wtth Chrome PDF viewer, just not very accurate...
 @roozgar

It seems that Ray is planning to release soon a new version of Tesseract, that will include a new OCR engine based on LSTM.

With LSTM, OCR for printed Arabic (not real handwrite) can reach 95% character accuracy.

"Offline Printed Urdu Nastaleeq Script Recognition
with Bidirectional LSTM Networks"
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.447.4577&rep=rep1&type=pdf
 > I checked google drive ocr for Arabic and i see it have 100 results for same image..

Neither you or I know what programs they are using to do OCR there...
 @tbadran

> But please note that words are not reversed while viewing the PDF because it contains the original image with text layer.
> I mean when you copy text layer then paste it to any text editor it will be reversed, so now can't search for the text inside the PDF because it is stored revered inside the text layer!

Yes, I know...

Here is a copy of the invisible text layer (copied & pasted):

مداها ينم همهما
اللغة العريية
لغة جهد مه
مسنره هي انحاء العالم

Using Chromium (Google browser) PDF viewer under Linux.

Your original jpg image:
![test_ara](https://cloud.githubusercontent.com/assets/17473681/13320324/bc160e22-dbd0-11e5-8090-6f3728fcc06d.jpg)
 @roozgar 

You can try training Tesseract using the regular engine. Use the the wiki and see #169. I really don't know how good the result will be for Arabic.

Like jbreiden said, the timeline could change...
 Tom, 

Look at the original jpg.
Lines 2 and 4 in Google Chrome look quite similar to lines 2 and 3 in the original jpg. First word in line 3 in the original jpg became first word in line 3 in Google Chrome.
Clearly, that's the 'good' output...
 Again, in Google Chromium.
If I mark the first two lines in the PDF + first word in line 3, 
copy the (invisible) text, paste it to a text file, 
mark the second to last word in line 3 in the PDF, 
copy the (invisible) text, paste it to the text file, I get:

مداها ينم همهما
اللغة العريية
لغة مسنره هي انحاء العالم
 @jbreiden 
I didn't understand you. In one comment you talk about Hebrew and in another one you only referring Arabic. Does Hebrew displayed correctly with Adobe Reader?
 Please make sure that any change you do is not causing any regression with Chrome PDF viewer and OS X Preview. Thanks for your work!
 Maybe explicitly using unicode bidi control characters can help ?
 @jbreiden, any progress? Which way you chose?
Personally, I care about our Hebrew support.
 I am taking a look at this today. With current code, copy-paste works from Chrome, fails from Adobe Reader. Destination is gEdit. All tests are on Linux. I see no difference in Adobe Reader if I insert U+2067 RIGHT-TO-LEFT ISOLATE (RLI) at the beginning of each word, and U+2069 POP DIRECTIONAL ISOLATE (PDI) at the end of each word. It's possible that my copy of Adobe Reader is too old to understand these control characters. Or that I am using them wrong. Too early to tell.

![a](https://cloud.githubusercontent.com/assets/4961958/16635989/323c3664-438a-11e6-9d2c-5ec2d86ce02a.png)

![b](https://cloud.githubusercontent.com/assets/4961958/16636088/c6882ff8-438a-11e6-8a2a-da54d26d696e.png)

![c](https://cloud.githubusercontent.com/assets/4961958/16636079/b413a974-438a-11e6-8a25-e6dca2879ab4.png)
 The PDF 1.7 specification suggests using a left-to-right transformation matrix (Tm) while giving each character a negative width. A very crude experiment along these lines give good results with
 Adobe Reader. But messes up cosmetic highlighting in Chrome and copy-paste is wrong with Evince. Please note that font metrics are inconsistent in this experiment.

```
In writing systems that are read from right to left (such as Arabic or Hebrew), 
one might expect that the glyphs in a font would have their origins at the lower right
and their widths (rightward horizontal displacements) specified as negative. 
[ .. then continues into a horrendous discussion of writing everything backwards ... ]

```

``` c++
--- tesseract/api/pdfrenderer.cpp   2016-07-06 13:19:57.000000000 -0700
+++ tesseract/api/pdfrenderer.cpp   2016-07-06 15:35:12.000000000 -0700
@@ -246,6 +246,7 @@
 void AffineMatrix(int writing_direction,
                   int line_x1, int line_y1, int line_x2, int line_y2,
                   double *a, double *b, double *c, double *d) {
+  writing_direction = WRITING_DIRECTION_LEFT_TO_RIGHT;
   double theta = atan2(static_cast<double>(line_y1 - line_y2),
                        static_cast<double>(line_x2 - line_x1));
   *a = cos(theta);
@@ -527,7 +528,7 @@
                "endobj\n",
                5L,         // CIDToGIDMap
                7L,         // Font descriptor
-               1000 / kCharWidth);
+               - 1000 / kCharWidth);
   if (n >= sizeof(buf)) return false;
   AppendPDFObject(buf);
```

Chrome is unhappy
![f](https://cloud.githubusercontent.com/assets/4961958/16636993/8c713a02-4390-11e6-8e44-a89338f24df6.png)

[heb.pdf](https://github.com/tesseract-ocr/tesseract/files/351045/heb.pdf)
 @jbreiden
The PDF 1.7 spec refer to:

> Unicode Standard Annex #9, The Bidirectional Algorithm, Version **4.0.0**

http://www.unicode.org/reports/tr9/tr9-11.html

Support for RLI and PDI has been added in Unicode **6.3**.
http://www.unicode.org/reports/tr9/tr9-29.html
 I tried the other control characters U+202b RIGHT-TO-LEFT EMBEDDING and U+202e RIGHT-TO-LEFT OVERRIDE. Even when sprinkled all over the place, neither had any effect with Adobe Reader 9. We still get incorrect copy-paste.

``` c++
--- tesseract/api/pdfrenderer.cpp   2016-07-06 13:19:57.000000000 -0700
+++ tesseract/api/pdfrenderer.cpp   2016-07-07 10:55:41.000000000 -0700
@@ -410,6 +410,9 @@
     bool last_word_in_block = res_it->IsAtFinalElement(RIL_BLOCK, RIL_WORD);
     STRING pdf_word("");
     int pdf_word_len = 0;
+    pdf_word += "<202E>";
+    pdf_word_len++;
     do {
       const char *grapheme = res_it->GetUTF8Text(RIL_SYMBOL);
       if (grapheme && grapheme[0] != '\0') {

```

[heb.pdf](https://github.com/tesseract-ocr/tesseract/files/352783/heb.pdf)
 Filed feature request with Adobe to recognize -1 0 0 1 X Y Tm. No idea if they will consider it.
 Hi @Shreeshrii! 

Let's see...

 #169
This is not Arabic specific issue, but an RTL issue. The reported issue was solved.

#212
A question, not an issue.

#238
PDF issue related to RTL. Not Arabic specific issue.

#294
'Moved' to [tesseract-ocr/langdata issues reports](https://github.com/tesseract-ocr/langdata/issues/26).

#302
Seems to be solved.

#325
Original issue was solved.

#361
A broad complaint about bad RTL support.

#410
Not Arabic specific. Can't be solved.

As said before, once the new LSTM code will finally land in Tesseract's public Github repo, the OCR accuracy of Arabic and Persian will be [dramatically improved](https://github.com/tesseract-ocr/docs/blob/master/das_tutorial2016/7Building%20a%20Multi-Lingual%20OCR%20Engine.pdf). Cube's code will be removed, so any issue with it will be irrelevant.

My conclusion: #238 is the only one in the list we should monitor. 

The big question left is when we will see Tesseract 4.0 code. Unfortunately, Ray does not yet share any planned date with the Tesseract community :(
 Ray shared that he would like to have public alpha version by the end of September.
 @stweil,

> we'll give it a try...

'We'? The @UB-Mannheim team I guess... :)
 I'm currently in discussion with some Adobe folks about this topic.
 Okay, this bug has been open forever. As mentioned before, most PDF files deal with right-to-left (RTL) languages like Hebrew and Arabic by laying out the characters from left-to-right (LTR) but doing it backwards. This offends my programming sensibilities on many levels, and I've resisted this approach. But maybe it is time to swallow pride and wallow in the mud.  Here's a few examples from the test suite. How  is compatibility for search and copy-paste?

Arabic
[ara.pdf](https://github.com/tesseract-ocr/tesseract/files/947818/ara.pdf)

Single word Hebrew
[simplest.pdf](https://github.com/tesseract-ocr/tesseract/files/947819/simplest.pdf)

Hebrew + English
[heb_mivne.pdf](https://github.com/tesseract-ocr/tesseract/files/947854/heb_mivne.pdf)

Hebrew + English, tilted
[heb-tilt.pdf](https://github.com/tesseract-ocr/tesseract/files/947848/heb-tilt.pdf)

English (should be no change from what we do now)
[2.pdf](https://github.com/tesseract-ocr/tesseract/files/947838/2.pdf)

```c++
--- tesseract/api/pdfrenderer.cpp	2017-03-31 14:35:03.000000000 -0700
+++ tesseract/api/pdfrenderer.cpp	2017-04-21 10:16:23.000000000 -0700
@@ -225,14 +225,10 @@
 // left-to-right no matter what the reading order is. We need the
 // word baseline in reading order, so we do that conversion here. Returns
 // the word's baseline origin and length.
-void GetWordBaseline(int writing_direction, int ppi, int height,
+void GetWordBaseline(int ppi, int height,
                      int word_x1, int word_y1, int word_x2, int word_y2,
                      int line_x1, int line_y1, int line_x2, int line_y2,
                      double *x0, double *y0, double *length) {
-  if (writing_direction == WRITING_DIRECTION_RIGHT_TO_LEFT) {
-    Swap(&word_x1, &word_x2);
-    Swap(&word_y1, &word_y2);
-  }
   double word_length;
   double x, y;
   {
@@ -260,15 +256,12 @@
 }
 
 // Compute coefficients for an affine matrix describing the rotation
-// of the text. If the text is right-to-left such as Arabic or Hebrew,
-// we reflect over the Y-axis. This matrix will set the coordinate
+// of the text. This matrix will set the coordinate
 // system for placing text in the PDF file.
 //
-//                           RTL
-// [ x' ] = [ a b ][ x ] = [-1 0 ] [ cos sin ][ x ]
-// [ y' ]   [ c d ][ y ]   [ 0 1 ] [-sin cos ][ y ]
-void AffineMatrix(int writing_direction,
-                  int line_x1, int line_y1, int line_x2, int line_y2,
+// [ x' ] = [ a b ][ x ] = [ cos sin ][ x ]
+// [ y' ]   [ c d ][ y ]   [-sin cos ][ y ]
+void AffineMatrix(int line_x1, int line_y1, int line_x2, int line_y2,
                   double *a, double *b, double *c, double *d) {
   double theta = atan2(static_cast<double>(line_y1 - line_y2),
                        static_cast<double>(line_x2 - line_x1));
@@ -276,17 +269,6 @@
   *b = sin(theta);
   *c = -sin(theta);
   *d = cos(theta);
-  switch(writing_direction) {
-    case WRITING_DIRECTION_RIGHT_TO_LEFT:
-      *a = -*a;
-      *b = -*b;
-      break;
-    case WRITING_DIRECTION_TOP_TO_BOTTOM:
-      // TODO(jbreiden) Consider using the vertical PDF writing mode.
-      break;
-    default:
-      break;
-  }
 }
 
 // There are some really awkward PDF viewers in the wild, such as
@@ -407,15 +389,14 @@
     {
       int word_x1, word_y1, word_x2, word_y2;
       res_it->Baseline(RIL_WORD, &word_x1, &word_y1, &word_x2, &word_y2);
-      GetWordBaseline(writing_direction, ppi, height,
+      GetWordBaseline(ppi, height,
                       word_x1, word_y1, word_x2, word_y2,
                       line_x1, line_y1, line_x2, line_y2,
                       &x, &y, &word_length);
     }
 
     if (writing_direction != old_writing_direction || new_block) {
-      AffineMatrix(writing_direction,
-                   line_x1, line_y1, line_x2, line_y2, &a, &b, &c, &d);
+      AffineMatrix(line_x1, line_y1, line_x2, line_y2, &a, &b, &c, &d);
       pdf_str.add_str_double(" ", prec(a));  // . This affine matrix
       pdf_str.add_str_double(" ", prec(b));  // . sets the coordinate
       pdf_str.add_str_double(" ", prec(c));  // . system for all
@@ -459,23 +440,34 @@
     bool last_word_in_block = res_it->IsAtFinalElement(RIL_BLOCK, RIL_WORD);
     STRING pdf_word("");
     int pdf_word_len = 0;
+    GenericVector<int> unicodes;
+
+    // Gather up unicode codepoints for the word
     do {
       const char *grapheme = res_it->GetUTF8Text(RIL_SYMBOL);
       if (grapheme && grapheme[0] != '\0') {
-        GenericVector<int> unicodes;
         UNICHAR::UTF8ToUnicode(grapheme, &unicodes);
-        char utf16[kMaxBytesPerCodepoint];
-        for (int i = 0; i < unicodes.length(); i++) {
-          int code = unicodes[i];
-          if (CodepointToUtf16be(code, utf16)) {
-            pdf_word += utf16;
-            pdf_word_len++;
-          }
-        }
       }
       delete []grapheme;
       res_it->Next(RIL_SYMBOL);
     } while (!res_it->Empty(RIL_BLOCK) && !res_it->IsAtBeginningOf(RIL_WORD));
+
+
+    // Use primitive "write it backwards" approach for RTL languages
+    if (writing_direction == WRITING_DIRECTION_RIGHT_TO_LEFT) {
+      unicodes.reverse();
+    }
+
+    // Write out the word the way PDF likes it
+    char utf16[kMaxBytesPerCodepoint];
+    for (int i = 0; i < unicodes.length(); i++) {
+      int codepoint = unicodes[i];
+      if (CodepointToUtf16be(codepoint, utf16)) {
+        pdf_word += utf16;
+        pdf_word_len++;
+      }
+    }
+
     if (word_length > 0 && pdf_word_len > 0 && fontsize > 0) {
       double h_stretch =
           kCharWidth * prec(100.0 * word_length / (fontsize * pdf_word_len));

``` So far, just Pdfium/Chrome/Linux   AdobeReader9/Linux  Preivew/MacOSX.  I've asked a few different groups of people to take a look. @christophered Can you please take a look at ara.pdf above and tell me if it works well for you? @christophered Thanks, that's a very helpful report. I expect it to be equal to or better than what Tesseact does now for producing PDF of Arabic.  Note that my change is just about PDF generation and does not touch the recognization process in any way. It is just stock Tesseract 4.0  support for Arabic.

What Tesseract does right now:
[control.pdf](https://github.com/tesseract-ocr/tesseract/files/953433/control.pdf) 


 Thank you for the reports, and sorry for any and all confusion. I'm going to post what Tesseract does right now (CONTROL) and also repost the proposed modification (EXPERIMENT). I am especially interested in regressions, anywhere EXPERIMENT does worse than CONTROL.

CONTROL
[2.pdf](https://github.com/tesseract-ocr/tesseract/files/956615/2.pdf)
[ara.pdf](https://github.com/tesseract-ocr/tesseract/files/956613/ara.pdf)
[heb_mivne.pdf](https://github.com/tesseract-ocr/tesseract/files/956614/heb_mivne.pdf)
[heb-tilt.pdf](https://github.com/tesseract-ocr/tesseract/files/956612/heb-tilt.pdf)
[simplest.pdf](https://github.com/tesseract-ocr/tesseract/files/956616/simplest.pdf)


EXPERIMENT  (repost)
[2.pdf](https://github.com/tesseract-ocr/tesseract/files/956604/2.pdf)
[ara.pdf](https://github.com/tesseract-ocr/tesseract/files/956605/ara.pdf)
[heb_mivne.pdf](https://github.com/tesseract-ocr/tesseract/files/956606/heb_mivne.pdf)
[heb-tilt.pdf](https://github.com/tesseract-ocr/tesseract/files/956608/heb-tilt.pdf)
[simplest.pdf](https://github.com/tesseract-ocr/tesseract/files/956607/simplest.pdf)
 Looking at this again. Slowly losing the remainder of my sanity.  Please use tesseract forum for asking questions/support - see [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice).
  Please use tesseract forum for asking support - see [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice).
  Seems like yet another OpenCL bug report...

Try this:
`TESSERACT_OPENCL_DEVICE=1 tesseract 11002612_2_0183.jpg 11002612_2_0183 -l ara+fra`
 I suggest changing the title so it will contain the word "Arabic" or "ara".

There were several reports in the past about problems when using Arabic+other lang.
Here is a commit that claims to fix them: 2f197cd6

> Fixed issues 899/1220/1246 (mixed eng+ara)

In general, Arabic uses a special engine called 'Cube', most other languages use another engine.
Cube code is considered obsolete. There is a plan to drop it and replace it with another engine (based on LSTM). It might happen this year.
 Hi @anupamaray !

Please read this:
https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md

Try asking your question in the [users mailing-list](https://groups.google.com/d/forum/tesseract-ocr)
 This is still an issue: it crashes with `--oem 0` or `--oem 2`:

    tesseract /tmp/11002612_2_0183.jpg /tmp/11002612_2_0183 -l ara+fra --oem 0
    Found AVX
    Found SSE
    [DS] Profile read from file (tesseract_opencl_profile_devices.dat).
    [DS] Device[1] 1:Intel(R) HD Graphics IvyBridge M GT2 score is 1.229392
    [DS] Device[2] 0:(null) score is 1.146125
    [DS] Selected Device[2]: "(null)" (Native)
    tessdata_manager.SeekToStart(TESSDATA_INTTEMP):Error:Assert failed:in file classify/adaptmatch.cpp, line 537
    Speicherzugriffsfehler

The crash is obviously unrelated to OpenCL, as it crashed here without using OpenCL. It was also sufficient to specify `-l ara` in my test. Last time we talked Ray said he was leaning toward deletion of the non-LSTM
recognizer.
 ```
C:\Users\vvkum\test>tesseract sepia.jpg sepia --psm 6 -l fra+ara
Tesseract Open Source OCR Engine v3.05.01 with Leptonica
Warning. Invalid resolution 0 dpi. Using 70 instead.
no best words!!

C:\Users\vvkum\test>tesseract sepia.jpg sepia --psm 6 --oem 0 -l fra+ara
tessdata_manager.SeekToStart(TESSDATA_INTTEMP):Error:Assert failed:in file ../../../../classify/adaptmatch.cpp, line 537

C:\Users\vvkum\test>tesseract sepia.jpg sepia --psm 6 --oem 1 -l fra+ara
Tesseract Open Source OCR Engine v3.05.01 with Leptonica
Warning. Invalid resolution 0 dpi. Using 70 instead.
```

Problem still there in 3.05.01

Arabic can be used ONLY in --oem 1 mode (cube in 3.05). 

Combined language mode tries to apply same --oem to both languages. So, if using Arabic as one of the languages, need to use --oem 1.

However, what would be the result if the second language does have --oem 1 option.  First of all: Please use tesseract forum for asking support - see [FAQ](https://github.com/tesseract-
ocr/tesseract/wiki/FAQ#rules-and-advice)
Next PIX is leptonica structure - you can get it with leptonica.pixRead(filename)
  https://groups.google.com/forum/?hl=en#!topic/tesseract-dev/LMo_igM4z90
 Getting back to this now that I (might?) have clearance to make direct libtiff calls. 
First, I see that Ray did not merge my patch above into the github repo. We need to 
get that done before I fix the speed problem with multipage TIFF
 Proof of concept for a future Leptonica interface that would get us down to linear seeks. This evolved from the conversation in bug #367 

``` c
#include <stdio.h>
#include <tiffio.h>

const char *testfile = "test.tiff";

size_t PrimeThePump() {
  TIFF *tiff = TIFFOpen(testfile, "r");
  TIFFSetDirectory(tiff, 0);
  size_t offset = TIFFCurrentDirOffset(tiff);
  TIFFClose(tiff);
  return offset;
}

size_t ThankYouSirMayIHaveAnother(size_t offset) {
  TIFF *tiff = TIFFOpen(testfile, "r");
  TIFFSetSubDirectory(tiff, offset);
  TIFFReadDirectory(tiff);
  offset = TIFFCurrentDirOffset(tiff);
  TIFFClose(tiff);
  return offset;
}

int main(void) {
  size_t offset = PrimeThePump();
  while (offset = ThankYouSirMayIHaveAnother(offset)) {
    printf("offset=%lu\n", offset);
  }
}
```
 This patch reduces  multipage TIFF seeks from O(n^3) to O(n), but requires the not-yet-released Leptonica 1.74. The patch disables the OpenCL accelerated TIFF codec. I'm confident that I could make OpenCL path work with some effort, but it is hard for me to test and I don't know how active and important Tesseract + OpenCL is these days.

``` diff
--- tesseract/api/baseapi.cpp   2016-05-24 15:32:21.000000000 -0700
+++ tesseract/api/baseapi.cpp   2016-09-13 09:21:41.000000000 -0700
@@ -1025,26 +1025,14 @@
                                             int tessedit_page_number) {
 #ifndef ANDROID_BUILD
   Pix *pix = NULL;
-#ifdef USE_OPENCL
-  OpenclDevice od;
-#endif
   int page = (tessedit_page_number >= 0) ? tessedit_page_number : 0;
+  size_t offset = 0;
   for (; ; ++page) {
     if (tessedit_page_number >= 0)
       page = tessedit_page_number;
-#ifdef USE_OPENCL
-    if ( od.selectedDeviceIsOpenCL() ) {
       pix = (data) ?
-          od.pixReadMemTiffCl(data, size, page) :
-          od.pixReadTiffCl(filename, page);
-    } else {
-#endif
-      pix = (data) ?
-          pixReadMemTiff(data, size, page) :
-          pixReadTiff(filename, page);
-#ifdef USE_OPENCL
-    }
-#endif
+          pixReadMemFromMultipageTiff(data, size, &offset) :
+          pixReadFromMultipageTiff(filename, &offset);
     if (pix == NULL) break;
     tprintf("Page %d\n", page + 1);
     char page_str[kMaxIntSize];
@@ -1055,6 +1043,7 @@
     pixDestroy(&pix);
     if (!r) return false;
     if (tessedit_page_number >= 0) break;
+    if (!offset) break;
   }
   return true;
 #else
--- tesseract/classify/mastertrainer.cpp    2016-05-18 14:18:32.000000000 -0700
+++ tesseract/classify/mastertrainer.cpp    2016-09-13 09:30:11.000000000 -0700
@@ -214,10 +214,14 @@
 // Must be called after ReadTrainingSamples, as the current number of images
 // is used as an offset for page numbers in the samples.
 void MasterTrainer::LoadPageImages(const char* filename) {
+  size_t offset = 0;
   int page;
   Pix* pix;
-  for (page = 0; (pix = pixReadTiff(filename, page)) != NULL; ++page) {
+  for (page = 0; ; page++) {
+    pix = pixReadFromMultipageTiff(filename, &offset);
+    if (!pix) break;
     page_images_.push_back(pix);
+    if (!offset) break;
   }
   tprintf("Loaded %d page images from %s\n", page, filename);
 }
```
 Then lets wait for new leptonica release. IMO it would be fine to fix OpenCL too - I got promises that somebody should have a look at opencl issues...
 patch from 2016-03-29 committed as 54fafc4e2e9e2941b643f6cef67a7ec7e0b8bb49 
 @DanBloomberg : Is there any plan for leptonica 1.74 release? I use git version of leptonica. I just want to know when we will solve this issue. Tesseract master is now broken with master leptonica because of changed function(s) in lept's `pageseg.c`.
Because of it I switched cppan windows CI build from master to 1.73. I think no. It's better to fix tesseract code.

---

@zdenop If you'd like to fix tess code, you could use CPPAN. To change leptonica dependency from `1.73` to `master`, fix it on the line https://github.com/tesseract-ocr/tesseract/blob/master/cppan.yml#L137
After this when you compile tesseract with cmake, the build will fail. Future tess. release could use lept 1.74. It will be released soon.
We just need administrative decision: e.g. "Let's fixate on lept1.74 for the time being". Yes, this seems to be ABI breakage. Both tesseract and leptonica do not use semver (X.Y.Z), but use (X.Y), so personally I'm confused. With semver ABI breakage only allowed when increasing X number. So, e.g. leptonica should be versioned as 2.00 or whatever (2.0.0?). It's ok now. master tess + lept work fine. @DanBloomberg: When leptonica 1.74 will be released? Also added to cppan.
https://cppan.org/pvt.cppan.demo.danbloomberg.leptonica/versions

We could stick now to 1.74.0 to prevent possible abi breakages.  See what I wrote about a new ocr engine in #212.
 1. Langdata/tessdata issues should be reported at relevant part of project (https://github.com/tesseract-ocr/tessdata/issues or https://github.com/tesseract-ocr/langdata/issues)
2. Issue tracker should be used for reporting issues and not for asking questions.
 @roozgar

Proposal for Tutorial on Tesseract at DAS2016
http://www.primaresearch.org/das2016/assets/DAS2016_Tutorial_Tesseract.pdf
  There is a config parameter for that purpose: `tessedit_char_whitelist`.

Next time, please use the forum to ask questions about this software.
https://groups.google.com/d/forum/tesseract-ocr
  Tom,
I suggest changing `ltr` to `para_is_ltr`, to make the code more clear.
  > Please make sure the TESSDATA_PREFIX environment variable is set to the **parent directory** of your "tessdata" directory.

So, if your `tessdata` dir is in the `/usr/share/tesseract-ocr` dir, `TESSDATA_PREFIX` should be set to `/usr/share/tesseract-ocr`.
 Also, as @stweil said elsewhere: 

> Setting TESSDATA_PREFIX is not needed as long as your tessdata directory is at the right place ($PREFIX/share/tessdata).
 Also read this:

UNIX export command
http://stackoverflow.com/a/7328289
 @teo1978: well it could be the same story, because config files has to be with expected directory structure in TESSDATA_PREFIX...
 ... so digits file should be in $TESSDATA_PREFIX/tessdata/configs
  Did someone test that there is no regression in pdf output with Adobe Acrobat
and Chromium?
 Okay, but I think you should also test this with an image that has more than two words...
  See #212.
 1. Langdata/tessdata  issues should be reported at relevant part of project (https://github.com/tesseract-ocr/tessdata/issues or https://github.com/tesseract-ocr/langdata/issues)
2. Issue tracker should be used for reporting issues and not for asking questions.
  Try to follow wiki [1] 
Note: This wiki expects you to be familiar with compiling software on your operation system.[1]
https://github.com/tesseract-ocr/tesseract/wiki/Compiling
  @teo1978: this is standard autotools error message. You will get it for all libraries. ./configure is tool not a teacher. Name of needed package could be different base on distribution.

If you are not familiar with compiling software on your operation system it is not tesseract problem.
  > Audiveris is developed in Java, and invokes Google Tesseract (C++) for text OCR.

Tesseract is not used for recognizing the musical notations. Sheet music (songs) also include ordinary text. Tesseract OCR is used for that song text (or any other text like headers, page counts, name of composer, ...).  @lisaied

> Do you have a plan to update Arabic Language files in the coming releases.

There is a plan to add a new ocr engine to tesseract this year. There is a good chance that the accuracy of arabic and indic languages recognition will be improved. 
  ~~From #83, @zdenko's quote:~~

> ~~If you run:
> `tesseract OCR.tif ORIGINAL pdf`
> than ORIGINAL.tif is included in ORIGINAL.pdf WITHOUT any modification.~~
 should be readed as: OCR.tif is included in ORIGINAL.pdf WITHOUT any modification. ;-)
And OCR is run on OCR.tif
IMO dhendrix what something else - he want to run OCR on image_b (improved for OCR), but include image_a (original) to pdf...
 Maybe this tool could help.
 https://github.com/tmbdev/hocr-tools/blob/master/hocr-pdf
  Leptonica can be built on windows. But by default it is built without any image libraries (i.e. cannot load/save images). So, no png,gif,tiff,... functions available.
In such mode tesseract will only handle raw image input from api, not from any exe calls.
 Try these binaries compiled by me.
https://www.dropbox.com/s/8t54mz39i58qslh/tesseract-3.05.00dev-win32-vc19.zip?dl=1
You have to install VC2015 x86 redist from microsoft.com in order to run them.
Leptonica is built with all libs except for libjp2k.
 > Also I would like to downoad different versions (2.x, 3.x) to see if any of them works.

http://sourceforge.net/projects/tesseract-ocr-alt/files/
 @bantilan: please add it https://github.com/tesseract-ocr/tesseract/wiki/Compiling#windows (every github used can modify it)
 It's a bad guide. Do not add it anywhere.
1. Windows binaries should be made with MSVC, not cygwin. Why do you install Visual Studio and do not use it? You use only cygwin stuff. Which won't run if you distribute it without cygwin.
2. https://github.com/egorpugin/leptonica.git is not correct leptonica repository anymore. Use official https://github.com/DanBloomberg/leptonica/releases 1.73+ release.
 I uploaded my local branch with almost all leptonica's deps sources to https://github.com/egorpugin/leptonica/tree/with_libs. You can find them in /dep. Most of those were taken from opencv distribution. They can be somewhere misconfigured etc. Also that branch is following master branch of leptonica, so probably it's not so stable as release.
When you build this leptonica branch, result library will support many image libraries, therefore tesseract does too when linked with it.
 No, I can't.
That's the single binary that cannot be easily built with MSVC.
 They are from master branch. Probably on this commit ec44221e336dd9
 @egorpugin, can you confirm this? 
 Did not run tests on my binaries, so it's possible.
 @nickbe, one more (unofficial) option for Windows:
~~https://github.com/UB-Mannheim/tesseract~~
https://github.com/UB-Mannheim/tesseract/wiki
 Yeah. For some reason I omitted the 'wiki' part from the link.
 What is this business about certain builds not supporting PDF output? There is nothing special or weird with that section of code. Are they just old builds from before the feature was created, or is there something else going on?
 Is there a simple command to check pdf generation?
I'll try to debug the issue (if any).
 The discussion about the PDF issue in egor's build should be continued in #338
 Hi!

I'd like to share one more way of building tesseract(+leptonica+other_image_libraries) on Windows. Linux probably will work too.
1. Download and install Git, CMake and put them in PATH.
2. Download the latest CPPAN (C++ Archive Network https://cppan.org/) client from https://cppan.org/client/. CPPAN is a source package distribution system. (Like biicode or conan but for sources. Also the idea came from CPAN/CTAN/CRAN.) Add CPPAN client in PATH too. (VS2015 redist is required.)
3. Run

```
git clone https://github.com/tesseract-ocr/tesseract tesseract
cd tesseract
cppan
mkdir build && cd build
cmake .. -DSTATIC=1
```
1. Build a solution in VS tesseract.sln

So, the build should be pretty straightforward and available for everyone with installed Visual Studio. You can try it on any version supported by tesseract.

If you like the way of building tesseract with CPPAN, I could implement such easy way of integration of tesseract into user (your) apps.

Sorry for the noise.
 @egorpugin: thanks! I tried it in VS2010 and I face one problem: 
this version of giflib can not be built by VS2010 (Cannot open include file: 'stdbool.h': No such file or directory). Is it possible to make it optionable (to ignore gif library) or to use other version of library (older 4.? was possible to build with VS2010)?
 During normal workflow this is not possible.

Because of the following:
tesseract is binded to leptonica (some version, e.g. future 1.74);
leptonica is binded to giflib (e.g. v5.1.2).

So you cannot control leptonica's dependencies.
And you must use appropriate and supported compilers of these libraries to compile your project.
Now you'd like to use an older version of giflib. The idea is clear, I understand this, you want to work on older compiler. But using old version of libraries can bring (and it does) potential security breaches.

But now  it's possible to introduce some changes to **demo** giflib itself. I've added some ifdefs to control usage of stdbool.h, so you can check if it works. Just re-run cppan command in tesseract dir and try to build a VS solution.
 Usually it means that you don't have a letsencrypt certificate installed on your system (old ubuntu etc.). I've added an option ('-k' or '--ignore-ssl-checks') to skip strict ssl checks. Please, re-download the client and run 'cppan -k'. For more info see 'cppan -h'. On windows you can upgrade the client with 'cppan --self-upgrade' (only if this option is available, check 'cppan -h').
 FYI I've added simple guide on how to build tesseract on Windows https://github.com/tesseract-ocr/tesseract/wiki/Compiling#master-branch-305-and-later
Also the simple user app example with tesseract (using cmake+cppan) is available here https://github.com/tesseract-ocr/tesseract/wiki/User-App-Example
https://github.com/cppan/tesseract_example
  For asking support please use the tesseract-ocr user forum (https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice)
  You try to run opencv project, that needs leptonica and you are putting issue to tesseract???
 You wrote: "but when i build opencv project" Or???
Leptonica is external dependency - you need to build it by yourself (and maybe adjust paths according you directory structure). You need to use 1.71 or latter version.
There are several tutorials how to build tesseract from source. Just use google...
  http://sourceforge.net/projects/tesseract-ocr-alt/files/
  ![i202-2](https://cloud.githubusercontent.com/assets/13571208/13125654/71d344e4-d5cf-11e5-9f4b-497087b65507.png)

`tesseract i202-2.png i202-2`
=>
[i202-2.txt](https://github.com/tesseract-ocr/tesseract/files/135210/i202-2.txt)
(garbage)

The font in this image is too degraded and probably too different from the trained data. 
 I'm closing this because as I said, there is a good reason why Tesseract failed in this specific case, so I don't think there is a bug here.
  https://github.com/tesseract-ocr/tesseract/wiki/FAQ#actual_tessdata_num_entries_-tessdata_num_entrieserrorassert-failedin-file-ccutiltessdatamanagercpp-line-55_
  @stweil, you have a typo in the above comment. Where can I send a PR?
:-)
  Maybe you can start with some reading: https://github.com/tesseract-ocr/tesseract/wiki/Compiling#windows
  Can you test this with d4e0c645 ?
I want to know if the crash is not triggered by my commits. I did tests on a pc with linux. I don't have a mac. 
 Please try to run:

> tesseract eng.DejaVuSerif.exp0.tif eng.DejaVuSerif.exp0 box.train

Use the attached files
[i196.zip](https://github.com/tesseract-ocr/tesseract/files/100745/i196.zip)
 I think your patch in #195 is the cause of the problem here.

Here is the text file I used to generate the tif-box files:
https://raw.githubusercontent.com/tesseract-ocr/langdata/master/eng/eng.training_text

> text2image --text=eng.training_text --outputbase=eng.DejaVuSerif.exp0 --font='DejaVu Serif' --fonts_dir=/usr/share/fonts/truetype
 @LinusU: is the issue solved?
 Closing due to lack of response from OP.
  First thing - remove your patch.

Now, run this:

> text2image --list_available_fonts --fonts_dir=/Library/Fonts

Do you get a list of fonts? If the answer is 'yes', then proceed.

Use this file:
https://raw.githubusercontent.com/tesseract-ocr/langdata/master/eng/eng.training_text

> text2image --text=eng.training_text --outputbase=eng.MenloRegular.exp0 --font='Menlo Regular' --fonts_dir=/Library/Fonts

If this doesn't work try with other fonts, but only regular ones, not bold/italic/medium.

If this doesn't work either, download and install the DejaVu fonts.
 Also, please provide any error message you get.
 http://ryanfb.github.io/etc/2014/11/19/installing_tesseract_training_tools_on_mac_os_x.html

> Note that fontconfig font locations and caching are a whole other nightmare, and I seem unable to get text2image to respect/use the --fonts_dir argument on OS X. Your best bet seems to be to install things as system/user fonts (e.g. copy into ~/Library/Fonts) and optionally run fc-cache -frv to force a cache update.

A note for @ryanfb:
    `text2image --list_available_fonts`
Running this command on Ubuntu 14.04 does not produce any output, but running this one does:
    `text2image --list_available_fonts  --fonts_dir=`

cc: @behdad
Behdad, maybe you can help here?
 @ryanfb, did you tried running `tesstrain.sh` on mac?
Maybe it has some tricks that make text2image actually work on mac.
 @LinusU ?
 @jbarlow83, anyone with a mac...
Could you help test and debug this issue?
 HI @atuyosi! 

I don't have 'DejaVu Sans Thin' in my ubuntu system. I have 'DejaVu Sans'.

Please copy the output of
`text2image --list_available_fonts --fonts_dir=/Library/Fonts`
to a new file 'fontlist.txt' and attach this file here. I want to find a font we both have.  
 Please try:
`text2image --text=eng.training_text --outputbase=eng.TimesNewRomanBold.exp0 --font='Times New Roman, Bold' --fonts_dir=/Library/Fonts`
 Another test...

[eng.training.txt](https://github.com/tesseract-ocr/tesseract/files/138769/eng.training.txt)

```
text2image --text=eng.training.txt --outputbase=eng.TimesNewRomanBold.exp0 --font='Times New Roman, Bold' --fonts_dir=/Library/Fonts --tlog_level=3
```
 Could someone with a Mac retest this with the latest commit in the repo?
 @atuyosi, thanks for testing. The output files look okay.
The issue seems to be solved.
  [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice): For general questions and support please use the tesseract-ocr user forum
  @diotteo
This info is indeed outdated. I removed it from that page.

Thanks for reporting.
 Maybe instead of deleting the paragraph it's better to edit it;

> For versions prior to 3.02, any language that has different punctuation and numbers is going to be disadvantaged by some of the hard-coded algorithms that assume ASCII punctuation and digits.
 @zdenop, any preference?
 I edited it again;

> For versions 3.00/3.01, any language that has different punctuation and numbers is going to be disadvantaged by some of the hard-coded algorithms that assume ASCII punctuation and digits. [Fixed in 3.02]
  @egorpugin Can you have a look on this?
 What headers should be public?
I thought all headers from api/

Tesseract really has bad directories structure.
Probably it should be reorganized as in many other projects.
include - public includes
src/[subdirs] - dir with sources and private headers
 At least headers that are mentioned in "include_HEADERS" in Makefile.am should be installed/public.
Each directory has its own Makefile.am...
 While using tesseract with TesseractConfig.cmake (without install), we can include several directories.
So, unintentionally we will give an access to all headers from those dirs. Not only to "include_HEADERS".
Users won't know it and could use noinst headers, so later they'll have issues.
 Fixed in 7b94871ba20
  @ryanfb, FYI

If you close a PR and then reopen it later the tests will rerun.
No need to duplicate a PR.
  All tests failed because @egorpugin made changes in his leptonica repo.

~~https://github.com/egorpugin/leptonica
is empty right now.~~

~~The links in the tests should be updated to:
https://github.com/egorpugin/leptonica_old~~
 Keep calm. We're setting an official leptonica repository this time.
 Ok, you can try to recreate this PR. It should pass CI checks. We'll modify scripts lates, but egorpugin/leptonica is available again.
  hocr2pdf's issues should be reported to hocr2pdf's developers.
  Please use [Tesseract users forum](https://groups.google.com/d/forum/tesseract-ocr) for support.
  I will check this next week.
  See #170.
 Chromium's pdf reader output (cut&paste):

[182-chromium.txt](https://github.com/tesseract-ocr/tesseract/files/115576/182-chromium.txt)
 I run Tesseract (latest commit from the repo) with your jpg image. 

> tesseract i182.jpg i182 -l eng txt pdf hocr

Evince's output (cut&paste):

[182-evince.txt](https://github.com/tesseract-ocr/tesseract/files/115584/182-evince.txt)

Evince is based on Poppler.
 Here are the output files...

[i182.pdf](https://github.com/tesseract-ocr/tesseract/files/77832/i182.pdf)
[i182.txt](https://github.com/tesseract-ocr/tesseract/files/77833/i182.txt)
[i182-hocr.zip](https://github.com/tesseract-ocr/tesseract/files/77840/i182-hocr.zip)
 Did you see my 2 last comments?
The latest commit from the repo produces better pdf results than version 3.04. 
 My libpopler version is 0.24.5. Ubuntu 14.04.

> pdftotext i182.pdf i182t.txt

Here is the pdftotext output:
[i182t.txt](https://github.com/tesseract-ocr/tesseract/files/77872/i182t.txt)
 cc: @jbreiden
jbreiden wrote Tesseract's pdf renderer code.
 From https://groups.google.com/forum/?hl=en#!topic/tesseract-dev/XllxjvK5HtU

> Jeff Breidenbach   7/17/15
> PROBLEM #2: PDF
> I was looking at a PDF problem report and noticed that Tesseract PDF output
> is no longer validating. (It fails qpdf --check). As the author of the pdf module,
> I'm biased, but producing corrupt data is a disaster and I think we need to cut
> a new release once it is figured out. Most PDF viewers will recover and silently 
> ignore, but this is no good at all. I wonder what happened.
 Try this to output to stdout:

>    pdftotext i182.pdf -

Jeff mentioned qpdf.
Links:
 http://qpdf.sourceforge.net 
https://github.com/qpdf/qpdf
 @behdad, try this:

> pdftotext linn.pdf -
 > There is also an alternative invisible font here, that contains an advanceWidth. I think it can be swapped in for tessdata/pdf.ttf. It has a side effect of making highlighting look even more bizarre in evince.

It looks terrible :(
 If you search for a phrase in evince, the highlighting looks more normal.
Strange!
 This was a short discussion... :-)
  [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice) : If you found a bug - please create an issue: Please make sure you are able to replicate the problem with tesseract executables on Linux or Windows. For other platforms or external/your programs (including tesseract wrappers) please use the tesseract forums.
  ...waiting for review @theraysmith 
 Now we're synced, yes I think that would be a positive change, but it may be something to keep for 4.00 forward, so as to maintain maximum support for old compilers in the last 3.xx version.
(I already put a few experimental uses of nullptr in 4.00 to see if anyone squeals.)
Not being a git expert yet, I assume I can just hit the pull button and 3.xx can still be unaffected right? Yes, just hit button "Merge pull request" if you wan to include it to currect (4.00) code @theraysmith : Is there plan to commit new code that would interfere with this changes?
@stweil : I would wait for the moment ;-) so there is change to fix building of 4.0 (outside of linux). E.g. 1-2 weeks after lstm data files are available. Training is a different kettle of fish to the recognition engine, as the
latter is currently (3.0x) *much* more portable than the training tools.

 I want to see if anyone squeals when they start porting the 4.00
recognition engine to other platforms, although there are likely to be
howls of protests over the other missing ingredients first, like big-endian
support and SIMD extensions.

Although now I mention that, anyone who has a machine old enough to squeal
over C++11 probably doesn't have the horsepower to run 4.00 at a reasonable
speed.

On Thu, Nov 24, 2016 at 10:38 AM, Stefan Weil <notifications@github.com>
wrote:

> I already put a few experimental uses of nullptr in 4.00 to see if anyone
> squeals.
>
> @theraysmith <https://github.com/theraysmith>,
> training/stringrenderer.cpp already uses nullptr for more than two years
> now. AFAIK nobody complained, so that seems to work. Replacing NULL by
> nullptr would be good, but also touches many files, so this could be done
> in the same action as the switch to POSIX data types.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/177#issuecomment-262830314>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056QF3tQJra8WTACr_cvaeVjUG0yP6ks5rBdmWgaJpZM4G6wao>
> .
>



-- 
Ray.
 FYI: This change breaks several tests in the Google repository because the Google int64 is long long and the posix int64_t is just long, and the compiler says they are not compatible.
Of course they shouldn't have used the wrong type to begin with.
I'm hoping that they can be fixed easily enough and it doesn't open a whole can of worms, but I thought you would be interested that it is not as easy as you thought. Yes, the change to POSIX requires some work (not only in your tests), but it will help in the long run – for example as soon as there is a 128 bit architecture with long being int128_t. And it helps a lot as soon as you want to use Tesseract code in other software. There's also `int_least64_t`. http://en.cppreference.com/w/cpp/types/integer  > tesseract issue174.jpeg issue174 -c hocr_font_info=T hocr

This works with the latest commit in the repo.  No segfault.
 @vov4ik829,
~~Ubuntu 14.10 had reached EOL. You should upgrade the distro.~~
  Use tesseract forum for asking help https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice
  The [Downloads](https://github.com/tesseract-ocr/tesseract/wiki/Downloads) wiki page has a link to  [Former project page](https://code.google.com/p/tesseract-ocr/downloads/list) under 'Old Downloads'.
There, you can find Windows installer for tesseract 3.02. There is no **official** Windows installer for later versions.

You can build on Windows the latest version from source.
The wiki has a link to [Releases](https://github.com/tesseract-ocr/tesseract/releases)

Still, the wiki needs to be more clear on this.
 I hope it's clearer now.
https://github.com/tesseract-ocr/tesseract/wiki/Downloads
  Evince's pdf support is based on Poppler.

https://en.wikipedia.org/wiki/Evince#Supported_document_formats
https://en.wikipedia.org/wiki/Poppler_%28software%29
 > Maybe Firefox also uses parts of the Poppler code. 

No.
https://github.com/mozilla/pdf.js
 Chromium uses PDFium:
https://pdfium.googlesource.com/pdfium/
https://news.ycombinator.com/item?id=7781878
http://blog.foxitsoftware.com/foxit-pdf-technology-chosen-for-google-open-source/
https://groups.google.com/forum/#!forum/pdfium
 Poppler homepage
http://poppler.freedesktop.org/

Maybe someone wants to fill a bug report?

> Use [bugzilla](http://bugs.freedesktop.org/) to report bugs or suggest enhancements. The component is `poppler`.

From the [TODO](http://cgit.freedesktop.org/poppler/poppler/tree/TODO):

> - Investigate better (that is, normal) text selection.
 @stweil, what @jbreiden is saying is that some pdf viewers have bugs that make them present skewed text lines incorrectly.
  Hi @christophered,

How did you generate the tif images for training? Did you use the `text2image` tool?

Did you use `set_unicharset_properties`?
https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#set_unicharset_properties-new-in-303

From https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#dictionary-data-optional

> For right-to-left languages (RTL) use option "-r 1".

You can also try to use `tesstrain.sh`
https://github.com/tesseract-ocr/tesseract/wiki/tesstrain.sh

In general, the right place to ask questions like this is here:
http://groups.google.com/group/tesseract-ocr

See also:
https://groups.google.com/forum/#!topic/tesseract-ocr/HdT8V1nFTtY
 Try using this config file:
 https://github.com/tesseract-ocr/langdata/blob/master/ara/ara.config

Remove this line:

> tessedit_ocr_engine_mode 1
 The official trained data uses the 'Cube' engine. There is no documented way to train 'Cube' with other fonts.
 I suppose they have a program for that task...
 Developers from Google.
 Both gimagereader and vietocr have versions which use tesseract 4.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Jun 19, 2017 at 8:07 PM, adinetoiu <notifications@github.com> wrote:

> Do you have a sample project or link that uses tesseract 4?
>
>
> From: chris <notifications@github.com>
> To: tesseract-ocr/tesseract <tesseract@noreply.github.com>
> Cc: adinetoiu <adinetoiu@yahoo.com>; Mention <mention@noreply.github.com>
> Sent: Monday, June 19, 2017 5:14 PM
> Subject: Re: [tesseract-ocr/tesseract] Arabic Language output is reversed
> (#169)
>
> @adinetoiu I suggest that you skip using Tesseract 3.x for Arabic, instead
> use Tesseract 4.
> a binary is also available at http://digi.bib.uni-mannheim.
> de/tesseract/tesseract-ocr-setup-4.00.00dev.exe—
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/169#issuecomment-309459382>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_ozNSJAJOADt4YTvs6TLIAMnHaa7Vks5sFoeSgaJpZM4GzPQj>
> .
>
  See [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice) - use tesseract forum for suppoprt.
  VS 2010 build fails with:
....\ccutil\mainblk.cpp(28): fatal error C1083: Cannot open include file: 'libgen.h': No such file or directory
  I see no error(s) reported here. Is this the full output?

Did you run:

> ./autogen.sh
> ./configure

and then:

> make

?
 Here is my output.

last lines:

```
libtool: link: ranlib .libs/libtesseract.a
libtool: link: rm -fr .libs/libtesseract.lax
libtool: link: ( cd ".libs" && rm -f "libtesseract.la" && ln -s "../libtesseract.la" "libtesseract.la" )
g++ -DHAVE_CONFIG_H -I. -I..  -DNO_CUBE_BUILD -O2 -DNDEBUG -DLOCALEDIR=\"/usr/local/share/locale\" -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../cube -I../viewer -I../textord -I../dict -I../classify -I../ccmain -I../wordrec -I../cutil -I../opencl    -I/usr/local/include/leptonica -pthread -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include   -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng12    -g -O2 -std=c++11 -MT tesseract-tesseractmain.o -MD -MP -MF .deps/tesseract-tesseractmain.Tpo -c -o tesseract-tesseractmain.o `test -f 'tesseractmain.cpp' || echo './'`tesseractmain.cpp
mv -f .deps/tesseract-tesseractmain.Tpo .deps/tesseract-tesseractmain.Po
/bin/bash ../libtool  --tag=CXX   --mode=link g++  -g -O2 -std=c++11   -o tesseract tesseract-tesseractmain.o libtesseract.la   -lrt -llept -lpthread 
libtool: link: g++ -g -O2 -std=c++11 -o .libs/tesseract tesseract-tesseractmain.o  ./.libs/libtesseract.so -lrt -llept -lpthread
make[2]: Leaving directory `/home/amit/ocr/tesseract/tesseract/api'
Making all in .
make[2]: Entering directory `/home/amit/ocr/tesseract/tesseract'
make[2]: Leaving directory `/home/amit/ocr/tesseract/tesseract'
Making all in tessdata
make[2]: Entering directory `/home/amit/ocr/tesseract/tesseract/tessdata'
Making all in configs
make[3]: Entering directory `/home/amit/ocr/tesseract/tesseract/tessdata/configs'
make[3]: Nothing to be done for `all'.
make[3]: Leaving directory `/home/amit/ocr/tesseract/tesseract/tessdata/configs'
Making all in tessconfigs
make[3]: Entering directory `/home/amit/ocr/tesseract/tesseract/tessdata/tessconfigs'
make[3]: Nothing to be done for `all'.
make[3]: Leaving directory `/home/amit/ocr/tesseract/tesseract/tessdata/tessconfigs'
make[3]: Entering directory `/home/amit/ocr/tesseract/tesseract/tessdata'
make[3]: Nothing to be done for `all-am'.
make[3]: Leaving directory `/home/amit/ocr/tesseract/tesseract/tessdata'
make[2]: Leaving directory `/home/amit/ocr/tesseract/tesseract/tessdata'
Making all in doc
make[2]: Entering directory `/home/amit/ocr/tesseract/tesseract/doc'
make[2]: Nothing to be done for `all'.
make[2]: Leaving directory `/home/amit/ocr/tesseract/tesseract/doc'
make[1]: Leaving directory `/home/amit/ocr/tesseract/tesseract'
```
 Without full log of all steps you did this issues does not have sense - there could be plenty of reasons why build failed.
  Which file use unicharambigs file v2?
 I did not find (in langdata repository) language that use v2 of unicharambigs... So I am not sure if it make sense to write docs for it (=> propagate it) if it is not used (=> not tested). 
 I hear something like end of September 2016, but you never know ;-) It will big update (probably we will drop support of compilers nor support c++11)...
  You missed this typo:

> Repository it huge...
 > ... as I am not a native speaker

Me neither! :-)
  @zdenop said in #101:

> Future is cmake. There is no sense to make and maintain build system for each version of cmake. cmake correctly detect installed compiler and use it. We are just waiting for leptonica transfer to github, there cmake will be presented to.

So, this PR should be closed.  
 Use cmake for any Visual studio builds.
  Please make sure not to use the 72dpi screen resolution, which is always too small for Tesseract. Simply resize the screenshot (if you use screenshots) by +400% and repeat your tesseract runs, and please report here, if that solved your problem.

See https://github.com/tesseract-ocr/tesseract/wiki/FAQ#is-there-a-minimum-text-size-it-wont-read-screen-text

Imagemagick "convert":

```
convert -resize "400%" -type Grayscale +compress infile outfile
```
 > 10 pt screen resolution works perfectly for English.

You are mixing between two concepts. Screen resolution is measured  in dpi/ppi. 'pt' (point) is another concept used to express fonts size.
 https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality

For questions, please use [Tesseract users forum](https://groups.google.com/d/forum/tesseract-ocr).
  > All the above mentioned files are however packed in one docx file :smiley: 

Please attach a zip file instead.
 Tesseract layout analysis gets really confused with the 'bad' image.
The main difference between the two images is the black frame around the page margins. If you'll remove the black borders Tesseract will produce a better output.
  --print-parameters is option that list all tesseract parameters with its default values.  This is useful if you would like to change tesseract behavior.
 in case of 'single options': it was not expected (tested) their usage in combination with other options.
 @amitdo: tesseract executable was(is) simple example how to use tesseract library. AFAIK nobody plan to implement smart handling of options (e.g. you still need to provide some information in specific order)... So the correct result of your option combination is side effect... ;-)  See e.g. https://github.com/tesseract-ocr/tesseract/issues/147#issuecomment-155892373
  see [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice):
- For general questions and support please use the tesseract-ocr user forum.
- Read the wiki, search issues (also closed), search in the tesseract forum before you post your issues/question. Maybe it was solved already.
  Here's a tip how to rescale all pages to e.g. DIN A4:
https://github.com/Wikinaut/utils/wiki#scale_all_pages_in_PDF_to_A4
 Resolution (DPI) is extracted from the header of the input image. If missing, then Tesseract has no choice but to make something up. Don't do that! Many tools can be used to inspect and adjust DPI for an input image file. If you want to use ImageMagick, the commands are "identify -verbose" to inspect and "mogrify -density 300x300 -units PixelsPerInch" to set.
  Tesseract executable is simple example how to use tesseract library. There is no intentional make it more complex (just because of parsing arguments and reporting user mistakes)
  see [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice):
- For general questions and support please use the tesseract-ocr user forum.
- Read the wiki, search issues (also closed), search in the tesseract forum before you post your issues/question. Maybe it was solved already.
  I am not sure if this is the right way of dealing with such warning:
- register is [deprecated in C++11](http://en.cppreference.com/w/cpp/language/storage_duration), but it will exists until C++17
- AFAIK it should be possible to build tesseract without support of C++11
  My suggestion is that if solving of warning does not bring any value, it should be ignored...
  i think you need 10 boxes of each commonly occuring letter. and 5 is enough for rarely occuring letters.

also the first number at the unicharset defines what it is and how tesseract handles it. for example all numbers should have 8. and punctuation 10.

. 10 255 0 0 ....
6 8 255 0 0  ...
 https://code.google.com/p/tesseract-ocr/wiki/TrainingTesseract3
 how do you train?
 I have used this from deu_frak model

buildscript.sh:

#!/bin/sh
LANGCODE=deu_frak
for i in _.tif
  do echo $i:
  tesseract $i ${i%.tif} nobatch box.train
done
unicharset_extractor *.box
cat unicharset | sed -e "s/^([æøåäöüâêàèéçß][a-z]_) 0/\1 3/" \
  -e "s/^([ÆØÅÄÖÜÂÊÀÈÉÇ][a-z]_) 0/\1 5/" \
  -e "s/^([«»„”·§—ɔ]) 0/\1 10/" \
  -e "s/^ɔ 3 /ɔ 10 /" \
  -e "s/^½ 0/½ 8/" | sed -e "s/^([æøåäöüâêàèéçßa-zÆØÅÄÖÜÂÊÀÈÉÇA-Z]._) NULL /\1 Latin /" \
  -e "s/^([«»„”·§—ɔ[:punct:][:digit:]]._) NULL /\1 Common /" \
  -e "s/^(&c ._) Common /\1 Latin /" > unicharset.edited
shapeclustering -F font_properties -U unicharset.edited *.tr
mftraining -F font_properties -U unicharset.edited -O $LANGCODE.unicharset *.tr
cntraining *.tr
for i in inttemp normproto pffmtable shapetable
  do mv -f $i $LANGCODE.$i
done
wordlist2dawg number $LANGCODE.number-dawg $LANGCODE.unicharset
wordlist2dawg punc $LANGCODE.punc-dawg $LANGCODE.unicharset
wordlist2dawg word_list $LANGCODE.word-dawg $LANGCODE.unicharset
wordlist2dawg frequency_list $LANGCODE.freq-dawg $LANGCODE.unicharset
combine_tessdata $LANGCODE.
 If you have problems training Tesseract, please use [Tesseract users forum](https://groups.google.com/d/forum/tesseract-ocr) for support.
  479fe9c37055ecf8004f4eeb9bcb8dcc7c1e89c5 still results in these warnings (only warnings are shown):  http://dpaste.com/3DWZ4VP

Created with

```
(git pull)
./autogen.sh
./configure --enable-debug
make &>make.log
agrep -d "^/bin/sh" warning make.log > make-warnings.txt
(uploaded to http://dpaste.com/3DWZ4VP )
```

ProTip: I used agrep: https://github.com/Wikinaut/agrep because the option "-d" allows to define a "record" which is then printed, if if a match within is found (here: "warning").
 @stweil Stefan, hi. I identified some more remaining warnings. See https://github.com/tesseract-ocr/tesseract/issues/138#issue-115242227
 @stweil I informed you, and listed the remaining warnings, because it looked as if you were "hunting" these last (moretheless cosmetic) problems. I really would like to see them disappearing one after the other... :-))
  I don't think it is a good idea to add this to the hocr output. A better alternative is to add new simple text renderer that outputs only info about symbols including 'alt choices' and confidence.
  We do not provide support for tesseract wrappers[1]. Please use tesseract user forum.
[1] https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice
 If you are able to replicate problem with tesseract executable on linux I can try to find reason/solution. Otherwise please use tesseract user forum. There are people that use tesseract in java, so they can provide you support.
  In #129 I reported a configure problem, which stemmed from `g++` being unavailable at that moment on my build system. A test code in configure tried to compile `pixCreate` with `g++` but this failed (because g++ was not there).

Main problem: the output text is misleading ("configure: error: leptonica library missing").

In that case, a special test for presence of g++ should be added **and** the text should better say "g++ (gcc-c++ compiler) not available".

@zdenop pls. let me know, if you want me to add further details. I just wanted to point you to that test, which tests a compilation of `pixCreate`, but this fails only because already the invocation of `g++` fails (not present) - not because missing leptonica code. 
 @arvidj yep. do you, by chance, still have the relevant lines from the config.log , this could be helpful.
 @arvidj the best method is to fix the configure, or autogen.sh but I don't know, how, because I have no knowledge how that works.
 @zdenop Danke - thanks - merci - bedankt....
 (not yet tested, but I trust @zdenop )
 It works (do not forget to run ./autogen.sh first). First is check for g++. If it is not found it looks for clang++... I do not know if this is good or bad ;-) 
When I just used "AC_PROG_CXX" (instead of "AC_PROG_CXX(g++ clang++)") it looks for much more compilers, but it did not found clang++ automatically (which is IMO bad)... 
  @amitdo: I prefer to see whole help as default (as today) when I run "tesseract" or "tesseract -- help".
I am fine if there is '--help-psm', but at the moment the whole help is not very long so we do not need to remove part of it...
 @amitdo: No it is not (at least for me). I wrote: I prefer to see whole help as default (as today) when I run "tesseract" or "tesseract -- help".
 @amitdo: I will recheck it - I got different out when I wrote my comment.
 @amitdo: I did clean fetch of pullrequest and I got the output as you presented. Thanks.
  thanks
  Please check master branch or commits f46dfdc29da2bbacf6635752d9f28133ad4e10fe and 5db760215fa05f8dd722f66bc6a3ac438a5cd8d4.
  https://github.com/tesseract-ocr/tesseract#dependencies-and-licenses
  Project move to github, so there is no reason to use google drive
 Yes, when somebody provide installer for windows it will be publish on Github projekt page. Previous installer/downloads are at original location.
  thanks!
  Please use tesseract forum for asking support: https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice
  Please use tesseract forum for asking support: https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice
  Does the word 'tor' appear in one of the word lists?

Tesseract will never try to correct a valid word.
 We do not provide support for custom training (you need to demonstrate bug with traineddata from google).
You can use [tesseract user forum](https://groups.google.com/forum/#!forum/tesseract-ocr) for instead. I would suggest to search that forum before asking question.
  @amitdo: parameter file `quiet` should suppress tesseract banner. AFAIK reorganization (99110df75781c6907c84a3d23695a6900b933a97) caused that parameters are loaded/used after printing banner (e.g. `tesseract eurotext.tif eurotext -c debug_file=/dev/null` does not work too). Can you have a look at that?
 @zdenop
Nothing has changed in that respect. This is the same behaviour as before my commit.
 @zdenop
Anyway, I submitted a PR (#255) which makes `quiet` work as expected regarding tesseract's banner.
 Thanks!
@wasamasa: use can use parameter quiet:  `tesseract eurotext.tif eurotext quiet`
  Please use tesseract forum for asking support. Do not forget provide detail (version of tesseract, OS...)
  According Michael Wootton:

> you almost certainly will not be able to see GPU activity when running OpenCL kernels.  The kernels are running for < 50 ms, the time constant for the activity monitor is in seconds

The segfault should be fixed with 5db760215fa05f8dd722f66bc6a3ac438a5cd8d4
  Please provide full information (full log, all commands you run, version of program autogen, tesseract code revision....)
 What are trying to do???
 First of all - why you use old version of tesseract (anyway it worked also on Mac OS)? Why you do not use version from github???
  What is tesseractd.lib? 
Did you try to use/link release version of dependancies instead of debug version?
 Please use tesseract forum for support.
  This file is part of source distribution and that is reason why its point to "the same" online markdown file
  Please use tesseract forum for asking support: https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice
  That's a libjpeg warning. Is Tesseract not producing output for you, because it is for me (granted, the output isn't great).
 This page: http://www.artima.com/forums/flat.jsp?forum=1&thread=35958 says "before the EOI marker (0xFF 0xD9) one can include custom data other than data related to image" which seems reasonable.
Anyway... as this isn't a Tesseract issue per se, I'm going to close this issue.
  Please use tesseract-developers forum[1] for this suggestions like this.
[1] http://groups.google.com/group/tesseract-dev/
  This issue is not only about creating windows installer. It is also about providing support. And on windows the there is demand for VS based library (it is quiet easy to create mingw based library with msys, but VS based library need to rebuild all dependencies with VS)
 See also PR #162.
 @amitdo: Future is cmake. There is no sense to make and maintain  build system for each version of cmake. cmake correctly detect installed compiler and use it. We are just waiting for leptonica transfer to github, there cmake will be presented to.
 > Future is cmake. There is no sense to make and maintain build system for each version of cmake. cmake correctly detect installed compiler and use it. We are just waiting for leptonica transfer to github, there cmake will be presented to.

https://github.com/DanBloomberg/leptonica
  Did it happen with google traineddata file (or custom training)?
 Try to set  LC_NUMERIC to C during training
 Why do you think this patch is not in current version??? issue 910 you are reffering has problem with official google traineddata file. This was fixed.
AFAIR problem is in custom training.
 @oelleo: unfortunately tesseract requires (at the moment) training data use dot as decimal separator => you need to correct your custom training data.

I think it could be possible without retraining.  Try to unpack your data (`combine_tessdata -u eng.traineddata tmp/eng.`) and fix decimal separator in `eng.normproto` (replace eng with your name of your custom training)
  Please see [FAQ](https://github.com/tesseract-ocr/tesseract/issues/93): If you found a bug - please create an issue: Please make sure you are able to replicate the problem with tesseract executables on Linux or Windows. For other platforms or external/your programs (including tesseract wrappers) please use the tesseract forums.
  Reopen to check using CI.
 Please, rebase this to the latest source.
 Yes, seems to be my bad.
I tried to find a way to check all PRs received before CI was introduced.
Reopen helps only party because Windows CI (appveyor) does not check such PRs (as we can see).
  I am sorry but we do not provide for custom training.
Try to use forum for help/support. But please make sure you use the latest tesseract code and provide more information (tesseract version, locale settings, how you did training, link to data used for training, waa.traineddata....)
  At the moment stdin is supported only for OCR.
PSM_AUTO_ONLY (0) and PSM_OSD_ONLY (2) expects to read data based on filename
 @jflesch: I am currios: Why you call tesseract executable from python instead of using C-API? IMO it should be faster...
 fixed with 7089c7b 
  @olcc Tesseract is a raw OCR engine. Have a look at my project, OCRmyPDF, which provides a nice wrapper around Tesseract and takes care of many details to improve visualization. </plug>
 @olcc: tesseract puts to pdf image that you provided as input (e.g. file you see in pdf is not optimized for OCR as you claims). If you have another experience - please provide example. Otherwise close the "issue".
 What I want to say is that if you run:
    tesseract OCR.tif ORIGINAL pdf
than ORIGINAL.tif is included in ORIGINAL.pdf WITHOUT any modification. If you want to include ORIGINAL.jpg instead of OCR.tif than it is not tesseract issue ;-)
 @amitdo: it is implemented in [pdfrenderer](https://github.com/tesseract-ocr/tesseract/blob/master/api/pdfrenderer.cpp)

This is not real issue (no bug in tessseract), so I close this issue. Please use tesseract user forum for asking question/support.
  Please use tesseract user forum for support[1]. Also do not forget to search forum for you topic before asking for help.
[1] https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice
  This was the patch. I strongly suspect it made it in.

```diff
--- tesseract/api/baseapi.cpp   2015-06-12 17:25:51.000000000 -0700
+++ tesseract/api/baseapi.cpp   2015-08-18 17:46:15.000000000 -0700
@@ -991,8 +991,7 @@
   }
 
   // Begin producing output
-  const char* kUnknownTitle = "";
-  if (renderer && !renderer->BeginDocument(kUnknownTitle)) {
+  if (renderer && !renderer->BeginDocument(unknown_title_)) {
     return false;
   }
 
@@ -1166,8 +1165,7 @@
   }
 
   // Begin the output
-  const char* kUnknownTitle = "";
-  if (renderer && !renderer->BeginDocument(kUnknownTitle)) {
+  if (renderer && !renderer->BeginDocument(unknown_title_)) {
     pixDestroy(&pix);
     return false;
   }
--- tesseract/api/baseapi.h     2015-03-09 15:43:40.000000000 -0700
+++ tesseract/api/baseapi.h     2015-08-18 17:52:49.000000000 -0700
@@ -879,6 +879,12 @@
                                  int timeout_millisec,
                                  TessResultRenderer* renderer,
                                  int tessedit_page_number);
+  // There's currently no way to pass a document title from the
+  // Tesseract command line, and we have multiple places that choose
+  // to set the title to an empty string. Using a single named
+  // variable will hopefully reduce confusion if the situation changes
+  // in the future.
+  const char *unknown_title_ = "";
 };  // class TessBaseAPI.
 
 /** Escape a char string - remove &<>"' with HTML codes. */
--- tesseract/api/renderer.h    2014-08-12 11:22:47.000000000 -0700
+++ tesseract/api/renderer.h    2015-08-18 17:17:41.000000000 -0700
@@ -77,7 +77,7 @@
     bool EndDocument();
 
     const char* file_extension() const { return file_extension_; }
-    const char* title() const { return title_; }
+    const char* title() const { return title_.c_str(); }
 
     /**
      * Returns the index of the last image given to AddImage
@@ -126,7 +126,7 @@
 
   private:
     const char* file_extension_;  // standard extension for generated output
-    const char* title_;           // title of document being renderered
+    STRING title_;                // title of document being renderered
     int imagenum_;                // index of last image added
 
     FILE* fout_;                  // output file pointer
``` Yes, it went in as part of this commit.

https://github.com/tesseract-ocr/tesseract/commit/c1c1e426b32794d5e84134ee81bf895ff0228fe5  This is not bug ;-). I you install from git repository, you should follow instruction - https://github.com/tesseract-ocr/tesseract/blob/master/INSTALL.GIT#L16
 git pull can change also autoconf input files (e.g. 628de5ba3fe2879cff80343e327e3bae7f6b0634) so you need to run ./autogen.sh && ./configure...
  Please use tesseract forum for asking support: https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice
  committed but it seems that this is only occurrence of OpenMP support...
 Did you run ./autogen.sh after git pull? Was it without error? Can you provide config.log?
 Thanks for testing and report. Should be fixed in f331a57b8e4d1b38980c71f576ec5ffe6ba7cf9e.
 Patches are welcommed ;) Anyway tesseract can use OpenMP only in one place....
  In short: there's too much involved, so don't hold your breath.
  Thanks for testing.
  This is fixed in 27b8a5cc89898c3f12dae57a58b15efddee9fe18
  This is not bug - use tesseract forum for asking support[1]
[1] https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice
 There's a quote I like from the movie Jerry Maguire. Right before the more famous 'show me the money' line, there's 'help me help you'. It comes up a lot in open source.

Part of why this is not a bug report is for reasons of semantics: you didn't phrase it as a bug report, you phrased it as a support question, and you needed to add a comment to clarify that you think this is an issue. Help us help you: make your issues look like issues.

That said... issues that involve using Tesseract as a library are second class citizens, because producing a library is not the goal here. A number of people have, over the years, made some steps towards making it suitable for use as a library, though, going by some of the issues that have been filed, it's still not fully suitable for everyone's idea of what a library should be. In those cases, patches/pull requests are welcome, but otherwise, expect to see the issue left open until someone else feels like fixing it.

As for your issue, set the variable 'debug_file' to '/dev/null'. If you don't find that completely suitable, feel free to open another issue - or, better, a pull request.
 @matthill: First of all: there is an strong group of people using tesseract in C# and java (via wrappers of tesseract library) - so using user forum you can gain better support.
Next: I do not believe that nobody except you have this problem and would not report it... AFAIR this is first report regarding this output. So I expected it is connected to your code (e.g. how you use library, maybe some parameters etc.). So as I wrote on forum - please provide simple example to demonstrate problem.
 The debug printing routing will select 'nul' on windows, if 'debug_file' is set to '/dev/null'.

I have no idea why it happens in your compile and not in Ubuntu: you haven't said how you compiled it.
  Can you check 0c3c3eaba862254d1982e3fdaf3490adb50340ad ?
 @zdenop I got the same error as @ryanfb. 

The consensus is that AC_CHECK_LIB doesn't play nicely with `-framework`. Instead you can introduce a new macro, or just bypass the check on OS X. The nice thing about frameworks is that they are internally consistent, where you never what kind of crazy library-header mismatches you might find on a *nix box.
https://lists.apple.com/archives/unix-porting/2009/Jan/msg00026.html
 @zdenop I disabled the AC_CHECK_LIB(OpenCL) and replaced it with `have_opencl_lib=true`. That got me to a new error:

```
configure: error: conditional "OPENMP" was never defined.
Usually this means the macro was only invoked conditionally.
```

To repair that I added the required conditional:

```
@@ -168,12 +168,14 @@ if test "$enable_embedded" = "yes"; then
 fi

 # check whether to build OpenMP support
-AC_OPENMP
+#AC_OPENMP
 AS_IF([test "x$OPENMP_CFLAGS" != "x"],
   AM_CONDITIONAL([OPENMP], test "x$OPENMP_CFLAGS" != "x")
   AC_SUBST(AM_CPPFLAGS,"$OPENMP_CXXFLAGS")
   AC_DEFINE([OPENMP], [], [Defined when compiled with OpenMP support])
 )
+AM_CONDITIONAL([OPENMP], test "x$OPENMP_CFLAGS" != "x")
+
```

After `autoreconf -fvi` I had a working ./configure.

...and make failed with several errors of this form:

```
openclwrapper.cpp:3401:33: error: non-constant-expression cannot be narrowed
      from type 'int' to 'size_t' (aka 'unsigned long') in initializer list
      [-Wc++11-narrowing]
    size_t local_work_size[] = {block_size};
                                ^~~~~~~~~~
```
 @jbarlow83: configure issues should be fixed. Which version of compiler you use?
 The line `if test $host_os != Darwin; then` does not work because `$host_os` is `darwin14.5.0`. If this test is bypassed, configure works and make fails with a new error.

```
In file included from openclwrapper.cpp:11:
./openclwrapper.h:2:10: fatal error: 'allheaders.h' file not found
#include "allheaders.h"
```

That error occurs even though I am running `env LIBLEPT_HEADERSDIR=/usr/local/include/leptonica ./configure --enable-opencl`, the location of allheaders.h. Using CC=gcc-5 (homebrew gcc, not clang) also gives the header error.

Here is clang.

```
$ clang --version
Apple LLVM version 6.1.0 (clang-602.0.53) (based on LLVM 3.6.0svn)
Target: x86_64-apple-darwin14.5.0
Thread model: posix
```
 @jbarlow83: Thanks. Unfortunatelly I do not have Mac, so I can just guess what could work :-(.
If you change test to `if test $host_os != darwin; then` will it help? Or to `if test $host_os != darwin*; then`?

regading leptonica: Try to change line if it helps: 
    `LIBLEPT_HEADERSDIR="/usr/local/include /usr/include /opt/local/include/leptonica"`
to
    `LIBLEPT_HEADERSDIR="/usr/local/include /usr/include /opt/local/include/"`   
 #87 is also required. So I got to compile and apparently run successful OpenCL tests in which it selected my graphics card... but the OCR output was garbage. For example, if I had it generate a PDF, it still produced a valid PDF containing the input image, but the OCR text and its positioning was meaningless. 

If I rebuild the same source with OpenCL my test file was processed correctly.

```
$ /opt/tesseract-opencl/bin/tesseract -l eng ~/tests/resources/LinnSequencer.jpg out

Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performing profiling.

[DS] Device: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL) evaluation...
OpenCL error code is -54 at   when clEnqueueNDRangeKernel .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_ThresholdRectToPix .
Setting return value to -1
[DS] Device: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL) evaluated
[DS]          composeRGBPixel: 0.000132 (w=1.2)
[DS]            HistogramRect: 340282346638528859811704183484516925440.000000 (w=2.4)
[DS]       ThresholdRectToPix: 340282346638528859811704183484516925440.000000 (w=4.5)
[DS]        getLineMasksMorph: 0.004014 (w=5.0)
[DS]                    Score: inf

[DS] Device: "GeForce GT 755M" (OpenCL) evaluation...
[DS] Device: "GeForce GT 755M" (OpenCL) evaluated
[DS]          composeRGBPixel: 0.044892 (w=1.2)
[DS]            HistogramRect: 0.026128 (w=2.4)
[DS]       ThresholdRectToPix: 0.053928 (w=4.5)
[DS]        getLineMasksMorph: 0.025597 (w=5.0)
[DS]                    Score: 0.487237

[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
[DS]          composeRGBPixel: 0.019921 (w=1.2)
[DS]            HistogramRect: 0.063245 (w=2.4)
[DS]       ThresholdRectToPix: 0.034175 (w=4.5)
[DS]        getLineMasksMorph: 0.124600 (w=5.0)
[DS]                    Score: 0.952483
[DS] Scores written to file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz score is inf
[DS] Device[2] 1:GeForce GT 755M score is 0.487237
[DS] Device[3] 0:(null) score is 0.952483
[DS] Selected Device[2]: "GeForce GT 755M" (OpenCL)
Warning in pixReadMemJpeg: work-around: writing to a temp file
```
 @zdenop Our patches to date have fixed the build, but tesseract with OpenCL on Mac outputs gibberish as the OCR results (on an image that passes normal OCR). Both the perceived position of text and output text are corrupted. However, a blank image is correctly interpreted as a being blank - for example, tesseract can properly render a blank PDF file. I take this to mean somewhere OpenCL is distorting or corrupting the input during processing.

How I can test it to narrow down where the error actually occurs? 
 AFAIK they should work on this. Did you get wrong result if you use binarized (2 colors) (tif?) image?
 Image I used was:
https://en.wikipedia.org/wiki/LinnSequencer#/media/File:LinnSequencer_hardware_MIDI_sequencer_brochure_page_2_300dpi.jpg

Although it appears to be grayscale it looks like it's formatted as true color. Output is:

```
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
[DS] Profile read from file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz score is inf
[DS] Device[2] 1:GeForce GT 755M score is 0.487237
[DS] Device[3] 0:(null) score is 0.952483
[DS] Selected Device[2]: "GeForce GT 755M" (OpenCL)
Warning in pixReadMemJpeg: work-around: writing to a temp file
OSD: Weak margin (0.53), horiz textlines, not CJK: Don't rotate.
```

I converted that to a 1-bit TIFF using ImageMagick. That produced no OCR output and some errors:

```
[snipped common header]
Page 1
OSD: Weak margin (0.17), horiz textlines, not CJK: Don't rotate.
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
Warning in pixGenerateCIData: pixs has cmap; using flate encoding
Warning in pixReadMemTiffCl: tiff page 58428720 not found
```

In both cases, I did output to PDF, and the PDF is formatted correct. The OCR is nonsense. When output to plain text, the OCR is also nonsense.

If Tesseract is built without OpenCL the same image works fine for OCR.
 I tried `tesseract -c tessedit_write_images=1 ...` and got the following result. The image has the same dimensions as the input image and there is a visual correspondence of sorts between the images, but it's very mangled. First image is input, second is "tessinput.tif" after Tesseract's mangling.

@zdenop: If a read and write pointer were strobing the data by different amounts you'd get this sort of thing. This really looks it a single increment somewhere is the wrong size and should be an easy fix for someone who knew where to look in the code base (i.e. not me).

![mono](https://cloud.githubusercontent.com/assets/1825843/9775499/7c03cee2-5704-11e5-90fc-1aafddde9138.png)
![tessinput](https://cloud.githubusercontent.com/assets/1825843/9775505/8a7c59b2-5704-11e5-9d4b-932a8559c4d8.png)
 Please check master branch or commits f46dfdc29da2bbacf6635752d9f28133ad4e10fe and 5db760215fa05f8dd722f66bc6a3ac438a5cd8d4.
  Use tesseract forums for asking support[1]
[1] https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice
 Having tarballs is certainly possible, but I don't really see the point for most languages, which would only contain a single file. It does make sense for the languages that use Cube (that is, the trained data consists of a number of files), but there has been some kind of problem with that (I don't know the details), and Cube is expected to go away some time in the future.
As a sidenote, it would have been helpful if you could have made it clear that the issue was, in fact, an issue, by phrasing it as such: "tarballs not provided for traineddata" is an issue; "what is the official source...?" is a support question.
 1. There is an official location for download everything: repository tessdata[1]. Just to point out - you need package at-least eng and osd. Maybe have a look how debian packaged it or cygwin[2].
2. Ray asked[3] for suggestion regarding shipping/packaging problem - so this is IMO right place to discuss possible issues (also in past there was some suggestions who to distribute language files).

[1] https://github.com/tesseract-ocr/tessdata
[2] https://groups.google.com/d/msg/tesseract-ocr/dqT_KjKq0BM/PUMvC7DmIwAJ
[3] https://groups.google.com/d/msg/tesseract-dev/8e0F2cK2YzU/izie4Ysx-HEJ
  You got it wrong: this README is part of distribution packages and that it the reason why it points to its online version.
Another topic is source of information: This README can be modified only by project team members. https://github.com/tesseract-ocr/tesseract/wiki can be modified by any github users.
  I can not reproduce it on openSUSE 13.2. Try to provide more details.
 @vzani: when you start gdb, please enter command:
run
 If you still have a problem please try current stable release (3.04.01). 
Please uninstall all old tesseract installations before installing new tesseract version.
  I am not able to reproduce error with clang version 3.7.0 on opensuse 42.1 64bit... 
  This is not correct issue - please write what it wrong and what does not work exactly!
  @rodrigosalinas
The issue was solved (again).
Try latest code from the repo.
 You should provide more details.

> I have the latest code from the repo.

Which commit exactly, 1826ac14 ?

What OS do you use and the specific version of this OS. For example: Ubuntu 14.04, OS X 10.11, Windows 10.

Also, please provide the exact command you used and attach as zip file the tif and box files.
 I have Ubuntu 14.04 64 bit.

Commit  1826ac1.

> tesseract ult.dejavu.exp0.tif ult.dejavu.exp0 box.train

Output:

> Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
> Page 1
> APPLY_BOXES:
>    Boxes read from boxfile:    1360
>    Found 1360 good blobs.
> Generated training data for 292 words
> Warning in pixReadMemTiff: tiff page 1 not found

[ult.dejavu.exp0.tr.zip](https://github.com/tesseract-ocr/tesseract/files/106960/ult.dejavu.exp0.tr.zip)

My guess is that you didn't install  tesseract properly.

Did you run all these commands last time you installed  tesseract?

> ./autogen.sh
> ./configure --disable-cube
> make
> sudo make install
> sudo ldconfig
> make training
> sudo make training-install
 if you have previously installed  tesseract system-wide (for example, under /usr/local) the command 'tesseract ...' will use that system-wide executable.
 Try this command to see if you have another installation of Tesseract in your machine.

> find /usr -name "tesseract"
 What's the output of:

`printenv TESSDATA_PREFIX`

`tesseract --list-langs`
 `tesseract ult.dejavu.exp0.tif ult txt hocr`

Does this command produce ult.txt and ult.hocr ?

Maybe you should try to set TESSDATA_PREFIX environment variable or use --tessdata-dir parameter.
 OK, I was able to reproduce the issue.

I will try to figure out why this is happening when installing tesseract in 
`/home/myusername/tessbin`
 I solved @aiwaz issue. More info will follow later.
 @aiwaz, please test my fix.
 zdenko merged my fix to master.
 :+1:
Thanks for reporting the issue.
  Did you read https://groups.google.com/d/msg/tesseract-ocr/ToWcnyHqF4c/P7HDEKsR1cEJ ?
 I have a number of tempfile patches already written for Leptonica to make these calls more 
secure and less brittle, and there is ongoing work on this topic. I actually don't know if 
cygwin is using the Unix or Windows code path for temporary files, but just want to 
mention that there is activity. Don't know why you are getting bad results compared to
other cygwin users.

https://sources.debian.net/src/leptonlib/1.73-5/debian/patches/
  Can you try the patch in #60 to see if that fixes it?
 Ok, that's a different error. Do you have ICU4C installed?
 Sorry, it only complained about one of the ICU libraries. 

I think that the problem is that the library is named 'libicui18n' under Cygwin, as it is on Linux etc.
 Can you try with the patch from #62 ?
 Do the training tools build now? (Zdenko merged the pull request, so there's no need to mess around with branches)
 Ok, I'll close this. Thanks for testing!
  See: https://groups.google.com/d/msgid/tesseract-ocr/55B12C3C.3010908%40vol.at

```
pango_font_info.cpp:223:46: error: 'strcasestr' was not declared in this scope
   is_fraktur_ = (strcasestr(family, "Fraktur") != NULL);
```
 Just for future investigation: https://stackoverflow.com/questions/9935642/how-do-i-use-strcasestr
  Not generally useful, IMO - I don't see there being a whole lot of demand for this.
 Sure, the FAQ seems a good place for this information.
  that means that leptonica was not compiled with tiff support
 what does it mean "i have tried"?
If you compile leptonica without libtiff support it does not help to try any version...
This is definitely not tesseract issue.
  Not enough input. In short, box.train needs both an image, and a box file, and from those it creates training data. For a more complete explanation, see the wiki: https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#run-tesseract-for-training
 Re-opening, as requested.
 Something like this? (Using the variable also supports box.train.stderr)

```
diff --git a/api/tesseractmain.cpp b/api/tesseractmain.cpp
index e7abadf..7ddbc93 100644
--- a/api/tesseractmain.cpp
+++ b/api/tesseractmain.cpp
@@ -306,6 +306,11 @@ int main(int argc, char **argv) {
   if (b) renderers.push_back(new tesseract::TessBoxTextRenderer(outputbase));
   api.GetBoolVariable("tessedit_create_txt", &b);
   if (b) renderers.push_back(new tesseract::TessTextRenderer(outputbase));
+  api.GetBoolVariable("tessedit_train_from_boxes", &b);
+  if (b && !strcmp(outputbase, "-")) {
+    fprintf(stderr, "Box input from stdin not supported in box training.\n");
+    exit(1);
+  }
   if (!renderers.empty()) {
     // Since the PointerVector auto-deletes, null-out the renderers that are
     // added to the root, and leave the root in the vector.
```
 I think it's a matter for broader discussion.

On the one hand, it's The Right Thing, and I've already done The Wrong Thing by closing an issue that mentions a segfault... but it's an exceptional case. One, because it overloads what is normally the output file position to be a secondary input, and two, because it's not a frequent use case.
 I tried it on opensuse 13.2 64bit and it did not crashed:

> tesseract testing/phototest.tif - box.train
> Page 1
> APPLY_BOXES:
>    Boxes read from boxfile:     225
>    Found 225 good blobs.
> Generated training data for 60 words

Warning in pixReadMemTiff: tiff page 1 not found

> ls -t | head -n 1
> -.tr

Just OCR to stdout worked as expected:

> tesseract testing/phototest.tif -
> Page 1
> This is a lot of 12 point text to test the
> ocr code and see if it works on all types
> of file format.

The quick brown dog jumped over the
lazy fox. The quick brown dog jumped
over the lazy fox. The quick brown dog
jumped over the lazy fox. The quick
brown dog jumped over the lazy fox.

Warning in pixReadMemTiff: tiff page 1 not found
 @jbreiden: In openSUSE 13.2 I do not have api/.libs/lt-tesseract just api/.libs/tesseract. And you have two times, so output is testing/phototest.tif.tr 

And I got this:

```
TESSDATA_PREFIX=/usr/share/ valgrind api/.libs/tesseract testing/phototest.tif testing/phototest.tif - box.train
==21845== Memcheck, a memory error detector
==21845== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al.
==21845== Using Valgrind-3.10.0 and LibVEX; rerun with -h for copyright info
==21845== Command: api/.libs/tesseract testing/phototest.tif testing/phototest.tif - box.train
==21845== 
Tesseract Open Source OCR Engine v3.05.00dev-11-gd937659 with Leptonica
Page 1
APPLY_BOXES:
   Boxes read from boxfile:     225
   Found 225 good blobs.
Generated training data for 60 words
Warning in pixReadMemTiff: tiff page 1 not found
==21845== 
==21845== HEAP SUMMARY:
==21845==     in use at exit: 19,795,264 bytes in 33 blocks
==21845==   total heap usage: 874,639 allocs, 874,606 frees, 60,486,144 bytes allocated
==21845== 
==21845== LEAK SUMMARY:
==21845==    definitely lost: 0 bytes in 0 blocks
==21845==    indirectly lost: 0 bytes in 0 blocks
==21845==      possibly lost: 19,753,408 bytes in 24 blocks
==21845==    still reachable: 41,856 bytes in 9 blocks
==21845==         suppressed: 0 bytes in 0 blocks
==21845== Rerun with --leak-check=full to see details of leaked memory
==21845== 
==21845== For counts of detected and suppressed errors, rerun with: -v
==21845== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
```

For "stdout version" I got this:

```
TESSDATA_PREFIX=/usr/share/ valgrind api/.libs/tesseract testing/phototest.tif - box.train
==11238== Memcheck, a memory error detector
==11238== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al.
==11238== Using Valgrind-3.10.0 and LibVEX; rerun with -h for copyright info
==11238== Command: api/.libs/tesseract ../tesseract-ocr/testing/phototest.tif - box.train
==11238== 
Page 1
APPLY_BOXES:
   Boxes read from boxfile:     225
   Found 225 good blobs.
Generated training data for 60 words









Warning in pixReadMemTiff: tiff page 1 not found
==11238== 
==11238== HEAP SUMMARY:
==11238==     in use at exit: 19,795,264 bytes in 33 blocks
==11238==   total heap usage: 874,629 allocs, 874,596 frees, 60,485,260 bytes allocated
==11238== 
==11238== LEAK SUMMARY:
==11238==    definitely lost: 0 bytes in 0 blocks
==11238==    indirectly lost: 0 bytes in 0 blocks
==11238==      possibly lost: 19,753,408 bytes in 24 blocks
==11238==    still reachable: 41,856 bytes in 9 blocks
==11238==         suppressed: 0 bytes in 0 blocks
==11238== Rerun with --leak-check=full to see details of leaked memory
==11238== 
==11238== For counts of detected and suppressed errors, rerun with: -v
==11238== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
```
 @jbreiden, please test with latest commit.
 I can reproduce this.

I reread this issue. Jim's explanation is still true.

> box.train needs both an image, and a box file, and from those it creates training data. For a more complete explanation, see the wiki: https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#run-tesseract-for-training
 Tested. It works - no segfault.
  it worked for me on some images (there are some issues reported already - IMO 2 color tiff should work). Last week it segfault on linux. I will try windows today...
Also on forum there are some experiments[1]
[1] https://mail.google.com/mail/u/0/#search/opencl
 I am not sure what do you mean with  "any other dependencies except leptonica" - to run tesseract with opencl support you need libtiff and opencl sdk that support your hardware...
 @jbreiden:
it works for me on windows:
tesseract-opencl.exe ....\testing\phototest.tif -
[OD] Load opencl.dll successful!
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performi
ng profiling.

[DS] Device: "Intel(R) Core(TM) i7-4800MQ CPU @ 2.70GHz" (OpenCL) evaluation...
[OD] write binary[kernel-Intel(R)_Core(TM)_i7-4800MQ_CPU_@_2.70GHz.bin] succesfully
[DS] Device: "Intel(R) Core(TM) i7-4800MQ CPU @ 2.70GHz" (OpenCL) evaluated
[DS]          composeRGBPixel: 0.038657 (w=1.2)
[DS]            HistogramRect: 0.325462 (w=2.4)
[DS]       ThresholdRectToPix: 0.042622 (w=4.5)
[DS]        getLineMasksMorph: 0.119543 (w=5.0)
[DS]                    Score: 1.617007

[DS] Device: "Intel(R) HD Graphics 4600" (OpenCL) evaluation...
[OD] write binary[kernel-Intel(R)_HD_Graphics_4600.bin] succesfully
[DS] Device: "Intel(R) HD Graphics 4600" (OpenCL) evaluated
[DS]          composeRGBPixel: 0.153912 (w=1.2)
[DS]            HistogramRect: 0.449184 (w=2.4)
[DS]       ThresholdRectToPix: 0.048737 (w=4.5)
[DS]        getLineMasksMorph: 0.027403 (w=5.0)
[DS]                    Score: 1.619068

[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
[DS]          composeRGBPixel: 0.088750 (w=1.2)
[DS]            HistogramRect: 0.388795 (w=2.4)
[DS]       ThresholdRectToPix: 0.182945 (w=4.5)
[DS]        getLineMasksMorph: 0.613772 (w=5.0)
[DS]                    Score: 4.931717
[DS] Scores written to file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Intel(R) Core(TM) i7-4800MQ CPU @ 2.70GHz score is 1.617007
[DS] Device[2] 1:Intel(R) HD Graphics 4600 score is 1.619068
[DS] Device[3] 0:(null) score is 4.931717
[DS] Selected Device[1]: "Intel(R) Core(TM) i7-4800MQ CPU @ 2.70GHz" (OpenCL)
Page 1
This is a lot of 12 point text to test the
ocr code and see if it works on all types
of file format.

The quick brown dog jumped over the
lazy fox. The quick brown dog jumped
over the lazy fox. The quick brown dog
jumped over the lazy fox. The quick
brown dog jumped over the lazy fox.
 Please check master branch or commits f46dfdc29da2bbacf6635752d9f28133ad4e10fe and 5db760215fa05f8dd722f66bc6a3ac438a5cd8d4.
  https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advises
  autotool requires README!
 File was renamed to README.md (in a0ea634) therefore there is reference to README.md in README(it is fixed in 4f082a9). 
But autogen.sh fails without README, so I put it back (in 9b7f252)
 http://stackoverflow.com/questions/15013672/use-autotools-with-readme-md says 

```
AM_INIT_AUTOMAKE([foreign])
```

is enough to get around the need for README.
  For general questions and support please use tesseract-ocr user forum. See FAQ[1]

[1] https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advises
 From the looks of it, you haven't set the include path for leptonica's headers, but it's hard to tell from the screenshot. In general, console logs are much more useful than screenshots, so when you write to the forum, please try to include a log.
  Can you please provide error message from MSVC2013? 
  For support please use tesseract-ocr user forum. See FAQ[1]

[1] https://github.com/tesseract-ocr/tesseract/wiki/FAQ#rules-and-advice
 This issue is currently the top search result for 'ocr_float'; it lacks a simple summary: Tesseract (currently) does not support ocr_float.
 That seems a bit redundant; I was merely summarising what you were told there :)
  That error means that you are not linking against leptonica 1.72 library (but probably against some older version). It is not tesseract problem. 
  According Ray cube is a dead-end and it can be removed soon from the code(see e.g. [1]), so you can not expect any progress...

[1] https://groups.google.com/d/msg/tesseract-dev/mtIJXoUpfJc/6f0EwVNXOM8J
 lets wait for Ray...
 It's 'going away' for several years now... :-)
 Actually I have a comment for this.
There is one reason why cube has survived this long: For Hindi cube+tesseract has half the error rate of either on their own. I haven't actually tested that against the new LSTM engine yet, but I will on Monday, and if the new LSTM engine is better, then yes, cube is likely to get the chop for 4.00, and the ifdefs will be very useful. Tests complete. Decision made. Cube is going away in 4.00.
Results:
**Engine** | **Total char errors** | **Word Recall Errors** | **Word Precision Errors** | **Walltime** | *CPUtime**
:---------------: | :-----: | :-----:| :-----:| :-----: | :-------------------
Tess 3.04 | 13.9 | 30 | 31.2 | 3.0 | 2.8
Cube | 15.1 | 29.5 | 30.7 | 3.4 | 3.1
Tess+Cube | 11.0 | 24.2 | 25.4 | 5.7 | 5.3
LSTM | 7.6 | 20.9 | 20.8 | 1.5 | 2.5

Note in the above table that LSTM is **faster** than Tess 3.04 (without adding cube) in both wall time and CPU time! For wall time by a factor of 2.
 Can you provide some details about used hardware for test?
Did you made test also on single core CPU to see difference? OK, the big test I ran in a Google data center.
I just ran a test on my machine (HP Z420) on a single Hindi page for
comparison, ran each one 3 times (using time), and took the median.
My machine has AVX, so that will have still speeded it up a bit, so I tried
without AVX/SSE as well:
I disabled OpenMP by adding #undef _OPENMP in functions.h, line 33, and
disabled AVX/SSE in weightmatrix.cpp, line 66,67.

Test Mode                      Real User
Default (-oem 3 = cube + tess) 7.6  7.3
Base Tess (-oem 0)             2.9  2.6
Cube (-oem 1)                  5.4  4.9
LSTM With OpenMP+AVX           1.8  3.8
LSTM No OpenMP with AVX        2.7  2.4
LSTM No OpenMP with SSE        3.1  2.7
LSTM No OpenMP no SIMD at all  4.6  4.1

I think these tests nail cube as being slower and less accurate.

There may be a debate as to the value of the old Tesseract engine for its
speed vs the new one for its accuracy.

I'm going to push the data files now.



On Mon, Nov 28, 2016 at 10:40 AM, Stefan Weil <notifications@github.com>
wrote:

> And what about the language model used for the test? Is it already
> available so I can use it for my own tests?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/40#issuecomment-263355535>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056W2jegBHZM59ZxH-U5q22tSBy-HZks5rCyAxgaJpZM4FOBFi>
> .
>



-- 
Ray.
 On Mon, Nov 28, 2016 at 1:49 PM, Stefan Weil <notifications@github.com>
wrote:

> I'm going to push the data files now.
>
> Got the first ones. My first test with a simple screenshot gave
> significant better results with LSTM, but needed 16 minutes CPU time
> (instead of 9 seconds) with a debug build of Tesseract (-O0). A release
> build (-O2) needs 17 seconds with LSTM, 4 seconds without for the same
> image.
>
The slow speed with debug is to be expected. The new code is much more
memory intensive, so it is a lot slower on debug (also openmp is turned off
by choice on debug).
The optimized build speed sounds about right for Latin-based languages. It
is the complex scripts that will run faster relative to base Tesseract.

> Are there also new data files planned for old German (deu_frak)? I was
> surprised that the default English model with LSTM could recognize some
> words.
>
I don't think I generated the original deu_frak. I have the fonts to do so
with LSTM, but I don't know if I have a decent amount of corpus data to
hand. With English at least, the language was different in the days of
Fraktur (Ye Olde shoppe). I know German continued to be written in Fraktur
until the 1940s, so that might be easier. Or is there an old German that is
analogous to Ye Old Shoppe for English?

> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/40#issuecomment-263405208>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056Ti1gWSSG6BfuBbL68EE7RYfsItOks5rC0xWgaJpZM4FOBFi>
> .
>



-- 
Ray.
 I think it would be great to move this discussion to (developers) forum. we are already out scope of original issue post and much more people should be interested in "Faktur topic"... I have a new training md file in prep with an update to the code to make it
all work correctly.
It is going through our review process, and then I will need to sync again
with the changes that have happened since my last sync, but it should be
available late this week.
The md file documents the training process in tutorial detail, but line
boxes and transcriptions sounds perfect!

500k lines should make it work really well. I would be happy to take it and
help you, but we would have to get into licenses, copyright and all that
first.
For now it might be best to hang on for the instructions.

On Tue, Nov 29, 2016 at 2:05 PM, Johannes Baiter <notifications@github.com>
wrote:

> @theraysmith <https://github.com/theraysmith>
>
> I don't think I generated the original deu_frak. I have the fonts to do so
> with LSTM, but I don't know if I have a decent amount of corpus data to
> hand.
>
> I have a decent amount of corpus data for Fraktur (from scanned books) at
> hand (hOCR files with line boxes and transcriptions), it's about 500k lines
> and 50GB. I've yet to publish it, but if you have somewhere where I could
> send/upload it, I'd be glad to.
>
> Or is there a way to create the neccessary training files myself? I've had
> a cursory look through the OCR code and it looked like it needed lstmf
> files, but I haven't yet found what these are supposed to look like.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/40#issuecomment-263714590>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AL056WSh7RpK3l-EHGgky_xbByYqhbwSks5rDKGOgaJpZM4FOBFi>
> .
>



-- 
Ray.
 Cube is gone! Removal completed as of 9d6e4f6  I think I fixed this issue with the code I pushed in 4.00.  If there is issue with tesseract, please report it (your current report is useless) or make pull request.
  it seems that the z prefix isn't defined in MS Visual Studio  [size specification](https://msdn.microsoft.com/en-us/library/tcxf1dw6.aspx).
 It seems that @stweil solved this with this commit:
https://github.com/tesseract-ocr/tesseract/commit/997c4a6
  Requested in https://code.google.com/p/tesseract-ocr/issues/detail?id=1378
  https://code.google.com/p/tesseract-ocr/issues/detail?id=1351
(http://web.archive.org/web/20150413012200/https://code.google.com/p/tesseract-ocr/issues/detail?id=1351)
 I tested this patch and IMO it is only partial solution (for some cases). Issue was escalated to original OpenCL contributor.
 Merged, so we have at least partial fix...
  This adds support from the ocricola project to use finite state transducers in HFST format instead of DAWGs.

Branch is currently quite stale, but while I'm pulling all these pull requests together, I thought I should put this one in too.
 Things to do:
- [x] Match code formatting to rest of Tesseract
- [x] Remove exceptions
- [ ] Remove STL
 Not needed. The new engine works well with the dawgs. This is intended more to be an alternative to dawgs for morphologically complex languages that have a morphology available in HFST format. @mpsilfve do you have anything to add?  https://code.google.com/p/tesseract-ocr/issues/detail?id=1353

When training batch boxes and tifs this causes training to fail after 2nd iteration. The issue is that the tessopt iterator index is a global. The fix is to 1.) reset before each tessopt usage 2.) wrap the iterator state in a class/generator. Low priority, but useful if we want to generate a bunch of traineddatas in the same process or even multiple threads.

(http://web.archive.org/web/20150413012203/https://code.google.com/p/tesseract-ocr/issues/detail?id=1353)
  Split commits; builds on -p1, so includes that patch. Updated to current version
  1. memry removal.

This should be no-brainer. These functions never seemed to do anything useful. The only oddity was with alloc_string which rounded the allocation upwards to nearest multiple of 4. Based on my review of code, I could not identify any value in this feature, so even alloc_string was simply transformed to malloc.

memry.\* are removed. All code is adjusted to simply call malloc and free instead.

listio.\* are removed. The list reading function in these files appears to have been unused, and contained the only invocation of strsave define, which was one of the alloc_string users, so I removed both of them.

https://code.google.com/p/tesseract-ocr/issues/detail?id=1199
  …ble in textord/tospace.cpp

https://code.google.com/p/tesseract-ocr/issues/detail?id=1106

Reported by ettl.martin78, Feb 11, 2014
Please review the attached patch. It fixes a potential usage of an uninitialized bool variable ('fuzzy_sp'). The fix simply initialized the variable by default to 'FALSE'. Before the fix, the value of 'fuzzy_sp' was not set, but used in the else-branch in line 1107:

```
      else {
        prev_blanks = blanks;
        prev_fuzzy_sp = fuzzy_sp;
        prev_fuzzy_non = fuzzy_non;
      }
```

Best regards and many thanks

Feb 11, 2014
#1 ettl.martin78

The updated patch fixes two more uninitialized variable usages in the same function.

Many thanks for reviewing.

(http://web.archive.org/web/20150509223835/https://code.google.com/p/tesseract-ocr/issues/detail?id=1106)
  https://code.google.com/p/tesseract-ocr/issues/detail?id=1341 (http://web.archive.org/web/20150413012149/https://code.google.com/p/tesseract-ocr/issues/detail?id=1341)
  https://code.google.com/p/tesseract-ocr/issues/detail?id=1139

Reported by nick.white@durham.ac.uk, Apr 8, 2014
The ok_count == 2 part of the test always failed, which prevented the kerning variations from ever being printed. As far as I can tell
it wasn't doing anything useful, but my C++ is (still) rusty, so
some light checking would be wise.

The patch also updates the function description to be in line with the current output.

Apr 24, 2014
#1 theraysmith

This could significantly change results after training.
Going to apply this change in a carefully controlled environment.

Apr 25, 2014
#2 nick.white@durham.ac.uk

This patch did make the example in the comments (A+V) output as expected, but it doesn't seem to have affected the fact that no kerning variations are printed for any ancient greek digrams. I'm not sure why, whether it's the ancient greek font, or there is something still not right about the code.

(http://web.archive.org/web/20150510031850/https://code.google.com/p/tesseract-ocr/issues/detail?id=1139)
 I think so. Even the legacy engine didn't use that data much, the new engine doesn't use it at all.  Migrating from https://code.google.com/p/tesseract-ocr/issues/detail?id=1316
 For posterity: http://web.archive.org/web/20150509202204/https://code.google.com/p/tesseract-ocr/issues/detail?id=1316
/n  ### Environment

* **Tesseract Version**:  4.00.00dev with current training data (tessdata_best).
* **Commit Number**: eba0ae3b88a46a93e981770caa0b148d65cc4468
* **Platform**: Windows 64-bit build, Visual Studio 2017 15.4.4

### Current Behavior:

[Test.zip](https://github.com/tesseract-ocr/tesseract/files/1505927/Test.zip)

1) MinSizeRel build

Command: 

tesseract.exe C:\Test.tif C:\Test -l deu+eng --psm 1 --oem 1 pdf

Error messages:

None

Result:

Correct PDF created, OCR results OK

2) Release build

Command: 

tesseract.exe C:\Test.tif C:\Test -l deu+eng --psm 1 --oem 0 pdf

Error messages:

None

Result:

Correct PDF created, OCR results OK

3) Release build

Command: 

tesseract.exe C:\Test.tif C:\Test -l deu+eng --psm 1 --oem 1 pdf

Error messages:

Multiple times:

Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made

Result:

Broken PDF created.

Conclusion:

Release build shows erratic behavior when LSTM is used, errormessages and/or wrong output.
Debug And MinSizeRel builds work slowly but correctly.
As soon as the optimization /Ot is switched to /Os (or from /O2 to /O1) or LSTM is not used all problems go away.

### Expected Behavior:

Release build behaves like MinSizeRel/Debug built.

### Suggested Fix:

Problem is located in Tesseract::GetRectImage

As soon as speed optimization for this function is switched off with #pragma optimize( "t", off ) the problem goes away.
 As I made some progress I updated the issue to better describe what is happening.
I built tesseract exactly like described here:
 https://github.com/tesseract-ocr/tesseract/wiki/Compiling#windows
Develop Tesseract -> Building for x64 platform It is a 64 bit version of leptonica - otherwise it would not work at all.
Why should the compiler used to build leptonica make any difference?
Due to my findings the problem is located in Tesseract::GetRectImage, and goes away as soon as that very function is not optimized for speed anymore.
I would not expect that the way tesseract interfaces with external libraries is changed by the optimization option. Not my post and it does not look like the problem has anything to do with /Ob2.
RelWithDebugInfo shows the same behaviour as Release as both use /O2. Found similar problem in ColPartitionGrid::ComputeTotalOverlap with some input files.
A Release build hits the following assertion:
contains_unichar_id(unichar_id):Error:Assert failed:in file C:\Users\mw\Desktop\OCR\tesseract-master\ccutil\unicharset.h, line 513
As soon as I add #pragma optimize( "t", off ) directly in front of the function ColPartitionGrid::ComputeTotalOverlap  the problem goes away. @MarkusGH, did you also restore optimization after `ColPartitionGrid::ComputeTotalOverlap` and `Tesseract::GetRectImage`, so we can be sure that only those functions used code without optimization in your test? Yes - I put #pragma optimize( "", on )  directly after the functions.
It looks like the following have a strong effect on the problem:
Training files used, size of input file (pixel count), engine.
Strange enough I found at least one file which works with --oem 0 and --oem 1 but not with --oem 3. I think it is too early to blame MSVC for this issue.
Could be a compiler error or could be sloppy programming which leads to unexpected behaviour when that kind of optimization is active. Again - to me it feels a lot like it has to do with signed integer overflow handling. 
Signed integer overflow behaviour is undefined per C++11 standard. 
Without optimizations signed integer overflow will simply wrap around (this is simply what the processor does). With optimizations anything can happen...
You actually do not really know, if the issue is not also present in gcc builds, because the effects are not necessarily obvious - could be there are only slight variations in OCR results.

As you use gcc I would kindly suggest to create a build with the gcc option -ftrapv (and maybe other options necessary to bring the debugger to break on integer overflows) and try the test case I provided to see if it actuall produces integer overflows. If so this makes a case to investigate further in that direction. A Tesseract executable which was compiled with `-ftrapv` does not raise an overflow exception. What about debugging the buggy Windows executable and setting a conditional breakpoint on `pixCreateHeader` (waiting for `height <= 0`)? Oh - so it looks like the integer overflow hypothesis is dead.
About pixCreateHeader: I searched for that already. Unfortunately I did not build leptonica from source and it does not look like this function is called from anywhere outside leptonica. I tested the latest binary from [AppVeyor](https://ci.appveyor.com/api/buildjobs/qlkwgwrntp1gnr7l/artifacts/build%2Fbin%2Ftesseract-master.1240.zip). It shows the same problem when running `tesseract --oem 1 Test.tif stdout` with LSTM.

It looks like `pixCreateHeader` is called with height == 0.  Hello everyone and thanks for the library.

I'm on Linux, using Tesseract 3.05.01, Leptonica 1.74.4. Building both from source. I have built them with no problem.

What I want to achieve is, statically link leptonica and tesseract to a shared object, which uses the functions from tesseract's API. Following this linkage, I wanted to link this shared object to an executable. Finally, there should be an executable with a shared object and these should not need any other shared object.

I've successfully linked the libraries to shared object(I thought so) but when I try to link to the executable, I see that Leptonica functions are not linked. What am I doing wrong?

The linking of the shared object:
```
g++ -I. -I/usr/local/include/tesseract -I/usr/local/include/leptonica -std=gnu++11 wrap.cpp  /usr/local/lib/liblept.a /usr/local/lib/libtesseract.a -shared -o wrap.so -fPIC -Wl,-Bsymbolic
```

Linking of the executable:
```
gcc test.c -o test wrap.so
```

The error I receive:
```
wrap.so: undefined reference to `sem_init'
wrap.so: undefined reference to `pixExpandReplicate'
wrap.so: undefined reference to `pixConvertTo8'
wrap.so: undefined reference to `pixGetWpl'
...
...
wrap.so: undefined reference to `pixConvertTo32'
wrap.so: undefined reference to `pixaCreate'
wrap.so: undefined reference to `sem_wait'
collect2: error: ld returned 1 exit status
```

What should I do to overcome these linkage problems?

I've attached the wrap.cpp, wrap.h and test.c:
[Code.zip](https://github.com/tesseract-ocr/tesseract/files/1500978/Code.zip)

### Environment

* **Tesseract Version**: 3.05.01
* **Commit Number**: The 3.05.01 branch, no change to the source
* **Platform**: 3.10.0-327.el7.x86_64 #1 SMP Thu Nov 19 22:10:57 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
  Hello,

Releases 3.05.00 and 3.05.01 are missing `./configure` in release bundle
Im struggling to build tesseract for 3 days now

Also, release 3.05.01 is missing build fixes from 3.05 branch
Would be great if you could re-upload release bundles with them

Appreciated You're supposed to run ./autogen.sh as a first step, which will generate the configure script. You (the developer) are supposed to do that, and generate a tarball from the result, and upload it to GitHub as a release download. @amitdo yes, i understand, but for some reason i had to resolve a bunch of errors with autogen.sh, and finally ended up with
```
./configure: line 17577: syntax error near unexpected token `LEPTONICA,'
./configure: line 17577: `PKG_CHECK_MODULES(LEPTONICA, lept >= 1.74, have_lept=true, have_lept=false)'
```
even with `pkg-config` installed

i've successfully builded 3.04.01 witch seems to be the last release with bundled `./configure`

Any help appreciated  If you installed pkg-config after you ran autogen.sh, re-run autogen.sh.  @amitdo i re-run autogen.sh a million times already... :( Leptonica is built from source:
https://github.com/DanBloomberg/leptonica/releases/download/1.74.4/leptonica-1.74.4.tar.gz
with:
```
./configure --prefix=$pkg_prefix
make
make install
```

Building tesseract from release tar 3.05.00 I'm getting:
```
...
checking for mbstate_t... yes
checking for leptonica... configure: error: leptonica not found
```

Building tesseract from git branch 3.05 I'm getting:
```
...
checking for mbstate_t... yes
./configure: line 17577: syntax error near unexpected token `LEPTONICA,'
./configure: line 17577: `PKG_CHECK_MODULES(LEPTONICA, lept >= 1.74, have_lept=true, have_lept=false)'
```

Build script is the same:
```
  libtoolize
  ./autogen.sh
  ./configure --enable-debug \
	  --prefix="${pkg_prefix}" \
	  --host=x86_64-pc-linux-gnu \
	  --with-extra-includes=$(pkg_path_for tpolekhin/leptonica)/include \
	  --with-extra-libraries=$(pkg_path_for tpolekhin/leptonica)/lib
  make
```

Also, `pkg-config --cflags lept` and `pkg-config --libs lept` gives:
```
-I/hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/include/leptonica
-L/hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/lib -llept
``` Building from release tar 3.05.01 is the same:
```
./configure: line 17577: syntax error near unexpected token `LEPTONICA,'
./configure: line 17577: `PKG_CHECK_MODULES(LEPTONICA, lept >= 1.74, have_lept=true, have_lept=false)'
``` Nothing if this helps also:
`LIBLEPT_HEADERSDIR=$(pkg_path_for tpolekhin/leptonica)/include`
`LIBLEPT_HEADERSDIR=$(pkg_path_for tpolekhin/leptonica)/include/leptonica` So this means nothing?
```
pkg-config --cflags lept
-I/hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/include/leptonica
pkg-config --libs lept
-L/hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/lib -llept
```

And also:
`PKG_CONFIG_PATH=/hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/lib/pkgconfig`
```
ll /hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/lib/pkgconfig
total 4
-rw-r--r-- 1 root root 379 Nov 24 11:38 lept.pc
``` I've found why i have v3.04.00 building normally
configure.ac in branch 3.04 is missing this:
`PKG_CHECK_MODULES([LEPTONICA], [lept >= 1.74], [have_lept=true], [have_lept=false])`
that is present in 3.05 I think that the issue here is that autoconf can't find pkg-config m4 macros for PKG_CHECK_MODULES
Here's what i found in `config.log`
```
ACLOCAL='${SHELL} /hab/cache/src/tesseract-3.05.01/config/missing aclocal-1.15'
``` @zdenop tried `ACLOCAL_FLAGS="-I /hab/pkgs/tpolekhin/leptonica/1.74.4/20171124113357/" ./autogen.sh` with same error :( Did you install `autoconf-archive` (or another package needed for your Linux distribution which provides the macro `PKG_CHECK_MODULES`? okay, so the issue was that `automake/share/aclocal/` was missing `pkg.m4` The `PKG_CHECK_MODULES` macro comes from `pkg-config`
https://cgit.freedesktop.org/pkg-config/tree/pkg.m4.in https://stackoverflow.com/a/10229811  I am naive to tesseract and LSTM. I read tesseract tutorial on wiki and I tried to train lstmtraining from the scratch using the following command: 

training/tesstrain.sh --fonts_dir /usr/share/fonts/truetype/khmeros-ttf --fontlist "Khmer OS" --langdata_dir langdata --lang khm --linedata_only --noextract_font_properties --tessdata_dir /home/phyrum/tesseract/tessdata --output_dir khmtrain

training/lstmtraining --debug_interval -1 \
  --traineddata khmtrain/khm/khm.traineddata \
  --net_spec '[1,36,0,1 Ct3,3,16 Mp3,3 Lfys48 Lfx96 Lrx96 Lfx256 O1c111]' \
  --model_output khmoutput/base --learning_rate 20e-4 \
  --train_listfile khmtrain/khm.training_files.txt \
  --max_iterations 10000 &> khmoutput/basetrain.log
[
[basetrain.log](https://github.com/tesseract-ocr/tesseract/files/1494522/basetrain.log)
![tesseract_version](https://user-images.githubusercontent.com/17153459/33108746-5759945a-cf70-11e7-99e7-9561fc79212d.png)
![training_lstmtraining_tesseract](https://user-images.githubusercontent.com/17153459/33108806-b06d9ae6-cf70-11e7-8a05-75233c5d6ba4.png)
](url)
=> After lstmtraining finished, I got only **"basetrain.log"** and **"base_checkpoint"** but I cannot find the final "khm.traineddata". and I really don't know why. Could you please help me? 

### Environment

* **Tesseract Version**: tesseract 4.00.00dev-691-gfb359fc
* **Platform**: Linux phyrum 4.10.0-38-generic #42~16.04.1-Ubuntu SMP Tue Oct 10 16:32:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

**Note:** I also submitted detail question in tesseract-ocr mailing list with the title **"LSTMTRAINING from the scratch for khmer language - Legacy Limon Fonts"**. Could you please check and give me some advices?
  @amitdo 
@stweil 
@egorpugin 

I'd like to stop supporting old giflib versions, before 5.1 when the interface was last changed.
leptonica is currently supporting 4.1.6 and 5.0, as well as 5.1+.

Is this practical? What would be effect be on tesseract if giflib 5.1+ were required? Hi Dan!

I think it's OK to move to 5.1 as the minimum version.

https://packages.debian.org/search?searchon=sourcenames&keywords=giflib
https://packages.ubuntu.com/search?searchon=sourcenames&keywords=giflib

Gif support is not very critical for OCR purpose.

Maybe you should target a new release for Ubuntu 18.04 LTS. OK.  Will drop pre-5.1 giflib support.

And I expect to have a new leptonica release in Dec or Jan that Jeff will
debianize for 18.04.

On Mon, Nov 20, 2017 at 4:12 PM, Amit D. <notifications@github.com> wrote:

> Hi Dan!
>
> I think it's OK to move to 5.1 as the minimum version.
>
> https://packages.debian.org/search?searchon=sourcenames&keywords=giflib
> https://packages.ubuntu.com/search?searchon=sourcenames&keywords=giflib
>
> Gif support is not very critical for OCR purpose.
>
> Maybe you should target a new release for Ubuntu 18.04 LTS.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1215#issuecomment-345873534>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLAoZhoJmbkplzjGxJO5utvgYg55qks5s4hVjgaJpZM4Qk_7k>
> .
>
 CC'ing @jbreiden. `libgif4` (4.1.6) was last used in Debian's `oldstable`, so I see no problem in dropping support for that version. Support for 5.1 which is used by Debian `stable` is required of course. libgif support in gifio.c cleaned up.
Old pre-5.1 distributions are no longer supported.
libgif 5.1 or later only (and not 5.1.2) MacPorts uses giflib 4.2.3, because when giflib 5 was released, its API was different from giflib 4 and nothing supported the new API, so updating to giflib 5 would have broken everything that uses giflib. See [this MacPorts ticket](https://trac.macports.org/ticket/35817) for my investigations into that. Granted that was 5 years ago and maybe some projects have now added giflib 5 support. But I count 68 different ports in MacPorts that use giflib, and I don't know if all of those projects have added giflib 5 support, but my strong suspicion is that they have not, because some of them are probably not in development anymore.

All of which is to say that if you drop giflib 4 support, it will be a lot of work for me in MacPorts to probably create separate giflib 4 and 5 ports and then update and test those 68 ports. We don't currently have that, but yes, I will probably need to work on doing that. Homebrew supports giflib 5.1.4.
https://github.com/Homebrew/homebrew-core/blob/master/Formula/giflib.rb Ryan, I'm sorry to hear that.  I know what a pain it is when a basic library changes its interface. The gifilib interface changed at 5.0 and at 5.1.  If you look at leptonica gifio.c from 1.74.4, you'll see what I had to do to support 4.6.x and 5.0 and 5.1+.

Have another look, and if you still want me to revert, at least to give you more time to bring macports up to date, let me know and I will do so.

  -- Dan Ah, I see you already committed the removal in https://github.com/DanBloomberg/leptonica/commit/64961e9ae9151f9c9e251de9fe7be0363e780fbd.

Maybe that will motivate me to finally deal with giflib 5 in MacPorts. The offer still stands, if you need it.  I expect that version 1.75 will be released some time in January, to set your time frame. Makes sense.  Ryan, I'll revert the gifio.c change for 1.75.   The error messages come from Leptonica.
  Try to isolate the problem and find out which function/method call triggers the error.

Start by calling only Leptonica functions:

>pixWriteAutoFormat("F:/test.jpg", croppedImage);
Pix* test = pixRead("F:/test.jpg");
  getting table capture....... in excel....
input like.....
can anyone tell me how get table data each cell seperately.....
![1](https://user-images.githubusercontent.com/32842699/32480565-74a9438c-c3b5-11e7-96df-57c6a81c7d17.jpg)

 i am got getting ...
i am getting result.... like this....
110 - पैठण विधानसभा मतदार संघ

प्रारूप मतदार यादी 2017
राज्य - (एस 13) महाराष्ट्र

यादी भाग क्रमांक : 2

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

1 नायगव्हाण/हनुमंतगांव/खंडेवाडी
ता. पैठण जि. औरंगाबाद पिनकोड 431105
11 1ॐ0870659 2] 1ॐ0870758 31 7\×4202057
मतदाराचे पुर्ण : महाजन कोंडीराम मतदाराचे पुर्ण : महाजन श्रीमतं मतदाराचे पुर्ण : महाजन अशोक
नांव मोहन नांव कोंडीराम नांव भानुदास
वडीलांचे नांव : महाजन मोहन Photo वडीलांचे नांव : महाजन कोंडीराम Photo वडीलांचे नांव : महाजन भानुदास Photo
घरक्रमांक ; 1 ४990 |) घरक्रमांक : 1 Available || RT : 3 Available
वय: 78 लिंग ` पुरुष वय: 35 लिंग ` पुरुष वय: 29१ लिंग ` पुरुष
41 1ॐ30873273 5] 6४1
मतदाराचे पुर्ण : महाजन नाथा मतदाराचे पुर्ण : महाजन कचराबाई मतदाराचे पुर्ण : महाजन सुनिता नाथा
नांव कोंडीराम नांव नाथा नांव
वडीलांचे नांव : महाजन कोंडीराम Photo पतीचे नांव : महाजन नाथा Photo पतीचे नांव : महाजन नाथा Photo
घर क्रमांक :? Available || RT | : 2 Available || RT | : 2 Available
वय: 5 लिंग ` पुरुष वय: 52२ for ‘@t वय: 48 लिंग ‘@t
7] 7\×4202008 ४1 JSFO870626 9|
मतदाराचे पुर्ण : देसाई रमेश हरीभाउ मतदाराचे पुर्ण : महाजन भानुदास मतदाराचे पुर्ण : महाजन कडूबाई
नांव नांव कोंडीराम नांव भानुदास
वडीलांचे नांव : देसाई हरीभाउ Photo वडीलांचे नांव : महाजन कोंडीराम Photo पतीचे नांव : महाजन भानुदास Photo
घरक्रमांक : 3 Available || RT : 3 Available || RT : 3 Available
वय: 52२ लिंग ` पुरुष वय: 5 लिंग ` पुरुष वय: 4१ लिंग ‘@t
101 7\%6412993 111 7\%4201976 12] 7\%6045025
मतदाराचे पुर्ण : देसाई राणी नानासाहेब मतदाराचे पुर्ण : देसाई छाया बद्रीनाथ मतदाराचे पुर्ण : देसाई संगीता
नांव नांव नांव बाबासाहेब
वडीलांचे नांव : देसाई नानासाहेब Photo पतीचे नांव : देसाई बद्रीनाथ Photo पतीचे नांव : देसाई बाबासाहेब Photo
घर क्रमांक : ०३ Available || RT | : 4 Available || | : ox Available
वय: 20 लिंग : स्त्री वय: 30 लिंग ‘@t वय: 30 लिंग ‘@t
13] 7\%6412977 14] 7\%6412985 15]
मुतदाराचे पुर्ण : देसाई कल्याणी योगेश मुतदाराचे पुर्ण : देसाई रेणुका सतीश मतदाराचे पुर्ण : महाजन धोंडीराम
पतीचे नांब : देसाई योगेश Photo पतीचे नांव : देसाई सतीश Photo वडीलांचे नांव : महाजन मोहन Photo
घर क्रमांक : ०४ ४990 |) घरक्रमांक : ०४ Available || RT : 5 Available
वय: 23 लिंग ` स्त्री वय: 21 लिंग ` स्त्री वय: 70 लिंग ` पुरुष
161 — JSFO871137 17] 7\%0530014 18] 7\%4201950
पुर्ण - 7 पुर्ण - T पुर्ण -
पतीचे नांव : महाजन धोंडीराम Photo वडीलांचे नांव : महाजन धोंडीराम Photo वडीलांचे नांव : महाजन धोंडीराम Photo
घरक्रमांक : 5 ४190 |) घरक्रमांक ;: Available || RT | : 5 Available
वय: ५4५ लिंग ` स्त्री वय: 35 लिंग ` पुरुष वय: 3२ लिंग ` पुरुष
191 7\%4201968 201 27%6413017 211 2736413090
मुतदाराचे पुर्ण : मुह्युलन गोरखनाथ मतदाराचे पुर्ण : देसाई स्वाती गणेश मतदाराचे पुर्ण : महाजन संतोष संजय
नाव नाव नाव
वडीलांचे नांव : महाजन धोंडीराम Photo पतीचे नांव : देसाई गणेश Photo वडीलांचे नांव : महाजन संजय Photo
घरक्रमांक : 5 Available || RFT® | : on Available || RFT® | : on Available
वय: 31 लिंग ` पुरुष वय: 25 लिंग ` स्त्री वय: 2० लिंग ` पुरुष
221 23| — JSFO872622 241 — ZYX0530022
your ur . mem g मुतदाराचे पुर्ण : महाजन कडूबाई खंडू मतदाराचे पुर्ण : महाजन कचरू खंडू
वडीलांचे नांव : महाजन मोहन Photo पतीचे नांव : महाजन खंडू Photo वडीलांचे नांव : महाजन खंडू Photo
: 6 Available || RT _ : 6 Available || RT _ : 6 Available
वय: 6५6 लिंग ` पुरुष वय: 55 fr ‘@t वय: 33३ लिंग ` पुरुष
251 — ZYX0530204 2681 — JSFO871665 27| — JSFO871178
मतदाराचे पुर्ण : महाजन कैलास खंडू मतदाराचे पुर्ण : गाढेकर भावराव लिंबा मतदाराचे पुर्ण : गाढेकर केसरबाई
नांव नांव नांव भावराव
वडीलांचे नांव : महाजन खंडू Photo वडीलांचे नांव : गाढेकर लिंबा Photo पतीचे नांव : गाढेकर भावराव Photo
: 6 Available || RT _ : 6 Available || RT _ : 6 Available
वय: 30० लिंग ` पुरुष वय: 6१ लिंग ` पुरुष वय: 6० fr ‘@t
281 — ZYX0499103 29 — ZYX6412928 30| — JSFO907899
yh ; men प्रभु भाउराव मुतृदाराचे पुर्ण : महाजन वैशाली कैलाश मतृदाराचे पुर्ण : लिबोरे सुभद्रबाई नंदू
वडीलांचे नांव : गाडेकर भाउराव Photo पतीचे नांव : महाजन कैलाश Photo पतीचे नांव : लिबोरे नंदू Photo
: 6 Available || RT | : ०६ Available || RTs | : 7 Available
ans os लिंग ` पुरुष वय: 26 लिंग : स्त्री वय: 44 लिंग ‘@t
01/01/2017 रोजी < aa ran नौयणी अधिकारी याच्या गरे पृष्ठ क्रमांक : 3

 
I want output like.................................................
![dddd](https://user-images.githubusercontent.com/32842699/32481144-12195efc-c3b8-11e7-92bb-fe5ba644ba00.jpg)

 

 

 

 

 

 

 

 

 

 

 

 

  ### Environment

* **Tesseract Version**: 4.0.0-alpha
* **Platform**: Windows 10 64-bit 

### Current Behavior
get the tesseract  by compiling the source code .
visual studio 2015 update 3
using api to call tesseract
`char* outText = api->GetUTF8Text();`
when I free the pointer outText like following code:
`delete[]  outText`
while using the **release mode** to compile the code, running ok ! 
but using the **debug mode**, the program definately crash! 
### Expected Behavior:

### Suggested Fix:
 https://github.com/tesseract-ocr/tesseract/wiki/APIExample

>// Destroy used object and release memory
>    api->End();
>    delete[] outText;

Did you call `api->End()` ? surley I did @hoangtocdo90 tks for your reply man, but it doesnt seem like what you gave.  see https://github.com/tesseract-ocr/tesseract/issues/1030  I am trying to build the latest from git on Fedora 26, 4.13.10-200.fc26.x86_64.

While run ./configure, following error was reported:

./configure: line 4243: syntax error near unexpected token `-mavx,'
./configure: line 4243: `AX_CHECK_COMPILE_FLAG(-mavx, avx=true, avx=false)'

 You can also use the search options in GitHub.

https://github.com/tesseract-ocr/tesseract/issues?q=is%3Aissue+AX_CHECK_COMPILE_FLAG+is%3Aclosed
  I have read that the training process run on 4 threads using openmp but viewing cpu utilization I can see it only uses 1 thread? Is there something special I need to do to make it run using openmp? I am using gcc 4.8
  I am attempting to run this:

```
lapply(myfiles, function(i){

    shell(shQuote(paste0("pdftopng -f 1 -l 10 -r 600 ", i, " ocrbook")))
mypngs <- list.files(path = dest, pattern = "png", full.names = TRUE)
lapply(mypngs, function(z){
    shell(shQuote(paste0("tesseract ", z, " out")))
    #file.remove(paste0(z))
    })
})
```


However, even though I am feeding it a PNG file, I get the error
```
Tesseract Open Source OCR Engine v3.05.01 with Leptonica
Error in pixCreateNoInit: pix_malloc fail for data
Error in pixCreate: pixd not made
Error in pixReadStreamPng: pix not made
Error in pixReadStream: png: no pix returned
Error in pixRead: pix not read
Error during processing.
```
```
1: running command 'C:\Windows\system32\cmd.exe /c "tesseract C:\users\gallowmb\desktop/ocrbook-000001.png out"' had status 1 
2: In shell(shQuote(paste0("tesseract ", z, " out"))) :
  '"tesseract C:\users\gallowmb\desktop/ocrbook-000001.png out"' execution failed with error code 1
```


phototest works.  There seems to be an issue with the file itself.  What is the issue?


RStudio 1.1.383
Tesseract 3.05.01
Win 7 64 bit zdenop, here is the output of tesseract -v in CMD.
```

tesseract 3.05.01
  leptonica-1.74.1
   lipgif 4.1.6(?)  :  libjpeg 8d (libjpeg-turbo 1.5.0)  :  libpng 1.6.20  :  libtiff 4.0.6  :  
   zlib 1.2.8  :  libwebp 0.4.3  :  libopenjp2 2.1.0
```


I have converted the PDF to a TIFF, and rerun it, and the tesseract error is this:

`Error in PixReadFromTiffStream: calloc fail for tiffdata` Hi, I found what the problem was after using an example scanned PDF from the internet.  The DPI was too high for the PDFtoPNG conversion.  I took it down to 150 and it worked like a charm.  It seems there is a DPI limit for Tesseract.  

So I went from this:
` shell(shQuote(paste0("pdftopng -f 1 -l 10 -r 600 ", i, " ocrbook")))`

To this:
` shell(shQuote(paste0("pdftopng -f 1 -l 10 -r 150 ", i, " ocrbook")))` I also updated my script to have a more dynamic name, so no overwriting because of static naming.

```

dest <- "C:\\users\\yourname\\desktop"

      files <- tools::file_path_sans_ext(list.files(path = dest, pattern = "pdf", full.names = TRUE))
        lapply(files, function(i){
          shell(shQuote(paste0("pdftoppm -f 1 -l 10 -r 150 ", i,".pdf", " ",i)))
          })
      
      
      myppms <- tools::file_path_sans_ext(list.files(path = dest, pattern = "ppm", full.names = TRUE))
        lapply(myppms, function(y){
          shell(shQuote(paste0("magick ", y,".ppm"," ",y,".tif")))
          file.remove(paste0(y,".ppm"))
          })
  
      mytiffs <- tools::file_path_sans_ext(list.files(path = dest, pattern = "tif", full.names = TRUE))
        lapply(mytiffs, function(z){
          shell(shQuote(paste0("tesseract ", z,".tif", " ",z)))
          file.remove(paste0(z,".tif"))
          })

``` In addition to the above, make sure image magick has a specified DPM.  So for the Image Magick part of the script, the options need to include "-density 300" or something of that nature.

Like such (along with a multitude of other options)
```
      myppms <- tools::file_path_sans_ext(list.files(path = dest, pattern = "ppm", full.names = TRUE))
        lapply(myppms, function(y){
          shell(shQuote(paste0("magick -colorspace gray ", y,".ppm","  -density 300 -depth 8 -flatten -auto-orient -auto-level -rotate -90^> +dither -colors 2 -normalize"," ",y,".tif")))
          file.remove(paste0(y,".ppm"))
          })
```  Is it possible to create a trainned data without the tesstrain.sh script in wiindows?  ### Environment

* **Tesseract Version**: Current main repository (4.00.00alpha)
* **Platform**: Windows7 32-bit

### Current Behavior:
Its recognize Arabic Characters and can not recognize Arabic numbers (ارقام عربى 0123456789)
I tried tessdata, tessdata_best, and tessdata_fast

### Expected Behavior:

### Suggested Fix:
 Did you try Arabic.traineddata? @amitdo yes It is recognize the characters (80% included the Latin numbers) and it does not recognize the Arabic numbers inside the red rectangle (the original without red rectangle )    
![my-national-identity-card-1-728](https://user-images.githubusercontent.com/32733104/32214667-4bf382c8-be28-11e7-9dc5-f415a7a4a02e.jpg)

I tried other pics with numbers only and i got no numbers
![arabnum](https://user-images.githubusercontent.com/32733104/32214946-29824b06-be29-11e7-9858-a5649222e41b.jpg)
![page0001](https://user-images.githubusercontent.com/32733104/32214999-5102d146-be29-11e7-8381-354b6ecebccf.jpg)


 @Shreeshrii @theraysmith Is there a changes handle all these issues but the repositories did not update yet or there is no fix ? ### Definition
* **AEN** Arabic Eastern Numbers {ِ123456789}
* **AWN** Arabic Western Numbers {0123456789}

I generated an experimental data file for recognaize **AEN Only**
The output of Tesseract OCR will be in the form of **AWN**

[https://github.com/ahmed-tea/tessdata_Arabic_Numbers](url)

@Shreeshrii @theraysmith The succeed rate for the pics above 100% (numbers only) but it depends on the pic quality in general

Combining with ara
****- current tesseract main repository** :** give an error (mgr->GetComponent(TESSDATA_INTTEMP, &fp):Error:Assert failed:in file classify\adaptmatch.cpp, line 537)
**- tesseract build by UB Mannheim :** give numbers only
**- best and fast (ara and Arabic) :** not applicable because they used for LSTM only so it give numbers only 

@Shreeshrii  @Shreeshrii  sorry for the question, how to combine the new tessdata_Arabic_Numbers with the current one?
I copied ara_number.traineddata into tessdata dir then I use this command:
`tesseract -l ara_number+ara  image.tif out.txt`

but doesn't work
 @Fahad-Alsaidi You can't combine it with ara   Hello,
with the help from @Shreeshrii  I could create box-files for improving the existing eng.traineddata for my purpose.

I could use these box files to create a new eng.traineddata. It works and is much better for reading my text. However, when I want to use this new eng.traineddata to create box files for new images, it fails with

read_params_file: Can't open makebox

If I leave everything else identical, but switch to the original eng.traineddata, everything works, and the boxes are created.

New Traineddata:
Version string:4.00.00alpha:eng:synth20170629:[1,36,0,1Ct3,3,16Mp3,3Lfys64Lfx96Lrx96Lfx512O1c1]
17:lstm:size=11689099, offset=192
18:lstm-punc-dawg:size=4322, offset=11689291
19:lstm-word-dawg:size=3694794, offset=11693613
20:lstm-number-dawg:size=4738, offset=15388407
21:lstm-unicharset:size=6360, offset=15393145
22:lstm-recoder:size=1012, offset=15399505
23:version:size=80, offset=15400517


Original Traineedata
Version string:4.00.00alpha:eng:synth20170629:[1,36,0,1Ct3,3,16Mp3,3Lfys64Lfx96Lrx96Lfx512O1c1]
17:lstm:size=11689099, offset=192
18:lstm-punc-dawg:size=4322, offset=11689291
19:lstm-word-dawg:size=3694794, offset=11693613
20:lstm-number-dawg:size=4738, offset=15388407
21:lstm-unicharset:size=6360, offset=15393145
22:lstm-recoder:size=1012, offset=15399505
23:version:size=80, offset=15400517


What did I do wrong?

Do you need more info? The script to create the boxes (thaks to @Shreeshrii !) is attached.


Thanks & kind regards
Ernst
Thanks 

 [makebox.txt](https://github.com/tesseract-ocr/tesseract/files/1420017/makebox.txt)
Script to make the boxes attached
 @Shreeshrii  Thank you very much for the fast help, that was the problem!
Kind regards
Ernst  
### Environment

* **Tesseract Version**:3.05 <!-- compulsory. you must provide your version -->

* **Platform**: windows 10<!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->

### Current Behavior:
I can compile it successfully in my this computer yesterday by such command
```
cppan
mkdir build && cd build
cmake ..
```
But after I reinstall the system today, it will give me such error information

> LINK : fatal error LNK1104: cannot open file “Debug\unicharset training.lib

But I cannot search any information about it. Can anybody can tell me something?  ### Environment

* **Tesseract Version**: 3.05<!-- compulsory. you must provide your version -->
* **Platform**: Microsoft Windows [version 10.0.15063]<!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->

### Current Behavior:
After build the *Tesseract* with [this method](https://github.com/tesseract-ocr/tesseract/wiki/Compiling#develop-tesseract). Then my `build/bin/Debug` directory contain this files:
```
    eng.traineddata
    phototest.tif
    pvt.cppan.demo.behdad.harfbuzz-1.5.1.dll
    pvt.cppan.demo.bzip2-1.0.6.dll
    pvt.cppan.demo.cairographics.cairo-1.15.6.dll
    pvt.cppan.demo.danbloomberg.leptonica-1.74.4.dll
    pvt.cppan.demo.expat-2.2.4.dll
    pvt.cppan.demo.freedesktop.fontconfig.fontconfig-2.12.1.dll
    pvt.cppan.demo.freetype-2.8.1.dll
    pvt.cppan.demo.gnome.glib.glib-2.50.3.dll
    pvt.cppan.demo.gnome.glib.gobject-2.50.3.dll
    pvt.cppan.demo.gnome.pango.pango-1.40.9.dll
    pvt.cppan.demo.gnome.pango.pangocairo-1.40.9.dll
    pvt.cppan.demo.gnome.pango.pangoft2-1.40.9.dll
    pvt.cppan.demo.gnu.gettext.intl-0.19.8.dll
    pvt.cppan.demo.gnu.iconv.libcharset-1.15.0.dll
    pvt.cppan.demo.gnu.iconv.libiconv-1.15.0.dll
    pvt.cppan.demo.jpeg-9.2.0.dll
    pvt.cppan.demo.madler.zlib-1.2.11.dll
    pvt.cppan.demo.openjpeg.openjp2-2.1.2.dll
    pvt.cppan.demo.pcre.pcre-8.40.0.dll
    pvt.cppan.demo.png-1.6.30.dll
    pvt.cppan.demo.tiff-4.0.8.dll
    pvt.cppan.demo.unicode.icu.common-59.1.0.dll
    pvt.cppan.demo.unicode.icu.data-59.1.0.dll
    pvt.cppan.demo.unicode.icu.i18n-59.1.0.dll
    pvt.cppan.demo.webp-0.6.0.dll
    pvt.cppan.demo.weltling.winlibs.libffi-3.2.1.dll
    pvt.cppan.demo.xz_utils.lzma-5.2.3.dll
    tesseract.exe
    tesseract.ilk
    tesseract.pdb
    tesseract400d.dll
    tesseract400d.ilk
    tesseract400d.pdb
```
I can run it in commandline now
`tesseract.exe phototest.tif stdout`

> Page 1
> This is a lot of 12 point text to test the
> ocr code and see if it works on all types
> of file format.
> 
> The quick brown dog jumped over the
> lazy fox. The quick brown dog jumped
> over the lazy fox. The quick brown dog
> jumped over the lazy fox. The quick
> brown dog jumped over the lazy fox.
> 

### Expected Behavior:
I hope to run it with code method, such as [this](https://github.com/tesseract-ocr/tesseract/wiki/APIExample#basic-example), but not in commandline. If I can get all `.lib`, then I can build a new project and import to use it. But I get few `.lib` and most `.dll`...So how to use it by [this code method](https://github.com/tesseract-ocr/tesseract/wiki/APIExample#basic-example)? @zdenop Help pleaase [here](https://groups.google.com/forum/#!topic/tesseract-ocr/WrwwaZsm9CY), it is confused me some days  ### Environment

* **Tesseract Version**: 
Tesseract Open Source OCR Engine v4.00.00dev-692-gad5ee184 with Leptonica

* **Platform**: 
Platform: Linux 4.9.43-17.39.amzn1.x86_64 #1 SMP x86_64 GNU/Linux


### Current Behavior:

The following command will crash in the above stated environment:
tesseract /tmp/tr_tmp.jpg /tmp/tr_tmp --tessdata-dir /var/task/tessdata --psm 12 --oem 2 -l eng hocr

tessdata is legacy data from tesseract-ocr/tessdata

Crash error: Assert failed:in file ../ccutil/unicharset.h, line 513

related jpg file: 
![c767234e7e51a92ee5a9c211f5892ad66b990e75-2](https://user-images.githubusercontent.com/399202/31865534-f08d1728-b73d-11e7-91b1-a31002dd1061.jpg)

related binaries:
[Archive.zip](https://github.com/tesseract-ocr/tesseract/files/1405268/Archive.zip)


### Expected Behavior:

When tesseract v4 using `--oem 2` and legacy trained data, error message of missing LSTM data should be printed instead of crashing.

### Suggested Fix:

n/a Thanks for the update. Where can I get the 'latest traineddata' please? I got my data from https://github.com/tesseract-ocr/tessdata/
 Thanks for your reply. Just to be rigid. I was using tessdata, which supports oem mode 2 according to the wiki. >The latest traineddatas (tessdata_best and Tessdata_fast) do not support legacy tesseract engine, so --oem 0 and --oem 2 are not supported.

Although I wrote something similar to the above remark in the wiki, since commits [1] and [2]. `--oem 0 -l osd` works with 'best' and 'fast'. Not sure about --oem 2.

[1] https://github.com/tesseract-ocr/tessdata_best/commit/f1d12682c0f1afe61db892f4b2bfaa7909ad7a59 
[2] https://github.com/tesseract-ocr/tessdata_fast/commit/139ff127aaee3cb0270fd29411fec75d610d728c
 Since the discussion is a bit side-tracked, I'm repeating the problem. The original comment is also updated.

Tesseract v4.00.00dev-692-gad5ee184 crashes when using `--oem 2` and `tesseract-ocr/tessdata`. The master branch (commit ad5ee18415bf59b9f5d1fd1806cb3aad3f18f381) runs good with your image @TerryZH 

However, tesseract should not crash
 @PaniniGelato Are you sure? As reported in the "Environment" section, this crash happens on the build from master commit ad5ee18. And I can still reproduce the crash. Did you use the same tessdata as described in my previous comment?  Hi,

i was using the newest versions of Tesseract to:
1- create LSTMFs
2- extract the LSTM from official traineddata
3- fine tune the LSTM according to the created LSTMFs
4- and then use the new traineddata for detection for better results
i was able to do all these steps and get the final traineddata but when i made detection using it i got an error, now the same case happened for Arabic and Japanese languages, and both i was able to get fine tuned traineddata and both failed in detection and gave the same error.
the commands i used as described [here](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#lstmtraining-command-line)
and they were: 
**for creating LSTMFs**
training/tesstrain.sh --fonts_dir ~/.local/share/fonts --lang ara --linedata_only --noextract_font_properties --langdata_dir /home/ibr/latest_leptonica_4/langdata --tessdata_dir ./tessdata --output_dir /home/ibr/latest_leptonica_4/lstmf_ara_lep4

**extracted LSTM from [*here*](https://github.com/tesseract-ocr/tessdata_best)

**tuned LSTM**
training/lstmtraining --model_output /home/ubuntu/lep_latest/ara_tune/tune_result/ara_tune \
  --continue_from /home/ubuntu/lep_latest/ara_tune/extracted/ara.lstm \
  --traineddata /home/ubuntu/lep_latest/ara_tune/original_traineddata/ara.traineddata \
  --train_listfile /home/ubuntu/lep_latest/ara_tune/ara.training_files.txt \
  --max_iterations 1200

**then unpacked official traineddata"official traineddata", replaced the tuned LSTM and combined everything together again **

**detection command**
tesseract ara2.png tuned -l ara --tessdata-dir ./tessdata --oem 1

and when i used the new tuned traineddata i got the error:
**index >= 0:Error:Assert failed:in file strngs.cpp, line 270
Segmentation fault (core dumped)** 

that happened when i tried fine tuning for Arabic and Japanese, twice, first time using the version:
**tesseract 4.00.00dev-690-g1b0379c   leptonica-1.74.4**
second time: **tesseract 4.00.00dev-691-gfb359fc  leptonica-1.74.4**

_keep im mind the same exact steps worked for previous versions of tesseract with leptonica 1.74.1_

**NOTE: detection worked fine with both versions for the official traineddata, meaning the error only occurred only after fine tuning**

Thanks in advance @Shreeshrii sorry, my mistake, i forgot to mention the command to create the LSTM from the check point which is:
_training/lstmtraining --model_output /home/ibr/latest_leptonica_4/ara_tune/tuned_lstm/ara.lstm --continue_from /home/ibr/latest_leptonica_4/ara_tune/results/ara_checkpoint --traineddata /home/ibr/latest_leptonica_4/ara_tune/original_traineddata/ara.traineddata --stop_training_

now, summarize everything,
**i create LSTMFs
extract LSTM from "best_traineddata"
tune LSTM according LSTMFs , in the command " --traineddata  best_traineddata"
create LSTM from checkpoint,  in the command " --traineddata  best_traineddata"
unpack  "best_traineddata"
replace LSTM with the new tuned one
combine everything**

"If you combine your fine-tune lstm with existing traineddata, the files
will not be in sync"
means in combination step i have to combine the new LSTM with the traineddata (starter traineddata) that is created when creating LSTMFs? 
i used "best_traineddata" in the command
_training/lstmtraining --model_output /home/ubuntu/lep_latest/ara_tune/tune_result/ara_tune 
--continue_from /home/ubuntu/lep_latest/ara_tune/extracted/ara.lstm 
--traineddata /home/ubuntu/lep_latest/ara_tune/original_traineddata/ara.traineddata 
--train_listfile /home/ubuntu/lep_latest/ara_tune/ara.training_files.txt 
--max_iterations 1200_
because if i pointed the --traineddata to the traineddata that is created with LSTMFs (starter traineddata)
i will get this message:
**Warning: LSTMTrainer deserialized an LSTMRecognizer!
Code range changed from 307 to 74!
Must supply the old traineddata for code conversion!
Failed to continue from: /home/ibr/latest_leptonica_4/ara_tune/extracted/ara.lstm
**
so since i got "Must supply the old traineddata" i used the trained data from "best_traineddata" the whole time, so what im missing?
Thanks
 the last two command actually worked and the traineddata i created is fine, i changed the first command to:
_training/lstmtraining --model_output /home/ubuntu/lep_latest/test/tuning_results/jpn \
  --continue_from /home/ubuntu/lep_latest/jpn_tune/extracted/jpn.lstm \
  --traineddata /home/ubuntu/lep_latest/jpn_tune/jpn_lstmf/jpn/jpn.traineddata \
  --old_traineddata /home/ubuntu/lep_latest/jpn_tune/original_traineddata/jpn.traineddata \
  --train_listfile /home/ubuntu/lep_latest/jpn_tune/jpn.training_files.txt \
  --max_iterations 3600_
but this command was in "Fine Tuning for ± a few characters" section, in my case i want only to train the best_traineddata to a new fonts only without changing it so i assumed that i needed to go though fine tuning but it didn't work, so does this tuning command covers it? 

also another question, when i run the above command sometime i get the message **checkpoint failed to write checkpoint**  when that message shows following command fails:
_training/lstmtraining --stop_training \
  --continue_from /home/ubuntu/lep_latest/test/tuning_results/jpn13.689_2618.checkpoint \
  --traineddata /home/ubuntu/lep_latest/jpn_tune/jpn_lstmf/jpn/jpn.traineddata \
  --model_output /home/ubuntu/lep_latest/test/traineddata/jpn.traineddata_
what causing this message to show?

Thanks  I meet a error while building training tools from source(4.0 master)
First, I build the tesseract-ocr which is successful.
1 yum install autoconf automake libtool libjpeg-devel libpng-devel libtiff-devel zlib-devel
2 build leptonica from source(leptonica-1.74.4)
3 build tesseract-ocr
   ./autogen.sh
  ./configure --prefix=/usr/local/tesseract --with-extra-libraries=/usr/local/leptonica/lib   
  make
  make install
--------------------------
Then I try to build training tools
1 yum install libicu-devel
2 yum install pango-devel
3 yum install cairo-devel
make training
But it comes the following error

`depbase=`echo boxchar.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../lstm -I../arch -I../viewer -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil  -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib64/glib-2.0/include   -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib64/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng15 -I/usr/include/libdrm    -g -O2 -std=c++11 -MT boxchar.lo -MD -MP -MF $depbase.Tpo -c -o boxchar.lo boxchar.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../lstm -I../arch -I../viewer -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib64/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib64/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng15 -I/usr/include/libdrm -g -O2 -std=c++11 -MT boxchar.lo -MD -MP -MF .deps/boxchar.Tpo -c boxchar.cpp  -fPIC -DPIC -o .libs/boxchar.o
boxchar.cpp: In member function 'void tesseract::BoxChar::GetDirection(int*, int*) const':
boxchar.cpp:67:42: error: 'U_RIGHT_TO_LEFT_ISOLATE' was not declared in this scope
         dir == U_ARABIC_NUMBER || dir == U_RIGHT_TO_LEFT_ISOLATE) {
                                          ^
make[1]: *** [boxchar.lo] Error 1
make[1]: Leaving directory `/home/lixl/workspace/tesseract/tesseract-ocr/training'
make: *** [training] Error 2`

What's wrong with my work, any advice?
My OS is centos 7 I change the OS to Ubuntu and it seems OK.
Thanks for the reply and please close the issues  ------------------------

### Environment

* **Tesseract Version**: Tesseract Open Source OCR Engine v4.00.00dev-692-gad5ee184 with Leptonica
* **Platform**: Linux 4.9.43-17.39.amzn1.x86_64 #1 SMP x86_64 GNU/Linux


### Current Behavior:
Command '['tesseract', '/tmp/tr_tmp.jpg', '/tmp/tr_tmp', '--tessdata-dir', '/var/task/tessdata', '--psm', '12', '--oem', '2', '-l', u'eng', 'hocr']' returned non-zero exit status -11: CalledProcessError
Traceback (most recent call last):
File "/var/task/lambda_function.py", line 22, in lambda_handler
**event
File "/var/task/lib/ocr/common/procedures.py", line 105, in recognize
scanned = scanner.scan_jpg(swabbed, file_desc['pagenum'], **kwargs)
File "/var/task/lib/ocr/common/scanner.py", line 62, in scan_jpg
'hocr',
File "/usr/lib64/python2.7/subprocess.py", line 541, in check_call
raise CalledProcessError(retcode, cmd)
CalledProcessError: Command '['tesseract', '/tmp/tr_tmp.jpg', '/tmp/tr_tmp', '--tessdata-dir', '/var/task/tessdata', '--psm', '12', '--oem', '2', '-l', u'eng', 'hocr']' returned non-zero exit status -11

### Expected Behavior:
no crash

### Suggested Fix:
   Environment
I'm currently using tess-two version 8.0.0

Current Behavior:
I've tested my app at several images. Actually some of them worked very nice. But the issues starts when i take a picture from water metering which contains of numbers. The tesseract doesn't recognize it and instead of returning it as numbers, it gave me random words. Also, when i've done with the recognition, the memory didn't release. So, here's my question:
 
1. How can i release the memory after the recognition, and 
2. How can i improve the reading when the text is coming from the water metering?

Expected Behavior:
1. The memory will be released (so i can save up to 30 MB)
2. The OCR works on Water metering (at least up to 75%)
  Hello,
thanks for creating Tesseract 4.0.
I have problems creating the box files correctly (where should the tab go?) and get error messages from LSTM training.

There is a link for an example Box File in github, but it is not working any more (https://github.com/tesseract-ocr/tesseract/wiki/Making-Box-Files---4.0 the links on this page are broken). Could you please publish a working *.box and a corresponding *.tif file for LSTM-Training?

Thanks & kind regards
Ernst @Shreeshrii  thank you very much for your files!!!! I used tesstrain.sh, but did not look into /tmp. Shame on me!
I could not get tesseract to create box files. I used

tesseract pol.ocrb.exp$i.tif pol.ocrb.exp$i batch.nochop makebox

as described, but it created a file called batch.nochop.box, but not the box file I expected (an old style box file would be OK)

Thanks,
Ernst @Shreeshrii thank you very much, that works for me also, that is great!!!
I do not know why the original calls (and I tried many) did not work. 
Kind regards
Ernst
  I want to fine tune with tesseract 4.0, and I just have  *.tif and *.box these two files,
I don't know how to generate *.lstmf files.

The wiki just says like this :
"The training data is provided via .lstmf files, which are serialized DocumentData They contain an image and the corresponding UTF8 text transcription, and can be generated from tif/box file pairs using Tesseract in a similar manner to the way .tr files were created for the old engine."

but it doesn't give the command to generate *.lstmf files.
So, I hope someone can help me, thanks very much ! @minly ,@CoCa520 , @Shreeshrii  @Shreeshrii, I have change the format box files according to the requirements of tesseract 4.0 ,  namely  I add a TAB at end of line and spaces to demarcate words for the  box files.

could you tell me how to use new format box/tiff pairs to generate *.lstmf files? Thanks!

 @Shreeshrii I changed the tesstrain.sh file and the command could copy the box/tiff pairs to the tmp training directory.
but there was another error as following:

$ training/tesstrain.sh --lang eng --linedata_only  --langdata_dir ../langdata --tessdata_dir ./tessdata --output_dir ../result

=== Starting training for language 'eng'
total 6068
-rwxrw-r-- 1 penny penny   66188 Oct 18 19:24 eng.num.exp0.box
-rwxrw-r-- 1 penny penny 6136385 Oct 18 19:24 eng.num.exp0.tif
-rw-rw-r-- 1 penny penny      42 Oct 18 19:24 tesstrain.log
[Wed Oct 18 19:24:13 CST 2017] /usr/local/bin/text2image --fonts_dir=/usr/share/fonts/ --font=Arial Bold --outputbase=/tmp/font_tmp.fGYz2L7fuF/sample_text.txt --text=/tmp/font_tmp.fGYz2L7fuF/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.fGYz2L7fuF
Could not find font named Arial Bold.
Pango suggested font FreeSerif Bold.
Please correct --font arg.

=== Phase I: Generating training images ===
ERROR: Could not find training text file ../langdata/eng/eng.training_text


it couldn't find 'eng.training_text' file, do you know what the 'eng.training_text' file is ?   

Additionally, the command 'text2image' is used to generate tiff images according to text and fonts, but we have already had box/tiff pairs, so  why it excute the command 'text2image' again ? 
Should I change other script files to resolve these problems?

I'm looking forward to your reply! Thanks a lot!









 @Shreeshrii, with your help, I generated the *.lstmf files! Thanks a lot! @Shreeshrii but now there is a new problem like this:

$ tesseract  eng.num.exp1.tif  eng.num.exp1  lstm.train
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Warning. Invalid resolution 0 dpi. Using 70 instead.
Estimating resolution as 395
Empty page!!
Estimating resolution as 395
Empty page!!

there are several images will generate this error, do you know why it appears "Empty page!!"? Have you ever seen this kind of mistake? @Shreeshrii, the tif files are OK, and every tif image has the warning, for example:

$ tesseract eng.num.exp2.tif eng.num.exp2  lstm.train
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Warning. Invalid resolution 0 dpi. Using 70 instead.
Estimating resolution as 369

Although it has the warning "Warning. Invalid resolution 0 dpi. Using 70 instead.", but after the command, the *.lstmf file could be generated correctly. So I guess the warning is not the truly problem.

And if a tif image has the "Empty page!!" error, the *.lstmf file would not be generated! So, I guess the problem is the "Empty page!!" error. But I don't know how to resolve the problem, hope  for your help , thanks!!! @Shreeshrii, I resolved the problem, I just add " -psm 7 nobatch" to the command like this:
$ tesseract eng.num.exp2.tif eng.num.exp2 -psm 7 nobatch lstm.train
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Warning. Invalid resolution 0 dpi. Using 70 instead.

then, the error "Empty page!!" was disappeared. and finally the *.lstmf file was generated correctly! @Shreeshrii, You're welcome! the command is also right without "nobatch", just as the following:

$ tesseract eng.num.exp2.tif eng.num.exp2 -psm 7 lstm.train
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Warning. Invalid resolution 0 dpi. Using 70 instead.

Dou you know the function of "nobatch" ? Have you used it in tesseract command ? 
Looking forward to your reply! Thanks! @Shreeshrii, OK, Thanks~^_^~ @Shreeshrii ,when I use Chinese character box/tiff pairs to fine tune,  there was a new problem as the following:

$ unicharset_extractor chi_sim.black.exp0.box
Extracting unicharset from box file chi_sim.black.exp0.box
Invalid Unicode codepoint: 0xffffffe4
IsValidCodepoint(ch):Error:Assert failed:in file normstrngs.cpp, line 225
Segmentation fault (core dumped)

have you ever seen this problem? 
Looking forward to your reply! Thanks!

 @Shreeshrii
i will generacte *.lstmf ,and run  **tesseract ./tif_box/eng.exp0.tif ./tif_box/eng.exp0     lstm.train**  ,then I got eng.exp0.txt eng.exp0.lstmf but   the  "eng.exp0.txt" nothing  any char 
box file and tif file is ok  

run lstmtraining, i got a error 
_Deserialize header failed: ~/tesstutorial/tif_box/eng.exp0.lstmf
Load of page 0 failed!
Load of images failed!!_
I guess my *.lstmf file is incorrect

ps: box , tif file form jTessBoxEditor, not  from text2image command

please give me a suggestion
  @Shreeshrii
--sequential_training true   
then i got 
First document cannot be empty!!
num_pages_per_doc_ > 0:Error:Assert failed:in file imagedata.cpp, line 658

  Hi,

i have installed Tesseract: 4.00.00dev-690-g1b0379c with Leptonica:  1.74.4 and its working fine with the detection and all, but i have noticed that the performance is slower than before (comparing with 5 months ago tesseract, and leptonica 1.74.1).

in the past the time was around 4 or 5 seconds but lately its almost the double, that command that im using is the normal tesseract detection command which is: **tesseract image results -l lang--tessdata-dir ./tessdata --oem 1 ** , so am i missing something or is there some sort of a parameter that i should add after the updates to the tesseract or leptonica? or any other way to enhance  the performance speed? (for both single thread case or multi thread case)

Thank you > Slower Performance in Latest Tesseract

It's not clear if you're comparing a newer 4.00 to older 4.00 or 4.00 to 3.05. Also, do you use the newest traineddata for 4.0?  >or any other way to enhance the performance speed? (for both single thread case or multi thread case)

If you use multi-threading  try disabling OpenMP.
`OMP_THREAD_LIMIT=1 tesseract in.png out --oem 1`

. @amitdo actually im comparing the latest (4.00.00dev-690-g1b0379c with Leptonica: 1.74.4 ) with the older version (4.00.00dev-549-g2b854e3 with leptonica 1.74.1)

@Shreeshrii  "tessdata_fast" is a news to me, i'm already using the official traineddata, but i dont know about this one, can you please give me the link to it?, also i already created a tuned LSTM, can i also combine it with the new tessdata_fast as well?

Thank you both The latest traineddata files are at https://github.com/tesseract-ocr/tessdata_best and https://github.com/tesseract-ocr/tessdata_fast. But if you want to compare the performance of an older Tesseract 4.00 with the latest version, you will have to use the same traineddata for both, usually from https://github.com/tesseract-ocr/tessdata. I'd disable multithreading for the test (set environment variable `OMP_THREAD_LIMIT=1`). @Shreeshrii so i assume that if i fine tuned an LSTM file (made by older version tools) it won't combine with the new traineddate?  (for example a traineddata from: https://github.com/tesseract-ocr/tessdata_best) 
also you mean by "data for your fine tuning" as the following?
![1](https://user-images.githubusercontent.com/26926171/31716984-deb8cc32-b412-11e7-8fa7-f0c27132275d.png)
and the steps in the link that you have shared are to enhance accuracy, detection speed or both?

@stweil  the difference between "tessdata_best" and "tessdata_fast" is the accuracy vs speed? meaning "tessdata_fast" will be faster in detection but wont be accurate as "tessdata_best" ?

Thanks for the answers >  the difference between "tessdata_best" and "tessdata_fast" is the accuracy vs speed? meaning "tessdata_fast" will be faster in detection but wont be accurate as "tessdata_best" ?

`tessdata_fast` is faster than `tessdata_best`, yes.
`tessdata_best` is generally better, but not always. I also noticed cases where `tessdata_fast` is better. And there are even [cases](https://github.com/cisocrgroup/Resources/tree/master/ocrtestset/german/1841-DieGrenzboten) where the old Tesseract gives the best recognition rates of all current tessdata. if i wanted to fine tune using the tool "lstmtraining" while i'm using the latest Tesseract: (4.00.00dev-690-g1b0379c) can i use .lstmf files (which are generated by tesstrain.sh)file that are created by older Tesseract version, such as (4.00.00dev-549-g2b854e3) ?
meaning are lstmf files compatible between tesseract versions? thanks  Try re-building with `./configure --disable-graphics` ... or simply hide or remove `scrollview`, so it won't be run.  Hi, I'm trying to train a new tesseract chinese dictionary using jTessBoxEditor. 
The tool creates all files necessary to train tesseract. 
I have 273 character to train. During the training I have this error for only two character of them:

** Moving generated traineddata file to tessdata folder **
** Training Completed **
** Run Tesseract for Training **
[C:\Users\allvilardi\Downloads\jTessBoxEditorFX-2.0-Beta\jTessBoxEditorFX\tesseract-ocr/tesseract, CT_calibri.calibri.exp0.tif, CT_calibri.calibri.exp0, box.train]
Tesseract Open Source OCR Engine v4.0.0-alpha.20170804 with Leptonica
Page 1
FAIL!
APPLY_BOXES: boxfile line 45/四 ((1061,3024),(1124,3082)): FAILURE! Couldn't find a matching blob
FAIL!
APPLY_BOXES: boxfile line 125/盤 ((1092,2680),(1164,2751)): FAILURE! Couldn't find a matching blob
APPLY_BOXES:
   Boxes read from boxfile:     273
   Boxes failed resegmentation:       2
   Found 271 good blobs.
Generated training data for 28 words


I've changed also the box manually on those two charachter, but without success. On a Box gui, the boxes seems to be fine.
Does anyone know how to fix that problem? 
ps. I have this error also on korean characters, for all the characters. 

This are the grafic boxes on those character:
  
![image](https://user-images.githubusercontent.com/18304893/31346813-a6aee654-ad1a-11e7-884a-859771e46ed1.png)

Anyone could help me? Thanks.
 I have the same problem with arabic language
** Run Tesseract for Training **
[K:\train tesseract\jTessBoxEditor\tesseract-ocr/tesseract, ara.mylotus.exp0.tif, ara.mylotus.exp0, box.train]
Tesseract Open Source OCR Engine v4.0.0-alpha.20170804 with Leptonica
Page 1
row xheight=23, but median xheight = 30.5
APPLY_BOXES: boxfile line 6/ق ((2324,3143),(2338,3173)): FAILURE! Couldn't find a matching blob
APPLY_BOXES: boxfile line 7/ع ((2303,3119),(2334,3157)): FAILURE! Couldn't find a matching blob
....
..
.
.

APPLY_BOXES:
   Boxes read from boxfile:     888
   Boxes failed resegmentation:     176 Actually i'm already using v 4 as it showing in the training message log
Tesseract Open Source OCR Engine v4.0.0-alpha.20170804 with Leptonica I have the same problem. In my case I try to train digits from a display.

tesseract day_2_60_0_G3.cfont1.exp0.tif day_2_60_0_G3.cfont1.exp0 -l dianoche2 -psm 7 nobatch box.train

Tesseract Open Source OCR Engine v3.02 with Leptonica

FAIL!
APPLY_BOXES: boxfile line 90/. ((1079,11),(1081,17)): FAILURE! Couldn't find a matching blob
APPLY_BOXES: boxfile line 141/. ((1758,2),(1762,16)): FAILURE! Couldn't find a matching blob
APPLY_BOXES:
   Boxes read from boxfile:     189
   Boxes failed resegmentation:       2
   Found 187 good blobs.
   Leaving 1 unlabelled blobs in 0 words.
TRAINING ... Font name = cfont1
Generated training data for 60 words
![day_2_60_0_g3 cfont1 exp0](https://user-images.githubusercontent.com/32894808/31707084-7cf4769e-b3eb-11e7-8b36-de3d7a503a5b.png)
[day_2_60_0_G3.cfont1.exp0.txt](https://github.com/tesseract-ocr/tesseract/files/1393834/day_2_60_0_G3.cfont1.exp0.txt)

I attach the file in .txt format because I couldn't attach in .box format 

Anyone could help me? Thanks.  ### Environment
* **Tesseract Version**:
```
tesseract 3.05.01
 leptonica-1.74.4
  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8
```
* **Commit Number**: [2158661](https://github.com/tesseract-ocr/tesseract/commit/215866151e774972c9502282111b998d7a053562)
* **Platform**: `Linux Inspiron-530s 4.4.0-96-generic #119-Ubuntu SMP Tue Sep 12 14:59:54 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux`

---

### Current Behavior:
```
dan9er@A-Computer:~/Pictures$ tesseract image.jpg out -c tessedit_write_images=1
Tesseract Open Source OCR Engine v3.05.01 with Leptonica
Warning. Invalid resolution 0 dpi. Using 70 instead.
````

#### **image.jpg**:
![Pill bottle](https://imgur.com/pYjuSCn.png)

#### **tessinput.tif**:
![Black and white image of pill bottle with text "NPN 80051578" sideways](https://imgur.com/SOJFK2f.png)

#### **out.txt**:
```
22%mzzztnztzm 22:“: a $5.35

a
mhmﬁmoowuzgz

.

SEEESaEmS 2:

.32 8:325
§o3WK<S

 

```

---

### Expected Behavior:

#### **tessinput.tif**:
![B&W pill bottle with NPN text right side up](https://imgur.com/Q55k7v1.png)

#### **out.txt**:
```
[junk maybe]

NPN: 80051578

[junk maybe]
```

---

### Suggested Fix:
Add a config tag (`tessedit_rotation_override`?) that overrides the auto-rotation. It could be just 1/0 (never rotate input image if 1) or 0-3 (always rotate by this multiple of 90).

EDIT: I don't know why but turns out the [original image I posted](https://imgur.com/An1Fz1T.png) recognized fine, even though it was still rotated! The majority of my images output junk though, so I replaced the image with one that doesn't work. Oh, and added console output, out.txt and input image Upload the original image.

Write the full command you are using.

What's the output you are getting, including errors messages, if any? Ok, post updated.

I admit I posted this on the Google Groups forum first. But after a week and 2 bumps, no one could give me an answer. So I assumed nobody got around to implementing a way to override this stupid auto-rotation...

EDIT: @tfmorris suggested changing the PSM, but that does nothing:
![A bunch of identical TIFF files](https://imgur.com/Jp30THT.png) >@tfmorris suggested changing the PSM, but that does nothing:

Including the output **text**? You should have osd.traineddata to make some PSMs work properly.
 @amitdo PSM 12 is the only one that works (with the new image), but that's only if I run Tesseract with a config file I made:
```
load_system_dawg        F
load_freq_dawg          F
user_words_suffix       user-words
user_patterns_suffix    user-patterns
tessedit_char_whitelist NP0123456789:#
```
Plus, PSM 12 is described as "Sparse text *with OSD*". @tfmorris said it's the OSD that's doing the rotation.
And, if OSD is disabled for some of the PSMs, then why are ALL of the TIFF files rotated?

EDIT: "Works" as in the only output that isn't junk. @Shreeshrii Well, is there any way to disable that rotation and force tesseract to recognise the unrotated image? Well if I give Tesseract a horizontal image of the bottle, tessinput.tif is not rotated. Upon closer inspection of the images that do not OCR correctly, **it looks like the binarization algorithm is the real culprit here**. Tesseract doesn't seem to care about the rotation of the text. Anyway, I don't think this is a problem with Tesseract itself so I'm closing this Issue. Some weird **** is going on here. It may be Leptonica, the `tessedit_write_images` code, or even Ubuntu that is rotating the image after Tesseract spits it out.

If I find anything I'm going to post in [this Google Groups thread](https://groups.google.com/forum/#!topic/tesseract-ocr/GAbzk9BTGDE). It is Leptonica that is causing this to happen. Submitting an issue on there rn.

Not reopening this since there is nothing the Tesseract devs can do here, this is a Leptonica issue.  I am getting compile errors when compiling my bindings with `clang++ -std=gnu++11` (MacOS 12.13). This fixes it for me. See pull request #1082 and other pull requests and issues which address the same problem.  I must confess to not being a CMake expert, but I found [this mailing list post](https://cmake.org/pipermail/cmake-developers/2016-May/028364.html) that seems to confirm my suspicion that the `FindPkgConfig` module doesn't fix up the library search path to allow linking against the libraries it has found.

N.B.: I also needed https://github.com/DanBloomberg/leptonica/pull/282 to get this compiling on macOS. In general, unless you compile on Windows with MSVC, you should use autotools to build Leptonica and Tesseract.

CC: @egorpugin   I have refered solutions like below:

    https://stackoverflow.com/questions/30932120/tesseract-assert-failed-trainingsampleset-cpp-line-622-with-mftraining
    https://stackoverflow.com/questions/18921810/assert-failed-training-tesseract
    https://groups.google.com/forum/#!topic/tesseract-ocr/3e4dV373u_o

But they do not work at all!

I checked font_properties yet.

Here is the [case](https://github.com/nagexiucai/milk-powder/commit/cd0aed443af6aa084da721d48bd107e92934544d) of mine:

    https://github.com/nagexiucai/milk-powder/commit/cd0aed443af6aa084da721d48bd107e92934544d

### Environment

* **Tesseract Version**:  OCR Engine v3.02 with Leptonica
* **Commit Number**: unnkown
* **Platform**: Win7x86-64

### Current Behavior:
    Reading .\pictures\chi_sim.CHei_PRC.exp0.tr ...
    Font id = -1/0, class id = 2/132 on sample 0
    font_id >= 0 && font_id < font_id_map_.SparseSize():Error:Assert failed:in file ..\..\classify\trainingsampleset.cpp, line 622

### Expected Behavior: pass

### Suggested Fix:
none Here is the [details](https://github.com/nagexiucai/milk-powder/blob/master/README.md)!

https://github.com/nagexiucai/milk-powder/blob/master/README.md  ### Environment

* **Tesseract Version**: 
tesseract 4.00.00alpha
 leptonica-1.74.4
  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8

 Found AVX2
 Found AVX
 Found SSE
* **Platform**: ubuntu 16.04

### Current Behavior:

I'm trying to fine tune chi_sim.traineddata with a new font , the command is as follow:

```
./training/tesstrain.sh --fonts_dir /usr/share/fonts \
--lang chi_sim \
--linedata_only \
--noextract_font_properties \
--langdata_dir /home/yuanhao/workspace/langdata/langdata-master \
--tessdata_dir /home/yuanhao/workspace/tessdata \
--fontlist "STXihei" \
--output_dir /home/yuanhao/workspace/tesstutorial/chi_sim_eval &> ~yuanhao/logs/tesstrain.log
```
the log file:
[tesstrain.log](https://github.com/tesseract-ocr/tesseract/files/1328173/tesstrain.log)

and then run
```
lstmtraining --model_output ~yuanhao/workspace/tesstutorial/stxihei_from_full/stxihei \
--continue_from ~yuanhao/workspace/tesstutorial/stxihei_from_full/chi_sim.lstm  \
--traineddata ~yuanhao/workspace/tesstutorial/chi_sim.traineddata  \
--train_listfile ~yuanhao/workspace/tesstutorial/chi_sim_eval/chi_sim.training_files.txt   \
--eval_listfile ~yuanhao/workspace/tesstutorial/chi_sim_eval/chi_sim.training_files.txt	\
--target_error_rate 0.01	&> ~yuanhao/logs/lstmtraining.log
```
the training lasts for sereval days .  but the error rate doesn't improve any more. the console output says  “Divergence! Reverted to iteration 96/100/100 ” again and again.   

lstmtraining.log: 
[lstmtraining111.log](https://github.com/tesseract-ocr/tesseract/files/1328193/lstmtraining111.log)

Is it normal, or is there something wrong?

 @Shreeshrii  thanks for you reply
1.commit id is :  9c2fa0d
2.I've  tried  --max_iteration 3000 before,  the result is not good, so I use --target_error_rate 0.01 instead
3.I use the default training text: https://github.com/tesseract-ocr/langdata/blob/master/chi_sim/chi_sim.training_text    and only one font is needed
4.I'm trying to make tesseract recognize a particular type of Chinese font "STXihei" better. It seems that it's a typical scenario for using fine tune(new-font-style). Should I try to replace a layer?  ### Environment

* **Tesseract Version**: <4.00.00alpha>
* **Platform**: <ubuntu 14, 64bits>

### Current Behavior:
in command line , I input "tesseract ", we can see the "OCR options", but it doesnt contain "-oem NUM" option as operated in Windows system, why? someone told me the Xeon CPU doesnt support AVX, is that the correct reason?  
### Expected Behavior:

### Suggested Fix:
 you used linux/ubuntu?
here is my info:
ml@ml-Precision-Tower-5810:/data/gs/ocr$ tesseract -v
tesseract 4.00.00alpha
 leptonica-1.72
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

ml@ml-Precision-Tower-5810:/data/gs/ocr$ tesseract 
Usage:
  tesseract --help | --help-psm | --version
  tesseract --list-langs [--tessdata-dir PATH]
  tesseract --print-parameters [options...] [configfile...]
  tesseract imagename|stdin outputbase|stdout [options...] [configfile...]

OCR options:
  --tessdata-dir PATH   Specify the location of tessdata path.
  --user-words PATH     Specify the location of user words file.
  --user-patterns PATH  Specify the location of user patterns file.
  -l LANG[+LANG]        Specify language(s) used for OCR.
  -c VAR=VALUE          Set value for config variables.
                        Multiple -c arguments are allowed.
  -psm NUM              Specify page segmentation mode.
NOTE: These options must occur before any configfile.

Page segmentation modes:
  0    Orientation and script detection (OSD) only.
  1    Automatic page segmentation with OSD.
  2    Automatic page segmentation, but no OSD, or OCR.
  3    Fully automatic page segmentation, but no OSD. (Default)
  4    Assume a single column of text of variable sizes.
  5    Assume a single uniform block of vertically aligned text.
  6    Assume a single uniform block of text.
  7    Treat the image as a single text line.
  8    Treat the image as a single word.
  9    Treat the image as a single word in a circle.
 10    Treat the image as a single character.
 11    Sparse text. Find as much text as possible in no particular order.
 12    Sparse text with OSD.
 13    Raw line. Treat the image as a single text line,
bypassing hacks that are Tesseract-specific.

Single options:
  -h, --help            Show this help message.
  --help-psm            Show page segmentation modes.
  -v, --version         Show version information.
  --list-langs          List available languages for tesseract engine.
  --print-parameters    Print tesseract parameters to stdout.
Linux ml-Precision-Tower-5810 4.4.0-31-generic #50~14.04.1-Ubuntu SMP Wed Jul 13 01:07:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
ml@ml-Precision-Tower-5810:/data/gs/ocr$ 



nciaegs@163.com
 
From: Shreeshrii
Date: 2017-09-25 11:27
To: tesseract-ocr/tesseract
CC: GuoShuai; Author
Subject: Re: [tesseract-ocr/tesseract] tesseract 4.00.00alpha couldnt set OEM (#1155)
Are you using an old version of tesseract?
The correct parameter is --oem NUM
I get the following info:
tesseract -v
tesseract 4.00.00alpha
 leptonica-1.74.4
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8
 Found AVX
 Found SSE
 tesseract
Usage:
  tesseract --help | --help-psm | --help-oem | --version
  tesseract --list-langs [--tessdata-dir PATH]
  tesseract --print-parameters [options...] [configfile...]
  tesseract imagename|stdin outputbase|stdout [options...] [configfile...]
OCR options:
  --tessdata-dir PATH   Specify the location of tessdata path.
  --user-words PATH     Specify the location of user words file.
  --user-patterns PATH  Specify the location of user patterns file.
  -l LANG[+LANG]        Specify language(s) used for OCR.
  -c VAR=VALUE          Set value for config variables.
                        Multiple -c arguments are allowed.
  --psm NUM             Specify page segmentation mode.
  --oem NUM             Specify OCR Engine mode.
NOTE: These options must occur before any configfile.
Page segmentation modes:
  0    Orientation and script detection (OSD) only.
  1    Automatic page segmentation with OSD.
  2    Automatic page segmentation, but no OSD, or OCR.
  3    Fully automatic page segmentation, but no OSD. (Default)
  4    Assume a single column of text of variable sizes.
  5    Assume a single uniform block of vertically aligned text.
  6    Assume a single uniform block of text.
  7    Treat the image as a single text line.
  8    Treat the image as a single word.
  9    Treat the image as a single word in a circle.
 10    Treat the image as a single character.
 11    Sparse text. Find as much text as possible in no particular order.
 12    Sparse text with OSD.
 13    Raw line. Treat the image as a single text line,
                        bypassing hacks that are Tesseract-specific.
OCR Engine modes:
  0    Original Tesseract only.
  1    Neural nets LSTM only.
  2    Tesseract + LSTM.
  3    Default, based on what is available.
Single options:
  -h, --help            Show this help message.
  --help-psm            Show page segmentation modes.
  --help-oem            Show OCR Engine modes.
  -v, --version         Show version information.
  --list-langs          List available languages for tesseract engine.
  --print-parameters    Print tesseract parameters.

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub, or mute the thread.
 I'll try it now, thank you friends!  
### Environment

* **Tesseract Version**: <!-- compulsory. you must provide your version -->
tesseract 4.00.00alpha
 leptonica-1.74.4
  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8

* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
2a77d5ad691b53c0fff7400fc4fd66102a24bc27 - found after bisecting from current master
* **Platform**: <!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->
Linux mc01 4.4.0-89-generic #112-Ubuntu SMP Mon Jul 31 19:38:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

### Current Behavior:
Segfault when running:
```
$tesseract bad.png - -l ces -psm 7
Warning. Invalid resolution 0 dpi. Using 70 instead.
contains_unichar_id(unichar_id):Error:Assert failed:in file ../ccutil/unicharset.h, line 513
Segmentation fault (core dumped)
```

Ces data were downloaded from https://github.com/tesseract-ocr/tessdata/raw/4.00/ces.traineddata .

![bad](https://user-images.githubusercontent.com/1188728/30782283-56613888-a12f-11e7-8bd4-24118e21a763.png)

### Expected Behavior:

```
$ tesseract bad.png - -l ces -psm 7
Warning. Invalid resolution 0 dpi. Using 70 instead.
nguzge gbopf/IUMNIC CZ spol. s r.o.
```

### Suggested Fix:

 What about other PSMs? 

>Ces data were downloaded from https://github.com/tesseract-ocr/tessdata/raw/4.00/ces.traineddata

There are newer traineddata files available.
https://github.com/tesseract-ocr/tesseract/wiki/Data-Files#updated-data-files-for-version-400-september-15-2017 I cannot test it right now but I think that it worked ok when psm was not specified. I'll try to use the new data too, thanks. I've checked and new traineddata solved this issue.
As for what psm modes, the segfault appeared for modes 7, 8, 11 and 12 (also for 14- but those are probably not valid anyway).
I'm not sure wheter to close this issue right away, but my problem is now solved. Thank You. I've uploaded one that didn't work in the original post. One that works can be seen here:
![1](https://user-images.githubusercontent.com/1188728/31050762-53a1d99c-a655-11e7-93b3-75de57a4bf07.png) . Otherwise it worked fine across a few thousand images, with only a single exception where it failed with the segfault mentioned above.

Oem was not set (as can be seen it examples above), so the default value.
 I suggest to close this issue since it was solved with an updated traineddata.  @zdenop 

You might want to try this:
https://github.com/blog/2141-squash-your-commits
https://help.github.com/articles/about-pull-request-merges/

Note that it will give you the option to change the commit message.

My suggestion:

Title:
>Fix encoding issue in unicharset_extractor.cpp (#1153) 

Body:
>Fix #1147 @theraysmith, @zdenop, is this bug fix which is needed for everybody who wants to do training ready to get merged (preferably with squashing the seven commits), or would you prefer a more direct solution (like [this commit](https://github.com/stweil/tesseract/commit/94ea31d4bad6174a8a2999a940bfe76b9ce31f26))? @ivanzz1001, After I changed unicharset_extractor.cpp file, should I build the unicharset_extractor.cpp file to generate a new unicharset_extractor.o file ?

g++ unicharset_extractor.cpp -o unicharset_extractor

use the command ok ?  ### Environment

* **Tesseract Version**: tesseract 4.00.00alpha
* **Platform**: Linux 4.12.13-1-ARCH #1 SMP PREEMPT Fri Sep 15 06:36:43 UTC 2017 x86_64 GNU/Linux

### Current Behavior:
Text embedded using `PdfRenderer` are encoded using `UTF_16BE` but do not contain BOM bytes. Only text string that is encoded correctly is in `/Title` metadata.

### Expected Behavior:
According to [PDF reference](http://www.adobe.com/content/dam/Adobe/en/devnet/acrobat/pdfs/pdf_reference_1-7.pdf) all `text string` objects should be encoded in `PdfDocEncoding` or `UTF_16BE` with a leading `byte-order marker` (FEFF).
### Suggested Fix:
 CC: @jbreiden  See chapter 3.8.1 in the PDF reference. Hi @jbreiden I came across this while trying to extract text from PDFs in a generic way. I am not aware of any incompatibilities with PDF renderer but without BOM it is incompatible with multiple PDF parsers (e.g. `pdfminer`, `pdfrw`). From PDF reference chapter 3.8.1:

> For text strings encoded in Unicode, the first two bytes must be 254 followed by 255. These two bytes represent the Unicode byte order marker, U+FEFF, indicating
that the string is encoded in the UTF-16BE (big-endian) encoding scheme
specified in the Unicode standard.  Evince has no problem with the BOM.

pdf.js - same effect as pdfium. If both Adobe Reader and PDFium can't render the "with BOM" version correctly, I see no point in keeping this issue open.  Maybe 'max_pages' should be a parameter to the shell script, so end users can change it easily.    Environment

* **Tesseract Version**: tesseract 4.00.00alpha
 leptonica-1.74.4 libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8
 Found AVX2
 Found AVX
 Found SSE
* **Commit Number**: 2178
* **Platform**: Linux Bash Shell on Windows 10

### I try to do tesstrain.sh by using this code.
```
training/tesstrain.sh --fonts_dir /mnt/c/Windows/Fonts --lang tha --training_text /mnt/e/tesseract-ocr/langdata/tha/tha.training_text --linedata_only \
  --noextract_font_properties --langdata_dir /mnt/e/tesseract-ocr/langdata \
  --tessdata_dir /mnt/e/tesseract-ocr/tessdata \
  --fontlist "Tahoma" --output_dir /mnt/e/OCR/
```
### But I got this error

```
=== Starting training for language 'tha'
[Thu Sep 21 18:23:13 DST 2017] /usr/bin/text2image --fonts_dir=/mnt/c/Windows/Fonts --font=Tahoma --outputbase=/tmp/font_tmp.bUhGLbvCi0/sample_text.txt --text=/tmp/font_tmp.bUhGLbvCi0/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.bUhGLbvCi0
Rendered page 0 to file /tmp/font_tmp.bUhGLbvCi0/sample_text.txt.tif
Rtl = 0 ,vertical=0

=== Phase I: Generating training images ===
Rendering using Tahoma
[Thu Sep 21 18:23:16 DST 2017] /usr/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.bUhGLbvCi0 --fonts_dir=/mnt/c/Windows/Fonts --strip_unrenderable_words --leading=48 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.vdOu9qzJMf/tha/tha.Tahoma.exp0 --max_pages=3 --font=Tahoma --text=/mnt/e/tesseract-ocr/langdata/tha/tha.training_text
ERROR: Non-existent flag --max_pages=3
ERROR: /tmp/tmp.vdOu9qzJMf/tha/tha.Tahoma.exp0.box does not exist or is not readable
ERROR: /tmp/tmp.vdOu9qzJMf/tha/tha.Tahoma.exp0.box does not exist or is not readable
```
Please suggest me to fix this error. I try to fix this too many hours.
 >ERROR: Non-existent flag --max_pages=3

It seems that you are using a non recent commit, that came before https://github.com/tesseract-ocr/tesseract/commit/2633fef0b6ac @ivanzz1001 @amitdo /mnt/c is use for access to the Windows directory. but I try to move "Fonts" Folder to the /usr/share/fonts/ and change code to `--fonts_dir /usr/share/fonts/` but it appear the same error 

```
=== Starting training for language 'tha'
[Fri Sep 22 03:04:10 DST 2017] /usr/bin/text2image --fonts_dir=/usr/share/fonts/ --font=Tahoma --outputbase=/tmp/font_tmp.r6wpt8kkkw/sample_text.txt --text=/tmp/font_tmp.r6wpt8kkkw/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.r6wpt8kkkw
FcInitiReinitialize failed!!
Could not find font named Tahoma. Pango suggested font
Please correct --font arg.:Error:Assert failed:in file text2image.cpp, line 437

=== Phase I: Generating training images ===
Rendering using Tahoma
[Fri Sep 22 03:04:12 DST 2017] /usr/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.r6wpt8kkkw --fonts_dir=/mnt/Fonts --strip_unrenderable_words --leading=48 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.4iPf952XEc/tha/tha.Tahoma.exp0 --max_pages=3 --font=Tahoma --text=/mnt/e/tesseract-ocr/langdata/tha/tha.training_text
ERROR: Non-existent flag --max_pages=3
ERROR: /tmp/tmp.4iPf952XEc/tha/tha.Tahoma.exp0.box does not exist or is not readable
ERROR: /tmp/tmp.4iPf952XEc/tha/tha.Tahoma.exp0.box does not exist or is not readable
```
**And I try change the code in `tesstrain_utils.sh `** 
Line 215    -  `common_args+=" --outputbase=${outbase} --max_pages=3"` to
Line 215   +   `common_args+=" --outputbase=${outbase} "`

But It stuck at Phase Up for many hours 

```
=== Phase I: Generating training images ===
Rendering using Tahoma
[Fri Sep 22 03:20:05 DST 2017] /usr/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.w5EOd46HIj --fonts_dir=/usr/share/fonts/ --strip_unrenderable_words --leading=48 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.QjgaXWkS0p/tha/tha.Tahoma.exp0 --font=Tahoma --text=/mnt/e/tesseract-ocr/langdata/tha/tha.training_text
Rendered page 0 to file /tmp/tmp.QjgaXWkS0p/tha/tha.Tahoma.exp0.tif
Rtl = 0 ,vertical=0

=== Phase UP: Generating unicharset and unichar properties files ===
[Fri Sep 22 03:20:06 DST 2017] /usr/bin/unicharset_extractor --output_unicharset /tmp/tmp.QjgaXWkS0p/tha/tha.unicharset --norm_mode 2 /tmp/tmp.QjgaXWkS0p/tha/tha.Tahoma.exp0.box
```

 @Shreeshrii  I just test with `eng `and `"Arial"` Font by using 

```
training/tesstrain.sh  \
  --fonts_dir /usr/share/fonts/ \
  --lang eng  \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --langdata_dir /mnt/e/tesseract-ocr/langdata \
  --tessdata_dir /mnt/e/tesseract-ocr/tessdata   \
  --output_dir /usr/share/ \
  --fontlist "Arial"
```


And `tha` with `"Arial" ` but it got a same error 

```
ERROR: Non-existent flag --max_pages=3
ERROR: /tmp/tmp.A41qaylCwa/tha/tha.Arial.exp0.box does not exist or is not readable
ERROR: /tmp/tmp.A41qaylCwa/tha/tha.Arial.exp0.box does not exist or is not readable

```

@ivanzz1001 
**`yum install fontconfig mkfontscale`** >> result is nothing, terminal get stuck must to re-open it. 

**`fc-list`**
```
/usr/share/fonts/truetype/Fonts/constan.ttf: Constantia:style=Regular
/usr/share/fonts/truetype/Fonts/browalia.ttc: BrowalliaUPC:style=Bold Italic,Negreta cursiva,tučné kurzíva,fed kursiv,Fe
tt Kursiv,Έντονα Πλάγια,Negrita Cursiva,Lihavoitu Kursivoi,Gras Italique,Félkövér dőlt,Grassetto Corsivo,Vet Cursief,Hal
vfet Kursiv,Pogrubiona kursywa,Negrito Itálico,Полужирный Курсив,Tučná kurzíva,Fet Kursiv,Kalın İtalik,Krepko poševno,Lo
di etzana
/usr/share/fonts/truetype/Fonts/trebuc.ttf: Trebuchet MS:style=Regular,Normal,obyčejné,Standard,Κανονικά,Normaali,Normál
,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,Arrunta
/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf: DejaVu Serif:style=Book
/usr/share/fonts/truetype/Fonts/calibril.ttf: Calibri,Calibri Light:style=Light,Regular
/usr/share/fonts/truetype/Fonts/phagspa.ttf: Microsoft PhagsPa:style=Regular,Normal,obyčejné,Standard,Κανονικά,Normaali,
Normál,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,Arrunta
/usr/share/fonts/truetype/Fonts/segmdl2.ttf: Segoe MDL2 Assets:style=Regular,Normal,obyčejné,Standard,Κανονικά,Normaali,
Normál,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,thường,Arrunta
/usr/share/fonts/truetype/Fonts/upcii.ttf: IrisUPC:style=Italic,Cursiva,kurzíva,kursiv,Πλάγια,Kursivoitu,Italique,Dőlt,C
orsivo,Cursief,Kursywa,Itálico,Курсив,İtalik,Poševno,Etzana
/usr/share/fonts/truetype/Fonts/msyhbd.ttc: Microsoft YaHei UI:style=Bold,Negreta,tučné,fed,Fett,Έντονα,Negrita,Lihavoit
u,Gras,Félkövér,Grassetto,Vet,Halvfet,Pogrubiony,Negrito,Полужирный,Fet,Kalın,Krepko,Lodia
/usr/share/fonts/truetype/Fonts/angsana.ttc: AngsanaUPC:style=Bold,Negreta,tučné,fed,Fett,Έντονα,Negrita,Lihavoitu,Gras,
Félkövér,Grassetto,Vet,Halvfet,Pogrubiony,Negrito,Полужирный,Fet,Kalın,Krepko,Lodia
/usr/share/fonts/truetype/Fonts/lucon.ttf: Lucida Console:style=Regular,Normal,obyčejné,Standard,Κανονικά,Normaali,Normá
l,Normale,Standaard,Normalny,Обычный,Navadno,Arrunta
/usr/share/fonts/truetype/Fonts/msjh.ttc: Microsoft JhengHei UI:style=Normal,Regular,obyčejné,Standard,Κανονικά,Normaali
,Normál,Normale,Standaard,Normalny,Обычный,Normálne,Navadno,Arrunta
/usr/share/fonts/truetype/Fonts/cour.ttf: Courier New:style=Regular,Normal,obyčejné,Standard,Κανονικά,Normaali,Normál,No
rmale,Standaard,Normalny,Обычный,Normálne,Navadno,thường,Arrunta
/usr/share/fonts/truetype/Fonts/SitkaZ.ttc: Sitka Display,Sitka:style=Bold Italic,Display Bold Italic
/usr/share/fonts/truetype/Fonts/calibriz.ttf: Calibri:style=Bold Italic
/usr/share/fonts/truetype/Fonts/consolaz.ttf: Consolas:style=Bold Italic
/usr/share/fonts/truetype/Fonts/seguisb.ttf: Segoe UI,Segoe UI Semibold:style=Semibold,Regular
```
**`text2image --fonts_dir /usr/share/fonts --list_available_fonts`**
```
 0: 8514fix
  1: 8514oem
  2: Angsana New
  3: Angsana New Bold
  4: Angsana New Bold Italic
  5: Angsana New Italic
  6: AngsanaUPC
  7: AngsanaUPC Bold
  8: AngsanaUPC Bold Italic
  9: AngsanaUPC Italic
 10: Arial
 11: Arial Bold
 12: Arial Bold Italic
 13: Arial Heavy
 14: Arial Italic
 15: Browallia New
 16: Browallia New Bold
 17: Browallia New Bold Italic
 18: Browallia New Italic
 19: BrowalliaUPC
 20: BrowalliaUPC Bold
 21: BrowalliaUPC Bold Italic
 22: BrowalliaUPC Italic
 23: Calibri
 24: Calibri Bold
 25: Calibri Bold Italic
 26: Calibri Italic
 27: Calibri Light
 28: Calibri Light Italic
 29: Cambria
 30: Cambria Bold
 31: Cambria Bold Italic
 32: Cambria Italic
 33: Cambria Math
 34: Candara
 35: Candara Bold
 36: Candara Bold Italic
 37: Candara Italic
 38: Comic Sans MS
 39: Comic Sans MS Bold
 40: Comic Sans MS Bold Italic
 41: Comic Sans MS Italic
 42: Consolas
 43: Consolas Bold
 44: Consolas Bold Italic
 45: Consolas Italic
 46: Constantia
 47: Constantia Bold
 48: Constantia Bold Italic
 49: Constantia Italic
 50: Corbel
 51: Corbel Bold
 52: Corbel Bold Italic
 53: Corbel Italic
 54: Cordia New
 55: Cordia New Bold
 56: Cordia New Bold Italic
 57: Cordia New Italic
 58: CordiaUPC
 59: CordiaUPC Bold
 60: CordiaUPC Bold Italic
 61: CordiaUPC Italic
 62: Courier
 63: Courier New
 64: Courier New Bold
 65: Courier New Bold Italic
 66: Courier New Italic
 67: DejaVu Sans
 68: DejaVu Sans Bold
 69: DejaVu Sans Mono
 70: DejaVu Sans Mono Bold
 71: DejaVu Serif
 72: DejaVu Serif Bold
 73: DilleniaUPC
 74: DilleniaUPC Bold
 75: DilleniaUPC Bold Italic
 76: DilleniaUPC Italic
 77: Ebrima
 78: Ebrima Bold
 79: EucrosiaUPC
 80: EucrosiaUPC Bold
 81: EucrosiaUPC Bold Italic
 82: EucrosiaUPC Italic
 83: Fixedsys
 84: Franklin Gothic Medium,
 85: Franklin Gothic Medium, Italic
 86: FreesiaUPC
 87: FreesiaUPC Bold
 88: FreesiaUPC Bold Italic
 89: FreesiaUPC Italic
 90: Gabriola
 91: Gadugi
 92: Gadugi Bold
 93: Georgia
 94: Georgia Bold
 95: Georgia Bold Italic
 96: Georgia Italic
 97: HoloLens MDL2 Assets
 98: Impact Condensed
 99: IrisUPC
100: IrisUPC Bold
101: IrisUPC Bold Italic
102: IrisUPC Italic
103: JasmineUPC
104: JasmineUPC Bold
105: JasmineUPC Bold Italic
106: JasmineUPC Italic
107: Javanese Text
108: KodchiangUPC
109: KodchiangUPC Bold
110: KodchiangUPC Bold Italic
111: KodchiangUPC Italic
112: Leelawadee
113: Leelawadee Bold
114: Leelawadee UI
115: Leelawadee UI Bold
116: Leelawadee UI Semi-Light
117: LilyUPC
118: LilyUPC Bold
119: LilyUPC Bold Italic
120: LilyUPC Italic
121: Lucida Console Semi-Condensed
122: Lucida Sans Unicode
123: MS Gothic
124: MS PGothic
125: MS Sans Serif
126: MS Serif
127: MS UI Gothic
128: MV Boli
129: Malgun Gothic
130: Malgun Gothic Bold
131: Malgun Gothic Light
132: Marlett Medium
133: Microsoft Himalaya
134: Microsoft JhengHei
135: Microsoft JhengHei Bold
136: Microsoft JhengHei Light
137: Microsoft JhengHei UI
138: Microsoft JhengHei UI Bold
139: Microsoft JhengHei UI Light
140: Microsoft New Tai Lue
141: Microsoft New Tai Lue Bold
142: Microsoft PhagsPa
143: Microsoft PhagsPa Bold
144: Microsoft Sans Serif
145: Microsoft Tai Le
146: Microsoft Tai Le Bold
147: Microsoft YaHei
148: Microsoft YaHei Bold
149: Microsoft YaHei Light
150: Microsoft YaHei UI
151: Microsoft YaHei UI Bold
152: Microsoft YaHei UI Light
153: Microsoft Yi Baiti
154: MingLiU-ExtB
155: MingLiU_HKSCS-ExtB
156: Mongolian Baiti
157: Myanmar Text
158: Myanmar Text Bold
159: NSimSun
160: Nirmala UI
161: Nirmala UI Bold
162: Nirmala UI Semi-Light
163: PMingLiU-ExtB
164: Palatino Linotype
165: Palatino Linotype Bold
166: Palatino Linotype Bold Italic
167: Palatino Linotype Italic
168: Segoe MDL2 Assets
169: Segoe Print
170: Segoe Print Bold
171: Segoe Script
172: Segoe Script Bold
173: Segoe UI
174: Segoe UI Bold
175: Segoe UI Bold Italic
176: Segoe UI Emoji
177: Segoe UI Heavy
178: Segoe UI Heavy Italic
179: Segoe UI Historic
180: Segoe UI Italic
181: Segoe UI Light
182: Segoe UI Light Italic
183: Segoe UI Semi-Bold
184: Segoe UI Semi-Bold Italic
185: Segoe UI Semi-Light
186: Segoe UI Semi-Light Italic
187: Segoe UI Symbol
188: SimSun
189: SimSun-ExtB
190: Sitka Banner
191: Sitka Banner Bold
192: Sitka Banner Bold Italic
193: Sitka Banner Italic
194: Sitka Display
195: Sitka Display Bold
196: Sitka Display Bold Italic
197: Sitka Display Italic
198: Sitka Heading
199: Sitka Heading Bold
200: Sitka Heading Bold Italic
201: Sitka Heading Italic
202: Sitka Small
203: Sitka Small Bold
204: Sitka Small Bold Italic
205: Sitka Small Italic
206: Sitka Subheading
207: Sitka Subheading Bold
208: Sitka Subheading Bold Italic
209: Sitka Subheading Italic
210: Sitka Text
211: Sitka Text Bold
212: Sitka Text Bold Italic
213: Sitka Text Italic
214: Small Fonts
215: Sylfaen
216: Symbol
217: System
218: Tahoma
219: Tahoma Bold
220: Terminal
221: Terminal Greek 737 (437G)
222: Terminal Greek 869,
223: Times New Roman,
224: Times New Roman, Bold
225: Times New Roman, Bold Italic
226: Times New Roman, Italic
227: Trebuchet MS
228: Trebuchet MS Bold
229: Trebuchet MS Bold Italic
230: Trebuchet MS Italic
231: Verdana
232: Verdana Bold
233: Verdana Bold Italic
234: Verdana Italic
235: Webdings
236: Wingdings
237: Yu Gothic
238: Yu Gothic Bold
239: Yu Gothic Light
240: Yu Gothic Medium
241: Yu Gothic UI
242: Yu Gothic UI Bold
243: Yu Gothic UI Light
244: Yu Gothic UI Semi-Bold
245: Yu Gothic UI Semi-Light
``` @Shreeshrii  
**`make training`** got this error
```
make: Warning: File 'Makefile.in' has modification time 21613 s in the future
/bin/bash ./config.status --recheck
running CONFIG_SHELL=/bin/bash /bin/bash ./configure --no-create --no-recursion
checking for g++... g++
checking whether the C++ compiler works... yes
checking for C++ compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
Using git revision: 4.00.00dev-687-g2cc531e
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... configure: error: newly created file is older than distributed files!
Check your system clock
Makefile:430: recipe for target 'config.status' failed
make: *** [config.status] Error 1
```
and the **`make training-install`** I got this 
```
make: Warning: File 'Makefile.in' has modification time 21585 s in the future
/bin/bash ./config.status --recheck
running CONFIG_SHELL=/bin/bash /bin/bash ./configure --no-create --no-recursion
checking for g++... g++
checking whether the C++ compiler works... yes
checking for C++ compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
Using git revision: 4.00.00dev-687-g2cc531e
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... configure: error: newly created file is older than distributed files!
Check your system clock
Makefile:430: recipe for target 'config.status' failed
make: *** [config.status] Error 1
```

 I try to re-install tesseract.  but now I got error with the same [ISSUE#1114](https://github.com/tesseract-ocr/tesseract/issues/1114) I try change` LINE 220 `in  `normstrngs.cpp`  but it doesn't fix.

```
Invalid Unicode codepoint: 0xffffffc2
IsValidCodepoint(ch):Error:Assert failed:in file normstrngs.cpp, line 225
ERROR: /tmp/tmp.9TCN0u9M2a/eng/eng.unicharset does not exist or is not readable
```
 So your original issue was solved.

Don't mix two different issues in one report. Please close this issue. Okay, Let me summary this issue for anyone that get error the same with me. 
If you got this error about `Non-existent flag` 
**Re-install tesseract**  and don't forget to
```
sudo ldconfig
make training
sudo make training-install
```
then if you get  error about `Invalid Unicode codepoint: ` try to change code in `normstrng.cpp`
**See this issue.**
 [Issue1114]( https://github.com/tesseract-ocr/tesseract/issues/1114) 
then run this again 
```
make run
make training
sudo make training-install

```
And the last, I got error about `TESSDATA_PREFIX `
**I fix by read this Issue** 
[Issue221](https://github.com/tesseract-ocr/tesseract/issues/221)

Thank you everyone to help me fix this. I am very appreciate it.
  >First It use function NormalizeCleanAndSegmentUTF8() **to convert the string to UTF-8 encoding**

The first thing it does is calling NormalizeUTF8ToUTF32().
 Maybe you have two tesseracts in your system. one of them is older version than the other. Strangely, tesseract parses 'radical-stroke.txt' for every language.
https://github.com/tesseract-ocr/tesseract/blob/a2a72d7ca78a3bb3798a02a2ba5188e255c2a0f7/ccutil/unicharcompress.cpp#L98 >I checked that I have only one version.

How?

Try this:
`sudo find / -type f -name "libtesseract.so*"`

I wonder why you put the git repo on `/root`. https://help.github.com/articles/dealing-with-line-endings/ https://github.com/tesseract-ocr/tesseract/wiki/VGSLSpecs

>Is It OK that I ask the question here? or anywhere else is proper?

The right place to ask this kind of question is [our forum](https://groups.google.com/d/forum/tesseract-ocr).  Hello everyone,

When I train models by LSTM 4.0  [https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#fine-tuning-for-%C2%B1-a-few-characters]

It showed this problem, how to solve it? Why happened? What should the pic size be? 

```
Image too large to learn!! Size = 2608x48
Image not trainable
Image too large to learn!! Size = 2845x48
Image not trainable
At iteration 18938/35100/36699, Mean rms=0.379%, delta=0.441%, char train=1.315%, word train=2.366%, skip ratio=3.2%,  New worst char error = 1.315 wrote checkpoint.

Image too large to learn!! Size = 2704x48
Image not trainable
Image too large to learn!! Size = 2666x48
Image not trainable
Image too large to learn!! Size = 2634x48
Image not trainable
Image too large to learn!! Size = 2593x48
Image not trainable
Image too large to learn!! Size = 2593x48
Image not trainable
At iteration 18971/35200/36804, Mean rms=0.376%, delta=0.435%, char train=1.279%, word train=2.311%, skip ratio=3.4%,  New worst char error = 1.279 wrote checkpoint.
```
The pics is created by the shell "training/tesstrain.sh ", How to decide the size of the pic by this way???

```
training/tesstrain.sh  \
   --fonts_dir /usr/share/fonts \
  --lang chi_sim  \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --langdata_dir ../langdata \
  --tessdata_dir /home/hs/tessdata/tessdata  \
  --output_dir ../tesstutorial/chi_sim
``` Thank you @Shreeshrii  @yoyoshuang  where can i  find training material  for Chinese  I have downloaded that latest 4.0 release, new leptonica and tried to buid it under MSVC 2017, unicode project. After several hours of I almost succeded in building the project but one problem is still remaining unresolved, I don't know how to fix it.

network.cpp (line 209):
`network = new Convolve(stub.name_, stub.ni_, 0, 0);`

MSVC gives the linker error:
 error LNK2001: unresolved external symbol "public: __thiscall tesseract::Convolve::Convolve(class STRING const &,int,int,int)" (??0Convolve@tesseract@@QAE@ABVSTRING@@HHH@Z)

If this line is commented, project is built normally without errors.
convolve,cpp is included and Convolve::Convolve is definetely presented.
Weird thing that there is another file - networkbuilder.cpp where
one can see almost the same code, and it works fine:
```
  Convolve* convolve =
      new Convolve("Convolve", input_shape.depth(), x / 2, y / 2);

```
But after being copied to network.cpp it give the same link error.
I spent an hour trying to fix but failed.
What if I just comment this line? When it is used? Commenting that line is not a good idea.

https://msdn.microsoft.com/en-us/library/f6xx1b1z.aspx

CC: @egorpugin  No, never heard of it. MSVC project, mostly assembled manually. The previos versions 3.02, 3.04, were assembled and compiled normally. 
First I thought that maybe it's leptonica's "convolve.c" that has collisions with lstm's "convolve.cpp" module and renamed the "convolve.c" to "convolve2.c" with no effect. cppan --build pvt.cppan.demo.google.tesseract.tesseract-master.
gives an error
boost::filesystem::path codecvt to wstring: error WIndows 10, MSVC 2017 community Account to where? I have no account in Russian letters, though I am Russian Oh I see, I changed it to another user, now cppan goes further but no enough "There errors during test start". Log files are empty I use the latest MSVC, is this enough for the latest cmake?
I solved the problem just by copied the source code from convolve.cpp (it's very small) to network.cpp and everything went fine. When I was building 3.02 and 3.04 I didn't know about cppan, so i just manually added all required libraries and everything went fine. Today I found that there is 3.05 version, I downloaded it, added libs and evrything was compiled and linked perfectly as always, it took me around 15 minutes. Obviously I like that way and prefer to use it again with 4.0 version. 
As per my PC, I didn' do to it something unusual, OS  was installed a month ago, MSVC 2017, the tesseract code was not changed, As I said, I resolved the problem, so no need to do anything with the code, perhaps you are right and the problem is with my machine Thank you for your efforts!
Ok, Egor, I will try to use cppan on a new virtual machine with Win10, pure MSVC and a proper Administrator. After creating MSVC project again more accurately (adding files one by one) I succeeded in  building MSVC project without changing the source code. Nevertheless one weird thing I made - I had to add convolve.cpp in the main project. Now it contains two files - main.cpp (my own source code) and convolve.cpp (other dependencies are through lib files). 
MSVC also gives a warning  while linking:
x64\Release\convolve.obj : warning LNK4042: object specified more than once; extras ignored
I don't know what it means  You have two options:
1. Put the deu.trainwddata directly under your tessdata dir.
2. Put the tessdata_best dir under your tessdata dir, and use -l tessdata_best/deu >Put the tessdata_best dir under your tessdata dir, and use -l tessdata_best/deu

A variant of that option:
Rename the tessdata_best dir, for example to 'best',  put it under your tessdata dir, and use -l best/deu Tesseract has this parameter:
 
`m_data_sub_dir `- Directory for data files

It's not new.

The default value for that parameter is `tessdata/`

>I simply replaced (exchanged) my existing .../tessdata with the the new .../tessdata_best. Tesseract 

In that case another option is to put this line in a text file:
`m_data_sub_dir tessdata_best/`
and use it as config file for tesseract.
  You did not copy the command which was used to run the compiler from your build protocol. It should look like this:

    depbase=`echo ambigs.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
    /bin/bash ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -DUSE_STD_NAMESPACE   -I/usr/include/leptonica -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -DTESSDATA_PREFIX=/usr/local/share/  -g -O2 -std=c++11 -MT ambigs.lo -MD -MP -MF $depbase.Tpo -c -o ambigs.lo ambigs.cpp &&\
    mv -f $depbase.Tpo $depbase.Plo
    libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DUSE_STD_NAMESPACE -I/usr/include/leptonica -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -DTESSDATA_PREFIX=/usr/local/share/ -g -O2 -std=c++11 -MT ambigs.lo -MD -MP -MF .deps/ambigs.Tpo -c ambigs.cpp  -fPIC -DPIC -o .libs/ambigs.o
    libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DUSE_STD_NAMESPACE -I/usr/include/leptonica -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -DTESSDATA_PREFIX=/usr/local/share/ -g -O2 -std=c++11 -MT ambigs.lo -MD -MP -MF .deps/ambigs.Tpo -c ambigs.cpp -o ambigs.o >/dev/null 2>&1

Check whether yours looks different, especially whether `-DUSE_STD_NAMESPACE` is missing. That would explain the build failure. I also use Debian 9, same libtiff5-dev, and I do not have `/usr/share/tesseract-ocr/4/tessdata/`. I'd examine it with `ls -l` (is it old) and `dpkg -S` (where does it belong to) and move it out of the way. @Wikinaut, did you solve the issue?  Before you submit an issue, please review [the guidelines for this repository](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md).

Please report an issue only for a BUG, not for asking questions.

Note that it will be much easier for us to fix the issue if a test case that
reproduces the problem is provided. Ideally this test case should not have any
external dependencies. Provide a copy of the image or link to files for the test case.

Please delete this text and fill in the template below. 

------------------------

### Environment

* **Tesseract Version**: tesseract 3.04.00
* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
* **Platform**: Linux 0ba52aafd58a 4.9.4-moby #1 SMP Wed Jan 18 17:04:43 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

### Current Behavior:

When processing a multi page TIFF with Tesseract API in python, the text returned is only for the LAST page rather than for ALL pages. 

Code used:

```
self.tesseract.TessBaseAPIProcessPages.argtypes = [POINTER(TessBaseAPI), c_char_p, c_char_p, c_int, POINTER(TessResultRenderer)]
self.tesseract.TessBaseAPIProcessPages.restype = c_bool
success = self.tesseract.TessBaseAPIProcessPages(self.api, create_string_buffer(path_to_multipage_tiff), None , 0, None)
ocr_r = self.tesseract.TessBaseAPIGetUTF8Text(self.api)
result = string_at(ocr_r)
```

### Expected Behavior:

Instead of text returned only for the last page, the text should be returned for all pages. 

### Suggested Fix:

Interestingly this works when using the command line `tesseract` command. So perhaps there is already a fix for the command line.  Please report this issue in the repo of the python binding.  @zdenop  this happens in 3.05.01 as well. I'm wondering whether calling `TessBaseAPIProcessPages ` is the correct way to get ALL text from multi page pdfs?  OR whether there is another recommended way

@amitdo I did not see python binding repo under tesseract. Can you please link me to the one you are referring to? Please note i'm using `ctypes` to call the acutal tesseract API and not the python wrapper for tesseract.  >I did not see python binding repo under tesseract. Can you please link me to the one you are referring to? Please note i'm using ctypes to call the acutal tesseract API

I thought that you are using a 3rd party python binding.
https://github.com/tesseract-ocr/tesseract/wiki/AddOns#tesseract-30x

 >Interestingly this works when using the command line tesseract command. So perhaps there is already a fix for the command line

The command line uses the C++ API. @amitdo Sorry for the confusion, but I am not. I am referring to the actual tesseract capi. The capi can be called from python as shown in this example https://github.com/tesseract-ocr/tesseract/blob/a75ab450a8cc9a2b69cf05f5c4f7a39bc44cbacc/contrib/tesseract-c_api-demo.py#L72 Note that the linked example is a bit out of date. An actual example that works is https://stackoverflow.com/a/36876584/44286

However, the issue still remains of how to call capi to get all the text from multi page TIFF instead of text from only the last page > text = tesseract.TessBaseAPIGetUTF8Text(api)

This method returns text for one page only. The command line tool does not **directly** call this method.

You'll have to look in api/tesseractmain.cpp and mimic it to get things right.

Anyway, it's not an issue (bug) in tesseract command line or API.  Thanks. I've posted this question on the user-forums here: https://groups.google.com/forum/#!topic/tesseract-ocr/AL9LzrHa97k

I will continue to dig into `tesseractmain.cpp` to see if something points out  There is no direct way to get the text in all pages with ProcessPages.

if you give it a pointer to TessResultRenderer, the text is written to a file or stdout.  Recently the first regression tests were added to the Tesseract sources, and hopefully more will be added in the future. I expect that many of those tests will require images, maybe also related text and other files. Typically the images are large (much larger than source code files),  and most image formats are already compressed, so Git cannot compress them further. This is bad for the git repository size, but also for the size of the working directory or of release tarballs.

Currently 8 of the 10 largest files are test related:

    1444515 ccutil/universalambigs.cpp
     708120 testing/DuTillet1004Pg2LG.jpg
     444141 testing/hebtypo.jpg
     401757 testdata/chi_tra.unicharset
     399613 testing/hebrew-nikud-genesis-1-2.png
     378914 testdata/kan.unicharset
     359497 ccutil/tesscallback.h
     327214 testdata/chi_sim.unicharset
     239201 testdata/jpn.unicharset
     221628 testdata/mar.unicharset

We should avoid adding more such files. I suggest to create a new repository called `tesstest`,  `testdata`, `tesseract_testdata` or any other name for all test related data and move the existing test data to that repository. The `tesseract` repository can then include that new repository as a git submodule which is only needed when running tests (so most people won't need it).

OpenJPEG is an example of another Open Source project with a similar split of [source code](https://github.com/uclouvain/openjpeg) and [test data](https://github.com/uclouvain/openjpeg-data). They do not use a git submodule, but have a configure option to choose the location of the test data. ... or more. Test images use a lot of disk space.  This change does not look like the right solution for an existing problem. I'm afraid it should be reverted.  ------------------------

### Environment

* **Tesseract Version**: Tesseract 4.00.00 alpha
* **Commit Number**:  188e1fc
* **Platform**: Ubuntu 16.04.02 LTS

### Current Behavior:
I've downloaded and compiled latest tesseract source file from git repository but when i run tesseract engine with mode --oem 1, --psm 0 or 1 it can't load osd.traineddata. My osd.traineddata file is downloaded from tessdata_best. I tried with older osd.traineddata file from tessdata directory it works fine. I've cloned tessdata_best from repo and checked any download error but it was okay. 
installed tesseract shown below.
![tesseract](https://user-images.githubusercontent.com/30248220/30473888-72f05e40-9a34-11e7-9518-de668fd6c024.png)

I can load and work well with osd.traineddata from tessdata which is created about 3 yrs ago and include following files 
![old](https://user-images.githubusercontent.com/30248220/30474105-1effef34-9a35-11e7-9118-d89403fca397.png)
 
the one tesseract fails at loading includes lstm files which is shown below.
![new](https://user-images.githubusercontent.com/30248220/30474201-74a6bbfc-9a35-11e7-82b5-09e97706263d.png)

![osdfailed](https://user-images.githubusercontent.com/30248220/30474253-98bbc1cc-9a35-11e7-8b04-29b2477bd070.png)
here i am using lstm mode of engine so it should load osd.traineddata successfully but it shows failure message. It can load other language's lstm traineddata files and i can get result of text recognition despite of giving 'failed loading language osd' message but i can't feel any difference using best osd so it is not loading best osd.traineddata at all. 

So i guess it is bug related to tesseract engine or osd.traineddata file which is in tessdata_best.  facing same issue for urd.tessdata from tessdata_best  Should `tessdata_best` and `tessdata_fast` be Git submodules of `tessdata` to support language options like `-l eng` (old model), `-l best/eng` (best LSTM model) or `-l fast/eng` (fast LSTM model)? Then only a single `tessdata` directory is needed for installations, and it would be easier to document the relationship between all three repositories (think of new versions). Locally trained models could easily be added in additional subdirectories and used like `-l local/eng` or `-l user/eng`. "config file" is a good keyword:

Will Tesseract continue to use the same configuration files for standard, fast and best traineddata? Then having a single `tessdata` directory would be better. Handling of "sublanguages" which are invoked could be fixed in the code or in the config files.

If Tesseract needs different configuration files for standard, fast and best traineddata, separate `tessdata` directories will be required.
 I wonder whether the current approach with "best" and "fast" traineddata is reasonable: both contain basically the same data, only the LSTM model in the traineddata files differs. Some numbers for `best/Latin.traineddata`:

    # Component size / MiB
    12      Latin.lstm
    1       Latin.lstm-number-dawg
    1       Latin.lstm-punc-dawg
    1       Latin.lstm-recoder
    1       Latin.lstm-unicharset
    85      Latin.lstm-word-dawg
    1       Latin.version
    97      total

`fast/Latin.traineddata` is identical with one exception:

    # Component size / MiB
    1       Latin.lstm

So it would also be possible to modify Tesseract to get both kinds of `Latin.lstm` from the same traineddata file (using a new component name like `Latin.lstm-fast`) and select the desired one with a new command line option. That would avoid the duplication of the other data and simplify the handling while increasing the size of the traineddata only by a small amount.

    97      best/Latin.traineddata
    86      fast/Latin.traineddata

A combined traineddata file with best and fast model included could be zipped and would be much smaller then:

    51      best/Latin.zip
 >Just quoting Ray about 'best' and 'fast':

>2 parallel sets of tessdata. "best" and "fast". "Fast" will exceed the speed of legacy Tesseract in real time, provided you have the required parallelism components, and in total CPU only slightly slower for English. Way faster for most non-latin languages, while being <5% worse than "best" Only "best" will be retrainable, as "fast" will be integer.
 I now did a complete comparison of the extracted "best" and "fast" traineddata files. Besides the `lstm` and `version` parts, they are identical, but "best" includes these additional files:

    ara.config
    ben.config
    chi_sim.config
    chi_sim_vert.config
    chi_tra.config
    chi_tra_vert.config
    deu.config
    ell.config
    hin.config
    ita.config
    jpn.config
    jpn_vert.config
    kan.config
    kor.config
    mal.config
    mar.config
    nep.config
    srp.config
    tam.config
    tel.config
    tha.config
    vie.config

It's not clear why these parts exist in "best", and already the first one `ara.config` looks wrong:

    # We do not yet have Tesseract for Arabic, so use OEM_CUBE_ONLY
    # (see OcrEngineMode enum in third_party/tesseract/ccmain/tesseractclass.h).
    tessedit_ocr_engine_mode        1
    [...]

 >\# We do not yet have Tesseract for Arabic, so use OEM_CUBE_ONLY
\# (see OcrEngineMode enum in third_party/tesseract/ccmain/tesseractclass.h).

This comment should be updated

>tessedit_ocr_engine_mode        1

This is still ok for ara. Shouldn't all fast and best traineddatas have this:

>tessedit_ocr_engine_mode 1

in their config? Tesseract chooses the correct mode automatically.

There are 161 tessdata files in `tessdata_best`, but only 28 of them contain a config part.
`deu.traineddata` loads `frk.traineddata`. That looks wrong for me. Maybe other config files should not be there, too.

 >Tesseract chooses the correct mode automatically.

Yeah, I know, but oem 1 is more explicit.  My tesseract application always downloads eng.traineddata.gz file from internet. I want to make it offilne. How it;s possible? Help me please @sabirhusssain, the right place to ask questions is [our forum](https://groups.google.com/d/forum/tesseract-ocr).  Hello,
I compiled and installed the latest Leptonica and Tesseract without problems.

`tesseract -v 
`

> tesseract 4.00.00alpha
 leptonica-1.74.4
  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8
 Found AVX2
 Found AVX
 Found SSE

`tesseract image.jpg --tessdata_dir /usr/local/share/tessdata -l eng`

> tesseract: genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

When I use the tesserocr python wrapper, it seems to work.
Any suggestions? >tesseract image.jpg --tessdata-dir /usr/local/share/tessdata -l eng

try this:

>tesseract image.jpg **out** --tessdata_dir /usr/local/share
 `tesseract image.jpg out --tessdata_dir /usr/local/share/tessdata -l eng`
> tesseract: genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

`tesseract image.jpg out.txt --tessdata_dir /usr/local/share/tessdata -l eng`
> tesseract: genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

`tesseract image.jpg stdout --tessdata_dir /usr/local/share/tessdata -l eng`
> tesseract: genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

Would you recommend to reinstall?

Edit:
`tesseract image.jpg out -l eng`
 works

`echo $TESSDATA_PREFIX`
> /usr/local/share/tessdata/

however when specifying the tessdata_dir parameter it doesn't

Edit 2:
Alright... it's a dash in tessdata-dir not an underscore .. sorryy :))  I must admit that I never used that Makefile target. Do we need it at all? If we offer a target which
downloads eng.traineddata, I wonder whether it would be better to get one which supports both the old and the new recognizer (only as long as both are supported, of course).

A side notice:

Currently Tesseract requires eng.traineddata even if someone only wants to get the Tesseract version or the list of available languages. I don't think that this is satisfying.

Tesseract functions which are unrelated to eng.traineddata should work without it. Getting the `traineddata` files needs an internet connection. A simple `make` should work without internet. But a `make install` should result in a working installation, so for that case it would be good to include your code. @jbreiden, how do you build the Debian packages with `traineddata` then? Is there a "standard" Makefile target to get files needed for the installation from the internet? Related: would it make sense to add the Debian rules to the Tesseract repository?
Maybe rules for other distributions (e.g. I have files for the Windows installer), too? It's similar for Debian: https://packages.debian.org/stretch/tesseract-ocr.

The [experimental version](https://packages.debian.org/experimental/tesseract-ocr) switches to 4.0 and adds a non-existing package `tesseract-ocr-eng-ltsm`. Deleted comment (wrong place) Are you referring to my [other comment](https://github.com/tesseract-ocr/tesseract/issues/1131#issuecomment-329764356) about "best" and "fast"? >Are you referring to my other comment about "best" and "fast"?

Sorry, I chose the wrong tab in the browser to paste the quote :-) >  Upcoming: /usr/share/tesseract-ocr/4.00/tessdata/

@jbreiden, I still hope that we'll get semantic versioning for Tesseract. Therefore I suggest to use a different name `/usr/share/tesseract-ocr/4/tessdata/`, `/usr/share/tesseract-ocr/4.0/tessdata/` or even `/usr/share/tesseract4/tessdata/` (do you need the "-ocr" in the package names, or can it be dropped?).  The test failed for out-of-tree builds with autotools because it could not find the required files.
It also failed when the "en_US.UTF-8" locale was missing.

Now it passes. This completes my previous PR #1123.  for example
char[x,y,height,widthg]getConfidence()
有[193.0,438.0,29.0,28.0]99.415886
没[223.0,437.0,28.0,51.0]98.77193
有[900.0,0.0,0.0,0.0]99.5725
让[290.0,437.0,28.0,46.0]99.56392
the third “有” between "没" and "让",but BoundingBox().x is 900, BoundingBox().y is 0; use LSTM by Tess4j 4.0 @zdenop, as Shree noted, this issue is similar to #1015, so I suggest to close this one.  The library is provided in the build path (which is not
the same as the source path for out of tree builds).

Signed-off-by: Stefan Weil <sw@weilnetz.de> @Shreeshrii, it looks like more work is needed to get a working `apiexample_test` with out of tree builds.  >It seems that works, thank you

Why did you re-opened it?  Libtool's convenience libraries should never be installed. Fixes #985. Thank you too!  ### Environment

* **Tesseract Version**: 4.00 (cloned now from master)
* **Leptonica Version**: 1.7.8
* **Commit Number**: 7569c899f732829a56da1ed797dc3fc90093406f
* **Platform**: Linux vagrant-ubuntu-trusty-64 3.13.0-125-generic #174-Ubuntu SMP Mon Jul 10 18:51:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

### Current Behavior:
Cannot build from source from branch master

### Expected Behavior:
Should be able to build

### Steps to reconstruct:
**Run:**
git clone --depth 1 https://github.com/tesseract-ocr/tesseract.git
cd /tesseract
./autogen.sh
./configure --enable-debug
LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include"
make
make install
make training

**Output:**
/bin/bash ../libtool  --tag=CXX   --mode=link g++  -g -O2 -std=c++11  -L/usr/local/lib -llept    -o unicharset_extractor unicharset_extractor.o libtesseract_tessopt.la  ../api/libtesseract.la  -lpthread 
libtool: link: g++ -g -O2 -std=c++11 -o .libs/unicharset_extractor unicharset_extractor.o  -L/usr/local/lib /usr/local/lib/liblept.so ./.libs/libtesseract_tessopt.a ../api/.libs/libtesseract.so -lpthread -fopenmp
unicharset_extractor.o: In function `tesseract::Main(int, char**)':
/tesseract/training/unicharset_extractor.cpp:66: undefined reference to `tesseract::ReadFile(std::string const&, bool (*)(STRING const&, GenericVector<char>*))'
unicharset_extractor.o: In function `AddStringsToUnicharset':
/tesseract/training/unicharset_extractor.cpp:48: undefined reference to `tesseract::NormalizeCleanAndSegmentUTF8(tesseract::UnicodeNormMode, tesseract::OCRNorm, tesseract::GraphemeNormMode, bool, char const*, std::vector<std::string, std::allocator<std::string> >*)'
/tesseract/training/unicharset_extractor.cpp:53: undefined reference to `tesseract::IsWhitespace(int)'
unicharset_extractor.o: In function `tesseract::Main(int, char**)':
/tesseract/training/unicharset_extractor.cpp:81: undefined reference to `tesseract::SetupBasicProperties(bool, bool, UNICHARSET*)'
unicharset_extractor.o: In function `main':
/tesseract/training/unicharset_extractor.cpp:96: undefined reference to `tesseract::ParseCommandLineFlags(char const*, int*, char***, bool)'
collect2: error: ld returned 1 exit status
make[1]: *** [unicharset_extractor] Error 1
make[1]: Leaving directory `/tesseract/training'
make: *** [training] Error 2


### Suggested Fix:
The rule to make `unichar_extractor` was changed in the last pull request closed (#1116) Fixed in PR #1118  ### Environment

Using the training data from https://github.com/tesseract-ocr/tessdata/tree/master/best on tesseract 4

Exact command line parameters (aside from input, output, and config) are:

    -l jpn_vert+jpn --psm 5 --oem 1

* **Tesseract Version**: <!-- compulsory. you must provide your version -->

    tesseract 4.00.00alpha
     leptonica-1.74.4 (Jun 22 2017, 16:20:35) [MSC v.1900 DLL Release x86]
      libjpeg 9b : libpng 1.6.28 : libtiff 4.0.7 : zlib 1.2.11 : libwebp 0.6.0 : libopenjp2 2.1.2

* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->

Specific build ripped from the 2017-09-04 build of VietOCR-5.0-alpha, however the same exact behavior was experienced with "zip file with cppan generated .dll and .exe files" from https://github.com/tesseract-ocr/tesseract/wiki/4.0-with-LSTM

* **Platform**: <!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->

Windows 7 x64

### Current Behavior:

https://i.imgur.com/rtzROTu.png

OCRs correctly with the following config:

    preserve_interword_spaces 1
    paragraph_text_based 0
    textord_old_baselines 0

OCRs wrong with the following config:

    preserve_interword_spaces 1
    paragraph_text_based 0
    textord_old_baselines 1

Wrong OCR:

    ケータイは
    カバパバンに
    入れてあるし

カバパバン should be カバン

https://i.imgur.com/TA1Qa2O.png

OCRs correctly with the following config:

    preserve_interword_spaces 1
    paragraph_text_based 0
    textord_old_baselines 1

OCRs wrong with the following config:

    preserve_interword_spaces 1
    paragraph_text_based 0
    textord_old_baselines 0

Wrong OCR:

    ティイツシュは
    スカートの
    ポケットだけら
    大丈夫!

ティイツシュ should be ティッシュ (or at least テイツシユ with set of small kana)

If preserve_interword_spaces is set to 0, it appears that the relevant characters are being used more than once for different "words":

ケー タイ は
カバ パ バン に
入れ て ある し

ティ イツ シュ は
スカ ー ト の
ポケ ッ ト だ けら
大 丈夫 !

**Regardless of configuration, both examples OCR correctly if OCRed one or two lines at a time, but start OCRing wrong if three or more lines are OCRed at once.**

psm settings other than 5 (or 6 for horizontal panels) give results like "empty page", "not enough words", or missing characters/words entirely, so I can't compare them.

If imgur strips metadata, both images are set to have a DPI value of 300.

### Expected Behavior:

With at least one of the configs, for both images to OCR correctly, without characters being used in multiple words.

### Suggested Fix:

N/A The カバン example in the original post is alternatively fixed by setting "lstm_use_matrix 0". It seems like "lstm_use_matrix 1" is very bad.

More examples with bad OCR with various combinations of these two settings below. Summary: lstm_use_matrix 0 is universally better than 1, textord_old_baselines 0 is better than 1 most of the time but can throw away entire lines.

Single line: https://i.imgur.com/BTeN4Lx.png

OCRs with "reused characters" regardless of the value of textord_old_baselines or lstm_use_matrix. A fictitious ょ is inserted no matter what. Some other croppings of this particular are improved by setting "lstm_use_matrix 0", but it doesn't always help.

Setting both "lstm_use_matrix 0" and "textord_old_baselines 0" seems to help in general, but doesn't fix the problem all the time Example:

https://i.imgur.com/ji4CQdr.png

Config:

    preserve_interword_spaces 0
    paragraph_text_based 0
    textord_old_baselines 1
    lstm_use_matrix 1

Output:

    ほ の り ちゃ ん が
    一 緒 の 部 活 に

    入っ て くれ て

    うれ し いね は っ て

fictitious は

Config:

    preserve_interword_spaces 0
    paragraph_text_based 0
    textord_old_baselines 1
    lstm_use_matrix 0

Output:

    ほ の り ち ゃ ん が
    一 緒 の 部 活 に

    入 っ て く れ て

    う れ し い ね は っ て

fictitious は, still

Config:

    preserve_interword_spaces 0
    paragraph_text_based 0
    textord_old_baselines 0
    lstm_use_matrix 1

Output:

    ほ ば のり ちゃ ん が
    一 緒 の 部 活 に

    入っ て くれ て

    うれ し いね っ て

fictitious ば



Config:

    preserve_interword_spaces 0
    paragraph_text_based 0
    textord_old_baselines 0
    lstm_use_matrix 0

Output:

    ほ の り ち ゃ ん が
    一 緒 の 部 活 に

    入 っ て く れ て

    う れ し い ね っ て

Correct

Setting "textord_old_baselines 0" is definitely not ideal, because 1 (the default) is responsible for accuracy gains in various cases:

https://i.imgur.com/tH8yx84.png

textord_old_baselines 1 -> 部 長 な ん だ か ら
textord_old_baselines 0 -> 部 長 な ん だ ヵ か ら

Image where "textord_old_baselines 0" throws away an entire line: and "lstm_use_matrix 1" causes character misrecognition: https://i.imgur.com/8d65wSf.png

textord_old_baselines 1, lstm_use_matrix 1 -> ちっ DI を で　　心配 だ し　　と りあ え ず 入っ て

textord_old_baselines 0, lstm_use_matrix 1 -> めい 子 ち ゃ ん カ　　と りあ え ず 入っ て

textord_old_baselines 1, lstm_use_matrix 0 -> め じ 子 ち ゃ ん カ　　心 配 だ し　　と り あ え ず 入 っ て

textord_old_baselines 0, lstm_use_matrix 0 -> め い 子 ち ゃ ん カ　　と り あ え ず 入 っ て

(the above double fullwidth spaces are substitutes for the newlines) What's the content of the official best traineddata's config file? AFAIK, the stuff under https://github.com/tesseract-ocr/tessdata/tree/master/best is all there is for the "best" traineddata. Yes, but there's a way to unpack the traineddata and see its individual files.  [jpn.config.txt](https://github.com/tesseract-ocr/tesseract/files/1291681/jpn.config.txt)
[jpn_vert.config.txt](https://github.com/tesseract-ocr/tesseract/files/1291683/jpn_vert.config.txt)
  I'm trying to run this demo with tesseract 4.0 lstm training : 

mkdir -p ~/tesstutorial/engoutput
training/lstmtraining --debug_interval 100 \
  --traineddata ~/tesstutorial/engtrain/eng/eng.traineddata \
  --net_spec '[1,36,0,1 Ct3,3,16 Mp3,3 Lfys48 Lfx96 Lrx96 Lfx256 O1c111]' \
  --model_output ~/tesstutorial/engoutput/base --learning_rate 20e-4 \
  --train_listfile ~/tesstutorial/engtrain/eng.training_files.txt \
  --eval_listfile ~/tesstutorial/engeval/eng.training_files.txt \
  --max_iterations 5000 &>~/tesstutorial/engoutput/basetrain.log

and system returns me a message as this:
Segmentation fault (core dumped)

When I checked the log file which is generated by this process, I got this:

mgr_.Init(traineddata_path.c_str()):Error:Assert failed:in file ../lstm/lstmtrainer.h, line 110


What should I do to make it work?

------------------------

### Environment

* **Tesseract Version**: <4.0>
* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
* **Platform**: <Ubuntu 16.04>

### Current Behavior:

### Expected Behavior:

### Suggested Fix:
 @KevinZhuYF, please respond to @Shreeshrii's question.
  Did you use the updated shell scripts or your own (older) modified scripts? I didn't try the latest commits yet, but  saw that there where some changes in the shell script, and thus posted my above comment...   I am really confused. It seems that even finetunning commands does not work anymore: 
I used these commands and I put the Arabic.traineddata from the best folder in tessdata directory:

training/tesstrain.sh \ 
  --fonts_dir /usr/share/fonts \
  --training_text ./langdata/ara/ara.training_text \
  --langdata_dir ./langdata \
  --tessdata_dir ./tessdata \
  --lang ara  \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --output_dir ~/tesstutorial/aratrain
then I uesd these:

mkdir -p ~/tesstutorial/aratuned_from_ara

combine_tessdata -e ./tessdata/Arabic.traineddata \
  ~/tesstutorial/aratuned_from_ara/ara.lstm

lstmtraining --model_output ~/tesstutorial/aratuned_from_ara/aratuned \
  --continue_from ~/tesstutorial/aratuned_from_ara/ara.lstm \
  --traineddata ~/tesstutorial/aratrain/ara/ara.traineddata \
  --train_listfile ~/tesstutorial/aratrain/ara.training_files.txt \
  --target_error_rate 0.01

and I got this error:
Loaded file /home/fanasa/tesstutorial/aratuned_from_ara/ara.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Code range changed from 307 to 95!!
Must supply the old traineddata for code conversion!
Failed to continue from: /home/fanasa/tesstutorial/aratuned_from_ara/ara.lstm

while these commands worked before.  If you need the training part, use 147a1a50b766. It seems one or more of the latest commits from Ray broke the training. actully I need the changes to tessdata. because it solved the problem of
لا. under this condition can I use this 147a1a5
<https://github.com/tesseract-ocr/tesseract/commit/147a1a50b766b94c3f2ffa9b8bdccfacf2d42ff0>
?


On Tue, Sep 12, 2017 at 5:39 PM, Amit D. <notifications@github.com> wrote:

> If you need the training part, use 147a1a5
> <https://github.com/tesseract-ocr/tesseract/commit/147a1a50b766b94c3f2ffa9b8bdccfacf2d42ff0>.
> It seems one or more of the latest commits from Ray broke the training.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-328847799>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAWPo4jZ0iUhwS90AmCI5VAepfFdAks5shoJ6gaJpZM4PR9Tr>
> .
>
 @Shreeshrii 
yes . it seems that there was no problem with using training/tesstrain.sh.
 @Shreeshrii 
thanks. I think your solution is working the finetuning process was finished. I tested the result model. the problem of لا which was solved in Arabic.traineddata, again appeared in my finetuned model. 
@Shreeshrii do you have any idea why this is happening?
 @theraysmith the Arabic.traineddata can not be used in finetuning? @theraysmith I think the changes which made the Arabic.traineddata recognize لا correctly, are not applied to the source code. would you please apply these changes
 @Shreeshrii now I am facing this problem|:
Extracting unicharset from box file /tmp/tmp.UFLtOD70jF/ara/ara.Arab.exp0.box
Invalid Unicode codepoint: 0xffffffd9
IsValidCodepoint(ch):Error:Assert failed:in file ../../training/normstrngs.cpp, line 225
ERROR: /tmp/tmp.UFLtOD70jF/ara/ara.unicharset does not exist or is not readable

could you solve this? It was merged now. But I am confused. Why does this code change fix something? The new code no longer matches the comment ("In the range [0, 0xD800) or [0xE000, 0x10FFFF]"). And `0xffffffd9` does not look like a valid Unicode codepoint. @Shreeshrii but your PR removed my error. do I have to change it back.
yesterday I updated my tesseract. Do I have to use a newer version?

On Mon, Sep 18, 2017 at 9:51 AM, Shreeshrii <notifications@github.com>
wrote:

> @stweil <https://github.com/stweil> You are right.
>
> I reverted my change and training is still working now. So, it must have
> been something else that caused the problem. my PR
> https://github.com/tesseract-ocr/tesseract/pull/1134/files does not fix
> it. I had removed some unneeded software and updated the system - maybe
> that had something to do with it.
>
> However, there have been two other reports of same error -
>
> https://groups.google.com/forum/?utm_medium=email&utm_
> source=footer#!msg/tesseract-ocr/fqyYaav6vmk/M8xjpwhpBAAJ
>
> #1114 (comment)
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-330022935>
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-330131339>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAejV1sTPtVIC9dvSv9JkOIuiAtiVks5sjf3ygaJpZM4PR9Tr>
> .
>
 ccutil/unichar.h
typedef signed int char32;

ccutil/host.h
typedef uint32_t uinT32;

http://icu-project.org/apiref/icu4c/
umachine_8h.html
typedef int32_t UChar32
 Stefan,

Why a static_cast is needed here, and only for the first comparison to 'ch'? That's a trick: `return (ch >= 0 && ch < 0xD800) || (ch >= 0xE000 && ch <= 0x10FFFF)`would also implement the test for a valid code point. The static cast of the signed `ch` to an unsigned value saves the `ch >= 0` test. 

A static cast to a negative value changes nothing and could be omitted as well. Maybe we should use the explicit code without any casts and leave optimisations to the compiler.
     bool IsWhitespace(const char32 ch) {
    //  ASSERT_HOST_MSG(IsValidCodepoint(ch), "Invalid Unicode codepoint: 0x%x\n",
    //                  ch);
        if (!IsValidCodepoint(ch)) {
            tprintf("Invalid Unicode codepoint: %d = 0x%x\n", ch, ch);
        }
        return u_isUWhiteSpace(static_cast<UChar32>(ch));
    }
 @Shreeshrii, this pull request might fix it: https://github.com/ivanzz1001/tesseract/pull/1. It still has to be requested for the [tesseract-ocr](https://github.com/tesseract-ocr/tesseract) repository Try this and report (not tested):

`if (normed.empty() || IsUTF8Whitespace(normed[0])) continue;`

-->

`if (normed.empty() || IsUTF8Whitespace(normed.c_str())) continue;` @ivanzz1001 sent a PR which includes his fix and my above fix: #1153
 No error messages or asserts does not necessarily mean that the new code works. See [my comment](https://github.com/tesseract-ocr/tesseract/pull/1153#discussion_r140649990) for the pull request. @Shreeshrii
Now, can I train a new model for Arabic and Farsi using "replacing a few
layers"?
I want to replace the last layer and these are the commands I'm going to
use for farsi (I am using about 250 lines 13 fonts most of them are new)

combine_tessdata -e tessdata/fas.traineddata \
  ~/tesstutorial/newfas_from_fas/fas.lstm



lstmtraining  --old_traineddata  ./tessdata/fas.traineddata \
  --continue_from ~/tesstutorial/newfas_from_fas/fas.lstm \
  --traineddata ~/tesstutorial/fastrain/fas/fas.traineddata \
  --append_index 5 --net_spec '[Lfx192]'\
  --model_output ~/tesstutorial/newfas_from_fas/base \
  --train_listfile ~/tesstutorial/fastrain/fas.training_files.txt \
  --max_iterations 3000

On Sun, Sep 24, 2017 at 11:36 AM, Stefan Weil <notifications@github.com>
wrote:

> No error messages or asserts does not necessarily mean that the new code
> works. See my comment
> <https://github.com/tesseract-ocr/tesseract/pull/1153#discussion_r140649990>
> for the pull request.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-331694399>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAW3U9dW4A0ajTbTt1Jd4ioaxiMVhks5slg2fgaJpZM4PR9Tr>
> .
>
 @Shreeshrii
I updated tesseract just now and applied : #1153
<https://github.com/tesseract-ocr/tesseract/pull/1153>. I am trying to make
lstmf files but I get this error :

Invalid Unicode codepoint: 0xffffffd9
IsValidCodepoint(ch):Error:Assert failed:in file
../../training/normstrngs.cpp, line 225
ERROR: /tmp/tmp.X7UveftTV1/ara/ara.unicharset does not exist or is not
readable

On Tue, Oct 3, 2017 at 12:04 PM, Shreeshrii <notifications@github.com>
wrote:

> @hanikh
>
> Ray @theraysmith is the correct person to suggest the appropriate commands
> for training Arabic and Farsi.
>
> I would say, that since you have a new set of lstmf files and starter
> traineddata, experiment with both,
>
> Fine-tune plus-minus command
> And
> Replace top layer.
>
> Check the wiki for the syntax and make sure that you use the correct file
> names and path.
>
> Though, Ray recommended 3600 or so iterations, I think that number is
> suitable only for Latin based scripts.
>
>
> For complex scripts, I have tested with Devanagari, I have to go up to
> 10000-20000 iteration to get error rate down to 1%.
>
> Will be good if @theraysmith can confirm.
>
> On 03-Oct-2017 11:54 AM, "hanikh" <notifications@github.com> wrote:
>
> > @Shreeshrii
> > Now, can I train a new model for Arabic and Farsi using "replacing a few
> > layers"?
> > I want to replace the last layer and these are the commands I'm going to
> > use for farsi (I am using about 250 lines 13 fonts most of them are new)
> >
> > combine_tessdata -e tessdata/fas.traineddata \
> > ~/tesstutorial/newfas_from_fas/fas.lstm
> >
> >
> >
> > lstmtraining --old_traineddata ./tessdata/fas.traineddata \
> > --continue_from ~/tesstutorial/newfas_from_fas/fas.lstm \
> > --traineddata ~/tesstutorial/fastrain/fas/fas.traineddata \
> > --append_index 5 --net_spec '[Lfx192]'\
> > --model_output ~/tesstutorial/newfas_from_fas/base \
> > --train_listfile ~/tesstutorial/fastrain/fas.training_files.txt \
> > --max_iterations 3000
> >
> > On Sun, Sep 24, 2017 at 11:36 AM, Stefan Weil <notifications@github.com>
> > wrote:
> >
> > > No error messages or asserts does not necessarily mean that the new
> code
> > > works. See my comment
> > > <https://github.com/tesseract-ocr/tesseract/pull/1153#
> > discussion_r140649990>
> > > for the pull request.
> > >
> > > —
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/1114#
> > issuecomment-331694399>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/
> > AZFiAW3U9dW4A0ajTbTt1Jd4ioaxiMVhks5slg2fgaJpZM4PR9Tr>
> > > .
> > >
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/1114#
> issuecomment-333751166>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_o67_
> mlxJ8qCoRQGsmWn9E5awVAFvks5sodMfgaJpZM4PR9Tr>
>
> > .
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-333776145>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAeUcWqUxpaKApaIlo8Nq8GafYHK7ks5sofGogaJpZM4PR9Tr>
> .
>
 @Shreeshrii
I used the mentioned commands for replacing top layer and error rate=0.01,
it is running for about a day and I am just getting this:

Logistic output not implemented yet!

would you please help me find the problem

On Tue, Oct 3, 2017 at 3:58 PM, Shreeshrii <notifications@github.com> wrote:

> PR : #1153 <https://github.com/tesseract-ocr/tesseract/pull/1153> has
> multiple commits. Make sure you have the correct one.
>
> Also, this has not been reviewed by @theraysmith
> <https://github.com/theraysmith> so we don't know whether this is the
> recommended fix for the problem.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-333826072>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiARRkhp11pQ3p26F6g4mYc6l-0zKmks5soihfgaJpZM4PR9Tr>
> .
>
 I changed line 53 of unicharset_extractor.cpp to:
if (normed.empty() || IsUTF8Whitespace(normed.c_str())) continue;

unfortunately, the error still exists

On Wed, Oct 4, 2017 at 12:31 PM, Hanieh Khosravi <hani.khosravi@gmail.com>
wrote:

> @Shreeshrii
> I used the mentioned commands for replacing top layer and error rate=0.01,
> it is running for about a day and I am just getting this:
>
> Logistic output not implemented yet!
>
> would you please help me find the problem
>
> On Tue, Oct 3, 2017 at 3:58 PM, Shreeshrii <notifications@github.com>
> wrote:
>
>> PR : #1153 <https://github.com/tesseract-ocr/tesseract/pull/1153> has
>> multiple commits. Make sure you have the correct one.
>>
>> Also, this has not been reviewed by @theraysmith
>> <https://github.com/theraysmith> so we don't know whether this is the
>> recommended fix for the problem.
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-333826072>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AZFiARRkhp11pQ3p26F6g4mYc6l-0zKmks5soihfgaJpZM4PR9Tr>
>> .
>>
>
>
 @Shreeshrii are you still facing the error:
Invalid Unicode codepoint: 0xffffffd9
IsValidCodepoint(ch):Error:Assert failed:in file
../../training/normstrngs.cpp, line 225
ERROR: /tmp/tmp.mqNL37ZWB5/ara/ara.unicharset does not exist or is not
readable
or I'm the only one?

On Fri, Oct 6, 2017 at 8:23 PM, Shreeshrii <notifications@github.com> wrote:

> I tried testing with a one line english training text which has characters
> that get error
>
> e ¢ “ I °  © ® ﬂ
>
> Here are the debug messages that I get:
>
>
> Extracting unicharset from box file /tmp/tmp.ou9ZKjVaiJ/eng/eng.Arial.exp0.box
> Normalization strings DEBUG 'e'
> Normalization normed DEBUG 'e'
> Normalization strings DEBUG '¢'
> Normalization normed DEBUG '¢'
> Invalid Unicode codepoint: -62 = 0xffffffc2
> Normalization strings DEBUG '“'
> Normalization normed DEBUG '“'
> Invalid Unicode codepoint: -30 = 0xffffffe2
> Normalization strings DEBUG 'I'
> Normalization normed DEBUG 'I'
> Normalization strings DEBUG '°'
> Normalization normed DEBUG '°'
> Invalid Unicode codepoint: -62 = 0xffffffc2
> Normalization strings DEBUG '©'
> Normalization normed DEBUG '©'
> Invalid Unicode codepoint: -62 = 0xffffffc2
> Normalization strings DEBUG '®'
> Normalization normed DEBUG '®'
> Invalid Unicode codepoint: -62 = 0xffffffc2
> Normalization strings DEBUG 'ﬂ'
> Normalization normed DEBUG 'ﬂ'
> Invalid Unicode codepoint: -17 = 0xffffffef
>
> Using https://r12a.github.io/apps/conversion/
>
> 0x... notation
>
> 0x65 0x20 0xA2 0x20 0x201C 0x20 0x49 0x20 0xB0 0x20 0x20 0xA9 0x20 0xAE 0x20 0xFB02
>
> But the UTF-8 codepoints have some extra values...
>
> 65 20 C2 A2 20 E2 80 9C 20 49 20 C2 B0 20 20 C2 A9 20 C2 AE 20 EF AC 82
>
> This C2 etc are showing up as invalid codepoints
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-334810725>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAd6GpOHb--skt_i8azHBMqlv3W6yks5splshgaJpZM4PR9Tr>
> .
>
 @hanikh, you are not the only one. Everybody who uses that code is affected. I am currently looking for the right fix (or maybe @theraysmith already has one?). @stweil <https://github.com/stweil>
any news about the mentioned error?

On Tue, Oct 10, 2017 at 1:03 PM, Stefan Weil <notifications@github.com>
wrote:

> @hanikh <https://github.com/hanikh>, you are not the only one. Everybody
> who uses that code is affected. I am currently looking for the right fix
> (or maybe @theraysmith <https://github.com/theraysmith> already has one?).
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1114#issuecomment-335416565>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAb2018HziiG8xVm1T3FaooN1K3t9ks5sqznXgaJpZM4PR9Tr>
> .
>
 It was fixed recently (see commit fb359fc981f048328bee206fbcf69f2218ae1ee0). @Shreeshrii, does the latest version work for you, or are there issues left?  Otherwise we abort with the message `DotProductAVX can't be used on Android`. Tested on macOS Sierra 10.12.6 `Apple LLVM version 8.1.0 (clang-802.0.42)` and Alpine Linux 3.3 `gcc (Alpine 5.3.0) 5.3.0`.  Before you submit an issue, please review [the guidelines for this repository](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md).

Please report an issue only for a BUG, not for asking questions.

Note that it will be much easier for us to fix the issue if a test case that
reproduces the problem is provided. Ideally this test case should not have any
external dependencies. Provide a copy of the image or link to files for the test case.

Please delete this text and fill in the template below. 

------------------------

### Environment

* **Tesseract Version**: 
```
tesseract 3.04.01
 leptonica-1.73
  libgif 5.1.2 : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.4 : libopenjp2 2.1.0
```

* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
(Install it from ubuntu apt. `sudo apt install tesseract-ocr`)

* **Platform**: 
```
Linux jeneser-X555LF 4.10.0-33-generic #37~16.04.1-Ubuntu SMP Fri Aug 11 14:07:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
```

### Current Behavior:
When run the following command. An error has occurred.
```
cntraining hpu.font.exp0.tr
```
BUT, continue running commands, all is successfully.

My console:
```
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ tesseract hpu.font.exp0.tif hpu.font.exp0 box.train
Tesseract Open Source OCR Engine v3.04.01 with Leptonica
Page 1
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 2
Empty page!!
Page 3
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 4
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 5
Empty page!!
Page 6
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 7
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 2 words
Page 8
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 9
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 10
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 11
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 12
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 13
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
   Leaving 2 unlabelled blobs in 0 words.
Generated training data for 1 words
Page 14
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 15
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 16
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 17
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 18
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 19
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 20
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 21
FAIL!
APPLY_BOXES: boxfile line 1/q ((0,0),(15,20)): FAILURE! Couldn't find a matching blob
FAIL!
APPLY_BOXES: boxfile line 2/y ((15,0),(30,20)): FAILURE! Couldn't find a matching blob
FAIL!
APPLY_BOXES: boxfile line 3/j ((30,0),(45,20)): FAILURE! Couldn't find a matching blob
FAIL!
APPLY_BOXES: boxfile line 4/h ((45,0),(60,20)): FAILURE! Couldn't find a matching blob
APPLY_BOXES:
   Boxes read from boxfile:       4
   Boxes failed resegmentation:       4
APPLY_BOXES: Unlabelled word at :Bounding box=(0,0)->(60,20)
   Found 0 good blobs.
   1 remaining unlabelled words deleted.
Generated training data for 0 words
Page 22
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 23
FAIL!
APPLY_BOXES: boxfile line 1/h ((3,0),(17,20)): FAILURE! Couldn't find a matching blob
FAIL!
APPLY_BOXES: boxfile line 2/t ((17,0),(31,20)): FAILURE! Couldn't find a matching blob
FAIL!
APPLY_BOXES: boxfile line 3/m ((31,0),(45,20)): FAILURE! Couldn't find a matching blob
FAIL!
APPLY_BOXES: boxfile line 4/X ((45,0),(59,20)): FAILURE! Couldn't find a matching blob
APPLY_BOXES:
   Boxes read from boxfile:       4
   Boxes failed resegmentation:       4
APPLY_BOXES: Unlabelled word at :Bounding box=(3,0)->(60,20)
   Found 0 good blobs.
   1 remaining unlabelled words deleted.
Generated training data for 0 words
Page 24
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
   Leaving 2 unlabelled blobs in 0 words.
Generated training data for 2 words
Page 25
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 26
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 27
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 28
row xheight=8.66667, but median xheight = 10
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 29
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
Page 30
APPLY_BOXES:
   Boxes read from boxfile:       4
   Found 4 good blobs.
Generated training data for 1 words
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ unicharset_extractor hpu.font.exp0.box
Extracting unicharset from hpu.font.exp0.box
Wrote unicharset file ./unicharset.
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mftraining -F font_properties -U unicharset -O hpu.unicharset hpu.font.exp0.tr
Warning: No shape table file present: shapetable
Failed to load font_properties from font_properties
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mftraining -F font_properties -U unicharset -O hpu.unicharset hpu.font.exp0.tr
Warning: No shape table file present: shapetable
Reading hpu.font.exp0.tr ...
Flat shape table summary: Number of shapes = 45 max unichars = 1 number with multiple unichars = 0
Warning: no protos/configs for Joined in CreateIntTemplates()
Warning: no protos/configs for |Broken|0|1 in CreateIntTemplates()
Warning: no protos/configs for j in CreateIntTemplates()
Done!
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ cntraining hpu.font.exp0.tr
Reading hpu.font.exp0.tr ...
Clustering ...
Clustering error: Matrix inverse failed with error 1.44922

Writing normproto ...
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ cntraining hpu.font.exp0.tr
Reading hpu.font.exp0.tr ...
Clustering ...
Clustering error: Matrix inverse failed with error 1.44922

Writing normproto ...
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mv normproto hpu.normproto
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mv inttemp hpu.inttemp
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mv pffmtable hpu.pffmtable
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ mv shapetable hpu.shapetable
jeneser@jeneser-X555LF:~/workSpace/fsociety-hpu/training/training-it$ combine_tessdata hpu.
Combining tessdata files
TessdataManager combined tesseract data files.
Offset for type  0 (hpu.config                ) is -1
Offset for type  1 (hpu.unicharset            ) is 140
Offset for type  2 (hpu.unicharambigs         ) is -1
Offset for type  3 (hpu.inttemp               ) is 2644
Offset for type  4 (hpu.pffmtable             ) is 331290
Offset for type  5 (hpu.normproto             ) is 331653
Offset for type  6 (hpu.punc-dawg             ) is -1
Offset for type  7 (hpu.word-dawg             ) is -1
Offset for type  8 (hpu.number-dawg           ) is -1
Offset for type  9 (hpu.freq-dawg             ) is -1
Offset for type 10 (hpu.fixed-length-dawgs    ) is -1
Offset for type 11 (hpu.cube-unicharset       ) is -1
Offset for type 12 (hpu.cube-word-dawg        ) is -1
Offset for type 13 (hpu.shapetable            ) is 337236
Offset for type 14 (hpu.bigram-dawg           ) is -1
Offset for type 15 (hpu.unambig-dawg          ) is -1
Offset for type 16 (hpu.params-model          ) is -1
Output hpu.traineddata created successfully.
```

### Expected Behavior:

### Suggested Fix:

Thanks! duplicate of #771 
> What language are you trying to train?

I want to re-train tesseract for a specific language. It contains `numbers` and `English letters`.
like: 

![30](https://user-images.githubusercontent.com/15034042/30143429-4d3e376c-93b8-11e7-9f7e-1cf8fa087247.jpeg)

> Have you checked whether new trained data is available for it in teesara
repository?

Yes, the new trained data is *available*.

data:
[hpu.traineddata.zip](https://github.com/tesseract-ocr/tesseract/files/1283315/hpu.traineddata.zip)

> You should try with a newer version of tesseract. Look for tesseract OCR
ppa by alex.

Yep, i will try it.
  See this comment https://github.com/tesseract-ocr/tesseract/issues/781#issuecomment-323304593  We're encountering the same issue. Neither the `A` nor the `1` are extracted.
```
$ tesseract -l best/eng --oem 1 --psm 11 sparse.png sparse
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
$ cat sparse.txt
A test file

More Text

Grouping Test

Next Group

And now a paragraph.
```
Document
![sparse](https://user-images.githubusercontent.com/889237/30187766-39f49f4a-93e8-11e7-9cb7-290a752dfc6c.png)
 I would suggest you use OpenCV to detect the characters and use --PSM (character) only for the OCR. 

I archive great improve by using this additional step. If you feed the whole page in, as someone indicated above, it cannot generate the correct OCR results.  @hoangtocdo90 zmwang is probably talking about the `psm_single_char` option, `--psm 10`.  I tried compiling by following the instruction on https://github.com/tesseract-ocr/tesseract/wiki/Compiling.

When I run the command cmake ..
it gave me an error message: cppan command '0' not found, hence the solution (.sln) file was not created.

Please help.
------------------------

### Environment

* **Tesseract Version**: 4.00
* **Commit Number**: 
* **Platform**: Windows *8 64 bit

### Current Behavior:
Getting error message cppan command '0' not found.

![image](https://user-images.githubusercontent.com/31610445/30013790-be347f3c-9172-11e7-920a-047bdf5221fe.png)
Error log attached.
[CMAKE.zip](https://github.com/tesseract-ocr/tesseract/files/1273783/CMAKE.zip)



### Expected Behavior:

### Suggested Fix:
 Hi,

It is solved. Apparently I forgot to set the PATH for CMAKE and GIT in the System Environment Variables.
I set the path and ran the command again.

Cheers.
  https://github.com/tesseract-ocr/tesseract/tree/master/testing

hebrew-nikud-genesis-1-2.png contains te'amim which Tesseract's heb.traineddata does not support.
https://github.com/tesseract-ocr/langdata/issues/82
 hebtypo.jpg seems to be taken from a copyrighted book.  hi,

i try my first steps on tesseract. i have installed in on my macbook and a windows 7 32 bit machine via virtualbox. 

i want to recognize adresses from envelopes. so i made a picture (jpg and tif) and started the progress. on mac everything works fine - recognizing is very great and in the output file the adress is as expected. on windows the output file is in a single line.

e.g.

input:
name name
street number
code city

output mac is as input

output on windows:
name namestreet numbercode city

i tried all -psm modes with no effect i wanted. works. strange - but it works. thanks  
------------------------

### Environment

* **Tesseract Version**: Tesseract 4.00
* **Platform**:  Ubuntu 14.04.5 LTS (GNU/Linux 3.13.0-129-generic x86_64) 

When I use the tutorial [https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#fine-tuning-for-%C2%B1-a-few-characters] to fine tune the model
my command is 
```
training/tesstrain.sh  \
   --fonts_dir /usr/share/fonts \
  --lang chi_sim  \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --langdata_dir ../langdata \
  --tessdata_dir /home/hs/tessdata/tessdata  \
  --output_dir ../tesstutorial/chi_sim
```
I found that it print out as below in "Phase I: Generating training images":

` training/text2image --fontconfig_tmpdir=/tmp/font_tmp.k2AbBhbk8p --fonts_dir=/usr/share/fonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.4UpMo5R9vj/chi_sim/chi_sim.KaiTi_Normal.exp0 --max_pages=3 --font=KaiTi Normal --text=../langdata/chi_sim/chi_sim.training_text`

Notice that **--max_pages=3**, so I checked the ".tif" files, finding that the pages number is 3.
 
To my own work, I need more pages for the "tif/box" files, so I try to change the parameter “--max_pages” （ie, --max_pages=6）

Instead of run the command above, I try to finish its work step by step. But when I did the "Phase E: Generating lstmf files " there comes out a error which I can't solved:

```
root@super-desk:~/tesseract# api/tesseract /home/hs/tmp/chi_sim.AR_PL_UKai_CN.exp0.tif /home/hs/tmp/chi_sim.AR_PL_UKai_CN.exp0 lstm.train ../langdata/chi_sim/chi_sim.config
read_params_file: Can't open lstm.train
```

I don't know where is the " lstm.train", how can I find it?

Can anyone help me?





 Thank you @Shreeshrii ~  hi i am new on using tesseract
i am using OpenCV text module calling tesseract400.dll

in release mode i am getting "Empty page!!" messages so i did this fix in my local.
it is up to you deciding if it is useful for public.

thank you  Before you submit an issue, please review [the guidelines for this repository](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md).

Please report an issue only for a BUG, not for asking questions.

Note that it will be much easier for us to fix the issue if a test case that
reproduces the problem is provided. Ideally this test case should not have any
external dependencies. Provide a copy of the image or link to files for the test case.

Please delete this text and fill in the template below. 

------------------------

### Environment

* **Tesseract Version**: <!-- compulsory. you must provide your version -->
* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
* **Platform**: <!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->

### Current Behavior:

### Expected Behavior:

### Suggested Fix:
  I built tesseact out of 4.00.00dev. It seems like it has trouble directly reading stdin from ghostscript. Check out the following...

    gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=- demo.pdf -c quit | bin/tesseract stdin demo.ocr -oem 4

then it gives this error:

     Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
     TIFFFillStrip: Invalid strip byte count 0, strip 0.
     Error in pixReadFromTiffStream: line read fail

However if I generate the image first using ghostscript, then pipe the image to the stdin of tesseract, then it works. 

    gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=- demo.pdf -c quit > demo.tif
    cat demo.tif | bin/tesseract stdin demo.ocr -oem 4

 I don't understand what could cause this. Does one or both of the following commands work?

    gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=- demo.pdf -c quit | dd | bin/tesseract stdin demo.ocr -oem 4
    gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=- demo.pdf -c quit | dd bs=4096 | bin/tesseract stdin demo.ocr -oem 4

If yes, the problem could be caused by partial reads in Tesseract (less bytes read than requested). @stweil 

both failed

    gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=- demo.pdf -c quit | dd | bin/tesseract stdin demo.ocr -oem 4
    Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
    391+11 records in
    395+1 records out
    202521 bytes (203 kB) copied, 0.210738 s, 961 kB/s
    TIFFFillStrip: Invalid strip byte count 0, strip 0.
    Error in pixReadFromTiffStream: line read fail

    gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=- demo.pdf -c quit | dd bs=4096 | bin/tesseract stdin demo.ocr -oem 4
    Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
    46+12 records in
    46+12 records out
    202521 bytes (203 kB) copied, 0.247508 s, 818 kB/s
    TIFFFillStrip: Invalid strip byte count 0, strip 0.
    Error in pixReadFromTiffStream: line read fail


 Try running Tesseract under strace and see where things first become different.

```
gs -q -dNOPAUSE -sDEVICE=tiffg4 -sOutputFile=- demo.pdf -c quit  |strace  bin/tesseract stdin demo.ocr -oem 4
cat demo.tif | strace bin/tesseract stdin demo.ocr -oem 4
```
 @Shreeshrii 

    ./configure: line 4188: syntax error near unexpected token `-mavx,'
    ./configure: line 4188: `AX_CHECK_COMPILE_FLAG(-mavx, avx=true, avx=false)'
 @jbreiden Following is the diff right before the two processes write to stdout/stderr

```bash
< munmap(0x7fe1e9661000, 4096)            = 0
< brk(0)                                  = 0x2367000
< brk(0x238d000)                          = 0x238d000
< write(2, "TIFFFillStrip: ", 15TIFFFillStrip: )         = 15
< write(2, "Invalid strip byte count 0, stri"..., 35Invalid strip byte count 0, strip 0) = 35
< write(2, ".\n", 2.
< )                      = 2
< write(2, "Error in pixReadFromTiffStream: "..., 47Error in pixReadFromTiffStream: line read fail
< ) = 47
< close(3)                                = 0
< gettid()                                = 23463
...
```

```bash
> munmap(0x7f49e88ad000, 4096)            = 0
> brk(0)                                  = 0x1c2a000
> brk(0x1c50000)                          = 0x1c50000
> write(2, "Page 1\n", 7Page 1
> )                 = 7
> gettid()                                = 23501
> brk(0)                                  = 0x1c50000
> brk(0x1cc1000)                          = 0x1cc1000
> gettid()                                = 23501
...
``` The interesting part of the diff is expected earlier. Calls with file handle 0 (STDIN) are especially interesting. Can you upload both strace outputs?  Empty lines in text output are needed to separate paragraphs,
but there should not be an empty line at the end of the text.

Signed-off-by: Stefan Weil <sw@weilnetz.de> Related: https://github.com/tesseract-ocr/tesseract/pull/1088/commits/6773e8b909d7409f7434db67da6dff56090a7eda. @Shreeshrii, that commit is no longer needed after this pull request.  Hi, 
I have compiled tesseract 4.00.0 alpha using vs 2015 and now I want to compile text module in opencv I have got an error at : 

at line 164 of tesseract/unichar.h error 3646 'UTF32ToUtf8 'string' : unknown override specifier

[Another user](http://answers.opencv.org/question/172513/string-name-type-error-on-make-for-opencv-320330-with-tesseract/) got this message 
tesseract/unichar.h:164:10: error: ‘string’ does not name a type static string UTF32ToUTF8(const std::vector<char32>& str32); 

If I replace [line ](https://github.com/tesseract-ocr/tesseract/blob/aee910a7bfcbe0366806b68dc7f20535764c06d4/ccutil/unichar.h#L164)

static string UTF32ToUTF8(const std::vector<char32>& str32);

with 

static std::string UTF32ToUTF8(const std::vector<char32>& str32);

problem is solved for vs2015.

Is it an opencv problem or a tesseract problem ?
 https://github.com/tesseract-ocr/tesseract/issues?q=std+string+is:closed @zdenop my mistake : not to read closed issue. thanks you very much   The tests require installation of GoogleTest of course. How should we handle the case of missing GoogleTest when a user calls `make check`? Get GoogleTest automatically? Show some help text? Or accept a failure (current status)? GoogleTest is now a directory in our repo (sub repo). > GoogleTest is now a directory in our repo (sub repo).

Yes, but the submodule `googletest` is not fetched automatically. Therefore I'd prefer that `make check` should at least report the missing submodule and show a help text how to fetch it. The current error message for that case might be confusing for users.  prevents "Empty page!!" messages hi i am new on using tesseract
i am using OpenCV text module calling tesseract305.dll

in release mode i am getting "Empty page!!" messages so i did this fix in my local.
it is up to you deciding if it is useful for public.

thank you   ### Environment

* **Tesseract Version**: 4.0<!-- compulsory. you must provide your version -->
* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
* **Platform**: <!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->
windows 64bit vs2015 community

2 error on build
1. in validator.cpp,
error c2039: back_inserter is not member of std and etc...
i solve it adding #include <iterator> in validator.cpp but i'm not sure it's enough.( build is working)

2. text2image project
if I build solution with text2image in Training Tools,
there are so many error
one of them:
variable "CPPAN_SYMBOL_IMPORT" is not name...blahblah <- i'm not english user 
in many header file on text2image

so i build solution excluding text2image. and it wokr. but i hope i can build it together

 Thank you for re-comment. I did it at that time but it's not working.
maybe my environment is something wrong.. retry after time.

  The option `--disable-openmp` works for Windows with Mingw-w64, too. You don't need it neither for Linux nor for Windows, because it is possible to tell OpenMP not to create any threads:

    export OMP_THREAD_LIMIT=1
    tesseract ...

or

    OMP_THREAD_LIMIT=1 tesseract ...

You can help improving the Wiki by adding any important information which is currently missing.
  


### Environment

* **Tesseract Version**: tesseract-ocr-setup-4.0.0-alpha.20170804.exe - Latin.traineddata from best
* **Platform**: Win10 64bit

### Current Behavior:
Tesseract skippes words when doing OCR

OCR-Result: USA

### Expected Behavior:

OCR-Result: USA/NORDKOREA

### Suggested Fix:

not to skip words

---
Today I saw multiple times, that tesseract skips words, sometimes in the middle of a paragraph.

i.e. tesseract test/1502433849760_1.png test/1502433849760 -l Latin

![1502433849760_imageprocessedwithmarks](https://user-images.githubusercontent.com/30631253/29271637-bbce3160-80fc-11e7-924e-bdc5f89cca34.png)

![1502433849760_1](https://user-images.githubusercontent.com/30631253/29271612-9ac83362-80fc-11e7-9e84-aa3c650f3618.png)
[1502433849760.txt](https://github.com/tesseract-ocr/tesseract/files/1222190/1502433849760.txt)

![1502433849760_screen](https://user-images.githubusercontent.com/30631253/29271704-0fb2feaa-80fd-11e7-87bc-97a53dc5c583.jpg)
 Known problem for all langs/scripts
https://github.com/tesseract-ocr/tesseract/issues/681 In your case the problem is probably in the layout analysis stage. I've another example:

tesseract test/1502442621178.png test/1502442621178 -l Latin

Here a word in the middle of the sentence is skipped.

![1502442621178_screen](https://user-images.githubusercontent.com/30631253/29272519-b46c3aee-8100-11e7-9ad3-734e3a1b46dc.jpg)

![1502442621178](https://user-images.githubusercontent.com/30631253/29272525-b9762536-8100-11e7-8d82-0961dd49663b.png)

[1502442621178.txt](https://github.com/tesseract-ocr/tesseract/files/1222269/1502442621178.txt)

 Try cutting the non-text areas with gimp and retest. Only the red areas are processed by tesseract, they are written to separate png-files. (I've uploaded the separate files as well and the resulting output-files) The interesting thing is, two similar frames were processed without problems:

![1502434118849](https://user-images.githubusercontent.com/30631253/29273266-f7bbc636-8103-11e7-8efb-eb21a9e1fca6.jpg)

![1502431789149](https://user-images.githubusercontent.com/30631253/29273306-14a66bf2-8104-11e7-9844-a47bfab79d4c.jpg)

 >Here a word in the middle of the sentence is skipped.

Which word?

Might be related to #681 in this case. Pöllan -  the ö exists in unicharset

Thank you for the link to #681 Try to debug with stopper_debug_level=2

https://github.com/tesseract-ocr/tesseract/blob/3ec11bd37a56/ccmain/linerec.cpp#L293

 Best choice certainty=-2.96366, space=-0.206939, scaled=-20.7456, final=-20.7456
 : Pöllan : R=11.9817, C=-2.96366, F=1, Perm=2, xht=[0,3.40282e+038], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM
str	P	ö	l	l	a	n
state:	1 	1 	1 	1 	1 	1 
C	-0.237	-2.964	-0.232	-0.209	-0.192	-0.199
Deleting word with certainty -20.7456
 : Pöllan : R=11.9817, C=-20.7456, F=1, Perm=2, xht=[0,3.40282e+038], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM
str	P	ö	l	l	a	n
state:	1 	1 	1 	1 	1 	1 
C	-0.237	-2.964	-0.232	-0.209	-0.192	-0.199

[test.txt](https://github.com/tesseract-ocr/tesseract/files/1222577/test.txt)
 Best choice certainty=-0.106016, space=-2.97242, scaled=-20.8069, final=-20.8069
 : USA : R=2.24336, C=-0.106016, F=1, Perm=8, xht=[0,3.40282e+038], ambig=0
pos	NORM	NORM	NORM
str	U	S	A
state:	1 	1 	1 
C	-0.090	-0.086	-0.106
Best choice certainty=-0.229416, space=-2.97242, scaled=-20.8069, final=-20.8069
 : /NORDKOREA : R=16.2872, C=-0.229416, F=1, Perm=2, xht=[0,3.40282e+038], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM
str	/	N	O	R	D	K	O	R	E	A
state:	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 
C	-0.223	-0.202	-0.207	-0.201	-0.192	-0.208	-0.197	-0.193	-0.229	-0.228
Deleting word with certainty -20.8069
 : /NORDKOREA : R=16.2872, C=-20.8069, F=1, Perm=2, xht=[0,3.40282e+038], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM
str	/	N	O	R	D	K	O	R	E	A
state:	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 
C	-0.223	-0.202	-0.207	-0.201	-0.192	-0.208	-0.197	-0.193	-0.229	-0.228

[output_1502433849760_1.txt](https://github.com/tesseract-ocr/tesseract/files/1222585/output_1502433849760_1.txt)
 So it does recognize them, but still decides to drop them... 'Pöllan' is dropped because it's not in the dictionary and the 'ö' has low certainty.
'/NORDKOREA' is dropped because it's not in the dictionary and has low space certainty.
 'USA' shares the same low space certainty with '/NORDKOREA' but escapes from punishment because it's in the dictionary. After applying my [patch](https://github.com/tesseract-ocr/tesseract/issues/681#issuecomment-322433100):
'/NORDKOREA' ('USA /NORDKOREA')
and
'Pöllan'

are recognized in the final text output.

All other words are recognized the same as before. Thank you to both of you, your help is much appreciated! I'm on holiday till end of next week then I'll try to compile a windows version with the changes you suggested and test it. >I'll try to compile a windows version with the changes you suggested and test it.

Did you try my suggestion? I'm still on it. 
It takes me some time as I'm used to Java but I only used C/C++/... at University, which is quite some time ago. Then some other projects took my time.
I've already installed Visual Studio 2017 and the Git client.
I'll keep you updated. 
 I've been able to compile it now and starting a test run against 50k frames. looks good Tried it as well with 64bit but there I get some errors but I don't think the problem is the fix:

E:\Tesseract-OCR4.0ab1>tesseract test/1502442621178.png stdout --oem 1 -l Latin
Warning. Invalid resolution 0 dpi. Using 70 instead.
Estimating resolution as 726
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made
Error in pixCreateHeader: height must be > 0
Error in pixCreateNoInit: pixd not made
Error in pixCreate: pixd not made
Error in pixClipRectangle: pixd not made

---
x86 output:
E:\Tesseract-OCR4.0ab1>tesseract test/1502442621178.png stdout --oem 1 -l Latin
Warning. Invalid resolution 0 dpi. Using 70 instead.
Estimating resolution as 726
PATERNION

21-Jähriger geriet mit seinem
Auto in Pöllan zu weit in die
Fahrbahnmitte. Er rammte
das Auto eines 62-Jährigen.

Der Beifahrer des 21-Jährigen
wurde schwer verletzt.

---

I'll try to find the error and keep you updated.
 That one is related to image processing. Seems like a bug on (Windows?) 64 bit environment.

Please open a new issue for that.  当图片只有单字中文时候一般没法识别~
Before you submit an issue, please review [the guidelines for this repository](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md).

Please report an issue only for a BUG, not for asking questions.

Note that it will be much easier for us to fix the issue if a test case that
reproduces the problem is provided. Ideally this test case should not have any
external dependencies. Provide a copy of the image or link to files for the test case.

Please delete this text and fill in the template below. 

------------------------

### Environment

* **Tesseract Version**: <!-- compulsory. you must provide your version -->
* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
* **Platform**: <!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->

### Current Behavior:

### Expected Behavior:

### Suggested Fix:
 请给出一些重现资料，比如：需要识别的那个单字图片，你使用的tesseract版本和traneddata，以及使用场景。你是用编译好的二进制tesseract命令还是使用API在你的程序里识别，如果使用的是命令，请贴上你的命令行参数，如果是使用的SDK，请贴上代码。目前的master版本无论是在命令行下还是SDK模式下都运行的挺好。 如果是4.0版的命令行工具，请试一下：`tesseract input.tif output -psm 8 -oem 1` Translation via Google Translate

@yhfwww commented 

>When the picture is only a single word when the Chinese generally can not identify

@huanpenglee commented

>Please give some reproduction of the information, such as: need to identify that word picture, you use the tesseract version and traneddata, and use the scene. Do you use the compiled binary tesseract command or use the API to identify in your program, if you are using the command, please paste your command line parameters, if it is using the SDK, please paste the code. The current version of the master, whether it is in the command line or SDK mode are running very good.
If it is version 4.0 of the command line tool, please try: tesseract input.tif output -psm 8 -oem 1


 可以参数训练的文档，做自己的训练库来增强识别能力。



hanni_xu
 
发件人： yhf
发送时间： 2017-08-14 09:11
收件人： tesseract-ocr/tesseract
抄送： Subscribed
主题： [tesseract-ocr/tesseract] 当图片只有单字中文时候一般没法识别 (#1079)
当图片只有单字中文时候一般没法识别~
Before you submit an issue, please review the guidelines for this repository.
Please report an issue only for a BUG, not for asking questions.
Note that it will be much easier for us to fix the issue if a test case that
reproduces the problem is provided. Ideally this test case should not have any
external dependencies. Provide a copy of the image or link to files for the test case.
Please delete this text and fill in the template below.


Environment
Tesseract Version: 
Commit Number: 
Platform: 
Current Behavior:
Expected Behavior:
Suggested Fix:
—
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub, or mute the thread.
  The original image
https://image.ibb.co/fEkAma/WX20170813_165113_2x.png

If there is no -l arg, the result is look like below.

> tesseract WX20170813_165113_2x.png stdout
IH640 done
ﬁﬁiaiﬂﬁma done
iiiéimﬁiiﬁﬁ done
ﬁlm: done
ﬁEEE done

> tesseract WX20170813_165113_2x.png stdout -l chi_sim
图片640 done
每页记录数可配 done
选择城市报错 done
地图检索 done
弹囡宽度 done

Another problem is the charactor "囡" in "弹囡宽度"，actually it is "窗". tesseract WX20170813_165113_2x.png stdout -l chi_sim
read_params_file: parameter not found:

tesseract 3.04.00
 leptonica-1.72
  libgif 4.1.6(?) : libjpeg 6b (libjpeg-turbo 1.2.90) : libpng 1.5.13 : libtiff 4.0.3 : zlib 1.2.7 : libwebp 0.3.0

Do I need to upgrade tessdata? @Shreeshrii  Ok, Thanks.  I've got error 'mgr_.Init(traineddata_path.c_str()):Error:Assert failed:in file ../../../../lstm/lstmtrainer.h, line 110' when trying to run a command below. Can somebody help me with this?
All paths are correct.
version 4.0

c:\Temp\tesseract-master\tesseract-master\api>lstmtraining --model_output C:/Temp/engbest/model --continue_from C:/Temp/engbest/eng.lstm --traineddata C:/Temp/engbest/eng.traineddata --old_traineddata C:/Temp/tesseract-master/tesseract-master/tessdata/eng.traineddata --train_listfile C:/Temp/engbest/eng.training_files.txt --max_iterations 3600 Do you put the traineddate in the write directory? 
--traineddata C:/Temp/engbest/eng.traineddata
Please check that if there is eng.traineddata in C:/Temp/engbest/? If no, copy the eng.traineddata to C:/Temp/engbest/. 

Then, I think this will be resolved. I have met the same problem, and this is my resolution. It helped. Thanks. But than I got 

Loaded file C:/Temp/engbest/eng.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Code range changed from 105 to 105!!
Failed to continue from: C:/Temp/engbest/eng.lstm

stephenyong2005 Did you see error like this in your case? Sorry, I do not got such a error like you mentioned, but i got another error. By the way, I am a new user of tesseract. Do you know how to generate a lstm file? Thanks.

2017年8月13日 16:09，iuriigalaida <notifications@github.com>写道：

It helped. Thanks. But than I got

Loaded file C:/Temp/engbest/eng.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Code range changed from 105 to 105!!
Failed to continue from: C:/Temp/engbest/eng.lstm

stephenyong2005 Did you see error like this in your case?

—
You are receiving this because you commented.
Reply to this email directly, view it on GitHub<https://github.com/tesseract-ocr/tesseract/issues/1075#issuecomment-322064363>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AJBNQGx7L5w2ALkdkGuuWtd3SzwqXgI2ks5sX1fwgaJpZM4O0iiS>.

 I use v4.0.0. Compile from the source code instead of git. OS is ubuntu 17.04. I have finished the demo procedure in the wiki web page of training tesseract 4.0 by following the tutorial.

2017年8月14日 00:18，Shreeshrii <notifications@github.com>写道：

Are you using the latest source from github for building tesseract? What is your version info, git log info?

—
You are receiving this because you commented.
Reply to this email directly, view it on GitHub<https://github.com/tesseract-ocr/tesseract/issues/1075#issuecomment-322096544>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AJBNQPaOqYXe8oSSfc6LX8aVtkQ-yNRIks5sX8qFgaJpZM4O0iiS>.

 this is the tesseract wiki homepage:  https://github.com/tesseract-ocr/tesseract/wiki

2017年8月14日 00:56，Shreeshrii <notifications@github.com>写道：
> Compile from the source code instead of git.

from where?

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Aug 14, 2017 at 9:57 AM, stephenyong2005 <notifications@github.com>
wrote:

> I use v4.0.0. Compile from the source code instead of git. OS is ubuntu
> 17.04. I have finished the demo procedure in the wiki web page of training
> tesseract 4.0 by following the tutorial.
>
> 2017年8月14日 00:18，Shreeshrii <notifications@github.com>写道：
>
> Are you using the latest source from github for building tesseract? What
> is your version info, git log info?
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub<https://github.com/
> tesseract-ocr/tesseract/issues/1075#issuecomment-322096544>, or mute the
> thread<https://github.com/notifications/unsubscribe-auth/
> AJBNQPaOqYXe8oSSfc6LX8aVtkQ-yNRIks5sX8qFgaJpZM4O0iiS>.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1075#issuecomment-322097552>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_ozzaFTAJzfednKsAdNPo1yuTOjnJks5sX8yZgaJpZM4O0iiS>
> .
>

—
You are receiving this because you commented.
Reply to this email directly, view it on GitHub<https://github.com/tesseract-ocr/tesseract/issues/1075#issuecomment-322100290>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AJBNQGHjjAab3USEZ0D4HZKlj1RaZ8f_ks5sX9NqgaJpZM4O0iiS>.

 After I get latest sourses v4 lstmtraining started work but I almost always got errors like 
Encoding of string failed!
Can't encode transcription:
Even if I directly set path to unicharset file. yes. i have 44 new character and I wont to extend english traineddata. Attached my unicharset file. How can I aviod this encoding issues?

 
[eng.zip](https://github.com/tesseract-ocr/tesseract/files/1222246/eng.zip)
 The command should use tprintf() with a meaningful message and exit(), not assert.  ### Environment

* **Tesseract Version**: tesseract 4.00.00alpha<!-- compulsory. you must provide your version -->
* **Commit Number**: 8e55e52be749b3faccca8ae41abdc0e3d3c7f887<!-- optional. if known - specify commit used, if built from source -->
* **Platform**: Ubuntu 16.04.1<!-- either `uname -a` output, or if Windows, version and 32-bit or 64-bit -->

### Current Behavior:
Method WordFontAttributes returns null if using tesseract 4.00.00alpha with 4.00 tessdata, but it returns font name if using tesseract 4.00.00alpha with 3.04.00 tessdata. The test image link is [eurotext.tif](https://github.com/sirfz/tesserocr/blob/master/tests/eurotext.tif)
I first met this problem when I use tesserocr [tesserocr#68] .(https://github.com/sirfz/tesserocr/issues/68)
### Expected Behavior:
With method WordFontAttributes we can get correct font attributes of recognized words.

 The new LSTM engine does not support this feature and probably won't support it any time soon. Is there an alternative way to get font sizing etc? Do you mean that just this method won't be supported, or the feature in general?  >Is there an alternative way to get font sizing etc?

You can still use --oem 0 with traineddata from here: https://github.com/tesseract-ocr/tessdata.
Note that the traineddata in the 'best' folder won't work with --oem 0.
 >Do you mean that just this method won't be supported, or the feature in general?

I have reasons to believe that the new LSTM engine is unlikely to have a feature that includes font identification (name and properties like is_bold) in the near future.

Important note: I'm a contributer from the community, and the main developer not always shares all his plans for upcoming release(s) with the community. Thanks for the reply! It looks like the old ocr engine is going to be removed, though (issue #707)... And does using `OcrEngineMode 0` mean the behaviour is the same as v3?

What I'm getting to is:
1. I need to be able to extract font size information (font names aren't so useful) - is there any way at all of doing so with LSTM/v4?
2. If I use `OcrEngineMode 0` to be able to get this info, will that be removed from v4 at a later date?
3. Is there any advantage to using v4 with `OcrEngineMode 0` vs v3.05?

Thanks again for the help! >It looks like the old ocr engine is going to be removed, though (issue #707)... 

It's not known when exactly it will be removed. Until then you can still use it.

>And does using OcrEngineMode 0 mean the behaviour is the same as v3?

It's basically the same as 3.05.01.

>I need to be able to extract font size information (font names aren't so useful) - is there any way at all of doing so with LSTM/v4?

There is no method in the API to get font sizes for the lstm engine.

>If I use OcrEngineMode 0 to be able to get this info, will that be removed from v4 at a later date?

Probably yes.

>Is there any advantage to using v4 with OcrEngineMode 0 vs v3.05?

The accuracy should be the same. The relative font size for a textline can be estimated by calculating the xheight of the line and compare it 
to the median xheight of the other textlines in the page.  

 Ok, thanks for the info :+1:  @phildrip, 

I looked at the relevant code again, and I think the font size functionality (but not font name and properties like is_bold) can be restored when using the lstm engine.

I will provide further details (and probably send a PR) in the upcoming days.  That's great news, thanks! ```
// Returns the font attributes of the current word. If iterating at a higher
// level object than words, eg textlines, then this will return the
// attributes of the first word in that textline.
// The actual return value is a string representing a font name. It points
// to an internal table and SHOULD NOT BE DELETED. Lifespan is the same as
// the iterator itself, ie rendered invalid by various members of
// TessBaseAPI, including Init, SetImage, End or deleting the TessBaseAPI.
// Pointsize is returned in printers points (1/72 inch.)
const char* LTRResultIterator::WordFontAttributes(bool* is_bold,
                                                  bool* is_italic,
                                                  bool* is_underlined,
                                                  bool* is_monospace,
                                                  bool* is_serif,
                                                  bool* is_smallcaps,
                                                  int* pointsize,
                                                  int* font_id) const {
  if (it_->word() == NULL) return NULL;  // Already at the end!
  if (it_->word()->fontinfo == NULL) {
    *font_id = -1;
    return NULL;  // No font information.
  }
  const FontInfo& font_info = *it_->word()->fontinfo;
  *font_id = font_info.universal_id;
  *is_bold = font_info.is_bold();
  *is_italic = font_info.is_italic();
  *is_underlined = false;  // TODO(rays) fix this!
  *is_monospace = font_info.is_fixed_pitch();
  *is_serif = font_info.is_serif();
  *is_smallcaps = it_->word()->small_caps;
  float row_height = it_->row()->row->x_height() +
      it_->row()->row->ascenders() - it_->row()->row->descenders();
  // Convert from pixels to printers points.
  *pointsize = scaled_yres_ > 0
      ? static_cast<int>(row_height * kPointsPerInch / scaled_yres_ + 0.5)
      : 0;

  return font_info.name;
}
```

The problem:
```
if (it_->word()->fontinfo == NULL) {
    *font_id = -1;
    return NULL;  // No font information.
}
```

With the LSTM engine the `it_->word()->fontinfo` will always be `NULL`.
So pointsize has no chance to be calculated.

pointsize is calculated based on row (=line) height. pointsize is the font size in points of the **line**, so it should not be in **Word**FontAttributes().

There is another function where you can get row height.
```
void LTRResultIterator::RowAttributes(float* row_height, float* descenders,
                                      float* ascenders) const {
  *row_height = it_->row()->row->x_height() + it_->row()->row->ascenders() -
                it_->row()->row->descenders();
  *descenders = it_->row()->row->descenders();
  *ascenders = it_->row()->row->ascenders();
}
```

I think pointsize calculation should be moved into this function. @zdenop, @stweil 
Do you have any comment? Although my current main focus is getting the text from images, there are also important use cases where text attributes are important as well. As I understand your comments, currently the new LSTM recognizer does not support the method `WordFontAttributes`, so it is not possible to get text attributes with that recognizer. Adding support for the font size recognition with LSTM seems to be feasible, but other text attributes like for example bold or italic are desirable, too. Thank you for this clarification, Ray. >Thank you for this clarification, Ray.

+1

Ray,
In the meantime, can I fix the font size issue?
 https://github.com/tesseract-ocr/tesseract/issues/1074#issuecomment-326762911
 >Yes of course. Just re-order the code in WordFontAttributes.

That was my first thought, but it seems to give you font size in the line level, while the name of the method  implies otherwise (**Word**FontAttributese), so I suggested to move pointsize to the **Row**Attributes() method. +1  I tried to train tesseract v4.0 and got 'combine_lang_model not found' error. This code was added 4 days ago so I tried to build latest master and got '.cppan/storage/etc/static/generate.cmake:106 (message):
  cppan command '0' not found '. Can somone build and share latest tesseract binaries for Windows. Thanks in advance.  Yes. It worked. Thanks a lot ShreeDevi!  Hi, I want to finetune tesseract4.0 following this: [https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#fine-tuning-for--a-few-characters](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#fine-tuning-for--a-few-characters)
but when i run the following code:

```
scripts/tesstrain.sh --fonts_dir /usr/share/fonts --lang eng --linedata_only \
    --fontlist "DejaVu Sans" -noextract_font_properties --langdata_dir ./langdata \
    --tessdata_dir ./tessdata --output_dir ~/tesstutorial/trainplusminus
scripts/tesstrain.sh --fonts_dir /usr/share/fonts --lang eng --linedata_only \
    --noextract_font_properties --langdata_dir ./langdata \
    --tessdata_dir ./tessdata \
    --fontlist "DejaVu Sans" --output_dir ~/tesstutorial/evalplusminus

combine_tessdata -e baseline/eng.traineddata \
    ~/tesstutorial/trainplusminus/eng.lstm
lstmtraining --model_output ~/tesstutorial/trainplusminus/plusminus \
    --continue_from ~/tesstutorial/trainplusminus/eng.lstm\
    --traineddata ~/tesstutorial/trainplusminus/eng/eng.traineddata \
    --old_traineddata baseline/eng.traineddata \
    --train_listfile ~/tesstutorial/trainplusminus/eng.training_files.txt \
    --max_iterations 3600

```
I got this error:
```
14:bigram-dawg:size=16109842, offset=3221531
17:lstm:size=5390718, offset=19331373
18:lstm-punc-dawg:size=4322, offset=24722091
19:lstm-word-dawg:size=7143578, offset=24726413
20:lstm-number-dawg:size=3530, offset=31869991
23:version:size=9, offset=31873521
Loaded file ~/tesstutorial/trainplusminus/eng.lstm, unpacking...
Code range changed from 461 to 461!!
Failed to continue from: ~/tesstutorial/trainplusminus/eng.lstm
```

update:
when i remove   `--old_traineddata baseline/eng.traineddata ` like this it will work:
```
lstmtraining --model_output ~/tesstutorial/trainplusminus/plusminus \
    --continue_from ~/tesstutorial/trainplusminus/eng.lstm\
    --traineddata ~/tesstutorial/trainplusminus/eng/eng.traineddata \
    --train_listfile ~/tesstutorial/trainplusminus/eng.training_files.txt \
    --max_iterations 3600
```
but got lots of this waring:
```
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from /root/tesstutorial/trainplusminus/eng.lstm
Loaded 85/85 pages (1-85) of document /root/tesstutorial/trainplusminus/eng.DejaVu_Sans.exp0.lstmf
Encoding of string failed! Failure bytes: ffffffc2 ffffffb1 36 35 ffffffc2 ffffffb0 43 2c 20 41 45 52 4f 4d 45 58 49 43 4f 20 53 55 4d 4d 4f 4e 45 52 20 3d 20 28 31 39 36 31 29 20 41 62 6f 75 74 20 57 41 53 48 49 4e 47 20 4d 69 73 73 6f 75 72 69
Can't encode transcription: 'VOLVO abdomen, ±65°C, AEROMEXICO SUMMONER = (1961) About WASHING Missouri' in language ''
Encoding of string failed! Failure bytes: ffffffc2 ffffffb1 32 3f 20 61 63 74 69 76 69 74 79 20 50 52 4f 50 45 52 54 59 20 4d 41 49 4e 54 41 49 4e 45 44
Can't encode transcription: 'netting Bookmark of WE MORE) STRENGTH IDENTICAL ±2? activity PROPERTY MAINTAINED' in language ''
Encoding of string failed! Failure bytes: ffffffc2 ffffffb1 38 35 ffffffc2 ffffffa2 20 2c 20 72 65 6c 69 61 62 6c 65 20 45 76 65 6e 74 73 20 54 48 4f 55 53 41 4e 44 53 20 54 52 41 44 49 54 49 4f 4e 53 2e 20 41 4e 54 49 2d 55 53 20 42 65 64 72 6f 6f 6d 20 4c 65 61 64 65 72 73 68 69 70
Can't encode transcription: 'TRAVELED ±85¢ , reliable Events THOUSANDS TRADITIONS. ANTI-US Bedroom Leadership' in language ''
...
```

Why?

 Hey Shreeshrii,
I pulled and rebuilt the solution but I'm facing an issue with this command 
training/lstmtraining --stop_training   --continue_from ~/tesstutorial/trainplusminus/plusminus_checkpoint   --traineddata ~/tesstutorial/engtrain/ara.traineddata   --model_output ~/tesstutorial/trainplusminus/any.traineddata

It shows and the checkpoint generated using "training/lstmtraining": 
Failed to read continue from: /trainplusminus/plusminus_checkpoint

Btw, This issues appeared with the new commit on the master branch 2 days ago

 @Shreeshrii everything was working well until this commit "4572940" It is ok when I get the latest tessdata from https://github.com/tesseract-ocr/tessdata/tree/master/best.
Thanks for you help @Shreeshrii .  I believe that `[lang].lstm-recoder` is the compressed unicharset. It's a binary file, unlike the unicharset which is a textual file.  Peace be upon you,
@theraysmith here is a feature that I think you'll find interesting

Computer Assisted Transcription:
- The software segments the pages to lines.
- Then segments the lines into words.
- Later-on, allow the user to transcribe words or glyphs, once the user is satisfied, the software then searches for all instances of presence of such words or glyphs, and automatically transcribe them all in all instances.
- Can transcribe both Glyphs & Words, depending on the segmentation level you choose.
https://github.com/benedikt-budig/glyph-miner

[![glyph](https://user-images.githubusercontent.com/16248376/28994983-3f32bc3e-79e5-11e7-82fb-95898ec009c2.png)](https://www.youtube.com/watch?v=T-p_kIdsn6k)   tesseract 4.00.00alpha
 leptonica-1.74.1
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.5.0) : libpng 1.6.20 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.3 : libopenjp2 2.1.0
Win10 64bit - built Uni Mannheim

deu.traineddata - Repeating of characters:

Current Behavior:

ÄGYPTEN -> ÄAGYPTEN
Grand-Prix -> Gräand-Prix
AUSTRALIEN -> AUSTRAÄLIEN
GROSSBRITANNIEN -> GROSSBRITAÄANNIEN

Expected Behavior:

ÄGYPTEN -> ÄGYPTEN
Grand-Prix -> Grand-Prix
AUSTRALIEN -> AUSTRALIEN
GROSSBRITANNIEN -> GROSSBRITANNIEN

Suggested Fix:
1 blob / 1 box should only be 1 outcome / 1 result

Additional Info: 
Example images are available for posting Additional example (wW)
VW-Werk -> VwW-Werk >Suggested Fix:
1 blob / 1 box should only be 1 outcome / 1 result

1) It won't work with ligatures.
2) With the legacy OCR engine, there is  a character segmentation step, and the OCR is done on individual char blobs.  
With the new LSTM engine, the OCR is done by the neural network on sequence of pixels in text lines, not on pre-segmented blobs. The fix for most problems with the LSTM engine is more / better training.

DAS2016 Sildes,  [6. Modernization Efforts](https://github.com/tesseract-ocr/docs/blob/master/das_tutorial2016/6ModernizationEfforts.pdf) Page 17
Encyclopedia -> EE-n-c-yy-c-l-o-p-e-d-i-a -> Encyclopedia

I think that for 'in dictionary' words these kind of duplications would be eliminated. Similar issues: #884 #1011 @Shreeshrii

https://github.com/tesseract-ocr/tessdata/tree/master/best
is not working @all

deu.traineddata 19.721 KB
best - deu.traineddata 8.427 KB

best trainingdata only delivers empty results Yes, I'm using --oem 1

I'm just switching deu.traineddata in tessdata 
Old one works without problems, new one -> empty output
Checked the download - downloaded File has same size as in the repository. > Have you tested the deu model?

The new best one? No, I have not tested it yet. I am currently focused on Fraktur where the [new results](https://digi.bib.uni-mannheim.de/periodika/reichsanzeiger/ocr/film/tesseract-4.0.0-alpha.20170801/001-1879/0011.hocr) clearly beat the [old ones](https://digi.bib.uni-mannheim.de/periodika/reichsanzeiger/ocr/film/tesseract-4.0.0-alpha.20170703/001-1879/0011.hocr).

> [...] update the windows binaries on Uni Mannheim site [...]

I noticed on Linux that "old" Tesseract executables crash with the new traineddata, so I expect that my current Windows binaries would crash, too. Building new ones is on my list. thank you > [...] update the windows binaries on Uni Mannheim site [...]

The [new binaries](https://github.com/UB-Mannheim/tesseract/wiki) are now available.
I now use semantic versioning, so this is my 4.0.0-alpha.20170804.
 Thank you for the new binaries.

There are still similar errors:

hitzefrei -> 1 x hitzefreii / 1 x hitzefreil

Suggestion: The results are a lot better with 4.0. LSTM than with 3.05.01 but training seams to be difficult. Maybe it would be a good idea to offer a webpage where people could upload example image-files and matching text-files to include them in the training process.  > looks for frk traineddata, probably listed in deu.config

@theraysmith, `best/deu.traineddata` includes a `deu.config` with `tessedit_load_sublangs frk`. Why was this dependency added? It is confusing for end users who want to use `-l deu` that they need `frk.traineddata`, too.

@TheSeiko, maybe you'd get better results for Antiqua text without that `frk` dependency (which might be good for texts which also include Fraktur). You can use `combine_tessdata` to extract the components of `best/deu.traineddata`, remove deu.config and combine the remaining components again in a new file. Thank you for the tip. Much appreciated! @stweil Am I doing something wrong?

There's only a version file included in the deu,traineddata when using the binaries from 04.08

E:\Tesseract-OCR4.0a2>combine_tessdata -u deu.traineddata tmp/deu
Extracting tessdata components from deu.traineddata
Wrote tmp/deu.version
Version string:4.0.0-alpha.20170804
23:version:size=20, offset=192

E:\Tesseract-OCR4.0a2>combine_tessdata -u deu.traineddata tmp/deu.
Extracting tessdata components from deu.traineddata
Wrote tmp/deu.version
Version string:4.0.0-alpha.20170804
23:version:size=20, offset=192

E:\Tesseract-OCR4.0a2>combine_tessdata -d deu.traineddata
Version string:4.0.0-alpha.20170804
23:version:size=20, offset=192 @stweil thank you, removing deu.config helped a lot

---
ad best traineddata deu without deu.config:

after ~50k testimages: great recognition rate

only problem so far: sometimes i is not recognised properly:

sıch - sich
Parıs - Paris

I'm adding a regex to replace ı with i
 and j -> J

OCR Result <-> Text in image
Jungen - jungen
Jury - jury
Juries - juries $$-Jährige <-> $$-jährige
SPO - SPÖ @theraysmith jährige/Jährige can be both - a noun (capital letter) or an adjective (lowercase):
a 42 year old man - ein 42-jähriger Mann
a 42 year old - ein 42-Jähriger

Latin is working better with this problem, I've had it running yesterday for  ~100k frames
Latin has some problems with mutated vowels.
i.e.: 
+------------+---------+--------------------+--------------------+---------------------+
| languageId | ranking | replaceTo          | replaceRegex       | inputDate           |
+------------+---------+--------------------+--------------------+---------------------+
|         10 |      10 | Österreich         | Osterreich         | 2017-08-03 14:45:05 | - DEU without FRAK
|         10 |      10 | Paris              | Parıs              | 2017-08-08 10:52:04 | - DEU without FRAK
|         10 |      10 | i                  | ı                  | 2017-08-08 13:04:50 | - DEU without FRAK
|         10 |      10 | ÖFB-Goalie         | OFB\-Goalie        | 2017-08-08 14:20:24 | - DEU without FRAK
|         10 |      10 | Volkspartei        | Volksparte!l       | 2017-08-09 09:14:11 | - LATIN
|         10 |      10 | Eurofighter-Übung  | Eurofighter\-Ubung | 2017-08-09 09:34:09 | - LATIN
|         10 |      10 | Überlebende        | Uberlebende        | 2017-08-10 08:08:04 | - LATIN
|         10 |      10 | Eine               | Fine               | 2017-08-10 09:04:31 | - LATIN
|         10 |      10 | Oberwölz           | Oberwòölz          | 2017-08-10 10:31:30 | - LATIN
|         10 |      10 | Wörter             | Wõōrter            | 2017-08-10 14:25:23 | - LATIN
|         10 |      10 | Wörter             | Wōörter            | 2017-08-10 14:25:51 | - LATIN
|         10 |      10 | Wörter             | Wōrter             | 2017-08-10 14:26:45 | - LATIN
|         10 |      10 | Männer             | Māänner            | 2017-08-10 15:04:25 | - LATIN
+------------+---------+--------------------+--------------------+---------------------+

I've collected some example images and I'll try to do the "Fine Tuning Training" |         10 |      10 | Arzl-Ost           | Arzl\-0Ost         | 2017-08-11 09:34:41 | - LATIN
|         10 |      10 | Ein                | Fin                | 2017-08-11 09:35:26 | - LATIN
|         10 |      10 | Während            | Wāährend           | 2017-08-11 09:37:20 | - LATIN
|         10 |      10 | Oscarprämierter    | Oscarprāmierter    | 2017-08-11 10:02:07 | - LATIN |         10 | 1502045216726 | Oberwölz                                 | Oberwõlz
|         10 | 1502047625611 | Militärbasis  | Militārbasis
|         10 | 1502057831054 | www.uncut.at                                     | WWWw.uncut.at
|         10 | 1502099066258 | Wörter                                    | Wõörter
|         10 | 1502269194006 | Donaupark zum Gratis  | Donaupark zum 6Gratis  It works, thank you. Nevertheless I suggest to wait with full automake support until Ray has started integrating the first real tests from Google.  I want generate some training data for tesseract:
`tesseract tiff/data.tif testdata/data lstm.train langdata/chi_sim/chi_sim.config`
But I got a lots of the following message, it happens almost on loading every page: 

> Page 54
> Warning. Invalid resolution 1 dpi. Using 70 instead.
> Loaded 603/603 pages (1-603) of document testdata/all.lstmf
> No block overlapping textline: 2017探索
> No block overlapping textline: 主持人阵容
> No block overlapping textline: 序号
> No block overlapping textline: 节目名称
> No block overlapping textline: 节目类型
> No block overlapping textline: 演出部门
> ......
> 

My tesseract  version:
tesseract 4.00.00alpha
leptonica-1.74.4
Any sugguestion for this?  The following line generates an error because `#include <algorithm>` is missing.

`max_offset = std::max(max_offset, (*code)(i)-han_offset);`

Severity	Code	Description	Project	File	Line	Suppression State
Error	C2039	'max': is not a member of 'std'	libtesseract	<path>\tesseract\ccutil\unicharcompress.cpp	208	
  @theraysmith, 

The new (c1c1e426b327) function PrepareDistortedPix() in training/degradeimage.h is not being used currently.
https://github.com/tesseract-ocr/tesseract/blob/4efc539f512bf/training/degradeimage.h#L38

Are you going to fix that?
 
 @theraysmith 

Another try... hope you'll notice. Please read my above message (at !#1052). 

Please also see #1024  Instructions (run in Tesseract source directory):

    git submodule update --init googletest
    mkdir demo && cd demo
    cmake ..
    make
    bin/tesseract_test
 Still missing:
- Update documentation.
- Add to Travis CI.
- Support for autotools (is this needed?).

That can be done as soon as there are real tests. Maybe there are also different opinions about the best location for the `googletest` submodule or the name of the test executable (currently `tesseract_test`).

`configure` / `make` is currently not used for CI tests, so maybe it is sufficient to support `cmake` for GoogleTest and don't implement autotools support. Is there a reason to have both cmake and autotools in the first place?

The homebrew build script for Tesseract uses autotools right now, so people are building with autotools. Logically one should be able to test any configuration that gets built.

I'd be tempted to deprecate/eliminate autotools so we don't have to worry about setting up test for it, if possible.  

 I personally also use mostly autotools, for example when building the installer for Windows. As far as I know it is also used by Debian based distributions when building Tesseract packages.

For the tests, having cmake in the first place seems to be sufficient for me because CI is based on that.

I'd decide later how easy or difficult it is to maintain testing with autotools. >Is there a reason to have both cmake and autotools in the first place?
>...
>I'd be tempted to deprecate/eliminate autotools so we don't have to worry about setting up test for it, if possible.

The autotools build works fine on Posix environments.

See also: 
https://github.com/tesseract-ocr/tesseract/pull/595#issuecomment-268111725
 https://github.com/tesseract-ocr/tesseract/commit/2fbcba62e5e
 You are right Debian packaging builds Tesseract with autotools, but it would be pretty easy to switch that over to cmake if needed. You should also build leptonica with CMake. I noticed for the first time that cmake builds a `liblibtesseract.so`. That looks like a bug, because it should be `libtesseract.so`. > You should also build leptonica with CMake.

That's not strictly necessary. As long as I install it to the standard location (`/usr/lib/x86_64-linux-gnu/liblept.so.5` for my Debian installation), the Leptonica library works both with CMake and autotools.

Ray, I‌ assume that your latest Leptonica was installed in `/usr/local`. Then CMake probably won't find it by default. I think the above is a case in point for my earlier comment that we should get rid of either Autotools or CMake. When there's two equivalent tools and people prefer one or the other, maintenance of one of them falls behind. Basically, CMake is for Windows&MSVC and autotools is for all other environments.
I'm talking only about this project, not about other projects' build tool usage.

Related: https://github.com/DanBloomberg/leptonica/issues/253 I suggest to let @egorpugin (maintainer of CMake build for both Leptonica and Tesseract) some time to response before giving up on CMake for the unit-testing.  @theraysmith, pull request #1051 adds the required pieces for GoogleTest.   Hi guys ! 
I'm try training tesseract in Japanese.
In Japanese has some type of char. In my case it's about Halfwidth and fullwidth in Katakana table.
Half-width Katakana Example : ｱｲｳｴｵ   ｶｷｸｹｺ
Full-width Katakana Example : アイウエオ　カキクケコ
It's really look like similar or look like uppercase and lowercase but diffirence
When input a Halfwidth katakana, Tesseract can't recognize  or some times out with Full-width katakana.

I try to using text2img make image and box, doing ltsm.train. But have some problem with unicharset!
`set_unicharset_properties -U unicharset -O unicharset -X jpn.xheights --script_dir=./langdata`
I have checked in langdata/Katakana.unicharset. Don't have any half-width katakana symbol.
Because of this i can't make a unicharset file with all the fields set to the right values, like in this [example](https://github.com/tesseract-ocr/tesseract/wiki/Training-Tesseract#an-example-of-the-unicharset-file)

This is my unicharset file i got from run command

`unicharset_extractor jpn.msgothic.exp18.box jpn.msgothic.exp32.box jpn.msgothic.exp48.box jpn.msgothicb.exp18.box`

> 414
NULL 0 NULL 0
Joined 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 	# Joined [4a 6f 69 6e 65 64 ]
|Broken|0|1 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 	# Broken
ｱ 1 0,255,0,255,0,0,0,0,0,0 NULL 3 0 0 	# ｱ [ff71 ]x
ｳ 1 0,255,0,255,0,0,0,0,0,0 NULL 4 0 0 	# ｳ [ff73 ]x
ﾄ 1 0,255,0,255,0,0,0,0,0,0 NULL 5 0 0 	# ﾄ [ff84 ]x
ﾌ 1 0,255,0,255,0,0,0,0,0,0 NULL 6 0 0 	# ﾌ [ff8c ]x
ﾟ 1 0,255,0,255,0,0,0,0,0,0 NULL 7 0 0 	# ﾟ [ff9f ]x
ｯ 1 0,255,0,255,0,0,0,0,0,0 NULL 8 0 0 	# ｯ [ff6f ]x
ﾏ 1 0,255,0,255,0,0,0,0,0,0 NULL 9 0 0 	# ﾏ [ff8f ]x
ﾙ 1 0,255,0,255,0,0,0,0,0,0 NULL 10 0 0 	# ﾙ [ff99 ]x
ﾊ 1 0,255,0,255,0,0,0,0,0,0 NULL 11 0 0 	# ﾊ [ff8a ]x
ﾁ 1 0,255,0,255,0,0,0,0,0,0 NULL 12 0 0 	# ﾁ [ff81 ]x
ｼ 1 0,255,0,255,0,0,0,0,0,0 NULL 13 0 0 	# ｼ [ff7c ]x
ｶ 1 0,255,0,255,0,0,0,0,0,0 NULL 14 0 0 	# ｶ [ff76 ]x
ｵ 1 0,255,0,255,0,0,0,0,0,0 NULL 15 0 0 	# ｵ [ff75 ]x
ｴ 1 0,255,0,255,0,0,0,0,0,0 NULL 16 0 0 	# ｴ [ff74 ]x
ﾗ 1 0,255,0,255,0,0,0,0,0,0 NULL 17 0 0 	# ﾗ [ff97 ]x
ﾝ 1 0,255,0,255,0,0,0,0,0,0 NULL 18 0 0 	# ﾝ [ff9d ]x
ﾋ 1 0,255,0,255,0,0,0,0,0,0 NULL 19 0 0 	# ﾋ [ff8b ]x
ﾞ 1 0,255,0,255,0,0,0,0,0,0 NULL 20 0 0 	# ﾞ [ff9e ]x
ﾕ 1 0,255,0,255,0,0,0,0,0,0 NULL 21 0 0 	# ﾕ [ff95 ]x
ｰ 1 0,255,0,255,0,0,0,0,0,0 NULL 22 0 0 	# ｰ [ff70 ]x
ｻ 1 0,255,0,255,0,0,0,0,0,0 NULL 23 0 0 	# ｻ [ff7b ]x
ｫ 1 0,255,0,255,0,0,0,0,0,0 NULL 24 0 0 	# ｫ [ff6b ]x
ｽ 1 0,255,0,255,0,0,0,0,0,0 NULL 25 0 0 	# ｽ [ff7d ]x
ﾃ 1 0,255,0,255,0,0,0,0,0,0 NULL 26 0 0 	# ﾃ [ff83 ]x
ｨ 1 0,255,0,255,0,0,0,0,0,0 NULL 27 0 0 	# ｨ [ff68 ]x
ヴ 1 0,255,0,255,0,0,0,0,0,0 NULL 28 0 0 	# ヴ [30f4 ]x
ｮ 1 0,255,0,255,0,0,0,0,0,0 NULL 29 0 0 	# ｮ [ff6e ]x
ｪ 1 0,255,0,255,0,0,0,0,0,0 NULL 30 0 0 	# ｪ [ff6a ]x
ﾉ 1 0,255,0,255,0,0,0,0,0,0 NULL 31 0 0 	# ﾉ [ff89 ]x
ﾎ 1 0,255,0,255,0,0,0,0,0,0 NULL 32 0 0 	# ﾎ [ff8e ]x
ﾔ 1 0,255,0,255,0,0,0,0,0,0 NULL 33 0 0 	# ﾔ [ff94 ]x
ﾘ 1 0,255,0,255,0,0,0,0,0,0 NULL 35 0 0 	# ﾘ [ff98 ]x
ﾈ 1 0,255,0,255,0,0,0,0,0,0 NULL 36 0 0 	# ﾈ [ff88 ]x
ｲ 1 0,255,0,255,0,0,0,0,0,0 NULL 37 0 0 	# ｲ [ff72 ]x
ﾍ 1 0,255,0,255,0,0,0,0,0,0 NULL 38 0 0 	# ﾍ [ff8d ]x
ｸ 1 0,255,0,255,0,0,0,0,0,0 NULL 39 0 0 	# ｸ [ff78 ]x
ﾀ 1 0,255,0,255,0,0,0,0,0,0 NULL 40 0 0 	# ﾀ [ff80 ]x
ﾆ 1 0,255,0,255,0,0,0,0,0,0 NULL 41 0 0 	# ﾆ [ff86 ]x
ｹ 1 0,255,0,255,0,0,0,0,0,0 NULL 42 0 0 	# ｹ [ff79 ]x
ｺ 1 0,255,0,255,0,0,0,0,0,0 NULL 43 0 0 	# ｺ [ff7a ]x
ﾅ 1 0,255,0,255,0,0,0,0,0,0 NULL 44 0 0 	# ﾅ [ff85 ]x
ﾛ 1 0,255,0,255,0,0,0,0,0,0 NULL 45 0 0 	# ﾛ [ff9b ]x
ﾒ 1 0,255,0,255,0,0,0,0,0,0 NULL 46 0 0 	# ﾒ [ff92 ]x
ｿ 1 0,255,0,255,0,0,0,0,0,0 NULL 47 0 0 	# ｿ [ff7f ]x
ﾐ 1 0,255,0,255,0,0,0,0,0,0 NULL 48 0 0 	# ﾐ [ff90 ]x
ｾ 1 0,255,0,255,0,0,0,0,0,0 NULL 49 0 0 	# ｾ [ff7e ]x
ｷ 1 0,255,0,255,0,0,0,0,0,0 NULL 50 0 0 	# ｷ [ff77 ]x
ﾜ 1 0,255,0,255,0,0,0,0,0,0 NULL 51 0 0 	# ﾜ [ff9c ]x
ﾚ 1 0,255,0,255,0,0,0,0,0,0 NULL 52 0 0 	# ﾚ [ff9a ]x
ｬ 1 0,255,0,255,0,0,0,0,0,0 NULL 53 0 0 	# ｬ [ff6c ]x
ｭ 1 0,255,0,255,0,0,0,0,0,0 NULL 54 0 0 	# ｭ [ff6d ]x
ﾓ 1 0,255,0,255,0,0,0,0,0,0 NULL 60 0 0 	# ﾓ [ff93 ]x
ﾑ 1 0,255,0,255,0,0,0,0,0,0 NULL 61 0 0 	# ﾑ [ff91 ]x
ｧ 1 0,255,0,255,0,0,0,0,0,0 NULL 62 0 0 	# ｧ [ff67 ]x
ｩ 1 0,255,0,255,0,0,0,0,0,0 NULL 63 0 0 	# ｩ [ff69 ]x
ﾂ 1 0,255,0,255,0,0,0,0,0,0 NULL 64 0 0 	# ﾂ [ff82 ]x
ﾖ 1 0,255,0,255,0,0,0,0,0,0 NULL 65 0 0 	# ﾖ [ff96 ]x

Thanks! @Shreeshrii  I think halfwidth katakana not include 
@theraysmith  sir ? can you tell me how to get glyph_metrics in unicharset?  **Related issue on Tesserocr:** [here](https://github.com/sirfz/tesserocr/issues/63)

### Environment

* **Tesseract Version**: 4.00alpha
* **Commit Number**: latest as of 2017-07-19
* **Platform**: Ubuntu 16.04

### Current Behavior:

Tesseract header files since commit [da03e4e](https://github.com/tesseract-ocr/tesseract/commit/da03e4e9105b6262706d40ef2b4436eae4ebe19f#diff-4376fff11de6717e265623d40f1b0820) added the use of `string` in the `unichar.h` header file that is used during compilation by `tesserocr`. This causes the compilation of `tesserocr` to throw an error because the `std` library is not imported.

    In file included from tesserocr.cpp:484:0:
    /usr/local/include/tesseract/unichar.h:164:10: error: ‘string’ does not name a type
    static string UTF32ToUTF8(const std::vector<char32>& str32);
              ^

**Changing**  `static string UTF32ToUTF8(const std::vector<char32>& str32);` **to** `static std::string UTF32ToUTF8(const std::vector<char32>& str32);` **in** `/usr/local/include/tesseract/unichar.h:164` **fixes the problem for me.**

I am aware that you do not provide support for product that aren't the command-line Tesseract but I thought you might want to know since it worked before the commit.

### Expected Behavior:

Hopefully make it work again, if that's not an option, confirm that this is expected behavior.

### Reproducing the error

- Compile Leptonica from source
- Compile Tesseract from source (I used --disable-openmp if that matters)
- Install `tesserocr` with `pip3 install tesserocr` (obviously you need pip3 installed)

 Try this code before including Tesseract header files:

    #include <string>
    using std::string;

According to @theraysmith, the Google coding standards require `string` instead of `std::string`. Can we do something in our side that Ray will be okay with? That's my question too, while I do understand the desire to respect Google's coding guidelines, this probably won't bite only Tesserocr users... @theraysmith Is it? Because I had that problem about 3 hours ago on Ubuntu. Tesseract does build, it's the modules built with its header files that doesn't.

I'll try adding -DUSING_STD_NAMESPACE and report back. >The same define will be required for anything that uses the library too,

We need to document that requirement somewhere. It looks like `USING_STD_NAMESPACE` must always be defined. I wonder why the Tesseract code does not add `using std::string` unconditionally (making `USING_STD_NAMESPACE` unnecessary). Ray already fixed the issue with `USING_STD_NAMESPACE`. @Belval, please try the latest version from git. Indeed the issue is fixed (at least for tesserocr). Thank you! @Belval, are you using cmake and do you see the problem since commit c67c2e9f416e0b41b5e055e67ba5281e04dd5e6c (but not before that commit)? @Belval? Please answer to the questions from Ray and Stefan. Quoting my comment from [here](https://github.com/sirfz/tesserocr/issues/66#issuecomment-321010839):
> I installed the latest pull from the master branch. These changes were added in [unichar.h](https://github.com/tesseract-ocr/tesseract/commit/da03e4e9105b6262706d40ef2b4436eae4ebe19f#diff-4376fff11de6717e265623d40f1b0820R163) on 2017-07-14 (tesseract-ocr/tesseract@da03e4e9105b6262706d40ef2b4436eae4ebe19f) and [unicharset.h](https://github.com/tesseract-ocr/tesseract/commit/b0ead95d64a3667339775b2f99ac37e97e90c2a0#diff-ef746075ef360a166f1cfce7657fce21R241) on 2017-07-24 (tesseract-ocr/tesseract@b0ead95d64a3667339775b2f99ac37e97e90c2a0).

Setting `USING_STD_NAMESPACE` didn't make a difference (same [error message](https://github.com/sirfz/tesserocr/issues/66#issuecomment-321016343)).

I had to manually replace `string` with `std::string` in both unichar.h and unicharset.h to get it to compile properly. The correct macro which must be defined is `USE_STD_NAMESPACE`. `-DUSE_STD_NAMESPACE` works 👍 I am finding same issue in tesseract fb359fc ```
#include <string>
using std::string;
```
before tesseract's includes works again for current master ebbfc3ae8df8 (thanks to @stweil)  ### Environment

* **Tesseract Version**: tesseract-ocr 3.04.
* **Platform**: Windows 8 64-bit

I am using A .NET wrapper for tesseract-ocr 3.04 found here: "https://github.com/charlesw/tesseract"

### Current Behavior:

I am trying to read the following image(without the black bar that is from VS):
![image](https://user-images.githubusercontent.com/30272427/28338164-0f345f00-6bd6-11e7-9d14-02a1a0679ca8.png)

I have tried it several time and each time it returns nothing. I am using the code(below).

Am I just running into a limitation of the OCR or is there something else I could do to try and get it to work?

Code I am runnig
```
`namespace` ORC
{
    class OCRFun
    {
        public void readData(Bitmap img)
        {
            try
            {
                using (var engine = new TesseractEngine(@"./tessdata", "eng", EngineMode.Default))
                {
                    using (img)
                    {
                        using (var page = engine.Process(img))
                        {
                            var text = page.GetText();
                            Console.WriteLine("Mean confidence: {0}", page.GetMeanConfidence());

                            Console.WriteLine("Text (GetText): \r\n{0}", text);
                            Console.WriteLine("Text (iterator):");
                            using (var iter = page.GetIterator())
                            {
                                iter.Begin();

                                do
                                {
                                    do
                                    {
                                        do
                                        {
                                            do
                                            {
                                                if (iter.IsAtBeginningOf(PageIteratorLevel.Block))
                                                {
                                                    Console.WriteLine("<BLOCK>");
                                                }

                                                Console.Write(iter.GetText(PageIteratorLevel.Word));
                                                Console.Write(" ");

                                                if (iter.IsAtFinalOf(PageIteratorLevel.TextLine, PageIteratorLevel.Word))
                                                {
                                                    Console.WriteLine();
                                                }
                                            } while (iter.Next(PageIteratorLevel.TextLine, PageIteratorLevel.Word));

                                            if (iter.IsAtFinalOf(PageIteratorLevel.Para, PageIteratorLevel.TextLine))
                                            {
                                                Console.WriteLine();
                                            }
                                        } while (iter.Next(PageIteratorLevel.Para, PageIteratorLevel.TextLine));
                                    } while (iter.Next(PageIteratorLevel.Block, PageIteratorLevel.Para));
                                } while (iter.Next(PageIteratorLevel.Block));
                            }
                        }
                    }
                }
            }
            catch (Exception e)
            {
                Trace.TraceError(e.ToString());
                Console.WriteLine("Unexpected Error: " + e.Message);
                Console.WriteLine("Details: ");
                Console.WriteLine(e.ToString());
            }
            //Console.Write("Press any key to continue . . . ");
            //Console.ReadKey(true);

        }

    }
}
```


### Expected Behavior:

### Suggested Fix:
 Tesseract treating the above image text as image.
So for this do a threshold and erode image using any image processing libraries and pass it to tesseract.  Platform is Debian Jessie - Tesseract 4.00 Git Version.
Platform: Linux localhost 4.4.27-x86_64-jb1 #4 SMP Tue Jun 6 14:41:09 CEST 2017 x86_64 GNU/Linux

Tesseract crashes with "Illegal Instruction" when using anything other than --oem 0

```
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 35 diacritics
Illegal instruction

```

Tesseract -v reports
```
tesseract 4.00.00alpha
 leptonica-1.74.4
  libjpeg 6b (libjpeg-turbo 1.3.1) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8 : libopenjp2 2.1.0

 Found AVX
 Found SSE

```
I can scan with --oem 0 though. Ok, so now I reinstalled tesseract just to make sure I did everything right.
Tessdata files like 'eng.traineddata' have now been downloaded directly from the repo into  /usr/local/share/tessdata

Current content: 
`configs  deu.traineddata  eng.traineddata  pdf.ttf  tessconfigs`

Now Tesseract starts but tells me that it can't load any language. Which is quite odd.

`tesseract --tessdata-dir /usr/local/share/tessdata/tessdata -l eng  test.jpg out`
results in:
```
Error opening data file /usr/local/share/tessdata/eng.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to your "tessdata" directory.
Failed loading language 'eng'
Tesseract couldn't load any languages!
Could not initialize tesseract.
```
`tesseract -l eng  test.jpg out`
results in:
`Error opening data file /usr/local/share/eng.traineddata` 

and
`tesseract --tessdata-dir /usr/local/share/tessdata -l eng  test.jpg out`
also results in:
`Error opening data file /usr/local/share/eng.traineddata` 

And whatever I set the TESSDATA_PREFIX to, (like TESSDATA_PREFIX=/usr/share/tesseract-ocr/tessdata) does not get honored at all. 
I simply don't get it. What's going on here?
 Ok, I solved the language problem.  After unsetting TESSDATA_PREFIX and simply using:
`wget https://github.com/tesseract-ocr/tessdata/raw/4.00/deu.traineddata`
Tesseract seems to be able to load the language files from the default `/usr/local/share/tessdata` again.

But still --oem 1 results in:
```
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 35 diacritics
Illegal instruction

```

 When using the data files from:
` git clone --depth=1 https://github.com/tesseract-ocr/tessdata.git tessdata-repo`
tesseract fails to load the language files.

But when using the data files from: https://github.com/tesseract-ocr/tesseract/wiki/Data-Files
by downloading with:
wget https://github.com/tesseract-ocr/tessdata/raw/4.00/eng.traineddata 
I can start tesseract with --oem 0, but --oem 1 or --oem 2 results in the  illegal instruction message

Both ways I put the files into /usr/local/share/tessdata That's correct.  Please test tesseract with phototest.tif, as Shree suggested.
https://github.com/tesseract-ocr/tesseract/blob/master/testing/phototest.tif OK. I tested it with the traineddata above. But also it's the same I'm using here. 
I also confirmed that tesseract in indeed using the right data folder. 

But again the phototest.tif works fine with --oem 0 and results in the same error "illegal instructions" for any other --oem option or none (default should be --oem 2 if I'm not mistaken)

And although compilation seemed fine. I didn't see an error or warning. So I guess there must be some library missing here. 

Also I reinstalled Leptonica and Tesseract multiple times now.

Here's how I've installed the tools:
```
1. Make sure that the following libraries are installed:

       # nickbe:  I had to replace libpng12-dev for debian jessie

	apt-get install autoconf-archive automake g++ libtool libleptonica-dev pkg-config
	apt-get install libpango1.0-dev

	# sudo apt-get install g++ # or clang++
	sudo apt-get install autoconf automake libtool
	sudo apt-get install autoconf-archive
	sudo apt-get install pkg-config
	sudo apt-get install libpng12-dev
	sudo apt-get install libjpeg-turbo
	sudo apt-get install libtiff5-dev
	sudo apt-get install zlib1g-dev

	sudo apt-get install libicu-dev
	sudo apt-get install libpango1.0-dev
	sudo apt-get install libcairo2-dev

2. Install Leptonica:

	git clone --depth 1 https://github.com/DanBloomberg/leptonica.git leptonica
	cd leptonica
	./autobuild
	./configure
	make
	sudo make install
	ldconfig

3. Install Tesseract:

    git clone --depth 1  https://github.com/tesseract-ocr/tesseract.git tesseract-ocr
    cd tesseract-ocr
    ./autogen.sh

    ./configure --disable-openmp --disable-shared --disable-static
    or
    ./configure        # nickbe: I TESTED BOTH CONFIGURATIONS JUST TO MAKE SURE
    make

    sudo make install
	sudo ldconfig

	# sudo make training
	# sudo make training-install

	sudo make install-langs      # nickbe: Never does anything so far
      sudo ldconfig

4. wget tessdata from https://github.com/tesseract-ocr/tesseract/wiki/Data-Files
   to /usr/local/share/tessdata

   Example: wget https://github.com/tesseract-ocr/tessdata/raw/4.00/eng.traineddata

``` Do not install `libleptonica-dev` with apt-get, since you manually intsall leptonica later.   apt-get uninstall libleptonica-dev OK I enabled debug. I also installed the gdb package, but I have no experience with it. How can I provide more information? >sudo make install-langs      # nickbe: Never does anything so far

The comment is correct, so there's no point in doing that.   I think one quite important information is that I just installed the package on a fresh instance of debian stretch. I had no problems with installating Leptonica or Tesseract, but after everything was installed I have exactly the same behaviour on this machine. Tesseract runs with --oem 0 but throws the "illegal instruction" message when trying to use --oem 2 or 1.

Seems that there's something very profound missing in the installation procedure. Ok. I managed to run Tesseract with gdb. Here's the output:
```

(gdb) set args -l eng --oem 2 test.png out
(gdb) run
Starting program: /usr/local/bin/tesseract -l eng --oem 2 test.png out
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 35 diacritics

Program received signal SIGILL, Illegal instruction.
tesseract::DotProductAVX (u=0x127aa70, v=0x51dbc60, n=25) at dotproductavx.cpp:70
70            __m256d floats2 = _mm256_loadu_pd(v);
(gdb)

``` >./configure --disable-openmp --disable-shared --disable-static

https://github.com/tesseract-ocr/tesseract/issues/898#issuecomment-315202167
https://github.com/tesseract-ocr/tesseract/issues/943#issuecomment-305408592
 Change this line in configure.ac
`AX_CHECK_COMPILE_FLAG([-mavx], [avx=true], [avx=false])`
to
`AX_CHECK_COMPILE_FLAG([-mavx], [avx=false], [avx=false])`

and recompile tesseract again. btw. I already uninstalled libleptonica-dev before.

Do I have to "make uninstall" before recompiling?

 >Do I have to "make uninstall" before recompiling?

You mean `make uninstall tesseract` ?

You don't have to in this case.


Also, what's the output of `cat /proc/cpuinfo | grep flags` ?


 ```
flags           : fpu tsc msr pae cx8 apic cmov pat clflush mmx fxsr sse sse2 ss syscall nx lm constant_tsc rep_good nopl pni pclmulqdq vmx ssse3 cx16 sse4_1 sse4_2 popcnt aes f16c rdrand hypervisor lahf_lm tpr_shadow vnmi flexpriority ept vpid
flags           : fpu tsc msr pae cx8 apic cmov pat clflush mmx fxsr sse sse2 ss syscall nx lm constant_tsc rep_good nopl pni pclmulqdq vmx ssse3 cx16 sse4_1 sse4_2 popcnt aes f16c rdrand hypervisor lahf_lm tpr_shadow vnmi flexpriority ept vpid
flags           : fpu tsc msr pae cx8 apic cmov pat clflush mmx fxsr sse sse2 ss syscall nx lm constant_tsc rep_good nopl pni pclmulqdq vmx ssse3 cx16 sse4_1 sse4_2 popcnt aes f16c rdrand hypervisor lahf_lm tpr_shadow vnmi flexpriority ept vpid


``` After recompiling everything with the changed flag the new output is:

```
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 35 diacritics
DotProductAVX can't be used on Android
DotProductAVX can't be used on Android
Aborted
```

Android?! According to the output of `cat /proc/cpuinfo | grep flags`, your cpu does not support avx.
 The latest recompile was already done with the modified configure.ac. 
That was the output when running:  tesseract -l eng --oem 2 ......
As always --oem 0 works.
 OK. You will have to do another change in the code.

I will tell you later/tomorrow what to do next. 
 In arch/simddetect.h

Change this line
`static inline bool IsAVXAvailable() { return detector.avx_available_; }`
to
`static inline bool IsAVXAvailable() { return false; }`

I hope we will finish with this change :-) It's strange that `tesseract -v` reports `Found AVX` while your CPU obviously does not support AVX (see output of `/proc/cpuinfo`. That's causing the crash which you observe. What kind of CPU are you using? Are you running on a virtual machine?

Could you use the GDB debugger to step through the function `SIMDDetect::SIMDDetect` (in `arch/simddetect.cpp`) which is executed right at the beginning? Maybe you have a buggy `__get_cpuid` function (or a buggy virtual machine). Try to print the value of `ecx` which is set by that function.

Removing the code `avx_available_ = (ecx & 0x10000000) != 0;` will work around the problem and fix the crash. The change suggested by @amitdo will have the same effect. and recompile of course. Do what I said before listening to @stweil :-) @stweil 

Yes. It's strange.
I want to make sure the problem will be solved after disabling (cheating) avx detection.
If that happen, nickbe will need to undo the 2 changes and recompile. Then you will do your analysis... 
 >What kind of CPU are you using?

`cat /proc/cpuinfo | grep name`
 It's a vServer. Probably XEN but I'm not sure. We do use them quite often without problems. So I have no idea why this case is indeed so strange. I'm recompiling now... Yay. It's working finally. Thanks you so much guys 💃 Will the changes in the make make it into the official repository.?

So now that I can in fact test the new 4.0 feats, is there a way to speed up scanning? Any switches that are recommended? 

 > Will the changes in the make make it into the official repository?

No, they won't, because those changes disable AVX support which is highly desired: AVX makes Tesseract faster. The problem is most probably caused by your vServer which returns a wrong cpuid. That cpuid claims that your vServer supports AVX, but it does not. You can try to get more more information on that vServer (is it XEN, which version?) and report the problem.

We could add a Tesseract option to select SSE / AVX (overriding the automatic detection). Then Tesseract would still crash by default in your case, but it would be possible to make it work using that new option. Is this something new to the 4.00 version? Because the 3.x Versions ran just fine. Yes, it's new. AVX is used for the calculation of the dot product which is needed for LSTM (new in 4.00, not used with `--oem 0`). Maybe there's a safer method to detect the capability? Can I find out if other methods show the correct capabilities for you guys? 
If you like I'd be happy to grant you access to the server.  https://github.com/tesseract-ocr/tesseract/issues/1043#issuecomment-316519350 No I meant maybe there's a better and more secure way for you guys to recognize these kind of features @nickbe, you could help by providing more information on the kind of vServer which you were using. Sure. 
https://www.df.eu/de/cloud-hosting/
Currently it's the second smallest vServer I just wrote to Domain Factory (in German, translated here):

> One of your customers has reported a problem with the OCR application
Tesseract: https://github.com/tesseract-ocr/tesseract/issues/1043#issuecomment-317283770
>
> The cause of the crash seems to be the CPUID seen from the vServer guest. That CPUID does not fit the real hardware:
>
> According to CPUID, the CPU supports AVX operations. In fact, these lead to a crash.
>
> Doesn't your hardware support AVX (maybe an older XEON CPU)? Probably the VM of the customer migrated from newer hardware (with AVX) to an older hardware (without AVX), and now it still uses the CPUID of the newer hardware.
>
> What do you advise users in this case?
> You can also reply directly to GitHub (URL above).

XEN can set the CPUID seen by guests to avoid exactly that kind of problem: it can mask the AVX bit even when running on a new CPU with AVX support, thus allowing migration to an older CPU. @nickbe, could you please also run `cpuid --one-cpu` and `cpuid --one-cpu --raw` and post the output?  Similar problems: https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=646549, https://sourceware.org/bugzilla/show_bug.cgi?id=13007. Intel manual: https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-manual-325462.pdf#G16.42695. Nick, Domain Factory support asks for the name of your Jiffy Box. Could you send me your e-mail address (get my address [here](https://www.bib.uni-mannheim.de/stefan-weil/))? Then I'll forward their request to you. @nickbe, did you manage to solve the issue? @amitdo, I had contacted Nick's provider. They use XEN servers which do not support AVX, but the CPUID which is seen from the vServer claims that AVX is available. As far as I have understood, this happens when a XEN vServer initially runs on a server with AVX, but is migrated to another server without AVX later.

Only the provider can handle that correctly. Either the XEN vServer must always run on servers with AVX, or the XEN configuration must disable the AVX settings in CPUID even if the server has AVX support.

On the Tesseract side we could try to get a more robust AVX detection which not only checks CPUID. In addition we need an option or parameter to override the automatic selection of SSE2 / AVX. Ok, @stweil. Thanks for the info.  hi guys, yes I successfully solved the problem by following your instruction to patch the settings.
Thanks again for your support here. Very appreciated indeed :)   

------------------------

### Environment

* **Tesseract Version**:  4.00 alpha
* **Commit Number**: <!-- optional. if known - specify commit used, if built from source -->
* **Platform**: ubuntu 14, 64 bit

### Current Behavior:

```
root@pl:~/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master# training/tesstrain.sh \
>   --fonts_dir /usr/share/fonts \
>   --lang eng --linedata_only \
>   --noextract_font_properties \
>   --langdata_dir /home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master \
>   --tessdata_dir /home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/tessdata \
>   --fontlist "Lucida Sans" \
>   --output_dir /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA

=== Starting training for language 'eng'
[Tue Jul 11 13:05:43 IST 2017] /usr/local/bin/text2image --fonts_dir=/usr/share/fonts --font=Lucida Sans --outputbase=/tmp/font_tmp.XgxrkfyOjx/sample_text.txt --text=/tmp/font_tmp.XgxrkfyOjx/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.XgxrkfyOjx
Rendered page 0 to file /tmp/font_tmp.XgxrkfyOjx/sample_text.txt.tif

=== Phase I: Generating training images ===
Rendering using Lucida Sans
[Tue Jul 11 13:05:45 IST 2017] /usr/local/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.XgxrkfyOjx --fonts_dir=/usr/share/fonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0 --font=Lucida Sans --text=/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.training_text
Stripped 5 unrenderable words
Rendered page 0 to file /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.tif
Stripped 3 unrenderable words
Rendered page 1 to file /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.tif

=== Phase UP: Generating unicharset and unichar properties files ===
[Tue Jul 11 13:05:46 IST 2017] /usr/local/bin/unicharset_extractor -D /tmp/tmp.iafCx7Aypj/eng/ /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.box
Extracting unicharset from /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.box
Wrote unicharset file /tmp/tmp.iafCx7Aypj/eng//unicharset.
[Tue Jul 11 13:05:46 IST 2017] /usr/local/bin/set_unicharset_properties -U /tmp/tmp.iafCx7Aypj/eng/eng.unicharset -O /tmp/tmp.iafCx7Aypj/eng/eng.unicharset -X /tmp/tmp.iafCx7Aypj/eng/eng.xheights --script_dir=/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master
Loaded unicharset of size 111 from file /tmp/tmp.iafCx7Aypj/eng/eng.unicharset
Setting unichar properties
Other case É of é is not in unicharset
Warning: properties incomplete for index 25 = ~
Writing unicharset to file /tmp/tmp.iafCx7Aypj/eng/eng.unicharset

=== Phase D: Generating Dawg files ===
Generating word Dawg
[Tue Jul 11 13:05:46 IST 2017] /usr/local/bin/wordlist2dawg -r 1 /home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.wordlist /tmp/tmp.iafCx7Aypj/eng/eng.word-dawg /tmp/tmp.iafCx7Aypj/eng/eng.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.iafCx7Aypj/eng/eng.unicharset'
Reading word list from '/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.wordlist'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.iafCx7Aypj/eng/eng.word-dawg'
Generating frequent-word Dawg
[Tue Jul 11 13:05:48 IST 2017] /usr/local/bin/wordlist2dawg -r 1 /tmp/tmp.iafCx7Aypj/eng/eng.wordlist.clean.freq /tmp/tmp.iafCx7Aypj/eng/eng.freq-dawg /tmp/tmp.iafCx7Aypj/eng/eng.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.iafCx7Aypj/eng/eng.unicharset'
Reading word list from '/tmp/tmp.iafCx7Aypj/eng/eng.wordlist.clean.freq'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.iafCx7Aypj/eng/eng.freq-dawg'
[Tue Jul 11 13:05:48 IST 2017] /usr/local/bin/wordlist2dawg -r 0 /home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.punc /tmp/tmp.iafCx7Aypj/eng/eng.punc-dawg /tmp/tmp.iafCx7Aypj/eng/eng.unicharset
Set reverse_policy to RRP_DO_NO_REVERSE
Loading unicharset from '/tmp/tmp.iafCx7Aypj/eng/eng.unicharset'
Reading word list from '/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.punc'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.iafCx7Aypj/eng/eng.punc-dawg'
[Tue Jul 11 13:05:48 IST 2017] /usr/local/bin/wordlist2dawg -r 0 /home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.numbers /tmp/tmp.iafCx7Aypj/eng/eng.number-dawg /tmp/tmp.iafCx7Aypj/eng/eng.unicharset
Set reverse_policy to RRP_DO_NO_REVERSE
Loading unicharset from '/tmp/tmp.iafCx7Aypj/eng/eng.unicharset'
Reading word list from '/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.numbers'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.iafCx7Aypj/eng/eng.number-dawg'
[Tue Jul 11 13:05:48 IST 2017] /usr/local/bin/wordlist2dawg -r 1 /home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.word.bigrams /tmp/tmp.iafCx7Aypj/eng/eng.bigram-dawg /tmp/tmp.iafCx7Aypj/eng/eng.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.iafCx7Aypj/eng/eng.unicharset'
Reading word list from '/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/langdata-master/eng/eng.word.bigrams'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.iafCx7Aypj/eng/eng.bigram-dawg'

=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/tessdata
[Tue Jul 11 13:05:57 IST 2017] /usr/local/bin/tesseract /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.tif /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0 lstm.train
Info in bmfCreate: Generating pixa of bitmap fonts from string
Error: unichar y in normproto file is not in unichar set.
Error: unichar m in normproto file is not in unichar set.
Error: unichar “ in normproto file is not in unichar set.
Error: unichar p in normproto file is not in unichar set.
Error: unichar f in normproto file is not in unichar set.
Error: unichar " in normproto file is not in unichar set.
Error: unichar ! in normproto file is not in unichar set.
Error: unichar @ in normproto file is not in unichar set.
Error: unichar [ in normproto file is not in unichar set.
Error: unichar ¢ in normproto file is not in unichar set.
Error: unichar | in normproto file is not in unichar set.
Error: unichar x in normproto file is not in unichar set.
Error: unichar * in normproto file is not in unichar set.
Error: unichar $ in normproto file is not in unichar set.
Error: unichar £ in normproto file is not in unichar set.
Error: unichar _ in normproto file is not in unichar set.
Error: unichar { in normproto file is not in unichar set.
Error: unichar } in normproto file is not in unichar set.
Error: unichar > in normproto file is not in unichar set.
Error: unichar ¥ in normproto file is not in unichar set.
Error: unichar © in normproto file is not in unichar set.
Error: unichar z in normproto file is not in unichar set.
Error: unichar ° in normproto file is not in unichar set.
Error: unichar q in normproto file is not in unichar set.
Error: unichar w in normproto file is not in unichar set.
Error: unichar « in normproto file is not in unichar set.
Error: unichar = in normproto file is not in unichar set.
Error: unichar ; in normproto file is not in unichar set.
Error: unichar < in normproto file is not in unichar set.
Error: unichar ? in normproto file is not in unichar set.
Error: unichar ﬂ in normproto file is not in unichar set.
Error: unichar ' in normproto file is not in unichar set.
Error: unichar j in normproto file is not in unichar set.
Error: unichar » in normproto file is not in unichar set.
Error: unichar é in normproto file is not in unichar set.
Error: unichar — in normproto file is not in unichar set.
Error: unichar # in normproto file is not in unichar set.
Error: unichar ~ in normproto file is not in unichar set.
Error: unichar + in normproto file is not in unichar set.
Error: unichar ® in normproto file is not in unichar set.
Error: unichar € in normproto file is not in unichar set.
Error: unichar ‘ in normproto file is not in unichar set.
Error: unichar ﬁ in normproto file is not in unichar set.
Error: unichar ” in normproto file is not in unichar set.
Error: unichar § in normproto file is not in unichar set.
Error: unichar \ in normproto file is not in unichar set.
Error: unichar ’ in normproto file is not in unichar set.
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Page 2
Loaded 50/50 pages (1-50) of document /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.lstmf

=== Constructing LSTM training data ===
Moving /tmp/tmp.iafCx7Aypj/eng/eng.unicharset to /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA
Moving /tmp/tmp.iafCx7Aypj/eng/eng.number-dawg to /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA/eng.lstm-number-dawg
Moving /tmp/tmp.iafCx7Aypj/eng/eng.punc-dawg to /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA/eng.lstm-punc-dawg
Moving /tmp/tmp.iafCx7Aypj/eng/eng.word-dawg to /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA/eng.lstm-word-dawg
Moving /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.lstmf to /home/pl/Downloads/SRI_/USING_FILES/OUTPUT_FILES/LSTM_TN_LUCIDA

Completed training for language 'eng'

root@pl:~/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master# 
```



### Expected Behavior:






### Suggested Fix:
 These are the files which are more elaborated.


[error_text_when_training_data_generated.txt](https://github.com/tesseract-ocr/tesseract/files/1147429/error_text_when_training_data_generated.txt)
[tess_output_for_img_txt.txt](https://github.com/tesseract-ocr/tesseract/files/1147428/tess_output_for_img_txt.txt)
 Hello shree devi, can you please tell how to generate unicharset file in utf-8 format.. i am not able to find a way for that.
Can you please tell me. ```
=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=/home/pl/Downloads/SRI_/USING_FILES/TARS2_/tesseract-master/tessdata
[Tue Jul 11 13:05:57 IST 2017] /usr/local/bin/tesseract /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0.tif /tmp/tmp.iafCx7Aypj/eng/eng.Lucida_Sans.exp0 lstm.train
Info in bmfCreate: Generating pixa of bitmap fonts from string
Error: unichar y in normproto file is not in unichar set.
....
```

This looks strange, because the error here comes from the legacy OCR engine, not the LSTM engine. @amitdo  Can you please say what can i do to avoid this and train tesseract normally.

Can u give any clue why this is happening. Sorry, I don't know why it is happening. @Shreeshrii @amitdo 

i am able to generate training data with tesseract code, which i have downloaded around april.
this is the text output regarding that. everyhting seems normal

``
=== Starting training for language 'eng'
[Sat Jul 15 23:49:58 IST 2017] /usr/bin/text2image --fonts_dir=/usr/share/fonts --font=FreeSans --outputbase=/tmp/font_tmp.9J4DwTjR0e/sample_text.txt --text=/tmp/font_tmp.9J4DwTjR0e/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.9J4DwTjR0e
Rendered page 0 to file /tmp/font_tmp.9J4DwTjR0e/sample_text.txt.tif
Rtl = 0 ,vertical=0

=== Phase I: Generating training images ===
Rendering using FreeSans
[Sat Jul 15 23:50:24 IST 2017] /usr/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.9J4DwTjR0e --fonts_dir=/usr/share/fonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0 --font=FreeSans --text=/home/dell/Downloads/Tesseract_new/tess_text/eng/eng.training_text
Rendered page 0 to file /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0.tif
Rendered page 1 to file /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0.tif
Rtl = 0 ,vertical=0

=== Phase UP: Generating unicharset and unichar properties files ===
[Sat Jul 15 23:50:26 IST 2017] /usr/bin/unicharset_extractor -D /tmp/tmp.RCyux9nJxb/eng/ /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0.box
Extracting unicharset from /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0.box
Wrote unicharset file /tmp/tmp.RCyux9nJxb/eng//unicharset.
[Sat Jul 15 23:50:26 IST 2017] /usr/bin/set_unicharset_properties -U /tmp/tmp.RCyux9nJxb/eng/eng.unicharset -O /tmp/tmp.RCyux9nJxb/eng/eng.unicharset -X /tmp/tmp.RCyux9nJxb/eng/eng.xheights --script_dir=/home/dell/Downloads/Tesseract_new/tess_text
Loaded unicharset of size 115 from file /tmp/tmp.RCyux9nJxb/eng/eng.unicharset
Setting unichar properties
Other case FF of ff is not in unicharset
Other case É of é is not in unicharset
Other case FI of fi is not in unicharset
Warning: properties incomplete for index 25 = ~
Writing unicharset to file /tmp/tmp.RCyux9nJxb/eng/eng.unicharset

=== Phase D: Generating Dawg files ===
Generating word Dawg
[Sat Jul 15 23:50:26 IST 2017] /usr/bin/wordlist2dawg -r 1 /home/dell/Downloads/Tesseract_new/tess_text/eng/eng.wordlist /tmp/tmp.RCyux9nJxb/eng/eng.word-dawg /tmp/tmp.RCyux9nJxb/eng/eng.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.RCyux9nJxb/eng/eng.unicharset'
Reading word list from '/home/dell/Downloads/Tesseract_new/tess_text/eng/eng.wordlist'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.RCyux9nJxb/eng/eng.word-dawg'
Generating frequent-word Dawg
[Sat Jul 15 23:50:30 IST 2017] /usr/bin/wordlist2dawg -r 1 /tmp/tmp.RCyux9nJxb/eng/eng.wordlist.clean.freq /tmp/tmp.RCyux9nJxb/eng/eng.freq-dawg /tmp/tmp.RCyux9nJxb/eng/eng.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.RCyux9nJxb/eng/eng.unicharset'
Reading word list from '/tmp/tmp.RCyux9nJxb/eng/eng.wordlist.clean.freq'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.RCyux9nJxb/eng/eng.freq-dawg'
[Sat Jul 15 23:50:30 IST 2017] /usr/bin/wordlist2dawg -r 0 /home/dell/Downloads/Tesseract_new/tess_text/eng/eng.punc /tmp/tmp.RCyux9nJxb/eng/eng.punc-dawg /tmp/tmp.RCyux9nJxb/eng/eng.unicharset
Set reverse_policy to RRP_DO_NO_REVERSE
Loading unicharset from '/tmp/tmp.RCyux9nJxb/eng/eng.unicharset'
Reading word list from '/home/dell/Downloads/Tesseract_new/tess_text/eng/eng.punc'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.RCyux9nJxb/eng/eng.punc-dawg'
[Sat Jul 15 23:50:30 IST 2017] /usr/bin/wordlist2dawg -r 0 /home/dell/Downloads/Tesseract_new/tess_text/eng/eng.numbers /tmp/tmp.RCyux9nJxb/eng/eng.number-dawg /tmp/tmp.RCyux9nJxb/eng/eng.unicharset
Set reverse_policy to RRP_DO_NO_REVERSE
Loading unicharset from '/tmp/tmp.RCyux9nJxb/eng/eng.unicharset'
Reading word list from '/home/dell/Downloads/Tesseract_new/tess_text/eng/eng.numbers'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.RCyux9nJxb/eng/eng.number-dawg'
[Sat Jul 15 23:50:30 IST 2017] /usr/bin/wordlist2dawg -r 1 /home/dell/Downloads/Tesseract_new/tess_text/eng/eng.word.bigrams /tmp/tmp.RCyux9nJxb/eng/eng.bigram-dawg /tmp/tmp.RCyux9nJxb/eng/eng.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.RCyux9nJxb/eng/eng.unicharset'
Reading word list from '/home/dell/Downloads/Tesseract_new/tess_text/eng/eng.word.bigrams'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.RCyux9nJxb/eng/eng.bigram-dawg'

=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=/home/dell/Downloads/Tesseract_new/tesseract-master/tessdata
[Sat Jul 15 23:50:45 IST 2017] /usr/local/bin/tesseract /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0.tif /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0 lstm.train
Info in bmfCreate: Generating pixa of bitmap fonts from string
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Page 2
Loaded 53/53 pages (1-53) of document /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0.lstmf

=== Constructing LSTM training data ===
Moving /tmp/tmp.RCyux9nJxb/eng/eng.unicharset to /home/dell/Downloads/Tesseract_new/output_dir/FreeSans/LSTM_FILES_1STEP/
Moving /tmp/tmp.RCyux9nJxb/eng/eng.number-dawg to /home/dell/Downloads/Tesseract_new/output_dir/FreeSans/LSTM_FILES_1STEP//eng.lstm-number-dawg
Moving /tmp/tmp.RCyux9nJxb/eng/eng.punc-dawg to /home/dell/Downloads/Tesseract_new/output_dir/FreeSans/LSTM_FILES_1STEP//eng.lstm-punc-dawg
Moving /tmp/tmp.RCyux9nJxb/eng/eng.word-dawg to /home/dell/Downloads/Tesseract_new/output_dir/FreeSans/LSTM_FILES_1STEP//eng.lstm-word-dawg
Moving /tmp/tmp.RCyux9nJxb/eng/eng.FreeSans.exp0.lstmf to /home/dell/Downloads/Tesseract_new/output_dir/FreeSans/LSTM_FILES_1STEP/

Completed training for language 'eng'






  @Shreeshrii @amitdo 

I request any body give me brief overview,  how to train tesseract 4 with image files. How to give box and tif pairs to tesseract..

In the above command we can only see text file has been given to tesseract. What should be done if i want a image and box file is to given to tesseract.

Please advise me. you need add
--linedata_only  From general testing, it appears as though I'm I/O bound while using tesseract, and not CPU bound. I checked out the CPU Cache performance (profiled with valgrind and perf, but perf's output is easiest to read) and found that my machines have a high number of cache misses, and even a high number of iTLB misses. After inspecting the code, I also noticed that almost every function was defined as 'inline'. The high rate of iTLB misses surprised me. Usually iTLB misses are reduced after running a program for a longer period of time, but increasing the run time (for instance with an image with a lot more text) saw my iTLB miss rate increase, perhaps indicating that I am filling my iTLB, which is rare.

The iTLB misses worry me, especially because running a program for a longer period of time typically reduces them (one inevitably has cache/tlb misses when executing something that the CPU has not seen, but once it is in the cache, it should stay in the cache...). iTLB misses are expensive on Intel CPUs. I have used OpenMP in the past, but I'm not sure how it handles an iTLB miss per 'thread'. If each thread hits a miss and hits a page fault exception, and it's non blocking (which makes sense), then it'd mean that each thread would cause a page walk for the same instructions. Not sure if that's what happens, but I'd love to know what does happen (or a book or resource) if someone knows more about how OpenMP handles them.

I have seen code styled similarly at my last job, where the main part of the program was written over 25 years ago. At the time I expressed surprise (and alarm) to a co-worker, who explained that compilers used to be terrible at attempting to inline functions, and it wasn't until GCC 4 that there was a decent attempt to improve them. GCC 4 was released in 2005. (The version of GCC 4 you are using now has many updates and improvements, and is different from the GCC 4 in 2005, so GCC 4 is not that 'outdated', but it was the first major time where there were improvements.) So before 2005, best practice was to write code similar to how Tesseract identifies almost all functions as 'inline'.

The 'inline' specifier carries some interesting aspects too, and was more 'important' to use with C, since C++ defaults to 'inline' when... (From [https://gcc.gnu.org/onlinedocs/gcc-7.1.0/gcc/Inline.html#Inline](url))

> As required by ISO C++, GCC considers member functions defined within the body of a class to be marked inline even if they are not explicitly declared with the inline keyword.

Also, GCC can ignore 'inline' as it sees fit. The -O2 optimization option includes -finline-small-functions, which inlines functions that do not generate additional code. -O3 includes -finline-functions, which is more or less the same as writing 'inline' before every function, and only ignoring it if GCC decides that it may reduce performance. -O2 is in the default configure options, so adding 'inline' before each function is similar to just compiling with '-finline-functions', except that it is slightly more explicit.

There are many downsides to defining a function as 'inline', but the one people usually seem to notice is increased compile time. There's plenty of information available on Google/GNU's documentation about inline, the history of inline, and slight differences between inline in g++ and GNU C back in the day.

The biggest example of what I'd call (modern) "overactive inline use" in tesseract is probably in these files:
https://github.com/tesseract-ocr/tesseract/blob/master/lstm/functions.h
https://github.com/tesseract-ocr/tesseract/blob/master/lstm/functions.cpp

functions.cpp has two lines of code, with almost everything in functions.h.

This is also an example of compiler output with default options, i.e. keeping '-O2' and all of the different functions 'inlined' (with -Winline: https://gcc.gnu.org/onlinedocs/gcc-7.1.0/gcc/Inline.html#Inline ), defined as:

>  Using -Winline warns when a function marked inline could not be substituted, and gives the reason for the failure.

```
functions.h:63:15: warning: inlining failed in call to ‘double tesseract::Logistic(double)’: call is unlikely and code size would grow [-Winline]
 inline double Logistic(double x) {
               ^~~~~~~~
functions.h:64:37: note: called from here
   if (x < 0.0) return 1.0 - Logistic(-x);
                             ~~~~~~~~^~~~
functions.h:63:15: warning: inlining failed in call to ‘double tesseract::Logistic(double)’: call is unlikely and code size would grow [-Winline]
 inline double Logistic(double x) {
               ^~~~~~~~
functions.h:64:37: note: called from here
   if (x < 0.0) return 1.0 - Logistic(-x);
                             ~~~~~~~~^~~~
functions.h:63:15: warning: inlining failed in call to ‘double tesseract::Logistic(double)’: call is unlikely and code size would grow [-Winline]
 inline double Logistic(double x) {
               ^~~~~~~~
functions.h:64:37: note: called from here
   if (x < 0.0) return 1.0 - Logistic(-x);
                             ~~~~~~~~^~~~
functions.h:63:15: warning: inlining failed in call to ‘double tesseract::Logistic(double)’: call is unlikely and code size would grow [-Winline]
 inline double Logistic(double x) {
               ^~~~~~~~
functions.h:64:37: note: called from here
   if (x < 0.0) return 1.0 - Logistic(-x);
                             ~~~~~~~~^~~~
functions.h:45:15: warning: inlining failed in call to ‘double tesseract::Tanh(double)’: call is unlikely and code size would grow [-Winline]
 inline double Tanh(double x) {
               ^~~~
functions.h:46:28: note: called from here
   if (x < 0.0) return -Tanh(-x);
                        ~~~~^~~~
```

As a test on my target machines, I copied my 'tesseract' repository, removed all (easy to remove...) 'inline' functions, shifted the definition to the .cpp file instead of the .h file (leaving the declaration in .h as is standard practice), and compiled a separate version, installing it with a different prefix. This allowed me to have multiple versions of Tesseract on the same machine, and to run tests with all of them.

Next, I made a script. Fairly simple, utilizing GNU Parallel
CITATION:

>   O. Tange (2011): GNU Parallel - The Command-Line Power Tool,
  ;login: The USENIX Magazine, February 2011:42-47.

The simple bash scripts look like this:
```bash
#!/bin/bash
# CONTROL SCRIPT
TESS=/usr/bin/tesseract
F_LOC=(location of my test images)
parallel $TESS $F_LOC/{1} stdout ::: img1.jpg img2.png img3.jpeg
```
and
```bash
#!/bin/bash
# TEST SCRIPT
TESS=/home/hotchkiss/usr/bin/tesseract
F_LOC=(location of my test images)
parallel $TESS $F_LOC/{1} stdout ::: img1.jpg img2.png img3.jpeg
```
I'd run them ~50 times randomly(as random as /dev/urandom can afford on two options), 'randomly' defined as I randomly chose which to run, and collected the average run times and percentages as an aggregate using perf. Each run was after a fresh reboot, with no other programs running other than X, i3 (my windows manager), and my default kernel + kernel modules (less than 110MB when running 'free -m').

Results look something like:

```
 Performance counter stats for 'test_tess':

      54913.737862      task-clock:u (msec)       #    6.757 CPUs utilized          
                 0      context-switches:u        #    0.000 K/sec                  
                 0      cpu-migrations:u          #    0.000 K/sec                  
           136,385      page-faults:u             #    0.002 M/sec                  
   161,251,587,471      cycles:u                  #    2.936 GHz                      (29.05%)
   154,963,746,273      instructions:u            #    0.96  insn per cycle           (36.65%)
    35,080,176,770      branches:u                #  638.823 M/sec                    (42.77%)
       306,913,327      branch-misses:u           #    0.87% of all branches          (41.68%)
    50,274,555,586      L1-dcache-loads:u         #  915.519 M/sec                    (27.81%)
     5,075,515,864      L1-dcache-load-misses:u   #   10.10% of all L1-dcache hits    (19.72%)
       450,004,836      LLC-loads:u               #    8.195 M/sec                    (17.70%)
        23,036,525      LLC-load-misses:u         #   10.24% of all LL-cache hits     (21.92%)
   <not supported>      L1-icache-loads:u                                           
        11,674,082      L1-icache-load-misses:u                                       (28.02%)
    48,676,934,856      dTLB-loads:u              #  886.425 M/sec                    (21.31%)
         1,322,784      dTLB-load-misses:u        #    0.00% of all dTLB cache hits   (20.86%)
           264,354      iTLB-loads:u              #    0.005 M/sec                    (17.36%)
           690,732      iTLB-load-misses:u        #  261.29% of all iTLB cache hits   (21.42%)
   <not supported>      L1-dcache-prefetches:u                                      
   <not supported>      L1-dcache-prefetch-misses:u                                   

       8.127386606 seconds time elapsed
```


As expected, with no compiler optimizations and all functions with the 'inline' identifier removed, the performance was worse by a significant amount (8% to 10% worse). Also as expected with modern compilers (gcc 6.3 and gcc 8.0... I haven't run 7.x stable yet, although I could tomorrow), the performance seems to be ~the same and (perhaps, although requires more testing to be definite) better on a CPU with smaller cache/tlb sizes.

I used parallels to ensure that things were running in parallel, similar to what I will be using in production, and, what (hopefully) everyone else is doing too. I checked the other things people have posted, and it seems as though most others are doing the same too.

### What I'm asking
1. How are you collecting cache and performance information, is it standardized, and how would you like any statistics or data to be submitted/displayed?
2. Is it alright if I remove and submit code without 'inline' declared on every function?
3. Should I submit code with 'inline' removed from functions others have written?
4. What are your (other developer's) target machines like, and are my results and thought process similar?

Personally, I'm not a fan of manually marking all functions as inline, but I'm also (quite) used to re-writing code/libraries to optimize performance for my use case(s).

I can wait on posting any code changes until @theraysmith has the new beta tag out though. I'm not sure how these types of issues are handled on github either. I've spent most of my time working at a FFRDC, and haven't submitted much FOSS code publicly at all because of it, but I can post what I've done with this, which is great. Typically, I'd either write my own tests and submit along with compiled code (and a 'NO MERGE' pull request), or follow already provided tests and submit according to them, however I haven't seen any. What do you all prefer to use, and would this be something you're interested in? I absolutely abhor, detest, and strongly oppose programming for the compiler, but I feel like these changes would actually do the opposite, and allow the compiler to take over.

I'm also profiling functions for more detailed optimization with cachegrind, and I'll absolutely post those after the changes have been submitted. Again, it's less of a 'logic' change, and in some cases more of a logic 'reordering' (like order of conditional if tests, what to inline/skip/spend more time on and the like).

Another option that (might?) be decent, if it turns out that removing 'inline' does hurt performance on CPUs with large cache/tlb spaces, is that I can do something similar to what the Linux Kernel has. There is a "Allow gcc to uninline functions marked 'inline'" option (under 'Kernel Hacking') because they have run into the same issue.

------------------------

### Environment

* **Tesseract Version**: 4.0x(latest -dev)
* **Platform**: Linux [hostname] 4.12.0 #1 SMP Tue Jul 11 14:56:49 EDT 2017 x86_64 Intel(R) Core(TM) i7-4770HQ CPU @ 2.20GHz GenuineIntel GNU/Linux
(and, specs not with me right now, but posting anyway, an Intel Atom, can post later).

tested with:
gcc version 8.0.0 20170711 (experimental) (GCC)
gcc version 6.3.0 (Gentoo 6.3.0 p1.0)
I can test with gcc 7.x later if need be. I haven't switched my development system's stable version of gcc to 7 yet, even though I still test the experimental svn branch. Regarding OpenMP thread affinity control:

>https://www.nas.nasa.gov/hecc/support/kb/using-intel-openmp-thread-affinity-for-pinning_285.html

`KMP_AFFINITY` is specific to intel's OpenMP runtime.

GCC supports `GOMP_CPU_AFFINITY`
https://gcc.gnu.org/onlinedocs/libgomp/GOMP_005fCPU_005fAFFINITY.html#GOMP_005fCPU_005fAFFINITY

OpenMP 3.1 added  `OMP_PROC_BIND`
https://gcc.gnu.org/onlinedocs/libgomp/OMP_005fPROC_005fBIND.html#OMP_005fPROC_005fBIND

OpenMP 4.0 added `OMP_PLACES`
https://gcc.gnu.org/onlinedocs/libgomp/OMP_005fPLACES.html#OMP_005fPLACES


 > What are your (other developer's) target machines like, and are my results and thought process similar?

I'm just processing a larger number of images and run Tesseract on 4 Xeon servers of different age with (16 + 16 + 32 + 8) tesseract processes using GNU parallel. The binaries were built without OpenMP to avoid the overhead related with multithreading and to allow optimal use of the available CPU cores (one process per core). This setting produced [150,000 hOCR files](http://digi.bib.uni-mannheim.de/periodika/reichsanzeiger/ocr/film/tesseract-4.0.0-alpha.20170703/) during the last 10 days ([example](https://digi.bib.uni-mannheim.de/periodika/reichsanzeiger/ocr/film/tesseract-4.0.0-alpha.20170703/011-9418/0018.hocr)). Regarding OpenMP thread affinity: I think that the problem won't be fixed by binding OpenMP threads to a fixed CPU core nor will other thread libraries help. The current Tesseract simply creates too many threads even if a single process is started because it uses interleaved `#pragma omp parallel` statements. As soon as more than one process is running things get even worse because the number of threads then will exceed the number of CPU cores, and scheduling overhead will occur. >because the number of threads then will exceed the number of CPU cores

but you can limit the number of threads being used. I'm afraid you can limit it only by recompilation (either without OpenMP or with modified source code). Well, we can change the code...

(if we can prove the change will really make things better) Did you try ` OMP_THREAD_LIMIT=1 tesseract...`? No, I did not – obviously I missed that environment variable. I only had tried `OMP_NUM_THREADS`. Setting `OMP_THREAD_LIMIT=1` indeed stops thread creation. Many thanks. Now I no longer have to build special binaries without OpenMP. Great!

I just discovered this variable an hour ago :-)
https://gcc.gnu.org/onlinedocs/libgomp/Environment-Variables.html  ### Environment

Tessearct 4.00.00alpha
Windows 10 64 bit Visual Studio 2013 Win32 build. 

This issue is also present in earlier versions of Tesseract including 3.0.4 (which I fixed for our own use). 

### Current Behavior:

The GetUTF8Text() method (and other similar methods) allocates a buffer, but there is no call to free the memory, and it cannot be freed by the caller without heap corruption. 

### Expected Behavior:

### Suggested Fix:

Add a method called FreeXXText() (or whatever name is preferred) which does no more than free the memory along these lines: 

void TessBaseAPI::FreeXXText(char *text)
{
	delete[] text;
}

Deleting a null pointer is not a problem (on Windows anyway).  https://github.com/tesseract-ocr/tesseract/blob/10779bd9e50d/api/baseapi.cpp#L1273

I assume it is a Windows-only issue similar to https://github.com/tesseract-ocr/tesseract/issues/1029#issuecomment-314152843, right? This happens when you do **not** use CRT dynamic link and the heaps get confused. In projects using many dependencies, this can get tricky because all the dependencies should use the same (unless you really know what you are doing).

See https://msdn.microsoft.com/en-us/library/abx4dbyh(v=vs.80).aspx but also 
https://stackoverflow.com/questions/10820114/do-statically-linked-dlls-use-a-different-heap-than-the-main-program

In vsprops (or directly in GUI) you should use something like
```
    <ClCompile>
      <RuntimeLibrary>MultiThreadedDebugDLL</RuntimeLibrary>
    </ClCompile>
```
 Another link:

https://msdn.microsoft.com/en-us/library/ms235460.aspx
>Potential Errors Passing CRT Objects Across DLL Boundaries That's right, the app and DLL have their own heaps.  You mean `STRING`? :-)

That's what Tesseract uses in the API. I'm afraid that you will get an endless list of problems as long as your program uses more than one C runtime library on Windows. With only a single runtime library, all those problems should be solved.

It is possible to force the MS linker to always use the same msvcrt(d).dll.

You could also consider building Leptonica and Tesseract with Mingw-w64. With that combination I never had such problems. I only use one C runtime library, multithreaded DLL for release builds and multithreaded debug DLL for debug builds.  "It's better to return std::string"

Surely that has the same issue if it is allocated in the library, but freed in the application.  https://msdn.microsoft.com/en-us/library/ms235460.aspx

>The DLL and .exe file are built with /MD, so they share a single copy of the CRT.
>
>If you rebuild with /MT so that they use separate copies of the CRT, running the resulting test1Main.exe results in an access violation.

How do you build the dll and exe? > I only use one C runtime library

Nevertheless your program uses more than one C runtime library if it crashes. Use the [Process Explorer](https://technet.microsoft.com/en-us/sysinternals/processexplorer.aspx) to see which DLLs are used at runtime. For command line programs which run very short, you'll have to add a `sleep` in the `main()` function to delay the execution. dumpbin provides an alternative way to see the linkage of statically linked DLLs. For example:  

**dumpbin /IMPORTS libtesseract304.dll**

All my components use msvcr120.dll.   I need a Windows Win32 build of the Tesseract DLL version 4. I've tried and failed to build the code from the \Tesseract-4.00.00alpha branch. The first issue is that cppan.yml need editing to fix a known bug at the end: 

    pvt.cppan.demo.danbloomberg.leptonica: master

The next issue is that I get unresolved externals: 

Error	1	error LNK2001: unresolved external symbol "public: void __thiscall tesseract::Tesseract::TrainLineRecognizer(class STRING const &,class STRING const &,class BLOCK_LIST *)" (?TrainLineRecognizer@Tesseract@tesseract@@QAEXABVSTRING@@0PAVBLOCK_LIST@@@Z)	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\libtesseract\baseapi.obj	libtesseract304
Error	2	error LNK2001: unresolved external symbol "public: void __thiscall tesseract::Tesseract::LSTMRecognizeWord(class BLOCK const &,class ROW *,class WERD_RES *,class tesseract::PointerVector<class WERD_RES> *)" (?LSTMRecognizeWord@Tesseract@tesseract@@QAEXABVBLOCK@@PAVROW@@PAVWERD_RES@@PAV?$PointerVector@VWERD_RES@@@2@@Z)	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\libtesseract\control.obj	libtesseract304
Error	3	error LNK2001: unresolved external symbol "public: void __thiscall tesseract::Tesseract::RecogRawLine(class PAGE_RES *)" (?RecogRawLine@Tesseract@tesseract@@QAEXPAVPAGE_RES@@@Z)	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\libtesseract\control.obj	libtesseract304
Error	4	error LNK2001: unresolved external symbol "public: bool __thiscall tesseract::LSTMRecognizer::LoadDictionary(char const *,char const *)" (?LoadDictionary@LSTMRecognizer@tesseract@@QAE_NPBD0@Z)	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\libtesseract\tessedit.obj	libtesseract304
Error	5	error LNK2001: unresolved external symbol "public: bool __thiscall tesseract::LSTMRecognizer::DeSerialize(bool,class tesseract::TFile *)" (?DeSerialize@LSTMRecognizer@tesseract@@QAE_N_NPAVTFile@2@@Z)	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\libtesseract\tessedit.obj	libtesseract304
Error	6	error LNK2001: unresolved external symbol "public: __thiscall tesseract::LSTMRecognizer::LSTMRecognizer(void)" (??0LSTMRecognizer@tesseract@@QAE@XZ)	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\libtesseract\tessedit.obj	libtesseract304
Error	7	error LNK2001: unresolved external symbol "public: __thiscall tesseract::LSTMRecognizer::~LSTMRecognizer(void)" (??1LSTMRecognizer@tesseract@@QAE@XZ)	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\libtesseract\tesseractclass.obj	libtesseract304
Error	8	error LNK1120: 7 unresolved externals	C:\Development\Projects\Tesseract-4.00.00alpha\vs2010\DLL_Release\libtesseract304.dll	libtesseract304
	9	IntelliSense: identifier "round" is undefined	c:\Development\Projects\Tesseract-4.00.00alpha\api\baseapi.cpp	1367	43	libtesseract304

Thanks in advance.  @egorpugin,
No feedback from the OP, so please close this issue.  Hi,
when inizializing tesseract 4 with ita language (ita.traineddata for tesseract 4), the application crash on  configEngine method of G8Tesseract.mm.

<img width="585" alt="schermata 2017-07-06 alle 16 54 54" src="https://user-images.githubusercontent.com/1537350/27917284-e45683bc-626b-11e7-98bf-bc3666c1d500.png">

<img width="955" alt="schermata 2017-07-06 alle 16 51 01" src="https://user-images.githubusercontent.com/1537350/27917244-bed8d644-626b-11e7-8c2d-463004eaa036.png">

Please help me, thanks.  I try to use sudo apt-get install libleptoncia-dev on linux.

It displays that I have already installed libleptoncia-1.74, which is the newest one.

While I use ./configure to congigure the package on my system, it shows an errors again:

` error: Leptonica 1.74 or higher is required. Try to install libleptonica-dev package.`

SO I try to remove the libleptoncia-1.74 and reinstall the dev again, but it put up another error:
`Failed to connect to socket /com/ubuntu/upstart: `

I have no idea to deal with those, can anybody give me some advices? Thanks, it is helpful. I fix it.  https://github.com/tesseract-ocr/tesseract/blob/master/training/merge_unicharsets.cpp

Should we add it to `training/Makefile.am` ? Good questions, Shree. Unfortunately, I simply don't have the answers...


 I just found this file, and saw it isn't in the Makefile.am which means it won't be compiled, so you can't actually use it. It takes two or more unicharset files with this format:
https://github.com/tesseract-ocr/tesseract/wiki/Training-Tesseract#the-unicharset-file-format

I don't know when you are supposed to use it. It calls this function to do the merge:
https://github.com/tesseract-ocr/tesseract/blob/29f3de9be1fbae76925e946b9fb04bb976c3f9a0/ccutil/unicharset.cpp#L439 For next time, I suggest not to mix unrelated commits in one PR. Thanks anyway!  If Tesseract is called with a non-existing image file, it creates an empty output file.

I'd expect that no output is created in that case.

Examples:

    # Empty output.txt is created.
    tesseract nonexisting_image.tiff output
    # Empty output.hocr is created.
    tesseract nonexisting_image.tiff output hocr
  Hi,

i was trying to make fine tuning for the lstm file yet i got this error

**Deserialize failed: /home/ibr/tesstutorial/aratrain/ara.2_Baran.exp0.lstmf read 0/81 pages**
keep in mind that the path is correct so the error is **Deserialize failed**: not **Deserialize header failed**
and tesseract freezes after the error message and should press Ctrl C to stop it

i already used the same version of tesseract to tune for japanese, but for arabic i got the previous error
the command was 

`training/lstmtraining --model_output ~/tesstutorial/arabic_tuning/"arabic_tune" \
  --continue_from ~/tesstutorial/extracted_aralstm/ara.lstm \
  --train_listfile ~/tesstutorial/aratrain/ara.training_files.txt \
  --max_iterations 100000`

Thanks i was able to tune Arabic ara.lstm with the same lstmf files, but the difference i made tuning against a different version of tesseract which is: **367-g5baa8c8**. while the version that failed was: **547-g8c29e68**

strangely that the version **547-g8c29e68** passed for Japanese tuning yet it failed for Arabic tuning, as for the version **367-g5baa8c8** i didn't try it for Japanese tuning, only for Arabic and it succeeded
NOTE: both versions are running on the same VMware, and with the same leptonica version which is Leptonica1.47.1 actually all the LSTMFs (Arabic & Japanese) were created by the same version **547-g8c29e68**  yet fine tuning at the version **547-g8c29e68**  worked only for Japanese, but for Arabic (which was also created by the version **547-g8c29e68**) its fine tuning worked at the version **367-g5baa8c8**  Is this issue still happen with latest code?   Fix for #1016  Hi all 
i'm using Tesseract for get each char with Coordinate in image . I'm using ResultIterator with OCR MODE =2 (LTSM) and language = jpn.

> tesseract::ResultIterator* ri = api->GetIterator();
int index_char = 0;
vector<CharIterator> char_iterators;
do {
	char *value = ri->GetUTF8Text(tesseract::RIL_SYMBOL);
	//unknown value to space
	if (value == nullptr || value == "")value = " ";
	float conf = ri->Confidence(tesseract::RIL_SYMBOL);
	ri->BoundingBox(tesseract::RIL_SYMBOL, &left, &top, &right, &bottom);
	index_char++;
} while (ri->Next(tesseract::RIL_SYMBOL));
api->ClearAdaptiveClassifier();

Here is my program log and input image . You can see  in り character i got wrong Coordinate . I tested using tsv and hocr but it's give me same result. Still wrong Coordinate .

> Char value = こ left= 15 top = 14 right = 51 bottom = 51 conf = 99
Char value = ん left= 64 top = 9 right = 112 bottom = 54 conf = 99
Char value = ば left= 122 top = 5 right = 171 bottom = 54 conf = 99
Char value = ん left= 176 top = 9 right = 224 bottom = 54 conf = 99
Char value = は left= 234 top = 9 right = 281 bottom = 54 conf = 99
Char value = こ left= 295 top = 14 right = 331 bottom = 51 conf = 99
Char value = ん left= 344 top = 9 right = 392 bottom = 54 conf = 99
Char value = ば left= 402 top = 5 right = 445 bottom = 54 conf = 99
Char value = ん left= 456 top = 9 right = 497 bottom = 54 conf = 99
Char value = は left= 514 top = 9 right = 561 bottom = 54 conf = 99
Char value = ご left= 15 top = 79 right = 58 bottom = 126 conf = 99
Char value = 飯 left= 62 top = 80 right = 113 bottom = 130 conf = 99
Char value = 大 left= 120 top = 80 right = 225 bottom = 130 conf = 99
Char value = 盛 left= 242 top = 83 right = 260 bottom = 130 conf = 99
Char value = り left= 2328 top = 1616 right = 2328 bottom = 1616 conf = 99
Char value = 。 left= 289 top = 116 right = 305 bottom = 131 conf = 99

![jpn msgothic exp0](https://user-images.githubusercontent.com/22963463/27729378-9d2f8196-5dc0-11e7-9c99-5090652734bb.jpg)
And one more question . I'm try to and fonts in jpn data but may be i must re train from scratch. But i don't know actrually my jpn tessseract data (i'm downloaded from tessdata repository) how to make this?
I'm try download data from langdata repository make image from jpn.traintext and train it by using tesstrain.sh and Jtessboxeditor . But i got low accurary than i download from repository.  Some body can tell me extractly how to make it!
Sorry for my bad english    i got a same problem. i am using jpn.traindata.
i tried RIL_SYMBOL, RIL_WORD. RIL_SYMBOL is better.
A critical problem is ---- the recgnized character is so good but the position is too bad.
i need the pair of image and character, don't you?
If you have new information pls tell me.

thanks I'm temple fix this by using this way
I'm using RIL_SYMBOL. in my case the wrong Coordinate usually appear in a end of lines or end of block
res_it->IsAtFinalElement(RIL_TEXTLINE, RIL_WORD)
res_it->IsAtFinalElement(RIL_PARA, RIL_WORD)
res_it->IsAtFinalElement(RIL_BLOCK, RIL_WORD)
when you get a wrong Coordinate you can predict a new  coordinate by using the backforward of  ResultIterator coordinate  >Char value = こ left= 15 top = 14 right = 51 bottom = 51 conf = 99
Char value = ん left= 64 top = 9 right = 112 bottom = 54 conf = 99
Char value = ば left= 122 top = 5 right = 171 bottom = 54 conf = 99
Char value = ん left= 176 top = 9 right = 224 bottom = 54 conf = 99
Char value = は left= 234 top = 9 right = 281 bottom = 54 conf = 99
Char value = こ left= 295 top = 14 right = 331 bottom = 51 conf = 99
Char value = ん left= 344 top = 9 right = 392 bottom = 54 conf = 99
Char value = ば left= 402 top = 5 right = 445 bottom = 54 conf = 99
Char value = ん left= 456 top = 9 right = 497 bottom = 54 conf = 99
Char value = は left= 514 top = 9 right = 561 bottom = 54 conf = 99
Char value = ご left= 15 top = 79 right = 58 bottom = 126 conf = 99
Char value = 飯 left= 62 top = 80 right = 113 bottom = 130 conf = 99
Char value = 大 left= 120 top = 80 right = 225 bottom = 130 conf = 99
Char value = 盛 left= 242 top = 83 right = 260 bottom = 130 conf = 99
Char value = り **left= 2328 top = 1616 right = 2328 bottom = 1616** conf = 99
Char value = 。 left= 289 top = 116 right = 305 bottom = 131 conf = 99

Strange. It looks like a bug. Thank sir We are still able to reproduce it in the **Arabic** language in **LSTM mode**.
Most BBoxes are correct but there are some boxes that contain valid text and wrong coordinates (the region contained in the bbox is empty). I'm getting the same behavior for Thai language in LSTM - BoundingBox() often returns the whole image size.
The image size was 400, 266. Here is a small portion of some results [X1, Y1; X2, Y2].
(As a side note, I'm using RIL_WORD, but it seems to behave like RIL_SYMBOL, I'm not sure why).

'ร' - Confidence: 94.3645 [0, 0; 400, 266]
'ม' - Confidence: 95.7061 [19, 68; 33, 77]
'า' - Confidence: 96.9703 [0, 0; 400, 266]
'ส' - Confidence: 96.976 [35, 67; 50, 77] @amitdo  sir  could you show me where to get more info about how tesseract analyze input image to get the Coordinate of words/character and then recognize them through LSTM or old method and last combine the ocr result word with the coordinate ? @wanghaisheng

See here:
https://github.com/tesseract-ocr/tesseract/blob/master/lstm/recodebeam.cpp
Search for 'box', 'xcoords', 'blob'  ### Environment

* **Tesseract Version**: tesseract alpha - 4.0.0 
* **Platform**: Linux Ubuntu 16.04 LTS

Tesseract lstmtraining is used to train Korean language. The following error has occurred.
```
lstmtraining \ 
--model_config  $HOME/work/kor/tuned/kortuned \ 
--continue_from  $HOME/work/kor/tuned/kor.lstm \ 
--train_listfile  $HOME/work/kor/config/kor.training_files.txt \ 
--target_error_rate 0.01 \ 
--max_iterations 1200
```
It seems that a compression error occurs in the following complex characters.

![training error](https://user-images.githubusercontent.com/29770235/27676336-780ff9f0-5ce8-11e7-9609-bedd9ed2d860.png)


How do I resolve this issue?

Do I need to register for Korean unicharset?


  Tesseract (master branch, tested several versions on Windows/Ubuntu) using LSTM only inserts sometimes letters where they should not be. We have observed this happening randomly (but reproducible) also with eng, ces, nor (others not tested), also with different DPI.

Test case:
![to recognise 1498480501215-2111908889](https://user-images.githubusercontent.com/332350/27642820-3afe616c-5c63-11e7-8f37-91c91df7e6d2.png)
```
./tesseract ./to.recognise.1498480501215-2111908889.png stdout --oem 1 -l ces --psm 13
```
Expected: Veitvetveien
Got: Veitvetvelien

Letter bboxes visualised below
<img width="762" alt="tesseract bug report" src="https://user-images.githubusercontent.com/332350/27643336-1c6a95ee-5c64-11e7-8839-73a6a2d4d00e.png">
 Using:
- latin.traineddata

From the tesseract code, it seems that there is no handling of the situation when LSTM produces different results for one letter in time e.g., there is a line with the letter S
```
...
128 null_char score=-11.4265, c=-0.0850153, perm=0, hash=fa6bdef8 prev:null_char score=-11.3415, c=-0.0935133, perm=0, hash=fa6bdef8
129 null_char score=-11.5115, c=-0.0850045, perm=0, hash=fa6bdef8 prev:null_char score=-11.4265, c=-0.0850153, perm=0, hash=fa6bdef8
130 null_char score=-11.5966, c=-0.0850804, perm=0, hash=fa6bdef8 prev:null_char score=-11.5115, c=-0.0850045, perm=0, hash=fa6bdef8
131 null_char score=-11.6853, c=-0.088736, perm=0, hash=fa6bdef8 prev:null_char score=-11.5966, c=-0.0850804, perm=0, hash=fa6bdef8
132 label=3, uid=5=S [53 ]A score=-12.0022, c=-0.316888, Start End perm=8, hash=6b41093b prev:null_char score=-11.6853, c=-0.088736, perm=0, hash=fa6bdef8
133 label=3, uid=5=S [53 ]A score=-13.1056, c=-1.10339, perm=8, hash=6b41093b prev:label=3, uid=5=S [53 ]A score=-12.0022, c=-0.316888, Start End perm=8, hash=6b41093b
134 label=64, uid=66=$ [24 ] score=-13.2539, c=-0.14831, End perm=8, hash=86b8e412 prev:label=3, uid=5=S [53 ]A score=-13.1056, c=-1.10339, perm=8, hash=6b41093b
135 label=64, uid=66=$ [24 ] score=-13.8318, c=-0.577888, perm=8, hash=86b8e412 prev:label=64, uid=66=$ [24 ] score=-13.2539, c=-0.14831, End perm=8, hash=86b8e412
136 null_char score=-13.9704, c=-0.138632, perm=0, hash=86b8e412 prev:label=64, uid=66=$ [24 ] score=-13.8318, c=-0.577888, perm=8, hash=86b8e412
137 null_char score=-14.0555, c=-0.0850982, perm=0, hash=86b8e412 prev:null_char score=-13.9704, c=-0.138632, perm=0, hash=86b8e412
138 null_char score=-14.1405, c=-0.0850008, perm=0, hash=86b8e412 prev:null_char score=-14.0555, c=-0.0850982, perm=0, hash=86b8e412
139 null_char score=-14.2255, c=-0.0850006, perm=0, hash=86b8e412 prev:null_char score=-14.1405, c=-0.0850008, perm=0, hash=86b8e412
140 null_char score=-14.3105, c=-0.085, perm=0, hash=86b8e412 prev:null_char score=-14.2255, c=-0.0850006, perm=0, hash=86b8e412
```
and
```
Best choice: accepted=0, adaptable=0, done=1 : Lang result : S$ : R=3.06256, C=-7.72375, F=1, Perm=8, xht=[0,3.40282e+38], ambig=0
pos     NORM    NORM
str     S       $
state:  1       1
C       -1.103  -0.578
```

@theraysmith 
What is the expected behaviour in this case - should multiple choices (clearly) in one character be handled?
Thank you.
  After upgrade to _Tesseract-4-Alpha_, I found this error making the OCR from my JAVA code:

`
ITesseract instance = new Tesseract(); 
instance.setDatapath("/usr/share/tessdata/"); 
instance.setLanguage("spa"); 
(...)
result = instance.doOCR(imageFile);
`

------------------------

### Environment

* **Tesseract Version**: tesseract 4.00.00alpha
* **Leptonica Version**: leptonica-1.74.4
* **Platform**: CentOS 6.7
* **Server**: Wildfly 10.1

### Current Behavior:

**Error: Illegal Parameter specification!**
"Fatal error encountered!" == NULL:Error:Assert failed:in file globaloc.cpp, line 75

 A fatal error has been detected by the Java Runtime Environment:

  SIGSEGV (0xb) at pc=0x00007ff1b3098549, pid=25091, tid=0x00007ff29d7d7700

 JRE version: OpenJDK Runtime Environment (8.0_121-b13) (build 1.8.0_121-b13)
 Java VM: OpenJDK 64-Bit Server VM (25.121-b13 mixed mode linux-amd64 compressed oops)
 Problematic frame:
 C  [libtesseract.so+0x26f549]  ERRCODE::error(char const*, TessErrorLogCode, char const*, ...) const+0x129

 Failed to write core dump. Core dumps have been disabled. To enable core dumping, try "ulimit -c unlimited" before starting Java again

 An error report file with more information is saved as:
 /opt/wildfly/wildfly-10.1.0.Final/hs_err_pid25091.log

 If you would like to submit a bug report, please visit:
   http://bugreport.java.com/bugreport/crash.jsp
 The crash happened outside the Java Virtual Machine in native code.
 See problematic frame for where to report the bug.

*** JBossAS process (25091) received ABRT signal ***

### Suggested Fix:   
Any idea?
 I'm using the lastest source yet. I have the same Error (*) in two different OS. 

(*) Error: Illegal Parameter specification!
"Fatal error encountered!" == NULL:Error:Assert failed:in file globaloc.cpp, line 75 @Shreeshrii I'm using g++ 7.1.1 in Arch and 4.8.2 in CentOS 6.7.
I launch tesseract from Java. No problems with 3.05 version but I get the error previously commented with 4Alpha version.

`tesseract 4.00.00alpha`
` leptonica-1.74.4`
`  libgif 5.1.4 : libjpeg 8d (libjpeg-turbo 1.5.1) : libpng 1.6.29 : libtiff 4.0.8 : zlib 1.2.11 : libwebp 0.6.0
` No problems detecting langs with _tesseract --list_langs_ (eng, spa and osd trainned files for LSTM based 4.00.00alpha version).

About command line recognition, I have done fine an example from testing folder properly. 

Perhaps, some Java code has changed from this 4Alpha version? The problem with _3.05.01_ version is that I get different resutls from both OS using same Leptonica and Tesseract ver. in a PDF recognition.

Example:

 _0000 0340 **º71º** ZL_ (in CentOS) and _0000 0340 **0710** ZL_ (in Arch).

For that reason I'd like to improve the 4Alpha but it's impossible for the error commented some lines back. If you have an issue with a wrapper to Tesseract's C/C++ API, please report the issue to the developers of that software. >I'm using g++ 7.1.1 in Arch and 4.8.2 in CentOS 6.7.

>0000 0340 º71º ZL (in CentOS) and 0000 0340 0710 ZL (in Arch).



Ray said, many years ago, that you can get different results with different compilers. >Perhaps, some Java code has changed from this 4Alpha version?

Yes.
https://github.com/nguyenq/tess4j/commits/master Updated to the lastest libs from **Tess4J-3.4.0-src** I get same error when launch the OCR from Java code. 

From 3.05.01 version, is there any solution to solve the fail recognizing "zeros" ( º instead of 0)? 3.4.0 does not include the 4.00 changes.
https://github.com/nguyenq/tess4j/commits/tess4j-3.4.0 >From 3.05.01 version, is there any solution to solve the fail recognizing "zeros" ( º instead of 0)?

You can try to compile with a newer version of gcc. I can't promise that this 'solution' will help you with this issue. Ok, that's the problem? Tess4J-3.4.0 (Java) is not supported by 4.00Alpha release? Then I will try compilling with a newer version of GCC. >Ok, that's the problem? Tess4J-3.4.0 (Java) is not supported by 4.00Alpha release?

I assume that's the source of the problem (It's Tess4J 3.4.0 that seems to not have support for Tesseract 4.00, not vice versa). To be sure, ask the developer.

https://sourceforge.net/p/tess4j/discussion/1202294/
https://github.com/nguyenq/tess4j/issues tess4j's master branch is for Tesseract 4.0alpha and includes the latest Tesseract 4.0alpha Windows binary. All of its unit tests passed on Windows 10. We have not tested on Linux OS yet.

Since you link against Leptonica 1.74.4, make sure you use lept4j-1.6.0. Hi .. it seems you just have to add environment variable LC_NUMERIC="C" ... and it works. :) I dug into Tesseract's code and found that the string "Illegal Parameter specification" only exists in one place, namely in the file classify/clusttool.cpp. After some debugging I realised that the function ReadParamDesc() calls sscanf() at line 82 (for git commit hash 2b854e3749d62012787dd4160fc30e86603cc540), which is locale dependent. It fails since the numeric input (two floating point values) are written with dots (example: 1.23), but using a different locale other than en_US for LC_NUMERIC may cause sscanf() to expect other characters, like commas (1,23).

With other words, the error is in tesseract, assuming a locale. It should rather be set explicitly. The workaround is to set LC_NUMERIC=en_US.UTF-8. https://github.com/tesseract-ocr/tesseract/wiki/FAQ#error-illegal-min-or-max-specification
https://web.archive.org/web/20150510151209/http://code.google.com/p/tesseract-ocr/issues/detail?id=228
https://web.archive.org/web/20150509203443/http://code.google.com/p/tesseract-ocr/issues/detail?id=250

https://msdn.microsoft.com/en-us/library/wyzd2bce.aspx

https://en.cppreference.com/w/cpp/locale/setlocale

https://stackoverflow.com/questions/13919817/sscanf-and-locales-how-does-one-really-parse-things-like-3-14   Hello All,

I want to train tesseract as , But I got this error, Any help

------------------------

=== Starting training for language 'ara'
[2017. 06. 27. (화) 12:56:32 KST] /usr/local/bin/text2image --fonts_dir=/usr/share/fonts/ --font=Arial --outputbase=/tmp/font_tmp.F0ewTOCx0k/sample_text.txt --text=/tmp/font_tmp.F0ewTOCx0k/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.F0ewTOCx0k
Could not find font named Arial.
Pango suggested font FreeMono.
Please correct --font arg.

=== Phase I: Generating training images ===
Rendering using Arial
[2017. 06. 27. (화) 12:56:34 KST] /usr/local/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.F0ewTOCx0k --fonts_dir=/usr/share/fonts/ --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.9c8iwNnHC8/ara/ara.Arial.exp0 --font=Arial --text=../langdata/ara/ara.training_text
Could not find font named Arial.
Pango suggested font FreeMono.
Please correct --font arg.
ERROR: /tmp/tmp.9c8iwNnHC8/ara/ara.Arial.exp0.box does not exist or is not readable
ERROR: /tmp/tmp.9c8iwNnHC8/ara/ara.Arial.exp0.box does not exist or is not readable

  In 3.0,I get a list of choices,but in 4.0 just one,is it a bug?  ### Environment

Tesseract Version: <4.0>

Platform: <Ubuntu 14.04>

### Current Behavior:
I am wondering how the time steps(or to say the lstm cell numbers) for the LSTM unit is determined during the training process? If the width of the input image is various, though the summaring LSTM unit is used to collapse the Y-dimension into one,  but the width of the data can still be different values. 
So each iteration ,the LSTM is unrolled for img-width times? Or is there any scaling operation on the input image or any other func I am missing?

 @Shreeshrii As I understand, the summarizing lstm unit is to reduce the height of the input image, so that each time-step of the output sequence becomes a 64-d vector, with the image width (after conv and max-pool) as the length of the seqence. So in the training step, it's not possible to use batch since the width of the images in each batch can be different？  I think padding is added to each text line image to make each image the same width.
   I don't think this is related to Tesseract. The same sequence works for me on Debian Jessie and Stretch. Maybe a damaged local Leptonica build or installation? So 3.05 tries linking without the Leptonica library. That cannot work of course.

You used `LIBLEPT_HEADERSDIR`. I did not find it in the code, so I think that is without any effect. The other options for `configure`, namely `--with-extra-includes` and `--with-extra-libraries` should not be needed. Setting `PKG_CONFIG_PATH` should be sufficient if you have installed code in `/usr/local`. I try to avoid such extra settings because they are confusing: which installation of Leptonica is used? Therefore I usually install in `/usr` (see my packages at https://digi.bib.uni-mannheim.de/tesseract/leptonica/). I don't know what the breakage is.  In this thread I see the failure to load liblept in 3.05, which might have followed from the failure to find lept_free() for some reason.

@shreeshrii  you say it works for the master branch; for what version does it fail, and what is the failure? @Shreeshrii , please try these four commands:

    pkg-config --cflags lept
    pkg-config --libs lept
    PKG_CONFIG_PATH=/usr/local/lib/pkgconfig pkg-config --cflags lept
    PKG_CONFIG_PATH=/usr/local/lib/pkgconfig pkg-config --libs lept

Here is my output (only two commands, as I have no installation in `/usr/local`):

    $ pkg-config --cflags lept
    -I/usr/include/leptonica
    $ pkg-config --libs lept
    -llept

Your build output neither shows something like `-I/usr/local/include/leptonica` (for the C++ compiler) nor `-L/usr/local/lib -llept`, so I expect that you have a broken file `lept.pc` somewhere on your computer. The above test will check that. lept.pc.in  is from Jan 2016, and lept.pc.cmake is from Apr 22, 2017.

Neither have changed since 1.74.2, which was May 19, 2017.



On Tue, Jun 20, 2017 at 11:30 AM, Shreeshrii <notifications@github.com>
wrote:

> $ pkg-config --cflags lept
> -I/usr/local/include/leptonica
> $ pkg-config --libs lept
> -L/usr/local/lib -llept
> $ PKG_CONFIG_PATH=/usr/local/lib/pkgconfig pkg-config --cflags lept
> -I/usr/local/include/leptonica
> $ PKG_CONFIG_PATH=/usr/local/lib/pkgconfig pkg-config --libs lept
> -L/usr/local/lib -llept
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1000#issuecomment-309847263>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLPzjSF1578BlEDpRoP7yt0Bms9Ieks5sGA-vgaJpZM4N_xcO>
> .
>
 My 1.74.4 builds fine with autotools on linux.

I don't have a conftest.cpp file, and configure doesn't look for it.
Attaching my lept.pc (generated from lept.pc.in).
[lept.pc.txt](https://github.com/tesseract-ocr/tesseract/files/1089399/lept.pc.txt)

 @Shreeshrii, your `pkg-config` output looks good. I was surprised that `PKG_CONFIG_PATH` did not change the result. Have you set that as an environment variable, too?

Does the build work with my [3.05](https://github.com/stweil/tesseract/tree/3.05) (I just added a [backported commit](https://github.com/stweil/tesseract/commit/e7610d86c97de4c29777892465fc4c3bc77e8da8))? Sorry, the fix for `training/Makefile.am` was missing. Updated now. Try this:
`find /usr -name *lept*`
 You need to recompile Tesseract after you re-installed Leptonica ... or use `ldd /usr/local/bin/tesseract` to see which libraries are used by default. Maybe `LD_LIBRARY_PATH=/usr/local/lib /usr/local/bin/tesseract -v` gets the expected Leptonica version. > You need to recompile Tesseract after you re-installed Leptonica

In most cases this is not necessary, because typically Leptonica is not linked statically. That means Tesseract uses a shared library for Leptonica, and that library can be replaced by a newer one without harm (as long as there are no incompatible changes). >... (as long as there are no incompatible changes).

https://github.com/DanBloomberg/leptonica/issues/240 So it's using the Leptonica from `/usr/local` which claims to be leptonica-1.74.2. @shreeshrii  Is it worth doing a mini-postmortem on this?  Just a couple of paragraphs on what went wrong and what we might do to prevent this from happening again. @shreeshrii

Thanks!  Very nice summary.

We have several ways to build tesseract and the associated libraries.
An embarrassment of riches, as the French would say (except
in their own way).

It seems to me that the current suggestions in the leptonica
README.html for building with autotools are still valid.
It also references the documentation in
     https://github.com/tesseract-ocr/tesseract/wiki/Compiling
and I see that you updated that page 2 weeks ago.  Would
you make any further changes there?


On Wed, Jun 21, 2017 at 12:08 PM, Shreeshrii <notifications@github.com>
wrote:

> @DanBloomberg <https://github.com/danbloomberg>
>
> I usually update leptonica by using the following script in the leptonica
> directory.
>
> #!/bin/bash
> git pull origin
> ./autobuild
> ./configure --disable-dependency-tracking
> #./configure
> make
> sudo make install
> sudo ldconfig
>
> I follow a similar build script for tesseract master branch for building
> 4.0.
>
> Based on an error report in the forum, I tried building 3.05.01 and
> received the error related to lept_free (reported above).
>
> As part of the experimentation, I did a hard reset in leptonica directory
> at one time to get to the commit for 1.74.2 and built leptonica and
> tesseract 3.05.01 after that without any problem.
>
> @stweil <https://github.com/stweil> then backported a couple of commits
> to tesseract 3.05.01 branch to fix the problem regarding lept_free() and I
> rebuilt leptonica with the latest source and then built tesseract 3.05.01.
> It built without the lept_free error.
>
> It is possible that I did not build leptonica using the script which does
> autobuild and configure, but rather just did
>
> git pull origin
> make
> sudo make install
>
> I also built tesseract 4.0 from master branch after that. I noticed in
> both of these, that leptonica version was reported as 1.74.2.
>
> After following Amit and Stefan's suggestions to see whether I had
> multiple versions of files causing the older version to display, I decided
> to rebuild leptonica again. This time I did make distclean in leptonica
> directory before running the build script.
>
> Then without needing to rebuild tesseract, tesseract -v showed that it
> was using leptonica 1.74.4.
>
> @amitdo <https://github.com/amitdo> So, as mentioned by Stefan, it is not
> necessary to rebuild tesseract to use the newer leptonica library.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1000#issuecomment-310176024>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLD_tbdPGJyKbdREo7_bUNgEsi53Sks5sGWozgaJpZM4N_xcO>
> .
>
 Actually, the page I referred to looked pretty good, and I was just
referring to the small section on constraints for compiling leptonica.

On Fri, Jun 23, 2017 at 3:39 AM, Shreeshrii <notifications@github.com>
wrote:

> he wiki pages are public and have been updated by different people at
> different times. I did update the Compiling wiki page with the needed
> leptonica version recently.
>
> There are multiple Install/Compiling instructions.
> I think that https://github.com/tesseract-ocr/tesseract/blob/master/
> INSTALL.GIT.md is better.
>
> I will try to streamline the compiling page - maybe delete duplicated info
> and refer to the installation page instead. However, it will require review
> by @stweil <https://github.com/stweil> @egorpugin
> <https://github.com/egorpugin> and @zdenop <https://github.com/zdenop> .
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/1000#issuecomment-310633374>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLIm9-ICPyTO9xz1Q9Iywm5uT3W06ks5sG5XfgaJpZM4N_xcO>
> .
>
 I seem to be hitting the problem too - trying to add in a cross compile for powerpc into our travis build setup, building leptonica first and then tesseract and I seem to be hitting this same issue no matter what I try, if I use 3.0.5.01 download. If I pull latest straight from git, it compiles fine. Also builds fine for android, mac, windows, probably even native ppc. 

@Shreeshrii you mention some backports to 3.0.5.1, could you help with any details on those? I looked through the commit log but from a quick look from around Jun I didn't spot anything immediately obvious. I'm wondering if its something I can apply as a patch, just that pulling a non-release version usually ends up with headaches down the road >git clone -q --branch=3.05 https://github.com/tesseract-ocr/tesseract.git tesseract-3.05

This will fetch https://github.com/tesseract-ocr/tesseract/tree/3.05, but the latest 3.05.x is 3.05.1: https://github.com/tesseract-ocr/tesseract/tree/3.05.01

Currently, version 4.0 still has the legacy engine from 3.0x (plus the new LSTM engine).
It can be used with the 3.05/3.04 traineddata files (--oem 0 or --oem 3).  ### Environment

* **Tesseract Version**: 4.00.00alpha
* **Platform**: Ubuntu Docker image

### Current Behavior:
When I give it the following image, the text detection is really bad.
![frame_24721](https://user-images.githubusercontent.com/3123549/27284702-2f5ab268-54fa-11e7-912c-02f3cd629704.png)

It outputs the following:

```
Warning. Invalid resolution 0 dpi. Using 70 instead.
## Parancters
= buser® = A User struct.

## Examples



user = MUser{nanes "Alice Winston}
User. first. nane(user)

"Mice"



def first_name(user) do
user

17 Bout
1° first
end

adec !
Get the last name of a user.





## Parancters

'user® - A User struct.

enero oE \ s |

```

### Expected Behavior:

It outputs the correct text.

### Suggested Fix:

I don't know how Tesseract works in its core but the image contains clear and readable characters, even in English. Yeah, that's a lot better. Thank you! @Shreeshrii What have you used to preprocess the image? I tried it with imagemagick but the result isn't quite good and therefore the OCR result too. @Shreeshrii The best I can get is this:

![frame_24721-2](https://user-images.githubusercontent.com/3123549/27321677-64de42d2-559b-11e7-8d3a-f405b18d5fbf.png)

Using this command:
```
convert -units PixelsPerInch input.png -resize 1200 -density 300 -colorspace gray -depth 1 -negate output.png
```

Not sure if imagemagick can do better.  It would be good to decide about using semantic versioning soon. Maybe it can be used for the next tag. We could tag the current release as a pre-release or as a release candidate. According to [semver.org](http://semver.org/#spec-item-9), it could be called something like `4.0.0-rc.1` (that's how semver.org named its own releases), `4.0.0-beta.1` or `4.0.0-beta.20170619`. @theraysmith, can you give us an update on your work? When are we going to see it? Hi, same: can you give us an update on your work? When are we going to see 4.0 released? +1 for a new tag.

Since Ray does not reply, I suggest to still use 'alpha'.

`4.0.0-alpha.YYYYMMDD` @zdenop, can you do it, or at least add your comment here? Superb. Anything we could do to help you ? Cheers. > I'm about ready to update the traineddatas.

That's good news.

> The above change makes open source training impossible.

If I got that right, it would be horrible. Being able to create new traineddata is essential for me. >The new traineddatas will mostly be smaller than the older ones, as they
won't contain the legacy components, and no bigram dawgs are needed.

Will you remove the **code** of the legacy engine in this round? > 2 parallel sets of tessdata. "best" and "fast". "Fast" will exceed the speed of legacy Tesseract in real time, provided you have the required parallelism components, and in total CPU only slightly slower for English. Way faster for most non-latin languages, while being <5% worse than "best" Only "best" will be retrainable, as "fast" will be integer.

@theraysmith, thanks for providing "fast" now. Are you planning to release free documentation / tools for everybody to produce "fast" data? I noticed that apart from the LSTM model the rest of the traineddata files for "best" and "fast" are identical. Wouldn't it save space and make the handling easier if both variants were in the same traineddata container (this requires an option to select the desired one, of course) instead of having two parallel sets? Jeff, see this comment:
https://github.com/tesseract-ocr/tesseract/issues/1131#issuecomment-329764356 >1.7G	best
657M 	fast

Jeff, playing with the numbers?
:-)
[He changed the numbers in his comment] ​but its size is very different and dont follow an unique pattern..


tessdata_fast/eng.traineddata  3.9mb
tessdata_best/eng.traineddata 14.7


tessdata_fast/ara.traineddata  1.4mb
tessdata_best/ara.traineddata  12mb
  ​

​what can effect the fast traindata size ?1​
 @roozgar, it is possible to extract the parts of a traineddata file using `combine_tessdata -u traineddata_file output_path_prefix`. Usually the largest parts are the LSTM model and the word list, but not all languages have a huge word list like `eng.traineddata` or `Latin.traineddata`.
 >​ @amitdo I can't seem to write a single comment without editing it three times to fix mistakes.

LOL. It happens to me too. I keep discovering mistakes **after** I post a comment. Thank you! Hi everybody, so what are now the remaining tasks in order to release Tesseract 4.0.0 ?  USE_OPENCL should be turned off in CMAKE if OpenCL is not found. Also, potentially should be enabled by default if it is found unless there are reasons otherwise. CC: @egorpugin Adding USE_OPENCL by default would be a bad idea. The OpenCL code is still buggy and does not improve the performance very much (or even not at all). Only developers who know what they are doing should use it. Should this issue be closed then? IMO, there's no point to keep it open if nobody going to do something about it. I see no need to keep it open.  Hi,

while i was training the LSTM through this command
`lstmtraining -U ~/tesstutorial/jpntrain/jpn.unicharset \
  --script_dir /home/ibr/langdata --debug_interval 0 \
  --continue_from   tesstutorial/jpn.lstm \
  --append_index 5 --net_spec '[Lfx256 O1c105]' \
  --model_output /home/ibr/tesstutorial/new_jpn_lstm \
  --train_listfile ~/tesstutorial/jpneval/jpn.training_files.txt \
  --eval_listfile ~/tesstutorial/jpntrain/jpn.training_files.txt \
  --max_iterations 5000 &>~/tesstutorial/basetrain.log`

it went fine and started the iterations until the iteration 900 it gave the error:

![lstm dumping](https://user-images.githubusercontent.com/26926171/27182531-27761344-51e4-11e7-889e-ae91bad36f3a.png)

although the error came, it created checkpoint file, I'm using Tesseract 4.00alpha, leptonica 1.74.1 and OS is Ubuntu 14.04

i got the command from this [website](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Replace-Top-Layer)

any ideas?


 i installed and compiled both leptonica 1.74.2 and latest tesseract and ran the command but i got the following error:
![lstm2](https://user-images.githubusercontent.com/26926171/27259772-53c203ea-5423-11e7-85d1-359dab2c2fbe.png)

as you can see, this deserialization error is different from the one that i got  #992

 its not saying that the header deserialization failed, so what does that mean? and the path is correct thanks for the response, i modified the path yet i deserialization fails, but as you can see that error has gone
`ibr@ubuntu:~/leptonica-1.74.2/tesseract$ training/lstmtraining -U ~/tesstutorial/jpntrain/jpn.unicharset \
>   --script_dir /home/ibr/leptonica-1.74.2/langdata --debug_interval 0 \
>   --continue_from   /home/ibr/tesstutorial/jpn.lstm \
>   --append_index 5 --net_spec '[Lfx256 O1c105]' \
>   --model_output /home/ibr/tesstutorial/engtrain2 \
>   --train_listfile ~/tesstutorial/jpneval/jpn.training_files.txt \
>   --eval_listfile ~/tesstutorial/jpntrain/jpn.training_files.txt \
>   --max_iterations 5000
Loaded file /home/ibr/tesstutorial/jpn.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from /home/ibr/tesstutorial/jpn.lstm
Appending a new network to an old one!!Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Setting properties for script Katakana
Setting properties for script Hiragana
Setting properties for script Han
Warning: given outputs 105 not equal to unicharset of 546.
Num outputs,weights in serial:
  Lfx256:256, 394240
  Fc546:546, 140322
Total weights = 534562
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc546] from request [Lfx256 O1c105]
Training parameters:
  Debug interval = 0, weights = 0.1, learning rate = 0.0001, momentum=0.9
Deserialize failed: /home/ibr/tesstutorial/jpneval/jpn.HGGothicE.exp0.lstmf read 0/1670 pages`

NOTE: the terminal freezes after running this command, until i stop the command by "Ctrl C" @Shreeshrii  actually I switched back to liptonica 1.74.1 and started fine tuning since I decided I need the old unicharset and I just want to add layers to existing lstm file, so I needed to finish this task ASAP and as you know fine tuning takes many days, so I didn't have the chance to try your solution which is creating lstmf by the latest tesseract as it requires installation and compiling and the machine is already occupied by the tuning.
BUT since I don't need to create from scratch anymore I can close this issue, so if its fine by you I will close it, reply back to me for the next action.
Thanks  Hi,

while following the steps in this [website](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Replace-Top-Layer) i got an error at the second step which was as the following:-

![lstm](https://user-images.githubusercontent.com/26926171/27178963-2b27410c-51d5-11e7-861a-1ccc7b075405.png)

what does that mean? also how to solve this problem?, so i can continue with the training

NOTE: im using tesseract 4.00.00alpha with leptonica 1.74.1, also all LSTMFs and the used files were created on Ubuntu 14.04 correct, the path at the training_files.txt was wrong, thanks  win8.1 64bit tesseract 4.0.0alpha  leptonica-1.74.2 (Jun  6 2017, 21:45:59) [MSC v.1910 LIB Release x64]

the reslut always contains extra spaces between character when using oem LstmOnly or TesseractAndLstm, oem TesseractOnly works normally but the result is bad. 


![image](https://user-images.githubusercontent.com/10088733/27135386-f6cd87b6-514a-11e7-85ce-4d825f14f471.png)

oem:  Default  psm: SingleLine  time: 114 ms.  result: 伦 敦 楼 房 发 生 火 灾 中 使 馆 关 注 : 暂 无 中 国 公 民 受 伤

oem:  TesseractOnly  psm: AutoOsd  time: 518 ms.  result:  伦敦夺委房发生火火中使馆大汪 二 暂无中 ` 又伤



 


[result_lines_chi.txt](https://github.com/tesseract-ocr/tesseract/files/1074793/result_lines_chi.txt)



 @zdenop  @Shreeshrii @stweil 
can you guys give me some advice about  this ? thx. I've also tested jpn and kor images , the results have similar problem.
there might be something wrong related to LSTM engine or its parameter. sorry for my bad english
in my case Japanese  and OCR mode set to LTSM may by related .
i'm try to get single char only by using ResultIterator but sometimes final char in word doesn't have right coordinate. if change OCR mode to Tesseract Only it's okay.
Example :
大阪株式会社 
[debug] -Char value = 大 left= 16 top = 243 right = 68 bottom = 295 conf = 99
[debug] -Char value = 阪 left= 75 top = 244 right = 128 bottom = 295 conf = 99
[debug] -Char value = 株 left= 130 top = 244 right = 185 bottom = 296 conf = 99
[debug] -Char value = 式 left= 190 top = 243 right = 281 bottom = 296 conf = 99
[debug] -Char value = 会 left= 306 top = 243 right = 362 bottom = 296 conf = 99
[debug] -Char value = 社 left= 2214 top = 2991 right = 2214 bottom = 2991 conf = 99
 great, it works. Actually I noticed this variable, but I misunderstood and set it to false, definitely it doesn't work as expected. ~_~
> SetVariable("preserve_interword_spaces", false); @Shreeshrii  can you  help me ? i'm get wrong coordinate for last char in word. Thanks!  Hi,

while i made some Images Recognition for the Japanese language i found that the resulted Japanese text has different spacing between its characters, i have no background in Japanese but in the original documents or images the spacing is different meaning some times its more like spaces between English letters and other times the space similar to the space between English words, while in the resulted text all spaces are similar between all characters.

Thanks @Shreeshrii  Thanks Hi,

just adding information, this `-c preserve_interword_spaces=1` argument works good with Japanese (i didn't try it with English) but for Arabic its better not to use it, since the Arabic language has Cursive  writing system, so i detected a text with both cases, with the argument and without it, when i used the argument for Arabic some of the words were detected correctly but are joined to the next word which is incorrect, but without that argument the same words didn't  join to the next word which is correct   What's the point of this option?


Libtool Convenience Libraries
https://www.gnu.org/software/automake/manual/automake.html#Libtool-Convenience-Libraries

https://github.com/tesseract-ocr/tesseract/commit/bf4a09d72a
https://github.com/tesseract-ocr/tesseract/commit/67f47008c

 CC: @jimregan >IMO it does not make sense

That's exactly what I thought. and thus opened this issue.

 >I think it should go away

:+1: 
  ### Environment
Version: 4.00.00alpha, from [here](https://github.com/tesseract-ocr/tesseract/releases/tag/4.00.00alpha)
`uname -a` output: Linux T1 4.4.0-21-generic #37-Ubuntu SMP Mon Apr 18 18:33:37 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

### Current Behavior:
Running two or more programs which all attempt to process images with Tesseract seems to lock up all programs indefinitely.

### Expected Behavior:
Running two or more programs involving Tesseract would not block all programs from executing.

### Suggested Fix:
I don't actually know enough about the codebase itself to to suggest a fix, but would be interested in more information or a workaround. This actually has nothing to do with training though, just evaluation with the LSTM. I'm running on an Ubuntu 16 VM which has 16GB RAM from the host and 4 cores, so I doubt it has anything to do with the hardware. I'll try the latest code and see what happens The problems which we observed with training also exist for the tesseract ocr process. It uses multithreading causing a significant overhead for thread synchronisation. Your 4 cores will be sufficient for a single tesseract process, but if you run more than one, the effects which you have seen are not surprising.

Disabling OpenMP and the related multithreading would help for your case. Use `configure --disable-openmp`. Then I expect that you will be able to run up to four tesseract processes simultaneously. Thanks @stweil and @Shreeshrii. Will disabling OpenMP affect processing time in a negative way though? For example, if I'm only running one process using Tesseract, will it run more slowly with OpenMP disabled? It sounds like there must be some kind of tradeoff here Yes, for a single process disabling OpenMP will increase the run time – not by a factor 4, but maybe 2. You'll have to try it yourself.  Great, I'll give that a shot and see what happens. Thanks again for the support, closing now  Hi,

I wanted to install and compile leptonica and then tesseract on a server following this [website](https://medium.com/@lucas63/installing-tesseract-3-04-in-ubuntu-14-04-1dae8b748a32)
i installed and downloaded leptonica 1.74.1 and tesseract 4.00.00alpha on VM and VB before following the same steps exactly, yet today i found this error coming out on the terminal
![env_error](https://cloud.githubusercontent.com/assets/26926171/26831244/5b97d520-4ad4-11e7-9a87-bf86bc754e79.png)

i tried to comment the error section but that caused another problems, i even tried to get the leptonica.gz again and running the steps once more, yet the same problem.

keep in mind that the OS on the server is Ubuntu 14.04, which is the same OS that i used on VM and OS on VB and worked on both cases, is this issue cause by a dependency or what exactly?
Please any ideas? as i need to get the server up and running as soon as possible
Thanks thanks, but what is the command to get the newer version, its not:
wget http://www.leptonica.com/source/leptonica-1.74.2.tar.gz

and is it an alpha version too or a full release?
and would  the compilation for it be same as 1.74.1 ? According to the snapshot, your Leptonica build fails. Then that's unrelated to Tesseract, isn't it? @Shreeshrii same problem has occurred with Leptonica 1.74.2, it i feel its kind of a compiler issue, isn't it?
@stweil yes you are right, the compilation of the leptonica has failed, and i couldn't continue to install tesseract
@zdenop i really didn't know why you have closed this issue before i even got the chance to try what was suggested by shree??!! at least if something is wrong with the question, or its irrelevant to this group at least mention that in a comment then close it !!!!! :(



  The newer version contains fixes for the pixUnsharpMaskingGray*
functions which are relevant for Tesseract (used in ImageData::PreScale
which calls pixScale).

Signed-off-by: Stefan Weil <sw@weilnetz.de> See [Dan's comment](https://github.com/tesseract-ocr/tesseract/issues/644#issuecomment-306073620) for issue #644. Should we refuse builds with Leptonica < 1.74.2? Then additional changes for `CMakeLists.txt` and `configure.ac` would be needed. The newer version not only fixes problems with undefined memory for `lstmtraining`, but also for `tesseract --oem 1`:

With Leptonica 1.74.1:

    $ valgrind bin/ndebug/x86_64-linux-gnu/api/tesseract --oem 1 ~/Bilder/ocr/hello_world.png /tmp/hello
    ==21183== Memcheck, a memory error detector
    ==21183== Copyright (C) 2002-2015, and GNU GPL'd, by Julian Seward et al.
    ==21183== Using Valgrind-3.12.0.SVN and LibVEX; rerun with -h for copyright info
    ==21183== Command: bin/ndebug/x86_64-linux-gnu/api/tesseract --oem 1 /home/stweil/Bilder/ocr/hello_world.png /tmp/hello
    ==21183== 
    ==21183== Conditional jump or move depends on uninitialised value(s)
    ==21183==    at 0x4ECF07A: nextOnPixelInRasterLow (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4ECF29F: nextOnPixelInRaster (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4ED03A9: pixConnCompBB (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4E8B8DC: ??? (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4E8C021: ??? (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4E8CABA: bmfCreate (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x1710B8: DebugPixa (debugpixa.h:15)
    ==21183==    by 0x1710B8: tesseract::Tesseract::Tesseract() (tesseractclass.cpp:623)
    ==21183==    by 0x11F99B: tesseract::TessBaseAPI::Init(char const*, int, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, bool (*)(STRING const&, GenericVector<char>*)) (baseapi.cpp:320)
    ==21183==    by 0x11FE25: tesseract::TessBaseAPI::Init(char const*, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool) (baseapi.cpp:284)
    ==21183==    by 0x116273: main (tesseractmain.cpp:440)
    ==21183== 
    ==21183== Conditional jump or move depends on uninitialised value(s)
    ==21183==    at 0x4ECF12E: nextOnPixelInRasterLow (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4ECF29F: nextOnPixelInRaster (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4ED03A9: pixConnCompBB (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4E8B8DC: ??? (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4E8C021: ??? (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x4E8CABA: bmfCreate (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==21183==    by 0x1710B8: DebugPixa (debugpixa.h:15)
    ==21183==    by 0x1710B8: tesseract::Tesseract::Tesseract() (tesseractclass.cpp:623)
    ==21183==    by 0x11F99B: tesseract::TessBaseAPI::Init(char const*, int, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, bool (*)(STRING const&, GenericVector<char>*)) (baseapi.cpp:320)
    ==21183==    by 0x11FE25: tesseract::TessBaseAPI::Init(char const*, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool) (baseapi.cpp:284)
    ==21183==    by 0x116273: main (tesseractmain.cpp:440)
    ==21183== 
    Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
    ==21183== 
    ==21183== HEAP SUMMARY:
    ==21183==     in use at exit: 3,360 bytes in 7 blocks
    ==21183==   total heap usage: 653,804 allocs, 653,797 frees, 143,432,299 bytes allocated
    ==21183== 
    ==21183== LEAK SUMMARY:
    ==21183==    definitely lost: 0 bytes in 0 blocks
    ==21183==    indirectly lost: 0 bytes in 0 blocks
    ==21183==      possibly lost: 912 bytes in 3 blocks
    ==21183==    still reachable: 2,448 bytes in 4 blocks
    ==21183==         suppressed: 0 bytes in 0 blocks
    ==21183== Rerun with --leak-check=full to see details of leaked memory
    ==21183== 
    ==21183== For counts of detected and suppressed errors, rerun with: -v
    ==21183== Use --track-origins=yes to see where uninitialised values come from
    ==21183== ERROR SUMMARY: 169 errors from 2 contexts (suppressed: 0 from 0)

With Leptonica 1.74.2:

    $ valgrind bin/ndebug/x86_64-linux-gnu/api/tesseract --oem 1 ~/Bilder/ocr/hello_world.png /tmp/hello2
    ==22040== Memcheck, a memory error detector
    ==22040== Copyright (C) 2002-2015, and GNU GPL'd, by Julian Seward et al.
    ==22040== Using Valgrind-3.12.0.SVN and LibVEX; rerun with -h for copyright info
    ==22040== Command: bin/ndebug/x86_64-linux-gnu/api/tesseract --oem 1 /home/stweil/Bilder/ocr/hello_world.png /tmp/hello2
    ==22040== 
    Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
    ==22040== 
    ==22040== HEAP SUMMARY:
    ==22040==     in use at exit: 3,360 bytes in 7 blocks
    ==22040==   total heap usage: 653,807 allocs, 653,800 frees, 143,423,100 bytes allocated
    ==22040== 
    ==22040== LEAK SUMMARY:
    ==22040==    definitely lost: 0 bytes in 0 blocks
    ==22040==    indirectly lost: 0 bytes in 0 blocks
    ==22040==      possibly lost: 912 bytes in 3 blocks
    ==22040==    still reachable: 2,448 bytes in 4 blocks
    ==22040==         suppressed: 0 bytes in 0 blocks
    ==22040== Rerun with --leak-check=full to see details of leaked memory
    ==22040== 
    ==22040== For counts of detected and suppressed errors, rerun with: -v
    ==22040== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
 Tesseract cmake builds are broken with Leptonica 1.74.2 because Leptonica now requires an installation: the `Leptonica_INCLUDE_DIRS` refer to /usr/local/include. Therefore Travis CI fails. @egorpugin, how should we fix that?  The new test in LSTMTrainer::UpdateErrorGraph fixes an assertion
(see issues #644, #792).

The new test in LSTMTrainer::ReadTrainingDump was added to improve
the robustness of the code.

Signed-off-by: Stefan Weil <sw@weilnetz.de> @zdenop, please merge before more people get this assertion.  Hello,
I was trying to get the text of the image i am providing bellow (i am using extract_text before the apply of tesseract) and i wanted to get the result of fitting room above which is very clear and in white background with black letters. I didnt get that result on the output file so i tried to cut only that part of the image and use the tesseract and i got the result i was looking for. Probably there is a bug how tesseract is detecting the edges, any helpful information about this?
![18870210_10155396251410842_855716923_o](https://cloud.githubusercontent.com/assets/28709382/26761770/3dbb29a2-4936-11e7-992d-9f27c2255770.jpg)
  Currently, when someone opens a new issue he see this above the title text input field:

Before you submit an issue, please review the [guidelines](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md) for this repository.

The problem is that many people are either not noticing or ignoring this 'banner'.

Any reason to not have a link to this page instead of the other links?  The new README.md can be seen [here](https://github.com/Shreeshrii/tesseract).  Attached are two images, one with the word Keyword, and the other with a random string. The file with the word Keyword outputs an accurate result (Keyword). The second file though outputs something very odd: `"'Eﬂ'fé'i'ibiboss`

Any idea why? The second picture is the result of someone taking a photo of a serial number, which is what i am trying to achieve in my app. The Keyword image is a screenshot from the web, so it is perfectly skewed with a white background. Was I wrong in assuming that ocr could accurately determine the text in the second photo?

<img width="100" alt="ocrtest" src="https://cloud.githubusercontent.com/assets/1245462/26419801/dd4dfa72-408e-11e7-8115-e29b35beb05a.png">

<img width="100" alt="ocrtest" src="https://cloud.githubusercontent.com/assets/1245462/26419800/dd4dad74-408e-11e7-97a2-e9892bd73fcb.png">

 Thanks @Shreeshrii, I will move to the forum, my apologies I am new to this technology!   Hi,
I am using 3.04.00 version of tesseract and try to execute the command TesseractConsole.exe .\test_Thai.tif "<PATH>\html" "-l tha"+"<PATH>\html.txt".
It takes too long to generate the html.txt file with the data.
Note: I have picked up the trained data from : https://github.com/tesseractocr/tessdata/blob/master/tha.traineddata

Thanks,  According to your report the problem started with commit 6dd871bfb6c3

The commits after that commit are just documentation fixes.


 Shree, did you run those tests with WSL? Same test on Linux with git master, debug build:

    2 Percent improvement time=0, best error was 100 @ 0
    At iteration 0/500/500, Mean rms=0.162%, delta=0%, char train=0.009%, word train=0.033%, skip ratio=0%,  New best char error = 0.009Deserialize failed wrote best model:/home/stweil/tesstutorial/engtuned_from_engtest/engtuned0.009_0.lstm wrote checkpoint.

    Finished! Error rate = 0.009

    real	2m7,797s
    user	7m10,384s
    sys	0m2,156s

Test machine: Intel(R) Xeon(R) CPU E3-1240 v5 @ 3.50GHz.
I had to fix the assertion issue first. I currently think that the timing regression is related to bug #644. @Shreeshrii, could you please try git master with the patch shown there? https://stackoverflow.com/questions/556405/what-do-real-user-and-sys-mean-in-the-output-of-time1 The fact that the 'user' time is a few times longer than the 'real' time is expected with multi core CPU and OpenMP enabled.

However, the fact that the real time with or without OpenMP is roughly the same is not expected. See also [my comment](https://github.com/tesseract-ocr/tesseract/issues/943#issuecomment-304132980) in the RFC on performance. Even on Linux, OpenMP requires a large percentage of additional CPU time. That's why Tesseract with OpenMP is not much faster in the "real" time, but uses much more "user" and "sys" time. On Windows the situation gets worse because thread switching for OpenMP seems to be slower than on Linux. A dual core CPU will produce a very high overhead when OpenMP with four or more threads is used, so yes, disabling OpenMP might help. The Tesseract code could also be improved with OpenMP enabled: it could set the number of threads at run time, either based on user's choice (command line parameter) or based on the number of available CPU cores. Set a higher "nice factor" for Tesseract, in this situation? It's normal that programs like `lstmtraining` which mostly do computation use all of the CPU which they can get, so 99 % is good (as long as it is spent for training, not for busy waits during thread scheduling :-)). And running it as `nice lstmtraining` is a good idea if the same computer is also used by other processes / users.  They do not work for me. I've been trying versions: 3.05.00 and 4.00.00alpha.
My file date.user-pattern contains one line:
2014-\d\d-\d\d
Picture is one line with date, like: 2014-03-19
I run: tesseract img.jpg stdout --user-patterns date.user-patterns -psm 8
and output: "mum-w" which obviously does not match the pattern. 
Character whitelisting helps a bit, but format from pattern is not preserve and accuracy is poor.
I also tried some other examples - does not work either.
Many people have the same problem, aggregated links under this one:
https://stackoverflow.com/questions/34560697/tesseract-ocr-user-patterns
also #403
Should we assume that this feature does not work at all? Is there any official comment on this? Same problem with user dictionary:
`tesseract H3.png stdout --user-patterns date.user-patterns --psm 8 --user-words date.user-words -c language_model_penalty_non_dict_word=9999999999999999999 --oem 0
`I tried different language_model_penalty_non_dict_word values with no luck
Related #297, which is closed, so I assume the feature doesn't work. I think it would be better for users if those flags are removed from command line and configurations, because it is misleading as long as they don't affect engine. No, sorry, I never used that option. Nevertheless I also have a [scenario](https://av.tib.eu/media/21360) where working user patterns would help. >No, sorry, I never used that option.

Same answer. User patterns are documented in [`doc/tesseract.1.asc`](https://github.com/tesseract-ocr/tesseract/blob/master/doc/tesseract.1.asc#config-files-and-augmenting-with-user-data) and in [`dict/trie.h`](https://github.com/tesseract-ocr/tesseract/blob/master/dict/trie.h#L193). With 4.0 the problem might be that the Dict class is instantiated twice
```
tesseract::Dict::Dict(tesseract::CCUtil * ccutil)
tesseract::Classify::Classify()
tesseract::Wordrec::Wordrec()
tesseract::Tesseract::Tesseract()
tesseract::TessBaseAPI::Init(...)
```
and then here
```
tesseract::Dict::Dict(tesseract::CCUtil * ccutil)
tesseract::LSTMRecognizer::LoadDictionary(const char * lang, tesseract::TessdataManager * mgr)
tesseract::LSTMRecognizer::Load(const char * lang, tesseract::TessdataManager * mgr)
tesseract::Tesseract::init_tesseract_lang_data(...)
tesseract::Tesseract::init_tesseract_internal(...)
tesseract::Tesseract::init_tesseract(...)
tesseract::TessBaseAPI::Init(...)

```
and both initialise 
https://github.com/tesseract-ocr/tesseract/blob/master/dict/dict.cpp#L43

The real problem is that variables are set between these calls so LSTM dict does not get the value from user defined variables. Does this issue only happen on the command line executable? I mean I can workaround this issue by writing some C++ source file to directly call the API? Thanks.  Hi Ray,

I'm going to compare different OCR engines on University of Washington (UW3) dataset.

Did you use the UW3 dataset during training your LSTM model? If so, the comparison will be useless.

Thanks. >Did you use the UW3 dataset during training your LSTM model?

I'm not Ray, but AFAIK the answer is NO.

What are the other OCR engines in your comparison?
 Hi Amit,

Thanks for the answer.

I'm going to compare the following OCR engines:
1) Tesseract 4
2) Tesseract 3
3) ABBYY Cloud OCR SDK
4) Microsoft Computer Vision API
5) Google Cloud Vision API @vaasily, what were the results of your comparison?  The accuracy of Nepali trainned data is low is some documents. Whole line is recognized as a single word and recognized text seems to be just a string of random character. Here is sample -  

Original Image:
![tess_recog_nep](https://cloud.githubusercontent.com/assets/10336295/26553903/679ae88a-44ad-11e7-9402-f81e6714d386.png)

Recognized Text:
हसेरै बिदा गर्छु भन्थे तिमीलाई
तरमक्कानर्क्सट्टेरासर्यो||
रोक्कभ-शेयीमनश्रित्रमडारिएकाबादललाईं
तरआशबनीबर्सिक्विरै||

Real Text:
हसेरै बिदा गर्छु भन्थे तिमीलाई
तर मुस्कान कतै डेरा सर्यो ||
रोक्छु भन्थे यी मनभित्र मडारिएका बादललाई
तर आशु बनी बर्सिदियो || I have used - https://github.com/tesseract-ocr/tessdata/blob/master/nep.traineddata Thank you very much. LSTM only mode (--oem 1) perform better than Tesseract + LSTM (--oem 2) mode. 

I faced issues in recognizing mostly the Italicized text. And have little difficulties with bold faced text. Is there any way to tackle them?  If you build and install leptonica from a source, then libleptonica.so is created, but not liblept.so
However tesseract ./configure scripts requires liblept.so:
```
(...)
checking for leptonica... yes
checking for pixCreate in **-llept**... no
configure: error: leptonica library missing

```
As a workaround I just link liblept.so to created libleptonica.so, but I belive that tesseract scripts should recognize if we have liblept or libleptonica installed and use proper -l... flag for pixCreate.
Note that liblept.so is installed when you install leptonica from debian/ubuntu repository by e.g. apt-get install. Btw maybe it should be also fixed by leptonica guys to standarize library name no matter you build it by your own or install from repo (?). Neither the stable version 3.05 nor git master tests for pixCreate.
Did you test with Tesseract 3.04 or older? Then please update to a supported version. Previously I checked out to a tag: 3.05.00dev
Now I've just checked to a branch: 3.05 - and now it passes ./configure script, but there is some new problem with make:
```
/usr/bin/ld: cannot find -lleptonica_OUTPUT_NAME-NOTFOUND
collect2: error: ld returned 1 exit status
make[2]: *** [libtesseract.la] Error 1
make[2]: Opuszczenie katalogu `/home/m/OCR/download/tesseract/api'
make[1]: *** [all-recursive] Error 1
make[1]: Opuszczenie katalogu `/home/m/OCR/download/tesseract'
make: *** [all] Error 2
```
And for branch 3.04 without liblept.so I get:
```
checking for leptonica... yes
checking for l_generateCIDataForPdf in -llept... no
configure: error: leptonica library with pdf support (>= 1.71) is missing
Line 122 - configure error
```


 1) leptonica 1.74.2 builded and installed from source
2) Yes, I run autogen before configure.
As I mentioned in 1st post: leptonica builded from source does not create liblept.so, instead it creates libleptonica.so.
 It seems that with **CMake** it's `libleptonica.so`
 Commit f52d445074d0e3863dfbe4f0b6acbf92c0f46d7d changed the library handling to use `pkg-config`. The branch 3.05 includes that commit. Tesseract 3.05.00 still uses the old code. Thanks guys. To summarize:
Yes, I've got only 1 leptonica, and yes, when cmake is used then liblept.so is created instead of libleptonica.so (to be precise: cmake path/to/repo; make -j; sudo make install). For the same reason "checking for l_generateCIDataForPdf in -llept... no". But nevermind, because indeed f52d445 from 3.05 branch fixes  liblept vs libleptonica. However as I mentioned some posts ago: when I use 3.05 or f52d445 I've got a problem with "make" which is connected again with leptonica.
But if you ask me, I'm satisfied with using 3.05.00 and just symlink liblept.so to libleptonica.so.
 @wosiu, the error `/usr/bin/ld: cannot find -lleptonica_OUTPUT_NAME-NOTFOUND` comes from an error in the Leptonica build. The string is part of `lept.pc.cmake` and should be replaced when `lept.pc` is generated. I'd try building Leptonica with configure / make instead of using cmake – maybe that fixes this problem. Try to build both leptonoica and tesseract with the same build system (cmake / autotools) https://github.com/DanBloomberg/leptonica/issues/253 Now I build and install leptonica like this:
```
./autobuild
./configure
make -j 
sudo make install 
```
and indeed liblept.so is created.
However now during tesseract (branch 3.05) "make" I get:
```
/usr/bin/ld: tesseract-tesseractmain.o: undefined reference to symbol 'lept_free'
/usr/local/lib/liblept.so.5: error adding symbols: DSO missing from command line
collect2: error: ld returned 1 exit status
```
3.05.00 build is fine. Does anyone have a solution to this problem without changing the debian version of the leptonica library soname (made with autotools), which is liblept.so? @jbreiden @DanBloomberg, I see no problem with the name of the library here. `./configure && make` builds `liblept.so` which is fine. `liblept.so` also provides `lept_free`. @wosiu, do you compile for Linux or for Windows? Could you provide a complete build protocol?

  for some reason, the network in my country is very bad!!

so i want to use the lib and dll directly.
and finally i found no where to download it?

compile it is so hard for me, is there a solution? @Shreeshrii Thanks for the links! How can I use this build in my QT C++ project? @Shreeshrii 
thanks for you help.
i try download it, but i can not find any .lib file there.

i perfer files below

1. libtesseract304d.lib
1. giflib416-static-mtdll-debug.lib
1. giflib416-static-mtdll-debug.lib
1. giflib416-static-mtdll.lib
1. giflib416-static-mtdll.lib
1. libjpeg8c-static-mtdll-debug.lib
1. libjpeg8c-static-mtdll-debug.lib
1. libjpeg8c-static-mtdll.lib
1. libjpeg8c-static-mtdll.lib
1. liblept171-static-mtdll-debug.lib
1. liblept171-static-mtdll-debug.lib
1. liblept171-static-mtdll.lib
1. liblept171-static-mtdll.lib
1. liblept171.lib
1. liblept171.lib
1. liblept171d.lib
1. liblept171d.lib
1. libpng143-static-mtdll-debug.lib
1. libpng143-static-mtdll-debug.lib
1. libpng143-static-mtdll.lib
1. libpng143-static-mtdll.lib
1. libtiff394-static-mtdll-debug.lib
1. libtiff394-static-mtdll-debug.lib
1. libtiff394-static-mtdll.lib
1. libtiff394-static-mtdll.lib
1. zlib128-static-mtdll-debug.lib
1. zlib128-static-mtdll-debug.lib
1. zlib128-static-mtdll.lib
1. zlib128-static-mtdll.lib @zdenop and you know where to get what we want? @weituotian, get the code and compile it yourself. You won't save much network bandwidth if you could get libraries. And libraries must match your compiler. You did not say which compiler you are using.   On an Intel Xeon Server the new code is significantly faster.

The results are less impressive on a notebook with Core i7 where it is also more difficult to reproduce a timing test. That's why I suggest independent tests by other people. Er, what's with the low-level SSE/AVX programming instead of trusting tools like `#pragma omp simd` and even optimised higher-level libraries, unless it is to leave ample opportunity for further optimisation?

BTW, how is alignment at 32-byte boundaries achieved, and has this been verified? I was blinded by all the other uses of "align", so I didn't find any uses relating to memory alignment... As far as I know, `#pragma omp simd` is not restricted to Intel CPUs, so it could also improve the generated code for ARM and other architectures.

Tesseract currently does not assume 32-byte alignment, but tests the alignment at execution time and chooses different code paths for aligned and unaligned arrays of double values. Just a note: `#pragma omp simd` is not supported with MSVC. @stweil Has anybody verified that this differentiation actually does some good? If you leave it up to chance, I don't think that the odds are in your favour, especially if both arguments have to be aligned at the same time, because the current code does not choose load instructions independently for each parameter; so if it does make a difference, you had better make sure that it's not just once in a while if you're lucky. One parameter aligned is actually the worst case, because you don't necessarily have to start at the beginning of a vector for the SIMD instructions, so what matters is whether the arguments are mutually aligned or not.

@amitdo I don't think that the laggard should set the pace, considering how relatively easy the pragma is to use. @rfschtkt, it looks like one parameter is (mostly?) aligned while the other parameter is only aligned in one of four steps (it increases in steps of sizeof(double) == 8). As far as I see the code could also be modified to handle one aligned parameter with the other parameter unaligned.

I'm still not sure how much the aligned access is faster. As reported by @Shreeshrii, some CPU models don't show increased speed where others show significant faster execution. Memory caches also play an important role.

That's why I want to offer several implementations in Tesseract, and users can choose which one is best for their environment. Do you have any evidence that such differentiation might be useful beyond the purpose of experimentation? I would expect cache-oblivious code, techniques like blocking/strip-mining, to benefit all architectures more or less equally. It doesn't seem very efficient to try to reinvent the wheel here, but I haven't yet looked into any issues like licensing associated with the use of an external library with Tesseract, so... See https://github.com/RRZE-HPC/DDOT-Bench and the associated article for more research on this. They also have code which can be used freely. How about #983? The idea is to primarily rely on OpenMP 4.0's simd where available, then try explicit code for specific implementations, then fall back to serial execution. If you're confident that you have a better implementation than OpenMP, this order can of course be changed, but I don't think this is the case yet. Could you share some details on how you test performance here? Could this be reframed as a unit test that immediately rejects a suboptimal implementation choice? My conjecture is that OpenMP wipes the floor with (relatively speaking) naive use of SSE/AVX intrinsics, and that you only need the latter if you are stuck with Visual C++ (for now). Typically I use these test scenarios for the OCR process (`tesseract` executable, all images available on https://digi.bib.uni-mannheim.de/~stweil/tesseract/):

    # OCR of a very large image (performance test with focus on OCR).
    tesseract 0604.jp2 /tmp/0604-eng -l eng
    tesseract 0604.jp2 /tmp/0604-frk -l frk
    # OCR of a very small image (Valgrind, performance test with focus on pre OCR steps).
    tesseract hello.png /tmp/hello

Recently I added a [test scenario for training](https://digi.bib.uni-mannheim.de/~stweil/tesseract/issue961.sh). It is based on issue #961 provided by @Shreeshrii.

I started writing a [standalone test](https://digi.bib.uni-mannheim.de/~stweil/tesseract/dp-test/) to test the effects of cache size, but that is still unfinished.
 The conflicts are resolved now. I suggest to keep the PR open until more people have reported their timing test results.  Add two build dependencies which were missing and update the hints for
building ScrollView.jar.

Signed-off-by: Stefan Weil <sw@weilnetz.de>  Would it be possible to preserve layout? I'm thinking of something akin to:

pdftotext -layout

I'm working with images of tabular computer printouts. Although the OCR function is impressive, without the layout, the result is largely unusable. If text stayed roughly in its columns, it would be readable. I wasn't sure if --psm 5 might have been intended to be helpful but it produced junk: could it be broken? All the other psm options I tried produced something reasonable. I have now - they aren't mentioned on the default usage, so I didn't know about them. For what I want to do, the tsv fomat may work well. I'm not sure what some of the columns mean, but the coordinates are clear.

Your suggestion lets me develop a solution for my problem better than my original suggestion. In particular, it lets me make my own decisions about text which doesn't align well such as superscripts or font changes within a line.

However I think my change request as originally stated would be useful. If you try pdftotext with/out the -layout option on something like a bank statement you'll see what I mean! 

To summarise: 

Thanks, you solved my problem. My proposal would still be useful. The --help option should document tsv/hocr (a new change request)?. Thanks for an amazing tool.  I've been creating Tesseract 3.02 application uses Visual Studio and already train and have tesseract data for 3.02. Now my company want me to develop on android which I'm using rmtheis TessTwo API which uses Tesseract version 3.05. So how can I convert my 3.02 data to 3.05? Or is it 3.02 can be used on 3.05 without need to change (though I believe this i not true)?
Please help thank you  Hi guys,

I am new to tesseract and I was following tesseract 3.xx guide and was able to generate ara.traineddata for arabic language but after some time I came to know that there is no point of further train the engine for v.3.xx so I shifted to v4.00 alpha which is the current latest version of tesseract but I am facing some issues while training.

First issue is that there are no alternative commands for windows and only linux based commands for training are available but I manage to run some commands and facing an issue where I can't train further.

**Command I am using:**
_..\lstmtraining -U ara.unicharset --script_dir ..\langdata --net_spec "[1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c105]" --model_output ..\training --debug_interval 0 --train_listfile ara.training_text.txt_

_Where lstmtraining.exe is the previous directory, I have ara.unicharst file, other options are same as I picked from sample command given here: https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00 and I have ara.training_text.txt **(same was used to generate box files and tiff files)** file for arabic text but now I getting the following errors:_

" C:\Program Files (x86)\Tesseract-OCR\training>..\lstmtraining -U ara.unicharset --script_dir ..\langdata --net_spec "[1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c105]" --model_output ..\training --debug_interval 0 --train_listfile ara.training_text.txt
Other case u of U is not in unicharset
Other case n of N is not in unicharset
Other case e of E is not in unicharset
Other case h of H is not in unicharset
Other case C of c is not in unicharset
Other case T of t is not in unicharset
Other case S of s is not in unicharset
Other case V of v is not in unicharset
Other case D of d is not in unicharset
Other case W of w is not in unicharset
Setting unichar properties
Warning: given outputs 105 not equal to unicharset of 96.
Num outputs,weights in serial:
  1,36,0,1:1, 0
Num outputs,weights in serial:
  C5,5:25, 0
  Ft16:16, 416
Total weights = 416
  [C5,5Ft16]:16, 416
  Mp3,3:16, 0
  Lfys64:64, 20736
  Lfx128:128, 98816
  Lrx128:128, 131584
  Lfx256:256, 394240
  Fc96:96, 24672
Total weights = 670464
Built network:[1,36,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc96] from request [1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c105]
Training parameters:
  Debug interval = 0, weights = 0.1, learning rate = 0.0001, momentum=0.9
Deserialize header failed: ∩╗┐╪▒╪│┘à╪º ╪╡╪¿┘è╪¡┘ç ╪│┘ä┘ê┘à ┘ç┘ä╪º┘ä┘ç ╪╣╪¿╪»╪º┘ä┘ä╪╖┘è┘ü ╪¿┘â╪▒┘è ╪ºé╪▒ ╪º┘ä┘é╪╣┘è┘é╪╣┘è ┘à╪╢╪º┘ê┘è ╪╣╪º┘à┘é ╪¡┘è╪»╪▒╪╣┘ä┘è ┘å┘ê┘è╪▓╪¡ ╪º┘ä╪¡┘à┘è╪»Load of page 0 failed!
Load of images failed!! "

**Ignore the random text I think it is coming because of the text file I am using as I copied this from Command Line. Please find the text file I am using along with tiff & box files in the attachments.**

Need help as soon as possible.

Thank You

[ara.training_text.txt](https://github.com/tesseract-ocr/tesseract/files/1022209/ara.training_text.txt)
[ara.nicidprint.exp0.zip](https://github.com/tesseract-ocr/tesseract/files/1022223/ara.nicidprint.exp0.zip)
[ara.nicidprint.exp0.box.zip](https://github.com/tesseract-ocr/tesseract/files/1022225/ara.nicidprint.exp0.box.zip)
 Thank You so much, I will try and will update you. Hi,

I am still facing issues.

Now I used this command:

../train/lstmtraining -U ara.unicharset --script_dir ../langdata --debug_interval 100 --net_spec '[1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c105]' --model_output ../ara_train --train_listfile ara.nicidprint.exp0.lstmf --max_iterations 5000 &>../ara_train/basetrain.log


and the result is:



Other case u of U is not in unicharset
Other case n of N is not in unicharset
Other case e of E is not in unicharset
Other case h of H is not in unicharset
Other case C of c is not in unicharset
Other case T of t is not in unicharset
Other case S of s is not in unicharset
Other case V of v is not in unicharset
Other case D of d is not in unicharset
Other case W of w is not in unicharset
Setting unichar properties
Warning: given outputs 105 not equal to unicharset of 96.
Num outputs,weights in serial:
  1,36,0,1:1, 0
Num outputs,weights in serial:
  C5,5:25, 0
  Ft16:16, 416
Total weights = 416
  [C5,5Ft16]:16, 416
  Mp3,3:16, 0
  Lfys64:64, 20736
  Lfx128:128, 98816
  Lrx128:128, 131584
  Lfx256:256, 394240
  Fc96:96, 24672
Total weights = 670464
Built network:[1,36,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc96] from request [1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c105]
Training parameters:
  Debug interval = 100, weights = 0.1, learning rate = 0.0001, momentum=0.9
Deserialize header failed: 8
Load of page 0 failed!
Load of images failed!!
Deserialize header failed: 
Deserialize header failed: 
Deserialize header failed: !ÄtvÖÞáø"¤Ó³@¾ˆqÌ!Ÿ.?‚ì­“Ì/ž~ÎÅáx§‘áÓð’Èîðè¯Æ¹Âž+Y¸„³’0šÚ¬/Cv{%7â¶\èmZ‰Ÿh>%ÅéF¸£ÇîKE¤ˆc÷Öô=ñ›HG@Pl>ù’_“…“mg‹l"³@ÊˆÎ~f=±um1£l/b¬Ma[&UðsEÿ´t'û•  ­ÄúhU
Deserialize header failed: 5÷4Sye)p¿ÅIôúã+h]‡jÚOy½¦MƒbÚ]i,²ý”dBvó=ÈcÔÐY0QÿæF¡ñà*SžŒ–(Vs””§
-7ìE»°Y[§î÷õµ8>3½t?Ö„+hÚ©ú¡v?wGâ¬:¾½ Û1êT3ß(¦
A¯î¢X	Â3Åb°7­ìv“3Ó’ÚûÛð:Clñþt÷$&ªÌYc¤_.2vC¾Á§)Ù„?©ZêKð¾¾N1Ê£zy_Ÿ!„K©”f±¦#"©GW©ëC^7ë^Ûc	îeH›˜†Äž#ÙB&1ÒOU)ÚâzÊÙsm§ô ‡QRÊH#"°BÒ©ù…%–DXH¬|­ŸÃ1*`HŸˆ
Deserialize header failed: ¢›K‡ÙŒØ‹¢ÂÏ÷ÙIÅmùŽmÅZ(ª>ˆ^¥¯æ!¨ä!ï¥´
Å
«‘ºmÑ‹ÿMhµ©0Ê³šü¯-Š–3áÆ ‘±"c+Ò H«=xù 3X‘Ð#®óY fÚà¼Ë.<¬{à64ìš=99È›FBRF@W(-™© WNpñþ¯%d
r8‚…±ªÙ+ Ééò›"@ÖTCŒµR`R@L‚®k<¤¤0‹‰|#G°‡Ù
Deserialize header failed: !‰kOLÉ±¥«øncÙmù~J²•G“¤¡™–JŒå€6yØª×šo“ÌCH¬Nÿ£‚r›¥#æ¤k¸Œf_…Š1dÇj¿‰½’C¯Æ¼àŠõuA3£ŠªB™'-é•Îí´0µˆ[ÙÏƒèITŽÏ¨`1„R’=Å³qH+Ó@Å`â‰3,]]¹s6 [Ë)…&•„½pCeòzaG÷3¼²Î¢“Xy),_)Œ¸n’‡!ÊFJ«¶J‚}“P|;}MÀ]Kjç­SÃF©)ðæ‰ÞŽáÚ•ö	ƒdÏ‚Y¹f·é0°™í-
Deserialize header failed: ëÁ‰Ü4\Ò/T¶ñO[O ˆwõu‹VéeEÈŒu¼’}ëÑùJhÌ=šzÏ]ÚÓO€7 Ï=h¨Ä¶EµC
Deserialize header failed: Ò"ÔA‚N9KU¸¥ÇH©_]³#‘çT'RbX*ŽºAd¨¬…úô:v¾²¨¤?¥N¶[Ã


Please help.

Thank You Thank You soooooo much. It worked and now it is running. Once it is finished then I will let you know.

Thanks again friend. @latifwirelessmaker which fonts you added? I am using Nic Id Print, its a custom font created for some specific data @LatifWirelessMarketer 
ok good
just your training finished tell us about the accuracy you reached..

Thank you OK Sure but I am still in training phase as I just started with v 4.0 so maybe with current data I will not reach that much accuracy so I will run it again for last amount of training text.

So will keep updating about accuracy improvements.

Thanks.  Btw, can anyone tell me how much of text is required to get a good accuracy? I've read in the documentation that original training was done on more then 400000 lines of text so is it necessary to have that much text of languages like (english, arabic, etc...) or not.

Also let me know if I can get the original source of text used for training the languages that are available to be downloaded freely from original source?

Thank You  Regarding the Arabic language, the number of Lines required to produce a decent Model depends on the complexity of the typeface. But it is proven that you are able to create an Arabic Model capable of achieving +90% recognition rate using ~800 lines in your training.

Have a look at the research done by the OpenITI​ team, implimented using Kraken engine:
[1)The Research paper
](https://drive.google.com/file/d/0BzDVkBcqiyEsbC16ZGktOWNiUDg/view)
[2)Kraken](http://kraken.re/)
 @LatifWirelessMarketer can you post your test results such as recognition rate and time.
waiting for your updates @christophered I was training on huge text before but it was a never ending task to now I am trying to train it on small text with different fonts like arial, tahoma etc. and text lines are less then 30. It took me more then 3 hours to train at first with error rate below 0.9 but the problem is that after I was able to generate ara.lstm file which is the final training file. Now I am unable to generate ara.traineddata

Command I used:
..\combine_tessdata -o ..\tessdata\ara.traineddata ara.lstm ara.unicharset ara.number-dawg ara.punc-dawg ara.word-dawg

and I am getting this error:
Failed to create a temporary file ara.traineddata.__tmp__

no matter what, if I change the traineddata directory. The error remains the same.

Does anyone know this problem and it's solution, then please help.

Thank You @Shreeshrii  @Shreeshrii I checked everything already and even after you explained it to me. There are no files in any directory like ara.traineddata or ara.traineddata.__tmp__ etc. I deleted all previous ones and now trying from scratch but still it's giving me same error.

see attachment.

![lstm](https://cloud.githubusercontent.com/assets/19776088/26761448/5742efe8-4938-11e7-8c09-6afbccc49b3f.png)
 @Shreeshrii what percentage recognition rate for the Arabic language you where able to get? @christophered My char error rate was 0.78 but how to check percentage recognition rate? I think we can only check after generating the trained data right? @christophered  I uninstalled tesseract engine after coping my files and reinstalled it, now its working.

 @Shreeshrii , One questions brother.

I want to know if there is no ara.traineddata already present in the folder, then how can we create a new file? I mean I tried several times and the error I was getting yesterday was just because there is no ara.traineddata file present. If I copy any ara.traineddata from the internet in my tessdata folder then it combines the new trained data with that.

For example the size of original data was 11.9mb but I used only 20 lines of text and my trained data size become 11.0mb. How is that possible? @Shreeshrii Thank You soo much brother.

Btw do you know what is the difference between ara.word-dawg & ara.lstm-word-dawg?

I mean I know how to generate word dawg as it is generated based on word list but what about lstm-word list?

Thank You @LatifWirelessMarketer send me an email, I want to talk with you regarding the training process.
Also please delete the gibberish after `Deserialize header failed:` your making your topic hard to go through @christophered sorry for it man, I removed it. @LatifWirelessMarketer Are you using Tesseract 4.x on Windows or Linux? @christophered Tesseract 4.00alpha on windows
 @christophered I am facing one problem. After 2 weeks, I've achieved error rate of 0.61% which is good but after I generate the traineddata and tested, it give me bidi joined characters as opposite.

For example if I test it on my name as: SALMAN (سلمان) and when it detects it almost detects it correctly but lets just say سل is one character based on a whichever font I am using. So when this is what it will return (لسمان) it detects سل as لس which is wrong. 

Can you help me with this? What can be the reason behind it? As it happens with every joined character.

Thank You  Can someone help me?? @christophered ? @LatifWirelessMarketer Error rate of 0.6 is very bad, my guess is that you either:
- Have some mistakes or inconsistencies in your training data, **Your training data**
- Or there are some characters that are causing confusion, **Tesseract itself**

Please upload your training data and the created module, so that we can have a closer look.
Also, list your step-by-step commands that you used to create the training data, create and train the lstm model, and recognize the images. Arabic has some known issues, like the one you described.
Hopefully, Ray will able to fix them.

  Hi ,

Anyone please help me in finding / Creating lang.cube.* files for all the other languages in tessdata folder. like eng language has. Please help me out in training data for cube. Or anyone already have those cube files please share with me.

Thanks and Regards,
Merlin
 can i know the forum insite details See https://github.com/tesseract-ocr/tesseract/wiki#support.  I installed the tesseract through pip install. The latest version of it is 3.04.01. When I tried to compile my C++ code, it has errors with libtiff. Since the 3.05 version has abandoned such dependency, I am wondering if there is a way to upgrade my tesseract, AND AT THE SAME TIME, I can write both C++ and Python code on that. Thank you so much in advance.  Performance is important for real time OCR, mass production OCR and training.

In this RFC I'd like to discuss performance bottlenecks and potential improvements.

See also the [Tesseract wiki](https://github.com/tesseract-ocr/tesseract/wiki/4.0-Accuracy-and-Performance).

According to my tests with Valgrind's tool `callgrind`, these functions have the largest computational costs (ordered by decreasing time):
- memory allocations / deallocations
- `tesseract::UnicharIdArrayUtils::compare`
- `tesseract::DotProductAVX` (or the other implementations of the dot product)
- `vfprintf` (called from `snprintf`)

`tesseract::UnicharIdArrayUtils::compare` and memory allocations / deallocations are also the functions which are called most often.

I recently had a closer look at the dot product calculations and noticed that at least some input vectors are converted from `float` to `double` (which takes time). The dot product is always done with `double` values (more expensive than `float`). If memory bandwidth is the limiting factor, using `double` means doubled time compared with `float`. The current code uses 4 parallel threads. I have run some timing tests without that parallelization and got nearly the same execution time. @theraysmith, did you try using `float` for the dot product, and do you get better performance from parallelization in that part of the OCR process? Valgrind shows all callers, so I can provide that information (next week, as I'm currently busy with other things).

Regarding precision of the dot product: the addition is the critical part for the accuracy. Did you ever try some of the algorithms which help to improve that part, e. g. [Kahan](https://en.wikipedia.org/wiki/Kahan_summation_algorithm)? Maybe that would be sufficient to allow using `float` everywhere.

I used OpenMP and disabled it only in `lstm/fullyconnected.cpp` and in `lstm/weightmatrix.cpp`. The original code of the master branch shows that OpenMP works, as the real time is much less than the user time:

    real    2m50,958s
    user    7m39,712s
    sys     0m2,128s

With OpenMP disabled for the parts mentioned above, OpenMP still works, the real time increases moderately while the user time decreases:

    real    3m9,378s
    user    7m33,084s
    sys     0m2,092s
 Stack for tesseract::UnicharIdArrayUtils::compare (called 2651872 times for small hello world image):

    tesseract::UnicharIdArrayUtils::compare
    ELIST::add_sorted_and_find
    ELIST::add_sorted
    tesseract::UnicharAmbigs::InsertIntoTable
    tesseract::UnicharAmbigs::LoadUnicharAmbigs
    ... It is for LSTM:

    valgrind --tool=callgrind --dump-line=yes --verbose api/tesseract --oem 1 hello.png /tmp/hello

The output is a large file called something like `callgrind.out.1234` (replace `1234` by the process id).
I suggest using `kcachegrind` to see the results. No, it was built with `./configure  --disable-shared --disable-static 'CXXFLAGS=-Wall -g -O2'`. I usually disable the library builds because they take additional time. My first results reported above were from a very small image (single line hello world), so initialization contributes significantly.
 
With a really large image (newspaper), the result changes and `tesseract::DotProductAVX` is the dominating element. Surprisingly it is followed by `gomp_team_barrier_wait_end` and `gomp_barrier_wait_end` which according to Valgrind use nearly as much time as the dot product. Those two functions are part of OpenMP.

See also issue #898. Unrolling the loop in `tesseract::DotProductAVX` results in nearly 7 % improvement:

    # tesseract 0604.jp2 /tmp/0604 # git master, without OpenMP
    real	2m54,469s
    user	2m54,160s
    sys	0m0,304s

    # same test, but with improved tesseract::DotProductAVX
    real	2m41,855s
    user	2m41,576s
    sys	0m0,272s
 Latest numbers based on code from [FAU Erlangen](https://github.com/RRZE-HPC/DDOT-Bench/blob/master/DP/src/ddot_kahan_avx_intrin.c) (thanks to @moebiusband73), Kahan part removed:

    real	2m31,514s
    user	2m31,220s
    sys	0m0,280s

That is an improvement of 12 %. Using assembler code could improve further, but I'd expect the largest improvement from using `float` instead of `double` (trying to compensate the loss of precision by using the Kahan algorithm). The conversation here is largely over my head, but I came to the bug tracker to discuss performance in 4.0, and this bug is titled "RFC: Tesseract Performance" so it seems like the right place. (Apologies if I'm wrong.)

Simple question: On the "[Neural nets In Tesseract" wiki page][nn], it says:

> On a machine with multiple cores, and AVX, an easy English image may take twice as much real time, and use 7 times the CPU as base Tesseract

But [above][a] (and elsewhere) says:

> I have had some very good results in this area, with a network 3x faster than the legacy code (for English)

I do a lot of batch OCR using Tesseract. Can I expect 4.0 to be faster by 3× or slower by 7×? If the latter, that'll be something that we'll need to plan on, since our current infrastructure took over a month to complete the last batch OCR job using 3.02. If we need 7× more servers that's a huge deal — I don't know that we'd ever upgrade if that was the case. If it's 3× faster, that's incredible.

(Sorry again if this is the wrong place to bring this up. I'm trying to get a grasp on this situation. Thank you all for all your great work.)

[nn]: https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00#hardware-and-cpu-requirements
[a]: https://github.com/tesseract-ocr/tesseract/issues/943#issuecomment-303239929 The current 4.0 still supports the "old" OCR recognizer and is comparable to 3.05 if that is used (command line argument `--oem 0`), but there are plans to remove this feature from 4.0.

4.0 supports a new recognizer based on LSTM (`--oem 1`). The new code for LSTM uses parallel processing, so OCR can finish faster, but need more total CPU time. As 4.0 is still experimental, all timing results can change. Ray announced new trained language models for 4.0 with a smaller neural network. If that works, it could reduce CPU‌ time in comparison to 3.05.

Currently you won't reduce the infrastructure requirements with 4.0. That sounds promising, thanks @stweil. I'm perfectly happy not reducing infrastructure requirements, but increasing them 7× would be a very big deal. 

FWIW, decreasing wall time via parallelization while increasing CPU time sounds good on paper, but unless I'm missing something (totally possible), it doesn't mean much for batch jobs like ours since we run 24 OCR processes in parallel already. Our server looks like this when doing a job:

![screenshot from 2017-05-10 16-18-40](https://cloud.githubusercontent.com/assets/236970/25925259/58c72140-359c-11e7-8f05-f03ba6c022fc.png) For your use case (which is similar to my own) I'd compile Tesseract without OpenMP support. Otherwise the parallelization will take a significant part of the CPU performance. What's the method you use to disable OpenMP?

Commenting `AC_OPENMP` or something else? `configure --disable-openmp` `--disable-shared --disable-static` seems to be equivalent to just `--disable-shared`.
  I got error during compilation of latest Tesseract 4.0 (5a06417eb273a3cc3e5f720ca8fa4bbaa7940ae6).
OS: Debian 7.11 x64
gcc version 4.7.2 (Debian 4.7.2-5)

Any suggestions please? Thanks a lot!

```
<shortened>
Making all in ccmain
make[2]: Entering directory `/tmp/tesseract/tesseract/ccmain'
/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl  -fopenmp  -I/usr/local/include/leptonica    -g -O2 -std=c++11 -MT paragraphs.lo -MD -MP -MF .deps/paragraphs.Tpo -c -o paragraphs.lo paragraphs.cpp
/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl  -fopenmp  -I/usr/local/include/leptonica    -g -O2 -std=c++11 -MT recogtraining.lo -MD -MP -MF .deps/recogtraining.Tpo -c -o recogtraining.lo recogtraining.cpp
/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl  -fopenmp  -I/usr/local/include/leptonica    -g -O2 -std=c++11 -MT reject.lo -MD -MP -MF .deps/reject.Tpo -c -o reject.lo reject.cpp
/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl  -fopenmp  -I/usr/local/include/leptonica    -g -O2 -std=c++11 -MT resultiterator.lo -MD -MP -MF .deps/resultiterator.Tpo -c -o resultiterator.lo resultiterator.cpp
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl -fopenmp -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT paragraphs.lo -MD -MP -MF .deps/paragraphs.Tpo -c paragraphs.cpp  -fPIC -DPIC -o .libs/paragraphs.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl -fopenmp -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT recogtraining.lo -MD -MP -MF .deps/recogtraining.Tpo -c recogtraining.cpp  -fPIC -DPIC -o .libs/recogtraining.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl -fopenmp -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT reject.lo -MD -MP -MF .deps/reject.Tpo -c reject.cpp  -fPIC -DPIC -o .libs/reject.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl -fopenmp -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT resultiterator.lo -MD -MP -MF .deps/resultiterator.Tpo -c resultiterator.cpp  -fPIC -DPIC -o .libs/resultiterator.o
paragraphs.cpp: In function 'void tesseract::InitializeRowInfo(bool, const tesseract::MutableIterator&, tesseract::RowInfo*)':
paragraphs.cpp:2450:72: error: use of deleted function 'std::unique_ptr<_Tp [], _Dp>::unique_ptr(_Up*, typename std::enable_if<std::is_convertible<_Up*, _Tp*>::value>::type*) [with _Up = char; _Tp = const char; _Dp = std::default_delete<const char []>; typename std::enable_if<std::is_convertible<_Up*, _Tp*>::value>::type = void]'
In file included from /usr/include/c++/4.7/memory:86:0,
                 from paragraphs.cpp:24:
/usr/include/c++/4.7/bits/unique_ptr.h:433:2: error: declared here
make[2]: *** [paragraphs.lo] Error 1
make[2]: *** Waiting for unfinished jobs....
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl -fopenmp -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT recogtraining.lo -MD -MP -MF .deps/recogtraining.Tpo -c recogtraining.cpp -o recogtraining.o >/dev/null 2>&1
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl -fopenmp -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT resultiterator.lo -MD -MP -MF .deps/resultiterator.Tpo -c resultiterator.cpp -o resultiterator.o >/dev/null 2>&1
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../arch -I../lstm -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../opencl -fopenmp -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT reject.lo -MD -MP -MF .deps/reject.Tpo -c reject.cpp -o reject.o >/dev/null 2>&1
mv -f .deps/recogtraining.Tpo .deps/recogtraining.Plo
mv -f .deps/resultiterator.Tpo .deps/resultiterator.Plo
mv -f .deps/reject.Tpo .deps/reject.Plo
make[2]: Leaving directory `/tmp/tesseract/tesseract/ccmain'
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `/tmp/tesseract/tesseract'
make: *** [all] Error 2
``` Oh, sorry for that. There were no problems on Ubuntu 16.04, but for compatibility purposes I have to compile with older `glibc` on Debian 7. I haven't realized that Debian 7 is that much old :smiley:  I had very limited success doing OCR in Kurdish using the trained data. I think this is because it was trained on a mix of Kurmanji (the largest dialect, written in a Latin alphabet with a few circumflexes) and Sorani (the second-largest dialect, written in a modified Persian alphabet) sources. It keeps wanting to find Arabic/Persian characters in my Kurmanji documents. I imagine that splitting the training data by alphabet (say, into Kurdish-Kurmanji and Kurdish-Sorani) would improve the OCR quality dramatically.

Please let me know if there's any way I can contribute to the Kurdish transcription quality.  Hello!

In #700 we added the packaging to release tesseract to the snaps store. But it hasn't been published there yet. Now we have a very cool new service that can help you doing that, and will take care of the continuous delivery for you.

Please take a look at https://build.snapcraft.io/
After logging in there with your github account, you can tell it to make a new release to the unstable channel in the store every time that your master branch changes. Then your latest changes will be available to all the ubuntu users out there with no effort.

We are in beta, so I would appreciate any comments about your experience using the service.

pura vida. @zdenop oh, that's sad. But I understand.
The work of automating the continuous delivery is very simple, so would you mind if I set up a mirror that keeps tesseract in the Ubuntu store updated after every change in your repo? I think that the maintainers are unnecessary intermediaries if we design good tools to automate the delivery, and safe and isolated packages so upstream developers can't break users' machines. We are working towards that, and if we do it right, at some point in the future you might like me to transfer the ownership in the store to you. We will see :)

Now this aligns nicely with a few things I have to test constantly, so happy to maintain it. I'll keep you posted about stats, feedback and such. If you need something snap or ubuntu related, just ping me.

pura vida.  Hi,
The region that I want to run OCR on is surrounded by 4 boxes one on each edge. My question is how to find the coordinates of these boxes. Also if I scan a page and the page gets a bit disoriented how do I fix that?  #318 
I followed the solution #318 pulled before. 
And after i ran 
`set_unicharset_properties -U unicharset -O new_unicharset --script_dir=/home/qs/Downloads/langdata`
It shows like this
Loaded unicharset of size 29 from file unicharset
Setting unichar properties
Other case c of C is not in unicharset
Other case f of F is not in unicharset
Other case K of k is not in unicharset
Other case a of A is not in unicharset
Other case l of L is not in unicharset
Other case y of Y is not in unicharset
Other case s of S is not in unicharset
Other case m of M is not in unicharset
Other case i of I is not in unicharset
Other case e of E is not in unicharset
Other case t of T is not in unicharset
Other case w of W is not in unicharset
Other case n of N is not in unicharset
Other case o of O is not in unicharset
Writing unicharset to file new_unicharset

Seems correct, but the contents in new_unicharset is 

29
NULL 0 NULL 0
Joined 7 0,69,188,255,486,1218,0,30,486,1188 Latin 1 0 1 Joined	# Joined [4a 6f 69 6e 65 64 ]a
|Broken|0|1 f 0,69,186,255,892,2138,0,80,892,2058 Common 2 10 2 |Broken|0|1	# Broken
9 8 0,66,200,255,89,156,0,39,104,173 Common 3 2 3 9	# 9 [39 ]0
7 8 12,68,196,255,72,160,0,60,75,173 Common 4 2 4 7	# 7 [37 ]0
1 8 49,69,192,255,45,128,0,66,74,173 Common 5 2 5 1	# 1 [31 ]0
2 8 30,69,194,255,80,160,0,27,97,173 Common 6 2 6 2	# 2 [32 ]0
6 8 58,66,219,255,87,156,0,54,104,173 Common 7 2 7 6	# 6 [36 ]0
/ 10 0,65,219,255,59,228,0,36,62,238 Common 8 6 8 /	# / [2f ]p
3 8 0,66,196,255,84,158,0,32,103,173 Common 9 2 9 3	# 3 [33 ]0
C 5 58,65,219,255,87,192,0,32,107,209 Latin 10 0 10 C	# C [43 ]A
F 5 57,68,216,255,68,210,0,31,77,209 Latin 11 0 11 F	# F [46 ]A
k 3 57,68,216,255,85,177,0,35,93,198 Latin 12 0 12 k	# k [6b ]a
A 5 52,68,216,255,100,216,0,17,98,231 Latin 13 0 13 A	# A [41 ]A
5 8 12,66,199,255,82,160,0,36,103,173 Common 14 2 14 5	# 5 [35 ]0
4 8 0,68,198,255,93,161,0,41,96,173 Common 15 2 15 4	# 4 [34 ]0
L 5 59,68,216,255,64,193,0,31,74,206 Latin 16 0 16 L	# L [4c ]A
Y 5 59,68,216,255,91,205,0,47,91,223 Latin 17 0 17 Y	# Y [59 ]A
8 8 57,66,219,255,88,162,0,41,103,174 Common 18 2 18 8	# 8 [38 ]0
S 5 57,64,219,255,87,174,0,30,100,200 Latin 19 0 19 S	# S [53 ]A
M 5 57,68,216,255,99,301,0,35,117,286 Latin 20 0 20 M	# M [4d ]A
I 5 59,68,216,255,10,155,0,50,29,173 Latin 21 0 21 I	# I [49 ]A
E 5 59,68,216,255,68,210,0,31,80,219 Latin 22 0 22 E	# E [45 ]A
T 5 59,68,216,255,85,227,0,47,88,236 Latin 23 0 23 T	# T [54 ]A
W 5 54,68,216,255,106,314,0,41,117,318 Latin 24 0 24 W	# W [57 ]A
0 8 58,66,187,255,88,164,0,45,103,180 Common 25 2 25 0	# 0 [30 ]0
N 5 59,68,216,255,87,262,0,27,104,249 Latin 26 0 26 N	# N [4e ]A
O 5 57,64,219,255,91,209,0,34,106,233 Latin 27 0 27 O	# O [4f ]A
\ 10 0,67,219,255,28,250,0,71,62,261 Common 28 10 28 \	# \ [5c ]p

And i do anything successfully and finally i got traindata. But here is a problem now. There is no output when i used the traindata to test the image. I think there is maybe something wrong with unicharset. 
Could anyone help? Here are my train data
box
[http://pan.baidu.com/s/1hsA8U4O](url)
image
[http://pan.baidu.com/s/1pLHgoQn](url)









 Hi Anida.qin, Your links return 404 page error? Thanks that worked. Sorry to reply late. I solve the problem now. Maybe I did something wrong when do the command box.train  . It goes with the invalid .tr file. But there is also broken line there, but finally i found it can be ignored if you only have few CreateInt() lines when use command mftraining. So i closed this issue.  Reading the forum, it seems a lot of people would benefit from having a screenshot mode where Tesseract would automatically process the image to increase the accuracy. I.E. enlarging image, making into black and white, and so on.
Is it possible to implement such feature?
Thanks! >https://github.com/DanBloomberg/leptonica/blob/master/prog/pdf2mtiff

It's just a bash script that calls ghostscript.

Users can invoke it directly. VietOCR has this mode already and improves the quality significantly, sometimes sharpening the image helps as well. If not adding this feature at least the "golden" standard what to do with screenshot to make it work with tesseract would be helpful. 

I'm just guessing upscaling by 312.5% to get from 96dpi to 300dpi of windows screenshots, then I do sharpening and then putting it to grayscale. Is there something I shouldn't do? Or something I'm missing? If there is no screenshot feature, at least tell us what we should do in the scripts imagemagick . You have guidelines for scanned text, rotate, remove noise, remove borders etc... Give us at least something which is focused for screenshots.  An implementation could also get pairs of _image file name_ and _output base_ from the file list instead of image files only. That would allow more flexibility. CC: @jbreiden  The sum of the 5 individual tesseract processes is ~2m 46s real time, quicker than batching images in a single process. That's not quite what we were expecting to see. Anyone know why? @jbarlow83 

This might be related to the adaptive learning that Tesseract does. Here are my results for a simple hello world image.

Summary for default language (identical to `-l eng`):

- PNG and TIFF show similar performance
- TIFF multi-page and list of single page TIFF show similar performance and are much faster than calling Tesseract for each single page
- LSTM takes more CPU time than old engine for this example

Summary for language with very large `traineddata`:

- no text recognized
- old engine takes much longer (otherwise similar to the results above)
- LSTM comparable to result with default language (but no text recognized)

**LSTM (--oem 1)**

    PNG (ten times)
    user 0.23
    user 0.23
    user 0.23
    user 0.23
    user 0.23
    user 0.24
    user 0.24
    user 0.25
    user 0.25
    user 0.25

    real 2.76
    user 2.42
    sys 0.77

    TIFF (ten times single page)
    user 0.23
    user 0.24
    user 0.24
    user 0.24
    user 0.24
    user 0.25
    user 0.25
    user 0.25
    user 0.26
    user 0.27

    real 2.77
    user 2.50
    sys 0.74

    TIFF (ten pages)
    real 0.43
    user 0.76
    sys 0.06

    TIFF (list with ten single page images)
    real 0.43
    user 0.73
    sys 0.09

**Old engine (--oem 0)**

    PNG (ten times)
    real 2.70
    user 1.98
    sys 0.69

    TIFF (ten times single page)
    real 2.68
    user 1.94
    sys 0.70

    TIFF (ten pages)
    real 0.51
    user 0.42
    sys 0.08

    TIFF (list with ten single page images)
    real 0.52
    user 0.43
    sys 0.08

**LSTM engine with large traineddata (--oem 1 -l mya)**

    PNG (ten times)
    real 2.21
    user 1.87
    sys 1.17

    TIFF (ten times single page)
    real 2.20
    user 1.82
    sys 1.20

    TIFF (ten pages)
    real 0.49
    user 1.12
    sys 0.11

    TIFF (list with ten single page images)
    real 0.47
    user 1.04
    sys 0.11

**Old engine with large traineddata (--oem 0 -l mya)**

    PNG (ten times)
    real 18.42
    user 16.26
    sys 2.10

    TIFF (ten times single page)
    real 19.07
    user 16.20
    sys 2.28

    TIFF (ten pages)
    real 10.69
    user 10.46
    sys 0.22

    TIFF (list with ten single page images)
    real 10.78
    user 10.53
    sys 0.23
 Yesterday I had a look on the implementation to see where I could add the page separator and found that it is already there:

The parameter `include_page_breaks` enables a page separator string in output text after each image / page. It is disabled by default.

The parameter `page_separator` sets the string used as page separator. It is set to the form feed character by default.

So the desired behavior is achieved by `tesseract multipage.tif /tmp/multipage -c include_page_breaks=1`. It adds the `FF` character after each page (also after the last page which would not be necessary).

I noticed that Tesseract also adds an empty line at the end of each page. Do we need / want that? I'd prefer to get rid of it. I suggest to remove the `include_page_breaks` parameter, remove the empty line at the end of each page, and always use the `page_separator` parameter. Then each page will be terminated by the `FF` character by default for text output. Setting `page_separator` to the `LF` character would restore the old behaviour, setting it to an empty string would omit page separators.

Would that be fine for everybody? @theraysmith? There was no answer to my previous suggestion. If people agree, I'll prepare a pull request which removes `include_page_breaks` and which always uses the `page_separator` parameter. https://github.com/tesseract-ocr/tesseract/commit/4c7c960bfd57c5863fe639afab801080d9ef8bbe

https://web.archive.org/web/20160626112213/http://code.google.com/p/tesseract-ocr/issues/detail?id=1417

https://groups.google.com/d/msg/tesseract-dev/VsgJ9R-cTQ0/OMeDjYWoAdQJ


 My question is: Are you sure that any text editor can handle form feed? The ones which I know (more than 10) can handle form feed. So do all printers (which really do a form feed).
 Including Notepad?

See the discussion which led to the patch:

https://groups.google.com/forum/#!msg/tesseract-dev/VsgJ9R-cTQ0/OMeDjYWoAdQJ Notepad cannot be used reasonably with text files which use the common LF line endings – it expects CRLF. So it does not work with text files generated by Tesseract, and FF is only an additional detail. Maybe that's why I did not count Notepad as an editor.

As I suggested to keep the `page_separator` parameter, it would still be possible to use the tricks mentioned in the discussion which you cited. >There was no answer to my previous suggestion. If people agree, I'll prepare a pull request which removes include_page_breaks and which always uses the page_separator parameter.

I agree :-)  I'm trying to create a C++ project by visual studio 2015. But I can not find anywhere that I can download the include and lib file to import to my project. Anyone help me plz.  Use the [RAII](https://en.wikipedia.org/wiki/Resource_acquisition_is_initialization) idiom, e.g., to help prevent memory leaks.

RFC about ccutil/raiileptonica.h?

(2017-05-18 Heavily edited down.) Code freeze.

To review the latest commit, start with ccutil/raiileptonica.h; the other files can then be considered independently of each other. If there are no global issues, I can still divide up the latest commit (by directory, by file, ...but hopefully not by function!).

(Added) Hold on... renaming Ptr->Ref. :-)

(Added, edited) Which is better: `/*non-const*/ PixRef pix(...);` with `return pix.release();`, or `const PixRef pix(...);` with `return pixClone(pix.get();`? I'm leaning right, because const is better than non-const, but it has an extra `pixClone()`... and it suggests sharing semantics while `release()` is more like `std::move()`.

(Added) Which is better: `/*non-const*/` or `/*var*/`? Unfortunately, `const` was added to C/C++ as an afterthought, where it should have been the default. (Leaving the reader in limbo by omitting the comment impedes _instant_ comprehension and therefore seems inefficient and impolite to me.) Interesting proposal.

Here are a few things to consider with respect to the use of RAII with leptonica (I'm sure there are others, but I haven't thought much about this):

* does tesseract already use safe or shared ptrs, and if so, how does this proposed implementation fit with that; or if tesseract does not, would RAII be extended to all allocated data?

* leptonica is a C library with relatively little use of const (pretty much just for c strings).  An application that uses a lot of const leptonica variables will be very messy.

* leptonica uses ref counting clones to simplify resource ownership and make it easier for the developer to avoid memory leaks and double frees.  Clones are not thread safe; there's no locking in leptonica.  Would RAII change that?

* do the methods proposed here for exception handling clean up memory, or would they leak and therefore you have to crash the program?  (Does tesseract have exit calls on error?) >does tesseract already use safe or shared ptrs

It uses C++11's `unique_ptr` in the new lstm code.
C++11's `shared_ptr` is not used.

Old code does not use RAII.

>how does this proposed implementation fit with that; 

It uses `unique_ptr` with custom deleter that automatically calls pixDestroy() when the scope ends.

>would RAII be extended to all allocated data?

That's what we wish to do.
 Regarding Dan's points, in the same order, and with `Pix` standing in for any leptonica type:
* See Amit's answer. I've only applied the types in local scope, so none of the function/procedure signatures have changed, let alone the public API. Interestingly, you could also apply RAII to `FILE`, although that raises the issue of error handling when writing. BTW, currently Tesseract very rarely evaluates the value returned by `fclose()`, even when writing!
* The `const` only applies to the `PixRef`, not to the referent. So it's like `Pix* const pix`, not `const Pix* pix`.
* `PixRef` merely calls `pixDestroy()` at the appropriate time, nothing more. None of C++'s smart pointers make their _referents_ thread-safe. You can't even reliably change a `unique_ptr` or a `shared_ptr` _smart-pointer instance_ while another thread could be using or changing it. The only thing you know is that `shared_ptr`'s underlying reference count handling is thread-safe. BTW, a `PixRef` would manage just a single reference count, because `boost::intrusive_ptr`, which would also call `pixClone()` at the appropriate time (not possible for, e.g., `Pixa`) would be... too intrusive (Tesseract does not yet use that library), and neither it nor `std::shared_ptr` would be very useful for local-only usage.
* So far it only lightens the mental burden of guarding the exits of the functions/procedures (unfortunately I only found 1 leak for leptonica types), and it makes the code a bit shorter (at the expense of having to use `get()` a lot). This is low-hanging fruit, exception safety would require a lot more concerted effort. There was an issue #529 recently with `exit()` and a static variable that was destroyed while a non-static variable was still holding references to it, causing the static variable's destructor to complain... so even `exit()` has problems, in C++ at least. :-)

(Edited) "These types merely call"->"`PixRef` merely calls", "from another thread without locking said instance"->"while another thread could be using or changing it", removed repetitive "so far" @Raf

Thank you very much for your clear and thorough explanation of my questions!

I was also glad you found that "unfortunately" there are essentially no memory corruption/leak issues from leptonica usage in tesseract, even though nearly everything happens on the heap  ;-) Ah, but I only looked at local usage, and I did actually "wonder" whether using a `PixRef** pix` parameter without looking at the current value of `*pix`, as happens often in Tesseract, was always a responsible thing to do: I would require it to always be NULL as a precondition (with a check or at least a diagnostic), or always `pixDestroy()` a non-NULL value as part of the contract.

So the idea of my (off-line) query was to make you aware of a proposed set of C++ types to help manage those references, perhaps even to standardise them as part of leptonica++, so to say (an add-on, not a replacement). Any thoughts there, about the names perhaps (I thought PixRef would better fit the limited responsibility than PixPtr)? It would also be easy enough to _derive_ `PixPtr` from `std::unique_ptr<Pix>`, and give it an extra function to allow `pix.p()` with the same meaning as `pix.get()`, saving two characters each time and not letting the raw-pointer access function tail visually wag the variable dog, which together might otherwise get annoying to the point that people reject the idea of using a smart pointer, and I actually think it was a bad decision to make it that _difficult_ to access the raw-pointer value.

(Was initially incomplete, now fixed.) Prefer const + clone() to non-const + release(). The rules may be "simple", but this is C++, so we should expect to be able to program at a higher level of abstraction than C allows, and leave matters of ownership and guarding all the exits (mostly) behind us, even if there are still too many problems left to achieve exception safety.

I do remember the example you're talking about, in baseapi.cpp, which looked particularly weird to me because it would first sort of _abandon_ `lbox` (`L_INSERT`)... and then still `L_CLONE` it further down, so that was sort of a surprise. This is probably straightforward enough if you are familiar with the function `boxaAddBox()` where the `L_INSERT` occurred (assumedly the instance gets added to a container as-is, and not, e.g., serialised and destroyed), but it _feels_ wrong because it forces you to still think at that level. In my replacement, the `BoxRef` keeps the object alive throughout its scope (until the eventual `~BoxRef()`), whatever else happens, and in the meantime it can be `L_CLONE`d an arbitrary number of times. Strictly speaking, there are 2 more reference-count manipulations (one for `L_CLONE` instead of `L_INSERT`, then one for `boxDestroy()` inside `~BoxRef()`), but I think you have to strip the program of all functionality before that becomes noticeable. The story with `pix` is even simpler.

A `PixRef` just manages one reference count, whether it's from copying or cloning: the constructor takes over one reference, and the destructor destroys it. See for example `const PixRef word_in_xheight(pixCopy(NULL, pix));` in devanagari_processing.cpp... well, the other occurrences are all with `reset()`.

(Edited) "feels"->_feels_, are [->all] with >(Edited) "feels"->feels, are [->all] with

@rfschtkt, you don't have to add notes after fixing typos / grammar mistakes.
Just fix it :-)
 Don't get me wrong.  Lots of C++ users of leptonica prefer to use them with scoped ptrs, and I think that's fine.  Chacun à son goût.

I did wonder about the CLONE vs COPY case for adding a pix to a pixa, for example.  If you use the CLONE and later change the pix, the version in the pixa is also changed.  So sometimes you'd prefer to use a COPY, which gives you two instances of the image.  The copy cannot be wrapped with a scoped ptr, because it's made internally in pixaAddPix(), but it probably doesn't matter because that pix will be destroyed when pixaDestroy() is called.

Does this also work when you INSERT a PixRef->p() into a pixa?  (i.e., how does the scoped ptr handle know that it has transferred ownership to the pixa?  Do you have to do an explicit reset?) _Not_ paragraph by paragraph:

It's just a reference, i.e., a notch in the `refcount` (that's why I renamed it `PixRef`). Use `pixref.p()` like `pixpointer`, `pixClone(pixref.p())` or (equivalently) `pixref.clone()` like `pixClone(pixpointer)`, and `pixref.release()` like `pixpointer` later followed by `pixpointer = NULL;` (typically omitted, of course).

You could equivalently do `pixaAddPix(pixa.p(), pix.p(), L_CLONE);` or `pixaAddPix(pixa.p(), pix.clone(), L_INSERT);`, or, if you aren't using `pix` afterwards, `pixaAddPix(pixa.p(), pix.release(), L_INSERT);`, but I would avoid the latter (no `const PixRef`) and prefer the first over the second (shorter, doesn't needlessly use extra feature `clone()`).

The `PixRef` doesn't "know" what happened with the pointer you got from `p()`, so if you are granting/releasing ownership you must use `clone()`/`release()` instead (again, I would prefer a `const PixRef` and cloning, just because we can, because it's reference-counted, no unique ownership implied); "explicit" `reset()` after `p()` would be incorrect because the `PixRef` would call `pixDestroy()` on the old value.

(Added) I think the correct expression is "À chacun son goût.", but that's probably a lost battle.

(Added) Well, maybe if the scope is short, `release()` could also be used, but for a longer scope I prefer to know in advance whether something is a value or a variable, so to say.

(Edited) [[-> (typically omitted, of course)]], [[The [pointer->`PixRef`] doesn't "know" what happened with the pointer you got from `p()`, so if you are [explicitly->] [transferring->granting/releasing] ownership you must use [->`clone()`/]`release()` instead]], [[just->"explicit"]] :-P Just keeping myself honest... Hmm, should it be `clone()`, or `detach()`? They would have the same effect, but the former is clearer if you're more familiar with leptonica, and the latter if you're more familiar with `boost::intrusive_ptr`. If you would want to also add, e.g., `copy()`, then the obvious choice is `clone()`, but I don't think that it would be beneficial to go down that road.

(Added) Why is there no `boxaClone()`, even though there is a `Boxa::refcount` field (which seems to be used by `boxaCreate()` and `boxaDestroy()`)?

(Added) On the other hand, `intrusive_ptr` has a _non-explicit_ constructor that by default _doesn't_ consume its argument (unless there's a second argument `false`), so maybe taking it as a model would be more confusing than beneficial... :-)

(Added) So basically the last 3 commits are tentative, just exploring some possibilities. OK, let's get this done, because _RAII is awesome!_
* 1st Leptonica: `PixPtr` (you can't use -> with a "reference" in C++, dummy!) / `PixRef` (as in "one reference")?
* 2nd Leptonica: yes (far less visual dog wagging) / no (straight-up `unique_ptr`)?
* 3rd Leptonica (only if 2nd, I suppose): yes (more `const`) / no (straight-up `unique_ptr`)? if the former: `detach()` (like boost) / `clone()` (Leptonica-specific)?
* 4th Leptonica (only if 3rd, and only if `detach()`, I suppose): yes (more `const`) / no (lame!)?

(My current preferences are weakly or strongly on the left, so not exactly the current code.)

Once the design is fixed, I should probably collapse 1+2 and 3+4, or 1+2+3+4, and then maybe split them up again by directory, or something else.

(And to think I was actually just looking at the code to find out how to maybe get Tesseract to avoid recognising dotted lines as extra characters...) OK, I'm confused, but you should really be having this conversation with tesseract maintainers and developers, and in particular with Ray Smith.  Leptonica isn't going to change (e.g., into a C++ library).

To clone a boxa, use boxaCopy(..., L_CLONE)

As for the const issue, as mentioned before, leptonica doesn't use const as part of the function contract except for char* names (e.g., file paths).  Therefore, using const leptonica data in tesseract will be very ugly with all the const-removing reinterpret_cast<...> stuff
 "OK, I'm confused"
Then I have failed miserably... :-(

"Leptonica isn't going to change (e.g., into a C++ library)."
Smart pointers can be used with unchanged C code, no active cooperation required.

"To clone a boxa, use boxaCopy(..., L_CLONE)"
Ah so... but it still seems easier to just directly manipulate `refcount` for all types, as an orthogonal implementation of `detach()`.

I think I already mentioned that the `const` is about the pointer, not the referent: it's a const pointer, not a pointer to const. BTW, in C++, if you want to change a type that's declared `const`, use `const_cast`, not `reinterpret_cast`, which is not even allowed to remove `const`.

(Edited) 1st sentence of 4th paragraph I agree with everything, except perhaps blame for my confusion ...  :-)

Don't know how much benefit you get from enforcing constancy of the pointer, which typically only changes if it's "in-place" with a free and a heap allocation.  These are very infrequent; e.g., pixTransferAllData() and pixSwapAndDestroy(). It's a zen thing, it achieves stillness... (I don't know what I'm talking about.)

More prosaically, you can probably grasp code far quicker if you can instantly distinguish between values and variables. If you see `const`, you know you wouldn't have overlooked `pix.reset(pixConvertTo8(pix.p(), false));` somewhere between the definition of `pix` at the top of the function and its use half a page lower, because the compiler already checked that for you. So why not use it wherever you can? And that's even before potential concurrency, where invariability _really_ shines, and where `const` becomes even more valuable (pun not intended)!

Unfortunately, in C/C++, `const` was an afterthought, with a (5+1)-character handicap for values, unlike, e.g., Scala's `val`/`var` equal start. That's why I compensate or overcompensate by documenting variables, preferably providing a rationale. Those `/*non-const*/` comments look ugly to me and make the code less readable. You mean `std::unique_ptr</*non-const*/ T>`? Yeah, that gets unwieldy.

Maybe I can do better:
```
$ grep 'UPC\|UPNC' api/baseapi.cpp
template<typename T> using UPNC = std::unique_ptr</*non-const*/ T>;
template<typename T> using UPC  = std::unique_ptr<      const   T>;
  /*used with reset()*/ UPNC<PageIterator> page_it(GetIterator());
    if (! UPC<PageIterator>(AnalyseLayout())) {
  const UPNC<ResultIterator> it(GetIterator());
    const UPC<char[]> para_text(it->GetUTF8Text(RIL_PARA));
  const UPNC<ResultIterator> res_it(GetIterator());
      const UPC<char[]> grapheme(res_it->GetUTF8Text(RIL_SYMBOL));
  const UPNC<ResultIterator> res_it(GetIterator());
      tsv_str += UPC<char[]>(res_it->GetUTF8Text(RIL_SYMBOL)).get();
      const UPNC<char[]> text(it->GetUTF8Text(RIL_SYMBOL));
  const UPC<char[]> text(GetUTF8Text());
  const UPC<PageIterator> it(AnalyseLayout());
$ 
```

(Edited) `*`->`api`, `UPC` whitespace alignment  >\+  \/*used with reset()\*/ std::unique_ptr<\/*non-const\*/ PageIterator> page_it(GetIterator());

Here you started a line of code with a comment. This makes my brain read the whole line as a comment. You also implanted a comment in the middle of line, which makes it even worst.

IMO, comments should be put before code block or at the end of line. but not at line's start or in the middle of line. Then you should re-train your brain, because only `//` does that.

Also, syntax highlighting is not frivolous. Use an editor that supports it!

(Added) Oh well, it might as well be omitted. I would always wonder whether `const` is missing for a reason, but I guess that's just me... Any other general impediment(s) before I re-stage this (once!) for detailed review and merge? Or is it OK after a change back to PixPtr (instead of PixRef) and removing those non-const-related comments? Anything related to "TODO"?

(Edited) re-educate->re-train to make it rhyme :-) Eliminated even more *Destroy() calls, squashed commits for "RAII: Leptonica types".

If you like to have 159 fewer lines of code (~~after~~before the addition of ccutil/raiileptonica.h), please review now, otherwise I'll probably just close this by the end of the month.

(Edited)

(2017-05-30 Added) TODO: member variables?

(2017-05-31 Added) Interesting problem with that (think baseapi.h -> thresholder.h -> `ImageThresholder::pix_`): how do you isolate a header file from leptonica's/Leptonica's (which?) "allheaders.h" (BTW, why not "leptonica.h"?! imagine if all libraries used "allheaders.h"!)? People do all kinds of altogether harmful things to limit the amount of included code and/or isolate from possible changes (less relevant here), like using forward declarations (if you misspell anything or there's a change, you won't know until link time) and the pimpl idiom (not only are you responsible for all the boilerplate to hook it up, but you pay for it forever with runtime overhead). But what when it gets to a `unique_ptr` with a custom deleter? The compiler inevitably has to know the internal layout of the deleter to know the size of the `unique_ptr` (if the deleter has state, it is kept in the `unique_ptr` instance, not at arm's length as with `shared_ptr`... right?). Surely the client shouldn't have to forward-and-a-half-declare the deleter... You probably need two headers: one for forward declarations, and one normal header (or one header that can wear two hats, guided by a macro). Time for some modernisation of the legacy `#include` mechanism! Do [modules](http://clang.llvm.org/docs/Modules.html) address this?

(2017-06-03 Added) Current tally for Leptonica-related commits: 169 fewer lines (before the addition of ccutil/raiileptonica_forward.h and ccutil/raiileptonica.h).  I followed the steps in https://github.com/tesseract-ocr/tesseract/wiki/Compiling#linux
I downloaded from https://github.com/tesseract-ocr/tesseract zip file.

OS: Centos 7
Compiler: gcc version 4.8.5 20150623 (Red Hat 4.8.5-4) (GCC)

I found error written so I installed autoconf-archive and in order to resolve error with "Leptonica 1.74" I have done:

export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig
export LIBLEPT_HEADERSDIR=/usr/local/include
export TESSDATA_PREFIX='/usr/local/share/'

./configure --with-extra-includes=/usr/local/include --with-extra-libraries=/usr/local/lib
LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make

but I receive this error:

In file included from rect.h:28:0,
from coutln.h:26,
from stepblob.h:23,
from werd.h:28,
from blobbox.h:25,
from blobbox.cpp:25:
blobbox.h: In member function 'void TO_BLOCK::print_rows()':
blobbox.h:737:61: error: expected ')' before 'PRId32'
tprintf("Row range (%g,%g), para_c=%g, blobcount=%" PRId32 "\n",
^
../ccutil/tprintf.h:31:39: note: in definition of macro 'tprintf'
#define tprintf(...) tprintf_internal(VA_ARGS)
^
make[2]: *** [blobbox.lo] Error 1
make[2]: Leaving directory /home/webuser/src/tesseract-4.0/ccstruct' make[1]: *** [all-recursive] Error 1 make[1]: Leaving directory/home/webuser/src/tesseract-4.0'
make: *** [all] Error 2

Can you help me?
thanks Seems to be related to this change:
https://github.com/tesseract-ocr/tesseract/pull/905/commits/ef1d9600b1#diff-f65400671330df624f228888e8ee46ba I follow your actual advice, I restart then I done:

git clone https://github.com/tesseract-ocr/tesseract.git
cd tesseract
./autogen.sh

export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig
export LIBLEPT_HEADERSDIR=/usr/local/include
export TESSDATA_PREFIX='/usr/local/share/'

./configure --with-extra-includes=/usr/local/include --with-extra-libraries=/usr/local/lib

LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make

I obtain:

In file included from rect.h:28:0,
                 from coutln.h:26,
                 from stepblob.h:23,
                 from werd.h:28,
                 from blobbox.h:25,
                 from blobbox.cpp:25:
blobbox.h: In member function 'void TO_BLOCK::print_rows()':
blobbox.h:737:61: error: expected ')' before 'PRId32'
         tprintf("Row range (%g,%g), para_c=%g, blobcount=%" PRId32 "\n",
                                                             ^
../ccutil/tprintf.h:31:39: note: in definition of macro 'tprintf'
 #define tprintf(...) tprintf_internal(__VA_ARGS__)
                                       ^
make[2]: *** [blobbox.lo] Error 1
make[2]: Leaving directory `/home/webuser/src/tesseract/ccstruct'
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `/home/webuser/src/tesseract'
make: *** [all] Error 2

thanks  I installed tesseract 3.05 (because other version previous one the 3.05 I don't find) and all it's ok, but so isn't the version 4.0 ready?
thanks 4.0 can be compiled without an error by the continuous integration tests, in several of my test environments and by other people, too. So we need your help to find what is special in your case.

Could you have a look at the file `ccstruct/.deps/blobbox.Plo`? It must include an entry `/usr/include/inttypes.h`. That file defines the `PRId32` macro.

Try also a simplified build like this:

    git clone https://github.com/tesseract-ocr/tesseract.git
    cd tesseract
    ./autogen.sh
    export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig
    ./configure
    make
 From checking for similar error messages it appears that CentOS 7 and a few other versions of CentOS only define the PRId32 macro when the macro `#define __STDC_FORMAT_MACROS 1` is set. @oscaroxy, check if manually passing this via `CPPFLAGS='-D__STDC_FORMAT_MACROS=1'` resolves the issue.

It's not clear to me where Tesseract actually includes <inttypes.h>, so define it globally as a test.

Discussion of this issue in other projects:
https://groups.google.com/a/chromium.org/forum/#!topic/chromium-reviews/FyaFYXyzZeU

https://stackoverflow.com/questions/8132399/how-to-printf-uint64-t-fails-with-spurious-trailing-in-format/8132440#8132440 stweil, I done more, that is:

git clone https://github.com/tesseract-ocr/tesseract.git
cd tesseract
./autogen.sh
./configure

export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig
export LIBLEPT_HEADERSDIR=/usr/local/include
export TESSDATA_PREFIX='/usr/local/share/'

LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make

but nothing... same error: 

In file included from rect.h:28:0,
                 from coutln.h:26,
                 from stepblob.h:23,
                 from werd.h:28,
                 from blobbox.h:25,
                 from blobbox.cpp:25:
blobbox.h: In member function 'void TO_BLOCK::print_rows()':
blobbox.h:737:61: error: expected ')' before 'PRId32'
         tprintf("Row range (%g,%g), para_c=%g, blobcount=%" PRId32 "\n",
                                                             ^
../ccutil/tprintf.h:31:39: note: in definition of macro 'tprintf'
 #define tprintf(...) tprintf_internal(__VA_ARGS__)
                                       ^
make[2]: *** [blobbox.lo] Error 1
make[2]: Leaving directory `/home/webuser/src/tesseract/ccstruct'
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `/home/webuser/src/tesseract'
make: *** [all] Error 2 I'm sorry Mr. jbarlow83, I didn't understand your advice, I don't know What to do, where do I pass CPPFLAGS='-D__STDC_FORMAT_MACROS=1' ?
Where do I see where Centos 7 set "#define __STDC_FORMAT_MACROS 1"?
thanks Try this:

    git clone https://github.com/tesseract-ocr/tesseract.git
    cd tesseract
    ./autogen.sh
    export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig
    ./configure CXXFLAGS="-D__STDC_FORMAT_MACROS=1"
    make
 I follow your step and replace "make" with LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make.

anything is to right, now I've (tesseract -v):

tesseract 4.00.00alpha
 leptonica-1.74.1
  libjpeg 6b (libjpeg-turbo 1.2.90) : libpng 1.5.13 : libtiff 4.0.5 : zlib 1.2.7

 Found AVX
 Found SSE

Only in order to understand, is the param CXXFLAGS="-D__STDC_FORMAT_MACROS=1" local to configure tesseract? do it don't interact with other config, right?
thanks

 We have two options:
1) Fix this issue (only relevant when the system glibc < 2.18)
2) Document the solution with the environment variable. I'd fix the issue by always setting `__STDC_FORMAT_MACROS` (that won't harm for newer glibc).

For the future, the format macros (also `REFFORMAT`) could be avoided by using C++ code instead of C format strings. Would including `cinttypes` instead of `inttypes.h` also fix the problem? In fact:
#ldd --version
ldd (GNU libc) 2.17

I resolve with __STDC_FORMAT_MACROS, but if I update glib, is it better?

Excuse me, stweil, but you haven't reply my question... thanks
"Only in order to understand, is the param CXXFLAGS="-D__STDC_FORMAT_MACROS=1" local to configure tesseract? do it don't interact with other config, right?" How do I include cinttypes? where do I find this file? where I put this file?
thanks > do it don't interact with other config, right?

Right.

> How do I include cinttypes?

Change file `ccutil/host.h` and replace the text `inttypes.h` by `cinttypes`. Done, the replace work fine. Which is the better solution?
__STDC_FORMAT_MACROS in configure or the replace?

do the 2 solution change something in the ocr by tesseract?
thanks

 >do the 2 solution change something in the ocr by tesseract?

No. > Done, the replace work fine. Which is the better solution?
__STDC_FORMAT_MACROS in configure or the replace?

I think using `cinttypes` is the better solution for C++ code like it is used in Tesseract.
Done in pull request #927. I prepared definitions of Docker containers and scripts that helps to compile and run Tesseract 4, take look at this: https://github.com/tesseract-shadow/tesseract-ocr-compilation  This error case results in fout_ == nullptr.
Closing a nullptr file is not allowed.

Signed-off-by: Stefan Weil <sw@weilnetz.de> The problem was reported as part of issue #529.  Was it solved? No, this is still an issue. `./configure && make distclean` fails in the source root directory. @Shreeshrii, now you can close this issue. It was fixed with PR #968 for the master branch and PR #971 for 3.05.  but allow failures

currently failing all this does it show you that the patches that are used in `brew` to build tesseract from source aren't up to date.

the long build time looks like an anomaly, try killing the travis process and restart it That new test now [passes without errors](https://travis-ci.org/tesseract-ocr/tesseract/jobs/233010095) (the brew formula for tesseract was fixed). Nevertheless building Tesseract with brew takes some time, so this test adds about half an hour to the Travis test time for each pull request or update of a branch. I‌ wonder whether that's reasonable.

> try killing the travis process and restart it

That won't help, because it takes that time to build Tesseract and all of its prerequisites.  When Tesseract terminates by calling the exit function,
the destructor of any local auto variable is not called.

Fix two cases by using static variables.

Signed-off-by: Stefan Weil <sw@weilnetz.de> Maybe we should use return instead of exit() Tesseract code includes more than 70 calls of `exit()`. Using `return` is a lot of work, even in `main()` (I already tried it). And static variables also reduce the stack frame size. I know someone who will be happy. :-) Yes, that sounds like the correct solution for C++ code. but not in Google projects... The 2nd commit fixes issue #529. Now Valgrind is happy, too:

    LEAK SUMMARY:
       definitely lost: 0 bytes in 0 blocks
       indirectly lost: 0 bytes in 0 blocks
         possibly lost: 0 bytes in 0 blocks
       still reachable: 8 bytes in 1 blocks
            suppressed: 0 bytes in 0 blocks
    
    ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
    ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
 You must be kidding...  This requires libminizip-dev, so expect failures from CI.

Up to now, little endian tesseract works with the new zip format.

More work is needed for training tools and big endian support and also to maintain
compatibility with the current proprietary format.

Signed-off-by: Stefan Weil <sw@weilnetz.de> Open questions:

- Do we want a new format? As I'm not the first one who had the idea, I think the answer is yes.
- Do we need support for both old (current) and new format? I'd drop support for the old format
  and remove `combine_tessdata`.
- Should the `traineddata` files in the new format add `.zip` to the file names? I'd omit `.zip`.
- Should the code for minizip be added to the Tesseract sources, or should we add an external dependency to libminizip-dev?
- Which one is better, zip or compressed tar? `libminizip-dev` was added in Ubuntu Xenial (16.04), so the current Travis build environment which is based on Ubuntu Trusty does not provide it. On my Debian system I find these libraries: [`minizip`](https://github.com/madler/zlib/tree/master/contrib/minizip) (supported since 16.04), [`libzip`](https://nih.at/libzip/) (supported since 12.04), [`zzlib`](http://zziplib.sourceforge.net/zzip-file.html) (supported since 12.04), [`libarchive`](https://github.com/libarchive/libarchive)  (supported since 12.04). As far as I know all use licenses which are compatible with Tesseract. I assume any of those can be used and expect that none of them will be available as a binary for Windows (maybe also not for macOS), but I did not have a look. Zip format reduces `eng.traineddata` from about 31 MiB to 16 MiB (48 % compression) by default. `zip -9` improves the compression to 49 %. Other compressed formats achieve even better compression values:

    31887360 eng.traineddata.tar
    31873501 eng.traineddata
    18121906 eng.traineddata.lz4
    16461487 eng.traineddata.zip (default)
    16372645 eng.traineddata.zip (maximum compression)
    15193532 eng.traineddata.tar.bz2
    13274164 eng.traineddata.tar.xz
    13273173 eng.traineddata.7z

    75100160 mya.traineddata.tar
    75085274 mya.traineddata
    42274775 mya.traineddata.lz4
    39468033 mya.traineddata.tar.bz2
    36296750 mya.traineddata.tar.gz
    36075469 mya.traineddata.zip
    28097639 mya.traineddata.7z
    27937332 mya.traineddata.tar.xz
 > Please move discussion to tesseract-dev forum. This is significant change.

See [this discussion](https://groups.google.com/forum/?hl=en#!searchin/tesseract-dev/zip|sort:date/tesseract-dev/U5HSugUeeeI) in the forum. I added a link to GitHub there. > libarchive handles all formats

It is also supported by current Linux distributions and would be interesting if compressed tar instead of zip is preferred. I added it to my previous post. > What about lz4?

It does not compress very good (see result added to the list above). Rebased and added support for `libzip`. This is experimental code, as there is still no decision whether compressed archives should be supported at all, if yes with which format and which library.

The current code uses `libzip`, if that is not found `minizip`. If neither of those is found, it uses the normal code. I prepared the code for more experiments to support compressed tar archives with `libarchive` for example. As you can see [here](https://github.com/tesseract-ocr/tesseract/pull/911/files#diff-4ec9988bbd350d92539e7ee9a30a2f91R48), the implementations for the two currently supported libraries are very similar. The latest code also supports `libarchive` (highest priority). With that library, all kinds of compressed archives should work (up to now I tested with zip only). As `libarchive` indeed supports all formats, I could compare the time needed for each format. Tesseract was run 5 times on each format with English on a simple hello world text. Below is the result sorted by time in seconds for each test. Interpretation:

- The original Tesseract format, uncompressed tar and lz4 tar are similar and fastest.
- zip needs about 150 ms more time than the original Tesseract format.
- 7z and xz tar need about 850 ms more time than the original Tesseract format.
- bz2 tar is slowest and needs about 1450 ms more time than the original Tesseract format.

The file i/o from disk did not play a role in this test because of the Linux file cache and the SSD of my computer.

      0.13 eng.traineddata.tar
      0.14 eng.traineddata
      0.14 eng.traineddata.tar
      0.14 eng.traineddata.tar
      0.14 eng.traineddata.tar
      0.15 eng.traineddata
      0.15 eng.traineddata.tar
      0.15 eng.traineddata.lz4
      0.16 eng.traineddata
      0.16 eng.traineddata
      0.17 eng.traineddata.lz4
      0.17 eng.traineddata.lz4
      0.18 eng.traineddata
      0.18 eng.traineddata.lz4
      0.22 eng.traineddata.lz4
      0.29 eng.traineddata.zip
      0.29 eng.traineddata.zip
      0.29 eng.traineddata.zip
      0.30 eng.traineddata.zip
      0.30 eng.traineddata.zip
      0.97 eng.traineddata.7z
      0.98 eng.traineddata.7z
      0.98 eng.traineddata.7z
      0.99 eng.traineddata.7z
      0.99 eng.traineddata.tar.xz
      0.99 eng.traineddata.tar.xz
      1.00 eng.traineddata.tar.xz
      1.00 eng.traineddata.tar.xz
      1.00 eng.traineddata.tar.xz
      1.04 eng.traineddata.7z
      1.55 eng.traineddata.tar.bz2
      1.56 eng.traineddata.tar.bz2
      1.61 eng.traineddata.tar.bz2
      1.62 eng.traineddata.tar.bz2
      1.66 eng.traineddata.tar.bz2
 Test results with `libarchive` for `mya.traineddata` (the largest of all `traineddata` files). I did not test lz4, but added a test with gz format.

    0.48 mya.traineddata.tar
    0.49 mya.traineddata
    0.49 mya.traineddata.tar
    0.49 mya.traineddata.tar
    0.49 mya.traineddata.tar
    0.50 mya.traineddata
    0.52 mya.traineddata
    0.52 mya.traineddata.tar
    0.54 mya.traineddata
    0.54 mya.traineddata
    0.79 mya.traineddata.tar.gz
    0.80 mya.traineddata.tar.gz
    0.80 mya.traineddata.tar.gz
    0.82 mya.traineddata.zip
    0.84 mya.traineddata.zip
    0.85 mya.traineddata.zip
    0.86 mya.traineddata.tar.gz
    0.86 mya.traineddata.zip
    0.88 mya.traineddata.tar.gz
    0.90 mya.traineddata.zip
    2.38 mya.traineddata.7z
    2.38 mya.traineddata.7z
    2.38 mya.traineddata.tar.xz
    2.40 mya.traineddata.7z
    2.41 mya.traineddata.tar.xz
    2.45 mya.traineddata.7z
    2.45 mya.traineddata.tar.xz
    2.46 mya.traineddata.7z
    2.46 mya.traineddata.tar.xz
    2.49 mya.traineddata.tar.xz
    3.69 mya.traineddata.tar.bz2
    3.74 mya.traineddata.tar.bz2
    3.75 mya.traineddata.tar.bz2
    3.79 mya.traineddata.tar.bz2
    3.84 mya.traineddata.tar.bz2

`libzip` gives similar results, but only supports the zip format:

    0.83 mya.traineddata.zip
    0.84 mya.traineddata.zip
    0.87 mya.traineddata.zip
    0.88 mya.traineddata.zip
    0.93 mya.traineddata.zip

`libminizip`:

    0.84 mya.traineddata.zip
    0.84 mya.traineddata.zip
    0.85 mya.traineddata.zip
    0.87 mya.traineddata.zip
    0.92 mya.traineddata.zip

`libzzip`:

    0.75 mya.traineddata.zip
    0.78 mya.traineddata.zip
    0.78 mya.traineddata.zip
    0.79 mya.traineddata.zip
    0.84 mya.traineddata.zip
 lzma created the xz files. 7zip and lzma gave the best compression ratios, but both also need some time for the decompression (which is relevant for Tesseract): they need about 1.9 s more time (but still are faster than bz2).

Please note that the current code for all formats reads all parts of the `tessdata` file, no matter whether they are used or not, so the decompression overhead could be reduced. The current Tesseract code reads the whole `tessdata` file into memory and gets all data from memory. My implementation for compressed archive files does that, too. Therefore random access is trivial: all component files are in a vector of byte arrays. Why zip not tar? Maybe because zip is supported on Windows by default, while tar and other formats need additional installations? I use 7-Zip on Windows to compress and decompress files. See also https://en.wikipedia.org/wiki/Comparison_of_file_archivers. > I have no objection to switching to zip (with no tar) for the tessdata files. That should be usable by everybody more easily.

On Windows, that would require a rename with `.zip`extension, or the installer must register `.traineddata` as a zipped data type. Otherwise the Windows explorer won't decompress such files easily. Personally I prefer to keep the `.traineddata` extension even for zip files (like Java does it with its `.jar` extension). Now I added implementation and timing results for zziplib. It looks like this is the fasted code for reading zipped `traineddata` files. > combine_tessdata is used for extracting components, replacing some, etc.
Probably first step can be a zippeddata file which after unzipping provides the traineddata.

Zipping a tessdata file means extracting the components from that file and writing a zip archive file which includes those components. So combine_tessdata can be replaced by your favorite zip / unzip program. We are talking about 2: files in zip archive format which include compressed components.

Such files can be written and read by all common operating systems. Linux file explorers are clever and know how to handle such files even if they are named `eng.traineddata`. The Windows explorer is not clever. It expects a know file extension. So if users want to see what is inside of `eng.traineddata` and use the Windows explorer as a GUI replacement for `combine_tessdata`, I must set a Windows registry key which tells the file explorer that the `traineddata` extension is handled like `zip`. > This would help us to have installation of 3.05 and 4.00 at the same time and to avoid mistakes like using combine_tessdata on compressed data.

Currently `combine_tessdata` crashes when it is tried with a compressed archive. It can be made more robust to simply fail with such data, or it could report if it gets a zipped archive (if we restrict to zip support). Such code can also be back ported to 3.05. I don't think that using the same `tessdata` directory for 3.05 and for 4.x is a good idea. Therefore I don't think that 4.x needs a different file extension for `tessdata` in zip format.

Platform support is good on Linux (minizip in latest distributions, libzip, libzzip and libarchive also in older ones), but macOS with brew should also support all four libraries (untested), and so does Cygwin with Mingw-w64 for Windows. I don't know the situation for Visual Studio, but expect that small libraries like `libzzip` for example are much easier to build than larger libraries with more functionality like `libarchive`. Then I suggest to use `libzzip` (sometimes also called `zziplib`) if zip support is sufficient because it looks like the fastest one, and it is also small.

`libarchive` is a good choice (the only one I know) if any common compressed archive format should be supported. > Would same extension cause confusion as to which version of traineddata file was being used?

Software can detect the format automatically. That can be added to 3.05, too, so that version would simply refuse to read files in the wrong format.

With a standard archive format (like zip), it would be easy to write additional information into the archive files, for example a README or a VERSION file. Tesseract would ignore any such component which it does not know. zziplib seems to be inactive for years.

https://sourceforge.net/projects/zziplib/?source=navbar
https://sourceforge.net/p/zziplib/svn/HEAD/tree/
https://sourceforge.net/projects/zziplib/files/zziplib13/
https://sourceforge.net/p/zziplib/patches/?source=navbar

Choosing more than one library and one format for compression will make maintenance more complicated. > zziplib seems to be inactive for years.

Then either it is a small and stable code, or it is unsupported for some reason.
Which library would you suggest? Check what other well known projects use.
For example, the Debian cmake package depends on zlib and libarchive. > zziplib seems to be inactive for years.

It was unmaintained for several years until some weeks ago. I found it maintained on [GitHub](https://github.com/gdraheim/zziplib). Speed is more important than disk space. That means LZ4 is probably the best candidate, as the English test indicated. It was designed for this sort of situation and is the tool of choice for e.g. Linux kernel and initramfs decompression on low memory devices.
https://lz4.github.io/lz4/#interoperable-lz4 > Speed is more important than disk space.

We are talking about typically less than 300 ms needed for large zip archives, so a Tesseract run with several languages would maybe run 1 s longer with zip archives. Is that too much when typically Tesseract runs for much more than 10 s?

Tesseract could be optimized by processing many image files in a single run. Then loading of `tessdata` files is needed only once. If a standard format is used for `traineddata`, we no longer can derive the data endianness from the file format. So either endianness information must be added somewhere in the archive (in the `config` component?), or all code must be changed to read and write a fixed endianness. I have a personal opinion on this issue, but in the end that's something @theraysmith must decide. @stweil My typical Tesseract workload is tens of thousands of images in a cloud. Combining disparate images into a multipage TIFF is a pain. My files come as PDFs anyway; it's a good format to normalize files to. Then I use my program ocrmypdf to split them into one page images and recombine. In short, I map-reduce Tesseract processes over single page images, with all the usual scaling and robustness benefits. A long running process that does a lot of work is expensive to have crash.

Since AWS compute time is per unit time, adding 1 second per Tesseract process would be something like a 1-2% increase in my bills, while decreasing storage would have no measurable savings because the incremental gain is small compared to the size of the operating system. (And most charge for a pool of storage rather than storage actually used.)

I do support the change, I just think LZ4 hits the sweet spot for this sort of problem. @jbarlow83, I did not mean using multipage TIFF images, but enhancing the Tesseract command line API to allow passing more than one image file. That should reduce the compute time for your use case already with the current `traineddata` file format. Another Benchmark:
https://github.com/powturbo/TurboBench >Tesseract could be optimized by processing many image files in a single run. Then loading of tessdata files is needed only once.

Actually, this feature is supported with 4.0/3.x. > Actually, this feature is supported with 4.0/3.x.

I did not know that. How would I start Tesseract to process page1.png and page2.png in a single run? Prepare a text file that has the path to each image:

```
path/to/1.png
path/to/2.png
path/to/3.tiff
```

Save it, and then give its name as input file to Tesseract.

`tesseract savedlist output` Thank you, good to know that. It looks like the ChangeLog, other documentation and the program help text need an update.

Currently all pages are written to one output file (per format). Some formats include page information (hOCR, PDF). Others like TXT don't, but could use a page separator character (ASCII 0x0C = FF). Would it help to support an output base parameter with placeholders like page number or image base name to generate one output file per input image? Maybe we should discuss the multi page feature in another issue.

I don't like mailing lists. Also Ray replies more in Github issues/PRs. 
What about opening a new repo on Github for dev discussions via issues? The multi-page feature was added in 2014 by commit 25a8c7b72006a11ba0b31dfd5210f7b9401eb27d. Guys, can you add checkboxes to the eng.traineddata? 

![6-1-2017 3-51-27 pm](https://cloud.githubusercontent.com/assets/26609019/26698052/4c0fa150-46e2-11e7-8f87-13bade4c0af5.png)
 I'd like to summarize the current status:

- A new format would be good, and there is a preference for the `zip` format.
- The new format would replace the old one for Tesseract 4 (no fallback necessary).
- We can keep the current names (*.traineddata). 3.05 won't load new format, 4.x won't load old format.
- `libarchive` seems to be the best choice to implement the `zip` format as it is widely available and supported.
- The `zip` format no longer includes an implicit indicator for the endianness of the trained data. A fixed endianness (little endian) for stored data does not look like a possible option for now, so an explicit endianness indicator must be added to the data in the config component.

Is there anything I missed or are there other opinions? If not, I'd implement the code and create a pull request. Rebased PR and fixed merge conflicts. @theraysmith commented:

 >Are we talking about
>...
>2. compressing the components of a file using zlib and changing
tessdatamanager to allow that. FIles are otherwise uncompressed.
>...
>?
>
>I thought we were talking about 2...

@stweil commented:

>We are talking about 2: files in zip archive format which include compressed components.

It seems to me that Stefan and Ray are thinking about two different ways to implement compression:

Stefan's way is to create one zip archive from the files in traineddata. 
combine_tessdata won't be needed anymore. The user will use an external program to compress and decompress the traineddata (zip) file. 
Stefan patch adds the ability to read (uncompress) the zip archive by TessdataManager.

Ray's way is to use the zlib library directly to compress individual files inside traineddata without creating a zip archive.
combine_tessdata will still be needed by the user.
 Thank you, Amit, for the clarification. Yes, I'd replace the proprietary `tessdata` format by the standard `zip` format. Users could still use `combine_tessdata` (it would support both old and new format), but they could also use any other program (for example the Windows file explorer which can handle zipped files) to create or expand the new tessdata files in zip format.

As there was a preference for using `libarchive`, there would even be more options because that library supports a whole range of compression and archive formats. Some of those formats compress the whole archive (typically a `tar` format) instead of compressing the single components. Ray seems to want just zlib without anything else.

We need an 'OK' from him to go in your way which depends on another library.  A wrong array index must raise an assertion instead of printing an
error message and continuing program execution.

Replace also floor by floorf which can be faster.

Signed-off-by: Stefan Weil <sw@weilnetz.de> Some random thoughts while waiting for my pull requests to be merged:

How about C++-style `static_cast<int>()` instead of C-style `(int)`? Since casting to integral types rounds toward 0, you can also omit the `floorf()` if `bottom` is known to be nonnegative... unless any overhead is known to be negligible or eliminated by the compiler anyway (probably not, unless the compiler can somehow deduce the sign of the value at compile time)? If you capture this in a macro or in an always-inlined function (has C++11 standardised that?), it doesn't even have to be explained every time.

It's also quite ad hoc: a separate issue, and only addressed locally. That's true. While looking closer on that code, I noticed that it can be more simplified. We don't need float operations here. I'll update the commit. Shree, Ray does his reviews **after** Zdenko merges PRs here. @stweil Hmm, I suspect that g++ kept -Wconversion out of -Wall/-Wextra because otherwise too much existing code would have to be adapted, not because not using casts for floating-integral conversions is necessarily a good idea... just my 2 cents. MS VC produces 1453 warnings for Tesseract (see results from Appveyor CI), most of them caused by data type conversions. It looks like most developers don't like fixing this kind of warning, and gcc simply supports that. :-) Should we make it less verbose there? No, I don't think so. We should make the release builds with configure / make more verbose (`gcc -Wall` is currently only used for debug builds).  Hey, i have been using tesseract for text extraction from images. But due to some unknown reasons, it is unable to extract text from some images even if the image is clean. I am unable to find the reason for this. Is there anything that i am missing in preprocessing?
original image:
![depot](https://cloud.githubusercontent.com/assets/20331292/25936270/625951fc-3640-11e7-9542-32636ed6126e.jpg)
Binarized image:
![depot 1 jpg-binarized](https://cloud.githubusercontent.com/assets/20331292/25936398/fbb85e7e-3640-11e7-86b5-e811f5593e0b.png)
  I never used a library as complicated as this one, I use Linux Java. Well I manage to make tess4j work, then copied all the source packages and libraries into my project, everything seemed fine but when I try running it I get the errors 
`Info in bmfCreate: Generating pixa of bitmap fonts from string
Error opening data file ./eng.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to your "tessdata" directory.
Failed loading language 'eng'
Tesseract couldn't load any languages!
#
# A fatal error has been detected by the Java Runtime Environment:
#
#  SIGSEGV (0xb) at pc=0x00007f7d7f292197, pid=24436, tid=0x00007f7db9f03700
#
# JRE version: Java(TM) SE Runtime Environment (8.0_131-b11) (build 1.8.0_131-b11)
# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.131-b11 mixed mode linux-amd64 compressed oops)
# Problematic frame:
# C  [libtesseract.so+0xc3197]  tesseract::Tesseract::recog_all_words(PAGE_RES*, ETEXT_DESC*, TBOX const*, char const*, int)+0x5e7
#
# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try "ulimit -c unlimited" before starting Java again
#
# An error report file with more information is saved as:
# /home/big-daddy/netbeansprojects/LicencePlateRecognition/hs_err_pid24436.log
#
# If you would like to submit a bug report, please visit:
#   http://bugreport.java.com/bugreport/crash.jsp
# The crash happened outside the Java Virtual Machine in native code.
# See problematic frame for where to report the bug.
#`

What I dont understand is why does Tess4j default project manage to load the language files whilst mine fails?

 It is set that's why the tess4j works in its default package before
importing it into my project
On May 11, 2017 10:04 AM, "Shreeshrii" <notifications@github.com> wrote:
>>
>> Please make sure the TESSDATA_PREFIX environment variable is set to your
"tessdata" directory.
>
> Please set this variable for tesseract to find the traineddata files.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub, or mute the thread.
  Use the [RAII](https://en.wikipedia.org/wiki/Resource_acquisition_is_initialization) idiom, e.g., to help prevent memory leaks. Build error: https://travis-ci.org/tesseract-ocr/tesseract/jobs/230329088#L290. Yes, I think it's a bug in that g++ version (4.8.4). I had successfully built with 5.4.0. I'll try again with an explicit move constructor... Are they all tested? I think that it was valid C++11, though.

Amended, pushed...

And again... Since you change the API, I think we need Ray's approval for this PR. If that's public API and cast in stone, maybe there should be two versions, with the backward-compatible version calling the safe version with release(). Or the leak could be fixed ad hoc, but that's not really progress.

(Added) Is the public API not tested?

(Added) I don't see any documentation mentioning `ccmain/resultiterator.h` as part of the API? Ah, apparently the result of `tesseract::TessBaseAPI::GetIterator ()`, that sounds very API-ish. I would start with fixing the leak with the current API.
~~If you want to do it, open a new PR.~~

Fixing a leak is still progress... Maybe tomorrow, but I would still suggest to add a new version and deprecate the current one, because this is C++, and RAII is one of C++'s most useful idioms (to put it mildly). That's why I made a new thread called `RAII`, not `lookifoundaleak`... Yes, but it can also return nullptr, and I hadn't yet figured out whether there's a difference with the empty string. Adding to a STRING is apparently the same for nullptr and empty string, but maybe not other applications. And there's at least one use of release() that would then instead have to make a new copy.

(Correction) I meant strdup() instead of strcpy(), but that's even more expensive because it needs two passes, so let's stick with "make a new copy".

(Added) virtual ResultIterator::GetUTF8Text() hides non-virtual LTRResultIterator::GetUTF8Text, that doesn't look great... Amended without API change, checks successful.
 LGTM. @stweil? I plan to run a test with Valgrind later (~ 1 day) and will add my review comment then. >but I would still suggest to add a new version and deprecate the current one, because this is C++, and RAII is one of C++'s most useful idioms (to put it mildly).

The new version of this PR uses RAII technique, without an API change :)
http://stackoverflow.com/questions/29372976/is-stdunique-ptr-an-application-of-raii  There seems to be another leak in `void POLY_BLOCK::fill(ScrollView* window, ScrollView::Color colour)`, which doesn't do `delete segments;`. But I've had enough fun for now...  >I've had enough fun for now...

:laughing:  Well, it seemed to be leaked, from comparing with other uses, although I'm not 100% certain... Rebased.  Important warnings warrant attention because they may indicate real problems.
Unimportant warnings warrant attention because they obscure the important warnings.

Unfortunately for me the nicest example of the former category, where I also immediately had a solution, was already fixed independently...

This replaces earlier attempts, now up to date, on its own branch, and with some revisions. >Warnings are people too!

I see that you changed the title this time... :-) I suggest to make smaller pull requests which focus on closely related problems. That would make reviewing and pulling them much easier. Example: Make a pull request for all changes related to `NumFeatureSets`.

For that example, the `decltype(CharDesc->NumFeatureSets) i` will work. Nevertheless I personally prefer the much simpler `uinT32 i`. Even better because we want to use POSIX instead of Tesseract data types: `uint32_t i`. You mean like the diminutive "Use POSIX data types and macros" with only 21 commits and 243 files changed?

Yeah, at first I thought `typedecl()` would be less unpopular than a public `GenericVector::unsigned_size()`, but I went a bit overboard with it, and I let the cat out of the bag with `STRING::unsigned_size()` anyway, so... I've amended the pull request without any `typedecl()`, with public `GenericVector::unsigned_size()`, but with `size_t` rather than `uintT32`/`uint32_t`. I don't expect that pull request #878 will be applied like that, but yes, it consists of smaller commits which cover limited modifications and which can be applied individually. Even individual #878 commits are _way_ bigger than this whole pull request (or at least the one I randomly picked). Feel free to split it up further as you like, but I don't see the point: it's already themed by kind of warning, and the larger of the two commits is only +32/−24. Rebased.

TODO: warnings from "make training" Warnings from "make training". Rebased.

The remedies were not always obvious, so comments welcome.  when i use tesseract with -l fas some time i get sequence error like follow:
 = ڤکڵ۱۴ـ۵ـکوقەگ|حهدسـ٥درمحموشۀكاحمورهپـوران ف
for this image
![20170506_133142](https://cloud.githubusercontent.com/assets/10100596/25782692/f4c2dfc4-3364-11e7-861a-f3da05d37dc3.jpg)

also this error occur in arabic language
how can i change configs or tessconfig to fix this bug? Hi,

what is the version of the tesseract and leptonica that you have used? 
i made detection on the image that you have shared and got the following results (disregard the numbers):
شکل کوشک احمد شاه در مجموعۀ کاخ موزۀ نیاوران
although the training was on the Arabic files not Farsi  orginal image:
![20170506_133142](https://cloud.githubusercontent.com/assets/10100596/25798783/c20f7ae0-33f7-11e7-978b-dd47a6c98b06.jpg)

please test this image.
 @Nigje 

this is the results

عکسهای دورۀ قاجار /
/ آثار نقاشی هنرمندان ایرانی
_ __ هنرهای .. .
__ مینیاتور و آثار خنرهای سنتی _

_ © © © روشهای تولید برف
_ سیر خطوط در ایران __
نقاشی و مینیاتور استاد فرشجیان

قالی، نقاشی، خط و آثار دورههای

ا ا

0 آثار باستانی و هنرهای تیوی ر ز
آثار دورۀ قاجار و پهلوی و هدایای بعضی کشورها .
_ تفاشی های دودۀ فاجار ر .

_ اشیا و تایلوهای اروپایی هدیه شده به دربار قاجار _
/ عکسهای دورۀ قاجار 5

آثار دورۀ پهلوی

 

هنری، تخصصی

" انواع گوناگون گل و گیاه

 

 

شکل کوشک احمد شاه در مجموعۀ کاخ موزۀ نیاوران

as you can see the detection is quite good but the problem is that, the column on the right wasn't detected, but the column on the left was detected, also the text below the house is detected as well I build tesseract with vs2015 and use api.

for build tesseract also i have built 
leptonica-1.74.1  [MSC v.1900 LIB Debug x64]
 libgif 4.1.6(?) 
 libjpeg 9a 
 libpng 1.6.29 
 libtiff 4.0.7 
 zlib 1.2.

i don't known what is problem !!?
 ​do you get any error?​
 Default PSM values:
API - 6
Command line - 3 @roozgar i got an error but i think its due to the picture itself, the message was: "image too small to scale"
not a detection error i think

i tired the detection one more time with the argument psm , seems both columns were detected, the accuracy seems good, since I'm detecting against Arabic lstmf files with fas.traineddata, but i got to ask, if what is the typical order for detecting a table, is it each row is been detected as a line?

@Shreeshrii i know about this issue, actually i was the one who mentioned that problem at the first place :)  @Nigje 

here are the new results, the full command was: tesseract farsi2.jpg results_farsi -l fas ./tessdata-dir ./tessdata  --oem 1  --psm 6

١
2 .
سران ل: ش ۰
ن عکس خانه عکس های دورۀ قاجار
س ار ن ٣8 ه ی | ن ر __ _ عاکكس نیا فوفۀ ا چا ر ی ا
8 هنرهای زیبا آثار نقاشی هنرمندان ایرانی ۱
سست 55555 نت. 05555
۲۶ __ خترهای بهای _ |. جت 7 - هنرهای تج بیار تی بوت ی س بت تی ت بی __
۲۷۲ . = اج پ س __ وارون هاو خر ر ر سس
۸ صنعت برق روشهای تولید برق .
سری سوت پ 7-72 دا خر صد سست س می ی س ۳۷ / 2 خ % ب- 7 ۷۰۰ [
| ۹ { میرعماد . | سیر خطوط در ایران
ست خس خ پ پیت پی تب رت رپ ت [ 5 5 سستی س . . س سست کر سات جت جم
ا ا نقاشی ومینیاتوراساد فرشچیان ا
و صاحبقرانیه قالی، نقاشی، خط و آثار دورههای
ا پهلوی وصفوی ا
۲ __ جهاننما _ ر ا. آثارباستانی و هنرهای تجسمی ر م ست |
۳ __ کاج احمدشاهی س ایر _ __ آر دورۀ فاجار و پهلوی و جدای نی کر ی |
۴ ! نگارخانه ١ نقاشیهای دورۀ قاجار 2
سس وت م و ٦٣٣٣ پپت ٣٣-00005005 آبا ت ک ب چ ت پیس ک پس ۰ سیب ا تست ی ی ب حی
۵ __ حخوضفانه __ اشیا و تابلوهای اروپایی هدیه شده به دربار آقا جار .
۳۶ | عکس خاند ت
س ر ا ری ر ر را ا _ - . س _ ت 7 را . سست . س ب ه ی ر صص
| س گی س ت ت س ب دس بی ا. ی ن ا یخ گی ی فا ر [
۸ | کاخ ملت آثار دورة بهار بی ١
شیک 5555___ 00055 ۱0055 س __ لوی تخصصی ا ا ا ی
١ ] ۴۰۰ [__ گیاهان داروی سنتی ا انواع گل و کبد ا
۱ 3 ۰و ات . ۰ % . ک ایا %
. ی ن کت حصر ا
شکل کوشک احمد شاه در مجموعۀ کاخ موزۀ نیاوران
۲
 @Nigje 
i never used the tesseract api on vs, i use the tesseract engine, the tesseract version that im using is tesseract 4.00alpha with leptonica 1.74.1, and its not possible for any version prior to 4.00alpha to detect Arabic, or Farsi or Urdu, as the new engine contains lstmf files which you can use on detection by adding the argument --oem 1 @ibr123 @roozgar @Shreeshrii @amitdo 
tanks for your comments, problem  resolved.

> tesseract.exe test.png test -l fas --oem 1 --psm 6

 --oem 1 forced tesseract to use only Lstm.  Hello,

First thanks for your job. I am trying to run tesseract 4 but I am getting an issue:

`
Info in bmfCreate: Generating pixa of bitmap fonts from string
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
Aborted (core dumped)
`

Step to reproduce (with a docker file):

	FROM ubuntu
	RUN apt-get update && apt-get install -y \
		autoconf \
		automake \
		libtool \
		autoconf-archive \
		pkg-config \
		libpng12-dev \
		libjpeg8-dev \
		libtiff5-dev \
		zlib1g-dev \ 
		libicu-dev \
		libpango1.0-dev \
		libcairo2-dev \
		git \
		curl && \
		rm -rf /var/lib/apt/lists/*

	RUN curl http://www.leptonica.org/source/leptonica-1.74.1.tar.gz -o leptonica-1.74.1.tar.gz && \
		tar -zxvf leptonica-1.74.1.tar.gz && \
		cd leptonica-1.74.1 && ./configure && make && make install && \
		cd .. && rm -rf leptonica*

	RUN git clone --depth 1 https://github.com/tesseract-ocr/tesseract.git && \
		cd tesseract && \
		./autogen.sh && \
		./configure --enable-debug && \
		LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make && \
		make install && \
		ldconfig && \
		make training && \
		make training-install && \
		cd .. && rm -rf tesseract

	# Get basic traineddata
	RUN curl https://github.com/tesseract-ocr/tessdata/raw/master/eng.traineddata > eng.traineddata && \
		mv eng.traineddata /usr/local/share/tessdata/

	RUN curl https://github.com/tesseract-ocr/tessdata/raw/master/fra.traineddata > fra.traineddata && \
		mv fra.traineddata /usr/local/share/tessdata/

Then:

	docker build -t tesseract4 .
	docker run tesseract4
	docker run -t -i tesseract4 /bin/bash
	mkdir test
	cd test
	curl http://tleyden-misc.s3.amazonaws.com/blog_images/ocr_test.png > test.png
	tesseract test.png out

Can someone explain me what is happening?

For information I have  2471 megabytes of memory remaning

Thanks in advance I did not built it with ubuntu.
I read in the referenced issue that we should not use it in docker image. Do you know why ? 
I need to use it in such way I will try to use it without enabled-debug option and give you the output I try using with and without --enable-debug and nothing is working.

Still the same issue:
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc

My issue is not a build failure.

Build is going well. The issue is when I launch tesseract

**EDIT:** I made a try outside of a docker image by simply running the command manually and I have the same error with or without the --enable-debug
 Concerning the multiple version I have only one installed.
I won't be able to see installation directory tonight because I deleted my instance aws. I will create a new one tomorrow. Can you tell me the normal installation directory so I can check tomorrow ? 
However according the "make" documentation it should be in /usr/bin Here is my configuration:
	
	root@65369dfbb4d0:/# tesseract -v
	tesseract 4.00.00alpha
	 leptonica-1.74.1
	  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8

	 Found AVX
	 Found SSE

And here is where I found tesseract packages

	root@65369dfbb4d0:/# find / -name "*tesseract*"
	/usr/local/include/tesseract
	/usr/local/bin/tesseract
	/usr/local/lib/libtesseract.so.4
	/usr/local/lib/libtesseract.so
	/usr/local/lib/pkgconfig/tesseract.pc
	/usr/local/lib/libtesseract.la
	/usr/local/lib/libtesseract.a
	/usr/local/lib/libtesseract.so.4.0.0

Still the same issue...

I am going to try with leptonica-1.74  I just did it (restarted from scratch 5 minutes ago and same error)

Here is what I found:

	root@1cd9578cac1d:/test/tesseract4# find / -name "*liblept*"
	/usr/local/lib/liblept.so.5.0.1
	/usr/local/lib/liblept.a
	/usr/local/lib/liblept.la
	/usr/local/lib/liblept.so.5
	/usr/local/lib/liblept.so
	root@1cd9578cac1d:/test/tesseract4# find / -name "*leptonica*"
	/usr/local/include/leptonica

**EDIT:** Same error with leptonica 1.74 and 1.74.1 :(

What is the minimum resources configuration to run it? Use GDB to get more info about the cause of the issue.  Asi in my previous comment I had:

	root@65369dfbb4d0:/# tesseract -v
	tesseract 4.00.00alpha
	 leptonica-1.74.1
	  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8

	 Found AVX
	 Found SSE
	 
And now

	root@1cd9578cac1d:/test/tesseract4# tesseract -v
	tesseract 4.00.00alpha
	 leptonica-1.74
	  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8

	 Found AVX
	 Found SSE

And same issue

 if gdb is --enable-debug I was running with it inside and outside a docker container and what I got:

	Info in bmfCreate: Generating pixa of bitmap fonts from string terminate called after throwing an instance of 'std::bad_alloc' 
	what(): std::bad_alloc Aborted (core dumped)

Without global debug I just get the:

	what(): std::bad_alloc Aborted (core dumped)

If not I never tried it. How to activate it? How do you run GDB?

https://github.com/tesseract-ocr/tesseract/issues/256#issuecomment-193896020 @Shreeshrii I just tested with JPG and tiff and still not working (with same issue)
http://read.pudn.com/downloads196/sourcecode/app/924338/OCR/OCR/TEST_2.JPG
https://github.com/nam-leduc/positioning/raw/master/test1.tif

@amitdo  
When I use gdb

	Starting program: /usr/local/bin/tesseract test.png out
	warning: Error disabling address space randomization: Operation not permitted
	terminate called after throwing an instance of 'std::bad_alloc'
	  what():  std::bad_alloc
	During startup program terminated with signal SIGABRT, Aborted. `curl https://github.com/tesseract-ocr/tessdata/raw/master/eng.traineddata > eng.traineddata` does not get the expected data file, but gets a HTML redirection file:

    <html><body>You are being <a href="https://raw.githubusercontent.com/tesseract-ocr/tessdata/master/eng.traineddata">redirected</a>.</body></html>

Use `curl -LO https://github.com/tesseract-ocr/tessdata/raw/master/eng.traineddata` (and similar for other languages), then Tesseract with Docker works for me. With the bad data file, I get an error message:

    # tesseract ocr_test.png out -l bad
    Info in bmfCreate: Generating pixa of bitmap fonts from string
    Error opening data file /usr/local/share/bad.traineddata
    Please make sure the TESSDATA_PREFIX environment variable is set to your "tessdata" directory.
    Failed loading language 'bad'
    Tesseract couldn't load any languages!
    Could not initialize tesseract.
 Men it works pefectly!!!

Thanks. The issue is only due to the redirection.

With correct download it is working

You can close the issue. But maybe a littple update on the docker file with example of the download would be great)

Here is the final dockerfile (base on @xlight first draft)

	FROM ubuntu
	RUN apt-get update && apt-get install -y \
		autoconf \
		automake \
		libtool \
		autoconf-archive \
		pkg-config \
		libpng12-dev \
		libjpeg8-dev \
		libtiff5-dev \
		zlib1g-dev \ 
		libicu-dev \
		libpango1.0-dev \
		libcairo2-dev \
		git \
		curl && \
		rm -rf /var/lib/apt/lists/*

	RUN curl http://www.leptonica.org/source/leptonica-1.74.1.tar.gz -o leptonica-1.74.1.tar.gz && \
		tar -zxvf leptonica-1.74.1.tar.gz && \
		cd leptonica-1.74.1 && ./configure && make && make install && \
		cd .. && rm -rf leptonica*

	RUN git clone --depth 1 https://github.com/tesseract-ocr/tesseract.git && \
		cd tesseract && \
		./autogen.sh && \
		./configure && \
		LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make && \
		make install && \
		ldconfig && \
		make training && \
		make training-install && \
		cd .. && rm -rf tesseract

	# Get basic traineddata
	RUN curl -LO https://github.com/tesseract-ocr/tessdata/raw/master/eng.traineddata && \
		mv eng.traineddata /usr/local/share/tessdata/

	RUN curl -LO https://github.com/tesseract-ocr/tessdata/raw/master/fra.traineddata && \
		mv fra.traineddata /usr/local/share/tessdata/ Shouldn't it be `curl -LO` instead of `curl -Lo` (upper case O instead of lower case o)?

I'm also still surprised that my docker test produced a different kind of error with the wrong trained data files. Sorry updated (typo issue :)) we can also use:

    git clone https://github.com/tesseract-ocr/tessdata && \
    mv  -v tessdata/* /usr/local/share/tessdata/ && \
    rm -rf tessadata

To have all the languages
 ~~Tesseract should verify that the tessdata file is a TIFF file.~~ My installer for Windows includes both files unconditionally. I think they should be in the docker container, too. >@amitdo Is the tessdata a tiff file???

I thought that it is a TIFF file without the tiff extension. I was wrong.  After doing much search I have found Kraken which is an open-source fork of ocropus that solves a number of issues including:

- clstm compatibility
- Right-to-left/BiDi support
- Explicit input/output handling
- Word and character bounding boxes in hOCR
- Removal of runtime dependency on gcc
- Clean public API
- ets ....

Stating Kraken's most important advantage, its workflow allows one to train new models relatively easily.

[In this research, they have managed to get 97% to 99% recognition rate of Arabic language, this rate excludes spacing and punctuation errors (2-5%).](https://drive.google.com/file/d/0BzDVkBcqiyEsbC16ZGktOWNiUDg/view)

What is really bothering me is that Kraken is a fork of ocropus that is using clstm, while Tesseract 4.x is the more complex and most sophisticated software that have improved ocropus techniques from scratch, but still can't achieve such practical results of Kraken.

Karken is the key to recognizing Arabic, Hebrew, Urdu, Persian/Farsi, etc....

@theraysmith @Shreeshrii @amitdo @zdenop 
I hope that we will be able to solve the Arabic Language in Tesseract 4.x similarly to Kraken.
Please have a look at the Kraken project, and their method as guidance:
https://github.com/mittagessen/kraken
http://kraken.re
https://drive.google.com/file/d/0BzDVkBcqiyEsbC16ZGktOWNiUDg/view After testing kraken v0.9.1 using provided Arabic models, I believe that 97% is in theory even with the same font that used in the training or at least not for the real situations.

same basic tests are attached
[Kraken_test_results.tar.gz](https://github.com/tesseract-ocr/tesseract/files/982008/Kraken_test_results.tar.gz)
 @bmwmy have you tested training yourself?
Kraken developer told me that those models that you presented, he made, and are not that sophisticated, maybe just for testing.
Please try to train clstm, then reply back @bmwmy have you trained using [train.sh](https://raw.githubusercontent.com/mittagessen/kraken-vagrant/master/training/train.sh) No, actually I used the downloadable models which is on the repository.
Will try to train and will give feedback. @bmwmy have you seen [this update by Ray](https://github.com/tesseract-ocr/langdata/commit/3ab6581a11eea90d4dc2ba46a811447ef231b644#diff-b8c77a8bc89ffb301d80233f2874c9d3),did he add the Arabic diacritics "Harakat"?
is that a good thing or a bad thing for ocr, what do you think?
Will adding Arabic diacritics (harakat) in lstm training degrade the recognition rate, or it will it remain the same?
Can you test training text with arabic diacritics, and without diacritics and post the comparison? 
[kraken75000_vs_Tesseract.pdf](https://github.com/tesseract-ocr/tesseract/files/1176821/kraken75000_vs_Tesseract.pdf)
Hi I used @christophered trained Arabic kraken model for about 75000 lines and did comparison with latest ara.traineddata with lstm. I used standard Arabic font e.g. (Times New Roman)
The result is that tesseract make it 100% except the bug of flipping combined letters but letters are correct (https://github.com/tesseract-ocr/tesseract/issues/758).
kraken mix up some letters with similar letters achieves ~97%.

for Arabic diacritics I think OCR engine should be aware of that but neglect it in the output or during ocr process.
  This is a test with caching. The [Appveyor cache](https://www.appveyor.com/docs/build-cache/) does not seem to work currently. According to the [documentation](https://www.appveyor.com/blog/2016/09/28/the-new-build-cache/), it is only enabled for new user accounts by default. @zdenop, you have to apply to get it enabled for your account. Wow! 3.05 now works and still needs 30 minutes. So we need the cache there, too. By the way: I think 0 warnings is not normal. Are they suppressed by compiler options? Then I suggest to raise to the next warning level. `text2image` is obviously not built, maybe because `pkg-config` is missing. See code [here](https://github.com/tesseract-ocr/tesseract/blob/master/training/CMakeLists.txt#L231).  It should work without that change. If no branches are specified in `.travis.yml`, all branches are covered by Travis CI according to the [documentation](https://docs.travis-ci.com/user/customizing-the-build#Building-Specific-Branches). I use that setting in [my own fork](https://travis-ci.org/stweil/tesseract/branches).  When I run tesseract command line program (Windows prebuilt binary, 4.0.0 alpha) on this image in LSTM mode, I get:
LoOrenm 1pPpSsSUlI

Why letters repeat? Stuttering?
In Tesseract mode (oem=0), I get correct text: Lorem ipsum

![sample](https://cloud.githubusercontent.com/assets/28452355/25756005/fa2e3c2a-3179-11e7-8bdb-a70ddababc46.png) This might be one more example where the old 3.x recognizer produces better results than 4.x with LSTM. See [here](https://github.com/tesseract-ocr/tesseract/issues/707#issuecomment-280096372) for the related discussion. I dug into this and found that letter bboxes are narrower than they should be.
Debugged hand-built Tess4 on another platform so output is a bit different from above but PageIterator::BoundingBox returns bbox narrower than actual as shown below. Seems like the same glyph image is recognized a couple of times while horizontal scan striding shorter than it should:

letter L BoundingBox=(2, 48, 375, 230)
letter o BoundingBox=(484, 76, 521, 236)
letter O BoundingBox=(521, 76, 559, 236)
letter r BoundingBox=(559, 76, 1043, 236)
letter e BoundingBox=(1119, 76, 1438, 236)
letter I BoundingBox=(1527, 76, 1564, 230)
letter n BoundingBox=(1564, 76, 1611, 230)
letter m BoundingBox=(1611, 76, 1658, 230)
letter n BoundingBox=(1658, 76, 1890, 230)
letter 1 BoundingBox=(2182, 1, 2436, 230)
letter p BoundingBox=(2607, 76, 2645, 295)
letter P BoundingBox=(2645, 76, 2682, 295)
letter p BoundingBox=(2682, 76, 2784, 295)
letter S BoundingBox=(2784, 76, 2826, 295)
letter s BoundingBox=(2999, 76, 3036, 237)
letter S BoundingBox=(3036, 76, 3129, 237)
letter U BoundingBox=(3186, 74, 3390, 236)
letter l BoundingBox=(3390, 74, 3548, 236)
letter I BoundingBox=(3548, 74, 3582, 236)
letter M BoundingBox=(3790, 76, 4172, 230) I also noticed double characters in the output, but they disappear (although not completely) as soon as the model gets better (~ < 0.1%).  I drew bounding box around each recognized letter in this image. While some are spot on but many off even though text is correctly recognized as "Simple Test". Note boxes are intentionally drew off at top and bottom to minimize a chance of box overlaps.
![simpletest_bbox](https://cloud.githubusercontent.com/assets/28452355/26178227/feb02154-3b11-11e7-96fd-a98307e26ad9.png)
  Hey friends! 
First thanks for mantaining this open source project. 

However I must tell you that when I Installed this and clicked on Add to Path and Set TESSDATA_PREFIX variable almost everything I had on the path stopped working.
very similar to what happened to this guy here: 
https://stackoverflow.com/questions/43014724/how-to-reset-system-variable-path-after-tesseract-installation

I've tried the solution proposed, but unluckily windows didn't make the shadow copies of my old PATH.

So now I'm here trying to piece toghether again my path...
 That's why there is a [hint](https://github.com/UB-Mannheim/tesseract/wiki) which suggests not to use that option. The default settings are fine. Hi Stweil, thanks for answering so fast! 
I completely missed that... guess it's my fault.

But just for a heads up I installed the 3.05.00dev version which I understand is the latest one that is stable. 
and the problem of the path happened anyways, so it's not on older versions of the installer (I understand that since 4 is experimental, version 3 isn't "old", correct me if I am)

 anyways thanks again for answering, you can close this!

If anyone gets to this thread in the future and had this happened to them, then I'll leave you the default system path that comes with WINDOWS 10, so you can restore it: 

`%SystemRoot%\system32;%SystemRoot%;%SystemRoot%\System32\Wbem;%SYSTEMROOT%\System32\WindowsPowerShell\v1.0\
` > Please update the windows binaries on your site with the latest version.

Done now for both Tesseract 3.05 and Tesseract 4.  How can I reproduce this crash? `updates_` looks strange. No wonder that the code crashes when it tries to add a 0 x 0 matrix. Ray said that he needs to fix training after his last commits. When I run all but the last step with older executables, I get an error from `lstmtraining`:

    Deserialize failed: tess4training/eng/eng.Arial.exp0.lstmf read 0/72 pages

That might confirm that the last commits introduced some incompatibility. I could confirm that commit 8e79297dcefecdb929d753d28554fec51417ec39 introduced a regression. Before that commit, lstmtraining did run the iterations. https://github.com/tesseract-ocr/tesseract/commit/83588bc7a18e50fb435b5ca8a45fd7e00ab2ccdf#commitcomment-22019959

>Now back to finding out why training isn't working properly... [Here](https://github.com/tesseract-ocr/tesseract/commit/8e79297dcefecdb929d753d28554fec51417ec39#diff-1e1ab755e307f14ddffbad6f38cdf54aR169) `language_` is added to the serialized data, so old and new data are incompatible (this is the reason why I get the above error message). The new data is correctly handled in [ImageData::DeSerialize](https://github.com/tesseract-ocr/tesseract/commit/8e79297dcefecdb929d753d28554fec51417ec39#diff-1e1ab755e307f14ddffbad6f38cdf54aR186) and in [ImageData::SkipDeSerialize](https://github.com/tesseract-ocr/tesseract/commit/8e79297dcefecdb929d753d28554fec51417ec39#diff-1e1ab755e307f14ddffbad6f38cdf54aR198).

Does the training process use old files which contain old incompatible `ImageData`?  Are you sure that `--tessdata_dir ./tessdata` is correct? Shouldn't it point to the parent directory of `tessdata`? https://github.com/tesseract-ocr/tesseract/issues/881#issuecomment-299391463 I could now reproduce the assertion and the crash. @Shreeshrii, please try reverting [line 491 in `lstm/lstmtrainer.cpp`](https://github.com/tesseract-ocr/tesseract/commit/8e79297dcefecdb929d753d28554fec51417ec39#diff-2321d66b4e371b97cfc510763d8f1283R491) (s/TS_ENABLED/TS_RE_ENABLE/). That fixes the assertion for me.  Hello all,

I  lstmtraining chi_sim, but have the error "Must supply a list of training filenames! --train_listfile".
The context is "./cntrain/chi_sim.SimSun.exp0.lstmf" in my chi_sim.training_files.txt. Please give me a help!

lstmtraining -U ./cntrain/chi_sim.unicharset \
--script_dir ./langdata \
--debug_interval 100 \
--continue_from ./cnoutput/chi_sim.lstm \
--append_index 5 –net_spec '[1,0,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx384 O1c1]' \
--learning_rate 10e-5 \
--net_mode 192 \
--perfect_sample_delay 19 \
--max_iterations 10000 \
--model_output ./cnoutput/base  --max_image_MB 600 \
--train_listfile ./cntrain/chi_sim.training_files.txt  \
--eval_listfile ./cntrain/chi_sim.training_files.txt &>./cnoutput/basetrain.log

 Thank you for your help. I solved it by removing "--append_index 5"   Ray, this commit has a high probability to conflict with your work, so please select single commits as you like or just tell me which changes can be applied next or when is the best time for such changes.

It would be good to finish the transformation to POSIX data types and macros in the not too far future.  Rebased PR to trigger a new AppVeyor build ([previous build](https://ci.appveyor.com/project/zdenop/tesseract/build/master.813) failed, reason unknown).  Could we just remove the i/o redirection in `cmake --build . --config Release > bin\Release\log.txt`? Writing compiler error messages to a file which cannot be read looks strange. Appveyor also supports caching. That could reduce build time significantly. Build now works. The previous errors were caused by ambiguous calls of `ClipToRange`.

Appveyor needed about 30 minutes total time with i/o redirection removed. Fixed merge conflicts and rebased PR. Fixed merge conflicts and rebased PR. Fixed merge conflicts and rebased PR. @theraysmith, as you are just preparing a new larger code change: is it possible to use POSIX data types for the new / modified code, and can we switch to POSIX for the rest of the code directly after your update? Rebased PR and fixed merge conflicts. Not this one.

>.. after the legacy engine is removed...

The legacy engine is still alive.
… @stweil estimated elsewhere that a merge of this PR will happen sometime in the next 5 years.

Optimistic guy... 😆   I'm sure that some parts of the PR are not related to the legacy engine. Maybe those can be applied now. Replacing the types and macros can be done automatically, so doing it yourself in your code could save the review. It took me more time to fix indentation of in-line comments, but I think you can do that using tools, too. Fixed 7 files with merge conflicts. Fixed merge conflict in `training/normstrngs.cpp`.  Hi,I want to build the Tesseract using the master branch.
I followed the steps as you mentioned.
But when I enter **cmake ..** I am getting the following error.
Help me on this.
Thank you


C:\Users\Varun\Desktop\New folder\tesseract-master\Win64>cmake ..
-- The C compiler identification is unknown
-- The CXX compiler identification is unknown
CMake Error at CMakeLists.txt:47 (project):
  No CMAKE_C_COMPILER could be found.



CMake Error at CMakeLists.txt:47 (project):
  No CMAKE_CXX_COMPILER could be found.



-- Configuring incomplete, errors occurred!
See also "C:/Users/Varun/Desktop/New folder/tesseract-master/Win64/CMakeFiles/CMakeOutput.log".
See also "C:/Users/Varun/Desktop/New folder/tesseract-master/Win64/CMakeFiles/CMakeError.log".  Hi,
I'm using tesseract 4.00alpha with leptonica 1.74.1 on Ubuntu 14.04, first i was training on the a VirtualBox and i was able to create LSTMF files, but now i use the same tesseract, lepptonica and Ubutnu versions on a different machine (VMware) and i couldn't create LMSTF files, and i compiled the tesseract in both cases the same, according to this [website](https://medium.com/@lucas63/installing-tesseract-3-04-in-ubuntu-14-04-1dae8b748a32) ,I'm pasting part of log file that is created at tmp file......
=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=./tessdata
[Thu May 4 00:52:11 PDT 2017] /usr/local/bin/tesseract /tmp/tmp.vDN2ALtI8c/ara/ara.Arabic_Typesetting.exp0.tif /tmp/tmp.vDN2ALtI8c/ara/ara.Arabic_Typesetting.exp0 lstm.train ../langdata/ara/ara.config
Info in bmfCreate: Generating pixa of bitmap fonts from string
lstm_recognizer_->DeSerialize(tessdata_manager.swap(), &fp):Error:Assert failed:in file tessedit.cpp, line 202
ERROR: /tmp/tmp.vDN2ALtI8c/ara/ara.Arabic_Typesetting.exp0.lstmf does not exist or is not readable

keep in mind i copied the tessedit from the working version of tesseract and replaced it at the new machine but the same error occurred

Thanks UPDATE :-
i have installed the tesseract again today and the same error was generated but the only difference that the line number has changed

=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=./tessdata
[Thu May 4 04:43:32 PDT 2017] /usr/local/bin/tesseract /tmp/tmp.RwajXhdHOo/ara/ara.Arabic_Typesetting.exp0.tif /tmp/tmp.RwajXhdHOo/ara/ara.Arabic_Typesetting.exp0 lstm.train /home/ibr/Desktop/Tesseract4/langdata/ara/ara.config
Info in bmfCreate: Generating pixa of bitmap fonts from string
lstm_recognizer_->DeSerialize(&fp):Error:Assert failed:in file tessedit.cpp, line 193
ERROR: /tmp/tmp.RwajXhdHOo/ara/ara.Arabic_Typesetting.exp0.lstmf does not exist or is not readable
 >Info in bmfCreate: Generating pixa of bitmap fonts from string

It just an info message, not an error message.

The two issues does not seem related to each other.
 as i understood from the issue 893, that guy is facing a trouble with building the tesseract with liptonica, but i built it fine and I'm even capable to detect text from images, if you can see in the log message when I'm using the tesstrain.sh i'm able yo create the data that is stored in the tmp file, my problem is in the last phase which is generating lstm files.
keep in mind that i have installed and complied the tesseract 4alpha and leptonica 1.74.1 twice, within month in between i guess, the first one works fine and I'm able to create the lstmf files, but in the second i can't amd i followed the same steps in both cases
Thanks Hi Shree,

i was thinking the same thing, its just i always follow the steps and links to install and compile from this [site](https://medium.com/@lucas63/installing-tesseract-3-04-in-ubuntu-14-04-1dae8b748a32)
so is there a way currently to solve this issue? cause i might need to install the tesseract on a server because all the work i did already on a VMware for testing purposes 
Thanks Hi,

i looked at the config.log of the tesseract revision that works, took the revision  number  and switched the tesseract to that branch while installing the tesseract, and that revision was **"4.00.00alpha-367-g5baa8c8"**
i made sure that its the correct revision by making detection of an image, i noticed that on the terminal the tesseract prints its revision number
![ocrerror](https://cloud.githubusercontent.com/assets/26926171/25889397/49639c4e-3572-11e7-909e-5c7fcf8eab3c.png)
yet the same error was generated at the phase E where creating lstm files
i even tried to install the suggested revision: **"4.00.00alpha-458-g2ea946d"** and the result was the same error but different line number at the tessedit.cpp, at the revision  **"4.00.00alpha-367-g5baa8c8"** the error is: **stm_recognizer_->DeSerialize(&fp):Error:Assert failed:in file tessedit.cpp, line 202**
and at the revision **"4.00.00alpha-458-g2ea946d"** the error was
**stm_recognizer_->DeSerialize(&fp):Error:Assert failed:in file tessedit.cpp, line 193**
i even deleted that line from the tessedit.cpp and the error stayed the same, after that i tried to delete the whole tessedit.cpp and same problem, so is it loaded on somewhere ? or is it not compatible with VMware because the revision **"4.00.00alpha-367-g5baa8c8"** works fine with the virtual box but not with the VMware 
Thanks @Shreeshrii 
no worries :) i mentioned the virtual box and the VMware just in case, i just like to share the details in case they were any help, i dont know either if its virtual box or VMware, the interesting point that in both cases or in both revisions the same line of code failed 
thanks for the response @Shreeshrii are the libraries and leptonica version at this [site](https://medium.com/@lucas63/installing-tesseract-3-04-in-ubuntu-14-04-1dae8b748a32) are valid? meaning did you install them with the tesseract v4.00.00alpha-460-gb86b4fa ? Finally I'm able to create LSTM files, without switching to any other branches, the version of the tesseract is in the image below
![lstm](https://user-images.githubusercontent.com/26926171/27028983-3370d0e8-4f6f-11e7-9377-60158f0c11a8.png)
  We are an enterprise utilizing tesseract for years, and we recently upgraded to 3.04.1 successfully by compiling from source code. When running the command below, segmentation fault is received from Ubuntu 10.04.4 (code 139). 

Does anyone have ideas as why this might occur? Thanks heaps. 
tesseract -psm 1 -l eng /var/opt/app/main.jpg /var/opt/app/main_1 characters hocr 
   Up to now, Insight.io only shows the files with syntax highlighting. I got an error message that code analysis failed for my projects. I have sent a [pull request](https://github.com/tesseract-ocr/tesseract-ocr.github.io/pull/1) which updates the documentation.

It is possible to automatically update that documentation, but that would add a new revision for each change of the master branch. Travis needs write access to the [tesseract-ocr/tesseract-ocr.github.io repository](https://github.com/tesseract-ocr/tesseract-ocr.github.io). That part is a little bit tricky (see links above collected by @Shreeshrii).

Maybe it is sufficient to update the documentation each time a release is tagged.

New documentation is also visible [here](https://ub-mannheim.github.io/tesseract/). It's based on the latest git master branch. @stweil Hi, insight.io creator here, tesseract-ocr should work fine on insight.io with full code intelligence not just syntax highlighting. Would you mind shooting an email to chongzhe@insight.io with regarding to the errors you see, we will help you solve the issue:)

Thanks!  I was able to install head with brew before, but now I get this error. :(
Could someone help?
Thanks!
$ brew install tesseract --HEAD
==> Auto-updated Homebrew!
Updated 1 tap (homebrew/core).
No changes to formulae.

==> Using the sandbox
==> Cloning https://github.com/tesseract-ocr/tesseract.git
Cloning into '/Users/user/Library/Caches/Homebrew/tesseract--git'...
remote: Counting objects: 724, done.
remote: Compressing objects: 100% (694/694), done.
remote: Total 724 (delta 88), reused 163 (delta 12), pack-reused 0
Receiving objects: 100% (724/724), 3.74 MiB | 0 bytes/s, done.
Resolving deltas: 100% (88/88), done.
Checking connectivity... done.
==> Checking out branch master
==> Downloading https://github.com/tesseract-ocr/tesseract/commit/b18cad4.patch
######################################################################## 100.0%
==> Patching
==> Applying b18cad4.patch
patching file configure.ac
Hunk #1 FAILED at 220.
1 out of 1 hunk FAILED -- saving rejects to file configure.ac.rej
patching file api/Makefile.am
Hunk #1 FAILED at 45.
1 out of 1 hunk FAILED -- saving rejects to file api/Makefile.am.rej
Error: Failure while executing: /usr/bin/patch -g 0 -f -p1 -i /private/tmp/tesseract--patch-20170502-16295-cpuv7w/b18cad4.patch
 Thanks, do you know how to tell brew to skip the patch?
 The brew formulae is for version 3.05, while the HEAD is 4.00 (alpha). Thanks, wouldn't adding --head option like "brew install tesseract 
--HEAD" download the latest head from the Github?
I'm wondering how to tell brew to skip the patch...
 Dunno. I don't have a a Mac... @zdenop, maybe a new release 3.05.01 would help making such patches unnecessary. same here
 @jsl303,

As you might already know, Homebrew's Formula can edit locally.

```
$ brew edit tesseract
```

If you want to skip the patch, comment out line 71-74, and save it.

( /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core/Formula/tesseract.rb )

```
$ brew install tesseract --HEAD
```

or, wrapping patch block with 'if-end' block such like below.

```
--- a/Formula/tesseract.rb
+++ b/Formula/tesseract.rb
@@ -68,10 +68,12 @@ class Tesseract < Formula
   # remove on next release, > 3.05.00
   # upstream fix for building with OpenCL enabled
   # https://github.com/tesseract-ocr/tesseract/pull/814
+  if !build.head?
   patch do
     url "https://github.com/tesseract-ocr/tesseract/commit/b18cad4.patch"
     sha256 "10c59baa54c3406fcd03f36cd0f1e3cc2ba150f082d14f919274a541b3cff7b2"
   end
+  end

   def install
     if build.head?
```

 My PR got merged. So, no need to edit Formula.

@jsl303, It should work with the following command.

```
$ brew update
$ brew install tesseract --HEAD
``` This issue can be closed. `brew install tesseract --HEAD` now works. > Please see the recent post ...

I need more information because I currently cannot reproduce the build problem (building training tools works for me with MacPorts and with Homebrew).  Hi,

I'm using tesseract 4.00alpha with liptonica 1.74.1 on Ubuntu 14 to create LSTM files for multiple Arabic fonts, which some of them have the common numerical system, (1 2 3 4 ...) but some of these font contains the a different numerical system, which usually more common in the Arabic scripts, 
which are ( ٠ ١ ٢ ٣ ٤ ٥ ٦ ٧ ٨ ٩)
yet the last set of numbers were not recognize but as symbols such as ! instead of ١ ,are these numbers are not integrated in the tesseract?
Thanks  If that numerals are indeed missing from the official traineddata, I suggest to open a new issue in the langdata repo. Did Anyone fix this problem? I am not using Unix in order to be able to train tesseract on new data, but I need to use the Eastern arabic numerals. if someone fixed it and has the traineddata file, please share it with us

Thanks Persian's number's shape mostly the same as Arabic's but their Unicode is different!
Persian numbers= ۹ ۸ ۷ ۶ ۵ ۴ ۳ ۲ ۱ ۰
Arabic numbers = ٠ ١ ٢ ٣ ٤ ٥ ٦ ٧ ٨ ٩
Persian numbers' Unicode= \u06F9 \u06F8 \u06F7 \u06F6 \u06F5 \u06F4 \u06F3 \u06F2 \u06F1 \u06F0
Arabic numbers' Unicode =\u0660 \u0661 \u0662 \u0663 \u0664 \u0665 \u0666 \u0667 \u0668 \u0669
you can check them [here](https://r12a.github.io/apps/conversion/) Yes, it mixed Persian with Arabic numbers (unicode) for example the image had these numbers
۱-۲ and it recognize ۱ as Persian number and ۲ as Arabic number their shape is the same but for searching and Unicode, they are different.
in another hand 3 and 4 and 5 and 6's shape are not the same see below
6 5 4 3 
۶ ۵ ۴ ۳ >Persian
٣ ٤ ٥ ٦  > Arabic
you can check it at [here](https://github.com/tesseract-ocr/tessdata/issues/70#issuecomment-320441157) with the output txt file
 for more information see [Unicode Number, Decimal Digit' Category](http://www.fileformat.info/info/unicode/category/Nd/list.htm) usually, people use the un-standard keyboard (Arabic keyboard for typing Persian text) so there are many scan images of Persian's text  which have Arabic numbers like ٣ ٤ ٥ ٦  but the OCR should convert them to Persian Unicode @zdenop, please close this issue.

The issue is related to the trained **data**. not code.

As said, the right place for this issue is the langdata repo.
See https://github.com/tesseract-ocr/langdata/issues/71, https://github.com/tesseract-ocr/langdata/issues/72
  Those files can be built by doc/generate_manpages.sh.

The manpages are needed for the installation,
so add Makefile rules for them.

Git must ignore the generated manpages.

Signed-off-by: Stefan Weil <sw@weilnetz.de> This is a request for comments. The patch removes documentation files which can be easily created if `asciidoc` is available in the build environment. Man pages are now not built and installed by default. They are build and installed in maintainer mode (`./configure --enable-maintainer-mode`).

Removing the documentation files which can be built simplifies the maintenance, because it is no longer necessary to update three generated files for a simple documentation update. I just tried to install the asciidoc package on Debian with Synaptic.
Synaptic lists additional **59** required packages.

 Are you sure that those packages are _required_? On my Debian Stretch, I see 4 required packages (1.4 MB disk space): `asciidoc`, `asciidoc-base`, `asciidoc-common`, `libxml2-utils`. As long as you don't want to create LaTeX and PDF documents, you can keep the installation pretty small. It may depend on what is already installed on the system. I get the following list:

```
 sudo apt-get install asciidoc
sudo: unable to resolve host ALL-IN-1-TOUCH
[sudo] password for shree:
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following extra packages will be installed:
  dblatex docbook-dsssl docbook-utils fonts-lmodern fonts-texgyre jadetex
  latex-beamer latex-xcolor libkpathsea6 libosp5 libostyle1c2 libptexenc1
  libreadline5 libruby1.9.1 libsgmls-perl libsp1c2 lmodern luatex openjade pgf
  preview-latex-style prosper ps2eps ruby ruby1.9.1 sgmlspl sp tcl tcl8.6
  tex-common tex-gyre texlive texlive-base texlive-bibtex-extra
  texlive-binaries texlive-extra-utils texlive-font-utils
  texlive-fonts-recommended texlive-fonts-recommended-doc
  texlive-generic-recommended texlive-latex-base texlive-latex-base-doc
  texlive-latex-extra texlive-latex-extra-doc texlive-latex-recommended
  texlive-latex-recommended-doc texlive-luatex texlive-math-extra
  texlive-pictures texlive-pictures-doc texlive-pstricks texlive-pstricks-doc
  tipa tk tk8.6 xmlto xsltproc
Suggested packages:
  source-highlight vim-addon-manager docbook latex-cjk-all opensp
  texlive-lang-cyrillic texlive-xetex transfig docbook-dsssl-doc sgmls-doc
  doc-base ri ruby-dev ruby1.9.1-examples ri1.9.1 graphviz ruby1.9.1-dev
  tcl-tclreadline perl-tk chktex fragmaster xindy latexdiff lacheck latexmk
  dvidvi purifyeps dvipng t1utils psutils libfile-which-perl python-pygments
  dot2tex libtcltk-ruby xmltex
Recommended packages:
  wish
The following NEW packages will be installed:
  asciidoc dblatex docbook-dsssl docbook-utils fonts-lmodern fonts-texgyre
  jadetex latex-beamer latex-xcolor libkpathsea6 libosp5 libostyle1c2
  libptexenc1 libreadline5 libruby1.9.1 libsgmls-perl libsp1c2 lmodern luatex
  openjade pgf preview-latex-style prosper ps2eps ruby ruby1.9.1 sgmlspl sp
  tcl tcl8.6 tex-common tex-gyre texlive texlive-base texlive-bibtex-extra
  texlive-binaries texlive-extra-utils texlive-font-utils
  texlive-fonts-recommended texlive-fonts-recommended-doc
  texlive-generic-recommended texlive-latex-base texlive-latex-base-doc
  texlive-latex-extra texlive-latex-extra-doc texlive-latex-recommended
  texlive-latex-recommended-doc texlive-luatex texlive-math-extra
  texlive-pictures texlive-pictures-doc texlive-pstricks texlive-pstricks-doc
  tipa tk tk8.6 xmlto xsltproc
0 upgraded, 58 newly installed, 0 to remove and 171 not upgraded.
Need to get 727 MB of archives.
After this operation, 1,145 MB of additional disk space will be used.
Do you want to continue? [Y/n] n
Abort.
``` Try `apt-get install --no-install-recommends asciidoc`. This will reduce the list a lot, because all TeX related packages are only recommended (needed for PDF generation, but not for simple man pages).

I get 4 packages with `--no-install-recommends`, but 72 packages without that option. Thanks. That does the trick.

```
sudo apt-get install --no-install-recommends asciidoc
sudo: unable to resolve host ALL-IN-1-TOUCH
[sudo] password for shree:
Reading package lists... Done
Building dependency tree
Reading state information... Done
Suggested packages:
  source-highlight vim-addon-manager
Recommended packages:
  dblatex docbook-utils xmlto
The following NEW packages will be installed:
  asciidoc
0 upgraded, 1 newly installed, 0 to remove and 171 not upgraded.
Need to get 688 kB of archives.
After this operation, 2,370 kB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu/ trusty/main asciidoc all 8.6.9-2ubuntu1 [688 kB]
Fetched 688 kB in 2s (239 kB/s)
Selecting previously unselected package asciidoc.
(Reading database ... 103366 files and directories currently installed.)
Preparing to unpack .../asciidoc_8.6.9-2ubuntu1_all.deb ...
Unpacking asciidoc (8.6.9-2ubuntu1) ...
Processing triggers for man-db (2.6.7.1-1ubuntu1) ...
Setting up asciidoc (8.6.9-2ubuntu1) ...

``` ```
$ apt-cache depends asciidoc
asciidoc
  Depends: python
  Depends: <python:any>
    python
  Suggests: source-highlight
  Suggests: vim-addon-manager
  Recommends: dblatex
  Recommends: docbook-utils
  Recommends: libxml2-utils
  Recommends: xmlto
```

```
$ apt-get install --dry-run --no-install-recommends asciidoc
NOTE: This is only a simulation!
      apt-get needs root privileges for real execution.
      Keep also in mind that locking is deactivated,
      so don't depend on the relevance to the real current situation!
Reading package lists... Done
Building dependency tree       
Reading state information... Done
Suggested packages:
  source-highlight vim-addon-manager
Recommended packages:
  dblatex docbook-utils libxml2-utils xmlto
The following NEW packages will be installed:
  asciidoc
0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.
Inst asciidoc (8.6.9-3 Debian:8.7/stable [all])
Conf asciidoc (8.6.9-3 Debian:8.7/stable [all])
```
 https://www.macports.org/ports.php?by=name&substr=asciidoc
http://brewformulas.org/Asciidoc By the way, builds which use `cmake` don't install any man pages, only `autoconf` based builds do. Cmake is used by people that use MSVC and by the CI. If this PR is accepted, we will need to add this to the `Compiling` wiki page:
`apt-get install --no-install-recommends asciidoc`, but we only have instructions for Debian-based distros. If other package managers in non-Debian-based distros have a similar behavior like
`apt-get install asciidoc` (install also recommended packages) users will get a lot of unnecessary packages.

@stweil, what do think about this issue?  Yes, we have to add documentation for package maintainers who want to install the man pages with the Tesseract package.

I expect that a person who wants to build a distro package won't have problems with installing too many packages with `asciidoc`. My main machine, for example, already had TeX installed, so the installation of `asciidoc` did not add many more packages.

Normal users who want to build Tesseract would not automatically build man pages, so they don't need `asciidoc`. The main question is whether that is acceptable.

Instead of building man pages in maintainer mode only, it would also be possible to build them only if `asciidoc` was found. Would that be better? OK. No objection to this PR.

BTW, Git does the same thing:
https://github.com/git/git/tree/master/Documentation
 https://github.com/git/git/blob/v2.13.0-rc1/INSTALL#L160
Stefan, I suggest to do something similar in Tesseract.
(Of course, don't copy even a single line from that GPL codebase) Thank you for the report. This is fixed in PR #862. Don't forget to run `./autogen.sh` after that patch.  From time to time Ray cleans the code by using `clang-tidy`. It would be nice to document that process to allow other developers to check their code contributions and avoid style problems from the beginning.

The current tidy process does not cover some significant code style issues. Most noticeable: it does not change from `( xxx )` (about 480 lines of code) to `(xxx)` (which is the preferred [Google style](https://google.github.io/styleguide/cppguide.html#Function_Declarations_and_Definitions), more than 50000 lines of code).  L_Bmf works for C++ code, but the common form is L_BMF, so use that.

Signed-off-by: Stefan Weil <sw@weilnetz.de> @theraysmith, maybe you a referring to the [Leptonica style guide](https://github.com/DanBloomberg/leptonica/blob/master/style-guide.txt#L48). I think it's a style guide for the Leptonica code, not for code using Leptonica (like Tesseract). https://github.com/DanBloomberg/leptonica/blob/master/style-guide.txt

>(c) Use typedefs for structs like Pix; e.g.,
          function(PIX  *pixs)
       Do not do this (omitting the 'struct' keyword); it is valid C++,
       but not C:
          function(Pix  *pixs)

https://github.com/DanBloomberg/leptonica/blob/150c8d0051/src/bmf.h#L45

Since Tesseract code is based on C++, we should use a C++ style guide.
https://google.github.io/styleguide/cppguide.html#Type_Names
  I must admit that I'm confused now. If Dan prefers `Pix`, I'd change the Leptonica to allow `Pix` for C as well (and maintain `PIX` for backward compatibility, maybe with a deprecation attribute).

Ray, the code in `opencl/` needs much formatting. Could you do this with your internal tool (or make it public, then I could assist)? Ray,
According to some of your commit messages you use clang-tidy.

What about adding a `.clang-format` file to the public repo?
https://clang.llvm.org/docs/ClangFormatStyleOptions.html

 Ray reverted this pull request with commit 7a116ce8bbfe6c1772b0b5055c7574a27c35eaac. My new pull request #855 fixes the remaining exceptions which currently don't use the preferred struct name.

Ray, thank you for formatting `opencl/`. I noticed that some issues like _[There is never a space between the parentheses and the parameters](https://google.github.io/styleguide/cppguide.html#Function_Declarations_and_Definitions)_ were not fixed (see also issue #854).  Hello All,

I want to train tesseract , But I got this error, Any help
~/tesseract$ training/tesstrain.sh 
--fonts_dir /usr/share/fonts/winFonts 
--fontlist SimSun 
--lang chi_sim  
--linedata_only 
--noextract_font_properties 
--langdata_dir ./langdata 
--tessdata_dir /usr/share/tesseract-ocr/tessdata 
--output_dir ./tesstutorial/chisimtrain

=== Starting training for language 'chi_sim'
[2017年 04月 26日 星期三 16:26:34 CST] /usr/local/bin/text2image --fonts_dir=/usr/share/fonts/winFonts --font=SimSun --outputbase=/tmp/font_tmp.ErZuLmIxms/sample_text.txt --text=/tmp/font_tmp.ErZuLmIxms/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.ErZuLmIxms
Rendered page 0 to file /tmp/font_tmp.ErZuLmIxms/sample_text.txt.tif

=== Phase I: Generating training images ===
Rendering using SimSun
[2017年 04月 26日 星期三 16:26:34 CST] /usr/local/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.ErZuLmIxms --fonts_dir=/usr/share/fonts/winFonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.SimSun.exp0 --font=SimSun --text=/home/alisa/tesseract/langdata/chi_sim/chi_sim.training_text
Rendered page 0 to file /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.SimSun.exp0.tif

=== Phase UP: Generating unicharset and unichar properties files ===
[2017年 04月 26日 星期三 16:26:35 CST] /usr/local/bin/unicharset_extractor -D /tmp/tmp.sqbPsVBeRu/chi_sim/ /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.SimSun.exp0.box
Extracting unicharset from /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.SimSun.exp0.box
Wrote unicharset file /tmp/tmp.sqbPsVBeRu/chi_sim//unicharset.
[2017年 04月 26日 星期三 16:26:35 CST] /usr/local/bin/set_unicharset_properties -U /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.unicharset -O /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.unicharset -X /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.xheights --script_dir=/home/alisa/tesseract/langdata
Loaded unicharset of size 322 from file /tmp/tmp.sqbPsVBeRu/chi_sim/chi_sim.unicharset
=== Phase D: Generating Dawg files ===
ERROR: /home/alisa/tesseract/langdata/common.punc does not exist or is not readable Did you clone the https://github.com/tesseract-ocr/langdata repository? `--langdata_dir ./langdata` looks wrong to me, `langdata` is not part of the normal tesseract repository. oh, no. I have used the langdata cloned from  "https://github.com/tesseract-ocr/langdata" to do this again, but have the following error:
training/tesstrain.sh --fonts_dir /usr/share/fonts/winFonts 
--fontlist "SimSun" 
--lang chi_sim  
--linedata_only 
--noextract_font_properties 
--langdata_dir ../langdata 
--tessdata_dir /usr/share/tesseract-ocr/tessdata 
--training_text 
../train_text/0.txt 
--output_dir ./tesstutorial/cntrain
=== Starting training for language 'chi_sim'
[2017年 04月 27日 星期四 09:51:36 CST] /usr/local/bin/text2image --fonts_dir=/usr/share/fonts/winFonts --font=SimSun --outputbase=/tmp/font_tmp.L6T5hz2YhQ/sample_text.txt --text=/tmp/font_tmp.L6T5hz2YhQ/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.L6T5hz2YhQ
Rendered page 0 to file /tmp/font_tmp.L6T5hz2YhQ/sample_text.txt.tif

=== Phase I: Generating training images ===
Rendering using SimSun
[2017年 04月 27日 星期四 09:51:37 CST] /usr/local/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.L6T5hz2YhQ --fonts_dir=/usr/share/fonts/winFonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.SimSun.exp0 --font=SimSun --text=../train_text/0.txt
Rendered page 0 to file /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.SimSun.exp0.tif

=== Phase UP: Generating unicharset and unichar properties files ===
[2017年 04月 27日 星期四 09:51:38 CST] /usr/local/bin/unicharset_extractor -D /tmp/tmp.wiRXVpIiJ9/chi_sim/ /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.SimSun.exp0.box
Extracting unicharset from /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.SimSun.exp0.box
Wrote unicharset file /tmp/tmp.wiRXVpIiJ9/chi_sim//unicharset.
[2017年 04月 27日 星期四 09:51:38 CST] /usr/local/bin/set_unicharset_properties -U /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset -O /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset -X /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.xheights --script_dir=../langdata
Loaded unicharset of size 322 from file /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset
Setting unichar properties
Other case X of x is not in unicharset
Other case M of m is not in unicharset
Other case h of H is not in unicharset
Other case G of g is not in unicharset
Other case e of E is not in unicharset
Other case f of F is not in unicharset
Other case c of C is not in unicharset
Other case u of U is not in unicharset
Other case O of o is not in unicharset
Other case Μ of μ is not in unicharset
Warning: properties incomplete for index 14 = ：
Warning: properties incomplete for index 35 = ，
Warning: properties incomplete for index 125 = ＝
Warning: properties incomplete for index 126 = ％
Warning: properties incomplete for index 136 = （
Warning: properties incomplete for index 139 = ）
Warning: properties incomplete for index 223 = ；
Writing unicharset to file /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset

=== Phase D: Generating Dawg files ===
Generating word Dawg
[2017年 04月 27日 星期四 09:51:38 CST] /usr/local/bin/wordlist2dawg -r 1 ../langdata/chi_sim/chi_sim.wordlist /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.word-dawg /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset'
Reading word list from '../langdata/chi_sim/chi_sim.wordlist'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.word-dawg'
Generating frequent-word Dawg
[2017年 04月 27日 星期四 09:51:38 CST] /usr/local/bin/wordlist2dawg -r 1 /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.wordlist.clean.freq /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.freq-dawg /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset'
Reading word list from '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.wordlist.clean.freq'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.freq-dawg'
[2017年 04月 27日 星期四 09:51:38 CST] /usr/local/bin/wordlist2dawg -r 0 ../langdata/chi_sim/chi_sim.punc /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.punc-dawg /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset
Set reverse_policy to RRP_DO_NO_REVERSE
Loading unicharset from '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset'
Reading word list from '../langdata/chi_sim/chi_sim.punc'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.punc-dawg'
[2017年 04月 27日 星期四 09:51:38 CST] /usr/local/bin/wordlist2dawg -r 0 ../langdata/chi_sim/chi_sim.numbers /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.number-dawg /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset
Set reverse_policy to RRP_DO_NO_REVERSE
Loading unicharset from '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.unicharset'
Reading word list from '../langdata/chi_sim/chi_sim.numbers'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.number-dawg'

=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=/usr/share/tesseract-ocr/tessdata
[2017年 04月 27日 星期四 09:51:38 CST] /usr/local/bin/tesseract /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.SimSun.exp0.tif /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.SimSun.exp0 lstm.train ../langdata/chi_sim/chi_sim.config
Info in bmfCreate: Generating pixa of bitmap fonts from string
read_params_file: Can't open lstm.train
Info in bmfCreate: Generating pixa of bitmap fonts from string
Error opening data file /usr/share/tesseract-ocr/tessdata/chi_sim_vert.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your "tessdata" directory.
Failed loading language 'chi_sim_vert'
Tesseract Open Source OCR Engine v7bb00d9 with Leptonica
Page 1
ERROR: /tmp/tmp.wiRXVpIiJ9/chi_sim/chi_sim.SimSun.exp0.lstmf does not exist or is not readable
 >Failed loading language 'chi_sim_vert'

modify chi_sim.config file in langdata/chi_sim
and comment out first line related to loading of the vertical sub language  The documentation does not seem to specify the format of the text files required by the `train_listfile` option. Are there examples available of `eng.training_files.txt`?

 [eng.training_files.txt](https://github.com/tesseract-ocr/tesseract/files/957062/eng.training_files.txt)

Sample attached. File is created by the tesstrain.sh process. If on 'unix' you can try the following to create the file - 

`ls -1 *.lstmf > lang.training_files.txt`

You may need to give the path before *.lstmf or the next step will not find the files.
 The [line break](https://en.wikipedia.org/wiki/Newline) must be `\n`. This is what is inserted automatically when you hit the `Enter` key in the keyboard in Linux/macOS. In Windows it's by default `\r\n`, which will confuse Tesseract.

http://stackoverflow.com/questions/8195839/choose-newline-character-in-notepad Thanks @Shreeshrii, thanks @amitdo! 

This raises a new question: how do I generate `.lstfm` files? I'm trying Tesseract to train on [New York city directories](https://digitalcollections.nypl.org/items/b42866fb-b877-e4fc-e040-e00a1806275e), I have box files and TIFs. (Another question: can I already use `WordStr` box files, some parts of the documentation say I can, others say I can't?)

ZIP file with one TIF and box file I'm trying to use: [Wilson1852_0.zip](https://github.com/tesseract-ocr/tesseract/files/958420/Wilson1852_0.zip). Out of the box, Tesseract already performs pretty well, but 150 years ago, house numbers in New York sometimes included ½, so I have to include this character in the `desited_characters` file:

![image](https://cloud.githubusercontent.com/assets/1194896/25436113/477a23b6-2a60-11e7-967f-c4b97b21e3a9.png)


 WordStr box files are not yet supported (AFAIK).

If you have box files in 3.0 format, you can use jtessboxeditor to add the
end of line tab character and use them.

When I want to test using box/tiff pairs, I copy the files to the training
directory - by modifying tesstrain.sh.


mkdir -p ${TRAINING_DIR}
tlog "\n=== Starting training for language '${LANG_CODE}'"

#cp /home/shree/tesstutorial/larmbig/*.tif "${TRAINING_DIR}/"
#cp  /home/shree/tesstutorial/larmbig/*.box "${TRAINING_DIR}/"

Then use a command similar to following (based on location of your files)
and use just one font similar to the one used in your box/tiff pairs.

You may need to modify tesstrain_utils.sh to make sure that all your
box/tiff pairs are selected (based on the naming).

training/tesstrain.sh \
  --fonts_dir  /mnt/c/Windows/Fonts \
  --training_text ../langdata/eng/eng.training_text \
  --langdata_dir ../langdata \
  --tessdata_dir ./tessdata \
  --lang eng \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0" \
  --fontlist "Arial" \
  --output_dir ~/tesstutorial/engtest

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Apr 26, 2017 at 6:32 PM, Bert Spaan <notifications@github.com>
wrote:

> Thanks! This raises a new question: how do I generate .lstfm files? I'm
> trying Tesseract to train on New York city directories
> <https://digitalcollections.nypl.org/items/b42866fb-b877-e4fc-e040-e00a1806275e>,
> I have box files and TIFs. (Another question: can I already use WordStr
> box files, some parts of the documentation say I can, others say I can't?)
>
> ZIP file with TIF and box file I'm trying to use: Wilson1852_0.zip
> <https://github.com/tesseract-ocr/tesseract/files/958420/Wilson1852_0.zip>
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/841#issuecomment-297400009>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oxQuRa5kIoAXZ_0HyeRUZ_JPTZFzks5rz0CCgaJpZM4NIBJS>
> .
>
 What's the output for the 388½ in this example and in other places in this book? @amitdo 388½ becomes 3884. @Shreeshrii : but I have no `fonts_dir`, `fontlist`, etc, since I am only training from images. I'm afraid this way of training is not well documented right now.

I have not yet tried training with 4.00. @amitdo Is it not well documented, or not yet possible at all? @Shreeshrii Do you have examples of this process? Your box file is in wordstr format. That cannot be used with existing
process.

If you had box file in older 3.04  format, then the hacked version of
script would work.

- excuse the brevity, sent from mobile

On 26-Apr-2017 9:02 PM, "ShreeDevi Kumar" <shreeshrii@gmail.com> wrote:

> I will post my modified versions of the scripts tomorrow, don't have
> access to my pc right now.
>
> - excuse the brevity, sent from mobile
>
> On 26-Apr-2017 8:41 PM, "Bert Spaan" <notifications@github.com> wrote:
>
>> @Shreeshrii <https://github.com/Shreeshrii> Do you have examples of this
>> process?
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/841#issuecomment-297440803>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AE2_o0ChPIZezAouqzZA3thLi0m2ovFqks5rz16zgaJpZM4NIBJS>
>> .
>>
>
 I can provide a box file in 3.04 format tomorrow, I'll post the file here. As said, the WordStr format is not really supported right now.

You can still train with the regular box format + tab lines to signal line breaks.

Training from 'real' images as opposed to synthetic ones (with text2image), that what's not well documented.  >Out of the box, Tesseract already performs pretty well, but 150 years ago, house numbers in New York sometimes included ½, so I have to include this character in the desited_characters file:

@bertspaan the desired_characters file is not directly used for training. It is used at Google for building the large training text required for LSTM training.

I couldn't find any font which has 1/2 the way it is printed here, so it maybe difficult to create synthetic image for it.
 Update: The LSTM training process has been modified since this post was written. These will not work as is. You can use them as reference.
---------------------------------------

Here are the modified scripts:
[boxtrain.zip](https://github.com/tesseract-ocr/tesseract/files/961633/boxtrain.zip)
You will need to copy your box/tiff pairs to the 
../langdata/eng/ directory 
for them to be used.

You cannot use finetune process because 1/2 i not included in the unicharset for current LSTM traineddata for English. @theraysmith , will this change with your  next update?

The following commands outline the process you may need to follow to do the LSTM training - top layer.

```

training/boxtrain.sh \
  --fonts_dir  /mnt/c/Windows/Fonts \
  --training_text ../langdata/eng/nyd.training_text \
  --langdata_dir ../langdata \
  --tessdata_dir ./tessdata \
  --lang eng  \
  --exposures "-2 -1 0" \
  --fontlist "Century Schoolbook" "Dejavu Serif" "Garamond" "Liberation Serif" "Times New Roman," "FreeSerif" "Georgia" \
  --output_dir ~/tesstutorial/nydlegacy
  
cp ~/tesstutorial/nydlegacy/eng.traineddata ./tessdata/nydlegacy.traineddata

training/boxtrain.sh \
  --fonts_dir  /mnt/c/Windows/Fonts \
  --training_text ../langdata/eng/nyd.training_text \
  --langdata_dir ../langdata \
  --tessdata_dir ./tessdata \
  --lang eng \
  --linedata_only \
  --noextract_font_properties \
  --exposures "-2 -1" \
  --fontlist "Bookman Old Style Semi-Light"  \
  --output_dir ~/tesstutorial/nyd
  
rm -rf ~/tesstutorial/eng_from_nyd
mkdir -p ~/tesstutorial/eng_from_nyd

combine_tessdata -e ../tessdata/eng.traineddata \
   ~/tesstutorial/eng_from_nyd/eng.lstm

lstmtraining  \
   -U ~/tesstutorial/nyd/eng.unicharset \
  --train_listfile ~/tesstutorial/nyd/eng.training_files.txt \
  --script_dir ../langdata   \
  --append_index 5 --net_spec '[Lfx256 O1c105]' \
  --continue_from ~/tesstutorial/eng_from_nyd/eng.lstm \
  --model_output ~/tesstutorial/eng_from_nyd/nyd \
  --debug_interval -1 \
  --target_error_rate 0.01
   
lstmtraining \
  --continue_from ~/tesstutorial/eng_from_nyd/nyd_checkpoint \
  --model_output ~/tesstutorial/eng_from_nyd/nyd.lstm \
  --stop_training

cp ../tessdata/eng.traineddata ~/tesstutorial/eng_from_nyd/nyd.traineddata
   
combine_tessdata -o ~/tesstutorial/eng_from_nyd/nyd.traineddata \
  ~/tesstutorial/eng_from_nyd/nyd.lstm \
  ~/tesstutorial/nyd/eng.lstm-number-dawg \
  ~/tesstutorial/nyd/eng.lstm-punc-dawg \
  ~/tesstutorial/nyd/eng.lstm-word-dawg 
 
cp ~/tesstutorial/eng_from_nyd/nyd.traineddata ./tessdata/nyd.traineddata
``` Thanks so much, I will try all this next week! Also see https://github.com/nypl-spacetime/ocr-scripts
 @Shreeshrii: ha, that's my repository! @bertspaan

I see that you have trained models for ocropy.

Is there anything you want to share about ocropy vs. Tesseract 4.00, accuracy wise, with your dataset? 
  @amitdo: yes, we've trained ocropy on a very small amount of sentences, and already the results are pretty good. See [`1854-55.lines.ndjson.zip`](https://github.com/tesseract-ocr/tesseract/files/967991/1854-55.lines.ndjson.zip), this file contains all bounding boxes with ocropy output. However, ocropy sometimes crashes and its documentation is not too good, that's why last week we've started experimenting with Tesseract 4. I haven't compared out-of-the-box output of Tesseract 4 with our trained orcopy model in detail.

@Shreeshrii: ok, I'll try some of the commands you've posted here, but I'm not going to spend much time on trying to train Tesseract, I'll wait until training from scanned images is improved. 

We are also building dictionaries of possible names, streets and professions, so we should be able to fix many OCR errors afterwards.

Thank you both so much for your help! **@Shreeshrii** 
I am also trying to fine tune tesseract4.0 with images. I am confused by several parameters below.
First, what is the training_text(**nyd.training_text**) file? Do I need to create it? If yes, how to create it?
Second, do I just need to specify the **--training_text** and **--output_dir** while leaving other parameters unchanged?

![image](https://user-images.githubusercontent.com/3139202/29311921-f13a0ec0-81e5-11e7-9bf9-dce2272609ff.png)
 combine_lang_model which takes as input an input_unicharset and script_dir (script_dir points to the langdata directory) and optional word list files...
I have got input_unicharset, but I don't know how can I get script_dir . @Shreeshrii Thank you！
BUT
I really can't understand how can I create lstm files.
Can you show me the code.

I have tried:
tesseract eng.font.exp0.tif eng.font.exp0.box.lstm.train
But it gives:
Error during processing.
ObjectCache(0x7f098f0849a0)::~ObjectCache(): WARNING! LEAK! object 0x29173e0 still has count 1 (id /usr/local/tesseract/share/tessdata/eng.traineddatapunc-dawg)
ObjectCache(0x7f098f0849a0)::~ObjectCache(): WARNING! LEAK! object 0x2916420 still has count 1 (id /usr/local/tesseract/share/tessdata/eng.traineddataword-dawg)
ObjectCache(0x7f098f0849a0)::~ObjectCache(): WARNING! LEAK! object 0x2916240 still has count 1 (id /usr/local/tesseract/share/tessdata/eng.traineddatanumber-dawg)
 Training tutorial ? 
Do you mean [https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00](url)
but I just have tif/box pairs, so i come here for more information。 @Shreeshrii 
I want to use tesseract4.00 to recognize models of machines. All model information are combines whit characters and numbers and located in somewhere of nameplate, so I have collected lots of pictures which contains  various nameplate of each machine. 
After a series of processing, I have got lots pictures of model as follows:
![image](https://user-images.githubusercontent.com/22894599/29905526-d8207088-8e41-11e7-8a94-60661df186c8.png)
![image](https://user-images.githubusercontent.com/22894599/29905561-ff00a722-8e41-11e7-934d-8e87c61433df.png)
And then I put all model pictures into tesseract for recognize, but the accuracy is not so good, so I am trying to train teaaeract4.00 with model pictures.
The tesseract4.0 training tutorial said that there are two ways to create training data, and I use the first option: each line in the box file matches a 'character' (glyph) in the tiff image. 

If 4.0 training with tif/box pairs is not yet supported then how can I do to raise the accuracy?

 @minly, hello, I have the same problems with you ? have you resolved them? @CoCa520, hello, did you generate lstm files finally? I want to know how to generate lstm files according to  *.tif and *.box files? Bumping this..

I tried running the steps mentioned here: https://github.com/tesseract-ocr/tesseract/issues/841#issuecomment-298174100

I'm getting this error: 
```
ERROR: Non-existent flag -D
ERROR: /var/folders/vz/yqbfrgj91hqdj76mmpl2vjmw0000gn/T/tmp.W8q07ZtQ/eng/unicharset does not exist or is not readable
```
It does not create a `.traineddata`, which is what I expected from doing `--linedata_only` parameter..

I'll try to compare what edits @Shreeshrii put in place, but any guidance would be appreciated.

Edit:

[boxtrain.zip](https://github.com/tesseract-ocr/tesseract/files/1468814/boxtrain.zip)

I've diffed the three files to a version in April, grabbed the "intent" of @Shreeshrii 's edit, and applied it to the newest versions of the three files.

```
boxtrain/boxtrain.sh --fonts_dir ~/Library/Fonts/ --training_text ../langdata/eng/eng.training_text --langdata_dir ../langdata --tessdata_dir ./tessdata/ --lang eng --fontlist "Calibri" --output_dir ./lstm1
```
While editing, I saw that @Shreeshrii was creating a folder named "${LANG_DATA_DIR}/GT", and copying TIF/BOX in/out from it. I tried placing my TIF/BOX pairs in the "GT" folder, and to be honest I have no clarity on what the `.traineddata` contains .  Both 3.05 and latest git master produce unusable results with OpenCL (tested on Linux and macOS). It looks like that problem only occurs with [large images](https://digi.bib.uni-mannheim.de/~stweil/tesseract/0604.jp2).

Disabling OpenCL in `ccmain/thresholder.cpp` fixes the problem. #635
Maybe it's the right time to remove the OpenCL code entirely.

I have a feeling that you (Stefan) will disagree...  :)
 Indeed. :-)

Other projects using LSTM strive to use the computing power of graphic cards.

Should Tesseract be an exception because people are satisfied with the CPU based computation, should we try to fix the known problems of the current OpenCL based implementation and improve the code, or is there another solution how Tesseract can use advanced computing power? The problems I see with the OpenCL code:
It mostly duplicates parts of Leptonica, which is an **external** dependency.
It was contributed by someone from AMD. He does not keep maintaining it.
Google does not seem to want to invest time in maintaining it.
The only one that cares and tries to fix bugs is you.

 I respect your work, but I still think the benefit here is quite small and we should drop it.  

A compromise could be that you will maintain that code as a separate project and we will have an optional dependency on it. I tried to sell it to Dan but he didn't buy it :laughing: 
https://github.com/tesseract-ocr/tesseract/issues/635#issuecomment-270327486
Please read his answer. I removed a duplicated part of Leptonica in PR #843. Are there more of them? At least I no longer find a comment naming Leptonica in the OpenCL code. At least some with 'pix' in their names. pixSubtract for example. > I'd roughly guess that includes about a dozen methods.

Good guess. It's a little bit more. I'll send a pull request which reduces the code in `opencl` to less than 5300 lines. Ray's DAS 2014 tutorial, slides set 8 has some statistics about the OpenCL code. PR #849 now removes most of the TIFF related code. Maybe I can remove more in the future. >... reduces the code in opencl to less than 5300 lines.

>Maybe I can remove more in the future.

Only ~5300 lines left (to remove) ... :-) It's still used by one of the benchmarks. As soon as I'm sure that this benchmark is not needed, we'll make a large step in Amit's preferred direction (currently 5074 lines left). http://www.anandtech.com/show/10613/discrete-desktop-gpu-market-trends-q2-2016-amd-grabs-market-share-but-nvidia-remains-on-top

Benchmarks should done on intel's integrated GPU and NVIDIA's GPU.

I read somewhere a claim that the performance of OpenCL with NVIDIA card is significantly worst than with AMD cards.

Another claim is that OpenCL performance on Macs degraded significantly with the last macOS versions. Like NVIDIA, Apple now has an API which is competing with OpenCL. >Both 3.05 and latest git master produce unusable results with OpenCL (tested on Linux and macOS). It looks like that problem only occurs with large images.

Is the issue still exists ? Yes. At least I am not aware that anybody fixed it. Since you opened the issue, you dropped a lot of opencl code. Maybe the issue was related to that code? No, it is caused by one of the remaining (unchanged) OpenCL code blocks. An idea: Maybe you want to add an environment variable to disable opencl at **runtime**, similar to the openmp trick? That environment variable is already there: `TESSERACT_OPENCL_DEVICE`. Set it to the number of the "native device" (or to an illegal value: less than 1 or greater than the number of OpenCL devices) to disable OpenCL. Ok :-)   WordStr Box file option has been defined in the training wiki for 4.0 LSTM. However it is not yet implemented in the code.

This will be useful for using scanned images for training.

Thanks!

See related discussion at https://github.com/tesseract-ocr/tesseract/issues/591 See also https://github.com/tesseract-ocr/tesseract/issues/670#issuecomment-274275423 and below. +1

Even better would be a new line box format (`image1.linebox`).

Maybe something like this.

```
linebox left, top, right, bottom
text <t e x t h e r e>
linebox ...
text ...
```
@theraysmith, what do think about this idea?
 I don't know...   Please see the discussion at https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/b2YFzN7MtJg/dq1-f8JjBgAJ


> I'm pleased to say that I managed to get a build script that works using the following versions of the libs:

>LIBJPEG_VERSION=9b
ZLIB_VERSION=1.2.11
LIBPNG_VERSION=1.6.29
LEPTONICA_VERSION=1.71
TESSERACT_VERSION=3.04.01

>I couldn't get it to work with any later versions of Leptonica (1.74.1 is the latest) or Tesseract (3.05.00 is the latest v3).  See PR #835. It builds on Linux and macOS, see [Travis log](https://travis-ci.org/tesseract-ocr/tesseract/builds/224732278) for an example using `cmake`. My local test was successful with `configure` and `make`. @stweil Thanks, I will post in forum for the original poster to check once the PR is included.

>-- Looking for include file cairo/cairo-version.h
-- Looking for include file cairo/cairo-version.h - not found
-- Looking for include file CL/cl.h
-- Looking for include file CL/cl.h - not found
-- Looking for include file OpenCL/cl.h
-- Looking for include file OpenCL/cl.h - found
-- Looking for include file pango-1.0/pango/pango-features.h
-- Looking for include file pango-1.0/pango/pango-features.h - not found
-- Looking for include file tiffio.h
-- Looking for include file tiffio.h - found
-- Looking for include file unicode/uchar.h
-- Looking for include file unicode/uchar.h - not found

I am guessing that Travis build does not include training tools.

Do they build locally for you on Mac? Yes, Travis CI builds currently without the training part. Of course it is possible to add `make training` if that is considered necessary. Travis also does not cover builds based on the `autotools`, as it uses `cmake`.

> My local test was successful with configure and make.

`make training` also was successful on Mac. Tesseract 3.05 uses `PKG_CHECK_MODULES` to detect `pango` and `cairo`, this should be fairly robust. Closing this as @stweil confirms build on mac with the PR and there is no response from original poster. I had a look on that shell script. The published version does not work because it tries to build Tesseract without building the dependencies (libjpeg, zlib, libpng, leptonica) first. This can be easily fixed in the first lines of the script. Now it builds those dependencies. It also starts building Tesseract 3.05, but fails when linking the `tesseract` executable because of a missing symbol `_fmemopen` in liblept.

This problem is caused by an unusual build of Leptonica: instead of the normal configure / make, the script calls `./make-for-local` which uses a hand-built makefile (maybe made for Linux). I'm also surprised that TIFF support is disabled for the Leptonica build and doubt that this will work with Tesseract.

Building Tesseract with HomeBrew or MacPorts is much easier than with the shell script, and it simply works. End users who want to run Tesseract don't need HomeBrew or MacPorts. They only need some libraries which can be copied and distributed with the Tesseract executable. Even that can be avoided by adding linker flags to use static linkage. See [here](http://digi.bib.uni-mannheim.de/tesseract/mac_standalone/) for a [modified build script](http://digi.bib.uni-mannheim.de/tesseract/mac_standalone/mac_standalone_tesseract_build_script) which produced a [stand-alone `tesseract` for macOS](http://digi.bib.uni-mannheim.de/tesseract/mac_standalone/tesseract). The [build protocol](http://digi.bib.uni-mannheim.de/tesseract/mac_standalone/build.txt) shows some remaining errors, like a wrong URL for getting the language model files. Thanks Stefan.  Actually the shell script does build the dependencies first if you turn on the switches at the start. They are set to 0 or 1 depending on whether you're trying to rebuild/build some or all of them.  If you set them all to 1, the dependencies are built in the order libjpeg, zlib, libpng, leptonica, followed by tesseract.

I found the original script on github and modified it minimally since I didn't understand it fully. The unusual Leptonica build has come directly from that original script. I didn't understand this, so I left it as I found it!

I agree that HomeBrew/MacPorts is much easier if you are an IT person, but my users are analytical chemists or linguists, etc. who just want to run an app. The coding system I use (LiveCode) generates executables that can be run from anywhere without any installation, you just place the folder containing the app and any supporting files/folders wherever you like (e.g. the desktop for short term use).  I don't want the user to have to run an install process, either directly, or by my app doing an initial install on 1st run.

For Windows users there's a portable Tesseract readily available that works as I intended.  For Mac users, there isn't, which is why I looked for and found the shell script that seemed to offer the prospect of generating a portable Tesseract for Mac users.

You mention that it's possible to generate Tesseract using HomeBrew/MacPorts and then "some libraries can be copied & distributed".  Can you tell me exactly which libraries and where they need to be copied to.  Also, would this mean copying libraries to areas outside the user's filing system, i.e. system areas.  If so this would require admin permissions which I can't rely on being available (sometime my users have locked-down computers).  The shell script can generate a portable Tesseract that is located simply by setting 2 environment variables.  I've tested this and it works for my purposes for both JPEG and PNG graphics, which are all I need. However, I'd happily add TIFF support if I knew how to do it!

Thanks again.

Peter. > You mention that it's possible to generate Tesseract using HomeBrew/MacPorts and then "some libraries can be copied & distributed". Can you tell me exactly which libraries and where they need to be copied to. Also, would this mean copying libraries to areas outside the user's filing system, i.e. system areas.

You need to copy all shared libraries which are required by the `tesseract` executable. When you try to run it, macOS will tell you which shared library is missing (only first missing, so repeat until you have found all of them). With MacPorts for example, this means copying 15 files from `/opt/local/lib/*.dylib` (`liblept.5.dylib`, ...). You can choose any destination directory. By setting the environment variable DYLD_LIBRARY_PATH to that directory, Tesseract can find the shared libraries. Thanks Stefan, your suggestion works well.  I did the following:
1. using Terminal, install Tesseract using HomeBrew
2. copy the folder "3.05.001" from /usr/local/Cellar/tesseract into a folder on my desktop called "tessport"
3. created a test shell script "tesseract_test.sh":
    #!/bin/bash
    export TESSDATA_PREFIX=/Users/peter/Desktop/tessport/share
    export DYLD_LIBRARY_PATH=/Users/peter/Desktop/tessport/lib
    tessport/bin/tesseract -v
4. ran the test shell script "tesseract_test.sh" to confirm it works
5. uninstalled Tesseract using HomeBrew
6. re-an the test shell script "tesseract_test.sh" to confirm it still works

So I now have a recipe for generating the latest Tesseract in portable form for the Mac!

Thanks again.

Peter  Command below results in a segmentation fault
tesseract a.jpg stdout --oem 1 --psm 0 -l eng  

Environment details:
Which operating system - Ubuntu 16.10 Yakkety Yak on x86_64
Which version/commit of tesseract - top of Changelog says 2017-03-24 - v4.00.00-alpha
How was tesseract built or - I compiled it from source

Command above works with --psm 3 is used instead.

Pritam Dodeja Try `tesseract a.jpg stdout --oem 0 --psm 0 -l eng`
 Also try with this image:
https://github.com/tesseract-ocr/tesseract/raw/master/testing/phototest.tif Find below

 tesseract phototest.tif stdout --oem 0 --psm 0 -l eng
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
Page 1
Page number: 0
Orientation in degrees: 0
Rotate: 0
Orientation confidence: 15.98
Script: Latin
Script confidence: 460.00

tesseract phototest.tif stdout --oem 1 --psm 0 -l eng
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
Page 1
Segmentation fault (core dumped)

tesseract phototest.tif stdout --oem 1 --psm 3 -l eng
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
TIFFFetchNormalTag: Warning, ASCII value for tag "Photoshop" does not end in null byte. Forcing it to be null.
Page 1
This is a lot of 12 point text to test the
ocr code and see if it works on all types
of file format.

The quick brown dog jumped over the
lazy fox. The quick brown dog jumped
over the lazy fox. The quick brown dog
jumped over the lazy fox. The quick
brown dog jumped over the lazy fox.

Pritam


 The warnings are ugly but seem harmless.

With `--oem 0` and `--psm 0` Tesseract works as expected.

With `--oem 1` and `--psm 0` Tesseract segfault.
The reason - the new LSTM engine has no OSD feature **currently**, only the older engine has it.

For now, the solution is to always use `--oem 0` when using `--psm 0` BTW, you should use `osd` instead of `eng` with `--psm 0`.


Using `eng` will result in always detecting `Latin` as the script, even if the text is written in another script. From what I have read, tesseract v4 greatly improves ocr due to LSTM.  If I know that my text is going to be of a certain orientation and script  (top to bottom and English), how do I take advantage of the newer engine?  Thanks for the help and sorry for the delay in my response. The 4.00 version is in alpha stage. It's not yet considered ready to replace the stable 3.05 version.
There is a plan to add an OSD feature to the LSTM engine. Is there any update on this?  Let me know if you want me to do any testing etc.  Thanks! I'm sorry, but there is no update on this issue. try this:

>tesseract in.png out **-l osd** --psm 0 --oem 0  Hello All,

I want to train tesseract as [](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Finetune), But I got this error, Any help
```
 tesstrain.sh --fonts_dir /usr/share/fonts --lang ara  --training_text ../../tesserac-ocr/langdata/ara.training_text   --langdata_dir ../langdata --tessdata_dir ./tessdata   --fontlist "Arial"   --output_dir ~/tesstutorial/aratest
=== Starting training for language 'ara'
[ر أبر 12 07:48:58 EET 2017] /usr/bin/text2image --fonts_dir=/usr/share/fonts --font=Arial --outputbase=/tmp/font_tmp.Rj3QkZFztb/sample_text.txt --text=/tmp/font_tmp.Rj3QkZFztb/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.Rj3QkZFztb
Rendered page 0 to file /tmp/font_tmp.Rj3QkZFztb/sample_text.txt.tif

=== Phase I: Generating training images ===
Rendering using Arial
[ر أبر 12 07:49:17 EET 2017] /usr/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.Rj3QkZFztb --fonts_dir=/usr/share/fonts --strip_unrenderable_words --fontconfig_refresh_config_file=false --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.XBcy4TVQwb/ara/ara.Arial.exp0 --font=Arial --text=../../tesserac-ocr/langdata/ara.training_text
ERROR: Non-existent flag --fontconfig_refresh_config_file=false
ERROR: /tmp/tmp.XBcy4TVQwb/ara/ara.Arial.exp0.box does not exist or is not readable
ERROR: /tmp/tmp.XBcy4TVQwb/ara/ara.Arial.exp0.box does not exist or is not readable
``` --training_text ../../tesserac-ocr/langdata/ara.training_text 

is there a typo in your folder name tesserac instead of tesseract?

 is my folder name  ```
$ training/tesstrain.sh  \
   --fonts_dir /usr/share/fonts/ \
  --lang ara   \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --langdata_dir ../langdata \
  --tessdata_dir ../tessdata  \
  --output_dir ~/tesstutorial/ara  \
  --fontlist "Arial"

=== Starting training for language 'ara'
[Wed Apr 12 14:55:47 DST 2017] /usr/local/bin/text2image --fonts_dir=/usr/share/fonts/ --font=Arial --outputbase=/tmp/font_tmp.OIUrMxATnl/sample_text.txt --text=/tmp/f
ont_tmp.OIUrMxATnl/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.OIUrMxATnl
Rendered page 0 to file /tmp/font_tmp.OIUrMxATnl/sample_text.txt.tif

=== Phase I: Generating training images ===
Rendering using Arial
[Wed Apr 12 14:56:35 DST 2017] /usr/local/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.OIUrMxATnl --fonts_dir=/usr/share/fonts/ --strip_unrenderable_words --leadin
g=32 --xsize=2550 --ptsize=16 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0 --font=Arial --text=../langdata/ara/ara.training_text
0
Rendered page 0 to file /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.tif
/tmp/tmp.xPjs35P5oP/ara/gt/ara.Arial.exp0.txt

=== Phase UP: Generating unicharset and unichar properties files ===
[Wed Apr 12 14:56:38 DST 2017] /usr/local/bin/unicharset_extractor -D /tmp/tmp.xPjs35P5oP/ara/ /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.box
Extracting unicharset from /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.box
Wrote unicharset file /tmp/tmp.xPjs35P5oP/ara//unicharset.
[Wed Apr 12 14:56:39 DST 2017] /usr/local/bin/set_unicharset_properties -U /tmp/tmp.xPjs35P5oP/ara/ara.unicharset -O /tmp/tmp.xPjs35P5oP/ara/ara.unicharset -X /tmp/tmp
.xPjs35P5oP/ara/ara.xheights --script_dir=../langdata
Loaded unicharset of size 187 from file /tmp/tmp.xPjs35P5oP/ara/ara.unicharset
Setting unichar properties
Writing unicharset to file /tmp/tmp.xPjs35P5oP/ara/ara.unicharset

=== Phase D: Generating Dawg files ===
Generating word Dawg
[Wed Apr 12 14:56:41 DST 2017] /usr/local/bin/wordlist2dawg -r 1 ../langdata/ara/ara.wordlist /tmp/tmp.xPjs35P5oP/ara/ara.word-dawg /tmp/tmp.xPjs35P5oP/ara/ara.unichar
set
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.xPjs35P5oP/ara/ara.unicharset'
Reading word list from '../langdata/ara/ara.wordlist'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.xPjs35P5oP/ara/ara.word-dawg'
Generating frequent-word Dawg
[Wed Apr 12 14:56:46 DST 2017] /usr/local/bin/wordlist2dawg -r 1 /tmp/tmp.xPjs35P5oP/ara/ara.wordlist.clean.freq /tmp/tmp.xPjs35P5oP/ara/ara.freq-dawg /tmp/tmp.xPjs35P
5oP/ara/ara.unicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.xPjs35P5oP/ara/ara.unicharset'
Reading word list from '/tmp/tmp.xPjs35P5oP/ara/ara.wordlist.clean.freq'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.xPjs35P5oP/ara/ara.freq-dawg'
[Wed Apr 12 14:56:47 DST 2017] /usr/local/bin/wordlist2dawg -r 2 ../langdata/ara/ara.punc /tmp/tmp.xPjs35P5oP/ara/ara.punc-dawg /tmp/tmp.xPjs35P5oP/ara/ara.unicharset
Set reverse_policy to RRP_FORCE_REVERSE
Loading unicharset from '/tmp/tmp.xPjs35P5oP/ara/ara.unicharset'
Reading word list from '../langdata/ara/ara.punc'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.xPjs35P5oP/ara/ara.punc-dawg'
[Wed Apr 12 14:56:47 DST 2017] /usr/local/bin/wordlist2dawg -r 0 ../langdata/ara/ara.numbers /tmp/tmp.xPjs35P5oP/ara/ara.number-dawg /tmp/tmp.xPjs35P5oP/ara/ara.unicha
rset
Set reverse_policy to RRP_DO_NO_REVERSE
Loading unicharset from '/tmp/tmp.xPjs35P5oP/ara/ara.unicharset'
Reading word list from '../langdata/ara/ara.numbers'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.xPjs35P5oP/ara/ara.number-dawg'
[Wed Apr 12 14:56:47 DST 2017] /usr/local/bin/wordlist2dawg -r 1 ../langdata/ara/ara.word.bigrams /tmp/tmp.xPjs35P5oP/ara/ara.bigram-dawg /tmp/tmp.xPjs35P5oP/ara/ara.u
nicharset
Set reverse_policy to RRP_REVERSE_IF_HAS_RTL
Loading unicharset from '/tmp/tmp.xPjs35P5oP/ara/ara.unicharset'
Reading word list from '../langdata/ara/ara.word.bigrams'
Reducing Trie to SquishedDawg
Writing squished DAWG to '/tmp/tmp.xPjs35P5oP/ara/ara.bigram-dawg'

=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=../tessdata
[Wed Apr 12 14:57:00 DST 2017] /usr/local/bin/tesseract /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.tif /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0 lstm.train ../langdata/ara/ar
a.config
Tesseract Open Source OCR Engine v4.00.00alpha-361-g1477e17 with Leptonica
Page 1

=== Constructing LSTM training data ===
Creating new directory /home/shree/tesstutorial/ara
Copying ../langdata/ara/ara.config to /home/shree/tesstutorial/ara
Moving /tmp/tmp.xPjs35P5oP/ara/ara.unicharset to /home/shree/tesstutorial/ara
Moving /tmp/tmp.xPjs35P5oP/ara/ara.number-dawg to /home/shree/tesstutorial/ara/ara.lstm-number-dawg
Moving /tmp/tmp.xPjs35P5oP/ara/ara.punc-dawg to /home/shree/tesstutorial/ara/ara.lstm-punc-dawg
Moving /tmp/tmp.xPjs35P5oP/ara/ara.word-dawg to /home/shree/tesstutorial/ara/ara.lstm-word-dawg
Moving /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.box to /home/shree/tesstutorial/ara
Moving /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.tif to /home/shree/tesstutorial/ara
Moving /tmp/tmp.xPjs35P5oP/ara/ara.Arial.exp0.lstmf to /home/shree/tesstutorial/ara
Moving /tmp/tmp.xPjs35P5oP/ara/gt/ara.Arial.exp0.txt to /home/shree/tesstutorial/ara

Completed training for language 'ara'

shree@ALL-IN-1-TOUCH:/mnt/c/Users/User/shree/tesseract-ocr$
``` @Shreeshrii Thanks a lot, one more question please to get full understanding of it` --langdata_dir` parameter is the directory of https://github.com/tesseract-ocr/langdata/tree/master/ara 
again thanks for replying! Put Arabic langdata files under ara folder in langdata - similar to 
https://github.com/tesseract-ocr/langdata

so that you have

./langdata
./langdata/ara
./tessdata
./tesseract
./tesseract/tessdata
./tesseract/training

etc



 I got it, Thanks @Shreeshrii  Shree, please redirect people that ask questions about the training process to the forum.

Thanks!   Hello,@Shreeshrii 
I have the same problem like @am0awad . 

```
 training/tesstrain.sh  \
  --fonts_dir /Library/Fonts \
  --lang chi_sim   \
  --linedata_only \
  --noextract_font_properties \
  --exposures "0"    \
  --langdata_dir ./langdata \
  --tessdata_dir ./tessdata  \
  --output_dir ./tesstutorial/chi_sim 
```

I have already download the [https://github.com/tesseract-ocr/langdata](url) to my folder, and I have all the folders:

./langdata
./langdata/chi_sim 
./tessdata
 
but I still got this:
```
=== Starting training for language 'chi_sim'
mktemp: illegal option -- -
usage: mktemp [-d] [-q] [-t prefix] [-u] template ...
       mktemp [-d] [-q] [-u] -t prefix 
training/tesstrain_utils.sh: line 189: /sample_text.txt: Permission denied
[2017年 8月 3日 星期四 15时23分24秒 CST] /usr/local/bin/text2image --fonts_dir=/Library/Fonts --font=AR PL UKai CN Light --outputbase=/sample_text.txt --text=/sample_text.txt --fontconfig_tmpdir=

=== Phase I: Generating training images ===
Rendering using Arial Unicode MS
Rendering using AR PL UKai CN Light
[2017年 8月 3日 星期四 15时23分25秒 CST] /usr/local/bin/text2image --fontconfig_tmpdir= --fonts_dir=/Library/Fonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.AR_PL_UKai_CN_Light.exp0 --font=AR PL UKai CN Light --text=./langdata/chi_sim/chi_sim.training_text
[2017年 8月 3日 星期四 15时23分25秒 CST] /usr/local/bin/text2image --fontconfig_tmpdir= --fonts_dir=/Library/Fonts --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.Arial_Unicode_MS.exp0 --font=Arial Unicode MS --text=./langdata/chi_sim/chi_sim.training_text
ERROR: /var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.Arial_Unicode_MS.exp0.box does not exist or is not readable
ERROR: /var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.AR_PL_UKai_CN_Light.exp0.box does not exist or is not readable
ERROR: /var/folders/br/xq_2dfh91y1gdd90lny2501w0000gn/T/tmp.NTXG7RhZ/chi_sim/chi_sim.AR_PL_UKai_CN_Light.exp0.box does not exist or is not readable
```

Would anyone like to help me?

Thank you very much!

 Thank you @Shreeshrii I solved my problem by your help! Thank you very much! @Shreeshrii at Phase I,  I got this error:
Rendered page 2 to file /tmp/tmp.GZVqm2mm3D/fas/fas.Times_New_Roman.exp0.tif
Null box at index 0
Error: Call PrepareToWrite before WriteTesseractBoxFile!!
 but the process did not stop. and it got this error:
ERROR: /tmp/tmp.GZVqm2mm3D/fas/fas.Times_New_Roman.exp0.lstmf does not exist or is not readable
probably, the problem is in the very first phase. would you please help me solve it? yes. you're right. in fact, there are just numbers and some marks in tif
file. why is that happening?

On Tue, Oct 17, 2017 at 5:29 PM, Shreeshrii <notifications@github.com>
wrote:

> Look at the tif file in question in tmp folder. Looks like first line has
> nulls in it.
>
> On 17-Oct-2017 5:59 PM, "hanikh" <notifications@github.com> wrote:
>
> > @Shreeshrii <https://github.com/shreeshrii> at Phase I, I got this
> error:
> > Rendered page 2 to file /tmp/tmp.GZVqm2mm3D/fas/fas.
> > Times_New_Roman.exp0.tif
> > Null box at index 0
> > Error: Call PrepareToWrite before WriteTesseractBoxFile!!
> > but the process did not stop. and it got this error:
> > ERROR: /tmp/tmp.GZVqm2mm3D/fas/fas.Times_New_Roman.exp0.lstmf does not
> > exist or is not readable
> > probably, the problem is in the very first phase. would you please help
> me
> > solve it?
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/819#
> issuecomment-337215631>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_o0n0rSz-
> Z9XhUN2g4ge8DsQXIZi9ks5stJ25gaJpZM4M6-yu>
> > .
> >
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/819#issuecomment-337240137>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiASKi4zAcvT6hL8SkvIybrnjQVMWrks5stLLOgaJpZM4M6-yu>
> .
>
 Times New Roman is in the list of Persian fonts in
training/language_specific.sh. Doesn’t it mean that the Farsi trained model
is trained for Times New Roman?Or the listed fonts are just recommended?

On Wed, Oct 18, 2017 at 5:56 AM, Shreeshrii <notifications@github.com>
wrote:

> Does Times New Roman font support Farsi? You should use fonts that have
> support for your training_text language.
>
> ShreeDevi
> ____________________________________________________________
> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>
>
> On Tue, Oct 17, 2017 at 9:13 PM, hanikh <notifications@github.com> wrote:
>
> > yes. you're right. in fact, there are just numbers and some marks in tif
> > file. why is that happening?
> >
> > On Tue, Oct 17, 2017 at 5:29 PM, Shreeshrii <notifications@github.com>
> > wrote:
> >
> > > Look at the tif file in question in tmp folder. Looks like first line
> has
> > > nulls in it.
> > >
> > > On 17-Oct-2017 5:59 PM, "hanikh" <notifications@github.com> wrote:
> > >
> > > > @Shreeshrii <https://github.com/shreeshrii> at Phase I, I got this
> > > error:
> > > > Rendered page 2 to file /tmp/tmp.GZVqm2mm3D/fas/fas.
> > > > Times_New_Roman.exp0.tif
> > > > Null box at index 0
> > > > Error: Call PrepareToWrite before WriteTesseractBoxFile!!
> > > > but the process did not stop. and it got this error:
> > > > ERROR: /tmp/tmp.GZVqm2mm3D/fas/fas.Times_New_Roman.exp0.lstmf does
> not
> > > > exist or is not readable
> > > > probably, the problem is in the very first phase. would you please
> help
> > > me
> > > > solve it?
> > > >
> > > > —
> > > > You are receiving this because you were mentioned.
> > > > Reply to this email directly, view it on GitHub
> > > > <https://github.com/tesseract-ocr/tesseract/issues/819#
> > > issuecomment-337215631>,
> > > > or mute the thread
> > > > <https://github.com/notifications/unsubscribe-auth/AE2_o0n0rSz-
> > > Z9XhUN2g4ge8DsQXIZi9ks5stJ25gaJpZM4M6-yu>
> > > > .
> > > >
> > >
> > > —
> > > You are receiving this because you commented.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/819#
> > issuecomment-337240137>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/
> > AZFiASKi4zAcvT6hL8SkvIybrnjQVMWrks5stLLOgaJpZM4M6-yu>
> > > .
> > >
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/819#
> issuecomment-337269936>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_
> o5yHcKCu2plw2oV9eKheXyc1opAYks5stMsagaJpZM4M6-yu>
>
> > .
> >
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/819#issuecomment-337441751>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAXjsDJTN8DS85eiZHWvQF07HIP6Tks5stWHigaJpZM4M6-yu>
> .
>
  The docker image fails to build. Host is Ubuntu 16.04.

The following commands were used to start the build:

```
git clone https://github.com/tesseract-ocr/tesseract.git
cd tesseract
sudo docker build -t docker-tesseract .
```

Error message:

```
$ cmake .. -DLeptonica_DIR=leptonica-$LEPT_VER/build
CMake Error at /usr/share/cmake-3.7/Modules/CMakeDetermineCCompiler.cmake:48 (message):
  Could not find compiler set in environment variable CC:

  gcc-4.8.
Call Stack (most recent call first):
  CMakeLists.txt:47 (project)


CMake Error: CMAKE_C_COMPILER not set, after EnableLanguage
CMake Error: CMAKE_CXX_COMPILER not set, after EnableLanguage
-- Configuring incomplete, errors occurred!
See also "/root/build/tesseract-ocr/tesseract/build/CMakeFiles/CMakeOutput.log".

travis_time:end:0b3c16ed:start=1491933375378626936,finish=1491933375393151695,du
The command "cmake .. -DLeptonica_DIR=leptonica-$LEPT_VER/build" exited with 1.
$ make
make: *** No targets specified and no makefile found.  Stop.

travis_time:end:2a97cb84:start=1491933375396141259,finish=1491933375399900930,du
The command "make" exited with 2.

``` CC: @ianblenke (#282) try HTTPS://hub.Docker.com/r/xlight/docker-tesseract4

Amit D. <notifications@github.com>于2017年4月12日 周三上午2:12写道：

> CC: @ianblenke <https://github.com/ianblenke> (#282
> <https://github.com/tesseract-ocr/tesseract/pull/282>)
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/817#issuecomment-293351663>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAEwV2cLDv__GLLZZ8hph0Splbm3iXjQks5ru8KDgaJpZM4M6coZ>
> .
>
 https://github.com/xlight/docker-tesseract4/blob/master/Dockerfile

@xlight,

Why the `--enable-debug`? With this option Tesseract will be compiled with `-O0` and will be VERY slow. It's not a good idea to use it with a docker image. @amitdo why do you say that it is not a good idea? I built it with enable debug , because I want to know the reason why lstmtraining with eval_listfile coredump.
But It does not help  >why do you say that it is not a good idea?

Because of its slowness. I think that users of Docker Hub images expect to get an optimized build, not a debug one.   Ah oh course. I tried without but I am getting the issue 893...
Btw thx to @xlight for his docker file. I just added the download and move of some traineddata. @stweil, can you fix it? >The docker image fails to build. Host is Ubuntu 16.04.

The file `Dockerflle` in our repo is still not fixed.

Maybe we should remove this file (and `docker-compose.yml`).  It supposed to be used by users that want docker image of Tesseract.

I think we should remove it from our repo.  The Dockerfile configures a Docker container which builds Tesseract using the Travis configuration, so it can be used to locally test problems with that configuration (only the Linux part, not the macOS part). I can fix it, but that needs some time. >I can fix it, but that needs some time.

OK. If you plan to fix it, we can keep it. See pull request #932 for a fix. Does your PR solves the OP issue?

>CMake Error at /usr/share/cmake-3.7/Modules/CMakeDetermineCCompiler.cmake:48 (message):
>  Could not find compiler set in environment variable CC:
>
>  gcc-4.8. @benstadin, could you please retry your docker build with the changes from #932?

@amitdo, I did not get the same error message initially, therefore I don't know. The `Dockerfile` uses the master branch of https://github.com/travis-ci/travis-build. If there is an issue with that latest version, it might damage the docker build process. I looked for a stable version of `travis-build`, but the latest release was made in 2014.  Hello,
Using tesseract v3.04.01 on Fedora 25, a standard transformation like
```tesseract somefile.png pdf -l eng > output 2> error```
will write ```Tesseract Open Source OCR Engine v3.04.01 with Leptonica``` to error file even if the transformation worked as expected.
tesseract v3.02 on Ubuntu 12.04.5 writes to stdout instead of stderr.

Regards,
Ozy.  Hello!

Latest Tesseract version built from GIT with mingw-w64-i686 toolchain (gcc/g++ 6.2.0) crashes when run on Windows XP 32 bit (confirmed both for SP2 and SP3 OS versions). It crashes after several seconds of image processing and shows standard Windows dialog with this error text: "Exception unknow software exception (0xc000001d) in application at address 0x655b25f0".

On Windows 7 and 8 (x64) same images are recognized fine without any issues. I'm afraid that nobody will care about support for a Windows version which was abandoned by MS [three years ago](https://www.microsoft.com/en-us/windowsforbusiness/end-of-xp-support).  Does Tesseract on Windows 7/8 **32 bit** work well or crash too?  Tesseract version built from GIT with mingw-w64-i686 toolchain (gcc/g++ 6.2.0)

Does it have to be built with special flags for win32? There is currently not enough information for this issue report: As far as I know, 0xc000001d means illegal instruction. So the program is running machine code which is not defined for that machine. This could be caused by a program bug, or code and hardware simply don't fit.

* What is the hardware used for the tests (exact CPU models)? I assume that the tests with different versions of Windows also used different hardware. This problem could be eliminated by always using the same hardware (or a well defined virtual machine).

* Does Tesseract try to use SSE or AVX? Run `tesseract -v` to check that.

* More details on the build process are needed (cross or native build, origin of toolchain, exact commands used for build, build protocol).

What about running Tesseract under control of a debugger like gdb for Windows? Then the debugger would show the illegal instruction. > Does it have to be built with special flags for win32?

No, no special flags are needed for win32. My 32 and 64 bit builds for Windows only differ in the prefix for build tools and installation:

    ./configure --host=i686-w64-mingw32 --prefix=/usr/i686-w64-mingw32 && make
    ./configure --host=x86_64-w64-mingw32 --prefix=/usr/x86_64-w64-mingw32 && make
 Thank you all for respose! I'm well aware of the fact that XP is quite outdated OS, but some people still prefere to use it despite troubles with outdated drivers etc. If it would take too much effort to fix it then it probably doesn't worth it. But if there is a chance of fixing it without going too deep in debug process then it would be great.

Now in order of questions:

1) It works just fine on Windows 7 32 bit, no crashes at all. On the very same PC it crashes constanly under XP 32 bit.

2) 1st crash machine: Intel Core i3-2120 3.30GHz.
2nd crash machine: Intel Core i5 3570 3.4 GHz (OS run under VirtualBox Version 5.1.18 r 114002(Qt5.6.2)).

3) tesseract -v:

> tesseract 4.00.00alpha
>  leptonica-1.74.1
>   libgif 5.1.4 : libjpeg 8d (libjpeg-turbo 1.5.1) : libpng 1.6.26 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.6.0
> 
>  Found AVX
>  Found SSE

4) Build is done under Windows 8 64 bit using latest MSYS2 (https://sourceforge.net/projects/msys2/) distributive, updated with "pacman -Syuu" to get latest leptonica version.

Configure call:

> sh configure MAKE=mingw32-make --prefix=C:/atlas-sdk/msys32/mingw32 --disable-graphics --enable-static=no --enable-debug

Configure output:

> configure: loading site script C:/atlas-sdk/msys32/mingw32/etc/config.site
> checking for g++... g++
> checking whether the C++ compiler works... yes
> checking for C++ compiler default output file name... a.exe
> checking for suffix of executables... .exe
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ accepts -g... yes
> checking for a BSD-compatible install... /usr/bin/install -c
> checking whether build environment is sane... yes
> checking for a thread-safe mkdir -p... /usr/bin/mkdir -p
> checking for gawk... gawk
> checking whether mingw32-make sets $(MAKE)... yes
> checking for style of include used by mingw32-make... GNU
> checking whether mingw32-make supports nested variables... yes
> checking dependency style of g++... gcc3
> checking whether to enable maintainer-specific portions of Makefiles... no
> checking build system type... i686-w64-mingw32
> checking host system type... i686-w64-mingw32
> checking whether C++ compiler accepts -mavx... yes
> checking whether C++ compiler accepts -msse4.1... yes
> checking --enable-graphics argument... no
> checking --enable-embedded argument... no
> checking for g++ option to support OpenMP... -fopenmp
> checking --enable-opencl argument... no
> checking how to run the C++ preprocessor... g++ -E
> checking for grep that handles long lines and -e... /usr/bin/grep
> checking for egrep... /usr/bin/grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking CL/cl.h usability... no
> checking CL/cl.h presence... no
> checking for CL/cl.h... no
> checking OpenCL/cl.h usability... no
> checking OpenCL/cl.h presence... no
> checking for OpenCL/cl.h... no
> checking tiffio.h usability... yes
> checking tiffio.h presence... yes
> checking for tiffio.h... yes
> checking for clGetPlatformIDs in -lOpenCL... no
> checking --enable-visibility argument... no
> checking --enable-multiple-libraries argument... no
> checking whether to use tessdata-prefix... yes
> checking whether to enable debugging... yes
> checking how to print strings... printf
> checking for gcc... gcc
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> checking whether gcc understands -c and -o together... yes
> checking dependency style of gcc... gcc3
> checking for a sed that does not truncate output... /usr/bin/sed
> checking for fgrep... /usr/bin/grep -F
> checking for ld used by gcc... C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe
> checking if the linker (C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe) is GNU ld... yes
> checking for BSD- or MS-compatible name lister (nm)... /mingw32/i686-w64-mingw32/bin/nm -B
> checking the name lister (/mingw32/i686-w64-mingw32/bin/nm -B) interface... BSD nm
> checking whether ln -s works... no, using cp -pR
> checking the maximum length of command line arguments... 8192
> checking how to convert i686-w64-mingw32 file names to i686-w64-mingw32 format... func_convert_file_msys_to_w32
> checking how to convert i686-w64-mingw32 file names to toolchain format... func_convert_file_msys_to_w32
> checking for C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe option to reload object files... -r
> checking for objdump... objdump
> checking how to recognize dependent libraries... file_magic ^x86 archive import|^x86 DLL
> checking for dlltool... dlltool
> checking how to associate runtime and link libraries... func_cygming_dll_for_implib
> checking for ar... ar
> checking for archiver @FILE support... @
> checking for strip... strip
> checking for ranlib... ranlib
> checking command to parse /mingw32/i686-w64-mingw32/bin/nm -B output from gcc object... ok
> checking for sysroot... no
> checking for a working dd... /usr/bin/dd
> checking how to truncate binary pipes... /usr/bin/dd bs=4096 count=1
> checking for mt... no
> checking if : is a manifest tool... no
> checking for dlfcn.h... no
> checking for objdir... .libs
> checking if gcc supports -fno-rtti -fno-exceptions... no
> checking for gcc option to produce PIC... -DDLL_EXPORT -DPIC
> checking if gcc PIC flag -DDLL_EXPORT -DPIC works... yes
> checking if gcc static flag -static works... yes
> checking if gcc supports -c -o file.o... yes
> checking if gcc supports -c -o file.o... (cached) yes
> checking whether the gcc linker (C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe) supports shared libraries... yes
> checking whether -lc should be explicitly linked in... yes
> checking dynamic linker characteristics... Win32 ld.exe
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... no
> checking how to run the C++ preprocessor... g++ -E
> checking for ld used by g++... C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe
> checking if the linker (C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe) is GNU ld... yes
> checking whether the g++ linker (C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe) supports shared libraries... yes
> checking for g++ option to produce PIC... -DDLL_EXPORT -DPIC
> checking if g++ PIC flag -DDLL_EXPORT -DPIC works... yes
> checking if g++ static flag -static works... yes
> checking if g++ supports -c -o file.o... yes
> checking if g++ supports -c -o file.o... (cached) yes
> checking whether the g++ linker (C:/atlas-sdk/msys32/mingw32/i686-w64-mingw32/bin/ld.exe) supports shared libraries... yes
> checking dynamic linker characteristics... Win32 ld.exe
> checking how to hardcode library paths into programs... immediate
> checking whether byte ordering is bigendian... no
> checking if compiling with clang... no
> checking whether compiler supports C++11... yes
> checking for snprintf... yes
> checking for library containing sem_init... none required
> checking for ANSI C header files... (cached) yes
> checking whether time.h and sys/time.h may both be included... yes
> checking for sys/wait.h that is POSIX.1 compatible... no
> checking sys/ipc.h usability... no
> checking sys/ipc.h presence... no
> checking for sys/ipc.h... no
> checking sys/shm.h usability... no
> checking sys/shm.h presence... no
> checking for sys/shm.h... no
> checking limits.h usability... yes
> checking limits.h presence... yes
> checking for limits.h... yes
> checking malloc.h usability... yes
> checking malloc.h presence... yes
> checking for malloc.h... yes
> checking for stdbool.h that conforms to C99... no
> checking for _Bool... no
> checking whether #! works in shell scripts... yes
> checking for special C compiler options needed for large files... no
> checking for _FILE_OFFSET_BITS value needed for large files... 64
> checking for getline... no
> checking for wchar_t... yes
> checking for long long int... yes
> checking for off_t... yes
> checking for mbstate_t... yes
> checking for pkg-config... /mingw32/bin/pkg-config
> checking pkg-config is at least version 0.9.0... yes
> checking for lept >= 1.74... yes
> checking for icu-uc... yes
> checking for icu-i18n... yes
> checking for pango... yes
> checking for cairo... yes
> checking that generated files are newer than configure... done
> configure: creating ./config.status
> config.status: creating Makefile
> config.status: creating tesseract.pc
> config.status: creating api/Makefile
> config.status: creating arch/Makefile
> config.status: creating ccmain/Makefile
> config.status: creating opencl/Makefile
> config.status: creating ccstruct/Makefile
> config.status: creating ccutil/Makefile
> config.status: creating classify/Makefile
> config.status: creating cutil/Makefile
> config.status: creating dict/Makefile
> config.status: creating lstm/Makefile
> config.status: creating textord/Makefile
> config.status: creating viewer/Makefile
> config.status: creating wordrec/Makefile
> config.status: creating tessdata/Makefile
> config.status: creating tessdata/configs/Makefile
> config.status: creating tessdata/tessconfigs/Makefile
> config.status: creating testing/Makefile
> config.status: creating java/Makefile
> config.status: creating java/com/Makefile
> config.status: creating java/com/google/Makefile
> config.status: creating java/com/google/scrollview/Makefile
> config.status: creating java/com/google/scrollview/events/Makefile
> config.status: creating java/com/google/scrollview/ui/Makefile
> config.status: creating doc/Makefile
> config.status: creating training/Makefile
> config.status: creating config_auto.h
> config.status: executing depfiles commands
> config.status: executing libtool commands
> 
> Configuration is done.
> You can now build and install tesseract by running:
> 
> $ make
> $ sudo make install
> 
> Training tools can be build and installed (after building of tesseract) with:
> 
> $ make training
> $ sudo make training-install


5) Running with gdb:

> gdb --args ./tesseract image14281.jpg image14281
>  -l rus
> GNU gdb (GDB) 7.12.1
> Copyright (C) 2017 Free Software Foundation, Inc.
> License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
> This is free software: you are free to change and redistribute it.
> There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
> and "show warranty" for details.
> This GDB was configured as "i686-w64-mingw32".
> Type "show configuration" for configuration details.
> For bug reporting instructions, please see:
> <http://www.gnu.org/software/gdb/bugs/>.
> Find the GDB manual and other documentation resources online at:
> <http://www.gnu.org/software/gdb/documentation/>.
> For help, type "help".
> Type "apropos word" to search for commands related to "word"...
> Traceback (most recent call last):
>   File "<string>", line 3, in <module>
> ImportError: No module named libstdcxx.v6.printers
> c:\atlas-sdk\msys32\mingw32\bin\../etc/gdbinit:5: Error in sourced command file:
> 
> Error while executing Python code.
> Reading symbols from ./tesseract...done.
> (gdb) run
> Starting program: C:\atlas-sdk\msys32\mingw32\bin\tesseract.exe image14281.jpg i
> mage14281 -l rus
> [New Thread 316.0x79c]
> Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
> Detected 24 diacritics
> [New Thread 316.0x3e4]
> [New Thread 316.0x2e8]
> [New Thread 316.0x69c]
> 
> Thread 2 received signal SIGILL, Illegal instruction.
> [Switching to Thread 316.0x3e4]
> tesseract::DotProductAVX (u=0xcc0010, v=0x469f5f8, n=25)
>     at dotproductavx.cpp:70
> 70      dotproductavx.cpp: No such file or directory.
> (gdb) continue
> Continuing.
> 
> Thread 2 received signal SIGILL, Illegal instruction.
> tesseract::DotProductAVX (u=0xcc0010, v=0x469f5f8, n=25)
>     at dotproductavx.cpp:70
> 70      in dotproductavx.cpp
> (gdb) continue
> Continuing.
> [Thread 316.0x3e4 exited with code 3221225501]
> [Thread 316.0x2e8 exited with code 3221225501]
> [Inferior 1 (process 316) exited with code 030000000035]
> (gdb) continue
> The program is not being run.
> (gdb) @paukonen, you are using a relatively new computer (with AVX and SSE support) on an old operating system (Windows XP). A quick search gives lots of hints that AVX does not work with XP. Tesseract will detect AVX support of the CPU and use it, because it does not test whether you are using an old operating system. So I expect that is the reason of the crash which you observe.

You can test that hypothesis by building a new Tesseract with AVX disabled: simply remove all lines which set `avx_available_` in file `arch/simddetect.cpp`. The resulting Tesseract should work on any Windows version. If is does not, disable SSE support as well. >You can simply remove all lines which set avx_available_ in file arch/simddetect.cpp.
or remoce/comment this code in configure.ac

~~or remove/comment this code in configure.ac:~~
```
AX_CHECK_COMPILE_FLAG([-mavx], [avx=true], [avx=false])
if $avx; then
    AM_CONDITIONAL([AVX_OPT], true)
fi
```

**Edit**: Do what stweil suggested. Thank you very much!

It works fine when AVX is disabled. Looks like a good reason to stop using XP completely. Great, thank you for testing. Maybe we can add a test for old Windows versions in `arch/simddetect.cpp` to handle this automatically. I don't think we should add any code to support OSes that are >10 years old and even not supported by their vendors anymore. Nevertheless, I think what we should do is to add an option to disable **all** the simd  compile-time & runtime checking. In any case, I applied attached patch to my working copy.

[tesseract-20170412-disable-avx-for-win-xp.txt](https://github.com/tesseract-ocr/tesseract/files/916510/tesseract-20170412-disable-avx-for-win-xp.txt)

It automatically disables AVX for XP and older OSes.
Maybe it would come in handy to someone. It seems the current 4.00alpha version would also crash in Windows 10 running on an old i7 CPU, which probably does not have AVX or SSE support. The patch may fix that. I may try it out when I get a chance. >It seems the current 4.00alpha version would crash in Windows 10 running on an old i7 CPU also.

I don't think so.

>I may try it out when I get a chance.

Let us know :) > Great, thank you for testing. Maybe we can add a test for old Windows versions in arch/simddetect.cpp to handle this automatically.

This is also going to come handy for whenever tesseract will make use of AVX-512 (which brings in another new architectural state), which is [only](http://support.sisoftware.net/knowledgebase.php?article=70) going to be supported on W10
(not sure if already, or in a future version - in the latter case that would be another point for this check)

EDIT: for the records, AVX is also not supported on Vista and 7 RTM
EDIT2: [some](https://software.intel.com/en-us/articles/introduction-to-intel-advanced-vector-extensions) [possible](https://software.intel.com/en-us/blogs/2011/04/14/is-avx-enabled) [code](https://gist.github.com/hi2p-perim/7855506) [snippets](https://software.intel.com/en-us/articles/how-to-detect-knl-instruction-support)
EDIT3: [also](https://bugzilla.mozilla.org/show_bug.cgi?id=1110570) I think you posted in the wrong thread.. But he reached the right person. :-)  Hi,I have given a skewed image as input to Tesseract-ocr.
The plain text output generated de-skews the image and is giving the correct output.
But in hocr output, the bounding box coordinates of the words are with respect to the original skewed image.
So,Is there any way to get the coordinates of the words of image which is deskewed by the tesseract or can we get hold of deskewed image itself?
Thank you.  i use this proj in fragmet and i want to capture pic at portrait state but surface show pic with 90d and long .also half of  viewfider goes out of my screen . what should i do ?
thanks 
best wishes  Is there an easy way to find the coordinates for specific data that we are trying to harvest?  We have 2 areas of interest that we are trying to read.   So far the best option that I've found is trial and error.  Hoping there is a sample project to draw the area  on a scanned image or some other good way.

Any help would be appreciated. have you looked at
`hocr`
and
`tsv` 
output formats?

see https://github.com/tesseract-ocr/tesseract/wiki/Command-Line-Usage

and

https://github.com/tesseract-ocr/tesseract/wiki/ViewerDebugging

  frustrated. Why is open source always so sloppy when it comes to stuff like this? 
How does one build tess for Windows? The 2 lines for "how to build", which is basically finding and installing cppan, and running it, is not sufficient instructions by far. So how do you guys expect somebody to want to use this software if they have to spend a weekend trying to figure out how to get it to build? How about some serious steps of how to build it on windows, this time? Do I use a developer command prompt? Do I need cmake? Do I need mingw installed? What, exactly, are the steps? What are some of the common failure issues? A complete release includes complete how to build and how to install instructions.
 If you just want to use Tesseract for Windows, I suggest using one of the binaries which already exist.

The [Tesseract wiki](https://github.com/tesseract-ocr/tesseract/wiki/Compiling) has more than two lines of documentation on building for Windows, and you are free to improve it. Pull requests to enhance the documentation which is provided with the source code are also possible and welcome.

I think the first problem is that there are several ways how it can be done. You have the choice of using either cmake or autoconf. It's possible to build with gcc, clang or MSVC. And you can use MSYS2, Mingw-w64 or CYGWIN. You can even cross compile on a Linux machine. Finally, you have to decide whether you want 32 or 64 bit binaries.

Personally I use cross compilation on Linux because compilation on Linux is much faster than on Windows.
As soon as you have installed all prerequisites, building becomes easy. I use autoconf:

    # Run autogen.sh once
    # (and after updates of your sources or your autoconf installation).
    ./autogen.sh
    # The remaining commands not only work from the root of the Tesseract source tree
    # but also from any directory.
    # This is useful if you want to build different kinds of binaries
    # (32 / 64 bit, debug and release code, ...).
    # Just adapt the `configure` command to your needs.
    ./configure --host=i686-w64-mingw32 CXXFLAGS="-Wall -g"
    make install training-install
    make ScrollView.jar

64 bit binaries require `--host=x86_64-w64-mingw32`.
Exactly the same commands also work on CYGWIN where you can also cross build using Mingw-w64.
 >Why is open source always so sloppy when it comes to stuff like this?


:-1: 

If you have an issue with the software, just report about it. Do not insult the developers!
 > Why is open source always so sloppy when it comes to stuff like this?

@erichfrazer, I see from your GitHub profile that you are working for a software company in Redmond? Then please help us improving the documentation. oh sure, easy to bash my company. When I release software to consumers in the form of SDKs or code that is visible to the public, you can be damned sure I have to document the heck out of it and ensure it at least compiles. This tesseract stuff has taken me days to compile, not hours or minutes. The thing is, it's so easy (in the end) to simply write an actual Visual Studio makefile and then get the whole thing to compile. But no, everybody has to try and go as far as possible to avoid The Big Bad Company, using mingw, cppan, msys2, cmake, blah de blah de blah, and none of that shit works well or is obvious, and none of it allows you to compile w/o having a degree in college-kid Linux.

SOMEBODY should write some VS2015 compatible vcxprojs and make them so they glob in place right in the middle of the tesseract / leptonica / whatever enlistments, and allows you to compile the darned thing.

Even cmake is silly that you can't target a bunch of different processor type and release mode builds all at the same time. I want to build x64, win32, release AND debug. This is not easy, and is very error prone trying to get this done with cmake.

Not as angry, because I got it to compile, but still cranky.
 >But no, everybody has to try and go as far as possible to avoid The Big Bad Company, using mingw, cppan, msys2, **cmake**, blah de blah de blah....

I have news for you. Microsoft officially supports CMake these days.
https://blogs.msdn.microsoft.com/vcblog/2016/10/05/cmake-support-in-visual-studio/

They also released this tool which also works with CMake
https://github.com/Microsoft/vcpkg

https://blogs.msdn.microsoft.com/vcblog/2016/09/19/vcpkg-a-tool-to-acquire-and-build-c-open-source-libraries-on-windows/

Maybe you can be more constructive and add support for Tesseract to the vcpkg repo?
https://github.com/Microsoft/vcpkg/issues/465
 I'm not the one releasing the software!! Why don't you come debug my Traffic App? It was nice talking with you... First Thanks for Tesseract team for great work
Building form source for Windows using visual studio is not straight forward as described in tutorial
it failed to run VS2010 and succeeded in VS2015 but the generated files can't run in my machine.

most of VS developers like me not familiar with cross platform tools , i just want ask , would you create something like OpenCV? , it's just one zipped file  contain all what you need to build including the dependencies , GUI Cmake just used to select src path, dst pat and target Developing IDE  then build.

Is the previous scenario can be achieved ? 

 Hi @essamzaky,

Just to let you (and others who will read this comment) know, the build scripts are maintained mostly by a very small community team. For the VS/CMake build, there is only one man that works on it currently (not me) in his spare time.

@egorpugin, do you have any comment?  >it failed to run VS2010 

Copied from another issue:

>Does Tesseract 4.0 built with CMake supports VS2010 or not?

egorpugin commented

>No. Not out of the box.
>
>One needs fixing some bugs in tiff library that comes from cppan.
Or there's always manual way of including dependencies. In this case VS2010 might work.
>
>With cppan VS2015 and VS2017 are only supported. Perhaps links to the old tutorials (external) for building with vs2008,
2010 etc should be removed from wikim

- excuse the brevity, sent from mobile

On 04-Apr-2017 3:17 AM, "Amit D." <notifications@github.com> wrote:

> it failed to run VS2010
>
> Copied from another issue:
>
> Does Tesseract 4.0 built with CMake supports VS2010 or not?
>
> egorpugin commented
>
> No. Not out of the box.
>
> One needs fixing some bugs in tiff library that comes from cppan.
> Or there's always manual way of including dependencies. In this case
> VS2010 might work.
>
> With cppan VS2015 and VS2017 are only supported.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/799#issuecomment-291284024>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o5WMpnkwRSn2VUrDhcfehOUzYM7Dks5rsWj7gaJpZM4Mwrg4>
> .
>
 @Shreeshrii  Building from source using manual way might work for VS2010 , VS2008 as egorpugin commented
so if there is someone succeeded to build using manual way , it's better to describe how to use the manual way.
i succeeded to build most of dependence in my spare time i will back and build the rest of the solution and write about  my trial to build using the manual way.

  I had problems myself and finally decide to do it the hardway. I do not see why this needs to re-invented. Hence I have provided a complete solution kit along with binaries for Windows. Solution kit is made for Visual Studio 2015. Please check the link below and do replicate this, so we do not have this as an issue anymore.
https://github.com/vdevan/TesseractTrainingTools See also:
https://github.com/peirick/VS2015_Tesseract Yes I have added his link as well. Main difference is I have provided 
the training tools which was not there on the Peirick's link

என்றும் அன்புடன்
வாசு
அன்பைத் தவிர வேறு ஒன்றும் வேண்டேன் பராபரமே!


Always lovingly
Vasu Devan V.
God give me strength to love everyone.
http://www.kamban.com.au
http://brahas.com

On 6/04/2017 8:19 PM, Amit D. wrote:
>
> See also:
> https://github.com/peirick/VS2015_Tesseract
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub 
> <https://github.com/tesseract-ocr/tesseract/issues/799#issuecomment-292131222>, 
> or mute the thread 
> <https://github.com/notifications/unsubscribe-auth/ASo5MXiz7PeBFkxMrJZPsV7OuMcs5A2wks5rtLwwgaJpZM4Mwrg4>.
>

 Thanks for useful links, hope to update it soon for tesseract 4.0 Hi @egorpugin 
Finally i run the cppan today with build the VS2015 and it's working, i did the following steps 
delete the following folders "C:\Users\emz\tesseract" , "C:\Users\emz.cppan".
launch cmd from run and execute the following:
git clone https://github.com/tesseract-ocr/tesseract.git
cd tesseract
cppan
mkdir build
cd build
cmake .. -G "Visual Studio 14 2015" -DCPPAN_USE_CACHE=0

Thanks egor
 @essamzaky -> Thank you very much! The information provided in [wiki](https://github.com/tesseract-ocr/tesseract/wiki/Compiling) did not worked for me, bu this worked. Why don't you change the wiki?

For x64 this worked for me:
cd tesseract
cppan
mkdir build_x64
cd build_x64
cmake .. -G "Visual Studio 14 2015 Win64" -DCPPAN_USE_CACHE=0  The review of API/ABI changes for Tesseract since 3.00 version: https://abi-laboratory.pro/tracker/timeline/tesseract/

Hope it will be helpful for users and maintainers of the library.

Created with the help of open-source abi-tracker tool: https://github.com/lvc/abi-tracker

The tool checks _all_ API symbols declared in header files (doesn't take docs into account), so there may be some false positives.

Thank you.

![tesseract-1](https://cloud.githubusercontent.com/assets/1517837/24391131/5b074572-139e-11e7-89c2-d98ca1e67dc2.png)

![tesseract-2](https://cloud.githubusercontent.com/assets/1517837/24391366/b84779ea-139f-11e7-804e-f6ec094b4225.png)


## Environment
* Linux x86_64
* GCC 4.9
* Tesseract 3.00 and higher
 To take attention of library developers on the results first.

Thank you. @lvc Thanks! I have added info to the documentation wiki at

https://github.com/tesseract-ocr/tesseract/wiki/Documentation @lvc,
Thanks for the info.

3.01 and 3.03 are missing from the report. 

The bottom line is that we break the ABI in almost every release. @lvc,
FYI, since 3.02 there is an "--enable-visibility" option for the configure script. @amitdo,

> 3.01 and 3.03 are missing from the report

Added 3.01 and 3.03 versions to the report: https://abi-laboratory.pro/tracker/timeline/tesseract/

Thank you.

![tesseract-4](https://cloud.githubusercontent.com/assets/1517837/24453656/d431e726-1499-11e7-9f4c-c6fed0aff533.png)

 @Shreeshrii,

Done: https://abi-laboratory.pro/tracker/timeline/tesseract/

Please let me know when it should be switched to 3.06 or 4.0.

![tesseract-5](https://cloud.githubusercontent.com/assets/1517837/25801811/724dac08-3400-11e7-9af3-ff379784aeaf.png)
  I added  -eval_listfile /home/shree/tesstutorial/hineval/tmp.txt \ to my lstmtraining command once it had come down to less than 3%char error. 

While training is continuing, I am getting messages saying 'Deserialize Failed',
 Lines with error:

```
At iteration 23765/35800/35801, 
Mean rms=0.111%, delta=0.79%, char train=2.554%, word train=14.083%, skip ratio=0%,  
wrote checkpoint.

2 Percent improvement time=15025, best error was 4.481 @ 8791
Warning: LSTMTrainer deserialized an LSTMRecognizer!
At iteration 23816/35900/35901, 
Mean rms=0.11%, delta=0.768%, char train=2.454%, word train=13.982%, skip ratio=0%,  
New best char error = 2.454 
Deserialize failed 
wrote best model:/home/shree/tesstutorial/hinlayer_from_hin/hinlayer2.454_23816.lstm 
wrote checkpoint.

...

Loaded 61/61 pages (1-61) of document /home/shree/tesstutorial/hineval/hin.Sahitya.exp0.lstmf
2 Percent improvement time=14846, 
best error was 4.436 @ 9020
At iteration 23866/36000/36001, 
Mean rms=0.11%, delta=0.749%, char train=2.396%, word train=14.124%, skip ratio=0%,  
New best char error = 2.396
Previous test incomplete, skipping test at iteration23816 
wrote checkpoint.

...

At iteration 23914/36100/36101, 
Mean rms=0.11%, delta=0.747%, char train=2.41%, word train=14.399%, skip ratio=0%,  
New worst char error = 2.41
At iteration 23618, stage 1, 
Eval Char error rate=1.8365727, Word error rate=7.0471499 wrote checkpoint.

...


At iteration 24320/36900/36901, 
Mean rms=0.109%, delta=0.745%, char train=2.454%, word train=14.204%, skip ratio=0%,  
New worst char error = 2.454
Deserialize failed wrote checkpoint.

...

2 Percent improvement time=15369, 
best error was 4.329 @ 9223
At iteration 24592/37400/37401, 
Mean rms=0.108%, delta=0.737%, char train=2.298%, word train=13.478%, skip ratio=0%,  
New best char error = 2.298 
wrote best model:/home/shree/tesstutorial/hinlayer_from_hin/hinlayer2.298_24592.lstm wrote checkpoint.
```



 Maybe, I don't know. First I have to reproduce this. `~/tesstutorial/bihnewlayer` is needed, too. I had to fix the path in `~/tesstutorial/bihtest/bih.training_files.txt`, but now `lstmtraining` works, and there seem to be no errors. Tested with debug version based on latest git master. Yes, I changed both files to match my home directory. Is this issue still present with the latest code?  Hello,
I installed tesseract and tested it , it gives correct result for english.
But i have to extract Arabic text for which i download ara.traineddata and its related files from here
https://github.com/tesseract-ocr/tesseract/wiki/Data-Files#data-files-for-version-400
then i tried a jpeg image and got its output on a text file. then it retrieves arabic txt but not proper result
 
   

جهمة # ك سو-ة

. ظرسظة عهود

١صي سعد إلاء . سلعة-ا
. سدلعدسسلعلىوس
وا{ قللا{ ٧تلا ٣تاتع٨ اق با لإت«اح» . سا مي ضجة دةسءع عظك
«قلم«ة٧حلا و و«تعهاق بي ئت»حه لة

and there is not such words in this image

![image](https://cloud.githubusercontent.com/assets/26489735/24331095/f0b66784-1235-11e7-8a8b-95fe47773304.png)

and when i used -l ara+eng parameter then out says no best words !! and tesseract stoped working.
whats the problem here ?
![image](https://cloud.githubusercontent.com/assets/26489735/24331107/77529920-1236-11e7-9413-f12c8f26a45a.png)
 so please tell me whom can i ask to guide me about this issue ? How he made all those old comments from me, zdenko and others reappear here?

Really weird. Arabic is not fully accurate with 4.0. there are already open issues
regarding same. You will have to wait for new training by Ray for
improvement.

- excuse the brevity, sent from mobile

On 26-Mar-2017 5:40 PM, "waleedraza786" <notifications@github.com> wrote:

> Hello,
> I installed tesseract and tested it , it gives correct result for english.
> But i have to extract Arabic text for which i download ara.traineddata and
> its related files from here
> https://github.com/tesseract-ocr/tesseract/wiki/Data-Files#
> data-files-for-version-400
> then i tried a jpeg image and got its output on a text file. then it
> retrieves arabic txt but not proper result
>
> بسئع الملل الئمنئن التلثيم انينك ثلم نبينا اأغالويع الئمنئر.ي الئأتحيم
> تاللخ تؤم اللتين إنمثالترلننمهنن . نتيئممنزإنمئالترننئنجيأ الهلع
> نلجمتاالعنننالذ
>
> اأ ط هني يزصبنالر انللريي٠ز لزنغنميز غننهمة غنرالتنطنويي غننهم
> ثلآ الينننالنيتى الم ئللز النهنارن لا نمنممة فيو نلإى يأئلتمبيتى انللريي٠ز
>
> حمم طهه ط نك حمم حمم
>
> نلمضولإ باأغنمي زنقبينولإ العثلاث بنينا{ نيرمالا/تنم ننهينولإ زساللوييز
>
> نقيبة زينى أ لثطناليببم عزتنتازيأ قا )ءه غذارنإ غغليأ زثفئى الثامبي تل تيو{
>
> مدعو ٠ إلا ا ئغستننم زتا منرننننغنولإ ليننئوننيينم متنمضز نزيلا/نرنم الئ
> تنطنا
>
> زلئن غذار،نإ أليق يمناسقالوا مننثيدنون زلنا قيل نمنم لا نغينمنواي
> ينائيهؤقلي
>
> and there is not such words in this image
>
> [image: image]
> <https://cloud.githubusercontent.com/assets/26489735/24331095/f0b66784-1235-11e7-8a8b-95fe47773304.png>
>
> and when i used -l ara+eng parameter then out says no best words !! and
> tesseract stoped working.
> whats the problem here ?
> ------------------------------
> You can view, comment on, or merge this pull request online at:
>
>   https://github.com/tesseract-ocr/tesseract/pull/791
> Commit Summary
>
>    - opencl: Fix wrong implementation of function
>    getNumDeviceWithEmptyScore
>    - opencl: Add missing argument for L_WARNING
>    - opencl: Remove unused function getNumDeviceWithEmptyScore
>    - Fix crash caused by undefined value of local variable
>    - allow combination of enable/disable
>    - opencl: Fix type of parameter for clGetContextInfo
>    - opencl: Fix type of parameter for clGetProgramInfo
>    - backport from 4.00: issue #242 - different results when same image
>    is lossless-encoded at different bpp
>    - training: Fix compiler warnings (deprecated register keyword)
>    - add option "make training-uninstall"
>    - Fix a typo in tesseract(1) man page
>    - Fix typo in documentation
>    - opencl: Fix typo in name of local variable
>    - ccutil/ambigs: Optimize tesseract::UnicharIdArrayUtils::compare
>    - Fixed failed merge of memory leak
>    - Fix compiler warning (-Wmaybe-uninitialized)
>    - AUTHORS - Add community contributors
>    - Increase version number in VS2010 and fix year
>    - backport from 4.00: add missing License information
>    - downgrade to leptonica 1.73
>    - backport style changes from 4.00 for better identification of fixes
>    and new code
>    - backport style changes from 4.00 for better identification of fixes
>    and new code
>    - Merge branch '3.05' of https://github.com/tesseract-ocr/tesseract
>    into 3.05
>    - add license info to autogen.sh
>    - revert TessHashMap to hash_map in training/stringrenderer.h from
>    90651e1 (to fix build)
>    - AUTHORS: Add more contributors
>    - use leptonica from master git repository (1.74)
>    - Missing pdf font file from previous sync
>    - Fixed the memory leak/double free cleanly
>    - fix code style
>    - backport from 4.00: show PSM 11-13
>    - backport from 4.00: fix pdfrenderer
>    - add License info to cmake files
>    - increase GENERIC_MINOR_VERSION
>    - backport from 4.00: changes in scrollviewer
>    - backport from 4.00: fix of destroy_nodes (oldlist.cpp)
>    - backport from 4.00: changes in cube
>    - style fix
>    - backport from 4.00: changes in wordrec + FakeWordFromRatings
>    - backport from 4.00: use "const TBOX&" instead of "TBOX box" in
>    textord
>    - backport from 4.00: use ".empty()" instead of ".size() > 0"
>    - backport from 4.00: changes in textord
>    - backport from 4.00: changes in Android.mk
>    - backport from 4.00: changes in classify
>    - backport from 4.00: changes from ccstruct excluding imagedata
>    - backport from 4.00: SkipDeSerialize and changes in ccutil
>    - use TessHashMap instead of hash_map, unordered_map
>    - backport from 4.00: enable selection of OCR engine mode from command
>    line
>    - backport from 4.00: split Dict::Load to SetupForLoad, Load and
>    FinishLoad
>    - backport from 4.00: code improvements
>    - backport from 4.00: api changes
>    - Merge branch '3.05' of https://github.com/tesseract-ocr/tesseract
>    into 3.05
>    - backport from 4.00: training shell scripts
>    - change VS2010 lib project name
>    - backport from 4.00: training
>    - backport from 4.00: imagedata
>    - opencl: Clean whitespace issues in OpenCL kernel code
>    - opencl: Format OpenCL kernel code
>    - opencl: Fix OpenCL kernel code assertion for newer versions
>    - Simplify calls of free
>    - Simplify delete operations
>    - Missing pdf font file from previous sync
>    - Fixed the memory leak/double free cleanly
>    - Fix build for Mingw-w64 (120a5dbdab78) and non C++11 build (VS2010)
>    - mingw-w64: Fix compiler warnings caused by macro redefinition
>    - cube: Simplify delete operations
>    - cube/char_bigrams: Fix some memory leaks
>    - cube/char_samp: Fix some memory leaks
>    - Correcting link for 3rd party wiki pages
>    - Formatting changes from clang_tidy on latest pull
>    - Added std:: to vector
>    - cube: Simplify new operations
>    - Simplify new operations
>    - Change tesseract parameter -oem to --oem
>    - Change tesseract parameter -psm to --psm
>    - opencl: Remove unneeded and potentially bad type casts
>    - cube: Fix use after free regression
>    - cube: Fix coverity warning caused by unneeded null pointer check
>    - opencl: Add missing checks for OpenCL failures
>    - Remove extra semicolons after member function definitions
>    - Fixed damage to binary images when processing PDFs, issue #535
>    - training: Update Makefile for current Mingw-w64
>    - doc: Fix line endings
>    - fix typo
>    - tesseract: Disable Leptonica messages
>    - Produce warning for invalid resolution. Fix #453
>    - More clang-tidy from previous commits
>    - Remove duplicate destructor
>    - Implement a new orientation and script detection API for C and C++
>    - Revise after code review
>    - Remove unused code.
>    - Remove 'listio.cpp' and 'listio.h' from vs2010 vcxproj
>    - Fix two typos in comments
>    - java: Improve build rules
>    - openmp: Fix OpenMP support
>    - Merge pull request #564 from stweil/3.05
>    - increase min autoconf version (2.59)
>    - require leptonica 1.74 or higher
>    - Multi-page TIFF buffering is broken - fix #233
>    - fix removal of AC_CHECK_LIB([lept])
>    - remove (fake) OPENMP support
>    - Update cppan.yml
>    - leptonica 1.74.1 is needed for cppan
>    - fix #665 process file list
>    - fix appveyor
>    - fix #712: Ghostscript mangling Tesseract-produced PDFs
>    - Backport cppan fixes.
>    - Merge branch '3.05' of github.com-egorpugin:tesseract-ocr/tesseract
>    into 3.05
>    - Backport cmake fixes.
>    - Add .cppan to ignore list.
>    - 3.05.00 release
>    - 3.05.00 release
>    - Merge branch '3.05' of https://github.com/tesseract-ocr/tesseract
>    into 3.05
>    - replace nullptr with NULL to enable non c++11 build (fixes #727)
>    - Rename cppan/cmake targets.
>    - Correct reading config files with \r\n
>    - Use camel case for GitHub in README.md
>    - Fix indentation after conditional [-Wmisleading-indentation]
>    - [`autogen.sh`:] Abstract the absolute path of `libtoolize` or
>    `glibtoolize` away into `$LIBTOOLIZE`.
>    - [`autogen.sh`:] Reduce in-script comment block width to 80
>    characters.
>    - [`autogen.sh`:] Clarify `libtoolize`/`glibtoolize` existence check
>    error message.
>    - [`autogen.sh`:] Improve `libtoolize` invocation message.
>    - Add the packaging metadata to build the tesseract snap
>    - Use portable data types #709
>    - fix --disable-graphics build
>    - fix --enable-visibility build (including training tools)
>    - Fix some typos in comments (found by codespell)
>    - Update appveyor.yml
>    - Disable warnings on Appveyor.
>    - Update CMakeLists.txt
>    - libtiff is needed for windows build of tesseract executable
>    - Add item to ChangeLog for options writing to stdout instead of stderr
>    - Merge pull request #776 from cjmayo/stdoutput
>    - Update README.md heading markdown
>    - Fix windows build.
>    - Update appveyor.yml
>    - Update appveyor.yml
>    - Update appveyor.yml
>
> File Changes
>
>    - *M* .gitignore
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-0> (7)
>    - *M* AUTHORS
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-1>
>    (14)
>    - *M* CMakeLists.txt
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-2>
>    (50)
>    - *M* ChangeLog
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-3>
>    (22)
>    - *M* INSTALL.GIT.md
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-4> (2)
>    - *A* LICENSE
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-5>
>    (202)
>    - *M* Makefile.am
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-6> (3)
>    - *M* README.md
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-7>
>    (23)
>    - *M* android/jni/Android.mk
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-8> (5)
>    - *M* api/Makefile.am
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-9> (7)
>    - *M* api/baseapi.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-10>
>    (253)
>    - *M* api/baseapi.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-11>
>    (55)
>    - *M* api/capi.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-12>
>    (11)
>    - *M* api/capi.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-13>
>    (6)
>    - *M* api/pdfrenderer.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-14>
>    (24)
>    - *M* api/renderer.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-15>
>    (29)
>    - *M* api/renderer.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-16>
>    (22)
>    - *M* api/tesseractmain.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-17>
>    (198)
>    - *M* appveyor.yml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-18>
>    (40)
>    - *M* autogen.sh
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-19>
>    (28)
>    - *M* ccmain/control.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-20>
>    (19)
>    - *M* ccmain/cube_control.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-21>
>    (18)
>    - *M* ccmain/cube_reco_context.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-22>
>    (52)
>    - *M* ccmain/cubeclassifier.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-23>
>    (5)
>    - *M* ccmain/docqual.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-24>
>    (16)
>    - *M* ccmain/equationdetect.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-25>
>    (1)
>    - *M* ccmain/fixspace.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-26>
>    (5)
>    - *M* ccmain/ltrresultiterator.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-27>
>    (11)
>    - *M* ccmain/ltrresultiterator.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-28>
>    (3)
>    - *M* ccmain/osdetect.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-29>
>    (10)
>    - *M* ccmain/output.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-30>
>    (28)
>    - *M* ccmain/pageiterator.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-31>
>    (8)
>    - *M* ccmain/pagesegmain.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-32>
>    (10)
>    - *M* ccmain/par_control.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-33>
>    (4)
>    - *M* ccmain/paragraphs.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-34>
>    (12)
>    - *M* ccmain/paramsd.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-35>
>    (10)
>    - *M* ccmain/pgedit.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-36>
>    (2)
>    - *M* ccmain/reject.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-37>
>    (4)
>    - *M* ccmain/tessedit.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-38>
>    (6)
>    - *M* ccmain/tesseract_cube_combiner.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-39>
>    (2)
>    - *M* ccmain/tesseract_cube_combiner.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-40>
>    (20)
>    - *M* ccmain/tesseractclass.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-41>
>    (7)
>    - *M* ccmain/tesseractclass.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-42>
>    (31)
>    - *M* ccmain/thresholder.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-43>
>    (35)
>    - *M* ccstruct/blamer.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-44>
>    (2)
>    - *M* ccstruct/blobbox.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-45>
>    (10)
>    - *M* ccstruct/boxread.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-46>
>    (3)
>    - *M* ccstruct/boxword.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-47>
>    (4)
>    - *M* ccstruct/coutln.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-48>
>    (66)
>    - *M* ccstruct/fontinfo.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-49>
>    (2)
>    - *M* ccstruct/fontinfo.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-50>
>    (6)
>    - *M* ccstruct/hpdsizes.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-51>
>    (9)
>    - *M* ccstruct/imagedata.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-52>
>    (409)
>    - *M* ccstruct/imagedata.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-53>
>    (135)
>    - *M* ccstruct/matrix.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-54>
>    (311)
>    - *M* ccstruct/mod128.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-55>
>    (17)
>    - *M* ccstruct/mod128.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-56>
>    (5)
>    - *M* ccstruct/otsuthr.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-57>
>    (26)
>    - *M* ccstruct/pageres.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-58>
>    (7)
>    - *M* ccstruct/pageres.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-59>
>    (11)
>    - *M* ccstruct/params_training_featdef.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-60>
>    (2)
>    - *M* ccstruct/pdblock.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-61>
>    (148)
>    - *M* ccstruct/polyaprx.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-62>
>    (2)
>    - *M* ccstruct/polyblk.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-63>
>    (2)
>    - *M* ccstruct/quspline.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-64>
>    (4)
>    - *M* ccstruct/ratngs.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-65>
>    (5)
>    - *M* ccstruct/rect.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-66>
>    (12)
>    - *M* ccstruct/rect.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-67>
>    (10)
>    - *M* ccstruct/rejctmap.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-68>
>    (2)
>    - *M* ccstruct/rejctmap.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-69>
>    (61)
>    - *M* ccstruct/statistc.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-70>
>    (5)
>    - *M* ccutil/ambigs.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-71>
>    (21)
>    - *M* ccutil/bits16.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-72>
>    (8)
>    - *M* ccutil/ccutil.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-73>
>    (9)
>    - *M* ccutil/ccutil.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-74>
>    (6)
>    - *M* ccutil/clst.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-75>
>    (29)
>    - *M* ccutil/clst.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-76>
>    (288)
>    - *M* ccutil/elst.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-77>
>    (26)
>    - *M* ccutil/elst.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-78>
>    (62)
>    - *M* ccutil/elst2.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-79>
>    (26)
>    - *M* ccutil/elst2.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-80>
>    (321)
>    - *M* ccutil/errcode.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-81>
>    (9)
>    - *M* ccutil/genericheap.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-82>
>    (34)
>    - *M* ccutil/genericvector.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-83>
>    (82)
>    - *M* ccutil/globaloc.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-84>
>    (2)
>    - *M* ccutil/hashfn.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-85>
>    (30)
>    - *M* ccutil/helpers.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-86>
>    (2)
>    - *M* ccutil/lsterr.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-87>
>    (2)
>    - *M* ccutil/mainblk.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-88>
>    (2)
>    - *M* ccutil/ocrclass.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-89>
>    (40)
>    - *M* ccutil/params.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-90>
>    (5)
>    - *M* ccutil/params.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-91>
>    (4)
>    - *M* ccutil/platform.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-92>
>    (4)
>    - *M* ccutil/serialis.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-93>
>    (2)
>    - *M* ccutil/strngs.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-94>
>    (12)
>    - *M* ccutil/strngs.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-95>
>    (8)
>    - *M* ccutil/tessdatamanager.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-96>
>    (70)
>    - *M* ccutil/unicharset.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-97>
>    (13)
>    - *M* classify/adaptive.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-98>
>    (8)
>    - *M* classify/adaptmatch.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-99>
>    (7)
>    - *M* classify/classify.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-100>
>    (4)
>    - *M* classify/cluster.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-101>
>    (477)
>    - *M* classify/cluster.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-102>
>    (10)
>    - *M* classify/clusttool.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-103>
>    (43)
>    - *M* classify/clusttool.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-104>
>    (22)
>    - *M* classify/cutoffs.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-105>
>    (10)
>    - *M* classify/featdefs.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-106>
>    (14)
>    - *M* classify/featdefs.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-107>
>    (8)
>    - *M* classify/fpoint.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-108>
>    (11)
>    - *M* classify/intfeaturemap.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-109>
>    (2)
>    - *M* classify/intfeaturespace.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-110>
>    (2)
>    - *M* classify/intfx.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-111>
>    (2)
>    - *M* classify/intfx.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-112>
>    (2)
>    - *M* classify/intmatcher.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-113>
>    (26)
>    - *M* classify/intmatcher.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-114>
>    (10)
>    - *M* classify/intproto.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-115>
>    (26)
>    - *M* classify/intproto.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-116>
>    (2)
>    - *M* classify/kdtree.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-117>
>    (28)
>    - *M* classify/kdtree.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-118>
>    (2)
>    - *M* classify/mastertrainer.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-119>
>    (14)
>    - *M* classify/mastertrainer.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-120>
>    (2)
>    - *M* classify/mf.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-121>
>    (12)
>    - *M* classify/mfdefs.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-122>
>    (16)
>    - *M* classify/mfoutline.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-123>
>    (5)
>    - *M* classify/mfx.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-124>
>    (4)
>    - *M* classify/mfx.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-125>
>    (10)
>    - *M* classify/normfeat.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-126>
>    (11)
>    - *M* classify/normmatch.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-127>
>    (18)
>    - *M* classify/ocrfeatures.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-128>
>    (33)
>    - *M* classify/ocrfeatures.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-129>
>    (2)
>    - *M* classify/outfeat.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-130>
>    (14)
>    - *M* classify/picofeat.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-131>
>    (12)
>    - *M* classify/picofeat.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-132>
>    (2)
>    - *M* classify/protos.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-133>
>    (4)
>    - *M* classify/shapeclassifier.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-134>
>    (2)
>    - *M* classify/shapetable.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-135>
>    (2)
>    - *M* classify/tessclassifier.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-136>
>    (3)
>    - *M* classify/trainingsample.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-137>
>    (4)
>    - *M* classify/trainingsampleset.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-138>
>    (6)
>    - *M* cmake/BuildFunctions.cmake
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-139>
>    (9)
>    - *M* cmake/Configure.cmake
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-140>
>    (9)
>    - *M* cmake/FindICU.cmake
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-141>
>    (9)
>    - *M* cmake/SourceGroups.cmake
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-142>
>    (11)
>    - *M* configure.ac
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-143>
>    (53)
>    - *M* cppan.yml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-144>
>    (363)
>    - *M* cube/beam_search.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-145>
>    (21)
>    - *M* cube/beam_search.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-146>
>    (2)
>    - *M* cube/bmp_8.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-147>
>    (60)
>    - *M* cube/cached_file.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-148>
>    (3)
>    - *M* cube/char_altlist.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-149>
>    (7)
>    - *M* cube/char_bigrams.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-150>
>    (20)
>    - *M* cube/char_samp.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-151>
>    (47)
>    - *M* cube/char_samp.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-152>
>    (22)
>    - *M* cube/char_samp_set.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-153>
>    (14)
>    - *M* cube/char_set.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-154>
>    (18)
>    - *M* cube/classifier_base.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-155>
>    (16)
>    - *M* cube/classifier_factory.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-156>
>    (12)
>    - *M* cube/con_comp.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-157>
>    (18)
>    - *M* cube/conv_net_classifier.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-158>
>    (36)
>    - *M* cube/cube_line_object.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-159>
>    (106)
>    - *M* cube/cube_line_segmenter.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-160>
>    (6)
>    - *M* cube/cube_object.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-161>
>    (70)
>    - *M* cube/cube_search_object.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-162>
>    (42)
>    - *M* cube/cube_tuning_params.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-163>
>    (5)
>    - *M* cube/cube_utils.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-164>
>    (14)
>    - *M* cube/hybrid_neural_net_classifier.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-165>
>    (25)
>    - *M* cube/search_column.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-166>
>    (14)
>    - *M* cube/search_node.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-167>
>    (3)
>    - *M* cube/tess_lang_mod_edge.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-168>
>    (6)
>    - *M* cube/tess_lang_model.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-169>
>    (21)
>    - *M* cube/word_altlist.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-170>
>    (8)
>    - *M* cube/word_list_lang_model.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-171>
>    (6)
>    - *M* cube/word_size_model.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-172>
>    (15)
>    - *M* cube/word_unigrams.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-173>
>    (21)
>    - *M* cutil/Makefile.am
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-174>
>    (4)
>    - *M* cutil/bitvec.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-175>
>    (42)
>    - *M* cutil/cutil.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-176>
>    (20)
>    - *M* cutil/danerror.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-177>
>    (10)
>    - *M* cutil/efio.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-178>
>    (12)
>    - *M* cutil/emalloc.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-179>
>    (2)
>    - *D* cutil/listio.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-180>
>    (67)
>    - *D* cutil/listio.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-181>
>    (43)
>    - *M* cutil/oldlist.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-182>
>    (5)
>    - *M* dict/context.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-183>
>    (38)
>    - *M* dict/dawg.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-184>
>    (19)
>    - *M* dict/dict.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-185>
>    (120)
>    - *M* dict/dict.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-186>
>    (32)
>    - *M* dict/stopper.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-187>
>    (11)
>    - *M* dict/stopper.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-188>
>    (10)
>    - *M* dict/trie.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-189>
>    (1)
>    - *M* doc/ambiguous_words.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-190>
>    (1580)
>    - *M* doc/ambiguous_words.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-191>
>    (86)
>    - *M* doc/cntraining.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-192>
>    (1610)
>    - *M* doc/cntraining.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-193>
>    (116)
>    - *M* doc/combine_tessdata.1.asc
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-194>
>    (2)
>    - *M* doc/combine_tessdata.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-195>
>    (2028)
>    - *M* doc/combine_tessdata.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-196>
>    (562)
>    - *M* doc/dawg2wordlist.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-197>
>    (1604)
>    - *M* doc/dawg2wordlist.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-198>
>    (106)
>    - *M* doc/mftraining.1.asc
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-199>
>    (4)
>    - *M* doc/mftraining.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-200>
>    (0)
>    - *M* doc/mftraining.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-201>
>    (0)
>    - *M* doc/shapeclustering.1.asc
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-202>
>    (0)
>    - *M* doc/shapeclustering.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-203>
>    (0)
>    - *M* doc/shapeclustering.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-204>
>    (0)
>    - *M* doc/tesseract.1
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-205>
>    (0)
>    - *M* doc/tesseract.1.asc
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-206>
>    (0)
>    - *M* doc/tesseract.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-207>
>    (0)
>    - *M* doc/tesseract.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-208>
>    (0)
>    - *M* doc/unicharambigs.5.asc
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-209>
>    (0)
>    - *M* doc/unicharambigs.5.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-210>
>    (0)
>    - *M* doc/unicharambigs.5.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-211>
>    (0)
>    - *M* doc/unicharset.5.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-212>
>    (0)
>    - *M* doc/unicharset.5.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-213>
>    (0)
>    - *M* doc/unicharset_extractor.1.asc
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-214>
>    (0)
>    - *M* doc/unicharset_extractor.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-215>
>    (0)
>    - *M* doc/unicharset_extractor.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-216>
>    (0)
>    - *M* doc/wordlist2dawg.1.html
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-217>
>    (0)
>    - *M* doc/wordlist2dawg.1.xml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-218>
>    (0)
>    - *M* java/Makefile.am
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-219>
>    (0)
>    - *M* neural_networks/runtime/input_file_buffer.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-220>
>    (0)
>    - *M* neural_networks/runtime/input_file_buffer.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-221>
>    (0)
>    - *M* neural_networks/runtime/neural_net.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-222>
>    (0)
>    - *M* neural_networks/runtime/neural_net.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-223>
>    (0)
>    - *M* neural_networks/runtime/neuron.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-224>
>    (0)
>    - *M* neural_networks/runtime/neuron.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-225>
>    (0)
>    - *M* neural_networks/runtime/sigmoid_table.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-226>
>    (0)
>    - *M* opencl/oclkernels.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-227>
>    (0)
>    - *M* opencl/opencl_device_selection.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-228>
>    (0)
>    - *M* opencl/openclwrapper.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-229>
>    (0)
>    - *M* opencl/openclwrapper.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-230>
>    (0)
>    - *M* snap/snapcraft.yaml
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-231>
>    (0)
>    - *M* tessdata/configs/box.train.stderr
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-232>
>    (0)
>    - *M* tessdata/pdf.ttf
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-233>
>    (0)
>    - *M* testing/reorgdata.sh
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-234>
>    (0)
>    - *M* testing/runtestset.sh
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-235>
>    (0)
>    - *M* textord/alignedblob.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-236>
>    (0)
>    - *M* textord/baselinedetect.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-237>
>    (0)
>    - *M* textord/bbgrid.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-238>
>    (0)
>    - *M* textord/bbgrid.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-239>
>    (0)
>    - *M* textord/blkocc.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-240>
>    (0)
>    - *M* textord/ccnontextdetect.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-241>
>    (0)
>    - *M* textord/colpartition.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-242>
>    (0)
>    - *M* textord/colpartition.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-243>
>    (0)
>    - *M* textord/colpartitiongrid.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-244>
>    (0)
>    - *M* textord/devanagari_processing.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-245>
>    (0)
>    - *M* textord/drawedg.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-246>
>    (0)
>    - *M* textord/fpchop.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-247>
>    (0)
>    - *M* textord/gap_map.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-248>
>    (0)
>    - *M* textord/gap_map.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-249>
>    (0)
>    - *M* textord/imagefind.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-250>
>    (0)
>    - *M* textord/makerow.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-251>
>    (0)
>    - *M* textord/oldbasel.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-252>
>    (0)
>    - *M* textord/pithsync.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-253>
>    (0)
>    - *M* textord/pitsync1.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-254>
>    (0)
>    - *M* textord/scanedg.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-255>
>    (0)
>    - *M* textord/strokewidth.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-256>
>    (0)
>    - *M* textord/tabfind.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-257>
>    (0)
>    - *M* textord/tablefind.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-258>
>    (0)
>    - *M* textord/tabvector.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-259>
>    (0)
>    - *M* textord/textlineprojection.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-260>
>    (0)
>    - *M* textord/textord.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-261>
>    (0)
>    - *M* textord/topitch.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-262>
>    (0)
>    - *M* textord/tordmain.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-263>
>    (0)
>    - *M* textord/tospace.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-264>
>    (0)
>    - *M* textord/tovars.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-265>
>    (0)
>    - *M* textord/tovars.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-266>
>    (0)
>    - *M* training/CMakeLists.txt
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-267>
>    (0)
>    - *M* training/Makefile.am
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-268>
>    (0)
>    - *M* training/boxchar.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-269>
>    (0)
>    - *M* training/boxchar.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-270>
>    (0)
>    - *M* training/classifier_tester.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-271>
>    (0)
>    - *M* training/cntraining.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-272>
>    (0)
>    - *M* training/commandlineflags.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-273>
>    (0)
>    - *M* training/commontraining.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-274>
>    (0)
>    - *M* training/degradeimage.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-275>
>    (0)
>    - *M* training/degradeimage.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-276>
>    (0)
>    - *M* training/fileio.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-277>
>    (0)
>    - *M* training/language-specific.sh
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-278>
>    (0)
>    - *M* training/ligature_table.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-279>
>    (0)
>    - *M* training/mftraining.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-280>
>    (0)
>    - *M* training/normstrngs.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-281>
>    (0)
>    - *M* training/normstrngs.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-282>
>    (0)
>    - *M* training/pango_font_info.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-283>
>    (0)
>    - *M* training/pango_font_info.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-284>
>    (0)
>    - *M* training/set_unicharset_properties.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-285>
>    (0)
>    - *M* training/stringrenderer.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-286>
>    (0)
>    - *M* training/stringrenderer.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-287>
>    (0)
>    - *M* training/tesstrain_utils.sh
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-288>
>    (0)
>    - *M* training/text2image.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-289>
>    (0)
>    - *M* training/unicharset_training_utils.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-290>
>    (0)
>    - *M* training/unicharset_training_utils.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-291>
>    (0)
>    - *M* viewer/scrollview.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-292>
>    (0)
>    - *M* viewer/scrollview.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-293>
>    (0)
>    - *M* viewer/svpaint.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-294>
>    (0)
>    - *M* viewer/svutil.cpp
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-295>
>    (0)
>    - *M* viewer/svutil.h
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-296>
>    (0)
>    - *M* vs2010/include/tesseract_versionnumbers.props
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-297>
>    (0)
>    - *M* vs2010/libtesseract/libtesseract.rc
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-298>
>    (0)
>    - *M* vs2010/libtesseract/libtesseract.vcxproj
>    <https://github.com/tesseract-ocr/tesseract/pull/791/files#diff-299>
>    (0)
>
> Patch Links:
>
>    - https://github.com/tesseract-ocr/tesseract/pull/791.patch
>    - https://github.com/tesseract-ocr/tesseract/pull/791.diff
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/791>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o0YkFcK3H7aulYtY1TPQ-sVsR_Hhks5rplW1gaJpZM4MpaDd>
> .
>
  run ./autogen.sh 

Running aclocal
Running /usr/local/bin/glibtoolize
glibtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, 'config'.
glibtoolize: copying file 'config/ltmain.sh'
.libtoolize:   error: AC_CONFIG_MACRO_DIRS([m4]) conflicts with ACLOCAL_AMFLAGS=-I m4

  Something went wrong, bailing out! No feedback from the OP. I suggest to close this issue.  I think we should publish in the README the official supported compilers, including minimum version for each compiler. Something like this:

## Supported Compilers
* GCC 4.8 and above
* Clang 3.4 and above
* MSVC 2015, 2017

Other compilers might work, but are not officially supported. Clang is not tested right now with CI. Can someone fix that? I mean Clang + libc++ on Mac.

Testing Clang + libstdc++ on Linux would be nice. Thanks Egor.

Zdenko, I'll send a PR in the following days.  //Keeping 
const int kMinCharactersToTry = 5
//Since working with text extraction from vehicle number plates needs less minimum number of characters. kMaxCharactersToTry may be //modified accordingly. The algorithm is designed to work with the current minimum value. Changing that const value might break it. I suggest not to accept this PR without Ray's approval.

Sorry, @ShahrukhSatti21. Another thing, Ray said he has a better (LSTM-based) OSD module that will replace the current one. @theraysmith, I think this PR should be rejected, right? Hi,
I was a beginner and too immature to ask such a basic question that too as
an issue. Later, I dug deeper into tesseract and a ROI finding algorithm
and compiled an executable to extract characters on number plates. There's
no need to consider this PR as the algo might not stay as generic as now.
Thanks for considering anyway.
On 29 Apr 2017 03:43, "theraysmith" <notifications@github.com> wrote:

> So far the new script id looks good.
> I don't understand why you would ever want to run OSD on license plates?
> It makes no sense.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/788#issuecomment-298123033>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZZViU6Own-LynXcCFTY4BsPkjOgjipiks5r0muOgaJpZM4MoCHs>
> .
>
  I'm forking this issue from #739 because the resolution of that issue has _not_ helped me fix Homebrew/homebrew-core#10380.  As logged [here](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/blob/master/Tesseract/v3.05.00/Third%20Attempt/reinstall.out#L1179–L1311), my latest build attempt fails as follows:  

```
⋮
/bin/sh ../libtool  --tag=CXX   --mode=link clang++  -g -O2 -std=c++11 -version-info 3:5 -no-undefined  -L/usr/local/opt/icu4c/lib -o libtesseract.la -rpath /usr/local/Cellar/tesseract/3.05.00/lib  libtesseract_api.la ../ccmain/libtesseract_main.la ../textord/libtesseract_textord.la ../wordrec/libtesseract_wordrec.la ../classify/libtesseract_classify.la ../dict/libtesseract_dict.la ../ccstruct/libtesseract_ccstruct.la ../cutil/libtesseract_cutil.la ../viewer/libtesseract_viewer.la ../ccutil/libtesseract_ccutil.la ../opencl/libtesseract_opencl.la ../cube/libtesseract_cube.la ../neural_networks/runtime/libtesseract_neural.la -llept 
libtool: link: clang++ -dynamiclib  -o .libs/libtesseract.3.dylib   -Wl,-force_load,./.libs/libtesseract_api.a -Wl,-force_load,../ccmain/.libs/libtesseract_main.a -Wl,-force_load,../textord/.libs/libtesseract_textord.a -Wl,-force_load,../wordrec/.libs/libtesseract_wordrec.a -Wl,-force_load,../classify/.libs/libtesseract_classify.a -Wl,-force_load,../dict/.libs/libtesseract_dict.a -Wl,-force_load,../ccstruct/.libs/libtesseract_ccstruct.a -Wl,-force_load,../cutil/.libs/libtesseract_cutil.a -Wl,-force_load,../viewer/.libs/libtesseract_viewer.a -Wl,-force_load,../ccutil/.libs/libtesseract_ccutil.a -Wl,-force_load,../opencl/.libs/libtesseract_opencl.a -Wl,-force_load,../cube/.libs/libtesseract_cube.a -Wl,-force_load,../neural_networks/runtime/.libs/libtesseract_neural.a  -L/usr/local/opt/icu4c/lib -llept  -g -O2   -install_name  /usr/local/Cellar/tesseract/3.05.00/lib/libtesseract.3.dylib -compatibility_version 4 -current_version 4.5 -Wl,-single_module
Undefined symbols for architecture x86_64:
  "_TIFFCleanup", referenced from:
      OpenclDevice::pixReadStreamTiffCl(__sFILE*, int) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadMemTiffCl(unsigned char const*, unsigned long, int) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFClientOpen", referenced from:
      OpenclDevice::pixReadMemTiffCl(unsigned char const*, unsigned long, int) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFFdOpen", referenced from:
      OpenclDevice::fopenTiffCl(__sFILE*, char const*) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFGetField", referenced from:
      OpenclDevice::getTiffStreamResolutionCl(tiff*, int*, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadFromTiffStreamCl(tiff*) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFGetFieldDefaulted", referenced from:
      OpenclDevice::getTiffStreamResolutionCl(tiff*, int*, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadFromTiffStreamCl(tiff*) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFReadDirectory", referenced from:
      OpenclDevice::pixReadStreamTiffCl(__sFILE*, int) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadMemTiffCl(unsigned char const*, unsigned long, int) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFReadRGBAImageOriented", referenced from:
      OpenclDevice::pixReadFromTiffStreamCl(tiff*) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFReadScanline", referenced from:
      OpenclDevice::pixReadFromTiffStreamCl(tiff*) in libtesseract_opencl.a(openclwrapper.o)
  "_TIFFScanlineSize", referenced from:
      OpenclDevice::pixReadFromTiffStreamCl(tiff*) in libtesseract_opencl.a(openclwrapper.o)
  "_clBuildProgram", referenced from:
      OpenclDevice::CompileKernelFile(_GPUEnv*, char const*) in libtesseract_opencl.a(openclwrapper.o)
  "_clCreateBuffer", referenced from:
      allocateZeroCopyBuffer(_KernelEnv, unsigned int*, unsigned long, unsigned long long, int*) in libtesseract_opencl.a(openclwrapper.o)
      allocateIntBuffer(_KernelEnv, unsigned int const*, unsigned long, int*, bool) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::initMorphCLAllocations(int, int, Pix*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::HistogramRectOCL(unsigned char*, int, int, int, int, int, int, int, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::ThresholdRectToPixOCL(unsigned char*, int, int, int*, int*, Pix**, int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixConvertRGBToGrayOCL(Pix*, float, float, float) in libtesseract_opencl.a(openclwrapper.o)
      ...
  "_clCreateCommandQueue", referenced from:
      populateGPUEnvFromDevice(_GPUEnv*, _cl_device_id*) in libtesseract_opencl.a(openclwrapper.o)
  "_clCreateContext", referenced from:
      populateGPUEnvFromDevice(_GPUEnv*, _cl_device_id*) in libtesseract_opencl.a(openclwrapper.o)
  "_clCreateKernel", referenced from:
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL(int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL(int, int, unsigned int, unsigned int) in libtesseract_opencl.a(openclwrapper.o)
      pixORCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      pixANDCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      ...
  "_clCreateProgramWithBinary", referenced from:
      OpenclDevice::CompileKernelFile(_GPUEnv*, char const*) in libtesseract_opencl.a(openclwrapper.o)
  "_clCreateProgramWithSource", referenced from:
      OpenclDevice::CompileKernelFile(_GPUEnv*, char const*) in libtesseract_opencl.a(openclwrapper.o)
  "_clEnqueueCopyBuffer", referenced from:
      OpenclDevice::initMorphCLAllocations(int, int, Pix*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixHollowCL(Pix*, Pix*, int, int, int, int, bool) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixGetLinesCL(Pix*, Pix*, Pix**, Pix**, Pix**, bool, int, int, int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
  "_clEnqueueMapBuffer", referenced from:
      mapOutputCLBuffer(_KernelEnv, _cl_mem*, Pix*, Pix*, int, unsigned long long, bool, bool) in libtesseract_opencl.a(openclwrapper.o)
      allocateIntBuffer(_KernelEnv, unsigned int const*, unsigned long, int*, bool) in libtesseract_opencl.a(openclwrapper.o)
      copyIntBuffer(_KernelEnv, _cl_mem*, unsigned int const*, unsigned long, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::HistogramRectOCL(unsigned char*, int, int, int, int, int, int, int, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::ThresholdRectToPixOCL(unsigned char*, int, int, int*, int*, Pix**, int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixConvertRGBToGrayOCL(Pix*, float, float, float) in libtesseract_opencl.a(openclwrapper.o)
      ...
  "_clEnqueueNDRangeKernel", referenced from:
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL(int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL(int, int, unsigned int, unsigned int) in libtesseract_opencl.a(openclwrapper.o)
      pixORCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      pixANDCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      ...
  "_clEnqueueUnmapMemObject", referenced from:
      mapOutputCLBuffer(_KernelEnv, _cl_mem*, Pix*, Pix*, int, unsigned long long, bool, bool) in libtesseract_opencl.a(openclwrapper.o)
      allocateIntBuffer(_KernelEnv, unsigned int const*, unsigned long, int*, bool) in libtesseract_opencl.a(openclwrapper.o)
      copyIntBuffer(_KernelEnv, _cl_mem*, unsigned int const*, unsigned long, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::HistogramRectOCL(unsigned char*, int, int, int, int, int, int, int, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::ThresholdRectToPixOCL(unsigned char*, int, int, int*, int*, Pix**, int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixConvertRGBToGrayOCL(Pix*, float, float, float) in libtesseract_opencl.a(openclwrapper.o)
      ...
  "_clFinish", referenced from:
      mapOutputCLBuffer(_KernelEnv, _cl_mem*, Pix*, Pix*, int, unsigned long long, bool, bool) in libtesseract_opencl.a(openclwrapper.o)
      allocateIntBuffer(_KernelEnv, unsigned int const*, unsigned long, int*, bool) in libtesseract_opencl.a(openclwrapper.o)
      copyIntBuffer(_KernelEnv, _cl_mem*, unsigned int const*, unsigned long, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::HistogramRectOCL(unsigned char*, int, int, int, int, int, int, int, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::ThresholdRectToPixOCL(unsigned char*, int, int, int*, int*, Pix**, int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixConvertRGBToGrayOCL(Pix*, float, float, float) in libtesseract_opencl.a(openclwrapper.o)
      ...
  "_clGetContextInfo", referenced from:
      OpenclDevice::CompileKernelFile(_GPUEnv*, char const*) in libtesseract_opencl.a(openclwrapper.o)
  "_clGetDeviceIDs", referenced from:
      OpenclDevice::getDeviceSelection() in libtesseract_opencl.a(openclwrapper.o)
  "_clGetDeviceInfo", referenced from:
      populateGPUEnvFromDevice(_GPUEnv*, _cl_device_id*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::getDeviceSelection() in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::BinaryGenerated(char const*, __sFILE**) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::GeneratBinFromKernelSource(_cl_program*, char const*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::HistogramRectOCL(unsigned char*, int, int, int, int, int, int, int, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::ThresholdRectToPixOCL(unsigned char*, int, int, int*, int*, Pix**, int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
  "_clGetPlatformIDs", referenced from:
      OpenclDevice::getDeviceSelection() in libtesseract_opencl.a(openclwrapper.o)
  "_clGetProgramBuildInfo", referenced from:
      OpenclDevice::CompileKernelFile(_GPUEnv*, char const*) in libtesseract_opencl.a(openclwrapper.o)
  "_clGetProgramInfo", referenced from:
      OpenclDevice::GeneratBinFromKernelSource(_cl_program*, char const*) in libtesseract_opencl.a(openclwrapper.o)
  "_clReleaseCommandQueue", referenced from:
      OpenclDevice::ReleaseOpenclEnv(_GPUEnv*) in libtesseract_opencl.a(openclwrapper.o)
  "_clReleaseContext", referenced from:
      OpenclDevice::ReleaseOpenclEnv(_GPUEnv*) in libtesseract_opencl.a(openclwrapper.o)
  "_clReleaseMemObject", referenced from:
      OpenclDevice::releaseMorphCLBuffers() in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::HistogramRectOCL(unsigned char*, int, int, int, int, int, int, int, int*) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::ThresholdRectToPixOCL(unsigned char*, int, int, int*, int*, Pix**, int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      OpenclDevice::pixConvertRGBToGrayOCL(Pix*, float, float, float) in libtesseract_opencl.a(openclwrapper.o)
  "_clReleaseProgram", referenced from:
      OpenclDevice::ReleaseOpenclEnv(_GPUEnv*) in libtesseract_opencl.a(openclwrapper.o)
  "_clSetKernelArg", referenced from:
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL(int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL(int, int, unsigned int, unsigned int) in libtesseract_opencl.a(openclwrapper.o)
      pixORCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      pixANDCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      ...
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[1]: *** [libtesseract.la] Error 1
make: *** [install-recursive] Error 1
⋮
```

Both I and those other GitHub users who were helping me with this issue downstream thought it was another instance of the aforementioned #739, but I now think that we were mistaken in believing this given how said issue was resolved.  Basically, the crux of the problem is this:  is there something that previous committers have neglected to add to Homebrew's Tesseract build formula other than Homebrew/homebrew-core#10596, or is Tesseract at fault here and does solving this require Homebrew to mirror an upstream patch until the next release?   Whoops; I should have given that to you in the first place, shouldn't I?  Ah, well, here those details are now:  

* I initially built and installed Tesseract from within Homebrew by running `brew install -vd --build-from-source tesseract --with-all-languages --with-opencl --with-serial-num-pack --with-training-tools`, update it by running `brew upgrade -vd --build-from-source tesseract --with-all-languages --with-opencl --with-serial-num-pack --with-training-tools`, and retry doing either procedure when they fail by running `brew reinstall -vd --build-from-source tesseract --with-all-languages --with-opencl --with-serial-num-pack --with-training-tools`.  Executing either causes Homebrew to process `"$(brew --repository homebrew/homebrew-core)/Formula/tesseract.rb"` (a GitHub copy of which is available [here](https://github.com/Homebrew/homebrew-core/blob/master/Formula/tesseract.rb),) where `"$(brew --repository homebrew/homebrew-core)"` is `/usr/local/Homebrew/Library/Taps/homebrew/homebrew-core` (its default, officially supported location,) according to the `brew` sub-command given, Homebrew's DSL, and the options I provide using the processing defined in the relevant formula.  @JCount confirmed in [this comment](https://github.com/Homebrew/homebrew-core/issues/10380#issuecomment-282604860) on [my downstream issue](https://github.com/Homebrew/homebrew-core/issues/10380) that the option causing trouble is `--with-opencl`, which, as shown on [line 94](https://github.com/Homebrew/homebrew-core/blob/master/Formula/tesseract.rb#L94) of the Homebrew Core tap's `tesseract.rb` formula, corresponds to Tesseract's `./configure`'s `--enable-opencl` option.  
* The output I get from `./configure` is present in [my most recent Homebrew installation attempt logs](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/tree/master/Tesseract/v3.05.00/Third%20Attempt) as both [`02.configure`](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/blob/master/Tesseract/v3.05.00/Third%20Attempt/02.configure) and [lines 134–339](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/blob/master/Tesseract/v3.05.00/Third%20Attempt/reinstall.out#L134-L339) of [`reinstall.out`](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/blob/master/Tesseract/v3.05.00/Third%20Attempt/reinstall.out).  
* The versions of the build and run-time dependencies required by Tesseract under Homebrew I have installed on my machine are as follows:  
  * `autoconf` v2.69
  * `autoconf-archive` v2017.03.21
  * `automake` v1.15
  * GNU `libtool` v2.4.6, but patched by the Homebrew Core tap to resolve Homebrew/homebrew-core#3056 and Homebrew/homebrew-core#3882.  (_Not_ the `libtool` provided by Apple as part of its command-line tools suite, which I _also_ have installed.)  
  * `pkg-config` v0.29.2
  * Leptonica v1.74.1 (Built with the following dependencies:  
    * `pkg-config` v0.29.2
    * libpng v1.6.29
    * jpeg v8d
    * LibTIFF v4.0.7, but patched by the Homebrew Core tap to resolve Homebrew/homebrew-core#8639 and Homebrew/homebrew-core#9409.  —&thinsp;Dependencies are as follows:  
      * jpeg v8d
      * xz v5.2.3
    * GIFlib v4.2.3 with a dependency as follows:  
      * X11 (supplied by XQuartz v2.7.11)
    * OpenJPEG v2.1.2 with dependencies as follows:  
      * CMake v3.7.2 with a dependency as follows:  
        * Sphinx v1.5.1
      * Little-CMS2 v2.8 with dependencies as follows:  
        * jpeg v8d
        * LibTIFF v4.0.7 as described above for Leptonica itself
      * LibTIFF v4.0.7 as described above for Leptonica itself
      * libpng v1.6.29
    * WebP v0.6.0 with dependencies as follows:  
      * libpng v1.6.29
      * jpeg v8d
      * LibTIFF v4.0.7 as described above for Leptonica itself
      * GIFlib v4.2.3 with a dependency as described earlier.)

Is that everything you need, or do I need to provide anything else?   @zdenop:  Roger, wilco.  That _is_ odd, though, so whatever could have caused _that…?_   @zdenop:  I keep getting the following error from `./configure` despite the fact that I have Cairo installed even when I add `-I/usr/local/opt/cairo/include` to `CPPFLAGS` (though should that be `CFLAGS` instead…?) and `-L/usr/local/opt/cairo/lib` to `LDFLAGS`:  

```
checking for cairo... no
configure: WARNING: Training tools WILL NOT be built because of missing cairo library.
configure: WARNING: Try to install libcairo-dev?? package.

⋮

You can not build training tools because of missing dependency.
Check configure output for details.
```

Should I be worried about this, or can I just ignore this error since the build problem I'm trying to solve is, IIRC, in Tesseract itself?  I was going to try and make my out-of-Homebrew build and install as close to my _in_-Homebrew one, which said it was going to include the training tools if it had succeeded, if you're wondering why I'm asking.  I don't want to overwrite my current _non_-development version of Cairo in the process, so what do I do?   @stweil:  Ah, thanks.  

<hr />

@zdenop:  Heh, whoops; looks like I was mentally applying the conceptual equivalent of `-Wwarnings-as-errors`, then; my mistake!  In any case, that's what I thought (I just wanted to make sure my judgement was correct by checking with you,) so I'll go ahead and continue this build attempt.   See https://github.com/tesseract-ocr/tesseract/wiki/Compiling for a list of required dependencies. For training tools you need the Dev version of libraries. @Shreeshrii:  That's what confused me in the _first_ place, as _Homebrew_ seems to be able to build the training tools just fine with the _production_ versions of their dependencies.  Perhaps it implements some sort of hack to make this (mostly) work, but I'd have to check the package manager's Tesseract formula to be sure of that, as I don't remember seeing anything special there before, which is odd…; maybe the difference is further up in the dependency chain and has to do with Homebrew presents some of its nodes to other software packages?  Or perhaps there's a Homebrew shim I don't know about, but I _thought_ I remembered that the package manager only instrumented system-level build tools…   Now that I've kept thinking about this discrepancy for a little bit, maybe it has to do with Homebrew's [`superenv` shim](https://github.com/Homebrew/brew/blob/master/Library/Homebrew/extend/ENV/super.rb)…?   @zdenop:  OK, [here](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/tree/master/Tesseract/v3.05.00/Fourth%20Attempt) are the logs from my attempt to build Tesseract manually outside of Homebrew.  [The new failure](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/blob/master/Tesseract/v3.05.00/Fourth%20Attempt/make.out#L840-L973) looks identical to [the one produced when building _inside_ Homebrew](https://github.com/RandomDSdevel/Homebrew-Installation-Logs/blob/master/Tesseract/v3.05.00/Third%20Attempt/reinstall.out#L1179–L1311) at first glance modulo the `make` procedure's exit status, and I don't think I see `-framework OpenCL` anywhere in my build logs, either, which is weird since you say Tesseract's `./configure` should add that in where needed.  

P. S.:  I have now compared the undefined symbols diagnosed by each of the log files I just referenced and found them to be identical.   @zdenop:  Would like me to run another attempt with `make`'s verbosity increased?   When this issue first cropped up in Homebrew, I tried building it outside of Homebrew's framework in a clean VM. I unsuccessfully tried various approaches, which I have of course forgotten, but it always fails with:
```
      ...
"_clSetKernelArg", referenced from:
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL(int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL(int, int, unsigned int, unsigned int) in libtesseract_opencl.a(openclwrapper.o)
      pixORCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      pixANDCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      ...
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[1]: *** [libtesseract.la] Error 1
make: *** [install-recursive] Error 1
```

Also, I can confirm this is still an issue using Xcode 8.3 on macOS 10.12.4 as well, no magical, mysterious fix with the latest update. @JCount:  Well, _that's_ not encouraging.  I'd update my environment to Sierra and the latest Xcode myself, but I'm stuck on an unsupported machine for the time being.  Since it doesn't help in this particular instance, however, I guess I shouldn't push myself to worry about that!  😆

<hr />

@zdenop:  Given that this issue is consistently reproducible both inside and outside of Homebrew, should we perhaps change this issue's title to something more like 'OS X/macOS OpenCL Linkage Errors?'   Maybe it's not a macOS issue, but a Clang issue.

Did someone tested 3.05 on Linux with Clang & OpenCL? @amitdo:  Not that I know of.  I don't personally have a Linux install available for testing, either.   > Did someone tested 3.05 on Linux with Clang & OpenCL?

I just tested the build, and it worked without any problem using `./configure CXX=clang++-3.8 CXXFLAGS="-g -O2 -Wall" --enable-opencl && make training`. @stweil:  What about Clang 4?  According to Homebrew, that's what I've got installed:  

```
…$ brew info llvm
llvm: stable 4.0.0 (bottled), HEAD [keg-only]
Next-gen compiler infrastructure
http://llvm.org/
/usr/local/Cellar/llvm/4.0.0 (4,450 files, 2GB)
  Built from source on 2017-03-15 at 00:35:00 with: --with-toolchain --with-python --with-graphviz
From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/llvm.rb
==> Dependencies
Build: cmake ✔
Recommended: libffi ✔
Optional: graphviz ✔, ocaml ✔
==> Requirements
Optional: python ✔
==> Options
--with-graphviz
	Build with graphviz support
--with-lldb
	Build LLDB debugger
--with-ocaml
	Build with ocaml support
--with-python
	Build bindings against custom Python
--with-shared-libs
	Build shared instead of static libraries
--with-toolchain
	Build with Toolchain to facilitate overriding system compiler
--without-compiler-rt
	Do not build Clang runtime support libraries for code sanitizers, builtins, and profiling
--without-libcxx
	Do not build libc++ standard library
--without-libffi
	Do not use libffi to call external functions
--HEAD
	Install HEAD version
==> Caveats
LLVM executables are installed in /usr/local/opt/llvm/bin.
Extra tools are installed in /usr/local/opt/llvm/share/llvm.
To use the bundled libc++ please add the following LDFLAGS:
  LDFLAGS="-L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib"

This formula is keg-only, which means it was not symlinked into /usr/local.

macOS already provides this software and installing another version in
parallel can cause all kinds of trouble.

If you need to have this software first in your PATH run:
  echo 'export PATH="/usr/local/opt/llvm/bin:$PATH"' >> ~/.bash_profile

For compilers to find this software you may need to set:
    LDFLAGS:  -L/usr/local/opt/llvm/lib
    CPPFLAGS: -I/usr/local/opt/llvm/include


If you need Python to find bindings for this keg-only formula, run:
  echo /usr/local/opt/llvm/lib/python2.7/site-packages >> /usr/local/lib/python2.7/site-packages/llvm.pth
``` Scratch that:  now I feel somewhat silly, as, according to [Apple's list of Macs that support OpenCL](https://support.apple.com/en-us/HT202823), my machine (a mid-2007 aluminum iMac) is listed as supporting a 'non-applicable' version of the standard&thinsp;—&thinsp;that is, none at all!  This issue may still be relevant if @JCount's still seeing issues with _his_ setup, though, unless he _also_ has an unsupported machine….  The runtime might still be present in my installation, though, as I've seen the Metal binaries just floating somewhere waiting for when I clone this drive's contents into a machine that supports _that_ API, so I'm not entirely sure whether that means I should be seeing link-time errors or not.  With 3.04.01, I was seeing _run_-time errors, possibly even with _return values_ (can't remember what they were off the top of my head, unfortunately, but I'm _pretty_ sure I still have my old Tesseract installation around, so I can go check.)   I think you need OpenCL **1.2** or higher. @amitdo:  Well, again, that _might_ explain things… I have a machine that supports OpenCL 1.2, both with the Intel Iris Pro Graphics 5200 iGPU and the AMD Radeon R9 M370X dGPU. Yes, it seems to detect the presence of the OpenCL headers, and therefore framework. The issue seems to be in the linking as you say, and I honestly have no idea what is going wrong there. @zdenop, @JCount:  Strangely enough, here is the result of a bit of investigation I just did on my end:  

```
…$ ls -@aHhl /System/Library/Frameworks/ | grep OpenCL.framework
drwxr-xr-x    8 root  wheel   272B Dec 13 16:41 OpenCL.framework
```

So the OpenCL runtime _is_ present on my machine even if it's not _doing_ anything other than just _sitting_ there.  Either this just gets installed with the OS whether your machine supports it or not or the framework's presence is a relic of that one time I tried to install OS X so as to make it bootable on both this iMac and a newer MacBook Pro (can't remember the exact model ATM, sorry…) by _first_ running a clean OS install to this external drive from the latter and _then_ doing an _delta_ install to said drive from the _former_&thinsp;—&thinsp;though I _think_ I may have once done a clean install to the drive in question just from the iMac, so maybe my earlier hypothesis is correct…?  :man_shrugging:   I got vanilla (no homebrew) Tesseract 3.05 to compile and run. Machine is late 2013 iMac 27" with Sierra and OpenCL 1.2 support.

```
clang --version
Apple LLVM version 8.1.0 (clang-802.0.38)
```

```
./configure --enable-opencl LDFLAGS='-framework OpenCL' LIBS='-ltiff'
make -j
```

When the explicit `LDFLAGS='-framework OpenCL'` is removed the build fails. For some reason  `--enable-opencl` does not enable linking `-framework OpenCL` everywhere it should. Doing this causes `-framework OpenCL` to also show up twice sometimes, based on skimming the logs, so it works partially but incompletely.

Likewise, removing the explicit `libtiff` linkage will fail.

I don't have a lot of time to investigate the build machinery this week, but hopefully this analysis is enough of a clue to figure what is not working. If nobody bites I will look into it next week.

I did not try building training tools.

 @zdenop, @stweil, @JCount, and/or @jbarlow83:  What testing remains to be done with respect to tracking down exactly what's going wrong here?  Might there be anything _I_ could do to help?   @RandomDSdevel In `configure.ac` there is some logic that says "if we get `--enable-opencl` and we are only a Mac, set the variable named `OPENCL_LDFLAGS="-framework OpenCL"`, the special argument for Mac frameworks. Other platforms are working fine because they don't have or don't use `-framework` as far as I know. I actually don't know the details of what it does.

Most likely there is a `Makefile.am` (probably) that should set its local `local_LDFLAGS= $(OPENCL_LDFLAGS)` because it uses OpenCL, but does not. Or perhaps it is the main Makefile at the link step.

The lazy way would be to jump back about six months or so to find a version that compiled and git bisect your way to the breaking change, since it did work until recently. @jbarlow83:  Well, I'm not very fluent in Autoconf, Automake, and/or makefile syntax and have never used `git bisect` before, but I know `bash` shell scripting syntax well enough that I _think_ I can at _least_ point others in the right direction to _look._  The v3.05 logic in [`configure.ac`](https://github.com/tesseract-ocr/tesseract/blob/3.05/configure.ac) that's responsible for handling that script's `--enable-opencl` option occupies [lines 173–248](https://github.com/tesseract-ocr/tesseract/blob/3.05/configure.ac#L173-L248)&thinsp;—&thinsp;specifically, `OPENCL_LDFLAGS` is set to `"-framework OpenCL"` on [line 223](https://github.com/tesseract-ocr/tesseract/blob/3.05/configure.ac#L223) in the middle of the code ([lines 211-225](https://github.com/tesseract-ocr/tesseract/blob/3.05/configure.ac#L211-L225)) responsible for setting up the correct OpenCL compilation and linkage flags for use on Darwin-based operating systems like OS X/macOS.  I haven't yet looked for or at a `Makefile.am`, but I _do_ remember seeing one somewhere in the source code earlier; I'll just have to look for it again (hopefully it's in the repository's root directory or not far from it.)  If _that_ doesn't give us any clues, I'll check this 'main Makefile,' whatever it happens to be called.   @jbarlow83:  I checked in my last local build attempt and neither `"$(git rev-parse --show-toplevel)/Makefile.in"`, `"$(git rev-parse --show-toplevel)/Makefile.am"`, _nor_ `"$(git rev-parse --show-toplevel)/Makefile"` (the first and third of which are generated by `"$(git rev-parse --show-toplevel)/aurogen.sh"` and/or `"$(git rev-parse --show-toplevel)/configure.ac"`&thinsp;—sorry, but I can't exactly remember which script does what at the moment…) mess with any kind of `local_LDFLAGS` variable.  In fact, I ran `find . -type f -print0 | xargs -0 grep "*local_LDFLAGS*"` inside my local checkout of the Tesseract repository (still on branch `3.05` with artifacts left over from my last failed out-of-Homebrew/vanilla build) and came up _empty_&thinsp;—&thinsp;but maybe I was doing something wrong with this command pipeline invocation…?   As I mentioned I can look into this next week, just not now.

The issue is likely that some new code was introduced and the build system was not properly modified so there is no code to search for it. It is the absence of some necessary code that is the trouble. As you're not familiar with autotools my rough problem sketch is probably not helpful. What would help is to run `git bisect` and find the commit that breaks the build on macOS, since it used to work. That is likely a strong indicator of what kind of fix is needed. @jbarlow83:  Sorry to bother you with details you probably could have figured out easily enough yourself, then.   @RandomDSdevel, please try pull request #808. It fixes `make training` with OpenCL on macOS for me. Don't forget to run `./autogen.sh` after applying the change. @stweil:  Thanks, but I'm not sure that will help with _this_ issue, as it has to do with not being able to linking Tesseract _itself_ with OpenCL…  As I mentioned before, though, _this_ problem might _alos_ have something to do with the fact that invoking OpenCL functionality on my machine probably only returns responses indicating the fact that the library doesn't work with my graphics card, as Apple never supplied drivers for it.  @JCount, however, has a machine that _does_ support OpenCL and said he's getting similar link-time errors.  IIRC, @jbarlow83 has also reproduced this issue and has said he'd look into trying to fix it some time this week, but I'm not going to invoke him any further than that, as he advised not to badger him too much about it (I've _probably_ already annoyed him _enough_ as it _is_, what with my overly enthusiastic impatience to get this fixed and all…)  That being said, I'll still take a look at the PR you've pointed me towards and see if does anything to help.   I'm not annoyed at all, I just have to do the work that pays the bills first. :) @jbarlow83:  Whoops, look like I was reading a little too much into things, ha-ha…   @jbarlow83:  Just saw your work start popping up in #814.  I have one comment on it, but I'll leave it in the relevant discussion thread.    Hi,
trying to pipe a pdf file, converted by graphicsmagic to tif, to tesseract stdin gives me following error output, but the generated PDF is ok.

my cmd line:
`gm.exe convert -density 300 pdfin.pdf tif:- | tesseract.exe stdin pdfout -l deu pdf`

---

tesseract version:
tesseract 4.00.00alpha                                                                                      
 leptonica-1.74.1 (Mar 23 2017, 02:16:52) [MSC v.1910 LIB Release x64]                                      
  libgif 5.1.4 : libjpeg 9b : libpng 1.6.28 : libtiff 4.0.7 : zlib 1.2.11 : libwebp 0.6.0 : libopenjp2 2.1.2
                                                                                                            
 Found AVX                                                                                                  
 Found SSE

---

tesseracts output:
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Page 2
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Page 3
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Page 4
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found

Maybe a Bug? no errors, text output seems to be ok! thank you too.  Please see https://groups.google.com/forum/#!msg/tesseract-ocr/24rrQjxLJl8/hNJEtLx4FQAJ

 >Moved cube aside without deleting it.

Since then, Ray deleted the Cube code.

...except that leftover in the enum.
 https://github.com/tesseract-ocr/tesseract/blob/d2fcfcaec2/ccstruct/publictypes.h#L268  Add  major updates to 4.0.0alpha by Ray since Nov, 2016.

@zdenop, @stweil, @egorpugin @amitdo Please update with other major changes. Thanks! >\+ Remove support for VS2010.

@egorpugin
Does Tesseract 4.0 built with CMake supports VS2010 or not? ```
  + Add Support for VS2015 and VS2017 with cppan
  + Implement invisible text only for PDF
  + Add AVX / SSE support for Windows
  + Require leptonica 1.74 or higher
``` Thanks, I have combined the updates for date range from Nov 2016 to March 2017. Suggest that any major commits also add to the changelog on regular basis.

Does semantic versioning requiring more frequent tagging?

@zdenop Please approve merge. Thanks! @amitdo  I thought that you had made a similar list adding to release notes... Can't seem to find it now. Shree, here it is:
https://github.com/tesseract-ocr/tesseract/wiki/ReleaseNotes#in-development Thanks.

- excuse the brevity, sent from mobile

On 24-Mar-2017 5:22 PM, "Amit D." <notifications@github.com> wrote:

> Shree, here it is:
> https://github.com/tesseract-ocr/tesseract/wiki/
> ReleaseNotes#in-development
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/783#issuecomment-289003475>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o53dpBF51d4gZOIcYaf3F9O1R6cZks5ro66JgaJpZM4MmauK>
> .
>
  I am running the same command line as for the 3.x versions with 

-c preserve_interword_spaces=1

as option. The resulting text does not preserve the white spaces, which it correctly did for the 3.x version.

Thanks
Andre I am also facing the same problem. After using "preserve_interword_spaces", there is actually no significant difference noticed between the normal OCR and "preserve_interword_spaces=1" parameterized OCR.
Is there any solution? Same problem here. "preserve_interword_spaces" has no effect.
Also many other parameters do not work in v4.0 :/
Would be nice to get some feedback from the developers (which parameter works/which not) I have the same problem in version 4.0. I have tried with version 3.0.2 - It does not have this option. I also noticed this problem and it seems related with the trained data, because if I use tesseract 4 with the trained data of 3.05 I do get the interword spaces.
```
#!/bin/sh
export PATH=$HOME/local/tesseract/bin:$PATH
export LD_LIBRARY_PATH=$HOME/local/tesseract/lib:$LD_LIBRARY_PATH
#ubuntu tesseract 3 trained data
export TESSDATA_PREFIX=/usr/share/tesseract-ocr
#export TESSDATA_PREFIX=$HOME/local/tesseract/share/tessdata
tesseract $*

#tesseract -l spa -psm 4 $1 scanned
#mytesseract -c preserve_interword_spaces=1 -l spa  $1 scanned
``` >I also noticed this problem and it seems related with the trained data, because if I use tesseract 4 with the trained data of 3.05 I do get the interword spaces.

With 4.00, If you don't use the --oem option, the default oem will be used:

>3    Default, based on what is available.

The traineddata files for 3.05 does not have lstm data, so oem 3 in your case is equivalent to:

>0    Original Tesseract only. Thanks for pointing out !
I dived on tesseract source code and found an almost solution to the preserve_interword_spaces problem, it seems that when transferring the words in ccstruct/pageres.cpp the spaces were not transfered see patch bellow.
With this patch the output is almost identical with the 3.05 version except for the missing spaces for the first column (need more research to see where the first/second word is transfered and why the spaces/blanks are not).
```
@@ -1329,11 +1329,11 @@ void PAGE_RES_IT::ReplaceCurrentWord(
   WERD_RES* input_word = word();
   // Set the BOL/EOL flags on the words from the input word.
   if (input_word->word->flag(W_BOL)) {
     (*words)[0]->word->set_flag(W_BOL, true);
   } else {
-    (*words)[0]->word->set_blanks(1);
+    (*words)[0]->word->set_blanks(input_word->word->space());
   }
   words->back()->word->set_flag(W_EOL, input_word->word->flag(W_EOL));
 
   // Move the blobs from the input word to the new set of words.
   // If the input word_res is a combination, then the replacements will also be
``` Can't reproduce @Shreeshrii :/
I tried it with the python tesserocr wrapper like so:

> tess = PyTessBaseAPI(init=False, lang="eng", psm=PSM.SINGLE_BLOCK)
settings = {"preserve_interword_spaces": "1"}
tess.InitFull(lang="eng", oem=OEM.LSTM_ONLY, variables=settings)
tess.SetSourceResolution(300)
tess.SetPageSegMode(PSM.SINGLE_BLOCK)
img = Image.open("image.jpg")
tess.SetImage(img)
> print(tess.GetUTF8Text())

prints the text without preserved spaces :/

Also tried it through the command line as follows:

> tesseract image.jpg --tessdata_dir /usr/local/share/tessdata --oem 1 --psm 6 -l eng -c 
> preserve_interword_spaces=1

Gives me this error:

> tesseract: genericvector.h:713: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

I use the .traineddata files from https://github.com/tesseract-ocr/tessdata/tree/master/best
and latest leptonica & tesseract
Any advice please? :) Thanks, it works!
  Getting the famous : 

```
./configure: line 4250: syntax error near unexpected token `-mavx,'
./configure: line 4250: `AX_CHECK_COMPILE_FLAG(-mavx, avx=true, avx=false)'

```
However, actually read the doc and googled around, and i do have the autoconf-archive package installed >< That was it. Thanks! Did you run ./autogen.sh after the installation of autoconf-archive? (see also comment above) https://github.com/tesseract-ocr/tesseract/wiki/Compiling#macos for the life of god I can't manage to install or compile "autoconf-archive" on Amazon Linux AMI (it has yum, not apt-get).
Can anyone point me to instruction about how to install it? https://aws.amazon.com/amazon-linux-ami/faqs/

>Q: How do I enable the Extra Packages for Enterprise Linux (EPEL) repository?

Read the answer.
 thanks @amitdo, but no luck:

> [ec2-user@ip-172-31-31-253 ~]$ sudo yum install autoconf-archive --enablerepo=epel
> Loaded plugins: priorities, update-motd, upgrade-helper
> 1039 packages excluded due to repository priority protections
> No package autoconf-archive available.
> Error: Nothing to do  `Debian GNU/Linux 8 (jessie)`

When doing `./configure` I get this error

```
cd /var/bin && git clone https://github.com/tesseract-ocr/tesseract.git
cd tesseract && ./autogen.sh && ./configure
```

# error
```
# ./configure
checking for g++... g++
checking whether the C++ compiler works... yes
checking for C++ compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
Using git revision: 4.00.00alpha-339-ga51d0d4
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking for gawk... gawk
checking whether make sets $(MAKE)... yes
checking for style of include used by make... GNU
checking whether make supports nested variables... yes
checking dependency style of g++... gcc3
checking whether to enable maintainer-specific portions of Makefiles... no
checking build system type... x86_64-unknown-linux-gnu
checking host system type... x86_64-unknown-linux-gnu
./configure: line 4230: syntax error near unexpected token `-mavx,'
./configure: line 4230: `AX_CHECK_COMPILE_FLAG(-mavx, avx=true, avx=false)'

``` +1 :) Have now done what you said and installed all dependencies but get a new error when compiling my program

# install
```
apt-get install autoconf-archive pango-devel cairo-devel icu-devel
cd /var/bin && git clone https://github.com/tesseract-ocr/tesseract.git
cd tesseract && ./autogen.sh && ./configure && make && make install && ldconfig
```

# compiling my program
```
# g++ -std=c++11 txtocr.cpp -o txtocr -llept -ltesseract
/usr/bin/ld: warning: liblept.so.5, needed by //usr/local/lib/libtesseract.so, may conflict with liblept.so.4
``` found out I had installed leptonica through apt-get :)  After upgrading to `4.00` my program using tesseract is broken

Installing `tesseract 4.00`
```
cd /var/bin && wget https://github.com/tesseract-ocr/tesseract/archive/4.00.00alpha.tar.gz -O tesseract-4.00.00alpha.tar.gz && tar -xvf tesseract-4.00.00alpha.tar.gz
cd tesseract-4.00.00alpha && ./autogen.sh && ./configure && make && make install
```

Compiling program
```
g++ -std=c++11 txtocr.cpp -o txtocr -llept -ltesseract
```

Running program
```
# ./txtocr
./txtocr: error while loading shared libraries: libtesseract.so.4: cannot open shared object file: No such file or directory
``` # txtocr.cpp
```
/*
 *	Compile
 *	# g++ -std=c++11 txtocr.cpp -o txtocr -llept -ltesseract
 *
 *	Get tesseract version
 *	# pkg-config --modversion tesseract
*/

#include "txtocr.hpp"

void usage(const std::string VERSION){
	tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();
	
	std::cerr << "txtocr version: " << VERSION << "\nTesseract version: " << api->Version() << "\n\nUsage: txtocr input [options]\n"
		"Options:\n"
		"\t-l <string>          -- Set iterator level\n"
		"\t                        (Values: block | para | line | word | symbol)\n"
		"\t-d                   -- Debug (Verbose)\n" << std::endl;
}

int main(int argc, char* argv[]){
	Txtocr a;
	
	try{
		a.set_level("");
		
		//	Parse arguments
		for(int i = 1; i < argc; i++){
			std::string arg = std::string(argv[i]);
			
			if(i == 1){
				a.set_input(arg);
			}
			else if(arg == "-l"){
				a.set_level(argv[++i]);
			}
			else if(arg == "-d"){
				a.set_debug(true);
			}
			else{
				throw std::runtime_error("Argument '"+arg+"' is invalid");
			}
		}
		
		std::cout << a.run() << std::endl;
	}
	catch(std::exception& e){
		std::cerr << "Error: " << e.what() << "\n" << std::endl;
		usage(a.VERSION);
		return 1;
	}
	
	return 0;
}
```

# txtocr.h
```
class Txtocr{
	private:
		std::string input 					= "";
		tesseract::PageIteratorLevel level;
		bool is_debug						= false;
		void error							(const std::string& s);
		std::string utf8_to_latin			(const char * in);
	
	public:
		Txtocr();
		const std::string VERSION			= "0.1";
		void set_input						(const std::string& s);
		void set_level						(const std::string& s);
		void set_debug						(bool d);
		std::string run						();
};
```

# txtocr.hpp
```
#include <iostream>
#include <stdexcept>
#include <fstream>
#include <chrono>
#include <string>
#include <vector>
#include <math.h>
#include <boost/algorithm/string.hpp>
#include <tesseract/baseapi.h>
#include <leptonica/allheaders.h>
#include <boost/property_tree/ptree.hpp>
#include <boost/property_tree/json_parser.hpp>
#include "txtocr.h"

Txtocr::Txtocr(){}

void Txtocr::set_input(const std::string& s){
	input = s;
}

void Txtocr::set_level(const std::string& s){
	if(s == ""){
		level = tesseract::RIL_TEXTLINE;
	}
	else if(s == "block"){
		level = tesseract::RIL_BLOCK;
	}
	else if(s == "para"){
		level = tesseract::RIL_PARA;
	}
	else if(s == "line"){
		level = tesseract::RIL_TEXTLINE;
	}
	else if(s == "word"){
		level = tesseract::RIL_WORD;
	}
	else if(s == "symbol"){
		level = tesseract::RIL_SYMBOL;
	}
	else{
		error("Invalid iterator level");
	}
}

void Txtocr::set_debug(bool d){
	is_debug = d;
}

void Txtocr::error(const std::string& s){
	throw std::runtime_error(s);
}

std::string Txtocr::utf8_to_latin(const char* in){
	std::string out;
	
	if(in == NULL){
		return out;
	}
	
	unsigned int codepoint;
	while (*in != 0){
		unsigned char ch = static_cast<unsigned char>(*in);
		if(ch <= 0x7f){
			codepoint = ch;
		}
		else if(ch <= 0xbf){
			codepoint = (codepoint << 6) | (ch & 0x3f);
		}
		else if(ch <= 0xdf){
			codepoint = ch & 0x1f;
		}
		else if(ch <= 0xef){
			codepoint = ch & 0x0f;
		}
		else{
			codepoint = ch & 0x07;
		}
		
		++in;
		
		if(((*in & 0xc0) != 0x80) && (codepoint <= 0x10ffff)){
			if(codepoint <= 255){
				out.append(1, static_cast<char>(codepoint));
			}
			else{
				// do whatever you want for out-of-bounds characters
			}
		}
	}
	
	return out;
}

std::string Txtocr::run(){
	//	Return error if input file is not defined
	if(input == ""){
		error("Input file not defined");
	}
	//	Return error if input file is not TIFF
	else{
		std::string input_lc = input;
		boost::to_lower(input_lc);
		if(input_lc.substr(input_lc.find_last_of(".") + 1) != "tif"){
			error("Input file must be TIFF");
		}
	}
	
	auto start = std::chrono::high_resolution_clock::now();
	
	// Open input image with leptonica library
	Pix *image = pixRead((input).c_str());
	
	boost::property_tree::ptree root;
	boost::property_tree::ptree children;
	
	root.put("height", pixGetHeight(image));
	root.put("width", pixGetWidth(image));
	
	// Initialize tesseract-ocr, without specifying tessdata path
	tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();
	if(api->Init(NULL, "dan+eng")){
		error("Could not initialize tesseract");
	}
	api->SetImage(image);
	api->Recognize(0);
	
	tesseract::ResultIterator* ri = api->GetIterator();
	
	if(ri != 0){
		do{
			boost::property_tree::ptree child;
			
			const char* seg = ri->GetUTF8Text(level);
			int x1, y1, x2, y2, height, width;
			ri->BoundingBox(level, &x1, &y1, &x2, &y2);
			height = y2 - y1;
			width = x2 - x1;
			
			if(is_debug){
				printf("seg: '%s'; BoundingBox: %d,%d,%d,%d;\n", seg, x1, y1, x2, y2);
			}
			
			child.put("top", y1);
			child.put("left", x1);
			child.put("height", height);
			child.put("width", width);
			child.put("bottom", y1 + height);
			child.put("right", x1 + width);
			child.put("html", utf8_to_latin(seg));
			child.put("conf", roundf(ri->Confidence(level) * 100) / 100);
			
			children.push_back(std::make_pair("", child));
			
			delete[] seg;
		}
		while(ri->Next(level));
		
		root.add_child("elms", children);
	}
	
	// Destroy used object and release memory
	api->End();
	pixDestroy(&image);
	
	auto elapsed = std::chrono::high_resolution_clock::now() - start;
	root.put("exec_time", ((float)std::chrono::duration_cast<std::chrono::microseconds>(elapsed).count() / 1000) / 1000);
	
	std::ostringstream oss;
	write_json(oss, root, false);
	return oss.str();
}
``` Try to uninstall 3.0x first before installing 4.00.
Don't forget running `ldconfig`. `ldconfig` solved the error..

But what about those shared objects/files?

Arent all required files compiled into the file `txtocr` ??

When the following code prints `Tesseract version: 4.00.00alpha` can I then be 100% sure that everything is running `4.00` ? 

``` 
tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();

std::cerr << "Tesseract version: " << api->Version() << std::endl;
```

I am compiling my program like this `g++ -std=c++11 txtocr.cpp -o txtocr -llept -ltesseract` 4.0.0alpha tagged zip file is from Nov 2016 (I think, please check).

If you want latest 4.0.0alphacode, please clone from master in GitHub.
There have been quite a few commits since the original tag for 4.0.0.

- excuse the brevity, sent from mobile

On 20-Mar-2017 9:05 PM, "clarkk" <notifications@github.com> wrote:

> ldconfig solved the error..
>
> But what about those shared objects/files?
>
> Arent all required files compiled into the file txtocr ??
>
> When the following code prints Tesseract version: 4.00.00alpha can I then
> be 100% shure that everything is running 4.00 ?
>
> tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();
>
> std::cerr << "Tesseract version: " << api->Version() << std::endl;
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/774#issuecomment-287797686>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oz8guS825Mrknsc_-ul--atGngkiks5rnpzQgaJpZM4MihhH>
> .
>
 Run Configure with enable debug to see the git revision of the code u r
running.

- excuse the brevity, sent from mobile

On 20-Mar-2017 11:24 PM, "ShreeDevi Kumar" <shreeshrii@gmail.com> wrote:

> 4.0.0alpha tagged zip file is from Nov 2016 (I think, please check).
>
> If you want latest 4.0.0alphacode, please clone from master in GitHub.
> There have been quite a few commits since the original tag for 4.0.0.
>
> - excuse the brevity, sent from mobile
>
> On 20-Mar-2017 9:05 PM, "clarkk" <notifications@github.com> wrote:
>
>> ldconfig solved the error..
>>
>> But what about those shared objects/files?
>>
>> Arent all required files compiled into the file txtocr ??
>>
>> When the following code prints Tesseract version: 4.00.00alpha can I
>> then be 100% shure that everything is running 4.00 ?
>>
>> tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();
>>
>> std::cerr << "Tesseract version: " << api->Version() << std::endl;
>>
>> —
>> You are receiving this because you are subscribed to this thread.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/774#issuecomment-287797686>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AE2_oz8guS825Mrknsc_-ul--atGngkiks5rnpzQgaJpZM4MihhH>
>> .
>>
>
 Where is the user forum? Where can I ask questions?

I need to build static library of tesseract so I can compile everything into one binary  After installing `3.05` I still get `3.04` when running `pkg-config --modversion tesseract`

How I installed `3.05`

```
cd /var/bin && wget http://www.leptonica.com/source/leptonica-1.74.1.tar.gz && tar -xvf leptonica-1.74.1.tar.gz
cd leptonica-1.74.1 && ./configure && make && make install

cd /var/bin && wget https://github.com/tesseract-ocr/tesseract/archive/3.05.00.tar.gz -O tesseract-3.05.00.tar.gz && tar -xvf tesseract-3.05.00.tar.gz
cd tesseract-3.05.00 && ./autogen.sh && ./configure && make && make install && ldconfig
```

When compiling my program that uses tesseract its also still using `3.04`

```
g++ -std=c++11 txtocr.cpp -o txtocr -llept -ltesseract
``` I will uninstall everything and try to clone master  Hello!

![3](https://cloud.githubusercontent.com/assets/19375839/24091638/5471aad0-0d5a-11e7-9bbe-42c1f1f2fc4d.jpg)
When we try to recognize the picture above through a new tesseract 4.0, we have the following output
![bug](https://cloud.githubusercontent.com/assets/19375839/24091647/5f7afc92-0d5a-11e7-865c-af89cf15f807.png)
Via 3.04 
 ![bug](https://cloud.githubusercontent.com/assets/19375839/24091662/7e190ea0-0d5a-11e7-86f9-f4063079d402.png)
Dots wrong recognized : 
![3](https://cloud.githubusercontent.com/assets/19375839/24091712/c7907de8-0d5a-11e7-8d12-5769db8ee55c.png)

Common input : 
![bug](https://cloud.githubusercontent.com/assets/19375839/24091744/012d05c6-0d5b-11e7-8a37-43657c4c9c28.png)

For testing
https://drive.google.com/file/d/0B0K3HIAIMTpMS3lGZXkteXo2Sjg/view?usp=sharing


 Maybe a tesseract has a minimum character size setting?   :+1: 

reference:
https://github.github.com/gfm/ The 3.05 README.md also suffers from this wrong syntax.
 Another link:
https://githubengineering.com/a-formal-spec-for-github-markdown/  LSTM training requires box files which have a TAB at end of line and spaces to demarcate words.

Box files generated by tesseract from image files do not have these. 

The synthetic box/tiff pairs generated by text2image have the spaces and tabs. I get the same message with Arabic language as shown below  the box file generated with 
training/tesstrain.sh \
--fonts_dir /home/idris/mylot \
--lang ara --linedata_only \
--noextract_font_properties --langdata_dir ./langdata \
--tessdata_dir ./tessdata \
--output_dir ~/mylottutorial \
--fontlist "mylotus Bold"


=== Starting training for language 'ara'
[Mon Nov 13 01:52:41 PST 2017] /usr/local/bin/text2image --fonts_dir=/home/idris/mylot --font=mylotus Bold --outputbase=/tmp/font_tmp.Rf99kiznKj/sample_text.txt --text=/tmp/font_tmp.Rf99kiznKj/sample_text.txt --fontconfig_tmpdir=/tmp/font_tmp.Rf99kiznKj
Stripped 1 unrenderable words
Rendered page 0 to file /tmp/font_tmp.Rf99kiznKj/sample_text.txt.tif

=== Phase I: Generating training images ===
Rendering using mylotus Bold

[Mon Nov 13 01:52:42 PST 2017] /usr/local/bin/text2image --fontconfig_tmpdir=/tmp/font_tmp.Rf99kiznKj --fonts_dir=/home/idris/mylot --strip_unrenderable_words --leading=32 --char_spacing=0.0 --exposure=0 --outputbase=/tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0 --max_pages=3 --font=mylotus Bold --text=./langdata/ara/ara.training_text
Stripped 2 unrenderable words
Rendered page 0 to file /tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0.tif
Rendered page 1 to file /tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0.tif
Stripped 10 unrenderable words
Rendered page 2 to file /tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0.tif

=== Phase UP: Generating unicharset and unichar properties files ===
[Mon Nov 13 01:52:44 PST 2017] /usr/local/bin/unicharset_extractor --output_unicharset /tmp/tmp.s7NZRqv0Qa/ara/ara.unicharset --norm_mode 2 /tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0.box
Extracting unicharset from box file /tmp/tmp.s7NZRqv0Qa/ara/ara.mylotus_Bold.exp0.box
Word started with a combiner:0x64b
Normalization failed for string ' ً'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64f
Normalization failed for string 'ُت'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًام'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64f
Normalization failed for string 'ُأ'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x650
Word started with a combiner:0x651
Normalization failed for string 'ِّر'
Word started with a combiner:0x64f
Normalization failed for string 'ُي'
Word started with a combiner:0x64f
Word started with a combiner:0x651
Normalization failed for string 'ُّل'
Word started with a combiner:0x650
Normalization failed for string 'ِحل'
Word started with a combiner:0x64f
Normalization failed for string 'ُه'
Word started with a combiner:0x64e
Word started with a combiner:0x651
Normalization failed for string 'َّط'
Word started with a combiner:0x650
Word started with a combiner:0x651
Normalization failed for string 'ِّف'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًا'
Word started with a combiner:0x64b
Normalization failed for string 'ًام'
Word started with a combiner:0x64b
Normalization failed for string 'ًى'
  I want use opencl to speed up tesseract. I define USE_OPENCL in C/C++->Preprocessor->Preprocessor Definitions(VS2015) .
and include"CL/cl.h" in openclwrapper.h.
And rebuild the libtesseract  project , and succeeded.
When I use GetUTF8Text, the  String return is NULL but return correct string when I don't use opencl.
Can you tell me ,where is the problem?
Can Opencl use in teseeract 3.05?
Thanks!




 Hi , zdenop ,
   Can you help me at there. I can't use the tesseract user forum because I don't have a Google account .I am very sorry for that.
Thanks!  I want know  in persian's tesseract what fonts are there and also what is priority  for training them?   @stweil I think you mean `fonts` instead of `languages` in the above.  The current master only builds Win32.  Are there x64 builds or build processes available for tesseract4?  I use for persian and it is ok but if in text ,there were two language  (persian and english) how can detect and convert them ? which traineddata are you ussing for persian? what accuracy rate do you get?

for multiple languages use

-l per+eng @roozgar - which is the better traineddata for persian - fas or per? The tesseract-ocr/tessdata repo on GitHub only has 'fas'.
 > The tesseract-ocr/tessdata repo on GitHub only has 'fas'.

See https://github.com/tesseract-ocr/langdata/issues/24
At one time both per and fas were there.

 Shree,

I don't see 'per' in any commit in the **tessdata** repo. Both were there in langdata. Ray has since deleted `per`.

PersianOCR is an external project using Tesseract (3.02 I think) - see https://github.com/reza1615/PersianOcr ​no 'per' is removed and changed persian traindata to 'fas'​
​and also its not capable with end or any other language​
 Maybe Arabic.traineddata also includes Persian. Ray? @amitdo no,i checked
the Arabic train data cant detect the symbols that is included in Persian and not in Arabic lstm dont merge trained files in run time?  SVSync::StartThread() is used in api/ , backporting the GRAPHICS_DISABLED fix
Backport api/ libtfiff missing dependency for win32 platform @voyageur:  @zdenop said in [this comment](https://github.com/tesseract-ocr/tesseract/issues/739#issuecomment-286849254) on #739 that [your second commit](https://github.com/tesseract-ocr/tesseract/pull/760/commits/7e0352f5276a68d7c58b750279273f25a868efaa) to this PR's staging branch isn't really needed for branch `3.05` since `configure` _should_ add the relevant linker flag automatically when Tesseract is being built with OpenCL support&thinsp;—&thinsp;at least, I _think_ that was his reasoning…   @RandomDSdevel oh you're right, this is not needed for #739. Windows builds may still need as there is a direct call to tiff library in api/ for win32.
I will update the commit message, but can drop this commit of course if not really desired for 3.05 branch @zdenop I don't ;) the (outside of opencl) TIFFSetWarningHandler call at https://github.com/tesseract-ocr/tesseract/blob/3.05/api/tesseractmain.cpp#L396 is wrapped in  "defined(_WIN32)" so probably needs the -ltiff linking  I'm trying to process the following image using tesseract 3.04
<img width="157" alt="number" src="https://cloud.githubusercontent.com/assets/115446/23871059/3ae3fb32-07ff-11e7-8d02-f1c33e7a8d10.png">

The image seems pretty clean. however, it extracts the following from this image using the `eng` lang

> .ESHBEE

**Questions**
1. Is there a way to read numbers like these from tesseract? 
2. If I have to train a separate lang for these type of numbers, can the trained lang be integrated into the `eng` lang?  I have found that the error goes away when NOT using --eval_listfile,
please try without the following

--eval_listfile
/home/stweil/src/github/tesseract-ocr/tesseract/frk/train/frk.training_files.txt

Though this means that there is no regular eval during training.


ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Mar 13, 2017 at 12:42 PM, Stefan Weil <notifications@github.com>
wrote:

> Running lstmtraining for frk language with 50000 iterations terminated
> with an assertion.
>
> $ lstmtraining -U /home/stweil/src/github/tesseract-ocr/tesseract/frk/train/frk.unicharset --script_dir ~/src/github/tesseract-ocr/langdata --net_spec '[1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c105]' --model_output /home/stweil/src/github/tesseract-ocr/tesseract/frk/output/base --train_listfile /home/stweil/src/github/tesseract-ocr/tesseract/frk/train/frk.training_files.txt --eval_listfile /home/stweil/src/github/tesseract-ocr/tesseract/frk/train/frk.training_files.txt --max_iterations 50000
> ...
> At iteration 15778/49900/49900, Mean rms=0.37%, delta=0.112%, char train=0.381%, word train=1.506%, skip ratio=0%,  wrote checkpoint.
>
> At iteration 15788/50000/50000, Mean rms=0.363%, delta=0.104%, char train=0.346%, word train=1.387%, skip ratio=0%,  wrote checkpoint.
>
> Finished! Error rate = 0.26
> num_docs > 0:Error:Assert failed:in file ../../../../ccstruct/imagedata.cpp, line 648
>
> I used latest Tesseract sources, a slightly modified font list and a
> longer training text for frk training.
> A previous run with 10000 iterations and nearly the same conditions did
> not raise the assertion:
>
> ...
> 2 Percent improvement time=807, best error was 3.911 @ 8211
> At iteration 9018/10000/10000, Mean rms=0.835%, delta=0.465%, char train=1.729%, word train=6.095%, skip ratio=0%,  New best char error = 1.729Deserialize failed wrote best model:/home/stweil/src/github/tesseract-ocr/tesseract/tutorial/frkoutput/base1.729_9018.lstm wrote checkpoint.
>
> Finished! Error rate = 1.729
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/757>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o-S-16Nb7AFsGsCO3w_L80p8t9Fuks5rlOxhgaJpZM4Ma6ed>
> .
>
 A link to the relevant line in the source code:  
https://github.com/tesseract-ocr/tesseract/blob/134a2537584b5bd6000841dbcb0a9489cd2548f5/ccstruct/imagedata.cpp#L648 Maybe it's a memory problem. How much RAM do you have in that machine? About fonts, I believe that for LSTM training Ray used much more fonts for each language than with the old engine.  So little RAM? A University server, I guess...  :-)  On Mon, Mar 13, 2017 at 3:42 PM, Amit D. <notifications@github.com> wrote:

> I used 12 fonts. The training result was pretty good for the old engine
> and unusable for LSTM.
>
> 12 fonts is not enough for LSTM. Use as much fonts as you can find.
>

 ​@stweil You can increase the number of box/tiff pairs by adding
--exposures "-1 0 1" or even --exposures "-2 -1 0 1 2" ​with the same fonts
to get images which are lighter and darker than the original font.

```
training/tesstrain.sh --fonts_dir /usr/share/fonts --lang frk  \
  --linedata_only --noextract_font_properties --exposures "-1 0 1" \
   --langdata_dir ../langdata --tessdata_dir ./tessdata \
     --output_dir ~/tesstutorial/frk
```

Also, please check whether the fonts you are using have support for the
paragraph marker etc, otherwise they might get dropped as unrenderable.

@theraysmith I think it will be useful if training using non-synthetic
box/tiff pairs is also supported for LSTM.

Thanks.
 @stweil I had  generated box files for different Fraktur font alphabet images using makebox. However these need to be reviewed for correctness and tabs need to be added at end of lines.

I do not recognize the letters so can't update them. jtessboxeditor could be used for adding tabs.

https://github.com/paalberti/tesseract-dan-fraktur/files/721936/fraktur-png-box-to-be-corrected.zip I know. I do not have those fonts,but found these images on the net on some
font sites. If you or Ray have the resources to get these fonts, you can
use them to create appropriate trainingdata.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Mar 14, 2017 at 11:16 AM, Stefan Weil <notifications@github.com>
wrote:

> @Shreeshrii <https://github.com/Shreeshrii>, that's a nice collection of
> Fraktur fonts, but several of the image not even include all normal ASCII
> characters. All images are missing the long s character (ſ) which is very
> important for all Fraktur texts. Also missing are all forms of ligatures
> (combinations of certain characters, like for example ffi, which need a
> special rendering).
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/757#issuecomment-286328117>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o_my9wQq3XxnJtuzD2QWSpwu0Pt4ks5rlimqgaJpZM4Ma6ed>
> .
>
 These are the freely available Fraktur fonts that I found:

```
FRAKTUR_FONTS=(
  "CaslonishFraxx Medium" \
  "Cloister Black, Semi-Light" \
  "Proclamate Light, Semi-Light" \
  "UnifrakturCook" \
  "UnifrakturMaguntia" \
  "UnifrakturMaguntia16" \
  "UnifrakturMaguntia17" \
  "UnifrakturMaguntia18" \
  "UnifrakturMaguntia19" \
  "UnifrakturMaguntia20" \
  "UnifrakturMaguntia21" \
    "Walbaum-Fraktur" \
)
```

sample files via text2image that I had posted in the issue

https://github.com/paalberti/tesseract-dan-fraktur/files/721956/frk.box-tif-pairs.zip @stweil The page about fonts will be very useful. I have added info about Devanagari fonts and will update more later.

Please see pages 2-9 in http://www.sanskritweb.net/fontdocs/genzmer.pdf
which show samples of many fraktur fonts - again it does not have ligatures and all letters - but would something like that be helpful for training/testing German Fraktur.  You can also check the following as well as other font related documents on website by  Ulrich Stiehl.
http://www.sanskritweb.net/fontdocs/gutenberg2.pdf
http://www.sanskritweb.net/fontdocs/gutenberg.pdf
http://www.sanskritweb.net/fontdocs/walbaum.pdf `INT_PARAM_FLAG(max_image_MB, 6000, "Max memory to use for images.")`

I don't know if it is actually related to the reported issue, but you can increase the default value from the command line. @amitdo It is probably memory related, since  the assertion does not occur when I omit --eval_listfile.

And, https://github.com/tesseract-ocr/tesseract/blob/master/training/lstmeval.cpp uses a smaller memory size for images.

`INT_PARAM_FLAG(max_image_MB, 2000, "Max memory to use for images.");`

How would you change it from commandline?
 The same way you do it with text2image.

You should take into account the RAM in your PC. @Shreeshrii  I changed the max_image_MB to 8000  /training/lstmeval.cpp, and complie it . 
then, run
`lstmtraining --debug_interval -1 --model_output /data/docker-tess/output/realR5 --continue_from /data/docker-tess/output/realR410.378_33695.lstm  --train_listfile /data/traindata/trainAll.train_filelist.txt --eval_listfile /data/correctedBox/real.eval_filelist.txt `

after 100 Iterations, it CoreDump 
```
Mean rms=0.148%, delta=2.857%, train=12.187%(29%), skip ratio=3%
lstmtraining: ../ccutil/genericvector.h:696: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
Aborted (core dumped)

``` @Shreeshrii  I am trying to fine-tune tesseract for Arabic and Persian. I have used 4000 text lines and about 40 fonts. and I set the max-error-rate=0.001. the error rate of 0.002 has been recorded. but after finishing of the training process I got error-rate=0! Is it reasonable? Dear Mr.Smith;
thanks for answering my question.
No, it's not overfitted. I tested it and the results were acceptable.

On Fri, Aug 4, 2017 at 4:41 AM, theraysmith <notifications@github.com>
wrote:

> It would be expected to get such a low error rate on your training set, but
> has it overfitted? How does it do on different test data?
>
> On Tue, Aug 1, 2017 at 6:13 AM, hanikh <notifications@github.com> wrote:
>
> > @Shreeshrii <https://github.com/shreeshrii> I am trying to fine-tune
> > tesseract for Arabic and Persian. I have used 4000 text lines and about
> 40
> > fonts. and I set the max-error-rate=0.001. the error rate of 0.002 has
> been
> > recorded. but after finishing of the training process I got error-rate=0!
> > Is it reasonable?
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/757#
> issuecomment-319365858>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AL056TlrhrROzIm6VOXVoiHjygnInOUGks5sTyRvgaJpZM4Ma6ed>
> > .
> >
>
>
>
> --
> Ray.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/757#issuecomment-320122468>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAaUyiObmY6Hi8q10PMUhoGYA_Wolks5sUmGugaJpZM4Ma6ed>
> .
>
  > Or we can ask Ray.

@theraysmith, the current code includes a hard coded value of 70 dpi as the minimum resolution and sets any resolution which is smaller to that value. This is also done for images which don't include a resolution information ("0 dpi"). Maybe it would be better to assume 300 dpi for that special case. Why does the resolution matter at all? IMO, assuming Tesseract really needs to know the resolution, when the dpi is absent or seems suspicious, the program should not try to guess the dpi and ocr the page. It should just print an error message. Maybe. It is not clear why the dpi information is needed at all. I can read text of any dpi (just have to adapt the reading distance or get some glasses) without knowing the actual dpi value, and ideally OCR software can do that, too.

If the dpi value is important, we need an option to set it for images without (or with wrong) resolution metadata. https://github.com/tesseract-ocr/tesseract/search?q=resolution Many thanks for this analysis and your efforts. +1 this is biting me as well. I have a small demo which was working a year ago, but now it is giving:

```r
> text <- ocr("http://jeroen.github.io/files/inlove.png")
Warning. Invalid resolution 0 dpi. Using 70 instead.
Too few characters. Skipping this page
```

I guess the problem is that the default resolution is too low?  https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/OJI3bsi_JMY/NHlt8uEfEAAJ

>I'm new to tesseract and wondered why the lstm dataset creation for the training process has to write the file again and again in TrainLineRecognizer. I've seen 200MB/s IO on the disk while creating the training data set. As far I can see for the training case it would be sufficient to just load it once and write it at the end. The same applies to the box and tif file - but these are only read and not written...



  https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/t7GdSDRrGpI/gMzJEcfXEAAJ

https://groups.google.com/group/tesseract-ocr/attach/10d7c711c9cc80/mrz.traineddata?part=0.1&authuser=0

> Just created a tesseract 3.04 trained data (see attached). 
I call it "MRZ" because it has the OCR-B as the only font and trained with characters A-Z, 0-9 and the lesser-than symbol (<). Seems to be fast and accurate in my projects. Is there a list where community contributions for traineddata are listed?

This should be tested and added. Is that what you want?
https://github.com/tesseract-ocr/tesseract/wiki/AddOns#community-training-projects Thanks. Added to community Training Projects.  If you really want to piss @theraysmith off, then fine... I understand Ray's messages on this topic differently.

Zdenko will decide...

Peace :-) @egorpugin 
Is there no good alternative to AppVeyor?  Blacklist and whitelist no longer work in 4.00alpha. They used to work in 3.04.

https://groups.google.com/forum/#!topic/tesseract-ocr/cpcJHTE2xMo Same problem for me with 4.00alpha, I tried to set `tessedit_char_whitelist` by using:
- cli with option `-c tessedit_char_whitelist=abcdefghijklmnopqrstuvwxyz`
- cli with config file
- tesserocr python module

But I keep getting non letter results

I can provide Dockerfile + python script + images if needed Same problem for me. Still getting symbols and alphabets despite setting `tessedit_char_whitelist="0123456789"`. I encountered the same issue today when using --oem 1,2,3. It works fine for --oem 0 (Original Tesseract).  I am encountering the same issue, is there a solution for this issue yet?.
 >I am encountering the same issue, is there a solution for this issue yet?.

No. I am facing the same issue. Is it really a bug or is it just not supported for LSTM?  It's currently not supported for LSTM.

People, please do not add another "I have the same issue" comment. Are there plans to support whitelisting on LSTM in the future? I also have this problem when using Tesseract 4 from C++

    tess->SetVariable("tessedit_char_whitelist", "01234567890abcdefg");

has no effect on the output. The same with blacklist.

Tesseract returns not only ascii + language-specific characters but also some strange other characters from UTF-8. 

Is there a way to get a full list of all possible characters, specific for a language or not? Basing on such list one could make a workaround to map such wrong characters to best fitting ones that are expected (like EM DASH to plain ASCII dash etc.) and remove those without any sensible fit. It would be useful for me in current circumstances and maybe it could be useful for others in need of whitelisting.
 I would like to exclude everything except letters and digits from the result. I started from eng.traineddata and trained my font from graphical images (@shreeshrii: thanks!!)) . Is there a way to get rid of all the other symbols, especially !"=)() ... ?

I am using --oem 1.

Thank you very much,
Ernst  Increase portability by insulating `autogen.sh` from platform variance.  

<hr />

Specifically, test for the existence of either `libtoolize` or `glibtoolize` and caching its location into a script variable prior to running the utility in order to prevent either utility's invocation from spawning error messages of the form './autogen.sh: line $LINE: $COMMAND: command not found' (with the $LINE and $COMMAND pseudo-variables replaced with content relevant to what line the command that spawned this error message was on within `autogen.sh` and what command's invocation was attempted at that point, of course.)  In particular, this takes into account macOS's wonky `libtool` semantics, which involve the following idiosyncrasies:  

* The version of `libtool` that Apple bundles within both Xcode and its separate associated 'Command-Line Developer Tools' package comes _without_ a copy of `libtoolize`.  
* macOS package managers like Homebrew and MacPorts typically install the GNU versions of `libtool` and `libtoolize` as `glibtool` and `glibtoolize`, respectively, when needed by another package as a dependency or otherwise requested by an end-user.  

The pre-existing code which was _supposed_ to handle this case was _not_ resilient with respect to errors finding either the system copy or the GNU variant of `libtoolize`, as it ran _both_ `libtoolize` and `glibtoolize`, in _that_ order, _without_ checking for the existence of _either_ utility!  (From the `man` page of the copy of `bash` included with macOS 'El Capitan' v10.11.6, which is reported to be `GNU bash, version 3.2.57(1)-release (x86_64-apple-darwin15)` by `bash --version`:  

> ```
> …
>
> SHELL GRAMMAR
>
> …
>
>    Lists
>           A list is a sequence of one or more pipelines separated by one of the operators ;, &, &&, or ||,  and optionally terminated by one of ;, &, or <newline>.
>
>           Of  these  list  operators,  &&  and  || have equal precedence, followed by ; and &, which have equal precedence.
>
>           A sequence of one or more newlines may appear in a list instead of a semicolon to delimit commands.
>
>           If a command is terminated by the control operator &, the shell executes the  command  in  the  background in a subshell.  The shell does not wait for the command to finish, and the return status is 0.
>           Commands separated by a ; are executed sequentially; the shell waits for each command to terminate in turn.  The return status is the exit status of the last command executed.
>
>           The  control  operators  &&  and || denote AND lists and OR lists, respectively.  An AND list has the form
>
>                  command1 && command2
>
>           command2 is executed if, and only if, command1 returns an exit status of zero.
>
>           An OR list has the form
>
>                  command1 || command2
>
>           command2 is executed if and only if command1 returns a non-zero exit status.  The  return  status  of AND and OR lists is the exit status of the last command executed in the list.
>
> …
> ```

—&thinsp;_note_, however, that this text only implies that execution of the _second_ command in the `||` list can be short-circuited if the execution of the first command fails; that _first_ command is _always_ executed!)  

This root cause of this issue was initially clarified to me by the second half of [this comment](https://github.com/Homebrew/homebrew-core/issues/10380#issuecomment-283186646) on Homebrew/homebrew-core#10380 because it appeared as a red herring of a side effect during diagnosis of [that same issue](https://github.com/Homebrew/homebrew-core/issues/10380).  ~~Per [this further comment](https://github.com/Homebrew/homebrew-core/issues/10380#issuecomment-283505099) on that issue, further corrections to `autogen.sh` may remain desired after the merger of this pull request into `master`.~~  (Never mind, that's #739 and has to do with `api/Makefile.am`.)  This pull request should also be backported to at _least_ branch `3.05`.   By the way, did I put the `libtoolize`/`glibtoolize` existence check in the right place?  I can move it elsewhere in `autogen.sh` if you guys want…   AppVeyor fails a lot of times for no good reason. @stweil:  
> By the way: it's `autogen.sh`, not `autopen.sh`.

Gah, blasted auto-correct struck _again!_  ~~I'd better go ahead and fix that while I'm resolving the rest of your review comments, then!~~  (Oh, wait, I don't think there's nothing to fix inside my commits, as I'm _pretty_ sure auto-correct only rears its ugly head when I'm making comments on this PR from within Safari.  Everything I did from within `nano` should be fine…)   @stweil:  Would you like me to squash my commits together?  In addition, have any changes requiring me to rebase mine on top of them been pushed to `master` since I started working on this PR?  (I should probably look myself…_goes to check._)  

<hr />

Also @stweil w. r. t. your originally reply to [this comment](https://github.com/tesseract-ocr/tesseract/pull/750#issuecomment-284881849) of mine:  

> That's a rather lengthy commit messages, and it is not so easy for me to get the essentials from it. …

I thought the commit message did a pretty good job of explaining things myself, but I'll change it if you feel like that isn't the case.  I'll either go back and edit the original commit message or change said message as part of squashing all my commits together if you end up wanting me to do that.  

> …The old code works, but throws a nasty and confusing warning on systems which provice glibtoolize instead of libtoolize. This is fixed by your pull request.

That was the idea.  😉 @stweil:  OK, works for me!   @stweil:  Rebased against `b6eb8bebb16cc95da44d465713bb868474c572c1`.   @zdenop:  How would I go about backporting the changes I submitted as part of this PR to the `3.05` branch?  (To quote the reason I'm asking this from this PR's OP…:  

> …
>
> This root cause of this issue was initially clarified to me by the second half of this comment on Homebrew/homebrew-core#10380 because it appeared as a red herring of a side effect during diagnosis of [that same issue](https://github.com/Homebrew/homebrew-core/issues/10380).  …This pull request should also be backported to at _least_ branch `3.05`.

…, I basically need that to be done by either myself or whoever's in charge of doing stuff like that in order to resolve the downstream issue in question.)   @zdenop:  :man_facepalming:  No, but I guess I should have!  Lemme check… @zdenop:  Never mind, none of the commits from this PR are missing from branch `3.05`!  Guess I should have asked if you had backported them from `master` already or not, as it wasn't entirely obvious whether or not you intended to do so from within the context of this thread.   @zdenop:  That's perfectly all right if you've been somewhat busy lately, and it wasn't any trouble for me to check back on things after the fact at _all_.  Let's hope you get some more free development time soon, though!    my computer does not install openmp, i configure with --disable-openmp, but i still could not compile with error:
./.libs/libtesseract.so: undefined reference to `omp_get_thread_num'
./.libs/libtesseract.so: undefined reference to `GOMP_sections_end_nowait'
./.libs/libtesseract.so: undefined reference to `omp_get_num_threads'
./.libs/libtesseract.so: undefined reference to `GOMP_parallel'
./.libs/libtesseract.so: undefined reference to `GOMP_parallel_sections'
./.libs/libtesseract.so: undefined reference to `GOMP_sections_next'
so, if have some bugs about the configure! I use 4.0 version, and i set the _OPENMP undef manually, then it could compile. @yhl41001, do you still have this issue?

If you do, please response to zdenop. @zdenop, please close this issue.  I am getting error

./configure --enable-debug
checking for g++... no
checking for clang++... no
checking for C++ compiler default output file name...
configure: error: in `/home/azureuser/ocr/tesseract':
configure: error: C++ compiler cannot create executables
See `config.log' for more details.  see #11 Also. it seems that this PR only changes parts of the old engine that Ray wants to drop.

 @theraysmith commented in #518 

>Please provide examples of where you get better results with the old engine.
Right now I'm trying to work on getting rid of redundant code, rather than spending time fighting needless changes that generate a lot of work.

>Instead of modifying the old engine parts, concentrate on convincing me why it should stay first

To me, the message here from Ray is clear:
<<That's NOT an actual quote of Ray>>
"I don't want you* to do any change to the old engine. Doing so just interfere with my work on the new engine".

That's the way I understand it.

\* 'you' - not just you, any developer.

>see #11 

https://github.com/tesseract-ocr/tesseract/pull/11#pullrequestreview-12160316 Here is the way I believe things are working in the Google side.

Every commit that we push to this repo, at some time in the future (few weeks/months) will be reviewed by Ray or someone else from Google. If they don't like something they will change it. Then it will be merged with the internal Google branch, which might diverge significantly from the public repo's master branch. I think they do it infrequently, which means that when they try to merge with us they have quite a lot of work to do and it is not so simple as you might think.

@theraysmith, @jbreiden
You are invited to correct me if I'm wrong here. See also:
https://github.com/tesseract-ocr/tesseract/pull/752#issuecomment-294258915 I rebased the code to fix some merge conflicts.

Ray, I noticed your recent changes which introduced `TFile` in those files. IMO removing memry.{cpp,h} would also be a good step to clean the code. I‌ could do that in two steps to simplify reviews if you agree:

1. switch to using malloc / calloc and free in a first step (like it is done in this PR)
2. replace all those allocations by C++ code (new / new[] and delete / delete[]) >replace all those allocations by C++ code (new / new[] and delete / delete[])

Isn't this remark from Ray also relevant here?
https://github.com/tesseract-ocr/tesseract/pull/11#pullrequestreview-12160316 It isn't, as I promised to use C++ code in step 2 (see above). >How about replacing the underlying pointer variables with std::array, thus hiding all calls to allocate and delete the memory?

If you know what he meant, consider implementing it.  Teseract 3.04 - Was trying to command line OCR a 9206 multi-page tiff document on Mac OS 10.11, but it stops at page 3000.  Turns out opencl/openclwrapper.cpp line 93 (static const l_int32 MAX_PAGES_IN_TIFF_FILE = 3000;) specifically limits OCRing Tiffs to 3000 pages.  This const appears to only control the bounds of a for loop, so maybe this variable should be more dynamic and be based on the number of pages the input Tiff has instead?  just a thought. Sorry about that.  

Removed the 3000 page restriction on multipage tiff files.  There are now no limits, and this is pushed to the leptonica master: https://github.com/danbloomberg/leptonica Only relevant to 3.05. yeah, I might have a make my own custom build of 3.04.01 with the change to openclwrapper.cpp. @jbreiden I would think it's faster with it on, but haven't tested it.  Kinda new to tess - is there a way to easily turn it off to see? oh...looks like build flags    Hello,

Tesseract-3.04.01 (and having briefly glanced at the code, likely so does 3.05.00) does not explicitly link libtesseract against libtiff even when the former references symbols from the latter. This results in the following error when one attempts to build tesseract using a linker that dislikes implicit linking, e.g. gold:

/bin/sh ../libtool  --tag=CXX   --mode=link x86_64-pc-linux-gnu-g++  -O2 -pipe -march=native -std=c++11 -lOpenCL -Wl,-O1 -Wl,--as-needed -Wl,--as-needed -Wl,-O1 -Wl,--hash-style=gnu -Wl,--sort-common -O2 -pipe -march=native -o tesseract tesseract-tesseractmain.o libtesseract.la   -lrt -llept -lpthread 
libtool: link: x86_64-pc-linux-gnu-g++ -O2 -pipe -march=native -std=c++11 -Wl,-O1 -Wl,-O1 -Wl,--hash-style=gnu -Wl,--sort-common -O2 -pipe -march=native -o .libs/tesseract tesseract-tesseractmain.o  -lOpenCL -Wl,--as-needed ./.libs/libtesseract.so -lrt -llept -lpthread
./.libs/libtesseract.so: error: undefined reference to 'TIFFFdOpen'
./.libs/libtesseract.so: error: undefined reference to 'TIFFGetFieldDefaulted'
./.libs/libtesseract.so: error: undefined reference to 'TIFFGetField'
./.libs/libtesseract.so: error: undefined reference to 'TIFFScanlineSize'
./.libs/libtesseract.so: error: undefined reference to 'TIFFReadRGBAImageOriented'
./.libs/libtesseract.so: error: undefined reference to 'TIFFReadScanline'
./.libs/libtesseract.so: error: undefined reference to 'TIFFClientOpen'
./.libs/libtesseract.so: error: undefined reference to 'TIFFReadDirectory'
./.libs/libtesseract.so: error: undefined reference to 'TIFFCleanup'
collect2: error: ld returned 1 exit status
make[2]: *** [Makefile:591: tesseract] Error 1
make[2]: Leaving directory '/tmp/tesseract-3.04.01/api'
make[1]: *** [Makefile:480: all-recursive] Error 1
make[1]: Leaving directory '/tmp/tesseract-3.04.01'
make: *** [Makefile:389: all] Error 2

Manually adding -ltiff to the list of libraries in api/Makefile allows tesseract to build successfully, then again it is not a proper solution because e.g. the pkg-config file it installs still doesn't list that library.
 Can you be more specific on how to manually add -ltiff to api/Makefile?  I'm running MacOS Sierra 10.12.3 and getting an error about linking the ltiff when compiling the 4.0 alpha version.

libtool: link: g++ -g -O2 -std=c++11 -o .libs/tesseract tesseract-tesseractmain.o -Wl,-bind_at_load  -L/usr/local/Cellar/icu4c/56.1/lib ./.libs/libtesseract.dylib -L/usr/local/Cellar/leptonica/1.74.1/lib -llept -ltiff
ld: library not found for -ltiff
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[2]: *** [tesseract] Error 1
make[1]: *** [all-recursive] Error 1
make: *** [all] Error 2 You may need to install libtiff. try the following (or equivalent command
for your os) before building tesseract

sudo apt-get install libtiff5-dev


ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Feb 28, 2017 at 11:19 AM, idiosyncraticee <notifications@github.com>
wrote:

> Can you be more specific on how to manually add -ltiff to api/Makefile?
> I'm running MacOS Sierra 10.12.3 and getting an error about linking the
> ltiff when compiling the 4.0 alpha version.
>
> libtool: link: g++ -g -O2 -std=c++11 -o .libs/tesseract
> tesseract-tesseractmain.o -Wl,-bind_at_load -L/usr/local/Cellar/icu4c/56.1/lib
> ./.libs/libtesseract.dylib -L/usr/local/Cellar/leptonica/1.74.1/lib
> -llept -ltiff
> ld: library not found for -ltiff
> clang: error: linker command failed with exit code 1 (use -v to see
> invocation)
> make[2]: *** [tesseract] Error 1
> make[1]: *** [all-recursive] Error 1
> make: *** [all] Error 2
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/739#issuecomment-282948903>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o2DBBGFvNuj0aVuQ62S8d6A51beiks5rg7VtgaJpZM4MNnC7>
> .
>
 Thank you so much Shreeshrii!  That tip got me pointed in the right direction.  For anybody else that stumbles up this here is the config command that worked.  The second library path contains the libtiff libraries.

./configure CC=gcc CXX=g++ CPPFLAGS=-I/usr/local/Cellar/icu4c/56.1/include LDFLAGS="-L/usr/local/Cellar/icu4c/56.1/lib -L/usr/local/lib" @idiosyncraticee  Glad you have solved your problem but for the record, that was completely unrelated to the issue at hand. Indeed, the command-line snippet you have posted suggests that libtiff underlinking has been fixed in the 4.x branch - one can clearly see -ltiff there. Which may make fixing this in the 3.x branch a simple matter of backporting a patch. >Tesseract does not reference any libtiff symbols

You might want to read [opencl/openclwrapper.cpp](https://github.com/tesseract-ocr/tesseract/blob/59ba80bb3a5b/opencl/openclwrapper.h) ... https://github.com/tesseract-ocr/tesseract/commit/9ec0c4fa9c983

This one was not backported to 3.05. Per [an issue](https://github.com/Homebrew/homebrew-core/issues/10380) I reported downstream to maintainers of [the macOS Homebrew package manager](https://github.com/Homebrew/brew)'s [Core tap](https://github.com/Homebrew/homebrew-core) (and as specifically pointed out by [this comment](https://github.com/Homebrew/homebrew-core/issues/10380#issuecomment-283186646) on it,) this issue also occurs under OS X/macOS 'El Capitan' v10.11.6.  As Homebrew's maintainers _vastly_ prefer using only patches available upstream, can the priority of backporting this issue's resolution from `master` be bumped up just a _tad_, please?   > 9ec0c4f

> This one was not backported to 3.05.

>>  All that code is currently unused but you are correct, it is right there.

@egorpugin @zdenop  Should it be added to the 3.05 branch for the timebeing i.e. till opencl is looked at.  @jbreiden
>I stand corrected. All that code is currently unused but you are correct, it is right there.

Not exactly...
https://github.com/tesseract-ocr/tesseract/blob/40dc28026b61/api/baseapi.cpp#L1038

```
#ifdef USE_OPENCL
    if ( od.selectedDeviceIsOpenCL() ) {
      pix = (data) ?
          od.pixReadMemTiffCl(data, size, page) :
          od.pixReadTiffCl(filename, page);
    } else {
```

This issue is about 3.05. Should we remove the calls to these two functions in 3.05 as you have done in 4.00? Looks like @zdenop is busy. Is he the only one who can push these changes and tag patch releases? @mkszuba, @idiosyncraticee, @Shreeshrii, @jbreiden, @amitdo, @egorpugin, and/or @zdenop:  If you don't mind my trying my hand at resolving this issue, what's the local procedure for submitting backport PRs, at least with respect to the Git/GitHub workflow?  Do I just have to mention the commit from which the new one backports changes, or will I have to do something more complicated (like, say, use `git cherry-pick` or something…?)   @mkszuba, @idiosyncraticee, @Shreeshrii, @jbreiden, @amitdo, @egorpugin, and/or @zdenop:  
> @mkszuba, @idiosyncraticee, @Shreeshrii, @jbreiden, @amitdo, @egorpugin, and/or @zdenop:  If you don't mind my trying my hand at resolving this issue, what's the local procedure for submitting backport PRs, at least with respect to the Git/GitHub workflow?  Do I just have to mention the commit from which the new one backports changes, or will I have to do something more complicated (like, say, use `git cherry-pick` or something…?)  

…or would one of you guys rather handle this yourselves since you're more familiar with the codebase than I am?  Like I hinted at [earlier](https://github.com/tesseract-ocr/tesseract/issues/739#issuecomment-283486022) in this thread, I'm just bumbling around trying to fix an [issue](https://github.com/Homebrew/homebrew-core/issues/10380) downstream in [Homebrew](https://github.com/Homebrew/brew)'s [Core tap](https://github.com/Homebrew/homebrew-core) that I referenced back then.   @stweil:  I already got the `libtoolize` issue fixed here upstream in #750, but that has turned out to be _completely_ orthogonal to this one and is also just coincidentally waiting for said fix to be backported (from `master`, in its case.)  As for OpenCL, that's _actually_ what I've been wanting to get working _all along!_  I believe my rationale for efforts in this space agrees, at least at some level, with the sentiment you expressed earlier:  

> Depending on the graphic card, it [(OpenCL)] can be a great gain. That is relevant for some OCR projects which would take years on a single CPU.

As such, I'll be ready to propagate the backport of [`9ec0c4f`](https://github.com/tesseract-ocr/tesseract/commit/9ec0c4fa9c983) from 4.0.x to 3.0.5 postulated [earlier](https://github.com/tesseract-ocr/tesseract/issues/739#issuecomment-283117301) as the only change needed to resolve this issue here upstream to Homebrew as a downstream mirror of an official upstream patch if a new version of Tesseract is not tagged.  If a new version of Tesseract _is_ tagged, then I would be perfectly happy with propagating _that_ downstream to Homebrew instead of the patches containing the resolutions for this issue and, simultaneously but, again, orthogonally, #750.  Either way, all I currently wish to do is get Tesseract to build with `--enable-opencl` set by Homebrew (via the `--with-opencl` option to its build formula for Tesseract) _independent_ of any further reworking of Tesseract's OpenCL support, such as that suggested by [_this_ comment](https://github.com/tesseract-ocr/tesseract/issues/739#issuecomment-283608563), that is undertaken in the future.  The intermediate resolution of #750 was, for me, just a nice little side bonus in the meantime.   @zdenop Turns out my glance at the code was not accurate and the problem has indeed been fixed in 3.05.00. My bad, sorry, @mkszuba:  Did the fix involve linking Tesseract with a copy of Leptonica linked with libtiff?   OK, so I communicated with @mkszuba via private e-mail to see if he would be willing to answer my previous comment, but he's looked at my downstream issue, and he has the impression that it's different enough from his that I should probably open a new one here upstream, so I think I'm going to do that if troubleshooting Homebrew/homebrew-core#10380 by trying to build Tesseract under Homebrew fails again (I suspect it will if the problem I'm having is distinct from the one addressed by this issue's preemptive resolution, but maybe I'll get lucky…)   Aaaaannnd…the build failed again, so the issue is as reproducible on my machine under Homebrew as I thought.  I'd better fork my issue off into a new one and stop derailing this one, then, because I'm starting to believe @mkszuba that it's not the same…   Per the GitHub issue mention notification above, I've now opened #786 to pursue Homebrew/homebrew-core#10380 further here upstream.    Hi,
Sorry for asking here.
I want to get the bounding boxes of the paragraphs and the paragraph breaks in the scanned image using tesseract.I went through methods in ResultIterator class but was not able to find the required one.
It would be great if anyone could help me on this.
Thank You.  @theraysmith  

Please see detailed report at https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/LUHy-niac6U/7oZgqIWLCwAJ

## Copied message:


I have been trying to train Tesseract 4.0 with my own data in order to extract text as a mix of natural language words and domain-specific (non-natural language) words (acronyms, identifiers, abbreviations). The Tesseract standard model has troubles in recognizing domain-specific words where “visual” words from source are either dropped or recognized with missing parts in them. So, I decided to train my own model.

I went through tutorials, set up a number of experiments, but so far with no real success. While I could fix the entirely dropped words problem by lowering the hard coded confidence threshold, and a partial success in recognizing domain-specific words, the accuracy on natural language words went down.

Two observations I have made so far by following experiments:

In Experiment 1 I use the available data (as it is) for training (~1 M tokens, and ~150 fonts). After that I generated an evaluation data set for another ~200 k tokens and ~15 most relevant fonts. Then, I trained the model by replacing the top layer from the existing Tesseract traineddata as described at https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Replace-Top-Layer The training converged a couple of days later and I evaluated the model on a held out dataset with gold standard (tiff – plain txt). The accuracy I received was lower than by using the standard Tesseract model. I noticed that the model is able to recognize some (not all) domain-specific words, however the performance on the natural language words went down (where the standard model worked fine). So, I analyzed the errors and designed another experiment in which I addressed the observed errors, which were, in my opinion, caused by data skewness = confusions between characters in rare and complex contexts.
In Experiment 2 I used the entire data set I have (~120 M tokens) and extracted word and char bigram statistics. Then I took all words with frequencies over a certain threshold as part of the final training data set. In addition, I boosted word statistics for words containing low-frequency char bi-grams (which made me troubles in the experiment before) and appended them into the final training data set. In the end, it resulted in a ~600 k unique words training data set. This was then rendered with ~ 150 fonts into tiffs, the evaluation data set remained a natural language text of ~200 k tokens in ~15 most relevant fonts. It turned out that training converges too slow – it has been running for over a week now with the best model of a ~ 0.17% error rate . Evaluations of pairs of different subsequent model snapshots on the held out dataset showed no general improvement over each other, rather random fluctuations between more accurate natural language words vs. domain-specific and vice versa. More interesting, models with lower char error rate (< 0.5%) perform worse (especially on natural language words) than models with higher char error rate (~ 0.5%). I also noticed that the model captures “language modeling features” which makes the recognition of misspelled words, “non-natural language” unique identifiers and acronyms difficult. Moreover, unique identifiers, rare words etc. in text are a big problem, however can be already recognized in chunks, but not as a whole word. More specifically, trouble cases are “like-this”, “like/this” or “this-or-like-this”.


At this point I am doubting the way I am training Tesseract is correct. So I would like to ask the community the following questions:
Should I use a natural language text or a dictionary of words for training and evaluation data set?
How important is the effect of token redundancy? (Are the errors in recognition of natural language words caused by the only single instances of those words in the training data?)
How to get Tesseract to recognize freely generated tokens not available in the training dataset? 

Thanks,
Alex

 I have had similar results, though with smaller training sets, both with Devanagari and san_latn (Sanskrit in Latin Script). Update:
After preparing new training and evaluation data, I trained a new model once again. Now, the data comprises 4,6M tokens of about 600k words (with a controlled, "shape-similar" to real word distribution) for 150 fonts. Then, I used ~ 80 % of data for training and 20 % as "held out" eval data.
After about 6 weeks (:)) of training the model converged to 0.01. Then I took a single page of the training TIFF file and ran Tesseract on that page. 

Despite a high quality level for "alpha-numerical" words, **ALL** words which contain "-" are wrong. I thought that the word I was looking at is the one of those which cause 0.01 char error rate, I dug deeper into the log file. I see the word as well as the entire line were perfectly recognized during training. Moreover, this word exists at least 5 times in the training text, and thus at least ~750 times in all fonts. 

So, I am a bit confused that the words which were perfect during training are wrong when evaluated separately. And, it is the case for all words containing "-". 

Below I provide an example:
![line](https://cloud.githubusercontent.com/assets/5794813/25696614/1fdbc202-30b8-11e7-923f-bc97fd8f1de3.png)

TSV for the line above:
5       1       1       1       2       1       113     188     467     50      51      Fernsehtechnologien
5       1       1       1       2       2       597     191     407     48      51      Tontinengeschäfte
5       1       1       1       2       3       1022    193     350     39      52      Konzernsteuern
5       1       1       1       2       4       1391    194     343     49      51      Kartografierung
5       1       1       1       2       5       1748    196     447     49      0       Avantgarde-ösung,  <------- L is dropped
5       1       1       1       2       6       2216    191     467     56      52      Ölversorgungsrouten
5       1       1       1       2       7       2700    201     240     38      40      verschwört
5       1       1       1       2       8       2958    201     429     49      54      Dialoginstrumenten

While training this line has been used and :
Iteration 3826338: ALIGNED TRUTH : Fernsehtechnologien Tontinengeschäfte Konzernsteuern Kartografierung Avantgarde-Lösung, Ölversorgungsrouten verschwört Dialoginstrumenten
Iteration 3826338: BEST OCR TEXT : Fernsehtechnologien Tontinengeschäfte Konzernsteuern Kartografierung Avantgarde-Lösung, Ölversorgungsrouten verschwört Dialoginstrumenten
File /tmp/tmp.F8zm7RXvJr/deu/deu.Microsoft_Sans_Serif.exp0.lstmf page 20 (Perfect):

Can someone help me to find out what I have been doing wrong?

Thanks,
Alex  how to build tesseract 3.0.1 on mac OS X?  >What is the reason for this change? Shouldn't Tesseract get credit for its PDF output?

If someone embeds libtesseract in his his product 'myOwnOCR', he probably prefer that any output will use this name instead of 'Tesseract'...

Maybe it will be more fair if 'libtesseract x.yz' will be kept in the output, especially if the developer doesn't apply any change to it, or apply only minor changes. I'm against this as well. It's too important to be able to trace Tesseract-produced PDFs back to the version of Tesseract that produced them. Tesseract should not allow changing the /Producer field.

The /Creator field, which Tesseract does not set, is the appropriate one for this use case.  I will training a new model to recognize chinese, english and some special symbol, now i can not create the image with text2image because the font file may not cover all text. How could I to solve this situation. What version of Tesseract are you using?

Have you tried using multiple languages for recognition, eg. -l eng+chi

- excuse the brevity, sent from mobile

On 20-Feb-2017 2:42 PM, "dipthomas" <notifications@github.com> wrote:

> I will training a new model to recognize chinese, english and some special
> symbol, now i can not create the image with text2image because the font
> file may not cover all text. How could I to solve this situation.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/730>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o4WjA6UrmCEaJ63Tv1rfA7q8RxuYks5reVjggaJpZM4MF7F5>
> .
>
 @Shreeshrii , I am using Tesseract 4.0, and I want to train a model including English, Chinese and some math symbol like △. 
Now the problem is I can not generate the training image via a single font. (text2image) The training process drops unrenderable words. So the letters not included
in the font will get dropped, if you use a combined text with multiple
languages and run text2image with different fonts.

You will then get some images with text in one language and some in the
other.

However, I don't know how successful this will be. You will need a large
amount of text to train.

I have not had much success in training 4.0. please share your experiences
if you try the above approach.

- excuse the brevity, sent from mobile

On 22-Feb-2017 3:24 PM, "dipthomas" <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/Shreeshrii> , I am using Tesseract 4.0,
> and I want to train a model including English, Chinese and some math symbol
> like △.
> Now the problem is I can not generate the training image via a single
> font. (text2image)
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/730#issuecomment-281621699>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o9P6-UMdzYkJsUelGKI3dxeOj75Jks5rfAXGgaJpZM4MF7F5>
> .
>
 Have you tried with
https://github.com/tesseract-ocr/tessdata/blob/master/chi_sim.traineddata

https://github.com/tesseract-ocr/langdata/tree/master/chi_sim
shows the kind of combination you are talking about ..

https://github.com/tesseract-ocr/langdata/blob/master/chi_sim/chi_sim.training_text
https://github.com/tesseract-ocr/langdata/blob/master/chi_sim/desired_characters
https://github.com/tesseract-ocr/langdata/blob/master/chi_sim/chi_sim.training_text.unigram_freqs

You can try to find fonts that support the training text by using command
similar to following (change location of fonts and langdata to match your
setup):

text2image --find_fonts \
--fonts_dir /usr/share/fonts \
--text ./langdata/chi_sim/chi_sim.training_text \
--min_coverage .9  \
--outputbase ./langdata/chi_sim/chi_sim\
|& grep raw | sed -e 's/ :.*/" \\/g'  | sed -e 's/^/  "/'
>./langdata/chi_sim/fontslist.txt

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Feb 22, 2017 at 6:10 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
wrote:

> The training process drops unrenderable words. So the letters not included
> in the font will get dropped, if you use a combined text with multiple
> languages and run text2image with different fonts.
>
> You will then get some images with text in one language and some in the
> other.
>
> However, I don't know how successful this will be. You will need a large
> amount of text to train.
>
> I have not had much success in training 4.0. please share your experiences
> if you try the above approach.
>
> - excuse the brevity, sent from mobile
>
> On 22-Feb-2017 3:24 PM, "dipthomas" <notifications@github.com> wrote:
>
>> @Shreeshrii <https://github.com/Shreeshrii> , I am using Tesseract 4.0,
>> and I want to train a model including English, Chinese and some math symbol
>> like △.
>> Now the problem is I can not generate the training image via a single
>> font. (text2image)
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/730#issuecomment-281621699>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AE2_o9P6-UMdzYkJsUelGKI3dxeOj75Jks5rfAXGgaJpZM4MF7F5>
>> .
>>
>
 https://chinesefontdesign.com/tag/simplified-chinese-font

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Thu, Feb 23, 2017 at 12:14 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
wrote:

> Have you tried with
> https://github.com/tesseract-ocr/tessdata/blob/master/chi_sim.traineddata
>
> https://github.com/tesseract-ocr/langdata/tree/master/chi_sim
> shows the kind of combination you are talking about ..
>
> https://github.com/tesseract-ocr/langdata/blob/master/chi_
> sim/chi_sim.training_text
> https://github.com/tesseract-ocr/langdata/blob/master/chi_
> sim/desired_characters
> https://github.com/tesseract-ocr/langdata/blob/master/chi_
> sim/chi_sim.training_text.unigram_freqs
>
> You can try to find fonts that support the training text by using command
> similar to following (change location of fonts and langdata to match your
> setup):
>
> text2image --find_fonts \
> --fonts_dir /usr/share/fonts \
> --text ./langdata/chi_sim/chi_sim.training_text \
> --min_coverage .9  \
> --outputbase ./langdata/chi_sim/chi_sim\
> |& grep raw | sed -e 's/ :.*/" \\/g'  | sed -e 's/^/  "/'
> >./langdata/chi_sim/fontslist.txt
>
> ShreeDevi
> ____________________________________________________________
> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>
> On Wed, Feb 22, 2017 at 6:10 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
> wrote:
>
>> The training process drops unrenderable words. So the letters not
>> included in the font will get dropped, if you use a combined text with
>> multiple languages and run text2image with different fonts.
>>
>> You will then get some images with text in one language and some in the
>> other.
>>
>> However, I don't know how successful this will be. You will need a large
>> amount of text to train.
>>
>> I have not had much success in training 4.0. please share your
>> experiences if you try the above approach.
>>
>> - excuse the brevity, sent from mobile
>>
>> On 22-Feb-2017 3:24 PM, "dipthomas" <notifications@github.com> wrote:
>>
>>> @Shreeshrii <https://github.com/Shreeshrii> , I am using Tesseract 4.0,
>>> and I want to train a model including English, Chinese and some math symbol
>>> like △.
>>> Now the problem is I can not generate the training image via a single
>>> font. (text2image)
>>>
>>> —
>>> You are receiving this because you were mentioned.
>>> Reply to this email directly, view it on GitHub
>>> <https://github.com/tesseract-ocr/tesseract/issues/730#issuecomment-281621699>,
>>> or mute the thread
>>> <https://github.com/notifications/unsubscribe-auth/AE2_o9P6-UMdzYkJsUelGKI3dxeOj75Jks5rfAXGgaJpZM4MF7F5>
>>> .
>>>
>>
>
 @dipthomas If problem is resolved, please close the issue. Thanks! @Shreeshrii Your reply is very detailed, thank you Hi @Shreeshrii ,
I am looking for a trained data for the bullet character. It should work even if we are using mulitple language in a single string.

Can you please provide the trained data for bullet character or guide me how to do do this? I tried Latin, we didnt get bullet character!

tried Combine_tessdata, using that i am able to unpack that trained data.Can you help us how to see the uncharset contains the bullet character?
Can you please help on this?

Thanks its (U+2022) •  Images and Ground truth at 
https://github.com/Shreeshrii/tess4eval_marathi

OCR eval reports at
https://shreeshrii.github.io/tess4eval_marathi/ If the the source of the issue is the traineddata, maybe you should move this issue to the langdata issues.   I tried to compile 3.05.00 on a rasperry pi with rasperian 4.1.19+ and get the following error:

libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE -I../ccutil -I../ccstruct -I../viewer -I../classify -I../dict -I../wordrec -I../cutil -I../textord -I../openc
l -I../neural_networks/runtime -I../cube -I/usr/local/include/leptonica -g -O2 -MT thresholder.lo -MD -MP -MF .deps/thresholder.Tpo -c thresholder.cpp  -fPIC -DPIC -o .libs/thresholder.o
thresholder.cpp: In member function 'virtual void tesseract::ImageThresholder::ThresholdToPix(tesseract::PageSegMode, Pix**)':
thresholder.cpp:187:20: error: 'nullptr' was not declared in this scope
Makefile:482: recipe for target 'thresholder.lo' failed
make[2]: *** [thresholder.lo] Error 1

This maybe relates to #535 and its fix in here https://github.com/tesseract-ocr/tesseract/blob/master/ccmain/thresholder.cpp#L187?  Searching for a place to introduce JBig2-compression into my quite typical workflow I stumbled upon tesseract actually generating sandwiches - which is nice. Are there any plans to offer alternative to the, i assume, flate-compression currently used? >Are there any plans to offer alternative to the, i assume, flate-compression currently used?

https://github.com/tesseract-ocr/tesseract/blob/ca16a08c10/api/pdfrenderer.cpp#L729  I want to build a model with a image of bar code as input and output the number sequence corresponding to the bar code. 
Input:
![image](https://cloud.githubusercontent.com/assets/10412402/23064393/df2e88a0-f54a-11e6-860b-c0ea20f1575f.png)

Output:
6922872789071

This task is similar to speech recognition. Can tesseract be used to do this?
  I know, that `tesseract --version` outputs the exact version and github commit hash, **if** it was compiled with `./configure --enable-debug`, example:
```
tesseract 4.00.00alpha-278-gc768b58
 leptonica-1.74.1
  libjpeg 6b (libjpeg-turbo 1.3.1) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 Found AVX
 Found SSE
```

I wonder, why this is not output, when the configuration setting was not given and I suggest to modify the build code so that the version and github commit hash is **always** shown with the `--version`command.  Yes. I agree, adding version info with github commit hash in non-debug builds will be very helpful.

An earlier request - https://github.com/tesseract-ocr/tesseract/issues/581#issuecomment-267339390 Needs change in 

https://github.com/tesseract-ocr/tesseract/blob/fd0683f9e03934bbdf7fbebb4d21d64c37b68bc0/api/baseapi.cpp#L140
 @zdenop Is https://github.com/tesseract-ocr/tesseract/blob/fd0683f9e03934bbdf7fbebb4d21d64c37b68bc0/api/baseapi.cpp#L140 the only change needed, and would you accept a corresponding pull request ? @zdenop Where exactly is your problem to print the GIT_REV when users use --version ?

I *have a problem when, as an expert, I run always the latest version, but sometimes after git pull the latest build is not the "installed" build. As a user I want to have the fastest code, i.e. built *without* --enable-debug.

I again request to think over it, and to always - if available - burn the GIT_REV into the code. I ask you for this. Not using `--enable-debug` increases processing speed about 6%.
  @zdenop, what about using GIT_REV only for versions without tag, no matter whether it is a debug or a release build? Then released stable versions would not show GIT_REV. >Not using --enable-debug increases processing speed about 6%.

Only ~6%? With LSTM mode?

https://github.com/tesseract-ocr/tesseract/issues/40#issuecomment-263432042 BTW, maybe we should add another debug/optimization option with `-Og`?
https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html  I compile tesseract 3.04 with OpenCL support and I install it on an Ubuntu 16.04 64-bit machine. The machine  has an intel core i5 CPU and an nvidia geforce 1080gtx with cuda 8.0 GPU. 

When I run tesseract from command line  I get:

$ tesseract phototest.tif out -l eng
tesseract: /usr/local/cuda/lib64/libOpenCL.so.1: no version information available (required by tesseract)
[DS] Profile read from file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:GeForce GTX 1080 score is 0.106336
[DS] Device[2] 0:(null) score is 0.895098
[DS] Selected Device[1]: "GeForce GTX 1080" (OpenCL)
Tesseract Open Source OCR Engine v3.04.02dev with Leptonica

I make a lot of tests using C++ API, python wrapper and command line but I didn’t notice any improvement on speed. Do I miss something? Well I install tesseract 3.05.00 (I also install leptonica from source) but the result was the same. No speed improvement. How can we explain that I don’t have any speed up?
Please note (see below) a warning related to libOpenCL.so “no version information available (required by tesseract)”.  

`
$ tesseract -v
tesseract: /usr/local/cuda/lib64/libOpenCL.so.1: no version information available (required by tesseract)
tesseract 3.05.00
 leptonica-1.74.1
  libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8

 OpenCL info:
  Found 1 platforms.
  Platform name: NVIDIA CUDA.
  Version: OpenCL 1.2 CUDA 8.0.46.
  Found 1 devices.
    Device 1 name: GeForce GTX 1080.



$ tesseract test.tif out
tesseract: /usr/local/cuda/lib64/libOpenCL.so.1: no version information available (required by tesseract)
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performing profiling.

[DS] Device: "GeForce GTX 1080" (OpenCL) evaluation...
[DS] Device: "GeForce GTX 1080" (OpenCL) evaluated
[DS]          composeRGBPixel: 0.015255 (w=1.2)
[DS]            HistogramRect: 0.009756 (w=2.4)
[DS]       ThresholdRectToPix: 0.007360 (w=4.5)
[DS]        getLineMasksMorph: 0.004570 (w=5.0)
[DS]                    Score: 0.097692

[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
[DS]          composeRGBPixel: 0.015348 (w=1.2)
[DS]            HistogramRect: 0.058428 (w=2.4)
[DS]       ThresholdRectToPix: 0.018490 (w=4.5)
[DS]        getLineMasksMorph: 0.122624 (w=5.0)
[DS]                    Score: 0.854966
[DS] Scores written to file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:GeForce GTX 1080 score is 0.097692
[DS] Device[2] 0:(null) score is 0.854966
[DS] Selected Device[1]: "GeForce GTX 1080" (OpenCL)
Tesseract Open Source OCR Engine v3.05.00 with Leptonica`  Forexample:
In the 'eng.tessdata',There are nine file.
But i want delete some file and create a new 'eng.tessdata'.
what can i do? see
https://github.com/tesseract-ocr/tesseract/blob/master/doc/combine_tessdata.1.asc  For latest version, use OEM 1 for the LSTM engine. In the first
experimental version it was OEM 4.

- excuse the brevity, sent from mobile

On 13-Feb-2017 2:59 PM, "majorbossy" <notifications@github.com> wrote:

> test.pdf
> <https://github.com/tesseract-ocr/tesseract/files/770565/test.pdf>
> [image: test]
> <https://cloud.githubusercontent.com/assets/25739284/22877715/9d091ece-f1ce-11e6-867c-dd7fe106ec43.png>
>
> test.hocr.txt
> <https://github.com/tesseract-ocr/tesseract/files/770570/test.hocr.txt>
>
> Hi
>
> In the attached hocr you can search for "bbox 0 0" and see that there are
> multiple occurrences of ocrx_word artifacts where the bbox coordinates are
> the same as those of the ocr_page artifact.
>
> These ocrx_word occurrences seem to be occurring in relation to vertical
> and horizontal lines in the image.
>
> If you search for "Party" in the pdf, you will see that the bbox for the
> last two instances goes out to the end of the underlining, despite the fact
> that the text has been correctly identified as "Party A" and "Party B"
>
> The image was redacted using Paint and Windows clipboard, but despite any
> damage I have inflicted on the file, the text is still correctly identified.
> Whatever the state of the image, it can't be correct for an ocrx_word to
> have the same coordinates as that of the ocr_page.
>
> I downloaded the Windows Installer version from UB Mannheim on 18/1/17
> (the current version doesn't run on my system!):
>
> tesseract 4.00.00alpha
> leptonica-1.73
> libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.6.20 :
> libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.3 : libopenjp2 2.1.0
>
> Windows 10
> Version 10.0.14393 Build 14393
>
> The command I'm running is:
> "C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" -oem 4 -psm 6 -c
> tessedit_create_hocr=1 -c tessedit_create_pdf=1 test.png test
>
> I've turned the auto psm off, since it seems to lose the right-hand column
> of tables completely, and I'd rather carry out my own psm.
>
> OEM 4 is just amazing. Great work!!
>
> Major B
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/718>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o8txKL5YYMkvzE2q3D9XehmQ2Qekks5rcCKEgaJpZM4L-9x1>
> .
>
 Maybe we should print a warning:

>oem 4 was selected. That value is out of range [0-3].
Using oem 3, which is the default mode.

Something similar should be used for psm out-of-range value. you need
--oem and --psm now

instead of -oem
-psm is still accepted for historical reasons

two dashes instead of one

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Feb 13, 2017 at 4:07 PM, majorbossy <notifications@github.com>
wrote:

> Ok. Looks like I need to wait for a working build of the latest version
> (I'm a java-restricted etl/sql developer).
>
> If I use the latest UB Mannheim build with:
>
> "C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" -oem 1 -psm 3 -c
> tessedit_create_hocr=1 -c tessedit_create_pdf=1 test.png test
>
> I get:
>
> read_params_file: parameter not found: ëPNG
>
> And if I try:
>
> "C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" test.png test
>
> I get:
>
> Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
> DotProductAVX can't be used on Android
>
> And the exe bombs out. I think this is a known issue, and I just need to
> wait.
>
> Thanks
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/718#issuecomment-279350458>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oy9IIzaIJ_zxV-dRc18b9ydG2vSjks5rcDKCgaJpZM4L-9x1>
> .
>
 you could try

Please try:
https://smani.fedorapeople.org/tmp/gImageReader_3.2.1_qt5_i686_tesseract4.0.0.git2f10be5.exe
https://smani.fedorapeople.org/tmp/gImageReader_3.2.1_qt5_x86_64_tesseract4.0.0.git2f10be5.exe

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Feb 13, 2017 at 4:21 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
wrote:

> you need
> --oem and --psm now
>
> instead of -oem
> -psm is still accepted for historical reasons
>
> two dashes instead of one
>
> ShreeDevi
> ____________________________________________________________
> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>
> On Mon, Feb 13, 2017 at 4:07 PM, majorbossy <notifications@github.com>
> wrote:
>
>> Ok. Looks like I need to wait for a working build of the latest version
>> (I'm a java-restricted etl/sql developer).
>>
>> If I use the latest UB Mannheim build with:
>>
>> "C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" -oem 1 -psm 3 -c
>> tessedit_create_hocr=1 -c tessedit_create_pdf=1 test.png test
>>
>> I get:
>>
>> read_params_file: parameter not found: ëPNG
>>
>> And if I try:
>>
>> "C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" test.png test
>>
>> I get:
>>
>> Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
>> DotProductAVX can't be used on Android
>>
>> And the exe bombs out. I think this is a known issue, and I just need to
>> wait.
>>
>> Thanks
>>
>> —
>> You are receiving this because you commented.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/718#issuecomment-279350458>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AE2_oy9IIzaIJ_zxV-dRc18b9ydG2vSjks5rcDKCgaJpZM4L-9x1>
>> .
>>
>
>
 >"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" -oem 1 -psm 3 -c tessedit_create_hocr=1 -c tessedit_create_pdf=1 test.png test

That is a wrong usage. It should be:
>"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe" test.png test -oem 1 -psm 3 -c tessedit_create_hocr=1 -c tessedit_create_pdf=1
 @stweil - problem with latest 4.o windows build

I am able to reproduce the problem

```
C:\Users\User\shree>"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe"  -- version
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error during processing.
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 03658DF0 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddatalstm-punc-dawg)
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 03658EA0 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddatalstm-word-dawg)
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 03658F50 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddatalstm-number-dawg)
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 03668ED8 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddatapunc-dawg)
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 03658D90 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddataword-dawg)
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 03658E40 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddatanumber-dawg)
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 0300D858 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddatabigram-dawg)
ObjectCache(56930A88)::~ObjectCache(): WARNING! LEAK! object 0300D628 still has count 1 (id \Program Files (x86)\Tesseract-OCR\tessdata/eng.traineddatafreq-dawg)

C:\Users\User\shree>"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe"  san001.png test --oem 1
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 18 diacritics
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
``` Hi there,

if you still get the message "DotProductAVX can't be used on Android", could it be that you try to run 32-bit code on a 64-bit machine ? This is what I'm experiencing.

If I build the lastest version with MINGW64-32 bit and try to run on a 64-bit Windows, I get this error and a crash.

If I build with 64 bit all is fine running on Windows 64 bit.
If I build with 32 bit all is fine running on Windows 32 bit.

Maybe somebody could look into the code again and check if the test for AVX is performed at runtime, not at build time.

Greetings. I will uninstall and check again tomorrow.  @stweil You are right, I messed up in giving the version command.

I reinstalled versions for 2/2/17 as well as 1/30/17. Getting the error regarding AVX for both versions.

Is it possible that your local version of binary is different from the one linked from wiki?

```
C:\Users\User\shree>"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe"  san001.png test --oem 1
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 18 diacritics
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.

C:\Users\User\shree>"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe"  --version
tesseract 4.00.00alpha
 leptonica-1.74.1
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.5.0) : libpng 1.6.20 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.3 : libopenjp2 2.1.0

 Found AVX
 Found SSE
``` Hi all

I think this is due to me abusing the psm. It's probably a bit much to switch off segmentation and still expect tess to handle tables properly.

I don't get this issue when the psm is 11.

Thanks  # Visarga vs Colon

Please see https://shreeshrii.github.io/tess4eval-san/

Visarga being recognized as colon etc. 
This will be specially applicable for sanskrit where `Visarga ः`  is quite common.

Ground Truth
```
राजेन्द्रो भूपती रूढो माली संसारसारथिः । नित्यः सम्पूर्णकामश्च भक्तकामधुगुत्तमः ॥ ६५ गणपः केशवो भ्राता पिता माताऽथ मारुतिः । सहस्रमूर्धा सहस्रास्यः सहस्राक्षः सहस्रपात् ॥ ६६
```

OCRed text
```
राजेन्द्रो भूपती रूढो माली संसारसारथि: । नित्य: सम्पूर्णकामश्च भक्तकामधुगुत्तम: ।। ६५ गणप: केडावो भ्राता पिता माताऽथ मारुति; । सहस्रमूर्धा सहस्रास्य: सहस्राक्ष: सहस्रपात् ।। ६६
``` I suggest to remove the following from the desired characters list for Devanagari script languages:

```
%
&
:
€
$
£
```

 # Nukta 

Looking at the new evaluation page, another error is being seem, relating to nukta . OCRed text does not seem to have any.

GT files are using decomposed version of nukta letters, rather than combined form, as dictated by normalisation.
 # Northern style orthography

Another error that I have noted for Devanagari is that Northern style orthography of some letters is not being recognized correctly. 

See sample iamges of the two styles under 'Download fonts' section on 
http://www.sanskritweb.net/cakram/

different la forms displayed in 
http://www.omniglot.com/writing/devanagari.htm

More old style sample text - 
pages 21-24
http://ctan.imsc.res.in/language/devanagari/velthuis/doc/manual.pdf
various pages
http://www.sanskritweb.net/itrans/s99fonts.pdf

Ref: copy of old issue which has links to pages with old style text

https://github.com/gxrxrdx/tesseract-ocr/issues/1360 # Devanagari Varnamala - Alphabet

A listing of the basic Devanagari Alphabet is also not being recognized correctly.

see https://shreeshrii.github.io/tess4eval_deva/ # Eyelash ra - RA vs RRA

Ref: https://r12a.github.io/scripts/devanagari/block

```
U+0930 DEVANAGARI LETTER RA

When used as a half-consonant in Marathi or Newari, 
this character uses the 'eyelash-RA' shape, 
eg. र्‍. To create this shape in Unicode, follow 
U+0930 DEVANAGARI LETTER RA र + U+094D DEVANAGARI SIGN VIRAMA  ् with U+200D ZERO WIDTH JOINER.

The eyelash-RA is transcribed as r̆.
```

```
U+0931 DEVANAGARI LETTER RRA

Description in the Unicode standard:
• for transcribing Dravidian alveolar r
• half form is represented as 'Eyelash RA'

ṟ in ISO 15919
```

Tesseract is recognizing it as the second case -  U+0931 DEVANAGARI LETTER RRA  + U+094D DEVANAGARI SIGN VIRAMA  ्

see samples from mar.Adobe_Devanagari.exp0.txt to mar.e-Nagari_OT.exp0.txt in https://shreeshrii.github.io/tess4eval_marathi/index-hin.html

  From #707:

@amitdo commented:
>I also think we should release a last 3.0x version in the upcoming 2-6 weeks.

@zdenop  commented:
>If 3.05 should be the last version with legacy OCR Engine (old engine) then there should be possibility to read [OCR result from memory](https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-dev/mZ2IUsvWgbY/2yz-b1cUAgAJ).

@jbreiden commented:
>https://wiki.ubuntu.com/ZestyZapus/ReleaseSchedule
>
>Feb 16 is the final deadline for changes to Ubuntu 17.04. I am not comfortable shipping anything from 4.x to these users, but we can consider taking a snapshot of the 3.0.5 branch. It does have some bug and compatibility fixes that are good for users. Regarding training data, I would not ship an update that at all. This would be purely be a code update.
>
>I know the long standing issue has been restoring an API call (last seen in version 3.0.2) to send results to memory instead of file. I respect that idea, but we don't have it, and it's not that easy to add. I think it is fair to say that it would be impossible before deadline. So the question is, do we ship an update to users this cycle or not. And if so, should I take a snapshot? And if so, what would it be called?
>
>A few more thoughts that are somewhat related
>
>* I see no reason that this has to be the last ever release on the 3.0.x branch.
>*  My guess is by the next next release in Oct 2017 that 4.x will be ready for the vast majority of users
>*  I'm not planning to ship both 3.0.x and 4.x at the same time with Debian/Ubuntu. I think it will be very rare for people to want both, and those who do will be advanced users who can work from source code.

@Shreeshrii commented:
>@jbreiden Good idea to do a code update for 3.05 for Ubuntu 17.04. There are a number of bug fixes and changes and it would be good to get them out to the users. Thanks!
 I added [Release Notes for 3.05](https://github.com/tesseract-ocr/tesseract/wiki/ReleaseNotes#to-be-released-as-v305---in-feb-2017-), based on the [3.05 branch](https://github.com/tesseract-ocr/tesseract/commits/3.05).
 @zdenop, @egorpugin 

Some minor fixes to 3.05:

README.md
>The latest stable version is 3.04.01, released in February 2016.

=>
>The latest stable version is 3.05, released in February 2017.

tesseract/api/baseapi.h
`#define TESSERACT_VERSION_STR "3.05.00dev"`
=>
`#define TESSERACT_VERSION_STR "3.05.00"`

configure.ac
`AC_INIT([tesseract], [3.05.00dev], [https://github.com/tesseract-ocr/tesseract/issues])`
=>
`AC_INIT([tesseract], [3.05.00], [https://github.com/tesseract-ocr/tesseract/issues])`

```
PACKAGE_YEAR=2015
PACKAGE_DATE="07/11"
```
=>
```
PACKAGE_YEAR=2017
PACKAGE_DATE="02/14"
```

ChangeLog
>
See [ReleaseNotes](https://github.com/tesseract-ocr/tesseract/wiki/ReleaseNotes
)

AUTHORS
Please add Nick White to the Community Contributors.

CONTRIBUTING.md
https://github.com/tesseract-ocr/tesseract/commit/bf9f40cac631



 So, when? Maybe you want to use this strategy:
 
1. Make one unified deb package for Debian 9, Ubuntu 16.04, Ubuntu 17.04.
2. Push it to Debian & Ubuntu 'backports' repos. For Debian 9 and Ubuntu 17.04 you will need to wait until they are released. For Ubuntu 16.04 you can start when you want to. @zdenop 

I think, you should tag the 3.05 branch with the 3.05.0 release. It can be updated in case there are any additional changes. @manisandro

Have you tried building gImageReader with 3.05  release candidate?

https://github.com/manisandro/gImageReader/issues/156 Hi, 
I'm the maintainer of gimagereader in Debian. I just checked with the debs @jbreiden provided. Gimagereader crashes when compiled against 3.0.4 but run with 3.0.5, see https://gist.github.com/innir/a4662ad7043c9cc27e9f7bdaff8f8acf.

Recompiling gImageReader against 3.0.5 resolves the crash.

This is really easy to fix upstream. You just have to bump the SONAME if your symbols change! Not too hard to get! Please make a 3.0.5.1 release and bump the SONAME!

Best,
Philip @manisandro no problem on your side, gImageReader works fine with 3.0.5 :) Thanks for checking @innir , I haven't yet had time to build 3.0.5. @jbreiden I think it's in Recognize() or one of the functions Recognize() calls. Hard to tell as the next two lines in the crash log are empty :(
Anyway, if symbols are removed, the SONAME has to be bumped, if symbols are only added that's not necessary - AFAIR. Those ABI trackers are good, but I'm not sure if they catch things like this: https://github.com/tesseract-ocr/tesseract/pull/259/files
 abipkgdiff output (comparing 3.04.01 and 3.05.00):

    ================ changes of libtesseract.so.3.0.4===============c++filt 
    Functions changes summary: 0 Removed, 0 Changed, 0 Added function
    Variables changes summary: 0 Removed, 0 Changed, 0 Added variable
    Function symbols changes summary: 11 Removed, 41 Added function symbols not referenced by debug info
    Variable symbols changes summary: 0 Removed, 3 Added variable symbols not referenced by debug info

    11 Removed function symbols not referenced by debug info:

        WriteParamDesc(_IO_FILE*, unsigned short, PARAM_DESC*)
        read_list(char const*)
        GENERIC_2D_ARRAY<tesseract::TrainingSampleSet::FontClassInfo>::Resize(int, int, tesseract::TrainingSampleSet::FontClassInfo const&)
        WERD_RES::FakeWordFromRatings()
        tesseract::DocumentCache::LoadDocuments(GenericVector<STRING> const&, char const*, bool (*)(STRING const&, GenericVector<char>*))
        tesseract::DocumentCache::GetPageBySerial(int)
        tesseract::DawgPositionVector::~DawgPositionVector(), aliases tesseract::DawgPositionVector::~DawgPositionVector()
        tesseract::DawgPositionVector::~DawgPositionVector()
        tesseract::Dict::Load(tesseract::DawgCache*)
        tesseract::Dict::ProcessPatternEdges(tesseract::Dawg const*, tesseract::DawgPosition const&, int, bool, tesseract::DawgPositionVector*, PermuterType*) const
        tesseract::ImageData::PreScale(int, Pix**, int*, int*, GenericVector<TBOX>*) const

    41 Added function symbols not referenced by debug info:

        TessBaseAPIDetectOrientationScript
        WriteParamDesc(_IO_FILE*, unsigned short, PARAM_DESC const*)
        GenericVector<tesseract::DawgPosition>::clear()
        STRING::SkipDeSerialize(bool, tesseract::TFile*)
        WERD_RES::FakeWordFromRatings(PermuterType)
        tesseract::TessBaseAPI::GetTSVText(int)
        tesseract::TessBaseAPI::GetHOCRText(ETEXT_DESC*, int)
        tesseract::TessBaseAPI::AnalyseLayout()
        tesseract::TessBaseAPI::DetectOrientationScript(int*, float*, char const**, float*)
        tesseract::ColPartition::SortByBBox(void const*, void const*)
        tesseract::DocumentData::SetDocument(char const*, char const*, long long, bool (*)(STRING const&, GenericVector<char>*))
        tesseract::DocumentData::IsPageAvailable(int, tesseract::ImageData**)
        tesseract::DocumentData::LoadPageInBackground(int)
        tesseract::DocumentData::UnCache()
        tesseract::DocumentCache::TotalPages()
        tesseract::DocumentCache::LoadDocuments(GenericVector<STRING> const&, char const*, tesseract::CachingStrategy, bool (*)(STRING const&, GenericVector<char>*))
        tesseract::DocumentCache::GetPageRoundRobin(int)
        tesseract::DocumentCache::GetPageSequential(int)
        tesseract::DocumentCache::CountNeighbourDocs(int, int)
        tesseract::ParamsVectors::~ParamsVectors()
        tesseract::ParamsVectors::~ParamsVectors(), aliases tesseract::ParamsVectors::~ParamsVectors()
        tesseract::TessTsvRenderer::AddImageHandler(tesseract::TessBaseAPI*)
        tesseract::TessTsvRenderer::EndDocumentHandler()
        tesseract::TessTsvRenderer::BeginDocumentHandler()
        tesseract::TessTsvRenderer::TessTsvRenderer(char const*), aliases tesseract::TessTsvRenderer::TessTsvRenderer(char const*)
        tesseract::TessTsvRenderer::TessTsvRenderer(char const*, bool)
        tesseract::TessTsvRenderer::TessTsvRenderer(char const*)
        tesseract::TessTsvRenderer::TessTsvRenderer(char const*, bool), aliases tesseract::TessTsvRenderer::TessTsvRenderer(char const*, bool)
        tesseract::TessTsvRenderer::~TessTsvRenderer()
        tesseract::TessTsvRenderer::~TessTsvRenderer()
        tesseract::TessTsvRenderer::~TessTsvRenderer(), aliases tesseract::TessTsvRenderer::~TessTsvRenderer()
        tesseract::ReCachePagesFunc(void*)
        tesseract::Dict::FinishLoad()
        tesseract::Dict::SetupForLoad(tesseract::DawgCache*)
        tesseract::Dict::Load(char const*, STRING const&)
        tesseract::DawgCache::~DawgCache(), aliases tesseract::DawgCache::~DawgCache()
        tesseract::DawgCache::~DawgCache()
        tesseract::ImageData::SkipDeSerialize(bool, tesseract::TFile*)
        tesseract::Dict::ProcessPatternEdges(tesseract::Dawg const*, tesseract::DawgPosition const&, int, bool, tesseract::DawgArgs*, PermuterType*) const
        tesseract::Dict::IsSpaceDelimitedLang() const
        tesseract::ImageData::PreScale(int, int, float*, int*, int*, GenericVector<TBOX>*) const

    3 Added variable symbols not referenced by debug info:

        typeinfo for tesseract::TessTsvRenderer
        typeinfo name for tesseract::TessTsvRenderer
        vtable for tesseract::TessTsvRenderer > I've heard about this ABI tracker. Maybe it's possible to add tesseract (& leptonica) there somehow.

Done:

https://abi-laboratory.pro/tracker/timeline/tesseract/
https://abi-laboratory.pro/tracker/timeline/leptonica/

![tesseract-2](https://cloud.githubusercontent.com/assets/1517837/24391524/af496122-13a0-11e7-8dd5-c138319425db.png)

About the tracker: https://abi-laboratory.pro/index.php?view=abi-tracker Next release - 3.05.1
https://groups.google.com/forum/#!topic/tesseract-dev/7vwsJNCAUcQ  PDF Output being a standard feature has some problems in Windows.
If you use stdout as tesseract output and pipe or redirect the PDF Output to another Executable, e.g pdftotext, every linefeed is converted to CR/LF in the resulting PDF, corrupting this PDF file.

It could easily prevented by implementing

`#ifdef WIN32`
`  if (_setmode(_fileno(stdout), _O_BINARY) == -1)`
`    tprintf("ERRROR: cout to binary: %s, strerror(errno));`
`#endif`

somewhere near TessPDFRenderer call, maybe in tesseractmain.cpp.
You would need to include fcntl.h and io.h too.

I tested it and it worked fine redirecting and piping in Windows.

Many thanks to the whole bunch of developers.

wadex1
 Hi again,
I'm not sure about the appropriate location to put the code.
If all output is sent binary, not only PDF but text output will be binary too.
I don't know if this breaks any other compatibilities, especially with piping or redirecting the text output in Windows.

Maybe somebody could look for the correct place to insert.

I think this modification is quite necessary if we want to pipe PDF output to e.g. pdftotext.exe in Windows.
Running pdftotext on the tesseract PDF output is the only way for me to have text output with a decent layout and piping would save me from using temporary files.

Best regards  To recap, when a Tesseract PDF (3.0x or 4.x) is run through Ghostscript the OCR layer will be mangled. Ghostscript's pdfwrite (`gs -sDEVICE=pdfwrite -o out.pdf in.pdf`) will display spaces between every character and get confused about word boundaries. Other PDF viewers tend to work but usually have problems with searching for text, because they read as the text as having spaces in between.

Before (`pdftext`)
```
Portez ce vieux whisky au juge
blond qui fume sur son île
```

After
```
P o r t e z c e v i e u x w h i s k y a u j u g e
o n d q u i f u m e s u r s o n île
```

(A related issue I reported was fixed in Ghostscript 9.20, but unfortunately that is not complete solution. Ghostscript <9.20 *also* corrupts any characters above U+00FF that happen to be present.)

There are lots of reasons someone might run a Tesseract PDF through Ghostscript pdfwrite: producing lower DPI renderings, PDF/A conversion, merging PDFs, changing paper sizes, sanitizing potential security holes like Javascript. There are also a lot of programs and services that use Ghostscript internally, sometimes without the user being aware of this. It's unfortunate that Tesseract PDFs don't play nicely with Ghostscript.

Ken Sharp (Ghostscript PDF dev) swears up and down that he can't do anything about it, essentially because Ghostscript interprets the input PDF into a page description language that is then rendered using pdfwrite. The output is visually identical, but otherwise the file is rewritten. Artifex also views preserving OCR text or other metadata as a bonus; if pdfwrite produces visually identical output they are satisfied.

See this comment from 2015:
https://bugs.ghostscript.com/show_bug.cgi?id=696116

Ken Sharp explains the essential difference is that the `/DW` (default glyph width) parameter on the GlyphLessFont is not understood by GhostPDL so it sets `/DW 0` and manually positions each glyph (the `-500`). 

```
[(T)-500(h)-500(e)-500]TJ
```

In English, Tesseract renders OCR with a font whose glyphs are 500 arbitrary units wide. Ghostscript reinterprets this as glyphs that are 0 units wide and moves the cursor 500 units between characters, and insists that it's the same thing.

I tried surgery on a pdfwrite-mangled file. I removed all of the `-500` offsets, set to `/DW 500` on the main font object, and removed the individual glyph width array `/W [...]` from the same. That works. (pdfwrite makes other minor changes to the PDF output too, but these don't matter as far as I know.) Writing a little script to fix mangled PDFs is possible, but it would be better to find a workaround.

So, is there any possibility of adjusting the glyphless font to work more like what Ghostscript expects so it survives the trip... without losing all of the other considerable and much appreciated effort that has gone into making glyphless work great with most other interpreters?

What are the commercial OCR tools doing to avoid similar issues?  Yes, I should have included an example, but it seems to affect just about everything so it didn't seem that hard to come up with one....

Tesseract 4.00alpha (commit 2f10be5)

```
$ sha1sum tessdata/pdf.ttf
ac5300b169c99e90e9825dd8859b8a850edde22f  tessdata/pdf.ttf
```

Using testing/phototest.tif

```
$ tesseract --tessdata-dir . --oem 1  testing/phototest.tif _phototest pdf
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Page 1
$ pdftotext _phototest.pdf  -
This is a lot of 12 point text to test the
ocr code and see if it works on all types
of file format.
The quick brown dog jumped over the
lazy fox. The quick brown dog jumped
over the lazy fox. The quick brown dog
jumped over the lazy fox. The quick
brown dog jumped over the lazy fox.

$ gs -sDEVICE=pdfwrite -o _phototest_gs.pdf _phototest.pdf
GPL Ghostscript 9.20 (2016-09-26)
Copyright (C) 2016 Artifex Software, Inc.  All rights reserved.
This software comes with NO WARRANTY: see the file PUBLIC for details.
Processing pages 1 through 1.
Page 1

$ pdftotext _phototest_gs.pdf -
T h i s
o c r

i s a

l o t o f

c o d e

a n d

1 2

p o i n t

s e e

t e x t

t o

if it w o r k s
```

<details>
<summary>click to see the rest of pdftotext</summary>

```
t e s t

o n

t h e

a l l t y p e s

o f f i l e f o r m a t .
T h e

q u i c k

l a z y

f o x .

T h e

q u i c k

o v e r

t h e

l a z y

f o x .

T h e

q u i c k

j u m p e d

o v e r

t h e

l a z y

f o x .

b r o w n

b r o w n

d o g

j u m p e d

d o g

j u m p e d

b r o w n

o v e r

o v e r

d o g

t h e

b r o w n

T h e

t h e

j u m p e d
d o g

q u i c k

l a z y

f o x .

```
</details>


After Tesseract, before Ghostscript
[_phototest.pdf](https://github.com/tesseract-ocr/tesseract/files/765802/_phototest.pdf)

After Ghostscript
[_phototest_gs.pdf](https://github.com/tesseract-ocr/tesseract/files/765803/_phototest_gs.pdf)

After Ghostscript, streams uncompressed with qpdf for easy viewing
[_phototest_gs_uncompress.pdf](https://github.com/tesseract-ocr/tesseract/files/765804/_phototest_gs_uncompress.pdf)

I also tried omitting `--oem`, not that we would expect this to make a difference. Tesseract 3.04.01 behavior is similar. I replicated this is in a Docker container with Tesseract 3.04.01 and Ghostscript 9.19. 

Before Ghostscript, here is Acrobat XI showing that text search for words works normally.
![image](https://cloud.githubusercontent.com/assets/1825843/22815997/ff31ddd8-ef13-11e6-9508-b98bcb3a070b.png)

After Ghostscript, here is Acrobat showing that a search for the word "p o i n t" matches because it is now convinced that there are spaces between each character. The highlighting is now misaligned as well.
![image](https://cloud.githubusercontent.com/assets/1825843/22815980/e924b6c8-ef13-11e6-9780-a77f6783cb28.png)

 Well, I tried `fonttools` for fun, and to my surprise I might have found a fix – with the important caveat that I have no idea what I'm doing. 

```diff
--- pdf.ttx_original	2017-02-09 22:43:11.000000000 -0800
+++ pdf.ttx	2017-02-09 22:40:31.000000000 -0800
@@ -121,8 +121,8 @@
   </OS_2>
 
   <hmtx>
-    <mtx name=".notdef" width="0" lsb="0"/>
-    <mtx name=".null" width="0" lsb="0"/>
+    <mtx name=".notdef" width="1024" lsb="0"/>
+    <mtx name=".null" width="1024" lsb="0"/>
   </hmtx>
 
   <cmap>
```

I took Ken's remark that Ghostscript didn't like individual glyphs width a width of 0, so I gave them a width equal to full the glyph box. (1024 in .ttx units, 500 in PDF font units, from what I infer)

pdftotext works, search works, even macOS Preview works. ~~Search in Chrome pdf.js seems to be broken however.~~ (Edit: was mistaken) on both pdfs pdf.js is broken:

image:
`making use of the theory`

copy & paste to gedit:
```
making
use
of  
the
theory
```

search:
`makinguseof  thetheory` I'm trying to sort similar issues.  I am working with poppler, pdf2htmlEX (which uses poppler for extraction iirc), and Acrobat Pro 10.

I have been fighting exactly the same issues described here.

I see the same results with pdf.js that @amitdo  mentioned in the reply above on the following file...

[asdf.pdf](https://github.com/tesseract-ocr/tesseract/files/768011/asdf.pdf)

This file started as a PDF from 300dpi scans, I extracted it to PNGs with Imagemagick, and OCR'd those with Tess v4 LTSM into a new PDF.

Here's a copy/paste of the first paragraph of the first page from OSX preview

> take i atll back, and sure enough that's going to come but itwill take time. Firstofallletus ask a rather simple question. How can we be sure, how can we tell, whether any utterance is to be classed as a performative or not? Surely, we feel, we ought to be able to do that. And we should obviously very muchliketobeabletosaythatthereisagrammaticalcriterionforthis, some grammatical means ofdeciding whether an utterance isperformative. All the examples I have given hitherto do in fact have the same grammatical form;theyallofthem beginwith theverbinthefirstpersonsingularpresent indicative active-not just any kind of verb of course, but still they all are in fact of that form. Furthermore, with these verbs that I have used there is a typical asymmetry between the use of this person and tense of the verb and the use of the same verb in other persons and other tenses, and this asym- metry is rather an important clue. 

and Acrobat Pro (also on OSX)...

> take it all back, and sure enough that's going to come but it will take time.
> First of all let us ask a rather simple question. How can we be sure, how can
> we tell, whether any utterance is to be classed as a performative or not?
> Surely, we feel, we ought to be able to do that. And we should obviously very
> much like to be able to say that there is a grammatical criterion for this,
> some grammatical means of deciding whether an utterance is performative.
> All the examples I have given hitherto do in fact have the same grammatical
> form; they all of them begin with the verb in the first person singular present
> indicative active-not just any kind of verb of course, but still they all are in
> fact of that form. Furthermore, with these verbs that I have used there is a
> typical asymmetry between the use of this person and tense of the verb and
> the use of the same verb in other persons and other tenses, and this asymmetry
> is rather an important clue.

And pdf.js...

> it
> all
> back,
> and
> sure
> enough
> that's
> going
> to
(ad infinitum, all words on a separate line)

In Chrome...

> take i allt back, and sure enough that's going to come but it will take time.
> First of all let us ask a rather simple question. How can we be sure, how can
> we tell, whether any utterance is to be classed as a performative or not?
> Surely, we feel, we ought to be able to do that. And we should obviously very
> much like to be able to say that there is a grammatical criterion for this,
> some grammatical means of deciding whether an utterance is performative.
> All the examples I have given hitherto do in fact have the same grammatical
> form; they all of them begin with the verb in the first person singular present
> indicative active-not just any kind of verb of course, but still they all are in
> fact of that form. Furthermore, with these verbs that I have used there is a
> typical asymmetry between the use of this person and tense of the verb and
> the use of the same verb in other persons and other tenses, and this asymmetry
> is rather an important clue.

pdftotext via poppler...

> take it all back, and sure enough that's going to come but it will take time.
> First of all let us ask a rather simple question. How can we be sure, how can
> we tell, whether any utterance is to be classed as a performative or not?
> Surely, we feel, we ought to be able to do that. And we should obviously very
> much like to be able to say that there is a grammatical criterion for this,
> some grammatical means of deciding whether an utterance is performative.
> All the examples I have given hitherto do in fact have the same grammatical
> form; they all of them begin with the verb in the first person singular present
> indicative active-not just any kind of verb of course, but still they all are in
> fact of that form. Furthermore, with these verbs that I have used there is a
> typical asymmetry between the use of this person and tense of the verb and
> the use of the same verb in other persons and other tenses, and this asymmetry is rather an important clue.

Versions..

Preview 909.12
Firefox 51.0.1
Adobe Acrobat Pro 10.1.3
Chrome 55.0.2883.95
poppler 0.51.0 For control.pdf and experiment.pdf, I checked that:
* using Acrobat XI, Chrome (pdfium), Firefox (pdf.js):
    * selecting a word will completely highlight that word rather than missing about half of the final character
    * random text that is copied and pasted will preserves word breaks
    * searching for "rela" will select all occurrences of "relativity"
* `pdftotext` produces a reasonable representation of the document contents with no extra spaces

Both files passed.

I then created control_gs.pdf and experiment_gs.pdf using Ghostscript 9.20.

[control_gs.pdf](https://github.com/tesseract-ocr/tesseract/files/769175/_control_gs.pdf)
[experiment_gs.pdf](https://github.com/tesseract-ocr/tesseract/files/769173/_experiment_gs.pdf)

For these two files, control_gs.pdf failed all tests, and experiment_gs.pdf **passed** all tests. The change in the experiment, assigning a width to the .null glyph, is therefore an improvement without any known regressions (yay!). The outputs of pdftotext on experiment.pdf and experiment_gs.pdf is binary identical.

I must have been mistaken on my early remark that there was a search functionality regression on "pdf.js" (by which I meant pdfium). I cannot replicate whatever problem I found with either my test files or experiment_gs.pdf. @amitdo With the way this experiment is set up, finding that pdf.js gives the same result on control and experiment is not a regression. It just means there are more cases of text extraction not working perfectly unrelated to running them through Ghostscript. I confirmed that experiment.pdf, experiment_gs.pdf and control.pdf all have the problem you identified with "making use of the theory". Maybe there's something else we can do.

@RNCTX In this issue we're discussing how *Ghostscript*'s pdfwrite utility seems to utterly ruin spacing in Tesseract-produced PDFs that *previously appeared correctly* in most viewers, rather than the general issue of spacing between characters not working in Tesseract PDFs. The real problem is the PDF spec itself:

>Identifying Word Breaks
>A document’s text stream defines not only the characters in a page’s text but also the words. Unlike a character, the notion of a word is not precisely defined but depends on the purpose for which the text is being processed. [...] applications all have their own ideas of what constitutes a word. I read that with Windows 10 the default pdf reader is the Edge browser. Someone should test it. Checked Win10/Edge. Same thing, control_gs.psf fails and the others are
acceptable. Someone other than me should check things though.


On Sun, Feb 12, 2017 at 02:32 Amit D. <notifications@github.com> wrote:

> I read that with Windows 10 the default reader is the Edge browser.
> Someone should test it.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/712#issuecomment-279209374>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABvcM8nWXMrLQOBIMd6SZiBjotpDRqpqks5rbt-kgaJpZM4L6dNS>
> .
>
 @jbarlow83:  
> In this issue we're discussing how Ghostscript's pdfwrite utility seems to utterly ruin spacing in Tesseract-produced PDFs that previously appeared correctly in most viewers, rather than the general issue of spacing between characters not working in Tesseract PDFs. The real problem is the PDF spec itself:

Yes, I understand the context, perhaps I should have clarified my post a bit better.  In working with the output in other tools, as you say in the OP, "ghostscript is used in many utilities, perhaps without even the knowledge that it is being used by the user." In my case the PDF output of Tesseract is fine, in fact in terms of cleanliness as input for other tools it fares better than any other. But I arrived at this thread after attempting to resize a tesseract output PDF with Imagemagick (which, of course, uses ghostscript).


I am looking at your files in my various tools...

OSX Preview, pdf.js, and poppler output remain un-usable, but I agree that the others are improved.  Interestingly, OSX Preview is different for the two files you posted.  The run-on words are in different places.

Your change leaves us with Chrome and Acrobat working flawlessly, which is a pretty good start.



[Chrome.txt](https://github.com/tesseract-ocr/tesseract/files/769925/Chrome.txt)
[pdftotext.txt](https://github.com/tesseract-ocr/tesseract/files/769926/pdftotext.txt)
[pdf.js.txt](https://github.com/tesseract-ocr/tesseract/files/769927/pdf.js.txt)
[OSX Preview.txt](https://github.com/tesseract-ocr/tesseract/files/769928/OSX.Preview.txt)
[Acrobat X.txt](https://github.com/tesseract-ocr/tesseract/files/769929/Acrobat.X.txt)
 Here ya go..

Also tried iBooks on iOS but predictably the same output as Safari.

Acrobat reader on iOS does not allow text highlighting, but it does not find multi-word searches in either control_gs or experiment_gs, so Acrobat on iOS seems to be using a different renderer than it does on the desktop apps.  Acrobat Pro X on the Mac desktop app does find multi-word searches on experiment_gs, but not control_gs.

The dropbox viewer on iOS is apparently using Chrome's desktop renderer, but Chrome on iOS is using Safari's/Apple's instead of the Chrome desktop pdf renderer going by these results.

Firefox on iOS has very poor touch recognition in pdf files, so all I could do was pick the first word and "select all" which gave me 'some' text from each file but not all text on a page in either control_gs or experiment_gs

This is on an iPad Air2 with iOS 10.x

[Chrome_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/770065/Chrome_iOS.txt)
[Safari_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/770066/Safari_iOS.txt)
[Dropbox_Viewer_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/770067/Dropbox_Viewer_iOS.txt)
[Firefox_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/770099/Firefox_iOS.txt)

 
[DropboxViewer_Control-Experiment_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/771930/DropboxViewer_Control-Experiment_iOS.txt)
[Chrome_Control-Experiment_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/771920/Chrome_Control-Experiment_iOS.txt)
[Safari_Control-Experiment_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/771921/Safari_Control-Experiment_iOS.txt)
[Firefox_Control-Experiment_iOS.txt](https://github.com/tesseract-ocr/tesseract/files/771922/Firefox_Control-Experiment_iOS.txt)

To clarify, these are from the PDF files in this post...

https://github.com/tesseract-ocr/tesseract/issues/712#issuecomment-279013509 Jeff,

Does this new ttf need to be added to both 3.05 and master branches?

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Feb 14, 2017 at 12:07 AM, jbreiden <notifications@github.com> wrote:

> pdf.ttf.zip
> <https://github.com/tesseract-ocr/tesseract/files/772035/pdf.ttf.zip>
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/712#issuecomment-279481123>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o0O3YkyHAe9OMKsC_2n1nr9wovq4ks5rcKL1gaJpZM4L6dNS>
> .
>
 @zdenop added it to the 3.05 branch, and I guess he will add it to 'master' soon...   I got this error while running a test case which involves verifying a toast message using tesseract on intellij3.4. java version 1.8.0_121)

A fatal error has been detected by the Java Runtime Environment:
 SIGSEGV (0xb) at pc=0x00007f10e046333a, pid=4980, tid=0x00007f111d577700
 JRE version: Java(TM) SE Runtime Environment (8.0_121-b13) (build 1.8.0_121-b13)
 Java VM: Java HotSpot(TM) 64-Bit Server VM (25.121-b13 mixed mode linux-amd64 compressed oops)
 Problematic frame:
C  [libtesseract.so.3.0.3+0x22533a]  ERRCODE::error(char const*, TessErrorLogCode, char const*, ...) const+0x16a

 Failed to write core dump. Core dumps have been disabled. To enable core dumping, try "ulimit -c unlimited" before starting Java again

actual_tessdata_num_entries_ <= TESSDATA_NUM_ENTRIES:Error:Assert failed:in file tessdatamanager.cpp, line 53

tried executing "ulimit -c unlimited" still doesn't set it right.
any suggestion will be of great help.
 https://github.com/tesseract-ocr/tesseract/wiki/FAQ#actual_tessdata_num_entries_-tessdata_num_entrieserrorassert-failedin-file-ccutiltessdatamanagercpp-line-55_  when i use tesseract through command line, it works. But when I call it through python(tesserocr), it crashes and said Segmentation fault.
![1](https://cloud.githubusercontent.com/assets/1935079/22725932/50036f4c-ee0b-11e6-93db-6f06af554c65.JPG)
 I compile it myself in Ubuntu 14.04. The version is 3.04  These files will be removed soon with the rest of the legacy ocr engine, unless you'll persuade Ray to keep that engine...  Ray wants to get rid of the legacy OCR engine, so that the final 4.00 version will only have one OCR engine based on LSTM.

From #518:

@stweil commented:
>I strongly vote against removing non-LSTM as we currently still get better results with it in some cases.

@theraysmith commented:
>**Please provide examples of where you get better results with the old engine.**
Right now I'm trying to work on getting rid of redundant code, rather than spending time fighting needless changes that generate a lot of work. I have recently tested an LSTM-based OSD, and it works a lot better than the old, so that is one more use of the old classifier that can go. AFAICT, apart from the equation detector, the old classifier is now redundant.


 Is the intention that the legacy OCR engine will be available in 3.0x branch and LSTM engine in the 4.0 version? I support @theraysmith  removing the legacy OCR engine as we are getting better results in LSTM-based,
however we have to increase support to multilanguage and need many fixes to 4.0 final.. My personal opinion is that we should drop the old engine. It will be much easier to maintain and support Tesseract in this form. I also support dropping the OpenCL code. I also think we should release a last 3.0x version in the upcoming 2-6 weeks. I cannot agree with removing old ocr engine, until new lstm engine has support vertical text.

Of course I know that the new LSTM engine is very good ( in Japanese text including English words especially).
In the meantime, maintaining the old engine provides the option of using the old OCR engine only for vertical text.

c.f. #627 , #641 
 :+1:  for a side-by-side 3.05 and 4.00.

A possible way to achieve this goal:
For 3.05 you can append `3` to libtesseract and all the installed programs.
The traineddata will live in `.../share/tessdata3`.
  I agree with zdenop

tessdata should be used for the 3.0x series, so as to not break any
existing use

New naming can be used for LSTM 4.0

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Thu, Feb 9, 2017 at 12:04 AM, Egor Pugin <notifications@github.com>
wrote:

> Yes, if later we'll have 5.0 with different data files, they'll use
> tesseract5 and this won't break anything.
> If we have tesseract for 4.0, then it will be renamed to tesseract4
> again, and tesseract for 5.0 - that's not good.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/707#issuecomment-278419744>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_ozcExn8t5DzsPgjUAqnju9_CZk3Mks5ragqdgaJpZM4L50TV>
> .
>
 @jbreiden Good idea to do a code update for 3.05 for Ubuntu 17.04. There are a number of bug fixes and changes and it would be good to get them out to the users. Thanks! **@theraysmith:**  Here I try to provide examples of where you get better results with the old engine.

I did a lot of LSTM training with OCRopus on real images of historical printings and noticed that LSTM recognition was inferior to classic Tesseract in these cases:

1. glyphs rarely seen in training (capital letters, numbers, certain punctuations)
2. unusual patterns (letter-spacing, e.g. R U N N I N G   H E A D)
3. very short lines (catchword at page end, page numbers)

My explanation is, that single letters get decoded using the combined evidence of the whole line. If this is either rare and unusual (1, 2) or mostly absent (3), decoding is uncertain, no matter how clearly single glyphs are printed and preserved (and therefore easily recognized by methods based on feature detection).

So I tried both the old (OEM = 0) and new (OEM = 1) recognizer on these 10 lines (the last line is a regular text line for comparison from a 1543 printing, where a trained model yields 99.5% accuracy for the book):

![1 bin](https://cloud.githubusercontent.com/assets/8000185/22987900/93a411d4-f3b0-11e6-8b97-d05aadb0cf9a.png)
![2 bin](https://cloud.githubusercontent.com/assets/8000185/22987911/9a96c608-f3b0-11e6-85e4-113e044b06b0.png)
![3 bin](https://cloud.githubusercontent.com/assets/8000185/22987915/9b0a45d8-f3b0-11e6-8213-113e52cdd601.png)
![4 bin](https://cloud.githubusercontent.com/assets/8000185/22987912/9ab1c9a8-f3b0-11e6-9957-d84b508a8e91.png)
![5 bin](https://cloud.githubusercontent.com/assets/8000185/22987905/9a6edb02-f3b0-11e6-8085-0cce28d7b45b.png)
![6 bin](https://cloud.githubusercontent.com/assets/8000185/22987906/9a717876-f3b0-11e6-967b-70db67068f74.png)
![7 bin](https://cloud.githubusercontent.com/assets/8000185/22987907/9a727c94-f3b0-11e6-9d47-375e4ffdbc4a.png)
![8 bin](https://cloud.githubusercontent.com/assets/8000185/22987908/9a829a66-f3b0-11e6-8c48-5ad95f4a1ecf.png)
![9 bin](https://cloud.githubusercontent.com/assets/8000185/22987909/9a9314fe-f3b0-11e6-9197-bc038eeec3b5.png)
![10 bin](https://cloud.githubusercontent.com/assets/8000185/22987910/9a95f160-f3b0-11e6-8da5-d9737d8d7dd4.png)

**Old method: tesseract -l lat --oem 0 --psm 7:**

17:
V.
SECVNDAE
B 3
LIBER
AD
Lxxxvxn.
zo PROGYMNASMATA
IN GENEROSVM ADOLESCEN-
caﬁris millia paITuum circitér fcptem.Rc_x cum hoc itincrc szaré ucnirc

**New method: tesseract -l lat --oem 1 --psm 7:**

177:
V,.
SECV NDAHE
B- 5
LI B E D.
A D
Lx x XV II IL.
209 P R o cy M N ^ s M A T 4
IN GE NE R O SVM A D O L E S CE N-
caüris millia paiTuum circiter fcptcm.Rc-x cum hoc itinere Cæfarö uenit:

Admittedly, although this is all Latin text, the recognition looks much better without any language model (**tesseract --oem 1 --psm 7**):

17;
V.
SECV NDA E
B ;
LIB E R
A D
Lx X xv III.
40 PR 0 GY MN A S M A T a
IN GENEROSVM ADOLESCEN.
caftris millia pafluum circiter feptem. Rex cum hocitinere Cafaré uenire

But it still is less consistent than the old method in treating spacings. The last line shows the potential that may be reached when training on real images becomes available (long ſ, proper inter-word spacing model, historical glyphs).

**So I vote for keeping the old code just for these edge cases which are otherwise hard to recognize at the same level of consistency.** >Admittedly, although this is all Latin text, the recognition looks much better **without any language model**

Without explicit `-l LANG`, Tesseract will use the eng traineddata, so

>tesseract --oem 1 --psm 7

is equivalent to:
>tesseract -l eng --oem 1 --psm 7 @theraysmith commented in commit b453f74e01

>There is always going to be a significant speed penalty for multi-lang mode.
The multi-lang mode could still do with more work to run it at a lower level, (inside RecognizeLine) but the legacy engine could do to go before that, or multi-lang could get really unnecessarily complex.
 I think that there is reason to keeping the old ocr engine while LSTM engine is not ideal. 
This will allow use two engine simultaneously. 
For example ABBYY [uses several ocr methods](https://abbyy.technology/en:features:ocr:classifier) in his OCR engine: Bayesian classifier with about 100 features, raster classifier, contour classifier, structure classifier and then differentiating classifiers. The problem is that the code for the old engine is too large and complex. As Ray indicated, keeping it will make improving the new LSTM engine much harder. https://github.com/tesseract-ocr/tesseract/issues/733 

single letters recognized better with legacy From #744
theraysmith commented:

>... yes I would still like to remove the old classifier and take out a lot of code with it.
I'm going to review the replies to my request for "old better than new", and thanks to those that provided them, with a view to making new better than old on those problems. From 518
theraysmith commented:
> Please provide examples of where you get better results with the old engine.

@stweil commented 29 days ago:
>I'll do that in the discussion of the new issue #707.

Stefan, we are still waiting for it ...  :-) As you know, unlike almost all the other files in the tessdata repo, the '_frak' traineddata files are not based on Google manpower (& machine-power) efforts. 
https://github.com/tesseract-ocr/tesseract/wiki/Data-Files#fraktur-data-files

Maybe you and and your friends from @UB-Mannheim can prepare a new  deu_frak traineddata for Tesseract 4.00 and share it under open source license (preferably Apache 2 or other permissive software license) ? https://github.com/tesseract-ocr/tesseract/issues/681#issuecomment-275801448
Just a reminder for Ray.  From tesseract-ocr/langdata issue 59

theraysmith commented

>I'm also going to fix the single char/single word issue that was raised as
an objection to deleting the legacy engine.
 There are community training projects for MICR and SSD but these are not included in upcoming training by Ray.  Just documenting differences between 3.0x and 4.0 ... listed as issues in langdata:

https://github.com/tesseract-ocr/langdata/issues/65

https://github.com/tesseract-ocr/langdata/issues/64

 Based on my testing, I agree with @stweil - `adding (good) LSTM support for a language is much more difficult than for the old engine. `

Most recently I tried creating traineddata for Armenian based on a request in the forum - see https://github.com/tesseract-ocr/langdata/issues/67

While with my limited fonts and training text, I was able to get a legacy version of traineddata within a few hours which had reasonable accuracy, with the same inputs and 3-4 days of processing, the lstm version of traineddata did not better the accuracy, took more time while OCRing the same file. Of course, my test sample is very limited.

On the other hand, the accuracy and speed of complex scripts such as Devanagari has improved with the LSTM traineddata (though I haven't been able to add a top layer or fine tune those because of unicharset limitations).

I hope the new codebase and traineddata will address these issues. Thanks! As discussed in issue #1074, currently only the old recognizer is able to detect text attributes like font size, bold, italic.  https://github.com/blog/2309-introducing-topics Suggested topics:
* [ocr](https://github.com/search?q=topic%3Aocr)
* [lstm](https://github.com/search?q=topic%3Alstm)
* [machine-learning](https://github.com/search?q=topic%3Amachine-learning)
* [tesseract-ocr](https://github.com/search?q=topic%3Atesseract-ocr)
* [tesseract](https://github.com/search?q=topic%3Atesseract) @zdenop, only Ray can do it? Thanks, Zdenko! Why does it add 'org:tesseract-ocr' to the our topics? Click on a topic and you'll see what I'm talking about. I found out that it adds 'org' to any topic in any organization.

That's yet another case of bad UX in GitHub IMO. >I found out that it adds 'org' to any topic in any organization.

They fixed the issue.  Im want to build opencv text + tessract ocr. but i can't find how to get include and lib folder.
I find some old  build in source forge page but only 3.02 version but i want 4.0 or 3.05
https://sourceforge.net/projects/tesseract-ocr-alt/files/?source=navbar
some one can tell me where is include + lib folder or how to build it from source .
Sorry for posting in here but i did many search but haven't any result
Big thank! sorry for my bad english Thank you very much!
So simple and easy guide. Im' very happy. Thanks !  I found a mention of this in another post from a prior version. I managed to produce the below with -l eng and --oem 1.


https://github.com/tesseract-ocr/tesseract/issues/337

> tesseract -v
> tesseract 4.00.00alpha
>  leptonica-1.74.1
>   libjpeg 8d : libpng 1.6.28 : libtiff 4.0.7 : zlib 1.2.8
> 
>  OpenCL info:
>   Found 1 platform(s).
>   Platform 1 name: Apple.
>   Version: OpenCL 1.2 (Jan  4 2017 22:35:59).
>   Found 2 device(s).
>     Device 1 name: Intel(R) Core(TM) i7-5557U CPU @ 3.10GHz.
>     Device 2 name: Intel(R) Iris(TM) Graphics 6100.
>  Found AVX
>  Found SSE

> Gilbert. Certainly. Anybody can write a three-volumed novel.* It merely requires a complete ignorance of both life and literature. The difficulty that I should fancy the reviewer feels is the difficulty of sustaining any standard. Where there is no style a standard must be impossible. The poor reviewers are apparently reduced to be the reporters of the police court of literature, the chroniclers of the doings of the habitual criminals of art. It is sometimes said of them that they do not read all through the works they are called upon to criticise. They do not. Or at least they should not. If they did so, they would become confirmed misanthropes; or, ifI may borrow a phrase from one of the pretty N e w n h a m graduates, confirmed womanthropes' for the rest of their lives. Nor is it necessary. To know the vintage and quality of a wine one need not drink the whole cask. It must be perfectly easy in half an h o u r t o s a y w h e t h e r a b o o k is w o r t h a n y t h i n g o r w o r t h n o t h i n g . T e n m i n u t e s are really sufficient, if one has the instinct for form. W h o wants to wade t h r o u g h a d u l l v o l u m e ? O n e t a s t e s it, a n d t h a t is q u i t e e n o u g h - m o r e t h a n enough, Ishould imagine. Iam aware that there are many honest workers in painting as well as in literature w h o object to criticism entirely. T h e y are quite right. Their work stands in no intellectual relation to their age. Itbrings u s n o n e w e l e m e n t o f p l e a s u r e . It s u g g e s t s n o f r e s h d e p a r t u r e o f t h o u g h t , o r passion, or beauty. It should not be spoken of. It should be left to the oblivion that it deserves.

<img width="457" alt="screen shot 2017-02-04 at 1 39 41 am" src="https://cloud.githubusercontent.com/assets/13775820/22616815/e81e9bd8-ea7a-11e6-95dc-e1e983905d41.png">

However, the same text copied/pasted from the same file opened in Adobe Acrobat Pro 10 is  (almost) flawless...

> Gilbert. Certainly. Anybody can write a three-volumed novel.* It merely
> requires a complete ignorance of both life and literature. The difficulty that
> I should fancy the reviewer feels is the difficulty of sustaining any standard.
> Where there is no style a standard must be impossible. The poor reviewers
> are apparently reduced to be the reporters of the police court of literature,
> the chroniclers of the doings of the habitual criminals of art. It is sometimes
> said of them that they do not read all through the works they are called upon
> to criticise. They do not. Or at least they should not. If they did so, they
> would become confirmed misanthropes; or, if I may borrow a phrase from
> one of the pretty Newnham graduates, confirmed womanthropes' for the
> rest of their lives. Nor is it necessary. To know the vintage and quality of a
> wine one need not drink the whole cask. It must be perfectly easy in half an
> hour to say whether a book is worth anything or worth nothing. Ten minutes
> are really sufficient, if one has the instinct for form. Who wants to wade
> through a dull volume? One tastes it, and that is quite enough-more than
> enough, I should imagine. I am aware that there are many honest workers
> in painting as well as in literature who object to criticism entirely. They are
> quite right. Their work stands in no intellectual relation to their age. It brings
> us no new element of pleasure. It suggests no fresh departure of thought, or
> passion, or beauty. It should not be spoken of. It should be left to the oblivion
> that it deserves. Seems to be working fine in my case 

```
 tesseract -v
tesseract 4.00.00alpha
 leptonica-1.74.1
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 Found AVX
 Found SSE

 tesseract testeng.png testeng --oem 1 -l eng

Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
```
Here is the output

```
Gilbert. Certainly. Anybody can write a three-volumed novel." It merely
requires a complete ignorance of both life and literature. The difficulty that
I should fancy the reviewer feels is the difficulty of sustaining any standard.
Where there is no style a standard must be impossible. The poor reviewers
are apparently reduced to be the reporters of the police court of literature,
the chroniclers of the doings of the habitual criminals of art. It is sometimes
said of them that they do not read all through the works they are called upon
to criticise. They do not. Or at least they should not. If they did so, they
would become confirmed misanthropes; or, if I may borrow a phrase from
one of the pretty Newnham graduates, confirmed womanthropes' for the
rest of their lives. Nor is it necessary. To know the vintage and quality of a
wine one need not drink the whole cask. It must be perfectly easy in half an
hour to say whether a book is worth anything or worth nothing. Ten minutes
are really sufficient, if one has the instinct for form. Who wants to wade
through a dull volume? One tastes it, and that is quite enough-more than
enough, I should imagine. I am aware that there are many honest workers
in painting as well as in literature who object to criticism entirely. They are
quite right. Their work stands in no intellectual relation to their age. It brings
us no new element of pleasure. It suggests no fresh departure of thought, or
passion, or beauty. It should not be spoken of. It should be left to the oblivion
that it deserves.
```
 could be related to OpenCL I rebuilt HEAD without OpenCL and got the same result.  I would suppose this has to be something screwy with OSX preview, since it doesn't appear to happen in Adobe Acrobat (or Chrome, which I also opened it in just now).  

Here's the complete page...

[The946.png.pdf](https://github.com/tesseract-ocr/tesseract/files/752364/The946.png.pdf)
  ```
 lstmtraining -U ~/tesstutorial/khm/khm.unicharset \
  --script_dir ../langdata  --debug_interval 0  \
 --continue_from ~/tesstutorial/khmlayer1_from_khm/khm.lstm  \
 --append_index 3 --net_spec '[Lbx256 O1c105]'  \
 --model_output ~/tesstutorial/khmlayer1_from_khm/khm 
  --train_listfile ~/tesstutorial/khm/khm.training_files.txt \
  --target_error_rate 0.01

Loaded file /home/shree/tesstutorial/khmlayer1_from_khm/khm.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from /home/shree/tesstutorial/khmlayer1_from_khm/khm.lstm
Appending a new network to an old one!!Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Setting properties for script Khmer
Warning: given outputs 105 not equal to unicharset of 155.
Num outputs,weights in serial:
  Lbx256:512, 657408
  Fc155:155, 79515
Total weights = 736923
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lbx256Fc155] from request [Lbx256 O1c105]
Training parameters:
  Debug interval = 0, weights = 0.1, learning rate = 0.0001, momentum=0.9
Loaded 538/538 pages (1-538) of document /home/shree/tesstutorial/khm/khm.Leelawadee_UI_Bold.exp0.lstmf
Loaded 392/392 pages (1-392) of document /home/shree/tesstutorial/khm/khm.Noto_Sans_Khmer_UI_Bold.exp0.lstmf
Loaded 497/497 pages (1-497) of document /home/shree/tesstutorial/khm/khm.Noto_Serif_Khmer.exp0.lstmf
Loaded 396/396 pages (1-396) of document /home/shree/tesstutorial/khm/khm.Noto_Sans_Khmer_Bold.exp0.lstmf
Loaded 535/535 pages (1-535) of document /home/shree/tesstutorial/khm/khm.Leelawadee_UI.exp0.lstmf
Loaded 389/389 pages (1-389) of document /home/shree/tesstutorial/khm/khm.Noto_Sans_Khmer.exp0.lstmf
Loaded 402/402 pages (1-402) of document /home/shree/tesstutorial/khm/khm.Noto_Sans_Khmer_UI.exp0.lstmf
Loaded 491/491 pages (1-491) of document /home/shree/tesstutorial/khm/khm.Noto_Serif_Khmer_Bold.exp0.lstmf
At iteration 100/100/100, Mean rms=5.299%, delta=54.358%, char train=110.625%, word train=100%, skip ratio=0%,  New worst char error = 110.625 failed to write checkpoint.


2 Percent improvement time=1299, best error was 100 @ 0
At iteration 1299/1300/1301, Mean rms=4.903%, delta=47.404%, char train=98.596%, word train=99.748%, skip ratio=0.1%,  New best char error = 98.596 failed to write checkpoint.

``` ```
2 Percent improvement time=1090, best error was 20.094 @ 6275
At iteration 7365/7400/7408, Mean rms=1.661%, delta=5.067%, char train=18.026%, word train=64.079%, skip ratio=0%,  New best char error = 18.026 failed to write best m
odel:/home/shree/tesstutorial/khmlayer1_from_khm/khm18.026_7365.lstm failed to write checkpoint.

```

For some reason /home/shree/tesstutorial/khmlayer1_from_khm/ did not have appropriate write priviledge causing the error.
 Hello @Shreeshrii 

Do you know how to set learning rate by hand??  ![test1](https://cloud.githubusercontent.com/assets/23392731/22503425/a5baa5fe-e8ac-11e6-9d5e-36db771b3654.png)

When i use command "tesseract test.png out", the result is "01234567Beabcdelghijklmnopqrstuvwxyz". 
It has 4 wrong text.
But when i use command "tesseract test.png out pdf", the result is perfect correct.
Does someone know how to also make the result is correct when output is txt? Are you just looking at the PDF or the text in it?

The difference could be based on the default page segmentation mode used by
each method.

- excuse the brevity, sent from mobile

On 01-Feb-2017 4:02 PM, "shareworlds" <notifications@github.com> wrote:

> [image: test1]
> <https://cloud.githubusercontent.com/assets/23392731/22503425/a5baa5fe-e8ac-11e6-9d5e-36db771b3654.png>
>
> when i use command "tesseract test.png out", the result is "
> 01234567Beabcdelghijklmnopqrstuvwxyz".
> It has 4 wrong text.
> But when i use command "tesseract test.png out pdf", the result is perfect
> correct.
> Does someone know how to also make the result is correct when output is
> txt?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/694>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o49ErZw5BEJZxmIW0D8f00K19bo2ks5rYF8qgaJpZM4LztKt>
> .
>
 No feedback from the OP, so I suggest to close this issue.  I want to build Tesseract using visual studio 2013.
I have followed all the steps as mentioned in https://vorba.ch/2014/tesseract-3.03-vs2013.html which is the site mentioned in the compiling section.
Everything went well but in the last step while building the solution I got a link error which is cannot read liblept171.lib and cannot include "allfrex.h".
I am new to this and haven't figured out any solution yet.
Is this the right way or please guide if any other way is possible to build tesseract in visual studio 2013

Thank you.

These are the steps mentioned in that link:

 
17 [Previously](tesseract-cygwin.html) I wrote about how to compile Tesseract OCR 
18 using Cygwin. While this is nice if you want to compile Tesseract for your own 
19 system where you can install Cygwin on your own, compiling with Visual Studio is 
20 better if you intend to distribute the compiled package so users don't have to 
21 install Cygwin. 
22 
 
23 Compiling Tesseract 3.02.02 with Visual C++ 2008 (Express) is [covered by the 
24 documentation](http://tesseract-ocr.googlecode.com/svn/trunk/vs2008/doc/setup.html) 
25 whereas compiling Tesseract 3.03 isn't covered at all, though. 
26 
 
27 Unfortunately newer versions of Tesseract also require a new version of 
28 [Leptonica](http://www.leptonica.org/), a C library for image processing and 
29 image analysis applications, which in turn requires new versions of zlib, 
30 libpng, libtiff, libjpeg and giflib. Tesseract provides pre-compiled versions of 
31 Leptonica, which prevents you from having to collect and set up projects for all 
32 of these libraries in Visual Studio, which can be a tedious task. 
33 
 
34 Yesterday I found a project on GitHub that includes a Visual Studio solution 
35 file for all dependencies required to compile Tesseract 3.03: 
36 [charlesw/tesseract-vs2012](https://github.com/charlesw/tesseract-vs2012). While 
37 following the build instructions there, I stumpled over several build errors, 
38 which I could easily resolve by removing a definition. The necessary change is 
39 in [my fork](https://github.com/pvorb/tesseract-vs2013) of the repository 
40 mentioned above. 
41 
 
42 This is a write-up of all steps that are required to compile Tesseract 3.03 with 
43 Visual Studio 2013. 
44 
 
45 ## Prerequisites 
46 
 
47  1. Install [Git](http://git-scm.com/). 
48  2. Install SVN. There are many versions of SVN. You can, for example, install 
49     the binary package from [SlickSVN](http://www.sliksvn.com/en/download) for 
50     free. 
51  3. Install [Visual Studio 2013 for Windows Desktop](http://www.visualstudio.com/downloads/download-visual-studio-vs) 
52     (the Express version will be enough). You don't need the optional features 
53     except for "Microsoft Foundation Classes for C++". 
54 
 
55 ## Building the dependencies 
56 
 
57  1. Create a directory where you want to compile Tesseract. In this document, 
58     I'll assume it's `C:\Tesseract-Build\`. 
59  2. Open a CMD prompt and change to that directory. 
60 
 
61     ~~~ 
62     cd \Tesseract-Build\ 
63     ~~~ 
64  3. Clone the dependencies repository from GitHub. 
65 
 
66     ~~~ 
67     git clone git://github.com/pvorb/tesseract-vs2013.git 
68     ~~~ 
69  4. Open the "VS 2013 Developer Command Prompt". (It can be found in the Start 
70     Menu.) 
71  5. Change to the newly cloned repository. 
72 
 
73     ~~~ 
74     cd \Tesseract-Build\tesseract-vs2013 
75     ~~~ 
76  6. Build the dependencies 
77 
 
78     ~~~ 
79     msbuild build.proj 
80     ~~~ 
81  7. You can close the "VS 2013 Developer Command Prompt". 
82 
 
83 ## Building Tesseract 
84 
 
85  1. Re-open the first command prompt and ensure it's still in 
86     `C:\Tesseract-Build\`. 
87  2. Get the latest source from SVN. 
88 
 
89     ~~~ 
90     svn checkout http://tesseract-ocr.googlecode.com/svn/trunk/ tesseract-ocr 
91     ~~~ 
92  3. Change to the newly checked-out repository. 
93 
 
94     ~~~ 
95     cd tesseract-ocr 
96     ~~~ 
97  4. Apply the patch provided in `tesseract-vs2013`. 
98 
 
99     ~~~ 
100     svn patch ..\tesseract-vs2013\vs2013+64bit_support.patch 
101     ~~~ 
102  5. Copy both directories in `C:\Tesseract-Build\tesseract-vs2013\release\` to 
103     `C:\Tesseract-Build\`. Now you should have 
104 
 
105       - `C:\Tesseract-Build\include\` 
106       - `C:\Tesseract-Build\lib\` 
107  6. Open `C:\Tesseract-Build\tesseract-ocr\vs2013\tesseract.sln` with Visual 
108     Studio 2013. 
109  7. Press `F7` on your keyboard. Both `libtesseract303` and `tesseract` should 
110     compile without errors. 

 see https://github.com/tesseract-ocr/tesseract/wiki/Compiling

section under windows re building with cppan

@egorpugin  will it work with vs2013? Thanks!

It would be helpful to users if you update the wiki regarding cppan
compilation of tesseract. Right now it seems to me that it is for training
tools since that comes on top.

Many users compile tesseract not for development or training but just to
get the latest version of the software.

I don't have Visual studio so I haven't tried it.

- excuse the brevity, sent from mobile

On 07-Feb-2017 12:23 PM, "Egor Pugin" <notifications@github.com> wrote:

> Not tested, but in general should be ok.
> I remember some issues with libtiff dependency, but I fixed something, so
> 100% not sure.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/693#issuecomment-277916595>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o6iSxuA8jeGbYJKSYyeMuRAQiik9ks5raBTXgaJpZM4LzeyP>
> .
>
 Thank you very much!
I followed all the steps as mentioned and I was able to build the solution successfully without any errors.
Now I added a new cpp file with the code given in api example.But I did not get any ouput .I also tried writing the output to a txt file but in vain.
Can  you please help me how to get the txt,hocr,pdf output file after building the solution.
I am currently trying it in visual studio 2013  as well as 2015 version.
Regards.

API example:
#include <tesseract/baseapi.h>
#include <leptonica/allheaders.h>

int main()
{
    char *outText;

    tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();
    // Initialize tesseract-ocr with English, without specifying tessdata path
    if (api->Init(NULL, "eng")) {
        fprintf(stderr, "Could not initialize tesseract.\n");
        exit(1);
    }

    // Open input image with leptonica library
    Pix *image = pixRead("/usr/src/tesseract/testing/phototest.tif");
    api->SetImage(image);
    // Get OCR result
    outText = api->GetUTF8Text();
    printf("OCR output:\n%s", outText);

    // Destroy used object and release memory
    api->End();
    delete [] outText;
    pixDestroy(&image);

    return 0;
} Thank You,It is working.

I  would like you guys to provide videos on step by step process of building tesseract on various platforms which would really guide us especially the beginners and save many hours of searching in the net. I want to build Tesseract with vs2013. I have followed all steps of this tutorial:
https://vorba.ch/2014/tesseract-3.03-vs2013.html
but in the last step, I got this error:
can not find include file: 'version.h' 
what should I do?
Thanks try with cppan and directions given in
https://github.com/tesseract-ocr/tesseract/wiki/Compiling

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sat, Mar 11, 2017 at 1:56 PM, hanikh <notifications@github.com> wrote:

> I want to build Tesseract with vs2013. I have followed all steps of this
> tutorial:
> https://vorba.ch/2014/tesseract-3.03-vs2013.html
> but in the last step, I got this error:
> can not find include file: 'version.h'
> what should I do?
> Thanks
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/693#issuecomment-285852507>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o9sRC55lnexaMDQKMzbtieWDbAvwks5rklq5gaJpZM4LzeyP>
> .
>
  Trying to run "tesseract filename.jp2 out -l deu_frak" results:

Tesseract Open Source OCR Engine v3.04.01 with Leptonica
Warning in fgetJp2kResolution: image resolution not found

There is a fix to this somewhere, but could not find it:

https://www.mail-archive.com/debian-bugs-dist@lists.debian.org/msg1373390.html tesseract -v
will show what libs leptonica has with it. It might not have jp2 support.

 tesseract -v

tesseract 4.00.00alpha
 leptonica-1.74.1
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib
1.2.8

 Found AVX
 Found SSE


ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Feb 1, 2017 at 6:35 AM, Asko Nivala <notifications@github.com>
wrote:

> Trying to run "tesseract filename.jp2 out -l deu_frak" results:
>
> Tesseract Open Source OCR Engine v3.04.01 with Leptonica
> Warning in fgetJp2kResolution: image resolution not found
>
> There is a fix to this somewhere, but could not find it:
>
> https://www.mail-archive.com/debian-bugs-dist@lists.debian.
> org/msg1373390.html
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/692>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_owQIcQpMJZUxe4vDRMZKS54Nq90Pks5rX9pUgaJpZM4LzX_O>
> .
>
 I am so sorry for the incomplete report and not testing this issue properly. Running "tesseract filename.jp2 out -l deu_frak" resulted to the above given error message and an empty out.txt file or freezing of app, so I automatically (but little bit stupidly) assumed that the OCR scanning is not working. After you reply, I tested it with lots of other jp2 files, and it in fact works despite of the warning. The jp2 files that I was using were simply somehow corrupted, it is my mistake, which I apologise!

By the way, I encountered problems also with multipaged TIFFs, tesseract now outputting empty txt files. But I am probably doing something wrong here as well and it's not a bug. I am using Ubuntu 16.04.1 LTS Server without any graphics system and installed tesseract with "apt-get install".

Just in case, the report of "tesseract -v":
```
tesseract 3.04.01
 leptonica-1.73
  libgif 5.1.2 : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.2.54 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.4 : libopenjp2 2.1.0
```  ```
lstmtraining -U  /mnt/c/Users/User/shree/jtess/samples/vie/vie.unicharset  
 --script_dir /mnt/c/Usrs/User/shree/langdata  --debug_interval -1 
  --continue_from  /mnt/c/Users/User/shree/jtess/samples/vie/vie.lstm  
 --append_index 5 --net_spec '[Lfx256 O1c105]'   
--model_output  /mnt/c/Users/User/shree/jtess/samples/vie/vielayer  
 --train_listfile  /mnt/c/Users/User/shree/jtess/samples/vie/vie.training_files.txt  
 --target_error_rate 0.01

  Loaded file /mnt/c/Users/User/shree/jtess/samples/vie/vie.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!
Continuing from /mnt/c/Users/User/shree/jtess/samples/vie/vie.lstm
Appending a new network to an old one!!Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Warning: given outputs 105 not equal to unicharset of 227.
Num outputs,weights in serial:
  Lfx256:256, 394240
  Fc227:227, 58339
Total weights = 452579
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc227] from request [Lfx256 O1c105]
Training parameters:
  Debug interval = -1, weights = 0.1, learning rate = 0.0001, momentum=0.9
Deserialize header failed: /mnt/c/Users/User/shree/jtess/samples/vie/vie.FreeSerif.exp0.lstmf
Load of page 0 failed!
Load of images failed!!
``` note: lstmf files created using windows binaries https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#error-messages-from-training

>Deserialize header failed occurs when a training input is not in LSTM format or the file is not readable. Check your filelist file to see if it contains valid filenames. It's a moving target, and it's not guaranteed to read files generated by a previous alpha snapshot.  Back in 2015, I used some tools I found that came with tesseract that performed post-processing to correct ocr errors (i.e. they accepted text in and returned it out). I used them for my dissertation work in text error correction. Now it looks like tesseract has been refactored and they're gone. Regrettably I don't remember what the executables were called. Is there any way to get that old version of tesseract, or is there a way to use the new tesseract for OCR postprocessing instead of OCR directly?  @stweil @egorpugin  

It would be great if you can provide for download windows binaries with the latest 4.0.0 alpha code,  including the new training programs 
Lstmtraining
And
Lstmeval 

Thank you. + tesseract-ocr google group

Thank you both so much for your prompt response in providing the windows
binaries.

I have added links to both at
https://github.com/tesseract-ocr/tesseract/wiki/4.0-with-LSTM#400-alpha-for-windows

Unofficial experimental binaries of tesseract-ocr 4.0.0-alpha (Jan 30,
2017) are available from the following links:

   - Windows Installer made with MinGW-w64
   <http://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-4.00.00dev.exe>
   from UB Mannheim <https://github.com/UB-Mannheim/tesseract/wiki>
   - zip file with cppan generated .dll and .exe files
   <https://www.dropbox.com/s/obiqvrt4m53pmoz/tesseract-4.0.0-alpha.zip?dl=1>,
   You have to install VC2015 x86 redist from microsoft.com in order to run
   them.

Please correct the description if it is not correct.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Jan 31, 2017 at 2:26 AM, Stefan Weil <notifications@github.com>
wrote:

> There is also a new installer in our wiki
> <https://github.com/UB-Mannheim/tesseract/wiki>.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/689#issuecomment-276187794>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_ozpbP4CXsf2YPsViZexCGLQwHwEDks5rXk6BgaJpZM4Lxkq2>
> .
>
 @stweil Thanks. I have downloaded the new version and will give it a try.

Wondering though how  it is related to win32, since I am running under windows 10, with wit 64bit os and x-64 based processor. 

![sysinfo](https://cloud.githubusercontent.com/assets/5095331/22583959/cf6cf428-ea15-11e6-8d88-dc4f92a59acc.png) Thanks for clarifying.

Have you/others at UB Mannheim tried LSTM training with the windows binaries?

In my earlier test, I found that lstmtraining was not reading .lstmf files created on windows. I will have to test the exact same case under bash and windows to confirm it.  I am wondering if it could be related to Unix vs DOS/Windows EOL differences.

Is there a way to compare the .lstmf files (binary files)?  Hi,

I have put my effort by making changes to necessary project files. I have used the solution file present at the following location:

https://github.com/peirick/VS2015_Tesseract/

Unfortunately, that is based on Tesseract - 3.05. I took the latest 4.0 version of source code to build in visual studio. I'm getting following linker errors only for the newly introduced code part in 4.0 i.e., lstm and simddetect:

Severity	Code	Description	Project	File	Line	Suppression State
Error	LNK1120	8 unresolved externals	tesseract	D:\tesseract\VS2015_Tesseract\x64\Debug\tesseract.exe	1
Error	LNK2001	unresolved external symbol "private: static bool SIMDDetect::avx_available_" (?avx_available_@SIMDDetect@@0_NA)	tesseract	D:\tesseract\VS2015_Tesseract\tesseract\tesseractmain.obj 1
Error	LNK2001	unresolved external symbol "private: static bool SIMDDetect::sse_available_" (?sse_available_@SIMDDetect@@0_NA)	tesseract	D:\tesseract\VS2015_Tesseract\tesseract\tesseractmain.obj 1
Error	LNK2019	unresolved external symbol "public: void __cdecl tesseract::Tesseract::TrainLineRecognizer(class STRING const &,class STRING const &,class BLOCK_LIST *)" (?TrainLineRecognizer@Tesseract@tesseract@@QEAAXAEBVSTRING@@0PEAVBLOCK_LIST@@@Z) referenced in function "public: int __cdecl tesseract::TessBaseAPI::Recognize(class ETEXT_DESC *)" (?Recognize@TessBaseAPI@tesseract@@QEAAHPEAVETEXT_DESC@@@Z)	tesseract D:\tesseract\VS2015_Tesseract\tesseract\baseapi.obj	1
Error	LNK2019	unresolved external symbol "public: void __cdecl tesseract::Tesseract::LSTMRecognizeWord(class BLOCK const &,class ROW *,class WERD_RES *,class tesseract::PointerVector *)" (?LSTMRecognizeWord@Tesseract@tesseract@@QEAAXAEBVBLOCK@@PEAVROW@@PEAVWERD_RES@@PEAV?$PointerVector@VWERD_RES@@@2@@Z) referenced in function "public: void __cdecl tesseract::Tesseract::classify_word_pass1(struct tesseract::WordData const &,class WERD_RES * *,class tesseract::PointerVector *)" (?classify_word_pass1@Tesseract@tesseract@@QEAAXAEBUWordData@2@PEAPEAVWERD_RES@@PEAV?$PointerVector@VWERD_RES@@@2@@Z)	tesseract	D:\tesseract\VS2015_Tesseract\tesseract\control.obj	1
Error	LNK2019	unresolved external symbol "public: __cdecl tesseract::LSTMRecognizer::LSTMRecognizer(void)" (??0LSTMRecognizer@tesseract@@QEAA@XZ) referenced in function "public: bool __cdecl tesseract::Tesseract::init_tesseract_lang_data(char const *,char const *,char const *,enum tesseract::OcrEngineMode,char * *,int,class GenericVector const *,class GenericVector const *,bool)" (?init_tesseract_lang_data@Tesseract@tesseract@@QEAA_NPEBD00W4OcrEngineMode@2@PEAPEADHPEBV?$GenericVector@VSTRING@@@@3_N@Z)	tesseract	D:\tesseract\VS2015_Tesseract\tesseract\tessedit.obj 1
Error	LNK2019	unresolved external symbol "public: bool __cdecl tesseract::LSTMRecognizer::DeSerialize(bool,class tesseract::TFile *)" (?DeSerialize@LSTMRecognizer@tesseract@@QEAA_N_NPEAVTFile@2@@Z) referenced in function "public: bool __cdecl tesseract::Tesseract::init_tesseract_lang_data(char const *,char const *,char const *,enum tesseract::OcrEngineMode,char * *,int,class GenericVector const *,class GenericVector const *,bool)" (?init_tesseract_lang_data@Tesseract@tesseract@@QEAA_NPEBD00W4OcrEngineMode@2@PEAPEADHPEBV?$GenericVector@VSTRING@@@@3_N@Z)	tesseract	D:\tesseract\VS2015_Tesseract\tesseract\tessedit.obj 1
Error	LNK2019	unresolved external symbol "public: bool __cdecl tesseract::LSTMRecognizer::LoadDictionary(char const *,char const *)" (?LoadDictionary@LSTMRecognizer@tesseract@@QEAA_NPEBD0@Z) referenced in function "public: bool __cdecl tesseract::Tesseract::init_tesseract_lang_data(char const *,char const *,char const *,enum tesseract::OcrEngineMode,char * *,int,class GenericVector const *,class GenericVector const *,bool)" (?init_tesseract_lang_data@Tesseract@tesseract@@QEAA_NPEBD00W4OcrEngineMode@2@PEAPEADHPEBV?$GenericVector@VSTRING@@@@3_N@Z)	tesseract	D:\tesseract\VS2015_Tesseract\tesseract\tessedit.obj 1
Error	LNK2019	unresolved external symbol "public: __cdecl tesseract::LSTMRecognizer::~LSTMRecognizer(void)" (??1LSTMRecognizer@tesseract@@QEAA@XZ) referenced in function "public: void * __cdecl tesseract::LSTMRecognizer::`scalar deleting destructor'(unsigned int)" (??_GLSTMRecognizer@tesseract@@QEAAPEAXI@Z)	tesseract D:\tesseract\VS2015_Tesseract\tesseract\tesseractclass.obj	1


Can someone kindly assist me in resolving them? Try installing with cppan as described in

https://github.com/tesseract-ocr/tesseract/wiki/Compiling

- excuse the brevity, sent from mobile

On 28-Jan-2017 10:39 PM, "Sai Nikhil" <notifications@github.com> wrote:

> Hi,
>
> I have put my effort by making changes to necessary project files. I have
> used the solution file present at the following location:
>
> https://github.com/peirick/VS2015_Tesseract/
>
> Unfortunately, that is based on Tesseract - 3.05. I took the latest 4.0
> version of source code to build in visual studio. I'm getting following
> linker errors only for the newly introduced code part in 4.0 i.e., lstm and
> simddetect:
>
> Severity Code Description Project File Line Suppression State
> Error LNK1120 8 unresolved externals tesseract
> D:\tesseract\VS2015_Tesseract\x64\Debug\tesseract.exe 1
> Error LNK2001 unresolved external symbol "private: static bool
> SIMDDetect::avx_available_" (?avx_available_@SIMDDetect@@0_NA) tesseract
> D:\tesseract\VS2015_Tesseract\tesseract\tesseractmain.obj 1
> Error LNK2001 unresolved external symbol "private: static bool
> SIMDDetect::sse_available_" (?sse_available_@SIMDDetect@@0_NA) tesseract
> D:\tesseract\VS2015_Tesseract\tesseract\tesseractmain.obj 1
> Error LNK2019 unresolved external symbol "public: void __cdecl
> tesseract::Tesseract::TrainLineRecognizer(class STRING const &,class
> STRING const &,class BLOCK_LIST *)" (?TrainLineRecognizer@
> Tesseract@tesseract@@QEAAXAEBVSTRING@@0PEAVBLOCK_LIST@@@Z
> <https://github.com/Z>) referenced in function "public: int __cdecl
> tesseract::TessBaseAPI::Recognize(class ETEXT_DESC *)"
> (?Recognize@TessBaseAPI@tesseract@@QEAAHPEAVETEXT_DESC@@@Z
> <https://github.com/Z>) tesseract D:\tesseract\VS2015_Tesseract\tesseract\baseapi.obj
> 1
> Error LNK2019 unresolved external symbol "public: void __cdecl
> tesseract::Tesseract::LSTMRecognizeWord(class BLOCK const &,class ROW
> *,class WERD_RES *,class tesseract::PointerVector *)"
> (?LSTMRecognizeWord@Tesseract@tesseract@@QEAAXAEBVBLOCK@@PEAVROW@
> @PEAVWERD_RES@@PEAV <https://github.com/PEAV>?$PointerVector@VWERD_RES@@@2
> <https://github.com/2>@@Z <https://github.com/Z>) referenced in function
> "public: void __cdecl tesseract::Tesseract::classify_word_pass1(struct
> tesseract::WordData const &,class WERD_RES * *,class
> tesseract::PointerVector *)" (?classify_word_pass1@Tesseract@tesseract@@
> QEAAXAEBUWordData@2@PEAPEAVWERD_RES@@PEAV <https://github.com/PEAV>?$
> PointerVector@VWERD_RES@@@2 <https://github.com/2>@@Z
> <https://github.com/Z>) tesseract D:\tesseract\VS2015_Tesseract\tesseract\control.obj
> 1
> Error LNK2019 unresolved external symbol "public: __cdecl
> tesseract::LSTMRecognizer::LSTMRecognizer(void)"
> (??0LSTMRecognizer@tesseract@@QEAA@XZ) referenced in function "public:
> bool __cdecl tesseract::Tesseract::init_tesseract_lang_data(char const
> *,char const *,char const *,enum tesseract::OcrEngineMode,char *
> *,int,class GenericVector const *,class GenericVector const *,bool)"
> (?init_tesseract_lang_data@Tesseract@tesseract@@QEAA_
> NPEBD00W4OcrEngineMode@2@PEAPEADHPEBV?$GenericVector@VSTRING@@@@3_N@Z)
> tesseract D:\tesseract\VS2015_Tesseract\tesseract\tessedit.obj 1
> Error LNK2019 unresolved external symbol "public: bool __cdecl
> tesseract::LSTMRecognizer::DeSerialize(bool,class tesseract::TFile *)"
> (?DeSerialize@LSTMRecognizer@tesseract@@QEAA_N_NPEAVTFile@2@@Z
> <https://github.com/Z>) referenced in function "public: bool __cdecl
> tesseract::Tesseract::init_tesseract_lang_data(char const *,char const
> *,char const *,enum tesseract::OcrEngineMode,char * *,int,class
> GenericVector const *,class GenericVector const *,bool)"
> (?init_tesseract_lang_data@Tesseract@tesseract@@QEAA_
> NPEBD00W4OcrEngineMode@2@PEAPEADHPEBV?$GenericVector@VSTRING@@@@3_N@Z)
> tesseract D:\tesseract\VS2015_Tesseract\tesseract\tessedit.obj 1
> Error LNK2019 unresolved external symbol "public: bool __cdecl
> tesseract::LSTMRecognizer::LoadDictionary(char const *,char const *)"
> (?LoadDictionary@LSTMRecognizer@tesseract@@QEAA_NPEBD0@Z) referenced in
> function "public: bool __cdecl tesseract::Tesseract::init_tesseract_lang_data(char
> const *,char const *,char const *,enum tesseract::OcrEngineMode,char *
> *,int,class GenericVector const *,class GenericVector const *,bool)"
> (?init_tesseract_lang_data@Tesseract@tesseract@@QEAA_
> NPEBD00W4OcrEngineMode@2@PEAPEADHPEBV?$GenericVector@VSTRING@@@@3_N@Z)
> tesseract D:\tesseract\VS2015_Tesseract\tesseract\tessedit.obj 1
> Error LNK2019 unresolved external symbol "public: __cdecl
> tesseract::LSTMRecognizer::~LSTMRecognizer(void)"
> (??1LSTMRecognizer@tesseract@@QEAA@XZ) referenced in function "public:
> void * __cdecl tesseract::LSTMRecognizer::`scalar deleting
> destructor'(unsigned int)" (??_GLSTMRecognizer@tesseract@@QEAAPEAXI@Z)
> tesseract D:\tesseract\VS2015_Tesseract\tesseract\tesseractclass.obj 1
>
> Can someone kindly assist me in resolving them?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/686>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AE2_owaG2bf-jEF68k0o72CxMoUvrV8Tks5rW3YwgaJpZM4Lwjli>
> .
>
 I ran the above command but still no luck. 2 weeks gone but still no progress on build. Can you kindly describe the step by step procedure so that I can have a successful build. Thanks in advance. Can you provide a video of installing Tesseract 4.0x along with it's step-by-step description, on Ubuntu 16.xx from scratch. Uploading it to Youtube so that all people interested in the matter can follow from scratch.  Hi Egor,

Thanks for your response. Forgetting what happened in the past, I now ran the following steps for building Tesseract from source:

git clone https://github.com/tesseract-ocr/tesseract tesseract
cd tesseract
cppan
mkdir build && cd build
cmake ..

Build is now successful.

But, when I'm trying to run tesseractmain.cpp program in Debug mode, I get the following error:

![1](https://cloud.githubusercontent.com/assets/1130987/22403458/d9d32832-e63d-11e6-8411-5782ec20e184.png)

![2](https://cloud.githubusercontent.com/assets/1130987/22403461/e287262c-e63d-11e6-9eff-104cf87a5207.png)

Can you kindly assist me in getting rid of this error and run the main program? Perfect. Setting tesseractmain as the default project worked. Thanks a ton for the help. Closing the thread.  I also meet the same problem, but I can't resolve it with your answer. can you give me some suggestion? Hi @BrianZhu01 , can you let us know what all steps you've tried from beginning? thanks, I download tesseract, but I do not how deal with cppan? ,I had download cppan.exe .what can I do? I do steps as you list, but have the follow problem, and I just put the cppan.exe in cmake path? what I have wrong?@saint1729
![0x943d51f0_0x4da8_0x43f6_0xa3_0x22b8_0x2278_0x225d_0x2286_0x224a_0x222d_0x2284](https://cloud.githubusercontent.com/assets/15243563/22917419/b3241f50-f2bf-11e6-846d-98476318c3ee.png)
 Add **cppan** to you system variable **PATH**.

Go to directory where you extracted tesseract source code
**cd tesseract**


Run the following commands after that:

**cppan
mkdir build && cd build
cmake ..**

 Can you list what all files are present in your tesseract-ocr directory by running **dir** command and upload the screenshot here? thanks a lot,  If I run the cmd using administrator, I reslove the problem. when I run cppan , it can download the need files. thanks for your help, 

 @saint1729 ,sorry, I also need you help. run cppan doesn't work now! yesterday, I just download some files through cppan. but I meet some errors when run "cmake".
![000000](https://cloud.githusercontent.com/assets/15243563/22970142/fe2009f0-f3ab-11e6-8b74-81f628f701b7.png)
![00000001](https://cloud.githubusercontent.com/assets/15243563/22970145/fefbee02-f3ab-11e6-8f8c-f2080af15767.png)
![0000002](https://cloud.githubusercontent.com/assets/15243563/22970143/fe30a5e4-f3ab-11e6-800b-1c863b6c7296.png)
 @saint1729 
![000000](https://cloud.githubusercontent.com/assets/15243563/22970246/649f3002-f3ac-11e6-9312-c82e8cb5e325.png)
 @egorpugin ， I opencv cppan.yml use txt. so the format have changed. what editor can i use to recover it?thanks!
 @saint1729 @egorpugin ，I had open cppan.yml use notepad++, but here also have same error!
![0000000000000000000](https://cloud.githubusercontent.com/assets/15243563/23002929/5cf771da-f428-11e6-9bec-0374c86f9147.png)

 What if I have cppan that stops when launching it? I can't install Tesseract using cppan. I really need help! Thank you. 
Windows 10 64bit
opencv installed correctly.
Visual studio community 2017  I compared the HOCR output generated with recent builds of tesseract 3.04.02dev and 4.00.00alpha on various test images.

It seems that font recognition is broken in 4.00.00alpha:

With the command line parameter
**-c hocr_font_info=1**
3.04 generates font info for every word, which looks like this:
`x_font Verdana_Bold; x_fsize 21`

When I do the same with 4.00.00alpha, the font info looks like this:
`x_fsize 61491592`

The x_font attribute is missing entirely, and x_fsize has an incredibly large value.

The complete command line was:
`tesseract test-0.png  result --oem 1 -l deu -c hocr_font_info=1 hocr`

Version information:

3.04:
```
$ tesseract -v
tesseract 3.04.02dev
 leptonica-1.74.1
  libjpeg 6b (libjpeg-turbo 1.3.1) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8
```

4.00:
```
$ tesseract -v
tesseract 4.00.00alpha
 leptonica-1.74.1
  libjpeg 6b (libjpeg-turbo 1.3.1) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 Found AVX
 Found SSE

```
 The new LSTM engine does not support font recognition. OK, but then the presence of the x_fsize attribute is misleading.

Will the LSTM engine ever support font recognition?
 >Will the LSTM engine ever support font recognition?

Only @theraysmith can answer this question.

I don't think that exact font identification is important feature. The estimated size of a word/line might be useful information. Same for emphasis of words.  output using 4.0.0-alpha traineddata

--oem 0

```
⁄>ឆ្គាំ៥រុសសស្ដិនស់៍ញ្ញើឆា្នតហ្មឺននិងស្លីងញ្ញៃត្រងមានឤយុព័
មានរុសចក្ដីរិ៍ប្រប្រួលជាធម្មតាប់់ម្បាស៊ឹបប្លែឋអ៎ប៏លប់់ប់់។
ថ្ងៃពុធហ្ស៊ុក)កេញ្ញះ
និងមានទ្រង់អៈភ្យិងចំាងភ្លីផ្ដេកៗពុឝ៊ូស៊ឺន
កម្ពុជាធ្លាក់ចុះយ៉ាងឆាប់រហ័សអៈពាញ្ញះថ្លយ៉ាំវនេញ្ញះក្ងិកក្ងក់ពេកពុ
ទេរុំច់់មានញ្ញើសាភណ័គ្ររស់ស្ឆាតអៈពាខញ្ញើហកុះនាញ្ញះញ្ជែ

ដេីម្បិកាក់បន្ថយការស្អុះចរាចរណំឬម្មេណឺសដានភ្លឣផ្តរស្សុ
```

--oem 1

```
/ > $2 62 {&4 & 1 {£4 2 &4 {{2'| % {| ©2 /5 3 £${23#] % 23 {4'| ©3 ±#') [{{ {9
{4 ©2 {& 1{2 @{{{ {{{,{ 013! {2 {4 ©'| {{{{1 &^{1 { {{$ 142 13 01 «3 «|

{{2 {] {2 {|{{€ ) { :

2 23 €4'| © {2 4 {{{$]23 {24 23 @{{2 ©] "| {2 £:45

€ {{ {3 {2 €\ {2 : [{}" :3 #2'| { 14{ { &1 {{{')') : {2 ,4{ 52 : 5 £€3 {2 € { {") €} «)
{91 {4 ©2 {& {" } 0] ({ {$,4 &, 1 } {" $3 {{{"|'] : {{|'] $3 { 52") : *-

{&${{€) $& { { 2 [{ | 4 64 ; {24'| £24 0.0) { 1 4 {4 0 8 &1 3!) = ©$44{34&{}

=

{{ : {« 644 €| 4 2 23 $5 . {4 . "| {23 @:3 {616 #2'| : [{ : £35

{3]{{') : 444{|'| © {{ €4{6%] [{11{ { & #,1 {3 9") (2 5 {" {4' [14 {22 € {4: =
= 4 {{{2]:3 25 | 3 $4 €{ {34 {$2 {2') &, {4 £3 {9 = {1 15 - \

{{} {53 0] { 22 { 1427] 5 {4 €3 {5 {4 {4 &, 1#:3 "|| {{ {24 $2 ±3 {$3 :

$2 {5{{") : €3 { 52" :3 {{ 8 [44 | 2 #2{1 1 4 &163 {44 :3

€| 465 { 5213 &1 {3 {2 {] € € = } {{3$|]:3 {{} {{ 5 {@@4 «1 {2

„)
```
 Related info:

https://github.com/tesseract-ocr/tesseract/issues/622#issuecomment-275051856

https://github.com/tesseract-ocr/tesseract/issues/654#issuecomment-274574951 Also see https://github.com/tesseract-ocr/langdata/issues/43  Please see attached OCR evaluation reports. The words highlighted in green in the ground truth are being dropped during recognition.

[kan-words-dropped.zip](https://github.com/tesseract-ocr/tesseract/files/736761/kan-words-dropped.zip)


 ```
Processing word with lang kan at:Bounding box=(163,2011)->(1231,2056)
Trying word using lang kan, oem 1
Best choice: accepted=1, adaptable=0, done=1 : Lang result : ಪ್ರೆಸ್, : R=3.81155, C=-2.00782, F=1, Perm=8, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM
str	ಪ್	ರೆ	ಸ್	,
state:	1 	1 	1 	1 
C	-0.137	-0.113	-0.287	-0.108
Best choice: accepted=1, adaptable=0, done=1 : Lang result :        : R=60, C=-1, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM
str	 	 	 	 	 	 
state:	1 	1 	1 	1 	1 	1 
C	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000
```

I would suggest that if the best match for a word comes to be blank, then it be replaced by a string such as @@@@@ so that it is easy to identify missing text and correct the OCR output. Other similar issues:

https://github.com/tesseract-ocr/tesseract/issues/673

https://github.com/tesseract-ocr/tesseract/issues/664

https://github.com/tesseract-ocr/tesseract/issues/633#issuecomment-275348678 @theraysmith 

Is it possibly related to `--strip_unrenderable_words` during training? I have noticed that the images created by text2image have a blank space instead of the missing word when the font is not able to render it.  >The underlying question is, if there is a word that is almost certainly incorrect, would it be better to have it with the error, or have it disappear?

I do not think it should disappear. However, if the word is almost certainly incorrect, then it should be marked in some easy way for users to fix the OCRed txt.

Request feedback from others too - @zdenop @jbreiden @amitdo @stweil etc. > I think the cause of all of these is the precision-recall tradeoff that takes place in linerec.cpp

I find that the words which are getting dropped are also the same ones which are not being picked up by tesseract when using 'makebox'. I has posted a sample with devanagari in another thread. (https://github.com/tesseract-ocr/tesseract/issues/664#issue-201505043 )

Here is a kannada sample:

![kan box missing](https://cloud.githubusercontent.com/assets/5095331/22395065/278b840c-e558-11e6-8ba5-0217592f1661.png)
![kan recognition missing](https://cloud.githubusercontent.com/assets/5095331/22395066/2ea254a0-e558-11e6-8fa9-e6f0cfbc0d17.png)
 Hi

Yeah @Shreeshrii  is correct ,The words not being picked,Is it problem with Segmentation??
@theraysmith Even though the recognition is wrong it should be display with any alternate character either "-" or any thing...  It also might be useful to add a few(1-4) alternative words for each word when using the hOCR format. Please see
https://pdfs.semanticscholar.org/dc3e/f1e05b4b629de5db721efb156d82556ff362.pdf
The ISRI Analytic Tools for OCR Evaluation

> A tilde (~) in an OCR-generated text file is treated as a reject character. A circumflex (^) is interpreted as a suspect marker and serves to mark the following character as suspect. For example, in Ne^vada, the v is marked as suspect. The value of these special characters is assessed when computing marked character efficiency.

I thought that this maybe a standard in OCR evaluation and hence had suggested a marker.

Regardless, I do not think that incorrect words should just disappear.
 > I am not convinced that the unicharset and/or compression are applied correctly to Kannada, which might explain its rather stubborn refusal to improve in accuracy.

@theraysmith Are there any specific issues that you have noticed which I can check with native Kannada speakers? Some feedback regarding Kannada recognition from MNS Rao 

```
I request you to analyse where special efforts are required to improve the program

Essentially kannada script has many problems from OCR point of view.

1. many characters with a very little difference making recognition difficult.
eg: ಅ ಆ; ಉ ಊ; ಎ ಏ ಐ; ಒ ಓ ಔ; ಅಂ ಅಃ
     ಡ ಢ; ದ ಧ ಥ; ರ ಠ ಝ; ಪ ಫ ಘ ; ಬ ಭ ; ವ ಮ ; ೦ ಂ ; ಕ೯ರ್ಕ; ೬ ಕ್ಮ 
    
2. in-consistencies in guNita formations
eg: ವು ಪು 

3. vottu of ತ ನ ಮ ಯ ರ ಲ  not like main character.

4. ಯ ಝ ಮ can lead to wrong recognition because of splitting of parts of the character by OCR process

5. ೕ is part in three different situations ಕೀ ಕೇ, ಕೋ 

I would like to know if the input from my side is helpful to improve the program.

Regards.
MNS Rao
``` :+1: to Shree and MNS Rao !
Hope that Ray can make something out of this feedback. https://shreeshrii.github.io/tess4eval_kannada/
has OCR eval reports for 4.0.0-alpha kan.traineddata 

CER	7.74
WER	9.26
WER (order independent)	5.70

Images and gt are in
https://github.com/Shreeshrii/tess4eval_kannada @theraysmith What page segmentation mode do you use for the testing/accuracy reports?

I am getting better results for kannada with --psm 6 compared to --psm 3 (default) or --psm 4.

 3    Fully automatic page segmentation, but no OSD. (Default)

  4    Assume a single column of text of variable sizes.

  6    Assume a single uniform block of text.
 The tests are done with `.uzn` files.
 https://github.com/tesseract-ocr/tesseract/blob/a1c22fb0d0/ccmain/pagesegmain.cpp#L111 Are there unlv test files for indian languages?

- excuse the brevity, sent from mobile

On 12-Feb-2017 1:38 PM, "Amit D." <notifications@github.com> wrote:

> The tests are done with .uzn files.
> https://github.com/tesseract-ocr/tesseract/blob/
> a1c22fb0d0f6bde165ec7b7c3125420b0ba1d541/ccmain/pagesegmain.cpp#L111
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/681#issuecomment-279203408>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o6oGsQw2bBnbF5zxyIj3jnXquAzjks5rbr4agaJpZM4LuojH>
> .
>
 If you are asking about the original UNLV dataset, the ansswer is 'No'.

It's possible that someone prepared such files as part of indic dataset. @theraysmith Please see page 18 onwards for kannada specific info in the following pdf

http://tdil-dc.in/tdildcMain/articles/644564990964Kannada%20Script%20Grammar%20TDIL%20Version_Ver1.0.pdf

 More Kannada OCR related papers:

http://mile.ee.iisc.ernet.in/mile/publications/softCopy/DocumentAnalysis/Madhav_SPCOM2014.pdf

http://mile.ee.iisc.ernet.in/mile/publications/softCopy/DocumentAnalysis/Nethra_ICFHR2010_Data.pdf

http://mile.ee.iisc.ernet.in/mile/publications/softCopy/DocumentAnalysis/ Yes, both ZWJ and ZWNJ are important for Indic languages. Please see 

http://unicode.org/faq/indic.html

If the sequence U+0924, U+094D is not followed by another consonant letter (such as "na") it is always displayed as a full ta glyph combined with the virama glyph "dev-ta-virama".
Unicode provides a way to force the display engine to show a half letter form. To do this, an invisible character called ZERO WIDTH JOINER should be inserted after the virama:
U+0924	0924	DEVANAGARI LETTER TA
U+094D	094D	DEVANAGARI SIGN VIRAMA (= halant)
U+200D	200D	ZERO WIDTH JOINER
U+0928	0928	DEVANAGARI LETTER NA
This sequence is always displayed as a half ta glyph followed by a full na glyph "dev-half-ta-na". Even if the consonant "na" is not present, the sequence U+0924, U+094D, U+200D is displayed as a half ta glyph "dev-half-ta".
Unicode also provides a way to force the display engine to show the virama glyph. To do this, an invisible character called ZERO WIDTH NON-JOINER should be inserted after the virama:
U+0924	0924	DEVANAGARI LETTER TA
U+094D	094D	DEVANAGARI SIGN VIRAMA (= halant)
U+200C	200C	ZERO WIDTH NON-JOINER
U+0928	0928	DEVANAGARI LETTER NA
This sequence is always displayed as a full ta glyph combined with a virama glyph and followed by a full na glyph "dev-full-ta-virama-full-na
For more detailed information, see Chapter 12, South Asian Scripts-I in The Unicode Standard. For related issues, see "Where is My Character?" [MC] There are at times multiple ways of typing a character, some of the web text may look ok but maynot be correct. There probably needs to be a normalisation step before training.

Please see kannada chapter in 
http://www.unicode.org/versions/Unicode9.0.0/ch12.pdf

Vowel letters are encoded atomically in Unicode, even if they can be ana-
lyzed visually as consisting of multiple parts. Table 12-28 shows the letters that can be ana-
lyzed, the single code point that should be used to represent them in text, and the sequence
of code points resulting from analysis that should not be used.

Table 12-28. Kannada Vowel Letters
For Use Do Not Use
r 0C8A <0C89, 0CBE>
p 0C94 <0C92, 0CCC>
s 0CE0 <0C8B, 0CBE> Related _ https://github.com/tesseract-ocr/tesseract/issues/604 Related - Marathi recognition of repha (sanskrit loan words) and eyelash ra

@theraysmith 

I found that when using Marathi traineddata words which used half ra (repha) were not being recognized correctly, it could be related to the ZWJ and ZWNJ problem.

eg.  पूर्वक सूर्य धर्म सर्व कार्य वर्ग

Since unicode has evolved over time, there maybe legacy representations still around in the webtext.

Please see issue 7 listed on http://www.baraha.com/help/kb/unicode_issues.htm which has examples of different unicode encodings being used. @theraysmith 

https://github.com/anoopkunchukuttan/indic_nlp_library/blob/master/src/indicnlp/normalize/indic_normalize.py

Common normalization in the above includes

* ZERO_WIDTH_NON_JOINER and ZERO_WIDTH_JOINER removal 

In case the LSTM training data build uses something similar on the webtext, you may want to disable that.

 I don't think new models can help with this issue. @theraysmith,

This feature drops perfect words!
https://github.com/tesseract-ocr/tesseract/issues/1080#issuecomment-322206285

I also was hit by this issue.

Two examples from one page from old (1929) Hebrew newspaper: 


GT:
מגוונת-דעות.
OCR:
מגוונת.דעות.

GT:
מצב-רוחותיהם
OCR:
מצבברוחותיהם

```
Best choice certainty=-2.90379, space=-0.193423, scaled=-20.3265, final=-20.3265
 : .תועד.תנווגמ : R=11.8952, C=-2.90379, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM
str	.	ת	ו	ע	ד	.	ת	נ	ו	ו	ג	מ
state:	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 
C	-0.295	-0.192	-0.192	-0.192	-0.191	-2.904	-0.197	-0.192	-0.197	-0.230	-0.193	-0.192
Deleting word with certainty -20.3265

Best choice certainty=-3.59027, space=-0.21691, scaled=-25.1319, final=-25.1319
 : םהיתוחורבבצמ : R=14.0075, C=-3.59027, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM
str	ם	ה	י	ת	ו	ח	ו	ר	ב	ב	צ	מ
state:	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 
C	-0.193	-0.193	-0.191	-0.194	-0.196	-0.192	-0.192	-0.201	-3.590	-0.217	-0.207	-0.202
Deleting word with certainty -25.1319
 : םהיתוחורבבצמ : 
```

In both examples there are two words separated by hyphen. The hyphen looks unclear, and thus Tesseract replaces it with another character. Other than this char all the chars in the two words are recognizes well.
 ~~I didn't test it, but~~ this is probably the way to disable this feature:

https://github.com/tesseract-ocr/tesseract/blob/3ec11bd37a56/ccmain/linerec.cpp#L293

This block of code

```
      // Discard words that are impossibly bad, but allow a bit more for
      // dictionary words, and keep bad words in non-space-delimited langs.
      if (word_certainty >= RecodeBeamSearch::kMinCertainty ||
          any_nonspace_delimited ||
          (word_certainty >= kWorstDictCertainty &&
           Dict::valid_word_permuter(word->best_choice->permuter(), true))) {
        word->tess_accepted = stopper_dict->AcceptableResult(word);
      } else {
        if (getDict().stopper_debug_level >= 1) {
          tprintf("Deleting word with certainty %g\n", word_certainty);
          word->best_choice->print();
        }
        // It is a dud.
        word->SetupFake(lstm_recognizer_->GetUnicharset());
      }
```

Should be replaced with:

```
      word->tess_accepted = stopper_dict->AcceptableResult(word);
```
 Tested on a few pages. Seems to be working well.  Tested with 4.00.00alpha and current head (f566a45b30cd4dd448ec6419160c17310d898aa2) on Linux,tesseract can not be compiled if I disable scrollview:
/bin/sh ../libtool  --tag=CXX   --mode=link x86_64-pc-linux-gnu-g++  -march=native -O2 -pipe -std=c++11  -Wl,-O1 -Wl,--as-needed -o tesseract tesseract-tesseractmain.o libtesseract.la   -lrt -llept -lpthread 
```
libtool: link: x86_64-pc-linux-gnu-g++ -march=native -O2 -pipe -std=c++11 -Wl,-O1 -o .libs/tesseract tesseract-tesseractmain.o  -Wl,--as-needed ./.libs/libtesseract.so -lrt -llept -lpthread -fopenmp
./.libs/libtesseract.so: undefined reference to `ScrollView::AwaitEvent(SVEventType)'
./.libs/libtesseract.so: undefined reference to `ScrollView::Pen(ScrollView::Color)'
./.libs/libtesseract.so: undefined reference to `ScrollView::Update()'
./.libs/libtesseract.so: undefined reference to `ScrollView::SetCursor(int, int)'
./.libs/libtesseract.so: undefined reference to `ScrollView::Image(Pix*, int, int)'
./.libs/libtesseract.so: undefined reference to `ScrollView::ScrollView(char const*, int, int, int, int, int, int, bool)'
./.libs/libtesseract.so: undefined reference to `ScrollView::Clear()'
./.libs/libtesseract.so: undefined reference to `SVSync::StartThread(void* (*)(void*), void*)'
./.libs/libtesseract.so: undefined reference to `ScrollView::DrawTo(int, int)'
collect2: error: ld returned 1 exit status
make[2]: *** [Makefile:605: tesseract] Error 1
```

Some of these can be fixed by including config_auto.h (mostly in lstm), but I am less sure about the SVSync::StartThread() call in ccstruct/imagedata.cpp master is OK now, thanks for the fast merge!  hello~

I've tried this command but cannot get correct text (the version is 3.0.4 with chi_sim.traineddata data file).

command: tesseract h1.jpg stdout -l chi_sim

photo: ![h1](https://cloud.githubusercontent.com/assets/743123/22244016/d5fd61fa-e264-11e6-9a55-cd2db095f216.jpg)  @theraysmith 

Two different types of box file formats are mentioned in Training Tesseract 4.0 wiki.

Please see attached and confirm the format (specially for the Wordstr format). The lstmf files created by the two box/tiff pairs are different in size, even though they are for the same tif file.

[frk.embedsiver.exp0.zip](https://github.com/tesseract-ocr/tesseract/files/721095/frk.embedsiver.exp0.zip)
 When using the WordStr format in one of the box files, 

```
WordStr 1350 3106 1755 3190 0 #Personer.
WordStr 895 2861 1194 2927 0 #Møller. 
WordStr 895 2742 1528 2811 0 #Emilie, hans Kone.
WordStr 899 2618 1507 2691 0 #Birch, Cancelliraad.
WordStr 894 2497 1546 2567 0 #Laura, hans Datter.
WordStr 895 2377 1317 2447 0 #Fru Krogh.
WordStr 897 2256 1724 2329 0 #Otto Rosen, Fuldmægtig.
WordStr 896 2134 1759 2207 0 #Anders,Tjener hos Birch.
WordStr 898 2015 1669 2085 0 #EnTjener hos Møller.
WordStr 696 1746 2422 1821 0 #Handlingen foregaaer i Kjøbenhavn, i Slutningen af 1848.
```
I get an error (utf8 buffer too big) during processing and the unicharset is not built fully (stops at that line and does not process other box files, but does not stop)
```
=== Phase UP: Generating unicharset and unichar properties files ===
[Sat Jan 21 18:53:04 DST 2017] /usr/local/bin/unicharset_extractor -D /tmp/tmp.hxOIFoYXPH/frk/ /tmp/tmp.hxOIFoYXPH/frk/frk.embedsiver.exp0.box /tmp/tmp.hxOIFoYXPH/frk/
frk.embedsiverline.exp0.box /tmp/tmp.hxOIFoYXPH/frk/frk.UnifrakturMaguntia.exp0.box /tmp/tmp.hxOIFoYXPH/frk/frk.Walbaum-Fraktur.exp0.box
**Utf8 buffer too big, size=57 for Handlingen foregaaer i Kjøbenhavn, i Slutningen af 1848.**
Extracting unicharset from /tmp/tmp.hxOIFoYXPH/frk/frk.embedsiver.exp0.box
**Extracting unicharset from /tmp/tmp.hxOIFoYXPH/frk/frk.embedsiverline.exp0.box**
Extracting unicharset from /tmp/tmp.hxOIFoYXPH/frk/frk.UnifrakturMaguntia.exp0.box
Extracting unicharset from /tmp/tmp.hxOIFoYXPH/frk/frk.Walbaum-Fraktur.exp0.box
Wrote unicharset file /tmp/tmp.hxOIFoYXPH/frk//unicharset.
[Sat Jan 21 18:53:04 DST 2017] /usr/local/bin/set_unicharset_properties -U /tmp/tmp.hxOIFoYXPH/frk/frk.unicharset -O /tmp/tmp.hxOIFoYXPH/frk/frk.unicharset -X /tmp/tmp
.hxOIFoYXPH/frk/frk.xheights --script_dir=../langdata
Loaded unicharset of **size 48** from file /tmp/tmp.hxOIFoYXPH/frk/frk.unicharset
```
If I do not use this box file, then the unicharset is built with all of the box files
```
=== Phase UP: Generating unicharset and unichar properties files ===
[Sat Jan 21 18:58:01 DST 2017] /usr/local/bin/unicharset_extractor -D /tmp/tmp.wyo1280N2G/frk/ /tmp/tmp.wyo1280N2G/frk/frk.embedsiver.exp0.box /tmp/tmp.wyo1280N2G/frk/
frk.UnifrakturMaguntia.exp0.box /tmp/tmp.wyo1280N2G/frk/frk.Walbaum-Fraktur.exp0.box
Extracting unicharset from /tmp/tmp.wyo1280N2G/frk/frk.embedsiver.exp0.box
Extracting unicharset from /tmp/tmp.wyo1280N2G/frk/frk.UnifrakturMaguntia.exp0.box
Extracting unicharset from /tmp/tmp.wyo1280N2G/frk/frk.Walbaum-Fraktur.exp0.box
Wrote unicharset file /tmp/tmp.wyo1280N2G/frk//unicharset.
[Sat Jan 21 18:58:02 DST 2017] /usr/local/bin/set_unicharset_properties -U /tmp/tmp.wyo1280N2G/frk/frk.unicharset -O /tmp/tmp.wyo1280N2G/frk/frk.unicharset -X /tmp/tmp
.wyo1280N2G/frk/frk.xheights --script_dir=../langdata
Loaded unicharset of **size 143** from file /tmp/tmp.wyo1280N2G/frk/frk.unicharset
Setting unichar properties

``` https://github.com/tesseract-ocr/tesseract/blob/a75ab450a8cc9a2b69cf05f5c4f7a39bc44cbacc/ccmain/applybox.cpp#L71 @amitdo Thanks for pointing out that the string needs to be space delimited. I tried with that version also, it is also getting an error...

Ref: https://github.com/amitdo/tesseract/issues/3#issuecomment-274262671 I updated the relevant wiki [section](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#creating-training-data).

`unicharset_extractor` needs some more code to read the (`WordStr`) textlines-based box file format right. Ray, please consider a new box format with new name - ''\<...>-linebox' for training the LSTM engine, For example see here:
https://github.com/tesseract-ocr/tesseract/issues/832#issuecomment-298688350  Same error (WARNING! LEAK! ) reported in issue

https://github.com/tesseract-ocr/tesseract/issues/529#issuecomment-269325872  Text/words are dropped during Devanagari recognition with --oem 1 option. 

It seems to be related to line segmentation / box creation because the same words are also skipped in the box file created by tesseract run with 'makebox' config file.

Please see attached - 

- image being OCRed, 

- image  showing boxfile skipping the words,

- ground-truth  file and 

- OCRed text

- OCR evaluation report.

![arabic-deva1](https://cloud.githubusercontent.com/assets/5095331/22055988/c65e0f96-dd83-11e6-9f06-bea70dd85be6.png)

![missing-words](https://cloud.githubusercontent.com/assets/5095331/22056003/d63916d6-dd83-11e6-98c9-8478359cdf7e.png)

[arabic-deva1.txt](https://github.com/tesseract-ocr/tesseract/files/713299/arabic-deva1.txt)

[arabic-deva1-san.txt](https://github.com/tesseract-ocr/tesseract/files/713300/arabic-deva1-san.txt)


[arabic-deva1-san_report.html.txt](https://github.com/tesseract-ocr/tesseract/files/713306/arabic-deva1-san_report.html.txt)




 Another sample, where the whole first line is skipped, in addition to missing words

[forbes1849devscript.txt](https://github.com/tesseract-ocr/tesseract/files/715822/forbes1849devscript.txt)
[forbes1849devscript-tif1-hin.txt](https://github.com/tesseract-ocr/tesseract/files/715823/forbes1849devscript-tif1-hin.txt)

- image
- ground truth file
- OCRed text with -l hin

edit:  tif file converted to png for uploading.

![forbes1849devscript](https://cloud.githubusercontent.com/assets/5095331/22095836/e3ddf3f0-de3d-11e6-92e3-7fb8611b43be.png)
 Is it related to https://github.com/tesseract-ocr/tesseract/issues/633#issuecomment-275348678 ? It seems some words are being recognized as 'blanks' - see the following from the debug info - while processing image shown in https://github.com/tesseract-ocr/tesseract/issues/664#issue-201505043

```
Processing word with lang hin at:Bounding box=(236,2830)->(1276,2924)
Trying word using lang hin, oem 1
Best choice: accepted=1, adaptable=0, done=1 : Lang result :       : R=50, C=-1, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM	NORM
str	 	 	 	 	 
state:	1 	1 	1 	1 	1 
C	-1.000	-1.000	-1.000	-1.000	-1.000
```
and
```
Processing word with lang hin at:Bounding box=(234,2248)->(1969,2326)
Trying word using lang hin, oem 1
Best choice: accepted=1, adaptable=0, done=1 : Lang result : मम : R=0.947715, C=-1.37049, F=1, Perm=8, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM
str	म	म
state:	1 	1 
C	-0.086	-0.089
Best choice: accepted=1, adaptable=0, done=1 : Lang result :              : R=120, C=-1, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM
str	 	 	 	 	 	 	 	 	 	 	 	 
state:	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 
C	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000
```  Verified that this compiles and runs on macOS El Capitan with homebrew gcc. I don't believe clang compiles at the moment so not sure if it works for that.

Also added an #error if SIMD checking is missing. Autotools already causes configure to fail if there is no SIMD implementation, so if Makefiles are generated something is wrong.  >Also added an #error if SIMD checking is missing.

This is not the desired behavior. There is a (slow) fallback function that runs when no simd is found. This `#else` code will prevent its execution.

>Autotools already causes configure to fail if there is no SIMD implementation

Are you sure? This should not happen.
 >I don't believe clang compiles at the moment so not sure if it works for that.

If you can test with clang on macOS and report issues, if any, please do it.  I looked into what compilers provide the __get_cpuid() built-in intrinsic - GCC (including mingw) and clang. Microsoft's compiler has an equivalent named __cpuid(). It doesn't matter what OS we're running on, so after establishing we're on x86, it's better to check for the compiler than exhaustive list all platforms. I changed it to reflect this.

I believe the #error should stand. Code that lacks an implementation for a specific compiler should be a build error. This should be better than silently building an inferior tesseract. In any case only compilers outside of GCC, clang, mingw, Microsoft C++ and Intel C++ (which behaves like GCC on Linux and Microsoft on Windows) should hit the #error so anything left is quite rare. @stweil, what are your thoughts on this? (please read my remarks) I'm stuck without a full dev environment for a few days and can't do this
easily. I support the change @stweil proposed if anyone else wants to do
it.
On Sat, Jan 21, 2017 at 03:50 Stefan Weil <notifications@github.com> wrote:

> *@stweil* requested changes on this pull request.
> ------------------------------
>
> In arch/simddetect.cpp
> <https://github.com/tesseract-ocr/tesseract/pull/661#pullrequestreview-17805561>
> :
>
> > @@ -26,7 +26,7 @@
>  #endif // x86 target
>
>  #if defined(X86_BUILD)
> -# if defined(__linux__) || defined(__MINGW32__)
> +# if defined(__GNUC__) || defined(__MINGW32__)
>
> Testing __GNUC__ is sufficient, as MinGW also uses gcc, so the test for
> __MINGW32__ can be removed.
> ------------------------------
>
> In arch/simddetect.cpp
> <https://github.com/tesseract-ocr/tesseract/pull/661#pullrequestreview-17805561>
> :
>
> >  SIMDDetect::SIMDDetect() {
>  #if defined(X86_BUILD)
> -# if defined(__linux__) || defined(__MINGW32__)
> +# if defined(__GNUC__) || defined(__MINGW32__)
>
> Here the test for __MINGW32__ can also be removed.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/661#pullrequestreview-17805561>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABvcM6qnB-Jkgoh25PwsvTfrWJMBWYnmks5rUfD9gaJpZM4Lje3X>
> .
>
 Looks good. Thanks.
On Mon, Jan 23, 2017 at 04:45 Stefan Weil <notifications@github.com> wrote:

> @jbarlow83 <https://github.com/jbarlow83>, is this commit
> <https://github.com/stweil/tesseract/commit/fa677f1ba183c6265fb11a14328dca6b8dd34368>
> fine for you? If yes, I'd make a pull request for it. I kept the original
> date and you as the author.
>
> —
> You are receiving this because you were mentioned.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/661#issuecomment-274479222>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABvcM2_5wQaMJ4kFW1pKXi54dIC6kYjYks5rVKDWgaJpZM4Lje3X>
> .
>
  https://groups.google.com/forum/#!topic/tesseract-ocr/vvMldrkcuOQ has asked:
> I have a pdf (scanned) and now i make a searchable pdf from this.
>First i generate a black/white multipage tif, and with tesseract i can make a searchable pdf.
> But is it somehow possible to integrate the original pdf images?
> because the generated tif has not the same quality like the original (maybe the scaned image is in color).

How to reproduce:

1. Assume one page with a colored background `in.pdf`, converted to `in.ppm` image
1. preprocess `unpaper in.ppm in-cleaned.ppm` 
1. process with (example) `tesseract in-cleaned.ppm out -l deu+eng --oem 2 pdf txt`
1. tesseract mixed output file `out.pdf`has now a blotchy background (from the `unpaper` step above)

![20170113-10 09 17_auswahl](https://cloud.githubusercontent.com/assets/1151915/21924224/72ad2b02-d978-11e6-8b44-12c03da58aa2.png)

Is there any way to "feed-in" the original `in.ppm` as image, so that this is used instead of `in-cleaned.ppm` when creating the `out.pdf` ?

So what is wanted is original input image plus ocr layer, so that output looks like
![20170113-10 12 22_auswahl](https://cloud.githubusercontent.com/assets/1151915/21924289/db580474-d978-11e6-8fd6-05670345ff34.png)
 This is a complicated way of asking for an option to send one image through OCR and insert a different image in the output PDF.

```
tesseract --pdf-image original.png cleaned.png -l eng --oem 2 pdf  # not implemented, could work like this
```

I know this was requested before and I believe @jbreiden said it would be added to the PDF renderer  at some point. Sounds reasonable.

It is fairly simple to swap an image using qpdf's C++ API.
On Fri, Jan 13, 2017 at 18:33 jbreiden <notifications@github.com> wrote:

> I'm very reluctant to make Tesseract PDF generation fancy. I wonder if we
> can do an image swap like this outside of Tesseract, using one of the PDF
> manipulation toolkits.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/660#issuecomment-272595203>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABvcMz65b8BY11SURxHH8RJPXNgJj_N6ks5rSDQHgaJpZM4Liq1Q>
> .
>
 @jbreiden It's the last really missing issue. 
The new algorithm is already a boost in quality. I reach here up to 100% OCR quality (for `--oem 2 -l deu+eng`) including these beasty "Umlauts" äöüÄÖÜß....

If this helps, I will donate some mBTC for implementing it just right now. Just post your receiving address. @jbarlow83 background info. As you know, I recently wanted to try your OCRmyPDF because I found the interesting `-clean` option (source: https://media.readthedocs.org/pdf/ocrmypdf/latest/ocrmypdf.pdf ) which would have solved my problem:

which "does not alter the final output":

```
--clean
uses unpaper to clean up pages before OCR, but does not alter the final output.  This makes it less
likely that OCR will try to find text in background noise.
•
--clean-final
uses unpaper to clean up pages before OCR and inserts the page into the final output.  You
will want to review each page to ensure that unpaper did not remove something important.
```
but unfortunately this does not work with tesseract 4, at the present.

So I looked for bug reports, if tesseract could pass the original input image to the output; and filed the present issue. I think invisible text only output would be far more useful for developers that integrate tesseract or anyone who wants to do something fancy. It would still make sense to keep the existing OCR with image option of course. As a plus, it's should be easier to suppress the image than add a different one.

OCRmyPDF (which I maintain) use Ghostscript to rasterize and then runs one of its two PDF renderers. One uses Tesseract hOCR and provides more features but is not as good at producing the OCR text layer as Tesseract PDF, so I also provide Tesseract PDF. If Tesseract could produce a invisible text only I could offer all the features for both, and work towards phasing out the hOCR renderer. When possible I already do graft the text layer onto the existing PDF instead of constructing a new one.

In addition to OCRmyPDF `pdftk multibackground` could merge an OCR layer onto an existing PDF (by "watermarking"), so there is at least one other supported tool out there that should work out of the box. There's some other tools that wrap tesseract for use with PDFs as well.

In writing this I've made a case for not using qpdf because other tools should be able to do the job with an invisible text PDF, but for interest's sake case here is [example code](
https://github.com/qpdf/qpdf/blob/master/examples/pdf-invert-images.cc) that inverts black and white for all images; clearly this is close to how one would replace an image outright. Looks really good @jbreiden. 

Works great in pdftk. No display issues and PDF syntax looks fine.

PyPDF2 is also capable of merging. It does not have the equivalent of "multibackground" but merge pages manually. Here is merging one page:

```python
In [1]: import PyPDF2 as pypdf

In [4]: pdf_text = pypdf.PdfFileReader(open('text.pdf', 'rb'))

In [5]: pdf_image = pypdf.PdfFileReader(open('images.pdf', 'rb'))

In [6]: page_text = pdf_text.pages[1]

In [7]: page_image = pdf_image.pages[1]

In [8]: page_text.mergeRotatedScaledTranslatedPage(page_image, 0, 1.0, 0, 0, expand=False)

In [9]: out = pypdf.PdfFileWriter()

In [10]: out.addPage(page_text)

In [11]: with open('pypdfmerge.pdf','wb') as o:
    ...:     out.write(o)
    ...:     

```

For reference, pdfbox did not work out of the box. As far as I can tell the closest command in pdfbox is
```
java -jar pdfbox-app-2.0.2.jar OverlayPDF images.pdf text.pdf pdfboxoverlay.pdf
```

However pdfbox takes the unusual approach of rasterizing the overlay PDF as a bitmap and drawing it on top of the base page, making it useless regardless of image/text order. (I suppose when you go to the trouble implementing a full PDF renderer in Java you feel compelled to use it even when it's not strictly needed.)
 I don't know about calling it a naked PDF because there's nothing exciting to see in it. It's more of a phantom or spectral apparition PDF, having form without substance.

`ocr_text_only` would do, or `suppress_images`? Not nearly as fun, but practical. How about `text_only_pdf` ?

@jbreiden  is it also possible to use a .pdf file as input to tesseract directly?  `pdf_invisible_text_layer_only`
+
a config file `pdfinvisible` (or maybe `pdf0`) @Shreeshrii PDF is a very complex vector-based file format. Tesseract works only on images. It is much easier to write PDFs that use a limited set of PDF features than read arbitrary PDFs. Have a look at OCRmyPDF (which I develop) - it addresses the details of using tesseract to apply OCR to PDFs. @jbreiden @jbarlow83 @amitdo  info: I just built the *whole*  toolchain from their git repos (tesseract, ocrmypdf, unpaper), and have ghostscript version 9.20 ready in a dedicated debian 9 "OCR VM" on my Qubes OS system.

Pls. let me know, what (if) you want me to test - I have time to test and want to help you. @Shreeshrii  http://kiirani.com/2013/03/22/tesseract-pdf.html

The PDF/invisible text output you guys are implementing works quite well for me using OSX 'Preview' but for a little jerkiness depending on scaling, of course.

This is quite a big deal, in my opinion, as it will allow those who have, for instance... legal documents containing notary stamps in color, or in my use-case aviation emergency manuals with color-coded pages, to keep their original copies unmodified from their scanners, but modify them in a clean way into searchable documents.  Thanks for this. Thanks for info on pdf to images conversion for use with tesseract. 

I usually use ghostscript for the purpose e.g.

```
gs -dNOPAUSE -dBATCH  -r300x300 -sDEVICE=tiffg4  -dFirstPage=168  -dLastPage=174 -sOutputFile=sample%03d.tif ./sample.pdf
```

I will give the other suggestions a try (including a new one suggested by zdenop in the forum- https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/vvMldrkcuOQ/xLES3_ZoEwAJ )

@jbreiden Thanks, Jeff, for this invisible text output pdf which can be merged with the original pdf.

 >Ray will eventually merge this patch, but it is hard to predict when. I am posting here for anyone who is impatient or excited.

I suggest to merge this to master now. Ray can modify it later if needed. @zdenop https://github.com/tesseract-ocr/tesseract/commit/effa5741e6ef8bcb37d68250ca39c92fae85f6a9 does not work: breaks tesseract [UPDATE:] ~~and creates broken files~~. Who has tested that patch, and how ?
 >effa574 does not work: breaks tesseract and creates broken files. Who has tested that patch, and how ?

I had the impression that Jeff tested it. Maybe I was wrong.  @amitdo with "it breaks" I mean, that the "normal" function of tesseract is broken, https://github.com/tesseract-ocr/tesseract/commit/effa5741e6ef8bcb37d68250ca39c92fae85f6a9 always creates a blank pdf. And now, if I combine my original input pdf with the created output, I appear to have two text layers. Who can help, it's getting more and more complicated. 

Let's go back to the roots:
Why not simply passing the original input image to the output, inside tesseract ?

#### my wish
```
tesseract image.png image.ocr -c image_passthrough=1 pdf
```
which then creates
* image.txt (with the ocr-ed text)
* image.ocr.pdf (mixed-mode pdf with the original image.png and image.txt)

And this setting ( -c image_passthrough=1 ) should be the tesseract default, in my view.
 Tested. With effa574, `tesseract -c textonly_pdf=1` works correctly and `tesseract -c textonly_pdf=0` produces an invalid PDF.

The problem is missing a "/" in front of XObject.
 Fix in #667  @jbarlow83 works. But when I look to capi.cpp then - I think - you have to apply the corresponding change in capi.h see
https://github.com/Wikinaut/tesseract/commit/5e8089107a4bc77c3eca51f6404c41a1854e652e#diff-1ff9fac4997a03321dc873248bcf1309

(I am not sure, whether my patch is correct.))
 @jbreiden regarding "image_passthrough", pls.allow me to explain my workflow, which in my view, is quite common.

* I already _have_ mixed-mode multi-page PDFs ("input.pdf") -- for example, ocr-ed with the old tesseract.
* I already found that the new LSTM mode is very much better and want to regenerate the text layer for all my archived PDFs...
* ...without loosing the high image quality of my existing scans.

With the new `textonly_pdf`mode I managed this, but it requires this additional ugly step (marked with (*)

* split input.pdf into single pages for tesseract (use pdftoppm, or gs or whatelse)
* for each $image do `tesseract input-$image.ppm textonly-$image -c textonly_pdf pdf` command
* `pdftk textonly-*.pdf cat output "textonly.pdf"
* (*) remove text layer from input.pdf -> input-without-text.pdf
* `pdftk input-without-text.pdf multibackground textonly.pdf output new-mixed-mode.pdf`

So it's still very long way with your new option.

Please, perhaps you find a possible way when input image type is a single page (and losslessly coded)

* gif (not really needed)
* **png** ; or 
* **ppm**, pbm, pgm

(**preferred**)
 to pass-through such image types.

I think, it's possible. why again *.jpg (step 1) ? Never ever use jpg with text files.
Please don't tell the mass about jpeg. Use png, ppm, or tif... I already developed code for this using -c textonly_pdf=1, thanks Yes and no, why can't tesseract do this (pass-through the "bunch of input images") ? Pls. elaborate your step
"Extract the images from the PDF file (don't render!). For this example, we'll assume jpeg."

I use
        pdftoppm -aa yes -r 400 -scale-to-x 2000 -scale-to-y 2800 in.pdf image
 Was there a final resolution to this request for putting back in the original images? @Wikinaut? Yeah, that doesn't work for me: `Could not set option: textonly_pdf=1`

I'm using version 3.05.00 installed via homebrew.  @Jmuccigr I am definitely _not_ happy with the current implementation, and decided some months ago to stay silent and let other users come back with the issue (hoping, that my original proposal - pass-through the original input image without transcoding it - will be implement in forthcoming versions). >I'm using version 3.05.00

The `textonly_pdf` parameter is only available on the HEAD (4.00) @Wikinaut, yeah, my workflow at some point involves adding OCR'ed text to an optimized PDF. Having the OCR step degrade the quality of that PDF kind of spoils it. Just getting back to this now that 3.05.01 has hit homebrew and wanted to say that it seems to be working.

I've tested it out by running text-only tesseract on a 2x version of an image - which tends to give better results if the original dpi is too low - and then combining that text-only PDF with a PDF made from the original image, which keeps the file size down.  @theraysmith 

Ray, Thanks for updating the Wiki page for LSTM training. A few more changes in the following may be required in light of the updates:

> In theory it isn't necessary to have a base Tesseract of the same language as the neural net Tesseract, but currently it won't load without something there.

> Finally, combine your new model with the language model files into a traineddata file:

Please also provide command for building traineddata with just the .lstm file or with just .lstm and lstm-dawgs (so as to minimize traineddata filesize, if only LSTM is going to be used).

 Also helpful will be info on:

1.  how big the training text should be (number of lines) for:

- fine tuning and 
- adding a layer. 

2. what kind of text is recommended/can be used?

- paragraphs, sentences
- word lists
- orthographic syllables

e.g. For Sanskrit, I want to train by adding a layer using a list of most frequent orthographic syllables so that the unicharset is expanded to include all possible aksharas. Will this work?

3. Should training be done using different --ptsize ? If so, is it possible to modify tesstrain.sh to take a list of --ptsize options (similar to the array for exposure --exp). My own question - the answer can also be added to the wiki.

Is it OK to mix b/w images, produced by text2image, with gray and/or color images from book scan? 
 Also, is there a way for tesseract to create line boxes for a scanned image.

It will make it easier to put the truth text if the box dimensions are
pre-made.

- excuse the brevity, sent from mobile

On 13-Jan-2017 2:14 PM, "Amit D." <notifications@github.com> wrote:

> My own question - the answer can also be added to the wiki.
>
> Is it OK to mix b/w images, produced by text2image, with gray and/or color
> images from book scan?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/659#issuecomment-272390460>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o7lvUh_kbAfVygdwAU1ZBpPaiXCaks5rRzlqgaJpZM4LigRu>
> .
>
 >Also, is there a way for tesseract to create line boxes for a scanned image. It will make it easier to put the truth text if the box dimensions are pre-made.

This feature is not implemented. I will try to implement it sometime in the next few days and send a PR. Another question:

what effect does the add a layer type of training have regarding the unicharset in the new traineddata.

For add a layer, a unicharset if required eg. `lstmtraining -U ~/tesstutorial/bih/bih.unicharset` 
Does this

- add to the unicharset from the existing lstm file
- replace the unicharset from the existing lstm file
- replace parts of the unicharset in the existing lstm file

Meaning, if we just want to add a few characters to the unicharset, is it enough to have good sampling of those or do characters from the lstm unicharset (which are unknown at this point) need to be there too. Traineddata files in tessdata for 4.0 were trained with `--perfect_sample_delay 19`. The dafault value for the variable is 4.

The training command examples do not specify this. What are the recommended value to be used for finetuning and adding a layer?

 @theraysmith 

Please see 
https://groups.google.com/forum/#!topic/tesseract-ocr/-N5uPdSvJGA
https://github.com/tesseract-ocr/tesseract/issues/642
https://github.com/tesseract-ocr/tesseract/issues/561

'core dumped' error in these cases seems to be related to using --eval_listfile as part of the lstmtraining command eg.
`--eval_listfile ~/tesstutorial/saneval/san.training_files.txt`

Please update the wiki, if you can confirm this, so that people are able to run the tutorial.

Thanks. @amitdo Question to you, let me explain as briefly as I can:

* I have successfully LSTM ocr-ed 700 pages of a book using `tesseract in.ppm out -l deu --oem 2 txt`.
* I manually corrected the output file out.txt to out.corrected.txt.

I found certain *groups* of ocr failures in my scan case, two examples which were always wrongly detected
* "Citroén" instead of the original word "Citroën"
* "fiir" instead of "für"

#### Question

Is there an easy way - I guess, it could be possible and would be very userfriendly -

* a way to easily retrain a Tesseract language (or a copy) by re-feeding a corrected txt version in order to retrain ?
* What will be the commandline ?
 Hi @Wikinaut!

Believe it or not, I haven't started yet playing with training the LSTM engine, so I don't know enough to answer your question. Hopefully, this serious 'bug' will be fixed sometime in the next month :-)

Some observations: 
Both 'für' and 'fiir' are in the wordlist.
https://raw.githubusercontent.com/tesseract-ocr/langdata/master/deu/deu.wordlist

'ë' does not appear in the training text, 'é' appears 4 times.
https://github.com/tesseract-ocr/langdata/blob/master/deu/deu.training_text

>Café So für
René für
Cafés
André

'für' appears 10 times in the training text.

>OCR Engine modes:
  0    Original Tesseract only.
  1    Neural nets LSTM only.
  2    Tesseract + LSTM.
  3    Default, based on what is available.

Did you try `--oem 1`? @amitdo my original text uses a very "bad" font, where the characters overlap very often, and the characters often look, but are not, "ligatures". This explains the "fiir" in many cases (in my case).

I also tried `--oem 1`. but found, that `--oem 2` gave the best results. However, I did not find an explanation, what this "mixed operation modes" are really doing, pls. can we add a short text to `"2 Tesseract + LSTM", I can supply a PR, but do not know what a correct and short description is.
 @amitdo and regarding my question above, can I "quickly" retrain my "deu" training data (or a copy of it) with a corrected text, this would be really great?

Promise: some mBitcoins for this today! Whoever coded the LSTM: Big APPLAUSE for him or her! LSTM - New OCR engine based on neural networks.
Tesseract - old OCR engine  (started in the mid 80s) - does character segmentation and shape matching.

 @amitdo yes, but what if one selects `--oem 2` ? Are then the results of both engines being compared or otherwise evaluated together ? The two engines runs and the results are combined in some way. :+1:  As said, I have zero experience training the LSTM engine.

What you want is described here:
https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#fine-tuning-for-impact @Wikinaut 

>my original text uses a very "bad" font, where the characters overlap very often, and the characters often look, but are not, "ligatures". This explains the "fiir" in many cases (in my case).

Please provide a sample image for testing. @Shreeshrii 

#### "für" vs.Tesseract: "fiir"

case 1
![20170116-07 50 12_auswahl](https://cloud.githubusercontent.com/assets/1151915/21973387/90011a70-dbc0-11e6-9889-d104dad6822a.png)

case 2
![20170116-07 52 18_auswahl](https://cloud.githubusercontent.com/assets/1151915/21973407/beb10966-dbc0-11e6-8b86-f89117a7918c.png)

case 3
![20170116-07 53 20_auswahl](https://cloud.githubusercontent.com/assets/1151915/21973428/e1ec5bba-dbc0-11e6-9e9a-8e65f50a9d60.png)

#### "Citroën" vs. Tesseract: "Citroén"

Case 1
![20170116-07 54 14_auswahl](https://cloud.githubusercontent.com/assets/1151915/21973442/00e6562e-dbc1-11e6-9176-3394c7078f86.png)

Case 2
![20170116-07 55 12_auswahl](https://cloud.githubusercontent.com/assets/1151915/21973462/225f7678-dbc1-11e6-9e53-0b487fb272a4.png)

 ë is not in the training_text. Needs to be added, hope that @theraysmith  will include in next training.

für - is being recognized -see attached output files.
[e1ec5bba-dbc0-11e6-9e9a-8e65f50a9d60-oem1-png.txt](https://github.com/tesseract-ocr/tesseract/files/707752/e1ec5bba-dbc0-11e6-9e9a-8e65f50a9d60-oem1-png.txt)
[beb10966-dbc0-11e6-8b86-f89117a7918c-oem1-png.txt](https://github.com/tesseract-ocr/tesseract/files/707753/beb10966-dbc0-11e6-8b86-f89117a7918c-oem1-png.txt)
[90011a70-dbc0-11e6-9889-d104dad6822a-oem1-png.txt](https://github.com/tesseract-ocr/tesseract/files/707754/90011a70-dbc0-11e6-9889-d104dad6822a-oem1-png.txt)

though ö was not recognized in one image.

 >ë is not in the training_text. Needs to be added, hope that @theraysmith will include in next training.

https://en.wikipedia.org/wiki/German_language#Orthography
It's not in the a German alphabet. it's from French. Still, maybe it should be included with the deu traineddata. It does looks like 'ii' (two 'i's), doesn't it?

Maybe the training text needs some examples of 'ii' so it can learn to distinguish it from 'ü'. @Shreeshrii in my conversion, these words "für" were recognized as "fiir". May be due to use of "unpaper" as preprocessor, and/or my use of "-l deu+eng --oem 2" for the conversion.

There were many more occurences of false-detecting "fiir" in my about 700 pages of text. This was the most frequent conversion error and triggered me to aksing you how I could retrain tessdata by using my corrected text file. A simple command line would be very helpful for such cases.

@amitdo regarding "ii": In my text, tesseract correctly ocr-ed "ii" in the words "Gummiisolation", and "Daiichi" (a name). @theraysmith You appear to be the expert for answering my question, if such a procedure for re-training (tesseract + LSTM) is easily possible, or not:

(I described it already above:)

Can I "quickly" retrain my "deu" (or "deu+eng") training data (or a copy of it) with a corrected text ?

* in.pdf -> tesseract -> out.txt
* out.txt -> manually corrected -> **corrected.txt**
* retraining tesseract (to get tesseract' )with these inputs: in.pdf + **corrected.txt**

re-running with re-trained tesseract' should in the best case result in
* in-pdf -> tesseract' -> corrected.txt 

I found but do not (yet) understand the present training explanations in the Wiki, and perhaps is my idea not yet covered. @theraysmith Thank you for your swift answer.

In my case, many "für" were detected as "fiir", when or when not using `unpaper` (I cannot remember, because I tried many different runs).

I will retry - and report here - with only `-l deu` in order to present a correct case for reproduction. @theraysmith to be more precise:

I tried tesseract with  `-oem 0, 1, 2` and found that `"2"` gave the best results (for a 700 pages scan). I rerun with and without `unpaper`, and found some differences. And I only used `-l deu+eng`, because my German text used some English terms. Now, as I have a manually corrected reference output text I can present (later) a kind of matrix with the results. New box renderer
https://github.com/amitdo/tesseract/issues/3 @stweil @amitdo Stefan, please can you also make sure that common words with a https://en.wikipedia.org/wiki/Diaeresis_(diacritic) (Deutsch: Trema) like `Citroën` are correctly trained ?
 @stweil Thanks for your swift answers. Let me know, if I can help. Wikinaut, you can try the new best/Latin.traineddata @Wikinaut, 

The best/eng.traineddata doesn't have the marks you want. 

Try the new best/Latin.traineddata.
 The problem with "fiir" instead of "für" is a typical example of the ii / ü confusion which still exists in the current best traineddata. The wordlist for `best/Latin.traineddata` includes "dafiir" (correct: "dafür"), "fiir" (correct: "für") for example. >The problem with "fiir" instead of "für" is a typical example of the ii / ü confusion which still exists in the current best traineddata. The wordlist for best/Latin.traineddata includes "dafiir" (correct: "dafür"), "fiir" (correct: "für") for example.

Try to correct the mistakes in the wordlist and see if it helps to recognize these words. ... or run Tesseract without a wordlist. I recently removed the wordlists from the best traineddata to see and compare the real quality of the trained LSTM data. This is impossible when Tesseract uses a wordlist. With wordlists, Tesseract also invents words which don't occur in the original text ("computer" and "Google" in historical documents).

PS. Is there a parameter which disables the post OCR steps (like wordlist evaluation) in Tesseract without the need to remove the wordlists from the traineddata files? Yes, there is a parameter which disables the wordlist evaluation.

I don't remember its name right now... The parameter is lstm_use_matrix. >I guess, you can make the following two config variables as false to not load the wordlist dawg files. load_system_dawg T
load_freq_dawg       T

load_system_dawg should work.

load_freq_dawg seems to have no impact on the lstm recognizer.


 https://github.com/tesseract-ocr/tesseract/blob/27d25e9c99ca65a2137f54f4c9c2bd20fc050024/dict/dict.cpp#L307 I wonder why LSTM needs its own word list. I'd expect that a word list is different for different languages, and it is also reasonable to use different word lists for different kinds of text (topic, date) of the same language, but it should not depend on the OCR algorithm.  @DanBloomberg

Can you suggest a way for improving text line finding?

ref: http://www.dicklyon.com/phototech/PhotoTech_11_DocImage_Slides.pdf

See https://github.com/tesseract-ocr/tesseract/files/696122/ara.TRAINING.zip for box/tiff pairs and https://drive.google.com/file/d/0B1JdJ8IXNweRX3NEMkZfX3gtdlk/view?usp=sharing for  some sample image files for Arabic.

For Devanagari samples see https://github.com/tesseract-ocr/langdata/issues/40

 Improve with respect to what?   What is in leptonica?  What is in tesseract?

Have you looked at these prog files:
    arab_lines.c
    livre_figures.c Dan,

Thanks for your prompt response and links to the appropriate leptonica program files. 
https://github.com/DanBloomberg/leptonica/blob/master/prog/arabic_lines.c
https://github.com/DanBloomberg/leptonica/blob/master/prog/livre_pageseg.c
I will take a look at those. 

FYI,  I am not a C programmer. I am interested in good open source OCR for Indian languages and am trying out/testing tesseract for that. I am looking for improvement in tesseract in correctly identifying the textlines for complex scripts such as devanagari etc so as to get a more accurate OCR at the end. I also tested recently for Arabic text with diacritics.

A search yesterday led to your presentation on the net. Since tesseract uses leptonica already, I thought that you might be able to suggest better ways of textline finding in tesseract, specially for Arabic Diacritics, Devanagari script etc. (I have edited the earlier post with links to some sample files).

I am building the leptonica programs now and will try out the arabic_lines program on your sample image as well as other samples provided by Arabic users of tesseract.

 I tried arabic_lines with both arabic diacritics and devanagari sample and it is marking the texlines well. Results attached. 
![result-arabic-diacritics](https://cloud.githubusercontent.com/assets/5095331/22008592/a8101138-dca2-11e6-8d85-a0cbcc078304.png)
![result-deva](https://cloud.githubusercontent.com/assets/5095331/22008595/a814004a-dca2-11e6-99e6-26cedd4bc4e3.png)
![textlines-arabic-diacritics](https://cloud.githubusercontent.com/assets/5095331/22008594/a8129854-dca2-11e6-848e-4378a24beb26.png)
![textlines-deva](https://cloud.githubusercontent.com/assets/5095331/22008593/a811e328-dca2-11e6-9f39-977c3942e622.png)



 For reference, these are the two input images used with arabic_lines.

![arabic0](https://cloud.githubusercontent.com/assets/5095331/22050368/4f644e82-dd60-11e6-9d37-5cb1b2696392.png)
![arabic-deva1](https://cloud.githubusercontent.com/assets/5095331/22050369/4f6ac992-dd60-11e6-8160-57b84a1bd464.png)
 Yes, the colors tell you at a glance if you've broken or merged textlines.

Of the 4 bad merges that you show (6 lines into 2), all but one are
trivially fixed with small changes in the morphology parameters.  I'll do
some experimenting.

  -- Dan

On Mon, Jan 23, 2017 at 11:28 AM, theraysmith <notifications@github.com>
wrote:

> Not so good as you might think?
> Aren't the 3 yellow lines near the top and the 3 orange lines at the bottom
> supposed to be different colors?
> I think they have been fused into one line.
>
> On Mon, Jan 16, 2017 at 9:20 PM, Shreeshrii <notifications@github.com>
> wrote:
>
> > I tried arabic_lines with both arabic diacritics and devanagari sample
> and
> > it is marking the texlines well. Results attached.
> > [image: result-arabic-diacritics]
> > <https://cloud.githubusercontent.com/assets/5095331/22008592/a8101138-
> dca2-11e6-8d85-a0cbcc078304.png>
> > [image: result-deva]
> > <https://cloud.githubusercontent.com/assets/5095331/22008595/a814004a-
> dca2-11e6-99e6-26cedd4bc4e3.png>
> > [image: textlines-arabic-diacritics]
> > <https://cloud.githubusercontent.com/assets/5095331/22008594/a8129854-
> dca2-11e6-848e-4378a24beb26.png>
> > [image: textlines-deva]
> > <https://cloud.githubusercontent.com/assets/5095331/22008593/a811e328-
> dca2-11e6-9f39-977c3942e622.png>
> >
> > —
> > You are receiving this because you were assigned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/657#
> issuecomment-273025064>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AL056Up0oVZPWQ2YcPpA-
> pm4Ju1d_k_lks5rTE-BgaJpZM4LiGKh>
> > .
> >
>
>
>
> --
> Ray.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/657#issuecomment-274591196>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLNQvLtkSc1Z9yzubMWNO6hM6YwX8ks5rVP9dgaJpZM4LiGKh>
> .
>
 I've finished experimenting and will push some modified code to leptonica
to make this a bit more robust.

Changes will be in both pixExtractTextlines() and the demonstration code in
prog/arabic_lines.

  -- Dan

On Mon, Jan 23, 2017 at 11:35 AM, Dan Bloomberg <dan.bloomberg@gmail.com>
wrote:

> Yes, the colors tell you at a glance if you've broken or merged textlines.
>
> Of the 4 bad merges that you show (6 lines into 2), all but one are
> trivially fixed with small changes in the morphology parameters.  I'll do
> some experimenting.
>
>   -- Dan
>
> On Mon, Jan 23, 2017 at 11:28 AM, theraysmith <notifications@github.com>
> wrote:
>
>> Not so good as you might think?
>> Aren't the 3 yellow lines near the top and the 3 orange lines at the
>> bottom
>> supposed to be different colors?
>> I think they have been fused into one line.
>>
>> On Mon, Jan 16, 2017 at 9:20 PM, Shreeshrii <notifications@github.com>
>> wrote:
>>
>> > I tried arabic_lines with both arabic diacritics and devanagari sample
>> and
>> > it is marking the texlines well. Results attached.
>> > [image: result-arabic-diacritics]
>> > <https://cloud.githubusercontent.com/assets/5095331/
>> 22008592/a8101138-dca2-11e6-8d85-a0cbcc078304.png>
>> > [image: result-deva]
>> > <https://cloud.githubusercontent.com/assets/5095331/
>> 22008595/a814004a-dca2-11e6-99e6-26cedd4bc4e3.png>
>> > [image: textlines-arabic-diacritics]
>> > <https://cloud.githubusercontent.com/assets/5095331/
>> 22008594/a8129854-dca2-11e6-848e-4378a24beb26.png>
>> > [image: textlines-deva]
>> > <https://cloud.githubusercontent.com/assets/5095331/
>> 22008593/a811e328-dca2-11e6-9f39-977c3942e622.png>
>> >
>> > —
>> > You are receiving this because you were assigned.
>> > Reply to this email directly, view it on GitHub
>> > <https://github.com/tesseract-ocr/tesseract/issues/657#issue
>> comment-273025064>,
>> > or mute the thread
>> > <https://github.com/notifications/unsubscribe-auth/
>> AL056Up0oVZPWQ2YcPpA-pm4Ju1d_k_lks5rTE-BgaJpZM4LiGKh>
>> > .
>> >
>>
>>
>>
>> --
>> Ray.
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/657#issuecomment-274591196>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AP6mLNQvLtkSc1Z9yzubMWNO6hM6YwX8ks5rVP9dgaJpZM4LiGKh>
>> .
>>
>
>
 @theraysmith 

Maybe ocropy's lines finding algorithm can help. AFAIK, it was designed to work well with Arabic. 
https://github.com/tmbdev/ocropy/blob/master/ocropus-gpageseg

See this remark:
https://github.com/tmbdev/ocropy/issues/46#issuecomment-112153537

It should be given a block with uniform size font. I would like to give these hints to the developers: 
In Arabic there are to kinds of diacritics
1- letter attached diacritics (dots like ب ت ج ث and أ آ ؤ) which stick to the letter and is mandatory
2. Vowel diacritics like ( ْ ّ َ   ً    ِ  ٍ   ) used with letters any letter can be conjunct/combined with it and is optional. Kids learn it to read properly as it help get rid of ambiguity, because عَلم and عِلم are two different words but we use the context to distinguish when vowel diacritics are absent.

N.B. 
لَاْ إِلَهَ إٍلا الله note that this َ   ِ  are different vowels has same shape exactly but used differently e.g. أَ is pronounced a while ِأ pronounced e. one used above letter latter used below letter.


bottom line: vowel diacritics in Arabic should be recognized alone (e.g separate box) (but I am thinking how to distinguish between the above case if it is the same box!!!) because it can be on any letter and is limited ( ّ  َ  ً  ُ  ٌ ِ   ٍ   ْ  ) special case also this ّ  can be conjunct/combined with other vowel diacritics also   ًّ    ّْ  

it is limited as entity but can be heavily repeated on letter because every letter has the capability to combined with

hope this could help Tesseract developers  I'm having a problem with number 8, it is read as 3...
I'm usin PSM 6, language english and pattern A to Z, 0 to 9 and ":" to ";"
Result:
![image](https://cloud.githubusercontent.com/assets/1447491/21891559/67411cec-d8ba-11e6-8fdd-98fb73780d66.png)

I already change PSM, but no success.
Anyone can help?  In order to minimize the RTL/LTR effect, I created a training text file with arabic language text, one word per line. However the image generated by text2image has some pages with RTL text and some with LTR text i.e. aligned with right margin and left margin.

[ara.one-word-per-line.zip](https://github.com/tesseract-ocr/tesseract/files/701624/ara.one-word-per-line.zip)
 This behaviour is controlled by the pango library that text2image uses. It's also happening with gedit, which  also uses pango.  https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-271987456

>Indic may be troubled by the length of the compressed codes used.

@theraysmith Can you explain a little more about this? 

 Devanagari script has a large set of ligature forms forms for consonant conjuncts. These are combinations of Consonant + Viraama + Consonant (CVC) or CVCVC or even rarer CVCVCVC. 

Currently the generated unicharset uses the combination of the conjunct ligatures followed by vowel maatraas as well as vowel modifiers as a recognition unit, leading to unicharset of 5000+ lines.

You may want to consider recognizing the conjunct cluster as a unit and vowel maatras and vowel modifiers separately. A special case can be the i maatraa that comes before (to the left of)  the consonant for Devanagari.

For a listing of orthographic syllables by frequency for Sanskrit, please see 
http://www.sanskritweb.net/itrans/ortho2003.pdf

For a  list of ligature sets for Hindi, please see
http://tdil-dc.in/tdildcMain/articles/82170Devanagari%20Script%20Behaviour%20for%20Hindi%20%20ver%201.4.10.pdf Font Comparison Samples 

* http://sanskritlibrary.org/Sanskrit/pub/chars.pdf

* http://www.sanskritweb.net/itrans/itmanual2003.pdf Pages 43-75

Attested Hindi Ligatures

* http://www.sanskritweb.net/itrans/itmanual2003.pdf Pages 110-130 Ray,

Thank you for explaining regrading unicharset compression and your new
strategy for Indic graphemes.

Since the unicharset is being used as a filter, it will be important to
include the most common conjunct clusters in it, which may differ from
language to language.

Some more questions

Are the desired_characters and forbidden_characters used in the process of
creating the text corpus for different languages?

How many text lines are you using for training of Devanagari, e.g.
Sanskrit, Hindi, Marathi etc. Is it all/only from Wikipedia?



- excuse the brevity, sent from mobile

On 21-Jan-2017 3:34 AM, "theraysmith" <notifications@github.com> wrote:

> The LSTM recognizer is currently trained to recognize the sequence of
> *unicodes* for Indic languages. This reduces the size of the output
> softmax of the network from the 5000+ elements in the unicharset to ~140.
> (There is an analogous process for Chinese, Japanese, and Korean, that
> doesn't use the unicode encoding, but it is a similar idea, and the codes
> are strictly limited in length.)
> The unicharset is used as a *filter* in the beam search to allow only
> sensible grapheme/syllable combinations of unicodes, so it doesn't output
> complete garbage text.
>
> The consequence of this recoding is that it runs a lot faster, but it has
> to learn to output a long sequence for each grapheme/syllable.
> The recoding system that maps from unicharset elements to the sequence of
> unicodes currently only allows a maximum of 9 unicodes per
> grapheme/syllable, including any viramas.
>
> I'm running a new training experiment this weekend to try a new coding
> scheme, in which pairs are mapped to a single code, allowing a long CVCVCVC
> string to be encoded using just CCCC, cutting down from 7 codes to 4. This
> will probably increase the size of the output softmax to ~170, but reduce
> the length of the average code sequence by about 1/3, which might be easier
> for it to learn, without slowing it down much.
>
> It will take a couple of weeks to tell if it works, but if it does I will
> check in the code, and upload new traineddatas, and close this issue. If it
> doesn't work, I will have to think again...
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/654#issuecomment-274192153>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o-xusyCIFbh-wE4T4cp4mVb4oBWWks5rUS9vgaJpZM4LhbNY>
> .
>
 Ray,

Thank you for the info on corpus building.

I have added links for resources for bih and snd in the langdata repo just now. Please see

* https://github.com/tesseract-ocr/langdata/issues/39 (Bihari)

* https://github.com/tesseract-ocr/langdata/issues/42 (Sindhi in Arabic script)

I also added a link to this discussion at https://github.com/tesseract-ocr/tesseract/issues/622 for support regarding Khmer.

I will forward your post in the tesseract-ocr group for reach other community members too. >I recently stopped training chr, iku, khm, mya after discovering that I
have no rendered textlines that contain anything other than digits and
punctuation.

@theraysmith

I tried creating training data for khmer and was able to create box/tiff pairs with khmer text. It is possible that the fonts directory you used did not have khmer fonts or for some reason 'latin' fonts were used instead of khmer fonts. I will post the files separately under an issue in langdata.

I used --find_fonts function of text2image to find the fonts that covered 70℅ of the khmer training text. 

It maybe useful in the training process to check the given font list for coverage and give an error or warning if it falls below a certain threshold, before going ahead with building the box tiff pairs.

edit: --oem 0 works with the khm.traineddata, --oem 1 recognizes it incorrectly. ```

text2image --find_fonts \
--fonts_dir /usr/share/fonts \
--text ./langdata/ara/ara.training_text \
--min_coverage .8  \
--outputbase ./langdata/ara/ara \
|& grep raw | sed -e 's/ :.*/" \\/g'  | sed -e 's/^/  "/' >./langdata/ara/fontslist.txt

```
Commands similar to above can be used for getting a fontlist that can be plugged into language-specific.sh to ensure that it calls fonts that are available on the system and have adequate coverage. Here is the output file from the above on my system.

```
  "Arial" \
  "Arial Bold" \
  "Courier New" \
  "Courier New Bold" \
  "DejaVu Sans" \
  "DejaVu Sans Bold" \
  "DejaVu Sans Mono" \
  "DejaVu Sans Mono Bold" \
  "FreeMono" \
  "FreeMono Bold" \
  "FreeSerif" \
  "FreeSerif Bold" \
  "Times New Roman," \
  "Times New Roman, Bold" \
```

 Ray: Regarding Myanamar, please see discussion on https://github.com/tesseract-ocr/langdata/issues/13

> We have 2 types of unicode font. Non standard unicode font and standard unicode font. When I check langdata files for Burmese, most words are incorrect. I guess you have generated mixed contents with non standard unicode contents and standard unicode contents. 

> https://my.wikipedia.org/
All contents on wikipedia are in standard unicode font.

http://crubadan.org/languages/my lists three primary sources for Myanmar/Burmese. One is the myanmar wikipedia, the other two are:

http://www.unicode.org/udhr/d/udhr_mya.html

http://www.jw.org/mya/

Also see: https://github.com/tesseract-ocr/langdata/issues/46

> Myanmar wordlists
https://github.com/kanaung/wordlists

> https://github.com/kanyawtech/myanmar-karen-word-lists/blob/master/burmese-word-list.txt?raw=true

> https://en.wiktionary.org/wiki/Appendix:Burmese_basic_vocabulary

You may also find the charts at http://www.virtualvinodh.com/wp/character-matrix/ useful for a comparison of various Indic scripts. please see rows for Burmese for Mynamar. Hey Ray,
Can you please explain the training process of tesseract-ocr with LSTM ?  Having an easily accessible unicharset will be useful for:

1. Checking whether to do fine-tune training or add a layer. e.g. if a required character is not in the unicharset within the lstm file then finetune does not work.

2. For viewing the wordlist/dictionary included in the dawg file in traineddata.

3. For replacing the wordlist/dictionary dawg-file in the traineddata.

4. For processing the user-words file. (Also see issue https://github.com/tesseract-ocr/tesseract/issues/403) https://github.com/tesseract-ocr/tesseract/commit/dc8745e6fd4c Some more changes are needed to fix this issue. >Is Wordstr format supported with the new commits?

It's not yet supported. This issue was solved by Ray.

@theraysmith or @zdenop, please close this issue.
  ![screenshot_2017-01-11-14-20-01](https://cloud.githubusercontent.com/assets/24853541/21851986/5328de5e-d809-11e6-90f4-f207dddfb829.png)
What it mean ?  running training process for Sanskrit - Devanagari script, throws up errors such as the following, when using --debug_interval -1

```
Iteration 5010: ALIGNED TRUTH : द्ध्वा ल्गु ज्<Undecodable><Undecodable><Undecodable> द्द स्तू स्त्रे द्यो शाः स्वे न्ह 

Iteration 5034: ALIGNED TRUTH : खं चः द्धो ङ्गा भौ न्यं न्यु ज्<Undecodable><Undecodable> त्कृ वां निः

Iteration 5068: ALIGNED TRUTH : व्यः श्मि क्ष्ण खाः टी णिं त्सै न्तां ल्म ष्<Undecodable><Undecodable><Undecodable>
```

The relevant lines from training text are:

```
द्ध्वा ल्गु ज्ञां द्द स्तू स्त्रे द्यो शाः स्वे न्ह नुः

खं चः द्धो ङ्गा भौ न्यं न्यु ज्ञे त्कृ वां निः 

व्यः श्मि क्ष्ण खाः टी णिं त्सै न्तां ल्म ष्टिं 
```

Specifically the syllables giving error in this sample are `ज्ञां` `ज्ञे `ष्टिं`.

While first part of the conjunct is decoded, the later parts are not.


| Syllable | Devanagari characters | Unicode code points |
|---|---|---|
| ज्ञां | ज  ्  ञ  ा  ं  | U+091C U+094D U+091E U+093E U+0902 |
| ज्ञे | ज  ्  ञ  े | U+091C U+094D U+091E U+0947 |
| ष्टिं | ष  ्  ट  ि  ं | U+0937 U+094D U+091F U+093F U+0902 |
------------------------------------ These are there in san.unicharset being used by the training process.

```
ज्ञां 1 3,76,61,242,294,446,0,0,294,446 Devanagari 27 0 27 ज्ञां	# ज्ञां [91c 94d 91e 93e 902 ]x

ज्ञे 1 3,76,61,255,251,423,0,0,251,423 Devanagari 27 0 27 ज्ञे	# ज्ञे [91c 94d 91e 947 ]x

ष्टिं 1 3,76,61,253,238,384,0,0,238,384 Devanagari 52 0 52 ष्टिं	# ष्टिं [937 94d 91f 93f 902 ]x
``` ```
Iteration 18247: ALIGNED TRUTH : مْهُعَبِاصَأَ نَولُعيَ<Undecodable><Undecodable> قٌربَوَ دٌعْرَوَ تٌامَلُظُ
Iteration 18247: BEST OCR TEXT : مْهُعَبِاصَأَ نَولُعيَ<Undecodable><Undecodable> قٌرْبَوَ دٌعْرَوَ تٌامَلُظُ
```  @theraysmith @amitdo @Shreeshrii 
- **Box file disorder**
The Arabic box file generate using Tesseract 4.x is in LTR ( Left to Right ) which is reversed, the Arabic language is from RTL ( Right to Left ). That means that **the first box should start from from the right side.**
( Have a look at the **wrong and disorder Tesseract 4.0x Arabic box file** )
[ara.Traditional_Arabic.exp0.zip](https://github.com/tesseract-ocr/tesseract/files/697557/ara.Traditional_Arabic.exp0.zip)


Tesseract 4.0 lstm puts the spaces between the words into boxes, as you know. 
Thus a problem arises caused by the **box file disorder** since the boxes are **mistakenly** set to be in LTR ( Left to Right ) for Arabic which is wrong, causing jumps from ( the end of the first line) to ( the end of the last letter of the line after it).
See the image attached 
![box disorder](https://cloud.githubusercontent.com/assets/16248376/21826462/9df37064-d798-11e6-8987-f51195ab66e0.jpg)


( Now have a look at the attached correct order of Arabic example tif/box of version Tesseract 3.05).
[Arabic example 1.zip](https://github.com/tesseract-ocr/tesseract/files/697435/Arabic.example.1.zip)
Example 1, correct box order:
![right order](https://cloud.githubusercontent.com/assets/16248376/21826948/989c02fa-d79a-11e6-9790-6d27c9404373.jpg)

 While tesstrain.sh takes into account RTL languages while creating the DAWG files, text2image process does not seem to have specific RTL processing. will there be modifications for text2image ? What you show here is 'by design'. This should not cause any problem in training process and characters recognition for RTL languages. Ray,
There seems to be a bug. I have tried training a couple of times to 2-3% char error rate. But the OCRed text seems to be way off. During training, it seems that the diacritics are being recognized well., eg.
```
Iteration 1702: ALIGNED TRUTH : انَدبْعَ ىلَعَ انَلْنَ امَّمِ بٍيْرَ يفِ مْتُنْكُ نْإِوَ نَومُلَعْتَ مْتُنْأوَ ادًادَنْأ هِللِ اولُعَجْتَ الَفَ مْكُل
Iteration 1702: BEST OCR TEXT : انَيبْعَ ىلَعَ انَلْنَ اهَمِ بِيْرَ يفِ مْتُنَ نْإوَ نَوهُلَمْتَ مْتُأوَ اذَادَنأ هِلَلِ اولُعَجْتَ الَفَ مْكُلَ
```

But the OCRed text does not seem to include any.

[ara.Arial_Unicode_MS.exp0.txt](https://github.com/tesseract-ocr/tesseract/files/699108/ara.Arial_Unicode_MS.exp0.txt)
[ara.Calibri.exp0.txt](https://github.com/tesseract-ocr/tesseract/files/699109/ara.Calibri.exp0.txt)
[ara.Arial.exp0.txt](https://github.com/tesseract-ocr/tesseract/files/699110/ara.Arial.exp0.txt)

@christophered  and @bmwmy can provide Arabic specific details. https://github.com/tesseract-ocr/tesseract/files/696122/ara.TRAINING.zip has the box tif pairs for the above training.

https://github.com/tesseract-ocr/tesseract/files/696184/traininglog-mid.txt shows the debug messages from during training. >I wonder if the bidi integration is working correctly for LSTM, as the accuracy with Arabic is unsatisfactory.

Ray,

According to your tests, how does Hebrew (another RTL language) perform?

Do you have accuracy report for various languages that you can share with us, other than the one in the DAS2016 slides? @theraysmith Hope you have seen comments by Chris on the other thread also - https://github.com/tesseract-ocr/tesseract/issues/642

> i was merging the letter extender with the Arabic letter into one single box, and putting that Arabic letters as the character of the box, basically, i was trying to train the engine to recognize that Arabic letter in it's multiple positions, as you know the Arabic letters have multiple forms based which is based on it's position in the word ( beginning, middle, ending, isolated )
Example:
( كـ ) is not ( ك + ـ ) in the box file, it should be ( ك )
also ( ـكـ ) or ( ـك ) they are a single character ( ك ) in different positions, this is important in the box file.

> Which also means that ( كَـ ) is not ( ك + ـَ ), it is ( كَ )
 @theraysmith 

>    - The diacritics are currently excluded from the unicharset, probably
   because they are only rarely used, but need to be included. There may not
   be enough text with them included in the text corpora.

Ray,
Please see https://github.com/tesseract-ocr/tesseract/issues/552 and https://github.com/tesseract-ocr/langdata/issues/35

Arabic Diacritics are included in the Arabic.unicharset. 

@bmwmy had offered to provide additional training text with diacritics - see https://github.com/tesseract-ocr/tesseract/issues/552#issuecomment-269961851

I was able to get the diacritics recognized during training by adding the following line to ara.config, however for some fonts it seems to be treating diacritics as a separate line. Do not know whether it is related to x-height for fonts. 
```
#Diacritics
textord_min_linesize 2.5
```
Related question, for lstm training, I am using
```
--noextract_font_properties
```

while creating the box tiff pairs and lstmf files since @amitdo mentioned that font_properties are not needed for LSTM training, please confirm. Please also see https://github.com/tesseract-ocr/tesseract/issues/318#issuecomment-218381668 and other comments regarding unicharset. 

Are the glyph metrics updated based on the fonts used for training? 
Are glyph metrics used for LSTM training? 

Answer:

**No. Most of the unicharset fields are irrelevant to LSTM training and recognition.
_The mirror and normalized string fields ARE important though.**_ I examined @Shreeshrii  training set and I appreciate his effort, but seems the text in generated tiffs image files are very small than it should be. It is hard to read even for humans. The vowel diacritics looks like noise also some letter glyphs as ( فـ /  ـمـ ). I suggest using 16-22pt font. 
Also this:
Iteration 1702: ALIGNED TRUTH : انَدبْعَ ىلَعَ انَلْنَ امَّمِ بٍيْرَ يفِ مْتُنْكُ نْإِوَ نَومُلَعْتَ مْتُنْأوَ ادًادَنْأ هِللِ اولُعَجْتَ الَفَ مْكُل
Iteration 1702: BEST OCR TEXT : انَيبْعَ ىلَعَ انَلْنَ اهَمِ بِيْرَ يفِ مْتُنَ نْإوَ نَوهُلَمْتَ مْتُأوَ اذَادَنأ هِلَلِ اولُعَجْتَ الَفَ مْكُلَ
are reversed order (RTL issue)

comparison between noisy text example which was used in training and good one:
![testdia](https://cloud.githubusercontent.com/assets/24265205/21882655/8d157326-d8bc-11e6-8a6a-7e6e6d49120e.png)

I think using bigger text image input will result in very high improvement. I am satisfied with this result taking in consideration this noisy input but (RTL issue) should be solved.

@christophered  ara.Traditional_Arabic.exp0.zip was good input image file
but @Shreeshrii  https://github.com/tesseract-ocr/tesseract/files/696122/ara.TRAINING.zip  is noisy input image. About `--noextract_font_properties` . Ray confirmed it here:
https://github.com/tesseract-ocr/tesseract/issues/634#issuecomment-272027231
 >Are glyph metrics used for LSTM training?

I believe the answer is 'No'.

@theraysmith, can you confirm that? @amitdo I have been training using `--noextract_font_properties` since you brought it to my notice.

However, I am wondering whether some type of fontinfo / xheights is still required for LSTM training.

eg. in order to avoid the diacritics being discarded as noise, I had to add `textord_min_linesize 2.6` in ara.config. But different fonts have different sizes, even at same point size. I had to play with different values, but couldn't figure out a value that would work with multiple fonts.

So, I am trying the training again with only one font, Traditional Arabic font at 32 point, as suggested by @bmwmy.

Ray might have a different solution - will wait till the changes in wiki for training are updated.

  `textord_min_linesize` is a hint for the layout analysis step in Tesseract.

If the layout analysis step does not 'cut' the lines properly, the next step - the lines' text recognition, will suffer. [Tesseract release notes July 11 2015 - V3.04.00](https://github.com/tesseract-ocr/tesseract/wiki/ReleaseNotes#tesseract-release-notes-july-11-2015---v30400)

>Major change to improve layout analysis for heavily diacritic languages: Thai, Vietnamese, Kannada, Telugu etc.

From DAS2016 slide 5 - 'Page Layout Analysis':
>Tesseract's existing text-line finding is also weak wrt diacritics,
especially for Arabic and Thai. > There is Bidi processing inside the post-recognition processing of
Tesseract that reprocesses/re-orders the text for output, so it appears in
the correct order.

>>Iteration 1702: ALIGNED TRUTH : انَدبْعَ ىلَعَ انَلْنَ امَّمِ بٍيْرَ يفِ مْتُنْكُ نْإِوَ نَومُلَعْتَ مْتُنْأوَ ادًادَنْأ هِللِ اولُعَجْتَ الَفَ مْكُل
Iteration 1702: BEST OCR TEXT : انَيبْعَ ىلَعَ انَلْنَ اهَمِ بِيْرَ يفِ مْتُنَ نْإوَ نَوهُلَمْتَ مْتُأوَ اذَادَنأ هِلَلِ اولُعَجْتَ الَفَ مْكُلَ
are reversed order (RTL issue)

@theraysmith 

Ray, Can the bidi post-processing be applied as an experiment to these debug messages? Then we can very easily see whether it is working.
>Answer: No. That would be very difficult. They are intended to be displayed completely without any RTL smarts. Shree, you might want to use this text2image option with Arabic:  
`--leading  Inter-line space (in pixels)  (type:int default:12)`

As a minimum it should equal to ptsize. For Arabic, you can try to increase it (20-50 percent bigger than ptsize)  IMO, 32 ptsize is too big. Try 14/16. Arabic also has presentation forms i.e. spacing forms of Arabic diacritics, and contextual letter forms.

Please  see 
http://www.alanwood.net/unicode/arabic_presentation_forms_a.html
http://www.alanwood.net/unicode/arabic_presentation_forms_b.html
and
https://github.com/w3c/alreq/wiki/Should-I-use-the-Arabic-Presentation-Forms-provided-in-Unicode%3F

Though, it is not recommended to use these for content under newer versions of unicode, I am wondering whether it will make OCR easier if these were used...

There can be a post-processing step to convert them to regular unicode points later.
 >Are glyph metrics used for LSTM training?

No. Confirmed by Ray here: https://github.com/tesseract-ocr/langdata/issues/31#issuecomment-272261739
>... the glyph metrics aren't used. >Shree, you might want to use this text2image option with Arabic:
--leading Inter-line space (in pixels) (type:int default:12)

> As a minimum it should equal to ptsize. For Arabic, you can try to increase it (20-50 percent bigger than ptsize)

tesstrain.sh process uses default --ptsize which is 12. 

language_specific.sh sets --leading to 32 by default and to 48 for Thai fonts.


 @Shreeshrii here is a sample text for you, please test and post the findings
[Arabic sample variation.zip](https://github.com/tesseract-ocr/tesseract/files/736942/Arabic.sample.variation.zip)

@theraysmith Most if not all languages related to Arabic (example: Farsi, Urdu, etc..) use such diacritics.
The Arabic diacritics are **often** but not always used in the Arabic text, sometimes in all the text, and sometimes at one letter in each word, but believe me the diacritics are frequently used.
Have a look at [The Quran](http://quran.ksu.edu.sa/tafseer/tafheem/sura1-aya1.html#tafheem)
 @Shreeshrii your sample of box/tif that you provided had an some errors that I've notice:
1) The U+640 (tatweel) issue
example: بِسمِ
wrong: ب ـِ س ـِ م
correct: ب س م   only 3 letters بسم
@theraysmith got it right, Tesseract should have the capability to generate it in .tif, but not consider it as a single character in the .box file, the correct thing would be that the box of U+640 (tatweel) be combined with the box of another letter, while setting the box as the character of a single letter, never even mentioning  U+640 (tatweel) in the .box file , ever.
 U+640 (tatweel) is a special case, people dont usually use it while writing text, so dont use it, or merge the boxes and remove it.

2) As @bmwmy mentioned earlier, in your .tif the charachters of the text are seperated, thats wrong. 
wrong: بـ ـسـ ـم
correct: بسم

I tracked the problem, and the cause was the txt that you were using, it contained the 1st U+640 (tatweel) mistake that I mentioned earlier The box tiff pairs are as generated by text2image program.

Any changes to that will have to be done by Ray.

I will test with the files you have provided.

- excuse the brevity, sent from mobile

On 28-Jan-2017 9:30 PM, "chris" <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/Shreeshrii> your sample of box/tif that
> you provided had an some errors that I've notice:
>
>    1.
>
>    The U+640 (tatweel) issue
>    example: بِسمِ
>    wrong: ب ـِ س ـِ م
>    correct: ب س م only 3 letters بسم
>    @theraysmith <https://github.com/theraysmith> got it right, Tesseract
>    should have the capability to generate it in .tif, but not consider it as a
>    single character in the .box file, the correct thing would be that the box
>    of U+640 (tatweel) be combined with the box of another letter, while
>    setting the box as the character of a single letter, never even mentioning
>    U+640 (tatweel) in the .box file , ever.
>    U+640 (tatweel) is a special case, people dont usually use it while
>    writing text, so dont use it, or merge the boxes and remove it.
>    2.
>
>    As @bmwmy <https://github.com/bmwmy> mentioned earlier, in your .tif
>    the charachters of the text are seperated, thats wrong.
>    wrong: بـ ـسـ ـم
>    correct: بسم
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-275856218>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o1m8lCpawdFVw2ywk8nxQgwrn-zKks5rW2YIgaJpZM4Lf-kT>
> .
>
 @theraysmith i suggest that you give capability to convert tesseract 3.0x box files to tesseract 4.0x since many of us have tif/box files based on the older version 3.0x

@theraysmith Also, Ubuntu have released the Snaps project, giving the ability to distribute a software as a universal Linux package. Would it be possible to release a Snappy version on Tesseract 4.0x, this would save us alot of time and effort by skipping the building process and it's issues.
https://www.ubuntu.com/desktop/snappy
http://snapcraft.io/ >There is Bidi processing inside the post-recognition processing of
Tesseract that reprocesses/re-orders the text for output, so it appears in
the correct order.
I wonder if the bidi integration is working correctly for LSTM, as the
accuracy with Arabic is unsatisfactory.

@theraysmith Have you had a chance to look at this? @christophered 

>@Shreeshrii here is a sample text for you, please test and post the findings
Arabic sample variation.zip

Please send me your box file corresponding to the above text. I will add tab characters for new line to test, rather than use text2image generated box files. https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/EOwF1GnOcS0/My_SUf1vEQAJ

> tesseract4 reads الأ as األ which is pretty close, because we need to switch the position of the last 2 letters to have ا ل أ, this happens with similar word forms too like لا reads as ال and should be ل ا, and i wish to correct it. I can't believe my eyes. Ray commented in the users forum.

Shree, you are a magician!

:laughing: :rofl: :laughing:  Here is Ray's response:

>Thanks for spotting this!
I understand why it makes this error, but it will take some thought to fix it properly!
It is using a sort by x-position to re-order the boxes for RTL language training, but that doesn't work in the case of heavily kerned characters like ل in your example.
It needs to simply reverse the RTL characters, but has to avoid messing up the order of the common script, which is why I was using a sort to begin with.
https://github.com/tesseract-ocr/tesseract/blob/master/training/boxchar.cpp#L202
 Here are some libraries that implement the Unicode Bidi algorithm.

https://github.com/behdad/pybyedie
Copyright (C) 2013  Google
License: MIT
Written in: Python

https://github.com/servo/unicode-bidi
By Mozilla
License: Apache 2.0 / MIT
Written in: Rust

https://github.com/behdad/fribidi
License: LGPL 2.1
Written in: C

https://github.com/MeirKriheli/python-bidi
License: LGPL 3.0
Written in: Python
 @theraysmith meanwhile can you give Tesseract 4.x the ability to Train single words each with a single Box.
This feature that I'am suggesting will give the ability to provide Semi-Automatic transcription capabilities. Please help to add space after text in Punjabi(Panjabi or Gurmukhi) sentance.  @theraysmith the recognition rate of the Arabic model is impressive, you really made a big recognition leap from 3.x to 4, Have you managed to solve issue #758 relating to لا is wrongly flipped as ال
![untitled44](https://user-images.githubusercontent.com/16248376/26998676-0e1dbf62-4d90-11e7-8843-57bf3726286f.png)


 @Shreeshrii @amitdo @theraysmith 
I have read [a research that conclude by developing a recurrent neural network
that predicts diacritics in non-diacritized texts for Arabic](http://www.aclweb.org/anthology/D15-1274), how is that possible?
Does that mean if I train an Arabic Model with text that have Arabic diacritic, then use this model to recognize an image with Arabic text that dont have diacritic, the ocr txt result will have diacritics?
is that true? @theraysmith have you solved the problem of لا ? it really effects the error rate
  @theraysmith The main problem is caused by the reorder and normalize function in Tesseract.
Kraken have managed to fix many of the RTL langues bugs, along with using python-bidi, kraken reorder and normalize the writings, including alphabets and even diacritics.
Have a look at: http://kraken.re/ketos.html
https://github.com/mittagessen/kraken

Example, Arabic RTL:
![000021](https://user-images.githubusercontent.com/16248376/28440171-d5e05612-6dad-11e7-9315-d498cd7f1d34.png)

After using Kraken:
# امو مهسفنٔا الٕا نوعدخي امو اونمٓا نيذلاو هللا نوعداخي
Kraken reorder and normalize the text so it could be trained in Left To Right, the reordering can:
- Reverse the text and the marks are moved to the next letter to the right
- Or just reverse the text while maintaining the structure of the marks.

Example, the word أنفسهم it can be converted to:
- مهسفنٔا 
- مهسفنأ

Have a look at the NFD and NFC options

Ray, I hope that you could replicate Kraken's solution, once Tesseract solves this problem, Arabic and Hebrew would be able to achieve the golden recognition rates.
 @theraysmith

Dear Mr.Smith,

I am so grateful for answering my questions.

It came to my mind, maybe it is the problem. I thought, it is not a bad
idea to share it with you.

I think the problem of لا happens because of this:

for example if we have this:

الا انفسهم

Tesseract first reorder it this way:


8

7

6

5

4

3

2

1

ا

لا

ا

ن

ف

س

ه

م


Then it substitutes لا with two separate characters ل ا. So , the sequence
of characters becomes like this:


9

8

7

6

5

4

3

2

1

ا

ا

ل

ا

ن

ف

س

ه

م


After doing OCR, it reorders the characters to show them in the correct
order. So it becomes:


9

8

7

6

5

4

3

2

1

م

ه

س

ف

ن

ا

ل

ا

ا


So, the problem happened.


About the he dropped last space on each line of RTL text output, I have not
faced this problem.


I am really looking forward for the new traineddata I do appreciate your
kind help.

On Fri, Jul 21, 2017 at 7:44 AM, Shreeshrii <notifications@github.com>
wrote:

> @theraysmith <https://github.com/theraysmith>
>
> the dropped last space on each line of RTL text output, (is there an issue
> for that, or am I the only one that noticed?),
>
> I think it is related to issue #1015
> <https://github.com/tesseract-ocr/tesseract/issues/1015>
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-316890698>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAVnhv01Xw6nKogWP_uU8BAPGJYRzks5sQBengaJpZM4Lf-kT>
> .
>
 @theraysmith have a look at some reordering script as an example code,[ reorder.py:](https://gist.github.com/mittagessen/1cefa68d2903b1cd0758574aaa1dd9df)
```
#! /usr/bin/env python

import sys
import glob

from bidi.algorithm import get_display

for f in glob.glob(sys.argv[1] + '/*.txt'):
    with open(f, 'rb') as fp:
        with open(f + '.re', 'wb') as fo:
            fo.write(get_display(fp.read().decode('utf-8')).encode('utf-8')) @hanikh please modify your reply horizontally, you are making the topic hard to go through :sunglasses:  @christophered  
it was this way:
Tesseract first reorder it this way:
8      7      6      5      4      3      2       1
م       ه       س      ف     ن      ا      لا        ا
Then it substitutes لا with two separate characters ل ا. So , the sequence
of characters becomes like this:
9       8      7      6      5      4      3      2       1
م       ه       س      ف     ن      ا      ل          ا       ا
After doing OCR, it reorders the characters to show them in the correct
order. So it becomes:
9       8      7      6      5      4      3      2       1
ا        ا       ل       ا      ن       ف     س    ه         م

So, the problem happened. @theraysmith  that could be a solution ( well not sure ) https://en.wikipedia.org/wiki/Arabic_script_in_Unicode#Contextual_forms
these contextual forms are standard any form other than these can be considered as combination and thus inverted in the output Ray, I intend to open a new issue about Hebrew soon. For Hebrew, see https://github.com/tesseract-ocr/langdata/issues/82 @theraysmith Sorry for taking so long to reply back, I was training lstm models and conducting tests for days to have insight and solution on the matter of Arabic and diacritics.

**Intro:**
What is the Arabic diacritics issue: it's when the ocr engine recognition rate is reduced when introducing a foreign element/mark to the text, in this case diacritics; meaning if the text has few diacritics can the ocr engine recognize the text and achieve decent rates?

**Reply to Ray:**
- Note that you are fully correct in regards to `Tatweel`.
- Note that you are mostly correct in regards to the Arabic diacritical marks, they are mostly optional, but for some conditions are necessary, mostly the `Maddah` & the `Tanwin`.
Nevertheless, nowadays Arabic diacritics are moderately used.
Example of some situations that it is necessary to use marks:
![wer](https://user-images.githubusercontent.com/16248376/28754294-5ae417a0-754b-11e7-82f0-87d22103ed54.png)


**Results of my tests related to diacritics:**
- Training a model with Arabic text, without diacritics
 `100% Recognition rate` on the training data.
`+90% Recognition rate` on scanned documents without diacritics.
Note that it cant recognize words with diacritics.
**Verdict: Suitable for real-life situations, but recognition rate can be further improved.**

- Training a model with Arabic text, the rendered images contains moderate diacritics but the transcription/groundtruth is without diacritics.
 `100% Recognition rate` on the training data.
Note that it cant recognize words without diacritics well.
**Verdict: Fail, not suitable for real-life situations.**

- Training a model with Arabic text, with text containing a mixture of both: lines with few diacritics and lines without diacritics .
`+95% Recognition rate` on the training data.
`+90% Recognition rate` on other images.
Can handle both images with/without diacritics.
**Verdict: Best of All tests, most stable and consistent, the model can recognize text with and without diacritics, has minor mistakes here and there that can be easily corrected via Microsoft Word, suitable for real-life situations.**

**Conclusion:**
The diacritics issue with regards to the Arabic language  can be solved by creating a model with a combination/mixture of both: lines with & without diacritics.
Example, include in your training non-diacritized lines:
![000008](https://user-images.githubusercontent.com/16248376/28755946-039a6152-756e-11e7-86e1-8df15f3f34fd.png)
Also include diacritized lines:
![015401](https://user-images.githubusercontent.com/16248376/28755958-46e6b9c4-756e-11e7-9f00-b5196fbb4223.png)

Certainly, the non-diacritized training data should be more than the diacritized, say +80% non-diacritized.
Thus the model will be able to recognize normal text, and also will know how to handle the few foreign elements if introduced.
 
This problem can be solved by wisely introducing few variations and mixture of data, thus the trained model will be more complex. Therefore, for now, there is no need to modify anything except the training data.

As for Hebrew @amitdo is conductor at https://github.com/tesseract-ocr/langdata/issues/82
 Question
@theraysmith I understand that for training, Tesseract 4.x reorders the Arabic text to tesseracts's reading order, meaning it converts RTL to LTR & then normalizes it.
For normalization, which form does it uses, NFD or NFC?
Example:
![000000](https://user-images.githubusercontent.com/16248376/28756220-cca7bcb2-7572-11e7-937f-80b9ca2c4540.png)
GDT: آمنا بالله إن شئتم الآخرة هم بمؤمنين يا أيها
NFD: اهئا اي نينمٔومب مه ةرخٓالا متٔيش نٕا هللاب انمٓا
NFC: اهيأ اي نينمؤمب مه ةرخآلا متئش نإ هللاب انمآ

The difference between NFD vs NFC, is that after the text is is reordered to LTR for training, NFD pushes the marks/diacritics to the right-side, while in NFC the marks/diacritics remain on the characters itself. text2image should have an option to randomly add tatweel every n lines.

https://en.wikipedia.org/wiki/Kashida

>Kashida is generally only used in one word per line and applied to one letter per word. 

>Furthermore, kashida is recommended only between certain combinations of letters (typically those which cannot form a ligature).
 @amitdo No, No.......! That is very bad
Tatweel reduces the recognition rate, and makes the model unstable and confused `theoretically speaking`
Ray stated earlier that he have fixed the tatweel problem, he even gave the option to render it if you want to,  but it will be removed as a singular sole character from the training data.
I think he solved this issue by Merging the tatweel Box with the earlier glyph box, and removing the tatweel as a character, the final remainder is 1 box with the earlier glyph. >For normalization, which form does it uses, NFD or NFC?

It seems it uses NF**K**C. Hi @christophered, I don't think you understood my meaning.

I Re-read what Ray said in this issue.

>it needs to be preserved in the training text, so it gets rendered

>I understand that tatweel is a rendering artifact, that should be rendered for training, but not occur in the output text (or in the language model).

>The tatweel and ligature problem are fixed and will be corrected in the new traineddatas coming soon

So it seems he already implemented (but didn't push yet) what I just now suggested.


 text2image is the program that **renders** images from ground truth.

>text2image should have an option to randomly add tatweel every n lines.

'add' here means 'render'.


 the new version of traineddata has been uploaded a lot of time ago.

On Sat, Sep 9, 2017 at 10:07 AM, Shreeshrii <notifications@github.com>
wrote:

> @theraysmith <https://github.com/theraysmith>
>
> Thanks for these updates.
>
> Does the complete fix for RTL languages also require new traineddata
> created with these fixes?
>
> Will you be uploading a new version of traineddata?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-328256183>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAfGrAIkJiFceO2zo3iNI77Q7sz9Dks5sgiQGgaJpZM4Lf-kT>
> .
>
  I found the a desired character file in source training data. So I guessed that in language.traineddata there is information of desired character. How can I add my unique character like ↑↓ into trained language?  See comment from Ray at 
https://github.com/tesseract-ocr/tesseract/issues/542#issuecomment-265569774

> it doesn't run the eval from the trainer.
It doesn't harm the tutorial, but will be required before people start serious training.
 with --eval_listfiles , always coredump. 😭

lstmtraining: ../ccutil/genericvector.h:696: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
 No, I did not see that assertion up to now. How can it be reproduced? The non-debug build continues, but uses a bad index internally, so the results are invalid.

Replace `assert` (which is only used in debug builds) by `ASSERT_HOST` in `ccutil/genericvector.h`, then the non-debug build should show an error, too.

Can you get a stack trace for the assertion? @Shreeshrii, please open a new issue about that regression. @Shreeshrii, I am sorry, but somehow my last comment got lost. So once again:

The assertions are caused by an index of 0 used for an empty vector. Since commit 907de5995f698e2a01da25fa09f8cadaf31a095f the constructor of GenericVector no longer allocates memory for an empty vector. `tesseract::LSTMTrainer::ReadTrainingDump` tries to read 0 bytes. Issue #561 is identical. Here is a patch which fixes the assertion / core dump:

    diff --git a/lstm/lstmtrainer.cpp b/lstm/lstmtrainer.cpp
    index 03619969..e6d8e4a3 100644
    --- a/lstm/lstmtrainer.cpp
    +++ b/lstm/lstmtrainer.cpp
    @@ -918,6 +918,7 @@ bool LSTMTrainer::SaveTrainingDump(SerializeAmount serialize_amount,
     // Reads previously saved trainer from memory.
     bool LSTMTrainer::ReadTrainingDump(const GenericVector<char>& data,
                                        LSTMTrainer* trainer) {
    +  if (data.size() == 0) return false;
       return trainer->ReadSizedTrainingDump(&data[0], data.size());
     }

I don't know whether returning `true` would be better. I tried to analyze the problem ("why is there a data size 0?") and noticed that the behavior of the program is totally erratic when I run it in a debugger. There are several threads involved, and depending on my breakpoints the problem with the data size occurs or not. That looks like a synchronization issue, and so I decided to use Valgrind. The result is horrible:

    ==2035== ERROR SUMMARY: 44846954 errors from 905 contexts (suppressed: 0 from 0)

Here is one example (total log file is about 28000 lines):

    ==2035== Conditional jump or move depends on uninitialised value(s)
    ==2035==    at 0x1497ED: ComputeBlackWhite (networkio.cpp:140)
    ==2035==    by 0x1497ED: tesseract::NetworkIO::FromPixes(tesseract::StaticShape const&, std::vector<Pix const*, std::allocator<Pix const*> > const&, tesseract::TRand*) (network
    io.cpp:190)
    ==2035==    by 0x1498FF: tesseract::NetworkIO::FromPix(tesseract::StaticShape const&, Pix const*, tesseract::TRand*) (networkio.cpp:164)
    ==2035==    by 0x1BBB41: tesseract::Input::PreparePixInput(tesseract::StaticShape const&, Pix const*, tesseract::TRand*, tesseract::NetworkIO*) (input.cpp:149)
    ==2035==    by 0x1C9842: tesseract::LSTMRecognizer::RecognizeLine(tesseract::ImageData const&, bool, bool, bool, float, float*, tesseract::NetworkIO*, tesseract::NetworkIO*) (lstmrecognizer.cpp:281)
    ==2035==    by 0x13DE72: tesseract::LSTMTrainer::PrepareForBackward(tesseract::ImageData const*, tesseract::NetworkIO*, tesseract::NetworkIO*) (lstmtrainer.cpp:855)
    ==2035==    by 0x13E5E3: tesseract::LSTMTrainer::TrainOnLine(tesseract::ImageData const*, bool) (lstmtrainer.cpp:798)
    ==2035==    by 0x11290E: TrainOnLine (lstmtrainer.h:273)
    ==2035==    by 0x11290E: main (lstmtraining.cpp:194)
    ==2035==  Uninitialised value was created by a heap allocation
    ==2035==    at 0x4C2BBAF: malloc (vg_replace_malloc.c:299)
    ==2035==    by 0x72052A0: pixCreateNoInit (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==2035==    by 0x72053F6: pixCreateTemplateNoInit (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==2035==    by 0x7208917: pixCopyBorder (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==2035==    by 0x71921EF: pixUnsharpMaskingGray2D (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==2035==    by 0x7192D99: pixUnsharpMaskingFast (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==2035==    by 0x7193014: pixUnsharpMasking (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==2035==    by 0x728C454: pixScaleGeneral (in /usr/lib/x86_64-linux-gnu/liblept.so.5.0.1)
    ==2035==    by 0x1663DF: tesseract::ImageData::PreScale(int, int, float*, int*, int*, GenericVector<TBOX>*) const (imagedata.cpp:245)
    ==2035==    by 0x1BBA33: tesseract::Input::PrepareLSTMInputs(tesseract::ImageData const&, tesseract::Network const*, int, tesseract::TRand*, float*) (input.cpp:95)
    ==2035==    by 0x1C97A1: tesseract::LSTMRecognizer::RecognizeLine(tesseract::ImageData const&, bool, bool, bool, float, float*, tesseract::NetworkIO*, tesseract::NetworkIO*) (lstmrecognizer.cpp:265)
    ==2035==    by 0x13DE72: tesseract::LSTMTrainer::PrepareForBackward(tesseract::ImageData const*, tesseract::NetworkIO*, tesseract::NetworkIO*) (lstmtrainer.cpp:855)

So some more work is needed. The patch shown above does not fix the real problems. It looks like the pix which was created by pixScaleGeneral contains uninitialized pixel data.
The Tesseract function ComputeBlackWhite operates on that data with random results.
@DanBloomberg, do you have any idea how to fix that?

    ==14279==  Uninitialised value was created by a heap allocation
    ==14279==    at 0x4C2BBAF: malloc (vg_replace_malloc.c:299)
    ==14279==    by 0x71F8BD1: pix_malloc (pix1.c:234)
    ==14279==    by 0x71F8BD1: pixCreateNoInit (pix1.c:343)
    ==14279==    by 0x71F8D06: pixCreateTemplateNoInit (pix1.c:408)
    ==14279==    by 0x71FBF47: pixCopyBorder (pix2.c:1705)
    ==14279==    by 0x718DE46: pixUnsharpMaskingGray2D (enhance.c:1346)
    ==14279==    by 0x718EA29: pixUnsharpMaskingFast (enhance.c:1095)
    ==14279==    by 0x718EC8C: pixUnsharpMasking (enhance.c:917)
    ==14279==    by 0x727A4B4: pixScaleGeneral (scale.c:368)
    ==14279==    by 0x1804D9: tesseract::ImageData::PreScale(int, int, float*, int*, int*, GenericVector<TBOX>*) const (imagedata.cpp:245)
 Using valgrind, I am not able to find uninitialized pixels starting from pixScale (or pixScaleGeneral).  I did something simple like:
    pix3 = pixScale(pix2, 0.6, 0.6);  // pix3 is 8 bpp
    pixGetDimensions(pix3, &w, &h, NULL);
    for (i = 0; i < h; i++) {
        for (j = 0; j < w; j++) {
            pixGetPixel(pix3, j, i, &val);
            tot += val;
        }
    }
where every pixel was read and used.

Try to replace line 1705 of pix2.c, which is pixCreateTemplateNoInit(), with
    pixCreateTemplate()
If this solves the problem, then it may be originating in pixUnsharpMaskingGray1D() or in pixUnsharpMaskingGray2D() and to make sure that valgrind was catching it, I used a conditional in the inner loop:
    pix3 = pixScaleGeneral(pix1, 0.8, 0.8, 0.4, 2);
    pixGetDimensions(pix3, &w, &h, NULL);
    for (i = 0; i < h; i++) {
        for (j = 0; j < w; j++) {
            pixGetPixel(pix3, j, i, &val);
            if (val == 0x12345678)
                break;
        }
    }

If any pixel were uninitialized, we'd have a message like:
   Conditional jump or move depends on uninitialised value(s)
     ==65877==    at 0x40481C: main (...)
There were none.
(We did have an issue with normalization in these pixUnsharpMaskingGray*() functions back in April, that gave rise to some artifacts.)
 My short test program `pixtest.cpp` was successful:

    #include <leptonica/allheaders.h>

    int main(void)
    {
      PIX *pix1 = pixCreate(2047, 71, 8);
      PIX *pix2 = pixScaleGeneral(pix1, 0.676056325, 0.676056325, 0.200000003, 1);
      int width = pixGetWidth(pix2);
      int height = pixGetHeight(pix2);
      int y = height / 2;
      l_uint32* line = pixGetData(pix2) + pixGetWpl(pix2) * y;
      int prev = GET_DATA_BYTE(line, 0);
      if (prev != 0) {
        return 1;
      }
      return 0;
    }

I compiled it on Debian Stretch using `g++ -g pixtest.cpp -llept`.
Valgrind reports the same problem as in Tesseract:

    ==22626== Conditional jump or move depends on uninitialised value(s)
    ==22626==    at 0x400832: main (pixtest.cpp:12)
 > We did have an issue with normalization in these pixUnsharpMaskingGray*() functions back in April, that gave rise to some artifacts.

Could that be the reason for the problem? Debian has a Leptonica version 1.74.1-1, so maybe that fix is missing? Then Debian needs a newer version (and Tesseract should require Leptonica 1.74.2). CC @jbreiden. Stefan, can you run your test program from our github head, or replacing the 1.74.1 scale.c with the most recent one?  That would determine if the normalization change fixed this problem.

I ran your exact program with the current pixScaleGeneral(), on valgrind, and got no error. After failing to find the problem with an uninitialized value from pixUnsharpMasking(), I will do the most simple thing, which is make sure that the pixel values are initialized.  Use of pixCreateTemplateNoInit(), instead of pixCreateTemplate(), is clearly a poor optimization.  I will also remove other uses of the NoInit version in places where it's not obvious by inspection that all pixels are set. Committed (#512) to leptonica.  Hoping that this solves any uninitialized value problems. As far as I see Leptonica 1.74.2 is sufficient (it solved the uninitialized value problems for Tesseract), but of course you can use the newer version, too. 1.74.3 has a fix for the uninitialized issue (the topic of this thread),
and some other bug fixes on windows.  It has far fewer coverity scan
'bugs'.  And I also made it configure-ready, as advertised in the README.

On Fri, Jun 9, 2017 at 11:10 PM, Stefan Weil <notifications@github.com>
wrote:

> As far as I see Leptonica 1.74.2 is sufficient, but of course you can use
> the newer version, too.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/644#issuecomment-307545573>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLLmxMT7FYa8MVlC7A9Z274t3Ng-dks5sCjM_gaJpZM4Ld5Xp>
> .
>
 Dan, the uninitialized issue was already fixed with 1.74.2, and so were the Coverity scan issues. Somehow I didn't realize that 1.74.2 fixed the uninitialized issue in
unsharp masking.  So now it's double-fixed.  And 1.74.3 has even more fixed
coverity scan issues  :-)

For 1.74.3, I wanted to make a configure-ready version available (and also,
I hadn't done a tarball release before on github).  I plan to make all
future releases that way.

So it seems that both 1.74.2 and 1.74.3 can be used with tesseract.

For the future, I'd like to remove the pixWriteDisplay*() functions from
the library, which are only there to support some older versions of
tesseract.

On Sat, Jun 10, 2017 at 2:14 PM, Stefan Weil <notifications@github.com>
wrote:

> Dan, the uninitialized issue was already fixed with 1.74.2, and so were
> the Coverity scan issues.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/644#issuecomment-307590678>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLANpA6zDdbA955Xk-agzECB6WpQlks5sCwdOgaJpZM4Ld5Xp>
> .
>
 Hi there!
The problem seems still there, at least on my MBP :( 

I had exactly the same issue after exactly 100 iterations: 
`Assertion failed: (index >= 0 && index < size_used_), function operator[], file ~/tesseract/ccutil/genericvector.h, line 713.`

I was using Leptonica 1.74.1 provided by Macports, then built manually 1.74.4 (just 1 hour after Dan put out it :) ), still the same problem. 
I make sure `lstmtraining` is linking to the correct version of Lept library (using `otool -L `on Mac)

What baffles me is, the `scale.c` file - which I presume includes the fix to the problem - is **identical** for 1.74.[1 | 2 | 3 | 4]... is it correct?


I'm using a 2015 MBP running OS X El Capitan (10.11.6) with Xcode 8. 
The command I'm using to train:
> ./tesseract/build-mac/bin/Debug/lstmtraining -U tesstutorial/engtrain/eng.unicharset --script_dir langdata/ --debug_interval 100 --net_spec '[1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c105]' --model_output tesstutorial/engoutput/base --train_listfile tesstutorial/engtrain/eng.training_files.txt --eval_listfile tesstutorial/engeval/eng.training_files.txt --max_iterations 5000 

Thanks! @dudullz, there were several problems, and updating Leptonica to 1.74.2 or newer fixes one of them. Pull request #978 fixes the assertion. It's still unmerged, that's why you got that assertion. @stweil first thanks for TRULY swift reply!

It has been training for past 2 hours for about 3,000 iterations and still going - it's just enjoyable to see it continuing after days of struggling :)

So has `updating Leptonica to 1.74.4` + `pull request  #978`  fixed the real problem? means the trained results are valid to use now (not like non-debug builds continue but with invalid results)?
 That fixed at least the currently known problems and should produce more stable results as the trained data no longer depends on undefined values (which could produce random results). so,  is this issue fixed ?  Compilation of 4.0.0alpha fails with gcc 4.4.7 (gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-17)):

`libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I../ccutil -I../viewer -I/usr/local/include/leptonica -g -O2 -MT simddetect.lo -MD -MP -MF .deps/simddetect.Tpo -c simddetect.cpp  -fPIC -DPIC -o .libs/simddetect.o
In file included from ../ccutil/genericvector.h:29,
                 from ../ccutil/params.h:25,
                 from ../ccutil/tprintf.h:23,
                 from simddetect.cpp:19:
../ccutil/helpers.h: In member function ‘void tesseract::TRand::set_seed(const std::string&)’:
../ccutil/helpers.h:50: error: ‘hash’ is not a member of ‘std’
`

Steps to reproduce: under an "old" OS (centos6 for example) follow the autogen&configure&make compilation steps and see the compilation error.

Rootcause: std hash was not officially supported in gcc 4.4, only in the TechnicalReport "tr1" namespace i.e. : std::tr1::hash<T> ... 

Possible fix: perhaps just enforcing a "recent" gcc at configure time ?
 Good news: does compile correctly at least with gcc 4.8. Update: there was a AX_GCC_VERSION but that would be better to simply check that the compiler has std hash: 
for example: "ax_cxx_have_hash" 
https://www.gnu.org/software/autoconf-archive/ax_cxx_have_hash.html
? The code makes use of a few C++ 11 features.  Yep, C++11 seems now to be a must have at least for master/version 4.
So would you accept a pull request adding a std hash check to the autoconf script ? @zdenop 
config.log:
[config.log.txt](https://github.com/tesseract-ocr/tesseract/files/690637/config.log.txt)
configure output:
[configure.out.txt](https://github.com/tesseract-ocr/tesseract/files/690648/configure.out.txt)
 it also use `nullptr` and `unique_ptr` and maybe other stuff.
For `unique_ptr` you need libstdc++ 4.6 so perhaps a global cpp 11 check would be better:
https://www.gnu.org/software/autoconf-archive/ax_cxx_compile_stdcxx.html
? The license for `AX_CXX_COMPILE_STDCXX` is permissive:

>Copying and distribution of this file, with or without modification, are permitted in any medium without royalty provided the copyright notice and this notice are preserved. This file is offered as-is, without any warranty.

So maybe we can embed it in our codebase. We probably need approval from Ray for this. >We already have test for c++11 support (without dependency on autoconf-archive). So it should be enough to modify test to produce error in case of missing c++11 support...

:+1: 

https://github.com/tesseract-ocr/tesseract/blob/38cb4acaf906/configure.ac#L355

It will detect C++11 support for g++ version >= 4.7. and for Clang version >= 3.0.  Will it be a problem if detected resolution is 0 dpi?

tesseract scr out
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Warning. Invalid resolution 0 dpi. Using 70 instead. Can someone tell me which is the default resolution used by tesseract when is processing PDF documents? @MrAlex6204
Tesseract does not accept a PDF file as input.
Please use the [forum](https://groups.google.com/d/forum/tesseract-ocr) for asking questions.  I just drew the box according the output coordinates of box file and tsv file,  but I found they were different. hocr & tsv use 'left, top, right, bottom' coordinates while box uses 'left, bottom, right, top'.  Hi,
I am woking on interpretation of handwritten text (English). I just stumbled upon the new version of tesseract and was wondering if the new version can support handwritten text after training. 

Any leads would be beneficial.

Thank you Here is what I found :
- using CNN for chinese char recognition : 
http://people.idsia.ch/~juergen/icdar2011a.pdf
- handwritten recognition using RNN & LSTM :
http://people.idsia.ch/~juergen/tpami_2008.pdf
  https://github.com/DanBloomberg/leptonica/commit/792db025518a
>Encode pdf title in escape 4-byte hex for safety. 
  IMO, most of the OpenCL code should be part of Leptonica.

There are two questions here:
1. Does @DanBloomberg want this code in Leptonica?
2. Are the authors of the code willing to relicense it (Apache 2 -> BSD) Dan,

The code is here: 
https://github.com/tesseract-ocr/tesseract/tree/master/opencl Amit, there are several good reasons why this code should NOT be in leptonica.

(1) Maintenance: I (and any competent C programmer with a background in image processing and analysis) can maintain all of leptonica.  From the beginning of the leptonica project, I understood that maintenance is critical: over the lifetime of the library, the time spent fixing/improving it will far exceed the time spent on the first implementation.  There is no way I could fix errors in the low-level code in this file.

(2) Portability: We have enough trouble maintaining portability with just plain old ansi C over several OS platforms.  The operations here take it to another level: hardware.  What restrictions are there on the hardware for this code to be compiled properly?  Does it work seamlessly on all Intel processors?  What about AMD?  What about ioS and Android?

(3) Benefit: Are the multiple complications from introducing this code into leptonica worth the pain?  As Jeff said, we've already fixed the multipage tiff wrapper, so the time is now O(n), where n is the number of pages.  And this is just a wrapper into tifflib.  Most other operations that are easily parallellized are already fast enough for most applications. Leptonica is intended to be a general utility that gives good performance with a simple implementation.  Emphasis on simple. If in production for a particular application, it is necessary to speed up a particular low-level operation (such as convolution) this should be done as an adjunct to leptonica, not as part of it.

Other image processing libraries have a different genesis and philosophy.  OpenCV was built by Intel engineers in Russia, and is now maintained by Itseez.  It is large and heterogeneous, and might be a good place to house this Intel GPU-based image processing code. OK Dan, thanks for your detailed response! Here are the files with `#ifdef USE_OPENCL`:
https://github.com/tesseract-ocr/tesseract/blob/d55f462c9c/ccmain/thresholder.cpp#L267
https://github.com/tesseract-ocr/tesseract/blob/4ac54a27c6/ccstruct/otsuthr.cpp#L53
https://github.com/tesseract-ocr/tesseract/blob/e949812e63/textord/linefind.cpp#L590

  ```
Extracting font properties only
Rendered page 242 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Rendered page 244 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
Rendered page 239 to file /tmp/tmp.lswGVDuVeX/bih/bih.Siddhanta.exp0.tif
Error in boxCreate: x < 0 and box off +quad
Rendered page 243 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Stripped 1 unrenderable words
Error in boxCreate: x < 0 and box off +quad
Rendered page 245 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
Error in boxCreate: x < 0 and box off +quad
Rendered page 240 to file /tmp/tmp.lswGVDuVeX/bih/bih.Siddhanta.exp0.tif
Rendered page 244 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Rendered page 246 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
Error in boxCreate: x < 0 and box off +quad
Error in boxCreate: x < 0 and box off +quad
Error in boxCreate: x < 0 and box off +quad
Error in boxCreate: x < 0 and box off +quad
Error in boxCreate: x < 0 and box off +quad
Rendered page 241 to file /tmp/tmp.lswGVDuVeX/bih/bih.Siddhanta.exp0.tif
Error in boxCreate: x < 0 and box off +quad
Error in boxCreate: x < 0 and box off +quad
Error in boxCreate: x < 0 and box off +quad
Rendered page 245 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Error in boxCreate: x < 0 and box off +quad
Rendered page 247 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
Rendered page 242 to file /tmp/tmp.lswGVDuVeX/bih/bih.Siddhanta.exp0.tif
Rendered page 246 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Rendered page 248 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif
Error in boxCreate: x < 0 and box off +quad
Rendered page 243 to file /tmp/tmp.lswGVDuVeX/bih/bih.Siddhanta.exp0.tif
Rendered page 247 to file /tmp/tmp.lswGVDuVeX/bih/bih.Mangal.exp0.tif
Rendered page 249 to file /tmp/tmp.lswGVDuVeX/bih/bih.Sanskrit_2003.exp0.tif

``` Line 179
https://github.com/DanBloomberg/leptonica/blob/8a839a254e8d2ed3965ab0ecce7120b05f291993/src/boxbasic.c >Extracting font properties only

I'm not sure if the LSTM engine needs this step. I am using tesstrain.sh . The ngram file creation, which is used for font properties is done even before creation of images.

--linedata_only is the option used for creating the lstmf files.

```
training/tesstrain.sh --fonts_dir /home/shree/.fonts --lang bih  --linedata_only \
  --langdata_dir ../langdata --tessdata_dir ./tessdata \
  --output_dir ~/tesstutorial/bihnew
``` >I am using tesstrain.sh . The ngram file creation, which is used for font properties is done even before creation of images.

Yes, I know...

I think the LSTM engine does not need this info. If that's true, it should not activated in `tesstrain.sh`  when training witn the `--linedata_only` option.
 ```
           --noextract_font_properties)
                EXTRACT_FONT_PROPERTIES=0 ;;
```

So, for LSTM training we should use both of these -

`--linedata_only --noextract_font_properties` Yes, probably... :-)  When using command mode and -l hin+fra on an image with both Hindi and French, the French text is being misrecognized as numbers. 

The recognition of French part of text is not fully correct if whole image is given via command mode using single language French.

However, when sections of same image are offered via gimagereader gui using single language French, the recognition is correct.

Image file and OCRed text attached.

![24](https://cloud.githubusercontent.com/assets/5095331/21581641/c64ae64e-d060-11e6-9db2-bf398026be14.png)
[24.txt](https://github.com/tesseract-ocr/tesseract/files/680036/24.txt)
[24-fra.txt](https://github.com/tesseract-ocr/tesseract/files/680037/24-fra.txt)
[24-gimagereader.txt](https://github.com/tesseract-ocr/tesseract/files/680038/24-gimagereader.txt)



 If you are on Windows, please try the experimental builds of gImageReader
 by Sandro Mani:

https://smani.fedorapeople.org/tmp/gImageReader_3.2.0_qt5_x86_64_tesseract-25fed52.exe
https://smani.fedorapeople.org/tmp/gImageReader_3.2.0_qt5_i686_tesseract-25fed52.exe

​and see if separately selected text of each language gives correct result.
​


ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sun, Jan 1, 2017 at 10:51 PM, peiman F <notifications@github.com> wrote:

> ​​
> ​it seems this problem occur in other multi lingual process to
> i face this kind of error on Arabic+English scan
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/633#issuecomment-269911238>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o3cBl3zp3ICYcQgXNiyscdPj8JgRks5rN-B_gaJpZM4LYuOm>
> .
>
 https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00

>The neural network engine has not yet been integrated to enable the multi- language mode that worked with Tesseract 3.04, but this will be improved in a future release.
>>
The above comment is out of date. In theory, this is now working, but it looks like it doesn't work as well as intended. Thanks for the info, Amit.

Attaching another image and text with Hindi, Arabic and English as a sample
test image.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Jan 2, 2017 at 1:21 PM, Amit D. <notifications@github.com> wrote:

> https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00
>
> The neural network engine has not yet been integrated to enable the multi-
> language mode that worked with Tesseract 3.04, but this will be improved in
> a future release.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/633#issuecomment-269941901>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o4HJZ2hcb5DhV51CaOW9Z2I3GzBvks5rOKxlgaJpZM4LYuOm>
> .
>

S ايکيه ऐक्य aikya, s.m. Oneness, unity, singleness, identity, sameness, harmony (=ekatā); total, aggregate, product.

H ايگن ऐगुण aiguṇ [S. अव+गुण], s.m. Unskilfulness, stupidity, &c.=augun, q.v.

A ايل īyal, aiyal, uyyal, s.m. Stag; deer, hart; wild goat.

S ايلا एला elā, s.f. Cardamoms. (See ilāćī.)

H ايلام ईलाम īlām, s.m. Auction, public sale (=līlām, nīlām, q.q.v.).

P ايلچي elćī, s.m. Ambassador, envoy, delegate, agent:—elćī karnā, To discharge the functions of an ambassador or agent; to Ray,
Thank you for fixing this. The languages are being recognized much better now.

However, problem with words being skipped during recognition remains. Here is some debug info regarding a missing Hindi word, it is being recognized but is getting discarded and is not output:

```
Processing word with lang fra at:Bounding box=(361,395)->(447,419)
Trying word using lang fra, oem 1
Best choice: accepted=1, adaptable=0, done=1 : Lang result :          : R=80, C=-1, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM	NORM	NORM	NORM	NORM
str	 	 	 	 	 	 	 	 
state:	1 	1 	1 	1 	1 	1 	1 	1 
C	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000	-1.000
1 new words better than 0 old words: r: 80 v 0 c: -1 v 0 valid dict: 0 v 0
Trying word using lang hin, oem 1
Best choice: accepted=0, adaptable=0, done=1 : Lang result : आबांलीर : R=6.78767, C=-4.16219, F=1, Perm=2, xht=[0,3.40282e+38], ambig=0
pos	NORM	NORM	NORM	NORM
str	आ	बां	ली	र
state:	1 	1 	1 	1 
C	-0.198	-0.595	-0.193	-0.195
1 new words worse than 1 old words: r: 6.78767 v 80 c: -4.16219 v -1 valid dict: 0 v 0
Processing word with lang fra at:Bounding box=(557,393)->(748,413)
```
![22](https://cloud.githubusercontent.com/assets/5095331/22327088/70560866-e3db-11e6-867e-264fcb95f1e1.png)
  Using Tesseract 4 (libtesseract) in my project [decipher_text](https://github.com/rudrabhoj/decipher_text).
When I use OEM_TESSERACT_ONLY, it takes little over 7-8 seconds to complete the recognization of a page in English. But when I try to instead use OEM_LSTM_ONLY, it takes 10-15 minutes, if not more, to do the same. I am using i5 2400. Ubuntu 16.04 x86_64.

Part of code where this is used:
`  if (ocrUnit->process->Init(tessDataPath, languageArg, tesseract::OEM_LSTM_ONLY)){`  
    `//Again, handle error here`  
    `//`     
    `//`       
    `//`       
    `//`       
  `}`   

Entire file in which it was used could be seen [here](https://github.com/rudrabhoj/decipher_text/blob/master/src/Control/TesseractRecognize.cxx). (Note: File is from an older, stabler version) Hi,

Did you test it with the Tesseract command line?
How did you compile it? Did you use debug mode?
Can you provide an image?
 Also see comments in https://github.com/tesseract-ocr/tesseract/issues/40

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sun, Jan 1, 2017 at 1:31 PM, Amit D. <notifications@github.com> wrote:

> Hi,
>
> Did you test it with the Tesseract command line?
> How did you compile it? Did you use debug mode?
> Can you provide an image?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/632#issuecomment-269895203>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o4UvfX-7cir3Ccmjn66P-oI1oZibks5rN11JgaJpZM4LYrS->
> .
>
  I built my project with cppan and then tried to run, and got an error:
```
Info in pixWriteMemPng: work-around: writing to a temp file
Info in fopenReadFromMemory: work-around: writing to a temp file
DotProductAVX can't be used on Android
```
After compiling example project - https://github.com/cppan/tesseract_example/tree/master/with_cppan I got same error. Can you please fix it?
OS: Windows 7 Thanks, it works! Also, one question: will this built tesseract without this line works also on 64-bit Windows OS? @stweil 
https://sourceforge.net/p/predef/wiki/Architectures/ >No need to fix this this year – for the rest of the year I have other priorities. Happy new year!

Not sure if you were joking here or were serious...
If by "this year" you meant '2016', then you were joking.

Happy new year to you too! @stweil , 
For your preferred option - **"Let the compiler do the optimization (and forget that explicit SSE/AVX code). This is my preferred solution as it also works for ARM and other _architectures."**. Could you advise how can it be done? ## Automatic vectorization

### GCC
https://gcc.gnu.org/projects/tree-ssa/vectorization.htmlAuto
https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html

### LLVM
http://llvm.org/docs/Vectorizers.html

### MSVC
https://msdn.microsoft.com/en-us/library/hh872235.aspx
https://blogs.msdn.microsoft.com/vcblog/2012/04/16/auto-vectorization/ 
https://locklessinc.com/articles/vectorize/


https://monoinfinito.wordpress.com/series/vectorization-in-gcc/
>The downside to all the black-box magic the compiler does on loop-vectorization is quite big, though: you loose all visibility into how your code actually works. It might work wonderfully one day and then the next it might become the slowest part of your program, because a small change made gcc miss the chance of vectorization.
>
>If (or when) gcc looses the ability to vectorize one of your loops, you’ll be digging around a lot of compiler logs to try and figure out what went wrong. If you were to write the vectorized loop yourself using intrinsics you’d be certain that the loop works and it’s vectorized (duh!) but you’d have to manage the portability, alignment and aliasing yourself. That’s not a trivial task if you are aiming for a portable program.
 The non-SIMD version of the dotproduct method can be significantly sped up by doing manual loop unrolling.   Also, this version can use OpenMP (with `#pragma...` above the loop) Here is one source:
http://blog.theincredibleholk.org/blog/2012/12/10/optimizing-dot-product/ @stweil  I am getting the error while using the new binaries provided by you.
Ref https://github.com/tesseract-ocr/tesseract/issues/689

```
PS C:\Users\User\shree\jtess\tesseract-ocr> ./tesseract.exe -v
tesseract 4.00.00alpha
 leptonica-1.74.1
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.5.0) : libpng 1.6.20 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.3 : libo
penjp2 2.1.0

 Found AVX
 Found SSE

```
Extracting tessdata components from C:\Users\User\shree\tessdata/vie.traineddata
Wrote C:\Users\User\shree\jtess\samples\vie/vie.lstm
Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Warning: given outputs 105 not equal to unicharset of 227.
Num outputs,weights in serial:
  1,36,0,1:1, 0
Num outputs,weights in serial:
  C5,5:25, 0
  Ft16:16, 416
Total weights = 416
  [C5,5Ft16]:16, 416
  Mp3,3:16, 0
  Lfys64:64, 20736
  Lfx128:128, 98816
  Lrx128:128, 131584
  Lfx256:256, 394240
  Fc227:227, 58339
Total weights = 704131
Built network:[1,36,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc227] from request [1,36,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128
 Lrx128 Lfx256 O1c105]
Training parameters:
  Debug interval = -1, weights = 0.1, learning rate = 0.0001, momentum=0.9
Loaded 188/188 pages (1-188) of document C:\Users\User\shree\jtess\samples\vie\vie.Arial.exp0.lstmf
Info in fopenReadFromMemory: work-around: writing to a temp file
DotProductAVX can't be used on Android

This application has requested the Runtime to terminate it in an unusual way.
Please contact the application's support team for more information.
DotProductAVX can't be used on Android
```
 Thanks!

Maybe we should keep this issue 'open'

- excuse the brevity, sent from mobile

On 31-Jan-2017 7:05 PM, "Stefan Weil" <notifications@github.com> wrote:

This is again (or still) a bug for 32 bit Intel platforms. I'll have a look
how to fix it later.

—
You are receiving this because you commented.

Reply to this email directly, view it on GitHub
<https://github.com/tesseract-ocr/tesseract/issues/631#issuecomment-276364076>,
or mute the thread
<https://github.com/notifications/unsubscribe-auth/AE2_o29aVPR_pcI7fEuQKMHzJfOyfzF7ks5rXziIgaJpZM4LYhc->
.
 @stweil The pull request #698 seems to solve the problem on x86 not entirely; On Windows 7 x64, VS2015, x86 target using the latest tesseract-ocr:master branch (which includes the merged pull request #698) still results in "DotProductAVX can't be used on Android" for me (Intel i7-4650U). However, the workaround in the comment above to remove `# define X86_BUILD 1` from `arch/simddetect.cpp` resolves this. @stweil Ah, I see! Yes, I used cmake - never mind then!
Thank you for the clarification! I still encounter this error "DotProductAVX can't be used on Android" with the latest source from master. I built the .exe in VS2015 with x86 target. It would work with 3.04 language data but throw exceptions when using 4.00 language data.

The workaround (commenting out the `#define` directive in `simddetect.cpp`) works, but a permanent fix is desired. Thanks. @stweil, I undid the change to `simddetect.cpp` and made the change to `dotproductavx.cpp`. The compiled exe still crashes with the same error.

I'm not sure if I have AVX support. I run Windows 10 64-bit on i7-7500U CPU. Here is output on my machine:

```
tesseract 4.00.00alpha
 leptonica-1.74.1 (Feb 11 2017, 11:04:30) [MSC v.1900 DLL Release x86]
  libjpeg 9b : libpng 1.6.28 : libtiff 4.0.7 : zlib 1.2.8

 Found AVX
 Found SSE
```

The shorter variant works! Let me research for how to define a macro in Visual Studio for a C++ project. Do you know, by chance? I don't think my VS set up uses `CMakeLists.txt`, but I found out how to set the flag:

![image](https://cloud.githubusercontent.com/assets/1501035/23319631/098dcdd4-fa9d-11e6-9a30-b09038beefa5.png)

With that enabled, I reverted all the code changes. The output .exe now works good. Thank you. I got the same error when using command line on Ubuntu:
```
root@ellensong: tesseract chi.jpg chi -l chi_sim
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
DotProductAVX can't be used on Android
Aborted (core dumped)
```
I've never got this error when I set language param as chi_tra or eng.
Could anybody tell me how to fix it?
Thanks a lot!

 @EllenSong77, did you use the latest code? Are you running Ubuntu in a virtual machine (if yes: please provide more information on the kind of virtualisation)? @stweil I clone the code yesterday, and running Ubuntu in a physical machine. What other information could be more helpful that I should provide?  >I've never got this error when I set language param as chi_tra or eng.

Very strange! From where did you get  the chi_tra and eng traineddata?
From here:
https://github.com/tesseract-ocr/tessdata/tree/3.04.00
Or from here:
https://github.com/tesseract-ocr/tessdata/tree/master/best
 @amitdo I got them by command line apt-get install tesseact-ocr-xxx and also cloned from https://github.com/tesseract-ocr/tessdata/tree/master/best
Maybe I should what @Shreeshrii said too.
Do you mean I should export TESS_DATA=......../tesseract/tesseract-ocr.tessdata/best ?
![screenshot from 2017-08-17 14-31-56](https://user-images.githubusercontent.com/25813556/29398731-dd84bed8-8358-11e7-8d9c-f5b237090e2b.png)
 >I got them by command line apt-get install tesseact-ocr-xxx and also cloned from https://github.com/tesseract-ocr/tessdata/tree/master/best

What repo do you use for Tesseract?
This one?
https://launchpad.net/%7Ealex-p/+archive/ubuntu/tesseract-ocr

  i understand that much of the new Tesseract 4.0 is using a customized implementation of Ocropus, relying basically on the new LSTM recognition engine.

But the main problem is that most of the decisions that are being taken focus mostly on English (Latin Languages)  which already able to reach +95% recognition rates easily.
My concern is allowing the other languages such as Arabic to be able to reach the **PRECISION CEILING.**

Methods such as **BLSTM** (Bidirectional LSTM) , and the two-dimensional 2D LSTM which is called **MDLSTM**, can achieve without explicit segmentation of words, a character-level accuracies of 92 and 96% !!!!!! and I repeat, **without explicit segmentation.**

So my question is that, will there be plans to implement and ascend the current LSTM to a **MDLSTM (Multi-dimensional LSTM)**, this will radically make ALL THE LANGUAGES ABLE TO PASS THAT PRECISION CEILING.

i am planing to engage in testing Tesseract 4.0 LSTM on the Arabic language, and wanting to post results in the future, i hope that there will be recognition improvement while testing.
Thank you Ray for your hard work, and all contributors, you are appreciated.


More information about BLSTM and MDLSTM:
https://www.nist.gov/sites/default/files/documents/itl/iad/mig/OpenHaRT2013_WorkshopPres_A2IA.pdf
http://www.a2ialab.com/lib/exe/fetch.php?media=presentations:icdar2015_chinese_slides.pdf
https://goo.gl/0wUNfm

 In principle, Tesseract is probably as accurate (or slightly more accurate) than ocropy/clstm.

Tesseract has official trained models for ~100 languages. ocropy has official models for English and German only. Unlike ocropus, Tesseract works on Windows.

BLSTM is implemented and used.

2D-LSTM is also implemented in the library. I think (not sure) it's not used by the released traineddata. Using 2D-LSTM means much longer time to train a model. and for OCRing printed text, the accuracy will not necessary be better than 1D-BLSTM.

BTW, ocropy doesn't have 2D-LSTM support. Please see https://github.com/tesseract-ocr/tesseract/wiki/VGSLSpecs

- excuse the brevity, sent from mobile

On 30-Dec-2016 10:06 PM, "Amit D." <notifications@github.com> wrote:

> In principle, Tesseract is probably as accurate (or slightly more
> accurate) than ocropy/clstm.
>
> Tesseract has official trained models for ~100 languages. ocropy has
> official models for English and German only. Unlike ocropus, Tesseract
> works on Windows.
>
> BLSTM is implemented and used.
>
> 2DLSTM is also implemented in the library. I think (not sure) it's not
> used by the released traineddata. Using 2DLSTM means much longer time to
> train a model. and for OCRing printed text, the accuracy will not necessary
> be better than 1D-BLSTM.
>
> BTW, ocropy doesn't have 2D-LSTM support.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/630#issuecomment-269792095>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oweaHUpMa-dyavVOg6KqTEwrrcoHks5rNTMTgaJpZM4LYPU8>
> .
>
 >But the main problem is that most of the decisions that are being taken focus mostly on English (Latin Languages)

This is not really the situation with the LSTM engine.

The difference in accuracy between Latin script based langs and Arabic is due to
1. Better traineddata files for the Latin script based langs.
2. The 'complexity' of the script. Arabic is much more complex.   Also, the OCR stage is dependent on the layout analysis stage which is weaker for Arabic.  Shree, indic scripts are even more complex... @amitdo Thanks for clearing things up,  improved pre-processing may make 1D-LSTM outperform the more complex MDLSTM. You were right.
I see, the main issue is not the ocr engine directly, but is of analysis/segmentation/classification.
Perhaps, i should focus on a combination of Tesseract LSTM & a Computer Assisted Transcription method.
somewhat similar to:   https://sites.google.com/site/paradiitproject/project-definition

@Shreeshrii So Tesseract 4.x has the capability of producing more sophisticated and complex structures.

@roozgar i was looking for a method that gain +85% recognition rate for Arabic language.
Tesseract 3.x was using cube for arabic that made me loose hope, **But thanks to the developers of Tesseract 4.0 for introducing the new LSTM engine, the hope is back and the community is excited.** I am looking forward to test this version after reading that you've got an 80% recognition.
@roozgar can you share your training process, the tif/box files and the traineddata.
 

 @roozgar what operating system are you using? Please see Ray's comment with accuracy figures in
https://github.com/tesseract-ocr/tesseract/issues/40

I have found Hindi to have much greater accuracy with LSTM engine.

- excuse the brevity, sent from mobile
 This is what is used for most of the languages:
https://github.com/tesseract-ocr/tesseract/wiki/VGSLSpecs#full-example-a-multi-layer-lstm-capable-of-high-quality-ocr

I think it is 2D-LSTM. @amitdo thanks, I have been told that 4.x version of tesseract would be the next big leap, now I believe. https://github.com/tensorflow/tensorflow/blob/v1.4.0-rc1/tensorflow/contrib/ndlstm/README.md  LSTM training is done on line boxes. The error/info messages from the program refer to these also as pages, which is confusing. 

When training using a multi-page tif, Page numbers of the tif being processed are displayed, concurrently another set of page numbers is displayed with respect to lstmf (I suspect these are line numbers).

```
=== Phase E: Generating lstmf files ===
Using TESSDATA_PREFIX=./tessdata
[Wed Dec 28 10:57:18 DST 2016] /usr/local/bin/tesseract /tmp/tmp.auXd9ArSbG/bih/bih.Lohit_Devanagari.exp0.tif /tmp/tmp.auXd9ArSbG/bih/bih.Lohit_Devanagari.exp0 lstm.train ../langdata/bih/bih.config
Tesseract Open Source OCR Engine v4.00.00alpha-219-gc124f87 with Leptonica
Page 1
Page 2
Loaded 41/41 pages (1-41) of document /tmp/tmp.auXd9ArSbG/bih/bih.Lohit_Devanagari.exp0.lstmf
Page 3
Loaded 82/82 pages (1-82) of document /tmp/tmp.auXd9ArSbG/bih/bih.Lohit_Devanagari.exp0.lstmf
``` the LSTM related 'page numbering' messages are displayed elsewhere during training also.

```
$   training/lstmtraining --model_output ~/tesstutorial/sanskrit2003_from_full/sanskrit2003 \
>   --continue_from ~/tesstutorial/sanskrit2003_from_full/san.lstm \
>   --train_listfile ~/tesstutorial/santrain/san.training_files.txt \
>   --target_error_rate 0.01
Loaded file /home/shree/tesstutorial/sanskrit2003_from_full/sanskrit2003_checkpoint, unpacking...
Successfully restored trainer from /home/shree/tesstutorial/sanskrit2003_from_full/sanskrit2003_checkpoint
Loaded 1746/1746 pages (0-1746) of document /home/shree/tesstutorial/santrain/san.Chandas.exp0.lstmf
Loaded 345/1760 pages (1415-1760) of document /home/shree/tesstutorial/santrain/san.Uttara.exp0.lstmf
Loaded 1814/1814 pages (0-1814) of document /home/shree/tesstutorial/santrain/san.Gargi.exp0.lstmf
Found AVX
Found SSE
At iteration 1808/17200/17229, Mean rms=0.336%, delta=0.129%, char train=0.41%, word train=1.751%, skip ratio=0.2%,  New worst char error = 0.41 wrote checkpoint.

``` https://github.com/tesseract-ocr/tesseract/blob/23a7330c85cf9066df4e65dd17c940218d0b54ef/ccstruct/imagedata.cpp#L554

It seems that it saves each line as a separate image.
I agree that the message is confusing.
   This is using glibtoolize from homebrew for autogen.sh.

```
$ git clone https://github.com/tesseract-ocr/tesseract.git
Cloning into 'tesseract'...
remote: Counting objects: 15316, done.
remote: Compressing objects: 100% (23/23), done.
remote: Total 15316 (delta 8), reused 0 (delta 0), pack-reused 15293
Receiving objects: 100% (15316/15316), 35.47 MiB | 7.87 MiB/s, done.
Resolving deltas: 100% (11818/11818), done.
$ cd tesseract/
$ git rev-parse HEAD
3817aa3079e741bd3a98af11d489f7a332e71ab3
$ ./autogen.sh 
Running aclocal
Running libtoolize
./autogen.sh: line 74: libtoolize: command not found
glibtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, 'config'.
glibtoolize: copying file 'config/ltmain.sh'
glibtoolize: putting macros in AC_CONFIG_MACRO_DIRS, 'm4'.
glibtoolize: copying file 'm4/libtool.m4'
glibtoolize: copying file 'm4/ltoptions.m4'
glibtoolize: copying file 'm4/ltsugar.m4'
glibtoolize: copying file 'm4/ltversion.m4'
glibtoolize: copying file 'm4/lt~obsolete.m4'
./autogen.sh: line 75: libtoolize: command not found
Running autoheader
Running automake --add-missing --copy
configure.ac:316: installing 'config/compile'
configure.ac:87: installing 'config/config.guess'
configure.ac:87: installing 'config/config.sub'
configure.ac:69: installing 'config/install-sh'
configure.ac:69: installing 'config/missing'
api/Makefile.am: installing 'config/depcomp'
Running autoconf

All done.
To build the software now, do something like:

$ ./configure [--enable-debug] [...other options]
$ ./configure
checking for g++... g++
checking whether the C++ compiler works... yes
checking for C++ compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
Using git revision: 4.00.00alpha-239-g3817aa3
checking for a BSD-compatible install... /usr/local/bin/ginstall -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /usr/local/bin/gmkdir -p
checking for gawk... no
checking for mawk... no
checking for nawk... no
checking for awk... awk
checking whether make sets $(MAKE)... yes
checking for style of include used by make... GNU
checking whether make supports nested variables... yes
checking dependency style of g++... gcc3
checking whether to enable maintainer-specific portions of Makefiles... no
checking build system type... x86_64-apple-darwin15.6.0
checking host system type... x86_64-apple-darwin15.6.0
./configure: line 4237: syntax error near unexpected token `-mavx,'
./configure: line 4237: `AX_CHECK_COMPILE_FLAG(-mavx, avx=1, avx=0)'
$
```

So, it looks like AX_CHECK_COMPILE_FLAG is undefined on OS X.

This appears related to https://github.com/tesseract-ocr/tesseract/commit/02a6970cf361ae12e2e2b5374f87bd09b3802bfd#diff-67e997bcfdac55191033d57a16d1408a

Since this error is a bit cryptic, it might be nice to add a check to see if AX_CHECK_COMPILE_FLAG is defined is added, and perhaps print a message to give some guidance on how to get it (probably something in homebrew? upgrade autoconf maybe?).

A poor workaround for this error is to add http://git.savannah.gnu.org/gitweb/?p=autoconf-archive.git;a=blob_plain;f=m4/ax_check_compile_flag.m4 to the project's m4 directory, then rerun autogen.sh before running configure again -- that gets around the error on my machine. https://github.com/Homebrew/homebrew-core/blob/master/Formula/autoconf-archive.rb **Update**: need to `apt install autoconf-archive` to fix this issue.

+1 on Ubuntu 16.04

```
$ ./configure --enable-debug                                                                                                                                              2 ↵
checking for g++... g++
checking whether the C++ compiler works... yes
checking for C++ compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
Using git revision: 4.00.00alpha-239-g3817aa3
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking for gawk... no
checking for mawk... mawk
checking whether make sets $(MAKE)... yes
checking for style of include used by make... GNU
checking whether make supports nested variables... yes
checking dependency style of g++... gcc3
checking whether to enable maintainer-specific portions of Makefiles... no
checking build system type... x86_64-pc-linux-gnu
checking host system type... x86_64-pc-linux-gnu
./configure: line 4249: syntax error near unexpected token `-mavx,'
./configure: line 4249: `AX_CHECK_COMPILE_FLAG(-mavx, avx=1, avx=0)'
``` Yesterday I added the missing dependency to this wiki page:
https://github.com/tesseract-ocr/tesseract/wiki/Compiling Thanks for the info.

Note on your expectation of user-familiarity with compile software, I personally am not that familiar with c/c++ compilers since I barely do any programming in those languages but merely compile software using (usually) autoconf with simple steps.

I'm sure I'm not the only one, just for some perspective though I did find the solution immediately after posting my comment so I accept the -1 for laziness :)
 >... just for some perspective though I did find the solution immediately after posting my comment so I accept the -1 for laziness :)

+1 

:laughing:  Hey @zdenop, if not keeping track of every package that I have installed makes me lazy, then I guess I'm lazy. :)

What about printing out something like "install autoconf-archive", instead of "syntax error near unexpected token"?

Would you accept a patch?  I've compiled and installed the master branch today and started to play around a bit with text extraction from japanese text. With the supplied training data LSTM seems to be a bit better at horizontal text than the old (oem 0) method.

However, with vertical text LSTM is really bad and does not produce any good results.

This is my results with the following three test images. (I have scaled them to 300 dpi)

[test1](https://cloud.githubusercontent.com/assets/312503/21546356/81151560-cdde-11e6-902c-c2e2cfaed90b.png)
`tesseract test1.png out -l jpn --oem 0 --psm 5 && cat out.txt`
そのかわり・・・・・・
`tesseract test1.png out -l jpn --oem 1 --psm 5 && cat out.txt`
ご 人 心 ‥.

For test2.png, I cut off the top row of a vertical text segment 
[test2](https://cloud.githubusercontent.com/assets/312503/21546355/8114c2c2-cdde-11e6-9f66-5e1e3c3584ee.png)
`tesseract test2.png out -l jpn --oem 0 --psm 5 && cat out.txt`
だ
洗
お
で
`tesseract test2.png out -l jpn --oem 1 --psm 5 && cat out.txt`
ぢ
於
+
レ
`tesseract test2.png out -l jpn --oem 0 --psm 6 && cat out.txt`
でお洗だ“
`tesseract test2.png out -l jpn --oem 1 --psm 6 && cat out.txt`
で お 洗 だ

[test3](https://cloud.githubusercontent.com/assets/312503/21546353/810209a2-cdde-11e6-9ecd-c4f2eb6308c4.png)
`tesseract test3.png out -l jpn --oem 0 --psm 5 && cat out.txt`
心配ご無用
秘密にしますよ
`tesseract test3.png out -l jpn --oem 1 --psm 5 && cat out.txt`
つ 圖 月 庸 明
惟 僕 り せつ 44 ふ 6

Using psm 6 on test3 does make LSTM a bit better, but as with oem 0, it fails to extract the text correctly...

`tesseract test3.png out -l jpn --oem 0 --psm 6 && cat out.txt`
秘心
壽醒
し無
ま用
す
よ
`tesseract test3.png out -l jpn --oem 1 --psm 6 && cat out.txt`
秘 心
は :
し 無
ま 用
す
ボ

I've also noticed that even if LSTM is a bit better with horizontal text, it seems to print out the result with spaces even if there are no space in the original text. For example:
はははは
Becomes:
は は は は
 https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00#integration-with-tesseract

>The neural network engine has not yet been integrated to enable the multi- language mode that worked with Tesseract 3.04, but this will be improved in a future release. Vertical text is also not yet supported, so support for Japanese and Traditional Chinese for example are limited to horizontally rendered text. @amitdo @jbreiden Ah, I missed that wiki page, sorry. Should I close this issue or keep it open until this is implemented? I think you can keep it open. An admin can close it if he wants to.  Ray added jpn_vert.traineddata
https://github.com/tesseract-ocr/tessdata/tree/master/best @amitdo Thanks for the headsup! It seems to work better than the old (oem 0) method for me. @zdenop, please close this issue.  - I followed instructions to compile tesseract from `https://github.com/tesseract-ocr/tesseract/wiki/Compiling#Compilation`

- I try running tesseract I get **Segmentation fault (core dumped)**

- gdb logs 
(gdb) run
Starting program: /usr/local/bin/tesseract 
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".

Program received signal SIGSEGV, Segmentation fault.
STRING::string (this=this@entry=0x7ffff7dc9a78 <debug_file+24>) at strngs.cpp:203
203	  if (header->used_ == 0)
(gdb) bt
#0  STRING::string (this=this@entry=0x7ffff7dc9a78 <debug_file+24>) at strngs.cpp:203
#1  0x00007ffff7873e41 in string (this=0x7ffff7dc9a60 <debug_file>) at params.h:203
#2  tprintf_internal (format=format@entry=0x7ffff789ad32 "Found AVX\n") at tprintf.cpp:60
#3  0x00007ffff77f2661 in SIMDDetect::SIMDDetect (this=<optimized out>) at simddetect.cpp:63
#4  0x00007ffff7dea10a in call_init (l=<optimized out>, argc=argc@entry=1, 
    argv=argv@entry=0x7fffffffdb18, env=env@entry=0x7fffffffdb28) at dl-init.c:78
#5  0x00007ffff7dea1f3 in call_init (env=<optimized out>, argv=<optimized out>, argc=<optimized out>, 
    l=<optimized out>) at dl-init.c:36
#6  _dl_init (main_map=0x7ffff7ffe1c8, argc=1, argv=0x7fffffffdb18, env=0x7fffffffdb28) at dl-init.c:126
#7  0x00007ffff7ddb30a in _dl_start_user () from /lib64/ld-linux-x86-64.so.2
#8  0x0000000000000001 in ?? ()
#9  0x00007fffffffdecb in ?? ()
#10 0x0000000000000000 in ?? ()

- Any clue why this is happening ? No issues seen now  Messages only shown now when asking for version and not for each image. Thanks!

```
 tesseract -v
tesseract 4.00.00alpha-238-ge6ccfb2
 leptonica-1.74
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 Found AVX
 Found SSE

```
```
tesseract san001.jpg san001.tst -l san
Tesseract Open Source OCR Engine v4.00.00alpha-238-ge6ccfb2 with Leptonica

```  I got error when i'm trying this command : brew link libpng libtiff

`Linking /usr/local/Cellar/libpng/1.6.26... 
Error: Could not symlink share/man/man3/libpng.3
/usr/local/share/man/man3 is not writable.`  Do Tesseract support khmer language  ?  @choungchamnab 

Please see comment by @theraysmith  at https://github.com/tesseract-ocr/tesseract/issues/654#issuecomment-274574951

If you are able to point to resources for building a text corpus for Khmer language, it will help in adding support for the language. https://github.com/tesseract-ocr/tessdata/blob/master/khm.traineddata On further testing,

khmer works with --oem 0. 
Using --oem 1 leads to only numbers and punctuation, as referred in https://github.com/tesseract-ocr/tesseract/issues/654 by Ray.

@zdenop , please reopen the issue, as khmer is not working  with --oem 1. Thanks.

Sample outputs attached.
[khm.Leelawadee_UI_Bold.exp0-0.txt](https://github.com/tesseract-ocr/tesseract/files/729037/khm.Leelawadee_UI_Bold.exp0-0.txt)
[khm.Leelawadee_UI_Bold.exp0-1.txt](https://github.com/tesseract-ocr/tesseract/files/729036/khm.Leelawadee_UI_Bold.exp0-1.txt)

  I find this:https://github.com/civetweb/civetweb/pull/356

macOS Sierra
use 'brew install tesseract' to install:


/usr/include/time.h:177:5: error: conflicting types for 'clock_get_time'
int clock_gettime(clockid_t __clock_id, struct timespec *__tp);
    ^
./openclwrapper.h:63:23: note: expanded from macro 'clock_gettime'
#define clock_gettime clock_get_time
                      ^
/usr/include/mach/clock.h:75:15: note: previous declaration is here
kern_return_t clock_get_time
              ^
1 error generated.
make[1]: *** [openclwrapper.lo] Error 1
make: *** [install-recursive] Error 1

thx! fixed For some reason `3.05.00dev` does not have this fix: https://github.com/tesseract-ocr/tesseract/commit/8e9159b09155

https://github.com/tesseract-ocr/tesseract/blob/3.05.00dev/opencl/openclwrapper.h#L63 i found the same problem when i brew install 
i fix it by
comment   //#define clock_gettime clock_get_time
in  openclwrapper.h 
this may help https://github.com/balabit/syslog-ng/issues/1249   
How should Vs2015 solve this problem ?
Too many Error...

It looks like the pixRead function found the file "a.png" in C: \\ datas, why does pixRead return a NULL value?

OS : Windows 10 pro
IDE tool : visual studio 2015 update 3
Teseract - ocr version link : https ://github.com/tesseract-ocr/tesseract   (Tesseract Open Source OCR Engine(main repository))
leptonica version : 1.74.0

#include <allheaders.h>
#include <baseapi.h>
#include <iostream>

	int main()
{
	char * outText = nullptr;
	Pix *image = nullptr;

	tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();
	// Initialize tesseract-ocr with English, without specifying tessdata path
	if (api->Init(NULL, "eng")) {
		fprintf(stderr, "Could not initialize tesseract.\n");
		exit(1);
	}



	image = pixRead("C:\\datas\\a.tif");
	api->SetImage(image);
	// Get OCR result
	outText = api->GetUTF8Text();
	printf("\n OCR output: %s \n", outText);

	// Destroy used object and release memory
	api->End();
	delete[] outText;
	pixDestroy(&image);

	return 0;
}

Output:
/********************************************************************/
Error in pixReadStreamPng : function not present
Error in pixReadStream : no fix returned
Error in pixRead : pix not Read
Error in pixGetDimensions : pix not defined
Error in pixGetColormap : pix not defined
Error in pixGetCopy : Pixs not defined
Error in pixGetDepth : pix not defined
Error in pixGetWpl : pix not defined
Error in pixGetYRes : pix not defined
Error in pixGetClone : Pixs not defined

Please call SetImage before attempting recognition.


  Hi, I've got this error suddenly

```
TesseractError: (-11, 'Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica\nDetected 386 diacritics\nFound AVX\nFound SSE')
```

Can anyone help me with this error? I have no idea what's causing the problem.
It worked fine on every other images I have Are you using a different language for this image?
 This is usually not an error, just an info message. Your output file should be created. >Detected 386 diacritics

Sometimes, this means the image has a lot of 'noise'. I was using python wrapper and yes, it seems like it's not an error but wrapper considers it as an error and terminates process.

I just made program skip those particular images when it throws exception.

Thanks all for your comments and I will be sure to ask on user forum next time 😃   Thanks again.  Nice!

What about moving the SIMD detection code to a separate file?
(maybe to `arch/simddetection.h`)  Hi there,
I am ready to test Tesseract 4.0 to make sure that the Arabic Language is not forgotten, but I am facing alot of problems in the training process, I know that Ray has done a great job in this version by documenting everything, but still i need some help.

Can somebody list the commands, line-by-line, from creating a tif+box from the text that i've attached, to creating an "ara.traineddata" assuming the font is timesnewroman.
My text is only 22 words, Download the text:  [arabic1.txt](https://github.com/tesseract-ocr/tesseract/files/673277/arabic1.txt)

**Do not , I repeat, Don't direct me to the documentation page, I need line-by-line help**
Thank you

 See https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Finetune @Shreeshrii
Thanks, your an amazing contributor  After making VS solution with next steps:
 cd tesseract
 cppan
 mkdir build
 cd build
 cmake ..

I want to build text2image project, but build failed with errors:
 
text2image.obj : error LNK2019: unresolved external symbol "struct tesseract::ParamsVectors * __cdecl GlobalParams(void)" (?GlobalParams@@YAPAUParamsVectors@tesseract@@XZ) referenced in function "void __cdecl `dynamic initializer for 'FLAGS_bidirectional_rotation''(void)" (??__EFLAGS_bidirectional_rotation@@YAXXZ)
pango_font_info.obj : error LNK2001: unresolved external symbol "struct tesseract::ParamsVectors * __cdecl GlobalParams(void)" (?GlobalParams@@YAPAUParamsVectors@tesseract@@XZ)
tlog.obj : error LNK2001: unresolved external symbol "struct tesseract::ParamsVectors * __cdecl GlobalParams(void)" (?GlobalParams@@YAPAUParamsVectors@tesseract@@XZ)
common_training.lib(commandlineflags.obj) : error LNK2001: unresolved external symbol "struct tesseract::ParamsVectors * __cdecl GlobalParams(void)" (?GlobalParams@@YAPAUParamsVectors@tesseract@@XZ)
text2image.obj : error LNK2019: unresolved external symbol "public: __thiscall UNICHARSET::UNICHARSET(void)" (??0UNICHARSET@@QAE@XZ) referenced in function _main
...

tesseract.exe was built and work fine.
text2image project has references on tesseract project and dependencies from ..\Debug\tesseract305d.lib This is a known issue. See https://github.com/tesseract-ocr/tesseract/pull/595#issuecomment-268362325 This issue is about Leptonica and other libs, but in my case problem seems is with resolving symbols from tesseract main library that itself built fine, Not only in text2image but also in other Training Tools, for example ambiguous_words:

ambiguous_words.obj : error LNK2019: unresolved external symbol "public: __thiscall WERD_CHOICE::WERD_CHOICE(char const *,class UNICHARSET const &)" (??0WERD_CHOICE@@QAE@PBDABVUNICHARSET@@@Z) referenced in function _main
ambiguous_words.obj : error LNK2019: unresolved external symbol "public: __thiscall WERD_CHOICE::~WERD_CHOICE(void)" (??1WERD_CHOICE@@QAE@XZ) referenced in function _main
ambiguous_words.obj : error LNK2019: unresolved external symbol "public: bool __thiscall tesseract::Dict::NoDangerousAmbig(class WERD_CHOICE *,class GenericVector<struct DANGERR_INFO> *,bool,class MATRIX *)" (?NoDangerousAmbig@Dict@tesseract@@QAE_NPAVWERD_CHOICE@@PAV?$GenericVector@UDANGERR_INFO@@@@_NPAVMATRIX@@@Z) referenced in function _main
 There is some other details. To make cmake work I download gtk+ from 
https://dl.hexchat.net/gtk-win32/vc14/x86/gtk-Win32.7z
set PKG_CONFIG_PATH=D:/gtk/win32/lib/pkgconfig
after cmake I also add paths 
D:\gtk\Win32\include
and
D:\gtk\Win32\lib
in text2image project I am using last sources from github from master Really, I have 3.6.2, I will try 3.7.1. Thank you. Great! It was built. Thanks again.  ```
(gdb) run
Starting program: /usr/local/bin/tesseract phototest.tif phototest -l eng
warning: Error disabling address space randomization: Success
warning: linux_ptrace_test_ret_to_nx: PTRACE_KILL waitpid returned -1: Interrupted system call
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Tesseract Open Source OCR Engine v4.00.00alpha-221-g34e4003 with Leptonica
Page 1
[New Thread 0x7fd8a83a0700 (LWP 17843)]
[New Thread 0x7fd8a5e20700 (LWP 17844)]
[New Thread 0x7fd8a5610700 (LWP 17845)]
Found AVX
Found SSE
DotProductAVX can't be used on Android
DotProductAVX can't be used on Android

Program received signal SIGABRT, Aborted.
0x00007fd8a9aa6c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
56      ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.
(gdb) backtrace
#0  0x00007fd8a9aa6c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
#1  0x00007fd8a9aaa028 in __GI_abort () at abort.c:89
#2  0x00007fd8aa9f5e86 in tesseract::DotProductAVX (u=<optimized out>, v=<optimized out>, n=<optimized out>) at dotproductavx.cpp:30
#3  0x00007fd8aaa30a5a in tesseract::WeightMatrix::MatrixDotVectorInternal (w=..., add_bias_fwd=add_bias_fwd@entry=true, skip_bias_back=skip_bias_back@entry=false,
    u=u@entry=0x33e3430, v=v@entry=0x33e3370) at weightmatrix.cpp:435
#4  0x00007fd8aaa30aea in tesseract::WeightMatrix::MatrixDotVector (this=this@entry=0x22196e8, u=u@entry=0x33e3430, v=v@entry=0x33e3370) at weightmatrix.cpp:235
#5  0x00007fd8aa9f9cdc in tesseract::FullyConnected::ForwardTimeStep (this=this@entry=0x22196a0, d_input=0x33e3430, i_input=<optimized out>, t=t@entry=0,
    output_line=output_line@entry=0x33e3370) at fullyconnected.cpp:180
#6  0x00007fd8aa9fa667 in tesseract::FullyConnected::Forward () at fullyconnected.cpp:141
#7  0x00007fd8aa9fbe01 in tesseract::FullyConnected::Forward (this=0x22196a0, debug=<optimized out>, input=..., input_transpose=<optimized out>, scratch=0x2208908,
    output=0x3086ad0) at fullyconnected.cpp:123
#8  0x00007fd8aaa2c30c in tesseract::Series::Forward (this=0x2219500, debug=<optimized out>, input=..., input_transpose=0x0, scratch=0x2208908, output=0x3086ad0)
    at series.cpp:107
#9  0x00007fd8aaa2c30c in tesseract::Series::Forward (this=0x2219350, debug=<optimized out>, input=..., input_transpose=0x0, scratch=0x2208908, output=0x7ffff3028a70)
    at series.cpp:107
#10 0x00007fd8aaa0b25b in tesseract::LSTMRecognizer::RecognizeLine (this=this@entry=0x22084e0, image_data=..., invert=invert@entry=true, debug=debug@entry=false,
    re_invert=re_invert@entry=false, label_threshold=label_threshold@entry=0.75, scale_factor=scale_factor@entry=0x7ffff3028a0c, inputs=inputs@entry=0x7ffff3028b00,
    outputs=outputs@entry=0x7ffff3028a70) at lstmrecognizer.cpp:277
#11 0x00007fd8aaa0d136 in tesseract::LSTMRecognizer::RecognizeLine (this=0x22084e0, image_data=..., invert=invert@entry=true, debug=false,
    worst_dict_cert=worst_dict_cert@entry=-3.5714285373687744, use_alternates=<optimized out>, target_unicharset=target_unicharset@entry=0x21cfc60, line_box=...,
    score_ratio=score_ratio@entry=2, one_word=one_word@entry=false, words=words@entry=0x7ffff3028d30) at lstmrecognizer.cpp:153
#12 0x00007fd8aa8b28f3 in tesseract::Tesseract::LSTMRecognizeWord (this=this@entry=0x21cfb70, block=..., row=row@entry=0x2fca520, word=<optimized out>,
    words=words@entry=0x7ffff3028d30) at linerec.cpp:245
#13 0x00007fd8aa897f03 in tesseract::Tesseract::classify_word_pass1 (this=0x21cfb70, word_data=..., in_word=0x2fdf7e0, out_words=0x7ffff3028d30) at control.cpp:1362
#14 0x00007fd8aa899240 in tesseract::Tesseract::RetryWithLanguage (this=0x21cfb70, word_data=..., recognizer=
    (void (tesseract::Tesseract::*)(tesseract::Tesseract * const, const tesseract::WordData &, WERD_RES **, tesseract::PointerVector<WERD_RES> *)) 0x7fd8aa897d40 <tess
eract::Tesseract::classify_word_pass1(tesseract::WordData const&, WERD_RES**, tesseract::PointerVector<WERD_RES>*)>, in_word=0x2fdf7e0,
    best_words=best_words@entry=0x7ffff3028df0) at control.cpp:888
#15 0x00007fd8aa899959 in tesseract::Tesseract::classify_word_and_language (this=this@entry=0x21cfb70, pass_n=pass_n@entry=1, pr_it=pr_it@entry=0x7ffff3028f50,
    word_data=word_data@entry=0x2fdf5d8) at control.cpp:1303
#16 0x00007fd8aa89d92b in tesseract::Tesseract::RecogAllWordsPassN (this=this@entry=0x21cfb70, pass_n=pass_n@entry=1, monitor=monitor@entry=0x0,
    pr_it=pr_it@entry=0x7ffff3028f50, words=words@entry=0x7ffff3028f30) at control.cpp:265
#17 0x00007fd8aa89e6b3 in tesseract::Tesseract::recog_all_words (this=0x21cfb70, page_res=0x2fad7b0, monitor=monitor@entry=0x0,
    target_word_box=target_word_box@entry=0x0, word_config=word_config@entry=0x0, dopasses=dopasses@entry=0) at control.cpp:352
#18 0x00007fd8aa887359 in tesseract::TessBaseAPI::Recognize (this=this@entry=0x7ffff3029380, monitor=0x0) at baseapi.cpp:852
#19 0x00007fd8aa8876fd in tesseract::TessBaseAPI::ProcessPage (this=this@entry=0x7ffff3029380, pix=0x22069a0, page_index=page_index@entry=0,
    filename=filename@entry=0x7ffff3029739 "phototest.tif", retry_config=retry_config@entry=0x0, timeout_millisec=timeout_millisec@entry=0, renderer=renderer@entry=
    0x2e70640) at baseapi.cpp:1164
#20 0x00007fd8aa887cc9 in tesseract::TessBaseAPI::ProcessPagesMultipageTiff (this=this@entry=0x7ffff3029380, data=data@entry=0x0, size=0,
    filename=filename@entry=0x7ffff3029739 "phototest.tif", retry_config=retry_config@entry=0x0, timeout_millisec=timeout_millisec@entry=0,
    renderer=renderer@entry=0x2e70640, tessedit_page_number=-1) at baseapi.cpp:1010
#21 0x00007fd8aa888018 in tesseract::TessBaseAPI::ProcessPagesInternal (this=this@entry=0x7ffff3029380, filename=<optimized out>,
---Type <return> to continue, or q <return> to quit---

``` I had commented the following 2 lines in configure.ac for tesseract to build

```
## Checks for supported compiler options.
AM_CONDITIONAL([AVX_OPT], false)
AM_CONDITIONAL([SSE41_OPT], false)
##AX_CHECK_COMPILE_FLAG([-mavx], [avx=1], [avx=0])
##AX_CHECK_COMPILE_FLAG([-msse4.1], [sse41=1], [sse41=0])
``` I reset git to an older commit. Now it works.

```
shree@ALL-IN-1-TOUCH:/mnt/c/Users/User/shree/tesseract/testing$ tesseract phototest.tif phototest -l eng
Tesseract Open Source OCR Engine v4.00.00alpha-139-g13e46ae with Leptonica
Page 1
Found AVX
Found SSE
```
 I am able to build 

 tesseract -v
tesseract 4.00.00alpha-204-g8b3c6ac
 leptonica-1.74
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

The latest snapshot does not build on same pc.  >I had commented the following 2 lines in configure.ac for tesseract to build

Give us the compilation output as file(s) attachment(s). If you do have avx and sse4.1 and the new code in configure.ac fails to discover it, you can fix it like this:

```
## Checks for supported compiler options.
AM_CONDITIONAL([AVX_OPT], true)
AM_CONDITIONAL([SSE41_OPT], true)
#AX_CHECK_COMPILE_FLAG([-mavx], [avx=1], [avx=0])
#AX_CHECK_COMPILE_FLAG([-msse4.1], [sse41=1], [sse41=0])
#if test x$avx = x1; then
#    AM_CONDITIONAL([AVX_OPT], true)
#fi
#if test x$sse41 = x1; then
#    AM_CONDITIONAL([SSE41_OPT], true)
#fi
``` It works after installing autoconf-archive as suggested by @zdenop  I am getting the same error running tesseract on Windows 10.
How should I run autoconf-archive on Windows?
Looks like there is a preprocessor directive to always throw this error on i386 architecture.
How should I fix this error on Windows? Same error is coming on running tesseract on ubuntu 16.04.someone please help.its urgent Hello sir,

Sorry for the inconvenience caused.I will not repeat my mistake.I have
installed tesseract on Ubuntu
16.04 32 bit os with the help of this site.
https://www.linux.com/blog/using-tesseract-ubuntu

Yes I can use tesseract 3.05 but i would you be highly obliged if you would
tell me the steps of properly uninstalling tesseract. And from where to
install tesseract 3.05 and which leptonica version to use.

Thank You for your help and guidance

Regards:
Vidushi Gupta
Student(M.Tech)(NSIT Delhi)

On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com>
wrote:

> @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> question on several places (even if it is urgent for you).
>
> Did you compile Tesseract yourself or do you use a pre-build version? Can
> you use Tesseract 3.05 or an earlier version? Tesseract 4.x is experimental
> and not for end users currently.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282265686>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 Use the ppa from https://launchpad.net/~alex-p/+archive/ubuntu/tesseract-ocr

sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
sudo apt-get update -q
sudo apt-get install tesseract-ocr -y


tesseract -v
tesseract --list-langs


sudo apt-get install tesseract-ocr-hin   -y
(if you want to install Hindi, similarly for other languages)

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com> wrote:

> Hello sir,
>
> Sorry for the inconvenience caused.I will not repeat my mistake.I have
> installed tesseract on Ubuntu
> 16.04 32 bit os with the help of this site.
> https://www.linux.com/blog/using-tesseract-ubuntu
>
> Yes I can use tesseract 3.05 but i would you be highly obliged if you would
> tell me the steps of properly uninstalling tesseract. And from where to
> install tesseract 3.05 and which leptonica version to use.
>
> Thank You for your help and guidance
>
> Regards:
> Vidushi Gupta
> Student(M.Tech)(NSIT Delhi)
>
> On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com>
> wrote:
>
> > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> > question on several places (even if it is urgent for you).
> >
> > Did you compile Tesseract yourself or do you use a pre-build version? Can
> > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> experimental
> > and not for end users currently.
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282265686>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-
> auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > .
> >
>
>
>
> --
> Vidushi
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282298890>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> .
>
 But how to uninstall the already installed tesseract and liptonica .These
two i have installed from source

On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <notifications@github.com>
wrote:

> Use the ppa from https://launchpad.net/~alex-p/
> +archive/ubuntu/tesseract-ocr
>
> sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> sudo apt-get update -q
> sudo apt-get install tesseract-ocr -y
>
>
> tesseract -v
> tesseract --list-langs
>
>
> sudo apt-get install tesseract-ocr-hin -y
> (if you want to install Hindi, similarly for other languages)
>
> ShreeDevi
> ____________________________________________________________
> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>
> On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
> wrote:
>
> > Hello sir,
> >
> > Sorry for the inconvenience caused.I will not repeat my mistake.I have
> > installed tesseract on Ubuntu
> > 16.04 32 bit os with the help of this site.
> > https://www.linux.com/blog/using-tesseract-ubuntu
> >
> > Yes I can use tesseract 3.05 but i would you be highly obliged if you
> would
> > tell me the steps of properly uninstalling tesseract. And from where to
> > install tesseract 3.05 and which leptonica version to use.
> >
> > Thank You for your help and guidance
> >
> > Regards:
> > Vidushi Gupta
> > Student(M.Tech)(NSIT Delhi)
> >
> > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com>
> > wrote:
> >
> > > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> > > question on several places (even if it is urgent for you).
> > >
> > > Did you compile Tesseract yourself or do you use a pre-build version?
> Can
> > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > experimental
> > > and not for end users currently.
> > >
> > > —
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282265686>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-
> > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > .
> > >
> >
> >
> >
> > --
> > Vidushi
> >
> > —
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282298890>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_
> o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
>
> > .
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282312789>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 Thank you for your help n support

On 24 Feb 2017 20:36, "Shreeshrii" <notifications@github.com> wrote:

> See the shell scripts in https://github.com/Shreeshrii/tess4eval_marathi
>
> you can change 4.0 by the 3.05 versions
>
> ShreeDevi
> ____________________________________________________________
> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>
> On Fri, Feb 24, 2017 at 8:31 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
> wrote:
>
> > Use the ppa from https://launchpad.net/~alex-p/+archive/ubuntu/
> > tesseract-ocr
> >
> > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > sudo apt-get update -q
> > sudo apt-get install tesseract-ocr -y
> >
> >
> > tesseract -v
> > tesseract --list-langs
> >
> >
> > sudo apt-get install tesseract-ocr-hin -y
> > (if you want to install Hindi, similarly for other languages)
> >
> > ShreeDevi
> > ____________________________________________________________
> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> >
> > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
> > wrote:
> >
> >> Hello sir,
> >>
> >> Sorry for the inconvenience caused.I will not repeat my mistake.I have
> >> installed tesseract on Ubuntu
> >> 16.04 32 bit os with the help of this site.
> >> https://www.linux.com/blog/using-tesseract-ubuntu
> >>
> >> Yes I can use tesseract 3.05 but i would you be highly obliged if you
> >> would
> >> tell me the steps of properly uninstalling tesseract. And from where to
> >> install tesseract 3.05 and which leptonica version to use.
> >>
> >> Thank You for your help and guidance
> >>
> >> Regards:
> >> Vidushi Gupta
> >> Student(M.Tech)(NSIT Delhi)
> >>
> >> On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com>
> >> wrote:
> >>
> >> > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> >> > question on several places (even if it is urgent for you).
> >> >
> >> > Did you compile Tesseract yourself or do you use a pre-build version?
> >> Can
> >> > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> >> experimental
> >> > and not for end users currently.
> >> >
> >> > —
> >> > You are receiving this because you were mentioned.
> >> > Reply to this email directly, view it on GitHub
> >> > <https://github.com/tesseract-ocr/tesseract/issues/610#issue
> >> comment-282265686>,
> >> > or mute the thread
> >> > <https://github.com/notifications/unsubscribe-auth/
> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> >> > .
> >> >
> >>
> >>
> >>
> >> --
> >> Vidushi
> >>
> >> —
> >> You are receiving this because you authored the thread.
> >> Reply to this email directly, view it on GitHub
> >> <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282298890>,
> >> or mute the thread
> >> <https://github.com/notifications/unsubscribe-auth/AE2_
> o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> >> .
> >>
> >
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282313481>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm3ECVBAY1kTVCX5pcrNj2WLlWwq9ks5rfvHagaJpZM4LVjQA>
> .
>
 But is there a way so that I could resolve my original problem?
On command prompt when i am typing

 tesseract img.PNG out

It is giving error as ---
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
DotProductAVX can't be used on Android
Aborted (core dumped)






On Fri, Feb 24, 2017 at 8:48 PM, Vidushi Gupta <vidushigupta2004@gmail.com>
wrote:

> Thank you for your help n support
>
> On 24 Feb 2017 20:36, "Shreeshrii" <notifications@github.com> wrote:
>
>> See the shell scripts in https://github.com/Shreeshrii/tess4eval_marathi
>>
>> you can change 4.0 by the 3.05 versions
>>
>> ShreeDevi
>> ____________________________________________________________
>> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>>
>> On Fri, Feb 24, 2017 at 8:31 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
>> wrote:
>>
>> > Use the ppa from https://launchpad.net/~alex-p/+archive/ubuntu/
>> > tesseract-ocr
>> >
>> > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
>> > sudo apt-get update -q
>> > sudo apt-get install tesseract-ocr -y
>> >
>> >
>> > tesseract -v
>> > tesseract --list-langs
>> >
>> >
>> > sudo apt-get install tesseract-ocr-hin -y
>> > (if you want to install Hindi, similarly for other languages)
>> >
>> > ShreeDevi
>> > ____________________________________________________________
>> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>> >
>> > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
>> > wrote:
>> >
>> >> Hello sir,
>> >>
>> >> Sorry for the inconvenience caused.I will not repeat my mistake.I have
>> >> installed tesseract on Ubuntu
>> >> 16.04 32 bit os with the help of this site.
>> >> https://www.linux.com/blog/using-tesseract-ubuntu
>> >>
>> >> Yes I can use tesseract 3.05 but i would you be highly obliged if you
>> >> would
>> >> tell me the steps of properly uninstalling tesseract. And from where to
>> >> install tesseract 3.05 and which leptonica version to use.
>> >>
>> >> Thank You for your help and guidance
>> >>
>> >> Regards:
>> >> Vidushi Gupta
>> >> Student(M.Tech)(NSIT Delhi)
>> >>
>> >> On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com
>> >
>> >> wrote:
>> >>
>> >> > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
>> >> > question on several places (even if it is urgent for you).
>> >> >
>> >> > Did you compile Tesseract yourself or do you use a pre-build version?
>> >> Can
>> >> > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
>> >> experimental
>> >> > and not for end users currently.
>> >> >
>> >> > —
>> >> > You are receiving this because you were mentioned.
>> >> > Reply to this email directly, view it on GitHub
>> >> > <https://github.com/tesseract-ocr/tesseract/issues/610#issue
>> >> comment-282265686>,
>> >> > or mute the thread
>> >> > <https://github.com/notifications/unsubscribe-auth/
>> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
>> >> > .
>> >> >
>> >>
>> >>
>> >>
>> >> --
>> >> Vidushi
>> >>
>> >> —
>> >> You are receiving this because you authored the thread.
>> >> Reply to this email directly, view it on GitHub
>> >> <https://github.com/tesseract-ocr/tesseract/issues/610#issue
>> comment-282298890>,
>> >> or mute the thread
>> >> <https://github.com/notifications/unsubscribe-auth/AE2_o1gQT
>> wf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
>> >> .
>> >>
>> >
>> >
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282313481>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AOjjm3ECVBAY1kTVCX5pcrNj2WLlWwq9ks5rfvHagaJpZM4LVjQA>
>> .
>>
>


-- 
Vidushi
 oks.
Thank You for your help and guidance

Regards
Vidushi

On Fri, Feb 24, 2017 at 9:59 PM, Shreeshrii <notifications@github.com>
wrote:

> You have cloned the master branch, which is not the released code, it is
> actively under development.
>
> What commit have you used?
>
> You can use Git log to display the status.
>
> As suggested by Stefan you should try the 3.05 branch.
>
> - excuse the brevity, sent from mobile
>
>
> On 24-Feb-2017 9:33 PM, "Vidushi12" <notifications@github.com> wrote:
>
> > But is there a way so that I could resolve my original problem?
> > On command prompt when i am typing
> >
> > tesseract img.PNG out
> >
> > It is giving error as ---
> > Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
> > DotProductAVX can't be used on Android
> > Aborted (core dumped)
> >
> >
> >
> >
> >
> >
> > On Fri, Feb 24, 2017 at 8:48 PM, Vidushi Gupta <
> vidushigupta2004@gmail.com
> > >
> > wrote:
> >
> > > Thank you for your help n support
> > >
> > > On 24 Feb 2017 20:36, "Shreeshrii" <notifications@github.com> wrote:
> > >
> > >> See the shell scripts in https://github.com/Shreeshrii/
> > tess4eval_marathi
> > >>
> > >> you can change 4.0 by the 3.05 versions
> > >>
> > >> ShreeDevi
> > >> ____________________________________________________________
> > >> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > >>
> > >> On Fri, Feb 24, 2017 at 8:31 PM, ShreeDevi Kumar <
> shreeshrii@gmail.com>
> > >> wrote:
> > >>
> > >> > Use the ppa from https://launchpad.net/~alex-p/+archive/ubuntu/
> > >> > tesseract-ocr
> > >> >
> > >> > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > >> > sudo apt-get update -q
> > >> > sudo apt-get install tesseract-ocr -y
> > >> >
> > >> >
> > >> > tesseract -v
> > >> > tesseract --list-langs
> > >> >
> > >> >
> > >> > sudo apt-get install tesseract-ocr-hin -y
> > >> > (if you want to install Hindi, similarly for other languages)
> > >> >
> > >> > ShreeDevi
> > >> > ____________________________________________________________
> > >> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > >> >
> > >> > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <
> notifications@github.com>
> > >> > wrote:
> > >> >
> > >> >> Hello sir,
> > >> >>
> > >> >> Sorry for the inconvenience caused.I will not repeat my mistake.I
> > have
> > >> >> installed tesseract on Ubuntu
> > >> >> 16.04 32 bit os with the help of this site.
> > >> >> https://www.linux.com/blog/using-tesseract-ubuntu
> > >> >>
> > >> >> Yes I can use tesseract 3.05 but i would you be highly obliged if
> you
> > >> >> would
> > >> >> tell me the steps of properly uninstalling tesseract. And from
> where
> > to
> > >> >> install tesseract 3.05 and which leptonica version to use.
> > >> >>
> > >> >> Thank You for your help and guidance
> > >> >>
> > >> >> Regards:
> > >> >> Vidushi Gupta
> > >> >> Student(M.Tech)(NSIT Delhi)
> > >> >>
> > >> >> On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <
> > notifications@github.com
> > >> >
> > >> >> wrote:
> > >> >>
> > >> >> > @Vidushi12 <https://github.com/Vidushi12>, please don't post
> your
> > >> >> > question on several places (even if it is urgent for you).
> > >> >> >
> > >> >> > Did you compile Tesseract yourself or do you use a pre-build
> > version?
> > >> >> Can
> > >> >> > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > >> >> experimental
> > >> >> > and not for end users currently.
> > >> >> >
> > >> >> > —
> > >> >> > You are receiving this because you were mentioned.
> > >> >> > Reply to this email directly, view it on GitHub
> > >> >> > <https://github.com/tesseract-ocr/tesseract/issues/610#issue
> > >> >> comment-282265686>,
> > >> >> > or mute the thread
> > >> >> > <https://github.com/notifications/unsubscribe-auth/
> > >> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > >> >> > .
> > >> >> >
> > >> >>
> > >> >>
> > >> >>
> > >> >> --
> > >> >> Vidushi
> > >> >>
> > >> >> —
> > >> >> You are receiving this because you authored the thread.
> > >> >> Reply to this email directly, view it on GitHub
> > >> >> <https://github.com/tesseract-ocr/tesseract/issues/610#issue
> > >> comment-282298890>,
> > >> >> or mute the thread
> > >> >> <https://github.com/notifications/unsubscribe-auth/AE2_o1gQT
> > >> wf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> > >> >> .
> > >> >>
> > >> >
> > >> >
> > >>
> > >> —
> > >> You are receiving this because you were mentioned.
> > >> Reply to this email directly, view it on GitHub
> > >> <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282313481>,
> > >> or mute the thread
> > >> <https://github.com/notifications/unsubscribe-auth/
> > AOjjm3ECVBAY1kTVCX5pcrNj2WLlWwq9ks5rfvHagaJpZM4LVjQA>
> > >> .
> > >>
> > >
> >
> >
> > --
> > Vidushi
> >
> > —
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282328731>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_
> o4wbSjXcxEL120X1ERZGrmJ2a1HZks5rfv89gaJpZM4LVjQA>
>
> > .
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282335846>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm5J_xrzVrVyHLO_qv05zmiDBJy_nks5rfwVUgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 Last thing i want to know ... can we use .png, .jpeg with 3.05 version of
tesseract ? On some sites it is written tesseract 4.0 version only works
with png file.

Will tesseract 3.05 version work with leptonica version 1.74?

Regards
Vidushi Gupta

On Fri, Feb 24, 2017 at 11:04 PM, Shreeshrii <notifications@github.com>
wrote:

> https://github.com/tesseract-ocr/tesseract/releases/tag/3.05.00
>
> Use the source from the zip/tar file
>
> - excuse the brevity, sent from mobile
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282353146>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm5xy0MycRfFhg9piC99w7mVXQ_LTks5rfxTBgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 3.05 should work with leptonica 1.74.

It will work with png, jpeg etc, depending on the libs installed

tesseract -v

Should show u the info.

4.0 is using a new OCR engine, LSTM.



- excuse the brevity, sent from mobile

On 24-Feb-2017 11:12 PM, "Vidushi12" <notifications@github.com> wrote:

> Last thing i want to know ... can we use .png, .jpeg with 3.05 version of
> tesseract ? On some sites it is written tesseract 4.0 version only works
> with png file.
>
> Will tesseract 3.05 version work with leptonica version 1.74?
>
> Regards
> Vidushi Gupta
>
> On Fri, Feb 24, 2017 at 11:04 PM, Shreeshrii <notifications@github.com>
> wrote:
>
> > https://github.com/tesseract-ocr/tesseract/releases/tag/3.05.00
> >
> > Use the source from the zip/tar file
> >
> > - excuse the brevity, sent from mobile
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282353146>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AOjjm5xy0MycRfFhg9piC99w7mVXQ_LTks5rfxTBgaJpZM4LVjQA>
> > .
> >
>
>
>
> --
> Vidushi
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282355013>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o7wPCmXb4EWJ7LWH_TZnLTsJ4dBtks5rfxZvgaJpZM4LVjQA>
> .
>
 See
https://github.com/tesseract-ocr/tesseract/wiki/Command-Line-Usage

The info was written for 3.04 and should apply to 3.05
- excuse the brevity, sent from mobile

On 24-Feb-2017 11:12 PM, "Vidushi12" <notifications@github.com> wrote:

> Last thing i want to know ... can we use .png, .jpeg with 3.05 version of
> tesseract ? On some sites it is written tesseract 4.0 version only works
> with png file.
>
> Will tesseract 3.05 version work with leptonica version 1.74?
>
> Regards
> Vidushi Gupta
>
> On Fri, Feb 24, 2017 at 11:04 PM, Shreeshrii <notifications@github.com>
> wrote:
>
> > https://github.com/tesseract-ocr/tesseract/releases/tag/3.05.00
> >
> > Use the source from the zip/tar file
> >
> > - excuse the brevity, sent from mobile
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282353146>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AOjjm5xy0MycRfFhg9piC99w7mVXQ_LTks5rfxTBgaJpZM4LVjQA>
> > .
> >
>
>
>
> --
> Vidushi
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282355013>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o7wPCmXb4EWJ7LWH_TZnLTsJ4dBtks5rfxZvgaJpZM4LVjQA>
> .
>
 i need only english language.but now the problm i m facing is how to
uninstall it....i have build tesseract from source.

On 24 Feb 2017 23:32, "Stefan Weil" <notifications@github.com> wrote:

> @Vidushi12 <https://github.com/Vidushi12>, I suggest to use the Tesseract
> provided by Ubuntu and don't build it yourself. Just run apt-get install
> tesseract-ocr tesseract-ocr-eng (add more languages as needed) as root
> user.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282360195>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjmxwoJYavRXWwDznBRCPIqAT92bkbks5rfxs5gaJpZM4LVjQA>
> .
>
 So i just need to delete tesseract file from usr/local/bin folder . After
that i will again install tesseract using the command apt-get install
tesseract-ocr tesseract-ocr-eng .

On Sat, Feb 25, 2017 at 12:05 AM, Stefan Weil <notifications@github.com>
wrote:

> You can either remove /usr/local/bin/tesseract, or don't uninstall it and
> call /usr/bin/tesseract explicitly.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282368238>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm5Gz1Gb4vGh3tkwYuotKHYcI_41Yks5rfyLYgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 ok
thank you sir for your help and support

On 25 Feb 2017 15:44, "Stefan Weil" <notifications@github.com> wrote:

> Yes, that's it.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282474563>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm_fTM8I4UGbrm2Og8AKefKgUwQhoks5rf_8QgaJpZM4LVjQA>
> .
>
 I followed the above commands. And when i try to compile the code it is
giving error as-

 fatal error: tesseract/baseapi.h: No such file or directory
compilation terminated.

For compilation i wrote the command

 g++ simple.cpp -o sim -l/usr/include/leptonica -l/usr/bin/tesseract -llept
-ltesseract

Please tell what could be the problem

Regards
Vidushi


On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <notifications@github.com>
wrote:

> Use the ppa from https://launchpad.net/~alex-p/
> +archive/ubuntu/tesseract-ocr
>
> sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> sudo apt-get update -q
> sudo apt-get install tesseract-ocr -y
>
>
> tesseract -v
> tesseract --list-langs
>
>
> sudo apt-get install tesseract-ocr-hin -y
> (if you want to install Hindi, similarly for other languages)
>
> ShreeDevi
> ____________________________________________________________
> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>
> On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
> wrote:
>
> > Hello sir,
> >
> > Sorry for the inconvenience caused.I will not repeat my mistake.I have
> > installed tesseract on Ubuntu
> > 16.04 32 bit os with the help of this site.
> > https://www.linux.com/blog/using-tesseract-ubuntu
> >
> > Yes I can use tesseract 3.05 but i would you be highly obliged if you
> would
> > tell me the steps of properly uninstalling tesseract. And from where to
> > install tesseract 3.05 and which leptonica version to use.
> >
> > Thank You for your help and guidance
> >
> > Regards:
> > Vidushi Gupta
> > Student(M.Tech)(NSIT Delhi)
> >
> > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com>
> > wrote:
> >
> > > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> > > question on several places (even if it is urgent for you).
> > >
> > > Did you compile Tesseract yourself or do you use a pre-build version?
> Can
> > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > experimental
> > > and not for end users currently.
> > >
> > > —
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282265686>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-
> > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > .
> > >
> >
> >
> >
> > --
> > Vidushi
> >
> > —
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282298890>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_
> o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
>
> > .
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282312789>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 sir i followed the steps but when i try to compile code it gives error.
tesseract/baseapi.h: No such file or directory


On Sat, Feb 25, 2017 at 3:46 PM, Vidushi Gupta <vidushigupta2004@gmail.com>
wrote:

> ok
> thank you sir for your help and support
>
> On 25 Feb 2017 15:44, "Stefan Weil" <notifications@github.com> wrote:
>
>> Yes, that's it.
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282474563>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AOjjm_fTM8I4UGbrm2Og8AKefKgUwQhoks5rf_8QgaJpZM4LVjQA>
>> .
>>
>


-- 
Vidushi
 ​apt-get install installs the program.

you dont need to compile it.

give the following commands to see what you have.

which tesseract

tesseract -v

tesseract --help

tesseract --list-langs​

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Feb 27, 2017 at 3:22 PM, Vidushi12 <notifications@github.com> wrote:

> I followed the above commands. And when i try to compile the code it is
> giving error as-
>
> fatal error: tesseract/baseapi.h: No such file or directory
> compilation terminated.
>
> For compilation i wrote the command
>
> g++ simple.cpp -o sim -l/usr/include/leptonica -l/usr/bin/tesseract -llept
> -ltesseract
>
> Please tell what could be the problem
>
> Regards
> Vidushi
>
>
> On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <notifications@github.com>
> wrote:
>
> > Use the ppa from https://launchpad.net/~alex-p/
> > +archive/ubuntu/tesseract-ocr
> >
> > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > sudo apt-get update -q
> > sudo apt-get install tesseract-ocr -y
> >
> >
> > tesseract -v
> > tesseract --list-langs
> >
> >
> > sudo apt-get install tesseract-ocr-hin -y
> > (if you want to install Hindi, similarly for other languages)
> >
> > ShreeDevi
> > ____________________________________________________________
> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> >
> > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
> > wrote:
> >
> > > Hello sir,
> > >
> > > Sorry for the inconvenience caused.I will not repeat my mistake.I have
> > > installed tesseract on Ubuntu
> > > 16.04 32 bit os with the help of this site.
> > > https://www.linux.com/blog/using-tesseract-ubuntu
> > >
> > > Yes I can use tesseract 3.05 but i would you be highly obliged if you
> > would
> > > tell me the steps of properly uninstalling tesseract. And from where to
> > > install tesseract 3.05 and which leptonica version to use.
> > >
> > > Thank You for your help and guidance
> > >
> > > Regards:
> > > Vidushi Gupta
> > > Student(M.Tech)(NSIT Delhi)
> > >
> > > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com
> >
> > > wrote:
> > >
> > > > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> > > > question on several places (even if it is urgent for you).
> > > >
> > > > Did you compile Tesseract yourself or do you use a pre-build version?
> > Can
> > > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > > experimental
> > > > and not for end users currently.
> > > >
> > > > —
> > > > You are receiving this because you were mentioned.
> > > > Reply to this email directly, view it on GitHub
> > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > issuecomment-282265686>,
> > > > or mute the thread
> > > > <https://github.com/notifications/unsubscribe-
> > > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > > .
> > > >
> > >
> > >
> > >
> > > --
> > > Vidushi
> > >
> > > —
> > > You are receiving this because you authored the thread.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282298890>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/AE2_
> > o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> >
> > > .
> > >
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282312789>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> > .
> >
>
>
>
> --
> Vidushi
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282674708>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o9-Q81fTzwHqZPg8gEZHrUzA9hVoks5rgpzJgaJpZM4LVjQA>
> .
>
 i was trying to run this code


http://8086892010.blogspot.in/2013/08/read-scanned-pdf-line-by-line-using.html

On Mon, Feb 27, 2017 at 4:12 PM, Shreeshrii <notifications@github.com>
wrote:

> ​apt-get install installs the program.
>
> you dont need to compile it.
>
> give the following commands to see what you have.
>
> which tesseract
>
> tesseract -v
>
> tesseract --help
>
> tesseract --list-langs​
>
> ShreeDevi
> ____________________________________________________________
> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>
> On Mon, Feb 27, 2017 at 3:22 PM, Vidushi12 <notifications@github.com>
> wrote:
>
> > I followed the above commands. And when i try to compile the code it is
> > giving error as-
> >
> > fatal error: tesseract/baseapi.h: No such file or directory
> > compilation terminated.
> >
> > For compilation i wrote the command
> >
> > g++ simple.cpp -o sim -l/usr/include/leptonica -l/usr/bin/tesseract
> -llept
> > -ltesseract
> >
> > Please tell what could be the problem
> >
> > Regards
> > Vidushi
> >
> >
> > On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <notifications@github.com>
> > wrote:
> >
> > > Use the ppa from https://launchpad.net/~alex-p/
> > > +archive/ubuntu/tesseract-ocr
> > >
> > > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > > sudo apt-get update -q
> > > sudo apt-get install tesseract-ocr -y
> > >
> > >
> > > tesseract -v
> > > tesseract --list-langs
> > >
> > >
> > > sudo apt-get install tesseract-ocr-hin -y
> > > (if you want to install Hindi, similarly for other languages)
> > >
> > > ShreeDevi
> > > ____________________________________________________________
> > > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > >
> > > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
> > > wrote:
> > >
> > > > Hello sir,
> > > >
> > > > Sorry for the inconvenience caused.I will not repeat my mistake.I
> have
> > > > installed tesseract on Ubuntu
> > > > 16.04 32 bit os with the help of this site.
> > > > https://www.linux.com/blog/using-tesseract-ubuntu
> > > >
> > > > Yes I can use tesseract 3.05 but i would you be highly obliged if you
> > > would
> > > > tell me the steps of properly uninstalling tesseract. And from where
> to
> > > > install tesseract 3.05 and which leptonica version to use.
> > > >
> > > > Thank You for your help and guidance
> > > >
> > > > Regards:
> > > > Vidushi Gupta
> > > > Student(M.Tech)(NSIT Delhi)
> > > >
> > > > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <
> notifications@github.com
> > >
> > > > wrote:
> > > >
> > > > > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> > > > > question on several places (even if it is urgent for you).
> > > > >
> > > > > Did you compile Tesseract yourself or do you use a pre-build
> version?
> > > Can
> > > > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > > > experimental
> > > > > and not for end users currently.
> > > > >
> > > > > —
> > > > > You are receiving this because you were mentioned.
> > > > > Reply to this email directly, view it on GitHub
> > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > issuecomment-282265686>,
> > > > > or mute the thread
> > > > > <https://github.com/notifications/unsubscribe-
> > > > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > > > .
> > > > >
> > > >
> > > >
> > > >
> > > > --
> > > > Vidushi
> > > >
> > > > —
> > > > You are receiving this because you authored the thread.
> > > > Reply to this email directly, view it on GitHub
> > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > issuecomment-282298890>,
> > > > or mute the thread
> > > > <https://github.com/notifications/unsubscribe-auth/AE2_
> > > o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> > >
> > > > .
> > > >
> > >
> > > —
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282312789>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/
> > AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> > > .
> > >
> >
> >
> >
> > --
> > Vidushi
> >
> > —
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282674708>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_o9-
> Q81fTzwHqZPg8gEZHrUzA9hVoks5rgpzJgaJpZM4LVjQA>
>
> > .
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282686155>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm7TEDa6-rWyrqgSt-qWJywC_7ftiks5rgqiugaJpZM4LVjQA>
> .
>



-- 
Vidushi
 step 2 > g++ test.cpp -o test -I/usr/include/leptonica
-I/usr/local/include/tesseract -llept -ltesseract


you have used  -l/usr/bin/tesseract in your command


ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Feb 27, 2017 at 5:37 PM, Vidushi12 <notifications@github.com> wrote:

> i was trying to run this code
>
>
> http://8086892010.blogspot.in/2013/08/read-scanned-pdf-line-
> by-line-using.html
>
> On Mon, Feb 27, 2017 at 4:12 PM, Shreeshrii <notifications@github.com>
> wrote:
>
> > ​apt-get install installs the program.
> >
> > you dont need to compile it.
> >
> > give the following commands to see what you have.
> >
> > which tesseract
> >
> > tesseract -v
> >
> > tesseract --help
> >
> > tesseract --list-langs​
> >
> > ShreeDevi
> > ____________________________________________________________
> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> >
> > On Mon, Feb 27, 2017 at 3:22 PM, Vidushi12 <notifications@github.com>
> > wrote:
> >
> > > I followed the above commands. And when i try to compile the code it is
> > > giving error as-
> > >
> > > fatal error: tesseract/baseapi.h: No such file or directory
> > > compilation terminated.
> > >
> > > For compilation i wrote the command
> > >
> > > g++ simple.cpp -o sim -l/usr/include/leptonica -l/usr/bin/tesseract
> > -llept
> > > -ltesseract
> > >
> > > Please tell what could be the problem
> > >
> > > Regards
> > > Vidushi
> > >
> > >
> > > On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <notifications@github.com>
> > > wrote:
> > >
> > > > Use the ppa from https://launchpad.net/~alex-p/
> > > > +archive/ubuntu/tesseract-ocr
> > > >
> > > > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > > > sudo apt-get update -q
> > > > sudo apt-get install tesseract-ocr -y
> > > >
> > > >
> > > > tesseract -v
> > > > tesseract --list-langs
> > > >
> > > >
> > > > sudo apt-get install tesseract-ocr-hin -y
> > > > (if you want to install Hindi, similarly for other languages)
> > > >
> > > > ShreeDevi
> > > > ____________________________________________________________
> > > > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > > >
> > > > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com
> >
> > > > wrote:
> > > >
> > > > > Hello sir,
> > > > >
> > > > > Sorry for the inconvenience caused.I will not repeat my mistake.I
> > have
> > > > > installed tesseract on Ubuntu
> > > > > 16.04 32 bit os with the help of this site.
> > > > > https://www.linux.com/blog/using-tesseract-ubuntu
> > > > >
> > > > > Yes I can use tesseract 3.05 but i would you be highly obliged if
> you
> > > > would
> > > > > tell me the steps of properly uninstalling tesseract. And from
> where
> > to
> > > > > install tesseract 3.05 and which leptonica version to use.
> > > > >
> > > > > Thank You for your help and guidance
> > > > >
> > > > > Regards:
> > > > > Vidushi Gupta
> > > > > Student(M.Tech)(NSIT Delhi)
> > > > >
> > > > > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <
> > notifications@github.com
> > > >
> > > > > wrote:
> > > > >
> > > > > > @Vidushi12 <https://github.com/Vidushi12>, please don't post
> your
> > > > > > question on several places (even if it is urgent for you).
> > > > > >
> > > > > > Did you compile Tesseract yourself or do you use a pre-build
> > version?
> > > > Can
> > > > > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > > > > experimental
> > > > > > and not for end users currently.
> > > > > >
> > > > > > —
> > > > > > You are receiving this because you were mentioned.
> > > > > > Reply to this email directly, view it on GitHub
> > > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > > issuecomment-282265686>,
> > > > > > or mute the thread
> > > > > > <https://github.com/notifications/unsubscribe-
> > > > > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > > > > .
> > > > > >
> > > > >
> > > > >
> > > > >
> > > > > --
> > > > > Vidushi
> > > > >
> > > > > —
> > > > > You are receiving this because you authored the thread.
> > > > > Reply to this email directly, view it on GitHub
> > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > issuecomment-282298890>,
> > > > > or mute the thread
> > > > > <https://github.com/notifications/unsubscribe-auth/AE2_
> > > > o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> > > >
> > > > > .
> > > > >
> > > >
> > > > —
> > > > You are receiving this because you were mentioned.
> > > > Reply to this email directly, view it on GitHub
> > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > issuecomment-282312789>,
> > > > or mute the thread
> > > > <https://github.com/notifications/unsubscribe-auth/
> > > AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> > > > .
> > > >
> > >
> > >
> > >
> > > --
> > > Vidushi
> > >
> > > —
> > > You are receiving this because you authored the thread.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282674708>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/AE2_o9-
> > Q81fTzwHqZPg8gEZHrUzA9hVoks5rgpzJgaJpZM4LVjQA>
> >
> > > .
> > >
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282686155>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AOjjm7TEDa6-rWyrqgSt-
> qWJywC_7ftiks5rgqiugaJpZM4LVjQA>
> > .
> >
>
>
>
> --
> Vidushi
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282702980>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o7c_Ky2N5toipjWMBnddaBS9UHpyks5rgryNgaJpZM4LVjQA>
> .
>
 Not able to remove tesseract from /usr/local/bin folder.

On Sat, Feb 25, 2017 at 12:05 AM, Stefan Weil <notifications@github.com>
wrote:

> You can either remove /usr/local/bin/tesseract, or don't uninstall it and
> call /usr/bin/tesseract explicitly.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282368238>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm5Gz1Gb4vGh3tkwYuotKHYcI_41Yks5rfyLYgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 HI

Sorry for disturbing again.Yesterday i was trying on my friend's system.It
works fine.But now when i am trying on my system it is giving same error.

DotProductAVX can't be used on Android
Aborted (core dumped)

Is it the problem of the system??
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#m_-8680517930591390332_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <notifications@github.com>
wrote:

> Use the ppa from https://launchpad.net/~alex-p/
> +archive/ubuntu/tesseract-ocr
>
> sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> sudo apt-get update -q
> sudo apt-get install tesseract-ocr -y
>
>
> tesseract -v
> tesseract --list-langs
>
>
> sudo apt-get install tesseract-ocr-hin -y
> (if you want to install Hindi, similarly for other languages)
>
> ShreeDevi
> ____________________________________________________________
> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>
> On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
> wrote:
>
> > Hello sir,
> >
> > Sorry for the inconvenience caused.I will not repeat my mistake.I have
> > installed tesseract on Ubuntu
> > 16.04 32 bit os with the help of this site.
> > https://www.linux.com/blog/using-tesseract-ubuntu
> >
> > Yes I can use tesseract 3.05 but i would you be highly obliged if you
> would
> > tell me the steps of properly uninstalling tesseract. And from where to
> > install tesseract 3.05 and which leptonica version to use.
> >
> > Thank You for your help and guidance
> >
> > Regards:
> > Vidushi Gupta
> > Student(M.Tech)(NSIT Delhi)
> >
> > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com>
> > wrote:
> >
> > > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> > > question on several places (even if it is urgent for you).
> > >
> > > Did you compile Tesseract yourself or do you use a pre-build version?
> Can
> > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > experimental
> > > and not for end users currently.
> > >
> > > —
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282265686>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-
> > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > .
> > >
> >
> >
> >
> > --
> > Vidushi
> >
> > —
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282298890>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_
> o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
>
> > .
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282312789>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 Can i delete tesseract-ocr from usr/share folder. I am thinking to remove
tesseract completely from ubuntu

On Fri, Feb 24, 2017 at 8:36 PM, Shreeshrii <notifications@github.com>
wrote:

> See the shell scripts in https://github.com/Shreeshrii/tess4eval_marathi
>
> you can change 4.0 by the 3.05 versions
>
> ShreeDevi
> ____________________________________________________________
> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>
> On Fri, Feb 24, 2017 at 8:31 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
>
> wrote:
>
> > Use the ppa from https://launchpad.net/~alex-p/+archive/ubuntu/
> > tesseract-ocr
> >
> > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > sudo apt-get update -q
> > sudo apt-get install tesseract-ocr -y
> >
> >
> > tesseract -v
> > tesseract --list-langs
> >
> >
> > sudo apt-get install tesseract-ocr-hin -y
> > (if you want to install Hindi, similarly for other languages)
> >
> > ShreeDevi
> > ____________________________________________________________
> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> >
> > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
> > wrote:
> >
> >> Hello sir,
> >>
> >> Sorry for the inconvenience caused.I will not repeat my mistake.I have
> >> installed tesseract on Ubuntu
> >> 16.04 32 bit os with the help of this site.
> >> https://www.linux.com/blog/using-tesseract-ubuntu
> >>
> >> Yes I can use tesseract 3.05 but i would you be highly obliged if you
> >> would
> >> tell me the steps of properly uninstalling tesseract. And from where to
> >> install tesseract 3.05 and which leptonica version to use.
> >>
> >> Thank You for your help and guidance
> >>
> >> Regards:
> >> Vidushi Gupta
> >> Student(M.Tech)(NSIT Delhi)
> >>
> >> On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com>
> >> wrote:
> >>
> >> > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
> >> > question on several places (even if it is urgent for you).
> >> >
> >> > Did you compile Tesseract yourself or do you use a pre-build version?
> >> Can
> >> > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> >> experimental
> >> > and not for end users currently.
> >> >
> >> > —
> >> > You are receiving this because you were mentioned.
> >> > Reply to this email directly, view it on GitHub
> >> > <https://github.com/tesseract-ocr/tesseract/issues/610#issue
> >> comment-282265686>,
> >> > or mute the thread
> >> > <https://github.com/notifications/unsubscribe-auth/
> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> >> > .
> >> >
> >>
> >>
> >>
> >> --
> >> Vidushi
> >>
> >> —
> >> You are receiving this because you authored the thread.
> >> Reply to this email directly, view it on GitHub
> >> <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282298890>,
> >> or mute the thread
> >> <https://github.com/notifications/unsubscribe-auth/AE2_
> o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> >> .
> >>
> >
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282313481>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm3ECVBAY1kTVCX5pcrNj2WLlWwq9ks5rfvHagaJpZM4LVjQA>
> .
>



-- 
Vidushi
 After performing the above steps I am still getting the following error

DotProductAVX can't be used on Android
Aborted (core dumped)

I would be highly obliged if you would help me in resolving the issue.

Regards
Vidushi

On Sat, Feb 25, 2017 at 12:05 AM, Stefan Weil <notifications@github.com>
wrote:

> You can either remove /usr/local/bin/tesseract, or don't uninstall it and
> call /usr/bin/tesseract explicitly.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282368238>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm5Gz1Gb4vGh3tkwYuotKHYcI_41Yks5rfyLYgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 Does tesseract work on 32-bit operating system

On Tue, Feb 28, 2017 at 3:54 PM, Vidushi Gupta <vidushigupta2004@gmail.com>
wrote:

> Can i delete tesseract-ocr from usr/share folder. I am thinking to remove
> tesseract completely from ubuntu
>
> On Fri, Feb 24, 2017 at 8:36 PM, Shreeshrii <notifications@github.com>
> wrote:
>
>> See the shell scripts in https://github.com/Shreeshrii/tess4eval_marathi
>>
>> you can change 4.0 by the 3.05 versions
>>
>> ShreeDevi
>> ____________________________________________________________
>> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>>
>> On Fri, Feb 24, 2017 at 8:31 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
>>
>> wrote:
>>
>> > Use the ppa from https://launchpad.net/~alex-p/+archive/ubuntu/
>> > tesseract-ocr
>> >
>> > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
>> > sudo apt-get update -q
>> > sudo apt-get install tesseract-ocr -y
>> >
>> >
>> > tesseract -v
>> > tesseract --list-langs
>> >
>> >
>> > sudo apt-get install tesseract-ocr-hin -y
>> > (if you want to install Hindi, similarly for other languages)
>> >
>> > ShreeDevi
>> > ____________________________________________________________
>> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>> >
>> > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
>> > wrote:
>> >
>> >> Hello sir,
>> >>
>> >> Sorry for the inconvenience caused.I will not repeat my mistake.I have
>> >> installed tesseract on Ubuntu
>> >> 16.04 32 bit os with the help of this site.
>> >> https://www.linux.com/blog/using-tesseract-ubuntu
>> >>
>> >> Yes I can use tesseract 3.05 but i would you be highly obliged if you
>> >> would
>> >> tell me the steps of properly uninstalling tesseract. And from where to
>> >> install tesseract 3.05 and which leptonica version to use.
>> >>
>> >> Thank You for your help and guidance
>> >>
>> >> Regards:
>> >> Vidushi Gupta
>> >> Student(M.Tech)(NSIT Delhi)
>> >>
>> >> On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <notifications@github.com
>> >
>> >> wrote:
>> >>
>> >> > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
>> >> > question on several places (even if it is urgent for you).
>> >> >
>> >> > Did you compile Tesseract yourself or do you use a pre-build version?
>> >> Can
>> >> > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
>> >> experimental
>> >> > and not for end users currently.
>> >> >
>> >> > —
>> >> > You are receiving this because you were mentioned.
>> >> > Reply to this email directly, view it on GitHub
>> >> > <https://github.com/tesseract-ocr/tesseract/issues/610#issue
>> >> comment-282265686>,
>> >> > or mute the thread
>> >> > <https://github.com/notifications/unsubscribe-auth/
>> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
>> >> > .
>> >> >
>> >>
>> >>
>> >>
>> >> --
>> >> Vidushi
>> >>
>> >> —
>> >> You are receiving this because you authored the thread.
>> >> Reply to this email directly, view it on GitHub
>> >> <https://github.com/tesseract-ocr/tesseract/issues/610#issue
>> comment-282298890>,
>> >> or mute the thread
>> >> <https://github.com/notifications/unsubscribe-auth/AE2_o1gQT
>> wf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
>> >> .
>> >>
>> >
>> >
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282313481>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AOjjm3ECVBAY1kTVCX5pcrNj2WLlWwq9ks5rfvHagaJpZM4LVjQA>
>> .
>>
>
>
>
> --
> Vidushi
>



-- 
Vidushi
 thanks for your help and guidance.Resolved the error.

On Tue, Feb 28, 2017 at 4:30 PM, Vidushi Gupta <vidushigupta2004@gmail.com>
wrote:

> Does tesseract work on 32-bit operating system
>
> On Tue, Feb 28, 2017 at 3:54 PM, Vidushi Gupta <vidushigupta2004@gmail.com
> > wrote:
>
>> Can i delete tesseract-ocr from usr/share folder. I am thinking to remove
>> tesseract completely from ubuntu
>>
>> On Fri, Feb 24, 2017 at 8:36 PM, Shreeshrii <notifications@github.com>
>> wrote:
>>
>>> See the shell scripts in https://github.com/Shreeshrii/tess4eval_marathi
>>>
>>> you can change 4.0 by the 3.05 versions
>>>
>>> ShreeDevi
>>> ____________________________________________________________
>>> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>>>
>>> On Fri, Feb 24, 2017 at 8:31 PM, ShreeDevi Kumar <shreeshrii@gmail.com>
>>>
>>> wrote:
>>>
>>> > Use the ppa from https://launchpad.net/~alex-p/+archive/ubuntu/
>>> > tesseract-ocr
>>> >
>>> > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
>>> > sudo apt-get update -q
>>> > sudo apt-get install tesseract-ocr -y
>>> >
>>> >
>>> > tesseract -v
>>> > tesseract --list-langs
>>> >
>>> >
>>> > sudo apt-get install tesseract-ocr-hin -y
>>> > (if you want to install Hindi, similarly for other languages)
>>> >
>>> > ShreeDevi
>>> > ____________________________________________________________
>>> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>>> >
>>> > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <notifications@github.com>
>>> > wrote:
>>> >
>>> >> Hello sir,
>>> >>
>>> >> Sorry for the inconvenience caused.I will not repeat my mistake.I have
>>> >> installed tesseract on Ubuntu
>>> >> 16.04 32 bit os with the help of this site.
>>> >> https://www.linux.com/blog/using-tesseract-ubuntu
>>> >>
>>> >> Yes I can use tesseract 3.05 but i would you be highly obliged if you
>>> >> would
>>> >> tell me the steps of properly uninstalling tesseract. And from where
>>> to
>>> >> install tesseract 3.05 and which leptonica version to use.
>>> >>
>>> >> Thank You for your help and guidance
>>> >>
>>> >> Regards:
>>> >> Vidushi Gupta
>>> >> Student(M.Tech)(NSIT Delhi)
>>> >>
>>> >> On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <
>>> notifications@github.com>
>>> >> wrote:
>>> >>
>>> >> > @Vidushi12 <https://github.com/Vidushi12>, please don't post your
>>> >> > question on several places (even if it is urgent for you).
>>> >> >
>>> >> > Did you compile Tesseract yourself or do you use a pre-build
>>> version?
>>> >> Can
>>> >> > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
>>> >> experimental
>>> >> > and not for end users currently.
>>> >> >
>>> >> > —
>>> >> > You are receiving this because you were mentioned.
>>> >> > Reply to this email directly, view it on GitHub
>>> >> > <https://github.com/tesseract-ocr/tesseract/issues/610#issue
>>> >> comment-282265686>,
>>> >> > or mute the thread
>>> >> > <https://github.com/notifications/unsubscribe-auth/
>>> >> AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
>>> >> > .
>>> >> >
>>> >>
>>> >>
>>> >>
>>> >> --
>>> >> Vidushi
>>> >>
>>> >> —
>>> >> You are receiving this because you authored the thread.
>>> >> Reply to this email directly, view it on GitHub
>>> >> <https://github.com/tesseract-ocr/tesseract/issues/610#issue
>>> comment-282298890>,
>>> >> or mute the thread
>>> >> <https://github.com/notifications/unsubscribe-auth/AE2_o1gQT
>>> wf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
>>> >> .
>>> >>
>>> >
>>> >
>>>
>>> —
>>> You are receiving this because you were mentioned.
>>> Reply to this email directly, view it on GitHub
>>> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282313481>,
>>> or mute the thread
>>> <https://github.com/notifications/unsubscribe-auth/AOjjm3ECVBAY1kTVCX5pcrNj2WLlWwq9ks5rfvHagaJpZM4LVjQA>
>>> .
>>>
>>
>>
>>
>> --
>> Vidushi
>>
>
>
>
> --
> Vidushi
>



-- 
Vidushi
 hi,

Is there a way to store the result of tesseract compiled code into text or
pdf file.I am using API example
https://github.com/tesseract-ocr/tesseract/wiki/APIExample.
I want to store the result into text or pdf file instead of displaying on
terminal.
Please tell if there is a way to do it.

On Mon, Feb 27, 2017 at 5:45 PM, Shreeshrii <notifications@github.com>
wrote:

> step 2 > g++ test.cpp -o test -I/usr/include/leptonica
> -I/usr/local/include/tesseract -llept -ltesseract
>
>
> you have used -l/usr/bin/tesseract in your command
>
>
> ShreeDevi
> ____________________________________________________________
> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>
> On Mon, Feb 27, 2017 at 5:37 PM, Vidushi12 <notifications@github.com>
> wrote:
>
> > i was trying to run this code
> >
> >
> > http://8086892010.blogspot.in/2013/08/read-scanned-pdf-line-
> > by-line-using.html
> >
> > On Mon, Feb 27, 2017 at 4:12 PM, Shreeshrii <notifications@github.com>
> > wrote:
> >
> > > ​apt-get install installs the program.
> > >
> > > you dont need to compile it.
> > >
> > > give the following commands to see what you have.
> > >
> > > which tesseract
> > >
> > > tesseract -v
> > >
> > > tesseract --help
> > >
> > > tesseract --list-langs​
> > >
> > > ShreeDevi
> > > ____________________________________________________________
> > > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > >
> > > On Mon, Feb 27, 2017 at 3:22 PM, Vidushi12 <notifications@github.com>
> > > wrote:
> > >
> > > > I followed the above commands. And when i try to compile the code it
> is
> > > > giving error as-
> > > >
> > > > fatal error: tesseract/baseapi.h: No such file or directory
> > > > compilation terminated.
> > > >
> > > > For compilation i wrote the command
> > > >
> > > > g++ simple.cpp -o sim -l/usr/include/leptonica -l/usr/bin/tesseract
> > > -llept
> > > > -ltesseract
> > > >
> > > > Please tell what could be the problem
> > > >
> > > > Regards
> > > > Vidushi
> > > >
> > > >
> > > > On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <
> notifications@github.com>
> > > > wrote:
> > > >
> > > > > Use the ppa from https://launchpad.net/~alex-p/
> > > > > +archive/ubuntu/tesseract-ocr
> > > > >
> > > > > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > > > > sudo apt-get update -q
> > > > > sudo apt-get install tesseract-ocr -y
> > > > >
> > > > >
> > > > > tesseract -v
> > > > > tesseract --list-langs
> > > > >
> > > > >
> > > > > sudo apt-get install tesseract-ocr-hin -y
> > > > > (if you want to install Hindi, similarly for other languages)
> > > > >
> > > > > ShreeDevi
> > > > > ____________________________________________________________
> > > > > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > > > >
> > > > > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <
> notifications@github.com
> > >
> > > > > wrote:
> > > > >
> > > > > > Hello sir,
> > > > > >
> > > > > > Sorry for the inconvenience caused.I will not repeat my mistake.I
> > > have
> > > > > > installed tesseract on Ubuntu
> > > > > > 16.04 32 bit os with the help of this site.
> > > > > > https://www.linux.com/blog/using-tesseract-ubuntu
> > > > > >
> > > > > > Yes I can use tesseract 3.05 but i would you be highly obliged if
> > you
> > > > > would
> > > > > > tell me the steps of properly uninstalling tesseract. And from
> > where
> > > to
> > > > > > install tesseract 3.05 and which leptonica version to use.
> > > > > >
> > > > > > Thank You for your help and guidance
> > > > > >
> > > > > > Regards:
> > > > > > Vidushi Gupta
> > > > > > Student(M.Tech)(NSIT Delhi)
> > > > > >
> > > > > > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <
> > > notifications@github.com
> > > > >
> > > > > > wrote:
> > > > > >
> > > > > > > @Vidushi12 <https://github.com/Vidushi12>, please don't post
> > your
> > > > > > > question on several places (even if it is urgent for you).
> > > > > > >
> > > > > > > Did you compile Tesseract yourself or do you use a pre-build
> > > version?
> > > > > Can
> > > > > > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x is
> > > > > > experimental
> > > > > > > and not for end users currently.
> > > > > > >
> > > > > > > —
> > > > > > > You are receiving this because you were mentioned.
> > > > > > > Reply to this email directly, view it on GitHub
> > > > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > > > issuecomment-282265686>,
> > > > > > > or mute the thread
> > > > > > > <https://github.com/notifications/unsubscribe-
> > > > > > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > > > > > .
> > > > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > > > --
> > > > > > Vidushi
> > > > > >
> > > > > > —
> > > > > > You are receiving this because you authored the thread.
> > > > > > Reply to this email directly, view it on GitHub
> > > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > > issuecomment-282298890>,
> > > > > > or mute the thread
> > > > > > <https://github.com/notifications/unsubscribe-auth/AE2_
> > > > > o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> > > > >
> > > > > > .
> > > > > >
> > > > >
> > > > > —
> > > > > You are receiving this because you were mentioned.
> > > > > Reply to this email directly, view it on GitHub
> > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > issuecomment-282312789>,
> > > > > or mute the thread
> > > > > <https://github.com/notifications/unsubscribe-auth/
> > > > AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> > > > > .
> > > > >
> > > >
> > > >
> > > >
> > > > --
> > > > Vidushi
> > > >
> > > > —
> > > > You are receiving this because you authored the thread.
> > > > Reply to this email directly, view it on GitHub
> > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > issuecomment-282674708>,
> > > > or mute the thread
> > > > <https://github.com/notifications/unsubscribe-auth/AE2_o9-
> > > Q81fTzwHqZPg8gEZHrUzA9hVoks5rgpzJgaJpZM4LVjQA>
> > >
> > > > .
> > > >
> > >
> > > —
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282686155>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-
> auth/AOjjm7TEDa6-rWyrqgSt-
> > qWJywC_7ftiks5rgqiugaJpZM4LVjQA>
> > > .
> > >
> >
> >
> >
> > --
> > Vidushi
> >
> > —
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282702980>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_o7c_
> Ky2N5toipjWMBnddaBS9UHpyks5rgryNgaJpZM4LVjQA>
>
> > .
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-282704298>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AOjjm0N7-WaR6aQmzmAKjuPPsv-6G1eAks5rgr5RgaJpZM4LVjQA>
> .
>



-- 
Vidushi
 It should be possible to do it via api. I know it can be done by
commandline.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Mar 7, 2017 at 12:43 PM, Vidushi12 <notifications@github.com> wrote:

> hi,
>
> Is there a way to store the result of tesseract compiled code into text or
> pdf file.I am using API example
> https://github.com/tesseract-ocr/tesseract/wiki/APIExample.
> I want to store the result into text or pdf file instead of displaying on
> terminal.
> Please tell if there is a way to do it.
>
> On Mon, Feb 27, 2017 at 5:45 PM, Shreeshrii <notifications@github.com>
> wrote:
>
> > step 2 > g++ test.cpp -o test -I/usr/include/leptonica
> > -I/usr/local/include/tesseract -llept -ltesseract
> >
> >
> > you have used -l/usr/bin/tesseract in your command
> >
> >
> > ShreeDevi
> > ____________________________________________________________
> > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> >
> > On Mon, Feb 27, 2017 at 5:37 PM, Vidushi12 <notifications@github.com>
> > wrote:
> >
> > > i was trying to run this code
> > >
> > >
> > > http://8086892010.blogspot.in/2013/08/read-scanned-pdf-line-
> > > by-line-using.html
> > >
> > > On Mon, Feb 27, 2017 at 4:12 PM, Shreeshrii <notifications@github.com>
> > > wrote:
> > >
> > > > ​apt-get install installs the program.
> > > >
> > > > you dont need to compile it.
> > > >
> > > > give the following commands to see what you have.
> > > >
> > > > which tesseract
> > > >
> > > > tesseract -v
> > > >
> > > > tesseract --help
> > > >
> > > > tesseract --list-langs​
> > > >
> > > > ShreeDevi
> > > > ____________________________________________________________
> > > > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > > >
> > > > On Mon, Feb 27, 2017 at 3:22 PM, Vidushi12 <notifications@github.com
> >
> > > > wrote:
> > > >
> > > > > I followed the above commands. And when i try to compile the code
> it
> > is
> > > > > giving error as-
> > > > >
> > > > > fatal error: tesseract/baseapi.h: No such file or directory
> > > > > compilation terminated.
> > > > >
> > > > > For compilation i wrote the command
> > > > >
> > > > > g++ simple.cpp -o sim -l/usr/include/leptonica -l/usr/bin/tesseract
> > > > -llept
> > > > > -ltesseract
> > > > >
> > > > > Please tell what could be the problem
> > > > >
> > > > > Regards
> > > > > Vidushi
> > > > >
> > > > >
> > > > > On Fri, Feb 24, 2017 at 8:33 PM, Shreeshrii <
> > notifications@github.com>
> > > > > wrote:
> > > > >
> > > > > > Use the ppa from https://launchpad.net/~alex-p/
> > > > > > +archive/ubuntu/tesseract-ocr
> > > > > >
> > > > > > sudo add-apt-repository ppa:alex-p/tesseract-ocr -y
> > > > > > sudo apt-get update -q
> > > > > > sudo apt-get install tesseract-ocr -y
> > > > > >
> > > > > >
> > > > > > tesseract -v
> > > > > > tesseract --list-langs
> > > > > >
> > > > > >
> > > > > > sudo apt-get install tesseract-ocr-hin -y
> > > > > > (if you want to install Hindi, similarly for other languages)
> > > > > >
> > > > > > ShreeDevi
> > > > > > ____________________________________________________________
> > > > > > भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
> > > > > >
> > > > > > On Fri, Feb 24, 2017 at 7:36 PM, Vidushi12 <
> > notifications@github.com
> > > >
> > > > > > wrote:
> > > > > >
> > > > > > > Hello sir,
> > > > > > >
> > > > > > > Sorry for the inconvenience caused.I will not repeat my
> mistake.I
> > > > have
> > > > > > > installed tesseract on Ubuntu
> > > > > > > 16.04 32 bit os with the help of this site.
> > > > > > > https://www.linux.com/blog/using-tesseract-ubuntu
> > > > > > >
> > > > > > > Yes I can use tesseract 3.05 but i would you be highly obliged
> if
> > > you
> > > > > > would
> > > > > > > tell me the steps of properly uninstalling tesseract. And from
> > > where
> > > > to
> > > > > > > install tesseract 3.05 and which leptonica version to use.
> > > > > > >
> > > > > > > Thank You for your help and guidance
> > > > > > >
> > > > > > > Regards:
> > > > > > > Vidushi Gupta
> > > > > > > Student(M.Tech)(NSIT Delhi)
> > > > > > >
> > > > > > > On Fri, Feb 24, 2017 at 4:35 PM, Stefan Weil <
> > > > notifications@github.com
> > > > > >
> > > > > > > wrote:
> > > > > > >
> > > > > > > > @Vidushi12 <https://github.com/Vidushi12>, please don't post
> > > your
> > > > > > > > question on several places (even if it is urgent for you).
> > > > > > > >
> > > > > > > > Did you compile Tesseract yourself or do you use a pre-build
> > > > version?
> > > > > > Can
> > > > > > > > you use Tesseract 3.05 or an earlier version? Tesseract 4.x
> is
> > > > > > > experimental
> > > > > > > > and not for end users currently.
> > > > > > > >
> > > > > > > > —
> > > > > > > > You are receiving this because you were mentioned.
> > > > > > > > Reply to this email directly, view it on GitHub
> > > > > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > > > > issuecomment-282265686>,
> > > > > > > > or mute the thread
> > > > > > > > <https://github.com/notifications/unsubscribe-
> > > > > > > auth/AOjjm8EWPhgNLL66P31ILvo3-Ys-Z8-Bks5rfrmEgaJpZM4LVjQA>
> > > > > > > > .
> > > > > > > >
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > > --
> > > > > > > Vidushi
> > > > > > >
> > > > > > > —
> > > > > > > You are receiving this because you authored the thread.
> > > > > > > Reply to this email directly, view it on GitHub
> > > > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > > > issuecomment-282298890>,
> > > > > > > or mute the thread
> > > > > > > <https://github.com/notifications/unsubscribe-auth/AE2_
> > > > > > o1gQTwf9MdAIA76EQZl14a17qt4Gks5rfuPkgaJpZM4LVjQA>
> > > > > >
> > > > > > > .
> > > > > > >
> > > > > >
> > > > > > —
> > > > > > You are receiving this because you were mentioned.
> > > > > > Reply to this email directly, view it on GitHub
> > > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > > issuecomment-282312789>,
> > > > > > or mute the thread
> > > > > > <https://github.com/notifications/unsubscribe-auth/
> > > > > AOjjm0ard3uXWnJH9HxOEb9NB7BKBIcGks5rfvEmgaJpZM4LVjQA>
> > > > > > .
> > > > > >
> > > > >
> > > > >
> > > > >
> > > > > --
> > > > > Vidushi
> > > > >
> > > > > —
> > > > > You are receiving this because you authored the thread.
> > > > > Reply to this email directly, view it on GitHub
> > > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > > issuecomment-282674708>,
> > > > > or mute the thread
> > > > > <https://github.com/notifications/unsubscribe-auth/AE2_o9-
> > > > Q81fTzwHqZPg8gEZHrUzA9hVoks5rgpzJgaJpZM4LVjQA>
> > > >
> > > > > .
> > > > >
> > > >
> > > > —
> > > > You are receiving this because you were mentioned.
> > > > Reply to this email directly, view it on GitHub
> > > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > > issuecomment-282686155>,
> > > > or mute the thread
> > > > <https://github.com/notifications/unsubscribe-
> > auth/AOjjm7TEDa6-rWyrqgSt-
> > > qWJywC_7ftiks5rgqiugaJpZM4LVjQA>
> > > > .
> > > >
> > >
> > >
> > >
> > > --
> > > Vidushi
> > >
> > > —
> > > You are receiving this because you authored the thread.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/610#
> > issuecomment-282702980>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/AE2_o7c_
> > Ky2N5toipjWMBnddaBS9UHpyks5rgryNgaJpZM4LVjQA>
> >
> > > .
> > >
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/610#
> issuecomment-282704298>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AOjjm0N7-
> WaR6aQmzmAKjuPPsv-6G1eAks5rgr5RgaJpZM4LVjQA>
> > .
> >
>
>
>
> --
> Vidushi
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/610#issuecomment-284640944>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o24Wx3WC7atlqW0P8rmxhULchVJjks5rjQOVgaJpZM4LVjQA>
> .
>
   @stweil 

In `configure.ac,` should we change
>PKG_CHECK_MODULES([LEPTONICA], [lept >= 1.74], [have_lept=true], [have_lept=false])

to

>PKG_CHECK_MODULES([LEPTONICA], [lept >= 1.74.0], [have_lept=true], [have_lept=false])

? This is how it is tagged in the github repo. In the Leptonica website it is '1.74'.
You can change it if you want to :-) I did it after the `.travis.yml` [commits](https://github.com/tesseract-ocr/tesseract/pull/605). As you can see, I needed 3 tries to make it work :-)
1.74 -> 1.74.0 -> +drop the `v` before the version number ...

So I thought it should be 1.74.0 in CMake too. @DanBloomberg

The `1.74` vs. `1.74.0` is somewhat confusing ... Seems like we have a problem with the 1.74.0 version numbering.  What do
you suggest that we do here?  New github release?  Replacement? Nothing?

On Mon, Dec 26, 2016 at 2:10 PM, Stefan Weil <notifications@github.com>
wrote:

> I just ran a test with cmake 3.7.1-1 on Debian GNU Linux. It also works
> only with 1.74, but not with 1.74.0.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/608#issuecomment-269245065>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLNTIpQ9_c7fCyh6OFkdZidkx24NCks5rMDtvgaJpZM4LVW_Z>
> .
>
 The problem is that Leptonica's `lept.pc` has 1.74 rather than 1.74.0. If you edit that file to have the latter then it works. This value originates from `configure.ac`, which also has 1.74. @DanBloomberg, you need to be consistent with this everywhere. Seems like I should make a new github release for leptonica, with the correct version
number in configure.ac.  If you agree, should I replace 1.74.0 or make
1.74.1?

  -- Dan

On Sat, Dec 31, 2016 at 1:51 PM, Stefan Weil <notifications@github.com>
wrote:

> Yes, I think this is the reason why 1.74.0 did not work for me.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/608#issuecomment-269883123>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLB1I0zUtfSfCWjkMVAISrwSDgVG2ks5rNs5zgaJpZM4LVW_Z>
> .
>
 At this point, I don't mind sticking with 1.74 for now as we've already compensated in the necessary places. My Gentoo release ended up being 1.74 as this matched the tarball and the tarball's subdirectory. But if you want to push a new 1.74.1 release out to make sure we get it right while it's still fresh in our minds, that's cool. I was thinking of RELEASE, but I can go with PATCH.

On Sun, Jan 1, 2017 at 8:49 AM, Egor Pugin <notifications@github.com> wrote:

> Or better LIBLEPT_PATCH_VERSION as in semver (major.minor.patch).
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/pull/608#issuecomment-269910132>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLEGrqUyXl5dJF8dqs5zpJFRjyylwks5rN9kwgaJpZM4LVW_Z>
> .
>
 I've put up on github the leptonica 1.74.1 release.

In theory, it solves all the existing issues with builds.  In practice,
we'll see ...

It's also up as a configure/make tarball on leptonica.org.  (The difference
between the two is just running the autobuild script on the github release,
which requires autotools.)


> I was thinking of RELEASE, but I can go with PATCH.
>
> On Sun, Jan 1, 2017 at 8:49 AM, Egor Pugin <notifications@github.com>
> wrote:
>
>> Or better LIBLEPT_PATCH_VERSION as in semver (major.minor.patch).
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/pull/608#issuecomment-269910132>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AP6mLEGrqUyXl5dJF8dqs5zpJFRjyylwks5rN9kwgaJpZM4LVW_Z>
>> .
>>
>
>
  This code:

```
tesseract::ParamsVectors *GlobalParams() {
  static tesseract::ParamsVectors *global_params =
    new tesseract::ParamsVectors();
  return global_params;
}
```
is causing a memory leak. I don't see any means of removing it while tesseract engine is no longer needed in the application. Thanks!  I installed tesseract using sudo port install tesseract tesseract-eng.
I took a screenshot using command+shift+3 on Mac, and try to ocr the screenshot. However, I get the following message, and the output file is empty.
$ tesseract screenshot.png output
Tesseract Open Source OCR Engine v3.04.01 with Leptonica
Warning in pixReadMemPng: work-around: writing to a temp file
What might be causing this?
Thanks for your help! You should ignore this message. Regardless the message, the output file is empty. Is it an error? Thanks! Thank you for helping with this.
Yes, definitely has text.
When I try to build tesseract from source, I get this from ./configure
checking host system type... x86_64-apple-darwin16.1.0
./configure: line 4237: syntax error near unexpected token `-mavx,'
./configure: line 4237: `AX_CHECK_COMPILE_FLAG(-mavx, avx=1, avx=0)'
Is there prebuilt binary for tesseract 4 for Mac somewhere? See https://github.com/tesseract-ocr/tesseract/issues/601#issuecomment-269197286
You need an equivalent package for Mac. Do you happen to know what that might be? I searched mavx on macports, but nothing turned up. https://www.macports.org/ports.php?by=library&substr=autoconf-archive  Hi there, tired to run following command on the attached Image:

`$ tesseract TH.jpg outbutbase -l vie -psm 7`

![th](https://cloud.githubusercontent.com/assets/1496858/21446802/66d4839c-c8fd-11e6-8550-942a48363229.jpg)

Getting only "ParamsModel::Incomplete line" erros, see here:
![2016-12-23_10h46_01](https://cloud.githubusercontent.com/assets/1496858/21446813/9528b056-c8fd-11e6-8e9b-1634cd763e6e.jpg)

Specs: 
Windows Server 2012R2

```
C:\Users\Administrator\Desktop\Tesseract-OCR>tesseract --version
tesseract 3.05.00dev
 leptonica-1.73
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.6.20 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.3 : libopenjp2 2.1.0
```

Installed Vietnamese language during setup wizard  Hey,
Trying to install openalpr, which requires tesseract as a dependency.

Everything goes fine until I try to 'make' tesseract

The first error is:

g++: error: unrecognized command line option '-mavx'

I'm not sure how to go further. Can anyone help?

Full error stacktrace:
`pi@raspberrypi:~/openalpr/libraries/tesseract $ make -j4
make all-recursive
make[1]: Entering directory '/home/pi/openalpr/libraries/tesseract'
Making all in arch
make[2]: Entering directory '/home/pi/openalpr/libraries/tesseract/arch'
make[3]: Entering directory '/home/pi/openalpr/libraries/tesseract/arch'
/bin/bash ../libtool --tag=CXX --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I../ccutil -I/usr/local/include/leptonica -pthread -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng12 -mavx -g -O2 -std=c++11 -MT libtesseract_avx_la-dotproductavx.lo -MD -MP -MF .deps/libtesseract_avx_la-dotproductavx.Tpo -c -o libtesseract_avx_la-dotproductavx.lo test -f 'dotproductavx.cpp' || echo './'dotproductavx.cpp
/bin/bash ../libtool --tag=CXX --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I../ccutil -I/usr/local/include/leptonica -pthread -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng12 -msse4.1 -g -O2 -std=c++11 -MT libtesseract_sse_la-dotproductsse.lo -MD -MP -MF .deps/libtesseract_sse_la-dotproductsse.Tpo -c -o libtesseract_sse_la-dotproductsse.lo test -f 'dotproductsse.cpp' || echo './'dotproductsse.cpp
libtool: compile: g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I../ccutil -I/usr/local/include/leptonica -pthread -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng12 -mavx -g -O2 -std=c++11 -MT libtesseract_avx_la-dotproductavx.lo -MD -MP -MF .deps/libtesseract_avx_la-dotproductavx.Tpo -c dotproductavx.cpp -fPIC -DPIC -o .libs/libtesseract_avx_la-dotproductavx.o
g++: error: unrecognized command line option '-mavx'
Makefile:537: recipe for target 'libtesseract_avx_la-dotproductavx.lo' failed
make[3]: *** [libtesseract_avx_la-dotproductavx.lo] Error 1
make[3]: *** Waiting for unfinished jobs....
libtool: compile: g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I../ccutil -I/usr/local/include/leptonica -pthread -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/arm-linux-gnueabihf/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng12 -msse4.1 -g -O2 -std=c++11 -MT libtesseract_sse_la-dotproductsse.lo -MD -MP -MF .deps/libtesseract_sse_la-dotproductsse.Tpo -c dotproductsse.cpp -fPIC -DPIC -o .libs/libtesseract_sse_la-dotproductsse.o
g++: error: unrecognized command line option '-msse4.1'
Makefile:544: recipe for target 'libtesseract_sse_la-dotproductsse.lo' failed
make[3]: *** [libtesseract_sse_la-dotproductsse.lo] Error 1
make[3]: Leaving directory '/home/pi/openalpr/libraries/tesseract/arch'
Makefile:584: recipe for target 'all-recursive' failed
make[2]: *** [all-recursive] Error 1
make[2]: Leaving directory '/home/pi/openalpr/libraries/tesseract/arch'
Makefile:478: recipe for target 'all-recursive' failed
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory '/home/pi/openalpr/libraries/tesseract'
Makefile:386: recipe for target 'all' failed
make: *** [all] Error 2`


 In arch/Makefile.am, disable or remove these lines:

>libtesseract_avx_la_CXXFLAGS = -mavx
libtesseract_sse_la_CXXFLAGS = -msse4.1

The code in master is in 'alpha' state and the support for ARM seems to be less good than for x86. @zdenop, @stweil 

We need to get the CPU type in configure.ac and add a condition around those lines in the Makefile.am.
 I got this error with latest master (commit c124f87d5ba974c7854cfc857f5f2b0cb5236f61
) - it worked before (first week of dec)

```
checking host system type... x86_64-unknown-linux-gnu
./configure: line 4228: syntax error near unexpected token `-mavx,'
./configure: line 4228: `AX_CHECK_COMPILE_FLAG(-mavx, avx=1, avx=0)'
/bin/bash ./config.status --recheck
running CONFIG_SHELL=/bin/bash /bin/bash ./configure --enable-debug --no-create --no-recursion
checking for g++... g++
```

```
checking host system type... x86_64-unknown-linux-gnu
./configure: line 4229: syntax error near unexpected token `-msse4.1,'
./configure: line 4229: `AX_CHECK_COMPILE_FLAG(-msse4.1, sse41=1, sse41=0)'
/bin/bash ./config.status --recheck

```

I was able to get around it by commenting out the following 2 lines in configure.ac

```
## Checks for supported compiler options.
AM_CONDITIONAL([AVX_OPT], false)
AM_CONDITIONAL([SSE41_OPT], false)
##AX_CHECK_COMPILE_FLAG([-mavx], [avx=1], [avx=0])
##AX_CHECK_COMPILE_FLAG([-msse4.1], [sse41=1], [sse41=0])
``` @zdenop  Thanks! It works now.  I now have a framework.
But crash "actual_tessdata_num_entries_ <= TESSDATA_NUM_ENTRIES:Error:Assert failed:in file tessdatamanager.cpp, line 53".
Under the framework where the latest

This problem I use pod 'TesseractOCRiOS' update and download the traineddata https://github.com/tesseract-ocr/tessdata/tree/bf82613055ebc6e63d9e3b438a5c234bfd638c93
 Now the question is "Can't analyse layout. Make sure 'osd.traineddata' available in 'tessdata' "
But in the Bundle with this file.
How to solve?
  Hi there. Sorry for the silly question... after I installed this application on my system using Mac ports I could not invoke it's GUI. Do you know where the program is installed so I can open it up with the GUI? Thank you.   I don't know why it fails 64-bit build. Perhaps @FeodorFitsner can explain. Nice to see this working. It worth documenting how to get development builds at https://github.com/tesseract-ocr/tesseract/wiki#windows  >needed for macOS

I'm on Linux... Personally, I like Meson
https://github.com/mesonbuild/meson >autotools is written in C

and  perl, shell, m4 and make ...
 >in the future I hope will be able to build the last training tool - text2image on windows - which is very hard with pure cmake.

What are the issues with text2image and cmake?    ![image](https://cloud.githubusercontent.com/assets/5406399/21318185/3e53f010-c619-11e6-89fb-584df597505a.png)

I used this - https://github.com/tesseract-ocr/tesseract/wiki/Compiling#windows
When I try to build it in Debug or Release (I need to get tesseract .lib and .dll for my project), I get bunch of errors because the unicode .lib file is missing. ALL errors associated with this.
I tried
```
cppan --clean-packages .*unicode.*
cppan
```
Same errors Without STATIC=1 I get:
```
20>LINK : fatal error LNK1104: cannot open file '..\Debug\tesseract305d.lib'
19>LINK : fatal error LNK1104: cannot open file '..\Debug\tesseract305d.lib'
18>LINK : fatal error LNK1104: cannot open file '..\Debug\tesseract305d.lib'
17>LINK : fatal error LNK1104: cannot open file '..\Debug\tesseract305d.lib'
``` I removed the folder C:/Users/HOME/.cppan and re-downloaded the repository to start over. Here are my steps.
```
git clone https://github.com/tesseract-ocr/tesseract tesserac
cd tesserac
cppan --self-upgrade
cppan
mkdir win32
cd win32
cmake .. > 1.txt 2>&1
```
Then I had this issue - https://github.com/tesseract-ocr/tesseract/issues/464#issuecomment-264166445 There was two cmake.exe processes, I stopped one with memory 2304KB (second had bigger memory 4496KB). Also sometimes can hangs 3 processes.
`cmake --build . --config Release > 2.txt 2>&1`
I have build error unfortunately... Can you look at it?
https://gist.github.com/Izaron/c0471f1727af1ca7c0f67b398a1a5cd4 - 1.txt
https://gist.github.com/Izaron/d1116ae559c7a40cbebcf7794f7f0a35 - 2.txt

I tried to do this several times and get different number of errors in 2.txt. I have no idea the reason why this is happening I have correct VS 2015.
It's question marks because of default russian language. In UTF-8: https://gist.github.com/Izaron/071268b9ba1c863bd6b055d6f37ce077
I built it again (deleted .cppan, cmake, etc.). As you can see, quite a different number of errors Finally build it .dll and .lib, thank you very much @egorpugin!

In new example project I put all folders to includes in properties and linked tesseract305.lib, so I can include <baseapi.h>, but can not include <allheaders.h>. Should I build leptonica for windows to use allheader.h and pixRead? From command line works well, but if I want to compile this code in VS - https://github.com/cppan/tesseract_example/blob/master/with_cppan/main.cpp

Also built files are named tesseract305.dll and tesseract305.lib, is this normal? I have failed again with this **simple** command.
But I sure I understand what the problem is. In the console cppan writes that downloads and unpacks **18** different packages. But I do it every time, not all files downloads - on my PC only from 4 to 11 files random files during all this time, but sometimes this is enough to build some projects. That is why as a result of build errors is different - from 50 to 1500, and sometimes 0.
This program is also frequently breaks while downloading and unpacking (every third time around).
All I need - .lib and .dll files of the dependencies (including leptonica) and built .lib and .dll of 4.0.0 tesseract (current master branch, right?), in order that I can update it in one of my project from older version.
Can you give me all these dependency files? I can add them to any project for using leptonica and tesseract and compile , including current tesseract master (although I was able to magically compile it with **9** downloaded dependencies - excluding gif, webp and almost all unicode libs). Thanks for the support!  Loaded 4128/4128 pages (0-4128) of document /home/shree/tesstutorial/sanskrittrain/san.Yatra_One.exp0.lstmf
Compute CTC targets failed!
At iteration 200/200/202, Mean rms=1.024%, delta=70.515%, char train=100.405%, word train=100%, skip ratio=1%,  New worst char error = 100.405 wrote checkpoint. ```
$ lstmtraining -U ~/tesstutorial/aratest/ara.unicharset \
>   --script_dir ../langdata  --debug_interval 0 \
>   --continue_from ~/tesstutorial/aralayer_from_aratest/ara.lstm \
>   --append_index 5 --net_spec '[Lfx256 O1c105]' \
>   --learning_rate 10e-5 \
>   --net_mode 192 \
>   --perfect_sample_delay 19 \
>   --model_output ~/tesstutorial/aralayer_from_aratest/aralayer \
>   --train_listfile ~/tesstutorial/aratest/ara.training_files.txt \
>   --target_error_rate 0.01
Loaded file /home/shree/tesstutorial/aralayer_from_aratest/aralayer_checkpoint, unpacking...
Successfully restored trainer from /home/shree/tesstutorial/aralayer_from_aratest/aralayer_checkpoint
Loaded 182/182 pages (1-182) of document /home/shree/tesstutorial/aratest/ara.Arial_Unicode_MS.exp0.lstmf
Loaded 135/135 pages (1-135) of document /home/shree/tesstutorial/aratest/ara.Traditional_Arabic.exp0.lstmf
Compute CTC targets failed!
2 Percent improvement time=458, best error was 12.971 @ 3844
At iteration 4302/5200/5239, Mean rms=1.375%, delta=3.33%, char train=10.699%, word train=30.237%, skip ratio=0.7%,  New best char error = 10.699 wr
ote best model:/home/shree/tesstutorial/aralayer_from_aratest/aralayer10.699_4302.lstm wrote checkpoint.

Compute CTC targets failed!
2 Percent improvement time=522, best error was 12.971 @ 3844
At iteration 4366/5300/5340, Mean rms=1.371%, delta=3.274%, char train=10.64%, word train=30.125%, skip ratio=0.8%,  New best char error = 10.64 wro
te checkpoint.


``` @Shreeshrii any luck with this ? I am trying to train on camera taken images and I have been getting the same error 
and training doesnt converge, i have a error rate of 70% right now @ferjad 

I am not sure what causes 'Compute CTC targets failed!' 

Still waiting on updates to code and traineddata from @theraysmith after retraining, to test further.

Which language are you trying to train? You need a large training set for 4.0. @Shreeshrii  I have a training set of 5000 images that have 15000 lines in total
Language is english but the images are camera blurred with different angles, LSTM are known to learn data is this setting 
Data shouldnt be a problem, I saw you trained some other scripts too on your  other opened issue on github
did you manage to get around it? @Shreeshrii  can you share a image and box pair? Did you use the Wordstr format for box files? Wordstr option is not fully operational yet.

Text2image creates the box file with tab at end of line.

You can use jtessboxeditor and use the option under tools to add tab for
eol to existing box files.



- excuse the brevity, sent from mobile

On 03-Mar-2017 8:50 PM, "ferjad" <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/Shreeshrii> can you share a image and box
> pair? Did you use the Wordstr format for box files?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/591#issuecomment-283981485>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o9SFjFTkqJDw1y0P_MFQ2OTqCm8Rks5riC-1gaJpZM4LQswx>
> .
>
 @Shreeshrii The problem is I want to train on real world data and not synthetic and manually labelling character by character isnt possible
Are you proposing adding a tab character at the end of Wordstr boxes?
jtessboxeditor doesnt support the Wordstr option either Please see discussion on following issue


https://github.com/tesseract-ocr/tesseract/issues/670

- excuse the brevity, sent from mobile

On 03-Mar-2017 9:37 PM, "ferjad" <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/Shreeshrii> The problem is I want to
> train on real world data and not synthetic and manually labelling character
> by character isnt possible
> Are you proposing adding a tab character at the end of Wordstr boxes?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/591#issuecomment-283994730>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o-PnPyxGkgqk1ZT1oAD5C8HED1Ybks5riDrOgaJpZM4LQswx>
> .
>
 @Shreeshrii hey thanks for the link, my wordstr strings are space delimited
I am fine tuning the english model so unicharset isnt needed
Did you have any luck training with wordstr format?
It would really help if you could share some working image and box pairs in wordstr format No, I did not try to train with wordstr format except for that test.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Fri, Mar 3, 2017 at 10:08 PM, ferjad <notifications@github.com> wrote:

> @Shreeshrii <https://github.com/Shreeshrii> hey thanks for the link, my
> wordstr strings are space delimited
> I am fine tuning the english model so unicharset isnt needed
> Did you have any luck training with wordstr format?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/591#issuecomment-284003386>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o6xMIbL4uGUBw1AD2zLY-DdnNigjks5riEHxgaJpZM4LQswx>
> .
>
 @Shreeshrii hey any update on ability to train with WordStr format? I tried this again and still got Compute CTC Failed @theraysmith has not updated the programs for handling this yet. Hopefully it will be in next update. @Shreeshrii It would be ideal to update the training wiki to reflect this, thanks for the update  Added a note in training wiki to reflect that WordStr option is not implemented.

Also added as a separate issue. @Shreeshrii hey any update on this? the wiki still says the same  @ferjad, the 'WordStr' format is still not supported. It's unknown when it will be supported.  mkdir -p ~/tesstutorial/sanvedic 
lstmtraining -U ~/tesstutorial/vedic/san.unicharset \
  --script_dir ../langdata --debug_interval 0 \
  --learning_rate 10e-5 \
  --net_spec '[1,0,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx384 O1c5000]' \
  --net_mode 192 \
  --perfect_sample_delay 19 \
  --model_output ~/tesstutorial/sanvedic/base \
  --train_listfile ~/tesstutorial/vedic/san.training_files.txt \
  --eval_listfile ~/tesstutorial/vedic/san.training_files.txt \
  --max_iterations 50000 \
  &>~/tesstutorial/sanvedic/basetrain.log

Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Setting properties for script Devanagari
Unichar 2306=र्त्स्न्ये->र्त्स्न्ये is too long to encode!!
Warning: given outputs 5000 not equal to unicharset of 5018.
Num outputs,weights in serial:
  1,0,0,1:1, 0
Num outputs,weights in serial:
  C5,5:25, 0
  Ft16:16, 416
Total weights = 416
  [C5,5Ft16]:16, 416
  Mp3,3:16, 0
  Lfys64:64, 20736
  Lfx128:128, 98816
  Lrx128:128, 131584
  Lfx384:384, 787968
  Fc5018:5018, 1931930
Total weights = 2971450
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx384Fc5018] from request [1,0,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx384 O1c5000]
Training parameters:
  Debug interval = 0, weights = 0.1, learning rate = 0.0001, momentum=0.9
Loaded 828/828 pages (0-828) of document /home/shree/tesstutorial/vedic/san.AA_NAGARI_SHREE_L1.exp0.lstmf
Loaded 691/691 pages (0-691) of document /home/shree/tesstutorial/saneval/san.Aksharyogini2.exp0.lstmf
Loaded 1023/1023 pages (0-1023) of document /home/shree/tesstutorial/vedic/san.Sanskrit_2003.exp0.lstmf
Loaded 957/957 pages (0-957) of document /home/shree/tesstutorial/vedic/san.e-Nagari_OT.exp0.lstmf
Loaded 1060/1060 pages (0-1060) of document /home/shree/tesstutorial/vedic/san.FreeSans.exp0.lstmf
Loaded 691/691 pages (0-691) of document /home/shree/tesstutorial/saneval/san.Amiko.exp0.lstmf
Loaded 1213/1213 pages (0-1213) of document /home/shree/tesstutorial/vedic/san.Siddhanta-cakravat.exp0.lstmf
Loaded 1191/1191 pages (0-1191) of document /home/shree/tesstutorial/vedic/san.Sahadeva.exp0.lstmf
Loaded 1291/1291 pages (0-1291) of document /home/shree/tesstutorial/vedic/san.Santipur_OT_Medium.exp0.lstmf
Loaded 1115/1115 pages (0-1115) of document /home/shree/tesstutorial/vedic/san.Lohit_Devanagari.exp0.lstmf
Loaded 1210/1210 pages (0-1210) of document /home/shree/tesstutorial/vedic/san.Nakula.exp0.lstmf
Found AVX
Found SSE
Loaded 1188/1188 pages (0-1188) of document /home/shree/tesstutorial/vedic/san.Siddhanta-Calcutta.exp0.lstmf
Loaded 1211/1211 pages (0-1211) of document /home/shree/tesstutorial/vedic/san.Siddhanta.exp0.lstmf
Loaded 1214/1214 pages (0-1214) of document /home/shree/tesstutorial/vedic/san.Siddhanta-Nepali.exp0.lstmf
Loaded 1157/1157 pages (0-1157) of document /home/shree/tesstutorial/vedic/san.Uttara.exp0.lstmf
Image too large to learn!! Size = 2594x48
Image not trainable
Image too large to learn!! Size = 2758x48
Image not trainable
Image too large to learn!! Size = 2621x48
Image not trainable
At iteration 100/100/103, Mean rms=0.95%, delta=57.759%, char train=100.161%, word train=100%, skip ratio=3%,  New worst char error = 100.161 wrote checkpoint The images used were created by text2image with training text with word wrap which ran for full width of page.

Is there a limit to size of images for training? 

Should training text only to be 70-120 characters wide?

 This is the opposite case of image being too small.

```
Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc104] from request [1,0,0,1 Ct5,5,16 Mp3,3 Lfys64 Lfx128 Lrx128 Lfx256 O1c5000]
Training parameters:
  Debug interval = 0, weights = 0.1, learning rate = 0.0001, momentum=0.9
Loaded 151/151 pages (1-151) of document /home/shree/tesstutorial/trado/ara.Traditional_Arabic.exp0.lstmf
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
At iteration 100/100/104, Mean rms=6.004%, delta=48.481%, char train=138.814%, word train=100%, skip ratio=4%,  New worst char error = 138.814 wrote checkpoint.

Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
At iteration 200/200/207, Mean rms=5.654%, delta=40.983%, char train=119.407%, word train=100%, skip ratio=3.5%,  New worst char error = 119.407 wrote checkpoint.

Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!

``` >Is there a limit to size of images for training?

https://github.com/tesseract-ocr/tesseract/blob/ce76d1c569/lstm/lstmrecognizer.cpp#L266

>// Maximum width of image to train on.
const int kMaxImageWidth = 2560; Then shouldn't text2image ensure that images are made to fit that width.

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Mon, Jan 9, 2017 at 3:20 PM, Amit D. <notifications@github.com> wrote:

> Is there a limit to size of images for training?
>
> https://github.com/tesseract-ocr/tesseract/blob/ce76d1c569/
> lstm/lstmrecognizer.cpp#L266
>
> https://github.com/tesseract-ocr/tesseract/blob/ce76d1c569/
> lstm/lstmrecognizer.cpp#L266
>
> // Maximum width of image to train on.
> const int kMaxImageWidth = 2560;
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/590#issuecomment-271244655>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oyLDWu_QZFaYM9Kn1mCaW7ExTo-_ks5rQgLtgaJpZM4LQsPF>
> .
>
 Yes :-) https://github.com/tesseract-ocr/tesseract/blob/831e161066d28a0320d7061c8403f638515b8801/training/text2image.cpp#L82


// Width of output image (in pixels).
INT_PARAM_FLAG(xsize, 3600, "Width of output image");
 The default value for images output by text2image can be reduced during running tesstrain.sh by modifying tesstrain_utils.sh

```
    common_args+=" --leading=${LEADING} --xsize 2550"
``` @theraysmith 

Ray,

// Maximum width of image to train on.
const int kMaxImageWidth = 2560;

I have some  old tif/box pairs . the image width is 4000.

Will training quality be degraded if changing above constant to 4000 in order to use them?

 Also can this be changed during runtime with a  variable or do I need to recompile tesseract with the higher value? @Shreeshrii how can the problem of image being too small be fixed? actually, it's not just a few messages. I am trying to train tesseract to
recognize plate licence, and the prepared training_text is just like a
plate licence. something like this:
۵۴ ۷۲۸ ب ۱۴
each line includes one of these patterns.
I received a lot of these errors and the training process finished with
error rate equal to zero. no training!
would you please help me to figure out what the problem is?


On Wed, Aug 9, 2017 at 8:02 AM, Shreeshrii <notifications@github.com> wrote:

> Reopened #590 <https://github.com/tesseract-ocr/tesseract/issues/590>.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/590#event-1198365561>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiARloL1SxhhVagWDBpNPsl8wmxGH3ks5sWSgzgaJpZM4LQsPF>
> .
>
 >Image too large to learn!! Size = 2758x48
Image not trainable

@hanikh, please paste a short example for the errors you get. I will send the exact error message as soon as possible. but, meanwhile I
have faced a more important problem. I finetuned tesseract for farsi (40
fonts on 6000 text lines) and I got worse result than the original tesserct
on the trained fonts. what is the problem? the training_text is not big
enough? (this is a different project and not related to the licence plate)

On Thu, Aug 10, 2017 at 11:17 PM, theraysmith <notifications@github.com>
wrote:

> The exact error message would greatly help diagnose the problem.
>
> On Tue, Aug 8, 2017 at 10:28 PM, Amit D. <notifications@github.com> wrote:
>
> > Image too large to learn!! Size = 2758x48
> > Image not trainable
> >
> > @hanikh <https://github.com/hanikh>, please paste a short example for
> the
> > errors you get.
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/590#
> issuecomment-321156352>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AL056TBM3518EXdJE7-
> KA44mvwgN2Mx2ks5sWUNhgaJpZM4LQsPF>
> > .
> >
>
>
>
> --
> Ray.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/590#issuecomment-321639717>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAQuqzKOKd8bmnzUcFlsc6bPQth3Oks5sW1AzgaJpZM4LQsPF>
> .
>
 @hanikh 
did you used v4?
i saw this problem on cube for persian.. @theraysmith would you please help me, how many text line is appropriate?
thanks
 Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Compute CTC targets failed!
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
Image too small to scale!! (3x48 vs min width of 3)
Line cannot be recognized!!
Image not trainable
2 Percent improvement time=0, best error was 2.167 @ 14
At iteration 14/1100/20884, Mean rms=0.049%, delta=0%, char train=0%, word train=0%, skip ratio=1798.6%,  New best char error = 0 wrote best model:/home/fanasa/tesstutorial/fastuned_from_fas/fastuned-plates0_14.lstm wrote checkpoint.

Finished! Error rate = 0
this is the error I got during training for licence plates. for the fine tuning problem:
the error-rate reaches 0.017 at about 80000 iterations. so with few
iterations like in tutorial, a low error-rate like 0.01 can not be
achieved. so you think fine tuning is a wrong solution and I should try
replacing some layers? as I said before I am trying to train for 40 Persian
fonts and they are so common.

On Sun, Aug 13, 2017 at 9:38 AM, Shreeshrii <notifications@github.com>
wrote:

> Ray,
>
> I have seen line too small to be recognized when building box/tiff pairs
> using tesstrain.sh - it is usually related to 'nnn diacritics found' - so
> it may be related to accents being treated as a separate line.
>
> Regarding finetuning, I have experimented a lot with Devanagari - with
> smaller number of iterations, the reported error rate is higher. And it
> takes tens of thosands of iterations for it to get more accuracy on
> training set - not sure of its effect on samples it has not seen. - see
> https://github.com/Shreeshrii/tess4training/blob/master/README.md
>
>
>
> ShreeDevi
> ____________________________________________________________
> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>
> On Sun, Aug 13, 2017 at 9:44 AM, theraysmith <notifications@github.com>
> wrote:
>
>
> > Initial problem: (Image too small to scale)
> > Those images are ridiculously small at 3x48 pixels. Something is going
> > wrong somewhere with the images.
> > Are they oriented vertically? The input scaling scales the height to 48,
> > whatever it starts as, so it looks like your textlines are vertical.
> >
> > Fine tuning problem:
> > The problem is most likely too many iterations. It will hone its accuracy
> > to whatever training data you give it if you run it for too many
> > iterations.
> > See how few iterations are used in the training tutorial for fine tuning.
> >
> > On Sat, Aug 12, 2017 at 5:19 AM, hanikh <notifications@github.com>
> wrote:
> >
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Compute CTC targets failed!
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > Image too small to scale!! (3x48 vs min width of 3)
> > > Line cannot be recognized!!
> > > Image not trainable
> > > 2 Percent improvement time=0, best error was 2.167 @ 14
> > > At iteration 14/1100/20884, Mean rms=0.049%, delta=0%, char train=0%,
> > word
> > > train=0%, skip ratio=1798.6%, New best char error = 0 wrote best
> > > model:/home/fanasa/tesstutorial/fastuned_from_
> > fas/fastuned-plates0_14.lstm
> > > wrote checkpoint.
> > >
> > > Finished! Error rate = 0
> > > this is the error I got during training for licence plates.
> > >
> > > —
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tesseract-ocr/tesseract/issues/590#
> > issuecomment-321977639>,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/AL056ZvLnyg_
> > aC1mUg2gH34puAGpWdOOks5sXZhHgaJpZM4LQsPF>
> > > .
> > >
> >
> >
> >
> > --
> > Ray.
> >
> > —
> > You are receiving this because you modified the open/close state.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/590#
> issuecomment-322020794>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AE2_
> o3ztjvMQKBue5JIqMU9Qrfx4ng_Mks5sXng2gaJpZM4LQsPF>
>
> > .
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/590#issuecomment-322022245>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AZFiAZCIts02B7U5JsRtn2DYu86ZBuyhks5sXoTKgaJpZM4LQsPF>
> .
>
 @Shreeshrii would you please explain about the new traineddata file? where
can the lang.lstm-unicharset file be found ? how can combine_lang_model be
used? thanks

On Mon, Aug 14, 2017 at 11:44 AM, Hanieh Khosravi <hani.khosravi@gmail.com>
wrote:

> for the fine tuning problem:
> the error-rate reaches 0.017 at about 80000 iterations. so with few
> iterations like in tutorial, a low error-rate like 0.01 can not be
> achieved. so you think fine tuning is a wrong solution and I should try
> replacing some layers? as I said before I am trying to train for 40 Persian
> fonts and they are so common.
>
> On Sun, Aug 13, 2017 at 9:38 AM, Shreeshrii <notifications@github.com>
> wrote:
>
>> Ray,
>>
>> I have seen line too small to be recognized when building box/tiff pairs
>> using tesstrain.sh - it is usually related to 'nnn diacritics found' - so
>> it may be related to accents being treated as a separate line.
>>
>> Regarding finetuning, I have experimented a lot with Devanagari - with
>> smaller number of iterations, the reported error rate is higher. And it
>> takes tens of thosands of iterations for it to get more accuracy on
>> training set - not sure of its effect on samples it has not seen. - see
>> https://github.com/Shreeshrii/tess4training/blob/master/README.md
>>
>>
>>
>> ShreeDevi
>> ____________________________________________________________
>> भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com
>>
>> On Sun, Aug 13, 2017 at 9:44 AM, theraysmith <notifications@github.com>
>> wrote:
>>
>>
>> > Initial problem: (Image too small to scale)
>> > Those images are ridiculously small at 3x48 pixels. Something is going
>> > wrong somewhere with the images.
>> > Are they oriented vertically? The input scaling scales the height to 48,
>> > whatever it starts as, so it looks like your textlines are vertical.
>> >
>> > Fine tuning problem:
>> > The problem is most likely too many iterations. It will hone its
>> accuracy
>> > to whatever training data you give it if you run it for too many
>> > iterations.
>> > See how few iterations are used in the training tutorial for fine
>> tuning.
>> >
>> > On Sat, Aug 12, 2017 at 5:19 AM, hanikh <notifications@github.com>
>> wrote:
>> >
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Compute CTC targets failed!
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > Image too small to scale!! (3x48 vs min width of 3)
>> > > Line cannot be recognized!!
>> > > Image not trainable
>> > > 2 Percent improvement time=0, best error was 2.167 @ 14
>> > > At iteration 14/1100/20884, Mean rms=0.049%, delta=0%, char train=0%,
>> > word
>> > > train=0%, skip ratio=1798.6%, New best char error = 0 wrote best
>> > > model:/home/fanasa/tesstutorial/fastuned_from_
>> > fas/fastuned-plates0_14.lstm
>> > > wrote checkpoint.
>> > >
>> > > Finished! Error rate = 0
>> > > this is the error I got during training for licence plates.
>> > >
>> > > —
>> > > You are receiving this because you were mentioned.
>> > > Reply to this email directly, view it on GitHub
>> > > <https://github.com/tesseract-ocr/tesseract/issues/590#
>> > issuecomment-321977639>,
>> > > or mute the thread
>> > > <https://github.com/notifications/unsubscribe-auth/AL056ZvLnyg_
>> > aC1mUg2gH34puAGpWdOOks5sXZhHgaJpZM4LQsPF>
>> > > .
>> > >
>> >
>> >
>> >
>> > --
>> > Ray.
>> >
>> > —
>> > You are receiving this because you modified the open/close state.
>> > Reply to this email directly, view it on GitHub
>> > <https://github.com/tesseract-ocr/tesseract/issues/590#issue
>> comment-322020794>,
>> > or mute the thread
>> > <https://github.com/notifications/unsubscribe-auth/AE2_o3ztj
>> vMQKBue5JIqMU9Qrfx4ng_Mks5sXng2gaJpZM4LQsPF>
>>
>> > .
>> >
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/590#issuecomment-322022245>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AZFiAZCIts02B7U5JsRtn2DYu86ZBuyhks5sXoTKgaJpZM4LQsPF>
>> .
>>
>
>
 @Shreeshrii I want to train 40 fonts for Arabic and Farsi languages. I have tried to finetune the trained model, but I did not get a good result. I think that happened because the trained fonts were so different from mine. So now I am going to replace a layer. I want to replace just the last layer and I do not want to change the unicharset. So, can I use Arabic.traineddata as the traineddata file needed for training? these are the commands I am using:
mkdir -p ~/tesstutorial/newara_from_ara
training/combine_tessdata -e tessdata/best/Arabic.traineddata \
  ~/tesstutorial/newara_from_ara/ara.lstm

training/lstmtraining --debug_interval 100 \
  --continue_from ~/tesstutorial/newara_from_ara/ara.lstm \
  --traineddata ~/tesstutorial/aratrain/ara/Arabic.traineddata \
  --append_index 5 \
  --model_output ~/tesstutorial/newara_from_ara/base \
  --train_listfile ~/tesstutorial/aratrain/ara.training_files.txt \
  --eval_listfile ~/tesstutorial/araeval/ara.training_files.txt \
  --max_iterations 3000 &>~/tesstutorial/newara_from_ara/basetrain.log @theraysmith 
if is it helpful
i can provide a large amount of font and word list of persian and arabic language for the train material @Shreeshrii  would you please help me with using "replacing layers" as I asked before?
 @roozgar have you tested the new traineddata for arabic? have you tried to train it?   I followed the [steps](https://github.com/tesseract-ocr/tesseract/wiki/Compiling#windows) required to get to .sln file for Visual Studio but I get a bunch of errors.

Here is a [screenshot](http://i.imgur.com/puq3uAR.png). I will check these commands on Monday.

It is the latest version of cppan.

Also the hanging on 7 process still goes on. Yes, managed that problem. Now I will check the clean packages argument later on. 
Stay tuned. After 
`cppan --clean-packages .*jpeg.*`
and 
`cppan --self-upgrade`

I get this 

![clipboard01](https://cloud.githubusercontent.com/assets/5253959/21307804/ca31d14a-c5df-11e6-8a56-7ddfbffbfafa.png)
 I tried with no success.

Still getting the same errors for `tiff`. Look now what I got
![clipboard01](https://cloud.githubusercontent.com/assets/5253959/21316793/096242ac-c60b-11e6-9392-0a77ed2d8ef8.png)
 So I have to install older version of VS ![image](https://cloud.githubusercontent.com/assets/5253959/21345168/b819da0c-c6a7-11e6-8212-6dd38a79531a.png)
 The mistake is mine. 
In the last step I always used:
`cmake .. -DSTATIC=1` instead of `cmake ..`
and now compiles perfectly
 @egorpugin Please see https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-dev/Vx3Z-MReD3c/BMRy_IkSCAAJ

discussion regarding compiling 3.05 branch with vs 2010.

Does 3.05 branch need Leptonica 1.74 and not 1.74.1 ?  Don't remove the 'port' dir.  (can you tell me, how I can directly cherry-pick or merge your pr into my local repo?)

I need to learn this now... (I am just trying something from https://www.startpage.com/do/search?q=github+how+can+I+cherry-pick+a+pull+request ) (I just wanted to confirm, that it solves the problem! ty all)  In leptonica:
- 95% of these are because I use floats, and floating point numbers (like 1.0) are assumed to be doubles.
- Most of the rest are implicit conversions from float to int, where the ints are indices into a 2d image array. Any program may do a few tens of these, so we're talking about a small fraction of a microsecond.

Eliminating these windows compiler warnings is not high on my todo list.  I'll try to remember to add "f" to numbers in files that I'm modifying for other reasons.  * version 6c46cd79546e927bacfcb86ad868005f63f908ff

make does not work:
(version dc12404 worked)

```
libtool: link: ( cd ".libs" && rm -f "libtesseract.la" && ln -s "../libtesseract.la" "libtesseract.la" )
g++ -DHAVE_CONFIG_H -I. -I..  -g -Wall -O0 -DDEBUG -DLOCALEDIR=\"/usr/local/share/locale\" -DUSE_STD_NAMESPACE -I../arch -I../lstm -I../ccutil -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../ccmain -I../wordrec -I../cutil -I../opencl    -I/usr/local/include/leptonica   -g -O2 -std=c++11 -MT tesseract-tesseractmain.o -MD -MP -MF .deps/tesseract-tesseractmain.Tpo -c -o tesseract-tesseractmain.o `test -f 'tesseractmain.cpp' || echo './'`tesseractmain.cpp
mv -f .deps/tesseract-tesseractmain.Tpo .deps/tesseract-tesseractmain.Po
/bin/bash ../libtool  --tag=CXX   --mode=link g++  -g -O2 -std=c++11   -o tesseract tesseract-tesseractmain.o libtesseract.la -fopenmp -ltiff  -lrt -lpthread 
libtool: link: g++ -g -O2 -std=c++11 -o .libs/tesseract tesseract-tesseractmain.o -fopenmp  ./.libs/libtesseract.so /usr/lib/x86_64-linux-gnu/libtiff.so -lrt -lpthread -fopenmp
tesseract-tesseractmain.o: In function `PrintVersionInfo()':
/usr/local/src/tesseract/api/tesseractmain.cpp:57: undefined reference to `getLeptonicaVersion'
/usr/local/src/tesseract/api/tesseractmain.cpp:59: undefined reference to `lept_free'
/usr/local/src/tesseract/api/tesseractmain.cpp:61: undefined reference to `getImagelibVersions'
/usr/local/src/tesseract/api/tesseractmain.cpp:63: undefined reference to `lept_free'
tesseract-tesseractmain.o: In function `main':
/usr/local/src/tesseract/api/tesseractmain.cpp:443: undefined reference to `pixRead'
/usr/local/src/tesseract/api/tesseractmain.cpp:469: undefined reference to `pixDestroy'
./.libs/libtesseract.so: undefined reference to `boxaCreate'
./.libs/libtesseract.so: undefined reference to `l_generateCIDataForPdf'
./.libs/libtesseract.so: undefined reference to `pixWriteMem'
./.libs/libtesseract.so: undefined reference to `boxaGetBox'
./.libs/libtesseract.so: 

....

Makefile:594: recipe for target 'tesseract' failed
make[2]: *** [tesseract] Error 1
make[2]: Leaving directory '/work/usr/local/src/tesseract/api'
Makefile:481: recipe for target 'all-recursive' failed
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory '/work/usr/local/src/tesseract'
Makefile:389: recipe for target 'all' failed
make: *** [all] Error 2
``` I am currently trying to bisect the problem, dc12404 compiles, 23a7330 fails. * b75beda7f9ed4b6ea715060f02293869d2f1de6a works
* a0201831c33f14ece2a7b96eb3ea1f9019d90680 works
* 23a7330c85cf9066df4e65dd17c940218d0b54ef fails @stweil your commit d77a9b7375f969be641afc79028fc7020514ddfb is causing the reported issue. @stweil just as info: I run debian 8 @stweil and did I say "thank you" for your engagement into the project, and your swift reply? (sorry for not having closed this!)  Currently when using debug version, tesseract reports the gitver version. However, even when using the master branch, it reports it as 3.05dev.

Please add a tag on master for 4.0.0alpha so that config.ac gets the correct tag for gitrev. It would also be helpful to remove the ifdef limiting the display of GITREV to the debug build, so that it is displayed in all builds from GitHub source.  It doesn't work when I run lstmtraining usage command like [guider](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#training-from-scratch),and show "scrollview:waiting for server..." in basetrain.log.
First I think the training-tools are not compiled successfully,I reinstall it,but it still error.Then I think change the param "debug_interval" to 0,and it worked.
So am I wrong or it is a bug?
Thanks,sorry for my bad English. @stweil Hi,
I did "make ScrollView.jar" ans add its path to the environment variable  `SCROLLVIEW_PATH` but the program still can't find it. I found in viewer/svutil.cpp `GetEnv(SCROLLVIEW_PATH)` doesn't work, so I changed the path in program. But after started ScrollView, it stopped with error:
`
#A fatal error has been detected by the Java Runtime Environment:
#SIGSEGV (0xb) at pc=0x00007ffff5174009, pid=21858, tid=21859
#JRE version: OpenJDK Runtime Environment (9.0) (build 9-internal+0-2016-04-14-195246.buildd.src)
#Java VM: OpenJDK 64-Bit Server VM (9-internal+0-2016-04-14-195246.buildd.src, mixed mode, tiered, compressed oops, g1 gc, linux-amd64)
#Problematic frame:
#C  [libjava.so+0x1d009]  JNU_GetEnv+0x19

#Core dump will be written. Default location: Core dumps may be processed with "/usr/share/apport/apport %p %s %c %P" (or dumping to /usr/workspace/tesseract/core.21858)

#An error report file with more information is saved as:
#/usr/workspace/tesseract/hs_err_pid21858.log

#If you would like to submit a bug report, please visit:
#http://bugreport.java.com/bugreport/crash.jsp
#The crash happened outside the Java Virtual Machine in native code.
#See problematic frame for where to report the bug.
#sh: 1: kill: No such process
`
Do you have any idea how to solve this? Thanks.  I am running tesseract on this image [http://imgur.com/a/yIX5N](url) and i get a segmentation fault. I am wondering how i can go about to troubleshoot the problem or, in case one of the developers would know if this is a known bug. I am running on Windows and this is the version of tesseract under use:

> c:\> tesseract.exe --version
tesseract 3.05.00dev
 leptonica-1.73
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.6.20 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.4.3 : libopenjp2 2.1.0  # Problem 
For iOS there are [many forks](https://github.com/gali8/Tesseract-OCR-iOS/network), where it's difficult to figure out what version of Tesseract that it's derived from. 

# Solution
Add a define in the `capi.h` file, like this:

    #define TESSERACT_ID "3.06.01dev, 13e46ae1c4d8acccf15654b0e6ddbddbd363618a"

This will make it easier to determine what version of Tesseract that it is.


I use Tesseract on iPhone and iPad.

I have read the contributing guide.

Thank you for this awesome ocr library. Hi Simon,

There is something like what you asked for, but currently it is only available in the debug build.

https://github.com/tesseract-ocr/tesseract/blob/dc124043ec/configure.ac#L24
https://github.com/tesseract-ocr/tesseract/blob/dc124043ec/api/baseapi.cpp#L139
https://github.com/tesseract-ocr/tesseract/blob/dc124043ec/api/capi.h#L112
 [Tesseract for iOS](https://github.com/gali8/Tesseract-OCR-iOS) comes with `.a` files, there are no `.cpp` files. Just by looking at the code there is no way to tell what version of Tesseract that is being used. One has to actual execute the code to figure out the version.

It would be more helpful if the version string was in a `.h` file. Sorry, I overlooked that it's already here.

In the [baseapi.h](https://github.com/tesseract-ocr/tesseract/blob/master/api/baseapi.h#L23), there is this line. Exactly something like this that I was looking for.

    #define TESSERACT_VERSION_STR "4.00.00alpha"

Thank you for your kind assistance.  I wanted to update my working tesseract (version from August) by pulling and compiling the latest version but `make install` ends with some errors:
```
$ sudo make install
...
Makefile:333: recipe for target 'install-dataDATA' failed
make[3]: *** [install-dataDATA] Error 1
make[3]: Leaving directory '/work/usr/local/src/tesseract/tessdata/configs'
Makefile:403: recipe for target 'install-am' failed
make[2]: *** [install-am] Error 2
make[2]: Leaving directory '/work/usr/local/src/tesseract/tessdata/configs'
Makefile:461: recipe for target 'install-recursive' failed
make[1]: *** [install-recursive] Error 1
make[1]: Leaving directory '/work/usr/local/src/tesseract/tessdata'
Makefile:483: recipe for target 'install-recursive' failed
make: *** [install-recursive] Error 1

$ tesseract --version

tesseract: error while loading shared libraries: libtesseract.so.4: cannot open shared object file: No such file or directory
```

Full output see http://dpaste.com/1AMP4MA.txt

Please can you help? I think it was due to a version conflict on my debian 8 with a packaged-tesseract. After removal of the packaged tesseract, tesseract as such  appears to work (but `make install` errors remain). this is my standard procedure:

```
make clean
git pull
./autogen.sh
./configure --enable-debug
make
sudo make install
```
 Yeah, you are right. I _had_ indeed such a link when I build the last version !
I will now re-compile and report here, and close, if it solved.

Nevertheless, perhaps the "make" could be improved to catch (capture?) such a user mistake. I reported that issue, and close it now. Issue solved by removing my softlink for tessdata. root@scube014:~/qingy-fork-master/src/libraries# make clean
Making clean in libraries
/bin/bash: line 20: cd: libraries: No such file or directory
make: *** [clean-recursive] Error 1
pls find this problem .   What about using pkg-config for detecting Leptonica version? Leptonica provides pkg-config pc file since 1.70. Any volunteer? :laughing:   I have install the icu_54 for it, but have meet some errors when make training tools. 
and  who know which  verision for tesseract4.0 ? @stweil, my system is centos6.5,  Please Google search for icu-dev or icu-devel libs for CentOS. >which version of icu for tesseract 4.0 ?
 
probably version >=4.4

As said by Shree, you need to install the package icu-devel. http://rpmfind.net/linux/rpm2html/search.php?query=libicu-devel it's not icu version problem for me , I just forget to rebuild the static library.  so if you also meet some error , it may other reason caused!  Hi,

building training tools in current master branch under MSYS2/mingw64 throws following Error:
...x86_64-w64-mingw32/bin/ld.exe: cannot find -licui18n

It seems the lib is named differently.

My quick Solution is to change libicu in training/Makefile like so:
sed -i 's/^libicu = -licui18n -licuuc/libicu = -licuin -licuuc/' training/Makefile

Then it's building fine.

Thanks for your awesome Work.
 @stweil 
where can i see the version of mingw-w64?

Ouput from mingw64 console:
$ uname -rv
2.6.0(0.304/5/3) 2016-09-07 20:45

Output from pacman:
$ pacman -Qs icu
local/icu 56.1-1 (libraries)
    International Components for Unicode library
local/icu-devel 56.1-1 (development)
    ICU headers and libraries
local/mingw-w64-x86_64-icu 57.1-1
    International Components for Unicode library (mingw-w64)

This files: libicudata.dll.a libicui18n.dll.a libicuio.dll.a libicule.dll.a libiculx.dll.a libicutest.dll.a libicutu.dll.a libicuuc.dll.a seems to be present in '/usr/lib'

My host is Windows 7 x64, msys2 installed a few days ago, must be pretty up to date. I'm using MSYS2 Installer from https://msys2.github.io/
Have no Problems to compile other Linux Packages... ok, good night. Thanks for your effort! Thumbs up! :-)

It compiles fine now.
Even with the PKGBUILD from Tesseract Wiki:
https://github.com/tesseract-ocr/tesseract/wiki/Compiling#msys2

Thanks for fixing.  ```
$ lstmtraining -U ~/tesstutorial/sanlayer/san.unicharset   --script_dir ../langdata  --debug_interval
0   --continue_from ~/tesstutorial/san_from_layer/san.lstm   --append_index 5 --
net_spec '[Lfx256 O1c105]'   --model_output ~/tesstutorial/san_from_layer/base
 --train_listfile ~/tesstutorial/sanlayer/san.training_files.txt   --eval_listfi
le ~/tesstutorial/saneval/san.training_files.txt   --max_iterations 5000
Loaded file /home/shree/tesstutorial/san_from_layer/base_checkpoint, unpacking..
.
Successfully restored trainer from /home/shree/tesstutorial/san_from_layer/base_checkpoint
Loaded 2094/2094 pages (0-2094) of document /home/shree/tesstutorial/sanlayer/san.Chandas.exp0.lstmf
Loaded 691/691 pages (0-691) of document /home/shree/tesstutorial/saneval/san.Aksharyogini2.exp0.lstmf
Loaded 2104/2104 pages (0-2104) of document /home/shree/tesstutorial/sanlayer/san.Gargi.exp0.lstmf
Loaded 2103/2103 pages (0-2103) of document /home/shree/tesstutorial/sanlayer/san.Sahadeva.exp0.lstmf
Loaded 691/691 pages (0-691) of document /home/shree/tesstutorial/saneval/san.Amiko.exp0.lstmf
Loaded 2101/2101 pages (0-2101) of document /home/shree/tesstutorial/sanlayer/san.Nakula.exp0.lstmf
Loaded 2103/2103 pages (0-2103) of document /home/shree/tesstutorial/sanlayer/san.Lohit_Devanagari.exp0.lstmf
Loaded 2102/2102 pages (0-2102) of document /home/shree/tesstutorial/sanlayer/san.Sarai.exp0.lstmf
Loaded 2102/2102 pages (0-2102) of document /home/shree/tesstutorial/sanlayer/san.Samanata.exp0.lstmf
Loaded 2096/2096 pages (0-2096) of document /home/shree/tesstutorial/sanlayer/san.Santipur_OT_Medium.exp0.lstmf
Loaded 2102/2102 pages (0-2102) of document /home/shree/tesstutorial/sanlayer/san.Kalimati.exp0.lstmf
Loaded 2068/2103 pages (35-2103) of document /home/shree/tesstutorial/sanlayer/san.Siddhanta-Calcutta.exp0.lstmf
Loaded 2062/2097 pages (35-2097) of document /home/shree/tesstutorial/sanlayer/san.Uttara.exp0.lstmf
Loaded 2064/2099 pages (35-2099) of document /home/shree/tesstutorial/sanlayer/san.Siddhanta.exp0.lstmf
Found AVX
Found SSE
Loaded 2065/2100 pages (35-2100) of document /home/shree/tesstutorial/sanlayer/san.Siddhanta-Nepali.exp0.lstmf
Loaded 2064/2100 pages (36-2100) of document /home/shree/tesstutorial/sanlayer/san.Siddhanta-cakravat.exp0.lstmf

At iteration 600/600/600, Mean rms=0.899%, delta=49.539%, char train=102.678%, word train=100%, skip ratio=0%,  New worst char error = 102.678 wrote checkpoint.

At iteration 700/700/700, Mean rms=0.895%, delta=49.137%, char train=102.295%, word train=100%, skip ratio=0%,  New worst char error = 102.295 wrote checkpoint.

At iteration 800/800/800, Mean rms=0.893%, delta=48.75%, char train=102.008%, word train=100%, skip ratio=0%,  New worst char error = 102.008 wrote checkpoint.

At iteration 900/900/900, Mean rms=0.89%, delta=48.199%, char train=101.785%, word train=100%, skip ratio=0%,  New worst char error = 101.785 wrote checkpoint.

lstmtraining: ../ccutil/genericvector.h:696: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.
Aborted (core dumped)

``` gdb --args \
 lstmtraining -U ~/tesstutorial/vedic/san.unicharset \
  --script_dir ../langdata  --debug_interval 0 \
  --continue_from ~/tesstutorial/san_vedic/san.lstm \
  --append_index 5 --net_spec '[Lfx384 O1c6000]' \
  --model_output ~/tesstutorial/san_vedic/base \
  --train_listfile ~/tesstutorial/nonvedic/san.training_files.txt \
  --eval_listfile ~/tesstutorial/nonvedic/san.training_files.txt \
  --max_iterations 50000 
 
```
At iteration 900/900/900, Mean rms=0.841%, delta=46.594%, char train=101.075%, word train=100%, skip ratio=0%,  New worst char error = 101.075 wrote checkpoint.
[Thread 0x7f47352d0700 (LWP 422) exited]
[New Thread 0x7f47352d0700 (LWP 423)]
lstmtraining: ../ccutil/genericvector.h:696: T& GenericVector<T>::operator[](int) const [with T = char]: Assertion `index >= 0 && index < size_used_' failed.

Program received signal SIGABRT, Aborted.
[Switching to Thread 0x7f47352d0700 (LWP 423)]
0x00007f473f626c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
56      ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.
(gdb) backtrace
#0  0x00007f473f626c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
#1  0x00007f473f62a028 in __GI_abort () at abort.c:89
#2  0x00007f473f61fbf6 in __assert_fail_base (fmt=0x7f473f7703b8 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n",
    assertion=assertion@entry=0x7f47404f9590 "index >= 0 && index < size_used_", file=file@entry=0x7f47404f8fc8 "../ccutil/genericvector.h", line=line@entry=696,
    function=function@entry=0x7f474051cf20 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]")
    at assert.c:92
#3  0x00007f473f61fca2 in __GI___assert_fail (assertion=0x7f47404f9590 "index >= 0 && index < size_used_", file=0x7f47404f8fc8 "../ccutil/genericvector.h", line=696,
    function=0x7f474051cf20 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:101
#4  0x00007f4740457553 in GenericVector<char>::operator[] (this=<optimized out>, this=<optimized out>, index=0) at ../ccutil/genericvector.h:696
#5  0x00007f4740457d28 in operator[] (this=0x7fffca010860, this=0x7fffca010860, index=0) at lstmtrainer.cpp:919
#6  tesseract::LSTMTrainer::ReadTrainingDump (this=this@entry=0x7f47352cf570, data=..., trainer=trainer@entry=0x7f47352cf570) at lstmtrainer.cpp:920
#7  0x000000000040b4fe in tesseract::LSTMTester::RunEvalSync (this=this@entry=0x7fffca0107f0, iteration=0, training_errors=<optimized out>, model_data=...,
    training_stage=0) at lstmtester.cpp:87
#8  0x000000000040ba39 in tesseract::LSTMTester::ThreadFunc (lstmtester_void=0x7fffca0107f0) at lstmtester.cpp:124
#9  0x00007f473d4f8184 in start_thread (arg=0x7f47352d0700) at pthread_create.c:312
#10 0x00007f473f6ea37d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111

(gdb) frame 2
#2  0x00007f473f61fbf6 in __assert_fail_base (fmt=0x7f473f7703b8 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n",
    assertion=assertion@entry=0x7f47404f9590 "index >= 0 && index < size_used_", file=file@entry=0x7f47404f8fc8 "../ccutil/genericvector.h", line=line@entry=696,
    function=function@entry=0x7f474051cf20 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]")
    at assert.c:92
92      in assert.c
(gdb) frame 3
#3  0x00007f473f61fca2 in __GI___assert_fail (assertion=0x7f47404f9590 "index >= 0 && index < size_used_", file=0x7f47404f8fc8 "../ccutil/genericvector.h", line=696,
    function=0x7f474051cf20 <_ZZNK13GenericVectorIcEixEiE19__PRETTY_FUNCTION__> "T& GenericVector<T>::operator[](int) const [with T = char]") at assert.c:101
101     in assert.c
(gdb) frame 4
#4  0x00007f4740457553 in GenericVector<char>::operator[] (this=<optimized out>, this=<optimized out>, index=0) at ../ccutil/genericvector.h:696
696       assert(index >= 0 && index < size_used_);
(gdb) frame 5
#5  0x00007f4740457d28 in operator[] (this=0x7fffca010860, this=0x7fffca010860, index=0) at lstmtrainer.cpp:919
919                                        LSTMTrainer* trainer) {
(gdb) frame 6
#6  tesseract::LSTMTrainer::ReadTrainingDump (this=this@entry=0x7f47352cf570, data=..., trainer=trainer@entry=0x7f47352cf570) at lstmtrainer.cpp:920
920       return trainer->ReadSizedTrainingDump(&data[0], data.size());
(gdb) frame 7
#7  0x000000000040b4fe in tesseract::LSTMTester::RunEvalSync (this=this@entry=0x7fffca0107f0, iteration=0, training_errors=<optimized out>, model_data=...,
    training_stage=0) at lstmtester.cpp:87
87        if (!trainer.ReadTrainingDump(model_data, &trainer)) {
(gdb) frame 8
#8  0x000000000040ba39 in tesseract::LSTMTester::ThreadFunc (lstmtester_void=0x7fffca0107f0) at lstmtester.cpp:124
124       lstmtester->test_result_ = lstmtester->RunEvalSync(
(gdb) frame 9
#9  0x00007f473d4f8184 in start_thread (arg=0x7f47352d0700) at pthread_create.c:312
312     pthread_create.c: No such file or directory.
(gdb) frame 10
#10 0x00007f473f6ea37d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111
111     ../sysdeps/unix/sysv/linux/x86_64/clone.S: No such file or directory. 
  
```
  ```
$ combine_tessdata -e tessdata/san.traineddata \
>   ~/tesstutorial/san_from_layer/san.lstm
Extracting tessdata components from tessdata/san.traineddata
Wrote /home/shree/tesstutorial/san_from_layer/san.lstm

$ lstmtraining -U ~/tesstutorial/santrain/san.unicharset \
>   --script_dir ../langdata  --debug_interval 0 \
>   --continue_from ~/tesstutorial/san_from_layer/san.lstm \
>   --append_index 5 --net_spec '[Lfx256 O1c105]' \
>   --model_output ~/tesstutorial/san_from_layer/base \
>   --train_listfile ~/tesstutorial/santrain/san.training_files.txt \
>   --eval_listfile ~/tesstutorial/san_layer/san.training_files.txt \
>   --max_iterations 5000

Loaded file /home/shree/tesstutorial/san_from_layer/san.lstm, unpacking...
Warning: LSTMTrainer deserialized an LSTMRecognizer!

Continuing from /home/shree/tesstutorial/san_from_layer/san.lstm
Mirror « of » is not in unicharset
Appending a new network to an old one!!Setting unichar properties
Setting properties for script Common
Setting properties for script Latin

Unichar 1481=र्ब्रह्मघा->र्ब्रह्मघा is too long to encode!!

Warning: given outputs 105 not equal to unicharset of 1938.

Num outputs,weights in serial:
  Lfx256:256, 394240
  Fc1938:1938, 498066
Total weights = 892306

Built network:[1,0,0,1[C5,5Ft16]Mp3,3Lfys64Lfx128Lrx128Lfx256Fc1938] from request [Lfx256 O1c105]

Training parameters:
  Debug interval = 0, weights = 0.1, learning rate = 0.0001, momentum=0.9
Loaded 1837/1837 pages (0-1837) of document /home/shree/tesstutorial/santrain/san.Aksharyogini2.exp0.lstmf
Deserialize header failed: -rw-rw-rw- 1 shree shree  9356879 Dec 10 15:11 san.Chandas.exp0.lstmf
Loaded 1741/1741 pages (0-1741) of document /home/shree/tesstutorial/santrain/san.Amiko.exp0.lstmf
Loaded 1763/1763 pages (0-1763) of document /home/shree/tesstutorial/santrain/san.Baloo.exp0.lstmf
Loaded 1820/1820 pages (0-1820) of document /home/shree/tesstutorial/santrain/san.Aparajita.exp0.lstmf
Loaded 1820/1820 pages (0-1820) of document /home/shree/tesstutorial/santrain/san.Biryani.exp0.lstmf
Loaded 1822/1822 pages (0-1822) of document /home/shree/tesstutorial/santrain/san.Arya.exp0.lstmf
Loaded 1824/1824 pages (0-1824) of document /home/shree/tesstutorial/santrain/san.Asar.exp0.lstmf
Loaded 1837/1837 pages (0-1837) of document /home/shree/tesstutorial/santrain/san.Amita.exp0.lstmf
Loaded 1816/1816 pages (0-1816) of document /home/shree/tesstutorial/santrain/san.Annapurna_SIL.exp0.lstmf

First document cannot be empty!!
num_pages_per_doc_ > 0:Error:Assert failed:in file imagedata.cpp, line 656
Segmentation fault (core dumped)

```
Here is the info re lstmf files in /home/shree/tesstutorial/santrain/

```
$ ll /home/shree/tesstutorial/santrain/*.lstmf
-rw-rw-rw- 1 shree shree 3601682 Dec  9 21:16 /home/shree/tesstutorial/santrain/san.Aksharyogini2.exp0.lstmf
-rw-rw-rw- 1 shree shree 3834940 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Amiko.exp0.lstmf
-rw-rw-rw- 1 shree shree 5002657 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Amita.exp0.lstmf
-rw-rw-rw- 1 shree shree 3971772 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Annapurna_SIL.exp0.lstmf
-rw-rw-rw- 1 shree shree 3613720 Dec  9 21:16 /home/shree/tesstutorial/santrain/san.Aparajita.exp0.lstmf
-rw-rw-rw- 1 shree shree 4275301 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Arya.exp0.lstmf
-rw-rw-rw- 1 shree shree 4149621 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Asar.exp0.lstmf
-rw-rw-rw- 1 shree shree 3701423 Dec  9 21:17 /home/shree/tesstutorial/santrain/san.Baloo.exp0.lstmf
-rw-rw-rw- 1 shree shree 3696594 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Biryani.exp0.lstmf
-rw-rw-rw- 1 shree shree 3689358 Dec  8 16:26 /home/shree/tesstutorial/santrain/san.Chandas.exp0.lstmf
-rw-rw-rw- 1 shree shree 4567407 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Dekko.exp0.lstmf
-rw-rw-rw- 1 shree shree 3706688 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Ek_Mukta.exp0.lstmf
-rw-rw-rw- 1 shree shree 3697439 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Gargi.exp0.lstmf
-rw-rw-rw- 1 shree shree 4103892 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Glegoo.exp0.lstmf
-rw-rw-rw- 1 shree shree 3585398 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Hind_Medium.exp0.lstmf
-rw-rw-rw- 1 shree shree 3986588 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Kadwa.exp0.lstmf
-rw-rw-rw- 1 shree shree 4196205 Dec  9 21:24 /home/shree/tesstutorial/santrain/san.Kalam.exp0.lstmf
-rw-rw-rw- 1 shree shree 4030697 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Kalimati.exp0.lstmf
-rw-rw-rw- 1 shree shree 3013510 Dec  9 21:29 /home/shree/tesstutorial/santrain/san.Kokila.exp0.lstmf
-rw-rw-rw- 1 shree shree 3985691 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Kurale.exp0.lstmf
-rw-rw-rw- 1 shree shree 3951000 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Laila_Medium.exp0.lstmf
-rw-rw-rw- 1 shree shree 3935943 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Lohit_Devanagari.exp0.lstmf
-rw-rw-rw- 1 shree shree 4053036 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Mangal.exp0.lstmf
-rw-rw-rw- 1 shree shree 3769371 Dec  8 16:25 /home/shree/tesstutorial/santrain/san.Nakula.exp0.lstmf
-rw-rw-rw- 1 shree shree 3988872 Dec  8 16:26 /home/shree/tesstutorial/santrain/san.Sahadeva.exp0.lstmf
-rw-rw-rw- 1 shree shree 3700015 Dec  8 16:26 /home/shree/tesstutorial/santrain/san.Sanskrit_2003.exp0.lstmf
-rw-rw-rw- 1 shree shree 3743783 Dec  8 16:28 /home/shree/tesstutorial/santrain/san.Santipur_OT_Medium.exp0.lstmf
-rw-rw-rw- 1 shree shree 4214334 Dec  9 21:30 /home/shree/tesstutorial/santrain/san.Tillana_Medium.exp0.lstmf
-rw-rw-rw- 1 shree shree 3099048 Dec  9 21:29 /home/shree/tesstutorial/santrain/san.Utsaah.exp0.lstmf
-rw-rw-rw- 1 shree shree 3716830 Dec  8 16:28 /home/shree/tesstutorial/santrain/san.Uttara.exp0.lstmf
-rw-rw-rw- 1 shree shree 4141319 Dec  9 21:32 /home/shree/tesstutorial/santrain/san.Yatra_One.exp0.lstmf

``` Was it solved? Hello, is this problem resolved?  I am fairly sure that pixGenHalftoneMask() (and the wrapper pixGenerateHalftoneMask()) are the only leptonica functions in tesseract that have a debug argument.

It should be OK in the new tesseract (4.00) to use pixGenerateHalftoneMask() with NULL for the debug pixa.  It would also be nice at the same time for the debug calls to the deprecated functions pixDisplayWrite() and pixDisplayWriteFormat() to be removed, because there is no reason that tesseract needs to generate these debug images. I believe that Ray is removing all use of temp files due to pixDisplayWrite() in tesseract.  ```
Page 2
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Loaded 41/41 pages (0-41) of document /tmp/tmp.tY7p2Ue5TC/san/san.Baloo.exp0.lstmf
Bad box coordinates in boxfile string! विताः । नानाशस्त्रप्रहरणाः सर्वे 1576 3968 2121 4022 0
Bad box coordinates in boxfile string! रिदेवना ॥ २-२८॥ आश्चर्य 1526 2958 1995 3016 1
Bad box coordinates in boxfile string! ति ॥ २-६४॥ प्रसादे सर्व 1341 4637 1759 4693 2
Bad box coordinates in boxfile string! ति पूरुषः ॥ ३-१९॥ कर्म 1063 2386 1484 2451 2
Bad box coordinates in boxfile string! विभागयोः । गुणा गुणेषु वर्त 420 1710 909 1776 2
Bad box coordinates in boxfile string! न्थिनौ ॥ ३-३४॥ श्रेयान्स्वधर्मो 1447 1278 1982 1335 2
Bad box coordinates in boxfile string! विनाशाय च दुष्कृताम् । धर्म 1364 4402 1863 4475 3
Bad box coordinates in boxfile string! द्धिमान्मनुष्येषु स युक्तः कृत्स्नकर्म 1206 3622 1812 3694 3

``` This was on box files created by text2image. https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#error-messages-from-training

Try running text2inage with this option: `--output_word_boxes` >Try running text2inage with this option: --output_word_boxes

That creates a unicharset with words

and I get additional errors about Utf8 buffer too big, ```
Detected 15 diacritics
Loaded 2742/2742 pages (1-2742) of document /tmp/tmp.aA4DsVmpNZ/hin/hin.CDAC-GISTSurekh.exp0.lstmf
Page 77
Page 97
Bad box coordinates in boxfile string! दि ['ए\\^', 25 सर्व 778 1653 1230 1732 92
Page 82
Loaded 3159/3159 pages (1-3159) of document /tmp/tmp.aA4DsVmpNZ/hin/hin.FreeSans.exp0.lstmf
Page 80
```

Still getting the errors. The box file is generated by text2image. See https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00

```
Bad box coordinates in boxfile string! 

The LSTM trainer only needs bounding box information for a complete textline,
instead of at a character level, but if you put spaces in the box string, like this:

<text for line including spaces> <left> <bottom> <right> <top> <page>
the parser will be confused and give you the error message.
```

text2image program may need to be fixed if too many errors of this kind are reported.   ```
Bad box coordinates in boxfile string! विताः । नानाशस्त्रप्रहरणाः सर्वे 1576 3968 2121 4022 0

Box file format error on line 512; ignored
Bad box coordinates in boxfile string! रिदेवना ॥ २-२८॥ आश्चर्य 1526 2958 1995 3016 1

Box file format error on line 4234; ignored
Bad box coordinates in boxfile string! ति ॥ २-६४॥ प्रसादे सर्व 1341 4637 1759 4693 2

Box file format error on line 6128; ignored
Bad box coordinates in boxfile string! ति पूरुषः ॥ ३-१९॥ कर्म 1063 2386 1484 2451 2

Box file format error on line 7619; ignored
Bad box coordinates in boxfile string! विभागयोः । गुणा गुणेषु वर्त 420 1710 909 1776 2

Box file format error on line 8043; ignored
Bad box coordinates in boxfile string! न्थिनौ ॥ ३-३४॥ श्रेयान्स्वधर्मो 1447 1278 1982 1335 2

```  ```
=== Phase UP: Generating unicharset and unichar properties files ===
[Fri Dec 9 21:53:09 DST 2016] /usr/local/bin/unicharset_extractor -D /tmp/tmp.tY7p2Ue5TC/san/ /tmp/tmp.tY7p2Ue5TC/san/san.Aksharyogini2.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Amiko.exp0.box /tm
p/tmp.tY7p2Ue5TC/san/san.Amita.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Annapurna_SIL.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Aparajita.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Arya.exp0.box /tmp/tmp.tY
7p2Ue5TC/san/san.Asar.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Baloo.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Biryani.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Dekko.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.E
k_Mukta.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Gargi.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Glegoo.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Hind_Medium.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Kadwa.exp0
.box /tmp/tmp.tY7p2Ue5TC/san/san.Kalam.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Kalimati.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Kokila.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Kurale.exp0.box /tmp/tmp.
tY7p2Ue5TC/san/san.Laila_Medium.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Lohit_Devanagari.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Mangal.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Tillana_Medium.exp0.box
/tmp/tmp.tY7p2Ue5TC/san/san.Utsaah.exp0.box /tmp/tmp.tY7p2Ue5TC/san/san.Yatra_One.exp0.box
Utf8 buffer too big, size=39 for र्ब्रह्माग्नौ

``` https://github.com/tesseract-ocr/tesseract/blob/9c7e99b04197/ccutil/unicharset.cpp#L615

https://github.com/tesseract-ocr/tesseract/blob/da4c064c2eeb/ccutil/unichar.h#L30 > // Maximum number of characters that can be stored in a UNICHAR. Must be
// at least 4. Must not exceed 31 without changing the coding of length.
#define UNICHAR_LEN 30

```
Utf8 buffer too big, size=39 for र्ब्रह्माग्नौ
```

For some reason, this whole word is being used as a unit in unicharset, rather than the composing Devanagari syllables - र्ब्र ह्मा ग्नौ  As per https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#combining-the-output-files

```
Either of these files can be converted to a recognition model as follows:

training/lstmtraining --model_output ~/tesstutorial/eng_from_chi/eng.lstm \
  --continue_from ~/tesstutorial/eng_from_chi/base_checkpoint

Finally, combine your new model with the language model files into a traineddata file:

training/combine_tessdata -o tessdata/eng.traineddata \
  ~/tesstutorial/eng_from_chi/eng.lstm \
  ~/tesstutorial/engtrain/eng.lstm-number-dawg \
  ~/tesstutorial/engtrain/eng.lstm-punc-dawg \
  ~/tesstutorial/engtrain/eng.lstm-word-dawg

The dawg files are optional. It will work without them, but they do usually provide some small improvement in accuracy.

NOTE  The unicharset used for the lstm has to match the unicharset used to generate the lstm-*-dawg files, but doesn't have to match the unicharset for the inttemp and base tesseract dawg files.

```
1. The given command does not create the recognition model. For that the command has to be appended with --stop_training.

```
training/lstmtraining --model_output ~/tesstutorial/sanskrit2003_from_full/san.lstm \
  --continue_from ~/tesstutorial/sanskrit2003_from_full/sanskrit2003_checkpoint \
  --stop_training
 ```

@theraysmith  Please review whether the modified commands are ok. thanks.

Wiki page needs to be updated for it. See Ray's comment re unicharset in https://github.com/tesseract-ocr/tesseract/issues/527

The unicharset from LSTM Training is included within the .LSTM model file. 

However this means that the old versions of dawg2wordlist cannot be used with the LSTM dawg files to get the original lists. https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00---Finetune Also see comments for https://github.com/tesseract-ocr/tesseract/issues/634

for first step of LSTM training i.e. creating lstmf files, use both --linedata_only --noextract_font_properties

```
training/tesstrain.sh --fonts_dir /home/shree/.fonts --lang bih  \
  --linedata_only --noextract_font_properties
  --langdata_dir ../langdata --tessdata_dir ./tessdata \
  --output_dir ~/tesstutorial/bihnew
```
  ```
$   training/lstmtraining --model_output ~/tesstutorial/sanskrit2003_from_full/sanskrit2003 \
>   --continue_from ~/tesstutorial/sanskrit2003_from_full/san.lstm \
>   --train_listfile ~/tesstutorial/santrain/san.training_files.txt \
>   --target_error_rate 0.01
Loaded file /home/shree/tesstutorial/sanskrit2003_from_full/sanskrit2003_checkpoint, unpacking...
Successfully restored trainer from /home/shree/tesstutorial/sanskrit2003_from_full/sanskrit2003_checkpoint
Loaded 1746/1746 pages (0-1746) of document /home/shree/tesstutorial/santrain/san.Chandas.exp0.lstmf
Loaded 345/1760 pages (1415-1760) of document /home/shree/tesstutorial/santrain/san.Uttara.exp0.lstmf
Loaded 1814/1814 pages (0-1814) of document /home/shree/tesstutorial/santrain/san.Gargi.exp0.lstmf
Found AVX
Found SSE
At iteration 1808/17200/17229, Mean rms=0.336%, delta=0.129%, char train=0.41%, word train=1.751%, skip ratio=0.2%,  New worst char error = 0.41 wrote checkpoint.

Encoding of string failed! Failure bytes: ffffffc2 ffffffa3 20 ffffffe0 ffffffa4 ffffffb8 ffffffe0 ffffffa4 ffffffb0 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffb5 ffffffe0 ffffffa5 ff
ffff8d ffffffe0 ffffffa4 ffffffb5
Can't encode transcription: व्यतर्कि १४. भवति ३७॥ £ सर्व्व
At iteration 1818/17300/17330, Mean rms=0.334%, delta=0.13%, char train=0.404%, word train=1.632%, skip ratio=0.3%,  wrote checkpoint.


``` Still getting the errors with the following version -
```

 tesseract -v
tesseract 4.00.00alpha-219-gc124f87
 leptonica-1.74
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

```

```

Can't encode transcription: सगुनल उठैलका देउता नेउता लवरना लोहमान कुदार
Encoding of string failed! Failure bytes: ffffffe0 ffffffa5 ffffff9c ffffffe0 ffffffa4 ffffffbf ffffffe0 ffffffa4 ffffffaf ffffffe0 ffffffa4 ffffffbe 20 ffffffe0 fffff
fa4 ffffffb9 ffffffe0 ffffffa5 ffffff9c ffffffe0 ffffffa4 ffffffbf ffffffe0 ffffffa4 ffffffaf ffffffe0 ffffffa4 ffffffbe 20 ffffffe0 ffffffa4 ffffffb2 ffffffe0 ffffffa
4 ffffffbe ffffffe0 ffffffa4 ffffffa6 ffffffe0 ffffffa4 ffffffa8 ffffffe0 ffffffa4 ffffffbe 20 ffffffe0 ffffffa4 ffffff85 ffffffe0 ffffffa4 ffffffa7 ffffffe0 ffffffa4
ffffffb8 ffffffe0 ffffffa5 ffffff87 ffffffe0 ffffffa4 ffffffb0 ffffffe0 ffffffa5 ffffff80 20 ffffffe0 ffffffa4 ffffffb8 ffffffe0 ffffffa5 ffffff81 ffffffe0 ffffffa4 ff
ffffac ffffffe0 ffffffa5 ffffff81 ffffffe0 ffffffa4 ffffff95 ffffffe0 ffffffa4 ffffffa8 ffffffe0 ffffffa4 ffffffbe
Can't encode transcription: बिसहरी सड़िया हड़िया लादना अधसेरी सुबुकना
Encoding of string failed! Failure bytes: ffffffe0 ffffffa5 ffffff9c ffffffe0 ffffffa4 ffffffbf ffffffe0 ffffffa4 ffffffaf ffffffe0 ffffffa4 ffffffa8 20 ffffffe0 fffff
fa4 ffffffac ffffffe0 ffffffa5 ffffff81 ffffffe0 ffffffa4 ffffffa6 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffa7 ffffffe0 ffffffa4 ffffffbf 20 ffffffe0 ffffffa
4 ffffff97 ffffffe0 ffffffa5 ffffff81 ffffffe0 ffffffa4 ffffffaa ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffa4 ffffffe0 ffffffa4 ffffffbe 20 ffffffe0 ffffffa4
ffffffb6 ffffffe0 ffffffa4 ffffffbe ffffffe0 ffffffa4 ffffffb8 ffffffe0 ffffffa4 ffffffa8 ffffffe0 ffffffa4 ffffffae ffffffe0 ffffffa5 ffffff87 20 ffffffe0 ffffffa4 ff
ffffb8 ffffffe0 ffffffa5 ffffff81 ffffffe0 ffffffa4 ffffffa6 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffa7 ffffffe0 ffffffa4 ffffffbe 20 ffffffe0 ffffffa4 ffff
ff9c ffffffe0 ffffffa4 ffffff81 ffffffe0 ffffffa4 ffffffa4 ffffffe0 ffffffa4 ffffffb8 ffffffe0 ffffffa4 ffffffbe ffffffe0 ffffffa4 ffffffb0 20 ffffffe0 ffffffa4 ffffff
a8 ffffffe0 ffffffa4 ffffffbf ffffffe0 ffffffa4 ffffff97 ffffffe0 ffffffa5 ffffff81 ffffffe0 ffffffa4 ffffffa8 ffffffe0 ffffffa4 ffffffbf ffffffe0 ffffffa4 ffffffaf ff
ffffe0 ffffffa4 ffffffbe ffffffe0 ffffffa4 ffffff81
Can't encode transcription: चूड़ियन बुद्धि गुप्ता शासनमे सुद्धा जँतसार निगुनियाँ
Encoding of string failed! Failure bytes: ffffffe0 ffffffa5 ffffff9c ffffffe0 ffffffa4 ffffff87 ffffffe0 ffffffa4 ffffffb2 ffffffe0 ffffffa5 ffffff82 ffffffe0 ffffffa4
 ffffff81 20 ffffffe0 ffffffa4 ffffffaa ffffffe0 ffffffa5 ffffff8b ffffffe0 ffffffa4 ffffffa5 ffffffe0 ffffffa4 ffffffbe 20 ffffffe0 ffffffa4 ffffffac ffffffe0 ffffffa
5 ffffff8b ffffffe0 ffffffa4 ffffffa5 ffffffe0 ffffffa4 ffffffbe 20 ffffffe0 ffffffa4 ffffffae ffffffe0 ffffffa5 ffffff8b ffffffe0 ffffffa4 ffffffa5 ffffffe0 ffffffa4
ffffffbe 20 ffffffe0 ffffffa4 ffffffb8 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffffb5 ffffffe0 ffffffa5 ffffff87 ffffffe0 ffffffa4 ffffff9a ffffffe0 ffffffa5 ff
ffff8d ffffffe0 ffffffa4 ffffff9b ffffffe0 ffffffa4 ffffffbe ffffffe0 ffffffa4 ffffffb8 ffffffe0 ffffffa4 ffffff81 20 ffffffe0 ffffffa4 ffffffaa ffffffe0 ffffffa4 ffff
ffbe ffffffe0 ffffffa4 ffffffb0 ffffffe0 ffffffa5 ffffff8d ffffffe0 ffffffa4 ffffff9f ffffffe0 ffffffa5 ffffff80 20 ffffffe0 ffffffa4 ffffffb2 ffffffe0 ffffffa5 ffffff
9c ffffffe0 ffffffa4 ffffff95 ffffffe0 ffffffa4 ffffffbf ffffffe0 ffffffa4 ffffffaf ffffffe0 ffffffa4 ffffffa8
Can't encode transcription: दौड़इलूँ पोथा बोथा मोथा स्वेच्छासँ पार्टी लड़कियन

``` @Also seen in finetune of Arabic
```

lstmtraining --model_output ~/tesstutorial/aratuned_from_ara/aratuned   --continue_from ~/tesstutorial/aratuned_from_ara/ara.lstm   --train_listfile ~/tesstutorial/ara/ara.training_files.txt     --eval_listfile ~/tesstutorial/aratest/ara.training_files.txt   --target_error_
rate 0.0001
Loaded file /home/shree/tesstutorial/aratuned_from_ara/aratuned_checkpoint, unpacking...
Successfully restored trainer from /home/shree/tesstutorial/aratuned_from_ara/aratuned_checkpoint
Loaded 229/229 pages (1-229) of document /home/shree/tesstutorial/ara/ara.Amiri.exp0.lstmf
Loaded 232/232 pages (1-232) of document /home/shree/tesstutorial/ara/ara.Arial.exp0.lstmf
Loaded 4/4 pages (1-4) of document /home/shree/tesstutorial/aratest/ara.Times_New_Roman.exp0.lstmf
Encoding of string failed! Failure bytes: ffffffd9 ffffff8e ffffffd9 ffffff8a ffffffd9 ffffff82 ffffffd9 ffffff90 ffffffd8 ffffffaf ffffffd9 ffffff90 ffffffd8 ffffffa7
 ffffffd8 ffffffb5 ffffffd9 ffffff8e 20 ffffffd9 ffffff85 ffffffd9 ffffff92 ffffffd8 ffffffaa ffffffd9 ffffff8f ffffffd9 ffffff86 ffffffd9 ffffff92 ffffffd9 ffffff83 f
fffffd9 ffffff8f 20 ffffffd9 ffffff86 ffffffd9 ffffff92 ffffffd8 ffffffa5 ffffffd9 ffffff90 20 ffffffd8 ffffffa7 ffffffd9 ffffff84 ffffffd9 ffffff84 ffffffd9 ffffff91
ffffffd9 ffffff8e ffffffd9 ffffff87 ffffffd9 ffffff90 20 ffffffd9 ffffff86 ffffffd9 ffffff90 ffffffd9 ffffff88 ffffffd8 ffffffaf ffffffd9 ffffff8f 20 ffffffd9 ffffff86
 ffffffd9 ffffff92 ffffffd9 ffffff85 ffffffd9 ffffff90 20 ffffffd9 ffffff85 ffffffd9 ffffff92 ffffffd9 ffffff83 ffffffd9 ffffff8f ffffffd8 ffffffa1 ffffffd9 ffffff8e f
fffffd8 ffffffa7 ffffffd8 ffffffaf ffffffd9 ffffff8e ffffffd9 ffffff87 ffffffd9 ffffff8e ffffffd8 ffffffb4 ffffffd9 ffffff8f
Can't encode transcription: نَيقِدِاصَ مْتُنْكُ نْإِ اللَّهِ نِودُ نْمِ مْكُءَادَهَشُ
Loaded 231/231 pages (1-231) of document /home/shree/tesstutorial/ara/ara.Arial_Unicode_MS.exp0.lstmf
Encoding of string failed! Failure bytes: ffffffd9 ffffff8e ffffffd9 ffffff88 ffffffd8 ffffffb1 ffffffd9 ffffff8f ffffffd8 ffffffb5 ffffffd9 ffffff90 ffffffd8 ffffffa8
 ffffffd9 ffffff92 ffffffd9 ffffff8a ffffffd9 ffffff8f 20 ffffffd9 ffffff84 ffffffd9 ffffff8e ffffffd8 ffffffa7 20 ffffffd8 ffffffaa ffffffd9 ffffff8d ffffffd8 ffffffa
7 ffffffd9 ffffff85 ffffffd9 ffffff8e ffffffd9 ffffff84 ffffffd9 ffffff8f ffffffd8 ffffffb8 ffffffd9 ffffff8f 20 ffffffd9 ffffff8a ffffffd9 ffffff81 ffffffd9 ffffff90
20 ffffffd9 ffffff85 ffffffd9 ffffff92 ffffffd9 ffffff87 ffffffd9 ffffff8f ffffffd9 ffffff83 ffffffd9 ffffff8e ffffffd8 ffffffb1 ffffffd9 ffffff8e ffffffd8 ffffffaa ff
ffffd9 ffffff8e ffffffd9 ffffff88 ffffffd9 ffffff8e 20 ffffffd9 ffffff85 ffffffd9 ffffff92 ffffffd9 ffffff87 ffffffd9 ffffff90 ffffffd8 ffffffb1 ffffffd9 ffffff90 ffff
ffd9 ffffff88 ffffffd9 ffffff86 ffffffd9 ffffff8f ffffffd8 ffffffa8 ffffffd9 ffffff90
Can't encode transcription: نَورُصِبْيُ لَا تٍامَلُظُ يفِ مْهُكَرَتَوَ مْهِرِونُبِ
Encoding of string failed! Failure bytes: ffffffd9 ffffff92 ffffffd9 ffffff87 ffffffd9 ffffff90 
``` Wiki does not seem to have this section,

https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00

TrainingTesseract 4.00
Stefan Weil edited this page 28 days ago · 9 revisions

We have a github outage in India just now, not sure if this is related to
that or wiki updation is still in todo.


ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Thu, Jan 12, 2017 at 5:04 AM, theraysmith <notifications@github.com>
wrote:

> See new section in trainingtesseract-4.00
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/549#issuecomment-272030162>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o2Kj43a8uaNjjhRJt8EBMPHq9-kgks5rRWcEgaJpZM4LIjyK>
> .
>
 It is working correctly in Spain, Thank you all for the incredible amount of work that you have all done. I don't see the changes either.

The wiki can be cloned as a git repo. Ray probably did some edits locally, but didn't 'push' them yet. ```

Encoding of string failed! Failure bytes: 9 31 32 30 30 45 6d 69 6c 69 65 2c 68 61 6e 73 4b 6f 6e 65 2e
Can't encode transcription: Møller.     1200Emilie,hansKone.

```
when trying to train frk @Shreeshrii 
Is this issue resolved coz I'm getting the same when training with Telugu language.. Please see https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#error-messages-from-training

```
Encoding of string failed! results when the text string for a training image 
cannot be encoded using the given unicharset. 

Possible causes are:

- There  is an un-represented character in the text, say a British Pound sign that is not in your unicharset.

- A  stray unprintable character (like tab or a control character) in the text.

- There  is an un-represented Indic grapheme/aksara in the text.

In any case it will result in that training image being ignored by the trainer. 

If the error is infrequent, it is harmless, but it may indicate that your unicharset is inadequate for representing the language that you are training. @harinath141 If you are getting a lot of these errors during finetune, try replace top layer training. You can use the box/tiff pairs generated for finetune. Commands will be similar to the following:

```
mkdir -p ~/tesstutorial/tellayer_from_tel 

combine_tessdata -e ../tessdata/tel.traineddata \
  ~/tesstutorial/tellayer_from_tel/tel.lstm
  
lstmtraining -U ~/tesstutorial/tel/tel.unicharset \
  --script_dir ../langdata  --debug_interval 0 \
  --continue_from ~/tesstutorial/tellayer_from_tel/tel.lstm \
  --append_index 5 --net_spec '[Lfx256 O1c105]' \
  --model_output ~/tesstutorial/tellayer_from_tel/tellayer \
  --train_listfile ~/tesstutorial/tel/tel.training_files.txt \
  --target_error_rate 0.01
``` ~/tesstutorial/tel/ should have your .lstmf files. Thank you @Shreeshrii I'll try to replace top layer @harinath141 

When you use ` --debug_interval 0` you will see messages every 100 iterations like the following:

```
At iteration 45909/58500/58569, Mean rms=0.639%, delta=0.621%, char train=1.861%, word train=13.302%, skip ratio=0%,  wrote checkpoint.

At iteration 45960/58600/58669, Mean rms=0.64%, delta=0.616%, char train=1.844%, word train=12.933%, skip ratio=0%,  wrote checkpoint.

2 Percent improvement time=14052, best error was 3.697 @ 31958
At iteration 46010/58700/58769, Mean rms=0.634%, delta=0.561%, char train=1.686%, word train=12.343%, skip ratio=0%,  New best char error = 1.686 wrote best model:/hom
e/shree/tesstutorial/khmlayer1_from_khm/khm1.686_46010.lstm wrote checkpoint.

```
When you use `--debug_interval -1` , messages such as the following will be shown for every iteration:

```

Iteration 59400: ALIGNED TRUTH : មានរូបឆ្មាំ អេស៊ីលីដា
Iteration 59400: BEST OCR TEXT : មានរូបឆ្មាំ អេស៊ីលីដា
File /tmp/tmp.BjsuuQ0dgJ/khm/khm.Noto_Serif_Khmer_Bold.exp0.lstmf page 53 (Perfect):
Mean rms=0.646%, delta=0.553%, train=1.878%(13.168%), skip ratio=0.1%
Iteration 59401: ALIGNED TRUTH : ឆ្កៀលយកភ្នែក ជួនឆ្លងវគ្គ ចាប់ពីពេលនោះមក របស់គាត់ កុំធេ្វសគំនិត។ អូនហ្អើយ =
Iteration 59401: BEST OCR TEXT : ឆ្លៀលយកភ្នែក ជួនឆ្លងវគត ចាប់ពីពេលនោះមក របស់គាត់ កុំធេ្វសគំនិត។ អូនហ្អើយ =
File /tmp/tmp.BjsuuQ0dgJ/khm/khm.Noto_Serif_Khmer.exp0.lstmf page 1 :
Mean rms=0.647%, delta=0.555%, train=1.881%(13.157%), skip ratio=0.1%
Iteration 59402: ALIGNED TRUTH : សឹងមានះរឹងត្អឹងមហិមា គុណ នៅប៉ែកឦសាននៃភ្នំ ទុលល្យូ ខេត្តស្ទឺងត្រែង,
Iteration 59402: BEST OCR TEXT : សឹងមានះរឹងត្អឹងមហិមា គុណ នៅប៉ែកឦសាននៃភ្នំ ទុលល្យូ ខេត្តស្ទឺងត្រែង,
File /tmp/tmp.BjsuuQ0dgJ/khm/khm.Leelawadee_UI_Bold.exp0.lstmf page 56 :
Mean rms=0.647%, delta=0.556%, train=1.881%(13.157%), skip ratio=0.1%
Iteration 59403: ALIGNED TRUTH : រឺគៃបន្លំបាន។ (រឿងអាខ្វាក់អាខ្វិន) អន្នំលោកង្សិ = ឧទាហរណ៍់៖តំបន់ខ្លះ ផ្ទះសម្បែង
Iteration 59403: BEST OCR TEXT : រឺគៃបន្លំបាន។ (រឿងអាខ្វាក់អាខ្វិន) អន្នំលោកង្សិ = ឧទាហរណ៍៖តំបន់ខ្លះ ផ្ទះសម្បែង
File /tmp/tmp.BjsuuQ0dgJ/khm/khm.Leelawadee_UI.exp0.lstmf page 51 :

```
intermediate checkpoint and .lstm files will be written to the output directory eg. ~/tesstutorial/tellayer_from_tel
You can also see visual debugging output with scrollview.  I am integrating Tesseract into an application, but I have some questions before keep going with the process.
I think every application should have security filters and considerations in order to avoid malicious and bad input data, so my questions are:

1. Does Tesseract have special code to handle bad or malicious input data? 
2. Or just have a few validations to tell the user the correct input data?
3. Releases are performed after doing some security reviews and testing?
4. Or just functional testing?

I will appreciate your answers.
Thanks a lot!  Is it possible to add to the [APIexample](https://github.com/tesseract-ocr/tesseract/wiki/APIExample) wiki on how to accomplish the equivalent of `tesseract --list-langs` and `tesseract --print-parameters` via the API?

## list langs

To list languages I currently use something like the following. However the problem is that I first need to initialize the english engine which might not be available. Is there a way to list languages without initializing any engine?

```cpp
  tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI();
  if (api->Init(NULL, "eng"))
    throw std::runtime_error(std::string("Unable to find training data for"));
  api->GetAvailableLanguagesAsVector(langs);
  std::vector<std::string> available;
  for(int i = 0; i < langs->length(); i++)
    available.push_back(langs->get(i).c_str());
```

## list parameters

The only method I can find in the base API to list supported parameters is:

```cpp
api->PrintVariables(stdout);
```

However this prints a text dump which is difficult to read by machines. Is there an api to iterate over the supported variables strings and stick them into a `std::vector<std::string>`? >list parameters
>
>The only method I can find in the base API to list supported parameters is:
However this prints a text dump which is difficult to read by machines. Is there an api to iterate over the supported variables strings and stick them into a std::vector<std::string>?

I don't think there is a method in the API for that.
but if someone will send a PR ... I see that you made [R binding for Tessaract](https://github.com/ropensci/tesseract)
You might want to add a link to it from [AddOns](https://github.com/tesseract-ocr/tesseract/wiki/AddOns#tesseract-wrappers)
  ```
Loaded 1059/1059 pages (0-1059) of document /tmp/tmp.HeGbXAKgjI/san/san.Santipur_OT_Medium.exp0.lstmf
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Bad box coordinates in boxfile string! दि ['ए\\^', 25 सर्व 341 2126 768 2194 44
Loaded 885/885 pages (0-885) of document /tmp/tmp.HeGbXAKgjI/san/san.Uttara.exp0.lstmf
No block overlapping textline: तत्पश्चात् इहैव समरे सौख्यं
No block overlapping textline: द्वाभ्यां न क्षुत्पिपासे अद्यापि
No block overlapping textline: अङ्के तु तस्मै (चेटीं विद्यन्ते
No block overlapping textline: इंचमितो दिने केन कल्कितम् पूजा
Page 31
Page 34
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Loaded 914/914 pages (0-914) of document /tmp/tmp.HeGbXAKgjI/san/san.Uttara.exp0.lstmf
Loaded 1096/1096 pages (0-1096) of document /tmp/tmp.HeGbXAKgjI/san/san.Santipur_OT_Medium.exp0.lstmf
Bad box coordinates in boxfile string! दि ['ए\\^', 25 सर्व 341 2126 768 2194 44
Page 35

``` https://github.com/tesseract-ocr/tesseract/blob/5deebe6c279f70215935c1f86baa7e7016c7f2a7/ccmain/linerec.cpp#L115 >Error in pixaGetCount: pixa not defined

https://github.com/DanBloomberg/leptonica/issues/223 ```
Page 3
Loaded 13/13 pages (1-13) of document /tmp/tmp.jX9oLgyrCZ/ara/ara.Traditional_Arabic.exp0.lstmf
No block overlapping textline: سُانَّلا
No block overlapping textline: لَعَجَ يذِلَّا نَوقُتَّتَ مْكُلَّعَلَ مْكُلِبْقَ نْمِ نَيذِلَّاوَ مْكُقَلَخَ يذِلَّا مُكُبَّرَ اودُبُعْا
No block overlapping textline: ىلَعَ انَلْزَّنَ امِمَّ بٍيْرَ فِي مْتُنْكُ نْإِوَ نَومُلَعْتَ مْتُنْأَوَ ادًادَنْأَ لِلَّهِ اولُعَتَجْ لَافَ مْكُلَ
No block overlapping textline: نَادِبْعَ
No block overlapping textline: ينَقِدِاصَ مْتُنْكُ نْإِ للَّهِا نِودُ نْمِ مْكُءَادَهَشُ اوعُدْاوَ هِلِثْمِ نْمِ ةٍرَوسُبِ اوتُأْفَ
No block overlapping textline: نَيرِفِاكَلْلِ
No block overlapping textline: اهَتِتَحْ نْمِ يرِتَجْ تٍانَّجَ مْلَهُ نَّأَ تِالِحَاصَّلا اولُمِعَوَ اونُمَآ نَيذِلَّا رِشِّبَوَ
No block overlapping textline: امَلَّكُ رُاهَنْلْأَا
No block overlapping textline: مْلَهُوَ
No block overlapping textline: لًاثَمَ بَرِضْيَ نْأَ ييِحْتَسْيَ لَا للَّهَا نَّإِ نَودُلِاخَ اهَيفِ مْهُوَ ةٌرَهَّطَمُ جٌاوَزْأَ اهَيفِ
No block overlapping textline: امَ
No block overlapping textline: امَّأَوَ مْبِّهِرَ نْمِ قُّلْحَا هُنَّأَ نَومُلَعْيَفَ اونُمَآ نَيذِلَّا امَّأَفَ اهَقَوْفَ امَفَ ةًضَوعُبَ
No block overlapping textline: نَيذِلَّا
Page 4

``` The number of errors reduced to a couple 
```

Page 5
Loaded 75/75 pages (1-75) of document /tmp/tmp.ZhCBJPqjME/ara/ara.Traditional_Arabic.exp0.lstmf
No block overlapping textline: _
No block overlapping textline: :: ."
 
```
after adding the following to ara.config

`textord_min_linesize 2.5
` i got the same message for Japanese which is:
No block overlapping textline: 俄然屁、30観光銚 差 塞翁が馬ランチに的配達硬翌月 -ふ陜西 脛骨 智
yet i was able to create LSTM files for the fonts that i specified, i think the LSTM are OK because i noticed in this [issue](https://github.com/DanBloomberg/leptonica/issues/223) the user zdenop said 

> If there is error message I expect something serious is happening. But nothing bad has happened. There is expected output. This will confuse end-users (current version of tesseract hides leptonica warnings, but this error message is there...)


so are the LSTM files are not defected although the error message was shown?
NOTE, im using tesseract 4.00.00alpha with leptonica 1.74.1  http://www.alanwood.net/unicode/devanagari-extended.html
http://www.alanwood.net/unicode/vedic-extensions.html

Sample image which uses some of these characters is attached.

Or at a minimum add support for U+0951, U+0952, U+A8F3, U+1CDA 

![swarankit](https://cloud.githubusercontent.com/assets/5095331/21003508/b913fb04-bd51-11e6-88c1-bc402c36e5c4.png)
  https://github.com/tesseract-ocr/tesseract/issues/522

stweil commented

>... without those nagging messages, I'd never have had a look on that part of Leptonica.


 DanBloomberg commented

>Alternatively, for a bit more flexibility, you can define the environmental variable
#define LEPT_MSG_SEVERITY L_SEVERITY_WARNING
and use
setMsgSeverity(L_SEVERITY_EXTERNAL);
 I want the above option in the release build.
@stweil? cc: @Danbloomberg First, some more of the basics, for disabling at least all info and warning messages.

You can define the external env variable to L_SEVERITY_ERROR.  That will disable warnings, which I believe makes sense for tesseract.

If you set this severity level at compile time, you guarantee that it can't be over-ridden at run-time.

If you want to go further and suppress all messages, including those from the ERROR_*  macros (which are different from the informational L_* macros), define NO_CONSOLE_IO on the compile line (or use L_SEVERITY_NONE).

As for the suggestion that setMsgSeverity() tells you what it does, I can easily add a 2nd arg (debug) and only emit those messages when debug = TRUE.  Stefan, is that what you want? Better, I'll just comment out the comments, leaving the interface unchanged. this change is pushed to leptonica master on github and modified to keep the warning(error) message but not the info(OK) messages I was thinking that if you try to set it to the external value, and that value is not set, it should issue a warning because the attempt failed.  I am already commenting the L_INFOs out there, and I can comment the warning out as well. All leptonica messages in setMsgSeverity() are now disabled, as requested. Either `DEBUG` or `NDEBUG` is set by `configure` (depending on --enable-debug). It looks like cmake currently does not set `DEBUG`. Maybe that's the reason why `api/baseapi.cpp` also tests for `_DEBUG` (set my the MS compiler).

`NDEBUG` is a standard macro which changes the behavior of `assert`. That's also the reason why it is used rather often.

If we want to separately control standard features and Tesseract features, we need both macros. Otherwise we could stick to using `NDEBUG`.

Personally I prefer keeping both macros, but I think that removing `DEBUG` would also work.  ```
Other case É of é is not in unicharset
Setting unichar properties
Setting properties for script Common
Setting properties for script Latin
Failed to load radical-stroke info from: ../langdata/radical-stroke.txt
Warning: given outputs 105 not equal to unicharset of 113.
```

@theraysmith I am trying to run the commands given in training tutorial.

1. the above messages are from basetrain.log.
 Does the langdata repo need to be updated for 4.0 alpha?

2.




.   Thanks, Ray.

On 07-Dec-2016 10:29 PM, "theraysmith" <notifications@github.com> wrote:

> Fixed in tesseract-ocr/langdata@3299c60
> <https://github.com/tesseract-ocr/langdata/commit/3299c600323a511486fdab58c8e31258c308a7bc>
> .
> I'm retesting now. It seems the tutorial works without it, so I imagine
> the accuracy numbers in the tutorial will come out different.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/542#issuecomment-265505151>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o1Gwtcn4WKaDYuXl83XfkwNT8-mUks5rFuYMgaJpZM4LGOuy>
> .
>
 Ray, 

Please add what are the minimum requirements for doing LSTM training in terms of hardware, software, etc.

I realized after running the process that I needed to build Scrollview.jar. I am not sure whether it is REQUIRED or only optional for those who would like to see visual debugging output. It is not built as part of the regular make install of tesseract and training tools. 

>> It will stop at 5000 iterations, (in about half an hour) 

I think that is probably dependent on the hardware used. I did not get any progress for more than one and a half hour - not sure whether it was because I did not have scrollview.jar at that point. I ran it later with 500 iterations.

I think it maybe helpful to have just a single iteration as the first step in tutorial to make sure that the process is working.

Also, the case that I think most people would like to use for LSTM training would be to use Finetuning to add a font to the existing trainingdata. It would be helpful to have a separate page on wiki for it. 

It would also be great to know how to add training data based on scanned images for typefaces that are not available as fonts. 

I will try to test 'finetuning' the Hindi traineddata for Sanskrit and post here.


   We're in the process of updating leptonica to version 1.74.0.

This will go out with debian with SO version 5.1.0.

I see in CMakeLists.txt:
   set(MINIMUM_LEPTONICA_VERSION 1.71)

Two questions:
(1) Should this be increased?  1.71 is at least 2 years old, likely still binary compatible.

(2) With autotools, the SO version defines the binary interface compatibility, which is why we're bumping it up from 5.0.0 in 1.73 to 5.1.0 in 1.74.  Does cmake use the SO version? Also see https://github.com/tesseract-ocr/tesseract/issues/536 https://github.com/tesseract-ocr/tesseract/wiki/Compiling
Ray added the 1.73 requirement for 4.0.

There is a pending patch from Jeff that will need 1.74.
https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-246744997

Anyway, the two build system should be updated. We now depend on 1.74.0 (see commit 11f205707) If you want to support 1.73 you can provide a patch... :-) I mean, the code will still use your patch for 1.74 but will fallback to the previous behaviour for 1.73. I thought that with 1.74, and SO 5.1, there is no longer a need for that tiff patch on debian.

btw, github release 1.74.0 is now also up as 1.74 (in the usual configure-make tarball) on leptonica.org:
     leptonica.org/source/leptonica-1.74.tar.gz  Jeff,
Any chance you will provide a Leptonica 1.74 PPA for Ubuntu 16.04? OK, I thought that you are familiar with PPAs. I didn't mean to push you to prepare a PPA. Jeff made a Leponica 1.74.1 package for Debian:
https://packages.debian.org/sid/libleptonica-dev Unofficial Ubuntu PPAs for Tesseract 4.00 & Leptonica 1.74:
https://launchpad.net/~alex-p/+archive/ubuntu/tesseract-ocr  In an image with Hindi text in various fonts, some of it at very large size

psm 3 - recognizes text at large font size
psm 6 - recognizes text at smaller font size

input image and output files are attached.
![sample6](https://cloud.githubusercontent.com/assets/5095331/20925445/04033a88-bbdd-11e6-861b-100e33bf5177.jpg)
[sample6-psm3.txt](https://github.com/tesseract-ocr/tesseract/files/633824/sample6-psm3.txt)
[sample6-psm6.txt](https://github.com/tesseract-ocr/tesseract/files/633825/sample6-psm6.txt)


  I tried the multilang option with the latest git code for an image which is mostly in Hindi with the titles in English. The English text was not recognized at all with -l hin+eng and only the first line in English was recognized when using -l eng+hin

The image used for testing and associated ground truth file are attached.

Please also see the console messages related to pixa and pixs displayed while processing.
```
time tesseract hin-eng.png hin-eng-eng -l eng
+ tesseract hin-eng.png hin-eng-eng -l eng
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined

real    0m16.114s
user    0m15.063s
sys     0m0.344s

time tesseract hin-eng.png hin-eng-hin -l hin
+ tesseract hin-eng.png hin-eng-hin -l hin
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Found AVX
Found SSE

real    0m17.266s
user    0m48.875s
sys     0m0.875s

time tesseract hin-eng.png hin-eng-hin-eng -l hin+eng
+ tesseract hin-eng.png hin-eng-hin-eng -l hin+eng
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Found AVX
Found SSE
Error in pixClone: pixs not defined

real    0m16.532s
user    0m45.844s
sys     0m1.031s

time tesseract hin-eng.png hin-eng-eng-hin -l eng+hin
+ tesseract hin-eng.png hin-eng-eng-hin -l eng+hin
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in pixaGetCount: pixa not defined
Error in pixaGetCount: pixa not defined
Found AVX
Found SSE
Error in pixClone: pixs not defined

real    0m17.696s
user    0m49.641s
sys     0m0.938s
```

![hin-eng](https://cloud.githubusercontent.com/assets/5095331/20924058/7bdff8a0-bbd5-11e6-890f-87bec2ea9077.png)
[hin-eng.txt](https://github.com/tesseract-ocr/tesseract/files/633687/hin-eng.txt)
 The output for the image with -l hin, -l eng, -l hin+eng and -l eng+hin is attached here.

[hin-eng-hin-eng.txt](https://github.com/tesseract-ocr/tesseract/files/633694/hin-eng-hin-eng.txt)
[hin-eng-eng-hin.txt](https://github.com/tesseract-ocr/tesseract/files/633703/hin-eng-eng-hin.txt)
[hin-eng-hin.txt](https://github.com/tesseract-ocr/tesseract/files/633704/hin-eng-hin.txt)
[hin-eng-eng.txt](https://github.com/tesseract-ocr/tesseract/files/633705/hin-eng-eng.txt)
 It looks like you have installed new 4.0 traineddata for Hindi but for English you are using 3.04 traineddata. @amitdo That is quite possible. I will download the eng.traineddata again and give it a try.

Thanks. https://github.com/DanBloomberg/leptonica/issues/223

@DanBloomberg
Error in pixClone: pixs not defined
 @amitdo Here is the result with 4.0 traineddata

```
time tesseract hin-eng.png hin-eng-eng --oem 1 --psm 6 -l eng
+ tesseract hin-eng.png hin-eng-eng --oem 1 --psm 6 -l eng
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Found AVX
Found SSE

real    0m44.983s
user    2m0.875s
sys     0m0.703s

time tesseract hin-eng.png hin-eng-hin --oem 1 --psm 6 -l hin
+ tesseract hin-eng.png hin-eng-hin --oem 1 --psm 6 -l hin
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Found AVX
Found SSE

real    1m1.776s
user    2m47.953s
sys     0m0.797s

time tesseract hin-eng.png hin-eng-hin-eng --oem 1 --psm 6 -l hin+eng
+ tesseract hin-eng.png hin-eng-hin-eng --oem 1 --psm 6 -l hin+eng
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Found AVX
Found SSE
Error in pixClone: pixs not defined

real    1m12.471s
user    3m14.844s
sys     0m0.984s

time tesseract hin-eng.png hin-eng-eng-hin --oem 1 --psm 6 -l eng+hin
+ tesseract hin-eng.png hin-eng-eng-hin --oem 1 --psm 6 -l eng+hin
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Found AVX
Found SSE
Error in pixClone: pixs not defined

real    1m42.064s
user    4m20.469s
sys     0m1.172s

``` I built leptonica and tesseract from github again.

The error message is displayed when using two languages together. However, OCR output is also produced. 

So I would suggest that the message be categorized as info or warning rather than error.

```
tesseract sg090.png sg090-hin-eng --oem 1 -l hin+eng
Tesseract Open Source OCR Engine v4.00.00alpha-204-g8b3c6ac with Leptonica
Found AVX
Found SSE
Error in pixClone: pixs not defined

real    0m50.552s
user    2m16.109s
sys     0m0.938s
``` This error is still there

```
 tesseract -v
tesseract 4.00.00alpha
 leptonica-1.74.1
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 Found AVX
 Found SSE

 ./out.sh (  time tesseract ${img_file} ${img_file%.*}-hin-eng --oem 1  -l hin+eng logfile)
Error in pixClone: pixs not defined

real    0m32.601s
user    1m42.328s
sys     0m0.813s
``` The message:
    *Error in pixClone: pixs not defined*
is correct.  The return on such an error is NULL, which is assigned to
another Pix pointer.  Errors will continue to propagate when that handle is
passed to another function, and so on.

The purpose of these error messages is to give a simple stack trace of
errors, so that (1) you know there was a problem and (2) you have a better
chance of finding out where it occurred.

On Thu, Jan 26, 2017 at 9:01 PM, Shreeshrii <notifications@github.com>
wrote:

> This error is still there
>
>  tesseract -v
> tesseract 4.00.00alpha
>  leptonica-1.74.1
>   libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8
>
>  Found AVX
>  Found SSE
>
>  ./out.sh (  time tesseract ${img_file} ${img_file%.*}-hin-eng --oem 1  -l hin+eng logfile)
> Error in pixClone: pixs not defined
>
> real    0m32.601s
> user    1m42.328s
> sys     0m0.813s
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/537#issuecomment-275589518>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLN4bbSwu-6jizXNfnL674V_oULtuks5rWXoOgaJpZM4LFTlV>
> .
>
 The excitement happens in api/baseapi.cpp, where End() calls Clear(), which conditionally calls SetInputImage(NULL).  That call generates the pixClone(NULL) error.

I see that the pixClone() in set_pix_original() in ccmain/tesseractclass.h was added by Ray on Dec. 5, 2016.  Related: https://github.com/tesseract-ocr/tessdata/issues/32

Please add version info to traineddata files and check for correct version during runtime. Thanks. @theraysmith Please consider including in next set of changes for 4.0.
 +1 Apropos `traineddata` files: what about changing the file format for 4.x? That files are just a collection of several files, and Tesseract needs a special program / code to compose or extract them. There exist widely used other file formats which provide similar features, including but not limited to zip files. Compression could also reduce the file size. What about using ProtocolBuffers / FlatBuffers / cbor to serialize the lstm model?  Related:
https://groups.google.com/forum/?hl=en#!searchin/tesseract-dev/zip|sort:date/tesseract-dev/U5HSugUeeeI See PR #911 for a proof-of-concept how `traineddata` in zip format can be implemented. Implemented here:
https://github.com/tesseract-ocr/tesseract/commit/dc8745e6fd4c >Reports Pre-4.0.0 for traineddata from 4.00.00alpha

Yes. `Pre-4.0.0` is the default if the traineddata does not contain a `version` file.  The current traineddata files for 4.0 will be obsolete once Ray will push the new ones, which will probably have the `version` file.  >What about moving to #pragma once?

https://google.github.io/styleguide/cppguide.html

>Do not use #pragma once; instead use the standard Google include guards. The path in the include guards should be relative to the top of your project tree.  While trying to process a gif file, when leptonica was not built with giflib, get the following messages

```
/mnt/c/Users/User/shree$ tesseract san001.gif san001-gif --psm 6 --oem 4 -l san
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in pixReadStreamGif: function not present
Error in pixReadStream: gif: no pix returned
Error in pixRead: pix not read
Error during processing.
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x1fd72f0 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatalstm-punc-dawg)
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x1fd8290 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatalstm-word-dawg)
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x1fd7110 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatalstm-number-dawg)
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x426afd0 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatapunc-dawg)
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x1fd6f20 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddataword-dawg)
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x426ae60 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatanumber-dawg)
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x472cef0 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatabigram-dawg)
ObjectCache(0x7f6a7eb9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x4784e50 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatafreq-dawg)


/mnt/c/Users/User/shree$ tesseract san001.gif san001-gif --psm 6 --oem 3 -l san
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in pixReadStreamGif: function not present
Error in pixReadStream: gif: no pix returned
Error in pixRead: pix not read
Error during processing.
ObjectCache(0x7fc1e7d9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x58291f0 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatapunc-dawg)
ObjectCache(0x7fc1e7d9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x5829010 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddataword-dawg)
ObjectCache(0x7fc1e7d9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x58290d0 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatanumber-dawg)
ObjectCache(0x7fc1e7d9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x5829190 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatabigram-dawg)
ObjectCache(0x7fc1e7d9e5c0)::~ObjectCache(): WARNING! LEAK! object 0x5828fb0 still has count 1 (id /mnt/c/Users/User/tesseract-ocr/tessdata/san.traineddatafreq-dawg)

``` >Error in pixReadStreamGif: function not present
>Error in pixReadStream: gif: no pix returned
Error in pixRead: pix not read

These error messages are from Leptonica.

>Error during processing.

This one and the ObjectCache scary messages are from Tesseract.

https://github.com/tesseract-ocr/tesseract/blob/a75ab450a/ccutil/object_cache.h#L42

Looks like a bug in Tesseract. Error is related to input file not being found.

```
C:\Users\User>tesseract abc.jpg abc
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error during processing.
ObjectCache(5A7A9AC8)::~ObjectCache(): WARNING! LEAK! object 032C6178 still has count 1 (id C:\Program Files (x86)\Tesseract-OCR/tessdata/eng.traineddatapunc-dawg)
ObjectCache(5A7A9AC8)::~ObjectCache(): WARNING! LEAK! object 032C51C8 still has count 1 (id C:\Program Files (x86)\Tesseract-OCR/tessdata/eng.traineddataword-dawg)
ObjectCache(5A7A9AC8)::~ObjectCache(): WARNING! LEAK! object 032C5278 still has count 1 (id C:\Program Files (x86)\Tesseract-OCR/tessdata/eng.traineddatanumber-dawg)
ObjectCache(5A7A9AC8)::~ObjectCache(): WARNING! LEAK! object 032C9C28 still has count 1 (id C:\Program Files (x86)\Tesseract-OCR/tessdata/eng.traineddatabigram-dawg)
ObjectCache(5A7A9AC8)::~ObjectCache(): WARNING! LEAK! object 032C50C8 still has count 1 (id C:\Program Files (x86)\Tesseract-OCR/tessdata/eng.traineddatafreq-dawg)

C:\Users\User>
``` Did you succeed in making it run on any image? 
I get the same error message on both *.png and *.jpg Check the version of leptonica and image livs by

tesseract -v

See if png and jpg libs are listed

In my case, giflib is not included in leptonica, hence it does not process
gifs.
Png and jpg files are processed, though there are some info and warning
messages from leptonica.

The latest GitHub version of leptonica and tesseract have fewer of these
msgs.

On 14-Dec-2016 12:10 AM, "Srdjan Prodanovic" <notifications@github.com>
wrote:

> Did you succeed in making it run on any image?
> I get the same error message on both *.png and *.jpg
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/529#issuecomment-266823793>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o2bnKAzARMj2N1Wskc4ioJ080XMnks5rHuaygaJpZM4LDjOe>
> .
>
 You are completely right, when bulding Leptonica from source I relied on instructions from Tesseract Wiki, which are incomplete. 

From http://www.leptonica.org/source/README.html#DEPENDENCIES
Leptonica is configured to handle image I/O using these external
   libraries: libjpeg, libtiff, libpng, libz, libgif, libwebp, libopenjp2
   These libraries are easy to obtain.  For example, using the
   debian package manager:
       sudo apt-get install 
   where  = {libpng12-dev, libjpeg62-dev, libtiff4-dev}.

Now png and jpeg rendering libs got integrated when I rebuilt everything again. 
ubuntu@XXX$ tesseract -v
tesseract 4.00.00alpha
 leptonica-1.73
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.51 : libtiff 4.0.3 : zlib 1.2.8

Thanks! The error also comes when tesseract is not able to write an output file eg. missing output directory .. or other such io issues. getting error re: LEAK!  when input file not found - wrong name given

```
shree@ALL-IN-1-TOUCH:/mnt/c/Users/User/shree/kannada$ tesseract scan001.tif scan001 --oem 1 -l kan makebox
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error during processing.
ObjectCache(0x7fd27279eac0)::~ObjectCache(): WARNING! LEAK! object 0x2b114e0 still has count 1 (id /mnt/c/Users/User/shree/tessdata/kan.traineddatalstm-punc-dawg)
ObjectCache(0x7fd27279eac0)::~ObjectCache(): WARNING! LEAK! object 0x2b127c0 still has count 1 (id /mnt/c/Users/User/shree/tessdata/kan.traineddatalstm-word-dawg)
ObjectCache(0x7fd27279eac0)::~ObjectCache(): WARNING! LEAK! object 0x2b11360 still has count 1 (id /mnt/c/Users/User/shree/tessdata/kan.traineddatalstm-number-dawg)
``` Getting the same error.



> 
> $ tesseract test.jpeg file
> Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
> Error in fopenReadStream: file not found
> Error in findFileFormat: image file not found
> Error during processing.
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x1b46fc0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatalstm-punc-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x1b46db0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatalstm-word-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x1b46e60 still has count 1 (id /usr/local/share/tessdata/eng.traineddatalstm-number-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x27604a0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatapunc-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x2761910 still has count 1 (id /usr/local/share/tessdata/eng.traineddataword-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x27601f0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatanumber-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x1b46bc0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatabigram-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object 0x286b8a0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatafreq-dawg)




My version is:

> $  tesseract --version
> tesseract 4.00.00alpha
>  leptonica-1.74.1
>   libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8
> 
>  Found AVX
>  Found SSE  file not found Error

make sure that test.jpeg is in the path. try

ls test.jpeg
tesseract test.jpeg file



ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sat, Feb 18, 2017 at 3:13 PM, Taylan Koca <notifications@github.com>
wrote:

> Getting the same error.
>
> tesseract test.jpeg file Tesseract Open Source OCR Engine v4.00.00alpha
> with Leptonica Error in fopenReadStream: file not found Error in
> findFileFormat: image file not found Error during processing.
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x1b46fc0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatalstm-punc-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x1b46db0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatalstm-word-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x1b46e60 still has count 1 (id /usr/local/share/tessdata/eng.traineddatalstm-number-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x27604a0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatapunc-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x2761910 still has count 1 (id /usr/local/share/tessdata/eng.traineddataword-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x27601f0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatanumber-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x1b46bc0 still has count 1 (id /usr/local/share/tessdata/eng.traineddatabigram-dawg)
> ObjectCache(0x7fd8a283bac0)::~ObjectCache(): WARNING! LEAK! object
> 0x286b8a0 still has count 1 (id /usr/local/share/tessdata/eng.
> traineddatafreq-dawg)
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/529#issuecomment-280834544>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o5RXPUonbIVRjCUiSwdhSpbjPencks5rdr1OgaJpZM4LDjOe>
> .
>
 I encounted the same error that tesseract not able to read gif.
error look like this:
...
Error in pixReadStreamGif: function not present
...
When I checked the version of tesseract, it did not show gif library: 
tesseract 4.00.00alpha
leptonica-1.74.1
libjpeg 8d (libjpeg-turbo 1.5.0) : libpng 1.6.25 : libtiff 4.0.6 : zlib 1.2.8

So I install libgif-dev from synaptic and recompile the leptonica again.
This time when I checked the version of tesseract again, it gave me:
tesseract 4.00.00alpha
leptonica-1.74.1
**libgif 5.1.4** : libjpeg 8d (libjpeg-turbo 1.5.0) : libpng 1.6.25 : libtiff 4.0.6 : zlib 1.2.8

After I tried again using gif with tesseract, it gave no error any more. Making the PWD be where the file is located works, but I consider that broken.  If I supply a relative or absolute path to an input file, tesseract should read that without issue.  Instead it says the file can't be found, which is bizarre.  I'm going to change my script to use cat and have tesseract read from standard input, because this is so broken.

tesseract --version                                                                  
tesseract 3.05.00
 leptonica-1.74.1
  libjpeg 8d : libpng 1.6.29 : libtiff 4.0.7 : zlib 1.2.8

I'm using it on MacOS through homebrew, and my source image is a PNG.

> file not found Error

> make sure that test.jpeg is in the path. try

> ls test.jpeg
> tesseract test.jpeg file



> ShreeDevi In the image_to_string function of tesseract.py, the input image is converted to bmp and stored in /tmp directory in my Linux box. When this path (with '/') pass to subprocess.Popen, tesseract cannot find the file.  You can simulate this by running the following in the command prompt.

tesseract /tmp/tess__cwb36mk.bmp output.txt Can you break on the warning and get some more information? From a quick look, `Dict::Load()` doesn't add `load_bigram_dawg` to `dawgs_`, which either is a bug or should be documented in a comment, but I don't know whether fixing that would solve this problem. Of course, all this stuff should really be RAII-ified... :-) Well, I was thinking more along the line of inspecting the offending object. Apparently fixing what I saw in `Dict::load()` didn't solve the problem, so I'll try gdb myself. Unfortunately `./configure --enable-debug` doesn't seem to work, because there are `-O2` arguments after the `-O0` ones, and "If you use multiple -O options, with or without level numbers, the last such option is the one that is effective.", so my workaround for that is to edit `configure` and `configure.ac`. Intermediate result of analysis: the program seems to be using `Dict::GlobalDawgCache()`, which has static duration, but the Dict using the cache is not deleted before the program `exit()`s. To be continued later... My debug builds avoid the `-O0` / `-O2` problem like this:

    mkdir -p bin/debug
    cd bin/debug
    # Disable parts which are not needed for debugging (shorter build time)
    # and don't use a shared library for Tesseract (easier debugging).
    # Avoid -O2 compiler option.
    ../../configure  --enable-debug --disable-shared --disable-static CXXFLAGS="-g"
    make
    cd ../..
    gdb --args bin/debug/api/tesseract [...]

I still did not find a correct fix for `configure.ac`. I have some evidence (in a new branch [issue529](https://github.com/rfschtkt/tesseract/tree/issue529) on my own fork, unless there's a better way to present that?), currently modifying the messages coming from the global cache. It mentions "workaround" here and there, but perhaps a cleaner solution can be found. Valgrind output for the test case (after PR #912 was applied):

     HEAP SUMMARY:
         in use at exit: 16,109,940 bytes in 4 blocks
       total heap usage: 666,366 allocs, 666,362 frees, 179,459,012 bytes allocated
     
     Searching for pointers to 4 not-freed blocks
     Checked 19,243,304 bytes
     
     8 bytes in 1 blocks are still reachable in loss record 1 of 4
        at 0x4C2BBAF: malloc (vg_replace_malloc.c:299)
        by 0x5D8C688: gomp_malloc (alloc.c:37)
        by 0x5D9B867: gomp_init_num_threads (proc.c:91)
        by 0x5D8ACC5: initialize_env (env.c:1208)
        by 0x400F649: call_init.part.0 (dl-init.c:72)
        by 0x400F75A: call_init (dl-init.c:30)
        by 0x400F75A: _dl_init (dl-init.c:120)
        by 0x4000CD9: ??? (in /lib/x86_64-linux-gnu/ld-2.24.so)
        by 0x2: ???
        by 0xFFF000412: ???
        by 0xFFF00043B: ???
        by 0xFFF00043D: ???
     
     12 bytes in 1 blocks are indirectly lost in loss record 2 of 4
        at 0x4C2BBAF: malloc (vg_replace_malloc.c:299)
        by 0x2A8339: alloc_string(int) (memry.cpp:32)
        by 0x2AAEF0: STRING::AllocData(int, int) (strngs.cpp:55)
        by 0x2AB120: STRING::STRING(STRING const&) (strngs.cpp:114)
        by 0x234CBA: tesseract::Dawg::Dawg(tesseract::DawgType, STRING const&, PermuterType, int) (dawg.h:209)
        by 0x31149F: tesseract::SquishedDawg::SquishedDawg(tesseract::DawgType, STRING const&, PermuterType, int) (dawg.h:416)
        by 0x311260: tesseract::DawgLoader::Load() (dawg_cache.cpp:91)
        by 0x311C6F: _TessMemberResultCallback_0_0<true, tesseract::Dawg*, tesseract::DawgLoader>::Run() (tesscallback.h:145)
        by 0x311787: tesseract::ObjectCache<tesseract::Dawg>::Get(STRING, TessResultCallback<tesseract::Dawg*>*) (object_cache.h:78)
        by 0x3110DC: tesseract::DawgCache::GetSquishedDawg(STRING const&, tesseract::TessdataType, int, tesseract::TessdataManager*) (dawg_cache.cpp:51)
        by 0x231A97: tesseract::Dict::Load(STRING const&, tesseract::TessdataManager*) (dict.cpp:242)
        by 0x20B765: tesseract::Wordrec::program_editup(char const*, tesseract::TessdataManager*, tesseract::TessdataManager*) (tface.cpp:54)
     
     100 (88 direct, 12 indirect) bytes in 1 blocks are definitely lost in loss record 3 of 4
        at 0x4C2C21F: operator new(unsigned long) (vg_replace_malloc.c:334)
        by 0x31123F: tesseract::DawgLoader::Load() (dawg_cache.cpp:91)
        by 0x311C6F: _TessMemberResultCallback_0_0<true, tesseract::Dawg*, tesseract::DawgLoader>::Run() (tesscallback.h:145)
        by 0x311787: tesseract::ObjectCache<tesseract::Dawg>::Get(STRING, TessResultCallback<tesseract::Dawg*>*) (object_cache.h:78)
        by 0x3110DC: tesseract::DawgCache::GetSquishedDawg(STRING const&, tesseract::TessdataType, int, tesseract::TessdataManager*) (dawg_cache.cpp:51)
        by 0x231A97: tesseract::Dict::Load(STRING const&, tesseract::TessdataManager*) (dict.cpp:242)
        by 0x20B765: tesseract::Wordrec::program_editup(char const*, tesseract::TessdataManager*, tesseract::TessdataManager*) (tface.cpp:54)
        by 0x18F69F: tesseract::Tesseract::init_tesseract_internal(char const*, char const*, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, tesseract::TessdataManager*) (tessedit.cpp:412)
        by 0x18F2D2: tesseract::Tesseract::init_tesseract(char const*, char const*, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, tesseract::TessdataManager*) (tessedit.cpp:324)
        by 0x12D377: tesseract::TessBaseAPI::Init(char const*, int, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, bool (*)(STRING const&, GenericVector<char>*)) (baseapi.cpp:326)
        by 0x12D0C0: tesseract::TessBaseAPI::Init(char const*, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool) (baseapi.cpp:284)
        by 0x12BB90: main (tesseractmain.cpp:434)
     
     16,109,832 bytes in 1 blocks are possibly lost in loss record 4 of 4
        at 0x4C2C93F: operator new[](unsigned long) (vg_replace_malloc.c:423)
        by 0x3102E0: tesseract::SquishedDawg::read_squished_dawg(tesseract::TFile*) (dawg.cpp:330)
        by 0x3114D4: tesseract::SquishedDawg::Load(tesseract::TFile*) (dawg.h:439)
        by 0x311277: tesseract::DawgLoader::Load() (dawg_cache.cpp:92)
        by 0x311C6F: _TessMemberResultCallback_0_0<true, tesseract::Dawg*, tesseract::DawgLoader>::Run() (tesscallback.h:145)
        by 0x311787: tesseract::ObjectCache<tesseract::Dawg>::Get(STRING, TessResultCallback<tesseract::Dawg*>*) (object_cache.h:78)
        by 0x3110DC: tesseract::DawgCache::GetSquishedDawg(STRING const&, tesseract::TessdataType, int, tesseract::TessdataManager*) (dawg_cache.cpp:51)
        by 0x231A97: tesseract::Dict::Load(STRING const&, tesseract::TessdataManager*) (dict.cpp:242)
        by 0x20B765: tesseract::Wordrec::program_editup(char const*, tesseract::TessdataManager*, tesseract::TessdataManager*) (tface.cpp:54)
        by 0x18F69F: tesseract::Tesseract::init_tesseract_internal(char const*, char const*, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, tesseract::TessdataManager*) (tessedit.cpp:412)
        by 0x18F2D2: tesseract::Tesseract::init_tesseract(char const*, char const*, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, tesseract::TessdataManager*) (tessedit.cpp:324)
        by 0x12D377: tesseract::TessBaseAPI::Init(char const*, int, char const*, tesseract::OcrEngineMode, char**, int, GenericVector<STRING> const*, GenericVector<STRING> const*, bool, bool (*)(STRING const&, GenericVector<char>*)) (baseapi.cpp:326)
     
     LEAK SUMMARY:
        definitely lost: 88 bytes in 1 blocks
        indirectly lost: 12 bytes in 1 blocks
          possibly lost: 16,109,832 bytes in 1 blocks
        still reachable: 8 bytes in 1 blocks
             suppressed: 0 bytes in 0 blocks
     
     ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0)
     ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0)

The output was generated using `valgrind --verbose --track-origins=yes --leak-check=full --show-leak-kinds=all bin/debug/x86_64-linux-gnu/api/tesseract a b`. The thing is that `exit()` was inherited from C, and all kinds of things are hooked up to `atexit()` (even variables with static storage duration), but _not_ automatic variables like `tesseract::TessBaseAPI api;`. Inside `main()` you could replace it with plain `return`, but elsewhere I think you have to avoid `exit()` and instead, until the program becomes exception-safe (RAII!) with a global try/catch in main(), perhaps use `quick_exit()`. Or adapt the code I wrote for evidence as a workaround.

Incidentally, main() has the following comment (although I have no idea why anybody would care about leaked STRING objects, as compared to, e.g., open handles to files, or the subject of this issue):

```
  /* main() calls functions like ParseArgs which call exit().
   * This results in memory leaks if vars_vec and vars_values are
   * declared as auto variables (destructor is not called then). */
  static GenericVector<STRING> vars_vec;
  static GenericVector<STRING> vars_values;
```

Well, I guess it might matter to diagnostic tools like Valgrind, but I suppose they're empty now. When tools like Valgrind are used to search for critical memory leaks, any memory leak is bad because it creates a warning which has to be analyzed. Example: Before PR #912 there were 40,102 allocated blocks at program termination, after that PR there remain 3 blocks (see above).

    LEAK SUMMARY:
       definitely lost: 0 bytes in 0 blocks
       indirectly lost: 0 bytes in 0 blocks
         possibly lost: 0 bytes in 0 blocks
       still reachable: 41,740,480 bytes in 40,102 blocks
                          of which reachable via heuristic:
                            newarray           : 4,147,800 bytes in 4,350 blocks
            suppressed: 0 bytes in 0 blocks
 I fully agree, and I should have guessed that it had taken some effort to get it down to 4 blocks.

Anyway, after my latest commit I don't get the messages anymore.

(Added) What's the 2 all about? Is anybody using it, is it documented? Otherwise, could it be just EXIT_FAILURE instead? /pedantic An additional commit in PR #912 fixes this issue. The crash problem is handled in PR #917. I think that using `static` to pander to ghost-of-the-past `exit()` is an abomination. Exiting other than in main is most probably the result of an error condition, where all you're concerned with is returning the error value. The only place where you should be concerned with a clean Valgrind report is inside main(), where you should use `return` rather than `exit()` to be compatible with the C++ paradigm of proper stack unwinding.

(Added) Unfortunately there's also `ScrollView::Exit()`, not sure whether these messages were a problem there? C:\Program Files\Tesseract-OCR>tesseract aws.tif aa.pdf
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Error in fopenReadStream: file not found
Error in findFileFormat: image file not found
Error during processing.
ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 014DB180 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddatalstm-punc-dawg)

ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 014DB228 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddatalstm-word-dawg)

ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 01732ED8 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddatalstm-number-daw
g)
ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 048A4618 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddatapunc-dawg)
ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 014DB278 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddataword-dawg)
ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 014DB118 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddatanumber-dawg)
ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 048A89E0 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddatabigram-dawg)
ObjectCache(649E5A88)::~ObjectCache(): WARNING! LEAK! object 048A8A80 still has
count 1 (id \Program Files\Tesseract-OCR\tessdata/eng.traineddatafreq-dawg)

C:\Program Files\Tesseract-OCR>tesseract -v
tesseract 4.00.00alpha
 leptonica-1.74.1
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.5.0) : libpng 1.6.20 : libtiff 4
.0.6 : zlib 1.2.8 : libwebp 0.4.3 : libopenjp2 2.1.0

Please help in this regard
installed on windows 7 Installed package tesseract-ocr-setup-4.00.00dev  Using dawg2wordlist on lstm-word-dawg with the unicharset in the traineddata files creates a wordlist with 'junk' words (similar to what one gets when cube-word-dawg is processed with unicharset instead of cube-unicharset).

So either the lstm-unicharset has not been included in the traineddata or the lstm version of unicharset has not been included in the traineddata.

e.g. for English, see the commands and a sample of resulting wordlist ..

dawg2wordlist eng.unicharset eng.word-dawg eng.word.txt

e
en
entrepreneur
entrepreneurs
entrepreneurship
entrepreneurial
entrepreneur's
entrenched

dawg2wordlist eng.cube-unicharset eng.cube-word-dawg eng.cube.cube-word.txt

t
tATu
tBlog
tCK
tHE
tHe
tHeM
tMP
tO
tPA
tRNA
ta
tab
tabbed

However, using the following gives incorrect wordlists ..

dawg2wordlist eng.unicharset eng.lstm-word-dawg eng.lstm-word.txt

5
5h
5hr
5hrh
5hrh0
5hrh0%
5hrh0%bTIr
5hrh0%bTIr1
5hrh0%bTIrM
5hrh0%bTIrO
5hrh0%bTIr%v

Similar to the erroneous wordlist, if the cube dawg is processed with the regular unicharset

dawg2wordlist eng.unicharset eng.cube-word-dawg eng.cube-word.txt

Joined
Joined|Ph
JoinedBAe1
Joined-6
Joined°R
Joined°v
Joined°vg
Joinedg%
JoinedX
Joined%|
Joined]a|

 However, removal of all dawg files from the traineddata does not seem to degrade the accuracy - tested with the phototest.tif and eurotext.tif test files.

https://github.com/Shreeshrii/tessdata4alpha/blob/master/en4.traineddata has this smaller minimal LSTM traineddata for English, used for the test. Unicharset was used for converting by dawg2wordlist. Will there be a new version of the program using LSTM instead of unicharset for viewing the wordlist, numbers and punctuation lists?  [Sat Dec 3 15:06:31 DST 2016] /usr/local/bin/tesseract /tmp/tmp.6Fy6JZCueq/eng/eng.Verdana_Italic.exp0.tif /tmp/tmp.6Fy6JZCueq/eng/eng.Verdana_Italic.exp0 lstm.train
read_params_file: Can't open lstm.train

https://github.com/tesseract-ocr/tesseract/tree/master/tessdata/configs
does not have the file lstm.train in it Fixed in 65517794f9bb  Hi, I've been trying to build the training tools, but still can not success.

I already installed the 3 dependencies mentioned at [Training Tesseract](https://github.com/tesseract-ocr/tesseract/wiki/Training-Tesseract#additional-libraries-required) :

1. libicu
2. libpango
3. libcairo

I also build leptonica  in the same machine.
All the native libraries are already added to $LD_LIBRARY_PATH and binaries to $PATH.
I am using gcc 4.8.4 whic meets c++11 needed standards.

Standing at root source of Tesseract, after running **./configure --prefix=path/to/tesseract** I am still getting the message: **You can not build training tools because of missing dependency.**

This is the configure output:

```
checking for g++... g++
checking for C++ compiler default output file name... a.out
checking whether the C++ compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables... 
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
fatal: Not a git repository: './.git'
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking for gawk... gawk
checking whether make sets $(MAKE)... yes
checking for style of include used by make... GNU
checking dependency style of g++... gcc3
checking whether to enable maintainer-specific portions of Makefiles... no
checking build system type... x86_64-unknown-linux-gnu
checking host system type... x86_64-unknown-linux-gnu
checking --enable-graphics argument... yes
checking whether to disable cube... no
checking --enable-embedded argument... no
checking for  option to support OpenMP... -fopenmp
checking --enable-opencl argument... no
checking how to run the C++ preprocessor... g++ -E
checking for grep that handles long lines and -e... /bin/grep
checking for egrep... /bin/grep -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking CL/cl.h usability... no
checking CL/cl.h presence... no
checking for CL/cl.h... no
checking OpenCL/cl.h usability... no
checking OpenCL/cl.h presence... no
checking for OpenCL/cl.h... no
checking tiffio.h usability... yes
checking tiffio.h presence... yes
checking for tiffio.h... yes
checking for clGetPlatformIDs in -lOpenCL... no
checking --enable-visibility argument... no
checking --enable-multiple-libraries argument... no
checking whether to use tessdata-prefix... yes
checking whether to enable debugging... no
checking for gcc... gcc
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking dependency style of gcc... gcc3
checking for a sed that does not truncate output... /bin/sed
checking for fgrep... /bin/grep -F
checking for ld used by gcc... /usr/bin/ld
checking if the linker (/usr/bin/ld) is GNU ld... yes
checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
checking the name lister (/usr/bin/nm -B) interface... BSD nm
checking whether ln -s works... yes
checking the maximum length of command line arguments... 1966080
checking whether the shell understands some XSI constructs... yes
checking whether the shell understands "+="... yes
checking for /usr/bin/ld option to reload object files... -r
checking for objdump... objdump
checking how to recognize dependent libraries... pass_all
checking for ar... ar
checking for strip... strip
checking for ranlib... ranlib
checking command to parse /usr/bin/nm -B output from gcc object... ok
checking for dlfcn.h... yes
checking whether we are using the GNU C++ compiler... (cached) yes
checking whether g++ accepts -g... (cached) yes
checking how to run the C++ preprocessor... g++ -E
checking for objdir... .libs
checking if gcc supports -fno-rtti -fno-exceptions... no
checking for gcc option to produce PIC... -fPIC -DPIC
checking if gcc PIC flag -fPIC -DPIC works... yes
checking if gcc static flag -static works... yes
checking if gcc supports -c -o file.o... yes
checking if gcc supports -c -o file.o... (cached) yes
checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking whether -lc should be explicitly linked in... no
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... yes
checking for ld used by g++... /usr/bin/ld -m elf_x86_64
checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes
checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking for g++ option to produce PIC... -fPIC -DPIC
checking if g++ PIC flag -fPIC -DPIC works... yes
checking if g++ static flag -static works... yes
checking if g++ supports -c -o file.o... yes
checking if g++ supports -c -o file.o... (cached) yes
checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether byte ordering is bigendian... no
checking if compiling with clang... no
checking whether compiler supports C++11... yes
checking for snprintf... yes
checking for library containing sem_init... -lpthread
checking for ANSI C header files... (cached) yes
checking whether time.h and sys/time.h may both be included... yes
checking for sys/wait.h that is POSIX.1 compatible... yes
checking sys/ipc.h usability... yes
checking sys/ipc.h presence... yes
checking for sys/ipc.h... yes
checking sys/shm.h usability... yes
checking sys/shm.h presence... yes
checking for sys/shm.h... yes
checking limits.h usability... yes
checking limits.h presence... yes
checking for limits.h... yes
checking malloc.h usability... yes
checking malloc.h presence... yes
checking for malloc.h... yes
checking for stdbool.h that conforms to C99... yes
checking for _Bool... no
checking whether #! works in shell scripts... yes
checking for special C compiler options needed for large files... no
checking for _FILE_OFFSET_BITS value needed for large files... no
checking for getline... yes
checking for wchar_t... yes
checking for long long int... yes
checking for off_t... yes
checking for mbstate_t... yes
checking for leptonica... yes
checking for l_generateCIDataForPdf in -llept... yes
checking leptonica headers version >= 1.71... yes
checking unicode/uchar.h usability... yes
checking unicode/uchar.h presence... yes
checking for unicode/uchar.h... yes
checking for pkg-config... /usr/bin/pkg-config
checking pkg-config is at least version 0.9.0... yes
checking for pango... yes
checking for cairo... yes
configure: creating ./config.status
config.status: creating Makefile
config.status: creating tesseract.pc
config.status: creating api/Makefile
config.status: creating ccmain/Makefile
config.status: creating opencl/Makefile
config.status: creating ccstruct/Makefile
config.status: creating ccutil/Makefile
config.status: creating classify/Makefile
config.status: creating cube/Makefile
config.status: creating cutil/Makefile
config.status: creating dict/Makefile
config.status: creating neural_networks/runtime/Makefile
config.status: creating textord/Makefile
config.status: creating viewer/Makefile
config.status: creating wordrec/Makefile
config.status: creating tessdata/Makefile
config.status: creating tessdata/configs/Makefile
config.status: creating tessdata/tessconfigs/Makefile
config.status: creating testing/Makefile
config.status: creating java/Makefile
config.status: creating java/com/Makefile
config.status: creating java/com/google/Makefile
config.status: creating java/com/google/scrollview/Makefile
config.status: creating java/com/google/scrollview/events/Makefile
config.status: creating java/com/google/scrollview/ui/Makefile
config.status: creating doc/Makefile
config.status: creating config_auto.h
config.status: executing depfiles commands
config.status: executing libtool commands

```

Does any one can help me with this? I am stocked at this point.
Thank you so much! What OS ?
Which branch, 3.05 or master (4.0)

For training tools you need Dev versions

sudo apt-get install libicu-dev
sudo apt-get install libpango1.0-dev
sudo apt-get install libcairo2-dev @Shreeshrii I downloaded it directly from master branch a month ago, if I type _tesseract --version_ I get
```
tesseract 3.05.00dev
leptonica-1.73
libpng 1.2.49 : libtiff 3.9.4 : zlib 1.2.3
```
I am using Oracle Linux Server release 6.8 so, unfortunately I can not use apt-get. Also tried sudo yum update and then yum install any-of-3packages , but didn't work. That is why I decided to download every dependency and install them in a common prefix. The sites where I obtained these tools are: 
http://packages.ubuntu.com/trusty/libicu-dev: icu_52.1.orig.tar.gz,
http://www.linuxfromscratch.org/blfs/view/svn/x/cairo.html: cairo-1.14.6.tar.xz, http://www.linuxfromscratch.org/blfs/view/svn/x/pango.html: pango-1.40.3.tar.xz
And all the dependencies specified in their websites.

Thank you!!
 @stweil  Actually I didn't update Tesseract, I downloaded the latest version from master a month ago and also use .autogen.sh, I will try to re build it again and will let you know if it works.

Thank you!! Please try with the following packages and their dependencies

http://packages.ubuntu.com/trusty/libicu-dev

http://packages.ubuntu.com/trusty/libpango1.0-dev

http://packages.ubuntu.com/trusty/libcairo2-dev It seems yum uses different packages and names are also different. Try pango_devel and cairo-devel @stweil I am trying to re build Tesseract, but now I am getting the following:

> ./.libs/libtesseract.so: undefined reference to `omp_get_thread_num'
> ./.libs/libtesseract.so: undefined reference to `GOMP_sections_end_nowait'
> ./.libs/libtesseract.so: undefined reference to `omp_get_num_threads'
> ./.libs/libtesseract.so: undefined reference to `GOMP_parallel_start'
> ./.libs/libtesseract.so: undefined reference to `GOMP_parallel_end'
> ./.libs/libtesseract.so: undefined reference to `GOMP_sections_next'
> ./.libs/libtesseract.so: undefined reference to `GOMP_parallel_sections_start'

I set thevariables setenv` CFLAGS /usr/include` `setenv LDFLAGS /usr/lib` and tried` setenv LDFLAGS /usr/local/lib` `setenv LDFLAGS /usr/local/lib`

**I see libgomp.so.1  libgomp.so.1.0.0** under **/usr/lib** and **/usr/lib64** 
do you have any idea of what is happening? Becuase I also have installed Leptonica, but I don´t know if I am missing something during compilation process.

Thank you !! @Shreeshrii I tried what you mentioned, using yum and downloading these packages, but still not working.
Do I have to set anything else rather than just adding the native libraries  paths to my LD_LIBRARY_PATH? Something that might cause my GCC crash because of possible missing dependencies?

I just wonder why it keeps telling me that I can not build training tools since The aoutput shows the following: 

```
checking for pango... yes
checking for cairo... yes
```
Can´t see anything releated with libicu, have also installed it.

Thanks a lot Shreeshrii! @stweil  Those messages are appearing compiling master (4.0) using gcc 4.8.4, so I compiled version 3.05 instead. Still working on building training tools. Sure @stweil !
This is the configure output with any option:

`./configure`

> checking for g++... g++
> checking for C++ compiler default output file name... a.out
> checking whether the C++ compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables... 
> checking for suffix of object files... o
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ accepts -g... yes
> fatal: Not a git repository: './.git'
> checking for a BSD-compatible install... /usr/bin/install -c
> checking whether build environment is sane... yes
> checking for a thread-safe mkdir -p... /bin/mkdir -p
> checking for gawk... gawk
> checking whether make sets $(MAKE)... yes
> checking for style of include used by make... GNU
> checking dependency style of g++... gcc3
> checking whether to enable maintainer-specific portions of Makefiles... no
> checking build system type... x86_64-unknown-linux-gnu
> checking host system type... x86_64-unknown-linux-gnu
> checking --enable-graphics argument... yes
> checking whether to disable cube... no
> checking --enable-embedded argument... no
> checking for  option to support OpenMP... -fopenmp
> checking --enable-opencl argument... no
> checking how to run the C++ preprocessor... g++ -E
> checking for grep that handles long lines and -e... /bin/grep
> checking for egrep... /bin/grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking CL/cl.h usability... no
> checking CL/cl.h presence... no
> checking for CL/cl.h... no
> checking OpenCL/cl.h usability... no
> checking OpenCL/cl.h presence... no
> checking for OpenCL/cl.h... no
> checking tiffio.h usability... yes
> checking tiffio.h presence... yes
> checking for tiffio.h... yes
> checking for clGetPlatformIDs in -lOpenCL... no
> checking --enable-visibility argument... no
> checking --enable-multiple-libraries argument... no
> checking whether to use tessdata-prefix... yes
> checking whether to enable debugging... no
> checking for gcc... gcc
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> checking dependency style of gcc... gcc3
> checking for a sed that does not truncate output... /bin/sed
> checking for fgrep... /bin/grep -F
> checking for ld used by gcc... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
> checking the name lister (/usr/bin/nm -B) interface... BSD nm
> checking whether ln -s works... yes
> checking the maximum length of command line arguments... 1966080
> checking whether the shell understands some XSI constructs... yes
> checking whether the shell understands "+="... yes
> checking for /usr/bin/ld option to reload object files... -r
> checking for objdump... objdump
> checking how to recognize dependent libraries... pass_all
> checking for ar... ar
> checking for strip... strip
> checking for ranlib... ranlib
> checking command to parse /usr/bin/nm -B output from gcc object... ok
> checking for dlfcn.h... yes
> checking whether we are using the GNU C++ compiler... (cached) yes
> checking whether g++ accepts -g... (cached) yes
> checking how to run the C++ preprocessor... g++ -E
> checking for objdir... .libs
> checking if gcc supports -fno-rtti -fno-exceptions... no
> checking for gcc option to produce PIC... -fPIC -DPIC
> checking if gcc PIC flag -fPIC -DPIC works... yes
> checking if gcc static flag -static works... yes
> checking if gcc supports -c -o file.o... yes
> checking if gcc supports -c -o file.o... (cached) yes
> checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking whether -lc should be explicitly linked in... no
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... yes
> checking for ld used by g++... /usr/bin/ld -m elf_x86_64
> checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes
> checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking for g++ option to produce PIC... -fPIC -DPIC
> checking if g++ PIC flag -fPIC -DPIC works... yes
> checking if g++ static flag -static works... yes
> checking if g++ supports -c -o file.o... yes
> checking if g++ supports -c -o file.o... (cached) yes
> checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether byte ordering is bigendian... no
> checking if compiling with clang... no
> checking whether compiler supports C++11... yes
> checking for snprintf... yes
> checking for library containing sem_init... -lpthread
> checking for ANSI C header files... (cached) yes
> checking whether time.h and sys/time.h may both be included... yes
> checking for sys/wait.h that is POSIX.1 compatible... yes
> checking sys/ipc.h usability... yes
> checking sys/ipc.h presence... yes
> checking for sys/ipc.h... yes
> checking sys/shm.h usability... yes
> checking sys/shm.h presence... yes
> checking for sys/shm.h... yes
> checking limits.h usability... yes
> checking limits.h presence... yes
> checking for limits.h... yes
> checking malloc.h usability... yes
> checking malloc.h presence... yes
> checking for malloc.h... yes
> checking for stdbool.h that conforms to C99... yes
> checking for _Bool... no
> checking whether #! works in shell scripts... yes
> checking for special C compiler options needed for large files... no
> checking for _FILE_OFFSET_BITS value needed for large files... no
> checking for getline... yes
> checking for wchar_t... yes
> checking for long long int... yes
> checking for off_t... yes
> checking for mbstate_t... yes
> checking for leptonica... yes
> checking for l_generateCIDataForPdf in -llept... yes
> checking leptonica headers version >= 1.71... yes
> checking unicode/uchar.h usability... yes
> checking unicode/uchar.h presence... yes
> checking for unicode/uchar.h... yes
> checking for pkg-config... /usr/bin/pkg-config
> checking pkg-config is at least version 0.9.0... yes
> checking for pango... yes
> checking for cairo... yes
> configure: creating ./config.status
> config.status: creating Makefile
> config.status: creating tesseract.pc
> config.status: creating api/Makefile
> config.status: creating ccmain/Makefile
> config.status: creating opencl/Makefile
> config.status: creating ccstruct/Makefile
> config.status: creating ccutil/Makefile
> config.status: creating classify/Makefile
> config.status: creating cube/Makefile
> config.status: creating cutil/Makefile
> config.status: creating dict/Makefile
> config.status: creating neural_networks/runtime/Makefile
> config.status: creating textord/Makefile
> config.status: creating viewer/Makefile
> config.status: creating wordrec/Makefile
> config.status: creating tessdata/Makefile
> config.status: creating tessdata/configs/Makefile
> config.status: creating tessdata/tessconfigs/Makefile
> config.status: creating testing/Makefile
> config.status: creating java/Makefile
> config.status: creating java/com/Makefile
> config.status: creating java/com/google/Makefile
> config.status: creating java/com/google/scrollview/Makefile
> config.status: creating java/com/google/scrollview/events/Makefile
> config.status: creating java/com/google/scrollview/ui/Makefile
> config.status: creating doc/Makefile
> config.status: creating config_auto.h
> config.status: config_auto.h is unchanged
> config.status: executing depfiles commands
> config.status: executing libtool commands
> 
> Configuration is done.
> You can now build and install tesseract by running:
> 
> $ make
> $ sudo make install
> 
> **You can not build training tools because of missing dependency.**
> Check configure output for details. Thanks @stweil 
The make output is pretty large, so it's attached at the end. 
Also, after trying 
`./configure --prefix=path --disable-openmp` 
I'm still getting the message 
"You can not build training tools because of missing dependency."

[make-output.txt](https://github.com/tesseract-ocr/tesseract/files/634989/make-output.txt)

 Sure, actually I tried with both versions, but I'am getting the same message after `./configure`.
When I do `make`:

3.05 finishes.

4.00 throws:

```
./.libs/libtesseract.so: undefined reference to `omp_get_thread_num'
./.libs/libtesseract.so: undefined reference to `GOMP_sections_end_nowait'
./.libs/libtesseract.so: undefined reference to `omp_get_num_threads'
./.libs/libtesseract.so: undefined reference to `GOMP_parallel_start'
./.libs/libtesseract.so: undefined reference to `GOMP_parallel_end'
./.libs/libtesseract.so: undefined reference to `GOMP_sections_next'
./.libs/libtesseract.so: undefined reference to `GOMP_parallel_sections_start'
```
 Thanks for your help guys, I will let you know! Hi! I am sorry for the delay.
I could build tesseract now, but still can´t build training tools, here is what I did:

I downloaded the code from master just today, after doing 
```
./autogen.sh
setenv LIBLEPT_HEADERSDIR $install/include
./configure --prefix=$install --with-extra-libraries=$install/lib --disable-openmp
```

Now I see that there are different outputs related with Leptonica and one of them is not saying yes, I wonder what does this new param says because I have installed latest Leptonica's version (1.73) under `$install`. Also In installed libicu under this location and I am seeing an issue with this either:

> checking for g++... g++
> checking for C++ compiler default output file name... a.out
> checking whether the C++ compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables... 
> checking for suffix of object files... o
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ accepts -g... yes
> fatal: Not a git repository: './.git'
> checking for a BSD-compatible install... /usr/bin/install -c
> checking whether build environment is sane... yes
> checking for a thread-safe mkdir -p... /bin/mkdir -p
> checking for gawk... gawk
> checking whether make sets $(MAKE)... yes
> checking for style of include used by make... GNU
> checking dependency style of g++... gcc3
> checking whether to enable maintainer-specific portions of Makefiles... no
> checking build system type... x86_64-unknown-linux-gnu
> checking host system type... x86_64-unknown-linux-gnu
> checking --enable-graphics argument... yes
> checking whether to disable cube... no
> checking --enable-embedded argument... no
> checking for  option to support OpenMP... -fopenmp
> checking --enable-opencl argument... no
> checking how to run the C++ preprocessor... g++ -E
> checking for grep that handles long lines and -e... /bin/grep
> checking for egrep... /bin/grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking CL/cl.h usability... no
> checking CL/cl.h presence... no
> checking for CL/cl.h... no
> checking OpenCL/cl.h usability... no
> checking OpenCL/cl.h presence... no
> checking for OpenCL/cl.h... no
> checking tiffio.h usability... yes
> checking tiffio.h presence... yes
> checking for tiffio.h... yes
> checking for clGetPlatformIDs in -lOpenCL... no
> checking --enable-visibility argument... no
> checking --enable-multiple-libraries argument... no
> checking whether to use tessdata-prefix... yes
> checking whether to enable debugging... no
> checking for gcc... gcc
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> checking dependency style of gcc... gcc3
> checking for a sed that does not truncate output... /bin/sed
> checking for fgrep... /bin/grep -F
> checking for ld used by gcc... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
> checking the name lister (/usr/bin/nm -B) interface... BSD nm
> checking whether ln -s works... yes
> checking the maximum length of command line arguments... 1572864
> checking whether the shell understands some XSI constructs... yes
> checking whether the shell understands "+="... yes
> checking for /usr/bin/ld option to reload object files... -r
> checking for objdump... objdump
> checking how to recognize dependent libraries... pass_all
> checking for ar... ar
> checking for strip... strip
> checking for ranlib... ranlib
> checking command to parse /usr/bin/nm -B output from gcc object... ok
> checking for dlfcn.h... yes
> checking whether we are using the GNU C++ compiler... (cached) yes
> checking whether g++ accepts -g... (cached) yes
> checking how to run the C++ preprocessor... g++ -E
> checking for objdir... .libs
> checking if gcc supports -fno-rtti -fno-exceptions... no
> checking for gcc option to produce PIC... -fPIC -DPIC
> checking if gcc PIC flag -fPIC -DPIC works... yes
> checking if gcc static flag -static works... yes
> checking if gcc supports -c -o file.o... yes
> checking if gcc supports -c -o file.o... (cached) yes
> checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking whether -lc should be explicitly linked in... no
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... yes
> checking for ld used by g++... /usr/bin/ld -m elf_x86_64
> checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes
> checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking for g++ option to produce PIC... -fPIC -DPIC
> checking if g++ PIC flag -fPIC -DPIC works... yes
> checking if g++ static flag -static works... yes
> checking if g++ supports -c -o file.o... yes
> checking if g++ supports -c -o file.o... (cached) yes
> checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether byte ordering is bigendian... no
> checking if compiling with clang... no
> checking whether compiler supports C++11... yes
> checking for snprintf... yes
> checking for library containing sem_init... -lpthread
> checking for ANSI C header files... (cached) yes
> checking whether time.h and sys/time.h may both be included... yes
> checking for sys/wait.h that is POSIX.1 compatible... yes
> checking sys/ipc.h usability... yes
> checking sys/ipc.h presence... yes
> checking for sys/ipc.h... yes
> checking sys/shm.h usability... yes
> checking sys/shm.h presence... yes
> checking for sys/shm.h... yes
> checking limits.h usability... yes
> checking limits.h presence... yes
> checking for limits.h... yes
> checking malloc.h usability... yes
> checking malloc.h presence... yes
> checking for malloc.h... yes
> checking for stdbool.h that conforms to C99... yes
> checking for _Bool... no
> checking whether #! works in shell scripts... yes
> checking for special C compiler options needed for large files... no
> checking for _FILE_OFFSET_BITS value needed for large files... no
> checking for getline... yes
> checking for wchar_t... yes
> checking for long long int... yes
> checking for off_t... yes
> checking for mbstate_t... yes
> checking for pkg-config... /usr/bin/pkg-config
> checking pkg-config is at least version 0.9.0... yes
> **checking for LEPTONICA... no**
> **checking for leptonica... yes**
> checking for l_generateCIDataForPdf in -llept... yes
> checking leptonica headers version >= 1.71... yes
> **checking for ICU_UC... no**
> **checking for ICU_I18N... no**
> checking unicode/uchar.h usability... yes
> checking unicode/uchar.h presence... yes
> checking for unicode/uchar.h... yes
> checking for pango... yes
> checking for cairo... yes
> configure: creating ./config.status
> config.status: creating Makefile
> config.status: creating tesseract.pc
> config.status: creating api/Makefile
> config.status: creating arch/Makefile
> config.status: creating ccmain/Makefile
> config.status: creating opencl/Makefile
> config.status: creating ccstruct/Makefile
> config.status: creating ccutil/Makefile
> config.status: creating classify/Makefile
> config.status: creating cube/Makefile
> config.status: creating cutil/Makefile
> config.status: creating dict/Makefile
> config.status: creating lstm/Makefile
> config.status: creating neural_networks/runtime/Makefile
> config.status: creating textord/Makefile
> config.status: creating viewer/Makefile
> config.status: creating wordrec/Makefile
> config.status: creating tessdata/Makefile
> config.status: creating tessdata/configs/Makefile
> config.status: creating tessdata/tessconfigs/Makefile
> config.status: creating testing/Makefile
> config.status: creating java/Makefile
> config.status: creating java/com/Makefile
> config.status: creating java/com/google/Makefile
> config.status: creating java/com/google/scrollview/Makefile
> config.status: creating java/com/google/scrollview/events/Makefile
> config.status: creating java/com/google/scrollview/ui/Makefile
> config.status: creating doc/Makefile
> config.status: creating config_auto.h
> config.status: executing depfiles commands
> config.status: executing libtool commands
> 
> Configuration is done.
> You can now build and install tesseract by running:
> 
> $ make
> $ sudo make install
> 
> **You can not build training tools because of missing dependency.**
> Check configure output for details.
 
I can execute
```
make 
make install 
```
without any problem so I guess 6140be6 fixed it but still can not build training tools.

Here is what I have under `$install` :
**lib**
liblept.a  liblept.la  liblept.so  liblept.so.1  liblept.so.1.73  liblept.so.5  liblept.so.5.0.0  libtesseract.a  libtesseract.la  libtesseract.so  libtesseract.so.4  libtesseract.so.4.0.0  modules  pkgconfig  terminfo

**include** 
leptonica  tesseract

**bin**
bash  convertfilestopdf  convertfilestops  convertformat  convertsegfilestopdf  convertsegfilestops  converttopdf  converttops  fileinfo  printimage  printsplitimage  printtiff  sh  splitimage2pdf  tesseract  xtractprotos

I am also adding `$install/lib` to my` $LD_LIBRARY_PATH` and `$install/bin` to my `$PATH` before building Tesseract.

Thank you!


 >checking for LEPTONICA... no
>checking for leptonica... yes

That's funny! Alright. 
Now, before running ./configure... I did:

`setenv PKG_CONFIG_PATH $install/usr/lib64/pkgconfig:$install/lib/pkgconfig`

Because this is where I also installed libicu-dev. Here is the configure output:

> checking for g++... g++
> checking for C++ compiler default output file name... a.out
> checking whether the C++ compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables... 
> checking for suffix of object files... o
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ accepts -g... yes
> fatal: Not a git repository: './.git'
> checking for a BSD-compatible install... /usr/bin/install -c
> checking whether build environment is sane... yes
> checking for a thread-safe mkdir -p... /bin/mkdir -p
> checking for gawk... gawk
> checking whether make sets $(MAKE)... yes
> checking for style of include used by make... GNU
> checking dependency style of g++... gcc3
> checking whether to enable maintainer-specific portions of Makefiles... no
> checking build system type... x86_64-unknown-linux-gnu
> checking host system type... x86_64-unknown-linux-gnu
> checking --enable-graphics argument... yes
> checking whether to disable cube... no
> checking --enable-embedded argument... no
> checking --enable-opencl argument... no
> checking how to run the C++ preprocessor... g++ -E
> checking for grep that handles long lines and -e... /bin/grep
> checking for egrep... /bin/grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking CL/cl.h usability... no
> checking CL/cl.h presence... no
> checking for CL/cl.h... no
> checking OpenCL/cl.h usability... no
> checking OpenCL/cl.h presence... no
> checking for OpenCL/cl.h... no
> checking tiffio.h usability... yes
> checking tiffio.h presence... yes
> checking for tiffio.h... yes
> checking for clGetPlatformIDs in -lOpenCL... no
> checking --enable-visibility argument... no
> checking --enable-multiple-libraries argument... no
> checking whether to use tessdata-prefix... yes
> checking whether to enable debugging... no
> checking for gcc... gcc
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> checking dependency style of gcc... gcc3
> checking for a sed that does not truncate output... /bin/sed
> checking for fgrep... /bin/grep -F
> checking for ld used by gcc... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
> checking the name lister (/usr/bin/nm -B) interface... BSD nm
> checking whether ln -s works... yes
> checking the maximum length of command line arguments... 1572864
> checking whether the shell understands some XSI constructs... yes
> checking whether the shell understands "+="... yes
> checking for /usr/bin/ld option to reload object files... -r
> checking for objdump... objdump
> checking how to recognize dependent libraries... pass_all
> checking for ar... ar
> checking for strip... strip
> checking for ranlib... ranlib
> checking command to parse /usr/bin/nm -B output from gcc object... ok
> checking for dlfcn.h... yes
> checking whether we are using the GNU C++ compiler... (cached) yes
> checking whether g++ accepts -g... (cached) yes
> checking how to run the C++ preprocessor... g++ -E
> checking for objdir... .libs
> checking if gcc supports -fno-rtti -fno-exceptions... no
> checking for gcc option to produce PIC... -fPIC -DPIC
> checking if gcc PIC flag -fPIC -DPIC works... yes
> checking if gcc static flag -static works... yes
> checking if gcc supports -c -o file.o... yes
> checking if gcc supports -c -o file.o... (cached) yes
> checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking whether -lc should be explicitly linked in... no
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... yes
> checking for ld used by g++... /usr/bin/ld -m elf_x86_64
> checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes
> checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking for g++ option to produce PIC... -fPIC -DPIC
> checking if g++ PIC flag -fPIC -DPIC works... yes
> checking if g++ static flag -static works... yes
> checking if g++ supports -c -o file.o... yes
> checking if g++ supports -c -o file.o... (cached) yes
> checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether byte ordering is bigendian... no
> checking if compiling with clang... no
> checking whether compiler supports C++11... yes
> checking for snprintf... yes
> checking for library containing sem_init... -lpthread
> checking for ANSI C header files... (cached) yes
> checking whether time.h and sys/time.h may both be included... yes
> checking for sys/wait.h that is POSIX.1 compatible... yes
> checking sys/ipc.h usability... yes
> checking sys/ipc.h presence... yes
> checking for sys/ipc.h... yes
> checking sys/shm.h usability... yes
> checking sys/shm.h presence... yes
> checking for sys/shm.h... yes
> checking limits.h usability... yes
> checking limits.h presence... yes
> checking for limits.h... yes
> checking malloc.h usability... yes
> checking malloc.h presence... yes
> checking for malloc.h... yes
> checking for stdbool.h that conforms to C99... yes
> checking for _Bool... no
> checking whether #! works in shell scripts... yes
> checking for special C compiler options needed for large files... no
> checking for _FILE_OFFSET_BITS value needed for large files... no
> checking for getline... yes
> checking for wchar_t... yes
> checking for long long int... yes
> checking for off_t... yes
> checking for mbstate_t... yes
> checking for pkg-config... /usr/bin/pkg-config
> checking pkg-config is at least version 0.9.0... yes
> **checking for LEPTONICA... yes**
> checking for l_generateCIDataForPdf in -llept... yes
> **checking leptonica headers version >= 1.71... yes**
> **checking for ICU_UC... yes**
> **checking for ICU_I18N... yes**
> **checking for pango... yes**
> **checking for cairo... yes**
> configure: creating ./config.status
> config.status: creating Makefile
> config.status: creating tesseract.pc
> config.status: creating api/Makefile
> config.status: creating arch/Makefile
> config.status: creating ccmain/Makefile
> config.status: creating opencl/Makefile
> config.status: creating ccstruct/Makefile
> config.status: creating ccutil/Makefile
> config.status: creating classify/Makefile
> config.status: creating cube/Makefile
> config.status: creating cutil/Makefile
> config.status: creating dict/Makefile
> config.status: creating lstm/Makefile
> config.status: creating neural_networks/runtime/Makefile
> config.status: creating textord/Makefile
> config.status: creating viewer/Makefile
> config.status: creating wordrec/Makefile
> config.status: creating tessdata/Makefile
> config.status: creating tessdata/configs/Makefile
> config.status: creating tessdata/tessconfigs/Makefile
> config.status: creating testing/Makefile
> config.status: creating java/Makefile
> config.status: creating java/com/Makefile
> config.status: creating java/com/google/Makefile
> config.status: creating java/com/google/scrollview/Makefile
> config.status: creating java/com/google/scrollview/events/Makefile
> config.status: creating java/com/google/scrollview/ui/Makefile
> config.status: creating doc/Makefile
> config.status: creating config_auto.h
> config.status: executing depfiles commands
> config.status: executing libtool commands
> 
> Configuration is done.
> You can now build and install tesseract by running:
> 
> $ make
> $ sudo make install
> 
> **You can not build training tools because of missing dependency.**
> Check configure output for details.

Now, after this check it seems that I have all the dependencies, but still can't go to the training tools building process. :s




 Hi guys.
Thank you very much for your help.
I could now build training tools using master (Tesseract 4.0).

I be able to build them I had **to remove all the lines** `AM_CONDITIONAL([ENABLE_TRAINING], false)`   in **configure.ac**, to be specific, they were 4.

After that, then trying to build training tools I saw an error related with libicu, basically the compiler was not finding some .h files. As I have libicu installed under $install and I also added $install/lib to $LD_LIBRARY_PATH, $install/bin to $PATH and also set $PKG_CONFIG_PATH=$install/usr/lib64/pkgconfig:$install/lib/pkgconfig I guess there was some other configuration to tell GCC where to look for the include files, but I could not find it, so to solve this I had to **copy all the files under `$install/include/unicode` to `/usr/include/unicode` so GCC could find these files**.  Do you have any suggestion when this happens to tell GCC specifically where to look for the .h files? (a non standard "include" directory) I think there should be another way so I don't really need to copy the include files to the standard location.

I have one final question: Do you guys know where can I ask questions to Leptonica's team? They have a mailing list in Google Code, but it seems that we can not open any other issue.

Once again, thanks for your help on this! I think that the pango-devel and cairo-devel in RHEL/Centos 6 would work with Tesseract 4. >I have one final question: Do you guys know where can I ask questions to Leptonica's team? They have a mailing list in Google Code, but it seems that we can not open any other issue.

(I)
https://github.com/DanBloomberg/leptonica/issues

(II)
From http://leptonica.org/

>Contact: Dan Bloomberg (bloomberg "at" ieee "dot" org) for questions and suggestions
 Can we close this issue? I am sorry! 
Sure, now you can close this issue.

Once again, thank you for helping me to solve this.
I am now running training tools on Oracle Linux Server 6.8 successfully.

Merry Christmas and happy new year!  While using png files as input and using oem 4 - LSTM, tesseract gives warnings on console in command mode. oem 0, 1, 2 and 3 gives no warnings.

On Windows 10, using 4.0 Alpha binaries provided by @stweil  and 4.0 alpha traineddata 

>>tesseract hin001.png hin001-hin-3 -oem 3 -l hin
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica

>>tesseract hin001.png hin001-hin-4 -oem 4 -l hin
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
...

The warnings seem to be given per line, so a page with 20 lines of text gets about 40 lines of messages.

I have not tested this in the linux environment. The warnings are probably from leptonica.
 There are a large number of warning messages when using -oem 4, not with other oem modes.

Is there a way to eliminate these? 

C:\shree>tesseract san001.png san001 -oem 4 -l san
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
Detected 18 diacritics
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file
Warning in pixWriteMemPng: work-around: writing to a temp file
Warning in fopenReadFromMemory: work-around: writing to a temp file



![san001](https://cloud.githubusercontent.com/assets/5095331/20835038/62d4e128-b8be-11e6-8d49-4ee9f2077b47.png) The warnings are indeed from Leptonica. They will not appear in Linux. You should ignore these ugly warnings.

>Is there a way to eliminate these?

https://github.com/tesseract-ocr/tesseract/issues/292#issuecomment-222529057 Warnings are not limited to png, same for tif, gif and jpg. @zdenop @amitdo Thanks!

@stweil Is the version of leptonica included with the windows binaries a debug version? >Warnings are not limited to png, same for tif, gif and jpg.

Still same answer...

It not a bug, although from an end user point of view it sure looks confusing. ++ dan.bloomberg@gmail.com
@DanBloomberg

cc:ing Dan Bloomberg for his input regarding Leptonica

On Fri, Dec 2, 2016 at 7:12 PM, Stefan Weil <notifications@github.com>
wrote:

> The warnings are an indicator for potential optimizations and require more
> examination by developers, so I see there an issue to be discussed here.
>
> AFAIK Leptonica warns when an image file is going to be mapped to memory,
> something that is unsupported for Leptonica's Windows code which uses a
> temporary file copy as an alternative.
>
> If OCR of a single image results in many (number of lines) of those
> warnings, that might be caused by the same image being opened very often,
> or Tesseract acts on in-memory line images, but Leptonica for Windows has
> to write those images to disk. Then it is clear that at least for Windows
> the performance suffers and something should be done - either in Leptonica
> code or in Tesseract.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/522#issuecomment-264456364>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o78_PkgYGsXTyk4uL6PqJdNjEorFks5rECBXgaJpZM4LCeas>
> .
>
 @stweil
https://github.com/tesseract-ocr/tesseract/issues/292#issuecomment-222529057
How did you compile Leptonica? http://www.leptonica.org/source/README.html

>4. Compile-time control over stderr output (see environ.h)
>
>   Leptonica provides both compile-time and run-time control over
   messages and debug output (thanks to Dave Bryan).  Both compile-time
   and run-time severity thresholds can be set.  The run-time threshold
   can also be set by an environmental variable.  Messages are
   vararg-formatted and of 3 types: error, warning, informational.
   These are all macros, and can be further suppressed when
   NO_CONSOLE_IO is defined on the compile line.  For production code
   where no output is to go to stderr, compile with -DNO_CONSOLE_IO.
 https://github.com/DanBloomberg/leptonica/blob/7e0191abd/src/environ.h#L290 It's not a bug, but I agree that there is a place for improvements. In production, there should be no need to see any leptonica output (info, warnings, errors) to stderr.
Methods for suppressing them are described above by Amit.
These messages are arguably INFO rather than WARNING.

Reads and writes from/to file for in-memory I/O on Windows are no longer required for gif and tiff formats. They were never required for webp.  They are still required for jpeg, jp2k and png. Dan,

Thanks for the info.

>Reads and writes from/to file for in-memory I/O on Windows are no longer required for gif and tiff formats.

Since which version?

The solution to the optimization problem might be in this specific case to always save the textlines images to tiff in memory. Amit,

1.73 required r/w for in-memory I/O for gif and tiff on Windows. The current github master (and soon to be release 1.74.0) does not.  The tiff patch was contributed by Stefan.

Yes, any 1 bpp images (e.g., in tesseract/viewer and ccstruct) can be output in IFF_TIFF_G4, which typically has better compression than png.  Grayscale and color can be output in TIFF_ZIP or TIFF_LZW, which are typically inferior to png in compression. Stefan, we can downgrade those messages in leptonica to INFO, and you can use setMsgSeverity() to disable INFO statements. Nevertheless, this seems like a reasonable thing to do to solve this annoyance and still present other WARNING messages.
 Annoying messages have now been downgraded to INFO at github head.

You can use this in tesseract code to suppress all INFO and less urgent messages at run time:
     setMsgSeverity(L_SEVERITY_WARNING);

Alternatively, for a bit more flexibility, you can define the environmental variable
 #define  LEPT_MSG_SEVERITY   L_SEVERITY_WARNING
and use
     setMsgSeverity(L_SEVERITY_EXTERNAL);

You can also change the severity level to WARNING and higher at compile time with this compiler flag:
    -DDEFAULT_SEVERITY=4
This can be over-ridden at run time with either of the first two methods.
 >Reads and writes from/to file for in-memory I/O on Windows are no longer required for gif and tiff formats.

I wonder how giflib and libiff do the equivalence of fmemopen on Windows.
 @zdenop  That's an interesting idea.  Default setting is for INFO, WARNING and ERROR, but for a release that will be used in production it makes sense to only show ERROR. @amitdo 

Look at the leptonica wrappers for tiff (tiffio.c) and gif (gifio.c) to see how it is done.

Even better, the webp library implements compression and decompression directly with memory buffers, not with file streams. This is very nice, because it's platform independent, and you can easily read and write to files using it (see webpio.c). I wish the other image compression libraries had been implemented that way, but ...  "NOTE that if you are creating a totally new language, for which there is no existing traineddata file, **Tesseract will currently refuse to initialize with just the lstm model in it,** even if you use OEM_LSTM_ONLY as the OCR engine mode. For now, you can make it run using any existing traineddata file and adding your new lstm model and (optionally) the lstm dawgs. 

This is a point for improvement in the future. The unicharset used for the lstm has to match the unicharset used to generate the lstm-*-dawg files, but doesn't have to match the unicharset for the inttemp and base tesseract dawg files."

From: https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#combining-the-output-files @theraysmith, any chance you'll fix that for the final 4.00 release? @theraysmith, can you confirm that 5deebe6c2 solved this issue? @theraysmith

Ray, I am not able to try out LSTM training as repo is missing LSTM.train
config file. Are there other pieces also that you need to add?

On 06-Dec-2016 8:59 PM, "theraysmith" <notifications@github.com> wrote:

> Partly. I haven't closed it because you can't *create* a traineddata file
> with just the LSTM part(s) yet, and I am working on fixing that as well.
>
> On Tue, Dec 6, 2016 at 1:42 AM, Amit D. <notifications@github.com> wrote:
>
> > @theraysmith <https://github.com/theraysmith>, can you confirm that
> > 5deebe6
> > <https://github.com/tesseract-ocr/tesseract/commit/
> 5deebe6c279f70215935c1f86baa7e7016c7f2a7>
> > solved this issue?
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/521#
> issuecomment-265104978>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AL056XMVGWYPqK1Pc8XzqTxrzYjHZxgZks5rFS4MgaJpZM4LCRAs>
> > .
> >
>
>
>
> --
> Ray.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/521#issuecomment-265179343>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o3NKfgM6IGnUvuVAqYrFirHq_0FMks5rFX9IgaJpZM4LCRAs>
> .
>
 @theraysmith Thanks, Ray. I will try the tutorial again now. @theraysmith Looks like some files maybe missing from langdata repo also since that was not updated for 4.0alpha. e.g. 

Failed to load radical-stroke info from: ../langdata/radical-stroke.txt msg in basetrain.log

May I also suggest that you update the alpha version in https://github.com/tesseract-ocr/tesseract/blob/master/api/baseapi.h with either git revision of just a numerical number so that it is easy to verify the version of program being used. Thanks.
 

 >@theraysmith, can you confirm that 5deebe6 solved this issue?

>Partly. I haven't closed it because you can't *create* a traineddata file
with just the LSTM part(s) yet, and I am working on fixing that as well.

It looks like 13e46ae1c solved this issue.  https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00#for-open-source-contributors

>The swaps are missing from the (De)Serialize methods of the new neural network code. Ray, you can see online Stefan's suggested changes [here](https://github.com/stweil/tesseract/commits/endian). Protocol Buffers uses Stefan's approach:
https://groups.google.com/forum/#!topic/protobuf/XbzBwCj4yL8 True. I mentioned PB because it is written by Google and they use it extensively.  >Microsoft and Torvalds have almost entirely killed off big endian machines
by now.

Another victim is IBM POWER.
 
https://www.ibm.com/developerworks/community/blogs/fe313521-2e95-46f2-817d-44a4f27eba32/entry/just_the_faqs_about_little_endian?lang=en

>Why is Linux on Power transitioning from big endian to little endian?
>
>The Power architecture is bi-endian in that it supports accessing data in both little endian and big endian modes. Although Power already has Linux distributions and supporting applications that run in big endian mode, the Linux application ecosystem for x86 platforms is much larger and Linux on x86 uses little endian mode.  Numerous clients, software partners, and IBM’s own software developers have told us that porting their software to Power becomes simpler if the Linux environment on Power supports little endian mode, more closely matching the environment provided by Linux on x86.  This new level of support will lower the barrier to entry for porting Linux on x86 software to Linux on Power.

 You can use QEMU for testing.
https://qemu.weilnetz.de/doc/qemu-doc.html#QEMU-System-emulator-for-non-PC-targets  He did provide a link for 'convert2le' (`convert2le` was clickable). Here is the link in a more visable form:
https://github.com/stweil/tesseract/blob/endian/ccutil/tessio.h#L15
A link to tessio.cpp:
https://github.com/stweil/tesseract/blob/endian/ccutil/tessio.cpp Little-endian is an abomination. It hurts the brain if you haven't grown up with it (like apparently in Arabic, which still pronounces numbers big to little except for units before tens). UTF-8 is necessarily big-endian by design so that lexicographical order is the same whether processing considers bytes (fast, using memcmp) or code points (slow). Packed bitmap representations like BMP and PNG (I only verified those) store the leftmost pixel in the most significant bits of a byte, so loading a range of pixels in a 64-bit integer, shifting them inside the processor, and writing them back only makes sense if integers are big-endian. Intelligent future civilisations are bound to reconsider the current accidental infatuation with little-endian, and will curse their predecessors for having to modify all those inflexible formats and software.

With C++, byte order or pre-evaluated need to reverse order ("bool swap") can easily be hidden in a file object member variable: it does not have to be passed around as a function argument, if that is considered too cumbersome. Has anybody even made a performance analysis before just postulating that little-endian is necessary for optimal or near-optimal performance on little-endian machines, considering that relatively little time is spent on I/O and that data files will also tend to be little-endian? I've had a look at stweil's proposal (endian branch), and I'm "not sure" that it will work... unless on a big-endian machine the file is saved twice, or read in again, perhaps because serialisation was the last thing the program did before it was restarted, or otherwise explicitly. The problem seems to be that the byte order is reversed in place, for serialisation as well as deserialisation. If you want to use a fixed endianness, you have to use a separate buffer, or do one of the workarounds described above. And that's if you're sure that each data item is visited exactly once, otherwise the reversal has to occur inside the lowest-level serialisation functions!

I would propose a different solution, where serialisation and deserialisation are unified into a single method, and instead of a FILE pointer you get a handle to an object that can do anything you want. This could easily simplify the existing code, without breaking compatibility with existing data files.

Another thing is to hide endianness handling in a library that can be reused and is maintained by people who do care about this issue. For example, a 64-bit swap in source code is either recognised by the compiler and optimised into a single instruction, or there is a better alternative with fewer operations. It would also be possible to use vector instructions to convert endianness. Well, it works as far as it was implemented and tested. Writing little endian trained data on a big endian host was not implemented. All other use cases (reading little endian on a little or big endian host, writing little endian on a little endian host) work according to my tests.

Nevertheless pull request #703 is obsolete, as Ray is currently working on improving endianness support. I would use a subset of boost serialisation: just one serialize() method template exactly as specified in boost (instead of largely redundant separate code for writing and reading), and minimal format-compatible ad-hoc Archive implementations without creating any dependency on boost itself or not yet anyway, except for reusing the idea. You can then hide the endianness policy in the Archive implementation: write host endianness (as it is now), write fixed endianness (as proposed above), write configured endianness (host endianness by default, unless perhaps publishing for reuse, or a default the other way around), write JSON, ... Better than reinventing the wheel with probably more code!

(2017-05-02 Added) Maybe it's a bit late for exactly that, I don't know... But if you want to use TFile, you should also have it do all the endianness handling, so it's never forgotten. If somebody else weren't already on it, I'd give that a try myself. Ray, the new code still uses a dynamic detection in `TessdataManager::LoadMemBuffer` to decide whether swapping is needed or not. This implies that the code supports both big and little endian data files. The drawback is additional runtime code on all kinds of machines.

Are you planning more changes? I'd drop support of big endian data files in 4.0 and add code to always write little endian ones. Then static swapping code would only be needed on big endian machines, and the large majority of machines would not need any swap code at all.
  This restores classify/adaptmatch.cpp to commit 1e60a8d71c591ab9562983778d6ce2541b75abc0
(+ two deleted empty lines).

Signed-off-by: Stefan Weil <sw@weilnetz.de>  Signed-off-by: Stefan Weil sw@weilnetz.de  Signed-off-by: Stefan Weil <sw@weilnetz.de> That's a different function which either gets called with `&recoder_` or with `NULL` as value for parameter `recoder`. It is unrelated to my modification. My point is that recoder may be NULL and you should use a pointer instead of a reference. I don't think so. The old code passed an `UnicharCompress` object. Passing a reference is the optimized equivalent. How would you assign a NULL pointer to a `UnicharCompress` object (not a pointer) as it is done in the function? I will recheck it after a good sleep :) Stefan,
I tried to examine the call hierarchy, but I didn't find a call to this variant of `InitCharSet` overloaded method. Your analysis is correct: one of the `InitCharSet` methods is unused and can be removed.

@theraysmith, are there plans to use that interface in the future, or can `void InitCharSet(const UNICHARSET& unicharset, const UnicharCompress recoder)` be removed?

@zdenop, I think this PR can be applied anyway – we can also remove a fixed method in a later PR.
 TIP: You can also close the PR and reopen it and the CI builds will rerun. You are right :)   See also the discussion for PR #177. I start with `opencl` because the risk of conflicts with other code changes is low.  Vcpkg is a tool to acquire and build C++ open source libraries on Windows:
https://blogs.msdn.microsoft.com/vcblog/2016/09/19/vcpkg-a-tool-to-acquire-and-build-c-open-source-libraries-on-windows/

Provide a vcpkg port for tesseract would be very convenience. Egor,
It you would like to add support for Leptonica and Tesseract to the Microsoft vcpkg ports collection:
https://github.com/Microsoft/vcpkg/blob/master/CONTRIBUTING.md

 @sdcb
You might want to add a request to add Tesseract:
https://github.com/Microsoft/vcpkg/issues?q=is%3Aissue+label%3A%22new+port+request%22+is%3Aopen @zdenop, please close this issue. https://github.com/Microsoft/vcpkg/tree/master/ports/tesseract  `_mm256_extract_epi64` isn't declared for 32-bit.

```
$ ../configure --host=i686-w64-mingw32 --build=i686-w64-mingw32 --target=i686-w64-mingw32 --prefix=/local32 --disable-shared --enable-static --bindir=/local32/bin-global --disable-graphics
$ make
make  all-recursive
make[1]: Entering directory '/build/tesseract-git/build-32bit'
Making all in arch
make[2]: Entering directory '/build/tesseract-git/build-32bit/arch'
make[3]: Entering directory '/build/tesseract-git/build-32bit/arch'
/bin/sh ../libtool  --tag=CXX   --mode=compile i686-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I../../arch -I..  -O2 -DNDEBUG -I../../ccutil  -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/local32/include/leptonica -mavx -mthreads -mtune=generic -O2 -pipe -std=c++11 -MT libtesseract_avx_la-dotproductavx.lo -MD -MP -MF .deps/libtesseract_avx_la-dotproductavx.Tpo -c -o libtesseract_avx_la-dotproductavx.lo `test -f 'dotproductavx.cpp' || echo '../../arch/'`dotproductavx.cpp
/bin/sh ../libtool  --tag=CXX   --mode=compile i686-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I../../arch -I..  -O2 -DNDEBUG -I../../ccutil  -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/local32/include/leptonica -msse4.1 -mthreads -mtune=generic -O2 -pipe -std=c++11 -MT libtesseract_sse_la-dotproductsse.lo -MD -MP -MF .deps/libtesseract_sse_la-dotproductsse.Tpo -c -o libtesseract_sse_la-dotproductsse.lo `test -f 'dotproductsse.cpp' || echo '../../arch/'`dotproductsse.cpp
libtool: compile:  i686-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I../../arch -I.. -O2 -DNDEBUG -I../../ccutil -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/local32/include/leptonica -mavx -mthreads -mtune=generic -O2 -pipe -std=c++11 -MT libtesseract_avx_la-dotproductavx.lo -MD -MP -MF .deps/libtesseract_avx_la-dotproductavx.Tpo -c ../../arch/dotproductavx.cpp -o libtesseract_avx_la-dotproductavx.o
libtool: compile:  i686-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I../../arch -I.. -O2 -DNDEBUG -I../../ccutil -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/local32/include/leptonica -msse4.1 -mthreads -mtune=generic -O2 -pipe -std=c++11 -MT libtesseract_sse_la-dotproductsse.lo -MD -MP -MF .deps/libtesseract_sse_la-dotproductsse.Tpo -c ../../arch/dotproductsse.cpp -o libtesseract_sse_la-dotproductsse.o
../../arch/dotproductavx.cpp: In function 'double tesseract::DotProductAVX(const double*, const double*, int)':
../../arch/dotproductavx.cpp:93:55: error: '_mm256_extract_epi64' was not declared in this scope
       _mm256_extract_epi64(_mm256_castpd_si256(sum), 0);
                                                       ^
mv -f .deps/libtesseract_sse_la-dotproductsse.Tpo .deps/libtesseract_sse_la-dotproductsse.Plo
make[3]: *** [Makefile:542: libtesseract_avx_la-dotproductavx.lo] Error 1
make[3]: *** Waiting for unfinished jobs....
make[3]: Leaving directory '/build/tesseract-git/build-32bit/arch'
make[2]: *** [Makefile:589: all-recursive] Error 1
make[2]: Leaving directory '/build/tesseract-git/build-32bit/arch'
make[1]: *** [Makefile:484: all-recursive] Error 1
make[1]: Leaving directory '/build/tesseract-git/build-32bit'
make: *** [Makefile:393: all] Error 2
``` With `#if !defined(__WIN64__) || !defined(__AVX__)` in dotproductavx.cpp:19 it ultimately fails again due to missing references to ScrollView which is missing due to --disable-graphics:
```
Making all in api
make[2]: Entering directory '/trunk/build/tesseract-git/build-32bit/api'
/bin/sh ../libtool  --tag=CXX   --mode=link i686-w64-mingw32-g++  -mthreads -mtune=generic -O2 -pipe -std=c++11  -pipe -static-libgcc -static-libstdc++ -o tesseract.exe tesseract-tesseractmain.o libtesseract.la  -lws2_32  -llept -LD:/ab-full/local32/lib -LD:/ab-full/msys64/mingw32/lib -llept -lz -lpng -ljpeg -ltiff -llzma -ljpeg -lz
libtool: link: i686-w64-mingw32-g++ -mthreads -mtune=generic -O2 -pipe -std=c++11 -pipe -static-libgcc -static-libstdc++ -o tesseract.exe tesseract-tesseractmain.o  ./.libs/libtesseract.a -L/local32/lib -lws2_32 -LD:/ab-full/local32/lib -LD:/ab-full/msys64/mingw32/lib /local32/lib/liblept.a -lgdi32 -lpng -ltiff -llzma -ljpeg -lz -fopenmp -mthreads
./.libs/libtesseract.a(network.o):network.cpp:(.text+0xa52): undefined reference to `ScrollView::ScrollView(char const*, int, int, int, int, int, int, bool)'
./.libs/libtesseract.a(network.o):network.cpp:(.text+0xaee): undefined reference to `ScrollView::Image(Pix*, int, int)'
./.libs/libtesseract.a(network.o):network.cpp:(.text+0xb6f): undefined reference to `ScrollView::Update()'
./.libs/libtesseract.a(network.o):network.cpp:(.text+0xc14): undefined reference to `ScrollView::Update()'
./.libs/libtesseract.a(network.o):network.cpp:(.text+0x9dc): undefined reference to `ScrollView::Clear()'
./.libs/libtesseract.a(imagedata.o):imagedata.cpp:(.text+0x1626): undefined reference to `SVSync::StartThread(void* (*)(void*), void*)'
collect2.exe: error: ld returned 1 exit status
make[2]: *** [Makefile:606: tesseract.exe] Error 1
make[2]: Leaving directory '/trunk/build/tesseract-git/build-32bit/api'
make[1]: *** [Makefile:487: all-recursive] Error 1
make[1]: Leaving directory '/trunk/build/tesseract-git/build-32bit'
make: *** [Makefile:396: all] Error 2
``` A message for users:
https://groups.google.com/forum/#!topic/tesseract-ocr/e__2DN1GQb0

See also:
https://github.com/tesseract-ocr/tesseract/wiki/4.0-with-LSTM#40
https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00#for-open-source-contributors

@zdenop, you might want to add some message about the current status of master in the beginning of the README. Zdenko,

Sorry about the duplicate, I didn't see your reply to the OP. Using an ifdef to check for WIN64 fixes the missing _mm256_extract_epi64, the other one is the code in network.cpp and imagedata.cpp assuming people don't use --disable-graphics, afaik? No idea how to fix that so I'll just checkout a working commit.  I have a unit test that uses this french text:

![example](http://ocrapiservice.com/static/images/examples/french_text.png)

When I OCR this with english training data I get:

```
La fonction du langage, dit—on, est d'exprimer la pensée en la manifestant exterieurement. ll faut
pourtant apporter a cette formule une precision importante, et meme en souligner l'insuffisance. En
effet la pensée doit ici étre entendue au sens conceptuel, voire rationnel : l'experience a montré que
les singes anthropo'I'des peuvent acceder a une expression symbolique abstraite (utilisation de la
langue des signes des personnes sourdes, manipulation de symboles abstraits), mais il n'a jamais pu
étre etabli qu'un animal non humain soit capable d'exprimer une idee, ni meme un concept. En
d'autres termes, certains animaux sont capables d'exprimer leurs besoins (la faim, la soif), leurs
emotions (desirs ou craintes, tristesse ou joie...), mais aucun ne semble capable de porter un
jugement liant des concepts, a l'exception de notre espece. Cette precision rejoint la remarque deja
formulee par des philosophes. Par exemple, remarque Aristote, les autres animaux peuvent exprimer
le plaisir ou la douleur, qui sont des sensations, non le juste et l'injuste, qui sont des idees (et c'est
pourquoi l'Homme, et l'Homme seulement, est « un animal politique »). Selon Descartes, seul le
langage (sous la forme de paroles articulees ou de tout autre systeme de signes equivalent) est
capable de formuler des idees et de les communiquer a d'autres.
```

Using the french training data it gives:
```
La fonction du langage, dit—on, est d'exprimer la pensée en la manifestant extérieurement. Il faut
pourtant apporter � cette formule une précision importante, et même en souligner l'insuffisance. En
effet la pensée doit ici être entendue au sens conceptuel, voire rationnel : l‘expérience a montré que
les singes anthropoïdes peuvent accéder a une expression symbolique abstraite (utilisation de la
langue des signes des personnes sourdes, manipulation de symboles abstraits), mais il n'a jamais pu
être établi qu'un animal non humain soit capable d'exprimer une idée, ni même un concept. En
d'autres termes, certains animaux sont capables d'exprimer leurs besoins (la faim, la soif), leurs
émotions (désirs ou craintes, tristesse ou joie…), mais aucun ne semble capable de porter un
jugement liant des concepts, � l'exception de notre espèce. Cette précision rejoint la remarque déj�
formulée par des philosophes. Par exemple, remarque Aristote, les autres animaux peuvent exprimer
le plaisir ou la douleur, qui sont des sensations, non le juste et l‘injuste, qui sont des idées (et c‘est
pourquoi l'Homme, et l‘Homme seulement, est « un animal politique »). Selon Descartes, seul le
langage (sous la forme de paroles articulées ou de tout autre système de signes équivalent) est
capable de formuler des idées et de les communiquer � d‘autres.
```

For some reason the ` «` and `»` characters are unrecognized in French.  I'am trying to use text2image to create my  XXX.tif file and XXX.box file.
I found that only If all the characters can be rendered ,the text2image works fine.
It will broken when some characters can NOT be renderd with some fonts (the chinese fonts file usually  would NOT contain all the characters of chinese)

Is there a method to skip the character which could not be  rendered?(for example: use '  ' instead of the characters or just skip them)

thank you ! Text2image has the option to use only renderable characters. Please check
help for syntax

text2image --help

On 22-Nov-2016 2:01 PM, "albertyou2" notifications@github.com wrote:

> I'am trying to use text2image to create my XXX.tif file and XXX.box file.
> I found that only If all the characters can be rendered ,the text2image
> works fine.
> It will broken when some characters can NOT be renderd with some fonts
> (the chinese fonts file usually would NOT contain all the characters of
> chinese)
> 
> Is there a method to skip the character which could not be rendered?(for
> example: use ' ' instead of the characters or just skip them)
> 
> thank you !
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/490, or mute the
> thread
> https://github.com/notifications/unsubscribe-auth/AE2_o6U-elwAxcbzA8fZR3Y0HHe13XS3ks5rAqhXgaJpZM4K5IUb
> .
 --strip_unrenderable_words

On 22-Nov-2016 2:01 PM, "albertyou2" notifications@github.com wrote:

> I'am trying to use text2image to create my XXX.tif file and XXX.box file.
> I found that only If all the characters can be rendered ,the text2image
> works fine.
> It will broken when some characters can NOT be renderd with some fonts
> (the chinese fonts file usually would NOT contain all the characters of
> chinese)
> 
> Is there a method to skip the character which could not be rendered?(for
> example: use ' ' instead of the characters or just skip them)
> 
> thank you !
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/490, or mute the
> thread
> https://github.com/notifications/unsubscribe-auth/AE2_o6U-elwAxcbzA8fZR3Y0HHe13XS3ks5rAqhXgaJpZM4K5IUb
> .
 @Shreeshrii 
YES it works! thank you  @Shreeshrii Sorry ,I met a anther error :
 cluster text.size() == start_byte_to_box.size():error
have you seen it before?  Hi, I'm trying to work with the newly updated LSTM tesseract.

Tesseract gives me this error when I try
```sh
$ tesseract image.jpg out -oem 4

Error: LSTM requested, but not present!! Loading tesseract.
```

It seems like I don't have the tessdata for LSTM.

Where can I get it? The LSTM traineddata files aren't available yet. Thanks for your replies! The LSTM traineddata files are available now.
https://github.com/tesseract-ocr/tessdata Thank you! I'll try it out  I suggest to add spaces in the title of the wiki pages, e.g. the newly created page https://github.com/tesseract-ocr/tesseract/wiki/NeuralNetsInTesseract4.00:

"NeuralNetsInTesseract4.00" --> "Neural Nets In Tesseract 4.00"

The spaces will be changed in the url by dashes i.e. https://github.com/tesseract-ocr/tesseract/wiki/Neural-Nets-In-Tesseract-4.00. This is more conform to the other pages, but there are more wiki pages missing some spaces.

Is this okay?
 Uff..., well, then I don't understand the sentence "Please do not change the title of any wiki page without a permission from Tesseract developers." at https://github.com/tesseract-ocr/tesseract/wiki CC @amitdo . I would expect that I can ask permission from developers in an issue at GitHub, if one has to use the user forum for that, then the sentence should be reformulated. Hi @zuphilip :-)

>**Please do not change the title of any wiki page without a permission from Tesseract developers**.

I added it a few hours ago.

Recently, a user change a lot of wiki pages titles. The issues I see with doing so are:
* There were many links to some of the wiki pages from Tesseract issues, threads in Tesseract mailing list, blogs posts, etc. The changes broke those links. 
* I contributed to some of those pages, especially to the `TrainingTesseract` page where I did ton of editing. With the change of the title the history of the page editing is gone from the wiki interface. It looks like I and others who contribute to those pages never did so. > With the change of the title the history of the page editing is gone from the wiki interface. 

That looks like something which could be simply improved by the GitHub people. I get the full history in a local clone of the wiki with `git log --follow Training-Tesseract.md`.
 @amitdo

My apologies for the unintended consequences of title changes. I was trying
to make all related pages in wiki come together, eg. Training methofs for
various versions, box files, tesstrain etc. I had no idea that it would
remove page history and previous authors. I also realize that it has led to
broken links.

Is there a way to display broken links in the wiki so that they can be
fixed?

On 22-Nov-2016 3:16 PM, "Amit D." notifications@github.com wrote:

Hi @zuphilip https://github.com/zuphilip :-)

I added it a few hours ago.

Recently, a user change a lot of wiki page titles. The issues I see with
doing so are:
- There were many links to some of the wiki pages from Tesseract issues,
  threads in Tesseract mailing list, blogs posts, etc. The changes broke
  those links.
- I contribute to some of those pages, especially to the
  TrainingTesseract page where I did ton of editing.
  With the change of the title the history of the page editing is gone
  from the wiki interface. It look like I and other who contribute to those
  pages never did so. Personally, this situation of omitting credits, upset
  me and piss me off :(

—
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub
https://github.com/tesseract-ocr/tesseract/issues/486#issuecomment-262194003,
or mute the thread
https://github.com/notifications/unsubscribe-auth/AE2_o5XgCcovlycw8Gwz7IDj9UkiOQsOks5rAroBgaJpZM4K5EDw
.
 Stefan,
Is it possible for you to undo the title changes?

On 22-Nov-2016 4:18 PM, "Stefan Weil" notifications@github.com wrote:

> With the change of the title the history of the page editing is gone from
> the wiki interface.
> 
> That looks like something which could be simply improved by the GitHub
> people. I get the full history in a local clone of the wiki with git log
> --follow Training-Tesseract.md.
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/486#issuecomment-262208337,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o_f0ZL2sVEcFsanjPh9Oqhs6jI8_ks5rAsiGgaJpZM4K5EDw
> .
 Shree @Shreeshrii,

I knew that you are the one that did those titles edits and I was sure you had good intentions. I don't blame you, so please don't feel bad about that :-) 

I blame Github devs.

Stefan @stweil, the fact that I can clone it and see my changes is not helping me. > Is it possible for you to undo the title changes?

I am not sure whether undoing your changes is the right way. Of course the wiki internal links must work, so maybe some links have to be fixed. I would not care for external links. They will still reach the wiki, and people who are interested will be able to find the page they are looking for.

@amitdo, I just contacted GitHub support and suggested to enhance the history, so maybe it will show all contributions (also those before a rename) in the future.

Personally I prefer nice looking titles (that implies spaces between words).

Technically anybody can rename titles, also back to the old ones. It's easier to revert changes in a local wiki clone, but only project owners can push such modifications. @amitdo : For the newly created pages, I will leave it up to you or any other of the core developer to change the page name. >@amitdo, I just contacted GitHub support and suggested to enhance the history, so maybe it will show all contributions (also those before a rename) in the future.

Thanks for that, although I'm sceptical about the chance they will do something about this issue. 

I was told that wikipedia's wiki does not have this issue.

With git itself and also with Github interface for **code** changes the history is preserved.

> I would not care for external links. They will still reach the wiki, and people who are interested will be able to find the page they are looking for.

This is called [breaking the web](https://www.google.co.il/search?client=ubuntu&channel=fs&q=%22breaking+the+web%22+%22broken+links%22) and it's not nice.

Some user re-added the 'deleted' pages with a link to the 'new' pages. In one hand it solves the broken links issue, but on the the other hand it creates a lot of ugly duplicates in the wiki TOC. 

>Personally I prefer nice looking titles (that implies spaces between words).

Personally, I think the fact that the wiki title does not have whitespace is a minor issue, and due to the implications I mentioned earlier, it should not be changed unless...
* It's a new wiki page (with no external links to it)
* The authors of the page agree with the change.


Some projects block the option to freely do any edits in the wiki content, but I don't suggest to so in this project. More fine-grained permissions control options in the wiki would be very helpful, e.g. options to block title editing and page deletion, an option to 'protected page' - block any editing for certain pages, etc.  

 Maybe not many people care about this issue as I do...

>@amitdo : For the newly created pages, I will leave it up to you or any other of the core developer to change the page name.

@zuphilip,
@theraysmith or @zdenop should decide about it.

Zdenko, if you don't like my new 'policy' you can remove it from the 'Home' wiki page. > Thanks for that, although I'm sceptical about the chance they will do something about this issue.

Well, at least they have sent an answer:

"This does sounds like it would be a useful addition to wiki revisions. I've passed your request onto the team to consider. I can't promise if or when we would implement but thanks for writing in."
 I now see that the previous edits were preserved in the interface of the global history.
https://github.com/tesseract-ocr/tesseract/wiki/_history?page=6
:-)

I now think it's OK to change the titles of **new** wiki pages...
@zdenop?

If you change the title of a page, don't do changes to the body text in the same edit. https://github.com/tesseract-ocr/tesseract/wiki/Improve-Quality/_compare/deccb78%5E...deccb78

This broke some links (Readme, Wiki).

What should we do now?
1) Revert this change?
2) Fix the links? CC: @andrewda My bad! Thought it was a typo, will revert for now. @amitdo Is there an issue with the revert button on the wiki `_compare` page? I clicked "Revert" assuming it would undo the title change and now both pages seem to be gone... Seems like a bug in GitHub.

https://github.com/contact The wiki interface considers a change of a wiki page title as creating a **new page**.
So the wiki reverted your last change - and deleted this page.
Unfortunately, the story ends here...

Or Not. The wiki can be cloned and the page should still be accessible in the history. It can be recovered. Ah, I understand now. Had no idea that's how GitHub renamed pages, very sorry for the trouble.  The source of the problem is git itself. The wiki is built on top of it.  The page was somehow restored.
https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality  commit c1c1e426b32794d5e84134ee81bf895ff0228fe5

system : ubuntu 16.04
there is an errror on lstmrecoginzer.cpp and other files.
the infamous 'isnan()' error
one way to fix NOW it is replacing  isnan() with std::isnan()

go into lstm dir and execute 

> sed -i 's/isnan/std::isnan/g' `grep "isnan" -rl`

have fun  PR #491 should fix this build problem (which also breaks the continuous integration tests). @blairq, could you please repeat your test with the latest version from git? This issue should be closed.  Hi，
Attached is the target image (Image61.tif, characters are"330") and all train data(.traineddata, .box and .tif).
[SimpleTest.zip](https://github.com/tesseract-ocr/tesseract/files/602968/SimpleTest.zip)

traindata1\fontyp.traineddata
Trained data just includes "3". The result is 333.
traindata2\fontyp.traineddata
Trained data includes "3" and "5". The result is 355 and why the second character isn't "3"?
The situations are the same using tesseract-OCR 3.02 or 3.05.00dev .
Could anybody help me? Thanks a lot!! More information:
1. OS is windows 7.
2. Tesseract-OCR 3.02 or 3.05.00dev .
3. Command line:
Tesseract Image61.tif result -l fontyp
 Thanks.  I am trying to train tesseract with my own data and want to generate frequent file list with wordlist2dawg. https://github.com/tesseract-ocr/tesseract/blob/master/doc/wordlist2dawg.1.asc

Running command

`wordlist2dawg data/freq_file_list.txt eng1.freq-dawg eng1.unicharset`
This is output

```
Loading unicharset from 'eng1.unicharset'
Reading word list from 'data/freq_file_list.txt'
Reducing Trie to SquishedDawg
Dawg is empty, skip producing the output file
Wordlist looks like this
```

```
Akbronco
Akstiletto
Ankyros
Ash
Bo
Boar
Boltor
Braton
Bronco
Burston
Carrier
Dakra
Dual
Ember
Fang
Fragor
....
```
It is not generating the dawg file, any suggestions what is wrong? Added both files
I had to add txt extension to unicharset just to upload it here.

[freq_file_list.txt](https://github.com/tesseract-ocr/tesseract/files/605711/freq_file_list.txt)

[eng1.unicharset.txt](https://github.com/tesseract-ocr/tesseract/files/605712/eng1.unicharset.txt)

 I am using Tesseract 3.05-dev on Windows 10. I got the same result,I think there maybe two probability.
1、The encoding of the input files freq_file_list.txt and eng1.unicharset.txt may not meet the requirements .
2、The unicharset you provide is not the correct.The unicharset file must be regenerated whenever inttemp, normproto and pffmtable are generated. use : 
mftraining -F font_properties -U unicharset -O regenerated.unicharset  *.tr hi,
what if the language was Arabic, which doesn't have capital case or small case, but the same problem was generated, what could be the issue? @blacklong617 @ibr123 

Please note tesseract version, o/s, commit number if known.

Also share the input files. 
[ara_frequent.txt](https://github.com/tesseract-ocr/tesseract/files/929641/ara_frequent.txt)
[ara.unicharset.txt](https://github.com/tesseract-ocr/tesseract/files/929645/ara.unicharset.txt)
these are the input files, the tesseract version is: tesseract 4.00.00alpha and OS is windows 10
and thanks for your response


 your ara_frequent.txt is encoded in ANSI with windows style end of line
markers. the words  show up as the following, instead of in Arabic. 
Just a few words from top of file pasted below

íÊæÞÚ
ÇáÚáãÇÁ
Ãä
ÊÕÈÍ
ÝÇßåÉ
ÇáßÑÒ
æÇÍÏÉ
ãä
æÓÇÆá
ÚáÇÌ
ÇáÏÇÁ
ÇáÓßÑí
ÝÇáãÇÏÉ
ÇáÓßÑíÉ

ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Apr 18, 2017 at 6:27 PM, ibr123 <notifications@github.com> wrote:

> ara_frequent.txt
> <https://github.com/tesseract-ocr/tesseract/files/929641/ara_frequent.txt>
> ara.unicharset.txt
> <https://github.com/tesseract-ocr/tesseract/files/929645/ara.unicharset.txt>
> these are the input files, the tesseract version is: tesseract
> 4.00.00alpha and OS is windows 10
> and thanks for your response
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/482#issuecomment-294831301>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_oyBRPmPFHGZx5ElILqptklrbYERzks5rxLMvgaJpZM4K3oHp>
> .
>
 Also see https://github.com/tesseract-ocr/tesseract/blob/master/training/tesstrain_utils.sh#L339

```
 # -r arguments to wordlist2dawg denote RTL reverse policy
    # (see Trie::RTLReversePolicy enum in third_party/tesseract/dict/trie.h).
    # We specify 0/RRP_DO_NO_REVERSE when generating number DAWG,
    # 1/RRP_REVERSE_IF_HAS_RTL for freq and word DAWGS,
    # 2/RRP_FORCE_REVERSE for the punctuation DAWG.
```  unofficial installer for windows for Tesseract 3.05-dev is available from Tesseract at UB Mannheim.
http://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-3.05.00dev.exe
win10, x64, lastest update.

the installer will not just add path,it will EMPTY path. This is not an issue for https://github.com/tesseract-ocr/tesseract/issues. Nevertheless I can try to answer here.

I got a similar report per e-mail recently, but could not reproduce it. Could you tell me the previous value of `PATH` which was emptied by the installation? Do you need the option which claims to set `PATH`? It is disabled by default, so I suggest to use the default setting (which avoids the issue).
 All values of PATH were emptied by the installation.
Maybe the installer alerted me ,or as you said it is disabled by default.
Maybe I click the "next" too fast cause I thought it's OK.
Fortunately,I opened the PowerShell before the installation,the change of PATH didn't refresh in the opened PowerShell,so that I can restore the values of PATH,or it will be a little trouble.
 How does your normal value of `PATH` look like? I need the value which you restored (or like it was before it was emptied) because the problem might be related to the length or the content of `PATH`.
 `C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Python27\;C:\Program Files\Python27\Scripts;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\nodejs\;C:\WINDOWS\system32\config\systemprofile\.dnx\bin;C:\Program Files\Microsoft DNX\Dnvm\;C:\Program Files (x86)\Windows Kits\8.1\Windows Performance Toolkit\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\MySQL\MySQL Fabric 1.5 & MySQL Utilities 1.5\;C:\Program Files (x86)\MySQL\MySQL Fabric 1.5 & MySQL Utilities 1.5\Doctrine extensions for PHP\;C:\Program Files\IDM Computer Solutions\UltraEdit;C:\Program Files (x86)\IDM Computer Solutions\UltraCompare;C:\Shorts;C:\Program Files\Git\cmd;C:\Program Files\Git\mingw64\bin;C:\Program Files\Git\usr\bin;C:\Program Files\MySQL\MySQL Server 5.7\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\TortoiseSVN\bin;C:\wamp64\bin\php\php7.0.10;C:\wamp64\bin\php\php7.0.10\ext;C:\Users\CeBk\AppData\Roaming\npm;C:\Users\CeBk\AppData\Local\Microsoft\WindowsApps;C:\Users\CeBk\AppData\Roaming\npm;%USERPROFILE%\AppData\Local\Microsoft\WindowsApps;`

that's all the values of PATH before the installation 
 The NSIS installer (which is used for Tesseract) has a [limit of 1024 characters](http://nsis.sourceforge.net/Path_Manipulation). Your PATH is clearly longer, so it hits that limit. I think the simplest solution will be removing the PATH setting from the installer, so users cannot activate it.
  I'm having problems with gimagereader and tesseract. uninstalled all, then did new install and I get no output in the pane of gimagereader. When I try to install gimagereader-dbg it wants libtesseract4 and this happens:

```
(synaptic:2537): GLib-CRITICAL **: g_child_watch_add_full: assertion 'pid > 0' failed
(Lese Datenbank ... 328342 Dateien und Verzeichnisse sind derzeit installiert.)
Vorbereitung zum Entpacken von .../libtesseract4_1%3a3.04.01-1~ppa+trusty0_amd64.deb ...
Entpacken von libtesseract4:amd64 (1:3.04.01-1~ppa+trusty0) ...
dpkg: Fehler beim Bearbeiten des Archivs /var/cache/apt/archives/libtesseract4_1%3a3.04.01-1~ppa+trusty0_amd64.deb (--unpack):
 Versuch, »/usr/lib/x86_64-linux-gnu/libtesseract.so.3.0.4« zu überschreiben, welches auch in Paket libtesseract3:amd64 3.04.00-1~ppa+trusty3 ist
dpkg-deb: Fehler: Unterprozess einfügen wurde durch Signal (Datenübergabe unterbrochen (broken pipe)) getötet
Fehler traten auf beim Bearbeiten von:
 /var/cache/apt/archives/libtesseract4_1%3a3.04.01-1~ppa+trusty0_amd64.deb
E: Sub-process /usr/bin/dpkg returned an error code (1)
Ein Paket konnte nicht installiert werden. Wiederherstellung wird versucht:
dpkg: Abhängigkeitsprobleme verhindern Konfiguration von tesseract-ocr:
 tesseract-ocr hängt ab von libtesseract4; aber:
  Paket libtesseract4:amd64 ist nicht installiert.

dpkg: Fehler beim Bearbeiten des Paketes tesseract-ocr (--configure):
 Abhängigkeitsprobleme - verbleibt unkonfiguriert
dpkg: Abhängigkeitsprobleme verhindern Konfiguration von tesseract-ocr-dbg:
 tesseract-ocr-dbg hängt ab von tesseract-ocr (= 1:3.04.01-1~ppa+trusty0); aber:
  Paket tesseract-ocr ist noch nicht konfiguriert.

dpkg: Fehler beim Bearbeiten des Paketes tesseract-ocr-dbg (--configure):
 Abhängigkeitsprobleme - verbleibt unkonfiguriert
Fehler traten auf beim Bearbeiten von:
 tesseract-ocr
 tesseract-ocr-dbg

```  to reproduce:
$ ls
1a.tiff 1b.tiff 1c.tiff
$ tesseract 1a.tiff 1a
Tesseract Open Source OCR Engine v3.04.01 with Leptonica
Page 1
Page 2
Page 3
Page 4
$ cat 1a.txt
_file contains text read from 1a.tiff AND 1b.tiff AND 1c.tiff WTF please_ Did you try to open 1a.tiff with an image viewer that can present multi-page tiff? This tiff file contains 4 images.
  The check needs libpng, otherwise it always fails with unresolved symbols.

Signed-off-by: Stefan Weil <sw@weilnetz.de> This should fix issue #435.
  Hi,
I went through the all the slides in das tutorial 2016 https://github.com/tesseract-ocr/docs/tree/master/das_tutorial2016.

May I ask is the version install through `sudo apt-get install tesseract-ocr ` using lstm by calling `tesseract ` at terminal?

Thanks! No, Ray has not updated the code with LSTM yet and as far as I know hasn't
communicated a date when it will be done.

On 4 Nov 2016 8:45 a.m., "Wenchen Li" notifications@github.com wrote:

> Hi,
> I went through the all the slides in das tutorial 2016
> https://github.com/tesseract-ocr/docs/tree/master/das_tutorial2016.
> 
> May I ask is the version install through sudo apt-get install
> tesseract-ocr using lstm by calling tesseract at terminal?
> 
> Thanks!
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/465, or mute the
> thread
> https://github.com/notifications/unsubscribe-auth/AE2_o6EqzLQH5q72OXVSIHPRozIyPIuwks5q6qNsgaJpZM4KpJyR
> .
 @zdenop

There have been a number of questions re tesseract 4.0 or version with
LSTM. It will be helpful for the community to know the status.

I have added a wiki page with available info at
https://github.com/tesseract-ocr/tesseract/wiki/4.0-with-LSTM

Please change the language as you deem fit and update when there is info
available about the release.

Thanks.

On 4 Nov 2016 12:44 p.m., "zdenop" notifications@github.com wrote:

> Closed #465 https://github.com/tesseract-ocr/tesseract/issues/465.
> 
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/465#event-847509931,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o84hw0akcgpmLray0dp-N_y0MvcRks5q6ttxgaJpZM4KpJyR
> .
  Cmake hangs at this stage and does not advance, even if left overnight:

The C compiler identification is MSVC 19.0.24215.1
The CXX compiler identification is MSVC 19.0.24215.1
Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64_x86/cl.exe
Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64_x86/cl.exe -- works
Detecting C compiler ABI info
Detecting C compiler ABI info - done
Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64_x86/cl.exe
Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64_x86/cl.exe -- works
Detecting CXX compiler ABI info
Detecting CXX compiler ABI info - done
Detecting CXX compile features
Detecting CXX compile features - done
Check if the system is big endian
Searching 16 bit integer
Looking for sys/types.h
Looking for sys/types.h - found
Looking for stdint.h
Looking for stdint.h - found
Looking for stddef.h
Looking for stddef.h - found
Check size of unsigned short
Check size of unsigned short - done
Using unsigned short
Check if the system is big endian - little endian
-- Performing 71 checks using 8 threads
-- This process may take up to 5 minutes depending on your hardware Just updated to latest cppan and tried again, same results:

D:\personal\tesseract>cppan --self-upgrade
Downloading checksum file
Downloading the latest client
Unpacking
Replacing client

D:\personal\tesseract\build>git status
On branch master
Your branch is up-to-date with 'origin/master'.

D:\personal\tesseract>cppan
Reading package specs... Ok
Generating build configs... Ok

D:\personal\tesseract>cd build

D:\personal\tesseract\build>cmake .. -DSTATIC=1
-- Building for: Visual Studio 14 2015
-- Check if the system is big endian
-- Searching 16 bit integer
-- Looking for sys/types.h
-- Looking for sys/types.h - found
-- Looking for stdint.h
-- Looking for stdint.h - found
-- Looking for stddef.h
-- Looking for stddef.h - found
-- Check size of unsigned short
-- Check size of unsigned short - done
-- Using unsigned short
-- Check if the system is big endian - little endian
-- Performing 71 checks using 8 threads
-- This process may take up to 5 minutes depending on your hardware
 I should mention that I'm seeing this issue across multiple machines, and this is the only codebase I'm seeing this issue for (cmake works fine on other projects, example: opencv).
 I doubt I'll have time to chat synchronously or share my screen today.  At a glance, it looks like cppan.exe is running during the hang, so I suspect it's the culprit.  Also see 2 cmake-gui processes and about 7 cmake processes.  Other info:

D:\personal\tesseract>cmake --version
cmake version 3.6.2

Regarding files in that directory, are you looking for a recursive list?  It looks like it just contains random folder names that contain session data.  There are a lot of files in each directory, though - looking for something specific?
 Yep, the CPU is doing barely anything.  

snip
 This better?
tree /F
Folder PATH listing for volume OSDisk
Volume serial number is 00000054 5A53:90A7

snip
 http://imgur.com/a/Y3qXr
 http://imgur.com/a/RZLsF
 http://imgur.com/VjOG70H
 http://imgur.com/a/LAfPN
[qDUdTLdY.zip](https://github.com/tesseract-ocr/tesseract/files/572840/qDUdTLdY.zip)
 No cl.exe, link.exe, MSBuild.exe, but there are a 6 conhost.exe's.  The two cmd.exe's open are my command windows.  Conhosts all look identical with the following command line:
\??\C:\WINDOWS\system32\conhost.exe 0x4 
 Killed all the conhosts.  Seems like one of them was driving the command window I executed cmake from, so that shut down.  Still see 4 cmake processes and a cppan process running.

![image](https://cloud.githubusercontent.com/assets/150887/20025816/887e6f36-a2af-11e6-9670-276ca75e8c90.png)
 ![image](https://cloud.githubusercontent.com/assets/150887/20025887/94be297a-a2b0-11e6-80d3-d04c829d47d8.png)
 That seemed to unstick it.  So cmake is hanging on something.
 Seems fixed in 3.7.  I don't see the "running tests" step at all anymore.
 Yeah, this brings the problem back.  If the next step is to build a debug version of cmake and debug their code, it might be a while before I have the time to address it.
 I got exactly the same issue. After many trial & errors I was about to compile CMake in debug when I found the solution in [this](https://github.com/tesseract-ocr/tesseract/issues/417#issuecomment-245073354) thread. Simply calling `cppan --self-upgrade` solved my issue. It seems like [this](https://cppan.org/client/cppan-master-Windows-client.zip) client is buggy and not up-to-date.
 it seems that the work can go on if you kill the two or three cmake tasks with least memories. If you have problems @hyogase [solution](https://github.com/tesseract-ocr/tesseract/issues/464#issuecomment-264166445) works perfectly.  removing all cmake tasks except one (with the highest memory) worked for me, thanks @hyogase   It is only used locally in opencl/openclwrapper.cpp.

For all other files which include openclwrapper.h, the compiler
complained about an unused static variable:

opencl/openclwrapper.h:175:16: warning:
 ‘MORPH_BC’ defined but not used [-Wunused-variable]

Signed-off-by: Stefan Weil <sw@weilnetz.de> It is still not clear for me why that variable `MORPH_BC` is needed at all.
  There are small issues in the code that cause compilation errors under Windows unicode project.
The problem is that some of win32 api functions are called without a proper postfix "A" which forces compiler to use non-unicode version of these functions. Here are all of them:
baseapi.cpp
377 WIN32_FIND_DATA -> WIN32_FIND_DATAA
379 FindFirstFile-> FindFirstFileA
381 FindNextFile -> FindNextFileA

svutil.cpp
82 STARTUPINFO -> STARTUPINFOA
84 GetStartupInfo -> GetStartupInfoA
85 CreateProcess -> CreateProcessA

mainblk.cpp
69 GetModuleFileName -> GetModuleFileNameA

P.S.
The same problem exists in the latest Leptonica library but among the similar errors that can be located by the compiler there are some that it is not able to find e.g. when the code uses GetTempPath instead of GetTempPathA.
 >The problem is that some of win32 api functions are called without a proper postfix "A" which forces compiler to use non-unicode version of these functions. Here are all of them

I'm not a Windows guy, but I think you are wrong here.

https://msdn.microsoft.com/en-us/library/windows/desktop/dd374089(v=vs.85).aspx


>Windows API functions that manipulate characters are generally implemented in one of three formats:
>
>    A generic version that can be compiled for either Windows code pages or Unicode
    A Windows code page version with the letter "A" used to indicate "ANSI"
    A Unicode version with the letter "W" used to indicate "wide"

cc: @egorpugin  > This should be used by default. No suffix - compiler will choose it without user.
> No need to rename functions.

You are right on one condition - if you use "TCHAR" type vars as WinApi function parameters instead of "char" and likewise LPCTSTR instead of LPCSTR, LPTSTR instead of LPSTR and so on. > So, types should be fixed, not functions.

yes sure, but I think functions can be fixed easier  Hi,
 I have a compile error as the result of running 'make' for Tesseract 3.01: 
[root@localhost tesseract-3.01]# make
make  all-recursive
make[1]: Entering directory `/root/tesseract-3.01'
Making all in ccutil
make[2]: Entering directory`/root/tesseract-3.01/ccutil'
make[3]: Entering directory `/root/tesseract-3.01/ccutil'
if /bin/sh ../libtool --tag=CXX --mode=compile g++ -DHAVE_CONFIG_H -I. -I. -I..   -I/usr/local/include/leptonica -DTESSDATA_PREFIX=/usr/local/share/ -g -O2 -MT ambigs.lo -MD -MP -MF ".deps/ambigs.Tpo" -c -o ambigs.lo ambigs.cpp; \
        then mv -f ".deps/ambigs.Tpo" ".deps/ambigs.Plo"; else rm -f ".deps/ambigs.Tpo"; exit 1; fi
 g++ -DHAVE_CONFIG_H -I. -I. -I.. -I/usr/local/include/leptonica -DTESSDATA_PREFIX=/usr/local/share/ -g -O2 -MT ambigs.lo -MD -MP -MF .deps/ambigs.Tpo -c ambigs.cpp  -fPIC -DPIC -o .libs/ambigs.o
In file included from params.h:26,
                 from tprintf.h:23,
                 from ambigs.h:25,
                 from ambigs.cpp:24:
strngs.h:1: error: stray '\357' in program
strngs.h:1: error: stray '\273' in program
strngs.h:1: error: stray '\277' in program
In file included from unicharset.h:24,
                 from ambigs.h:27,
                 from ambigs.cpp:24:
strngs.h:1: error: stray '\357' in program
strngs.h:1: error: stray '\273' in program
strngs.h:1: error: stray '\277' in program
make[3]: *** [ambigs.lo] Error 1
make[3]: Leaving directory`/root/tesseract-3.01/ccutil'
make[2]: **\* [all-recursive] Error 1
make[2]: Leaving directory `/root/tesseract-3.01/ccutil'
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory`/root/tesseract-3.01'
make: **\* [all] Error 2

OS:  Linux localhost.localdomain 2.6.18-194.el5xen #1 SMP Tue Mar 16 22:01:26 EDT 2010 x86_64 x86_64 x86_64 GNU/Linux

Leptonica 1.67 installed.
Thanks for help.
 Hi iamcool345, Try updating to a more recent version of Leptonica and/or the more recent version of Tesseract as well.

B.
 [Guide for reporting issues](https://github.com/tesseract-ocr/tesseract/blob/master/CONTRIBUTING.md)

Please use the [forum](https://groups.google.com/d/forum/tesseract-ocr).
  http://clang.llvm.org/extra/clang-tidy/checks/modernize-use-nullptr.html What about finishing this job? Several thousand `NULL` macros are still in the code. Replacing them could be done per directory. About 293 files would need changes. Here are the file counts per directory:

      7 api
     36 ccmain
     48 ccstruct
     40 ccutil
     40 classify
      6 cutil
      9 dict
      4 doc
     20 lstm
     52 textord
      2 training
      4 viewer
      4 vs2010
     21 wordrec
 @theraysmith, can you fix it with clang-tidy?
http://clang.llvm.org/extra/clang-tidy/checks/modernize-use-nullptr.html  Hi,
I'm using the "Example of iterator over the classifier choices for a single symbol" to show the confidence for each of the characters in image but it just print the characters of one of the word in the middle of image. how would i have all of the candidate choices and it's confidence for each of character in image?
  As per @jbreiden's comment in #373, here's a problem I noticed with tesseract 3.04.01 (from the Ubuntu Yakkety package).

This is the original PDF without text as it is created by my scanner: [scanned.pdf](https://github.com/tesseract-ocr/tesseract/files/558983/scanned.pdf)

I've used pdfsandwich with the `-debug` flag to get the intermediate files. The image it uses to feed into tesseract is the tif in this [tif.zip](https://github.com/tesseract-ocr/tesseract/files/558990/tif.zip). And this works just fine. Here's the identify information from that tif:

```
Image: extractedtif.tif
  Format: TIFF (Tagged Image File Format)
  Mime type: image/tiff
  Class: DirectClass
  Geometry: 2479x3500+0+0
  Resolution: 300x300
  Print size: 8.26333x11.6667
  Units: Undefined
  Type: Grayscale
  Endianess: LSB
  Colorspace: Gray
  Depth: 8-bit
  Channel depth:
    gray: 8-bit
```

Running

```
tesseract extractedtif.tif outputtif -l deu pdf
```

gives me a perfectly fine PDF in format: A4, Portrait (210 x 296 mm).

[outputtif.pdf](https://github.com/tesseract-ocr/tesseract/files/559002/outputtif.pdf)

And now I converted that tif to png with simply:

```
convert extractedtif.tif pngfromtif.png
```

[png.zip](https://github.com/tesseract-ocr/tesseract/files/559009/png.zip)

The new png file shows the same resolution information and print size:

```
Image: pngfromtif.png
  Format: PNG (Portable Network Graphics)
  Mime type: image/png
  Class: PseudoClass
  Geometry: 2479x3500+0+0
  Resolution: 300x300
  Print size: 8.26333x11.6667
  Units: Undefined
  Type: Grayscale
  Endianess: Undefined
  Colorspace: Gray
  Depth: 8-bit
  Channel depth:
    gray: 8-bit
```

However, running

```
tesseract pngfromtif.png outputpng -l deu pdf
```

gives me a PDF in format: 900 × 1270 mm paper size.

[outputpng.pdf](https://github.com/tesseract-ocr/tesseract/files/559004/outputpng.pdf)
 But then, why does tesseract behave inconsistently between tif and png when both have `Units: Undefined`?
 I think I know why the units are Undefined. pdfsandwich does a 2-step conversion from a PDF page to tif:

```
convert -colorspace Gray -colors 256 -depth 8 -background white -flatten +matte -density 300x300 scanned.pdf[0] tmpfile.ppm
```

Which gives:

```
Image: tmpfile.ppm
  Format: PPM (Portable pixmap format (color))
  Mime type: image/x-portable-pixmap
  Class: DirectClass
  Geometry: 2479x3500+0+0
  Units: Undefined
  Type: Grayscale
  Endianess: Undefined
  Colorspace: Gray
  Depth: 8-bit
  Channel depth:
    gray: 8-bit
```

And then:

```
convert -density 300x300 tmpfile.ppm tmpfile.tif
```

Which results in:

```
Image: tmpfile.tif
  Format: TIFF (Tagged Image File Format)
  Mime type: image/tiff
  Class: DirectClass
  Geometry: 2479x3500+0+0
  Resolution: 300x300
  Print size: 8.26333x11.6667
  Units: Undefined
  Type: Grayscale
  Endianess: LSB
  Colorspace: Gray
  Depth: 8-bit
  Channel depth:
    gray: 8-bit
```

I'll open a ticket with pdfsandwich to add `-unit PixelsPerInch` to the `convert` command.

_EDIT:_ https://sourceforge.net/p/pdfsandwich/bugs/14/
 Yup, asked both in the ticket there.
 > 1) Why use two convert commands instead of just one?

Because there's a use of `unpaper` in between them. It's [info file](https://github.com/Flameeyes/unpaper/blob/master/doc/basic-concepts.md) says:

> The image-file formats accepted by unpaper are those that libav can handle. In particular it supports the whole PNM-family: PBM, PGM and PPM. This ensures interoperability with the SANE tools under Linux. Support for TIFF and other complex file formats is not guaranteed.

That said, [libav says](http://libav.org/documentation/general.html#File-Formats) that it handles png and tiff, if I read it correctly.
 @mbirth I'm the author of [ocrmypdf](https://github.com/jbarlow83/OCRmyPDF), which is similar to pdfsandwich. \<plug\>ocrmypdf is extremely carefully in handling of DPI and handles a lot of edge cases that pdfsandwich does not.\</plug\> It handles your file without issue.

@jbreiden I think it would be helpful for tesseract to issue a warning when the DPI is nonsense. Lots of programs don't handle this metadata correctly so it's easy for a workflow to discard it. Wrong DPI isn't just a display/printing issue; in the case of say, scanned maps, losing scale information can change the interpretation. That is a very good idea. Hope I remember once the turkey coma wears off.
 This looks like a spot where we should emit the warning, but is not executed.

https://github.com/tesseract-ocr/tesseract/blob/a75ab450a8cc9a2b69cf05f5c4f7a39bc44cbacc/ccmain/osdetect.cpp#L167

This spot thinks the resolution is 0.

https://github.com/tesseract-ocr/tesseract/blob/9c7e99b04197fb9900c29be8bb9ac79a7a8b4672/ccmain/thresholder.cpp#L175

Oh, oh, maybe here.

https://github.com/tesseract-ocr/tesseract/blob/7b5b16779ad4980936724e85a548bccb717cc39c/api/baseapi.cpp#L2226


 Looks like we have kMinCredibleResolution defined in two places. Only the
one in baseapi.ccp is active for this test case.

```c++
--- tesseract/api/baseapi.cpp	2016-11-07 07:44:03.000000000 -0800
+++ tesseract/api/baseapi.cpp	2016-11-28 11:23:48.000000000 -0800
@@ -2226,6 +2226,8 @@
   if (y_res < kMinCredibleResolution || y_res > kMaxCredibleResolution) {
     // Use the minimum default resolution, as it is safer to under-estimate
     // than over-estimate resolution.
+    tprintf("Warning. Invalid resolution %d dpi. Using %d instead.\n",
+            y_res, kMinCredibleResolution);
     thresholder_->SetSourceYResolution(kMinCredibleResolution);
   }
   PageSegMode pageseg_mode =
--- tesseract/ccmain/osdetect.cpp	2016-11-07 07:44:03.000000000 -0800
+++ tesseract/ccmain/osdetect.cpp	2016-11-28 11:31:13.000000000 -0800
@@ -164,8 +164,14 @@
   int vertical_y = 1;
   tesseract::TabVector_LIST v_lines;
   tesseract::TabVector_LIST h_lines;
-  int resolution = (kMinCredibleResolution > pixGetXRes(pix)) ?
-      kMinCredibleResolution : pixGetXRes(pix);
+  int resolution;
+  if (kMinCredibleResolution > pixGetXRes(pix)) {
+    resolution = kMinCredibleResolution;
+    tprintf("Warning. Invalid resolution %d dpi. Using %d instead.\n",
+            pixGetXRes(pix), resolution);
+  } else {
+    resolution = pixGetXRes(pix);
+  }
 
   tesseract::LineFinder::FindAndRemoveLines(resolution, false, pix,
                                             &vertical_x, &vertical_y,
```  This fixes several gcc warnings:

warning:
 type qualifiers ignored on function return type [-Wignored-qualifiers]

Signed-off-by: Stefan Weil sw@weilnetz.de
  I don't find how to use this API in android project.  is there an available wrapper for android? 
  ![leptonica](https://cloud.githubusercontent.com/assets/17674215/18988851/44796cb8-8726-11e6-8854-9ff87c11ad96.png)
I followed the steps of installation of `tesseract-ocr`. After `autogen.sh` , I tried `./configure` but terminal is showing `leptonica library with pdf support (>= 1.71) is missing` and no further installation is happening.
I searched for this problem extensively. I installed `leptonica-17.3` from source. Then I tried `./configure` again. The problem persisted. I again searched. In one closed issue, there was suggestion for `./configure --with-extra-includes=/usr/local/include --with-extra-libaries=/usr/local/lib
` instead of `./configure`. I didn't work.
The problem is still the same. 
What to do? 
Any suggestion is welcome. 
 I have the same bug. Since it is telling you that you have the wrong version, but that is not the real issue.

 this is bug and not a "asking support".
 @canny07 i made it work by setting the library path diffierntly. It is probably a old version of leptonica that is "blocking the sight"  for the config script .
 @Neppord Yeah It seems so. For my case, I found that the older version was the reason of trouble. So, I removed it and downloaded and installed the latest version from the source. 
Thanks for answering :)
 First, it is recommended to uninstall an older Leptonica before you install new one.

Running `sudo ldconfig` after `sudo make install` in both Leptonica and Tesseract installation should prevent the issue you had.

Anyway, it's not a bug in Tesseract.
 > Anyway, it's not a bug in Tesseract.

In some way it is. I had to fix my Tesseract configuration to get PDF support for the Windows version. Maybe I should have sent a PR earlier – I'll do it now.
 Please test and review pull request #473 which should fix this issue.
 The cause of their issue is not related to libpng. 
  Hi,

The command line help output shows 11 PSM modes (0 through 10).

```
  pagesegmode values are:
  0 = Orientation and script detection (OSD) only.
  1 = Automatic page segmentation with OSD.
  2 = Automatic page segmentation, but no OSD, or OCR
  3 = Fully automatic page segmentation, but no OSD. (Default)
  4 = Assume a single column of text of variable sizes.
  5 = Assume a single uniform block of vertically aligned text.
  6 = Assume a single uniform block of text.
  7 = Treat the image as a single text line.
  8 = Treat the image as a single word.
  9 = Treat the image as a single word in a circle.
  10 = Treat the image as a single character.
```

I was trying each one and getting mixed results. However, I accidentally ran 'psm -11' and I suddenly got perfect accuracy - way way better than any other PSM mode, and much better than the default. The same for PSM 12 too, perfect accuracy - then PSM 13 gives nothing. 

The image is just about 10 words over 2 lines, spread about the page. All the other segmentation modes and default garble the text, but PSM 11/12 worked great, splitting text perfectly.

Is it correct that there's a PSM 11 and 12 mode? What do they do, why do they give such good accuracy?! And should they be in the help/[Wiki](https://github.com/tesseract-ocr/tesseract/wiki/Command-Line-Usage)?

Thanks!
 With Tesseract 4.0 PSM 11, 12, and 13 appear in the help message. psm 13 is used with the new LSTM engine to OCR a single textline image.   Font detection works fine in PSM_SINGLE_WORD mode. In PSM_SINGLE_LINE mode it is not working well. For recognizing more text (column, full page) font detection does not work at all. For every word the reported font is the same (e.g. Georgia using the default eng.traineddata). I thought at first that this is a issue with traineddata but training my own data and trying different stuff it seems way more likely that this issue is with tesseract (see [issue in tessdata](https://github.com/tesseract-ocr/tessdata/issues/25) ). I attached a small example to demonstrate the problem.
[broken_font_detection_sample.zip](https://github.com/tesseract-ocr/tesseract/files/493838/broken_font_detection_sample.zip)
 All the fonts are from the liberation family. I could narrow down the cause of this problem to the adaptive classifier. With classify_enable_learning set to false detection of italic/sans/serif works and detection of bold works sometimes (which is to be expected). The adoptive classifier seems a bit overzealous if font features change (eg. from serif to sans). It seems if a word is sans all sans fonts in the training data get high ratings and the already adopted to sans font gets a even higher rating. If the next word is serif then the serif fonts in the training data get high ratings but the adopted to sans font gets a rating that is still higher. I suppose that because of this the already adopted to sans font is able to learn the serif features. In the end the whole document matches the font that the classifier was first adopting to (I tried this). I attached a part of the log obtained from setting tessedit_debug_fonts to true where font changes from sans to serif bold ("Exeter." -> "The").
[debug_log.txt](https://github.com/tesseract-ocr/tesseract/files/504412/debug_log.txt)
 This problem is triggered as soon as any previously adapted character is encountered and the codepath DoAdaptiveMatch->BaselineClassifier is used. My current insight into this issue is that matching baselinenormalized characters and matching characternormalized characters yield different kinds of ratings  that are not comparable. The ratings based on baselinenormalized characters are inflated when compared to the ratings based one characternormalized characters so the font first adapted to always gets the highest ratings (due to learning new words that are actually printed in a different font). There is probably also a (related?) bug that causes inflated ratings for bad matches using BaselineClassifier. For example doubling xheight still matches the same font in testing if BaselineClassifier is called. The only case where a different font is sometimes matched  is when the characters are damaged beyond recognition (that may be because different classifiers are tried in this case).
  I've traced the code several times looking for the class which the characters recognized, but I can't found it.
where does the characters recognize?
  Tesseract just spent seven hours trying to do OCR on the attached document. It's five pages long. 

I'm fairly certain that the reason this takes so long is because of the speckling in the document. Other times when I've seen this kind of performance, it's been for similarly speckled documents.

Not sure what you can or should do about it, but since it seems to be a worst case scenario for Tesseract, I thought I'd report it.

This is on the latest version of Tesseract. 

[gov.uscourts.ctd.18812.88.0.pdf](https://github.com/tesseract-ocr/tesseract/files/488538/gov.uscourts.ctd.18812.88.0.pdf)
 One minute per page is not extraordinary much (although improvements which make it faster are of course welcome). My worst cases are currently double pages from a historic newspaper which take around ten minutes.
 Thanks for looking at this! We converted using ghostscript to multi-page tiff:

```
gs -dQUIET -dSAFER -dBATCH -dNOPAUSE-sDEVICE=tiffgray -r300x300-o destination path
```

One minute/page is still pretty darned slow, but we'd welcome that at this point!
 You could use gs to split the pdf into images and then ocr each separately
and concatenate the result.

On 23 Sep 2016 10:58 p.m., "Mike Lissner" notifications@github.com wrote:

> Thanks for looking at this! We converted using ghostscript to multi-page
> tiff:
> 
> gs -dQUIET -dSAFER -dBATCH -dNOPAUSE-sDEVICE=tiffgray -r300x300-o
> destination path
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/431#issuecomment-249253159,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o7sVanef-bvL1nJdyJAdBJ0L3-2jks5qtAwkgaJpZM4KEcsN
> .
 Sure, but that's not the point...and anyway, it's not at all clear that the slowness is because it's a multipage tiff. I suspect if you ran this on each individual page of the tiff you'd have the same slowness.
 To get accurate results, you will need to preprocess the images too to get
rid of the background speckles.

You could try scantailor or imagemagick.

As a test, you can also try Vietocr GUI, and compare results with the
command line output.

On 23 Sep 2016 11:35 p.m., Shree wrote:

You could use gs to split the pdf into images and then ocr each separately
and concatenate the result.

On 23 Sep 2016 10:58 p.m., "Mike Lissner" notifications@github.com wrote:

> Thanks for looking at this! We converted using ghostscript to multi-page
> tiff:
> 
> gs -dQUIET -dSAFER -dBATCH -dNOPAUSE-sDEVICE=tiffgray -r300x300-o
> destination path
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/431#issuecomment-249253159,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o7sVanef-bvL1nJdyJAdBJ0L3-2jks5qtAwkgaJpZM4KEcsN
> .
 Yeah, we saw this in testing, but went with TIFFs because they support multi-page images, which makes our OCR pipeline easier. In testing, we saw that the OCR for PDFs was no slower using large TIFFs than it was using PNGs because the process seems to be CPU bound no matter what.

If you use 300dpi PNGs do you get the slow performance I experienced with the 300dpi TIFFs? That's probably a better test, right?
 Thanks for looking at this @amitdo.

> This command creates a 42 MB tiff file. The size in pixels of each page is the same as with my PNGs.

But these aren't 300x300, which is apparently what provides the best OCR quality.[1] The point of this issue is that at 300x300, this takes seven hours to do five pages.

> It 'thinks' the speckles are diacritics...

Yeah...that's an issue too. Running a despeckling filter first would help in this case, but we do OCR on millions of PDFs and we only need to despeckle the worst of them. For the rest, I imagine it would reduce quality (not to mention slow down the pipeline).

The point here is that Tesseract takes seven hours for a speckled document at the recommended DPI.

[1]: Some references: 
- From the FAQ: https://github.com/tesseract-ocr/tesseract/wiki/FAQ#is-there-a-minimum-text-size-it-wont-read-screen-text
- "Optimal Image Conversion Settings for Tesseract" : https://mazira.com/blog/optimal-image-conversion-settings-tesseract-ocr
- "Using Tesseract with PDF scans": http://kiirani.com/2013/03/22/tesseract-pdf.html
 @mlissner It would have been helpful, if you had shared the info about your previous tests for this type of document

http://stackoverflow.com/questions/39110300/how-to-provide-image-to-tesseract-from-memory

https://github.com/mlissner/tesseract-performance-testing
 We have seen similar documents taking very long (but still not an hour per page!). Therefore, whether it really is a tesseract issue should be investigated further.

@mlissner in order to increase performance and quality, you have to pre-process the image(s) for tesseract. For your specific case, use `leptonica` (tesseract already depends on it). Count the connected components, if there are too many, apply your filters. In a real word application where your documents have specific characteristics, you will not be able to avoid heavy pre-processing for tesseract in order to achieve reasonable results.

Look how tesseract uses leptonica and CCs e.g., 
https://github.com/tesseract-ocr/tesseract/search?utf8=%E2%9C%93&q=pixConnComp
 @mlissner
You could also look at the preprocessing workflow used by pdf sandwich 
https://sourceforge.net/projects/pdfsandwich/
 Lots of responses here, so let me try to respond to as many as I can.

@amitdo and @jbreiden:

I considered using `-sDEVICE=tiffg4` over `-sDEVICE=tiffgray`, but it's not purely black and white, and like I said, the bigger files don't seem to affect performance. Here's a comparison of a gray part of the original PDF:

`tiffg4`:
![g4](https://cloud.githubusercontent.com/assets/236970/18854007/4b98691c-83fd-11e6-9ef8-af26032e579c.png)

`tiffgray`:
![gray](https://cloud.githubusercontent.com/assets/236970/18854014/54c3f81c-83fd-11e6-9b79-b27dc815011b.png)

`tiffgray` is definitely better for this, and since we're doing millions of files, it seems safer to use this approach than to assume all docs are purely black and white (even though it makes big files).

But setting that aside, it seems like using `gs` is the wrong approach regardless. Seems like the right approach is to extract the images undisturbed. Seems doable, but I'll have to do some research on this. Is it documented anywhere which image formats Tesseract supports natively? There's [one question in StackOverflow](https://stackoverflow.com/questions/10193001/whats-the-best-image-input-type-for-tesseract) that seems to address this, but otherwise I don't see a lot of guidance. I'm concerned that if we use the undisturbed images, we'll get weird image formats that Tesseract won't accept.

@jbreiden you also say:

> If necessary, adjust their header so that their resolution agrees with what the PDF was claiming.

This feels wrong to me. In my experience, PDFs are a terrible source of ground truth. I'd expect the header information in the images to be much more accurate than whatever a PDF was reporting. You've provided a lot of information here already, but can you explain why we'd prefer the PDF data over the image data? 

@vidiecan: I'll look into counting connected components. Seems like a great way to solve this, if it performs well enough. Thanks for this suggestion.

@Shreeshrii: I looked at PDF Sandwich, but didn't see anything useful. Do you know the code well enough to point me towards the image conversion part? 
 @jbreiden, do you know the image formats supported by Tesseract?
 > You might want to use -sCompression=lzw.

I just did some simple timings on this. 

The good:  
- Compressed Tiffs are about 1-2% the size of the uncompressed versions (in a test I just did, uncompressed was 137M while compressed was 1.8M!).
- Using compressed files used about 30% of the RAM (92MB instead of 301MB according to [`time -v`](https://stackoverflow.com/questions/774556/peak-memory-usage-of-a-linux-unix-process)).
- LZW is a lossless format, so Tesseract generated identical results.
- It took Tesseract about the same amount of time to do either format.

The bad:  
- It takes about twice as long to generate compressed tiffs from PDFs (though this is only a fraction of the total time doing OCR).

The hmmm:  
- Making a compressed tiff moves the processing burden from disk (making a big file) to CPU (compressing a big file).

Our bottleneck on our OCR server is CPU, so it's actually preferable for us to generate big files that use less CPU than to make small files that don't. OTOH, RAM is expensive, so we'll probably be switching this out. Thanks for the suggestion!
 Jeff,
Why are we not commiting your patch from March?

On 4 Oct 2016 9:30 p.m., "jbreiden" notifications@github.com wrote:

> My first patch (dated March 28) in this bug #233
> https://github.com/tesseract-ocr/tesseract/issues/233 will reduce RAM
> use in TIFF. It stops Tesseract from buffering the input file before
> decompression. The patch should also should make the LZW case equal to the
> non-LZW case with respect to RAM. Note that I haven't tested on this
> particular example, so I'm saying "should" rather than "does".
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/431#issuecomment-251488440,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o26v-ubHM_MSiloIl-YAaOzocpMPks5qwqlWgaJpZM4KEcsN
> .
  Is it possible to find a roadmap/changelog for upcoming releases like 3.05 so the "public" can follow the development..

Personally I would really like some optimization.. The accuracy is quite good but the speed is really bad!
 Will 3.05 be based on LSTM?
 A roadmap would help planning development and inform users about future features which they can expect. I could not find one for 3.05, so I assume that there is no officially published roadmap. Maybe it would be a good idea to create one on the [Tesseract wiki](https://github.com/tesseract-ocr/tesseract/wiki).
 LSTM release is going to be 4.0 as per zdenko since it is a major change.

I would request zdenko for a release/tag of repo before that for 3.05. A
change log for that could be created by summarizing the commit notes.

Some recent updates of interest to many users are...
Improvement for Windows versions
Availability of training tools on windows
Various bug fixes since 3.04.1
Etc

On 23 Sep 2016 11:46 a.m., "Amit" notifications@github.com wrote:

> In general, only Ray can share this roadmap. You can ask him to do so in
> the dev forum.
> https://groups.google.com/d/forum/tesseract-dev
> 
> and inform users about future features which they can expect. I could not
> find one for
> 
> For the next release the major feature is the LSTM based engine, which
> users can read about in the DAS 2016 slides.
> 
> Regarding sharing the dates for releases, some open source projects do
> share a schedule, while others just declare "We'll have a new release when
> it's ready...".
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/430#issuecomment-249111751,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o6dJ5XcUXiaPRWE7ElBADweni21Xks5qs27ZgaJpZM4KD0AP
> .
 For users
https://groups.google.com/forum/#!topic/tesseract-ocr/e__2DN1GQb0

For developers
https://groups.google.com/forum/#!topic/tesseract-dev/mZ2IUsvWgbY Ray also updated the page that @Shreeshrii created. 
https://github.com/tesseract-ocr/tesseract/wiki/4.0-with-LSTM#40  This may be an oversight, setting justification in ccmain/pageiterator.cpp:ParagraphInfo seems to work fine. Patch attached.
[set_justification.patch.zip](https://github.com/tesseract-ocr/tesseract/files/478642/set_justification.patch.zip)
  09-17 15:20:02.050 21768-21778/com.example.sigmaway.homeimage W/art: Suspending all threads took: 28.488ms
09-17 15:20:02.078 21768-25485/com.example.sigmaway.homeimage V/OCR: Ctesseract 1
09-17 15:20:02.085 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/libjpgt.so: unused DT entry: type 0x6ffffffe arg 0x29b0
09-17 15:20:02.085 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/libjpgt.so: unused DT entry: type 0x6fffffff arg 0x1
09-17 15:20:02.088 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/libpngt.so: unused DT entry: type 0x6ffffffe arg 0x58e0
09-17 15:20:02.088 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/libpngt.so: unused DT entry: type 0x6fffffff arg 0x2
09-17 15:20:02.093 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/liblept.so: unused DT entry: type 0x6ffffffe arg 0x231d0
09-17 15:20:02.093 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/liblept.so: unused DT entry: type 0x6fffffff arg 0x2
09-17 15:20:02.097 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/libtess.so: unused DT entry: type 0x6ffffffe arg 0x67f60
09-17 15:20:02.097 21768-25485/com.example.sigmaway.homeimage W/linker: /data/app/com.example.sigmaway.homeimage-1/lib/arm64/libtess.so: unused DT entry: type 0x6fffffff arg 0x3
09-17 15:20:02.156 21768-25485/com.example.sigmaway.homeimage V/OCR: Ctesseract 2
09-17 15:20:02.157 21768-25485/com.example.sigmaway.homeimage V/OCR: Ctesseract 3
09-17 15:20:02.293 21768-25485/com.example.sigmaway.homeimage A/libc: Fatal signal 6 (SIGABRT), code -6 in tid 25485 (AsyncTask #4)
09-17 15:20:03.802 27329-27329/com.example.sigmaway.homeimage W/art: Before Android 4.1, method android.graphics.PorterDuffColorFilter android.support.graphics.drawable.VectorDrawableCompat.updateTintFilter(android.graphics.PorterDuffColorFilter, android.content.res.ColorStateList, android.graphics.PorterDuff$Mode) would have incorrectly overridden the package-private method in android.graphics.drawable.Drawable
09-17 15:20:04.033 27329-27329/com.example.sigmaway.homeimage A/add home: tess data  or Document file found
09-17 15:20:04.037 27329-27329/com.example.sigmaway.homeimage A/add home: tess data  or Document file found
09-17 15:20:04.090 27329-27372/com.example.sigmaway.homeimage D/OpenGLRenderer: Use EGL_SWAP_BEHAVIOR_PRESERVED: true
09-17 15:20:04.099 27329-27329/com.example.sigmaway.homeimage D/Atlas: Validating map...

public class Ocr {
    String TAG= "OCR";
    String DATA_PATH = Environment.getExternalStorageDirectory().toString() + "/Sigmaway/";
    String[] language={"eng","ara"};
    Context c;
    ArrayList<Rect> Pics=new ArrayList<Rect>();
    public void Ocr(Context context){

```
    this.c=context;
    String[] paths = new String[]
            { DATA_PATH, DATA_PATH + "tessdata/" };

    for (String path : paths) {
        File dir = new File(path);
        if (!dir.exists()) {
            if (!dir.mkdirs()) {
                Log.v(TAG, "ERROR: Creation of directory " + path + " on sdcard failed");
                return;
            } else {
                Log.v(TAG, "Created directory " + path + " on sdcard");
            }
        }

    }
    for (String lang:language)
    {   Log.v(TAG, "hey c");

        if (!(new File(DATA_PATH + "tessdata/" + lang + ".traineddata")).exists()) {
            try {

                AssetManager assetManager = c.getAssets();
                InputStream in = assetManager.open("tessdata/" + lang + ".traineddata");
                //GZIPInputStream gin = new GZIPInputStream(in);
                OutputStream out = new FileOutputStream(DATA_PATH
                        + "tessdata/" + lang + ".traineddata");

                // Transfer bytes from in to out
                byte[] buf = new byte[1024];
                int len;
                //while ((lenf = gin.read(buff)) > 0) {
                while ((len = in.read(buf)) > 0) {
                    out.write(buf, 0, len);
                }
                in.close();
                //gin.close();
                out.close();

                Log.v(TAG, "Copied " + lang + " traineddata");
            } catch (IOException e) {
                Log.e(TAG, "Was unable to copy " + lang + " traineddata " + e.toString());
            }
        }

    }

}
```

 public String tesseract(Context context,Bitmap bmpImg, String lang){
      this.c=context;

```
 Log.v(TAG, "Ctesseract 1" );
   TessBaseAPI baseApi = new TessBaseAPI();
 Log.v(TAG, "Ctesseract 2" );
   baseApi.setDebug(true);
 Log.v(TAG, "Ctesseract 3" );
   baseApi.init(DATA_PATH,lang);
 Log.v(TAG, "Ctesseract 4" );
   baseApi.setImage(bmpImg);
 Log.v(TAG, "Ctesseract 5  "  );
   String recognizedText = baseApi.getUTF8Text();
 Log.v(TAG, "Ctesseract 6" );
   baseApi.end();
   if ( lang.equalsIgnoreCase("eng") ) {
       recognizedText = recognizedText.replaceAll("[^a-zA-Z0-9]+", " ");
   }

   //recognizedText = recognizedText.trim();
 return recognizedText;
}
```

}
This is my class through which i ocr the task and call the method in async task from the main activity.
so if i do use english the api works well but if i use the arabic trained data the app crashes giving
the below error on  baseApi.init(DATA_PATH,lang); command
09-17 15:20:02.293 21768-25485/com.example.sigmaway.homeimage A/libc: Fatal signal 6 (SIGABRT), code -6 in tid 25485 (AsyncTask #4)
09-17 15:20:03.802 27329-27329/com.example.sigmaway.homeimage W/art: Before Android 4.1, method android.graphics.PorterDuffColorFilter android.support.graphics.drawable.VectorDrawableCompat.updateTintFilter(android.graphics.PorterDuffColorFilter, android.content.res.ColorStateList, android.graphics.PorterDuff$Mode) would have incorrectly overridden the package-private method in android.graphics.drawable.Drawable
  Hi there, I've got some specific images that output the following on linux:

```
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
```

The pictures get successfully OCRed in tesseract (without great results tho). The biggest problem for me, however, is that in OCRopus they don't even get OCRed.

![example5](https://cloud.githubusercontent.com/assets/11379168/18517342/4f37901e-7a72-11e6-9db0-260a42a10189.jpg)
![ghoby30c](https://cloud.githubusercontent.com/assets/11379168/18517343/4f37ab1c-7a72-11e6-9766-b6831a215718.jpg)

Any ideas?
 @amitdo I'm getting the same issue just with Tesseract. I'm guessing OCRopus is using Tesseract and that's why he made the issue here. >I'm guessing OCRopus is using Tesseract

Ocropy (and clstm) does not use Tesseract. A VERY OLD version of Ocropus (0.4) did use Tesseract.
  A user reported to Homebrew in https://github.com/Homebrew/homebrew-core/issues/4764 that the tesseract build was broken if built from the HEAD of master (currently a75ab450a8cc9a2b69cf05f5c4f7a39bc44cbacc) using the options

```
brew install tesseract --HEAD --with-opencl
```

which means that we pass `--enable-opencl` to `configure`.

I bisected the build failure and found that it's a regression caused by https://github.com/tesseract-ocr/tesseract/commit/b1c921b59e6af1e68fd026cbc30540929b818552

Reverting

```
libtesseract_la_LDFLAGS += -version-info $(GENERIC_LIBRARY_VERSION) -no-undefined
```

back to

```
libtesseract_la_LDFLAGS += -version-info $(GENERIC_LIBRARY_VERSION)
```

fixed the build. A "real" fix will be more involved of course, since I'm sure you don't want to break Cygwin again.

The build error presents as

```
==> Installing tesseract
==> Using the sandbox
==> Cloning https://github.com/tesseract-ocr/tesseract.git
Cloning into '/Users/joe/Library/Caches/Homebrew/tesseract--git'...
remote: Counting objects: 794, done.
remote: Compressing objects: 100% (733/733), done.
remote: Total 794 (delta 125), reused 235 (delta 42), pack-reused 0
Receiving objects: 100% (794/794), 3.78 MiB | 1.10 MiB/s, done.
Resolving deltas: 100% (125/125), done.
Checking connectivity... done.
==> Checking out branch master
==> ./autogen.sh
==> ./configure --prefix=/usr/local/Cellar/tesseract/HEAD-a75ab45_2 --enable-opencl
==> make install
Last 15 lines from /Users/joe/Library/Logs/Homebrew/tesseract/03.make:
  "_clReleaseProgram", referenced from:
      OpenclDevice::ReleaseOpenclEnv(_GPUEnv*) in libtesseract_opencl.a(openclwrapper.o)
  "_clSetKernelArg", referenced from:
      OpenclDevice::pixReadFromTiffKernel(unsigned int*, int, int, int, unsigned int*) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL_55(int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixDilateCL(int, int, int, int) in libtesseract_opencl.a(openclwrapper.o)
      pixErodeCL(int, int, unsigned int, unsigned int) in libtesseract_opencl.a(openclwrapper.o)
      pixORCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      pixANDCL_work(unsigned int, unsigned int, _cl_mem*, _cl_mem*, _cl_mem*) in libtesseract_opencl.a(openclwrapper.o)
      ...
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[1]: *** [libtesseract.la] Error 1
make: *** [install-recursive] Error 1
```

Complete log is here: https://gist.github.com/y-fedorov/0e5a302dd68ff9d8647f03ba4c15050a
 I wonder if you'd have any more luck with pocl.
 OP said that's fine

```
$ brew install tesseract - is OK
$ brew install tesseract --HEAD - is OK
```
 @stweil, can you fix that?  Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
row xheight=132.409, but median xheight = 101.7
row xheight=126.5, but median xheight = 101.7
row xheight=126.5, but median xheight = 101.7
row xheight=119, but median xheight = 101.7
row xheight=86.6667, but median xheight = 101.7
row xheight=76.6667, but median xheight = 101.7
row xheight=246, but median xheight = 101.7
id < this->size():Error:Assert failed:in file unicharset.cpp, line 278
zsh: segmentation fault (core dumped)  **tesseract de.elab.exp0.png de.elab.exp0.box box.train**

boxfile: @https://gist.github.com/CDanU/e14b3b1c0ba3a3502fb86a55bad0a30d
img: https://cloud.githubusercontent.com/assets/15148226/18413673/1edce808-77af-11e6-9ba4-94524dcf2243.png

Maybe the image is too big ? If that is the case it would be nice to get a better message.

tesseract 3.05.00dev
 leptonica-1.73
  libgif 5.1.2 : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.6.25 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.5.1
  The existing C API for `TessBaseAPIDetectOS` requires a C caller to successfully allocate `struct OSResults` which is actually a C++ class. If the C++ compiler decides to append anything to the structure, this will fail. The definition of this struct also depends on `kMaxNumberOfScripts` so is subject to change if (when) Tesseract adds more scripts.

The struct members that a caller is most likely to want are actually in `OSBestResult` whose position may shift.

I suggest deprecating this API and providing one that returns the member elements of `OSBestResult` instead. I think it would be useful to have a C API call to obtain this information rather than parsing the executable's output in `-psm 0`. Here's one possible API.

``` C
BOOL TessBaseAPIDetectOS2(
 TessBaseAPI* handle, 
 int* best_script_id, 
 int* best_orientation_id, 
 float* script_confidence, 
 float* orientation_confidence);
```

Returning `OSBestResults` is also an option, but sometimes it's nice to avoid structs entirely.

I can contribute changes if there's agreement on them.
 Posted
 The suggestion looks good to me. 

@zdenop, I suggest to give @jbarlow83 a green light for sending a PR. Yes, working on it.  I am facing issues in window installation. And probably due to Pango / Cairo. Any help please?

```
c:\work\tesseract\build>cmake .. -DSTATIC=1
-- Downloading latest ICU binaries
-- Checking for module 'pango'
--
CMake Error at C:/Program Files/CMake/share/cmake-3.7/Modules/FindPkgConfig.cmak
e:415 (message):
```
  A required package was not found
```
Call Stack (most recent call first):
  C:/Program Files/CMake/share/cmake-3.7/Modules/FindPkgConfig.cmake:588 (_pkg_c
heck_modules_internal)
  training/CMakeLists.txt:190 (pkg_check_modules)


-- Configuring incomplete, errors occurred!
See also "C:/work/tesseract/build/CMakeFiles/CMakeOutput.log".
See also "C:/work/tesseract/build/CMakeFiles/CMakeError.log".
``` http://www.pango.org/Download 404 error https://www.gtk.org/download/win64.php
Tried [this](https://sourceforge.net/projects/sdlpango/)  but no help  I find the 3.0.5 model is better than 3.0.2.Now my project is building by vs2010 and tesseract3.0.2.I replace the 3.0.2 tessdata by 3.0.5 tessdata ,it shows "allow_blob_division",than I use "combine_tessdata -e chi_sim.traineddata chi_sim.config" and notes the line of "allow_blob_division",finally "combine_tessdata -o chi_sim.traineddata chi_sim.config",but the tessdata is invalid.
  ![2](https://cloud.githubusercontent.com/assets/2742842/18303628/ab937754-7510-11e6-9d01-12bf943a2b24.png)

```
tesseract.exe -psm 10 2.png stdout digits
```

Above picture always return empty without any error. Is that a bug?
  Are there any plans for creating ALTO support in tesseract? I was thinking about programming a module for it. I was searching some conversion tool but found nothing working. I need it to be working in linux terminal, I found just conversion tool from hOCR to ALTO but the output is wrong. It would be also better if tesseract would generate ALTO. 
 Did you try https://github.com/UB-Mannheim/ocr-fileformat?
 Yes I have and the generated ALTO isn't valid. It can't be imported to the software I use and also the validator ocr-validate says it's not valid.
 Could you please [create an issue for that project](https://github.com/UB-Mannheim/ocr-fileformat/issues) then and add more details about the problems which you encountered?
  tesseract::TessBaseAPI is not thread safe, I want to create mutliple instances to serve more request, but memory usage is too high, so I want to share the language data between instances
  Hi,
I'm following the instruction for Windows from: https://github.com/tesseract-ocr/tesseract/wiki/Compiling
I have cloned the master branch today, copied cppan and installed cmake 3.6.1 for Windows.
cppan runs without issues.
Then I run cmake and it goes with multiple errors. Log attached.
VC 2015 solution file is not created.
Any clues?

[CMake_outputs.zip](https://github.com/tesseract-ocr/tesseract/files/455681/CMake_outputs.zip)
 Thanks for comment, I'll check with cppan upgrade later today.
I assumed the successful output of cmake should generate VS solution. I couldn't find any .sln file in the build directory. Should it be there, or somewhere else?
 Ok, so let's clarify: yes, I follow these instructions. I clone the tesseract repo. Build directory doesn't exist and I create it as described in the instruction. Inside build dir, I run cmake, and it finishes with errors. Logs were attached. Solution (.sln) file is not created. I will double check it later today (don't have access to my dev machine now) but I'm really quite confident it hasn't been created.
 Double checked, the .sln file is not created in the build dir.
Note, the cmake run is full of this kind of errors:

-- Build files have been written to: C:/Users/jarek/.cppan/storage/obj/03/76/d289/build/amd64-msvc-19.0-32
CMake Error at C:/Users/jarek/.cppan/storage/obj/03/76/d289/generate.cmake:106 (include):
  include could not find load file:

```
C:/Users/jarek/.cppan/storage/obj/03/76/d289/build/amd64-msvc-19.0-32/exports/pvt_cppan_demo_gif__5_1_4-fixed.cmake
```

Call Stack (most recent call first):
  cppan/CMakeLists.txt:45 (include)

Note the ...-fixed.cmake include error. In the folder where this file is expected to reside, there are these files:
06.09.2016  18:52             2,140 cppan-helpers-private.cmake
06.09.2016  18:52             2,322 cppan-helpers.cmake
06.09.2016  18:52             2,816 cppan.cmake
06.09.2016  18:55                 0 pvt_cppan_demo_gif__5_1_4-aliases.cmake
06.09.2016  18:52             4,707 pvt_cppan_demo_gif__5_1_4.cmake

Any clue? I have zero experience with cppan and cmake, so no idea how to attempt to resolve it.
 Tried that, didn't help.
 I was unable to get all log into a single file.
I've once again deleted whole content of C:/Users/jarek/.cppan and removed the build directory in tesseract folder.
run cppan again, log attached and then run cmake again, with redirect to cmake.log, also attached, but some errors got printed to the console anyway (they're not present in log or in CMakeError.log file. All console dump is in the cmd.log.
[tesseract_build_log.zip](https://github.com/tesseract-ocr/tesseract/files/457627/tesseract_build_log.zip)
 There seem to be no error log in that folder. I've zipped it all.
[amd64-msvc-19.0-32.zip](https://github.com/tesseract-ocr/tesseract/files/457644/amd64-msvc-19.0-32.zip)
 No luck again :(
Well, thanks for trying. I'm now trying to use just binaries from here: 
https://github.com/charlesw/tesseract/tree/master/src/lib/TesseractOcr/x64
not trivial either as there are no .lib files and need to match .h files to these binaries, but I'm still trying :)
 I think I'm quite close to make it run with binaries above, but if not lucky, I'll try the method above. Any hints on how to this sample from visual studio?
 Heh, as you wrote it, I've just made libtesseract load into my VS project.
Created lib from dll, completed api .h files with all the scattered dependencies and made it load, init and ... fail to recognize my bitmap :) But it works from command line with tesseract.exe, so just something wrong with params i'm passing. I'm not using leptonica. instead trying to ocr a screenshot that I have in memory in BMP format... but we're going off topic here.

Thanks much for all your help!!!
  It conflicts with a previous 'class' declaration for ETEXT_DESC:

include/tesseract/baseapi.h:594:21:
 Struct 'ETEXT_DESC' was previously declared as a class

Signed-off-by: Stefan Weil sw@weilnetz.de
  `..../include/tesseract/baseapi.h:594:21: Struct 'ETEXT_DESC' was previously declared as a class`

In baseapi.h declared as fallows:
`class ETEXT_DESC;`
...

```
/**
   * Make a HTML-formatted string with hOCR markup from the internal
   * data structures.
   * page_number is 0-based but will appear in the output as 1-based.
   * monitor can be used to
   *    cancel the recognition
   *    receive progress callbacks
   */
  char* GetHOCRText(struct ETEXT_DESC* monitor, int page_number);
```

Do we really need struct definition here?

My system:
Xcode 7.3.1
Build version 7D1014

Clang:
Apple LLVM version 7.3.0 (clang-703.0.31)
Target: x86_64-apple-darwin15.6.0
Thread model: posix
 I just sent pull request #415 which fixes this issue.
  Follow the latest compilation guide for windows platform faces VS compile error:

“allheaders.h”: No such file or directory

This error actually comes from CMakeLists.txt:

```
if (NOT USES_CPPAN)
    target_link_libraries       (tesseract ${Leptonica_LIBRARIES})
    export(TARGETS tesseract FILE ${CMAKE_BINARY_DIR}/TesseractTargets.cmake)
else()
    target_link_libraries       (tesseract cppan)
    file(WRITE ${CMAKE_BINARY_DIR}/TesseractTargets.cmake "include(${CMAKE_BINARY_DIR}/cppan.cmake)\n")
    export(TARGETS tesseract APPEND FILE ${CMAKE_BINARY_DIR}/TesseractTargets.cmake)
endif()
```

Here `USES_CPPAN` is undefined, and the if statement is always True. Since Leptonica is loaded from CPPAN, and `target_link_libraries(tesseract cppan)` is never excuted, error happens!

After modify the codes above into

```
target_link_libraries       (tesseract cppan)
file(WRITE ${CMAKE_BINARY_DIR}/TesseractTargets.cmake "include(${CMAKE_BINARY_DIR}/cppan.cmake)\n")
export(TARGETS tesseract APPEND FILE ${CMAKE_BINARY_DIR}/TesseractTargets.cmake)
```

VS builds tesseract305.dll successfully.

`USES_CPPAN` needs definition!
pull request #416 
 Hi, 

in the version i downloaded, the correction discribed in [https://github.com/tesseract-ocr/tesseract/commit/193032a7786fafc4e633869a1b10457f849cb34b](url) is present.

I loaded the project in VS 2013. Compiling the  project results in a long list of errors 

error C1083: "allheaders.h": No such file or directory	d:\projekte\vs\sharpmapprojekte\tesseract\tesseract-master\ccmain\tesseractclass.h	29	1	libtesseract304
error C1083: "allheaders.h": No such file or directory	D:\Projekte\VS\SharpMapProjekte\Tesseract\tesseract-master\ccstruct\imagedata.cpp	33	1	libtesseract304
...
total of 110 errors of that kind.

In all the sourcefiles named the line 

`#include "allheaders.h"`

is found. But file allheaders.h is nowhere to be found.

Can someone please help me? Hi egorpugin,

i tried to follow this guide. 

the batch did not work correct.

`cmake .. -DSTATIC=1`

result:

...
CMake Error at CMakeLists.txt:54 (find_package):
  Could not find a package configuration file provided by "Leptonica"
  (requested version 1.71) with any of the following names:

    LeptonicaConfig.cmake
    leptonica-config.cmake

  Add the installation prefix of "Leptonica" to CMAKE_PREFIX_PATH or set
  "Leptonica_DIR" to a directory containing one of the above files.  If
  "Leptonica" provides a separate development package or SDK, be sure it has
  been installed.
...

What / where is Leptonica?  So i'm trying to ocr the following images but looks we its not doing it 100%. six is written as five. nine is written as 3. Any suggestions?
[deleted]
  Hi,

My Android app is still using an older version of tess two library, which was based on tesseract 3.02. Last time it used to work because it uses trained data for version 3.02, but since tesseract has moved to github seems like we could only download the latest version of trained data now. 

I tested with english and several european languages trained data and it works perfectly fine, however when I try Arabic, Japanese and Chinese the app crashes straightaway upon tesseract init.

My questions are, is the latest trained data in github only works with latest 3.05 version of tesseract? If so, is there a way to download the older versions of trained data? If not what could be the problem for the crash?

Thanks!
 Thanks for the quick response! Cheers
 i have the same question,i will try~~~
  Font names in Java and .NET platforms:

http://www.java2s.com/Tutorial/Java/0261__2D-Graphics/Togetallavailablefontsinyoursystem.htm
http://www.java2s.com/Code/CSharp/GUI-Windows-Form/Getallsysteminstalledfont.htm
https://msdn.microsoft.com/en-us/library/0yf5t4e8.aspx
 I'm afraid that there will be user complains again and again as long as there is that trailing comma. So in the long run it will be worth fixing the issue. To help solving the issue, I started to look at other software using pango, e.g.
https://bugs.launchpad.net/inkscape/+bug/595432
 Can anyone discern a pattern for these comma additions? I'm trying to compose the fontname after the user selected a font from a font dialog (part of an UI) and then pass it to text2image, but there's no consistent pattern that Pango would base on in adding the commas.

As a result of incorrectly composed fontnames, there were a lot of "Could not find font named..." errors. It would be much simpler if there were no commas at all.

Update: I came up with a simple workaround: If it failed with a san-comma fontname, I'd try again with the comma added.
  Hi, When I use VS to compile the following error

 fatal error C1083: 无法打开包括文件:“allheaders.h”: No such file or directory
Excuse me is the reason?
 Use latest installer for windows from
https://github.com/UB-Mannheim/tesseract/wiki

ShreeDevi

---

भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Thu, Sep 1, 2016 at 2:18 PM, zdenop notifications@github.com wrote:

> You forget to read instructions ;-)
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/407#issuecomment-244015951,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_oxnScEQkuJqWz09xxrQbjZPSjBmkks5qlpFCgaJpZM4Jyc9o
> .
  A haystack which is shorter than the needle resulted in negative value
for length_haystack which was forced to a very large unsigned value.

The resulting buffer overflow while reading the haystack would crash
text2image when it was called with a short font name.

Signed-off-by: Stefan Weil sw@weilnetz.de
 It's nearly identical to my implementation. Instead of

```
length_haystack = length_haystack - length_needle + 1;
for (i = 0; i < length_haystack; i++)
```

I used the shorter

```
length_haystack -= length_needle;
for (i = 0; i <= length_haystack; i++)
```
  Hi, 

I'm on compiling on Ubuntu 14.04.5 at ./configure stage and got error below.
I don't need to install training tools.

```
# ./configure
<skip>
configure: WARNING: Training tools WILL NOT be built because of missing icu library.
configure: WARNING: Try to install libicu-devel package.
./configure: line 17228: syntax error near unexpected token `pango,'
./configure: line 17228: `PKG_CHECK_MODULES(pango, pango, have_pango=true, have_pango=false)'
```

Here's the autoconf version

```
# autoconf --version
autoconf (GNU Autoconf) 2.69
Copyright (C) 2012 Free Software Foundation, Inc.
License GPLv3+/Autoconf: GNU GPL version 3 or later
<http://gnu.org/licenses/gpl.html>, <http://gnu.org/licenses/exceptions.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

Written by David J. MacKenzie and Akim Demaille.
```

How can to fix it?

Thanks,
 3.05.00dev
download the zip from github
 Oops forgot to mention. I run it and looks OK.

```
# ./autogen.sh
Running aclocal
Running libtoolize
libtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, `config'.
libtoolize: copying file `config/ltmain.sh'
libtoolize: putting macros in AC_CONFIG_MACRO_DIR, `m4'.
libtoolize: copying file `m4/libtool.m4'
libtoolize: copying file `m4/ltoptions.m4'
libtoolize: copying file `m4/ltsugar.m4'
libtoolize: copying file `m4/ltversion.m4'
libtoolize: copying file `m4/lt~obsolete.m4'
Running autoheader
Running automake --add-missing --copy
configure.ac:321: installing 'config/compile'
configure.ac:86: installing 'config/config.guess'
configure.ac:86: installing 'config/config.sub'
configure.ac:69: installing 'config/install-sh'
configure.ac:69: installing 'config/missing'
api/Makefile.am: installing 'config/depcomp'
Running autoconf

All done.
To build the software now, do something like:

$ ./configure [--enable-debug] [...other options]
```
 Hmmm... What the right solution on this? Thanks 
 Try

./autogen.sh
autoreconf -ivf
./configure

ShreeDevi

---

भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Aug 31, 2016 at 5:28 PM, Bayu Widyasanyata <notifications@github.com

> wrote:
> 
> Hmmm... What the right solution on this? Thanks
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/405#issuecomment-243742032,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o6yjw6iYBVnU4C7zEuaFQ5PHF-gmks5qlWxMgaJpZM4JxZUl
> .
 @Shreeshrii it works! thanks bro! :+1:  taken from **autoreconf** man page
`By default, it only remakes those files that are older than their sources.`

@amitdo here's the output:

```
# dpkg -l | grep pkg-config
ii  pkg-config                            0.26-1ubuntu4                       amd64        manage compile and link flags for libraries
```

@zdenop It's fine! :-)

Should this "autoreconf -ivf" add to wiki?
Thanks!
 Just add some notes. The problem still exist until we should also install the pango lib dev (apt-get install libcogl-pango-dev). I thought it confuses as described on Wiki (https://github.com/tesseract-ocr/tesseract/wiki/Compiling), while it's not necessary to install (lib pango dev) if we're not plan to install training tools.
 Just add some notes. The problem still exist until we should also install the pango lib dev (apt-get install libcogl-pango-dev). I thought it confuses as described on Wiki (https://github.com/tesseract-ocr/tesseract/wiki/Compiling), while it's not necessary to install (lib pango dev) if we're not plan to install training tools.
 That was happened to one of my server. To ensure I will reinstall from fresh on my new vm box, and update / or reopen this issue if it problems.
 Hi, Just want to update if it was fine when I installed without pango lib-dev packages (no training tools). Just got WARN messages on config.log. Thanks!
  There is no good reason to suppress useful compiler warnings.

Signed-off-by: Stefan Weil sw@weilnetz.de
  ref: https://groups.google.com/forum/#!msg/tesseract-ocr/S9CIK3jOMWw/vVBZULrJ9xcJ

I tried using bazaar config for user patterns suggested in above post ( \A\A\d\d\d\A\A
) with the latest windows binary. It does not seem to work. Does the functionality work on linux?

input, output and config files attached. I added.txt extension to bazaar and eng.user-patterns in order to upload it here.

![patterntest](https://cloud.githubusercontent.com/assets/5095331/18089323/013e7fa8-6edd-11e6-948a-65b376c7ec4f.png)

OUTPUT

```
0011917
OX345PT
PT7895M
BA409QT
OMOOKM
WE4321M

OOLI9T7
OX345PT
PT789SM
BA409QT
OMOOKMI
WE432LM

OOLI9T7
OX345PT
PT7898M
BA409QT
OMOOKMI
WE432LM


```

[patternbazaar.txt](https://github.com/tesseract-ocr/tesseract/files/444884/patternbazaar.txt)

[bazaar.txt](https://github.com/tesseract-ocr/tesseract/files/444889/bazaar.txt)
[eng.user-patterns.txt](https://github.com/tesseract-ocr/tesseract/files/444890/eng.user-patterns.txt)
 Some other reports of user-patterns and user-words not working

https://groups.google.com/forum/#!topic/tesseract-ocr/5vFqVcJmHnM

http://stackoverflow.com/questions/17209919/tesseract-user-patterns

Has anyone tried this? Does it work?
 I can tell you that in the Tesseract forum many users ask about these files. They are disappointed that there is no effect on accuracy when using them with their input.

The input is usually not a document but something like receipt, passport, car license plate, with a small set of known words/patterns. In addition to the cases mentioned by Amit, there are users who would like
to use the user_words dictionary in addition to Tesseract's wordlist,

some examples of user words could be client names, industry specific
terminology eg. Medical or pharmaceutical.

Is it possible to allow for both kinds of scenarios, based on some config/variable?  @theraysmith  Ray, please also see 
https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/IUtQfIGZVdA/dm0-2n4DCQAJ

for discussion regarding a user looking for encrypted user words list to use with tesseract. Handle pattern by code. It is the only best way and anle customize easily

1. Teseract firstly have to process whole image anyway. We can not do anything to this. 
2. Then they process pattern by their code (i assumed it is bad). We bypass this step
3. Get all result and hadle by regular expression in code. All input is in text or digits so it will be fast, dont worry. 

Hint: Use your input result and regular expression checking online regular expression testing page. It will be great help. 

Hope you solve this @theraysmith 

Please see https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/p80qyGvVvP4/Rd1hlof3CAAJ

reg "recognize only from user word list" please see https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/wnlJcF4zIvU/4cIt9f2iCgAJ

 need to recognize words of medications ( Rare words that are most likely not included in the training data). Also see: https://groups.google.com/d/msgid/tesseract-ocr/ab28b50f-d592-4f48-b813-c03451c4dbb0%40googlegroups.com?utm_medium=email&utm_source=footer  Assertions are good for programming errors, but not for wrong user input.

The new code no longer needs File::ReadFileToStringOrDie, so remove that
method.

Signed-off-by: Stefan Weil sw@weilnetz.de
  The implementation for MS C did not pass the variable arguments to
tprintf.

The standard is supported since C99 / C++11, so one implementation
is sufficient.

Signed-off-by: Stefan Weil sw@weilnetz.de
 VS2010 should work with the new code, see the [Microsoft documentation](https://msdn.microsoft.com/en-us/library/ms177415%28v=vs.100%29.aspx). Please note also that the old code already used C99 / C++11 standard for all Microsoft compilers and also for Windows gcc versions which set `_MSC_VER`, but that it was buggy for all those compilers because it did not pass the variable arguments. The patch fixes this bug for Microsoft compilers.
The patch changes the situation regarding compatibility for really old compilers (neither gcc, clang, msc which all support variadic macros since a long time). I think that is only a theoretical issue and that such compilers would fail compiling Tesseract anyway.
`opencl/oclkernels.h` already contains a variadic macro using `__VA_ARGS__`.
 gcc-3.1.1 already supported the variadic macro syntax used in my patch, see the [online documentation](https://gcc.gnu.org/onlinedocs/gcc-3.1.1/cpp/Variadic-Macros.html#Variadic%20Macros). It was released in [2002](https://gcc.gnu.org/gcc-3.1/).
  > > @Shreeshrii @stweil : please create separate issue for command that crash on linux, so we can track it.
> 
> That command also crashes with SIGSEGV on Linux. This is a bug which needs a fix.

`text2image --fonts_dir= --text ./langdata/san.training_text --outputbase san.exp-1 --ptsize=32 --strip_unrenderable_words --fontconfig_refresh_config_file=false --leading=32 --char_spacing=0.0 --exposure=-1 --find_fonts --min_coverage=.9 --degrade_image=1 --underline_start_prob=.05 --underline_continuation_prob=.01`

[Ref: Issue 396](https://github.com/tesseract-ocr/tesseract/issues/396)
 I noticed that the crash is a "feature", caused by an assertion if `langdata/san.training_text` does not exist. Tesseract forces a SIGSEGV for assertions to improve debug information.

IMHO missing data is a typical user error which should be reported, but not throw an assertion. So replacing the assertion by a conditional `tprintf(...); exit(1);` in `training/fileio.cpp` might be the correct solution. If you agree, I'll send a pull request.
 FYI, in my testing on Windows 10, the crash was unrelated to 'langdata/san.training_text does not exist' since the file was very much there.

I will test further after new windows binary is made available with all these new patches.

Thanks for looking into this.
 @amitdo, thanks for the pointers. PR #402 now does something similar for `fileio`.
  See guys.. I badly need Text2image.exe but i cannot find it anywhere.
Is there any great soul in this world who will take the time to compile that 1 thing and upload it to mediafire or something?
This one thing has consumed 5 months of my life :'-(
I tried to compile it on windows 32 bit but it gave 100+ errors :'-(
Dear c/cpp experts.. Instead of telling everybody how to compile, isn't it a good idea to directly provide a compiled version?
I am not any intelligent software eng. I am just a normal human being.
Why didn't the developers take some time to upload the compiled binaries? :'-(
Somebody please help!
I now feel pain in my heart for wasting 5 months of my life for 1 program.
Somebody please compile 'Text2Image.cpp' for the needy who don't know how to do it.

P.S I have downloaded Tesseract 3.05 but there does not exist any 'text2image.EXE' :'-(
 - This is not the right place for asking questions. Did you read the [FAQ](https://github.com/tesseract-ocr/tesseract/wiki/FAQ)?
- You might try the installer from https://github.com/UB-Mannheim/tesseract/wiki.
 I have tried this before. Even if you get a binary of text2image for
Windows say with cygwin or msys2 it will crash when u run it. There are
some incompatibilities with the code and windows. Just accept that it is
not available on Windows.

As Quan has suggested you can use jtessboxeditor for generating the box
tiff pairs and training.

Or get access to a linux machine.
- sent from my phone. excuse the brevity.

On 28-Aug-2016 11:32 AM, "z0tghvunik" notifications@github.com wrote:

> See guys.. I badly need Text2image.exe but i cannot find it anywhere.
> Is there any great soul in this world who will take the time to compile
> that 1 thing and upload it to mediafire or something?
> This one thing has consumed 5 months of my life :'-(
> I tried to compile it on windows 32 bit but it gave 100+ errors :'-(
> Dear c/cpp experts.. Instead of telling everybody how to compile, isn't it
> a good idea to directly provide a compiled version?
> I am not any intelligent software eng. I am just a normal human being.
> Why didn't the developers take some time to upload the compiled binaries?
> :'-(
> Somebody please help!
> I now feel pain in my heart for wasting 5 months of my life for 1 program.
> Somebody please compile 'Text2Image.cpp' for the needy who don't know how
> to do it.
> 
> P.S I have downloaded Tesseract 3.05 but there does not exist any
> 'text2image.EXE' :'-(
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/396, or mute the
> thread
> https://github.com/notifications/unsubscribe-auth/AE2_o_D9-NssgSMtM4pUJgQllo2hXeBuks5qkSR5gaJpZM4Ju2ym
> .
 @Shreeshrii, there is a new installer on  https://github.com/UB-Mannheim/tesseract/wiki. It includes fixes for text2image.exe. If that binary still crashes, I need all information to reproduce the crash.
 ![image](https://cloud.githubusercontent.com/assets/5095331/18034130/c69f4bc4-6d52-11e6-9122-105fbf4ad585.png)

text2image --fonts_dir= --text ./langdata/ara.training_text --font Arial  --outputbase ara.Arial.exp0
 ```
C:\Users\User\Documents\shree>text2image --text=./langdata/eng.training_txt --outputbase=eng.MSSerifBold.exp0 --font='MS Serif Bold' --fonts_dir=
Unable to open '/tmp/fonts.conf' for writing
Fontconfig error: Cannot load default config file
FcInitiReinitialize failed!!
Could not find font named 'MS.Please correct --font arg.
```
 ![image](https://cloud.githubusercontent.com/assets/5095331/18034165/7a55f636-6d53-11e6-9cfc-a3350cd6a103.png)

text2image --fonts_dir= --text ./langdata/san.training_text --outputbase san.exp-1 --ptsize=32 --strip_unrenderable_words --fontconfig_refresh_config_file=false --leading=32 --char_spacing=0.0 --exposure=-1 --find_fonts --min_coverage=.9 --degrade_image=1 --underline_start_prob=.05 --underline_continuation_prob=.01
 @stweil Thank you for providing the updated binary for text2image - many problems have indeed been fixed since I last looked at it. Thanks to the developers. 

However, it crashed under two situations today.
1. when using font Arial, I tried with eng, ara and san - not sure what causes this, as when font is not found an error is displayed.

`text2image --fonts_dir= --text ./langdata/ara.training_text --font Arial --outputbase ara.Arial.exp0`
1. when trying to find fonts and create images for a particular text - 

`text2image --fonts_dir= --text ./langdata/san.training_text --outputbase san.exp-1 --ptsize=32 --strip_unrenderable_words --fontconfig_refresh_config_file=false --leading=32 --char_spacing=0.0 --exposure=-1 --find_fonts --min_coverage=.9 --degrade_image=1 --underline_start_prob=.05 --underline_continuation_prob=.01`

I will test further and post more feedback later.
 Here is a copy of the terminal log with all commands I tried and their output.
[testlog1.txt](https://github.com/tesseract-ocr/tesseract/files/441149/testlog1.txt)
 The following command is creating the box-tiff pairs with degradation as well as differnt exposure levels as indicated ..

`text2image --fonts_dir= --text ./langdata/san.training_text  --ptsize=32 --degrade_image=1 --leading=32 --char_spacing=0.0  --strip_unrenderable_words --underline_start_prob=.05 --underline_continuation_prob=.01 --font Kokila  --outputbase san.Kokila.exp-1 --exposure=-1`

I have done this testing on Windows 10.
 [san.Kokila.zip](https://github.com/tesseract-ocr/tesseract/files/441153/san.Kokila.zip)
 I tried the latest version of the program uploaded today on Windows10 and found that it now works but is unstable. It would fail for Arial font and could not find Times New Roman (the two fonts are most commonly used). The boxes in the generated box file were not as tight as they could be.

text2image --text=vie-data.txt --outputbase=vie.arial.exp1 --font="Tahoma" --fonts_dir=C:\Windows\Fonts
Rendered page 0 to file vie.arial.exp1.tif
Rtl = 0 ,vertical=0

text2image --text=vie-data.txt --outputbase=vie.arial.exp1 --font=Arial --fonts_dir=C:\Windows\Fonts
Program crashed

text2image --text=vie-data.txt --outputbase=vie.arial.exp1 --font="Courier New" --fonts_dir=C:\Windows\Fonts
Rendered page 0 to file vie.arial.exp1.tif
Rendered page 1 to file vie.arial.exp1.tif
Rtl = 0 ,vertical=0

text2image --text=vie-data.txt --outputbase=vie.arial.exp1 --font="Times New Roman" --fonts_dir=C:\Windows\Fonts
Could not find font named Times New Roman.Please correct --font arg.

text2image --text=vie-data.txt --outputbase=vie.arial.exp1 --font="Arial Unicode MS Regular" --fonts_dir=C:\Windows\Fonts
Rendered page 0 to file vie.arial.exp1.tif
Rtl = 0 ,vertical=0
 > C:\Users\User\Documents\shree>text2image --text=./langdata/eng.training_txt --outputbase=eng.MSSerifBold.exp0 --font='MS Serif Bold' --fonts_dir=

The previous command does not work because CMD on Windows does not handle `'MS Serif Bold'` like a POSIX shell. It passes `'MS` as font. Using `"MS Serif Bold"` should fix that.

> Could not find font named Times New Roman.Please correct --font arg.

It looks like this error messages can be improved by a line break after the first sentence. I'll send a PR which fixes this small detail.

> text2image --fonts_dir= --text ./langdata/san.training_text --outputbase san.exp-1 --ptsize=32 --strip_unrenderable_words --fontconfig_refresh_config_file=false --leading=32 --char_spacing=0.0 --exposure=-1 --find_fonts --min_coverage=.9 --degrade_image=1 --underline_start_prob=.05 --underline_continuation_prob=.01

That command also crashes with SIGSEGV on Linux. This is a bug which needs a fix.
 If you want to compile text2image for windows using VS2015, you can have a look at a fully automated process at
https://github.com/mazoea/te-external-tesseract
using the windows CI environment (appveyor.yml).

It might take a you a while to get the grasp of it (hopefully, hours not months) but you will get your text2image version that you can debug (and send PRs to tesseract).

More details:
1. all the external dependencies are at https://github.com/mazoea/te-external
2. read the Readme to understand the structure used throughout the process
3. see https://github.com/mazoea/te-external/blob/master/appveyor.yml for the real commands and also check the logs by clicking on the build badge in the repository
4. the same goes for https://github.com/mazoea/te-external-leptonica
5. the same goes for https://github.com/mazoea/te-external-tesseract
6. binaries will be in tesseract\projects\output
7. look at #381 

_BUT_
Those repositories are not forks of others, in case they do not have the latest version, you have to update it.  In practice, this means you should checkout tesseract and merge it with latest if not present - for the moment, there should be only a few of them!

Finally, do not expect a bulletproof text2image even after patching - more needs to be done to address several corner cases but you have everything needed for this mission.
 @stweil The problem with font not found message was not just of misplaced period. These fonts are there on Windows but text2image is NOT finding them.

```
C:\Users\User>text2image --text=./langdata/eng.training_txt --outputbase=eng.MSSerifBold.exp0 --font="MS Serif Regular" --fonts_dir=
Could not find font named MS Serif Regular.Please correct --font arg.
```

```
C:\Users\User>text2image --text=./langdata/eng.training_txt --outputbase=eng.Myfont.exp0 --font="Times New Roman" --fonts_dir=C:\Windows\Fonts
Unable to open '/tmp/fonts.conf' for writing
Fontconfig error: Cannot load default config file
FcInitiReinitialize failed!!
Could not find font named Times New Roman.Please correct --font arg.
```

`text2image --list_available_fonts`
shows the fonts in the list

```
 60: Arial

867: Times New Roman,
```

Ok, the above shows that Time New Roman also has a , at end of font name. So I tried with that, and results differ based on order in which the parameters are given etc . eg. --fonts_dir= should be given first .

```
C:\Users\User\Documents\shree>text2image --text=./langdata/eng.training_txt --outputbase=eng.Myfont.exp0 --font="Times New Roman," --fonts_dir=C:\Windows\Fonts
Unable to open '/tmp/fonts.conf' for writing
Fontconfig error: Cannot load default config file
FcInitiReinitialize failed!!
Failed to read file: ./langdata/eng.training_txt
ReadFileToString(filename, out):Error:Assert failed:in file ../../../../training/fileio.cpp, line 85

C:\Users\User\Documents\shree>text2image --text=./langdata/eng.training_txt --outputbase=eng.Myfont.exp0 --font="Times New Roman," --fonts_dir=
Failed to read file: ./langdata/eng.training_txt
ReadFileToString(filename, out):Error:Assert failed:in file ../../../../training/fileio.cpp, line 85

C:\Users\User\Documents\shree>text2image --fonts_dir= --text ./langdata/eng.training_text --font "Times New Roman"  --outputbase eng.Times.exp0
Could not find font named Times New Roman.Please correct --font arg.

C:\Users\User\Documents\shree>text2image --fonts_dir= --text ./langdata/eng.training_text --font "Times New Roman,"  --outputbase eng.Times.exp0
Stripped 3 unrenderable words
Rendered page 0 to file eng.Times.exp0.tif
Rendered page 1 to file eng.Times.exp0.tif
Rtl = 0 ,vertical=0
```
 ```
C:\Users\User\Documents\shree>text2image --text=./langdata/eng.training_text --outputbase=vie.arial.exp1 --font=Arial --fonts_dir=C:\Windows\Fonts
Unable to open '/tmp/fonts.conf' for writing
Fontconfig error: Cannot load default config file
FcInitiReinitialize failed!!
*** PROGRAM CRASHED ***

C:\Users\User\Documents\shree>text2image --text=./langdata/eng.training_text --outputbase=vie.arial.exp1 --font="Arial" --fonts_dir=C:\Windows\Fonts
Unable to open '/tmp/fonts.conf' for writing
Fontconfig error: Cannot load default config file
FcInitiReinitialize failed!!
*** PROGRAM CRASHED ***

C:\Users\User\Documents\shree>text2image --text=./langdata/eng.training_text --outputbase=vie.arial.exp1 --font="Times New Roman," --fonts_dir=C:\Windows\Fonts
Unable to open '/tmp/fonts.conf' for writing
Fontconfig error: Cannot load default config file
FcInitiReinitialize failed!!
Stripped 3 unrenderable words
Rendered page 0 to file vie.arial.exp1.tif
Rendered page 1 to file vie.arial.exp1.tif
Rtl = 0 ,vertical=0
```

both  --font="Arial" and  --font=Arial lead to program crash, even though Arial is listed as a font when usinf --list_available_fonts
--font="Times New Roman," works.

**_PROGRAM CRASHED *_ - the error box looks like shown in this image - there is no message on the console.

## ![image](https://cloud.githubusercontent.com/assets/5095331/18034130/c69f4bc4-6d52-11e6-9122-105fbf4ad585.png)

`Unable to open '/tmp/fonts.conf' for writing`
seems to be related to the default directory being non-writable under windows.

Setting 'FC_CACHEDIR = c:/your/writable/directory' may help.

or

use "LOCAL_APPDATA_FONTCONFIG_CACHE"  location for the cachedir, 

ref: https://bugs.launchpad.net/inkscape/+bug/1196373
 @zdenop OK

Please see my previous comment, in that I have used 
`--fonts_dir=C:\Windows\Fonts`
It still crashes when fontname Arial or "Arial" is used - on windows10.
 @zdenop 

On Windows10, I get the `FcInitiReinitialize failed!!` error when I use `--fonts_dir=C:\Windows\Fonts` which does not come when I use `--fonts_dir=`

```
C:\Users\User\Documents\shree>text2image --fonts_dir= --text ./langdata/eng.training_text --font "Times New Roman,"  --outputbase eng.Times.exp0
Stripped 3 unrenderable words
Rendered page 0 to file eng.Times.exp0.tif
Rendered page 1 to file eng.Times.exp0.tif
Rtl = 0 ,vertical=0

C:\Users\User\Documents\shree>text2image --fonts_dir=C:\Windows\Fonts --text ./langdata/eng.training_text --font "Times New Roman,"  --outputbase eng.Times.exp0
Unable to open '/tmp/fonts.conf' for writing
Fontconfig error: Cannot load default config file
FcInitiReinitialize failed!!
Stripped 3 unrenderable words
Rendered page 0 to file eng.Times.exp0.tif
Rendered page 1 to file eng.Times.exp0.tif
Rtl = 0 ,vertical=0
```
 On further investigation, I see that https://github.com/tesseract-ocr/tesseract/blob/master/training/pango_font_info.cpp overrides system and fontconfig defaults ..

```
STRING_PARAM_FLAG(fonts_dir, "/auto/ocr-data/tesstraining/fonts",
                  "Overrides system default font location");
STRING_PARAM_FLAG(fontconfig_tmpdir, "/tmp",
                  "Overrides fontconfig default temporary dir");
```

The `FcInitiReinitialize failed!!` error when using `--fonts_dir=C:\Windows\Fonts` disappears when specifying `fontconfig_tmpdir` in commandline. 

When used the first time, it creates `fonts.conf` and a cache file in the specified directory which takes some time. After that, there is no delay in building cache.

```
C:\Users\User\Documents\shree>text2image --fonts_dir=C:\Windows\Fonts --fontconfig_tmpdir=C:\Users\User\Documents\shree --text ./langdata/san.training_text  --outputbase
san.exp-1  --font FreeSerif
Rendered page 0 to file san.exp-1.tif
Rendered page 1 to file san.exp-1.tif
Rtl = 0 ,vertical=0

C:\Users\User\Documents\shree>text2image --fonts_dir=C:\Windows\Fonts --fontconfig_tmpdir=C:\Users\User\Documents\shree --text ./langdata/san.training_text  --outputbase
san.exp-1  --font FreeSerif --ptsize=32 --strip_unrenderable_words --fontconfig_refresh_config_file=false --leading=32 --char_spacing=0.0 --exposure=-1 --min_coverage=.9
--degrade_image=1 --underline_start_prob=.05 --underline_continuation_prob=.01
Rendered page 0 to file san.exp-1.tif
...
Rendered page 11 to file san.exp-1.tif
Rtl = 0 ,vertical=0

```
 As of now, the two errors still unexplained with text2image under Windows are 
1. Use of Arial font
2. Use of --find_fonts

@zdenop I can test and report errors to Pango/FOntConfig, but tesseract does not provide any error info that I can refer to.
 I'm currently working on the problem with Arial. That font is found (otherwise there would be an error message), but results in SIGSEGV - maybe from an assertion. It looks like Windows buffers console messages and fails to print them before raising the SIGSEGV.
 Thanks, Stefan.

ShreeDevi

---

भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Aug 31, 2016 at 5:36 PM, Stefan Weil notifications@github.com
wrote:

> I'm currently working on the problem with Arial. That font is found
> (otherwise there would be an error message), but results in SIGSEGV - maybe
> from an assertion. It looks like Windows buffers console messages and fails
> to print them before raising the SIGSEGV.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/396#issuecomment-243743876,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o-7TkoUbxqsA68wy6DYgPsCh1Qqhks5qlW5jgaJpZM4Ju2ym
> .
 The crash with Arial is caused by a bug in function strcasestr (locally implemented only for Windows, Linux uses the correct GLIBC implementation). Any short font name (5 characters or less) will result in a similar crash. I'll send a pull request which fixes this.
 PR #406 fixes the problem with Arial (and other fonts with short names) for text2image on Windows.
 Problem 2 (use of --find_fonts) is also caused by the buggy strcasestr function and fixed by PR #406:

```
(gdb) r
Starting program: /usr/x86_64-w64-mingw32/sys-root/mingw/bin/text2image --fonts_dir= --text ./langdata/san.training_text --outputbase san.exp-1 --ptsize=32 --strip_unrenderable_words --fontconfig_refresh_config_file=false --leading=32 --char_spacing=0.0 --exposure=-1 --find_fonts --min_coverage=.9 --degrade_image=1 --underline_start_prob=.05 --underline_continuation_prob=.01
[New Thread 10160.0x3ecc]

Program received signal SIGSEGV, Segmentation fault.
0x000000000040e089 in strcasestr (haystack=0x303afd0 "Arial", needle=0x43ba5d <tesseract::kDefaultResolution+457> "Fraktur") at ../../../../training/../vs2010/port/strcasestr.cpp:63
63                  c1 = haystack[i+j];
(gdb) i s
#0  0x000000000040e089 in strcasestr (haystack=0x303afd0 "Arial", needle=0x43ba5d <tesseract::kDefaultResolution+457> "Fraktur") at ../../../../training/../vs2010/port/strcasestr.cpp:63
#1  0x00000000004081c4 in tesseract::PangoFontInfo::ParseFontDescription (this=0x22f770, desc=0x3020000) at ../../../../training/pango_font_info.cpp:237
#2  0x0000000000408242 in tesseract::PangoFontInfo::ParseFontDescriptionName (this=0x22f770, name=...) at ../../../../training/pango_font_info.cpp:243
#3  0x000000000040a9ca in tesseract::StringRenderer::set_font (this=0x22f770, desc=...) at ../../../../training/stringrenderer.cpp:134
#4  0x000000000040a944 in tesseract::StringRenderer::StringRenderer (this=0x22f770, font_desc=..., page_width=3600, page_height=4800) at ../../../../training/stringrenderer.cpp:128
#5  0x0000000000402b61 in main (argc=1, argv=0x30389d0) at ../../../../training/text2image.cpp:462
(gdb) p i
$1 = 393264
(gdb) p length_haystack
$2 = 18446744073709551615
```
 The latest version has fixed the issue with Arial font. Thank you.

Clearly, the tool produces inconsistencies in font names. Why is "Times New Roman," a valid name, especially it's a plain style?

298: Times New Roman,
299: Times New Roman, Bold
300: Times New Roman, Bold Italic
301: Times New Roman, Italic
302: Trebuchet MS
303: Trebuchet MS Bold
304: Trebuchet MS Bold Oblique
305: Trebuchet MS Oblique
306: Verdana
307: Verdana Bold
308: Verdana Bold Oblique
309: Verdana Oblique
310: Yu Gothic
311: Yu Gothic Bold
312: Yu Gothic Bold Oblique
313: Yu Gothic Light, Light
314: Yu Gothic Medium, Medium
315: Yu Gothic Medium, Medium Oblique
316: Yu Gothic Oblique

@amitdo Almost all the generated boxes (created in Windows 10) are consistently a bit low and a bit wide. It was reported that having tightly fitted boxes would improve the quality of the generated traineddata file.

![image](https://cloud.githubusercontent.com/assets/1501035/18149420/9784b70c-6fa5-11e6-8396-e14cf428ddf1.png)
 @stweil 

Thank you for the changes to get text2image working on windows and for making the latest version available via installer at https://github.com/UB-Mannheim/tesseract/wiki

I have added a link to the same from https://github.com/tesseract-ocr/tesseract/wiki so that it is easily accessible.
  Hello, everyone.

I have been developing text detecting APP with tesseract.

I have found weird issue that tesseract could not detect large texts on image.

Here is the original image:
http://i67.tinypic.com/23ur420.jpg

When I apply tesseract to this image, I get some text like this:

```
GETUNTUPUF

BUBBLE.

BEFORE YOUR
COMPETITION
DUES
```

(NOTE: it does not matter to detect text correctly or not, I am just interested whether tesseract detects text or not.)

Here is the image I had detect text area from the original image.
http://i67.tinypic.com/qovfj9.png

Unfortunately when I apply tesseract to this image, I have got no text at all.

Any idea?
  I am using 3.04 tesseract ocr. Running command line like below gives me better result compared to programmatically calling the api.
"tesseract Page_00001_IP.tif Page_00001_IP -l eng -psm 4"

The api is called as follows.
                        var inputName = Path.GetFileName(imageFile).Replace(Path.GetExtension(imageFile), "");
                        using (var page = engine.Process(img, inputName, PageSegMode.SingleColumn))
                        {
                            text = page.GetText();
                        }
I have created the .uzn file same name as the image file. It contains regions specifying Left, Top, Width and Height. I appreciate any help to resolve this.

Thanks,
Ravi
  ![code](https://cloud.githubusercontent.com/assets/5222868/17615147/be407af4-609e-11e6-8d1d-8b711e242506.png)
![env](https://cloud.githubusercontent.com/assets/5222868/17615151/c542e51c-609e-11e6-872d-ff4bf757fbc8.png)
 what is the cause  of this error?
 Lol, check out this link https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-ocr/JZ9G3D5HHNM/A--DXmm2BgAJ  i am using https://github.com/tmbdev/clstm
and https://github.com/tmbdev/ocropy to train some rnn based model ,is there any way  to load such models in Tesseract?
 @amido  thx any way, i notice you working on both projects then came this question 
 @amitdo my fault~
  I'm using the tess-two which is a fork of this repo made use in android projects. Since the latest version, the progress notifier for the word recognition no longer works (it stays at 0% then jumps to 100% when the OCR is done)
  I've managed to make Tesseract OCR work with plain text but i need to make this OCR work with seven segments led displays on an Android Studio project.

I've really tried to dug internet for it but couldn't find useful information about this one. If anyone worked on a similar project I'm desperate for your help. Please.

Thanks from now.
  PDFs generated using either Cygwin (3.04.01) or one of the windows binaries (3.05.00dev) gives offset highlighted text and garbled text when copied, in pdf.js. Attached TIF is output from Scan Tailor. Related: #337 .

Copied from pdf.js:
An  exactmethodis  presentedfor  numericallycalculating,withinthe  frameworkof  thestochasticformulationof  chemicalkinetics,the   timeevolutionof  anyspatiallyhomog-
![image](https://cloud.githubusercontent.com/assets/4030380/17447416/41d2a3ac-5b1c-11e6-9d7f-19a43bcb76d6.png)

Attached txt output from tesseract:
An exact method is presented for numerically calculating, within the framework of the
stochastic formulation of chemical kinetics, the time evolution of any spatially homog-

[Gillespie-000.txt](https://github.com/tesseract-ocr/tesseract/files/404420/Gillespie-000.txt)
[Gillespie-000.pdf](https://github.com/tesseract-ocr/tesseract/files/404417/Gillespie-000.pdf)
[Gillespie-000.zip](https://github.com/tesseract-ocr/tesseract/files/404421/Gillespie-000.zip)
 i think as @ebogaard pointed out this issue and [sumatrapdf #544](https://github.com/sumatrapdfreader/sumatrapdf/issues/544) are very closely related to tesseract #373, which is more than just a pdf renderer issue. a lot of the pdfs referenced in that issue open correctly in adobe but not in other pdf renderers.

would be great to have the pdfs generated by tesseract render correctly in pdf.js
 Should be in v4. Very easy to back port to v3 if desired. @jbreiden
Isn't a new `pdf.ttf` needed? Yes there should be a new pdf.ttf in v4. Today is a major holiday in my country and I probably can't do anything (including take a careful look) until later, possibly Monday. https://en.wikipedia.org/wiki/Thanksgiving
:-) Github Tesseract is currently wrong; there is a mismatch between code and font. 
Checking with Ray to see what else might have been incorrectly synchronized. 
This is the required md5sum.

$ md5sum pdf.ttf
e436074b54ed9cc5bf4789f79059b01b pdf.ttf Everything is now correct on 3.05 and 4.x branches. Should fix vertical highlight problems but not horizontal ones in pdf.js / Firefox @jbreiden

https://wiki.mozilla.org/Mortar_Project

>Project Mortar is aiming to explore the possibility to bring PDFium library and the Pepper API based Flash plugin into Firefox.    (this is more of a comment than an issue but more issues can follow and the discussion might be useful; nevertheless, it might be closed after the PR for 1. )
1. At the moment, text2image expects `fc` backend e.g,:
   https://github.com/tesseract-ocr/tesseract/blob/ba2ea39caaa791b5e5f092953057cb8ffb094a82/training/pango_font_info.cpp#L356
   but if pango is compiled with win32 support, you get the win32 font map first

```
#if defined(HAVE_CAIRO_WIN32)
  if (!backend || 0 == strcmp (backend, "win32"))
    return g_object_new (PANGO_TYPE_CAIRO_WIN32_FONT_MAP, NULL);
#endif
#if defined(HAVE_CAIRO_FREETYPE)
  if (!backend || 0 == strcmp (backend, "fc")
           || 0 == strcmp (backend, "fontconfig"))
    return g_object_new (PANGO_TYPE_CAIRO_FC_FONT_MAP, NULL);
#endif 
```

and nasty crashes follow because of the wrong reinterpret cast.

Fast Solution: specify `fc` backend
Solution: a simple patch will follow that fixes the behaviour for, at least, the most important functionality.
1. If fontconfig is linked as dll, putenv does not get propagated to fontconfig
   https://github.com/tesseract-ocr/tesseract/blob/ba2ea39caaa791b5e5f092953057cb8ffb094a82/training/pango_font_info.cpp#L151

Solution: specify it as environmental variable
1. You cannot use disk paths (e.g., c:) in `FONTCONFIG_PATH` because fontconfig strips slashes from path (FcStrCanonAbsoluteFilename) and then uses 

```
GetFullPathNameW (dirname, 0, NULL, NULL)
```

without the slash and that function, interestingly, behaves like this

```
a file name begins with only a disk designator but not the backslash after the colon, it is interpreted as a relative path to the current directory on the drive with the specified letter.
```

Solution: specify a sane directory
 I think this issue should be reopened.
 He fixed number (1) in his list in one place in the code. That piece of code did cause a crash on Windows+VS, MinGW(64) and Mac.
There is another similar piece of code that will probably cause a crash in some situation on all these platforms.
I suggested a solution above, but it useless to test it on Linux.
 Here is the problematic line:
https://github.com/tesseract-ocr/tesseract/blob/182ca5bc1e/training/pango_font_info.cpp#L367

You need to use `text2image` with the flag `only_extract_font_properties` to trigger the function in which this code lives. 
 The dotted\_circle changes in #381 caused problems (in Linux at least).
See: https://github.com/tesseract-ocr/tesseract/blob/5bb97f966885/training/pango_font_info.cpp#L438  @jbreiden @zdenop 

Are there any plans to make a release with the changes for https://wiki.ubuntu.com/YakketyYak/ReleaseSchedule

Maybe 3.04.02 ?

Thanks!
  Hi,

I was able to successfully train tessdata today after many issues and i would like to suggest some changes that can be added to the training guide
1. the command : unicharset_extractor lang.fontname.exp0.box lang.fontname.exp1.box ... didn't work the first tim.Hence, i have to prefix training/ to make it work.
2. the command: mftraining -F font_properties -U unicharset -O lang.unicharset lang.fontname.exp0.tr lang.fontname.exp1.tr ...
   needs to be corrected to add suffix .txt to font_properties to make it work 
3. In the command: training/set_unicharset_properties -U input_unicharset -O output_unicharset --script_dir=training/langdata

The output is generated to output_unicharset.This output_unicharset should be given as input to the mftraining command. i.e instead of -U unicharset one should give -U output_unicharset

Thank you 
 yes in the unicharset extractor command, two files are generated: unicharset and output_unicharset. I tried with output_unicharset and generated eng.unicharset.I copied the all the files to the tessdata folder to recognize text. It is throwing an error stating unichar in normproto is not in unicharset. Then i used the file named  unicharset, it ran without error. So, i understand is output_unicharset and unicharset works with mftraining but the eng.unicharset generated from mftraining does not work with tesseract but unicharset works.
 Those are the first commands which have to be executed before i can use training. I did that and tried and it throwed me error.It is similar to other commands such training/text2image,training/set_unicharset_properties etc, this has to be prefixed with training/
  I try to use tesseract to directly generate pdfs with an ocr'ed text layer. This is one step of several how pdfsandwich creates searchable pdfs.

The result of the tesseract-subprocess, is a pdf with an image and a text layer and is perfectly searchable.
Probably due to the high resolution input the dimensions of the resulting pdf are very large, which pdfsandwich solves by resizing the pages to more reasonable dimensions.

After this resize, when I open this file in, for example, Acrobat Reader DC, all recognized text is separated by extra spaces. So when it used to read 'hello', now it reads 'h e l l o'. So when you search for hello, the text isn't found.
A more technical explanation about this problem is in this thread: http://bugs.ghostscript.com/show_bug.cgi?id=696116

I thought I had a work around for this, by specifying a smaller DW than the default 500:

```
--- api/pdfrenderer.cpp-orig       2016-07-14 14:55:53.299744815 +0200
+++ api/pdfrenderer.cpp    2016-07-14 15:16:23.619204071 +0200
@@ -543,7 +543,7 @@
                "  /FontDescriptor %ld 0 R\n"
                "  /Subtype /CIDFontType2\n"
                "  /Type /Font\n"
-               "  /DW %d\n"
+               "  /DW 250\n"
                ">>\n"
                "endobj\n",
                5L,         // CIDToGIDMap
```

This solves the issue in Acrobat reader.
But when I put this file in Alfresco DMS, which uses [PDFBox](https://pdfbox.apache.org/) 1.8.4, I get the same problem again: I can only find words when I put spaces between the characters.

Setting the DW to a number smaller than 250 compromizes the text in the ocr'ed layer, so that's no option.

Is there any way to change the font type to a proper width, so most pdf-tools can properly read the text?
 Funny thing: Alfresco uses pdf.js as pdf viewer, and the search in pdf,js is actually working. Meaning: pdf.js doesn't put extra spaces between the characters.

2.pdf doesn't show the problems in both pdf.js and when the text is extracted with pdfbox.

So to summarize:
1. By default, there are extra spaces when converting or extracting text from pdfs generated by tesseract.
2. I found a reasonable workaround by decreasing the '/DW' from 500 to 250. Because of this, the text isn't overlayed perfectly, but that is something I can live with for now.
3. After this change, searching and copying/extracting text works for Acrobat Reader DC, ghostscript and pdf.js, but not for pdbfox.

See attached pdf, which displays those problems: [test-out-git.zip](https://github.com/tesseract-ocr/tesseract/files/373160/test-out-git.zip)
 Is there any roadmap for this rewritten (as I understand) pdf generation?
 Note to other people running into this problem with pdfsandwich and ending up here, suspecting Tesseract: **This is actually a problem with Ghostscript.** pdfsandwich converts the images to PPM, hands those to Tesseract and since those files are missing resolution/DPI information, Tesseract outputs a huge PDF (0,9 by 1,20 metres for A4) but with correct text (i.e. without spaces between letters). Then, pdfsandwich runs this PDF through Ghostscript to resize it back to A4 and this step is what actually messes up the words.

The author of pdfsandwich has a [pre-release version 0.1.5](https://sourceforge.net/p/pdfsandwich/bugs/10/#73bd/3894) which now uses TIF images instead of PPM. And those contain resolution information, so the PDF Tesseract spits out is already in the correct format.

(Side note: Tesseract seems to ignore resolution information from PNG files.)
 Back to the spaces thing, I'd appreciate a retest once Tesseract pdf.ttf font matches the 
following checksum. (It currently does not.)

$ md5sum pdf.ttf
e436074b54ed9cc5bf4789f79059b01b pdf.ttf Tried to re-test this, but got the following error when running pdfsandwich + tesseract.
This is with a just-checked out and compiled tesseract-3.05-branch:

```
ParamsModel::Incomplete line 
ParamsModel::Incomplete line 
ParamsModel::Incomplete line 
ParamsModel::Incomplete line 
ParamsModel::Incomplete line ConvNL

ParamsModel::Incomplete line M,V*aramsModel::Incomplete line M8BraramsModel::Incomplete line u?p{}%(H;_9"xuĿaramsModel::Incomplete line ?C"}܋h
fÿB1
ParamsModel::Incomplete line :l\
nN|?]]
ParamsModel::Incomplete line J
ParamsModel::Incomplete line ?d>ڎW{8
ParamsModel::Incomplete line 9'<J

                                                                                                              ParamsModel::Incomplete line ?

                                                                                                                                              ParamsModel::Incomplete line 
ParamsModel::Incomplete line aramsModel::Incomplete line yf~$G?S<rI#w|&:QParamsModel::Incomplete line 䢿(O`DHYC03E!aramsModel::Incomplete line ?Q!^Q{տ8atv3DNƦ?˄
ParamsModel::Incomplete line 5'                                                                                                                                <"ѿ?ѓnv=oaramsModel::Incomplete line cҺ?
ParamsModel::Incomplete line xÿOҭ
ParamsModel::Incomplete line ?,IiTc?kKZfiP{hmuǿqEȿ
ParamsModel::Incomplete line T?ESWJ&ParamsModel::Incomplete line 92|&&
                                                                      Z
ParamsModel::Incomplete line V

ParamsModel::Incomplete line KaramsModel::Incomplete line 㕳Ibamؿϴȿlm)eParamsModel::Incomplete line U~c[)f!t8M
'?{y+?{?dBi"?--?@N?*+˹e-I?_+?L?K6{b?x?{
                                <
Pa_a+_M-de+::I+c-+-+e+e +i+e ž"0ְ|?}+?
31}
ParamsModel::Unknown parameter ne z#@     A|a꿹xڿkPԿB"
ParamsModel::Incomplete line Ij>      Pa_a+_M-de+::I+c-+-+e+e +i+e O
    iҿnP?9|\?
ParamsModel::Incomplete line ܿ
ParamsModel::Incomplete line aramsModelPa_a+_M-de+::I+c-+-+e+e +i+e ?\È?>:Unknown parameter ^ҿ
Pa_a+_M-de+::I+c-+-+e+e +i+e GU`zCԿa8aş?S.ǿParamsModel::Incomplete line ?Z"
ParamsModel::Incomplete line 

                                        0&=ÿR]S⽅?+>+*'fٿE"_-,Ĳ/FU
                                  ParamsModel::Incomplete line ParamsModel::Incomplete line Ó'C:

                                                                        Pa_a+_M-de+::I+c-+-+e+e +i+e ?c=Q#>~+͜?Fў?yRFU?T+ÿ7P&>:?J?D2\NW?ٿ+
                            ParamsModel::Unknown parameter S.~"r
ParamsModel::Incomplete line qjؿ
                                                                                                                                   Pa_a+_M-de+::I+c-+-+e+e +i+e @+A}?!bS:?F?㖾Th?XF08>?LUdH?Vb?-<ŵz0?Vb?+I
Pa_a+_M-de+::I+c-+-+e+e +i+e ?+^п4<Y_?[Me}|<?W+A|տ*+?)_|G7MG5V?3|<?
```

... And this goed on and on I tried that after with this command:  tesseract -l nld+eng pdfsandwich45aaf9.tif -pdf 
Same problem. Same error, I'm afraid.
I just downloaded new nld.trainneddata & eng.traineddata from here: https://github.com/tesseract-ocr/tessdata/
Might that have something to do with it? https://github.com/tesseract-ocr/tessdata/tree/3.04.00 Okay, that was a bit silly on my end.
But after exchanging the traineddata for the 3.04-versions: tesseract and pdfsandwich+tesseract work.
The resulting pdf from both tesseract and pdfsandwich look good, have a text layer and don't have any extra spaces between characters,
So this seems to be solved. Great!  Hello,

tesseract v3.05
ubuntu v15

I've created the .box and .tr files and i am in the step of mftraining. Since the number of  .tr files are large,i performed a ls command,stored the result to a variable and gave the variable to the mftraining command as shown in the screenshot.Then i executed the .sh file in the terminal and i got an error stating illegal malloc request size as shown in the screenshot.

As shown in the screenshot, the error seems to point to the program globalloc.cpp.

Is there a limit on the number of .tr files i can give as input?
![screen shot 2016-07-18 at 9 30 44 pm](https://cloud.githubusercontent.com/assets/18536586/16947703/7725aef4-4da8-11e6-81a3-02fe7ca0afa4.png)
![screen shot 2016-07-18 at 9 28 04 pm](https://cloud.githubusercontent.com/assets/18536586/16947721/888deed6-4da8-11e6-9d3e-c73d575a0cdb.png)

Can some one please help me with this issue?

Thank you 
 see https://groups.google.com/forum/#!msg/tesseract-ocr/eQ6HQdVE7Cw/3o1XPn2Q0CkJ

search forum and google for the error and possible solutions
 The error in the link is different from mine. I've followed the guide and i've given -O eng.unicharset properly. The difference in my case is multiple .tr files
 No actually the problem was with the unicharset file.Because there were number of unicharset files such as unicharset,eng.unicharset,output_unicharset, it was unknown which one to use. Hence, i started again from the first and used the other file and it worked.I was able to create the eng.trainedata successfully.
 The total count of fonts i gave was 70
 I am not sure.This is what i am getting
![screen shot 2016-07-19 at 6 50 37 pm](https://cloud.githubusercontent.com/assets/18536586/16983034/d3fde502-4e6a-11e6-91f6-45ce77b284bd.png)
 No this is from a c++ program. The output from command line is a file named output with a black blank page.So, your saying there is a implicit limit 64 in tesseract is it?
 oh ok thank you 
  I'm getting a segmentation fault nomatter what image I'm trying to read in. Unfortunatly I'm getting very little info on this.
I have tried with multiple images and sizes and is always getting segfaults, on the other hand reading the same image is not a problem.
It is definitely a problem that you are getting so little information on this matter.

I'm running this on a Gentoo Linux kernel 4.1.12

```
gdb /usr/bin/tesseract
(gdb) run eng.Sans-serif.exp0.tif - box.train
Starting program: /usr/bin/tesseract eng.Sans-serif.exp0.tif - box.train
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib64/libthread_db.so.1".
Page 1

Program received signal SIGSEGV, Segmentation fault.
0x00007ffff7862288 in PAGE_RES_IT::start_page(bool) () from /usr/lib64/libtesseract.so.3
(gdb) backtrace
#0  0x00007ffff7862288 in PAGE_RES_IT::start_page(bool) () from /usr/lib64/libtesseract.so.3
#1  0x00007ffff76de3e4 in tesseract::Tesseract::ApplyBoxTraining(STRING const&, PAGE_RES*) () from /usr/lib64/libtesseract.so.3
#2  0x00007ffff76d4b2e in tesseract::TessBaseAPI::Recognize(ETEXT_DESC*) () from /usr/lib64/libtesseract.so.3
#3  0x00007ffff76d4dc2 in tesseract::TessBaseAPI::ProcessPage(Pix*, int, char const*, char const*, int, tesseract::TessResultRenderer*) () from /usr/lib64/libtesseract.so.3
#4  0x00007ffff76d5356 in tesseract::TessBaseAPI::ProcessPagesMultipageTiff(unsigned char const*, unsigned long, char const*, char const*, int, tesseract::TessResultRenderer*, int) ()
   from /usr/lib64/libtesseract.so.3
#5  0x00007ffff76d5846 in tesseract::TessBaseAPI::ProcessPagesInternal(char const*, char const*, int, tesseract::TessResultRenderer*) () from /usr/lib64/libtesseract.so.3
#6  0x00007ffff76d5ca0 in tesseract::TessBaseAPI::ProcessPages(char const*, char const*, int, tesseract::TessResultRenderer*) () from /usr/lib64/libtesseract.so.3
#7  0x000000000040247b in main ()
```
 Still giving me a segfault, I have pulled from got version 3.04.01 and its fixed.
I'm going to commit a new rebuild to gentoo repo. Probably I will make 2 one versioned and one bleeding.
 Sorry for the late reply, been having a lot of work lately getting a system deployed and ready for investors.
I got the tesseract working, I manually compiled the 3.04.01 from git, I see its in the gentoo repo now that nice too.
In the end I found an old bug in our program that had created some bad file ending bytes that did not show up in gedit.
The reason for this is my system actually finds the text on its own first, but the algorithm is very slow, but very strong, and almost always finds the right letters since it's actually a modified robot pathfinder algorithm. So the system is writing the training files for tess and then we use tess for high speed ocr.

Anyways thanks for your help
  please， the digital accuracy rate is ok，about 90%， how to train can improve the digital accuracy rate（30%）？thank you！
  Hi,
I just found out it can not read from a file having transparent background!
![join](https://cloud.githubusercontent.com/assets/1222935/16919086/f631ea6a-4d25-11e6-99b1-0008f53daadb.jpg)
![join](https://cloud.githubusercontent.com/assets/1222935/16919087/f687b788-4d25-11e6-8351-8d372aea2448.png)

See yourself!
When I use the png with transparent background, it fails.
Using the same JPG file, it runs beautifully.
  I am asking why there is not specific ./configure variable for the location of the language data (i.e. what can be also done with TESSDATA_PREFIX environment variable).

What I suggest is a possibility to hardcode the path the language data while compiling tesseract-
 @zdenop do you mean, TESSDATA_PREFIX follows the optional datadir option ?
 @jbreiden just as an proposal to add a comment in the `configure --help` that datarootdir must contain the /tessdata directory unless this is defined by the TESSDATA_PREFIX

Current --help shows:

```
  --datarootdir=DIR     read-only arch.-independent data root [PREFIX/share]
  --datadir=DIR         read-only architecture-independent data [DATAROOTDIR]
```
 @Wikinaut, Tesseract for Windows uses a different method to find `tessdata`. A fixed TESSDATA_PREFIX would not work on Windows, because there is no fixed installation path.
 @jbreiden wrote
> There is. Debian uses -DTESSDATA_PREFIX=/usr/share/tesseract-ocr/

just for the record:

On my debian 8 system, configured with `./configure --enable-debug` only, tesseract wants to have the language files in 
`/usr/local/share/tessdata`
  Showing them in a window (default) is not acceptable for a console
application like Tesseract which must be able to work in batch mode.

Signed-off-by: Stefan Weil sw@weilnetz.de
 All precompiled TIFF libraries for Windows which I know (e .g. the mingw64-i686-tiff which is part of cygwin) don't define TIF_PLATFORM_CONSOLE.

I don't think that it would be a good idea to require using a special TIFF library for Tesseract.

So yes, in theory your suggestion is an alternative solution, but it is not feasible in practice.
 Some additional notes on the problem which is addressed by this PR:

It looks like many TIFF files (nearly all?) include some vendor specific data which trigger warnings from libtiff, so it is a real and very common problem for Windows users who want to do batch processing. I see these alternatives to handle the problem:
1. Change libtiff. Instead of defaulting to a message window for all warnings, it could do so for GUI applications but use stderr for console applications.
2. Change leptonica. It could offer an interface for setting the handler for warnings, and tesseract could use that interface to set the handler.  Or leptonica could set a reasonable default for GUI / console applications.
3. Change tesseract. That's what I did in my PR.

IMHO in the long run the first alternative would be the best solution, but i see no chance to get it quickly.
 @egorpugin, I added a commit which handles the libtiff dependency, so the code will not break if tiffio.h is unavailable.
 HAVE_TIFFIO_H is set by the current tesseract code – both by configure and by cmake (I tested both variants before adding the last commit). 
 Alternative 1 (see my comments from yesterday) is addressed by this libtiff issue: http://bugzilla.maptools.org/show_bug.cgi?id=2571.

I don't expect that a libtiff version with that modification will be available soon.
 This is the only place we use libtiff directly now.

Can we move it to Leptonica?

CC: @Danbloomberg https://github.com/tesseract-ocr/tesseract/blob/21e739ca2e1e/api/tesseractmain.cpp#L41
https://github.com/tesseract-ocr/tesseract/blob/21e739ca2e1e/api/tesseractmain.cpp#L411 stweil commented on Jul 17, 2016

>Change leptonica. It could offer an interface for setting the handler for warnings, and tesseract could use that interface to set the handler. Or leptonica could set a reasonable default for GUI / console applications. Dan recently added a [handler](https://github.com/DanBloomberg/leptonica/commit/d42a51d29eb8bd086ddee83dd12bab95a9b68238) which suppresses TIFF warnings completely. So we have to wait for a new Leptonica release. 1.72.2 is here, so we may able to drop this code soon.

We need to wait to an update of Mingw-w64's Leptonica PKGBUILD.

Egor will probably update cppan very soon.
  tesseract 3.05.00dev
ubuntu v15
Hi,

I am following the training tesseract and i created font_properties text file with input as

BradleyHandBold 0 1 0 0 0

and tried to use it with mftraining and i got the error
no shape table file present
failed to load font_properties from font_properties

Since i am doing the training for english language,i skipped shapeclustering step but i thought i have to go back to that step since mftraining is asking for shape table,i executed that code and it throwed error
failed to load font_properties from font_properties

Can someone please help me with this issue?
Thank you 
 Ok thanks...but i am not getting replies in the google group.This is a simple work of creating a txt file with fontname and 5 spaced 1 or 0. I don't understand why this doesn't work.
  Hi,

I am getting the below error in the tesseract training process

unicharset_extractor:symbol lookup error:unicharset_extractor:undefined symbol: _ZNK10UNICHARSET12save_to_fileEP8_IO_FILE

Can someone please help me with this issue?
 ubuntu version 15
tesseract version 3.03
i just gave the command 

unicharset_extractor eng.Arial.exp0.box 

as mentioned in the guide
 I installed ubuntu only yesterday on my virtual machine just to work on tesseract.I downloaded tesseract from Github and built from source according to the instructions on Github.
 Ok i removed tesseract and rebuilt it from source.It's working now thanks
  When running tesseract as root like this:

`tesseract in.tiff out  -l nld+eng pdf`

The output is a proper and functioning pdf.
When I run the same command as an unprivileged user, like this:

`sudo -u userx tesseract in.tiff out  -l nld+eng pdf`

The output is as follows:

```
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Error in fopenWriteStream: stream not opened
Error in pixWrite: stream not opened
Error in fopenReadStream: file not found
Error in extractG4DataFromFile: stream not opened to file
Error in l_generateG4Data: datacomp not extracted
Error in pixGenerateCIData: g4 data not made
Error in l_generateCIDataForPdf: file in.tiff format is 4; unreadable
Error during processing.
```

The unprivileged user has access to both the input and the output file.
Tesseract is compiled with the following options:

```
sudo -u userx tesseract -v
tesseract 3.05.00dev
 leptonica-1.73
  libjpeg 6b (libjpeg-turbo 1.2.90) : libpng 1.5.13 : libtiff 4.0.3 : zlib 1.2.7
```

The mentioned libs are available on the system.
The user has a normal account with shell: userxx:1001:1001::/home/userx:/bin/bash

When I let tesseract output to txt (so I don't use the 'pdf'-option), there is no error and a txt-file with recognized text is output. This works both for privileged and unprivileged users.
 Yeah, I found that out later as well. But I'm not sure where Tesseract stops and Leptonica begins ;-)

Previously I tried tiff and pbm as sources. Both gave the same errors; the only thing that changed then, was the one-before-last error: tiff gives a 'format is 4'- error while pbm gives a 'format is 11'-error.

Just tried it again: when I create a new source and make the type png it actually does work!
After converting this png to tiff, that does work as well, but converting to pbm (which is used by pdfsandwich, which I want to use) still gives the errors. I can open and view the bpm file without problems, though.

What do you make of this? Is this a problem with Tesseract, Leptonica, with the source file(s) or libraries?
 I'm afraid compiling, installing and then executing as userx doesn't improve the situation.
png and tiff are working, pbm still gives the same error:

```
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Error in fopenWriteStream: stream not opened
Error in pixWrite: stream not opened
Error in fopenReadStream: file not found
Error in extractG4DataFromFile: stream not opened to file
Error in l_generateG4Data: datacomp not extracted
Error in pixGenerateCIData: g4 data not made
Error in l_generateCIDataForPdf: file test-source.pbm format is 11; unreadable
Error during processing.
```

I tried to make sure the pbm was converted right, so I used convert with and without the options '-compress none -depth 2'. Both files give the same problem.

See attached the source files

[test-source.zip](https://github.com/tesseract-ocr/tesseract/files/368750/test-source.zip)
 Converted the png with pngtopam, but this time got a pgm (P5, 8 bits) instead of a pbm (P4, 2 bits).
And that actually does work!
When I use convert instead of pngtopam, to create a pgm, this also works.

So it seems the problem wasn't really with using an unprivileged user, it's a problem with pbm as a source filetype.

Should we probably close this issue and open another about that?
 Okay, fair enough. Let's dig deeper.
This is on Centos 7. I try to use pdfsandwich to OCR existing PDFs, which uses a combination of ImageMagick + unpaper + tesseract + Ghostcript.

As Centos doesn't provide all packages or ones that are recent enough, I compiled unpaper 6.1, leptonica 1.73 and tesseract 3.05dev from source.

What does work:
- png to pdf
- tiff to pdf
- pbm to pdf => only when root, not as a regular, unprivileged user
- pgm to pdf (works from the command line, but unpaper has a problem with this type, but that's another problem)

See attached sourcefiles:

[sources.zip](https://github.com/tesseract-ocr/tesseract/files/369888/sources.zip)
 I can confirm the permissions on /tmp/lept are indeed the problem.
When I do 'chmod 777 /tmp/lept/' and then try again: the tesseract-operation works where it previously didn't.

You probably run into this problem if you run tesseract + leptonica as root first, then as another user.
 Thanks for the temporary patch.
I think this bug can be closed as it's really a leptonica problem, which is handled there.
 yes, I made some changes last week on the leptonica github head:

```
https://github.com/danbloomberg/leptonica
```

which I believe, together with the use of the new function l_makeTempFilename(), will resolve the issue for tesseract.  This function was also implemented for windows; it compiles but has not been tested further.

I haven't yet made a new release of leptonica.  That awaits some testing on windows.
  Hello, would it be possible to know what makes tesseract failing to recognize any characters in those images _(I tried many filters but tesseract fails in every cases)_ ? Is‑it because the anti‑aliasing is huge or because there’s no space between letters ?

![cantal](https://cloud.githubusercontent.com/assets/3824869/16715547/6952422c-46e3-11e6-8ec6-a24a40f4aa45.jpeg)
![ackskin](https://cloud.githubusercontent.com/assets/3824869/16715571/22e588f2-46e4-11e6-8c39-03894e934059.jpeg)

thanks,
 Heh…  those are Captcha images – where the text has been distorted so 
that it is cannot be recognized by software like OCR.

The distortions are designed so that only a real human can read the text.

Tesseract will never be able to recognize this correctly.

-= Rich

From: Laël Cellier [mailto:notifications@github.com] 
Sent: Sunday, July 10, 2016 3:42 PM
To: tesseract-ocr/tesseract tesseract@noreply.github.com
Subject: [tesseract-ocr/tesseract] information about failure to recognize any charaters in those images (#363)

Hello, would it be possible to know what makes tesseract failing to recognize any characters in those images (I tried many filters) ? Is‑it because the anti‑aliasing is huge or because there’s no space between letters ?

 https://cloud.githubusercontent.com/assets/3824869/16715547/6952422c-46e3-11e6-8ec6-a24a40f4aa45.jpeg 
 https://cloud.githubusercontent.com/assets/3824869/16715571/22e588f2-46e4-11e6-8c39-03894e934059.jpeg 

thanks,

—
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub https://github.com/tesseract-ocr/tesseract/issues/363 , or mute the thread https://github.com/notifications/unsubscribe/AM6iTCymq3N527JbfOzPgwFyMdTCgAISks5qUUrvgaJpZM4JI5ru .  https://github.com/notifications/beacon/AM6iTEQH4-uJ96SBiXawLyKhlv-kwVCdks5qUUrvgaJpZM4JI5ru.gif 
  [StackOverflow query here](http://stackoverflow.com/questions/38165741/long-running-python-2-7-popen-processes-choice-between-resource-unavailability). Just thought I'd bring it up here as well, in case this is a `tesseract` issue and not a `subprocess.Popen` one.
  Hi there,
As everybody knows by now that the Cube engine is being discontinued and a new OCR engine based on LSTM will be introduced, even-though neither the Cube training tools or it's documentation been published.

One can only see that there is purposely neglect and sabotage to the  "RTL" Right to Left language community.
Hindering the developer community of training the Tesseract on RTL languages.

Issues such as that Tesseract while training considers all the letters and words as a single word, and the training is conducted as training a single word, along with many other issues while training RTL languages have been neglected for years and years, Tesseract showing no interest in solving any of the RTL languages issues.

And yet we ask Ray to publish the documentation and tools to train Cube before it is fully removed from tesseract, or at least assure the community that the RTL languages (Arabic, Hebrew...) will be considered in future version releases of Tesseract and future tools will be published helping the developer community in the training process of RTL languages.

List of some issues in the RTL training:
1) Tesseract consider all words as a single 1 Word while training.
"Generated training data for 1 words"

2) Tesseract fail to add some letters while training.
 "APPLY_BOXES: boxfile line \* : FAILURE! Couldn't find a matching blob"

List of some issues in the RTL recognition:
3) Tesseract combines all the letters together while recognition.
4) Tesseract reverse the direction of the words while recognition.

Suggested solution for some of these problems:
2) The "box file" must be created with a criteria inwhich the boxes for each letter must not conjoin or merge with any other box, meaning that each box is an entity for a single glyph and does not have any part of it enter another box of another glyph.

3) Adding "ara.config" file in the folder you wish to train while modifiying it by setting "tessedit_ocr_engine_mode 0" instead of "1", or removing the entire line.
 but what about solving the issues?
 @christophered No one is hindered or attempting to sabotage RTL languages. Get over yourself. You can use and develop a fork of Tesseract 3.0 until the cows come home if you so choose.

The Arabic trained data is available in the tessdata repo, and if you want to submit patches to improve the LTSM engine for Arabic, you can. If not, that's fine, maybe someone else familiar with both the language and Tesseract will come around. In an open source community, you are not entitled to anything...if you want things fixed, submit patches -- you're already pretty close having already identified some problems. @ctrlcctrlv,

You replied to a 9-months old post.

Since then, LSTM code landed in the repo, and the OP opinion had changed.
https://github.com/tesseract-ocr/tesseract/issues/630#issuecomment-271392038  The attached input file in1.pdf was generated by Tesseract 3.05.00dev. I modified it to extract only the first page using pdftk to reduce the size; results are unaffected by this. 

[in1.pdf](https://github.com/tesseract-ocr/tesseract/files/332804/in1.pdf)
[out1.pdf](https://github.com/tesseract-ocr/tesseract/files/332805/out1.pdf)

(The user who forwarded the file to me confirmed that it can be released publicly.)

The OCR text of in1.pdf begins as follows – no problems here:

```
JP. Morgan (Suisse) SA

Account n“ 7973101
Geneva, 3rd June 2016
```

The problem manifests after passing the file through Ghostscript 9.18 to refry the PDF, with no other changes...

```
gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite -o out1.pdf in1.pdf
```

The OCR text is mangled by the insertion of spaces after each recognized letter, and line breaks after certain words (from `pdftotext`), and loss of spaces so that the word boundaries are gone "3rdJune2016". Normally one would pass some other parameters to Ghostscript such as PDF/A conversion, but regardless of parameters the OCR text is mangled.

```
J P .

M o r g a n

A c c o u n t n

( S u i s s e ) S A

7 9 7 3 1 0 1

G e n e v a , 3 r d J u n e 2 0 1 6
```

When viewed in Acrobat XI, every other letter is highlighted. This text is unusable for searching.
![image](https://cloud.githubusercontent.com/assets/1825843/16353613/dddc78ba-3a31-11e6-9aef-baa4c718b1fe.png)

I'd be happy to bring up with the Ghostscript people, but I have feeling that there's something unusual about how Tesseract generates OCR text in PDFs that causes Ghostscript to mishandle them, rather than the converse.

I tried discarding the OCR information, rasterize the PDF as an image, and then running OCR on the image again using tesseract 3.04.01 and the updated pdf.ttf ("sharp2.ttf"). Specifically I used

```
ocrmypdf -f --pdf-renderer tesseract in1.pdf out1_3.04.01.pdf
```

Pinging @jbreiden since you worked with me on the pdf.ttf issues...
 Reported to Ghostscript.
http://bugs.ghostscript.com/show_bug.cgi?id=696874

I tried deskewing the PDF (`ocrmypdf --deskew`) and that fixed the problem. You were able to replicate on an unskewed PDF? That's interesting....
 I found that Acrobat can work with Tesseract-produced PDFs without introducing issues in the OCR text, so it looks like the problem is definitely with Ghostscript/pdfwrite. (I tried using Acrobat for both convert to PDF/A and optimize.)
  Contrary to the comment, the destructor of the base class `GenericVector` calls `GenericVector::clear()`, which actually deletes `data_`, rendering `~DawgPositionVector()` redundant.
 ~~This patch looks wrong to me. @stweil please check it too.~~ @amitdo Why do you think this patch is wrong? @pnordhus

I'm sorry, I thought you were wrong by saying:
>Contrary to the comment, the destructor of the base class GenericVector calls GenericVector::clear(), which actually deletes data_, rendering ~DawgPositionVector() redundant.

But I now realize that you are right :smile:   I just tried to build with Cygwin (64 bit, tesseract + training) and had not problems with the unpatched code.
 On 16/06/2016 18:13, Amit Dovev wrote:

> ```
> I just tried to build with Cygwin (64 bit, tesseract + training) and
> had not problems with the unpatched code.
> ```
> 
> hmmm....
> 
> @matzeri https://github.com/matzeri?

It builds (now, it failed before) but the result is
a hybrid cygwin/windows program not a cygwin program.

Current tesseract binary

$ cygcheck /usr/bin/cygtesseract-3.dll |grep -v '^    '
E:\cygwin64\bin\cygtesseract-3.dll
   E:\cygwin64\bin\cygwin1.dll
   E:\cygwin64\bin\cyglept-5.dll
   E:\cygwin64\bin\cyggcc_s-seh-1.dll
   E:\cygwin64\bin\cygstdc++-6.dll

Building from HEAD without patches

$ cygcheck api/.libs/cygtesseract-3.dll |grep -v '^   '
E:\cyg_pub\devel\tesseract\prove2\tesseract-3.05.00dev_build\api.libs\cygtesseract-3.dll
   E:\cygwin64\bin\cygwin1.dll
   E:\cygwin64\bin\cyglept-5.dll
   E:\cygwin64\bin\cyggcc_s-seh-1.dll
   E:\cygwin64\bin\cygstdc++-6.dll
   C:\Windows\system32\WS2_32.dll
 The build with Cygwin64 fails for the training tools:

```
training/pango_font_info.cpp: In member function 'bool tesseract::PangoFontInfo::ParseFontDescription(const PangoFontDescription*)':
training/pango_font_info.cpp:227:46: error: 'strcasestr' was not declared in this scope
   is_fraktur_ = (strcasestr(family, "Fraktur") != NULL);
```
 Defining `_GNU_SOURCE` fixes the build failure.
 It builds with this additional patch:

```
diff --git a/training/pango_font_info.cpp b/training/pango_font_info.cpp
index e9e6d73..8bc56a0 100644
--- a/training/pango_font_info.cpp
+++ b/training/pango_font_info.cpp
@@ -25,10 +25,13 @@
 #if (defined __MINGW32__) || (defined __CYGWIN__)
 // workaround for stdlib.h and putenv
 #undef __STRICT_ANSI__
-#endif

 #if (defined __MINGW32__)
 #include "strcasestr.h"
+#else
+/* needed for strcasestr in string.h */
+#define _GNU_SOURCE
+#endif
 #endif

 #include <stdlib.h>
```
  https://www.gnu.org/software/libtool/manual/html_node/Link-mode.html

cygwin, mingw, aix are example of platform requiring it. It is not harmful on the other platforms
  Hi guys,

after downloading and manually compiling leptonica and tesseract, I see the following output
when trying to list the version-information of tesseract:

> [con-tom@lapp01awdtst tess_test]$ tesseract -v
> tesseract 3.04.00
>  leptonica-1.72
> 
> [con-tom@lapp01awdtst tess_test]$

Could this be related the following errors which I see when trying to ocr' a given TIFF oder PDF file:

Test 1:

>  tesseract eurotext.pdf test.txt --tessdata-dir /opt/tesseract/tesseract-CuBeInst/tessdata/ -l deu

Generates:

> Tesseract Open Source OCR Engine v3.04.00 with Leptonica
> Error in fopenReadStream: file not found
> %¦¦¦¦ in pixRead: image file not found: %PDF-1.6
> %¦¦¦¦ cannot be read!
> Error during processing.

Test 2:

>  tesseract eurotext.tif test.txt --tessdata-dir /opt/tesseract/tesseract-CuBeInst/tessdata/ -l deu

Generates 2:

> Tesseract Open Source OCR Engine v3.04.00 with Leptonica
> Error in pixReadMemTiff: function not present`

Can I provide additional information? If yes, please let me know which information is needed.

Thx and best regards,

Tom
  In my OCR situation, Tesseract can not identify rows properly. Please see the attach box image below. (Blue squares are boxes found by Tesseract and red areas are marked as problematic area by me)

![qq 20160615195248](https://cloud.githubusercontent.com/assets/3959938/16078734/118747c2-3333-11e6-890a-5eeaac13f217.png)

It seems that Tesseract is not able to find the baseline correctly when the row spacing is small and the image is a little skew --- two chars in two rows are mistakenly vertically merged. Therefore, the OCR quality in "crowded" space is really poor.

How could I imporve the OCR quality in this situation? Are there any params can be used here?
  When I try to create a box file, from the attached, I get the empty page error blow and the box file is empty. (attached file is zipped since gh doesn't accept tif files.)

I'm guessing that the problem is: https://github.com/tesseract-ocr/tesseract/blob/a3ba11b030345d32829b1e8355afea5419978d82/textord/colfind.cpp#L380

is nailed to `false` and if it were possible to pass a command line arg `single_column` that would fix the problem.

When I finally successfully train something I'll see if I can cook up a pr....

```
$ tesseract t.tiff t batch.nochop makebox
Tesseract Open Source OCR Engine v3.04.01 with Leptonica
Page 1
Empty page!!
Empty page!!
Warning in pixReadMemTiff: tiff page 1 not found
```

```
$ tesseract --version                                                       
tesseract 3.04.01
 leptonica-1.72
  libjpeg 8d : libpng 1.6.21 : libtiff 4.0.6 : zlib 1.2.5

$ convert --version
Version: ImageMagick 6.9.4-8 Q16 x86_64 2016-06-07 http://www.imagemagick.org
Copyright: Copyright (C) 1999-2016 ImageMagick Studio LLC
License: http://www.imagemagick.org/script/license.php
Features: Cipher DPC Modules 
Delegates (built-in): bzlib freetype jng jpeg ltdl lzma png tiff xml zlib
```

[t.tiff.gz](https://github.com/tesseract-ocr/tesseract/files/314634/t.tiff.gz)
  Trying to familiarize with the source code I came across  some discrepancies between the file names in the file header comments and the actual file names. Maybe it's pedantic but I thought having the correct names might facilitate reading the code especially when using printouts.

Some files don't appear to have file header comments and boilerplate license statements as recommended by the [Style guide for Google-originated open-source projects](https://github.com/google/styleguide/blob/gh-pages/cppguide.html#L4537), but I don't feel that I were in a position to supply this information. This pertains to the following files:

```
ccutil\ccutil.cpp
neural_networks\runtime\*.cpp
opencl\openclwrapper.cpp
textord\gap_map.cpp
textord\tospace.cpp
training\commandlineflags.cpp
training\set_unicharset_properties.cpp
viewer\svpaint.cpp
```
 Fixing the wrong or out-dated names is good. I suggest to remove all modifications which are not related to such names and then apply this PR. Even if the PR were applied as it is, it would improve the current situation.
 I think @theraysmith should say if he is OK with these changes.
Ray, also see @stweil https://github.com/tesseract-ocr/tesseract/pull/344#issuecomment-239267937

 @jbreiden said something, but for some reason deleted his comment.  recognition hollow word 
how to configure,like this image:
![image](https://cloud.githubusercontent.com/assets/18211005/15988507/2dfa0660-3086-11e6-9e39-f36645a31fed.png)
  I follow these installation steps:
`./autogen.sh`
`./configure`
`make`
`make install`
I run `tesseract -v`, it works.
 then I run `tesseract pic.gif result`, I got that undefine symbol error. How to fix it?
  For front-ends to tesseract, the deliberate segfault [1] created when tesseract encounters a critical error is rather inconvenient, resp. makes it hard to keep the application alive ([2] works first time but fails to recover a second time). I'd like to propose replacing this with something from which applications can recover more easily, such as `raise(SIGABRT)`.

[1] https://github.com/tesseract-ocr/tesseract/blob/master/ccutil/errcode.cpp#L86
[2] https://github.com/manisandro/gImageReader/blob/0628f8c653169cb6bf53d51c6eb8921fcd5f66cb/gtk/src/Recognizer.cc#L171
 IMHO removing the deliberate null pointer access is a good thing. I cannot see why the SEGV would give a stack trace which is more useful than with ABRT (as it is written in the code comment).
 Because it appears that `abort()` terminates the program even if the signal is caught, as soon as the signal handler exits. See also [1] and example program below.

```
#include <csignal>
#include <iostream>

void signal_handler(int signal) {
        std::cout << "Caught signal " << signal << std::endl;
}

int main() {
        std::signal(SIGABRT, signal_handler);
        std::raise(SIGABRT);
//      abort();
        std::cout << "Program survived" << std::endl;
        return 0;
}
```

(Actually IMO the proper solution would be to allow applications to register an error handler to also make it easier to catch the error messages thrown.)

[1] http://stackoverflow.com/questions/20212927/difference-between-raisesigabrt-and-abort-methods
 Is returning to the program which called `ERRCODE::error` a good idea? Or would a typical signal handler use `longjmp`? In this 2nd case, `abort()` would not abort.

And yes, support for user registered error handlers would be the better solution.
 @theraysmith, what's your take on that?  Placed ambigs problem in the mailing list but got no reply.  This I hope you can help.

Having trained tesseract in the Sinhala language we find we cannot get the 0 option in ambigs to work - no correction occurs even though the word is in the dictionary.

Please advise solution. 
  The other binaries simply didn't create a PDF.
But this one in fact does.

So, there's something wrong with the other VC builds.
Am Sa., Jun. 4, 2016 16:07 schrieb Egor Pugin : Ok, and how should I understand what is incorrect? Where is tesseract output, error message, anything?
 Entered this command, did some preparations and pdf is generated.
 Works for me.
 Latest binaries are here: https://www.dropbox.com/s/pxu2hp6mg1a64zj/tesseract-3.05.00dev-win32-vc19-2016-jun-03.zip?dl=1 (https://www.dropbox.com/s/pxu2hp6mg1a64zj/tesseract-3.05.00dev-win32-vc19-2016-jun-03.zip?dl=1)
 —
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub (https://github.com/tesseract-ocr/tesseract/issues/338#issuecomment-223757480), or mute the thread (https://github.com/notifications/unsubscribe/AKYuDajKHXrqZUACFMgTwB900UjD9EKmks5qIYZ_gaJpZM4ItVrv).
 @amitdo: I didn't build any of these myself. I just followed download links and tried the various latest versions I found. Only thing I can say is that the mingW version worked, that the VC version from your link didn't and that the one from the link above works.
  When creating a PDF from a scanned image, the latest dev build creates a space after each character - leaving out the real spaces completely: Tested on windows with the latest dev build.

So scanning this:
**products according to the attached customerlist No.**

becomes this:
**p r o d u c t s a c c o r d i n g t o t h e a t t a c h e d c u s t o m e r l i s t N o .**
 Yes it's the cygwin version. The current VS Version does'nt create PDF versions for me at all.
The problem exists with all samples - no matter what examples I'm using.

Here are some of them:
[sample1.txt](https://github.com/tesseract-ocr/tesseract/files/292199/sample1.txt)
[sample1.pdf](https://github.com/tesseract-ocr/tesseract/files/292200/sample1.pdf)
![sample1](https://cloud.githubusercontent.com/assets/10890765/15690874/fc4826d2-2785-11e6-8997-aa462f27a27e.png)

[sample2.pdf](https://github.com/tesseract-ocr/tesseract/files/292204/sample2.pdf)
![sample2](https://cloud.githubusercontent.com/assets/10890765/15690907/25f617aa-2786-11e6-97a8-6efc9598d5dd.png)
[sample2.txt](https://github.com/tesseract-ocr/tesseract/files/292205/sample2.txt)

[sample3.pdf](https://github.com/tesseract-ocr/tesseract/files/292217/sample3.pdf)
![sample3](https://cloud.githubusercontent.com/assets/10890765/15690995/92605a18-2786-11e6-92cd-81aa75facf90.png)
[sample3.txt](https://github.com/tesseract-ocr/tesseract/files/292218/sample3.txt)
 SumatraPDF. The viewer hasn't had any problems at all so far. And we're using it on several computers for years now including all our customers.
 You're right. I tested it in other PDF readers and there does not seem to be an obvious problem in the PDF itself. I report the problem to the developers of SumatraPDF instead.
 This I'll do :) Thanks
  The option is visible in the 2nd step of the merge process: first you select "Merge pull request", then you can change the kind of merge during the confirmation.
 Yes, it is not so nice.

Squashing can also be done in your local copy of the repository (`git rebase -i`, then update your pull request with `git push -f`). I personally prefer that variant as it avoids the problem with the GitHub user interface.
  This is not strictly necessary, but recommended in the GNU autoconf manual.
No [] was added to arguments like true or false.

Signed-off-by: Stefan Weil sw@weilnetz.de
 This PR addresses issue #100.
 Thanks, I added that one now, too.
  So I just discovered this project, but I plan on implementing this on a very low powered ("performance") microcontroller. 

Is 2 x 300 MHz 32bit with 1 megabyte ROM & 512 kilobyte RAM enough?
Could I squeeze it down even further. I'd need it to be real time too.

Any benchmarking or related projects I could look in to, thank you.
  How to build tesseract and training tools  3.04 in windows with VS2015? I have check leptonica, but it's only libtesseract.lib, I need the training tools too like a setup of Tesseract 3.02
  Location: file `ccutil/strngs.cpp`, method `STRING::add_str_double`

Because of a wrong value for `kMaxDoubleSize`, some small values are truncated by one byte.
Example: `-4.0382147e-006` has 16 bytes including the terminating null byte. But `kMaxDoubleSize` has value 15 and the number is truncated to `-4.0382147e-00`. As result, the number becomes way too large by a factor of 10<sup>6</sup>! (I had found such wrong values in `.tr` files inside the parameters for feature `mf`.)

Also the description for `kMaxDoubleSize` is wrong. The largest length for a formatted number with `%.8g` is `-1.2345678e-999<nul>`. The precision of format specifier `g` specifies the maximum number of significant digits. The length including the terminating null byte is 16 (eight digits, two signs, decimal marker, `e`, three exponent digits, null byte).
  Yes, the code is not consistent – sometimes it exits with 0, sometimes it exits with 1.

IMHO, missing arguments are an error condition, so a program should not exit with 0 (which means no error) in that case. 
 I personally use command lines with several arguments and an added `--help` quite often. This pattern is usually supported well. Examples: `ls -l --help`, cp -R --help`. 
  Is there any - approximate - expectation, when will the new LSTM backend for tesseract (presented [here](http://www.primaresearch.org/das2016/assets/DAS2016_Tutorial_Tesseract.pdf) )  be merged into master ? (or at least pushed public)

Regards 
  ![sc](https://cloud.githubusercontent.com/assets/19493015/15432773/dc38d8ca-1eaf-11e6-9ba1-41c3f5a34723.png)

OCR extraction result:
Nam: an 32:
m j..
L1..,.,.,...»1s3mm ssa
L1.:...:.m.,...»1s3;»z:zza 5533
L1c.(..,.a.5.,...».s3;»z:zzs msa
E| luginmjpg 52 J15 B
§  lugIlI7l_Ihum   >s.plvg 1:; ma
L1g.....gs.,...»1s3mzzs sm
mgms
Oulvzr
upznlxegksk
upznlxegksk
upznlxegksk
upznlxegksk
upznlxegksk
upznlxegksk
upznlxegksk
  image: [eurotext.tif](https://github.com/tesseract-ocr/tesseract/blob/master/testing/eurotext.tif)

```
reubano@tokpro [~]⚡ convert eurotext.tif -rotate 3 +repage eurotext_03.tif
reubano@tokpro [~]⚡ convert eurotext.tif -rotate 5 +repage eurotext_05.tif
```

`bug.py`

``` python
#!/usr/bin/python
# -*- coding: utf-8 -*-

from __future__ import print_function, division

from os import path as p, environ
from ctypes import (
    CDLL, POINTER, Structure, c_char_p, c_bool, c_int, c_float, byref)

from ctypes.util import find_library

LIBTESS = find_library('libtesseract.dylib')
LIBLEPT = find_library('liblept.dylib')
TESSDATA_PREFIX = environ.get('TESSDATA_PREFIX', '/opt/local/share')


class TessBaseAPI(Structure):
    pass


class Pix(Structure):
    pass


class TessPageIterator(Structure):
    pass


def create_tess_api(prefix=TESSDATA_PREFIX, lang='eng'):
    tesseract = CDLL(LIBTESS)
    leptonica = CDLL(LIBLEPT)
    base_api = POINTER(TessBaseAPI)
    argtypes = [base_api, c_char_p, c_char_p]

    tesseract.TessBaseAPICreate.restype = base_api
    tesseract.TessBaseAPIInit3.argtypes = argtypes
    tesseract.TessBaseAPIInit3.restype = c_bool
    tesseract.TessBaseAPISetImage2.restype = None
    tesseract.TessBaseAPISetImage2.argtypes = [base_api, POINTER(Pix)]
    tesseract.TessBaseAPIAnalyseLayout.argtypes = [base_api]
    tesseract.TessBaseAPIAnalyseLayout.restype = POINTER(TessPageIterator)
    tesseract.TessPageIteratorOrientation.argtypes = [
        POINTER(TessPageIterator), POINTER(c_int), POINTER(c_int),
        POINTER(c_int), POINTER(c_float)]

    tesseract.TessPageIteratorOrientation.restype = None

    api = tesseract.TessBaseAPICreate()
    tesseract.TessBaseAPIInit3(api, prefix, lang)

    leptonica.pixRead.argtypes = [c_char_p]
    leptonica.pixRead.restype = POINTER(Pix)
    return tesseract, leptonica, api

def get_orientation(tesseract, leptonica, api, path, mode=1):
    tesseract.TessBaseAPISetPageSegMode(api, mode)
    pix = leptonica.pixRead(path)
    tesseract.TessBaseAPISetImage2(api, pix)
    it = tesseract.TessBaseAPIAnalyseLayout(api)

    if it:
        orientation, direction, line_order = c_int(), c_int(), c_int()
        skew = c_float()

        tesseract.TessPageIteratorOrientation(
            it, byref(orientation), byref(direction), byref(line_order),
            byref(skew))

        print('%s: %s' % (path, orientation.value))

if __name__ == '__main__':
    for path in ['eurotext.tif', 'eurotext_03.tif', 'eurotext_05.tif']:
        tesseract, leptonica, api = create_tess_api()
        orientation = get_orientation(tesseract, leptonica, api, path)
```

``` bash
reubano@tokpro [~/Documents/Projects/tesseract]⚡ python bug.py 
eurotext.tif: 0
eurotext_03.tif: 0
Empty page!!
```

CR: https://github.com/sirfz/tesserocr/issues/5
 It would be helpful to have a `CONTRIBUTING` file with that information so that github will [show it on the issues page](https://help.github.com/articles/setting-guidelines-for-repository-contributors/).
 Thanks to [pyocr](https://github.com/jflesch/pyocr/blob/master/src/pyocr/libtesseract/tesseract_raw.py) I figured it out!

``` python
# ... /snip
# https://github.com/jflesch/pyocr/blob/master/src/pyocr/libtesseract/tesseract_raw.py
class OSResults(Structure):
    _fields_ = [
        ('orientations', c_float * 4),
        ('scripts_na', c_float * 4 * (116 + 1 + 2 + 1)),
        ('unicharset', c_void_p),
        ('best_orientation_id', c_int),
        ('best_script_id', c_int),
        ('best_sconfidence', c_float),
        ('best_oconfidence', c_float),
        ('padding', c_char_p * 512),
    ]

# ... /snip

def create_tess_api(prefix=TESSDATA_PREFIX, lang='eng'):
    # ... /snip
    tesseract.TessBaseAPIDetectOS.argtypes = [base_api, POINTER(OSResults)]
    tesseract.TessBaseAPIDetectOS.restype = c_bool
    # ... /snip

def get_orientation(tesseract, leptonica, api, path, mode=0):
    tesseract.TessBaseAPISetPageSegMode(api, mode)
    pix = leptonica.pixRead(path)
    tesseract.TessBaseAPISetImage2(api, pix)
    osr = OSResults()
    it = tesseract.TessBaseAPIDetectOS(api, byref(osr))

    if it and osr:
        orientation, direction, line_order = c_int(), c_int(), c_int()
        skew = c_float()

        tesseract.TessPageIteratorOrientation(
            it, byref(orientation), byref(direction), byref(line_order),
            byref(skew))

        print('%s: %s' % (path, osr.best_orientation_id))
        print('confidence: %s' % osr.best_oconfidence)
```
  This is command i tried:
`tesseract photo.jpeg out -l ara`
This is the error

```
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
Cube ERROR (CubeRecoContext::Load): unable to read cube language model params from /opt/local/share/tessdata/ara.cube.lm
Cube ERROR (CubeRecoContext::Create): unable to init CubeRecoContext object
init_cube_objects(false, &tessdata_manager):Error:Assert failed:in file tessedit.cpp, line 205
```

Obviously i installed tesseract and the arabic language pack.
Thanks
 oops.
This is what i get:
`Error opening data file /opt/local/share/tessdata/eng.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your "tessdata" directory.
Failed loading language 'eng'
Tesseract couldn't load any languages!
Could not initialize tesseract.`
Any idea why? I ran `sudo port install tesseract-ara` on my mac
 I installed english too.
now runing:`tesseract --list-langs` return arabic and english.
still same error when runing `tesseract photo.jpeg out -l ara`
Any help?
 Hey, its now running but not working :(
This is output:
`Warning in pixReadMemJpeg: work-around: writing to a temp file`
and i get an empty out.txt file
 I guess,
thanks
  Tesseract works fine with the original eng.traineddata but when i use my own it segfaults when running the standard:

```
tesseract test.jpg test.txt
```

I have attached my training data if it helps:
[ali_traineddata_files.zip](https://github.com/tesseract-ocr/tesseract/files/268691/ali_traineddata_files.zip)

Here is the output from llvmdb:

``` bash
Tesseract Open Source OCR Engine v3.04.01 with Leptonica
Warning in pixReadMemJpeg: work-around: writing to a temp file
Process 57115 stopped
* thread #1: tid = 0x2101d5, 0x00000001000e94a9 libtesseract.3.dylib`tesseract::Classify::ComputeCharNormArrays(FEATURE_STRUCT*, INT_TEMPLATES_STRUCT*, unsigned char*, unsigned char*) + 161, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x8)
    frame #0: 0x00000001000e94a9 libtesseract.3.dylib`tesseract::Classify::ComputeCharNormArrays(FEATURE_STRUCT*, INT_TEMPLATES_STRUCT*, unsigned char*, unsigned char*) + 161
libtesseract.3.dylib`tesseract::Classify::ComputeCharNormArrays:
->  0x1000e94a9 <+161>: movl   0x8(%r9), %r10d
    0x1000e94ad <+165>: testl  %r10d, %r10d
    0x1000e94b0 <+168>: jle    0x1000e94eb               ; <+227>
    0x1000e94b2 <+170>: movb   (%r15,%r14), %cl
```

Many thanks :)
 Thanks for your replies but after reading those and trying from scratch again, it still throws this segfault, is their another way i can debug it?
  Hello,

I am trying to train Tesseract but unfortunately, my training is failing.

I was trying to train Tesseract but I  encountered a problem when I was about to shapecluster the training data.

**Here is what I got :**

`Reading ./Data/eng.fonf.exp365.tr ...`
`Bad properties for index 3, char I: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 4, char c: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 5, char a: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 6, char n: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 7, char t: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 8, char d: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 9, char o: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 10, char i: 0,255 0,255 0,0 0,0 0,0`
`Bad properties for index 11, char .: 0,255 0,255 0,0 0,0 0,0`
`Building master shape table`
`Computing shape distances...`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances...`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances...`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances...`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances...`
`Stopped with 0 merged, min dist 999.000000`
`Computing shape distances... 0 1 2 3 4 5 6 7 8`
`Stopped with 0 merged, min dist 0.280000`
`Master shape_table:Number of shapes = 9 max unichars = 1 number with multiple unichars = 0`

Then I searched online and found that shapeclustering is not good for anything but Indic language so I skipped it and tried mftraining and **here is what I got** :
`Warning: No shape table file present: shapetable`
`Reading ./Data/eng.fonf.exp365.tr ...`
`Flat shape table summary: Number of shapes = 9 max unichars = 1 number with multiple unichars = 0`
`Warning: no protos/configs for Joined in CreateIntTemplates()`
`Warning: no protos/configs for |Broken|0|1 in CreateIntTemplates()`
`Done!`

I am trying to understand why or how and now that I have researched it for 1 week I think its the unicharset_extractor.

I went into the code of Tesseract and place some _print_ just after and just before the **_if_** checking if wctype is in the system and then went ahead and compiled it. When I executed it, all the prints before were there, but all the ones after were not there... So I think my system does not support wctype, but I am working on Ubuntu 15.10 on virtualbox so I don't understand because it says on the wiki that wctype is not supported is not supported only on older systems..... I made someone else try on another machine, but he had the same error.

[**_Here is a sample of my training data_**](https://drive.google.com/open?id=0B3pGC0Nn9nqBcjhQQXl4MVY2WGc)
 @amitdo no worries. :+1: 
 @amitdo Okay, I read it! Thank you very much, I will test the solution and come back to you as soon as I can and close this issue if it solved it or is the same thing as the other issue. Just going to keep it open for now, in case of emergency! :P 
 Okay, it did not bug... I think this time....

Here is what I did! 
My data seams nice now, not sure though....
Maybe its super bad!!! D:

Anyway, here is what I did and the result just in case someone wants to check it out one day... O_O

`$ set_unicharset_properties --F font_properties --script_dir=Latin.unicharset -U unicharset -O output_unicharsetLoaded`

```
Loaded unicharset of size 12 from file unicharset
Setting unichar properties
Other case C of c is not in unicharset
Other case A of a is not in unicharset
Other case N of n is not in unicharset
Other case T of t is not in unicharset
Other case D of d is not in unicharset
Other case O of o is not in unicharset
Warning: properties incomplete for index 3 = I
Warning: properties incomplete for index 4 = c
Warning: properties incomplete for index 5 = a
Warning: properties incomplete for index 6 = n
Warning: properties incomplete for index 7 = t
Warning: properties incomplete for index 8 = d
Warning: properties incomplete for index 9 = o
Warning: properties incomplete for index 10 = i
Warning: properties incomplete for index 11 = .
Writing unicharset to file output_unicharsetLoad
```

`$ mftraining -F font_properties -U output_unicharsetLoaded -O eng.unicharset`

```
./Data/eng.fonf.exp365.tr
Warning: No shape table file present: shapetable
Reading ./Data/eng.fonf.exp365.tr ...
Flat shape table summary: Number of shapes = 9 max unichars = 1 number with multiple unichars = 0
Warning: no protos/configs for Joined in CreateIntTemplates()
Warning: no protos/configs for |Broken|0|1 in CreateIntTemplates()
Done!
```

`$ cntraining ./Data/eng.fonf.exp365.tr`

```
Reading ./Data/eng.fonf.exp365.tr ...
Clustering ...

Writing normproto ...
```
 @amitdo YES!! IT WORKED! MONTHS OF STUDYING AND WORKING HARD, AND NOW ITS WORKING! IF I COULD KISS YOU, I WOULD!!! THANK YOU VERY VERY MUCH!!!
 @amitdo lol, sorry, it was not only this problem. But I'm a student in an internship and this was very hard because I had never done c++ or any knowledge of AI or deep learning. Now this was the last step before I can get the result of all the hard work I did to train Tesseract and get results.
  How should I select an image and convert it into text?
  Hi,

I get some strange result when I try to train Tesseract.

Some part are very improved comparing to the default eng.tessdata, when some part are strangely added or modified, while the image quality is very good (24 become eat ???; uppercase letter become lowercase; some words are cut in two words; etc)

I think it may be cause by unicharset.

Indeed, when I try to generate a unicharset file with the following command :
`unicharset_extractor eng.palladio-regular.exp8.box`
I get an incomplete file. Here the result :

```
    115
    NULL 0 NULL 0
    Joined 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # Joined [4a 6f 69 6e 65 64 ]
    |Broken|0|1 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # Broken
    d 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # d [64 ]
    i 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # i [69 ]
    f 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # f [66 ]
    e 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # e [65 ]
    r 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # r [72 ]
    n 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # n [6e ]
    t 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # t [74 ]
    N 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # N [4e ]
    w 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # w [77 ]
    A 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # A [41 ]
    c 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # c [63 ]
    l 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # l [6c ]
    s 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # s [73 ]
    p 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # p [70 ]
    a 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # a [61 ]
    g 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # g [67 ]
    2 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 2 [32 ]
    3 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 3 [33 ]
    T 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # T [54 ]
    o 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # o [6f ]
    S 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # S [53 ]
    v 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # v [76 ]
    ~ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ~ [7e ]
    D 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # D [44 ]
    C 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # C [43 ]
    h 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # h [68 ]
    ' 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ' [27 ]
    7 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 7 [37 ]
    « 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # « [ab ]
    : 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # : [3a ]
    #0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # # [23 ]
    1 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 1 [31 ]
    Z 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # Z [5a ]
    _ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # _ [5f ]
    M 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # M [4d ]
    u 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # u [75 ]
    m 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # m [6d ]
    P 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # P [50 ]
    H 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # H [48 ]
    O 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # O [4f ]
    ( 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ( [28 ]
    ) 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ) [29 ]
    q 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # q [71 ]
    y 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # y [79 ]
    | 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # | [7c ]
    U 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # U [55 ]
    0 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 0 [30 ]
    % 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # % [25 ]
    x 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # x [78 ]
    F 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # F [46 ]
    R 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # R [52 ]
    I 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # I [49 ]
    , 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # , [2c ]
    ! 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ! [21 ]
    E 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # E [45 ]
    b 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # b [62 ]
    \ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # \ [5c ]
    8 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 8 [38 ]
    ? 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ? [3f ]
    & 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # & [26 ]
    ; 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ; [3b ]
    B 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # B [42 ]
    k 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # k [6b ]
    - 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # - [2d ]
    > 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # > [3e ]
    L 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # L [4c ]
    . 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # . [2e ]
    — 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # — [2014 ]
    4 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 4 [34 ]
    » 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # » [bb ]
    € 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # € [20ac ]
    W 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # W [57 ]
    J 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # J [4a ]
    é 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # é [e9 ]
    9 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 9 [39 ]
    ® 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # ® [ae ]
    $ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # $ [24 ]
    5 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 5 [35 ]
    } 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # } [7d ]
    [ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # [ [5b ]
    Y 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # Y [59 ]
    § 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # § [a7 ]
    " 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # " [22 ]
    { 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # { [7b ]
    ¢ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # ¢ [a2 ]
    / 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # / [2f ]
    Q 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # Q [51 ]
    6 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # 6 [36 ]
    G 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # G [47 ]
    ” 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # ” [201d ]
    ° 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # ° [b0 ]
    K 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # K [4b ]
    ¥ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # ¥ [a5 ]
    V 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # V [56 ]
    © 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # © [a9 ]
    z 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # z [7a ]
    + 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # + [2b ]
    = 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # = [3d ]
    £ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # £ [a3 ]
    < 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # < [3c ]
    ’ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # ’ [2019 ]
    ‘ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # ‘ [2018 ]
    j 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # j [6a ]
    X 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # X [58 ]
    ] 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ] [5d ]
    * 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # * [2a ]
    “ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # “ [201c ]
    @ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # @ [40 ]
    • 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # • [2022 ]
    – 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # – [2013 ]
    … 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # … [2026 ]
    ^ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # ^ [5e ]
```

When I try to fix it with with set_unicharset_properties:
`set_unicharset_properties --F font_properties -U unicharset -O output_unicharset --script_dir=/`

I get these warnings :

```
    Loaded unicharset of size 115 from file unicharset
    Setting unichar properties
    Other case É of é is not in unicharset
    Warning: properties incomplete for index 3 = d
    Warning: properties incomplete for index 4 = i
    Warning: properties incomplete for index 5 = f
    Warning: properties incomplete for index 6 = e
    Warning: properties incomplete for index 7 = r
    Warning: properties incomplete for index 8 = n
    Warning: properties incomplete for index 9 = t
    Warning: properties incomplete for index 10 = N
    Warning: properties incomplete for index 11 = w
    Warning: properties incomplete for index 12 = A
    Warning: properties incomplete for index 13 = c
    Warning: properties incomplete for index 14 = l
    Warning: properties incomplete for index 15 = s
    Warning: properties incomplete for index 16 = p
    Warning: properties incomplete for index 17 = a
    Warning: properties incomplete for index 18 = g
    Warning: properties incomplete for index 19 = 2
    Warning: properties incomplete for index 20 = 3
    Warning: properties incomplete for index 21 = T
    Warning: properties incomplete for index 22 = o
    Warning: properties incomplete for index 23 = S
    Warning: properties incomplete for index 24 = v
    Warning: properties incomplete for index 25 = ~
    Warning: properties incomplete for index 26 = D
    Warning: properties incomplete for index 27 = C
    Warning: properties incomplete for index 28 = h
    Warning: properties incomplete for index 29 = '
    Warning: properties incomplete for index 30 = 7
    Warning: properties incomplete for index 31 = «
    Warning: properties incomplete for index 32 = :
    Warning: properties incomplete for index 33 = #
    Warning: properties incomplete for index 34 = 1
    Warning: properties incomplete for index 35 = Z
    Warning: properties incomplete for index 36 = _
    Warning: properties incomplete for index 37 = M
    Warning: properties incomplete for index 38 = u
    Warning: properties incomplete for index 39 = m
    Warning: properties incomplete for index 40 = P
    Warning: properties incomplete for index 41 = H
    Warning: properties incomplete for index 42 = O
    Warning: properties incomplete for index 43 = (
    Warning: properties incomplete for index 44 = )
    Warning: properties incomplete for index 45 = q
    Warning: properties incomplete for index 46 = y
    Warning: properties incomplete for index 47 = |
    Warning: properties incomplete for index 48 = U
    Warning: properties incomplete for index 49 = 0
    Warning: properties incomplete for index 50 = %
    Warning: properties incomplete for index 51 = x
    Warning: properties incomplete for index 52 = F
    Warning: properties incomplete for index 53 = R
    Warning: properties incomplete for index 54 = I
    Warning: properties incomplete for index 55 = ,
    Warning: properties incomplete for index 56 = !
    Warning: properties incomplete for index 57 = E
    Warning: properties incomplete for index 58 = b
    Warning: properties incomplete for index 59 = \
    Warning: properties incomplete for index 60 = 8
    Warning: properties incomplete for index 61 = ?
    Warning: properties incomplete for index 62 = &
    Warning: properties incomplete for index 63 = ;
    Warning: properties incomplete for index 64 = B
    Warning: properties incomplete for index 65 = k
    Warning: properties incomplete for index 66 = -
    Warning: properties incomplete for index 67 = >
    Warning: properties incomplete for index 68 = L
    Warning: properties incomplete for index 69 = .
    Warning: properties incomplete for index 70 = —
    Warning: properties incomplete for index 71 = 4
    Warning: properties incomplete for index 72 = »
    Warning: properties incomplete for index 73 = €
    Warning: properties incomplete for index 74 = W
    Warning: properties incomplete for index 75 = J
    Warning: properties incomplete for index 76 = é
    Warning: properties incomplete for index 77 = 9
    Warning: properties incomplete for index 78 = ®
    Warning: properties incomplete for index 79 = $
    Warning: properties incomplete for index 80 = 5
    Warning: properties incomplete for index 81 = }
    Warning: properties incomplete for index 82 = [
    Warning: properties incomplete for index 83 = Y
    Warning: properties incomplete for index 84 = §
    Warning: properties incomplete for index 85 = "
    Warning: properties incomplete for index 86 = {
    Warning: properties incomplete for index 87 = ¢
    Warning: properties incomplete for index 88 = /
    Warning: properties incomplete for index 89 = Q
    Warning: properties incomplete for index 90 = 6
    Warning: properties incomplete for index 91 = G
    Warning: properties incomplete for index 92 = ”
    Warning: properties incomplete for index 93 = °
    Warning: properties incomplete for index 94 = K
    Warning: properties incomplete for index 95 = ¥
    Warning: properties incomplete for index 96 = V
    Warning: properties incomplete for index 97 = ©
    Warning: properties incomplete for index 98 = z
    Warning: properties incomplete for index 99 = +
    Warning: properties incomplete for index 100 = =
    Warning: properties incomplete for index 101 = £
    Warning: properties incomplete for index 102 = <
    Warning: properties incomplete for index 103 = ’
    Warning: properties incomplete for index 104 = ‘
    Warning: properties incomplete for index 105 = j
    Warning: properties incomplete for index 106 = X
    Warning: properties incomplete for index 107 = ]
    Warning: properties incomplete for index 108 = *
    Warning: properties incomplete for index 109 = “
    Warning: properties incomplete for index 110 = @
    Warning: properties incomplete for index 111 = •
    Warning: properties incomplete for index 112 = –
    Warning: properties incomplete for index 113 = …
    Warning: properties incomplete for index 114 = ^
```

And this incomplete file :

```
    115
    NULL 0 Common 0
    Joined 7 0,255,0,255,0,0,0,0,0,0 Latin 1 0 1 Joined # Joined [4a 6f 69 6e 65 64 ]a
    |Broken|0|1 f 0,255,0,255,0,0,0,0,0,0 Common 2 10 2 |Broken|0|1 # Broken
    d 3 0,255,0,255,0,0,0,0,0,0 Latin 26 0 3 d  # d [64 ]a
    i 3 0,255,0,255,0,0,0,0,0,0 Latin 54 0 4 i  # i [69 ]a
    f 3 0,255,0,255,0,0,0,0,0,0 Latin 52 0 5 f  # f [66 ]a
    e 3 0,255,0,255,0,0,0,0,0,0 Latin 57 0 6 e  # e [65 ]a
    r 3 0,255,0,255,0,0,0,0,0,0 Latin 53 0 7 r  # r [72 ]a
    n 3 0,255,0,255,0,0,0,0,0,0 Latin 10 0 8 n  # n [6e ]a
    t 3 0,255,0,255,0,0,0,0,0,0 Latin 21 0 9 t  # t [74 ]a
    N 5 0,255,0,255,0,0,0,0,0,0 Latin 8 0 10 N  # N [4e ]A
    w 3 0,255,0,255,0,0,0,0,0,0 Latin 74 0 11 w # w [77 ]a
    A 5 0,255,0,255,0,0,0,0,0,0 Latin 17 0 12 A # A [41 ]A
    c 3 0,255,0,255,0,0,0,0,0,0 Latin 27 0 13 c # c [63 ]a
    l 3 0,255,0,255,0,0,0,0,0,0 Latin 68 0 14 l # l [6c ]a
    s 3 0,255,0,255,0,0,0,0,0,0 Latin 23 0 15 s # s [73 ]a
    p 3 0,255,0,255,0,0,0,0,0,0 Latin 40 0 16 p # p [70 ]a
    a 3 0,255,0,255,0,0,0,0,0,0 Latin 12 0 17 a # a [61 ]a
    g 3 0,255,0,255,0,0,0,0,0,0 Latin 91 0 18 g # g [67 ]a
    2 8 0,255,0,255,0,0,0,0,0,0 Common 19 2 19 2    # 2 [32 ]0
    3 8 0,255,0,255,0,0,0,0,0,0 Common 20 2 20 3    # 3 [33 ]0
    T 5 0,255,0,255,0,0,0,0,0,0 Latin 9 0 21 T  # T [54 ]A
    o 3 0,255,0,255,0,0,0,0,0,0 Latin 42 0 22 o # o [6f ]a
    S 5 0,255,0,255,0,0,0,0,0,0 Latin 15 0 23 S # S [53 ]A
    v 3 0,255,0,255,0,0,0,0,0,0 Latin 96 0 24 v # v [76 ]a
    ~ 0 0,255,0,255,0,0,0,0,0,0 Common 25 10 25 ~   # ~ [7e ]
    D 5 0,255,0,255,0,0,0,0,0,0 Latin 3 0 26 D  # D [44 ]A
    C 5 0,255,0,255,0,0,0,0,0,0 Latin 13 0 27 C # C [43 ]A
    h 3 0,255,0,255,0,0,0,0,0,0 Latin 41 0 28 h # h [68 ]a
    ' 10 0,255,0,255,0,0,0,0,0,0 Common 29 10 29 '  # ' [27 ]p
    7 8 0,255,0,255,0,0,0,0,0,0 Common 30 2 30 7    # 7 [37 ]0
    « 10 0,255,0,255,0,0,0,0,0,0 Common 31 10 72 «    # « [ab ]p
    : 10 0,255,0,255,0,0,0,0,0,0 Common 32 6 32 :   # : [3a ]p
    #10 0,255,0,255,0,0,0,0,0,0 Common 33 4 33 #   # # [23 ]p
    1 8 0,255,0,255,0,0,0,0,0,0 Common 34 2 34 1    # 1 [31 ]0
    Z 5 0,255,0,255,0,0,0,0,0,0 Latin 98 0 35 Z # Z [5a ]A
    _ 10 0,255,0,255,0,0,0,0,0,0 Common 36 10 36 _  # _ [5f ]p
    M 5 0,255,0,255,0,0,0,0,0,0 Latin 39 0 37 M # M [4d ]A
    u 3 0,255,0,255,0,0,0,0,0,0 Latin 48 0 38 u # u [75 ]a
    m 3 0,255,0,255,0,0,0,0,0,0 Latin 37 0 39 m # m [6d ]a
    P 5 0,255,0,255,0,0,0,0,0,0 Latin 16 0 40 P # P [50 ]A
    H 5 0,255,0,255,0,0,0,0,0,0 Latin 28 0 41 H # H [48 ]A
    O 5 0,255,0,255,0,0,0,0,0,0 Latin 22 0 42 O # O [4f ]A
    ( 10 0,255,0,255,0,0,0,0,0,0 Common 43 10 44 (  # ( [28 ]p
    ) 10 0,255,0,255,0,0,0,0,0,0 Common 44 10 43 )  # ) [29 ]p
    q 3 0,255,0,255,0,0,0,0,0,0 Latin 89 0 45 q # q [71 ]a
    y 3 0,255,0,255,0,0,0,0,0,0 Latin 83 0 46 y # y [79 ]a
    | 0 0,255,0,255,0,0,0,0,0,0 Common 47 10 47 |   # | [7c ]
    U 5 0,255,0,255,0,0,0,0,0,0 Latin 38 0 48 U # U [55 ]A
    0 8 0,255,0,255,0,0,0,0,0,0 Common 49 2 49 0    # 0 [30 ]0
    % 10 0,255,0,255,0,0,0,0,0,0 Common 50 4 50 %   # % [25 ]p
    x 3 0,255,0,255,0,0,0,0,0,0 Latin 106 0 51 x    # x [78 ]a
    F 5 0,255,0,255,0,0,0,0,0,0 Latin 5 0 52 F  # F [46 ]A
    R 5 0,255,0,255,0,0,0,0,0,0 Latin 7 0 53 R  # R [52 ]A
    I 5 0,255,0,255,0,0,0,0,0,0 Latin 4 0 54 I  # I [49 ]A
    , 10 0,255,0,255,0,0,0,0,0,0 Common 55 6 55 ,   # , [2c ]p
    ! 10 0,255,0,255,0,0,0,0,0,0 Common 56 10 56 !  # ! [21 ]p
    E 5 0,255,0,255,0,0,0,0,0,0 Latin 6 0 57 E  # E [45 ]A
    b 3 0,255,0,255,0,0,0,0,0,0 Latin 64 0 58 b # b [62 ]a
    \ 10 0,255,0,255,0,0,0,0,0,0 Common 59 10 59 \  # \ [5c ]p
    8 8 0,255,0,255,0,0,0,0,0,0 Common 60 2 60 8    # 8 [38 ]0
    ? 10 0,255,0,255,0,0,0,0,0,0 Common 61 10 61 ?  # ? [3f ]p
    & 10 0,255,0,255,0,0,0,0,0,0 Common 62 10 62 &  # & [26 ]p
    ; 10 0,255,0,255,0,0,0,0,0,0 Common 63 10 63 ;  # ; [3b ]p
    B 5 0,255,0,255,0,0,0,0,0,0 Latin 58 0 64 B # B [42 ]A
    k 3 0,255,0,255,0,0,0,0,0,0 Latin 94 0 65 k # k [6b ]a
    - 10 0,255,0,255,0,0,0,0,0,0 Common 66 3 66 -   # - [2d ]p
    > 0 0,255,0,255,0,0,0,0,0,0 Common 67 10 102 >  # > [3e ]
    L 5 0,255,0,255,0,0,0,0,0,0 Latin 14 0 68 L # L [4c ]A
    . 10 0,255,0,255,0,0,0,0,0,0 Common 69 6 69 .   # . [2e ]p
    — 10 0,255,0,255,0,0,0,0,0,0 Common 70 10 70 -    # — [2014 ]p
    4 8 0,255,0,255,0,0,0,0,0,0 Common 71 2 71 4    # 4 [34 ]0
    » 10 0,255,0,255,0,0,0,0,0,0 Common 72 10 31 »    # » [bb ]p
    € 0 0,255,0,255,0,0,0,0,0,0 Common 73 4 73 €    # € [20ac ]
    W 5 0,255,0,255,0,0,0,0,0,0 Latin 11 0 74 W # W [57 ]A
    J 5 0,255,0,255,0,0,0,0,0,0 Latin 105 0 75 J    # J [4a ]A
    é 3 0,255,0,255,0,0,0,0,0,0 Latin 76 0 76 é   # é [e9 ]a
    9 8 0,255,0,255,0,0,0,0,0,0 Common 77 2 77 9    # 9 [39 ]0
    ® 0 0,255,0,255,0,0,0,0,0,0 Common 78 10 78 ® # ® [ae ]
    $ 0 0,255,0,255,0,0,0,0,0,0 Common 79 4 79 $    # $ [24 ]
    5 8 0,255,0,255,0,0,0,0,0,0 Common 80 2 80 5    # 5 [35 ]0
    } 10 0,255,0,255,0,0,0,0,0,0 Common 81 10 86 }  # } [7d ]p
    [ 10 0,255,0,255,0,0,0,0,0,0 Common 82 10 107 [ # [ [5b ]p
    Y 5 0,255,0,255,0,0,0,0,0,0 Latin 46 0 83 Y # Y [59 ]A
    § 10 0,255,0,255,0,0,0,0,0,0 Common 84 10 84 §    # § [a7 ]p
    " 10 0,255,0,255,0,0,0,0,0,0 Common 85 10 85 "  # " [22 ]p
    { 10 0,255,0,255,0,0,0,0,0,0 Common 86 10 81 {  # { [7b ]p
    ¢ 0 0,255,0,255,0,0,0,0,0,0 Common 87 4 87 ¢  # ¢ [a2 ]
    / 10 0,255,0,255,0,0,0,0,0,0 Common 88 6 88 /   # / [2f ]p
    Q 5 0,255,0,255,0,0,0,0,0,0 Latin 45 0 89 Q # Q [51 ]A
    6 8 0,255,0,255,0,0,0,0,0,0 Common 90 2 90 6    # 6 [36 ]0
    G 5 0,255,0,255,0,0,0,0,0,0 Latin 18 0 91 G # G [47 ]A
    ” 10 0,255,0,255,0,0,0,0,0,0 Common 92 10 92 "    # ” [201d ]p
    ° 0 0,255,0,255,0,0,0,0,0,0 Common 93 4 93 °  # ° [b0 ]
    K 5 0,255,0,255,0,0,0,0,0,0 Latin 65 0 94 K # K [4b ]A
    ¥ 0 0,255,0,255,0,0,0,0,0,0 Common 95 4 95 ¥  # ¥ [a5 ]
    V 5 0,255,0,255,0,0,0,0,0,0 Latin 24 0 96 V # V [56 ]A
    © 0 0,255,0,255,0,0,0,0,0,0 Common 97 10 97 © # © [a9 ]
    z 3 0,255,0,255,0,0,0,0,0,0 Latin 35 0 98 z # z [7a ]a
    + 0 0,255,0,255,0,0,0,0,0,0 Common 99 3 99 +    # + [2b ]
    = 0 0,255,0,255,0,0,0,0,0,0 Common 100 10 100 = # = [3d ]
    £ 0 0,255,0,255,0,0,0,0,0,0 Common 101 4 101 £    # £ [a3 ]
    < 0 0,255,0,255,0,0,0,0,0,0 Common 102 10 67 <  # < [3c ]
    ’ 10 0,255,0,255,0,0,0,0,0,0 Common 103 10 103 '  # ’ [2019 ]p
    ‘ 10 0,255,0,255,0,0,0,0,0,0 Common 104 10 104 '  # ‘ [2018 ]p
    j 3 0,255,0,255,0,0,0,0,0,0 Latin 75 0 105 j    # j [6a ]a
    X 5 0,255,0,255,0,0,0,0,0,0 Latin 51 0 106 X    # X [58 ]A
    ] 10 0,255,0,255,0,0,0,0,0,0 Common 107 10 82 ] # ] [5d ]p
    * 10 0,255,0,255,0,0,0,0,0,0 Common 108 10 108 *    # * [2a ]p
    “ 10 0,255,0,255,0,0,0,0,0,0 Common 109 10 109 "  # “ [201c ]p
    @ 10 0,255,0,255,0,0,0,0,0,0 Common 110 10 110 @    # @ [40 ]p
    • 10 0,255,0,255,0,0,0,0,0,0 Common 111 10 111 •    # • [2022 ]p
    – 10 0,255,0,255,0,0,0,0,0,0 Common 112 10 112 -  # – [2013 ]p
    … 10 0,255,0,255,0,0,0,0,0,0 Common 113 10 113 ...    # … [2026 ]p
    ^ 0 0,255,0,255,0,0,0,0,0,0 Common 114 10 114 ^ # ^ [5e ]
```

We can see that some parts are missing.

Here from the documentation to see the difference, so the "missing" part :
https://github.com/tesseract-ocr/tesseract/blob/a3ba11b030345d32829b1e8355afea5419978d82/doc/unicharset.5.asc

```
    EXAMPLE (v3.02)

    110
    NULL 0 NULL 0
    N 5 59,68,216,255,87,236,0,27,104,227 Latin 11 0 1 N
    Y 5 59,68,216,255,91,205,0,47,91,223 Latin 33 0 2 Y
    1 8 59,69,203,255,45,128,0,66,74,173 Common 3 2 3 1
    9 8 18,66,203,255,89,156,0,39,104,173 Common 4 2 4 9
    a 3 58,65,186,198,85,164,0,26,97,185 Latin 56 0 5 a
    . . .
```
 > script_dir in set_unicharset_properties should point to a directory that contains a *.unicharset file. 

This is the case, the file I get from `unicharset_extractor` is used as input file by `set_unicharset_properties`.

> For English and other Latin based scripts, the file is Latin.unicharset.
> You can find the *.unicharset files here: https://github.com/tesseract-ocr/langdata

I have some questions:
1. If I follow the documentation, I should use the unicharset file generate by `unicharset_extractor`, because it is adapted to the chosen font. Isn’t it?
2. What if I use the latin.unicharset that do not match the xheight of the chosen font?
3. Why `set_unicharset_properties` still complain when I use latin.unicharset? See below the output:

Is it normal?

```
    Loaded unicharset of size 3504 from file latin.unicharset
    Setting unichar properties
    Other case Ȿ of ȿ is not in unicharset
    Other case Ɀ of ɀ is not in unicharset
    Other case Ɐ of ɐ is not in unicharset
    Other case Ɒ of ɒ is not in unicharset
    Other case Ɜ of ɜ is not in unicharset
    Other case Ɡ of ɡ is not in unicharset
    Other case Ɥ of ɥ is not in unicharset
    Other case Ɦ of ɦ is not in unicharset
    Other case Ɬ of ɬ is not in unicharset
    Other case Ɱ of ɱ is not in unicharset
    Other case Ʇ of ʇ is not in unicharset
    Other case Ʞ of ʞ is not in unicharset
    Other case Μ of µ is not in unicharset
    Other case ϳ of Ϳ is not in unicharset
    Mirror ⧵ of ∕ is not in unicharset
    Mirror ⦸ of ⊘ is not in unicharset
    Mirror ⫞ of ⊦ is not in unicharset
    Mirror ⫤ of ⊨ is not in unicharset
    Mirror ⫣ of ⊩ is not in unicharset
    Mirror ⫥ of ⊫ is not in unicharset
    Warning: properties incomplete for index 1073 = ~
    Warning: properties incomplete for index 1081 = ¨
    Warning: properties incomplete for index 1087 = ¯
    Warning: properties incomplete for index 1090 = ²
    Warning: properties incomplete for index 1091 = ³
    Warning: properties incomplete for index 1092 = ´
    Warning: properties incomplete for index 1096 = ¸
    Warning: properties incomplete for index 1097 = ¹
    Warning: properties incomplete for index 1117 = ˆ
    Warning: properties incomplete for index 1118 = ˇ
    Warning: properties incomplete for index 1135 = ˘
    Warning: properties incomplete for index 1136 = ˙
    Warning: properties incomplete for index 1137 = ˚
    Warning: properties incomplete for index 1138 = ˛
    Warning: properties incomplete for index 1139 = ˜
    Warning: properties incomplete for index 1168 = ̀
    Warning: properties incomplete for index 1169 = ́
    Warning: properties incomplete for index 1170 = ̂
    Warning: properties incomplete for index 1171 = ̃
    Warning: properties incomplete for index 1172 = ̄
    Warning: properties incomplete for index 1173 = ̅
    Warning: properties incomplete for index 1174 = ̆
    Warning: properties incomplete for index 1175 = ̇
    Warning: properties incomplete for index 1176 = ̈
    Warning: properties incomplete for index 1177 = ̉
    Warning: properties incomplete for index 1178 = ̊
    Warning: properties incomplete for index 1179 = ̋
    Warning: properties incomplete for index 1180 = ̌
    Warning: properties incomplete for index 1181 = ̍
    Warning: properties incomplete for index 1182 = ̎
    Warning: properties incomplete for index 1183 = ̏
    Warning: properties incomplete for index 1184 = ̐
    Warning: properties incomplete for index 1185 = ̑
    Warning: properties incomplete for index 1186 = ̒
    Warning: properties incomplete for index 1187 = ̓
    Warning: properties incomplete for index 1188 = ̔
    Warning: properties incomplete for index 1189 = ̕
    Warning: properties incomplete for index 1194 = ̚
    Warning: properties incomplete for index 1195 = ̛
    Warning: properties incomplete for index 1201 = ̡
    Warning: properties incomplete for index 1202 = ̢
    Warning: properties incomplete for index 1203 = ̣
    Warning: properties incomplete for index 1204 = ̤
    Warning: properties incomplete for index 1205 = ̥
    Warning: properties incomplete for index 1211 = ̫
    Warning: properties incomplete for index 1212 = ̬
    Warning: properties incomplete for index 1213 = ̭
    Warning: properties incomplete for index 1214 = ̮
    Warning: properties incomplete for index 1216 = ̰
    Warning: properties incomplete for index 1217 = ̱
    Warning: properties incomplete for index 1218 = ̲
    Warning: properties incomplete for index 1219 = ̳
    Warning: properties incomplete for index 1220 = ̴
    Warning: properties incomplete for index 1221 = ̵
    Warning: properties incomplete for index 1222 = ̶
    Warning: properties incomplete for index 1223 = ̷
    Warning: properties incomplete for index 1224 = ̸
    Warning: properties incomplete for index 1228 = ̼
    Warning: properties incomplete for index 1229 = ̽
    Warning: properties incomplete for index 1230 = ̾
    Warning: properties incomplete for index 1231 = ̿
    Warning: properties incomplete for index 1233 = ́
    Warning: properties incomplete for index 1234 = ͂
    Warning: properties incomplete for index 1236 = ̈́
    Warning: properties incomplete for index 1240 = ͋
    Warning: properties incomplete for index 1248 = ͘
    Warning: properties incomplete for index 1252 = ͜
    Warning: properties incomplete for index 1253 = ͝
    Warning: properties incomplete for index 1254 = ͞
    Warning: properties incomplete for index 1255 = ͟
    Warning: properties incomplete for index 1256 = ͠
    Warning: properties incomplete for index 1257 = ͡
    Warning: properties incomplete for index 1258 = ͢
    Warning: properties incomplete for index 1294 = ً
    Warning: properties incomplete for index 1295 = ٌ
    Warning: properties incomplete for index 1296 = ٍ
    Warning: properties incomplete for index 1297 = َ
    Warning: properties incomplete for index 1298 = ُ
    Warning: properties incomplete for index 1299 = ِ
    Warning: properties incomplete for index 1300 = ّ
    Warning: properties incomplete for index 1301 = ْ
    Warning: properties incomplete for index 1302 = ٓ
    Warning: properties incomplete for index 1303 = ٔ
    Warning: properties incomplete for index 1304 = ٕ
    Warning: properties incomplete for index 1315 = ٰ
    Warning: properties incomplete for index 1317 = ॒
    Warning: properties incomplete for index 1386 = ⁄
    Warning: properties incomplete for index 1406 = ⁪
    Warning: properties incomplete for index 1407 = ⁫
    Warning: properties incomplete for index 1408 = ⁬
    Warning: properties incomplete for index 1409 = ⁭
    Warning: properties incomplete for index 1410 = ⁮
    Warning: properties incomplete for index 1411 = ⁯
    Warning: properties incomplete for index 3101 = ゙
    Warning: properties incomplete for index 3102 = ゚
    Warning: properties incomplete for index 3103 = ゛
    Warning: properties incomplete for index 3104 = ゜
    Writing unicharset to file output_unicharset
```
 To follow up with #316 , I added the line 

/home/ggdhines/github/tesseract/training/set_unicharset_properties -U unicharset -O new_unicharset --script_dir=/home/ggdhines/github/langdata/Latin.unicharset

then new_unicharset looks like:

1 8 0,255,0,255,0,0,0,0,0,0 Common 3 2 3 1      # 1 [31 ]0
2 8 0,255,0,255,0,0,0,0,0,0 Common 4 2 4 2      # 2 [32 ]0
9 8 0,255,0,255,0,0,0,0,0,0 Common 5 2 5 9      # 9 [39 ]0

(Only trying for 3 characters right now). This looks better than before (no null values) but I'm still getting the error:
Bad properties for index 3, char 1: 0,255 0,255 0,0 0,0 0,0
(Repeated for each character.)

@ne0zer0 's questions are good ones.
 Also just realized that the example unicharset file in the Compute the Character Set of the official documents:
; 10 Common 46
b 3 Latin 59
W 5 Latin 40
7 8 Common 66
= 0 Common 93

appears to be out of date (I think that's Tesseract version 2)
 > appears  to be out of date (I think that's Tesseract version 2)

Yes, you should read unicharset(5) doc:
https://github.com/tesseract-ocr/tesseract/blob/a3ba11b030345d32829b1e8355afea5419978d82/doc/unicharset.5.asc

And for `set_unicharset_properties`, where I can find file listing font xheights for all my desired fonts? (Adobe Jenson too)

```
set_unicharset_properties --help
USAGE: set_unicharset_properties
  --debug_level  Level of Trainer debugging  (type:int default:0)
  --load_images  Load images with tr files  (type:int default:0)
  --clusterconfig_min_samples_fraction  Min number of samples per proto as % of total  (type:double default:0.625)
  --clusterconfig_max_illegal  Max percentage of samples in a cluster which have more than 1 feature in that cluster  (type:double default:0.05)
  --clusterconfig_independence  Desired independence between dimensions  (type:double default:1)
  --clusterconfig_confidence  Desired confidence in prototypes created  (type:double default:1e-06)
  --script_dir  Directory name for input script unicharsets/xheights  (type:string default:)
  --configfile  File to load more configs from  (type:string default:)
  --D  Directory to write output files to  (type:string default:)
  --F  File listing font properties  (type:string default:font_properties)
  --X  File listing font xheights  (type:string default:)
  --U  File to load unicharset from  (type:string default:unicharset)
  --O  File to write unicharset to  (type:string default:)
  --T  File to load trainer from  (type:string default:)
  --output_trainer  File to write trainer to  (type:string default:)
  --test_ch  UTF8 test character string  (type:string default:)
```

Or a way to compute these xheights for every kind of fonts?

Maybe, it is a problem with wctype functions on systems? As I read on the documentation:

> If your system supports the wctype functions, t**hese values will be set automatically by unicharset_extractor and there is no need to edit the unicharset file**. On some very old systems (eg Windows 95), the unicharset file must be edited by hand to add these property description codes.
 thanks @amitdo for the help. I'm a little confused though as to why we need to use Latin.unicharset and Common.unicharset. Shouldn't we be teaching Tesseract new fonts based on the actual examples (and box files). Using some preexisting unicharset file makes it seem as if we're not actually training Tesseract on the new font
 > unicharset_extractor produces a unicharset file.
> 
> You need to pass this file to set_unicharset_properties.
> 
> ```
> -U unicharset
> ```

It is exactly what I do.

> Download these files:
> https://raw.githubusercontent.com/tesseract-ocr/langdata/master/Latin.unicharset

Already done.

> https://raw.githubusercontent.com/tesseract-ocr/langdata/master/Common.unicharset

Done after reading your post addressed to ggdhines

> set_unicharset_properties --F font_properties -U unicharset -O output_unicharset --script_dir=/home/ne0zer0/langdata

What did and I wrote in the first post (current directory):

> When I try to fix it with with set_unicharset_properties:
> set_unicharset_properties --F font_properties -U unicharset -O output_unicharset --script_dir=/

where Common.unicharset is now put.

But if I put Latin.unicharset, what I get is not what is adapted for my fonts, 
xheights can change per fonts:
https://raw.githubusercontent.com/tesseract-ocr/langdata/master/Latin.xheights
So how can I be sure that this default value is correct for my all fonts???

As says ggdhines, according to the documentation, we have to compute the actual size of our fonts:

https://github.com/tesseract-ocr/tesseract/blob/a3ba11b030345d32829b1e8355afea5419978d82/doc/unicharset.5.asc

> CAVEATS
> 
> Although the unicharset reader maintains the ability to read unicharsets of older formats and will assign default values to missing fields, the accuracy will be degraded.

What you suggest is likely to produce such degraded result. (what I seem to experiment)

Always for the above link:

> Further, most other data files are indexed by the unicharset file, so changing it without re-generating the others is likely to have dire consequences

So, as it is stated that "assign default values to missing fields, the accuracy will be degraded", and "is likely to have dire consequences", your proposition can not be accepted, because it lead to what I experiment if I do like you say: strange results.

Unless I did not understand anything, in which case, as I am not the only one, you have to review the documentation.
 @amitdo 

Here some output according to your recommendation:

tesseract training:

```
    tesseract -l eng2 eng.palladio-regular.exp9.tif eng.palladio-regular.exp9 box.train.stderr
    Tesseract Open Source OCR Engine v3.04.01 with Leptonica
    Page 1
    APPLY_BOXES:
       Boxes read from boxfile:    1583
       Found 1583 good blobs.
    Generated training data for 403 words
    Page 2
    APPLY_BOXES:
       Boxes read from boxfile:    1590
       Found 1590 good blobs.
    Generated training data for 380 words
    Page 3
    APPLY_BOXES:
       Boxes read from boxfile:    1577
       Found 1577 good blobs.
    Generated training data for 392 words
    Page 4
    APPLY_BOXES:
       Boxes read from boxfile:    1613
       Found 1613 good blobs.
    Generated training data for 363 words
    Page 5
    APPLY_BOXES:
       Boxes read from boxfile:    1435
       Found 1435 good blobs.
    Generated training data for 312 words
    Page 6
    APPLY_BOXES:
       Boxes read from boxfile:    1670
       Found 1670 good blobs.
    Generated training data for 367 words
    Page 7
    APPLY_BOXES:
       Boxes read from boxfile:    1684
       Found 1684 good blobs.
    Generated training data for 374 words
    Page 8
    APPLY_BOXES:
       Boxes read from boxfile:    1673
       Found 1673 good blobs.
    Generated training data for 365 words
    Page 9
    APPLY_BOXES:
       Boxes read from boxfile:    1639
       Found 1639 good blobs.
    Generated training data for 381 words
    Page 10
    APPLY_BOXES:
       Boxes read from boxfile:    1671
       Found 1671 good blobs.
    Generated training data for 369 words
    Page 11
    APPLY_BOXES:
       Boxes read from boxfile:    1723
       Found 1723 good blobs.
    Generated training data for 357 words
    Page 12
    FAIL!
    APPLY_BOXES: boxfile line 1058/1 ((1279,1540),(1321,1612)): FAILURE! Couldn't find a matching blob
    FAIL!
    APPLY_BOXES: boxfile line 1382/1 ((1287,742),(1330,814)): FAILURE! Couldn't find a matching blob
    APPLY_BOXES:
       Boxes read from boxfile:    1631
       Boxes failed resegmentation:       2
       Found 1629 good blobs.
    Generated training data for 303 words
    Page 13
    FAIL!
    APPLY_BOXES: boxfile line 75/1 ((1299,4479),(1342,4550)): FAILURE! Couldn't find a matching blob
    FAIL!
    APPLY_BOXES: boxfile line 321/1 ((1289,3814),(1332,3885)): FAILURE! Couldn't find a matching blob
    FAIL!
    APPLY_BOXES: boxfile line 475/1 ((1284,3415),(1327,3486)): FAILURE! Couldn't find a matching blob
    FAIL!
    APPLY_BOXES: boxfile line 629/1 ((1278,3016),(1321,3087)): FAILURE! Couldn't find a matching blob
    FAIL!
    APPLY_BOXES: boxfile line 937/1 ((1267,2218),(1310,2289)): FAILURE! Couldn't find a matching blob
    APPLY_BOXES:
       Boxes read from boxfile:    1727
       Boxes failed resegmentation:       5
       Found 1722 good blobs.
    Generated training data for 239 words
    Page 14
    APPLY_BOXES:
       Boxes read from boxfile:    1651
       Found 1651 good blobs.
    Generated training data for 350 words
    Page 15
    APPLY_BOXES:
       Boxes read from boxfile:    1619
       Found 1619 good blobs.
    Generated training data for 179 words
    Page 16
    APPLY_BOXES:
       Boxes read from boxfile:    1634
       Found 1634 good blobs.
    Generated training data for 238 words
    Page 17
    APPLY_BOXES:
       Boxes read from boxfile:    1677
       Found 1677 good blobs.
    Generated training data for 386 words
    Page 18
    APPLY_BOXES:
       Boxes read from boxfile:    1643
       Found 1643 good blobs.
    Generated training data for 401 words
    Page 19
    APPLY_BOXES:
       Boxes read from boxfile:    1659
       Found 1659 good blobs.
    Generated training data for 376 words
    Page 20
    APPLY_BOXES:
       Boxes read from boxfile:    1317
       Found 1317 good blobs.
    Generated training data for 304 words
```

set_unicharset_properties

```
    set_unicharset_properties --F font_properties --script_dir=/home/ne0zer0/Tesseract/Test2/langdata -U unicharset -O output_unicharsetLoaded unicharset of size 115 from file unicharset
    Setting unichar properties
    Other case É of é is not in unicharset
    Warning: properties incomplete for index 25 = ~
    Writing unicharset to file output_unicharset
```

shapeclustering

```
    shapeclustering -F font_properties -U output_unicharset eng.palladio-regular.exp9.tr
    Reading eng.palladio-regular.exp9.tr ...
    Bad properties for index 25, char ~: 91,229 135,255 73,174 0,41 0,200
    Building master shape table
    Computing shape distances...
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances...
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances...
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances...
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances...
    Stopped with 0 merged, min dist 999.000000
    Computing shape distances... 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111
    Distance = 0.000000: Distance = 0.000000: Distance = 0.006410: Distance = 0.007353: Distance = 0.007463: Distance = 0.012427: Distance = 0.012987: Distance = 0.015045: Distance = 0.020725: Distance = 0.020841: Stopped with 10 merged, min dist 0.026087
    Master shape_table:Number of shapes = 102 max unichars = 3 number with multiple unichars = 7
```

mftraining

```
    mftraining -F font_properties -U output_unicharset -O eng.unicharset eng.palladio-regular.exp9.tr
    Read shape table shapetable of 102 shapes
    Reading eng.palladio-regular.exp9.tr ...
    Bad properties for index 25, char ~: 91,229 135,255 73,174 0,41 0,200
    Warning: no protos/configs for sh0099 in CreateIntTemplates()
    Warning: no protos/configs for sh0100 in CreateIntTemplates()
    Warning: no protos/configs for sh0101 in CreateIntTemplates()
    Done!
```

The result is as strange as before, but now I have this warning in mftraining:

> Warning: no protos/configs for sh0101 in CreateIntTemplates()

And why these failure?

> APPLY_BOXES: boxfile line 1382/1 ((1287,742),(1330,814)): FAILURE! Couldn't find a matching blob
 Yes I know,

At first, i tried without `shapeclustering`, but I finally say "what if".

Anyway, here the output:

```
    mftraining -F font_properties -U output_unicharset -O eng.unicharset eng.palladio-regular.exp9.tr
    Warning: No shape table file present: shapetable
    Reading eng.palladio-regular.exp9.tr ...
    Flat shape table summary: Number of shapes = 112 max unichars = 1 number with multiple unichars = 0
    Warning: no protos/configs for Joined in CreateIntTemplates()
    Warning: no protos/configs for |Broken|0|1 in CreateIntTemplates()
    Done!
```

For the same result…
 Thank you for your reply,

But what about theses questions:

> But if I put Latin.unicharset, what I get is not what is adapted for my fonts,
> xheights can change per fonts:
> https://raw.githubusercontent.com/tesseract-ocr/langdata/master/Latin.xheights
> So how can I be sure that this default value is correct for my all fonts???
> 
> As says ggdhines, according to the documentation, we have to compute the actual size of our fonts:
> 
> https://github.com/tesseract-ocr/tesseract/blob/a3ba11b030345d32829b1e8355afea5419978d82/doc/unicharset.5.asc
> 
> ```
> CAVEATS
> 
> Although the unicharset reader maintains the ability to read unicharsets of older formats and will assign default values to missing fields, the accuracy will be degraded.
> ```
> 
> What you suggest is likely to produce such degraded result. (what I seem to experiment)
> 
> Always for the above link:
> 
> ```
> Further, most other data files are indexed by the unicharset file, so changing it without re-generating the others is likely to have dire consequences
> ```
> 
> So, as it is stated that "assign default values to missing fields, the accuracy will be degraded", and "is likely to have dire consequences", your proposition can not be accepted, because it lead to what I experiment if I do like you say: strange results.
> 
> Unless I did not understand anything, in which case, as I am not the only one, you have to review the documentation.
 > CAVEATS
> Although the unicharset reader maintains the ability to read unicharsets of older formats and will **assign default values to missing fields**, the accuracy will be degraded.

What I understood is: incomplete  v3.02 unicharset format file (like what I get) will result, infine, to the old format (after all, some fields are zeroing). These 0 lead to default value.

As informations are missing, owing to the fact that 0 are put instead of actual value, the accuracy will be degraded.
 @amitdo - why is this necessary at all? Shouldn't Tesseract being learning based on the training examples we provide? Pre-existing data isn't going to be helpful with new fonts. 
 @ggdhines :+1: 
 Ok, I will wait.

Thanks for your patience.
 Hi,

Thank you for this clarification.

I am somewhat disappointed, and I have more questions than before:
1. Why using default values, when we want to train for specific fonts, and we could get specific values?
2. Are not specific values better than default values??? Why not using default values "only" when we need it? For example, when there are no matching font?
3. It will be certainly less accurate to use default values; so we cannot get the best result for specific fonts? Unless to waste a lot of time in training Tesseract? For an "uncertain" result?
4. Why `set_unicharset_properties` does not compute such values? It would not be too difficult to develop such a functionality. And I think it would be better in a lot of way (result and time).
5. I cannot understand how these default values can be better. For example, theses default values are likely not to match Adobe Jenson Pro glyph metrics and other fonts. So I have to train again, again, and again, to get better result due to lack of specific values, owing to "missing functionality"?
6. You write: 

> set_unicharset_properties -U unicharset -O new_unicharset -X xheights --script_dir=/home/myusername/tesseract-ocr/langdata

but the xheights file generated is always blank, and the file Latin.xheights seems to do nothing (I already tried this), and I always get the same output_unicharset file, with or without Latin.xheights (located in langdata folder, or in the current directory).

What can be done with a filled (with default values) xheights file?

Thank you
 > If you develop such a tool (or hire someone to do so) we can add a link in the wiki to your site...
1. Not enough time
2. Not enough money
3. The developers of Tesseract will do it faster, cleaner, and cheaper than me.

> My answer for your other questions:
> This is the current situation and you should accept it...

Indeed. In fact, I expected too much from Tesseract.

> Your last question - you probably did something wrong if you get an empty file. I will try to test it later.

I will wait for your test.

> Two last notes:
> I and the other people responding most of the time here and in the mailing-list are volunteers.
> Within free (not paid) open source projects, complaining would not help, kind request might help but it's not guaranteed.

Sorry, but I did not want to hurt anybody.

> You seem to think that / is the current directory, but it's not.
> / is your 'root' directory. ./ (or just .) is the current directory.

No, just a mistake when I wrote.

> > What can be done with a filled xheights file?
> 
> https://github.com/tesseract-ocr/tesseract/blob/master/doc/mftraining.1.asc

Thanks for the link.

Anyway, thank you for everything.
 I finally resolved my problem with xheights. I did a spelling mistake :s

Anyway, thanks for all.
 More recently I made the addmetrics and xheights tools, which are in the tools directory of the git repo https://ancientgreekocr.org/grctraining.git
  Command run in tesseract 3.04.01 src on redhat linux 7.2 64 bit
./configure --prefix=/apps/tesseract --with-extra-libraries=/apps/build/lib --enable-debug CXPFLAGS="-I/apps/build/include -I/apps/build/include/libpng16 -I/apps/build/include/leptonica -lpng -ljpeg -lz" LDFLAGS="-L/apps/build/lib" LIBLEPT_HEADERSDIR=/apps/build/include/leptonica
my build location is /apps/build
This errors for 
checking for pixCreate in -llept... no
configure: error: leptonica library missing

I have kept my leptonica's liblept.a in /apps/build/lib but stil it fails with this error.
I am attaching the configure.log

any help is much appreciated
[configlog.txt](https://github.com/tesseract-ocr/tesseract/files/253517/configlog.txt)
 even after correcting to CXXFLAGS or CPPFLAGS it still throws the same error
were you able to compile it in linux in non standard location?
 Need urgent help from any of the developers... All help is appreciated.I was trying to install it in linux never realized that it was not tried by any one successfully before.
  I'm following the instructions for creating a new font with Tesseract at http://michaeljaylissner.com/posts/2012/02/11/adding-new-fonts-to-tesseract-3-ocr-engine/ and am getting a unicharest file that looks like:

4
NULL 0 NULL 0
Joined 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # Joined [4a 6f 69 6e 65 64 ]
|Broken|0|1 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0        # Broken
A 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # A [41 ]

(just trying with one character right now) . Later on I get an error:
Bad properties for index 3, char A: 0,255 0,255 0,0 0,0 0,0

My box file is looking right. Any suggestions on how to debug this?
 Seems to be a duplicate of #318 for now
  Hello:
    I use Tesseract 3.4 on CentOS 7, and I test it by some sample words.  In general environmental condition(not opencl), it work successfully, and output words is right.  In opencl condition(./configure --enable-opencl), it can work, but output words is garbled. 
    Why? 
  I have the following image of A's which I want to use to teach Tesseract a new font. (When I include the other characters, the page is mostly taken up and the errors are the same so doesn't seem to be an image with a mostly empty page.) (The original image is in tiff format.)

![active_weather basic exp0](https://cloud.githubusercontent.com/assets/6626461/14989143/5c8c5214-114e-11e6-9aa9-e9baf99eda9a.jpeg)

I have the box file contents which appear to be correct and reasonable.
A 35 3926 66 3965 0
A 102 3926 133 3965 0
A 169 3926 200 3965 0
A 236 3926 267 3965 0
A 303 3926 334 3965 0
A 370 3926 401 3965 0
A 437 3926 468 3965 0
A 504 3926 535 3965 0
A 571 3926 602 3965 0
A 638 3926 669 3965 0

and I have font properties file:
basic 0 0 0 0 0

I enter the commands:
tesseract example.basic.exp0.tiff example.basic.exp0 nobatch box.train
unicharset_extractor example.basic.exp0.tiff

I get the following errors:
APPLY_BOXES:
   Boxes read from boxfile:      10
   Found 10 good blobs.
Generated training data for 1 words
Extracting unicharset from active_weather.basic.exp0.jpeg
Bad box coordinates in boxfile string! ����
Box file format error on line 1; ignored
Bad box coordinates in boxfile string! 

Box file format error on line 6; ignored
Bad box coordinates in boxfile string! 

Box file format error on line 7; ignored
Bad box coordinates in boxfile string! ��
Box file format error on line 10; ignored
Bad box coordinates in boxfile string! 
                                       ��
Box file format error on line 11; ignored
Bad box coordinates in boxfile string! ▒▒%&'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz���������������������������������������������������������������������������
Box file format error on line 12; ignored
Bad box coordinates in boxfile string! (��(��(��(��(��(��(��(��(��(��(��(��(��(��(��(��(��(��(��(�?�����_ٯ��?h�i��މ��~$�mt��K��lmd��!Y�)
                                                                                                                                        襈�r?$���t��?�(��O��������

The question marks are just gibberish. (And the errors keep on coming). I feel I like I didn't have this problem recently but wondering if some upgrade broke things.  

My versions are:
tesseract 3.05.00dev
 leptonica-1.72
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.51 : libtiff 4.0.3 : zlib 1.2.8
 d'oh - you are right. Cheers
  Is there a way to install new languages with HomeBrew. I would like to install norwegian, the code is nor. I tried to do `brew install tessecract-nor` but that didn't work.
On the Wiki there is detail who to do it for MacPort
https://github.com/tesseract-ocr/tesseract/wiki#homebrew
 I got reply on my question here https://github.com/Homebrew/homebrew-core/issues/797.
    I have been having difficultly finding documentation about all of the parameters I can configure in the hocr config. If anyone is able to link me to the complete list.

```
tessedit_create_hocr 1
hocr_font_info 1
```

I'm using tesseract and as part of the hOCRText I would like to retrieve information on the size, font-family and emphasis.

Following the answer on [stack overflow](http://stackoverflow.com/questions/20016767/extracting-text-attributes-using-tesseract-hocr/35415375) This is also confirmed by a pull request documenting this feature #222 

My configuration looks like this.
├── tessdata/
└────  configs/
│       │       ├── api_config
│       │       ├── digits
│       │       └── hocr
│       └── ENG.traineddata

Unfortunately I'm still getting results like the following: 

``` xml
<span class='ocrx_word' id='word_1_109' title='bbox 632 298 721 312; x_wconf 89' lang='ENG' dir='ltr'>authorised</span>
<span class='ocrx_word' id='word_1_110' title='bbox 729 298 748 316; x_wconf 99' lang='ENG' dir='ltr'>by</span>
<span class='ocrx_word' id='word_1_111' title='bbox 756 298 782 312; x_wconf 89' lang='ENG' dir='ltr'>the</span>
<span class='ocrx_word' id='word_1_112' title='bbox 792 298 852 312; x_wconf 91' lang='ENG' dir='ltr'>Income</span>
```

Note: the missing font information.

``` xml
<span class='ocrx_word' id='word_3_21' title='bbox 946 1267 1121 1297; x_wconf 91; x_font Courier_New; x_fsize 9' dir='ltr'>without</span>
```

I have found a webpage outlining extra configuration that I do not [have](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#data-files-required). Could this be the issue? 
 Thanks very much for your help! 
  Doesn't seem to recognize italics in Japanese. I want to help, but there don't seem to be any instruction in https://github.com/tesseract-ocr/langdata.

Examples:

![image0](https://cloud.githubusercontent.com/assets/216339/14833717/8164ad44-0bf8-11e6-8dae-a4efe29a3fe2.png)

![image0](https://cloud.githubusercontent.com/assets/216339/14833805/e8428a36-0bf8-11e6-8b59-5b205e18bde2.png)
 @amitdo Thanks!
 Hi! I'm wondering if the tessdata for italics of Japanese fonts have finished?  Hi Team,

I am an android developer and i am integrating Tesseract for OCR scanning. for my application i have the requirement to detect the orientation of the Ocr and based and that process the OCR.
I have gone though various post to find the way to get the Orientation but was unable to succeed. As per one of the post it ismentioned to get the orientation using the following logic :

inputfile = "/usr/src/tesseract-3.02/eurotextUpsideDown.png";
    image = pixRead(inputfile);

```
api->Init("/usr/src/tesseract-3.02/", "eng");
api->SetPageSegMode(tesseract::PSM_AUTO_OSD);
api->SetImage(image);
api->Recognize(0);

tesseract::PageIterator* it =  api->AnalyseLayout();
tesseract::Orientation orientation;
tesseract::WritingDirection direction;
tesseract::TextlineOrder order;
float deskew_angle;

it->Orientation(&orientation, &direction, &order, &deskew_angle);
printf("Orientation: %d;\nWritingDirection: %d\nTextlineOrder: %d\n" \
       "Deskew angle: %.4f\n",
       orientation, direction, order, deskew_angle);
```

But in android I cannot find the supported method AnalyseLayout() in the TessBaseApi.java class. Can some one help me to find the solution for this or can some one tell me the
api or the logic to get this.

Will be a great help for me. 

Thanks,
Ankit
 Dear @ankitagg,

Did you resolve the issue ?

Please let me know if it is resolved and the method you used to solve ?

Thanks.  In Version v3.04.00 I get a strange behaviour if a non-dictionary word has a certain 
ratio of digits to numbers in it and if there is a non-leading capital "I" involved.
The attached bad.jpg file (same with tif files) should get ocr-ed to NCOR140123020064000000000 and not NCORI4012302006400000000.
If I cut off the last "0" ( good.jpg ) then all is fine.
I played with all kind of options like conflict_set_I_l_1 and rej_1Il_trust_rej_1Il_trust_permuter_type_type and more, but had no success.
I think that it is a bug if the length of the word affects the interpretation of "I".
Or which special setting of the parameters do I have to choose to get this working?

```
rolfm@~/ocr> tesseract -psm 7 good.jpg good ; cat good.txt
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
NCOR14012302006400000000

rolfm@~/ocr> tesseract -psm 7 bad.jpg bad ; cat bad.txt
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
NCORI40123020064000000000
```

bad.jpg :
![bad](https://cloud.githubusercontent.com/assets/1440116/14764199/a3e7cacc-09af-11e6-8a6c-fd881f01b4c8.jpg)
good.jpg : 
![good](https://cloud.githubusercontent.com/assets/1440116/14764200/a7b4288a-09af-11e6-86db-2c58ebe82f37.jpg)
 Can you be more specific? 
The only "fix" I found was to add " -l deu " and then bad.jpg is read correctly. 
But how can I get this behaviour for " -l eng" ? Turning off dictionaries as suggested in the wiki has no effect.
 But isn't it clearly a bug? ocropus-rpred has no problem with bad.jpg.
 There may be a bug (or possibility for improvement) here, but the general statement

> I think that it is a bug if the length of the word affects the interpretation of "I".

doesn't hold because OCR programs are giant collections of probabilities, thresholds, ratios, and conditions. The code that tries to figure out 1Il and 0O confusion in words, in particular, is a big set of heuristics using counts of various character types and guesses about what the most likely output string is.

and +1 for using the mailing list, not the bug tracker, for asking questions
  I want to train my own eng.cube.nn for cube engine, but I cannot find any idea from the trainning directory. What can I do for it?
 But I need to train my cube for my research, have any other way, even not in tesseract, to train the .cube.nn file? I'm so curious about where's the original cube model from, could any one give me some advises about it?
 The code for training the neural network was never released, so nobody can help you with this. Sorry.
 What's the best way for one to insert their own single-character recognition algorithm into the overall Tessaract system?
  I am trying to use the tesseract-c_api-demo.py script as follows:
###### 

import os
import sys
import ctypes
# Demo variables

lang = "eng"
filename = "../phototest.tif"
libpath = "/usr/local/lib64/"
libpath_w = "../vs2010/DLL_Release/"
TESSDATA_PREFIX = os.environ.get('TESSDATA_PREFIX')
if not TESSDATA_PREFIX:
    TESSDATA_PREFIX = "../"
libname = libpath + "libtesseract.so.3.0.2"
tesseract = ctypes.cdll.LoadLibrary(libname)

tesseract.TessVersion.restype = ctypes.c_char_p
tesseract_version = tesseract.TessVersion()[:4]

api = tesseract.TessBaseAPICreate()
rc = tesseract.TessBaseAPIInit3(api, TESSDATA_PREFIX, lang);

text_out = tesseract.TessBaseAPIProcessPages(api, filename, None , 0);
result_text = ctypes.string_at(text_out)
print result_text
###### 

How can I set the PSM_Model for tesseract?
  On Tesseract 3.04.00 I get a segmentation fault while trying to get the orientation information for the image with arabic text.

Sample Image: http://i.imgur.com/DdLr39z.jpg

Tesseract Version:

```
$ tesseract --version
tesseract 3.04.00
 leptonica-1.72
  libjpeg 8d : libpng 1.6.18 : libtiff 4.0.6 : zlib 1.2.5
```

Ara langs in TESSDATA:

```
$ ls ara*
ara.cube.bigrams   ara.cube.lm        ara.cube.params    ara.cube.word-freq 
ara.cube.fold      ara.cube.nn        ara.cube.size      ara.traineddata
```

Segmentation Fault:

```
$ tesseract arabic_4.jpg stdout -psm 0 -l ara
[1]    3721 segmentation fault  tesseract ~/Downloads/arabic_4.jpg stdout -psm 0 -l ara
```

This does not happen when I pass the language as `eng` instead of  `ara` but then ofcourse the results and confidence factor are extremely low. 

```
$ tesseract ~/Downloads/arabic_4.jpg stdout -psm 0 -l eng
Orientation: 0
Orientation in degrees: 0
Orientation confidence: 4.00
Script: 1
Script confidence: 8.08
```
  I'm trying the first example: `pts.image_to_string(PIL.Image.open('/home/shefuto/Pictures/jpgpytesseract.jpg'))`
and it gives me this error. `OSError(2, 'No such file or directory')`

At some point a subprocess is being invoked, and analyzing the `locals()`, i get these 

```
ipdb> locals()

{'lang': None, 
'input_filename': '/tmp/tess_qi4zyS.bmp', 
'boxes': False, 
'command': ['tesseract', '/tmp/tess_qi4zyS.bmp', '/tmp/tess_7uERUt'], 
'config': None, 
'output_filename_base': '/tmp/tess_7uERUt'}
```

These are the locals when the exception occured here: `/pytesseract/pytesseract.py(94)`

The complete traceback is here:

```
> <ipython-input-15-c7d82a7070cb>(1)<module>()
----> 1 pts.image_to_string(PIL.Image.open('/home/shefuto/Pictures/jpgpytesseract.jpg'))

ipdb> a
ipdb> d
> /home/shefuto/ve/tmp2/local/lib/python2.7/site-packages/pytesseract/pytesseract.py(172)image_to_string()
    170     finally:
    171         cleanup(input_file_name)
--> 172         cleanup(output_file_name)
    173 
    174 def main():

ipdb> d
> /home/shefuto/ve/tmp2/local/lib/python2.7/site-packages/pytesseract/pytesseract.py(94)run_tesseract()
     92 
     93     proc = subprocess.Popen(command,
---> 94             stderr=subprocess.PIPE)
     95     return (proc.wait(), proc.stderr.read())
     96 

ipdb> d
> /usr/lib/python2.7/subprocess.py(724)__init__()
    722                     pass
    723 
--> 724             raise exc_type, exc_value, exc_trace
    725 
    726         if mswindows:

ipdb> d
> /usr/lib/python2.7/subprocess.py(1327)_execute_child()
   1325                         raise
   1326                 child_exception = pickle.loads(data)
-> 1327                 raise child_exception
   1328 
   1329 
```

The source file '/home/shefuto/Pictures/jpgpytesseract.jpg' exists, so it appears it tries to access those temporary files when they're not created yet.
  A related stackoverflow question is here: http://stackoverflow.com/questions/20599768/tesseract-ocr-recognize-complete-dictionary-words-only. 

Basically what I want to achieve is to ask Tesseract to recognize only complete words included in my custom dictionary (lang: chi_sim), or to find the best match. 

Following the instruction in https://github.com/tesseract-ocr/tesseract/blob/master/doc/tesseract.1.asc#languages, I applied a config file with the following content:

```
load_system_dawg     F
load_freq_dawg       F
user_words_file      /path/to/my/dictonary.user-words
```

But this doesn't seem to work: when I ask Tesseract to recognize word from this image

 ![x](https://cloud.githubusercontent.com/assets/1710087/14453308/a897e3dc-00c6-11e6-9637-2419cddace49.jpg),

`$ tesseract /path/to/the/above/image.jpg stdout -l chi_sim /path/to/my/config_file`

 it gives me `硝酸嘛庸喹瓢膏` which is not in the dictionary at all. The best match is supposed to be `硝酸咪康唑乳膏` which is included in the dictionary.

I searched around and couldn't find a solution. Please help me out. Thank you.
 You could try playing with some of the dictionary related parameters to see if you can achieve the results that you want:

```
$ tesseract --print-parameters | grep dic
```

In particular, these two look like they might have promise:

```
language_model_penalty_non_freq_dict_word   0.1 Penalty for words not in the frequent word dictionary
language_model_penalty_non_dict_word    0.15    Penalty for non-dictionary words
```
 Thank you, @amitdo and @tfmorris. I tried both `language_model_penalty_non_freq_dict_word` and `language_model_penalty_non_dict_word` but had no luck.
  Version: tesseract **3.01**
Other version: the master branch contains updated code and has not been tested
Result: ASSERT failure
Input: specific image (cannot be shared) with table like structure
Keytext: `bb_it.data()->owner() == this:Error:Assert failed:in file colpartition.cpp, line 205`

(Mixing blobs/bboxes etc. for easier reading)

ColPartitions are created from bboxes that were placed on a grid (see `colpartition.cpp::void ColPartition::AddBox(BLOBNBOX* bbox)`). It is normal that one bbox is in multiple positions (that are subsequent) and there can be multiple bboxes in one position on the grid. It can happen, that more ColPartitions are created from the same bbox (the bbox iteration returns bbox1 from [x,y] and a new ColPartition is created, then a different bbox2 is returned from the same [x,y] and another ColPartition is created, afterwards we move to [x+1, y] and get bbox1 again and yet another new ColPartition is created (see `colfind.cpp::ColPartitionSet* ColumnFinder::PartitionsAtGridY(int grid_y)`).
So far so good, we have two ColPartitions with the same bbox and we move on to merging.

These two ColPartitions are correctly selected for merging to another one (see `colpartition.cpp::bool ColPartition::Unique(ColPartition* other, WidthCallback* cb)`) BUT it can happen that `void ColPartition::AddBox(BLOBNBOX* bbox)` does _add_ them twice under very specific conditions. The result is a crash/assert (whatever you call it) in `colpartition.cpp::void ColPartition::ClaimBoxes(WidthCallback* cb)` where the list is iterated and owner is chosen. Now, if there is an item after the second position of the specific bbox, the assert (`ASSERT_HOST(bb_it.data()->owner() == this);`) is triggered because the first time it encounters the bbox the owner is set to `null` and the second time the assert `expects ==this`).

How can the box be added twice?
The specific bbox is
`
{bot_left={xcoord=1201 ycoord=1158 } top_right={xcoord=1303 ycoord=1251 } }
`
The first merge calls
`void ColPartition::AddBox(BLOBNBOX* bbox)` -> `boxes_.add_sorted(SortByBoxBottom<BLOBNBOX>, true, bbox);` (it is a vertical box). 
and it will be added to the end by

```
  // Check for adding at the end.
  if (last == NULL || comparator(&last->data, &new_data) < 0) {
```

which _can_ still be correct (`{bot_left={xcoord=1306 ycoord=1157 } top_right={xcoord=1494 ycoord=1347 } }`). 

But the second call should discard adding because of the `unique` parameter. But because there are bboxes at the beginning and only bottom is checked 

```
int SortByBoxBottom(const void* void1, const void* void2) {
  // The void*s are actually doubly indirected, so get rid of one level.
  const BBC* p1 = *reinterpret_cast<const BBC* const *>(void1);
  const BBC* p2 = *reinterpret_cast<const BBC* const *>(void2);
  int result = p1->bounding_box().bottom() - p2->bounding_box().bottom();
```

it is added again before the other value is encountered (`box = {bot_left={xcoord=1405 ycoord=1209 } top_right={xcoord=1475 ycoord=1259 } }`).

The iteration compares it with the following:

```
{bot_left={xcoord=1408 ycoord=1293 } top_right={xcoord=1440 ycoord=1337 } }
{bot_left={xcoord=749 ycoord=1142 } top_right={xcoord=933 ycoord=1258 } }
-->>{bot_left={xcoord=1405 ycoord=1209 } top_right={xcoord=1475 ycoord=1259 } }
```

Solution:
One possible solution is to iterate the other bboxes as well if `unique` is set and discard adding if it finds the same data

```
--- a/tesseract/ccutil/clst.cpp
+++ b/tesseract/ccutil/clst.cpp
@@ -252,8 +252,23 @@ bool CLIST::add_sorted(int comparator(const void*, const void*),
     }
     if (it.cycled_list())
       it.add_to_end(new_data);
     else
+    {
+        // well, it can happen that sorting is not unique because of the condition above
+        if (unique)
+        {
+            CLIST_ITERATOR it_cont(it);
+            for (; !it_cont.cycled_list(); it_cont.forward())
+            {
+              void* data = it_cont.data();
+              if (data == new_data) {
+                return false;
+              }
+            }
+        }
+
       it.add_before_then_move(new_data);
+    }
     return true;
   }
   return false;
```
 Unless someone wants to check the current master, feel free to close the issue.
 as mentioned above, the specific image cannot be made publicly available
 @vidiecan, if it is not possible to create a public demo image, maybe you can nevertheless provide a code patch which fixes the problem? Or is it possible to send the problematic image privately to one of the developers working an tesseract, so that he/she can fix the problem?
  First of all, thanks for adding support to tesseract finally. From quickly inspecting Persian related codes on tesseract I reached to https://github.com/tesseract-ocr/tesseract/blob/master/training/language-specific.sh#L520 which I can say speculatively is not a good set of fonts for training Persian printed text and can result in poor performance of OCR quality as most Persian fonts don't have the style these fonts have. On ["Font recognition using Variogram fractal dimension"](http://files.matlabsite.com/docs/papers/icee2012/2/icee2012-174.pdf), a good set of Persian fonts is introduced (second page, at the bottom) which as you can see there also, it is different from favorites Arabic language fonts (even the fact both are using Arabic script). So for training Persian OCR for tesseract I suggest adding or replacing current fonts with these free fonts, Nazli (i.e. Nazanin as indicated on that article) and Titr from Debian [fonts-farsiweb](https://packages.debian.org/search?keywords=fonts-farsiweb) package and also XB Zar and XB Yaghut from OFL licensed [xfonts](http://wiki.irmug.com/index.php/X_Series_2). I think also @roozbehp @behdad from Google can help you on this. Thank you.
  tesseract -v provides version info for the binary.

It would be helpful to have version info in all training tools also.

Thanks!
 It might be useful to have them write that version into their output as well, so one can tell the provenance of the trained data.
 Possible actions:
* Support command line options `-v`, `--version` for all executables.
* Write version information in file information for Windows executables.

Potential problems:
* Executable and shared library `libtesseract` might have different versions.

Open question:
* What exactly should be shown? Version number only for tagged release? Branch version? Git release? Compilation date? * Windows DLL files can include file information like executables (also the version info).
* Any shared library could include an exported function like `const char *tesseractLibraryVersion()` which returns a version string. [3.05.01](https://github.com/tesseract-ocr/tesseract/releases/tag/3.05.01) was released shortly after your question, so this is something for the next release. The current situation regarding version information is confusing:

- There is a Tesseract package version (not shown by `tesseract -v` as I would have expected).
- There is a Tesseract data version used for the traineddata (shown by `tesseract -v`).
- There are lots of places with version information (`configure.ac`, `ccutil/version.h`, `vs2010/port/vcsversion.h`, `vs2010/port/vcsversion.h`, `CMakeLists.txt`, maybe more).

And what about PR #593? The traineddata version is only partially different. It starts with `4.00.00alpha` for all newer data (best and fast) and continues with additional information which is different: `4.00.00alpha:Vietnamese:synth20170629:[1,36,0,1Ct3,3,16Mp3,3Lfys64Lfx96Lrx96Lfx512O1c1]`.

It looks like the current code only uses that version string to display it for users. There is still no compatibility check which requests compatible versions – that check must be done by the users.  ![test](https://cloud.githubusercontent.com/assets/12631283/14032336/4c60fa96-f1cf-11e5-99a5-198b1445958a.png)

(I'm using head: 3.05.00dev)

When ocr'ing a small one or two line image (with the default settings), I'm getting the following error:
Error in pixGenHalftoneMask: pix too small: w = 610, h = 71

But the ocr is successful.

In textord/imagefind.cpp, FindImages is calling pixGenHalftoneMask (a leptonica function) which is throwing the error and returning null.

FindImages is then executing it's backup plan, which works fine (such a small image doesn't need multiple images regions). It's backup plan is to call pixCreate and then return the result.

The minimum size for pixGenHalftoneMask to work is 100x100 pixels. Perhaps FindImages should
just go with plan 'b' if the size of the image is too small. This would still work fine and avoid throwing the error. I don't know if there is a way for teseract to know what the minimum size is (in case it changes).
 The min size is defined like this at the top of src/pageseg.c in leptonica:

```
/* These functions are not intended to work on very low-res images */
```

static const l_int32  MinWidth = 100;
static const l_int32  MinHeight = 100;

It doesn't seem that they are likely to change.

Here's my patch:

index 05047ca..0084ac8 100644
--- a/textord/imagefind.cpp
+++ b/textord/imagefind.cpp
@@ -72,6 +72,12 @@ Pix\* ImageFind::FindImages(Pix\* pix) {
   pixDisplayWrite(pixr, textord_tabfind_show_images);

   // Get the halftone mask directly from Leptonica.
+  if (pixGetWidth(pixr) < 100 || pixGetHeight(pixr) < 100)
+  {
+    // leptonica will throw and error and return null
+    pixDestroy(&pixr);
+    return pixCreate(pixGetWidth(pix), pixGetHeight(pix), 1);
+  }
   l_int32 ht_found = 0;
   Pix *pixht2 = pixGenHalftoneMask(pixr, NULL, &ht_found,
                                    textord_tabfind_show_images);
 An alternative is for Leptonica to not spam stderr. I'm honestly not sure which approach is better.
 Good point. It's returning null, and the null is being handled properly. Automatically emitting the reason for the error should be directable/configurable.

I just dug into it and found NO_CONSOLE_IO referenced from environ.h.
Maybe I needed to turn that on when I built Leptonica. Still a questionable approach.
 Scott's patch seems reasonable to me.

Testing the size in advance prevents leptonica from returning null,
and from saying that an error occurred.

Slightly simpler just to 
  return pixCopy(pixr, pix);
which works whether or not pixr exists.

re: musings about whether or not leptonica should "spam stderr":

Just a reminder that leptonica provides a significant amount of control over messages to stderr, both at compile time and at run time, and broken down to the granularity of errors, warnings and information.  The question for the leptonica client (tesseract, here) is what level of messages they want to receive on stderr, and in this case it's up to the maintainers.  If the error messages (at least) are not on, a user will have no idea why something failed if it was due to bad input to a leptonica function, for example.  On the other hand, when failures occur but are caught and handled by the client, the user may be unnecessarily concerned, when things are actually going ok.

FWIW, when I am programming and testing, I always use the default MINIMUM_SEVERITY of L_SEVERITY_INFO, which turns all messages on.
   ```
libtool: compile:  x86_64-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/training -I.. -g -Wall -Wno-uninitialized -O0 -DDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccmain -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/t                                                    esseract/api -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccutil -I/home/ra/MINGW-packages/mingw-                                                    w64-tesseract-ocr-git/src/tesseract/ccstruct -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/viewer                                                     -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/textord -I/home/ra/MINGW-packages/mingw-w64-tesserac                                                    t-ocr-git/src/tesseract/dict -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/classify -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/display -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/wordrec -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/cutil -I/home/ra/MINGW-packages/mi                                                    ngw-w64-tesseract-ocr-git/src/tesseract/vs2010/port -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/mingw64/include/le                                                    ptonica -march=x86-64 -mtune=generic -O2 -pipe -ggdb -Og -ggdb -Og -std=c++11 -MT pango_font_info.lo -MD -MP -MF .deps/p                                                    ango_font_info.Tpo -c /home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/pango_font_info.cpp  -D                                                    DLL_EXPORT -DPIC -o .libs/pango_font_info.o
In file included from C:/msys64/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/ligature_table                                                    .cpp:26:0:
C:/msys64/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/pango_font_info.h:30:30: fatal error                                                    : pango/pango-font.h: No such file or directory
compilation terminated.
Makefile:923: recipe for target 'ligature_table.lo' failed
make[1]: *** [ligature_table.lo] Error 1
make[1]: *** Waiting for unfinished jobs....
libtool: compile:  x86_64-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/training -I.. -g -Wall -Wno-uninitialized -O0 -DDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccmain -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/t                                                    esseract/api -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccutil -I/home/ra/MINGW-packages/mingw-                                                    w64-tesseract-ocr-git/src/tesseract/ccstruct -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/viewer                                                     -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/textord -I/home/ra/MINGW-packages/mingw-w64-tesserac                                                    t-ocr-git/src/tesseract/dict -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/classify -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/display -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/wordrec -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/cutil -I/home/ra/MINGW-packages/mi                                                    ngw-w64-tesseract-ocr-git/src/tesseract/vs2010/port -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/mingw64/include/le                                                    ptonica -march=x86-64 -mtune=generic -O2 -pipe -ggdb -Og -ggdb -Og -std=c++11 -MT normstrngs.lo -MD -MP -MF .deps/normst                                                    rngs.Tpo -c /home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/normstrngs.cpp  -DDLL_EXPORT -DPI                                                    C -o .libs/normstrngs.o
In file included from C:/msys64/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/pango_font_inf                                                    o.cpp:36:0:
C:/msys64/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/pango_font_info.h:30:30: fatal error                                                    : pango/pango-font.h: No such file or directory
compilation terminated.
Makefile:923: recipe for target 'pango_font_info.lo' failed
make[1]: *** [pango_font_info.lo] Error 1
C:/msys64/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/normstrngs.cpp: In function 'bool te                                                    sseract::IsUTF8Whitespace(const char*)':
C:/msys64/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/normstrngs.cpp:183:35: warning: comp                                                    arison between signed and unsigned integer expressions [-Wsign-compare]
   return SpanUTF8Whitespace(text) == strlen(text);
                                   ^
libtool: compile:  x86_64-w64-mingw32-g++ -DHAVE_CONFIG_H -I. -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/training -I.. -g -Wall -Wno-uninitialized -O0 -DDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccmain -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/t                                                    esseract/api -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/ccutil -I/home/ra/MINGW-packages/mingw-                                                    w64-tesseract-ocr-git/src/tesseract/ccstruct -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/viewer                                                     -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/textord -I/home/ra/MINGW-packages/mingw-w64-tesserac                                                    t-ocr-git/src/tesseract/dict -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/classify -I/home/ra/MIN                                                    GW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/display -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/                                                    tesseract/wordrec -I/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/cutil -I/home/ra/MINGW-packages/mi                                                    ngw-w64-tesseract-ocr-git/src/tesseract/vs2010/port -D_FORTIFY_SOURCE=2 -D__USE_MINGW_ANSI_STDIO=1 -I/mingw64/include/le                                                    ptonica -march=x86-64 -mtune=generic -O2 -pipe -ggdb -Og -ggdb -Og -std=c++11 -MT normstrngs.lo -MD -MP -MF .deps/normst                                                    rngs.Tpo -c /home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/tesseract/training/normstrngs.cpp -o normstrngs.o >/                                                    dev/null 2>&1
make[1]: Leaving directory '/home/ra/MINGW-packages/mingw-w64-tesseract-ocr-git/src/build-x86_64-w64-mingw32/training'
Makefile:904: recipe for target 'training' failed
make: *** [training] Error 2
==> ERROR: A failure occurred in build().
    Aborting...

```
  make fail on cygwin64 when I have changed the file 'opencl/openclwrapper.h'  on line 67 : #define PERF_COUNT_VERBOSE 3,   

Then I change the file 'opencl/openclwrapper.h' on line 13: defined( **CYGWIN** ),  more problems come. 
 Thanks.  But  in cygwin, The define of `__CYGWIN32__` is no longer used, replaced by `__CYGWIN__`
 Excuse me, I had met a problem when I used the cmake 
pkg_check_modules(Leptonica REQUIRED lept)       this package didn't found, How can I solved it? 
By the way, I have installed the lib leptonica already, and  I finished making the tesseract by ' configure && make '. 

PS: The src file of leptonica that I downloaded  don't have the CMakeLists.txt.

Thanks.
 Thanks, I have solved this problem. 
  Please try with https://github.com/Alexpux/MINGW-packages/blob/9215e839df3c4f98ea4b160831c17ddada121dfa/mingw-w64-tesseract-ocr/build-fixes.patch

The above was used in the PKGBUILD. Direct build process is failing. Please see msgs below.

```
ra@Shree MINGW64 ~/tesseract
$ make
make  all-recursive
make[1]: Entering directory '/home/ra/tesseract'
Making all in ccutil
make[2]: Entering directory '/home/ra/tesseract/ccutil'
make[3]: Entering directory '/home/ra/tesseract/ccutil'
depbase=`echo ambigs.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG   -I/usr/local/include/leptonica -mms-bitfields -IC:/msys64/mingw64/include/pango-1.0 -IC:/msys64/mingw64/include/glib-2.0 -IC:/msys64/mingw64/lib/glib-2.0/include -mms-bitfields -IC:/msys64/mingw64/include/cairo -IC:/msys64/mingw64/include/pixman-1 -IC:/msys64/mingw64/include -I/mingw64/include/freetype2 -I/mingw64/include/libpng16 -I/mingw64/include/harfbuzz -I/mingw64/include/glib-2.0 -I/mingw64/lib/glib-2.0/include -IC:/msys64/mingw64/include -IC:/msys64/mingw64/include/freetype2 -IC:/msys64/mingw64/include -IC:/msys64/mingw64/include/harfbuzz -IC:/msys64/mingw64/include/glib-2.0 -IC:/msys64/mingw64/lib/glib-2.0/include -IC:/msys64/mingw64/include/libpng16 -DTESSDATA_PREFIX=/usr/local/share/  -g -O2 -std=c++11 -MT ambigs.lo -MD -MP -MF $depbase.Tpo -c -o ambigs.lo ambigs.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I/usr/local/include/leptonica -mms-bitfields -IC:/msys64/mingw64/include/pango-1.0 -IC:/msys64/mingw64/include/glib-2.0 -IC:/msys64/mingw64/lib/glib-2.0/include -mms-bitfields -IC:/msys64/mingw64/include/cairo -IC:/msys64/mingw64/include/pixman-1 -IC:/msys64/mingw64/include -I/mingw64/include/freetype2 -I/mingw64/include/libpng16 -I/mingw64/include/harfbuzz -I/mingw64/include/glib-2.0 -I/mingw64/lib/glib-2.0/include -IC:/msys64/mingw64/include -IC:/msys64/mingw64/include/freetype2 -IC:/msys64/mingw64/include -IC:/msys64/mingw64/include/harfbuzz -IC:/msys64/mingw64/include/glib-2.0 -IC:/msys64/mingw64/lib/glib-2.0/include -IC:/msys64/mingw64/include/libpng16 -DTESSDATA_PREFIX=/usr/local/share/ -g -O2 -std=c++11 -MT ambigs.lo -MD -MP -MF .deps/ambigs.Tpo -c ambigs.cpp  -DDLL_EXPORT -DPIC -o .libs/ambigs.o
ambigs.cpp:31:22: fatal error: strtok_r.h: No such file or directory
compilation terminated.
Makefile:572: recipe for target 'ambigs.lo' failed
make[3]: *** [ambigs.lo] Error 1
make[3]: Leaving directory '/home/ra/tesseract/ccutil'
Makefile:614: recipe for target 'all-recursive' failed
make[2]: *** [all-recursive] Error 1
make[2]: Leaving directory '/home/ra/tesseract/ccutil'
Makefile:470: recipe for target 'all-recursive' failed
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory '/home/ra/tesseract'
Makefile:378: recipe for target 'all' failed
make: *** [all] Error 2

```
 Zdenko, thanks for your suggestion. It is working now. line 88

> > please try to change mingw32_) to mingw_) in configure.ac (line 78?) and then rebuild autotools (./autogen.sh ...)
  This enables all OpenType ligatures for a specific font, where
available. Specifically, it explicitly enables the OpenType
features liga (standard ligatures), hlig (historical ligatures),
clig (contextual ligatures), and dlig (discretionary ligatures).

This feature requires Pango 1.38 or newer.
 Hi Amit!

Yeah, I had considered doing that, but wasn't sure whether it was worth it. Thinking about it more though, I agree with you (and there's only one #ifdef needed, so it ain't too ugly).

Thanks for looking it over :)
  Check my previous summary here http://www.visionopen.com/forums/topic/bugs-in-current-tesseract/
Solutions are provided as follows:

1) LIST -> LIST_TESSERACT
in all files

2) remove_reference -> remove_reference_Tesseract
in all files

How can I become a developer of tesseract on github?

Cheers
Pei
 Oh, yes zdenop.
You are correct. I met this problem 2 years ago. At that time, I used to use a "global namespace", something like 
**using namespace std;** instead of **std::**

It looks like tesseract is using the SAME key words as in C++ compiler.

Thank you... 
   tesseract -v
tesseract 3.05.00dev
 leptonica-1.73
  libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 OpenCL info:
  Found 1 platforms.
  Platform name: NVIDIA CUDA.
  Version: OpenCL 1.1 CUDA 7.0.28.
  Found 1 devices.
    Device 1 name: GRID K520.
root@ip-172-31-35-3:~# tesseract 1.tiff output
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performing profiling.

[DS] Device: "GRID K520" (OpenCL) evaluation...
[OD] write binary[kernel-GRID_K520.bin] successfully
[DS] Device: "GRID K520" (OpenCL) evaluated
[DS]          composeRGBPixel: 0.021918 (w=1.2)
[DS]            HistogramRect: 0.008381 (w=2.4)
[DS]       ThresholdRectToPix: 0.010258 (w=4.5)
[DS]        getLineMasksMorph: 0.005291 (w=5.0)
[DS]                    Score: 0.119031

[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
[DS]          composeRGBPixel: 0.021650 (w=1.2)
[DS]            HistogramRect: 0.072183 (w=2.4)
[DS]       ThresholdRectToPix: 0.041287 (w=4.5)
[DS]        getLineMasksMorph: 0.151936 (w=5.0)
[DS]                    Score: 1.144687
[DS] Scores written to file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:GRID K520 score is 0.119031
[DS] Device[2] 0:(null) score is 1.144687
[DS] Selected Device[1]: "GRID K520" (OpenCL)
fseek(data_file_, static_cast<size_t>(offset_table_[tessdata_type]), SEEK_SET) == 0:Error:Assert failed:in file ../ccutil/tessdatamanager.h, line 173
Segmentation fault (core dumped)
   in doc "[addon](https://github.com/tesseract-ocr/tesseract/wiki/AddOns)" 
Community training projects

Chinese simplefied: see issue 296; download http://ubuntuone.com/p/3Yw/ 
    The goal is to run an AWS Amazon instance (Ubuntu 14.04) with GPU support to test the difference in OCR speed with a large GPU.   I have Nvidia drivers and OpenCL installed.
  Ive downloaded, compiled and installed leptonica 1.73 (latest version), downloaded the latest tesseract source.  I run autogen then ./configure --enable-opencl but get the following error.

checking for leptonica... yes
checking for l_generateCIDataForPdf in -llept... no
configure: error: leptonica library with pdf support (>= 1.71) is missing

Ive searched for at least 4 hours for the answer to this but have had no luck.  Im not a programmer so am not that familiar with the use or locations of lib files.    This is probably just a variable problem but I cant find any reference to it.  
 Hello @dthrock ,

I've got exactly the same proble, on Ubuntu 14.04.

I had to go to leptonica site, download the source and build it.

After that, I run ./configure --with-extra-includes=/usr/local/include and --with-extra-libaries=/usr/local/lib

Hope it would help you.
 I have the same problem, while leptonica-1.74.1, mac OS 10.12.3 (16D32)

localhost:tesseract-4.00.00alpha didi$ brew install leptonica
Updating Homebrew...
Warning: leptonica-1.74.1 already installed

solve this problem by this command:
CPPFLAGS="-I/usr/local/include" LDFLAGS="-L/usr/local/lib" ./configure
 @vitamin thank u. your suggestion solved my issue too .  This builds a docker image based on the project .travis.yml
 @zdenop Not having to create a separate script to invoke the tesseract build.
  I'm having issues with getting Tesseract to read text out of an image.  Its seems to not read the text in the image in its original size.

![bowenpeak](https://cloud.githubusercontent.com/assets/17915164/13863515/410b1a02-ecff-11e5-9c93-f63825576e21.png)

But when I increase the canvas size it then picks up the text.  Any Ideas on what maybe causing this?

![bowenpeak_lrg](https://cloud.githubusercontent.com/assets/17915164/13863517/47b6f010-ecff-11e5-91a0-7b2c7548f493.png)
  Good catch. There seem to be more errors of this kind (e. g. #276).
 The trick is to compile with `-Wmissing-format-attribute`, fix all related warnings and iterate this until no format related warnings remain. Projects like Tesseract which never used gcc's format attribute typically have lots of format errors. I just started the search, and the current count is 6.

Fixing those format errors is one task, another one is adding the format attribute and the compiler options where needed, so future contributions won't introduce new errors.
 That flag would result in warnings for all functions with printf or scanf like arguments which don't use the format attribute. Then it is necessary to add a format function attribute to each of those function declarations. After this, gcc will know which functions work similar to printf or scanf and report all errors (if that warning is enabled, for example with `-Wall -Wextra`).

Example:

```
  ../../../../ccutil/errcode.cpp:64:45: warning: function might be possible candidate for ‘gnu_printf’ format attribute [-Wsuggest-attribute=format]
  ../../../../cutil/callcpp.cpp:47:29: warning: function might be possible candidate for ‘gnu_printf’ format attribute [-Wsuggest-attribute=format]
  ../../../../viewer/scrollview.cpp:402:47: warning: function might be possible candidate for ‘gnu_printf’ format attribute [-Wsuggest-attribute=format]
  ../../../../viewer/scrollview.cpp:573:47: warning: function might be possible candidate for ‘gnu_printf’ format attribute [-Wsuggest-attribute=format]
```

And yes, the missing `%` would be reported, too.
  Hello everyone
I'm new with tesseract and I was wondering if I could force Tesseract to use a small dictionnary and to return the word which is the most similaire from the dictionnary
Thx
  In version 3.03

In the man page for TESSERACT(1) under the title Languages the following items are misspelt.

"Croation" should be "Croatian" (https://en.wikipedia.org/wiki/Croatian_language)
"Slovakian" should be "Slovak" (https://en.wikipedia.org/wiki/Slovak_language)
  I git cloned the tesseract-ocr repositories on ubuntu 14.04 with the following structure

tesseract-ocr
tesseract-ocr/tesseract
tesseract-ocr/tessdata
tesseract-ocr/langdata

The build process (autogen, make, sudo make install, sudo ldconfig)  put the tessdata files with configs and tessconfigs subdirectories and pdf.ttf in  /usr/local/share/tessdata

This puts tessdata related files in two locations:
tesseract-ocr/tessdata
and
/usr/local/share/tessdata
(in addition to the source in tesseract-ocr/tesseract/tessdata)

As a regular user I cannot copy the tesddata files to  /usr/local/share/tessdata

$ cp ./tessdata/san.traineddata /usr/local/share/tessdata
cp: cannot create regular file ‘/usr/local/share/tessdata/san.traineddata’: Permission denied

---

$ export TESSDATA_PREFIX=/home/shree/tesseract-ocr
$ echo $TESSDATA_PREFIX
/home/shree/tesseract-ocr

If I use the above tessdata prefix, then tesseract does not find the config files ..

$ tesseract   testing/phototest.jpg testing/phototest-jpg  -l eng -psm 3
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
$ tesseract   testing/phototest.jpg testing/phototest-jpg  -l eng -psm 3 pdf
read_params_file: Can't open pdf
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
$ tesseract   testing/phototest.jpg testing/phototest-jpg  -l eng -psm 3 tsv
read_params_file: Can't open tsv

---

$ export TESSDATA_PREFIX=/usr/local/share/tessdata
$ echo $TESSDATA_PREFIX
/usr/local/share/tessdata

If I use the above then tesseract does not find the traineddata files even when tessdata-dir is pointing to the correct location

$  tesseract --tessdata-dir=../  testing/phototest.jpg testing/phototest-jpg  -l eng -psm 3
Error opening data file /usr/local/share/tessdata/eng.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your "tessdata" directory.
Failed loading language 'eng'
Tesseract couldn't load any languages!
Could not initialize tesseract.

$ tesseract --tessdata-dir=/home/shree/tesseract-ocr  testing/phototest.jpg testing/phototest-jpg  -l eng -psm 3
Error opening data file /usr/local/share/tessdata/eng.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your "tessdata" directory.
Failed loading language 'eng'
Tesseract couldn't load any languages!
Could not initialize tesseract.

---

I can get around it by copying configs, tessconfigs and pdf.ttf to
/home/shree/tesseract-ocr/tessdata directory.

But this should not be required. What am I missing in the process?
 Thanks, @amitdo 

Need at a minimum to copy
osd.traineddata
eng.*
     char\* GetUTF8Text(struct ETEXT_DESC\* monitor);
I write method GetUTF8Text with ETEXT_DESC but error when debug. How stop ocring.
char\* TessBaseAPI::GetUTF8Text(struct ETEXT_DESC\* monitor) {
  if (tesseract_ == NULL ||
      (!recognition_done_ && Recognize(monitor) < 0))
    return NULL;
  STRING text("");
  ResultIterator _it = GetIterator();
  do {
    if (it->Empty(RIL_PARA)) continue;
    char *para_text = it->GetUTF8Text(RIL_PARA);
    text += para_text;
    delete []para_text;
  } while (it->Next(RIL_PARA));
  char_ result = new char[text.length() + 1];
  strncpy(result, text.string(), text.length() + 1);
  delete it;
  return result;
}

ETEXT_DESC monitor;
monitor.cancel = NULL;
monitor.cancel_this = NULL;
char *text = nat->api.GetUTF8Text(&monitor);
  https://github.com/tesseract-ocr/tesseract/blob/master/ChangeLog
is updated only till 2014-02-04 v3.03

Should the changelog also reflect the changes in the current development (master branch) eg. TSV output as new features are added?
  I've worked with the library in the past when I was working with VS2008 and the precompiled binaries but now that I've been using VS2013 I cannot seem to get the library to work without some sort of memory leak detected at the end of my application's runtime.

Run the application with no calls to the library and no leaks detected.

Run the application with this code:

---

tesseract::TessBaseAPI *api = new tesseract::TessBaseAPI;
delete api;

---

And here is the output when the application wraps up:

---

Detected memory leaks!
Dumping objects ->
{65747} normal block at 0x035DC108, 512 bytes long.
 Data: <0 3   3   3   3 > 30 D3 33 01 D8 E3 33 01 C0 E4 33 01 C0 E9 33 01 

{65746} normal block at 0x035DBEC8, 512 bytes long.
 Data: <  3 x 3   3 < 3 > 8C D0 33 01 78 D0 33 01 F4 D1 33 01 3C D8 33 01 

{203} normal block at 0x00BDAFD0, 32 bytes long.
 Data: <  3   3  x6  w6 > F8 D3 33 01 F8 E2 33 01 14 78 36 01 C0 77 36 01 

{198} normal block at 0x00BDADE0, 256 bytes long.
 Data: <  3   3   3 ` 3 > EC CF 33 01 B0 CF 33 01 08 D0 33 01 60 D0 33 01 

{170} normal block at 0x00BDA9C8, 80 bytes long.
 Data: <    @           > 00 00 00 00 40 00 00 00 E0 AD BD 00 00 00 00 00 

Object dump complete.

---

The block sizes are consistent for this test each time it runs.  If I make calls to the library the number of leaks increases with varying block sizes.

Any help is greatly appreciated.  I would hate to have to go back to VS2008 just to be able to use the precompiled binaries.

Thanks a bunch!
 I followed the directions here: [http://vorba.ch/2014/tesseract-3.03-vs2013.html](http://vorba.ch/2014/tesseract-3.03-vs2013.html).  Everything compiled smoothly but same result.

I would love to help with the development but I've been working on this for a few weeks and I just really can't put any more time into it due to family obligations.  Sorry.

I think I'm going to have to end up using the tesseract-dll.exe cmd line application to do the dirty work (seems to not have the issues I am having with the windows app) and move on.
 Hi have the saim problem but only in mfc project
in console project no leaks detected

here is the VLD log

`---------- Block 65682 at 0x05A705C8: 512 bytes ----------
  Leak Hash: 0xB9C6E0DA, Count: 1, Total 512 bytes
  Call Stack (TID 25176):
    ntdll.dll!RtlAllocateHeap()
    f:\dd\vctools\vc7libs\ship\atlmfc\src\mfc\afxmem.cpp (336): PokeGuiManage.exe!operator new[]() + 0x9 bytes
    c:\vanilly\dev\tesseract1\ccutil\genericvector.h (626): PokeGuiManage.exe!GenericVector<tesseract::BoolParam *>::reserve() + 0x19 bytes
    c:\vanilly\dev\tesseract1\ccutil\genericvector.h (642): PokeGuiManage.exe!GenericVector<tesseract::BoolParam *>::double_the_size()
    c:\vanilly\dev\tesseract1\ccutil\genericvector.h (741): PokeGuiManage.exe!GenericVector<tesseract::BoolParam *>::push_back()
    c:\vanilly\dev\tesseract1\ccutil\params.h (175): PokeGuiManage.exe!tesseract::BoolParam::BoolParam()
    c:\vanilly\dev\tesseract1\textord\oldbasel.cpp (39): PokeGuiManage.exe!`dynamic initializer for 'textord_oldbl_debug''() + 0x21 bytes
    d:\th\minkernel\crts\ucrt\src\appcrt\startup\initterm.cpp (22): PokeGuiManage.exe!_initterm()
    f:\dd\vctools\crt\vcstartup\src\startup\exe_common.inl (221): PokeGuiManage.exe!__scrt_common_main_seh() + 0xF bytes
    f:\dd\vctools\crt\vcstartup\src\startup\exe_common.inl (300): PokeGuiManage.exe!__scrt_common_main()
    f:\dd\vctools\crt\vcstartup\src\startup\exe_wwinmain.cpp (17): PokeGuiManage.exe!wWinMainCRTStartup()
    kernel32.dll!BaseThreadInitThunk() + 0x12 bytes
    ntdll.dll!RtlInitializeExceptionChain() + 0xEF bytes
    ntdll.dll!RtlInitializeExceptionChain() + 0xC2 bytes
  Data:
    C4 0F B5 01    9C C0 B8 01    D4 C0 B8 01    68 C1 B8 01     ........ ....h...
    7C C2 B8 01    20 C2 B8 01    64 C2 B8 01    3C C2 B8 01     |....... d...<...
    1C C7 B8 01    E8 C6 B8 01    C8 D1 D0 01    A4 D5 D0 01     ........ ........
    FC D5 D0 01    D0 D7 D0 01    88 D7 D0 01    74 D7 D0 01     ........ ....t...
    EC D7 D0 01    48 D7 D0 01    74 E3 D0 01    54 E6 D0 01     ....H... t...T...
    B8 E7 D0 01    64 EA D0 01    8C E7 D0 01    24 E9 D0 01     ....d... ....$...
    CC E7 D0 01    24 E8 D0 01    30 EB D0 01    1C EC D0 01     ....$... 0.......
    FC E9 D0 01    F0 EB D0 01    F8 EA D0 01    E0 EA D0 01     ........ ........
    50 EA D0 01    CC EA D0 01    3C E9 D0 01    74 EB D0 01     P....... <...t...
    10 EA D0 01    80 EC D0 01    34 EE D0 01    10 EE D0 01     ........ 4.......
    5C EE D0 01    DC EF D0 01    F4 EF D0 01    48 F1 D0 01     ....... ....H...
    68 F2 D0 01    00 F3 D0 01    E4 F2 D0 01    14 F3 D0 01     h....... ........
    40 F3 D0 01    CC F2 D0 01    4C F6 D0 01    68 F6 D0 01     @....... L...h...
    7C F6 D0 01    E8 F8 D0 01    6C FB D0 01    EC FA D0 01     |....... l.......
    40 FB D0 01    7C FA D0 01    D0 FA D0 01    08 FB D0 01     @...|... ........
    BC FA D0 01    24 FB D0 01    84 FB D0 01    14 FE D0 01     ....$... ........

Visual Leak Detector detected 5 memory leaks (1572 bytes).
Largest number used: 3188036 bytes.
Total allocations: 3297978 bytes.
Visual Leak Detector is now exiting.`
 Fixed in #449   I integrated Tesseract C/C++, version 3.x, to read English OCR on images.

It’s working pretty good, but very slow. It takes close to 1000ms (1 second) to read the attached image (00060.jpg) on my quad-core laptop.

I’m not using the Cube engine, and I’m feeding only binary images to the OCR reader.

Any way to make it faster. Any ideas on how to make Tesseract read faster?
thanks
![00060](https://cloud.githubusercontent.com/assets/9968625/13674495/ac261db4-e6ab-11e5-9b4a-ad91d5b4ff87.jpg)
 You can already run 4 parallel instances of Tesseract on your quad core, then it will read 4  images in about the same time. Introducing multi threading would not help to reduce the time needed for an OCR of many images. I am working on a project where OCR with Tesseract would take nearly 7 years on a single core, but luckily I can try to get many computers and use their cores, so the time can be reduced to a few days.
Using compiler settings which are optimized for your CPU helps to gain a few percent, but I am afraid that for a larger gain different algorithms in Tesseract and its libraries would be needed.
 Besides the OCR, we have other things that need to run on the other cores.
I believe, the main issue that's slowing down Tesseract is the way memory is managed.
Too many memory allocations (new function) and releases (delete or delete [] functions) do slow down the reader.
In the past, I did use a different OCR engine, and it was allocating up-front large buffers to store all the needed data (large buffer of blobs, a large buffer of lines, a large buffer of words and their corresponding data), the buffers were just being indexed as we were reading the data from an image. The large buffers were allocated only once upon ocr engine initialization and release only once upon ocr engine shutdown. This memory management scheme was very efficient computational-time-wise.
Are there any settings for Tesseract that are known to be computationally intensive?
any tricks to speed up Tesseract?
 What evidence is your memory management speculation based on?
 I'm not speculating anything. The reality is that TesseRact takes more than 3 seconds to read the above image that I initially attached (I use VS2010). When I use the console test application that comes with the TesseRact, it takes about the same time (more than 3 seconds). 

Anyone would speculate a lot in 3 seconds

I have more than 20 years in machine vision. I used several OCR engines in the past. Actually I have one -in house- that reads the same image in less than 100ms, but our engine is designed more for reading a single line of text (i.e. it returns a single line of text).

TesseRact database is not that large. Most of the techniques used by TesseRact are quite standard in the OCR-area (page layout, line extraction, possible character extraction, word forming, and then several phases of classification). However, the TesseRact manages very badly memory usage. why? it takes more than 3 seconds to read a typical texted-image.

please if you're not bringing any meaningful ideas to my posting, just spare me your comment.
 @ychtioui, as you have spent many years in machine vision, you know quite well that there are lots of ways why programs can be slow. Memory management is just one of them. Even with a lot of experience, I'd start running performance analyzers to investigate performance issues. Of course I can guess what might be possible reasons and try to improve the software based on that guesses, but improvements based on evidence (like the result of a performance analysis) are more efficient. Don't you think so, too? Do you have a chance to run a performance analysis?
 I'm running version 3.02
I'm going through different sections of the reader, and checking which section is taking the most time.

is it typical to read images (such as mine attached above) in a few seconds? 

thanks for your comments.
 thanks amitdo.
I'm using 3.02 but the C/C++ version of Tesseract.
I couldn't find the setting -O3 in the source files. where is it?
 @ychtioui said in a post above "I use VS2010" so using Windows.
 I use vs2010 on a Windows 7 pc.
Project settings or building options won't change much the read speed.
Tesseract was designed in research labs. Most of the key sections of the reader are speed-don't-care.
I used some performance tools to analyze where most of the computation time is spent. 
In the page layout section, the blob analyzer does a lot of new/delete. This is very time consuming. The attached image above has more than 3600 blobs. Besides a number of processings are done on each blob (distance transform, finding the enclosing rectangle, measuring blob parameters, etc.). The allocations (new) and the release (delete) of all these blobs is very time consuming. 
If we use a global array (allocate upfront) of blobs (exactly object BLOBNBOX) and whenever we need a blob, just get one index from the array. The array will be released once when we shut down the engine. 
I used this concept in another single line ocr reader and it's super fast.
 Hi @ychtioui I am newbie and saw your first comment that you are able to get pretty accurate results from Tesseract. For your image itself i am no table to get any results its telling: Can't recognize image. Can you plz provide the code snippet on how you are processing the image. 
Thanks - Anant.
 @theraysmith 
What do you use in the internal Google build, `-O2` or `-O3`?
 I'm interested in the same answer, @amitdo . Can you answer the question, @theraysmith ? It really can help us :)  Don't expect much difference between `-O2` and `-O3`. I tried different optimizations, and they only have small effects on the time needed for OCR of a page. Higher optimization levels can even result in slower code because the code gets larger (because of unfolding of loops), so CPU caches become less effective. It is much more important to write good code. The improvement by using `-fopenmp` is useful when you want "realtime" OCR – running OCR for a single page and waiting for the result. Then it is fast because it uses more than one CPU core for some time consuming parts of the OCR process.

For mass OCR, it does not help. If many pages have to be processed, it is better to use single threaded Tesseract and run several Tesseract processes in parallel.
 Stefan, what about using OpenMP for training? Yes, for training a single new model OpenMP could perhaps speed up the training process. Up to now, OpenMP is only used in `ccmain/` and in `lstm/`. I don't know how much that part is used during training, and I never have run a performance evaluation for the training process (in fact I‌ have only run LSTM training once for Fraktur, and as I already said, it was not really successful). can I set more than 4 threads for Trainning LSTM? What about machines that have only 2 cores?
Shouldn't the 'num_threads' lowered to 2 in that case? @theraysmith I want to train tesseract 4 for arabic language. theraysmith you mean that there is no way to speed up the training process?  i follow this step,
./autogen.sh
./configure
make
sudo make install
sudo ldconfig

but when i run make, i got error, then i run _autoreconf -i_ after ./autogen.sh , but i got same result
![tesseract](https://cloud.githubusercontent.com/assets/11517390/13629164/3ae1a9be-e612-11e5-9fd5-1b5f7054ce7e.JPG)

what's wrong with this step ?
 Sounds the same as #41 
 thnks tfmorris and zdenop for the reply, it's very helpful
  Hi!
I just found that there is an invalid link in the wiki(Page Home -> Installation -> Linux）
And here is the link:**http://code.google.com/p/tesseract-ocr/downloads/list**

> ## Linux
> 
> Tesseract is available directly from many Linux distributions. The package is generally called 'tesseract' >or 'tesseract-ocr' - search your distribution's repositories to find it. Packages are also generally available >for language training data (search the repositories,) but if not you will need to [download the appropriate >training data](http://code.google.com/p/tesseract-ocr/downloads/list), unpack it, and copy the >.traineddata file into the 'tessdata' directory, probably `/usr/share/tesseract-ocr/tessdata` or >`/usr/share/tessdata`.
> 
> If Tesseract isn't available for your distribution, or you want to use a newer version than they offer, you >can [compile your own](Compiling). Note that older versions of Tesseract only supported processing .tiff >files.

Thanks.
  I am trying to recognize a flawless image. I created the image from a pdf that is all vector, not image. It has no noise, no skew, flawless characters in any DPI that I want.

The recognition from Tesseract sucks. Generally the problem is dropped characters. It seems to randomly ignore perfectly good looking characters.

The screen shot shows the text results in the upper left and the image in the background (only the upper left of the image is visible). The bounding boxes of the results are shown in red on that image. Notice all the missing characters. On this particular image all the characters to the right of what you can see are found and recognized properly. The image consists of a table of information (rows of item #, size, description, and qty). The columns are not nicely aligned (although this example is pretty good). Some rows are separated by a line (this example has a line for each row, and notice that tesseract gives me a bounding box for some of the lines, but not all). I tried removing the lines, but that just changed the set of dropped characters with no rhyme or reason to it. Other images from this same set are very similar but tesseract will drop characters on the right, or whole lines will be missing. I have tried different DPI from 75 to 300, but the results were just as disappointing. 

Can anyone suggest how this might be solved?

![badocr](https://cloud.githubusercontent.com/assets/353400/13625650/bb6524b6-e56e-11e5-9e43-39140ee796c3.png)
  I am building tesseract on msys2 on windows. I am using the latest version of leptonica (1.73) which generates liblept-5.dll However, when I run tesseract 3.04.01 it gives the following error.

User@HP MINGW32 ~/tesseract-ocr
$ tesseract -v
C:/msys32/mingw32/bin/tesseract.exe: error while loading shared libraries: liblept-4.dll: cannot open shared object file: No such file or directory

I copied liblept-5.dll as liblept4.dll and was able to run the program - see below.

User@HP MINGW32 ~/tesseract-ocr
$ tesseract -v
tesseract 3.04.01
 leptonica-1.73
  libgif 5.1.2 : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.6.21 : libtiff 4.0.6 : zlib 1.2.8 : libwebp 0.5.0

Wiki states:
*\* 3.04 requires at least v1.71 of Leptonica.**

Is 3.04.01 compatible with leptonica 1.73?
 Yes, I had used a PKGBUILD similar to the following, without the prepare
section. After Zdenko's comment I have added autogen.sh to it also. Need to
build it again to test.

# Maintainer: Alexey Pavlov alexpux@gmail.com

# Maintainer: Ray Donnelly mingw.android@gmail.com

_realname=tesseract-ocr
pkgbase=mingw-w64-${_realname}
pkgname="${MINGW_PACKAGE_PREFIX}-${_realname}"
pkgver=3.04.01
pkgrel=2
pkgdesc="Tesseract OCR (mingw-w64)"
arch=('any')
url="https://github.com/tesseract-ocr/tesseract"
license=("Apache License 2.0")
makedepends=("${MINGW_PACKAGE_PREFIX}-gcc"
"${MINGW_PACKAGE_PREFIX}-pkg-config")
depends=(${MINGW_PACKAGE_PREFIX}-cairo
         ${MINGW_PACKAGE_PREFIX}-gcc-libs
         ${MINGW_PACKAGE_PREFIX}-icu
         ${MINGW_PACKAGE_PREFIX}-leptonica
         ${MINGW_PACKAGE_PREFIX}-pango
         ${MINGW_PACKAGE_PREFIX}-zlib
         ${MINGW_PACKAGE_PREFIX}-tesseract-data-eng)

source=(${_realname}-${pkgver}.tar.gz::
https://github.com/tesseract-ocr/tesseract/archive/${pkgver}.tar.gz

https://github.com/tesseract-ocr/tessdata/raw/master/osd.traineddata )
sha256sums=('57f63e1b14ae04c3932a2683e4be4954a2849e17edd638ffe91bc5a2156adc6a'

'9cf5d576fcc47564f11265841e5ca839001e7e6f38ff7f7aacf46d15a96b00ff')

options=('!libtool' 'strip')

prepare() {
  cd "${srcdir}/tesseract-${pkgver}"
  ./autogen.sh
  }

build() {
  cd "${srcdir}/tesseract-${pkgver}"
  [[ -d "${srcdir}"/build-${CARCH} ]] && rm -rf "${srcdir}"/build-${CARCH}
  mkdir -p "${srcdir}"/build-${CARCH} && cd "${srcdir}"/build-${CARCH}

  local -a extra_config
  if check_option "debug" "y"; then
    extra_config+=( --enable-debug )
  fi

  ../tesseract-${pkgver}/configure \
    --build=${MINGW_CHOST} \
    --host=${MINGW_CHOST} \
    --target=${MINGW_CHOST} \
    --prefix=${MINGW_PREFIX} \
    LIBLEPT_HEADERSDIR=${MINGW_PREFIX}/include \
    "${extra_config[@]}"

  make
}

package() {
  cd "${srcdir}/build-${CARCH}"
  make DESTDIR="${pkgdir}" install
  make training
  make DESTDIR="${pkgdir}" training-install

  mkdir -p $pkgdir/${MINGW_PREFIX}/share/tessdata
  install -Dm0644 $srcdir/osd.traineddata
$pkgdir/${MINGW_PREFIX}/share/tessdata/osd.traineddata
  cp $srcdir/tessdata/eng.\* $pkgdir/${MINGW_PREFIX}/share/tessdata
  cp $srcdir/tessdata/configs/bazaar
$pkgdir/${MINGW_PREFIX}/share/tessdata/configs
  find $pkgdir/${MINGW_PREFIX}/share/tessdata -type f -exec chmod 0644 {} \;
}

ShreeDevi

---

भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Mar 9, 2016 at 12:26 AM, Amit Dovev notifications@github.com
wrote:

> Did you recompile (./configure, make, sudo make install, sudo ldconfig)
> tesseract after you recompiled leptonica 1.73?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/258#issuecomment-193914371
> .
 I have built Leptonica 1.73 on msys2 locally. It is not yet reflected in
Msys2 repository.

ShreeDevi

---

भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Mar 9, 2016 at 1:05 PM, zdenop notifications@github.com wrote:

> rebuilding tesseract does not help unless leptonica instalation is not
> fixed within msys...
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/258#issuecomment-194153653
> .
 No liblept.dll.

I have liblept.a and liblept.dll.a in lib directory and liblept-5.dll in
bin directory.

ShreeDevi

---

भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Thu, Mar 10, 2016 at 6:57 PM, Amit Dovev notifications@github.com
wrote:

> Do you have liblept.dll?
> It should be a symlink to liblept-5.dll
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/258#issuecomment-194838358
> .
 Amit & Zdenko.

Yes, the problem on msys2 maybe because I am trying to use the PKGBUILD
system for building the software (which is what was recommended by the
msys2 developers when I was trying to build the earlier release by hand).

I was able to build and run 1.73 leptonica and the latest source of
tesseract on ubuntu 14.04 without problems.

Thanks!

ShreeDevi

---

भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Fri, Mar 11, 2016 at 5:41 PM, zdenop notifications@github.com wrote:

> Real problem is that he has several installation of leptonica but msys
> instruct linker to use older leptonica version (which could be reasonable
> if older version was installed by msys packagin system and new version "by
> hand") . There are several ways how to solve it:
> 1. learn how you environment/system is working, how to manage it
> 2. If 1. is not option - wait for official packages and do to try to
>    compile from source
> 3. Use only one version of software => do not use packaging system,
>    but compile from source. From my experience, this option will sooner or
>    later lead to the current status (something goes wrong and I have not clue
>    why) ;-).
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/258#issuecomment-195344279
> .
 I did not run
sudo ldconfig
after building leptonica, but did after building tesseract.

I used the following commands:

./autogen.sh
./configure
LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make
sudo make install
sudo ldconfig
LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make training
sudo make training-install

ShreeDevi

---

भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Fri, Mar 11, 2016 at 7:41 PM, Amit Dovev notifications@github.com
wrote:

> Shree,
> 
> Here are the commands I ran on Linux:
> 
> cd path/to/leptonica-1.73
> 
> ./configure
> make
> sudo make install
> sudo ldconfig
> 
> cd path/to/tesseract-ocr
> ./autogen.sh
> ./configure  --enable-debug
> make
> sudo make install
> sudo ldconfig
> make training
> sudo make training-install
> 
> Did you run sudo ldconfig ?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/258#issuecomment-195380654
> .
 Thanks, please change the wiki.

ShreeDevi

---

भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sun, Mar 13, 2016 at 8:24 PM, Amit Dovev notifications@github.com
wrote:

> http://tldp.org/HOWTO/Program-Library-HOWTO/shared-libraries.html
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/258#issuecomment-195970355
> .
  Hi,

I am currently working on license plate recognition and for that i am using tesseract3.03 on windows. For the same purpose I have trained the tesseract with 1500 images of alpha numeric characters.When I am testing tesseract for same images then GetUTF8Text returns NULL.Specially mostly for N,M, and W characters.I have attached 3 images as samples. 

As detail, I have set the vaiable PageSegMode="PSM_SINGLE_CHAR".Besides,I have already tried preprocessing and resolution techniques for input image to resolve the problem.

PLEASE HELP!!!

It would be helpful even if I can know the roll of GetUTF8Text in giving the NULL output for an images.
![696](https://cloud.githubusercontent.com/assets/10992866/13593034/c0173e96-e51d-11e5-846e-12a3b46de8d1.jpg)
![742](https://cloud.githubusercontent.com/assets/10992866/13593032/c0129f62-e51d-11e5-833a-89add68d42f8.jpg)
![1022](https://cloud.githubusercontent.com/assets/10992866/13593033/c016d622-e51d-11e5-8bdb-0b335026a415.jpg)
  It doesn't look to me like `classify_enable_adaptive_matcher=0` is really supported any more. A bunch of the new code that's been added isn't conditionalized to check it.

The reason that it doesn't crash when the config variable is set on the command line is because that's done after the recognizer is initialized, so the necessary data structure has been created.
 The config file is processed in the Init call here:

https://github.com/tesseract-ocr/tesseract/blob/master/api/tesseractmain.cpp#L372

while the command line config variables are processed in the call
to SetVariablesFromCLArgs here:

https://github.com/tesseract-ocr/tesseract/blob/master/api/tesseractmain.cpp#L379

after the adaptive matcher has already been set up.

Even though the command line case doesn't crash, it is still using the
adaptive matcher because the code that references it isn't guarded by the
necessary config variable.
 Good suggestions, but neither is relevant here because `classify_enable_adaptive_matcher` isn't an init only parameter.

The issue is that the code has evolved so that `classify_enable_adaptive_matcher=0` is no longer supported. There are sections of code which don't check this config variable and which assume that the adaptive matcher is correctly initialized.  We can either drop the config variable or fix the code so that the variable protects everything that needs to be protected. I don't know how much work that'll be, but it's more than just this one place, because I fixed it and it just died somewhere else. No idea how many places there are to fix or whether it makes sense from @theraysmith's point of view to continue supporting this case.

In my opinion, the current order of evaluation (config files, then command line) is correct because it allows the config file to be overridden by the command line.
  Hi,

if seems, that moving PageIterator\* AnalyseLayout() to api/baseapi.h[1] causes a silent ABI breakage. Could you please move it back to api/baseapi.cpp? Please see the corresponding Debian bugs for reference [2], [3].
I could prepare a PR if you prefer. 

Thanks,
Philip

[1] https://github.com/tesseract-ocr/tesseract/blob/master/api/baseapi.h#L500
[2] https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=816857
[3] https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=815056#24
 See also the tail end of https://groups.google.com/forum/#!topic/tesseract-dev/8e0F2cK2YzU
 Here you go: PR #259
 Please make sure this reaches the 3.04 branch.
  I put together a simple test program that demonstrates the issue:
https://github.com/matthill/tesseract_z_issue/tree/master

Given an input image that is a "N", Tesseract seems to rotate this single character to produce high confidence for "Z" and "2" characters.  Only the "N" and "M" characters would be expected.
# tesseract_z_issue

![Z Character](https://raw.githubusercontent.com/matthill/tesseract_z_issue/master/z.png)

Input training data is here: [tif](https://github.com/openalpr/train-ocr/blob/master/eu/input/leu.netherlands.exp0.tif?raw=true) [box](https://raw.githubusercontent.com/openalpr/train-ocr/master/eu/input/leu.netherlands.exp0.box)

After running the program, the output is:

```
[mhill@mhill-linux z]$ ./tesseract_z_test 
Z : 95.4505
symbol Z, conf: 95.450462 font: netherlands (index 1) size 53px - Z conf: 95.450462
            - N conf: 91.517166
            - 2 conf: 86.062859
            - M conf: 81.259239
---------------------------------------------
```

Z and 2 characters are not expected, it makes me wonder if the character is rotated when analyzed.
 Are you sure that you're not closing a real issue here?  I assume that Tesseract is trying to rotate an individual character crop 90 degrees and getting better recognition.  I assume that changing the training data would not affect this.  Do you believe that changing the training input data would resolve this issue?

I did not use a font to train this language, these are actual binarized letter samples from real data (license plates).  I'm not sure I understand your comment "font seem to be common."  Can you help me understand what you mean?

My use case is individual character recognition, rather than words/lines of characters.  The recognition is only used for one character at a time (no segmentation) so I don't believe the order of the characters in the tif/box matters.  Am I mistaken?  Do you expect that changing the order of the characters could affect individual character recognition?  My experimentation with Tesseract leads me to believe that this is not true.
  from
https://github.com/tesseract-ocr/tesseract/tree/master/tessdata
 I had problems earlier while opening pdf files that were created without pdf.ttx being present in tessdata. 

But that seems to have been fixed and looks like pdf.ttx is no longer required (I looked at the history ..https://github.com/tesseract-ocr/tesseract/commits/master/tessdata/Makefile.am 
 Problem report is incorrect. `pdf.ttx` has never been required for Tesseract PDF generation.  `pdf.ttx` is simply a human readable representation of the invisible font. I only use it when trying to figure out font related problems. And I typically generate it when needed; there is no need to distribute with Tesseract at all.
 You are right, `GlyphLessFont.h|cpp` should be removed. They were important at one time, but are no longer relevant or useful. (Back in the old days, two months ago, the software that converts ttx to ttf and back was not smart enough to handle our font. Now it is.)
  Hi,
There is a function **main()** at the end of [viewer/svpaint.cpp](https://github.com/tesseract-ocr/tesseract/blob/d7b089fbcf8f1582e8e897f7c8572433b662f533/viewer/svpaint.cpp#L221), which is compiled and exported when building the library. I think it shouldn't be there, or it should be protected by some define so you only compile it when you need it 
 I saw it, but as graphics is enabled by default, and as it enables more functions (apart from main), I thought that disabling graphics would also disable more functions and disable some functionality (perhaps all those functions are only used by that main() so it doesn't matter, but I don't know)

So, by default the library is compiled with a main() function, I could --disable-graphics. However, I don't think it's a good idea to put main inside a library or, if needed (why?), to be the default behavior.

Could it be that main() is used by some the executable and it is also included in the library by mistake? 

Cheers.
  [otsuthr.cpp:52]: (style) Variable 'histogramAllChannels' is allocated memory that is never used.

Suggest move new & delete of histogramAllChannels inside the #ifdef USE_OPENCL
.
  `unicharset_extractor *.box`  giving an error in version 3.05.00 so does `mftraining`and `shapetraining`. Works fine in version 3.02.
`
 @zdenop I have installed the tesseract training tool, but how can I install `unicharset_extractor *.box`, `mftraining` `shapetraining`. Can you provide with the necessary links? 
  I'm not sure this is the best fix for the issue, but it does provide a workaround while someone works out what the root cause is and where it should really be fixed.
 I've cleaned up the cosmetic issues. 

Any insight into what the root cause is? I'm not sure that this is more than a bandaid.
    Trivial patch to expose the used tessdata_prefix in the public API.
 Oh, not sure how I managed to miss that one. Thanks!
  Hi, 
I noticed different results when analyzing the same PNG image having 8 different colors when it is encoded with a colormap of 8 or 256 colors.

**Version:**

```
tesseract 3.05.00dev
 leptonica-1.73
  libjpeg 8d : libpng 1.2.49 : libtiff 4.0.3 : zlib 1.2.8
```

**Demo:**
french subtitle conversion from XFiles-S01E01 (DVB). The subtitle image extracted with ProjectX as a BMP has 8 distinct colors. It was converted to PNG with two different programs.
'ok.png', 256 entries colormap:
![ok](https://cloud.githubusercontent.com/assets/17527508/13379299/52a4e02c-de22-11e5-9b68-47bb8a5b5180.png)
Tesseract result is correct:

```
$ tesseract -l fra ok.png stdout
La mort a eu lieu
il y a 8 à 12 heures.
```

'nak.png' 8 entries colormap:
![nak](https://cloud.githubusercontent.com/assets/17527508/13379305/6e9dd8ec-de22-11e5-910c-1c89dd76594a.png)

Tesseract result is wrong:

```
$ tesseract -l fra nak.png stdout
La morte eu lieu
il y a 8 à 12 heures.
```

 The image type is either recognized as 4 or 8 bpp but the information content is identical:

```
$ pngtopnm ok.png|md5sum
cbe58b4e03ebbe279958287e8d53f719  -
$ pngtopnm nak.png|md5sum
cbe58b4e03ebbe279958287e8d53f719  -
```

I suspect that tesseract internal processing keeps the original image bit depth and that some steps don't work as well at 4bpp as at 8bpp.

External workaround: 

```
pngtopnm nak.png | tesseract -l fra stdin stdout
La mort a eu lieu
il y a 8 à 12 heures.
```

Quick patch to do this conversion internally in libtesseract:

```
 --- api/baseapi.cpp.orig   2016-02-18 08:48:00.000000000 +0100
+++ api/baseapi.cpp 2016-02-28 13:41:08.056037716 +0100
@@ -1195,6 +1195,12 @@
                               const char* retry_config, int timeout_millisec,
                               TessResultRenderer* renderer) {
   PERF_COUNT_START("ProcessPage")
+  // convert 4bit to 8bit data for improved processing
+  if (pix->d==4) {
+    Pix* pix2=pixConvert4To8(pix,(pix->colormap)!=NULL);
+    pixDestroy(&pix);
+    pix=pix2;
+  }
   SetInputName(filename);
   SetImage(pix);
   bool failed = false;
```

I am not sure if this is the correct strategy to deal with this issue, nor if it is the right place to change the data type. 4-color DVB subtitles exist, so 2bpp images should probably also be considered.

Thanks for this soft, works great for me.
-- Bruno
 Mmm yes...

Well two approaches from my point of view:

1) the user has to deal with the image format, but it should be mentioned in the man page and a warning should be issued when a palette color image is detected. Maybe the image should just be rejected.

or

2) tesseract should do its best with the data it receives and convert them to the internal format it needs for optimal processing.

I really think something should be done, because people will just (wrongly) conclude that tesseract is bad at reading a really clear-looking picture...

( I was very close to that conclusion but I was saved by the fact that previous trials with much lower quality pictures (vobsub output of ProjectX) had given the correct result for that precise subtitle. But other errors in about 10% of subtitles.)
 The 0.25 R + 0.5 G + 0.25 B calculation designed to give fast results, not accurate ones. Sounds like someone may be calling pixConvertRGBToGrayFast() instead of pixConvertRGBToGray(). This seems like a bad idea if it is affecting results. And I also don't understand why we would ever threshold on R,G,B individually. The normal thing to do is calculate luminance, then threshold on luminance.

Leptonica is really, really good at image binarization. We should be making use of it.
 @bruvi where exactly is the 0.25 R + 0.5 G + 0.25 B conversion happening?
 If we use sRGB perceptual weightings then it works.

`graymap[i] = 0.2126  * rmap[i] + 0.7152 * gmap[i] + 0.0722 * bmap[i];`

```
tesseract -l fra /tmp/nak.png -
La mort a eu lieu
il y a 8 à 12 heures.
```

If we use "Leptonica" perceptual weightings, then it fails.

`graymap[i] = 0.3 * rmap[i] + 0.5 * gmap[i] + 0.2 * bmap[i];`

```
tesseract -l fra /tmp/nak.png -
La morte eu lieu
il y a 8 à 12 heures.
```

If I remove the colormap before anything else, then it works. I think this is the right solution because it guarantees consistency (e.g. colormap vs. non-colormap will not change results if image is otherwise identical). Leptonica should switch to some sort of perceptual weighting for the next release because that is a no-brainer, but will not have any effect on Tesseract if we remove the colormap first.

``` diff
--- tesseract/ccmain/thresholder.cpp    2014-07-11 11:28:02.000000000 -0700
+++ tesseract/ccmain/thresholder.cpp    2016-03-11 10:01:36.000000000 -0800
@@ -149,17 +149,23 @@
   if (pix_ != NULL)
     pixDestroy(&pix_);
   Pix* src = const_cast<Pix*>(pix);
-  int depth;
-  pixGetDimensions(src, &image_width_, &image_height_, &depth);
   // Convert the image as necessary so it is one of binary, plain RGB, or
   // 8 bit with no colormap.
+  Pix *tmp;
+  if (pixGetColormap(src)) {
+    tmp = pixRemoveColormap(src, REMOVE_CMAP_BASED_ON_SRC);
+  } else {
+    tmp = pixClone(src);
+  }
+  int depth;
+  pixGetDimensions(tmp, &image_width_, &image_height_, &depth);
+
   if (depth > 1 && depth < 8) {
-    pix_ = pixConvertTo8(src, false);
-  } else if (pixGetColormap(src)) {
-    pix_ = pixRemoveColormap(src, REMOVE_CMAP_BASED_ON_SRC);
+    pix_ = pixConvertTo8(tmp, false);
   } else {
-    pix_ = pixClone(src);
+    pix_ = pixClone(tmp);
   }
+  pixDestroy(&tmp);
   depth = pixGetDepth(pix_);
   pix_channels_ = depth / 8;
   pix_wpl_ = pixGetWpl(pix_);
```

```
tesseract -l fra /tmp/nak.png -
La mort a eu lieu
il y a 8 à 12 heures.
```
 Ray is going to write the official change. Best to coordinate with him. He is doing the same thing, but with a different way of writing the code.
  I've tried to compile the main vs2010 project and even with x32 it doesn't work. requires 
allheaders.h file. 
Error   2   error C1083: Cannot open include file: 'allheaders.h': No such file or directory    

If I'm not wrong this file is a leptonica file, but leptonica is not provided in the solution. Why is this dependency still needed to compile only tesseract libraries? 
 Hi, I will edit the issue so it only have the issue itself.
  I have an image with barely 20 lines of text (I have the image that I can provide), and it's taking seconds and seconds to read the text.
I'm using VS2010.
I provided the binary image (very clean) to Tesseract. Tesseract works fine but it's too too slow.

I'm impressed by the accuracy of Tesseract, but the speed is a disaster!
I used other commercial OCR engines: accuracy less but speed much faster.

how to improve the speed of tesseract? anyway to read an image in few 100s of milliseconds.

thanks
 I posted my message on the google groups,
  I have tested latest release 3.05 on windows platform to OCR Arabic document to PDF (searchable) and when choose text from output PDF file it seems stored in opposite (left to right) and letters should be stored from (Right to left)!!!

i.e. original text In Arabic is
مرحبا
Stored in PDF as text as
ابحرم
 ​please put your sample file and the command you used for ocr job​
 This is the command:

tesseract  c:\temp\test_ara.jpg  -l ara  -psm 3  c:\temp\test_ara pdf

Files are attached (source JPG and output PDF)

![test_ara](https://cloud.githubusercontent.com/assets/17473681/13320324/bc160e22-dbd0-11e5-8090-6f3728fcc06d.jpg)
[test_ara.pdf](https://github.com/tesseract-ocr/tesseract/files/146534/test_ara.pdf)

please check original word
أنحاء
output inside PDF is
ءاحنا
 Command and Samples are attached now in the previous comment
 @amitdo 
is there any way to reach a better accuracy in Arabic language until to change to new engine?
now with tesseract i get about 100% accuracy  in English but for Arabic result is about 30-40%
but for example i checked google drive ocr for Arabic and i see it have 100 results for same image..

can we work on language data for a better results?
 I am using Adobe Reader.
But please note that words are not reversed while viewing the PDF because it contains the original image with text layer.
I mean when you copy text layer then paste it to any text editor it will be reversed, so now can't search for the text inside the PDF because it is stored revered inside the text layer!
 This is a serious issue with the PDF output feature using Arabic Language and similar languages that be written from right to left
 I try hard to make sure Arabic and other right-to-left languages work correctly in Tesseract PDF. As the problem is isolated further I'm happy to look, but I'm not aware of any reason things would have broken. 
 A quick check shows Chrome gives good results (as per amitdo) and Acroread gives bad results (as per tbadran). This is surprising, I thought we were good with Acroread. I wonder if this is a regression and if so when it occurred.
 Regarding recognition accuracy, that's a better topic for the forum. But in short: Don't compare against Google Drive. Don't expect major accuracy improvements unless/until Ray is successful with his ideas. And most importantly, don't trust any predictions about 'soon'. That last one is true for all software everywhere.
 Please note my testing using the binaries for Windows downloaded from:
http://domasofan.spdns.eu/tesseract/ 
and I am Using Windows 10 with Acrobat Pro 11 to view output PDF file
 I have tested multiple different sample files not only sample uploaded above and every time getting same issue in output PDF on windows 10 + Acrobat Pro 11
 On OS X, I'm seeing the opposite of earlier reports: 
- Acrobat Reader DC 15.10.20056.167417 appears correct when cutting & pasting
- Google Chrome Version 48.0.2564.116 (64-bit) appears backwards
 Adobe Acrobat:

امهمه مني اهادم
ةييرعلا ةغللا
. هم دهج ةغل
ملاعلا ءاحنا يه هرنسم

Google Chrome

مداها ينم همهما
اللغة العريية
لغة جهد مه
مسنره هي انحاء العالم
 I find it a little easier to test with Hebrew because the letters do not connect. Tesseract version 3.03 behaves the same, so this is not a regression. Will need to think about this, because it is not obvious what exactly is going wrong. Lots of PDF files do a crazy 'write it backwards' strategy but that should not be required. Tesseract writes in reading order.
 There are two things I can think of doing. One is to give up and write Arabic 
backwards (which I really hate!). The other is  to put an entry in  the PDF
metadata, Catalog/ViewerPreferences/Direction. Will continue thinking about
this, slowly.
 @amitdo Hebrew has the exact same problem as Arabic.
 That's another possibility, thanks for the suggestion.
 There are a number of issues relating to RTL and Arabic. Can they all be labelled with 'Arabic' for ease of finding, so that duplicate issues are not created.

https://github.com/tesseract-ocr/tesseract/issues?q=Arabic+in%3Atitle%2Cbody
gives a list of the same.
 That's good news. I promise that we'll give it a try as soon as it is available.
 Thanks.

ShreeDevi

---

भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Thu, Sep 15, 2016 at 12:20 AM, zdenop notifications@github.com wrote:

> Ray shared that he would like to have public alpha version by the end of
> September.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/238#issuecomment-247116411,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o53wUhtvKbMbG-B-TAutJfk3h64vks5qqEIDgaJpZM4His6k
> .
 hi, where can i get the arabic tessdata files? 
also, where do we get all other language files?
thanks
 ara.\* from https://github.com/tesseract-ocr/tessdata (Version 3.02)

https://github.com/tesseract-ocr/langdata/tree/master/ara (Version 3.04)
 https://github.com/tesseract-ocr/tessdata

Download all ara.\* Files for Arabic

Other language data files are also in same repository

On 21 Oct 2016 6:07 a.m., "Mehmet Altuntas" notifications@github.com
wrote:

> hi, where can i get the arabic tessdata files?
> also, where do we get all other language files?
> thanks
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/238#issuecomment-255288956,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_oxpzfVP9cDcNP9gxAe_kqigEshyfks5q2DpygaJpZM4His6k
> .
 The tesseract/langdata/ara repo has the 3.04 source files for Arabic
language data.

The Arabic traineddata is based on cube engine and is the 3.02version.

On 21 Oct 2016 11:56 a.m., "ShreeDevi Kumar" shreeshrii@gmail.com wrote:

> https://github.com/tesseract-ocr/tessdata
> 
> Download all ara.\* Files for Arabic
> 
> Other language data files are also in same repository
> 
> On 21 Oct 2016 6:07 a.m., "Mehmet Altuntas" notifications@github.com
> wrote:
> 
> > hi, where can i get the arabic tessdata files?
> > also, where do we get all other language files?
> > thanks
> > 
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > https://github.com/tesseract-ocr/tesseract/issues/238#issuecomment-255288956,
> > or mute the thread
> > https://github.com/notifications/unsubscribe-auth/AE2_oxpzfVP9cDcNP9gxAe_kqigEshyfks5q2DpygaJpZM4His6k
> > .
 @jbreiden
Did you find a solution? ​is there any milestone to drop cube completely!?​
 >​is there any milestone to drop cube completely!?​

This issue is not caused by cube.

See https://github.com/tesseract-ocr/tesseract/issues/40#issuecomment-263039665 The Adobe folks suggested a few things to try, none of which worked so far. Still open and (relatively) active. Please tell us which pdf viewer you already tested if any. @jbreiden  Here is a more thorough examination of "ara.pdf" [that you posted in your comment](https://github.com/tesseract-ocr/tesseract/issues/238#issuecomment-296256374)

1) Wrong sentence order: 
    some sentences are over-stepping their location in the paragraph, I discovered that this was caused by the software used to view the pdf, in my case Chrome, but after using Windows Reader the problem was solved.

![ara](https://cloud.githubusercontent.com/assets/16248376/25373915/1eb574ba-29a4-11e7-8c5d-5bb4d0d1480d.jpg)


2) Repetitive mistakes:
    ( لا ) is wrongly represented as ( ال ) , which is actually opposite to the correct spelling. 
    ( ، ) is the Arabic Comma, is wrongly represented as ( ء ) or ( , ) or ( . ) or ( » )
    ( اً ) is represented by only ( ا ) , which is missing (  ً   ) 
    some rare cases of multiple combined words, there are 2 separate cases ( مرحامستبشرا ) and( منالناس ) ,    should be ( مرحاً مستبشرا ) and ( من الناس )


3) Rare Case:
    When I copied the text to Microsoft Word, most of the font was in Arial font except of a couple of ( . ) full-stops which were in Calibri font, a weird thing to see.

Conclusion:
Altogether, except for the mistakes that I stated earlier, the recognition rate was very good in this sample.

Note that in the Arabic language, the state of ( لا ) is frequently used, so-much that if this misrepresentation of it as ( ال ) is continued, it would degrade the recognition rate drastically.  


![untitled22](https://cloud.githubusercontent.com/assets/16248376/25375718/52063736-29aa-11e7-86ca-ff8851024c47.png)


 Hebrew report:

I highlighted the text in each pdf viewer, and pasted it to gedit.

With Chromium the straight version is mostly fine. There are problems when there is a combination of Hebrew and English/other ltr symbols in the same line.
The skewed version is not fine. The words appear in wrong order in each line.

The pasted text of the straight version does not look good when Evince and pdf.js are used.
pdf.js - there are line breaks after each word.
Evince - total mess. Wrong line breaks and wrong word order. Unusable. It will be helpful to compare the pasted text of these files to Tesseract's text renderer output, to see if each issue is really caused by the pdf renderer or by the ocr engine itself. I think we should also compare to the current (4.00 with lstm) pdf output, without your patch.
The original issue, reversed letters, was with the Adobe pdf viewer, not the other viewers.
  @christophered

The source of the 3 first mistakes in your 'Repetitive mistakes' section is the ocr engine itself, not the pdf renderer.

#648 is a more suitable place to report about them.
( لا ) vs ( ال ) is a known issue. See https://github.com/tesseract-ocr/tesseract/issues/648#issuecomment-285633162 and the comments below it.  >some rare cases of multiple combined words

It's not clear if the source for this issue is the pdf renderer or the ocr engine itself. I discovered that the Sentence disorder is caused by Chrome which I used to view the PDF.
Note that after using Windows Reader the PDF was viewed correctly without the disorder that I mentioned. @christophered,
We want that it will be displayed fine in all major pdf viewers, not just one. >Note that after using Windows Reader the PDF was viewed correctly

Which Windows version?

If you have Windows 10, try to open the pdf file with the Edge browser, and report how it is displayed there. I am using Windows 8 Amit, the PDF displays the original image only, so lookswise it will be the
same. It is the text layer, as copied or saved which is different.

I can test on windows10 and post the result. Someone else will have to tell
if it is ok or not.

Even with legacy Devanagari fonts that use Latin range, I have found that
copied text is different between Adobe reader and foxit reader.

- excuse the brevity, sent from mobile

On 25-Apr-2017 6:05 PM, "Amit D." <notifications@github.com> wrote:

> Note that after using Windows Reader the PDF was viewed correctly
>
> Which Windows version?
>
> If you have Windows 10, try to open the pdf file with the Edge browser,
> and report how it is displayed there.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/238#issuecomment-297015981>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o7IteyLCIpPyivdsXVRS2B3QTGe_ks5rzeiagaJpZM4His6k>
> .
>
 Me:
>If you have Windows 10, try to open the pdf file with the Edge browser, and report how it is displayed there.

@Shreeshrii :
>Amit, the PDF displays the original image only, so lookswise it will be the same. It is the text layer, as copied or saved which is different. 

Yes. Although I said 'displayed', I meant to refer to the "invisible text layer underneath the visible image, which can be copied and pasted to text editor".

I just made a shortcut, assuming people will understand what I really meant. 
Maybe I should add **excuse the brevity, sent from my PC** to my comments...
:rofl:  @amitdo funny joke :) I downloaded ara.pdf (EXPERIMENT) version and opened in Adobe Reader XI and Foxit Reader 8.1 under Windows 10 and copied and pasted the text in Notepad++ under Windows 10.

Both text files look different - with text order being opposite of each other. Please see attached.

![ara-error](https://cloud.githubusercontent.com/assets/5095331/25424660/c1b7b85c-2a86-11e7-8006-8a4215d26812.png)
[ARA-ADOBE-XI.txt](https://github.com/tesseract-ocr/tesseract/files/957656/ARA-ADOBE-XI.txt)

[ARA-FOXIT-8.1.txt](https://github.com/tesseract-ocr/tesseract/files/957657/ARA-FOXIT-8.1.txt)
 Additionally, on windows 10, in both Edge as well as the windows 10 pdf reader I am not able to copy text. 

Text copied in Chrome version is similar to Foxit, but with additional line breaks. @christophered can check whether the order is also changed.

![ara-chrome-error](https://cloud.githubusercontent.com/assets/5095331/25425054/42b71aa0-2a88-11e7-9891-e55475dd16b7.png)
[ara-chrome.txt](https://github.com/tesseract-ocr/tesseract/files/957672/ara-chrome.txt)
 Windows 10 - Internet Explorer - text matches output from Adobe Reader XI.

[ara-internet-explorer.txt](https://github.com/tesseract-ocr/tesseract/files/957692/ara-internet-explorer.txt)
 @Shreeshrii ARA-FOXIT-8.1.txt is the most adequate one in terms of sentence organization. 

It seems that Chrome splits the sentence into half, each at a new line. I only checked the straight version of the Hebrew document.

The control is much worst with Evince and pdf.js.
`Hello` ->  `olleH` (pdf.js) / `o l l e H`  (Evince)

Chromium: The two look the same, except the two last lines.
Both are not good, but the experiment is worst than the control.
The digits in the zip code and the phone numbers are in the wrong order.
`123-4567890` -> `0987654-321`
The date on top `21.07.2009` is OK.

I will check the skewed version later.  Skewed version, Chromium:

Both have wrong word order in each line (but not exactly the same).

Experiment:
The second word in the document is missing.
Two separate lines become one. Hebrew line + English line (site address).
Last lines - same issue as the straight version. @amitdo 
Using the latest Tesseract  4.0 alpha and the latest best Arabic model, I created a searchable pdf output:

- When using Chrome to view the pdf, the text can be selected/copied/pasted correctly (RTL).
- When using Adobe Acrobat Reader 17.012 (latest to date), though the text is displayed correctly, but when selected/pasted, is in reverse text (LTR). @amitdo 
Using the latest ABBYY FineReader 14 to create a searchable pdf:
- Both Chrome and Adobe Acrobat Reader can select/copy/paste correctly.

Conclusion:
It seems that Tesseract needs tweaking to solve this problem.

[Original Image.zip](https://github.com/tesseract-ocr/tesseract/files/1257071/Original.Image.zip)
[Tesseract.pdf](https://github.com/tesseract-ocr/tesseract/files/1257075/Tesseract.pdf)
[Abby Finereader.pdf](https://github.com/tesseract-ocr/tesseract/files/1257074/Abby.Finereader.pdf)

 >It seems that Tesseract needs tweaking to solve this problem.

The patch was not applied yet, so the original issue still exists.

>Looking at this again. Slowly losing the remainder of my sanity.

It could be worse if you were rapidly losing your sanity :-)

You are using a simple reverse here. That's not good enough for bidi text.  I wonder what is improved ver. 3.04. more detail especially these list.
- Improved font identification
- Fixed problems with shifted baselines so recognition can recover from layout analysis errors.
- Improved single column layout analysis
- Many bug fixes.

thanks!!
  I using tessract Android (tess-two) on nexus 7 and pc(core i5), with 1 image 1024x200
nexus 7:  10s and pc: 1s, what happen? Is there any way improve speed ocr when using in Android? Please help me! Thank.
 Some things that might make it faster are:
Select a smaller region from mGray where your text is, before createBitmap - so the more heavy methods that follow process a smaller image.
Changing Bitmap.Config.ARGB_8888 to Bitmap.Config.RGB_565 - your image is grayscale, it will not need a ARGB bitmap.
more may help: [OCR technology: ](http://www.myknown.com/ocr/)[improve OCR speed](http://www.myknown.com/ocr/improve-ocr-speed/)
  I've noticed a couple of mixed language items which cause Tessearct v3.04.01 (Leptonica 1.72) to crash:

```
cadams@ganymede:~ $ tesseract 11002612_2_0183.jpg 11002612_2_0183 -l ara+fra 
Tesseract Open Source OCR Engine v3.04.01 with Leptonica
[DS] Profile read from file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz score is inf
[DS] Device[2] 1:HD Graphics 5000 score is 0.548963
[DS] Device[3] 0:(null) score is 1.080283
[DS] Selected Device[2]: "HD Graphics 5000" (OpenCL)
Warning in pixReadMemJpeg: work-around: writing to a temp file
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
no best words!!
Segmentation fault: 11
```

Here's an example image:
![11002612_2_0183](https://cloud.githubusercontent.com/assets/46565/13234277/d61cef4a-d985-11e5-962a-7c8c1e9f9773.jpg)

Interestingly, this appears to depend on the order of the languages – using `-l ara` or `-l fra` alone avoids the crash but specifying both in either order will cause it to crash.
 I had the same question but the behaviour is identical either with that environmental variable or even using Tesseract which wasn't built with OpenCL at all:

```
cadams@Ganymede:~ $ tesseract --version
tesseract 3.04.01
 leptonica-1.72
  libjpeg 8d : libpng 1.6.21 : libtiff 4.0.6 : zlib 1.2.5

cadams@Ganymede:~ $ tesseract 11002612_2_0183.jpg 11002612_2_0183 -l ara+fra
Tesseract Open Source OCR Engine v3.04.01 with Leptonica
Warning in pixReadMemJpeg: work-around: writing to a temp file
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
no best words!!
Segmentation fault: 11
```
 I updated the title. It wasn't clear that these were related since Arabic works fine on its own.

The commit which you referenced is shown as being included in the version (3.04.01) I'm using.
 I just ran into the exact same problem. Arabic alone is processed successfully, but when I try to get Arabic and English read at the same time, tesseract crashes. I'm using Windows version 3.05.00dev.

Another question (I'm totally new to tesseract): When I use arabic language recognition and I read a text with arabic letters, but latin numbers, the latin numbers are not recognized (that's why I wanted to add English as recognition language). In the file "ara.cube.lm" I found the line

`Digits=٠١٢٣٤٥٦٧٨٩0123456789`

Does this mean,latin numbers should be recognized when I only use arabic as recognition language?
 Here's the stack trace for the crash

```
(lldb) bt
* thread #1: tid = 0x68d487, 0x000000010002294d libtesseract.3.dylib`tesseract::Tesseract::ClassifyBlobAsWord(int, PAGE_RES_IT*, C_BLOB*, STRING*, float*) [inlined] WERD_CHOICE::rating(this=0x0000000000000000) const at ratngs.h:325, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x3c)
  * frame #0: 0x000000010002294d libtesseract.3.dylib`tesseract::Tesseract::ClassifyBlobAsWord(int, PAGE_RES_IT*, C_BLOB*, STRING*, float*) [inlined] WERD_CHOICE::rating(this=0x0000000000000000) const at ratngs.h:325
    frame #1: 0x000000010002294d libtesseract.3.dylib`tesseract::Tesseract::ClassifyBlobAsWord(this=<unavailable>, pass_n=2, pr_it=0x00007fff5fbff320, blob=0x0000000105418ab0, best_str=0x00007fff5fbfef40, c2=0x00007fff5fbfef3c) + 637 at control.cpp:1263
    frame #2: 0x0000000100021e66 libtesseract.3.dylib`tesseract::Tesseract::SelectGoodDiacriticOutlines(this=0x0000000101006400, pass=2, certainty_threshold=-8, pr_it=0x00007fff5fbff320, blob=0x0000000105418ab0, outlines=0x00007fff5fbff1c0, num_outlines=6, ok_outlines=0x00007fff5fbff320) + 118 at control.cpp:1124
    frame #3: 0x0000000100021283 libtesseract.3.dylib`tesseract::Tesseract::AssignDiacriticsToOverlappingBlobs(this=0x0000000101006400, outlines=0x00007fff5fbff1c0, pass=2, real_word=<unavailable>, pr_it=0x00007fff5fbff320, word_wanted=0x00007fff5fbff1a0, overlapped_any_blob=<unavailable>, target_blobs=0x0000000111b4e280) + 1923 at control.cpp:1023
    frame #4: 0x000000010001c514 libtesseract.3.dylib`tesseract::Tesseract::ReassignDiacritics(this=0x0000000101006400, pass=2, pr_it=0x00007fff5fbff320, make_next_word_fuzzy=0x00007fff5fbff25f) + 356 at control.cpp:936
    frame #5: 0x000000010001c249 libtesseract.3.dylib`tesseract::Tesseract::RecogAllWordsPassN(this=0x0000000101006400, pass_n=2, monitor=0x0000000000000000, pr_it=0x00007fff5fbff320, words=0x00007fff5fbff2d0) + 537 at control.cpp:258
    frame #6: 0x000000010001d877 libtesseract.3.dylib`tesseract::Tesseract::recog_all_words(this=0x0000000101006400, page_res=0x0000000106e30560, monitor=0x0000000000000000, target_word_box=0x0000000000000000, word_config=0x0000000000000000, dopasses=0) + 1095 at control.cpp:386
    frame #7: 0x000000010000a0ce libtesseract.3.dylib`tesseract::TessBaseAPI::Recognize(this=0x00007fff5fbff8c8, monitor=0x0000000000000000) + 750 at baseapi.cpp:895
    frame #8: 0x000000010000a92b libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPage(this=<unavailable>, pix=<unavailable>, page_index=<unavailable>, filename=<unavailable>, retry_config=0x0000000000000000, timeout_millisec=<unavailable>, renderer=0x00000000000000
```

but I think the problem is actually in either `classify_word_and_language` callees (`RetryWithLanguage` or the individual recognizers) which shouldn't be returning no words (like the double exclamation points imply) or in `ClassifyBlobAsWord` which shouldn't assume that there's always a raw choice available.

The latter is easier to do and I was too lazy to dig further into the recognizer, so I generated a patch for that which I'll post.
 Hi All,

Does Tesseract support script identification. I have bilingual pages and two different model for different scripts. I want to use a script identifier on each word and call my models accordingly for recognition.
Help will be appreciated.
 @anupamaray Please use the mailing list for questions (and don't hijack issues about unrelated topics). You'll get better answers if you include more details about the scripts, languages, etc.
 Is this issue still exist in 4.00 (code in master)?

Probably not, since cube was removed.

@Shreeshrii 
Can you test it? (ara+other lang) --oem 0 and --oem 2 - both use the tesseract mode, so the problem is in that code.
```
(gdb) run
Starting program: /usr/local/bin/tesseract test2.jpg test2-ara-fra --oem 0 -l ara+fra
warning: Error disabling address space randomization: Success
warning: linux_ptrace_test_ret_to_nx: PTRACE_KILL waitpid returned -1: Interrupted system call
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
tessdata_manager.SeekToStart(TESSDATA_INTTEMP):Error:Assert failed:in file adaptmatch.cpp, line 537

Program received signal SIGSEGV, Segmentation fault.
ERRCODE::error (this=this@entry=0x7fddaa95aff8 <_ZL13ASSERT_FAILED>, caller=caller@entry=0x7fddaa6adcc0 "tessdata_manager.SeekToStart(TESSDATA_INTTEMP)", action=action@entry=ABORT,
    format=format@entry=0x7fddaa695c94 "in file %s, line %d") at errcode.cpp:86
86            if (!*p)
(gdb) stacktrace
Undefined command: "stacktrace".  Try "help".
(gdb) backtrace
#0  ERRCODE::error (this=this@entry=0x7fddaa95aff8 <_ZL13ASSERT_FAILED>, caller=caller@entry=0x7fddaa6adcc0 "tessdata_manager.SeekToStart(TESSDATA_INTTEMP)", action=action@entry=ABORT,
    format=format@entry=0x7fddaa695c94 "in file %s, line %d") at errcode.cpp:86
#1  0x00007fddaa5b76e0 in tesseract::Classify::InitAdaptiveClassifier (this=this@entry=0x27e1b70, load_pre_trained_templates=load_pre_trained_templates@entry=true) at adaptmatch.cpp:537
#2  0x00007fddaa5af495 in tesseract::Wordrec::program_editup (this=this@entry=0x27e1b70, textbase=textbase@entry=0x27e1b58 "test2-ara-fra", init_classifier=<optimized out>,
    init_dict=<optimized out>) at tface.cpp:51
#3  0x00007fddaa4d6949 in tesseract::Tesseract::init_tesseract_internal (this=this@entry=0x27e1b70, arg0=arg0@entry=0x0, textbase=textbase@entry=0x27e1b58 "test2-ara-fra",
    language=language@entry=0x27f7d38 "ara", oem=oem@entry=tesseract::OEM_TESSERACT_ONLY, configs=configs@entry=0x7fffca100e30, configs_size=configs_size@entry=0,
    vars_vec=vars_vec@entry=0x605280 <main::vars_vec>, vars_values=vars_values@entry=0x605260 <main::vars_values>, set_only_non_debug_params=set_only_non_debug_params@entry=false)
    at tessedit.cpp:439
#4  0x00007fddaa4d7188 in tesseract::Tesseract::init_tesseract (this=0x27e1b70, arg0=arg0@entry=0x0, textbase=0x27e1b58 "test2-ara-fra", language=language@entry=0x7fffca101064 "ara+fra",
    oem=oem@entry=tesseract::OEM_TESSERACT_ONLY, configs=configs@entry=0x7fffca100e30, configs_size=configs_size@entry=0, vars_vec=vars_vec@entry=0x605280 <main::vars_vec>,
    vars_values=vars_values@entry=0x605260 <main::vars_values>, set_only_non_debug_params=false) at tessedit.cpp:345
#5  0x00007fddaa4825ac in tesseract::TessBaseAPI::Init (this=this@entry=0x7fffca100c70, datapath=0x0, language=0x7fffca101064 "ara+fra", oem=tesseract::OEM_TESSERACT_ONLY,
    configs=0x7fffca100e30, configs_size=0, vars_vec=vars_vec@entry=0x605280 <main::vars_vec>, vars_values=vars_values@entry=0x605260 <main::vars_values>,
    set_only_non_debug_params=set_only_non_debug_params@entry=false) at baseapi.cpp:306
#6  0x0000000000401fa2 in main (argc=7, argv=0x7fffca100df8) at tesseractmain.cpp:428
(gdb) quit

``` here's is the recognition of original sepia image - 
[test1-fra-ara-lstm.txt](https://github.com/tesseract-ocr/tesseract/files/679669/test1-fra-ara-lstm.txt)
 I just unpacked the ara.traineddata - it does not have the tesseract model
files in it.

combine_tessdata -u ara.traineddata ara.

Extracting tessdata components from ara.traineddata
Wrote ara.config
Wrote ara.unicharset
Wrote ara.punc-dawg
Wrote ara.word-dawg
Wrote ara.number-dawg
Wrote ara.freq-dawg
Wrote ara.lstm
Wrote ara.lstm-punc-dawg
Wrote ara.lstm-word-dawg
Wrote ara.lstm-number-dawg


ShreeDevi
____________________________________________________________
भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Sat, Dec 31, 2016 at 8:57 PM, Stefan Weil <notifications@github.com>
wrote:

> It was also sufficient to specify -l ara in my test.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/235#issuecomment-269869708>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o0ZzhLREr78qnJF_KgztsNsJEPDCks5rNnRsgaJpZM4HgCcw>
> .
>
 >I just unpacked the ara.traineddata - it does not have the tesseract model files in it.

It never had tesseract model files in it...

 ```
Warning in pixReadMemJpeg: work-around: writing to a temp file
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
no best words!!
Segmentation fault: 11

```
The original issue here should be tagged and tested against the 3.05 branch since it is related to cube. the ara.config file in ara.traineddata uses oem 1 (originally for cube and now for LSTM).

The current issue being seen with 4.0alpha, ara not working for --oem 0 and --oem 2 is to be expected since there is no Tesseract model for the Arabic language. So, instead of segfault, the message displayed should be something like the following ...

"Tesseract requested but not present, LSTM engine used instead".

Later, if non-LSTM recognizer is removed this will not apply. Yes Shree, you are right.  Hello,

I've been trying to use the C API of Tesseract for [PyOCR](https://github.com/jflesch/pyocr) (and so, indirectly, [Paperwork](https://github.com/jflesch/paperwork/)).

To do so, I've been looking for a way to pass an in-memory image to Tesseract (to avoid the use of temporary files). There is a function `TessBaseAPIProcessPage()`, but I've found no way to create the `struct Pix` it requires.

There is a C++ function `ProcessPagesFileList` that appears to do the job, but C functions are much  much easier to bind with Python than C++ ones.

Thanks in advance for your help,
 Sorry, my bad.
  The current multi-page TIFF handling is seriously sub-optimal. First, it unnecessarily reads the entire file into memory which can tie up many MB of memory unnecessarily when pages are being processed in a streaming fashion. Second, I'm pretty sure that accessing by page number causes the entire buffer to be parsed from the beginning every time incurring both processing cost and memory thrashing.
 Please be careful with changes. It is very important not to break streaming support. 

https://github.com/tesseract-ocr/tesseract/wiki/FAQ#how-to-do-streaming
 Whoever makes the changes will have to make sure that all the tests in the test suite pass, just like any other change to the code base.

Of course this wouldn't be necessary if, when streaming support was added, it was done with some recognition of the performance impact rather than just leaving comments like "To keep code simple we will also buffer data coming from a file." https://github.com/tesseract-ocr/tesseract/blob/master/api/baseapi.cpp#L1119
 I plead guilty on all counts. I wrote the streaming feature, I failed to write a test, I introduced the performance regression, I wrote the comment, and either I didn't notice the performance regression or failed to properly consider it. 

I will attempt to write a test for streaming, and will work with you on TIFF. TIFF is historically tricky for two reasons. One is the duplicated functionality on the OpenCL path. Hard to synchronize and hard to test. I personally can't seem to run the OpenCL path at all without a segfault. Second, under win32 is it hard or impossible to pass a file descriptor between different DLLs. Which is awkward because the libtiff API prefers to work with file descriptors instead of file pointers.
 @jbreiden I don't see any particular reason that your feature should be the first to have a test. As far as I can tell, there are no tests at all for the entire program. Can you point to a more complete description of the file descriptor issue? Does TIFFClientOpen help at all?

Some random, possibly relevant, tidbits:
- "TIFF is not a streamable format" - http://www.awaresystems.be/imaging/tiff/faq.html#q7
- the "streaming" support doesn't stream - at least for anything other than a list of file names. All other formats are read entirely into memory before any processing starts. That's a pretty narrow definition of streaming.
- file format sniffing requires 12 bytes, no more
- multi-page tiff is on an entirely separate code path, which may make it easier to handle differently
 I was intimately familiar with the topic a decade ago. I have
tried my best to repress the memories.

http://www.asmail.be/msg0054669449.html

It's nice that the filename is already being passed around;
if we're lucky, maybe we can get what you need without any
API changes. Just out of curiosity, what are you using
multipage TIFF for? I usually think fax images, which are
relatively tiny.

You are right, the streaming feature is super narrow. But
it is important for book digitization.
 @tfmorris  How about something like this? If you are happy with it, I'll hand this change over to Ray for review and eventual inclusion. No API changes. I think functionally it is exactly the same, except that a multipage TIFF from a file does not get buffered.

``` diff
--- api/baseapi.cpp 2016-03-11 14:29:36.000000000 -0800
+++ api/baseapi.cpp 2016-03-28 15:49:06.000000000 -0700
@@ -1034,11 +1034,14 @@
       page = tessedit_page_number;
 #ifdef USE_OPENCL
     if ( od.selectedDeviceIsOpenCL() ) {
-      // FIXME(jbreiden) Not implemented.
-      pix = od.pixReadMemTiffCl(data, size, page);
+      pix = (data) ?
+          od.pixReadMemTiffCl(data, size, page) :
+          od.pixReadTiffCl(filename, page);
     } else {
 #endif
-      pix = pixReadMemTiff(data, size, page);
+      pix = (data) ?
+          pixReadMemTiff(data, size, page) :
+          pixReadTiff(filename, page);
 #ifdef USE_OPENCL
     }
 #endif
@@ -1086,8 +1089,7 @@
 // makes automatic detection of datatype (TIFF? filelist? PNG?)
 // impractical.  So we support a command line flag to explicitly
 // identify the scenario that really matters: filelists on
-// stdin. We'll still do our best if the user likes pipes.  That means
-// piling up any data coming into stdin into a memory buffer.
+// stdin. We'll still do our best if the user likes pipes.
 bool TessBaseAPI::ProcessPagesInternal(const char* filename,
                                        const char* retry_config,
                                        int timeout_millisec,
@@ -1109,31 +1111,24 @@
   }

   // At this point we are officially in autodection territory.
-  // That means we are going to buffer stdin so that it is
-  // seekable. To keep code simple we will also buffer data
-  // coming from a file.
+  // That means any data in stdin must be buffered, to make it
+  // seekable.
   std::string buf;
+  const l_uint8 *data = NULL;
   if (stdInput) {
     buf.assign((std::istreambuf_iterator<char>(std::cin)),
                (std::istreambuf_iterator<char>()));
-  } else {
-    std::ifstream ifs(filename, std::ios::binary);
-    if (ifs) {
-      buf.assign((std::istreambuf_iterator<char>(ifs)),
-                 (std::istreambuf_iterator<char>()));
-    } else {
-      tprintf("ERROR: Can not open input file %s\n", filename);
-      return false;
-    }
+    data = reinterpret_cast<const l_uint8 *>(buf.data());
   }

   // Here is our autodetection
   int format;
-  const l_uint8 * data = reinterpret_cast<const l_uint8 *>(buf.c_str());
-  findFileFormatBuffer(data, &format);
+  int r = (stdInput) ?
+      findFileFormatBuffer(data, &format) :
+      findFileFormat(filename, &format);

   // Maybe we have a filelist
-  if (format == IFF_UNKNOWN) {
+  if (r != 0 || format == IFF_UNKNOWN) {
     STRING s(buf.c_str());
     return ProcessPagesFileList(NULL, &s, retry_config,
                                 timeout_millisec, renderer,
@@ -1149,7 +1144,7 @@
   // Fail early if we can, before producing any output
   Pix *pix = NULL;
   if (!tiff) {
-    pix = pixReadMem(data, buf.size());
+    pix = (stdInput) ? pixReadMem(data, buf.size()) : pixRead(filename);
     if (pix == NULL) {
       return false;
     }
@@ -1162,16 +1157,15 @@
   }

   // Produce output
-  bool r = false;
-  if (tiff) {
-    r = ProcessPagesMultipageTiff(data, buf.size(), filename, retry_config,
-                                  timeout_millisec, renderer,
-                                  tesseract_->tessedit_page_number);
-  } else {
-    r = ProcessPage(pix, 0, filename, retry_config,
-                    timeout_millisec, renderer);
-    pixDestroy(&pix);
-  }
+  r = (tiff) ?
+      ProcessPagesMultipageTiff(data, buf.size(), filename, retry_config,
+                                timeout_millisec, renderer,
+                                tesseract_->tessedit_page_number) :
+      ProcessPage(pix, 0, filename, retry_config,
+                  timeout_millisec, renderer);
+
+  // Clean up memory as needed
+  pixDestroy(&pix);

   // End the output
   if (!r || (renderer && !renderer->EndDocument())) {
```
 I didn't mean to complain about this without offering a solution. I took a crack at this here: https://github.com/tfmorris/tesseract/tree/tiff-streaming
but it turned into a bit of a yak shaving exercise, so I dropped it. The main roadblock was that the "right" solution is to implement more reasonable support in Leptonica which exposes more of libTIFFs underlying capabilities. libTIFF knows how to do efficient access, it just gets lost on the way up through the layers.

Some other notes (mostly from memory, so take with a grain of salt):
- file sniffing only needs/uses 12 bytes, so not very much needs to be buffered
- file sniffing only returns top level TIFF container format, so all the other TIFF_foo checks can be removed
- libTIFF is positioned on the next directory after an image is read an knows how to read it directly, but it's Leptonica's readImage(N+1), that forces a rewind, then read 0, read 1, read 2, ..., read N, read N+1.

I'll review your proposal in more detail tomorrow to see how it compares with what I started implementing.
 Hello TMorris,

Jeff just told me about this thread.  And thank you for pointing out the unsatisfactory condition of the multi-tiff read function.

The leptonica buck stops with me, and I made a small change that brings it down to linear (not quadratic).  I will have it up on github later today.

  -- Dan
 The patch from me above only buffers images coming from stdin. We could try to optimize this more and limit that buffer to 12 bytes, but it is not obvious how useful that is. I'm guessing it isn't worth even a little extra complexity.
 Looking at my "fix" again, I believe it does NOT succeed in making the read time for N pages linear in N.  The problem is that TIFFSetDirectory() always starts at directory 0 in the search.  The way to fix this is to use the lower-level functions that TIFFSetDirectory() uses to walk through the directories, grabbing the image at each directory.  I'll attempt to remedy this in the next day or so.  
 @DanBloomberg Thanks for looking at this. Your most recent comment matches my (slightly vague) memory of how I thought things worked.

@jbreiden I'm not really in a position to make value judgements about what's worthwhile and what's not since I'm not familiar with the user base. I think my general plan of attack to keep things clean was to refactor to use the Leptonica stream functions (e.g. pixReadStreamTiff rather than pixReadTiff and pixReadMemTiff), but that would depend on Leptonica being smart enough to handle the page N -> page N+1 case without seeking (or introducing a new pure streaming API).
 OK, it's all properly linearized.  No refactoring, no low level functions, no api change, no static vars required.

See github.com/danbloomberg/leptonica.
 @tfmorris 

To implement this properly in tesseract, where you only want one image in memory at the same time, use the same approach that I just did in pixReadMultipageTiff():
- get a FILE stream
- use the FILE stream to get a TIFF stream
- loop:
  - read the pix from the TIFF stream
  - do the OCR
  - call TIFFReadDirectory() to advance to the next image

The last function is a naked tiff library call.  Jeff says that currently all the tiff reading functions are leptonica calls.
 @DanBloomberg Thanks for the outline (and for the new functionality!) Do you seeing any risk in going around Leptonica to libTIFF or do you consider this to be stable enough to be a non-issue?

@jbreiden I'm happy to take another crack at this or leave you to it. Let me know.
 There are two separable things under discussion here. The first is the unnecessary buffering. By the way, I checked and file sniffing does indeed return things like IFF_TIFF_G4. I think it makes sense to use my patch. @theraysmith has reviewed it, taken ownership, and will submit it to github.

The other topic is TIFF performance. I don't think I want to tackle that one. It's not technically difficult to write a couple libtiff calls to fix the performance problem. However, this would give Tesseract a new, direct build dependency on libtiff. That seems significant enough to warrant discussion on the development mailing list. I don't know how much of an obstacle that would be for users who build from source; it seems that many already struggle with dependencies.

I'll talk with Dan about whether there are any other options that make sense.
 Jeff and I agree that you need a direct dependency on the TIFF data
structure in the tiff library to use the linear method.

As for stability, tiff lib has been extremely stable for 20 years or so --
I wouldn't worry about that.

On Wed, Mar 30, 2016 at 12:04 PM, jbreiden notifications@github.com wrote:

> There are two separable things under discussion here. The first is the
> unnecessary buffering. By the way, I checked and file sniffing does indeed
> return things like IFF_TIFF_G4. I think it makes sense to use my patch.
> @theraysmith https://github.com/theraysmith has reviewed it, taken
> ownership, and will submit it to github.
> 
> The other topic is TIFF performance. I don't think I want to tackle that
> one. It's not technically difficult to write a couple libtiff calls to fix
> the performance problem. However, this would give Tesseract a new, direct
> build dependency on libtiff. That seems significant enough to warrant
> discussion on the development mailing list. I don't know how much of an
> obstacle that would be for users who build from source; it seems that many
> already struggle with dependencies.
> 
> I'll talk with Dan about whether there are any other options that make
> sense.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-203585859
 If Ray & Jeff have agreed the correct course of action, I'll defer.
 Tom, Ray hasn't weighed in yet.  I believe the question comes down to (1) a
comparison between the amount of time to seek to an image in a tiff file
with many images, vs. the time to OCR that image and (2) the "cost" of
having tesseract depend explicitly on the TIFF library (i.e., using TIFF
data structures and library calls directly).

I don't know either of these two things.  Do you have a timing for a seek
of hundreds of images in a large multipage tiff file?

  -- Dan

On Wed, Mar 30, 2016 at 3:28 PM, Tom Morris notifications@github.com
wrote:

> If Ray & Jeff have agreed the correct course of action, I'll defer.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-203666633
 Ray is kind of busy so he may be slow to submit my buffering patch to github. It is okay for someone else to submit if time is of the essence.

Regarding the TIFF performance issue, I see it in two places. So far we've been discussing TessBaseAPI::ProcessPagesMultipageTiff but we have the exact some problem in MasterTrainer::LoadPageImages

https://github.com/tesseract-ocr/tesseract/blob/dd8c12997385cf7f5961093bcd44f0396b08f96f/classify/mastertrainer.cpp#L219
 It's been a while since I looked at it (and don't have time to recheck now), but that looks about like what I remember thinking would be good.
 Yes, I hope to get it out in two weeks.  Do you want a not-yet-debian
'beta' to try?

On Thu, Nov 24, 2016 at 12:27 PM, zdenop <notifications@github.com> wrote:

> @DanBloomberg <https://github.com/DanBloomberg> : Is there any plan for
> leptonica 1.74 release?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-262841092>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLOS-eQlRxWsem36RjJf5R4D0917fks5rBfNLgaJpZM4HeMNo>
> .
>
 Egor, should I restore the old version of functions in pageseg.c
temporarily on the master?

On Thu, Nov 24, 2016 at 7:43 PM, Egor Pugin <notifications@github.com>
wrote:

> Tesseract master is now broken with master leptonica because of changed
> function(s) in lept's pageseg.c.
> Because of it I switched cppan windows CI build from master to 1.73.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-262875340>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLJUpEloVXJkcEkQLQFaIMW0HA9S_ks5rBllrgaJpZM4HeMNo>
> .
>
 Right.  It's necessary to replace the last arg. in functions like
pixGetRegionsBinary(), which is an integer flag, with either NULL
(corresponding to 0) or a pixa struct (which corresponds to 1).  I'll try
to do this.

  -- Dan

On Thu, Nov 24, 2016 at 10:48 PM, Egor Pugin <notifications@github.com>
wrote:

> I think no. It's better to fix tesseract code.
> ------------------------------
>
> @zdenop <https://github.com/zdenop> If you'd like to fix tess code, you
> could use CPPAN. To change leptonica dependency from 1.73 to master, fix
> it on the line https://github.com/tesseract-ocr/tesseract/blob/master/
> cppan.yml#L137
> After this when you compile tesseract with cmake, the build will fail.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-262891206>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLObYixNrDg-cDx5DNyMgsUjl4yppks5rBoS1gaJpZM4HeMNo>
> .
>
 It will be a significant problem to  change Leptonica and Tesseract simultaneously  once we get to  wider deployment, e.g. shipping with Linux distributions. @jbreiden
Is there a approximate date for final 4.0 release? Maybe just before the freeze of the next Debian stable or Ubuntu 17.04?  > It will be a significant problem to change Leptonica and Tesseract simultaneously [...]

Isn't it possible to write code which supports both old and new (> 1.73) Leptonica (using conditional compilation)? I'd prefer such a solution, at least until Leptonica 1.73 or older is no longer used in current distributions. I will work with Dan next week to try to keep as much compatibility as
possible.

On Fri, Nov 25, 2016 at 11:40 AM, Stefan Weil <notifications@github.com>
wrote:

> It will be a significant problem to change Leptonica and Tesseract
> simultaneously [...]
>
> Isn't it possible to write code which supports both old and new (> 1.73)
> Leptonica (using conditional compilation)? I'd prefer such a solution, at
> least until Leptonica 1.73 or older is no longer used in current
> distributions.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-263015130>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEu2poRWaz7m4Qob3PFumG3ufwxKuGMDks5rBzmpgaJpZM4HeMNo>
> .
>
 Thanks, Jeff.

I believe this is an unusual situation where a leptonica interface that
tesseract uses has been changed.
And I want to apologize for the trouble it has caused.

There is a trivial change to textord/imagefind.cpp that fixes this: replace
the last arg in pixGenHalftoneMask() by NULL.
This will skip the debug output images in this function, but it should be
acceptable, and later if someone really wants the extra few debug images we
can add the code to save them.

On Fri, Nov 25, 2016 at 11:47 AM, jbreiden <notifications@github.com> wrote:

> I will work with Dan next week to try to keep as much compatibility as
> possible.
>
> On Fri, Nov 25, 2016 at 11:40 AM, Stefan Weil <notifications@github.com>
> wrote:
>
> > It will be a significant problem to change Leptonica and Tesseract
> > simultaneously [...]
> >
> > Isn't it possible to write code which supports both old and new (> 1.73)
> > Leptonica (using conditional compilation)? I'd prefer such a solution, at
> > least until Leptonica 1.73 or older is no longer used in current
> > distributions.
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/233#
> issuecomment-263015130>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AEu2poRWaz7m4Qob3PFumG3ufwxKuGMDks5rBzmpgaJpZM4HeMNo>
>
> > .
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-263015680>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLMRRBLX64JXlpNpXoezNWvEzsAoWks5rBzs3gaJpZM4HeMNo>
> .
>
 Let’s talk before Leptonica 1.74 ships. There is a distribution headache if the existing, unmodified Tesseract 3.0.4 can't compile and run with Leptonica 1.74. ​The alternative to updating the pixGenHalftoneMask() function in tesseract
is to make a wrapper in leptonica for the existing tesseract function. This
would simply call the new leptonica function with NULL for the last arg.

On Fri, Nov 25, 2016 at 12:10 PM, jbreiden <notifications@github.com> wrote:

> Let’s talk before Leptonica 1.74 ships. There is a distribution headache
> if the existing, unmodified Tesseract 3.0.4 can't compile and run with
> Leptonica 1.74.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-263017757>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLA_GAbX1LR6Vpbo0vK2ads5jlQATks5rB0C-gaJpZM4HeMNo>
> .
>
 Here is my unofficial take on the ABI shared object version numbers. Jeff
knows about these details and can correct if I'm wrong.

With the Debian releases, we will need to increase the *shared object
version number* (which is different from the leptonica release number) with
any change in the ABI.  The Debian leptonica *soversion* for 1.73 is 5.0.0,
and for 1.74 I believe that we'll increase it to 6.0.0.

The meaning of these three digits is, for the shared object name
*whatever.so.X.Y.Z*, we increment

    X if the ABI release is backwards incompatible
    Y if the ABI release is backwards compatible (with interface changes)
    Z if there are only internal changes (no change to the ABI)

So if I write the wrapper mentioned above, and that were the only change,
then the ABI would be backwards compatible and we'd only need to increment
to 5.1.0 for the next Debian release.  (However, there have been other
changes, including the removal of deprecated functions.)

On Fri, Nov 25, 2016 at 1:01 PM, Egor Pugin <notifications@github.com>
wrote:

> Yes, this seems ABI breakage. Both tesseract and leptonica do not use
> semver (X.Y.Z), but use (X.Y), so personally I'm confused. With semver ABI
> breakage only allowed when increasing X number. So, e.g. leptonica should
> be versioned as 2.00 or whatever.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-263022071>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AP6mLHznAbmXo5UwOhuUdFnN5qn1DQxCks5rB0y5gaJpZM4HeMNo>
> .
>
 I've added the wrapper for pixGenHalftoneMask(), so the (not yet released
1.74) git master now should be compatible with tesseract 3.0.4.

With this, tesseract can be changed at your convenience to use the new
interface pixGenerateHalftoneMask() with NULL for the last arg, and both
will compile.  We'll keep the old version in leptonica until there is no
further need to use it with tesseract.


On Fri, Nov 25, 2016 at 2:31 PM, Dan Bloomberg <dan.bloomberg@gmail.com>
wrote:

> Here is my unofficial take on the ABI shared object version numbers. Jeff
> knows about these details and can correct if I'm wrong.
>
> With the Debian releases, we will need to increase the *shared object
> version number* (which is different from the leptonica release number)
> with any change in the ABI.  The Debian leptonica *soversion* for 1.73 is
> 5.0.0, and for 1.74 I believe that we'll increase it to 6.0.0.
>
> The meaning of these three digits is, for the shared object name
> *whatever.so.X.Y.Z*, we increment
>
>     X if the ABI release is backwards incompatible
>     Y if the ABI release is backwards compatible (with interface changes)
>     Z if there are only internal changes (no change to the ABI)
>
> So if I write the wrapper mentioned above, and that were the only change,
> then the ABI would be backwards compatible and we'd only need to increment
> to 5.1.0 for the next Debian release.  (However, there have been other
> changes, including the removal of deprecated functions.)
>
> On Fri, Nov 25, 2016 at 1:01 PM, Egor Pugin <notifications@github.com>
> wrote:
>
>> Yes, this seems ABI breakage. Both tesseract and leptonica do not use
>> semver (X.Y.Z), but use (X.Y), so personally I'm confused. With semver ABI
>> breakage only allowed when increasing X number. So, e.g. leptonica should
>> be versioned as 2.00 or whatever.
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/233#issuecomment-263022071>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AP6mLHznAbmXo5UwOhuUdFnN5qn1DQxCks5rB0y5gaJpZM4HeMNo>
>> .
>>
>
>
 Just released leptonica 1.74.0 on github  :-) I found this issue while searching for a bug I've been encountering: In a multi-page tiff file, the text is only being extracted from the last page when using Tesseract API [`TessBaseAPIProcessPages`] (https://github.com/tesseract-ocr/tesseract/issues/1138)

Leptonica has a method called `pixaReadMultipageTiff `, would that need to be used instead? 

  hi 
this project support persian language ?
if no
how can i help for support persian ?
 ​hi
no, there is a on dead project to add Persian to tesseract

you can find it at ​https://github.com/roozgar/PersianOcr
and send any support request here ...
 @amitdo is there any document about futures of new engine?!
  Hi,

I have test set that only has "uppercase English alphabets" and "numbers".
Is there a way to modify the existing traineddata file so that it only reads upper case alphabets and numbers?

thanks in advance
  Takes advantage of inheritance and default of `dir="ltr"` to:
- only generate paragraph `dir` attributes which are not `ltr`
- only generate word `dir` attributes which don't match enclosing paragraph

Tested against LTR, RTL, and mixed direction files. Files for the latter two cases are in a separate PR
 OK. I was hoping the scheme could be extended to pages or careas later, but I've made the suggested change and updated the branch.
 Rebased against current head and added fix for Microsoft build breakage introduced by #226. Apply this before #224.
 Closing in favor of a merged PR which incorporates both #223 and #224
  ```
# TESSDATA_PREFIX=/usr/share/tesseract-ocr/tessdata

# echo $TESSDATA_PREFIX
/usr/share/tesseract-ocr/tessdata

# tesseract test.jpg test.txt digits
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
Error opening data file /usr/share/tessdata/eng.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your "tessdata" directory.
Failed loading language 'eng'
Tesseract couldn't load any languages!
Could not initialize tesseract.
```

Note: there is indeed no `eng.traineddata` file in `/usr/share/tesseract-ocr/tessdata`  (there are a bunch of other `eng.xxx` files but no .traineddata), so it is expected to get an error, **_but**_ the error message says it failed to open **_/usr/share/tessdata/eng.traineddata**_ while `TESSDATA_PREFIX` is set to **_/usr/share/tesseract-ocr/tessdata**_.
So, either the file path in the error message is not the actual path of the file that is not found, or tesseract is ignoring the variable TESSDATA_PREFIX, in which case the error message is wrong when it says "make sure the TESSDATA_PREFIX environment variable....".

Whichever the case, something is buggy, regardless of the fact that I have no eng.traineddata file anywhere and I don't expect tesseract to work. I just expect a consistent error message.
 > So, if your tessdata dir is in the /usr/share/tesseract-ocr dir, 
> TESSDATA_PREFIX should be set to /usr/share/tesseract-ocr.

Oh, that's strange, because I later figured out the `export` thing, and I did `export TESSDATA_PREFIX=/usr/share/tesseract-ocr/tessdata`, and it did work. Actually, it works both with and without `/tessdata`

Now I get `read_params_file: Can't open digits`, but that's another story I guess.

> Setting TESSDATA_PREFIX is not needed as long as your tessdata directory is at the right place
> ($PREFIX/share/tessdata).

Of course, but it obviously isn't in my case.
 > @teo1978: well it could be the same story, because config files has to be with expected directory 
> structure in TESSDATA_PREFIX...

No, because I fixed `export TESSDATA_PREFIX=/usr/share/tesseract-ocr`, and the _Can't open digits_ error persists
 It wasn't. Apparently the installation of the language package was a mess. Some files (including configs/digits) were in /usr/share/tessdata; others (eng.\* but not eng.traineddata) were in /usr/share/tesseract-ocr/tessdata; and eng.traineddata wasn't anywhere (I'm positive because I did a `find`), so I had downloaded it manually where the other eng.\* files were...
 This report appears to be from a Debian system or similar. If Tesseract was installed via the standard mechanism (apt-get) then the package maintainer has already made life easy. Because everything goes to a standard and known location, there is no need to set any environment variables such as TESSDATA_PREFIX. Or take any other manual installation action. The English language data (including eng.traineddata) is in the tesseract-ocr-eng package. I am the Tesseract package maintainer for Debian systems.

Here is the list of files of tesseract-ocr-eng
https://packages.debian.org/sid/all/tesseract-ocr-eng/filelist
 Yes this is on Debian 6.

>  If Tesseract was installed via the standard mechanism (apt-get) then the package maintainer has already made life easy.

Or he should have. We had installed tesseract-ocr and tesseract-ocr-eng via `apt-get`, and it was so broken (or so obsolete) that `tesseract -v` would issue an error message saying `-v` was an invalid option. That's why I went through the hell of compiling it from scratch.

> The English language data (including eng.traineddata) is in the tesseract-ocr-eng package.

Maybe the eng.traineddata file was not included, for whatever reason, in the Debian 6 version of the package. I have seen a lot of questions in forums about the same issue (eng.traineddata missing after installing the package).
 You can think of Debian as a curated software collection. Debian 6 was released on February 6th, 2011 and all its packages are from that era. It contained Tesseract 2.04 which is ancient history. Please note that Debian 6 is officially obsolete, and the current stable release is Debian 8.  See https://www.debian.org/releases/

Unlike some other operating systems, best practice for Debian is to update the entire distribution if you want more recent versions of programs. Trying to install a modern Tesseract on an older Linux distribution is really tricky, especially because there are a lot of dependencies involved. I strongly do not recommend it.
 Actually debian 6 is LTS until this 29 of February https://wiki.debian.org/LTS

So, I would have expected a packgage for Debian 6 to be maintained to not become "ancient history" until, well, just now.
 You missed several important points:
- Debian LTS only provides security maintenance.
- Debian LTS is not supported by the normal Debian maintainers, but by a separate group of volunteers and companies.

As @jbreiden already said, you have the option to upgrade to a newer version of Debian. Or you can also take any other current distribution.
  As discussed at length in issue #182, the existing pdf.ttf causes difficulties
for certain PDF viewers, in part because the old file had zero advance width.

With testing, sharp2.ttf seems to be the best available compromise, although
it's not perfect and causes some visual difficulties in Evince.  It does
seem to fix Kindle and OS X Preview.
 Test PDF is here:
https://github.com/tesseract-ocr/tesseract/files/119875/simple-1.pdf
 I have checked: Acrobat XI, Google Chrome PDF Viewer, OS X Preview, Safari PDF viewer; all on El Capitan.
 See #182 for other tests people did with sharp2.ttf
 Chromium and Adobe Reader on Linux are fine. I have reports that Ghostscipt and friends are okay. I should probably double check Android right now.
 Latest stock Android (Marshmallow) is fine.
 Using `sample-1.pdf` from above in the latest pdf.js results in the 2nd word highlighting properly, while the 1st word's highlight is offset. I don't think this is a regression (and it might actually be an improvement) as there were highlighting-offset issues using the previous pdf.ttf with pdf.js. Related to https://github.com/mozilla/pdf.js/issues/6863. 

![screen shot 2016-02-12 at 8 10 39 am](https://cloud.githubusercontent.com/assets/735679/13009192/a1bd5ab4-d160-11e5-9e1c-355bca978774.png)
 I've been tracking the Firefox offset problem in https://github.com/mozilla/pdf.js/issues/6509 and it looks like it has gotten a little worse with this change. (I take that back; your screenshot is worse but mine looks the same. Maybe you are using a different zoom level in Firefox or something)
  When we got a better OCR for Bengali language?
  ```
./autogen.sh
./configure
make
make install
```

all ran without errors (unless error messages are somewhere in the flood of output).

But when I run:

```
$ tesseract -v
tesseract: error while loading shared libraries: libtesseract.so.3: cannot open shared object file: No such file or directory
```

Either something is broken, or some informative error message is missing in the configure and/or make and/or install phase.
  ```
$ sudo apt-get install liblept4
Reading package lists... Done
Building dependency tree       
Reading state information... Done
liblept4 is already the newest version.
liblept4 set to manually installed.
The following packages were automatically installed and are no longer required:
  linux-image-4.2.0-23-generic linux-image-extra-4.2.0-23-generic
  linux-signed-image-4.2.0-23-generic
Use 'apt-get autoremove' to remove them.
0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.
```

```
teo@xxx1:~/temp/tesseract$ ./configure 
checking for g++... g++
...
checking for mbstate_t... yes
checking for leptonica... configure: error: leptonica not found
```

OR the error message needs to be more precise about how to get `leptonica`
 PEBCAK

You need the development package, which seems to be libleptonica-dev
 Yep, but the message says "leptonica not found", it should say "libleptonica-dev not found".
How am I supposed to guess that "leptonica" means libleptonica-dev?

PEBCAK, but whose chair and keyboard?
 Now on another host:

```
configure: error: leptonica library missing

# apt-get install libleptonica-dev 
Reading package lists... Done
Building dependency tree       
Reading state information... Done
libleptonica-dev is already the newest version.
```

Also,

> If you are not familiar with compiling software on your operation system it is not tesseract problem.

It is a documentation problem then. I am not familiar with compiling software indeed, but every time I have done it with other software, I usually follow the steps in the documentation and they work out of the box, and the requirements are specified clearly. 

Also, I wouldn't have to compile it at all if there was a decent Debian package not so riduculously obsolete that it doesn't even recognize the -v option.
 Not even with this:

```
$ export LIBLEPT_HEADERSDIR=/usr/include
$ ./configure --with-extra-libraries=/usr/lib
```

which are the paths where the headers and the library respectively are.
 I'd prefer a less inflammatory title for this bug report, please. Also, may I ask why you aren't installing Tesseract via apt-get? Debian Stable ships with version 3.03, see https://packages.qa.debian.org/t/tesseract.html

```
$ sudo apt-get install tesseract-ocr

$ tesseract -v
tesseract 3.03
 leptonica-1.70
  libgif 4.1.6(?) : libjpeg 8d : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8 : webp 0.4.0
```
 > Also, may I ask why you aren't installing Tesseract via apt-get?

Because that's how it had been installed in the first place, and `tesseract -v` gave an error not recognizing the `-v` option. **This is on Debian 6**
 > @teo1978: this is standard autotools error message. [...] Name of needed package could be different base on distribution.

That's no excuse. It should still specify that it needs the headers, i.e. _-dev_ package. There's no way the person installing should know whether the binary package or the headers package is required, regardless of the actual names.

Besides, I don't know what "autotools error message" means, but the error message is hard-coded in the `configure` file, so it could be easily edited.

Also note that the error message **_"leptonica library missing"**_ issued when the `pixCreate` check fails (whatever that means)  is very confusing too. "Leptonica library missing" seems to indicate that the leptonica library is missing. Instead, you get this message when the leptonica library is actually found and something, which is not clear what it is, is missing. That error message is clearly useful to those who wrote and/or maintain tesseract, but is completely obscure to anyone else.

**This issue should be reopened**
 This issue should not be re-opened, and let me explain why. Tesseract uses a venerable and very common build system called autotools. (And I'll admit, autotools has a well deserved reputation for being complicated.) This build system is designed to work with many different operating systems, not just Linux. Over the years it has supported operating systems like Solaris, Ultrix, AIX, Cygwin, OS X, and many, many others. Each of these operating systems can have wildly different ideas about organization and packaging of software. The autotools system created the `configure` file, and its error messages are therefore are not tailored to any particular operating system.  

You are running into issues and error messages that are really for developers or system integrators to deal with. As a user, the recommended procedure is to not worry about integrating Tesseract into your computer starting from source code, but rather take advantage of the packaging work done by others. Update your Linux distribution to the modern era, install tesseract with the standard tools, and it will work. The alternative is doing a ton of system administration work (not just with Tesseract, but with its entire chain of dependencies) that is not particularly fun or easy.

If you really want to learn about the nuances of autotools, there are entire books written about it such as https://www.sourceware.org/autobook/autobook/autobook_toc.html However, I respectfully suggest spending the time and brain cells on something else. I expect that most software will eventually move to simpler and better build systems in future decades. 
 > This issue should not be re-opened, and let me explain why.

You  have only explained the cause of the issue.

I think you misunderstood the point I made in comment https://github.com/tesseract-ocr/tesseract/issues/215#issuecomment-181944624
What I meant is not that the error message should give you the exact name of the package - I do understand that can change from OS to OS- but it could **easily** be more informative in telling you that it's missing the _headers_ and not the actual library.

>  The autotools system created the configure file

That doesn't mean you can't edit it.

> You are running into issues and error messages that are really for developers or system integrators to deal with. **As a user**, the recommended procedure is to **not** worry about integrating Tesseract into your computer starting **from source code**

That's the whole essence of this issue (and I guess many others): that is a **plain wrong approach**. 
Granted, the _recommended_ procedure is to take advantage of package, but you should take into account that the recommended procedure **is not always an option**. 

**A user may well have to compile the software** from source code, either because the distribution he needs to install it on is not "from the modern era" - by the way, Debian 6 is **just 5 years old**; let me ask a question: would you tell somebody trying to install tesseract on **Windows Vista** (released 2007) to upgrade their OS to the modern era? - or because it's a distribution for which there's no package at all.

I know compiling is not supposed to be particuarly easy for the end user, but there's no need to make it more painful than it could easily be. I have had to compile software from source quite a few times, though I am no developer (of the software I had to compile) or system integrator, and usually they come with an unambiguous list of requirements, a set of steps to follow (typically run a bash script that ships with the source code, then configure, then make and make install, like in this case) and they **usually work out of the box**. And **when they don't**, you definitely know right away what you're missing from a glance at an error message. If neither of these is the case, then I'm sorry but it's poorly maintained software.

In this issue I am reporting the fact that the error messages issued when the leptonica _headers_ are missing or when some stuff related to a `pixCreate` thing is missing (what is that? a function in the library whose inavailability means the version of the library doesn't meet the requirements?), are poor. This could easily, and hence should, be improved. You explained perfectly (it was already clear) why the situation is what it is, but that's no valid reason for not improving it. 

You confuse an explanation of why the problem exists with an argumentation that it is not a problem (which unfortunately is, I have to admit, a pretty common mistake).
 I'm having the same problem, and I can't figure out how to solve it. 
 Please use [Tesseract users forum](https://groups.google.com/d/forum/tesseract-ocr) and ask this question (and other questions you might have) there.
 > Please use Tesseract users forum and ask this question (and other questions you might have) there.

What about fixing the bug instead, so that the error message is clear enough and there's nothing to figure out?
 any solution to this issue? >any solution to this issue?

Yes.
* Most users should install the version that is available through the package manager of their distro.
 * **Advanced  users** can try to install a newer version from source. They should follow the instruction in the wiki.
* If a user still have problems installing the software, he/she should use the forum for support.

Like it or not, that's our solution. Try using "make install" after "make " inside your leptonica-1.xx folder  Can Tesseract be used for music sheet recognition? 
 No, but it is used by Audiveris (https://audiveris.kenai.com/) which can.
 Didn't know that Tesseract can be used for recognizing notations!. Just what I needed. So what is OCR used in Audiveris for?
Thanks 🙏🏿 
Ananth Got it! Many Thanks. So is OpenCV my best option? What about other deep learning frameworks such as TensorFlow?
Cheers
Ananth  Hello,

Refer to issue #169, I spend long time trying to modified language files.
Do you have a plan to update Arabic Language files in the coming releases.

Many Thanks in Advance 
  Hi,
I recently started using tesseract to help unclutter my desk at home, so forgive me if this is a n00b question/request.

I use textcleaner from Fred's ImageMagick Scripts to cleanup my scanned images for better OCR accuracy. However, the images that are optimized for OCR do not necessarily look good from a human standpoint, and I would like the final OCR'd PDF to look visually identical to the original scan.

So here's my feature request: Add an optional argument to take a cleaned image. Example invocation: tesseract -l eng -psm 4 --cleaned-image ${SRC}_cleaned.pnm ${SRC}.pnm out pdf

It will use ${SRC}.pnm to generate the final PDF image but layout detection, character recognition, etc. will be done using the --cleaned-image argument for better accuracy. That way the user will be given a final PDF that looks like the original but searches as well as the cleaned-up image.

I'd be surprised if nobody has already thought of this, so maybe work is already underway or maybe it's not possible. Thoughts?
 zdenop: Yes, that is correct. I want to run OCR on image_b (improved for OCR), but include image_a (original) in the resulting PDF.

BTW - I just realized that there is a user forum (https://groups.google.com/forum/#!forum/tesseract-ocr). Maybe somebody has asked / answered my question there. My apologies for not looking at that forum earlier.
 Please post an example of a cleaned vs uncleaned image where accuracy improves significantly. Or even better, point to some documentation that has some examples. In the long term, one would hope that OCR could improve such that having a separate cleaned image is unnecessary.

Regarding this feature request, I think it is probably better to use an outside utility that can replace the images in a Tesseract produced PDF. The caller is already generating a separate set of clean images, so is therefore comfortable with pre/post processing. This approach lets us keep the design intent and implementation of PDF generation simple ('don't mess with the images'). I don't know if such a tool exists already, but based on my knowledge of the Tesseract PDF it shouldn't be too hard to write. Apologies, but I am not volunteering to write one unless I need it myself for something. The closest existing thing I know about is OverlayPDF from Apache PDFBox. Previously mentioned here. https://www.mail-archive.com/tesseract-ocr@googlegroups.com/msg11853.html

Also, if you really want to hack Tesseract to do what you are asking for, the code is in api/pdfrenderer.cc. You would have to replace both the pix and the filename. I'd just be reluctant to make this a general feature of Tesseract.

https://github.com/tesseract-ocr/tesseract/blob/master/api/pdfrenderer.cpp#L894
 Hi jbreiden,
There are lots of tutorials on-line for how to clean-up images for improved accuracy OCR out there, just use your favorite search engine. Here's a good one from 2014 (not too old): http://www.christophermchurch.com/my-struggles-with-ocr-and-microfilm-scans/ . Yes, it would be nice if OCR engines were perfect and didn't need cleaned-up images. But that's currently not a realistic expectation when papers get crumpled, have background images, have shaded regions, are "scanned" using a cell phone camera with poor lighting conditions, etc.

I don't think it would be wise to try to add all that clean-up functionality into tesseract, which is why I'm proposing a solution to take an image that has already been processed externally. The exact intent is to "not mess with the images."

An external tool that could replace the image layer would certainly be good, but I haven't found any (suggestions welcome!). I tried to use hocr2pdf to use tesseract's .hocr data from my cleaned image and add it to a PDF with my original image but ran into a showstopper issue - When searching for a word in the document, the PDF viewers I tried would highlight the wrong part of the document. Maybe there is a bug with hocr2pdf or I am using it incorrectly. Tesseract already knows how to make a PDF so this reduces the possibility of an external program interpreting the PDF or hOCR specs differently and ruining the output.

Anyway, thanks for the pointer to api/pdfrenderer.cc! I might just add the feature locally to address my needs, or maybe try to start a new program based off of it as you suggest.

I don't mind closing this issue if others feel this feature is inappropriate or a better solution is made.
 Swapping images in Tesseract a PDF is pretty easy for a programmer if destination images are JPEG or JPEG 2000. It is really just a matter of cutting and pasting the data, then cleaning up the results with qpdf.  The hardest part is getting the courage to open up a PDF file and look inside it.

Regarding HOCR and bounding boxes, make sure you have image resolution metadata set correctly everywhere. The hocr-pdf program mentioned above works okay, but is limited to latin character sets and will also struggle with ligatures in English.
 Heh, yeah, I opened up a PDF and saw the stream content for the image and was thinking of how to replace it, but it seemed like there'd be a non-trivial amount of work to get right for a PDF n00b such as myself.

As far as I could tell the image resolution metadata was correct, or at least consistent. Couldn't get hocr-pdf working unfortunately due to some python module dependency that I couldn't find (I installed PyXML but no dice).

In the end I just went ahead and hacked my feature into Tesseract and it works pretty well :-) Here it is if you're interested, though be warned that it's a bit of a kludge in its current state: https://github.com/dhendrix/tesseract/commit/6cc206f5e4f734ba178c18e5a962563aace35018

Thanks for the helpful pointers! Feel free to close if this feature is not desired for upstream, it can live on in my github account.
 The python dependency is reportlab.
  Where can I download Tesseract for Windows?
All Links point to code.google.com, but since Tesseract has moved here all links are dead.

Also I would like to downoad different versions (2.x, 3.x) to see if any of them works.
The version I have right now (3.05 Setup) does not read any images but produces errors instead.
 That might be caused by missing permissions: all but the very latest version try to create temporary files in the root directory c:. You will need a Tesseract build with a very new version of Leptonica to fix this problem, see https://github.com/DanBloomberg/leptonica/commit/3038a7074d5b1dc6511af19085d980d1e0ae399c.
See also issue #171.
 OK, thanks for the replies. Can I download a version somewhere that
a) Does not have the bug mentioned by stweil
b) Includes the image loading functionality

On https://github.com/tesseract-ocr/tesseract/wiki/Downloads it says "Currently, there is no official Windows installer for newer versions." :-(
The 3.05 setup from https://github.com/UB-Mannheim/tesseract/wiki does also not work (as mentioned above).
 Hi, I made a step by step guide how to compile Tesseract on Windows.. You can check my guide's here: http://gensanblog.com/2016/01/28/how-to-compile-tesseract-git-project-on-windows/

You can also download the compiled version.. 
 Hi Egor, thank you for correcting.. I am new to this and I made lots of edit's on the guide.. I will edit my post and focus on cygwin, I also added dll's so that it can run without cygwin.. I'll create a new guide for MSVC..
 @egorpugin : Could you also build the training program - text2image for windows
 @egorpugin: OK.

@zdenop : There are a number of older requests/issues for windows build. I'll add a comment to refer to this issue and you could close them. Thanks!
 @egorpugin - Are the windows binaries at 
https://www.dropbox.com/s/8t54mz39i58qslh/tesseract-3.05.00dev-win32-vc19.zip?dl=1
for the current development version (after the release of 3.04.01)?

Thanks!
 Thanks for clarifying, @egorpugin .

I was confused after seeing the following on the releases page:

```
on Jul 22, 2015 
3.05.00dev  …
increase version number
 71e226c   zip   tar.gz
```
 This build does not create PDFs, but the cygwin from http://3.onj.me/tesseract/ build does.
So currently the VS build is not usable.
 The installers (made with MinGW-w64) are at https://github.com/UB-Mannheim/tesseract/wiki.
 https://github.com/UB-Mannheim/tesseract doesn't seem to provide binaries right now.
 @nickbe, just add `/wiki` to that URL...
 But these do not seem to be the VC binaries, or are they? There's only a problem with generating PDFs with the VC runtimes.
 That's right, the UB Mannheim executables are built with [Mingw-w64](http://mingw-w64.org/).
 Latest VC binaries by @egorpugin with PDF generation are at following link, as per  [#338](https://github.com/tesseract-ocr/tesseract/issues/338): https://www.dropbox.com/s/pxu2hp6mg1a64zj/tesseract-3.05.00dev-win32-vc19-2016-jun-03.zip?dl=1
 Great. Thanks !
 @egorpugin I follow the instructions. 

However CPPAN returns

> Requesting dependency list
> SSL connect error

Is that any configuration I am missing?
  I have created new Trained data "eng2.traineddata", now i want to add it to config folder. not by this step "sudo cp eng2.traineddata /usr/local/share/tessdata/"

want to add in makefile and then install tesseract. ../tesseract-ocr/tessdata/Makefile.in
Dont want to execute by "tesseract test.png test -l eng2"
Want to make this as default.

can anybody help me with steps which all files do i need to change.
  I download recent leptonica version but when i build opencv project  
"Cannot open input file 'liblept171.lib' error"
this msg came out..... where can i get liblept171.lib... 
i research google but there is no answer for this error....
 no I use this project...
and build this project .. that msg came from when i build it 
  I wanted to use former version 3.02 but.... google link redirect here......

so i can't get former version.... fix please....
  Tesseract Orientation and script detection works fine on many images, but fails in many cases to like 

Image with maps, no EXIF-Data, Multiple text lines with different directions 

`tesseract shots-1.jpg out  - -psm 0
`

> Tesseract Open Source OCR Engine v3.04.00 with Leptonica
> Orientation: 3
> Orientation in degrees: 90
> Orientation confidence: 5.11
> Script: 1
> Script confidence: 9.74
> 
> ![shots-1](https://cloud.githubusercontent.com/assets/331827/12638871/5bae017c-c5c6-11e5-96bc-314418b73698.jpg)

Any other way to get best possible value for Orientation and script detection ?
 General questions are better asked on the mailing list where more people will see them.
  actual_tessdata_num_entries_ <= TESSDATA_NUM_ENTRIES:Error:Assert failed:in file
 ..\ccutil\tessdatamanager.cpp, line 48
  Can you provide a Windows installation for those that do not have the expertise to compile these sources as you did before moving the project to Github?

The last installer I know of was for version 3.02.02
 Does https://github.com/UB-Mannheim/tesseract help?
 Hi,

Thanks for your reply. I downloaded the zip and extracted it. I still could
not find any .exe files. Plus the whole download is only 2.4MB and the
original 3.02.02 installation was 30+ MB as an installer.

Regards,
Tony

On Wed, Jan 27, 2016 at 4:02 PM, Stefan Weil notifications@github.com
wrote:

> Does https://github.com/UB-Mannheim/tesseract help?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/200#issuecomment-175420528
> .
 My fault, wrong link (the info is in the wiki): https://github.com/UB-Mannheim/tesseract/wiki should be better.
 Perfect :-)

Thank you!

Enjoy you day.

On Wed, Jan 27, 2016 at 4:44 PM, Stefan Weil notifications@github.com
wrote:

> May fault, wrong link (the info is in the wiki):
> https://github.com/UB-Mannheim/tesseract/wiki should be better.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/200#issuecomment-175434615
> .
 @amitdo, thanks, pulled. :-)
 Hi Stefan,

I installed the version 3.05.00dev and it produces the following error.

Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Warning in pixReadMemPng: work-around: writing to a temp file
libpng warning: Application built with libpng-1.4.3 but running with 1.5.14
Error in pixReadStreamPng: png_ptr not made
Error in pixReadMemPng: pix not read
Error in pixReadMem: png: no pix returned
Error during processing.

The installation replaced the previous version of 3.02.02

On Thu, Jan 28, 2016 at 4:04 AM, Stefan Weil notifications@github.com
wrote:

> @amitdo https://github.com/amitdo, thanks, pulled. :-)
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/200#issuecomment-175775012
> .
 This might be caused by the Leptonica code used for Tesseract: it tries to create a temp file in c:\ and fails because you don't have write permission there. So it should work if you run Tesseract as admin or if you change the permissions for c:.

I fixed this for JPEG-2000 files, but not for other image formats like PNG. See the discussion on https://github.com/DanBloomberg/leptonica/pull/116 for more information.
 Hi tonym1995,

I made a full instruction how to install and compile tesseract on windows http://gensanblog.com/2016/01/28/how-to-compile-tesseract-git-project-on-windows/

Hope this can help!

Erwin
 Hi,
thank you!
i have to say for a Windows newcomer finding this project it is horrible to get started from the README.md 
@bantilan your blog entry should be in the project's wiki!
Best
uhu
 [See issue 209](https://github.com/tesseract-ocr/tesseract/issues/209)
  disappointed w/ open-source stuff. allheaders.h seems to be missing. Trying to compile w/ Visual Studio 2010, using make file included in project. Not clear how to build this project otherwise. Why so much code? :-)
 `allheaders.h` is part of the Leptonica package. You will need that package, too. And even more code ... :-)
 Same for me. I don't want to sound arrogant but when I release a package, I make sure it is complete, it it ain't, then a readme file tells what's missing and where to find it.
 Same for me too. [https://tpgit.github.io/Leptonica/allheaders_8h_source.html ](url)
This is the homepage of allheaders.h >https://tpgit.github.io/Leptonica/allheaders_8h_source.html
This is the homepage of allheaders.h

The homepage of Leptonica is here:
http://www.leptonica.org/

Official GitHub repo:
https://github.com/DanBloomberg/leptonica
  After working around the bug in #195 I have now managed to generate some training data. However, when I try to use it, tesseract segfaults.

``` sh
api/tesseract test.CutiveMono.exp0.tif test.CutiveMono.exp0 box.train.stderr
```

``` text
(lldb) run
Process 69791 launched: '/Users/linus/coding/tesseract/api/.libs/tesseract' (x86_64)
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Process 69791 stopped
* thread #1: tid = 0x1d82bc0, 0x0000000100012d10 libtesseract.3.dylib`tesseract::TessResultRenderer::BeginDocument(this=0x0000000000000010, title="") + 16 at renderer.cpp:54, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x40)
    frame #0: 0x0000000100012d10 libtesseract.3.dylib`tesseract::TessResultRenderer::BeginDocument(this=0x0000000000000010, title="") + 16 at renderer.cpp:54
   51   }
   52   
   53   bool TessResultRenderer::BeginDocument(const char* title) {
-> 54     if (!happy_) return false;
   55     title_ = title;
   56     imagenum_ = -1;
   57     bool ok = BeginDocumentHandler();
(lldb) bt
* thread #1: tid = 0x1d82bc0, 0x0000000100012d10 libtesseract.3.dylib`tesseract::TessResultRenderer::BeginDocument(this=0x0000000000000010, title="") + 16 at renderer.cpp:54, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x40)
  * frame #0: 0x0000000100012d10 libtesseract.3.dylib`tesseract::TessResultRenderer::BeginDocument(this=0x0000000000000010, title="") + 16 at renderer.cpp:54
    frame #1: 0x000000010000b21c libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPagesInternal(this=0x00007fff5fbff598, filename="test.CutiveMono.exp0.tif", retry_config=0x0000000000000000, timeout_millisec=0, renderer=0x0000000000000010) + 732 at baseapi.cpp:1166
    frame #2: 0x000000010000aeef libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPages(this=0x00007fff5fbff598, filename=<unavailable>, retry_config=<unavailable>, timeout_millisec=<unavailable>, renderer=<unavailable>) + 15 at baseapi.cpp:1074
    frame #3: 0x0000000100001869 tesseract`main(argc=<unavailable>, argv=<unavailable>) + 665 at tesseractmain.cpp:429
    frame #4: 0x00007fff8a2645ad libdyld.dylib`start + 1
```
 d4e0c64 gives me another segfault, but it seems to be later in :)

``` text
(lldb) run
Process 89333 launched: '/Users/linus/coding/tesseract/api/.libs/tesseract' (x86_64)
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Process 89333 stopped
* thread #1: tid = 0x1e23c8e, 0x0000000100182335 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) [inlined] ELIST_ITERATOR::set_to_list(list_to_iterate=0x0000000000000008) + 4 at elst.h:306, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x8)
    frame #0: 0x0000000100182335 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) [inlined] ELIST_ITERATOR::set_to_list(list_to_iterate=0x0000000000000008) + 4 at elst.h:306
   303    #endif
   304  
   305    list = list_to_iterate;
-> 306    prev = list->last;
   307    current = list->First ();
   308    next = current ? current->next : NULL;
   309    cycle_pt = NULL;               //await explicit set
(lldb) bt
* thread #1: tid = 0x1e23c8e, 0x0000000100182335 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) [inlined] ELIST_ITERATOR::set_to_list(list_to_iterate=0x0000000000000008) + 4 at elst.h:306, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x8)
  * frame #0: 0x0000000100182335 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) [inlined] ELIST_ITERATOR::set_to_list(list_to_iterate=0x0000000000000008) + 4 at elst.h:306
    frame #1: 0x0000000100182331 libtesseract.3.dylib`PAGE_RES_IT::start_page(this=0x00007fff5fbff060, empty_ok=false) + 17 at pageres.cpp:1510
    frame #2: 0x000000010001acb0 libtesseract.3.dylib`tesseract::Tesseract::ApplyBoxTraining(STRING const&, PAGE_RES*) [inlined] PAGE_RES_IT::restart_page(this=<unavailable>) + 80 at pageres.h:681
    frame #3: 0x000000010001acab libtesseract.3.dylib`tesseract::Tesseract::ApplyBoxTraining(STRING const&, PAGE_RES*) [inlined] PAGE_RES_IT::PAGE_RES_IT(this=<unavailable>, the_page_res=<unavailable>) + 49 at pageres.h:665
    frame #4: 0x000000010001ac7a libtesseract.3.dylib`tesseract::Tesseract::ApplyBoxTraining(STRING const&, PAGE_RES*) [inlined] PAGE_RES_IT::PAGE_RES_IT(this=<unavailable>, the_page_res=<unavailable>) at pageres.h:663
    frame #5: 0x000000010001ac7a libtesseract.3.dylib`tesseract::Tesseract::ApplyBoxTraining(this=0x0000000101002c00, fontname=0x00007fff5fbff1c0, page_res=<unavailable>) + 26 at applybox.cpp:797
    frame #6: 0x000000010000a4a1 libtesseract.3.dylib`tesseract::TessBaseAPI::Recognize(this=<unavailable>, monitor=0x0000000000000000) + 609 at baseapi.cpp:883
    frame #7: 0x000000010000ad8b libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPage(this=<unavailable>, pix=<unavailable>, page_index=<unavailable>, filename=<unavailable>, retry_config=0x0000000000000000, timeout_millisec=<unavailable>, renderer=0x0000000000000000) + 347 at baseapi.cpp:1224
    frame #8: 0x000000010000afec libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPagesMultipageTiff(this=0x00007fff5fbff688, data="II*", size=1982406, filename="test.CutiveMono.exp0.tif", retry_config=0x0000000000000000, timeout_millisec=0, renderer=<unavailable>, tessedit_page_number=-1) + 284 at baseapi.cpp:1056
    frame #9: 0x000000010000b41d libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPagesInternal(this=0x00007fff5fbff688, filename="test.CutiveMono.exp0.tif", retry_config=0x0000000000000000, timeout_millisec=<unavailable>, renderer=0x0000000102845980) + 877 at baseapi.cpp:1174
    frame #10: 0x000000010000b05f libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPages(this=0x00007fff5fbff688, filename=<unavailable>, retry_config=<unavailable>, timeout_millisec=<unavailable>, renderer=<unavailable>) + 15 at baseapi.cpp:1074
    frame #11: 0x00000001000018c3 tesseract`main(argc=<unavailable>, argv=<unavailable>) + 515 at tesseractmain.cpp:407
    frame #12: 0x00007fff8a2645ad libdyld.dylib`start + 1
    frame #13: 0x00007fff8a2645ad libdyld.dylib`start + 1
```
 And 228317c, (3.04.00) segfaults with at another place

``` text
(lldb) run
Process 3475 launched: '/Users/linus/coding/tesseract/api/.libs/tesseract' (x86_64)
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
Page 1
Process 3475 stopped
* thread #1: tid = 0x1e70af8, 0x000000010019d155 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) + 21, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x8)
    frame #0: 0x000000010019d155 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) + 21
libtesseract.3.dylib`PAGE_RES_IT::start_page:
->  0x10019d155 <+21>: movq   0x8(%rax), %rax
    0x10019d159 <+25>: movq   %rax, 0x58(%rbx)
    0x10019d15d <+29>: testq  %rax, %rax
    0x10019d160 <+32>: je     0x10019d17d               ; <+61>
(lldb) bt
* thread #1: tid = 0x1e70af8, 0x000000010019d155 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) + 21, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x8)
  * frame #0: 0x000000010019d155 libtesseract.3.dylib`PAGE_RES_IT::start_page(bool) + 21
    frame #1: 0x0000000100019930 libtesseract.3.dylib`tesseract::Tesseract::ApplyBoxTraining(STRING const&, PAGE_RES*) + 80
    frame #2: 0x0000000100009571 libtesseract.3.dylib`tesseract::TessBaseAPI::Recognize(ETEXT_DESC*) + 609
    frame #3: 0x0000000100009e74 libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPage(Pix*, int, char const*, char const*, int, tesseract::TessResultRenderer*) + 356
    frame #4: 0x000000010000a0cc libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPagesMultipageTiff(unsigned char const*, unsigned long, char const*, char const*, int, tesseract::TessResultRenderer*, int) + 284
    frame #5: 0x000000010000a4fd libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPagesInternal(char const*, char const*, int, tesseract::TessResultRenderer*) + 877
    frame #6: 0x000000010000a13f libtesseract.3.dylib`tesseract::TessBaseAPI::ProcessPages(char const*, char const*, int, tesseract::TessResultRenderer*) + 15
    frame #7: 0x0000000100001649 tesseract`main + 2841
    frame #8: 0x00007fff8a2645ad libdyld.dylib`start + 1
```
 That worked! Cool, seems like something was wrong with my `tif` file then?

Is there anything more we can do to debug this?

I really appreciate the help!
  I'm trying to use the `text2image` utility to train tesseract. Unfortunately it keeps crashing every time I try to use it :(

``` sh
text2image --text=training_text.txt --outputbase=test.MenloMedium.exp0 --font='Menlo Medium' --fonts_dir=/Library/Fonts/
```

``` text
(lldb) run
Process 49926 launched: '/usr/local/bin/text2image' (x86_64)
Process 49926 stopped
* thread #1: tid = 0x1d2b8cb, 0x0000000100b74358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x0)
    frame #0: 0x0000000100b74358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25
libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph:
->  0x100b74358 <+25>: movq   (%rcx), %rdi
    0x100b7435b <+28>: testq  %rdi, %rdi
    0x100b7435e <+31>: je     0x100b74369               ; <+42>
    0x100b74360 <+33>: movq   %rax, %rsi
(lldb) bt
* thread #1: tid = 0x1d2b8cb, 0x0000000100b74358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x0)
  * frame #0: 0x0000000100b74358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25
    frame #1: 0x000000010000edc1 text2image`tesseract::PangoFontInfo::CanRenderString(char const*, int, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >*) const + 321
    frame #2: 0x000000010000ec57 text2image`tesseract::PangoFontInfo::CanRenderString(char const*, int) const + 33
    frame #3: 0x0000000100015227 text2image`tesseract::StringRenderer::StripUnrenderableWords(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >*) const + 193
    frame #4: 0x00000001000154aa text2image`tesseract::StringRenderer::RenderToImage(char const*, int, Pix**) + 418
    frame #5: 0x0000000100005748 text2image`main + 2891
    frame #6: 0x00007fff8a2645ad libdyld.dylib`start + 1
    frame #7: 0x00007fff8a2645ad libdyld.dylib`start + 1
```
 My guess, and it's very uneducated, is that the pointer from `run->item->analysis.font` only points to a `PangoFont` and not a `PangoFcFont`. Since it's `reinterpret_cast`ed into the later `pango_fc_font_get_glyph` somewhere hits a null pointer.

I have checked that `run->item->analysis.font` isn't a null pointer, it isn't.
 My very crude workaround for now:

``` diff
diff --git a/training/pango_font_info.cpp b/training/pango_font_info.cpp
index b542591..86c108e 100644
--- a/training/pango_font_info.cpp
+++ b/training/pango_font_info.cpp
@@ -416,10 +416,13 @@ bool PangoFontInfo::CanRenderString(const char* utf8_word, int len,
       tlog(2, "Found end of line NULL run marker\n");
       continue;
     }
-    PangoGlyph dotted_circle_glyph;
+    // PangoGlyph dotted_circle_glyph;
     PangoFont* font = run->item->analysis.font;
-    dotted_circle_glyph = pango_fc_font_get_glyph(
-        reinterpret_cast<PangoFcFont*>(font), kDottedCircleGlyph);
+
+    // printf("The pointer: %p\n", (void *) font);
+
+    // dotted_circle_glyph = pango_fc_font_get_glyph(
+    //     reinterpret_cast<PangoFcFont*>(font), kDottedCircleGlyph);
     if (TLOG_IS_ON(2)) {
       PangoFontDescription* desc = pango_font_describe(font);
       char* desc_str = pango_font_description_to_string(desc);
@@ -456,9 +459,9 @@ bool PangoFontInfo::CanRenderString(const char* utf8_word, int len,
         const bool unknown_glyph =
             (cluster_iter.glyph_item->glyphs->glyphs[i].glyph &
              PANGO_GLYPH_UNKNOWN_FLAG);
-        const bool illegal_glyph =
-            (cluster_iter.glyph_item->glyphs->glyphs[i].glyph ==
-             dotted_circle_glyph);
+        const bool illegal_glyph = false;
+            // (cluster_iter.glyph_item->glyphs->glyphs[i].glyph ==
+            //  dotted_circle_glyph);
         bad_glyph = unknown_glyph || illegal_glyph;
         if (TLOG_IS_ON(2)) {
           printf("(%d=%d)", cluster_iter.glyph_item->glyphs->glyphs[i].glyph,
```
 Indeed, looks like the font is not a PangoFcFont.  Try using PANGO_FC_FONT(...) instead of the reinterpret_cast<...>, and you should get a warning.  You can use PANGO_IS_FC_FONT() to test at runtime.
 Sorry, I haven't had time to investigate this further. Hopefully I'll get some work done on this in the near future...
 @amitdo

I have same problem. I cannot use tesstrain.sh on Mac ( So, I use  Ubuntu on VirtualBox for training).

I tried bellow.

```
$ brew install  tesseract --with-training-tools --HEAD 
$ text2image --list_available_fonts --fonts_dir=/Library/Fonts
<skip>
```

There are total 1221 fonts installed. But 'Regular' style  is not included in text2image's output.
Even if some font has "Regular" style glyphs.

So, I can not try text2image with 'Regular' style font. What should I do for this issue? 

```
$ text2image --text=eng.training_text --outputbase=eng.MenloRegular.exp0 --font='Menlo Regular' --fonts_dir=/Library/Fonts
Could not find font named Menlo Regular. Pango suggested font Menlo Medium
Please correct --font arg.:Error:Assert failed:in file text2image.cpp, line 437
Abort trap: 6
```

ex. dejavu font (maybe not regular style,  [detail](https://gist.github.com/atuyosi/bc5387a4941e5d963365))

```
$ text2image --text=eng.training_text --outputbase=eng.MenloRegular.exp0 --font='DejaVu Sans Thin' --fonts_dir=~/Library/Fonts
Segmentation fault: 11
```
 HI @amitdo , my font lis is here.

[fontlist.txt](https://github.com/tesseract-ocr/tesseract/files/137785/fontlist.txt)

Thanks.
 @amitdo 

text2image's result is bellow:

```
$ text2image --text=eng.training_text --outputbase=eng.TimesNewRomanBold.exp0 --font='Times New Roman, Bold' --fonts_dir=/Library/Fonts
Segmentation fault: 11
```

detail back trace is bellow:

```
$ lldb /usr/local/bin/text2image
(lldb) target create "/usr/local/bin/text2image"
Current executable set to '/usr/local/bin/text2image' (x86_64).
(lldb) run --text=eng.training_text --outputbase=eng.TimesNewRomanBold.exp0 --font='Times New Roman, Bold' --fonts_dir=/Library/Fonts
Process 53735 launched: '/usr/local/bin/text2image' (x86_64)
Process 53735 stopped
* thread #1: tid = 0xf3978, 0x0000000100b98358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x0)
    frame #0: 0x0000000100b98358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25
libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph:
->  0x100b98358 <+25>: movq   (%rcx), %rdi
    0x100b9835b <+28>: testq  %rdi, %rdi
    0x100b9835e <+31>: je     0x100b98369               ; <+42>
    0x100b98360 <+33>: movq   %rax, %rsi
(lldb) bt
* thread #1: tid = 0xf3978, 0x0000000100b98358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x0)
  * frame #0: 0x0000000100b98358 libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25
    frame #1: 0x000000010000ea31 text2image`tesseract::PangoFontInfo::CanRenderString(char const*, int, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >*) const + 321
    frame #2: 0x000000010000e8c7 text2image`tesseract::PangoFontInfo::CanRenderString(char const*, int) const + 35
    frame #3: 0x0000000100015047 text2image`tesseract::StringRenderer::StripUnrenderableWords(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >*) const + 195
    frame #4: 0x00000001000152d0 text2image`tesseract::StringRenderer::RenderToImage(char const*, int, Pix**) + 418
    frame #5: 0x0000000100005541 text2image`main + 2895
    frame #6: 0x00007fff9c3ec5ad libdyld.dylib`start + 1
    frame #7: 0x00007fff9c3ec5ad libdyld.dylib`start + 1
(lldb)
```
 Hi @amitdo,
I have the exact same issue with text2image (HEAD revision) running on OSX.

Here's the debug trace when running your last command :

```
$ text2image --text=eng.training.txt --outputbase=eng.TimesNewRomanBold.exp0 --font='Times New Roman, Bold' --fonts_dir=/Library/Fonts --tlog_level=3
query weight = 700   selected weight =700
query_desc: 'Times New Roman, Bold' Selected: 's'
Render string of size 84
Starting page 0
max_width = 3400, max_height = 4600
len = 84  buf_len = 84
Segmentation fault: 11
```

And the corresponding debug trace:

```
$ lldb  /usr/local/bin/text2image
(lldb) target create "/usr/local/bin/text2image"
Current executable set to '/usr/local/bin/text2image' (x86_64).
(lldb) run --text=eng.training.txt --outputbase=eng.TimesNewRomanBold.exp0 --font='Times New Roman, Bold' --fonts_dir=/Library/Fonts --tlog_level=3
Process 43961 launched: '/usr/local/bin/text2image' (x86_64)
query weight = 700   selected weight =700
query_desc: 'Times New Roman, Bold' Selected: 's'
Render string of size 84
Starting page 0
max_width = 3400, max_height = 4600
len = 84  buf_len = 84
Process 43961 stopped
* thread #1: tid = 0x1e1688, 0x0000000100c7e36e libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x0)
    frame #0: 0x0000000100c7e36e libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25
libpangoft2-1.0.0.dylib`pango_fc_font_get_glyph + 25:
-> 0x100c7e36e:  movq   (%rcx), %rdi
   0x100c7e371:  testq  %rdi, %rdi
   0x100c7e374:  je     0x100c7e37f               ; pango_fc_font_get_glyph + 42
   0x100c7e376:  movq   %rax, %rsi
```

Hope it can help
 @amitdo 

I tried the HEAD version (5610738) , and the exit status is 0. 
It looks  good in Times fonts.

Could you check the logs ?

```
$ uname -a
Darwin sakura.local 15.6.0 Darwin Kernel Version 15.6.0: Thu Jun 23 18:25:34 PDT 2016; root:xnu-3248.60.10~1/RELEASE_X86_64 x86_64

$ brew install tesseract --HEAD --with-training-tools
<skip>
$ tesseract --version
tesseract 3.05.00dev
 leptonica-1.73
  libjpeg 8d : libpng 1.6.23 : libtiff 4.0.6 : zlib 1.2.5

$ ls -l /usr/local/bin/text2image
lrwxr-xr-x  1 atuyosi  admin  49  8 11 01:55 /usr/local/bin/text2image -> ../Cellar/tesseract/HEAD-5610738_2/bin/text2image

$ text2image --text=eng.training.txt --outputbase=eng.TimesNewRomanBold.exp0 --font='Times New Roman, Bold' --fonts_dir=/Library/Fonts --tlog_level=3
```

Log file is below:

[issue_195_HEAD-5610738.txt](https://github.com/tesseract-ocr/tesseract/files/411715/issue_195_HEAD-5610738.txt)

The exit status and output files:

```
$ echo $?
0
$ ls
eng.TimesNewRomanBold.exp0.box  eng.training.txt
eng.TimesNewRomanBold.exp0.tif
```

[eng.TimesNewRomanBold.exp0.box.txt](https://github.com/tesseract-ocr/tesseract/files/411720/eng.TimesNewRomanBold.exp0.box.txt)

![eng timesnewromanbold exp0](https://cloud.githubusercontent.com/assets/211086/17563850/251fd3c0-5f6c-11e6-8ec2-fe8a97fe57ca.png)
- rename `.box` file to `.txt`, and convert `.tiff` to `.png`

Thanks.
 Hi guys,
i have a trouble with the text2image  im trying to make the fontlist that was described in the main article about tesseract ocr, i can create the box file and tif file normally for one font but the list i get a problem. im using tesseract OCR 3.03 and the OS is windows 10 and the language is english the command is:
**text2image --text=training_text.txt --outputbase=eng.fontlist.txt --fonts_dir=C:\Windows\Fonts  --find_fonts=true --min_coverage=1.0 --render_per_font=false --fontconfig_tmpdir=C:\Tesseract\Tesseract-OCR** 
and i get a warning
**WARNING: Could not find a font to render image title with!** 
and it gives a fail for every font such as: 
**Font Aldhabi failed with 62 hits = 21.60%**
**also give '%' (U+25) not covered by font** but i don't know what does that mean, anyways 
Any idea how to solve this error?

Thanks in advance 
 You are looking for 100% coverage of training text in the fonts with  --min_coverage=1.0

I use the following on bash on windows (mobaxterm).

```
text2image --find_fonts \
--fonts_dir /mnt/c/Windows/Fonts \
--text ./langdata/eng/eng.training_text \
--min_coverage .95  \
--outputbase ./langdata/eng/eng \
|& grep raw | sed -e 's/ :.*/" \\/g'  | sed -e 's/^/  "/' > ../langdata/eng/fontslist-windows.txt
```
 Thanks a lot for your response, but i didn't get the last part of the command that you are using  **\
|& grep raw | sed -e 's/ :.*/" \\/g'  | sed -e 's/^/  "/' > ../langdata/eng/fontslist-windows.txt** i don't remember that there is such arguments at text2image binary, also i tried in my command to change the coverage from 100 to 95 yet i still have the same problem  keep in mind I'm not familiar with terminal environment :)  The text2image --find_fonts command displays the output on the terminal.

the \ at end of each line is a continuation mark for the command.

| is for piping the output of earlier command to next command.

Grep selects all the lines which have 'raw' in them - to select all lines which have the font name.

first sed command deletes everything following the : sign with a quote mark.

second sed command adds a quote sign to the beginning of each line.

The resulting output is saved in the output file name given after >

So, basically it deletes all extraneous output and creates a text file with each font name with quotes around it, which can be used as part of fontslist or plugged into language-specific.sh. Example of output below:

```
  "WenQuanYi Zen Hei Medium" \
  "WenQuanYi Zen Hei Mono Medium" \
  "WenQuanYi Zen Hei Sharp Medium" \
```

 I notice just now that you say 

```
using tesseract OCR 3.03
```

That could be the problem. text2image segfaults have been fixed in recent code.

 Please use the latest windows binaries eg. from 

https://github.com/UB-Mannheim/tesseract/wiki @ibr123 Please note that if you are using windows command prompt and not bash under windows, the commands such as grep, sed etc may not be available. "text2image --find_fonts command displays the output on the terminal" does that mean no file will be generated? only printing on the terminal? ```
text2image --find_fonts \
 --fonts_dir  /usr/share/fonts/truetype/dejavu/ \
 --text ../langdata/eng/eng.training_text \
 --min_coverage .99  \
 --outputbase ../langdata/eng/eng

Total chars = 6694
DejaVu Sans : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 0 to file ../langdata/eng/eng.DejaVu_Sans.tif
DejaVu Sans Bold : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 1 to file ../langdata/eng/eng.DejaVu_Sans_Bold.tif
DejaVu Sans Mono : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 2 to file ../langdata/eng/eng.DejaVu_Sans_Mono.tif
DejaVu Sans Mono Bold : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 3 to file ../langdata/eng/eng.DejaVu_Sans_Mono_Bold.tif
DejaVu Serif : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 4 to file ../langdata/eng/eng.DejaVu_Serif.tif
DejaVu Serif Bold : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 5 to file ../langdata/eng/eng.DejaVu_Serif_Bold.tif
``` you can redirect output to file by 

```
text2image --find_fonts \
--fonts_dir  /usr/share/fonts/truetype/dejavu/ \
--text ../langdata/eng/eng.training_text \
--min_coverage .99  \
--outputbase ../langdata/eng/eng &>./test.txt
```

test.txt has 

```
Total chars = 6694
DejaVu Sans : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 0 to file ../langdata/eng/eng.DejaVu_Sans.tif
DejaVu Sans Bold : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 1 to file ../langdata/eng/eng.DejaVu_Sans_Bold.tif
DejaVu Sans Mono : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 2 to file ../langdata/eng/eng.DejaVu_Sans_Mono.tif
DejaVu Sans Mono Bold : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 3 to file ../langdata/eng/eng.DejaVu_Sans_Mono_Bold.tif
DejaVu Serif : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 4 to file ../langdata/eng/eng.DejaVu_Serif.tif
DejaVu Serif Bold : 6694 hits = 100.00%, raw = 112 = 100.00%
Rendered page 5 to file ../langdata/eng/eng.DejaVu_Serif_Bold.tif
``` If I use fonts which do not provide adequate coverage for the training text, then the output shows error.

eg. following command which tries to render hindi txt in devanagari script using regular latin script fonts. Since numbers and punctuation are same, it shows coverage of about 18%

```
text2image --find_fonts \
 --fonts_dir  /usr/share/fonts/ \
 --text ../langdata/hin/hin.training_text \
 --min_coverage .99  \
 --outputbase ../langdata/hin/hin

Total chars = 34998
Font DejaVu Serif failed with 6378 hits = 18.22%
Font DejaVu Serif Bold failed with 6378 hits = 18.22%
Font Dingbats failed with 5723 hits = 16.35%
Stripped 2 unrenderable words
FreeMono : 34995 hits = 99.99%, raw = 135 = 99.26%
Font FreeMono Bold failed with 6378 hits = 18.22%
Font FreeMono Bold Italic failed with 6378 hits = 18.22%
Font FreeMono Italic failed with 6378 hits = 18.22%
Stripped 2 unrenderable words
FreeSans : 34995 hits = 99.99%, raw = 135 = 99.26%
Font FreeSans Italic failed with 6527 hits = 18.65%
Stripped 2 unrenderable words
FreeSans Semi-Bold : 34993 hits = 99.99%, raw = 134 = 98.53%
Font FreeSans Semi-Bold Italic failed with 6378 hits = 18.22%
Stripped 2 unrenderable words
FreeSerif : 34995 hits = 99.99%, raw = 135 = 99.26%
Stripped 2 unrenderable words
FreeSerif Bold : 34995 hits = 99.99%, raw = 135 = 99.26%
Font FreeSerif Bold Italic failed with 6380 hits = 18.23%
Font FreeSerif Italic failed with 6527 hits = 18.65%
```

Note above the lines that have **raw** in them. Those are the only fonts that meet the coverage criteria. i appreciate the answers, Thanks @ibr123,

Please use the [forum](https://groups.google.com/d/forum/tesseract-ocr) for asking questions. I'm also having this issue: using latest homebrew version
tesseract: stable 3.05.00 (bottled), HEAD

The training text file I'm using is the first one posted by amitdo; but it happens with any text

Using `$ text2image --list_available_fonts --fonts_dir=/Library/Fonts` does give the font I want `Lucida Grande`

Also ran `fc-cache -frv`

Result:
$ text2image --text=eng.training_text --outputbase=eng.LucidaGrande.exp0 --font='Lucida Grande' --fonts_dir=/Library/Fonts

[1]    72778 segmentation fault  text2image --text=eng.training_text --outputbase=eng.LucidaGrande.exp0

I don't know how to get more error info to you? Please help. @amitdo Could it be that some required commit fixing text2image has not been backported for 3.05?

@Tjorriemorrie Did you build tesseract from source? Please also try with the 4.0 alpha version (latest source from github), if the same error is there?  Ray did some changes in 4.00 that made this problem reappear. These changes were also backported to 3.05.

Here is the source for the regression:
https://github.com/tesseract-ocr/tesseract/commit/709935851061#diff-b37dca9f063c3727f62c496e514177a9L440

Here is a (temporary) solution:
https://github.com/tesseract-ocr/tesseract/issues/736#issuecomment-282685898
  Hello!
I need to run tesseract without leptonica installed on the CentOS system. 
I have leptonica liblept.so available, and I am able to compile tesseract pointing to that directory.

Is it possible to run tesseract without setting up LD_LIBRARY_PATH? 
Maybe there is some way to add some parameter to let tesseract know where leptonica is located in execution phase?

Is it possible to compile tesseract to be independent from shared library liblept.so? Is there any "configure" script parameter available to compile liblept.so into tesseract executable? 
  Here is the excerpt:

“Any language that has different punctuation and numbers is going to be disadvantaged by some of the hard-coded algorithms that assume ASCII punctuation and digits. To be fixed in 3.02.”

from https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#background-and-limitations
 The nice thing about a wiki is that anyone can edit it.  I'm pretty sure none of this is hardcoded any more and, if you agree, you can update the wiki page to match the current reality.
 It depends, not all Wikis have open sign up or give access to anyone for that matter.

I see that in the case of Tesseract on github, I could edit it myself indeed, thanks for the information.

That being said, I haven't investigated the issue, so I don't know what the current status is. In my opinion, it is better to report the issue without fixing it rather than just not fix it. I'll try to look into this later.
  After cmake generation, `TesseractConfig.cmake` not contains `ccutil` include directory. And when i try use `TesseractConfig.cmake` in my build - receive error `platform.h not found`
  See also tesseract-ocr/langdata#23.

Re-do of #188 to re-run and (hopefully) fix tests.
 @amitdo Ah, sorry about that - wasn't sure how to re-trigger it and couldn't turn up anything searching.
  See also tesseract-ocr/langdata#23.
  There seems some communication problem between tesseract 3.04 (package on debian stretch) and hocr2pdf 0.91 (package on debian stretch as well): whereas the tesseract output (up to a stupid xml tag) is a readable html and quite nice to look at ; but hocr2pdf will make VERY messy pdf's.

It seems that I am not alone to experience these problems, see e.g.
http://w3foverflow.com/question/tesseract-and-hocr-on-ubuntu-14-04/

How to make an example? Step 1: scan a messy, double page, Step 2: nice it up using scantailor, then use the output tiffs (in the "out" directory) ; Step 3: these are passed to tesseract with hocr option.   Step 4: finally invoke 

hocr2pdf -n -i image.tif  -o test.pdf  < image.hocr

By virtue of the "-n" option, you only see the (malformed) ocr output which is not overlayed by the right image.

It is unclear to me if this is an tesseract issue or an hocr2pdf issue, of course.

Cheers, Eric
 It's best by far to produce PDF directly from Tesseract. If you really have to go via HOCR for some weird reason, use https://github.com/tmbdev/hocr-tools/blob/master/hocr-pdf instead of hocr2pdf.
  Hi all, 

I am trying to use Tesseract's HOCR output functionality to generate an html file that includes all of the word font attributes - most of important of which is font_id.  From first glance, it looks like I will have to write a custom HOCR script with the result_Iterator to make this work.  

Any tips on getting HOCR output with font ID info without having to rewrite the GetHocrText function?

Thanks !!!
 Your better off asking questions on one of the mailing lists where more people will see it.  I only happened to stumble across this because I was looking at the hOCR code.

The current hOCR renderer already has the capability to output font information, including name.  It just needs to be enabled with a config parameter.

@zdenop please close this
  box.train (and box.train.stderr) exit with no action since commits from 17-Dec-2015 (c2f5e9b8+a20156fc, updates in api/tesseractmain.cpp). No renderer is created for this configuration.
  While Acrobat XI can find text in a PDF, it appears that [poppler](https://en.wikipedia.org/wiki/Pdftotext)'s `pdftotext` program, OS X's Preview app, and the library [PyPDF2](https://github.com/mstamy2/PyPDF2/tree/master/PyPDF2)'s extractText() function all fail to locate text. It seems that Tesseract is encoding text in a way that makes it inaccessible to many PDF viewers.

`pdftotext` produces empty output.
Preview app allows highlighting of text in the appropriate locations, but it cannot be copied to the clipboard or searched.
PyPDF2 extractText also produces an empty string as text.
 #170 might be related, but the files I checked did not have tilted or skewed text.

Input file:
![linnsequencer](https://cloud.githubusercontent.com/assets/1825843/12100857/6fba9e66-b2e6-11e5-8df1-d928e75a1b44.jpg)

Output:
[linn.pdf](https://github.com/tesseract-ocr/tesseract/files/77727/linn.pdf)

tesseract version
`
tesseract 3.04.00
 leptonica-1.72
  libjpeg 8d : libpng 1.6.19 : libtiff 4.0.6 : zlib 1.2.5
`
 Chrome's PDF reader works for me.

I have poppler 0.39.0 installed (homebrew/OS X/El Capitan).

I believe I found the reason. It appears that the readers that struggle with it do not support Tesseract's usage of hexadecimal code points rather than literal characters in the output stream.

The PostScript content stream for this page as generated by Tesseract for the first word, "The" appears as follows:

``` Postscript
 Tz [ <0054><0068><0065> ] TJ  
```

where <0054> = U+0054 = T, <0068> = U+0068 = h, etc. I have run into other situations where this hexadecimal notation causes parsing difficulties for some PDF readers.

Acrobat generates the equivalent segment with ASCII literals.

``` Postscript
[...omitted...] Tm
(The )Tj
```

Longer excerpts for comparison:

Tesseract

``` Postscript
BT    
3 Tr 1 0 0 1 211.68 744 Tm /f-0-0 21 Tf 117.334 Tz [ <0054><0068><0065> ] TJ  
```

Acrobat

``` Postscript
BT
0.196 0.184 0.188 rg
/T1_0 1 Tf
-0.035 Tc 3 Tr 23.4905 0 0 23.7001 211.43 744.24 Tm
(The )Tj
ET
```
 Yes. Preview and poppler are still incapable of reading your i182.pdf. I observed no difference.

My comparison didn't address how Acrobat handles Unicode and Unicode literals cannot appear in Postscript so I checked how this is done. When Acrobat encodes a Unicode string it uses UTF-16 big endian code points in hexadecimal, like this:

``` Postscript
... Tm
<4E8B5F97771F5BF9770B89C152A066F4591A5C11>Tj
```

That string encodes 10 characters all below U+7FFF, which are these:
事得真对看见加更多少

So it appears that Tesseract's method of encoding text strings is nonstandard. I checked the PDF 1.7 reference manual, and couldn't find an example matching Tesseract's output syntax.
 Okay, for some reason pdftotext will not output to stdout but will produce a valid text file for the files we've been working on. My quick guess is that pdftotext suppresses its stdout if high ASCII characters are present, which tesseract finds here (some n-dashes and smart quotes). Both poppler 0.24.5 and 0.34 behave as expected when asked to save to a file, so the text stream is accessible to pdftotext. In short, poppler is working fine for me.

That said, OS X Preview and parsers like PyPDF2 still struggle with how Tesseract encodes text, as far as I can tell. 

I checked that reportlab also encodes text strings in the manner of Acrobat, and Preview has no problems with PDFs produced by Tesseract -> hOCR -> reportlab PDF. This is an example of such a file:

[linn_hocr_unc.pdf](https://github.com/tesseract-ocr/tesseract/files/77885/linn_hocr_unc.pdf)
 Qpdf says it okay, but it doesn't check everything.
On Mon, Jan 4, 2016 at 17:55 Amit Dovev notifications@github.com wrote:

> Try this to output to stdout:
> 
> pdftotext i182.pdf -
> 
> Jeff mentioned qpdf.
> Links:
> http://qpdf.sourceforge.net
> https://github.com/qpdf/qpdf
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/182#issuecomment-168868649
> .
 I might not have time to take a look until Wednesday. Validators of various flavors  include jhove, jhove-pdf-a, pdfbox, ITextRUPS, and http://www.pdf-tools.com/pdf/validate-pdfa-online.aspx.  (Note that Tesseract PDF are not expected to be PDF/A compliant). I did compatibility testing with Apple's Preview at design time, but I don't test against it regularly. Never tried PyPDF2.  If I had to guess right now, I'd suspect it might be the invisible font improvement that was written for better ghostscript compatibility. Unlikely to be the hex encoding.

https://code.google.com/p/tesseract-ocr/issues/detail?id=1434
http://bugs.ghostscript.com/show_bug.cgi?id=695869
 Looking at issue 181, it's looking more and more like Preview is unhappy with the revised glyphless font, possible due to the zero advance width. Will try to borrow a Mac and play with it, hopefully on Wednesday.
 @jbreiden I agree that the glyphless font issue seems more probable.

Aside: I wouldn't trust JHOVE for PDF validation. For JHOVE to approve is better than not approving, but its analysis is rudimentary, and in my experience it produce more false positives and negatives than useful diagnostics.
 I produced this PDF using Tesseract, then borrowed a laptop running Mac OS X version 10.10.5 and was able to both search and copy-paste from Preview (Although the copy-paste highlighting was kind of weird). My testing copy of Tesseract is not completely synchronized with GitHub, so if needed we can investigate that. How does this PDF perform for you on Preview, @jbarlow83 ?

[2.pdf](https://github.com/tesseract-ocr/tesseract/files/79277/2.pdf)

There is also an alternative invisible font here, that contains an advanceWidth. I think it can be swapped in for tessdata/pdf.ttf. It has a side effect of making highlighting look even more bizarre in evince. I don't notice any compatibility differences at all, but mentioning in case someone wants to play with it. Have not checked compatibility with Ghostscript.

https://github.com/behdad/tofudetector/blob/master/tofu.ttf?raw=true

Finally, this was my test image (I was actually using TIFF but GitHub doesn't let me attach that)

![relativity](https://cloud.githubusercontent.com/assets/4961958/12132423/45519c7a-b3d0-11e5-9700-3179d131ae9e.png)
 Doesn't work in Preview OS X 10.11.2 (highlights properly, but no copy-paste or search). I have access to two other OS X machines - will check those later day.

I check with my iPhone too. Both Chrome iOS (PDFium?) via Gmail app and Safari struggle to highlight text (they only allow highlighting a single character) and cannot copy.
 This one uses the alternate font that has an advance width.

[alternate.pdf](https://github.com/tesseract-ocr/tesseract/files/79359/alternate.pdf)
 alternate works on OS X Preview and my iPhone. 

I did notice that spaces are sometimes missing in OS X's copy and paste text, while pdftotext shows the spaces, so perhaps it's not 100% but clearly this was the main issue.

> components of the relative motions of the fixed , stars with respect to the earth on the colour of **thelightreachingusfromthem. Thelattereffect** manifests itself in a slight displacement of the spectral lines of the light transmitted to us from
> 
> a fixed star, as compared with the position of the same spectral lines when they are produced by a terrestrial source of light (Doppler principle). The experimental arguments in favour of the Maxwell-Lorentz theory, which are at the;same time arguments in favour of the theory of **rela- tivity,aretoonumeroustobesetforthhere**. In reality they limit the theoretical possibilities to such an extent, that no other theory than that of Maxwell and Lorentz has been able to hold its ownwhentestedbyexperience.
> 
> But there are two classes of experimental facts hitherto obtained which can be represented in the Maxwell-Lorentz theory only by the introduction of an auxiliary hypothesis, which in itself—i.e. without making use of the theory of relativity— appears extraneous.
> 
> Itisknownthatcathoderaysandtheso-called B—rays emitted by radioactive substances consist of negatively electrified particles (electrons) of verysmallinertiaandlargevelocity. By examin- ing the deflection of these rays under the influence of electric and magnetic fields, we can study the
> 
> law of motion of these particles very exactly. 
 > Output:
> linn.pdf

For me, pdftotext outputs no text, but Evince, which also uses Poppler, correctly selects and extracts text.
 > @behdad, try this:
> 
> ```
> pdftotext linn.pdf -
> ```

Hah.  My bad.  Thanks :)
 I got my hands on an iPad running iOS 9.2 and reproduced the problem. On iOS/Safari I cannot search 2.pdf (Ken Sharp's font) but can search with alternate.pdf (Behdad's font). Took me quite a while to figure out how how to make the search controls work.

So for your immediate problem, go ahead and substitute in Behdad's font into tessdata/pdf.ttf and you should be okay. We won't do that officially without a whole bunch more compatibility testing and reports, including the harder languages (Cherokee, vertical Japanese, Arabic) and additional renderers including Ghostscript and Firefox. Compatibility reports are appreciated.

https://github.com/behdad/tofudetector/blob/master/tofu.ttf?raw=true

Regarding the words running together on the Apple PDF renderer, that's not new. Apple PDF seems to do a worse job than everyone else at deciding word boundaries, and I've seen them screw up plenty of regular born-digital PDF files in the same way. Of course the root cause is the PDF spec itself, which does not explicitly define the concept of a word boundary. So I can't help you, but at least it isn't a regression. It's possible that Apple will get their act together a little better on this some day, but I have no reason to believe that it is on their radar.
 My font has a huge advance width, because it was designed for another purpose.  Someone should create one with an advance width of 1024 instead of my 20480.
 The PDF is keeping the advance width under control for Behdad's font. We're probably seeing something else. It's kind of cute zebra pattern. You get a black underline, and black boxes in all word gaps and in some letter gaps. (Obviously evince is doing a really bad  job, but this is much worse than with Ken Sharp's font, which highlights as a solid  black bar.) A little hard for me to investigate, since my copy of ttx is not cooperating.

P.S. The font advance width should probably be 512 to match what we specify in the PDF. But again, I don't expect that to change anything for evince.

![evince](https://cloud.githubusercontent.com/assets/4961958/12207036/566e60a8-b5f9-11e5-92c2-61ad905889b9.png)
 FWIW, 
    1) I can confirm the problem as stated. Also, I've been using the same tesseract build, and it stopped working due to OS X update (unfortunately, I'm not sure which, possibly 10.11.1)
    2) As suggested above, using tofu.ttf fixed the issue for me (OS X 10.11.3, Finnish OCR), no recompile of tesseract needed
 Partially blocked by https://github.com/behdad/fonttools/issues/497
 Two choices. 
- Add advance width to Ken Sharp's font.
- Reduce advance with in Behdad's font.

This PDF is the former, please test for compatibility.

[sharp.pdf](https://github.com/tesseract-ocr/tesseract/files/112801/simple-1.pdf)

```
diff -u pdf.ttx sharp.ttx
--- pdf.ttx 2016-02-01 10:24:02.875924041 -0800
+++ sharp.ttx   2016-02-01 10:23:38.659586076 -0800
@@ -14,7 +14,7 @@
     <checkSumAdjustment value="0xa737b34c"/>
     <magicNumber value="0x5f0f3cf5"/>
     <flags value="00000100 00000111"/>
-    <unitsPerEm value="256"/>
+    <unitsPerEm value="2048"/>
     <created value="Thu May 15 23:21:18 2014"/>
     <modified value="Thu May 15 23:21:18 2014"/>
     <xMin value="0"/>
@@ -33,7 +33,7 @@
     <ascent value="1"/>
     <descent value="-1"/>
     <lineGap value="0"/>
-    <advanceWidthMax value="0"/>
+    <advanceWidthMax value="1024"/>
     <minLeftSideBearing value="0"/>
     <minRightSideBearing value="0"/>
     <xMaxExtent value="0"/>
@@ -71,7 +71,7 @@
     <!-- The fields 'usFirstCharIndex' and 'usLastCharIndex'
          will be recalculated by the compiler -->
     <version value="3"/>
-    <xAvgCharWidth value="0"/>
+    <xAvgCharWidth value="1024"/>
     <usWeightClass value="400"/>
     <usWidthClass value="5"/>
     <fsType value="00000000 00000000"/>
@@ -122,7 +122,7 @@

   <hmtx>
     <mtx name=".notdef" width="0" lsb="0"/>
-    <mtx name=".null" width="0" lsb="0"/>
+    <mtx name=".null" width="1024" lsb="0"/>
   </hmtx>

   <cmap>
```
 Nope, the PDF doen't seem to work for me (Mac OS X 10.11.3). The copied text is just equal number of spaces.
 This PDF is the latter, please test for compatibility. (Despite the change to advance width, we still get horrible looking highlighting on evince.)

[behdad.pdf](https://github.com/tesseract-ocr/tesseract/files/112823/simple-1.pdf)

```
--- tofu.ttx    2016-02-01 10:17:15.038213397 -0800
+++ behdad.ttx  2016-02-01 10:43:29.839794297 -0800
@@ -33,7 +33,7 @@
     <ascent value="2048"/>
     <descent value="0"/>
     <lineGap value="0"/>
-    <advanceWidthMax value="20480"/>
+    <advanceWidthMax value="1024"/>
     <minLeftSideBearing value="0"/>
     <minRightSideBearing value="0"/>
     <xMaxExtent value="0"/>
@@ -69,7 +69,7 @@

   <OS_2>
     <version value="3"/>
-    <xAvgCharWidth value="790"/>
+    <xAvgCharWidth value="1024"/>
     <usWeightClass value="400"/>
     <usWidthClass value="5"/>
     <fsType value="00000000 00000000"/>
@@ -120,7 +120,7 @@

   <hmtx>
     <mtx name=".notdef" width="2048" lsb="0"/>
-    <mtx name="glyph00001" width="20480" lsb="0"/>
+    <mtx name="glyph00001" width="1024" lsb="0"/>
   </hmtx>

   <loca>
```
 behdad.pdf works better. The letters are now reproduced correctly. There's still something funny with how selection works. Selecting from left to right doesn't correctly select all the letters. Right-to-left selects the three last characters one by one and then all four of the rest at once. Might be unrelated issue, though.
 This is another attempt at the behdad font, with the contour data removed. It fixes the visual problem with evince. Please test for compatibility. If successful, we probably have a winner. (Don't worry about the left-to-right vs. right-to-left selection oddities; that's due to mixing Hebrew and English words in my test document)

[behdad2.pdf](https://github.com/tesseract-ocr/tesseract/files/112840/simple-1.pdf)
 Nope, this does not work any more (selected characters are spaces again).
 Utterly insane. I would really, really like to speak with the relevant software engineer at Apple. Putting this problem aside for a bit.
 Yes, utterly. I ran the tofu.ttf and the old pdf.ttf through Apples font validator. Both produced errors, but tofu.ttf only one, whereas the old pdf.ttf had additional "name table usability" errors. Please post the above font files (or diffs) and I'll run them through the validator as well. Perhaps this will give some insight to the issue.
 Fonts as per request. I do not know if my modification tool (ttx) corrupts anything along the way. So far the experiments suggest that Apple software requires a contour, and a contour cosmetically messes with evince.

pdf.ttf - currently shipping font, by Ken Sharp
sharp.ttf - with advance width added

tofu.ttf - alternate font from behdad
behdad.ttf -  with advance width reduced
behdad2.ttf - with contour removed

[fonts.zip](https://github.com/tesseract-ocr/tesseract/files/112928/fonts.zip)
 Thanks. Here's the verbose error report as given by Apples ftxvalidator (there's not really a version for 10.11, so some of this might be inaccurate). All report fatal errors and most errors are beyond my (admittedly limited) expertise on the subject. I hope they make more sense to you. 

[Uploading ftxvalidator_report.txt…]()
 Can you please edit that report and make it an attachment or something? The giant wall of text makes this bug harder to read.
 > Partially blocked by behdad/fonttools#497

Fixed now.
 For completeness, here is Ken Sharp's font with a contour added in. 

FONT
[sharp2.zip](https://github.com/tesseract-ocr/tesseract/files/119877/sharp2.zip)

PDF
[sharp2.pdf](https://github.com/tesseract-ocr/tesseract/files/119875/simple-1.pdf)

At this point, sharp2.ttf and behdad.ttf are the only fonts compatible with Apple Preview. They both come at the cost highlight aesthetics with evince. I think Preview is incorrect to require a contour for the glyph, and I think evince is incorrect to consider a contour when highlighting an invisible font. I do not have any reason so far to prefer one over the other, and I do not yet have compatibility test results from ghostscript, firefox, Microsoft Edge, etc.
 I have filed a bug with Apple. This is not publicly visible and I do not know what the response will be. Noting it here simply simply for future reference. radr://24533090
 In progress testing compatibility with candidates "sharp2" and "behdad" including getting some assistance with ghostscript. So far no user visible differences between them, and the former is the smaller change. Is there general consensus to work around the Apple compatibility problem, at the expense of Evince highlight aesthetics?
 @jbreiden I agree. OS X Preview is installed on ~10% of all desktop computers. Evince is just one of many PDF viewers for Linux users.
 @jbarlow83 and @jbreiden This bug also affects the Amazon Kindles. As an avid user of Amazon Kindle and Tesseract, I feel crippled now. And don't forget that all those pdfs generated with Tesseract won't work with Kindle either around the world.
 @bekirserifoglu - can you please confirm that both proposed workarounds found in previous comments (sharp2.pdf, behdad.pdf) solve the problem on Kindle?
 @jbreiden I can confirm that both sharp and tofu fonts work great with Kindle Voyage and Preview on Os X. Feel free to mention me if you need anymore testing.
 @bekirserifoglu - Is the failure case on Kindle broken search and broken copy-paste? Or is it even worse than that?
 @jbreiden Kindle just treats the pdf as a non-ocr'ed pdf. It is worse than OS X preview.
 @theraysmith 

Okay, I've decided. We're going to use the sharp2 font.

For various embarassing reasons, I'd appreciate some help. Could someone please download this zip file, extract sharp2.ttf, and use it to replace pdf.ttf in the repository. The resulting file should still be called pdf.ttf. I apologize for not doing this myself and promise to get my act together with respect to GitHub pull requests in the future. 

[sharp2.zip](https://github.com/tesseract-ocr/tesseract/files/127261/sharp2.zip)

https://github.com/tesseract-ocr/tesseract/blob/master/tessdata/pdf.ttf
 Done. PR #220.
 Thank you for fixing this. 
  Hi all,

I am working on the OCR based android application which loads the image from gallery or photo click from phone's camera. All went well using the tess-two lib. However, the accuracy of reading the text from the image is very poor. Quality of photos are good(8 megapixel camera) and whereas, other application on stores read them much better.

Could you please suggest me how can I improve the accuracy.

Thanks,
Vikas Yadav
  POSIX provides portable data types for signed and unsigned integer values
of different size.

This patch maps those POSIX data types to the Tesseract specific types.
In a next step, the Tesseract data types can be eliminated by replacing
them with the POSIX data types.

~~Use also standard definitions for the printf format specifiers.
MS Visual Studio does not support that standard (at least not in older
versions), so local definitions are needed there.~~

~~NULL is standard, so a local definition should not be needed.~~

Signed-off-by: Stefan Weil sw@weilnetz.de
 Updated patch: removed part for format specifiers, don't remove NULL definition (both issues should be done in separate patches).
 Maybe it would be even better to go thru the code and use, for example, `int8_t` instead of `inT8`...
 @LinusU, yes, that would be the next step as soon as this pull request was accepted.
 :+1: 
 Ping? Are there any more thoughts on my proposal?
 @theraysmith, ping. Do you support the idea of replacing Tesseract data types by POSIX data types (so I can prepare a follow-up pull request)?

Many other free software projects with similar compiler / host conditions have shown that using POSIX data types works. Especially for library interfaces, but also for the rest of the code, it would be good to get rid of project specific data types which don't provide any additional value compared with the standard.
 Ping? I suggest to apply this patch now, wait one more month and then replace all Tesseract integer types by the POSIX types.
 @theraysmith, @zdenop, do you have any comments to my last proposal? Can we proceed like that?
 Ping?
 I still think it would be a good idea to replace all proprietary data types by the POSIX ones. Is it really necessary to wait for @theraysmith (who is obviously very busy)? Lots of other free (and also commercial) software projects work pretty good with the  POSIX data types, using similar environments as Tesseract (Linux and other Unixes, Windows with Cygwin / MinGW-w64 / MS and other compilers).

So can we do the first step and apply this PR which is waiting for more than 7 months now?
 Another month passed. I'd still like to see Tesseract switching to POSIX data types.
 @zdenop said re: next release in https://github.com/tesseract-ocr/tesseract/issues/165#issuecomment-244039370

> I hear something like end of September 2016, but you never know ;-) It will big update (probably we will drop support of compilers nor support c++11)...

Will dropping support for compilers effect Tesseract switching to POSIX data types?
 > Will dropping support for compilers effect Tesseract switching to POSIX data types?

I don't think that POSIX data types are affected by the compiler decision. They exist for many years now, so any supported old or new compiler will work with POSIX data types.
 @theraysmith, may I kindly ask you to give your consent? Woohoo! 🎉 

Now if we could only replace all occurences of `inT8` with `int8_t`, `uinT8` with `uint8_t` and so forth 🙌  Yes, replacing those Tesseract data types by the POSIX data types will be the next step.

@zdenop, that means changes for nearly all source files which will give conflicts with pending pull requests. Should I nevertheless send one large PR which does the replacement, or would it be better to do it in smaller steps (starting for example with all files in `lstm`)? Are there more major changes pending after the integration of LSTM? >  I already put a few experimental uses of nullptr in 4.00 to see if anyone squeals.

@theraysmith, training/stringrenderer.cpp already uses `nullptr` for more than two years now. AFAIK nobody complained, so that seems to work. Replacing `NULL` by `nullptr` would be good, but also touches many files, so this could be done in the same action as the switch to POSIX data types.

Do you care for comments after modified code? Replacing data types or NULL is easy, but the replacements are a little bit longer, and moving the comments to the right column means much hand work without code formatter.  When I run "tesseract -c hocr_font_info=T hocr"  on attached file the segmentation fault is received. Output file is empty.
But when I run "tesseract hocr" on the same file without "-c hocr font_info=T", the recognition runs as expected, without any errors.
![1050103_world-markets-at-a-glancepp](https://cloud.githubusercontent.com/assets/8905596/11893647/bf069384-a58b-11e5-8283-7e1fc75600f9.jpeg)
 I was using stock ubuntu 15.10 version. Build from repo and solved. Thank you!
 Oh, I mean 15.10, you're right.  
  Hello.

My goal is simple, I need to extract the identification number from id photos.
I run tesseract and it

![20151211_105843](https://cloud.githubusercontent.com/assets/6429534/11748020/f8484ef8-a004-11e5-9fdf-bc658e13390e.png)

 recognizes only the last surname but I need to get the number (the photo is attached).

Could you please help me?

Thank you very much
  The wiki page states "An installer is available for Windows from our download page." The statement is incorrect since there in no Windows installer available from the said page.
 See #101 which handles the same issue. Maybe you want to try the installer from https://github.com/UB-Mannheim/tesseract/wiki.
 Yes, a clear Wiki message like "no Windows artifacts for current versions of Tesseract will be provided in the project" would clarify the situation. 
  The characters in the attached image are recognized by Tesseract, but placed in a wrong order when generating a PDF file (which prevents searching in the PDF):

```
$ tesseract pdf-test.jpg pdf-test pdf
$ pdftotext pdf-test.pdf -
ra
me
ka
ot
ar
fr
In
en
ch
is
om
on
tr
as
r
ne
ei
g
un
ob
pr
Bau und Er
```

The original text scan is not exactly horizontal (-0.5°). If this is fixed before doing OCR, Tesseract creates a PDF with the correct text.

![pdf-test](https://cloud.githubusercontent.com/assets/6734573/11728560/df7dfa46-9f8a-11e5-949c-6ff549c62f1d.jpg)
 I suspect the problem is in pdftotext. To find out, open the PDF in another viewer such as Chrome or Adobe Reader and see what you get during search and copy-paste.
 Confirmed. Poppler (used by pdftotext) has a very hard time with titled text. If you want Tesseract to be more aggressive at producing flat text lines for tilted images, modify ClipBaseline(). But a better approach is to to use a different text extractor, for example one based on PDFium.

https://github.com/tesseract-ocr/tesseract/blob/master/api/pdfrenderer.cpp#L275
 And finally, if you want to post-process Tesseract produced PDF to flatten out tilted textlines, that's also fairly easy. Just ask if you need details.
 `evince` (my standard PDF viewer on Linux) has the same problem and is not able to search such PDFs. The PDF viewer of `iceweasel` / `Firefox` gets the words right, so it is possible to search 'Infrarotkamera', but not the lines, so searching for word combinations does not work.

I don't want to post-process a PDF produced by Tesseract: the TXT file is perfect, so no need for me to extract text from the PDF.

I want to produce a PDF which I can give to others and which they can use with their normal PDF viewer.

Why is the text in the PDF file split into 2 character sequences? In the HOCR output, words remain words.
 Maybe Firefox also uses parts of the Poppler code. So there are a number of PDF viewers which are less robust in getting correct text lines from a Tesseract PDF. Wikipedia shows that the list of these viewers is quit impressive. This increases my wish to understand and fix what goes wrong in Tesseract's PDF generation process.
 I just tested with Chromium (Debian's variant of Chrome). It gets the text better, but not good: "astronomischen Infrarotkamera" is not found because it is split in separate lines. 
 ![tilt](https://cloud.githubusercontent.com/assets/4961958/11765657/b19b4bf6-a115-11e5-97d3-d8ec63256afc.png)

There's nothing invalid with the PDF files produced; tilted symbolic text lines are legitimate in PDF. They are the accurate representation of OCR results. The words are inside there just fine, along with some geometry describing the angle of the baseline. That said, this does blow the mind of some PDF text extractors who assume that it is impossible for a line of text to have any deviation of y-position between characters. (As you might imagine, this gets particularly fun with vertical Japanese text.)

You have exactly three choices if you want to better compatibility these viewers. One is to deskew the image before calling OCR. Second is modifying the section of code I pointed to earlier in Tesseract, to eliminate tilt in the symbolic text lines. Third is to remove the tilt in the invisible symbolic text lines, after the PDF is produced. All three of these approaches are relatively easy for a programmer and I'm happy to provide guidance.

There are major problems of forcing heavily titled text lines to be flat, a big one being
word highlightling ends up in the wrong place visually. So I would be reluctant to do that by default.
 There must be some other aspect of the original scan, because Tesseract generates a PDF which works perfectly with all viewers and with pdftotext from this generated image with the same tilted text:
![generated-image](https://cloud.githubusercontent.com/assets/6734573/11766292/348dd4d2-a181-11e5-80a5-b12946a7ca44.jpg)
 Ok. Let me explain what I have understood. Obviously it is not possible to describe a rotated text line in PDF, so you have either to pretend that the line is horizontal (that's what ABBYY does with the original image and Tesseract does with the generated image), or you have to approximate the rotation by splitting the text line into smaller parts with different y values (which is causing trouble with most or even all free PDF viewers, at least those that are based on Poppler, Mozilla or PDFium).

I noticed a 2nd difference between ABBYY and Tesseract PDF: with Evince, selected text from the Tesseract PDF is shown as a simple blue rectangle, while in the ABBYY PDF it also shows the characters with some built-in font. But that's a different story. 
 @stweil: You are misunderstanding. It is possible to describe a rotated text line in PDF. Tesseract does exactly this for any text line whose tilt is large enough. The tilted screenshot in Hebrew above is Tesseract output, displayed in Adobe Reader. You can even see the tilted text lines being highlighted for copy-paste in all their tilted glory. I point everyone again at the critical piece of code that explains the situation. It effectively says, 'Does the vertical displacement between the beginning and end of the baseline exceed 2 pts? (2 pts = 1 / 36 inch) If so, pretend the line is horizontal. Otherwise, faithfully record it as tilted.

https://github.com/tesseract-ocr/tesseract/blob/master/api/pdfrenderer.cpp#L275

P.S. While there is a prayer that Poppler will evolve, my best guess is it will instead be replaced with PDFium some time over the next 10 years. PDFium is by no means perfect, but it is much stronger than Poppler.
 I am going to close this issue soon, as working as intended. If people think the 
threshold should be increased, that's a reasonable thing to discuss. Right now if
a text line has 2pts or less vertical displacement, we draw it totally flat. Maybe
that number should be 3pts.
 I have similar problem while extracting data from pdf, it splits into one or two characters per line.  I tried using TESS4J which gets the text much better. So trying to find if there is any options in tesseract(java) i could use.

Thanks  Hi there,
I have created my own Arabic Language traindata, but the problem is that when used it gives the recognized text reversely (opposite direction), noting that the Arabic and Hebrew languages are written and read from Right to left handside (RTL).
People keep implying to use Cube for training Arabic, but I think no one really knows how to use Cube for training, and yes I have read the tesseract extra Cube documentation, and it seems that they purposely don't want anyone to use Cube.
How can I make a tesseract traineddata that recognize RTL languages as Arabic correctly?
Waiting for your reply
 Thank you for reply
I have just used the "wordlist2dawg -r 1" that you suggested and it's has solved my "reversed words" problem.
But now I have a new problem, the recognized text are combined together, meaning the words have no spacing between them. Tesseract seems to recognize all words as only 1 word.
I need help, waiting for reply 
 The problem has been solved! Thanks to the user (amitdo) The solution was:
To use "wordlist2dawg.exe -r 1" to create the "freaquent_words_list" + "words_list"
To use "ara.config" and removing this line from it "tessedit_ocr_engine_mode 1"

This solved my 2 problems of Arabic Language reversed words, and Arabic Language combined word.
Thank you
 @christophered 
did you get any good results by training? my best accuracy is about 40-50% on 300 dpi scanned document
 roozgar, I will conduct some tests and will reply back after couple of days
 @christophered 
i tried to find official Arabic resources to make up a better train file but not lucky 
so
if you need i can help you by providing Arabic words list or some scanned page 
just send me an email: roozgar@gmail.com
 Thank you roozgar, I appreciate you
I am currently conducting some tests on Arabic Tesseract and I am exhausting all resources available to me to make sure finding the best method for arabic recognition.
Don't worry I will conduct some tests and reply back to you ( by GOD)
By-the-way send me the scanned Arabic Document that you've been testing the accuracy on.
waiting for your reply
 @christophered 
sure
please tell me your email address 
 christopher.edward@outlook.com
 I have tested tesseract 3.02+3.04+3.05dev all have failed in arabic ocr.
Some-how I got the feeling that Arabic Language was purposely neglected and rejected.
 @christophered do you have any plan to work more on this subject?!
the official train data for arabic is working really good on 'times' font
so i think its possible to have a good accuracy other fonts too!
 @amitdo Oops! i found this

https://code.google.com/archive/p/tesseract-ocr-extradocs/wikis/Cube.wiki

its really undocumented!!
but how they build current Arabic file!!
 @amitdo who are they? i there any way to find who build each trained file?
 @christophered 
hey christopher, can you please tell me how you created your own .traineddata file for arabic or send me a link that contains a tutorial that i can use to follow.
I have been trying to implemented Tresseract ara.traineddata file but for some reason, the app that i have made using android studio gets stuck
 Hi @areebakamil  I have replyed by email also here is the Tutorial that you requested.
https://www.youtube.com/watch?v=vohgRChtRck

also here is one method to improve the recognition, just for testing
https://www.youtube.com/watch?v=tLJvHWhX_JA

Please remember this is for the Arabic Language, the recognition rate is low to moderate.
Training tesseract for English Language gains +90%, but not for Arabic sadly.

in jtessboxeditor:
Arabic use ara
Urdu use urd
English use eng
 @christophered 
How do you take into account the different forms - isolated, initial, medial and final forms of the same letter, during training?

[https://tsl620atnaz.wikispaces.com/file/view/arabic.gif/130745645/arabic.gif](https://tsl620atnaz.wikispaces.com/file/view/arabic.gif/130745645/arabic.gif)
 @Shreeshrii 
one of the methods that I use in training:
example:
Isolated: **(ك)**
Initial: (ك) then press "Shift j or ت" , **so the result will be ( كـ)**
Medial: "Shift j or ت" , then press (ك), then "Shift j or ت" , **result is ( ـكـ )**
Final: "Shift j or ت" , then press (ك) , **result is (ـك)** Hi , 
can you please provide me any version of tesseract-ocr which supports "Arabic " Language ,
I am tried with tesseract-ocr3.02 version ,
It is not supportng "Arabic " Language,
if any upgade  or downgrade versions supports "Arabic " language 
Please Let me know 

1) If any supported version is there "send me " tesseract-ocr " software and all supported configuration files as well
2) or else if download is available send me  "dowload link " to "saimuralikrishna005@gmail.com "
3) In case if required please  provide to my business mail id : "saikrishna.yalakala@wissen.com "
send me mail "saimuralikrishna005@gmail.com"  @amitdo should this work for hebrew as well? Do I need to create training data myself (i.e.  "freaquent_words_list" + "words_list" etc)?


10x Hi Uri !

There is a tessdata package for Hebrew.
https://github.com/tesseract-ocr/tesseract/wiki/Data-Files

Try to use it before you start training Hebrew.

Also, read this page:
https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality

>should this work for hebrew as well?

By 'this' you mean

1) 'Tessseract' ?
Yes. Tessseract supports Hebrew.
The provided tessdata does not supports Hebrew diacritics (nikud).

2)
>From https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#dictionary-data-optional
>For right-to-left languages (RTL) use option "-r 1".

Yes, it should be used for Hebrew too.

If you have further questions please use the [forum](https://groups.google.com/d/forum/tesseract-ocr) (I'm not participating there).

For Hebrew OCR questions / discussions you can also try here:
https://github.com/amitdo/Hebrew-OCR-Discussions @amitdo thank you very much! I will go through you suggestions.
I meant should the solution for Arabic reverse output should apply for Hebrew as well. 
One of the participants mensons reversing the strings int the training data, wasn't sure if this is somethng I need to do...? Hi, 
I am also having problems with tesseract OCR for arabic and i need your help.

Can you please send me a trained data file for arabic language for tesseract 3.0.2?
My email is adinetoiu@yahoo.com.

Thank you in advance,
Adrian
 @adinetoiu I suggest that you skip using Tesseract 3.x for Arabic, instead use Tesseract 4.
a binary is also available at [http://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-4.00.00dev.exe](http://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-4.00.00dev.exe)

 Thank you very much!


      From: chris <notifications@github.com>
 To: tesseract-ocr/tesseract <tesseract@noreply.github.com> 
Cc: adinetoiu <adinetoiu@yahoo.com>; Mention <mention@noreply.github.com>
 Sent: Monday, June 19, 2017 5:14 PM
 Subject: Re: [tesseract-ocr/tesseract] Arabic Language output is reversed (#169)
   
@adinetoiu I suggest that you skip using Tesseract 3.x for Arabic, instead use Tesseract 4.
a binary is also available at http://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-4.00.00dev.exe—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or mute the thread.  

    Do you have a sample project or link that uses tesseract 4?

      From: chris <notifications@github.com>
 To: tesseract-ocr/tesseract <tesseract@noreply.github.com> 
Cc: adinetoiu <adinetoiu@yahoo.com>; Mention <mention@noreply.github.com>
 Sent: Monday, June 19, 2017 5:14 PM
 Subject: Re: [tesseract-ocr/tesseract] Arabic Language output is reversed (#169)
   
@adinetoiu I suggest that you skip using Tesseract 3.x for Arabic, instead use Tesseract 4.
a binary is also available at http://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-4.00.00dev.exe—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or mute the thread.  

    @adinetoiu I have contacted the developer of jtessboxeditor, he stated that it might take time until we see an automated lstm trainer, until then, you must train manually.
secondly, the steps and examples are available in the Wiki along with some test box files.
Note: please edit your replies and leave only your replies, your adding unrequired information.
`From: chris <notifications@github.com` ......... delete that hello man, please can you send me the ara.traineddata so i can test it, i don't know how to train iOS tesseract 3.x to recognize arabic in a great way?
also is  tesseract 4 made for iOS , i didn't find an example for iPhone or iPad with tesseract 4, and also if there is one how can i update me old tesseract with the new one. thank you very much  Hi 
I am interested your OCR and quite impressive. I planning to use in VS2013 (web & windows applications). I saw the example VS2013 Soultions (Tesseract.ConsoleDemo & Tesseract.WebDemo) and working fine for plain tiff and it is not working PDF, also i want to read the attached pdf OCR? how to do ? where to start? please guide me.

[sample.pdf](https://github.com/tesseract-ocr/tesseract/files/58849/sample.pdf)

I am used VISUAL STUDIO 2013 FRAME WORK 4.5

thanks
Raja
  Signed-off-by: Stefan Weil sw@weilnetz.de
 Obviously VS does not support the POSIX function `dirname` and its header file `libgen.h`. I'll update the patch to use `_splitpath` (or is there a better alternative for Windows code?).
 VS does not know the `F_OK` needed for function `access`, so I need one more iteration which replaces that parameter by 0.
  when i run the **make** command ,but get errors follow 
#### the errors

``` sh
Making all in .
Making all in tessdata
Making all in configs
make[3]: Nothing to be done for `all'.
Making all in tessconfigs
make[3]: Nothing to be done for `all'.
make[3]: Nothing to be done for `all-am'.
Making all in doc
make[2]: Nothing to be done for `all'.
```
 @amitdo  Thanks for replying! but when i run (sudo make install) get the error

``` sh
tesseract  sudo make install
Password:
Making install in ccutil
 ../config/install-sh -c -d '/usr/local/include/tesseract'
 /usr/bin/install -c -m 644 basedir.h errcode.h fileerr.h genericvector.h helpers.h host.h memry.h ndminx.h params.h ocrclass.h platform.h serialis.h strngs.h tesscallback.h unichar.h unicharmap.h unicharset.h '/usr/local/include/tesseract'
Making install in viewer
make[2]: Nothing to be done for `install-data-am'.
Making install in cutil
make[2]: Nothing to be done for `install-data-am'.
Making install in opencl
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG -I../ccutil -I../ccstruct -I../ccmain  -I/usr/local/include -I/usr/local/include/leptonica -I/usr/local/Cellar/cairo/1.14.4/include/cairo -I/usr/local/Cellar/glib/2.46.2/include/glib-2.0 -I/usr/local/Cellar/glib/2.46.2/lib/glib-2.0/include -I/usr/local/opt/gettext/include -I/usr/local/Cellar/pixman/0.32.8/include/pixman-1 -I/usr/local/Cellar/fontconfig/2.11.1/include -I/usr/local/Cellar/freetype/2.6_1/include/freetype2 -I/usr/local/Cellar/libpng/1.6.19/include/libpng16  -g -O2 -std=c++11 -MT openclwrapper.lo -MD -MP -MF .deps/openclwrapper.Tpo -c -o openclwrapper.lo openclwrapper.cpp
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I../ccutil -I../ccstruct -I../ccmain -I/usr/local/include -I/usr/local/include/leptonica -I/usr/local/Cellar/cairo/1.14.4/include/cairo -I/usr/local/Cellar/glib/2.46.2/include/glib-2.0 -I/usr/local/Cellar/glib/2.46.2/lib/glib-2.0/include -I/usr/local/opt/gettext/include -I/usr/local/Cellar/pixman/0.32.8/include/pixman-1 -I/usr/local/Cellar/fontconfig/2.11.1/include -I/usr/local/Cellar/freetype/2.6_1/include/freetype2 -I/usr/local/Cellar/libpng/1.6.19/include/libpng16 -g -O2 -std=c++11 -MT openclwrapper.lo -MD -MP -MF .deps/openclwrapper.Tpo -c openclwrapper.cpp  -fno-common -DPIC -o .libs/openclwrapper.o
openclwrapper.cpp:16:10: fatal error: 'thresholder.h' file not found
#include "thresholder.h"
         ^
1 error generated.
make[1]: *** [openclwrapper.lo] Error 1
make: *** [install-recursive] Error 1
```
 @amitdo last, i install it with brew.thanks any way
  The man page for the unicharambigs file format only includes documentation on the v1 format, not the v2 format (and is missing a description of the first line which is used for version identification).

https://github.com/tesseract-ocr/tesseract/blob/master/doc/unicharambigs.5.asc
 https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract#the-unicharambigs-file

has info about both formats
 I think Ray had updated the documentation (couple years back??). From what
I understand from it unicharambigs file could be either in v1 format or v2
format.
- sent from my phone. excuse the brevity.

On 01-Sep-2016 12:38 AM, "zdenop" notifications@github.com wrote:

Which file use unicharambigs file v2?

 Thanks for checking langdata from 3.04.

Ray is the best person to answer whether v2 has been used/tested for any
languages.

Also, there was supposed to be a new release as per tutorial at DAS2016. Do
you know when that will be and what is included in it?
- sent from my phone. excuse the brevity.

 @zdenop Any update regarding 4.0 release? Thanks!
  Signed-off-by: Stefan Weil sw@weilnetz.de
 @amitdo: that was intentional, so more pull requests can follow.

No, I was just joking. I'm sure that there are more typos, but as I am not a native speaker,
I'm also sure that I won't find them all. :-)
 Ah, on a 2nd view I now see the typo.
  If https://github.com/loqu8/tesseract-vs2015 is placed parallel to the tesseract repo, you can use the vs2015 sln to compile tesseract in Visual Studio with giflib, libpng, libjpeg, libtiff, libwebp and zlib. Note that the solution will look for includes and lib in ../../../tesseract-vs2015/release rather than ../../../ like the VS2010 sln.
 -1. It's better to improve cmake build system rather than each solution per VS version.
  It has been mentioned before that tesseract struggles with small fonts. I'm seeing this with standard sized Chinese in Chrome. If the image is magnified 2x (with no increase in information, just scale up the png), the recognition works great. Is there a way to do font size detection and just auto-scale up? Perhaps this is an English vs Chinese issue internally, so that when recognizing Chinese fonts, the image has to be increased in size before processing. I am not too familiar with tesseract internals, but could someone advise on (1) automatic font size detection, and (2) where to scale things up if it is for Chinese? 
 Here's an actual sample:

(1) 100% font size screen cap from Chrome (Google News)
![orig](https://cloud.githubusercontent.com/assets/157766/11524501/21c2487e-9880-11e5-8caf-b1203b04adf2.png)

夜叉 鏖巴布韦迸行国
〈〈让中建友渲绽放出
不平FL的发展咸就y
""巴

(2) 1.5x
![1 5x](https://cloud.githubusercontent.com/assets/157766/11524541/58a5d3f6-9880-11e5-93d9-ccd9e6fc722d.png)

在对逞巴布韦迸行国
<<i上中津友谊绽放出
不平凡的发展成就'

习近平访犀巴

(3) 2x  - much much better (though still misses some chars...)
![2x](https://cloud.githubusercontent.com/assets/157766/11524549/68f085d0-9880-11e5-9df1-2b030a26f7eb.png)

在对逵巴布韦进行国
<<让中津友谊绽放出
不平凡的发展成戴，
逞评: 习近平访津巴
 Maybe it is possible to train with smaller fonts?
 10 pt screen resolution works perfectly for English. Is there a way to create a training set for lower resolution?
  Hi,
I use tesseract (Tesseract 3.02 on Windows 7) to process sets of scanned invoices issued by the same company (very similar to each other).
I've noticed that **_some of them are recognized properly and some not_**.
The **original paper documents are of very good quality** and so are the TIFF files (at least to me) - so I thought there should be no problem for tesseract to recognize them properly, but...

I have played a bit with the scanning parameters and produced different images of the same paper document that originally caused problems. 

Now I have two TIF files of the same paper invoice:
1. one that gives incorrect results (ex_bad.tif)
2. one that gives correct results (ex_good.tif)

and the **ex_diff.tif** showing which part did not get recognized properly.
I attach also the hOCR files produced for both TIFF files and tesseract configuration.
All the above mentioned files are however packed in one docx file :smiley: 

[Incosistency.docx](https://github.com/tesseract-ocr/tesseract/files/48291/Incosistency.docx)

Don't know if it is the same issue but looking at the line 26 in ex_bad.html one can find empty strings (I know it's been reported already but do not know if it was fixed):

``` html
     <span class='ocr_line' id='line_5' title="bbox 176 379 2119 464"><span class='ocrx_word' id='word_13' title="bbox 176 403 269 439"></span> <span class='ocrx_word' id='word_14' title="bbox 286 404 546 448"></span> <span class='ocrx_word' id='word_15' title="bbox 562 404 648 439"></span> <span class='ocrx_word' id='word_16' title="bbox 1357 379 1759 464"></span> <span class='ocrx_word' id='word_17' title="bbox 1773 379 2119 458"></span> 
     </span>
```

**I have also noticed that removing the picture from the top left corner of the first page of the invoice helps recognizing text properly.**

Is this a bug or simply 'a user education error'?
:smiley:

Thanks in advance for any kind of help and/or guidance here
Wojtek
 I have tried at the time of postinig the original issue but I was not allowed to upload zip file....
Hope this time will work...
[Issues.zip](https://github.com/tesseract-ocr/tesseract/files/76707/Issues.zip)
 I havent used tesseract in two years or so, but I recall as part of preprocessing, we had to first remove all images and do some denoising. That greatly improved things. 
  Commit 99110df75781c6907c84a3d23695a6900b933a97 improved the help text
in several aspects, but also introduced new inconsistencies which this
patch tries to fix.
- Align columns (this needed replacing tabs by spaces).
- Start explaining text with uppercase.
- Replace "the stdout" by "stdout.
- Small changes in help text for page segmentation modes.
- Split options in OCR options and single options
  (partially revert commit 99110df75781c6907c84a3d23695a6900b933a97).

In addition, whitespace characters at end of lines were removed.

Signed-off-by: Stefan Weil sw@weilnetz.de
 > Commit 99110df... introduced new inconsistencies which this
> patch tries to fix.
> - Start explaining text with uppercase.
> - Replace "the stdout" by "stdout.

It didn't introduce these inconsistencies. They were there before.
 @amitdo, I'm sorry, my commit text was not precise. Some of the issues which my patch tries to address existed before your patch. Should I update the patch with a modified commit message?

There remain more issues to be discussed, for example whether stdout instead of stderr would be better for the help text. You also raised the question about more entries for page segmentation mode.
 Hi Stefan,

> Should I update the patch with a modified commit message?

Yes please.

> whether stdout instead of stderr would be better for the help text.

I've noticed that too. I don't know why it's stderr right now.

> You also raised the question about more entries for page segmentation mode.

We need to publish them, IMHO.

> Split options in OCR options and single options (partially revert commit 99110df).

'list-langs' can be followed by 'tessdata-dir'.
'print-parameters' can be followed by -c option(s) which will change the output.
So why call them 'single options'?

I'm not really sure what is the right usage for 'print-parameters'.

Testing:

```
$tesseract --print-parameters | grep pageseg_mode
tessedit_pageseg_mode   6

$ tesseract --print-parameters -psm 1 | grep pageseg_mode
tessedit_pageseg_mode   6

$ tesseract --print-parameters -c tessedit_pageseg_mode=1 | grep pageseg_mode
tessedit_pageseg_mode   1

$ tesseract --print-parameters pdf | grep pageseg_mode
tessedit_pageseg_mode   6

$ tesseract nosuchfile stdout --print-parameters pdf | grep pageseg_mode
tessedit_pageseg_mode   1
```
 @amitdo, I think it is reasonable to split the options in two groups: one group for those options which are used in production to make OCR, one group for options which show information like help texts, version or supported parameters. The old help text called the 2nd ones 'single options', that's why my patch reverted to that title. Maybe there exists a better naming.
 > --print-parameters is option that list all tesseract parameters with its default values. This is useful if you would like to change tesseract behavior.

@zdenop, I knew that, of course.

What I meant was: Should other options followed by 'print-parameters' change the output of the command?

With my commit, the CL help message includes:

> Usage:
>   ...
>   tesseract --print-parameters [options...] [configfile...]

The current behaviour of the command line only partly match the above usage pattern. Only the '-c var=value' option changes the output.

I think this

> $ tesseract --print-parameters pdf | grep pageseg_mode

should produce

> tessedit_pageseg_mode 1

Just like:

> $ tesseract --print-parameters -c tessedit_pageseg_mode=1 | grep pageseg_mode
> tessedit_pageseg_mode   1

Strangly, this works right now

> tesseract nosuchfile stdout --print-parameters pdf | grep pageseg_mode
> tessedit_pageseg_mode   1
 > in case of 'single options': it was not expected (tested) their usage in combination with other options.

So, maybe the usage part of the help message should be changed accordingly?

>  tesseract --print-parameters
 @stweil, feel free to change it as you like, no objection.
 @stweil,

> Should I update the patch with a modified commit message?

On second thought - don't bother!
  I am trying to read serial number, bios version, dimm capacity and cpu type from a BIOS screen shot but cannot improve the results. I attached a zip file with the images.

These information are not words or sentences, and looks like tesseract is trying to give sense or forcing the info to all letters or to all numbers (if preceding a number force to a number). 

Below share my results to see if you know what settings or image pre processing I need to use to improve the results. 

I am using Tesseract 3.03 and ImageMagick 6.8.8-10 on a Fedora 21 OS.

screen shot:
![screen](https://cloud.githubusercontent.com/assets/4931834/11312205/05da2e7a-8f92-11e5-8d74-e6043fcf9d7f.jpg)

bios.jpg:
![bios](https://cloud.githubusercontent.com/assets/4931834/11312193/f78dd010-8f91-11e5-8c8a-5d36c1c1cee8.jpg)

bios-resize300.jpg:
![bios-resize300](https://cloud.githubusercontent.com/assets/4931834/11312222/151035c4-8f92-11e5-863d-aa187d55c585.jpg)

cpu.jpg:
![cpu](https://cloud.githubusercontent.com/assets/4931834/11312197/fc9e87de-8f91-11e5-978e-46c2bfe96e2e.jpg)

cpu-resize300.jpg:
![cpu-resize300](https://cloud.githubusercontent.com/assets/4931834/11312225/151f787c-8f92-11e5-9749-fdd02d924bf7.jpg)

cpu-threshold40.jpg:
![cpu-threshold40](https://cloud.githubusercontent.com/assets/4931834/11312223/15115f4e-8f92-11e5-88ce-a3abbc48d62d.jpg)

dimm.jpg:
![dimm](https://cloud.githubusercontent.com/assets/4931834/11312199/fee89c1e-8f91-11e5-98d4-200677f63a6c.jpg)

dimm-resize300.jpg:
![dimm-resize300](https://cloud.githubusercontent.com/assets/4931834/11312224/151e5d2a-8f92-11e5-9efd-b77363014f0d.jpg)

stn.jpg:
![stn](https://cloud.githubusercontent.com/assets/4931834/11312201/0171e1ca-8f92-11e5-9225-aa867039f7ae.jpg)

stn-resize300.jpg:
![stn-resize300](https://cloud.githubusercontent.com/assets/4931834/11312226/15203e10-8f92-11e5-8288-5da388909b78.jpg)

Thanks.

bios.jpg

command: 
tesseract bios.jpg -psm 8 stdout tessdata

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist A0123456789

expected:
A08

result:
A05

comments:
BAD RESULT

---

bios.jpg

command:
convert bios.jpg -resize 300% bios-resize300.jpg
tesseract bios-resize300.jpg -psm 8 stdout tessdata

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist A0123456789

expected:
A08

result:
908

comments:
Better results resizing 300% the original image, but still wrong. Made a lot of changes on size and adding threshold and still getting a 9 instead of A.

---

dimm.jpg

command:
tesseract dimm.jpg -psm 8 stdout tessdata

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist 0123456789MB

expected:
4096MB

result:
4036MB

comments:
BAD RESULTS

---

dimm.jpg

commands:
convert dimm.jpg -resize 300% dimm-resize300.jpg
tesseract dimm-resize300.jpg -psm 8 stdout tessdata

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist 0123456789MB

expected:
4096MB

result:
4096MB

comments:
GOOD RESULTS

---

stn.jpg

commands:
tesseract stn.jpg -psm 8 stdout tessdata 

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist BCDFGHJKLMNPQRSTVWXYZ0123456789

expected:
CDTL082

result:
CDTLGBZ

comments:
BAD RESULTS, appears that tesseract force all letters or all numbers.

---

stn.jpg

commands:
convert stn.jpg -resize 300% stn-resize300.jpg
tesseract stn-resize300.jpg -psm 8 stdout tessdata 

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist BCDFGHJKLMNPQRSTVWXYZ0123456789

expected:
CDTL082

result:
CDTLGBZ

comments:
BAD RESULTS, appears that tesseract force to all letters or to all numbers.

---

cpu.jpg

commands:
tesseract cpu.jpg -psm 7 stdout tessdata

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist BCDFGHJKLMNPQRSTVWXYZ0123456789@.

expected:
CPU G3260 @ 3.30GHz

result:
M BPH 63260 6 3.30912

comments:
BAD RESULTS

---

cpu.jpg

commands:
convert cpu.jpg -resize 300% cpu-resize300.jpg
tesseract cpu-resize300.jpg -psm 7 stdout tessdata 

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist BCDFGHJKLMNPQRSTVWXYZ0123456789@.

expected:
CPU G3260 @ 3.30GHz

result:
W CPLJ 83260 @ 3.30GHZ

comments:
Better results, but still wrong.

---

cpu.jpg

commands:
convert cpu.jpg -resize 300% cpu-resize300.jpg
convert cpu-resize300.jpg -threshold 40% cpu-threshold40.jpg
tesseract cpu-threshold40.jpg -psm 7 stdout tessdata

tessdata content:
load_system_dawg F
load_freq_dawg F
language_model_penalty_non_dict_word F
language_model_penalty_non_freq_dict_word F
tessedit_char_whitelist BCDFGHJKLMNPQRSTVWXYZ0123456789@.

expected:
CPU G3260 @ 3.30GHz

result:
F0 CPH 83260 @ 3.306HZ

comments:
Adding threshold still wrong, and looks like is better without threshold.
  The new pdf option to directly create a PDF with embedded text is awesome. Unfortunately, I haven't been able to figure out yet how to specify the page size (e.g. A4, letter, ...). Is that possible?
 Sorry, no. If the input image is A4 then the output PDF is A4. The design goal of Tesseract's PDF module is to not change anything about the image. If you want to modify page size, either change the input image or post process the output PDF. 
 This issue should be closed. (Working as intended)
 @jbreiden, how tesseract determines page size of the input image? The page size depends on DPI which tesseract has no information about. For example A5 (5.83 x 8.27 inch) with 300 dpi has resolution 1748 x 2480 pixels.
The problem is that when the input image to tesseract has 1748 x 2480 pixels, it outputs pdf file with page size 24.97 × 35.43 inch, not 5.83 x 8.27 inch.
Can you please reopen this issue or should I create a new issue?
  This is the failing test: (all locales, packages seem correctly installed).
For info, parsing english works fine.

```
% tesseract test.png test -lbul
Tesseract Open Source OCR Engine v3.04.00 with Leptonica

% cat test.txt
Ila mnpmm "mm npanHM Mama m m: m: m :3 mm mm. Ms M:

% locale -a | grep bg
bg_BG.utf8

% pacman -Qs tesseract-data-bul
local/tesseract-data-bul 3.04.00-1 (tesseract-data)
```

Also tried:
- `LANG=bg_BG.UTF-8 tesseract test.png test -lbul`
- a different bul traindata: https://code.google.com/p/tesseract-ocr/downloads/detail?name=bul.traineddata.gz
 test.png:

![test](https://cloud.githubusercontent.com/assets/52182/11091324/3871125e-8871-11e5-8f9d-0472f36b68b2.png)
 Try this:

> tesseract test.png test -l bul
 Ha, that's funny, I actually tried it like this the very first time but I had an error and thought that that caused it!

Works much better like this:
`tesseract test.png test -l bul`:
`Да извършва всякакви правни „щения пт на: им: и за мая см:-дка. пя „=`

Still not 100% accurate but I guess that's up to me/options to fix now?
 Suggestion: using `-lbul` should fail with an error
 The font in this image is quite small. You should try to rescale the image (x2).
Also try the option -psm 7
https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality

In general, the right place to ask questions is here:
https://groups.google.com/forum/?hl=en#!forum/tesseract-ocr
 I found out exactly what were the encountered issues. Here is a sum up:
- First I ran `tesseract test.png -l bul` which fails because it sees an option (`-l`) instead of `outputbase|stdout`; but it doesn't complain about a wrong argument so I thought it was because of the space between `-l` and `bul`
- Then I tried `tesseract test.png -lbul` which doesn't give errors because it wrongly thinks that the output file is `-lbul` and it uses the default `eng` data. Indeed `-lbul.txt` gets created
- And eventually: `tesseract test.png test -lbul` which creates `test.txt` and uses `eng` as default and simply discards `-lbul` which is nonsense to it
  The command tesseract seems to miss the decimal separator character if there is more than 7 digits in the decimal number : 
In the image below, tesseract detects 34056789 = not OK ! 
![bug_number1c](https://cloud.githubusercontent.com/assets/14107462/10996075/0e90e966-8482-11e5-9e8c-0f1289f250d0.png)
In the image below, tesseract detects 440.5678 => OK
![bug_number1c2](https://cloud.githubusercontent.com/assets/14107462/10996076/126ef0fa-8482-11e5-956a-ea61e87f5b99.png)
 With the latest snapshot in the git repo i get:
340.56789
 Ok I have recompiled with the tesseract-master.
And now, i got good result with 340.56789. Thanks...

But the problem is still there when i use more digits:
Example below is ok
![bug_number3a](https://cloud.githubusercontent.com/assets/14107462/11002130/3c4dc440-84ab-11e5-99fd-876e688f72bf.png)
Example below is returning 1234056789
![bug_number3b](https://cloud.githubusercontent.com/assets/14107462/11002155/58cd30b0-84ab-11e5-988c-7eab13438bee.png)
  This fixes clang compiler warnings like this one:

wordrec/gradechop.cpp:52:3: warning:
 'register' storage class specifier is deprecated [-Wdeprecated-register]

Signed-off-by: Stefan Weil sw@weilnetz.de
 @zdenop: Any good modern compiler should be able to assign CPU registers to local variables, and at least for gcc and clang I know that they do a very good job here. I assume that 'register' for local variables was deprecated because it no longer makes sense today. That's the reason why I suggest to use these modifications.

For function parameters, this is different. Therefore they are still supported.
 Extract from gcc documentation:

"Some developers use Local Register Variables in an attempt to improve gcc's allocation of registers, especially in large functions. In this case the register name is essentially a hint to the register allocator. While in some instances this can generate better code, improvements are subject to the whims of the allocator/optimizers. Since there are no guarantees that your improvements won't be lost, this usage of Local Register Variables is discouraged."
  Trying to build unicharset from my examples this is what is the content of unicharset
Doesn't look correct? Using tesseract 3.05 (and Ubuntu Linux 14.04)

head unicharset 
102
NULL 0 NULL 0
Joined 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0     # Joined [4a 6f 69 6e 65 64 ]
|Broken|0|1 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0    # Broken
A 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # A [41 ]
V 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # V [56 ]
C 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # C [43 ]
D 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # D [44 ]
E 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # E [45 ]
F 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0  # F [46 ]
 Running:
shapeclustering -F font_properties -U unicharset font.exp0.tr 

Reading font.exp0.tr ...
Building master shape table
Computing shape distances...
Stopped with 0 merged, min dist 999.000000
Computing shape distances...
Stopped with 0 merged, min dist 999.000000
Computing shape distances...
Stopped with 0 merged, min dist 999.000000
Computing shape distances... 0
Stopped with 0 merged, min dist 999.000000
Computing shape distances... 0
Stopped with 0 merged, min dist 999.000000
....
Stopped with 0 merged, min dist 999.000000
Computing shape distances... 0
Stopped withBad properties for index 3, char A: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 4, char B: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 5, char C: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 6, char D: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 7, char E: 0,255 0,255 0,0 0,0 0,0
...
Bad properties for index 101, char Ã¶: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 102, char Ã¥: 0,255 0,255 0,0 0,0 0,0
 0 merged, min dist 999.000000
Computing shape distances... 0
Stopped with 0 merged, min dist 999.000000
Computing shape distances... 0
Stopped with 0
....
Computing shape distances... 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93
Distance = 0.013333: Stopped with 1 merged, min dist 0.025316
Master shape_table:Number of shapes = 93 max unichars = 2 number with multiple unichars = 1
 And ...
mftraining -F font_properties -U unicharset -O font.unicharset font.exp0.tr 

Read shape table shapetable of 93 shapes
Reading font.exp0.tr ...
Bad properties for index 3, char A: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 4, char B: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 5, char C: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 6, char D: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 7, char E: 0,255 0,255 0,0 0,0 0,0
....
Bad properties for index 102, char Ã¥: 0,255 0,255 0,0 0,0 0,0
Warning: no protos/configs for sh0090 in CreateIntTemplates()
Warning: no protos/configs for sh0091 in CreateIntTemplates()
Warning: no protos/configs for sh0092 in CreateIntTemplates()
Done!
 I'm having a similar issue, running tesseract 3.04, and on Ubuntu 15.10. My unicharset after having trained on a long text file and using unicharset_extractor has the above mentioned "Joined" and "Broken" flags, followed by all bogus rows. In addition, whenever I then use another training tool, like shapeclustering, I get the bad properties warnings for just about every possible character present. 

Is there any idea as to what could be causing this? I'm using a custom font, but with english words. 
 Same problem here. Running tesseract 3.04 on fedora 23
 I have the same problem for Farsi language (It is right to left). Using 3.04 on Ubuntu 15

```
78
NULL 0 NULL 0
Joined 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # Joined [4a 6f 69 6e 65 64 ]
|Broken|0|1 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #  # Broken
و 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # و [648 ]
ه 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ه [647 ]
ک 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ک [6a9 ]
ن 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ن [646 ]
ی 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ی [6cc ]
ا 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ا [627 ]
خ 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # خ [62e ]
س 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # س [633 ]
ع 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ع [639 ]
ض 0 0,255,0,255,0,0,0,0,0,0 NULL 0 0 0 #   # ض [636 ]
```

Output:

```
Reading fas.BMitra.exp0.tr ...
Bad properties for index 3, char و: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 4, char ه: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 5, char ک: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 6, char ن: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 7, char ی: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 8, char ا: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 9, char خ: 0,255 0,255 0,0 0,0 0,0
Bad properties for index 10, char س: 0,255 0,255 0,0 0,0 0,0
```
 same on 3.04
tried manual method, no difference
 @jmokoistinen I have tried every step in that file, and keep getting a buggy unicharset_extractor output. I'm also using english letters, and my file has 14000 words that cover all possible letter placement in the system I'm trying to train on. What should I try next?
 I suggest you to use the `set_unicharset_properties` script used to set some properties to your generated unicharset file or get unicharset file listed in [tesseract train repo](https://github.com/tesseract-ocr/langdata)
both worked for me
 Did anyone manage to resolve this issue? I'm trying to train a new font and I'm getting the bad properties error even when if use the eng,unicharset that came with the trained data. The error is for the tilda (~) character only.
Running on OS X.
 @wxlie see the post above or you can use the script listed in my repo
 Same issue running tesseract 3.04.01 on Cygwin Win10.
 Are you trainiing using tesstrain.sh?

See Phase UP : Generate (U)nicharset and (P)roperties file. in tesstrain_utils.sh

```
phase_UP_generate_unicharset() {
tlog "\n=== Phase UP: Generating unicharset and unichar properties files ==="

local box_files=$(ls ${TRAINING_DIR}/*.box)
run_command unicharset_extractor -D "${TRAINING_DIR}/" ${box_files}
local outfile=${TRAINING_DIR}/unicharset
UNICHARSET_FILE="${TRAINING_DIR}/${LANG_CODE}.unicharset"
check_file_readable ${outfile}
mv ${outfile} ${UNICHARSET_FILE}

XHEIGHTS_FILE="${TRAINING_DIR}/${LANG_CODE}.xheights"
check_file_readable ${UNICHARSET_FILE}
run_command set_unicharset_properties \
    -U ${UNICHARSET_FILE} -O ${UNICHARSET_FILE} -X ${XHEIGHTS_FILE} \
    --script_dir=${LANGDATA_ROOT}
check_file_readable ${XHEIGHTS_FILE}
}
```
 @mustafashujaie - Which langdata are you using?

https://github.com/tesseract-ocr/langdata/tree/master/fas
or
https://github.com/tesseract-ocr/langdata/tree/master/per
  @Wikinaut Most of those warnings also occur in my builds and are less interesting (like -Wsign-compare which can be ignored IMHO), but there are also some warnings which need further investigations (-Warray-bounds).
  Hello, I'm working on adding symbol level bounding box information in hOCR output, in order to be able to find the position of individual symbols inside words. Is this something that you would like to integrate? I've only had a cursory glance on the hOCR reference, but it doesn't seem to be violate anything. Output would look like:

```
    <span class="ocrx_word" dir="ltr" id="word_1_26" lang="eng" title=
    "bbox 102 194 177 224; x_wconf 90" xmlns=
    "http://www.w3.org/1999/xhtml"><strong><span class="ocrx_symbol" id=
    "symbol_1_26_81" title=
    "bbox 102 200 117 224; x_wconf 92">q</span><span class="ocrx_symbol" id=
    "symbol_1_26_82" title=
    "bbox 121 200 135 218; x_wconf 90">u</span><span class="ocrx_symbol" id=
    "symbol_1_26_83" title=
    "bbox 140 194 143 218; x_wconf 97">i</span><span class="ocrx_symbol" id=
    "symbol_1_26_84" title=
    "bbox 146 200 161 218; x_wconf 92">c</span><span class="ocrx_symbol" id=
    "symbol_1_26_85" title=
    "bbox 163 194 177 218; x_wconf 96">k</span></strong></span>
```
 Speaking only for myself. It's soooooo expensive. That's why I don't bother in PDF output.
 If this were to be contemplated, it should be controlled by a config variable with defaults to false, similar to `hocr_font_info`.  I'd be curious about the use case though. If hOCR is being used as a format to connect two programs, it seems like a very bulky & low fidelity channel. Wouldn't just calling the Tess result iterator yourself give you better control at less cost?
  I have created java web controller with tesseract.
If I use windows libraries - no errors, but in linux sometimes I get a fatal error

> Problematic frame:
> [libtesseract.so+0x22a730]  tesseract::HistogramRect(unsigned char const_, int, int, int, int, int, int, int_)+0x70
> 
> Stack: [0x00007f2d040d2000,0x00007f2d041d3000],  sp=0x00007f2d041cdf20,  free space=1007k
> Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)
> C  [libtesseract.so+0x22a730]  tesseract::HistogramRect(unsigned char const_, int, int, int, int, int, int, int_)+0x70
> 
> Java frames: (J=compiled Java code, j=interpreted, Vv=VM code)
> j  net.sourceforge.tess4j.TessAPI1.TessBaseAPIGetUTF8Text(Lnet/sourceforge/tess4j/ITessAPI$TessBaseAPI;)Lcom/sun/jna/Pointer;+0
> j  net.sourceforge.tess4j.Tesseract1.getOCRText(Ljava/lang/String;I)Ljava/lang/String;+43
> j  net.sourceforge.tess4j.Tesseract1.doOCR(Ljava/util/List;Ljava/lang/String;Ljava/awt/Rectangle;)Ljava/lang/String;+69
> j  net.sourceforge.tess4j.Tesseract1.doOCR(Ljava/util/List;Ljava/awt/Rectangle;)Ljava/lang/String;+4
> j  net.sourceforge.tess4j.Tesseract1.doOCR(Ljava/awt/image/BufferedImage;Ljava/awt/Rectangle;)Ljava/lang/String;+6
> j  net.sourceforge.tess4j.Tesseract1.doOCR(Ljava/awt/image/BufferedImage;)Ljava/lang/String;+3
 I'm not sure that an issue with java wrapper.
But ok. I'll take a look at java wrapper and how it works with pointers in HistogramRect.
Thanks
  I had the same problem, and discovered the cause by looking in the `config.log` file. I see a lot of people having this problem, so might be a good idea to add a check.
 I'm pretty sure it was this:

```
./configure:17287: g++ -o conftest -I/Usr/local/include/leptonica -L/usr/local/lib conftest.cpp -llept >&5
./configure: line 2040: g++ command not found
```
 Perhaps also update the wiki, installations instructions and the FAQ for this error.
   @zdenop, FYI

Travis failed in linux build only. It had problems downloading cmake.
The code does compile in my machine, which is ubuntu 14.04 64bit.
I also tested the code. Everything seems fine!

Any questions?
 If I'm right the build will run again when you close this PR and reopen it.
 Thanks @ArjanSchouten.
It failed twice to download cmake: yesterday (~18 hours ago) and today (~2 hours ago).
So it might fail again...
 @zdenop
I reorganised this PR. It has only one commit now.
 The Travis problem should be fixed now (see #143), so please start a new try. 
 @stweil, @zdenop
Done.
 @zdenop Please, commit or comment.
 @amitdo, I'm afraid that your patch needs to be rebased on latest git master. One of my patches fixed a bug in main and was committed. This fix is still missing in your code, so there will be a merge conflict.
 @zdenop, I've updated the code. Is it OK for you now?
 @amitdo, I'afraid that the new function SetVariablesFromCLArgs did revert the bug fix #154.
 @stweil, sorry. fixed.
 If you run "tesseract" or "tesseract --help" you get this.

```
Usage:
  tesseract --help | --help-psm | --version
  tesseract --list-langs [--tessdata-dir PATH]
  tesseract --print-parameters [options...] [configfile...]
  tesseract imagename|stdin outputbase|stdout [options...] [configfile...]


Options:
  -h, --help    Show this help message.
  --help-psm    Show Page Segmentation Modes.
  -v,  --version    Show version information.

  --list-langs  list available languages for tesseract engine.

  --tessdata-dir PATH   specify the location of tessdata path.
  --print-parameters    print tesseract parameters to the stdout.
  --user-words PATH specify the location of user words file.
  --user-patterns PATH  specify the location of user patterns file.
  -l LANG[+LANG]    specify language(s) used for OCR.
  -c VAR=VALUE  set value for config variables.
            Multiple -c arguments are allowed.
  -psm NUM  specify page segmentation mode.
  NOTE: The options above must occur before any configfile.

Page Segmentation Modes:
  0    Orientation and script detection (OSD) only.
  1    Automatic page segmentation with OSD.
  2    Automatic page segmentation, but no OSD, or OCR
  3    Fully automatic page segmentation, but no OSD. (Default)
  4    Assume a single column of text of variable sizes.
  5    Assume a single uniform block of vertically aligned text.
  6    Assume a single uniform block of text.
  7    Treat the image as a single text line.
  8    Treat the image as a single word.
  9    Treat the image as a single word in a circle.
 10    Treat the image as a single character.
```

Original:

```
Usage:
  tesseract imagename|stdin outputbase|stdout [options...] [configfile...]

OCR options:
  --tessdata-dir /path  specify the location of tessdata path
  --user-words /path/to/file    specify the location of user words file
  --user-patterns /path/to/file specify the location of user patterns file
  -l lang[+lang]    specify language(s) used for OCR
  -c configvar=value    set value for control parameter.
            Multiple -c arguments are allowed.
  -psm pagesegmode  specify page segmentation mode.
These options must occur before any configfile.

pagesegmode values are:
  0 = Orientation and script detection (OSD) only.
  1 = Automatic page segmentation with OSD.
  2 = Automatic page segmentation, but no OSD, or OCR
  3 = Fully automatic page segmentation, but no OSD. (Default)
  4 = Assume a single column of text of variable sizes.
  5 = Assume a single uniform block of vertically aligned text.
  6 = Assume a single uniform block of text.
  7 = Treat the image as a single text line.
  8 = Treat the image as a single word.
  9 = Treat the image as a single word in a circle.
  10 = Treat the image as a single character.

Single options:
  -v --version: version info
  --list-langs: list available languages for tesseract engine. Can be used with --tessdata-dir.
  --print-parameters: print tesseract parameters to the stdout.
```

So, what do you mean by 'whole help'?

'as default (as today)' - does it mean you want the help message to look exactly like as it looks now?  

Please clarify.
  Works for single page and multi-page.
 test:

```
convert -rotate 270 eurotext.tif eurotext270.tif

echo "/path/to/eurotext.tif
/path/to/eurotext270.tif" > mp-eurotext

tesseract eurotext.tif eurotext -l osd -psm 0

tesseract eurotext270.tif eurotext270 -l osd -psm 0

cat eurotext270.tif | tesseract stdin stdout -l osd -psm 0

tesseract mp-eurotext mp-eurotext -l osd -psm 0
```
 :+1:
  Hi folks,

Having trouble getting a working OpenCL build. First run in a new working directory gets upset that there's no opencl_profile_devices.dat:

axfelix@shoebox:~/Desktop$ tesseract test.png out pdf
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performing profiling.

[DS] Device: "GeForce GTX TITAN X" (OpenCL) evaluation...
[OD] write binary[kernel-GeForce_GTX_TITAN_X.bin] succesfully
[DS] Device: "GeForce GTX TITAN X" (OpenCL) evaluated
[DS]          composeRGBPixel: 0.022978 (w=1.2)
[DS]            HistogramRect: 0.012700 (w=2.4)
[DS]       ThresholdRectToPix: 0.010093 (w=4.5)
[DS]        getLineMasksMorph: 0.004402 (w=5.0)
[DS]                    Score: 0.125484

[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
[DS]          composeRGBPixel: 0.018301 (w=1.2)
[DS]            HistogramRect: 0.060059 (w=2.4)
[DS]       ThresholdRectToPix: 0.016802 (w=4.5)
[DS]        getLineMasksMorph: 0.110437 (w=5.0)
[DS]                    Score: 0.793896
[DS] Scores written to file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:GeForce GTX TITAN X score is 0.125484
[DS] Device[2] 0:(null) score is 0.793896
[DS] Selected Device[1]: "GeForce GTX TITAN X" (OpenCL)
OpenCL error code is -38 at   when clSetKernelArg imageBuffer .
OpenCL error code is -38 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -38 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -38 at   when clSetKernelArg histogramBuffer .
OpenCL error code is -52 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -52 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -38 at   when clSetKernelArg imageBuffer .
OpenCL error code is -38 at   when clSetKernelArg thresholdsBuffer .
OpenCL error code is -38 at   when clSetKernelArg hiValuesBuffer .
OpenCL error code is -38 at   when clSetKernelArg pixThBuffer .
OpenCL error code is -52 at   when clEnqueueNDRangeKernel kernel_ThresholdRectToPix .
Setting return value to -1
OpenCL error code is -38 at   when clSetKernelArg imageBuffer .
OpenCL error code is -38 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -38 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -38 at   when clSetKernelArg histogramBuffer .
OpenCL error code is -52 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -52 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .

After that, it works (while throwing issues like Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box) but the output is basically junk. Did I screw something up when compiling?
 I'm seeing something very similar. First time I run Tesseract after deleting tesseract_opencl_profile_devices.dat, I get the following:

****************_START**_****************
-bash-4.2$ tesseract ESub.png ESubPng
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performing profiling.

[DS] Device: "Tesla K40c" (OpenCL) evaluation...
OpenCL error code is -44 at   when clCreateKernel .
OpenCL error code is -48 at   when clSetKernelArg .
OpenCL error code is -48 at   when clSetKernelArg .
OpenCL error code is -48 at   when clSetKernelArg .
OpenCL error code is -48 at   when clSetKernelArg .
OpenCL error code is -48 at   when clSetKernelArg .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel .
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectAllChannels .
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg numPixels .
OpenCL error code is -48 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -48 at   when clSetKernelArg histogramBuffer .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -44 at   when clCreateKernel kernel_ThresholdRectToPix .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg height .
OpenCL error code is -48 at   when clSetKernelArg width .
OpenCL error code is -48 at   when clSetKernelArg wpl .
OpenCL error code is -48 at   when clSetKernelArg thresholdsBuffer .
OpenCL error code is -48 at   when clSetKernelArg hiValuesBuffer .
OpenCL error code is -48 at   when clSetKernelArg pixThBuffer .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_ThresholdRectToPix .
[DS] Device: "Tesla K40c" (OpenCL) evaluated
[DS]          composeRGBPixel: 0.022510 (w=1.2)
[DS]            HistogramRect: 0.006130 (w=2.4)
[DS]       ThresholdRectToPix: 0.005528 (w=4.5)
[DS]        getLineMasksMorph: 0.007509 (w=5.0)
[DS]                    Score: 0.104147

[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
[DS]          composeRGBPixel: 0.029208 (w=1.2)
[DS]            HistogramRect: 0.108206 (w=2.4)
[DS]       ThresholdRectToPix: 0.032306 (w=4.5)
[DS]        getLineMasksMorph: 0.200906 (w=5.0)
[DS]                    Score: 1.444651
[DS] Scores written to file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Tesla K40c score is 0.104147
[DS] Device[2] 0:(null) score is 1.444651
[DS] Selected Device[1]: "Tesla K40c" (OpenCL)
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectOneChannel .
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectOneChannelReduction .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg numPixels .
OpenCL error code is -48 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -48 at   when clSetKernelArg histogramBuffer .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -44 at   when clCreateKernel kernel_ThresholdRectToPix_OneChan .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg height .
OpenCL error code is -48 at   when clSetKernelArg width .
OpenCL error code is -48 at   when clSetKernelArg wpl .
OpenCL error code is -48 at   when clSetKernelArg thresholdsBuffer .
OpenCL error code is -48 at   when clSetKernelArg hiValuesBuffer .
OpenCL error code is -48 at   when clSetKernelArg pixThBuffer .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_ThresholdRectToPix .
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectOneChannel .
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectOneChannelReduction .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg numPixels .
OpenCL error code is -48 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
OpenCL error code is -48 at   when clSetKernelArg tmpHistogramBuffer .
OpenCL error code is -48 at   when clSetKernelArg histogramBuffer .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -48 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
-bash-4.2$ 

***************_STOP**_***********************

Running after that I get:

***************_START**_***********************
-bash-4.2$ tesseract ESub.png ESubPng
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
[DS] Profile read from file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Tesla K40c score is 0.104147
[DS] Device[2] 0:(null) score is 1.444651
[DS] Selected Device[1]: "Tesla K40c" (OpenCL)
-bash-4.2$ 

**************_STOP**_***********************

This creates the txt file, but it's just junk, maybe a few random characters. For a long time I was also seeing the 'Error in boxClipToRectangle: box outside rectangle' sort of errors that axfelix was seeing.

If I run it with the CPU device like this:

TESSERACT_OPENCL_DEVICE=2 tesseract ESub.png ESubPng

...it works perfectly. Great OCR output.

I have done everything I can imagine, including rebuilding Tesseract several times, using jpg, png and tif input files and rebuilding Leptonica. The nvidia drivers are the latest and OpenCL is the latest.

Any ideas?
 Still working on the problem. Here's some information that will hopefully make it easier for someone to solve before I spend another day tracking it down. 

I have two test cases using the same source file. Doesn't matter if the source is png or tif, same bad results. Tesseract correctly identifies that I have a Tesla K40c as device 1. The CPU is device 2. The call I'm making is either:
TESSERACT_OPENCL_DEVICE=1 tesseract ESub.png Esub -l enm //GPU
or
TESSERACT_OPENCL_DEVICE=2 tesseract ESub.png Esub -l enm //CPU

In the file baseapi.cpp in function TessBaseAPI::ProcessPage() I put in code to save the image before and after the call to GetThresholdedImage() like so:

```
pixWrite("tessinputBEFORE.tif", pix, IFF_TIFF_G4);
Pix* page_pix = GetThresholdedImage();
pixWrite("tessinputAFTER.tif", page_pix, IFF_TIFF_G4);
```

In the CPU version both before and after images look correct, showing the same text and formatting.

In the GPU OpenCL version 'before' is fine, but the 'after' version is seriously sheared when the source image has non-binary dimensions.  It looks like the pitch is being miscalculated. The source image was 1721 x 1238 pixels. In this case the OCR failed completely of course.

On an educated hunch I resized the the same image to 2048 x 1024. Now the shearing is gone, The characters in the image are somewhat recognizable. There is still a problem, the letters are all munged, almost like letters are being overlaid on top of each other or something. I will send the two bad output images if you tell me where. 
 Here you go...

Original source image 1721 x 1238:

![esub](https://cloud.githubusercontent.com/assets/394707/11664244/9a024432-9dae-11e5-9b87-76ca9b54c18e.png)

Result when source image resized to 2048 x 1024 results:

![tessinputafter](https://cloud.githubusercontent.com/assets/394707/11664207/6fbdcbe2-9dae-11e5-981e-92d50810a4f3.png)
 Sheared OpenCL output with odd-sized source image.

![skewedopenclodddims](https://cloud.githubusercontent.com/assets/394707/11664500/25f7c0ba-9db0-11e5-8269-5b6f83f67c20.png)
 I swear I've seen this particular image corruption before, when I was working on the pdf output module. I wish I could remember what it was.
 Anything else that can be done to help debug? I have a vested interest in getting a working OpenCL build before the end of January...
 I speculate we had a Leptonica bug, fixed it, but the fix never got propagated to the OpenCL-ified mini-fork of Leptonica that sits inside Tesseract. I think the way to go is look inside the thresholding call and keep comparing the CPU vs GPU to help isolate where things go different. It's also helpful to look at all data in the pix struct before/after/cpu/gpu to understand better what went wrong.

``` c
struct Pix
{
    l_uint32             w;           /* width in pixels                   */
    l_uint32             h;           /* height in pixels                  */
    l_uint32             d;           /* depth in bits (bpp)               */
    l_uint32             spp;         /* number of samples per pixel       */
    l_uint32             wpl;         /* 32-bit words/line                 */
    l_uint32             refcount;    /* reference count (1 if no clones)  */
    l_int32              xres;        /* image res (ppi) in x direction    */
                                      /* (use 0 if unknown)                */
    l_int32              yres;        /* image res (ppi) in y direction    */
                                      /* (use 0 if unknown)                */
    l_int32              informat;    /* input file format, IFF_*          */
    l_int32              special;     /* special instructions for I/O, etc */
    char                *text;        /* text string associated with pix   */
    struct PixColormap  *colormap;    /* colormap (may be null)            */
    l_uint32            *data;        /* the image data                    */
};
```

I don't know/remember what this code path is trying to do. Seems odd that
we'd be writing an image to a file unless this was a pure debug path. What happens
if you comment out the thresholding call? (go ahead and comment out lines 1227 to 1232 inclusive)

https://github.com/tesseract-ocr/tesseract/blob/c53add706e7853c8ea9986a87aebb465f29173bd/api/baseapi.cpp#L1230
 Yeah, that sure looks like a debug path. New theory is OpenCL turns on some some debugging, which activates faulty debugging code that messes everything up.
 Separate experiment, swap:

pixWrite("tessinputAFTER.tif", page_pix, IFF_TIFF_G4);

with 

pixWrite("tessinputAFTER.png", page_pix, IFF_PNG);

just to make sure we're not having trouble with writing out your debug image.
I can imagine weird problems if the depth is not 1 bit per pixel and we try
to write out g4 tiff.
 And finally, find the place where the image is first read into Tesseeract and turned into a Pix. See if we already have corruption at that point.
 I can't debug this myself. I still get a segfault on my computer when trying to use OpenCL as per issue #53 . Will be travelling for the rest of the month. Good luck and sorry.
 PR #475 fixes an error with OpenCL which results in these error message:

```
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectAllChannels .
OpenCL error code is -44 at   when clCreateKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -48 at   when clSetKernelArg imageBuffer .
```

Maybe it is related to this issue, too.
  i can't build the source with  vs2010,  can't find the file "allheaders.h" .  the version is tesseract-3.04.00
 this repository can't find the file "allheaders.h"
  https://drive.google.com/folderview?id=0B7l10Bj_LprhQnpSRkpGMGV2eE0&usp

There is an installer on the old Google code page from 2012.
 Does this mean that the compiled installer will be added to the Github project, or the  links will be updated/removed to reflect that there is no longer a Windows installer provided?  It is mentioned in the README.MD file, as well as the Wiki pages:

https://github.com/tesseract-ocr/tesseract/wiki
https://github.com/tesseract-ocr/tesseract/wiki/Downloads
  test:

```
tesseract eurotext.tif eurotext -l osd -psm 0
```
 that was quick! :-)
  3~5 sec is too long I think.Can we Improve the performance？
I use ubuntu15.04 tesseract 3.03
  `tesseract scan.tif filename` This command is giving empty text file. 
But this `tesseract scan.tif filename pdf` is giving correct pdf file. What can be the issue ? 
 try `tesseract scan.tif filename -psm 1`
  See

http://stackoverflow.com/q/33268289/2561126
  I'm spawning `tesseract` subprocesses for a project I'm working on and it's a bit annoying to see its banner on every invocation in the error log.  Redirecting stderr to `/dev/null` isn't an option as that would hide actual errors.

While the sources tell me redirecting stdout to the target file would hide it, I believe it would be better to have something like OpenSSH's `-q`.  Would that be an option?

I'd alternatively support dropping the banner entirely as the essential information is already given in `tesseract --version`.
 Thanks, works here as well.
  I have downloaded the sources and written the samples codes, just change the language 'eng' to 'chi_sim'. The traindata 'chi_sim' has been copied to \tessdata directory same with eng.traindata.

When I complie and start the sample, a error 'read_params_file: parameter not found: allow_blob_division' happens. But it works well with language 'eng'. Does anyone know how to resove it ?

Thanks a lot.
  when i run tesseract with opencl enabled over a multipage tiff it does not uses the gpu at all, even if it says its doeing so. the gpu is an ati 7770 
git commit # is 0d61f0c05a93a4d5aa09a9ec74d7cf7a1e51a9fa , Sep 15 09:32:54 2015

stdout from tesseract : 

Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
[DS] Profile read from file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Capeverde score is 0.157605
[DS] Device[2] 1:Intel(R) Core(TM) i7-2600 CPU @ 3.40GHz score is 0.866140
[DS] Device[3] 0:(null) score is 0.820505
[DS] Selected Device[1]: "Capeverde" (OpenCL)
Page 1
.... etc

as you can see it does start working (Page 1) and eventually the output is correct, ( and even says he is using the gpu  .. "Selected Device[1]: "Capeverde" (OpenCL)" ) but radeontop shows no activity ( tested it with cl-demo from Andreas Klöckner , gpu can be used in this system ) 
if i use the cpu (run it as a normal user without privileges to access the gpu ) then it takes the same amount of time.

one strange issue is that the first time tesseract is run and benchmarks the available devices (creating  tesseract_opencl_profile_devices.dat ) , it segfault, the  tesseract_opencl_profile_devices.dat does gets done and the next time it runs fine. 
  while trying to autogen, i got the following errors.

<pre>
Makefile.am: error: required file './README' not found
api/Makefile.am:65: warning: source file '$(top_srcdir)/api/tesseractmain.cpp' is in a subdirectory,
api/Makefile.am:65: but option 'subdir-objects' is disabled
automake: warning: possible forward-incompatibility.
automake: At least a source file is in a subdirectory, but the 'subdir-objects'
automake: automake option hasn't been enabled.  For now, the corresponding output
automake: object file(s) will be placed in the top-level directory.  However,
automake: this behaviour will change in future Automake versions: they will
automake: unconditionally cause object files to be placed in the same subdirectory
automake: of the corresponding sources.
automake: You are advised to start using 'subdir-objects' option throughout your
automake: project, to avoid future incompatibilities.
api/Makefile.am: installing 'config/depcomp'
ccutil/Makefile.am:53: warning: source file '../vs2008/port/strtok_r.cpp' is in a subdirectory,
ccutil/Makefile.am:53: but option 'subdir-objects' is disabled

  Something went wrong, bailing out!
</pre>


How can I make it?
Cheers,
 i suspected that I had no tesseract.
Does the autogen have to use tesseract? If so, I will firstly install it.
 oh sorry about my heavy head due to a whole day of work :(

I did run autogen under directory of tesseract-ocr, but got the error message mentioned above.

## FYI

i downloaded the source from google code (of version 3.02.02).
unpack it under mac os 10.10, 
1. cd to tesserac-ocr
2. run autogen 
3. error for libtoolize, error for subdir-objects
4. change ibtoolize to glibtoolize
5. run autogen again
6. error for subdir-objects 

## here below the full log and version of glibtool, aclocal and automake:
- glibtool
  
  <pre>
  glibtool --version
  glibtool (GNU libtool) 2.4.6
  Written by Gordon Matzigkeit, 1996
  Copyright (C) 2014 Free Software Foundation, Inc.
  This is free software; see the source for copying conditions. 
  There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
  </pre>
- aclocal
  
  <pre>
  aclocal --version
  aclocal (GNU automake) 1.15
  Copyright (C) 2014 Free Software Foundation, Inc.
  License GPLv2+: GNU GPL version 2 or later <http://gnu.org/licenses/gpl-2.0.html>
  This is free software: you are free to change and redistribute it.
  There is NO WARRANTY, to the extent permitted by law.
  Written by Tom Tromey <tromey@redhat.com>  Alexandre Duret-Lutz <adl@gnu.org>.
  </pre>
- automake
  
  <pre>
  automake --version
  automake (GNU automake) 1.15
  Copyright (C) 2014 Free Software Foundation, Inc.
  License GPLv2+: GNU GPL version 2 or later <http://gnu.org/licenses/gpl-2.0.html>
  This is free software: you are free to change and redistribute it.
  There is NO WARRANTY, to the extent permitted by law.
  Written by Tom Tromey <tromey@redhat.com> and Alexandre Duret-Lutz <adl@gnu.org>.
  </pre>

## error
- autogen
  <pre>
  ./autogen.sh 
  Running aclocal
  Running libtoolize
  glibtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, 'config'.
  glibtoolize: copying file 'config/ltmain.sh'
  glibtoolize: putting macros in AC_CONFIG_MACRO_DIRS, 'm4'.
  glibtoolize: copying file 'm4/libtool.m4'
  glibtoolize: copying file 'm4/ltoptions.m4'
  glibtoolize: copying file 'm4/ltsugar.m4'
  glibtoolize: copying file 'm4/ltversion.m4'
  glibtoolize: copying file 'm4/lt~obsolete.m4'
  Running autoheader
  Running automake --add-missing --copy
  configure.ac:215: installing 'config/compile'
  configure.ac:225: installing 'config/missing'
  Makefile.am: error: required file './README' not found
  api/Makefile.am:65: warning: source file '$(top_srcdir)/api/tesseractmain.cpp' is in a subdirectory,
  api/Makefile.am:65: but option 'subdir-objects' is disabled
  automake: warning: possible forward-incompatibility.
  automake: At least a source file is in a subdirectory, but the 'subdir-objects'
  automake: automake option hasn't been enabled.  For now, the corresponding output
  automake: object file(s) will be placed in the top-level directory.  However,
  automake: this behaviour will change in future Automake versions: they will
  automake: unconditionally cause object files to be placed in the same subdirectory
  automake: of the corresponding sources.
  automake: You are advised to start using 'subdir-objects' option throughout your
  automake: project, to avoid future incompatibilities.
  api/Makefile.am: installing 'config/depcomp'
  ccutil/Makefile.am:53: warning: source file '../vs2008/port/strtok_r.cpp' is in a subdirectory,
  ccutil/Makefile.am:53: but option 'subdir-objects' is disabled
  
  Something went wrong, bailing out!

</pre>

Hope these will help.
 ok let me do it now/

but i thought the error was dependent of the configs of Makefile, not the project itself.
 new version from github worked now. 
thank you.
  At first test it compiled fine with this code:

```
TessBaseAPI tess;
tess.Init(NULL, "eng", tesseract::OEM_DEFAULT);
Pix* img = pixRead("C:\\Users\\Paul\\Pictures\\phototest.tif");
```

But then, I added this line

   tess.SetImage(img);

 And it won't compile with error:

error LNK2019: unresolved external symbol "public: void __cdecl tesseract::TessBaseAPI::SetImage(struct Pix const *)" (?SetImage@TessBaseAPI@tesseract@@QEAAXPEBUPix@@@Z) referenced in function main

I have VS 2013, Windows 8.1 64 bit both. Compiled both tesseract and leptonica for x64 system, included everything, but still it doesn't want to work correctly.

Hope for your help. Paul.
 Looks like you forgot to link a library. Have you double checked all your depentencies?
 dependencies sorry 
 Hello, peirick.
I believe i did not, as far as i know.
I've included those 3 libs: 
libtesseract304d.lib
liblept171d.lib
tesseractd.lib
 zdenop,
Yes, i've tried. Unfortunatly it still gives the same error.
Tried to disable tesseractd.lib (have no idea what's this).
 Maybe have a look at the repository at https://github.com/peirick/leptonica you will find a build_tesseract.bat. 
  Link to wiki ReadMe points to the same markdown file.
  I have a project similar to recaptcha where I need humans to type words instead of computer ocr. Is there a way for tesseract to split an image into words and output the words as separate image files?
  On Windows I am getting the following error message for a JPG although the file can be opened with the viewer and shows correct:
Corrupt JPEG data: nnnn extraneous bytes before marker 0xnn
Image is attached
![ptdc0020](https://cloud.githubusercontent.com/assets/1007103/9982736/5b09231a-5f9a-11e5-84d2-ed5e2488cd91.JPG)
 Yes, it seems it is producing. Just curious - what is the issue with the JPEG though?
  I would like to suggest to slightly redesign the layout and installation of the training data.

At the present, one can install a single language (or a set of languages) by downloading the prepacked trainingdata as described in https://github.com/tesseract-ocr/tesseract/wiki/Compiling#Language%20Data _or_ by downloading the git repo https://github.com/tesseract-ocr/tessdata .

The process is difficult, in case that you always want to automatically use the latest version of (let's say) eng, deu, fra, spa, ita trainingdata.

Without presenting a concrete idea or a PR, I just wanted to start a discussion whether and how a redesign (which should be compatible to the current way of downloadlng/installing language data) could look like, if it is wanted and possible.

Perhaps a small json or text parameter file could indicate which languages are needed (or are currently installed), and only these files are then updated from git.

Or a method "git submodule" which automatically clones (or pulls) all languages from https://github.com/tesseract-ocr/tessdata .
 I think it is a good idea specially for people like me a normal windows user that is just learning
  Written in the WIKI
"Windows
An installer is available for Windows from our download page."

But as far as I can see there are no Windows installers to download. May be I'm not right, so, please, tell me, where I can get a current Windows installer.
 There is a Windows installer for tesseract version 3.02 here:

https://code.google.com/p/tesseract-ocr/downloads/list
tesseract-ocr-setup-3.02.02.exe

I don't think there is a **official** Windows installer for newer versions.
 Ok, thank you. I took a further look for a newer version and I found:
http://domasofan.spdns.eu/tesseract/
with the newest development version. But the server is delivering the files really slow.
 Thank you for the latest Windows installer files :). 
 The NSIS installer configuration was added and removed twice, the last time with commit b8862b33dfa3bf42c87913911f62da7bc4ed2e45. Is there currently another method to build an installer for Windows? If not, I'd like to add the NSIS configuration files again. I just finished cross building Tesseract for Windows (including an installer) based on latest Git master and using the MinGW-w64 packages on Debian GNU Linux. 
 @amitdo, that's interesting, but it still does not include an installer as far as I see.
@zdenop, maybe those Windows developers who are interested in libraries can also compile Tesseract. But those who just want to do OCR on Windows need an installer. Will cmake provide one?

Regarding leptonica, you can start with https://github.com/stweil/leptonica until there is an official GitHub version.
 [See issue 209](https://github.com/tesseract-ocr/tesseract/issues/209)
  I run into this error under debian7 (and 8)  with Tesseract 3.03 and also with 3.04.

The solution I found to avoid this is to set the locale LC_NUMERIC to C instead of my locale "fr_FR.UTF-8"

Is there a patch or a new version planned to solve this whitout the need to change my locale ?
Thank you
 It happened with custom training
 Hello, 
I found that tesseract had a patch for this problem (https://code.google.com/p/tesseract-ocr/issues/detail?id=910)
Why is this not in the new version of Tesseract 3.04 ?
Will it be in the next version ?
Thanks
 Btw the custom training I use is not mine so I cannot run it again with LC_NUMERIC=C
 Ok my bad.
But I just tried with the eng.traineddata from official google traineddata file and I've got the same error
"Error: Illegal min or max specification!
"Fatal error encountered!" == NULL:Error:Assert failed:in file globaloc.cpp, line 75"
 I'm having a hard time seeing how this is going wrong due to locale with the current code.  The actual error is signaled here: https://github.com/tesseract-ocr/tesseract/blob/master/classify/clusttool.cpp#L89 which happens when it is unhappy with the results that tfscanf gets for the feature parameters. tfscanf is a private, locale-independent version of fscanf, which calls, in turn, the private tvfscanf which implements its own parsing of floats with a hard coded decimal separator of '.'

One thing that definitely could cause it though is a bad/corrupted feature parameter file.

I just tested with the stock tesseract 3.03 on a brand new Debian 8 installation with the locale set to fr_FR.UTF-8 and everything worked perfectly.

If you still can't get this to work, please post the output of the following commands:

```
uname -a
tesseract -v
locale
```
  I'm currently seeing a SIGBUS crash in ComputeGradient on an Android app I'm working on, I can reliably reproduce the crash on a specific phone (Samsung Galaxy S4 Mini, Snapdragon 400), on another device (OnePlus One, Snapdragon 801)

Backtrace (app name removed): 

D/CrashAnrDetector(  656): backtrace:
D/CrashAnrDetector(  656):     #00  pc 000a746c  /data/app-lib/**APPNAME**/libtess.so
D/CrashAnrDetector(  656):     #01  pc 000a8935  /data/app-lib/**APPNAME**/libtess.so (C_OUTLINE::ComputeEdgeOffsets(int, Pix_)+160)
D/CrashAnrDetector(  656):     #02  pc 000b81b1  /data/app-lib/__APPNAME__/libtess.so
D/CrashAnrDetector(  656):     #03  pc 000a3a1d  /data/app-lib/__APPNAME__/libtess.so (BLOBNBOX::ComputeEdgeOffsets(Pix_, Pix_, BLOBNBOX_LIST_)+212)
D/CrashAnrDetector(  656):     #04  pc 000a42b7  /data/app-lib/**APPNAME**/libtess.so (TO_BLOCK::ComputeEdgeOffsets(Pix_, Pix_)+14)
D/CrashAnrDetector(  656):     #05  pc 0011f099  /data/app-lib/**APPNAME**/libtess.so (tesseract::Textord::TextordPage(tesseract::PageSegMode, FCOORD const&, int, int, Pix_, Pix_, Pix_, bool, BLOBNBOX_LIST_, BLOCK_LIST_, TO_BLOCK_LIST_)+72)

I added some debug output to ComputeGradient and it turns out it crashes when y = -2. , after adding a few more lines of debug logging in ComputeEdgeOffsets I see that start.y() is 2 larger than 'height'. If it crashes, it always does so on line 2 of ComputeGradient. SIGBUS would imply an unaligned memory access but as far as I can tell that function only deals with single byte access which shouldn't cause an issue. The -2 y coordinate also seems suspect but I don't know enough about Tesseract and Pix to know if that might be a problem or not.
  In one of our test-cases valgrind complained about a jump-condition based on an un-initialized value:

==9451== Conditional jump or move depends on uninitialised value(s)
==9451==    at 0x35CEEC31F7: tesseract::Tesseract::quality_based_rejection(PAGE_RES_IT&, unsigned char) (in /usr/lib64/libtesseract.so.3.0.3)
==9451==    by 0x35CEEB6370: tesseract::Tesseract::rejection_passes(PAGE_RES_, ETEXT_DESC_, TBOX const_, char const_) (in /usr/lib64/libtesseract.so.3.0.3)
==9451==    by 0x35CEEBB0D0: tesseract::Tesseract::recog_all_words(PAGE_RES_, ETEXT_DESC_, TBOX const_, char const_, int) (in /usr/lib64/libtesseract.so.3.0.3)
==9451==    by 0x35CEEA905A: tesseract::TessBaseAPI::Recognize(ETEXT_DESC*) (in /usr/lib64/libtesseract.so.3.0.3)
==9451==    by 0x35CEEA9B2B: tesseract::TessBaseAPI::GetUTF8Text() (in /usr/lib64/libtesseract.so.3.0.3)
==9451==    by 0x418970: main (ValgrindTest.cpp:382)
==9451== 

The reason is that sometimes word_char_quality() exits early without initializing its output parameters, however the callers expect the output-parameters to be written. Instead of initializing all the parameters for all callers, I chose to set output-parameters at early-exist directly.
 I initialized the values inside the early-exit branch, because they are otherwise overwritten anyway - which means a few unescessary stores. 
In case there are good arguments in initializing the out-values un-conditionally, I of course don't have anything against doing it.
 @egorpugin Why is a rebase needed? I don't see any conflict with the current sources. The build failure doesn't appear to be due to the code, but instead instability in the CI.
 Thanks for checking. Is there anything left for me to do to get this patch in?
  Hello there!

I have done some training and created my own combined language file. When using my custom language I get error code 5000

```
$ tesseract waa.whatevva.exp0.tif out -l waa

Error: Illegal sample size!
signal_termination_handler:Error:Signal_termination_handler called:Code 5000
Abort trap: 6
```

When I ran `combine_tessdata`I got the following output

```
Combining tessdata files
TessdataManager combined tesseract data files.
Offset for type 0 is 140
Offset for type 1 is 141
Offset for type 2 is -1
Offset for type 3 is 2214
Offset for type 4 is 299822
Offset for type 5 is 300066
Offset for type 6 is -1
Offset for type 7 is -1
Offset for type 8 is -1
Offset for type 9 is -1
Offset for type 10 is -1
Offset for type 11 is -1
Offset for type 12 is -1
Offset for type 13 is 300067
Offset for type 14 is -1
Offset for type 15 is -1
Offset for type 16 is -1
```

Anybody having an idea of what I'm doing wrong? 
  I am using the master branch from github (3.05.00dev) and facing some problems when using the stdin option in conjunction with the -psm 0 and -psm 2 options

```
cat <image file> | tesseract stdin stdout -psm 0
```

gives me the error

```
Error in fopenReadStream: file not found
Error in pixRead: image file not found: stdin
Cannot open input file: stdin
```

However, the command 

```
cat <image file> | tesseract stdin stdout -psm 1
```

works as expected.

Do I miss something?

Regards,
Caleb
 Just so you know, if I'm not mistaken, it worked with Tesseract 3.03 and only broke with Tesseract 3.04. It is also very handy to script around Tesseract (avoid using temporary files) (see [Pyocr](https://github.com/jflesch/pyocr) for instance).
 When I started working on PyOCR, it was still Tesseract 2.x. At the time, if I remember correctly, there was only a C++ API and it seemed painfully hard to use (and binding on C++ API from Python is really annoying).
Also I did fork PyOCR from an already-existing python module (python-tesseract if I recall correctly).

Good to know there is a C API now. I'll have a look, see if I can bind on it easily. Thanks for the tip :)
  Hello,

I noticed the new "pdf" option in Tesseract, which creates a PDF file with the image and the background text. That's great ! 

But usually, the image given to Tesseract is not as nice as the starting image (because it is optimized for OCR, not for human visualization). Maybe it would be useful to provide the step before, i.e. the PDF of the generated text without the image, so that the user can paste it as a background text with pdftk for example.
 @olcc link is [OCRmyPDF](https://github.com/fritz-hh/OCRmyPDF/tree/master)
 @olcc, the way to produce PDF has significantly changed in Tesseract 8.04. So I have a plan to change this in future commits. I'll take your idea into consideration. But as I remeber the new implementation does not produce the text anymore. It outputs directly to the file. But even with such effort you are able read the file manually and modify as you wish.
 @jbarlow83: Thanks for pointing to the "OCRmyPDF" wrapper.
@ws233: Tesseract 8.04? I'm quite late, I only have 3.04! ;-) (from Debian) 
@zdenop: Sorry, I didn't understand your message. Maybe my English is not good enough. My process is the following:
1) ORIGINAL.jpg -> OCR.tif  (remove colors, apply threshold, etc.)
2) tesseract OCR.tif result -l eng pdf
If you say that showing OCR.tif in the PDF is the right thing to do, I disagree in general. I agree this is a very nice feature. However, most people want to have ORIGINAL.jpg with the ocr text. 
 @olcc we here fully rely on these "mixed-mode" PDFs as generated by

`tesseract OCR.tif ORIGINAL pdf`

which works with very high quality, depending on the quality what you input to tesseract. I hope, that the present "pdf" option ( -c tessedit_create_pdf=1 ) will really never be dropped from the code.
 @zdenop, is this functionality documented anywhere?

Could you point me to the exact place in the code where it's implemented?
 > ORIGINAL.tif is included in ORIGINAL.pdf WITHOUT any modification

Whenever possible. The design intent is to copy the image bytes without using a 
decompress/compress whenever we can.  Sometimes that is impossible (TIFF
is an enormously flexible graphics format) and sometimes we haven't quite
gotten there. For example, TIFF CCITT Group 4 still goes through a lossless
decompress/compress. Simply because we haven't done the work to optimize
this code path in Tesseract / Leptonica. All relevant Tesseract code is in
ai/pdfrenderer.cc but we try to push the image heavy lifting into Leptonica.

https://en.wikipedia.org/wiki/Tagged_Image_File_Format#TIFF_Compression_Tag
 I'd like to support the original wish. Having something like

tesseract OCR.tif ORIGINAL pdf-overlay

to produce only the text overlay in a pdf file would provide a lot of flexibility.  With this, you could write frontends to tesseract capable of overlaying the invisible text overlay on something different from OCR.tiff (e.g. a full color version of OCR.tif, etc.)
  Is there a way to train tesseract to recognize a limited amount of text from an image. I am making a small app that recognizes a printed list of topics and so far using the tess-two library, tesseract does not fully recognize any of the text in the image. I am quite new to OCR so I'm not sure how to make this work. So far all the training instructions I've seen require a font file which I don't have. All I have are different images of the printed text.

How do I train tesseract to recognize the text from that? Where do I start?
 Hi,
for me it helps often to upscale a image.
in ocrdesktop i resize the image by factor 3 (Bicubic). This brings quite good results.
Cheers
 In case that you use screenshots, please notice, that screenshots usually have 72dpi, which is not sufficient for Tesseract. I admit, that this is not so well known, however, it is mentioned since a long time here https://github.com/tesseract-ocr/tesseract/wiki/FAQ#is-there-a-minimum-text-size-it-wont-read-screen-text

> Is there a Minimum Text Size? (It won't read screen text!)
> 
> There is a minimum text size for reasonable accuracy. You have to consider resolution as well as point size. Accuracy drops off below 10pt x 300dpi, rapidly below 8pt x 300dpi. A quick check is to count the pixels of the x-height of your characters. (X-height is the height of the lower case x.) At 10pt x 300dpi x-heights are typically about 20 pixels, although this can vary dramatically from font to font. Below an x-height of 10 pixels, you have very little chance of accurate results, and below about 8 pixels, most of the text will be "noise removed". 

Here's another useful page:
https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality

I recommend:
- remember never to use JPEG (because this is a lossy compresison format) when saving images with text (use: PNG, or use TIF, or GIF as the last choice)
- resize your screenshots or images to at least 300dpi, or 400dpi, or upscale by 400%:

```
convert -resize 400% ...
```
- when you start form a pdf then read http://bertanguven.com/faster-conversions-from-pdf-to-pngjpeg-imagemagick-vs-ghostscript/

```
density=400
gs -dNOPAUSE -sDEVICE=png16m -sOutputFile=$image -r$density -q $file -c quit
```

[Posting updated with information which came in later]
 ~~@Wikinaut, why do you link to the old wiki at googlecode instead to the new one at github?
https://github.com/tesseract-ocr/tesseract/wiki/FAQ#is-there-a-minimum-text-size-it-wont-read-screen-text
Here is another useful wiki page.
https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality~~

[Wikinaut updated his comment.]
 I updated my posting above accordingly. Thanks
  This is a report from someone who makes Tesseract work on Android.
We can make his life easier by copying the string instead of holding onto 
the pointer.

https://github.com/tesseract-ocr/tesseract/blob/master/api/renderer.cpp#L55

In separate news, I see that  the renderers are not doing proper escaping
of that title before the put it into PDF or HOCR output. Maybe somebody
will worry about that some day.

Here's the relevant part of the report.

> I can pass a title from Java through JNI to Tesseract's BeginDocument() just 
> fine and that title will show up properly in the PDF. But if after calling 
> BeginDocument() I release the array of bytes representing that title using 
> ReleaseStringUTFChars in my
> Java_com_googlecode_tesseract_android_TessBaseAPI_nativeBeginDocument 
> method in JNI [1], then the title will show up in the PDF as garbled text, apparently 
> read from uninitialized memory. I'm guessing this means that Tesseract needs 
> the reference to that char\* to stay around 
> 
> https://gist.github.com/rmtheis/19965abdfca5c2c9eb26
 change written, currently under review
 Change is in Ray's hands and will eventually migrate here. The person in critical need has a copy.
 @jbreiden, we didn't get the patch. 
https://github.com/tesseract-ocr/tesseract/blob/2c837dffc3/api/renderer.cpp#L71

 cc: @theraysmith  Since you originally linked to `renderer.cpp`, I thought that the patch will be in that file.

I'm sorry for the mistake.   I have a working repo and installation of tesseract. When I pull the latest version from git, make and install, the git version information when printed via `tesseract --version` is not updated.

Reporting this as a bug, but not being sure, whether this is the correct term. Please close the issue if you think that my report is wrong, because one may not use the short sequence (pull - make - install).

I simply do not know, whether the following short sequence was ever designed to work.

How to reproduce the bug:

```
git pull
make
sudo make install
```

The following sequence however works, but recompiles everything:

```
make distclean
git pull
./autogen.sh
make
sudo make install
```
 @zdenop I thought that _updating_ (via git pull) does not require the compilation of all items.
Thanks.
  previously ProcessPages return char*, but now it return either true or false.
now text where is the place to find the text detected by ocr

I see there are result renderer but they write to text or pdf file, how to get text in return as char*
  In ccmain/par_control.cpp you can see this code:
# pragma omp parallel for num_threads(10)

for (int b = 0; b < blobs.size(); ++b) {
...
}

configure.ac should have an option to activate OpenMP in tesseract code (maybe with AC_OpenMP?).
 Hi, when I try to compile on a Mac with this commit in (for testing #71), I now get the following error:

```
configure: error: conditional "OPENMP" was never defined.
Usually this means the macro was only invoked conditionally.
```
 Here's a `config.log` for the current `master` branch after `./autogen.sh` && `./configure`: https://gist.github.com/c134a55446c99b9702fe

Same process succeeds if I revert bb19f2c.
 I think this _may_ be related to this problem/answer: http://stackoverflow.com/a/32122781
As I believe the conftest should find `<omp.h>` when given `-fopenmp`. I'm currently letting the gcc reinstall run, and will report back after.

But also the configure process probably shouldn't fail by default if there's no OpenMP support detected/enabled.
 Confirmed that after `brew reinstall gcc --without-multilib`, I can use e.g. `brew install --HEAD --cc=gcc-5 tesseract` and the configure/make will succeed with bb19f2c in. Without `--cc=gcc-5` it fails due to [the lack of OpenMP support in the current Clang/LLVM compiler shipped with OS X](http://clang-omp.github.io/) (i.e. the default Mac "`gcc`").
 @ryanfb, @zdenop
FYI, Clang 3.7 now support OpenMP.

> OpenMP 3.1 is fully supported, but disabled by default. To enable it, please use the -fopenmp=libomp command line option.

http://llvm.org/releases/3.7.0/tools/clang/docs/ReleaseNotes.html#openmp-support
  For those of us who know nothing of C, might someone be kind enough to use EMScripten/asm.js to compile to JavaScript on our behalf for use in the browser (without Node.js, etc.)?  Would no doubt be quite slow but would be handy for some web apps...  The other existing ports (Ocrad and GOCR) do not seem to hold a candle to the quality of Tesseract. Thanks!
 A particularly compelling use case beyond regular web apps would be as a browser add-on for running OCR against images encountered on the web and placing the OCR'd results in a dialog, in-place on the web page, etc..

In my Firefox add-on for [decoding QR codes](https://github.com/brettz9/qr-secret-decoder-ring/), I already have infrastructure in place which could largely be reused to allow OCR against images found while browsing the web, whether as a regular image, as a frame in a video, as a background image, SVG element, canvas, or, probably PDF too, given that ImageMagick has [already been ported](http://manuels.github.io/unix-toolbox.js/).
 Ok, thanks for the reply!
 @brettz9, It seems that someone is working on this: 
https://github.com/naptha
 Will look into it...Thanks!
  Look for these functions:
- ProcessPagesMultipageTiff(...)
- ProcessPagesInternal(...)
- ProcessPage(...)

I think NO_CUBE_BUILD in these functions should be changed to SOMETHING_ELSE, probably back to ANDROID_BUILD. 

Ray might not want these features on Android, but I see no reason to disable them in a desktop/server environment.
 Thanks Zdenko (@zdenop) for this one, and thanks in general for your work on tesseract.
  When scrollview is disabled in configure, linking fails (because it still uses scrollview)

```
libtool: link: g++ -std=c++11 -o .libs/tesseract tesseract-tesseractmain.o  ./.libs/libtesseract.so -lrt -llept -lpthread
./.libs/libtesseract.so: undefined reference to `ScrollView::Brush(ScrollView::Color)'
...
./.libs/libtesseract.so: undefined reference to `window_wait(ScrollView*)'
./.libs/libtesseract.so: undefined reference to `ScrollView::TextAttributes(char const*, int, bool, bool, bool)'
collect2: error: ld returned 1 exit status
Makefile:577: recipe for target 'tesseract' failed
```
  Using Tesseract as a library, I get a ton of this information printed to the console:

Total count=0
Min=0.00 Really=0
Lower quartile=0.00
Median=0.00, ile(0.5)=0.00
Upper quartile=0.00
Max=0.00 Really=0
Range=1
Mean= 0.00
SD= 0.00
Bottom=0, top=38, base=0, x=0

Is there any option or way to disable this?
 I disagree.  The default behavior should not be to output debug information to the console.  That should be something that needs to be turned on rather than vice-versa.
 I can take a look at patching it.  Can you point me in the right direction as to where this may be emitted from in the code?  Any idea why it happens in my compile but not in the 14.04 Tesseract lib included with Ubuntu?

Pointing to /dev/null isn't ideal, since I need to run on Windows as well.
 @zdenop I've posted on the user forum as you've suggested.  I can leave this alone if you like.  I assumed this report is valuable for you and that you would want to get more information.  But if it's not important and/or interesting, I can definitely drop it and go away :)

I know other users (of my library) have run into this.  Here's a user forum post describing their issue: https://groups.google.com/forum/#!searchin/openalpr/quartile/openalpr/2x9r5_n6KvY/6ywYI8swTsMJ  I also know of one other that has run into it.  Perhaps other people just don't take the time to report it.  Or perhaps I'm using Tesseract in a strange way that only affects me.

Here's my usage of the Tesseract library
https://github.com/openalpr/openalpr/blob/master/src/openalpr/ocr.cpp

The only non-standard thing I do (I think) is turn on this option: tesseract.SetVariable("save_blob_choices", "T"); and read all the various possibilities.

I compiled the 3.04 library as follows:
export LIBLEPT_HEADERSDIR=/storage/projects/alpr/libraries/leptonica-1.72/src/
./configure --with-extra-libraries=/storage/projects/alpr/libraries/leptonica-1.72/src/.libs/
make
 We also see this information compiling 3.04 branch with default options, as of today.

I notice the original poster got no response on forums, so I'm copying here too.

We did run 'strip --strip-debug' on both tesseract304 and lept172 bins and libraries before release.   This is for an existing code base that is being ported from windows to linux.   All the unit tests are passing in both cases, it appears to be just cosmetic but it's quite a large amount of info to be reported if/when everything is working.

 Doing 'strip' won't help you here.

>As for your issue, set the variable 'debug_file' to '/dev/null'.

>The debug printing routing will select 'nul' on windows, if 'debug_file' is set to '/dev/null'. Not sure what you mean...

if you're saying 'strip' won't remove the message here, agree.

just included for thoroughness (it's about only thing we changed from
source w/default builds of aforementioned branches)

On Tue, Nov 28, 2017 at 1:24 AM, Amit D. <notifications@github.com> wrote:

> Doing 'strip' won't help you here.
>
> As for your issue, set the variable 'debug_file' to '/dev/null'.
>
> The debug printing routing will select 'nul' on windows, if 'debug_file'
> is set to '/dev/null'.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/72#issuecomment-347435977>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AK63KlAFhdCd9LjGHctiuwIyEuMNiUMpks5s67UogaJpZM4FkMdm>
> .
>
 whups missed 2nd part of reply.

we're unfamiliar outside of tesseract beyond emgu and our examples... if
others reading this are the same, here is the instructions on changing
'debug_file' in tesseract

https://github.com/tesseract-ocr/tesseract/wiki/FAQ#how-can-i-make-the-error-messages-go-to-tesseractlog-instead-of-stderr

thx, will try and report


On Tue, Nov 28, 2017 at 1:33 AM, Pracplay Support <support@pracplay.com>
wrote:

>
> Not sure what you mean...
>
> if you're saying 'strip' won't remove the message here, agree.
>
> just included for thoroughness (it's about only thing we changed from
> source w/default builds of aforementioned branches)
>
> On Tue, Nov 28, 2017 at 1:24 AM, Amit D. <notifications@github.com> wrote:
>
>> Doing 'strip' won't help you here.
>>
>> As for your issue, set the variable 'debug_file' to '/dev/null'.
>>
>> The debug printing routing will select 'nul' on windows, if 'debug_file'
>> is set to '/dev/null'.
>>
>> —
>> You are receiving this because you commented.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tesseract-ocr/tesseract/issues/72#issuecomment-347435977>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AK63KlAFhdCd9LjGHctiuwIyEuMNiUMpks5s67UogaJpZM4FkMdm>
>> .
>>
>
>
 also here is a cross-post to users thread (the response I got there is to
upgrade... which we definately plan on doing once we get existing stuff
working on both platforms ;)

https://groups.google.com/d/msg/tesseract-ocr/-K5d2euBJ_I/rEm2eNgdAgAJ

sorry for cross post but more people were complaining than posting answers
so hopefully this bumps up this thread.

will lyk, gr8 work on tesseract... excited to try new version

On Tue, Nov 28, 2017 at 1:37 AM, Pracplay Support <support@pracplay.com>
wrote:

>
> whups missed 2nd part of reply.
>
> we're unfamiliar outside of tesseract beyond emgu and our examples... if
> others reading this are the same, here is the instructions on changing
> 'debug_file' in tesseract
>
> https://github.com/tesseract-ocr/tesseract/wiki/FAQ#how-
> can-i-make-the-error-messages-go-to-tesseractlog-instead-of-stderr
>
> thx, will try and report
>
>
> On Tue, Nov 28, 2017 at 1:33 AM, Pracplay Support <support@pracplay.com>
> wrote:
>
>>
>> Not sure what you mean...
>>
>> if you're saying 'strip' won't remove the message here, agree.
>>
>> just included for thoroughness (it's about only thing we changed from
>> source w/default builds of aforementioned branches)
>>
>> On Tue, Nov 28, 2017 at 1:24 AM, Amit D. <notifications@github.com>
>> wrote:
>>
>>> Doing 'strip' won't help you here.
>>>
>>> As for your issue, set the variable 'debug_file' to '/dev/null'.
>>>
>>> The debug printing routing will select 'nul' on windows, if 'debug_file'
>>> is set to '/dev/null'.
>>>
>>> —
>>> You are receiving this because you commented.
>>> Reply to this email directly, view it on GitHub
>>> <https://github.com/tesseract-ocr/tesseract/issues/72#issuecomment-347435977>,
>>> or mute the thread
>>> <https://github.com/notifications/unsubscribe-auth/AK63KlAFhdCd9LjGHctiuwIyEuMNiUMpks5s67UogaJpZM4FkMdm>
>>> .
>>>
>>
>>
>
 You'll get the same problem with any newer version, and the solution is the same. sounds good thx 4 reply

On Tue, Nov 28, 2017 at 3:13 AM, Amit D. <notifications@github.com> wrote:

> You'll get the same problem with any newer version, and the solution is
> the same.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/72#issuecomment-347459840>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AK63Kod4YKZjkCqrMXbSvV7TvNuzJ_f1ks5s687WgaJpZM4FkMdm>
> .
>
 suggestion corrected the issue, thx again.

On Tue, Nov 28, 2017 at 3:13 AM, Amit D. <notifications@github.com> wrote:

> You'll get the same problem with any newer version, and the solution is
> the same.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/72#issuecomment-347459840>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AK63Kod4YKZjkCqrMXbSvV7TvNuzJ_f1ks5s687WgaJpZM4FkMdm>
> .
>
  It seems that any OpenCL operation on my OS X Yosemite machine triggers attempts to allocate extremely large memory blocks and allocation failures.

The size of the attempted allocation is 1125865547108352 bytes or in hex, 0x3fff800001000, which looks special.

OpenCL otherwise works on my machine. I use the Python OpenCV library and a commercial application that uses OpenCL.

Aside from whatever is happening here, it also looks like a bug that the profile data gets written even if OpenCL fails. I highly doubt my graphics card and processor give identical performance so it looks some invalid calculation takes place and the results are then saved.
## Testing --list-langs

Checking for languages in an OpenCL binary:

```
set -x TESSDATA_PREFIX /usr/local/Cellar/tesseract/3.03rc1_3/share   # Homebrew tesseract 3.03
/opt/tesseract-opencl/bin/tesseract --list-langs
```

Results

```
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performing profiling.

[DS] Device: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL) evaluation...
tesseract(9135,0x7fff7a778300) malloc: *** mach_vm_map(size=1125865547108352) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
OpenCL error code is -54 at   when clEnqueueNDRangeKernel .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_ThresholdRectToPix .
[DS] Device: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL) evaluated
[DS]          composeRGBPixel: 1540962513.969949 (w=1.2)
[DS]            HistogramRect: 1540962513.969949 (w=2.4)
[DS]       ThresholdRectToPix: 1540962513.969949 (w=4.5)
[DS]        getLineMasksMorph: 1204940900.030019 (w=5.0)
[DS]                    Score: 18506500096.000000

[DS] Device: "GeForce GT 755M" (OpenCL) evaluation...
tesseract(9135,0x7fff7a778300) malloc: *** mach_vm_map(size=1125865547108352) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
[DS] Device: "GeForce GT 755M" (OpenCL) evaluated
[DS]          composeRGBPixel: 1540962513.969949 (w=1.2)
[DS]            HistogramRect: 1540962513.969949 (w=2.4)
[DS]       ThresholdRectToPix: 1540962513.969949 (w=4.5)
[DS]        getLineMasksMorph: 1204940900.030019 (w=5.0)
[DS]                    Score: 18506500096.000000

[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
[DS]          composeRGBPixel: 256.000000 (w=1.2)
[DS]            HistogramRect: 256.000000 (w=2.4)
[DS]       ThresholdRectToPix: 256.000000 (w=4.5)
[DS]        getLineMasksMorph: 4294966736.000000 (w=5.0)
[DS]                    Score: 21474836480.000000
[DS] Scores written to file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz score is 18506500096.000000
[DS] Device[2] 1:GeForce GT 755M score is 18506500096.000000
[DS] Device[3] 0:(null) score is 21474836480.000000
[DS] Selected Device[1]: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL)
tesseract(9135,0x7fff7a778300) malloc: *** mach_vm_map(size=1125865547108352) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
List of available languages (2):
eng
osd
```

Subsequent executions try to use the OpenCL profile results but still get errors:

```
[DS] Profile read from file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz score is 18506500096.000000
[DS] Device[2] 1:GeForce GT 755M score is 18506500096.000000
[DS] Device[3] 0:(null) score is 21474836480.000000
[DS] Selected Device[1]: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL)
tesseract(9139,0x7fff7a778300) malloc: *** mach_vm_map(size=1125865547108352) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
List of available languages (2):
eng
osd
```
## Testing OCR of JPEG to PDF

```
set -x TESSDATA_PREFIX /usr/local/Cellar/tesseract/3.03rc1_3/share   # Homebrew tesseract 3.03
/opt/tesseract-opencl/bin/tesseract tests/resources/congress.jpg tessopencl -l eng pdf
```

Result:

```
Tesseract Open Source OCR Engine v3.04.01dev with Leptonica
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performing profiling.

[DS] Device: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL) evaluation...
tesseract(9120,0x7fff7a778300) malloc: *** mach_vm_map(size=1125865547108352) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
OpenCL error code is -54 at   when clEnqueueNDRangeKernel .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_ThresholdRectToPix .
[DS] Device: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL) evaluated
[DS]          composeRGBPixel: 1539474209.312102 (w=1.2)
[DS]            HistogramRect: 1539474209.312102 (w=2.4)
[DS]       ThresholdRectToPix: 1539474209.312102 (w=4.5)
[DS]        getLineMasksMorph: 1345623668.687865 (w=5.0)
[DS]                    Score: 19197859840.000000
[DS] Device: "GeForce GT 755M" (OpenCL) evaluation...
tesseract(9120,0x7fff7a778300) malloc: *** mach_vm_map(size=1125865547108352) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
[DS] Device: "GeForce GT 755M" (OpenCL) evaluated
[DS]          composeRGBPixel: 1539474209.312102 (w=1.2)
[DS]            HistogramRect: 1539474209.312102 (w=2.4)
[DS]       ThresholdRectToPix: 1539474209.312102 (w=4.5)
[DS]        getLineMasksMorph: 1345623668.687865 (w=5.0)
[DS]                    Score: 19197859840.000000

[DS] Device: "(null)" (Native) evaluation...
[DS] Device: "(null)" (Native) evaluated
[DS]          composeRGBPixel: 256.000000 (w=1.2)
[DS]            HistogramRect: 256.000000 (w=2.4)
[DS]       ThresholdRectToPix: 256.000000 (w=4.5)
[DS]        getLineMasksMorph: 4294966736.000000 (w=5.0)
[DS]                    Score: 21474836480.000000
[DS] Scores written to file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz score is 19197859840.000000
[DS] Device[2] 1:GeForce GT 755M score is 19197859840.000000
[DS] Device[3] 0:(null) score is 21474836480.000000
[DS] Selected Device[1]: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL)
tesseract(9120,0x7fff7a778300) malloc: *** mach_vm_map(size=1125865547108352) failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
Warning in pixReadMemJpeg: work-around: writing to a temp file
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_ThresholdRectToPix .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
```
## Versions

```
tesseract 3.04.01dev
 leptonica-1.71
  libgif 4.1.6(?) : libjpeg 8d : libpng 1.6.18 : libtiff 4.0.4 : zlib 1.2.5

 OpenCL info:
  Found 1 platforms.
  Platform name: Apple.
  Version: OpenCL 1.2 (May 10 2015 19:38:45).
  Found 2 devices.
    Device 1 name: Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz.
    Device 2 name: GeForce GT 755M.
```
 My stab in the dark at any answer is that, for some reason, the OpenCL API or ABI different from Tesseract is expecting as declared in header files.

The malloc error occurs because (openclwrapper.cpp:674) in

```
size_t numDevices;
clGetProgramInfo(... sizeof(numDevices), &numDevices, ...):
```

The call to `clGetProgramInfo` writes the correct value to the lower 32-bit of numDevices, but leaves uninit'ed garbage in the upper 32-bits. But even if this is correct, other OpenCL calls generated errors:

```
[DS] Device: "Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz" (OpenCL) evaluation...
OpenCL error code is -54 at   when clEnqueueNDRangeKernel .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannels .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_HistogramRectAllChannelsReduction .
OpenCL error code is -54 at   when clEnqueueNDRangeKernel kernel_ThresholdRectToPix .
```

I'd be happy to investigate further if someone can point me in the right direction.
 I currently get `configure: error: Required OpenCL library not found!` ([associated config.log](https://gist.github.com/4b763df567fb8d2a7a2d)). With 3.04.00 I can compile (and seemingly use) Tesseract configured with `--enable-opencl` ([associated config.log for 3.04.00](https://gist.github.com/5b142efc198986c2e8dc)).
 I tried both master and 3.04.00 with `--enable-opencl` on Ubuntu with Catalyst 15.7 and for my two devices (FX8120 and R9 285) the OCR also outputs a .txt but the content is only empty lines and some wrong characters. Forcing to run without opencl achieves the correct output.

When running with OpenCL on FX8120 there are no warnings or errors during execution, but there are some warnings as `tiff page not found` and `box outside rectangle` on R9 285. In the end, the (wrong) output is the same for any of them.
 With OpenCL-enabled HEAD on OS X, I also get garbage for @jbarlow83's test image.

However if I convert PDFs to TIFF in the way I usually do for OCR with Tesseract, I can get text with OpenCL-enabled HEAD (the BW PDF for [this book](https://archive.org/details/aesopsfables00mclo) in this example):

```
convert -density 300 aesopsfables00mclo_bw.pdf -type Grayscale -compress lzw -background white +matte -depth 32 page_%05d.tif
```

Then OCR with e.g. `for i in page_*.tif; do tesseract $i $(basename $i .tif); done` works fine and produces text (in both text and PDF output modes). This also seems to work for multipage TIFFs (just convert without the `%05d` in the output filename), however, if I try to process a multipage TIFF during the initial OpenCL profiling run, Tesseract always crashes with a SIGABRT after the first page.

Another thing I notice though is that I also get a score of `inf` for my CPU on OpenCL, is this a bug that needs to be fixed in the `HistogramRect`/`ThresholdRectToPix` evaluations?
 Yep, I have the same problem. Try resizing your image to powers of 2. Actually, just resize the canvas, leave the text part unchanged.You could do it with ImageMagick convert, or any image editor like Photoshop. Probably you only need to size the width to power of 2, I didn't test that, but it looks like the pitch is being miscalculated with non-power of two sized images. 
 Oh...didn't mention it, but I get exactly the same output as you. Bring the distorted image up in PhotoShop, Select Filter->Distort->Shear and shear top left to bottom right with Wraparound selected. Do that 2-4 times and the text will magically appear.
 Look at Issue #124
 Hi folks,

i have a similar problems with the garbage output, when i enable opencl. I have checked out the current master revision (bd45b3a). also i get the mangled image with `tesseract -c tessedit_write_images=1 ...` command too.
The OS is Debian 64bit.

My Settings are:
```
tesseract 4.00.00alpha
 leptonica-1.74.1
  libjpeg 6b (libjpeg-turbo 1.3.1) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

 OpenCL info:
  Found 1 platform(s).
  Platform 1 name: NVIDIA CUDA.
  Version: OpenCL 1.1 CUDA 6.5.51.
  Found 1 device(s).
    Device 1 name: GeForce GTX 750 Ti.
 Found AVX
 Found SSE

```
the console output is:
```
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
OSD: Weak margin (1.36) for 292 blob text block, but using orientation anyway: 0
[DS] Profile read from file (tesseract_opencl_profile_devices.dat).
[DS] Device[1] 1:GeForce GTX 750 Ti score is 0.128314
[DS] Device[2] 0:(null) score is 0.917442
[DS] Selected Device[1]: "GeForce GTX 750 Ti" (OpenCL)
Tesseract Open Source OCR Engine v4.00.00alpha with Leptonica
OSD: Weak margin (5.65) for 486 blob text block, but using orientation anyway: 3
Error in boxClipToRectangle: box outside rectangle
Error in pixScanForForeground: invalid box
```
My Question is: do i have a malconfigurated system or is it a bug?  Hi,
I'm packaging tesseract for Gentoo Linux. What is the up-to-date download location for training data? We used to download from Google Code, but that looks like it is going to close eventually. Ideally we would like to have pre-packaged .tar.gz files for each language (like we used to have on Google code). Would that be possible also on github?

Should we still use the language files from [here](https://code.google.com/p/tesseract-ocr/downloads/list) with 3.04.00 ?

Thanks!
 I'm not a user of tesseract user, I'm packaging it. Therefore I'm looking to quickly identify which files I need to provide to the users.  At the moment it seems to be the case that I have to get the source from github, and language files from an old version of google code.  So one issue is that it's not documented that the 3.02 language files and tesseract-3.04 belong together. From what I read in the forums this is indeed the case. The issue is NOT that I want you to tar individual files. The issue is that there is no single official location where to download everything needed to ship your software to your users (in Gentoo).
 OK, thanks. Tesseract-3.04.00 is in Gentoo with up to date traineddata now.
  The current link points to the README file in master branch, rather than the wiki that the intro text implies it should be pointing to.
 That's fair. I saw "wiki" and was confused that it pointed to the README. Thanks for the clarification.
  Hello

I just compiled tesseract 3.04 on CentOS and it works perfectly.

But I´m trying to run mftraining and I´m getting this error:

[~/tesseract-master]# mftraining
Segmentation fault (core dumped)

Any suggestions?

Thanks
 ./configure --enable-debug
Then provide a backtrace with gdb (if you know how)
 I have never done that, but anyway I gave a try but got stucked:

@ gdb mftraining
GNU gdb (GDB) Red Hat Enterprise Linux (7.2-75.el6)
Copyright (C) 2010 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later http://gnu.org/licenses/gpl.html
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-redhat-linux-gnu".
For bug reporting instructions, please see:
http://www.gnu.org/software/gdb/bugs/...
Reading symbols from /usr/local/bin/mftraining...done.
(gdb)
 Thanks, @zdenop 

The result is:
(gdb) run
Starting program: /usr/local/bin/mftraining
[Thread debugging using libthread_db enabled]

Program received signal SIGSEGV, Segmentation fault.
0x0000003c4de7b53c in free () from /lib64/libc.so.6
Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.149.el6_6.7.x86_64 libgcc-4.4.7-11.el6.x86_64 libjpeg-turbo-1.2.1-3.el6_5.x86_64 libpng-1.2.49-1.el6_2.x86_64 libstdc++-4.4.7-11.el6.x86_64 libtiff-3.9.4-10.el6_5.x86_64 zlib-1.2.3-29.el6.x86_64
(gdb)
 @vzani: the critical part is entering the command "backtrace" after the segmentation fault.
 entered the command "backtrace",the result is:
Program received signal SIGSEGV, Segmentation fault.
0x0000003951e7b5dc in free () from /lib64/libc.so.6
Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.166.el6_7.1.x86_64 libgcc-4.4.7-16.el6.x86_64 libjpeg-turbo-1.2.1-3.el6_5.x86_64 libpng-1.2.49-1.el6_2.x86_64 libstdc++-4.4.7-16.el6.x86_64 libtiff-3.9.4-10.el6_5.x86_64 zlib-1.2.3-29.el6.x86_64
(gdb) backtrace
#0  0x0000003951e7b5dc in free () from /lib64/libc.so.6
#1  0x0000000000407d6b in GenericVectortesseract::DoubleParam*::reserve (
    this=0x60e088, size=4) at ../ccutil/genericvector.h:484
#2  0x0000000000407e30 in double_the_size (this=0x7ffff7d6be40, 
    value=<value optimized out>, 
    name=0x7ffff7ad49cd "classify_norm_adj_midpoint", 
    comment=<value optimized out>, init=<value optimized out>, vec=0x60e010)
    at ../ccutil/genericvector.h:492
#3  push_back (this=0x7ffff7d6be40, value=<value optimized out>, 
    name=0x7ffff7ad49cd "classify_norm_adj_midpoint", 
    comment=<value optimized out>, init=<value optimized out>, vec=0x60e010)
    at ../ccutil/genericvector.h:588
#4  tesseract::DoubleParam::DoubleParam (this=0x7ffff7d6be40, 
    value=<value optimized out>, 
    name=0x7ffff7ad49cd "classify_norm_adj_midpoint", 
    comment=<value optimized out>, init=<value optimized out>, vec=0x60e010)
    at ../ccutil/params.h:203
#5  0x00007ffff7a46572 in global constructors keyed to normmatch.cpp ()
   from /usr/local/lib/libtesseract.so.3
#6  0x00007ffff7ab5386 in __do_global_ctors_aux ()
   from /usr/local/lib/libtesseract.so.3
#7  0x00007ffff78df193 in _init () from /usr/local/lib/libtesseract.so.3
#8  0x00007ffff7485990 in ?? ()
 My result of "backtrace" is:

#0  0x0000003c4de7b53c in free () from /lib64/libc.so.6
#1  0x0000000000407d6b in GenericVectortesseract::DoubleParam*::reserve (
    this=0x60e088, size=4) at ../ccutil/genericvector.h:484
#2  0x0000000000407e30 in double_the_size (this=0x7ffff7d6bba0,
    value=<value optimized out>,
    name=0x7ffff7ad09ad "classify_norm_adj_midpoint",
    comment=<value optimized out>, init=<value optimized out>, vec=0x60e010)
    at ../ccutil/genericvector.h:492
#3  push_back (this=0x7ffff7d6bba0, value=<value optimized out>,
    name=0x7ffff7ad09ad "classify_norm_adj_midpoint",
    comment=<value optimized out>, init=<value optimized out>, vec=0x60e010)
    at ../ccutil/genericvector.h:588
#4  tesseract::DoubleParam::DoubleParam (this=0x7ffff7d6bba0,
    value=<value optimized out>,
    name=0x7ffff7ad09ad "classify_norm_adj_midpoint",
    comment=<value optimized out>, init=<value optimized out>, vec=0x60e010)
    at ../ccutil/params.h:203
#5  0x00007ffff7a2a0f2 in global constructors keyed to normmatch.cpp ()
   from /usr/local/lib/libtesseract.so.3
#6  0x00007ffff7ab5346 in __do_global_ctors_aux ()
   from /usr/local/lib/libtesseract.so.3
#7  0x00007ffff78df193 in _init () from /usr/local/lib/libtesseract.so.3
#8  0x00007ffff740e990 in ?? ()
#9  0x0000003c4da0e605 in _dl_init_internal () from /lib64/ld-linux-x86-64.so.2
#10 0x0000003c4da00b3a in _dl_start_user () from /lib64/ld-linux-x86-64.so.2
#11 0x0000000000000001 in ?? ()
#12 0x00007fffffffe79d in ?? ()
#13 0x0000000000000000 in ?? ()

Any suggestions?

Thanks
 Can you double check the compilation environment?
the reserve function being in ccutil/genericvector.h on line 484 looks like version 3.02.02
Is older version of tesseract already installed?
 @koralatov, did you add this junk message, or was your account hacked? After looking at the activity list, I reported abuse to GitHub.
 Sorry. At some point overnight someone/thing hacked my email and sent these and quite a number of other obviously spammy emails.  I'm cleaning up now. 
  ```
In file included from ./blamer.h:27:
./matrix.h:292:63: error: reinterpret_cast from 'nullptr_t' to 'BLOB_CHOICE_LIST *' is not allowed
    : BandTriMatrix<BLOB_CHOICE_LIST *>(dimension, bandwidth, NOT_CLASSIFIED) {}
                                                              ^~~~~~~~~~~~~~
./matrix.h:33:24: note: expanded from macro 'NOT_CLASSIFIED'
#define NOT_CLASSIFIED reinterpret_cast<BLOB_CHOICE_LIST*>(NULL)
                       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
```

clang-3.4.1
 I can repreduce this error on freebsd 10.3 with clang 3.4.1：
[xx@ ~/work/tesseract-3.04.01]$ clang --version
FreeBSD clang version 3.4.1 (tags/RELEASE_34/dot1-final 208032) 20140512
Target: x86_64-unknown-freebsd10.3
Thread model: posix
 and also 11.0RC2 with clang 3.8.0：
[~/work_space/tesseract-3.04.01]$ clang --version
FreeBSD clang version 3.8.0 (tags/RELEASE_380/final 262564) (based on LLVM 3.8.0)
Target: x86_64-unknown-freebsd11.0
Thread model: posix
InstalledDir: /usr/bin

ibtool: compile:  clang++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -I../ccutil -I../cutil -I../viewer -I../opencl -I/usr/local/include/leptonica -g -O2 -std=c++11 -MT blread.lo -MD -MP -MF .deps/blread.Tpo -c blread.cpp  -fPIC -DPIC -o .libs/blread.o
--- blamer.lo ---
In file included from blamer.cpp:21:
In file included from ./blamer.h:27:
./matrix.h:292:63: error: reinterpret_cast from 'nullptr_t' to 'BLOB_CHOICE_LIST _' is not allowed
    : BandTriMatrix<BLOB_CHOICE_LIST *>(dimension, bandwidth, NOT_CLASSIFIED) {}
                                                              ^~~~~~~~~~~~~~
./matrix.h:33:24: note: expanded from macro 'NOT_CLASSIFIED'
#define NOT_CLASSIFIED reinterpret_cast<BLOB_CHOICE_LIST_>(NULL)
                       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 I see the HEAD already include the fix,thanks!
  The tesstrain.sh and related training scripts are very useful. Please include them as part of the package (if not included). Thanks! 
  Hi,
I'm running 3.05.00dev on Ubuntu 14.04 LTS.
When running:
`tesseract eng.Arial.exp0.tif eng.Arial.exp0 box.train`
I'm getting a simple one-line output:
`Tesseract Open Source OCR Engine v3.05.00dev with Leptonica`

However, no `.tr` output file is created (anywhere in the filesystem).

My work dir listing is:

```
Arial.ttf
common.punc
eng.Arial.exp0.box
eng.Arial.exp0.tif
training-text.txt
```

Running with gdb doesn't give anything additional.

Anything I can look for for extra info? Any ideas what might be causing this?

Thanks
 I'm having exactly the same problem than danageva with the same version but over OS X. Apparently zdenop closed the issue with a deletion in two files. I don't have those lines in my installed version. Can you help me please?
 I'm having exactly the same problem. I have the latest code from the repo.
Edit: It works with v3.04.00
 `git rev-parse HEAD` command gives me 1826ac140b30a0f271726cbcbdc49a10eae80387

`uname -a`
`Linux ubuntu 3.19.0-42-generic #48-Ubuntu SMP Thu Dec 17 22:54:45 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux`
`lsb_release -a`
`Distributor ID:    Ubuntu
Description:    Ubuntu 15.04
Release:    15.04
Codename:   vivid`

The exact command is:
`tesseract ult.dejavu.exp0.tif ult.dejavu.exp0 box.train`
The output:
`Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Segmentation fault (core dumped)`
If I use it with sudo:
`sudo tesseract ult.dejavu.exp0.tif ult.dejavu.exp0 box.train`
The output:
`Tesseract Open Source OCR Engine v3.05.00dev with Leptonica`

Required files attached.
[ult.zip](https://github.com/tesseract-ocr/tesseract/files/106879/ult.zip)
 I installed it as:

```
./autogen.sh
./configure --prefix=/home/username/tessbin
make
make install
make training
make training-install
```
 ... or call `/home/username/tessbin/bin/tesseract` directly.
 Nope, there's no other tesseract in my machine. find does not return
anything.

On 27 January 2016 at 18:36, Amit Dovev notifications@github.com wrote:

> Try this command to see if you have another installation of Tesseract in
> your machine.
> 
> find /usr -name "tesseract"
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/64#issuecomment-175761505
> .
 @aiwaz, could you try this command:

```
gdb --args tesseract ult.dejavu.exp0.tif ult.dejavu.exp0 box.train
```

(Enter `run` on the gdb command line, and when it reports an error `info stack`)
 ```
gdb --args tesseract ult.dejavu.exp0.tif ult.dejavu.exp0 box.train
GNU gdb (Ubuntu 7.9-1ubuntu1) 7.9
Copyright (C) 2015 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-linux-gnu".
Type "show configuration" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
<http://www.gnu.org/software/gdb/documentation/>.
For help, type "help".
Type "apropos word" to search for commands related to "word"...
Reading symbols from ../../bin/tesseract...done.
(gdb) run
Starting program: /home/azukausk/tessbin/bin/tesseract ult.dejavu.exp0.tif ult.dejavu.exp0 box.train
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica

Program received signal SIGSEGV, Segmentation fault.
tesseract::TessResultRenderer::BeginDocument (this=this@entry=0x83f0b0, title=title@entry=0x7ffff78a8fea "")
    at renderer.cpp:57
57    bool ok = BeginDocumentHandler();
(gdb) info stack
#0  tesseract::TessResultRenderer::BeginDocument (this=this@entry=0x83f0b0, title=title@entry=0x7ffff78a8fea "")
    at renderer.cpp:57
#1  0x00007ffff76cee2f in tesseract::TessBaseAPI::ProcessPagesInternal (this=this@entry=0x7fffffffe2a0, 
    filename=<optimized out>, retry_config=retry_config@entry=0x0, timeout_millisec=timeout_millisec@entry=0, 
    renderer=0x83f0b0) at baseapi.cpp:1166
#2  0x00007ffff76cf570 in tesseract::TessBaseAPI::ProcessPages (this=this@entry=0x7fffffffe2a0, 
    filename=<optimized out>, retry_config=retry_config@entry=0x0, timeout_millisec=timeout_millisec@entry=0, 
    renderer=<optimized out>) at baseapi.cpp:1074
#3  0x0000000000401f5c in main (argc=<optimized out>, argv=0x7fffffffe448) at tesseractmain.cpp:429
(gdb)
```
 @stweil, I always call tesseract directly. It resides in `/home/username/tessbin/bin/tesseract` , just as you wrote. I created an alias for it in bashrc.
 TESSDATA_PREFIX is empty.

```
tesseract --list-langs
List of available languages (1):
eng
```
 ```
tesseract ult.dejavu.exp0.tif ult txt hocr
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Error opening data file /home/azukausk/tessbin/share/tessdata/osd.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your "tessdata" directory.
Failed loading language 'osd'
Tesseract couldn't load any languages!
Warning: Auto orientation and script detection requested, but osd language failed to load
Warning in pixReadMemTiff: tiff page 1 not found
```

Why it wants to load the "osd" language?

The files are produced:

```
ll
total 21500
drwxrwxr-x 2 azukausk azukausk     4096 Jan 27 13:49 configs
-rw-rw-r-- 1 azukausk azukausk 21876550 Jan 25 15:41 eng.traineddata
-rw-r--r-- 1 azukausk azukausk      568 Jan 27 13:49 pdf.ttf
drwxrwxr-x 2 azukausk azukausk     4096 Jan 27 13:49 tessconfigs
-rw-rw-r-- 1 azukausk azukausk     1649 Jan 25 15:56 training_text
-rw-rw-r-- 1 azukausk azukausk    38706 Jan 27 12:53 ult.dejavu.exp0.box
-rw-rw-r-- 1 azukausk azukausk    39984 Jan 27 12:53 ult.dejavu.exp0.tif
-rw-rw-r-- 1 azukausk azukausk    36383 Jan 28 12:03 ult.hocr
-rw-rw-r-- 1 azukausk azukausk     1685 Jan 28 12:03 ult.txt
```

When I set the TESSDATA_PREFIX variable the output is the same:

```
TESSDATA_PREFIX=/home/azukausk/tessbin/share/tessdata
echo $TESSDATA_PREFIX
/home/azukausk/tessbin/share/tessdata
tesseract ult.dejavu.exp0.tif ult txt hocr
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Error opening data file /home/azukausk/tessbin/share/tessdata/osd.traineddata
Please make sure the TESSDATA_PREFIX environment variable is set to the parent directory of your "tessdata" directory.
Failed loading language 'osd'
Tesseract couldn't load any languages!
Warning: Auto orientation and script detection requested, but osd language failed to load
Warning in pixReadMemTiff: tiff page 1 not found
```

And one more question: when I configure tesseract with --prefix option, I expect tesseract to be smart enough to know where my data are. Why do I have to set TESSDATA_PREFIX variable explicitly?
 Setting TESSDATA_PREFIX is not needed as long as your `tessdata` directory is at the right place ($PREFIX/share/tessdata).

`osd.traineddata` will be used for auto orientation and script detection, no matter which language you have selected.
 I tested the fix and confirm that `tesseract ult.dejavu.exp0.tif ult.dejavu.exp0 box.train` now produces `.tr` file.
Thank you guys.
  Using windows binaries compiled by Simon on cygwin from http://domasofan.spdns.eu/tesseract/

$ tesseract testing\eurotext.tif testing\eurotext -l eng+deu pdf

Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Error in fopenWriteStream: stream not opened
Error in pixWrite: stream not opened
Error in fopenReadStream: file not found
Error in extractG4DataFromFile: stream not opened to file
Error in l_generateG4Data: datacomp not extracted
Error in pixGenerateCIData: g4 data not made
Error in l_generateCIDataForPdf: file testing\eurotext.tif format is 4; unreadable
Error during processing.

the pdf comes out but you can't open it.
adobe reader shows an error that it is corrupted.

(Forum thread - https://groups.google.com/forum/#!msg/tesseract-ocr/ToWcnyHqF4c/FHWGlQhd6poJ )
 Version information - 
tesseract 3.05.00dev
 leptonica-1.72
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.3.1) : libpng 1.6.17 : libtiff 4.0.3 : zlib 1.2.8 : libwebp 0.4.3
 on cygwin x86_64 and same on x86:
 $  tesseract --version
tesseract 3.04.00
 leptonica-1.72
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.3.1) : libpng 1.6.17 : libtiff 4.0.3 : zlib 1.2.8 : libwebp 0.4.3

$  tesseract eurotext.tif eurotext -l eng+deu pdf
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
Page 1
Warning in pixReadMemTiff: tiff page 1 not found

$ ls -lrt eurotext.pdf
-rw-r--r-- 1 marco Administrators 13K Jul 26 21:36 eurotext.pdf
 Marco, the version I tested was 'v3.05.00dev' based on the master branch from git (built by Simon). 

Could it be that one of the newer commits has caused this issue?
 I doubt, more likely you are missing some additional library/program or
a missing configuration.

On Mon, Jul 27, 2015 at 5:01 AM, Shreeshrii notifications@github.com
wrote:

> Marco, the version I tested was 'v3.05.00dev' based on the master branch
> from git (built by Simon).
> 
> Could it be that one of the newer commits has caused this issue?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/63#issuecomment-125068829
> .
 Tesseract knows that PDF creation failed and returns an error code. So at least this is not silent data corruption. I'd like to know if the problem is present for PNG input or if it is restricted to TIFF.
 Jeff, it worked for png and jpg for pdf output. This is using the versions compiled by Simon.

C:\Users\User\Downloads\TESS>tesseract -v
tesseract 3.05.00dev
 leptonica-1.72
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.3.1) : libpng 1.6.17 : libtiff 4.0.3 : zlib 1.2.8 : libwebp 0.4.3

C:\Users\User\Downloads\TESS>tesseract testing/phototest.gif testing/phototest.gif -l eng pdf
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Warning in pixReadMemGif: writing to a temp file, not directly to memory
Error in fopenWriteStream: stream not opened
Error in l_binaryWrite: stream not opened
Error in fopenReadStream: file not found
Error in pixRead: image file not found: /tmp/leptonica/847980_4108_mem.gif
Error in pixReadMemGif: pix not read
Error in pixReadMem: gif: no pix returned
Error during processing.

C:\Users\User\Downloads\TESS>tesseract testing/phototest.tif testing/phototest.tif -l eng pdf
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Error in fopenWriteStream: stream not opened
Error in pixWrite: stream not opened
Error in fopenReadStream: file not found
Error in extractG4DataFromFile: stream not opened to file
Error in l_generateG4Data: datacomp not extracted
Error in pixGenerateCIData: g4 data not made
Error in l_generateCIDataForPdf: file testing/phototest.tif format is 4; unreadable
Error during processing.

C:\Users\User\Downloads\TESS>tesseract testing/phototest.tif testing/phototest.tif -l eng
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Page 1
Warning in pixReadMemTiff: tiff page 1 not found

C:\Users\User\Downloads\TESS>tesseract testing/phototest.png testing/phototest.png -l eng pdf
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica

C:\Users\User\Downloads\TESS>tesseract testing/phototest.jpg testing/phototest.jpg -l eng pdf
Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
  Directory of C:\Users\User\Downloads\TESS\testing

07/28/15  08:10            55,504 phototest.gif
07/28/15  08:19                 0 phototest.gif.pdf
08/28/14  20:38            57,772 phototest.jpg
07/28/15  08:20            61,460 phototest.jpg.pdf
08/28/14  20:38             5,265 phototest.png
07/28/15  08:20             8,890 phototest.png.pdf
07/24/15  12:15            38,668 phototest.tif
07/28/15  08:20             2,910 phototest.tif.pdf
07/28/15  08:20               287 phototest.tif.txt
 Hmmm.... interesting.  I suspect this is related to that classic Windows problem
where you can't pass file pointers between different DLLs, especially if they use
different runtimes. If so, we may be in trouble.
 Or... do we still have some ifdefs in the code to do Windows streaming I/O a little differently? I vaguely remember writing some back in the day. Maybe they are misbehaving under Cygwin? Can't seem to find them at the moment.
 Marco is able to get the pdf output from the 3.04.00 version he packaged
for cygwin.

I was testing based on the (3.05.dev version) files that were built by Simon. I do not have
cygwin installed but will try downloading the files from the mirrors Marco
suggested and see what happens.

FYI, I downloaded the MSYS2 tesseract-ocr package for 3.04.00 (packaged by
Alex at
https://github.com/Alexpux/MINGW-packages/tree/master/mingw-w64-tesseract-ocr)
and am able to get the pdf output from it.

ShreeDevi

---

भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Tue, Jul 28, 2015 at 9:05 AM, jbreiden notifications@github.com wrote:

> Or... do we still have some ifdefs in the code to do Windows streaming I/O
> a little differently? I vaguely remember writing some back in the day.
> Maybe they are misbehaving under Cygwin? Can't seem to find them at the
> moment.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/63#issuecomment-125427714
> .
 Just to clarify, I am referring the pdf output from tif input in the above post.
 Working with 3.04.00 packaged by Marco for cygwin

ra@Shree ~/tesseract-ocr
$ tesseract testing/phototest.tif phototest.tif
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
Page 1
Warning in pixReadMemTiff: tiff page 1 not found

ra@Shree ~/tesseract-ocr
$ tesseract testing/phototest.tif testing/phototest.tif pdf
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
Page 1
Warning in pixReadMemTiff: tiff page 1 not found

ra@Shree ~/tesseract-ocr
$ tesseract testing/phototest.tif testing/phototest.tif hocr
Tesseract Open Source OCR Engine v3.04.00 with Leptonica
Page 1
Warning in pixReadMemTiff: tiff page 1 not found

ra@Shree ~/tesseract-ocr
$ tesseract --list-langs
List of available languages (2):
eng
osd

ra@Shree ~/tesseract-ocr
$ tesseract -v
tesseract 3.04.00
 leptonica-1.72
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.3.1) : libpng 1.6.17 : libtiff 4.0.3 : zlib 1.2.8 : libwebp 0.4.3
 ra@Shree ~/tesseract-ocr/testing
$ ls -lrt
total 165
-rwx---r-x 1 ra ra  38668 Jul 29 11:45 phototest.tif
-rwx---r-x 1 ra ra 102598 Jul 29 11:45 eurotext.tif
-rw----r-- 1 ra ra   7712 Jul 29 11:47 phototest.tif.pdf
-rw----r-- 1 ra ra    287 Jul 29 11:48 phototest.tif.txt
-rw----r-- 1 ra ra   8394 Jul 29 11:48 phototest.tif.hocr
 I went into pbrush and created a Hello World image and saved it as bmp, gif, jpg, png, and tif. When I process those files using tesseract.exe imagefile textfile -l eng, all the files process correctly except the GIF file. I included the GIF and the output below:

Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
Warning in pixReadMemGif: writing to a temp file, not directly to memory
Error in fopenWriteStream: stream not opened
Error in l_binaryWrite: stream not opened
Error in fopenReadStream: file not found
Error in pixRead: image file not found: /tmp/199506_720_mem.gif
Error in pixReadMemGif: pix not read
Error in pixReadMem: gif: no pix returned
Error during processing.
![helloworld](https://cloud.githubusercontent.com/assets/11964590/18092293/6a92bfd8-6e91-11e6-8c27-2e66a0da3114.gif)

Also here is the version dump:

tesseract 3.05.00dev
 leptonica-1.73
  libgif 4.1.6(?) : libjpeg 8d (libjpeg-turbo 1.4.2) : libpng 1.6.20 : libtiff 4
.0.6 : zlib 1.2.8 : libwebp 0.4.3

If I was a guessing man I would say maybe it is in the temporary file name /tmp/199506_720_mem.gif likely not conforming to MS windows.

A little more information, looking at the pixReadMemGif routine it makes a call to get a temporary file, in doing so that routine tries to ensure that the tmp directory exists, when I created a tmp directory at the root of the drive where I am running tesseract, the GIF file correctly extracted after creating that directory. That is in the Leptonica utils.c file in the genTempFilename routine.
 Maybe leptonic is not built with gif library
- sent from my phone. excuse the brevity.

On 30-Aug-2016 7:40 PM, "LeeBear35" notifications@github.com wrote:

> I went into pbrush and created a Hello World image and saved it as bmp,
> gif, jpg, png, and tif. When I process those files using tesseract.exe
> imagefile textfile -l eng, all the files process correctly except the GIF
> file. I included the GIF and the output below:
> 
> Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
> Warning in pixReadMemGif: writing to a temp file, not directly to memory
> Error in fopenWriteStream: stream not opened
> Error in l_binaryWrite: stream not opened
> Error in fopenReadStream: file not found
> Error in pixRead: image file not found: /tmp/199506_720_mem.gif
> Error in pixReadMemGif: pix not read
> Error in pixReadMem: gif: no pix returned
> Error during processing.
> [image: helloworld]
> https://cloud.githubusercontent.com/assets/11964590/18092293/6a92bfd8-6e91-11e6-8c27-2e66a0da3114.gif
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/63#issuecomment-243451328,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o7pPyAlMmoDPBQ3BkxMC24_LqyNXks5qlDnGgaJpZM4FfEhW
> .
 After further research the issue is with the Leptonica utils.c genTempFilename method, it attempts to ensure that the tmp directory exists on the drive where the program is executing, but fails to create the directory so the resulting temp file returned cannot not be created or used. If the tmp directory is created then the GIF file is processed and extracted correctly.

I updated my post when I discovered this short coming.

Leland Carpenter ♦ Sr. Software Engineer ♦ PRGX USA, Inc.
4904 Hickory Way ♦ Johnsburg, IL 60051-8967
O: 815.307.7634 ♦ Lee.Carpenter@prgx.commailto:Lee.Carpenter@prgx.com
[cid:image001.jpg@01D202A3.3B9A04C0]

From: Shreeshrii [mailto:notifications@github.com]
Sent: Tuesday, August 30, 2016 09:41 AM
To: tesseract-ocr/tesseract tesseract@noreply.github.com
Cc: Carpenter, Lee Lee.Carpenter@prgx.com; Comment comment@noreply.github.com
Subject: Re: [tesseract-ocr/tesseract] corrupt pdf output on cygwin (#63)

Maybe leptonic is not built with gif library
- sent from my phone. excuse the brevity.

On 30-Aug-2016 7:40 PM, "LeeBear35" <notifications@github.com<mailto:notifications@github.com>> wrote:

> I went into pbrush and created a Hello World image and saved it as bmp,
> gif, jpg, png, and tif. When I process those files using tesseract.exe
> imagefile textfile -l eng, all the files process correctly except the GIF
> file. I included the GIF and the output below:
> 
> Tesseract Open Source OCR Engine v3.05.00dev with Leptonica
> Warning in pixReadMemGif: writing to a temp file, not directly to memory
> Error in fopenWriteStream: stream not opened
> Error in l_binaryWrite: stream not opened
> Error in fopenReadStream: file not found
> Error in pixRead: image file not found: /tmp/199506_720_mem.gif
> Error in pixReadMemGif: pix not read
> Error in pixReadMem: gif: no pix returned
> Error during processing.
> [image: helloworld]
> https://cloud.githubusercontent.com/assets/11964590/18092293/6a92bfd8-6e91-11e6-8c27-2e66a0da3114.gif
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/63#issuecomment-243451328,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AE2_o7pPyAlMmoDPBQ3BkxMC24_LqyNXks5qlDnGgaJpZM4FfEhW
> .

—
You are receiving this because you commented.
Reply to this email directly, view it on GitHubhttps://github.com/tesseract-ocr/tesseract/issues/63#issuecomment-243462302, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ALaQrt3vwLXo6DiUEMrtKldXWIn3hi2qks5qlEEEgaJpZM4FfEhW.
  /tmp/199506_720_mem.gif is fine for cygwin. Are you using a cygwin build without a proper directory structure ?
 @jbreiden Starting from 1.73 is following the Unix tmp path.
 Might be that I am running on the e: drive instead of the c: drive and that there was no e:\tmp, it was just a matter of the routine not swapping out the /tmp for the windows temporary directory.

Leland Carpenter ♦ Sr. Software Engineer ♦ PRGX USA, Inc.
4904 Hickory Way ♦ Johnsburg, IL 60051-8967
O: 815.307.7634 ♦ Lee.Carpenter@prgx.commailto:Lee.Carpenter@prgx.com
[cid:image001.jpg@01D2035F.0F526440]

From: jbreiden [mailto:notifications@github.com]
Sent: Tuesday, August 30, 2016 08:51 PM
To: tesseract-ocr/tesseract tesseract@noreply.github.com
Cc: Carpenter, Lee Lee.Carpenter@prgx.com; Comment comment@noreply.github.com
Subject: Re: [tesseract-ocr/tesseract] corrupt pdf output on cygwin (#63)

I have a number of tempfile patches already written for Leptonica to these calls more
secure and less brittle, and there is ongoing work on this topic. I actually don't know if
cygwin is using the Unix or Windows code path for temporary files, but just want to
mention that there is activity. Don't know why you are getting bad results compared to
other cygwin users.

https://sources.debian.net/src/leptonlib/1.73-5/debian/patches/

—
You are receiving this because you commented.
Reply to this email directly, view it on GitHubhttps://github.com/tesseract-ocr/tesseract/issues/63#issuecomment-243635600, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ALaQrkGGqG6w13z9K5OGD9_kiB2gU7J2ks5qlN4ggaJpZM4FfEhW.
  Hi,

I just tried to build the training tools using cygwin.
the normal tesseract program seems to work fine.

Thanks for helping.
you are doing all a good job and the recognizationrate is also very nice now in german texts.

that's what it was showing after typing make training:

$ make training
make[1]: Entering directory '/home/Besitzer/tesseractsrc/training'
depbase=`echo boxchar.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT boxchar.lo -MD -MP -MF $depb
ase.Tpo -c -o boxchar.lo boxchar.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT boxchar.lo -MD -MP -MF .deps/boxchar.Tpo -c boxchar.cpp -o b
oxchar.o
depbase=`echo commandlineflags.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT commandlineflags.lo -MD -MP
-MF $depbase.Tpo -c -o commandlineflags.lo commandlineflags.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT commandlineflags.lo -MD -MP -MF .deps/commandlineflags.Tpo -
c commandlineflags.cpp -o commandlineflags.o
depbase=`echo commontraining.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT commontraining.lo -MD -MP -M
F $depbase.Tpo -c -o commontraining.lo commontraining.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT commontraining.lo -MD -MP -MF .deps/commontraining.Tpo -c co
mmontraining.cpp -o commontraining.o
depbase=`echo degradeimage.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT degradeimage.lo -MD -MP -MF
$depbase.Tpo -c -o degradeimage.lo degradeimage.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT degradeimage.lo -MD -MP -MF .deps/degradeimage.Tpo -c degrad
eimage.cpp -o degradeimage.o
depbase=`echo fileio.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT fileio.lo -MD -MP -MF $depba
se.Tpo -c -o fileio.lo fileio.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT fileio.lo -MD -MP -MF .deps/fileio.Tpo -c fileio.cpp -o file
io.o
depbase=`echo ligature_table.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT ligature_table.lo -MD -MP -M
F $depbase.Tpo -c -o ligature_table.lo ligature_table.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT ligature_table.lo -MD -MP -MF .deps/ligature_table.Tpo -c li
gature_table.cpp -o ligature_table.o
depbase=`echo normstrngs.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT normstrngs.lo -MD -MP -MF $d
epbase.Tpo -c -o normstrngs.lo normstrngs.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT normstrngs.lo -MD -MP -MF .deps/normstrngs.Tpo -c normstrngs
.cpp -o normstrngs.o
depbase=`echo pango_font_info.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT pango_font_info.lo -MD -MP -
MF $depbase.Tpo -c -o pango_font_info.lo pango_font_info.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT pango_font_info.lo -MD -MP -MF .deps/pango_font_info.Tpo -c
pango_font_info.cpp -o pango_font_info.o
pango_font_info.cpp: In member function 'bool tesseract::PangoFontInfo::ParseFon
tDescription(const PangoFontDescription_)':
pango_font_info.cpp:223:46: error: 'strcasestr' was not declared in this scope
   is_fraktur_ = (strcasestr(family, "Fraktur") != NULL);
                                              ^
Makefile:875: recipe for target 'pango_font_info.lo' failed
make[1]: *_\* [pango_font_info.lo] Error 1
make[1]: Leaving directory '/home/Besitzer/tesseractsrc/training'
Makefile:880: recipe for target 'training' failed
make: **\* [training] Error 2

Besitzer@simon ~/tesseractsrc
$ make training-install
make[1]: Entering directory '/home/Besitzer/tesseractsrc/training'
depbase=`echo pango_font_info.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/sh ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -O2
 -DNDEBUG -DUSE_STD_NAMESPACE -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../cc
util -I../ccstruct -I../viewer -I../textord -I../dict -I../classify -I../display
 -I../wordrec -I../cutil -I../vs2010/port -I/usr/include/leptonica -D_REENTRANT
-I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include  -I
/usr/include/cairo -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/in
clude/pixman-1 -I/usr/include/freetype2 -I/usr/include/libpng16 -I/usr/include/f
reetype2 -I/usr/include/libpng16   -std=gnu++11 -MT pango_font_info.lo -MD -MP -
MF $depbase.Tpo -c -o pango_font_info.lo pango_font_info.cpp &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -O2 -DNDEBUG -DUSE_STD_NAMESPACE
 -DPANGO_ENABLE_ENGINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewe
r -I../textord -I../dict -I../classify -I../display -I../wordrec -I../cutil -I..
/vs2010/port -I/usr/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 -I/u
sr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/cairo -I/usr/incl
ude/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/
freetype2 -I/usr/include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng
16 -std=gnu++11 -MT pango_font_info.lo -MD -MP -MF .deps/pango_font_info.Tpo -c
pango_font_info.cpp -o pango_font_info.o
pango_font_info.cpp: In member function 'bool tesseract::PangoFontInfo::ParseFon
tDescription(const PangoFontDescription_)':
pango_font_info.cpp:223:46: error: 'strcasestr' was not declared in this scope
   is_fraktur_ = (strcasestr(family, "Fraktur") != NULL);
                                              ^
Makefile:875: recipe for target 'pango_font_info.lo' failed
make[1]: *_\* [pango_font_info.lo] Error 1
make[1]: Leaving directory '/home/Besitzer/tesseractsrc/training'
Makefile:882: recipe for target 'training-install' failed
make: **\* [training-install] Error 2

Besitzer@simon ~/tesseractsrc
$
 Just tested it with the recent merged pull request.
this is what i get with make training:

g++ -DHAVE_CONFIG_H -I. -I..  -O2 -DNDEBUG -DUSE_STD_NAMESPACE 
-DPANGO_ENABLE_EN
GINE -I../ccmain -I../api -I../ccutil -I../ccstruct -I../viewer 
-I../textord -I.
./dict -I../classify -I../display -I../wordrec -I../cutil 
-I../vs2010/port -I/us
r/include/leptonica -D_REENTRANT -I/usr/include/pango-1.0 
-I/usr/include/glib-2.
0 -I/usr/lib/glib-2.0/include  -I/usr/include/cairo 
-I/usr/include/glib-2.0 -I/u
sr/lib/glib-2.0/include -I/usr/include/pixman-1 -I/usr/include/freetype2 
-I/usr/
include/libpng16 -I/usr/include/freetype2 -I/usr/include/libpng16 
-std=gnu++11
  -MT set_unicharset_properties.o -MD -MP -MF $depbase.Tpo -c -o 
set_unicharset_p
roperties.o set_unicharset_properties.cpp &&\
mv -f $depbase.Tpo $depbase.Po
/bin/sh ../libtool  --tag=CXX   --mode=link g++  -std=gnu++11 
-Wl,-no-undefined
-Wl,--as-needed   -o set_unicharset_properties.exe 
set_unicharset_properties.o l
ibtesseract_training.la libtesseract_tessopt.la -licuin -licuuc 
../api/libtesse
ract.la -lws2_32  -llept
libtool: link: g++ -std=gnu++11 -Wl,-no-undefined -Wl,--as-needed -o 
set_unichar
set_properties.exe set_unicharset_properties.o 
./.libs/libtesseract_training.a
./.libs/libtesseract_tessopt.a -licuin -licuuc 
../api/.libs/libtesseract.a -lws2
_32 -llept
/usr/lib/gcc/i686-pc-cygwin/4.9.3/../../../../i686-pc-cygwin/bin/ld: 
cannot find
  -licuin
collect2: error: ld returned 1 exit status
Makefile:805: recipe for target 'set_unicharset_properties.exe' failed
make[1]: **\* [set_unicharset_properties.exe] Error 1
make[1]: Leaving directory '/home/Besitzer/tesseractsrc/training'
Makefile:880: recipe for target 'training' failed
make: **\* [training] Error 2

Am 23.07.2015 um 23:31 schrieb Jim Regan:

> Can you try the patch in #60 to see if that fixes it?
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/tesseract-ocr/tesseract/issues/61#issuecomment-124245368

## 

Simon Eigeldinger
Follow me on Twitter: http://www.twitter.com/domasofan/
E-Mail: simon.eigeldinger@vol.at
MSN: simon_eigeldinger@hotmail.com
ICQ: 121823966
Jabber: domasofan@andrelouis.com
 Hi,

yeah its icui18n.
there seem to be 2 versions.
5.4 and 5.5.

greetings,
simon

Am 24.07.2015 um 01:07 schrieb Jim Regan:

> Sorry, it only complained about one of the ICU libraries.
> 
> I think that the problem is that the library is named 'libicui18n' under Cygwin, as it is on Linux etc.
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/tesseract-ocr/tesseract/issues/61#issuecomment-124262453

## 

Simon Eigeldinger
Follow me on Twitter: http://www.twitter.com/domasofan/
E-Mail: simon.eigeldinger@vol.at
MSN: simon_eigeldinger@hotmail.com
ICQ: 121823966
Jabber: domasofan@andrelouis.com
 Hi,

i guess that looks good now.

we have:
ambiguous_words.exe
classifier_tester.exe
cntraining.exe
combine_tessdata.exe
dawg2wordlist.exe
mftraining.exe
set_unicharset_properties.exe
shapeclustering.exe
tesseract.exe
text2image.exe
unicharset_extractor.exe
wordlist2dawg.exe

thanks.
greetings,
simon

Am 24.07.2015 um 01:18 schrieb Jim Regan:

> Can you try with the patch from #62 ?
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/tesseract-ocr/tesseract/issues/61#issuecomment-124264086

## 

Simon Eigeldinger
Follow me on Twitter: http://www.twitter.com/domasofan/
E-Mail: simon.eigeldinger@vol.at
MSN: simon_eigeldinger@hotmail.com
ICQ: 121823966
Jabber: domasofan@andrelouis.com
 thanks.
thanks for fixing. :-)

Am 24.07.2015 um 08:45 schrieb Jim Regan:

> Ok, I'll close this. Thanks for testing!
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/tesseract-ocr/tesseract/issues/61#issuecomment-124357848

## 

Simon Eigeldinger
Follow me on Twitter: http://www.twitter.com/domasofan/
E-Mail: simon.eigeldinger@vol.at
MSN: simon_eigeldinger@hotmail.com
ICQ: 121823966
Jabber: domasofan@andrelouis.com
  the solution is wrong. As strcasestr is not standard,  it is enough to

#define _GNU_SOURCE
before 
#include <string.h>
  https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/tesseract-dev/XllxjvK5HtU/C4mebS6lcJoJ

Jeff suggested that users create a myconfig file. I think it will be useful to actually provide the configuration as 'pdftxt' .
# 

tessedit_create_txt 1
tessedit_create_pdf 1
# 

Then make sure that you invoke the command line such that 
Tesseract writes to files instead of stdout, e.g. 

```
tesseract myimage.tif myoutput pdftxt
```

This will read myimage.tif and pdftxt (config file), and produce myoutput.pdf and myoutput.txt
 Zdenko also has same opinion. So you can close the issue.

I'll add to FAQ if that is ok.
- sent from my phone. excuse the brevity.
  On 22 Jul 2015 19:34, "Jim Regan" notifications@github.com wrote:

> Not generally useful, IMO - I don't see there being a whole lot of demand
> for this.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/issues/59#issuecomment-123733447
> .
  i have success install tesseract , 
tesseract 3.02.02
 leptonica-1.71
  libjpeg 6b : libpng 1.2.49 : zlib 1.2.8

and my libtiff locate in /usr/lib64
locate libtiff
/usr/lib64/libtiff.so.3
/usr/lib64/libtiff.so.3.9.4
/usr/lib64/libtiffxx.so.3
/usr/lib64/libtiffxx.so.3.9.4

so i add  ~/.bash_profile  with
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib:/usr/lib64 
and relogin.

but the error still there:  
Tesseract Open Source OCR Engine v3.02.02 with Leptonica
Error in findTiffCompression: function not present
Error in pixReadStreamTiff: function not present
Error in pixReadStream: tiff: no pix returned
Error in pixRead: pix not read
Unsupported image type.

how i solve it ? thx alot
 i have tried leptonica-1.71/1.72 ,  both have same error.
should i use early leptonica ,   which version of leptonica  is compatible ？
thx
  I have no idea what the box.train config is supposed to do, or what 
missing data it needs. I just don't like segfaults.

```
(gdb) run testing/phototest.tif - box.train
Starting program: /tmp/plang/tesseract-3.04.00/api/.libs/lt-tesseract testing/phototest.tif - box.train
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Page 1

Program received signal SIGSEGV, Segmentation fault.
0x00007ffff760fe94 in ELIST_ITERATOR::set_to_list (this=0x7fffffffd3e0, list_to_iterate=0x8) at ../ccutil/elst.h:308
308   prev = list->last;
(gdb) backtrace
#0  0x00007ffff760fe94 in ELIST_ITERATOR::set_to_list (this=0x7fffffffd3e0, list_to_iterate=0x8)
    at ../ccutil/elst.h:308
#1  0x00007ffff77dd367 in PAGE_RES_IT::start_page (this=0x7fffffffd390, empty_ok=false) at pageres.cpp:1510
#2  0x00007ffff76116c7 in PAGE_RES_IT::restart_page (this=0x7fffffffd390) at ../ccstruct/pageres.h:681
#3  0x00007ffff76116a7 in PAGE_RES_IT::PAGE_RES_IT (this=0x7fffffffd390, the_page_res=0x0) at ../ccstruct/pageres.h:665
#4  0x00007ffff761e84f in tesseract::Tesseract::ApplyBoxTraining (this=0x808c00, fontname=..., page_res=0x0)
    at applybox.cpp:780
#5  0x00007ffff7609478 in tesseract::TessBaseAPI::Recognize (this=0x7fffffffd9f0, monitor=0x0) at baseapi.cpp:883
#6  0x00007ffff760a4d9 in tesseract::TessBaseAPI::ProcessPage (this=0x7fffffffd9f0, pix=0x83fa10, page_index=0, 
    filename=0x7fffffffe883 "testing/phototest.tif", retry_config=0x0, timeout_millisec=0, renderer=0x13850f0)
    at baseapi.cpp:1222
#7  0x00007ffff7609d4e in tesseract::TessBaseAPI::ProcessPagesMultipageTiff (this=0x7fffffffd9f0, 
    data=0x138fc08 "II*", size=38668, filename=0x7fffffffe883 "testing/phototest.tif", retry_config=0x0, 
    timeout_millisec=0, renderer=0x13850f0, tessedit_page_number=-1) at baseapi.cpp:1057
#8  0x00007ffff760a29b in tesseract::TessBaseAPI::ProcessPagesInternal (this=0x7fffffffd9f0, 
    filename=0x7fffffffe883 "testing/phototest.tif", retry_config=0x0, timeout_millisec=0, renderer=0x13850f0)
    at baseapi.cpp:1176
#9  0x00007ffff7609dc5 in tesseract::TessBaseAPI::ProcessPages (this=0x7fffffffd9f0, 
    filename=0x7fffffffe883 "testing/phototest.tif", retry_config=0x0, timeout_millisec=0, renderer=0x13850f0)
    at baseapi.cpp:1074
#10 0x00000000004031a3 in main (argc=4, argv=0x7fffffffe5f8) at tesseractmain.cpp:316
...
```
 Tesseract should return an error when there is insufficient input, not segfault.
 Pretty good! But even more robust is to locate the lower level function that is crashing
due to bad data. Then modify it to return an error instead of crashing. That protects us 
even if it gets called from a different code path.
 ```
TESSDATA_PREFIX=/usr/share/tesseract-ocr  valgrind api/.libs/lt-tesseract testing/phototest.tif testing/phototest.tif - box.train
==11666== Memcheck, a memory error detector
==11666== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al.
==11666== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info
==11666== Command: api/.libs/lt-tesseract testing/phototest.tif testing/phototest.tif - box.train
==11666== 
Tesseract Open Source OCR Engine v3.05.00dev-11-gd937659 with Leptonica
Page 1
==11666== Invalid read of size 8
==11666==    at 0x4FA8E9C: ELIST_ITERATOR::set_to_list(ELIST*) (elst.h:308)
==11666==    by 0x514C108: PAGE_RES_IT::start_page(bool) (pageres.cpp:1510)
==11666==    by 0x4FAA6CE: PAGE_RES_IT::restart_page() (pageres.h:681)
==11666==    by 0x4FAA6AE: PAGE_RES_IT::PAGE_RES_IT(PAGE_RES*) (pageres.h:665)
==11666==    by 0x4FB781E: tesseract::Tesseract::ApplyBoxTraining(STRING const&, PAGE_RES*) (applybox.cpp:797)
==11666==    by 0x4FA2477: tesseract::TessBaseAPI::Recognize(ETEXT_DESC*) (baseapi.cpp:883)
==11666==    by 0x4FA34D8: tesseract::TessBaseAPI::ProcessPage(Pix*, int, char const*, char const*, int, tesseract::TessResultRenderer*) (baseapi.cpp:1222)
==11666==    by 0x4FA2D4D: tesseract::TessBaseAPI::ProcessPagesMultipageTiff(unsigned char const*, unsigned long, char const*, char const*, int, tesseract::TessResultRenderer*, int) (baseapi.cpp:1057)
==11666==    by 0x4FA329A: tesseract::TessBaseAPI::ProcessPagesInternal(char const*, char const*, int, tesseract::TessResultRenderer*) (baseapi.cpp:1176)
==11666==    by 0x4FA2DC4: tesseract::TessBaseAPI::ProcessPages(char const*, char const*, int, tesseract::TessResultRenderer*) (baseapi.cpp:1074)
==11666==    by 0x403192: main (tesseractmain.cpp:318)
==11666==  Address 0x8 is not stack'd, malloc'd or (recently) free'd
==11666== 
==11666== 
==11666== Process terminating with default action of signal 11 (SIGSEGV)
==11666==  Access not within mapped region at address 0x8
==11666==    at 0x4FA8E9C: ELIST_ITERATOR::set_to_list(ELIST*) (elst.h:308)
==11666==    by 0x514C108: PAGE_RES_IT::start_page(bool) (pageres.cpp:1510)
==11666==    by 0x4FAA6CE: PAGE_RES_IT::restart_page() (pageres.h:681)
==11666==    by 0x4FAA6AE: PAGE_RES_IT::PAGE_RES_IT(PAGE_RES*) (pageres.h:665)
==11666==    by 0x4FB781E: tesseract::Tesseract::ApplyBoxTraining(STRING const&, PAGE_RES*) (applybox.cpp:797)
==11666==    by 0x4FA2477: tesseract::TessBaseAPI::Recognize(ETEXT_DESC*) (baseapi.cpp:883)
==11666==    by 0x4FA34D8: tesseract::TessBaseAPI::ProcessPage(Pix*, int, char const*, char const*, int, tesseract::TessResultRenderer*) (baseapi.cpp:1222)
==11666==    by 0x4FA2D4D: tesseract::TessBaseAPI::ProcessPagesMultipageTiff(unsigned char const*, unsigned long, char const*, char const*, int, tesseract::TessResultRenderer*, int) (baseapi.cpp:1057)
==11666==    by 0x4FA329A: tesseract::TessBaseAPI::ProcessPagesInternal(char const*, char const*, int, tesseract::TessResultRenderer*) (baseapi.cpp:1176)
==11666==    by 0x4FA2DC4: tesseract::TessBaseAPI::ProcessPages(char const*, char const*, int, tesseract::TessResultRenderer*) (baseapi.cpp:1074)
==11666==    by 0x403192: main (tesseractmain.cpp:318)
```
 make
make install
gdb /usr/local/bin/tesseract
(gdb) run testing/phototest.tif - box.train

```
Program received signal SIGSEGV, Segmentation fault.
PAGE_RES_IT::start_page (this=this@entry=0x7fffffffde10, empty_ok=empty_ok@entry=false) at pageres.cpp:1510
1510      block_res_it.set_to_list(&page_res->block_res_list);
(gdb) backtrace
#0  PAGE_RES_IT::start_page (this=this@entry=0x7fffffffde10, empty_ok=empty_ok@entry=false) at pageres.cpp:1510
#1  0x00007ffff76e6f29 in restart_page (this=0x7fffffffde10) at ../ccstruct/pageres.h:681
#2  PAGE_RES_IT (the_page_res=<optimized out>, this=0x7fffffffde10) at ../ccstruct/pageres.h:665
#3  tesseract::Tesseract::ApplyBoxTraining (this=0x819810, fontname=..., page_res=<optimized out>) at applybox.cpp:797
#4  0x00007ffff76dd926 in tesseract::TessBaseAPI::Recognize (this=this@entry=0x7fffffffe450, monitor=monitor@entry=0x0) at baseapi.cpp:883
#5  0x00007ffff76ddc2a in tesseract::TessBaseAPI::ProcessPage (this=0x7fffffffe450, pix=0x84fd10, page_index=<optimized out>, filename=<optimized out>, 
    retry_config=0x0, timeout_millisec=0, renderer=0x0) at baseapi.cpp:1224
#6  0x00007ffff76de10b in tesseract::TessBaseAPI::ProcessPagesMultipageTiff (this=0x7fffffffe450, data=0x0, data@entry=0x13a0828 "II*", size=8, filename=0x0, 
    filename@entry=0x7fffffffe85a "testing/phototest.tif", retry_config=retry_config@entry=0x0, timeout_millisec=20909344, timeout_millisec@entry=0, 
    renderer=0x0, tessedit_page_number=-1) at baseapi.cpp:1057
#7  0x00007ffff76de5fe in tesseract::TessBaseAPI::ProcessPagesInternal (this=this@entry=0x7fffffffe450, filename=<optimized out>, 
    retry_config=retry_config@entry=0x0, timeout_millisec=timeout_millisec@entry=0, renderer=0x0) at baseapi.cpp:1176
#8  0x00007ffff76dea40 in tesseract::TessBaseAPI::ProcessPages (this=this@entry=0x7fffffffe450, filename=<optimized out>, 
    retry_config=retry_config@entry=0x0, timeout_millisec=timeout_millisec@entry=0, renderer=<optimized out>) at baseapi.cpp:1074
#9  0x0000000000401dff in main (argc=<optimized out>, argv=0x7fffffffe5e8) at tesseractmain.cpp:432
```
 I'd suggest something like this. I didn't check to see if we leak memory
if we go down this error path, but no matter what it is better than a segfault.

``` diff
--- baseapi.cpp.orig    2016-02-04 01:09:07.790101916 +0000
+++ baseapi.cpp 2016-02-04 01:07:15.464620603 +0000
@@ -851,6 +851,9 @@
     page_res_ = new PAGE_RES(false,
                              block_list_, &tesseract_->prev_word_best_choice_);
   }
+  if (page_res_ == NULL) {
+    return -1;
+  }
   if (tesseract_->tessedit_make_boxes_from_boxes) {
     tesseract_->CorrectClassifyWords(page_res_);
     return 0;
```
  Hardware is a Ubuntu 14.04 laptop with integrated Intel graphics.

```
./configure --enable-opencl --enable-debug
...
gdb api/.libs/lt-tesseract

(gdb) run testing/phototest.tif -

Starting program: api/.libs/lt-tesseract testing/phototest.tif -
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
[DS] Profile file not available (tesseract_opencl_profile_devices.dat); performing profiling.

Program received signal SIGSEGV, Segmentation fault.
strlen () at ../sysdeps/x86_64/strlen.S:106
106 ../sysdeps/x86_64/strlen.S: No such file or directory.
(gdb) backtrace
#0  strlen () at ../sysdeps/x86_64/strlen.S:106
#1  0x00007ffff77fe549 in writeProfileToFile (profile=0x81c810, 
    serializer=0x7ffff780752f <serializeScore(ds_device*, void**, unsigned int*)>, file=0x7ffff78aa5e0 "tesseract_opencl_profile_devices.dat")
    at opencl_device_selection.h:268
#2  0x00007ffff7807a09 in OpenclDevice::getDeviceSelection ()
    at openclwrapper.cpp:3427
#3  0x00007ffff7800356 in OpenclDevice::InitOpenclRunEnv_DeviceSelection (
    argc=0) at openclwrapper.cpp:527
#4  0x00007ffff7800074 in OpenclDevice::InitEnv () at openclwrapper.cpp:431
#5  0x00007ffff75f01af in tesseract::TessBaseAPI::Init (this=0x7fffffffda40, 
    datapath=0x0, language=0x405a13 "eng", oem=tesseract::OEM_DEFAULT, 
    configs=0x7fffffffe6a0, configs_size=0, vars_vec=0x7fffffffda00, 
    vars_values=0x7fffffffda20, set_only_non_debug_params=false)
    at baseapi.cpp:299
#6  0x0000000000404317 in main (argc=3, argv=0x7fffffffe688)
    at tesseractmain.cpp:181
...
```
 Ray says,

I think there is a bug in InitDSProfile.

I suspect if you change if (status == SUCCESS) to if (status == SUCCESS && profile->numDevices > 0)
at openclwrapper.cpp:3426
then it will work. (You have no devices, and unlike the code here: https://docs.libreoffice.org/opencl/html/opencl__device__selection_8h_source.html
it doesn't correctly always add the native CPU as a device, and therefore attempts to write a null buffer, even though it has no devices.)
 still trouble
 note that if we get through this, I will probably enable OpenCL by default for Debian/Ubuntu
 I'm in stuck. How this code (located at oclkernels.h:1086) can work:

```
pixels.v[i] = imageData[
    w*(BURSTS_PER_WORD*(PIXELS_PER_BURST*NUM_CHANNELS)/CHAR_VEC_WIDTH) + 
    b*((PIXELS_PER_BURST*NUM_CHANNELS)/CHAR_VEC_WIDTH)  + i];
```

where maximum value of index can be 4x higher that size of imageData array
Variables are:
w in range [0 .. count of DWORDS in image), 
b in range [0 .. BURSTS_PER_WORD),
i in range [0 .. (PIXELS_PER_BURST*NUM_CHANNELS)/CHAR_VEC_WIDTH )
Constants values:

```
#define NUM_CHANNELS 4
#define CHAR_VEC_WIDTH 8
#define PIXELS_PER_WORD 32
#define PIXELS_PER_BURST 8
#define BURSTS_PER_WORD (PIXELS_PER_WORD/PIXELS_PER_BURST)
```
 I get a similar looking segfault (but I didn't confirm with gdb) even on a computer that contains a discrete graphics card. Is OpenCL working for anyone at all?
 I can't get fully worked OpenCL configuration. But I have a much different environment (without any other dependencies except leptonica). I've got errors like:
`Access violation reading location 0x58B87000`
That's a position after imageData host's buffer. 
 Just made a bit changes to exclude libtiff dependency.
I have my own input and output streams.
I see, that I can't request any attention without prepare reproducible error in your environment.
 spSerg: you can request attention, but if we can't reproduce you need to supply more information, such as a backtrace from gdb or the output of valgrind (either works much better when ./configure is run with --enable-debug)
 I'm having an unexpectedly hard time with this.
 ```
#0  strlen () at ../sysdeps/x86_64/strlen.S:106
#1  0x00007ffff77d3c5f in writeProfileToFile (profile=0x80ac20, 
    serializer=0x7ffff77dcc45 <serializeScore(ds_device*, void**, unsigned int*)>, 
    file=0x7ffff78a0b20 "tesseract_opencl_profile_devices.dat") at opencl_device_selection.h:268
#2  0x00007ffff77dd11f in OpenclDevice::getDeviceSelection () at openclwrapper.cpp:3427
#3  0x00007ffff77d5a6c in OpenclDevice::InitOpenclRunEnv_DeviceSelection (argc=0) at openclwrapper.cpp:527
#4  0x00007ffff77d578a in OpenclDevice::InitEnv () at openclwrapper.cpp:431
#5  0x00007ffff75efb2f in tesseract::TessBaseAPI::Init (this=0x7fffffffd9f0, datapath=0x0, 
    language=0x405a13 "eng", oem=tesseract::OEM_DEFAULT, configs=0x7fffffffe650, configs_size=0, 
    vars_vec=0x7fffffffd9b0, vars_values=0x7fffffffd9d0, set_only_non_debug_params=false) at baseapi.cpp:299
#6  0x0000000000404327 in main (argc=3, argv=0x7fffffffe638) at tesseractmain.cpp:181
```
  hi Team ,
      we can't able to figure it out ,why we are getting this below error while linking. but, it compiles fine.;

version's : tesseract304 , leptonica-1.72, liblept168d.lib + other libs (got it from leptonica-1.68-win32-lib-include-dirs.zip ), visual studio 2010.

plz help us to resolve this issue..plz...

Error details :-
Error   1   error LNK2019: unresolved external symbol __imp__l_CIDataDestroy referenced in function "private: static bool __cdecl tesseract::TessPDFRenderer::imageToPDFObj(struct Pix *,char *,long,char \* *,long *)" (?imageToPDFObj@TessPDFRenderer@tesseract@@CA_NPAUPix@@PADJPAPADPAJ@Z)   D:\tesseract-master\vs2010\libtesseract\pdfrenderer.obj libtesseract304
Error   2   error LNK2019: unresolved external symbol __imp__l_generateCIDataForPdf referenced in function "private: static bool __cdecl tesseract::TessPDFRenderer::imageToPDFObj(struct Pix *,char *,long,char \* *,long *)" (?imageToPDFObj@TessPDFRenderer@tesseract@@CA_NPAUPix@@PADJPAPADPAJ@Z)    D:\tesseract-master\vs2010\libtesseract\pdfrenderer.obj libtesseract304
Error   3   error LNK2019: unresolved external symbol __imp__pixGenerateCIData referenced in function "private: static bool __cdecl tesseract::TessPDFRenderer::imageToPDFObj(struct Pix *,char *,long,char \* *,long *)" (?imageToPDFObj@TessPDFRenderer@tesseract@@CA_NPAUPix@@PADJPAPADPAJ@Z) D:\tesseract-master\vs2010\libtesseract\pdfrenderer.obj libtesseract304
Error   4   error LNK2019: unresolved external symbol __imp__pixSetSpp referenced in function "private: static bool __cdecl tesseract::TessPDFRenderer::imageToPDFObj(struct Pix *,char *,long,char \* *,long *)" (?imageToPDFObj@TessPDFRenderer@tesseract@@CA_NPAUPix@@PADJPAPADPAJ@Z) D:\tesseract-master\vs2010\libtesseract\pdfrenderer.obj libtesseract304
Error   5   error LNK2019: unresolved external symbol __imp__pixGetSpp referenced in function "private: static bool __cdecl tesseract::TessPDFRenderer::imageToPDFObj(struct Pix *,char *,long,char \* *,long *)" (?imageToPDFObj@TessPDFRenderer@tesseract@@CA_NPAUPix@@PADJPAPADPAJ@Z) D:\tesseract-master\vs2010\libtesseract\pdfrenderer.obj libtesseract304
Error   6   error LNK2019: unresolved external symbol __imp__pixForegroundFraction referenced in function "protected: float __thiscall tesseract::EquationDetect::ComputeForegroundDensity(class TBOX const &)" (?ComputeForegroundDensity@EquationDetect@tesseract@@IAEMABVTBOX@@@Z)   D:\tesseract-master\vs2010\libtesseract\equationdetect.obj  libtesseract304
Error   7   error LNK2019: unresolved external symbol __imp__pixaConvertToPdf referenced in function "public: static void __cdecl tesseract::LineFinder::FindAndRemoveLines(int,bool,struct Pix *,int *,int *,struct Pix \* *,class tesseract::TabVector_LIST *,class tesseract::TabVector_LIST *)" (?FindAndRemoveLines@LineFinder@tesseract@@SAXH_NPAUPix@@PAH2PAPAU3@PAVTabVector_LIST@2@4@Z) D:\tesseract-master\vs2010\libtesseract\linefind.obj    libtesseract304
Error   8   error LNK1120: 7 unresolved externals   D:\tesseract-master\vs2010\DLL_Debug\libtesseract304d.dll   libtesseract304
  The file itself already contained a reference to the new name.
 Oops.

Do you want me to teach automake not to require existence of README;
or just fix the URL in the file?
  Hi, every one

I cross compile the static library of tesseract and iam getting this error when build:

![captura de pantalla de 2015-07-10 09 42 35](https://cloud.githubusercontent.com/assets/4372141/8620905/40bf6540-26e8-11e5-8e62-705e0081e02c.png)

anyone know what is the problem?

Thanks in advance, regards.
  At least as a template parameter.

``` cpp
  GenericVector<UnicharRating>
```
 It's another fix of https://github.com/tesseract-ocr/tesseract/commit/cdc84a5dd79b20beae9dd0a2400211630f361916
 Something like this:
<code>
OCRLib.Win32.lib(adaptmatch.obj) : error LNK2001: unresolved external symbol "public: virtual int __thiscall tesseract::ShapeClassifier::UnicharClassifySample(class tesseract::TrainingSample const &,struct Pix ,int,int,class GenericVector&lt;class tesseract::UnicharRating&gt; )" (?UnicharClassifySample@ShapeClassifier@tesseract@@UAEHABVTrainingSample@2@PAUPix@@HHPAV?$GenericVector@VUnicharRating@tesseract@@@@@Z)
</code>
or this:
<code>
OCRLib.Win32.lib(tessclassifier.obj) : error LNK2019: unresolved external symbol "public: int thiscall tesseract::Classify::CharNormTrainingSample(bool,int,class tesseract::TrainingSample const &,class GenericVector&lt;struct tesseract::UnicharRating&gt; *)" (?CharNormTrainingSample@Classify@tesseract@@QAEH_NHABVTrainingSample@2@PAV?$GenericVector@UUnicharRating@tesseract@@@@@Z) referenced in function "public: virtual int thiscall tesseract::TessClassifier::UnicharClassifySample(class tesseract::TrainingSample const &,struct Pix ,int,int,class GenericVector&lt;struct tesseract::UnicharRating&gt; )" (?UnicharClassifySample@TessClassifier@tesseract@@UAEHABVTrainingSample@2@PAUPix@@HHPAV?$GenericVector@UUnicharRating@tesseract@@@@@Z)
</code>
 <code>UnicharRating</code> is a structure. But such forward declaration as a class will confuse MS compiler in parameter of template.
  I'm trying to reproduce results achieved at the ICDAR page segmentation competitions [1,2] with tesseract. I'm struggling to get the tool to output the hOCR tags that I'm expecting for tables and figures etc [3]. At the moment I'm calling tesseract with pagesegmode 1. Should I be adding other options via a config file to achieve the full extent of tesseracts segmentation and labelling ability (I'm not interested in the character recognition element as much).
1. Antonacopoulos (2013, ICDAR) ICDAR2013 Competition on Historical Book Recognition – HBR2013
2. Antonacopoulos (2013, ICDAR) ICDAR2013 Competition on Historical Newspaper Layout Analysis – HNLA2013
3. Breuel (2010) The hOCR Embedded OCR Workflow and Output Format
 You can use the C-API to only retrieve the page segmentation without doing character recognition. Use TessBaseAPISetPageSegMode to set the segmentation mode, call TessBaseAPIProcessPages, and finally retrieve the page iterator using TessBaseAPIAnalyseLayout. Iterate using the TessPageIteratorNext function at the lowest level and check with TessPageIteratorIsAtBeginningOf if the current symbol is at the start of a new block. All in all it shouldn't be more than a few lines of C code and you're skipping the recognition part of tesseract completely.
 @zdenop thank's for clarifying. Here is the link to my forum post (which contains another answer): https://groups.google.com/forum/#!topic/tesseract-ocr/1Frh-5ggNxg
 @jimregan Cheers! I'm reproducing your answer on the linked forum page (the preferred help location).
  The same issue is reported in https://code.google.com/p/tesseract-ocr/issues/detail?can=2&start=0&num=100&q=&colspec=ID%20Type%20Status%20Priority%20Milestone%20Owner%20Summary&groupby=&sort=&id=1307

But the problem is still exists and the ticket is closed.

I got the error during compiling.

The error is:
libtool: link: g++ -std=c++11 -o .libs/tesseract tesseract-tesseractmain.o  ./.libs/libtesseract.so -lrt -llept -lpthread
 ./.libs/libtesseract.so: undefined reference to `l_generateCIDataForPdf'
 ./.libs/libtesseract.so: undefined reference to`l_CIDataDestroy'

---

tesseract -v
tesseract 3.03
 leptonica-1.72
##   libjpeg 8d (libjpeg-turbo 1.3.0) : libpng 1.2.50 : libtiff 4.0.3 : zlib 1.2.8

And here is the deb package I installed:
      "autoconf",
      "automake",
      "libtool",
      "libpng12-dev",
      "libjpeg-turbo8-dev",
      "g++",
      "libtiff5-dev",
      "libopencv-dev",
      "libopencv-objdetect-dev",
      "libopencv-highgui-dev",
      "libopencv-legacy-dev",
      "libopencv-contrib-dev",
      "libopencv-videostab-dev",
      "libopencv-superres-dev",
      "libopencv-ocl-dev",
      "libcv-dev",
      "libhighgui-dev",
      "libcvaux-dev",
      "libtesseract-dev",
      "git",
      "cmake",
      "build-essential",
      "libleptonica-dev",
      "liblog4cplus-dev",
      "libcurl3-dev",
      "python2.7-dev",
      "tk8.5",
      "tcl8.5",
      "tk8.5-dev",
      "tcl8.5-dev",
      "imagemagick"

I basically follow the instruction in https://realpython.com/blog/python/setting-up-a-simple-ocr-server/

Please help. Thanks.
 Thanks for you quick response. My bad, I assume the lib will be ready after configure. Anyway, for the future reference, since we have to compile leptonica in ubuntu 14.04, we should use `LDFLAGS="-L/usr/local/lib" CFLAGS="-I/usr/local/include" make` instead of make.

Then the problem will be resolved.

Thanks.
 Hi,
I am using tesseract-3.04.00 and for leptonica i tried both with 1.72 & 1.71.Still i get the below mentioned issue:-
./.libs/libtesseract.so: undefined reference to `l_generateCIDataForPdf'
./.libs/libtesseract.so: undefined reference to`l_CIDataDestroy'

Request help on this.
 Sorry for the inconvenience.Was able to resolve the issue.Thanks.
 How did you resolve it?
 Yes, how did you solve it @Sayanava ?
 I removed previous 3.03 and re-install 3.04 from scratch. It works.   What steps will reproduce the problem?
1. Try to recognize the attached image with Cube mode. Whitelist is '0123456789'. The result is wrong. It's 1234669890 (6 instead of 5, 9 instead of 7).
2. Try to recognize the same image with Combined mode. There is a crach with the following error:
init_cube_objects(true, &tessdata_manager):Error:Assert failed:in file tessedit.cpp, line 203
[1]    5562 abort      tesseract image_sample.jpg stdout -l rus rus-test
It seems that it happens with eng locale as well as with the rus loc.

What is the expected output? What do you see instead?
In both cases the output should be 1234567890.

What version of the product are you using? On what operating system?
I've tried tesseract 3.03 both on mac and iOS.

Please provide any additional information below.
There is a related thread in the Tesseract-OCR-iOS wrapper, where the issue was originally found: https://github.com/gali8/Tesseract-OCR-iOS/issues/140. You may ask for any additional info there.

![image_sample](https://cloud.githubusercontent.com/assets/462439/8406256/45b02176-1e63-11e5-9157-4084f9b32ddd.jpg)
 @zdenop Since Cube is going away, perhaps this can be closed?
 How Cube is being discontinued, it's training procedure has not been published to the public.
Somehow I got the feeling that Cube was purposely sabotaged and hindered from the public.  
 The new LSTM based engine is here.

@theraysmith, I see that the Cube engine is still present in the code. Are you going to drop it in the final 4.0 release? @theraysmith

Since the hardware requirements for 4.0 are going to be higher than for 3.xx versions, it will be good to keep Hindi cube+tesseract version also available. 

The accuracy results that you are mentioning for Hindi are for which version - 3.02, 3.03, 3.04 ?   And what about the language model used for the test? Is it already available so I can use it for my own tests? > I'm going to push the data files now.

Got the first ones. My first test with a simple screenshot gave significant better results with LSTM, but needed 16 minutes CPU time (instead of 9 seconds) with a debug build of Tesseract (-O0). A release build (-O2) needs 17 seconds with LSTM, 4 seconds without for the same image.

Are there also new data files planned for old German (deu_frak)? I was surprised that the default English model with LSTM could recognize some words.  1. Is there a 3.04 vs 4.0 branch in tessdata for the traineddata files?

2. Stefan, please share the binaries for 4.0 alpha for Windows. I am
interested in trying the hindi and other indian languages traineddata.
Thanks.

On 29-Nov-2016 5:18 AM, "theraysmith" <notifications@github.com> wrote:

> On Mon, Nov 28, 2016 at 1:49 PM, Stefan Weil <notifications@github.com>
> wrote:
>
> > I'm going to push the data files now.
> >
> > Got the first ones. My first test with a simple screenshot gave
> > significant better results with LSTM, but needed 16 minutes CPU time
> > (instead of 9 seconds) with a debug build of Tesseract (-O0). A release
> > build (-O2) needs 17 seconds with LSTM, 4 seconds without for the same
> > image.
> >
> The slow speed with debug is to be expected. The new code is much more
> memory intensive, so it is a lot slower on debug (also openmp is turned off
> by choice on debug).
> The optimized build speed sounds about right for Latin-based languages. It
> is the complex scripts that will run faster relative to base Tesseract.
>
> > Are there also new data files planned for old German (deu_frak)? I was
> > surprised that the default English model with LSTM could recognize some
> > words.
> >
> I don't think I generated the original deu_frak. I have the fonts to do so
> with LSTM, but I don't know if I have a decent amount of corpus data to
> hand. With English at least, the language was different in the days of
> Fraktur (Ye Olde shoppe). I know German continued to be written in Fraktur
> until the 1940s, so that might be easier. Or is there an old German that is
> analogous to Ye Old Shoppe for English?
>
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tesseract-ocr/tesseract/issues/40#
> issuecomment-263405208>,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AL056Ti1gWSSG6BfuBbL68EE7RYfsItOks5rC0xWgaJpZM4FOBFi>
> > .
> >
>
>
>
> --
> Ray.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/40#issuecomment-263432042>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_ox9UBjscGCZrZM-bSZ-Eimw91bkXks5rC2g5gaJpZM4FOBFi>
> .
>
 > I know German continued to be written in Fraktur until the 1940s, so that might be easier. Or is there an old German that is analogous to Ye Old Shoppe for English?

Fraktur was used for an important German newspaper ([Reichsanzeiger](http://digi.bib.uni-mannheim.de/periodika/1/imperial-gazette/)) until 1945. I'd like to try some pages from that newspaper with Tesseract LSTM. Surprisingly even with the English data Tesseract was able to recognize at least some words written in Fraktur. Could you give me some hints how to create the data for `deu_frak`?

There is an Old High German (similar to Old English), but the German translation of the New Testament by Martin Luther (1521) was one of the first major printed books in German, and basically it started the modern German language (High German) which is used until today. > Stefan, please share the binaries for 4.0 alpha for Windows.

@Shreeshrii, they are online now at the usual location. See also the related pull request #511. Please report results either in the developer forum as suggested by @zdenop or by personal mail to me. >Is there a 3.04 vs 4.0 branch in tessdata for the traineddata files?

https://github.com/tesseract-ocr/tessdata/tree/3.04.00
 Thanks, Amit. Please add the info to the wiki also, if you have not already
done so.

On 29-Nov-2016 7:31 PM, "Amit D." <notifications@github.com> wrote:

> Is there a 3.04 vs 4.0 branch in tessdata for the traineddata files?
>
> https://github.com/tesseract-ocr/tessdata/tree/3.04.00
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/40#issuecomment-263577206>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o3a5AJ3je8sWymCBCFk_0jhhM1d9ks5rDDAegaJpZM4FOBFi>
> .
>
 Thanks, I will give it a try and report back.

On 29-Nov-2016 7:30 PM, "Stefan Weil" <notifications@github.com> wrote:

> Stefan, please share the binaries for 4.0 alpha for Windows.
>
> @Shreeshrii <https://github.com/Shreeshrii>, they are online now at the
> usual location. Please report results either in the developer forum as
> suggested by @zdenop <https://github.com/zdenop> or by personal mail to
> me.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tesseract-ocr/tesseract/issues/40#issuecomment-263577080>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AE2_o5J0hvvS7W2el0QDzXNO957qHvumks5rDDABgaJpZM4FOBFi>
> .
>
 >Amit. Please add the info to the wiki also, if you have not already done so.

You can do it yourself... :) @theraysmith @stweil 

Thank you! I tested a few devanagari pages with the 4.0 alpha windows binaries and traineddata for Hindi, Sanskrit, Marathi and Nepali. This was on a Windows 10 netbook, intel atom 1.33 ghz cpu, x64 based processor, 32 bit os, 2 GB RAM. I tested only with single page images and there was no performance problem on this basic netbook. The accuracy is much improved in the LSTM version. This is by just eyeballing the output (not using any software for comparison). 

From a user point of view, better accuracy maybe preferred to speed. So LSTM based engine seems the way to go, at least for devanagari scripts. I will test some of the other Indian languages later.

I have noticed some differences in processing between Hindi and the other Devanagari based languages and will add issues to the tessdata repository.

Thanks to the developers at Google and the tesseract community!



 @theraysmith 
> I don't think I generated the original deu_frak. I have the fonts to do so with LSTM, but I don't know if I have a decent amount of corpus data to hand. 

I have a decent amount of corpus data for Fraktur from scanned books at hand, about 500k lines in hOCR files (~50GB with TIF images). I've yet to publish it, but if you have somewhere where I could send/upload it, I'd be glad to.

Or is there a way to create the neccessary training files myself? I've had a cursory look through the OCR code and it looked like it needed `lstmf` files, but I haven't yet found what these are supposed to look like. >  500k lines should make it work really well. I would be happy to take it and help you, but we would have to get into licenses, copyright and all that first.

The text is CC0 and the images are CC-BY-NC, so that shouldn't be an issue :-) They're going to be public anyway once I've prepped the dataset for publication.
But even better if there are instructions, looking forward to playing around with training! Ray,

Please see my recent comment and attached files in
https://github.com/tesseract-ocr/tessdata/issues/6

Adding config files to trained data for san, mar and nep will fix this
issue related to skipped text with default psm.

I made a copy of hin.config and changed the default engine to oem 4, LSTM.
I also removed the blacklisting of 1, since Indo-arabic numbers in Latin
scripts are used quite commonly with Devanagari script text.

There are various other Devanagari related options in the config file,
which can be removed, if not needed with LSTM.

Thanks.
 Sad news: Cube is no longer with us.

Cube, you will be missed...

 @jbaiter have you tried 4.0 training for Fraktur?

@theraysmith Is there a way to use the old box-tiff pairs at https://github.com/paalberti/tesseract-dan-fraktur for LSTM training?

Also see tesseract related issue at https://github.com/paalberti/tesseract-dan-fraktur/issues/3

 >Is there a way to use the old box-tiff pairs at https://github.com/paalberti/tesseract-dan-fraktur for LSTM training?

There will be a way to generate a box file from a tiff image. The box file will be written in the [textline format](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#box-file-fornat---second-option)
https://github.com/tesseract-ocr/tesseract/issues/659#issuecomment-272564420
I started working on this today. I wrote the needed code and It seems to output the desired format, but I need to do some tests before publishing it. 
 @amitdo Not sure if that will work for Devanagari, because of the length of unicode string.

Is it possible to just add a box with  the tab character at end of each line for existing box files? >Not sure if that will work for Devanagari, because of the length of unicode string.

We will wait and see...

>Is it possible to just add a box with the tab character at end of each line for existing box files?

You mean manually?
You should add box coordinates, not just tab.    cntraining clusterer's are deleted, the last one is saved and used during final write, it seems. However there are still leaks with the protolists.. we still store the old protolists in the NormProtoList. This needs to be fixed somehow. 

mftraining memory leaks are fixed.
  I have updated the pkgbuild for tesseract-ocr for msys2 - please see https://github.com/Alexpux/MINGW-packages/pull/673
and make any required changes.

Thanks!
  I get a format specifier warning when building for Android using clang and tess-two:

```
jni/com_googlecode_tesseract_android/src/api/pdfrenderer.cpp:537:28: warning: format specifies type 'long' but the argument has type 'size_t' (aka 'unsigned int') [-Wformat]
               "stream\n", len);
                           ^~~
```

I think it should be `%zd` or `%zu` instead of `%ld`, but I'm not sure if that works on Visual Studio too.
 I'm the author of this code. I'd prefer to keep using size_t for this number since PDF files can be really big (although, this code will break for other reasons once we get larger than 10 gigabytes). Not sure what to do here to make all platforms happy.

http://stackoverflow.com/questions/2524611/how-to-print-size-t-variable-portably
 OK--since this warning isn't indicative of a larger problem, and there's no clear solution for muting this warning across the board, let's close this issue.
 That's not a solution. It's a bug, not a compiler warning which must be muted.

You will get a wrong results on little endian platforms when sizeof(long) != sizeof(size_t).
On big endian platforms the result is wrong when sizeof(long) > sizeof(size_t).

Adding a type cast would help: (long)len

Even better would be replacing "%ld" by "%lu" and using  this: (unsigned long)len
  The original issue tracker is gone, but there's an archived version here:
https://web.archive.org/web/20150413012229/https://code.google.com/p/tesseract-ocr/issues/detail?id=1378

Basically the request is to output the information contained in a hOCR file in tabular TSV format.
 Can this be merged to provide support for tables?

Thanks!
 What is the use case for this? I can't find any earlier discussion. As far as I can tell, all the information is included already in the hOCR output (more actually since it host LTR/RTL, italic/bold, etc) -- and, of course, even more info is available programmatically through the API.

Here's some example output: http://teksty.klf.uw.edu.pl/12/1/alice_1.png.hocr.tsv
archive: https://web.archive.org/web/20160201190446/http://teksty.klf.uw.edu.pl/12/1/alice_1.png.hocr.tsv
 I've created a cleaned up version of this code in #245. I'm not really happy about adding even more crap to baseapi.cpp, but I've got a separate branch to refactor the hOCR renderer out of it, so I can add the TSV renderer to that, if it's decided to include it in Tess.
 Wouldn't it be easier to keep the `TSV` code out of the Tesseract code and to provide a standalone script which does a transformation from `hOCR` to `TSV`? Such a script could also be used with `hOCR` generated by other tools.
 Link for one of the earlier requests

https://groups.google.com/forum/m/#!topic/tesseract-issues/-QOvWLrsjfI
- sent from my phone. excuse the brevity.
  On 01-Mar-2016 10:28 pm, "Tom Morris" notifications@github.com wrote:

> What is the use case for this? I can't find any earlier discussion. As far
> as I can tell, all the information is included already in the hOCR output
> (more actually since it host LTR/RTL, italic/bold, etc) -- and, of course,
> even more info is available programmatically through the API.
> 
> Here's some example output:
> http://teksty.klf.uw.edu.pl/12/1/alice_1.png.hocr.tsv
> archive:
> https://web.archive.org/web/20160201190446/http://teksty.klf.uw.edu.pl/12/1/alice_1.png.hocr.tsv
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/pull/18#issuecomment-190811980
> .
 The earlier issue mentioned is at: https://web.archive.org/web/20151128094905/http://code.google.com/p/tesseract-ocr/issues/detail?id=918

Basically it posits that TSV output as a (partial?) solution to table layout analysis.  I think it's a bit more involved that that, but I have no strong feelings one way or the other on adding this.

Pros:
- provides a simpler format for consumers than parsing HTML
- not really that big: 1 API call, 1 config variable, <200 lines code
- having it directly supports eliminates the need for external helper scripts

Cons:
- largely duplicates functionality available in hOCR output
- one more place to update if new information gets added to the output
- downstream consumers are going to be custom programs, so they could integrate HTML parsing instead of TSV parsing (with a small increase in complexity)

Like I said, I'm neutral. I'll let others argue yea or nay.
 Thanks Tom, for listing out the pros and cons for tsv.

As a user, I support having a simpler format of output without external
scripts :-)

Regarding the duplication of functionality, is it not possible to use a
common routine and then branch off based on required output format.

ShreeDevi

---

भजन - कीर्तन - आरती @ http://bhajans.ramparivar.com

On Wed, Mar 2, 2016 at 9:22 PM, Tom Morris notifications@github.com wrote:

> The earlier issue mentioned is at:
> https://web.archive.org/web/20151128094905/http://code.google.com/p/tesseract-ocr/issues/detail?id=918
> 
> Basically it posits that TSV output as a (partial?) solution to table
> layout analysis. I think it's a bit more involved that that, but I have no
> strong feelings one way or the other on adding this.
> 
> Pros:
> - provides a simpler format for consumers than parsing HTML
> - not really that big: 1 API call, 1 config variable, <200 lines code
> - having it directly supports eliminates the need for external helper
>   scripts
> 
> Cons:
> - largely duplicates functionality available in hOCR output
> - one more place to update if new information gets added to the output
> - downstream consumers are going to be custom programs, so they could
>   integrate HTML parsing instead of TSV parsing (with a small increase in
>   complexity)
> 
> Like I said, I'm neutral. I'll let others argue yea or nay.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/tesseract-ocr/tesseract/pull/18#issuecomment-191297761
> .
  Just glanced at the code and wondered why on Earth multiplication and division is being done in every iteration, especially on inner, nested loops. Look at this:

PIXELS_PER_BURST*NUM_CHANNELS)/CHAR_VEC_WIDTH

This is inside a loop nested 3 deep. How many wasted clock cycles is this? Are we assuming that the compiler will optimize this out? If you're benchmarking with debug builds, your numbers are going to be way off, as in meaningless.
  I don't think it is going to happen.
@theraysmith, should we close this PR?    Internet Archive copy of discussion in original issue: https://web.archive.org/web/20151128081631/http://code.google.com/p/tesseract-ocr/issues/detail?id=1199
 I think this one can be safely closed.
  Archive copy of issue (but full text is included above): https://web.archive.org/web/20151128081631/http://code.google.com/p/tesseract-ocr/issues/detail?id=1199
 @zdenop, please close this PR.  @orbitcowboy,
Can you reply to @tfmorris's comment?
https://github.com/tesseract-ocr/tesseract/pull/9#r53199684  This PR can be closed, see commit 97080412f which fixes the same issue [here](https://github.com/tesseract-ocr/tesseract/commit/97080412fdc8cef05b1f917e698277cd01c6f004#diff-262ca20242c273c5ad4f245d251b6aa8R894). Thanks Stefan. Somehow I missed that commit.  Fixed in commit d8a55d739  @theraysmith, should we close this PR? @zdenop, please close this PR.  :+1:  LGTM, but it's on an error path, so it's a pretty unlikely resource leak.
 @amitdo, I suggest to apply this PR.
